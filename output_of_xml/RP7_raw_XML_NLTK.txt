				 *** Text Processing using NLTK *** 


========================================== PARAGRAPH 1 ===========================================

Natural Language Processing: State of The Art, Current Trends and  

------------------- Sentence 1 -------------------

Natural Language Processing: State of The Art, Current Trends and

>> Tokens are: 
 ['Natural', 'Language', 'Processing', ':', 'State', 'The', 'Art', ',', 'Current', 'Trends']

>> Bigrams are: 
 [('Natural', 'Language'), ('Language', 'Processing'), ('Processing', ':'), (':', 'State'), ('State', 'The'), ('The', 'Art'), ('Art', ','), (',', 'Current'), ('Current', 'Trends')]

>> Trigrams are: 
 [('Natural', 'Language', 'Processing'), ('Language', 'Processing', ':'), ('Processing', ':', 'State'), (':', 'State', 'The'), ('State', 'The', 'Art'), ('The', 'Art', ','), ('Art', ',', 'Current'), (',', 'Current', 'Trends')]

>> POS Tags are: 
 [('Natural', 'JJ'), ('Language', 'NNP'), ('Processing', 'NN'), (':', ':'), ('State', 'VB'), ('The', 'DT'), ('Art', 'NNP'), (',', ','), ('Current', 'NNP'), ('Trends', 'NNP')]

>> Noun Phrases are: 
 ['Natural Language Processing', 'The Art', 'Current Trends']

>> Named Entities are: 
 [('ORGANIZATION', 'Art'), ('PERSON', 'Current Trends')] 

>> Stemming using Porter Stemmer: 
 [('Natural', 'natur'), ('Language', 'languag'), ('Processing', 'process'), (':', ':'), ('State', 'state'), ('The', 'the'), ('Art', 'art'), (',', ','), ('Current', 'current'), ('Trends', 'trend')]

>> Stemming using Snowball Stemmer: 
 [('Natural', 'natur'), ('Language', 'languag'), ('Processing', 'process'), (':', ':'), ('State', 'state'), ('The', 'the'), ('Art', 'art'), (',', ','), ('Current', 'current'), ('Trends', 'trend')]

>> Lemmatization: 
 [('Natural', 'Natural'), ('Language', 'Language'), ('Processing', 'Processing'), (':', ':'), ('State', 'State'), ('The', 'The'), ('Art', 'Art'), (',', ','), ('Current', 'Current'), ('Trends', 'Trends')]



========================================== PARAGRAPH 2 ===========================================

Challenges  

------------------- Sentence 1 -------------------

Challenges

>> Tokens are: 
 ['Challenges']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Challenges', 'NNS')]

>> Noun Phrases are: 
 ['Challenges']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Challenges', 'challeng')]

>> Stemming using Snowball Stemmer: 
 [('Challenges', 'challeng')]

>> Lemmatization: 
 [('Challenges', 'Challenges')]



========================================== PARAGRAPH 3 ===========================================

Diksha Khurana 1 , Aditya Koli 

------------------- Sentence 1 -------------------

Diksha Khurana 1 , Aditya Koli

>> Tokens are: 
 ['Diksha', 'Khurana', '1', ',', 'Aditya', 'Koli']

>> Bigrams are: 
 [('Diksha', 'Khurana'), ('Khurana', '1'), ('1', ','), (',', 'Aditya'), ('Aditya', 'Koli')]

>> Trigrams are: 
 [('Diksha', 'Khurana', '1'), ('Khurana', '1', ','), ('1', ',', 'Aditya'), (',', 'Aditya', 'Koli')]

>> POS Tags are: 
 [('Diksha', 'NNP'), ('Khurana', 'NNP'), ('1', 'CD'), (',', ','), ('Aditya', 'NNP'), ('Koli', 'NNP')]

>> Noun Phrases are: 
 ['Diksha Khurana', 'Aditya Koli']

>> Named Entities are: 
 [('PERSON', 'Diksha'), ('PERSON', 'Aditya Koli')] 

>> Stemming using Porter Stemmer: 
 [('Diksha', 'diksha'), ('Khurana', 'khurana'), ('1', '1'), (',', ','), ('Aditya', 'aditya'), ('Koli', 'koli')]

>> Stemming using Snowball Stemmer: 
 [('Diksha', 'diksha'), ('Khurana', 'khurana'), ('1', '1'), (',', ','), ('Aditya', 'aditya'), ('Koli', 'koli')]

>> Lemmatization: 
 [('Diksha', 'Diksha'), ('Khurana', 'Khurana'), ('1', '1'), (',', ','), ('Aditya', 'Aditya'), ('Koli', 'Koli')]



========================================== PARAGRAPH 4 ===========================================

1 , Kiran Khatter 

------------------- Sentence 1 -------------------

1 , Kiran Khatter

>> Tokens are: 
 ['1', ',', 'Kiran', 'Khatter']

>> Bigrams are: 
 [('1', ','), (',', 'Kiran'), ('Kiran', 'Khatter')]

>> Trigrams are: 
 [('1', ',', 'Kiran'), (',', 'Kiran', 'Khatter')]

>> POS Tags are: 
 [('1', 'CD'), (',', ','), ('Kiran', 'NNP'), ('Khatter', 'NNP')]

>> Noun Phrases are: 
 ['Kiran Khatter']

>> Named Entities are: 
 [('PERSON', 'Kiran Khatter')] 

>> Stemming using Porter Stemmer: 
 [('1', '1'), (',', ','), ('Kiran', 'kiran'), ('Khatter', 'khatter')]

>> Stemming using Snowball Stemmer: 
 [('1', '1'), (',', ','), ('Kiran', 'kiran'), ('Khatter', 'khatter')]

>> Lemmatization: 
 [('1', '1'), (',', ','), ('Kiran', 'Kiran'), ('Khatter', 'Khatter')]



========================================== PARAGRAPH 5 ===========================================

1,2  and Sukhdev Singh 

------------------- Sentence 1 -------------------

1,2  and Sukhdev Singh

>> Tokens are: 
 ['1,2', 'Sukhdev', 'Singh']

>> Bigrams are: 
 [('1,2', 'Sukhdev'), ('Sukhdev', 'Singh')]

>> Trigrams are: 
 [('1,2', 'Sukhdev', 'Singh')]

>> POS Tags are: 
 [('1,2', 'CD'), ('Sukhdev', 'NNP'), ('Singh', 'NNP')]

>> Noun Phrases are: 
 ['Sukhdev Singh']

>> Named Entities are: 
 [('PERSON', 'Sukhdev Singh')] 

>> Stemming using Porter Stemmer: 
 [('1,2', '1,2'), ('Sukhdev', 'sukhdev'), ('Singh', 'singh')]

>> Stemming using Snowball Stemmer: 
 [('1,2', '1,2'), ('Sukhdev', 'sukhdev'), ('Singh', 'singh')]

>> Lemmatization: 
 [('1,2', '1,2'), ('Sukhdev', 'Sukhdev'), ('Singh', 'Singh')]



========================================== PARAGRAPH 6 ===========================================

1,2   

------------------- Sentence 1 -------------------

1,2

>> Tokens are: 
 ['1,2']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('1,2', 'CD')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('1,2', '1,2')]

>> Stemming using Snowball Stemmer: 
 [('1,2', '1,2')]

>> Lemmatization: 
 [('1,2', '1,2')]



========================================== PARAGRAPH 7 ===========================================

1 Department of Computer Science and Engineering  

------------------- Sentence 1 -------------------

1 Department of Computer Science and Engineering

>> Tokens are: 
 ['1', 'Department', 'Computer', 'Science', 'Engineering']

>> Bigrams are: 
 [('1', 'Department'), ('Department', 'Computer'), ('Computer', 'Science'), ('Science', 'Engineering')]

>> Trigrams are: 
 [('1', 'Department', 'Computer'), ('Department', 'Computer', 'Science'), ('Computer', 'Science', 'Engineering')]

>> POS Tags are: 
 [('1', 'CD'), ('Department', 'NNP'), ('Computer', 'NNP'), ('Science', 'NNP'), ('Engineering', 'NNP')]

>> Noun Phrases are: 
 ['Department Computer Science Engineering']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('1', '1'), ('Department', 'depart'), ('Computer', 'comput'), ('Science', 'scienc'), ('Engineering', 'engin')]

>> Stemming using Snowball Stemmer: 
 [('1', '1'), ('Department', 'depart'), ('Computer', 'comput'), ('Science', 'scienc'), ('Engineering', 'engin')]

>> Lemmatization: 
 [('1', '1'), ('Department', 'Department'), ('Computer', 'Computer'), ('Science', 'Science'), ('Engineering', 'Engineering')]



========================================== PARAGRAPH 8 ===========================================

Manav Rachna International University, Faridabad-121004, India  2 Accendere Knowledge Management Services Pvt. Ltd., India  

------------------- Sentence 1 -------------------

Manav Rachna International University, Faridabad-121004, India  2 Accendere Knowledge Management Services Pvt.

>> Tokens are: 
 ['Manav', 'Rachna', 'International', 'University', ',', 'Faridabad-121004', ',', 'India', '2', 'Accendere', 'Knowledge', 'Management', 'Services', 'Pvt', '.']

>> Bigrams are: 
 [('Manav', 'Rachna'), ('Rachna', 'International'), ('International', 'University'), ('University', ','), (',', 'Faridabad-121004'), ('Faridabad-121004', ','), (',', 'India'), ('India', '2'), ('2', 'Accendere'), ('Accendere', 'Knowledge'), ('Knowledge', 'Management'), ('Management', 'Services'), ('Services', 'Pvt'), ('Pvt', '.')]

>> Trigrams are: 
 [('Manav', 'Rachna', 'International'), ('Rachna', 'International', 'University'), ('International', 'University', ','), ('University', ',', 'Faridabad-121004'), (',', 'Faridabad-121004', ','), ('Faridabad-121004', ',', 'India'), (',', 'India', '2'), ('India', '2', 'Accendere'), ('2', 'Accendere', 'Knowledge'), ('Accendere', 'Knowledge', 'Management'), ('Knowledge', 'Management', 'Services'), ('Management', 'Services', 'Pvt'), ('Services', 'Pvt', '.')]

>> POS Tags are: 
 [('Manav', 'NNP'), ('Rachna', 'NNP'), ('International', 'NNP'), ('University', 'NNP'), (',', ','), ('Faridabad-121004', 'NNP'), (',', ','), ('India', 'NNP'), ('2', 'CD'), ('Accendere', 'NNP'), ('Knowledge', 'NNP'), ('Management', 'NNP'), ('Services', 'NNPS'), ('Pvt', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Manav Rachna International University', 'Faridabad-121004', 'India', 'Accendere Knowledge Management', 'Pvt']

>> Named Entities are: 
 [('PERSON', 'Manav'), ('PERSON', 'Rachna International University'), ('GPE', 'India')] 

>> Stemming using Porter Stemmer: 
 [('Manav', 'manav'), ('Rachna', 'rachna'), ('International', 'intern'), ('University', 'univers'), (',', ','), ('Faridabad-121004', 'faridabad-121004'), (',', ','), ('India', 'india'), ('2', '2'), ('Accendere', 'accender'), ('Knowledge', 'knowledg'), ('Management', 'manag'), ('Services', 'servic'), ('Pvt', 'pvt'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Manav', 'manav'), ('Rachna', 'rachna'), ('International', 'intern'), ('University', 'univers'), (',', ','), ('Faridabad-121004', 'faridabad-121004'), (',', ','), ('India', 'india'), ('2', '2'), ('Accendere', 'accender'), ('Knowledge', 'knowledg'), ('Management', 'manag'), ('Services', 'servic'), ('Pvt', 'pvt'), ('.', '.')]

>> Lemmatization: 
 [('Manav', 'Manav'), ('Rachna', 'Rachna'), ('International', 'International'), ('University', 'University'), (',', ','), ('Faridabad-121004', 'Faridabad-121004'), (',', ','), ('India', 'India'), ('2', '2'), ('Accendere', 'Accendere'), ('Knowledge', 'Knowledge'), ('Management', 'Management'), ('Services', 'Services'), ('Pvt', 'Pvt'), ('.', '.')]


------------------- Sentence 2 -------------------

Ltd., India

>> Tokens are: 
 ['Ltd.', ',', 'India']

>> Bigrams are: 
 [('Ltd.', ','), (',', 'India')]

>> Trigrams are: 
 [('Ltd.', ',', 'India')]

>> POS Tags are: 
 [('Ltd.', 'NNP'), (',', ','), ('India', 'NNP')]

>> Noun Phrases are: 
 ['Ltd.', 'India']

>> Named Entities are: 
 [('GPE', 'India')] 

>> Stemming using Porter Stemmer: 
 [('Ltd.', 'ltd.'), (',', ','), ('India', 'india')]

>> Stemming using Snowball Stemmer: 
 [('Ltd.', 'ltd.'), (',', ','), ('India', 'india')]

>> Lemmatization: 
 [('Ltd.', 'Ltd.'), (',', ','), ('India', 'India')]



========================================== PARAGRAPH 9 ===========================================

  


========================================== PARAGRAPH 10 ===========================================

Abstract   

------------------- Sentence 1 -------------------

Abstract

>> Tokens are: 
 ['Abstract']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Abstract', 'NN')]

>> Noun Phrases are: 
 ['Abstract']

>> Named Entities are: 
 [('GPE', 'Abstract')] 

>> Stemming using Porter Stemmer: 
 [('Abstract', 'abstract')]

>> Stemming using Snowball Stemmer: 
 [('Abstract', 'abstract')]

>> Lemmatization: 
 [('Abstract', 'Abstract')]



========================================== PARAGRAPH 11 ===========================================

Natural language processing (NLP) has recently gained much attention for representing and  

------------------- Sentence 1 -------------------

Natural language processing (NLP) has recently gained much attention for representing and

>> Tokens are: 
 ['Natural', 'language', 'processing', '(', 'NLP', ')', 'recently', 'gained', 'much', 'attention', 'representing']

>> Bigrams are: 
 [('Natural', 'language'), ('language', 'processing'), ('processing', '('), ('(', 'NLP'), ('NLP', ')'), (')', 'recently'), ('recently', 'gained'), ('gained', 'much'), ('much', 'attention'), ('attention', 'representing')]

>> Trigrams are: 
 [('Natural', 'language', 'processing'), ('language', 'processing', '('), ('processing', '(', 'NLP'), ('(', 'NLP', ')'), ('NLP', ')', 'recently'), (')', 'recently', 'gained'), ('recently', 'gained', 'much'), ('gained', 'much', 'attention'), ('much', 'attention', 'representing')]

>> POS Tags are: 
 [('Natural', 'JJ'), ('language', 'NN'), ('processing', 'NN'), ('(', '('), ('NLP', 'NNP'), (')', ')'), ('recently', 'RB'), ('gained', 'VBD'), ('much', 'JJ'), ('attention', 'NN'), ('representing', 'VBG')]

>> Noun Phrases are: 
 ['Natural language processing', 'NLP', 'much attention']

>> Named Entities are: 
 [('ORGANIZATION', 'NLP')] 

>> Stemming using Porter Stemmer: 
 [('Natural', 'natur'), ('language', 'languag'), ('processing', 'process'), ('(', '('), ('NLP', 'nlp'), (')', ')'), ('recently', 'recent'), ('gained', 'gain'), ('much', 'much'), ('attention', 'attent'), ('representing', 'repres')]

>> Stemming using Snowball Stemmer: 
 [('Natural', 'natur'), ('language', 'languag'), ('processing', 'process'), ('(', '('), ('NLP', 'nlp'), (')', ')'), ('recently', 'recent'), ('gained', 'gain'), ('much', 'much'), ('attention', 'attent'), ('representing', 'repres')]

>> Lemmatization: 
 [('Natural', 'Natural'), ('language', 'language'), ('processing', 'processing'), ('(', '('), ('NLP', 'NLP'), (')', ')'), ('recently', 'recently'), ('gained', 'gained'), ('much', 'much'), ('attention', 'attention'), ('representing', 'representing')]



========================================== PARAGRAPH 12 ===========================================

analysing human language computationally. It has spread its applications in various fields  

------------------- Sentence 1 -------------------

analysing human language computationally.

>> Tokens are: 
 ['analysing', 'human', 'language', 'computationally', '.']

>> Bigrams are: 
 [('analysing', 'human'), ('human', 'language'), ('language', 'computationally'), ('computationally', '.')]

>> Trigrams are: 
 [('analysing', 'human', 'language'), ('human', 'language', 'computationally'), ('language', 'computationally', '.')]

>> POS Tags are: 
 [('analysing', 'VBG'), ('human', 'JJ'), ('language', 'NN'), ('computationally', 'RB'), ('.', '.')]

>> Noun Phrases are: 
 ['human language']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('analysing', 'analys'), ('human', 'human'), ('language', 'languag'), ('computationally', 'comput'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('analysing', 'analys'), ('human', 'human'), ('language', 'languag'), ('computationally', 'comput'), ('.', '.')]

>> Lemmatization: 
 [('analysing', 'analysing'), ('human', 'human'), ('language', 'language'), ('computationally', 'computationally'), ('.', '.')]


------------------- Sentence 2 -------------------

It has spread its applications in various fields

>> Tokens are: 
 ['It', 'spread', 'applications', 'various', 'fields']

>> Bigrams are: 
 [('It', 'spread'), ('spread', 'applications'), ('applications', 'various'), ('various', 'fields')]

>> Trigrams are: 
 [('It', 'spread', 'applications'), ('spread', 'applications', 'various'), ('applications', 'various', 'fields')]

>> POS Tags are: 
 [('It', 'PRP'), ('spread', 'VBD'), ('applications', 'NNS'), ('various', 'JJ'), ('fields', 'NNS')]

>> Noun Phrases are: 
 ['applications', 'various fields']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('It', 'it'), ('spread', 'spread'), ('applications', 'applic'), ('various', 'variou'), ('fields', 'field')]

>> Stemming using Snowball Stemmer: 
 [('It', 'it'), ('spread', 'spread'), ('applications', 'applic'), ('various', 'various'), ('fields', 'field')]

>> Lemmatization: 
 [('It', 'It'), ('spread', 'spread'), ('applications', 'application'), ('various', 'various'), ('fields', 'field')]



========================================== PARAGRAPH 13 ===========================================

such as machine translation, email spam detection, information extraction, summarization,  

------------------- Sentence 1 -------------------

such as machine translation, email spam detection, information extraction, summarization,

>> Tokens are: 
 ['machine', 'translation', ',', 'email', 'spam', 'detection', ',', 'information', 'extraction', ',', 'summarization', ',']

>> Bigrams are: 
 [('machine', 'translation'), ('translation', ','), (',', 'email'), ('email', 'spam'), ('spam', 'detection'), ('detection', ','), (',', 'information'), ('information', 'extraction'), ('extraction', ','), (',', 'summarization'), ('summarization', ',')]

>> Trigrams are: 
 [('machine', 'translation', ','), ('translation', ',', 'email'), (',', 'email', 'spam'), ('email', 'spam', 'detection'), ('spam', 'detection', ','), ('detection', ',', 'information'), (',', 'information', 'extraction'), ('information', 'extraction', ','), ('extraction', ',', 'summarization'), (',', 'summarization', ',')]

>> POS Tags are: 
 [('machine', 'NN'), ('translation', 'NN'), (',', ','), ('email', 'VBP'), ('spam', 'JJ'), ('detection', 'NN'), (',', ','), ('information', 'NN'), ('extraction', 'NN'), (',', ','), ('summarization', 'NN'), (',', ',')]

>> Noun Phrases are: 
 ['machine translation', 'spam detection', 'information extraction', 'summarization']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('machine', 'machin'), ('translation', 'translat'), (',', ','), ('email', 'email'), ('spam', 'spam'), ('detection', 'detect'), (',', ','), ('information', 'inform'), ('extraction', 'extract'), (',', ','), ('summarization', 'summar'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('machine', 'machin'), ('translation', 'translat'), (',', ','), ('email', 'email'), ('spam', 'spam'), ('detection', 'detect'), (',', ','), ('information', 'inform'), ('extraction', 'extract'), (',', ','), ('summarization', 'summar'), (',', ',')]

>> Lemmatization: 
 [('machine', 'machine'), ('translation', 'translation'), (',', ','), ('email', 'email'), ('spam', 'spam'), ('detection', 'detection'), (',', ','), ('information', 'information'), ('extraction', 'extraction'), (',', ','), ('summarization', 'summarization'), (',', ',')]



========================================== PARAGRAPH 14 ===========================================

medical, and question answering etc. The paper distinguishes four phases by discussing  

------------------- Sentence 1 -------------------

medical, and question answering etc.

>> Tokens are: 
 ['medical', ',', 'question', 'answering', 'etc', '.']

>> Bigrams are: 
 [('medical', ','), (',', 'question'), ('question', 'answering'), ('answering', 'etc'), ('etc', '.')]

>> Trigrams are: 
 [('medical', ',', 'question'), (',', 'question', 'answering'), ('question', 'answering', 'etc'), ('answering', 'etc', '.')]

>> POS Tags are: 
 [('medical', 'JJ'), (',', ','), ('question', 'NN'), ('answering', 'VBG'), ('etc', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['question', 'etc']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('medical', 'medic'), (',', ','), ('question', 'question'), ('answering', 'answer'), ('etc', 'etc'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('medical', 'medic'), (',', ','), ('question', 'question'), ('answering', 'answer'), ('etc', 'etc'), ('.', '.')]

>> Lemmatization: 
 [('medical', 'medical'), (',', ','), ('question', 'question'), ('answering', 'answering'), ('etc', 'etc'), ('.', '.')]


------------------- Sentence 2 -------------------

The paper distinguishes four phases by discussing

>> Tokens are: 
 ['The', 'paper', 'distinguishes', 'four', 'phases', 'discussing']

>> Bigrams are: 
 [('The', 'paper'), ('paper', 'distinguishes'), ('distinguishes', 'four'), ('four', 'phases'), ('phases', 'discussing')]

>> Trigrams are: 
 [('The', 'paper', 'distinguishes'), ('paper', 'distinguishes', 'four'), ('distinguishes', 'four', 'phases'), ('four', 'phases', 'discussing')]

>> POS Tags are: 
 [('The', 'DT'), ('paper', 'NN'), ('distinguishes', 'VBZ'), ('four', 'CD'), ('phases', 'NNS'), ('discussing', 'VBG')]

>> Noun Phrases are: 
 ['The paper', 'phases']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('paper', 'paper'), ('distinguishes', 'distinguish'), ('four', 'four'), ('phases', 'phase'), ('discussing', 'discuss')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('paper', 'paper'), ('distinguishes', 'distinguish'), ('four', 'four'), ('phases', 'phase'), ('discussing', 'discuss')]

>> Lemmatization: 
 [('The', 'The'), ('paper', 'paper'), ('distinguishes', 'distinguishes'), ('four', 'four'), ('phases', 'phase'), ('discussing', 'discussing')]



========================================== PARAGRAPH 15 ===========================================

different levels of NLP and components of Natural Language Generation (NLG) followed by  

------------------- Sentence 1 -------------------

different levels of NLP and components of Natural Language Generation (NLG) followed by

>> Tokens are: 
 ['different', 'levels', 'NLP', 'components', 'Natural', 'Language', 'Generation', '(', 'NLG', ')', 'followed']

>> Bigrams are: 
 [('different', 'levels'), ('levels', 'NLP'), ('NLP', 'components'), ('components', 'Natural'), ('Natural', 'Language'), ('Language', 'Generation'), ('Generation', '('), ('(', 'NLG'), ('NLG', ')'), (')', 'followed')]

>> Trigrams are: 
 [('different', 'levels', 'NLP'), ('levels', 'NLP', 'components'), ('NLP', 'components', 'Natural'), ('components', 'Natural', 'Language'), ('Natural', 'Language', 'Generation'), ('Language', 'Generation', '('), ('Generation', '(', 'NLG'), ('(', 'NLG', ')'), ('NLG', ')', 'followed')]

>> POS Tags are: 
 [('different', 'JJ'), ('levels', 'NNS'), ('NLP', 'NNP'), ('components', 'NNS'), ('Natural', 'NNP'), ('Language', 'NNP'), ('Generation', 'NNP'), ('(', '('), ('NLG', 'NNP'), (')', ')'), ('followed', 'VBD')]

>> Noun Phrases are: 
 ['different levels NLP components Natural Language Generation', 'NLG']

>> Named Entities are: 
 [('ORGANIZATION', 'NLP'), ('ORGANIZATION', 'Natural Language Generation'), ('ORGANIZATION', 'NLG')] 

>> Stemming using Porter Stemmer: 
 [('different', 'differ'), ('levels', 'level'), ('NLP', 'nlp'), ('components', 'compon'), ('Natural', 'natur'), ('Language', 'languag'), ('Generation', 'gener'), ('(', '('), ('NLG', 'nlg'), (')', ')'), ('followed', 'follow')]

>> Stemming using Snowball Stemmer: 
 [('different', 'differ'), ('levels', 'level'), ('NLP', 'nlp'), ('components', 'compon'), ('Natural', 'natur'), ('Language', 'languag'), ('Generation', 'generat'), ('(', '('), ('NLG', 'nlg'), (')', ')'), ('followed', 'follow')]

>> Lemmatization: 
 [('different', 'different'), ('levels', 'level'), ('NLP', 'NLP'), ('components', 'component'), ('Natural', 'Natural'), ('Language', 'Language'), ('Generation', 'Generation'), ('(', '('), ('NLG', 'NLG'), (')', ')'), ('followed', 'followed')]



========================================== PARAGRAPH 16 ===========================================

presenting the history and evolution of NLP, state of the art presenting the various  

------------------- Sentence 1 -------------------

presenting the history and evolution of NLP, state of the art presenting the various

>> Tokens are: 
 ['presenting', 'history', 'evolution', 'NLP', ',', 'state', 'art', 'presenting', 'various']

>> Bigrams are: 
 [('presenting', 'history'), ('history', 'evolution'), ('evolution', 'NLP'), ('NLP', ','), (',', 'state'), ('state', 'art'), ('art', 'presenting'), ('presenting', 'various')]

>> Trigrams are: 
 [('presenting', 'history', 'evolution'), ('history', 'evolution', 'NLP'), ('evolution', 'NLP', ','), ('NLP', ',', 'state'), (',', 'state', 'art'), ('state', 'art', 'presenting'), ('art', 'presenting', 'various')]

>> POS Tags are: 
 [('presenting', 'VBG'), ('history', 'NN'), ('evolution', 'NN'), ('NLP', 'NNP'), (',', ','), ('state', 'NN'), ('art', 'NN'), ('presenting', 'VBG'), ('various', 'JJ')]

>> Noun Phrases are: 
 ['history evolution NLP', 'state art']

>> Named Entities are: 
 [('ORGANIZATION', 'NLP')] 

>> Stemming using Porter Stemmer: 
 [('presenting', 'present'), ('history', 'histori'), ('evolution', 'evolut'), ('NLP', 'nlp'), (',', ','), ('state', 'state'), ('art', 'art'), ('presenting', 'present'), ('various', 'variou')]

>> Stemming using Snowball Stemmer: 
 [('presenting', 'present'), ('history', 'histori'), ('evolution', 'evolut'), ('NLP', 'nlp'), (',', ','), ('state', 'state'), ('art', 'art'), ('presenting', 'present'), ('various', 'various')]

>> Lemmatization: 
 [('presenting', 'presenting'), ('history', 'history'), ('evolution', 'evolution'), ('NLP', 'NLP'), (',', ','), ('state', 'state'), ('art', 'art'), ('presenting', 'presenting'), ('various', 'various')]



========================================== PARAGRAPH 17 ===========================================

applications of NLP and current trends and challenges.   

------------------- Sentence 1 -------------------

applications of NLP and current trends and challenges.

>> Tokens are: 
 ['applications', 'NLP', 'current', 'trends', 'challenges', '.']

>> Bigrams are: 
 [('applications', 'NLP'), ('NLP', 'current'), ('current', 'trends'), ('trends', 'challenges'), ('challenges', '.')]

>> Trigrams are: 
 [('applications', 'NLP', 'current'), ('NLP', 'current', 'trends'), ('current', 'trends', 'challenges'), ('trends', 'challenges', '.')]

>> POS Tags are: 
 [('applications', 'NNS'), ('NLP', 'NNP'), ('current', 'JJ'), ('trends', 'NNS'), ('challenges', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['applications NLP', 'current trends challenges']

>> Named Entities are: 
 [('ORGANIZATION', 'NLP')] 

>> Stemming using Porter Stemmer: 
 [('applications', 'applic'), ('NLP', 'nlp'), ('current', 'current'), ('trends', 'trend'), ('challenges', 'challeng'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('applications', 'applic'), ('NLP', 'nlp'), ('current', 'current'), ('trends', 'trend'), ('challenges', 'challeng'), ('.', '.')]

>> Lemmatization: 
 [('applications', 'application'), ('NLP', 'NLP'), ('current', 'current'), ('trends', 'trend'), ('challenges', 'challenge'), ('.', '.')]



========================================== PARAGRAPH 18 ===========================================

  


========================================== PARAGRAPH 19 ===========================================

1. Introduction  

------------------- Sentence 1 -------------------

1.

>> Tokens are: 
 ['1', '.']

>> Bigrams are: 
 [('1', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('1', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('1', '1'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('1', '1'), ('.', '.')]

>> Lemmatization: 
 [('1', '1'), ('.', '.')]


------------------- Sentence 2 -------------------

Introduction

>> Tokens are: 
 ['Introduction']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Introduction', 'NN')]

>> Noun Phrases are: 
 ['Introduction']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Introduction', 'introduct')]

>> Stemming using Snowball Stemmer: 
 [('Introduction', 'introduct')]

>> Lemmatization: 
 [('Introduction', 'Introduction')]



========================================== PARAGRAPH 20 ===========================================

Natural Language Processing (NLP) is a tract of Artificial Intelligence and Linguistics,  

------------------- Sentence 1 -------------------

Natural Language Processing (NLP) is a tract of Artificial Intelligence and Linguistics,

>> Tokens are: 
 ['Natural', 'Language', 'Processing', '(', 'NLP', ')', 'tract', 'Artificial', 'Intelligence', 'Linguistics', ',']

>> Bigrams are: 
 [('Natural', 'Language'), ('Language', 'Processing'), ('Processing', '('), ('(', 'NLP'), ('NLP', ')'), (')', 'tract'), ('tract', 'Artificial'), ('Artificial', 'Intelligence'), ('Intelligence', 'Linguistics'), ('Linguistics', ',')]

>> Trigrams are: 
 [('Natural', 'Language', 'Processing'), ('Language', 'Processing', '('), ('Processing', '(', 'NLP'), ('(', 'NLP', ')'), ('NLP', ')', 'tract'), (')', 'tract', 'Artificial'), ('tract', 'Artificial', 'Intelligence'), ('Artificial', 'Intelligence', 'Linguistics'), ('Intelligence', 'Linguistics', ',')]

>> POS Tags are: 
 [('Natural', 'JJ'), ('Language', 'NNP'), ('Processing', 'NNP'), ('(', '('), ('NLP', 'NNP'), (')', ')'), ('tract', 'VBP'), ('Artificial', 'JJ'), ('Intelligence', 'NNP'), ('Linguistics', 'NNP'), (',', ',')]

>> Noun Phrases are: 
 ['Natural Language Processing', 'NLP', 'Artificial Intelligence Linguistics']

>> Named Entities are: 
 [('ORGANIZATION', 'NLP'), ('ORGANIZATION', 'Artificial Intelligence Linguistics')] 

>> Stemming using Porter Stemmer: 
 [('Natural', 'natur'), ('Language', 'languag'), ('Processing', 'process'), ('(', '('), ('NLP', 'nlp'), (')', ')'), ('tract', 'tract'), ('Artificial', 'artifici'), ('Intelligence', 'intellig'), ('Linguistics', 'linguist'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('Natural', 'natur'), ('Language', 'languag'), ('Processing', 'process'), ('(', '('), ('NLP', 'nlp'), (')', ')'), ('tract', 'tract'), ('Artificial', 'artifici'), ('Intelligence', 'intellig'), ('Linguistics', 'linguist'), (',', ',')]

>> Lemmatization: 
 [('Natural', 'Natural'), ('Language', 'Language'), ('Processing', 'Processing'), ('(', '('), ('NLP', 'NLP'), (')', ')'), ('tract', 'tract'), ('Artificial', 'Artificial'), ('Intelligence', 'Intelligence'), ('Linguistics', 'Linguistics'), (',', ',')]



========================================== PARAGRAPH 21 ===========================================

devoted to make computers understand the statements or words written in human languages.  

------------------- Sentence 1 -------------------

devoted to make computers understand the statements or words written in human languages.

>> Tokens are: 
 ['devoted', 'make', 'computers', 'understand', 'statements', 'words', 'written', 'human', 'languages', '.']

>> Bigrams are: 
 [('devoted', 'make'), ('make', 'computers'), ('computers', 'understand'), ('understand', 'statements'), ('statements', 'words'), ('words', 'written'), ('written', 'human'), ('human', 'languages'), ('languages', '.')]

>> Trigrams are: 
 [('devoted', 'make', 'computers'), ('make', 'computers', 'understand'), ('computers', 'understand', 'statements'), ('understand', 'statements', 'words'), ('statements', 'words', 'written'), ('words', 'written', 'human'), ('written', 'human', 'languages'), ('human', 'languages', '.')]

>> POS Tags are: 
 [('devoted', 'VBN'), ('make', 'VBP'), ('computers', 'NNS'), ('understand', 'JJ'), ('statements', 'NNS'), ('words', 'NNS'), ('written', 'VBN'), ('human', 'JJ'), ('languages', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['computers', 'understand statements words', 'human languages']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('devoted', 'devot'), ('make', 'make'), ('computers', 'comput'), ('understand', 'understand'), ('statements', 'statement'), ('words', 'word'), ('written', 'written'), ('human', 'human'), ('languages', 'languag'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('devoted', 'devot'), ('make', 'make'), ('computers', 'comput'), ('understand', 'understand'), ('statements', 'statement'), ('words', 'word'), ('written', 'written'), ('human', 'human'), ('languages', 'languag'), ('.', '.')]

>> Lemmatization: 
 [('devoted', 'devoted'), ('make', 'make'), ('computers', 'computer'), ('understand', 'understand'), ('statements', 'statement'), ('words', 'word'), ('written', 'written'), ('human', 'human'), ('languages', 'language'), ('.', '.')]



========================================== PARAGRAPH 22 ===========================================

Natural language processing came into existence to ease the user’s work and to satisfy the  

------------------- Sentence 1 -------------------

Natural language processing came into existence to ease the user’s work and to satisfy the

>> Tokens are: 
 ['Natural', 'language', 'processing', 'came', 'existence', 'ease', 'user', '’', 'work', 'satisfy']

>> Bigrams are: 
 [('Natural', 'language'), ('language', 'processing'), ('processing', 'came'), ('came', 'existence'), ('existence', 'ease'), ('ease', 'user'), ('user', '’'), ('’', 'work'), ('work', 'satisfy')]

>> Trigrams are: 
 [('Natural', 'language', 'processing'), ('language', 'processing', 'came'), ('processing', 'came', 'existence'), ('came', 'existence', 'ease'), ('existence', 'ease', 'user'), ('ease', 'user', '’'), ('user', '’', 'work'), ('’', 'work', 'satisfy')]

>> POS Tags are: 
 [('Natural', 'JJ'), ('language', 'NN'), ('processing', 'NN'), ('came', 'VBD'), ('existence', 'RB'), ('ease', 'JJ'), ('user', 'NN'), ('’', 'NNP'), ('work', 'NN'), ('satisfy', 'NN')]

>> Noun Phrases are: 
 ['Natural language processing', 'ease user ’ work satisfy']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Natural', 'natur'), ('language', 'languag'), ('processing', 'process'), ('came', 'came'), ('existence', 'exist'), ('ease', 'eas'), ('user', 'user'), ('’', '’'), ('work', 'work'), ('satisfy', 'satisfi')]

>> Stemming using Snowball Stemmer: 
 [('Natural', 'natur'), ('language', 'languag'), ('processing', 'process'), ('came', 'came'), ('existence', 'exist'), ('ease', 'eas'), ('user', 'user'), ('’', '’'), ('work', 'work'), ('satisfy', 'satisfi')]

>> Lemmatization: 
 [('Natural', 'Natural'), ('language', 'language'), ('processing', 'processing'), ('came', 'came'), ('existence', 'existence'), ('ease', 'ease'), ('user', 'user'), ('’', '’'), ('work', 'work'), ('satisfy', 'satisfy')]



========================================== PARAGRAPH 23 ===========================================

wish to communicate with the computer in natural language. Since all the users may not be  

------------------- Sentence 1 -------------------

wish to communicate with the computer in natural language.

>> Tokens are: 
 ['wish', 'communicate', 'computer', 'natural', 'language', '.']

>> Bigrams are: 
 [('wish', 'communicate'), ('communicate', 'computer'), ('computer', 'natural'), ('natural', 'language'), ('language', '.')]

>> Trigrams are: 
 [('wish', 'communicate', 'computer'), ('communicate', 'computer', 'natural'), ('computer', 'natural', 'language'), ('natural', 'language', '.')]

>> POS Tags are: 
 [('wish', 'JJ'), ('communicate', 'NN'), ('computer', 'NN'), ('natural', 'JJ'), ('language', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['wish communicate computer', 'natural language']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('wish', 'wish'), ('communicate', 'commun'), ('computer', 'comput'), ('natural', 'natur'), ('language', 'languag'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('wish', 'wish'), ('communicate', 'communic'), ('computer', 'comput'), ('natural', 'natur'), ('language', 'languag'), ('.', '.')]

>> Lemmatization: 
 [('wish', 'wish'), ('communicate', 'communicate'), ('computer', 'computer'), ('natural', 'natural'), ('language', 'language'), ('.', '.')]


------------------- Sentence 2 -------------------

Since all the users may not be

>> Tokens are: 
 ['Since', 'users', 'may']

>> Bigrams are: 
 [('Since', 'users'), ('users', 'may')]

>> Trigrams are: 
 [('Since', 'users', 'may')]

>> POS Tags are: 
 [('Since', 'IN'), ('users', 'NNS'), ('may', 'MD')]

>> Noun Phrases are: 
 ['users']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Since', 'sinc'), ('users', 'user'), ('may', 'may')]

>> Stemming using Snowball Stemmer: 
 [('Since', 'sinc'), ('users', 'user'), ('may', 'may')]

>> Lemmatization: 
 [('Since', 'Since'), ('users', 'user'), ('may', 'may')]



========================================== PARAGRAPH 24 ===========================================

well-versed in machine specific language, NLP caters those users who do not have enough  

------------------- Sentence 1 -------------------

well-versed in machine specific language, NLP caters those users who do not have enough

>> Tokens are: 
 ['well-versed', 'machine', 'specific', 'language', ',', 'NLP', 'caters', 'users', 'enough']

>> Bigrams are: 
 [('well-versed', 'machine'), ('machine', 'specific'), ('specific', 'language'), ('language', ','), (',', 'NLP'), ('NLP', 'caters'), ('caters', 'users'), ('users', 'enough')]

>> Trigrams are: 
 [('well-versed', 'machine', 'specific'), ('machine', 'specific', 'language'), ('specific', 'language', ','), ('language', ',', 'NLP'), (',', 'NLP', 'caters'), ('NLP', 'caters', 'users'), ('caters', 'users', 'enough')]

>> POS Tags are: 
 [('well-versed', 'JJ'), ('machine', 'NN'), ('specific', 'JJ'), ('language', 'NN'), (',', ','), ('NLP', 'NNP'), ('caters', 'VBZ'), ('users', 'NNS'), ('enough', 'RB')]

>> Noun Phrases are: 
 ['well-versed machine', 'specific language', 'NLP', 'users']

>> Named Entities are: 
 [('ORGANIZATION', 'NLP')] 

>> Stemming using Porter Stemmer: 
 [('well-versed', 'well-vers'), ('machine', 'machin'), ('specific', 'specif'), ('language', 'languag'), (',', ','), ('NLP', 'nlp'), ('caters', 'cater'), ('users', 'user'), ('enough', 'enough')]

>> Stemming using Snowball Stemmer: 
 [('well-versed', 'well-vers'), ('machine', 'machin'), ('specific', 'specif'), ('language', 'languag'), (',', ','), ('NLP', 'nlp'), ('caters', 'cater'), ('users', 'user'), ('enough', 'enough')]

>> Lemmatization: 
 [('well-versed', 'well-versed'), ('machine', 'machine'), ('specific', 'specific'), ('language', 'language'), (',', ','), ('NLP', 'NLP'), ('caters', 'caters'), ('users', 'user'), ('enough', 'enough')]



========================================== PARAGRAPH 25 ===========================================

time to learn new languages or get perfection in it.   

------------------- Sentence 1 -------------------

time to learn new languages or get perfection in it.

>> Tokens are: 
 ['time', 'learn', 'new', 'languages', 'get', 'perfection', '.']

>> Bigrams are: 
 [('time', 'learn'), ('learn', 'new'), ('new', 'languages'), ('languages', 'get'), ('get', 'perfection'), ('perfection', '.')]

>> Trigrams are: 
 [('time', 'learn', 'new'), ('learn', 'new', 'languages'), ('new', 'languages', 'get'), ('languages', 'get', 'perfection'), ('get', 'perfection', '.')]

>> POS Tags are: 
 [('time', 'NN'), ('learn', 'VB'), ('new', 'JJ'), ('languages', 'NNS'), ('get', 'VBP'), ('perfection', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['time', 'new languages', 'perfection']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('time', 'time'), ('learn', 'learn'), ('new', 'new'), ('languages', 'languag'), ('get', 'get'), ('perfection', 'perfect'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('time', 'time'), ('learn', 'learn'), ('new', 'new'), ('languages', 'languag'), ('get', 'get'), ('perfection', 'perfect'), ('.', '.')]

>> Lemmatization: 
 [('time', 'time'), ('learn', 'learn'), ('new', 'new'), ('languages', 'language'), ('get', 'get'), ('perfection', 'perfection'), ('.', '.')]



========================================== PARAGRAPH 26 ===========================================

A language can be defined as a set of rules or set of symbol. Symbol are combined and used  

------------------- Sentence 1 -------------------

A language can be defined as a set of rules or set of symbol.

>> Tokens are: 
 ['A', 'language', 'defined', 'set', 'rules', 'set', 'symbol', '.']

>> Bigrams are: 
 [('A', 'language'), ('language', 'defined'), ('defined', 'set'), ('set', 'rules'), ('rules', 'set'), ('set', 'symbol'), ('symbol', '.')]

>> Trigrams are: 
 [('A', 'language', 'defined'), ('language', 'defined', 'set'), ('defined', 'set', 'rules'), ('set', 'rules', 'set'), ('rules', 'set', 'symbol'), ('set', 'symbol', '.')]

>> POS Tags are: 
 [('A', 'DT'), ('language', 'NN'), ('defined', 'VBN'), ('set', 'VBN'), ('rules', 'NNS'), ('set', 'VBD'), ('symbol', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['A language', 'rules', 'symbol']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('A', 'a'), ('language', 'languag'), ('defined', 'defin'), ('set', 'set'), ('rules', 'rule'), ('set', 'set'), ('symbol', 'symbol'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('A', 'a'), ('language', 'languag'), ('defined', 'defin'), ('set', 'set'), ('rules', 'rule'), ('set', 'set'), ('symbol', 'symbol'), ('.', '.')]

>> Lemmatization: 
 [('A', 'A'), ('language', 'language'), ('defined', 'defined'), ('set', 'set'), ('rules', 'rule'), ('set', 'set'), ('symbol', 'symbol'), ('.', '.')]


------------------- Sentence 2 -------------------

Symbol are combined and used

>> Tokens are: 
 ['Symbol', 'combined', 'used']

>> Bigrams are: 
 [('Symbol', 'combined'), ('combined', 'used')]

>> Trigrams are: 
 [('Symbol', 'combined', 'used')]

>> POS Tags are: 
 [('Symbol', 'NN'), ('combined', 'VBD'), ('used', 'VBN')]

>> Noun Phrases are: 
 ['Symbol']

>> Named Entities are: 
 [('PERSON', 'Symbol')] 

>> Stemming using Porter Stemmer: 
 [('Symbol', 'symbol'), ('combined', 'combin'), ('used', 'use')]

>> Stemming using Snowball Stemmer: 
 [('Symbol', 'symbol'), ('combined', 'combin'), ('used', 'use')]

>> Lemmatization: 
 [('Symbol', 'Symbol'), ('combined', 'combined'), ('used', 'used')]



========================================== PARAGRAPH 27 ===========================================

for conveying information or broadcasting the information. Symbols are tyrannized by the  

------------------- Sentence 1 -------------------

for conveying information or broadcasting the information.

>> Tokens are: 
 ['conveying', 'information', 'broadcasting', 'information', '.']

>> Bigrams are: 
 [('conveying', 'information'), ('information', 'broadcasting'), ('broadcasting', 'information'), ('information', '.')]

>> Trigrams are: 
 [('conveying', 'information', 'broadcasting'), ('information', 'broadcasting', 'information'), ('broadcasting', 'information', '.')]

>> POS Tags are: 
 [('conveying', 'VBG'), ('information', 'NN'), ('broadcasting', 'VBG'), ('information', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['information', 'information']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('conveying', 'convey'), ('information', 'inform'), ('broadcasting', 'broadcast'), ('information', 'inform'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('conveying', 'convey'), ('information', 'inform'), ('broadcasting', 'broadcast'), ('information', 'inform'), ('.', '.')]

>> Lemmatization: 
 [('conveying', 'conveying'), ('information', 'information'), ('broadcasting', 'broadcasting'), ('information', 'information'), ('.', '.')]


------------------- Sentence 2 -------------------

Symbols are tyrannized by the

>> Tokens are: 
 ['Symbols', 'tyrannized']

>> Bigrams are: 
 [('Symbols', 'tyrannized')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Symbols', 'NNS'), ('tyrannized', 'VBD')]

>> Noun Phrases are: 
 ['Symbols']

>> Named Entities are: 
 [('PERSON', 'Symbols')] 

>> Stemming using Porter Stemmer: 
 [('Symbols', 'symbol'), ('tyrannized', 'tyrann')]

>> Stemming using Snowball Stemmer: 
 [('Symbols', 'symbol'), ('tyrannized', 'tyrann')]

>> Lemmatization: 
 [('Symbols', 'Symbols'), ('tyrannized', 'tyrannized')]



========================================== PARAGRAPH 28 ===========================================

Rules. Natural Language Processing basically can be classified into two parts i.e.- Natural  

------------------- Sentence 1 -------------------

Rules.

>> Tokens are: 
 ['Rules', '.']

>> Bigrams are: 
 [('Rules', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Rules', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['Rules']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Rules', 'rule'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Rules', 'rule'), ('.', '.')]

>> Lemmatization: 
 [('Rules', 'Rules'), ('.', '.')]


------------------- Sentence 2 -------------------

Natural Language Processing basically can be classified into two parts i.e.- Natural

>> Tokens are: 
 ['Natural', 'Language', 'Processing', 'basically', 'classified', 'two', 'parts', 'i.e.-', 'Natural']

>> Bigrams are: 
 [('Natural', 'Language'), ('Language', 'Processing'), ('Processing', 'basically'), ('basically', 'classified'), ('classified', 'two'), ('two', 'parts'), ('parts', 'i.e.-'), ('i.e.-', 'Natural')]

>> Trigrams are: 
 [('Natural', 'Language', 'Processing'), ('Language', 'Processing', 'basically'), ('Processing', 'basically', 'classified'), ('basically', 'classified', 'two'), ('classified', 'two', 'parts'), ('two', 'parts', 'i.e.-'), ('parts', 'i.e.-', 'Natural')]

>> POS Tags are: 
 [('Natural', 'JJ'), ('Language', 'NNP'), ('Processing', 'NNP'), ('basically', 'RB'), ('classified', 'VBD'), ('two', 'CD'), ('parts', 'NNS'), ('i.e.-', 'JJ'), ('Natural', 'NNP')]

>> Noun Phrases are: 
 ['Natural Language Processing', 'parts', 'i.e.- Natural']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Natural', 'natur'), ('Language', 'languag'), ('Processing', 'process'), ('basically', 'basic'), ('classified', 'classifi'), ('two', 'two'), ('parts', 'part'), ('i.e.-', 'i.e.-'), ('Natural', 'natur')]

>> Stemming using Snowball Stemmer: 
 [('Natural', 'natur'), ('Language', 'languag'), ('Processing', 'process'), ('basically', 'basic'), ('classified', 'classifi'), ('two', 'two'), ('parts', 'part'), ('i.e.-', 'i.e.-'), ('Natural', 'natur')]

>> Lemmatization: 
 [('Natural', 'Natural'), ('Language', 'Language'), ('Processing', 'Processing'), ('basically', 'basically'), ('classified', 'classified'), ('two', 'two'), ('parts', 'part'), ('i.e.-', 'i.e.-'), ('Natural', 'Natural')]



========================================== PARAGRAPH 29 ===========================================

Language Understanding and Natural Language Generation which evolves the task to  

------------------- Sentence 1 -------------------

Language Understanding and Natural Language Generation which evolves the task to

>> Tokens are: 
 ['Language', 'Understanding', 'Natural', 'Language', 'Generation', 'evolves', 'task']

>> Bigrams are: 
 [('Language', 'Understanding'), ('Understanding', 'Natural'), ('Natural', 'Language'), ('Language', 'Generation'), ('Generation', 'evolves'), ('evolves', 'task')]

>> Trigrams are: 
 [('Language', 'Understanding', 'Natural'), ('Understanding', 'Natural', 'Language'), ('Natural', 'Language', 'Generation'), ('Language', 'Generation', 'evolves'), ('Generation', 'evolves', 'task')]

>> POS Tags are: 
 [('Language', 'NN'), ('Understanding', 'VBG'), ('Natural', 'NNP'), ('Language', 'NNP'), ('Generation', 'NNP'), ('evolves', 'VBZ'), ('task', 'NN')]

>> Noun Phrases are: 
 ['Language', 'Natural Language Generation', 'task']

>> Named Entities are: 
 [('ORGANIZATION', 'Natural Language Generation')] 

>> Stemming using Porter Stemmer: 
 [('Language', 'languag'), ('Understanding', 'understand'), ('Natural', 'natur'), ('Language', 'languag'), ('Generation', 'gener'), ('evolves', 'evolv'), ('task', 'task')]

>> Stemming using Snowball Stemmer: 
 [('Language', 'languag'), ('Understanding', 'understand'), ('Natural', 'natur'), ('Language', 'languag'), ('Generation', 'generat'), ('evolves', 'evolv'), ('task', 'task')]

>> Lemmatization: 
 [('Language', 'Language'), ('Understanding', 'Understanding'), ('Natural', 'Natural'), ('Language', 'Language'), ('Generation', 'Generation'), ('evolves', 'evolves'), ('task', 'task')]



========================================== PARAGRAPH 30 ===========================================

understand and generate the text (Figure 1).  

------------------- Sentence 1 -------------------

understand and generate the text (Figure 1).

>> Tokens are: 
 ['understand', 'generate', 'text', '(', 'Figure', '1', ')', '.']

>> Bigrams are: 
 [('understand', 'generate'), ('generate', 'text'), ('text', '('), ('(', 'Figure'), ('Figure', '1'), ('1', ')'), (')', '.')]

>> Trigrams are: 
 [('understand', 'generate', 'text'), ('generate', 'text', '('), ('text', '(', 'Figure'), ('(', 'Figure', '1'), ('Figure', '1', ')'), ('1', ')', '.')]

>> POS Tags are: 
 [('understand', 'JJ'), ('generate', 'NN'), ('text', 'NN'), ('(', '('), ('Figure', 'NNP'), ('1', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['understand generate text', 'Figure']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('understand', 'understand'), ('generate', 'gener'), ('text', 'text'), ('(', '('), ('Figure', 'figur'), ('1', '1'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('understand', 'understand'), ('generate', 'generat'), ('text', 'text'), ('(', '('), ('Figure', 'figur'), ('1', '1'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('understand', 'understand'), ('generate', 'generate'), ('text', 'text'), ('(', '('), ('Figure', 'Figure'), ('1', '1'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 31 ===========================================

  


========================================== PARAGRAPH 32 ===========================================

                                      Figure 1. Broad Classification of NLP  

------------------- Sentence 1 -------------------

                                      Figure 1.

>> Tokens are: 
 ['Figure', '1', '.']

>> Bigrams are: 
 [('Figure', '1'), ('1', '.')]

>> Trigrams are: 
 [('Figure', '1', '.')]

>> POS Tags are: 
 [('Figure', 'NN'), ('1', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Figure']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Figure', 'figur'), ('1', '1'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Figure', 'figur'), ('1', '1'), ('.', '.')]

>> Lemmatization: 
 [('Figure', 'Figure'), ('1', '1'), ('.', '.')]


------------------- Sentence 2 -------------------

Broad Classification of NLP

>> Tokens are: 
 ['Broad', 'Classification', 'NLP']

>> Bigrams are: 
 [('Broad', 'Classification'), ('Classification', 'NLP')]

>> Trigrams are: 
 [('Broad', 'Classification', 'NLP')]

>> POS Tags are: 
 [('Broad', 'NNP'), ('Classification', 'NNP'), ('NLP', 'NNP')]

>> Noun Phrases are: 
 ['Broad Classification NLP']

>> Named Entities are: 
 [('PERSON', 'Broad')] 

>> Stemming using Porter Stemmer: 
 [('Broad', 'broad'), ('Classification', 'classif'), ('NLP', 'nlp')]

>> Stemming using Snowball Stemmer: 
 [('Broad', 'broad'), ('Classification', 'classif'), ('NLP', 'nlp')]

>> Lemmatization: 
 [('Broad', 'Broad'), ('Classification', 'Classification'), ('NLP', 'NLP')]



========================================== PARAGRAPH 33 ===========================================

Linguistics is the science of language which includes Phonology that refers to sound,  

------------------- Sentence 1 -------------------

Linguistics is the science of language which includes Phonology that refers to sound,

>> Tokens are: 
 ['Linguistics', 'science', 'language', 'includes', 'Phonology', 'refers', 'sound', ',']

>> Bigrams are: 
 [('Linguistics', 'science'), ('science', 'language'), ('language', 'includes'), ('includes', 'Phonology'), ('Phonology', 'refers'), ('refers', 'sound'), ('sound', ',')]

>> Trigrams are: 
 [('Linguistics', 'science', 'language'), ('science', 'language', 'includes'), ('language', 'includes', 'Phonology'), ('includes', 'Phonology', 'refers'), ('Phonology', 'refers', 'sound'), ('refers', 'sound', ',')]

>> POS Tags are: 
 [('Linguistics', 'NNS'), ('science', 'NN'), ('language', 'NN'), ('includes', 'VBZ'), ('Phonology', 'NNP'), ('refers', 'NNS'), ('sound', 'VBD'), (',', ',')]

>> Noun Phrases are: 
 ['Linguistics science language', 'Phonology refers']

>> Named Entities are: 
 [('ORGANIZATION', 'Phonology')] 

>> Stemming using Porter Stemmer: 
 [('Linguistics', 'linguist'), ('science', 'scienc'), ('language', 'languag'), ('includes', 'includ'), ('Phonology', 'phonolog'), ('refers', 'refer'), ('sound', 'sound'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('Linguistics', 'linguist'), ('science', 'scienc'), ('language', 'languag'), ('includes', 'includ'), ('Phonology', 'phonolog'), ('refers', 'refer'), ('sound', 'sound'), (',', ',')]

>> Lemmatization: 
 [('Linguistics', 'Linguistics'), ('science', 'science'), ('language', 'language'), ('includes', 'includes'), ('Phonology', 'Phonology'), ('refers', 'refers'), ('sound', 'sound'), (',', ',')]



========================================== PARAGRAPH 34 ===========================================

Morphology word formation, Syntax sentence structure, Semantics syntax and Pragmatics  

------------------- Sentence 1 -------------------

Morphology word formation, Syntax sentence structure, Semantics syntax and Pragmatics

>> Tokens are: 
 ['Morphology', 'word', 'formation', ',', 'Syntax', 'sentence', 'structure', ',', 'Semantics', 'syntax', 'Pragmatics']

>> Bigrams are: 
 [('Morphology', 'word'), ('word', 'formation'), ('formation', ','), (',', 'Syntax'), ('Syntax', 'sentence'), ('sentence', 'structure'), ('structure', ','), (',', 'Semantics'), ('Semantics', 'syntax'), ('syntax', 'Pragmatics')]

>> Trigrams are: 
 [('Morphology', 'word', 'formation'), ('word', 'formation', ','), ('formation', ',', 'Syntax'), (',', 'Syntax', 'sentence'), ('Syntax', 'sentence', 'structure'), ('sentence', 'structure', ','), ('structure', ',', 'Semantics'), (',', 'Semantics', 'syntax'), ('Semantics', 'syntax', 'Pragmatics')]

>> POS Tags are: 
 [('Morphology', 'NNP'), ('word', 'NN'), ('formation', 'NN'), (',', ','), ('Syntax', 'NNP'), ('sentence', 'NN'), ('structure', 'NN'), (',', ','), ('Semantics', 'NNP'), ('syntax', 'NN'), ('Pragmatics', 'NNS')]

>> Noun Phrases are: 
 ['Morphology word formation', 'Syntax sentence structure', 'Semantics syntax Pragmatics']

>> Named Entities are: 
 [('GPE', 'Morphology'), ('GPE', 'Syntax'), ('PERSON', 'Semantics')] 

>> Stemming using Porter Stemmer: 
 [('Morphology', 'morpholog'), ('word', 'word'), ('formation', 'format'), (',', ','), ('Syntax', 'syntax'), ('sentence', 'sentenc'), ('structure', 'structur'), (',', ','), ('Semantics', 'semant'), ('syntax', 'syntax'), ('Pragmatics', 'pragmat')]

>> Stemming using Snowball Stemmer: 
 [('Morphology', 'morpholog'), ('word', 'word'), ('formation', 'format'), (',', ','), ('Syntax', 'syntax'), ('sentence', 'sentenc'), ('structure', 'structur'), (',', ','), ('Semantics', 'semant'), ('syntax', 'syntax'), ('Pragmatics', 'pragmat')]

>> Lemmatization: 
 [('Morphology', 'Morphology'), ('word', 'word'), ('formation', 'formation'), (',', ','), ('Syntax', 'Syntax'), ('sentence', 'sentence'), ('structure', 'structure'), (',', ','), ('Semantics', 'Semantics'), ('syntax', 'syntax'), ('Pragmatics', 'Pragmatics')]



========================================== PARAGRAPH 35 ===========================================

which refers to understanding.  

------------------- Sentence 1 -------------------

which refers to understanding.

>> Tokens are: 
 ['refers', 'understanding', '.']

>> Bigrams are: 
 [('refers', 'understanding'), ('understanding', '.')]

>> Trigrams are: 
 [('refers', 'understanding', '.')]

>> POS Tags are: 
 [('refers', 'NNS'), ('understanding', 'VBG'), ('.', '.')]

>> Noun Phrases are: 
 ['refers']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('refers', 'refer'), ('understanding', 'understand'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('refers', 'refer'), ('understanding', 'understand'), ('.', '.')]

>> Lemmatization: 
 [('refers', 'refers'), ('understanding', 'understanding'), ('.', '.')]



========================================== PARAGRAPH 36 ===========================================

Noah Chomsky, one of the first linguists of twelfth century that started syntactic theories,  

------------------- Sentence 1 -------------------

Noah Chomsky, one of the first linguists of twelfth century that started syntactic theories,

>> Tokens are: 
 ['Noah', 'Chomsky', ',', 'one', 'first', 'linguists', 'twelfth', 'century', 'started', 'syntactic', 'theories', ',']

>> Bigrams are: 
 [('Noah', 'Chomsky'), ('Chomsky', ','), (',', 'one'), ('one', 'first'), ('first', 'linguists'), ('linguists', 'twelfth'), ('twelfth', 'century'), ('century', 'started'), ('started', 'syntactic'), ('syntactic', 'theories'), ('theories', ',')]

>> Trigrams are: 
 [('Noah', 'Chomsky', ','), ('Chomsky', ',', 'one'), (',', 'one', 'first'), ('one', 'first', 'linguists'), ('first', 'linguists', 'twelfth'), ('linguists', 'twelfth', 'century'), ('twelfth', 'century', 'started'), ('century', 'started', 'syntactic'), ('started', 'syntactic', 'theories'), ('syntactic', 'theories', ',')]

>> POS Tags are: 
 [('Noah', 'NNP'), ('Chomsky', 'NNP'), (',', ','), ('one', 'CD'), ('first', 'JJ'), ('linguists', 'VBZ'), ('twelfth', 'JJ'), ('century', 'NN'), ('started', 'VBD'), ('syntactic', 'JJ'), ('theories', 'NNS'), (',', ',')]

>> Noun Phrases are: 
 ['Noah Chomsky', 'twelfth century', 'syntactic theories']

>> Named Entities are: 
 [('PERSON', 'Noah Chomsky')] 

>> Stemming using Porter Stemmer: 
 [('Noah', 'noah'), ('Chomsky', 'chomski'), (',', ','), ('one', 'one'), ('first', 'first'), ('linguists', 'linguist'), ('twelfth', 'twelfth'), ('century', 'centuri'), ('started', 'start'), ('syntactic', 'syntact'), ('theories', 'theori'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('Noah', 'noah'), ('Chomsky', 'chomski'), (',', ','), ('one', 'one'), ('first', 'first'), ('linguists', 'linguist'), ('twelfth', 'twelfth'), ('century', 'centuri'), ('started', 'start'), ('syntactic', 'syntact'), ('theories', 'theori'), (',', ',')]

>> Lemmatization: 
 [('Noah', 'Noah'), ('Chomsky', 'Chomsky'), (',', ','), ('one', 'one'), ('first', 'first'), ('linguists', 'linguist'), ('twelfth', 'twelfth'), ('century', 'century'), ('started', 'started'), ('syntactic', 'syntactic'), ('theories', 'theory'), (',', ',')]



========================================== PARAGRAPH 37 ===========================================

marked a unique position in the field of theoretical linguistics because he revolutionised the  

------------------- Sentence 1 -------------------

marked a unique position in the field of theoretical linguistics because he revolutionised the

>> Tokens are: 
 ['marked', 'unique', 'position', 'field', 'theoretical', 'linguistics', 'revolutionised']

>> Bigrams are: 
 [('marked', 'unique'), ('unique', 'position'), ('position', 'field'), ('field', 'theoretical'), ('theoretical', 'linguistics'), ('linguistics', 'revolutionised')]

>> Trigrams are: 
 [('marked', 'unique', 'position'), ('unique', 'position', 'field'), ('position', 'field', 'theoretical'), ('field', 'theoretical', 'linguistics'), ('theoretical', 'linguistics', 'revolutionised')]

>> POS Tags are: 
 [('marked', 'VBN'), ('unique', 'JJ'), ('position', 'NN'), ('field', 'NN'), ('theoretical', 'JJ'), ('linguistics', 'NNS'), ('revolutionised', 'VBD')]

>> Noun Phrases are: 
 ['unique position field', 'theoretical linguistics']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('marked', 'mark'), ('unique', 'uniqu'), ('position', 'posit'), ('field', 'field'), ('theoretical', 'theoret'), ('linguistics', 'linguist'), ('revolutionised', 'revolutionis')]

>> Stemming using Snowball Stemmer: 
 [('marked', 'mark'), ('unique', 'uniqu'), ('position', 'posit'), ('field', 'field'), ('theoretical', 'theoret'), ('linguistics', 'linguist'), ('revolutionised', 'revolutionis')]

>> Lemmatization: 
 [('marked', 'marked'), ('unique', 'unique'), ('position', 'position'), ('field', 'field'), ('theoretical', 'theoretical'), ('linguistics', 'linguistics'), ('revolutionised', 'revolutionised')]



========================================== PARAGRAPH 38 ===========================================

area of syntax (Chomsky, 1965) [1]. Which can be broadly categorized into two levels Higher  

------------------- Sentence 1 -------------------

area of syntax (Chomsky, 1965) [1].

>> Tokens are: 
 ['area', 'syntax', '(', 'Chomsky', ',', '1965', ')', '[', '1', ']', '.']

>> Bigrams are: 
 [('area', 'syntax'), ('syntax', '('), ('(', 'Chomsky'), ('Chomsky', ','), (',', '1965'), ('1965', ')'), (')', '['), ('[', '1'), ('1', ']'), (']', '.')]

>> Trigrams are: 
 [('area', 'syntax', '('), ('syntax', '(', 'Chomsky'), ('(', 'Chomsky', ','), ('Chomsky', ',', '1965'), (',', '1965', ')'), ('1965', ')', '['), (')', '[', '1'), ('[', '1', ']'), ('1', ']', '.')]

>> POS Tags are: 
 [('area', 'NN'), ('syntax', 'NN'), ('(', '('), ('Chomsky', 'NNP'), (',', ','), ('1965', 'CD'), (')', ')'), ('[', 'VBD'), ('1', 'CD'), (']', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['area syntax', 'Chomsky', ']']

>> Named Entities are: 
 [('PERSON', 'Chomsky')] 

>> Stemming using Porter Stemmer: 
 [('area', 'area'), ('syntax', 'syntax'), ('(', '('), ('Chomsky', 'chomski'), (',', ','), ('1965', '1965'), (')', ')'), ('[', '['), ('1', '1'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('area', 'area'), ('syntax', 'syntax'), ('(', '('), ('Chomsky', 'chomski'), (',', ','), ('1965', '1965'), (')', ')'), ('[', '['), ('1', '1'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('area', 'area'), ('syntax', 'syntax'), ('(', '('), ('Chomsky', 'Chomsky'), (',', ','), ('1965', '1965'), (')', ')'), ('[', '['), ('1', '1'), (']', ']'), ('.', '.')]


------------------- Sentence 2 -------------------

Which can be broadly categorized into two levels Higher

>> Tokens are: 
 ['Which', 'broadly', 'categorized', 'two', 'levels', 'Higher']

>> Bigrams are: 
 [('Which', 'broadly'), ('broadly', 'categorized'), ('categorized', 'two'), ('two', 'levels'), ('levels', 'Higher')]

>> Trigrams are: 
 [('Which', 'broadly', 'categorized'), ('broadly', 'categorized', 'two'), ('categorized', 'two', 'levels'), ('two', 'levels', 'Higher')]

>> POS Tags are: 
 [('Which', 'WDT'), ('broadly', 'RB'), ('categorized', 'VBD'), ('two', 'CD'), ('levels', 'NNS'), ('Higher', 'RBR')]

>> Noun Phrases are: 
 ['levels']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Which', 'which'), ('broadly', 'broadli'), ('categorized', 'categor'), ('two', 'two'), ('levels', 'level'), ('Higher', 'higher')]

>> Stemming using Snowball Stemmer: 
 [('Which', 'which'), ('broadly', 'broad'), ('categorized', 'categor'), ('two', 'two'), ('levels', 'level'), ('Higher', 'higher')]

>> Lemmatization: 
 [('Which', 'Which'), ('broadly', 'broadly'), ('categorized', 'categorized'), ('two', 'two'), ('levels', 'level'), ('Higher', 'Higher')]



========================================== PARAGRAPH 39 ===========================================

Level which include speech recognition and Lower Level which corresponds to natural  

------------------- Sentence 1 -------------------

Level which include speech recognition and Lower Level which corresponds to natural

>> Tokens are: 
 ['Level', 'include', 'speech', 'recognition', 'Lower', 'Level', 'corresponds', 'natural']

>> Bigrams are: 
 [('Level', 'include'), ('include', 'speech'), ('speech', 'recognition'), ('recognition', 'Lower'), ('Lower', 'Level'), ('Level', 'corresponds'), ('corresponds', 'natural')]

>> Trigrams are: 
 [('Level', 'include', 'speech'), ('include', 'speech', 'recognition'), ('speech', 'recognition', 'Lower'), ('recognition', 'Lower', 'Level'), ('Lower', 'Level', 'corresponds'), ('Level', 'corresponds', 'natural')]

>> POS Tags are: 
 [('Level', 'NNP'), ('include', 'VBP'), ('speech', 'JJ'), ('recognition', 'NN'), ('Lower', 'NNP'), ('Level', 'NNP'), ('corresponds', 'VBZ'), ('natural', 'JJ')]

>> Noun Phrases are: 
 ['Level', 'speech recognition Lower Level']

>> Named Entities are: 
 [('GPE', 'Level'), ('PERSON', 'Lower Level')] 

>> Stemming using Porter Stemmer: 
 [('Level', 'level'), ('include', 'includ'), ('speech', 'speech'), ('recognition', 'recognit'), ('Lower', 'lower'), ('Level', 'level'), ('corresponds', 'correspond'), ('natural', 'natur')]

>> Stemming using Snowball Stemmer: 
 [('Level', 'level'), ('include', 'includ'), ('speech', 'speech'), ('recognition', 'recognit'), ('Lower', 'lower'), ('Level', 'level'), ('corresponds', 'correspond'), ('natural', 'natur')]

>> Lemmatization: 
 [('Level', 'Level'), ('include', 'include'), ('speech', 'speech'), ('recognition', 'recognition'), ('Lower', 'Lower'), ('Level', 'Level'), ('corresponds', 'corresponds'), ('natural', 'natural')]



========================================== PARAGRAPH 40 ===========================================

language. Few of the researched tasks of NLP are Automatic Summarization, Co-Reference  

------------------- Sentence 1 -------------------

language.

>> Tokens are: 
 ['language', '.']

>> Bigrams are: 
 [('language', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('language', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['language']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('language', 'languag'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('language', 'languag'), ('.', '.')]

>> Lemmatization: 
 [('language', 'language'), ('.', '.')]


------------------- Sentence 2 -------------------

Few of the researched tasks of NLP are Automatic Summarization, Co-Reference

>> Tokens are: 
 ['Few', 'researched', 'tasks', 'NLP', 'Automatic', 'Summarization', ',', 'Co-Reference']

>> Bigrams are: 
 [('Few', 'researched'), ('researched', 'tasks'), ('tasks', 'NLP'), ('NLP', 'Automatic'), ('Automatic', 'Summarization'), ('Summarization', ','), (',', 'Co-Reference')]

>> Trigrams are: 
 [('Few', 'researched', 'tasks'), ('researched', 'tasks', 'NLP'), ('tasks', 'NLP', 'Automatic'), ('NLP', 'Automatic', 'Summarization'), ('Automatic', 'Summarization', ','), ('Summarization', ',', 'Co-Reference')]

>> POS Tags are: 
 [('Few', 'JJ'), ('researched', 'VBD'), ('tasks', 'NNS'), ('NLP', 'NNP'), ('Automatic', 'NNP'), ('Summarization', 'NNP'), (',', ','), ('Co-Reference', 'NNP')]

>> Noun Phrases are: 
 ['tasks NLP Automatic Summarization', 'Co-Reference']

>> Named Entities are: 
 [('ORGANIZATION', 'NLP Automatic Summarization')] 

>> Stemming using Porter Stemmer: 
 [('Few', 'few'), ('researched', 'research'), ('tasks', 'task'), ('NLP', 'nlp'), ('Automatic', 'automat'), ('Summarization', 'summar'), (',', ','), ('Co-Reference', 'co-refer')]

>> Stemming using Snowball Stemmer: 
 [('Few', 'few'), ('researched', 'research'), ('tasks', 'task'), ('NLP', 'nlp'), ('Automatic', 'automat'), ('Summarization', 'summar'), (',', ','), ('Co-Reference', 'co-refer')]

>> Lemmatization: 
 [('Few', 'Few'), ('researched', 'researched'), ('tasks', 'task'), ('NLP', 'NLP'), ('Automatic', 'Automatic'), ('Summarization', 'Summarization'), (',', ','), ('Co-Reference', 'Co-Reference')]



========================================== PARAGRAPH 41 ===========================================

Resolution, Discourse Analysis, Machine Translation, Morphological Segmentation, Named  

------------------- Sentence 1 -------------------

Resolution, Discourse Analysis, Machine Translation, Morphological Segmentation, Named

>> Tokens are: 
 ['Resolution', ',', 'Discourse', 'Analysis', ',', 'Machine', 'Translation', ',', 'Morphological', 'Segmentation', ',', 'Named']

>> Bigrams are: 
 [('Resolution', ','), (',', 'Discourse'), ('Discourse', 'Analysis'), ('Analysis', ','), (',', 'Machine'), ('Machine', 'Translation'), ('Translation', ','), (',', 'Morphological'), ('Morphological', 'Segmentation'), ('Segmentation', ','), (',', 'Named')]

>> Trigrams are: 
 [('Resolution', ',', 'Discourse'), (',', 'Discourse', 'Analysis'), ('Discourse', 'Analysis', ','), ('Analysis', ',', 'Machine'), (',', 'Machine', 'Translation'), ('Machine', 'Translation', ','), ('Translation', ',', 'Morphological'), (',', 'Morphological', 'Segmentation'), ('Morphological', 'Segmentation', ','), ('Segmentation', ',', 'Named')]

>> POS Tags are: 
 [('Resolution', 'NN'), (',', ','), ('Discourse', 'NNP'), ('Analysis', 'NNP'), (',', ','), ('Machine', 'NNP'), ('Translation', 'NNP'), (',', ','), ('Morphological', 'NNP'), ('Segmentation', 'NNP'), (',', ','), ('Named', 'NNP')]

>> Noun Phrases are: 
 ['Resolution', 'Discourse Analysis', 'Machine Translation', 'Morphological Segmentation', 'Named']

>> Named Entities are: 
 [('GPE', 'Resolution'), ('PERSON', 'Discourse Analysis'), ('PERSON', 'Machine Translation'), ('PERSON', 'Morphological Segmentation'), ('PERSON', 'Named')] 

>> Stemming using Porter Stemmer: 
 [('Resolution', 'resolut'), (',', ','), ('Discourse', 'discours'), ('Analysis', 'analysi'), (',', ','), ('Machine', 'machin'), ('Translation', 'translat'), (',', ','), ('Morphological', 'morpholog'), ('Segmentation', 'segment'), (',', ','), ('Named', 'name')]

>> Stemming using Snowball Stemmer: 
 [('Resolution', 'resolut'), (',', ','), ('Discourse', 'discours'), ('Analysis', 'analysi'), (',', ','), ('Machine', 'machin'), ('Translation', 'translat'), (',', ','), ('Morphological', 'morpholog'), ('Segmentation', 'segment'), (',', ','), ('Named', 'name')]

>> Lemmatization: 
 [('Resolution', 'Resolution'), (',', ','), ('Discourse', 'Discourse'), ('Analysis', 'Analysis'), (',', ','), ('Machine', 'Machine'), ('Translation', 'Translation'), (',', ','), ('Morphological', 'Morphological'), ('Segmentation', 'Segmentation'), (',', ','), ('Named', 'Named')]



========================================== PARAGRAPH 42 ===========================================

Entity Recognition, Optical Character Recognition, Part Of Speech Tagging etc. Some of  

------------------- Sentence 1 -------------------

Entity Recognition, Optical Character Recognition, Part Of Speech Tagging etc.

>> Tokens are: 
 ['Entity', 'Recognition', ',', 'Optical', 'Character', 'Recognition', ',', 'Part', 'Of', 'Speech', 'Tagging', 'etc', '.']

>> Bigrams are: 
 [('Entity', 'Recognition'), ('Recognition', ','), (',', 'Optical'), ('Optical', 'Character'), ('Character', 'Recognition'), ('Recognition', ','), (',', 'Part'), ('Part', 'Of'), ('Of', 'Speech'), ('Speech', 'Tagging'), ('Tagging', 'etc'), ('etc', '.')]

>> Trigrams are: 
 [('Entity', 'Recognition', ','), ('Recognition', ',', 'Optical'), (',', 'Optical', 'Character'), ('Optical', 'Character', 'Recognition'), ('Character', 'Recognition', ','), ('Recognition', ',', 'Part'), (',', 'Part', 'Of'), ('Part', 'Of', 'Speech'), ('Of', 'Speech', 'Tagging'), ('Speech', 'Tagging', 'etc'), ('Tagging', 'etc', '.')]

>> POS Tags are: 
 [('Entity', 'NNP'), ('Recognition', 'NNP'), (',', ','), ('Optical', 'NNP'), ('Character', 'NNP'), ('Recognition', 'NNP'), (',', ','), ('Part', 'NNP'), ('Of', 'IN'), ('Speech', 'NNP'), ('Tagging', 'NNP'), ('etc', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Entity Recognition', 'Optical Character Recognition', 'Part', 'Speech Tagging etc']

>> Named Entities are: 
 [('GPE', 'Entity'), ('ORGANIZATION', 'Recognition'), ('PERSON', 'Optical Character Recognition'), ('ORGANIZATION', 'Part Of Speech')] 

>> Stemming using Porter Stemmer: 
 [('Entity', 'entiti'), ('Recognition', 'recognit'), (',', ','), ('Optical', 'optic'), ('Character', 'charact'), ('Recognition', 'recognit'), (',', ','), ('Part', 'part'), ('Of', 'of'), ('Speech', 'speech'), ('Tagging', 'tag'), ('etc', 'etc'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Entity', 'entiti'), ('Recognition', 'recognit'), (',', ','), ('Optical', 'optic'), ('Character', 'charact'), ('Recognition', 'recognit'), (',', ','), ('Part', 'part'), ('Of', 'of'), ('Speech', 'speech'), ('Tagging', 'tag'), ('etc', 'etc'), ('.', '.')]

>> Lemmatization: 
 [('Entity', 'Entity'), ('Recognition', 'Recognition'), (',', ','), ('Optical', 'Optical'), ('Character', 'Character'), ('Recognition', 'Recognition'), (',', ','), ('Part', 'Part'), ('Of', 'Of'), ('Speech', 'Speech'), ('Tagging', 'Tagging'), ('etc', 'etc'), ('.', '.')]


------------------- Sentence 2 -------------------

Some of

>> Tokens are: 
 ['Some']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Some', 'DT')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Some', 'some')]

>> Stemming using Snowball Stemmer: 
 [('Some', 'some')]

>> Lemmatization: 
 [('Some', 'Some')]



========================================== PARAGRAPH 43 ===========================================

these tasks have direct real world applications such as Machine translation, Named entity  

------------------- Sentence 1 -------------------

these tasks have direct real world applications such as Machine translation, Named entity

>> Tokens are: 
 ['tasks', 'direct', 'real', 'world', 'applications', 'Machine', 'translation', ',', 'Named', 'entity']

>> Bigrams are: 
 [('tasks', 'direct'), ('direct', 'real'), ('real', 'world'), ('world', 'applications'), ('applications', 'Machine'), ('Machine', 'translation'), ('translation', ','), (',', 'Named'), ('Named', 'entity')]

>> Trigrams are: 
 [('tasks', 'direct', 'real'), ('direct', 'real', 'world'), ('real', 'world', 'applications'), ('world', 'applications', 'Machine'), ('applications', 'Machine', 'translation'), ('Machine', 'translation', ','), ('translation', ',', 'Named'), (',', 'Named', 'entity')]

>> POS Tags are: 
 [('tasks', 'NNS'), ('direct', 'JJ'), ('real', 'JJ'), ('world', 'NN'), ('applications', 'NNS'), ('Machine', 'NNP'), ('translation', 'NN'), (',', ','), ('Named', 'NNP'), ('entity', 'NN')]

>> Noun Phrases are: 
 ['tasks', 'direct real world applications Machine translation', 'Named entity']

>> Named Entities are: 
 [('PERSON', 'Machine'), ('PERSON', 'Named')] 

>> Stemming using Porter Stemmer: 
 [('tasks', 'task'), ('direct', 'direct'), ('real', 'real'), ('world', 'world'), ('applications', 'applic'), ('Machine', 'machin'), ('translation', 'translat'), (',', ','), ('Named', 'name'), ('entity', 'entiti')]

>> Stemming using Snowball Stemmer: 
 [('tasks', 'task'), ('direct', 'direct'), ('real', 'real'), ('world', 'world'), ('applications', 'applic'), ('Machine', 'machin'), ('translation', 'translat'), (',', ','), ('Named', 'name'), ('entity', 'entiti')]

>> Lemmatization: 
 [('tasks', 'task'), ('direct', 'direct'), ('real', 'real'), ('world', 'world'), ('applications', 'application'), ('Machine', 'Machine'), ('translation', 'translation'), (',', ','), ('Named', 'Named'), ('entity', 'entity')]



========================================== PARAGRAPH 44 ===========================================

recognition, Optical character recognition etc. Automatic summarization produces an  

------------------- Sentence 1 -------------------

recognition, Optical character recognition etc.

>> Tokens are: 
 ['recognition', ',', 'Optical', 'character', 'recognition', 'etc', '.']

>> Bigrams are: 
 [('recognition', ','), (',', 'Optical'), ('Optical', 'character'), ('character', 'recognition'), ('recognition', 'etc'), ('etc', '.')]

>> Trigrams are: 
 [('recognition', ',', 'Optical'), (',', 'Optical', 'character'), ('Optical', 'character', 'recognition'), ('character', 'recognition', 'etc'), ('recognition', 'etc', '.')]

>> POS Tags are: 
 [('recognition', 'NN'), (',', ','), ('Optical', 'NNP'), ('character', 'NN'), ('recognition', 'NN'), ('etc', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['recognition', 'Optical character recognition etc']

>> Named Entities are: 
 [('GPE', 'Optical')] 

>> Stemming using Porter Stemmer: 
 [('recognition', 'recognit'), (',', ','), ('Optical', 'optic'), ('character', 'charact'), ('recognition', 'recognit'), ('etc', 'etc'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('recognition', 'recognit'), (',', ','), ('Optical', 'optic'), ('character', 'charact'), ('recognition', 'recognit'), ('etc', 'etc'), ('.', '.')]

>> Lemmatization: 
 [('recognition', 'recognition'), (',', ','), ('Optical', 'Optical'), ('character', 'character'), ('recognition', 'recognition'), ('etc', 'etc'), ('.', '.')]


------------------- Sentence 2 -------------------

Automatic summarization produces an

>> Tokens are: 
 ['Automatic', 'summarization', 'produces']

>> Bigrams are: 
 [('Automatic', 'summarization'), ('summarization', 'produces')]

>> Trigrams are: 
 [('Automatic', 'summarization', 'produces')]

>> POS Tags are: 
 [('Automatic', 'JJ'), ('summarization', 'NN'), ('produces', 'NNS')]

>> Noun Phrases are: 
 ['Automatic summarization produces']

>> Named Entities are: 
 [('GPE', 'Automatic')] 

>> Stemming using Porter Stemmer: 
 [('Automatic', 'automat'), ('summarization', 'summar'), ('produces', 'produc')]

>> Stemming using Snowball Stemmer: 
 [('Automatic', 'automat'), ('summarization', 'summar'), ('produces', 'produc')]

>> Lemmatization: 
 [('Automatic', 'Automatic'), ('summarization', 'summarization'), ('produces', 'produce')]



========================================== PARAGRAPH 45 ===========================================

understandable summary of a set of text and provides summaries or detailed information of  

------------------- Sentence 1 -------------------

understandable summary of a set of text and provides summaries or detailed information of

>> Tokens are: 
 ['understandable', 'summary', 'set', 'text', 'provides', 'summaries', 'detailed', 'information']

>> Bigrams are: 
 [('understandable', 'summary'), ('summary', 'set'), ('set', 'text'), ('text', 'provides'), ('provides', 'summaries'), ('summaries', 'detailed'), ('detailed', 'information')]

>> Trigrams are: 
 [('understandable', 'summary', 'set'), ('summary', 'set', 'text'), ('set', 'text', 'provides'), ('text', 'provides', 'summaries'), ('provides', 'summaries', 'detailed'), ('summaries', 'detailed', 'information')]

>> POS Tags are: 
 [('understandable', 'JJ'), ('summary', 'JJ'), ('set', 'NN'), ('text', 'NN'), ('provides', 'VBZ'), ('summaries', 'NNS'), ('detailed', 'VBN'), ('information', 'NN')]

>> Noun Phrases are: 
 ['understandable summary set text', 'summaries', 'information']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('understandable', 'understand'), ('summary', 'summari'), ('set', 'set'), ('text', 'text'), ('provides', 'provid'), ('summaries', 'summari'), ('detailed', 'detail'), ('information', 'inform')]

>> Stemming using Snowball Stemmer: 
 [('understandable', 'understand'), ('summary', 'summari'), ('set', 'set'), ('text', 'text'), ('provides', 'provid'), ('summaries', 'summari'), ('detailed', 'detail'), ('information', 'inform')]

>> Lemmatization: 
 [('understandable', 'understandable'), ('summary', 'summary'), ('set', 'set'), ('text', 'text'), ('provides', 'provides'), ('summaries', 'summary'), ('detailed', 'detailed'), ('information', 'information')]



========================================== PARAGRAPH 46 ===========================================

text of a known type. Co-reference resolution it refers to a sentence or larger set of text that  

------------------- Sentence 1 -------------------

text of a known type.

>> Tokens are: 
 ['text', 'known', 'type', '.']

>> Bigrams are: 
 [('text', 'known'), ('known', 'type'), ('type', '.')]

>> Trigrams are: 
 [('text', 'known', 'type'), ('known', 'type', '.')]

>> POS Tags are: 
 [('text', 'NN'), ('known', 'VBN'), ('type', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['text', 'type']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('text', 'text'), ('known', 'known'), ('type', 'type'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('text', 'text'), ('known', 'known'), ('type', 'type'), ('.', '.')]

>> Lemmatization: 
 [('text', 'text'), ('known', 'known'), ('type', 'type'), ('.', '.')]


------------------- Sentence 2 -------------------

Co-reference resolution it refers to a sentence or larger set of text that

>> Tokens are: 
 ['Co-reference', 'resolution', 'refers', 'sentence', 'larger', 'set', 'text']

>> Bigrams are: 
 [('Co-reference', 'resolution'), ('resolution', 'refers'), ('refers', 'sentence'), ('sentence', 'larger'), ('larger', 'set'), ('set', 'text')]

>> Trigrams are: 
 [('Co-reference', 'resolution', 'refers'), ('resolution', 'refers', 'sentence'), ('refers', 'sentence', 'larger'), ('sentence', 'larger', 'set'), ('larger', 'set', 'text')]

>> POS Tags are: 
 [('Co-reference', 'NNP'), ('resolution', 'NN'), ('refers', 'NNS'), ('sentence', 'NN'), ('larger', 'JJR'), ('set', 'NN'), ('text', 'NN')]

>> Noun Phrases are: 
 ['Co-reference resolution refers sentence', 'set text']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Co-reference', 'co-refer'), ('resolution', 'resolut'), ('refers', 'refer'), ('sentence', 'sentenc'), ('larger', 'larger'), ('set', 'set'), ('text', 'text')]

>> Stemming using Snowball Stemmer: 
 [('Co-reference', 'co-refer'), ('resolution', 'resolut'), ('refers', 'refer'), ('sentence', 'sentenc'), ('larger', 'larger'), ('set', 'set'), ('text', 'text')]

>> Lemmatization: 
 [('Co-reference', 'Co-reference'), ('resolution', 'resolution'), ('refers', 'refers'), ('sentence', 'sentence'), ('larger', 'larger'), ('set', 'set'), ('text', 'text')]



========================================== PARAGRAPH 47 ===========================================

determines which word refer to the same object. Discourse analysis refers to the task of  

------------------- Sentence 1 -------------------

determines which word refer to the same object.

>> Tokens are: 
 ['determines', 'word', 'refer', 'object', '.']

>> Bigrams are: 
 [('determines', 'word'), ('word', 'refer'), ('refer', 'object'), ('object', '.')]

>> Trigrams are: 
 [('determines', 'word', 'refer'), ('word', 'refer', 'object'), ('refer', 'object', '.')]

>> POS Tags are: 
 [('determines', 'NNS'), ('word', 'NN'), ('refer', 'NN'), ('object', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['determines word refer object']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('determines', 'determin'), ('word', 'word'), ('refer', 'refer'), ('object', 'object'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('determines', 'determin'), ('word', 'word'), ('refer', 'refer'), ('object', 'object'), ('.', '.')]

>> Lemmatization: 
 [('determines', 'determines'), ('word', 'word'), ('refer', 'refer'), ('object', 'object'), ('.', '.')]


------------------- Sentence 2 -------------------

Discourse analysis refers to the task of

>> Tokens are: 
 ['Discourse', 'analysis', 'refers', 'task']

>> Bigrams are: 
 [('Discourse', 'analysis'), ('analysis', 'refers'), ('refers', 'task')]

>> Trigrams are: 
 [('Discourse', 'analysis', 'refers'), ('analysis', 'refers', 'task')]

>> POS Tags are: 
 [('Discourse', 'NNP'), ('analysis', 'NN'), ('refers', 'NNS'), ('task', 'VBP')]

>> Noun Phrases are: 
 ['Discourse analysis refers']

>> Named Entities are: 
 [('GPE', 'Discourse')] 

>> Stemming using Porter Stemmer: 
 [('Discourse', 'discours'), ('analysis', 'analysi'), ('refers', 'refer'), ('task', 'task')]

>> Stemming using Snowball Stemmer: 
 [('Discourse', 'discours'), ('analysis', 'analysi'), ('refers', 'refer'), ('task', 'task')]

>> Lemmatization: 
 [('Discourse', 'Discourse'), ('analysis', 'analysis'), ('refers', 'refers'), ('task', 'task')]



========================================== PARAGRAPH 48 ===========================================

identifying the discourse structure of connected text. Machine translation which refers to  

------------------- Sentence 1 -------------------

identifying the discourse structure of connected text.

>> Tokens are: 
 ['identifying', 'discourse', 'structure', 'connected', 'text', '.']

>> Bigrams are: 
 [('identifying', 'discourse'), ('discourse', 'structure'), ('structure', 'connected'), ('connected', 'text'), ('text', '.')]

>> Trigrams are: 
 [('identifying', 'discourse', 'structure'), ('discourse', 'structure', 'connected'), ('structure', 'connected', 'text'), ('connected', 'text', '.')]

>> POS Tags are: 
 [('identifying', 'VBG'), ('discourse', 'NN'), ('structure', 'NN'), ('connected', 'VBN'), ('text', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['discourse structure', 'text']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('identifying', 'identifi'), ('discourse', 'discours'), ('structure', 'structur'), ('connected', 'connect'), ('text', 'text'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('identifying', 'identifi'), ('discourse', 'discours'), ('structure', 'structur'), ('connected', 'connect'), ('text', 'text'), ('.', '.')]

>> Lemmatization: 
 [('identifying', 'identifying'), ('discourse', 'discourse'), ('structure', 'structure'), ('connected', 'connected'), ('text', 'text'), ('.', '.')]


------------------- Sentence 2 -------------------

Machine translation which refers to

>> Tokens are: 
 ['Machine', 'translation', 'refers']

>> Bigrams are: 
 [('Machine', 'translation'), ('translation', 'refers')]

>> Trigrams are: 
 [('Machine', 'translation', 'refers')]

>> POS Tags are: 
 [('Machine', 'NN'), ('translation', 'NN'), ('refers', 'NNS')]

>> Noun Phrases are: 
 ['Machine translation refers']

>> Named Entities are: 
 [('GPE', 'Machine')] 

>> Stemming using Porter Stemmer: 
 [('Machine', 'machin'), ('translation', 'translat'), ('refers', 'refer')]

>> Stemming using Snowball Stemmer: 
 [('Machine', 'machin'), ('translation', 'translat'), ('refers', 'refer')]

>> Lemmatization: 
 [('Machine', 'Machine'), ('translation', 'translation'), ('refers', 'refers')]



========================================== PARAGRAPH 49 ===========================================

automatic translation of text from one human language to another. Morphological  

------------------- Sentence 1 -------------------

automatic translation of text from one human language to another.

>> Tokens are: 
 ['automatic', 'translation', 'text', 'one', 'human', 'language', 'another', '.']

>> Bigrams are: 
 [('automatic', 'translation'), ('translation', 'text'), ('text', 'one'), ('one', 'human'), ('human', 'language'), ('language', 'another'), ('another', '.')]

>> Trigrams are: 
 [('automatic', 'translation', 'text'), ('translation', 'text', 'one'), ('text', 'one', 'human'), ('one', 'human', 'language'), ('human', 'language', 'another'), ('language', 'another', '.')]

>> POS Tags are: 
 [('automatic', 'JJ'), ('translation', 'NN'), ('text', 'IN'), ('one', 'CD'), ('human', 'JJ'), ('language', 'NN'), ('another', 'DT'), ('.', '.')]

>> Noun Phrases are: 
 ['automatic translation', 'human language']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('automatic', 'automat'), ('translation', 'translat'), ('text', 'text'), ('one', 'one'), ('human', 'human'), ('language', 'languag'), ('another', 'anoth'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('automatic', 'automat'), ('translation', 'translat'), ('text', 'text'), ('one', 'one'), ('human', 'human'), ('language', 'languag'), ('another', 'anoth'), ('.', '.')]

>> Lemmatization: 
 [('automatic', 'automatic'), ('translation', 'translation'), ('text', 'text'), ('one', 'one'), ('human', 'human'), ('language', 'language'), ('another', 'another'), ('.', '.')]


------------------- Sentence 2 -------------------

Morphological

>> Tokens are: 
 ['Morphological']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Morphological', 'JJ')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Morphological', 'morpholog')]

>> Stemming using Snowball Stemmer: 
 [('Morphological', 'morpholog')]

>> Lemmatization: 
 [('Morphological', 'Morphological')]



========================================== PARAGRAPH 50 ===========================================

segmentation which refers to separate word into individual morphemes and identify the class  

------------------- Sentence 1 -------------------

segmentation which refers to separate word into individual morphemes and identify the class

>> Tokens are: 
 ['segmentation', 'refers', 'separate', 'word', 'individual', 'morphemes', 'identify', 'class']

>> Bigrams are: 
 [('segmentation', 'refers'), ('refers', 'separate'), ('separate', 'word'), ('word', 'individual'), ('individual', 'morphemes'), ('morphemes', 'identify'), ('identify', 'class')]

>> Trigrams are: 
 [('segmentation', 'refers', 'separate'), ('refers', 'separate', 'word'), ('separate', 'word', 'individual'), ('word', 'individual', 'morphemes'), ('individual', 'morphemes', 'identify'), ('morphemes', 'identify', 'class')]

>> POS Tags are: 
 [('segmentation', 'NN'), ('refers', 'NNS'), ('separate', 'VBP'), ('word', 'NN'), ('individual', 'JJ'), ('morphemes', 'NNS'), ('identify', 'VBP'), ('class', 'NN')]

>> Noun Phrases are: 
 ['segmentation refers', 'word', 'individual morphemes', 'class']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('segmentation', 'segment'), ('refers', 'refer'), ('separate', 'separ'), ('word', 'word'), ('individual', 'individu'), ('morphemes', 'morphem'), ('identify', 'identifi'), ('class', 'class')]

>> Stemming using Snowball Stemmer: 
 [('segmentation', 'segment'), ('refers', 'refer'), ('separate', 'separ'), ('word', 'word'), ('individual', 'individu'), ('morphemes', 'morphem'), ('identify', 'identifi'), ('class', 'class')]

>> Lemmatization: 
 [('segmentation', 'segmentation'), ('refers', 'refers'), ('separate', 'separate'), ('word', 'word'), ('individual', 'individual'), ('morphemes', 'morpheme'), ('identify', 'identify'), ('class', 'class')]



========================================== PARAGRAPH 51 ===========================================

of the morphemes. Named entity recognition (NER) it describes a stream of text, determine  

------------------- Sentence 1 -------------------

of the morphemes.

>> Tokens are: 
 ['morphemes', '.']

>> Bigrams are: 
 [('morphemes', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('morphemes', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['morphemes']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('morphemes', 'morphem'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('morphemes', 'morphem'), ('.', '.')]

>> Lemmatization: 
 [('morphemes', 'morpheme'), ('.', '.')]


------------------- Sentence 2 -------------------

Named entity recognition (NER) it describes a stream of text, determine

>> Tokens are: 
 ['Named', 'entity', 'recognition', '(', 'NER', ')', 'describes', 'stream', 'text', ',', 'determine']

>> Bigrams are: 
 [('Named', 'entity'), ('entity', 'recognition'), ('recognition', '('), ('(', 'NER'), ('NER', ')'), (')', 'describes'), ('describes', 'stream'), ('stream', 'text'), ('text', ','), (',', 'determine')]

>> Trigrams are: 
 [('Named', 'entity', 'recognition'), ('entity', 'recognition', '('), ('recognition', '(', 'NER'), ('(', 'NER', ')'), ('NER', ')', 'describes'), (')', 'describes', 'stream'), ('describes', 'stream', 'text'), ('stream', 'text', ','), ('text', ',', 'determine')]

>> POS Tags are: 
 [('Named', 'VBN'), ('entity', 'NN'), ('recognition', 'NN'), ('(', '('), ('NER', 'NNP'), (')', ')'), ('describes', 'VBZ'), ('stream', 'JJ'), ('text', 'NN'), (',', ','), ('determine', 'NN')]

>> Noun Phrases are: 
 ['entity recognition', 'NER', 'stream text', 'determine']

>> Named Entities are: 
 [('ORGANIZATION', 'NER')] 

>> Stemming using Porter Stemmer: 
 [('Named', 'name'), ('entity', 'entiti'), ('recognition', 'recognit'), ('(', '('), ('NER', 'ner'), (')', ')'), ('describes', 'describ'), ('stream', 'stream'), ('text', 'text'), (',', ','), ('determine', 'determin')]

>> Stemming using Snowball Stemmer: 
 [('Named', 'name'), ('entity', 'entiti'), ('recognition', 'recognit'), ('(', '('), ('NER', 'ner'), (')', ')'), ('describes', 'describ'), ('stream', 'stream'), ('text', 'text'), (',', ','), ('determine', 'determin')]

>> Lemmatization: 
 [('Named', 'Named'), ('entity', 'entity'), ('recognition', 'recognition'), ('(', '('), ('NER', 'NER'), (')', ')'), ('describes', 'describes'), ('stream', 'stream'), ('text', 'text'), (',', ','), ('determine', 'determine')]



========================================== PARAGRAPH 52 ===========================================

which items in the text relates to proper names. Optical character recognition (OCR) it gives  

------------------- Sentence 1 -------------------

which items in the text relates to proper names.

>> Tokens are: 
 ['items', 'text', 'relates', 'proper', 'names', '.']

>> Bigrams are: 
 [('items', 'text'), ('text', 'relates'), ('relates', 'proper'), ('proper', 'names'), ('names', '.')]

>> Trigrams are: 
 [('items', 'text', 'relates'), ('text', 'relates', 'proper'), ('relates', 'proper', 'names'), ('proper', 'names', '.')]

>> POS Tags are: 
 [('items', 'NNS'), ('text', 'JJ'), ('relates', 'NNS'), ('proper', 'JJ'), ('names', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['items', 'text relates', 'proper names']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('items', 'item'), ('text', 'text'), ('relates', 'relat'), ('proper', 'proper'), ('names', 'name'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('items', 'item'), ('text', 'text'), ('relates', 'relat'), ('proper', 'proper'), ('names', 'name'), ('.', '.')]

>> Lemmatization: 
 [('items', 'item'), ('text', 'text'), ('relates', 'relates'), ('proper', 'proper'), ('names', 'name'), ('.', '.')]


------------------- Sentence 2 -------------------

Optical character recognition (OCR) it gives

>> Tokens are: 
 ['Optical', 'character', 'recognition', '(', 'OCR', ')', 'gives']

>> Bigrams are: 
 [('Optical', 'character'), ('character', 'recognition'), ('recognition', '('), ('(', 'OCR'), ('OCR', ')'), (')', 'gives')]

>> Trigrams are: 
 [('Optical', 'character', 'recognition'), ('character', 'recognition', '('), ('recognition', '(', 'OCR'), ('(', 'OCR', ')'), ('OCR', ')', 'gives')]

>> POS Tags are: 
 [('Optical', 'JJ'), ('character', 'NN'), ('recognition', 'NN'), ('(', '('), ('OCR', 'NNP'), (')', ')'), ('gives', 'VBZ')]

>> Noun Phrases are: 
 ['Optical character recognition', 'OCR']

>> Named Entities are: 
 [('GPE', 'Optical'), ('ORGANIZATION', 'OCR')] 

>> Stemming using Porter Stemmer: 
 [('Optical', 'optic'), ('character', 'charact'), ('recognition', 'recognit'), ('(', '('), ('OCR', 'ocr'), (')', ')'), ('gives', 'give')]

>> Stemming using Snowball Stemmer: 
 [('Optical', 'optic'), ('character', 'charact'), ('recognition', 'recognit'), ('(', '('), ('OCR', 'ocr'), (')', ')'), ('gives', 'give')]

>> Lemmatization: 
 [('Optical', 'Optical'), ('character', 'character'), ('recognition', 'recognition'), ('(', '('), ('OCR', 'OCR'), (')', ')'), ('gives', 'give')]



========================================== PARAGRAPH 53 ===========================================

an image representing printed text, which help in determining the corresponding or related  

------------------- Sentence 1 -------------------

an image representing printed text, which help in determining the corresponding or related

>> Tokens are: 
 ['image', 'representing', 'printed', 'text', ',', 'help', 'determining', 'corresponding', 'related']

>> Bigrams are: 
 [('image', 'representing'), ('representing', 'printed'), ('printed', 'text'), ('text', ','), (',', 'help'), ('help', 'determining'), ('determining', 'corresponding'), ('corresponding', 'related')]

>> Trigrams are: 
 [('image', 'representing', 'printed'), ('representing', 'printed', 'text'), ('printed', 'text', ','), ('text', ',', 'help'), (',', 'help', 'determining'), ('help', 'determining', 'corresponding'), ('determining', 'corresponding', 'related')]

>> POS Tags are: 
 [('image', 'NN'), ('representing', 'VBG'), ('printed', 'VBN'), ('text', 'NN'), (',', ','), ('help', 'NN'), ('determining', 'VBG'), ('corresponding', 'VBG'), ('related', 'JJ')]

>> Noun Phrases are: 
 ['image', 'text', 'help']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('image', 'imag'), ('representing', 'repres'), ('printed', 'print'), ('text', 'text'), (',', ','), ('help', 'help'), ('determining', 'determin'), ('corresponding', 'correspond'), ('related', 'relat')]

>> Stemming using Snowball Stemmer: 
 [('image', 'imag'), ('representing', 'repres'), ('printed', 'print'), ('text', 'text'), (',', ','), ('help', 'help'), ('determining', 'determin'), ('corresponding', 'correspond'), ('related', 'relat')]

>> Lemmatization: 
 [('image', 'image'), ('representing', 'representing'), ('printed', 'printed'), ('text', 'text'), (',', ','), ('help', 'help'), ('determining', 'determining'), ('corresponding', 'corresponding'), ('related', 'related')]



========================================== PARAGRAPH 54 ===========================================

text. Part of speech tagging it describes a sentence, determines the part of speech for each  

------------------- Sentence 1 -------------------

text.

>> Tokens are: 
 ['text', '.']

>> Bigrams are: 
 [('text', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('text', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['text']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('text', 'text'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('text', 'text'), ('.', '.')]

>> Lemmatization: 
 [('text', 'text'), ('.', '.')]


------------------- Sentence 2 -------------------

Part of speech tagging it describes a sentence, determines the part of speech for each

>> Tokens are: 
 ['Part', 'speech', 'tagging', 'describes', 'sentence', ',', 'determines', 'part', 'speech']

>> Bigrams are: 
 [('Part', 'speech'), ('speech', 'tagging'), ('tagging', 'describes'), ('describes', 'sentence'), ('sentence', ','), (',', 'determines'), ('determines', 'part'), ('part', 'speech')]

>> Trigrams are: 
 [('Part', 'speech', 'tagging'), ('speech', 'tagging', 'describes'), ('tagging', 'describes', 'sentence'), ('describes', 'sentence', ','), ('sentence', ',', 'determines'), (',', 'determines', 'part'), ('determines', 'part', 'speech')]

>> POS Tags are: 
 [('Part', 'NN'), ('speech', 'NN'), ('tagging', 'VBG'), ('describes', 'JJ'), ('sentence', 'NN'), (',', ','), ('determines', 'NNS'), ('part', 'NN'), ('speech', 'NN')]

>> Noun Phrases are: 
 ['Part speech', 'describes sentence', 'determines part speech']

>> Named Entities are: 
 [('GPE', 'Part')] 

>> Stemming using Porter Stemmer: 
 [('Part', 'part'), ('speech', 'speech'), ('tagging', 'tag'), ('describes', 'describ'), ('sentence', 'sentenc'), (',', ','), ('determines', 'determin'), ('part', 'part'), ('speech', 'speech')]

>> Stemming using Snowball Stemmer: 
 [('Part', 'part'), ('speech', 'speech'), ('tagging', 'tag'), ('describes', 'describ'), ('sentence', 'sentenc'), (',', ','), ('determines', 'determin'), ('part', 'part'), ('speech', 'speech')]

>> Lemmatization: 
 [('Part', 'Part'), ('speech', 'speech'), ('tagging', 'tagging'), ('describes', 'describes'), ('sentence', 'sentence'), (',', ','), ('determines', 'determines'), ('part', 'part'), ('speech', 'speech')]



========================================== PARAGRAPH 55 ===========================================

word. Though NLP tasks are obviously very closely interweaved but they are used  

------------------- Sentence 1 -------------------

word.

>> Tokens are: 
 ['word', '.']

>> Bigrams are: 
 [('word', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('word', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['word']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('word', 'word'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('word', 'word'), ('.', '.')]

>> Lemmatization: 
 [('word', 'word'), ('.', '.')]


------------------- Sentence 2 -------------------

Though NLP tasks are obviously very closely interweaved but they are used

>> Tokens are: 
 ['Though', 'NLP', 'tasks', 'obviously', 'closely', 'interweaved', 'used']

>> Bigrams are: 
 [('Though', 'NLP'), ('NLP', 'tasks'), ('tasks', 'obviously'), ('obviously', 'closely'), ('closely', 'interweaved'), ('interweaved', 'used')]

>> Trigrams are: 
 [('Though', 'NLP', 'tasks'), ('NLP', 'tasks', 'obviously'), ('tasks', 'obviously', 'closely'), ('obviously', 'closely', 'interweaved'), ('closely', 'interweaved', 'used')]

>> POS Tags are: 
 [('Though', 'IN'), ('NLP', 'NNP'), ('tasks', 'NNS'), ('obviously', 'RB'), ('closely', 'RB'), ('interweaved', 'VBN'), ('used', 'VBN')]

>> Noun Phrases are: 
 ['NLP tasks']

>> Named Entities are: 
 [('ORGANIZATION', 'NLP')] 

>> Stemming using Porter Stemmer: 
 [('Though', 'though'), ('NLP', 'nlp'), ('tasks', 'task'), ('obviously', 'obvious'), ('closely', 'close'), ('interweaved', 'interweav'), ('used', 'use')]

>> Stemming using Snowball Stemmer: 
 [('Though', 'though'), ('NLP', 'nlp'), ('tasks', 'task'), ('obviously', 'obvious'), ('closely', 'close'), ('interweaved', 'interweav'), ('used', 'use')]

>> Lemmatization: 
 [('Though', 'Though'), ('NLP', 'NLP'), ('tasks', 'task'), ('obviously', 'obviously'), ('closely', 'closely'), ('interweaved', 'interweaved'), ('used', 'used')]



========================================== PARAGRAPH 56 ===========================================

frequently, for convenience. Some of the task such as automatic summarisation, co-reference  

------------------- Sentence 1 -------------------

frequently, for convenience.

>> Tokens are: 
 ['frequently', ',', 'convenience', '.']

>> Bigrams are: 
 [('frequently', ','), (',', 'convenience'), ('convenience', '.')]

>> Trigrams are: 
 [('frequently', ',', 'convenience'), (',', 'convenience', '.')]

>> POS Tags are: 
 [('frequently', 'RB'), (',', ','), ('convenience', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['convenience']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('frequently', 'frequent'), (',', ','), ('convenience', 'conveni'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('frequently', 'frequent'), (',', ','), ('convenience', 'conveni'), ('.', '.')]

>> Lemmatization: 
 [('frequently', 'frequently'), (',', ','), ('convenience', 'convenience'), ('.', '.')]


------------------- Sentence 2 -------------------

Some of the task such as automatic summarisation, co-reference

>> Tokens are: 
 ['Some', 'task', 'automatic', 'summarisation', ',', 'co-reference']

>> Bigrams are: 
 [('Some', 'task'), ('task', 'automatic'), ('automatic', 'summarisation'), ('summarisation', ','), (',', 'co-reference')]

>> Trigrams are: 
 [('Some', 'task', 'automatic'), ('task', 'automatic', 'summarisation'), ('automatic', 'summarisation', ','), ('summarisation', ',', 'co-reference')]

>> POS Tags are: 
 [('Some', 'DT'), ('task', 'NN'), ('automatic', 'JJ'), ('summarisation', 'NN'), (',', ','), ('co-reference', 'NN')]

>> Noun Phrases are: 
 ['Some task', 'automatic summarisation', 'co-reference']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Some', 'some'), ('task', 'task'), ('automatic', 'automat'), ('summarisation', 'summaris'), (',', ','), ('co-reference', 'co-refer')]

>> Stemming using Snowball Stemmer: 
 [('Some', 'some'), ('task', 'task'), ('automatic', 'automat'), ('summarisation', 'summaris'), (',', ','), ('co-reference', 'co-refer')]

>> Lemmatization: 
 [('Some', 'Some'), ('task', 'task'), ('automatic', 'automatic'), ('summarisation', 'summarisation'), (',', ','), ('co-reference', 'co-reference')]



========================================== PARAGRAPH 57 ===========================================

analysis etc. act as subtask that are used in solving larger tasks.  

------------------- Sentence 1 -------------------

analysis etc.

>> Tokens are: 
 ['analysis', 'etc', '.']

>> Bigrams are: 
 [('analysis', 'etc'), ('etc', '.')]

>> Trigrams are: 
 [('analysis', 'etc', '.')]

>> POS Tags are: 
 [('analysis', 'NN'), ('etc', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['analysis etc']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('analysis', 'analysi'), ('etc', 'etc'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('analysis', 'analysi'), ('etc', 'etc'), ('.', '.')]

>> Lemmatization: 
 [('analysis', 'analysis'), ('etc', 'etc'), ('.', '.')]


------------------- Sentence 2 -------------------

act as subtask that are used in solving larger tasks.

>> Tokens are: 
 ['act', 'subtask', 'used', 'solving', 'larger', 'tasks', '.']

>> Bigrams are: 
 [('act', 'subtask'), ('subtask', 'used'), ('used', 'solving'), ('solving', 'larger'), ('larger', 'tasks'), ('tasks', '.')]

>> Trigrams are: 
 [('act', 'subtask', 'used'), ('subtask', 'used', 'solving'), ('used', 'solving', 'larger'), ('solving', 'larger', 'tasks'), ('larger', 'tasks', '.')]

>> POS Tags are: 
 [('act', 'NN'), ('subtask', 'NN'), ('used', 'VBN'), ('solving', 'VBG'), ('larger', 'JJR'), ('tasks', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['act subtask', 'tasks']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('act', 'act'), ('subtask', 'subtask'), ('used', 'use'), ('solving', 'solv'), ('larger', 'larger'), ('tasks', 'task'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('act', 'act'), ('subtask', 'subtask'), ('used', 'use'), ('solving', 'solv'), ('larger', 'larger'), ('tasks', 'task'), ('.', '.')]

>> Lemmatization: 
 [('act', 'act'), ('subtask', 'subtask'), ('used', 'used'), ('solving', 'solving'), ('larger', 'larger'), ('tasks', 'task'), ('.', '.')]



========================================== PARAGRAPH 58 ===========================================

The goal of Natural Language Processing is to accommodate one or more specialities of an  

------------------- Sentence 1 -------------------

The goal of Natural Language Processing is to accommodate one or more specialities of an

>> Tokens are: 
 ['The', 'goal', 'Natural', 'Language', 'Processing', 'accommodate', 'one', 'specialities']

>> Bigrams are: 
 [('The', 'goal'), ('goal', 'Natural'), ('Natural', 'Language'), ('Language', 'Processing'), ('Processing', 'accommodate'), ('accommodate', 'one'), ('one', 'specialities')]

>> Trigrams are: 
 [('The', 'goal', 'Natural'), ('goal', 'Natural', 'Language'), ('Natural', 'Language', 'Processing'), ('Language', 'Processing', 'accommodate'), ('Processing', 'accommodate', 'one'), ('accommodate', 'one', 'specialities')]

>> POS Tags are: 
 [('The', 'DT'), ('goal', 'NN'), ('Natural', 'NNP'), ('Language', 'NNP'), ('Processing', 'NNP'), ('accommodate', 'VB'), ('one', 'CD'), ('specialities', 'NNS')]

>> Noun Phrases are: 
 ['The goal Natural Language Processing', 'specialities']

>> Named Entities are: 
 [('ORGANIZATION', 'Natural Language')] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('goal', 'goal'), ('Natural', 'natur'), ('Language', 'languag'), ('Processing', 'process'), ('accommodate', 'accommod'), ('one', 'one'), ('specialities', 'special')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('goal', 'goal'), ('Natural', 'natur'), ('Language', 'languag'), ('Processing', 'process'), ('accommodate', 'accommod'), ('one', 'one'), ('specialities', 'special')]

>> Lemmatization: 
 [('The', 'The'), ('goal', 'goal'), ('Natural', 'Natural'), ('Language', 'Language'), ('Processing', 'Processing'), ('accommodate', 'accommodate'), ('one', 'one'), ('specialities', 'speciality')]



========================================== PARAGRAPH 59 ===========================================

algorithm or system. The metric of NLP assess on an algorithmic system allows for the  

------------------- Sentence 1 -------------------

algorithm or system.

>> Tokens are: 
 ['algorithm', 'system', '.']

>> Bigrams are: 
 [('algorithm', 'system'), ('system', '.')]

>> Trigrams are: 
 [('algorithm', 'system', '.')]

>> POS Tags are: 
 [('algorithm', 'NN'), ('system', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['algorithm system']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('algorithm', 'algorithm'), ('system', 'system'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('algorithm', 'algorithm'), ('system', 'system'), ('.', '.')]

>> Lemmatization: 
 [('algorithm', 'algorithm'), ('system', 'system'), ('.', '.')]


------------------- Sentence 2 -------------------

The metric of NLP assess on an algorithmic system allows for the

>> Tokens are: 
 ['The', 'metric', 'NLP', 'assess', 'algorithmic', 'system', 'allows']

>> Bigrams are: 
 [('The', 'metric'), ('metric', 'NLP'), ('NLP', 'assess'), ('assess', 'algorithmic'), ('algorithmic', 'system'), ('system', 'allows')]

>> Trigrams are: 
 [('The', 'metric', 'NLP'), ('metric', 'NLP', 'assess'), ('NLP', 'assess', 'algorithmic'), ('assess', 'algorithmic', 'system'), ('algorithmic', 'system', 'allows')]

>> POS Tags are: 
 [('The', 'DT'), ('metric', 'JJ'), ('NLP', 'NNP'), ('assess', 'NN'), ('algorithmic', 'JJ'), ('system', 'NN'), ('allows', 'NNS')]

>> Noun Phrases are: 
 ['The metric NLP assess', 'algorithmic system allows']

>> Named Entities are: 
 [('ORGANIZATION', 'NLP')] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('metric', 'metric'), ('NLP', 'nlp'), ('assess', 'assess'), ('algorithmic', 'algorithm'), ('system', 'system'), ('allows', 'allow')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('metric', 'metric'), ('NLP', 'nlp'), ('assess', 'assess'), ('algorithmic', 'algorithm'), ('system', 'system'), ('allows', 'allow')]

>> Lemmatization: 
 [('The', 'The'), ('metric', 'metric'), ('NLP', 'NLP'), ('assess', 'ass'), ('algorithmic', 'algorithmic'), ('system', 'system'), ('allows', 'allows')]



========================================== PARAGRAPH 60 ===========================================

integration of language understanding and language generation. It is even used in  

------------------- Sentence 1 -------------------

integration of language understanding and language generation.

>> Tokens are: 
 ['integration', 'language', 'understanding', 'language', 'generation', '.']

>> Bigrams are: 
 [('integration', 'language'), ('language', 'understanding'), ('understanding', 'language'), ('language', 'generation'), ('generation', '.')]

>> Trigrams are: 
 [('integration', 'language', 'understanding'), ('language', 'understanding', 'language'), ('understanding', 'language', 'generation'), ('language', 'generation', '.')]

>> POS Tags are: 
 [('integration', 'NN'), ('language', 'NN'), ('understanding', 'JJ'), ('language', 'NN'), ('generation', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['integration language', 'understanding language generation']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('integration', 'integr'), ('language', 'languag'), ('understanding', 'understand'), ('language', 'languag'), ('generation', 'gener'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('integration', 'integr'), ('language', 'languag'), ('understanding', 'understand'), ('language', 'languag'), ('generation', 'generat'), ('.', '.')]

>> Lemmatization: 
 [('integration', 'integration'), ('language', 'language'), ('understanding', 'understanding'), ('language', 'language'), ('generation', 'generation'), ('.', '.')]


------------------- Sentence 2 -------------------

It is even used in

>> Tokens are: 
 ['It', 'even', 'used']

>> Bigrams are: 
 [('It', 'even'), ('even', 'used')]

>> Trigrams are: 
 [('It', 'even', 'used')]

>> POS Tags are: 
 [('It', 'PRP'), ('even', 'RB'), ('used', 'VBD')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('It', 'it'), ('even', 'even'), ('used', 'use')]

>> Stemming using Snowball Stemmer: 
 [('It', 'it'), ('even', 'even'), ('used', 'use')]

>> Lemmatization: 
 [('It', 'It'), ('even', 'even'), ('used', 'used')]



========================================== PARAGRAPH 61 ===========================================

multilingual event detection Rospocher et al. [2] purposed a novel modular system for cross- 

------------------- Sentence 1 -------------------

multilingual event detection Rospocher et al.

>> Tokens are: 
 ['multilingual', 'event', 'detection', 'Rospocher', 'et', 'al', '.']

>> Bigrams are: 
 [('multilingual', 'event'), ('event', 'detection'), ('detection', 'Rospocher'), ('Rospocher', 'et'), ('et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('multilingual', 'event', 'detection'), ('event', 'detection', 'Rospocher'), ('detection', 'Rospocher', 'et'), ('Rospocher', 'et', 'al'), ('et', 'al', '.')]

>> POS Tags are: 
 [('multilingual', 'JJ'), ('event', 'NN'), ('detection', 'NN'), ('Rospocher', 'NNP'), ('et', 'CC'), ('al', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['multilingual event detection Rospocher', 'al']

>> Named Entities are: 
 [('PERSON', 'Rospocher')] 

>> Stemming using Porter Stemmer: 
 [('multilingual', 'multilingu'), ('event', 'event'), ('detection', 'detect'), ('Rospocher', 'rospoch'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('multilingual', 'multilingu'), ('event', 'event'), ('detection', 'detect'), ('Rospocher', 'rospoch'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('multilingual', 'multilingual'), ('event', 'event'), ('detection', 'detection'), ('Rospocher', 'Rospocher'), ('et', 'et'), ('al', 'al'), ('.', '.')]


------------------- Sentence 2 -------------------

[2] purposed a novel modular system for cross-

>> Tokens are: 
 ['[', '2', ']', 'purposed', 'novel', 'modular', 'system', 'cross-']

>> Bigrams are: 
 [('[', '2'), ('2', ']'), (']', 'purposed'), ('purposed', 'novel'), ('novel', 'modular'), ('modular', 'system'), ('system', 'cross-')]

>> Trigrams are: 
 [('[', '2', ']'), ('2', ']', 'purposed'), (']', 'purposed', 'novel'), ('purposed', 'novel', 'modular'), ('novel', 'modular', 'system'), ('modular', 'system', 'cross-')]

>> POS Tags are: 
 [('[', 'RB'), ('2', 'CD'), (']', 'NNS'), ('purposed', 'VBD'), ('novel', 'JJ'), ('modular', 'JJ'), ('system', 'NN'), ('cross-', 'JJ')]

>> Noun Phrases are: 
 [']', 'novel modular system']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('2', '2'), (']', ']'), ('purposed', 'purpos'), ('novel', 'novel'), ('modular', 'modular'), ('system', 'system'), ('cross-', 'cross-')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('2', '2'), (']', ']'), ('purposed', 'purpos'), ('novel', 'novel'), ('modular', 'modular'), ('system', 'system'), ('cross-', 'cross-')]

>> Lemmatization: 
 [('[', '['), ('2', '2'), (']', ']'), ('purposed', 'purposed'), ('novel', 'novel'), ('modular', 'modular'), ('system', 'system'), ('cross-', 'cross-')]



========================================== PARAGRAPH 62 ===========================================

lingual event extraction for English, Dutch and Italian texts by using different pipelines for  

------------------- Sentence 1 -------------------

lingual event extraction for English, Dutch and Italian texts by using different pipelines for

>> Tokens are: 
 ['lingual', 'event', 'extraction', 'English', ',', 'Dutch', 'Italian', 'texts', 'using', 'different', 'pipelines']

>> Bigrams are: 
 [('lingual', 'event'), ('event', 'extraction'), ('extraction', 'English'), ('English', ','), (',', 'Dutch'), ('Dutch', 'Italian'), ('Italian', 'texts'), ('texts', 'using'), ('using', 'different'), ('different', 'pipelines')]

>> Trigrams are: 
 [('lingual', 'event', 'extraction'), ('event', 'extraction', 'English'), ('extraction', 'English', ','), ('English', ',', 'Dutch'), (',', 'Dutch', 'Italian'), ('Dutch', 'Italian', 'texts'), ('Italian', 'texts', 'using'), ('texts', 'using', 'different'), ('using', 'different', 'pipelines')]

>> POS Tags are: 
 [('lingual', 'JJ'), ('event', 'NN'), ('extraction', 'NN'), ('English', 'NNP'), (',', ','), ('Dutch', 'NNP'), ('Italian', 'NNP'), ('texts', 'NN'), ('using', 'VBG'), ('different', 'JJ'), ('pipelines', 'NNS')]

>> Noun Phrases are: 
 ['lingual event extraction English', 'Dutch Italian texts', 'different pipelines']

>> Named Entities are: 
 [('GPE', 'English'), ('PERSON', 'Dutch Italian')] 

>> Stemming using Porter Stemmer: 
 [('lingual', 'lingual'), ('event', 'event'), ('extraction', 'extract'), ('English', 'english'), (',', ','), ('Dutch', 'dutch'), ('Italian', 'italian'), ('texts', 'text'), ('using', 'use'), ('different', 'differ'), ('pipelines', 'pipelin')]

>> Stemming using Snowball Stemmer: 
 [('lingual', 'lingual'), ('event', 'event'), ('extraction', 'extract'), ('English', 'english'), (',', ','), ('Dutch', 'dutch'), ('Italian', 'italian'), ('texts', 'text'), ('using', 'use'), ('different', 'differ'), ('pipelines', 'pipelin')]

>> Lemmatization: 
 [('lingual', 'lingual'), ('event', 'event'), ('extraction', 'extraction'), ('English', 'English'), (',', ','), ('Dutch', 'Dutch'), ('Italian', 'Italian'), ('texts', 'text'), ('using', 'using'), ('different', 'different'), ('pipelines', 'pipeline')]



========================================== PARAGRAPH 63 ===========================================

different languages. The system incorporates a modular set of foremost multilingual Natural  

------------------- Sentence 1 -------------------

different languages.

>> Tokens are: 
 ['different', 'languages', '.']

>> Bigrams are: 
 [('different', 'languages'), ('languages', '.')]

>> Trigrams are: 
 [('different', 'languages', '.')]

>> POS Tags are: 
 [('different', 'JJ'), ('languages', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['different languages']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('different', 'differ'), ('languages', 'languag'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('different', 'differ'), ('languages', 'languag'), ('.', '.')]

>> Lemmatization: 
 [('different', 'different'), ('languages', 'language'), ('.', '.')]


------------------- Sentence 2 -------------------

The system incorporates a modular set of foremost multilingual Natural

>> Tokens are: 
 ['The', 'system', 'incorporates', 'modular', 'set', 'foremost', 'multilingual', 'Natural']

>> Bigrams are: 
 [('The', 'system'), ('system', 'incorporates'), ('incorporates', 'modular'), ('modular', 'set'), ('set', 'foremost'), ('foremost', 'multilingual'), ('multilingual', 'Natural')]

>> Trigrams are: 
 [('The', 'system', 'incorporates'), ('system', 'incorporates', 'modular'), ('incorporates', 'modular', 'set'), ('modular', 'set', 'foremost'), ('set', 'foremost', 'multilingual'), ('foremost', 'multilingual', 'Natural')]

>> POS Tags are: 
 [('The', 'DT'), ('system', 'NN'), ('incorporates', 'VBZ'), ('modular', 'JJ'), ('set', 'NN'), ('foremost', 'NN'), ('multilingual', 'JJ'), ('Natural', 'NNP')]

>> Noun Phrases are: 
 ['The system', 'modular set foremost', 'multilingual Natural']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('system', 'system'), ('incorporates', 'incorpor'), ('modular', 'modular'), ('set', 'set'), ('foremost', 'foremost'), ('multilingual', 'multilingu'), ('Natural', 'natur')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('system', 'system'), ('incorporates', 'incorpor'), ('modular', 'modular'), ('set', 'set'), ('foremost', 'foremost'), ('multilingual', 'multilingu'), ('Natural', 'natur')]

>> Lemmatization: 
 [('The', 'The'), ('system', 'system'), ('incorporates', 'incorporates'), ('modular', 'modular'), ('set', 'set'), ('foremost', 'foremost'), ('multilingual', 'multilingual'), ('Natural', 'Natural')]



========================================== PARAGRAPH 64 ===========================================

Language Processing (NLP) tools. The pipeline integrates modules for basic NLP processing  

------------------- Sentence 1 -------------------

Language Processing (NLP) tools.

>> Tokens are: 
 ['Language', 'Processing', '(', 'NLP', ')', 'tools', '.']

>> Bigrams are: 
 [('Language', 'Processing'), ('Processing', '('), ('(', 'NLP'), ('NLP', ')'), (')', 'tools'), ('tools', '.')]

>> Trigrams are: 
 [('Language', 'Processing', '('), ('Processing', '(', 'NLP'), ('(', 'NLP', ')'), ('NLP', ')', 'tools'), (')', 'tools', '.')]

>> POS Tags are: 
 [('Language', 'NN'), ('Processing', 'NNP'), ('(', '('), ('NLP', 'NNP'), (')', ')'), ('tools', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['Language Processing', 'NLP', 'tools']

>> Named Entities are: 
 [('PERSON', 'Language'), ('ORGANIZATION', 'Processing'), ('ORGANIZATION', 'NLP')] 

>> Stemming using Porter Stemmer: 
 [('Language', 'languag'), ('Processing', 'process'), ('(', '('), ('NLP', 'nlp'), (')', ')'), ('tools', 'tool'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Language', 'languag'), ('Processing', 'process'), ('(', '('), ('NLP', 'nlp'), (')', ')'), ('tools', 'tool'), ('.', '.')]

>> Lemmatization: 
 [('Language', 'Language'), ('Processing', 'Processing'), ('(', '('), ('NLP', 'NLP'), (')', ')'), ('tools', 'tool'), ('.', '.')]


------------------- Sentence 2 -------------------

The pipeline integrates modules for basic NLP processing

>> Tokens are: 
 ['The', 'pipeline', 'integrates', 'modules', 'basic', 'NLP', 'processing']

>> Bigrams are: 
 [('The', 'pipeline'), ('pipeline', 'integrates'), ('integrates', 'modules'), ('modules', 'basic'), ('basic', 'NLP'), ('NLP', 'processing')]

>> Trigrams are: 
 [('The', 'pipeline', 'integrates'), ('pipeline', 'integrates', 'modules'), ('integrates', 'modules', 'basic'), ('modules', 'basic', 'NLP'), ('basic', 'NLP', 'processing')]

>> POS Tags are: 
 [('The', 'DT'), ('pipeline', 'NN'), ('integrates', 'VBZ'), ('modules', 'NNS'), ('basic', 'JJ'), ('NLP', 'NNP'), ('processing', 'NN')]

>> Noun Phrases are: 
 ['The pipeline', 'modules', 'basic NLP processing']

>> Named Entities are: 
 [('ORGANIZATION', 'NLP')] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('pipeline', 'pipelin'), ('integrates', 'integr'), ('modules', 'modul'), ('basic', 'basic'), ('NLP', 'nlp'), ('processing', 'process')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('pipeline', 'pipelin'), ('integrates', 'integr'), ('modules', 'modul'), ('basic', 'basic'), ('NLP', 'nlp'), ('processing', 'process')]

>> Lemmatization: 
 [('The', 'The'), ('pipeline', 'pipeline'), ('integrates', 'integrates'), ('modules', 'module'), ('basic', 'basic'), ('NLP', 'NLP'), ('processing', 'processing')]



========================================== PARAGRAPH 65 ===========================================

as well as more advanced tasks such as cross-lingual named entity linking, semantic role  

------------------- Sentence 1 -------------------

as well as more advanced tasks such as cross-lingual named entity linking, semantic role

>> Tokens are: 
 ['well', 'advanced', 'tasks', 'cross-lingual', 'named', 'entity', 'linking', ',', 'semantic', 'role']

>> Bigrams are: 
 [('well', 'advanced'), ('advanced', 'tasks'), ('tasks', 'cross-lingual'), ('cross-lingual', 'named'), ('named', 'entity'), ('entity', 'linking'), ('linking', ','), (',', 'semantic'), ('semantic', 'role')]

>> Trigrams are: 
 [('well', 'advanced', 'tasks'), ('advanced', 'tasks', 'cross-lingual'), ('tasks', 'cross-lingual', 'named'), ('cross-lingual', 'named', 'entity'), ('named', 'entity', 'linking'), ('entity', 'linking', ','), ('linking', ',', 'semantic'), (',', 'semantic', 'role')]

>> POS Tags are: 
 [('well', 'RB'), ('advanced', 'JJ'), ('tasks', 'NNS'), ('cross-lingual', 'JJ'), ('named', 'VBN'), ('entity', 'NN'), ('linking', 'VBG'), (',', ','), ('semantic', 'JJ'), ('role', 'NN')]

>> Noun Phrases are: 
 ['advanced tasks', 'entity', 'semantic role']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('well', 'well'), ('advanced', 'advanc'), ('tasks', 'task'), ('cross-lingual', 'cross-lingu'), ('named', 'name'), ('entity', 'entiti'), ('linking', 'link'), (',', ','), ('semantic', 'semant'), ('role', 'role')]

>> Stemming using Snowball Stemmer: 
 [('well', 'well'), ('advanced', 'advanc'), ('tasks', 'task'), ('cross-lingual', 'cross-lingu'), ('named', 'name'), ('entity', 'entiti'), ('linking', 'link'), (',', ','), ('semantic', 'semant'), ('role', 'role')]

>> Lemmatization: 
 [('well', 'well'), ('advanced', 'advanced'), ('tasks', 'task'), ('cross-lingual', 'cross-lingual'), ('named', 'named'), ('entity', 'entity'), ('linking', 'linking'), (',', ','), ('semantic', 'semantic'), ('role', 'role')]



========================================== PARAGRAPH 66 ===========================================

labelling and time normalization. Thus, the cross-lingual framework allows for the  

------------------- Sentence 1 -------------------

labelling and time normalization.

>> Tokens are: 
 ['labelling', 'time', 'normalization', '.']

>> Bigrams are: 
 [('labelling', 'time'), ('time', 'normalization'), ('normalization', '.')]

>> Trigrams are: 
 [('labelling', 'time', 'normalization'), ('time', 'normalization', '.')]

>> POS Tags are: 
 [('labelling', 'VBG'), ('time', 'NN'), ('normalization', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['time normalization']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('labelling', 'label'), ('time', 'time'), ('normalization', 'normal'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('labelling', 'label'), ('time', 'time'), ('normalization', 'normal'), ('.', '.')]

>> Lemmatization: 
 [('labelling', 'labelling'), ('time', 'time'), ('normalization', 'normalization'), ('.', '.')]


------------------- Sentence 2 -------------------

Thus, the cross-lingual framework allows for the

>> Tokens are: 
 ['Thus', ',', 'cross-lingual', 'framework', 'allows']

>> Bigrams are: 
 [('Thus', ','), (',', 'cross-lingual'), ('cross-lingual', 'framework'), ('framework', 'allows')]

>> Trigrams are: 
 [('Thus', ',', 'cross-lingual'), (',', 'cross-lingual', 'framework'), ('cross-lingual', 'framework', 'allows')]

>> POS Tags are: 
 [('Thus', 'RB'), (',', ','), ('cross-lingual', 'JJ'), ('framework', 'NN'), ('allows', 'NNS')]

>> Noun Phrases are: 
 ['cross-lingual framework allows']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Thus', 'thu'), (',', ','), ('cross-lingual', 'cross-lingu'), ('framework', 'framework'), ('allows', 'allow')]

>> Stemming using Snowball Stemmer: 
 [('Thus', 'thus'), (',', ','), ('cross-lingual', 'cross-lingu'), ('framework', 'framework'), ('allows', 'allow')]

>> Lemmatization: 
 [('Thus', 'Thus'), (',', ','), ('cross-lingual', 'cross-lingual'), ('framework', 'framework'), ('allows', 'allows')]



========================================== PARAGRAPH 67 ===========================================

interpretation of events, participants, locations and time, as well as the relations between  

------------------- Sentence 1 -------------------

interpretation of events, participants, locations and time, as well as the relations between

>> Tokens are: 
 ['interpretation', 'events', ',', 'participants', ',', 'locations', 'time', ',', 'well', 'relations']

>> Bigrams are: 
 [('interpretation', 'events'), ('events', ','), (',', 'participants'), ('participants', ','), (',', 'locations'), ('locations', 'time'), ('time', ','), (',', 'well'), ('well', 'relations')]

>> Trigrams are: 
 [('interpretation', 'events', ','), ('events', ',', 'participants'), (',', 'participants', ','), ('participants', ',', 'locations'), (',', 'locations', 'time'), ('locations', 'time', ','), ('time', ',', 'well'), (',', 'well', 'relations')]

>> POS Tags are: 
 [('interpretation', 'NN'), ('events', 'NNS'), (',', ','), ('participants', 'NNS'), (',', ','), ('locations', 'NNS'), ('time', 'NN'), (',', ','), ('well', 'UH'), ('relations', 'NNS')]

>> Noun Phrases are: 
 ['interpretation events', 'participants', 'locations time', 'relations']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('interpretation', 'interpret'), ('events', 'event'), (',', ','), ('participants', 'particip'), (',', ','), ('locations', 'locat'), ('time', 'time'), (',', ','), ('well', 'well'), ('relations', 'relat')]

>> Stemming using Snowball Stemmer: 
 [('interpretation', 'interpret'), ('events', 'event'), (',', ','), ('participants', 'particip'), (',', ','), ('locations', 'locat'), ('time', 'time'), (',', ','), ('well', 'well'), ('relations', 'relat')]

>> Lemmatization: 
 [('interpretation', 'interpretation'), ('events', 'event'), (',', ','), ('participants', 'participant'), (',', ','), ('locations', 'location'), ('time', 'time'), (',', ','), ('well', 'well'), ('relations', 'relation')]



========================================== PARAGRAPH 68 ===========================================

them. Output of these individual pipelines is intended to be used as input for a system that  

------------------- Sentence 1 -------------------

them.

>> Tokens are: 
 ['.']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('.', '.')]

>> Lemmatization: 
 [('.', '.')]


------------------- Sentence 2 -------------------

Output of these individual pipelines is intended to be used as input for a system that

>> Tokens are: 
 ['Output', 'individual', 'pipelines', 'intended', 'used', 'input', 'system']

>> Bigrams are: 
 [('Output', 'individual'), ('individual', 'pipelines'), ('pipelines', 'intended'), ('intended', 'used'), ('used', 'input'), ('input', 'system')]

>> Trigrams are: 
 [('Output', 'individual', 'pipelines'), ('individual', 'pipelines', 'intended'), ('pipelines', 'intended', 'used'), ('intended', 'used', 'input'), ('used', 'input', 'system')]

>> POS Tags are: 
 [('Output', 'NNP'), ('individual', 'JJ'), ('pipelines', 'NNS'), ('intended', 'VBN'), ('used', 'VBN'), ('input', 'NN'), ('system', 'NN')]

>> Noun Phrases are: 
 ['Output', 'individual pipelines', 'input system']

>> Named Entities are: 
 [('GPE', 'Output')] 

>> Stemming using Porter Stemmer: 
 [('Output', 'output'), ('individual', 'individu'), ('pipelines', 'pipelin'), ('intended', 'intend'), ('used', 'use'), ('input', 'input'), ('system', 'system')]

>> Stemming using Snowball Stemmer: 
 [('Output', 'output'), ('individual', 'individu'), ('pipelines', 'pipelin'), ('intended', 'intend'), ('used', 'use'), ('input', 'input'), ('system', 'system')]

>> Lemmatization: 
 [('Output', 'Output'), ('individual', 'individual'), ('pipelines', 'pipeline'), ('intended', 'intended'), ('used', 'used'), ('input', 'input'), ('system', 'system')]



========================================== PARAGRAPH 69 ===========================================

obtains event centric knowledge graphs. All modules behave like UNIX pipes: they all take  

------------------- Sentence 1 -------------------

obtains event centric knowledge graphs.

>> Tokens are: 
 ['obtains', 'event', 'centric', 'knowledge', 'graphs', '.']

>> Bigrams are: 
 [('obtains', 'event'), ('event', 'centric'), ('centric', 'knowledge'), ('knowledge', 'graphs'), ('graphs', '.')]

>> Trigrams are: 
 [('obtains', 'event', 'centric'), ('event', 'centric', 'knowledge'), ('centric', 'knowledge', 'graphs'), ('knowledge', 'graphs', '.')]

>> POS Tags are: 
 [('obtains', 'NNS'), ('event', 'NN'), ('centric', 'NN'), ('knowledge', 'NN'), ('graphs', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['obtains event centric knowledge graphs']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('obtains', 'obtain'), ('event', 'event'), ('centric', 'centric'), ('knowledge', 'knowledg'), ('graphs', 'graph'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('obtains', 'obtain'), ('event', 'event'), ('centric', 'centric'), ('knowledge', 'knowledg'), ('graphs', 'graph'), ('.', '.')]

>> Lemmatization: 
 [('obtains', 'obtains'), ('event', 'event'), ('centric', 'centric'), ('knowledge', 'knowledge'), ('graphs', 'graph'), ('.', '.')]


------------------- Sentence 2 -------------------

All modules behave like UNIX pipes: they all take

>> Tokens are: 
 ['All', 'modules', 'behave', 'like', 'UNIX', 'pipes', ':', 'take']

>> Bigrams are: 
 [('All', 'modules'), ('modules', 'behave'), ('behave', 'like'), ('like', 'UNIX'), ('UNIX', 'pipes'), ('pipes', ':'), (':', 'take')]

>> Trigrams are: 
 [('All', 'modules', 'behave'), ('modules', 'behave', 'like'), ('behave', 'like', 'UNIX'), ('like', 'UNIX', 'pipes'), ('UNIX', 'pipes', ':'), ('pipes', ':', 'take')]

>> POS Tags are: 
 [('All', 'DT'), ('modules', 'NNS'), ('behave', 'VBP'), ('like', 'IN'), ('UNIX', 'NNP'), ('pipes', 'NNS'), (':', ':'), ('take', 'VB')]

>> Noun Phrases are: 
 ['All modules', 'UNIX pipes']

>> Named Entities are: 
 [('ORGANIZATION', 'UNIX')] 

>> Stemming using Porter Stemmer: 
 [('All', 'all'), ('modules', 'modul'), ('behave', 'behav'), ('like', 'like'), ('UNIX', 'unix'), ('pipes', 'pipe'), (':', ':'), ('take', 'take')]

>> Stemming using Snowball Stemmer: 
 [('All', 'all'), ('modules', 'modul'), ('behave', 'behav'), ('like', 'like'), ('UNIX', 'unix'), ('pipes', 'pipe'), (':', ':'), ('take', 'take')]

>> Lemmatization: 
 [('All', 'All'), ('modules', 'module'), ('behave', 'behave'), ('like', 'like'), ('UNIX', 'UNIX'), ('pipes', 'pipe'), (':', ':'), ('take', 'take')]



========================================== PARAGRAPH 70 ===========================================

standard input, to do some annotation, and produce standard output which in turn is the input  

------------------- Sentence 1 -------------------

standard input, to do some annotation, and produce standard output which in turn is the input

>> Tokens are: 
 ['standard', 'input', ',', 'annotation', ',', 'produce', 'standard', 'output', 'turn', 'input']

>> Bigrams are: 
 [('standard', 'input'), ('input', ','), (',', 'annotation'), ('annotation', ','), (',', 'produce'), ('produce', 'standard'), ('standard', 'output'), ('output', 'turn'), ('turn', 'input')]

>> Trigrams are: 
 [('standard', 'input', ','), ('input', ',', 'annotation'), (',', 'annotation', ','), ('annotation', ',', 'produce'), (',', 'produce', 'standard'), ('produce', 'standard', 'output'), ('standard', 'output', 'turn'), ('output', 'turn', 'input')]

>> POS Tags are: 
 [('standard', 'JJ'), ('input', 'NN'), (',', ','), ('annotation', 'NN'), (',', ','), ('produce', 'VB'), ('standard', 'JJ'), ('output', 'NN'), ('turn', 'NN'), ('input', 'NN')]

>> Noun Phrases are: 
 ['standard input', 'annotation', 'standard output turn input']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('standard', 'standard'), ('input', 'input'), (',', ','), ('annotation', 'annot'), (',', ','), ('produce', 'produc'), ('standard', 'standard'), ('output', 'output'), ('turn', 'turn'), ('input', 'input')]

>> Stemming using Snowball Stemmer: 
 [('standard', 'standard'), ('input', 'input'), (',', ','), ('annotation', 'annot'), (',', ','), ('produce', 'produc'), ('standard', 'standard'), ('output', 'output'), ('turn', 'turn'), ('input', 'input')]

>> Lemmatization: 
 [('standard', 'standard'), ('input', 'input'), (',', ','), ('annotation', 'annotation'), (',', ','), ('produce', 'produce'), ('standard', 'standard'), ('output', 'output'), ('turn', 'turn'), ('input', 'input')]



========================================== PARAGRAPH 71 ===========================================

for the next module pipelines are built as a data centric architecture so that modules can be  

------------------- Sentence 1 -------------------

for the next module pipelines are built as a data centric architecture so that modules can be

>> Tokens are: 
 ['next', 'module', 'pipelines', 'built', 'data', 'centric', 'architecture', 'modules']

>> Bigrams are: 
 [('next', 'module'), ('module', 'pipelines'), ('pipelines', 'built'), ('built', 'data'), ('data', 'centric'), ('centric', 'architecture'), ('architecture', 'modules')]

>> Trigrams are: 
 [('next', 'module', 'pipelines'), ('module', 'pipelines', 'built'), ('pipelines', 'built', 'data'), ('built', 'data', 'centric'), ('data', 'centric', 'architecture'), ('centric', 'architecture', 'modules')]

>> POS Tags are: 
 [('next', 'JJ'), ('module', 'NN'), ('pipelines', 'NNS'), ('built', 'VBN'), ('data', 'NNS'), ('centric', 'JJ'), ('architecture', 'NN'), ('modules', 'NNS')]

>> Noun Phrases are: 
 ['next module pipelines', 'data', 'centric architecture modules']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('next', 'next'), ('module', 'modul'), ('pipelines', 'pipelin'), ('built', 'built'), ('data', 'data'), ('centric', 'centric'), ('architecture', 'architectur'), ('modules', 'modul')]

>> Stemming using Snowball Stemmer: 
 [('next', 'next'), ('module', 'modul'), ('pipelines', 'pipelin'), ('built', 'built'), ('data', 'data'), ('centric', 'centric'), ('architecture', 'architectur'), ('modules', 'modul')]

>> Lemmatization: 
 [('next', 'next'), ('module', 'module'), ('pipelines', 'pipeline'), ('built', 'built'), ('data', 'data'), ('centric', 'centric'), ('architecture', 'architecture'), ('modules', 'module')]



========================================== PARAGRAPH 72 ===========================================

adapted and replaced. Furthermore, modular architecture allows for different configurations  

------------------- Sentence 1 -------------------

adapted and replaced.

>> Tokens are: 
 ['adapted', 'replaced', '.']

>> Bigrams are: 
 [('adapted', 'replaced'), ('replaced', '.')]

>> Trigrams are: 
 [('adapted', 'replaced', '.')]

>> POS Tags are: 
 [('adapted', 'VBN'), ('replaced', 'VBD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('adapted', 'adapt'), ('replaced', 'replac'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('adapted', 'adapt'), ('replaced', 'replac'), ('.', '.')]

>> Lemmatization: 
 [('adapted', 'adapted'), ('replaced', 'replaced'), ('.', '.')]


------------------- Sentence 2 -------------------

Furthermore, modular architecture allows for different configurations

>> Tokens are: 
 ['Furthermore', ',', 'modular', 'architecture', 'allows', 'different', 'configurations']

>> Bigrams are: 
 [('Furthermore', ','), (',', 'modular'), ('modular', 'architecture'), ('architecture', 'allows'), ('allows', 'different'), ('different', 'configurations')]

>> Trigrams are: 
 [('Furthermore', ',', 'modular'), (',', 'modular', 'architecture'), ('modular', 'architecture', 'allows'), ('architecture', 'allows', 'different'), ('allows', 'different', 'configurations')]

>> POS Tags are: 
 [('Furthermore', 'RB'), (',', ','), ('modular', 'JJ'), ('architecture', 'NN'), ('allows', 'VBZ'), ('different', 'JJ'), ('configurations', 'NNS')]

>> Noun Phrases are: 
 ['modular architecture', 'different configurations']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Furthermore', 'furthermor'), (',', ','), ('modular', 'modular'), ('architecture', 'architectur'), ('allows', 'allow'), ('different', 'differ'), ('configurations', 'configur')]

>> Stemming using Snowball Stemmer: 
 [('Furthermore', 'furthermor'), (',', ','), ('modular', 'modular'), ('architecture', 'architectur'), ('allows', 'allow'), ('different', 'differ'), ('configurations', 'configur')]

>> Lemmatization: 
 [('Furthermore', 'Furthermore'), (',', ','), ('modular', 'modular'), ('architecture', 'architecture'), ('allows', 'allows'), ('different', 'different'), ('configurations', 'configuration')]



========================================== PARAGRAPH 73 ===========================================

and for dynamic distribution.  

------------------- Sentence 1 -------------------

and for dynamic distribution.

>> Tokens are: 
 ['dynamic', 'distribution', '.']

>> Bigrams are: 
 [('dynamic', 'distribution'), ('distribution', '.')]

>> Trigrams are: 
 [('dynamic', 'distribution', '.')]

>> POS Tags are: 
 [('dynamic', 'JJ'), ('distribution', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['dynamic distribution']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('dynamic', 'dynam'), ('distribution', 'distribut'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('dynamic', 'dynam'), ('distribution', 'distribut'), ('.', '.')]

>> Lemmatization: 
 [('dynamic', 'dynamic'), ('distribution', 'distribution'), ('.', '.')]



========================================== PARAGRAPH 74 ===========================================

Most of the work in Natural Language Processing is conducted by computer scientists while  

------------------- Sentence 1 -------------------

Most of the work in Natural Language Processing is conducted by computer scientists while

>> Tokens are: 
 ['Most', 'work', 'Natural', 'Language', 'Processing', 'conducted', 'computer', 'scientists']

>> Bigrams are: 
 [('Most', 'work'), ('work', 'Natural'), ('Natural', 'Language'), ('Language', 'Processing'), ('Processing', 'conducted'), ('conducted', 'computer'), ('computer', 'scientists')]

>> Trigrams are: 
 [('Most', 'work', 'Natural'), ('work', 'Natural', 'Language'), ('Natural', 'Language', 'Processing'), ('Language', 'Processing', 'conducted'), ('Processing', 'conducted', 'computer'), ('conducted', 'computer', 'scientists')]

>> POS Tags are: 
 [('Most', 'JJS'), ('work', 'NN'), ('Natural', 'NNP'), ('Language', 'NNP'), ('Processing', 'NNP'), ('conducted', 'VBD'), ('computer', 'NN'), ('scientists', 'NNS')]

>> Noun Phrases are: 
 ['work Natural Language Processing', 'computer scientists']

>> Named Entities are: 
 [('ORGANIZATION', 'Natural Language')] 

>> Stemming using Porter Stemmer: 
 [('Most', 'most'), ('work', 'work'), ('Natural', 'natur'), ('Language', 'languag'), ('Processing', 'process'), ('conducted', 'conduct'), ('computer', 'comput'), ('scientists', 'scientist')]

>> Stemming using Snowball Stemmer: 
 [('Most', 'most'), ('work', 'work'), ('Natural', 'natur'), ('Language', 'languag'), ('Processing', 'process'), ('conducted', 'conduct'), ('computer', 'comput'), ('scientists', 'scientist')]

>> Lemmatization: 
 [('Most', 'Most'), ('work', 'work'), ('Natural', 'Natural'), ('Language', 'Language'), ('Processing', 'Processing'), ('conducted', 'conducted'), ('computer', 'computer'), ('scientists', 'scientist')]



========================================== PARAGRAPH 75 ===========================================

various other professionals have also shown interest such as linguistics, psychologist and  

------------------- Sentence 1 -------------------

various other professionals have also shown interest such as linguistics, psychologist and

>> Tokens are: 
 ['various', 'professionals', 'also', 'shown', 'interest', 'linguistics', ',', 'psychologist']

>> Bigrams are: 
 [('various', 'professionals'), ('professionals', 'also'), ('also', 'shown'), ('shown', 'interest'), ('interest', 'linguistics'), ('linguistics', ','), (',', 'psychologist')]

>> Trigrams are: 
 [('various', 'professionals', 'also'), ('professionals', 'also', 'shown'), ('also', 'shown', 'interest'), ('shown', 'interest', 'linguistics'), ('interest', 'linguistics', ','), ('linguistics', ',', 'psychologist')]

>> POS Tags are: 
 [('various', 'JJ'), ('professionals', 'NNS'), ('also', 'RB'), ('shown', 'VBN'), ('interest', 'NN'), ('linguistics', 'NNS'), (',', ','), ('psychologist', 'NN')]

>> Noun Phrases are: 
 ['various professionals', 'interest linguistics', 'psychologist']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('various', 'variou'), ('professionals', 'profession'), ('also', 'also'), ('shown', 'shown'), ('interest', 'interest'), ('linguistics', 'linguist'), (',', ','), ('psychologist', 'psychologist')]

>> Stemming using Snowball Stemmer: 
 [('various', 'various'), ('professionals', 'profession'), ('also', 'also'), ('shown', 'shown'), ('interest', 'interest'), ('linguistics', 'linguist'), (',', ','), ('psychologist', 'psychologist')]

>> Lemmatization: 
 [('various', 'various'), ('professionals', 'professional'), ('also', 'also'), ('shown', 'shown'), ('interest', 'interest'), ('linguistics', 'linguistics'), (',', ','), ('psychologist', 'psychologist')]



========================================== PARAGRAPH 76 ===========================================

philosophers etc. One of the most ironical aspect of NLP is that it adds up to the knowledge  

------------------- Sentence 1 -------------------

philosophers etc.

>> Tokens are: 
 ['philosophers', 'etc', '.']

>> Bigrams are: 
 [('philosophers', 'etc'), ('etc', '.')]

>> Trigrams are: 
 [('philosophers', 'etc', '.')]

>> POS Tags are: 
 [('philosophers', 'NNS'), ('etc', 'VBP'), ('.', '.')]

>> Noun Phrases are: 
 ['philosophers']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('philosophers', 'philosoph'), ('etc', 'etc'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('philosophers', 'philosoph'), ('etc', 'etc'), ('.', '.')]

>> Lemmatization: 
 [('philosophers', 'philosopher'), ('etc', 'etc'), ('.', '.')]


------------------- Sentence 2 -------------------

One of the most ironical aspect of NLP is that it adds up to the knowledge

>> Tokens are: 
 ['One', 'ironical', 'aspect', 'NLP', 'adds', 'knowledge']

>> Bigrams are: 
 [('One', 'ironical'), ('ironical', 'aspect'), ('aspect', 'NLP'), ('NLP', 'adds'), ('adds', 'knowledge')]

>> Trigrams are: 
 [('One', 'ironical', 'aspect'), ('ironical', 'aspect', 'NLP'), ('aspect', 'NLP', 'adds'), ('NLP', 'adds', 'knowledge')]

>> POS Tags are: 
 [('One', 'CD'), ('ironical', 'JJ'), ('aspect', 'NN'), ('NLP', 'NNP'), ('adds', 'VBZ'), ('knowledge', 'NN')]

>> Noun Phrases are: 
 ['ironical aspect NLP', 'knowledge']

>> Named Entities are: 
 [('ORGANIZATION', 'NLP')] 

>> Stemming using Porter Stemmer: 
 [('One', 'one'), ('ironical', 'iron'), ('aspect', 'aspect'), ('NLP', 'nlp'), ('adds', 'add'), ('knowledge', 'knowledg')]

>> Stemming using Snowball Stemmer: 
 [('One', 'one'), ('ironical', 'iron'), ('aspect', 'aspect'), ('NLP', 'nlp'), ('adds', 'add'), ('knowledge', 'knowledg')]

>> Lemmatization: 
 [('One', 'One'), ('ironical', 'ironical'), ('aspect', 'aspect'), ('NLP', 'NLP'), ('adds', 'add'), ('knowledge', 'knowledge')]



========================================== PARAGRAPH 77 ===========================================

of human language. The field of Natural Language Processing is related with different  

------------------- Sentence 1 -------------------

of human language.

>> Tokens are: 
 ['human', 'language', '.']

>> Bigrams are: 
 [('human', 'language'), ('language', '.')]

>> Trigrams are: 
 [('human', 'language', '.')]

>> POS Tags are: 
 [('human', 'JJ'), ('language', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['human language']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('human', 'human'), ('language', 'languag'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('human', 'human'), ('language', 'languag'), ('.', '.')]

>> Lemmatization: 
 [('human', 'human'), ('language', 'language'), ('.', '.')]


------------------- Sentence 2 -------------------

The field of Natural Language Processing is related with different

>> Tokens are: 
 ['The', 'field', 'Natural', 'Language', 'Processing', 'related', 'different']

>> Bigrams are: 
 [('The', 'field'), ('field', 'Natural'), ('Natural', 'Language'), ('Language', 'Processing'), ('Processing', 'related'), ('related', 'different')]

>> Trigrams are: 
 [('The', 'field', 'Natural'), ('field', 'Natural', 'Language'), ('Natural', 'Language', 'Processing'), ('Language', 'Processing', 'related'), ('Processing', 'related', 'different')]

>> POS Tags are: 
 [('The', 'DT'), ('field', 'NN'), ('Natural', 'NNP'), ('Language', 'NNP'), ('Processing', 'NNP'), ('related', 'JJ'), ('different', 'JJ')]

>> Noun Phrases are: 
 ['The field Natural Language Processing']

>> Named Entities are: 
 [('ORGANIZATION', 'Natural Language')] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('field', 'field'), ('Natural', 'natur'), ('Language', 'languag'), ('Processing', 'process'), ('related', 'relat'), ('different', 'differ')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('field', 'field'), ('Natural', 'natur'), ('Language', 'languag'), ('Processing', 'process'), ('related', 'relat'), ('different', 'differ')]

>> Lemmatization: 
 [('The', 'The'), ('field', 'field'), ('Natural', 'Natural'), ('Language', 'Language'), ('Processing', 'Processing'), ('related', 'related'), ('different', 'different')]



========================================== PARAGRAPH 78 ===========================================

theories and techniques that deal with the problem of natural language of communicating  

------------------- Sentence 1 -------------------

theories and techniques that deal with the problem of natural language of communicating

>> Tokens are: 
 ['theories', 'techniques', 'deal', 'problem', 'natural', 'language', 'communicating']

>> Bigrams are: 
 [('theories', 'techniques'), ('techniques', 'deal'), ('deal', 'problem'), ('problem', 'natural'), ('natural', 'language'), ('language', 'communicating')]

>> Trigrams are: 
 [('theories', 'techniques', 'deal'), ('techniques', 'deal', 'problem'), ('deal', 'problem', 'natural'), ('problem', 'natural', 'language'), ('natural', 'language', 'communicating')]

>> POS Tags are: 
 [('theories', 'NNS'), ('techniques', 'NNS'), ('deal', 'VBP'), ('problem', 'NN'), ('natural', 'JJ'), ('language', 'NN'), ('communicating', 'NN')]

>> Noun Phrases are: 
 ['theories techniques', 'problem', 'natural language communicating']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('theories', 'theori'), ('techniques', 'techniqu'), ('deal', 'deal'), ('problem', 'problem'), ('natural', 'natur'), ('language', 'languag'), ('communicating', 'commun')]

>> Stemming using Snowball Stemmer: 
 [('theories', 'theori'), ('techniques', 'techniqu'), ('deal', 'deal'), ('problem', 'problem'), ('natural', 'natur'), ('language', 'languag'), ('communicating', 'communic')]

>> Lemmatization: 
 [('theories', 'theory'), ('techniques', 'technique'), ('deal', 'deal'), ('problem', 'problem'), ('natural', 'natural'), ('language', 'language'), ('communicating', 'communicating')]



========================================== PARAGRAPH 79 ===========================================

with the computers. Ambiguity is one of the major problem of natural language which is  

------------------- Sentence 1 -------------------

with the computers.

>> Tokens are: 
 ['computers', '.']

>> Bigrams are: 
 [('computers', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('computers', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['computers']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('computers', 'comput'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('computers', 'comput'), ('.', '.')]

>> Lemmatization: 
 [('computers', 'computer'), ('.', '.')]


------------------- Sentence 2 -------------------

Ambiguity is one of the major problem of natural language which is

>> Tokens are: 
 ['Ambiguity', 'one', 'major', 'problem', 'natural', 'language']

>> Bigrams are: 
 [('Ambiguity', 'one'), ('one', 'major'), ('major', 'problem'), ('problem', 'natural'), ('natural', 'language')]

>> Trigrams are: 
 [('Ambiguity', 'one', 'major'), ('one', 'major', 'problem'), ('major', 'problem', 'natural'), ('problem', 'natural', 'language')]

>> POS Tags are: 
 [('Ambiguity', 'NNP'), ('one', 'CD'), ('major', 'JJ'), ('problem', 'NN'), ('natural', 'JJ'), ('language', 'NN')]

>> Noun Phrases are: 
 ['Ambiguity', 'major problem', 'natural language']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Ambiguity', 'ambigu'), ('one', 'one'), ('major', 'major'), ('problem', 'problem'), ('natural', 'natur'), ('language', 'languag')]

>> Stemming using Snowball Stemmer: 
 [('Ambiguity', 'ambigu'), ('one', 'one'), ('major', 'major'), ('problem', 'problem'), ('natural', 'natur'), ('language', 'languag')]

>> Lemmatization: 
 [('Ambiguity', 'Ambiguity'), ('one', 'one'), ('major', 'major'), ('problem', 'problem'), ('natural', 'natural'), ('language', 'language')]



========================================== PARAGRAPH 80 ===========================================

usually faced in syntactic level which has subtask as lexical and morphology which are  

------------------- Sentence 1 -------------------

usually faced in syntactic level which has subtask as lexical and morphology which are

>> Tokens are: 
 ['usually', 'faced', 'syntactic', 'level', 'subtask', 'lexical', 'morphology']

>> Bigrams are: 
 [('usually', 'faced'), ('faced', 'syntactic'), ('syntactic', 'level'), ('level', 'subtask'), ('subtask', 'lexical'), ('lexical', 'morphology')]

>> Trigrams are: 
 [('usually', 'faced', 'syntactic'), ('faced', 'syntactic', 'level'), ('syntactic', 'level', 'subtask'), ('level', 'subtask', 'lexical'), ('subtask', 'lexical', 'morphology')]

>> POS Tags are: 
 [('usually', 'RB'), ('faced', 'VBN'), ('syntactic', 'JJ'), ('level', 'NN'), ('subtask', 'NN'), ('lexical', 'JJ'), ('morphology', 'NN')]

>> Noun Phrases are: 
 ['syntactic level subtask', 'lexical morphology']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('usually', 'usual'), ('faced', 'face'), ('syntactic', 'syntact'), ('level', 'level'), ('subtask', 'subtask'), ('lexical', 'lexic'), ('morphology', 'morpholog')]

>> Stemming using Snowball Stemmer: 
 [('usually', 'usual'), ('faced', 'face'), ('syntactic', 'syntact'), ('level', 'level'), ('subtask', 'subtask'), ('lexical', 'lexic'), ('morphology', 'morpholog')]

>> Lemmatization: 
 [('usually', 'usually'), ('faced', 'faced'), ('syntactic', 'syntactic'), ('level', 'level'), ('subtask', 'subtask'), ('lexical', 'lexical'), ('morphology', 'morphology')]



========================================== PARAGRAPH 81 ===========================================

concerned with the study of words and word formation. Each of these levels can produce  

------------------- Sentence 1 -------------------

concerned with the study of words and word formation.

>> Tokens are: 
 ['concerned', 'study', 'words', 'word', 'formation', '.']

>> Bigrams are: 
 [('concerned', 'study'), ('study', 'words'), ('words', 'word'), ('word', 'formation'), ('formation', '.')]

>> Trigrams are: 
 [('concerned', 'study', 'words'), ('study', 'words', 'word'), ('words', 'word', 'formation'), ('word', 'formation', '.')]

>> POS Tags are: 
 [('concerned', 'VBN'), ('study', 'NN'), ('words', 'NNS'), ('word', 'NN'), ('formation', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['study words word formation']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('concerned', 'concern'), ('study', 'studi'), ('words', 'word'), ('word', 'word'), ('formation', 'format'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('concerned', 'concern'), ('study', 'studi'), ('words', 'word'), ('word', 'word'), ('formation', 'format'), ('.', '.')]

>> Lemmatization: 
 [('concerned', 'concerned'), ('study', 'study'), ('words', 'word'), ('word', 'word'), ('formation', 'formation'), ('.', '.')]


------------------- Sentence 2 -------------------

Each of these levels can produce

>> Tokens are: 
 ['Each', 'levels', 'produce']

>> Bigrams are: 
 [('Each', 'levels'), ('levels', 'produce')]

>> Trigrams are: 
 [('Each', 'levels', 'produce')]

>> POS Tags are: 
 [('Each', 'DT'), ('levels', 'NNS'), ('produce', 'VBP')]

>> Noun Phrases are: 
 ['Each levels']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Each', 'each'), ('levels', 'level'), ('produce', 'produc')]

>> Stemming using Snowball Stemmer: 
 [('Each', 'each'), ('levels', 'level'), ('produce', 'produc')]

>> Lemmatization: 
 [('Each', 'Each'), ('levels', 'level'), ('produce', 'produce')]



========================================== PARAGRAPH 82 ===========================================

ambiguities that can be solved by the knowledge of the complete sentence. The ambiguity  

------------------- Sentence 1 -------------------

ambiguities that can be solved by the knowledge of the complete sentence.

>> Tokens are: 
 ['ambiguities', 'solved', 'knowledge', 'complete', 'sentence', '.']

>> Bigrams are: 
 [('ambiguities', 'solved'), ('solved', 'knowledge'), ('knowledge', 'complete'), ('complete', 'sentence'), ('sentence', '.')]

>> Trigrams are: 
 [('ambiguities', 'solved', 'knowledge'), ('solved', 'knowledge', 'complete'), ('knowledge', 'complete', 'sentence'), ('complete', 'sentence', '.')]

>> POS Tags are: 
 [('ambiguities', 'NNS'), ('solved', 'VBD'), ('knowledge', 'NN'), ('complete', 'JJ'), ('sentence', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['ambiguities', 'knowledge', 'complete sentence']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('ambiguities', 'ambigu'), ('solved', 'solv'), ('knowledge', 'knowledg'), ('complete', 'complet'), ('sentence', 'sentenc'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('ambiguities', 'ambigu'), ('solved', 'solv'), ('knowledge', 'knowledg'), ('complete', 'complet'), ('sentence', 'sentenc'), ('.', '.')]

>> Lemmatization: 
 [('ambiguities', 'ambiguity'), ('solved', 'solved'), ('knowledge', 'knowledge'), ('complete', 'complete'), ('sentence', 'sentence'), ('.', '.')]


------------------- Sentence 2 -------------------

The ambiguity

>> Tokens are: 
 ['The', 'ambiguity']

>> Bigrams are: 
 [('The', 'ambiguity')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('The', 'DT'), ('ambiguity', 'NN')]

>> Noun Phrases are: 
 ['The ambiguity']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('ambiguity', 'ambigu')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('ambiguity', 'ambigu')]

>> Lemmatization: 
 [('The', 'The'), ('ambiguity', 'ambiguity')]



========================================== PARAGRAPH 83 ===========================================

can be solved by various methods such as Minimising Ambiguity, Preserving Ambiguity,  

------------------- Sentence 1 -------------------

can be solved by various methods such as Minimising Ambiguity, Preserving Ambiguity,

>> Tokens are: 
 ['solved', 'various', 'methods', 'Minimising', 'Ambiguity', ',', 'Preserving', 'Ambiguity', ',']

>> Bigrams are: 
 [('solved', 'various'), ('various', 'methods'), ('methods', 'Minimising'), ('Minimising', 'Ambiguity'), ('Ambiguity', ','), (',', 'Preserving'), ('Preserving', 'Ambiguity'), ('Ambiguity', ',')]

>> Trigrams are: 
 [('solved', 'various', 'methods'), ('various', 'methods', 'Minimising'), ('methods', 'Minimising', 'Ambiguity'), ('Minimising', 'Ambiguity', ','), ('Ambiguity', ',', 'Preserving'), (',', 'Preserving', 'Ambiguity'), ('Preserving', 'Ambiguity', ',')]

>> POS Tags are: 
 [('solved', 'VBN'), ('various', 'JJ'), ('methods', 'NNS'), ('Minimising', 'VBG'), ('Ambiguity', 'NNP'), (',', ','), ('Preserving', 'NNP'), ('Ambiguity', 'NNP'), (',', ',')]

>> Noun Phrases are: 
 ['various methods', 'Ambiguity', 'Preserving Ambiguity']

>> Named Entities are: 
 [('ORGANIZATION', 'Ambiguity')] 

>> Stemming using Porter Stemmer: 
 [('solved', 'solv'), ('various', 'variou'), ('methods', 'method'), ('Minimising', 'minimis'), ('Ambiguity', 'ambigu'), (',', ','), ('Preserving', 'preserv'), ('Ambiguity', 'ambigu'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('solved', 'solv'), ('various', 'various'), ('methods', 'method'), ('Minimising', 'minimis'), ('Ambiguity', 'ambigu'), (',', ','), ('Preserving', 'preserv'), ('Ambiguity', 'ambigu'), (',', ',')]

>> Lemmatization: 
 [('solved', 'solved'), ('various', 'various'), ('methods', 'method'), ('Minimising', 'Minimising'), ('Ambiguity', 'Ambiguity'), (',', ','), ('Preserving', 'Preserving'), ('Ambiguity', 'Ambiguity'), (',', ',')]



========================================== PARAGRAPH 84 ===========================================

Interactive Disambiguity and Weighting Ambiguity [3]. Some of the methods proposed by  

------------------- Sentence 1 -------------------

Interactive Disambiguity and Weighting Ambiguity [3].

>> Tokens are: 
 ['Interactive', 'Disambiguity', 'Weighting', 'Ambiguity', '[', '3', ']', '.']

>> Bigrams are: 
 [('Interactive', 'Disambiguity'), ('Disambiguity', 'Weighting'), ('Weighting', 'Ambiguity'), ('Ambiguity', '['), ('[', '3'), ('3', ']'), (']', '.')]

>> Trigrams are: 
 [('Interactive', 'Disambiguity', 'Weighting'), ('Disambiguity', 'Weighting', 'Ambiguity'), ('Weighting', 'Ambiguity', '['), ('Ambiguity', '[', '3'), ('[', '3', ']'), ('3', ']', '.')]

>> POS Tags are: 
 [('Interactive', 'JJ'), ('Disambiguity', 'NNP'), ('Weighting', 'NNP'), ('Ambiguity', 'NNP'), ('[', 'NNP'), ('3', 'CD'), (']', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Interactive Disambiguity Weighting Ambiguity [', ']']

>> Named Entities are: 
 [('ORGANIZATION', 'Disambiguity')] 

>> Stemming using Porter Stemmer: 
 [('Interactive', 'interact'), ('Disambiguity', 'disambigu'), ('Weighting', 'weight'), ('Ambiguity', 'ambigu'), ('[', '['), ('3', '3'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Interactive', 'interact'), ('Disambiguity', 'disambigu'), ('Weighting', 'weight'), ('Ambiguity', 'ambigu'), ('[', '['), ('3', '3'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('Interactive', 'Interactive'), ('Disambiguity', 'Disambiguity'), ('Weighting', 'Weighting'), ('Ambiguity', 'Ambiguity'), ('[', '['), ('3', '3'), (']', ']'), ('.', '.')]


------------------- Sentence 2 -------------------

Some of the methods proposed by

>> Tokens are: 
 ['Some', 'methods', 'proposed']

>> Bigrams are: 
 [('Some', 'methods'), ('methods', 'proposed')]

>> Trigrams are: 
 [('Some', 'methods', 'proposed')]

>> POS Tags are: 
 [('Some', 'DT'), ('methods', 'NNS'), ('proposed', 'VBD')]

>> Noun Phrases are: 
 ['Some methods']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Some', 'some'), ('methods', 'method'), ('proposed', 'propos')]

>> Stemming using Snowball Stemmer: 
 [('Some', 'some'), ('methods', 'method'), ('proposed', 'propos')]

>> Lemmatization: 
 [('Some', 'Some'), ('methods', 'method'), ('proposed', 'proposed')]



========================================== PARAGRAPH 85 ===========================================

researchers to remove ambiguity is preserving ambiguity, e.g.- (Shemtov 1997; Emele &  

------------------- Sentence 1 -------------------

researchers to remove ambiguity is preserving ambiguity, e.g.- (Shemtov 1997; Emele &

>> Tokens are: 
 ['researchers', 'remove', 'ambiguity', 'preserving', 'ambiguity', ',', 'e.g.-', '(', 'Shemtov', '1997', ';', 'Emele', '&']

>> Bigrams are: 
 [('researchers', 'remove'), ('remove', 'ambiguity'), ('ambiguity', 'preserving'), ('preserving', 'ambiguity'), ('ambiguity', ','), (',', 'e.g.-'), ('e.g.-', '('), ('(', 'Shemtov'), ('Shemtov', '1997'), ('1997', ';'), (';', 'Emele'), ('Emele', '&')]

>> Trigrams are: 
 [('researchers', 'remove', 'ambiguity'), ('remove', 'ambiguity', 'preserving'), ('ambiguity', 'preserving', 'ambiguity'), ('preserving', 'ambiguity', ','), ('ambiguity', ',', 'e.g.-'), (',', 'e.g.-', '('), ('e.g.-', '(', 'Shemtov'), ('(', 'Shemtov', '1997'), ('Shemtov', '1997', ';'), ('1997', ';', 'Emele'), (';', 'Emele', '&')]

>> POS Tags are: 
 [('researchers', 'NNS'), ('remove', 'VBP'), ('ambiguity', 'NN'), ('preserving', 'NN'), ('ambiguity', 'NN'), (',', ','), ('e.g.-', 'JJ'), ('(', '('), ('Shemtov', 'JJ'), ('1997', 'CD'), (';', ':'), ('Emele', 'NNP'), ('&', 'CC')]

>> Noun Phrases are: 
 ['researchers', 'ambiguity preserving ambiguity', 'Emele']

>> Named Entities are: 
 [('ORGANIZATION', 'Shemtov'), ('PERSON', 'Emele')] 

>> Stemming using Porter Stemmer: 
 [('researchers', 'research'), ('remove', 'remov'), ('ambiguity', 'ambigu'), ('preserving', 'preserv'), ('ambiguity', 'ambigu'), (',', ','), ('e.g.-', 'e.g.-'), ('(', '('), ('Shemtov', 'shemtov'), ('1997', '1997'), (';', ';'), ('Emele', 'emel'), ('&', '&')]

>> Stemming using Snowball Stemmer: 
 [('researchers', 'research'), ('remove', 'remov'), ('ambiguity', 'ambigu'), ('preserving', 'preserv'), ('ambiguity', 'ambigu'), (',', ','), ('e.g.-', 'e.g.-'), ('(', '('), ('Shemtov', 'shemtov'), ('1997', '1997'), (';', ';'), ('Emele', 'emel'), ('&', '&')]

>> Lemmatization: 
 [('researchers', 'researcher'), ('remove', 'remove'), ('ambiguity', 'ambiguity'), ('preserving', 'preserving'), ('ambiguity', 'ambiguity'), (',', ','), ('e.g.-', 'e.g.-'), ('(', '('), ('Shemtov', 'Shemtov'), ('1997', '1997'), (';', ';'), ('Emele', 'Emele'), ('&', '&')]



========================================== PARAGRAPH 86 ===========================================

Dorna 1998; Knight & Langkilde 2000) [3][4][5] Their objectives are closely in line with the  

------------------- Sentence 1 -------------------

Dorna 1998; Knight & Langkilde 2000) [3][4][5] Their objectives are closely in line with the

>> Tokens are: 
 ['Dorna', '1998', ';', 'Knight', '&', 'Langkilde', '2000', ')', '[', '3', ']', '[', '4', ']', '[', '5', ']', 'Their', 'objectives', 'closely', 'line']

>> Bigrams are: 
 [('Dorna', '1998'), ('1998', ';'), (';', 'Knight'), ('Knight', '&'), ('&', 'Langkilde'), ('Langkilde', '2000'), ('2000', ')'), (')', '['), ('[', '3'), ('3', ']'), (']', '['), ('[', '4'), ('4', ']'), (']', '['), ('[', '5'), ('5', ']'), (']', 'Their'), ('Their', 'objectives'), ('objectives', 'closely'), ('closely', 'line')]

>> Trigrams are: 
 [('Dorna', '1998', ';'), ('1998', ';', 'Knight'), (';', 'Knight', '&'), ('Knight', '&', 'Langkilde'), ('&', 'Langkilde', '2000'), ('Langkilde', '2000', ')'), ('2000', ')', '['), (')', '[', '3'), ('[', '3', ']'), ('3', ']', '['), (']', '[', '4'), ('[', '4', ']'), ('4', ']', '['), (']', '[', '5'), ('[', '5', ']'), ('5', ']', 'Their'), (']', 'Their', 'objectives'), ('Their', 'objectives', 'closely'), ('objectives', 'closely', 'line')]

>> POS Tags are: 
 [('Dorna', 'NNP'), ('1998', 'CD'), (';', ':'), ('Knight', 'NNP'), ('&', 'CC'), ('Langkilde', 'NNP'), ('2000', 'CD'), (')', ')'), ('[', 'VBD'), ('3', 'CD'), (']', 'NNP'), ('[', 'VBD'), ('4', 'CD'), (']', 'NNP'), ('[', 'VBD'), ('5', 'CD'), (']', 'NNP'), ('Their', 'NNP'), ('objectives', 'NNS'), ('closely', 'RB'), ('line', 'NN')]

>> Noun Phrases are: 
 ['Dorna', 'Knight', 'Langkilde', ']', ']', '] Their objectives', 'line']

>> Named Entities are: 
 [('PERSON', 'Knight')] 

>> Stemming using Porter Stemmer: 
 [('Dorna', 'dorna'), ('1998', '1998'), (';', ';'), ('Knight', 'knight'), ('&', '&'), ('Langkilde', 'langkild'), ('2000', '2000'), (')', ')'), ('[', '['), ('3', '3'), (']', ']'), ('[', '['), ('4', '4'), (']', ']'), ('[', '['), ('5', '5'), (']', ']'), ('Their', 'their'), ('objectives', 'object'), ('closely', 'close'), ('line', 'line')]

>> Stemming using Snowball Stemmer: 
 [('Dorna', 'dorna'), ('1998', '1998'), (';', ';'), ('Knight', 'knight'), ('&', '&'), ('Langkilde', 'langkild'), ('2000', '2000'), (')', ')'), ('[', '['), ('3', '3'), (']', ']'), ('[', '['), ('4', '4'), (']', ']'), ('[', '['), ('5', '5'), (']', ']'), ('Their', 'their'), ('objectives', 'object'), ('closely', 'close'), ('line', 'line')]

>> Lemmatization: 
 [('Dorna', 'Dorna'), ('1998', '1998'), (';', ';'), ('Knight', 'Knight'), ('&', '&'), ('Langkilde', 'Langkilde'), ('2000', '2000'), (')', ')'), ('[', '['), ('3', '3'), (']', ']'), ('[', '['), ('4', '4'), (']', ']'), ('[', '['), ('5', '5'), (']', ']'), ('Their', 'Their'), ('objectives', 'objective'), ('closely', 'closely'), ('line', 'line')]



========================================== PARAGRAPH 87 ===========================================

last of these: they cover a wide range of ambiguities and there is a statistical element implicit  

------------------- Sentence 1 -------------------

last of these: they cover a wide range of ambiguities and there is a statistical element implicit

>> Tokens are: 
 ['last', ':', 'cover', 'wide', 'range', 'ambiguities', 'statistical', 'element', 'implicit']

>> Bigrams are: 
 [('last', ':'), (':', 'cover'), ('cover', 'wide'), ('wide', 'range'), ('range', 'ambiguities'), ('ambiguities', 'statistical'), ('statistical', 'element'), ('element', 'implicit')]

>> Trigrams are: 
 [('last', ':', 'cover'), (':', 'cover', 'wide'), ('cover', 'wide', 'range'), ('wide', 'range', 'ambiguities'), ('range', 'ambiguities', 'statistical'), ('ambiguities', 'statistical', 'element'), ('statistical', 'element', 'implicit')]

>> POS Tags are: 
 [('last', 'JJ'), (':', ':'), ('cover', 'NN'), ('wide', 'JJ'), ('range', 'NN'), ('ambiguities', 'NNS'), ('statistical', 'JJ'), ('element', 'NN'), ('implicit', 'NN')]

>> Noun Phrases are: 
 ['cover', 'wide range ambiguities', 'statistical element implicit']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('last', 'last'), (':', ':'), ('cover', 'cover'), ('wide', 'wide'), ('range', 'rang'), ('ambiguities', 'ambigu'), ('statistical', 'statist'), ('element', 'element'), ('implicit', 'implicit')]

>> Stemming using Snowball Stemmer: 
 [('last', 'last'), (':', ':'), ('cover', 'cover'), ('wide', 'wide'), ('range', 'rang'), ('ambiguities', 'ambigu'), ('statistical', 'statist'), ('element', 'element'), ('implicit', 'implicit')]

>> Lemmatization: 
 [('last', 'last'), (':', ':'), ('cover', 'cover'), ('wide', 'wide'), ('range', 'range'), ('ambiguities', 'ambiguity'), ('statistical', 'statistical'), ('element', 'element'), ('implicit', 'implicit')]



========================================== PARAGRAPH 88 ===========================================

in their approach.   

------------------- Sentence 1 -------------------

in their approach.

>> Tokens are: 
 ['approach', '.']

>> Bigrams are: 
 [('approach', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('approach', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['approach']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('approach', 'approach'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('approach', 'approach'), ('.', '.')]

>> Lemmatization: 
 [('approach', 'approach'), ('.', '.')]



========================================== PARAGRAPH 89 ===========================================

2. Levels of NLP  

------------------- Sentence 1 -------------------

2.

>> Tokens are: 
 ['2', '.']

>> Bigrams are: 
 [('2', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('2', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('2', '2'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('2', '2'), ('.', '.')]

>> Lemmatization: 
 [('2', '2'), ('.', '.')]


------------------- Sentence 2 -------------------

Levels of NLP

>> Tokens are: 
 ['Levels', 'NLP']

>> Bigrams are: 
 [('Levels', 'NLP')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Levels', 'NNS'), ('NLP', 'NNP')]

>> Noun Phrases are: 
 ['Levels NLP']

>> Named Entities are: 
 [('ORGANIZATION', 'NLP')] 

>> Stemming using Porter Stemmer: 
 [('Levels', 'level'), ('NLP', 'nlp')]

>> Stemming using Snowball Stemmer: 
 [('Levels', 'level'), ('NLP', 'nlp')]

>> Lemmatization: 
 [('Levels', 'Levels'), ('NLP', 'NLP')]



========================================== PARAGRAPH 90 ===========================================

The ‘levels of language’ are one of the most explanatory method for representing the Natural  

------------------- Sentence 1 -------------------

The ‘levels of language’ are one of the most explanatory method for representing the Natural

>> Tokens are: 
 ['The', '‘', 'levels', 'language', '’', 'one', 'explanatory', 'method', 'representing', 'Natural']

>> Bigrams are: 
 [('The', '‘'), ('‘', 'levels'), ('levels', 'language'), ('language', '’'), ('’', 'one'), ('one', 'explanatory'), ('explanatory', 'method'), ('method', 'representing'), ('representing', 'Natural')]

>> Trigrams are: 
 [('The', '‘', 'levels'), ('‘', 'levels', 'language'), ('levels', 'language', '’'), ('language', '’', 'one'), ('’', 'one', 'explanatory'), ('one', 'explanatory', 'method'), ('explanatory', 'method', 'representing'), ('method', 'representing', 'Natural')]

>> POS Tags are: 
 [('The', 'DT'), ('‘', 'NN'), ('levels', 'NNS'), ('language', 'NN'), ('’', 'VBP'), ('one', 'CD'), ('explanatory', 'NN'), ('method', 'NN'), ('representing', 'VBG'), ('Natural', 'NNP')]

>> Noun Phrases are: 
 ['The ‘ levels language', 'explanatory method', 'Natural']

>> Named Entities are: 
 [('ORGANIZATION', 'Natural')] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('‘', '‘'), ('levels', 'level'), ('language', 'languag'), ('’', '’'), ('one', 'one'), ('explanatory', 'explanatori'), ('method', 'method'), ('representing', 'repres'), ('Natural', 'natur')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('‘', '‘'), ('levels', 'level'), ('language', 'languag'), ('’', '’'), ('one', 'one'), ('explanatory', 'explanatori'), ('method', 'method'), ('representing', 'repres'), ('Natural', 'natur')]

>> Lemmatization: 
 [('The', 'The'), ('‘', '‘'), ('levels', 'level'), ('language', 'language'), ('’', '’'), ('one', 'one'), ('explanatory', 'explanatory'), ('method', 'method'), ('representing', 'representing'), ('Natural', 'Natural')]



========================================== PARAGRAPH 91 ===========================================

Language processing which helps to generate the NLP text by realising Content Planning,  

------------------- Sentence 1 -------------------

Language processing which helps to generate the NLP text by realising Content Planning,

>> Tokens are: 
 ['Language', 'processing', 'helps', 'generate', 'NLP', 'text', 'realising', 'Content', 'Planning', ',']

>> Bigrams are: 
 [('Language', 'processing'), ('processing', 'helps'), ('helps', 'generate'), ('generate', 'NLP'), ('NLP', 'text'), ('text', 'realising'), ('realising', 'Content'), ('Content', 'Planning'), ('Planning', ',')]

>> Trigrams are: 
 [('Language', 'processing', 'helps'), ('processing', 'helps', 'generate'), ('helps', 'generate', 'NLP'), ('generate', 'NLP', 'text'), ('NLP', 'text', 'realising'), ('text', 'realising', 'Content'), ('realising', 'Content', 'Planning'), ('Content', 'Planning', ',')]

>> POS Tags are: 
 [('Language', 'NN'), ('processing', 'NN'), ('helps', 'VBZ'), ('generate', 'VB'), ('NLP', 'NNP'), ('text', 'IN'), ('realising', 'VBG'), ('Content', 'NNP'), ('Planning', 'NNP'), (',', ',')]

>> Noun Phrases are: 
 ['Language processing', 'NLP', 'Content Planning']

>> Named Entities are: 
 [('GPE', 'Language'), ('ORGANIZATION', 'NLP'), ('ORGANIZATION', 'Content Planning')] 

>> Stemming using Porter Stemmer: 
 [('Language', 'languag'), ('processing', 'process'), ('helps', 'help'), ('generate', 'gener'), ('NLP', 'nlp'), ('text', 'text'), ('realising', 'realis'), ('Content', 'content'), ('Planning', 'plan'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('Language', 'languag'), ('processing', 'process'), ('helps', 'help'), ('generate', 'generat'), ('NLP', 'nlp'), ('text', 'text'), ('realising', 'realis'), ('Content', 'content'), ('Planning', 'plan'), (',', ',')]

>> Lemmatization: 
 [('Language', 'Language'), ('processing', 'processing'), ('helps', 'help'), ('generate', 'generate'), ('NLP', 'NLP'), ('text', 'text'), ('realising', 'realising'), ('Content', 'Content'), ('Planning', 'Planning'), (',', ',')]



========================================== PARAGRAPH 92 ===========================================

Sentence Planning and Surface Realization phases (Figure 2).  

------------------- Sentence 1 -------------------

Sentence Planning and Surface Realization phases (Figure 2).

>> Tokens are: 
 ['Sentence', 'Planning', 'Surface', 'Realization', 'phases', '(', 'Figure', '2', ')', '.']

>> Bigrams are: 
 [('Sentence', 'Planning'), ('Planning', 'Surface'), ('Surface', 'Realization'), ('Realization', 'phases'), ('phases', '('), ('(', 'Figure'), ('Figure', '2'), ('2', ')'), (')', '.')]

>> Trigrams are: 
 [('Sentence', 'Planning', 'Surface'), ('Planning', 'Surface', 'Realization'), ('Surface', 'Realization', 'phases'), ('Realization', 'phases', '('), ('phases', '(', 'Figure'), ('(', 'Figure', '2'), ('Figure', '2', ')'), ('2', ')', '.')]

>> POS Tags are: 
 [('Sentence', 'NN'), ('Planning', 'VBG'), ('Surface', 'NNP'), ('Realization', 'NNP'), ('phases', 'NNS'), ('(', '('), ('Figure', 'NNP'), ('2', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['Sentence', 'Surface Realization phases', 'Figure']

>> Named Entities are: 
 [('GPE', 'Sentence'), ('PERSON', 'Surface Realization')] 

>> Stemming using Porter Stemmer: 
 [('Sentence', 'sentenc'), ('Planning', 'plan'), ('Surface', 'surfac'), ('Realization', 'realiz'), ('phases', 'phase'), ('(', '('), ('Figure', 'figur'), ('2', '2'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Sentence', 'sentenc'), ('Planning', 'plan'), ('Surface', 'surfac'), ('Realization', 'realize'), ('phases', 'phase'), ('(', '('), ('Figure', 'figur'), ('2', '2'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Sentence', 'Sentence'), ('Planning', 'Planning'), ('Surface', 'Surface'), ('Realization', 'Realization'), ('phases', 'phase'), ('(', '('), ('Figure', 'Figure'), ('2', '2'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 93 ===========================================

  


========================================== PARAGRAPH 94 ===========================================

                                      Figure 2. Phases of NLP architecture  

------------------- Sentence 1 -------------------

                                      Figure 2.

>> Tokens are: 
 ['Figure', '2', '.']

>> Bigrams are: 
 [('Figure', '2'), ('2', '.')]

>> Trigrams are: 
 [('Figure', '2', '.')]

>> POS Tags are: 
 [('Figure', 'NN'), ('2', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Figure']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Figure', 'figur'), ('2', '2'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Figure', 'figur'), ('2', '2'), ('.', '.')]

>> Lemmatization: 
 [('Figure', 'Figure'), ('2', '2'), ('.', '.')]


------------------- Sentence 2 -------------------

Phases of NLP architecture

>> Tokens are: 
 ['Phases', 'NLP', 'architecture']

>> Bigrams are: 
 [('Phases', 'NLP'), ('NLP', 'architecture')]

>> Trigrams are: 
 [('Phases', 'NLP', 'architecture')]

>> POS Tags are: 
 [('Phases', 'NNS'), ('NLP', 'NNP'), ('architecture', 'NN')]

>> Noun Phrases are: 
 ['Phases NLP architecture']

>> Named Entities are: 
 [('ORGANIZATION', 'NLP')] 

>> Stemming using Porter Stemmer: 
 [('Phases', 'phase'), ('NLP', 'nlp'), ('architecture', 'architectur')]

>> Stemming using Snowball Stemmer: 
 [('Phases', 'phase'), ('NLP', 'nlp'), ('architecture', 'architectur')]

>> Lemmatization: 
 [('Phases', 'Phases'), ('NLP', 'NLP'), ('architecture', 'architecture')]



========================================== PARAGRAPH 95 ===========================================

Linguistic is the science which involves meaning of language, language context and various  

------------------- Sentence 1 -------------------

Linguistic is the science which involves meaning of language, language context and various

>> Tokens are: 
 ['Linguistic', 'science', 'involves', 'meaning', 'language', ',', 'language', 'context', 'various']

>> Bigrams are: 
 [('Linguistic', 'science'), ('science', 'involves'), ('involves', 'meaning'), ('meaning', 'language'), ('language', ','), (',', 'language'), ('language', 'context'), ('context', 'various')]

>> Trigrams are: 
 [('Linguistic', 'science', 'involves'), ('science', 'involves', 'meaning'), ('involves', 'meaning', 'language'), ('meaning', 'language', ','), ('language', ',', 'language'), (',', 'language', 'context'), ('language', 'context', 'various')]

>> POS Tags are: 
 [('Linguistic', 'JJ'), ('science', 'NN'), ('involves', 'VBZ'), ('meaning', 'VBG'), ('language', 'NN'), (',', ','), ('language', 'NN'), ('context', 'NN'), ('various', 'JJ')]

>> Noun Phrases are: 
 ['Linguistic science', 'language', 'language context']

>> Named Entities are: 
 [('GPE', 'Linguistic')] 

>> Stemming using Porter Stemmer: 
 [('Linguistic', 'linguist'), ('science', 'scienc'), ('involves', 'involv'), ('meaning', 'mean'), ('language', 'languag'), (',', ','), ('language', 'languag'), ('context', 'context'), ('various', 'variou')]

>> Stemming using Snowball Stemmer: 
 [('Linguistic', 'linguist'), ('science', 'scienc'), ('involves', 'involv'), ('meaning', 'mean'), ('language', 'languag'), (',', ','), ('language', 'languag'), ('context', 'context'), ('various', 'various')]

>> Lemmatization: 
 [('Linguistic', 'Linguistic'), ('science', 'science'), ('involves', 'involves'), ('meaning', 'meaning'), ('language', 'language'), (',', ','), ('language', 'language'), ('context', 'context'), ('various', 'various')]



========================================== PARAGRAPH 96 ===========================================

forms of the language. The various important terminologies of Natural Language Processing  

------------------- Sentence 1 -------------------

forms of the language.

>> Tokens are: 
 ['forms', 'language', '.']

>> Bigrams are: 
 [('forms', 'language'), ('language', '.')]

>> Trigrams are: 
 [('forms', 'language', '.')]

>> POS Tags are: 
 [('forms', 'NNS'), ('language', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['forms language']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('forms', 'form'), ('language', 'languag'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('forms', 'form'), ('language', 'languag'), ('.', '.')]

>> Lemmatization: 
 [('forms', 'form'), ('language', 'language'), ('.', '.')]


------------------- Sentence 2 -------------------

The various important terminologies of Natural Language Processing

>> Tokens are: 
 ['The', 'various', 'important', 'terminologies', 'Natural', 'Language', 'Processing']

>> Bigrams are: 
 [('The', 'various'), ('various', 'important'), ('important', 'terminologies'), ('terminologies', 'Natural'), ('Natural', 'Language'), ('Language', 'Processing')]

>> Trigrams are: 
 [('The', 'various', 'important'), ('various', 'important', 'terminologies'), ('important', 'terminologies', 'Natural'), ('terminologies', 'Natural', 'Language'), ('Natural', 'Language', 'Processing')]

>> POS Tags are: 
 [('The', 'DT'), ('various', 'JJ'), ('important', 'JJ'), ('terminologies', 'NNS'), ('Natural', 'NNP'), ('Language', 'NNP'), ('Processing', 'NNP')]

>> Noun Phrases are: 
 ['The various important terminologies Natural Language Processing']

>> Named Entities are: 
 [('ORGANIZATION', 'Natural Language')] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('various', 'variou'), ('important', 'import'), ('terminologies', 'terminolog'), ('Natural', 'natur'), ('Language', 'languag'), ('Processing', 'process')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('various', 'various'), ('important', 'import'), ('terminologies', 'terminolog'), ('Natural', 'natur'), ('Language', 'languag'), ('Processing', 'process')]

>> Lemmatization: 
 [('The', 'The'), ('various', 'various'), ('important', 'important'), ('terminologies', 'terminology'), ('Natural', 'Natural'), ('Language', 'Language'), ('Processing', 'Processing')]



========================================== PARAGRAPH 97 ===========================================

are: -  

------------------- Sentence 1 -------------------

are: -

>> Tokens are: 
 [':', '-']

>> Bigrams are: 
 [(':', '-')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [(':', ':'), ('-', ':')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [(':', ':'), ('-', '-')]

>> Stemming using Snowball Stemmer: 
 [(':', ':'), ('-', '-')]

>> Lemmatization: 
 [(':', ':'), ('-', '-')]



========================================== PARAGRAPH 98 ===========================================

1. Phonology  

------------------- Sentence 1 -------------------

1.

>> Tokens are: 
 ['1', '.']

>> Bigrams are: 
 [('1', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('1', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('1', '1'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('1', '1'), ('.', '.')]

>> Lemmatization: 
 [('1', '1'), ('.', '.')]


------------------- Sentence 2 -------------------

Phonology

>> Tokens are: 
 ['Phonology']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Phonology', 'NN')]

>> Noun Phrases are: 
 ['Phonology']

>> Named Entities are: 
 [('GPE', 'Phonology')] 

>> Stemming using Porter Stemmer: 
 [('Phonology', 'phonolog')]

>> Stemming using Snowball Stemmer: 
 [('Phonology', 'phonolog')]

>> Lemmatization: 
 [('Phonology', 'Phonology')]



========================================== PARAGRAPH 99 ===========================================

Phonology is the part of Linguistics which refers to the systematic arrangement of sound. The  

------------------- Sentence 1 -------------------

Phonology is the part of Linguistics which refers to the systematic arrangement of sound.

>> Tokens are: 
 ['Phonology', 'part', 'Linguistics', 'refers', 'systematic', 'arrangement', 'sound', '.']

>> Bigrams are: 
 [('Phonology', 'part'), ('part', 'Linguistics'), ('Linguistics', 'refers'), ('refers', 'systematic'), ('systematic', 'arrangement'), ('arrangement', 'sound'), ('sound', '.')]

>> Trigrams are: 
 [('Phonology', 'part', 'Linguistics'), ('part', 'Linguistics', 'refers'), ('Linguistics', 'refers', 'systematic'), ('refers', 'systematic', 'arrangement'), ('systematic', 'arrangement', 'sound'), ('arrangement', 'sound', '.')]

>> POS Tags are: 
 [('Phonology', 'NNP'), ('part', 'NN'), ('Linguistics', 'NNP'), ('refers', 'VBZ'), ('systematic', 'JJ'), ('arrangement', 'NN'), ('sound', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Phonology part Linguistics', 'systematic arrangement sound']

>> Named Entities are: 
 [('GPE', 'Phonology'), ('PERSON', 'Linguistics')] 

>> Stemming using Porter Stemmer: 
 [('Phonology', 'phonolog'), ('part', 'part'), ('Linguistics', 'linguist'), ('refers', 'refer'), ('systematic', 'systemat'), ('arrangement', 'arrang'), ('sound', 'sound'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Phonology', 'phonolog'), ('part', 'part'), ('Linguistics', 'linguist'), ('refers', 'refer'), ('systematic', 'systemat'), ('arrangement', 'arrang'), ('sound', 'sound'), ('.', '.')]

>> Lemmatization: 
 [('Phonology', 'Phonology'), ('part', 'part'), ('Linguistics', 'Linguistics'), ('refers', 'refers'), ('systematic', 'systematic'), ('arrangement', 'arrangement'), ('sound', 'sound'), ('.', '.')]


------------------- Sentence 2 -------------------

The

>> Tokens are: 
 ['The']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('The', 'DT')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the')]

>> Lemmatization: 
 [('The', 'The')]



========================================== PARAGRAPH 100 ===========================================

term phonology comes from Ancient Greek and the term phono- which means voice or  

------------------- Sentence 1 -------------------

term phonology comes from Ancient Greek and the term phono- which means voice or

>> Tokens are: 
 ['term', 'phonology', 'comes', 'Ancient', 'Greek', 'term', 'phono-', 'means', 'voice']

>> Bigrams are: 
 [('term', 'phonology'), ('phonology', 'comes'), ('comes', 'Ancient'), ('Ancient', 'Greek'), ('Greek', 'term'), ('term', 'phono-'), ('phono-', 'means'), ('means', 'voice')]

>> Trigrams are: 
 [('term', 'phonology', 'comes'), ('phonology', 'comes', 'Ancient'), ('comes', 'Ancient', 'Greek'), ('Ancient', 'Greek', 'term'), ('Greek', 'term', 'phono-'), ('term', 'phono-', 'means'), ('phono-', 'means', 'voice')]

>> POS Tags are: 
 [('term', 'NN'), ('phonology', 'NN'), ('comes', 'VBZ'), ('Ancient', 'NNP'), ('Greek', 'JJ'), ('term', 'NN'), ('phono-', 'JJ'), ('means', 'NNS'), ('voice', 'NN')]

>> Noun Phrases are: 
 ['term phonology', 'Ancient', 'Greek term', 'phono- means voice']

>> Named Entities are: 
 [('ORGANIZATION', 'Ancient Greek')] 

>> Stemming using Porter Stemmer: 
 [('term', 'term'), ('phonology', 'phonolog'), ('comes', 'come'), ('Ancient', 'ancient'), ('Greek', 'greek'), ('term', 'term'), ('phono-', 'phono-'), ('means', 'mean'), ('voice', 'voic')]

>> Stemming using Snowball Stemmer: 
 [('term', 'term'), ('phonology', 'phonolog'), ('comes', 'come'), ('Ancient', 'ancient'), ('Greek', 'greek'), ('term', 'term'), ('phono-', 'phono-'), ('means', 'mean'), ('voice', 'voic')]

>> Lemmatization: 
 [('term', 'term'), ('phonology', 'phonology'), ('comes', 'come'), ('Ancient', 'Ancient'), ('Greek', 'Greek'), ('term', 'term'), ('phono-', 'phono-'), ('means', 'mean'), ('voice', 'voice')]



========================================== PARAGRAPH 101 ===========================================

sound, and the suffix –logy refers to word or speech. In 1993 Nikolai Trubetzkoy stated that  

------------------- Sentence 1 -------------------

sound, and the suffix –logy refers to word or speech.

>> Tokens are: 
 ['sound', ',', 'suffix', '–logy', 'refers', 'word', 'speech', '.']

>> Bigrams are: 
 [('sound', ','), (',', 'suffix'), ('suffix', '–logy'), ('–logy', 'refers'), ('refers', 'word'), ('word', 'speech'), ('speech', '.')]

>> Trigrams are: 
 [('sound', ',', 'suffix'), (',', 'suffix', '–logy'), ('suffix', '–logy', 'refers'), ('–logy', 'refers', 'word'), ('refers', 'word', 'speech'), ('word', 'speech', '.')]

>> POS Tags are: 
 [('sound', 'NN'), (',', ','), ('suffix', 'JJ'), ('–logy', 'NN'), ('refers', 'NNS'), ('word', 'NN'), ('speech', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['sound', 'suffix –logy refers word speech']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('sound', 'sound'), (',', ','), ('suffix', 'suffix'), ('–logy', '–logi'), ('refers', 'refer'), ('word', 'word'), ('speech', 'speech'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('sound', 'sound'), (',', ','), ('suffix', 'suffix'), ('–logy', '–logi'), ('refers', 'refer'), ('word', 'word'), ('speech', 'speech'), ('.', '.')]

>> Lemmatization: 
 [('sound', 'sound'), (',', ','), ('suffix', 'suffix'), ('–logy', '–logy'), ('refers', 'refers'), ('word', 'word'), ('speech', 'speech'), ('.', '.')]


------------------- Sentence 2 -------------------

In 1993 Nikolai Trubetzkoy stated that

>> Tokens are: 
 ['In', '1993', 'Nikolai', 'Trubetzkoy', 'stated']

>> Bigrams are: 
 [('In', '1993'), ('1993', 'Nikolai'), ('Nikolai', 'Trubetzkoy'), ('Trubetzkoy', 'stated')]

>> Trigrams are: 
 [('In', '1993', 'Nikolai'), ('1993', 'Nikolai', 'Trubetzkoy'), ('Nikolai', 'Trubetzkoy', 'stated')]

>> POS Tags are: 
 [('In', 'IN'), ('1993', 'CD'), ('Nikolai', 'NNP'), ('Trubetzkoy', 'NNP'), ('stated', 'VBD')]

>> Noun Phrases are: 
 ['Nikolai Trubetzkoy']

>> Named Entities are: 
 [('PERSON', 'Nikolai Trubetzkoy')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('1993', '1993'), ('Nikolai', 'nikolai'), ('Trubetzkoy', 'trubetzkoy'), ('stated', 'state')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('1993', '1993'), ('Nikolai', 'nikolai'), ('Trubetzkoy', 'trubetzkoy'), ('stated', 'state')]

>> Lemmatization: 
 [('In', 'In'), ('1993', '1993'), ('Nikolai', 'Nikolai'), ('Trubetzkoy', 'Trubetzkoy'), ('stated', 'stated')]



========================================== PARAGRAPH 102 ===========================================

Phonology is “the study of sound pertaining to the system of language". Whereas Lass in  

------------------- Sentence 1 -------------------

Phonology is “the study of sound pertaining to the system of language".

>> Tokens are: 
 ['Phonology', '“', 'study', 'sound', 'pertaining', 'system', 'language', "''", '.']

>> Bigrams are: 
 [('Phonology', '“'), ('“', 'study'), ('study', 'sound'), ('sound', 'pertaining'), ('pertaining', 'system'), ('system', 'language'), ('language', "''"), ("''", '.')]

>> Trigrams are: 
 [('Phonology', '“', 'study'), ('“', 'study', 'sound'), ('study', 'sound', 'pertaining'), ('sound', 'pertaining', 'system'), ('pertaining', 'system', 'language'), ('system', 'language', "''"), ('language', "''", '.')]

>> POS Tags are: 
 [('Phonology', 'NNP'), ('“', 'NNP'), ('study', 'NN'), ('sound', 'VBD'), ('pertaining', 'VBG'), ('system', 'NN'), ('language', 'NN'), ("''", "''"), ('.', '.')]

>> Noun Phrases are: 
 ['Phonology “ study', 'system language']

>> Named Entities are: 
 [('PERSON', 'Phonology')] 

>> Stemming using Porter Stemmer: 
 [('Phonology', 'phonolog'), ('“', '“'), ('study', 'studi'), ('sound', 'sound'), ('pertaining', 'pertain'), ('system', 'system'), ('language', 'languag'), ("''", "''"), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Phonology', 'phonolog'), ('“', '“'), ('study', 'studi'), ('sound', 'sound'), ('pertaining', 'pertain'), ('system', 'system'), ('language', 'languag'), ("''", "''"), ('.', '.')]

>> Lemmatization: 
 [('Phonology', 'Phonology'), ('“', '“'), ('study', 'study'), ('sound', 'sound'), ('pertaining', 'pertaining'), ('system', 'system'), ('language', 'language'), ("''", "''"), ('.', '.')]


------------------- Sentence 2 -------------------

Whereas Lass in

>> Tokens are: 
 ['Whereas', 'Lass']

>> Bigrams are: 
 [('Whereas', 'Lass')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Whereas', 'IN'), ('Lass', 'NNP')]

>> Noun Phrases are: 
 ['Lass']

>> Named Entities are: 
 [('ORGANIZATION', 'Lass')] 

>> Stemming using Porter Stemmer: 
 [('Whereas', 'wherea'), ('Lass', 'lass')]

>> Stemming using Snowball Stemmer: 
 [('Whereas', 'wherea'), ('Lass', 'lass')]

>> Lemmatization: 
 [('Whereas', 'Whereas'), ('Lass', 'Lass')]



========================================== PARAGRAPH 103 ===========================================

1998 wrote that phonology refers broadly with the sounds of language, concerned with the to  

------------------- Sentence 1 -------------------

1998 wrote that phonology refers broadly with the sounds of language, concerned with the to

>> Tokens are: 
 ['1998', 'wrote', 'phonology', 'refers', 'broadly', 'sounds', 'language', ',', 'concerned']

>> Bigrams are: 
 [('1998', 'wrote'), ('wrote', 'phonology'), ('phonology', 'refers'), ('refers', 'broadly'), ('broadly', 'sounds'), ('sounds', 'language'), ('language', ','), (',', 'concerned')]

>> Trigrams are: 
 [('1998', 'wrote', 'phonology'), ('wrote', 'phonology', 'refers'), ('phonology', 'refers', 'broadly'), ('refers', 'broadly', 'sounds'), ('broadly', 'sounds', 'language'), ('sounds', 'language', ','), ('language', ',', 'concerned')]

>> POS Tags are: 
 [('1998', 'CD'), ('wrote', 'VBD'), ('phonology', 'NN'), ('refers', 'NNS'), ('broadly', 'RB'), ('sounds', 'VBZ'), ('language', 'NN'), (',', ','), ('concerned', 'JJ')]

>> Noun Phrases are: 
 ['phonology refers', 'language']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('1998', '1998'), ('wrote', 'wrote'), ('phonology', 'phonolog'), ('refers', 'refer'), ('broadly', 'broadli'), ('sounds', 'sound'), ('language', 'languag'), (',', ','), ('concerned', 'concern')]

>> Stemming using Snowball Stemmer: 
 [('1998', '1998'), ('wrote', 'wrote'), ('phonology', 'phonolog'), ('refers', 'refer'), ('broadly', 'broad'), ('sounds', 'sound'), ('language', 'languag'), (',', ','), ('concerned', 'concern')]

>> Lemmatization: 
 [('1998', '1998'), ('wrote', 'wrote'), ('phonology', 'phonology'), ('refers', 'refers'), ('broadly', 'broadly'), ('sounds', 'sound'), ('language', 'language'), (',', ','), ('concerned', 'concerned')]



========================================== PARAGRAPH 104 ===========================================

lathe sub discipline of linguistics, whereas it could be explained as, "phonology proper is  

------------------- Sentence 1 -------------------

lathe sub discipline of linguistics, whereas it could be explained as, "phonology proper is

>> Tokens are: 
 ['lathe', 'sub', 'discipline', 'linguistics', ',', 'whereas', 'could', 'explained', ',', '``', 'phonology', 'proper']

>> Bigrams are: 
 [('lathe', 'sub'), ('sub', 'discipline'), ('discipline', 'linguistics'), ('linguistics', ','), (',', 'whereas'), ('whereas', 'could'), ('could', 'explained'), ('explained', ','), (',', '``'), ('``', 'phonology'), ('phonology', 'proper')]

>> Trigrams are: 
 [('lathe', 'sub', 'discipline'), ('sub', 'discipline', 'linguistics'), ('discipline', 'linguistics', ','), ('linguistics', ',', 'whereas'), (',', 'whereas', 'could'), ('whereas', 'could', 'explained'), ('could', 'explained', ','), ('explained', ',', '``'), (',', '``', 'phonology'), ('``', 'phonology', 'proper')]

>> POS Tags are: 
 [('lathe', 'NN'), ('sub', 'NN'), ('discipline', 'NN'), ('linguistics', 'NNS'), (',', ','), ('whereas', 'NNS'), ('could', 'MD'), ('explained', 'VB'), (',', ','), ('``', '``'), ('phonology', 'NN'), ('proper', 'NN')]

>> Noun Phrases are: 
 ['lathe sub discipline linguistics', 'whereas', 'phonology proper']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('lathe', 'lath'), ('sub', 'sub'), ('discipline', 'disciplin'), ('linguistics', 'linguist'), (',', ','), ('whereas', 'wherea'), ('could', 'could'), ('explained', 'explain'), (',', ','), ('``', '``'), ('phonology', 'phonolog'), ('proper', 'proper')]

>> Stemming using Snowball Stemmer: 
 [('lathe', 'lath'), ('sub', 'sub'), ('discipline', 'disciplin'), ('linguistics', 'linguist'), (',', ','), ('whereas', 'wherea'), ('could', 'could'), ('explained', 'explain'), (',', ','), ('``', '``'), ('phonology', 'phonolog'), ('proper', 'proper')]

>> Lemmatization: 
 [('lathe', 'lathe'), ('sub', 'sub'), ('discipline', 'discipline'), ('linguistics', 'linguistics'), (',', ','), ('whereas', 'whereas'), ('could', 'could'), ('explained', 'explained'), (',', ','), ('``', '``'), ('phonology', 'phonology'), ('proper', 'proper')]



========================================== PARAGRAPH 105 ===========================================

concerned with the function, behaviour and organization of sounds as linguistic items.  

------------------- Sentence 1 -------------------

concerned with the function, behaviour and organization of sounds as linguistic items.

>> Tokens are: 
 ['concerned', 'function', ',', 'behaviour', 'organization', 'sounds', 'linguistic', 'items', '.']

>> Bigrams are: 
 [('concerned', 'function'), ('function', ','), (',', 'behaviour'), ('behaviour', 'organization'), ('organization', 'sounds'), ('sounds', 'linguistic'), ('linguistic', 'items'), ('items', '.')]

>> Trigrams are: 
 [('concerned', 'function', ','), ('function', ',', 'behaviour'), (',', 'behaviour', 'organization'), ('behaviour', 'organization', 'sounds'), ('organization', 'sounds', 'linguistic'), ('sounds', 'linguistic', 'items'), ('linguistic', 'items', '.')]

>> POS Tags are: 
 [('concerned', 'JJ'), ('function', 'NN'), (',', ','), ('behaviour', 'JJ'), ('organization', 'NN'), ('sounds', 'VBZ'), ('linguistic', 'JJ'), ('items', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['concerned function', 'behaviour organization', 'linguistic items']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('concerned', 'concern'), ('function', 'function'), (',', ','), ('behaviour', 'behaviour'), ('organization', 'organ'), ('sounds', 'sound'), ('linguistic', 'linguist'), ('items', 'item'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('concerned', 'concern'), ('function', 'function'), (',', ','), ('behaviour', 'behaviour'), ('organization', 'organ'), ('sounds', 'sound'), ('linguistic', 'linguist'), ('items', 'item'), ('.', '.')]

>> Lemmatization: 
 [('concerned', 'concerned'), ('function', 'function'), (',', ','), ('behaviour', 'behaviour'), ('organization', 'organization'), ('sounds', 'sound'), ('linguistic', 'linguistic'), ('items', 'item'), ('.', '.')]



========================================== PARAGRAPH 106 ===========================================

Phonology include semantic use of sound to encode meaning of any Human language.   

------------------- Sentence 1 -------------------

Phonology include semantic use of sound to encode meaning of any Human language.

>> Tokens are: 
 ['Phonology', 'include', 'semantic', 'use', 'sound', 'encode', 'meaning', 'Human', 'language', '.']

>> Bigrams are: 
 [('Phonology', 'include'), ('include', 'semantic'), ('semantic', 'use'), ('use', 'sound'), ('sound', 'encode'), ('encode', 'meaning'), ('meaning', 'Human'), ('Human', 'language'), ('language', '.')]

>> Trigrams are: 
 [('Phonology', 'include', 'semantic'), ('include', 'semantic', 'use'), ('semantic', 'use', 'sound'), ('use', 'sound', 'encode'), ('sound', 'encode', 'meaning'), ('encode', 'meaning', 'Human'), ('meaning', 'Human', 'language'), ('Human', 'language', '.')]

>> POS Tags are: 
 [('Phonology', 'NNP'), ('include', 'VBP'), ('semantic', 'JJ'), ('use', 'NN'), ('sound', 'JJ'), ('encode', 'NN'), ('meaning', 'VBG'), ('Human', 'NNP'), ('language', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Phonology', 'semantic use', 'sound encode', 'Human language']

>> Named Entities are: 
 [('GPE', 'Phonology'), ('PERSON', 'Human')] 

>> Stemming using Porter Stemmer: 
 [('Phonology', 'phonolog'), ('include', 'includ'), ('semantic', 'semant'), ('use', 'use'), ('sound', 'sound'), ('encode', 'encod'), ('meaning', 'mean'), ('Human', 'human'), ('language', 'languag'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Phonology', 'phonolog'), ('include', 'includ'), ('semantic', 'semant'), ('use', 'use'), ('sound', 'sound'), ('encode', 'encod'), ('meaning', 'mean'), ('Human', 'human'), ('language', 'languag'), ('.', '.')]

>> Lemmatization: 
 [('Phonology', 'Phonology'), ('include', 'include'), ('semantic', 'semantic'), ('use', 'use'), ('sound', 'sound'), ('encode', 'encode'), ('meaning', 'meaning'), ('Human', 'Human'), ('language', 'language'), ('.', '.')]



========================================== PARAGRAPH 107 ===========================================

(Clark et al.,2007) [6].  

------------------- Sentence 1 -------------------

(Clark et al.,2007) [6].

>> Tokens are: 
 ['(', 'Clark', 'et', 'al.,2007', ')', '[', '6', ']', '.']

>> Bigrams are: 
 [('(', 'Clark'), ('Clark', 'et'), ('et', 'al.,2007'), ('al.,2007', ')'), (')', '['), ('[', '6'), ('6', ']'), (']', '.')]

>> Trigrams are: 
 [('(', 'Clark', 'et'), ('Clark', 'et', 'al.,2007'), ('et', 'al.,2007', ')'), ('al.,2007', ')', '['), (')', '[', '6'), ('[', '6', ']'), ('6', ']', '.')]

>> POS Tags are: 
 [('(', '('), ('Clark', 'NNP'), ('et', 'NNP'), ('al.,2007', 'NN'), (')', ')'), ('[', 'VBZ'), ('6', 'CD'), (']', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Clark et al.,2007', ']']

>> Named Entities are: 
 [('PERSON', 'Clark')] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('Clark', 'clark'), ('et', 'et'), ('al.,2007', 'al.,2007'), (')', ')'), ('[', '['), ('6', '6'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('Clark', 'clark'), ('et', 'et'), ('al.,2007', 'al.,2007'), (')', ')'), ('[', '['), ('6', '6'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('(', '('), ('Clark', 'Clark'), ('et', 'et'), ('al.,2007', 'al.,2007'), (')', ')'), ('[', '['), ('6', '6'), (']', ']'), ('.', '.')]



========================================== PARAGRAPH 108 ===========================================

2. Morphology  

------------------- Sentence 1 -------------------

2.

>> Tokens are: 
 ['2', '.']

>> Bigrams are: 
 [('2', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('2', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('2', '2'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('2', '2'), ('.', '.')]

>> Lemmatization: 
 [('2', '2'), ('.', '.')]


------------------- Sentence 2 -------------------

Morphology

>> Tokens are: 
 ['Morphology']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Morphology', 'NN')]

>> Noun Phrases are: 
 ['Morphology']

>> Named Entities are: 
 [('GPE', 'Morphology')] 

>> Stemming using Porter Stemmer: 
 [('Morphology', 'morpholog')]

>> Stemming using Snowball Stemmer: 
 [('Morphology', 'morpholog')]

>> Lemmatization: 
 [('Morphology', 'Morphology')]



========================================== PARAGRAPH 109 ===========================================

The different parts of the word represent the smallest units of meaning known as Morphemes.  

------------------- Sentence 1 -------------------

The different parts of the word represent the smallest units of meaning known as Morphemes.

>> Tokens are: 
 ['The', 'different', 'parts', 'word', 'represent', 'smallest', 'units', 'meaning', 'known', 'Morphemes', '.']

>> Bigrams are: 
 [('The', 'different'), ('different', 'parts'), ('parts', 'word'), ('word', 'represent'), ('represent', 'smallest'), ('smallest', 'units'), ('units', 'meaning'), ('meaning', 'known'), ('known', 'Morphemes'), ('Morphemes', '.')]

>> Trigrams are: 
 [('The', 'different', 'parts'), ('different', 'parts', 'word'), ('parts', 'word', 'represent'), ('word', 'represent', 'smallest'), ('represent', 'smallest', 'units'), ('smallest', 'units', 'meaning'), ('units', 'meaning', 'known'), ('meaning', 'known', 'Morphemes'), ('known', 'Morphemes', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('different', 'JJ'), ('parts', 'NNS'), ('word', 'NN'), ('represent', 'NN'), ('smallest', 'JJS'), ('units', 'NNS'), ('meaning', 'VBG'), ('known', 'VBN'), ('Morphemes', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['The different parts word represent', 'units', 'Morphemes']

>> Named Entities are: 
 [('PERSON', 'Morphemes')] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('different', 'differ'), ('parts', 'part'), ('word', 'word'), ('represent', 'repres'), ('smallest', 'smallest'), ('units', 'unit'), ('meaning', 'mean'), ('known', 'known'), ('Morphemes', 'morphem'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('different', 'differ'), ('parts', 'part'), ('word', 'word'), ('represent', 'repres'), ('smallest', 'smallest'), ('units', 'unit'), ('meaning', 'mean'), ('known', 'known'), ('Morphemes', 'morphem'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('different', 'different'), ('parts', 'part'), ('word', 'word'), ('represent', 'represent'), ('smallest', 'smallest'), ('units', 'unit'), ('meaning', 'meaning'), ('known', 'known'), ('Morphemes', 'Morphemes'), ('.', '.')]



========================================== PARAGRAPH 110 ===========================================

Morphology which comprise of Nature of words, are initiated by morphemes. An example of  

------------------- Sentence 1 -------------------

Morphology which comprise of Nature of words, are initiated by morphemes.

>> Tokens are: 
 ['Morphology', 'comprise', 'Nature', 'words', ',', 'initiated', 'morphemes', '.']

>> Bigrams are: 
 [('Morphology', 'comprise'), ('comprise', 'Nature'), ('Nature', 'words'), ('words', ','), (',', 'initiated'), ('initiated', 'morphemes'), ('morphemes', '.')]

>> Trigrams are: 
 [('Morphology', 'comprise', 'Nature'), ('comprise', 'Nature', 'words'), ('Nature', 'words', ','), ('words', ',', 'initiated'), (',', 'initiated', 'morphemes'), ('initiated', 'morphemes', '.')]

>> POS Tags are: 
 [('Morphology', 'NNP'), ('comprise', 'NN'), ('Nature', 'NN'), ('words', 'NNS'), (',', ','), ('initiated', 'VBN'), ('morphemes', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['Morphology comprise Nature words', 'morphemes']

>> Named Entities are: 
 [('GPE', 'Morphology')] 

>> Stemming using Porter Stemmer: 
 [('Morphology', 'morpholog'), ('comprise', 'compris'), ('Nature', 'natur'), ('words', 'word'), (',', ','), ('initiated', 'initi'), ('morphemes', 'morphem'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Morphology', 'morpholog'), ('comprise', 'compris'), ('Nature', 'natur'), ('words', 'word'), (',', ','), ('initiated', 'initi'), ('morphemes', 'morphem'), ('.', '.')]

>> Lemmatization: 
 [('Morphology', 'Morphology'), ('comprise', 'comprise'), ('Nature', 'Nature'), ('words', 'word'), (',', ','), ('initiated', 'initiated'), ('morphemes', 'morpheme'), ('.', '.')]


------------------- Sentence 2 -------------------

An example of

>> Tokens are: 
 ['An', 'example']

>> Bigrams are: 
 [('An', 'example')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('An', 'DT'), ('example', 'NN')]

>> Noun Phrases are: 
 ['An example']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('An', 'an'), ('example', 'exampl')]

>> Stemming using Snowball Stemmer: 
 [('An', 'an'), ('example', 'exampl')]

>> Lemmatization: 
 [('An', 'An'), ('example', 'example')]



========================================== PARAGRAPH 111 ===========================================

Morpheme could be, the word precancellation can be morphologically scrutinized into three  

------------------- Sentence 1 -------------------

Morpheme could be, the word precancellation can be morphologically scrutinized into three

>> Tokens are: 
 ['Morpheme', 'could', ',', 'word', 'precancellation', 'morphologically', 'scrutinized', 'three']

>> Bigrams are: 
 [('Morpheme', 'could'), ('could', ','), (',', 'word'), ('word', 'precancellation'), ('precancellation', 'morphologically'), ('morphologically', 'scrutinized'), ('scrutinized', 'three')]

>> Trigrams are: 
 [('Morpheme', 'could', ','), ('could', ',', 'word'), (',', 'word', 'precancellation'), ('word', 'precancellation', 'morphologically'), ('precancellation', 'morphologically', 'scrutinized'), ('morphologically', 'scrutinized', 'three')]

>> POS Tags are: 
 [('Morpheme', 'NNP'), ('could', 'MD'), (',', ','), ('word', 'NN'), ('precancellation', 'NN'), ('morphologically', 'RB'), ('scrutinized', 'VBD'), ('three', 'CD')]

>> Noun Phrases are: 
 ['Morpheme', 'word precancellation']

>> Named Entities are: 
 [('GPE', 'Morpheme')] 

>> Stemming using Porter Stemmer: 
 [('Morpheme', 'morphem'), ('could', 'could'), (',', ','), ('word', 'word'), ('precancellation', 'precancel'), ('morphologically', 'morpholog'), ('scrutinized', 'scrutin'), ('three', 'three')]

>> Stemming using Snowball Stemmer: 
 [('Morpheme', 'morphem'), ('could', 'could'), (',', ','), ('word', 'word'), ('precancellation', 'precancel'), ('morphologically', 'morpholog'), ('scrutinized', 'scrutin'), ('three', 'three')]

>> Lemmatization: 
 [('Morpheme', 'Morpheme'), ('could', 'could'), (',', ','), ('word', 'word'), ('precancellation', 'precancellation'), ('morphologically', 'morphologically'), ('scrutinized', 'scrutinized'), ('three', 'three')]



========================================== PARAGRAPH 112 ===========================================

separate morphemes: the prefix pre, the root cancella, and the suffix -tion. The interpretation  

------------------- Sentence 1 -------------------

separate morphemes: the prefix pre, the root cancella, and the suffix -tion.

>> Tokens are: 
 ['separate', 'morphemes', ':', 'prefix', 'pre', ',', 'root', 'cancella', ',', 'suffix', '-tion', '.']

>> Bigrams are: 
 [('separate', 'morphemes'), ('morphemes', ':'), (':', 'prefix'), ('prefix', 'pre'), ('pre', ','), (',', 'root'), ('root', 'cancella'), ('cancella', ','), (',', 'suffix'), ('suffix', '-tion'), ('-tion', '.')]

>> Trigrams are: 
 [('separate', 'morphemes', ':'), ('morphemes', ':', 'prefix'), (':', 'prefix', 'pre'), ('prefix', 'pre', ','), ('pre', ',', 'root'), (',', 'root', 'cancella'), ('root', 'cancella', ','), ('cancella', ',', 'suffix'), (',', 'suffix', '-tion'), ('suffix', '-tion', '.')]

>> POS Tags are: 
 [('separate', 'JJ'), ('morphemes', 'NNS'), (':', ':'), ('prefix', 'NN'), ('pre', 'NN'), (',', ','), ('root', 'NN'), ('cancella', 'NN'), (',', ','), ('suffix', 'JJ'), ('-tion', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['separate morphemes', 'prefix pre', 'root cancella', 'suffix -tion']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('separate', 'separ'), ('morphemes', 'morphem'), (':', ':'), ('prefix', 'prefix'), ('pre', 'pre'), (',', ','), ('root', 'root'), ('cancella', 'cancella'), (',', ','), ('suffix', 'suffix'), ('-tion', '-tion'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('separate', 'separ'), ('morphemes', 'morphem'), (':', ':'), ('prefix', 'prefix'), ('pre', 'pre'), (',', ','), ('root', 'root'), ('cancella', 'cancella'), (',', ','), ('suffix', 'suffix'), ('-tion', '-tion'), ('.', '.')]

>> Lemmatization: 
 [('separate', 'separate'), ('morphemes', 'morpheme'), (':', ':'), ('prefix', 'prefix'), ('pre', 'pre'), (',', ','), ('root', 'root'), ('cancella', 'cancella'), (',', ','), ('suffix', 'suffix'), ('-tion', '-tion'), ('.', '.')]


------------------- Sentence 2 -------------------

The interpretation

>> Tokens are: 
 ['The', 'interpretation']

>> Bigrams are: 
 [('The', 'interpretation')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('The', 'DT'), ('interpretation', 'NN')]

>> Noun Phrases are: 
 ['The interpretation']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('interpretation', 'interpret')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('interpretation', 'interpret')]

>> Lemmatization: 
 [('The', 'The'), ('interpretation', 'interpretation')]



========================================== PARAGRAPH 113 ===========================================

of morpheme stays same across all the words, just to understand the meaning humans can  

------------------- Sentence 1 -------------------

of morpheme stays same across all the words, just to understand the meaning humans can

>> Tokens are: 
 ['morpheme', 'stays', 'across', 'words', ',', 'understand', 'meaning', 'humans']

>> Bigrams are: 
 [('morpheme', 'stays'), ('stays', 'across'), ('across', 'words'), ('words', ','), (',', 'understand'), ('understand', 'meaning'), ('meaning', 'humans')]

>> Trigrams are: 
 [('morpheme', 'stays', 'across'), ('stays', 'across', 'words'), ('across', 'words', ','), ('words', ',', 'understand'), (',', 'understand', 'meaning'), ('understand', 'meaning', 'humans')]

>> POS Tags are: 
 [('morpheme', 'NN'), ('stays', 'VBZ'), ('across', 'IN'), ('words', 'NNS'), (',', ','), ('understand', 'VBP'), ('meaning', 'NN'), ('humans', 'NNS')]

>> Noun Phrases are: 
 ['morpheme', 'words', 'meaning humans']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('morpheme', 'morphem'), ('stays', 'stay'), ('across', 'across'), ('words', 'word'), (',', ','), ('understand', 'understand'), ('meaning', 'mean'), ('humans', 'human')]

>> Stemming using Snowball Stemmer: 
 [('morpheme', 'morphem'), ('stays', 'stay'), ('across', 'across'), ('words', 'word'), (',', ','), ('understand', 'understand'), ('meaning', 'mean'), ('humans', 'human')]

>> Lemmatization: 
 [('morpheme', 'morpheme'), ('stays', 'stay'), ('across', 'across'), ('words', 'word'), (',', ','), ('understand', 'understand'), ('meaning', 'meaning'), ('humans', 'human')]



========================================== PARAGRAPH 114 ===========================================

break any unknown word into morphemes. For example, adding the suffix –ed to a verb,  

------------------- Sentence 1 -------------------

break any unknown word into morphemes.

>> Tokens are: 
 ['break', 'unknown', 'word', 'morphemes', '.']

>> Bigrams are: 
 [('break', 'unknown'), ('unknown', 'word'), ('word', 'morphemes'), ('morphemes', '.')]

>> Trigrams are: 
 [('break', 'unknown', 'word'), ('unknown', 'word', 'morphemes'), ('word', 'morphemes', '.')]

>> POS Tags are: 
 [('break', 'VB'), ('unknown', 'JJ'), ('word', 'NN'), ('morphemes', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['unknown word morphemes']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('break', 'break'), ('unknown', 'unknown'), ('word', 'word'), ('morphemes', 'morphem'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('break', 'break'), ('unknown', 'unknown'), ('word', 'word'), ('morphemes', 'morphem'), ('.', '.')]

>> Lemmatization: 
 [('break', 'break'), ('unknown', 'unknown'), ('word', 'word'), ('morphemes', 'morpheme'), ('.', '.')]


------------------- Sentence 2 -------------------

For example, adding the suffix –ed to a verb,

>> Tokens are: 
 ['For', 'example', ',', 'adding', 'suffix', '–ed', 'verb', ',']

>> Bigrams are: 
 [('For', 'example'), ('example', ','), (',', 'adding'), ('adding', 'suffix'), ('suffix', '–ed'), ('–ed', 'verb'), ('verb', ',')]

>> Trigrams are: 
 [('For', 'example', ','), ('example', ',', 'adding'), (',', 'adding', 'suffix'), ('adding', 'suffix', '–ed'), ('suffix', '–ed', 'verb'), ('–ed', 'verb', ',')]

>> POS Tags are: 
 [('For', 'IN'), ('example', 'NN'), (',', ','), ('adding', 'VBG'), ('suffix', 'JJ'), ('–ed', 'NNP'), ('verb', 'NN'), (',', ',')]

>> Noun Phrases are: 
 ['example', 'suffix –ed verb']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('For', 'for'), ('example', 'exampl'), (',', ','), ('adding', 'ad'), ('suffix', 'suffix'), ('–ed', '–ed'), ('verb', 'verb'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('For', 'for'), ('example', 'exampl'), (',', ','), ('adding', 'ad'), ('suffix', 'suffix'), ('–ed', '–ed'), ('verb', 'verb'), (',', ',')]

>> Lemmatization: 
 [('For', 'For'), ('example', 'example'), (',', ','), ('adding', 'adding'), ('suffix', 'suffix'), ('–ed', '–ed'), ('verb', 'verb'), (',', ',')]



========================================== PARAGRAPH 115 ===========================================

conveys that the action of the verb took place in the past. The words that cannot be divided  

------------------- Sentence 1 -------------------

conveys that the action of the verb took place in the past.

>> Tokens are: 
 ['conveys', 'action', 'verb', 'took', 'place', 'past', '.']

>> Bigrams are: 
 [('conveys', 'action'), ('action', 'verb'), ('verb', 'took'), ('took', 'place'), ('place', 'past'), ('past', '.')]

>> Trigrams are: 
 [('conveys', 'action', 'verb'), ('action', 'verb', 'took'), ('verb', 'took', 'place'), ('took', 'place', 'past'), ('place', 'past', '.')]

>> POS Tags are: 
 [('conveys', 'NNS'), ('action', 'NN'), ('verb', 'NN'), ('took', 'VBD'), ('place', 'NN'), ('past', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['conveys action verb', 'place past']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('conveys', 'convey'), ('action', 'action'), ('verb', 'verb'), ('took', 'took'), ('place', 'place'), ('past', 'past'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('conveys', 'convey'), ('action', 'action'), ('verb', 'verb'), ('took', 'took'), ('place', 'place'), ('past', 'past'), ('.', '.')]

>> Lemmatization: 
 [('conveys', 'conveys'), ('action', 'action'), ('verb', 'verb'), ('took', 'took'), ('place', 'place'), ('past', 'past'), ('.', '.')]


------------------- Sentence 2 -------------------

The words that cannot be divided

>> Tokens are: 
 ['The', 'words', 'divided']

>> Bigrams are: 
 [('The', 'words'), ('words', 'divided')]

>> Trigrams are: 
 [('The', 'words', 'divided')]

>> POS Tags are: 
 [('The', 'DT'), ('words', 'NNS'), ('divided', 'VBD')]

>> Noun Phrases are: 
 ['The words']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('words', 'word'), ('divided', 'divid')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('words', 'word'), ('divided', 'divid')]

>> Lemmatization: 
 [('The', 'The'), ('words', 'word'), ('divided', 'divided')]



========================================== PARAGRAPH 116 ===========================================

and have meaning by themselves are called Lexical morpheme (e.g.-: table, chair) The words  

------------------- Sentence 1 -------------------

and have meaning by themselves are called Lexical morpheme (e.g.-: table, chair) The words

>> Tokens are: 
 ['meaning', 'called', 'Lexical', 'morpheme', '(', 'e.g.-', ':', 'table', ',', 'chair', ')', 'The', 'words']

>> Bigrams are: 
 [('meaning', 'called'), ('called', 'Lexical'), ('Lexical', 'morpheme'), ('morpheme', '('), ('(', 'e.g.-'), ('e.g.-', ':'), (':', 'table'), ('table', ','), (',', 'chair'), ('chair', ')'), (')', 'The'), ('The', 'words')]

>> Trigrams are: 
 [('meaning', 'called', 'Lexical'), ('called', 'Lexical', 'morpheme'), ('Lexical', 'morpheme', '('), ('morpheme', '(', 'e.g.-'), ('(', 'e.g.-', ':'), ('e.g.-', ':', 'table'), (':', 'table', ','), ('table', ',', 'chair'), (',', 'chair', ')'), ('chair', ')', 'The'), (')', 'The', 'words')]

>> POS Tags are: 
 [('meaning', 'NN'), ('called', 'VBN'), ('Lexical', 'JJ'), ('morpheme', 'NN'), ('(', '('), ('e.g.-', 'JJ'), (':', ':'), ('table', 'NN'), (',', ','), ('chair', 'NN'), (')', ')'), ('The', 'DT'), ('words', 'NNS')]

>> Noun Phrases are: 
 ['meaning', 'Lexical morpheme', 'table', 'chair', 'The words']

>> Named Entities are: 
 [('ORGANIZATION', 'Lexical')] 

>> Stemming using Porter Stemmer: 
 [('meaning', 'mean'), ('called', 'call'), ('Lexical', 'lexic'), ('morpheme', 'morphem'), ('(', '('), ('e.g.-', 'e.g.-'), (':', ':'), ('table', 'tabl'), (',', ','), ('chair', 'chair'), (')', ')'), ('The', 'the'), ('words', 'word')]

>> Stemming using Snowball Stemmer: 
 [('meaning', 'mean'), ('called', 'call'), ('Lexical', 'lexic'), ('morpheme', 'morphem'), ('(', '('), ('e.g.-', 'e.g.-'), (':', ':'), ('table', 'tabl'), (',', ','), ('chair', 'chair'), (')', ')'), ('The', 'the'), ('words', 'word')]

>> Lemmatization: 
 [('meaning', 'meaning'), ('called', 'called'), ('Lexical', 'Lexical'), ('morpheme', 'morpheme'), ('(', '('), ('e.g.-', 'e.g.-'), (':', ':'), ('table', 'table'), (',', ','), ('chair', 'chair'), (')', ')'), ('The', 'The'), ('words', 'word')]



========================================== PARAGRAPH 117 ===========================================

(e.g.- -ed, -ing, -est, -ly, -ful) that are combined with the lexical morpheme are known as  

------------------- Sentence 1 -------------------

(e.g.- -ed, -ing, -est, -ly, -ful) that are combined with the lexical morpheme are known as

>> Tokens are: 
 ['(', 'e.g.-', '-ed', ',', '-ing', ',', '-est', ',', '-ly', ',', '-ful', ')', 'combined', 'lexical', 'morpheme', 'known']

>> Bigrams are: 
 [('(', 'e.g.-'), ('e.g.-', '-ed'), ('-ed', ','), (',', '-ing'), ('-ing', ','), (',', '-est'), ('-est', ','), (',', '-ly'), ('-ly', ','), (',', '-ful'), ('-ful', ')'), (')', 'combined'), ('combined', 'lexical'), ('lexical', 'morpheme'), ('morpheme', 'known')]

>> Trigrams are: 
 [('(', 'e.g.-', '-ed'), ('e.g.-', '-ed', ','), ('-ed', ',', '-ing'), (',', '-ing', ','), ('-ing', ',', '-est'), (',', '-est', ','), ('-est', ',', '-ly'), (',', '-ly', ','), ('-ly', ',', '-ful'), (',', '-ful', ')'), ('-ful', ')', 'combined'), (')', 'combined', 'lexical'), ('combined', 'lexical', 'morpheme'), ('lexical', 'morpheme', 'known')]

>> POS Tags are: 
 [('(', '('), ('e.g.-', 'JJ'), ('-ed', 'NN'), (',', ','), ('-ing', 'VBG'), (',', ','), ('-est', 'JJS'), (',', ','), ('-ly', 'NN'), (',', ','), ('-ful', 'JJ'), (')', ')'), ('combined', 'VBD'), ('lexical', 'JJ'), ('morpheme', 'NN'), ('known', 'VBN')]

>> Noun Phrases are: 
 ['e.g.- -ed', '-ly', 'lexical morpheme']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('e.g.-', 'e.g.-'), ('-ed', '-ed'), (',', ','), ('-ing', '-ing'), (',', ','), ('-est', '-est'), (',', ','), ('-ly', '-li'), (',', ','), ('-ful', '-ful'), (')', ')'), ('combined', 'combin'), ('lexical', 'lexic'), ('morpheme', 'morphem'), ('known', 'known')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('e.g.-', 'e.g.-'), ('-ed', '-ed'), (',', ','), ('-ing', '-ing'), (',', ','), ('-est', '-est'), (',', ','), ('-ly', '-li'), (',', ','), ('-ful', '-ful'), (')', ')'), ('combined', 'combin'), ('lexical', 'lexic'), ('morpheme', 'morphem'), ('known', 'known')]

>> Lemmatization: 
 [('(', '('), ('e.g.-', 'e.g.-'), ('-ed', '-ed'), (',', ','), ('-ing', '-ing'), (',', ','), ('-est', '-est'), (',', ','), ('-ly', '-ly'), (',', ','), ('-ful', '-ful'), (')', ')'), ('combined', 'combined'), ('lexical', 'lexical'), ('morpheme', 'morpheme'), ('known', 'known')]



========================================== PARAGRAPH 118 ===========================================

Grammatical morphemes (eg. Worked, Consulting, Smallest, Likely, Use). Those  

------------------- Sentence 1 -------------------

Grammatical morphemes (eg.

>> Tokens are: 
 ['Grammatical', 'morphemes', '(', 'eg', '.']

>> Bigrams are: 
 [('Grammatical', 'morphemes'), ('morphemes', '('), ('(', 'eg'), ('eg', '.')]

>> Trigrams are: 
 [('Grammatical', 'morphemes', '('), ('morphemes', '(', 'eg'), ('(', 'eg', '.')]

>> POS Tags are: 
 [('Grammatical', 'JJ'), ('morphemes', 'NNS'), ('(', '('), ('eg', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Grammatical morphemes', 'eg']

>> Named Entities are: 
 [('GPE', 'Grammatical')] 

>> Stemming using Porter Stemmer: 
 [('Grammatical', 'grammat'), ('morphemes', 'morphem'), ('(', '('), ('eg', 'eg'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Grammatical', 'grammat'), ('morphemes', 'morphem'), ('(', '('), ('eg', 'eg'), ('.', '.')]

>> Lemmatization: 
 [('Grammatical', 'Grammatical'), ('morphemes', 'morpheme'), ('(', '('), ('eg', 'eg'), ('.', '.')]


------------------- Sentence 2 -------------------

Worked, Consulting, Smallest, Likely, Use).

>> Tokens are: 
 ['Worked', ',', 'Consulting', ',', 'Smallest', ',', 'Likely', ',', 'Use', ')', '.']

>> Bigrams are: 
 [('Worked', ','), (',', 'Consulting'), ('Consulting', ','), (',', 'Smallest'), ('Smallest', ','), (',', 'Likely'), ('Likely', ','), (',', 'Use'), ('Use', ')'), (')', '.')]

>> Trigrams are: 
 [('Worked', ',', 'Consulting'), (',', 'Consulting', ','), ('Consulting', ',', 'Smallest'), (',', 'Smallest', ','), ('Smallest', ',', 'Likely'), (',', 'Likely', ','), ('Likely', ',', 'Use'), (',', 'Use', ')'), ('Use', ')', '.')]

>> POS Tags are: 
 [('Worked', 'VBN'), (',', ','), ('Consulting', 'NNP'), (',', ','), ('Smallest', 'NNP'), (',', ','), ('Likely', 'NNP'), (',', ','), ('Use', 'NNP'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['Consulting', 'Smallest', 'Likely', 'Use']

>> Named Entities are: 
 [('GPE', 'Smallest'), ('GPE', 'Likely'), ('ORGANIZATION', 'Use')] 

>> Stemming using Porter Stemmer: 
 [('Worked', 'work'), (',', ','), ('Consulting', 'consult'), (',', ','), ('Smallest', 'smallest'), (',', ','), ('Likely', 'like'), (',', ','), ('Use', 'use'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Worked', 'work'), (',', ','), ('Consulting', 'consult'), (',', ','), ('Smallest', 'smallest'), (',', ','), ('Likely', 'like'), (',', ','), ('Use', 'use'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Worked', 'Worked'), (',', ','), ('Consulting', 'Consulting'), (',', ','), ('Smallest', 'Smallest'), (',', ','), ('Likely', 'Likely'), (',', ','), ('Use', 'Use'), (')', ')'), ('.', '.')]


------------------- Sentence 3 -------------------

Those

>> Tokens are: 
 ['Those']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Those', 'DT')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Those', 'those')]

>> Stemming using Snowball Stemmer: 
 [('Those', 'those')]

>> Lemmatization: 
 [('Those', 'Those')]



========================================== PARAGRAPH 119 ===========================================

grammatical morphemes that occurs in combination called bound morphemes( eg. -ed, -ing)  

------------------- Sentence 1 -------------------

grammatical morphemes that occurs in combination called bound morphemes( eg.

>> Tokens are: 
 ['grammatical', 'morphemes', 'occurs', 'combination', 'called', 'bound', 'morphemes', '(', 'eg', '.']

>> Bigrams are: 
 [('grammatical', 'morphemes'), ('morphemes', 'occurs'), ('occurs', 'combination'), ('combination', 'called'), ('called', 'bound'), ('bound', 'morphemes'), ('morphemes', '('), ('(', 'eg'), ('eg', '.')]

>> Trigrams are: 
 [('grammatical', 'morphemes', 'occurs'), ('morphemes', 'occurs', 'combination'), ('occurs', 'combination', 'called'), ('combination', 'called', 'bound'), ('called', 'bound', 'morphemes'), ('bound', 'morphemes', '('), ('morphemes', '(', 'eg'), ('(', 'eg', '.')]

>> POS Tags are: 
 [('grammatical', 'JJ'), ('morphemes', 'NNS'), ('occurs', 'VBZ'), ('combination', 'NN'), ('called', 'VBN'), ('bound', 'NN'), ('morphemes', 'NNS'), ('(', '('), ('eg', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['grammatical morphemes', 'combination', 'bound morphemes', 'eg']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('grammatical', 'grammat'), ('morphemes', 'morphem'), ('occurs', 'occur'), ('combination', 'combin'), ('called', 'call'), ('bound', 'bound'), ('morphemes', 'morphem'), ('(', '('), ('eg', 'eg'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('grammatical', 'grammat'), ('morphemes', 'morphem'), ('occurs', 'occur'), ('combination', 'combin'), ('called', 'call'), ('bound', 'bound'), ('morphemes', 'morphem'), ('(', '('), ('eg', 'eg'), ('.', '.')]

>> Lemmatization: 
 [('grammatical', 'grammatical'), ('morphemes', 'morpheme'), ('occurs', 'occurs'), ('combination', 'combination'), ('called', 'called'), ('bound', 'bound'), ('morphemes', 'morpheme'), ('(', '('), ('eg', 'eg'), ('.', '.')]


------------------- Sentence 2 -------------------

-ed, -ing)

>> Tokens are: 
 ['-ed', ',', '-ing', ')']

>> Bigrams are: 
 [('-ed', ','), (',', '-ing'), ('-ing', ')')]

>> Trigrams are: 
 [('-ed', ',', '-ing'), (',', '-ing', ')')]

>> POS Tags are: 
 [('-ed', 'NN'), (',', ','), ('-ing', 'VBG'), (')', ')')]

>> Noun Phrases are: 
 ['-ed']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('-ed', '-ed'), (',', ','), ('-ing', '-ing'), (')', ')')]

>> Stemming using Snowball Stemmer: 
 [('-ed', '-ed'), (',', ','), ('-ing', '-ing'), (')', ')')]

>> Lemmatization: 
 [('-ed', '-ed'), (',', ','), ('-ing', '-ing'), (')', ')')]



========================================== PARAGRAPH 120 ===========================================

Grammatical morphemes can be divided into bound morphemes and derivational morphemes.     

------------------- Sentence 1 -------------------

Grammatical morphemes can be divided into bound morphemes and derivational morphemes.

>> Tokens are: 
 ['Grammatical', 'morphemes', 'divided', 'bound', 'morphemes', 'derivational', 'morphemes', '.']

>> Bigrams are: 
 [('Grammatical', 'morphemes'), ('morphemes', 'divided'), ('divided', 'bound'), ('bound', 'morphemes'), ('morphemes', 'derivational'), ('derivational', 'morphemes'), ('morphemes', '.')]

>> Trigrams are: 
 [('Grammatical', 'morphemes', 'divided'), ('morphemes', 'divided', 'bound'), ('divided', 'bound', 'morphemes'), ('bound', 'morphemes', 'derivational'), ('morphemes', 'derivational', 'morphemes'), ('derivational', 'morphemes', '.')]

>> POS Tags are: 
 [('Grammatical', 'JJ'), ('morphemes', 'NNS'), ('divided', 'VBN'), ('bound', 'NN'), ('morphemes', 'VBZ'), ('derivational', 'JJ'), ('morphemes', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['Grammatical morphemes', 'bound', 'derivational morphemes']

>> Named Entities are: 
 [('GPE', 'Grammatical')] 

>> Stemming using Porter Stemmer: 
 [('Grammatical', 'grammat'), ('morphemes', 'morphem'), ('divided', 'divid'), ('bound', 'bound'), ('morphemes', 'morphem'), ('derivational', 'deriv'), ('morphemes', 'morphem'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Grammatical', 'grammat'), ('morphemes', 'morphem'), ('divided', 'divid'), ('bound', 'bound'), ('morphemes', 'morphem'), ('derivational', 'deriv'), ('morphemes', 'morphem'), ('.', '.')]

>> Lemmatization: 
 [('Grammatical', 'Grammatical'), ('morphemes', 'morpheme'), ('divided', 'divided'), ('bound', 'bound'), ('morphemes', 'morpheme'), ('derivational', 'derivational'), ('morphemes', 'morpheme'), ('.', '.')]



========================================== PARAGRAPH 121 ===========================================

3. Lexical  

------------------- Sentence 1 -------------------

3.

>> Tokens are: 
 ['3', '.']

>> Bigrams are: 
 [('3', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('3', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('3', '3'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('3', '3'), ('.', '.')]

>> Lemmatization: 
 [('3', '3'), ('.', '.')]


------------------- Sentence 2 -------------------

Lexical

>> Tokens are: 
 ['Lexical']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Lexical', 'JJ')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [('GPE', 'Lexical')] 

>> Stemming using Porter Stemmer: 
 [('Lexical', 'lexic')]

>> Stemming using Snowball Stemmer: 
 [('Lexical', 'lexic')]

>> Lemmatization: 
 [('Lexical', 'Lexical')]



========================================== PARAGRAPH 122 ===========================================

In Lexical, humans, as well as NLP systems, interpret the meaning of individual words.  

------------------- Sentence 1 -------------------

In Lexical, humans, as well as NLP systems, interpret the meaning of individual words.

>> Tokens are: 
 ['In', 'Lexical', ',', 'humans', ',', 'well', 'NLP', 'systems', ',', 'interpret', 'meaning', 'individual', 'words', '.']

>> Bigrams are: 
 [('In', 'Lexical'), ('Lexical', ','), (',', 'humans'), ('humans', ','), (',', 'well'), ('well', 'NLP'), ('NLP', 'systems'), ('systems', ','), (',', 'interpret'), ('interpret', 'meaning'), ('meaning', 'individual'), ('individual', 'words'), ('words', '.')]

>> Trigrams are: 
 [('In', 'Lexical', ','), ('Lexical', ',', 'humans'), (',', 'humans', ','), ('humans', ',', 'well'), (',', 'well', 'NLP'), ('well', 'NLP', 'systems'), ('NLP', 'systems', ','), ('systems', ',', 'interpret'), (',', 'interpret', 'meaning'), ('interpret', 'meaning', 'individual'), ('meaning', 'individual', 'words'), ('individual', 'words', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('Lexical', 'NNP'), (',', ','), ('humans', 'NNS'), (',', ','), ('well', 'RB'), ('NLP', 'NNP'), ('systems', 'NNS'), (',', ','), ('interpret', 'JJ'), ('meaning', 'VBG'), ('individual', 'JJ'), ('words', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['Lexical', 'humans', 'NLP systems', 'individual words']

>> Named Entities are: 
 [('GPE', 'Lexical'), ('ORGANIZATION', 'NLP')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('Lexical', 'lexic'), (',', ','), ('humans', 'human'), (',', ','), ('well', 'well'), ('NLP', 'nlp'), ('systems', 'system'), (',', ','), ('interpret', 'interpret'), ('meaning', 'mean'), ('individual', 'individu'), ('words', 'word'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('Lexical', 'lexic'), (',', ','), ('humans', 'human'), (',', ','), ('well', 'well'), ('NLP', 'nlp'), ('systems', 'system'), (',', ','), ('interpret', 'interpret'), ('meaning', 'mean'), ('individual', 'individu'), ('words', 'word'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('Lexical', 'Lexical'), (',', ','), ('humans', 'human'), (',', ','), ('well', 'well'), ('NLP', 'NLP'), ('systems', 'system'), (',', ','), ('interpret', 'interpret'), ('meaning', 'meaning'), ('individual', 'individual'), ('words', 'word'), ('.', '.')]



========================================== PARAGRAPH 123 ===========================================

Sundry types of processing bestow to word-level understanding – the first of these being a  

------------------- Sentence 1 -------------------

Sundry types of processing bestow to word-level understanding – the first of these being a

>> Tokens are: 
 ['Sundry', 'types', 'processing', 'bestow', 'word-level', 'understanding', '–', 'first']

>> Bigrams are: 
 [('Sundry', 'types'), ('types', 'processing'), ('processing', 'bestow'), ('bestow', 'word-level'), ('word-level', 'understanding'), ('understanding', '–'), ('–', 'first')]

>> Trigrams are: 
 [('Sundry', 'types', 'processing'), ('types', 'processing', 'bestow'), ('processing', 'bestow', 'word-level'), ('bestow', 'word-level', 'understanding'), ('word-level', 'understanding', '–'), ('understanding', '–', 'first')]

>> POS Tags are: 
 [('Sundry', 'NNP'), ('types', 'NNS'), ('processing', 'VBG'), ('bestow', 'NN'), ('word-level', 'JJ'), ('understanding', 'NN'), ('–', 'NN'), ('first', 'RB')]

>> Noun Phrases are: 
 ['Sundry types', 'bestow', 'word-level understanding –']

>> Named Entities are: 
 [('GPE', 'Sundry')] 

>> Stemming using Porter Stemmer: 
 [('Sundry', 'sundri'), ('types', 'type'), ('processing', 'process'), ('bestow', 'bestow'), ('word-level', 'word-level'), ('understanding', 'understand'), ('–', '–'), ('first', 'first')]

>> Stemming using Snowball Stemmer: 
 [('Sundry', 'sundri'), ('types', 'type'), ('processing', 'process'), ('bestow', 'bestow'), ('word-level', 'word-level'), ('understanding', 'understand'), ('–', '–'), ('first', 'first')]

>> Lemmatization: 
 [('Sundry', 'Sundry'), ('types', 'type'), ('processing', 'processing'), ('bestow', 'bestow'), ('word-level', 'word-level'), ('understanding', 'understanding'), ('–', '–'), ('first', 'first')]



========================================== PARAGRAPH 124 ===========================================

part-of-speech tag to each word. In this processing, words that can act as more than one part- 

------------------- Sentence 1 -------------------

part-of-speech tag to each word.

>> Tokens are: 
 ['part-of-speech', 'tag', 'word', '.']

>> Bigrams are: 
 [('part-of-speech', 'tag'), ('tag', 'word'), ('word', '.')]

>> Trigrams are: 
 [('part-of-speech', 'tag', 'word'), ('tag', 'word', '.')]

>> POS Tags are: 
 [('part-of-speech', 'JJ'), ('tag', 'NN'), ('word', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['part-of-speech tag word']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('part-of-speech', 'part-of-speech'), ('tag', 'tag'), ('word', 'word'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('part-of-speech', 'part-of-speech'), ('tag', 'tag'), ('word', 'word'), ('.', '.')]

>> Lemmatization: 
 [('part-of-speech', 'part-of-speech'), ('tag', 'tag'), ('word', 'word'), ('.', '.')]


------------------- Sentence 2 -------------------

In this processing, words that can act as more than one part-

>> Tokens are: 
 ['In', 'processing', ',', 'words', 'act', 'one', 'part-']

>> Bigrams are: 
 [('In', 'processing'), ('processing', ','), (',', 'words'), ('words', 'act'), ('act', 'one'), ('one', 'part-')]

>> Trigrams are: 
 [('In', 'processing', ','), ('processing', ',', 'words'), (',', 'words', 'act'), ('words', 'act', 'one'), ('act', 'one', 'part-')]

>> POS Tags are: 
 [('In', 'IN'), ('processing', 'NN'), (',', ','), ('words', 'NNS'), ('act', 'VBP'), ('one', 'CD'), ('part-', 'NN')]

>> Noun Phrases are: 
 ['processing', 'words', 'part-']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('processing', 'process'), (',', ','), ('words', 'word'), ('act', 'act'), ('one', 'one'), ('part-', 'part-')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('processing', 'process'), (',', ','), ('words', 'word'), ('act', 'act'), ('one', 'one'), ('part-', 'part-')]

>> Lemmatization: 
 [('In', 'In'), ('processing', 'processing'), (',', ','), ('words', 'word'), ('act', 'act'), ('one', 'one'), ('part-', 'part-')]



========================================== PARAGRAPH 125 ===========================================

of-speech are assigned the most probable part-of speech tag based on the context in which  

------------------- Sentence 1 -------------------

of-speech are assigned the most probable part-of speech tag based on the context in which

>> Tokens are: 
 ['of-speech', 'assigned', 'probable', 'part-of', 'speech', 'tag', 'based', 'context']

>> Bigrams are: 
 [('of-speech', 'assigned'), ('assigned', 'probable'), ('probable', 'part-of'), ('part-of', 'speech'), ('speech', 'tag'), ('tag', 'based'), ('based', 'context')]

>> Trigrams are: 
 [('of-speech', 'assigned', 'probable'), ('assigned', 'probable', 'part-of'), ('probable', 'part-of', 'speech'), ('part-of', 'speech', 'tag'), ('speech', 'tag', 'based'), ('tag', 'based', 'context')]

>> POS Tags are: 
 [('of-speech', 'JJ'), ('assigned', 'VBD'), ('probable', 'JJ'), ('part-of', 'JJ'), ('speech', 'NN'), ('tag', 'NN'), ('based', 'VBN'), ('context', 'NN')]

>> Noun Phrases are: 
 ['probable part-of speech tag', 'context']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('of-speech', 'of-speech'), ('assigned', 'assign'), ('probable', 'probabl'), ('part-of', 'part-of'), ('speech', 'speech'), ('tag', 'tag'), ('based', 'base'), ('context', 'context')]

>> Stemming using Snowball Stemmer: 
 [('of-speech', 'of-speech'), ('assigned', 'assign'), ('probable', 'probabl'), ('part-of', 'part-of'), ('speech', 'speech'), ('tag', 'tag'), ('based', 'base'), ('context', 'context')]

>> Lemmatization: 
 [('of-speech', 'of-speech'), ('assigned', 'assigned'), ('probable', 'probable'), ('part-of', 'part-of'), ('speech', 'speech'), ('tag', 'tag'), ('based', 'based'), ('context', 'context')]



========================================== PARAGRAPH 126 ===========================================

they occur. At the lexical level, Semantic representations can be replaced by the words that  

------------------- Sentence 1 -------------------

they occur.

>> Tokens are: 
 ['occur', '.']

>> Bigrams are: 
 [('occur', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('occur', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['occur']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('occur', 'occur'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('occur', 'occur'), ('.', '.')]

>> Lemmatization: 
 [('occur', 'occur'), ('.', '.')]


------------------- Sentence 2 -------------------

At the lexical level, Semantic representations can be replaced by the words that

>> Tokens are: 
 ['At', 'lexical', 'level', ',', 'Semantic', 'representations', 'replaced', 'words']

>> Bigrams are: 
 [('At', 'lexical'), ('lexical', 'level'), ('level', ','), (',', 'Semantic'), ('Semantic', 'representations'), ('representations', 'replaced'), ('replaced', 'words')]

>> Trigrams are: 
 [('At', 'lexical', 'level'), ('lexical', 'level', ','), ('level', ',', 'Semantic'), (',', 'Semantic', 'representations'), ('Semantic', 'representations', 'replaced'), ('representations', 'replaced', 'words')]

>> POS Tags are: 
 [('At', 'IN'), ('lexical', 'JJ'), ('level', 'NN'), (',', ','), ('Semantic', 'JJ'), ('representations', 'NNS'), ('replaced', 'VBD'), ('words', 'NNS')]

>> Noun Phrases are: 
 ['lexical level', 'Semantic representations', 'words']

>> Named Entities are: 
 [('ORGANIZATION', 'Semantic')] 

>> Stemming using Porter Stemmer: 
 [('At', 'at'), ('lexical', 'lexic'), ('level', 'level'), (',', ','), ('Semantic', 'semant'), ('representations', 'represent'), ('replaced', 'replac'), ('words', 'word')]

>> Stemming using Snowball Stemmer: 
 [('At', 'at'), ('lexical', 'lexic'), ('level', 'level'), (',', ','), ('Semantic', 'semant'), ('representations', 'represent'), ('replaced', 'replac'), ('words', 'word')]

>> Lemmatization: 
 [('At', 'At'), ('lexical', 'lexical'), ('level', 'level'), (',', ','), ('Semantic', 'Semantic'), ('representations', 'representation'), ('replaced', 'replaced'), ('words', 'word')]



========================================== PARAGRAPH 127 ===========================================

have one meaning. In NLP system, the nature of the representation varies according to the  

------------------- Sentence 1 -------------------

have one meaning.

>> Tokens are: 
 ['one', 'meaning', '.']

>> Bigrams are: 
 [('one', 'meaning'), ('meaning', '.')]

>> Trigrams are: 
 [('one', 'meaning', '.')]

>> POS Tags are: 
 [('one', 'CD'), ('meaning', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['meaning']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('one', 'one'), ('meaning', 'mean'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('one', 'one'), ('meaning', 'mean'), ('.', '.')]

>> Lemmatization: 
 [('one', 'one'), ('meaning', 'meaning'), ('.', '.')]


------------------- Sentence 2 -------------------

In NLP system, the nature of the representation varies according to the

>> Tokens are: 
 ['In', 'NLP', 'system', ',', 'nature', 'representation', 'varies', 'according']

>> Bigrams are: 
 [('In', 'NLP'), ('NLP', 'system'), ('system', ','), (',', 'nature'), ('nature', 'representation'), ('representation', 'varies'), ('varies', 'according')]

>> Trigrams are: 
 [('In', 'NLP', 'system'), ('NLP', 'system', ','), ('system', ',', 'nature'), (',', 'nature', 'representation'), ('nature', 'representation', 'varies'), ('representation', 'varies', 'according')]

>> POS Tags are: 
 [('In', 'IN'), ('NLP', 'NNP'), ('system', 'NN'), (',', ','), ('nature', 'JJ'), ('representation', 'NN'), ('varies', 'NNS'), ('according', 'VBG')]

>> Noun Phrases are: 
 ['NLP system', 'nature representation varies']

>> Named Entities are: 
 [('ORGANIZATION', 'NLP')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('NLP', 'nlp'), ('system', 'system'), (',', ','), ('nature', 'natur'), ('representation', 'represent'), ('varies', 'vari'), ('according', 'accord')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('NLP', 'nlp'), ('system', 'system'), (',', ','), ('nature', 'natur'), ('representation', 'represent'), ('varies', 'vari'), ('according', 'accord')]

>> Lemmatization: 
 [('In', 'In'), ('NLP', 'NLP'), ('system', 'system'), (',', ','), ('nature', 'nature'), ('representation', 'representation'), ('varies', 'varies'), ('according', 'according')]



========================================== PARAGRAPH 128 ===========================================

semantic theory deployed.  

------------------- Sentence 1 -------------------

semantic theory deployed.

>> Tokens are: 
 ['semantic', 'theory', 'deployed', '.']

>> Bigrams are: 
 [('semantic', 'theory'), ('theory', 'deployed'), ('deployed', '.')]

>> Trigrams are: 
 [('semantic', 'theory', 'deployed'), ('theory', 'deployed', '.')]

>> POS Tags are: 
 [('semantic', 'JJ'), ('theory', 'NN'), ('deployed', 'VBN'), ('.', '.')]

>> Noun Phrases are: 
 ['semantic theory']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('semantic', 'semant'), ('theory', 'theori'), ('deployed', 'deploy'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('semantic', 'semant'), ('theory', 'theori'), ('deployed', 'deploy'), ('.', '.')]

>> Lemmatization: 
 [('semantic', 'semantic'), ('theory', 'theory'), ('deployed', 'deployed'), ('.', '.')]



========================================== PARAGRAPH 129 ===========================================

4. Syntactic  

------------------- Sentence 1 -------------------

4.

>> Tokens are: 
 ['4', '.']

>> Bigrams are: 
 [('4', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('4', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('4', '4'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('4', '4'), ('.', '.')]

>> Lemmatization: 
 [('4', '4'), ('.', '.')]


------------------- Sentence 2 -------------------

Syntactic

>> Tokens are: 
 ['Syntactic']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Syntactic', 'JJ')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [('GPE', 'Syntactic')] 

>> Stemming using Porter Stemmer: 
 [('Syntactic', 'syntact')]

>> Stemming using Snowball Stemmer: 
 [('Syntactic', 'syntact')]

>> Lemmatization: 
 [('Syntactic', 'Syntactic')]



========================================== PARAGRAPH 130 ===========================================

This level emphasis to scrutinize the words in a sentence so as to uncover the grammatical  

------------------- Sentence 1 -------------------

This level emphasis to scrutinize the words in a sentence so as to uncover the grammatical

>> Tokens are: 
 ['This', 'level', 'emphasis', 'scrutinize', 'words', 'sentence', 'uncover', 'grammatical']

>> Bigrams are: 
 [('This', 'level'), ('level', 'emphasis'), ('emphasis', 'scrutinize'), ('scrutinize', 'words'), ('words', 'sentence'), ('sentence', 'uncover'), ('uncover', 'grammatical')]

>> Trigrams are: 
 [('This', 'level', 'emphasis'), ('level', 'emphasis', 'scrutinize'), ('emphasis', 'scrutinize', 'words'), ('scrutinize', 'words', 'sentence'), ('words', 'sentence', 'uncover'), ('sentence', 'uncover', 'grammatical')]

>> POS Tags are: 
 [('This', 'DT'), ('level', 'JJ'), ('emphasis', 'NN'), ('scrutinize', 'NN'), ('words', 'NNS'), ('sentence', 'NN'), ('uncover', 'RB'), ('grammatical', 'JJ')]

>> Noun Phrases are: 
 ['This level emphasis scrutinize words sentence']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('This', 'thi'), ('level', 'level'), ('emphasis', 'emphasi'), ('scrutinize', 'scrutin'), ('words', 'word'), ('sentence', 'sentenc'), ('uncover', 'uncov'), ('grammatical', 'grammat')]

>> Stemming using Snowball Stemmer: 
 [('This', 'this'), ('level', 'level'), ('emphasis', 'emphasi'), ('scrutinize', 'scrutin'), ('words', 'word'), ('sentence', 'sentenc'), ('uncover', 'uncov'), ('grammatical', 'grammat')]

>> Lemmatization: 
 [('This', 'This'), ('level', 'level'), ('emphasis', 'emphasis'), ('scrutinize', 'scrutinize'), ('words', 'word'), ('sentence', 'sentence'), ('uncover', 'uncover'), ('grammatical', 'grammatical')]



========================================== PARAGRAPH 131 ===========================================

structure of the sentence. Both grammar and parser are required in this level. The output of  

------------------- Sentence 1 -------------------

structure of the sentence.

>> Tokens are: 
 ['structure', 'sentence', '.']

>> Bigrams are: 
 [('structure', 'sentence'), ('sentence', '.')]

>> Trigrams are: 
 [('structure', 'sentence', '.')]

>> POS Tags are: 
 [('structure', 'NN'), ('sentence', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['structure sentence']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('structure', 'structur'), ('sentence', 'sentenc'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('structure', 'structur'), ('sentence', 'sentenc'), ('.', '.')]

>> Lemmatization: 
 [('structure', 'structure'), ('sentence', 'sentence'), ('.', '.')]


------------------- Sentence 2 -------------------

Both grammar and parser are required in this level.

>> Tokens are: 
 ['Both', 'grammar', 'parser', 'required', 'level', '.']

>> Bigrams are: 
 [('Both', 'grammar'), ('grammar', 'parser'), ('parser', 'required'), ('required', 'level'), ('level', '.')]

>> Trigrams are: 
 [('Both', 'grammar', 'parser'), ('grammar', 'parser', 'required'), ('parser', 'required', 'level'), ('required', 'level', '.')]

>> POS Tags are: 
 [('Both', 'DT'), ('grammar', 'FW'), ('parser', 'NN'), ('required', 'VBN'), ('level', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['parser', 'level']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Both', 'both'), ('grammar', 'grammar'), ('parser', 'parser'), ('required', 'requir'), ('level', 'level'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Both', 'both'), ('grammar', 'grammar'), ('parser', 'parser'), ('required', 'requir'), ('level', 'level'), ('.', '.')]

>> Lemmatization: 
 [('Both', 'Both'), ('grammar', 'grammar'), ('parser', 'parser'), ('required', 'required'), ('level', 'level'), ('.', '.')]


------------------- Sentence 3 -------------------

The output of

>> Tokens are: 
 ['The', 'output']

>> Bigrams are: 
 [('The', 'output')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('The', 'DT'), ('output', 'NN')]

>> Noun Phrases are: 
 ['The output']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('output', 'output')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('output', 'output')]

>> Lemmatization: 
 [('The', 'The'), ('output', 'output')]



========================================== PARAGRAPH 132 ===========================================

this level of processing is representation of the sentence that divulge the structural  

------------------- Sentence 1 -------------------

this level of processing is representation of the sentence that divulge the structural

>> Tokens are: 
 ['level', 'processing', 'representation', 'sentence', 'divulge', 'structural']

>> Bigrams are: 
 [('level', 'processing'), ('processing', 'representation'), ('representation', 'sentence'), ('sentence', 'divulge'), ('divulge', 'structural')]

>> Trigrams are: 
 [('level', 'processing', 'representation'), ('processing', 'representation', 'sentence'), ('representation', 'sentence', 'divulge'), ('sentence', 'divulge', 'structural')]

>> POS Tags are: 
 [('level', 'NN'), ('processing', 'VBG'), ('representation', 'NN'), ('sentence', 'NN'), ('divulge', 'JJ'), ('structural', 'NN')]

>> Noun Phrases are: 
 ['level', 'representation sentence', 'divulge structural']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('level', 'level'), ('processing', 'process'), ('representation', 'represent'), ('sentence', 'sentenc'), ('divulge', 'divulg'), ('structural', 'structur')]

>> Stemming using Snowball Stemmer: 
 [('level', 'level'), ('processing', 'process'), ('representation', 'represent'), ('sentence', 'sentenc'), ('divulge', 'divulg'), ('structural', 'structur')]

>> Lemmatization: 
 [('level', 'level'), ('processing', 'processing'), ('representation', 'representation'), ('sentence', 'sentence'), ('divulge', 'divulge'), ('structural', 'structural')]



========================================== PARAGRAPH 133 ===========================================

dependency relationships between the words. There are various grammars that can be  

------------------- Sentence 1 -------------------

dependency relationships between the words.

>> Tokens are: 
 ['dependency', 'relationships', 'words', '.']

>> Bigrams are: 
 [('dependency', 'relationships'), ('relationships', 'words'), ('words', '.')]

>> Trigrams are: 
 [('dependency', 'relationships', 'words'), ('relationships', 'words', '.')]

>> POS Tags are: 
 [('dependency', 'NN'), ('relationships', 'NNS'), ('words', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['dependency relationships words']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('dependency', 'depend'), ('relationships', 'relationship'), ('words', 'word'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('dependency', 'depend'), ('relationships', 'relationship'), ('words', 'word'), ('.', '.')]

>> Lemmatization: 
 [('dependency', 'dependency'), ('relationships', 'relationship'), ('words', 'word'), ('.', '.')]


------------------- Sentence 2 -------------------

There are various grammars that can be

>> Tokens are: 
 ['There', 'various', 'grammars']

>> Bigrams are: 
 [('There', 'various'), ('various', 'grammars')]

>> Trigrams are: 
 [('There', 'various', 'grammars')]

>> POS Tags are: 
 [('There', 'EX'), ('various', 'JJ'), ('grammars', 'NNS')]

>> Noun Phrases are: 
 ['various grammars']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('There', 'there'), ('various', 'variou'), ('grammars', 'grammar')]

>> Stemming using Snowball Stemmer: 
 [('There', 'there'), ('various', 'various'), ('grammars', 'grammar')]

>> Lemmatization: 
 [('There', 'There'), ('various', 'various'), ('grammars', 'grammar')]



========================================== PARAGRAPH 134 ===========================================

impeded, and which in twirl, whack the option of a parser. Not all NLP applications require a  

------------------- Sentence 1 -------------------

impeded, and which in twirl, whack the option of a parser.

>> Tokens are: 
 ['impeded', ',', 'twirl', ',', 'whack', 'option', 'parser', '.']

>> Bigrams are: 
 [('impeded', ','), (',', 'twirl'), ('twirl', ','), (',', 'whack'), ('whack', 'option'), ('option', 'parser'), ('parser', '.')]

>> Trigrams are: 
 [('impeded', ',', 'twirl'), (',', 'twirl', ','), ('twirl', ',', 'whack'), (',', 'whack', 'option'), ('whack', 'option', 'parser'), ('option', 'parser', '.')]

>> POS Tags are: 
 [('impeded', 'VBN'), (',', ','), ('twirl', 'VB'), (',', ','), ('whack', 'VB'), ('option', 'NN'), ('parser', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['option parser']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('impeded', 'imped'), (',', ','), ('twirl', 'twirl'), (',', ','), ('whack', 'whack'), ('option', 'option'), ('parser', 'parser'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('impeded', 'imped'), (',', ','), ('twirl', 'twirl'), (',', ','), ('whack', 'whack'), ('option', 'option'), ('parser', 'parser'), ('.', '.')]

>> Lemmatization: 
 [('impeded', 'impeded'), (',', ','), ('twirl', 'twirl'), (',', ','), ('whack', 'whack'), ('option', 'option'), ('parser', 'parser'), ('.', '.')]


------------------- Sentence 2 -------------------

Not all NLP applications require a

>> Tokens are: 
 ['Not', 'NLP', 'applications', 'require']

>> Bigrams are: 
 [('Not', 'NLP'), ('NLP', 'applications'), ('applications', 'require')]

>> Trigrams are: 
 [('Not', 'NLP', 'applications'), ('NLP', 'applications', 'require')]

>> POS Tags are: 
 [('Not', 'RB'), ('NLP', 'NNP'), ('applications', 'NNS'), ('require', 'VBP')]

>> Noun Phrases are: 
 ['NLP applications']

>> Named Entities are: 
 [('ORGANIZATION', 'NLP')] 

>> Stemming using Porter Stemmer: 
 [('Not', 'not'), ('NLP', 'nlp'), ('applications', 'applic'), ('require', 'requir')]

>> Stemming using Snowball Stemmer: 
 [('Not', 'not'), ('NLP', 'nlp'), ('applications', 'applic'), ('require', 'requir')]

>> Lemmatization: 
 [('Not', 'Not'), ('NLP', 'NLP'), ('applications', 'application'), ('require', 'require')]



========================================== PARAGRAPH 135 ===========================================

full parse of sentences, therefore the abide challenges in parsing of prepositional phrase  

------------------- Sentence 1 -------------------

full parse of sentences, therefore the abide challenges in parsing of prepositional phrase

>> Tokens are: 
 ['full', 'parse', 'sentences', ',', 'therefore', 'abide', 'challenges', 'parsing', 'prepositional', 'phrase']

>> Bigrams are: 
 [('full', 'parse'), ('parse', 'sentences'), ('sentences', ','), (',', 'therefore'), ('therefore', 'abide'), ('abide', 'challenges'), ('challenges', 'parsing'), ('parsing', 'prepositional'), ('prepositional', 'phrase')]

>> Trigrams are: 
 [('full', 'parse', 'sentences'), ('parse', 'sentences', ','), ('sentences', ',', 'therefore'), (',', 'therefore', 'abide'), ('therefore', 'abide', 'challenges'), ('abide', 'challenges', 'parsing'), ('challenges', 'parsing', 'prepositional'), ('parsing', 'prepositional', 'phrase')]

>> POS Tags are: 
 [('full', 'JJ'), ('parse', 'NN'), ('sentences', 'NNS'), (',', ','), ('therefore', 'RB'), ('abide', 'JJ'), ('challenges', 'NNS'), ('parsing', 'VBG'), ('prepositional', 'JJ'), ('phrase', 'NN')]

>> Noun Phrases are: 
 ['full parse sentences', 'abide challenges', 'prepositional phrase']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('full', 'full'), ('parse', 'pars'), ('sentences', 'sentenc'), (',', ','), ('therefore', 'therefor'), ('abide', 'abid'), ('challenges', 'challeng'), ('parsing', 'pars'), ('prepositional', 'preposit'), ('phrase', 'phrase')]

>> Stemming using Snowball Stemmer: 
 [('full', 'full'), ('parse', 'pars'), ('sentences', 'sentenc'), (',', ','), ('therefore', 'therefor'), ('abide', 'abid'), ('challenges', 'challeng'), ('parsing', 'pars'), ('prepositional', 'preposit'), ('phrase', 'phrase')]

>> Lemmatization: 
 [('full', 'full'), ('parse', 'parse'), ('sentences', 'sentence'), (',', ','), ('therefore', 'therefore'), ('abide', 'abide'), ('challenges', 'challenge'), ('parsing', 'parsing'), ('prepositional', 'prepositional'), ('phrase', 'phrase')]



========================================== PARAGRAPH 136 ===========================================

attachment and conjunction audit no longer impede that plea for which phrasal and clausal  

------------------- Sentence 1 -------------------

attachment and conjunction audit no longer impede that plea for which phrasal and clausal

>> Tokens are: 
 ['attachment', 'conjunction', 'audit', 'longer', 'impede', 'plea', 'phrasal', 'clausal']

>> Bigrams are: 
 [('attachment', 'conjunction'), ('conjunction', 'audit'), ('audit', 'longer'), ('longer', 'impede'), ('impede', 'plea'), ('plea', 'phrasal'), ('phrasal', 'clausal')]

>> Trigrams are: 
 [('attachment', 'conjunction', 'audit'), ('conjunction', 'audit', 'longer'), ('audit', 'longer', 'impede'), ('longer', 'impede', 'plea'), ('impede', 'plea', 'phrasal'), ('plea', 'phrasal', 'clausal')]

>> POS Tags are: 
 [('attachment', 'JJ'), ('conjunction', 'NN'), ('audit', 'NN'), ('longer', 'RBR'), ('impede', 'JJ'), ('plea', 'NN'), ('phrasal', 'NN'), ('clausal', 'NN')]

>> Noun Phrases are: 
 ['attachment conjunction audit', 'impede plea phrasal clausal']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('attachment', 'attach'), ('conjunction', 'conjunct'), ('audit', 'audit'), ('longer', 'longer'), ('impede', 'imped'), ('plea', 'plea'), ('phrasal', 'phrasal'), ('clausal', 'clausal')]

>> Stemming using Snowball Stemmer: 
 [('attachment', 'attach'), ('conjunction', 'conjunct'), ('audit', 'audit'), ('longer', 'longer'), ('impede', 'imped'), ('plea', 'plea'), ('phrasal', 'phrasal'), ('clausal', 'clausal')]

>> Lemmatization: 
 [('attachment', 'attachment'), ('conjunction', 'conjunction'), ('audit', 'audit'), ('longer', 'longer'), ('impede', 'impede'), ('plea', 'plea'), ('phrasal', 'phrasal'), ('clausal', 'clausal')]



========================================== PARAGRAPH 137 ===========================================

dependencies are adequate [7]. Syntax conveys meaning in most languages because order and  

------------------- Sentence 1 -------------------

dependencies are adequate [7].

>> Tokens are: 
 ['dependencies', 'adequate', '[', '7', ']', '.']

>> Bigrams are: 
 [('dependencies', 'adequate'), ('adequate', '['), ('[', '7'), ('7', ']'), (']', '.')]

>> Trigrams are: 
 [('dependencies', 'adequate', '['), ('adequate', '[', '7'), ('[', '7', ']'), ('7', ']', '.')]

>> POS Tags are: 
 [('dependencies', 'NNS'), ('adequate', 'VBP'), ('[', '$'), ('7', 'CD'), (']', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['dependencies', ']']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('dependencies', 'depend'), ('adequate', 'adequ'), ('[', '['), ('7', '7'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('dependencies', 'depend'), ('adequate', 'adequ'), ('[', '['), ('7', '7'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('dependencies', 'dependency'), ('adequate', 'adequate'), ('[', '['), ('7', '7'), (']', ']'), ('.', '.')]


------------------- Sentence 2 -------------------

Syntax conveys meaning in most languages because order and

>> Tokens are: 
 ['Syntax', 'conveys', 'meaning', 'languages', 'order']

>> Bigrams are: 
 [('Syntax', 'conveys'), ('conveys', 'meaning'), ('meaning', 'languages'), ('languages', 'order')]

>> Trigrams are: 
 [('Syntax', 'conveys', 'meaning'), ('conveys', 'meaning', 'languages'), ('meaning', 'languages', 'order')]

>> POS Tags are: 
 [('Syntax', 'NNP'), ('conveys', 'NNS'), ('meaning', 'VBG'), ('languages', 'NNS'), ('order', 'NN')]

>> Noun Phrases are: 
 ['Syntax conveys', 'languages order']

>> Named Entities are: 
 [('GPE', 'Syntax')] 

>> Stemming using Porter Stemmer: 
 [('Syntax', 'syntax'), ('conveys', 'convey'), ('meaning', 'mean'), ('languages', 'languag'), ('order', 'order')]

>> Stemming using Snowball Stemmer: 
 [('Syntax', 'syntax'), ('conveys', 'convey'), ('meaning', 'mean'), ('languages', 'languag'), ('order', 'order')]

>> Lemmatization: 
 [('Syntax', 'Syntax'), ('conveys', 'conveys'), ('meaning', 'meaning'), ('languages', 'language'), ('order', 'order')]



========================================== PARAGRAPH 138 ===========================================

dependency contribute to connotation. For example, the two sentences: ‘The cat chased the  

------------------- Sentence 1 -------------------

dependency contribute to connotation.

>> Tokens are: 
 ['dependency', 'contribute', 'connotation', '.']

>> Bigrams are: 
 [('dependency', 'contribute'), ('contribute', 'connotation'), ('connotation', '.')]

>> Trigrams are: 
 [('dependency', 'contribute', 'connotation'), ('contribute', 'connotation', '.')]

>> POS Tags are: 
 [('dependency', 'NN'), ('contribute', 'JJ'), ('connotation', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['dependency', 'contribute connotation']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('dependency', 'depend'), ('contribute', 'contribut'), ('connotation', 'connot'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('dependency', 'depend'), ('contribute', 'contribut'), ('connotation', 'connot'), ('.', '.')]

>> Lemmatization: 
 [('dependency', 'dependency'), ('contribute', 'contribute'), ('connotation', 'connotation'), ('.', '.')]


------------------- Sentence 2 -------------------

For example, the two sentences: ‘The cat chased the

>> Tokens are: 
 ['For', 'example', ',', 'two', 'sentences', ':', '‘', 'The', 'cat', 'chased']

>> Bigrams are: 
 [('For', 'example'), ('example', ','), (',', 'two'), ('two', 'sentences'), ('sentences', ':'), (':', '‘'), ('‘', 'The'), ('The', 'cat'), ('cat', 'chased')]

>> Trigrams are: 
 [('For', 'example', ','), ('example', ',', 'two'), (',', 'two', 'sentences'), ('two', 'sentences', ':'), ('sentences', ':', '‘'), (':', '‘', 'The'), ('‘', 'The', 'cat'), ('The', 'cat', 'chased')]

>> POS Tags are: 
 [('For', 'IN'), ('example', 'NN'), (',', ','), ('two', 'CD'), ('sentences', 'NNS'), (':', ':'), ('‘', 'VB'), ('The', 'DT'), ('cat', 'NN'), ('chased', 'VBD')]

>> Noun Phrases are: 
 ['example', 'sentences', 'The cat']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('For', 'for'), ('example', 'exampl'), (',', ','), ('two', 'two'), ('sentences', 'sentenc'), (':', ':'), ('‘', '‘'), ('The', 'the'), ('cat', 'cat'), ('chased', 'chase')]

>> Stemming using Snowball Stemmer: 
 [('For', 'for'), ('example', 'exampl'), (',', ','), ('two', 'two'), ('sentences', 'sentenc'), (':', ':'), ('‘', '‘'), ('The', 'the'), ('cat', 'cat'), ('chased', 'chase')]

>> Lemmatization: 
 [('For', 'For'), ('example', 'example'), (',', ','), ('two', 'two'), ('sentences', 'sentence'), (':', ':'), ('‘', '‘'), ('The', 'The'), ('cat', 'cat'), ('chased', 'chased')]



========================================== PARAGRAPH 139 ===========================================

mouse.’ and ‘The mouse chased the cat.’ differ only in terms of syntax, yet convey quite  

------------------- Sentence 1 -------------------

mouse.’ and ‘The mouse chased the cat.’ differ only in terms of syntax, yet convey quite

>> Tokens are: 
 ['mouse.', '’', '‘', 'The', 'mouse', 'chased', 'cat.', '’', 'differ', 'terms', 'syntax', ',', 'yet', 'convey', 'quite']

>> Bigrams are: 
 [('mouse.', '’'), ('’', '‘'), ('‘', 'The'), ('The', 'mouse'), ('mouse', 'chased'), ('chased', 'cat.'), ('cat.', '’'), ('’', 'differ'), ('differ', 'terms'), ('terms', 'syntax'), ('syntax', ','), (',', 'yet'), ('yet', 'convey'), ('convey', 'quite')]

>> Trigrams are: 
 [('mouse.', '’', '‘'), ('’', '‘', 'The'), ('‘', 'The', 'mouse'), ('The', 'mouse', 'chased'), ('mouse', 'chased', 'cat.'), ('chased', 'cat.', '’'), ('cat.', '’', 'differ'), ('’', 'differ', 'terms'), ('differ', 'terms', 'syntax'), ('terms', 'syntax', ','), ('syntax', ',', 'yet'), (',', 'yet', 'convey'), ('yet', 'convey', 'quite')]

>> POS Tags are: 
 [('mouse.', 'NN'), ('’', 'NNP'), ('‘', 'VBZ'), ('The', 'DT'), ('mouse', 'NN'), ('chased', 'VBD'), ('cat.', 'NN'), ('’', 'NNP'), ('differ', 'NN'), ('terms', 'NNS'), ('syntax', 'NN'), (',', ','), ('yet', 'RB'), ('convey', 'VBN'), ('quite', 'RB')]

>> Noun Phrases are: 
 ['mouse. ’', 'The mouse', 'cat. ’ differ terms syntax']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('mouse.', 'mouse.'), ('’', '’'), ('‘', '‘'), ('The', 'the'), ('mouse', 'mous'), ('chased', 'chase'), ('cat.', 'cat.'), ('’', '’'), ('differ', 'differ'), ('terms', 'term'), ('syntax', 'syntax'), (',', ','), ('yet', 'yet'), ('convey', 'convey'), ('quite', 'quit')]

>> Stemming using Snowball Stemmer: 
 [('mouse.', 'mouse.'), ('’', '’'), ('‘', '‘'), ('The', 'the'), ('mouse', 'mous'), ('chased', 'chase'), ('cat.', 'cat.'), ('’', '’'), ('differ', 'differ'), ('terms', 'term'), ('syntax', 'syntax'), (',', ','), ('yet', 'yet'), ('convey', 'convey'), ('quite', 'quit')]

>> Lemmatization: 
 [('mouse.', 'mouse.'), ('’', '’'), ('‘', '‘'), ('The', 'The'), ('mouse', 'mouse'), ('chased', 'chased'), ('cat.', 'cat.'), ('’', '’'), ('differ', 'differ'), ('terms', 'term'), ('syntax', 'syntax'), (',', ','), ('yet', 'yet'), ('convey', 'convey'), ('quite', 'quite')]



========================================== PARAGRAPH 140 ===========================================

different meanings.  

------------------- Sentence 1 -------------------

different meanings.

>> Tokens are: 
 ['different', 'meanings', '.']

>> Bigrams are: 
 [('different', 'meanings'), ('meanings', '.')]

>> Trigrams are: 
 [('different', 'meanings', '.')]

>> POS Tags are: 
 [('different', 'JJ'), ('meanings', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['different meanings']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('different', 'differ'), ('meanings', 'mean'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('different', 'differ'), ('meanings', 'mean'), ('.', '.')]

>> Lemmatization: 
 [('different', 'different'), ('meanings', 'meaning'), ('.', '.')]



========================================== PARAGRAPH 141 ===========================================

5. Semantic  

------------------- Sentence 1 -------------------

5.

>> Tokens are: 
 ['5', '.']

>> Bigrams are: 
 [('5', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('5', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('5', '5'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('5', '5'), ('.', '.')]

>> Lemmatization: 
 [('5', '5'), ('.', '.')]


------------------- Sentence 2 -------------------

Semantic

>> Tokens are: 
 ['Semantic']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Semantic', 'JJ')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [('GPE', 'Semantic')] 

>> Stemming using Porter Stemmer: 
 [('Semantic', 'semant')]

>> Stemming using Snowball Stemmer: 
 [('Semantic', 'semant')]

>> Lemmatization: 
 [('Semantic', 'Semantic')]



========================================== PARAGRAPH 142 ===========================================

In semantic most people think that meaning is determined, however, this is not it is all the  

------------------- Sentence 1 -------------------

In semantic most people think that meaning is determined, however, this is not it is all the

>> Tokens are: 
 ['In', 'semantic', 'people', 'think', 'meaning', 'determined', ',', 'however', ',']

>> Bigrams are: 
 [('In', 'semantic'), ('semantic', 'people'), ('people', 'think'), ('think', 'meaning'), ('meaning', 'determined'), ('determined', ','), (',', 'however'), ('however', ',')]

>> Trigrams are: 
 [('In', 'semantic', 'people'), ('semantic', 'people', 'think'), ('people', 'think', 'meaning'), ('think', 'meaning', 'determined'), ('meaning', 'determined', ','), ('determined', ',', 'however'), (',', 'however', ',')]

>> POS Tags are: 
 [('In', 'IN'), ('semantic', 'JJ'), ('people', 'NNS'), ('think', 'VBP'), ('meaning', 'VBG'), ('determined', 'VBD'), (',', ','), ('however', 'RB'), (',', ',')]

>> Noun Phrases are: 
 ['semantic people']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('semantic', 'semant'), ('people', 'peopl'), ('think', 'think'), ('meaning', 'mean'), ('determined', 'determin'), (',', ','), ('however', 'howev'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('semantic', 'semant'), ('people', 'peopl'), ('think', 'think'), ('meaning', 'mean'), ('determined', 'determin'), (',', ','), ('however', 'howev'), (',', ',')]

>> Lemmatization: 
 [('In', 'In'), ('semantic', 'semantic'), ('people', 'people'), ('think', 'think'), ('meaning', 'meaning'), ('determined', 'determined'), (',', ','), ('however', 'however'), (',', ',')]



========================================== PARAGRAPH 143 ===========================================

levels that bestow to meaning. Semantic processing determines the possible meanings of a  

------------------- Sentence 1 -------------------

levels that bestow to meaning.

>> Tokens are: 
 ['levels', 'bestow', 'meaning', '.']

>> Bigrams are: 
 [('levels', 'bestow'), ('bestow', 'meaning'), ('meaning', '.')]

>> Trigrams are: 
 [('levels', 'bestow', 'meaning'), ('bestow', 'meaning', '.')]

>> POS Tags are: 
 [('levels', 'NNS'), ('bestow', 'VBP'), ('meaning', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['levels', 'meaning']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('levels', 'level'), ('bestow', 'bestow'), ('meaning', 'mean'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('levels', 'level'), ('bestow', 'bestow'), ('meaning', 'mean'), ('.', '.')]

>> Lemmatization: 
 [('levels', 'level'), ('bestow', 'bestow'), ('meaning', 'meaning'), ('.', '.')]


------------------- Sentence 2 -------------------

Semantic processing determines the possible meanings of a

>> Tokens are: 
 ['Semantic', 'processing', 'determines', 'possible', 'meanings']

>> Bigrams are: 
 [('Semantic', 'processing'), ('processing', 'determines'), ('determines', 'possible'), ('possible', 'meanings')]

>> Trigrams are: 
 [('Semantic', 'processing', 'determines'), ('processing', 'determines', 'possible'), ('determines', 'possible', 'meanings')]

>> POS Tags are: 
 [('Semantic', 'JJ'), ('processing', 'NN'), ('determines', 'NNS'), ('possible', 'JJ'), ('meanings', 'NNS')]

>> Noun Phrases are: 
 ['Semantic processing determines', 'possible meanings']

>> Named Entities are: 
 [('GPE', 'Semantic')] 

>> Stemming using Porter Stemmer: 
 [('Semantic', 'semant'), ('processing', 'process'), ('determines', 'determin'), ('possible', 'possibl'), ('meanings', 'mean')]

>> Stemming using Snowball Stemmer: 
 [('Semantic', 'semant'), ('processing', 'process'), ('determines', 'determin'), ('possible', 'possibl'), ('meanings', 'mean')]

>> Lemmatization: 
 [('Semantic', 'Semantic'), ('processing', 'processing'), ('determines', 'determines'), ('possible', 'possible'), ('meanings', 'meaning')]



========================================== PARAGRAPH 144 ===========================================

sentence by pivoting on the interactions among word-level meanings in the sentence. This  

------------------- Sentence 1 -------------------

sentence by pivoting on the interactions among word-level meanings in the sentence.

>> Tokens are: 
 ['sentence', 'pivoting', 'interactions', 'among', 'word-level', 'meanings', 'sentence', '.']

>> Bigrams are: 
 [('sentence', 'pivoting'), ('pivoting', 'interactions'), ('interactions', 'among'), ('among', 'word-level'), ('word-level', 'meanings'), ('meanings', 'sentence'), ('sentence', '.')]

>> Trigrams are: 
 [('sentence', 'pivoting', 'interactions'), ('pivoting', 'interactions', 'among'), ('interactions', 'among', 'word-level'), ('among', 'word-level', 'meanings'), ('word-level', 'meanings', 'sentence'), ('meanings', 'sentence', '.')]

>> POS Tags are: 
 [('sentence', 'NN'), ('pivoting', 'VBG'), ('interactions', 'NNS'), ('among', 'IN'), ('word-level', 'JJ'), ('meanings', 'NNS'), ('sentence', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['sentence', 'interactions', 'word-level meanings sentence']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('sentence', 'sentenc'), ('pivoting', 'pivot'), ('interactions', 'interact'), ('among', 'among'), ('word-level', 'word-level'), ('meanings', 'mean'), ('sentence', 'sentenc'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('sentence', 'sentenc'), ('pivoting', 'pivot'), ('interactions', 'interact'), ('among', 'among'), ('word-level', 'word-level'), ('meanings', 'mean'), ('sentence', 'sentenc'), ('.', '.')]

>> Lemmatization: 
 [('sentence', 'sentence'), ('pivoting', 'pivoting'), ('interactions', 'interaction'), ('among', 'among'), ('word-level', 'word-level'), ('meanings', 'meaning'), ('sentence', 'sentence'), ('.', '.')]


------------------- Sentence 2 -------------------

This

>> Tokens are: 
 ['This']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('This', 'DT')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('This', 'thi')]

>> Stemming using Snowball Stemmer: 
 [('This', 'this')]

>> Lemmatization: 
 [('This', 'This')]



========================================== PARAGRAPH 145 ===========================================

level of processing can incorporate the semantic disambiguation of words with multiple  

------------------- Sentence 1 -------------------

level of processing can incorporate the semantic disambiguation of words with multiple

>> Tokens are: 
 ['level', 'processing', 'incorporate', 'semantic', 'disambiguation', 'words', 'multiple']

>> Bigrams are: 
 [('level', 'processing'), ('processing', 'incorporate'), ('incorporate', 'semantic'), ('semantic', 'disambiguation'), ('disambiguation', 'words'), ('words', 'multiple')]

>> Trigrams are: 
 [('level', 'processing', 'incorporate'), ('processing', 'incorporate', 'semantic'), ('incorporate', 'semantic', 'disambiguation'), ('semantic', 'disambiguation', 'words'), ('disambiguation', 'words', 'multiple')]

>> POS Tags are: 
 [('level', 'NN'), ('processing', 'NN'), ('incorporate', 'JJ'), ('semantic', 'JJ'), ('disambiguation', 'NN'), ('words', 'NNS'), ('multiple', 'NN')]

>> Noun Phrases are: 
 ['level processing', 'incorporate semantic disambiguation words multiple']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('level', 'level'), ('processing', 'process'), ('incorporate', 'incorpor'), ('semantic', 'semant'), ('disambiguation', 'disambigu'), ('words', 'word'), ('multiple', 'multipl')]

>> Stemming using Snowball Stemmer: 
 [('level', 'level'), ('processing', 'process'), ('incorporate', 'incorpor'), ('semantic', 'semant'), ('disambiguation', 'disambigu'), ('words', 'word'), ('multiple', 'multipl')]

>> Lemmatization: 
 [('level', 'level'), ('processing', 'processing'), ('incorporate', 'incorporate'), ('semantic', 'semantic'), ('disambiguation', 'disambiguation'), ('words', 'word'), ('multiple', 'multiple')]



========================================== PARAGRAPH 146 ===========================================

senses; in a cognate way to how syntactic disambiguation of words that can errand as  

------------------- Sentence 1 -------------------

senses; in a cognate way to how syntactic disambiguation of words that can errand as

>> Tokens are: 
 ['senses', ';', 'cognate', 'way', 'syntactic', 'disambiguation', 'words', 'errand']

>> Bigrams are: 
 [('senses', ';'), (';', 'cognate'), ('cognate', 'way'), ('way', 'syntactic'), ('syntactic', 'disambiguation'), ('disambiguation', 'words'), ('words', 'errand')]

>> Trigrams are: 
 [('senses', ';', 'cognate'), (';', 'cognate', 'way'), ('cognate', 'way', 'syntactic'), ('way', 'syntactic', 'disambiguation'), ('syntactic', 'disambiguation', 'words'), ('disambiguation', 'words', 'errand')]

>> POS Tags are: 
 [('senses', 'NNS'), (';', ':'), ('cognate', 'VB'), ('way', 'NN'), ('syntactic', 'JJ'), ('disambiguation', 'NN'), ('words', 'NNS'), ('errand', 'VBP')]

>> Noun Phrases are: 
 ['senses', 'way', 'syntactic disambiguation words']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('senses', 'sens'), (';', ';'), ('cognate', 'cognat'), ('way', 'way'), ('syntactic', 'syntact'), ('disambiguation', 'disambigu'), ('words', 'word'), ('errand', 'errand')]

>> Stemming using Snowball Stemmer: 
 [('senses', 'sens'), (';', ';'), ('cognate', 'cognat'), ('way', 'way'), ('syntactic', 'syntact'), ('disambiguation', 'disambigu'), ('words', 'word'), ('errand', 'errand')]

>> Lemmatization: 
 [('senses', 'sens'), (';', ';'), ('cognate', 'cognate'), ('way', 'way'), ('syntactic', 'syntactic'), ('disambiguation', 'disambiguation'), ('words', 'word'), ('errand', 'errand')]



========================================== PARAGRAPH 147 ===========================================

multiple parts-of-speech is adroit at the syntactic level. For example, amongst other  

------------------- Sentence 1 -------------------

multiple parts-of-speech is adroit at the syntactic level.

>> Tokens are: 
 ['multiple', 'parts-of-speech', 'adroit', 'syntactic', 'level', '.']

>> Bigrams are: 
 [('multiple', 'parts-of-speech'), ('parts-of-speech', 'adroit'), ('adroit', 'syntactic'), ('syntactic', 'level'), ('level', '.')]

>> Trigrams are: 
 [('multiple', 'parts-of-speech', 'adroit'), ('parts-of-speech', 'adroit', 'syntactic'), ('adroit', 'syntactic', 'level'), ('syntactic', 'level', '.')]

>> POS Tags are: 
 [('multiple', 'JJ'), ('parts-of-speech', 'JJ'), ('adroit', 'JJ'), ('syntactic', 'JJ'), ('level', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['multiple parts-of-speech adroit syntactic level']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('multiple', 'multipl'), ('parts-of-speech', 'parts-of-speech'), ('adroit', 'adroit'), ('syntactic', 'syntact'), ('level', 'level'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('multiple', 'multipl'), ('parts-of-speech', 'parts-of-speech'), ('adroit', 'adroit'), ('syntactic', 'syntact'), ('level', 'level'), ('.', '.')]

>> Lemmatization: 
 [('multiple', 'multiple'), ('parts-of-speech', 'parts-of-speech'), ('adroit', 'adroit'), ('syntactic', 'syntactic'), ('level', 'level'), ('.', '.')]


------------------- Sentence 2 -------------------

For example, amongst other

>> Tokens are: 
 ['For', 'example', ',', 'amongst']

>> Bigrams are: 
 [('For', 'example'), ('example', ','), (',', 'amongst')]

>> Trigrams are: 
 [('For', 'example', ','), ('example', ',', 'amongst')]

>> POS Tags are: 
 [('For', 'IN'), ('example', 'NN'), (',', ','), ('amongst', 'NN')]

>> Noun Phrases are: 
 ['example', 'amongst']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('For', 'for'), ('example', 'exampl'), (',', ','), ('amongst', 'amongst')]

>> Stemming using Snowball Stemmer: 
 [('For', 'for'), ('example', 'exampl'), (',', ','), ('amongst', 'amongst')]

>> Lemmatization: 
 [('For', 'For'), ('example', 'example'), (',', ','), ('amongst', 'amongst')]



========================================== PARAGRAPH 148 ===========================================

meanings, ‘file’ as a noun can mean either a binder for gathering papers, or a tool to form  

------------------- Sentence 1 -------------------

meanings, ‘file’ as a noun can mean either a binder for gathering papers, or a tool to form

>> Tokens are: 
 ['meanings', ',', '‘', 'file', '’', 'noun', 'mean', 'either', 'binder', 'gathering', 'papers', ',', 'tool', 'form']

>> Bigrams are: 
 [('meanings', ','), (',', '‘'), ('‘', 'file'), ('file', '’'), ('’', 'noun'), ('noun', 'mean'), ('mean', 'either'), ('either', 'binder'), ('binder', 'gathering'), ('gathering', 'papers'), ('papers', ','), (',', 'tool'), ('tool', 'form')]

>> Trigrams are: 
 [('meanings', ',', '‘'), (',', '‘', 'file'), ('‘', 'file', '’'), ('file', '’', 'noun'), ('’', 'noun', 'mean'), ('noun', 'mean', 'either'), ('mean', 'either', 'binder'), ('either', 'binder', 'gathering'), ('binder', 'gathering', 'papers'), ('gathering', 'papers', ','), ('papers', ',', 'tool'), (',', 'tool', 'form')]

>> POS Tags are: 
 [('meanings', 'NNS'), (',', ','), ('‘', 'NNP'), ('file', 'NN'), ('’', 'NNP'), ('noun', 'CC'), ('mean', 'VBP'), ('either', 'DT'), ('binder', 'NN'), ('gathering', 'NN'), ('papers', 'NNS'), (',', ','), ('tool', 'NN'), ('form', 'NN')]

>> Noun Phrases are: 
 ['meanings', '‘ file ’', 'either binder gathering papers', 'tool form']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('meanings', 'mean'), (',', ','), ('‘', '‘'), ('file', 'file'), ('’', '’'), ('noun', 'noun'), ('mean', 'mean'), ('either', 'either'), ('binder', 'binder'), ('gathering', 'gather'), ('papers', 'paper'), (',', ','), ('tool', 'tool'), ('form', 'form')]

>> Stemming using Snowball Stemmer: 
 [('meanings', 'mean'), (',', ','), ('‘', '‘'), ('file', 'file'), ('’', '’'), ('noun', 'noun'), ('mean', 'mean'), ('either', 'either'), ('binder', 'binder'), ('gathering', 'gather'), ('papers', 'paper'), (',', ','), ('tool', 'tool'), ('form', 'form')]

>> Lemmatization: 
 [('meanings', 'meaning'), (',', ','), ('‘', '‘'), ('file', 'file'), ('’', '’'), ('noun', 'noun'), ('mean', 'mean'), ('either', 'either'), ('binder', 'binder'), ('gathering', 'gathering'), ('papers', 'paper'), (',', ','), ('tool', 'tool'), ('form', 'form')]



========================================== PARAGRAPH 149 ===========================================

one’s fingernails, or a line of individuals in a queue (Elizabeth D. Liddy,2001) [7]. The  

------------------- Sentence 1 -------------------

one’s fingernails, or a line of individuals in a queue (Elizabeth D. Liddy,2001) [7].

>> Tokens are: 
 ['one', '’', 'fingernails', ',', 'line', 'individuals', 'queue', '(', 'Elizabeth', 'D.', 'Liddy,2001', ')', '[', '7', ']', '.']

>> Bigrams are: 
 [('one', '’'), ('’', 'fingernails'), ('fingernails', ','), (',', 'line'), ('line', 'individuals'), ('individuals', 'queue'), ('queue', '('), ('(', 'Elizabeth'), ('Elizabeth', 'D.'), ('D.', 'Liddy,2001'), ('Liddy,2001', ')'), (')', '['), ('[', '7'), ('7', ']'), (']', '.')]

>> Trigrams are: 
 [('one', '’', 'fingernails'), ('’', 'fingernails', ','), ('fingernails', ',', 'line'), (',', 'line', 'individuals'), ('line', 'individuals', 'queue'), ('individuals', 'queue', '('), ('queue', '(', 'Elizabeth'), ('(', 'Elizabeth', 'D.'), ('Elizabeth', 'D.', 'Liddy,2001'), ('D.', 'Liddy,2001', ')'), ('Liddy,2001', ')', '['), (')', '[', '7'), ('[', '7', ']'), ('7', ']', '.')]

>> POS Tags are: 
 [('one', 'CD'), ('’', 'NN'), ('fingernails', 'NNS'), (',', ','), ('line', 'NN'), ('individuals', 'NNS'), ('queue', 'VBP'), ('(', '('), ('Elizabeth', 'NNP'), ('D.', 'NNP'), ('Liddy,2001', 'NNP'), (')', ')'), ('[', 'VBD'), ('7', 'CD'), (']', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['’ fingernails', 'line individuals', 'Elizabeth D. Liddy,2001', ']']

>> Named Entities are: 
 [('PERSON', 'Elizabeth D.')] 

>> Stemming using Porter Stemmer: 
 [('one', 'one'), ('’', '’'), ('fingernails', 'fingernail'), (',', ','), ('line', 'line'), ('individuals', 'individu'), ('queue', 'queue'), ('(', '('), ('Elizabeth', 'elizabeth'), ('D.', 'd.'), ('Liddy,2001', 'liddy,2001'), (')', ')'), ('[', '['), ('7', '7'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('one', 'one'), ('’', '’'), ('fingernails', 'fingernail'), (',', ','), ('line', 'line'), ('individuals', 'individu'), ('queue', 'queue'), ('(', '('), ('Elizabeth', 'elizabeth'), ('D.', 'd.'), ('Liddy,2001', 'liddy,2001'), (')', ')'), ('[', '['), ('7', '7'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('one', 'one'), ('’', '’'), ('fingernails', 'fingernail'), (',', ','), ('line', 'line'), ('individuals', 'individual'), ('queue', 'queue'), ('(', '('), ('Elizabeth', 'Elizabeth'), ('D.', 'D.'), ('Liddy,2001', 'Liddy,2001'), (')', ')'), ('[', '['), ('7', '7'), (']', ']'), ('.', '.')]


------------------- Sentence 2 -------------------

The

>> Tokens are: 
 ['The']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('The', 'DT')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the')]

>> Lemmatization: 
 [('The', 'The')]



========================================== PARAGRAPH 150 ===========================================

semantic level scrutinizes words for their dictionary elucidation, but also for the elucidation  

------------------- Sentence 1 -------------------

semantic level scrutinizes words for their dictionary elucidation, but also for the elucidation

>> Tokens are: 
 ['semantic', 'level', 'scrutinizes', 'words', 'dictionary', 'elucidation', ',', 'also', 'elucidation']

>> Bigrams are: 
 [('semantic', 'level'), ('level', 'scrutinizes'), ('scrutinizes', 'words'), ('words', 'dictionary'), ('dictionary', 'elucidation'), ('elucidation', ','), (',', 'also'), ('also', 'elucidation')]

>> Trigrams are: 
 [('semantic', 'level', 'scrutinizes'), ('level', 'scrutinizes', 'words'), ('scrutinizes', 'words', 'dictionary'), ('words', 'dictionary', 'elucidation'), ('dictionary', 'elucidation', ','), ('elucidation', ',', 'also'), (',', 'also', 'elucidation')]

>> POS Tags are: 
 [('semantic', 'JJ'), ('level', 'NN'), ('scrutinizes', 'NNS'), ('words', 'NNS'), ('dictionary', 'JJ'), ('elucidation', 'NN'), (',', ','), ('also', 'RB'), ('elucidation', 'NN')]

>> Noun Phrases are: 
 ['semantic level scrutinizes words', 'dictionary elucidation', 'elucidation']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('semantic', 'semant'), ('level', 'level'), ('scrutinizes', 'scrutin'), ('words', 'word'), ('dictionary', 'dictionari'), ('elucidation', 'elucid'), (',', ','), ('also', 'also'), ('elucidation', 'elucid')]

>> Stemming using Snowball Stemmer: 
 [('semantic', 'semant'), ('level', 'level'), ('scrutinizes', 'scrutin'), ('words', 'word'), ('dictionary', 'dictionari'), ('elucidation', 'elucid'), (',', ','), ('also', 'also'), ('elucidation', 'elucid')]

>> Lemmatization: 
 [('semantic', 'semantic'), ('level', 'level'), ('scrutinizes', 'scrutinizes'), ('words', 'word'), ('dictionary', 'dictionary'), ('elucidation', 'elucidation'), (',', ','), ('also', 'also'), ('elucidation', 'elucidation')]



========================================== PARAGRAPH 151 ===========================================

they derive from the milieu of the sentence. Semantics milieu that most words have more  

------------------- Sentence 1 -------------------

they derive from the milieu of the sentence.

>> Tokens are: 
 ['derive', 'milieu', 'sentence', '.']

>> Bigrams are: 
 [('derive', 'milieu'), ('milieu', 'sentence'), ('sentence', '.')]

>> Trigrams are: 
 [('derive', 'milieu', 'sentence'), ('milieu', 'sentence', '.')]

>> POS Tags are: 
 [('derive', 'JJ'), ('milieu', 'NN'), ('sentence', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['derive milieu sentence']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('derive', 'deriv'), ('milieu', 'milieu'), ('sentence', 'sentenc'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('derive', 'deriv'), ('milieu', 'milieu'), ('sentence', 'sentenc'), ('.', '.')]

>> Lemmatization: 
 [('derive', 'derive'), ('milieu', 'milieu'), ('sentence', 'sentence'), ('.', '.')]


------------------- Sentence 2 -------------------

Semantics milieu that most words have more

>> Tokens are: 
 ['Semantics', 'milieu', 'words']

>> Bigrams are: 
 [('Semantics', 'milieu'), ('milieu', 'words')]

>> Trigrams are: 
 [('Semantics', 'milieu', 'words')]

>> POS Tags are: 
 [('Semantics', 'NNS'), ('milieu', 'VBP'), ('words', 'NNS')]

>> Noun Phrases are: 
 ['Semantics', 'words']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Semantics', 'semant'), ('milieu', 'milieu'), ('words', 'word')]

>> Stemming using Snowball Stemmer: 
 [('Semantics', 'semant'), ('milieu', 'milieu'), ('words', 'word')]

>> Lemmatization: 
 [('Semantics', 'Semantics'), ('milieu', 'milieu'), ('words', 'word')]



========================================== PARAGRAPH 152 ===========================================

than one elucidation but that we can spot the appropriate one by looking at the rest of the  

------------------- Sentence 1 -------------------

than one elucidation but that we can spot the appropriate one by looking at the rest of the

>> Tokens are: 
 ['one', 'elucidation', 'spot', 'appropriate', 'one', 'looking', 'rest']

>> Bigrams are: 
 [('one', 'elucidation'), ('elucidation', 'spot'), ('spot', 'appropriate'), ('appropriate', 'one'), ('one', 'looking'), ('looking', 'rest')]

>> Trigrams are: 
 [('one', 'elucidation', 'spot'), ('elucidation', 'spot', 'appropriate'), ('spot', 'appropriate', 'one'), ('appropriate', 'one', 'looking'), ('one', 'looking', 'rest')]

>> POS Tags are: 
 [('one', 'CD'), ('elucidation', 'NN'), ('spot', 'NN'), ('appropriate', 'VBP'), ('one', 'CD'), ('looking', 'VBG'), ('rest', 'NN')]

>> Noun Phrases are: 
 ['elucidation spot', 'rest']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('one', 'one'), ('elucidation', 'elucid'), ('spot', 'spot'), ('appropriate', 'appropri'), ('one', 'one'), ('looking', 'look'), ('rest', 'rest')]

>> Stemming using Snowball Stemmer: 
 [('one', 'one'), ('elucidation', 'elucid'), ('spot', 'spot'), ('appropriate', 'appropri'), ('one', 'one'), ('looking', 'look'), ('rest', 'rest')]

>> Lemmatization: 
 [('one', 'one'), ('elucidation', 'elucidation'), ('spot', 'spot'), ('appropriate', 'appropriate'), ('one', 'one'), ('looking', 'looking'), ('rest', 'rest')]



========================================== PARAGRAPH 153 ===========================================

sentence. [8]  

------------------- Sentence 1 -------------------

sentence.

>> Tokens are: 
 ['sentence', '.']

>> Bigrams are: 
 [('sentence', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('sentence', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['sentence']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('sentence', 'sentenc'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('sentence', 'sentenc'), ('.', '.')]

>> Lemmatization: 
 [('sentence', 'sentence'), ('.', '.')]


------------------- Sentence 2 -------------------

[8]

>> Tokens are: 
 ['[', '8', ']']

>> Bigrams are: 
 [('[', '8'), ('8', ']')]

>> Trigrams are: 
 [('[', '8', ']')]

>> POS Tags are: 
 [('[', 'RB'), ('8', 'CD'), (']', 'NNS')]

>> Noun Phrases are: 
 [']']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('8', '8'), (']', ']')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('8', '8'), (']', ']')]

>> Lemmatization: 
 [('[', '['), ('8', '8'), (']', ']')]



========================================== PARAGRAPH 154 ===========================================

6. Discourse  

------------------- Sentence 1 -------------------

6.

>> Tokens are: 
 ['6', '.']

>> Bigrams are: 
 [('6', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('6', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('6', '6'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('6', '6'), ('.', '.')]

>> Lemmatization: 
 [('6', '6'), ('.', '.')]


------------------- Sentence 2 -------------------

Discourse

>> Tokens are: 
 ['Discourse']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Discourse', 'NN')]

>> Noun Phrases are: 
 ['Discourse']

>> Named Entities are: 
 [('GPE', 'Discourse')] 

>> Stemming using Porter Stemmer: 
 [('Discourse', 'discours')]

>> Stemming using Snowball Stemmer: 
 [('Discourse', 'discours')]

>> Lemmatization: 
 [('Discourse', 'Discourse')]



========================================== PARAGRAPH 155 ===========================================

While syntax and semantics travail with sentence-length units, the discourse level of NLP  

------------------- Sentence 1 -------------------

While syntax and semantics travail with sentence-length units, the discourse level of NLP

>> Tokens are: 
 ['While', 'syntax', 'semantics', 'travail', 'sentence-length', 'units', ',', 'discourse', 'level', 'NLP']

>> Bigrams are: 
 [('While', 'syntax'), ('syntax', 'semantics'), ('semantics', 'travail'), ('travail', 'sentence-length'), ('sentence-length', 'units'), ('units', ','), (',', 'discourse'), ('discourse', 'level'), ('level', 'NLP')]

>> Trigrams are: 
 [('While', 'syntax', 'semantics'), ('syntax', 'semantics', 'travail'), ('semantics', 'travail', 'sentence-length'), ('travail', 'sentence-length', 'units'), ('sentence-length', 'units', ','), ('units', ',', 'discourse'), (',', 'discourse', 'level'), ('discourse', 'level', 'NLP')]

>> POS Tags are: 
 [('While', 'IN'), ('syntax', 'JJ'), ('semantics', 'NNS'), ('travail', 'JJ'), ('sentence-length', 'JJ'), ('units', 'NNS'), (',', ','), ('discourse', 'JJ'), ('level', 'NN'), ('NLP', 'NNP')]

>> Noun Phrases are: 
 ['syntax semantics', 'travail sentence-length units', 'discourse level NLP']

>> Named Entities are: 
 [('ORGANIZATION', 'NLP')] 

>> Stemming using Porter Stemmer: 
 [('While', 'while'), ('syntax', 'syntax'), ('semantics', 'semant'), ('travail', 'travail'), ('sentence-length', 'sentence-length'), ('units', 'unit'), (',', ','), ('discourse', 'discours'), ('level', 'level'), ('NLP', 'nlp')]

>> Stemming using Snowball Stemmer: 
 [('While', 'while'), ('syntax', 'syntax'), ('semantics', 'semant'), ('travail', 'travail'), ('sentence-length', 'sentence-length'), ('units', 'unit'), (',', ','), ('discourse', 'discours'), ('level', 'level'), ('NLP', 'nlp')]

>> Lemmatization: 
 [('While', 'While'), ('syntax', 'syntax'), ('semantics', 'semantics'), ('travail', 'travail'), ('sentence-length', 'sentence-length'), ('units', 'unit'), (',', ','), ('discourse', 'discourse'), ('level', 'level'), ('NLP', 'NLP')]



========================================== PARAGRAPH 156 ===========================================

travail with units of text longer than a sentence i.e, it does not interpret multi sentence texts as  

------------------- Sentence 1 -------------------

travail with units of text longer than a sentence i.e, it does not interpret multi sentence texts as

>> Tokens are: 
 ['travail', 'units', 'text', 'longer', 'sentence', 'i.e', ',', 'interpret', 'multi', 'sentence', 'texts']

>> Bigrams are: 
 [('travail', 'units'), ('units', 'text'), ('text', 'longer'), ('longer', 'sentence'), ('sentence', 'i.e'), ('i.e', ','), (',', 'interpret'), ('interpret', 'multi'), ('multi', 'sentence'), ('sentence', 'texts')]

>> Trigrams are: 
 [('travail', 'units', 'text'), ('units', 'text', 'longer'), ('text', 'longer', 'sentence'), ('longer', 'sentence', 'i.e'), ('sentence', 'i.e', ','), ('i.e', ',', 'interpret'), (',', 'interpret', 'multi'), ('interpret', 'multi', 'sentence'), ('multi', 'sentence', 'texts')]

>> POS Tags are: 
 [('travail', 'JJ'), ('units', 'NNS'), ('text', 'RB'), ('longer', 'RBR'), ('sentence', 'NN'), ('i.e', 'NN'), (',', ','), ('interpret', 'JJ'), ('multi', 'NN'), ('sentence', 'NN'), ('texts', 'NN')]

>> Noun Phrases are: 
 ['travail units', 'sentence i.e', 'interpret multi sentence texts']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('travail', 'travail'), ('units', 'unit'), ('text', 'text'), ('longer', 'longer'), ('sentence', 'sentenc'), ('i.e', 'i.e'), (',', ','), ('interpret', 'interpret'), ('multi', 'multi'), ('sentence', 'sentenc'), ('texts', 'text')]

>> Stemming using Snowball Stemmer: 
 [('travail', 'travail'), ('units', 'unit'), ('text', 'text'), ('longer', 'longer'), ('sentence', 'sentenc'), ('i.e', 'i.e'), (',', ','), ('interpret', 'interpret'), ('multi', 'multi'), ('sentence', 'sentenc'), ('texts', 'text')]

>> Lemmatization: 
 [('travail', 'travail'), ('units', 'unit'), ('text', 'text'), ('longer', 'longer'), ('sentence', 'sentence'), ('i.e', 'i.e'), (',', ','), ('interpret', 'interpret'), ('multi', 'multi'), ('sentence', 'sentence'), ('texts', 'text')]



========================================== PARAGRAPH 157 ===========================================

just sequence sentences, apiece of which can be elucidated singly. Rather, discourse focuses  

------------------- Sentence 1 -------------------

just sequence sentences, apiece of which can be elucidated singly.

>> Tokens are: 
 ['sequence', 'sentences', ',', 'apiece', 'elucidated', 'singly', '.']

>> Bigrams are: 
 [('sequence', 'sentences'), ('sentences', ','), (',', 'apiece'), ('apiece', 'elucidated'), ('elucidated', 'singly'), ('singly', '.')]

>> Trigrams are: 
 [('sequence', 'sentences', ','), ('sentences', ',', 'apiece'), (',', 'apiece', 'elucidated'), ('apiece', 'elucidated', 'singly'), ('elucidated', 'singly', '.')]

>> POS Tags are: 
 [('sequence', 'NN'), ('sentences', 'NNS'), (',', ','), ('apiece', 'RB'), ('elucidated', 'VBN'), ('singly', 'RB'), ('.', '.')]

>> Noun Phrases are: 
 ['sequence sentences']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('sequence', 'sequenc'), ('sentences', 'sentenc'), (',', ','), ('apiece', 'apiec'), ('elucidated', 'elucid'), ('singly', 'singli'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('sequence', 'sequenc'), ('sentences', 'sentenc'), (',', ','), ('apiece', 'apiec'), ('elucidated', 'elucid'), ('singly', 'singl'), ('.', '.')]

>> Lemmatization: 
 [('sequence', 'sequence'), ('sentences', 'sentence'), (',', ','), ('apiece', 'apiece'), ('elucidated', 'elucidated'), ('singly', 'singly'), ('.', '.')]


------------------- Sentence 2 -------------------

Rather, discourse focuses

>> Tokens are: 
 ['Rather', ',', 'discourse', 'focuses']

>> Bigrams are: 
 [('Rather', ','), (',', 'discourse'), ('discourse', 'focuses')]

>> Trigrams are: 
 [('Rather', ',', 'discourse'), (',', 'discourse', 'focuses')]

>> POS Tags are: 
 [('Rather', 'RB'), (',', ','), ('discourse', 'NN'), ('focuses', 'NNS')]

>> Noun Phrases are: 
 ['discourse focuses']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Rather', 'rather'), (',', ','), ('discourse', 'discours'), ('focuses', 'focus')]

>> Stemming using Snowball Stemmer: 
 [('Rather', 'rather'), (',', ','), ('discourse', 'discours'), ('focuses', 'focus')]

>> Lemmatization: 
 [('Rather', 'Rather'), (',', ','), ('discourse', 'discourse'), ('focuses', 'focus')]



========================================== PARAGRAPH 158 ===========================================

on the properties of the text as a whole that convey meaning by making connections between  

------------------- Sentence 1 -------------------

on the properties of the text as a whole that convey meaning by making connections between

>> Tokens are: 
 ['properties', 'text', 'whole', 'convey', 'meaning', 'making', 'connections']

>> Bigrams are: 
 [('properties', 'text'), ('text', 'whole'), ('whole', 'convey'), ('convey', 'meaning'), ('meaning', 'making'), ('making', 'connections')]

>> Trigrams are: 
 [('properties', 'text', 'whole'), ('text', 'whole', 'convey'), ('whole', 'convey', 'meaning'), ('convey', 'meaning', 'making'), ('meaning', 'making', 'connections')]

>> POS Tags are: 
 [('properties', 'NNS'), ('text', 'VBP'), ('whole', 'JJ'), ('convey', 'NN'), ('meaning', 'VBG'), ('making', 'VBG'), ('connections', 'NNS')]

>> Noun Phrases are: 
 ['properties', 'whole convey', 'connections']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('properties', 'properti'), ('text', 'text'), ('whole', 'whole'), ('convey', 'convey'), ('meaning', 'mean'), ('making', 'make'), ('connections', 'connect')]

>> Stemming using Snowball Stemmer: 
 [('properties', 'properti'), ('text', 'text'), ('whole', 'whole'), ('convey', 'convey'), ('meaning', 'mean'), ('making', 'make'), ('connections', 'connect')]

>> Lemmatization: 
 [('properties', 'property'), ('text', 'text'), ('whole', 'whole'), ('convey', 'convey'), ('meaning', 'meaning'), ('making', 'making'), ('connections', 'connection')]



========================================== PARAGRAPH 159 ===========================================

component sentences (Elizabeth D. Liddy,2001) [7]. The two of the most common levels are  

------------------- Sentence 1 -------------------

component sentences (Elizabeth D. Liddy,2001) [7].

>> Tokens are: 
 ['component', 'sentences', '(', 'Elizabeth', 'D.', 'Liddy,2001', ')', '[', '7', ']', '.']

>> Bigrams are: 
 [('component', 'sentences'), ('sentences', '('), ('(', 'Elizabeth'), ('Elizabeth', 'D.'), ('D.', 'Liddy,2001'), ('Liddy,2001', ')'), (')', '['), ('[', '7'), ('7', ']'), (']', '.')]

>> Trigrams are: 
 [('component', 'sentences', '('), ('sentences', '(', 'Elizabeth'), ('(', 'Elizabeth', 'D.'), ('Elizabeth', 'D.', 'Liddy,2001'), ('D.', 'Liddy,2001', ')'), ('Liddy,2001', ')', '['), (')', '[', '7'), ('[', '7', ']'), ('7', ']', '.')]

>> POS Tags are: 
 [('component', 'NN'), ('sentences', 'NNS'), ('(', '('), ('Elizabeth', 'NNP'), ('D.', 'NNP'), ('Liddy,2001', 'NNP'), (')', ')'), ('[', 'VBD'), ('7', 'CD'), (']', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['component sentences', 'Elizabeth D. Liddy,2001', ']']

>> Named Entities are: 
 [('PERSON', 'Elizabeth D.')] 

>> Stemming using Porter Stemmer: 
 [('component', 'compon'), ('sentences', 'sentenc'), ('(', '('), ('Elizabeth', 'elizabeth'), ('D.', 'd.'), ('Liddy,2001', 'liddy,2001'), (')', ')'), ('[', '['), ('7', '7'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('component', 'compon'), ('sentences', 'sentenc'), ('(', '('), ('Elizabeth', 'elizabeth'), ('D.', 'd.'), ('Liddy,2001', 'liddy,2001'), (')', ')'), ('[', '['), ('7', '7'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('component', 'component'), ('sentences', 'sentence'), ('(', '('), ('Elizabeth', 'Elizabeth'), ('D.', 'D.'), ('Liddy,2001', 'Liddy,2001'), (')', ')'), ('[', '['), ('7', '7'), (']', ']'), ('.', '.')]


------------------- Sentence 2 -------------------

The two of the most common levels are

>> Tokens are: 
 ['The', 'two', 'common', 'levels']

>> Bigrams are: 
 [('The', 'two'), ('two', 'common'), ('common', 'levels')]

>> Trigrams are: 
 [('The', 'two', 'common'), ('two', 'common', 'levels')]

>> POS Tags are: 
 [('The', 'DT'), ('two', 'CD'), ('common', 'JJ'), ('levels', 'NNS')]

>> Noun Phrases are: 
 ['common levels']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('two', 'two'), ('common', 'common'), ('levels', 'level')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('two', 'two'), ('common', 'common'), ('levels', 'level')]

>> Lemmatization: 
 [('The', 'The'), ('two', 'two'), ('common', 'common'), ('levels', 'level')]



========================================== PARAGRAPH 160 ===========================================

Anaphora Resolution - Anaphora resolution is the replacing of words such as pronouns,  

------------------- Sentence 1 -------------------

Anaphora Resolution - Anaphora resolution is the replacing of words such as pronouns,

>> Tokens are: 
 ['Anaphora', 'Resolution', '-', 'Anaphora', 'resolution', 'replacing', 'words', 'pronouns', ',']

>> Bigrams are: 
 [('Anaphora', 'Resolution'), ('Resolution', '-'), ('-', 'Anaphora'), ('Anaphora', 'resolution'), ('resolution', 'replacing'), ('replacing', 'words'), ('words', 'pronouns'), ('pronouns', ',')]

>> Trigrams are: 
 [('Anaphora', 'Resolution', '-'), ('Resolution', '-', 'Anaphora'), ('-', 'Anaphora', 'resolution'), ('Anaphora', 'resolution', 'replacing'), ('resolution', 'replacing', 'words'), ('replacing', 'words', 'pronouns'), ('words', 'pronouns', ',')]

>> POS Tags are: 
 [('Anaphora', 'NNP'), ('Resolution', 'NNP'), ('-', ':'), ('Anaphora', 'NNP'), ('resolution', 'NN'), ('replacing', 'VBG'), ('words', 'NNS'), ('pronouns', 'NNS'), (',', ',')]

>> Noun Phrases are: 
 ['Anaphora Resolution', 'Anaphora resolution', 'words pronouns']

>> Named Entities are: 
 [('PERSON', 'Anaphora'), ('ORGANIZATION', 'Resolution'), ('GPE', 'Anaphora')] 

>> Stemming using Porter Stemmer: 
 [('Anaphora', 'anaphora'), ('Resolution', 'resolut'), ('-', '-'), ('Anaphora', 'anaphora'), ('resolution', 'resolut'), ('replacing', 'replac'), ('words', 'word'), ('pronouns', 'pronoun'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('Anaphora', 'anaphora'), ('Resolution', 'resolut'), ('-', '-'), ('Anaphora', 'anaphora'), ('resolution', 'resolut'), ('replacing', 'replac'), ('words', 'word'), ('pronouns', 'pronoun'), (',', ',')]

>> Lemmatization: 
 [('Anaphora', 'Anaphora'), ('Resolution', 'Resolution'), ('-', '-'), ('Anaphora', 'Anaphora'), ('resolution', 'resolution'), ('replacing', 'replacing'), ('words', 'word'), ('pronouns', 'pronoun'), (',', ',')]



========================================== PARAGRAPH 161 ===========================================

which are semantically stranded, with the pertinent entity to which they refer. Discourse/Text  

------------------- Sentence 1 -------------------

which are semantically stranded, with the pertinent entity to which they refer.

>> Tokens are: 
 ['semantically', 'stranded', ',', 'pertinent', 'entity', 'refer', '.']

>> Bigrams are: 
 [('semantically', 'stranded'), ('stranded', ','), (',', 'pertinent'), ('pertinent', 'entity'), ('entity', 'refer'), ('refer', '.')]

>> Trigrams are: 
 [('semantically', 'stranded', ','), ('stranded', ',', 'pertinent'), (',', 'pertinent', 'entity'), ('pertinent', 'entity', 'refer'), ('entity', 'refer', '.')]

>> POS Tags are: 
 [('semantically', 'RB'), ('stranded', 'VBN'), (',', ','), ('pertinent', 'JJ'), ('entity', 'NN'), ('refer', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['pertinent entity refer']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('semantically', 'semant'), ('stranded', 'strand'), (',', ','), ('pertinent', 'pertin'), ('entity', 'entiti'), ('refer', 'refer'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('semantically', 'semant'), ('stranded', 'strand'), (',', ','), ('pertinent', 'pertin'), ('entity', 'entiti'), ('refer', 'refer'), ('.', '.')]

>> Lemmatization: 
 [('semantically', 'semantically'), ('stranded', 'stranded'), (',', ','), ('pertinent', 'pertinent'), ('entity', 'entity'), ('refer', 'refer'), ('.', '.')]


------------------- Sentence 2 -------------------

Discourse/Text

>> Tokens are: 
 ['Discourse/Text']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Discourse/Text', 'NN')]

>> Noun Phrases are: 
 ['Discourse/Text']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Discourse/Text', 'discourse/text')]

>> Stemming using Snowball Stemmer: 
 [('Discourse/Text', 'discourse/text')]

>> Lemmatization: 
 [('Discourse/Text', 'Discourse/Text')]



========================================== PARAGRAPH 162 ===========================================

Structure Recognition - Discourse/text structure recognition sway the functions of sentences  

------------------- Sentence 1 -------------------

Structure Recognition - Discourse/text structure recognition sway the functions of sentences

>> Tokens are: 
 ['Structure', 'Recognition', '-', 'Discourse/text', 'structure', 'recognition', 'sway', 'functions', 'sentences']

>> Bigrams are: 
 [('Structure', 'Recognition'), ('Recognition', '-'), ('-', 'Discourse/text'), ('Discourse/text', 'structure'), ('structure', 'recognition'), ('recognition', 'sway'), ('sway', 'functions'), ('functions', 'sentences')]

>> Trigrams are: 
 [('Structure', 'Recognition', '-'), ('Recognition', '-', 'Discourse/text'), ('-', 'Discourse/text', 'structure'), ('Discourse/text', 'structure', 'recognition'), ('structure', 'recognition', 'sway'), ('recognition', 'sway', 'functions'), ('sway', 'functions', 'sentences')]

>> POS Tags are: 
 [('Structure', 'NN'), ('Recognition', 'NNP'), ('-', ':'), ('Discourse/text', 'JJ'), ('structure', 'NN'), ('recognition', 'NN'), ('sway', 'NN'), ('functions', 'NNS'), ('sentences', 'NNS')]

>> Noun Phrases are: 
 ['Structure Recognition', 'Discourse/text structure recognition sway functions sentences']

>> Named Entities are: 
 [('PERSON', 'Structure'), ('ORGANIZATION', 'Recognition')] 

>> Stemming using Porter Stemmer: 
 [('Structure', 'structur'), ('Recognition', 'recognit'), ('-', '-'), ('Discourse/text', 'discourse/text'), ('structure', 'structur'), ('recognition', 'recognit'), ('sway', 'sway'), ('functions', 'function'), ('sentences', 'sentenc')]

>> Stemming using Snowball Stemmer: 
 [('Structure', 'structur'), ('Recognition', 'recognit'), ('-', '-'), ('Discourse/text', 'discourse/text'), ('structure', 'structur'), ('recognition', 'recognit'), ('sway', 'sway'), ('functions', 'function'), ('sentences', 'sentenc')]

>> Lemmatization: 
 [('Structure', 'Structure'), ('Recognition', 'Recognition'), ('-', '-'), ('Discourse/text', 'Discourse/text'), ('structure', 'structure'), ('recognition', 'recognition'), ('sway', 'sway'), ('functions', 'function'), ('sentences', 'sentence')]



========================================== PARAGRAPH 163 ===========================================

in the text, which, in turn, adds to the meaningful representation of the text.  

------------------- Sentence 1 -------------------

in the text, which, in turn, adds to the meaningful representation of the text.

>> Tokens are: 
 ['text', ',', ',', 'turn', ',', 'adds', 'meaningful', 'representation', 'text', '.']

>> Bigrams are: 
 [('text', ','), (',', ','), (',', 'turn'), ('turn', ','), (',', 'adds'), ('adds', 'meaningful'), ('meaningful', 'representation'), ('representation', 'text'), ('text', '.')]

>> Trigrams are: 
 [('text', ',', ','), (',', ',', 'turn'), (',', 'turn', ','), ('turn', ',', 'adds'), (',', 'adds', 'meaningful'), ('adds', 'meaningful', 'representation'), ('meaningful', 'representation', 'text'), ('representation', 'text', '.')]

>> POS Tags are: 
 [('text', 'NN'), (',', ','), (',', ','), ('turn', 'NN'), (',', ','), ('adds', 'VBZ'), ('meaningful', 'JJ'), ('representation', 'NN'), ('text', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['text', 'turn', 'meaningful representation text']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('text', 'text'), (',', ','), (',', ','), ('turn', 'turn'), (',', ','), ('adds', 'add'), ('meaningful', 'meaning'), ('representation', 'represent'), ('text', 'text'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('text', 'text'), (',', ','), (',', ','), ('turn', 'turn'), (',', ','), ('adds', 'add'), ('meaningful', 'meaning'), ('representation', 'represent'), ('text', 'text'), ('.', '.')]

>> Lemmatization: 
 [('text', 'text'), (',', ','), (',', ','), ('turn', 'turn'), (',', ','), ('adds', 'add'), ('meaningful', 'meaningful'), ('representation', 'representation'), ('text', 'text'), ('.', '.')]



========================================== PARAGRAPH 164 ===========================================

7. Pragmatic: 

------------------- Sentence 1 -------------------

7.

>> Tokens are: 
 ['7', '.']

>> Bigrams are: 
 [('7', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('7', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('7', '7'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('7', '7'), ('.', '.')]

>> Lemmatization: 
 [('7', '7'), ('.', '.')]


------------------- Sentence 2 -------------------

Pragmatic:

>> Tokens are: 
 ['Pragmatic', ':']

>> Bigrams are: 
 [('Pragmatic', ':')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Pragmatic', 'JJ'), (':', ':')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Pragmatic', 'pragmat'), (':', ':')]

>> Stemming using Snowball Stemmer: 
 [('Pragmatic', 'pragmat'), (':', ':')]

>> Lemmatization: 
 [('Pragmatic', 'Pragmatic'), (':', ':')]



========================================== PARAGRAPH 165 ===========================================

Pragmatic is concerned with the firm use of language in situations and utilizes nub over and  

------------------- Sentence 1 -------------------

Pragmatic is concerned with the firm use of language in situations and utilizes nub over and

>> Tokens are: 
 ['Pragmatic', 'concerned', 'firm', 'use', 'language', 'situations', 'utilizes', 'nub']

>> Bigrams are: 
 [('Pragmatic', 'concerned'), ('concerned', 'firm'), ('firm', 'use'), ('use', 'language'), ('language', 'situations'), ('situations', 'utilizes'), ('utilizes', 'nub')]

>> Trigrams are: 
 [('Pragmatic', 'concerned', 'firm'), ('concerned', 'firm', 'use'), ('firm', 'use', 'language'), ('use', 'language', 'situations'), ('language', 'situations', 'utilizes'), ('situations', 'utilizes', 'nub')]

>> POS Tags are: 
 [('Pragmatic', 'JJ'), ('concerned', 'JJ'), ('firm', 'NN'), ('use', 'NN'), ('language', 'NN'), ('situations', 'NNS'), ('utilizes', 'VBZ'), ('nub', 'NNS')]

>> Noun Phrases are: 
 ['Pragmatic concerned firm use language situations', 'nub']

>> Named Entities are: 
 [('GPE', 'Pragmatic')] 

>> Stemming using Porter Stemmer: 
 [('Pragmatic', 'pragmat'), ('concerned', 'concern'), ('firm', 'firm'), ('use', 'use'), ('language', 'languag'), ('situations', 'situat'), ('utilizes', 'util'), ('nub', 'nub')]

>> Stemming using Snowball Stemmer: 
 [('Pragmatic', 'pragmat'), ('concerned', 'concern'), ('firm', 'firm'), ('use', 'use'), ('language', 'languag'), ('situations', 'situat'), ('utilizes', 'util'), ('nub', 'nub')]

>> Lemmatization: 
 [('Pragmatic', 'Pragmatic'), ('concerned', 'concerned'), ('firm', 'firm'), ('use', 'use'), ('language', 'language'), ('situations', 'situation'), ('utilizes', 'utilizes'), ('nub', 'nub')]



========================================== PARAGRAPH 166 ===========================================

above the nub of the text for understanding the goal and to explain how extra meaning is read  

------------------- Sentence 1 -------------------

above the nub of the text for understanding the goal and to explain how extra meaning is read

>> Tokens are: 
 ['nub', 'text', 'understanding', 'goal', 'explain', 'extra', 'meaning', 'read']

>> Bigrams are: 
 [('nub', 'text'), ('text', 'understanding'), ('understanding', 'goal'), ('goal', 'explain'), ('explain', 'extra'), ('extra', 'meaning'), ('meaning', 'read')]

>> Trigrams are: 
 [('nub', 'text', 'understanding'), ('text', 'understanding', 'goal'), ('understanding', 'goal', 'explain'), ('goal', 'explain', 'extra'), ('explain', 'extra', 'meaning'), ('extra', 'meaning', 'read')]

>> POS Tags are: 
 [('nub', 'JJ'), ('text', 'NN'), ('understanding', 'JJ'), ('goal', 'NN'), ('explain', 'VBP'), ('extra', 'JJ'), ('meaning', 'NN'), ('read', 'NN')]

>> Noun Phrases are: 
 ['nub text', 'understanding goal', 'extra meaning read']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('nub', 'nub'), ('text', 'text'), ('understanding', 'understand'), ('goal', 'goal'), ('explain', 'explain'), ('extra', 'extra'), ('meaning', 'mean'), ('read', 'read')]

>> Stemming using Snowball Stemmer: 
 [('nub', 'nub'), ('text', 'text'), ('understanding', 'understand'), ('goal', 'goal'), ('explain', 'explain'), ('extra', 'extra'), ('meaning', 'mean'), ('read', 'read')]

>> Lemmatization: 
 [('nub', 'nub'), ('text', 'text'), ('understanding', 'understanding'), ('goal', 'goal'), ('explain', 'explain'), ('extra', 'extra'), ('meaning', 'meaning'), ('read', 'read')]



========================================== PARAGRAPH 167 ===========================================

into texts without literally being encoded in them. This requisite much world knowledge,  

------------------- Sentence 1 -------------------

into texts without literally being encoded in them.

>> Tokens are: 
 ['texts', 'without', 'literally', 'encoded', '.']

>> Bigrams are: 
 [('texts', 'without'), ('without', 'literally'), ('literally', 'encoded'), ('encoded', '.')]

>> Trigrams are: 
 [('texts', 'without', 'literally'), ('without', 'literally', 'encoded'), ('literally', 'encoded', '.')]

>> POS Tags are: 
 [('texts', 'NN'), ('without', 'IN'), ('literally', 'RB'), ('encoded', 'VBN'), ('.', '.')]

>> Noun Phrases are: 
 ['texts']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('texts', 'text'), ('without', 'without'), ('literally', 'liter'), ('encoded', 'encod'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('texts', 'text'), ('without', 'without'), ('literally', 'liter'), ('encoded', 'encod'), ('.', '.')]

>> Lemmatization: 
 [('texts', 'text'), ('without', 'without'), ('literally', 'literally'), ('encoded', 'encoded'), ('.', '.')]


------------------- Sentence 2 -------------------

This requisite much world knowledge,

>> Tokens are: 
 ['This', 'requisite', 'much', 'world', 'knowledge', ',']

>> Bigrams are: 
 [('This', 'requisite'), ('requisite', 'much'), ('much', 'world'), ('world', 'knowledge'), ('knowledge', ',')]

>> Trigrams are: 
 [('This', 'requisite', 'much'), ('requisite', 'much', 'world'), ('much', 'world', 'knowledge'), ('world', 'knowledge', ',')]

>> POS Tags are: 
 [('This', 'DT'), ('requisite', 'JJ'), ('much', 'JJ'), ('world', 'NN'), ('knowledge', 'NN'), (',', ',')]

>> Noun Phrases are: 
 ['This requisite much world knowledge']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('This', 'thi'), ('requisite', 'requisit'), ('much', 'much'), ('world', 'world'), ('knowledge', 'knowledg'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('This', 'this'), ('requisite', 'requisit'), ('much', 'much'), ('world', 'world'), ('knowledge', 'knowledg'), (',', ',')]

>> Lemmatization: 
 [('This', 'This'), ('requisite', 'requisite'), ('much', 'much'), ('world', 'world'), ('knowledge', 'knowledge'), (',', ',')]



========================================== PARAGRAPH 168 ===========================================

including the understanding of intentions, plans, and goals. For example, the following two  

------------------- Sentence 1 -------------------

including the understanding of intentions, plans, and goals.

>> Tokens are: 
 ['including', 'understanding', 'intentions', ',', 'plans', ',', 'goals', '.']

>> Bigrams are: 
 [('including', 'understanding'), ('understanding', 'intentions'), ('intentions', ','), (',', 'plans'), ('plans', ','), (',', 'goals'), ('goals', '.')]

>> Trigrams are: 
 [('including', 'understanding', 'intentions'), ('understanding', 'intentions', ','), ('intentions', ',', 'plans'), (',', 'plans', ','), ('plans', ',', 'goals'), (',', 'goals', '.')]

>> POS Tags are: 
 [('including', 'VBG'), ('understanding', 'JJ'), ('intentions', 'NNS'), (',', ','), ('plans', 'NNS'), (',', ','), ('goals', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['understanding intentions', 'plans', 'goals']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('including', 'includ'), ('understanding', 'understand'), ('intentions', 'intent'), (',', ','), ('plans', 'plan'), (',', ','), ('goals', 'goal'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('including', 'includ'), ('understanding', 'understand'), ('intentions', 'intent'), (',', ','), ('plans', 'plan'), (',', ','), ('goals', 'goal'), ('.', '.')]

>> Lemmatization: 
 [('including', 'including'), ('understanding', 'understanding'), ('intentions', 'intention'), (',', ','), ('plans', 'plan'), (',', ','), ('goals', 'goal'), ('.', '.')]


------------------- Sentence 2 -------------------

For example, the following two

>> Tokens are: 
 ['For', 'example', ',', 'following', 'two']

>> Bigrams are: 
 [('For', 'example'), ('example', ','), (',', 'following'), ('following', 'two')]

>> Trigrams are: 
 [('For', 'example', ','), ('example', ',', 'following'), (',', 'following', 'two')]

>> POS Tags are: 
 [('For', 'IN'), ('example', 'NN'), (',', ','), ('following', 'VBG'), ('two', 'CD')]

>> Noun Phrases are: 
 ['example']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('For', 'for'), ('example', 'exampl'), (',', ','), ('following', 'follow'), ('two', 'two')]

>> Stemming using Snowball Stemmer: 
 [('For', 'for'), ('example', 'exampl'), (',', ','), ('following', 'follow'), ('two', 'two')]

>> Lemmatization: 
 [('For', 'For'), ('example', 'example'), (',', ','), ('following', 'following'), ('two', 'two')]



========================================== PARAGRAPH 169 ===========================================

sentences need aspiration of the anaphoric term ‘they’, but this aspiration requires pragmatic  

------------------- Sentence 1 -------------------

sentences need aspiration of the anaphoric term ‘they’, but this aspiration requires pragmatic

>> Tokens are: 
 ['sentences', 'need', 'aspiration', 'anaphoric', 'term', '‘', '’', ',', 'aspiration', 'requires', 'pragmatic']

>> Bigrams are: 
 [('sentences', 'need'), ('need', 'aspiration'), ('aspiration', 'anaphoric'), ('anaphoric', 'term'), ('term', '‘'), ('‘', '’'), ('’', ','), (',', 'aspiration'), ('aspiration', 'requires'), ('requires', 'pragmatic')]

>> Trigrams are: 
 [('sentences', 'need', 'aspiration'), ('need', 'aspiration', 'anaphoric'), ('aspiration', 'anaphoric', 'term'), ('anaphoric', 'term', '‘'), ('term', '‘', '’'), ('‘', '’', ','), ('’', ',', 'aspiration'), (',', 'aspiration', 'requires'), ('aspiration', 'requires', 'pragmatic')]

>> POS Tags are: 
 [('sentences', 'NNS'), ('need', 'VBP'), ('aspiration', 'NN'), ('anaphoric', 'JJ'), ('term', 'NN'), ('‘', 'NNP'), ('’', 'NNP'), (',', ','), ('aspiration', 'NN'), ('requires', 'VBZ'), ('pragmatic', 'JJ')]

>> Noun Phrases are: 
 ['sentences', 'aspiration', 'anaphoric term ‘ ’', 'aspiration']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('sentences', 'sentenc'), ('need', 'need'), ('aspiration', 'aspir'), ('anaphoric', 'anaphor'), ('term', 'term'), ('‘', '‘'), ('’', '’'), (',', ','), ('aspiration', 'aspir'), ('requires', 'requir'), ('pragmatic', 'pragmat')]

>> Stemming using Snowball Stemmer: 
 [('sentences', 'sentenc'), ('need', 'need'), ('aspiration', 'aspir'), ('anaphoric', 'anaphor'), ('term', 'term'), ('‘', '‘'), ('’', '’'), (',', ','), ('aspiration', 'aspir'), ('requires', 'requir'), ('pragmatic', 'pragmat')]

>> Lemmatization: 
 [('sentences', 'sentence'), ('need', 'need'), ('aspiration', 'aspiration'), ('anaphoric', 'anaphoric'), ('term', 'term'), ('‘', '‘'), ('’', '’'), (',', ','), ('aspiration', 'aspiration'), ('requires', 'requires'), ('pragmatic', 'pragmatic')]



========================================== PARAGRAPH 170 ===========================================

or world knowledge (Elizabeth D. Liddy,2001) [7].  

------------------- Sentence 1 -------------------

or world knowledge (Elizabeth D. Liddy,2001) [7].

>> Tokens are: 
 ['world', 'knowledge', '(', 'Elizabeth', 'D.', 'Liddy,2001', ')', '[', '7', ']', '.']

>> Bigrams are: 
 [('world', 'knowledge'), ('knowledge', '('), ('(', 'Elizabeth'), ('Elizabeth', 'D.'), ('D.', 'Liddy,2001'), ('Liddy,2001', ')'), (')', '['), ('[', '7'), ('7', ']'), (']', '.')]

>> Trigrams are: 
 [('world', 'knowledge', '('), ('knowledge', '(', 'Elizabeth'), ('(', 'Elizabeth', 'D.'), ('Elizabeth', 'D.', 'Liddy,2001'), ('D.', 'Liddy,2001', ')'), ('Liddy,2001', ')', '['), (')', '[', '7'), ('[', '7', ']'), ('7', ']', '.')]

>> POS Tags are: 
 [('world', 'NN'), ('knowledge', 'NN'), ('(', '('), ('Elizabeth', 'NNP'), ('D.', 'NNP'), ('Liddy,2001', 'NNP'), (')', ')'), ('[', 'VBD'), ('7', 'CD'), (']', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['world knowledge', 'Elizabeth D. Liddy,2001', ']']

>> Named Entities are: 
 [('PERSON', 'Elizabeth D.')] 

>> Stemming using Porter Stemmer: 
 [('world', 'world'), ('knowledge', 'knowledg'), ('(', '('), ('Elizabeth', 'elizabeth'), ('D.', 'd.'), ('Liddy,2001', 'liddy,2001'), (')', ')'), ('[', '['), ('7', '7'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('world', 'world'), ('knowledge', 'knowledg'), ('(', '('), ('Elizabeth', 'elizabeth'), ('D.', 'd.'), ('Liddy,2001', 'liddy,2001'), (')', ')'), ('[', '['), ('7', '7'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('world', 'world'), ('knowledge', 'knowledge'), ('(', '('), ('Elizabeth', 'Elizabeth'), ('D.', 'D.'), ('Liddy,2001', 'Liddy,2001'), (')', ')'), ('[', '['), ('7', '7'), (']', ']'), ('.', '.')]



========================================== PARAGRAPH 171 ===========================================

3. Natural Language Generation  

------------------- Sentence 1 -------------------

3.

>> Tokens are: 
 ['3', '.']

>> Bigrams are: 
 [('3', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('3', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('3', '3'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('3', '3'), ('.', '.')]

>> Lemmatization: 
 [('3', '3'), ('.', '.')]


------------------- Sentence 2 -------------------

Natural Language Generation

>> Tokens are: 
 ['Natural', 'Language', 'Generation']

>> Bigrams are: 
 [('Natural', 'Language'), ('Language', 'Generation')]

>> Trigrams are: 
 [('Natural', 'Language', 'Generation')]

>> POS Tags are: 
 [('Natural', 'JJ'), ('Language', 'NNP'), ('Generation', 'NN')]

>> Noun Phrases are: 
 ['Natural Language Generation']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Natural', 'natur'), ('Language', 'languag'), ('Generation', 'gener')]

>> Stemming using Snowball Stemmer: 
 [('Natural', 'natur'), ('Language', 'languag'), ('Generation', 'generat')]

>> Lemmatization: 
 [('Natural', 'Natural'), ('Language', 'Language'), ('Generation', 'Generation')]



========================================== PARAGRAPH 172 ===========================================

Natural Language Generation (NLG) is the process of producing phrases, sentences and  

------------------- Sentence 1 -------------------

Natural Language Generation (NLG) is the process of producing phrases, sentences and

>> Tokens are: 
 ['Natural', 'Language', 'Generation', '(', 'NLG', ')', 'process', 'producing', 'phrases', ',', 'sentences']

>> Bigrams are: 
 [('Natural', 'Language'), ('Language', 'Generation'), ('Generation', '('), ('(', 'NLG'), ('NLG', ')'), (')', 'process'), ('process', 'producing'), ('producing', 'phrases'), ('phrases', ','), (',', 'sentences')]

>> Trigrams are: 
 [('Natural', 'Language', 'Generation'), ('Language', 'Generation', '('), ('Generation', '(', 'NLG'), ('(', 'NLG', ')'), ('NLG', ')', 'process'), (')', 'process', 'producing'), ('process', 'producing', 'phrases'), ('producing', 'phrases', ','), ('phrases', ',', 'sentences')]

>> POS Tags are: 
 [('Natural', 'JJ'), ('Language', 'NNP'), ('Generation', 'NNP'), ('(', '('), ('NLG', 'NNP'), (')', ')'), ('process', 'NN'), ('producing', 'VBG'), ('phrases', 'NNS'), (',', ','), ('sentences', 'NNS')]

>> Noun Phrases are: 
 ['Natural Language Generation', 'NLG', 'process', 'phrases', 'sentences']

>> Named Entities are: 
 [('ORGANIZATION', 'NLG')] 

>> Stemming using Porter Stemmer: 
 [('Natural', 'natur'), ('Language', 'languag'), ('Generation', 'gener'), ('(', '('), ('NLG', 'nlg'), (')', ')'), ('process', 'process'), ('producing', 'produc'), ('phrases', 'phrase'), (',', ','), ('sentences', 'sentenc')]

>> Stemming using Snowball Stemmer: 
 [('Natural', 'natur'), ('Language', 'languag'), ('Generation', 'generat'), ('(', '('), ('NLG', 'nlg'), (')', ')'), ('process', 'process'), ('producing', 'produc'), ('phrases', 'phrase'), (',', ','), ('sentences', 'sentenc')]

>> Lemmatization: 
 [('Natural', 'Natural'), ('Language', 'Language'), ('Generation', 'Generation'), ('(', '('), ('NLG', 'NLG'), (')', ')'), ('process', 'process'), ('producing', 'producing'), ('phrases', 'phrase'), (',', ','), ('sentences', 'sentence')]



========================================== PARAGRAPH 173 ===========================================

paragraphs that are meaningful from an internal representation. It is a part of Natural  

------------------- Sentence 1 -------------------

paragraphs that are meaningful from an internal representation.

>> Tokens are: 
 ['paragraphs', 'meaningful', 'internal', 'representation', '.']

>> Bigrams are: 
 [('paragraphs', 'meaningful'), ('meaningful', 'internal'), ('internal', 'representation'), ('representation', '.')]

>> Trigrams are: 
 [('paragraphs', 'meaningful', 'internal'), ('meaningful', 'internal', 'representation'), ('internal', 'representation', '.')]

>> POS Tags are: 
 [('paragraphs', 'NNS'), ('meaningful', 'JJ'), ('internal', 'JJ'), ('representation', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['paragraphs', 'meaningful internal representation']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('paragraphs', 'paragraph'), ('meaningful', 'meaning'), ('internal', 'intern'), ('representation', 'represent'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('paragraphs', 'paragraph'), ('meaningful', 'meaning'), ('internal', 'intern'), ('representation', 'represent'), ('.', '.')]

>> Lemmatization: 
 [('paragraphs', 'paragraph'), ('meaningful', 'meaningful'), ('internal', 'internal'), ('representation', 'representation'), ('.', '.')]


------------------- Sentence 2 -------------------

It is a part of Natural

>> Tokens are: 
 ['It', 'part', 'Natural']

>> Bigrams are: 
 [('It', 'part'), ('part', 'Natural')]

>> Trigrams are: 
 [('It', 'part', 'Natural')]

>> POS Tags are: 
 [('It', 'PRP'), ('part', 'NN'), ('Natural', 'NNP')]

>> Noun Phrases are: 
 ['part Natural']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('It', 'it'), ('part', 'part'), ('Natural', 'natur')]

>> Stemming using Snowball Stemmer: 
 [('It', 'it'), ('part', 'part'), ('Natural', 'natur')]

>> Lemmatization: 
 [('It', 'It'), ('part', 'part'), ('Natural', 'Natural')]



========================================== PARAGRAPH 174 ===========================================

Language Processing and happens in four phases: identifying the goals, planning on how  

------------------- Sentence 1 -------------------

Language Processing and happens in four phases: identifying the goals, planning on how

>> Tokens are: 
 ['Language', 'Processing', 'happens', 'four', 'phases', ':', 'identifying', 'goals', ',', 'planning']

>> Bigrams are: 
 [('Language', 'Processing'), ('Processing', 'happens'), ('happens', 'four'), ('four', 'phases'), ('phases', ':'), (':', 'identifying'), ('identifying', 'goals'), ('goals', ','), (',', 'planning')]

>> Trigrams are: 
 [('Language', 'Processing', 'happens'), ('Processing', 'happens', 'four'), ('happens', 'four', 'phases'), ('four', 'phases', ':'), ('phases', ':', 'identifying'), (':', 'identifying', 'goals'), ('identifying', 'goals', ','), ('goals', ',', 'planning')]

>> POS Tags are: 
 [('Language', 'NN'), ('Processing', 'VBG'), ('happens', 'VBZ'), ('four', 'CD'), ('phases', 'NNS'), (':', ':'), ('identifying', 'NN'), ('goals', 'NNS'), (',', ','), ('planning', 'VBG')]

>> Noun Phrases are: 
 ['Language', 'phases', 'identifying goals']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Language', 'languag'), ('Processing', 'process'), ('happens', 'happen'), ('four', 'four'), ('phases', 'phase'), (':', ':'), ('identifying', 'identifi'), ('goals', 'goal'), (',', ','), ('planning', 'plan')]

>> Stemming using Snowball Stemmer: 
 [('Language', 'languag'), ('Processing', 'process'), ('happens', 'happen'), ('four', 'four'), ('phases', 'phase'), (':', ':'), ('identifying', 'identifi'), ('goals', 'goal'), (',', ','), ('planning', 'plan')]

>> Lemmatization: 
 [('Language', 'Language'), ('Processing', 'Processing'), ('happens', 'happens'), ('four', 'four'), ('phases', 'phase'), (':', ':'), ('identifying', 'identifying'), ('goals', 'goal'), (',', ','), ('planning', 'planning')]



========================================== PARAGRAPH 175 ===========================================

goals maybe achieved by evaluating the situation and available communicative sources and  

------------------- Sentence 1 -------------------

goals maybe achieved by evaluating the situation and available communicative sources and

>> Tokens are: 
 ['goals', 'maybe', 'achieved', 'evaluating', 'situation', 'available', 'communicative', 'sources']

>> Bigrams are: 
 [('goals', 'maybe'), ('maybe', 'achieved'), ('achieved', 'evaluating'), ('evaluating', 'situation'), ('situation', 'available'), ('available', 'communicative'), ('communicative', 'sources')]

>> Trigrams are: 
 [('goals', 'maybe', 'achieved'), ('maybe', 'achieved', 'evaluating'), ('achieved', 'evaluating', 'situation'), ('evaluating', 'situation', 'available'), ('situation', 'available', 'communicative'), ('available', 'communicative', 'sources')]

>> POS Tags are: 
 [('goals', 'NNS'), ('maybe', 'RB'), ('achieved', 'VBD'), ('evaluating', 'VBG'), ('situation', 'NN'), ('available', 'JJ'), ('communicative', 'JJ'), ('sources', 'NNS')]

>> Noun Phrases are: 
 ['goals', 'situation', 'available communicative sources']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('goals', 'goal'), ('maybe', 'mayb'), ('achieved', 'achiev'), ('evaluating', 'evalu'), ('situation', 'situat'), ('available', 'avail'), ('communicative', 'commun'), ('sources', 'sourc')]

>> Stemming using Snowball Stemmer: 
 [('goals', 'goal'), ('maybe', 'mayb'), ('achieved', 'achiev'), ('evaluating', 'evalu'), ('situation', 'situat'), ('available', 'avail'), ('communicative', 'communic'), ('sources', 'sourc')]

>> Lemmatization: 
 [('goals', 'goal'), ('maybe', 'maybe'), ('achieved', 'achieved'), ('evaluating', 'evaluating'), ('situation', 'situation'), ('available', 'available'), ('communicative', 'communicative'), ('sources', 'source')]



========================================== PARAGRAPH 176 ===========================================

realizing the plans as a text [Figure 3]. It is opposite to Understanding.  

------------------- Sentence 1 -------------------

realizing the plans as a text [Figure 3].

>> Tokens are: 
 ['realizing', 'plans', 'text', '[', 'Figure', '3', ']', '.']

>> Bigrams are: 
 [('realizing', 'plans'), ('plans', 'text'), ('text', '['), ('[', 'Figure'), ('Figure', '3'), ('3', ']'), (']', '.')]

>> Trigrams are: 
 [('realizing', 'plans', 'text'), ('plans', 'text', '['), ('text', '[', 'Figure'), ('[', 'Figure', '3'), ('Figure', '3', ']'), ('3', ']', '.')]

>> POS Tags are: 
 [('realizing', 'VBG'), ('plans', 'NNS'), ('text', 'JJ'), ('[', 'JJ'), ('Figure', 'NN'), ('3', 'CD'), (']', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['plans', 'text [ Figure', ']']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('realizing', 'realiz'), ('plans', 'plan'), ('text', 'text'), ('[', '['), ('Figure', 'figur'), ('3', '3'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('realizing', 'realiz'), ('plans', 'plan'), ('text', 'text'), ('[', '['), ('Figure', 'figur'), ('3', '3'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('realizing', 'realizing'), ('plans', 'plan'), ('text', 'text'), ('[', '['), ('Figure', 'Figure'), ('3', '3'), (']', ']'), ('.', '.')]


------------------- Sentence 2 -------------------

It is opposite to Understanding.

>> Tokens are: 
 ['It', 'opposite', 'Understanding', '.']

>> Bigrams are: 
 [('It', 'opposite'), ('opposite', 'Understanding'), ('Understanding', '.')]

>> Trigrams are: 
 [('It', 'opposite', 'Understanding'), ('opposite', 'Understanding', '.')]

>> POS Tags are: 
 [('It', 'PRP'), ('opposite', 'RP'), ('Understanding', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Understanding']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('It', 'it'), ('opposite', 'opposit'), ('Understanding', 'understand'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('It', 'it'), ('opposite', 'opposit'), ('Understanding', 'understand'), ('.', '.')]

>> Lemmatization: 
 [('It', 'It'), ('opposite', 'opposite'), ('Understanding', 'Understanding'), ('.', '.')]



========================================== PARAGRAPH 177 ===========================================

  


========================================== PARAGRAPH 178 ===========================================

                                      Figure 3. Components of NLG  

------------------- Sentence 1 -------------------

                                      Figure 3.

>> Tokens are: 
 ['Figure', '3', '.']

>> Bigrams are: 
 [('Figure', '3'), ('3', '.')]

>> Trigrams are: 
 [('Figure', '3', '.')]

>> POS Tags are: 
 [('Figure', 'NN'), ('3', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Figure']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Figure', 'figur'), ('3', '3'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Figure', 'figur'), ('3', '3'), ('.', '.')]

>> Lemmatization: 
 [('Figure', 'Figure'), ('3', '3'), ('.', '.')]


------------------- Sentence 2 -------------------

Components of NLG

>> Tokens are: 
 ['Components', 'NLG']

>> Bigrams are: 
 [('Components', 'NLG')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Components', 'NNS'), ('NLG', 'NNP')]

>> Noun Phrases are: 
 ['Components NLG']

>> Named Entities are: 
 [('ORGANIZATION', 'NLG')] 

>> Stemming using Porter Stemmer: 
 [('Components', 'compon'), ('NLG', 'nlg')]

>> Stemming using Snowball Stemmer: 
 [('Components', 'compon'), ('NLG', 'nlg')]

>> Lemmatization: 
 [('Components', 'Components'), ('NLG', 'NLG')]



========================================== PARAGRAPH 179 ===========================================

Components of NLG are as follows:  

------------------- Sentence 1 -------------------

Components of NLG are as follows:

>> Tokens are: 
 ['Components', 'NLG', 'follows', ':']

>> Bigrams are: 
 [('Components', 'NLG'), ('NLG', 'follows'), ('follows', ':')]

>> Trigrams are: 
 [('Components', 'NLG', 'follows'), ('NLG', 'follows', ':')]

>> POS Tags are: 
 [('Components', 'NNS'), ('NLG', 'NNP'), ('follows', 'VBZ'), (':', ':')]

>> Noun Phrases are: 
 ['Components NLG']

>> Named Entities are: 
 [('ORGANIZATION', 'NLG')] 

>> Stemming using Porter Stemmer: 
 [('Components', 'compon'), ('NLG', 'nlg'), ('follows', 'follow'), (':', ':')]

>> Stemming using Snowball Stemmer: 
 [('Components', 'compon'), ('NLG', 'nlg'), ('follows', 'follow'), (':', ':')]

>> Lemmatization: 
 [('Components', 'Components'), ('NLG', 'NLG'), ('follows', 'follows'), (':', ':')]



========================================== PARAGRAPH 180 ===========================================

Speaker and Generator – To generate a text we need to have a speaker or an application  

------------------- Sentence 1 -------------------

Speaker and Generator – To generate a text we need to have a speaker or an application

>> Tokens are: 
 ['Speaker', 'Generator', '–', 'To', 'generate', 'text', 'need', 'speaker', 'application']

>> Bigrams are: 
 [('Speaker', 'Generator'), ('Generator', '–'), ('–', 'To'), ('To', 'generate'), ('generate', 'text'), ('text', 'need'), ('need', 'speaker'), ('speaker', 'application')]

>> Trigrams are: 
 [('Speaker', 'Generator', '–'), ('Generator', '–', 'To'), ('–', 'To', 'generate'), ('To', 'generate', 'text'), ('generate', 'text', 'need'), ('text', 'need', 'speaker'), ('need', 'speaker', 'application')]

>> POS Tags are: 
 [('Speaker', 'NNP'), ('Generator', 'NNP'), ('–', 'NNP'), ('To', 'TO'), ('generate', 'VB'), ('text', 'NN'), ('need', 'NN'), ('speaker', 'NN'), ('application', 'NN')]

>> Noun Phrases are: 
 ['Speaker Generator –', 'text need speaker application']

>> Named Entities are: 
 [('PERSON', 'Speaker')] 

>> Stemming using Porter Stemmer: 
 [('Speaker', 'speaker'), ('Generator', 'gener'), ('–', '–'), ('To', 'to'), ('generate', 'gener'), ('text', 'text'), ('need', 'need'), ('speaker', 'speaker'), ('application', 'applic')]

>> Stemming using Snowball Stemmer: 
 [('Speaker', 'speaker'), ('Generator', 'generat'), ('–', '–'), ('To', 'to'), ('generate', 'generat'), ('text', 'text'), ('need', 'need'), ('speaker', 'speaker'), ('application', 'applic')]

>> Lemmatization: 
 [('Speaker', 'Speaker'), ('Generator', 'Generator'), ('–', '–'), ('To', 'To'), ('generate', 'generate'), ('text', 'text'), ('need', 'need'), ('speaker', 'speaker'), ('application', 'application')]



========================================== PARAGRAPH 181 ===========================================

and a generator or a program that renders the application’s intentions into fluent phrase  

------------------- Sentence 1 -------------------

and a generator or a program that renders the application’s intentions into fluent phrase

>> Tokens are: 
 ['generator', 'program', 'renders', 'application', '’', 'intentions', 'fluent', 'phrase']

>> Bigrams are: 
 [('generator', 'program'), ('program', 'renders'), ('renders', 'application'), ('application', '’'), ('’', 'intentions'), ('intentions', 'fluent'), ('fluent', 'phrase')]

>> Trigrams are: 
 [('generator', 'program', 'renders'), ('program', 'renders', 'application'), ('renders', 'application', '’'), ('application', '’', 'intentions'), ('’', 'intentions', 'fluent'), ('intentions', 'fluent', 'phrase')]

>> POS Tags are: 
 [('generator', 'NN'), ('program', 'NN'), ('renders', 'NNS'), ('application', 'VBP'), ('’', 'JJ'), ('intentions', 'NNS'), ('fluent', 'JJ'), ('phrase', 'NN')]

>> Noun Phrases are: 
 ['generator program renders', '’ intentions', 'fluent phrase']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('generator', 'gener'), ('program', 'program'), ('renders', 'render'), ('application', 'applic'), ('’', '’'), ('intentions', 'intent'), ('fluent', 'fluent'), ('phrase', 'phrase')]

>> Stemming using Snowball Stemmer: 
 [('generator', 'generat'), ('program', 'program'), ('renders', 'render'), ('application', 'applic'), ('’', '’'), ('intentions', 'intent'), ('fluent', 'fluent'), ('phrase', 'phrase')]

>> Lemmatization: 
 [('generator', 'generator'), ('program', 'program'), ('renders', 'render'), ('application', 'application'), ('’', '’'), ('intentions', 'intention'), ('fluent', 'fluent'), ('phrase', 'phrase')]



========================================== PARAGRAPH 182 ===========================================

relevant to the situation.   

------------------- Sentence 1 -------------------

relevant to the situation.

>> Tokens are: 
 ['relevant', 'situation', '.']

>> Bigrams are: 
 [('relevant', 'situation'), ('situation', '.')]

>> Trigrams are: 
 [('relevant', 'situation', '.')]

>> POS Tags are: 
 [('relevant', 'JJ'), ('situation', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['relevant situation']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('relevant', 'relev'), ('situation', 'situat'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('relevant', 'relev'), ('situation', 'situat'), ('.', '.')]

>> Lemmatization: 
 [('relevant', 'relevant'), ('situation', 'situation'), ('.', '.')]



========================================== PARAGRAPH 183 ===========================================

Components and Levels of Representation -The process of language generation involves  

------------------- Sentence 1 -------------------

Components and Levels of Representation -The process of language generation involves

>> Tokens are: 
 ['Components', 'Levels', 'Representation', '-The', 'process', 'language', 'generation', 'involves']

>> Bigrams are: 
 [('Components', 'Levels'), ('Levels', 'Representation'), ('Representation', '-The'), ('-The', 'process'), ('process', 'language'), ('language', 'generation'), ('generation', 'involves')]

>> Trigrams are: 
 [('Components', 'Levels', 'Representation'), ('Levels', 'Representation', '-The'), ('Representation', '-The', 'process'), ('-The', 'process', 'language'), ('process', 'language', 'generation'), ('language', 'generation', 'involves')]

>> POS Tags are: 
 [('Components', 'NNS'), ('Levels', 'NNP'), ('Representation', 'NNP'), ('-The', 'NNP'), ('process', 'NN'), ('language', 'NN'), ('generation', 'NN'), ('involves', 'VBZ')]

>> Noun Phrases are: 
 ['Components Levels Representation -The process language generation']

>> Named Entities are: 
 [('PERSON', 'Levels')] 

>> Stemming using Porter Stemmer: 
 [('Components', 'compon'), ('Levels', 'level'), ('Representation', 'represent'), ('-The', '-the'), ('process', 'process'), ('language', 'languag'), ('generation', 'gener'), ('involves', 'involv')]

>> Stemming using Snowball Stemmer: 
 [('Components', 'compon'), ('Levels', 'level'), ('Representation', 'represent'), ('-The', '-the'), ('process', 'process'), ('language', 'languag'), ('generation', 'generat'), ('involves', 'involv')]

>> Lemmatization: 
 [('Components', 'Components'), ('Levels', 'Levels'), ('Representation', 'Representation'), ('-The', '-The'), ('process', 'process'), ('language', 'language'), ('generation', 'generation'), ('involves', 'involves')]



========================================== PARAGRAPH 184 ===========================================

the following interweaved tasks. Content selection: Information should be selected and  

------------------- Sentence 1 -------------------

the following interweaved tasks.

>> Tokens are: 
 ['following', 'interweaved', 'tasks', '.']

>> Bigrams are: 
 [('following', 'interweaved'), ('interweaved', 'tasks'), ('tasks', '.')]

>> Trigrams are: 
 [('following', 'interweaved', 'tasks'), ('interweaved', 'tasks', '.')]

>> POS Tags are: 
 [('following', 'VBG'), ('interweaved', 'JJ'), ('tasks', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['interweaved tasks']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('following', 'follow'), ('interweaved', 'interweav'), ('tasks', 'task'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('following', 'follow'), ('interweaved', 'interweav'), ('tasks', 'task'), ('.', '.')]

>> Lemmatization: 
 [('following', 'following'), ('interweaved', 'interweaved'), ('tasks', 'task'), ('.', '.')]


------------------- Sentence 2 -------------------

Content selection: Information should be selected and

>> Tokens are: 
 ['Content', 'selection', ':', 'Information', 'selected']

>> Bigrams are: 
 [('Content', 'selection'), ('selection', ':'), (':', 'Information'), ('Information', 'selected')]

>> Trigrams are: 
 [('Content', 'selection', ':'), ('selection', ':', 'Information'), (':', 'Information', 'selected')]

>> POS Tags are: 
 [('Content', 'JJ'), ('selection', 'NN'), (':', ':'), ('Information', 'NN'), ('selected', 'VBD')]

>> Noun Phrases are: 
 ['Content selection', 'Information']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Content', 'content'), ('selection', 'select'), (':', ':'), ('Information', 'inform'), ('selected', 'select')]

>> Stemming using Snowball Stemmer: 
 [('Content', 'content'), ('selection', 'select'), (':', ':'), ('Information', 'inform'), ('selected', 'select')]

>> Lemmatization: 
 [('Content', 'Content'), ('selection', 'selection'), (':', ':'), ('Information', 'Information'), ('selected', 'selected')]



========================================== PARAGRAPH 185 ===========================================

included in the set. Depending on how this information is parsed into representational units,  

------------------- Sentence 1 -------------------

included in the set.

>> Tokens are: 
 ['included', 'set', '.']

>> Bigrams are: 
 [('included', 'set'), ('set', '.')]

>> Trigrams are: 
 [('included', 'set', '.')]

>> POS Tags are: 
 [('included', 'VBN'), ('set', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['set']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('included', 'includ'), ('set', 'set'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('included', 'includ'), ('set', 'set'), ('.', '.')]

>> Lemmatization: 
 [('included', 'included'), ('set', 'set'), ('.', '.')]


------------------- Sentence 2 -------------------

Depending on how this information is parsed into representational units,

>> Tokens are: 
 ['Depending', 'information', 'parsed', 'representational', 'units', ',']

>> Bigrams are: 
 [('Depending', 'information'), ('information', 'parsed'), ('parsed', 'representational'), ('representational', 'units'), ('units', ',')]

>> Trigrams are: 
 [('Depending', 'information', 'parsed'), ('information', 'parsed', 'representational'), ('parsed', 'representational', 'units'), ('representational', 'units', ',')]

>> POS Tags are: 
 [('Depending', 'VBG'), ('information', 'NN'), ('parsed', 'VBD'), ('representational', 'JJ'), ('units', 'NNS'), (',', ',')]

>> Noun Phrases are: 
 ['information', 'representational units']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Depending', 'depend'), ('information', 'inform'), ('parsed', 'pars'), ('representational', 'represent'), ('units', 'unit'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('Depending', 'depend'), ('information', 'inform'), ('parsed', 'pars'), ('representational', 'represent'), ('units', 'unit'), (',', ',')]

>> Lemmatization: 
 [('Depending', 'Depending'), ('information', 'information'), ('parsed', 'parsed'), ('representational', 'representational'), ('units', 'unit'), (',', ',')]



========================================== PARAGRAPH 186 ===========================================

parts of the units may have to be removed while some others may be added by default.  

------------------- Sentence 1 -------------------

parts of the units may have to be removed while some others may be added by default.

>> Tokens are: 
 ['parts', 'units', 'may', 'removed', 'others', 'may', 'added', 'default', '.']

>> Bigrams are: 
 [('parts', 'units'), ('units', 'may'), ('may', 'removed'), ('removed', 'others'), ('others', 'may'), ('may', 'added'), ('added', 'default'), ('default', '.')]

>> Trigrams are: 
 [('parts', 'units', 'may'), ('units', 'may', 'removed'), ('may', 'removed', 'others'), ('removed', 'others', 'may'), ('others', 'may', 'added'), ('may', 'added', 'default'), ('added', 'default', '.')]

>> POS Tags are: 
 [('parts', 'NNS'), ('units', 'NNS'), ('may', 'MD'), ('removed', 'VB'), ('others', 'NNS'), ('may', 'MD'), ('added', 'VB'), ('default', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['parts units', 'others', 'default']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('parts', 'part'), ('units', 'unit'), ('may', 'may'), ('removed', 'remov'), ('others', 'other'), ('may', 'may'), ('added', 'ad'), ('default', 'default'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('parts', 'part'), ('units', 'unit'), ('may', 'may'), ('removed', 'remov'), ('others', 'other'), ('may', 'may'), ('added', 'ad'), ('default', 'default'), ('.', '.')]

>> Lemmatization: 
 [('parts', 'part'), ('units', 'unit'), ('may', 'may'), ('removed', 'removed'), ('others', 'others'), ('may', 'may'), ('added', 'added'), ('default', 'default'), ('.', '.')]



========================================== PARAGRAPH 187 ===========================================

Textual Organization: The information must be textually organized according the grammar, it  

------------------- Sentence 1 -------------------

Textual Organization: The information must be textually organized according the grammar, it

>> Tokens are: 
 ['Textual', 'Organization', ':', 'The', 'information', 'must', 'textually', 'organized', 'according', 'grammar', ',']

>> Bigrams are: 
 [('Textual', 'Organization'), ('Organization', ':'), (':', 'The'), ('The', 'information'), ('information', 'must'), ('must', 'textually'), ('textually', 'organized'), ('organized', 'according'), ('according', 'grammar'), ('grammar', ',')]

>> Trigrams are: 
 [('Textual', 'Organization', ':'), ('Organization', ':', 'The'), (':', 'The', 'information'), ('The', 'information', 'must'), ('information', 'must', 'textually'), ('must', 'textually', 'organized'), ('textually', 'organized', 'according'), ('organized', 'according', 'grammar'), ('according', 'grammar', ',')]

>> POS Tags are: 
 [('Textual', 'JJ'), ('Organization', 'NN'), (':', ':'), ('The', 'DT'), ('information', 'NN'), ('must', 'MD'), ('textually', 'RB'), ('organized', 'VBN'), ('according', 'VBG'), ('grammar', 'NN'), (',', ',')]

>> Noun Phrases are: 
 ['Textual Organization', 'The information', 'grammar']

>> Named Entities are: 
 [('GPE', 'Textual'), ('ORGANIZATION', 'Organization')] 

>> Stemming using Porter Stemmer: 
 [('Textual', 'textual'), ('Organization', 'organ'), (':', ':'), ('The', 'the'), ('information', 'inform'), ('must', 'must'), ('textually', 'textual'), ('organized', 'organ'), ('according', 'accord'), ('grammar', 'grammar'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('Textual', 'textual'), ('Organization', 'organ'), (':', ':'), ('The', 'the'), ('information', 'inform'), ('must', 'must'), ('textually', 'textual'), ('organized', 'organ'), ('according', 'accord'), ('grammar', 'grammar'), (',', ',')]

>> Lemmatization: 
 [('Textual', 'Textual'), ('Organization', 'Organization'), (':', ':'), ('The', 'The'), ('information', 'information'), ('must', 'must'), ('textually', 'textually'), ('organized', 'organized'), ('according', 'according'), ('grammar', 'grammar'), (',', ',')]



========================================== PARAGRAPH 188 ===========================================

must be ordered both sequentially and in terms of linguistic relations like modifications.  

------------------- Sentence 1 -------------------

must be ordered both sequentially and in terms of linguistic relations like modifications.

>> Tokens are: 
 ['must', 'ordered', 'sequentially', 'terms', 'linguistic', 'relations', 'like', 'modifications', '.']

>> Bigrams are: 
 [('must', 'ordered'), ('ordered', 'sequentially'), ('sequentially', 'terms'), ('terms', 'linguistic'), ('linguistic', 'relations'), ('relations', 'like'), ('like', 'modifications'), ('modifications', '.')]

>> Trigrams are: 
 [('must', 'ordered', 'sequentially'), ('ordered', 'sequentially', 'terms'), ('sequentially', 'terms', 'linguistic'), ('terms', 'linguistic', 'relations'), ('linguistic', 'relations', 'like'), ('relations', 'like', 'modifications'), ('like', 'modifications', '.')]

>> POS Tags are: 
 [('must', 'MD'), ('ordered', 'VBN'), ('sequentially', 'RB'), ('terms', 'NNS'), ('linguistic', 'JJ'), ('relations', 'NNS'), ('like', 'IN'), ('modifications', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['terms', 'linguistic relations', 'modifications']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('must', 'must'), ('ordered', 'order'), ('sequentially', 'sequenti'), ('terms', 'term'), ('linguistic', 'linguist'), ('relations', 'relat'), ('like', 'like'), ('modifications', 'modif'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('must', 'must'), ('ordered', 'order'), ('sequentially', 'sequenti'), ('terms', 'term'), ('linguistic', 'linguist'), ('relations', 'relat'), ('like', 'like'), ('modifications', 'modif'), ('.', '.')]

>> Lemmatization: 
 [('must', 'must'), ('ordered', 'ordered'), ('sequentially', 'sequentially'), ('terms', 'term'), ('linguistic', 'linguistic'), ('relations', 'relation'), ('like', 'like'), ('modifications', 'modification'), ('.', '.')]



========================================== PARAGRAPH 189 ===========================================

Linguistic Resources: To support the information’s realization, linguistic resources must be 

------------------- Sentence 1 -------------------

Linguistic Resources: To support the information’s realization, linguistic resources must be

>> Tokens are: 
 ['Linguistic', 'Resources', ':', 'To', 'support', 'information', '’', 'realization', ',', 'linguistic', 'resources', 'must']

>> Bigrams are: 
 [('Linguistic', 'Resources'), ('Resources', ':'), (':', 'To'), ('To', 'support'), ('support', 'information'), ('information', '’'), ('’', 'realization'), ('realization', ','), (',', 'linguistic'), ('linguistic', 'resources'), ('resources', 'must')]

>> Trigrams are: 
 [('Linguistic', 'Resources', ':'), ('Resources', ':', 'To'), (':', 'To', 'support'), ('To', 'support', 'information'), ('support', 'information', '’'), ('information', '’', 'realization'), ('’', 'realization', ','), ('realization', ',', 'linguistic'), (',', 'linguistic', 'resources'), ('linguistic', 'resources', 'must')]

>> POS Tags are: 
 [('Linguistic', 'JJ'), ('Resources', 'NNS'), (':', ':'), ('To', 'TO'), ('support', 'VB'), ('information', 'NN'), ('’', 'NNP'), ('realization', 'NN'), (',', ','), ('linguistic', 'JJ'), ('resources', 'NNS'), ('must', 'MD')]

>> Noun Phrases are: 
 ['Linguistic Resources', 'information ’ realization', 'linguistic resources']

>> Named Entities are: 
 [('GPE', 'Linguistic')] 

>> Stemming using Porter Stemmer: 
 [('Linguistic', 'linguist'), ('Resources', 'resourc'), (':', ':'), ('To', 'to'), ('support', 'support'), ('information', 'inform'), ('’', '’'), ('realization', 'realiz'), (',', ','), ('linguistic', 'linguist'), ('resources', 'resourc'), ('must', 'must')]

>> Stemming using Snowball Stemmer: 
 [('Linguistic', 'linguist'), ('Resources', 'resourc'), (':', ':'), ('To', 'to'), ('support', 'support'), ('information', 'inform'), ('’', '’'), ('realization', 'realize'), (',', ','), ('linguistic', 'linguist'), ('resources', 'resourc'), ('must', 'must')]

>> Lemmatization: 
 [('Linguistic', 'Linguistic'), ('Resources', 'Resources'), (':', ':'), ('To', 'To'), ('support', 'support'), ('information', 'information'), ('’', '’'), ('realization', 'realization'), (',', ','), ('linguistic', 'linguistic'), ('resources', 'resource'), ('must', 'must')]



========================================== PARAGRAPH 190 ===========================================

chosen. In the end these resources will come down to choices of particular words, idioms,  

------------------- Sentence 1 -------------------

chosen.

>> Tokens are: 
 ['chosen', '.']

>> Bigrams are: 
 [('chosen', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('chosen', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['chosen']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('chosen', 'chosen'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('chosen', 'chosen'), ('.', '.')]

>> Lemmatization: 
 [('chosen', 'chosen'), ('.', '.')]


------------------- Sentence 2 -------------------

In the end these resources will come down to choices of particular words, idioms,

>> Tokens are: 
 ['In', 'end', 'resources', 'come', 'choices', 'particular', 'words', ',', 'idioms', ',']

>> Bigrams are: 
 [('In', 'end'), ('end', 'resources'), ('resources', 'come'), ('come', 'choices'), ('choices', 'particular'), ('particular', 'words'), ('words', ','), (',', 'idioms'), ('idioms', ',')]

>> Trigrams are: 
 [('In', 'end', 'resources'), ('end', 'resources', 'come'), ('resources', 'come', 'choices'), ('come', 'choices', 'particular'), ('choices', 'particular', 'words'), ('particular', 'words', ','), ('words', ',', 'idioms'), (',', 'idioms', ',')]

>> POS Tags are: 
 [('In', 'IN'), ('end', 'JJ'), ('resources', 'NNS'), ('come', 'VBP'), ('choices', 'NNS'), ('particular', 'JJ'), ('words', 'NNS'), (',', ','), ('idioms', 'NNS'), (',', ',')]

>> Noun Phrases are: 
 ['end resources', 'choices', 'particular words', 'idioms']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('end', 'end'), ('resources', 'resourc'), ('come', 'come'), ('choices', 'choic'), ('particular', 'particular'), ('words', 'word'), (',', ','), ('idioms', 'idiom'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('end', 'end'), ('resources', 'resourc'), ('come', 'come'), ('choices', 'choic'), ('particular', 'particular'), ('words', 'word'), (',', ','), ('idioms', 'idiom'), (',', ',')]

>> Lemmatization: 
 [('In', 'In'), ('end', 'end'), ('resources', 'resource'), ('come', 'come'), ('choices', 'choice'), ('particular', 'particular'), ('words', 'word'), (',', ','), ('idioms', 'idiom'), (',', ',')]



========================================== PARAGRAPH 191 ===========================================

syntactic constructs etc. Realization: The selected and organized resources must be realized  

------------------- Sentence 1 -------------------

syntactic constructs etc.

>> Tokens are: 
 ['syntactic', 'constructs', 'etc', '.']

>> Bigrams are: 
 [('syntactic', 'constructs'), ('constructs', 'etc'), ('etc', '.')]

>> Trigrams are: 
 [('syntactic', 'constructs', 'etc'), ('constructs', 'etc', '.')]

>> POS Tags are: 
 [('syntactic', 'JJ'), ('constructs', 'NNS'), ('etc', 'FW'), ('.', '.')]

>> Noun Phrases are: 
 ['syntactic constructs']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('syntactic', 'syntact'), ('constructs', 'construct'), ('etc', 'etc'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('syntactic', 'syntact'), ('constructs', 'construct'), ('etc', 'etc'), ('.', '.')]

>> Lemmatization: 
 [('syntactic', 'syntactic'), ('constructs', 'construct'), ('etc', 'etc'), ('.', '.')]


------------------- Sentence 2 -------------------

Realization: The selected and organized resources must be realized

>> Tokens are: 
 ['Realization', ':', 'The', 'selected', 'organized', 'resources', 'must', 'realized']

>> Bigrams are: 
 [('Realization', ':'), (':', 'The'), ('The', 'selected'), ('selected', 'organized'), ('organized', 'resources'), ('resources', 'must'), ('must', 'realized')]

>> Trigrams are: 
 [('Realization', ':', 'The'), (':', 'The', 'selected'), ('The', 'selected', 'organized'), ('selected', 'organized', 'resources'), ('organized', 'resources', 'must'), ('resources', 'must', 'realized')]

>> POS Tags are: 
 [('Realization', 'NN'), (':', ':'), ('The', 'DT'), ('selected', 'VBN'), ('organized', 'JJ'), ('resources', 'NNS'), ('must', 'MD'), ('realized', 'VB')]

>> Noun Phrases are: 
 ['Realization', 'organized resources']

>> Named Entities are: 
 [('GPE', 'Realization')] 

>> Stemming using Porter Stemmer: 
 [('Realization', 'realiz'), (':', ':'), ('The', 'the'), ('selected', 'select'), ('organized', 'organ'), ('resources', 'resourc'), ('must', 'must'), ('realized', 'realiz')]

>> Stemming using Snowball Stemmer: 
 [('Realization', 'realize'), (':', ':'), ('The', 'the'), ('selected', 'select'), ('organized', 'organ'), ('resources', 'resourc'), ('must', 'must'), ('realized', 'realiz')]

>> Lemmatization: 
 [('Realization', 'Realization'), (':', ':'), ('The', 'The'), ('selected', 'selected'), ('organized', 'organized'), ('resources', 'resource'), ('must', 'must'), ('realized', 'realized')]



========================================== PARAGRAPH 192 ===========================================

as an actual text or voice output.   

------------------- Sentence 1 -------------------

as an actual text or voice output.

>> Tokens are: 
 ['actual', 'text', 'voice', 'output', '.']

>> Bigrams are: 
 [('actual', 'text'), ('text', 'voice'), ('voice', 'output'), ('output', '.')]

>> Trigrams are: 
 [('actual', 'text', 'voice'), ('text', 'voice', 'output'), ('voice', 'output', '.')]

>> POS Tags are: 
 [('actual', 'JJ'), ('text', 'NN'), ('voice', 'NN'), ('output', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['actual text voice output']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('actual', 'actual'), ('text', 'text'), ('voice', 'voic'), ('output', 'output'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('actual', 'actual'), ('text', 'text'), ('voice', 'voic'), ('output', 'output'), ('.', '.')]

>> Lemmatization: 
 [('actual', 'actual'), ('text', 'text'), ('voice', 'voice'), ('output', 'output'), ('.', '.')]



========================================== PARAGRAPH 193 ===========================================

Application or Speaker –  This is only for maintaining the model of the situation. Here the  

------------------- Sentence 1 -------------------

Application or Speaker –  This is only for maintaining the model of the situation.

>> Tokens are: 
 ['Application', 'Speaker', '–', 'This', 'maintaining', 'model', 'situation', '.']

>> Bigrams are: 
 [('Application', 'Speaker'), ('Speaker', '–'), ('–', 'This'), ('This', 'maintaining'), ('maintaining', 'model'), ('model', 'situation'), ('situation', '.')]

>> Trigrams are: 
 [('Application', 'Speaker', '–'), ('Speaker', '–', 'This'), ('–', 'This', 'maintaining'), ('This', 'maintaining', 'model'), ('maintaining', 'model', 'situation'), ('model', 'situation', '.')]

>> POS Tags are: 
 [('Application', 'NN'), ('Speaker', 'NNP'), ('–', 'NNP'), ('This', 'DT'), ('maintaining', 'VBG'), ('model', 'NN'), ('situation', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Application Speaker –', 'model situation']

>> Named Entities are: 
 [('PERSON', 'Speaker')] 

>> Stemming using Porter Stemmer: 
 [('Application', 'applic'), ('Speaker', 'speaker'), ('–', '–'), ('This', 'thi'), ('maintaining', 'maintain'), ('model', 'model'), ('situation', 'situat'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Application', 'applic'), ('Speaker', 'speaker'), ('–', '–'), ('This', 'this'), ('maintaining', 'maintain'), ('model', 'model'), ('situation', 'situat'), ('.', '.')]

>> Lemmatization: 
 [('Application', 'Application'), ('Speaker', 'Speaker'), ('–', '–'), ('This', 'This'), ('maintaining', 'maintaining'), ('model', 'model'), ('situation', 'situation'), ('.', '.')]


------------------- Sentence 2 -------------------

Here the

>> Tokens are: 
 ['Here']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Here', 'RB')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Here', 'here')]

>> Stemming using Snowball Stemmer: 
 [('Here', 'here')]

>> Lemmatization: 
 [('Here', 'Here')]



========================================== PARAGRAPH 194 ===========================================

speaker just initiates the process doesn’t take part in the language generation. It stores the  

------------------- Sentence 1 -------------------

speaker just initiates the process doesn’t take part in the language generation.

>> Tokens are: 
 ['speaker', 'initiates', 'process', '’', 'take', 'part', 'language', 'generation', '.']

>> Bigrams are: 
 [('speaker', 'initiates'), ('initiates', 'process'), ('process', '’'), ('’', 'take'), ('take', 'part'), ('part', 'language'), ('language', 'generation'), ('generation', '.')]

>> Trigrams are: 
 [('speaker', 'initiates', 'process'), ('initiates', 'process', '’'), ('process', '’', 'take'), ('’', 'take', 'part'), ('take', 'part', 'language'), ('part', 'language', 'generation'), ('language', 'generation', '.')]

>> POS Tags are: 
 [('speaker', 'NN'), ('initiates', 'VBZ'), ('process', 'JJ'), ('’', 'NNS'), ('take', 'VBP'), ('part', 'NN'), ('language', 'NN'), ('generation', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['speaker', 'process ’', 'part language generation']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('speaker', 'speaker'), ('initiates', 'initi'), ('process', 'process'), ('’', '’'), ('take', 'take'), ('part', 'part'), ('language', 'languag'), ('generation', 'gener'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('speaker', 'speaker'), ('initiates', 'initi'), ('process', 'process'), ('’', '’'), ('take', 'take'), ('part', 'part'), ('language', 'languag'), ('generation', 'generat'), ('.', '.')]

>> Lemmatization: 
 [('speaker', 'speaker'), ('initiates', 'initiate'), ('process', 'process'), ('’', '’'), ('take', 'take'), ('part', 'part'), ('language', 'language'), ('generation', 'generation'), ('.', '.')]


------------------- Sentence 2 -------------------

It stores the

>> Tokens are: 
 ['It', 'stores']

>> Bigrams are: 
 [('It', 'stores')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('It', 'PRP'), ('stores', 'NNS')]

>> Noun Phrases are: 
 ['stores']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('It', 'it'), ('stores', 'store')]

>> Stemming using Snowball Stemmer: 
 [('It', 'it'), ('stores', 'store')]

>> Lemmatization: 
 [('It', 'It'), ('stores', 'store')]



========================================== PARAGRAPH 195 ===========================================

history, structures the content that is potentially relevant and deploys a representation of what  

------------------- Sentence 1 -------------------

history, structures the content that is potentially relevant and deploys a representation of what

>> Tokens are: 
 ['history', ',', 'structures', 'content', 'potentially', 'relevant', 'deploys', 'representation']

>> Bigrams are: 
 [('history', ','), (',', 'structures'), ('structures', 'content'), ('content', 'potentially'), ('potentially', 'relevant'), ('relevant', 'deploys'), ('deploys', 'representation')]

>> Trigrams are: 
 [('history', ',', 'structures'), (',', 'structures', 'content'), ('structures', 'content', 'potentially'), ('content', 'potentially', 'relevant'), ('potentially', 'relevant', 'deploys'), ('relevant', 'deploys', 'representation')]

>> POS Tags are: 
 [('history', 'NN'), (',', ','), ('structures', 'VBZ'), ('content', 'JJ'), ('potentially', 'RB'), ('relevant', 'JJ'), ('deploys', 'NNS'), ('representation', 'NN')]

>> Noun Phrases are: 
 ['history', 'relevant deploys representation']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('history', 'histori'), (',', ','), ('structures', 'structur'), ('content', 'content'), ('potentially', 'potenti'), ('relevant', 'relev'), ('deploys', 'deploy'), ('representation', 'represent')]

>> Stemming using Snowball Stemmer: 
 [('history', 'histori'), (',', ','), ('structures', 'structur'), ('content', 'content'), ('potentially', 'potenti'), ('relevant', 'relev'), ('deploys', 'deploy'), ('representation', 'represent')]

>> Lemmatization: 
 [('history', 'history'), (',', ','), ('structures', 'structure'), ('content', 'content'), ('potentially', 'potentially'), ('relevant', 'relevant'), ('deploys', 'deploys'), ('representation', 'representation')]



========================================== PARAGRAPH 196 ===========================================

it actually knows. All these form the situation, while selecting subset of propositions that  

------------------- Sentence 1 -------------------

it actually knows.

>> Tokens are: 
 ['actually', 'knows', '.']

>> Bigrams are: 
 [('actually', 'knows'), ('knows', '.')]

>> Trigrams are: 
 [('actually', 'knows', '.')]

>> POS Tags are: 
 [('actually', 'RB'), ('knows', 'VBZ'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('actually', 'actual'), ('knows', 'know'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('actually', 'actual'), ('knows', 'know'), ('.', '.')]

>> Lemmatization: 
 [('actually', 'actually'), ('knows', 'know'), ('.', '.')]


------------------- Sentence 2 -------------------

All these form the situation, while selecting subset of propositions that

>> Tokens are: 
 ['All', 'form', 'situation', ',', 'selecting', 'subset', 'propositions']

>> Bigrams are: 
 [('All', 'form'), ('form', 'situation'), ('situation', ','), (',', 'selecting'), ('selecting', 'subset'), ('subset', 'propositions')]

>> Trigrams are: 
 [('All', 'form', 'situation'), ('form', 'situation', ','), ('situation', ',', 'selecting'), (',', 'selecting', 'subset'), ('selecting', 'subset', 'propositions')]

>> POS Tags are: 
 [('All', 'DT'), ('form', 'NN'), ('situation', 'NN'), (',', ','), ('selecting', 'VBG'), ('subset', 'NN'), ('propositions', 'NNS')]

>> Noun Phrases are: 
 ['All form situation', 'subset propositions']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('All', 'all'), ('form', 'form'), ('situation', 'situat'), (',', ','), ('selecting', 'select'), ('subset', 'subset'), ('propositions', 'proposit')]

>> Stemming using Snowball Stemmer: 
 [('All', 'all'), ('form', 'form'), ('situation', 'situat'), (',', ','), ('selecting', 'select'), ('subset', 'subset'), ('propositions', 'proposit')]

>> Lemmatization: 
 [('All', 'All'), ('form', 'form'), ('situation', 'situation'), (',', ','), ('selecting', 'selecting'), ('subset', 'subset'), ('propositions', 'proposition')]



========================================== PARAGRAPH 197 ===========================================

speaker has. The only requirement is the speaker has to make sense of the situation. [9]   

------------------- Sentence 1 -------------------

speaker has.

>> Tokens are: 
 ['speaker', '.']

>> Bigrams are: 
 [('speaker', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('speaker', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['speaker']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('speaker', 'speaker'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('speaker', 'speaker'), ('.', '.')]

>> Lemmatization: 
 [('speaker', 'speaker'), ('.', '.')]


------------------- Sentence 2 -------------------

The only requirement is the speaker has to make sense of the situation.

>> Tokens are: 
 ['The', 'requirement', 'speaker', 'make', 'sense', 'situation', '.']

>> Bigrams are: 
 [('The', 'requirement'), ('requirement', 'speaker'), ('speaker', 'make'), ('make', 'sense'), ('sense', 'situation'), ('situation', '.')]

>> Trigrams are: 
 [('The', 'requirement', 'speaker'), ('requirement', 'speaker', 'make'), ('speaker', 'make', 'sense'), ('make', 'sense', 'situation'), ('sense', 'situation', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('requirement', 'NN'), ('speaker', 'NN'), ('make', 'VBP'), ('sense', 'NN'), ('situation', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['The requirement speaker', 'sense situation']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('requirement', 'requir'), ('speaker', 'speaker'), ('make', 'make'), ('sense', 'sens'), ('situation', 'situat'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('requirement', 'requir'), ('speaker', 'speaker'), ('make', 'make'), ('sense', 'sens'), ('situation', 'situat'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('requirement', 'requirement'), ('speaker', 'speaker'), ('make', 'make'), ('sense', 'sense'), ('situation', 'situation'), ('.', '.')]


------------------- Sentence 3 -------------------

[9]

>> Tokens are: 
 ['[', '9', ']']

>> Bigrams are: 
 [('[', '9'), ('9', ']')]

>> Trigrams are: 
 [('[', '9', ']')]

>> POS Tags are: 
 [('[', 'RB'), ('9', 'CD'), (']', 'NNS')]

>> Noun Phrases are: 
 [']']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('9', '9'), (']', ']')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('9', '9'), (']', ']')]

>> Lemmatization: 
 [('[', '['), ('9', '9'), (']', ']')]



========================================== PARAGRAPH 198 ===========================================

4. History of NLP  

------------------- Sentence 1 -------------------

4.

>> Tokens are: 
 ['4', '.']

>> Bigrams are: 
 [('4', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('4', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('4', '4'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('4', '4'), ('.', '.')]

>> Lemmatization: 
 [('4', '4'), ('.', '.')]


------------------- Sentence 2 -------------------

History of NLP

>> Tokens are: 
 ['History', 'NLP']

>> Bigrams are: 
 [('History', 'NLP')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('History', 'NNP'), ('NLP', 'NNP')]

>> Noun Phrases are: 
 ['History NLP']

>> Named Entities are: 
 [('PERSON', 'History'), ('ORGANIZATION', 'NLP')] 

>> Stemming using Porter Stemmer: 
 [('History', 'histori'), ('NLP', 'nlp')]

>> Stemming using Snowball Stemmer: 
 [('History', 'histori'), ('NLP', 'nlp')]

>> Lemmatization: 
 [('History', 'History'), ('NLP', 'NLP')]



========================================== PARAGRAPH 199 ===========================================

In late 1940s the term wasn’t even in existence, but the work regarding machine translation  

------------------- Sentence 1 -------------------

In late 1940s the term wasn’t even in existence, but the work regarding machine translation

>> Tokens are: 
 ['In', 'late', '1940s', 'term', '’', 'even', 'existence', ',', 'work', 'regarding', 'machine', 'translation']

>> Bigrams are: 
 [('In', 'late'), ('late', '1940s'), ('1940s', 'term'), ('term', '’'), ('’', 'even'), ('even', 'existence'), ('existence', ','), (',', 'work'), ('work', 'regarding'), ('regarding', 'machine'), ('machine', 'translation')]

>> Trigrams are: 
 [('In', 'late', '1940s'), ('late', '1940s', 'term'), ('1940s', 'term', '’'), ('term', '’', 'even'), ('’', 'even', 'existence'), ('even', 'existence', ','), ('existence', ',', 'work'), (',', 'work', 'regarding'), ('work', 'regarding', 'machine'), ('regarding', 'machine', 'translation')]

>> POS Tags are: 
 [('In', 'IN'), ('late', 'JJ'), ('1940s', 'CD'), ('term', 'NN'), ('’', 'NNP'), ('even', 'RB'), ('existence', 'NN'), (',', ','), ('work', 'NN'), ('regarding', 'VBG'), ('machine', 'NN'), ('translation', 'NN')]

>> Noun Phrases are: 
 ['term ’', 'existence', 'work', 'machine translation']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('late', 'late'), ('1940s', '1940'), ('term', 'term'), ('’', '’'), ('even', 'even'), ('existence', 'exist'), (',', ','), ('work', 'work'), ('regarding', 'regard'), ('machine', 'machin'), ('translation', 'translat')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('late', 'late'), ('1940s', '1940s'), ('term', 'term'), ('’', '’'), ('even', 'even'), ('existence', 'exist'), (',', ','), ('work', 'work'), ('regarding', 'regard'), ('machine', 'machin'), ('translation', 'translat')]

>> Lemmatization: 
 [('In', 'In'), ('late', 'late'), ('1940s', '1940s'), ('term', 'term'), ('’', '’'), ('even', 'even'), ('existence', 'existence'), (',', ','), ('work', 'work'), ('regarding', 'regarding'), ('machine', 'machine'), ('translation', 'translation')]



========================================== PARAGRAPH 200 ===========================================

(MT) had started. Research in this period was not completely localised. Russian and English  

------------------- Sentence 1 -------------------

(MT) had started.

>> Tokens are: 
 ['(', 'MT', ')', 'started', '.']

>> Bigrams are: 
 [('(', 'MT'), ('MT', ')'), (')', 'started'), ('started', '.')]

>> Trigrams are: 
 [('(', 'MT', ')'), ('MT', ')', 'started'), (')', 'started', '.')]

>> POS Tags are: 
 [('(', '('), ('MT', 'NNP'), (')', ')'), ('started', 'VBD'), ('.', '.')]

>> Noun Phrases are: 
 ['MT']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('MT', 'mt'), (')', ')'), ('started', 'start'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('MT', 'mt'), (')', ')'), ('started', 'start'), ('.', '.')]

>> Lemmatization: 
 [('(', '('), ('MT', 'MT'), (')', ')'), ('started', 'started'), ('.', '.')]


------------------- Sentence 2 -------------------

Research in this period was not completely localised.

>> Tokens are: 
 ['Research', 'period', 'completely', 'localised', '.']

>> Bigrams are: 
 [('Research', 'period'), ('period', 'completely'), ('completely', 'localised'), ('localised', '.')]

>> Trigrams are: 
 [('Research', 'period', 'completely'), ('period', 'completely', 'localised'), ('completely', 'localised', '.')]

>> POS Tags are: 
 [('Research', 'NNP'), ('period', 'NN'), ('completely', 'RB'), ('localised', 'VBD'), ('.', '.')]

>> Noun Phrases are: 
 ['Research period']

>> Named Entities are: 
 [('GPE', 'Research')] 

>> Stemming using Porter Stemmer: 
 [('Research', 'research'), ('period', 'period'), ('completely', 'complet'), ('localised', 'localis'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Research', 'research'), ('period', 'period'), ('completely', 'complet'), ('localised', 'localis'), ('.', '.')]

>> Lemmatization: 
 [('Research', 'Research'), ('period', 'period'), ('completely', 'completely'), ('localised', 'localised'), ('.', '.')]


------------------- Sentence 3 -------------------

Russian and English

>> Tokens are: 
 ['Russian', 'English']

>> Bigrams are: 
 [('Russian', 'English')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Russian', 'JJ'), ('English', 'NNP')]

>> Noun Phrases are: 
 ['Russian English']

>> Named Entities are: 
 [('GPE', 'Russian'), ('GPE', 'English')] 

>> Stemming using Porter Stemmer: 
 [('Russian', 'russian'), ('English', 'english')]

>> Stemming using Snowball Stemmer: 
 [('Russian', 'russian'), ('English', 'english')]

>> Lemmatization: 
 [('Russian', 'Russian'), ('English', 'English')]



========================================== PARAGRAPH 201 ===========================================

were the dominant languages for MT, but others, like Chinese were used for MT (Booth  

------------------- Sentence 1 -------------------

were the dominant languages for MT, but others, like Chinese were used for MT (Booth

>> Tokens are: 
 ['dominant', 'languages', 'MT', ',', 'others', ',', 'like', 'Chinese', 'used', 'MT', '(', 'Booth']

>> Bigrams are: 
 [('dominant', 'languages'), ('languages', 'MT'), ('MT', ','), (',', 'others'), ('others', ','), (',', 'like'), ('like', 'Chinese'), ('Chinese', 'used'), ('used', 'MT'), ('MT', '('), ('(', 'Booth')]

>> Trigrams are: 
 [('dominant', 'languages', 'MT'), ('languages', 'MT', ','), ('MT', ',', 'others'), (',', 'others', ','), ('others', ',', 'like'), (',', 'like', 'Chinese'), ('like', 'Chinese', 'used'), ('Chinese', 'used', 'MT'), ('used', 'MT', '('), ('MT', '(', 'Booth')]

>> POS Tags are: 
 [('dominant', 'JJ'), ('languages', 'NNS'), ('MT', 'NNP'), (',', ','), ('others', 'NNS'), (',', ','), ('like', 'IN'), ('Chinese', 'NNP'), ('used', 'VBD'), ('MT', 'NNP'), ('(', '('), ('Booth', 'NNP')]

>> Noun Phrases are: 
 ['dominant languages MT', 'others', 'Chinese', 'MT', 'Booth']

>> Named Entities are: 
 [('GPE', 'Chinese')] 

>> Stemming using Porter Stemmer: 
 [('dominant', 'domin'), ('languages', 'languag'), ('MT', 'mt'), (',', ','), ('others', 'other'), (',', ','), ('like', 'like'), ('Chinese', 'chines'), ('used', 'use'), ('MT', 'mt'), ('(', '('), ('Booth', 'booth')]

>> Stemming using Snowball Stemmer: 
 [('dominant', 'domin'), ('languages', 'languag'), ('MT', 'mt'), (',', ','), ('others', 'other'), (',', ','), ('like', 'like'), ('Chinese', 'chines'), ('used', 'use'), ('MT', 'mt'), ('(', '('), ('Booth', 'booth')]

>> Lemmatization: 
 [('dominant', 'dominant'), ('languages', 'language'), ('MT', 'MT'), (',', ','), ('others', 'others'), (',', ','), ('like', 'like'), ('Chinese', 'Chinese'), ('used', 'used'), ('MT', 'MT'), ('(', '('), ('Booth', 'Booth')]



========================================== PARAGRAPH 202 ===========================================

,1967) [10]. MT/NLP research was almost died in 1966 according to ALPAC report, which  

------------------- Sentence 1 -------------------

,1967) [10].

>> Tokens are: 
 [',1967', ')', '[', '10', ']', '.']

>> Bigrams are: 
 [(',1967', ')'), (')', '['), ('[', '10'), ('10', ']'), (']', '.')]

>> Trigrams are: 
 [(',1967', ')', '['), (')', '[', '10'), ('[', '10', ']'), ('10', ']', '.')]

>> POS Tags are: 
 [(',1967', 'NN'), (')', ')'), ('[', 'VBZ'), ('10', 'CD'), (']', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 [',1967', ']']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [(',1967', ',1967'), (')', ')'), ('[', '['), ('10', '10'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [(',1967', ',1967'), (')', ')'), ('[', '['), ('10', '10'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [(',1967', ',1967'), (')', ')'), ('[', '['), ('10', '10'), (']', ']'), ('.', '.')]


------------------- Sentence 2 -------------------

MT/NLP research was almost died in 1966 according to ALPAC report, which

>> Tokens are: 
 ['MT/NLP', 'research', 'almost', 'died', '1966', 'according', 'ALPAC', 'report', ',']

>> Bigrams are: 
 [('MT/NLP', 'research'), ('research', 'almost'), ('almost', 'died'), ('died', '1966'), ('1966', 'according'), ('according', 'ALPAC'), ('ALPAC', 'report'), ('report', ',')]

>> Trigrams are: 
 [('MT/NLP', 'research', 'almost'), ('research', 'almost', 'died'), ('almost', 'died', '1966'), ('died', '1966', 'according'), ('1966', 'according', 'ALPAC'), ('according', 'ALPAC', 'report'), ('ALPAC', 'report', ',')]

>> POS Tags are: 
 [('MT/NLP', 'NNP'), ('research', 'NN'), ('almost', 'RB'), ('died', 'VBD'), ('1966', 'CD'), ('according', 'VBG'), ('ALPAC', 'NNP'), ('report', 'NN'), (',', ',')]

>> Noun Phrases are: 
 ['MT/NLP research', 'ALPAC report']

>> Named Entities are: 
 [('ORGANIZATION', 'ALPAC')] 

>> Stemming using Porter Stemmer: 
 [('MT/NLP', 'mt/nlp'), ('research', 'research'), ('almost', 'almost'), ('died', 'die'), ('1966', '1966'), ('according', 'accord'), ('ALPAC', 'alpac'), ('report', 'report'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('MT/NLP', 'mt/nlp'), ('research', 'research'), ('almost', 'almost'), ('died', 'die'), ('1966', '1966'), ('according', 'accord'), ('ALPAC', 'alpac'), ('report', 'report'), (',', ',')]

>> Lemmatization: 
 [('MT/NLP', 'MT/NLP'), ('research', 'research'), ('almost', 'almost'), ('died', 'died'), ('1966', '1966'), ('according', 'according'), ('ALPAC', 'ALPAC'), ('report', 'report'), (',', ',')]



========================================== PARAGRAPH 203 ===========================================

concluded that MT is going nowhere. But later on some MT production systems were  

------------------- Sentence 1 -------------------

concluded that MT is going nowhere.

>> Tokens are: 
 ['concluded', 'MT', 'going', 'nowhere', '.']

>> Bigrams are: 
 [('concluded', 'MT'), ('MT', 'going'), ('going', 'nowhere'), ('nowhere', '.')]

>> Trigrams are: 
 [('concluded', 'MT', 'going'), ('MT', 'going', 'nowhere'), ('going', 'nowhere', '.')]

>> POS Tags are: 
 [('concluded', 'VBN'), ('MT', 'NNP'), ('going', 'VBG'), ('nowhere', 'RB'), ('.', '.')]

>> Noun Phrases are: 
 ['MT']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('concluded', 'conclud'), ('MT', 'mt'), ('going', 'go'), ('nowhere', 'nowher'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('concluded', 'conclud'), ('MT', 'mt'), ('going', 'go'), ('nowhere', 'nowher'), ('.', '.')]

>> Lemmatization: 
 [('concluded', 'concluded'), ('MT', 'MT'), ('going', 'going'), ('nowhere', 'nowhere'), ('.', '.')]


------------------- Sentence 2 -------------------

But later on some MT production systems were

>> Tokens are: 
 ['But', 'later', 'MT', 'production', 'systems']

>> Bigrams are: 
 [('But', 'later'), ('later', 'MT'), ('MT', 'production'), ('production', 'systems')]

>> Trigrams are: 
 [('But', 'later', 'MT'), ('later', 'MT', 'production'), ('MT', 'production', 'systems')]

>> POS Tags are: 
 [('But', 'CC'), ('later', 'RBR'), ('MT', 'NNP'), ('production', 'NN'), ('systems', 'NNS')]

>> Noun Phrases are: 
 ['MT production systems']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('But', 'but'), ('later', 'later'), ('MT', 'mt'), ('production', 'product'), ('systems', 'system')]

>> Stemming using Snowball Stemmer: 
 [('But', 'but'), ('later', 'later'), ('MT', 'mt'), ('production', 'product'), ('systems', 'system')]

>> Lemmatization: 
 [('But', 'But'), ('later', 'later'), ('MT', 'MT'), ('production', 'production'), ('systems', 'system')]



========================================== PARAGRAPH 204 ===========================================

providing output to their customers (Hutchins, 1986) [11]. By this time, work on the use of  

------------------- Sentence 1 -------------------

providing output to their customers (Hutchins, 1986) [11].

>> Tokens are: 
 ['providing', 'output', 'customers', '(', 'Hutchins', ',', '1986', ')', '[', '11', ']', '.']

>> Bigrams are: 
 [('providing', 'output'), ('output', 'customers'), ('customers', '('), ('(', 'Hutchins'), ('Hutchins', ','), (',', '1986'), ('1986', ')'), (')', '['), ('[', '11'), ('11', ']'), (']', '.')]

>> Trigrams are: 
 [('providing', 'output', 'customers'), ('output', 'customers', '('), ('customers', '(', 'Hutchins'), ('(', 'Hutchins', ','), ('Hutchins', ',', '1986'), (',', '1986', ')'), ('1986', ')', '['), (')', '[', '11'), ('[', '11', ']'), ('11', ']', '.')]

>> POS Tags are: 
 [('providing', 'VBG'), ('output', 'NN'), ('customers', 'NNS'), ('(', '('), ('Hutchins', 'NNP'), (',', ','), ('1986', 'CD'), (')', ')'), ('[', 'VBD'), ('11', 'CD'), (']', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['output customers', 'Hutchins', ']']

>> Named Entities are: 
 [('ORGANIZATION', 'Hutchins')] 

>> Stemming using Porter Stemmer: 
 [('providing', 'provid'), ('output', 'output'), ('customers', 'custom'), ('(', '('), ('Hutchins', 'hutchin'), (',', ','), ('1986', '1986'), (')', ')'), ('[', '['), ('11', '11'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('providing', 'provid'), ('output', 'output'), ('customers', 'custom'), ('(', '('), ('Hutchins', 'hutchin'), (',', ','), ('1986', '1986'), (')', ')'), ('[', '['), ('11', '11'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('providing', 'providing'), ('output', 'output'), ('customers', 'customer'), ('(', '('), ('Hutchins', 'Hutchins'), (',', ','), ('1986', '1986'), (')', ')'), ('[', '['), ('11', '11'), (']', ']'), ('.', '.')]


------------------- Sentence 2 -------------------

By this time, work on the use of

>> Tokens are: 
 ['By', 'time', ',', 'work', 'use']

>> Bigrams are: 
 [('By', 'time'), ('time', ','), (',', 'work'), ('work', 'use')]

>> Trigrams are: 
 [('By', 'time', ','), ('time', ',', 'work'), (',', 'work', 'use')]

>> POS Tags are: 
 [('By', 'IN'), ('time', 'NN'), (',', ','), ('work', 'NN'), ('use', 'NN')]

>> Noun Phrases are: 
 ['time', 'work use']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('By', 'by'), ('time', 'time'), (',', ','), ('work', 'work'), ('use', 'use')]

>> Stemming using Snowball Stemmer: 
 [('By', 'by'), ('time', 'time'), (',', ','), ('work', 'work'), ('use', 'use')]

>> Lemmatization: 
 [('By', 'By'), ('time', 'time'), (',', ','), ('work', 'work'), ('use', 'use')]



========================================== PARAGRAPH 205 ===========================================

computers for literary and linguistic studies had also started.   

------------------- Sentence 1 -------------------

computers for literary and linguistic studies had also started.

>> Tokens are: 
 ['computers', 'literary', 'linguistic', 'studies', 'also', 'started', '.']

>> Bigrams are: 
 [('computers', 'literary'), ('literary', 'linguistic'), ('linguistic', 'studies'), ('studies', 'also'), ('also', 'started'), ('started', '.')]

>> Trigrams are: 
 [('computers', 'literary', 'linguistic'), ('literary', 'linguistic', 'studies'), ('linguistic', 'studies', 'also'), ('studies', 'also', 'started'), ('also', 'started', '.')]

>> POS Tags are: 
 [('computers', 'NNS'), ('literary', 'JJ'), ('linguistic', 'JJ'), ('studies', 'NNS'), ('also', 'RB'), ('started', 'VBD'), ('.', '.')]

>> Noun Phrases are: 
 ['computers', 'literary linguistic studies']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('computers', 'comput'), ('literary', 'literari'), ('linguistic', 'linguist'), ('studies', 'studi'), ('also', 'also'), ('started', 'start'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('computers', 'comput'), ('literary', 'literari'), ('linguistic', 'linguist'), ('studies', 'studi'), ('also', 'also'), ('started', 'start'), ('.', '.')]

>> Lemmatization: 
 [('computers', 'computer'), ('literary', 'literary'), ('linguistic', 'linguistic'), ('studies', 'study'), ('also', 'also'), ('started', 'started'), ('.', '.')]



========================================== PARAGRAPH 206 ===========================================

As early as 1960 signature work influenced by AI began, with the BASEBALL Q-A systems  

------------------- Sentence 1 -------------------

As early as 1960 signature work influenced by AI began, with the BASEBALL Q-A systems

>> Tokens are: 
 ['As', 'early', '1960', 'signature', 'work', 'influenced', 'AI', 'began', ',', 'BASEBALL', 'Q-A', 'systems']

>> Bigrams are: 
 [('As', 'early'), ('early', '1960'), ('1960', 'signature'), ('signature', 'work'), ('work', 'influenced'), ('influenced', 'AI'), ('AI', 'began'), ('began', ','), (',', 'BASEBALL'), ('BASEBALL', 'Q-A'), ('Q-A', 'systems')]

>> Trigrams are: 
 [('As', 'early', '1960'), ('early', '1960', 'signature'), ('1960', 'signature', 'work'), ('signature', 'work', 'influenced'), ('work', 'influenced', 'AI'), ('influenced', 'AI', 'began'), ('AI', 'began', ','), ('began', ',', 'BASEBALL'), (',', 'BASEBALL', 'Q-A'), ('BASEBALL', 'Q-A', 'systems')]

>> POS Tags are: 
 [('As', 'IN'), ('early', 'JJ'), ('1960', 'CD'), ('signature', 'NN'), ('work', 'NN'), ('influenced', 'VBD'), ('AI', 'NNP'), ('began', 'VBD'), (',', ','), ('BASEBALL', 'NNP'), ('Q-A', 'NNP'), ('systems', 'NNS')]

>> Noun Phrases are: 
 ['signature work', 'AI', 'BASEBALL Q-A systems']

>> Named Entities are: 
 [('ORGANIZATION', 'AI'), ('ORGANIZATION', 'BASEBALL')] 

>> Stemming using Porter Stemmer: 
 [('As', 'as'), ('early', 'earli'), ('1960', '1960'), ('signature', 'signatur'), ('work', 'work'), ('influenced', 'influenc'), ('AI', 'ai'), ('began', 'began'), (',', ','), ('BASEBALL', 'basebal'), ('Q-A', 'q-a'), ('systems', 'system')]

>> Stemming using Snowball Stemmer: 
 [('As', 'as'), ('early', 'earli'), ('1960', '1960'), ('signature', 'signatur'), ('work', 'work'), ('influenced', 'influenc'), ('AI', 'ai'), ('began', 'began'), (',', ','), ('BASEBALL', 'basebal'), ('Q-A', 'q-a'), ('systems', 'system')]

>> Lemmatization: 
 [('As', 'As'), ('early', 'early'), ('1960', '1960'), ('signature', 'signature'), ('work', 'work'), ('influenced', 'influenced'), ('AI', 'AI'), ('began', 'began'), (',', ','), ('BASEBALL', 'BASEBALL'), ('Q-A', 'Q-A'), ('systems', 'system')]



========================================== PARAGRAPH 207 ===========================================

(Green et al., 1961) [12]. LUNAR (Woods ,1978) [13] and Winograd SHRDLU were natural  

------------------- Sentence 1 -------------------

(Green et al., 1961) [12].

>> Tokens are: 
 ['(', 'Green', 'et', 'al.', ',', '1961', ')', '[', '12', ']', '.']

>> Bigrams are: 
 [('(', 'Green'), ('Green', 'et'), ('et', 'al.'), ('al.', ','), (',', '1961'), ('1961', ')'), (')', '['), ('[', '12'), ('12', ']'), (']', '.')]

>> Trigrams are: 
 [('(', 'Green', 'et'), ('Green', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '1961'), (',', '1961', ')'), ('1961', ')', '['), (')', '[', '12'), ('[', '12', ']'), ('12', ']', '.')]

>> POS Tags are: 
 [('(', '('), ('Green', 'JJ'), ('et', 'NN'), ('al.', 'NN'), (',', ','), ('1961', 'CD'), (')', ')'), ('[', 'VBD'), ('12', 'CD'), (']', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Green et al.', ']']

>> Named Entities are: 
 [('GPE', 'Green')] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('Green', 'green'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('1961', '1961'), (')', ')'), ('[', '['), ('12', '12'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('Green', 'green'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('1961', '1961'), (')', ')'), ('[', '['), ('12', '12'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('(', '('), ('Green', 'Green'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('1961', '1961'), (')', ')'), ('[', '['), ('12', '12'), (']', ']'), ('.', '.')]


------------------- Sentence 2 -------------------

LUNAR (Woods ,1978) [13] and Winograd SHRDLU were natural

>> Tokens are: 
 ['LUNAR', '(', 'Woods', ',1978', ')', '[', '13', ']', 'Winograd', 'SHRDLU', 'natural']

>> Bigrams are: 
 [('LUNAR', '('), ('(', 'Woods'), ('Woods', ',1978'), (',1978', ')'), (')', '['), ('[', '13'), ('13', ']'), (']', 'Winograd'), ('Winograd', 'SHRDLU'), ('SHRDLU', 'natural')]

>> Trigrams are: 
 [('LUNAR', '(', 'Woods'), ('(', 'Woods', ',1978'), ('Woods', ',1978', ')'), (',1978', ')', '['), (')', '[', '13'), ('[', '13', ']'), ('13', ']', 'Winograd'), (']', 'Winograd', 'SHRDLU'), ('Winograd', 'SHRDLU', 'natural')]

>> POS Tags are: 
 [('LUNAR', 'NNP'), ('(', '('), ('Woods', 'NNP'), (',1978', 'NNP'), (')', ')'), ('[', 'VBD'), ('13', 'CD'), (']', 'NNP'), ('Winograd', 'NNP'), ('SHRDLU', 'NNP'), ('natural', 'JJ')]

>> Noun Phrases are: 
 ['LUNAR', 'Woods ,1978', '] Winograd SHRDLU']

>> Named Entities are: 
 [('GPE', 'LUNAR'), ('PERSON', 'Woods')] 

>> Stemming using Porter Stemmer: 
 [('LUNAR', 'lunar'), ('(', '('), ('Woods', 'wood'), (',1978', ',1978'), (')', ')'), ('[', '['), ('13', '13'), (']', ']'), ('Winograd', 'winograd'), ('SHRDLU', 'shrdlu'), ('natural', 'natur')]

>> Stemming using Snowball Stemmer: 
 [('LUNAR', 'lunar'), ('(', '('), ('Woods', 'wood'), (',1978', ',1978'), (')', ')'), ('[', '['), ('13', '13'), (']', ']'), ('Winograd', 'winograd'), ('SHRDLU', 'shrdlu'), ('natural', 'natur')]

>> Lemmatization: 
 [('LUNAR', 'LUNAR'), ('(', '('), ('Woods', 'Woods'), (',1978', ',1978'), (')', ')'), ('[', '['), ('13', '13'), (']', ']'), ('Winograd', 'Winograd'), ('SHRDLU', 'SHRDLU'), ('natural', 'natural')]



========================================== PARAGRAPH 208 ===========================================

successors of these systems but they were seen as stepped up sophistication, in terms of their  

------------------- Sentence 1 -------------------

successors of these systems but they were seen as stepped up sophistication, in terms of their

>> Tokens are: 
 ['successors', 'systems', 'seen', 'stepped', 'sophistication', ',', 'terms']

>> Bigrams are: 
 [('successors', 'systems'), ('systems', 'seen'), ('seen', 'stepped'), ('stepped', 'sophistication'), ('sophistication', ','), (',', 'terms')]

>> Trigrams are: 
 [('successors', 'systems', 'seen'), ('systems', 'seen', 'stepped'), ('seen', 'stepped', 'sophistication'), ('stepped', 'sophistication', ','), ('sophistication', ',', 'terms')]

>> POS Tags are: 
 [('successors', 'NNS'), ('systems', 'NNS'), ('seen', 'VBN'), ('stepped', 'JJ'), ('sophistication', 'NN'), (',', ','), ('terms', 'NNS')]

>> Noun Phrases are: 
 ['successors systems', 'stepped sophistication', 'terms']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('successors', 'successor'), ('systems', 'system'), ('seen', 'seen'), ('stepped', 'step'), ('sophistication', 'sophist'), (',', ','), ('terms', 'term')]

>> Stemming using Snowball Stemmer: 
 [('successors', 'successor'), ('systems', 'system'), ('seen', 'seen'), ('stepped', 'step'), ('sophistication', 'sophist'), (',', ','), ('terms', 'term')]

>> Lemmatization: 
 [('successors', 'successor'), ('systems', 'system'), ('seen', 'seen'), ('stepped', 'stepped'), ('sophistication', 'sophistication'), (',', ','), ('terms', 'term')]



========================================== PARAGRAPH 209 ===========================================

linguistic and their task processing capabilities. There was a widespread belief that progress  

------------------- Sentence 1 -------------------

linguistic and their task processing capabilities.

>> Tokens are: 
 ['linguistic', 'task', 'processing', 'capabilities', '.']

>> Bigrams are: 
 [('linguistic', 'task'), ('task', 'processing'), ('processing', 'capabilities'), ('capabilities', '.')]

>> Trigrams are: 
 [('linguistic', 'task', 'processing'), ('task', 'processing', 'capabilities'), ('processing', 'capabilities', '.')]

>> POS Tags are: 
 [('linguistic', 'JJ'), ('task', 'NN'), ('processing', 'NN'), ('capabilities', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['linguistic task processing capabilities']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('linguistic', 'linguist'), ('task', 'task'), ('processing', 'process'), ('capabilities', 'capabl'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('linguistic', 'linguist'), ('task', 'task'), ('processing', 'process'), ('capabilities', 'capabl'), ('.', '.')]

>> Lemmatization: 
 [('linguistic', 'linguistic'), ('task', 'task'), ('processing', 'processing'), ('capabilities', 'capability'), ('.', '.')]


------------------- Sentence 2 -------------------

There was a widespread belief that progress

>> Tokens are: 
 ['There', 'widespread', 'belief', 'progress']

>> Bigrams are: 
 [('There', 'widespread'), ('widespread', 'belief'), ('belief', 'progress')]

>> Trigrams are: 
 [('There', 'widespread', 'belief'), ('widespread', 'belief', 'progress')]

>> POS Tags are: 
 [('There', 'EX'), ('widespread', 'JJ'), ('belief', 'NN'), ('progress', 'NN')]

>> Noun Phrases are: 
 ['widespread belief progress']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('There', 'there'), ('widespread', 'widespread'), ('belief', 'belief'), ('progress', 'progress')]

>> Stemming using Snowball Stemmer: 
 [('There', 'there'), ('widespread', 'widespread'), ('belief', 'belief'), ('progress', 'progress')]

>> Lemmatization: 
 [('There', 'There'), ('widespread', 'widespread'), ('belief', 'belief'), ('progress', 'progress')]



========================================== PARAGRAPH 210 ===========================================

could only be made on the two sides, one is ARPA Speech Understanding Research (SUR)  

------------------- Sentence 1 -------------------

could only be made on the two sides, one is ARPA Speech Understanding Research (SUR)

>> Tokens are: 
 ['could', 'made', 'two', 'sides', ',', 'one', 'ARPA', 'Speech', 'Understanding', 'Research', '(', 'SUR', ')']

>> Bigrams are: 
 [('could', 'made'), ('made', 'two'), ('two', 'sides'), ('sides', ','), (',', 'one'), ('one', 'ARPA'), ('ARPA', 'Speech'), ('Speech', 'Understanding'), ('Understanding', 'Research'), ('Research', '('), ('(', 'SUR'), ('SUR', ')')]

>> Trigrams are: 
 [('could', 'made', 'two'), ('made', 'two', 'sides'), ('two', 'sides', ','), ('sides', ',', 'one'), (',', 'one', 'ARPA'), ('one', 'ARPA', 'Speech'), ('ARPA', 'Speech', 'Understanding'), ('Speech', 'Understanding', 'Research'), ('Understanding', 'Research', '('), ('Research', '(', 'SUR'), ('(', 'SUR', ')')]

>> POS Tags are: 
 [('could', 'MD'), ('made', 'VB'), ('two', 'CD'), ('sides', 'NNS'), (',', ','), ('one', 'CD'), ('ARPA', 'NNP'), ('Speech', 'NNP'), ('Understanding', 'NNP'), ('Research', 'NNP'), ('(', '('), ('SUR', 'NNP'), (')', ')')]

>> Noun Phrases are: 
 ['sides', 'ARPA Speech Understanding Research', 'SUR']

>> Named Entities are: 
 [('ORGANIZATION', 'ARPA Speech'), ('ORGANIZATION', 'SUR')] 

>> Stemming using Porter Stemmer: 
 [('could', 'could'), ('made', 'made'), ('two', 'two'), ('sides', 'side'), (',', ','), ('one', 'one'), ('ARPA', 'arpa'), ('Speech', 'speech'), ('Understanding', 'understand'), ('Research', 'research'), ('(', '('), ('SUR', 'sur'), (')', ')')]

>> Stemming using Snowball Stemmer: 
 [('could', 'could'), ('made', 'made'), ('two', 'two'), ('sides', 'side'), (',', ','), ('one', 'one'), ('ARPA', 'arpa'), ('Speech', 'speech'), ('Understanding', 'understand'), ('Research', 'research'), ('(', '('), ('SUR', 'sur'), (')', ')')]

>> Lemmatization: 
 [('could', 'could'), ('made', 'made'), ('two', 'two'), ('sides', 'side'), (',', ','), ('one', 'one'), ('ARPA', 'ARPA'), ('Speech', 'Speech'), ('Understanding', 'Understanding'), ('Research', 'Research'), ('(', '('), ('SUR', 'SUR'), (')', ')')]



========================================== PARAGRAPH 211 ===========================================

project (Lea, 1980) and other in some major system developments projects building database  

------------------- Sentence 1 -------------------

project (Lea, 1980) and other in some major system developments projects building database

>> Tokens are: 
 ['project', '(', 'Lea', ',', '1980', ')', 'major', 'system', 'developments', 'projects', 'building', 'database']

>> Bigrams are: 
 [('project', '('), ('(', 'Lea'), ('Lea', ','), (',', '1980'), ('1980', ')'), (')', 'major'), ('major', 'system'), ('system', 'developments'), ('developments', 'projects'), ('projects', 'building'), ('building', 'database')]

>> Trigrams are: 
 [('project', '(', 'Lea'), ('(', 'Lea', ','), ('Lea', ',', '1980'), (',', '1980', ')'), ('1980', ')', 'major'), (')', 'major', 'system'), ('major', 'system', 'developments'), ('system', 'developments', 'projects'), ('developments', 'projects', 'building'), ('projects', 'building', 'database')]

>> POS Tags are: 
 [('project', 'NN'), ('(', '('), ('Lea', 'NNP'), (',', ','), ('1980', 'CD'), (')', ')'), ('major', 'JJ'), ('system', 'NN'), ('developments', 'NNS'), ('projects', 'NNS'), ('building', 'VBG'), ('database', 'NN')]

>> Noun Phrases are: 
 ['project', 'Lea', 'major system developments projects', 'database']

>> Named Entities are: 
 [('ORGANIZATION', 'Lea')] 

>> Stemming using Porter Stemmer: 
 [('project', 'project'), ('(', '('), ('Lea', 'lea'), (',', ','), ('1980', '1980'), (')', ')'), ('major', 'major'), ('system', 'system'), ('developments', 'develop'), ('projects', 'project'), ('building', 'build'), ('database', 'databas')]

>> Stemming using Snowball Stemmer: 
 [('project', 'project'), ('(', '('), ('Lea', 'lea'), (',', ','), ('1980', '1980'), (')', ')'), ('major', 'major'), ('system', 'system'), ('developments', 'develop'), ('projects', 'project'), ('building', 'build'), ('database', 'databas')]

>> Lemmatization: 
 [('project', 'project'), ('(', '('), ('Lea', 'Lea'), (',', ','), ('1980', '1980'), (')', ')'), ('major', 'major'), ('system', 'system'), ('developments', 'development'), ('projects', 'project'), ('building', 'building'), ('database', 'database')]



========================================== PARAGRAPH 212 ===========================================

front ends. The front-end projects (Hendrix et al., 1978) [14] were intended to go beyond  

------------------- Sentence 1 -------------------

front ends.

>> Tokens are: 
 ['front', 'ends', '.']

>> Bigrams are: 
 [('front', 'ends'), ('ends', '.')]

>> Trigrams are: 
 [('front', 'ends', '.')]

>> POS Tags are: 
 [('front', 'JJ'), ('ends', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['front ends']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('front', 'front'), ('ends', 'end'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('front', 'front'), ('ends', 'end'), ('.', '.')]

>> Lemmatization: 
 [('front', 'front'), ('ends', 'end'), ('.', '.')]


------------------- Sentence 2 -------------------

The front-end projects (Hendrix et al., 1978) [14] were intended to go beyond

>> Tokens are: 
 ['The', 'front-end', 'projects', '(', 'Hendrix', 'et', 'al.', ',', '1978', ')', '[', '14', ']', 'intended', 'go', 'beyond']

>> Bigrams are: 
 [('The', 'front-end'), ('front-end', 'projects'), ('projects', '('), ('(', 'Hendrix'), ('Hendrix', 'et'), ('et', 'al.'), ('al.', ','), (',', '1978'), ('1978', ')'), (')', '['), ('[', '14'), ('14', ']'), (']', 'intended'), ('intended', 'go'), ('go', 'beyond')]

>> Trigrams are: 
 [('The', 'front-end', 'projects'), ('front-end', 'projects', '('), ('projects', '(', 'Hendrix'), ('(', 'Hendrix', 'et'), ('Hendrix', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '1978'), (',', '1978', ')'), ('1978', ')', '['), (')', '[', '14'), ('[', '14', ']'), ('14', ']', 'intended'), (']', 'intended', 'go'), ('intended', 'go', 'beyond')]

>> POS Tags are: 
 [('The', 'DT'), ('front-end', 'JJ'), ('projects', 'NNS'), ('(', '('), ('Hendrix', 'NNP'), ('et', 'RB'), ('al.', 'RB'), (',', ','), ('1978', 'CD'), (')', ')'), ('[', 'VBD'), ('14', 'CD'), (']', 'NN'), ('intended', 'VBN'), ('go', 'VBP'), ('beyond', 'IN')]

>> Noun Phrases are: 
 ['The front-end projects', 'Hendrix', ']']

>> Named Entities are: 
 [('PERSON', 'Hendrix')] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('front-end', 'front-end'), ('projects', 'project'), ('(', '('), ('Hendrix', 'hendrix'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('1978', '1978'), (')', ')'), ('[', '['), ('14', '14'), (']', ']'), ('intended', 'intend'), ('go', 'go'), ('beyond', 'beyond')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('front-end', 'front-end'), ('projects', 'project'), ('(', '('), ('Hendrix', 'hendrix'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('1978', '1978'), (')', ')'), ('[', '['), ('14', '14'), (']', ']'), ('intended', 'intend'), ('go', 'go'), ('beyond', 'beyond')]

>> Lemmatization: 
 [('The', 'The'), ('front-end', 'front-end'), ('projects', 'project'), ('(', '('), ('Hendrix', 'Hendrix'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('1978', '1978'), (')', ')'), ('[', '['), ('14', '14'), (']', ']'), ('intended', 'intended'), ('go', 'go'), ('beyond', 'beyond')]



========================================== PARAGRAPH 213 ===========================================

LUNAR in interfacing the large databases.  

------------------- Sentence 1 -------------------

LUNAR in interfacing the large databases.

>> Tokens are: 
 ['LUNAR', 'interfacing', 'large', 'databases', '.']

>> Bigrams are: 
 [('LUNAR', 'interfacing'), ('interfacing', 'large'), ('large', 'databases'), ('databases', '.')]

>> Trigrams are: 
 [('LUNAR', 'interfacing', 'large'), ('interfacing', 'large', 'databases'), ('large', 'databases', '.')]

>> POS Tags are: 
 [('LUNAR', 'NNP'), ('interfacing', 'VBG'), ('large', 'JJ'), ('databases', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['LUNAR', 'large databases']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('LUNAR', 'lunar'), ('interfacing', 'interfac'), ('large', 'larg'), ('databases', 'databas'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('LUNAR', 'lunar'), ('interfacing', 'interfac'), ('large', 'larg'), ('databases', 'databas'), ('.', '.')]

>> Lemmatization: 
 [('LUNAR', 'LUNAR'), ('interfacing', 'interfacing'), ('large', 'large'), ('databases', 'database'), ('.', '.')]



========================================== PARAGRAPH 214 ===========================================

In early 1980s computational grammar theory became a very active area of research linked  

------------------- Sentence 1 -------------------

In early 1980s computational grammar theory became a very active area of research linked

>> Tokens are: 
 ['In', 'early', '1980s', 'computational', 'grammar', 'theory', 'became', 'active', 'area', 'research', 'linked']

>> Bigrams are: 
 [('In', 'early'), ('early', '1980s'), ('1980s', 'computational'), ('computational', 'grammar'), ('grammar', 'theory'), ('theory', 'became'), ('became', 'active'), ('active', 'area'), ('area', 'research'), ('research', 'linked')]

>> Trigrams are: 
 [('In', 'early', '1980s'), ('early', '1980s', 'computational'), ('1980s', 'computational', 'grammar'), ('computational', 'grammar', 'theory'), ('grammar', 'theory', 'became'), ('theory', 'became', 'active'), ('became', 'active', 'area'), ('active', 'area', 'research'), ('area', 'research', 'linked')]

>> POS Tags are: 
 [('In', 'IN'), ('early', 'JJ'), ('1980s', 'CD'), ('computational', 'JJ'), ('grammar', 'NN'), ('theory', 'NN'), ('became', 'VBD'), ('active', 'JJ'), ('area', 'NN'), ('research', 'NN'), ('linked', 'VBD')]

>> Noun Phrases are: 
 ['computational grammar theory', 'active area research']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('early', 'earli'), ('1980s', '1980'), ('computational', 'comput'), ('grammar', 'grammar'), ('theory', 'theori'), ('became', 'becam'), ('active', 'activ'), ('area', 'area'), ('research', 'research'), ('linked', 'link')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('early', 'earli'), ('1980s', '1980s'), ('computational', 'comput'), ('grammar', 'grammar'), ('theory', 'theori'), ('became', 'becam'), ('active', 'activ'), ('area', 'area'), ('research', 'research'), ('linked', 'link')]

>> Lemmatization: 
 [('In', 'In'), ('early', 'early'), ('1980s', '1980s'), ('computational', 'computational'), ('grammar', 'grammar'), ('theory', 'theory'), ('became', 'became'), ('active', 'active'), ('area', 'area'), ('research', 'research'), ('linked', 'linked')]



========================================== PARAGRAPH 215 ===========================================

with logics for meaning and knowledge’s ability to deal with the user’s beliefs and intentions  

------------------- Sentence 1 -------------------

with logics for meaning and knowledge’s ability to deal with the user’s beliefs and intentions

>> Tokens are: 
 ['logics', 'meaning', 'knowledge', '’', 'ability', 'deal', 'user', '’', 'beliefs', 'intentions']

>> Bigrams are: 
 [('logics', 'meaning'), ('meaning', 'knowledge'), ('knowledge', '’'), ('’', 'ability'), ('ability', 'deal'), ('deal', 'user'), ('user', '’'), ('’', 'beliefs'), ('beliefs', 'intentions')]

>> Trigrams are: 
 [('logics', 'meaning', 'knowledge'), ('meaning', 'knowledge', '’'), ('knowledge', '’', 'ability'), ('’', 'ability', 'deal'), ('ability', 'deal', 'user'), ('deal', 'user', '’'), ('user', '’', 'beliefs'), ('’', 'beliefs', 'intentions')]

>> POS Tags are: 
 [('logics', 'NNS'), ('meaning', 'VBG'), ('knowledge', 'NN'), ('’', 'NNP'), ('ability', 'NN'), ('deal', 'NN'), ('user', 'NN'), ('’', 'NNP'), ('beliefs', 'NN'), ('intentions', 'NNS')]

>> Noun Phrases are: 
 ['logics', 'knowledge ’ ability deal user ’ beliefs intentions']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('logics', 'logic'), ('meaning', 'mean'), ('knowledge', 'knowledg'), ('’', '’'), ('ability', 'abil'), ('deal', 'deal'), ('user', 'user'), ('’', '’'), ('beliefs', 'belief'), ('intentions', 'intent')]

>> Stemming using Snowball Stemmer: 
 [('logics', 'logic'), ('meaning', 'mean'), ('knowledge', 'knowledg'), ('’', '’'), ('ability', 'abil'), ('deal', 'deal'), ('user', 'user'), ('’', '’'), ('beliefs', 'belief'), ('intentions', 'intent')]

>> Lemmatization: 
 [('logics', 'logic'), ('meaning', 'meaning'), ('knowledge', 'knowledge'), ('’', '’'), ('ability', 'ability'), ('deal', 'deal'), ('user', 'user'), ('’', '’'), ('beliefs', 'belief'), ('intentions', 'intention')]



========================================== PARAGRAPH 216 ===========================================

and with functions like emphasis and themes.  

------------------- Sentence 1 -------------------

and with functions like emphasis and themes.

>> Tokens are: 
 ['functions', 'like', 'emphasis', 'themes', '.']

>> Bigrams are: 
 [('functions', 'like'), ('like', 'emphasis'), ('emphasis', 'themes'), ('themes', '.')]

>> Trigrams are: 
 [('functions', 'like', 'emphasis'), ('like', 'emphasis', 'themes'), ('emphasis', 'themes', '.')]

>> POS Tags are: 
 [('functions', 'NNS'), ('like', 'IN'), ('emphasis', 'NN'), ('themes', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['functions', 'emphasis themes']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('functions', 'function'), ('like', 'like'), ('emphasis', 'emphasi'), ('themes', 'theme'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('functions', 'function'), ('like', 'like'), ('emphasis', 'emphasi'), ('themes', 'theme'), ('.', '.')]

>> Lemmatization: 
 [('functions', 'function'), ('like', 'like'), ('emphasis', 'emphasis'), ('themes', 'theme'), ('.', '.')]



========================================== PARAGRAPH 217 ===========================================

By the end of the decade the powerful general purpose sentence processors like SRI’s Core  

------------------- Sentence 1 -------------------

By the end of the decade the powerful general purpose sentence processors like SRI’s Core

>> Tokens are: 
 ['By', 'end', 'decade', 'powerful', 'general', 'purpose', 'sentence', 'processors', 'like', 'SRI', '’', 'Core']

>> Bigrams are: 
 [('By', 'end'), ('end', 'decade'), ('decade', 'powerful'), ('powerful', 'general'), ('general', 'purpose'), ('purpose', 'sentence'), ('sentence', 'processors'), ('processors', 'like'), ('like', 'SRI'), ('SRI', '’'), ('’', 'Core')]

>> Trigrams are: 
 [('By', 'end', 'decade'), ('end', 'decade', 'powerful'), ('decade', 'powerful', 'general'), ('powerful', 'general', 'purpose'), ('general', 'purpose', 'sentence'), ('purpose', 'sentence', 'processors'), ('sentence', 'processors', 'like'), ('processors', 'like', 'SRI'), ('like', 'SRI', '’'), ('SRI', '’', 'Core')]

>> POS Tags are: 
 [('By', 'IN'), ('end', 'NN'), ('decade', 'NN'), ('powerful', 'JJ'), ('general', 'JJ'), ('purpose', 'NN'), ('sentence', 'NN'), ('processors', 'NNS'), ('like', 'IN'), ('SRI', 'NNP'), ('’', 'NNP'), ('Core', 'NNP')]

>> Noun Phrases are: 
 ['end decade', 'powerful general purpose sentence processors', 'SRI ’ Core']

>> Named Entities are: 
 [('ORGANIZATION', 'SRI')] 

>> Stemming using Porter Stemmer: 
 [('By', 'by'), ('end', 'end'), ('decade', 'decad'), ('powerful', 'power'), ('general', 'gener'), ('purpose', 'purpos'), ('sentence', 'sentenc'), ('processors', 'processor'), ('like', 'like'), ('SRI', 'sri'), ('’', '’'), ('Core', 'core')]

>> Stemming using Snowball Stemmer: 
 [('By', 'by'), ('end', 'end'), ('decade', 'decad'), ('powerful', 'power'), ('general', 'general'), ('purpose', 'purpos'), ('sentence', 'sentenc'), ('processors', 'processor'), ('like', 'like'), ('SRI', 'sri'), ('’', '’'), ('Core', 'core')]

>> Lemmatization: 
 [('By', 'By'), ('end', 'end'), ('decade', 'decade'), ('powerful', 'powerful'), ('general', 'general'), ('purpose', 'purpose'), ('sentence', 'sentence'), ('processors', 'processor'), ('like', 'like'), ('SRI', 'SRI'), ('’', '’'), ('Core', 'Core')]



========================================== PARAGRAPH 218 ===========================================

Language Engine (Alshawi,1992) [15] and Discourse Representation Theory (Kamp and  

------------------- Sentence 1 -------------------

Language Engine (Alshawi,1992) [15] and Discourse Representation Theory (Kamp and

>> Tokens are: 
 ['Language', 'Engine', '(', 'Alshawi,1992', ')', '[', '15', ']', 'Discourse', 'Representation', 'Theory', '(', 'Kamp']

>> Bigrams are: 
 [('Language', 'Engine'), ('Engine', '('), ('(', 'Alshawi,1992'), ('Alshawi,1992', ')'), (')', '['), ('[', '15'), ('15', ']'), (']', 'Discourse'), ('Discourse', 'Representation'), ('Representation', 'Theory'), ('Theory', '('), ('(', 'Kamp')]

>> Trigrams are: 
 [('Language', 'Engine', '('), ('Engine', '(', 'Alshawi,1992'), ('(', 'Alshawi,1992', ')'), ('Alshawi,1992', ')', '['), (')', '[', '15'), ('[', '15', ']'), ('15', ']', 'Discourse'), (']', 'Discourse', 'Representation'), ('Discourse', 'Representation', 'Theory'), ('Representation', 'Theory', '('), ('Theory', '(', 'Kamp')]

>> POS Tags are: 
 [('Language', 'NN'), ('Engine', 'NNP'), ('(', '('), ('Alshawi,1992', 'NNP'), (')', ')'), ('[', 'VBD'), ('15', 'CD'), (']', 'JJ'), ('Discourse', 'NNP'), ('Representation', 'NNP'), ('Theory', 'NNP'), ('(', '('), ('Kamp', 'NNP')]

>> Noun Phrases are: 
 ['Language Engine', 'Alshawi,1992', '] Discourse Representation Theory', 'Kamp']

>> Named Entities are: 
 [('PERSON', 'Language Engine'), ('ORGANIZATION', 'Discourse'), ('ORGANIZATION', 'Kamp')] 

>> Stemming using Porter Stemmer: 
 [('Language', 'languag'), ('Engine', 'engin'), ('(', '('), ('Alshawi,1992', 'alshawi,1992'), (')', ')'), ('[', '['), ('15', '15'), (']', ']'), ('Discourse', 'discours'), ('Representation', 'represent'), ('Theory', 'theori'), ('(', '('), ('Kamp', 'kamp')]

>> Stemming using Snowball Stemmer: 
 [('Language', 'languag'), ('Engine', 'engin'), ('(', '('), ('Alshawi,1992', 'alshawi,1992'), (')', ')'), ('[', '['), ('15', '15'), (']', ']'), ('Discourse', 'discours'), ('Representation', 'represent'), ('Theory', 'theori'), ('(', '('), ('Kamp', 'kamp')]

>> Lemmatization: 
 [('Language', 'Language'), ('Engine', 'Engine'), ('(', '('), ('Alshawi,1992', 'Alshawi,1992'), (')', ')'), ('[', '['), ('15', '15'), (']', ']'), ('Discourse', 'Discourse'), ('Representation', 'Representation'), ('Theory', 'Theory'), ('(', '('), ('Kamp', 'Kamp')]



========================================== PARAGRAPH 219 ===========================================

Reyle,1993) [16] offered a means of tackling more extended discourse within the  

------------------- Sentence 1 -------------------

Reyle,1993) [16] offered a means of tackling more extended discourse within the

>> Tokens are: 
 ['Reyle,1993', ')', '[', '16', ']', 'offered', 'means', 'tackling', 'extended', 'discourse', 'within']

>> Bigrams are: 
 [('Reyle,1993', ')'), (')', '['), ('[', '16'), ('16', ']'), (']', 'offered'), ('offered', 'means'), ('means', 'tackling'), ('tackling', 'extended'), ('extended', 'discourse'), ('discourse', 'within')]

>> Trigrams are: 
 [('Reyle,1993', ')', '['), (')', '[', '16'), ('[', '16', ']'), ('16', ']', 'offered'), (']', 'offered', 'means'), ('offered', 'means', 'tackling'), ('means', 'tackling', 'extended'), ('tackling', 'extended', 'discourse'), ('extended', 'discourse', 'within')]

>> POS Tags are: 
 [('Reyle,1993', 'NNP'), (')', ')'), ('[', 'VBD'), ('16', 'CD'), (']', 'NN'), ('offered', 'VBN'), ('means', 'VBZ'), ('tackling', 'VBG'), ('extended', 'JJ'), ('discourse', 'NN'), ('within', 'IN')]

>> Noun Phrases are: 
 ['Reyle,1993', ']', 'extended discourse']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Reyle,1993', 'reyle,1993'), (')', ')'), ('[', '['), ('16', '16'), (']', ']'), ('offered', 'offer'), ('means', 'mean'), ('tackling', 'tackl'), ('extended', 'extend'), ('discourse', 'discours'), ('within', 'within')]

>> Stemming using Snowball Stemmer: 
 [('Reyle,1993', 'reyle,1993'), (')', ')'), ('[', '['), ('16', '16'), (']', ']'), ('offered', 'offer'), ('means', 'mean'), ('tackling', 'tackl'), ('extended', 'extend'), ('discourse', 'discours'), ('within', 'within')]

>> Lemmatization: 
 [('Reyle,1993', 'Reyle,1993'), (')', ')'), ('[', '['), ('16', '16'), (']', ']'), ('offered', 'offered'), ('means', 'mean'), ('tackling', 'tackling'), ('extended', 'extended'), ('discourse', 'discourse'), ('within', 'within')]



========================================== PARAGRAPH 220 ===========================================

grammatico-logical framework. This period was one of the growing community. Practical  

------------------- Sentence 1 -------------------

grammatico-logical framework.

>> Tokens are: 
 ['grammatico-logical', 'framework', '.']

>> Bigrams are: 
 [('grammatico-logical', 'framework'), ('framework', '.')]

>> Trigrams are: 
 [('grammatico-logical', 'framework', '.')]

>> POS Tags are: 
 [('grammatico-logical', 'JJ'), ('framework', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['grammatico-logical framework']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('grammatico-logical', 'grammatico-log'), ('framework', 'framework'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('grammatico-logical', 'grammatico-log'), ('framework', 'framework'), ('.', '.')]

>> Lemmatization: 
 [('grammatico-logical', 'grammatico-logical'), ('framework', 'framework'), ('.', '.')]


------------------- Sentence 2 -------------------

This period was one of the growing community.

>> Tokens are: 
 ['This', 'period', 'one', 'growing', 'community', '.']

>> Bigrams are: 
 [('This', 'period'), ('period', 'one'), ('one', 'growing'), ('growing', 'community'), ('community', '.')]

>> Trigrams are: 
 [('This', 'period', 'one'), ('period', 'one', 'growing'), ('one', 'growing', 'community'), ('growing', 'community', '.')]

>> POS Tags are: 
 [('This', 'DT'), ('period', 'NN'), ('one', 'CD'), ('growing', 'VBG'), ('community', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['This period', 'community']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('This', 'thi'), ('period', 'period'), ('one', 'one'), ('growing', 'grow'), ('community', 'commun'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('This', 'this'), ('period', 'period'), ('one', 'one'), ('growing', 'grow'), ('community', 'communiti'), ('.', '.')]

>> Lemmatization: 
 [('This', 'This'), ('period', 'period'), ('one', 'one'), ('growing', 'growing'), ('community', 'community'), ('.', '.')]


------------------- Sentence 3 -------------------

Practical

>> Tokens are: 
 ['Practical']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Practical', 'JJ')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Practical', 'practic')]

>> Stemming using Snowball Stemmer: 
 [('Practical', 'practic')]

>> Lemmatization: 
 [('Practical', 'Practical')]



========================================== PARAGRAPH 221 ===========================================

resources, grammars, and tools and parsers became available (e.g the Alvey Natural  

------------------- Sentence 1 -------------------

resources, grammars, and tools and parsers became available (e.g the Alvey Natural

>> Tokens are: 
 ['resources', ',', 'grammars', ',', 'tools', 'parsers', 'became', 'available', '(', 'e.g', 'Alvey', 'Natural']

>> Bigrams are: 
 [('resources', ','), (',', 'grammars'), ('grammars', ','), (',', 'tools'), ('tools', 'parsers'), ('parsers', 'became'), ('became', 'available'), ('available', '('), ('(', 'e.g'), ('e.g', 'Alvey'), ('Alvey', 'Natural')]

>> Trigrams are: 
 [('resources', ',', 'grammars'), (',', 'grammars', ','), ('grammars', ',', 'tools'), (',', 'tools', 'parsers'), ('tools', 'parsers', 'became'), ('parsers', 'became', 'available'), ('became', 'available', '('), ('available', '(', 'e.g'), ('(', 'e.g', 'Alvey'), ('e.g', 'Alvey', 'Natural')]

>> POS Tags are: 
 [('resources', 'NNS'), (',', ','), ('grammars', 'NNS'), (',', ','), ('tools', 'NNS'), ('parsers', 'NNS'), ('became', 'VBD'), ('available', 'JJ'), ('(', '('), ('e.g', 'JJ'), ('Alvey', 'NNP'), ('Natural', 'NNP')]

>> Noun Phrases are: 
 ['resources', 'grammars', 'tools parsers', 'e.g Alvey Natural']

>> Named Entities are: 
 [('PERSON', 'Alvey Natural')] 

>> Stemming using Porter Stemmer: 
 [('resources', 'resourc'), (',', ','), ('grammars', 'grammar'), (',', ','), ('tools', 'tool'), ('parsers', 'parser'), ('became', 'becam'), ('available', 'avail'), ('(', '('), ('e.g', 'e.g'), ('Alvey', 'alvey'), ('Natural', 'natur')]

>> Stemming using Snowball Stemmer: 
 [('resources', 'resourc'), (',', ','), ('grammars', 'grammar'), (',', ','), ('tools', 'tool'), ('parsers', 'parser'), ('became', 'becam'), ('available', 'avail'), ('(', '('), ('e.g', 'e.g'), ('Alvey', 'alvey'), ('Natural', 'natur')]

>> Lemmatization: 
 [('resources', 'resource'), (',', ','), ('grammars', 'grammar'), (',', ','), ('tools', 'tool'), ('parsers', 'parser'), ('became', 'became'), ('available', 'available'), ('(', '('), ('e.g', 'e.g'), ('Alvey', 'Alvey'), ('Natural', 'Natural')]



========================================== PARAGRAPH 222 ===========================================

Language Tools (Briscoe et al., 1987) [17]. The (D)ARPA speech recognition and message  

------------------- Sentence 1 -------------------

Language Tools (Briscoe et al., 1987) [17].

>> Tokens are: 
 ['Language', 'Tools', '(', 'Briscoe', 'et', 'al.', ',', '1987', ')', '[', '17', ']', '.']

>> Bigrams are: 
 [('Language', 'Tools'), ('Tools', '('), ('(', 'Briscoe'), ('Briscoe', 'et'), ('et', 'al.'), ('al.', ','), (',', '1987'), ('1987', ')'), (')', '['), ('[', '17'), ('17', ']'), (']', '.')]

>> Trigrams are: 
 [('Language', 'Tools', '('), ('Tools', '(', 'Briscoe'), ('(', 'Briscoe', 'et'), ('Briscoe', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '1987'), (',', '1987', ')'), ('1987', ')', '['), (')', '[', '17'), ('[', '17', ']'), ('17', ']', '.')]

>> POS Tags are: 
 [('Language', 'NN'), ('Tools', 'NNP'), ('(', '('), ('Briscoe', 'NNP'), ('et', 'RB'), ('al.', 'RB'), (',', ','), ('1987', 'CD'), (')', ')'), ('[', 'VBD'), ('17', 'CD'), (']', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Language Tools', 'Briscoe', ']']

>> Named Entities are: 
 [('PERSON', 'Language Tools'), ('PERSON', 'Briscoe')] 

>> Stemming using Porter Stemmer: 
 [('Language', 'languag'), ('Tools', 'tool'), ('(', '('), ('Briscoe', 'brisco'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('1987', '1987'), (')', ')'), ('[', '['), ('17', '17'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Language', 'languag'), ('Tools', 'tool'), ('(', '('), ('Briscoe', 'brisco'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('1987', '1987'), (')', ')'), ('[', '['), ('17', '17'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('Language', 'Language'), ('Tools', 'Tools'), ('(', '('), ('Briscoe', 'Briscoe'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('1987', '1987'), (')', ')'), ('[', '['), ('17', '17'), (']', ']'), ('.', '.')]


------------------- Sentence 2 -------------------

The (D)ARPA speech recognition and message

>> Tokens are: 
 ['The', '(', 'D', ')', 'ARPA', 'speech', 'recognition', 'message']

>> Bigrams are: 
 [('The', '('), ('(', 'D'), ('D', ')'), (')', 'ARPA'), ('ARPA', 'speech'), ('speech', 'recognition'), ('recognition', 'message')]

>> Trigrams are: 
 [('The', '(', 'D'), ('(', 'D', ')'), ('D', ')', 'ARPA'), (')', 'ARPA', 'speech'), ('ARPA', 'speech', 'recognition'), ('speech', 'recognition', 'message')]

>> POS Tags are: 
 [('The', 'DT'), ('(', '('), ('D', 'NNP'), (')', ')'), ('ARPA', 'NNP'), ('speech', 'NN'), ('recognition', 'NN'), ('message', 'NN')]

>> Noun Phrases are: 
 ['D', 'ARPA speech recognition message']

>> Named Entities are: 
 [('ORGANIZATION', 'ARPA')] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('(', '('), ('D', 'd'), (')', ')'), ('ARPA', 'arpa'), ('speech', 'speech'), ('recognition', 'recognit'), ('message', 'messag')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('(', '('), ('D', 'd'), (')', ')'), ('ARPA', 'arpa'), ('speech', 'speech'), ('recognition', 'recognit'), ('message', 'messag')]

>> Lemmatization: 
 [('The', 'The'), ('(', '('), ('D', 'D'), (')', ')'), ('ARPA', 'ARPA'), ('speech', 'speech'), ('recognition', 'recognition'), ('message', 'message')]



========================================== PARAGRAPH 223 ===========================================

understanding (information extraction) conferences were not only for the tasks they  

------------------- Sentence 1 -------------------

understanding (information extraction) conferences were not only for the tasks they

>> Tokens are: 
 ['understanding', '(', 'information', 'extraction', ')', 'conferences', 'tasks']

>> Bigrams are: 
 [('understanding', '('), ('(', 'information'), ('information', 'extraction'), ('extraction', ')'), (')', 'conferences'), ('conferences', 'tasks')]

>> Trigrams are: 
 [('understanding', '(', 'information'), ('(', 'information', 'extraction'), ('information', 'extraction', ')'), ('extraction', ')', 'conferences'), (')', 'conferences', 'tasks')]

>> POS Tags are: 
 [('understanding', 'NN'), ('(', '('), ('information', 'NN'), ('extraction', 'NN'), (')', ')'), ('conferences', 'VBZ'), ('tasks', 'NNS')]

>> Noun Phrases are: 
 ['understanding', 'information extraction', 'tasks']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('understanding', 'understand'), ('(', '('), ('information', 'inform'), ('extraction', 'extract'), (')', ')'), ('conferences', 'confer'), ('tasks', 'task')]

>> Stemming using Snowball Stemmer: 
 [('understanding', 'understand'), ('(', '('), ('information', 'inform'), ('extraction', 'extract'), (')', ')'), ('conferences', 'confer'), ('tasks', 'task')]

>> Lemmatization: 
 [('understanding', 'understanding'), ('(', '('), ('information', 'information'), ('extraction', 'extraction'), (')', ')'), ('conferences', 'conference'), ('tasks', 'task')]



========================================== PARAGRAPH 224 ===========================================

addressed but for the emphasis on heavy evaluation, starting a trend that became a major  

------------------- Sentence 1 -------------------

addressed but for the emphasis on heavy evaluation, starting a trend that became a major

>> Tokens are: 
 ['addressed', 'emphasis', 'heavy', 'evaluation', ',', 'starting', 'trend', 'became', 'major']

>> Bigrams are: 
 [('addressed', 'emphasis'), ('emphasis', 'heavy'), ('heavy', 'evaluation'), ('evaluation', ','), (',', 'starting'), ('starting', 'trend'), ('trend', 'became'), ('became', 'major')]

>> Trigrams are: 
 [('addressed', 'emphasis', 'heavy'), ('emphasis', 'heavy', 'evaluation'), ('heavy', 'evaluation', ','), ('evaluation', ',', 'starting'), (',', 'starting', 'trend'), ('starting', 'trend', 'became'), ('trend', 'became', 'major')]

>> POS Tags are: 
 [('addressed', 'VBN'), ('emphasis', 'NN'), ('heavy', 'JJ'), ('evaluation', 'NN'), (',', ','), ('starting', 'VBG'), ('trend', 'NN'), ('became', 'VBD'), ('major', 'JJ')]

>> Noun Phrases are: 
 ['emphasis', 'heavy evaluation', 'trend']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('addressed', 'address'), ('emphasis', 'emphasi'), ('heavy', 'heavi'), ('evaluation', 'evalu'), (',', ','), ('starting', 'start'), ('trend', 'trend'), ('became', 'becam'), ('major', 'major')]

>> Stemming using Snowball Stemmer: 
 [('addressed', 'address'), ('emphasis', 'emphasi'), ('heavy', 'heavi'), ('evaluation', 'evalu'), (',', ','), ('starting', 'start'), ('trend', 'trend'), ('became', 'becam'), ('major', 'major')]

>> Lemmatization: 
 [('addressed', 'addressed'), ('emphasis', 'emphasis'), ('heavy', 'heavy'), ('evaluation', 'evaluation'), (',', ','), ('starting', 'starting'), ('trend', 'trend'), ('became', 'became'), ('major', 'major')]



========================================== PARAGRAPH 225 ===========================================

feature in 1990s (Young and Chase, 1998; Sundheim and Chinchor ,1993) [18][19]. Work on  

------------------- Sentence 1 -------------------

feature in 1990s (Young and Chase, 1998; Sundheim and Chinchor ,1993) [18][19].

>> Tokens are: 
 ['feature', '1990s', '(', 'Young', 'Chase', ',', '1998', ';', 'Sundheim', 'Chinchor', ',1993', ')', '[', '18', ']', '[', '19', ']', '.']

>> Bigrams are: 
 [('feature', '1990s'), ('1990s', '('), ('(', 'Young'), ('Young', 'Chase'), ('Chase', ','), (',', '1998'), ('1998', ';'), (';', 'Sundheim'), ('Sundheim', 'Chinchor'), ('Chinchor', ',1993'), (',1993', ')'), (')', '['), ('[', '18'), ('18', ']'), (']', '['), ('[', '19'), ('19', ']'), (']', '.')]

>> Trigrams are: 
 [('feature', '1990s', '('), ('1990s', '(', 'Young'), ('(', 'Young', 'Chase'), ('Young', 'Chase', ','), ('Chase', ',', '1998'), (',', '1998', ';'), ('1998', ';', 'Sundheim'), (';', 'Sundheim', 'Chinchor'), ('Sundheim', 'Chinchor', ',1993'), ('Chinchor', ',1993', ')'), (',1993', ')', '['), (')', '[', '18'), ('[', '18', ']'), ('18', ']', '['), (']', '[', '19'), ('[', '19', ']'), ('19', ']', '.')]

>> POS Tags are: 
 [('feature', 'NN'), ('1990s', 'CD'), ('(', '('), ('Young', 'NNP'), ('Chase', 'NNP'), (',', ','), ('1998', 'CD'), (';', ':'), ('Sundheim', 'NNP'), ('Chinchor', 'NNP'), (',1993', 'NNP'), (')', ')'), ('[', 'VBD'), ('18', 'CD'), (']', 'NNP'), ('[', 'VBD'), ('19', 'CD'), (']', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['feature', 'Young Chase', 'Sundheim Chinchor ,1993', ']', ']']

>> Named Entities are: 
 [('ORGANIZATION', 'Young'), ('ORGANIZATION', 'Sundheim Chinchor')] 

>> Stemming using Porter Stemmer: 
 [('feature', 'featur'), ('1990s', '1990'), ('(', '('), ('Young', 'young'), ('Chase', 'chase'), (',', ','), ('1998', '1998'), (';', ';'), ('Sundheim', 'sundheim'), ('Chinchor', 'chinchor'), (',1993', ',1993'), (')', ')'), ('[', '['), ('18', '18'), (']', ']'), ('[', '['), ('19', '19'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('feature', 'featur'), ('1990s', '1990s'), ('(', '('), ('Young', 'young'), ('Chase', 'chase'), (',', ','), ('1998', '1998'), (';', ';'), ('Sundheim', 'sundheim'), ('Chinchor', 'chinchor'), (',1993', ',1993'), (')', ')'), ('[', '['), ('18', '18'), (']', ']'), ('[', '['), ('19', '19'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('feature', 'feature'), ('1990s', '1990s'), ('(', '('), ('Young', 'Young'), ('Chase', 'Chase'), (',', ','), ('1998', '1998'), (';', ';'), ('Sundheim', 'Sundheim'), ('Chinchor', 'Chinchor'), (',1993', ',1993'), (')', ')'), ('[', '['), ('18', '18'), (']', ']'), ('[', '['), ('19', '19'), (']', ']'), ('.', '.')]


------------------- Sentence 2 -------------------

Work on

>> Tokens are: 
 ['Work']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Work', 'NN')]

>> Noun Phrases are: 
 ['Work']

>> Named Entities are: 
 [('GPE', 'Work')] 

>> Stemming using Porter Stemmer: 
 [('Work', 'work')]

>> Stemming using Snowball Stemmer: 
 [('Work', 'work')]

>> Lemmatization: 
 [('Work', 'Work')]



========================================== PARAGRAPH 226 ===========================================

user modelling (Kobsa and Wahlster , 1989) [20]  was one strand in research paper and on  

------------------- Sentence 1 -------------------

user modelling (Kobsa and Wahlster , 1989) [20]  was one strand in research paper and on

>> Tokens are: 
 ['user', 'modelling', '(', 'Kobsa', 'Wahlster', ',', '1989', ')', '[', '20', ']', 'one', 'strand', 'research', 'paper']

>> Bigrams are: 
 [('user', 'modelling'), ('modelling', '('), ('(', 'Kobsa'), ('Kobsa', 'Wahlster'), ('Wahlster', ','), (',', '1989'), ('1989', ')'), (')', '['), ('[', '20'), ('20', ']'), (']', 'one'), ('one', 'strand'), ('strand', 'research'), ('research', 'paper')]

>> Trigrams are: 
 [('user', 'modelling', '('), ('modelling', '(', 'Kobsa'), ('(', 'Kobsa', 'Wahlster'), ('Kobsa', 'Wahlster', ','), ('Wahlster', ',', '1989'), (',', '1989', ')'), ('1989', ')', '['), (')', '[', '20'), ('[', '20', ']'), ('20', ']', 'one'), (']', 'one', 'strand'), ('one', 'strand', 'research'), ('strand', 'research', 'paper')]

>> POS Tags are: 
 [('user', 'NN'), ('modelling', 'NN'), ('(', '('), ('Kobsa', 'NNP'), ('Wahlster', 'NNP'), (',', ','), ('1989', 'CD'), (')', ')'), ('[', 'VBD'), ('20', 'CD'), (']', 'NNP'), ('one', 'CD'), ('strand', 'NN'), ('research', 'NN'), ('paper', 'NN')]

>> Noun Phrases are: 
 ['user modelling', 'Kobsa Wahlster', ']', 'strand research paper']

>> Named Entities are: 
 [('PERSON', 'Kobsa Wahlster')] 

>> Stemming using Porter Stemmer: 
 [('user', 'user'), ('modelling', 'model'), ('(', '('), ('Kobsa', 'kobsa'), ('Wahlster', 'wahlster'), (',', ','), ('1989', '1989'), (')', ')'), ('[', '['), ('20', '20'), (']', ']'), ('one', 'one'), ('strand', 'strand'), ('research', 'research'), ('paper', 'paper')]

>> Stemming using Snowball Stemmer: 
 [('user', 'user'), ('modelling', 'model'), ('(', '('), ('Kobsa', 'kobsa'), ('Wahlster', 'wahlster'), (',', ','), ('1989', '1989'), (')', ')'), ('[', '['), ('20', '20'), (']', ']'), ('one', 'one'), ('strand', 'strand'), ('research', 'research'), ('paper', 'paper')]

>> Lemmatization: 
 [('user', 'user'), ('modelling', 'modelling'), ('(', '('), ('Kobsa', 'Kobsa'), ('Wahlster', 'Wahlster'), (',', ','), ('1989', '1989'), (')', ')'), ('[', '['), ('20', '20'), (']', ']'), ('one', 'one'), ('strand', 'strand'), ('research', 'research'), ('paper', 'paper')]



========================================== PARAGRAPH 227 ===========================================

discourse structure serving this (Cohen et al., 1990)  [21]. At the same time, as McKeown  

------------------- Sentence 1 -------------------

discourse structure serving this (Cohen et al., 1990)  [21].

>> Tokens are: 
 ['discourse', 'structure', 'serving', '(', 'Cohen', 'et', 'al.', ',', '1990', ')', '[', '21', ']', '.']

>> Bigrams are: 
 [('discourse', 'structure'), ('structure', 'serving'), ('serving', '('), ('(', 'Cohen'), ('Cohen', 'et'), ('et', 'al.'), ('al.', ','), (',', '1990'), ('1990', ')'), (')', '['), ('[', '21'), ('21', ']'), (']', '.')]

>> Trigrams are: 
 [('discourse', 'structure', 'serving'), ('structure', 'serving', '('), ('serving', '(', 'Cohen'), ('(', 'Cohen', 'et'), ('Cohen', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '1990'), (',', '1990', ')'), ('1990', ')', '['), (')', '[', '21'), ('[', '21', ']'), ('21', ']', '.')]

>> POS Tags are: 
 [('discourse', 'NN'), ('structure', 'NN'), ('serving', 'VBG'), ('(', '('), ('Cohen', 'NNP'), ('et', 'VBZ'), ('al.', 'RB'), (',', ','), ('1990', 'CD'), (')', ')'), ('[', 'VBD'), ('21', 'CD'), (']', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['discourse structure', 'Cohen', ']']

>> Named Entities are: 
 [('PERSON', 'Cohen')] 

>> Stemming using Porter Stemmer: 
 [('discourse', 'discours'), ('structure', 'structur'), ('serving', 'serv'), ('(', '('), ('Cohen', 'cohen'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('1990', '1990'), (')', ')'), ('[', '['), ('21', '21'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('discourse', 'discours'), ('structure', 'structur'), ('serving', 'serv'), ('(', '('), ('Cohen', 'cohen'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('1990', '1990'), (')', ')'), ('[', '['), ('21', '21'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('discourse', 'discourse'), ('structure', 'structure'), ('serving', 'serving'), ('(', '('), ('Cohen', 'Cohen'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('1990', '1990'), (')', ')'), ('[', '['), ('21', '21'), (']', ']'), ('.', '.')]


------------------- Sentence 2 -------------------

At the same time, as McKeown

>> Tokens are: 
 ['At', 'time', ',', 'McKeown']

>> Bigrams are: 
 [('At', 'time'), ('time', ','), (',', 'McKeown')]

>> Trigrams are: 
 [('At', 'time', ','), ('time', ',', 'McKeown')]

>> POS Tags are: 
 [('At', 'IN'), ('time', 'NN'), (',', ','), ('McKeown', 'NNP')]

>> Noun Phrases are: 
 ['time', 'McKeown']

>> Named Entities are: 
 [('ORGANIZATION', 'McKeown')] 

>> Stemming using Porter Stemmer: 
 [('At', 'at'), ('time', 'time'), (',', ','), ('McKeown', 'mckeown')]

>> Stemming using Snowball Stemmer: 
 [('At', 'at'), ('time', 'time'), (',', ','), ('McKeown', 'mckeown')]

>> Lemmatization: 
 [('At', 'At'), ('time', 'time'), (',', ','), ('McKeown', 'McKeown')]



========================================== PARAGRAPH 228 ===========================================

(1985) [22] showed, rhetorical schemas could be used for producing both linguistically  

------------------- Sentence 1 -------------------

(1985) [22] showed, rhetorical schemas could be used for producing both linguistically

>> Tokens are: 
 ['(', '1985', ')', '[', '22', ']', 'showed', ',', 'rhetorical', 'schemas', 'could', 'used', 'producing', 'linguistically']

>> Bigrams are: 
 [('(', '1985'), ('1985', ')'), (')', '['), ('[', '22'), ('22', ']'), (']', 'showed'), ('showed', ','), (',', 'rhetorical'), ('rhetorical', 'schemas'), ('schemas', 'could'), ('could', 'used'), ('used', 'producing'), ('producing', 'linguistically')]

>> Trigrams are: 
 [('(', '1985', ')'), ('1985', ')', '['), (')', '[', '22'), ('[', '22', ']'), ('22', ']', 'showed'), (']', 'showed', ','), ('showed', ',', 'rhetorical'), (',', 'rhetorical', 'schemas'), ('rhetorical', 'schemas', 'could'), ('schemas', 'could', 'used'), ('could', 'used', 'producing'), ('used', 'producing', 'linguistically')]

>> POS Tags are: 
 [('(', '('), ('1985', 'CD'), (')', ')'), ('[', 'VBD'), ('22', 'CD'), (']', 'NN'), ('showed', 'VBD'), (',', ','), ('rhetorical', 'JJ'), ('schemas', 'NN'), ('could', 'MD'), ('used', 'VBN'), ('producing', 'VBG'), ('linguistically', 'RB')]

>> Noun Phrases are: 
 [']', 'rhetorical schemas']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('1985', '1985'), (')', ')'), ('[', '['), ('22', '22'), (']', ']'), ('showed', 'show'), (',', ','), ('rhetorical', 'rhetor'), ('schemas', 'schema'), ('could', 'could'), ('used', 'use'), ('producing', 'produc'), ('linguistically', 'linguist')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('1985', '1985'), (')', ')'), ('[', '['), ('22', '22'), (']', ']'), ('showed', 'show'), (',', ','), ('rhetorical', 'rhetor'), ('schemas', 'schema'), ('could', 'could'), ('used', 'use'), ('producing', 'produc'), ('linguistically', 'linguist')]

>> Lemmatization: 
 [('(', '('), ('1985', '1985'), (')', ')'), ('[', '['), ('22', '22'), (']', ']'), ('showed', 'showed'), (',', ','), ('rhetorical', 'rhetorical'), ('schemas', 'schema'), ('could', 'could'), ('used', 'used'), ('producing', 'producing'), ('linguistically', 'linguistically')]



========================================== PARAGRAPH 229 ===========================================

coherent and communicatively effective text. Some researches in NLP marked important  

------------------- Sentence 1 -------------------

coherent and communicatively effective text.

>> Tokens are: 
 ['coherent', 'communicatively', 'effective', 'text', '.']

>> Bigrams are: 
 [('coherent', 'communicatively'), ('communicatively', 'effective'), ('effective', 'text'), ('text', '.')]

>> Trigrams are: 
 [('coherent', 'communicatively', 'effective'), ('communicatively', 'effective', 'text'), ('effective', 'text', '.')]

>> POS Tags are: 
 [('coherent', 'NN'), ('communicatively', 'RB'), ('effective', 'JJ'), ('text', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['coherent', 'effective text']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('coherent', 'coher'), ('communicatively', 'commun'), ('effective', 'effect'), ('text', 'text'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('coherent', 'coher'), ('communicatively', 'communic'), ('effective', 'effect'), ('text', 'text'), ('.', '.')]

>> Lemmatization: 
 [('coherent', 'coherent'), ('communicatively', 'communicatively'), ('effective', 'effective'), ('text', 'text'), ('.', '.')]


------------------- Sentence 2 -------------------

Some researches in NLP marked important

>> Tokens are: 
 ['Some', 'researches', 'NLP', 'marked', 'important']

>> Bigrams are: 
 [('Some', 'researches'), ('researches', 'NLP'), ('NLP', 'marked'), ('marked', 'important')]

>> Trigrams are: 
 [('Some', 'researches', 'NLP'), ('researches', 'NLP', 'marked'), ('NLP', 'marked', 'important')]

>> POS Tags are: 
 [('Some', 'DT'), ('researches', 'NNS'), ('NLP', 'NNP'), ('marked', 'VBD'), ('important', 'JJ')]

>> Noun Phrases are: 
 ['Some researches NLP']

>> Named Entities are: 
 [('ORGANIZATION', 'NLP')] 

>> Stemming using Porter Stemmer: 
 [('Some', 'some'), ('researches', 'research'), ('NLP', 'nlp'), ('marked', 'mark'), ('important', 'import')]

>> Stemming using Snowball Stemmer: 
 [('Some', 'some'), ('researches', 'research'), ('NLP', 'nlp'), ('marked', 'mark'), ('important', 'import')]

>> Lemmatization: 
 [('Some', 'Some'), ('researches', 'research'), ('NLP', 'NLP'), ('marked', 'marked'), ('important', 'important')]



========================================== PARAGRAPH 230 ===========================================

topics for future like word sense disambiguation (Small et al., 1988) [23] and probabilistic  

------------------- Sentence 1 -------------------

topics for future like word sense disambiguation (Small et al., 1988) [23] and probabilistic

>> Tokens are: 
 ['topics', 'future', 'like', 'word', 'sense', 'disambiguation', '(', 'Small', 'et', 'al.', ',', '1988', ')', '[', '23', ']', 'probabilistic']

>> Bigrams are: 
 [('topics', 'future'), ('future', 'like'), ('like', 'word'), ('word', 'sense'), ('sense', 'disambiguation'), ('disambiguation', '('), ('(', 'Small'), ('Small', 'et'), ('et', 'al.'), ('al.', ','), (',', '1988'), ('1988', ')'), (')', '['), ('[', '23'), ('23', ']'), (']', 'probabilistic')]

>> Trigrams are: 
 [('topics', 'future', 'like'), ('future', 'like', 'word'), ('like', 'word', 'sense'), ('word', 'sense', 'disambiguation'), ('sense', 'disambiguation', '('), ('disambiguation', '(', 'Small'), ('(', 'Small', 'et'), ('Small', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '1988'), (',', '1988', ')'), ('1988', ')', '['), (')', '[', '23'), ('[', '23', ']'), ('23', ']', 'probabilistic')]

>> POS Tags are: 
 [('topics', 'NNS'), ('future', 'VBP'), ('like', 'IN'), ('word', 'NN'), ('sense', 'NN'), ('disambiguation', 'NN'), ('(', '('), ('Small', 'NNP'), ('et', 'RB'), ('al.', 'RB'), (',', ','), ('1988', 'CD'), (')', ')'), ('[', 'VBD'), ('23', 'CD'), (']', 'NNP'), ('probabilistic', 'JJ')]

>> Noun Phrases are: 
 ['topics', 'word sense disambiguation', 'Small', ']']

>> Named Entities are: 
 [('ORGANIZATION', 'Small')] 

>> Stemming using Porter Stemmer: 
 [('topics', 'topic'), ('future', 'futur'), ('like', 'like'), ('word', 'word'), ('sense', 'sens'), ('disambiguation', 'disambigu'), ('(', '('), ('Small', 'small'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('1988', '1988'), (')', ')'), ('[', '['), ('23', '23'), (']', ']'), ('probabilistic', 'probabilist')]

>> Stemming using Snowball Stemmer: 
 [('topics', 'topic'), ('future', 'futur'), ('like', 'like'), ('word', 'word'), ('sense', 'sens'), ('disambiguation', 'disambigu'), ('(', '('), ('Small', 'small'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('1988', '1988'), (')', ')'), ('[', '['), ('23', '23'), (']', ']'), ('probabilistic', 'probabilist')]

>> Lemmatization: 
 [('topics', 'topic'), ('future', 'future'), ('like', 'like'), ('word', 'word'), ('sense', 'sense'), ('disambiguation', 'disambiguation'), ('(', '('), ('Small', 'Small'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('1988', '1988'), (')', ')'), ('[', '['), ('23', '23'), (']', ']'), ('probabilistic', 'probabilistic')]



========================================== PARAGRAPH 231 ===========================================

networks, statistically coloured NLP, the work on the lexicon, also pointed in this direction.  

------------------- Sentence 1 -------------------

networks, statistically coloured NLP, the work on the lexicon, also pointed in this direction.

>> Tokens are: 
 ['networks', ',', 'statistically', 'coloured', 'NLP', ',', 'work', 'lexicon', ',', 'also', 'pointed', 'direction', '.']

>> Bigrams are: 
 [('networks', ','), (',', 'statistically'), ('statistically', 'coloured'), ('coloured', 'NLP'), ('NLP', ','), (',', 'work'), ('work', 'lexicon'), ('lexicon', ','), (',', 'also'), ('also', 'pointed'), ('pointed', 'direction'), ('direction', '.')]

>> Trigrams are: 
 [('networks', ',', 'statistically'), (',', 'statistically', 'coloured'), ('statistically', 'coloured', 'NLP'), ('coloured', 'NLP', ','), ('NLP', ',', 'work'), (',', 'work', 'lexicon'), ('work', 'lexicon', ','), ('lexicon', ',', 'also'), (',', 'also', 'pointed'), ('also', 'pointed', 'direction'), ('pointed', 'direction', '.')]

>> POS Tags are: 
 [('networks', 'NNS'), (',', ','), ('statistically', 'RB'), ('coloured', 'VBN'), ('NLP', 'NNP'), (',', ','), ('work', 'NN'), ('lexicon', 'NN'), (',', ','), ('also', 'RB'), ('pointed', 'VBN'), ('direction', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['networks', 'NLP', 'work lexicon', 'direction']

>> Named Entities are: 
 [('ORGANIZATION', 'NLP')] 

>> Stemming using Porter Stemmer: 
 [('networks', 'network'), (',', ','), ('statistically', 'statist'), ('coloured', 'colour'), ('NLP', 'nlp'), (',', ','), ('work', 'work'), ('lexicon', 'lexicon'), (',', ','), ('also', 'also'), ('pointed', 'point'), ('direction', 'direct'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('networks', 'network'), (',', ','), ('statistically', 'statist'), ('coloured', 'colour'), ('NLP', 'nlp'), (',', ','), ('work', 'work'), ('lexicon', 'lexicon'), (',', ','), ('also', 'also'), ('pointed', 'point'), ('direction', 'direct'), ('.', '.')]

>> Lemmatization: 
 [('networks', 'network'), (',', ','), ('statistically', 'statistically'), ('coloured', 'coloured'), ('NLP', 'NLP'), (',', ','), ('work', 'work'), ('lexicon', 'lexicon'), (',', ','), ('also', 'also'), ('pointed', 'pointed'), ('direction', 'direction'), ('.', '.')]



========================================== PARAGRAPH 232 ===========================================

Statistical language processing was a major thing in 90s (Manning and Schuetze,1999) [24],  

------------------- Sentence 1 -------------------

Statistical language processing was a major thing in 90s (Manning and Schuetze,1999) [24],

>> Tokens are: 
 ['Statistical', 'language', 'processing', 'major', 'thing', '90s', '(', 'Manning', 'Schuetze,1999', ')', '[', '24', ']', ',']

>> Bigrams are: 
 [('Statistical', 'language'), ('language', 'processing'), ('processing', 'major'), ('major', 'thing'), ('thing', '90s'), ('90s', '('), ('(', 'Manning'), ('Manning', 'Schuetze,1999'), ('Schuetze,1999', ')'), (')', '['), ('[', '24'), ('24', ']'), (']', ',')]

>> Trigrams are: 
 [('Statistical', 'language', 'processing'), ('language', 'processing', 'major'), ('processing', 'major', 'thing'), ('major', 'thing', '90s'), ('thing', '90s', '('), ('90s', '(', 'Manning'), ('(', 'Manning', 'Schuetze,1999'), ('Manning', 'Schuetze,1999', ')'), ('Schuetze,1999', ')', '['), (')', '[', '24'), ('[', '24', ']'), ('24', ']', ',')]

>> POS Tags are: 
 [('Statistical', 'JJ'), ('language', 'NN'), ('processing', 'NN'), ('major', 'JJ'), ('thing', 'NN'), ('90s', 'CD'), ('(', '('), ('Manning', 'NNP'), ('Schuetze,1999', 'NNP'), (')', ')'), ('[', 'VBD'), ('24', 'CD'), (']', 'NN'), (',', ',')]

>> Noun Phrases are: 
 ['Statistical language processing', 'major thing', 'Manning Schuetze,1999', ']']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Statistical', 'statist'), ('language', 'languag'), ('processing', 'process'), ('major', 'major'), ('thing', 'thing'), ('90s', '90'), ('(', '('), ('Manning', 'man'), ('Schuetze,1999', 'schuetze,1999'), (')', ')'), ('[', '['), ('24', '24'), (']', ']'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('Statistical', 'statist'), ('language', 'languag'), ('processing', 'process'), ('major', 'major'), ('thing', 'thing'), ('90s', '90s'), ('(', '('), ('Manning', 'man'), ('Schuetze,1999', 'schuetze,1999'), (')', ')'), ('[', '['), ('24', '24'), (']', ']'), (',', ',')]

>> Lemmatization: 
 [('Statistical', 'Statistical'), ('language', 'language'), ('processing', 'processing'), ('major', 'major'), ('thing', 'thing'), ('90s', '90'), ('(', '('), ('Manning', 'Manning'), ('Schuetze,1999', 'Schuetze,1999'), (')', ')'), ('[', '['), ('24', '24'), (']', ']'), (',', ',')]



========================================== PARAGRAPH 233 ===========================================

because this not only involves data analysts. Information extraction and automatic  

------------------- Sentence 1 -------------------

because this not only involves data analysts.

>> Tokens are: 
 ['involves', 'data', 'analysts', '.']

>> Bigrams are: 
 [('involves', 'data'), ('data', 'analysts'), ('analysts', '.')]

>> Trigrams are: 
 [('involves', 'data', 'analysts'), ('data', 'analysts', '.')]

>> POS Tags are: 
 [('involves', 'NNS'), ('data', 'NNS'), ('analysts', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['involves data analysts']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('involves', 'involv'), ('data', 'data'), ('analysts', 'analyst'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('involves', 'involv'), ('data', 'data'), ('analysts', 'analyst'), ('.', '.')]

>> Lemmatization: 
 [('involves', 'involves'), ('data', 'data'), ('analysts', 'analyst'), ('.', '.')]


------------------- Sentence 2 -------------------

Information extraction and automatic

>> Tokens are: 
 ['Information', 'extraction', 'automatic']

>> Bigrams are: 
 [('Information', 'extraction'), ('extraction', 'automatic')]

>> Trigrams are: 
 [('Information', 'extraction', 'automatic')]

>> POS Tags are: 
 [('Information', 'NN'), ('extraction', 'NN'), ('automatic', 'NN')]

>> Noun Phrases are: 
 ['Information extraction automatic']

>> Named Entities are: 
 [('GPE', 'Information')] 

>> Stemming using Porter Stemmer: 
 [('Information', 'inform'), ('extraction', 'extract'), ('automatic', 'automat')]

>> Stemming using Snowball Stemmer: 
 [('Information', 'inform'), ('extraction', 'extract'), ('automatic', 'automat')]

>> Lemmatization: 
 [('Information', 'Information'), ('extraction', 'extraction'), ('automatic', 'automatic')]



========================================== PARAGRAPH 234 ===========================================

summarising (Mani and Maybury ,1999) [25] was also a point of focus.  

------------------- Sentence 1 -------------------

summarising (Mani and Maybury ,1999) [25] was also a point of focus.

>> Tokens are: 
 ['summarising', '(', 'Mani', 'Maybury', ',1999', ')', '[', '25', ']', 'also', 'point', 'focus', '.']

>> Bigrams are: 
 [('summarising', '('), ('(', 'Mani'), ('Mani', 'Maybury'), ('Maybury', ',1999'), (',1999', ')'), (')', '['), ('[', '25'), ('25', ']'), (']', 'also'), ('also', 'point'), ('point', 'focus'), ('focus', '.')]

>> Trigrams are: 
 [('summarising', '(', 'Mani'), ('(', 'Mani', 'Maybury'), ('Mani', 'Maybury', ',1999'), ('Maybury', ',1999', ')'), (',1999', ')', '['), (')', '[', '25'), ('[', '25', ']'), ('25', ']', 'also'), (']', 'also', 'point'), ('also', 'point', 'focus'), ('point', 'focus', '.')]

>> POS Tags are: 
 [('summarising', 'VBG'), ('(', '('), ('Mani', 'NNP'), ('Maybury', 'NNP'), (',1999', 'NNP'), (')', ')'), ('[', 'VBD'), ('25', 'CD'), (']', 'NNP'), ('also', 'RB'), ('point', 'NN'), ('focus', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Mani Maybury ,1999', ']', 'point focus']

>> Named Entities are: 
 [('PERSON', 'Mani Maybury')] 

>> Stemming using Porter Stemmer: 
 [('summarising', 'summaris'), ('(', '('), ('Mani', 'mani'), ('Maybury', 'mayburi'), (',1999', ',1999'), (')', ')'), ('[', '['), ('25', '25'), (']', ']'), ('also', 'also'), ('point', 'point'), ('focus', 'focu'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('summarising', 'summaris'), ('(', '('), ('Mani', 'mani'), ('Maybury', 'mayburi'), (',1999', ',1999'), (')', ')'), ('[', '['), ('25', '25'), (']', ']'), ('also', 'also'), ('point', 'point'), ('focus', 'focus'), ('.', '.')]

>> Lemmatization: 
 [('summarising', 'summarising'), ('(', '('), ('Mani', 'Mani'), ('Maybury', 'Maybury'), (',1999', ',1999'), (')', ')'), ('[', '['), ('25', '25'), (']', ']'), ('also', 'also'), ('point', 'point'), ('focus', 'focus'), ('.', '.')]



========================================== PARAGRAPH 235 ===========================================

Recent researches are mainly focused on unsupervised and semi-supervised learning  

------------------- Sentence 1 -------------------

Recent researches are mainly focused on unsupervised and semi-supervised learning

>> Tokens are: 
 ['Recent', 'researches', 'mainly', 'focused', 'unsupervised', 'semi-supervised', 'learning']

>> Bigrams are: 
 [('Recent', 'researches'), ('researches', 'mainly'), ('mainly', 'focused'), ('focused', 'unsupervised'), ('unsupervised', 'semi-supervised'), ('semi-supervised', 'learning')]

>> Trigrams are: 
 [('Recent', 'researches', 'mainly'), ('researches', 'mainly', 'focused'), ('mainly', 'focused', 'unsupervised'), ('focused', 'unsupervised', 'semi-supervised'), ('unsupervised', 'semi-supervised', 'learning')]

>> POS Tags are: 
 [('Recent', 'JJ'), ('researches', 'NNS'), ('mainly', 'RB'), ('focused', 'VBD'), ('unsupervised', 'JJ'), ('semi-supervised', 'JJ'), ('learning', 'NN')]

>> Noun Phrases are: 
 ['Recent researches', 'unsupervised semi-supervised learning']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Recent', 'recent'), ('researches', 'research'), ('mainly', 'mainli'), ('focused', 'focus'), ('unsupervised', 'unsupervis'), ('semi-supervised', 'semi-supervis'), ('learning', 'learn')]

>> Stemming using Snowball Stemmer: 
 [('Recent', 'recent'), ('researches', 'research'), ('mainly', 'main'), ('focused', 'focus'), ('unsupervised', 'unsupervis'), ('semi-supervised', 'semi-supervis'), ('learning', 'learn')]

>> Lemmatization: 
 [('Recent', 'Recent'), ('researches', 'research'), ('mainly', 'mainly'), ('focused', 'focused'), ('unsupervised', 'unsupervised'), ('semi-supervised', 'semi-supervised'), ('learning', 'learning')]



========================================== PARAGRAPH 236 ===========================================

algorithms.  

------------------- Sentence 1 -------------------

algorithms.

>> Tokens are: 
 ['algorithms', '.']

>> Bigrams are: 
 [('algorithms', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('algorithms', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['algorithms']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('algorithms', 'algorithm'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('algorithms', 'algorithm'), ('.', '.')]

>> Lemmatization: 
 [('algorithms', 'algorithm'), ('.', '.')]



========================================== PARAGRAPH 237 ===========================================

5. Related Work  

------------------- Sentence 1 -------------------

5.

>> Tokens are: 
 ['5', '.']

>> Bigrams are: 
 [('5', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('5', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('5', '5'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('5', '5'), ('.', '.')]

>> Lemmatization: 
 [('5', '5'), ('.', '.')]


------------------- Sentence 2 -------------------

Related Work

>> Tokens are: 
 ['Related', 'Work']

>> Bigrams are: 
 [('Related', 'Work')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Related', 'JJ'), ('Work', 'NN')]

>> Noun Phrases are: 
 ['Related Work']

>> Named Entities are: 
 [('GPE', 'Related'), ('ORGANIZATION', 'Work')] 

>> Stemming using Porter Stemmer: 
 [('Related', 'relat'), ('Work', 'work')]

>> Stemming using Snowball Stemmer: 
 [('Related', 'relat'), ('Work', 'work')]

>> Lemmatization: 
 [('Related', 'Related'), ('Work', 'Work')]



========================================== PARAGRAPH 238 ===========================================

Many researchers worked on NLP, building tools and systems which makes NLP what it is  

------------------- Sentence 1 -------------------

Many researchers worked on NLP, building tools and systems which makes NLP what it is

>> Tokens are: 
 ['Many', 'researchers', 'worked', 'NLP', ',', 'building', 'tools', 'systems', 'makes', 'NLP']

>> Bigrams are: 
 [('Many', 'researchers'), ('researchers', 'worked'), ('worked', 'NLP'), ('NLP', ','), (',', 'building'), ('building', 'tools'), ('tools', 'systems'), ('systems', 'makes'), ('makes', 'NLP')]

>> Trigrams are: 
 [('Many', 'researchers', 'worked'), ('researchers', 'worked', 'NLP'), ('worked', 'NLP', ','), ('NLP', ',', 'building'), (',', 'building', 'tools'), ('building', 'tools', 'systems'), ('tools', 'systems', 'makes'), ('systems', 'makes', 'NLP')]

>> POS Tags are: 
 [('Many', 'JJ'), ('researchers', 'NNS'), ('worked', 'VBD'), ('NLP', 'NNP'), (',', ','), ('building', 'NN'), ('tools', 'NNS'), ('systems', 'NNS'), ('makes', 'VBZ'), ('NLP', 'NNP')]

>> Noun Phrases are: 
 ['Many researchers', 'NLP', 'building tools systems', 'NLP']

>> Named Entities are: 
 [('ORGANIZATION', 'NLP'), ('ORGANIZATION', 'NLP')] 

>> Stemming using Porter Stemmer: 
 [('Many', 'mani'), ('researchers', 'research'), ('worked', 'work'), ('NLP', 'nlp'), (',', ','), ('building', 'build'), ('tools', 'tool'), ('systems', 'system'), ('makes', 'make'), ('NLP', 'nlp')]

>> Stemming using Snowball Stemmer: 
 [('Many', 'mani'), ('researchers', 'research'), ('worked', 'work'), ('NLP', 'nlp'), (',', ','), ('building', 'build'), ('tools', 'tool'), ('systems', 'system'), ('makes', 'make'), ('NLP', 'nlp')]

>> Lemmatization: 
 [('Many', 'Many'), ('researchers', 'researcher'), ('worked', 'worked'), ('NLP', 'NLP'), (',', ','), ('building', 'building'), ('tools', 'tool'), ('systems', 'system'), ('makes', 'make'), ('NLP', 'NLP')]



========================================== PARAGRAPH 239 ===========================================

today. Tools like Sentiment Analyser, Parts of Speech (POS)Taggers, Chunking, Named  

------------------- Sentence 1 -------------------

today.

>> Tokens are: 
 ['today', '.']

>> Bigrams are: 
 [('today', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('today', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['today']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('today', 'today'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('today', 'today'), ('.', '.')]

>> Lemmatization: 
 [('today', 'today'), ('.', '.')]


------------------- Sentence 2 -------------------

Tools like Sentiment Analyser, Parts of Speech (POS)Taggers, Chunking, Named

>> Tokens are: 
 ['Tools', 'like', 'Sentiment', 'Analyser', ',', 'Parts', 'Speech', '(', 'POS', ')', 'Taggers', ',', 'Chunking', ',', 'Named']

>> Bigrams are: 
 [('Tools', 'like'), ('like', 'Sentiment'), ('Sentiment', 'Analyser'), ('Analyser', ','), (',', 'Parts'), ('Parts', 'Speech'), ('Speech', '('), ('(', 'POS'), ('POS', ')'), (')', 'Taggers'), ('Taggers', ','), (',', 'Chunking'), ('Chunking', ','), (',', 'Named')]

>> Trigrams are: 
 [('Tools', 'like', 'Sentiment'), ('like', 'Sentiment', 'Analyser'), ('Sentiment', 'Analyser', ','), ('Analyser', ',', 'Parts'), (',', 'Parts', 'Speech'), ('Parts', 'Speech', '('), ('Speech', '(', 'POS'), ('(', 'POS', ')'), ('POS', ')', 'Taggers'), (')', 'Taggers', ','), ('Taggers', ',', 'Chunking'), (',', 'Chunking', ','), ('Chunking', ',', 'Named')]

>> POS Tags are: 
 [('Tools', 'NNS'), ('like', 'IN'), ('Sentiment', 'NNP'), ('Analyser', 'NNP'), (',', ','), ('Parts', 'NNP'), ('Speech', 'NNP'), ('(', '('), ('POS', 'NNP'), (')', ')'), ('Taggers', 'NNPS'), (',', ','), ('Chunking', 'NNP'), (',', ','), ('Named', 'NNP')]

>> Noun Phrases are: 
 ['Tools', 'Sentiment Analyser', 'Parts Speech', 'POS', 'Chunking', 'Named']

>> Named Entities are: 
 [('ORGANIZATION', 'Sentiment Analyser'), ('PERSON', 'Parts Speech'), ('ORGANIZATION', 'POS'), ('GPE', 'Chunking'), ('PERSON', 'Named')] 

>> Stemming using Porter Stemmer: 
 [('Tools', 'tool'), ('like', 'like'), ('Sentiment', 'sentiment'), ('Analyser', 'analys'), (',', ','), ('Parts', 'part'), ('Speech', 'speech'), ('(', '('), ('POS', 'po'), (')', ')'), ('Taggers', 'tagger'), (',', ','), ('Chunking', 'chunk'), (',', ','), ('Named', 'name')]

>> Stemming using Snowball Stemmer: 
 [('Tools', 'tool'), ('like', 'like'), ('Sentiment', 'sentiment'), ('Analyser', 'analys'), (',', ','), ('Parts', 'part'), ('Speech', 'speech'), ('(', '('), ('POS', 'pos'), (')', ')'), ('Taggers', 'tagger'), (',', ','), ('Chunking', 'chunk'), (',', ','), ('Named', 'name')]

>> Lemmatization: 
 [('Tools', 'Tools'), ('like', 'like'), ('Sentiment', 'Sentiment'), ('Analyser', 'Analyser'), (',', ','), ('Parts', 'Parts'), ('Speech', 'Speech'), ('(', '('), ('POS', 'POS'), (')', ')'), ('Taggers', 'Taggers'), (',', ','), ('Chunking', 'Chunking'), (',', ','), ('Named', 'Named')]



========================================== PARAGRAPH 240 ===========================================

Entity Recognitions (NER), Emotion detection, Semantic Role Labelling made NLP a good  

------------------- Sentence 1 -------------------

Entity Recognitions (NER), Emotion detection, Semantic Role Labelling made NLP a good

>> Tokens are: 
 ['Entity', 'Recognitions', '(', 'NER', ')', ',', 'Emotion', 'detection', ',', 'Semantic', 'Role', 'Labelling', 'made', 'NLP', 'good']

>> Bigrams are: 
 [('Entity', 'Recognitions'), ('Recognitions', '('), ('(', 'NER'), ('NER', ')'), (')', ','), (',', 'Emotion'), ('Emotion', 'detection'), ('detection', ','), (',', 'Semantic'), ('Semantic', 'Role'), ('Role', 'Labelling'), ('Labelling', 'made'), ('made', 'NLP'), ('NLP', 'good')]

>> Trigrams are: 
 [('Entity', 'Recognitions', '('), ('Recognitions', '(', 'NER'), ('(', 'NER', ')'), ('NER', ')', ','), (')', ',', 'Emotion'), (',', 'Emotion', 'detection'), ('Emotion', 'detection', ','), ('detection', ',', 'Semantic'), (',', 'Semantic', 'Role'), ('Semantic', 'Role', 'Labelling'), ('Role', 'Labelling', 'made'), ('Labelling', 'made', 'NLP'), ('made', 'NLP', 'good')]

>> POS Tags are: 
 [('Entity', 'NN'), ('Recognitions', 'NNP'), ('(', '('), ('NER', 'NNP'), (')', ')'), (',', ','), ('Emotion', 'NNP'), ('detection', 'NN'), (',', ','), ('Semantic', 'JJ'), ('Role', 'NNP'), ('Labelling', 'NNP'), ('made', 'VBD'), ('NLP', 'NNP'), ('good', 'JJ')]

>> Noun Phrases are: 
 ['Entity Recognitions', 'NER', 'Emotion detection', 'Semantic Role Labelling', 'NLP']

>> Named Entities are: 
 [('GPE', 'Entity'), ('ORGANIZATION', 'Recognitions'), ('ORGANIZATION', 'NER'), ('GPE', 'Emotion'), ('ORGANIZATION', 'Semantic Role'), ('ORGANIZATION', 'NLP')] 

>> Stemming using Porter Stemmer: 
 [('Entity', 'entiti'), ('Recognitions', 'recognit'), ('(', '('), ('NER', 'ner'), (')', ')'), (',', ','), ('Emotion', 'emot'), ('detection', 'detect'), (',', ','), ('Semantic', 'semant'), ('Role', 'role'), ('Labelling', 'label'), ('made', 'made'), ('NLP', 'nlp'), ('good', 'good')]

>> Stemming using Snowball Stemmer: 
 [('Entity', 'entiti'), ('Recognitions', 'recognit'), ('(', '('), ('NER', 'ner'), (')', ')'), (',', ','), ('Emotion', 'emot'), ('detection', 'detect'), (',', ','), ('Semantic', 'semant'), ('Role', 'role'), ('Labelling', 'label'), ('made', 'made'), ('NLP', 'nlp'), ('good', 'good')]

>> Lemmatization: 
 [('Entity', 'Entity'), ('Recognitions', 'Recognitions'), ('(', '('), ('NER', 'NER'), (')', ')'), (',', ','), ('Emotion', 'Emotion'), ('detection', 'detection'), (',', ','), ('Semantic', 'Semantic'), ('Role', 'Role'), ('Labelling', 'Labelling'), ('made', 'made'), ('NLP', 'NLP'), ('good', 'good')]



========================================== PARAGRAPH 241 ===========================================

topic for research.   

------------------- Sentence 1 -------------------

topic for research.

>> Tokens are: 
 ['topic', 'research', '.']

>> Bigrams are: 
 [('topic', 'research'), ('research', '.')]

>> Trigrams are: 
 [('topic', 'research', '.')]

>> POS Tags are: 
 [('topic', 'NN'), ('research', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['topic research']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('topic', 'topic'), ('research', 'research'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('topic', 'topic'), ('research', 'research'), ('.', '.')]

>> Lemmatization: 
 [('topic', 'topic'), ('research', 'research'), ('.', '.')]



========================================== PARAGRAPH 242 ===========================================

Sentiment analyser (Jeonghee etal.,2003) [26] works by extracting sentiments about given  

------------------- Sentence 1 -------------------

Sentiment analyser (Jeonghee etal.,2003) [26] works by extracting sentiments about given

>> Tokens are: 
 ['Sentiment', 'analyser', '(', 'Jeonghee', 'etal.,2003', ')', '[', '26', ']', 'works', 'extracting', 'sentiments', 'given']

>> Bigrams are: 
 [('Sentiment', 'analyser'), ('analyser', '('), ('(', 'Jeonghee'), ('Jeonghee', 'etal.,2003'), ('etal.,2003', ')'), (')', '['), ('[', '26'), ('26', ']'), (']', 'works'), ('works', 'extracting'), ('extracting', 'sentiments'), ('sentiments', 'given')]

>> Trigrams are: 
 [('Sentiment', 'analyser', '('), ('analyser', '(', 'Jeonghee'), ('(', 'Jeonghee', 'etal.,2003'), ('Jeonghee', 'etal.,2003', ')'), ('etal.,2003', ')', '['), (')', '[', '26'), ('[', '26', ']'), ('26', ']', 'works'), (']', 'works', 'extracting'), ('works', 'extracting', 'sentiments'), ('extracting', 'sentiments', 'given')]

>> POS Tags are: 
 [('Sentiment', 'NNP'), ('analyser', 'NN'), ('(', '('), ('Jeonghee', 'NNP'), ('etal.,2003', 'RB'), (')', ')'), ('[', 'VBZ'), ('26', 'CD'), (']', 'NN'), ('works', 'NNS'), ('extracting', 'VBG'), ('sentiments', 'NNS'), ('given', 'VBN')]

>> Noun Phrases are: 
 ['Sentiment analyser', 'Jeonghee', '] works', 'sentiments']

>> Named Entities are: 
 [('ORGANIZATION', 'Jeonghee')] 

>> Stemming using Porter Stemmer: 
 [('Sentiment', 'sentiment'), ('analyser', 'analys'), ('(', '('), ('Jeonghee', 'jeonghe'), ('etal.,2003', 'etal.,2003'), (')', ')'), ('[', '['), ('26', '26'), (']', ']'), ('works', 'work'), ('extracting', 'extract'), ('sentiments', 'sentiment'), ('given', 'given')]

>> Stemming using Snowball Stemmer: 
 [('Sentiment', 'sentiment'), ('analyser', 'analys'), ('(', '('), ('Jeonghee', 'jeonghe'), ('etal.,2003', 'etal.,2003'), (')', ')'), ('[', '['), ('26', '26'), (']', ']'), ('works', 'work'), ('extracting', 'extract'), ('sentiments', 'sentiment'), ('given', 'given')]

>> Lemmatization: 
 [('Sentiment', 'Sentiment'), ('analyser', 'analyser'), ('(', '('), ('Jeonghee', 'Jeonghee'), ('etal.,2003', 'etal.,2003'), (')', ')'), ('[', '['), ('26', '26'), (']', ']'), ('works', 'work'), ('extracting', 'extracting'), ('sentiments', 'sentiment'), ('given', 'given')]



========================================== PARAGRAPH 243 ===========================================

topic. Sentiment analysis consists of a topic specific feature term extraction, sentiment  

------------------- Sentence 1 -------------------

topic.

>> Tokens are: 
 ['topic', '.']

>> Bigrams are: 
 [('topic', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('topic', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['topic']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('topic', 'topic'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('topic', 'topic'), ('.', '.')]

>> Lemmatization: 
 [('topic', 'topic'), ('.', '.')]


------------------- Sentence 2 -------------------

Sentiment analysis consists of a topic specific feature term extraction, sentiment

>> Tokens are: 
 ['Sentiment', 'analysis', 'consists', 'topic', 'specific', 'feature', 'term', 'extraction', ',', 'sentiment']

>> Bigrams are: 
 [('Sentiment', 'analysis'), ('analysis', 'consists'), ('consists', 'topic'), ('topic', 'specific'), ('specific', 'feature'), ('feature', 'term'), ('term', 'extraction'), ('extraction', ','), (',', 'sentiment')]

>> Trigrams are: 
 [('Sentiment', 'analysis', 'consists'), ('analysis', 'consists', 'topic'), ('consists', 'topic', 'specific'), ('topic', 'specific', 'feature'), ('specific', 'feature', 'term'), ('feature', 'term', 'extraction'), ('term', 'extraction', ','), ('extraction', ',', 'sentiment')]

>> POS Tags are: 
 [('Sentiment', 'NN'), ('analysis', 'NN'), ('consists', 'VBZ'), ('topic', 'NN'), ('specific', 'JJ'), ('feature', 'JJ'), ('term', 'NN'), ('extraction', 'NN'), (',', ','), ('sentiment', 'NN')]

>> Noun Phrases are: 
 ['Sentiment analysis', 'topic', 'specific feature term extraction', 'sentiment']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Sentiment', 'sentiment'), ('analysis', 'analysi'), ('consists', 'consist'), ('topic', 'topic'), ('specific', 'specif'), ('feature', 'featur'), ('term', 'term'), ('extraction', 'extract'), (',', ','), ('sentiment', 'sentiment')]

>> Stemming using Snowball Stemmer: 
 [('Sentiment', 'sentiment'), ('analysis', 'analysi'), ('consists', 'consist'), ('topic', 'topic'), ('specific', 'specif'), ('feature', 'featur'), ('term', 'term'), ('extraction', 'extract'), (',', ','), ('sentiment', 'sentiment')]

>> Lemmatization: 
 [('Sentiment', 'Sentiment'), ('analysis', 'analysis'), ('consists', 'consists'), ('topic', 'topic'), ('specific', 'specific'), ('feature', 'feature'), ('term', 'term'), ('extraction', 'extraction'), (',', ','), ('sentiment', 'sentiment')]



========================================== PARAGRAPH 244 ===========================================

extraction, and association by relationship analysis. Sentiment Analysis utilizes two linguistic  

------------------- Sentence 1 -------------------

extraction, and association by relationship analysis.

>> Tokens are: 
 ['extraction', ',', 'association', 'relationship', 'analysis', '.']

>> Bigrams are: 
 [('extraction', ','), (',', 'association'), ('association', 'relationship'), ('relationship', 'analysis'), ('analysis', '.')]

>> Trigrams are: 
 [('extraction', ',', 'association'), (',', 'association', 'relationship'), ('association', 'relationship', 'analysis'), ('relationship', 'analysis', '.')]

>> POS Tags are: 
 [('extraction', 'NN'), (',', ','), ('association', 'NN'), ('relationship', 'NN'), ('analysis', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['extraction', 'association relationship analysis']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('extraction', 'extract'), (',', ','), ('association', 'associ'), ('relationship', 'relationship'), ('analysis', 'analysi'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('extraction', 'extract'), (',', ','), ('association', 'associ'), ('relationship', 'relationship'), ('analysis', 'analysi'), ('.', '.')]

>> Lemmatization: 
 [('extraction', 'extraction'), (',', ','), ('association', 'association'), ('relationship', 'relationship'), ('analysis', 'analysis'), ('.', '.')]


------------------- Sentence 2 -------------------

Sentiment Analysis utilizes two linguistic

>> Tokens are: 
 ['Sentiment', 'Analysis', 'utilizes', 'two', 'linguistic']

>> Bigrams are: 
 [('Sentiment', 'Analysis'), ('Analysis', 'utilizes'), ('utilizes', 'two'), ('two', 'linguistic')]

>> Trigrams are: 
 [('Sentiment', 'Analysis', 'utilizes'), ('Analysis', 'utilizes', 'two'), ('utilizes', 'two', 'linguistic')]

>> POS Tags are: 
 [('Sentiment', 'NN'), ('Analysis', 'NN'), ('utilizes', 'JJ'), ('two', 'CD'), ('linguistic', 'JJ')]

>> Noun Phrases are: 
 ['Sentiment Analysis']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Sentiment', 'sentiment'), ('Analysis', 'analysi'), ('utilizes', 'util'), ('two', 'two'), ('linguistic', 'linguist')]

>> Stemming using Snowball Stemmer: 
 [('Sentiment', 'sentiment'), ('Analysis', 'analysi'), ('utilizes', 'util'), ('two', 'two'), ('linguistic', 'linguist')]

>> Lemmatization: 
 [('Sentiment', 'Sentiment'), ('Analysis', 'Analysis'), ('utilizes', 'utilizes'), ('two', 'two'), ('linguistic', 'linguistic')]



========================================== PARAGRAPH 245 ===========================================

resources for the analysis: the sentiment lexicon and the sentiment pattern database. It  

------------------- Sentence 1 -------------------

resources for the analysis: the sentiment lexicon and the sentiment pattern database.

>> Tokens are: 
 ['resources', 'analysis', ':', 'sentiment', 'lexicon', 'sentiment', 'pattern', 'database', '.']

>> Bigrams are: 
 [('resources', 'analysis'), ('analysis', ':'), (':', 'sentiment'), ('sentiment', 'lexicon'), ('lexicon', 'sentiment'), ('sentiment', 'pattern'), ('pattern', 'database'), ('database', '.')]

>> Trigrams are: 
 [('resources', 'analysis', ':'), ('analysis', ':', 'sentiment'), (':', 'sentiment', 'lexicon'), ('sentiment', 'lexicon', 'sentiment'), ('lexicon', 'sentiment', 'pattern'), ('sentiment', 'pattern', 'database'), ('pattern', 'database', '.')]

>> POS Tags are: 
 [('resources', 'NNS'), ('analysis', 'NN'), (':', ':'), ('sentiment', 'NN'), ('lexicon', 'NN'), ('sentiment', 'NN'), ('pattern', 'JJ'), ('database', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['resources analysis', 'sentiment lexicon sentiment', 'pattern database']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('resources', 'resourc'), ('analysis', 'analysi'), (':', ':'), ('sentiment', 'sentiment'), ('lexicon', 'lexicon'), ('sentiment', 'sentiment'), ('pattern', 'pattern'), ('database', 'databas'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('resources', 'resourc'), ('analysis', 'analysi'), (':', ':'), ('sentiment', 'sentiment'), ('lexicon', 'lexicon'), ('sentiment', 'sentiment'), ('pattern', 'pattern'), ('database', 'databas'), ('.', '.')]

>> Lemmatization: 
 [('resources', 'resource'), ('analysis', 'analysis'), (':', ':'), ('sentiment', 'sentiment'), ('lexicon', 'lexicon'), ('sentiment', 'sentiment'), ('pattern', 'pattern'), ('database', 'database'), ('.', '.')]


------------------- Sentence 2 -------------------

It

>> Tokens are: 
 ['It']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('It', 'PRP')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('It', 'it')]

>> Stemming using Snowball Stemmer: 
 [('It', 'it')]

>> Lemmatization: 
 [('It', 'It')]



========================================== PARAGRAPH 246 ===========================================

analyses the documents for positive and negative words and try to give ratings on scale -5 to  

------------------- Sentence 1 -------------------

analyses the documents for positive and negative words and try to give ratings on scale -5 to

>> Tokens are: 
 ['analyses', 'documents', 'positive', 'negative', 'words', 'try', 'give', 'ratings', 'scale', '-5']

>> Bigrams are: 
 [('analyses', 'documents'), ('documents', 'positive'), ('positive', 'negative'), ('negative', 'words'), ('words', 'try'), ('try', 'give'), ('give', 'ratings'), ('ratings', 'scale'), ('scale', '-5')]

>> Trigrams are: 
 [('analyses', 'documents', 'positive'), ('documents', 'positive', 'negative'), ('positive', 'negative', 'words'), ('negative', 'words', 'try'), ('words', 'try', 'give'), ('try', 'give', 'ratings'), ('give', 'ratings', 'scale'), ('ratings', 'scale', '-5')]

>> POS Tags are: 
 [('analyses', 'NNS'), ('documents', 'NNS'), ('positive', 'JJ'), ('negative', 'JJ'), ('words', 'NNS'), ('try', 'VBP'), ('give', 'JJ'), ('ratings', 'NNS'), ('scale', 'NN'), ('-5', 'NN')]

>> Noun Phrases are: 
 ['analyses documents', 'positive negative words', 'give ratings scale -5']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('analyses', 'analys'), ('documents', 'document'), ('positive', 'posit'), ('negative', 'neg'), ('words', 'word'), ('try', 'tri'), ('give', 'give'), ('ratings', 'rate'), ('scale', 'scale'), ('-5', '-5')]

>> Stemming using Snowball Stemmer: 
 [('analyses', 'analys'), ('documents', 'document'), ('positive', 'posit'), ('negative', 'negat'), ('words', 'word'), ('try', 'tri'), ('give', 'give'), ('ratings', 'rate'), ('scale', 'scale'), ('-5', '-5')]

>> Lemmatization: 
 [('analyses', 'analysis'), ('documents', 'document'), ('positive', 'positive'), ('negative', 'negative'), ('words', 'word'), ('try', 'try'), ('give', 'give'), ('ratings', 'rating'), ('scale', 'scale'), ('-5', '-5')]



========================================== PARAGRAPH 247 ===========================================

+5.  

------------------- Sentence 1 -------------------

+5.

>> Tokens are: 
 ['+5', '.']

>> Bigrams are: 
 [('+5', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('+5', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['+5']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('+5', '+5'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('+5', '+5'), ('.', '.')]

>> Lemmatization: 
 [('+5', '+5'), ('.', '.')]



========================================== PARAGRAPH 248 ===========================================

Parts of speech taggers for the languages like European languages, research is being done on  

------------------- Sentence 1 -------------------

Parts of speech taggers for the languages like European languages, research is being done on

>> Tokens are: 
 ['Parts', 'speech', 'taggers', 'languages', 'like', 'European', 'languages', ',', 'research', 'done']

>> Bigrams are: 
 [('Parts', 'speech'), ('speech', 'taggers'), ('taggers', 'languages'), ('languages', 'like'), ('like', 'European'), ('European', 'languages'), ('languages', ','), (',', 'research'), ('research', 'done')]

>> Trigrams are: 
 [('Parts', 'speech', 'taggers'), ('speech', 'taggers', 'languages'), ('taggers', 'languages', 'like'), ('languages', 'like', 'European'), ('like', 'European', 'languages'), ('European', 'languages', ','), ('languages', ',', 'research'), (',', 'research', 'done')]

>> POS Tags are: 
 [('Parts', 'NNS'), ('speech', 'NN'), ('taggers', 'NNS'), ('languages', 'VBP'), ('like', 'IN'), ('European', 'JJ'), ('languages', 'NNS'), (',', ','), ('research', 'NN'), ('done', 'VBN')]

>> Noun Phrases are: 
 ['Parts speech taggers', 'European languages', 'research']

>> Named Entities are: 
 [('GPE', 'Parts'), ('GPE', 'European')] 

>> Stemming using Porter Stemmer: 
 [('Parts', 'part'), ('speech', 'speech'), ('taggers', 'tagger'), ('languages', 'languag'), ('like', 'like'), ('European', 'european'), ('languages', 'languag'), (',', ','), ('research', 'research'), ('done', 'done')]

>> Stemming using Snowball Stemmer: 
 [('Parts', 'part'), ('speech', 'speech'), ('taggers', 'tagger'), ('languages', 'languag'), ('like', 'like'), ('European', 'european'), ('languages', 'languag'), (',', ','), ('research', 'research'), ('done', 'done')]

>> Lemmatization: 
 [('Parts', 'Parts'), ('speech', 'speech'), ('taggers', 'tagger'), ('languages', 'language'), ('like', 'like'), ('European', 'European'), ('languages', 'language'), (',', ','), ('research', 'research'), ('done', 'done')]



========================================== PARAGRAPH 249 ===========================================

making parts of speech taggers for other languages like Arabic, Sanskrit (Namrata Tapswi ,  

------------------- Sentence 1 -------------------

making parts of speech taggers for other languages like Arabic, Sanskrit (Namrata Tapswi ,

>> Tokens are: 
 ['making', 'parts', 'speech', 'taggers', 'languages', 'like', 'Arabic', ',', 'Sanskrit', '(', 'Namrata', 'Tapswi', ',']

>> Bigrams are: 
 [('making', 'parts'), ('parts', 'speech'), ('speech', 'taggers'), ('taggers', 'languages'), ('languages', 'like'), ('like', 'Arabic'), ('Arabic', ','), (',', 'Sanskrit'), ('Sanskrit', '('), ('(', 'Namrata'), ('Namrata', 'Tapswi'), ('Tapswi', ',')]

>> Trigrams are: 
 [('making', 'parts', 'speech'), ('parts', 'speech', 'taggers'), ('speech', 'taggers', 'languages'), ('taggers', 'languages', 'like'), ('languages', 'like', 'Arabic'), ('like', 'Arabic', ','), ('Arabic', ',', 'Sanskrit'), (',', 'Sanskrit', '('), ('Sanskrit', '(', 'Namrata'), ('(', 'Namrata', 'Tapswi'), ('Namrata', 'Tapswi', ',')]

>> POS Tags are: 
 [('making', 'VBG'), ('parts', 'NNS'), ('speech', 'NN'), ('taggers', 'NNS'), ('languages', 'NNS'), ('like', 'IN'), ('Arabic', 'NNP'), (',', ','), ('Sanskrit', 'NNP'), ('(', '('), ('Namrata', 'NNP'), ('Tapswi', 'NNP'), (',', ',')]

>> Noun Phrases are: 
 ['parts speech taggers languages', 'Arabic', 'Sanskrit', 'Namrata Tapswi']

>> Named Entities are: 
 [('PERSON', 'Arabic'), ('GPE', 'Sanskrit'), ('ORGANIZATION', 'Namrata Tapswi')] 

>> Stemming using Porter Stemmer: 
 [('making', 'make'), ('parts', 'part'), ('speech', 'speech'), ('taggers', 'tagger'), ('languages', 'languag'), ('like', 'like'), ('Arabic', 'arab'), (',', ','), ('Sanskrit', 'sanskrit'), ('(', '('), ('Namrata', 'namrata'), ('Tapswi', 'tapswi'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('making', 'make'), ('parts', 'part'), ('speech', 'speech'), ('taggers', 'tagger'), ('languages', 'languag'), ('like', 'like'), ('Arabic', 'arab'), (',', ','), ('Sanskrit', 'sanskrit'), ('(', '('), ('Namrata', 'namrata'), ('Tapswi', 'tapswi'), (',', ',')]

>> Lemmatization: 
 [('making', 'making'), ('parts', 'part'), ('speech', 'speech'), ('taggers', 'tagger'), ('languages', 'language'), ('like', 'like'), ('Arabic', 'Arabic'), (',', ','), ('Sanskrit', 'Sanskrit'), ('(', '('), ('Namrata', 'Namrata'), ('Tapswi', 'Tapswi'), (',', ',')]



========================================== PARAGRAPH 250 ===========================================

Suresh Jain ., 2012) [27], Hindi (Pradipta Ranjan Ray et al., 2003 )[28] etc. It can efficiently  

------------------- Sentence 1 -------------------

Suresh Jain ., 2012) [27], Hindi (Pradipta Ranjan Ray et al., 2003 )[28] etc.

>> Tokens are: 
 ['Suresh', 'Jain', '.', ',', '2012', ')', '[', '27', ']', ',', 'Hindi', '(', 'Pradipta', 'Ranjan', 'Ray', 'et', 'al.', ',', '2003', ')', '[', '28', ']', 'etc', '.']

>> Bigrams are: 
 [('Suresh', 'Jain'), ('Jain', '.'), ('.', ','), (',', '2012'), ('2012', ')'), (')', '['), ('[', '27'), ('27', ']'), (']', ','), (',', 'Hindi'), ('Hindi', '('), ('(', 'Pradipta'), ('Pradipta', 'Ranjan'), ('Ranjan', 'Ray'), ('Ray', 'et'), ('et', 'al.'), ('al.', ','), (',', '2003'), ('2003', ')'), (')', '['), ('[', '28'), ('28', ']'), (']', 'etc'), ('etc', '.')]

>> Trigrams are: 
 [('Suresh', 'Jain', '.'), ('Jain', '.', ','), ('.', ',', '2012'), (',', '2012', ')'), ('2012', ')', '['), (')', '[', '27'), ('[', '27', ']'), ('27', ']', ','), (']', ',', 'Hindi'), (',', 'Hindi', '('), ('Hindi', '(', 'Pradipta'), ('(', 'Pradipta', 'Ranjan'), ('Pradipta', 'Ranjan', 'Ray'), ('Ranjan', 'Ray', 'et'), ('Ray', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2003'), (',', '2003', ')'), ('2003', ')', '['), (')', '[', '28'), ('[', '28', ']'), ('28', ']', 'etc'), (']', 'etc', '.')]

>> POS Tags are: 
 [('Suresh', 'NNP'), ('Jain', 'NNP'), ('.', '.'), (',', ','), ('2012', 'CD'), (')', ')'), ('[', 'VBD'), ('27', 'CD'), (']', 'NN'), (',', ','), ('Hindi', 'NNP'), ('(', '('), ('Pradipta', 'NNP'), ('Ranjan', 'NNP'), ('Ray', 'NNP'), ('et', 'FW'), ('al.', 'NN'), (',', ','), ('2003', 'CD'), (')', ')'), ('[', 'VBD'), ('28', 'CD'), (']', 'JJ'), ('etc', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Suresh Jain', ']', 'Hindi', 'Pradipta Ranjan Ray', 'al.', '] etc']

>> Named Entities are: 
 [('PERSON', 'Suresh'), ('ORGANIZATION', 'Jain'), ('GPE', 'Hindi'), ('ORGANIZATION', 'Pradipta Ranjan Ray')] 

>> Stemming using Porter Stemmer: 
 [('Suresh', 'suresh'), ('Jain', 'jain'), ('.', '.'), (',', ','), ('2012', '2012'), (')', ')'), ('[', '['), ('27', '27'), (']', ']'), (',', ','), ('Hindi', 'hindi'), ('(', '('), ('Pradipta', 'pradipta'), ('Ranjan', 'ranjan'), ('Ray', 'ray'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2003', '2003'), (')', ')'), ('[', '['), ('28', '28'), (']', ']'), ('etc', 'etc'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Suresh', 'suresh'), ('Jain', 'jain'), ('.', '.'), (',', ','), ('2012', '2012'), (')', ')'), ('[', '['), ('27', '27'), (']', ']'), (',', ','), ('Hindi', 'hindi'), ('(', '('), ('Pradipta', 'pradipta'), ('Ranjan', 'ranjan'), ('Ray', 'ray'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2003', '2003'), (')', ')'), ('[', '['), ('28', '28'), (']', ']'), ('etc', 'etc'), ('.', '.')]

>> Lemmatization: 
 [('Suresh', 'Suresh'), ('Jain', 'Jain'), ('.', '.'), (',', ','), ('2012', '2012'), (')', ')'), ('[', '['), ('27', '27'), (']', ']'), (',', ','), ('Hindi', 'Hindi'), ('(', '('), ('Pradipta', 'Pradipta'), ('Ranjan', 'Ranjan'), ('Ray', 'Ray'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2003', '2003'), (')', ')'), ('[', '['), ('28', '28'), (']', ']'), ('etc', 'etc'), ('.', '.')]


------------------- Sentence 2 -------------------

It can efficiently

>> Tokens are: 
 ['It', 'efficiently']

>> Bigrams are: 
 [('It', 'efficiently')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('It', 'PRP'), ('efficiently', 'RB')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('It', 'it'), ('efficiently', 'effici')]

>> Stemming using Snowball Stemmer: 
 [('It', 'it'), ('efficiently', 'effici')]

>> Lemmatization: 
 [('It', 'It'), ('efficiently', 'efficiently')]



========================================== PARAGRAPH 251 ===========================================

tag and classify words as nouns, adjectives, verbs etc. The most procedures for part of speech  

------------------- Sentence 1 -------------------

tag and classify words as nouns, adjectives, verbs etc.

>> Tokens are: 
 ['tag', 'classify', 'words', 'nouns', ',', 'adjectives', ',', 'verbs', 'etc', '.']

>> Bigrams are: 
 [('tag', 'classify'), ('classify', 'words'), ('words', 'nouns'), ('nouns', ','), (',', 'adjectives'), ('adjectives', ','), (',', 'verbs'), ('verbs', 'etc'), ('etc', '.')]

>> Trigrams are: 
 [('tag', 'classify', 'words'), ('classify', 'words', 'nouns'), ('words', 'nouns', ','), ('nouns', ',', 'adjectives'), (',', 'adjectives', ','), ('adjectives', ',', 'verbs'), (',', 'verbs', 'etc'), ('verbs', 'etc', '.')]

>> POS Tags are: 
 [('tag', 'NN'), ('classify', 'NN'), ('words', 'NNS'), ('nouns', 'NNS'), (',', ','), ('adjectives', 'NNS'), (',', ','), ('verbs', 'JJ'), ('etc', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['tag classify words nouns', 'adjectives', 'verbs etc']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('tag', 'tag'), ('classify', 'classifi'), ('words', 'word'), ('nouns', 'noun'), (',', ','), ('adjectives', 'adject'), (',', ','), ('verbs', 'verb'), ('etc', 'etc'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('tag', 'tag'), ('classify', 'classifi'), ('words', 'word'), ('nouns', 'noun'), (',', ','), ('adjectives', 'adject'), (',', ','), ('verbs', 'verb'), ('etc', 'etc'), ('.', '.')]

>> Lemmatization: 
 [('tag', 'tag'), ('classify', 'classify'), ('words', 'word'), ('nouns', 'noun'), (',', ','), ('adjectives', 'adjective'), (',', ','), ('verbs', 'verb'), ('etc', 'etc'), ('.', '.')]


------------------- Sentence 2 -------------------

The most procedures for part of speech

>> Tokens are: 
 ['The', 'procedures', 'part', 'speech']

>> Bigrams are: 
 [('The', 'procedures'), ('procedures', 'part'), ('part', 'speech')]

>> Trigrams are: 
 [('The', 'procedures', 'part'), ('procedures', 'part', 'speech')]

>> POS Tags are: 
 [('The', 'DT'), ('procedures', 'NNS'), ('part', 'NN'), ('speech', 'NN')]

>> Noun Phrases are: 
 ['The procedures part speech']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('procedures', 'procedur'), ('part', 'part'), ('speech', 'speech')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('procedures', 'procedur'), ('part', 'part'), ('speech', 'speech')]

>> Lemmatization: 
 [('The', 'The'), ('procedures', 'procedure'), ('part', 'part'), ('speech', 'speech')]



========================================== PARAGRAPH 252 ===========================================

can work efficiently on European languages, but it won’t on Asian languages or middle  

------------------- Sentence 1 -------------------

can work efficiently on European languages, but it won’t on Asian languages or middle

>> Tokens are: 
 ['work', 'efficiently', 'European', 'languages', ',', '’', 'Asian', 'languages', 'middle']

>> Bigrams are: 
 [('work', 'efficiently'), ('efficiently', 'European'), ('European', 'languages'), ('languages', ','), (',', '’'), ('’', 'Asian'), ('Asian', 'languages'), ('languages', 'middle')]

>> Trigrams are: 
 [('work', 'efficiently', 'European'), ('efficiently', 'European', 'languages'), ('European', 'languages', ','), ('languages', ',', '’'), (',', '’', 'Asian'), ('’', 'Asian', 'languages'), ('Asian', 'languages', 'middle')]

>> POS Tags are: 
 [('work', 'NN'), ('efficiently', 'RB'), ('European', 'JJ'), ('languages', 'NNS'), (',', ','), ('’', 'JJ'), ('Asian', 'JJ'), ('languages', 'NNS'), ('middle', 'VBP')]

>> Noun Phrases are: 
 ['work', 'European languages', '’ Asian languages']

>> Named Entities are: 
 [('GPE', 'European'), ('GPE', 'Asian')] 

>> Stemming using Porter Stemmer: 
 [('work', 'work'), ('efficiently', 'effici'), ('European', 'european'), ('languages', 'languag'), (',', ','), ('’', '’'), ('Asian', 'asian'), ('languages', 'languag'), ('middle', 'middl')]

>> Stemming using Snowball Stemmer: 
 [('work', 'work'), ('efficiently', 'effici'), ('European', 'european'), ('languages', 'languag'), (',', ','), ('’', '’'), ('Asian', 'asian'), ('languages', 'languag'), ('middle', 'middl')]

>> Lemmatization: 
 [('work', 'work'), ('efficiently', 'efficiently'), ('European', 'European'), ('languages', 'language'), (',', ','), ('’', '’'), ('Asian', 'Asian'), ('languages', 'language'), ('middle', 'middle')]



========================================== PARAGRAPH 253 ===========================================

eastern languages. Sanskrit part of speech tagger is specifically uses treebank technique.  

------------------- Sentence 1 -------------------

eastern languages.

>> Tokens are: 
 ['eastern', 'languages', '.']

>> Bigrams are: 
 [('eastern', 'languages'), ('languages', '.')]

>> Trigrams are: 
 [('eastern', 'languages', '.')]

>> POS Tags are: 
 [('eastern', 'JJ'), ('languages', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['eastern languages']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('eastern', 'eastern'), ('languages', 'languag'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('eastern', 'eastern'), ('languages', 'languag'), ('.', '.')]

>> Lemmatization: 
 [('eastern', 'eastern'), ('languages', 'language'), ('.', '.')]


------------------- Sentence 2 -------------------

Sanskrit part of speech tagger is specifically uses treebank technique.

>> Tokens are: 
 ['Sanskrit', 'part', 'speech', 'tagger', 'specifically', 'uses', 'treebank', 'technique', '.']

>> Bigrams are: 
 [('Sanskrit', 'part'), ('part', 'speech'), ('speech', 'tagger'), ('tagger', 'specifically'), ('specifically', 'uses'), ('uses', 'treebank'), ('treebank', 'technique'), ('technique', '.')]

>> Trigrams are: 
 [('Sanskrit', 'part', 'speech'), ('part', 'speech', 'tagger'), ('speech', 'tagger', 'specifically'), ('tagger', 'specifically', 'uses'), ('specifically', 'uses', 'treebank'), ('uses', 'treebank', 'technique'), ('treebank', 'technique', '.')]

>> POS Tags are: 
 [('Sanskrit', 'NNP'), ('part', 'NN'), ('speech', 'NN'), ('tagger', 'NN'), ('specifically', 'RB'), ('uses', 'VBZ'), ('treebank', 'NN'), ('technique', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Sanskrit part speech tagger', 'treebank technique']

>> Named Entities are: 
 [('GPE', 'Sanskrit')] 

>> Stemming using Porter Stemmer: 
 [('Sanskrit', 'sanskrit'), ('part', 'part'), ('speech', 'speech'), ('tagger', 'tagger'), ('specifically', 'specif'), ('uses', 'use'), ('treebank', 'treebank'), ('technique', 'techniqu'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Sanskrit', 'sanskrit'), ('part', 'part'), ('speech', 'speech'), ('tagger', 'tagger'), ('specifically', 'specif'), ('uses', 'use'), ('treebank', 'treebank'), ('technique', 'techniqu'), ('.', '.')]

>> Lemmatization: 
 [('Sanskrit', 'Sanskrit'), ('part', 'part'), ('speech', 'speech'), ('tagger', 'tagger'), ('specifically', 'specifically'), ('uses', 'us'), ('treebank', 'treebank'), ('technique', 'technique'), ('.', '.')]



========================================== PARAGRAPH 254 ===========================================

Arabic uses Support Vector Machine (SVM) (Mona Diab etal.,2004) [29] approach to  

------------------- Sentence 1 -------------------

Arabic uses Support Vector Machine (SVM) (Mona Diab etal.,2004) [29] approach to

>> Tokens are: 
 ['Arabic', 'uses', 'Support', 'Vector', 'Machine', '(', 'SVM', ')', '(', 'Mona', 'Diab', 'etal.,2004', ')', '[', '29', ']', 'approach']

>> Bigrams are: 
 [('Arabic', 'uses'), ('uses', 'Support'), ('Support', 'Vector'), ('Vector', 'Machine'), ('Machine', '('), ('(', 'SVM'), ('SVM', ')'), (')', '('), ('(', 'Mona'), ('Mona', 'Diab'), ('Diab', 'etal.,2004'), ('etal.,2004', ')'), (')', '['), ('[', '29'), ('29', ']'), (']', 'approach')]

>> Trigrams are: 
 [('Arabic', 'uses', 'Support'), ('uses', 'Support', 'Vector'), ('Support', 'Vector', 'Machine'), ('Vector', 'Machine', '('), ('Machine', '(', 'SVM'), ('(', 'SVM', ')'), ('SVM', ')', '('), (')', '(', 'Mona'), ('(', 'Mona', 'Diab'), ('Mona', 'Diab', 'etal.,2004'), ('Diab', 'etal.,2004', ')'), ('etal.,2004', ')', '['), (')', '[', '29'), ('[', '29', ']'), ('29', ']', 'approach')]

>> POS Tags are: 
 [('Arabic', 'JJ'), ('uses', 'VBZ'), ('Support', 'NNP'), ('Vector', 'NNP'), ('Machine', 'NNP'), ('(', '('), ('SVM', 'NNP'), (')', ')'), ('(', '('), ('Mona', 'NNP'), ('Diab', 'NNP'), ('etal.,2004', 'NN'), (')', ')'), ('[', 'VBZ'), ('29', 'CD'), (']', 'NN'), ('approach', 'NN')]

>> Noun Phrases are: 
 ['Support Vector Machine', 'SVM', 'Mona Diab etal.,2004', '] approach']

>> Named Entities are: 
 [('PERSON', 'Arabic'), ('PERSON', 'Support Vector Machine'), ('ORGANIZATION', 'SVM'), ('ORGANIZATION', 'Mona Diab')] 

>> Stemming using Porter Stemmer: 
 [('Arabic', 'arab'), ('uses', 'use'), ('Support', 'support'), ('Vector', 'vector'), ('Machine', 'machin'), ('(', '('), ('SVM', 'svm'), (')', ')'), ('(', '('), ('Mona', 'mona'), ('Diab', 'diab'), ('etal.,2004', 'etal.,2004'), (')', ')'), ('[', '['), ('29', '29'), (']', ']'), ('approach', 'approach')]

>> Stemming using Snowball Stemmer: 
 [('Arabic', 'arab'), ('uses', 'use'), ('Support', 'support'), ('Vector', 'vector'), ('Machine', 'machin'), ('(', '('), ('SVM', 'svm'), (')', ')'), ('(', '('), ('Mona', 'mona'), ('Diab', 'diab'), ('etal.,2004', 'etal.,2004'), (')', ')'), ('[', '['), ('29', '29'), (']', ']'), ('approach', 'approach')]

>> Lemmatization: 
 [('Arabic', 'Arabic'), ('uses', 'us'), ('Support', 'Support'), ('Vector', 'Vector'), ('Machine', 'Machine'), ('(', '('), ('SVM', 'SVM'), (')', ')'), ('(', '('), ('Mona', 'Mona'), ('Diab', 'Diab'), ('etal.,2004', 'etal.,2004'), (')', ')'), ('[', '['), ('29', '29'), (']', ']'), ('approach', 'approach')]



========================================== PARAGRAPH 255 ===========================================

automatically tokenize, parts of speech tag and annotate base phrases in Arabic text.  

------------------- Sentence 1 -------------------

automatically tokenize, parts of speech tag and annotate base phrases in Arabic text.

>> Tokens are: 
 ['automatically', 'tokenize', ',', 'parts', 'speech', 'tag', 'annotate', 'base', 'phrases', 'Arabic', 'text', '.']

>> Bigrams are: 
 [('automatically', 'tokenize'), ('tokenize', ','), (',', 'parts'), ('parts', 'speech'), ('speech', 'tag'), ('tag', 'annotate'), ('annotate', 'base'), ('base', 'phrases'), ('phrases', 'Arabic'), ('Arabic', 'text'), ('text', '.')]

>> Trigrams are: 
 [('automatically', 'tokenize', ','), ('tokenize', ',', 'parts'), (',', 'parts', 'speech'), ('parts', 'speech', 'tag'), ('speech', 'tag', 'annotate'), ('tag', 'annotate', 'base'), ('annotate', 'base', 'phrases'), ('base', 'phrases', 'Arabic'), ('phrases', 'Arabic', 'text'), ('Arabic', 'text', '.')]

>> POS Tags are: 
 [('automatically', 'RB'), ('tokenize', 'VB'), (',', ','), ('parts', 'NNS'), ('speech', 'VBP'), ('tag', 'JJ'), ('annotate', 'NN'), ('base', 'NN'), ('phrases', 'VBZ'), ('Arabic', 'NNP'), ('text', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['parts', 'tag annotate base', 'Arabic text']

>> Named Entities are: 
 [('PERSON', 'Arabic')] 

>> Stemming using Porter Stemmer: 
 [('automatically', 'automat'), ('tokenize', 'token'), (',', ','), ('parts', 'part'), ('speech', 'speech'), ('tag', 'tag'), ('annotate', 'annot'), ('base', 'base'), ('phrases', 'phrase'), ('Arabic', 'arab'), ('text', 'text'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('automatically', 'automat'), ('tokenize', 'token'), (',', ','), ('parts', 'part'), ('speech', 'speech'), ('tag', 'tag'), ('annotate', 'annot'), ('base', 'base'), ('phrases', 'phrase'), ('Arabic', 'arab'), ('text', 'text'), ('.', '.')]

>> Lemmatization: 
 [('automatically', 'automatically'), ('tokenize', 'tokenize'), (',', ','), ('parts', 'part'), ('speech', 'speech'), ('tag', 'tag'), ('annotate', 'annotate'), ('base', 'base'), ('phrases', 'phrase'), ('Arabic', 'Arabic'), ('text', 'text'), ('.', '.')]



========================================== PARAGRAPH 256 ===========================================

  


========================================== PARAGRAPH 257 ===========================================

Chunking – it is also known as Shadow Parsing, it works by labelling segments of sentences  

------------------- Sentence 1 -------------------

Chunking – it is also known as Shadow Parsing, it works by labelling segments of sentences

>> Tokens are: 
 ['Chunking', '–', 'also', 'known', 'Shadow', 'Parsing', ',', 'works', 'labelling', 'segments', 'sentences']

>> Bigrams are: 
 [('Chunking', '–'), ('–', 'also'), ('also', 'known'), ('known', 'Shadow'), ('Shadow', 'Parsing'), ('Parsing', ','), (',', 'works'), ('works', 'labelling'), ('labelling', 'segments'), ('segments', 'sentences')]

>> Trigrams are: 
 [('Chunking', '–', 'also'), ('–', 'also', 'known'), ('also', 'known', 'Shadow'), ('known', 'Shadow', 'Parsing'), ('Shadow', 'Parsing', ','), ('Parsing', ',', 'works'), (',', 'works', 'labelling'), ('works', 'labelling', 'segments'), ('labelling', 'segments', 'sentences')]

>> POS Tags are: 
 [('Chunking', 'VBG'), ('–', 'NNP'), ('also', 'RB'), ('known', 'VBN'), ('Shadow', 'NNP'), ('Parsing', 'NNP'), (',', ','), ('works', 'VBZ'), ('labelling', 'VBG'), ('segments', 'NNS'), ('sentences', 'NNS')]

>> Noun Phrases are: 
 ['–', 'Shadow Parsing', 'segments sentences']

>> Named Entities are: 
 [('PERSON', 'Shadow Parsing')] 

>> Stemming using Porter Stemmer: 
 [('Chunking', 'chunk'), ('–', '–'), ('also', 'also'), ('known', 'known'), ('Shadow', 'shadow'), ('Parsing', 'pars'), (',', ','), ('works', 'work'), ('labelling', 'label'), ('segments', 'segment'), ('sentences', 'sentenc')]

>> Stemming using Snowball Stemmer: 
 [('Chunking', 'chunk'), ('–', '–'), ('also', 'also'), ('known', 'known'), ('Shadow', 'shadow'), ('Parsing', 'pars'), (',', ','), ('works', 'work'), ('labelling', 'label'), ('segments', 'segment'), ('sentences', 'sentenc')]

>> Lemmatization: 
 [('Chunking', 'Chunking'), ('–', '–'), ('also', 'also'), ('known', 'known'), ('Shadow', 'Shadow'), ('Parsing', 'Parsing'), (',', ','), ('works', 'work'), ('labelling', 'labelling'), ('segments', 'segment'), ('sentences', 'sentence')]



========================================== PARAGRAPH 258 ===========================================

with syntactic correlated keywords like Noun Phrase and Verb Phrase (NP or VP). Every  

------------------- Sentence 1 -------------------

with syntactic correlated keywords like Noun Phrase and Verb Phrase (NP or VP).

>> Tokens are: 
 ['syntactic', 'correlated', 'keywords', 'like', 'Noun', 'Phrase', 'Verb', 'Phrase', '(', 'NP', 'VP', ')', '.']

>> Bigrams are: 
 [('syntactic', 'correlated'), ('correlated', 'keywords'), ('keywords', 'like'), ('like', 'Noun'), ('Noun', 'Phrase'), ('Phrase', 'Verb'), ('Verb', 'Phrase'), ('Phrase', '('), ('(', 'NP'), ('NP', 'VP'), ('VP', ')'), (')', '.')]

>> Trigrams are: 
 [('syntactic', 'correlated', 'keywords'), ('correlated', 'keywords', 'like'), ('keywords', 'like', 'Noun'), ('like', 'Noun', 'Phrase'), ('Noun', 'Phrase', 'Verb'), ('Phrase', 'Verb', 'Phrase'), ('Verb', 'Phrase', '('), ('Phrase', '(', 'NP'), ('(', 'NP', 'VP'), ('NP', 'VP', ')'), ('VP', ')', '.')]

>> POS Tags are: 
 [('syntactic', 'JJ'), ('correlated', 'VBD'), ('keywords', 'NNS'), ('like', 'IN'), ('Noun', 'NNP'), ('Phrase', 'NNP'), ('Verb', 'NNP'), ('Phrase', 'NNP'), ('(', '('), ('NP', 'NNP'), ('VP', 'NNP'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['keywords', 'Noun Phrase Verb Phrase', 'NP VP']

>> Named Entities are: 
 [('PERSON', 'Noun Phrase Verb Phrase'), ('ORGANIZATION', 'NP')] 

>> Stemming using Porter Stemmer: 
 [('syntactic', 'syntact'), ('correlated', 'correl'), ('keywords', 'keyword'), ('like', 'like'), ('Noun', 'noun'), ('Phrase', 'phrase'), ('Verb', 'verb'), ('Phrase', 'phrase'), ('(', '('), ('NP', 'np'), ('VP', 'vp'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('syntactic', 'syntact'), ('correlated', 'correl'), ('keywords', 'keyword'), ('like', 'like'), ('Noun', 'noun'), ('Phrase', 'phrase'), ('Verb', 'verb'), ('Phrase', 'phrase'), ('(', '('), ('NP', 'np'), ('VP', 'vp'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('syntactic', 'syntactic'), ('correlated', 'correlated'), ('keywords', 'keywords'), ('like', 'like'), ('Noun', 'Noun'), ('Phrase', 'Phrase'), ('Verb', 'Verb'), ('Phrase', 'Phrase'), ('(', '('), ('NP', 'NP'), ('VP', 'VP'), (')', ')'), ('.', '.')]


------------------- Sentence 2 -------------------

Every

>> Tokens are: 
 ['Every']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Every', 'DT')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Every', 'everi')]

>> Stemming using Snowball Stemmer: 
 [('Every', 'everi')]

>> Lemmatization: 
 [('Every', 'Every')]



========================================== PARAGRAPH 259 ===========================================

word has a unique tag often marked as Begin Chunk (B-NP) tag or Inside Chunk (I-NP) tag.  

------------------- Sentence 1 -------------------

word has a unique tag often marked as Begin Chunk (B-NP) tag or Inside Chunk (I-NP) tag.

>> Tokens are: 
 ['word', 'unique', 'tag', 'often', 'marked', 'Begin', 'Chunk', '(', 'B-NP', ')', 'tag', 'Inside', 'Chunk', '(', 'I-NP', ')', 'tag', '.']

>> Bigrams are: 
 [('word', 'unique'), ('unique', 'tag'), ('tag', 'often'), ('often', 'marked'), ('marked', 'Begin'), ('Begin', 'Chunk'), ('Chunk', '('), ('(', 'B-NP'), ('B-NP', ')'), (')', 'tag'), ('tag', 'Inside'), ('Inside', 'Chunk'), ('Chunk', '('), ('(', 'I-NP'), ('I-NP', ')'), (')', 'tag'), ('tag', '.')]

>> Trigrams are: 
 [('word', 'unique', 'tag'), ('unique', 'tag', 'often'), ('tag', 'often', 'marked'), ('often', 'marked', 'Begin'), ('marked', 'Begin', 'Chunk'), ('Begin', 'Chunk', '('), ('Chunk', '(', 'B-NP'), ('(', 'B-NP', ')'), ('B-NP', ')', 'tag'), (')', 'tag', 'Inside'), ('tag', 'Inside', 'Chunk'), ('Inside', 'Chunk', '('), ('Chunk', '(', 'I-NP'), ('(', 'I-NP', ')'), ('I-NP', ')', 'tag'), (')', 'tag', '.')]

>> POS Tags are: 
 [('word', 'NN'), ('unique', 'NN'), ('tag', 'NN'), ('often', 'RB'), ('marked', 'VBD'), ('Begin', 'NNP'), ('Chunk', 'NNP'), ('(', '('), ('B-NP', 'NNP'), (')', ')'), ('tag', 'NN'), ('Inside', 'NNP'), ('Chunk', 'NNP'), ('(', '('), ('I-NP', 'NNP'), (')', ')'), ('tag', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['word unique tag', 'Begin Chunk', 'B-NP', 'tag Inside Chunk', 'I-NP', 'tag']

>> Named Entities are: 
 [('PERSON', 'Begin Chunk'), ('PERSON', 'Inside Chunk')] 

>> Stemming using Porter Stemmer: 
 [('word', 'word'), ('unique', 'uniqu'), ('tag', 'tag'), ('often', 'often'), ('marked', 'mark'), ('Begin', 'begin'), ('Chunk', 'chunk'), ('(', '('), ('B-NP', 'b-np'), (')', ')'), ('tag', 'tag'), ('Inside', 'insid'), ('Chunk', 'chunk'), ('(', '('), ('I-NP', 'i-np'), (')', ')'), ('tag', 'tag'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('word', 'word'), ('unique', 'uniqu'), ('tag', 'tag'), ('often', 'often'), ('marked', 'mark'), ('Begin', 'begin'), ('Chunk', 'chunk'), ('(', '('), ('B-NP', 'b-np'), (')', ')'), ('tag', 'tag'), ('Inside', 'insid'), ('Chunk', 'chunk'), ('(', '('), ('I-NP', 'i-np'), (')', ')'), ('tag', 'tag'), ('.', '.')]

>> Lemmatization: 
 [('word', 'word'), ('unique', 'unique'), ('tag', 'tag'), ('often', 'often'), ('marked', 'marked'), ('Begin', 'Begin'), ('Chunk', 'Chunk'), ('(', '('), ('B-NP', 'B-NP'), (')', ')'), ('tag', 'tag'), ('Inside', 'Inside'), ('Chunk', 'Chunk'), ('(', '('), ('I-NP', 'I-NP'), (')', ')'), ('tag', 'tag'), ('.', '.')]



========================================== PARAGRAPH 260 ===========================================

Chunking is often evaluated using the CoNLL 2000 shared task.  CoNLL 2000 provides test  

------------------- Sentence 1 -------------------

Chunking is often evaluated using the CoNLL 2000 shared task.

>> Tokens are: 
 ['Chunking', 'often', 'evaluated', 'using', 'CoNLL', '2000', 'shared', 'task', '.']

>> Bigrams are: 
 [('Chunking', 'often'), ('often', 'evaluated'), ('evaluated', 'using'), ('using', 'CoNLL'), ('CoNLL', '2000'), ('2000', 'shared'), ('shared', 'task'), ('task', '.')]

>> Trigrams are: 
 [('Chunking', 'often', 'evaluated'), ('often', 'evaluated', 'using'), ('evaluated', 'using', 'CoNLL'), ('using', 'CoNLL', '2000'), ('CoNLL', '2000', 'shared'), ('2000', 'shared', 'task'), ('shared', 'task', '.')]

>> POS Tags are: 
 [('Chunking', 'VBG'), ('often', 'RB'), ('evaluated', 'VBN'), ('using', 'VBG'), ('CoNLL', 'NNP'), ('2000', 'CD'), ('shared', 'VBD'), ('task', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['CoNLL', 'task']

>> Named Entities are: 
 [('ORGANIZATION', 'CoNLL')] 

>> Stemming using Porter Stemmer: 
 [('Chunking', 'chunk'), ('often', 'often'), ('evaluated', 'evalu'), ('using', 'use'), ('CoNLL', 'conll'), ('2000', '2000'), ('shared', 'share'), ('task', 'task'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Chunking', 'chunk'), ('often', 'often'), ('evaluated', 'evalu'), ('using', 'use'), ('CoNLL', 'conll'), ('2000', '2000'), ('shared', 'share'), ('task', 'task'), ('.', '.')]

>> Lemmatization: 
 [('Chunking', 'Chunking'), ('often', 'often'), ('evaluated', 'evaluated'), ('using', 'using'), ('CoNLL', 'CoNLL'), ('2000', '2000'), ('shared', 'shared'), ('task', 'task'), ('.', '.')]


------------------- Sentence 2 -------------------

CoNLL 2000 provides test

>> Tokens are: 
 ['CoNLL', '2000', 'provides', 'test']

>> Bigrams are: 
 [('CoNLL', '2000'), ('2000', 'provides'), ('provides', 'test')]

>> Trigrams are: 
 [('CoNLL', '2000', 'provides'), ('2000', 'provides', 'test')]

>> POS Tags are: 
 [('CoNLL', 'JJ'), ('2000', 'CD'), ('provides', 'VBZ'), ('test', 'NN')]

>> Noun Phrases are: 
 ['test']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('CoNLL', 'conll'), ('2000', '2000'), ('provides', 'provid'), ('test', 'test')]

>> Stemming using Snowball Stemmer: 
 [('CoNLL', 'conll'), ('2000', '2000'), ('provides', 'provid'), ('test', 'test')]

>> Lemmatization: 
 [('CoNLL', 'CoNLL'), ('2000', '2000'), ('provides', 'provides'), ('test', 'test')]



========================================== PARAGRAPH 261 ===========================================

data for Chunking. Since then, a certain number of systems arised (Sha and Pereira, 2003;  

------------------- Sentence 1 -------------------

data for Chunking.

>> Tokens are: 
 ['data', 'Chunking', '.']

>> Bigrams are: 
 [('data', 'Chunking'), ('Chunking', '.')]

>> Trigrams are: 
 [('data', 'Chunking', '.')]

>> POS Tags are: 
 [('data', 'NNS'), ('Chunking', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['data Chunking']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('data', 'data'), ('Chunking', 'chunk'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('data', 'data'), ('Chunking', 'chunk'), ('.', '.')]

>> Lemmatization: 
 [('data', 'data'), ('Chunking', 'Chunking'), ('.', '.')]


------------------- Sentence 2 -------------------

Since then, a certain number of systems arised (Sha and Pereira, 2003;

>> Tokens are: 
 ['Since', ',', 'certain', 'number', 'systems', 'arised', '(', 'Sha', 'Pereira', ',', '2003', ';']

>> Bigrams are: 
 [('Since', ','), (',', 'certain'), ('certain', 'number'), ('number', 'systems'), ('systems', 'arised'), ('arised', '('), ('(', 'Sha'), ('Sha', 'Pereira'), ('Pereira', ','), (',', '2003'), ('2003', ';')]

>> Trigrams are: 
 [('Since', ',', 'certain'), (',', 'certain', 'number'), ('certain', 'number', 'systems'), ('number', 'systems', 'arised'), ('systems', 'arised', '('), ('arised', '(', 'Sha'), ('(', 'Sha', 'Pereira'), ('Sha', 'Pereira', ','), ('Pereira', ',', '2003'), (',', '2003', ';')]

>> POS Tags are: 
 [('Since', 'IN'), (',', ','), ('certain', 'JJ'), ('number', 'NN'), ('systems', 'NNS'), ('arised', 'VBN'), ('(', '('), ('Sha', 'NNP'), ('Pereira', 'NNP'), (',', ','), ('2003', 'CD'), (';', ':')]

>> Noun Phrases are: 
 ['certain number systems', 'Sha Pereira']

>> Named Entities are: 
 [('PERSON', 'Sha Pereira')] 

>> Stemming using Porter Stemmer: 
 [('Since', 'sinc'), (',', ','), ('certain', 'certain'), ('number', 'number'), ('systems', 'system'), ('arised', 'aris'), ('(', '('), ('Sha', 'sha'), ('Pereira', 'pereira'), (',', ','), ('2003', '2003'), (';', ';')]

>> Stemming using Snowball Stemmer: 
 [('Since', 'sinc'), (',', ','), ('certain', 'certain'), ('number', 'number'), ('systems', 'system'), ('arised', 'aris'), ('(', '('), ('Sha', 'sha'), ('Pereira', 'pereira'), (',', ','), ('2003', '2003'), (';', ';')]

>> Lemmatization: 
 [('Since', 'Since'), (',', ','), ('certain', 'certain'), ('number', 'number'), ('systems', 'system'), ('arised', 'arised'), ('(', '('), ('Sha', 'Sha'), ('Pereira', 'Pereira'), (',', ','), ('2003', '2003'), (';', ';')]



========================================== PARAGRAPH 262 ===========================================

McDonald et al., 2005; Sun et al., 2008) [30] [31] [32], all reporting around 94.3% F1 score.  These systems use features composed of words, POS tags, and tags.  

------------------- Sentence 1 -------------------

McDonald et al., 2005; Sun et al., 2008) [30] [31] [32], all reporting around 94.3% F1 score.

>> Tokens are: 
 ['McDonald', 'et', 'al.', ',', '2005', ';', 'Sun', 'et', 'al.', ',', '2008', ')', '[', '30', ']', '[', '31', ']', '[', '32', ']', ',', 'reporting', 'around', '94.3', '%', 'F1', 'score', '.']

>> Bigrams are: 
 [('McDonald', 'et'), ('et', 'al.'), ('al.', ','), (',', '2005'), ('2005', ';'), (';', 'Sun'), ('Sun', 'et'), ('et', 'al.'), ('al.', ','), (',', '2008'), ('2008', ')'), (')', '['), ('[', '30'), ('30', ']'), (']', '['), ('[', '31'), ('31', ']'), (']', '['), ('[', '32'), ('32', ']'), (']', ','), (',', 'reporting'), ('reporting', 'around'), ('around', '94.3'), ('94.3', '%'), ('%', 'F1'), ('F1', 'score'), ('score', '.')]

>> Trigrams are: 
 [('McDonald', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2005'), (',', '2005', ';'), ('2005', ';', 'Sun'), (';', 'Sun', 'et'), ('Sun', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2008'), (',', '2008', ')'), ('2008', ')', '['), (')', '[', '30'), ('[', '30', ']'), ('30', ']', '['), (']', '[', '31'), ('[', '31', ']'), ('31', ']', '['), (']', '[', '32'), ('[', '32', ']'), ('32', ']', ','), (']', ',', 'reporting'), (',', 'reporting', 'around'), ('reporting', 'around', '94.3'), ('around', '94.3', '%'), ('94.3', '%', 'F1'), ('%', 'F1', 'score'), ('F1', 'score', '.')]

>> POS Tags are: 
 [('McDonald', 'NNP'), ('et', 'CC'), ('al.', 'NN'), (',', ','), ('2005', 'CD'), (';', ':'), ('Sun', 'NNP'), ('et', 'FW'), ('al.', 'NN'), (',', ','), ('2008', 'CD'), (')', ')'), ('[', 'VBD'), ('30', 'CD'), (']', 'NNP'), ('[', 'VBD'), ('31', 'CD'), (']', 'NNP'), ('[', 'VBD'), ('32', 'CD'), (']', 'NN'), (',', ','), ('reporting', 'VBG'), ('around', 'RB'), ('94.3', 'CD'), ('%', 'NN'), ('F1', 'NNP'), ('score', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['McDonald', 'al.', 'Sun', 'al.', ']', ']', ']', '% F1 score']

>> Named Entities are: 
 [('ORGANIZATION', 'McDonald')] 

>> Stemming using Porter Stemmer: 
 [('McDonald', 'mcdonald'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2005', '2005'), (';', ';'), ('Sun', 'sun'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2008', '2008'), (')', ')'), ('[', '['), ('30', '30'), (']', ']'), ('[', '['), ('31', '31'), (']', ']'), ('[', '['), ('32', '32'), (']', ']'), (',', ','), ('reporting', 'report'), ('around', 'around'), ('94.3', '94.3'), ('%', '%'), ('F1', 'f1'), ('score', 'score'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('McDonald', 'mcdonald'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2005', '2005'), (';', ';'), ('Sun', 'sun'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2008', '2008'), (')', ')'), ('[', '['), ('30', '30'), (']', ']'), ('[', '['), ('31', '31'), (']', ']'), ('[', '['), ('32', '32'), (']', ']'), (',', ','), ('reporting', 'report'), ('around', 'around'), ('94.3', '94.3'), ('%', '%'), ('F1', 'f1'), ('score', 'score'), ('.', '.')]

>> Lemmatization: 
 [('McDonald', 'McDonald'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2005', '2005'), (';', ';'), ('Sun', 'Sun'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2008', '2008'), (')', ')'), ('[', '['), ('30', '30'), (']', ']'), ('[', '['), ('31', '31'), (']', ']'), ('[', '['), ('32', '32'), (']', ']'), (',', ','), ('reporting', 'reporting'), ('around', 'around'), ('94.3', '94.3'), ('%', '%'), ('F1', 'F1'), ('score', 'score'), ('.', '.')]


------------------- Sentence 2 -------------------

These systems use features composed of words, POS tags, and tags.

>> Tokens are: 
 ['These', 'systems', 'use', 'features', 'composed', 'words', ',', 'POS', 'tags', ',', 'tags', '.']

>> Bigrams are: 
 [('These', 'systems'), ('systems', 'use'), ('use', 'features'), ('features', 'composed'), ('composed', 'words'), ('words', ','), (',', 'POS'), ('POS', 'tags'), ('tags', ','), (',', 'tags'), ('tags', '.')]

>> Trigrams are: 
 [('These', 'systems', 'use'), ('systems', 'use', 'features'), ('use', 'features', 'composed'), ('features', 'composed', 'words'), ('composed', 'words', ','), ('words', ',', 'POS'), (',', 'POS', 'tags'), ('POS', 'tags', ','), ('tags', ',', 'tags'), (',', 'tags', '.')]

>> POS Tags are: 
 [('These', 'DT'), ('systems', 'NNS'), ('use', 'VBP'), ('features', 'NNS'), ('composed', 'VBD'), ('words', 'NNS'), (',', ','), ('POS', 'NNP'), ('tags', 'NN'), (',', ','), ('tags', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['These systems', 'features', 'words', 'POS tags', 'tags']

>> Named Entities are: 
 [('ORGANIZATION', 'POS')] 

>> Stemming using Porter Stemmer: 
 [('These', 'these'), ('systems', 'system'), ('use', 'use'), ('features', 'featur'), ('composed', 'compos'), ('words', 'word'), (',', ','), ('POS', 'po'), ('tags', 'tag'), (',', ','), ('tags', 'tag'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('These', 'these'), ('systems', 'system'), ('use', 'use'), ('features', 'featur'), ('composed', 'compos'), ('words', 'word'), (',', ','), ('POS', 'pos'), ('tags', 'tag'), (',', ','), ('tags', 'tag'), ('.', '.')]

>> Lemmatization: 
 [('These', 'These'), ('systems', 'system'), ('use', 'use'), ('features', 'feature'), ('composed', 'composed'), ('words', 'word'), (',', ','), ('POS', 'POS'), ('tags', 'tag'), (',', ','), ('tags', 'tag'), ('.', '.')]



========================================== PARAGRAPH 263 ===========================================

  


========================================== PARAGRAPH 264 ===========================================

Usage of Named Entity Recognition in places such as Internet is a problem as people don’t  

------------------- Sentence 1 -------------------

Usage of Named Entity Recognition in places such as Internet is a problem as people don’t

>> Tokens are: 
 ['Usage', 'Named', 'Entity', 'Recognition', 'places', 'Internet', 'problem', 'people', '’']

>> Bigrams are: 
 [('Usage', 'Named'), ('Named', 'Entity'), ('Entity', 'Recognition'), ('Recognition', 'places'), ('places', 'Internet'), ('Internet', 'problem'), ('problem', 'people'), ('people', '’')]

>> Trigrams are: 
 [('Usage', 'Named', 'Entity'), ('Named', 'Entity', 'Recognition'), ('Entity', 'Recognition', 'places'), ('Recognition', 'places', 'Internet'), ('places', 'Internet', 'problem'), ('Internet', 'problem', 'people'), ('problem', 'people', '’')]

>> POS Tags are: 
 [('Usage', 'NN'), ('Named', 'VBN'), ('Entity', 'NNP'), ('Recognition', 'NNP'), ('places', 'NNS'), ('Internet', 'NNP'), ('problem', 'NN'), ('people', 'NNS'), ('’', 'VBP')]

>> Noun Phrases are: 
 ['Usage', 'Entity Recognition places Internet problem people']

>> Named Entities are: 
 [('GPE', 'Usage'), ('PERSON', 'Named Entity')] 

>> Stemming using Porter Stemmer: 
 [('Usage', 'usag'), ('Named', 'name'), ('Entity', 'entiti'), ('Recognition', 'recognit'), ('places', 'place'), ('Internet', 'internet'), ('problem', 'problem'), ('people', 'peopl'), ('’', '’')]

>> Stemming using Snowball Stemmer: 
 [('Usage', 'usag'), ('Named', 'name'), ('Entity', 'entiti'), ('Recognition', 'recognit'), ('places', 'place'), ('Internet', 'internet'), ('problem', 'problem'), ('people', 'peopl'), ('’', '’')]

>> Lemmatization: 
 [('Usage', 'Usage'), ('Named', 'Named'), ('Entity', 'Entity'), ('Recognition', 'Recognition'), ('places', 'place'), ('Internet', 'Internet'), ('problem', 'problem'), ('people', 'people'), ('’', '’')]



========================================== PARAGRAPH 265 ===========================================

use traditional or standard English. This degrades the performance of standard natural  

------------------- Sentence 1 -------------------

use traditional or standard English.

>> Tokens are: 
 ['use', 'traditional', 'standard', 'English', '.']

>> Bigrams are: 
 [('use', 'traditional'), ('traditional', 'standard'), ('standard', 'English'), ('English', '.')]

>> Trigrams are: 
 [('use', 'traditional', 'standard'), ('traditional', 'standard', 'English'), ('standard', 'English', '.')]

>> POS Tags are: 
 [('use', 'IN'), ('traditional', 'JJ'), ('standard', 'NN'), ('English', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['traditional standard English']

>> Named Entities are: 
 [('GPE', 'English')] 

>> Stemming using Porter Stemmer: 
 [('use', 'use'), ('traditional', 'tradit'), ('standard', 'standard'), ('English', 'english'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('use', 'use'), ('traditional', 'tradit'), ('standard', 'standard'), ('English', 'english'), ('.', '.')]

>> Lemmatization: 
 [('use', 'use'), ('traditional', 'traditional'), ('standard', 'standard'), ('English', 'English'), ('.', '.')]


------------------- Sentence 2 -------------------

This degrades the performance of standard natural

>> Tokens are: 
 ['This', 'degrades', 'performance', 'standard', 'natural']

>> Bigrams are: 
 [('This', 'degrades'), ('degrades', 'performance'), ('performance', 'standard'), ('standard', 'natural')]

>> Trigrams are: 
 [('This', 'degrades', 'performance'), ('degrades', 'performance', 'standard'), ('performance', 'standard', 'natural')]

>> POS Tags are: 
 [('This', 'DT'), ('degrades', 'VBZ'), ('performance', 'NN'), ('standard', 'JJ'), ('natural', 'JJ')]

>> Noun Phrases are: 
 ['performance']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('This', 'thi'), ('degrades', 'degrad'), ('performance', 'perform'), ('standard', 'standard'), ('natural', 'natur')]

>> Stemming using Snowball Stemmer: 
 [('This', 'this'), ('degrades', 'degrad'), ('performance', 'perform'), ('standard', 'standard'), ('natural', 'natur')]

>> Lemmatization: 
 [('This', 'This'), ('degrades', 'degrades'), ('performance', 'performance'), ('standard', 'standard'), ('natural', 'natural')]



========================================== PARAGRAPH 266 ===========================================

language processing tools substantially. By annotating the phrases or tweets and building  

------------------- Sentence 1 -------------------

language processing tools substantially.

>> Tokens are: 
 ['language', 'processing', 'tools', 'substantially', '.']

>> Bigrams are: 
 [('language', 'processing'), ('processing', 'tools'), ('tools', 'substantially'), ('substantially', '.')]

>> Trigrams are: 
 [('language', 'processing', 'tools'), ('processing', 'tools', 'substantially'), ('tools', 'substantially', '.')]

>> POS Tags are: 
 [('language', 'NN'), ('processing', 'NN'), ('tools', 'NNS'), ('substantially', 'RB'), ('.', '.')]

>> Noun Phrases are: 
 ['language processing tools']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('language', 'languag'), ('processing', 'process'), ('tools', 'tool'), ('substantially', 'substanti'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('language', 'languag'), ('processing', 'process'), ('tools', 'tool'), ('substantially', 'substanti'), ('.', '.')]

>> Lemmatization: 
 [('language', 'language'), ('processing', 'processing'), ('tools', 'tool'), ('substantially', 'substantially'), ('.', '.')]


------------------- Sentence 2 -------------------

By annotating the phrases or tweets and building

>> Tokens are: 
 ['By', 'annotating', 'phrases', 'tweets', 'building']

>> Bigrams are: 
 [('By', 'annotating'), ('annotating', 'phrases'), ('phrases', 'tweets'), ('tweets', 'building')]

>> Trigrams are: 
 [('By', 'annotating', 'phrases'), ('annotating', 'phrases', 'tweets'), ('phrases', 'tweets', 'building')]

>> POS Tags are: 
 [('By', 'IN'), ('annotating', 'VBG'), ('phrases', 'NNS'), ('tweets', 'NNS'), ('building', 'VBG')]

>> Noun Phrases are: 
 ['phrases tweets']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('By', 'by'), ('annotating', 'annot'), ('phrases', 'phrase'), ('tweets', 'tweet'), ('building', 'build')]

>> Stemming using Snowball Stemmer: 
 [('By', 'by'), ('annotating', 'annot'), ('phrases', 'phrase'), ('tweets', 'tweet'), ('building', 'build')]

>> Lemmatization: 
 [('By', 'By'), ('annotating', 'annotating'), ('phrases', 'phrase'), ('tweets', 'tweet'), ('building', 'building')]



========================================== PARAGRAPH 267 ===========================================

tools trained on unlabelled, in domain and out domain data (Alan Ritter., 2011) [33]. It  

------------------- Sentence 1 -------------------

tools trained on unlabelled, in domain and out domain data (Alan Ritter., 2011) [33].

>> Tokens are: 
 ['tools', 'trained', 'unlabelled', ',', 'domain', 'domain', 'data', '(', 'Alan', 'Ritter.', ',', '2011', ')', '[', '33', ']', '.']

>> Bigrams are: 
 [('tools', 'trained'), ('trained', 'unlabelled'), ('unlabelled', ','), (',', 'domain'), ('domain', 'domain'), ('domain', 'data'), ('data', '('), ('(', 'Alan'), ('Alan', 'Ritter.'), ('Ritter.', ','), (',', '2011'), ('2011', ')'), (')', '['), ('[', '33'), ('33', ']'), (']', '.')]

>> Trigrams are: 
 [('tools', 'trained', 'unlabelled'), ('trained', 'unlabelled', ','), ('unlabelled', ',', 'domain'), (',', 'domain', 'domain'), ('domain', 'domain', 'data'), ('domain', 'data', '('), ('data', '(', 'Alan'), ('(', 'Alan', 'Ritter.'), ('Alan', 'Ritter.', ','), ('Ritter.', ',', '2011'), (',', '2011', ')'), ('2011', ')', '['), (')', '[', '33'), ('[', '33', ']'), ('33', ']', '.')]

>> POS Tags are: 
 [('tools', 'NNS'), ('trained', 'VBD'), ('unlabelled', 'JJ'), (',', ','), ('domain', 'VBP'), ('domain', 'NN'), ('data', 'NNS'), ('(', '('), ('Alan', 'NNP'), ('Ritter.', 'NNP'), (',', ','), ('2011', 'CD'), (')', ')'), ('[', 'VBD'), ('33', 'CD'), (']', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['tools', 'domain data', 'Alan Ritter.', ']']

>> Named Entities are: 
 [('PERSON', 'Alan Ritter.')] 

>> Stemming using Porter Stemmer: 
 [('tools', 'tool'), ('trained', 'train'), ('unlabelled', 'unlabel'), (',', ','), ('domain', 'domain'), ('domain', 'domain'), ('data', 'data'), ('(', '('), ('Alan', 'alan'), ('Ritter.', 'ritter.'), (',', ','), ('2011', '2011'), (')', ')'), ('[', '['), ('33', '33'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('tools', 'tool'), ('trained', 'train'), ('unlabelled', 'unlabel'), (',', ','), ('domain', 'domain'), ('domain', 'domain'), ('data', 'data'), ('(', '('), ('Alan', 'alan'), ('Ritter.', 'ritter.'), (',', ','), ('2011', '2011'), (')', ')'), ('[', '['), ('33', '33'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('tools', 'tool'), ('trained', 'trained'), ('unlabelled', 'unlabelled'), (',', ','), ('domain', 'domain'), ('domain', 'domain'), ('data', 'data'), ('(', '('), ('Alan', 'Alan'), ('Ritter.', 'Ritter.'), (',', ','), ('2011', '2011'), (')', ')'), ('[', '['), ('33', '33'), (']', ']'), ('.', '.')]


------------------- Sentence 2 -------------------

It

>> Tokens are: 
 ['It']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('It', 'PRP')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('It', 'it')]

>> Stemming using Snowball Stemmer: 
 [('It', 'it')]

>> Lemmatization: 
 [('It', 'It')]



========================================== PARAGRAPH 268 ===========================================

improves the performance as compared to standard natural language processing tools.  

------------------- Sentence 1 -------------------

improves the performance as compared to standard natural language processing tools.

>> Tokens are: 
 ['improves', 'performance', 'compared', 'standard', 'natural', 'language', 'processing', 'tools', '.']

>> Bigrams are: 
 [('improves', 'performance'), ('performance', 'compared'), ('compared', 'standard'), ('standard', 'natural'), ('natural', 'language'), ('language', 'processing'), ('processing', 'tools'), ('tools', '.')]

>> Trigrams are: 
 [('improves', 'performance', 'compared'), ('performance', 'compared', 'standard'), ('compared', 'standard', 'natural'), ('standard', 'natural', 'language'), ('natural', 'language', 'processing'), ('language', 'processing', 'tools'), ('processing', 'tools', '.')]

>> POS Tags are: 
 [('improves', 'NNS'), ('performance', 'NN'), ('compared', 'VBN'), ('standard', 'JJ'), ('natural', 'JJ'), ('language', 'NN'), ('processing', 'NN'), ('tools', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['improves performance', 'standard natural language processing tools']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('improves', 'improv'), ('performance', 'perform'), ('compared', 'compar'), ('standard', 'standard'), ('natural', 'natur'), ('language', 'languag'), ('processing', 'process'), ('tools', 'tool'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('improves', 'improv'), ('performance', 'perform'), ('compared', 'compar'), ('standard', 'standard'), ('natural', 'natur'), ('language', 'languag'), ('processing', 'process'), ('tools', 'tool'), ('.', '.')]

>> Lemmatization: 
 [('improves', 'improves'), ('performance', 'performance'), ('compared', 'compared'), ('standard', 'standard'), ('natural', 'natural'), ('language', 'language'), ('processing', 'processing'), ('tools', 'tool'), ('.', '.')]



========================================== PARAGRAPH 269 ===========================================

  


========================================== PARAGRAPH 270 ===========================================

Emotion Detection (Shashank Sharma, 2016) [34] is similar to sentiment analysis, but it  

------------------- Sentence 1 -------------------

Emotion Detection (Shashank Sharma, 2016) [34] is similar to sentiment analysis, but it

>> Tokens are: 
 ['Emotion', 'Detection', '(', 'Shashank', 'Sharma', ',', '2016', ')', '[', '34', ']', 'similar', 'sentiment', 'analysis', ',']

>> Bigrams are: 
 [('Emotion', 'Detection'), ('Detection', '('), ('(', 'Shashank'), ('Shashank', 'Sharma'), ('Sharma', ','), (',', '2016'), ('2016', ')'), (')', '['), ('[', '34'), ('34', ']'), (']', 'similar'), ('similar', 'sentiment'), ('sentiment', 'analysis'), ('analysis', ',')]

>> Trigrams are: 
 [('Emotion', 'Detection', '('), ('Detection', '(', 'Shashank'), ('(', 'Shashank', 'Sharma'), ('Shashank', 'Sharma', ','), ('Sharma', ',', '2016'), (',', '2016', ')'), ('2016', ')', '['), (')', '[', '34'), ('[', '34', ']'), ('34', ']', 'similar'), (']', 'similar', 'sentiment'), ('similar', 'sentiment', 'analysis'), ('sentiment', 'analysis', ',')]

>> POS Tags are: 
 [('Emotion', 'NN'), ('Detection', 'NNP'), ('(', '('), ('Shashank', 'NNP'), ('Sharma', 'NNP'), (',', ','), ('2016', 'CD'), (')', ')'), ('[', 'VBD'), ('34', 'CD'), (']', 'NNP'), ('similar', 'JJ'), ('sentiment', 'NN'), ('analysis', 'NN'), (',', ',')]

>> Noun Phrases are: 
 ['Emotion Detection', 'Shashank Sharma', ']', 'similar sentiment analysis']

>> Named Entities are: 
 [('PERSON', 'Emotion Detection'), ('ORGANIZATION', 'Shashank Sharma')] 

>> Stemming using Porter Stemmer: 
 [('Emotion', 'emot'), ('Detection', 'detect'), ('(', '('), ('Shashank', 'shashank'), ('Sharma', 'sharma'), (',', ','), ('2016', '2016'), (')', ')'), ('[', '['), ('34', '34'), (']', ']'), ('similar', 'similar'), ('sentiment', 'sentiment'), ('analysis', 'analysi'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('Emotion', 'emot'), ('Detection', 'detect'), ('(', '('), ('Shashank', 'shashank'), ('Sharma', 'sharma'), (',', ','), ('2016', '2016'), (')', ')'), ('[', '['), ('34', '34'), (']', ']'), ('similar', 'similar'), ('sentiment', 'sentiment'), ('analysis', 'analysi'), (',', ',')]

>> Lemmatization: 
 [('Emotion', 'Emotion'), ('Detection', 'Detection'), ('(', '('), ('Shashank', 'Shashank'), ('Sharma', 'Sharma'), (',', ','), ('2016', '2016'), (')', ')'), ('[', '['), ('34', '34'), (']', ']'), ('similar', 'similar'), ('sentiment', 'sentiment'), ('analysis', 'analysis'), (',', ',')]



========================================== PARAGRAPH 271 ===========================================

works on social media platforms on mixing of two languages (English + Any other Indian  

------------------- Sentence 1 -------------------

works on social media platforms on mixing of two languages (English + Any other Indian

>> Tokens are: 
 ['works', 'social', 'media', 'platforms', 'mixing', 'two', 'languages', '(', 'English', '+', 'Any', 'Indian']

>> Bigrams are: 
 [('works', 'social'), ('social', 'media'), ('media', 'platforms'), ('platforms', 'mixing'), ('mixing', 'two'), ('two', 'languages'), ('languages', '('), ('(', 'English'), ('English', '+'), ('+', 'Any'), ('Any', 'Indian')]

>> Trigrams are: 
 [('works', 'social', 'media'), ('social', 'media', 'platforms'), ('media', 'platforms', 'mixing'), ('platforms', 'mixing', 'two'), ('mixing', 'two', 'languages'), ('two', 'languages', '('), ('languages', '(', 'English'), ('(', 'English', '+'), ('English', '+', 'Any'), ('+', 'Any', 'Indian')]

>> POS Tags are: 
 [('works', 'NNS'), ('social', 'JJ'), ('media', 'NNS'), ('platforms', 'NNS'), ('mixing', 'VBG'), ('two', 'CD'), ('languages', 'NNS'), ('(', '('), ('English', 'JJ'), ('+', 'NNP'), ('Any', 'NNP'), ('Indian', 'JJ')]

>> Noun Phrases are: 
 ['works', 'social media platforms', 'languages', 'English + Any']

>> Named Entities are: 
 [('ORGANIZATION', 'English')] 

>> Stemming using Porter Stemmer: 
 [('works', 'work'), ('social', 'social'), ('media', 'media'), ('platforms', 'platform'), ('mixing', 'mix'), ('two', 'two'), ('languages', 'languag'), ('(', '('), ('English', 'english'), ('+', '+'), ('Any', 'ani'), ('Indian', 'indian')]

>> Stemming using Snowball Stemmer: 
 [('works', 'work'), ('social', 'social'), ('media', 'media'), ('platforms', 'platform'), ('mixing', 'mix'), ('two', 'two'), ('languages', 'languag'), ('(', '('), ('English', 'english'), ('+', '+'), ('Any', 'ani'), ('Indian', 'indian')]

>> Lemmatization: 
 [('works', 'work'), ('social', 'social'), ('media', 'medium'), ('platforms', 'platform'), ('mixing', 'mixing'), ('two', 'two'), ('languages', 'language'), ('(', '('), ('English', 'English'), ('+', '+'), ('Any', 'Any'), ('Indian', 'Indian')]



========================================== PARAGRAPH 272 ===========================================

Language). It categorizes statements into six groups based on emotions. During this process,  

------------------- Sentence 1 -------------------

Language).

>> Tokens are: 
 ['Language', ')', '.']

>> Bigrams are: 
 [('Language', ')'), (')', '.')]

>> Trigrams are: 
 [('Language', ')', '.')]

>> POS Tags are: 
 [('Language', 'NN'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['Language']

>> Named Entities are: 
 [('GPE', 'Language')] 

>> Stemming using Porter Stemmer: 
 [('Language', 'languag'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Language', 'languag'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Language', 'Language'), (')', ')'), ('.', '.')]


------------------- Sentence 2 -------------------

It categorizes statements into six groups based on emotions.

>> Tokens are: 
 ['It', 'categorizes', 'statements', 'six', 'groups', 'based', 'emotions', '.']

>> Bigrams are: 
 [('It', 'categorizes'), ('categorizes', 'statements'), ('statements', 'six'), ('six', 'groups'), ('groups', 'based'), ('based', 'emotions'), ('emotions', '.')]

>> Trigrams are: 
 [('It', 'categorizes', 'statements'), ('categorizes', 'statements', 'six'), ('statements', 'six', 'groups'), ('six', 'groups', 'based'), ('groups', 'based', 'emotions'), ('based', 'emotions', '.')]

>> POS Tags are: 
 [('It', 'PRP'), ('categorizes', 'VBZ'), ('statements', 'NNS'), ('six', 'CD'), ('groups', 'NNS'), ('based', 'VBN'), ('emotions', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['statements', 'groups', 'emotions']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('It', 'it'), ('categorizes', 'categor'), ('statements', 'statement'), ('six', 'six'), ('groups', 'group'), ('based', 'base'), ('emotions', 'emot'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('It', 'it'), ('categorizes', 'categor'), ('statements', 'statement'), ('six', 'six'), ('groups', 'group'), ('based', 'base'), ('emotions', 'emot'), ('.', '.')]

>> Lemmatization: 
 [('It', 'It'), ('categorizes', 'categorizes'), ('statements', 'statement'), ('six', 'six'), ('groups', 'group'), ('based', 'based'), ('emotions', 'emotion'), ('.', '.')]


------------------- Sentence 3 -------------------

During this process,

>> Tokens are: 
 ['During', 'process', ',']

>> Bigrams are: 
 [('During', 'process'), ('process', ',')]

>> Trigrams are: 
 [('During', 'process', ',')]

>> POS Tags are: 
 [('During', 'IN'), ('process', 'NN'), (',', ',')]

>> Noun Phrases are: 
 ['process']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('During', 'dure'), ('process', 'process'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('During', 'dure'), ('process', 'process'), (',', ',')]

>> Lemmatization: 
 [('During', 'During'), ('process', 'process'), (',', ',')]



========================================== PARAGRAPH 273 ===========================================

they were able to identify the language of ambiguous words which were common in Hindi  

------------------- Sentence 1 -------------------

they were able to identify the language of ambiguous words which were common in Hindi

>> Tokens are: 
 ['able', 'identify', 'language', 'ambiguous', 'words', 'common', 'Hindi']

>> Bigrams are: 
 [('able', 'identify'), ('identify', 'language'), ('language', 'ambiguous'), ('ambiguous', 'words'), ('words', 'common'), ('common', 'Hindi')]

>> Trigrams are: 
 [('able', 'identify', 'language'), ('identify', 'language', 'ambiguous'), ('language', 'ambiguous', 'words'), ('ambiguous', 'words', 'common'), ('words', 'common', 'Hindi')]

>> POS Tags are: 
 [('able', 'JJ'), ('identify', 'JJ'), ('language', 'NN'), ('ambiguous', 'JJ'), ('words', 'NNS'), ('common', 'JJ'), ('Hindi', 'NNP')]

>> Noun Phrases are: 
 ['able identify language', 'ambiguous words', 'common Hindi']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('able', 'abl'), ('identify', 'identifi'), ('language', 'languag'), ('ambiguous', 'ambigu'), ('words', 'word'), ('common', 'common'), ('Hindi', 'hindi')]

>> Stemming using Snowball Stemmer: 
 [('able', 'abl'), ('identify', 'identifi'), ('language', 'languag'), ('ambiguous', 'ambigu'), ('words', 'word'), ('common', 'common'), ('Hindi', 'hindi')]

>> Lemmatization: 
 [('able', 'able'), ('identify', 'identify'), ('language', 'language'), ('ambiguous', 'ambiguous'), ('words', 'word'), ('common', 'common'), ('Hindi', 'Hindi')]



========================================== PARAGRAPH 274 ===========================================

and English and tag lexical category or parts of speech in mixed script by identifying the base  

------------------- Sentence 1 -------------------

and English and tag lexical category or parts of speech in mixed script by identifying the base

>> Tokens are: 
 ['English', 'tag', 'lexical', 'category', 'parts', 'speech', 'mixed', 'script', 'identifying', 'base']

>> Bigrams are: 
 [('English', 'tag'), ('tag', 'lexical'), ('lexical', 'category'), ('category', 'parts'), ('parts', 'speech'), ('speech', 'mixed'), ('mixed', 'script'), ('script', 'identifying'), ('identifying', 'base')]

>> Trigrams are: 
 [('English', 'tag', 'lexical'), ('tag', 'lexical', 'category'), ('lexical', 'category', 'parts'), ('category', 'parts', 'speech'), ('parts', 'speech', 'mixed'), ('speech', 'mixed', 'script'), ('mixed', 'script', 'identifying'), ('script', 'identifying', 'base')]

>> POS Tags are: 
 [('English', 'JJ'), ('tag', 'NN'), ('lexical', 'JJ'), ('category', 'NN'), ('parts', 'NNS'), ('speech', 'VBD'), ('mixed', 'JJ'), ('script', 'NN'), ('identifying', 'VBG'), ('base', 'NN')]

>> Noun Phrases are: 
 ['English tag', 'lexical category parts', 'mixed script', 'base']

>> Named Entities are: 
 [('GPE', 'English')] 

>> Stemming using Porter Stemmer: 
 [('English', 'english'), ('tag', 'tag'), ('lexical', 'lexic'), ('category', 'categori'), ('parts', 'part'), ('speech', 'speech'), ('mixed', 'mix'), ('script', 'script'), ('identifying', 'identifi'), ('base', 'base')]

>> Stemming using Snowball Stemmer: 
 [('English', 'english'), ('tag', 'tag'), ('lexical', 'lexic'), ('category', 'categori'), ('parts', 'part'), ('speech', 'speech'), ('mixed', 'mix'), ('script', 'script'), ('identifying', 'identifi'), ('base', 'base')]

>> Lemmatization: 
 [('English', 'English'), ('tag', 'tag'), ('lexical', 'lexical'), ('category', 'category'), ('parts', 'part'), ('speech', 'speech'), ('mixed', 'mixed'), ('script', 'script'), ('identifying', 'identifying'), ('base', 'base')]



========================================== PARAGRAPH 275 ===========================================

language of the speaker.  

------------------- Sentence 1 -------------------

language of the speaker.

>> Tokens are: 
 ['language', 'speaker', '.']

>> Bigrams are: 
 [('language', 'speaker'), ('speaker', '.')]

>> Trigrams are: 
 [('language', 'speaker', '.')]

>> POS Tags are: 
 [('language', 'NN'), ('speaker', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['language speaker']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('language', 'languag'), ('speaker', 'speaker'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('language', 'languag'), ('speaker', 'speaker'), ('.', '.')]

>> Lemmatization: 
 [('language', 'language'), ('speaker', 'speaker'), ('.', '.')]



========================================== PARAGRAPH 276 ===========================================

 


========================================== PARAGRAPH 277 ===========================================

Sematic Role Labelling – SRL works by giving a semantic role to a sentence. For example in  

------------------- Sentence 1 -------------------

Sematic Role Labelling – SRL works by giving a semantic role to a sentence.

>> Tokens are: 
 ['Sematic', 'Role', 'Labelling', '–', 'SRL', 'works', 'giving', 'semantic', 'role', 'sentence', '.']

>> Bigrams are: 
 [('Sematic', 'Role'), ('Role', 'Labelling'), ('Labelling', '–'), ('–', 'SRL'), ('SRL', 'works'), ('works', 'giving'), ('giving', 'semantic'), ('semantic', 'role'), ('role', 'sentence'), ('sentence', '.')]

>> Trigrams are: 
 [('Sematic', 'Role', 'Labelling'), ('Role', 'Labelling', '–'), ('Labelling', '–', 'SRL'), ('–', 'SRL', 'works'), ('SRL', 'works', 'giving'), ('works', 'giving', 'semantic'), ('giving', 'semantic', 'role'), ('semantic', 'role', 'sentence'), ('role', 'sentence', '.')]

>> POS Tags are: 
 [('Sematic', 'JJ'), ('Role', 'NNP'), ('Labelling', 'NNP'), ('–', 'NNP'), ('SRL', 'NNP'), ('works', 'VBZ'), ('giving', 'VBG'), ('semantic', 'JJ'), ('role', 'NN'), ('sentence', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Sematic Role Labelling – SRL', 'semantic role sentence']

>> Named Entities are: 
 [('PERSON', 'Sematic'), ('ORGANIZATION', 'Role')] 

>> Stemming using Porter Stemmer: 
 [('Sematic', 'semat'), ('Role', 'role'), ('Labelling', 'label'), ('–', '–'), ('SRL', 'srl'), ('works', 'work'), ('giving', 'give'), ('semantic', 'semant'), ('role', 'role'), ('sentence', 'sentenc'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Sematic', 'semat'), ('Role', 'role'), ('Labelling', 'label'), ('–', '–'), ('SRL', 'srl'), ('works', 'work'), ('giving', 'give'), ('semantic', 'semant'), ('role', 'role'), ('sentence', 'sentenc'), ('.', '.')]

>> Lemmatization: 
 [('Sematic', 'Sematic'), ('Role', 'Role'), ('Labelling', 'Labelling'), ('–', '–'), ('SRL', 'SRL'), ('works', 'work'), ('giving', 'giving'), ('semantic', 'semantic'), ('role', 'role'), ('sentence', 'sentence'), ('.', '.')]


------------------- Sentence 2 -------------------

For example in

>> Tokens are: 
 ['For', 'example']

>> Bigrams are: 
 [('For', 'example')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('For', 'IN'), ('example', 'NN')]

>> Noun Phrases are: 
 ['example']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('For', 'for'), ('example', 'exampl')]

>> Stemming using Snowball Stemmer: 
 [('For', 'for'), ('example', 'exampl')]

>> Lemmatization: 
 [('For', 'For'), ('example', 'example')]



========================================== PARAGRAPH 278 ===========================================

the PropBank (Palmer et al., 2005) [35] formalism, one assigns roles to words that are  

------------------- Sentence 1 -------------------

the PropBank (Palmer et al., 2005) [35] formalism, one assigns roles to words that are

>> Tokens are: 
 ['PropBank', '(', 'Palmer', 'et', 'al.', ',', '2005', ')', '[', '35', ']', 'formalism', ',', 'one', 'assigns', 'roles', 'words']

>> Bigrams are: 
 [('PropBank', '('), ('(', 'Palmer'), ('Palmer', 'et'), ('et', 'al.'), ('al.', ','), (',', '2005'), ('2005', ')'), (')', '['), ('[', '35'), ('35', ']'), (']', 'formalism'), ('formalism', ','), (',', 'one'), ('one', 'assigns'), ('assigns', 'roles'), ('roles', 'words')]

>> Trigrams are: 
 [('PropBank', '(', 'Palmer'), ('(', 'Palmer', 'et'), ('Palmer', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2005'), (',', '2005', ')'), ('2005', ')', '['), (')', '[', '35'), ('[', '35', ']'), ('35', ']', 'formalism'), (']', 'formalism', ','), ('formalism', ',', 'one'), (',', 'one', 'assigns'), ('one', 'assigns', 'roles'), ('assigns', 'roles', 'words')]

>> POS Tags are: 
 [('PropBank', 'NNP'), ('(', '('), ('Palmer', 'NNP'), ('et', 'FW'), ('al.', 'NN'), (',', ','), ('2005', 'CD'), (')', ')'), ('[', 'VBD'), ('35', 'CD'), (']', 'JJ'), ('formalism', 'NN'), (',', ','), ('one', 'CD'), ('assigns', 'NN'), ('roles', 'VBZ'), ('words', 'NNS')]

>> Noun Phrases are: 
 ['PropBank', 'Palmer', 'al.', '] formalism', 'assigns', 'words']

>> Named Entities are: 
 [('GPE', 'PropBank'), ('ORGANIZATION', 'Palmer')] 

>> Stemming using Porter Stemmer: 
 [('PropBank', 'propbank'), ('(', '('), ('Palmer', 'palmer'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2005', '2005'), (')', ')'), ('[', '['), ('35', '35'), (']', ']'), ('formalism', 'formal'), (',', ','), ('one', 'one'), ('assigns', 'assign'), ('roles', 'role'), ('words', 'word')]

>> Stemming using Snowball Stemmer: 
 [('PropBank', 'propbank'), ('(', '('), ('Palmer', 'palmer'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2005', '2005'), (')', ')'), ('[', '['), ('35', '35'), (']', ']'), ('formalism', 'formal'), (',', ','), ('one', 'one'), ('assigns', 'assign'), ('roles', 'role'), ('words', 'word')]

>> Lemmatization: 
 [('PropBank', 'PropBank'), ('(', '('), ('Palmer', 'Palmer'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2005', '2005'), (')', ')'), ('[', '['), ('35', '35'), (']', ']'), ('formalism', 'formalism'), (',', ','), ('one', 'one'), ('assigns', 'assigns'), ('roles', 'role'), ('words', 'word')]



========================================== PARAGRAPH 279 ===========================================

arguments of a verb in the sentence. The precise arguments depend on verb frame and if there  

------------------- Sentence 1 -------------------

arguments of a verb in the sentence.

>> Tokens are: 
 ['arguments', 'verb', 'sentence', '.']

>> Bigrams are: 
 [('arguments', 'verb'), ('verb', 'sentence'), ('sentence', '.')]

>> Trigrams are: 
 [('arguments', 'verb', 'sentence'), ('verb', 'sentence', '.')]

>> POS Tags are: 
 [('arguments', 'NNS'), ('verb', 'JJ'), ('sentence', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['arguments', 'verb sentence']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('arguments', 'argument'), ('verb', 'verb'), ('sentence', 'sentenc'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('arguments', 'argument'), ('verb', 'verb'), ('sentence', 'sentenc'), ('.', '.')]

>> Lemmatization: 
 [('arguments', 'argument'), ('verb', 'verb'), ('sentence', 'sentence'), ('.', '.')]


------------------- Sentence 2 -------------------

The precise arguments depend on verb frame and if there

>> Tokens are: 
 ['The', 'precise', 'arguments', 'depend', 'verb', 'frame']

>> Bigrams are: 
 [('The', 'precise'), ('precise', 'arguments'), ('arguments', 'depend'), ('depend', 'verb'), ('verb', 'frame')]

>> Trigrams are: 
 [('The', 'precise', 'arguments'), ('precise', 'arguments', 'depend'), ('arguments', 'depend', 'verb'), ('depend', 'verb', 'frame')]

>> POS Tags are: 
 [('The', 'DT'), ('precise', 'JJ'), ('arguments', 'NNS'), ('depend', 'VBP'), ('verb', 'NN'), ('frame', 'NN')]

>> Noun Phrases are: 
 ['The precise arguments', 'verb frame']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('precise', 'precis'), ('arguments', 'argument'), ('depend', 'depend'), ('verb', 'verb'), ('frame', 'frame')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('precise', 'precis'), ('arguments', 'argument'), ('depend', 'depend'), ('verb', 'verb'), ('frame', 'frame')]

>> Lemmatization: 
 [('The', 'The'), ('precise', 'precise'), ('arguments', 'argument'), ('depend', 'depend'), ('verb', 'verb'), ('frame', 'frame')]



========================================== PARAGRAPH 280 ===========================================

exists multiple verbs  in a sentence, it might have multiple tags. State-of-the-art SRL systems  

------------------- Sentence 1 -------------------

exists multiple verbs  in a sentence, it might have multiple tags.

>> Tokens are: 
 ['exists', 'multiple', 'verbs', 'sentence', ',', 'might', 'multiple', 'tags', '.']

>> Bigrams are: 
 [('exists', 'multiple'), ('multiple', 'verbs'), ('verbs', 'sentence'), ('sentence', ','), (',', 'might'), ('might', 'multiple'), ('multiple', 'tags'), ('tags', '.')]

>> Trigrams are: 
 [('exists', 'multiple', 'verbs'), ('multiple', 'verbs', 'sentence'), ('verbs', 'sentence', ','), ('sentence', ',', 'might'), (',', 'might', 'multiple'), ('might', 'multiple', 'tags'), ('multiple', 'tags', '.')]

>> POS Tags are: 
 [('exists', 'NNS'), ('multiple', 'VBP'), ('verbs', 'JJ'), ('sentence', 'NN'), (',', ','), ('might', 'MD'), ('multiple', 'VB'), ('tags', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['exists', 'verbs sentence', 'tags']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('exists', 'exist'), ('multiple', 'multipl'), ('verbs', 'verb'), ('sentence', 'sentenc'), (',', ','), ('might', 'might'), ('multiple', 'multipl'), ('tags', 'tag'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('exists', 'exist'), ('multiple', 'multipl'), ('verbs', 'verb'), ('sentence', 'sentenc'), (',', ','), ('might', 'might'), ('multiple', 'multipl'), ('tags', 'tag'), ('.', '.')]

>> Lemmatization: 
 [('exists', 'exists'), ('multiple', 'multiple'), ('verbs', 'verb'), ('sentence', 'sentence'), (',', ','), ('might', 'might'), ('multiple', 'multiple'), ('tags', 'tag'), ('.', '.')]


------------------- Sentence 2 -------------------

State-of-the-art SRL systems

>> Tokens are: 
 ['State-of-the-art', 'SRL', 'systems']

>> Bigrams are: 
 [('State-of-the-art', 'SRL'), ('SRL', 'systems')]

>> Trigrams are: 
 [('State-of-the-art', 'SRL', 'systems')]

>> POS Tags are: 
 [('State-of-the-art', 'JJ'), ('SRL', 'NNP'), ('systems', 'NNS')]

>> Noun Phrases are: 
 ['State-of-the-art SRL systems']

>> Named Entities are: 
 [('ORGANIZATION', 'SRL')] 

>> Stemming using Porter Stemmer: 
 [('State-of-the-art', 'state-of-the-art'), ('SRL', 'srl'), ('systems', 'system')]

>> Stemming using Snowball Stemmer: 
 [('State-of-the-art', 'state-of-the-art'), ('SRL', 'srl'), ('systems', 'system')]

>> Lemmatization: 
 [('State-of-the-art', 'State-of-the-art'), ('SRL', 'SRL'), ('systems', 'system')]



========================================== PARAGRAPH 281 ===========================================

comprise of several stages: creating a parse tree, identifying which parse tree nodes represent  

------------------- Sentence 1 -------------------

comprise of several stages: creating a parse tree, identifying which parse tree nodes represent

>> Tokens are: 
 ['comprise', 'several', 'stages', ':', 'creating', 'parse', 'tree', ',', 'identifying', 'parse', 'tree', 'nodes', 'represent']

>> Bigrams are: 
 [('comprise', 'several'), ('several', 'stages'), ('stages', ':'), (':', 'creating'), ('creating', 'parse'), ('parse', 'tree'), ('tree', ','), (',', 'identifying'), ('identifying', 'parse'), ('parse', 'tree'), ('tree', 'nodes'), ('nodes', 'represent')]

>> Trigrams are: 
 [('comprise', 'several', 'stages'), ('several', 'stages', ':'), ('stages', ':', 'creating'), (':', 'creating', 'parse'), ('creating', 'parse', 'tree'), ('parse', 'tree', ','), ('tree', ',', 'identifying'), (',', 'identifying', 'parse'), ('identifying', 'parse', 'tree'), ('parse', 'tree', 'nodes'), ('tree', 'nodes', 'represent')]

>> POS Tags are: 
 [('comprise', 'VB'), ('several', 'JJ'), ('stages', 'NNS'), (':', ':'), ('creating', 'VBG'), ('parse', 'NN'), ('tree', 'NN'), (',', ','), ('identifying', 'VBG'), ('parse', 'NN'), ('tree', 'NN'), ('nodes', 'NNS'), ('represent', 'VBP')]

>> Noun Phrases are: 
 ['several stages', 'parse tree', 'parse tree nodes']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('comprise', 'compris'), ('several', 'sever'), ('stages', 'stage'), (':', ':'), ('creating', 'creat'), ('parse', 'pars'), ('tree', 'tree'), (',', ','), ('identifying', 'identifi'), ('parse', 'pars'), ('tree', 'tree'), ('nodes', 'node'), ('represent', 'repres')]

>> Stemming using Snowball Stemmer: 
 [('comprise', 'compris'), ('several', 'sever'), ('stages', 'stage'), (':', ':'), ('creating', 'creat'), ('parse', 'pars'), ('tree', 'tree'), (',', ','), ('identifying', 'identifi'), ('parse', 'pars'), ('tree', 'tree'), ('nodes', 'node'), ('represent', 'repres')]

>> Lemmatization: 
 [('comprise', 'comprise'), ('several', 'several'), ('stages', 'stage'), (':', ':'), ('creating', 'creating'), ('parse', 'parse'), ('tree', 'tree'), (',', ','), ('identifying', 'identifying'), ('parse', 'parse'), ('tree', 'tree'), ('nodes', 'node'), ('represent', 'represent')]



========================================== PARAGRAPH 282 ===========================================

the arguments of a given verb, and finally classifying these nodes to compute the  

------------------- Sentence 1 -------------------

the arguments of a given verb, and finally classifying these nodes to compute the

>> Tokens are: 
 ['arguments', 'given', 'verb', ',', 'finally', 'classifying', 'nodes', 'compute']

>> Bigrams are: 
 [('arguments', 'given'), ('given', 'verb'), ('verb', ','), (',', 'finally'), ('finally', 'classifying'), ('classifying', 'nodes'), ('nodes', 'compute')]

>> Trigrams are: 
 [('arguments', 'given', 'verb'), ('given', 'verb', ','), ('verb', ',', 'finally'), (',', 'finally', 'classifying'), ('finally', 'classifying', 'nodes'), ('classifying', 'nodes', 'compute')]

>> POS Tags are: 
 [('arguments', 'NNS'), ('given', 'VBN'), ('verb', 'NNS'), (',', ','), ('finally', 'RB'), ('classifying', 'VBG'), ('nodes', 'NNS'), ('compute', 'NN')]

>> Noun Phrases are: 
 ['arguments', 'verb', 'nodes compute']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('arguments', 'argument'), ('given', 'given'), ('verb', 'verb'), (',', ','), ('finally', 'final'), ('classifying', 'classifi'), ('nodes', 'node'), ('compute', 'comput')]

>> Stemming using Snowball Stemmer: 
 [('arguments', 'argument'), ('given', 'given'), ('verb', 'verb'), (',', ','), ('finally', 'final'), ('classifying', 'classifi'), ('nodes', 'node'), ('compute', 'comput')]

>> Lemmatization: 
 [('arguments', 'argument'), ('given', 'given'), ('verb', 'verb'), (',', ','), ('finally', 'finally'), ('classifying', 'classifying'), ('nodes', 'node'), ('compute', 'compute')]



========================================== PARAGRAPH 283 ===========================================

corresponding SRL tags.  

------------------- Sentence 1 -------------------

corresponding SRL tags.

>> Tokens are: 
 ['corresponding', 'SRL', 'tags', '.']

>> Bigrams are: 
 [('corresponding', 'SRL'), ('SRL', 'tags'), ('tags', '.')]

>> Trigrams are: 
 [('corresponding', 'SRL', 'tags'), ('SRL', 'tags', '.')]

>> POS Tags are: 
 [('corresponding', 'VBG'), ('SRL', 'NNP'), ('tags', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['SRL tags']

>> Named Entities are: 
 [('ORGANIZATION', 'SRL')] 

>> Stemming using Porter Stemmer: 
 [('corresponding', 'correspond'), ('SRL', 'srl'), ('tags', 'tag'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('corresponding', 'correspond'), ('SRL', 'srl'), ('tags', 'tag'), ('.', '.')]

>> Lemmatization: 
 [('corresponding', 'corresponding'), ('SRL', 'SRL'), ('tags', 'tag'), ('.', '.')]



========================================== PARAGRAPH 284 ===========================================

  


========================================== PARAGRAPH 285 ===========================================

Event discovery in social media feeds (Edward Benson et al.,2011) [36], using a graphical  

------------------- Sentence 1 -------------------

Event discovery in social media feeds (Edward Benson et al.,2011) [36], using a graphical

>> Tokens are: 
 ['Event', 'discovery', 'social', 'media', 'feeds', '(', 'Edward', 'Benson', 'et', 'al.,2011', ')', '[', '36', ']', ',', 'using', 'graphical']

>> Bigrams are: 
 [('Event', 'discovery'), ('discovery', 'social'), ('social', 'media'), ('media', 'feeds'), ('feeds', '('), ('(', 'Edward'), ('Edward', 'Benson'), ('Benson', 'et'), ('et', 'al.,2011'), ('al.,2011', ')'), (')', '['), ('[', '36'), ('36', ']'), (']', ','), (',', 'using'), ('using', 'graphical')]

>> Trigrams are: 
 [('Event', 'discovery', 'social'), ('discovery', 'social', 'media'), ('social', 'media', 'feeds'), ('media', 'feeds', '('), ('feeds', '(', 'Edward'), ('(', 'Edward', 'Benson'), ('Edward', 'Benson', 'et'), ('Benson', 'et', 'al.,2011'), ('et', 'al.,2011', ')'), ('al.,2011', ')', '['), (')', '[', '36'), ('[', '36', ']'), ('36', ']', ','), (']', ',', 'using'), (',', 'using', 'graphical')]

>> POS Tags are: 
 [('Event', 'JJ'), ('discovery', 'NN'), ('social', 'JJ'), ('media', 'NNS'), ('feeds', 'NNS'), ('(', '('), ('Edward', 'NNP'), ('Benson', 'NNP'), ('et', 'FW'), ('al.,2011', 'NN'), (')', ')'), ('[', 'VBZ'), ('36', 'CD'), (']', 'NN'), (',', ','), ('using', 'VBG'), ('graphical', 'JJ')]

>> Noun Phrases are: 
 ['Event discovery', 'social media feeds', 'Edward Benson', 'al.,2011', ']']

>> Named Entities are: 
 [('PERSON', 'Edward Benson')] 

>> Stemming using Porter Stemmer: 
 [('Event', 'event'), ('discovery', 'discoveri'), ('social', 'social'), ('media', 'media'), ('feeds', 'feed'), ('(', '('), ('Edward', 'edward'), ('Benson', 'benson'), ('et', 'et'), ('al.,2011', 'al.,2011'), (')', ')'), ('[', '['), ('36', '36'), (']', ']'), (',', ','), ('using', 'use'), ('graphical', 'graphic')]

>> Stemming using Snowball Stemmer: 
 [('Event', 'event'), ('discovery', 'discoveri'), ('social', 'social'), ('media', 'media'), ('feeds', 'feed'), ('(', '('), ('Edward', 'edward'), ('Benson', 'benson'), ('et', 'et'), ('al.,2011', 'al.,2011'), (')', ')'), ('[', '['), ('36', '36'), (']', ']'), (',', ','), ('using', 'use'), ('graphical', 'graphic')]

>> Lemmatization: 
 [('Event', 'Event'), ('discovery', 'discovery'), ('social', 'social'), ('media', 'medium'), ('feeds', 'feed'), ('(', '('), ('Edward', 'Edward'), ('Benson', 'Benson'), ('et', 'et'), ('al.,2011', 'al.,2011'), (')', ')'), ('[', '['), ('36', '36'), (']', ']'), (',', ','), ('using', 'using'), ('graphical', 'graphical')]



========================================== PARAGRAPH 286 ===========================================

model to analyse any social media feeds to determine whether it contains name of a person or  

------------------- Sentence 1 -------------------

model to analyse any social media feeds to determine whether it contains name of a person or

>> Tokens are: 
 ['model', 'analyse', 'social', 'media', 'feeds', 'determine', 'whether', 'contains', 'name', 'person']

>> Bigrams are: 
 [('model', 'analyse'), ('analyse', 'social'), ('social', 'media'), ('media', 'feeds'), ('feeds', 'determine'), ('determine', 'whether'), ('whether', 'contains'), ('contains', 'name'), ('name', 'person')]

>> Trigrams are: 
 [('model', 'analyse', 'social'), ('analyse', 'social', 'media'), ('social', 'media', 'feeds'), ('media', 'feeds', 'determine'), ('feeds', 'determine', 'whether'), ('determine', 'whether', 'contains'), ('whether', 'contains', 'name'), ('contains', 'name', 'person')]

>> POS Tags are: 
 [('model', 'NN'), ('analyse', 'VBZ'), ('social', 'JJ'), ('media', 'NNS'), ('feeds', 'NNS'), ('determine', 'VBP'), ('whether', 'IN'), ('contains', 'NNS'), ('name', 'CD'), ('person', 'NN')]

>> Noun Phrases are: 
 ['model', 'social media feeds', 'contains', 'person']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('model', 'model'), ('analyse', 'analys'), ('social', 'social'), ('media', 'media'), ('feeds', 'feed'), ('determine', 'determin'), ('whether', 'whether'), ('contains', 'contain'), ('name', 'name'), ('person', 'person')]

>> Stemming using Snowball Stemmer: 
 [('model', 'model'), ('analyse', 'analys'), ('social', 'social'), ('media', 'media'), ('feeds', 'feed'), ('determine', 'determin'), ('whether', 'whether'), ('contains', 'contain'), ('name', 'name'), ('person', 'person')]

>> Lemmatization: 
 [('model', 'model'), ('analyse', 'analyse'), ('social', 'social'), ('media', 'medium'), ('feeds', 'feed'), ('determine', 'determine'), ('whether', 'whether'), ('contains', 'contains'), ('name', 'name'), ('person', 'person')]



========================================== PARAGRAPH 287 ===========================================

name of a venue, place, time etc. The model operates on noisy feeds of data to extract records  

------------------- Sentence 1 -------------------

name of a venue, place, time etc.

>> Tokens are: 
 ['name', 'venue', ',', 'place', ',', 'time', 'etc', '.']

>> Bigrams are: 
 [('name', 'venue'), ('venue', ','), (',', 'place'), ('place', ','), (',', 'time'), ('time', 'etc'), ('etc', '.')]

>> Trigrams are: 
 [('name', 'venue', ','), ('venue', ',', 'place'), (',', 'place', ','), ('place', ',', 'time'), (',', 'time', 'etc'), ('time', 'etc', '.')]

>> POS Tags are: 
 [('name', 'NN'), ('venue', 'NN'), (',', ','), ('place', 'NN'), (',', ','), ('time', 'NN'), ('etc', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['name venue', 'place', 'time etc']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('name', 'name'), ('venue', 'venu'), (',', ','), ('place', 'place'), (',', ','), ('time', 'time'), ('etc', 'etc'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('name', 'name'), ('venue', 'venu'), (',', ','), ('place', 'place'), (',', ','), ('time', 'time'), ('etc', 'etc'), ('.', '.')]

>> Lemmatization: 
 [('name', 'name'), ('venue', 'venue'), (',', ','), ('place', 'place'), (',', ','), ('time', 'time'), ('etc', 'etc'), ('.', '.')]


------------------- Sentence 2 -------------------

The model operates on noisy feeds of data to extract records

>> Tokens are: 
 ['The', 'model', 'operates', 'noisy', 'feeds', 'data', 'extract', 'records']

>> Bigrams are: 
 [('The', 'model'), ('model', 'operates'), ('operates', 'noisy'), ('noisy', 'feeds'), ('feeds', 'data'), ('data', 'extract'), ('extract', 'records')]

>> Trigrams are: 
 [('The', 'model', 'operates'), ('model', 'operates', 'noisy'), ('operates', 'noisy', 'feeds'), ('noisy', 'feeds', 'data'), ('feeds', 'data', 'extract'), ('data', 'extract', 'records')]

>> POS Tags are: 
 [('The', 'DT'), ('model', 'NN'), ('operates', 'VBZ'), ('noisy', 'JJ'), ('feeds', 'NNS'), ('data', 'NNS'), ('extract', 'NN'), ('records', 'NNS')]

>> Noun Phrases are: 
 ['The model', 'noisy feeds data extract records']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('model', 'model'), ('operates', 'oper'), ('noisy', 'noisi'), ('feeds', 'feed'), ('data', 'data'), ('extract', 'extract'), ('records', 'record')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('model', 'model'), ('operates', 'oper'), ('noisy', 'noisi'), ('feeds', 'feed'), ('data', 'data'), ('extract', 'extract'), ('records', 'record')]

>> Lemmatization: 
 [('The', 'The'), ('model', 'model'), ('operates', 'operates'), ('noisy', 'noisy'), ('feeds', 'feed'), ('data', 'data'), ('extract', 'extract'), ('records', 'record')]



========================================== PARAGRAPH 288 ===========================================

of events by aggregating multiple information across multiple messages, despite the noise of  

------------------- Sentence 1 -------------------

of events by aggregating multiple information across multiple messages, despite the noise of

>> Tokens are: 
 ['events', 'aggregating', 'multiple', 'information', 'across', 'multiple', 'messages', ',', 'despite', 'noise']

>> Bigrams are: 
 [('events', 'aggregating'), ('aggregating', 'multiple'), ('multiple', 'information'), ('information', 'across'), ('across', 'multiple'), ('multiple', 'messages'), ('messages', ','), (',', 'despite'), ('despite', 'noise')]

>> Trigrams are: 
 [('events', 'aggregating', 'multiple'), ('aggregating', 'multiple', 'information'), ('multiple', 'information', 'across'), ('information', 'across', 'multiple'), ('across', 'multiple', 'messages'), ('multiple', 'messages', ','), ('messages', ',', 'despite'), (',', 'despite', 'noise')]

>> POS Tags are: 
 [('events', 'NNS'), ('aggregating', 'VBG'), ('multiple', 'JJ'), ('information', 'NN'), ('across', 'IN'), ('multiple', 'JJ'), ('messages', 'NNS'), (',', ','), ('despite', 'IN'), ('noise', 'NN')]

>> Noun Phrases are: 
 ['events', 'multiple information', 'multiple messages', 'noise']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('events', 'event'), ('aggregating', 'aggreg'), ('multiple', 'multipl'), ('information', 'inform'), ('across', 'across'), ('multiple', 'multipl'), ('messages', 'messag'), (',', ','), ('despite', 'despit'), ('noise', 'nois')]

>> Stemming using Snowball Stemmer: 
 [('events', 'event'), ('aggregating', 'aggreg'), ('multiple', 'multipl'), ('information', 'inform'), ('across', 'across'), ('multiple', 'multipl'), ('messages', 'messag'), (',', ','), ('despite', 'despit'), ('noise', 'nois')]

>> Lemmatization: 
 [('events', 'event'), ('aggregating', 'aggregating'), ('multiple', 'multiple'), ('information', 'information'), ('across', 'across'), ('multiple', 'multiple'), ('messages', 'message'), (',', ','), ('despite', 'despite'), ('noise', 'noise')]



========================================== PARAGRAPH 289 ===========================================

irrelevant noisy messages and very irregular message language, this model was able to extract  

------------------- Sentence 1 -------------------

irrelevant noisy messages and very irregular message language, this model was able to extract

>> Tokens are: 
 ['irrelevant', 'noisy', 'messages', 'irregular', 'message', 'language', ',', 'model', 'able', 'extract']

>> Bigrams are: 
 [('irrelevant', 'noisy'), ('noisy', 'messages'), ('messages', 'irregular'), ('irregular', 'message'), ('message', 'language'), ('language', ','), (',', 'model'), ('model', 'able'), ('able', 'extract')]

>> Trigrams are: 
 [('irrelevant', 'noisy', 'messages'), ('noisy', 'messages', 'irregular'), ('messages', 'irregular', 'message'), ('irregular', 'message', 'language'), ('message', 'language', ','), ('language', ',', 'model'), (',', 'model', 'able'), ('model', 'able', 'extract')]

>> POS Tags are: 
 [('irrelevant', 'JJ'), ('noisy', 'NN'), ('messages', 'NNS'), ('irregular', 'JJ'), ('message', 'NN'), ('language', 'NN'), (',', ','), ('model', 'NN'), ('able', 'JJ'), ('extract', 'NN')]

>> Noun Phrases are: 
 ['irrelevant noisy messages', 'irregular message language', 'model', 'able extract']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('irrelevant', 'irrelev'), ('noisy', 'noisi'), ('messages', 'messag'), ('irregular', 'irregular'), ('message', 'messag'), ('language', 'languag'), (',', ','), ('model', 'model'), ('able', 'abl'), ('extract', 'extract')]

>> Stemming using Snowball Stemmer: 
 [('irrelevant', 'irrelev'), ('noisy', 'noisi'), ('messages', 'messag'), ('irregular', 'irregular'), ('message', 'messag'), ('language', 'languag'), (',', ','), ('model', 'model'), ('able', 'abl'), ('extract', 'extract')]

>> Lemmatization: 
 [('irrelevant', 'irrelevant'), ('noisy', 'noisy'), ('messages', 'message'), ('irregular', 'irregular'), ('message', 'message'), ('language', 'language'), (',', ','), ('model', 'model'), ('able', 'able'), ('extract', 'extract')]



========================================== PARAGRAPH 290 ===========================================

records with high accuracy. However, there is some scope for improvement using broader  

------------------- Sentence 1 -------------------

records with high accuracy.

>> Tokens are: 
 ['records', 'high', 'accuracy', '.']

>> Bigrams are: 
 [('records', 'high'), ('high', 'accuracy'), ('accuracy', '.')]

>> Trigrams are: 
 [('records', 'high', 'accuracy'), ('high', 'accuracy', '.')]

>> POS Tags are: 
 [('records', 'NNS'), ('high', 'JJ'), ('accuracy', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['records', 'high accuracy']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('records', 'record'), ('high', 'high'), ('accuracy', 'accuraci'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('records', 'record'), ('high', 'high'), ('accuracy', 'accuraci'), ('.', '.')]

>> Lemmatization: 
 [('records', 'record'), ('high', 'high'), ('accuracy', 'accuracy'), ('.', '.')]


------------------- Sentence 2 -------------------

However, there is some scope for improvement using broader

>> Tokens are: 
 ['However', ',', 'scope', 'improvement', 'using', 'broader']

>> Bigrams are: 
 [('However', ','), (',', 'scope'), ('scope', 'improvement'), ('improvement', 'using'), ('using', 'broader')]

>> Trigrams are: 
 [('However', ',', 'scope'), (',', 'scope', 'improvement'), ('scope', 'improvement', 'using'), ('improvement', 'using', 'broader')]

>> POS Tags are: 
 [('However', 'RB'), (',', ','), ('scope', 'VBP'), ('improvement', 'NN'), ('using', 'VBG'), ('broader', 'JJR')]

>> Noun Phrases are: 
 ['improvement']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('However', 'howev'), (',', ','), ('scope', 'scope'), ('improvement', 'improv'), ('using', 'use'), ('broader', 'broader')]

>> Stemming using Snowball Stemmer: 
 [('However', 'howev'), (',', ','), ('scope', 'scope'), ('improvement', 'improv'), ('using', 'use'), ('broader', 'broader')]

>> Lemmatization: 
 [('However', 'However'), (',', ','), ('scope', 'scope'), ('improvement', 'improvement'), ('using', 'using'), ('broader', 'broader')]



========================================== PARAGRAPH 291 ===========================================

array of features on factors.  

------------------- Sentence 1 -------------------

array of features on factors.

>> Tokens are: 
 ['array', 'features', 'factors', '.']

>> Bigrams are: 
 [('array', 'features'), ('features', 'factors'), ('factors', '.')]

>> Trigrams are: 
 [('array', 'features', 'factors'), ('features', 'factors', '.')]

>> POS Tags are: 
 [('array', 'NN'), ('features', 'VBZ'), ('factors', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['array', 'factors']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('array', 'array'), ('features', 'featur'), ('factors', 'factor'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('array', 'array'), ('features', 'featur'), ('factors', 'factor'), ('.', '.')]

>> Lemmatization: 
 [('array', 'array'), ('features', 'feature'), ('factors', 'factor'), ('.', '.')]



========================================== PARAGRAPH 292 ===========================================

  


========================================== PARAGRAPH 293 ===========================================

6. Applications of NLP  

------------------- Sentence 1 -------------------

6.

>> Tokens are: 
 ['6', '.']

>> Bigrams are: 
 [('6', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('6', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('6', '6'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('6', '6'), ('.', '.')]

>> Lemmatization: 
 [('6', '6'), ('.', '.')]


------------------- Sentence 2 -------------------

Applications of NLP

>> Tokens are: 
 ['Applications', 'NLP']

>> Bigrams are: 
 [('Applications', 'NLP')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Applications', 'NNS'), ('NLP', 'NNP')]

>> Noun Phrases are: 
 ['Applications NLP']

>> Named Entities are: 
 [('ORGANIZATION', 'NLP')] 

>> Stemming using Porter Stemmer: 
 [('Applications', 'applic'), ('NLP', 'nlp')]

>> Stemming using Snowball Stemmer: 
 [('Applications', 'applic'), ('NLP', 'nlp')]

>> Lemmatization: 
 [('Applications', 'Applications'), ('NLP', 'NLP')]



========================================== PARAGRAPH 294 ===========================================

Natural Language Processing can be applied into various areas like Machine Translation,  

------------------- Sentence 1 -------------------

Natural Language Processing can be applied into various areas like Machine Translation,

>> Tokens are: 
 ['Natural', 'Language', 'Processing', 'applied', 'various', 'areas', 'like', 'Machine', 'Translation', ',']

>> Bigrams are: 
 [('Natural', 'Language'), ('Language', 'Processing'), ('Processing', 'applied'), ('applied', 'various'), ('various', 'areas'), ('areas', 'like'), ('like', 'Machine'), ('Machine', 'Translation'), ('Translation', ',')]

>> Trigrams are: 
 [('Natural', 'Language', 'Processing'), ('Language', 'Processing', 'applied'), ('Processing', 'applied', 'various'), ('applied', 'various', 'areas'), ('various', 'areas', 'like'), ('areas', 'like', 'Machine'), ('like', 'Machine', 'Translation'), ('Machine', 'Translation', ',')]

>> POS Tags are: 
 [('Natural', 'JJ'), ('Language', 'NNP'), ('Processing', 'NNP'), ('applied', 'VBD'), ('various', 'JJ'), ('areas', 'NNS'), ('like', 'IN'), ('Machine', 'NNP'), ('Translation', 'NNP'), (',', ',')]

>> Noun Phrases are: 
 ['Natural Language Processing', 'various areas', 'Machine Translation']

>> Named Entities are: 
 [('PERSON', 'Machine Translation')] 

>> Stemming using Porter Stemmer: 
 [('Natural', 'natur'), ('Language', 'languag'), ('Processing', 'process'), ('applied', 'appli'), ('various', 'variou'), ('areas', 'area'), ('like', 'like'), ('Machine', 'machin'), ('Translation', 'translat'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('Natural', 'natur'), ('Language', 'languag'), ('Processing', 'process'), ('applied', 'appli'), ('various', 'various'), ('areas', 'area'), ('like', 'like'), ('Machine', 'machin'), ('Translation', 'translat'), (',', ',')]

>> Lemmatization: 
 [('Natural', 'Natural'), ('Language', 'Language'), ('Processing', 'Processing'), ('applied', 'applied'), ('various', 'various'), ('areas', 'area'), ('like', 'like'), ('Machine', 'Machine'), ('Translation', 'Translation'), (',', ',')]



========================================== PARAGRAPH 295 ===========================================

Email Spam detection, Information Extraction, Summarization, Question Answering etc.  

------------------- Sentence 1 -------------------

Email Spam detection, Information Extraction, Summarization, Question Answering etc.

>> Tokens are: 
 ['Email', 'Spam', 'detection', ',', 'Information', 'Extraction', ',', 'Summarization', ',', 'Question', 'Answering', 'etc', '.']

>> Bigrams are: 
 [('Email', 'Spam'), ('Spam', 'detection'), ('detection', ','), (',', 'Information'), ('Information', 'Extraction'), ('Extraction', ','), (',', 'Summarization'), ('Summarization', ','), (',', 'Question'), ('Question', 'Answering'), ('Answering', 'etc'), ('etc', '.')]

>> Trigrams are: 
 [('Email', 'Spam', 'detection'), ('Spam', 'detection', ','), ('detection', ',', 'Information'), (',', 'Information', 'Extraction'), ('Information', 'Extraction', ','), ('Extraction', ',', 'Summarization'), (',', 'Summarization', ','), ('Summarization', ',', 'Question'), (',', 'Question', 'Answering'), ('Question', 'Answering', 'etc'), ('Answering', 'etc', '.')]

>> POS Tags are: 
 [('Email', 'NNP'), ('Spam', 'NNP'), ('detection', 'NN'), (',', ','), ('Information', 'NNP'), ('Extraction', 'NNP'), (',', ','), ('Summarization', 'NNP'), (',', ','), ('Question', 'NNP'), ('Answering', 'NNP'), ('etc', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Email Spam detection', 'Information Extraction', 'Summarization', 'Question Answering etc']

>> Named Entities are: 
 [('PERSON', 'Email'), ('ORGANIZATION', 'Spam'), ('ORGANIZATION', 'Information Extraction'), ('GPE', 'Summarization'), ('PERSON', 'Question Answering')] 

>> Stemming using Porter Stemmer: 
 [('Email', 'email'), ('Spam', 'spam'), ('detection', 'detect'), (',', ','), ('Information', 'inform'), ('Extraction', 'extract'), (',', ','), ('Summarization', 'summar'), (',', ','), ('Question', 'question'), ('Answering', 'answer'), ('etc', 'etc'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Email', 'email'), ('Spam', 'spam'), ('detection', 'detect'), (',', ','), ('Information', 'inform'), ('Extraction', 'extract'), (',', ','), ('Summarization', 'summar'), (',', ','), ('Question', 'question'), ('Answering', 'answer'), ('etc', 'etc'), ('.', '.')]

>> Lemmatization: 
 [('Email', 'Email'), ('Spam', 'Spam'), ('detection', 'detection'), (',', ','), ('Information', 'Information'), ('Extraction', 'Extraction'), (',', ','), ('Summarization', 'Summarization'), (',', ','), ('Question', 'Question'), ('Answering', 'Answering'), ('etc', 'etc'), ('.', '.')]



========================================== PARAGRAPH 296 ===========================================

6.1 Machine Translation   

------------------- Sentence 1 -------------------

6.1 Machine Translation

>> Tokens are: 
 ['6.1', 'Machine', 'Translation']

>> Bigrams are: 
 [('6.1', 'Machine'), ('Machine', 'Translation')]

>> Trigrams are: 
 [('6.1', 'Machine', 'Translation')]

>> POS Tags are: 
 [('6.1', 'CD'), ('Machine', 'NNP'), ('Translation', 'NN')]

>> Noun Phrases are: 
 ['Machine Translation']

>> Named Entities are: 
 [('GPE', 'Machine')] 

>> Stemming using Porter Stemmer: 
 [('6.1', '6.1'), ('Machine', 'machin'), ('Translation', 'translat')]

>> Stemming using Snowball Stemmer: 
 [('6.1', '6.1'), ('Machine', 'machin'), ('Translation', 'translat')]

>> Lemmatization: 
 [('6.1', '6.1'), ('Machine', 'Machine'), ('Translation', 'Translation')]



========================================== PARAGRAPH 297 ===========================================

As most of the world is online, the task of making data accessible and available to all is a  

------------------- Sentence 1 -------------------

As most of the world is online, the task of making data accessible and available to all is a

>> Tokens are: 
 ['As', 'world', 'online', ',', 'task', 'making', 'data', 'accessible', 'available']

>> Bigrams are: 
 [('As', 'world'), ('world', 'online'), ('online', ','), (',', 'task'), ('task', 'making'), ('making', 'data'), ('data', 'accessible'), ('accessible', 'available')]

>> Trigrams are: 
 [('As', 'world', 'online'), ('world', 'online', ','), ('online', ',', 'task'), (',', 'task', 'making'), ('task', 'making', 'data'), ('making', 'data', 'accessible'), ('data', 'accessible', 'available')]

>> POS Tags are: 
 [('As', 'IN'), ('world', 'NN'), ('online', 'NN'), (',', ','), ('task', 'NN'), ('making', 'VBG'), ('data', 'NNS'), ('accessible', 'JJ'), ('available', 'JJ')]

>> Noun Phrases are: 
 ['world online', 'task', 'data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('As', 'as'), ('world', 'world'), ('online', 'onlin'), (',', ','), ('task', 'task'), ('making', 'make'), ('data', 'data'), ('accessible', 'access'), ('available', 'avail')]

>> Stemming using Snowball Stemmer: 
 [('As', 'as'), ('world', 'world'), ('online', 'onlin'), (',', ','), ('task', 'task'), ('making', 'make'), ('data', 'data'), ('accessible', 'access'), ('available', 'avail')]

>> Lemmatization: 
 [('As', 'As'), ('world', 'world'), ('online', 'online'), (',', ','), ('task', 'task'), ('making', 'making'), ('data', 'data'), ('accessible', 'accessible'), ('available', 'available')]



========================================== PARAGRAPH 298 ===========================================

challenge. Major challenge in making data accessible is the language barrier. There are  

------------------- Sentence 1 -------------------

challenge.

>> Tokens are: 
 ['challenge', '.']

>> Bigrams are: 
 [('challenge', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('challenge', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['challenge']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('challenge', 'challeng'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('challenge', 'challeng'), ('.', '.')]

>> Lemmatization: 
 [('challenge', 'challenge'), ('.', '.')]


------------------- Sentence 2 -------------------

Major challenge in making data accessible is the language barrier.

>> Tokens are: 
 ['Major', 'challenge', 'making', 'data', 'accessible', 'language', 'barrier', '.']

>> Bigrams are: 
 [('Major', 'challenge'), ('challenge', 'making'), ('making', 'data'), ('data', 'accessible'), ('accessible', 'language'), ('language', 'barrier'), ('barrier', '.')]

>> Trigrams are: 
 [('Major', 'challenge', 'making'), ('challenge', 'making', 'data'), ('making', 'data', 'accessible'), ('data', 'accessible', 'language'), ('accessible', 'language', 'barrier'), ('language', 'barrier', '.')]

>> POS Tags are: 
 [('Major', 'JJ'), ('challenge', 'NN'), ('making', 'VBG'), ('data', 'NNS'), ('accessible', 'JJ'), ('language', 'NN'), ('barrier', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Major challenge', 'data', 'accessible language barrier']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Major', 'major'), ('challenge', 'challeng'), ('making', 'make'), ('data', 'data'), ('accessible', 'access'), ('language', 'languag'), ('barrier', 'barrier'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Major', 'major'), ('challenge', 'challeng'), ('making', 'make'), ('data', 'data'), ('accessible', 'access'), ('language', 'languag'), ('barrier', 'barrier'), ('.', '.')]

>> Lemmatization: 
 [('Major', 'Major'), ('challenge', 'challenge'), ('making', 'making'), ('data', 'data'), ('accessible', 'accessible'), ('language', 'language'), ('barrier', 'barrier'), ('.', '.')]


------------------- Sentence 3 -------------------

There are

>> Tokens are: 
 ['There']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('There', 'EX')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('There', 'there')]

>> Stemming using Snowball Stemmer: 
 [('There', 'there')]

>> Lemmatization: 
 [('There', 'There')]



========================================== PARAGRAPH 299 ===========================================

multitude of languages with different sentence structure and grammar. Machine Translation is  

------------------- Sentence 1 -------------------

multitude of languages with different sentence structure and grammar.

>> Tokens are: 
 ['multitude', 'languages', 'different', 'sentence', 'structure', 'grammar', '.']

>> Bigrams are: 
 [('multitude', 'languages'), ('languages', 'different'), ('different', 'sentence'), ('sentence', 'structure'), ('structure', 'grammar'), ('grammar', '.')]

>> Trigrams are: 
 [('multitude', 'languages', 'different'), ('languages', 'different', 'sentence'), ('different', 'sentence', 'structure'), ('sentence', 'structure', 'grammar'), ('structure', 'grammar', '.')]

>> POS Tags are: 
 [('multitude', 'NN'), ('languages', 'NNS'), ('different', 'JJ'), ('sentence', 'NN'), ('structure', 'NN'), ('grammar', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['multitude languages', 'different sentence structure grammar']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('multitude', 'multitud'), ('languages', 'languag'), ('different', 'differ'), ('sentence', 'sentenc'), ('structure', 'structur'), ('grammar', 'grammar'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('multitude', 'multitud'), ('languages', 'languag'), ('different', 'differ'), ('sentence', 'sentenc'), ('structure', 'structur'), ('grammar', 'grammar'), ('.', '.')]

>> Lemmatization: 
 [('multitude', 'multitude'), ('languages', 'language'), ('different', 'different'), ('sentence', 'sentence'), ('structure', 'structure'), ('grammar', 'grammar'), ('.', '.')]


------------------- Sentence 2 -------------------

Machine Translation is

>> Tokens are: 
 ['Machine', 'Translation']

>> Bigrams are: 
 [('Machine', 'Translation')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Machine', 'NN'), ('Translation', 'NN')]

>> Noun Phrases are: 
 ['Machine Translation']

>> Named Entities are: 
 [('GPE', 'Machine'), ('ORGANIZATION', 'Translation')] 

>> Stemming using Porter Stemmer: 
 [('Machine', 'machin'), ('Translation', 'translat')]

>> Stemming using Snowball Stemmer: 
 [('Machine', 'machin'), ('Translation', 'translat')]

>> Lemmatization: 
 [('Machine', 'Machine'), ('Translation', 'Translation')]



========================================== PARAGRAPH 300 ===========================================

generally translating phrases from one language to another with the help of a statistical  

------------------- Sentence 1 -------------------

generally translating phrases from one language to another with the help of a statistical

>> Tokens are: 
 ['generally', 'translating', 'phrases', 'one', 'language', 'another', 'help', 'statistical']

>> Bigrams are: 
 [('generally', 'translating'), ('translating', 'phrases'), ('phrases', 'one'), ('one', 'language'), ('language', 'another'), ('another', 'help'), ('help', 'statistical')]

>> Trigrams are: 
 [('generally', 'translating', 'phrases'), ('translating', 'phrases', 'one'), ('phrases', 'one', 'language'), ('one', 'language', 'another'), ('language', 'another', 'help'), ('another', 'help', 'statistical')]

>> POS Tags are: 
 [('generally', 'RB'), ('translating', 'VBG'), ('phrases', 'NNS'), ('one', 'CD'), ('language', 'NN'), ('another', 'DT'), ('help', 'NN'), ('statistical', 'NN')]

>> Noun Phrases are: 
 ['phrases', 'language', 'another help statistical']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('generally', 'gener'), ('translating', 'translat'), ('phrases', 'phrase'), ('one', 'one'), ('language', 'languag'), ('another', 'anoth'), ('help', 'help'), ('statistical', 'statist')]

>> Stemming using Snowball Stemmer: 
 [('generally', 'general'), ('translating', 'translat'), ('phrases', 'phrase'), ('one', 'one'), ('language', 'languag'), ('another', 'anoth'), ('help', 'help'), ('statistical', 'statist')]

>> Lemmatization: 
 [('generally', 'generally'), ('translating', 'translating'), ('phrases', 'phrase'), ('one', 'one'), ('language', 'language'), ('another', 'another'), ('help', 'help'), ('statistical', 'statistical')]



========================================== PARAGRAPH 301 ===========================================

engine like Google Translate. The challenge with machine translation technologies is not  

------------------- Sentence 1 -------------------

engine like Google Translate.

>> Tokens are: 
 ['engine', 'like', 'Google', 'Translate', '.']

>> Bigrams are: 
 [('engine', 'like'), ('like', 'Google'), ('Google', 'Translate'), ('Translate', '.')]

>> Trigrams are: 
 [('engine', 'like', 'Google'), ('like', 'Google', 'Translate'), ('Google', 'Translate', '.')]

>> POS Tags are: 
 [('engine', 'NN'), ('like', 'IN'), ('Google', 'NNP'), ('Translate', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['engine', 'Google Translate']

>> Named Entities are: 
 [('PERSON', 'Google Translate')] 

>> Stemming using Porter Stemmer: 
 [('engine', 'engin'), ('like', 'like'), ('Google', 'googl'), ('Translate', 'translat'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('engine', 'engin'), ('like', 'like'), ('Google', 'googl'), ('Translate', 'translat'), ('.', '.')]

>> Lemmatization: 
 [('engine', 'engine'), ('like', 'like'), ('Google', 'Google'), ('Translate', 'Translate'), ('.', '.')]


------------------- Sentence 2 -------------------

The challenge with machine translation technologies is not

>> Tokens are: 
 ['The', 'challenge', 'machine', 'translation', 'technologies']

>> Bigrams are: 
 [('The', 'challenge'), ('challenge', 'machine'), ('machine', 'translation'), ('translation', 'technologies')]

>> Trigrams are: 
 [('The', 'challenge', 'machine'), ('challenge', 'machine', 'translation'), ('machine', 'translation', 'technologies')]

>> POS Tags are: 
 [('The', 'DT'), ('challenge', 'NN'), ('machine', 'NN'), ('translation', 'NN'), ('technologies', 'NNS')]

>> Noun Phrases are: 
 ['The challenge machine translation technologies']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('challenge', 'challeng'), ('machine', 'machin'), ('translation', 'translat'), ('technologies', 'technolog')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('challenge', 'challeng'), ('machine', 'machin'), ('translation', 'translat'), ('technologies', 'technolog')]

>> Lemmatization: 
 [('The', 'The'), ('challenge', 'challenge'), ('machine', 'machine'), ('translation', 'translation'), ('technologies', 'technology')]



========================================== PARAGRAPH 302 ===========================================

directly translating words but keeping the meaning of sentences intact along with grammar  

------------------- Sentence 1 -------------------

directly translating words but keeping the meaning of sentences intact along with grammar

>> Tokens are: 
 ['directly', 'translating', 'words', 'keeping', 'meaning', 'sentences', 'intact', 'along', 'grammar']

>> Bigrams are: 
 [('directly', 'translating'), ('translating', 'words'), ('words', 'keeping'), ('keeping', 'meaning'), ('meaning', 'sentences'), ('sentences', 'intact'), ('intact', 'along'), ('along', 'grammar')]

>> Trigrams are: 
 [('directly', 'translating', 'words'), ('translating', 'words', 'keeping'), ('words', 'keeping', 'meaning'), ('keeping', 'meaning', 'sentences'), ('meaning', 'sentences', 'intact'), ('sentences', 'intact', 'along'), ('intact', 'along', 'grammar')]

>> POS Tags are: 
 [('directly', 'RB'), ('translating', 'VBG'), ('words', 'NNS'), ('keeping', 'VBG'), ('meaning', 'JJ'), ('sentences', 'NNS'), ('intact', 'JJ'), ('along', 'IN'), ('grammar', 'NN')]

>> Noun Phrases are: 
 ['words', 'meaning sentences', 'grammar']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('directly', 'directli'), ('translating', 'translat'), ('words', 'word'), ('keeping', 'keep'), ('meaning', 'mean'), ('sentences', 'sentenc'), ('intact', 'intact'), ('along', 'along'), ('grammar', 'grammar')]

>> Stemming using Snowball Stemmer: 
 [('directly', 'direct'), ('translating', 'translat'), ('words', 'word'), ('keeping', 'keep'), ('meaning', 'mean'), ('sentences', 'sentenc'), ('intact', 'intact'), ('along', 'along'), ('grammar', 'grammar')]

>> Lemmatization: 
 [('directly', 'directly'), ('translating', 'translating'), ('words', 'word'), ('keeping', 'keeping'), ('meaning', 'meaning'), ('sentences', 'sentence'), ('intact', 'intact'), ('along', 'along'), ('grammar', 'grammar')]



========================================== PARAGRAPH 303 ===========================================

and tenses. The statistical machine learning gathers as many data as they can find that seems  

------------------- Sentence 1 -------------------

and tenses.

>> Tokens are: 
 ['tenses', '.']

>> Bigrams are: 
 [('tenses', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('tenses', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['tenses']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('tenses', 'tens'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('tenses', 'tens'), ('.', '.')]

>> Lemmatization: 
 [('tenses', 'tense'), ('.', '.')]


------------------- Sentence 2 -------------------

The statistical machine learning gathers as many data as they can find that seems

>> Tokens are: 
 ['The', 'statistical', 'machine', 'learning', 'gathers', 'many', 'data', 'find', 'seems']

>> Bigrams are: 
 [('The', 'statistical'), ('statistical', 'machine'), ('machine', 'learning'), ('learning', 'gathers'), ('gathers', 'many'), ('many', 'data'), ('data', 'find'), ('find', 'seems')]

>> Trigrams are: 
 [('The', 'statistical', 'machine'), ('statistical', 'machine', 'learning'), ('machine', 'learning', 'gathers'), ('learning', 'gathers', 'many'), ('gathers', 'many', 'data'), ('many', 'data', 'find'), ('data', 'find', 'seems')]

>> POS Tags are: 
 [('The', 'DT'), ('statistical', 'JJ'), ('machine', 'NN'), ('learning', 'VBG'), ('gathers', 'NNS'), ('many', 'JJ'), ('data', 'NNS'), ('find', 'VBP'), ('seems', 'VBZ')]

>> Noun Phrases are: 
 ['The statistical machine', 'gathers', 'many data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('statistical', 'statist'), ('machine', 'machin'), ('learning', 'learn'), ('gathers', 'gather'), ('many', 'mani'), ('data', 'data'), ('find', 'find'), ('seems', 'seem')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('statistical', 'statist'), ('machine', 'machin'), ('learning', 'learn'), ('gathers', 'gather'), ('many', 'mani'), ('data', 'data'), ('find', 'find'), ('seems', 'seem')]

>> Lemmatization: 
 [('The', 'The'), ('statistical', 'statistical'), ('machine', 'machine'), ('learning', 'learning'), ('gathers', 'gather'), ('many', 'many'), ('data', 'data'), ('find', 'find'), ('seems', 'seems')]



========================================== PARAGRAPH 304 ===========================================

to be parallel between two languages and they crunch their data to find the likelihood that  

------------------- Sentence 1 -------------------

to be parallel between two languages and they crunch their data to find the likelihood that

>> Tokens are: 
 ['parallel', 'two', 'languages', 'crunch', 'data', 'find', 'likelihood']

>> Bigrams are: 
 [('parallel', 'two'), ('two', 'languages'), ('languages', 'crunch'), ('crunch', 'data'), ('data', 'find'), ('find', 'likelihood')]

>> Trigrams are: 
 [('parallel', 'two', 'languages'), ('two', 'languages', 'crunch'), ('languages', 'crunch', 'data'), ('crunch', 'data', 'find'), ('data', 'find', 'likelihood')]

>> POS Tags are: 
 [('parallel', 'RB'), ('two', 'CD'), ('languages', 'NNS'), ('crunch', 'VBP'), ('data', 'NNS'), ('find', 'VBP'), ('likelihood', 'NN')]

>> Noun Phrases are: 
 ['languages', 'data', 'likelihood']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('parallel', 'parallel'), ('two', 'two'), ('languages', 'languag'), ('crunch', 'crunch'), ('data', 'data'), ('find', 'find'), ('likelihood', 'likelihood')]

>> Stemming using Snowball Stemmer: 
 [('parallel', 'parallel'), ('two', 'two'), ('languages', 'languag'), ('crunch', 'crunch'), ('data', 'data'), ('find', 'find'), ('likelihood', 'likelihood')]

>> Lemmatization: 
 [('parallel', 'parallel'), ('two', 'two'), ('languages', 'language'), ('crunch', 'crunch'), ('data', 'data'), ('find', 'find'), ('likelihood', 'likelihood')]



========================================== PARAGRAPH 305 ===========================================

something in Language A corresponds to something in Language B. As for Google, in  

------------------- Sentence 1 -------------------

something in Language A corresponds to something in Language B.

>> Tokens are: 
 ['something', 'Language', 'A', 'corresponds', 'something', 'Language', 'B', '.']

>> Bigrams are: 
 [('something', 'Language'), ('Language', 'A'), ('A', 'corresponds'), ('corresponds', 'something'), ('something', 'Language'), ('Language', 'B'), ('B', '.')]

>> Trigrams are: 
 [('something', 'Language', 'A'), ('Language', 'A', 'corresponds'), ('A', 'corresponds', 'something'), ('corresponds', 'something', 'Language'), ('something', 'Language', 'B'), ('Language', 'B', '.')]

>> POS Tags are: 
 [('something', 'NN'), ('Language', 'VB'), ('A', 'NNP'), ('corresponds', 'NNS'), ('something', 'NN'), ('Language', 'NNP'), ('B', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['something', 'A corresponds something Language B']

>> Named Entities are: 
 [('PERSON', 'Language B')] 

>> Stemming using Porter Stemmer: 
 [('something', 'someth'), ('Language', 'languag'), ('A', 'a'), ('corresponds', 'correspond'), ('something', 'someth'), ('Language', 'languag'), ('B', 'b'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('something', 'someth'), ('Language', 'languag'), ('A', 'a'), ('corresponds', 'correspond'), ('something', 'someth'), ('Language', 'languag'), ('B', 'b'), ('.', '.')]

>> Lemmatization: 
 [('something', 'something'), ('Language', 'Language'), ('A', 'A'), ('corresponds', 'corresponds'), ('something', 'something'), ('Language', 'Language'), ('B', 'B'), ('.', '.')]


------------------- Sentence 2 -------------------

As for Google, in

>> Tokens are: 
 ['As', 'Google', ',']

>> Bigrams are: 
 [('As', 'Google'), ('Google', ',')]

>> Trigrams are: 
 [('As', 'Google', ',')]

>> POS Tags are: 
 [('As', 'IN'), ('Google', 'NNP'), (',', ',')]

>> Noun Phrases are: 
 ['Google']

>> Named Entities are: 
 [('GPE', 'Google')] 

>> Stemming using Porter Stemmer: 
 [('As', 'as'), ('Google', 'googl'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('As', 'as'), ('Google', 'googl'), (',', ',')]

>> Lemmatization: 
 [('As', 'As'), ('Google', 'Google'), (',', ',')]



========================================== PARAGRAPH 306 ===========================================

September 2016, announced a new machine translation system based on Artificial neural  

------------------- Sentence 1 -------------------

September 2016, announced a new machine translation system based on Artificial neural

>> Tokens are: 
 ['September', '2016', ',', 'announced', 'new', 'machine', 'translation', 'system', 'based', 'Artificial', 'neural']

>> Bigrams are: 
 [('September', '2016'), ('2016', ','), (',', 'announced'), ('announced', 'new'), ('new', 'machine'), ('machine', 'translation'), ('translation', 'system'), ('system', 'based'), ('based', 'Artificial'), ('Artificial', 'neural')]

>> Trigrams are: 
 [('September', '2016', ','), ('2016', ',', 'announced'), (',', 'announced', 'new'), ('announced', 'new', 'machine'), ('new', 'machine', 'translation'), ('machine', 'translation', 'system'), ('translation', 'system', 'based'), ('system', 'based', 'Artificial'), ('based', 'Artificial', 'neural')]

>> POS Tags are: 
 [('September', 'NNP'), ('2016', 'CD'), (',', ','), ('announced', 'VBD'), ('new', 'JJ'), ('machine', 'NN'), ('translation', 'NN'), ('system', 'NN'), ('based', 'VBN'), ('Artificial', 'NNP'), ('neural', 'JJ')]

>> Noun Phrases are: 
 ['September', 'new machine translation system', 'Artificial']

>> Named Entities are: 
 [('ORGANIZATION', 'Artificial')] 

>> Stemming using Porter Stemmer: 
 [('September', 'septemb'), ('2016', '2016'), (',', ','), ('announced', 'announc'), ('new', 'new'), ('machine', 'machin'), ('translation', 'translat'), ('system', 'system'), ('based', 'base'), ('Artificial', 'artifici'), ('neural', 'neural')]

>> Stemming using Snowball Stemmer: 
 [('September', 'septemb'), ('2016', '2016'), (',', ','), ('announced', 'announc'), ('new', 'new'), ('machine', 'machin'), ('translation', 'translat'), ('system', 'system'), ('based', 'base'), ('Artificial', 'artifici'), ('neural', 'neural')]

>> Lemmatization: 
 [('September', 'September'), ('2016', '2016'), (',', ','), ('announced', 'announced'), ('new', 'new'), ('machine', 'machine'), ('translation', 'translation'), ('system', 'system'), ('based', 'based'), ('Artificial', 'Artificial'), ('neural', 'neural')]



========================================== PARAGRAPH 307 ===========================================

networks and Deep learning . In recent years, various methods have been proposed to  

------------------- Sentence 1 -------------------

networks and Deep learning .

>> Tokens are: 
 ['networks', 'Deep', 'learning', '.']

>> Bigrams are: 
 [('networks', 'Deep'), ('Deep', 'learning'), ('learning', '.')]

>> Trigrams are: 
 [('networks', 'Deep', 'learning'), ('Deep', 'learning', '.')]

>> POS Tags are: 
 [('networks', 'NNS'), ('Deep', 'NNP'), ('learning', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['networks Deep learning']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('networks', 'network'), ('Deep', 'deep'), ('learning', 'learn'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('networks', 'network'), ('Deep', 'deep'), ('learning', 'learn'), ('.', '.')]

>> Lemmatization: 
 [('networks', 'network'), ('Deep', 'Deep'), ('learning', 'learning'), ('.', '.')]


------------------- Sentence 2 -------------------

In recent years, various methods have been proposed to

>> Tokens are: 
 ['In', 'recent', 'years', ',', 'various', 'methods', 'proposed']

>> Bigrams are: 
 [('In', 'recent'), ('recent', 'years'), ('years', ','), (',', 'various'), ('various', 'methods'), ('methods', 'proposed')]

>> Trigrams are: 
 [('In', 'recent', 'years'), ('recent', 'years', ','), ('years', ',', 'various'), (',', 'various', 'methods'), ('various', 'methods', 'proposed')]

>> POS Tags are: 
 [('In', 'IN'), ('recent', 'JJ'), ('years', 'NNS'), (',', ','), ('various', 'JJ'), ('methods', 'NNS'), ('proposed', 'VBD')]

>> Noun Phrases are: 
 ['recent years', 'various methods']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('recent', 'recent'), ('years', 'year'), (',', ','), ('various', 'variou'), ('methods', 'method'), ('proposed', 'propos')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('recent', 'recent'), ('years', 'year'), (',', ','), ('various', 'various'), ('methods', 'method'), ('proposed', 'propos')]

>> Lemmatization: 
 [('In', 'In'), ('recent', 'recent'), ('years', 'year'), (',', ','), ('various', 'various'), ('methods', 'method'), ('proposed', 'proposed')]



========================================== PARAGRAPH 308 ===========================================

automatically evaluate machine translation quality by comparing hypothesis translations with  

------------------- Sentence 1 -------------------

automatically evaluate machine translation quality by comparing hypothesis translations with

>> Tokens are: 
 ['automatically', 'evaluate', 'machine', 'translation', 'quality', 'comparing', 'hypothesis', 'translations']

>> Bigrams are: 
 [('automatically', 'evaluate'), ('evaluate', 'machine'), ('machine', 'translation'), ('translation', 'quality'), ('quality', 'comparing'), ('comparing', 'hypothesis'), ('hypothesis', 'translations')]

>> Trigrams are: 
 [('automatically', 'evaluate', 'machine'), ('evaluate', 'machine', 'translation'), ('machine', 'translation', 'quality'), ('translation', 'quality', 'comparing'), ('quality', 'comparing', 'hypothesis'), ('comparing', 'hypothesis', 'translations')]

>> POS Tags are: 
 [('automatically', 'RB'), ('evaluate', 'JJ'), ('machine', 'NN'), ('translation', 'NN'), ('quality', 'NN'), ('comparing', 'VBG'), ('hypothesis', 'NN'), ('translations', 'NNS')]

>> Noun Phrases are: 
 ['evaluate machine translation quality', 'hypothesis translations']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('automatically', 'automat'), ('evaluate', 'evalu'), ('machine', 'machin'), ('translation', 'translat'), ('quality', 'qualiti'), ('comparing', 'compar'), ('hypothesis', 'hypothesi'), ('translations', 'translat')]

>> Stemming using Snowball Stemmer: 
 [('automatically', 'automat'), ('evaluate', 'evalu'), ('machine', 'machin'), ('translation', 'translat'), ('quality', 'qualiti'), ('comparing', 'compar'), ('hypothesis', 'hypothesi'), ('translations', 'translat')]

>> Lemmatization: 
 [('automatically', 'automatically'), ('evaluate', 'evaluate'), ('machine', 'machine'), ('translation', 'translation'), ('quality', 'quality'), ('comparing', 'comparing'), ('hypothesis', 'hypothesis'), ('translations', 'translation')]



========================================== PARAGRAPH 309 ===========================================

reference translations. Examples of such methods are word error rate, position-independent  

------------------- Sentence 1 -------------------

reference translations.

>> Tokens are: 
 ['reference', 'translations', '.']

>> Bigrams are: 
 [('reference', 'translations'), ('translations', '.')]

>> Trigrams are: 
 [('reference', 'translations', '.')]

>> POS Tags are: 
 [('reference', 'NN'), ('translations', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['reference translations']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('reference', 'refer'), ('translations', 'translat'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('reference', 'refer'), ('translations', 'translat'), ('.', '.')]

>> Lemmatization: 
 [('reference', 'reference'), ('translations', 'translation'), ('.', '.')]


------------------- Sentence 2 -------------------

Examples of such methods are word error rate, position-independent

>> Tokens are: 
 ['Examples', 'methods', 'word', 'error', 'rate', ',', 'position-independent']

>> Bigrams are: 
 [('Examples', 'methods'), ('methods', 'word'), ('word', 'error'), ('error', 'rate'), ('rate', ','), (',', 'position-independent')]

>> Trigrams are: 
 [('Examples', 'methods', 'word'), ('methods', 'word', 'error'), ('word', 'error', 'rate'), ('error', 'rate', ','), ('rate', ',', 'position-independent')]

>> POS Tags are: 
 [('Examples', 'NNS'), ('methods', 'NNS'), ('word', 'NN'), ('error', 'NN'), ('rate', 'NN'), (',', ','), ('position-independent', 'NN')]

>> Noun Phrases are: 
 ['Examples methods word error rate', 'position-independent']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Examples', 'exampl'), ('methods', 'method'), ('word', 'word'), ('error', 'error'), ('rate', 'rate'), (',', ','), ('position-independent', 'position-independ')]

>> Stemming using Snowball Stemmer: 
 [('Examples', 'exampl'), ('methods', 'method'), ('word', 'word'), ('error', 'error'), ('rate', 'rate'), (',', ','), ('position-independent', 'position-independ')]

>> Lemmatization: 
 [('Examples', 'Examples'), ('methods', 'method'), ('word', 'word'), ('error', 'error'), ('rate', 'rate'), (',', ','), ('position-independent', 'position-independent')]



========================================== PARAGRAPH 310 ===========================================

word error rate (Tillmann et al., 1997) [37], generation string accuracy (Bangalore et al.,  

------------------- Sentence 1 -------------------

word error rate (Tillmann et al., 1997) [37], generation string accuracy (Bangalore et al.,

>> Tokens are: 
 ['word', 'error', 'rate', '(', 'Tillmann', 'et', 'al.', ',', '1997', ')', '[', '37', ']', ',', 'generation', 'string', 'accuracy', '(', 'Bangalore', 'et', 'al.', ',']

>> Bigrams are: 
 [('word', 'error'), ('error', 'rate'), ('rate', '('), ('(', 'Tillmann'), ('Tillmann', 'et'), ('et', 'al.'), ('al.', ','), (',', '1997'), ('1997', ')'), (')', '['), ('[', '37'), ('37', ']'), (']', ','), (',', 'generation'), ('generation', 'string'), ('string', 'accuracy'), ('accuracy', '('), ('(', 'Bangalore'), ('Bangalore', 'et'), ('et', 'al.'), ('al.', ',')]

>> Trigrams are: 
 [('word', 'error', 'rate'), ('error', 'rate', '('), ('rate', '(', 'Tillmann'), ('(', 'Tillmann', 'et'), ('Tillmann', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '1997'), (',', '1997', ')'), ('1997', ')', '['), (')', '[', '37'), ('[', '37', ']'), ('37', ']', ','), (']', ',', 'generation'), (',', 'generation', 'string'), ('generation', 'string', 'accuracy'), ('string', 'accuracy', '('), ('accuracy', '(', 'Bangalore'), ('(', 'Bangalore', 'et'), ('Bangalore', 'et', 'al.'), ('et', 'al.', ',')]

>> POS Tags are: 
 [('word', 'NN'), ('error', 'NN'), ('rate', 'NN'), ('(', '('), ('Tillmann', 'NNP'), ('et', 'RB'), ('al.', 'RB'), (',', ','), ('1997', 'CD'), (')', ')'), ('[', 'VBD'), ('37', 'CD'), (']', 'NN'), (',', ','), ('generation', 'NN'), ('string', 'VBG'), ('accuracy', 'NN'), ('(', '('), ('Bangalore', 'NNP'), ('et', 'FW'), ('al.', 'NN'), (',', ',')]

>> Noun Phrases are: 
 ['word error rate', 'Tillmann', ']', 'generation', 'accuracy', 'Bangalore', 'al.']

>> Named Entities are: 
 [('ORGANIZATION', 'Tillmann'), ('ORGANIZATION', 'Bangalore')] 

>> Stemming using Porter Stemmer: 
 [('word', 'word'), ('error', 'error'), ('rate', 'rate'), ('(', '('), ('Tillmann', 'tillmann'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('1997', '1997'), (')', ')'), ('[', '['), ('37', '37'), (']', ']'), (',', ','), ('generation', 'gener'), ('string', 'string'), ('accuracy', 'accuraci'), ('(', '('), ('Bangalore', 'bangalor'), ('et', 'et'), ('al.', 'al.'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('word', 'word'), ('error', 'error'), ('rate', 'rate'), ('(', '('), ('Tillmann', 'tillmann'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('1997', '1997'), (')', ')'), ('[', '['), ('37', '37'), (']', ']'), (',', ','), ('generation', 'generat'), ('string', 'string'), ('accuracy', 'accuraci'), ('(', '('), ('Bangalore', 'bangalor'), ('et', 'et'), ('al.', 'al.'), (',', ',')]

>> Lemmatization: 
 [('word', 'word'), ('error', 'error'), ('rate', 'rate'), ('(', '('), ('Tillmann', 'Tillmann'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('1997', '1997'), (')', ')'), ('[', '['), ('37', '37'), (']', ']'), (',', ','), ('generation', 'generation'), ('string', 'string'), ('accuracy', 'accuracy'), ('(', '('), ('Bangalore', 'Bangalore'), ('et', 'et'), ('al.', 'al.'), (',', ',')]



========================================== PARAGRAPH 311 ===========================================

2000) [38], multi-reference word error rate (Nießen et al., 2000) [39], BLEU score (Papineni  

------------------- Sentence 1 -------------------

2000) [38], multi-reference word error rate (Nießen et al., 2000) [39], BLEU score (Papineni

>> Tokens are: 
 ['2000', ')', '[', '38', ']', ',', 'multi-reference', 'word', 'error', 'rate', '(', 'Nießen', 'et', 'al.', ',', '2000', ')', '[', '39', ']', ',', 'BLEU', 'score', '(', 'Papineni']

>> Bigrams are: 
 [('2000', ')'), (')', '['), ('[', '38'), ('38', ']'), (']', ','), (',', 'multi-reference'), ('multi-reference', 'word'), ('word', 'error'), ('error', 'rate'), ('rate', '('), ('(', 'Nießen'), ('Nießen', 'et'), ('et', 'al.'), ('al.', ','), (',', '2000'), ('2000', ')'), (')', '['), ('[', '39'), ('39', ']'), (']', ','), (',', 'BLEU'), ('BLEU', 'score'), ('score', '('), ('(', 'Papineni')]

>> Trigrams are: 
 [('2000', ')', '['), (')', '[', '38'), ('[', '38', ']'), ('38', ']', ','), (']', ',', 'multi-reference'), (',', 'multi-reference', 'word'), ('multi-reference', 'word', 'error'), ('word', 'error', 'rate'), ('error', 'rate', '('), ('rate', '(', 'Nießen'), ('(', 'Nießen', 'et'), ('Nießen', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2000'), (',', '2000', ')'), ('2000', ')', '['), (')', '[', '39'), ('[', '39', ']'), ('39', ']', ','), (']', ',', 'BLEU'), (',', 'BLEU', 'score'), ('BLEU', 'score', '('), ('score', '(', 'Papineni')]

>> POS Tags are: 
 [('2000', 'CD'), (')', ')'), ('[', 'VBD'), ('38', 'CD'), (']', 'NN'), (',', ','), ('multi-reference', 'NN'), ('word', 'NN'), ('error', 'NN'), ('rate', 'NN'), ('(', '('), ('Nießen', 'NNP'), ('et', 'RB'), ('al.', 'RB'), (',', ','), ('2000', 'CD'), (')', ')'), ('[', 'VBD'), ('39', 'CD'), (']', 'NN'), (',', ','), ('BLEU', 'NNP'), ('score', 'NN'), ('(', '('), ('Papineni', 'NNP')]

>> Noun Phrases are: 
 [']', 'multi-reference word error rate', 'Nießen', ']', 'BLEU score', 'Papineni']

>> Named Entities are: 
 [('PERSON', 'Nießen'), ('ORGANIZATION', 'BLEU'), ('ORGANIZATION', 'Papineni')] 

>> Stemming using Porter Stemmer: 
 [('2000', '2000'), (')', ')'), ('[', '['), ('38', '38'), (']', ']'), (',', ','), ('multi-reference', 'multi-refer'), ('word', 'word'), ('error', 'error'), ('rate', 'rate'), ('(', '('), ('Nießen', 'nießen'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2000', '2000'), (')', ')'), ('[', '['), ('39', '39'), (']', ']'), (',', ','), ('BLEU', 'bleu'), ('score', 'score'), ('(', '('), ('Papineni', 'papineni')]

>> Stemming using Snowball Stemmer: 
 [('2000', '2000'), (')', ')'), ('[', '['), ('38', '38'), (']', ']'), (',', ','), ('multi-reference', 'multi-refer'), ('word', 'word'), ('error', 'error'), ('rate', 'rate'), ('(', '('), ('Nießen', 'nießen'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2000', '2000'), (')', ')'), ('[', '['), ('39', '39'), (']', ']'), (',', ','), ('BLEU', 'bleu'), ('score', 'score'), ('(', '('), ('Papineni', 'papineni')]

>> Lemmatization: 
 [('2000', '2000'), (')', ')'), ('[', '['), ('38', '38'), (']', ']'), (',', ','), ('multi-reference', 'multi-reference'), ('word', 'word'), ('error', 'error'), ('rate', 'rate'), ('(', '('), ('Nießen', 'Nießen'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2000', '2000'), (')', ')'), ('[', '['), ('39', '39'), (']', ']'), (',', ','), ('BLEU', 'BLEU'), ('score', 'score'), ('(', '('), ('Papineni', 'Papineni')]



========================================== PARAGRAPH 312 ===========================================

et al., 2002) [40], NIST score (Doddington, 2002) [41]  All these criteria try to approximate  

------------------- Sentence 1 -------------------

et al., 2002) [40], NIST score (Doddington, 2002) [41]  All these criteria try to approximate

>> Tokens are: 
 ['et', 'al.', ',', '2002', ')', '[', '40', ']', ',', 'NIST', 'score', '(', 'Doddington', ',', '2002', ')', '[', '41', ']', 'All', 'criteria', 'try', 'approximate']

>> Bigrams are: 
 [('et', 'al.'), ('al.', ','), (',', '2002'), ('2002', ')'), (')', '['), ('[', '40'), ('40', ']'), (']', ','), (',', 'NIST'), ('NIST', 'score'), ('score', '('), ('(', 'Doddington'), ('Doddington', ','), (',', '2002'), ('2002', ')'), (')', '['), ('[', '41'), ('41', ']'), (']', 'All'), ('All', 'criteria'), ('criteria', 'try'), ('try', 'approximate')]

>> Trigrams are: 
 [('et', 'al.', ','), ('al.', ',', '2002'), (',', '2002', ')'), ('2002', ')', '['), (')', '[', '40'), ('[', '40', ']'), ('40', ']', ','), (']', ',', 'NIST'), (',', 'NIST', 'score'), ('NIST', 'score', '('), ('score', '(', 'Doddington'), ('(', 'Doddington', ','), ('Doddington', ',', '2002'), (',', '2002', ')'), ('2002', ')', '['), (')', '[', '41'), ('[', '41', ']'), ('41', ']', 'All'), (']', 'All', 'criteria'), ('All', 'criteria', 'try'), ('criteria', 'try', 'approximate')]

>> POS Tags are: 
 [('et', 'NN'), ('al.', 'NN'), (',', ','), ('2002', 'CD'), (')', ')'), ('[', 'VBD'), ('40', 'CD'), (']', 'NN'), (',', ','), ('NIST', 'NNP'), ('score', 'NN'), ('(', '('), ('Doddington', 'NNP'), (',', ','), ('2002', 'CD'), (')', ')'), ('[', 'VBD'), ('41', 'CD'), (']', 'NNP'), ('All', 'NNP'), ('criteria', 'NNS'), ('try', 'VBP'), ('approximate', 'NN')]

>> Noun Phrases are: 
 ['et al.', ']', 'NIST score', 'Doddington', '] All criteria', 'approximate']

>> Named Entities are: 
 [('ORGANIZATION', 'NIST'), ('PERSON', 'Doddington')] 

>> Stemming using Porter Stemmer: 
 [('et', 'et'), ('al.', 'al.'), (',', ','), ('2002', '2002'), (')', ')'), ('[', '['), ('40', '40'), (']', ']'), (',', ','), ('NIST', 'nist'), ('score', 'score'), ('(', '('), ('Doddington', 'doddington'), (',', ','), ('2002', '2002'), (')', ')'), ('[', '['), ('41', '41'), (']', ']'), ('All', 'all'), ('criteria', 'criteria'), ('try', 'tri'), ('approximate', 'approxim')]

>> Stemming using Snowball Stemmer: 
 [('et', 'et'), ('al.', 'al.'), (',', ','), ('2002', '2002'), (')', ')'), ('[', '['), ('40', '40'), (']', ']'), (',', ','), ('NIST', 'nist'), ('score', 'score'), ('(', '('), ('Doddington', 'doddington'), (',', ','), ('2002', '2002'), (')', ')'), ('[', '['), ('41', '41'), (']', ']'), ('All', 'all'), ('criteria', 'criteria'), ('try', 'tri'), ('approximate', 'approxim')]

>> Lemmatization: 
 [('et', 'et'), ('al.', 'al.'), (',', ','), ('2002', '2002'), (')', ')'), ('[', '['), ('40', '40'), (']', ']'), (',', ','), ('NIST', 'NIST'), ('score', 'score'), ('(', '('), ('Doddington', 'Doddington'), (',', ','), ('2002', '2002'), (')', ')'), ('[', '['), ('41', '41'), (']', ']'), ('All', 'All'), ('criteria', 'criterion'), ('try', 'try'), ('approximate', 'approximate')]



========================================== PARAGRAPH 313 ===========================================

human assessment and often achieve an astonishing degree of correlation to human subjective  

------------------- Sentence 1 -------------------

human assessment and often achieve an astonishing degree of correlation to human subjective

>> Tokens are: 
 ['human', 'assessment', 'often', 'achieve', 'astonishing', 'degree', 'correlation', 'human', 'subjective']

>> Bigrams are: 
 [('human', 'assessment'), ('assessment', 'often'), ('often', 'achieve'), ('achieve', 'astonishing'), ('astonishing', 'degree'), ('degree', 'correlation'), ('correlation', 'human'), ('human', 'subjective')]

>> Trigrams are: 
 [('human', 'assessment', 'often'), ('assessment', 'often', 'achieve'), ('often', 'achieve', 'astonishing'), ('achieve', 'astonishing', 'degree'), ('astonishing', 'degree', 'correlation'), ('degree', 'correlation', 'human'), ('correlation', 'human', 'subjective')]

>> POS Tags are: 
 [('human', 'JJ'), ('assessment', 'NN'), ('often', 'RB'), ('achieve', 'VBP'), ('astonishing', 'VBG'), ('degree', 'JJ'), ('correlation', 'NN'), ('human', 'NN'), ('subjective', 'NN')]

>> Noun Phrases are: 
 ['human assessment', 'degree correlation human subjective']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('human', 'human'), ('assessment', 'assess'), ('often', 'often'), ('achieve', 'achiev'), ('astonishing', 'astonish'), ('degree', 'degre'), ('correlation', 'correl'), ('human', 'human'), ('subjective', 'subject')]

>> Stemming using Snowball Stemmer: 
 [('human', 'human'), ('assessment', 'assess'), ('often', 'often'), ('achieve', 'achiev'), ('astonishing', 'astonish'), ('degree', 'degre'), ('correlation', 'correl'), ('human', 'human'), ('subjective', 'subject')]

>> Lemmatization: 
 [('human', 'human'), ('assessment', 'assessment'), ('often', 'often'), ('achieve', 'achieve'), ('astonishing', 'astonishing'), ('degree', 'degree'), ('correlation', 'correlation'), ('human', 'human'), ('subjective', 'subjective')]



========================================== PARAGRAPH 314 ===========================================

evaluation of fluency and adequacy (Papineni et al., 2001; Doddington, 2002) [42][43].   

------------------- Sentence 1 -------------------

evaluation of fluency and adequacy (Papineni et al., 2001; Doddington, 2002) [42][43].

>> Tokens are: 
 ['evaluation', 'fluency', 'adequacy', '(', 'Papineni', 'et', 'al.', ',', '2001', ';', 'Doddington', ',', '2002', ')', '[', '42', ']', '[', '43', ']', '.']

>> Bigrams are: 
 [('evaluation', 'fluency'), ('fluency', 'adequacy'), ('adequacy', '('), ('(', 'Papineni'), ('Papineni', 'et'), ('et', 'al.'), ('al.', ','), (',', '2001'), ('2001', ';'), (';', 'Doddington'), ('Doddington', ','), (',', '2002'), ('2002', ')'), (')', '['), ('[', '42'), ('42', ']'), (']', '['), ('[', '43'), ('43', ']'), (']', '.')]

>> Trigrams are: 
 [('evaluation', 'fluency', 'adequacy'), ('fluency', 'adequacy', '('), ('adequacy', '(', 'Papineni'), ('(', 'Papineni', 'et'), ('Papineni', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2001'), (',', '2001', ';'), ('2001', ';', 'Doddington'), (';', 'Doddington', ','), ('Doddington', ',', '2002'), (',', '2002', ')'), ('2002', ')', '['), (')', '[', '42'), ('[', '42', ']'), ('42', ']', '['), (']', '[', '43'), ('[', '43', ']'), ('43', ']', '.')]

>> POS Tags are: 
 [('evaluation', 'NN'), ('fluency', 'NN'), ('adequacy', 'NN'), ('(', '('), ('Papineni', 'NNP'), ('et', 'RB'), ('al.', 'RB'), (',', ','), ('2001', 'CD'), (';', ':'), ('Doddington', 'NNP'), (',', ','), ('2002', 'CD'), (')', ')'), ('[', 'VBD'), ('42', 'CD'), (']', 'NNP'), ('[', 'VBD'), ('43', 'CD'), (']', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['evaluation fluency adequacy', 'Papineni', 'Doddington', ']', ']']

>> Named Entities are: 
 [('PERSON', 'Papineni'), ('GPE', 'Doddington')] 

>> Stemming using Porter Stemmer: 
 [('evaluation', 'evalu'), ('fluency', 'fluenci'), ('adequacy', 'adequaci'), ('(', '('), ('Papineni', 'papineni'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2001', '2001'), (';', ';'), ('Doddington', 'doddington'), (',', ','), ('2002', '2002'), (')', ')'), ('[', '['), ('42', '42'), (']', ']'), ('[', '['), ('43', '43'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('evaluation', 'evalu'), ('fluency', 'fluenci'), ('adequacy', 'adequaci'), ('(', '('), ('Papineni', 'papineni'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2001', '2001'), (';', ';'), ('Doddington', 'doddington'), (',', ','), ('2002', '2002'), (')', ')'), ('[', '['), ('42', '42'), (']', ']'), ('[', '['), ('43', '43'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('evaluation', 'evaluation'), ('fluency', 'fluency'), ('adequacy', 'adequacy'), ('(', '('), ('Papineni', 'Papineni'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2001', '2001'), (';', ';'), ('Doddington', 'Doddington'), (',', ','), ('2002', '2002'), (')', ')'), ('[', '['), ('42', '42'), (']', ']'), ('[', '['), ('43', '43'), (']', ']'), ('.', '.')]



========================================== PARAGRAPH 315 ===========================================

6.2 Text Categorization   

------------------- Sentence 1 -------------------

6.2 Text Categorization

>> Tokens are: 
 ['6.2', 'Text', 'Categorization']

>> Bigrams are: 
 [('6.2', 'Text'), ('Text', 'Categorization')]

>> Trigrams are: 
 [('6.2', 'Text', 'Categorization')]

>> POS Tags are: 
 [('6.2', 'CD'), ('Text', 'NNP'), ('Categorization', 'NN')]

>> Noun Phrases are: 
 ['Text Categorization']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('6.2', '6.2'), ('Text', 'text'), ('Categorization', 'categor')]

>> Stemming using Snowball Stemmer: 
 [('6.2', '6.2'), ('Text', 'text'), ('Categorization', 'categor')]

>> Lemmatization: 
 [('6.2', '6.2'), ('Text', 'Text'), ('Categorization', 'Categorization')]



========================================== PARAGRAPH 316 ===========================================

Categorization systems inputs a large flow of data like official documents, military casualty  

------------------- Sentence 1 -------------------

Categorization systems inputs a large flow of data like official documents, military casualty

>> Tokens are: 
 ['Categorization', 'systems', 'inputs', 'large', 'flow', 'data', 'like', 'official', 'documents', ',', 'military', 'casualty']

>> Bigrams are: 
 [('Categorization', 'systems'), ('systems', 'inputs'), ('inputs', 'large'), ('large', 'flow'), ('flow', 'data'), ('data', 'like'), ('like', 'official'), ('official', 'documents'), ('documents', ','), (',', 'military'), ('military', 'casualty')]

>> Trigrams are: 
 [('Categorization', 'systems', 'inputs'), ('systems', 'inputs', 'large'), ('inputs', 'large', 'flow'), ('large', 'flow', 'data'), ('flow', 'data', 'like'), ('data', 'like', 'official'), ('like', 'official', 'documents'), ('official', 'documents', ','), ('documents', ',', 'military'), (',', 'military', 'casualty')]

>> POS Tags are: 
 [('Categorization', 'NNP'), ('systems', 'NNS'), ('inputs', 'VBZ'), ('large', 'JJ'), ('flow', 'JJ'), ('data', 'NNS'), ('like', 'IN'), ('official', 'JJ'), ('documents', 'NNS'), (',', ','), ('military', 'JJ'), ('casualty', 'NN')]

>> Noun Phrases are: 
 ['Categorization systems', 'large flow data', 'official documents', 'military casualty']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Categorization', 'categor'), ('systems', 'system'), ('inputs', 'input'), ('large', 'larg'), ('flow', 'flow'), ('data', 'data'), ('like', 'like'), ('official', 'offici'), ('documents', 'document'), (',', ','), ('military', 'militari'), ('casualty', 'casualti')]

>> Stemming using Snowball Stemmer: 
 [('Categorization', 'categor'), ('systems', 'system'), ('inputs', 'input'), ('large', 'larg'), ('flow', 'flow'), ('data', 'data'), ('like', 'like'), ('official', 'offici'), ('documents', 'document'), (',', ','), ('military', 'militari'), ('casualty', 'casualti')]

>> Lemmatization: 
 [('Categorization', 'Categorization'), ('systems', 'system'), ('inputs', 'input'), ('large', 'large'), ('flow', 'flow'), ('data', 'data'), ('like', 'like'), ('official', 'official'), ('documents', 'document'), (',', ','), ('military', 'military'), ('casualty', 'casualty')]



========================================== PARAGRAPH 317 ===========================================

reports, market data, newswires etc. and assign them to predefined categories or indices. For  

------------------- Sentence 1 -------------------

reports, market data, newswires etc.

>> Tokens are: 
 ['reports', ',', 'market', 'data', ',', 'newswires', 'etc', '.']

>> Bigrams are: 
 [('reports', ','), (',', 'market'), ('market', 'data'), ('data', ','), (',', 'newswires'), ('newswires', 'etc'), ('etc', '.')]

>> Trigrams are: 
 [('reports', ',', 'market'), (',', 'market', 'data'), ('market', 'data', ','), ('data', ',', 'newswires'), (',', 'newswires', 'etc'), ('newswires', 'etc', '.')]

>> POS Tags are: 
 [('reports', 'NNS'), (',', ','), ('market', 'NN'), ('data', 'NNS'), (',', ','), ('newswires', 'NNS'), ('etc', 'VBP'), ('.', '.')]

>> Noun Phrases are: 
 ['reports', 'market data', 'newswires']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('reports', 'report'), (',', ','), ('market', 'market'), ('data', 'data'), (',', ','), ('newswires', 'newswir'), ('etc', 'etc'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('reports', 'report'), (',', ','), ('market', 'market'), ('data', 'data'), (',', ','), ('newswires', 'newswir'), ('etc', 'etc'), ('.', '.')]

>> Lemmatization: 
 [('reports', 'report'), (',', ','), ('market', 'market'), ('data', 'data'), (',', ','), ('newswires', 'newswires'), ('etc', 'etc'), ('.', '.')]


------------------- Sentence 2 -------------------

and assign them to predefined categories or indices.

>> Tokens are: 
 ['assign', 'predefined', 'categories', 'indices', '.']

>> Bigrams are: 
 [('assign', 'predefined'), ('predefined', 'categories'), ('categories', 'indices'), ('indices', '.')]

>> Trigrams are: 
 [('assign', 'predefined', 'categories'), ('predefined', 'categories', 'indices'), ('categories', 'indices', '.')]

>> POS Tags are: 
 [('assign', 'NN'), ('predefined', 'VBD'), ('categories', 'NNS'), ('indices', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['assign', 'categories indices']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('assign', 'assign'), ('predefined', 'predefin'), ('categories', 'categori'), ('indices', 'indic'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('assign', 'assign'), ('predefined', 'predefin'), ('categories', 'categori'), ('indices', 'indic'), ('.', '.')]

>> Lemmatization: 
 [('assign', 'assign'), ('predefined', 'predefined'), ('categories', 'category'), ('indices', 'index'), ('.', '.')]


------------------- Sentence 3 -------------------

For

>> Tokens are: 
 ['For']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('For', 'IN')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('For', 'for')]

>> Stemming using Snowball Stemmer: 
 [('For', 'for')]

>> Lemmatization: 
 [('For', 'For')]



========================================== PARAGRAPH 318 ===========================================

example, The Carnegie Group’s Construe system (Hayes PJ ,Westein ; 1991)[44] , inputs  

------------------- Sentence 1 -------------------

example, The Carnegie Group’s Construe system (Hayes PJ ,Westein ; 1991)[44] , inputs

>> Tokens are: 
 ['example', ',', 'The', 'Carnegie', 'Group', '’', 'Construe', 'system', '(', 'Hayes', 'PJ', ',', 'Westein', ';', '1991', ')', '[', '44', ']', ',', 'inputs']

>> Bigrams are: 
 [('example', ','), (',', 'The'), ('The', 'Carnegie'), ('Carnegie', 'Group'), ('Group', '’'), ('’', 'Construe'), ('Construe', 'system'), ('system', '('), ('(', 'Hayes'), ('Hayes', 'PJ'), ('PJ', ','), (',', 'Westein'), ('Westein', ';'), (';', '1991'), ('1991', ')'), (')', '['), ('[', '44'), ('44', ']'), (']', ','), (',', 'inputs')]

>> Trigrams are: 
 [('example', ',', 'The'), (',', 'The', 'Carnegie'), ('The', 'Carnegie', 'Group'), ('Carnegie', 'Group', '’'), ('Group', '’', 'Construe'), ('’', 'Construe', 'system'), ('Construe', 'system', '('), ('system', '(', 'Hayes'), ('(', 'Hayes', 'PJ'), ('Hayes', 'PJ', ','), ('PJ', ',', 'Westein'), (',', 'Westein', ';'), ('Westein', ';', '1991'), (';', '1991', ')'), ('1991', ')', '['), (')', '[', '44'), ('[', '44', ']'), ('44', ']', ','), (']', ',', 'inputs')]

>> POS Tags are: 
 [('example', 'NN'), (',', ','), ('The', 'DT'), ('Carnegie', 'NNP'), ('Group', 'NNP'), ('’', 'NNP'), ('Construe', 'NNP'), ('system', 'NN'), ('(', '('), ('Hayes', 'NNP'), ('PJ', 'NNP'), (',', ','), ('Westein', 'NNP'), (';', ':'), ('1991', 'CD'), (')', ')'), ('[', 'VBD'), ('44', 'CD'), (']', 'NN'), (',', ','), ('inputs', 'NNS')]

>> Noun Phrases are: 
 ['example', 'The Carnegie Group ’ Construe system', 'Hayes PJ', 'Westein', ']', 'inputs']

>> Named Entities are: 
 [('ORGANIZATION', 'Carnegie Group'), ('PERSON', 'Hayes PJ'), ('GPE', 'Westein')] 

>> Stemming using Porter Stemmer: 
 [('example', 'exampl'), (',', ','), ('The', 'the'), ('Carnegie', 'carnegi'), ('Group', 'group'), ('’', '’'), ('Construe', 'constru'), ('system', 'system'), ('(', '('), ('Hayes', 'hay'), ('PJ', 'pj'), (',', ','), ('Westein', 'westein'), (';', ';'), ('1991', '1991'), (')', ')'), ('[', '['), ('44', '44'), (']', ']'), (',', ','), ('inputs', 'input')]

>> Stemming using Snowball Stemmer: 
 [('example', 'exampl'), (',', ','), ('The', 'the'), ('Carnegie', 'carnegi'), ('Group', 'group'), ('’', '’'), ('Construe', 'constru'), ('system', 'system'), ('(', '('), ('Hayes', 'hay'), ('PJ', 'pj'), (',', ','), ('Westein', 'westein'), (';', ';'), ('1991', '1991'), (')', ')'), ('[', '['), ('44', '44'), (']', ']'), (',', ','), ('inputs', 'input')]

>> Lemmatization: 
 [('example', 'example'), (',', ','), ('The', 'The'), ('Carnegie', 'Carnegie'), ('Group', 'Group'), ('’', '’'), ('Construe', 'Construe'), ('system', 'system'), ('(', '('), ('Hayes', 'Hayes'), ('PJ', 'PJ'), (',', ','), ('Westein', 'Westein'), (';', ';'), ('1991', '1991'), (')', ')'), ('[', '['), ('44', '44'), (']', ']'), (',', ','), ('inputs', 'input')]



========================================== PARAGRAPH 319 ===========================================

Reuters articles and saves much time by doing the work that is to be done by staff or human 

------------------- Sentence 1 -------------------

Reuters articles and saves much time by doing the work that is to be done by staff or human

>> Tokens are: 
 ['Reuters', 'articles', 'saves', 'much', 'time', 'work', 'done', 'staff', 'human']

>> Bigrams are: 
 [('Reuters', 'articles'), ('articles', 'saves'), ('saves', 'much'), ('much', 'time'), ('time', 'work'), ('work', 'done'), ('done', 'staff'), ('staff', 'human')]

>> Trigrams are: 
 [('Reuters', 'articles', 'saves'), ('articles', 'saves', 'much'), ('saves', 'much', 'time'), ('much', 'time', 'work'), ('time', 'work', 'done'), ('work', 'done', 'staff'), ('done', 'staff', 'human')]

>> POS Tags are: 
 [('Reuters', 'NNS'), ('articles', 'VBP'), ('saves', 'NNS'), ('much', 'JJ'), ('time', 'NN'), ('work', 'NN'), ('done', 'VBN'), ('staff', 'NN'), ('human', 'NN')]

>> Noun Phrases are: 
 ['Reuters', 'saves', 'much time work', 'staff human']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Reuters', 'reuter'), ('articles', 'articl'), ('saves', 'save'), ('much', 'much'), ('time', 'time'), ('work', 'work'), ('done', 'done'), ('staff', 'staff'), ('human', 'human')]

>> Stemming using Snowball Stemmer: 
 [('Reuters', 'reuter'), ('articles', 'articl'), ('saves', 'save'), ('much', 'much'), ('time', 'time'), ('work', 'work'), ('done', 'done'), ('staff', 'staff'), ('human', 'human')]

>> Lemmatization: 
 [('Reuters', 'Reuters'), ('articles', 'article'), ('saves', 'save'), ('much', 'much'), ('time', 'time'), ('work', 'work'), ('done', 'done'), ('staff', 'staff'), ('human', 'human')]



========================================== PARAGRAPH 320 ===========================================

indexers. Some companies have been using categorization systems to categorize trouble  

------------------- Sentence 1 -------------------

indexers.

>> Tokens are: 
 ['indexers', '.']

>> Bigrams are: 
 [('indexers', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('indexers', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['indexers']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('indexers', 'index'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('indexers', 'index'), ('.', '.')]

>> Lemmatization: 
 [('indexers', 'indexer'), ('.', '.')]


------------------- Sentence 2 -------------------

Some companies have been using categorization systems to categorize trouble

>> Tokens are: 
 ['Some', 'companies', 'using', 'categorization', 'systems', 'categorize', 'trouble']

>> Bigrams are: 
 [('Some', 'companies'), ('companies', 'using'), ('using', 'categorization'), ('categorization', 'systems'), ('systems', 'categorize'), ('categorize', 'trouble')]

>> Trigrams are: 
 [('Some', 'companies', 'using'), ('companies', 'using', 'categorization'), ('using', 'categorization', 'systems'), ('categorization', 'systems', 'categorize'), ('systems', 'categorize', 'trouble')]

>> POS Tags are: 
 [('Some', 'DT'), ('companies', 'NNS'), ('using', 'VBG'), ('categorization', 'NN'), ('systems', 'NNS'), ('categorize', 'VBP'), ('trouble', 'NN')]

>> Noun Phrases are: 
 ['Some companies', 'categorization systems', 'trouble']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Some', 'some'), ('companies', 'compani'), ('using', 'use'), ('categorization', 'categor'), ('systems', 'system'), ('categorize', 'categor'), ('trouble', 'troubl')]

>> Stemming using Snowball Stemmer: 
 [('Some', 'some'), ('companies', 'compani'), ('using', 'use'), ('categorization', 'categor'), ('systems', 'system'), ('categorize', 'categor'), ('trouble', 'troubl')]

>> Lemmatization: 
 [('Some', 'Some'), ('companies', 'company'), ('using', 'using'), ('categorization', 'categorization'), ('systems', 'system'), ('categorize', 'categorize'), ('trouble', 'trouble')]



========================================== PARAGRAPH 321 ===========================================

tickets or complaint requests and routing to the appropriate desks. Another application of text  

------------------- Sentence 1 -------------------

tickets or complaint requests and routing to the appropriate desks.

>> Tokens are: 
 ['tickets', 'complaint', 'requests', 'routing', 'appropriate', 'desks', '.']

>> Bigrams are: 
 [('tickets', 'complaint'), ('complaint', 'requests'), ('requests', 'routing'), ('routing', 'appropriate'), ('appropriate', 'desks'), ('desks', '.')]

>> Trigrams are: 
 [('tickets', 'complaint', 'requests'), ('complaint', 'requests', 'routing'), ('requests', 'routing', 'appropriate'), ('routing', 'appropriate', 'desks'), ('appropriate', 'desks', '.')]

>> POS Tags are: 
 [('tickets', 'NNS'), ('complaint', 'VBP'), ('requests', 'NNS'), ('routing', 'VBG'), ('appropriate', 'JJ'), ('desks', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['tickets', 'requests', 'appropriate desks']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('tickets', 'ticket'), ('complaint', 'complaint'), ('requests', 'request'), ('routing', 'rout'), ('appropriate', 'appropri'), ('desks', 'desk'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('tickets', 'ticket'), ('complaint', 'complaint'), ('requests', 'request'), ('routing', 'rout'), ('appropriate', 'appropri'), ('desks', 'desk'), ('.', '.')]

>> Lemmatization: 
 [('tickets', 'ticket'), ('complaint', 'complaint'), ('requests', 'request'), ('routing', 'routing'), ('appropriate', 'appropriate'), ('desks', 'desk'), ('.', '.')]


------------------- Sentence 2 -------------------

Another application of text

>> Tokens are: 
 ['Another', 'application', 'text']

>> Bigrams are: 
 [('Another', 'application'), ('application', 'text')]

>> Trigrams are: 
 [('Another', 'application', 'text')]

>> POS Tags are: 
 [('Another', 'DT'), ('application', 'NN'), ('text', 'NN')]

>> Noun Phrases are: 
 ['Another application text']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Another', 'anoth'), ('application', 'applic'), ('text', 'text')]

>> Stemming using Snowball Stemmer: 
 [('Another', 'anoth'), ('application', 'applic'), ('text', 'text')]

>> Lemmatization: 
 [('Another', 'Another'), ('application', 'application'), ('text', 'text')]



========================================== PARAGRAPH 322 ===========================================

categorization is email spam filters. Spam filters is becoming important as the first line of  

------------------- Sentence 1 -------------------

categorization is email spam filters.

>> Tokens are: 
 ['categorization', 'email', 'spam', 'filters', '.']

>> Bigrams are: 
 [('categorization', 'email'), ('email', 'spam'), ('spam', 'filters'), ('filters', '.')]

>> Trigrams are: 
 [('categorization', 'email', 'spam'), ('email', 'spam', 'filters'), ('spam', 'filters', '.')]

>> POS Tags are: 
 [('categorization', 'NN'), ('email', 'NN'), ('spam', 'NN'), ('filters', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['categorization email spam filters']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('categorization', 'categor'), ('email', 'email'), ('spam', 'spam'), ('filters', 'filter'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('categorization', 'categor'), ('email', 'email'), ('spam', 'spam'), ('filters', 'filter'), ('.', '.')]

>> Lemmatization: 
 [('categorization', 'categorization'), ('email', 'email'), ('spam', 'spam'), ('filters', 'filter'), ('.', '.')]


------------------- Sentence 2 -------------------

Spam filters is becoming important as the first line of

>> Tokens are: 
 ['Spam', 'filters', 'becoming', 'important', 'first', 'line']

>> Bigrams are: 
 [('Spam', 'filters'), ('filters', 'becoming'), ('becoming', 'important'), ('important', 'first'), ('first', 'line')]

>> Trigrams are: 
 [('Spam', 'filters', 'becoming'), ('filters', 'becoming', 'important'), ('becoming', 'important', 'first'), ('important', 'first', 'line')]

>> POS Tags are: 
 [('Spam', 'NNP'), ('filters', 'NNS'), ('becoming', 'VBG'), ('important', 'JJ'), ('first', 'JJ'), ('line', 'NN')]

>> Noun Phrases are: 
 ['Spam filters', 'important first line']

>> Named Entities are: 
 [('GPE', 'Spam')] 

>> Stemming using Porter Stemmer: 
 [('Spam', 'spam'), ('filters', 'filter'), ('becoming', 'becom'), ('important', 'import'), ('first', 'first'), ('line', 'line')]

>> Stemming using Snowball Stemmer: 
 [('Spam', 'spam'), ('filters', 'filter'), ('becoming', 'becom'), ('important', 'import'), ('first', 'first'), ('line', 'line')]

>> Lemmatization: 
 [('Spam', 'Spam'), ('filters', 'filter'), ('becoming', 'becoming'), ('important', 'important'), ('first', 'first'), ('line', 'line')]



========================================== PARAGRAPH 323 ===========================================

defence against the unwanted emails. A false negative and false positive issues of spam filters  

------------------- Sentence 1 -------------------

defence against the unwanted emails.

>> Tokens are: 
 ['defence', 'unwanted', 'emails', '.']

>> Bigrams are: 
 [('defence', 'unwanted'), ('unwanted', 'emails'), ('emails', '.')]

>> Trigrams are: 
 [('defence', 'unwanted', 'emails'), ('unwanted', 'emails', '.')]

>> POS Tags are: 
 [('defence', 'NN'), ('unwanted', 'VBD'), ('emails', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['defence', 'emails']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('defence', 'defenc'), ('unwanted', 'unwant'), ('emails', 'email'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('defence', 'defenc'), ('unwanted', 'unwant'), ('emails', 'email'), ('.', '.')]

>> Lemmatization: 
 [('defence', 'defence'), ('unwanted', 'unwanted'), ('emails', 'email'), ('.', '.')]


------------------- Sentence 2 -------------------

A false negative and false positive issues of spam filters

>> Tokens are: 
 ['A', 'false', 'negative', 'false', 'positive', 'issues', 'spam', 'filters']

>> Bigrams are: 
 [('A', 'false'), ('false', 'negative'), ('negative', 'false'), ('false', 'positive'), ('positive', 'issues'), ('issues', 'spam'), ('spam', 'filters')]

>> Trigrams are: 
 [('A', 'false', 'negative'), ('false', 'negative', 'false'), ('negative', 'false', 'positive'), ('false', 'positive', 'issues'), ('positive', 'issues', 'spam'), ('issues', 'spam', 'filters')]

>> POS Tags are: 
 [('A', 'DT'), ('false', 'JJ'), ('negative', 'JJ'), ('false', 'JJ'), ('positive', 'JJ'), ('issues', 'NNS'), ('spam', 'VBP'), ('filters', 'NNS')]

>> Noun Phrases are: 
 ['A false negative false positive issues', 'filters']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('A', 'a'), ('false', 'fals'), ('negative', 'neg'), ('false', 'fals'), ('positive', 'posit'), ('issues', 'issu'), ('spam', 'spam'), ('filters', 'filter')]

>> Stemming using Snowball Stemmer: 
 [('A', 'a'), ('false', 'fals'), ('negative', 'negat'), ('false', 'fals'), ('positive', 'posit'), ('issues', 'issu'), ('spam', 'spam'), ('filters', 'filter')]

>> Lemmatization: 
 [('A', 'A'), ('false', 'false'), ('negative', 'negative'), ('false', 'false'), ('positive', 'positive'), ('issues', 'issue'), ('spam', 'spam'), ('filters', 'filter')]



========================================== PARAGRAPH 324 ===========================================

are at the heart of NLP technology, its brought down to the challenge of extracting meaning  

------------------- Sentence 1 -------------------

are at the heart of NLP technology, its brought down to the challenge of extracting meaning

>> Tokens are: 
 ['heart', 'NLP', 'technology', ',', 'brought', 'challenge', 'extracting', 'meaning']

>> Bigrams are: 
 [('heart', 'NLP'), ('NLP', 'technology'), ('technology', ','), (',', 'brought'), ('brought', 'challenge'), ('challenge', 'extracting'), ('extracting', 'meaning')]

>> Trigrams are: 
 [('heart', 'NLP', 'technology'), ('NLP', 'technology', ','), ('technology', ',', 'brought'), (',', 'brought', 'challenge'), ('brought', 'challenge', 'extracting'), ('challenge', 'extracting', 'meaning')]

>> POS Tags are: 
 [('heart', 'NN'), ('NLP', 'NNP'), ('technology', 'NN'), (',', ','), ('brought', 'VBD'), ('challenge', 'NN'), ('extracting', 'VBG'), ('meaning', 'NN')]

>> Noun Phrases are: 
 ['heart NLP technology', 'challenge', 'meaning']

>> Named Entities are: 
 [('ORGANIZATION', 'NLP')] 

>> Stemming using Porter Stemmer: 
 [('heart', 'heart'), ('NLP', 'nlp'), ('technology', 'technolog'), (',', ','), ('brought', 'brought'), ('challenge', 'challeng'), ('extracting', 'extract'), ('meaning', 'mean')]

>> Stemming using Snowball Stemmer: 
 [('heart', 'heart'), ('NLP', 'nlp'), ('technology', 'technolog'), (',', ','), ('brought', 'brought'), ('challenge', 'challeng'), ('extracting', 'extract'), ('meaning', 'mean')]

>> Lemmatization: 
 [('heart', 'heart'), ('NLP', 'NLP'), ('technology', 'technology'), (',', ','), ('brought', 'brought'), ('challenge', 'challenge'), ('extracting', 'extracting'), ('meaning', 'meaning')]



========================================== PARAGRAPH 325 ===========================================

from strings of text. A filtering solution that is applied to an email system uses a set of  

------------------- Sentence 1 -------------------

from strings of text.

>> Tokens are: 
 ['strings', 'text', '.']

>> Bigrams are: 
 [('strings', 'text'), ('text', '.')]

>> Trigrams are: 
 [('strings', 'text', '.')]

>> POS Tags are: 
 [('strings', 'NNS'), ('text', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['strings text']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('strings', 'string'), ('text', 'text'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('strings', 'string'), ('text', 'text'), ('.', '.')]

>> Lemmatization: 
 [('strings', 'string'), ('text', 'text'), ('.', '.')]


------------------- Sentence 2 -------------------

A filtering solution that is applied to an email system uses a set of

>> Tokens are: 
 ['A', 'filtering', 'solution', 'applied', 'email', 'system', 'uses', 'set']

>> Bigrams are: 
 [('A', 'filtering'), ('filtering', 'solution'), ('solution', 'applied'), ('applied', 'email'), ('email', 'system'), ('system', 'uses'), ('uses', 'set')]

>> Trigrams are: 
 [('A', 'filtering', 'solution'), ('filtering', 'solution', 'applied'), ('solution', 'applied', 'email'), ('applied', 'email', 'system'), ('email', 'system', 'uses'), ('system', 'uses', 'set')]

>> POS Tags are: 
 [('A', 'DT'), ('filtering', 'JJ'), ('solution', 'NN'), ('applied', 'VBN'), ('email', 'NN'), ('system', 'NN'), ('uses', 'VBZ'), ('set', 'VBN')]

>> Noun Phrases are: 
 ['A filtering solution', 'email system']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('A', 'a'), ('filtering', 'filter'), ('solution', 'solut'), ('applied', 'appli'), ('email', 'email'), ('system', 'system'), ('uses', 'use'), ('set', 'set')]

>> Stemming using Snowball Stemmer: 
 [('A', 'a'), ('filtering', 'filter'), ('solution', 'solut'), ('applied', 'appli'), ('email', 'email'), ('system', 'system'), ('uses', 'use'), ('set', 'set')]

>> Lemmatization: 
 [('A', 'A'), ('filtering', 'filtering'), ('solution', 'solution'), ('applied', 'applied'), ('email', 'email'), ('system', 'system'), ('uses', 'us'), ('set', 'set')]



========================================== PARAGRAPH 326 ===========================================

protocols to determine which of the incoming messages are spam and which are not. There  

------------------- Sentence 1 -------------------

protocols to determine which of the incoming messages are spam and which are not.

>> Tokens are: 
 ['protocols', 'determine', 'incoming', 'messages', 'spam', '.']

>> Bigrams are: 
 [('protocols', 'determine'), ('determine', 'incoming'), ('incoming', 'messages'), ('messages', 'spam'), ('spam', '.')]

>> Trigrams are: 
 [('protocols', 'determine', 'incoming'), ('determine', 'incoming', 'messages'), ('incoming', 'messages', 'spam'), ('messages', 'spam', '.')]

>> POS Tags are: 
 [('protocols', 'NNS'), ('determine', 'VBP'), ('incoming', 'VBG'), ('messages', 'NNS'), ('spam', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['protocols', 'messages spam']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('protocols', 'protocol'), ('determine', 'determin'), ('incoming', 'incom'), ('messages', 'messag'), ('spam', 'spam'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('protocols', 'protocol'), ('determine', 'determin'), ('incoming', 'incom'), ('messages', 'messag'), ('spam', 'spam'), ('.', '.')]

>> Lemmatization: 
 [('protocols', 'protocol'), ('determine', 'determine'), ('incoming', 'incoming'), ('messages', 'message'), ('spam', 'spam'), ('.', '.')]


------------------- Sentence 2 -------------------

There

>> Tokens are: 
 ['There']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('There', 'EX')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('There', 'there')]

>> Stemming using Snowball Stemmer: 
 [('There', 'there')]

>> Lemmatization: 
 [('There', 'There')]



========================================== PARAGRAPH 327 ===========================================

are several types of spam filters available. Content filters: Review the content within the  

------------------- Sentence 1 -------------------

are several types of spam filters available.

>> Tokens are: 
 ['several', 'types', 'spam', 'filters', 'available', '.']

>> Bigrams are: 
 [('several', 'types'), ('types', 'spam'), ('spam', 'filters'), ('filters', 'available'), ('available', '.')]

>> Trigrams are: 
 [('several', 'types', 'spam'), ('types', 'spam', 'filters'), ('spam', 'filters', 'available'), ('filters', 'available', '.')]

>> POS Tags are: 
 [('several', 'JJ'), ('types', 'NNS'), ('spam', 'VBD'), ('filters', 'NNS'), ('available', 'JJ'), ('.', '.')]

>> Noun Phrases are: 
 ['several types', 'filters']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('several', 'sever'), ('types', 'type'), ('spam', 'spam'), ('filters', 'filter'), ('available', 'avail'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('several', 'sever'), ('types', 'type'), ('spam', 'spam'), ('filters', 'filter'), ('available', 'avail'), ('.', '.')]

>> Lemmatization: 
 [('several', 'several'), ('types', 'type'), ('spam', 'spam'), ('filters', 'filter'), ('available', 'available'), ('.', '.')]


------------------- Sentence 2 -------------------

Content filters: Review the content within the

>> Tokens are: 
 ['Content', 'filters', ':', 'Review', 'content', 'within']

>> Bigrams are: 
 [('Content', 'filters'), ('filters', ':'), (':', 'Review'), ('Review', 'content'), ('content', 'within')]

>> Trigrams are: 
 [('Content', 'filters', ':'), ('filters', ':', 'Review'), (':', 'Review', 'content'), ('Review', 'content', 'within')]

>> POS Tags are: 
 [('Content', 'JJ'), ('filters', 'NNS'), (':', ':'), ('Review', 'NNP'), ('content', 'NN'), ('within', 'IN')]

>> Noun Phrases are: 
 ['Content filters', 'Review content']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Content', 'content'), ('filters', 'filter'), (':', ':'), ('Review', 'review'), ('content', 'content'), ('within', 'within')]

>> Stemming using Snowball Stemmer: 
 [('Content', 'content'), ('filters', 'filter'), (':', ':'), ('Review', 'review'), ('content', 'content'), ('within', 'within')]

>> Lemmatization: 
 [('Content', 'Content'), ('filters', 'filter'), (':', ':'), ('Review', 'Review'), ('content', 'content'), ('within', 'within')]



========================================== PARAGRAPH 328 ===========================================

message to determine whether it is a spam or not. Header filters: Review the email header  

------------------- Sentence 1 -------------------

message to determine whether it is a spam or not.

>> Tokens are: 
 ['message', 'determine', 'whether', 'spam', '.']

>> Bigrams are: 
 [('message', 'determine'), ('determine', 'whether'), ('whether', 'spam'), ('spam', '.')]

>> Trigrams are: 
 [('message', 'determine', 'whether'), ('determine', 'whether', 'spam'), ('whether', 'spam', '.')]

>> POS Tags are: 
 [('message', 'NN'), ('determine', 'NN'), ('whether', 'IN'), ('spam', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['message determine', 'spam']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('message', 'messag'), ('determine', 'determin'), ('whether', 'whether'), ('spam', 'spam'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('message', 'messag'), ('determine', 'determin'), ('whether', 'whether'), ('spam', 'spam'), ('.', '.')]

>> Lemmatization: 
 [('message', 'message'), ('determine', 'determine'), ('whether', 'whether'), ('spam', 'spam'), ('.', '.')]


------------------- Sentence 2 -------------------

Header filters: Review the email header

>> Tokens are: 
 ['Header', 'filters', ':', 'Review', 'email', 'header']

>> Bigrams are: 
 [('Header', 'filters'), ('filters', ':'), (':', 'Review'), ('Review', 'email'), ('email', 'header')]

>> Trigrams are: 
 [('Header', 'filters', ':'), ('filters', ':', 'Review'), (':', 'Review', 'email'), ('Review', 'email', 'header')]

>> POS Tags are: 
 [('Header', 'NN'), ('filters', 'NNS'), (':', ':'), ('Review', 'NNP'), ('email', 'VBP'), ('header', 'NN')]

>> Noun Phrases are: 
 ['Header filters', 'Review', 'header']

>> Named Entities are: 
 [('GPE', 'Header')] 

>> Stemming using Porter Stemmer: 
 [('Header', 'header'), ('filters', 'filter'), (':', ':'), ('Review', 'review'), ('email', 'email'), ('header', 'header')]

>> Stemming using Snowball Stemmer: 
 [('Header', 'header'), ('filters', 'filter'), (':', ':'), ('Review', 'review'), ('email', 'email'), ('header', 'header')]

>> Lemmatization: 
 [('Header', 'Header'), ('filters', 'filter'), (':', ':'), ('Review', 'Review'), ('email', 'email'), ('header', 'header')]



========================================== PARAGRAPH 329 ===========================================

looking for fake information. General Blacklist filters: Stopes all emails from blacklisted  

------------------- Sentence 1 -------------------

looking for fake information.

>> Tokens are: 
 ['looking', 'fake', 'information', '.']

>> Bigrams are: 
 [('looking', 'fake'), ('fake', 'information'), ('information', '.')]

>> Trigrams are: 
 [('looking', 'fake', 'information'), ('fake', 'information', '.')]

>> POS Tags are: 
 [('looking', 'VBG'), ('fake', 'JJ'), ('information', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['fake information']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('looking', 'look'), ('fake', 'fake'), ('information', 'inform'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('looking', 'look'), ('fake', 'fake'), ('information', 'inform'), ('.', '.')]

>> Lemmatization: 
 [('looking', 'looking'), ('fake', 'fake'), ('information', 'information'), ('.', '.')]


------------------- Sentence 2 -------------------

General Blacklist filters: Stopes all emails from blacklisted

>> Tokens are: 
 ['General', 'Blacklist', 'filters', ':', 'Stopes', 'emails', 'blacklisted']

>> Bigrams are: 
 [('General', 'Blacklist'), ('Blacklist', 'filters'), ('filters', ':'), (':', 'Stopes'), ('Stopes', 'emails'), ('emails', 'blacklisted')]

>> Trigrams are: 
 [('General', 'Blacklist', 'filters'), ('Blacklist', 'filters', ':'), ('filters', ':', 'Stopes'), (':', 'Stopes', 'emails'), ('Stopes', 'emails', 'blacklisted')]

>> POS Tags are: 
 [('General', 'NNP'), ('Blacklist', 'NNP'), ('filters', 'NNS'), (':', ':'), ('Stopes', 'NNP'), ('emails', 'NNS'), ('blacklisted', 'VBD')]

>> Noun Phrases are: 
 ['General Blacklist filters', 'Stopes emails']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('General', 'gener'), ('Blacklist', 'blacklist'), ('filters', 'filter'), (':', ':'), ('Stopes', 'stope'), ('emails', 'email'), ('blacklisted', 'blacklist')]

>> Stemming using Snowball Stemmer: 
 [('General', 'general'), ('Blacklist', 'blacklist'), ('filters', 'filter'), (':', ':'), ('Stopes', 'stope'), ('emails', 'email'), ('blacklisted', 'blacklist')]

>> Lemmatization: 
 [('General', 'General'), ('Blacklist', 'Blacklist'), ('filters', 'filter'), (':', ':'), ('Stopes', 'Stopes'), ('emails', 'email'), ('blacklisted', 'blacklisted')]



========================================== PARAGRAPH 330 ===========================================

recipients. Rules Based Filters: It uses user-defined criteria. Such as stopping mails from  

------------------- Sentence 1 -------------------

recipients.

>> Tokens are: 
 ['recipients', '.']

>> Bigrams are: 
 [('recipients', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('recipients', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['recipients']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('recipients', 'recipi'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('recipients', 'recipi'), ('.', '.')]

>> Lemmatization: 
 [('recipients', 'recipient'), ('.', '.')]


------------------- Sentence 2 -------------------

Rules Based Filters: It uses user-defined criteria.

>> Tokens are: 
 ['Rules', 'Based', 'Filters', ':', 'It', 'uses', 'user-defined', 'criteria', '.']

>> Bigrams are: 
 [('Rules', 'Based'), ('Based', 'Filters'), ('Filters', ':'), (':', 'It'), ('It', 'uses'), ('uses', 'user-defined'), ('user-defined', 'criteria'), ('criteria', '.')]

>> Trigrams are: 
 [('Rules', 'Based', 'Filters'), ('Based', 'Filters', ':'), ('Filters', ':', 'It'), (':', 'It', 'uses'), ('It', 'uses', 'user-defined'), ('uses', 'user-defined', 'criteria'), ('user-defined', 'criteria', '.')]

>> POS Tags are: 
 [('Rules', 'NNS'), ('Based', 'VBD'), ('Filters', 'NNS'), (':', ':'), ('It', 'PRP'), ('uses', 'VBZ'), ('user-defined', 'JJ'), ('criteria', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['Rules', 'Filters', 'user-defined criteria']

>> Named Entities are: 
 [('PERSON', 'Rules')] 

>> Stemming using Porter Stemmer: 
 [('Rules', 'rule'), ('Based', 'base'), ('Filters', 'filter'), (':', ':'), ('It', 'it'), ('uses', 'use'), ('user-defined', 'user-defin'), ('criteria', 'criteria'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Rules', 'rule'), ('Based', 'base'), ('Filters', 'filter'), (':', ':'), ('It', 'it'), ('uses', 'use'), ('user-defined', 'user-defin'), ('criteria', 'criteria'), ('.', '.')]

>> Lemmatization: 
 [('Rules', 'Rules'), ('Based', 'Based'), ('Filters', 'Filters'), (':', ':'), ('It', 'It'), ('uses', 'us'), ('user-defined', 'user-defined'), ('criteria', 'criterion'), ('.', '.')]


------------------- Sentence 3 -------------------

Such as stopping mails from

>> Tokens are: 
 ['Such', 'stopping', 'mails']

>> Bigrams are: 
 [('Such', 'stopping'), ('stopping', 'mails')]

>> Trigrams are: 
 [('Such', 'stopping', 'mails')]

>> POS Tags are: 
 [('Such', 'JJ'), ('stopping', 'NN'), ('mails', 'NNS')]

>> Noun Phrases are: 
 ['Such stopping mails']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Such', 'such'), ('stopping', 'stop'), ('mails', 'mail')]

>> Stemming using Snowball Stemmer: 
 [('Such', 'such'), ('stopping', 'stop'), ('mails', 'mail')]

>> Lemmatization: 
 [('Such', 'Such'), ('stopping', 'stopping'), ('mails', 'mail')]



========================================== PARAGRAPH 331 ===========================================

specific person or stopping mail including a specific word. Permission Filters: Require  

------------------- Sentence 1 -------------------

specific person or stopping mail including a specific word.

>> Tokens are: 
 ['specific', 'person', 'stopping', 'mail', 'including', 'specific', 'word', '.']

>> Bigrams are: 
 [('specific', 'person'), ('person', 'stopping'), ('stopping', 'mail'), ('mail', 'including'), ('including', 'specific'), ('specific', 'word'), ('word', '.')]

>> Trigrams are: 
 [('specific', 'person', 'stopping'), ('person', 'stopping', 'mail'), ('stopping', 'mail', 'including'), ('mail', 'including', 'specific'), ('including', 'specific', 'word'), ('specific', 'word', '.')]

>> POS Tags are: 
 [('specific', 'JJ'), ('person', 'NN'), ('stopping', 'VBG'), ('mail', 'NN'), ('including', 'VBG'), ('specific', 'JJ'), ('word', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['specific person', 'mail', 'specific word']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('specific', 'specif'), ('person', 'person'), ('stopping', 'stop'), ('mail', 'mail'), ('including', 'includ'), ('specific', 'specif'), ('word', 'word'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('specific', 'specif'), ('person', 'person'), ('stopping', 'stop'), ('mail', 'mail'), ('including', 'includ'), ('specific', 'specif'), ('word', 'word'), ('.', '.')]

>> Lemmatization: 
 [('specific', 'specific'), ('person', 'person'), ('stopping', 'stopping'), ('mail', 'mail'), ('including', 'including'), ('specific', 'specific'), ('word', 'word'), ('.', '.')]


------------------- Sentence 2 -------------------

Permission Filters: Require

>> Tokens are: 
 ['Permission', 'Filters', ':', 'Require']

>> Bigrams are: 
 [('Permission', 'Filters'), ('Filters', ':'), (':', 'Require')]

>> Trigrams are: 
 [('Permission', 'Filters', ':'), ('Filters', ':', 'Require')]

>> POS Tags are: 
 [('Permission', 'NN'), ('Filters', 'NNS'), (':', ':'), ('Require', 'VB')]

>> Noun Phrases are: 
 ['Permission Filters']

>> Named Entities are: 
 [('GPE', 'Permission')] 

>> Stemming using Porter Stemmer: 
 [('Permission', 'permiss'), ('Filters', 'filter'), (':', ':'), ('Require', 'requir')]

>> Stemming using Snowball Stemmer: 
 [('Permission', 'permiss'), ('Filters', 'filter'), (':', ':'), ('Require', 'requir')]

>> Lemmatization: 
 [('Permission', 'Permission'), ('Filters', 'Filters'), (':', ':'), ('Require', 'Require')]



========================================== PARAGRAPH 332 ===========================================

anyone sending a message to be pre-approved by the recipient. Challenge Response Filters:  

------------------- Sentence 1 -------------------

anyone sending a message to be pre-approved by the recipient.

>> Tokens are: 
 ['anyone', 'sending', 'message', 'pre-approved', 'recipient', '.']

>> Bigrams are: 
 [('anyone', 'sending'), ('sending', 'message'), ('message', 'pre-approved'), ('pre-approved', 'recipient'), ('recipient', '.')]

>> Trigrams are: 
 [('anyone', 'sending', 'message'), ('sending', 'message', 'pre-approved'), ('message', 'pre-approved', 'recipient'), ('pre-approved', 'recipient', '.')]

>> POS Tags are: 
 [('anyone', 'NN'), ('sending', 'VBG'), ('message', 'NN'), ('pre-approved', 'JJ'), ('recipient', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['anyone', 'message', 'pre-approved recipient']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('anyone', 'anyon'), ('sending', 'send'), ('message', 'messag'), ('pre-approved', 'pre-approv'), ('recipient', 'recipi'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('anyone', 'anyon'), ('sending', 'send'), ('message', 'messag'), ('pre-approved', 'pre-approv'), ('recipient', 'recipi'), ('.', '.')]

>> Lemmatization: 
 [('anyone', 'anyone'), ('sending', 'sending'), ('message', 'message'), ('pre-approved', 'pre-approved'), ('recipient', 'recipient'), ('.', '.')]


------------------- Sentence 2 -------------------

Challenge Response Filters:

>> Tokens are: 
 ['Challenge', 'Response', 'Filters', ':']

>> Bigrams are: 
 [('Challenge', 'Response'), ('Response', 'Filters'), ('Filters', ':')]

>> Trigrams are: 
 [('Challenge', 'Response', 'Filters'), ('Response', 'Filters', ':')]

>> POS Tags are: 
 [('Challenge', 'NNP'), ('Response', 'NNP'), ('Filters', 'NNS'), (':', ':')]

>> Noun Phrases are: 
 ['Challenge Response Filters']

>> Named Entities are: 
 [('PERSON', 'Challenge')] 

>> Stemming using Porter Stemmer: 
 [('Challenge', 'challeng'), ('Response', 'respons'), ('Filters', 'filter'), (':', ':')]

>> Stemming using Snowball Stemmer: 
 [('Challenge', 'challeng'), ('Response', 'respons'), ('Filters', 'filter'), (':', ':')]

>> Lemmatization: 
 [('Challenge', 'Challenge'), ('Response', 'Response'), ('Filters', 'Filters'), (':', ':')]



========================================== PARAGRAPH 333 ===========================================

Requires anyone sending a message to enter a code in order to gain permission to send email.  

------------------- Sentence 1 -------------------

Requires anyone sending a message to enter a code in order to gain permission to send email.

>> Tokens are: 
 ['Requires', 'anyone', 'sending', 'message', 'enter', 'code', 'order', 'gain', 'permission', 'send', 'email', '.']

>> Bigrams are: 
 [('Requires', 'anyone'), ('anyone', 'sending'), ('sending', 'message'), ('message', 'enter'), ('enter', 'code'), ('code', 'order'), ('order', 'gain'), ('gain', 'permission'), ('permission', 'send'), ('send', 'email'), ('email', '.')]

>> Trigrams are: 
 [('Requires', 'anyone', 'sending'), ('anyone', 'sending', 'message'), ('sending', 'message', 'enter'), ('message', 'enter', 'code'), ('enter', 'code', 'order'), ('code', 'order', 'gain'), ('order', 'gain', 'permission'), ('gain', 'permission', 'send'), ('permission', 'send', 'email'), ('send', 'email', '.')]

>> POS Tags are: 
 [('Requires', 'NNS'), ('anyone', 'NN'), ('sending', 'VBG'), ('message', 'NN'), ('enter', 'NN'), ('code', 'NN'), ('order', 'NN'), ('gain', 'NN'), ('permission', 'NN'), ('send', 'NN'), ('email', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Requires anyone', 'message enter code order gain permission send email']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Requires', 'requir'), ('anyone', 'anyon'), ('sending', 'send'), ('message', 'messag'), ('enter', 'enter'), ('code', 'code'), ('order', 'order'), ('gain', 'gain'), ('permission', 'permiss'), ('send', 'send'), ('email', 'email'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Requires', 'requir'), ('anyone', 'anyon'), ('sending', 'send'), ('message', 'messag'), ('enter', 'enter'), ('code', 'code'), ('order', 'order'), ('gain', 'gain'), ('permission', 'permiss'), ('send', 'send'), ('email', 'email'), ('.', '.')]

>> Lemmatization: 
 [('Requires', 'Requires'), ('anyone', 'anyone'), ('sending', 'sending'), ('message', 'message'), ('enter', 'enter'), ('code', 'code'), ('order', 'order'), ('gain', 'gain'), ('permission', 'permission'), ('send', 'send'), ('email', 'email'), ('.', '.')]



========================================== PARAGRAPH 334 ===========================================

6.3 Spam Filtering   

------------------- Sentence 1 -------------------

6.3 Spam Filtering

>> Tokens are: 
 ['6.3', 'Spam', 'Filtering']

>> Bigrams are: 
 [('6.3', 'Spam'), ('Spam', 'Filtering')]

>> Trigrams are: 
 [('6.3', 'Spam', 'Filtering')]

>> POS Tags are: 
 [('6.3', 'CD'), ('Spam', 'NNP'), ('Filtering', 'VBG')]

>> Noun Phrases are: 
 ['Spam']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('6.3', '6.3'), ('Spam', 'spam'), ('Filtering', 'filter')]

>> Stemming using Snowball Stemmer: 
 [('6.3', '6.3'), ('Spam', 'spam'), ('Filtering', 'filter')]

>> Lemmatization: 
 [('6.3', '6.3'), ('Spam', 'Spam'), ('Filtering', 'Filtering')]



========================================== PARAGRAPH 335 ===========================================

It works using text categorization and in recent times, various machine learning techniques  

------------------- Sentence 1 -------------------

It works using text categorization and in recent times, various machine learning techniques

>> Tokens are: 
 ['It', 'works', 'using', 'text', 'categorization', 'recent', 'times', ',', 'various', 'machine', 'learning', 'techniques']

>> Bigrams are: 
 [('It', 'works'), ('works', 'using'), ('using', 'text'), ('text', 'categorization'), ('categorization', 'recent'), ('recent', 'times'), ('times', ','), (',', 'various'), ('various', 'machine'), ('machine', 'learning'), ('learning', 'techniques')]

>> Trigrams are: 
 [('It', 'works', 'using'), ('works', 'using', 'text'), ('using', 'text', 'categorization'), ('text', 'categorization', 'recent'), ('categorization', 'recent', 'times'), ('recent', 'times', ','), ('times', ',', 'various'), (',', 'various', 'machine'), ('various', 'machine', 'learning'), ('machine', 'learning', 'techniques')]

>> POS Tags are: 
 [('It', 'PRP'), ('works', 'VBZ'), ('using', 'VBG'), ('text', 'JJ'), ('categorization', 'NN'), ('recent', 'JJ'), ('times', 'NNS'), (',', ','), ('various', 'JJ'), ('machine', 'NN'), ('learning', 'VBG'), ('techniques', 'NNS')]

>> Noun Phrases are: 
 ['text categorization', 'recent times', 'various machine', 'techniques']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('It', 'it'), ('works', 'work'), ('using', 'use'), ('text', 'text'), ('categorization', 'categor'), ('recent', 'recent'), ('times', 'time'), (',', ','), ('various', 'variou'), ('machine', 'machin'), ('learning', 'learn'), ('techniques', 'techniqu')]

>> Stemming using Snowball Stemmer: 
 [('It', 'it'), ('works', 'work'), ('using', 'use'), ('text', 'text'), ('categorization', 'categor'), ('recent', 'recent'), ('times', 'time'), (',', ','), ('various', 'various'), ('machine', 'machin'), ('learning', 'learn'), ('techniques', 'techniqu')]

>> Lemmatization: 
 [('It', 'It'), ('works', 'work'), ('using', 'using'), ('text', 'text'), ('categorization', 'categorization'), ('recent', 'recent'), ('times', 'time'), (',', ','), ('various', 'various'), ('machine', 'machine'), ('learning', 'learning'), ('techniques', 'technique')]



========================================== PARAGRAPH 336 ===========================================

have been applied to text categorization or Anti-Spam Filtering  like Rule Learning (Cohen  

------------------- Sentence 1 -------------------

have been applied to text categorization or Anti-Spam Filtering  like Rule Learning (Cohen

>> Tokens are: 
 ['applied', 'text', 'categorization', 'Anti-Spam', 'Filtering', 'like', 'Rule', 'Learning', '(', 'Cohen']

>> Bigrams are: 
 [('applied', 'text'), ('text', 'categorization'), ('categorization', 'Anti-Spam'), ('Anti-Spam', 'Filtering'), ('Filtering', 'like'), ('like', 'Rule'), ('Rule', 'Learning'), ('Learning', '('), ('(', 'Cohen')]

>> Trigrams are: 
 [('applied', 'text', 'categorization'), ('text', 'categorization', 'Anti-Spam'), ('categorization', 'Anti-Spam', 'Filtering'), ('Anti-Spam', 'Filtering', 'like'), ('Filtering', 'like', 'Rule'), ('like', 'Rule', 'Learning'), ('Rule', 'Learning', '('), ('Learning', '(', 'Cohen')]

>> POS Tags are: 
 [('applied', 'VBN'), ('text', 'JJ'), ('categorization', 'NN'), ('Anti-Spam', 'NNP'), ('Filtering', 'NNP'), ('like', 'IN'), ('Rule', 'NNP'), ('Learning', 'NNP'), ('(', '('), ('Cohen', 'NNP')]

>> Noun Phrases are: 
 ['text categorization Anti-Spam Filtering', 'Rule Learning', 'Cohen']

>> Named Entities are: 
 [('PERSON', 'Rule Learning'), ('PERSON', 'Cohen')] 

>> Stemming using Porter Stemmer: 
 [('applied', 'appli'), ('text', 'text'), ('categorization', 'categor'), ('Anti-Spam', 'anti-spam'), ('Filtering', 'filter'), ('like', 'like'), ('Rule', 'rule'), ('Learning', 'learn'), ('(', '('), ('Cohen', 'cohen')]

>> Stemming using Snowball Stemmer: 
 [('applied', 'appli'), ('text', 'text'), ('categorization', 'categor'), ('Anti-Spam', 'anti-spam'), ('Filtering', 'filter'), ('like', 'like'), ('Rule', 'rule'), ('Learning', 'learn'), ('(', '('), ('Cohen', 'cohen')]

>> Lemmatization: 
 [('applied', 'applied'), ('text', 'text'), ('categorization', 'categorization'), ('Anti-Spam', 'Anti-Spam'), ('Filtering', 'Filtering'), ('like', 'like'), ('Rule', 'Rule'), ('Learning', 'Learning'), ('(', '('), ('Cohen', 'Cohen')]



========================================== PARAGRAPH 337 ===========================================

1996)[45], Naïve Bayes (Sahami et al., 1998 ;Androutsopoulos et al.,2000b ;Rennie  

------------------- Sentence 1 -------------------

1996)[45], Naïve Bayes (Sahami et al., 1998 ;Androutsopoulos et al.,2000b ;Rennie

>> Tokens are: 
 ['1996', ')', '[', '45', ']', ',', 'Naïve', 'Bayes', '(', 'Sahami', 'et', 'al.', ',', '1998', ';', 'Androutsopoulos', 'et', 'al.,2000b', ';', 'Rennie']

>> Bigrams are: 
 [('1996', ')'), (')', '['), ('[', '45'), ('45', ']'), (']', ','), (',', 'Naïve'), ('Naïve', 'Bayes'), ('Bayes', '('), ('(', 'Sahami'), ('Sahami', 'et'), ('et', 'al.'), ('al.', ','), (',', '1998'), ('1998', ';'), (';', 'Androutsopoulos'), ('Androutsopoulos', 'et'), ('et', 'al.,2000b'), ('al.,2000b', ';'), (';', 'Rennie')]

>> Trigrams are: 
 [('1996', ')', '['), (')', '[', '45'), ('[', '45', ']'), ('45', ']', ','), (']', ',', 'Naïve'), (',', 'Naïve', 'Bayes'), ('Naïve', 'Bayes', '('), ('Bayes', '(', 'Sahami'), ('(', 'Sahami', 'et'), ('Sahami', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '1998'), (',', '1998', ';'), ('1998', ';', 'Androutsopoulos'), (';', 'Androutsopoulos', 'et'), ('Androutsopoulos', 'et', 'al.,2000b'), ('et', 'al.,2000b', ';'), ('al.,2000b', ';', 'Rennie')]

>> POS Tags are: 
 [('1996', 'CD'), (')', ')'), ('[', 'VBD'), ('45', 'CD'), (']', 'NN'), (',', ','), ('Naïve', 'NNP'), ('Bayes', 'NNP'), ('(', '('), ('Sahami', 'NNP'), ('et', 'RB'), ('al.', 'RB'), (',', ','), ('1998', 'CD'), (';', ':'), ('Androutsopoulos', 'NNP'), ('et', 'CC'), ('al.,2000b', 'NN'), (';', ':'), ('Rennie', 'NNP')]

>> Noun Phrases are: 
 [']', 'Naïve Bayes', 'Sahami', 'Androutsopoulos', 'al.,2000b', 'Rennie']

>> Named Entities are: 
 [('PERSON', 'Naïve Bayes'), ('PERSON', 'Sahami'), ('PERSON', 'Androutsopoulos'), ('PERSON', 'Rennie')] 

>> Stemming using Porter Stemmer: 
 [('1996', '1996'), (')', ')'), ('[', '['), ('45', '45'), (']', ']'), (',', ','), ('Naïve', 'naïv'), ('Bayes', 'bay'), ('(', '('), ('Sahami', 'sahami'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('1998', '1998'), (';', ';'), ('Androutsopoulos', 'androutsopoulo'), ('et', 'et'), ('al.,2000b', 'al.,2000b'), (';', ';'), ('Rennie', 'renni')]

>> Stemming using Snowball Stemmer: 
 [('1996', '1996'), (')', ')'), ('[', '['), ('45', '45'), (']', ']'), (',', ','), ('Naïve', 'naïv'), ('Bayes', 'bay'), ('(', '('), ('Sahami', 'sahami'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('1998', '1998'), (';', ';'), ('Androutsopoulos', 'androutsopoulo'), ('et', 'et'), ('al.,2000b', 'al.,2000b'), (';', ';'), ('Rennie', 'renni')]

>> Lemmatization: 
 [('1996', '1996'), (')', ')'), ('[', '['), ('45', '45'), (']', ']'), (',', ','), ('Naïve', 'Naïve'), ('Bayes', 'Bayes'), ('(', '('), ('Sahami', 'Sahami'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('1998', '1998'), (';', ';'), ('Androutsopoulos', 'Androutsopoulos'), ('et', 'et'), ('al.,2000b', 'al.,2000b'), (';', ';'), ('Rennie', 'Rennie')]



========================================== PARAGRAPH 338 ===========================================

.,2000)[46][47][48],Memory based Learning (Androutsopoulos et al.,2000b)[47], Support  

------------------- Sentence 1 -------------------

.,2000)[46][47][48],Memory based Learning (Androutsopoulos et al.,2000b)[47], Support

>> Tokens are: 
 ['.,2000', ')', '[', '46', ']', '[', '47', ']', '[', '48', ']', ',', 'Memory', 'based', 'Learning', '(', 'Androutsopoulos', 'et', 'al.,2000b', ')', '[', '47', ']', ',', 'Support']

>> Bigrams are: 
 [('.,2000', ')'), (')', '['), ('[', '46'), ('46', ']'), (']', '['), ('[', '47'), ('47', ']'), (']', '['), ('[', '48'), ('48', ']'), (']', ','), (',', 'Memory'), ('Memory', 'based'), ('based', 'Learning'), ('Learning', '('), ('(', 'Androutsopoulos'), ('Androutsopoulos', 'et'), ('et', 'al.,2000b'), ('al.,2000b', ')'), (')', '['), ('[', '47'), ('47', ']'), (']', ','), (',', 'Support')]

>> Trigrams are: 
 [('.,2000', ')', '['), (')', '[', '46'), ('[', '46', ']'), ('46', ']', '['), (']', '[', '47'), ('[', '47', ']'), ('47', ']', '['), (']', '[', '48'), ('[', '48', ']'), ('48', ']', ','), (']', ',', 'Memory'), (',', 'Memory', 'based'), ('Memory', 'based', 'Learning'), ('based', 'Learning', '('), ('Learning', '(', 'Androutsopoulos'), ('(', 'Androutsopoulos', 'et'), ('Androutsopoulos', 'et', 'al.,2000b'), ('et', 'al.,2000b', ')'), ('al.,2000b', ')', '['), (')', '[', '47'), ('[', '47', ']'), ('47', ']', ','), (']', ',', 'Support')]

>> POS Tags are: 
 [('.,2000', 'NN'), (')', ')'), ('[', 'VBZ'), ('46', 'CD'), (']', 'NN'), ('[', 'VBD'), ('47', 'CD'), (']', 'NNP'), ('[', 'VBD'), ('48', 'CD'), (']', 'NN'), (',', ','), ('Memory', 'NNP'), ('based', 'VBN'), ('Learning', 'NNP'), ('(', '('), ('Androutsopoulos', 'NNP'), ('et', 'RB'), ('al.,2000b', 'RB'), (')', ')'), ('[', 'VBZ'), ('47', 'CD'), (']', 'NN'), (',', ','), ('Support', 'NNP')]

>> Noun Phrases are: 
 ['.,2000', ']', ']', ']', 'Memory', 'Learning', 'Androutsopoulos', ']', 'Support']

>> Named Entities are: 
 [('PERSON', 'Memory'), ('PERSON', 'Androutsopoulos'), ('PERSON', 'Support')] 

>> Stemming using Porter Stemmer: 
 [('.,2000', '.,2000'), (')', ')'), ('[', '['), ('46', '46'), (']', ']'), ('[', '['), ('47', '47'), (']', ']'), ('[', '['), ('48', '48'), (']', ']'), (',', ','), ('Memory', 'memori'), ('based', 'base'), ('Learning', 'learn'), ('(', '('), ('Androutsopoulos', 'androutsopoulo'), ('et', 'et'), ('al.,2000b', 'al.,2000b'), (')', ')'), ('[', '['), ('47', '47'), (']', ']'), (',', ','), ('Support', 'support')]

>> Stemming using Snowball Stemmer: 
 [('.,2000', '.,2000'), (')', ')'), ('[', '['), ('46', '46'), (']', ']'), ('[', '['), ('47', '47'), (']', ']'), ('[', '['), ('48', '48'), (']', ']'), (',', ','), ('Memory', 'memori'), ('based', 'base'), ('Learning', 'learn'), ('(', '('), ('Androutsopoulos', 'androutsopoulo'), ('et', 'et'), ('al.,2000b', 'al.,2000b'), (')', ')'), ('[', '['), ('47', '47'), (']', ']'), (',', ','), ('Support', 'support')]

>> Lemmatization: 
 [('.,2000', '.,2000'), (')', ')'), ('[', '['), ('46', '46'), (']', ']'), ('[', '['), ('47', '47'), (']', ']'), ('[', '['), ('48', '48'), (']', ']'), (',', ','), ('Memory', 'Memory'), ('based', 'based'), ('Learning', 'Learning'), ('(', '('), ('Androutsopoulos', 'Androutsopoulos'), ('et', 'et'), ('al.,2000b', 'al.,2000b'), (')', ')'), ('[', '['), ('47', '47'), (']', ']'), (',', ','), ('Support', 'Support')]



========================================== PARAGRAPH 339 ===========================================

vector machines (Druker et al., 1999)[49], Decision Trees (Carreras and Marquez , 2001)[50]  

------------------- Sentence 1 -------------------

vector machines (Druker et al., 1999)[49], Decision Trees (Carreras and Marquez , 2001)[50]

>> Tokens are: 
 ['vector', 'machines', '(', 'Druker', 'et', 'al.', ',', '1999', ')', '[', '49', ']', ',', 'Decision', 'Trees', '(', 'Carreras', 'Marquez', ',', '2001', ')', '[', '50', ']']

>> Bigrams are: 
 [('vector', 'machines'), ('machines', '('), ('(', 'Druker'), ('Druker', 'et'), ('et', 'al.'), ('al.', ','), (',', '1999'), ('1999', ')'), (')', '['), ('[', '49'), ('49', ']'), (']', ','), (',', 'Decision'), ('Decision', 'Trees'), ('Trees', '('), ('(', 'Carreras'), ('Carreras', 'Marquez'), ('Marquez', ','), (',', '2001'), ('2001', ')'), (')', '['), ('[', '50'), ('50', ']')]

>> Trigrams are: 
 [('vector', 'machines', '('), ('machines', '(', 'Druker'), ('(', 'Druker', 'et'), ('Druker', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '1999'), (',', '1999', ')'), ('1999', ')', '['), (')', '[', '49'), ('[', '49', ']'), ('49', ']', ','), (']', ',', 'Decision'), (',', 'Decision', 'Trees'), ('Decision', 'Trees', '('), ('Trees', '(', 'Carreras'), ('(', 'Carreras', 'Marquez'), ('Carreras', 'Marquez', ','), ('Marquez', ',', '2001'), (',', '2001', ')'), ('2001', ')', '['), (')', '[', '50'), ('[', '50', ']')]

>> POS Tags are: 
 [('vector', 'NN'), ('machines', 'NNS'), ('(', '('), ('Druker', 'NNP'), ('et', 'VBZ'), ('al.', 'RB'), (',', ','), ('1999', 'CD'), (')', ')'), ('[', 'VBD'), ('49', 'CD'), (']', 'NN'), (',', ','), ('Decision', 'NNP'), ('Trees', 'NNP'), ('(', '('), ('Carreras', 'NNP'), ('Marquez', 'NNP'), (',', ','), ('2001', 'CD'), (')', ')'), ('[', 'VBD'), ('50', 'CD'), (']', 'NN')]

>> Noun Phrases are: 
 ['vector machines', 'Druker', ']', 'Decision Trees', 'Carreras Marquez', ']']

>> Named Entities are: 
 [('ORGANIZATION', 'Druker'), ('PERSON', 'Decision Trees'), ('ORGANIZATION', 'Carreras Marquez')] 

>> Stemming using Porter Stemmer: 
 [('vector', 'vector'), ('machines', 'machin'), ('(', '('), ('Druker', 'druker'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('1999', '1999'), (')', ')'), ('[', '['), ('49', '49'), (']', ']'), (',', ','), ('Decision', 'decis'), ('Trees', 'tree'), ('(', '('), ('Carreras', 'carrera'), ('Marquez', 'marquez'), (',', ','), ('2001', '2001'), (')', ')'), ('[', '['), ('50', '50'), (']', ']')]

>> Stemming using Snowball Stemmer: 
 [('vector', 'vector'), ('machines', 'machin'), ('(', '('), ('Druker', 'druker'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('1999', '1999'), (')', ')'), ('[', '['), ('49', '49'), (']', ']'), (',', ','), ('Decision', 'decis'), ('Trees', 'tree'), ('(', '('), ('Carreras', 'carrera'), ('Marquez', 'marquez'), (',', ','), ('2001', '2001'), (')', ')'), ('[', '['), ('50', '50'), (']', ']')]

>> Lemmatization: 
 [('vector', 'vector'), ('machines', 'machine'), ('(', '('), ('Druker', 'Druker'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('1999', '1999'), (')', ')'), ('[', '['), ('49', '49'), (']', ']'), (',', ','), ('Decision', 'Decision'), ('Trees', 'Trees'), ('(', '('), ('Carreras', 'Carreras'), ('Marquez', 'Marquez'), (',', ','), ('2001', '2001'), (')', ')'), ('[', '['), ('50', '50'), (']', ']')]



========================================== PARAGRAPH 340 ===========================================

Maximum Entropy Model (Berger et al. 1996)[51]. Sometimes combining different learners  

------------------- Sentence 1 -------------------

Maximum Entropy Model (Berger et al.

>> Tokens are: 
 ['Maximum', 'Entropy', 'Model', '(', 'Berger', 'et', 'al', '.']

>> Bigrams are: 
 [('Maximum', 'Entropy'), ('Entropy', 'Model'), ('Model', '('), ('(', 'Berger'), ('Berger', 'et'), ('et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('Maximum', 'Entropy', 'Model'), ('Entropy', 'Model', '('), ('Model', '(', 'Berger'), ('(', 'Berger', 'et'), ('Berger', 'et', 'al'), ('et', 'al', '.')]

>> POS Tags are: 
 [('Maximum', 'NNP'), ('Entropy', 'NNP'), ('Model', 'NNP'), ('(', '('), ('Berger', 'NNP'), ('et', 'VBZ'), ('al', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Maximum Entropy Model', 'Berger', 'al']

>> Named Entities are: 
 [('PERSON', 'Maximum'), ('PERSON', 'Entropy Model'), ('PERSON', 'Berger')] 

>> Stemming using Porter Stemmer: 
 [('Maximum', 'maximum'), ('Entropy', 'entropi'), ('Model', 'model'), ('(', '('), ('Berger', 'berger'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Maximum', 'maximum'), ('Entropy', 'entropi'), ('Model', 'model'), ('(', '('), ('Berger', 'berger'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('Maximum', 'Maximum'), ('Entropy', 'Entropy'), ('Model', 'Model'), ('(', '('), ('Berger', 'Berger'), ('et', 'et'), ('al', 'al'), ('.', '.')]


------------------- Sentence 2 -------------------

1996)[51].

>> Tokens are: 
 ['1996', ')', '[', '51', ']', '.']

>> Bigrams are: 
 [('1996', ')'), (')', '['), ('[', '51'), ('51', ']'), (']', '.')]

>> Trigrams are: 
 [('1996', ')', '['), (')', '[', '51'), ('[', '51', ']'), ('51', ']', '.')]

>> POS Tags are: 
 [('1996', 'CD'), (')', ')'), ('[', 'VBD'), ('51', 'CD'), (']', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 [']']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('1996', '1996'), (')', ')'), ('[', '['), ('51', '51'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('1996', '1996'), (')', ')'), ('[', '['), ('51', '51'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('1996', '1996'), (')', ')'), ('[', '['), ('51', '51'), (']', ']'), ('.', '.')]


------------------- Sentence 3 -------------------

Sometimes combining different learners

>> Tokens are: 
 ['Sometimes', 'combining', 'different', 'learners']

>> Bigrams are: 
 [('Sometimes', 'combining'), ('combining', 'different'), ('different', 'learners')]

>> Trigrams are: 
 [('Sometimes', 'combining', 'different'), ('combining', 'different', 'learners')]

>> POS Tags are: 
 [('Sometimes', 'RB'), ('combining', 'VBG'), ('different', 'JJ'), ('learners', 'NNS')]

>> Noun Phrases are: 
 ['different learners']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Sometimes', 'sometim'), ('combining', 'combin'), ('different', 'differ'), ('learners', 'learner')]

>> Stemming using Snowball Stemmer: 
 [('Sometimes', 'sometim'), ('combining', 'combin'), ('different', 'differ'), ('learners', 'learner')]

>> Lemmatization: 
 [('Sometimes', 'Sometimes'), ('combining', 'combining'), ('different', 'different'), ('learners', 'learner')]



========================================== PARAGRAPH 341 ===========================================

(Sakkis et al., 2001) [52]. Using these approaches is better as classifier is learned from  

------------------- Sentence 1 -------------------

(Sakkis et al., 2001) [52].

>> Tokens are: 
 ['(', 'Sakkis', 'et', 'al.', ',', '2001', ')', '[', '52', ']', '.']

>> Bigrams are: 
 [('(', 'Sakkis'), ('Sakkis', 'et'), ('et', 'al.'), ('al.', ','), (',', '2001'), ('2001', ')'), (')', '['), ('[', '52'), ('52', ']'), (']', '.')]

>> Trigrams are: 
 [('(', 'Sakkis', 'et'), ('Sakkis', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2001'), (',', '2001', ')'), ('2001', ')', '['), (')', '[', '52'), ('[', '52', ']'), ('52', ']', '.')]

>> POS Tags are: 
 [('(', '('), ('Sakkis', 'NNP'), ('et', 'RB'), ('al.', 'RB'), (',', ','), ('2001', 'CD'), (')', ')'), ('[', 'VBD'), ('52', 'CD'), (']', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Sakkis', ']']

>> Named Entities are: 
 [('PERSON', 'Sakkis')] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('Sakkis', 'sakki'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2001', '2001'), (')', ')'), ('[', '['), ('52', '52'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('Sakkis', 'sakki'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2001', '2001'), (')', ')'), ('[', '['), ('52', '52'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('(', '('), ('Sakkis', 'Sakkis'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2001', '2001'), (')', ')'), ('[', '['), ('52', '52'), (']', ']'), ('.', '.')]


------------------- Sentence 2 -------------------

Using these approaches is better as classifier is learned from

>> Tokens are: 
 ['Using', 'approaches', 'better', 'classifier', 'learned']

>> Bigrams are: 
 [('Using', 'approaches'), ('approaches', 'better'), ('better', 'classifier'), ('classifier', 'learned')]

>> Trigrams are: 
 [('Using', 'approaches', 'better'), ('approaches', 'better', 'classifier'), ('better', 'classifier', 'learned')]

>> POS Tags are: 
 [('Using', 'VBG'), ('approaches', 'NNS'), ('better', 'RBR'), ('classifier', 'NN'), ('learned', 'VBD')]

>> Noun Phrases are: 
 ['approaches', 'classifier']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Using', 'use'), ('approaches', 'approach'), ('better', 'better'), ('classifier', 'classifi'), ('learned', 'learn')]

>> Stemming using Snowball Stemmer: 
 [('Using', 'use'), ('approaches', 'approach'), ('better', 'better'), ('classifier', 'classifi'), ('learned', 'learn')]

>> Lemmatization: 
 [('Using', 'Using'), ('approaches', 'approach'), ('better', 'better'), ('classifier', 'classifier'), ('learned', 'learned')]



========================================== PARAGRAPH 342 ===========================================

training data rather than making by hand. The naïve bayes is preferred because of its  

------------------- Sentence 1 -------------------

training data rather than making by hand.

>> Tokens are: 
 ['training', 'data', 'rather', 'making', 'hand', '.']

>> Bigrams are: 
 [('training', 'data'), ('data', 'rather'), ('rather', 'making'), ('making', 'hand'), ('hand', '.')]

>> Trigrams are: 
 [('training', 'data', 'rather'), ('data', 'rather', 'making'), ('rather', 'making', 'hand'), ('making', 'hand', '.')]

>> POS Tags are: 
 [('training', 'VBG'), ('data', 'NNS'), ('rather', 'RB'), ('making', 'VBG'), ('hand', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['data', 'hand']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('training', 'train'), ('data', 'data'), ('rather', 'rather'), ('making', 'make'), ('hand', 'hand'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('training', 'train'), ('data', 'data'), ('rather', 'rather'), ('making', 'make'), ('hand', 'hand'), ('.', '.')]

>> Lemmatization: 
 [('training', 'training'), ('data', 'data'), ('rather', 'rather'), ('making', 'making'), ('hand', 'hand'), ('.', '.')]


------------------- Sentence 2 -------------------

The naïve bayes is preferred because of its

>> Tokens are: 
 ['The', 'naïve', 'bayes', 'preferred']

>> Bigrams are: 
 [('The', 'naïve'), ('naïve', 'bayes'), ('bayes', 'preferred')]

>> Trigrams are: 
 [('The', 'naïve', 'bayes'), ('naïve', 'bayes', 'preferred')]

>> POS Tags are: 
 [('The', 'DT'), ('naïve', 'JJ'), ('bayes', 'NNS'), ('preferred', 'VBD')]

>> Noun Phrases are: 
 ['The naïve bayes']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('naïve', 'naïv'), ('bayes', 'bay'), ('preferred', 'prefer')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('naïve', 'naïv'), ('bayes', 'bay'), ('preferred', 'prefer')]

>> Lemmatization: 
 [('The', 'The'), ('naïve', 'naïve'), ('bayes', 'bayes'), ('preferred', 'preferred')]



========================================== PARAGRAPH 343 ===========================================

performance despite its simplicity (Lewis, 1998) [53] In Text Categorization two types of  

------------------- Sentence 1 -------------------

performance despite its simplicity (Lewis, 1998) [53] In Text Categorization two types of

>> Tokens are: 
 ['performance', 'despite', 'simplicity', '(', 'Lewis', ',', '1998', ')', '[', '53', ']', 'In', 'Text', 'Categorization', 'two', 'types']

>> Bigrams are: 
 [('performance', 'despite'), ('despite', 'simplicity'), ('simplicity', '('), ('(', 'Lewis'), ('Lewis', ','), (',', '1998'), ('1998', ')'), (')', '['), ('[', '53'), ('53', ']'), (']', 'In'), ('In', 'Text'), ('Text', 'Categorization'), ('Categorization', 'two'), ('two', 'types')]

>> Trigrams are: 
 [('performance', 'despite', 'simplicity'), ('despite', 'simplicity', '('), ('simplicity', '(', 'Lewis'), ('(', 'Lewis', ','), ('Lewis', ',', '1998'), (',', '1998', ')'), ('1998', ')', '['), (')', '[', '53'), ('[', '53', ']'), ('53', ']', 'In'), (']', 'In', 'Text'), ('In', 'Text', 'Categorization'), ('Text', 'Categorization', 'two'), ('Categorization', 'two', 'types')]

>> POS Tags are: 
 [('performance', 'NN'), ('despite', 'IN'), ('simplicity', 'NN'), ('(', '('), ('Lewis', 'NNP'), (',', ','), ('1998', 'CD'), (')', ')'), ('[', 'VBD'), ('53', 'CD'), (']', 'NN'), ('In', 'IN'), ('Text', 'NNP'), ('Categorization', 'NNP'), ('two', 'CD'), ('types', 'NNS')]

>> Noun Phrases are: 
 ['performance', 'simplicity', 'Lewis', ']', 'Text Categorization', 'types']

>> Named Entities are: 
 [('PERSON', 'Lewis'), ('GPE', 'Text')] 

>> Stemming using Porter Stemmer: 
 [('performance', 'perform'), ('despite', 'despit'), ('simplicity', 'simplic'), ('(', '('), ('Lewis', 'lewi'), (',', ','), ('1998', '1998'), (')', ')'), ('[', '['), ('53', '53'), (']', ']'), ('In', 'in'), ('Text', 'text'), ('Categorization', 'categor'), ('two', 'two'), ('types', 'type')]

>> Stemming using Snowball Stemmer: 
 [('performance', 'perform'), ('despite', 'despit'), ('simplicity', 'simplic'), ('(', '('), ('Lewis', 'lewi'), (',', ','), ('1998', '1998'), (')', ')'), ('[', '['), ('53', '53'), (']', ']'), ('In', 'in'), ('Text', 'text'), ('Categorization', 'categor'), ('two', 'two'), ('types', 'type')]

>> Lemmatization: 
 [('performance', 'performance'), ('despite', 'despite'), ('simplicity', 'simplicity'), ('(', '('), ('Lewis', 'Lewis'), (',', ','), ('1998', '1998'), (')', ')'), ('[', '['), ('53', '53'), (']', ']'), ('In', 'In'), ('Text', 'Text'), ('Categorization', 'Categorization'), ('two', 'two'), ('types', 'type')]



========================================== PARAGRAPH 344 ===========================================

models have been used (McCallum and Nigam, 1998) [54]. Both modules assume that a fixed  

------------------- Sentence 1 -------------------

models have been used (McCallum and Nigam, 1998) [54].

>> Tokens are: 
 ['models', 'used', '(', 'McCallum', 'Nigam', ',', '1998', ')', '[', '54', ']', '.']

>> Bigrams are: 
 [('models', 'used'), ('used', '('), ('(', 'McCallum'), ('McCallum', 'Nigam'), ('Nigam', ','), (',', '1998'), ('1998', ')'), (')', '['), ('[', '54'), ('54', ']'), (']', '.')]

>> Trigrams are: 
 [('models', 'used', '('), ('used', '(', 'McCallum'), ('(', 'McCallum', 'Nigam'), ('McCallum', 'Nigam', ','), ('Nigam', ',', '1998'), (',', '1998', ')'), ('1998', ')', '['), (')', '[', '54'), ('[', '54', ']'), ('54', ']', '.')]

>> POS Tags are: 
 [('models', 'NNS'), ('used', 'VBN'), ('(', '('), ('McCallum', 'NNP'), ('Nigam', 'NNP'), (',', ','), ('1998', 'CD'), (')', ')'), ('[', 'VBD'), ('54', 'CD'), (']', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['models', 'McCallum Nigam', ']']

>> Named Entities are: 
 [('ORGANIZATION', 'McCallum Nigam')] 

>> Stemming using Porter Stemmer: 
 [('models', 'model'), ('used', 'use'), ('(', '('), ('McCallum', 'mccallum'), ('Nigam', 'nigam'), (',', ','), ('1998', '1998'), (')', ')'), ('[', '['), ('54', '54'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('models', 'model'), ('used', 'use'), ('(', '('), ('McCallum', 'mccallum'), ('Nigam', 'nigam'), (',', ','), ('1998', '1998'), (')', ')'), ('[', '['), ('54', '54'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('models', 'model'), ('used', 'used'), ('(', '('), ('McCallum', 'McCallum'), ('Nigam', 'Nigam'), (',', ','), ('1998', '1998'), (')', ')'), ('[', '['), ('54', '54'), (']', ']'), ('.', '.')]


------------------- Sentence 2 -------------------

Both modules assume that a fixed

>> Tokens are: 
 ['Both', 'modules', 'assume', 'fixed']

>> Bigrams are: 
 [('Both', 'modules'), ('modules', 'assume'), ('assume', 'fixed')]

>> Trigrams are: 
 [('Both', 'modules', 'assume'), ('modules', 'assume', 'fixed')]

>> POS Tags are: 
 [('Both', 'DT'), ('modules', 'NNS'), ('assume', 'VBP'), ('fixed', 'VBN')]

>> Noun Phrases are: 
 ['Both modules']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Both', 'both'), ('modules', 'modul'), ('assume', 'assum'), ('fixed', 'fix')]

>> Stemming using Snowball Stemmer: 
 [('Both', 'both'), ('modules', 'modul'), ('assume', 'assum'), ('fixed', 'fix')]

>> Lemmatization: 
 [('Both', 'Both'), ('modules', 'module'), ('assume', 'assume'), ('fixed', 'fixed')]



========================================== PARAGRAPH 345 ===========================================

vocabulary is present. But in first model a document is generated by first choosing a subset of  

------------------- Sentence 1 -------------------

vocabulary is present.

>> Tokens are: 
 ['vocabulary', 'present', '.']

>> Bigrams are: 
 [('vocabulary', 'present'), ('present', '.')]

>> Trigrams are: 
 [('vocabulary', 'present', '.')]

>> POS Tags are: 
 [('vocabulary', 'JJ'), ('present', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['vocabulary present']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('vocabulary', 'vocabulari'), ('present', 'present'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('vocabulary', 'vocabulari'), ('present', 'present'), ('.', '.')]

>> Lemmatization: 
 [('vocabulary', 'vocabulary'), ('present', 'present'), ('.', '.')]


------------------- Sentence 2 -------------------

But in first model a document is generated by first choosing a subset of

>> Tokens are: 
 ['But', 'first', 'model', 'document', 'generated', 'first', 'choosing', 'subset']

>> Bigrams are: 
 [('But', 'first'), ('first', 'model'), ('model', 'document'), ('document', 'generated'), ('generated', 'first'), ('first', 'choosing'), ('choosing', 'subset')]

>> Trigrams are: 
 [('But', 'first', 'model'), ('first', 'model', 'document'), ('model', 'document', 'generated'), ('document', 'generated', 'first'), ('generated', 'first', 'choosing'), ('first', 'choosing', 'subset')]

>> POS Tags are: 
 [('But', 'CC'), ('first', 'JJ'), ('model', 'NN'), ('document', 'NN'), ('generated', 'VBD'), ('first', 'JJ'), ('choosing', 'NN'), ('subset', 'NN')]

>> Noun Phrases are: 
 ['first model document', 'first choosing subset']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('But', 'but'), ('first', 'first'), ('model', 'model'), ('document', 'document'), ('generated', 'gener'), ('first', 'first'), ('choosing', 'choos'), ('subset', 'subset')]

>> Stemming using Snowball Stemmer: 
 [('But', 'but'), ('first', 'first'), ('model', 'model'), ('document', 'document'), ('generated', 'generat'), ('first', 'first'), ('choosing', 'choos'), ('subset', 'subset')]

>> Lemmatization: 
 [('But', 'But'), ('first', 'first'), ('model', 'model'), ('document', 'document'), ('generated', 'generated'), ('first', 'first'), ('choosing', 'choosing'), ('subset', 'subset')]



========================================== PARAGRAPH 346 ===========================================

vocabulary and then using the selected words any number of times, at least once irrespective  

------------------- Sentence 1 -------------------

vocabulary and then using the selected words any number of times, at least once irrespective

>> Tokens are: 
 ['vocabulary', 'using', 'selected', 'words', 'number', 'times', ',', 'least', 'irrespective']

>> Bigrams are: 
 [('vocabulary', 'using'), ('using', 'selected'), ('selected', 'words'), ('words', 'number'), ('number', 'times'), ('times', ','), (',', 'least'), ('least', 'irrespective')]

>> Trigrams are: 
 [('vocabulary', 'using', 'selected'), ('using', 'selected', 'words'), ('selected', 'words', 'number'), ('words', 'number', 'times'), ('number', 'times', ','), ('times', ',', 'least'), (',', 'least', 'irrespective')]

>> POS Tags are: 
 [('vocabulary', 'JJ'), ('using', 'VBG'), ('selected', 'VBN'), ('words', 'NNS'), ('number', 'NN'), ('times', 'NNS'), (',', ','), ('least', 'JJS'), ('irrespective', 'JJ')]

>> Noun Phrases are: 
 ['words number times']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('vocabulary', 'vocabulari'), ('using', 'use'), ('selected', 'select'), ('words', 'word'), ('number', 'number'), ('times', 'time'), (',', ','), ('least', 'least'), ('irrespective', 'irrespect')]

>> Stemming using Snowball Stemmer: 
 [('vocabulary', 'vocabulari'), ('using', 'use'), ('selected', 'select'), ('words', 'word'), ('number', 'number'), ('times', 'time'), (',', ','), ('least', 'least'), ('irrespective', 'irrespect')]

>> Lemmatization: 
 [('vocabulary', 'vocabulary'), ('using', 'using'), ('selected', 'selected'), ('words', 'word'), ('number', 'number'), ('times', 'time'), (',', ','), ('least', 'least'), ('irrespective', 'irrespective')]



========================================== PARAGRAPH 347 ===========================================

of order. This is called Multi-variate Bernoulli model. It takes the information of which  

------------------- Sentence 1 -------------------

of order.

>> Tokens are: 
 ['order', '.']

>> Bigrams are: 
 [('order', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('order', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['order']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('order', 'order'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('order', 'order'), ('.', '.')]

>> Lemmatization: 
 [('order', 'order'), ('.', '.')]


------------------- Sentence 2 -------------------

This is called Multi-variate Bernoulli model.

>> Tokens are: 
 ['This', 'called', 'Multi-variate', 'Bernoulli', 'model', '.']

>> Bigrams are: 
 [('This', 'called'), ('called', 'Multi-variate'), ('Multi-variate', 'Bernoulli'), ('Bernoulli', 'model'), ('model', '.')]

>> Trigrams are: 
 [('This', 'called', 'Multi-variate'), ('called', 'Multi-variate', 'Bernoulli'), ('Multi-variate', 'Bernoulli', 'model'), ('Bernoulli', 'model', '.')]

>> POS Tags are: 
 [('This', 'DT'), ('called', 'VBD'), ('Multi-variate', 'NNP'), ('Bernoulli', 'NNP'), ('model', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Multi-variate Bernoulli model']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('This', 'thi'), ('called', 'call'), ('Multi-variate', 'multi-vari'), ('Bernoulli', 'bernoulli'), ('model', 'model'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('This', 'this'), ('called', 'call'), ('Multi-variate', 'multi-vari'), ('Bernoulli', 'bernoulli'), ('model', 'model'), ('.', '.')]

>> Lemmatization: 
 [('This', 'This'), ('called', 'called'), ('Multi-variate', 'Multi-variate'), ('Bernoulli', 'Bernoulli'), ('model', 'model'), ('.', '.')]


------------------- Sentence 3 -------------------

It takes the information of which

>> Tokens are: 
 ['It', 'takes', 'information']

>> Bigrams are: 
 [('It', 'takes'), ('takes', 'information')]

>> Trigrams are: 
 [('It', 'takes', 'information')]

>> POS Tags are: 
 [('It', 'PRP'), ('takes', 'VBZ'), ('information', 'NN')]

>> Noun Phrases are: 
 ['information']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('It', 'it'), ('takes', 'take'), ('information', 'inform')]

>> Stemming using Snowball Stemmer: 
 [('It', 'it'), ('takes', 'take'), ('information', 'inform')]

>> Lemmatization: 
 [('It', 'It'), ('takes', 'take'), ('information', 'information')]



========================================== PARAGRAPH 348 ===========================================

words are used in a document irrespective of number of words and order. In second model, a  

------------------- Sentence 1 -------------------

words are used in a document irrespective of number of words and order.

>> Tokens are: 
 ['words', 'used', 'document', 'irrespective', 'number', 'words', 'order', '.']

>> Bigrams are: 
 [('words', 'used'), ('used', 'document'), ('document', 'irrespective'), ('irrespective', 'number'), ('number', 'words'), ('words', 'order'), ('order', '.')]

>> Trigrams are: 
 [('words', 'used', 'document'), ('used', 'document', 'irrespective'), ('document', 'irrespective', 'number'), ('irrespective', 'number', 'words'), ('number', 'words', 'order'), ('words', 'order', '.')]

>> POS Tags are: 
 [('words', 'NNS'), ('used', 'VBN'), ('document', 'NN'), ('irrespective', 'JJ'), ('number', 'NN'), ('words', 'NNS'), ('order', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['words', 'document', 'irrespective number words order']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('words', 'word'), ('used', 'use'), ('document', 'document'), ('irrespective', 'irrespect'), ('number', 'number'), ('words', 'word'), ('order', 'order'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('words', 'word'), ('used', 'use'), ('document', 'document'), ('irrespective', 'irrespect'), ('number', 'number'), ('words', 'word'), ('order', 'order'), ('.', '.')]

>> Lemmatization: 
 [('words', 'word'), ('used', 'used'), ('document', 'document'), ('irrespective', 'irrespective'), ('number', 'number'), ('words', 'word'), ('order', 'order'), ('.', '.')]


------------------- Sentence 2 -------------------

In second model, a

>> Tokens are: 
 ['In', 'second', 'model', ',']

>> Bigrams are: 
 [('In', 'second'), ('second', 'model'), ('model', ',')]

>> Trigrams are: 
 [('In', 'second', 'model'), ('second', 'model', ',')]

>> POS Tags are: 
 [('In', 'IN'), ('second', 'JJ'), ('model', 'NN'), (',', ',')]

>> Noun Phrases are: 
 ['second model']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('second', 'second'), ('model', 'model'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('second', 'second'), ('model', 'model'), (',', ',')]

>> Lemmatization: 
 [('In', 'In'), ('second', 'second'), ('model', 'model'), (',', ',')]



========================================== PARAGRAPH 349 ===========================================

document is generated by choosing a set of word occurrences and arranging them in any  

------------------- Sentence 1 -------------------

document is generated by choosing a set of word occurrences and arranging them in any

>> Tokens are: 
 ['document', 'generated', 'choosing', 'set', 'word', 'occurrences', 'arranging']

>> Bigrams are: 
 [('document', 'generated'), ('generated', 'choosing'), ('choosing', 'set'), ('set', 'word'), ('word', 'occurrences'), ('occurrences', 'arranging')]

>> Trigrams are: 
 [('document', 'generated', 'choosing'), ('generated', 'choosing', 'set'), ('choosing', 'set', 'word'), ('set', 'word', 'occurrences'), ('word', 'occurrences', 'arranging')]

>> POS Tags are: 
 [('document', 'NN'), ('generated', 'VBD'), ('choosing', 'VBG'), ('set', 'VBN'), ('word', 'NN'), ('occurrences', 'NNS'), ('arranging', 'VBG')]

>> Noun Phrases are: 
 ['document', 'word occurrences']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('document', 'document'), ('generated', 'gener'), ('choosing', 'choos'), ('set', 'set'), ('word', 'word'), ('occurrences', 'occurr'), ('arranging', 'arrang')]

>> Stemming using Snowball Stemmer: 
 [('document', 'document'), ('generated', 'generat'), ('choosing', 'choos'), ('set', 'set'), ('word', 'word'), ('occurrences', 'occurr'), ('arranging', 'arrang')]

>> Lemmatization: 
 [('document', 'document'), ('generated', 'generated'), ('choosing', 'choosing'), ('set', 'set'), ('word', 'word'), ('occurrences', 'occurrence'), ('arranging', 'arranging')]



========================================== PARAGRAPH 350 ===========================================

order. this model is called multi-nomial model, in addition to the Multi-variate Bernoulli  

------------------- Sentence 1 -------------------

order.

>> Tokens are: 
 ['order', '.']

>> Bigrams are: 
 [('order', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('order', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['order']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('order', 'order'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('order', 'order'), ('.', '.')]

>> Lemmatization: 
 [('order', 'order'), ('.', '.')]


------------------- Sentence 2 -------------------

this model is called multi-nomial model, in addition to the Multi-variate Bernoulli

>> Tokens are: 
 ['model', 'called', 'multi-nomial', 'model', ',', 'addition', 'Multi-variate', 'Bernoulli']

>> Bigrams are: 
 [('model', 'called'), ('called', 'multi-nomial'), ('multi-nomial', 'model'), ('model', ','), (',', 'addition'), ('addition', 'Multi-variate'), ('Multi-variate', 'Bernoulli')]

>> Trigrams are: 
 [('model', 'called', 'multi-nomial'), ('called', 'multi-nomial', 'model'), ('multi-nomial', 'model', ','), ('model', ',', 'addition'), (',', 'addition', 'Multi-variate'), ('addition', 'Multi-variate', 'Bernoulli')]

>> POS Tags are: 
 [('model', 'NN'), ('called', 'VBN'), ('multi-nomial', 'JJ'), ('model', 'NN'), (',', ','), ('addition', 'NN'), ('Multi-variate', 'NNP'), ('Bernoulli', 'NNP')]

>> Noun Phrases are: 
 ['model', 'multi-nomial model', 'addition Multi-variate Bernoulli']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('model', 'model'), ('called', 'call'), ('multi-nomial', 'multi-nomi'), ('model', 'model'), (',', ','), ('addition', 'addit'), ('Multi-variate', 'multi-vari'), ('Bernoulli', 'bernoulli')]

>> Stemming using Snowball Stemmer: 
 [('model', 'model'), ('called', 'call'), ('multi-nomial', 'multi-nomi'), ('model', 'model'), (',', ','), ('addition', 'addit'), ('Multi-variate', 'multi-vari'), ('Bernoulli', 'bernoulli')]

>> Lemmatization: 
 [('model', 'model'), ('called', 'called'), ('multi-nomial', 'multi-nomial'), ('model', 'model'), (',', ','), ('addition', 'addition'), ('Multi-variate', 'Multi-variate'), ('Bernoulli', 'Bernoulli')]



========================================== PARAGRAPH 351 ===========================================

model, it also captures information on how many times a word is used in a document. Most  

------------------- Sentence 1 -------------------

model, it also captures information on how many times a word is used in a document.

>> Tokens are: 
 ['model', ',', 'also', 'captures', 'information', 'many', 'times', 'word', 'used', 'document', '.']

>> Bigrams are: 
 [('model', ','), (',', 'also'), ('also', 'captures'), ('captures', 'information'), ('information', 'many'), ('many', 'times'), ('times', 'word'), ('word', 'used'), ('used', 'document'), ('document', '.')]

>> Trigrams are: 
 [('model', ',', 'also'), (',', 'also', 'captures'), ('also', 'captures', 'information'), ('captures', 'information', 'many'), ('information', 'many', 'times'), ('many', 'times', 'word'), ('times', 'word', 'used'), ('word', 'used', 'document'), ('used', 'document', '.')]

>> POS Tags are: 
 [('model', 'NN'), (',', ','), ('also', 'RB'), ('captures', 'VBZ'), ('information', 'NN'), ('many', 'JJ'), ('times', 'NNS'), ('word', 'NN'), ('used', 'VBN'), ('document', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['model', 'information', 'many times word', 'document']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('model', 'model'), (',', ','), ('also', 'also'), ('captures', 'captur'), ('information', 'inform'), ('many', 'mani'), ('times', 'time'), ('word', 'word'), ('used', 'use'), ('document', 'document'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('model', 'model'), (',', ','), ('also', 'also'), ('captures', 'captur'), ('information', 'inform'), ('many', 'mani'), ('times', 'time'), ('word', 'word'), ('used', 'use'), ('document', 'document'), ('.', '.')]

>> Lemmatization: 
 [('model', 'model'), (',', ','), ('also', 'also'), ('captures', 'capture'), ('information', 'information'), ('many', 'many'), ('times', 'time'), ('word', 'word'), ('used', 'used'), ('document', 'document'), ('.', '.')]


------------------- Sentence 2 -------------------

Most

>> Tokens are: 
 ['Most']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Most', 'JJS')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Most', 'most')]

>> Stemming using Snowball Stemmer: 
 [('Most', 'most')]

>> Lemmatization: 
 [('Most', 'Most')]



========================================== PARAGRAPH 352 ===========================================

text categorization approaches to anti spam Email filtering have used multi variate Bernoulli  

------------------- Sentence 1 -------------------

text categorization approaches to anti spam Email filtering have used multi variate Bernoulli

>> Tokens are: 
 ['text', 'categorization', 'approaches', 'anti', 'spam', 'Email', 'filtering', 'used', 'multi', 'variate', 'Bernoulli']

>> Bigrams are: 
 [('text', 'categorization'), ('categorization', 'approaches'), ('approaches', 'anti'), ('anti', 'spam'), ('spam', 'Email'), ('Email', 'filtering'), ('filtering', 'used'), ('used', 'multi'), ('multi', 'variate'), ('variate', 'Bernoulli')]

>> Trigrams are: 
 [('text', 'categorization', 'approaches'), ('categorization', 'approaches', 'anti'), ('approaches', 'anti', 'spam'), ('anti', 'spam', 'Email'), ('spam', 'Email', 'filtering'), ('Email', 'filtering', 'used'), ('filtering', 'used', 'multi'), ('used', 'multi', 'variate'), ('multi', 'variate', 'Bernoulli')]

>> POS Tags are: 
 [('text', 'JJ'), ('categorization', 'NN'), ('approaches', 'NNS'), ('anti', 'VBP'), ('spam', 'JJ'), ('Email', 'NNP'), ('filtering', 'NN'), ('used', 'VBN'), ('multi', 'NN'), ('variate', 'NN'), ('Bernoulli', 'NNP')]

>> Noun Phrases are: 
 ['text categorization approaches', 'spam Email filtering', 'multi variate Bernoulli']

>> Named Entities are: 
 [('PERSON', 'Bernoulli')] 

>> Stemming using Porter Stemmer: 
 [('text', 'text'), ('categorization', 'categor'), ('approaches', 'approach'), ('anti', 'anti'), ('spam', 'spam'), ('Email', 'email'), ('filtering', 'filter'), ('used', 'use'), ('multi', 'multi'), ('variate', 'variat'), ('Bernoulli', 'bernoulli')]

>> Stemming using Snowball Stemmer: 
 [('text', 'text'), ('categorization', 'categor'), ('approaches', 'approach'), ('anti', 'anti'), ('spam', 'spam'), ('Email', 'email'), ('filtering', 'filter'), ('used', 'use'), ('multi', 'multi'), ('variate', 'variat'), ('Bernoulli', 'bernoulli')]

>> Lemmatization: 
 [('text', 'text'), ('categorization', 'categorization'), ('approaches', 'approach'), ('anti', 'anti'), ('spam', 'spam'), ('Email', 'Email'), ('filtering', 'filtering'), ('used', 'used'), ('multi', 'multi'), ('variate', 'variate'), ('Bernoulli', 'Bernoulli')]



========================================== PARAGRAPH 353 ===========================================

model (Androutsopoulos et al.,2000b) [47]  

------------------- Sentence 1 -------------------

model (Androutsopoulos et al.,2000b) [47]

>> Tokens are: 
 ['model', '(', 'Androutsopoulos', 'et', 'al.,2000b', ')', '[', '47', ']']

>> Bigrams are: 
 [('model', '('), ('(', 'Androutsopoulos'), ('Androutsopoulos', 'et'), ('et', 'al.,2000b'), ('al.,2000b', ')'), (')', '['), ('[', '47'), ('47', ']')]

>> Trigrams are: 
 [('model', '(', 'Androutsopoulos'), ('(', 'Androutsopoulos', 'et'), ('Androutsopoulos', 'et', 'al.,2000b'), ('et', 'al.,2000b', ')'), ('al.,2000b', ')', '['), (')', '[', '47'), ('[', '47', ']')]

>> POS Tags are: 
 [('model', 'NN'), ('(', '('), ('Androutsopoulos', 'NNP'), ('et', 'RB'), ('al.,2000b', 'RB'), (')', ')'), ('[', 'VBZ'), ('47', 'CD'), (']', 'NN')]

>> Noun Phrases are: 
 ['model', 'Androutsopoulos', ']']

>> Named Entities are: 
 [('PERSON', 'Androutsopoulos')] 

>> Stemming using Porter Stemmer: 
 [('model', 'model'), ('(', '('), ('Androutsopoulos', 'androutsopoulo'), ('et', 'et'), ('al.,2000b', 'al.,2000b'), (')', ')'), ('[', '['), ('47', '47'), (']', ']')]

>> Stemming using Snowball Stemmer: 
 [('model', 'model'), ('(', '('), ('Androutsopoulos', 'androutsopoulo'), ('et', 'et'), ('al.,2000b', 'al.,2000b'), (')', ')'), ('[', '['), ('47', '47'), (']', ']')]

>> Lemmatization: 
 [('model', 'model'), ('(', '('), ('Androutsopoulos', 'Androutsopoulos'), ('et', 'et'), ('al.,2000b', 'al.,2000b'), (')', ')'), ('[', '['), ('47', '47'), (']', ']')]



========================================== PARAGRAPH 354 ===========================================

6.4 Information Extraction  

------------------- Sentence 1 -------------------

6.4 Information Extraction

>> Tokens are: 
 ['6.4', 'Information', 'Extraction']

>> Bigrams are: 
 [('6.4', 'Information'), ('Information', 'Extraction')]

>> Trigrams are: 
 [('6.4', 'Information', 'Extraction')]

>> POS Tags are: 
 [('6.4', 'CD'), ('Information', 'NNP'), ('Extraction', 'NN')]

>> Noun Phrases are: 
 ['Information Extraction']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('6.4', '6.4'), ('Information', 'inform'), ('Extraction', 'extract')]

>> Stemming using Snowball Stemmer: 
 [('6.4', '6.4'), ('Information', 'inform'), ('Extraction', 'extract')]

>> Lemmatization: 
 [('6.4', '6.4'), ('Information', 'Information'), ('Extraction', 'Extraction')]



========================================== PARAGRAPH 355 ===========================================

Information extraction is concerned with identifying phrases of interest of textual data. For  

------------------- Sentence 1 -------------------

Information extraction is concerned with identifying phrases of interest of textual data.

>> Tokens are: 
 ['Information', 'extraction', 'concerned', 'identifying', 'phrases', 'interest', 'textual', 'data', '.']

>> Bigrams are: 
 [('Information', 'extraction'), ('extraction', 'concerned'), ('concerned', 'identifying'), ('identifying', 'phrases'), ('phrases', 'interest'), ('interest', 'textual'), ('textual', 'data'), ('data', '.')]

>> Trigrams are: 
 [('Information', 'extraction', 'concerned'), ('extraction', 'concerned', 'identifying'), ('concerned', 'identifying', 'phrases'), ('identifying', 'phrases', 'interest'), ('phrases', 'interest', 'textual'), ('interest', 'textual', 'data'), ('textual', 'data', '.')]

>> POS Tags are: 
 [('Information', 'NNP'), ('extraction', 'NN'), ('concerned', 'VBD'), ('identifying', 'JJ'), ('phrases', 'NNS'), ('interest', 'NN'), ('textual', 'JJ'), ('data', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['Information extraction', 'identifying phrases interest', 'textual data']

>> Named Entities are: 
 [('GPE', 'Information')] 

>> Stemming using Porter Stemmer: 
 [('Information', 'inform'), ('extraction', 'extract'), ('concerned', 'concern'), ('identifying', 'identifi'), ('phrases', 'phrase'), ('interest', 'interest'), ('textual', 'textual'), ('data', 'data'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Information', 'inform'), ('extraction', 'extract'), ('concerned', 'concern'), ('identifying', 'identifi'), ('phrases', 'phrase'), ('interest', 'interest'), ('textual', 'textual'), ('data', 'data'), ('.', '.')]

>> Lemmatization: 
 [('Information', 'Information'), ('extraction', 'extraction'), ('concerned', 'concerned'), ('identifying', 'identifying'), ('phrases', 'phrase'), ('interest', 'interest'), ('textual', 'textual'), ('data', 'data'), ('.', '.')]


------------------- Sentence 2 -------------------

For

>> Tokens are: 
 ['For']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('For', 'IN')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('For', 'for')]

>> Stemming using Snowball Stemmer: 
 [('For', 'for')]

>> Lemmatization: 
 [('For', 'For')]



========================================== PARAGRAPH 356 ===========================================

many applications, extracting entities such as names, places, events, dates, times and prices is  

------------------- Sentence 1 -------------------

many applications, extracting entities such as names, places, events, dates, times and prices is

>> Tokens are: 
 ['many', 'applications', ',', 'extracting', 'entities', 'names', ',', 'places', ',', 'events', ',', 'dates', ',', 'times', 'prices']

>> Bigrams are: 
 [('many', 'applications'), ('applications', ','), (',', 'extracting'), ('extracting', 'entities'), ('entities', 'names'), ('names', ','), (',', 'places'), ('places', ','), (',', 'events'), ('events', ','), (',', 'dates'), ('dates', ','), (',', 'times'), ('times', 'prices')]

>> Trigrams are: 
 [('many', 'applications', ','), ('applications', ',', 'extracting'), (',', 'extracting', 'entities'), ('extracting', 'entities', 'names'), ('entities', 'names', ','), ('names', ',', 'places'), (',', 'places', ','), ('places', ',', 'events'), (',', 'events', ','), ('events', ',', 'dates'), (',', 'dates', ','), ('dates', ',', 'times'), (',', 'times', 'prices')]

>> POS Tags are: 
 [('many', 'JJ'), ('applications', 'NNS'), (',', ','), ('extracting', 'VBG'), ('entities', 'NNS'), ('names', 'RB'), (',', ','), ('places', 'NNS'), (',', ','), ('events', 'NNS'), (',', ','), ('dates', 'NNS'), (',', ','), ('times', 'NNS'), ('prices', 'NNS')]

>> Noun Phrases are: 
 ['many applications', 'entities', 'places', 'events', 'dates', 'times prices']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('many', 'mani'), ('applications', 'applic'), (',', ','), ('extracting', 'extract'), ('entities', 'entiti'), ('names', 'name'), (',', ','), ('places', 'place'), (',', ','), ('events', 'event'), (',', ','), ('dates', 'date'), (',', ','), ('times', 'time'), ('prices', 'price')]

>> Stemming using Snowball Stemmer: 
 [('many', 'mani'), ('applications', 'applic'), (',', ','), ('extracting', 'extract'), ('entities', 'entiti'), ('names', 'name'), (',', ','), ('places', 'place'), (',', ','), ('events', 'event'), (',', ','), ('dates', 'date'), (',', ','), ('times', 'time'), ('prices', 'price')]

>> Lemmatization: 
 [('many', 'many'), ('applications', 'application'), (',', ','), ('extracting', 'extracting'), ('entities', 'entity'), ('names', 'name'), (',', ','), ('places', 'place'), (',', ','), ('events', 'event'), (',', ','), ('dates', 'date'), (',', ','), ('times', 'time'), ('prices', 'price')]



========================================== PARAGRAPH 357 ===========================================

a powerful way of summarize the information relevant to a user’s needs. In the case of a  

------------------- Sentence 1 -------------------

a powerful way of summarize the information relevant to a user’s needs.

>> Tokens are: 
 ['powerful', 'way', 'summarize', 'information', 'relevant', 'user', '’', 'needs', '.']

>> Bigrams are: 
 [('powerful', 'way'), ('way', 'summarize'), ('summarize', 'information'), ('information', 'relevant'), ('relevant', 'user'), ('user', '’'), ('’', 'needs'), ('needs', '.')]

>> Trigrams are: 
 [('powerful', 'way', 'summarize'), ('way', 'summarize', 'information'), ('summarize', 'information', 'relevant'), ('information', 'relevant', 'user'), ('relevant', 'user', '’'), ('user', '’', 'needs'), ('’', 'needs', '.')]

>> POS Tags are: 
 [('powerful', 'JJ'), ('way', 'NN'), ('summarize', 'JJ'), ('information', 'NN'), ('relevant', 'JJ'), ('user', 'NN'), ('’', 'NN'), ('needs', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['powerful way', 'summarize information', 'relevant user ’ needs']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('powerful', 'power'), ('way', 'way'), ('summarize', 'summar'), ('information', 'inform'), ('relevant', 'relev'), ('user', 'user'), ('’', '’'), ('needs', 'need'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('powerful', 'power'), ('way', 'way'), ('summarize', 'summar'), ('information', 'inform'), ('relevant', 'relev'), ('user', 'user'), ('’', '’'), ('needs', 'need'), ('.', '.')]

>> Lemmatization: 
 [('powerful', 'powerful'), ('way', 'way'), ('summarize', 'summarize'), ('information', 'information'), ('relevant', 'relevant'), ('user', 'user'), ('’', '’'), ('needs', 'need'), ('.', '.')]


------------------- Sentence 2 -------------------

In the case of a

>> Tokens are: 
 ['In', 'case']

>> Bigrams are: 
 [('In', 'case')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('In', 'IN'), ('case', 'NN')]

>> Noun Phrases are: 
 ['case']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('case', 'case')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('case', 'case')]

>> Lemmatization: 
 [('In', 'In'), ('case', 'case')]



========================================== PARAGRAPH 358 ===========================================

domain specific search engine, the automatic identification of important information can  

------------------- Sentence 1 -------------------

domain specific search engine, the automatic identification of important information can

>> Tokens are: 
 ['domain', 'specific', 'search', 'engine', ',', 'automatic', 'identification', 'important', 'information']

>> Bigrams are: 
 [('domain', 'specific'), ('specific', 'search'), ('search', 'engine'), ('engine', ','), (',', 'automatic'), ('automatic', 'identification'), ('identification', 'important'), ('important', 'information')]

>> Trigrams are: 
 [('domain', 'specific', 'search'), ('specific', 'search', 'engine'), ('search', 'engine', ','), ('engine', ',', 'automatic'), (',', 'automatic', 'identification'), ('automatic', 'identification', 'important'), ('identification', 'important', 'information')]

>> POS Tags are: 
 [('domain', 'NN'), ('specific', 'JJ'), ('search', 'NN'), ('engine', 'NN'), (',', ','), ('automatic', 'JJ'), ('identification', 'NN'), ('important', 'JJ'), ('information', 'NN')]

>> Noun Phrases are: 
 ['domain', 'specific search engine', 'automatic identification', 'important information']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('domain', 'domain'), ('specific', 'specif'), ('search', 'search'), ('engine', 'engin'), (',', ','), ('automatic', 'automat'), ('identification', 'identif'), ('important', 'import'), ('information', 'inform')]

>> Stemming using Snowball Stemmer: 
 [('domain', 'domain'), ('specific', 'specif'), ('search', 'search'), ('engine', 'engin'), (',', ','), ('automatic', 'automat'), ('identification', 'identif'), ('important', 'import'), ('information', 'inform')]

>> Lemmatization: 
 [('domain', 'domain'), ('specific', 'specific'), ('search', 'search'), ('engine', 'engine'), (',', ','), ('automatic', 'automatic'), ('identification', 'identification'), ('important', 'important'), ('information', 'information')]



========================================== PARAGRAPH 359 ===========================================

increase accuracy and efficiency of a directed search. There is use of hidden Markov models  

------------------- Sentence 1 -------------------

increase accuracy and efficiency of a directed search.

>> Tokens are: 
 ['increase', 'accuracy', 'efficiency', 'directed', 'search', '.']

>> Bigrams are: 
 [('increase', 'accuracy'), ('accuracy', 'efficiency'), ('efficiency', 'directed'), ('directed', 'search'), ('search', '.')]

>> Trigrams are: 
 [('increase', 'accuracy', 'efficiency'), ('accuracy', 'efficiency', 'directed'), ('efficiency', 'directed', 'search'), ('directed', 'search', '.')]

>> POS Tags are: 
 [('increase', 'NN'), ('accuracy', 'NN'), ('efficiency', 'NN'), ('directed', 'VBD'), ('search', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['increase accuracy efficiency', 'search']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('increase', 'increas'), ('accuracy', 'accuraci'), ('efficiency', 'effici'), ('directed', 'direct'), ('search', 'search'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('increase', 'increas'), ('accuracy', 'accuraci'), ('efficiency', 'effici'), ('directed', 'direct'), ('search', 'search'), ('.', '.')]

>> Lemmatization: 
 [('increase', 'increase'), ('accuracy', 'accuracy'), ('efficiency', 'efficiency'), ('directed', 'directed'), ('search', 'search'), ('.', '.')]


------------------- Sentence 2 -------------------

There is use of hidden Markov models

>> Tokens are: 
 ['There', 'use', 'hidden', 'Markov', 'models']

>> Bigrams are: 
 [('There', 'use'), ('use', 'hidden'), ('hidden', 'Markov'), ('Markov', 'models')]

>> Trigrams are: 
 [('There', 'use', 'hidden'), ('use', 'hidden', 'Markov'), ('hidden', 'Markov', 'models')]

>> POS Tags are: 
 [('There', 'EX'), ('use', 'VB'), ('hidden', 'JJ'), ('Markov', 'NNP'), ('models', 'NNS')]

>> Noun Phrases are: 
 ['hidden Markov models']

>> Named Entities are: 
 [('PERSON', 'Markov')] 

>> Stemming using Porter Stemmer: 
 [('There', 'there'), ('use', 'use'), ('hidden', 'hidden'), ('Markov', 'markov'), ('models', 'model')]

>> Stemming using Snowball Stemmer: 
 [('There', 'there'), ('use', 'use'), ('hidden', 'hidden'), ('Markov', 'markov'), ('models', 'model')]

>> Lemmatization: 
 [('There', 'There'), ('use', 'use'), ('hidden', 'hidden'), ('Markov', 'Markov'), ('models', 'model')]



========================================== PARAGRAPH 360 ===========================================

(HMMs) to extract the relevant fields of research papers. These extracted text segments are 

------------------- Sentence 1 -------------------

(HMMs) to extract the relevant fields of research papers.

>> Tokens are: 
 ['(', 'HMMs', ')', 'extract', 'relevant', 'fields', 'research', 'papers', '.']

>> Bigrams are: 
 [('(', 'HMMs'), ('HMMs', ')'), (')', 'extract'), ('extract', 'relevant'), ('relevant', 'fields'), ('fields', 'research'), ('research', 'papers'), ('papers', '.')]

>> Trigrams are: 
 [('(', 'HMMs', ')'), ('HMMs', ')', 'extract'), (')', 'extract', 'relevant'), ('extract', 'relevant', 'fields'), ('relevant', 'fields', 'research'), ('fields', 'research', 'papers'), ('research', 'papers', '.')]

>> POS Tags are: 
 [('(', '('), ('HMMs', 'NNP'), (')', ')'), ('extract', 'NN'), ('relevant', 'JJ'), ('fields', 'NNS'), ('research', 'NN'), ('papers', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['HMMs', 'extract', 'relevant fields research papers']

>> Named Entities are: 
 [('ORGANIZATION', 'HMMs')] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('HMMs', 'hmm'), (')', ')'), ('extract', 'extract'), ('relevant', 'relev'), ('fields', 'field'), ('research', 'research'), ('papers', 'paper'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('HMMs', 'hmms'), (')', ')'), ('extract', 'extract'), ('relevant', 'relev'), ('fields', 'field'), ('research', 'research'), ('papers', 'paper'), ('.', '.')]

>> Lemmatization: 
 [('(', '('), ('HMMs', 'HMMs'), (')', ')'), ('extract', 'extract'), ('relevant', 'relevant'), ('fields', 'field'), ('research', 'research'), ('papers', 'paper'), ('.', '.')]


------------------- Sentence 2 -------------------

These extracted text segments are

>> Tokens are: 
 ['These', 'extracted', 'text', 'segments']

>> Bigrams are: 
 [('These', 'extracted'), ('extracted', 'text'), ('text', 'segments')]

>> Trigrams are: 
 [('These', 'extracted', 'text'), ('extracted', 'text', 'segments')]

>> POS Tags are: 
 [('These', 'DT'), ('extracted', 'VBD'), ('text', 'NN'), ('segments', 'NNS')]

>> Noun Phrases are: 
 ['text segments']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('These', 'these'), ('extracted', 'extract'), ('text', 'text'), ('segments', 'segment')]

>> Stemming using Snowball Stemmer: 
 [('These', 'these'), ('extracted', 'extract'), ('text', 'text'), ('segments', 'segment')]

>> Lemmatization: 
 [('These', 'These'), ('extracted', 'extracted'), ('text', 'text'), ('segments', 'segment')]



========================================== PARAGRAPH 361 ===========================================

used to allow searched over specific fields and to provide effective presentation of search  

------------------- Sentence 1 -------------------

used to allow searched over specific fields and to provide effective presentation of search

>> Tokens are: 
 ['used', 'allow', 'searched', 'specific', 'fields', 'provide', 'effective', 'presentation', 'search']

>> Bigrams are: 
 [('used', 'allow'), ('allow', 'searched'), ('searched', 'specific'), ('specific', 'fields'), ('fields', 'provide'), ('provide', 'effective'), ('effective', 'presentation'), ('presentation', 'search')]

>> Trigrams are: 
 [('used', 'allow', 'searched'), ('allow', 'searched', 'specific'), ('searched', 'specific', 'fields'), ('specific', 'fields', 'provide'), ('fields', 'provide', 'effective'), ('provide', 'effective', 'presentation'), ('effective', 'presentation', 'search')]

>> POS Tags are: 
 [('used', 'VBN'), ('allow', 'NN'), ('searched', 'VBD'), ('specific', 'JJ'), ('fields', 'NNS'), ('provide', 'VBP'), ('effective', 'JJ'), ('presentation', 'NN'), ('search', 'NN')]

>> Noun Phrases are: 
 ['allow', 'specific fields', 'effective presentation search']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('used', 'use'), ('allow', 'allow'), ('searched', 'search'), ('specific', 'specif'), ('fields', 'field'), ('provide', 'provid'), ('effective', 'effect'), ('presentation', 'present'), ('search', 'search')]

>> Stemming using Snowball Stemmer: 
 [('used', 'use'), ('allow', 'allow'), ('searched', 'search'), ('specific', 'specif'), ('fields', 'field'), ('provide', 'provid'), ('effective', 'effect'), ('presentation', 'present'), ('search', 'search')]

>> Lemmatization: 
 [('used', 'used'), ('allow', 'allow'), ('searched', 'searched'), ('specific', 'specific'), ('fields', 'field'), ('provide', 'provide'), ('effective', 'effective'), ('presentation', 'presentation'), ('search', 'search')]



========================================== PARAGRAPH 362 ===========================================

results and to match references to papers. For example, noticing the pop up ads on any  

------------------- Sentence 1 -------------------

results and to match references to papers.

>> Tokens are: 
 ['results', 'match', 'references', 'papers', '.']

>> Bigrams are: 
 [('results', 'match'), ('match', 'references'), ('references', 'papers'), ('papers', '.')]

>> Trigrams are: 
 [('results', 'match', 'references'), ('match', 'references', 'papers'), ('references', 'papers', '.')]

>> POS Tags are: 
 [('results', 'NNS'), ('match', 'VBP'), ('references', 'VBZ'), ('papers', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['results', 'papers']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('results', 'result'), ('match', 'match'), ('references', 'refer'), ('papers', 'paper'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('results', 'result'), ('match', 'match'), ('references', 'refer'), ('papers', 'paper'), ('.', '.')]

>> Lemmatization: 
 [('results', 'result'), ('match', 'match'), ('references', 'reference'), ('papers', 'paper'), ('.', '.')]


------------------- Sentence 2 -------------------

For example, noticing the pop up ads on any

>> Tokens are: 
 ['For', 'example', ',', 'noticing', 'pop', 'ads']

>> Bigrams are: 
 [('For', 'example'), ('example', ','), (',', 'noticing'), ('noticing', 'pop'), ('pop', 'ads')]

>> Trigrams are: 
 [('For', 'example', ','), ('example', ',', 'noticing'), (',', 'noticing', 'pop'), ('noticing', 'pop', 'ads')]

>> POS Tags are: 
 [('For', 'IN'), ('example', 'NN'), (',', ','), ('noticing', 'VBG'), ('pop', 'NN'), ('ads', 'NNS')]

>> Noun Phrases are: 
 ['example', 'pop ads']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('For', 'for'), ('example', 'exampl'), (',', ','), ('noticing', 'notic'), ('pop', 'pop'), ('ads', 'ad')]

>> Stemming using Snowball Stemmer: 
 [('For', 'for'), ('example', 'exampl'), (',', ','), ('noticing', 'notic'), ('pop', 'pop'), ('ads', 'ad')]

>> Lemmatization: 
 [('For', 'For'), ('example', 'example'), (',', ','), ('noticing', 'noticing'), ('pop', 'pop'), ('ads', 'ad')]



========================================== PARAGRAPH 363 ===========================================

websites showing the recent items you might have looked on an online store with discounts.  

------------------- Sentence 1 -------------------

websites showing the recent items you might have looked on an online store with discounts.

>> Tokens are: 
 ['websites', 'showing', 'recent', 'items', 'might', 'looked', 'online', 'store', 'discounts', '.']

>> Bigrams are: 
 [('websites', 'showing'), ('showing', 'recent'), ('recent', 'items'), ('items', 'might'), ('might', 'looked'), ('looked', 'online'), ('online', 'store'), ('store', 'discounts'), ('discounts', '.')]

>> Trigrams are: 
 [('websites', 'showing', 'recent'), ('showing', 'recent', 'items'), ('recent', 'items', 'might'), ('items', 'might', 'looked'), ('might', 'looked', 'online'), ('looked', 'online', 'store'), ('online', 'store', 'discounts'), ('store', 'discounts', '.')]

>> POS Tags are: 
 [('websites', 'NNS'), ('showing', 'VBG'), ('recent', 'JJ'), ('items', 'NNS'), ('might', 'MD'), ('looked', 'VB'), ('online', 'JJ'), ('store', 'NN'), ('discounts', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['websites', 'recent items', 'online store discounts']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('websites', 'websit'), ('showing', 'show'), ('recent', 'recent'), ('items', 'item'), ('might', 'might'), ('looked', 'look'), ('online', 'onlin'), ('store', 'store'), ('discounts', 'discount'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('websites', 'websit'), ('showing', 'show'), ('recent', 'recent'), ('items', 'item'), ('might', 'might'), ('looked', 'look'), ('online', 'onlin'), ('store', 'store'), ('discounts', 'discount'), ('.', '.')]

>> Lemmatization: 
 [('websites', 'website'), ('showing', 'showing'), ('recent', 'recent'), ('items', 'item'), ('might', 'might'), ('looked', 'looked'), ('online', 'online'), ('store', 'store'), ('discounts', 'discount'), ('.', '.')]



========================================== PARAGRAPH 364 ===========================================

In Information Retrieval two types of models have been used (McCallum and Nigam, 1998)  

------------------- Sentence 1 -------------------

In Information Retrieval two types of models have been used (McCallum and Nigam, 1998)

>> Tokens are: 
 ['In', 'Information', 'Retrieval', 'two', 'types', 'models', 'used', '(', 'McCallum', 'Nigam', ',', '1998', ')']

>> Bigrams are: 
 [('In', 'Information'), ('Information', 'Retrieval'), ('Retrieval', 'two'), ('two', 'types'), ('types', 'models'), ('models', 'used'), ('used', '('), ('(', 'McCallum'), ('McCallum', 'Nigam'), ('Nigam', ','), (',', '1998'), ('1998', ')')]

>> Trigrams are: 
 [('In', 'Information', 'Retrieval'), ('Information', 'Retrieval', 'two'), ('Retrieval', 'two', 'types'), ('two', 'types', 'models'), ('types', 'models', 'used'), ('models', 'used', '('), ('used', '(', 'McCallum'), ('(', 'McCallum', 'Nigam'), ('McCallum', 'Nigam', ','), ('Nigam', ',', '1998'), (',', '1998', ')')]

>> POS Tags are: 
 [('In', 'IN'), ('Information', 'NNP'), ('Retrieval', 'NNP'), ('two', 'CD'), ('types', 'NNS'), ('models', 'NNS'), ('used', 'VBN'), ('(', '('), ('McCallum', 'NNP'), ('Nigam', 'NNP'), (',', ','), ('1998', 'CD'), (')', ')')]

>> Noun Phrases are: 
 ['Information Retrieval', 'types models', 'McCallum Nigam']

>> Named Entities are: 
 [('GPE', 'Information'), ('ORGANIZATION', 'McCallum Nigam')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('Information', 'inform'), ('Retrieval', 'retriev'), ('two', 'two'), ('types', 'type'), ('models', 'model'), ('used', 'use'), ('(', '('), ('McCallum', 'mccallum'), ('Nigam', 'nigam'), (',', ','), ('1998', '1998'), (')', ')')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('Information', 'inform'), ('Retrieval', 'retriev'), ('two', 'two'), ('types', 'type'), ('models', 'model'), ('used', 'use'), ('(', '('), ('McCallum', 'mccallum'), ('Nigam', 'nigam'), (',', ','), ('1998', '1998'), (')', ')')]

>> Lemmatization: 
 [('In', 'In'), ('Information', 'Information'), ('Retrieval', 'Retrieval'), ('two', 'two'), ('types', 'type'), ('models', 'model'), ('used', 'used'), ('(', '('), ('McCallum', 'McCallum'), ('Nigam', 'Nigam'), (',', ','), ('1998', '1998'), (')', ')')]



========================================== PARAGRAPH 365 ===========================================

[55]. Both modules assume that a fixed vocabulary is present. But in first model a document  

------------------- Sentence 1 -------------------

[55].

>> Tokens are: 
 ['[', '55', ']', '.']

>> Bigrams are: 
 [('[', '55'), ('55', ']'), (']', '.')]

>> Trigrams are: 
 [('[', '55', ']'), ('55', ']', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('55', 'CD'), (']', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 [']']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('55', '55'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('55', '55'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('55', '55'), (']', ']'), ('.', '.')]


------------------- Sentence 2 -------------------

Both modules assume that a fixed vocabulary is present.

>> Tokens are: 
 ['Both', 'modules', 'assume', 'fixed', 'vocabulary', 'present', '.']

>> Bigrams are: 
 [('Both', 'modules'), ('modules', 'assume'), ('assume', 'fixed'), ('fixed', 'vocabulary'), ('vocabulary', 'present'), ('present', '.')]

>> Trigrams are: 
 [('Both', 'modules', 'assume'), ('modules', 'assume', 'fixed'), ('assume', 'fixed', 'vocabulary'), ('fixed', 'vocabulary', 'present'), ('vocabulary', 'present', '.')]

>> POS Tags are: 
 [('Both', 'DT'), ('modules', 'NNS'), ('assume', 'VBP'), ('fixed', 'VBN'), ('vocabulary', 'JJ'), ('present', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Both modules', 'vocabulary present']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Both', 'both'), ('modules', 'modul'), ('assume', 'assum'), ('fixed', 'fix'), ('vocabulary', 'vocabulari'), ('present', 'present'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Both', 'both'), ('modules', 'modul'), ('assume', 'assum'), ('fixed', 'fix'), ('vocabulary', 'vocabulari'), ('present', 'present'), ('.', '.')]

>> Lemmatization: 
 [('Both', 'Both'), ('modules', 'module'), ('assume', 'assume'), ('fixed', 'fixed'), ('vocabulary', 'vocabulary'), ('present', 'present'), ('.', '.')]


------------------- Sentence 3 -------------------

But in first model a document

>> Tokens are: 
 ['But', 'first', 'model', 'document']

>> Bigrams are: 
 [('But', 'first'), ('first', 'model'), ('model', 'document')]

>> Trigrams are: 
 [('But', 'first', 'model'), ('first', 'model', 'document')]

>> POS Tags are: 
 [('But', 'CC'), ('first', 'JJ'), ('model', 'NN'), ('document', 'NN')]

>> Noun Phrases are: 
 ['first model document']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('But', 'but'), ('first', 'first'), ('model', 'model'), ('document', 'document')]

>> Stemming using Snowball Stemmer: 
 [('But', 'but'), ('first', 'first'), ('model', 'model'), ('document', 'document')]

>> Lemmatization: 
 [('But', 'But'), ('first', 'first'), ('model', 'model'), ('document', 'document')]



========================================== PARAGRAPH 366 ===========================================

is generated by first choosing a subset of vocabulary and then using the selected words any  

------------------- Sentence 1 -------------------

is generated by first choosing a subset of vocabulary and then using the selected words any

>> Tokens are: 
 ['generated', 'first', 'choosing', 'subset', 'vocabulary', 'using', 'selected', 'words']

>> Bigrams are: 
 [('generated', 'first'), ('first', 'choosing'), ('choosing', 'subset'), ('subset', 'vocabulary'), ('vocabulary', 'using'), ('using', 'selected'), ('selected', 'words')]

>> Trigrams are: 
 [('generated', 'first', 'choosing'), ('first', 'choosing', 'subset'), ('choosing', 'subset', 'vocabulary'), ('subset', 'vocabulary', 'using'), ('vocabulary', 'using', 'selected'), ('using', 'selected', 'words')]

>> POS Tags are: 
 [('generated', 'VBN'), ('first', 'JJ'), ('choosing', 'VBG'), ('subset', 'NN'), ('vocabulary', 'JJ'), ('using', 'VBG'), ('selected', 'VBN'), ('words', 'NNS')]

>> Noun Phrases are: 
 ['subset', 'words']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('generated', 'gener'), ('first', 'first'), ('choosing', 'choos'), ('subset', 'subset'), ('vocabulary', 'vocabulari'), ('using', 'use'), ('selected', 'select'), ('words', 'word')]

>> Stemming using Snowball Stemmer: 
 [('generated', 'generat'), ('first', 'first'), ('choosing', 'choos'), ('subset', 'subset'), ('vocabulary', 'vocabulari'), ('using', 'use'), ('selected', 'select'), ('words', 'word')]

>> Lemmatization: 
 [('generated', 'generated'), ('first', 'first'), ('choosing', 'choosing'), ('subset', 'subset'), ('vocabulary', 'vocabulary'), ('using', 'using'), ('selected', 'selected'), ('words', 'word')]



========================================== PARAGRAPH 367 ===========================================

number of times, at least once without any order. This is called Multi-variate Bernoulli  

------------------- Sentence 1 -------------------

number of times, at least once without any order.

>> Tokens are: 
 ['number', 'times', ',', 'least', 'without', 'order', '.']

>> Bigrams are: 
 [('number', 'times'), ('times', ','), (',', 'least'), ('least', 'without'), ('without', 'order'), ('order', '.')]

>> Trigrams are: 
 [('number', 'times', ','), ('times', ',', 'least'), (',', 'least', 'without'), ('least', 'without', 'order'), ('without', 'order', '.')]

>> POS Tags are: 
 [('number', 'NN'), ('times', 'NNS'), (',', ','), ('least', 'JJS'), ('without', 'IN'), ('order', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['number times', 'order']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('number', 'number'), ('times', 'time'), (',', ','), ('least', 'least'), ('without', 'without'), ('order', 'order'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('number', 'number'), ('times', 'time'), (',', ','), ('least', 'least'), ('without', 'without'), ('order', 'order'), ('.', '.')]

>> Lemmatization: 
 [('number', 'number'), ('times', 'time'), (',', ','), ('least', 'least'), ('without', 'without'), ('order', 'order'), ('.', '.')]


------------------- Sentence 2 -------------------

This is called Multi-variate Bernoulli

>> Tokens are: 
 ['This', 'called', 'Multi-variate', 'Bernoulli']

>> Bigrams are: 
 [('This', 'called'), ('called', 'Multi-variate'), ('Multi-variate', 'Bernoulli')]

>> Trigrams are: 
 [('This', 'called', 'Multi-variate'), ('called', 'Multi-variate', 'Bernoulli')]

>> POS Tags are: 
 [('This', 'DT'), ('called', 'VBD'), ('Multi-variate', 'NNP'), ('Bernoulli', 'NNP')]

>> Noun Phrases are: 
 ['Multi-variate Bernoulli']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('This', 'thi'), ('called', 'call'), ('Multi-variate', 'multi-vari'), ('Bernoulli', 'bernoulli')]

>> Stemming using Snowball Stemmer: 
 [('This', 'this'), ('called', 'call'), ('Multi-variate', 'multi-vari'), ('Bernoulli', 'bernoulli')]

>> Lemmatization: 
 [('This', 'This'), ('called', 'called'), ('Multi-variate', 'Multi-variate'), ('Bernoulli', 'Bernoulli')]



========================================== PARAGRAPH 368 ===========================================

model. It takes the information of which words are used in a document irrespective of number  

------------------- Sentence 1 -------------------

model.

>> Tokens are: 
 ['model', '.']

>> Bigrams are: 
 [('model', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('model', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['model']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('model', 'model'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('model', 'model'), ('.', '.')]

>> Lemmatization: 
 [('model', 'model'), ('.', '.')]


------------------- Sentence 2 -------------------

It takes the information of which words are used in a document irrespective of number

>> Tokens are: 
 ['It', 'takes', 'information', 'words', 'used', 'document', 'irrespective', 'number']

>> Bigrams are: 
 [('It', 'takes'), ('takes', 'information'), ('information', 'words'), ('words', 'used'), ('used', 'document'), ('document', 'irrespective'), ('irrespective', 'number')]

>> Trigrams are: 
 [('It', 'takes', 'information'), ('takes', 'information', 'words'), ('information', 'words', 'used'), ('words', 'used', 'document'), ('used', 'document', 'irrespective'), ('document', 'irrespective', 'number')]

>> POS Tags are: 
 [('It', 'PRP'), ('takes', 'VBZ'), ('information', 'NN'), ('words', 'NNS'), ('used', 'VBN'), ('document', 'NN'), ('irrespective', 'JJ'), ('number', 'NN')]

>> Noun Phrases are: 
 ['information words', 'document', 'irrespective number']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('It', 'it'), ('takes', 'take'), ('information', 'inform'), ('words', 'word'), ('used', 'use'), ('document', 'document'), ('irrespective', 'irrespect'), ('number', 'number')]

>> Stemming using Snowball Stemmer: 
 [('It', 'it'), ('takes', 'take'), ('information', 'inform'), ('words', 'word'), ('used', 'use'), ('document', 'document'), ('irrespective', 'irrespect'), ('number', 'number')]

>> Lemmatization: 
 [('It', 'It'), ('takes', 'take'), ('information', 'information'), ('words', 'word'), ('used', 'used'), ('document', 'document'), ('irrespective', 'irrespective'), ('number', 'number')]



========================================== PARAGRAPH 369 ===========================================

of words and order. In second model, a document is generated by choosing a set of word  

------------------- Sentence 1 -------------------

of words and order.

>> Tokens are: 
 ['words', 'order', '.']

>> Bigrams are: 
 [('words', 'order'), ('order', '.')]

>> Trigrams are: 
 [('words', 'order', '.')]

>> POS Tags are: 
 [('words', 'NNS'), ('order', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['words order']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('words', 'word'), ('order', 'order'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('words', 'word'), ('order', 'order'), ('.', '.')]

>> Lemmatization: 
 [('words', 'word'), ('order', 'order'), ('.', '.')]


------------------- Sentence 2 -------------------

In second model, a document is generated by choosing a set of word

>> Tokens are: 
 ['In', 'second', 'model', ',', 'document', 'generated', 'choosing', 'set', 'word']

>> Bigrams are: 
 [('In', 'second'), ('second', 'model'), ('model', ','), (',', 'document'), ('document', 'generated'), ('generated', 'choosing'), ('choosing', 'set'), ('set', 'word')]

>> Trigrams are: 
 [('In', 'second', 'model'), ('second', 'model', ','), ('model', ',', 'document'), (',', 'document', 'generated'), ('document', 'generated', 'choosing'), ('generated', 'choosing', 'set'), ('choosing', 'set', 'word')]

>> POS Tags are: 
 [('In', 'IN'), ('second', 'JJ'), ('model', 'NN'), (',', ','), ('document', 'NN'), ('generated', 'VBD'), ('choosing', 'VBG'), ('set', 'NN'), ('word', 'NN')]

>> Noun Phrases are: 
 ['second model', 'document', 'set word']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('second', 'second'), ('model', 'model'), (',', ','), ('document', 'document'), ('generated', 'gener'), ('choosing', 'choos'), ('set', 'set'), ('word', 'word')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('second', 'second'), ('model', 'model'), (',', ','), ('document', 'document'), ('generated', 'generat'), ('choosing', 'choos'), ('set', 'set'), ('word', 'word')]

>> Lemmatization: 
 [('In', 'In'), ('second', 'second'), ('model', 'model'), (',', ','), ('document', 'document'), ('generated', 'generated'), ('choosing', 'choosing'), ('set', 'set'), ('word', 'word')]



========================================== PARAGRAPH 370 ===========================================

occurrences and arranging them in any order. this model is called multi-nomial model, in  

------------------- Sentence 1 -------------------

occurrences and arranging them in any order.

>> Tokens are: 
 ['occurrences', 'arranging', 'order', '.']

>> Bigrams are: 
 [('occurrences', 'arranging'), ('arranging', 'order'), ('order', '.')]

>> Trigrams are: 
 [('occurrences', 'arranging', 'order'), ('arranging', 'order', '.')]

>> POS Tags are: 
 [('occurrences', 'NNS'), ('arranging', 'VBG'), ('order', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['occurrences', 'order']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('occurrences', 'occurr'), ('arranging', 'arrang'), ('order', 'order'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('occurrences', 'occurr'), ('arranging', 'arrang'), ('order', 'order'), ('.', '.')]

>> Lemmatization: 
 [('occurrences', 'occurrence'), ('arranging', 'arranging'), ('order', 'order'), ('.', '.')]


------------------- Sentence 2 -------------------

this model is called multi-nomial model, in

>> Tokens are: 
 ['model', 'called', 'multi-nomial', 'model', ',']

>> Bigrams are: 
 [('model', 'called'), ('called', 'multi-nomial'), ('multi-nomial', 'model'), ('model', ',')]

>> Trigrams are: 
 [('model', 'called', 'multi-nomial'), ('called', 'multi-nomial', 'model'), ('multi-nomial', 'model', ',')]

>> POS Tags are: 
 [('model', 'NN'), ('called', 'VBN'), ('multi-nomial', 'JJ'), ('model', 'NN'), (',', ',')]

>> Noun Phrases are: 
 ['model', 'multi-nomial model']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('model', 'model'), ('called', 'call'), ('multi-nomial', 'multi-nomi'), ('model', 'model'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('model', 'model'), ('called', 'call'), ('multi-nomial', 'multi-nomi'), ('model', 'model'), (',', ',')]

>> Lemmatization: 
 [('model', 'model'), ('called', 'called'), ('multi-nomial', 'multi-nomial'), ('model', 'model'), (',', ',')]



========================================== PARAGRAPH 371 ===========================================

addition to the Multi-variate Bernoulli model , it also captures information on how many  

------------------- Sentence 1 -------------------

addition to the Multi-variate Bernoulli model , it also captures information on how many

>> Tokens are: 
 ['addition', 'Multi-variate', 'Bernoulli', 'model', ',', 'also', 'captures', 'information', 'many']

>> Bigrams are: 
 [('addition', 'Multi-variate'), ('Multi-variate', 'Bernoulli'), ('Bernoulli', 'model'), ('model', ','), (',', 'also'), ('also', 'captures'), ('captures', 'information'), ('information', 'many')]

>> Trigrams are: 
 [('addition', 'Multi-variate', 'Bernoulli'), ('Multi-variate', 'Bernoulli', 'model'), ('Bernoulli', 'model', ','), ('model', ',', 'also'), (',', 'also', 'captures'), ('also', 'captures', 'information'), ('captures', 'information', 'many')]

>> POS Tags are: 
 [('addition', 'NN'), ('Multi-variate', 'NNP'), ('Bernoulli', 'NNP'), ('model', 'NN'), (',', ','), ('also', 'RB'), ('captures', 'VBZ'), ('information', 'NN'), ('many', 'JJ')]

>> Noun Phrases are: 
 ['addition Multi-variate Bernoulli model', 'information']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('addition', 'addit'), ('Multi-variate', 'multi-vari'), ('Bernoulli', 'bernoulli'), ('model', 'model'), (',', ','), ('also', 'also'), ('captures', 'captur'), ('information', 'inform'), ('many', 'mani')]

>> Stemming using Snowball Stemmer: 
 [('addition', 'addit'), ('Multi-variate', 'multi-vari'), ('Bernoulli', 'bernoulli'), ('model', 'model'), (',', ','), ('also', 'also'), ('captures', 'captur'), ('information', 'inform'), ('many', 'mani')]

>> Lemmatization: 
 [('addition', 'addition'), ('Multi-variate', 'Multi-variate'), ('Bernoulli', 'Bernoulli'), ('model', 'model'), (',', ','), ('also', 'also'), ('captures', 'capture'), ('information', 'information'), ('many', 'many')]



========================================== PARAGRAPH 372 ===========================================

times a word is used in a document  

------------------- Sentence 1 -------------------

times a word is used in a document

>> Tokens are: 
 ['times', 'word', 'used', 'document']

>> Bigrams are: 
 [('times', 'word'), ('word', 'used'), ('used', 'document')]

>> Trigrams are: 
 [('times', 'word', 'used'), ('word', 'used', 'document')]

>> POS Tags are: 
 [('times', 'NNS'), ('word', 'NN'), ('used', 'VBN'), ('document', 'NN')]

>> Noun Phrases are: 
 ['times word', 'document']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('times', 'time'), ('word', 'word'), ('used', 'use'), ('document', 'document')]

>> Stemming using Snowball Stemmer: 
 [('times', 'time'), ('word', 'word'), ('used', 'use'), ('document', 'document')]

>> Lemmatization: 
 [('times', 'time'), ('word', 'word'), ('used', 'used'), ('document', 'document')]



========================================== PARAGRAPH 373 ===========================================

Discovery of knowledge is becoming important areas of research over the recent years.  

------------------- Sentence 1 -------------------

Discovery of knowledge is becoming important areas of research over the recent years.

>> Tokens are: 
 ['Discovery', 'knowledge', 'becoming', 'important', 'areas', 'research', 'recent', 'years', '.']

>> Bigrams are: 
 [('Discovery', 'knowledge'), ('knowledge', 'becoming'), ('becoming', 'important'), ('important', 'areas'), ('areas', 'research'), ('research', 'recent'), ('recent', 'years'), ('years', '.')]

>> Trigrams are: 
 [('Discovery', 'knowledge', 'becoming'), ('knowledge', 'becoming', 'important'), ('becoming', 'important', 'areas'), ('important', 'areas', 'research'), ('areas', 'research', 'recent'), ('research', 'recent', 'years'), ('recent', 'years', '.')]

>> POS Tags are: 
 [('Discovery', 'NNP'), ('knowledge', 'NN'), ('becoming', 'VBG'), ('important', 'JJ'), ('areas', 'NNS'), ('research', 'NN'), ('recent', 'JJ'), ('years', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['Discovery knowledge', 'important areas research', 'recent years']

>> Named Entities are: 
 [('GPE', 'Discovery')] 

>> Stemming using Porter Stemmer: 
 [('Discovery', 'discoveri'), ('knowledge', 'knowledg'), ('becoming', 'becom'), ('important', 'import'), ('areas', 'area'), ('research', 'research'), ('recent', 'recent'), ('years', 'year'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Discovery', 'discoveri'), ('knowledge', 'knowledg'), ('becoming', 'becom'), ('important', 'import'), ('areas', 'area'), ('research', 'research'), ('recent', 'recent'), ('years', 'year'), ('.', '.')]

>> Lemmatization: 
 [('Discovery', 'Discovery'), ('knowledge', 'knowledge'), ('becoming', 'becoming'), ('important', 'important'), ('areas', 'area'), ('research', 'research'), ('recent', 'recent'), ('years', 'year'), ('.', '.')]



========================================== PARAGRAPH 374 ===========================================

Knowledge discovery research use a variety of techniques in order to extract useful  

------------------- Sentence 1 -------------------

Knowledge discovery research use a variety of techniques in order to extract useful

>> Tokens are: 
 ['Knowledge', 'discovery', 'research', 'use', 'variety', 'techniques', 'order', 'extract', 'useful']

>> Bigrams are: 
 [('Knowledge', 'discovery'), ('discovery', 'research'), ('research', 'use'), ('use', 'variety'), ('variety', 'techniques'), ('techniques', 'order'), ('order', 'extract'), ('extract', 'useful')]

>> Trigrams are: 
 [('Knowledge', 'discovery', 'research'), ('discovery', 'research', 'use'), ('research', 'use', 'variety'), ('use', 'variety', 'techniques'), ('variety', 'techniques', 'order'), ('techniques', 'order', 'extract'), ('order', 'extract', 'useful')]

>> POS Tags are: 
 [('Knowledge', 'NNP'), ('discovery', 'NN'), ('research', 'NN'), ('use', 'NN'), ('variety', 'NN'), ('techniques', 'NNS'), ('order', 'NN'), ('extract', 'NN'), ('useful', 'JJ')]

>> Noun Phrases are: 
 ['Knowledge discovery research use variety techniques order extract']

>> Named Entities are: 
 [('GPE', 'Knowledge')] 

>> Stemming using Porter Stemmer: 
 [('Knowledge', 'knowledg'), ('discovery', 'discoveri'), ('research', 'research'), ('use', 'use'), ('variety', 'varieti'), ('techniques', 'techniqu'), ('order', 'order'), ('extract', 'extract'), ('useful', 'use')]

>> Stemming using Snowball Stemmer: 
 [('Knowledge', 'knowledg'), ('discovery', 'discoveri'), ('research', 'research'), ('use', 'use'), ('variety', 'varieti'), ('techniques', 'techniqu'), ('order', 'order'), ('extract', 'extract'), ('useful', 'use')]

>> Lemmatization: 
 [('Knowledge', 'Knowledge'), ('discovery', 'discovery'), ('research', 'research'), ('use', 'use'), ('variety', 'variety'), ('techniques', 'technique'), ('order', 'order'), ('extract', 'extract'), ('useful', 'useful')]



========================================== PARAGRAPH 375 ===========================================

information from source documents like   

------------------- Sentence 1 -------------------

information from source documents like

>> Tokens are: 
 ['information', 'source', 'documents', 'like']

>> Bigrams are: 
 [('information', 'source'), ('source', 'documents'), ('documents', 'like')]

>> Trigrams are: 
 [('information', 'source', 'documents'), ('source', 'documents', 'like')]

>> POS Tags are: 
 [('information', 'NN'), ('source', 'NN'), ('documents', 'NNS'), ('like', 'IN')]

>> Noun Phrases are: 
 ['information source documents']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('information', 'inform'), ('source', 'sourc'), ('documents', 'document'), ('like', 'like')]

>> Stemming using Snowball Stemmer: 
 [('information', 'inform'), ('source', 'sourc'), ('documents', 'document'), ('like', 'like')]

>> Lemmatization: 
 [('information', 'information'), ('source', 'source'), ('documents', 'document'), ('like', 'like')]



========================================== PARAGRAPH 376 ===========================================

Parts of Speech (POS) tagging, Chunking or Shadow Parsing, Stop-words (Keywords that  

------------------- Sentence 1 -------------------

Parts of Speech (POS) tagging, Chunking or Shadow Parsing, Stop-words (Keywords that

>> Tokens are: 
 ['Parts', 'Speech', '(', 'POS', ')', 'tagging', ',', 'Chunking', 'Shadow', 'Parsing', ',', 'Stop-words', '(', 'Keywords']

>> Bigrams are: 
 [('Parts', 'Speech'), ('Speech', '('), ('(', 'POS'), ('POS', ')'), (')', 'tagging'), ('tagging', ','), (',', 'Chunking'), ('Chunking', 'Shadow'), ('Shadow', 'Parsing'), ('Parsing', ','), (',', 'Stop-words'), ('Stop-words', '('), ('(', 'Keywords')]

>> Trigrams are: 
 [('Parts', 'Speech', '('), ('Speech', '(', 'POS'), ('(', 'POS', ')'), ('POS', ')', 'tagging'), (')', 'tagging', ','), ('tagging', ',', 'Chunking'), (',', 'Chunking', 'Shadow'), ('Chunking', 'Shadow', 'Parsing'), ('Shadow', 'Parsing', ','), ('Parsing', ',', 'Stop-words'), (',', 'Stop-words', '('), ('Stop-words', '(', 'Keywords')]

>> POS Tags are: 
 [('Parts', 'NNS'), ('Speech', 'NNP'), ('(', '('), ('POS', 'NNP'), (')', ')'), ('tagging', 'NN'), (',', ','), ('Chunking', 'VBG'), ('Shadow', 'NNP'), ('Parsing', 'NNP'), (',', ','), ('Stop-words', 'NNP'), ('(', '('), ('Keywords', 'NNP')]

>> Noun Phrases are: 
 ['Parts Speech', 'POS', 'tagging', 'Shadow Parsing', 'Stop-words', 'Keywords']

>> Named Entities are: 
 [('GPE', 'Speech'), ('ORGANIZATION', 'POS'), ('PERSON', 'Shadow Parsing'), ('ORGANIZATION', 'Keywords')] 

>> Stemming using Porter Stemmer: 
 [('Parts', 'part'), ('Speech', 'speech'), ('(', '('), ('POS', 'po'), (')', ')'), ('tagging', 'tag'), (',', ','), ('Chunking', 'chunk'), ('Shadow', 'shadow'), ('Parsing', 'pars'), (',', ','), ('Stop-words', 'stop-word'), ('(', '('), ('Keywords', 'keyword')]

>> Stemming using Snowball Stemmer: 
 [('Parts', 'part'), ('Speech', 'speech'), ('(', '('), ('POS', 'pos'), (')', ')'), ('tagging', 'tag'), (',', ','), ('Chunking', 'chunk'), ('Shadow', 'shadow'), ('Parsing', 'pars'), (',', ','), ('Stop-words', 'stop-word'), ('(', '('), ('Keywords', 'keyword')]

>> Lemmatization: 
 [('Parts', 'Parts'), ('Speech', 'Speech'), ('(', '('), ('POS', 'POS'), (')', ')'), ('tagging', 'tagging'), (',', ','), ('Chunking', 'Chunking'), ('Shadow', 'Shadow'), ('Parsing', 'Parsing'), (',', ','), ('Stop-words', 'Stop-words'), ('(', '('), ('Keywords', 'Keywords')]



========================================== PARAGRAPH 377 ===========================================

are used and must be removed before processing documents), Stemming (Mapping words to  

------------------- Sentence 1 -------------------

are used and must be removed before processing documents), Stemming (Mapping words to

>> Tokens are: 
 ['used', 'must', 'removed', 'processing', 'documents', ')', ',', 'Stemming', '(', 'Mapping', 'words']

>> Bigrams are: 
 [('used', 'must'), ('must', 'removed'), ('removed', 'processing'), ('processing', 'documents'), ('documents', ')'), (')', ','), (',', 'Stemming'), ('Stemming', '('), ('(', 'Mapping'), ('Mapping', 'words')]

>> Trigrams are: 
 [('used', 'must', 'removed'), ('must', 'removed', 'processing'), ('removed', 'processing', 'documents'), ('processing', 'documents', ')'), ('documents', ')', ','), (')', ',', 'Stemming'), (',', 'Stemming', '('), ('Stemming', '(', 'Mapping'), ('(', 'Mapping', 'words')]

>> POS Tags are: 
 [('used', 'VBN'), ('must', 'MD'), ('removed', 'VB'), ('processing', 'NN'), ('documents', 'NNS'), (')', ')'), (',', ','), ('Stemming', 'VBG'), ('(', '('), ('Mapping', 'VBG'), ('words', 'NNS')]

>> Noun Phrases are: 
 ['processing documents', 'words']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('used', 'use'), ('must', 'must'), ('removed', 'remov'), ('processing', 'process'), ('documents', 'document'), (')', ')'), (',', ','), ('Stemming', 'stem'), ('(', '('), ('Mapping', 'map'), ('words', 'word')]

>> Stemming using Snowball Stemmer: 
 [('used', 'use'), ('must', 'must'), ('removed', 'remov'), ('processing', 'process'), ('documents', 'document'), (')', ')'), (',', ','), ('Stemming', 'stem'), ('(', '('), ('Mapping', 'map'), ('words', 'word')]

>> Lemmatization: 
 [('used', 'used'), ('must', 'must'), ('removed', 'removed'), ('processing', 'processing'), ('documents', 'document'), (')', ')'), (',', ','), ('Stemming', 'Stemming'), ('(', '('), ('Mapping', 'Mapping'), ('words', 'word')]



========================================== PARAGRAPH 378 ===========================================

some base for, it has two methods, dictionary based stemming and Porter style stemming  

------------------- Sentence 1 -------------------

some base for, it has two methods, dictionary based stemming and Porter style stemming

>> Tokens are: 
 ['base', ',', 'two', 'methods', ',', 'dictionary', 'based', 'stemming', 'Porter', 'style', 'stemming']

>> Bigrams are: 
 [('base', ','), (',', 'two'), ('two', 'methods'), ('methods', ','), (',', 'dictionary'), ('dictionary', 'based'), ('based', 'stemming'), ('stemming', 'Porter'), ('Porter', 'style'), ('style', 'stemming')]

>> Trigrams are: 
 [('base', ',', 'two'), (',', 'two', 'methods'), ('two', 'methods', ','), ('methods', ',', 'dictionary'), (',', 'dictionary', 'based'), ('dictionary', 'based', 'stemming'), ('based', 'stemming', 'Porter'), ('stemming', 'Porter', 'style'), ('Porter', 'style', 'stemming')]

>> POS Tags are: 
 [('base', 'NN'), (',', ','), ('two', 'CD'), ('methods', 'NNS'), (',', ','), ('dictionary', 'JJ'), ('based', 'VBN'), ('stemming', 'VBG'), ('Porter', 'NNP'), ('style', 'NN'), ('stemming', 'VBG')]

>> Noun Phrases are: 
 ['base', 'methods', 'Porter style']

>> Named Entities are: 
 [('PERSON', 'Porter')] 

>> Stemming using Porter Stemmer: 
 [('base', 'base'), (',', ','), ('two', 'two'), ('methods', 'method'), (',', ','), ('dictionary', 'dictionari'), ('based', 'base'), ('stemming', 'stem'), ('Porter', 'porter'), ('style', 'style'), ('stemming', 'stem')]

>> Stemming using Snowball Stemmer: 
 [('base', 'base'), (',', ','), ('two', 'two'), ('methods', 'method'), (',', ','), ('dictionary', 'dictionari'), ('based', 'base'), ('stemming', 'stem'), ('Porter', 'porter'), ('style', 'style'), ('stemming', 'stem')]

>> Lemmatization: 
 [('base', 'base'), (',', ','), ('two', 'two'), ('methods', 'method'), (',', ','), ('dictionary', 'dictionary'), ('based', 'based'), ('stemming', 'stemming'), ('Porter', 'Porter'), ('style', 'style'), ('stemming', 'stemming')]



========================================== PARAGRAPH 379 ===========================================

(Porter, 1980) [55]. Former one has higher accuracy but higher cost of implementation while  

------------------- Sentence 1 -------------------

(Porter, 1980) [55].

>> Tokens are: 
 ['(', 'Porter', ',', '1980', ')', '[', '55', ']', '.']

>> Bigrams are: 
 [('(', 'Porter'), ('Porter', ','), (',', '1980'), ('1980', ')'), (')', '['), ('[', '55'), ('55', ']'), (']', '.')]

>> Trigrams are: 
 [('(', 'Porter', ','), ('Porter', ',', '1980'), (',', '1980', ')'), ('1980', ')', '['), (')', '[', '55'), ('[', '55', ']'), ('55', ']', '.')]

>> POS Tags are: 
 [('(', '('), ('Porter', 'NNP'), (',', ','), ('1980', 'CD'), (')', ')'), ('[', 'VBD'), ('55', 'CD'), (']', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Porter', ']']

>> Named Entities are: 
 [('PERSON', 'Porter')] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('Porter', 'porter'), (',', ','), ('1980', '1980'), (')', ')'), ('[', '['), ('55', '55'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('Porter', 'porter'), (',', ','), ('1980', '1980'), (')', ')'), ('[', '['), ('55', '55'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('(', '('), ('Porter', 'Porter'), (',', ','), ('1980', '1980'), (')', ')'), ('[', '['), ('55', '55'), (']', ']'), ('.', '.')]


------------------- Sentence 2 -------------------

Former one has higher accuracy but higher cost of implementation while

>> Tokens are: 
 ['Former', 'one', 'higher', 'accuracy', 'higher', 'cost', 'implementation']

>> Bigrams are: 
 [('Former', 'one'), ('one', 'higher'), ('higher', 'accuracy'), ('accuracy', 'higher'), ('higher', 'cost'), ('cost', 'implementation')]

>> Trigrams are: 
 [('Former', 'one', 'higher'), ('one', 'higher', 'accuracy'), ('higher', 'accuracy', 'higher'), ('accuracy', 'higher', 'cost'), ('higher', 'cost', 'implementation')]

>> POS Tags are: 
 [('Former', 'NNP'), ('one', 'CD'), ('higher', 'JJR'), ('accuracy', 'NN'), ('higher', 'JJR'), ('cost', 'NN'), ('implementation', 'NN')]

>> Noun Phrases are: 
 ['Former', 'accuracy', 'cost implementation']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Former', 'former'), ('one', 'one'), ('higher', 'higher'), ('accuracy', 'accuraci'), ('higher', 'higher'), ('cost', 'cost'), ('implementation', 'implement')]

>> Stemming using Snowball Stemmer: 
 [('Former', 'former'), ('one', 'one'), ('higher', 'higher'), ('accuracy', 'accuraci'), ('higher', 'higher'), ('cost', 'cost'), ('implementation', 'implement')]

>> Lemmatization: 
 [('Former', 'Former'), ('one', 'one'), ('higher', 'higher'), ('accuracy', 'accuracy'), ('higher', 'higher'), ('cost', 'cost'), ('implementation', 'implementation')]



========================================== PARAGRAPH 380 ===========================================

latter has lower implementation cost and is usually insufficient for IR). Compound or  

------------------- Sentence 1 -------------------

latter has lower implementation cost and is usually insufficient for IR).

>> Tokens are: 
 ['latter', 'lower', 'implementation', 'cost', 'usually', 'insufficient', 'IR', ')', '.']

>> Bigrams are: 
 [('latter', 'lower'), ('lower', 'implementation'), ('implementation', 'cost'), ('cost', 'usually'), ('usually', 'insufficient'), ('insufficient', 'IR'), ('IR', ')'), (')', '.')]

>> Trigrams are: 
 [('latter', 'lower', 'implementation'), ('lower', 'implementation', 'cost'), ('implementation', 'cost', 'usually'), ('cost', 'usually', 'insufficient'), ('usually', 'insufficient', 'IR'), ('insufficient', 'IR', ')'), ('IR', ')', '.')]

>> POS Tags are: 
 [('latter', 'NN'), ('lower', 'JJR'), ('implementation', 'NN'), ('cost', 'NN'), ('usually', 'RB'), ('insufficient', 'JJ'), ('IR', 'NNP'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['latter', 'implementation cost', 'insufficient IR']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('latter', 'latter'), ('lower', 'lower'), ('implementation', 'implement'), ('cost', 'cost'), ('usually', 'usual'), ('insufficient', 'insuffici'), ('IR', 'ir'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('latter', 'latter'), ('lower', 'lower'), ('implementation', 'implement'), ('cost', 'cost'), ('usually', 'usual'), ('insufficient', 'insuffici'), ('IR', 'ir'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('latter', 'latter'), ('lower', 'lower'), ('implementation', 'implementation'), ('cost', 'cost'), ('usually', 'usually'), ('insufficient', 'insufficient'), ('IR', 'IR'), (')', ')'), ('.', '.')]


------------------- Sentence 2 -------------------

Compound or

>> Tokens are: 
 ['Compound']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Compound', 'NN')]

>> Noun Phrases are: 
 ['Compound']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Compound', 'compound')]

>> Stemming using Snowball Stemmer: 
 [('Compound', 'compound')]

>> Lemmatization: 
 [('Compound', 'Compound')]



========================================== PARAGRAPH 381 ===========================================

Statistical Phrases (Compounds and statistical phrases index multi token units instead of  

------------------- Sentence 1 -------------------

Statistical Phrases (Compounds and statistical phrases index multi token units instead of

>> Tokens are: 
 ['Statistical', 'Phrases', '(', 'Compounds', 'statistical', 'phrases', 'index', 'multi', 'token', 'units', 'instead']

>> Bigrams are: 
 [('Statistical', 'Phrases'), ('Phrases', '('), ('(', 'Compounds'), ('Compounds', 'statistical'), ('statistical', 'phrases'), ('phrases', 'index'), ('index', 'multi'), ('multi', 'token'), ('token', 'units'), ('units', 'instead')]

>> Trigrams are: 
 [('Statistical', 'Phrases', '('), ('Phrases', '(', 'Compounds'), ('(', 'Compounds', 'statistical'), ('Compounds', 'statistical', 'phrases'), ('statistical', 'phrases', 'index'), ('phrases', 'index', 'multi'), ('index', 'multi', 'token'), ('multi', 'token', 'units'), ('token', 'units', 'instead')]

>> POS Tags are: 
 [('Statistical', 'JJ'), ('Phrases', 'NNP'), ('(', '('), ('Compounds', 'NNP'), ('statistical', 'JJ'), ('phrases', 'NNS'), ('index', 'NN'), ('multi', 'VBP'), ('token', 'VBN'), ('units', 'NNS'), ('instead', 'RB')]

>> Noun Phrases are: 
 ['Statistical Phrases', 'Compounds', 'statistical phrases index', 'units']

>> Named Entities are: 
 [('GPE', 'Phrases'), ('ORGANIZATION', 'Compounds')] 

>> Stemming using Porter Stemmer: 
 [('Statistical', 'statist'), ('Phrases', 'phrase'), ('(', '('), ('Compounds', 'compound'), ('statistical', 'statist'), ('phrases', 'phrase'), ('index', 'index'), ('multi', 'multi'), ('token', 'token'), ('units', 'unit'), ('instead', 'instead')]

>> Stemming using Snowball Stemmer: 
 [('Statistical', 'statist'), ('Phrases', 'phrase'), ('(', '('), ('Compounds', 'compound'), ('statistical', 'statist'), ('phrases', 'phrase'), ('index', 'index'), ('multi', 'multi'), ('token', 'token'), ('units', 'unit'), ('instead', 'instead')]

>> Lemmatization: 
 [('Statistical', 'Statistical'), ('Phrases', 'Phrases'), ('(', '('), ('Compounds', 'Compounds'), ('statistical', 'statistical'), ('phrases', 'phrase'), ('index', 'index'), ('multi', 'multi'), ('token', 'token'), ('units', 'unit'), ('instead', 'instead')]



========================================== PARAGRAPH 382 ===========================================

single tokens.) Word Sense Disambiguation (Word sense disambiguation is the task of  

------------------- Sentence 1 -------------------

single tokens.)

>> Tokens are: 
 ['single', 'tokens', '.', ')']

>> Bigrams are: 
 [('single', 'tokens'), ('tokens', '.'), ('.', ')')]

>> Trigrams are: 
 [('single', 'tokens', '.'), ('tokens', '.', ')')]

>> POS Tags are: 
 [('single', 'JJ'), ('tokens', 'NNS'), ('.', '.'), (')', ')')]

>> Noun Phrases are: 
 ['single tokens']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('single', 'singl'), ('tokens', 'token'), ('.', '.'), (')', ')')]

>> Stemming using Snowball Stemmer: 
 [('single', 'singl'), ('tokens', 'token'), ('.', '.'), (')', ')')]

>> Lemmatization: 
 [('single', 'single'), ('tokens', 'token'), ('.', '.'), (')', ')')]


------------------- Sentence 2 -------------------

Word Sense Disambiguation (Word sense disambiguation is the task of

>> Tokens are: 
 ['Word', 'Sense', 'Disambiguation', '(', 'Word', 'sense', 'disambiguation', 'task']

>> Bigrams are: 
 [('Word', 'Sense'), ('Sense', 'Disambiguation'), ('Disambiguation', '('), ('(', 'Word'), ('Word', 'sense'), ('sense', 'disambiguation'), ('disambiguation', 'task')]

>> Trigrams are: 
 [('Word', 'Sense', 'Disambiguation'), ('Sense', 'Disambiguation', '('), ('Disambiguation', '(', 'Word'), ('(', 'Word', 'sense'), ('Word', 'sense', 'disambiguation'), ('sense', 'disambiguation', 'task')]

>> POS Tags are: 
 [('Word', 'NNP'), ('Sense', 'NNP'), ('Disambiguation', 'NNP'), ('(', '('), ('Word', 'NNP'), ('sense', 'NN'), ('disambiguation', 'NN'), ('task', 'NN')]

>> Noun Phrases are: 
 ['Word Sense Disambiguation', 'Word sense disambiguation task']

>> Named Entities are: 
 [('PERSON', 'Word'), ('ORGANIZATION', 'Word')] 

>> Stemming using Porter Stemmer: 
 [('Word', 'word'), ('Sense', 'sens'), ('Disambiguation', 'disambigu'), ('(', '('), ('Word', 'word'), ('sense', 'sens'), ('disambiguation', 'disambigu'), ('task', 'task')]

>> Stemming using Snowball Stemmer: 
 [('Word', 'word'), ('Sense', 'sens'), ('Disambiguation', 'disambigu'), ('(', '('), ('Word', 'word'), ('sense', 'sens'), ('disambiguation', 'disambigu'), ('task', 'task')]

>> Lemmatization: 
 [('Word', 'Word'), ('Sense', 'Sense'), ('Disambiguation', 'Disambiguation'), ('(', '('), ('Word', 'Word'), ('sense', 'sense'), ('disambiguation', 'disambiguation'), ('task', 'task')]



========================================== PARAGRAPH 383 ===========================================

understanding the correct sense of a word in context. When used for information retrieval,  

------------------- Sentence 1 -------------------

understanding the correct sense of a word in context.

>> Tokens are: 
 ['understanding', 'correct', 'sense', 'word', 'context', '.']

>> Bigrams are: 
 [('understanding', 'correct'), ('correct', 'sense'), ('sense', 'word'), ('word', 'context'), ('context', '.')]

>> Trigrams are: 
 [('understanding', 'correct', 'sense'), ('correct', 'sense', 'word'), ('sense', 'word', 'context'), ('word', 'context', '.')]

>> POS Tags are: 
 [('understanding', 'VBG'), ('correct', 'JJ'), ('sense', 'NN'), ('word', 'NN'), ('context', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['correct sense word context']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('understanding', 'understand'), ('correct', 'correct'), ('sense', 'sens'), ('word', 'word'), ('context', 'context'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('understanding', 'understand'), ('correct', 'correct'), ('sense', 'sens'), ('word', 'word'), ('context', 'context'), ('.', '.')]

>> Lemmatization: 
 [('understanding', 'understanding'), ('correct', 'correct'), ('sense', 'sense'), ('word', 'word'), ('context', 'context'), ('.', '.')]


------------------- Sentence 2 -------------------

When used for information retrieval,

>> Tokens are: 
 ['When', 'used', 'information', 'retrieval', ',']

>> Bigrams are: 
 [('When', 'used'), ('used', 'information'), ('information', 'retrieval'), ('retrieval', ',')]

>> Trigrams are: 
 [('When', 'used', 'information'), ('used', 'information', 'retrieval'), ('information', 'retrieval', ',')]

>> POS Tags are: 
 [('When', 'WRB'), ('used', 'VBN'), ('information', 'NN'), ('retrieval', 'NN'), (',', ',')]

>> Noun Phrases are: 
 ['information retrieval']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('When', 'when'), ('used', 'use'), ('information', 'inform'), ('retrieval', 'retriev'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('When', 'when'), ('used', 'use'), ('information', 'inform'), ('retrieval', 'retriev'), (',', ',')]

>> Lemmatization: 
 [('When', 'When'), ('used', 'used'), ('information', 'information'), ('retrieval', 'retrieval'), (',', ',')]



========================================== PARAGRAPH 384 ===========================================

terms are replaced by their senses in the document vector.)  

------------------- Sentence 1 -------------------

terms are replaced by their senses in the document vector.)

>> Tokens are: 
 ['terms', 'replaced', 'senses', 'document', 'vector', '.', ')']

>> Bigrams are: 
 [('terms', 'replaced'), ('replaced', 'senses'), ('senses', 'document'), ('document', 'vector'), ('vector', '.'), ('.', ')')]

>> Trigrams are: 
 [('terms', 'replaced', 'senses'), ('replaced', 'senses', 'document'), ('senses', 'document', 'vector'), ('document', 'vector', '.'), ('vector', '.', ')')]

>> POS Tags are: 
 [('terms', 'NNS'), ('replaced', 'VBD'), ('senses', 'NNS'), ('document', 'JJ'), ('vector', 'NN'), ('.', '.'), (')', ')')]

>> Noun Phrases are: 
 ['terms', 'senses', 'document vector']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('terms', 'term'), ('replaced', 'replac'), ('senses', 'sens'), ('document', 'document'), ('vector', 'vector'), ('.', '.'), (')', ')')]

>> Stemming using Snowball Stemmer: 
 [('terms', 'term'), ('replaced', 'replac'), ('senses', 'sens'), ('document', 'document'), ('vector', 'vector'), ('.', '.'), (')', ')')]

>> Lemmatization: 
 [('terms', 'term'), ('replaced', 'replaced'), ('senses', 'sens'), ('document', 'document'), ('vector', 'vector'), ('.', '.'), (')', ')')]



========================================== PARAGRAPH 385 ===========================================

  


========================================== PARAGRAPH 386 ===========================================

Its extracted information can be applied on a variety of purpose, for example to prepare a  

------------------- Sentence 1 -------------------

Its extracted information can be applied on a variety of purpose, for example to prepare a

>> Tokens are: 
 ['Its', 'extracted', 'information', 'applied', 'variety', 'purpose', ',', 'example', 'prepare']

>> Bigrams are: 
 [('Its', 'extracted'), ('extracted', 'information'), ('information', 'applied'), ('applied', 'variety'), ('variety', 'purpose'), ('purpose', ','), (',', 'example'), ('example', 'prepare')]

>> Trigrams are: 
 [('Its', 'extracted', 'information'), ('extracted', 'information', 'applied'), ('information', 'applied', 'variety'), ('applied', 'variety', 'purpose'), ('variety', 'purpose', ','), ('purpose', ',', 'example'), (',', 'example', 'prepare')]

>> POS Tags are: 
 [('Its', 'PRP$'), ('extracted', 'JJ'), ('information', 'NN'), ('applied', 'VBD'), ('variety', 'NN'), ('purpose', 'NN'), (',', ','), ('example', 'NN'), ('prepare', 'NN')]

>> Noun Phrases are: 
 ['extracted information', 'variety purpose', 'example prepare']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Its', 'it'), ('extracted', 'extract'), ('information', 'inform'), ('applied', 'appli'), ('variety', 'varieti'), ('purpose', 'purpos'), (',', ','), ('example', 'exampl'), ('prepare', 'prepar')]

>> Stemming using Snowball Stemmer: 
 [('Its', 'it'), ('extracted', 'extract'), ('information', 'inform'), ('applied', 'appli'), ('variety', 'varieti'), ('purpose', 'purpos'), (',', ','), ('example', 'exampl'), ('prepare', 'prepar')]

>> Lemmatization: 
 [('Its', 'Its'), ('extracted', 'extracted'), ('information', 'information'), ('applied', 'applied'), ('variety', 'variety'), ('purpose', 'purpose'), (',', ','), ('example', 'example'), ('prepare', 'prepare')]



========================================== PARAGRAPH 387 ===========================================

summary, to build databases, identify keywords, classifying text items according to some pre- 

------------------- Sentence 1 -------------------

summary, to build databases, identify keywords, classifying text items according to some pre-

>> Tokens are: 
 ['summary', ',', 'build', 'databases', ',', 'identify', 'keywords', ',', 'classifying', 'text', 'items', 'according', 'pre-']

>> Bigrams are: 
 [('summary', ','), (',', 'build'), ('build', 'databases'), ('databases', ','), (',', 'identify'), ('identify', 'keywords'), ('keywords', ','), (',', 'classifying'), ('classifying', 'text'), ('text', 'items'), ('items', 'according'), ('according', 'pre-')]

>> Trigrams are: 
 [('summary', ',', 'build'), (',', 'build', 'databases'), ('build', 'databases', ','), ('databases', ',', 'identify'), (',', 'identify', 'keywords'), ('identify', 'keywords', ','), ('keywords', ',', 'classifying'), (',', 'classifying', 'text'), ('classifying', 'text', 'items'), ('text', 'items', 'according'), ('items', 'according', 'pre-')]

>> POS Tags are: 
 [('summary', 'NN'), (',', ','), ('build', 'JJ'), ('databases', 'NNS'), (',', ','), ('identify', 'VB'), ('keywords', 'NNS'), (',', ','), ('classifying', 'VBG'), ('text', 'NN'), ('items', 'NNS'), ('according', 'VBG'), ('pre-', 'NN')]

>> Noun Phrases are: 
 ['summary', 'build databases', 'keywords', 'text items', 'pre-']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('summary', 'summari'), (',', ','), ('build', 'build'), ('databases', 'databas'), (',', ','), ('identify', 'identifi'), ('keywords', 'keyword'), (',', ','), ('classifying', 'classifi'), ('text', 'text'), ('items', 'item'), ('according', 'accord'), ('pre-', 'pre-')]

>> Stemming using Snowball Stemmer: 
 [('summary', 'summari'), (',', ','), ('build', 'build'), ('databases', 'databas'), (',', ','), ('identify', 'identifi'), ('keywords', 'keyword'), (',', ','), ('classifying', 'classifi'), ('text', 'text'), ('items', 'item'), ('according', 'accord'), ('pre-', 'pre-')]

>> Lemmatization: 
 [('summary', 'summary'), (',', ','), ('build', 'build'), ('databases', 'database'), (',', ','), ('identify', 'identify'), ('keywords', 'keywords'), (',', ','), ('classifying', 'classifying'), ('text', 'text'), ('items', 'item'), ('according', 'according'), ('pre-', 'pre-')]



========================================== PARAGRAPH 388 ===========================================

defined categories etc. For example   CONSTRUE, it was developed for Reuters, that is used  

------------------- Sentence 1 -------------------

defined categories etc.

>> Tokens are: 
 ['defined', 'categories', 'etc', '.']

>> Bigrams are: 
 [('defined', 'categories'), ('categories', 'etc'), ('etc', '.')]

>> Trigrams are: 
 [('defined', 'categories', 'etc'), ('categories', 'etc', '.')]

>> POS Tags are: 
 [('defined', 'JJ'), ('categories', 'NNS'), ('etc', 'VBP'), ('.', '.')]

>> Noun Phrases are: 
 ['defined categories']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('defined', 'defin'), ('categories', 'categori'), ('etc', 'etc'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('defined', 'defin'), ('categories', 'categori'), ('etc', 'etc'), ('.', '.')]

>> Lemmatization: 
 [('defined', 'defined'), ('categories', 'category'), ('etc', 'etc'), ('.', '.')]


------------------- Sentence 2 -------------------

For example   CONSTRUE, it was developed for Reuters, that is used

>> Tokens are: 
 ['For', 'example', 'CONSTRUE', ',', 'developed', 'Reuters', ',', 'used']

>> Bigrams are: 
 [('For', 'example'), ('example', 'CONSTRUE'), ('CONSTRUE', ','), (',', 'developed'), ('developed', 'Reuters'), ('Reuters', ','), (',', 'used')]

>> Trigrams are: 
 [('For', 'example', 'CONSTRUE'), ('example', 'CONSTRUE', ','), ('CONSTRUE', ',', 'developed'), (',', 'developed', 'Reuters'), ('developed', 'Reuters', ','), ('Reuters', ',', 'used')]

>> POS Tags are: 
 [('For', 'IN'), ('example', 'NN'), ('CONSTRUE', 'NNP'), (',', ','), ('developed', 'VBD'), ('Reuters', 'NNP'), (',', ','), ('used', 'VBD')]

>> Noun Phrases are: 
 ['example CONSTRUE', 'Reuters']

>> Named Entities are: 
 [('ORGANIZATION', 'CONSTRUE'), ('ORGANIZATION', 'Reuters')] 

>> Stemming using Porter Stemmer: 
 [('For', 'for'), ('example', 'exampl'), ('CONSTRUE', 'constru'), (',', ','), ('developed', 'develop'), ('Reuters', 'reuter'), (',', ','), ('used', 'use')]

>> Stemming using Snowball Stemmer: 
 [('For', 'for'), ('example', 'exampl'), ('CONSTRUE', 'constru'), (',', ','), ('developed', 'develop'), ('Reuters', 'reuter'), (',', ','), ('used', 'use')]

>> Lemmatization: 
 [('For', 'For'), ('example', 'example'), ('CONSTRUE', 'CONSTRUE'), (',', ','), ('developed', 'developed'), ('Reuters', 'Reuters'), (',', ','), ('used', 'used')]



========================================== PARAGRAPH 389 ===========================================

in classifying news stories (Hayes, 1992) [57]. It has been suggested that many IE systems  

------------------- Sentence 1 -------------------

in classifying news stories (Hayes, 1992) [57].

>> Tokens are: 
 ['classifying', 'news', 'stories', '(', 'Hayes', ',', '1992', ')', '[', '57', ']', '.']

>> Bigrams are: 
 [('classifying', 'news'), ('news', 'stories'), ('stories', '('), ('(', 'Hayes'), ('Hayes', ','), (',', '1992'), ('1992', ')'), (')', '['), ('[', '57'), ('57', ']'), (']', '.')]

>> Trigrams are: 
 [('classifying', 'news', 'stories'), ('news', 'stories', '('), ('stories', '(', 'Hayes'), ('(', 'Hayes', ','), ('Hayes', ',', '1992'), (',', '1992', ')'), ('1992', ')', '['), (')', '[', '57'), ('[', '57', ']'), ('57', ']', '.')]

>> POS Tags are: 
 [('classifying', 'VBG'), ('news', 'NN'), ('stories', 'NNS'), ('(', '('), ('Hayes', 'NNP'), (',', ','), ('1992', 'CD'), (')', ')'), ('[', 'VBD'), ('57', 'CD'), (']', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['news stories', 'Hayes', ']']

>> Named Entities are: 
 [('PERSON', 'Hayes')] 

>> Stemming using Porter Stemmer: 
 [('classifying', 'classifi'), ('news', 'news'), ('stories', 'stori'), ('(', '('), ('Hayes', 'hay'), (',', ','), ('1992', '1992'), (')', ')'), ('[', '['), ('57', '57'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('classifying', 'classifi'), ('news', 'news'), ('stories', 'stori'), ('(', '('), ('Hayes', 'hay'), (',', ','), ('1992', '1992'), (')', ')'), ('[', '['), ('57', '57'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('classifying', 'classifying'), ('news', 'news'), ('stories', 'story'), ('(', '('), ('Hayes', 'Hayes'), (',', ','), ('1992', '1992'), (')', ')'), ('[', '['), ('57', '57'), (']', ']'), ('.', '.')]


------------------- Sentence 2 -------------------

It has been suggested that many IE systems

>> Tokens are: 
 ['It', 'suggested', 'many', 'IE', 'systems']

>> Bigrams are: 
 [('It', 'suggested'), ('suggested', 'many'), ('many', 'IE'), ('IE', 'systems')]

>> Trigrams are: 
 [('It', 'suggested', 'many'), ('suggested', 'many', 'IE'), ('many', 'IE', 'systems')]

>> POS Tags are: 
 [('It', 'PRP'), ('suggested', 'VBD'), ('many', 'JJ'), ('IE', 'NNP'), ('systems', 'NNS')]

>> Noun Phrases are: 
 ['many IE systems']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('It', 'it'), ('suggested', 'suggest'), ('many', 'mani'), ('IE', 'ie'), ('systems', 'system')]

>> Stemming using Snowball Stemmer: 
 [('It', 'it'), ('suggested', 'suggest'), ('many', 'mani'), ('IE', 'ie'), ('systems', 'system')]

>> Lemmatization: 
 [('It', 'It'), ('suggested', 'suggested'), ('many', 'many'), ('IE', 'IE'), ('systems', 'system')]



========================================== PARAGRAPH 390 ===========================================

can successfully extract terms from documents, acquiring relations between the terms is still a  

------------------- Sentence 1 -------------------

can successfully extract terms from documents, acquiring relations between the terms is still a

>> Tokens are: 
 ['successfully', 'extract', 'terms', 'documents', ',', 'acquiring', 'relations', 'terms', 'still']

>> Bigrams are: 
 [('successfully', 'extract'), ('extract', 'terms'), ('terms', 'documents'), ('documents', ','), (',', 'acquiring'), ('acquiring', 'relations'), ('relations', 'terms'), ('terms', 'still')]

>> Trigrams are: 
 [('successfully', 'extract', 'terms'), ('extract', 'terms', 'documents'), ('terms', 'documents', ','), ('documents', ',', 'acquiring'), (',', 'acquiring', 'relations'), ('acquiring', 'relations', 'terms'), ('relations', 'terms', 'still')]

>> POS Tags are: 
 [('successfully', 'RB'), ('extract', 'JJ'), ('terms', 'NNS'), ('documents', 'NNS'), (',', ','), ('acquiring', 'VBG'), ('relations', 'NNS'), ('terms', 'NNS'), ('still', 'RB')]

>> Noun Phrases are: 
 ['extract terms documents', 'relations terms']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('successfully', 'success'), ('extract', 'extract'), ('terms', 'term'), ('documents', 'document'), (',', ','), ('acquiring', 'acquir'), ('relations', 'relat'), ('terms', 'term'), ('still', 'still')]

>> Stemming using Snowball Stemmer: 
 [('successfully', 'success'), ('extract', 'extract'), ('terms', 'term'), ('documents', 'document'), (',', ','), ('acquiring', 'acquir'), ('relations', 'relat'), ('terms', 'term'), ('still', 'still')]

>> Lemmatization: 
 [('successfully', 'successfully'), ('extract', 'extract'), ('terms', 'term'), ('documents', 'document'), (',', ','), ('acquiring', 'acquiring'), ('relations', 'relation'), ('terms', 'term'), ('still', 'still')]



========================================== PARAGRAPH 391 ===========================================

difficulty. PROMETHEE is a system that extracts lexico-syntactic patterns relative to a  

------------------- Sentence 1 -------------------

difficulty.

>> Tokens are: 
 ['difficulty', '.']

>> Bigrams are: 
 [('difficulty', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('difficulty', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['difficulty']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('difficulty', 'difficulti'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('difficulty', 'difficulti'), ('.', '.')]

>> Lemmatization: 
 [('difficulty', 'difficulty'), ('.', '.')]


------------------- Sentence 2 -------------------

PROMETHEE is a system that extracts lexico-syntactic patterns relative to a

>> Tokens are: 
 ['PROMETHEE', 'system', 'extracts', 'lexico-syntactic', 'patterns', 'relative']

>> Bigrams are: 
 [('PROMETHEE', 'system'), ('system', 'extracts'), ('extracts', 'lexico-syntactic'), ('lexico-syntactic', 'patterns'), ('patterns', 'relative')]

>> Trigrams are: 
 [('PROMETHEE', 'system', 'extracts'), ('system', 'extracts', 'lexico-syntactic'), ('extracts', 'lexico-syntactic', 'patterns'), ('lexico-syntactic', 'patterns', 'relative')]

>> POS Tags are: 
 [('PROMETHEE', 'NNP'), ('system', 'NN'), ('extracts', 'VBZ'), ('lexico-syntactic', 'JJ'), ('patterns', 'NNS'), ('relative', 'JJ')]

>> Noun Phrases are: 
 ['PROMETHEE system', 'lexico-syntactic patterns']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('PROMETHEE', 'promethe'), ('system', 'system'), ('extracts', 'extract'), ('lexico-syntactic', 'lexico-syntact'), ('patterns', 'pattern'), ('relative', 'rel')]

>> Stemming using Snowball Stemmer: 
 [('PROMETHEE', 'promethe'), ('system', 'system'), ('extracts', 'extract'), ('lexico-syntactic', 'lexico-syntact'), ('patterns', 'pattern'), ('relative', 'relat')]

>> Lemmatization: 
 [('PROMETHEE', 'PROMETHEE'), ('system', 'system'), ('extracts', 'extract'), ('lexico-syntactic', 'lexico-syntactic'), ('patterns', 'pattern'), ('relative', 'relative')]



========================================== PARAGRAPH 392 ===========================================

specific conceptual relation (Morin,1999) [58]. IE systems should work at many levels, from  

------------------- Sentence 1 -------------------

specific conceptual relation (Morin,1999) [58].

>> Tokens are: 
 ['specific', 'conceptual', 'relation', '(', 'Morin,1999', ')', '[', '58', ']', '.']

>> Bigrams are: 
 [('specific', 'conceptual'), ('conceptual', 'relation'), ('relation', '('), ('(', 'Morin,1999'), ('Morin,1999', ')'), (')', '['), ('[', '58'), ('58', ']'), (']', '.')]

>> Trigrams are: 
 [('specific', 'conceptual', 'relation'), ('conceptual', 'relation', '('), ('relation', '(', 'Morin,1999'), ('(', 'Morin,1999', ')'), ('Morin,1999', ')', '['), (')', '[', '58'), ('[', '58', ']'), ('58', ']', '.')]

>> POS Tags are: 
 [('specific', 'JJ'), ('conceptual', 'JJ'), ('relation', 'NN'), ('(', '('), ('Morin,1999', 'NNP'), (')', ')'), ('[', 'VBD'), ('58', 'CD'), (']', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['specific conceptual relation', 'Morin,1999', ']']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('specific', 'specif'), ('conceptual', 'conceptu'), ('relation', 'relat'), ('(', '('), ('Morin,1999', 'morin,1999'), (')', ')'), ('[', '['), ('58', '58'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('specific', 'specif'), ('conceptual', 'conceptu'), ('relation', 'relat'), ('(', '('), ('Morin,1999', 'morin,1999'), (')', ')'), ('[', '['), ('58', '58'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('specific', 'specific'), ('conceptual', 'conceptual'), ('relation', 'relation'), ('(', '('), ('Morin,1999', 'Morin,1999'), (')', ')'), ('[', '['), ('58', '58'), (']', ']'), ('.', '.')]


------------------- Sentence 2 -------------------

IE systems should work at many levels, from

>> Tokens are: 
 ['IE', 'systems', 'work', 'many', 'levels', ',']

>> Bigrams are: 
 [('IE', 'systems'), ('systems', 'work'), ('work', 'many'), ('many', 'levels'), ('levels', ',')]

>> Trigrams are: 
 [('IE', 'systems', 'work'), ('systems', 'work', 'many'), ('work', 'many', 'levels'), ('many', 'levels', ',')]

>> POS Tags are: 
 [('IE', 'NNP'), ('systems', 'NNS'), ('work', 'VBP'), ('many', 'JJ'), ('levels', 'NNS'), (',', ',')]

>> Noun Phrases are: 
 ['IE systems', 'many levels']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('IE', 'ie'), ('systems', 'system'), ('work', 'work'), ('many', 'mani'), ('levels', 'level'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('IE', 'ie'), ('systems', 'system'), ('work', 'work'), ('many', 'mani'), ('levels', 'level'), (',', ',')]

>> Lemmatization: 
 [('IE', 'IE'), ('systems', 'system'), ('work', 'work'), ('many', 'many'), ('levels', 'level'), (',', ',')]



========================================== PARAGRAPH 393 ===========================================

word recognition to discourse analysis at the level of the complete document. An application  

------------------- Sentence 1 -------------------

word recognition to discourse analysis at the level of the complete document.

>> Tokens are: 
 ['word', 'recognition', 'discourse', 'analysis', 'level', 'complete', 'document', '.']

>> Bigrams are: 
 [('word', 'recognition'), ('recognition', 'discourse'), ('discourse', 'analysis'), ('analysis', 'level'), ('level', 'complete'), ('complete', 'document'), ('document', '.')]

>> Trigrams are: 
 [('word', 'recognition', 'discourse'), ('recognition', 'discourse', 'analysis'), ('discourse', 'analysis', 'level'), ('analysis', 'level', 'complete'), ('level', 'complete', 'document'), ('complete', 'document', '.')]

>> POS Tags are: 
 [('word', 'NN'), ('recognition', 'NN'), ('discourse', 'NN'), ('analysis', 'NN'), ('level', 'NN'), ('complete', 'JJ'), ('document', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['word recognition discourse analysis level', 'complete document']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('word', 'word'), ('recognition', 'recognit'), ('discourse', 'discours'), ('analysis', 'analysi'), ('level', 'level'), ('complete', 'complet'), ('document', 'document'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('word', 'word'), ('recognition', 'recognit'), ('discourse', 'discours'), ('analysis', 'analysi'), ('level', 'level'), ('complete', 'complet'), ('document', 'document'), ('.', '.')]

>> Lemmatization: 
 [('word', 'word'), ('recognition', 'recognition'), ('discourse', 'discourse'), ('analysis', 'analysis'), ('level', 'level'), ('complete', 'complete'), ('document', 'document'), ('.', '.')]


------------------- Sentence 2 -------------------

An application

>> Tokens are: 
 ['An', 'application']

>> Bigrams are: 
 [('An', 'application')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('An', 'DT'), ('application', 'NN')]

>> Noun Phrases are: 
 ['An application']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('An', 'an'), ('application', 'applic')]

>> Stemming using Snowball Stemmer: 
 [('An', 'an'), ('application', 'applic')]

>> Lemmatization: 
 [('An', 'An'), ('application', 'application')]



========================================== PARAGRAPH 394 ===========================================

of the Blank Slate Language Processor (BSLP) (Bondale et al., 1999) [59] approach for the  

------------------- Sentence 1 -------------------

of the Blank Slate Language Processor (BSLP) (Bondale et al., 1999) [59] approach for the

>> Tokens are: 
 ['Blank', 'Slate', 'Language', 'Processor', '(', 'BSLP', ')', '(', 'Bondale', 'et', 'al.', ',', '1999', ')', '[', '59', ']', 'approach']

>> Bigrams are: 
 [('Blank', 'Slate'), ('Slate', 'Language'), ('Language', 'Processor'), ('Processor', '('), ('(', 'BSLP'), ('BSLP', ')'), (')', '('), ('(', 'Bondale'), ('Bondale', 'et'), ('et', 'al.'), ('al.', ','), (',', '1999'), ('1999', ')'), (')', '['), ('[', '59'), ('59', ']'), (']', 'approach')]

>> Trigrams are: 
 [('Blank', 'Slate', 'Language'), ('Slate', 'Language', 'Processor'), ('Language', 'Processor', '('), ('Processor', '(', 'BSLP'), ('(', 'BSLP', ')'), ('BSLP', ')', '('), (')', '(', 'Bondale'), ('(', 'Bondale', 'et'), ('Bondale', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '1999'), (',', '1999', ')'), ('1999', ')', '['), (')', '[', '59'), ('[', '59', ']'), ('59', ']', 'approach')]

>> POS Tags are: 
 [('Blank', 'NNP'), ('Slate', 'NNP'), ('Language', 'NNP'), ('Processor', 'NNP'), ('(', '('), ('BSLP', 'NNP'), (')', ')'), ('(', '('), ('Bondale', 'NNP'), ('et', 'FW'), ('al.', 'NN'), (',', ','), ('1999', 'CD'), (')', ')'), ('[', 'VBD'), ('59', 'CD'), (']', 'NNS'), ('approach', 'NN')]

>> Noun Phrases are: 
 ['Blank Slate Language Processor', 'BSLP', 'Bondale', 'al.', '] approach']

>> Named Entities are: 
 [('PERSON', 'Blank'), ('ORGANIZATION', 'Slate Language'), ('ORGANIZATION', 'BSLP'), ('ORGANIZATION', 'Bondale')] 

>> Stemming using Porter Stemmer: 
 [('Blank', 'blank'), ('Slate', 'slate'), ('Language', 'languag'), ('Processor', 'processor'), ('(', '('), ('BSLP', 'bslp'), (')', ')'), ('(', '('), ('Bondale', 'bondal'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('1999', '1999'), (')', ')'), ('[', '['), ('59', '59'), (']', ']'), ('approach', 'approach')]

>> Stemming using Snowball Stemmer: 
 [('Blank', 'blank'), ('Slate', 'slate'), ('Language', 'languag'), ('Processor', 'processor'), ('(', '('), ('BSLP', 'bslp'), (')', ')'), ('(', '('), ('Bondale', 'bondal'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('1999', '1999'), (')', ')'), ('[', '['), ('59', '59'), (']', ']'), ('approach', 'approach')]

>> Lemmatization: 
 [('Blank', 'Blank'), ('Slate', 'Slate'), ('Language', 'Language'), ('Processor', 'Processor'), ('(', '('), ('BSLP', 'BSLP'), (')', ')'), ('(', '('), ('Bondale', 'Bondale'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('1999', '1999'), (')', ')'), ('[', '['), ('59', '59'), (']', ']'), ('approach', 'approach')]



========================================== PARAGRAPH 395 ===========================================

analysis of a real life natural language corpus that consists of responses to open-ended  

------------------- Sentence 1 -------------------

analysis of a real life natural language corpus that consists of responses to open-ended

>> Tokens are: 
 ['analysis', 'real', 'life', 'natural', 'language', 'corpus', 'consists', 'responses', 'open-ended']

>> Bigrams are: 
 [('analysis', 'real'), ('real', 'life'), ('life', 'natural'), ('natural', 'language'), ('language', 'corpus'), ('corpus', 'consists'), ('consists', 'responses'), ('responses', 'open-ended')]

>> Trigrams are: 
 [('analysis', 'real', 'life'), ('real', 'life', 'natural'), ('life', 'natural', 'language'), ('natural', 'language', 'corpus'), ('language', 'corpus', 'consists'), ('corpus', 'consists', 'responses'), ('consists', 'responses', 'open-ended')]

>> POS Tags are: 
 [('analysis', 'NN'), ('real', 'JJ'), ('life', 'NN'), ('natural', 'JJ'), ('language', 'NN'), ('corpus', 'NN'), ('consists', 'VBZ'), ('responses', 'VBZ'), ('open-ended', 'JJ')]

>> Noun Phrases are: 
 ['analysis', 'real life', 'natural language corpus']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('analysis', 'analysi'), ('real', 'real'), ('life', 'life'), ('natural', 'natur'), ('language', 'languag'), ('corpus', 'corpu'), ('consists', 'consist'), ('responses', 'respons'), ('open-ended', 'open-end')]

>> Stemming using Snowball Stemmer: 
 [('analysis', 'analysi'), ('real', 'real'), ('life', 'life'), ('natural', 'natur'), ('language', 'languag'), ('corpus', 'corpus'), ('consists', 'consist'), ('responses', 'respons'), ('open-ended', 'open-end')]

>> Lemmatization: 
 [('analysis', 'analysis'), ('real', 'real'), ('life', 'life'), ('natural', 'natural'), ('language', 'language'), ('corpus', 'corpus'), ('consists', 'consists'), ('responses', 'response'), ('open-ended', 'open-ended')]



========================================== PARAGRAPH 396 ===========================================

questionnaires in the field of advertising.  

------------------- Sentence 1 -------------------

questionnaires in the field of advertising.

>> Tokens are: 
 ['questionnaires', 'field', 'advertising', '.']

>> Bigrams are: 
 [('questionnaires', 'field'), ('field', 'advertising'), ('advertising', '.')]

>> Trigrams are: 
 [('questionnaires', 'field', 'advertising'), ('field', 'advertising', '.')]

>> POS Tags are: 
 [('questionnaires', 'NNS'), ('field', 'NN'), ('advertising', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['questionnaires field advertising']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('questionnaires', 'questionnair'), ('field', 'field'), ('advertising', 'advertis'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('questionnaires', 'questionnair'), ('field', 'field'), ('advertising', 'advertis'), ('.', '.')]

>> Lemmatization: 
 [('questionnaires', 'questionnaire'), ('field', 'field'), ('advertising', 'advertising'), ('.', '.')]



========================================== PARAGRAPH 397 ===========================================

There’s a system called MITA (Metlife’s Intelligent Text Analyzer) (Glasgow et al. (1998)  

------------------- Sentence 1 -------------------

There’s a system called MITA (Metlife’s Intelligent Text Analyzer) (Glasgow et al.

>> Tokens are: 
 ['There', '’', 'system', 'called', 'MITA', '(', 'Metlife', '’', 'Intelligent', 'Text', 'Analyzer', ')', '(', 'Glasgow', 'et', 'al', '.']

>> Bigrams are: 
 [('There', '’'), ('’', 'system'), ('system', 'called'), ('called', 'MITA'), ('MITA', '('), ('(', 'Metlife'), ('Metlife', '’'), ('’', 'Intelligent'), ('Intelligent', 'Text'), ('Text', 'Analyzer'), ('Analyzer', ')'), (')', '('), ('(', 'Glasgow'), ('Glasgow', 'et'), ('et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('There', '’', 'system'), ('’', 'system', 'called'), ('system', 'called', 'MITA'), ('called', 'MITA', '('), ('MITA', '(', 'Metlife'), ('(', 'Metlife', '’'), ('Metlife', '’', 'Intelligent'), ('’', 'Intelligent', 'Text'), ('Intelligent', 'Text', 'Analyzer'), ('Text', 'Analyzer', ')'), ('Analyzer', ')', '('), (')', '(', 'Glasgow'), ('(', 'Glasgow', 'et'), ('Glasgow', 'et', 'al'), ('et', 'al', '.')]

>> POS Tags are: 
 [('There', 'EX'), ('’', 'NN'), ('system', 'NN'), ('called', 'VBN'), ('MITA', 'NNP'), ('(', '('), ('Metlife', 'NNP'), ('’', 'NNP'), ('Intelligent', 'NNP'), ('Text', 'NNP'), ('Analyzer', 'NNP'), (')', ')'), ('(', '('), ('Glasgow', 'NNP'), ('et', 'RB'), ('al', 'RB'), ('.', '.')]

>> Noun Phrases are: 
 ['’ system', 'MITA', 'Metlife ’ Intelligent Text Analyzer', 'Glasgow']

>> Named Entities are: 
 [('ORGANIZATION', 'MITA'), ('ORGANIZATION', 'Metlife'), ('PERSON', 'Glasgow')] 

>> Stemming using Porter Stemmer: 
 [('There', 'there'), ('’', '’'), ('system', 'system'), ('called', 'call'), ('MITA', 'mita'), ('(', '('), ('Metlife', 'metlif'), ('’', '’'), ('Intelligent', 'intellig'), ('Text', 'text'), ('Analyzer', 'analyz'), (')', ')'), ('(', '('), ('Glasgow', 'glasgow'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('There', 'there'), ('’', '’'), ('system', 'system'), ('called', 'call'), ('MITA', 'mita'), ('(', '('), ('Metlife', 'metlif'), ('’', '’'), ('Intelligent', 'intellig'), ('Text', 'text'), ('Analyzer', 'analyz'), (')', ')'), ('(', '('), ('Glasgow', 'glasgow'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('There', 'There'), ('’', '’'), ('system', 'system'), ('called', 'called'), ('MITA', 'MITA'), ('(', '('), ('Metlife', 'Metlife'), ('’', '’'), ('Intelligent', 'Intelligent'), ('Text', 'Text'), ('Analyzer', 'Analyzer'), (')', ')'), ('(', '('), ('Glasgow', 'Glasgow'), ('et', 'et'), ('al', 'al'), ('.', '.')]


------------------- Sentence 2 -------------------

(1998)

>> Tokens are: 
 ['(', '1998', ')']

>> Bigrams are: 
 [('(', '1998'), ('1998', ')')]

>> Trigrams are: 
 [('(', '1998', ')')]

>> POS Tags are: 
 [('(', '('), ('1998', 'CD'), (')', ')')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('1998', '1998'), (')', ')')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('1998', '1998'), (')', ')')]

>> Lemmatization: 
 [('(', '('), ('1998', '1998'), (')', ')')]



========================================== PARAGRAPH 398 ===========================================

[60]) that extracts information from life insurance applications. Ahonen et al. (1998) [61]  

------------------- Sentence 1 -------------------

[60]) that extracts information from life insurance applications.

>> Tokens are: 
 ['[', '60', ']', ')', 'extracts', 'information', 'life', 'insurance', 'applications', '.']

>> Bigrams are: 
 [('[', '60'), ('60', ']'), (']', ')'), (')', 'extracts'), ('extracts', 'information'), ('information', 'life'), ('life', 'insurance'), ('insurance', 'applications'), ('applications', '.')]

>> Trigrams are: 
 [('[', '60', ']'), ('60', ']', ')'), (']', ')', 'extracts'), (')', 'extracts', 'information'), ('extracts', 'information', 'life'), ('information', 'life', 'insurance'), ('life', 'insurance', 'applications'), ('insurance', 'applications', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('60', 'CD'), (']', 'NN'), (')', ')'), ('extracts', 'VBZ'), ('information', 'NN'), ('life', 'NN'), ('insurance', 'NN'), ('applications', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 [']', 'information life insurance applications']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('60', '60'), (']', ']'), (')', ')'), ('extracts', 'extract'), ('information', 'inform'), ('life', 'life'), ('insurance', 'insur'), ('applications', 'applic'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('60', '60'), (']', ']'), (')', ')'), ('extracts', 'extract'), ('information', 'inform'), ('life', 'life'), ('insurance', 'insur'), ('applications', 'applic'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('60', '60'), (']', ']'), (')', ')'), ('extracts', 'extract'), ('information', 'information'), ('life', 'life'), ('insurance', 'insurance'), ('applications', 'application'), ('.', '.')]


------------------- Sentence 2 -------------------

Ahonen et al.

>> Tokens are: 
 ['Ahonen', 'et', 'al', '.']

>> Bigrams are: 
 [('Ahonen', 'et'), ('et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('Ahonen', 'et', 'al'), ('et', 'al', '.')]

>> POS Tags are: 
 [('Ahonen', 'NNP'), ('et', 'CC'), ('al', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Ahonen', 'al']

>> Named Entities are: 
 [('GPE', 'Ahonen')] 

>> Stemming using Porter Stemmer: 
 [('Ahonen', 'ahonen'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Ahonen', 'ahonen'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('Ahonen', 'Ahonen'), ('et', 'et'), ('al', 'al'), ('.', '.')]


------------------- Sentence 3 -------------------

(1998) [61]

>> Tokens are: 
 ['(', '1998', ')', '[', '61', ']']

>> Bigrams are: 
 [('(', '1998'), ('1998', ')'), (')', '['), ('[', '61'), ('61', ']')]

>> Trigrams are: 
 [('(', '1998', ')'), ('1998', ')', '['), (')', '[', '61'), ('[', '61', ']')]

>> POS Tags are: 
 [('(', '('), ('1998', 'CD'), (')', ')'), ('[', 'VBD'), ('61', 'CD'), (']', 'NN')]

>> Noun Phrases are: 
 [']']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('1998', '1998'), (')', ')'), ('[', '['), ('61', '61'), (']', ']')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('1998', '1998'), (')', ')'), ('[', '['), ('61', '61'), (']', ']')]

>> Lemmatization: 
 [('(', '('), ('1998', '1998'), (')', ')'), ('[', '['), ('61', '61'), (']', ']')]



========================================== PARAGRAPH 399 ===========================================

suggested a mainstream framework for text mining that uses pragmatic and discourse level  

------------------- Sentence 1 -------------------

suggested a mainstream framework for text mining that uses pragmatic and discourse level

>> Tokens are: 
 ['suggested', 'mainstream', 'framework', 'text', 'mining', 'uses', 'pragmatic', 'discourse', 'level']

>> Bigrams are: 
 [('suggested', 'mainstream'), ('mainstream', 'framework'), ('framework', 'text'), ('text', 'mining'), ('mining', 'uses'), ('uses', 'pragmatic'), ('pragmatic', 'discourse'), ('discourse', 'level')]

>> Trigrams are: 
 [('suggested', 'mainstream', 'framework'), ('mainstream', 'framework', 'text'), ('framework', 'text', 'mining'), ('text', 'mining', 'uses'), ('mining', 'uses', 'pragmatic'), ('uses', 'pragmatic', 'discourse'), ('pragmatic', 'discourse', 'level')]

>> POS Tags are: 
 [('suggested', 'VBN'), ('mainstream', 'JJ'), ('framework', 'NN'), ('text', 'NN'), ('mining', 'NN'), ('uses', 'VBZ'), ('pragmatic', 'JJ'), ('discourse', 'NNS'), ('level', 'NN')]

>> Noun Phrases are: 
 ['mainstream framework text mining', 'pragmatic discourse level']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('suggested', 'suggest'), ('mainstream', 'mainstream'), ('framework', 'framework'), ('text', 'text'), ('mining', 'mine'), ('uses', 'use'), ('pragmatic', 'pragmat'), ('discourse', 'discours'), ('level', 'level')]

>> Stemming using Snowball Stemmer: 
 [('suggested', 'suggest'), ('mainstream', 'mainstream'), ('framework', 'framework'), ('text', 'text'), ('mining', 'mine'), ('uses', 'use'), ('pragmatic', 'pragmat'), ('discourse', 'discours'), ('level', 'level')]

>> Lemmatization: 
 [('suggested', 'suggested'), ('mainstream', 'mainstream'), ('framework', 'framework'), ('text', 'text'), ('mining', 'mining'), ('uses', 'us'), ('pragmatic', 'pragmatic'), ('discourse', 'discourse'), ('level', 'level')]



========================================== PARAGRAPH 400 ===========================================

analyses of text.  

------------------- Sentence 1 -------------------

analyses of text.

>> Tokens are: 
 ['analyses', 'text', '.']

>> Bigrams are: 
 [('analyses', 'text'), ('text', '.')]

>> Trigrams are: 
 [('analyses', 'text', '.')]

>> POS Tags are: 
 [('analyses', 'NNS'), ('text', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['analyses text']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('analyses', 'analys'), ('text', 'text'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('analyses', 'analys'), ('text', 'text'), ('.', '.')]

>> Lemmatization: 
 [('analyses', 'analysis'), ('text', 'text'), ('.', '.')]



========================================== PARAGRAPH 401 ===========================================

6.5 Summarization  

------------------- Sentence 1 -------------------

6.5 Summarization

>> Tokens are: 
 ['6.5', 'Summarization']

>> Bigrams are: 
 [('6.5', 'Summarization')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('6.5', 'CD'), ('Summarization', 'NN')]

>> Noun Phrases are: 
 ['Summarization']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('6.5', '6.5'), ('Summarization', 'summar')]

>> Stemming using Snowball Stemmer: 
 [('6.5', '6.5'), ('Summarization', 'summar')]

>> Lemmatization: 
 [('6.5', '6.5'), ('Summarization', 'Summarization')]



========================================== PARAGRAPH 402 ===========================================

Overload of information is the real thing in this digital age, and already our reach and access  

------------------- Sentence 1 -------------------

Overload of information is the real thing in this digital age, and already our reach and access

>> Tokens are: 
 ['Overload', 'information', 'real', 'thing', 'digital', 'age', ',', 'already', 'reach', 'access']

>> Bigrams are: 
 [('Overload', 'information'), ('information', 'real'), ('real', 'thing'), ('thing', 'digital'), ('digital', 'age'), ('age', ','), (',', 'already'), ('already', 'reach'), ('reach', 'access')]

>> Trigrams are: 
 [('Overload', 'information', 'real'), ('information', 'real', 'thing'), ('real', 'thing', 'digital'), ('thing', 'digital', 'age'), ('digital', 'age', ','), ('age', ',', 'already'), (',', 'already', 'reach'), ('already', 'reach', 'access')]

>> POS Tags are: 
 [('Overload', 'NNP'), ('information', 'NN'), ('real', 'JJ'), ('thing', 'NN'), ('digital', 'JJ'), ('age', 'NN'), (',', ','), ('already', 'RB'), ('reach', 'VB'), ('access', 'NN')]

>> Noun Phrases are: 
 ['Overload information', 'real thing', 'digital age', 'access']

>> Named Entities are: 
 [('GPE', 'Overload')] 

>> Stemming using Porter Stemmer: 
 [('Overload', 'overload'), ('information', 'inform'), ('real', 'real'), ('thing', 'thing'), ('digital', 'digit'), ('age', 'age'), (',', ','), ('already', 'alreadi'), ('reach', 'reach'), ('access', 'access')]

>> Stemming using Snowball Stemmer: 
 [('Overload', 'overload'), ('information', 'inform'), ('real', 'real'), ('thing', 'thing'), ('digital', 'digit'), ('age', 'age'), (',', ','), ('already', 'alreadi'), ('reach', 'reach'), ('access', 'access')]

>> Lemmatization: 
 [('Overload', 'Overload'), ('information', 'information'), ('real', 'real'), ('thing', 'thing'), ('digital', 'digital'), ('age', 'age'), (',', ','), ('already', 'already'), ('reach', 'reach'), ('access', 'access')]



========================================== PARAGRAPH 403 ===========================================

to knowledge and information exceeds our capacity to understand it. This trend is not slowing  

------------------- Sentence 1 -------------------

to knowledge and information exceeds our capacity to understand it.

>> Tokens are: 
 ['knowledge', 'information', 'exceeds', 'capacity', 'understand', '.']

>> Bigrams are: 
 [('knowledge', 'information'), ('information', 'exceeds'), ('exceeds', 'capacity'), ('capacity', 'understand'), ('understand', '.')]

>> Trigrams are: 
 [('knowledge', 'information', 'exceeds'), ('information', 'exceeds', 'capacity'), ('exceeds', 'capacity', 'understand'), ('capacity', 'understand', '.')]

>> POS Tags are: 
 [('knowledge', 'NN'), ('information', 'NN'), ('exceeds', 'VBZ'), ('capacity', 'NN'), ('understand', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['knowledge information', 'capacity understand']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('knowledge', 'knowledg'), ('information', 'inform'), ('exceeds', 'exce'), ('capacity', 'capac'), ('understand', 'understand'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('knowledge', 'knowledg'), ('information', 'inform'), ('exceeds', 'exceed'), ('capacity', 'capac'), ('understand', 'understand'), ('.', '.')]

>> Lemmatization: 
 [('knowledge', 'knowledge'), ('information', 'information'), ('exceeds', 'exceeds'), ('capacity', 'capacity'), ('understand', 'understand'), ('.', '.')]


------------------- Sentence 2 -------------------

This trend is not slowing

>> Tokens are: 
 ['This', 'trend', 'slowing']

>> Bigrams are: 
 [('This', 'trend'), ('trend', 'slowing')]

>> Trigrams are: 
 [('This', 'trend', 'slowing')]

>> POS Tags are: 
 [('This', 'DT'), ('trend', 'NN'), ('slowing', 'VBG')]

>> Noun Phrases are: 
 ['This trend']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('This', 'thi'), ('trend', 'trend'), ('slowing', 'slow')]

>> Stemming using Snowball Stemmer: 
 [('This', 'this'), ('trend', 'trend'), ('slowing', 'slow')]

>> Lemmatization: 
 [('This', 'This'), ('trend', 'trend'), ('slowing', 'slowing')]



========================================== PARAGRAPH 404 ===========================================

down, so an ability to summarize the data while keeping the meaning intact is highly 

------------------- Sentence 1 -------------------

down, so an ability to summarize the data while keeping the meaning intact is highly

>> Tokens are: 
 [',', 'ability', 'summarize', 'data', 'keeping', 'meaning', 'intact', 'highly']

>> Bigrams are: 
 [(',', 'ability'), ('ability', 'summarize'), ('summarize', 'data'), ('data', 'keeping'), ('keeping', 'meaning'), ('meaning', 'intact'), ('intact', 'highly')]

>> Trigrams are: 
 [(',', 'ability', 'summarize'), ('ability', 'summarize', 'data'), ('summarize', 'data', 'keeping'), ('data', 'keeping', 'meaning'), ('keeping', 'meaning', 'intact'), ('meaning', 'intact', 'highly')]

>> POS Tags are: 
 [(',', ','), ('ability', 'NN'), ('summarize', 'VB'), ('data', 'NNS'), ('keeping', 'VBG'), ('meaning', 'VBG'), ('intact', 'JJ'), ('highly', 'RB')]

>> Noun Phrases are: 
 ['ability', 'data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [(',', ','), ('ability', 'abil'), ('summarize', 'summar'), ('data', 'data'), ('keeping', 'keep'), ('meaning', 'mean'), ('intact', 'intact'), ('highly', 'highli')]

>> Stemming using Snowball Stemmer: 
 [(',', ','), ('ability', 'abil'), ('summarize', 'summar'), ('data', 'data'), ('keeping', 'keep'), ('meaning', 'mean'), ('intact', 'intact'), ('highly', 'high')]

>> Lemmatization: 
 [(',', ','), ('ability', 'ability'), ('summarize', 'summarize'), ('data', 'data'), ('keeping', 'keeping'), ('meaning', 'meaning'), ('intact', 'intact'), ('highly', 'highly')]



========================================== PARAGRAPH 405 ===========================================

required. This is important not just allowing us the ability to recognize the understand the  

------------------- Sentence 1 -------------------

required.

>> Tokens are: 
 ['required', '.']

>> Bigrams are: 
 [('required', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('required', 'VBN'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('required', 'requir'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('required', 'requir'), ('.', '.')]

>> Lemmatization: 
 [('required', 'required'), ('.', '.')]


------------------- Sentence 2 -------------------

This is important not just allowing us the ability to recognize the understand the

>> Tokens are: 
 ['This', 'important', 'allowing', 'us', 'ability', 'recognize', 'understand']

>> Bigrams are: 
 [('This', 'important'), ('important', 'allowing'), ('allowing', 'us'), ('us', 'ability'), ('ability', 'recognize'), ('recognize', 'understand')]

>> Trigrams are: 
 [('This', 'important', 'allowing'), ('important', 'allowing', 'us'), ('allowing', 'us', 'ability'), ('us', 'ability', 'recognize'), ('ability', 'recognize', 'understand')]

>> POS Tags are: 
 [('This', 'DT'), ('important', 'JJ'), ('allowing', 'VBG'), ('us', 'PRP'), ('ability', 'NN'), ('recognize', 'VBP'), ('understand', 'NN')]

>> Noun Phrases are: 
 ['ability', 'understand']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('This', 'thi'), ('important', 'import'), ('allowing', 'allow'), ('us', 'us'), ('ability', 'abil'), ('recognize', 'recogn'), ('understand', 'understand')]

>> Stemming using Snowball Stemmer: 
 [('This', 'this'), ('important', 'import'), ('allowing', 'allow'), ('us', 'us'), ('ability', 'abil'), ('recognize', 'recogn'), ('understand', 'understand')]

>> Lemmatization: 
 [('This', 'This'), ('important', 'important'), ('allowing', 'allowing'), ('us', 'u'), ('ability', 'ability'), ('recognize', 'recognize'), ('understand', 'understand')]



========================================== PARAGRAPH 406 ===========================================

important information for a large set of data, it is used to understand the deeper emotional  

------------------- Sentence 1 -------------------

important information for a large set of data, it is used to understand the deeper emotional

>> Tokens are: 
 ['important', 'information', 'large', 'set', 'data', ',', 'used', 'understand', 'deeper', 'emotional']

>> Bigrams are: 
 [('important', 'information'), ('information', 'large'), ('large', 'set'), ('set', 'data'), ('data', ','), (',', 'used'), ('used', 'understand'), ('understand', 'deeper'), ('deeper', 'emotional')]

>> Trigrams are: 
 [('important', 'information', 'large'), ('information', 'large', 'set'), ('large', 'set', 'data'), ('set', 'data', ','), ('data', ',', 'used'), (',', 'used', 'understand'), ('used', 'understand', 'deeper'), ('understand', 'deeper', 'emotional')]

>> POS Tags are: 
 [('important', 'JJ'), ('information', 'NN'), ('large', 'JJ'), ('set', 'NN'), ('data', 'NNS'), (',', ','), ('used', 'VBD'), ('understand', 'JJ'), ('deeper', 'JJR'), ('emotional', 'NN')]

>> Noun Phrases are: 
 ['important information', 'large set data', 'emotional']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('important', 'import'), ('information', 'inform'), ('large', 'larg'), ('set', 'set'), ('data', 'data'), (',', ','), ('used', 'use'), ('understand', 'understand'), ('deeper', 'deeper'), ('emotional', 'emot')]

>> Stemming using Snowball Stemmer: 
 [('important', 'import'), ('information', 'inform'), ('large', 'larg'), ('set', 'set'), ('data', 'data'), (',', ','), ('used', 'use'), ('understand', 'understand'), ('deeper', 'deeper'), ('emotional', 'emot')]

>> Lemmatization: 
 [('important', 'important'), ('information', 'information'), ('large', 'large'), ('set', 'set'), ('data', 'data'), (',', ','), ('used', 'used'), ('understand', 'understand'), ('deeper', 'deeper'), ('emotional', 'emotional')]



========================================== PARAGRAPH 407 ===========================================

meanings; For example, a company determine the general sentiment on social media and use  

------------------- Sentence 1 -------------------

meanings; For example, a company determine the general sentiment on social media and use

>> Tokens are: 
 ['meanings', ';', 'For', 'example', ',', 'company', 'determine', 'general', 'sentiment', 'social', 'media', 'use']

>> Bigrams are: 
 [('meanings', ';'), (';', 'For'), ('For', 'example'), ('example', ','), (',', 'company'), ('company', 'determine'), ('determine', 'general'), ('general', 'sentiment'), ('sentiment', 'social'), ('social', 'media'), ('media', 'use')]

>> Trigrams are: 
 [('meanings', ';', 'For'), (';', 'For', 'example'), ('For', 'example', ','), ('example', ',', 'company'), (',', 'company', 'determine'), ('company', 'determine', 'general'), ('determine', 'general', 'sentiment'), ('general', 'sentiment', 'social'), ('sentiment', 'social', 'media'), ('social', 'media', 'use')]

>> POS Tags are: 
 [('meanings', 'NNS'), (';', ':'), ('For', 'IN'), ('example', 'NN'), (',', ','), ('company', 'NN'), ('determine', 'VB'), ('general', 'JJ'), ('sentiment', 'NN'), ('social', 'JJ'), ('media', 'NNS'), ('use', 'NN')]

>> Noun Phrases are: 
 ['meanings', 'example', 'company', 'general sentiment', 'social media use']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('meanings', 'mean'), (';', ';'), ('For', 'for'), ('example', 'exampl'), (',', ','), ('company', 'compani'), ('determine', 'determin'), ('general', 'gener'), ('sentiment', 'sentiment'), ('social', 'social'), ('media', 'media'), ('use', 'use')]

>> Stemming using Snowball Stemmer: 
 [('meanings', 'mean'), (';', ';'), ('For', 'for'), ('example', 'exampl'), (',', ','), ('company', 'compani'), ('determine', 'determin'), ('general', 'general'), ('sentiment', 'sentiment'), ('social', 'social'), ('media', 'media'), ('use', 'use')]

>> Lemmatization: 
 [('meanings', 'meaning'), (';', ';'), ('For', 'For'), ('example', 'example'), (',', ','), ('company', 'company'), ('determine', 'determine'), ('general', 'general'), ('sentiment', 'sentiment'), ('social', 'social'), ('media', 'medium'), ('use', 'use')]



========================================== PARAGRAPH 408 ===========================================

it on their latest product offering. This application is useful as a valuable marketing asset.  

------------------- Sentence 1 -------------------

it on their latest product offering.

>> Tokens are: 
 ['latest', 'product', 'offering', '.']

>> Bigrams are: 
 [('latest', 'product'), ('product', 'offering'), ('offering', '.')]

>> Trigrams are: 
 [('latest', 'product', 'offering'), ('product', 'offering', '.')]

>> POS Tags are: 
 [('latest', 'JJS'), ('product', 'NN'), ('offering', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['product offering']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('latest', 'latest'), ('product', 'product'), ('offering', 'offer'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('latest', 'latest'), ('product', 'product'), ('offering', 'offer'), ('.', '.')]

>> Lemmatization: 
 [('latest', 'latest'), ('product', 'product'), ('offering', 'offering'), ('.', '.')]


------------------- Sentence 2 -------------------

This application is useful as a valuable marketing asset.

>> Tokens are: 
 ['This', 'application', 'useful', 'valuable', 'marketing', 'asset', '.']

>> Bigrams are: 
 [('This', 'application'), ('application', 'useful'), ('useful', 'valuable'), ('valuable', 'marketing'), ('marketing', 'asset'), ('asset', '.')]

>> Trigrams are: 
 [('This', 'application', 'useful'), ('application', 'useful', 'valuable'), ('useful', 'valuable', 'marketing'), ('valuable', 'marketing', 'asset'), ('marketing', 'asset', '.')]

>> POS Tags are: 
 [('This', 'DT'), ('application', 'NN'), ('useful', 'JJ'), ('valuable', 'JJ'), ('marketing', 'NN'), ('asset', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['This application', 'useful valuable marketing asset']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('This', 'thi'), ('application', 'applic'), ('useful', 'use'), ('valuable', 'valuabl'), ('marketing', 'market'), ('asset', 'asset'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('This', 'this'), ('application', 'applic'), ('useful', 'use'), ('valuable', 'valuabl'), ('marketing', 'market'), ('asset', 'asset'), ('.', '.')]

>> Lemmatization: 
 [('This', 'This'), ('application', 'application'), ('useful', 'useful'), ('valuable', 'valuable'), ('marketing', 'marketing'), ('asset', 'asset'), ('.', '.')]



========================================== PARAGRAPH 409 ===========================================

The types of text summarization depends on the basis of the number of documents and  the  

------------------- Sentence 1 -------------------

The types of text summarization depends on the basis of the number of documents and  the

>> Tokens are: 
 ['The', 'types', 'text', 'summarization', 'depends', 'basis', 'number', 'documents']

>> Bigrams are: 
 [('The', 'types'), ('types', 'text'), ('text', 'summarization'), ('summarization', 'depends'), ('depends', 'basis'), ('basis', 'number'), ('number', 'documents')]

>> Trigrams are: 
 [('The', 'types', 'text'), ('types', 'text', 'summarization'), ('text', 'summarization', 'depends'), ('summarization', 'depends', 'basis'), ('depends', 'basis', 'number'), ('basis', 'number', 'documents')]

>> POS Tags are: 
 [('The', 'DT'), ('types', 'NNS'), ('text', 'JJ'), ('summarization', 'NN'), ('depends', 'VBZ'), ('basis', 'NN'), ('number', 'NN'), ('documents', 'NNS')]

>> Noun Phrases are: 
 ['The types', 'text summarization', 'basis number documents']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('types', 'type'), ('text', 'text'), ('summarization', 'summar'), ('depends', 'depend'), ('basis', 'basi'), ('number', 'number'), ('documents', 'document')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('types', 'type'), ('text', 'text'), ('summarization', 'summar'), ('depends', 'depend'), ('basis', 'basi'), ('number', 'number'), ('documents', 'document')]

>> Lemmatization: 
 [('The', 'The'), ('types', 'type'), ('text', 'text'), ('summarization', 'summarization'), ('depends', 'depends'), ('basis', 'basis'), ('number', 'number'), ('documents', 'document')]



========================================== PARAGRAPH 410 ===========================================

two important categories are single document summarization and multi document  

------------------- Sentence 1 -------------------

two important categories are single document summarization and multi document

>> Tokens are: 
 ['two', 'important', 'categories', 'single', 'document', 'summarization', 'multi', 'document']

>> Bigrams are: 
 [('two', 'important'), ('important', 'categories'), ('categories', 'single'), ('single', 'document'), ('document', 'summarization'), ('summarization', 'multi'), ('multi', 'document')]

>> Trigrams are: 
 [('two', 'important', 'categories'), ('important', 'categories', 'single'), ('categories', 'single', 'document'), ('single', 'document', 'summarization'), ('document', 'summarization', 'multi'), ('summarization', 'multi', 'document')]

>> POS Tags are: 
 [('two', 'CD'), ('important', 'JJ'), ('categories', 'NNS'), ('single', 'JJ'), ('document', 'NN'), ('summarization', 'NN'), ('multi', 'FW'), ('document', 'NN')]

>> Noun Phrases are: 
 ['important categories', 'single document summarization', 'document']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('two', 'two'), ('important', 'import'), ('categories', 'categori'), ('single', 'singl'), ('document', 'document'), ('summarization', 'summar'), ('multi', 'multi'), ('document', 'document')]

>> Stemming using Snowball Stemmer: 
 [('two', 'two'), ('important', 'import'), ('categories', 'categori'), ('single', 'singl'), ('document', 'document'), ('summarization', 'summar'), ('multi', 'multi'), ('document', 'document')]

>> Lemmatization: 
 [('two', 'two'), ('important', 'important'), ('categories', 'category'), ('single', 'single'), ('document', 'document'), ('summarization', 'summarization'), ('multi', 'multi'), ('document', 'document')]



========================================== PARAGRAPH 411 ===========================================

summarization (Zajic et al. 2008 [62]; Fattah and Ren 2009 [63]). Summaries can also be of  

------------------- Sentence 1 -------------------

summarization (Zajic et al.

>> Tokens are: 
 ['summarization', '(', 'Zajic', 'et', 'al', '.']

>> Bigrams are: 
 [('summarization', '('), ('(', 'Zajic'), ('Zajic', 'et'), ('et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('summarization', '(', 'Zajic'), ('(', 'Zajic', 'et'), ('Zajic', 'et', 'al'), ('et', 'al', '.')]

>> POS Tags are: 
 [('summarization', 'NN'), ('(', '('), ('Zajic', 'NNP'), ('et', 'RB'), ('al', 'RB'), ('.', '.')]

>> Noun Phrases are: 
 ['summarization', 'Zajic']

>> Named Entities are: 
 [('PERSON', 'Zajic')] 

>> Stemming using Porter Stemmer: 
 [('summarization', 'summar'), ('(', '('), ('Zajic', 'zajic'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('summarization', 'summar'), ('(', '('), ('Zajic', 'zajic'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('summarization', 'summarization'), ('(', '('), ('Zajic', 'Zajic'), ('et', 'et'), ('al', 'al'), ('.', '.')]


------------------- Sentence 2 -------------------

2008 [62]; Fattah and Ren 2009 [63]).

>> Tokens are: 
 ['2008', '[', '62', ']', ';', 'Fattah', 'Ren', '2009', '[', '63', ']', ')', '.']

>> Bigrams are: 
 [('2008', '['), ('[', '62'), ('62', ']'), (']', ';'), (';', 'Fattah'), ('Fattah', 'Ren'), ('Ren', '2009'), ('2009', '['), ('[', '63'), ('63', ']'), (']', ')'), (')', '.')]

>> Trigrams are: 
 [('2008', '[', '62'), ('[', '62', ']'), ('62', ']', ';'), (']', ';', 'Fattah'), (';', 'Fattah', 'Ren'), ('Fattah', 'Ren', '2009'), ('Ren', '2009', '['), ('2009', '[', '63'), ('[', '63', ']'), ('63', ']', ')'), (']', ')', '.')]

>> POS Tags are: 
 [('2008', 'CD'), ('[', '$'), ('62', 'CD'), (']', 'NNP'), (';', ':'), ('Fattah', 'NNP'), ('Ren', 'NNP'), ('2009', 'CD'), ('[', 'NNP'), ('63', 'CD'), (']', 'NN'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 [']', 'Fattah Ren', '[', ']']

>> Named Entities are: 
 [('PERSON', 'Fattah Ren')] 

>> Stemming using Porter Stemmer: 
 [('2008', '2008'), ('[', '['), ('62', '62'), (']', ']'), (';', ';'), ('Fattah', 'fattah'), ('Ren', 'ren'), ('2009', '2009'), ('[', '['), ('63', '63'), (']', ']'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('2008', '2008'), ('[', '['), ('62', '62'), (']', ']'), (';', ';'), ('Fattah', 'fattah'), ('Ren', 'ren'), ('2009', '2009'), ('[', '['), ('63', '63'), (']', ']'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('2008', '2008'), ('[', '['), ('62', '62'), (']', ']'), (';', ';'), ('Fattah', 'Fattah'), ('Ren', 'Ren'), ('2009', '2009'), ('[', '['), ('63', '63'), (']', ']'), (')', ')'), ('.', '.')]


------------------- Sentence 3 -------------------

Summaries can also be of

>> Tokens are: 
 ['Summaries', 'also']

>> Bigrams are: 
 [('Summaries', 'also')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Summaries', 'NNS'), ('also', 'RB')]

>> Noun Phrases are: 
 ['Summaries']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Summaries', 'summari'), ('also', 'also')]

>> Stemming using Snowball Stemmer: 
 [('Summaries', 'summari'), ('also', 'also')]

>> Lemmatization: 
 [('Summaries', 'Summaries'), ('also', 'also')]



========================================== PARAGRAPH 412 ===========================================

two types: generic or query-focused (Gong and Liu 2001 [64]; Dunlavy et al. 2007 [65]; Wan  

------------------- Sentence 1 -------------------

two types: generic or query-focused (Gong and Liu 2001 [64]; Dunlavy et al.

>> Tokens are: 
 ['two', 'types', ':', 'generic', 'query-focused', '(', 'Gong', 'Liu', '2001', '[', '64', ']', ';', 'Dunlavy', 'et', 'al', '.']

>> Bigrams are: 
 [('two', 'types'), ('types', ':'), (':', 'generic'), ('generic', 'query-focused'), ('query-focused', '('), ('(', 'Gong'), ('Gong', 'Liu'), ('Liu', '2001'), ('2001', '['), ('[', '64'), ('64', ']'), (']', ';'), (';', 'Dunlavy'), ('Dunlavy', 'et'), ('et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('two', 'types', ':'), ('types', ':', 'generic'), (':', 'generic', 'query-focused'), ('generic', 'query-focused', '('), ('query-focused', '(', 'Gong'), ('(', 'Gong', 'Liu'), ('Gong', 'Liu', '2001'), ('Liu', '2001', '['), ('2001', '[', '64'), ('[', '64', ']'), ('64', ']', ';'), (']', ';', 'Dunlavy'), (';', 'Dunlavy', 'et'), ('Dunlavy', 'et', 'al'), ('et', 'al', '.')]

>> POS Tags are: 
 [('two', 'CD'), ('types', 'NNS'), (':', ':'), ('generic', 'JJ'), ('query-focused', 'JJ'), ('(', '('), ('Gong', 'NNP'), ('Liu', 'NNP'), ('2001', 'CD'), ('[', 'NNP'), ('64', 'CD'), (']', 'NNP'), (';', ':'), ('Dunlavy', 'NNP'), ('et', 'FW'), ('al', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['types', 'Gong Liu', '[', ']', 'Dunlavy', 'al']

>> Named Entities are: 
 [('ORGANIZATION', 'Gong'), ('PERSON', 'Dunlavy')] 

>> Stemming using Porter Stemmer: 
 [('two', 'two'), ('types', 'type'), (':', ':'), ('generic', 'gener'), ('query-focused', 'query-focus'), ('(', '('), ('Gong', 'gong'), ('Liu', 'liu'), ('2001', '2001'), ('[', '['), ('64', '64'), (']', ']'), (';', ';'), ('Dunlavy', 'dunlavi'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('two', 'two'), ('types', 'type'), (':', ':'), ('generic', 'generic'), ('query-focused', 'query-focus'), ('(', '('), ('Gong', 'gong'), ('Liu', 'liu'), ('2001', '2001'), ('[', '['), ('64', '64'), (']', ']'), (';', ';'), ('Dunlavy', 'dunlavi'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('two', 'two'), ('types', 'type'), (':', ':'), ('generic', 'generic'), ('query-focused', 'query-focused'), ('(', '('), ('Gong', 'Gong'), ('Liu', 'Liu'), ('2001', '2001'), ('[', '['), ('64', '64'), (']', ']'), (';', ';'), ('Dunlavy', 'Dunlavy'), ('et', 'et'), ('al', 'al'), ('.', '.')]


------------------- Sentence 2 -------------------

2007 [65]; Wan

>> Tokens are: 
 ['2007', '[', '65', ']', ';', 'Wan']

>> Bigrams are: 
 [('2007', '['), ('[', '65'), ('65', ']'), (']', ';'), (';', 'Wan')]

>> Trigrams are: 
 [('2007', '[', '65'), ('[', '65', ']'), ('65', ']', ';'), (']', ';', 'Wan')]

>> POS Tags are: 
 [('2007', 'CD'), ('[', '$'), ('65', 'CD'), (']', 'NNP'), (';', ':'), ('Wan', 'NNP')]

>> Noun Phrases are: 
 [']', 'Wan']

>> Named Entities are: 
 [('GPE', 'Wan')] 

>> Stemming using Porter Stemmer: 
 [('2007', '2007'), ('[', '['), ('65', '65'), (']', ']'), (';', ';'), ('Wan', 'wan')]

>> Stemming using Snowball Stemmer: 
 [('2007', '2007'), ('[', '['), ('65', '65'), (']', ']'), (';', ';'), ('Wan', 'wan')]

>> Lemmatization: 
 [('2007', '2007'), ('[', '['), ('65', '65'), (']', ']'), (';', ';'), ('Wan', 'Wan')]



========================================== PARAGRAPH 413 ===========================================

2008 [66]; Ouyang et al. 2011 [67]). Summarization task can be either supervised or  

------------------- Sentence 1 -------------------

2008 [66]; Ouyang et al.

>> Tokens are: 
 ['2008', '[', '66', ']', ';', 'Ouyang', 'et', 'al', '.']

>> Bigrams are: 
 [('2008', '['), ('[', '66'), ('66', ']'), (']', ';'), (';', 'Ouyang'), ('Ouyang', 'et'), ('et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('2008', '[', '66'), ('[', '66', ']'), ('66', ']', ';'), (']', ';', 'Ouyang'), (';', 'Ouyang', 'et'), ('Ouyang', 'et', 'al'), ('et', 'al', '.')]

>> POS Tags are: 
 [('2008', 'CD'), ('[', '$'), ('66', 'CD'), (']', 'NNP'), (';', ':'), ('Ouyang', 'NNP'), ('et', 'FW'), ('al', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 [']', 'Ouyang', 'al']

>> Named Entities are: 
 [('PERSON', 'Ouyang')] 

>> Stemming using Porter Stemmer: 
 [('2008', '2008'), ('[', '['), ('66', '66'), (']', ']'), (';', ';'), ('Ouyang', 'ouyang'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('2008', '2008'), ('[', '['), ('66', '66'), (']', ']'), (';', ';'), ('Ouyang', 'ouyang'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('2008', '2008'), ('[', '['), ('66', '66'), (']', ']'), (';', ';'), ('Ouyang', 'Ouyang'), ('et', 'et'), ('al', 'al'), ('.', '.')]


------------------- Sentence 2 -------------------

2011 [67]).

>> Tokens are: 
 ['2011', '[', '67', ']', ')', '.']

>> Bigrams are: 
 [('2011', '['), ('[', '67'), ('67', ']'), (']', ')'), (')', '.')]

>> Trigrams are: 
 [('2011', '[', '67'), ('[', '67', ']'), ('67', ']', ')'), (']', ')', '.')]

>> POS Tags are: 
 [('2011', 'CD'), ('[', '$'), ('67', 'CD'), (']', 'NN'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 [']']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('2011', '2011'), ('[', '['), ('67', '67'), (']', ']'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('2011', '2011'), ('[', '['), ('67', '67'), (']', ']'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('2011', '2011'), ('[', '['), ('67', '67'), (']', ']'), (')', ')'), ('.', '.')]


------------------- Sentence 3 -------------------

Summarization task can be either supervised or

>> Tokens are: 
 ['Summarization', 'task', 'either', 'supervised']

>> Bigrams are: 
 [('Summarization', 'task'), ('task', 'either'), ('either', 'supervised')]

>> Trigrams are: 
 [('Summarization', 'task', 'either'), ('task', 'either', 'supervised')]

>> POS Tags are: 
 [('Summarization', 'NNP'), ('task', 'NN'), ('either', 'RB'), ('supervised', 'VBD')]

>> Noun Phrases are: 
 ['Summarization task']

>> Named Entities are: 
 [('GPE', 'Summarization')] 

>> Stemming using Porter Stemmer: 
 [('Summarization', 'summar'), ('task', 'task'), ('either', 'either'), ('supervised', 'supervis')]

>> Stemming using Snowball Stemmer: 
 [('Summarization', 'summar'), ('task', 'task'), ('either', 'either'), ('supervised', 'supervis')]

>> Lemmatization: 
 [('Summarization', 'Summarization'), ('task', 'task'), ('either', 'either'), ('supervised', 'supervised')]



========================================== PARAGRAPH 414 ===========================================

unsupervised (Mani and Maybury 1999 [68]; Fattah and Ren 2009 [63]; Riedhammer et al.  

------------------- Sentence 1 -------------------

unsupervised (Mani and Maybury 1999 [68]; Fattah and Ren 2009 [63]; Riedhammer et al.

>> Tokens are: 
 ['unsupervised', '(', 'Mani', 'Maybury', '1999', '[', '68', ']', ';', 'Fattah', 'Ren', '2009', '[', '63', ']', ';', 'Riedhammer', 'et', 'al', '.']

>> Bigrams are: 
 [('unsupervised', '('), ('(', 'Mani'), ('Mani', 'Maybury'), ('Maybury', '1999'), ('1999', '['), ('[', '68'), ('68', ']'), (']', ';'), (';', 'Fattah'), ('Fattah', 'Ren'), ('Ren', '2009'), ('2009', '['), ('[', '63'), ('63', ']'), (']', ';'), (';', 'Riedhammer'), ('Riedhammer', 'et'), ('et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('unsupervised', '(', 'Mani'), ('(', 'Mani', 'Maybury'), ('Mani', 'Maybury', '1999'), ('Maybury', '1999', '['), ('1999', '[', '68'), ('[', '68', ']'), ('68', ']', ';'), (']', ';', 'Fattah'), (';', 'Fattah', 'Ren'), ('Fattah', 'Ren', '2009'), ('Ren', '2009', '['), ('2009', '[', '63'), ('[', '63', ']'), ('63', ']', ';'), (']', ';', 'Riedhammer'), (';', 'Riedhammer', 'et'), ('Riedhammer', 'et', 'al'), ('et', 'al', '.')]

>> POS Tags are: 
 [('unsupervised', 'JJ'), ('(', '('), ('Mani', 'NNP'), ('Maybury', 'NNP'), ('1999', 'CD'), ('[', 'NNP'), ('68', 'CD'), (']', 'NNP'), (';', ':'), ('Fattah', 'NNP'), ('Ren', 'NNP'), ('2009', 'CD'), ('[', 'NNP'), ('63', 'CD'), (']', 'NNP'), (';', ':'), ('Riedhammer', 'NNP'), ('et', 'FW'), ('al', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Mani Maybury', '[', ']', 'Fattah Ren', '[', ']', 'Riedhammer', 'al']

>> Named Entities are: 
 [('PERSON', 'Mani Maybury'), ('PERSON', 'Fattah Ren')] 

>> Stemming using Porter Stemmer: 
 [('unsupervised', 'unsupervis'), ('(', '('), ('Mani', 'mani'), ('Maybury', 'mayburi'), ('1999', '1999'), ('[', '['), ('68', '68'), (']', ']'), (';', ';'), ('Fattah', 'fattah'), ('Ren', 'ren'), ('2009', '2009'), ('[', '['), ('63', '63'), (']', ']'), (';', ';'), ('Riedhammer', 'riedhamm'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('unsupervised', 'unsupervis'), ('(', '('), ('Mani', 'mani'), ('Maybury', 'mayburi'), ('1999', '1999'), ('[', '['), ('68', '68'), (']', ']'), (';', ';'), ('Fattah', 'fattah'), ('Ren', 'ren'), ('2009', '2009'), ('[', '['), ('63', '63'), (']', ']'), (';', ';'), ('Riedhammer', 'riedhamm'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('unsupervised', 'unsupervised'), ('(', '('), ('Mani', 'Mani'), ('Maybury', 'Maybury'), ('1999', '1999'), ('[', '['), ('68', '68'), (']', ']'), (';', ';'), ('Fattah', 'Fattah'), ('Ren', 'Ren'), ('2009', '2009'), ('[', '['), ('63', '63'), (']', ']'), (';', ';'), ('Riedhammer', 'Riedhammer'), ('et', 'et'), ('al', 'al'), ('.', '.')]



========================================== PARAGRAPH 415 ===========================================

2010 [69]). Training data is required in a supervised system for selecting relevant material  

------------------- Sentence 1 -------------------

2010 [69]).

>> Tokens are: 
 ['2010', '[', '69', ']', ')', '.']

>> Bigrams are: 
 [('2010', '['), ('[', '69'), ('69', ']'), (']', ')'), (')', '.')]

>> Trigrams are: 
 [('2010', '[', '69'), ('[', '69', ']'), ('69', ']', ')'), (']', ')', '.')]

>> POS Tags are: 
 [('2010', 'CD'), ('[', '$'), ('69', 'CD'), (']', 'NN'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 [']']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('2010', '2010'), ('[', '['), ('69', '69'), (']', ']'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('2010', '2010'), ('[', '['), ('69', '69'), (']', ']'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('2010', '2010'), ('[', '['), ('69', '69'), (']', ']'), (')', ')'), ('.', '.')]


------------------- Sentence 2 -------------------

Training data is required in a supervised system for selecting relevant material

>> Tokens are: 
 ['Training', 'data', 'required', 'supervised', 'system', 'selecting', 'relevant', 'material']

>> Bigrams are: 
 [('Training', 'data'), ('data', 'required'), ('required', 'supervised'), ('supervised', 'system'), ('system', 'selecting'), ('selecting', 'relevant'), ('relevant', 'material')]

>> Trigrams are: 
 [('Training', 'data', 'required'), ('data', 'required', 'supervised'), ('required', 'supervised', 'system'), ('supervised', 'system', 'selecting'), ('system', 'selecting', 'relevant'), ('selecting', 'relevant', 'material')]

>> POS Tags are: 
 [('Training', 'VBG'), ('data', 'NNS'), ('required', 'VBN'), ('supervised', 'JJ'), ('system', 'NN'), ('selecting', 'VBG'), ('relevant', 'JJ'), ('material', 'NN')]

>> Noun Phrases are: 
 ['data', 'supervised system', 'relevant material']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Training', 'train'), ('data', 'data'), ('required', 'requir'), ('supervised', 'supervis'), ('system', 'system'), ('selecting', 'select'), ('relevant', 'relev'), ('material', 'materi')]

>> Stemming using Snowball Stemmer: 
 [('Training', 'train'), ('data', 'data'), ('required', 'requir'), ('supervised', 'supervis'), ('system', 'system'), ('selecting', 'select'), ('relevant', 'relev'), ('material', 'materi')]

>> Lemmatization: 
 [('Training', 'Training'), ('data', 'data'), ('required', 'required'), ('supervised', 'supervised'), ('system', 'system'), ('selecting', 'selecting'), ('relevant', 'relevant'), ('material', 'material')]



========================================== PARAGRAPH 416 ===========================================

from the documents. Large amount of annotated data is needed for learning techniques. Few  

------------------- Sentence 1 -------------------

from the documents.

>> Tokens are: 
 ['documents', '.']

>> Bigrams are: 
 [('documents', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('documents', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['documents']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('documents', 'document'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('documents', 'document'), ('.', '.')]

>> Lemmatization: 
 [('documents', 'document'), ('.', '.')]


------------------- Sentence 2 -------------------

Large amount of annotated data is needed for learning techniques.

>> Tokens are: 
 ['Large', 'amount', 'annotated', 'data', 'needed', 'learning', 'techniques', '.']

>> Bigrams are: 
 [('Large', 'amount'), ('amount', 'annotated'), ('annotated', 'data'), ('data', 'needed'), ('needed', 'learning'), ('learning', 'techniques'), ('techniques', '.')]

>> Trigrams are: 
 [('Large', 'amount', 'annotated'), ('amount', 'annotated', 'data'), ('annotated', 'data', 'needed'), ('data', 'needed', 'learning'), ('needed', 'learning', 'techniques'), ('learning', 'techniques', '.')]

>> POS Tags are: 
 [('Large', 'JJ'), ('amount', 'NN'), ('annotated', 'VBD'), ('data', 'NNS'), ('needed', 'VBN'), ('learning', 'NN'), ('techniques', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['Large amount', 'data', 'learning techniques']

>> Named Entities are: 
 [('GPE', 'Large')] 

>> Stemming using Porter Stemmer: 
 [('Large', 'larg'), ('amount', 'amount'), ('annotated', 'annot'), ('data', 'data'), ('needed', 'need'), ('learning', 'learn'), ('techniques', 'techniqu'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Large', 'larg'), ('amount', 'amount'), ('annotated', 'annot'), ('data', 'data'), ('needed', 'need'), ('learning', 'learn'), ('techniques', 'techniqu'), ('.', '.')]

>> Lemmatization: 
 [('Large', 'Large'), ('amount', 'amount'), ('annotated', 'annotated'), ('data', 'data'), ('needed', 'needed'), ('learning', 'learning'), ('techniques', 'technique'), ('.', '.')]


------------------- Sentence 3 -------------------

Few

>> Tokens are: 
 ['Few']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Few', 'JJ')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Few', 'few')]

>> Stemming using Snowball Stemmer: 
 [('Few', 'few')]

>> Lemmatization: 
 [('Few', 'Few')]



========================================== PARAGRAPH 417 ===========================================

techniques are as follows–  

------------------- Sentence 1 -------------------

techniques are as follows–

>> Tokens are: 
 ['techniques', 'follows–']

>> Bigrams are: 
 [('techniques', 'follows–')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('techniques', 'NNS'), ('follows–', 'VBP')]

>> Noun Phrases are: 
 ['techniques']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('techniques', 'techniqu'), ('follows–', 'follows–')]

>> Stemming using Snowball Stemmer: 
 [('techniques', 'techniqu'), ('follows–', 'follows–')]

>> Lemmatization: 
 [('techniques', 'technique'), ('follows–', 'follows–')]



========================================== PARAGRAPH 418 ===========================================

- Bayesian Sentence based Topic Model (BSTM) uses both term-sentences and term  document associations for summarizing multiple documents. (Wang et al. 2009  [70])    

------------------- Sentence 1 -------------------

- Bayesian Sentence based Topic Model (BSTM) uses both term-sentences and term  document associations for summarizing multiple documents.

>> Tokens are: 
 ['-', 'Bayesian', 'Sentence', 'based', 'Topic', 'Model', '(', 'BSTM', ')', 'uses', 'term-sentences', 'term', 'document', 'associations', 'summarizing', 'multiple', 'documents', '.']

>> Bigrams are: 
 [('-', 'Bayesian'), ('Bayesian', 'Sentence'), ('Sentence', 'based'), ('based', 'Topic'), ('Topic', 'Model'), ('Model', '('), ('(', 'BSTM'), ('BSTM', ')'), (')', 'uses'), ('uses', 'term-sentences'), ('term-sentences', 'term'), ('term', 'document'), ('document', 'associations'), ('associations', 'summarizing'), ('summarizing', 'multiple'), ('multiple', 'documents'), ('documents', '.')]

>> Trigrams are: 
 [('-', 'Bayesian', 'Sentence'), ('Bayesian', 'Sentence', 'based'), ('Sentence', 'based', 'Topic'), ('based', 'Topic', 'Model'), ('Topic', 'Model', '('), ('Model', '(', 'BSTM'), ('(', 'BSTM', ')'), ('BSTM', ')', 'uses'), (')', 'uses', 'term-sentences'), ('uses', 'term-sentences', 'term'), ('term-sentences', 'term', 'document'), ('term', 'document', 'associations'), ('document', 'associations', 'summarizing'), ('associations', 'summarizing', 'multiple'), ('summarizing', 'multiple', 'documents'), ('multiple', 'documents', '.')]

>> POS Tags are: 
 [('-', ':'), ('Bayesian', 'NN'), ('Sentence', 'NN'), ('based', 'VBN'), ('Topic', 'NNP'), ('Model', 'NNP'), ('(', '('), ('BSTM', 'NNP'), (')', ')'), ('uses', 'VBZ'), ('term-sentences', 'JJ'), ('term', 'NN'), ('document', 'NN'), ('associations', 'NNS'), ('summarizing', 'VBG'), ('multiple', 'JJ'), ('documents', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['Bayesian Sentence', 'Topic Model', 'BSTM', 'term-sentences term document associations', 'multiple documents']

>> Named Entities are: 
 [('GPE', 'Bayesian'), ('PERSON', 'Topic Model'), ('ORGANIZATION', 'BSTM')] 

>> Stemming using Porter Stemmer: 
 [('-', '-'), ('Bayesian', 'bayesian'), ('Sentence', 'sentenc'), ('based', 'base'), ('Topic', 'topic'), ('Model', 'model'), ('(', '('), ('BSTM', 'bstm'), (')', ')'), ('uses', 'use'), ('term-sentences', 'term-sent'), ('term', 'term'), ('document', 'document'), ('associations', 'associ'), ('summarizing', 'summar'), ('multiple', 'multipl'), ('documents', 'document'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('-', '-'), ('Bayesian', 'bayesian'), ('Sentence', 'sentenc'), ('based', 'base'), ('Topic', 'topic'), ('Model', 'model'), ('(', '('), ('BSTM', 'bstm'), (')', ')'), ('uses', 'use'), ('term-sentences', 'term-sent'), ('term', 'term'), ('document', 'document'), ('associations', 'associ'), ('summarizing', 'summar'), ('multiple', 'multipl'), ('documents', 'document'), ('.', '.')]

>> Lemmatization: 
 [('-', '-'), ('Bayesian', 'Bayesian'), ('Sentence', 'Sentence'), ('based', 'based'), ('Topic', 'Topic'), ('Model', 'Model'), ('(', '('), ('BSTM', 'BSTM'), (')', ')'), ('uses', 'us'), ('term-sentences', 'term-sentences'), ('term', 'term'), ('document', 'document'), ('associations', 'association'), ('summarizing', 'summarizing'), ('multiple', 'multiple'), ('documents', 'document'), ('.', '.')]


------------------- Sentence 2 -------------------

(Wang et al.

>> Tokens are: 
 ['(', 'Wang', 'et', 'al', '.']

>> Bigrams are: 
 [('(', 'Wang'), ('Wang', 'et'), ('et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('(', 'Wang', 'et'), ('Wang', 'et', 'al'), ('et', 'al', '.')]

>> POS Tags are: 
 [('(', '('), ('Wang', 'NNP'), ('et', 'RB'), ('al', 'RB'), ('.', '.')]

>> Noun Phrases are: 
 ['Wang']

>> Named Entities are: 
 [('PERSON', 'Wang')] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('Wang', 'wang'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('Wang', 'wang'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('(', '('), ('Wang', 'Wang'), ('et', 'et'), ('al', 'al'), ('.', '.')]


------------------- Sentence 3 -------------------

2009  [70])

>> Tokens are: 
 ['2009', '[', '70', ']', ')']

>> Bigrams are: 
 [('2009', '['), ('[', '70'), ('70', ']'), (']', ')')]

>> Trigrams are: 
 [('2009', '[', '70'), ('[', '70', ']'), ('70', ']', ')')]

>> POS Tags are: 
 [('2009', 'CD'), ('[', '$'), ('70', 'CD'), (']', 'NN'), (')', ')')]

>> Noun Phrases are: 
 [']']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('2009', '2009'), ('[', '['), ('70', '70'), (']', ']'), (')', ')')]

>> Stemming using Snowball Stemmer: 
 [('2009', '2009'), ('[', '['), ('70', '70'), (']', ']'), (')', ')')]

>> Lemmatization: 
 [('2009', '2009'), ('[', '['), ('70', '70'), (']', ']'), (')', ')')]



========================================== PARAGRAPH 419 ===========================================

- Factorization with Given Bases (FGB) is a language model where sentence bases  are the given bases and it utilizes document-term and sentence term matrices.  This approach groups and summarizes the documents simultaneously. (Wang et  al. 2011) [71])  

------------------- Sentence 1 -------------------

- Factorization with Given Bases (FGB) is a language model where sentence bases  are the given bases and it utilizes document-term and sentence term matrices.

>> Tokens are: 
 ['-', 'Factorization', 'Given', 'Bases', '(', 'FGB', ')', 'language', 'model', 'sentence', 'bases', 'given', 'bases', 'utilizes', 'document-term', 'sentence', 'term', 'matrices', '.']

>> Bigrams are: 
 [('-', 'Factorization'), ('Factorization', 'Given'), ('Given', 'Bases'), ('Bases', '('), ('(', 'FGB'), ('FGB', ')'), (')', 'language'), ('language', 'model'), ('model', 'sentence'), ('sentence', 'bases'), ('bases', 'given'), ('given', 'bases'), ('bases', 'utilizes'), ('utilizes', 'document-term'), ('document-term', 'sentence'), ('sentence', 'term'), ('term', 'matrices'), ('matrices', '.')]

>> Trigrams are: 
 [('-', 'Factorization', 'Given'), ('Factorization', 'Given', 'Bases'), ('Given', 'Bases', '('), ('Bases', '(', 'FGB'), ('(', 'FGB', ')'), ('FGB', ')', 'language'), (')', 'language', 'model'), ('language', 'model', 'sentence'), ('model', 'sentence', 'bases'), ('sentence', 'bases', 'given'), ('bases', 'given', 'bases'), ('given', 'bases', 'utilizes'), ('bases', 'utilizes', 'document-term'), ('utilizes', 'document-term', 'sentence'), ('document-term', 'sentence', 'term'), ('sentence', 'term', 'matrices'), ('term', 'matrices', '.')]

>> POS Tags are: 
 [('-', ':'), ('Factorization', 'NN'), ('Given', 'VBN'), ('Bases', 'NNP'), ('(', '('), ('FGB', 'NNP'), (')', ')'), ('language', 'NN'), ('model', 'NN'), ('sentence', 'NN'), ('bases', 'NNS'), ('given', 'VBN'), ('bases', 'NNS'), ('utilizes', 'JJ'), ('document-term', 'JJ'), ('sentence', 'NN'), ('term', 'NN'), ('matrices', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['Factorization', 'Bases', 'FGB', 'language model sentence bases', 'bases', 'utilizes document-term sentence term matrices']

>> Named Entities are: 
 [('GPE', 'Bases'), ('ORGANIZATION', 'FGB')] 

>> Stemming using Porter Stemmer: 
 [('-', '-'), ('Factorization', 'factor'), ('Given', 'given'), ('Bases', 'base'), ('(', '('), ('FGB', 'fgb'), (')', ')'), ('language', 'languag'), ('model', 'model'), ('sentence', 'sentenc'), ('bases', 'base'), ('given', 'given'), ('bases', 'base'), ('utilizes', 'util'), ('document-term', 'document-term'), ('sentence', 'sentenc'), ('term', 'term'), ('matrices', 'matric'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('-', '-'), ('Factorization', 'factor'), ('Given', 'given'), ('Bases', 'base'), ('(', '('), ('FGB', 'fgb'), (')', ')'), ('language', 'languag'), ('model', 'model'), ('sentence', 'sentenc'), ('bases', 'base'), ('given', 'given'), ('bases', 'base'), ('utilizes', 'util'), ('document-term', 'document-term'), ('sentence', 'sentenc'), ('term', 'term'), ('matrices', 'matric'), ('.', '.')]

>> Lemmatization: 
 [('-', '-'), ('Factorization', 'Factorization'), ('Given', 'Given'), ('Bases', 'Bases'), ('(', '('), ('FGB', 'FGB'), (')', ')'), ('language', 'language'), ('model', 'model'), ('sentence', 'sentence'), ('bases', 'base'), ('given', 'given'), ('bases', 'base'), ('utilizes', 'utilizes'), ('document-term', 'document-term'), ('sentence', 'sentence'), ('term', 'term'), ('matrices', 'matrix'), ('.', '.')]


------------------- Sentence 2 -------------------

This approach groups and summarizes the documents simultaneously.

>> Tokens are: 
 ['This', 'approach', 'groups', 'summarizes', 'documents', 'simultaneously', '.']

>> Bigrams are: 
 [('This', 'approach'), ('approach', 'groups'), ('groups', 'summarizes'), ('summarizes', 'documents'), ('documents', 'simultaneously'), ('simultaneously', '.')]

>> Trigrams are: 
 [('This', 'approach', 'groups'), ('approach', 'groups', 'summarizes'), ('groups', 'summarizes', 'documents'), ('summarizes', 'documents', 'simultaneously'), ('documents', 'simultaneously', '.')]

>> POS Tags are: 
 [('This', 'DT'), ('approach', 'NN'), ('groups', 'NNS'), ('summarizes', 'VBZ'), ('documents', 'NNS'), ('simultaneously', 'RB'), ('.', '.')]

>> Noun Phrases are: 
 ['This approach groups', 'documents']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('This', 'thi'), ('approach', 'approach'), ('groups', 'group'), ('summarizes', 'summar'), ('documents', 'document'), ('simultaneously', 'simultan'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('This', 'this'), ('approach', 'approach'), ('groups', 'group'), ('summarizes', 'summar'), ('documents', 'document'), ('simultaneously', 'simultan'), ('.', '.')]

>> Lemmatization: 
 [('This', 'This'), ('approach', 'approach'), ('groups', 'group'), ('summarizes', 'summarizes'), ('documents', 'document'), ('simultaneously', 'simultaneously'), ('.', '.')]


------------------- Sentence 3 -------------------

(Wang et  al.

>> Tokens are: 
 ['(', 'Wang', 'et', 'al', '.']

>> Bigrams are: 
 [('(', 'Wang'), ('Wang', 'et'), ('et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('(', 'Wang', 'et'), ('Wang', 'et', 'al'), ('et', 'al', '.')]

>> POS Tags are: 
 [('(', '('), ('Wang', 'NNP'), ('et', 'RB'), ('al', 'RB'), ('.', '.')]

>> Noun Phrases are: 
 ['Wang']

>> Named Entities are: 
 [('PERSON', 'Wang')] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('Wang', 'wang'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('Wang', 'wang'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('(', '('), ('Wang', 'Wang'), ('et', 'et'), ('al', 'al'), ('.', '.')]


------------------- Sentence 4 -------------------

2011) [71])

>> Tokens are: 
 ['2011', ')', '[', '71', ']', ')']

>> Bigrams are: 
 [('2011', ')'), (')', '['), ('[', '71'), ('71', ']'), (']', ')')]

>> Trigrams are: 
 [('2011', ')', '['), (')', '[', '71'), ('[', '71', ']'), ('71', ']', ')')]

>> POS Tags are: 
 [('2011', 'CD'), (')', ')'), ('[', 'VBD'), ('71', 'CD'), (']', 'NN'), (')', ')')]

>> Noun Phrases are: 
 [']']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('2011', '2011'), (')', ')'), ('[', '['), ('71', '71'), (']', ']'), (')', ')')]

>> Stemming using Snowball Stemmer: 
 [('2011', '2011'), (')', ')'), ('[', '['), ('71', '71'), (']', ']'), (')', ')')]

>> Lemmatization: 
 [('2011', '2011'), (')', ')'), ('[', '['), ('71', '71'), (']', ']'), (')', ')')]



========================================== PARAGRAPH 420 ===========================================

- Topic Aspect-Oriented Summarization (TAOS) is based on topic factors. These  topic factors are various features that describe topics such as capital words are  used to represent entity. Various topics can have various aspects and various  preferences of features are used to represent various aspects. (Fang et al. 2015 [72])  

------------------- Sentence 1 -------------------

- Topic Aspect-Oriented Summarization (TAOS) is based on topic factors.

>> Tokens are: 
 ['-', 'Topic', 'Aspect-Oriented', 'Summarization', '(', 'TAOS', ')', 'based', 'topic', 'factors', '.']

>> Bigrams are: 
 [('-', 'Topic'), ('Topic', 'Aspect-Oriented'), ('Aspect-Oriented', 'Summarization'), ('Summarization', '('), ('(', 'TAOS'), ('TAOS', ')'), (')', 'based'), ('based', 'topic'), ('topic', 'factors'), ('factors', '.')]

>> Trigrams are: 
 [('-', 'Topic', 'Aspect-Oriented'), ('Topic', 'Aspect-Oriented', 'Summarization'), ('Aspect-Oriented', 'Summarization', '('), ('Summarization', '(', 'TAOS'), ('(', 'TAOS', ')'), ('TAOS', ')', 'based'), (')', 'based', 'topic'), ('based', 'topic', 'factors'), ('topic', 'factors', '.')]

>> POS Tags are: 
 [('-', ':'), ('Topic', 'NN'), ('Aspect-Oriented', 'JJ'), ('Summarization', 'NNP'), ('(', '('), ('TAOS', 'NNP'), (')', ')'), ('based', 'VBN'), ('topic', 'NN'), ('factors', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['Topic', 'Aspect-Oriented Summarization', 'TAOS', 'topic factors']

>> Named Entities are: 
 [('ORGANIZATION', 'TAOS')] 

>> Stemming using Porter Stemmer: 
 [('-', '-'), ('Topic', 'topic'), ('Aspect-Oriented', 'aspect-ori'), ('Summarization', 'summar'), ('(', '('), ('TAOS', 'tao'), (')', ')'), ('based', 'base'), ('topic', 'topic'), ('factors', 'factor'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('-', '-'), ('Topic', 'topic'), ('Aspect-Oriented', 'aspect-ori'), ('Summarization', 'summar'), ('(', '('), ('TAOS', 'tao'), (')', ')'), ('based', 'base'), ('topic', 'topic'), ('factors', 'factor'), ('.', '.')]

>> Lemmatization: 
 [('-', '-'), ('Topic', 'Topic'), ('Aspect-Oriented', 'Aspect-Oriented'), ('Summarization', 'Summarization'), ('(', '('), ('TAOS', 'TAOS'), (')', ')'), ('based', 'based'), ('topic', 'topic'), ('factors', 'factor'), ('.', '.')]


------------------- Sentence 2 -------------------

These  topic factors are various features that describe topics such as capital words are  used to represent entity.

>> Tokens are: 
 ['These', 'topic', 'factors', 'various', 'features', 'describe', 'topics', 'capital', 'words', 'used', 'represent', 'entity', '.']

>> Bigrams are: 
 [('These', 'topic'), ('topic', 'factors'), ('factors', 'various'), ('various', 'features'), ('features', 'describe'), ('describe', 'topics'), ('topics', 'capital'), ('capital', 'words'), ('words', 'used'), ('used', 'represent'), ('represent', 'entity'), ('entity', '.')]

>> Trigrams are: 
 [('These', 'topic', 'factors'), ('topic', 'factors', 'various'), ('factors', 'various', 'features'), ('various', 'features', 'describe'), ('features', 'describe', 'topics'), ('describe', 'topics', 'capital'), ('topics', 'capital', 'words'), ('capital', 'words', 'used'), ('words', 'used', 'represent'), ('used', 'represent', 'entity'), ('represent', 'entity', '.')]

>> POS Tags are: 
 [('These', 'DT'), ('topic', 'NN'), ('factors', 'NNS'), ('various', 'JJ'), ('features', 'NNS'), ('describe', 'VBP'), ('topics', 'NNS'), ('capital', 'NN'), ('words', 'NNS'), ('used', 'VBN'), ('represent', 'JJ'), ('entity', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['These topic factors', 'various features', 'topics capital words', 'represent entity']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('These', 'these'), ('topic', 'topic'), ('factors', 'factor'), ('various', 'variou'), ('features', 'featur'), ('describe', 'describ'), ('topics', 'topic'), ('capital', 'capit'), ('words', 'word'), ('used', 'use'), ('represent', 'repres'), ('entity', 'entiti'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('These', 'these'), ('topic', 'topic'), ('factors', 'factor'), ('various', 'various'), ('features', 'featur'), ('describe', 'describ'), ('topics', 'topic'), ('capital', 'capit'), ('words', 'word'), ('used', 'use'), ('represent', 'repres'), ('entity', 'entiti'), ('.', '.')]

>> Lemmatization: 
 [('These', 'These'), ('topic', 'topic'), ('factors', 'factor'), ('various', 'various'), ('features', 'feature'), ('describe', 'describe'), ('topics', 'topic'), ('capital', 'capital'), ('words', 'word'), ('used', 'used'), ('represent', 'represent'), ('entity', 'entity'), ('.', '.')]


------------------- Sentence 3 -------------------

Various topics can have various aspects and various  preferences of features are used to represent various aspects.

>> Tokens are: 
 ['Various', 'topics', 'various', 'aspects', 'various', 'preferences', 'features', 'used', 'represent', 'various', 'aspects', '.']

>> Bigrams are: 
 [('Various', 'topics'), ('topics', 'various'), ('various', 'aspects'), ('aspects', 'various'), ('various', 'preferences'), ('preferences', 'features'), ('features', 'used'), ('used', 'represent'), ('represent', 'various'), ('various', 'aspects'), ('aspects', '.')]

>> Trigrams are: 
 [('Various', 'topics', 'various'), ('topics', 'various', 'aspects'), ('various', 'aspects', 'various'), ('aspects', 'various', 'preferences'), ('various', 'preferences', 'features'), ('preferences', 'features', 'used'), ('features', 'used', 'represent'), ('used', 'represent', 'various'), ('represent', 'various', 'aspects'), ('various', 'aspects', '.')]

>> POS Tags are: 
 [('Various', 'JJ'), ('topics', 'NNS'), ('various', 'JJ'), ('aspects', 'NNS'), ('various', 'JJ'), ('preferences', 'NNS'), ('features', 'NNS'), ('used', 'VBN'), ('represent', 'VBP'), ('various', 'JJ'), ('aspects', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['Various topics', 'various aspects', 'various preferences features', 'various aspects']

>> Named Entities are: 
 [('GPE', 'Various')] 

>> Stemming using Porter Stemmer: 
 [('Various', 'variou'), ('topics', 'topic'), ('various', 'variou'), ('aspects', 'aspect'), ('various', 'variou'), ('preferences', 'prefer'), ('features', 'featur'), ('used', 'use'), ('represent', 'repres'), ('various', 'variou'), ('aspects', 'aspect'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Various', 'various'), ('topics', 'topic'), ('various', 'various'), ('aspects', 'aspect'), ('various', 'various'), ('preferences', 'prefer'), ('features', 'featur'), ('used', 'use'), ('represent', 'repres'), ('various', 'various'), ('aspects', 'aspect'), ('.', '.')]

>> Lemmatization: 
 [('Various', 'Various'), ('topics', 'topic'), ('various', 'various'), ('aspects', 'aspect'), ('various', 'various'), ('preferences', 'preference'), ('features', 'feature'), ('used', 'used'), ('represent', 'represent'), ('various', 'various'), ('aspects', 'aspect'), ('.', '.')]


------------------- Sentence 4 -------------------

(Fang et al.

>> Tokens are: 
 ['(', 'Fang', 'et', 'al', '.']

>> Bigrams are: 
 [('(', 'Fang'), ('Fang', 'et'), ('et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('(', 'Fang', 'et'), ('Fang', 'et', 'al'), ('et', 'al', '.')]

>> POS Tags are: 
 [('(', '('), ('Fang', 'NNP'), ('et', 'RB'), ('al', 'RB'), ('.', '.')]

>> Noun Phrases are: 
 ['Fang']

>> Named Entities are: 
 [('PERSON', 'Fang')] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('Fang', 'fang'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('Fang', 'fang'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('(', '('), ('Fang', 'Fang'), ('et', 'et'), ('al', 'al'), ('.', '.')]


------------------- Sentence 5 -------------------

2015 [72])

>> Tokens are: 
 ['2015', '[', '72', ']', ')']

>> Bigrams are: 
 [('2015', '['), ('[', '72'), ('72', ']'), (']', ')')]

>> Trigrams are: 
 [('2015', '[', '72'), ('[', '72', ']'), ('72', ']', ')')]

>> POS Tags are: 
 [('2015', 'CD'), ('[', '$'), ('72', 'CD'), (']', 'NN'), (')', ')')]

>> Noun Phrases are: 
 [']']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('2015', '2015'), ('[', '['), ('72', '72'), (']', ']'), (')', ')')]

>> Stemming using Snowball Stemmer: 
 [('2015', '2015'), ('[', '['), ('72', '72'), (']', ']'), (')', ')')]

>> Lemmatization: 
 [('2015', '2015'), ('[', '['), ('72', '72'), (']', ']'), (')', ')')]



========================================== PARAGRAPH 421 ===========================================

  6.6 Dialogue System  

------------------- Sentence 1 -------------------

  6.6 Dialogue System

>> Tokens are: 
 ['6.6', 'Dialogue', 'System']

>> Bigrams are: 
 [('6.6', 'Dialogue'), ('Dialogue', 'System')]

>> Trigrams are: 
 [('6.6', 'Dialogue', 'System')]

>> POS Tags are: 
 [('6.6', 'CD'), ('Dialogue', 'NNP'), ('System', 'NNP')]

>> Noun Phrases are: 
 ['Dialogue System']

>> Named Entities are: 
 [('PERSON', 'Dialogue System')] 

>> Stemming using Porter Stemmer: 
 [('6.6', '6.6'), ('Dialogue', 'dialogu'), ('System', 'system')]

>> Stemming using Snowball Stemmer: 
 [('6.6', '6.6'), ('Dialogue', 'dialogu'), ('System', 'system')]

>> Lemmatization: 
 [('6.6', '6.6'), ('Dialogue', 'Dialogue'), ('System', 'System')]



========================================== PARAGRAPH 422 ===========================================

Perhaps the most desirable application of the future, in the systems envisioned by large  

------------------- Sentence 1 -------------------

Perhaps the most desirable application of the future, in the systems envisioned by large

>> Tokens are: 
 ['Perhaps', 'desirable', 'application', 'future', ',', 'systems', 'envisioned', 'large']

>> Bigrams are: 
 [('Perhaps', 'desirable'), ('desirable', 'application'), ('application', 'future'), ('future', ','), (',', 'systems'), ('systems', 'envisioned'), ('envisioned', 'large')]

>> Trigrams are: 
 [('Perhaps', 'desirable', 'application'), ('desirable', 'application', 'future'), ('application', 'future', ','), ('future', ',', 'systems'), (',', 'systems', 'envisioned'), ('systems', 'envisioned', 'large')]

>> POS Tags are: 
 [('Perhaps', 'RB'), ('desirable', 'JJ'), ('application', 'NN'), ('future', 'NN'), (',', ','), ('systems', 'NNS'), ('envisioned', 'VBD'), ('large', 'JJ')]

>> Noun Phrases are: 
 ['desirable application future', 'systems']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Perhaps', 'perhap'), ('desirable', 'desir'), ('application', 'applic'), ('future', 'futur'), (',', ','), ('systems', 'system'), ('envisioned', 'envis'), ('large', 'larg')]

>> Stemming using Snowball Stemmer: 
 [('Perhaps', 'perhap'), ('desirable', 'desir'), ('application', 'applic'), ('future', 'futur'), (',', ','), ('systems', 'system'), ('envisioned', 'envis'), ('large', 'larg')]

>> Lemmatization: 
 [('Perhaps', 'Perhaps'), ('desirable', 'desirable'), ('application', 'application'), ('future', 'future'), (',', ','), ('systems', 'system'), ('envisioned', 'envisioned'), ('large', 'large')]



========================================== PARAGRAPH 423 ===========================================

providers of end user applications, Dialogue systems, which focuses on a narrowly defined  

------------------- Sentence 1 -------------------

providers of end user applications, Dialogue systems, which focuses on a narrowly defined

>> Tokens are: 
 ['providers', 'end', 'user', 'applications', ',', 'Dialogue', 'systems', ',', 'focuses', 'narrowly', 'defined']

>> Bigrams are: 
 [('providers', 'end'), ('end', 'user'), ('user', 'applications'), ('applications', ','), (',', 'Dialogue'), ('Dialogue', 'systems'), ('systems', ','), (',', 'focuses'), ('focuses', 'narrowly'), ('narrowly', 'defined')]

>> Trigrams are: 
 [('providers', 'end', 'user'), ('end', 'user', 'applications'), ('user', 'applications', ','), ('applications', ',', 'Dialogue'), (',', 'Dialogue', 'systems'), ('Dialogue', 'systems', ','), ('systems', ',', 'focuses'), (',', 'focuses', 'narrowly'), ('focuses', 'narrowly', 'defined')]

>> POS Tags are: 
 [('providers', 'NNS'), ('end', 'VBP'), ('user', 'NN'), ('applications', 'NNS'), (',', ','), ('Dialogue', 'NNP'), ('systems', 'NNS'), (',', ','), ('focuses', 'VBZ'), ('narrowly', 'RB'), ('defined', 'VBN')]

>> Noun Phrases are: 
 ['providers', 'user applications', 'Dialogue systems']

>> Named Entities are: 
 [('GPE', 'Dialogue')] 

>> Stemming using Porter Stemmer: 
 [('providers', 'provid'), ('end', 'end'), ('user', 'user'), ('applications', 'applic'), (',', ','), ('Dialogue', 'dialogu'), ('systems', 'system'), (',', ','), ('focuses', 'focus'), ('narrowly', 'narrowli'), ('defined', 'defin')]

>> Stemming using Snowball Stemmer: 
 [('providers', 'provid'), ('end', 'end'), ('user', 'user'), ('applications', 'applic'), (',', ','), ('Dialogue', 'dialogu'), ('systems', 'system'), (',', ','), ('focuses', 'focus'), ('narrowly', 'narrowli'), ('defined', 'defin')]

>> Lemmatization: 
 [('providers', 'provider'), ('end', 'end'), ('user', 'user'), ('applications', 'application'), (',', ','), ('Dialogue', 'Dialogue'), ('systems', 'system'), (',', ','), ('focuses', 'focus'), ('narrowly', 'narrowly'), ('defined', 'defined')]



========================================== PARAGRAPH 424 ===========================================

applications (like refrigerator or home theater systems) currently uses the phonetic and lexical  

------------------- Sentence 1 -------------------

applications (like refrigerator or home theater systems) currently uses the phonetic and lexical

>> Tokens are: 
 ['applications', '(', 'like', 'refrigerator', 'home', 'theater', 'systems', ')', 'currently', 'uses', 'phonetic', 'lexical']

>> Bigrams are: 
 [('applications', '('), ('(', 'like'), ('like', 'refrigerator'), ('refrigerator', 'home'), ('home', 'theater'), ('theater', 'systems'), ('systems', ')'), (')', 'currently'), ('currently', 'uses'), ('uses', 'phonetic'), ('phonetic', 'lexical')]

>> Trigrams are: 
 [('applications', '(', 'like'), ('(', 'like', 'refrigerator'), ('like', 'refrigerator', 'home'), ('refrigerator', 'home', 'theater'), ('home', 'theater', 'systems'), ('theater', 'systems', ')'), ('systems', ')', 'currently'), (')', 'currently', 'uses'), ('currently', 'uses', 'phonetic'), ('uses', 'phonetic', 'lexical')]

>> POS Tags are: 
 [('applications', 'NNS'), ('(', '('), ('like', 'IN'), ('refrigerator', 'NN'), ('home', 'NN'), ('theater', 'NN'), ('systems', 'NNS'), (')', ')'), ('currently', 'RB'), ('uses', 'VBZ'), ('phonetic', 'JJ'), ('lexical', 'JJ')]

>> Noun Phrases are: 
 ['applications', 'refrigerator home theater systems']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('applications', 'applic'), ('(', '('), ('like', 'like'), ('refrigerator', 'refriger'), ('home', 'home'), ('theater', 'theater'), ('systems', 'system'), (')', ')'), ('currently', 'current'), ('uses', 'use'), ('phonetic', 'phonet'), ('lexical', 'lexic')]

>> Stemming using Snowball Stemmer: 
 [('applications', 'applic'), ('(', '('), ('like', 'like'), ('refrigerator', 'refriger'), ('home', 'home'), ('theater', 'theater'), ('systems', 'system'), (')', ')'), ('currently', 'current'), ('uses', 'use'), ('phonetic', 'phonet'), ('lexical', 'lexic')]

>> Lemmatization: 
 [('applications', 'application'), ('(', '('), ('like', 'like'), ('refrigerator', 'refrigerator'), ('home', 'home'), ('theater', 'theater'), ('systems', 'system'), (')', ')'), ('currently', 'currently'), ('uses', 'us'), ('phonetic', 'phonetic'), ('lexical', 'lexical')]



========================================== PARAGRAPH 425 ===========================================

levels of language. It is believed that these dialogue systems when utilizing all levels of  

------------------- Sentence 1 -------------------

levels of language.

>> Tokens are: 
 ['levels', 'language', '.']

>> Bigrams are: 
 [('levels', 'language'), ('language', '.')]

>> Trigrams are: 
 [('levels', 'language', '.')]

>> POS Tags are: 
 [('levels', 'NNS'), ('language', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['levels language']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('levels', 'level'), ('language', 'languag'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('levels', 'level'), ('language', 'languag'), ('.', '.')]

>> Lemmatization: 
 [('levels', 'level'), ('language', 'language'), ('.', '.')]


------------------- Sentence 2 -------------------

It is believed that these dialogue systems when utilizing all levels of

>> Tokens are: 
 ['It', 'believed', 'dialogue', 'systems', 'utilizing', 'levels']

>> Bigrams are: 
 [('It', 'believed'), ('believed', 'dialogue'), ('dialogue', 'systems'), ('systems', 'utilizing'), ('utilizing', 'levels')]

>> Trigrams are: 
 [('It', 'believed', 'dialogue'), ('believed', 'dialogue', 'systems'), ('dialogue', 'systems', 'utilizing'), ('systems', 'utilizing', 'levels')]

>> POS Tags are: 
 [('It', 'PRP'), ('believed', 'VBD'), ('dialogue', 'JJ'), ('systems', 'NNS'), ('utilizing', 'JJ'), ('levels', 'NNS')]

>> Noun Phrases are: 
 ['dialogue systems', 'utilizing levels']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('It', 'it'), ('believed', 'believ'), ('dialogue', 'dialogu'), ('systems', 'system'), ('utilizing', 'util'), ('levels', 'level')]

>> Stemming using Snowball Stemmer: 
 [('It', 'it'), ('believed', 'believ'), ('dialogue', 'dialogu'), ('systems', 'system'), ('utilizing', 'util'), ('levels', 'level')]

>> Lemmatization: 
 [('It', 'It'), ('believed', 'believed'), ('dialogue', 'dialogue'), ('systems', 'system'), ('utilizing', 'utilizing'), ('levels', 'level')]



========================================== PARAGRAPH 426 ===========================================

language processing offer potential for fully automated dialog systems. (Elizabeth D. Liddy,  

------------------- Sentence 1 -------------------

language processing offer potential for fully automated dialog systems.

>> Tokens are: 
 ['language', 'processing', 'offer', 'potential', 'fully', 'automated', 'dialog', 'systems', '.']

>> Bigrams are: 
 [('language', 'processing'), ('processing', 'offer'), ('offer', 'potential'), ('potential', 'fully'), ('fully', 'automated'), ('automated', 'dialog'), ('dialog', 'systems'), ('systems', '.')]

>> Trigrams are: 
 [('language', 'processing', 'offer'), ('processing', 'offer', 'potential'), ('offer', 'potential', 'fully'), ('potential', 'fully', 'automated'), ('fully', 'automated', 'dialog'), ('automated', 'dialog', 'systems'), ('dialog', 'systems', '.')]

>> POS Tags are: 
 [('language', 'NN'), ('processing', 'NN'), ('offer', 'VBP'), ('potential', 'JJ'), ('fully', 'RB'), ('automated', 'VBN'), ('dialog', 'NN'), ('systems', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['language processing', 'dialog systems']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('language', 'languag'), ('processing', 'process'), ('offer', 'offer'), ('potential', 'potenti'), ('fully', 'fulli'), ('automated', 'autom'), ('dialog', 'dialog'), ('systems', 'system'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('language', 'languag'), ('processing', 'process'), ('offer', 'offer'), ('potential', 'potenti'), ('fully', 'fulli'), ('automated', 'autom'), ('dialog', 'dialog'), ('systems', 'system'), ('.', '.')]

>> Lemmatization: 
 [('language', 'language'), ('processing', 'processing'), ('offer', 'offer'), ('potential', 'potential'), ('fully', 'fully'), ('automated', 'automated'), ('dialog', 'dialog'), ('systems', 'system'), ('.', '.')]


------------------- Sentence 2 -------------------

(Elizabeth D. Liddy,

>> Tokens are: 
 ['(', 'Elizabeth', 'D.', 'Liddy', ',']

>> Bigrams are: 
 [('(', 'Elizabeth'), ('Elizabeth', 'D.'), ('D.', 'Liddy'), ('Liddy', ',')]

>> Trigrams are: 
 [('(', 'Elizabeth', 'D.'), ('Elizabeth', 'D.', 'Liddy'), ('D.', 'Liddy', ',')]

>> POS Tags are: 
 [('(', '('), ('Elizabeth', 'NNP'), ('D.', 'NNP'), ('Liddy', 'NNP'), (',', ',')]

>> Noun Phrases are: 
 ['Elizabeth D. Liddy']

>> Named Entities are: 
 [('PERSON', 'Elizabeth D. Liddy')] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('Elizabeth', 'elizabeth'), ('D.', 'd.'), ('Liddy', 'liddi'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('Elizabeth', 'elizabeth'), ('D.', 'd.'), ('Liddy', 'liddi'), (',', ',')]

>> Lemmatization: 
 [('(', '('), ('Elizabeth', 'Elizabeth'), ('D.', 'D.'), ('Liddy', 'Liddy'), (',', ',')]



========================================== PARAGRAPH 427 ===========================================

2001) [7]. Whether on text or via voice. This could lead to produce systems that can enable  

------------------- Sentence 1 -------------------

2001) [7].

>> Tokens are: 
 ['2001', ')', '[', '7', ']', '.']

>> Bigrams are: 
 [('2001', ')'), (')', '['), ('[', '7'), ('7', ']'), (']', '.')]

>> Trigrams are: 
 [('2001', ')', '['), (')', '[', '7'), ('[', '7', ']'), ('7', ']', '.')]

>> POS Tags are: 
 [('2001', 'CD'), (')', ')'), ('[', 'VBD'), ('7', 'CD'), (']', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 [']']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('2001', '2001'), (')', ')'), ('[', '['), ('7', '7'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('2001', '2001'), (')', ')'), ('[', '['), ('7', '7'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('2001', '2001'), (')', ')'), ('[', '['), ('7', '7'), (']', ']'), ('.', '.')]


------------------- Sentence 2 -------------------

Whether on text or via voice.

>> Tokens are: 
 ['Whether', 'text', 'via', 'voice', '.']

>> Bigrams are: 
 [('Whether', 'text'), ('text', 'via'), ('via', 'voice'), ('voice', '.')]

>> Trigrams are: 
 [('Whether', 'text', 'via'), ('text', 'via', 'voice'), ('via', 'voice', '.')]

>> POS Tags are: 
 [('Whether', 'NNP'), ('text', 'NN'), ('via', 'IN'), ('voice', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Whether text', 'voice']

>> Named Entities are: 
 [('GPE', 'Whether')] 

>> Stemming using Porter Stemmer: 
 [('Whether', 'whether'), ('text', 'text'), ('via', 'via'), ('voice', 'voic'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Whether', 'whether'), ('text', 'text'), ('via', 'via'), ('voice', 'voic'), ('.', '.')]

>> Lemmatization: 
 [('Whether', 'Whether'), ('text', 'text'), ('via', 'via'), ('voice', 'voice'), ('.', '.')]


------------------- Sentence 3 -------------------

This could lead to produce systems that can enable

>> Tokens are: 
 ['This', 'could', 'lead', 'produce', 'systems', 'enable']

>> Bigrams are: 
 [('This', 'could'), ('could', 'lead'), ('lead', 'produce'), ('produce', 'systems'), ('systems', 'enable')]

>> Trigrams are: 
 [('This', 'could', 'lead'), ('could', 'lead', 'produce'), ('lead', 'produce', 'systems'), ('produce', 'systems', 'enable')]

>> POS Tags are: 
 [('This', 'DT'), ('could', 'MD'), ('lead', 'VB'), ('produce', 'VB'), ('systems', 'NNS'), ('enable', 'JJ')]

>> Noun Phrases are: 
 ['systems']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('This', 'thi'), ('could', 'could'), ('lead', 'lead'), ('produce', 'produc'), ('systems', 'system'), ('enable', 'enabl')]

>> Stemming using Snowball Stemmer: 
 [('This', 'this'), ('could', 'could'), ('lead', 'lead'), ('produce', 'produc'), ('systems', 'system'), ('enable', 'enabl')]

>> Lemmatization: 
 [('This', 'This'), ('could', 'could'), ('lead', 'lead'), ('produce', 'produce'), ('systems', 'system'), ('enable', 'enable')]



========================================== PARAGRAPH 428 ===========================================

robots to interact with humans in natural languages. Examples like Google’s assistant,  

------------------- Sentence 1 -------------------

robots to interact with humans in natural languages.

>> Tokens are: 
 ['robots', 'interact', 'humans', 'natural', 'languages', '.']

>> Bigrams are: 
 [('robots', 'interact'), ('interact', 'humans'), ('humans', 'natural'), ('natural', 'languages'), ('languages', '.')]

>> Trigrams are: 
 [('robots', 'interact', 'humans'), ('interact', 'humans', 'natural'), ('humans', 'natural', 'languages'), ('natural', 'languages', '.')]

>> POS Tags are: 
 [('robots', 'NNS'), ('interact', 'VBP'), ('humans', 'NNS'), ('natural', 'JJ'), ('languages', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['robots', 'humans', 'natural languages']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('robots', 'robot'), ('interact', 'interact'), ('humans', 'human'), ('natural', 'natur'), ('languages', 'languag'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('robots', 'robot'), ('interact', 'interact'), ('humans', 'human'), ('natural', 'natur'), ('languages', 'languag'), ('.', '.')]

>> Lemmatization: 
 [('robots', 'robot'), ('interact', 'interact'), ('humans', 'human'), ('natural', 'natural'), ('languages', 'language'), ('.', '.')]


------------------- Sentence 2 -------------------

Examples like Google’s assistant,

>> Tokens are: 
 ['Examples', 'like', 'Google', '’', 'assistant', ',']

>> Bigrams are: 
 [('Examples', 'like'), ('like', 'Google'), ('Google', '’'), ('’', 'assistant'), ('assistant', ',')]

>> Trigrams are: 
 [('Examples', 'like', 'Google'), ('like', 'Google', '’'), ('Google', '’', 'assistant'), ('’', 'assistant', ',')]

>> POS Tags are: 
 [('Examples', 'NNS'), ('like', 'IN'), ('Google', 'NNP'), ('’', 'NNP'), ('assistant', 'NN'), (',', ',')]

>> Noun Phrases are: 
 ['Examples', 'Google ’ assistant']

>> Named Entities are: 
 [('PERSON', 'Google')] 

>> Stemming using Porter Stemmer: 
 [('Examples', 'exampl'), ('like', 'like'), ('Google', 'googl'), ('’', '’'), ('assistant', 'assist'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('Examples', 'exampl'), ('like', 'like'), ('Google', 'googl'), ('’', '’'), ('assistant', 'assist'), (',', ',')]

>> Lemmatization: 
 [('Examples', 'Examples'), ('like', 'like'), ('Google', 'Google'), ('’', '’'), ('assistant', 'assistant'), (',', ',')]



========================================== PARAGRAPH 429 ===========================================

Windows Cortana, Apple’s Siri and Amazon’s Alexa are the software and devices that follow  

------------------- Sentence 1 -------------------

Windows Cortana, Apple’s Siri and Amazon’s Alexa are the software and devices that follow

>> Tokens are: 
 ['Windows', 'Cortana', ',', 'Apple', '’', 'Siri', 'Amazon', '’', 'Alexa', 'software', 'devices', 'follow']

>> Bigrams are: 
 [('Windows', 'Cortana'), ('Cortana', ','), (',', 'Apple'), ('Apple', '’'), ('’', 'Siri'), ('Siri', 'Amazon'), ('Amazon', '’'), ('’', 'Alexa'), ('Alexa', 'software'), ('software', 'devices'), ('devices', 'follow')]

>> Trigrams are: 
 [('Windows', 'Cortana', ','), ('Cortana', ',', 'Apple'), (',', 'Apple', '’'), ('Apple', '’', 'Siri'), ('’', 'Siri', 'Amazon'), ('Siri', 'Amazon', '’'), ('Amazon', '’', 'Alexa'), ('’', 'Alexa', 'software'), ('Alexa', 'software', 'devices'), ('software', 'devices', 'follow')]

>> POS Tags are: 
 [('Windows', 'NNP'), ('Cortana', 'NNP'), (',', ','), ('Apple', 'NNP'), ('’', 'NNP'), ('Siri', 'NNP'), ('Amazon', 'NNP'), ('’', 'NNP'), ('Alexa', 'NNP'), ('software', 'NN'), ('devices', 'NNS'), ('follow', 'VBP')]

>> Noun Phrases are: 
 ['Windows Cortana', 'Apple ’ Siri Amazon ’ Alexa software devices']

>> Named Entities are: 
 [('PERSON', 'Windows'), ('ORGANIZATION', 'Cortana'), ('PERSON', 'Apple'), ('PERSON', 'Amazon'), ('PERSON', 'Alexa')] 

>> Stemming using Porter Stemmer: 
 [('Windows', 'window'), ('Cortana', 'cortana'), (',', ','), ('Apple', 'appl'), ('’', '’'), ('Siri', 'siri'), ('Amazon', 'amazon'), ('’', '’'), ('Alexa', 'alexa'), ('software', 'softwar'), ('devices', 'devic'), ('follow', 'follow')]

>> Stemming using Snowball Stemmer: 
 [('Windows', 'window'), ('Cortana', 'cortana'), (',', ','), ('Apple', 'appl'), ('’', '’'), ('Siri', 'siri'), ('Amazon', 'amazon'), ('’', '’'), ('Alexa', 'alexa'), ('software', 'softwar'), ('devices', 'devic'), ('follow', 'follow')]

>> Lemmatization: 
 [('Windows', 'Windows'), ('Cortana', 'Cortana'), (',', ','), ('Apple', 'Apple'), ('’', '’'), ('Siri', 'Siri'), ('Amazon', 'Amazon'), ('’', '’'), ('Alexa', 'Alexa'), ('software', 'software'), ('devices', 'device'), ('follow', 'follow')]



========================================== PARAGRAPH 430 ===========================================

Dialogue systems.  

------------------- Sentence 1 -------------------

Dialogue systems.

>> Tokens are: 
 ['Dialogue', 'systems', '.']

>> Bigrams are: 
 [('Dialogue', 'systems'), ('systems', '.')]

>> Trigrams are: 
 [('Dialogue', 'systems', '.')]

>> POS Tags are: 
 [('Dialogue', 'NNP'), ('systems', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['Dialogue systems']

>> Named Entities are: 
 [('GPE', 'Dialogue')] 

>> Stemming using Porter Stemmer: 
 [('Dialogue', 'dialogu'), ('systems', 'system'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Dialogue', 'dialogu'), ('systems', 'system'), ('.', '.')]

>> Lemmatization: 
 [('Dialogue', 'Dialogue'), ('systems', 'system'), ('.', '.')]



========================================== PARAGRAPH 431 ===========================================

6.7 Medicine  

------------------- Sentence 1 -------------------

6.7 Medicine

>> Tokens are: 
 ['6.7', 'Medicine']

>> Bigrams are: 
 [('6.7', 'Medicine')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('6.7', 'CD'), ('Medicine', 'NN')]

>> Noun Phrases are: 
 ['Medicine']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('6.7', '6.7'), ('Medicine', 'medicin')]

>> Stemming using Snowball Stemmer: 
 [('6.7', '6.7'), ('Medicine', 'medicin')]

>> Lemmatization: 
 [('6.7', '6.7'), ('Medicine', 'Medicine')]



========================================== PARAGRAPH 432 ===========================================

NLP is applied in medicine field as well. The Linguistic String Project-Medical Language  

------------------- Sentence 1 -------------------

NLP is applied in medicine field as well.

>> Tokens are: 
 ['NLP', 'applied', 'medicine', 'field', 'well', '.']

>> Bigrams are: 
 [('NLP', 'applied'), ('applied', 'medicine'), ('medicine', 'field'), ('field', 'well'), ('well', '.')]

>> Trigrams are: 
 [('NLP', 'applied', 'medicine'), ('applied', 'medicine', 'field'), ('medicine', 'field', 'well'), ('field', 'well', '.')]

>> POS Tags are: 
 [('NLP', 'NNP'), ('applied', 'VBD'), ('medicine', 'JJ'), ('field', 'NN'), ('well', 'RB'), ('.', '.')]

>> Noun Phrases are: 
 ['NLP', 'medicine field']

>> Named Entities are: 
 [('ORGANIZATION', 'NLP')] 

>> Stemming using Porter Stemmer: 
 [('NLP', 'nlp'), ('applied', 'appli'), ('medicine', 'medicin'), ('field', 'field'), ('well', 'well'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('NLP', 'nlp'), ('applied', 'appli'), ('medicine', 'medicin'), ('field', 'field'), ('well', 'well'), ('.', '.')]

>> Lemmatization: 
 [('NLP', 'NLP'), ('applied', 'applied'), ('medicine', 'medicine'), ('field', 'field'), ('well', 'well'), ('.', '.')]


------------------- Sentence 2 -------------------

The Linguistic String Project-Medical Language

>> Tokens are: 
 ['The', 'Linguistic', 'String', 'Project-Medical', 'Language']

>> Bigrams are: 
 [('The', 'Linguistic'), ('Linguistic', 'String'), ('String', 'Project-Medical'), ('Project-Medical', 'Language')]

>> Trigrams are: 
 [('The', 'Linguistic', 'String'), ('Linguistic', 'String', 'Project-Medical'), ('String', 'Project-Medical', 'Language')]

>> POS Tags are: 
 [('The', 'DT'), ('Linguistic', 'JJ'), ('String', 'NNP'), ('Project-Medical', 'JJ'), ('Language', 'NN')]

>> Noun Phrases are: 
 ['The Linguistic String', 'Project-Medical Language']

>> Named Entities are: 
 [('ORGANIZATION', 'Linguistic')] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('Linguistic', 'linguist'), ('String', 'string'), ('Project-Medical', 'project-med'), ('Language', 'languag')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('Linguistic', 'linguist'), ('String', 'string'), ('Project-Medical', 'project-med'), ('Language', 'languag')]

>> Lemmatization: 
 [('The', 'The'), ('Linguistic', 'Linguistic'), ('String', 'String'), ('Project-Medical', 'Project-Medical'), ('Language', 'Language')]



========================================== PARAGRAPH 433 ===========================================

Processor is one the large scale projects of NLP in the field of medicine [74][75][76][77][78].  

------------------- Sentence 1 -------------------

Processor is one the large scale projects of NLP in the field of medicine [74][75][76][77][78].

>> Tokens are: 
 ['Processor', 'one', 'large', 'scale', 'projects', 'NLP', 'field', 'medicine', '[', '74', ']', '[', '75', ']', '[', '76', ']', '[', '77', ']', '[', '78', ']', '.']

>> Bigrams are: 
 [('Processor', 'one'), ('one', 'large'), ('large', 'scale'), ('scale', 'projects'), ('projects', 'NLP'), ('NLP', 'field'), ('field', 'medicine'), ('medicine', '['), ('[', '74'), ('74', ']'), (']', '['), ('[', '75'), ('75', ']'), (']', '['), ('[', '76'), ('76', ']'), (']', '['), ('[', '77'), ('77', ']'), (']', '['), ('[', '78'), ('78', ']'), (']', '.')]

>> Trigrams are: 
 [('Processor', 'one', 'large'), ('one', 'large', 'scale'), ('large', 'scale', 'projects'), ('scale', 'projects', 'NLP'), ('projects', 'NLP', 'field'), ('NLP', 'field', 'medicine'), ('field', 'medicine', '['), ('medicine', '[', '74'), ('[', '74', ']'), ('74', ']', '['), (']', '[', '75'), ('[', '75', ']'), ('75', ']', '['), (']', '[', '76'), ('[', '76', ']'), ('76', ']', '['), (']', '[', '77'), ('[', '77', ']'), ('77', ']', '['), (']', '[', '78'), ('[', '78', ']'), ('78', ']', '.')]

>> POS Tags are: 
 [('Processor', 'NNP'), ('one', 'CD'), ('large', 'JJ'), ('scale', 'JJ'), ('projects', 'NNS'), ('NLP', 'NNP'), ('field', 'NN'), ('medicine', 'NN'), ('[', '$'), ('74', 'CD'), (']', 'NNP'), ('[', 'VBD'), ('75', 'CD'), (']', 'NNP'), ('[', 'VBD'), ('76', 'CD'), (']', 'NNP'), ('[', 'VBD'), ('77', 'CD'), (']', 'NNP'), ('[', 'VBD'), ('78', 'CD'), (']', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Processor', 'large scale projects NLP field medicine', ']', ']', ']', ']', ']']

>> Named Entities are: 
 [('ORGANIZATION', 'NLP')] 

>> Stemming using Porter Stemmer: 
 [('Processor', 'processor'), ('one', 'one'), ('large', 'larg'), ('scale', 'scale'), ('projects', 'project'), ('NLP', 'nlp'), ('field', 'field'), ('medicine', 'medicin'), ('[', '['), ('74', '74'), (']', ']'), ('[', '['), ('75', '75'), (']', ']'), ('[', '['), ('76', '76'), (']', ']'), ('[', '['), ('77', '77'), (']', ']'), ('[', '['), ('78', '78'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Processor', 'processor'), ('one', 'one'), ('large', 'larg'), ('scale', 'scale'), ('projects', 'project'), ('NLP', 'nlp'), ('field', 'field'), ('medicine', 'medicin'), ('[', '['), ('74', '74'), (']', ']'), ('[', '['), ('75', '75'), (']', ']'), ('[', '['), ('76', '76'), (']', ']'), ('[', '['), ('77', '77'), (']', ']'), ('[', '['), ('78', '78'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('Processor', 'Processor'), ('one', 'one'), ('large', 'large'), ('scale', 'scale'), ('projects', 'project'), ('NLP', 'NLP'), ('field', 'field'), ('medicine', 'medicine'), ('[', '['), ('74', '74'), (']', ']'), ('[', '['), ('75', '75'), (']', ']'), ('[', '['), ('76', '76'), (']', ']'), ('[', '['), ('77', '77'), (']', ']'), ('[', '['), ('78', '78'), (']', ']'), ('.', '.')]



========================================== PARAGRAPH 434 ===========================================

The LSP-MLP helps enabling physicians to extract and summarize information of any signs  

------------------- Sentence 1 -------------------

The LSP-MLP helps enabling physicians to extract and summarize information of any signs

>> Tokens are: 
 ['The', 'LSP-MLP', 'helps', 'enabling', 'physicians', 'extract', 'summarize', 'information', 'signs']

>> Bigrams are: 
 [('The', 'LSP-MLP'), ('LSP-MLP', 'helps'), ('helps', 'enabling'), ('enabling', 'physicians'), ('physicians', 'extract'), ('extract', 'summarize'), ('summarize', 'information'), ('information', 'signs')]

>> Trigrams are: 
 [('The', 'LSP-MLP', 'helps'), ('LSP-MLP', 'helps', 'enabling'), ('helps', 'enabling', 'physicians'), ('enabling', 'physicians', 'extract'), ('physicians', 'extract', 'summarize'), ('extract', 'summarize', 'information'), ('summarize', 'information', 'signs')]

>> POS Tags are: 
 [('The', 'DT'), ('LSP-MLP', 'NNP'), ('helps', 'VBZ'), ('enabling', 'VBG'), ('physicians', 'NNS'), ('extract', 'JJ'), ('summarize', 'JJ'), ('information', 'NN'), ('signs', 'NNS')]

>> Noun Phrases are: 
 ['The LSP-MLP', 'physicians', 'extract summarize information signs']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('LSP-MLP', 'lsp-mlp'), ('helps', 'help'), ('enabling', 'enabl'), ('physicians', 'physician'), ('extract', 'extract'), ('summarize', 'summar'), ('information', 'inform'), ('signs', 'sign')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('LSP-MLP', 'lsp-mlp'), ('helps', 'help'), ('enabling', 'enabl'), ('physicians', 'physician'), ('extract', 'extract'), ('summarize', 'summar'), ('information', 'inform'), ('signs', 'sign')]

>> Lemmatization: 
 [('The', 'The'), ('LSP-MLP', 'LSP-MLP'), ('helps', 'help'), ('enabling', 'enabling'), ('physicians', 'physician'), ('extract', 'extract'), ('summarize', 'summarize'), ('information', 'information'), ('signs', 'sign')]



========================================== PARAGRAPH 435 ===========================================

or symptoms, drug dosage and response data with aim of identifying possible side effects of  

------------------- Sentence 1 -------------------

or symptoms, drug dosage and response data with aim of identifying possible side effects of

>> Tokens are: 
 ['symptoms', ',', 'drug', 'dosage', 'response', 'data', 'aim', 'identifying', 'possible', 'side', 'effects']

>> Bigrams are: 
 [('symptoms', ','), (',', 'drug'), ('drug', 'dosage'), ('dosage', 'response'), ('response', 'data'), ('data', 'aim'), ('aim', 'identifying'), ('identifying', 'possible'), ('possible', 'side'), ('side', 'effects')]

>> Trigrams are: 
 [('symptoms', ',', 'drug'), (',', 'drug', 'dosage'), ('drug', 'dosage', 'response'), ('dosage', 'response', 'data'), ('response', 'data', 'aim'), ('data', 'aim', 'identifying'), ('aim', 'identifying', 'possible'), ('identifying', 'possible', 'side'), ('possible', 'side', 'effects')]

>> POS Tags are: 
 [('symptoms', 'NNS'), (',', ','), ('drug', 'NN'), ('dosage', 'NN'), ('response', 'NN'), ('data', 'NNS'), ('aim', 'NN'), ('identifying', 'VBG'), ('possible', 'JJ'), ('side', 'NN'), ('effects', 'NNS')]

>> Noun Phrases are: 
 ['symptoms', 'drug dosage response data aim', 'possible side effects']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('symptoms', 'symptom'), (',', ','), ('drug', 'drug'), ('dosage', 'dosag'), ('response', 'respons'), ('data', 'data'), ('aim', 'aim'), ('identifying', 'identifi'), ('possible', 'possibl'), ('side', 'side'), ('effects', 'effect')]

>> Stemming using Snowball Stemmer: 
 [('symptoms', 'symptom'), (',', ','), ('drug', 'drug'), ('dosage', 'dosag'), ('response', 'respons'), ('data', 'data'), ('aim', 'aim'), ('identifying', 'identifi'), ('possible', 'possibl'), ('side', 'side'), ('effects', 'effect')]

>> Lemmatization: 
 [('symptoms', 'symptom'), (',', ','), ('drug', 'drug'), ('dosage', 'dosage'), ('response', 'response'), ('data', 'data'), ('aim', 'aim'), ('identifying', 'identifying'), ('possible', 'possible'), ('side', 'side'), ('effects', 'effect')]



========================================== PARAGRAPH 436 ===========================================

any medicine while highlighting or flagging data items [74]. The National Library of  

------------------- Sentence 1 -------------------

any medicine while highlighting or flagging data items [74].

>> Tokens are: 
 ['medicine', 'highlighting', 'flagging', 'data', 'items', '[', '74', ']', '.']

>> Bigrams are: 
 [('medicine', 'highlighting'), ('highlighting', 'flagging'), ('flagging', 'data'), ('data', 'items'), ('items', '['), ('[', '74'), ('74', ']'), (']', '.')]

>> Trigrams are: 
 [('medicine', 'highlighting', 'flagging'), ('highlighting', 'flagging', 'data'), ('flagging', 'data', 'items'), ('data', 'items', '['), ('items', '[', '74'), ('[', '74', ']'), ('74', ']', '.')]

>> POS Tags are: 
 [('medicine', 'NN'), ('highlighting', 'VBG'), ('flagging', 'VBG'), ('data', 'NNS'), ('items', 'NNS'), ('[', 'VBD'), ('74', 'CD'), (']', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['medicine', 'data items', ']']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('medicine', 'medicin'), ('highlighting', 'highlight'), ('flagging', 'flag'), ('data', 'data'), ('items', 'item'), ('[', '['), ('74', '74'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('medicine', 'medicin'), ('highlighting', 'highlight'), ('flagging', 'flag'), ('data', 'data'), ('items', 'item'), ('[', '['), ('74', '74'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('medicine', 'medicine'), ('highlighting', 'highlighting'), ('flagging', 'flagging'), ('data', 'data'), ('items', 'item'), ('[', '['), ('74', '74'), (']', ']'), ('.', '.')]


------------------- Sentence 2 -------------------

The National Library of

>> Tokens are: 
 ['The', 'National', 'Library']

>> Bigrams are: 
 [('The', 'National'), ('National', 'Library')]

>> Trigrams are: 
 [('The', 'National', 'Library')]

>> POS Tags are: 
 [('The', 'DT'), ('National', 'NNP'), ('Library', 'NNP')]

>> Noun Phrases are: 
 ['The National Library']

>> Named Entities are: 
 [('ORGANIZATION', 'National')] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('National', 'nation'), ('Library', 'librari')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('National', 'nation'), ('Library', 'librari')]

>> Lemmatization: 
 [('The', 'The'), ('National', 'National'), ('Library', 'Library')]



========================================== PARAGRAPH 437 ===========================================

Medicine is developing The Specialist System [79][80][81][82][83]. It is expected to function  

------------------- Sentence 1 -------------------

Medicine is developing The Specialist System [79][80][81][82][83].

>> Tokens are: 
 ['Medicine', 'developing', 'The', 'Specialist', 'System', '[', '79', ']', '[', '80', ']', '[', '81', ']', '[', '82', ']', '[', '83', ']', '.']

>> Bigrams are: 
 [('Medicine', 'developing'), ('developing', 'The'), ('The', 'Specialist'), ('Specialist', 'System'), ('System', '['), ('[', '79'), ('79', ']'), (']', '['), ('[', '80'), ('80', ']'), (']', '['), ('[', '81'), ('81', ']'), (']', '['), ('[', '82'), ('82', ']'), (']', '['), ('[', '83'), ('83', ']'), (']', '.')]

>> Trigrams are: 
 [('Medicine', 'developing', 'The'), ('developing', 'The', 'Specialist'), ('The', 'Specialist', 'System'), ('Specialist', 'System', '['), ('System', '[', '79'), ('[', '79', ']'), ('79', ']', '['), (']', '[', '80'), ('[', '80', ']'), ('80', ']', '['), (']', '[', '81'), ('[', '81', ']'), ('81', ']', '['), (']', '[', '82'), ('[', '82', ']'), ('82', ']', '['), (']', '[', '83'), ('[', '83', ']'), ('83', ']', '.')]

>> POS Tags are: 
 [('Medicine', 'NNP'), ('developing', 'VBG'), ('The', 'DT'), ('Specialist', 'NN'), ('System', 'NNP'), ('[', 'VBZ'), ('79', 'CD'), (']', 'NN'), ('[', 'VBD'), ('80', 'CD'), (']', 'NNP'), ('[', 'VBD'), ('81', 'CD'), (']', 'NNP'), ('[', 'VBD'), ('82', 'CD'), (']', 'NNP'), ('[', 'VBD'), ('83', 'CD'), (']', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Medicine', 'The Specialist System', ']', ']', ']', ']', ']']

>> Named Entities are: 
 [('GPE', 'Medicine'), ('ORGANIZATION', 'Specialist System')] 

>> Stemming using Porter Stemmer: 
 [('Medicine', 'medicin'), ('developing', 'develop'), ('The', 'the'), ('Specialist', 'specialist'), ('System', 'system'), ('[', '['), ('79', '79'), (']', ']'), ('[', '['), ('80', '80'), (']', ']'), ('[', '['), ('81', '81'), (']', ']'), ('[', '['), ('82', '82'), (']', ']'), ('[', '['), ('83', '83'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Medicine', 'medicin'), ('developing', 'develop'), ('The', 'the'), ('Specialist', 'specialist'), ('System', 'system'), ('[', '['), ('79', '79'), (']', ']'), ('[', '['), ('80', '80'), (']', ']'), ('[', '['), ('81', '81'), (']', ']'), ('[', '['), ('82', '82'), (']', ']'), ('[', '['), ('83', '83'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('Medicine', 'Medicine'), ('developing', 'developing'), ('The', 'The'), ('Specialist', 'Specialist'), ('System', 'System'), ('[', '['), ('79', '79'), (']', ']'), ('[', '['), ('80', '80'), (']', ']'), ('[', '['), ('81', '81'), (']', ']'), ('[', '['), ('82', '82'), (']', ']'), ('[', '['), ('83', '83'), (']', ']'), ('.', '.')]


------------------- Sentence 2 -------------------

It is expected to function

>> Tokens are: 
 ['It', 'expected', 'function']

>> Bigrams are: 
 [('It', 'expected'), ('expected', 'function')]

>> Trigrams are: 
 [('It', 'expected', 'function')]

>> POS Tags are: 
 [('It', 'PRP'), ('expected', 'VBD'), ('function', 'NN')]

>> Noun Phrases are: 
 ['function']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('It', 'it'), ('expected', 'expect'), ('function', 'function')]

>> Stemming using Snowball Stemmer: 
 [('It', 'it'), ('expected', 'expect'), ('function', 'function')]

>> Lemmatization: 
 [('It', 'It'), ('expected', 'expected'), ('function', 'function')]



========================================== PARAGRAPH 438 ===========================================

as Information Extraction tool for Biomedical Knowledge Bases, particularly Medline 

------------------- Sentence 1 -------------------

as Information Extraction tool for Biomedical Knowledge Bases, particularly Medline

>> Tokens are: 
 ['Information', 'Extraction', 'tool', 'Biomedical', 'Knowledge', 'Bases', ',', 'particularly', 'Medline']

>> Bigrams are: 
 [('Information', 'Extraction'), ('Extraction', 'tool'), ('tool', 'Biomedical'), ('Biomedical', 'Knowledge'), ('Knowledge', 'Bases'), ('Bases', ','), (',', 'particularly'), ('particularly', 'Medline')]

>> Trigrams are: 
 [('Information', 'Extraction', 'tool'), ('Extraction', 'tool', 'Biomedical'), ('tool', 'Biomedical', 'Knowledge'), ('Biomedical', 'Knowledge', 'Bases'), ('Knowledge', 'Bases', ','), ('Bases', ',', 'particularly'), (',', 'particularly', 'Medline')]

>> POS Tags are: 
 [('Information', 'NN'), ('Extraction', 'NNP'), ('tool', 'NN'), ('Biomedical', 'NNP'), ('Knowledge', 'NNP'), ('Bases', 'NNP'), (',', ','), ('particularly', 'RB'), ('Medline', 'NN')]

>> Noun Phrases are: 
 ['Information Extraction tool Biomedical Knowledge Bases', 'Medline']

>> Named Entities are: 
 [('ORGANIZATION', 'Biomedical'), ('PERSON', 'Medline')] 

>> Stemming using Porter Stemmer: 
 [('Information', 'inform'), ('Extraction', 'extract'), ('tool', 'tool'), ('Biomedical', 'biomed'), ('Knowledge', 'knowledg'), ('Bases', 'base'), (',', ','), ('particularly', 'particularli'), ('Medline', 'medlin')]

>> Stemming using Snowball Stemmer: 
 [('Information', 'inform'), ('Extraction', 'extract'), ('tool', 'tool'), ('Biomedical', 'biomed'), ('Knowledge', 'knowledg'), ('Bases', 'base'), (',', ','), ('particularly', 'particular'), ('Medline', 'medlin')]

>> Lemmatization: 
 [('Information', 'Information'), ('Extraction', 'Extraction'), ('tool', 'tool'), ('Biomedical', 'Biomedical'), ('Knowledge', 'Knowledge'), ('Bases', 'Bases'), (',', ','), ('particularly', 'particularly'), ('Medline', 'Medline')]



========================================== PARAGRAPH 439 ===========================================

abstracts. The lexicon was created using MeSH (Medical Subject Headings), Dorland’s  

------------------- Sentence 1 -------------------

abstracts.

>> Tokens are: 
 ['abstracts', '.']

>> Bigrams are: 
 [('abstracts', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('abstracts', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['abstracts']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('abstracts', 'abstract'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('abstracts', 'abstract'), ('.', '.')]

>> Lemmatization: 
 [('abstracts', 'abstract'), ('.', '.')]


------------------- Sentence 2 -------------------

The lexicon was created using MeSH (Medical Subject Headings), Dorland’s

>> Tokens are: 
 ['The', 'lexicon', 'created', 'using', 'MeSH', '(', 'Medical', 'Subject', 'Headings', ')', ',', 'Dorland', '’']

>> Bigrams are: 
 [('The', 'lexicon'), ('lexicon', 'created'), ('created', 'using'), ('using', 'MeSH'), ('MeSH', '('), ('(', 'Medical'), ('Medical', 'Subject'), ('Subject', 'Headings'), ('Headings', ')'), (')', ','), (',', 'Dorland'), ('Dorland', '’')]

>> Trigrams are: 
 [('The', 'lexicon', 'created'), ('lexicon', 'created', 'using'), ('created', 'using', 'MeSH'), ('using', 'MeSH', '('), ('MeSH', '(', 'Medical'), ('(', 'Medical', 'Subject'), ('Medical', 'Subject', 'Headings'), ('Subject', 'Headings', ')'), ('Headings', ')', ','), (')', ',', 'Dorland'), (',', 'Dorland', '’')]

>> POS Tags are: 
 [('The', 'DT'), ('lexicon', 'NN'), ('created', 'VBD'), ('using', 'VBG'), ('MeSH', 'NNP'), ('(', '('), ('Medical', 'NNP'), ('Subject', 'NNP'), ('Headings', 'NNP'), (')', ')'), (',', ','), ('Dorland', 'NNP'), ('’', 'NNP')]

>> Noun Phrases are: 
 ['The lexicon', 'MeSH', 'Medical Subject Headings', 'Dorland ’']

>> Named Entities are: 
 [('ORGANIZATION', 'MeSH'), ('ORGANIZATION', 'Medical Subject'), ('PERSON', 'Dorland')] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('lexicon', 'lexicon'), ('created', 'creat'), ('using', 'use'), ('MeSH', 'mesh'), ('(', '('), ('Medical', 'medic'), ('Subject', 'subject'), ('Headings', 'head'), (')', ')'), (',', ','), ('Dorland', 'dorland'), ('’', '’')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('lexicon', 'lexicon'), ('created', 'creat'), ('using', 'use'), ('MeSH', 'mesh'), ('(', '('), ('Medical', 'medic'), ('Subject', 'subject'), ('Headings', 'head'), (')', ')'), (',', ','), ('Dorland', 'dorland'), ('’', '’')]

>> Lemmatization: 
 [('The', 'The'), ('lexicon', 'lexicon'), ('created', 'created'), ('using', 'using'), ('MeSH', 'MeSH'), ('(', '('), ('Medical', 'Medical'), ('Subject', 'Subject'), ('Headings', 'Headings'), (')', ')'), (',', ','), ('Dorland', 'Dorland'), ('’', '’')]



========================================== PARAGRAPH 440 ===========================================

Illustrated Medical Dictionary and general English Dictionaries. The Centre d’Informatique  

------------------- Sentence 1 -------------------

Illustrated Medical Dictionary and general English Dictionaries.

>> Tokens are: 
 ['Illustrated', 'Medical', 'Dictionary', 'general', 'English', 'Dictionaries', '.']

>> Bigrams are: 
 [('Illustrated', 'Medical'), ('Medical', 'Dictionary'), ('Dictionary', 'general'), ('general', 'English'), ('English', 'Dictionaries'), ('Dictionaries', '.')]

>> Trigrams are: 
 [('Illustrated', 'Medical', 'Dictionary'), ('Medical', 'Dictionary', 'general'), ('Dictionary', 'general', 'English'), ('general', 'English', 'Dictionaries'), ('English', 'Dictionaries', '.')]

>> POS Tags are: 
 [('Illustrated', 'NNP'), ('Medical', 'NNP'), ('Dictionary', 'NNP'), ('general', 'JJ'), ('English', 'NNP'), ('Dictionaries', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Illustrated Medical Dictionary', 'general English Dictionaries']

>> Named Entities are: 
 [('GPE', 'Illustrated'), ('ORGANIZATION', 'Medical'), ('PERSON', 'English Dictionaries')] 

>> Stemming using Porter Stemmer: 
 [('Illustrated', 'illustr'), ('Medical', 'medic'), ('Dictionary', 'dictionari'), ('general', 'gener'), ('English', 'english'), ('Dictionaries', 'dictionari'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Illustrated', 'illustr'), ('Medical', 'medic'), ('Dictionary', 'dictionari'), ('general', 'general'), ('English', 'english'), ('Dictionaries', 'dictionari'), ('.', '.')]

>> Lemmatization: 
 [('Illustrated', 'Illustrated'), ('Medical', 'Medical'), ('Dictionary', 'Dictionary'), ('general', 'general'), ('English', 'English'), ('Dictionaries', 'Dictionaries'), ('.', '.')]


------------------- Sentence 2 -------------------

The Centre d’Informatique

>> Tokens are: 
 ['The', 'Centre', '’', 'Informatique']

>> Bigrams are: 
 [('The', 'Centre'), ('Centre', '’'), ('’', 'Informatique')]

>> Trigrams are: 
 [('The', 'Centre', '’'), ('Centre', '’', 'Informatique')]

>> POS Tags are: 
 [('The', 'DT'), ('Centre', 'NNP'), ('’', 'NNP'), ('Informatique', 'NNP')]

>> Noun Phrases are: 
 ['The Centre ’ Informatique']

>> Named Entities are: 
 [('ORGANIZATION', 'Centre')] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('Centre', 'centr'), ('’', '’'), ('Informatique', 'informatiqu')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('Centre', 'centr'), ('’', '’'), ('Informatique', 'informatiqu')]

>> Lemmatization: 
 [('The', 'The'), ('Centre', 'Centre'), ('’', '’'), ('Informatique', 'Informatique')]



========================================== PARAGRAPH 441 ===========================================

Hospitaliere of the Hopital Cantonal de Geneve is working on an electronic archiving  

------------------- Sentence 1 -------------------

Hospitaliere of the Hopital Cantonal de Geneve is working on an electronic archiving

>> Tokens are: 
 ['Hospitaliere', 'Hopital', 'Cantonal', 'de', 'Geneve', 'working', 'electronic', 'archiving']

>> Bigrams are: 
 [('Hospitaliere', 'Hopital'), ('Hopital', 'Cantonal'), ('Cantonal', 'de'), ('de', 'Geneve'), ('Geneve', 'working'), ('working', 'electronic'), ('electronic', 'archiving')]

>> Trigrams are: 
 [('Hospitaliere', 'Hopital', 'Cantonal'), ('Hopital', 'Cantonal', 'de'), ('Cantonal', 'de', 'Geneve'), ('de', 'Geneve', 'working'), ('Geneve', 'working', 'electronic'), ('working', 'electronic', 'archiving')]

>> POS Tags are: 
 [('Hospitaliere', 'NNP'), ('Hopital', 'NNP'), ('Cantonal', 'NNP'), ('de', 'IN'), ('Geneve', 'NNP'), ('working', 'VBG'), ('electronic', 'JJ'), ('archiving', 'NN')]

>> Noun Phrases are: 
 ['Hospitaliere Hopital Cantonal', 'Geneve', 'electronic archiving']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Hospitaliere', 'hospitalier'), ('Hopital', 'hopit'), ('Cantonal', 'canton'), ('de', 'de'), ('Geneve', 'genev'), ('working', 'work'), ('electronic', 'electron'), ('archiving', 'archiv')]

>> Stemming using Snowball Stemmer: 
 [('Hospitaliere', 'hospitalier'), ('Hopital', 'hopit'), ('Cantonal', 'canton'), ('de', 'de'), ('Geneve', 'genev'), ('working', 'work'), ('electronic', 'electron'), ('archiving', 'archiv')]

>> Lemmatization: 
 [('Hospitaliere', 'Hospitaliere'), ('Hopital', 'Hopital'), ('Cantonal', 'Cantonal'), ('de', 'de'), ('Geneve', 'Geneve'), ('working', 'working'), ('electronic', 'electronic'), ('archiving', 'archiving')]



========================================== PARAGRAPH 442 ===========================================

environment with NLP features [84][85]. In first phase, patient records were archived . At  

------------------- Sentence 1 -------------------

environment with NLP features [84][85].

>> Tokens are: 
 ['environment', 'NLP', 'features', '[', '84', ']', '[', '85', ']', '.']

>> Bigrams are: 
 [('environment', 'NLP'), ('NLP', 'features'), ('features', '['), ('[', '84'), ('84', ']'), (']', '['), ('[', '85'), ('85', ']'), (']', '.')]

>> Trigrams are: 
 [('environment', 'NLP', 'features'), ('NLP', 'features', '['), ('features', '[', '84'), ('[', '84', ']'), ('84', ']', '['), (']', '[', '85'), ('[', '85', ']'), ('85', ']', '.')]

>> POS Tags are: 
 [('environment', 'NN'), ('NLP', 'NNP'), ('features', 'VBZ'), ('[', '$'), ('84', 'CD'), (']', 'NNP'), ('[', 'VBD'), ('85', 'CD'), (']', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['environment NLP', ']', ']']

>> Named Entities are: 
 [('ORGANIZATION', 'NLP')] 

>> Stemming using Porter Stemmer: 
 [('environment', 'environ'), ('NLP', 'nlp'), ('features', 'featur'), ('[', '['), ('84', '84'), (']', ']'), ('[', '['), ('85', '85'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('environment', 'environ'), ('NLP', 'nlp'), ('features', 'featur'), ('[', '['), ('84', '84'), (']', ']'), ('[', '['), ('85', '85'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('environment', 'environment'), ('NLP', 'NLP'), ('features', 'feature'), ('[', '['), ('84', '84'), (']', ']'), ('[', '['), ('85', '85'), (']', ']'), ('.', '.')]


------------------- Sentence 2 -------------------

In first phase, patient records were archived .

>> Tokens are: 
 ['In', 'first', 'phase', ',', 'patient', 'records', 'archived', '.']

>> Bigrams are: 
 [('In', 'first'), ('first', 'phase'), ('phase', ','), (',', 'patient'), ('patient', 'records'), ('records', 'archived'), ('archived', '.')]

>> Trigrams are: 
 [('In', 'first', 'phase'), ('first', 'phase', ','), ('phase', ',', 'patient'), (',', 'patient', 'records'), ('patient', 'records', 'archived'), ('records', 'archived', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('first', 'JJ'), ('phase', 'NN'), (',', ','), ('patient', 'NN'), ('records', 'NNS'), ('archived', 'VBD'), ('.', '.')]

>> Noun Phrases are: 
 ['first phase', 'patient records']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('first', 'first'), ('phase', 'phase'), (',', ','), ('patient', 'patient'), ('records', 'record'), ('archived', 'archiv'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('first', 'first'), ('phase', 'phase'), (',', ','), ('patient', 'patient'), ('records', 'record'), ('archived', 'archiv'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('first', 'first'), ('phase', 'phase'), (',', ','), ('patient', 'patient'), ('records', 'record'), ('archived', 'archived'), ('.', '.')]


------------------- Sentence 3 -------------------

At

>> Tokens are: 
 ['At']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('At', 'IN')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('At', 'at')]

>> Stemming using Snowball Stemmer: 
 [('At', 'at')]

>> Lemmatization: 
 [('At', 'At')]



========================================== PARAGRAPH 443 ===========================================

later stage the LSP-MLP has been adapted for French [86][87][88][89] , and finally , a proper  

------------------- Sentence 1 -------------------

later stage the LSP-MLP has been adapted for French [86][87][88][89] , and finally , a proper

>> Tokens are: 
 ['later', 'stage', 'LSP-MLP', 'adapted', 'French', '[', '86', ']', '[', '87', ']', '[', '88', ']', '[', '89', ']', ',', 'finally', ',', 'proper']

>> Bigrams are: 
 [('later', 'stage'), ('stage', 'LSP-MLP'), ('LSP-MLP', 'adapted'), ('adapted', 'French'), ('French', '['), ('[', '86'), ('86', ']'), (']', '['), ('[', '87'), ('87', ']'), (']', '['), ('[', '88'), ('88', ']'), (']', '['), ('[', '89'), ('89', ']'), (']', ','), (',', 'finally'), ('finally', ','), (',', 'proper')]

>> Trigrams are: 
 [('later', 'stage', 'LSP-MLP'), ('stage', 'LSP-MLP', 'adapted'), ('LSP-MLP', 'adapted', 'French'), ('adapted', 'French', '['), ('French', '[', '86'), ('[', '86', ']'), ('86', ']', '['), (']', '[', '87'), ('[', '87', ']'), ('87', ']', '['), (']', '[', '88'), ('[', '88', ']'), ('88', ']', '['), (']', '[', '89'), ('[', '89', ']'), ('89', ']', ','), (']', ',', 'finally'), (',', 'finally', ','), ('finally', ',', 'proper')]

>> POS Tags are: 
 [('later', 'RB'), ('stage', 'NN'), ('LSP-MLP', 'JJ'), ('adapted', 'JJ'), ('French', 'JJ'), ('[', 'NN'), ('86', 'CD'), (']', 'NNP'), ('[', 'VBD'), ('87', 'CD'), (']', 'NNP'), ('[', 'VBD'), ('88', 'CD'), (']', 'NNP'), ('[', 'VBD'), ('89', 'CD'), (']', 'NN'), (',', ','), ('finally', 'RB'), (',', ','), ('proper', 'NN')]

>> Noun Phrases are: 
 ['stage', 'LSP-MLP adapted French [', ']', ']', ']', ']', 'proper']

>> Named Entities are: 
 [('GPE', 'French')] 

>> Stemming using Porter Stemmer: 
 [('later', 'later'), ('stage', 'stage'), ('LSP-MLP', 'lsp-mlp'), ('adapted', 'adapt'), ('French', 'french'), ('[', '['), ('86', '86'), (']', ']'), ('[', '['), ('87', '87'), (']', ']'), ('[', '['), ('88', '88'), (']', ']'), ('[', '['), ('89', '89'), (']', ']'), (',', ','), ('finally', 'final'), (',', ','), ('proper', 'proper')]

>> Stemming using Snowball Stemmer: 
 [('later', 'later'), ('stage', 'stage'), ('LSP-MLP', 'lsp-mlp'), ('adapted', 'adapt'), ('French', 'french'), ('[', '['), ('86', '86'), (']', ']'), ('[', '['), ('87', '87'), (']', ']'), ('[', '['), ('88', '88'), (']', ']'), ('[', '['), ('89', '89'), (']', ']'), (',', ','), ('finally', 'final'), (',', ','), ('proper', 'proper')]

>> Lemmatization: 
 [('later', 'later'), ('stage', 'stage'), ('LSP-MLP', 'LSP-MLP'), ('adapted', 'adapted'), ('French', 'French'), ('[', '['), ('86', '86'), (']', ']'), ('[', '['), ('87', '87'), (']', ']'), ('[', '['), ('88', '88'), (']', ']'), ('[', '['), ('89', '89'), (']', ']'), (',', ','), ('finally', 'finally'), (',', ','), ('proper', 'proper')]



========================================== PARAGRAPH 444 ===========================================

NLP system called RECIT  [90][91][92][93] has been developed using a method called  

------------------- Sentence 1 -------------------

NLP system called RECIT  [90][91][92][93] has been developed using a method called

>> Tokens are: 
 ['NLP', 'system', 'called', 'RECIT', '[', '90', ']', '[', '91', ']', '[', '92', ']', '[', '93', ']', 'developed', 'using', 'method', 'called']

>> Bigrams are: 
 [('NLP', 'system'), ('system', 'called'), ('called', 'RECIT'), ('RECIT', '['), ('[', '90'), ('90', ']'), (']', '['), ('[', '91'), ('91', ']'), (']', '['), ('[', '92'), ('92', ']'), (']', '['), ('[', '93'), ('93', ']'), (']', 'developed'), ('developed', 'using'), ('using', 'method'), ('method', 'called')]

>> Trigrams are: 
 [('NLP', 'system', 'called'), ('system', 'called', 'RECIT'), ('called', 'RECIT', '['), ('RECIT', '[', '90'), ('[', '90', ']'), ('90', ']', '['), (']', '[', '91'), ('[', '91', ']'), ('91', ']', '['), (']', '[', '92'), ('[', '92', ']'), ('92', ']', '['), (']', '[', '93'), ('[', '93', ']'), ('93', ']', 'developed'), (']', 'developed', 'using'), ('developed', 'using', 'method'), ('using', 'method', 'called')]

>> POS Tags are: 
 [('NLP', 'NNP'), ('system', 'NN'), ('called', 'VBD'), ('RECIT', 'NNP'), ('[', 'NNP'), ('90', 'CD'), (']', 'NNP'), ('[', 'VBD'), ('91', 'CD'), (']', 'NNP'), ('[', 'VBD'), ('92', 'CD'), (']', 'NNP'), ('[', 'VBD'), ('93', 'CD'), (']', 'NNP'), ('developed', 'VBD'), ('using', 'VBG'), ('method', 'NN'), ('called', 'VBD')]

>> Noun Phrases are: 
 ['NLP system', 'RECIT [', ']', ']', ']', ']', 'method']

>> Named Entities are: 
 [('ORGANIZATION', 'RECIT')] 

>> Stemming using Porter Stemmer: 
 [('NLP', 'nlp'), ('system', 'system'), ('called', 'call'), ('RECIT', 'recit'), ('[', '['), ('90', '90'), (']', ']'), ('[', '['), ('91', '91'), (']', ']'), ('[', '['), ('92', '92'), (']', ']'), ('[', '['), ('93', '93'), (']', ']'), ('developed', 'develop'), ('using', 'use'), ('method', 'method'), ('called', 'call')]

>> Stemming using Snowball Stemmer: 
 [('NLP', 'nlp'), ('system', 'system'), ('called', 'call'), ('RECIT', 'recit'), ('[', '['), ('90', '90'), (']', ']'), ('[', '['), ('91', '91'), (']', ']'), ('[', '['), ('92', '92'), (']', ']'), ('[', '['), ('93', '93'), (']', ']'), ('developed', 'develop'), ('using', 'use'), ('method', 'method'), ('called', 'call')]

>> Lemmatization: 
 [('NLP', 'NLP'), ('system', 'system'), ('called', 'called'), ('RECIT', 'RECIT'), ('[', '['), ('90', '90'), (']', ']'), ('[', '['), ('91', '91'), (']', ']'), ('[', '['), ('92', '92'), (']', ']'), ('[', '['), ('93', '93'), (']', ']'), ('developed', 'developed'), ('using', 'using'), ('method', 'method'), ('called', 'called')]



========================================== PARAGRAPH 445 ===========================================

Proximity Processing [94]. It’s task was to implement a robust and multilingual system able  

------------------- Sentence 1 -------------------

Proximity Processing [94].

>> Tokens are: 
 ['Proximity', 'Processing', '[', '94', ']', '.']

>> Bigrams are: 
 [('Proximity', 'Processing'), ('Processing', '['), ('[', '94'), ('94', ']'), (']', '.')]

>> Trigrams are: 
 [('Proximity', 'Processing', '['), ('Processing', '[', '94'), ('[', '94', ']'), ('94', ']', '.')]

>> POS Tags are: 
 [('Proximity', 'NN'), ('Processing', 'NNP'), ('[', 'VBZ'), ('94', 'CD'), (']', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Proximity Processing', ']']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Proximity', 'proxim'), ('Processing', 'process'), ('[', '['), ('94', '94'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Proximity', 'proxim'), ('Processing', 'process'), ('[', '['), ('94', '94'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('Proximity', 'Proximity'), ('Processing', 'Processing'), ('[', '['), ('94', '94'), (']', ']'), ('.', '.')]


------------------- Sentence 2 -------------------

It’s task was to implement a robust and multilingual system able

>> Tokens are: 
 ['It', '’', 'task', 'implement', 'robust', 'multilingual', 'system', 'able']

>> Bigrams are: 
 [('It', '’'), ('’', 'task'), ('task', 'implement'), ('implement', 'robust'), ('robust', 'multilingual'), ('multilingual', 'system'), ('system', 'able')]

>> Trigrams are: 
 [('It', '’', 'task'), ('’', 'task', 'implement'), ('task', 'implement', 'robust'), ('implement', 'robust', 'multilingual'), ('robust', 'multilingual', 'system'), ('multilingual', 'system', 'able')]

>> POS Tags are: 
 [('It', 'PRP'), ('’', 'VBZ'), ('task', 'JJ'), ('implement', 'NN'), ('robust', 'JJ'), ('multilingual', 'JJ'), ('system', 'NN'), ('able', 'JJ')]

>> Noun Phrases are: 
 ['task implement', 'robust multilingual system']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('It', 'it'), ('’', '’'), ('task', 'task'), ('implement', 'implement'), ('robust', 'robust'), ('multilingual', 'multilingu'), ('system', 'system'), ('able', 'abl')]

>> Stemming using Snowball Stemmer: 
 [('It', 'it'), ('’', '’'), ('task', 'task'), ('implement', 'implement'), ('robust', 'robust'), ('multilingual', 'multilingu'), ('system', 'system'), ('able', 'abl')]

>> Lemmatization: 
 [('It', 'It'), ('’', '’'), ('task', 'task'), ('implement', 'implement'), ('robust', 'robust'), ('multilingual', 'multilingual'), ('system', 'system'), ('able', 'able')]



========================================== PARAGRAPH 446 ===========================================

to analyze/comprehend medical sentences, and to preserve a knowledge of free text into a  

------------------- Sentence 1 -------------------

to analyze/comprehend medical sentences, and to preserve a knowledge of free text into a

>> Tokens are: 
 ['analyze/comprehend', 'medical', 'sentences', ',', 'preserve', 'knowledge', 'free', 'text']

>> Bigrams are: 
 [('analyze/comprehend', 'medical'), ('medical', 'sentences'), ('sentences', ','), (',', 'preserve'), ('preserve', 'knowledge'), ('knowledge', 'free'), ('free', 'text')]

>> Trigrams are: 
 [('analyze/comprehend', 'medical', 'sentences'), ('medical', 'sentences', ','), ('sentences', ',', 'preserve'), (',', 'preserve', 'knowledge'), ('preserve', 'knowledge', 'free'), ('knowledge', 'free', 'text')]

>> POS Tags are: 
 [('analyze/comprehend', 'RB'), ('medical', 'JJ'), ('sentences', 'NNS'), (',', ','), ('preserve', 'VB'), ('knowledge', 'NNP'), ('free', 'JJ'), ('text', 'NN')]

>> Noun Phrases are: 
 ['medical sentences', 'knowledge', 'free text']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('analyze/comprehend', 'analyze/comprehend'), ('medical', 'medic'), ('sentences', 'sentenc'), (',', ','), ('preserve', 'preserv'), ('knowledge', 'knowledg'), ('free', 'free'), ('text', 'text')]

>> Stemming using Snowball Stemmer: 
 [('analyze/comprehend', 'analyze/comprehend'), ('medical', 'medic'), ('sentences', 'sentenc'), (',', ','), ('preserve', 'preserv'), ('knowledge', 'knowledg'), ('free', 'free'), ('text', 'text')]

>> Lemmatization: 
 [('analyze/comprehend', 'analyze/comprehend'), ('medical', 'medical'), ('sentences', 'sentence'), (',', ','), ('preserve', 'preserve'), ('knowledge', 'knowledge'), ('free', 'free'), ('text', 'text')]



========================================== PARAGRAPH 447 ===========================================

language independent knowledge representation [95][96]. The Columbia university of New  

------------------- Sentence 1 -------------------

language independent knowledge representation [95][96].

>> Tokens are: 
 ['language', 'independent', 'knowledge', 'representation', '[', '95', ']', '[', '96', ']', '.']

>> Bigrams are: 
 [('language', 'independent'), ('independent', 'knowledge'), ('knowledge', 'representation'), ('representation', '['), ('[', '95'), ('95', ']'), (']', '['), ('[', '96'), ('96', ']'), (']', '.')]

>> Trigrams are: 
 [('language', 'independent', 'knowledge'), ('independent', 'knowledge', 'representation'), ('knowledge', 'representation', '['), ('representation', '[', '95'), ('[', '95', ']'), ('95', ']', '['), (']', '[', '96'), ('[', '96', ']'), ('96', ']', '.')]

>> POS Tags are: 
 [('language', 'NN'), ('independent', 'JJ'), ('knowledge', 'NN'), ('representation', 'NN'), ('[', 'VBD'), ('95', 'CD'), (']', 'NNP'), ('[', 'VBD'), ('96', 'CD'), (']', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['language', 'independent knowledge representation', ']', ']']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('language', 'languag'), ('independent', 'independ'), ('knowledge', 'knowledg'), ('representation', 'represent'), ('[', '['), ('95', '95'), (']', ']'), ('[', '['), ('96', '96'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('language', 'languag'), ('independent', 'independ'), ('knowledge', 'knowledg'), ('representation', 'represent'), ('[', '['), ('95', '95'), (']', ']'), ('[', '['), ('96', '96'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('language', 'language'), ('independent', 'independent'), ('knowledge', 'knowledge'), ('representation', 'representation'), ('[', '['), ('95', '95'), (']', ']'), ('[', '['), ('96', '96'), (']', ']'), ('.', '.')]


------------------- Sentence 2 -------------------

The Columbia university of New

>> Tokens are: 
 ['The', 'Columbia', 'university', 'New']

>> Bigrams are: 
 [('The', 'Columbia'), ('Columbia', 'university'), ('university', 'New')]

>> Trigrams are: 
 [('The', 'Columbia', 'university'), ('Columbia', 'university', 'New')]

>> POS Tags are: 
 [('The', 'DT'), ('Columbia', 'NNP'), ('university', 'NN'), ('New', 'NNP')]

>> Noun Phrases are: 
 ['The Columbia university New']

>> Named Entities are: 
 [('ORGANIZATION', 'Columbia'), ('GPE', 'New')] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('Columbia', 'columbia'), ('university', 'univers'), ('New', 'new')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('Columbia', 'columbia'), ('university', 'univers'), ('New', 'new')]

>> Lemmatization: 
 [('The', 'The'), ('Columbia', 'Columbia'), ('university', 'university'), ('New', 'New')]



========================================== PARAGRAPH 448 ===========================================

York has developed an NLP system called MEDLEE (MEDical Language Extraction and  

------------------- Sentence 1 -------------------

York has developed an NLP system called MEDLEE (MEDical Language Extraction and

>> Tokens are: 
 ['York', 'developed', 'NLP', 'system', 'called', 'MEDLEE', '(', 'MEDical', 'Language', 'Extraction']

>> Bigrams are: 
 [('York', 'developed'), ('developed', 'NLP'), ('NLP', 'system'), ('system', 'called'), ('called', 'MEDLEE'), ('MEDLEE', '('), ('(', 'MEDical'), ('MEDical', 'Language'), ('Language', 'Extraction')]

>> Trigrams are: 
 [('York', 'developed', 'NLP'), ('developed', 'NLP', 'system'), ('NLP', 'system', 'called'), ('system', 'called', 'MEDLEE'), ('called', 'MEDLEE', '('), ('MEDLEE', '(', 'MEDical'), ('(', 'MEDical', 'Language'), ('MEDical', 'Language', 'Extraction')]

>> POS Tags are: 
 [('York', 'NNP'), ('developed', 'VBD'), ('NLP', 'NNP'), ('system', 'NN'), ('called', 'VBN'), ('MEDLEE', 'NNP'), ('(', '('), ('MEDical', 'NNP'), ('Language', 'NNP'), ('Extraction', 'NN')]

>> Noun Phrases are: 
 ['York', 'NLP system', 'MEDLEE', 'MEDical Language Extraction']

>> Named Entities are: 
 [('PERSON', 'York'), ('ORGANIZATION', 'NLP'), ('ORGANIZATION', 'MEDLEE'), ('ORGANIZATION', 'MEDical Language Extraction')] 

>> Stemming using Porter Stemmer: 
 [('York', 'york'), ('developed', 'develop'), ('NLP', 'nlp'), ('system', 'system'), ('called', 'call'), ('MEDLEE', 'medle'), ('(', '('), ('MEDical', 'medic'), ('Language', 'languag'), ('Extraction', 'extract')]

>> Stemming using Snowball Stemmer: 
 [('York', 'york'), ('developed', 'develop'), ('NLP', 'nlp'), ('system', 'system'), ('called', 'call'), ('MEDLEE', 'medle'), ('(', '('), ('MEDical', 'medic'), ('Language', 'languag'), ('Extraction', 'extract')]

>> Lemmatization: 
 [('York', 'York'), ('developed', 'developed'), ('NLP', 'NLP'), ('system', 'system'), ('called', 'called'), ('MEDLEE', 'MEDLEE'), ('(', '('), ('MEDical', 'MEDical'), ('Language', 'Language'), ('Extraction', 'Extraction')]



========================================== PARAGRAPH 449 ===========================================

Encoding System) that identifies clinical information in narrative reports and transforms the  

------------------- Sentence 1 -------------------

Encoding System) that identifies clinical information in narrative reports and transforms the

>> Tokens are: 
 ['Encoding', 'System', ')', 'identifies', 'clinical', 'information', 'narrative', 'reports', 'transforms']

>> Bigrams are: 
 [('Encoding', 'System'), ('System', ')'), (')', 'identifies'), ('identifies', 'clinical'), ('clinical', 'information'), ('information', 'narrative'), ('narrative', 'reports'), ('reports', 'transforms')]

>> Trigrams are: 
 [('Encoding', 'System', ')'), ('System', ')', 'identifies'), (')', 'identifies', 'clinical'), ('identifies', 'clinical', 'information'), ('clinical', 'information', 'narrative'), ('information', 'narrative', 'reports'), ('narrative', 'reports', 'transforms')]

>> POS Tags are: 
 [('Encoding', 'VBG'), ('System', 'NNP'), (')', ')'), ('identifies', 'VBZ'), ('clinical', 'JJ'), ('information', 'NN'), ('narrative', 'JJ'), ('reports', 'NNS'), ('transforms', 'NNS')]

>> Noun Phrases are: 
 ['System', 'clinical information', 'narrative reports transforms']

>> Named Entities are: 
 [('GPE', 'System')] 

>> Stemming using Porter Stemmer: 
 [('Encoding', 'encod'), ('System', 'system'), (')', ')'), ('identifies', 'identifi'), ('clinical', 'clinic'), ('information', 'inform'), ('narrative', 'narr'), ('reports', 'report'), ('transforms', 'transform')]

>> Stemming using Snowball Stemmer: 
 [('Encoding', 'encod'), ('System', 'system'), (')', ')'), ('identifies', 'identifi'), ('clinical', 'clinic'), ('information', 'inform'), ('narrative', 'narrat'), ('reports', 'report'), ('transforms', 'transform')]

>> Lemmatization: 
 [('Encoding', 'Encoding'), ('System', 'System'), (')', ')'), ('identifies', 'identifies'), ('clinical', 'clinical'), ('information', 'information'), ('narrative', 'narrative'), ('reports', 'report'), ('transforms', 'transforms')]



========================================== PARAGRAPH 450 ===========================================

textual information into structured representation [97].  

------------------- Sentence 1 -------------------

textual information into structured representation [97].

>> Tokens are: 
 ['textual', 'information', 'structured', 'representation', '[', '97', ']', '.']

>> Bigrams are: 
 [('textual', 'information'), ('information', 'structured'), ('structured', 'representation'), ('representation', '['), ('[', '97'), ('97', ']'), (']', '.')]

>> Trigrams are: 
 [('textual', 'information', 'structured'), ('information', 'structured', 'representation'), ('structured', 'representation', '['), ('representation', '[', '97'), ('[', '97', ']'), ('97', ']', '.')]

>> POS Tags are: 
 [('textual', 'JJ'), ('information', 'NN'), ('structured', 'VBN'), ('representation', 'NN'), ('[', 'VBZ'), ('97', 'CD'), (']', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['textual information', 'representation', ']']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('textual', 'textual'), ('information', 'inform'), ('structured', 'structur'), ('representation', 'represent'), ('[', '['), ('97', '97'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('textual', 'textual'), ('information', 'inform'), ('structured', 'structur'), ('representation', 'represent'), ('[', '['), ('97', '97'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('textual', 'textual'), ('information', 'information'), ('structured', 'structured'), ('representation', 'representation'), ('[', '['), ('97', '97'), (']', ']'), ('.', '.')]



========================================== PARAGRAPH 451 ===========================================

7. Approaches  

------------------- Sentence 1 -------------------

7.

>> Tokens are: 
 ['7', '.']

>> Bigrams are: 
 [('7', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('7', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('7', '7'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('7', '7'), ('.', '.')]

>> Lemmatization: 
 [('7', '7'), ('.', '.')]


------------------- Sentence 2 -------------------

Approaches

>> Tokens are: 
 ['Approaches']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Approaches', 'NNS')]

>> Noun Phrases are: 
 ['Approaches']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Approaches', 'approach')]

>> Stemming using Snowball Stemmer: 
 [('Approaches', 'approach')]

>> Lemmatization: 
 [('Approaches', 'Approaches')]



========================================== PARAGRAPH 452 ===========================================

Rationalist approach or symbolic approach assume that crucial part of the knowledge in the  

------------------- Sentence 1 -------------------

Rationalist approach or symbolic approach assume that crucial part of the knowledge in the

>> Tokens are: 
 ['Rationalist', 'approach', 'symbolic', 'approach', 'assume', 'crucial', 'part', 'knowledge']

>> Bigrams are: 
 [('Rationalist', 'approach'), ('approach', 'symbolic'), ('symbolic', 'approach'), ('approach', 'assume'), ('assume', 'crucial'), ('crucial', 'part'), ('part', 'knowledge')]

>> Trigrams are: 
 [('Rationalist', 'approach', 'symbolic'), ('approach', 'symbolic', 'approach'), ('symbolic', 'approach', 'assume'), ('approach', 'assume', 'crucial'), ('assume', 'crucial', 'part'), ('crucial', 'part', 'knowledge')]

>> POS Tags are: 
 [('Rationalist', 'JJ'), ('approach', 'NN'), ('symbolic', 'JJ'), ('approach', 'NN'), ('assume', 'VBP'), ('crucial', 'JJ'), ('part', 'NN'), ('knowledge', 'NN')]

>> Noun Phrases are: 
 ['Rationalist approach', 'symbolic approach', 'crucial part knowledge']

>> Named Entities are: 
 [('GPE', 'Rationalist')] 

>> Stemming using Porter Stemmer: 
 [('Rationalist', 'rationalist'), ('approach', 'approach'), ('symbolic', 'symbol'), ('approach', 'approach'), ('assume', 'assum'), ('crucial', 'crucial'), ('part', 'part'), ('knowledge', 'knowledg')]

>> Stemming using Snowball Stemmer: 
 [('Rationalist', 'rationalist'), ('approach', 'approach'), ('symbolic', 'symbol'), ('approach', 'approach'), ('assume', 'assum'), ('crucial', 'crucial'), ('part', 'part'), ('knowledge', 'knowledg')]

>> Lemmatization: 
 [('Rationalist', 'Rationalist'), ('approach', 'approach'), ('symbolic', 'symbolic'), ('approach', 'approach'), ('assume', 'assume'), ('crucial', 'crucial'), ('part', 'part'), ('knowledge', 'knowledge')]



========================================== PARAGRAPH 453 ===========================================

human mind is not derived by the sense but is firm in advance, probably by genetic in  

------------------- Sentence 1 -------------------

human mind is not derived by the sense but is firm in advance, probably by genetic in

>> Tokens are: 
 ['human', 'mind', 'derived', 'sense', 'firm', 'advance', ',', 'probably', 'genetic']

>> Bigrams are: 
 [('human', 'mind'), ('mind', 'derived'), ('derived', 'sense'), ('sense', 'firm'), ('firm', 'advance'), ('advance', ','), (',', 'probably'), ('probably', 'genetic')]

>> Trigrams are: 
 [('human', 'mind', 'derived'), ('mind', 'derived', 'sense'), ('derived', 'sense', 'firm'), ('sense', 'firm', 'advance'), ('firm', 'advance', ','), ('advance', ',', 'probably'), (',', 'probably', 'genetic')]

>> POS Tags are: 
 [('human', 'JJ'), ('mind', 'NN'), ('derived', 'VBD'), ('sense', 'JJ'), ('firm', 'NN'), ('advance', 'NN'), (',', ','), ('probably', 'RB'), ('genetic', 'JJ')]

>> Noun Phrases are: 
 ['human mind', 'sense firm advance']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('human', 'human'), ('mind', 'mind'), ('derived', 'deriv'), ('sense', 'sens'), ('firm', 'firm'), ('advance', 'advanc'), (',', ','), ('probably', 'probabl'), ('genetic', 'genet')]

>> Stemming using Snowball Stemmer: 
 [('human', 'human'), ('mind', 'mind'), ('derived', 'deriv'), ('sense', 'sens'), ('firm', 'firm'), ('advance', 'advanc'), (',', ','), ('probably', 'probabl'), ('genetic', 'genet')]

>> Lemmatization: 
 [('human', 'human'), ('mind', 'mind'), ('derived', 'derived'), ('sense', 'sense'), ('firm', 'firm'), ('advance', 'advance'), (',', ','), ('probably', 'probably'), ('genetic', 'genetic')]



========================================== PARAGRAPH 454 ===========================================

heritance. Noam Chomsky was the strongest advocate of this approach. It was trusted that  

------------------- Sentence 1 -------------------

heritance.

>> Tokens are: 
 ['heritance', '.']

>> Bigrams are: 
 [('heritance', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('heritance', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['heritance']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('heritance', 'herit'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('heritance', 'herit'), ('.', '.')]

>> Lemmatization: 
 [('heritance', 'heritance'), ('.', '.')]


------------------- Sentence 2 -------------------

Noam Chomsky was the strongest advocate of this approach.

>> Tokens are: 
 ['Noam', 'Chomsky', 'strongest', 'advocate', 'approach', '.']

>> Bigrams are: 
 [('Noam', 'Chomsky'), ('Chomsky', 'strongest'), ('strongest', 'advocate'), ('advocate', 'approach'), ('approach', '.')]

>> Trigrams are: 
 [('Noam', 'Chomsky', 'strongest'), ('Chomsky', 'strongest', 'advocate'), ('strongest', 'advocate', 'approach'), ('advocate', 'approach', '.')]

>> POS Tags are: 
 [('Noam', 'NNP'), ('Chomsky', 'NNP'), ('strongest', 'JJS'), ('advocate', 'NN'), ('approach', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Noam Chomsky', 'advocate approach']

>> Named Entities are: 
 [('PERSON', 'Noam'), ('PERSON', 'Chomsky')] 

>> Stemming using Porter Stemmer: 
 [('Noam', 'noam'), ('Chomsky', 'chomski'), ('strongest', 'strongest'), ('advocate', 'advoc'), ('approach', 'approach'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Noam', 'noam'), ('Chomsky', 'chomski'), ('strongest', 'strongest'), ('advocate', 'advoc'), ('approach', 'approach'), ('.', '.')]

>> Lemmatization: 
 [('Noam', 'Noam'), ('Chomsky', 'Chomsky'), ('strongest', 'strongest'), ('advocate', 'advocate'), ('approach', 'approach'), ('.', '.')]


------------------- Sentence 3 -------------------

It was trusted that

>> Tokens are: 
 ['It', 'trusted']

>> Bigrams are: 
 [('It', 'trusted')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('It', 'PRP'), ('trusted', 'VBD')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('It', 'it'), ('trusted', 'trust')]

>> Stemming using Snowball Stemmer: 
 [('It', 'it'), ('trusted', 'trust')]

>> Lemmatization: 
 [('It', 'It'), ('trusted', 'trusted')]



========================================== PARAGRAPH 455 ===========================================

machine can be  made to function like human brain by giving some fundamental knowledge  

------------------- Sentence 1 -------------------

machine can be  made to function like human brain by giving some fundamental knowledge

>> Tokens are: 
 ['machine', 'made', 'function', 'like', 'human', 'brain', 'giving', 'fundamental', 'knowledge']

>> Bigrams are: 
 [('machine', 'made'), ('made', 'function'), ('function', 'like'), ('like', 'human'), ('human', 'brain'), ('brain', 'giving'), ('giving', 'fundamental'), ('fundamental', 'knowledge')]

>> Trigrams are: 
 [('machine', 'made', 'function'), ('made', 'function', 'like'), ('function', 'like', 'human'), ('like', 'human', 'brain'), ('human', 'brain', 'giving'), ('brain', 'giving', 'fundamental'), ('giving', 'fundamental', 'knowledge')]

>> POS Tags are: 
 [('machine', 'NN'), ('made', 'VBN'), ('function', 'NN'), ('like', 'IN'), ('human', 'JJ'), ('brain', 'NN'), ('giving', 'VBG'), ('fundamental', 'JJ'), ('knowledge', 'NN')]

>> Noun Phrases are: 
 ['machine', 'function', 'human brain', 'fundamental knowledge']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('machine', 'machin'), ('made', 'made'), ('function', 'function'), ('like', 'like'), ('human', 'human'), ('brain', 'brain'), ('giving', 'give'), ('fundamental', 'fundament'), ('knowledge', 'knowledg')]

>> Stemming using Snowball Stemmer: 
 [('machine', 'machin'), ('made', 'made'), ('function', 'function'), ('like', 'like'), ('human', 'human'), ('brain', 'brain'), ('giving', 'give'), ('fundamental', 'fundament'), ('knowledge', 'knowledg')]

>> Lemmatization: 
 [('machine', 'machine'), ('made', 'made'), ('function', 'function'), ('like', 'like'), ('human', 'human'), ('brain', 'brain'), ('giving', 'giving'), ('fundamental', 'fundamental'), ('knowledge', 'knowledge')]



========================================== PARAGRAPH 456 ===========================================

and reasoning mechanism linguistics  knowledge is directly encoded in rule or other forms of  

------------------- Sentence 1 -------------------

and reasoning mechanism linguistics  knowledge is directly encoded in rule or other forms of

>> Tokens are: 
 ['reasoning', 'mechanism', 'linguistics', 'knowledge', 'directly', 'encoded', 'rule', 'forms']

>> Bigrams are: 
 [('reasoning', 'mechanism'), ('mechanism', 'linguistics'), ('linguistics', 'knowledge'), ('knowledge', 'directly'), ('directly', 'encoded'), ('encoded', 'rule'), ('rule', 'forms')]

>> Trigrams are: 
 [('reasoning', 'mechanism', 'linguistics'), ('mechanism', 'linguistics', 'knowledge'), ('linguistics', 'knowledge', 'directly'), ('knowledge', 'directly', 'encoded'), ('directly', 'encoded', 'rule'), ('encoded', 'rule', 'forms')]

>> POS Tags are: 
 [('reasoning', 'VBG'), ('mechanism', 'NN'), ('linguistics', 'NNS'), ('knowledge', 'VBP'), ('directly', 'RB'), ('encoded', 'VBN'), ('rule', 'NN'), ('forms', 'NNS')]

>> Noun Phrases are: 
 ['mechanism linguistics', 'rule forms']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('reasoning', 'reason'), ('mechanism', 'mechan'), ('linguistics', 'linguist'), ('knowledge', 'knowledg'), ('directly', 'directli'), ('encoded', 'encod'), ('rule', 'rule'), ('forms', 'form')]

>> Stemming using Snowball Stemmer: 
 [('reasoning', 'reason'), ('mechanism', 'mechan'), ('linguistics', 'linguist'), ('knowledge', 'knowledg'), ('directly', 'direct'), ('encoded', 'encod'), ('rule', 'rule'), ('forms', 'form')]

>> Lemmatization: 
 [('reasoning', 'reasoning'), ('mechanism', 'mechanism'), ('linguistics', 'linguistics'), ('knowledge', 'knowledge'), ('directly', 'directly'), ('encoded', 'encoded'), ('rule', 'rule'), ('forms', 'form')]



========================================== PARAGRAPH 457 ===========================================

representation. This helps automatic process of natural languages. [98] Statistical and  

------------------- Sentence 1 -------------------

representation.

>> Tokens are: 
 ['representation', '.']

>> Bigrams are: 
 [('representation', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('representation', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['representation']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('representation', 'represent'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('representation', 'represent'), ('.', '.')]

>> Lemmatization: 
 [('representation', 'representation'), ('.', '.')]


------------------- Sentence 2 -------------------

This helps automatic process of natural languages.

>> Tokens are: 
 ['This', 'helps', 'automatic', 'process', 'natural', 'languages', '.']

>> Bigrams are: 
 [('This', 'helps'), ('helps', 'automatic'), ('automatic', 'process'), ('process', 'natural'), ('natural', 'languages'), ('languages', '.')]

>> Trigrams are: 
 [('This', 'helps', 'automatic'), ('helps', 'automatic', 'process'), ('automatic', 'process', 'natural'), ('process', 'natural', 'languages'), ('natural', 'languages', '.')]

>> POS Tags are: 
 [('This', 'DT'), ('helps', 'VBZ'), ('automatic', 'JJ'), ('process', 'NN'), ('natural', 'JJ'), ('languages', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['automatic process', 'natural languages']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('This', 'thi'), ('helps', 'help'), ('automatic', 'automat'), ('process', 'process'), ('natural', 'natur'), ('languages', 'languag'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('This', 'this'), ('helps', 'help'), ('automatic', 'automat'), ('process', 'process'), ('natural', 'natur'), ('languages', 'languag'), ('.', '.')]

>> Lemmatization: 
 [('This', 'This'), ('helps', 'help'), ('automatic', 'automatic'), ('process', 'process'), ('natural', 'natural'), ('languages', 'language'), ('.', '.')]


------------------- Sentence 3 -------------------

[98] Statistical and

>> Tokens are: 
 ['[', '98', ']', 'Statistical']

>> Bigrams are: 
 [('[', '98'), ('98', ']'), (']', 'Statistical')]

>> Trigrams are: 
 [('[', '98', ']'), ('98', ']', 'Statistical')]

>> POS Tags are: 
 [('[', 'RB'), ('98', 'CD'), (']', 'JJ'), ('Statistical', 'NNP')]

>> Noun Phrases are: 
 ['] Statistical']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('98', '98'), (']', ']'), ('Statistical', 'statist')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('98', '98'), (']', ']'), ('Statistical', 'statist')]

>> Lemmatization: 
 [('[', '['), ('98', '98'), (']', ']'), ('Statistical', 'Statistical')]



========================================== PARAGRAPH 458 ===========================================

machine learning entail evolution of algorithms that allow a program to infer patterns. An  

------------------- Sentence 1 -------------------

machine learning entail evolution of algorithms that allow a program to infer patterns.

>> Tokens are: 
 ['machine', 'learning', 'entail', 'evolution', 'algorithms', 'allow', 'program', 'infer', 'patterns', '.']

>> Bigrams are: 
 [('machine', 'learning'), ('learning', 'entail'), ('entail', 'evolution'), ('evolution', 'algorithms'), ('algorithms', 'allow'), ('allow', 'program'), ('program', 'infer'), ('infer', 'patterns'), ('patterns', '.')]

>> Trigrams are: 
 [('machine', 'learning', 'entail'), ('learning', 'entail', 'evolution'), ('entail', 'evolution', 'algorithms'), ('evolution', 'algorithms', 'allow'), ('algorithms', 'allow', 'program'), ('allow', 'program', 'infer'), ('program', 'infer', 'patterns'), ('infer', 'patterns', '.')]

>> POS Tags are: 
 [('machine', 'NN'), ('learning', 'VBG'), ('entail', 'JJ'), ('evolution', 'NN'), ('algorithms', 'NN'), ('allow', 'JJ'), ('program', 'NN'), ('infer', 'NN'), ('patterns', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['machine', 'entail evolution algorithms', 'allow program infer patterns']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('machine', 'machin'), ('learning', 'learn'), ('entail', 'entail'), ('evolution', 'evolut'), ('algorithms', 'algorithm'), ('allow', 'allow'), ('program', 'program'), ('infer', 'infer'), ('patterns', 'pattern'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('machine', 'machin'), ('learning', 'learn'), ('entail', 'entail'), ('evolution', 'evolut'), ('algorithms', 'algorithm'), ('allow', 'allow'), ('program', 'program'), ('infer', 'infer'), ('patterns', 'pattern'), ('.', '.')]

>> Lemmatization: 
 [('machine', 'machine'), ('learning', 'learning'), ('entail', 'entail'), ('evolution', 'evolution'), ('algorithms', 'algorithm'), ('allow', 'allow'), ('program', 'program'), ('infer', 'infer'), ('patterns', 'pattern'), ('.', '.')]


------------------- Sentence 2 -------------------

An

>> Tokens are: 
 ['An']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('An', 'DT')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('An', 'an')]

>> Stemming using Snowball Stemmer: 
 [('An', 'an')]

>> Lemmatization: 
 [('An', 'An')]



========================================== PARAGRAPH 459 ===========================================

iterative process is used to characterize a given algorithm’s underlying algorithm that are  

------------------- Sentence 1 -------------------

iterative process is used to characterize a given algorithm’s underlying algorithm that are

>> Tokens are: 
 ['iterative', 'process', 'used', 'characterize', 'given', 'algorithm', '’', 'underlying', 'algorithm']

>> Bigrams are: 
 [('iterative', 'process'), ('process', 'used'), ('used', 'characterize'), ('characterize', 'given'), ('given', 'algorithm'), ('algorithm', '’'), ('’', 'underlying'), ('underlying', 'algorithm')]

>> Trigrams are: 
 [('iterative', 'process', 'used'), ('process', 'used', 'characterize'), ('used', 'characterize', 'given'), ('characterize', 'given', 'algorithm'), ('given', 'algorithm', '’'), ('algorithm', '’', 'underlying'), ('’', 'underlying', 'algorithm')]

>> POS Tags are: 
 [('iterative', 'JJ'), ('process', 'NN'), ('used', 'VBN'), ('characterize', 'VB'), ('given', 'VBN'), ('algorithm', 'RP'), ('’', 'JJ'), ('underlying', 'JJ'), ('algorithm', 'NN')]

>> Noun Phrases are: 
 ['iterative process', '’ underlying algorithm']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('iterative', 'iter'), ('process', 'process'), ('used', 'use'), ('characterize', 'character'), ('given', 'given'), ('algorithm', 'algorithm'), ('’', '’'), ('underlying', 'underli'), ('algorithm', 'algorithm')]

>> Stemming using Snowball Stemmer: 
 [('iterative', 'iter'), ('process', 'process'), ('used', 'use'), ('characterize', 'character'), ('given', 'given'), ('algorithm', 'algorithm'), ('’', '’'), ('underlying', 'under'), ('algorithm', 'algorithm')]

>> Lemmatization: 
 [('iterative', 'iterative'), ('process', 'process'), ('used', 'used'), ('characterize', 'characterize'), ('given', 'given'), ('algorithm', 'algorithm'), ('’', '’'), ('underlying', 'underlying'), ('algorithm', 'algorithm')]



========================================== PARAGRAPH 460 ===========================================

optimised by a numerical measure that characterize numerical parameters and learning phase.  

------------------- Sentence 1 -------------------

optimised by a numerical measure that characterize numerical parameters and learning phase.

>> Tokens are: 
 ['optimised', 'numerical', 'measure', 'characterize', 'numerical', 'parameters', 'learning', 'phase', '.']

>> Bigrams are: 
 [('optimised', 'numerical'), ('numerical', 'measure'), ('measure', 'characterize'), ('characterize', 'numerical'), ('numerical', 'parameters'), ('parameters', 'learning'), ('learning', 'phase'), ('phase', '.')]

>> Trigrams are: 
 [('optimised', 'numerical', 'measure'), ('numerical', 'measure', 'characterize'), ('measure', 'characterize', 'numerical'), ('characterize', 'numerical', 'parameters'), ('numerical', 'parameters', 'learning'), ('parameters', 'learning', 'phase'), ('learning', 'phase', '.')]

>> POS Tags are: 
 [('optimised', 'VBN'), ('numerical', 'JJ'), ('measure', 'NN'), ('characterize', 'VB'), ('numerical', 'JJ'), ('parameters', 'NNS'), ('learning', 'VBG'), ('phase', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['numerical measure', 'numerical parameters', 'phase']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('optimised', 'optimis'), ('numerical', 'numer'), ('measure', 'measur'), ('characterize', 'character'), ('numerical', 'numer'), ('parameters', 'paramet'), ('learning', 'learn'), ('phase', 'phase'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('optimised', 'optimis'), ('numerical', 'numer'), ('measure', 'measur'), ('characterize', 'character'), ('numerical', 'numer'), ('parameters', 'paramet'), ('learning', 'learn'), ('phase', 'phase'), ('.', '.')]

>> Lemmatization: 
 [('optimised', 'optimised'), ('numerical', 'numerical'), ('measure', 'measure'), ('characterize', 'characterize'), ('numerical', 'numerical'), ('parameters', 'parameter'), ('learning', 'learning'), ('phase', 'phase'), ('.', '.')]



========================================== PARAGRAPH 461 ===========================================

Machine-learning models can be predominantly categorized as either generative or  

------------------- Sentence 1 -------------------

Machine-learning models can be predominantly categorized as either generative or

>> Tokens are: 
 ['Machine-learning', 'models', 'predominantly', 'categorized', 'either', 'generative']

>> Bigrams are: 
 [('Machine-learning', 'models'), ('models', 'predominantly'), ('predominantly', 'categorized'), ('categorized', 'either'), ('either', 'generative')]

>> Trigrams are: 
 [('Machine-learning', 'models', 'predominantly'), ('models', 'predominantly', 'categorized'), ('predominantly', 'categorized', 'either'), ('categorized', 'either', 'generative')]

>> POS Tags are: 
 [('Machine-learning', 'JJ'), ('models', 'NNS'), ('predominantly', 'RB'), ('categorized', 'VBD'), ('either', 'CC'), ('generative', 'JJ')]

>> Noun Phrases are: 
 ['Machine-learning models']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Machine-learning', 'machine-learn'), ('models', 'model'), ('predominantly', 'predominantli'), ('categorized', 'categor'), ('either', 'either'), ('generative', 'gener')]

>> Stemming using Snowball Stemmer: 
 [('Machine-learning', 'machine-learn'), ('models', 'model'), ('predominantly', 'predomin'), ('categorized', 'categor'), ('either', 'either'), ('generative', 'generat')]

>> Lemmatization: 
 [('Machine-learning', 'Machine-learning'), ('models', 'model'), ('predominantly', 'predominantly'), ('categorized', 'categorized'), ('either', 'either'), ('generative', 'generative')]



========================================== PARAGRAPH 462 ===========================================

discriminative. Generative methods can generate synthetic data because of which they create  

------------------- Sentence 1 -------------------

discriminative.

>> Tokens are: 
 ['discriminative', '.']

>> Bigrams are: 
 [('discriminative', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('discriminative', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['discriminative']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('discriminative', 'discrimin'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('discriminative', 'discrimin'), ('.', '.')]

>> Lemmatization: 
 [('discriminative', 'discriminative'), ('.', '.')]


------------------- Sentence 2 -------------------

Generative methods can generate synthetic data because of which they create

>> Tokens are: 
 ['Generative', 'methods', 'generate', 'synthetic', 'data', 'create']

>> Bigrams are: 
 [('Generative', 'methods'), ('methods', 'generate'), ('generate', 'synthetic'), ('synthetic', 'data'), ('data', 'create')]

>> Trigrams are: 
 [('Generative', 'methods', 'generate'), ('methods', 'generate', 'synthetic'), ('generate', 'synthetic', 'data'), ('synthetic', 'data', 'create')]

>> POS Tags are: 
 [('Generative', 'JJ'), ('methods', 'NNS'), ('generate', 'VBP'), ('synthetic', 'JJ'), ('data', 'NNS'), ('create', 'NN')]

>> Noun Phrases are: 
 ['Generative methods', 'synthetic data create']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Generative', 'gener'), ('methods', 'method'), ('generate', 'gener'), ('synthetic', 'synthet'), ('data', 'data'), ('create', 'creat')]

>> Stemming using Snowball Stemmer: 
 [('Generative', 'generat'), ('methods', 'method'), ('generate', 'generat'), ('synthetic', 'synthet'), ('data', 'data'), ('create', 'creat')]

>> Lemmatization: 
 [('Generative', 'Generative'), ('methods', 'method'), ('generate', 'generate'), ('synthetic', 'synthetic'), ('data', 'data'), ('create', 'create')]



========================================== PARAGRAPH 463 ===========================================

rich models of probability distributions. Discriminative methods are more functional and  

------------------- Sentence 1 -------------------

rich models of probability distributions.

>> Tokens are: 
 ['rich', 'models', 'probability', 'distributions', '.']

>> Bigrams are: 
 [('rich', 'models'), ('models', 'probability'), ('probability', 'distributions'), ('distributions', '.')]

>> Trigrams are: 
 [('rich', 'models', 'probability'), ('models', 'probability', 'distributions'), ('probability', 'distributions', '.')]

>> POS Tags are: 
 [('rich', 'JJ'), ('models', 'NNS'), ('probability', 'NN'), ('distributions', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['rich models probability distributions']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('rich', 'rich'), ('models', 'model'), ('probability', 'probabl'), ('distributions', 'distribut'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('rich', 'rich'), ('models', 'model'), ('probability', 'probabl'), ('distributions', 'distribut'), ('.', '.')]

>> Lemmatization: 
 [('rich', 'rich'), ('models', 'model'), ('probability', 'probability'), ('distributions', 'distribution'), ('.', '.')]


------------------- Sentence 2 -------------------

Discriminative methods are more functional and

>> Tokens are: 
 ['Discriminative', 'methods', 'functional']

>> Bigrams are: 
 [('Discriminative', 'methods'), ('methods', 'functional')]

>> Trigrams are: 
 [('Discriminative', 'methods', 'functional')]

>> POS Tags are: 
 [('Discriminative', 'JJ'), ('methods', 'NNS'), ('functional', 'JJ')]

>> Noun Phrases are: 
 ['Discriminative methods']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Discriminative', 'discrimin'), ('methods', 'method'), ('functional', 'function')]

>> Stemming using Snowball Stemmer: 
 [('Discriminative', 'discrimin'), ('methods', 'method'), ('functional', 'function')]

>> Lemmatization: 
 [('Discriminative', 'Discriminative'), ('methods', 'method'), ('functional', 'functional')]



========================================== PARAGRAPH 464 ===========================================

have right estimating posterior probabilities and are based on observations.   

------------------- Sentence 1 -------------------

have right estimating posterior probabilities and are based on observations.

>> Tokens are: 
 ['right', 'estimating', 'posterior', 'probabilities', 'based', 'observations', '.']

>> Bigrams are: 
 [('right', 'estimating'), ('estimating', 'posterior'), ('posterior', 'probabilities'), ('probabilities', 'based'), ('based', 'observations'), ('observations', '.')]

>> Trigrams are: 
 [('right', 'estimating', 'posterior'), ('estimating', 'posterior', 'probabilities'), ('posterior', 'probabilities', 'based'), ('probabilities', 'based', 'observations'), ('based', 'observations', '.')]

>> POS Tags are: 
 [('right', 'RB'), ('estimating', 'VBG'), ('posterior', 'JJ'), ('probabilities', 'NNS'), ('based', 'VBN'), ('observations', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['posterior probabilities', 'observations']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('right', 'right'), ('estimating', 'estim'), ('posterior', 'posterior'), ('probabilities', 'probabl'), ('based', 'base'), ('observations', 'observ'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('right', 'right'), ('estimating', 'estim'), ('posterior', 'posterior'), ('probabilities', 'probabl'), ('based', 'base'), ('observations', 'observ'), ('.', '.')]

>> Lemmatization: 
 [('right', 'right'), ('estimating', 'estimating'), ('posterior', 'posterior'), ('probabilities', 'probability'), ('based', 'based'), ('observations', 'observation'), ('.', '.')]



========================================== PARAGRAPH 465 ===========================================

Srihari [99] explains the different generative models as one with a resemblance that is used to  

------------------- Sentence 1 -------------------

Srihari [99] explains the different generative models as one with a resemblance that is used to

>> Tokens are: 
 ['Srihari', '[', '99', ']', 'explains', 'different', 'generative', 'models', 'one', 'resemblance', 'used']

>> Bigrams are: 
 [('Srihari', '['), ('[', '99'), ('99', ']'), (']', 'explains'), ('explains', 'different'), ('different', 'generative'), ('generative', 'models'), ('models', 'one'), ('one', 'resemblance'), ('resemblance', 'used')]

>> Trigrams are: 
 [('Srihari', '[', '99'), ('[', '99', ']'), ('99', ']', 'explains'), (']', 'explains', 'different'), ('explains', 'different', 'generative'), ('different', 'generative', 'models'), ('generative', 'models', 'one'), ('models', 'one', 'resemblance'), ('one', 'resemblance', 'used')]

>> POS Tags are: 
 [('Srihari', 'NNP'), ('[', 'VBD'), ('99', 'CD'), (']', 'JJ'), ('explains', 'NNS'), ('different', 'JJ'), ('generative', 'JJ'), ('models', 'NNS'), ('one', 'CD'), ('resemblance', 'NN'), ('used', 'VBN')]

>> Noun Phrases are: 
 ['Srihari', '] explains', 'different generative models', 'resemblance']

>> Named Entities are: 
 [('PERSON', 'Srihari')] 

>> Stemming using Porter Stemmer: 
 [('Srihari', 'srihari'), ('[', '['), ('99', '99'), (']', ']'), ('explains', 'explain'), ('different', 'differ'), ('generative', 'gener'), ('models', 'model'), ('one', 'one'), ('resemblance', 'resembl'), ('used', 'use')]

>> Stemming using Snowball Stemmer: 
 [('Srihari', 'srihari'), ('[', '['), ('99', '99'), (']', ']'), ('explains', 'explain'), ('different', 'differ'), ('generative', 'generat'), ('models', 'model'), ('one', 'one'), ('resemblance', 'resembl'), ('used', 'use')]

>> Lemmatization: 
 [('Srihari', 'Srihari'), ('[', '['), ('99', '99'), (']', ']'), ('explains', 'explains'), ('different', 'different'), ('generative', 'generative'), ('models', 'model'), ('one', 'one'), ('resemblance', 'resemblance'), ('used', 'used')]



========================================== PARAGRAPH 466 ===========================================

spot an unknown speaker’s language and would bid the deep knowledge of numerous  

------------------- Sentence 1 -------------------

spot an unknown speaker’s language and would bid the deep knowledge of numerous

>> Tokens are: 
 ['spot', 'unknown', 'speaker', '’', 'language', 'would', 'bid', 'deep', 'knowledge', 'numerous']

>> Bigrams are: 
 [('spot', 'unknown'), ('unknown', 'speaker'), ('speaker', '’'), ('’', 'language'), ('language', 'would'), ('would', 'bid'), ('bid', 'deep'), ('deep', 'knowledge'), ('knowledge', 'numerous')]

>> Trigrams are: 
 [('spot', 'unknown', 'speaker'), ('unknown', 'speaker', '’'), ('speaker', '’', 'language'), ('’', 'language', 'would'), ('language', 'would', 'bid'), ('would', 'bid', 'deep'), ('bid', 'deep', 'knowledge'), ('deep', 'knowledge', 'numerous')]

>> POS Tags are: 
 [('spot', 'NN'), ('unknown', 'JJ'), ('speaker', 'NN'), ('’', 'NNP'), ('language', 'NN'), ('would', 'MD'), ('bid', 'VB'), ('deep', 'JJ'), ('knowledge', 'NN'), ('numerous', 'JJ')]

>> Noun Phrases are: 
 ['spot', 'unknown speaker ’ language', 'deep knowledge']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('spot', 'spot'), ('unknown', 'unknown'), ('speaker', 'speaker'), ('’', '’'), ('language', 'languag'), ('would', 'would'), ('bid', 'bid'), ('deep', 'deep'), ('knowledge', 'knowledg'), ('numerous', 'numer')]

>> Stemming using Snowball Stemmer: 
 [('spot', 'spot'), ('unknown', 'unknown'), ('speaker', 'speaker'), ('’', '’'), ('language', 'languag'), ('would', 'would'), ('bid', 'bid'), ('deep', 'deep'), ('knowledge', 'knowledg'), ('numerous', 'numer')]

>> Lemmatization: 
 [('spot', 'spot'), ('unknown', 'unknown'), ('speaker', 'speaker'), ('’', '’'), ('language', 'language'), ('would', 'would'), ('bid', 'bid'), ('deep', 'deep'), ('knowledge', 'knowledge'), ('numerous', 'numerous')]



========================================== PARAGRAPH 467 ===========================================

language to perform the match. Whereas discriminative methods rely on a less knowledge- 

------------------- Sentence 1 -------------------

language to perform the match.

>> Tokens are: 
 ['language', 'perform', 'match', '.']

>> Bigrams are: 
 [('language', 'perform'), ('perform', 'match'), ('match', '.')]

>> Trigrams are: 
 [('language', 'perform', 'match'), ('perform', 'match', '.')]

>> POS Tags are: 
 [('language', 'NN'), ('perform', 'NN'), ('match', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['language perform match']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('language', 'languag'), ('perform', 'perform'), ('match', 'match'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('language', 'languag'), ('perform', 'perform'), ('match', 'match'), ('.', '.')]

>> Lemmatization: 
 [('language', 'language'), ('perform', 'perform'), ('match', 'match'), ('.', '.')]


------------------- Sentence 2 -------------------

Whereas discriminative methods rely on a less knowledge-

>> Tokens are: 
 ['Whereas', 'discriminative', 'methods', 'rely', 'less', 'knowledge-']

>> Bigrams are: 
 [('Whereas', 'discriminative'), ('discriminative', 'methods'), ('methods', 'rely'), ('rely', 'less'), ('less', 'knowledge-')]

>> Trigrams are: 
 [('Whereas', 'discriminative', 'methods'), ('discriminative', 'methods', 'rely'), ('methods', 'rely', 'less'), ('rely', 'less', 'knowledge-')]

>> POS Tags are: 
 [('Whereas', 'NNP'), ('discriminative', 'JJ'), ('methods', 'NNS'), ('rely', 'RB'), ('less', 'RBR'), ('knowledge-', 'JJ')]

>> Noun Phrases are: 
 ['Whereas', 'discriminative methods']

>> Named Entities are: 
 [('GPE', 'Whereas')] 

>> Stemming using Porter Stemmer: 
 [('Whereas', 'wherea'), ('discriminative', 'discrimin'), ('methods', 'method'), ('rely', 'reli'), ('less', 'less'), ('knowledge-', 'knowledge-')]

>> Stemming using Snowball Stemmer: 
 [('Whereas', 'wherea'), ('discriminative', 'discrimin'), ('methods', 'method'), ('rely', 'reli'), ('less', 'less'), ('knowledge-', 'knowledge-')]

>> Lemmatization: 
 [('Whereas', 'Whereas'), ('discriminative', 'discriminative'), ('methods', 'method'), ('rely', 'rely'), ('less', 'le'), ('knowledge-', 'knowledge-')]



========================================== PARAGRAPH 468 ===========================================

intensive approach and using distinction between language.  Whereas generative models, can  

------------------- Sentence 1 -------------------

intensive approach and using distinction between language.

>> Tokens are: 
 ['intensive', 'approach', 'using', 'distinction', 'language', '.']

>> Bigrams are: 
 [('intensive', 'approach'), ('approach', 'using'), ('using', 'distinction'), ('distinction', 'language'), ('language', '.')]

>> Trigrams are: 
 [('intensive', 'approach', 'using'), ('approach', 'using', 'distinction'), ('using', 'distinction', 'language'), ('distinction', 'language', '.')]

>> POS Tags are: 
 [('intensive', 'JJ'), ('approach', 'NN'), ('using', 'VBG'), ('distinction', 'NN'), ('language', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['intensive approach', 'distinction language']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('intensive', 'intens'), ('approach', 'approach'), ('using', 'use'), ('distinction', 'distinct'), ('language', 'languag'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('intensive', 'intens'), ('approach', 'approach'), ('using', 'use'), ('distinction', 'distinct'), ('language', 'languag'), ('.', '.')]

>> Lemmatization: 
 [('intensive', 'intensive'), ('approach', 'approach'), ('using', 'using'), ('distinction', 'distinction'), ('language', 'language'), ('.', '.')]


------------------- Sentence 2 -------------------

Whereas generative models, can

>> Tokens are: 
 ['Whereas', 'generative', 'models', ',']

>> Bigrams are: 
 [('Whereas', 'generative'), ('generative', 'models'), ('models', ',')]

>> Trigrams are: 
 [('Whereas', 'generative', 'models'), ('generative', 'models', ',')]

>> POS Tags are: 
 [('Whereas', 'NNP'), ('generative', 'JJ'), ('models', 'NNS'), (',', ',')]

>> Noun Phrases are: 
 ['Whereas', 'generative models']

>> Named Entities are: 
 [('GPE', 'Whereas')] 

>> Stemming using Porter Stemmer: 
 [('Whereas', 'wherea'), ('generative', 'gener'), ('models', 'model'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('Whereas', 'wherea'), ('generative', 'generat'), ('models', 'model'), (',', ',')]

>> Lemmatization: 
 [('Whereas', 'Whereas'), ('generative', 'generative'), ('models', 'model'), (',', ',')]



========================================== PARAGRAPH 469 ===========================================

become troublesome when many features are used and discriminative models allow use of  

------------------- Sentence 1 -------------------

become troublesome when many features are used and discriminative models allow use of

>> Tokens are: 
 ['become', 'troublesome', 'many', 'features', 'used', 'discriminative', 'models', 'allow', 'use']

>> Bigrams are: 
 [('become', 'troublesome'), ('troublesome', 'many'), ('many', 'features'), ('features', 'used'), ('used', 'discriminative'), ('discriminative', 'models'), ('models', 'allow'), ('allow', 'use')]

>> Trigrams are: 
 [('become', 'troublesome', 'many'), ('troublesome', 'many', 'features'), ('many', 'features', 'used'), ('features', 'used', 'discriminative'), ('used', 'discriminative', 'models'), ('discriminative', 'models', 'allow'), ('models', 'allow', 'use')]

>> POS Tags are: 
 [('become', 'VB'), ('troublesome', 'JJ'), ('many', 'JJ'), ('features', 'NNS'), ('used', 'VBD'), ('discriminative', 'JJ'), ('models', 'NNS'), ('allow', 'VBP'), ('use', 'NN')]

>> Noun Phrases are: 
 ['troublesome many features', 'discriminative models', 'use']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('become', 'becom'), ('troublesome', 'troublesom'), ('many', 'mani'), ('features', 'featur'), ('used', 'use'), ('discriminative', 'discrimin'), ('models', 'model'), ('allow', 'allow'), ('use', 'use')]

>> Stemming using Snowball Stemmer: 
 [('become', 'becom'), ('troublesome', 'troublesom'), ('many', 'mani'), ('features', 'featur'), ('used', 'use'), ('discriminative', 'discrimin'), ('models', 'model'), ('allow', 'allow'), ('use', 'use')]

>> Lemmatization: 
 [('become', 'become'), ('troublesome', 'troublesome'), ('many', 'many'), ('features', 'feature'), ('used', 'used'), ('discriminative', 'discriminative'), ('models', 'model'), ('allow', 'allow'), ('use', 'use')]



========================================== PARAGRAPH 470 ===========================================

more features. [100] Few of the examples of discriminative methods are Logistic regression  

------------------- Sentence 1 -------------------

more features.

>> Tokens are: 
 ['features', '.']

>> Bigrams are: 
 [('features', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('features', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['features']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('features', 'featur'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('features', 'featur'), ('.', '.')]

>> Lemmatization: 
 [('features', 'feature'), ('.', '.')]


------------------- Sentence 2 -------------------

[100] Few of the examples of discriminative methods are Logistic regression

>> Tokens are: 
 ['[', '100', ']', 'Few', 'examples', 'discriminative', 'methods', 'Logistic', 'regression']

>> Bigrams are: 
 [('[', '100'), ('100', ']'), (']', 'Few'), ('Few', 'examples'), ('examples', 'discriminative'), ('discriminative', 'methods'), ('methods', 'Logistic'), ('Logistic', 'regression')]

>> Trigrams are: 
 [('[', '100', ']'), ('100', ']', 'Few'), (']', 'Few', 'examples'), ('Few', 'examples', 'discriminative'), ('examples', 'discriminative', 'methods'), ('discriminative', 'methods', 'Logistic'), ('methods', 'Logistic', 'regression')]

>> POS Tags are: 
 [('[', 'RB'), ('100', 'CD'), (']', 'JJ'), ('Few', 'JJ'), ('examples', 'NNS'), ('discriminative', 'VBP'), ('methods', 'NNS'), ('Logistic', 'JJ'), ('regression', 'NN')]

>> Noun Phrases are: 
 ['] Few examples', 'methods', 'Logistic regression']

>> Named Entities are: 
 [('ORGANIZATION', 'Logistic')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('100', '100'), (']', ']'), ('Few', 'few'), ('examples', 'exampl'), ('discriminative', 'discrimin'), ('methods', 'method'), ('Logistic', 'logist'), ('regression', 'regress')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('100', '100'), (']', ']'), ('Few', 'few'), ('examples', 'exampl'), ('discriminative', 'discrimin'), ('methods', 'method'), ('Logistic', 'logist'), ('regression', 'regress')]

>> Lemmatization: 
 [('[', '['), ('100', '100'), (']', ']'), ('Few', 'Few'), ('examples', 'example'), ('discriminative', 'discriminative'), ('methods', 'method'), ('Logistic', 'Logistic'), ('regression', 'regression')]



========================================== PARAGRAPH 471 ===========================================

and conditional random fields (CRFs), generative methods are Naive Bayes classifiers and  

------------------- Sentence 1 -------------------

and conditional random fields (CRFs), generative methods are Naive Bayes classifiers and

>> Tokens are: 
 ['conditional', 'random', 'fields', '(', 'CRFs', ')', ',', 'generative', 'methods', 'Naive', 'Bayes', 'classifiers']

>> Bigrams are: 
 [('conditional', 'random'), ('random', 'fields'), ('fields', '('), ('(', 'CRFs'), ('CRFs', ')'), (')', ','), (',', 'generative'), ('generative', 'methods'), ('methods', 'Naive'), ('Naive', 'Bayes'), ('Bayes', 'classifiers')]

>> Trigrams are: 
 [('conditional', 'random', 'fields'), ('random', 'fields', '('), ('fields', '(', 'CRFs'), ('(', 'CRFs', ')'), ('CRFs', ')', ','), (')', ',', 'generative'), (',', 'generative', 'methods'), ('generative', 'methods', 'Naive'), ('methods', 'Naive', 'Bayes'), ('Naive', 'Bayes', 'classifiers')]

>> POS Tags are: 
 [('conditional', 'JJ'), ('random', 'NN'), ('fields', 'NNS'), ('(', '('), ('CRFs', 'NNP'), (')', ')'), (',', ','), ('generative', 'JJ'), ('methods', 'NNS'), ('Naive', 'JJ'), ('Bayes', 'NNP'), ('classifiers', 'NNS')]

>> Noun Phrases are: 
 ['conditional random fields', 'CRFs', 'generative methods', 'Naive Bayes classifiers']

>> Named Entities are: 
 [('ORGANIZATION', 'CRFs'), ('PERSON', 'Naive Bayes')] 

>> Stemming using Porter Stemmer: 
 [('conditional', 'condit'), ('random', 'random'), ('fields', 'field'), ('(', '('), ('CRFs', 'crf'), (')', ')'), (',', ','), ('generative', 'gener'), ('methods', 'method'), ('Naive', 'naiv'), ('Bayes', 'bay'), ('classifiers', 'classifi')]

>> Stemming using Snowball Stemmer: 
 [('conditional', 'condit'), ('random', 'random'), ('fields', 'field'), ('(', '('), ('CRFs', 'crfs'), (')', ')'), (',', ','), ('generative', 'generat'), ('methods', 'method'), ('Naive', 'naiv'), ('Bayes', 'bay'), ('classifiers', 'classifi')]

>> Lemmatization: 
 [('conditional', 'conditional'), ('random', 'random'), ('fields', 'field'), ('(', '('), ('CRFs', 'CRFs'), (')', ')'), (',', ','), ('generative', 'generative'), ('methods', 'method'), ('Naive', 'Naive'), ('Bayes', 'Bayes'), ('classifiers', 'classifier')]



========================================== PARAGRAPH 472 ===========================================

hidden Markov models (HMMs).  

------------------- Sentence 1 -------------------

hidden Markov models (HMMs).

>> Tokens are: 
 ['hidden', 'Markov', 'models', '(', 'HMMs', ')', '.']

>> Bigrams are: 
 [('hidden', 'Markov'), ('Markov', 'models'), ('models', '('), ('(', 'HMMs'), ('HMMs', ')'), (')', '.')]

>> Trigrams are: 
 [('hidden', 'Markov', 'models'), ('Markov', 'models', '('), ('models', '(', 'HMMs'), ('(', 'HMMs', ')'), ('HMMs', ')', '.')]

>> POS Tags are: 
 [('hidden', 'JJ'), ('Markov', 'NNP'), ('models', 'NNS'), ('(', '('), ('HMMs', 'NNP'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['hidden Markov models', 'HMMs']

>> Named Entities are: 
 [('PERSON', 'Markov'), ('ORGANIZATION', 'HMMs')] 

>> Stemming using Porter Stemmer: 
 [('hidden', 'hidden'), ('Markov', 'markov'), ('models', 'model'), ('(', '('), ('HMMs', 'hmm'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('hidden', 'hidden'), ('Markov', 'markov'), ('models', 'model'), ('(', '('), ('HMMs', 'hmms'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('hidden', 'hidden'), ('Markov', 'Markov'), ('models', 'model'), ('(', '('), ('HMMs', 'HMMs'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 473 ===========================================

7.1 Hidden Markov Model (HMM)  

------------------- Sentence 1 -------------------

7.1 Hidden Markov Model (HMM)

>> Tokens are: 
 ['7.1', 'Hidden', 'Markov', 'Model', '(', 'HMM', ')']

>> Bigrams are: 
 [('7.1', 'Hidden'), ('Hidden', 'Markov'), ('Markov', 'Model'), ('Model', '('), ('(', 'HMM'), ('HMM', ')')]

>> Trigrams are: 
 [('7.1', 'Hidden', 'Markov'), ('Hidden', 'Markov', 'Model'), ('Markov', 'Model', '('), ('Model', '(', 'HMM'), ('(', 'HMM', ')')]

>> POS Tags are: 
 [('7.1', 'CD'), ('Hidden', 'NNP'), ('Markov', 'NNP'), ('Model', 'NNP'), ('(', '('), ('HMM', 'NNP'), (')', ')')]

>> Noun Phrases are: 
 ['Hidden Markov Model', 'HMM']

>> Named Entities are: 
 [('PERSON', 'Hidden Markov Model'), ('ORGANIZATION', 'HMM')] 

>> Stemming using Porter Stemmer: 
 [('7.1', '7.1'), ('Hidden', 'hidden'), ('Markov', 'markov'), ('Model', 'model'), ('(', '('), ('HMM', 'hmm'), (')', ')')]

>> Stemming using Snowball Stemmer: 
 [('7.1', '7.1'), ('Hidden', 'hidden'), ('Markov', 'markov'), ('Model', 'model'), ('(', '('), ('HMM', 'hmm'), (')', ')')]

>> Lemmatization: 
 [('7.1', '7.1'), ('Hidden', 'Hidden'), ('Markov', 'Markov'), ('Model', 'Model'), ('(', '('), ('HMM', 'HMM'), (')', ')')]



========================================== PARAGRAPH 474 ===========================================

An HMM is a system where a shifting takes place between several states, generating feasible  

------------------- Sentence 1 -------------------

An HMM is a system where a shifting takes place between several states, generating feasible

>> Tokens are: 
 ['An', 'HMM', 'system', 'shifting', 'takes', 'place', 'several', 'states', ',', 'generating', 'feasible']

>> Bigrams are: 
 [('An', 'HMM'), ('HMM', 'system'), ('system', 'shifting'), ('shifting', 'takes'), ('takes', 'place'), ('place', 'several'), ('several', 'states'), ('states', ','), (',', 'generating'), ('generating', 'feasible')]

>> Trigrams are: 
 [('An', 'HMM', 'system'), ('HMM', 'system', 'shifting'), ('system', 'shifting', 'takes'), ('shifting', 'takes', 'place'), ('takes', 'place', 'several'), ('place', 'several', 'states'), ('several', 'states', ','), ('states', ',', 'generating'), (',', 'generating', 'feasible')]

>> POS Tags are: 
 [('An', 'DT'), ('HMM', 'NNP'), ('system', 'NN'), ('shifting', 'VBG'), ('takes', 'VBZ'), ('place', 'NN'), ('several', 'JJ'), ('states', 'NNS'), (',', ','), ('generating', 'VBG'), ('feasible', 'JJ')]

>> Noun Phrases are: 
 ['An HMM system', 'place', 'several states']

>> Named Entities are: 
 [('ORGANIZATION', 'HMM')] 

>> Stemming using Porter Stemmer: 
 [('An', 'an'), ('HMM', 'hmm'), ('system', 'system'), ('shifting', 'shift'), ('takes', 'take'), ('place', 'place'), ('several', 'sever'), ('states', 'state'), (',', ','), ('generating', 'gener'), ('feasible', 'feasibl')]

>> Stemming using Snowball Stemmer: 
 [('An', 'an'), ('HMM', 'hmm'), ('system', 'system'), ('shifting', 'shift'), ('takes', 'take'), ('place', 'place'), ('several', 'sever'), ('states', 'state'), (',', ','), ('generating', 'generat'), ('feasible', 'feasibl')]

>> Lemmatization: 
 [('An', 'An'), ('HMM', 'HMM'), ('system', 'system'), ('shifting', 'shifting'), ('takes', 'take'), ('place', 'place'), ('several', 'several'), ('states', 'state'), (',', ','), ('generating', 'generating'), ('feasible', 'feasible')]



========================================== PARAGRAPH 475 ===========================================

output symbols with each switch. The sets of viable states and unique symbols may be large,  

------------------- Sentence 1 -------------------

output symbols with each switch.

>> Tokens are: 
 ['output', 'symbols', 'switch', '.']

>> Bigrams are: 
 [('output', 'symbols'), ('symbols', 'switch'), ('switch', '.')]

>> Trigrams are: 
 [('output', 'symbols', 'switch'), ('symbols', 'switch', '.')]

>> POS Tags are: 
 [('output', 'NN'), ('symbols', 'NNS'), ('switch', 'VBP'), ('.', '.')]

>> Noun Phrases are: 
 ['output symbols']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('output', 'output'), ('symbols', 'symbol'), ('switch', 'switch'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('output', 'output'), ('symbols', 'symbol'), ('switch', 'switch'), ('.', '.')]

>> Lemmatization: 
 [('output', 'output'), ('symbols', 'symbol'), ('switch', 'switch'), ('.', '.')]


------------------- Sentence 2 -------------------

The sets of viable states and unique symbols may be large,

>> Tokens are: 
 ['The', 'sets', 'viable', 'states', 'unique', 'symbols', 'may', 'large', ',']

>> Bigrams are: 
 [('The', 'sets'), ('sets', 'viable'), ('viable', 'states'), ('states', 'unique'), ('unique', 'symbols'), ('symbols', 'may'), ('may', 'large'), ('large', ',')]

>> Trigrams are: 
 [('The', 'sets', 'viable'), ('sets', 'viable', 'states'), ('viable', 'states', 'unique'), ('states', 'unique', 'symbols'), ('unique', 'symbols', 'may'), ('symbols', 'may', 'large'), ('may', 'large', ',')]

>> POS Tags are: 
 [('The', 'DT'), ('sets', 'NNS'), ('viable', 'JJ'), ('states', 'NNS'), ('unique', 'JJ'), ('symbols', 'NNS'), ('may', 'MD'), ('large', 'JJ'), (',', ',')]

>> Noun Phrases are: 
 ['The sets', 'viable states', 'unique symbols']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('sets', 'set'), ('viable', 'viabl'), ('states', 'state'), ('unique', 'uniqu'), ('symbols', 'symbol'), ('may', 'may'), ('large', 'larg'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('sets', 'set'), ('viable', 'viabl'), ('states', 'state'), ('unique', 'uniqu'), ('symbols', 'symbol'), ('may', 'may'), ('large', 'larg'), (',', ',')]

>> Lemmatization: 
 [('The', 'The'), ('sets', 'set'), ('viable', 'viable'), ('states', 'state'), ('unique', 'unique'), ('symbols', 'symbol'), ('may', 'may'), ('large', 'large'), (',', ',')]



========================================== PARAGRAPH 476 ===========================================

but finite and known. We can descry the outputs, but the system’s internals are hidden. Few  

------------------- Sentence 1 -------------------

but finite and known.

>> Tokens are: 
 ['finite', 'known', '.']

>> Bigrams are: 
 [('finite', 'known'), ('known', '.')]

>> Trigrams are: 
 [('finite', 'known', '.')]

>> POS Tags are: 
 [('finite', 'RB'), ('known', 'VBN'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('finite', 'finit'), ('known', 'known'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('finite', 'finit'), ('known', 'known'), ('.', '.')]

>> Lemmatization: 
 [('finite', 'finite'), ('known', 'known'), ('.', '.')]


------------------- Sentence 2 -------------------

We can descry the outputs, but the system’s internals are hidden.

>> Tokens are: 
 ['We', 'descry', 'outputs', ',', 'system', '’', 'internals', 'hidden', '.']

>> Bigrams are: 
 [('We', 'descry'), ('descry', 'outputs'), ('outputs', ','), (',', 'system'), ('system', '’'), ('’', 'internals'), ('internals', 'hidden'), ('hidden', '.')]

>> Trigrams are: 
 [('We', 'descry', 'outputs'), ('descry', 'outputs', ','), ('outputs', ',', 'system'), (',', 'system', '’'), ('system', '’', 'internals'), ('’', 'internals', 'hidden'), ('internals', 'hidden', '.')]

>> POS Tags are: 
 [('We', 'PRP'), ('descry', 'VBP'), ('outputs', 'NNS'), (',', ','), ('system', 'NN'), ('’', 'JJ'), ('internals', 'NNS'), ('hidden', 'VBP'), ('.', '.')]

>> Noun Phrases are: 
 ['outputs', 'system', '’ internals']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('We', 'we'), ('descry', 'descri'), ('outputs', 'output'), (',', ','), ('system', 'system'), ('’', '’'), ('internals', 'intern'), ('hidden', 'hidden'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('We', 'we'), ('descry', 'descri'), ('outputs', 'output'), (',', ','), ('system', 'system'), ('’', '’'), ('internals', 'intern'), ('hidden', 'hidden'), ('.', '.')]

>> Lemmatization: 
 [('We', 'We'), ('descry', 'descry'), ('outputs', 'output'), (',', ','), ('system', 'system'), ('’', '’'), ('internals', 'internals'), ('hidden', 'hidden'), ('.', '.')]


------------------- Sentence 3 -------------------

Few

>> Tokens are: 
 ['Few']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Few', 'JJ')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Few', 'few')]

>> Stemming using Snowball Stemmer: 
 [('Few', 'few')]

>> Lemmatization: 
 [('Few', 'Few')]



========================================== PARAGRAPH 477 ===========================================

of the problem could be solved are by Inference A certain sequence of output symbols,  

------------------- Sentence 1 -------------------

of the problem could be solved are by Inference A certain sequence of output symbols,

>> Tokens are: 
 ['problem', 'could', 'solved', 'Inference', 'A', 'certain', 'sequence', 'output', 'symbols', ',']

>> Bigrams are: 
 [('problem', 'could'), ('could', 'solved'), ('solved', 'Inference'), ('Inference', 'A'), ('A', 'certain'), ('certain', 'sequence'), ('sequence', 'output'), ('output', 'symbols'), ('symbols', ',')]

>> Trigrams are: 
 [('problem', 'could', 'solved'), ('could', 'solved', 'Inference'), ('solved', 'Inference', 'A'), ('Inference', 'A', 'certain'), ('A', 'certain', 'sequence'), ('certain', 'sequence', 'output'), ('sequence', 'output', 'symbols'), ('output', 'symbols', ',')]

>> POS Tags are: 
 [('problem', 'NN'), ('could', 'MD'), ('solved', 'VB'), ('Inference', 'NNP'), ('A', 'NNP'), ('certain', 'JJ'), ('sequence', 'NN'), ('output', 'NN'), ('symbols', 'NNS'), (',', ',')]

>> Noun Phrases are: 
 ['problem', 'Inference A', 'certain sequence output symbols']

>> Named Entities are: 
 [('PERSON', 'Inference')] 

>> Stemming using Porter Stemmer: 
 [('problem', 'problem'), ('could', 'could'), ('solved', 'solv'), ('Inference', 'infer'), ('A', 'a'), ('certain', 'certain'), ('sequence', 'sequenc'), ('output', 'output'), ('symbols', 'symbol'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('problem', 'problem'), ('could', 'could'), ('solved', 'solv'), ('Inference', 'infer'), ('A', 'a'), ('certain', 'certain'), ('sequence', 'sequenc'), ('output', 'output'), ('symbols', 'symbol'), (',', ',')]

>> Lemmatization: 
 [('problem', 'problem'), ('could', 'could'), ('solved', 'solved'), ('Inference', 'Inference'), ('A', 'A'), ('certain', 'certain'), ('sequence', 'sequence'), ('output', 'output'), ('symbols', 'symbol'), (',', ',')]



========================================== PARAGRAPH 478 ===========================================

compute the probabilities of one or more candidate states with sequences. Pattern matching  

------------------- Sentence 1 -------------------

compute the probabilities of one or more candidate states with sequences.

>> Tokens are: 
 ['compute', 'probabilities', 'one', 'candidate', 'states', 'sequences', '.']

>> Bigrams are: 
 [('compute', 'probabilities'), ('probabilities', 'one'), ('one', 'candidate'), ('candidate', 'states'), ('states', 'sequences'), ('sequences', '.')]

>> Trigrams are: 
 [('compute', 'probabilities', 'one'), ('probabilities', 'one', 'candidate'), ('one', 'candidate', 'states'), ('candidate', 'states', 'sequences'), ('states', 'sequences', '.')]

>> POS Tags are: 
 [('compute', 'NN'), ('probabilities', 'VBZ'), ('one', 'CD'), ('candidate', 'NN'), ('states', 'NNS'), ('sequences', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['compute', 'candidate states sequences']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('compute', 'comput'), ('probabilities', 'probabl'), ('one', 'one'), ('candidate', 'candid'), ('states', 'state'), ('sequences', 'sequenc'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('compute', 'comput'), ('probabilities', 'probabl'), ('one', 'one'), ('candidate', 'candid'), ('states', 'state'), ('sequences', 'sequenc'), ('.', '.')]

>> Lemmatization: 
 [('compute', 'compute'), ('probabilities', 'probability'), ('one', 'one'), ('candidate', 'candidate'), ('states', 'state'), ('sequences', 'sequence'), ('.', '.')]


------------------- Sentence 2 -------------------

Pattern matching

>> Tokens are: 
 ['Pattern', 'matching']

>> Bigrams are: 
 [('Pattern', 'matching')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Pattern', 'NNP'), ('matching', 'VBG')]

>> Noun Phrases are: 
 ['Pattern']

>> Named Entities are: 
 [('GPE', 'Pattern')] 

>> Stemming using Porter Stemmer: 
 [('Pattern', 'pattern'), ('matching', 'match')]

>> Stemming using Snowball Stemmer: 
 [('Pattern', 'pattern'), ('matching', 'match')]

>> Lemmatization: 
 [('Pattern', 'Pattern'), ('matching', 'matching')]



========================================== PARAGRAPH 479 ===========================================

the state-switch sequence is realised are most likely to have generated a particular output-

------------------- Sentence 1 -------------------

the state-switch sequence is realised are most likely to have generated a particular output-

>> Tokens are: 
 ['state-switch', 'sequence', 'realised', 'likely', 'generated', 'particular', 'output-']

>> Bigrams are: 
 [('state-switch', 'sequence'), ('sequence', 'realised'), ('realised', 'likely'), ('likely', 'generated'), ('generated', 'particular'), ('particular', 'output-')]

>> Trigrams are: 
 [('state-switch', 'sequence', 'realised'), ('sequence', 'realised', 'likely'), ('realised', 'likely', 'generated'), ('likely', 'generated', 'particular'), ('generated', 'particular', 'output-')]

>> POS Tags are: 
 [('state-switch', 'JJ'), ('sequence', 'NN'), ('realised', 'VBD'), ('likely', 'RB'), ('generated', 'VBN'), ('particular', 'JJ'), ('output-', 'JJ')]

>> Noun Phrases are: 
 ['state-switch sequence']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('state-switch', 'state-switch'), ('sequence', 'sequenc'), ('realised', 'realis'), ('likely', 'like'), ('generated', 'gener'), ('particular', 'particular'), ('output-', 'output-')]

>> Stemming using Snowball Stemmer: 
 [('state-switch', 'state-switch'), ('sequence', 'sequenc'), ('realised', 'realis'), ('likely', 'like'), ('generated', 'generat'), ('particular', 'particular'), ('output-', 'output-')]

>> Lemmatization: 
 [('state-switch', 'state-switch'), ('sequence', 'sequence'), ('realised', 'realised'), ('likely', 'likely'), ('generated', 'generated'), ('particular', 'particular'), ('output-', 'output-')]



========================================== PARAGRAPH 480 ===========================================

symbol sequence. Training the output-symbol chain data, reckon the state-switch/output  

------------------- Sentence 1 -------------------

symbol sequence.

>> Tokens are: 
 ['symbol', 'sequence', '.']

>> Bigrams are: 
 [('symbol', 'sequence'), ('sequence', '.')]

>> Trigrams are: 
 [('symbol', 'sequence', '.')]

>> POS Tags are: 
 [('symbol', 'NN'), ('sequence', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['symbol sequence']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('symbol', 'symbol'), ('sequence', 'sequenc'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('symbol', 'symbol'), ('sequence', 'sequenc'), ('.', '.')]

>> Lemmatization: 
 [('symbol', 'symbol'), ('sequence', 'sequence'), ('.', '.')]


------------------- Sentence 2 -------------------

Training the output-symbol chain data, reckon the state-switch/output

>> Tokens are: 
 ['Training', 'output-symbol', 'chain', 'data', ',', 'reckon', 'state-switch/output']

>> Bigrams are: 
 [('Training', 'output-symbol'), ('output-symbol', 'chain'), ('chain', 'data'), ('data', ','), (',', 'reckon'), ('reckon', 'state-switch/output')]

>> Trigrams are: 
 [('Training', 'output-symbol', 'chain'), ('output-symbol', 'chain', 'data'), ('chain', 'data', ','), ('data', ',', 'reckon'), (',', 'reckon', 'state-switch/output')]

>> POS Tags are: 
 [('Training', 'VBG'), ('output-symbol', 'NN'), ('chain', 'NN'), ('data', 'NNS'), (',', ','), ('reckon', 'VB'), ('state-switch/output', 'NN')]

>> Noun Phrases are: 
 ['output-symbol chain data', 'state-switch/output']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Training', 'train'), ('output-symbol', 'output-symbol'), ('chain', 'chain'), ('data', 'data'), (',', ','), ('reckon', 'reckon'), ('state-switch/output', 'state-switch/output')]

>> Stemming using Snowball Stemmer: 
 [('Training', 'train'), ('output-symbol', 'output-symbol'), ('chain', 'chain'), ('data', 'data'), (',', ','), ('reckon', 'reckon'), ('state-switch/output', 'state-switch/output')]

>> Lemmatization: 
 [('Training', 'Training'), ('output-symbol', 'output-symbol'), ('chain', 'chain'), ('data', 'data'), (',', ','), ('reckon', 'reckon'), ('state-switch/output', 'state-switch/output')]



========================================== PARAGRAPH 481 ===========================================

probabilities that fit this data best.  

------------------- Sentence 1 -------------------

probabilities that fit this data best.

>> Tokens are: 
 ['probabilities', 'fit', 'data', 'best', '.']

>> Bigrams are: 
 [('probabilities', 'fit'), ('fit', 'data'), ('data', 'best'), ('best', '.')]

>> Trigrams are: 
 [('probabilities', 'fit', 'data'), ('fit', 'data', 'best'), ('data', 'best', '.')]

>> POS Tags are: 
 [('probabilities', 'NNS'), ('fit', 'VBP'), ('data', 'NN'), ('best', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['probabilities', 'data best']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('probabilities', 'probabl'), ('fit', 'fit'), ('data', 'data'), ('best', 'best'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('probabilities', 'probabl'), ('fit', 'fit'), ('data', 'data'), ('best', 'best'), ('.', '.')]

>> Lemmatization: 
 [('probabilities', 'probability'), ('fit', 'fit'), ('data', 'data'), ('best', 'best'), ('.', '.')]



========================================== PARAGRAPH 482 ===========================================

Hidden Markov Models are extensively used for speech recognition, where the output  

------------------- Sentence 1 -------------------

Hidden Markov Models are extensively used for speech recognition, where the output

>> Tokens are: 
 ['Hidden', 'Markov', 'Models', 'extensively', 'used', 'speech', 'recognition', ',', 'output']

>> Bigrams are: 
 [('Hidden', 'Markov'), ('Markov', 'Models'), ('Models', 'extensively'), ('extensively', 'used'), ('used', 'speech'), ('speech', 'recognition'), ('recognition', ','), (',', 'output')]

>> Trigrams are: 
 [('Hidden', 'Markov', 'Models'), ('Markov', 'Models', 'extensively'), ('Models', 'extensively', 'used'), ('extensively', 'used', 'speech'), ('used', 'speech', 'recognition'), ('speech', 'recognition', ','), ('recognition', ',', 'output')]

>> POS Tags are: 
 [('Hidden', 'NNP'), ('Markov', 'NNP'), ('Models', 'NNP'), ('extensively', 'RB'), ('used', 'VBD'), ('speech', 'NN'), ('recognition', 'NN'), (',', ','), ('output', 'NN')]

>> Noun Phrases are: 
 ['Hidden Markov Models', 'speech recognition', 'output']

>> Named Entities are: 
 [('PERSON', 'Hidden'), ('PERSON', 'Markov Models')] 

>> Stemming using Porter Stemmer: 
 [('Hidden', 'hidden'), ('Markov', 'markov'), ('Models', 'model'), ('extensively', 'extens'), ('used', 'use'), ('speech', 'speech'), ('recognition', 'recognit'), (',', ','), ('output', 'output')]

>> Stemming using Snowball Stemmer: 
 [('Hidden', 'hidden'), ('Markov', 'markov'), ('Models', 'model'), ('extensively', 'extens'), ('used', 'use'), ('speech', 'speech'), ('recognition', 'recognit'), (',', ','), ('output', 'output')]

>> Lemmatization: 
 [('Hidden', 'Hidden'), ('Markov', 'Markov'), ('Models', 'Models'), ('extensively', 'extensively'), ('used', 'used'), ('speech', 'speech'), ('recognition', 'recognition'), (',', ','), ('output', 'output')]



========================================== PARAGRAPH 483 ===========================================

sequence is matched to the sequence of individual phonemes. Frederick Jelinek, a statistical- 

------------------- Sentence 1 -------------------

sequence is matched to the sequence of individual phonemes.

>> Tokens are: 
 ['sequence', 'matched', 'sequence', 'individual', 'phonemes', '.']

>> Bigrams are: 
 [('sequence', 'matched'), ('matched', 'sequence'), ('sequence', 'individual'), ('individual', 'phonemes'), ('phonemes', '.')]

>> Trigrams are: 
 [('sequence', 'matched', 'sequence'), ('matched', 'sequence', 'individual'), ('sequence', 'individual', 'phonemes'), ('individual', 'phonemes', '.')]

>> POS Tags are: 
 [('sequence', 'NN'), ('matched', 'VBD'), ('sequence', 'NN'), ('individual', 'JJ'), ('phonemes', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['sequence', 'sequence', 'individual phonemes']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('sequence', 'sequenc'), ('matched', 'match'), ('sequence', 'sequenc'), ('individual', 'individu'), ('phonemes', 'phonem'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('sequence', 'sequenc'), ('matched', 'match'), ('sequence', 'sequenc'), ('individual', 'individu'), ('phonemes', 'phonem'), ('.', '.')]

>> Lemmatization: 
 [('sequence', 'sequence'), ('matched', 'matched'), ('sequence', 'sequence'), ('individual', 'individual'), ('phonemes', 'phoneme'), ('.', '.')]


------------------- Sentence 2 -------------------

Frederick Jelinek, a statistical-

>> Tokens are: 
 ['Frederick', 'Jelinek', ',', 'statistical-']

>> Bigrams are: 
 [('Frederick', 'Jelinek'), ('Jelinek', ','), (',', 'statistical-')]

>> Trigrams are: 
 [('Frederick', 'Jelinek', ','), ('Jelinek', ',', 'statistical-')]

>> POS Tags are: 
 [('Frederick', 'NNP'), ('Jelinek', 'NNP'), (',', ','), ('statistical-', 'NN')]

>> Noun Phrases are: 
 ['Frederick Jelinek', 'statistical-']

>> Named Entities are: 
 [('PERSON', 'Frederick'), ('ORGANIZATION', 'Jelinek')] 

>> Stemming using Porter Stemmer: 
 [('Frederick', 'frederick'), ('Jelinek', 'jelinek'), (',', ','), ('statistical-', 'statistical-')]

>> Stemming using Snowball Stemmer: 
 [('Frederick', 'frederick'), ('Jelinek', 'jelinek'), (',', ','), ('statistical-', 'statistical-')]

>> Lemmatization: 
 [('Frederick', 'Frederick'), ('Jelinek', 'Jelinek'), (',', ','), ('statistical-', 'statistical-')]



========================================== PARAGRAPH 484 ===========================================

NLP advocate who first instigated HMMs at IBM’s Speech Recognition Group, reportedly  

------------------- Sentence 1 -------------------

NLP advocate who first instigated HMMs at IBM’s Speech Recognition Group, reportedly

>> Tokens are: 
 ['NLP', 'advocate', 'first', 'instigated', 'HMMs', 'IBM', '’', 'Speech', 'Recognition', 'Group', ',', 'reportedly']

>> Bigrams are: 
 [('NLP', 'advocate'), ('advocate', 'first'), ('first', 'instigated'), ('instigated', 'HMMs'), ('HMMs', 'IBM'), ('IBM', '’'), ('’', 'Speech'), ('Speech', 'Recognition'), ('Recognition', 'Group'), ('Group', ','), (',', 'reportedly')]

>> Trigrams are: 
 [('NLP', 'advocate', 'first'), ('advocate', 'first', 'instigated'), ('first', 'instigated', 'HMMs'), ('instigated', 'HMMs', 'IBM'), ('HMMs', 'IBM', '’'), ('IBM', '’', 'Speech'), ('’', 'Speech', 'Recognition'), ('Speech', 'Recognition', 'Group'), ('Recognition', 'Group', ','), ('Group', ',', 'reportedly')]

>> POS Tags are: 
 [('NLP', 'NNP'), ('advocate', 'NN'), ('first', 'RB'), ('instigated', 'VBD'), ('HMMs', 'NNP'), ('IBM', 'NNP'), ('’', 'NNP'), ('Speech', 'NNP'), ('Recognition', 'NNP'), ('Group', 'NNP'), (',', ','), ('reportedly', 'RB')]

>> Noun Phrases are: 
 ['NLP advocate', 'HMMs IBM ’ Speech Recognition Group']

>> Named Entities are: 
 [('ORGANIZATION', 'HMMs')] 

>> Stemming using Porter Stemmer: 
 [('NLP', 'nlp'), ('advocate', 'advoc'), ('first', 'first'), ('instigated', 'instig'), ('HMMs', 'hmm'), ('IBM', 'ibm'), ('’', '’'), ('Speech', 'speech'), ('Recognition', 'recognit'), ('Group', 'group'), (',', ','), ('reportedly', 'reportedli')]

>> Stemming using Snowball Stemmer: 
 [('NLP', 'nlp'), ('advocate', 'advoc'), ('first', 'first'), ('instigated', 'instig'), ('HMMs', 'hmms'), ('IBM', 'ibm'), ('’', '’'), ('Speech', 'speech'), ('Recognition', 'recognit'), ('Group', 'group'), (',', ','), ('reportedly', 'report')]

>> Lemmatization: 
 [('NLP', 'NLP'), ('advocate', 'advocate'), ('first', 'first'), ('instigated', 'instigated'), ('HMMs', 'HMMs'), ('IBM', 'IBM'), ('’', '’'), ('Speech', 'Speech'), ('Recognition', 'Recognition'), ('Group', 'Group'), (',', ','), ('reportedly', 'reportedly')]



========================================== PARAGRAPH 485 ===========================================

joked, every time a linguist leaves my group, the speech recognizer’s performance improves.  

------------------- Sentence 1 -------------------

joked, every time a linguist leaves my group, the speech recognizer’s performance improves.

>> Tokens are: 
 ['joked', ',', 'every', 'time', 'linguist', 'leaves', 'group', ',', 'speech', 'recognizer', '’', 'performance', 'improves', '.']

>> Bigrams are: 
 [('joked', ','), (',', 'every'), ('every', 'time'), ('time', 'linguist'), ('linguist', 'leaves'), ('leaves', 'group'), ('group', ','), (',', 'speech'), ('speech', 'recognizer'), ('recognizer', '’'), ('’', 'performance'), ('performance', 'improves'), ('improves', '.')]

>> Trigrams are: 
 [('joked', ',', 'every'), (',', 'every', 'time'), ('every', 'time', 'linguist'), ('time', 'linguist', 'leaves'), ('linguist', 'leaves', 'group'), ('leaves', 'group', ','), ('group', ',', 'speech'), (',', 'speech', 'recognizer'), ('speech', 'recognizer', '’'), ('recognizer', '’', 'performance'), ('’', 'performance', 'improves'), ('performance', 'improves', '.')]

>> POS Tags are: 
 [('joked', 'NNS'), (',', ','), ('every', 'DT'), ('time', 'NN'), ('linguist', 'JJ'), ('leaves', 'NNS'), ('group', 'NN'), (',', ','), ('speech', 'NN'), ('recognizer', 'NN'), ('’', 'JJ'), ('performance', 'NN'), ('improves', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['joked', 'every time', 'linguist leaves group', 'speech recognizer', '’ performance improves']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('joked', 'joke'), (',', ','), ('every', 'everi'), ('time', 'time'), ('linguist', 'linguist'), ('leaves', 'leav'), ('group', 'group'), (',', ','), ('speech', 'speech'), ('recognizer', 'recogn'), ('’', '’'), ('performance', 'perform'), ('improves', 'improv'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('joked', 'joke'), (',', ','), ('every', 'everi'), ('time', 'time'), ('linguist', 'linguist'), ('leaves', 'leav'), ('group', 'group'), (',', ','), ('speech', 'speech'), ('recognizer', 'recogn'), ('’', '’'), ('performance', 'perform'), ('improves', 'improv'), ('.', '.')]

>> Lemmatization: 
 [('joked', 'joked'), (',', ','), ('every', 'every'), ('time', 'time'), ('linguist', 'linguist'), ('leaves', 'leaf'), ('group', 'group'), (',', ','), ('speech', 'speech'), ('recognizer', 'recognizer'), ('’', '’'), ('performance', 'performance'), ('improves', 'improves'), ('.', '.')]



========================================== PARAGRAPH 486 ===========================================

[101] HMM is not restricted to this application it has several others such as bioinformatics  

------------------- Sentence 1 -------------------

[101] HMM is not restricted to this application it has several others such as bioinformatics

>> Tokens are: 
 ['[', '101', ']', 'HMM', 'restricted', 'application', 'several', 'others', 'bioinformatics']

>> Bigrams are: 
 [('[', '101'), ('101', ']'), (']', 'HMM'), ('HMM', 'restricted'), ('restricted', 'application'), ('application', 'several'), ('several', 'others'), ('others', 'bioinformatics')]

>> Trigrams are: 
 [('[', '101', ']'), ('101', ']', 'HMM'), (']', 'HMM', 'restricted'), ('HMM', 'restricted', 'application'), ('restricted', 'application', 'several'), ('application', 'several', 'others'), ('several', 'others', 'bioinformatics')]

>> POS Tags are: 
 [('[', 'RB'), ('101', 'CD'), (']', 'JJ'), ('HMM', 'NNP'), ('restricted', 'VBD'), ('application', 'NN'), ('several', 'JJ'), ('others', 'NNS'), ('bioinformatics', 'NNS')]

>> Noun Phrases are: 
 ['] HMM', 'application', 'several others bioinformatics']

>> Named Entities are: 
 [('ORGANIZATION', 'HMM')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('101', '101'), (']', ']'), ('HMM', 'hmm'), ('restricted', 'restrict'), ('application', 'applic'), ('several', 'sever'), ('others', 'other'), ('bioinformatics', 'bioinformat')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('101', '101'), (']', ']'), ('HMM', 'hmm'), ('restricted', 'restrict'), ('application', 'applic'), ('several', 'sever'), ('others', 'other'), ('bioinformatics', 'bioinformat')]

>> Lemmatization: 
 [('[', '['), ('101', '101'), (']', ']'), ('HMM', 'HMM'), ('restricted', 'restricted'), ('application', 'application'), ('several', 'several'), ('others', 'others'), ('bioinformatics', 'bioinformatics')]



========================================== PARAGRAPH 487 ===========================================

problems, for example, multiple sequence alignment [102]. Sonnhammer mentioned that  

------------------- Sentence 1 -------------------

problems, for example, multiple sequence alignment [102].

>> Tokens are: 
 ['problems', ',', 'example', ',', 'multiple', 'sequence', 'alignment', '[', '102', ']', '.']

>> Bigrams are: 
 [('problems', ','), (',', 'example'), ('example', ','), (',', 'multiple'), ('multiple', 'sequence'), ('sequence', 'alignment'), ('alignment', '['), ('[', '102'), ('102', ']'), (']', '.')]

>> Trigrams are: 
 [('problems', ',', 'example'), (',', 'example', ','), ('example', ',', 'multiple'), (',', 'multiple', 'sequence'), ('multiple', 'sequence', 'alignment'), ('sequence', 'alignment', '['), ('alignment', '[', '102'), ('[', '102', ']'), ('102', ']', '.')]

>> POS Tags are: 
 [('problems', 'NNS'), (',', ','), ('example', 'NN'), (',', ','), ('multiple', 'JJ'), ('sequence', 'NN'), ('alignment', 'NN'), ('[', 'VBD'), ('102', 'CD'), (']', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['problems', 'example', 'multiple sequence alignment', ']']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('problems', 'problem'), (',', ','), ('example', 'exampl'), (',', ','), ('multiple', 'multipl'), ('sequence', 'sequenc'), ('alignment', 'align'), ('[', '['), ('102', '102'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('problems', 'problem'), (',', ','), ('example', 'exampl'), (',', ','), ('multiple', 'multipl'), ('sequence', 'sequenc'), ('alignment', 'align'), ('[', '['), ('102', '102'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('problems', 'problem'), (',', ','), ('example', 'example'), (',', ','), ('multiple', 'multiple'), ('sequence', 'sequence'), ('alignment', 'alignment'), ('[', '['), ('102', '102'), (']', ']'), ('.', '.')]


------------------- Sentence 2 -------------------

Sonnhammer mentioned that

>> Tokens are: 
 ['Sonnhammer', 'mentioned']

>> Bigrams are: 
 [('Sonnhammer', 'mentioned')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Sonnhammer', 'NN'), ('mentioned', 'VBD')]

>> Noun Phrases are: 
 ['Sonnhammer']

>> Named Entities are: 
 [('PERSON', 'Sonnhammer')] 

>> Stemming using Porter Stemmer: 
 [('Sonnhammer', 'sonnhamm'), ('mentioned', 'mention')]

>> Stemming using Snowball Stemmer: 
 [('Sonnhammer', 'sonnhamm'), ('mentioned', 'mention')]

>> Lemmatization: 
 [('Sonnhammer', 'Sonnhammer'), ('mentioned', 'mentioned')]



========================================== PARAGRAPH 488 ===========================================

Pfam hold multiple alignments and hidden Markov model based profiles (HMM-profiles) of  

------------------- Sentence 1 -------------------

Pfam hold multiple alignments and hidden Markov model based profiles (HMM-profiles) of

>> Tokens are: 
 ['Pfam', 'hold', 'multiple', 'alignments', 'hidden', 'Markov', 'model', 'based', 'profiles', '(', 'HMM-profiles', ')']

>> Bigrams are: 
 [('Pfam', 'hold'), ('hold', 'multiple'), ('multiple', 'alignments'), ('alignments', 'hidden'), ('hidden', 'Markov'), ('Markov', 'model'), ('model', 'based'), ('based', 'profiles'), ('profiles', '('), ('(', 'HMM-profiles'), ('HMM-profiles', ')')]

>> Trigrams are: 
 [('Pfam', 'hold', 'multiple'), ('hold', 'multiple', 'alignments'), ('multiple', 'alignments', 'hidden'), ('alignments', 'hidden', 'Markov'), ('hidden', 'Markov', 'model'), ('Markov', 'model', 'based'), ('model', 'based', 'profiles'), ('based', 'profiles', '('), ('profiles', '(', 'HMM-profiles'), ('(', 'HMM-profiles', ')')]

>> POS Tags are: 
 [('Pfam', 'NNP'), ('hold', 'VBP'), ('multiple', 'JJ'), ('alignments', 'NNS'), ('hidden', 'JJ'), ('Markov', 'NNP'), ('model', 'NN'), ('based', 'VBN'), ('profiles', 'NNS'), ('(', '('), ('HMM-profiles', 'NNP'), (')', ')')]

>> Noun Phrases are: 
 ['Pfam', 'multiple alignments', 'hidden Markov model', 'profiles', 'HMM-profiles']

>> Named Entities are: 
 [('GPE', 'Pfam'), ('PERSON', 'Markov')] 

>> Stemming using Porter Stemmer: 
 [('Pfam', 'pfam'), ('hold', 'hold'), ('multiple', 'multipl'), ('alignments', 'align'), ('hidden', 'hidden'), ('Markov', 'markov'), ('model', 'model'), ('based', 'base'), ('profiles', 'profil'), ('(', '('), ('HMM-profiles', 'hmm-profil'), (')', ')')]

>> Stemming using Snowball Stemmer: 
 [('Pfam', 'pfam'), ('hold', 'hold'), ('multiple', 'multipl'), ('alignments', 'align'), ('hidden', 'hidden'), ('Markov', 'markov'), ('model', 'model'), ('based', 'base'), ('profiles', 'profil'), ('(', '('), ('HMM-profiles', 'hmm-profil'), (')', ')')]

>> Lemmatization: 
 [('Pfam', 'Pfam'), ('hold', 'hold'), ('multiple', 'multiple'), ('alignments', 'alignment'), ('hidden', 'hidden'), ('Markov', 'Markov'), ('model', 'model'), ('based', 'based'), ('profiles', 'profile'), ('(', '('), ('HMM-profiles', 'HMM-profiles'), (')', ')')]



========================================== PARAGRAPH 489 ===========================================

entire protein domains. The cue of domain boundaries, family members and alignment is  

------------------- Sentence 1 -------------------

entire protein domains.

>> Tokens are: 
 ['entire', 'protein', 'domains', '.']

>> Bigrams are: 
 [('entire', 'protein'), ('protein', 'domains'), ('domains', '.')]

>> Trigrams are: 
 [('entire', 'protein', 'domains'), ('protein', 'domains', '.')]

>> POS Tags are: 
 [('entire', 'JJ'), ('protein', 'NN'), ('domains', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['entire protein domains']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('entire', 'entir'), ('protein', 'protein'), ('domains', 'domain'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('entire', 'entir'), ('protein', 'protein'), ('domains', 'domain'), ('.', '.')]

>> Lemmatization: 
 [('entire', 'entire'), ('protein', 'protein'), ('domains', 'domain'), ('.', '.')]


------------------- Sentence 2 -------------------

The cue of domain boundaries, family members and alignment is

>> Tokens are: 
 ['The', 'cue', 'domain', 'boundaries', ',', 'family', 'members', 'alignment']

>> Bigrams are: 
 [('The', 'cue'), ('cue', 'domain'), ('domain', 'boundaries'), ('boundaries', ','), (',', 'family'), ('family', 'members'), ('members', 'alignment')]

>> Trigrams are: 
 [('The', 'cue', 'domain'), ('cue', 'domain', 'boundaries'), ('domain', 'boundaries', ','), ('boundaries', ',', 'family'), (',', 'family', 'members'), ('family', 'members', 'alignment')]

>> POS Tags are: 
 [('The', 'DT'), ('cue', 'NN'), ('domain', 'NN'), ('boundaries', 'NNS'), (',', ','), ('family', 'NN'), ('members', 'NNS'), ('alignment', 'VBP')]

>> Noun Phrases are: 
 ['The cue domain boundaries', 'family members']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('cue', 'cue'), ('domain', 'domain'), ('boundaries', 'boundari'), (',', ','), ('family', 'famili'), ('members', 'member'), ('alignment', 'align')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('cue', 'cue'), ('domain', 'domain'), ('boundaries', 'boundari'), (',', ','), ('family', 'famili'), ('members', 'member'), ('alignment', 'align')]

>> Lemmatization: 
 [('The', 'The'), ('cue', 'cue'), ('domain', 'domain'), ('boundaries', 'boundary'), (',', ','), ('family', 'family'), ('members', 'member'), ('alignment', 'alignment')]



========================================== PARAGRAPH 490 ===========================================

done semi-automatically found on expert knowledge, sequence similarity, other protein  

------------------- Sentence 1 -------------------

done semi-automatically found on expert knowledge, sequence similarity, other protein

>> Tokens are: 
 ['done', 'semi-automatically', 'found', 'expert', 'knowledge', ',', 'sequence', 'similarity', ',', 'protein']

>> Bigrams are: 
 [('done', 'semi-automatically'), ('semi-automatically', 'found'), ('found', 'expert'), ('expert', 'knowledge'), ('knowledge', ','), (',', 'sequence'), ('sequence', 'similarity'), ('similarity', ','), (',', 'protein')]

>> Trigrams are: 
 [('done', 'semi-automatically', 'found'), ('semi-automatically', 'found', 'expert'), ('found', 'expert', 'knowledge'), ('expert', 'knowledge', ','), ('knowledge', ',', 'sequence'), (',', 'sequence', 'similarity'), ('sequence', 'similarity', ','), ('similarity', ',', 'protein')]

>> POS Tags are: 
 [('done', 'VBN'), ('semi-automatically', 'RB'), ('found', 'VBN'), ('expert', 'NN'), ('knowledge', 'NN'), (',', ','), ('sequence', 'NN'), ('similarity', 'NN'), (',', ','), ('protein', 'NN')]

>> Noun Phrases are: 
 ['expert knowledge', 'sequence similarity', 'protein']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('done', 'done'), ('semi-automatically', 'semi-automat'), ('found', 'found'), ('expert', 'expert'), ('knowledge', 'knowledg'), (',', ','), ('sequence', 'sequenc'), ('similarity', 'similar'), (',', ','), ('protein', 'protein')]

>> Stemming using Snowball Stemmer: 
 [('done', 'done'), ('semi-automatically', 'semi-automat'), ('found', 'found'), ('expert', 'expert'), ('knowledge', 'knowledg'), (',', ','), ('sequence', 'sequenc'), ('similarity', 'similar'), (',', ','), ('protein', 'protein')]

>> Lemmatization: 
 [('done', 'done'), ('semi-automatically', 'semi-automatically'), ('found', 'found'), ('expert', 'expert'), ('knowledge', 'knowledge'), (',', ','), ('sequence', 'sequence'), ('similarity', 'similarity'), (',', ','), ('protein', 'protein')]



========================================== PARAGRAPH 491 ===========================================

family databases and the capability of HMM-profiles to correctly identify and align the  

------------------- Sentence 1 -------------------

family databases and the capability of HMM-profiles to correctly identify and align the

>> Tokens are: 
 ['family', 'databases', 'capability', 'HMM-profiles', 'correctly', 'identify', 'align']

>> Bigrams are: 
 [('family', 'databases'), ('databases', 'capability'), ('capability', 'HMM-profiles'), ('HMM-profiles', 'correctly'), ('correctly', 'identify'), ('identify', 'align')]

>> Trigrams are: 
 [('family', 'databases', 'capability'), ('databases', 'capability', 'HMM-profiles'), ('capability', 'HMM-profiles', 'correctly'), ('HMM-profiles', 'correctly', 'identify'), ('correctly', 'identify', 'align')]

>> POS Tags are: 
 [('family', 'NN'), ('databases', 'VBZ'), ('capability', 'NN'), ('HMM-profiles', 'NNP'), ('correctly', 'RB'), ('identify', 'VBZ'), ('align', 'NN')]

>> Noun Phrases are: 
 ['family', 'capability HMM-profiles', 'align']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('family', 'famili'), ('databases', 'databas'), ('capability', 'capabl'), ('HMM-profiles', 'hmm-profil'), ('correctly', 'correctli'), ('identify', 'identifi'), ('align', 'align')]

>> Stemming using Snowball Stemmer: 
 [('family', 'famili'), ('databases', 'databas'), ('capability', 'capabl'), ('HMM-profiles', 'hmm-profil'), ('correctly', 'correct'), ('identify', 'identifi'), ('align', 'align')]

>> Lemmatization: 
 [('family', 'family'), ('databases', 'database'), ('capability', 'capability'), ('HMM-profiles', 'HMM-profiles'), ('correctly', 'correctly'), ('identify', 'identify'), ('align', 'align')]



========================================== PARAGRAPH 492 ===========================================

members. [103]   

------------------- Sentence 1 -------------------

members.

>> Tokens are: 
 ['members', '.']

>> Bigrams are: 
 [('members', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('members', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['members']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('members', 'member'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('members', 'member'), ('.', '.')]

>> Lemmatization: 
 [('members', 'member'), ('.', '.')]


------------------- Sentence 2 -------------------

[103]

>> Tokens are: 
 ['[', '103', ']']

>> Bigrams are: 
 [('[', '103'), ('103', ']')]

>> Trigrams are: 
 [('[', '103', ']')]

>> POS Tags are: 
 [('[', 'RB'), ('103', 'CD'), (']', 'NNS')]

>> Noun Phrases are: 
 [']']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('103', '103'), (']', ']')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('103', '103'), (']', ']')]

>> Lemmatization: 
 [('[', '['), ('103', '103'), (']', ']')]



========================================== PARAGRAPH 493 ===========================================

7.2 Naive Bayes Classifiers  

------------------- Sentence 1 -------------------

7.2 Naive Bayes Classifiers

>> Tokens are: 
 ['7.2', 'Naive', 'Bayes', 'Classifiers']

>> Bigrams are: 
 [('7.2', 'Naive'), ('Naive', 'Bayes'), ('Bayes', 'Classifiers')]

>> Trigrams are: 
 [('7.2', 'Naive', 'Bayes'), ('Naive', 'Bayes', 'Classifiers')]

>> POS Tags are: 
 [('7.2', 'CD'), ('Naive', 'JJ'), ('Bayes', 'NNP'), ('Classifiers', 'NNP')]

>> Noun Phrases are: 
 ['Naive Bayes Classifiers']

>> Named Entities are: 
 [('PERSON', 'Bayes Classifiers')] 

>> Stemming using Porter Stemmer: 
 [('7.2', '7.2'), ('Naive', 'naiv'), ('Bayes', 'bay'), ('Classifiers', 'classifi')]

>> Stemming using Snowball Stemmer: 
 [('7.2', '7.2'), ('Naive', 'naiv'), ('Bayes', 'bay'), ('Classifiers', 'classifi')]

>> Lemmatization: 
 [('7.2', '7.2'), ('Naive', 'Naive'), ('Bayes', 'Bayes'), ('Classifiers', 'Classifiers')]



========================================== PARAGRAPH 494 ===========================================

 The choice of area is wide ranging covering usual items like word segmentation and  

------------------- Sentence 1 -------------------

 The choice of area is wide ranging covering usual items like word segmentation and

>> Tokens are: 
 ['The', 'choice', 'area', 'wide', 'ranging', 'covering', 'usual', 'items', 'like', 'word', 'segmentation']

>> Bigrams are: 
 [('The', 'choice'), ('choice', 'area'), ('area', 'wide'), ('wide', 'ranging'), ('ranging', 'covering'), ('covering', 'usual'), ('usual', 'items'), ('items', 'like'), ('like', 'word'), ('word', 'segmentation')]

>> Trigrams are: 
 [('The', 'choice', 'area'), ('choice', 'area', 'wide'), ('area', 'wide', 'ranging'), ('wide', 'ranging', 'covering'), ('ranging', 'covering', 'usual'), ('covering', 'usual', 'items'), ('usual', 'items', 'like'), ('items', 'like', 'word'), ('like', 'word', 'segmentation')]

>> POS Tags are: 
 [('The', 'DT'), ('choice', 'NN'), ('area', 'NN'), ('wide', 'JJ'), ('ranging', 'VBG'), ('covering', 'VBG'), ('usual', 'JJ'), ('items', 'NNS'), ('like', 'IN'), ('word', 'NN'), ('segmentation', 'NN')]

>> Noun Phrases are: 
 ['The choice area', 'usual items', 'word segmentation']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('choice', 'choic'), ('area', 'area'), ('wide', 'wide'), ('ranging', 'rang'), ('covering', 'cover'), ('usual', 'usual'), ('items', 'item'), ('like', 'like'), ('word', 'word'), ('segmentation', 'segment')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('choice', 'choic'), ('area', 'area'), ('wide', 'wide'), ('ranging', 'rang'), ('covering', 'cover'), ('usual', 'usual'), ('items', 'item'), ('like', 'like'), ('word', 'word'), ('segmentation', 'segment')]

>> Lemmatization: 
 [('The', 'The'), ('choice', 'choice'), ('area', 'area'), ('wide', 'wide'), ('ranging', 'ranging'), ('covering', 'covering'), ('usual', 'usual'), ('items', 'item'), ('like', 'like'), ('word', 'word'), ('segmentation', 'segmentation')]



========================================== PARAGRAPH 495 ===========================================

translation but also unusual areas like segmentation for infant learning and identifying  

------------------- Sentence 1 -------------------

translation but also unusual areas like segmentation for infant learning and identifying

>> Tokens are: 
 ['translation', 'also', 'unusual', 'areas', 'like', 'segmentation', 'infant', 'learning', 'identifying']

>> Bigrams are: 
 [('translation', 'also'), ('also', 'unusual'), ('unusual', 'areas'), ('areas', 'like'), ('like', 'segmentation'), ('segmentation', 'infant'), ('infant', 'learning'), ('learning', 'identifying')]

>> Trigrams are: 
 [('translation', 'also', 'unusual'), ('also', 'unusual', 'areas'), ('unusual', 'areas', 'like'), ('areas', 'like', 'segmentation'), ('like', 'segmentation', 'infant'), ('segmentation', 'infant', 'learning'), ('infant', 'learning', 'identifying')]

>> POS Tags are: 
 [('translation', 'NN'), ('also', 'RB'), ('unusual', 'JJ'), ('areas', 'NNS'), ('like', 'IN'), ('segmentation', 'NN'), ('infant', 'NN'), ('learning', 'VBG'), ('identifying', 'VBG')]

>> Noun Phrases are: 
 ['translation', 'unusual areas', 'segmentation infant']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('translation', 'translat'), ('also', 'also'), ('unusual', 'unusu'), ('areas', 'area'), ('like', 'like'), ('segmentation', 'segment'), ('infant', 'infant'), ('learning', 'learn'), ('identifying', 'identifi')]

>> Stemming using Snowball Stemmer: 
 [('translation', 'translat'), ('also', 'also'), ('unusual', 'unusu'), ('areas', 'area'), ('like', 'like'), ('segmentation', 'segment'), ('infant', 'infant'), ('learning', 'learn'), ('identifying', 'identifi')]

>> Lemmatization: 
 [('translation', 'translation'), ('also', 'also'), ('unusual', 'unusual'), ('areas', 'area'), ('like', 'like'), ('segmentation', 'segmentation'), ('infant', 'infant'), ('learning', 'learning'), ('identifying', 'identifying')]



========================================== PARAGRAPH 496 ===========================================

documents for opinions and facts. In addition, exclusive article was selected for its use of  

------------------- Sentence 1 -------------------

documents for opinions and facts.

>> Tokens are: 
 ['documents', 'opinions', 'facts', '.']

>> Bigrams are: 
 [('documents', 'opinions'), ('opinions', 'facts'), ('facts', '.')]

>> Trigrams are: 
 [('documents', 'opinions', 'facts'), ('opinions', 'facts', '.')]

>> POS Tags are: 
 [('documents', 'NNS'), ('opinions', 'NNS'), ('facts', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['documents opinions facts']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('documents', 'document'), ('opinions', 'opinion'), ('facts', 'fact'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('documents', 'document'), ('opinions', 'opinion'), ('facts', 'fact'), ('.', '.')]

>> Lemmatization: 
 [('documents', 'document'), ('opinions', 'opinion'), ('facts', 'fact'), ('.', '.')]


------------------- Sentence 2 -------------------

In addition, exclusive article was selected for its use of

>> Tokens are: 
 ['In', 'addition', ',', 'exclusive', 'article', 'selected', 'use']

>> Bigrams are: 
 [('In', 'addition'), ('addition', ','), (',', 'exclusive'), ('exclusive', 'article'), ('article', 'selected'), ('selected', 'use')]

>> Trigrams are: 
 [('In', 'addition', ','), ('addition', ',', 'exclusive'), (',', 'exclusive', 'article'), ('exclusive', 'article', 'selected'), ('article', 'selected', 'use')]

>> POS Tags are: 
 [('In', 'IN'), ('addition', 'NN'), (',', ','), ('exclusive', 'JJ'), ('article', 'NN'), ('selected', 'VBN'), ('use', 'NN')]

>> Noun Phrases are: 
 ['addition', 'exclusive article', 'use']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('addition', 'addit'), (',', ','), ('exclusive', 'exclus'), ('article', 'articl'), ('selected', 'select'), ('use', 'use')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('addition', 'addit'), (',', ','), ('exclusive', 'exclus'), ('article', 'articl'), ('selected', 'select'), ('use', 'use')]

>> Lemmatization: 
 [('In', 'In'), ('addition', 'addition'), (',', ','), ('exclusive', 'exclusive'), ('article', 'article'), ('selected', 'selected'), ('use', 'use')]



========================================== PARAGRAPH 497 ===========================================

Bayesian methods to aid the research in designing algorithms for their investigation.  

------------------- Sentence 1 -------------------

Bayesian methods to aid the research in designing algorithms for their investigation.

>> Tokens are: 
 ['Bayesian', 'methods', 'aid', 'research', 'designing', 'algorithms', 'investigation', '.']

>> Bigrams are: 
 [('Bayesian', 'methods'), ('methods', 'aid'), ('aid', 'research'), ('research', 'designing'), ('designing', 'algorithms'), ('algorithms', 'investigation'), ('investigation', '.')]

>> Trigrams are: 
 [('Bayesian', 'methods', 'aid'), ('methods', 'aid', 'research'), ('aid', 'research', 'designing'), ('research', 'designing', 'algorithms'), ('designing', 'algorithms', 'investigation'), ('algorithms', 'investigation', '.')]

>> POS Tags are: 
 [('Bayesian', 'JJ'), ('methods', 'NNS'), ('aid', 'VBD'), ('research', 'NN'), ('designing', 'VBG'), ('algorithms', 'JJ'), ('investigation', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Bayesian methods', 'research', 'algorithms investigation']

>> Named Entities are: 
 [('GPE', 'Bayesian')] 

>> Stemming using Porter Stemmer: 
 [('Bayesian', 'bayesian'), ('methods', 'method'), ('aid', 'aid'), ('research', 'research'), ('designing', 'design'), ('algorithms', 'algorithm'), ('investigation', 'investig'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Bayesian', 'bayesian'), ('methods', 'method'), ('aid', 'aid'), ('research', 'research'), ('designing', 'design'), ('algorithms', 'algorithm'), ('investigation', 'investig'), ('.', '.')]

>> Lemmatization: 
 [('Bayesian', 'Bayesian'), ('methods', 'method'), ('aid', 'aid'), ('research', 'research'), ('designing', 'designing'), ('algorithms', 'algorithm'), ('investigation', 'investigation'), ('.', '.')]



========================================== PARAGRAPH 498 ===========================================

8. NLP in Talk  

------------------- Sentence 1 -------------------

8.

>> Tokens are: 
 ['8', '.']

>> Bigrams are: 
 [('8', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('8', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('8', '8'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('8', '8'), ('.', '.')]

>> Lemmatization: 
 [('8', '8'), ('.', '.')]


------------------- Sentence 2 -------------------

NLP in Talk

>> Tokens are: 
 ['NLP', 'Talk']

>> Bigrams are: 
 [('NLP', 'Talk')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('NLP', 'NNP'), ('Talk', 'NN')]

>> Noun Phrases are: 
 ['NLP Talk']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('NLP', 'nlp'), ('Talk', 'talk')]

>> Stemming using Snowball Stemmer: 
 [('NLP', 'nlp'), ('Talk', 'talk')]

>> Lemmatization: 
 [('NLP', 'NLP'), ('Talk', 'Talk')]



========================================== PARAGRAPH 499 ===========================================

This section discusses the recent developments in the NLP projects implemented by various  

------------------- Sentence 1 -------------------

This section discusses the recent developments in the NLP projects implemented by various

>> Tokens are: 
 ['This', 'section', 'discusses', 'recent', 'developments', 'NLP', 'projects', 'implemented', 'various']

>> Bigrams are: 
 [('This', 'section'), ('section', 'discusses'), ('discusses', 'recent'), ('recent', 'developments'), ('developments', 'NLP'), ('NLP', 'projects'), ('projects', 'implemented'), ('implemented', 'various')]

>> Trigrams are: 
 [('This', 'section', 'discusses'), ('section', 'discusses', 'recent'), ('discusses', 'recent', 'developments'), ('recent', 'developments', 'NLP'), ('developments', 'NLP', 'projects'), ('NLP', 'projects', 'implemented'), ('projects', 'implemented', 'various')]

>> POS Tags are: 
 [('This', 'DT'), ('section', 'NN'), ('discusses', 'VBZ'), ('recent', 'JJ'), ('developments', 'NNS'), ('NLP', 'NNP'), ('projects', 'NNS'), ('implemented', 'VBD'), ('various', 'JJ')]

>> Noun Phrases are: 
 ['This section', 'recent developments NLP projects']

>> Named Entities are: 
 [('ORGANIZATION', 'NLP')] 

>> Stemming using Porter Stemmer: 
 [('This', 'thi'), ('section', 'section'), ('discusses', 'discuss'), ('recent', 'recent'), ('developments', 'develop'), ('NLP', 'nlp'), ('projects', 'project'), ('implemented', 'implement'), ('various', 'variou')]

>> Stemming using Snowball Stemmer: 
 [('This', 'this'), ('section', 'section'), ('discusses', 'discuss'), ('recent', 'recent'), ('developments', 'develop'), ('NLP', 'nlp'), ('projects', 'project'), ('implemented', 'implement'), ('various', 'various')]

>> Lemmatization: 
 [('This', 'This'), ('section', 'section'), ('discusses', 'discus'), ('recent', 'recent'), ('developments', 'development'), ('NLP', 'NLP'), ('projects', 'project'), ('implemented', 'implemented'), ('various', 'various')]



========================================== PARAGRAPH 500 ===========================================

companies and these are as follows:  

------------------- Sentence 1 -------------------

companies and these are as follows:

>> Tokens are: 
 ['companies', 'follows', ':']

>> Bigrams are: 
 [('companies', 'follows'), ('follows', ':')]

>> Trigrams are: 
 [('companies', 'follows', ':')]

>> POS Tags are: 
 [('companies', 'NNS'), ('follows', 'VBZ'), (':', ':')]

>> Noun Phrases are: 
 ['companies']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('companies', 'compani'), ('follows', 'follow'), (':', ':')]

>> Stemming using Snowball Stemmer: 
 [('companies', 'compani'), ('follows', 'follow'), (':', ':')]

>> Lemmatization: 
 [('companies', 'company'), ('follows', 'follows'), (':', ':')]



========================================== PARAGRAPH 501 ===========================================

8.1 ACE Powered GDPR Robot Launched by RAVN Systems [104]  

------------------- Sentence 1 -------------------

8.1 ACE Powered GDPR Robot Launched by RAVN Systems [104]

>> Tokens are: 
 ['8.1', 'ACE', 'Powered', 'GDPR', 'Robot', 'Launched', 'RAVN', 'Systems', '[', '104', ']']

>> Bigrams are: 
 [('8.1', 'ACE'), ('ACE', 'Powered'), ('Powered', 'GDPR'), ('GDPR', 'Robot'), ('Robot', 'Launched'), ('Launched', 'RAVN'), ('RAVN', 'Systems'), ('Systems', '['), ('[', '104'), ('104', ']')]

>> Trigrams are: 
 [('8.1', 'ACE', 'Powered'), ('ACE', 'Powered', 'GDPR'), ('Powered', 'GDPR', 'Robot'), ('GDPR', 'Robot', 'Launched'), ('Robot', 'Launched', 'RAVN'), ('Launched', 'RAVN', 'Systems'), ('RAVN', 'Systems', '['), ('Systems', '[', '104'), ('[', '104', ']')]

>> POS Tags are: 
 [('8.1', 'CD'), ('ACE', 'NNP'), ('Powered', 'NNP'), ('GDPR', 'NNP'), ('Robot', 'NNP'), ('Launched', 'NNP'), ('RAVN', 'NNP'), ('Systems', 'NNP'), ('[', 'NNP'), ('104', 'CD'), (']', 'NN')]

>> Noun Phrases are: 
 ['ACE Powered GDPR Robot Launched RAVN Systems [', ']']

>> Named Entities are: 
 [('ORGANIZATION', 'ACE Powered'), ('PERSON', 'Robot Launched')] 

>> Stemming using Porter Stemmer: 
 [('8.1', '8.1'), ('ACE', 'ace'), ('Powered', 'power'), ('GDPR', 'gdpr'), ('Robot', 'robot'), ('Launched', 'launch'), ('RAVN', 'ravn'), ('Systems', 'system'), ('[', '['), ('104', '104'), (']', ']')]

>> Stemming using Snowball Stemmer: 
 [('8.1', '8.1'), ('ACE', 'ace'), ('Powered', 'power'), ('GDPR', 'gdpr'), ('Robot', 'robot'), ('Launched', 'launch'), ('RAVN', 'ravn'), ('Systems', 'system'), ('[', '['), ('104', '104'), (']', ']')]

>> Lemmatization: 
 [('8.1', '8.1'), ('ACE', 'ACE'), ('Powered', 'Powered'), ('GDPR', 'GDPR'), ('Robot', 'Robot'), ('Launched', 'Launched'), ('RAVN', 'RAVN'), ('Systems', 'Systems'), ('[', '['), ('104', '104'), (']', ']')]



========================================== PARAGRAPH 502 ===========================================

RAVN Systems, an leading expert in Artificial Intelligence (AI), Search and Knowledge  

------------------- Sentence 1 -------------------

RAVN Systems, an leading expert in Artificial Intelligence (AI), Search and Knowledge

>> Tokens are: 
 ['RAVN', 'Systems', ',', 'leading', 'expert', 'Artificial', 'Intelligence', '(', 'AI', ')', ',', 'Search', 'Knowledge']

>> Bigrams are: 
 [('RAVN', 'Systems'), ('Systems', ','), (',', 'leading'), ('leading', 'expert'), ('expert', 'Artificial'), ('Artificial', 'Intelligence'), ('Intelligence', '('), ('(', 'AI'), ('AI', ')'), (')', ','), (',', 'Search'), ('Search', 'Knowledge')]

>> Trigrams are: 
 [('RAVN', 'Systems', ','), ('Systems', ',', 'leading'), (',', 'leading', 'expert'), ('leading', 'expert', 'Artificial'), ('expert', 'Artificial', 'Intelligence'), ('Artificial', 'Intelligence', '('), ('Intelligence', '(', 'AI'), ('(', 'AI', ')'), ('AI', ')', ','), (')', ',', 'Search'), (',', 'Search', 'Knowledge')]

>> POS Tags are: 
 [('RAVN', 'NNP'), ('Systems', 'NNPS'), (',', ','), ('leading', 'VBG'), ('expert', 'JJ'), ('Artificial', 'JJ'), ('Intelligence', 'NNP'), ('(', '('), ('AI', 'NNP'), (')', ')'), (',', ','), ('Search', 'NNP'), ('Knowledge', 'NNP')]

>> Noun Phrases are: 
 ['RAVN', 'expert Artificial Intelligence', 'AI', 'Search Knowledge']

>> Named Entities are: 
 [('ORGANIZATION', 'RAVN Systems'), ('ORGANIZATION', 'Artificial Intelligence'), ('PERSON', 'Search Knowledge')] 

>> Stemming using Porter Stemmer: 
 [('RAVN', 'ravn'), ('Systems', 'system'), (',', ','), ('leading', 'lead'), ('expert', 'expert'), ('Artificial', 'artifici'), ('Intelligence', 'intellig'), ('(', '('), ('AI', 'ai'), (')', ')'), (',', ','), ('Search', 'search'), ('Knowledge', 'knowledg')]

>> Stemming using Snowball Stemmer: 
 [('RAVN', 'ravn'), ('Systems', 'system'), (',', ','), ('leading', 'lead'), ('expert', 'expert'), ('Artificial', 'artifici'), ('Intelligence', 'intellig'), ('(', '('), ('AI', 'ai'), (')', ')'), (',', ','), ('Search', 'search'), ('Knowledge', 'knowledg')]

>> Lemmatization: 
 [('RAVN', 'RAVN'), ('Systems', 'Systems'), (',', ','), ('leading', 'leading'), ('expert', 'expert'), ('Artificial', 'Artificial'), ('Intelligence', 'Intelligence'), ('(', '('), ('AI', 'AI'), (')', ')'), (',', ','), ('Search', 'Search'), ('Knowledge', 'Knowledge')]



========================================== PARAGRAPH 503 ===========================================

Management Solutions, announced the launch of a RAVN ("Applied Cognitive Engine") i.e  

------------------- Sentence 1 -------------------

Management Solutions, announced the launch of a RAVN ("Applied Cognitive Engine") i.e

>> Tokens are: 
 ['Management', 'Solutions', ',', 'announced', 'launch', 'RAVN', '(', '``', 'Applied', 'Cognitive', 'Engine', "''", ')', 'i.e']

>> Bigrams are: 
 [('Management', 'Solutions'), ('Solutions', ','), (',', 'announced'), ('announced', 'launch'), ('launch', 'RAVN'), ('RAVN', '('), ('(', '``'), ('``', 'Applied'), ('Applied', 'Cognitive'), ('Cognitive', 'Engine'), ('Engine', "''"), ("''", ')'), (')', 'i.e')]

>> Trigrams are: 
 [('Management', 'Solutions', ','), ('Solutions', ',', 'announced'), (',', 'announced', 'launch'), ('announced', 'launch', 'RAVN'), ('launch', 'RAVN', '('), ('RAVN', '(', '``'), ('(', '``', 'Applied'), ('``', 'Applied', 'Cognitive'), ('Applied', 'Cognitive', 'Engine'), ('Cognitive', 'Engine', "''"), ('Engine', "''", ')'), ("''", ')', 'i.e')]

>> POS Tags are: 
 [('Management', 'JJ'), ('Solutions', 'NNP'), (',', ','), ('announced', 'VBD'), ('launch', 'JJ'), ('RAVN', 'NNP'), ('(', '('), ('``', '``'), ('Applied', 'NNP'), ('Cognitive', 'NNP'), ('Engine', 'NNP'), ("''", "''"), (')', ')'), ('i.e', 'NN')]

>> Noun Phrases are: 
 ['Management Solutions', 'launch RAVN', 'Applied Cognitive Engine', 'i.e']

>> Named Entities are: 
 [('ORGANIZATION', 'RAVN'), ('PERSON', 'Applied Cognitive Engine')] 

>> Stemming using Porter Stemmer: 
 [('Management', 'manag'), ('Solutions', 'solut'), (',', ','), ('announced', 'announc'), ('launch', 'launch'), ('RAVN', 'ravn'), ('(', '('), ('``', '``'), ('Applied', 'appli'), ('Cognitive', 'cognit'), ('Engine', 'engin'), ("''", "''"), (')', ')'), ('i.e', 'i.e')]

>> Stemming using Snowball Stemmer: 
 [('Management', 'manag'), ('Solutions', 'solut'), (',', ','), ('announced', 'announc'), ('launch', 'launch'), ('RAVN', 'ravn'), ('(', '('), ('``', '``'), ('Applied', 'appli'), ('Cognitive', 'cognit'), ('Engine', 'engin'), ("''", "''"), (')', ')'), ('i.e', 'i.e')]

>> Lemmatization: 
 [('Management', 'Management'), ('Solutions', 'Solutions'), (',', ','), ('announced', 'announced'), ('launch', 'launch'), ('RAVN', 'RAVN'), ('(', '('), ('``', '``'), ('Applied', 'Applied'), ('Cognitive', 'Cognitive'), ('Engine', 'Engine'), ("''", "''"), (')', ')'), ('i.e', 'i.e')]



========================================== PARAGRAPH 504 ===========================================

powered software Robot to help and facilitate the GDPR ("General Data Protection  

------------------- Sentence 1 -------------------

powered software Robot to help and facilitate the GDPR ("General Data Protection

>> Tokens are: 
 ['powered', 'software', 'Robot', 'help', 'facilitate', 'GDPR', '(', '``', 'General', 'Data', 'Protection']

>> Bigrams are: 
 [('powered', 'software'), ('software', 'Robot'), ('Robot', 'help'), ('help', 'facilitate'), ('facilitate', 'GDPR'), ('GDPR', '('), ('(', '``'), ('``', 'General'), ('General', 'Data'), ('Data', 'Protection')]

>> Trigrams are: 
 [('powered', 'software', 'Robot'), ('software', 'Robot', 'help'), ('Robot', 'help', 'facilitate'), ('help', 'facilitate', 'GDPR'), ('facilitate', 'GDPR', '('), ('GDPR', '(', '``'), ('(', '``', 'General'), ('``', 'General', 'Data'), ('General', 'Data', 'Protection')]

>> POS Tags are: 
 [('powered', 'VBN'), ('software', 'NN'), ('Robot', 'NNP'), ('help', 'NN'), ('facilitate', 'VB'), ('GDPR', 'NNP'), ('(', '('), ('``', '``'), ('General', 'NNP'), ('Data', 'NNP'), ('Protection', 'NNP')]

>> Noun Phrases are: 
 ['software Robot help', 'GDPR', 'General Data Protection']

>> Named Entities are: 
 [('PERSON', 'Robot'), ('ORGANIZATION', 'GDPR'), ('PERSON', 'Data')] 

>> Stemming using Porter Stemmer: 
 [('powered', 'power'), ('software', 'softwar'), ('Robot', 'robot'), ('help', 'help'), ('facilitate', 'facilit'), ('GDPR', 'gdpr'), ('(', '('), ('``', '``'), ('General', 'gener'), ('Data', 'data'), ('Protection', 'protect')]

>> Stemming using Snowball Stemmer: 
 [('powered', 'power'), ('software', 'softwar'), ('Robot', 'robot'), ('help', 'help'), ('facilitate', 'facilit'), ('GDPR', 'gdpr'), ('(', '('), ('``', '``'), ('General', 'general'), ('Data', 'data'), ('Protection', 'protect')]

>> Lemmatization: 
 [('powered', 'powered'), ('software', 'software'), ('Robot', 'Robot'), ('help', 'help'), ('facilitate', 'facilitate'), ('GDPR', 'GDPR'), ('(', '('), ('``', '``'), ('General', 'General'), ('Data', 'Data'), ('Protection', 'Protection')]



========================================== PARAGRAPH 505 ===========================================

Regulation") compliance.  

------------------- Sentence 1 -------------------

Regulation") compliance.

>> Tokens are: 
 ['Regulation', "''", ')', 'compliance', '.']

>> Bigrams are: 
 [('Regulation', "''"), ("''", ')'), (')', 'compliance'), ('compliance', '.')]

>> Trigrams are: 
 [('Regulation', "''", ')'), ("''", ')', 'compliance'), (')', 'compliance', '.')]

>> POS Tags are: 
 [('Regulation', 'NNP'), ("''", "''"), (')', ')'), ('compliance', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Regulation', 'compliance']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Regulation', 'regul'), ("''", "''"), (')', ')'), ('compliance', 'complianc'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Regulation', 'regul'), ("''", "''"), (')', ')'), ('compliance', 'complianc'), ('.', '.')]

>> Lemmatization: 
 [('Regulation', 'Regulation'), ("''", "''"), (')', ')'), ('compliance', 'compliance'), ('.', '.')]



========================================== PARAGRAPH 506 ===========================================

The Robot uses AI techniques to automatically analyse documents and other types of data in  

------------------- Sentence 1 -------------------

The Robot uses AI techniques to automatically analyse documents and other types of data in

>> Tokens are: 
 ['The', 'Robot', 'uses', 'AI', 'techniques', 'automatically', 'analyse', 'documents', 'types', 'data']

>> Bigrams are: 
 [('The', 'Robot'), ('Robot', 'uses'), ('uses', 'AI'), ('AI', 'techniques'), ('techniques', 'automatically'), ('automatically', 'analyse'), ('analyse', 'documents'), ('documents', 'types'), ('types', 'data')]

>> Trigrams are: 
 [('The', 'Robot', 'uses'), ('Robot', 'uses', 'AI'), ('uses', 'AI', 'techniques'), ('AI', 'techniques', 'automatically'), ('techniques', 'automatically', 'analyse'), ('automatically', 'analyse', 'documents'), ('analyse', 'documents', 'types'), ('documents', 'types', 'data')]

>> POS Tags are: 
 [('The', 'DT'), ('Robot', 'NNP'), ('uses', 'VBZ'), ('AI', 'NNP'), ('techniques', 'NNS'), ('automatically', 'RB'), ('analyse', 'JJ'), ('documents', 'NNS'), ('types', 'NNS'), ('data', 'NNS')]

>> Noun Phrases are: 
 ['The Robot', 'AI techniques', 'analyse documents types data']

>> Named Entities are: 
 [('ORGANIZATION', 'Robot')] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('Robot', 'robot'), ('uses', 'use'), ('AI', 'ai'), ('techniques', 'techniqu'), ('automatically', 'automat'), ('analyse', 'analys'), ('documents', 'document'), ('types', 'type'), ('data', 'data')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('Robot', 'robot'), ('uses', 'use'), ('AI', 'ai'), ('techniques', 'techniqu'), ('automatically', 'automat'), ('analyse', 'analys'), ('documents', 'document'), ('types', 'type'), ('data', 'data')]

>> Lemmatization: 
 [('The', 'The'), ('Robot', 'Robot'), ('uses', 'us'), ('AI', 'AI'), ('techniques', 'technique'), ('automatically', 'automatically'), ('analyse', 'analyse'), ('documents', 'document'), ('types', 'type'), ('data', 'data')]



========================================== PARAGRAPH 507 ===========================================

any business system which is subject to GDPR rules. It allows users to quickly and easily  

------------------- Sentence 1 -------------------

any business system which is subject to GDPR rules.

>> Tokens are: 
 ['business', 'system', 'subject', 'GDPR', 'rules', '.']

>> Bigrams are: 
 [('business', 'system'), ('system', 'subject'), ('subject', 'GDPR'), ('GDPR', 'rules'), ('rules', '.')]

>> Trigrams are: 
 [('business', 'system', 'subject'), ('system', 'subject', 'GDPR'), ('subject', 'GDPR', 'rules'), ('GDPR', 'rules', '.')]

>> POS Tags are: 
 [('business', 'NN'), ('system', 'NN'), ('subject', 'JJ'), ('GDPR', 'NNP'), ('rules', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['business system', 'subject GDPR rules']

>> Named Entities are: 
 [('ORGANIZATION', 'GDPR')] 

>> Stemming using Porter Stemmer: 
 [('business', 'busi'), ('system', 'system'), ('subject', 'subject'), ('GDPR', 'gdpr'), ('rules', 'rule'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('business', 'busi'), ('system', 'system'), ('subject', 'subject'), ('GDPR', 'gdpr'), ('rules', 'rule'), ('.', '.')]

>> Lemmatization: 
 [('business', 'business'), ('system', 'system'), ('subject', 'subject'), ('GDPR', 'GDPR'), ('rules', 'rule'), ('.', '.')]


------------------- Sentence 2 -------------------

It allows users to quickly and easily

>> Tokens are: 
 ['It', 'allows', 'users', 'quickly', 'easily']

>> Bigrams are: 
 [('It', 'allows'), ('allows', 'users'), ('users', 'quickly'), ('quickly', 'easily')]

>> Trigrams are: 
 [('It', 'allows', 'users'), ('allows', 'users', 'quickly'), ('users', 'quickly', 'easily')]

>> POS Tags are: 
 [('It', 'PRP'), ('allows', 'VBZ'), ('users', 'NNS'), ('quickly', 'RB'), ('easily', 'RB')]

>> Noun Phrases are: 
 ['users']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('It', 'it'), ('allows', 'allow'), ('users', 'user'), ('quickly', 'quickli'), ('easily', 'easili')]

>> Stemming using Snowball Stemmer: 
 [('It', 'it'), ('allows', 'allow'), ('users', 'user'), ('quickly', 'quick'), ('easily', 'easili')]

>> Lemmatization: 
 [('It', 'It'), ('allows', 'allows'), ('users', 'user'), ('quickly', 'quickly'), ('easily', 'easily')]



========================================== PARAGRAPH 508 ===========================================

search, retrieve, flag, classify and report on data mediated to be supersensitive under GDPR.  

------------------- Sentence 1 -------------------

search, retrieve, flag, classify and report on data mediated to be supersensitive under GDPR.

>> Tokens are: 
 ['search', ',', 'retrieve', ',', 'flag', ',', 'classify', 'report', 'data', 'mediated', 'supersensitive', 'GDPR', '.']

>> Bigrams are: 
 [('search', ','), (',', 'retrieve'), ('retrieve', ','), (',', 'flag'), ('flag', ','), (',', 'classify'), ('classify', 'report'), ('report', 'data'), ('data', 'mediated'), ('mediated', 'supersensitive'), ('supersensitive', 'GDPR'), ('GDPR', '.')]

>> Trigrams are: 
 [('search', ',', 'retrieve'), (',', 'retrieve', ','), ('retrieve', ',', 'flag'), (',', 'flag', ','), ('flag', ',', 'classify'), (',', 'classify', 'report'), ('classify', 'report', 'data'), ('report', 'data', 'mediated'), ('data', 'mediated', 'supersensitive'), ('mediated', 'supersensitive', 'GDPR'), ('supersensitive', 'GDPR', '.')]

>> POS Tags are: 
 [('search', 'NN'), (',', ','), ('retrieve', 'VBP'), (',', ','), ('flag', 'NN'), (',', ','), ('classify', 'VB'), ('report', 'NN'), ('data', 'NNS'), ('mediated', 'VBD'), ('supersensitive', 'JJ'), ('GDPR', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['search', 'flag', 'report data', 'supersensitive GDPR']

>> Named Entities are: 
 [('ORGANIZATION', 'GDPR')] 

>> Stemming using Porter Stemmer: 
 [('search', 'search'), (',', ','), ('retrieve', 'retriev'), (',', ','), ('flag', 'flag'), (',', ','), ('classify', 'classifi'), ('report', 'report'), ('data', 'data'), ('mediated', 'mediat'), ('supersensitive', 'supersensit'), ('GDPR', 'gdpr'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('search', 'search'), (',', ','), ('retrieve', 'retriev'), (',', ','), ('flag', 'flag'), (',', ','), ('classify', 'classifi'), ('report', 'report'), ('data', 'data'), ('mediated', 'mediat'), ('supersensitive', 'supersensit'), ('GDPR', 'gdpr'), ('.', '.')]

>> Lemmatization: 
 [('search', 'search'), (',', ','), ('retrieve', 'retrieve'), (',', ','), ('flag', 'flag'), (',', ','), ('classify', 'classify'), ('report', 'report'), ('data', 'data'), ('mediated', 'mediated'), ('supersensitive', 'supersensitive'), ('GDPR', 'GDPR'), ('.', '.')]



========================================== PARAGRAPH 509 ===========================================

Users also have the ability to identify personal data from documents, view feeds on the latest  

------------------- Sentence 1 -------------------

Users also have the ability to identify personal data from documents, view feeds on the latest

>> Tokens are: 
 ['Users', 'also', 'ability', 'identify', 'personal', 'data', 'documents', ',', 'view', 'feeds', 'latest']

>> Bigrams are: 
 [('Users', 'also'), ('also', 'ability'), ('ability', 'identify'), ('identify', 'personal'), ('personal', 'data'), ('data', 'documents'), ('documents', ','), (',', 'view'), ('view', 'feeds'), ('feeds', 'latest')]

>> Trigrams are: 
 [('Users', 'also', 'ability'), ('also', 'ability', 'identify'), ('ability', 'identify', 'personal'), ('identify', 'personal', 'data'), ('personal', 'data', 'documents'), ('data', 'documents', ','), ('documents', ',', 'view'), (',', 'view', 'feeds'), ('view', 'feeds', 'latest')]

>> POS Tags are: 
 [('Users', 'NNS'), ('also', 'RB'), ('ability', 'NN'), ('identify', 'VBP'), ('personal', 'JJ'), ('data', 'NN'), ('documents', 'NNS'), (',', ','), ('view', 'NN'), ('feeds', 'NNS'), ('latest', 'JJS')]

>> Noun Phrases are: 
 ['Users', 'ability', 'personal data documents', 'view feeds']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Users', 'user'), ('also', 'also'), ('ability', 'abil'), ('identify', 'identifi'), ('personal', 'person'), ('data', 'data'), ('documents', 'document'), (',', ','), ('view', 'view'), ('feeds', 'feed'), ('latest', 'latest')]

>> Stemming using Snowball Stemmer: 
 [('Users', 'user'), ('also', 'also'), ('ability', 'abil'), ('identify', 'identifi'), ('personal', 'person'), ('data', 'data'), ('documents', 'document'), (',', ','), ('view', 'view'), ('feeds', 'feed'), ('latest', 'latest')]

>> Lemmatization: 
 [('Users', 'Users'), ('also', 'also'), ('ability', 'ability'), ('identify', 'identify'), ('personal', 'personal'), ('data', 'data'), ('documents', 'document'), (',', ','), ('view', 'view'), ('feeds', 'feed'), ('latest', 'latest')]



========================================== PARAGRAPH 510 ===========================================

personal data that requires attention and provide reports on the data suggested to be deleted or  

------------------- Sentence 1 -------------------

personal data that requires attention and provide reports on the data suggested to be deleted or

>> Tokens are: 
 ['personal', 'data', 'requires', 'attention', 'provide', 'reports', 'data', 'suggested', 'deleted']

>> Bigrams are: 
 [('personal', 'data'), ('data', 'requires'), ('requires', 'attention'), ('attention', 'provide'), ('provide', 'reports'), ('reports', 'data'), ('data', 'suggested'), ('suggested', 'deleted')]

>> Trigrams are: 
 [('personal', 'data', 'requires'), ('data', 'requires', 'attention'), ('requires', 'attention', 'provide'), ('attention', 'provide', 'reports'), ('provide', 'reports', 'data'), ('reports', 'data', 'suggested'), ('data', 'suggested', 'deleted')]

>> POS Tags are: 
 [('personal', 'JJ'), ('data', 'NNS'), ('requires', 'VBZ'), ('attention', 'NN'), ('provide', 'NN'), ('reports', 'NNS'), ('data', 'NNS'), ('suggested', 'VBD'), ('deleted', 'JJ')]

>> Noun Phrases are: 
 ['personal data', 'attention provide reports data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('personal', 'person'), ('data', 'data'), ('requires', 'requir'), ('attention', 'attent'), ('provide', 'provid'), ('reports', 'report'), ('data', 'data'), ('suggested', 'suggest'), ('deleted', 'delet')]

>> Stemming using Snowball Stemmer: 
 [('personal', 'person'), ('data', 'data'), ('requires', 'requir'), ('attention', 'attent'), ('provide', 'provid'), ('reports', 'report'), ('data', 'data'), ('suggested', 'suggest'), ('deleted', 'delet')]

>> Lemmatization: 
 [('personal', 'personal'), ('data', 'data'), ('requires', 'requires'), ('attention', 'attention'), ('provide', 'provide'), ('reports', 'report'), ('data', 'data'), ('suggested', 'suggested'), ('deleted', 'deleted')]



========================================== PARAGRAPH 511 ===========================================

secured.  RAVN's GDPR Robot is also able to hasten requests for information (Data Subject  

------------------- Sentence 1 -------------------

secured.

>> Tokens are: 
 ['secured', '.']

>> Bigrams are: 
 [('secured', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('secured', 'VBN'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('secured', 'secur'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('secured', 'secur'), ('.', '.')]

>> Lemmatization: 
 [('secured', 'secured'), ('.', '.')]


------------------- Sentence 2 -------------------

RAVN's GDPR Robot is also able to hasten requests for information (Data Subject

>> Tokens are: 
 ['RAVN', "'s", 'GDPR', 'Robot', 'also', 'able', 'hasten', 'requests', 'information', '(', 'Data', 'Subject']

>> Bigrams are: 
 [('RAVN', "'s"), ("'s", 'GDPR'), ('GDPR', 'Robot'), ('Robot', 'also'), ('also', 'able'), ('able', 'hasten'), ('hasten', 'requests'), ('requests', 'information'), ('information', '('), ('(', 'Data'), ('Data', 'Subject')]

>> Trigrams are: 
 [('RAVN', "'s", 'GDPR'), ("'s", 'GDPR', 'Robot'), ('GDPR', 'Robot', 'also'), ('Robot', 'also', 'able'), ('also', 'able', 'hasten'), ('able', 'hasten', 'requests'), ('hasten', 'requests', 'information'), ('requests', 'information', '('), ('information', '(', 'Data'), ('(', 'Data', 'Subject')]

>> POS Tags are: 
 [('RAVN', 'NNP'), ("'s", 'POS'), ('GDPR', 'NNP'), ('Robot', 'NNP'), ('also', 'RB'), ('able', 'JJ'), ('hasten', 'JJ'), ('requests', 'NNS'), ('information', 'NN'), ('(', '('), ('Data', 'NNP'), ('Subject', 'NNP')]

>> Noun Phrases are: 
 ['RAVN', 'GDPR Robot', 'able hasten requests information', 'Data Subject']

>> Named Entities are: 
 [('ORGANIZATION', 'RAVN'), ('ORGANIZATION', 'GDPR Robot'), ('ORGANIZATION', 'Data Subject')] 

>> Stemming using Porter Stemmer: 
 [('RAVN', 'ravn'), ("'s", "'s"), ('GDPR', 'gdpr'), ('Robot', 'robot'), ('also', 'also'), ('able', 'abl'), ('hasten', 'hasten'), ('requests', 'request'), ('information', 'inform'), ('(', '('), ('Data', 'data'), ('Subject', 'subject')]

>> Stemming using Snowball Stemmer: 
 [('RAVN', 'ravn'), ("'s", "'s"), ('GDPR', 'gdpr'), ('Robot', 'robot'), ('also', 'also'), ('able', 'abl'), ('hasten', 'hasten'), ('requests', 'request'), ('information', 'inform'), ('(', '('), ('Data', 'data'), ('Subject', 'subject')]

>> Lemmatization: 
 [('RAVN', 'RAVN'), ("'s", "'s"), ('GDPR', 'GDPR'), ('Robot', 'Robot'), ('also', 'also'), ('able', 'able'), ('hasten', 'hasten'), ('requests', 'request'), ('information', 'information'), ('(', '('), ('Data', 'Data'), ('Subject', 'Subject')]



========================================== PARAGRAPH 512 ===========================================

Access Requests - "DSAR") in a simple and efficient way, removing the need for a physical  

------------------- Sentence 1 -------------------

Access Requests - "DSAR") in a simple and efficient way, removing the need for a physical

>> Tokens are: 
 ['Access', 'Requests', '-', '``', 'DSAR', "''", ')', 'simple', 'efficient', 'way', ',', 'removing', 'need', 'physical']

>> Bigrams are: 
 [('Access', 'Requests'), ('Requests', '-'), ('-', '``'), ('``', 'DSAR'), ('DSAR', "''"), ("''", ')'), (')', 'simple'), ('simple', 'efficient'), ('efficient', 'way'), ('way', ','), (',', 'removing'), ('removing', 'need'), ('need', 'physical')]

>> Trigrams are: 
 [('Access', 'Requests', '-'), ('Requests', '-', '``'), ('-', '``', 'DSAR'), ('``', 'DSAR', "''"), ('DSAR', "''", ')'), ("''", ')', 'simple'), (')', 'simple', 'efficient'), ('simple', 'efficient', 'way'), ('efficient', 'way', ','), ('way', ',', 'removing'), (',', 'removing', 'need'), ('removing', 'need', 'physical')]

>> POS Tags are: 
 [('Access', 'NN'), ('Requests', 'NNPS'), ('-', ':'), ('``', '``'), ('DSAR', 'NNP'), ("''", "''"), (')', ')'), ('simple', 'JJ'), ('efficient', 'JJ'), ('way', 'NN'), (',', ','), ('removing', 'VBG'), ('need', 'NN'), ('physical', 'JJ')]

>> Noun Phrases are: 
 ['Access', 'DSAR', 'simple efficient way', 'need']

>> Named Entities are: 
 [('ORGANIZATION', 'Access Requests')] 

>> Stemming using Porter Stemmer: 
 [('Access', 'access'), ('Requests', 'request'), ('-', '-'), ('``', '``'), ('DSAR', 'dsar'), ("''", "''"), (')', ')'), ('simple', 'simpl'), ('efficient', 'effici'), ('way', 'way'), (',', ','), ('removing', 'remov'), ('need', 'need'), ('physical', 'physic')]

>> Stemming using Snowball Stemmer: 
 [('Access', 'access'), ('Requests', 'request'), ('-', '-'), ('``', '``'), ('DSAR', 'dsar'), ("''", "''"), (')', ')'), ('simple', 'simpl'), ('efficient', 'effici'), ('way', 'way'), (',', ','), ('removing', 'remov'), ('need', 'need'), ('physical', 'physic')]

>> Lemmatization: 
 [('Access', 'Access'), ('Requests', 'Requests'), ('-', '-'), ('``', '``'), ('DSAR', 'DSAR'), ("''", "''"), (')', ')'), ('simple', 'simple'), ('efficient', 'efficient'), ('way', 'way'), (',', ','), ('removing', 'removing'), ('need', 'need'), ('physical', 'physical')]



========================================== PARAGRAPH 513 ===========================================

approach to these requests which tends to be very labour thorough. Peter Wallqvist, CSO at  

------------------- Sentence 1 -------------------

approach to these requests which tends to be very labour thorough.

>> Tokens are: 
 ['approach', 'requests', 'tends', 'labour', 'thorough', '.']

>> Bigrams are: 
 [('approach', 'requests'), ('requests', 'tends'), ('tends', 'labour'), ('labour', 'thorough'), ('thorough', '.')]

>> Trigrams are: 
 [('approach', 'requests', 'tends'), ('requests', 'tends', 'labour'), ('tends', 'labour', 'thorough'), ('labour', 'thorough', '.')]

>> POS Tags are: 
 [('approach', 'NN'), ('requests', 'NNS'), ('tends', 'VBZ'), ('labour', 'JJ'), ('thorough', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['approach requests', 'labour thorough']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('approach', 'approach'), ('requests', 'request'), ('tends', 'tend'), ('labour', 'labour'), ('thorough', 'thorough'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('approach', 'approach'), ('requests', 'request'), ('tends', 'tend'), ('labour', 'labour'), ('thorough', 'thorough'), ('.', '.')]

>> Lemmatization: 
 [('approach', 'approach'), ('requests', 'request'), ('tends', 'tends'), ('labour', 'labour'), ('thorough', 'thorough'), ('.', '.')]


------------------- Sentence 2 -------------------

Peter Wallqvist, CSO at

>> Tokens are: 
 ['Peter', 'Wallqvist', ',', 'CSO']

>> Bigrams are: 
 [('Peter', 'Wallqvist'), ('Wallqvist', ','), (',', 'CSO')]

>> Trigrams are: 
 [('Peter', 'Wallqvist', ','), ('Wallqvist', ',', 'CSO')]

>> POS Tags are: 
 [('Peter', 'NNP'), ('Wallqvist', 'NNP'), (',', ','), ('CSO', 'NNP')]

>> Noun Phrases are: 
 ['Peter Wallqvist', 'CSO']

>> Named Entities are: 
 [('PERSON', 'Peter Wallqvist'), ('ORGANIZATION', 'CSO')] 

>> Stemming using Porter Stemmer: 
 [('Peter', 'peter'), ('Wallqvist', 'wallqvist'), (',', ','), ('CSO', 'cso')]

>> Stemming using Snowball Stemmer: 
 [('Peter', 'peter'), ('Wallqvist', 'wallqvist'), (',', ','), ('CSO', 'cso')]

>> Lemmatization: 
 [('Peter', 'Peter'), ('Wallqvist', 'Wallqvist'), (',', ','), ('CSO', 'CSO')]



========================================== PARAGRAPH 514 ===========================================

RAVN Systems commented, "GDPR compliance is of universal paramountcy as it will  

------------------- Sentence 1 -------------------

RAVN Systems commented, "GDPR compliance is of universal paramountcy as it will

>> Tokens are: 
 ['RAVN', 'Systems', 'commented', ',', '``', 'GDPR', 'compliance', 'universal', 'paramountcy']

>> Bigrams are: 
 [('RAVN', 'Systems'), ('Systems', 'commented'), ('commented', ','), (',', '``'), ('``', 'GDPR'), ('GDPR', 'compliance'), ('compliance', 'universal'), ('universal', 'paramountcy')]

>> Trigrams are: 
 [('RAVN', 'Systems', 'commented'), ('Systems', 'commented', ','), ('commented', ',', '``'), (',', '``', 'GDPR'), ('``', 'GDPR', 'compliance'), ('GDPR', 'compliance', 'universal'), ('compliance', 'universal', 'paramountcy')]

>> POS Tags are: 
 [('RAVN', 'NNP'), ('Systems', 'NNPS'), ('commented', 'VBD'), (',', ','), ('``', '``'), ('GDPR', 'NNP'), ('compliance', 'NN'), ('universal', 'NN'), ('paramountcy', 'NN')]

>> Noun Phrases are: 
 ['RAVN', 'GDPR compliance universal paramountcy']

>> Named Entities are: 
 [('ORGANIZATION', 'RAVN Systems'), ('ORGANIZATION', 'GDPR')] 

>> Stemming using Porter Stemmer: 
 [('RAVN', 'ravn'), ('Systems', 'system'), ('commented', 'comment'), (',', ','), ('``', '``'), ('GDPR', 'gdpr'), ('compliance', 'complianc'), ('universal', 'univers'), ('paramountcy', 'paramountci')]

>> Stemming using Snowball Stemmer: 
 [('RAVN', 'ravn'), ('Systems', 'system'), ('commented', 'comment'), (',', ','), ('``', '``'), ('GDPR', 'gdpr'), ('compliance', 'complianc'), ('universal', 'univers'), ('paramountcy', 'paramountci')]

>> Lemmatization: 
 [('RAVN', 'RAVN'), ('Systems', 'Systems'), ('commented', 'commented'), (',', ','), ('``', '``'), ('GDPR', 'GDPR'), ('compliance', 'compliance'), ('universal', 'universal'), ('paramountcy', 'paramountcy')]



========================================== PARAGRAPH 515 ===========================================

exploit to any organisation that control and process data concerning EU citizens.  

------------------- Sentence 1 -------------------

exploit to any organisation that control and process data concerning EU citizens.

>> Tokens are: 
 ['exploit', 'organisation', 'control', 'process', 'data', 'concerning', 'EU', 'citizens', '.']

>> Bigrams are: 
 [('exploit', 'organisation'), ('organisation', 'control'), ('control', 'process'), ('process', 'data'), ('data', 'concerning'), ('concerning', 'EU'), ('EU', 'citizens'), ('citizens', '.')]

>> Trigrams are: 
 [('exploit', 'organisation', 'control'), ('organisation', 'control', 'process'), ('control', 'process', 'data'), ('process', 'data', 'concerning'), ('data', 'concerning', 'EU'), ('concerning', 'EU', 'citizens'), ('EU', 'citizens', '.')]

>> POS Tags are: 
 [('exploit', 'JJ'), ('organisation', 'NN'), ('control', 'NN'), ('process', 'NN'), ('data', 'NNS'), ('concerning', 'VBG'), ('EU', 'NNP'), ('citizens', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['exploit organisation control process data', 'EU citizens']

>> Named Entities are: 
 [('GPE', 'EU')] 

>> Stemming using Porter Stemmer: 
 [('exploit', 'exploit'), ('organisation', 'organis'), ('control', 'control'), ('process', 'process'), ('data', 'data'), ('concerning', 'concern'), ('EU', 'eu'), ('citizens', 'citizen'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('exploit', 'exploit'), ('organisation', 'organis'), ('control', 'control'), ('process', 'process'), ('data', 'data'), ('concerning', 'concern'), ('EU', 'eu'), ('citizens', 'citizen'), ('.', '.')]

>> Lemmatization: 
 [('exploit', 'exploit'), ('organisation', 'organisation'), ('control', 'control'), ('process', 'process'), ('data', 'data'), ('concerning', 'concerning'), ('EU', 'EU'), ('citizens', 'citizen'), ('.', '.')]



========================================== PARAGRAPH 516 ===========================================

LINK:http://markets.financialcontent.com/stocks/news/read/33888795/RAVN_Systems_Launch_the_ACE_Po 

------------------- Sentence 1 -------------------

LINK:http://markets.financialcontent.com/stocks/news/read/33888795/RAVN_Systems_Launch_the_ACE_Po

>> Tokens are: 
 ['LINK', ':', 'http', ':', '//markets.financialcontent.com/stocks/news/read/33888795/RAVN_Systems_Launch_the_ACE_Po']

>> Bigrams are: 
 [('LINK', ':'), (':', 'http'), ('http', ':'), (':', '//markets.financialcontent.com/stocks/news/read/33888795/RAVN_Systems_Launch_the_ACE_Po')]

>> Trigrams are: 
 [('LINK', ':', 'http'), (':', 'http', ':'), ('http', ':', '//markets.financialcontent.com/stocks/news/read/33888795/RAVN_Systems_Launch_the_ACE_Po')]

>> POS Tags are: 
 [('LINK', 'NN'), (':', ':'), ('http', 'NN'), (':', ':'), ('//markets.financialcontent.com/stocks/news/read/33888795/RAVN_Systems_Launch_the_ACE_Po', 'NN')]

>> Noun Phrases are: 
 ['LINK', 'http', '//markets.financialcontent.com/stocks/news/read/33888795/RAVN_Systems_Launch_the_ACE_Po']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('LINK', 'link'), (':', ':'), ('http', 'http'), (':', ':'), ('//markets.financialcontent.com/stocks/news/read/33888795/RAVN_Systems_Launch_the_ACE_Po', '//markets.financialcontent.com/stocks/news/read/33888795/ravn_systems_launch_the_ace_po')]

>> Stemming using Snowball Stemmer: 
 [('LINK', 'link'), (':', ':'), ('http', 'http'), (':', ':'), ('//markets.financialcontent.com/stocks/news/read/33888795/RAVN_Systems_Launch_the_ACE_Po', '//markets.financialcontent.com/stocks/news/read/33888795/ravn_systems_launch_the_ace_po')]

>> Lemmatization: 
 [('LINK', 'LINK'), (':', ':'), ('http', 'http'), (':', ':'), ('//markets.financialcontent.com/stocks/news/read/33888795/RAVN_Systems_Launch_the_ACE_Po', '//markets.financialcontent.com/stocks/news/read/33888795/RAVN_Systems_Launch_the_ACE_Po')]



========================================== PARAGRAPH 517 ===========================================

wered_GDPR_Robot  

------------------- Sentence 1 -------------------

wered_GDPR_Robot

>> Tokens are: 
 ['wered_GDPR_Robot']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('wered_GDPR_Robot', 'NN')]

>> Noun Phrases are: 
 ['wered_GDPR_Robot']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('wered_GDPR_Robot', 'wered_gdpr_robot')]

>> Stemming using Snowball Stemmer: 
 [('wered_GDPR_Robot', 'wered_gdpr_robot')]

>> Lemmatization: 
 [('wered_GDPR_Robot', 'wered_GDPR_Robot')]



========================================== PARAGRAPH 518 ===========================================

8.2 Eno A Natural Language Chatbot Launched by Capital One [105] 

------------------- Sentence 1 -------------------

8.2 Eno A Natural Language Chatbot Launched by Capital One [105]

>> Tokens are: 
 ['8.2', 'Eno', 'A', 'Natural', 'Language', 'Chatbot', 'Launched', 'Capital', 'One', '[', '105', ']']

>> Bigrams are: 
 [('8.2', 'Eno'), ('Eno', 'A'), ('A', 'Natural'), ('Natural', 'Language'), ('Language', 'Chatbot'), ('Chatbot', 'Launched'), ('Launched', 'Capital'), ('Capital', 'One'), ('One', '['), ('[', '105'), ('105', ']')]

>> Trigrams are: 
 [('8.2', 'Eno', 'A'), ('Eno', 'A', 'Natural'), ('A', 'Natural', 'Language'), ('Natural', 'Language', 'Chatbot'), ('Language', 'Chatbot', 'Launched'), ('Chatbot', 'Launched', 'Capital'), ('Launched', 'Capital', 'One'), ('Capital', 'One', '['), ('One', '[', '105'), ('[', '105', ']')]

>> POS Tags are: 
 [('8.2', 'CD'), ('Eno', 'NNP'), ('A', 'NNP'), ('Natural', 'NNP'), ('Language', 'NNP'), ('Chatbot', 'NNP'), ('Launched', 'NNP'), ('Capital', 'NNP'), ('One', 'NNP'), ('[', 'VBZ'), ('105', 'CD'), (']', 'NN')]

>> Noun Phrases are: 
 ['Eno A Natural Language Chatbot Launched Capital One', ']']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('8.2', '8.2'), ('Eno', 'eno'), ('A', 'a'), ('Natural', 'natur'), ('Language', 'languag'), ('Chatbot', 'chatbot'), ('Launched', 'launch'), ('Capital', 'capit'), ('One', 'one'), ('[', '['), ('105', '105'), (']', ']')]

>> Stemming using Snowball Stemmer: 
 [('8.2', '8.2'), ('Eno', 'eno'), ('A', 'a'), ('Natural', 'natur'), ('Language', 'languag'), ('Chatbot', 'chatbot'), ('Launched', 'launch'), ('Capital', 'capit'), ('One', 'one'), ('[', '['), ('105', '105'), (']', ']')]

>> Lemmatization: 
 [('8.2', '8.2'), ('Eno', 'Eno'), ('A', 'A'), ('Natural', 'Natural'), ('Language', 'Language'), ('Chatbot', 'Chatbot'), ('Launched', 'Launched'), ('Capital', 'Capital'), ('One', 'One'), ('[', '['), ('105', '105'), (']', ']')]



========================================== PARAGRAPH 519 ===========================================

Capital one announces chatbot for customers called Eno. Eno is a natural language chatbot  

------------------- Sentence 1 -------------------

Capital one announces chatbot for customers called Eno.

>> Tokens are: 
 ['Capital', 'one', 'announces', 'chatbot', 'customers', 'called', 'Eno', '.']

>> Bigrams are: 
 [('Capital', 'one'), ('one', 'announces'), ('announces', 'chatbot'), ('chatbot', 'customers'), ('customers', 'called'), ('called', 'Eno'), ('Eno', '.')]

>> Trigrams are: 
 [('Capital', 'one', 'announces'), ('one', 'announces', 'chatbot'), ('announces', 'chatbot', 'customers'), ('chatbot', 'customers', 'called'), ('customers', 'called', 'Eno'), ('called', 'Eno', '.')]

>> POS Tags are: 
 [('Capital', 'NN'), ('one', 'CD'), ('announces', 'VBZ'), ('chatbot', 'NN'), ('customers', 'NNS'), ('called', 'VBN'), ('Eno', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Capital', 'chatbot customers', 'Eno']

>> Named Entities are: 
 [('PERSON', 'Eno')] 

>> Stemming using Porter Stemmer: 
 [('Capital', 'capit'), ('one', 'one'), ('announces', 'announc'), ('chatbot', 'chatbot'), ('customers', 'custom'), ('called', 'call'), ('Eno', 'eno'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Capital', 'capit'), ('one', 'one'), ('announces', 'announc'), ('chatbot', 'chatbot'), ('customers', 'custom'), ('called', 'call'), ('Eno', 'eno'), ('.', '.')]

>> Lemmatization: 
 [('Capital', 'Capital'), ('one', 'one'), ('announces', 'announces'), ('chatbot', 'chatbot'), ('customers', 'customer'), ('called', 'called'), ('Eno', 'Eno'), ('.', '.')]


------------------- Sentence 2 -------------------

Eno is a natural language chatbot

>> Tokens are: 
 ['Eno', 'natural', 'language', 'chatbot']

>> Bigrams are: 
 [('Eno', 'natural'), ('natural', 'language'), ('language', 'chatbot')]

>> Trigrams are: 
 [('Eno', 'natural', 'language'), ('natural', 'language', 'chatbot')]

>> POS Tags are: 
 [('Eno', 'NNP'), ('natural', 'JJ'), ('language', 'NN'), ('chatbot', 'NN')]

>> Noun Phrases are: 
 ['Eno', 'natural language chatbot']

>> Named Entities are: 
 [('GPE', 'Eno')] 

>> Stemming using Porter Stemmer: 
 [('Eno', 'eno'), ('natural', 'natur'), ('language', 'languag'), ('chatbot', 'chatbot')]

>> Stemming using Snowball Stemmer: 
 [('Eno', 'eno'), ('natural', 'natur'), ('language', 'languag'), ('chatbot', 'chatbot')]

>> Lemmatization: 
 [('Eno', 'Eno'), ('natural', 'natural'), ('language', 'language'), ('chatbot', 'chatbot')]



========================================== PARAGRAPH 520 ===========================================

that people socialize through texting. Capital one claims that Eno is First natural language  

------------------- Sentence 1 -------------------

that people socialize through texting.

>> Tokens are: 
 ['people', 'socialize', 'texting', '.']

>> Bigrams are: 
 [('people', 'socialize'), ('socialize', 'texting'), ('texting', '.')]

>> Trigrams are: 
 [('people', 'socialize', 'texting'), ('socialize', 'texting', '.')]

>> POS Tags are: 
 [('people', 'NNS'), ('socialize', 'VBP'), ('texting', 'VBG'), ('.', '.')]

>> Noun Phrases are: 
 ['people']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('people', 'peopl'), ('socialize', 'social'), ('texting', 'text'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('people', 'peopl'), ('socialize', 'social'), ('texting', 'text'), ('.', '.')]

>> Lemmatization: 
 [('people', 'people'), ('socialize', 'socialize'), ('texting', 'texting'), ('.', '.')]


------------------- Sentence 2 -------------------

Capital one claims that Eno is First natural language

>> Tokens are: 
 ['Capital', 'one', 'claims', 'Eno', 'First', 'natural', 'language']

>> Bigrams are: 
 [('Capital', 'one'), ('one', 'claims'), ('claims', 'Eno'), ('Eno', 'First'), ('First', 'natural'), ('natural', 'language')]

>> Trigrams are: 
 [('Capital', 'one', 'claims'), ('one', 'claims', 'Eno'), ('claims', 'Eno', 'First'), ('Eno', 'First', 'natural'), ('First', 'natural', 'language')]

>> POS Tags are: 
 [('Capital', 'NN'), ('one', 'CD'), ('claims', 'VBZ'), ('Eno', 'NNP'), ('First', 'NNP'), ('natural', 'JJ'), ('language', 'NN')]

>> Noun Phrases are: 
 ['Capital', 'Eno First', 'natural language']

>> Named Entities are: 
 [('PERSON', 'Eno First')] 

>> Stemming using Porter Stemmer: 
 [('Capital', 'capit'), ('one', 'one'), ('claims', 'claim'), ('Eno', 'eno'), ('First', 'first'), ('natural', 'natur'), ('language', 'languag')]

>> Stemming using Snowball Stemmer: 
 [('Capital', 'capit'), ('one', 'one'), ('claims', 'claim'), ('Eno', 'eno'), ('First', 'first'), ('natural', 'natur'), ('language', 'languag')]

>> Lemmatization: 
 [('Capital', 'Capital'), ('one', 'one'), ('claims', 'claim'), ('Eno', 'Eno'), ('First', 'First'), ('natural', 'natural'), ('language', 'language')]



========================================== PARAGRAPH 521 ===========================================

SMS chatbot from a U.S. bank that allows customer to ask questions using natural language.  

------------------- Sentence 1 -------------------

SMS chatbot from a U.S. bank that allows customer to ask questions using natural language.

>> Tokens are: 
 ['SMS', 'chatbot', 'U.S.', 'bank', 'allows', 'customer', 'ask', 'questions', 'using', 'natural', 'language', '.']

>> Bigrams are: 
 [('SMS', 'chatbot'), ('chatbot', 'U.S.'), ('U.S.', 'bank'), ('bank', 'allows'), ('allows', 'customer'), ('customer', 'ask'), ('ask', 'questions'), ('questions', 'using'), ('using', 'natural'), ('natural', 'language'), ('language', '.')]

>> Trigrams are: 
 [('SMS', 'chatbot', 'U.S.'), ('chatbot', 'U.S.', 'bank'), ('U.S.', 'bank', 'allows'), ('bank', 'allows', 'customer'), ('allows', 'customer', 'ask'), ('customer', 'ask', 'questions'), ('ask', 'questions', 'using'), ('questions', 'using', 'natural'), ('using', 'natural', 'language'), ('natural', 'language', '.')]

>> POS Tags are: 
 [('SMS', 'NNP'), ('chatbot', 'VBZ'), ('U.S.', 'NNP'), ('bank', 'NN'), ('allows', 'VBZ'), ('customer', 'NN'), ('ask', 'NN'), ('questions', 'NNS'), ('using', 'VBG'), ('natural', 'JJ'), ('language', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['SMS', 'U.S. bank', 'customer ask questions', 'natural language']

>> Named Entities are: 
 [('ORGANIZATION', 'SMS'), ('GPE', 'U.S.')] 

>> Stemming using Porter Stemmer: 
 [('SMS', 'sm'), ('chatbot', 'chatbot'), ('U.S.', 'u.s.'), ('bank', 'bank'), ('allows', 'allow'), ('customer', 'custom'), ('ask', 'ask'), ('questions', 'question'), ('using', 'use'), ('natural', 'natur'), ('language', 'languag'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('SMS', 'sms'), ('chatbot', 'chatbot'), ('U.S.', 'u.s.'), ('bank', 'bank'), ('allows', 'allow'), ('customer', 'custom'), ('ask', 'ask'), ('questions', 'question'), ('using', 'use'), ('natural', 'natur'), ('language', 'languag'), ('.', '.')]

>> Lemmatization: 
 [('SMS', 'SMS'), ('chatbot', 'chatbot'), ('U.S.', 'U.S.'), ('bank', 'bank'), ('allows', 'allows'), ('customer', 'customer'), ('ask', 'ask'), ('questions', 'question'), ('using', 'using'), ('natural', 'natural'), ('language', 'language'), ('.', '.')]



========================================== PARAGRAPH 522 ===========================================

Customers can interact with Eno asking questions about their savings and others using a text  

------------------- Sentence 1 -------------------

Customers can interact with Eno asking questions about their savings and others using a text

>> Tokens are: 
 ['Customers', 'interact', 'Eno', 'asking', 'questions', 'savings', 'others', 'using', 'text']

>> Bigrams are: 
 [('Customers', 'interact'), ('interact', 'Eno'), ('Eno', 'asking'), ('asking', 'questions'), ('questions', 'savings'), ('savings', 'others'), ('others', 'using'), ('using', 'text')]

>> Trigrams are: 
 [('Customers', 'interact', 'Eno'), ('interact', 'Eno', 'asking'), ('Eno', 'asking', 'questions'), ('asking', 'questions', 'savings'), ('questions', 'savings', 'others'), ('savings', 'others', 'using'), ('others', 'using', 'text')]

>> POS Tags are: 
 [('Customers', 'NNS'), ('interact', 'VBP'), ('Eno', 'NNP'), ('asking', 'VBG'), ('questions', 'NNS'), ('savings', 'NNS'), ('others', 'NNS'), ('using', 'VBG'), ('text', 'NN')]

>> Noun Phrases are: 
 ['Customers', 'Eno', 'questions savings others', 'text']

>> Named Entities are: 
 [('PERSON', 'Eno')] 

>> Stemming using Porter Stemmer: 
 [('Customers', 'custom'), ('interact', 'interact'), ('Eno', 'eno'), ('asking', 'ask'), ('questions', 'question'), ('savings', 'save'), ('others', 'other'), ('using', 'use'), ('text', 'text')]

>> Stemming using Snowball Stemmer: 
 [('Customers', 'custom'), ('interact', 'interact'), ('Eno', 'eno'), ('asking', 'ask'), ('questions', 'question'), ('savings', 'save'), ('others', 'other'), ('using', 'use'), ('text', 'text')]

>> Lemmatization: 
 [('Customers', 'Customers'), ('interact', 'interact'), ('Eno', 'Eno'), ('asking', 'asking'), ('questions', 'question'), ('savings', 'saving'), ('others', 'others'), ('using', 'using'), ('text', 'text')]



========================================== PARAGRAPH 523 ===========================================

interface. Eno makes such an environment that it feels that a human is interacting. Ken  

------------------- Sentence 1 -------------------

interface.

>> Tokens are: 
 ['interface', '.']

>> Bigrams are: 
 [('interface', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('interface', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['interface']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('interface', 'interfac'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('interface', 'interfac'), ('.', '.')]

>> Lemmatization: 
 [('interface', 'interface'), ('.', '.')]


------------------- Sentence 2 -------------------

Eno makes such an environment that it feels that a human is interacting.

>> Tokens are: 
 ['Eno', 'makes', 'environment', 'feels', 'human', 'interacting', '.']

>> Bigrams are: 
 [('Eno', 'makes'), ('makes', 'environment'), ('environment', 'feels'), ('feels', 'human'), ('human', 'interacting'), ('interacting', '.')]

>> Trigrams are: 
 [('Eno', 'makes', 'environment'), ('makes', 'environment', 'feels'), ('environment', 'feels', 'human'), ('feels', 'human', 'interacting'), ('human', 'interacting', '.')]

>> POS Tags are: 
 [('Eno', 'NNP'), ('makes', 'VBZ'), ('environment', 'NN'), ('feels', 'NNS'), ('human', 'JJ'), ('interacting', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Eno', 'environment feels', 'human interacting']

>> Named Entities are: 
 [('PERSON', 'Eno')] 

>> Stemming using Porter Stemmer: 
 [('Eno', 'eno'), ('makes', 'make'), ('environment', 'environ'), ('feels', 'feel'), ('human', 'human'), ('interacting', 'interact'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Eno', 'eno'), ('makes', 'make'), ('environment', 'environ'), ('feels', 'feel'), ('human', 'human'), ('interacting', 'interact'), ('.', '.')]

>> Lemmatization: 
 [('Eno', 'Eno'), ('makes', 'make'), ('environment', 'environment'), ('feels', 'feel'), ('human', 'human'), ('interacting', 'interacting'), ('.', '.')]


------------------- Sentence 3 -------------------

Ken

>> Tokens are: 
 ['Ken']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Ken', 'NNP')]

>> Noun Phrases are: 
 ['Ken']

>> Named Entities are: 
 [('PERSON', 'Ken')] 

>> Stemming using Porter Stemmer: 
 [('Ken', 'ken')]

>> Stemming using Snowball Stemmer: 
 [('Ken', 'ken')]

>> Lemmatization: 
 [('Ken', 'Ken')]



========================================== PARAGRAPH 524 ===========================================

Dodelin, Capital One’s vice president of digital product development, said “We kind of  

------------------- Sentence 1 -------------------

Dodelin, Capital One’s vice president of digital product development, said “We kind of

>> Tokens are: 
 ['Dodelin', ',', 'Capital', 'One', '’', 'vice', 'president', 'digital', 'product', 'development', ',', 'said', '“', 'We', 'kind']

>> Bigrams are: 
 [('Dodelin', ','), (',', 'Capital'), ('Capital', 'One'), ('One', '’'), ('’', 'vice'), ('vice', 'president'), ('president', 'digital'), ('digital', 'product'), ('product', 'development'), ('development', ','), (',', 'said'), ('said', '“'), ('“', 'We'), ('We', 'kind')]

>> Trigrams are: 
 [('Dodelin', ',', 'Capital'), (',', 'Capital', 'One'), ('Capital', 'One', '’'), ('One', '’', 'vice'), ('’', 'vice', 'president'), ('vice', 'president', 'digital'), ('president', 'digital', 'product'), ('digital', 'product', 'development'), ('product', 'development', ','), ('development', ',', 'said'), (',', 'said', '“'), ('said', '“', 'We'), ('“', 'We', 'kind')]

>> POS Tags are: 
 [('Dodelin', 'NNP'), (',', ','), ('Capital', 'NNP'), ('One', 'NNP'), ('’', 'NNP'), ('vice', 'NN'), ('president', 'NN'), ('digital', 'JJ'), ('product', 'NN'), ('development', 'NN'), (',', ','), ('said', 'VBD'), ('“', 'IN'), ('We', 'PRP'), ('kind', 'NN')]

>> Noun Phrases are: 
 ['Dodelin', 'Capital One ’ vice president', 'digital product development', 'kind']

>> Named Entities are: 
 [('GPE', 'Dodelin'), ('ORGANIZATION', 'Capital One')] 

>> Stemming using Porter Stemmer: 
 [('Dodelin', 'dodelin'), (',', ','), ('Capital', 'capit'), ('One', 'one'), ('’', '’'), ('vice', 'vice'), ('president', 'presid'), ('digital', 'digit'), ('product', 'product'), ('development', 'develop'), (',', ','), ('said', 'said'), ('“', '“'), ('We', 'we'), ('kind', 'kind')]

>> Stemming using Snowball Stemmer: 
 [('Dodelin', 'dodelin'), (',', ','), ('Capital', 'capit'), ('One', 'one'), ('’', '’'), ('vice', 'vice'), ('president', 'presid'), ('digital', 'digit'), ('product', 'product'), ('development', 'develop'), (',', ','), ('said', 'said'), ('“', '“'), ('We', 'we'), ('kind', 'kind')]

>> Lemmatization: 
 [('Dodelin', 'Dodelin'), (',', ','), ('Capital', 'Capital'), ('One', 'One'), ('’', '’'), ('vice', 'vice'), ('president', 'president'), ('digital', 'digital'), ('product', 'product'), ('development', 'development'), (',', ','), ('said', 'said'), ('“', '“'), ('We', 'We'), ('kind', 'kind')]



========================================== PARAGRAPH 525 ===========================================

launched a chatbot and didn’t know it.”   

------------------- Sentence 1 -------------------

launched a chatbot and didn’t know it.”

>> Tokens are: 
 ['launched', 'chatbot', '’', 'know', '.', '”']

>> Bigrams are: 
 [('launched', 'chatbot'), ('chatbot', '’'), ('’', 'know'), ('know', '.'), ('.', '”')]

>> Trigrams are: 
 [('launched', 'chatbot', '’'), ('chatbot', '’', 'know'), ('’', 'know', '.'), ('know', '.', '”')]

>> POS Tags are: 
 [('launched', 'VBN'), ('chatbot', 'NN'), ('’', 'NN'), ('know', 'VBP'), ('.', '.'), ('”', 'VB')]

>> Noun Phrases are: 
 ['chatbot ’']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('launched', 'launch'), ('chatbot', 'chatbot'), ('’', '’'), ('know', 'know'), ('.', '.'), ('”', '”')]

>> Stemming using Snowball Stemmer: 
 [('launched', 'launch'), ('chatbot', 'chatbot'), ('’', '’'), ('know', 'know'), ('.', '.'), ('”', '”')]

>> Lemmatization: 
 [('launched', 'launched'), ('chatbot', 'chatbot'), ('’', '’'), ('know', 'know'), ('.', '.'), ('”', '”')]



========================================== PARAGRAPH 526 ===========================================

This provides a different platform than other brands that launch chatbots like Facebook  

------------------- Sentence 1 -------------------

This provides a different platform than other brands that launch chatbots like Facebook

>> Tokens are: 
 ['This', 'provides', 'different', 'platform', 'brands', 'launch', 'chatbots', 'like', 'Facebook']

>> Bigrams are: 
 [('This', 'provides'), ('provides', 'different'), ('different', 'platform'), ('platform', 'brands'), ('brands', 'launch'), ('launch', 'chatbots'), ('chatbots', 'like'), ('like', 'Facebook')]

>> Trigrams are: 
 [('This', 'provides', 'different'), ('provides', 'different', 'platform'), ('different', 'platform', 'brands'), ('platform', 'brands', 'launch'), ('brands', 'launch', 'chatbots'), ('launch', 'chatbots', 'like'), ('chatbots', 'like', 'Facebook')]

>> POS Tags are: 
 [('This', 'DT'), ('provides', 'VBZ'), ('different', 'JJ'), ('platform', 'NN'), ('brands', 'NNS'), ('launch', 'JJ'), ('chatbots', 'NNS'), ('like', 'IN'), ('Facebook', 'NNP')]

>> Noun Phrases are: 
 ['different platform brands', 'launch chatbots', 'Facebook']

>> Named Entities are: 
 [('ORGANIZATION', 'Facebook')] 

>> Stemming using Porter Stemmer: 
 [('This', 'thi'), ('provides', 'provid'), ('different', 'differ'), ('platform', 'platform'), ('brands', 'brand'), ('launch', 'launch'), ('chatbots', 'chatbot'), ('like', 'like'), ('Facebook', 'facebook')]

>> Stemming using Snowball Stemmer: 
 [('This', 'this'), ('provides', 'provid'), ('different', 'differ'), ('platform', 'platform'), ('brands', 'brand'), ('launch', 'launch'), ('chatbots', 'chatbot'), ('like', 'like'), ('Facebook', 'facebook')]

>> Lemmatization: 
 [('This', 'This'), ('provides', 'provides'), ('different', 'different'), ('platform', 'platform'), ('brands', 'brand'), ('launch', 'launch'), ('chatbots', 'chatbots'), ('like', 'like'), ('Facebook', 'Facebook')]



========================================== PARAGRAPH 527 ===========================================

Messenger and Skype. They believed that Facebook has too much access of private  

------------------- Sentence 1 -------------------

Messenger and Skype.

>> Tokens are: 
 ['Messenger', 'Skype', '.']

>> Bigrams are: 
 [('Messenger', 'Skype'), ('Skype', '.')]

>> Trigrams are: 
 [('Messenger', 'Skype', '.')]

>> POS Tags are: 
 [('Messenger', 'NNP'), ('Skype', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Messenger Skype']

>> Named Entities are: 
 [('PERSON', 'Messenger'), ('ORGANIZATION', 'Skype')] 

>> Stemming using Porter Stemmer: 
 [('Messenger', 'messeng'), ('Skype', 'skype'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Messenger', 'messeng'), ('Skype', 'skype'), ('.', '.')]

>> Lemmatization: 
 [('Messenger', 'Messenger'), ('Skype', 'Skype'), ('.', '.')]


------------------- Sentence 2 -------------------

They believed that Facebook has too much access of private

>> Tokens are: 
 ['They', 'believed', 'Facebook', 'much', 'access', 'private']

>> Bigrams are: 
 [('They', 'believed'), ('believed', 'Facebook'), ('Facebook', 'much'), ('much', 'access'), ('access', 'private')]

>> Trigrams are: 
 [('They', 'believed', 'Facebook'), ('believed', 'Facebook', 'much'), ('Facebook', 'much', 'access'), ('much', 'access', 'private')]

>> POS Tags are: 
 [('They', 'PRP'), ('believed', 'VBD'), ('Facebook', 'NNP'), ('much', 'JJ'), ('access', 'NN'), ('private', 'JJ')]

>> Noun Phrases are: 
 ['Facebook', 'much access']

>> Named Entities are: 
 [('PERSON', 'Facebook')] 

>> Stemming using Porter Stemmer: 
 [('They', 'they'), ('believed', 'believ'), ('Facebook', 'facebook'), ('much', 'much'), ('access', 'access'), ('private', 'privat')]

>> Stemming using Snowball Stemmer: 
 [('They', 'they'), ('believed', 'believ'), ('Facebook', 'facebook'), ('much', 'much'), ('access', 'access'), ('private', 'privat')]

>> Lemmatization: 
 [('They', 'They'), ('believed', 'believed'), ('Facebook', 'Facebook'), ('much', 'much'), ('access', 'access'), ('private', 'private')]



========================================== PARAGRAPH 528 ===========================================

information of a person, which could get them into trouble with privacy laws of U.S.  

------------------- Sentence 1 -------------------

information of a person, which could get them into trouble with privacy laws of U.S.

>> Tokens are: 
 ['information', 'person', ',', 'could', 'get', 'trouble', 'privacy', 'laws', 'U.S', '.']

>> Bigrams are: 
 [('information', 'person'), ('person', ','), (',', 'could'), ('could', 'get'), ('get', 'trouble'), ('trouble', 'privacy'), ('privacy', 'laws'), ('laws', 'U.S'), ('U.S', '.')]

>> Trigrams are: 
 [('information', 'person', ','), ('person', ',', 'could'), (',', 'could', 'get'), ('could', 'get', 'trouble'), ('get', 'trouble', 'privacy'), ('trouble', 'privacy', 'laws'), ('privacy', 'laws', 'U.S'), ('laws', 'U.S', '.')]

>> POS Tags are: 
 [('information', 'NN'), ('person', 'NN'), (',', ','), ('could', 'MD'), ('get', 'VB'), ('trouble', 'NN'), ('privacy', 'NN'), ('laws', 'NNS'), ('U.S', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['information person', 'trouble privacy laws U.S']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('information', 'inform'), ('person', 'person'), (',', ','), ('could', 'could'), ('get', 'get'), ('trouble', 'troubl'), ('privacy', 'privaci'), ('laws', 'law'), ('U.S', 'u.'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('information', 'inform'), ('person', 'person'), (',', ','), ('could', 'could'), ('get', 'get'), ('trouble', 'troubl'), ('privacy', 'privaci'), ('laws', 'law'), ('U.S', 'u.'), ('.', '.')]

>> Lemmatization: 
 [('information', 'information'), ('person', 'person'), (',', ','), ('could', 'could'), ('get', 'get'), ('trouble', 'trouble'), ('privacy', 'privacy'), ('laws', 'law'), ('U.S', 'U.S'), ('.', '.')]



========================================== PARAGRAPH 529 ===========================================

financial institutions work under. Like any Facebook Page admin can access full transcripts  

------------------- Sentence 1 -------------------

financial institutions work under.

>> Tokens are: 
 ['financial', 'institutions', 'work', '.']

>> Bigrams are: 
 [('financial', 'institutions'), ('institutions', 'work'), ('work', '.')]

>> Trigrams are: 
 [('financial', 'institutions', 'work'), ('institutions', 'work', '.')]

>> POS Tags are: 
 [('financial', 'JJ'), ('institutions', 'NNS'), ('work', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['financial institutions work']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('financial', 'financi'), ('institutions', 'institut'), ('work', 'work'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('financial', 'financi'), ('institutions', 'institut'), ('work', 'work'), ('.', '.')]

>> Lemmatization: 
 [('financial', 'financial'), ('institutions', 'institution'), ('work', 'work'), ('.', '.')]


------------------- Sentence 2 -------------------

Like any Facebook Page admin can access full transcripts

>> Tokens are: 
 ['Like', 'Facebook', 'Page', 'admin', 'access', 'full', 'transcripts']

>> Bigrams are: 
 [('Like', 'Facebook'), ('Facebook', 'Page'), ('Page', 'admin'), ('admin', 'access'), ('access', 'full'), ('full', 'transcripts')]

>> Trigrams are: 
 [('Like', 'Facebook', 'Page'), ('Facebook', 'Page', 'admin'), ('Page', 'admin', 'access'), ('admin', 'access', 'full'), ('access', 'full', 'transcripts')]

>> POS Tags are: 
 [('Like', 'IN'), ('Facebook', 'NNP'), ('Page', 'NNP'), ('admin', 'JJ'), ('access', 'NN'), ('full', 'JJ'), ('transcripts', 'NNS')]

>> Noun Phrases are: 
 ['Facebook Page', 'admin access', 'full transcripts']

>> Named Entities are: 
 [('PERSON', 'Facebook Page')] 

>> Stemming using Porter Stemmer: 
 [('Like', 'like'), ('Facebook', 'facebook'), ('Page', 'page'), ('admin', 'admin'), ('access', 'access'), ('full', 'full'), ('transcripts', 'transcript')]

>> Stemming using Snowball Stemmer: 
 [('Like', 'like'), ('Facebook', 'facebook'), ('Page', 'page'), ('admin', 'admin'), ('access', 'access'), ('full', 'full'), ('transcripts', 'transcript')]

>> Lemmatization: 
 [('Like', 'Like'), ('Facebook', 'Facebook'), ('Page', 'Page'), ('admin', 'admin'), ('access', 'access'), ('full', 'full'), ('transcripts', 'transcript')]



========================================== PARAGRAPH 530 ===========================================

of the bot’s conversations. If that would be the case then the admins could easily view the  

------------------- Sentence 1 -------------------

of the bot’s conversations.

>> Tokens are: 
 ['bot', '’', 'conversations', '.']

>> Bigrams are: 
 [('bot', '’'), ('’', 'conversations'), ('conversations', '.')]

>> Trigrams are: 
 [('bot', '’', 'conversations'), ('’', 'conversations', '.')]

>> POS Tags are: 
 [('bot', 'NN'), ('’', 'NN'), ('conversations', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['bot ’ conversations']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('bot', 'bot'), ('’', '’'), ('conversations', 'convers'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('bot', 'bot'), ('’', '’'), ('conversations', 'convers'), ('.', '.')]

>> Lemmatization: 
 [('bot', 'bot'), ('’', '’'), ('conversations', 'conversation'), ('.', '.')]


------------------- Sentence 2 -------------------

If that would be the case then the admins could easily view the

>> Tokens are: 
 ['If', 'would', 'case', 'admins', 'could', 'easily', 'view']

>> Bigrams are: 
 [('If', 'would'), ('would', 'case'), ('case', 'admins'), ('admins', 'could'), ('could', 'easily'), ('easily', 'view')]

>> Trigrams are: 
 [('If', 'would', 'case'), ('would', 'case', 'admins'), ('case', 'admins', 'could'), ('admins', 'could', 'easily'), ('could', 'easily', 'view')]

>> POS Tags are: 
 [('If', 'IN'), ('would', 'MD'), ('case', 'NN'), ('admins', 'NNS'), ('could', 'MD'), ('easily', 'RB'), ('view', 'VB')]

>> Noun Phrases are: 
 ['case admins']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('If', 'if'), ('would', 'would'), ('case', 'case'), ('admins', 'admin'), ('could', 'could'), ('easily', 'easili'), ('view', 'view')]

>> Stemming using Snowball Stemmer: 
 [('If', 'if'), ('would', 'would'), ('case', 'case'), ('admins', 'admin'), ('could', 'could'), ('easily', 'easili'), ('view', 'view')]

>> Lemmatization: 
 [('If', 'If'), ('would', 'would'), ('case', 'case'), ('admins', 'admins'), ('could', 'could'), ('easily', 'easily'), ('view', 'view')]



========================================== PARAGRAPH 531 ===========================================

personal banking information of customers with is not correct  

------------------- Sentence 1 -------------------

personal banking information of customers with is not correct

>> Tokens are: 
 ['personal', 'banking', 'information', 'customers', 'correct']

>> Bigrams are: 
 [('personal', 'banking'), ('banking', 'information'), ('information', 'customers'), ('customers', 'correct')]

>> Trigrams are: 
 [('personal', 'banking', 'information'), ('banking', 'information', 'customers'), ('information', 'customers', 'correct')]

>> POS Tags are: 
 [('personal', 'JJ'), ('banking', 'NN'), ('information', 'NN'), ('customers', 'NNS'), ('correct', 'VBP')]

>> Noun Phrases are: 
 ['personal banking information customers']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('personal', 'person'), ('banking', 'bank'), ('information', 'inform'), ('customers', 'custom'), ('correct', 'correct')]

>> Stemming using Snowball Stemmer: 
 [('personal', 'person'), ('banking', 'bank'), ('information', 'inform'), ('customers', 'custom'), ('correct', 'correct')]

>> Lemmatization: 
 [('personal', 'personal'), ('banking', 'banking'), ('information', 'information'), ('customers', 'customer'), ('correct', 'correct')]



========================================== PARAGRAPH 532 ===========================================

 LINK: https://www.macobserver.com/analysis/capital-one-natural-language-chatbot-eno/  

------------------- Sentence 1 -------------------

 LINK: https://www.macobserver.com/analysis/capital-one-natural-language-chatbot-eno/

>> Tokens are: 
 ['LINK', ':', 'https', ':', '//www.macobserver.com/analysis/capital-one-natural-language-chatbot-eno/']

>> Bigrams are: 
 [('LINK', ':'), (':', 'https'), ('https', ':'), (':', '//www.macobserver.com/analysis/capital-one-natural-language-chatbot-eno/')]

>> Trigrams are: 
 [('LINK', ':', 'https'), (':', 'https', ':'), ('https', ':', '//www.macobserver.com/analysis/capital-one-natural-language-chatbot-eno/')]

>> POS Tags are: 
 [('LINK', 'NN'), (':', ':'), ('https', 'NN'), (':', ':'), ('//www.macobserver.com/analysis/capital-one-natural-language-chatbot-eno/', 'JJ')]

>> Noun Phrases are: 
 ['LINK', 'https']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('LINK', 'link'), (':', ':'), ('https', 'http'), (':', ':'), ('//www.macobserver.com/analysis/capital-one-natural-language-chatbot-eno/', '//www.macobserver.com/analysis/capital-one-natural-language-chatbot-eno/')]

>> Stemming using Snowball Stemmer: 
 [('LINK', 'link'), (':', ':'), ('https', 'https'), (':', ':'), ('//www.macobserver.com/analysis/capital-one-natural-language-chatbot-eno/', '//www.macobserver.com/analysis/capital-one-natural-language-chatbot-eno/')]

>> Lemmatization: 
 [('LINK', 'LINK'), (':', ':'), ('https', 'http'), (':', ':'), ('//www.macobserver.com/analysis/capital-one-natural-language-chatbot-eno/', '//www.macobserver.com/analysis/capital-one-natural-language-chatbot-eno/')]



========================================== PARAGRAPH 533 ===========================================

8.3  Future of BI in Natural Language Processing [106]  

------------------- Sentence 1 -------------------

8.3  Future of BI in Natural Language Processing [106]

>> Tokens are: 
 ['8.3', 'Future', 'BI', 'Natural', 'Language', 'Processing', '[', '106', ']']

>> Bigrams are: 
 [('8.3', 'Future'), ('Future', 'BI'), ('BI', 'Natural'), ('Natural', 'Language'), ('Language', 'Processing'), ('Processing', '['), ('[', '106'), ('106', ']')]

>> Trigrams are: 
 [('8.3', 'Future', 'BI'), ('Future', 'BI', 'Natural'), ('BI', 'Natural', 'Language'), ('Natural', 'Language', 'Processing'), ('Language', 'Processing', '['), ('Processing', '[', '106'), ('[', '106', ']')]

>> POS Tags are: 
 [('8.3', 'CD'), ('Future', 'NNP'), ('BI', 'NNP'), ('Natural', 'NNP'), ('Language', 'NNP'), ('Processing', 'NNP'), ('[', 'VBZ'), ('106', 'CD'), (']', 'NN')]

>> Noun Phrases are: 
 ['Future BI Natural Language Processing', ']']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('8.3', '8.3'), ('Future', 'futur'), ('BI', 'bi'), ('Natural', 'natur'), ('Language', 'languag'), ('Processing', 'process'), ('[', '['), ('106', '106'), (']', ']')]

>> Stemming using Snowball Stemmer: 
 [('8.3', '8.3'), ('Future', 'futur'), ('BI', 'bi'), ('Natural', 'natur'), ('Language', 'languag'), ('Processing', 'process'), ('[', '['), ('106', '106'), (']', ']')]

>> Lemmatization: 
 [('8.3', '8.3'), ('Future', 'Future'), ('BI', 'BI'), ('Natural', 'Natural'), ('Language', 'Language'), ('Processing', 'Processing'), ('[', '['), ('106', '106'), (']', ']')]



========================================== PARAGRAPH 534 ===========================================

Several companies in Bi spaces are trying to get with the trend and trying hard to ensure that  

------------------- Sentence 1 -------------------

Several companies in Bi spaces are trying to get with the trend and trying hard to ensure that

>> Tokens are: 
 ['Several', 'companies', 'Bi', 'spaces', 'trying', 'get', 'trend', 'trying', 'hard', 'ensure']

>> Bigrams are: 
 [('Several', 'companies'), ('companies', 'Bi'), ('Bi', 'spaces'), ('spaces', 'trying'), ('trying', 'get'), ('get', 'trend'), ('trend', 'trying'), ('trying', 'hard'), ('hard', 'ensure')]

>> Trigrams are: 
 [('Several', 'companies', 'Bi'), ('companies', 'Bi', 'spaces'), ('Bi', 'spaces', 'trying'), ('spaces', 'trying', 'get'), ('trying', 'get', 'trend'), ('get', 'trend', 'trying'), ('trend', 'trying', 'hard'), ('trying', 'hard', 'ensure')]

>> POS Tags are: 
 [('Several', 'JJ'), ('companies', 'NNS'), ('Bi', 'NNP'), ('spaces', 'NNS'), ('trying', 'VBG'), ('get', 'VB'), ('trend', 'NN'), ('trying', 'VBG'), ('hard', 'JJ'), ('ensure', 'VB')]

>> Noun Phrases are: 
 ['Several companies Bi spaces', 'trend']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Several', 'sever'), ('companies', 'compani'), ('Bi', 'bi'), ('spaces', 'space'), ('trying', 'tri'), ('get', 'get'), ('trend', 'trend'), ('trying', 'tri'), ('hard', 'hard'), ('ensure', 'ensur')]

>> Stemming using Snowball Stemmer: 
 [('Several', 'sever'), ('companies', 'compani'), ('Bi', 'bi'), ('spaces', 'space'), ('trying', 'tri'), ('get', 'get'), ('trend', 'trend'), ('trying', 'tri'), ('hard', 'hard'), ('ensure', 'ensur')]

>> Lemmatization: 
 [('Several', 'Several'), ('companies', 'company'), ('Bi', 'Bi'), ('spaces', 'space'), ('trying', 'trying'), ('get', 'get'), ('trend', 'trend'), ('trying', 'trying'), ('hard', 'hard'), ('ensure', 'ensure')]



========================================== PARAGRAPH 535 ===========================================

data becomes more friendly and easily accessible. But still there is long way for this.BI will  

------------------- Sentence 1 -------------------

data becomes more friendly and easily accessible.

>> Tokens are: 
 ['data', 'becomes', 'friendly', 'easily', 'accessible', '.']

>> Bigrams are: 
 [('data', 'becomes'), ('becomes', 'friendly'), ('friendly', 'easily'), ('easily', 'accessible'), ('accessible', '.')]

>> Trigrams are: 
 [('data', 'becomes', 'friendly'), ('becomes', 'friendly', 'easily'), ('friendly', 'easily', 'accessible'), ('easily', 'accessible', '.')]

>> POS Tags are: 
 [('data', 'NNS'), ('becomes', 'NNS'), ('friendly', 'RB'), ('easily', 'RB'), ('accessible', 'JJ'), ('.', '.')]

>> Noun Phrases are: 
 ['data becomes']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('data', 'data'), ('becomes', 'becom'), ('friendly', 'friendli'), ('easily', 'easili'), ('accessible', 'access'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('data', 'data'), ('becomes', 'becom'), ('friendly', 'friend'), ('easily', 'easili'), ('accessible', 'access'), ('.', '.')]

>> Lemmatization: 
 [('data', 'data'), ('becomes', 'becomes'), ('friendly', 'friendly'), ('easily', 'easily'), ('accessible', 'accessible'), ('.', '.')]


------------------- Sentence 2 -------------------

But still there is long way for this.BI will

>> Tokens are: 
 ['But', 'still', 'long', 'way', 'this.BI']

>> Bigrams are: 
 [('But', 'still'), ('still', 'long'), ('long', 'way'), ('way', 'this.BI')]

>> Trigrams are: 
 [('But', 'still', 'long'), ('still', 'long', 'way'), ('long', 'way', 'this.BI')]

>> POS Tags are: 
 [('But', 'CC'), ('still', 'RB'), ('long', 'JJ'), ('way', 'NN'), ('this.BI', 'NN')]

>> Noun Phrases are: 
 ['long way this.BI']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('But', 'but'), ('still', 'still'), ('long', 'long'), ('way', 'way'), ('this.BI', 'this.bi')]

>> Stemming using Snowball Stemmer: 
 [('But', 'but'), ('still', 'still'), ('long', 'long'), ('way', 'way'), ('this.BI', 'this.bi')]

>> Lemmatization: 
 [('But', 'But'), ('still', 'still'), ('long', 'long'), ('way', 'way'), ('this.BI', 'this.BI')]



========================================== PARAGRAPH 536 ===========================================

also make it easier to access as GUI is not needed. Because now a days the queries are made  

------------------- Sentence 1 -------------------

also make it easier to access as GUI is not needed.

>> Tokens are: 
 ['also', 'make', 'easier', 'access', 'GUI', 'needed', '.']

>> Bigrams are: 
 [('also', 'make'), ('make', 'easier'), ('easier', 'access'), ('access', 'GUI'), ('GUI', 'needed'), ('needed', '.')]

>> Trigrams are: 
 [('also', 'make', 'easier'), ('make', 'easier', 'access'), ('easier', 'access', 'GUI'), ('access', 'GUI', 'needed'), ('GUI', 'needed', '.')]

>> POS Tags are: 
 [('also', 'RB'), ('make', 'VBP'), ('easier', 'JJR'), ('access', 'NN'), ('GUI', 'NNP'), ('needed', 'VBD'), ('.', '.')]

>> Noun Phrases are: 
 ['access GUI']

>> Named Entities are: 
 [('ORGANIZATION', 'GUI')] 

>> Stemming using Porter Stemmer: 
 [('also', 'also'), ('make', 'make'), ('easier', 'easier'), ('access', 'access'), ('GUI', 'gui'), ('needed', 'need'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('also', 'also'), ('make', 'make'), ('easier', 'easier'), ('access', 'access'), ('GUI', 'gui'), ('needed', 'need'), ('.', '.')]

>> Lemmatization: 
 [('also', 'also'), ('make', 'make'), ('easier', 'easier'), ('access', 'access'), ('GUI', 'GUI'), ('needed', 'needed'), ('.', '.')]


------------------- Sentence 2 -------------------

Because now a days the queries are made

>> Tokens are: 
 ['Because', 'days', 'queries', 'made']

>> Bigrams are: 
 [('Because', 'days'), ('days', 'queries'), ('queries', 'made')]

>> Trigrams are: 
 [('Because', 'days', 'queries'), ('days', 'queries', 'made')]

>> POS Tags are: 
 [('Because', 'IN'), ('days', 'NNS'), ('queries', 'NNS'), ('made', 'VBD')]

>> Noun Phrases are: 
 ['days queries']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Because', 'becaus'), ('days', 'day'), ('queries', 'queri'), ('made', 'made')]

>> Stemming using Snowball Stemmer: 
 [('Because', 'becaus'), ('days', 'day'), ('queries', 'queri'), ('made', 'made')]

>> Lemmatization: 
 [('Because', 'Because'), ('days', 'day'), ('queries', 'query'), ('made', 'made')]



========================================== PARAGRAPH 537 ===========================================

by text or voice command on smartphones.one of the most common example is Google might  

------------------- Sentence 1 -------------------

by text or voice command on smartphones.one of the most common example is Google might

>> Tokens are: 
 ['text', 'voice', 'command', 'smartphones.one', 'common', 'example', 'Google', 'might']

>> Bigrams are: 
 [('text', 'voice'), ('voice', 'command'), ('command', 'smartphones.one'), ('smartphones.one', 'common'), ('common', 'example'), ('example', 'Google'), ('Google', 'might')]

>> Trigrams are: 
 [('text', 'voice', 'command'), ('voice', 'command', 'smartphones.one'), ('command', 'smartphones.one', 'common'), ('smartphones.one', 'common', 'example'), ('common', 'example', 'Google'), ('example', 'Google', 'might')]

>> POS Tags are: 
 [('text', 'JJ'), ('voice', 'NN'), ('command', 'NN'), ('smartphones.one', 'NN'), ('common', 'JJ'), ('example', 'NN'), ('Google', 'NNP'), ('might', 'MD')]

>> Noun Phrases are: 
 ['text voice command smartphones.one', 'common example Google']

>> Named Entities are: 
 [('PERSON', 'Google')] 

>> Stemming using Porter Stemmer: 
 [('text', 'text'), ('voice', 'voic'), ('command', 'command'), ('smartphones.one', 'smartphones.on'), ('common', 'common'), ('example', 'exampl'), ('Google', 'googl'), ('might', 'might')]

>> Stemming using Snowball Stemmer: 
 [('text', 'text'), ('voice', 'voic'), ('command', 'command'), ('smartphones.one', 'smartphones.on'), ('common', 'common'), ('example', 'exampl'), ('Google', 'googl'), ('might', 'might')]

>> Lemmatization: 
 [('text', 'text'), ('voice', 'voice'), ('command', 'command'), ('smartphones.one', 'smartphones.one'), ('common', 'common'), ('example', 'example'), ('Google', 'Google'), ('might', 'might')]



========================================== PARAGRAPH 538 ===========================================

tell you today what will be the tomorrows weather. But soon enough, we will be able to ask  

------------------- Sentence 1 -------------------

tell you today what will be the tomorrows weather.

>> Tokens are: 
 ['tell', 'today', 'tomorrows', 'weather', '.']

>> Bigrams are: 
 [('tell', 'today'), ('today', 'tomorrows'), ('tomorrows', 'weather'), ('weather', '.')]

>> Trigrams are: 
 [('tell', 'today', 'tomorrows'), ('today', 'tomorrows', 'weather'), ('tomorrows', 'weather', '.')]

>> POS Tags are: 
 [('tell', 'NN'), ('today', 'NN'), ('tomorrows', 'VBZ'), ('weather', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['tell today', 'weather']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('tell', 'tell'), ('today', 'today'), ('tomorrows', 'tomorrow'), ('weather', 'weather'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('tell', 'tell'), ('today', 'today'), ('tomorrows', 'tomorrow'), ('weather', 'weather'), ('.', '.')]

>> Lemmatization: 
 [('tell', 'tell'), ('today', 'today'), ('tomorrows', 'tomorrow'), ('weather', 'weather'), ('.', '.')]


------------------- Sentence 2 -------------------

But soon enough, we will be able to ask

>> Tokens are: 
 ['But', 'soon', 'enough', ',', 'able', 'ask']

>> Bigrams are: 
 [('But', 'soon'), ('soon', 'enough'), ('enough', ','), (',', 'able'), ('able', 'ask')]

>> Trigrams are: 
 [('But', 'soon', 'enough'), ('soon', 'enough', ','), ('enough', ',', 'able'), (',', 'able', 'ask')]

>> POS Tags are: 
 [('But', 'CC'), ('soon', 'RB'), ('enough', 'RB'), (',', ','), ('able', 'JJ'), ('ask', 'NN')]

>> Noun Phrases are: 
 ['able ask']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('But', 'but'), ('soon', 'soon'), ('enough', 'enough'), (',', ','), ('able', 'abl'), ('ask', 'ask')]

>> Stemming using Snowball Stemmer: 
 [('But', 'but'), ('soon', 'soon'), ('enough', 'enough'), (',', ','), ('able', 'abl'), ('ask', 'ask')]

>> Lemmatization: 
 [('But', 'But'), ('soon', 'soon'), ('enough', 'enough'), (',', ','), ('able', 'able'), ('ask', 'ask')]



========================================== PARAGRAPH 539 ===========================================

our personal data chatbot about customer sentiment today, and how do we feel about their  

------------------- Sentence 1 -------------------

our personal data chatbot about customer sentiment today, and how do we feel about their

>> Tokens are: 
 ['personal', 'data', 'chatbot', 'customer', 'sentiment', 'today', ',', 'feel']

>> Bigrams are: 
 [('personal', 'data'), ('data', 'chatbot'), ('chatbot', 'customer'), ('customer', 'sentiment'), ('sentiment', 'today'), ('today', ','), (',', 'feel')]

>> Trigrams are: 
 [('personal', 'data', 'chatbot'), ('data', 'chatbot', 'customer'), ('chatbot', 'customer', 'sentiment'), ('customer', 'sentiment', 'today'), ('sentiment', 'today', ','), ('today', ',', 'feel')]

>> POS Tags are: 
 [('personal', 'JJ'), ('data', 'NNS'), ('chatbot', 'NN'), ('customer', 'NN'), ('sentiment', 'NN'), ('today', 'NN'), (',', ','), ('feel', 'VB')]

>> Noun Phrases are: 
 ['personal data chatbot customer sentiment today']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('personal', 'person'), ('data', 'data'), ('chatbot', 'chatbot'), ('customer', 'custom'), ('sentiment', 'sentiment'), ('today', 'today'), (',', ','), ('feel', 'feel')]

>> Stemming using Snowball Stemmer: 
 [('personal', 'person'), ('data', 'data'), ('chatbot', 'chatbot'), ('customer', 'custom'), ('sentiment', 'sentiment'), ('today', 'today'), (',', ','), ('feel', 'feel')]

>> Lemmatization: 
 [('personal', 'personal'), ('data', 'data'), ('chatbot', 'chatbot'), ('customer', 'customer'), ('sentiment', 'sentiment'), ('today', 'today'), (',', ','), ('feel', 'feel')]



========================================== PARAGRAPH 540 ===========================================

brand next week; all while walking down the street. Today, NLP tends to be based on turning  

------------------- Sentence 1 -------------------

brand next week; all while walking down the street.

>> Tokens are: 
 ['brand', 'next', 'week', ';', 'walking', 'street', '.']

>> Bigrams are: 
 [('brand', 'next'), ('next', 'week'), ('week', ';'), (';', 'walking'), ('walking', 'street'), ('street', '.')]

>> Trigrams are: 
 [('brand', 'next', 'week'), ('next', 'week', ';'), ('week', ';', 'walking'), (';', 'walking', 'street'), ('walking', 'street', '.')]

>> POS Tags are: 
 [('brand', 'NN'), ('next', 'JJ'), ('week', 'NN'), (';', ':'), ('walking', 'VBG'), ('street', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['brand', 'next week', 'street']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('brand', 'brand'), ('next', 'next'), ('week', 'week'), (';', ';'), ('walking', 'walk'), ('street', 'street'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('brand', 'brand'), ('next', 'next'), ('week', 'week'), (';', ';'), ('walking', 'walk'), ('street', 'street'), ('.', '.')]

>> Lemmatization: 
 [('brand', 'brand'), ('next', 'next'), ('week', 'week'), (';', ';'), ('walking', 'walking'), ('street', 'street'), ('.', '.')]


------------------- Sentence 2 -------------------

Today, NLP tends to be based on turning

>> Tokens are: 
 ['Today', ',', 'NLP', 'tends', 'based', 'turning']

>> Bigrams are: 
 [('Today', ','), (',', 'NLP'), ('NLP', 'tends'), ('tends', 'based'), ('based', 'turning')]

>> Trigrams are: 
 [('Today', ',', 'NLP'), (',', 'NLP', 'tends'), ('NLP', 'tends', 'based'), ('tends', 'based', 'turning')]

>> POS Tags are: 
 [('Today', 'NN'), (',', ','), ('NLP', 'NNP'), ('tends', 'VBZ'), ('based', 'VBN'), ('turning', 'VBG')]

>> Noun Phrases are: 
 ['Today', 'NLP']

>> Named Entities are: 
 [('ORGANIZATION', 'NLP')] 

>> Stemming using Porter Stemmer: 
 [('Today', 'today'), (',', ','), ('NLP', 'nlp'), ('tends', 'tend'), ('based', 'base'), ('turning', 'turn')]

>> Stemming using Snowball Stemmer: 
 [('Today', 'today'), (',', ','), ('NLP', 'nlp'), ('tends', 'tend'), ('based', 'base'), ('turning', 'turn')]

>> Lemmatization: 
 [('Today', 'Today'), (',', ','), ('NLP', 'NLP'), ('tends', 'tends'), ('based', 'based'), ('turning', 'turning')]



========================================== PARAGRAPH 541 ===========================================

natural language into machine language. But with time the technology matures – especially  

------------------- Sentence 1 -------------------

natural language into machine language.

>> Tokens are: 
 ['natural', 'language', 'machine', 'language', '.']

>> Bigrams are: 
 [('natural', 'language'), ('language', 'machine'), ('machine', 'language'), ('language', '.')]

>> Trigrams are: 
 [('natural', 'language', 'machine'), ('language', 'machine', 'language'), ('machine', 'language', '.')]

>> POS Tags are: 
 [('natural', 'JJ'), ('language', 'NN'), ('machine', 'NN'), ('language', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['natural language machine language']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('natural', 'natur'), ('language', 'languag'), ('machine', 'machin'), ('language', 'languag'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('natural', 'natur'), ('language', 'languag'), ('machine', 'machin'), ('language', 'languag'), ('.', '.')]

>> Lemmatization: 
 [('natural', 'natural'), ('language', 'language'), ('machine', 'machine'), ('language', 'language'), ('.', '.')]


------------------- Sentence 2 -------------------

But with time the technology matures – especially

>> Tokens are: 
 ['But', 'time', 'technology', 'matures', '–', 'especially']

>> Bigrams are: 
 [('But', 'time'), ('time', 'technology'), ('technology', 'matures'), ('matures', '–'), ('–', 'especially')]

>> Trigrams are: 
 [('But', 'time', 'technology'), ('time', 'technology', 'matures'), ('technology', 'matures', '–'), ('matures', '–', 'especially')]

>> POS Tags are: 
 [('But', 'CC'), ('time', 'NN'), ('technology', 'NN'), ('matures', 'VBZ'), ('–', 'NNP'), ('especially', 'RB')]

>> Noun Phrases are: 
 ['time technology', '–']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('But', 'but'), ('time', 'time'), ('technology', 'technolog'), ('matures', 'matur'), ('–', '–'), ('especially', 'especi')]

>> Stemming using Snowball Stemmer: 
 [('But', 'but'), ('time', 'time'), ('technology', 'technolog'), ('matures', 'matur'), ('–', '–'), ('especially', 'especi')]

>> Lemmatization: 
 [('But', 'But'), ('time', 'time'), ('technology', 'technology'), ('matures', 'matures'), ('–', '–'), ('especially', 'especially')]



========================================== PARAGRAPH 542 ===========================================

the AI component –the computer will get better at “understanding” the query and start to  

------------------- Sentence 1 -------------------

the AI component –the computer will get better at “understanding” the query and start to

>> Tokens are: 
 ['AI', 'component', '–the', 'computer', 'get', 'better', '“', 'understanding', '”', 'query', 'start']

>> Bigrams are: 
 [('AI', 'component'), ('component', '–the'), ('–the', 'computer'), ('computer', 'get'), ('get', 'better'), ('better', '“'), ('“', 'understanding'), ('understanding', '”'), ('”', 'query'), ('query', 'start')]

>> Trigrams are: 
 [('AI', 'component', '–the'), ('component', '–the', 'computer'), ('–the', 'computer', 'get'), ('computer', 'get', 'better'), ('get', 'better', '“'), ('better', '“', 'understanding'), ('“', 'understanding', '”'), ('understanding', '”', 'query'), ('”', 'query', 'start')]

>> POS Tags are: 
 [('AI', 'NNP'), ('component', 'NN'), ('–the', 'NNP'), ('computer', 'NN'), ('get', 'VBP'), ('better', 'JJR'), ('“', 'NN'), ('understanding', 'VBG'), ('”', 'JJ'), ('query', 'JJ'), ('start', 'NN')]

>> Noun Phrases are: 
 ['AI component –the computer', '“', '” query start']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('AI', 'ai'), ('component', 'compon'), ('–the', '–the'), ('computer', 'comput'), ('get', 'get'), ('better', 'better'), ('“', '“'), ('understanding', 'understand'), ('”', '”'), ('query', 'queri'), ('start', 'start')]

>> Stemming using Snowball Stemmer: 
 [('AI', 'ai'), ('component', 'compon'), ('–the', '–the'), ('computer', 'comput'), ('get', 'get'), ('better', 'better'), ('“', '“'), ('understanding', 'understand'), ('”', '”'), ('query', 'queri'), ('start', 'start')]

>> Lemmatization: 
 [('AI', 'AI'), ('component', 'component'), ('–the', '–the'), ('computer', 'computer'), ('get', 'get'), ('better', 'better'), ('“', '“'), ('understanding', 'understanding'), ('”', '”'), ('query', 'query'), ('start', 'start')]



========================================== PARAGRAPH 543 ===========================================

deliver answers rather than search results.  

------------------- Sentence 1 -------------------

deliver answers rather than search results.

>> Tokens are: 
 ['deliver', 'answers', 'rather', 'search', 'results', '.']

>> Bigrams are: 
 [('deliver', 'answers'), ('answers', 'rather'), ('rather', 'search'), ('search', 'results'), ('results', '.')]

>> Trigrams are: 
 [('deliver', 'answers', 'rather'), ('answers', 'rather', 'search'), ('rather', 'search', 'results'), ('search', 'results', '.')]

>> POS Tags are: 
 [('deliver', 'NN'), ('answers', 'NNS'), ('rather', 'RB'), ('search', 'JJ'), ('results', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['deliver answers', 'search results']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('deliver', 'deliv'), ('answers', 'answer'), ('rather', 'rather'), ('search', 'search'), ('results', 'result'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('deliver', 'deliv'), ('answers', 'answer'), ('rather', 'rather'), ('search', 'search'), ('results', 'result'), ('.', '.')]

>> Lemmatization: 
 [('deliver', 'deliver'), ('answers', 'answer'), ('rather', 'rather'), ('search', 'search'), ('results', 'result'), ('.', '.')]



========================================== PARAGRAPH 544 ===========================================

 Initially, the data chatbot will probably ask the question as how have revenues changed over  

------------------- Sentence 1 -------------------

 Initially, the data chatbot will probably ask the question as how have revenues changed over

>> Tokens are: 
 ['Initially', ',', 'data', 'chatbot', 'probably', 'ask', 'question', 'revenues', 'changed']

>> Bigrams are: 
 [('Initially', ','), (',', 'data'), ('data', 'chatbot'), ('chatbot', 'probably'), ('probably', 'ask'), ('ask', 'question'), ('question', 'revenues'), ('revenues', 'changed')]

>> Trigrams are: 
 [('Initially', ',', 'data'), (',', 'data', 'chatbot'), ('data', 'chatbot', 'probably'), ('chatbot', 'probably', 'ask'), ('probably', 'ask', 'question'), ('ask', 'question', 'revenues'), ('question', 'revenues', 'changed')]

>> POS Tags are: 
 [('Initially', 'RB'), (',', ','), ('data', 'NNS'), ('chatbot', 'NN'), ('probably', 'RB'), ('ask', 'JJ'), ('question', 'NN'), ('revenues', 'NNS'), ('changed', 'VBD')]

>> Noun Phrases are: 
 ['data chatbot', 'ask question revenues']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Initially', 'initi'), (',', ','), ('data', 'data'), ('chatbot', 'chatbot'), ('probably', 'probabl'), ('ask', 'ask'), ('question', 'question'), ('revenues', 'revenu'), ('changed', 'chang')]

>> Stemming using Snowball Stemmer: 
 [('Initially', 'initi'), (',', ','), ('data', 'data'), ('chatbot', 'chatbot'), ('probably', 'probabl'), ('ask', 'ask'), ('question', 'question'), ('revenues', 'revenu'), ('changed', 'chang')]

>> Lemmatization: 
 [('Initially', 'Initially'), (',', ','), ('data', 'data'), ('chatbot', 'chatbot'), ('probably', 'probably'), ('ask', 'ask'), ('question', 'question'), ('revenues', 'revenue'), ('changed', 'changed')]



========================================== PARAGRAPH 545 ===========================================

the last three-quarters?’ and then return pages of data for you to analyse. But once it learns  

------------------- Sentence 1 -------------------

the last three-quarters?’ and then return pages of data for you to analyse.

>> Tokens are: 
 ['last', 'three-quarters', '?', '’', 'return', 'pages', 'data', 'analyse', '.']

>> Bigrams are: 
 [('last', 'three-quarters'), ('three-quarters', '?'), ('?', '’'), ('’', 'return'), ('return', 'pages'), ('pages', 'data'), ('data', 'analyse'), ('analyse', '.')]

>> Trigrams are: 
 [('last', 'three-quarters', '?'), ('three-quarters', '?', '’'), ('?', '’', 'return'), ('’', 'return', 'pages'), ('return', 'pages', 'data'), ('pages', 'data', 'analyse'), ('data', 'analyse', '.')]

>> POS Tags are: 
 [('last', 'JJ'), ('three-quarters', 'NNS'), ('?', '.'), ('’', 'JJ'), ('return', 'NN'), ('pages', 'NNS'), ('data', 'VBP'), ('analyse', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['last three-quarters', '’ return pages', 'analyse']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('last', 'last'), ('three-quarters', 'three-quart'), ('?', '?'), ('’', '’'), ('return', 'return'), ('pages', 'page'), ('data', 'data'), ('analyse', 'analys'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('last', 'last'), ('three-quarters', 'three-quart'), ('?', '?'), ('’', '’'), ('return', 'return'), ('pages', 'page'), ('data', 'data'), ('analyse', 'analys'), ('.', '.')]

>> Lemmatization: 
 [('last', 'last'), ('three-quarters', 'three-quarters'), ('?', '?'), ('’', '’'), ('return', 'return'), ('pages', 'page'), ('data', 'data'), ('analyse', 'analyse'), ('.', '.')]


------------------- Sentence 2 -------------------

But once it learns

>> Tokens are: 
 ['But', 'learns']

>> Bigrams are: 
 [('But', 'learns')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('But', 'CC'), ('learns', 'NNS')]

>> Noun Phrases are: 
 ['learns']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('But', 'but'), ('learns', 'learn')]

>> Stemming using Snowball Stemmer: 
 [('But', 'but'), ('learns', 'learn')]

>> Lemmatization: 
 [('But', 'But'), ('learns', 'learns')]



========================================== PARAGRAPH 546 ===========================================

the semantic relations and inferences of the question, it will be able to automatically perform  

------------------- Sentence 1 -------------------

the semantic relations and inferences of the question, it will be able to automatically perform

>> Tokens are: 
 ['semantic', 'relations', 'inferences', 'question', ',', 'able', 'automatically', 'perform']

>> Bigrams are: 
 [('semantic', 'relations'), ('relations', 'inferences'), ('inferences', 'question'), ('question', ','), (',', 'able'), ('able', 'automatically'), ('automatically', 'perform')]

>> Trigrams are: 
 [('semantic', 'relations', 'inferences'), ('relations', 'inferences', 'question'), ('inferences', 'question', ','), ('question', ',', 'able'), (',', 'able', 'automatically'), ('able', 'automatically', 'perform')]

>> POS Tags are: 
 [('semantic', 'JJ'), ('relations', 'NNS'), ('inferences', 'NNS'), ('question', 'NN'), (',', ','), ('able', 'JJ'), ('automatically', 'RB'), ('perform', 'VB')]

>> Noun Phrases are: 
 ['semantic relations inferences question']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('semantic', 'semant'), ('relations', 'relat'), ('inferences', 'infer'), ('question', 'question'), (',', ','), ('able', 'abl'), ('automatically', 'automat'), ('perform', 'perform')]

>> Stemming using Snowball Stemmer: 
 [('semantic', 'semant'), ('relations', 'relat'), ('inferences', 'infer'), ('question', 'question'), (',', ','), ('able', 'abl'), ('automatically', 'automat'), ('perform', 'perform')]

>> Lemmatization: 
 [('semantic', 'semantic'), ('relations', 'relation'), ('inferences', 'inference'), ('question', 'question'), (',', ','), ('able', 'able'), ('automatically', 'automatically'), ('perform', 'perform')]



========================================== PARAGRAPH 547 ===========================================

the filtering and formulation necessary to provide an intelligible answer, rather than simply  

------------------- Sentence 1 -------------------

the filtering and formulation necessary to provide an intelligible answer, rather than simply

>> Tokens are: 
 ['filtering', 'formulation', 'necessary', 'provide', 'intelligible', 'answer', ',', 'rather', 'simply']

>> Bigrams are: 
 [('filtering', 'formulation'), ('formulation', 'necessary'), ('necessary', 'provide'), ('provide', 'intelligible'), ('intelligible', 'answer'), ('answer', ','), (',', 'rather'), ('rather', 'simply')]

>> Trigrams are: 
 [('filtering', 'formulation', 'necessary'), ('formulation', 'necessary', 'provide'), ('necessary', 'provide', 'intelligible'), ('provide', 'intelligible', 'answer'), ('intelligible', 'answer', ','), ('answer', ',', 'rather'), (',', 'rather', 'simply')]

>> POS Tags are: 
 [('filtering', 'VBG'), ('formulation', 'NN'), ('necessary', 'JJ'), ('provide', 'NN'), ('intelligible', 'JJ'), ('answer', 'NN'), (',', ','), ('rather', 'RB'), ('simply', 'RB')]

>> Noun Phrases are: 
 ['formulation', 'necessary provide', 'intelligible answer']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('filtering', 'filter'), ('formulation', 'formul'), ('necessary', 'necessari'), ('provide', 'provid'), ('intelligible', 'intellig'), ('answer', 'answer'), (',', ','), ('rather', 'rather'), ('simply', 'simpli')]

>> Stemming using Snowball Stemmer: 
 [('filtering', 'filter'), ('formulation', 'formul'), ('necessary', 'necessari'), ('provide', 'provid'), ('intelligible', 'intellig'), ('answer', 'answer'), (',', ','), ('rather', 'rather'), ('simply', 'simpli')]

>> Lemmatization: 
 [('filtering', 'filtering'), ('formulation', 'formulation'), ('necessary', 'necessary'), ('provide', 'provide'), ('intelligible', 'intelligible'), ('answer', 'answer'), (',', ','), ('rather', 'rather'), ('simply', 'simply')]



========================================== PARAGRAPH 548 ===========================================

showing you data.  

------------------- Sentence 1 -------------------

showing you data.

>> Tokens are: 
 ['showing', 'data', '.']

>> Bigrams are: 
 [('showing', 'data'), ('data', '.')]

>> Trigrams are: 
 [('showing', 'data', '.')]

>> POS Tags are: 
 [('showing', 'VBG'), ('data', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('showing', 'show'), ('data', 'data'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('showing', 'show'), ('data', 'data'), ('.', '.')]

>> Lemmatization: 
 [('showing', 'showing'), ('data', 'data'), ('.', '.')]



========================================== PARAGRAPH 549 ===========================================

Link: http://www.smartdatacollective.com/eran-levy/489410/here-s-why-natural-language-processing-future-bi  

------------------- Sentence 1 -------------------

Link: http://www.smartdatacollective.com/eran-levy/489410/here-s-why-natural-language-processing-future-bi

>> Tokens are: 
 ['Link', ':', 'http', ':', '//www.smartdatacollective.com/eran-levy/489410/here-s-why-natural-language-processing-future-bi']

>> Bigrams are: 
 [('Link', ':'), (':', 'http'), ('http', ':'), (':', '//www.smartdatacollective.com/eran-levy/489410/here-s-why-natural-language-processing-future-bi')]

>> Trigrams are: 
 [('Link', ':', 'http'), (':', 'http', ':'), ('http', ':', '//www.smartdatacollective.com/eran-levy/489410/here-s-why-natural-language-processing-future-bi')]

>> POS Tags are: 
 [('Link', 'NN'), (':', ':'), ('http', 'NN'), (':', ':'), ('//www.smartdatacollective.com/eran-levy/489410/here-s-why-natural-language-processing-future-bi', 'JJ')]

>> Noun Phrases are: 
 ['Link', 'http']

>> Named Entities are: 
 [('GPE', 'Link')] 

>> Stemming using Porter Stemmer: 
 [('Link', 'link'), (':', ':'), ('http', 'http'), (':', ':'), ('//www.smartdatacollective.com/eran-levy/489410/here-s-why-natural-language-processing-future-bi', '//www.smartdatacollective.com/eran-levy/489410/here-s-why-natural-language-processing-future-bi')]

>> Stemming using Snowball Stemmer: 
 [('Link', 'link'), (':', ':'), ('http', 'http'), (':', ':'), ('//www.smartdatacollective.com/eran-levy/489410/here-s-why-natural-language-processing-future-bi', '//www.smartdatacollective.com/eran-levy/489410/here-s-why-natural-language-processing-future-bi')]

>> Lemmatization: 
 [('Link', 'Link'), (':', ':'), ('http', 'http'), (':', ':'), ('//www.smartdatacollective.com/eran-levy/489410/here-s-why-natural-language-processing-future-bi', '//www.smartdatacollective.com/eran-levy/489410/here-s-why-natural-language-processing-future-bi')]



========================================== PARAGRAPH 550 ===========================================

8.4 Using Natural Language Processing and Network Analysis to  

------------------- Sentence 1 -------------------

8.4 Using Natural Language Processing and Network Analysis to

>> Tokens are: 
 ['8.4', 'Using', 'Natural', 'Language', 'Processing', 'Network', 'Analysis']

>> Bigrams are: 
 [('8.4', 'Using'), ('Using', 'Natural'), ('Natural', 'Language'), ('Language', 'Processing'), ('Processing', 'Network'), ('Network', 'Analysis')]

>> Trigrams are: 
 [('8.4', 'Using', 'Natural'), ('Using', 'Natural', 'Language'), ('Natural', 'Language', 'Processing'), ('Language', 'Processing', 'Network'), ('Processing', 'Network', 'Analysis')]

>> POS Tags are: 
 [('8.4', 'CD'), ('Using', 'VBG'), ('Natural', 'NNP'), ('Language', 'NNP'), ('Processing', 'NNP'), ('Network', 'NNP'), ('Analysis', 'NNP')]

>> Noun Phrases are: 
 ['Natural Language Processing Network Analysis']

>> Named Entities are: 
 [('ORGANIZATION', 'Natural Language'), ('PERSON', 'Network Analysis')] 

>> Stemming using Porter Stemmer: 
 [('8.4', '8.4'), ('Using', 'use'), ('Natural', 'natur'), ('Language', 'languag'), ('Processing', 'process'), ('Network', 'network'), ('Analysis', 'analysi')]

>> Stemming using Snowball Stemmer: 
 [('8.4', '8.4'), ('Using', 'use'), ('Natural', 'natur'), ('Language', 'languag'), ('Processing', 'process'), ('Network', 'network'), ('Analysis', 'analysi')]

>> Lemmatization: 
 [('8.4', '8.4'), ('Using', 'Using'), ('Natural', 'Natural'), ('Language', 'Language'), ('Processing', 'Processing'), ('Network', 'Network'), ('Analysis', 'Analysis')]



========================================== PARAGRAPH 551 ===========================================

Develop a Conceptual Framework for Medication Therapy  

------------------- Sentence 1 -------------------

Develop a Conceptual Framework for Medication Therapy

>> Tokens are: 
 ['Develop', 'Conceptual', 'Framework', 'Medication', 'Therapy']

>> Bigrams are: 
 [('Develop', 'Conceptual'), ('Conceptual', 'Framework'), ('Framework', 'Medication'), ('Medication', 'Therapy')]

>> Trigrams are: 
 [('Develop', 'Conceptual', 'Framework'), ('Conceptual', 'Framework', 'Medication'), ('Framework', 'Medication', 'Therapy')]

>> POS Tags are: 
 [('Develop', 'NNP'), ('Conceptual', 'NNP'), ('Framework', 'NNP'), ('Medication', 'NNP'), ('Therapy', 'NNP')]

>> Noun Phrases are: 
 ['Develop Conceptual Framework Medication Therapy']

>> Named Entities are: 
 [('PERSON', 'Develop'), ('ORGANIZATION', 'Conceptual Framework Medication')] 

>> Stemming using Porter Stemmer: 
 [('Develop', 'develop'), ('Conceptual', 'conceptu'), ('Framework', 'framework'), ('Medication', 'medic'), ('Therapy', 'therapi')]

>> Stemming using Snowball Stemmer: 
 [('Develop', 'develop'), ('Conceptual', 'conceptu'), ('Framework', 'framework'), ('Medication', 'medic'), ('Therapy', 'therapi')]

>> Lemmatization: 
 [('Develop', 'Develop'), ('Conceptual', 'Conceptual'), ('Framework', 'Framework'), ('Medication', 'Medication'), ('Therapy', 'Therapy')]



========================================== PARAGRAPH 552 ===========================================

Management Research [107]  

------------------- Sentence 1 -------------------

Management Research [107]

>> Tokens are: 
 ['Management', 'Research', '[', '107', ']']

>> Bigrams are: 
 [('Management', 'Research'), ('Research', '['), ('[', '107'), ('107', ']')]

>> Trigrams are: 
 [('Management', 'Research', '['), ('Research', '[', '107'), ('[', '107', ']')]

>> POS Tags are: 
 [('Management', 'NNP'), ('Research', 'NNP'), ('[', 'VBZ'), ('107', 'CD'), (']', 'NN')]

>> Noun Phrases are: 
 ['Management Research', ']']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Management', 'manag'), ('Research', 'research'), ('[', '['), ('107', '107'), (']', ']')]

>> Stemming using Snowball Stemmer: 
 [('Management', 'manag'), ('Research', 'research'), ('[', '['), ('107', '107'), (']', ']')]

>> Lemmatization: 
 [('Management', 'Management'), ('Research', 'Research'), ('[', '['), ('107', '107'), (']', ']')]



========================================== PARAGRAPH 553 ===========================================

Natural Language Processing and Network Analysis to Develop a Conceptual Framework for  

------------------- Sentence 1 -------------------

Natural Language Processing and Network Analysis to Develop a Conceptual Framework for

>> Tokens are: 
 ['Natural', 'Language', 'Processing', 'Network', 'Analysis', 'Develop', 'Conceptual', 'Framework']

>> Bigrams are: 
 [('Natural', 'Language'), ('Language', 'Processing'), ('Processing', 'Network'), ('Network', 'Analysis'), ('Analysis', 'Develop'), ('Develop', 'Conceptual'), ('Conceptual', 'Framework')]

>> Trigrams are: 
 [('Natural', 'Language', 'Processing'), ('Language', 'Processing', 'Network'), ('Processing', 'Network', 'Analysis'), ('Network', 'Analysis', 'Develop'), ('Analysis', 'Develop', 'Conceptual'), ('Develop', 'Conceptual', 'Framework')]

>> POS Tags are: 
 [('Natural', 'JJ'), ('Language', 'NNP'), ('Processing', 'NNP'), ('Network', 'NNP'), ('Analysis', 'NNP'), ('Develop', 'NNP'), ('Conceptual', 'NNP'), ('Framework', 'NNP')]

>> Noun Phrases are: 
 ['Natural Language Processing Network Analysis Develop Conceptual Framework']

>> Named Entities are: 
 [('PERSON', 'Network Analysis Develop Conceptual Framework')] 

>> Stemming using Porter Stemmer: 
 [('Natural', 'natur'), ('Language', 'languag'), ('Processing', 'process'), ('Network', 'network'), ('Analysis', 'analysi'), ('Develop', 'develop'), ('Conceptual', 'conceptu'), ('Framework', 'framework')]

>> Stemming using Snowball Stemmer: 
 [('Natural', 'natur'), ('Language', 'languag'), ('Processing', 'process'), ('Network', 'network'), ('Analysis', 'analysi'), ('Develop', 'develop'), ('Conceptual', 'conceptu'), ('Framework', 'framework')]

>> Lemmatization: 
 [('Natural', 'Natural'), ('Language', 'Language'), ('Processing', 'Processing'), ('Network', 'Network'), ('Analysis', 'Analysis'), ('Develop', 'Develop'), ('Conceptual', 'Conceptual'), ('Framework', 'Framework')]



========================================== PARAGRAPH 554 ===========================================

Medication Therapy Management Research describes a theory derivation process that is used  

------------------- Sentence 1 -------------------

Medication Therapy Management Research describes a theory derivation process that is used

>> Tokens are: 
 ['Medication', 'Therapy', 'Management', 'Research', 'describes', 'theory', 'derivation', 'process', 'used']

>> Bigrams are: 
 [('Medication', 'Therapy'), ('Therapy', 'Management'), ('Management', 'Research'), ('Research', 'describes'), ('describes', 'theory'), ('theory', 'derivation'), ('derivation', 'process'), ('process', 'used')]

>> Trigrams are: 
 [('Medication', 'Therapy', 'Management'), ('Therapy', 'Management', 'Research'), ('Management', 'Research', 'describes'), ('Research', 'describes', 'theory'), ('describes', 'theory', 'derivation'), ('theory', 'derivation', 'process'), ('derivation', 'process', 'used')]

>> POS Tags are: 
 [('Medication', 'NNP'), ('Therapy', 'NNP'), ('Management', 'NNP'), ('Research', 'NNP'), ('describes', 'VBZ'), ('theory', 'JJ'), ('derivation', 'NN'), ('process', 'NN'), ('used', 'VBN')]

>> Noun Phrases are: 
 ['Medication Therapy Management Research', 'theory derivation process']

>> Named Entities are: 
 [('ORGANIZATION', 'Medication')] 

>> Stemming using Porter Stemmer: 
 [('Medication', 'medic'), ('Therapy', 'therapi'), ('Management', 'manag'), ('Research', 'research'), ('describes', 'describ'), ('theory', 'theori'), ('derivation', 'deriv'), ('process', 'process'), ('used', 'use')]

>> Stemming using Snowball Stemmer: 
 [('Medication', 'medic'), ('Therapy', 'therapi'), ('Management', 'manag'), ('Research', 'research'), ('describes', 'describ'), ('theory', 'theori'), ('derivation', 'deriv'), ('process', 'process'), ('used', 'use')]

>> Lemmatization: 
 [('Medication', 'Medication'), ('Therapy', 'Therapy'), ('Management', 'Management'), ('Research', 'Research'), ('describes', 'describes'), ('theory', 'theory'), ('derivation', 'derivation'), ('process', 'process'), ('used', 'used')]



========================================== PARAGRAPH 555 ===========================================

to develop conceptual framework for medication therapy management (MTM) research. The  

------------------- Sentence 1 -------------------

to develop conceptual framework for medication therapy management (MTM) research.

>> Tokens are: 
 ['develop', 'conceptual', 'framework', 'medication', 'therapy', 'management', '(', 'MTM', ')', 'research', '.']

>> Bigrams are: 
 [('develop', 'conceptual'), ('conceptual', 'framework'), ('framework', 'medication'), ('medication', 'therapy'), ('therapy', 'management'), ('management', '('), ('(', 'MTM'), ('MTM', ')'), (')', 'research'), ('research', '.')]

>> Trigrams are: 
 [('develop', 'conceptual', 'framework'), ('conceptual', 'framework', 'medication'), ('framework', 'medication', 'therapy'), ('medication', 'therapy', 'management'), ('therapy', 'management', '('), ('management', '(', 'MTM'), ('(', 'MTM', ')'), ('MTM', ')', 'research'), (')', 'research', '.')]

>> POS Tags are: 
 [('develop', 'VB'), ('conceptual', 'JJ'), ('framework', 'NN'), ('medication', 'NN'), ('therapy', 'NN'), ('management', 'NN'), ('(', '('), ('MTM', 'NNP'), (')', ')'), ('research', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['conceptual framework medication therapy management', 'MTM', 'research']

>> Named Entities are: 
 [('ORGANIZATION', 'MTM')] 

>> Stemming using Porter Stemmer: 
 [('develop', 'develop'), ('conceptual', 'conceptu'), ('framework', 'framework'), ('medication', 'medic'), ('therapy', 'therapi'), ('management', 'manag'), ('(', '('), ('MTM', 'mtm'), (')', ')'), ('research', 'research'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('develop', 'develop'), ('conceptual', 'conceptu'), ('framework', 'framework'), ('medication', 'medic'), ('therapy', 'therapi'), ('management', 'manag'), ('(', '('), ('MTM', 'mtm'), (')', ')'), ('research', 'research'), ('.', '.')]

>> Lemmatization: 
 [('develop', 'develop'), ('conceptual', 'conceptual'), ('framework', 'framework'), ('medication', 'medication'), ('therapy', 'therapy'), ('management', 'management'), ('(', '('), ('MTM', 'MTM'), (')', ')'), ('research', 'research'), ('.', '.')]


------------------- Sentence 2 -------------------

The

>> Tokens are: 
 ['The']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('The', 'DT')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the')]

>> Lemmatization: 
 [('The', 'The')]



========================================== PARAGRAPH 556 ===========================================

MTM service model and chronic care model are selected as parent theories. Review article 

------------------- Sentence 1 -------------------

MTM service model and chronic care model are selected as parent theories.

>> Tokens are: 
 ['MTM', 'service', 'model', 'chronic', 'care', 'model', 'selected', 'parent', 'theories', '.']

>> Bigrams are: 
 [('MTM', 'service'), ('service', 'model'), ('model', 'chronic'), ('chronic', 'care'), ('care', 'model'), ('model', 'selected'), ('selected', 'parent'), ('parent', 'theories'), ('theories', '.')]

>> Trigrams are: 
 [('MTM', 'service', 'model'), ('service', 'model', 'chronic'), ('model', 'chronic', 'care'), ('chronic', 'care', 'model'), ('care', 'model', 'selected'), ('model', 'selected', 'parent'), ('selected', 'parent', 'theories'), ('parent', 'theories', '.')]

>> POS Tags are: 
 [('MTM', 'NNP'), ('service', 'NN'), ('model', 'NN'), ('chronic', 'JJ'), ('care', 'NN'), ('model', 'NN'), ('selected', 'VBN'), ('parent', 'NN'), ('theories', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['MTM service model', 'chronic care model', 'parent theories']

>> Named Entities are: 
 [('ORGANIZATION', 'MTM')] 

>> Stemming using Porter Stemmer: 
 [('MTM', 'mtm'), ('service', 'servic'), ('model', 'model'), ('chronic', 'chronic'), ('care', 'care'), ('model', 'model'), ('selected', 'select'), ('parent', 'parent'), ('theories', 'theori'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('MTM', 'mtm'), ('service', 'servic'), ('model', 'model'), ('chronic', 'chronic'), ('care', 'care'), ('model', 'model'), ('selected', 'select'), ('parent', 'parent'), ('theories', 'theori'), ('.', '.')]

>> Lemmatization: 
 [('MTM', 'MTM'), ('service', 'service'), ('model', 'model'), ('chronic', 'chronic'), ('care', 'care'), ('model', 'model'), ('selected', 'selected'), ('parent', 'parent'), ('theories', 'theory'), ('.', '.')]


------------------- Sentence 2 -------------------

Review article

>> Tokens are: 
 ['Review', 'article']

>> Bigrams are: 
 [('Review', 'article')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Review', 'NNP'), ('article', 'NN')]

>> Noun Phrases are: 
 ['Review article']

>> Named Entities are: 
 [('GPE', 'Review')] 

>> Stemming using Porter Stemmer: 
 [('Review', 'review'), ('article', 'articl')]

>> Stemming using Snowball Stemmer: 
 [('Review', 'review'), ('article', 'articl')]

>> Lemmatization: 
 [('Review', 'Review'), ('article', 'article')]



========================================== PARAGRAPH 557 ===========================================

abstracts target medication therapy management in chronic disease care that were retrieved  

------------------- Sentence 1 -------------------

abstracts target medication therapy management in chronic disease care that were retrieved

>> Tokens are: 
 ['abstracts', 'target', 'medication', 'therapy', 'management', 'chronic', 'disease', 'care', 'retrieved']

>> Bigrams are: 
 [('abstracts', 'target'), ('target', 'medication'), ('medication', 'therapy'), ('therapy', 'management'), ('management', 'chronic'), ('chronic', 'disease'), ('disease', 'care'), ('care', 'retrieved')]

>> Trigrams are: 
 [('abstracts', 'target', 'medication'), ('target', 'medication', 'therapy'), ('medication', 'therapy', 'management'), ('therapy', 'management', 'chronic'), ('management', 'chronic', 'disease'), ('chronic', 'disease', 'care'), ('disease', 'care', 'retrieved')]

>> POS Tags are: 
 [('abstracts', 'NNS'), ('target', 'VBP'), ('medication', 'NN'), ('therapy', 'NN'), ('management', 'NN'), ('chronic', 'JJ'), ('disease', 'NN'), ('care', 'NN'), ('retrieved', 'VBD')]

>> Noun Phrases are: 
 ['abstracts', 'medication therapy management', 'chronic disease care']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('abstracts', 'abstract'), ('target', 'target'), ('medication', 'medic'), ('therapy', 'therapi'), ('management', 'manag'), ('chronic', 'chronic'), ('disease', 'diseas'), ('care', 'care'), ('retrieved', 'retriev')]

>> Stemming using Snowball Stemmer: 
 [('abstracts', 'abstract'), ('target', 'target'), ('medication', 'medic'), ('therapy', 'therapi'), ('management', 'manag'), ('chronic', 'chronic'), ('disease', 'diseas'), ('care', 'care'), ('retrieved', 'retriev')]

>> Lemmatization: 
 [('abstracts', 'abstract'), ('target', 'target'), ('medication', 'medication'), ('therapy', 'therapy'), ('management', 'management'), ('chronic', 'chronic'), ('disease', 'disease'), ('care', 'care'), ('retrieved', 'retrieved')]



========================================== PARAGRAPH 558 ===========================================

from Ovid Medline (2000-2016).  

------------------- Sentence 1 -------------------

from Ovid Medline (2000-2016).

>> Tokens are: 
 ['Ovid', 'Medline', '(', '2000-2016', ')', '.']

>> Bigrams are: 
 [('Ovid', 'Medline'), ('Medline', '('), ('(', '2000-2016'), ('2000-2016', ')'), (')', '.')]

>> Trigrams are: 
 [('Ovid', 'Medline', '('), ('Medline', '(', '2000-2016'), ('(', '2000-2016', ')'), ('2000-2016', ')', '.')]

>> POS Tags are: 
 [('Ovid', 'NNP'), ('Medline', 'NNP'), ('(', '('), ('2000-2016', 'JJ'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['Ovid Medline']

>> Named Entities are: 
 [('PERSON', 'Ovid'), ('ORGANIZATION', 'Medline')] 

>> Stemming using Porter Stemmer: 
 [('Ovid', 'ovid'), ('Medline', 'medlin'), ('(', '('), ('2000-2016', '2000-2016'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Ovid', 'ovid'), ('Medline', 'medlin'), ('(', '('), ('2000-2016', '2000-2016'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Ovid', 'Ovid'), ('Medline', 'Medline'), ('(', '('), ('2000-2016', '2000-2016'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 559 ===========================================

Unique concepts in each abstract are extracted using Meta Map and their pairwise  

------------------- Sentence 1 -------------------

Unique concepts in each abstract are extracted using Meta Map and their pairwise

>> Tokens are: 
 ['Unique', 'concepts', 'abstract', 'extracted', 'using', 'Meta', 'Map', 'pairwise']

>> Bigrams are: 
 [('Unique', 'concepts'), ('concepts', 'abstract'), ('abstract', 'extracted'), ('extracted', 'using'), ('using', 'Meta'), ('Meta', 'Map'), ('Map', 'pairwise')]

>> Trigrams are: 
 [('Unique', 'concepts', 'abstract'), ('concepts', 'abstract', 'extracted'), ('abstract', 'extracted', 'using'), ('extracted', 'using', 'Meta'), ('using', 'Meta', 'Map'), ('Meta', 'Map', 'pairwise')]

>> POS Tags are: 
 [('Unique', 'JJ'), ('concepts', 'NNS'), ('abstract', 'VBP'), ('extracted', 'VBN'), ('using', 'VBG'), ('Meta', 'NNP'), ('Map', 'NNP'), ('pairwise', 'NN')]

>> Noun Phrases are: 
 ['Unique concepts', 'Meta Map pairwise']

>> Named Entities are: 
 [('GPE', 'Unique'), ('ORGANIZATION', 'Meta Map')] 

>> Stemming using Porter Stemmer: 
 [('Unique', 'uniqu'), ('concepts', 'concept'), ('abstract', 'abstract'), ('extracted', 'extract'), ('using', 'use'), ('Meta', 'meta'), ('Map', 'map'), ('pairwise', 'pairwis')]

>> Stemming using Snowball Stemmer: 
 [('Unique', 'uniqu'), ('concepts', 'concept'), ('abstract', 'abstract'), ('extracted', 'extract'), ('using', 'use'), ('Meta', 'meta'), ('Map', 'map'), ('pairwise', 'pairwis')]

>> Lemmatization: 
 [('Unique', 'Unique'), ('concepts', 'concept'), ('abstract', 'abstract'), ('extracted', 'extracted'), ('using', 'using'), ('Meta', 'Meta'), ('Map', 'Map'), ('pairwise', 'pairwise')]



========================================== PARAGRAPH 560 ===========================================

cooccurrence are determined. Then the information is used to construct a network graph of  

------------------- Sentence 1 -------------------

cooccurrence are determined.

>> Tokens are: 
 ['cooccurrence', 'determined', '.']

>> Bigrams are: 
 [('cooccurrence', 'determined'), ('determined', '.')]

>> Trigrams are: 
 [('cooccurrence', 'determined', '.')]

>> POS Tags are: 
 [('cooccurrence', 'NN'), ('determined', 'VBD'), ('.', '.')]

>> Noun Phrases are: 
 ['cooccurrence']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('cooccurrence', 'cooccurr'), ('determined', 'determin'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('cooccurrence', 'cooccurr'), ('determined', 'determin'), ('.', '.')]

>> Lemmatization: 
 [('cooccurrence', 'cooccurrence'), ('determined', 'determined'), ('.', '.')]


------------------- Sentence 2 -------------------

Then the information is used to construct a network graph of

>> Tokens are: 
 ['Then', 'information', 'used', 'construct', 'network', 'graph']

>> Bigrams are: 
 [('Then', 'information'), ('information', 'used'), ('used', 'construct'), ('construct', 'network'), ('network', 'graph')]

>> Trigrams are: 
 [('Then', 'information', 'used'), ('information', 'used', 'construct'), ('used', 'construct', 'network'), ('construct', 'network', 'graph')]

>> POS Tags are: 
 [('Then', 'RB'), ('information', 'NN'), ('used', 'VBN'), ('construct', 'NN'), ('network', 'NN'), ('graph', 'NN')]

>> Noun Phrases are: 
 ['information', 'construct network graph']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Then', 'then'), ('information', 'inform'), ('used', 'use'), ('construct', 'construct'), ('network', 'network'), ('graph', 'graph')]

>> Stemming using Snowball Stemmer: 
 [('Then', 'then'), ('information', 'inform'), ('used', 'use'), ('construct', 'construct'), ('network', 'network'), ('graph', 'graph')]

>> Lemmatization: 
 [('Then', 'Then'), ('information', 'information'), ('used', 'used'), ('construct', 'construct'), ('network', 'network'), ('graph', 'graph')]



========================================== PARAGRAPH 561 ===========================================

concept co-occurrence that is further analysed to identify content for the new conceptual  

------------------- Sentence 1 -------------------

concept co-occurrence that is further analysed to identify content for the new conceptual

>> Tokens are: 
 ['concept', 'co-occurrence', 'analysed', 'identify', 'content', 'new', 'conceptual']

>> Bigrams are: 
 [('concept', 'co-occurrence'), ('co-occurrence', 'analysed'), ('analysed', 'identify'), ('identify', 'content'), ('content', 'new'), ('new', 'conceptual')]

>> Trigrams are: 
 [('concept', 'co-occurrence', 'analysed'), ('co-occurrence', 'analysed', 'identify'), ('analysed', 'identify', 'content'), ('identify', 'content', 'new'), ('content', 'new', 'conceptual')]

>> POS Tags are: 
 [('concept', 'JJ'), ('co-occurrence', 'NN'), ('analysed', 'VBD'), ('identify', 'VB'), ('content', 'JJ'), ('new', 'JJ'), ('conceptual', 'JJ')]

>> Noun Phrases are: 
 ['concept co-occurrence']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('concept', 'concept'), ('co-occurrence', 'co-occurr'), ('analysed', 'analys'), ('identify', 'identifi'), ('content', 'content'), ('new', 'new'), ('conceptual', 'conceptu')]

>> Stemming using Snowball Stemmer: 
 [('concept', 'concept'), ('co-occurrence', 'co-occurr'), ('analysed', 'analys'), ('identify', 'identifi'), ('content', 'content'), ('new', 'new'), ('conceptual', 'conceptu')]

>> Lemmatization: 
 [('concept', 'concept'), ('co-occurrence', 'co-occurrence'), ('analysed', 'analysed'), ('identify', 'identify'), ('content', 'content'), ('new', 'new'), ('conceptual', 'conceptual')]



========================================== PARAGRAPH 562 ===========================================

model. 142 abstracts are analysed. Medication adherence is the most studied drug therapy  

------------------- Sentence 1 -------------------

model.

>> Tokens are: 
 ['model', '.']

>> Bigrams are: 
 [('model', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('model', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['model']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('model', 'model'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('model', 'model'), ('.', '.')]

>> Lemmatization: 
 [('model', 'model'), ('.', '.')]


------------------- Sentence 2 -------------------

142 abstracts are analysed.

>> Tokens are: 
 ['142', 'abstracts', 'analysed', '.']

>> Bigrams are: 
 [('142', 'abstracts'), ('abstracts', 'analysed'), ('analysed', '.')]

>> Trigrams are: 
 [('142', 'abstracts', 'analysed'), ('abstracts', 'analysed', '.')]

>> POS Tags are: 
 [('142', 'CD'), ('abstracts', 'NNS'), ('analysed', 'VBN'), ('.', '.')]

>> Noun Phrases are: 
 ['abstracts']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('142', '142'), ('abstracts', 'abstract'), ('analysed', 'analys'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('142', '142'), ('abstracts', 'abstract'), ('analysed', 'analys'), ('.', '.')]

>> Lemmatization: 
 [('142', '142'), ('abstracts', 'abstract'), ('analysed', 'analysed'), ('.', '.')]


------------------- Sentence 3 -------------------

Medication adherence is the most studied drug therapy

>> Tokens are: 
 ['Medication', 'adherence', 'studied', 'drug', 'therapy']

>> Bigrams are: 
 [('Medication', 'adherence'), ('adherence', 'studied'), ('studied', 'drug'), ('drug', 'therapy')]

>> Trigrams are: 
 [('Medication', 'adherence', 'studied'), ('adherence', 'studied', 'drug'), ('studied', 'drug', 'therapy')]

>> POS Tags are: 
 [('Medication', 'NNP'), ('adherence', 'NN'), ('studied', 'VBD'), ('drug', 'NN'), ('therapy', 'NN')]

>> Noun Phrases are: 
 ['Medication adherence', 'drug therapy']

>> Named Entities are: 
 [('GPE', 'Medication')] 

>> Stemming using Porter Stemmer: 
 [('Medication', 'medic'), ('adherence', 'adher'), ('studied', 'studi'), ('drug', 'drug'), ('therapy', 'therapi')]

>> Stemming using Snowball Stemmer: 
 [('Medication', 'medic'), ('adherence', 'adher'), ('studied', 'studi'), ('drug', 'drug'), ('therapy', 'therapi')]

>> Lemmatization: 
 [('Medication', 'Medication'), ('adherence', 'adherence'), ('studied', 'studied'), ('drug', 'drug'), ('therapy', 'therapy')]



========================================== PARAGRAPH 563 ===========================================

problem and co-occurred with concepts related to patient-centred interventions targeting self- 

------------------- Sentence 1 -------------------

problem and co-occurred with concepts related to patient-centred interventions targeting self-

>> Tokens are: 
 ['problem', 'co-occurred', 'concepts', 'related', 'patient-centred', 'interventions', 'targeting', 'self-']

>> Bigrams are: 
 [('problem', 'co-occurred'), ('co-occurred', 'concepts'), ('concepts', 'related'), ('related', 'patient-centred'), ('patient-centred', 'interventions'), ('interventions', 'targeting'), ('targeting', 'self-')]

>> Trigrams are: 
 [('problem', 'co-occurred', 'concepts'), ('co-occurred', 'concepts', 'related'), ('concepts', 'related', 'patient-centred'), ('related', 'patient-centred', 'interventions'), ('patient-centred', 'interventions', 'targeting'), ('interventions', 'targeting', 'self-')]

>> POS Tags are: 
 [('problem', 'NN'), ('co-occurred', 'JJ'), ('concepts', 'NNS'), ('related', 'VBN'), ('patient-centred', 'JJ'), ('interventions', 'NNS'), ('targeting', 'VBG'), ('self-', 'NN')]

>> Noun Phrases are: 
 ['problem', 'co-occurred concepts', 'patient-centred interventions', 'self-']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('problem', 'problem'), ('co-occurred', 'co-occur'), ('concepts', 'concept'), ('related', 'relat'), ('patient-centred', 'patient-centr'), ('interventions', 'intervent'), ('targeting', 'target'), ('self-', 'self-')]

>> Stemming using Snowball Stemmer: 
 [('problem', 'problem'), ('co-occurred', 'co-occur'), ('concepts', 'concept'), ('related', 'relat'), ('patient-centred', 'patient-centr'), ('interventions', 'intervent'), ('targeting', 'target'), ('self-', 'self-')]

>> Lemmatization: 
 [('problem', 'problem'), ('co-occurred', 'co-occurred'), ('concepts', 'concept'), ('related', 'related'), ('patient-centred', 'patient-centred'), ('interventions', 'intervention'), ('targeting', 'targeting'), ('self-', 'self-')]



========================================== PARAGRAPH 564 ===========================================

management. The enhanced model consists of 65 concepts clustered into 14 constructs. The  

------------------- Sentence 1 -------------------

management.

>> Tokens are: 
 ['management', '.']

>> Bigrams are: 
 [('management', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('management', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['management']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('management', 'manag'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('management', 'manag'), ('.', '.')]

>> Lemmatization: 
 [('management', 'management'), ('.', '.')]


------------------- Sentence 2 -------------------

The enhanced model consists of 65 concepts clustered into 14 constructs.

>> Tokens are: 
 ['The', 'enhanced', 'model', 'consists', '65', 'concepts', 'clustered', '14', 'constructs', '.']

>> Bigrams are: 
 [('The', 'enhanced'), ('enhanced', 'model'), ('model', 'consists'), ('consists', '65'), ('65', 'concepts'), ('concepts', 'clustered'), ('clustered', '14'), ('14', 'constructs'), ('constructs', '.')]

>> Trigrams are: 
 [('The', 'enhanced', 'model'), ('enhanced', 'model', 'consists'), ('model', 'consists', '65'), ('consists', '65', 'concepts'), ('65', 'concepts', 'clustered'), ('concepts', 'clustered', '14'), ('clustered', '14', 'constructs'), ('14', 'constructs', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('enhanced', 'JJ'), ('model', 'NN'), ('consists', 'VBZ'), ('65', 'CD'), ('concepts', 'NNS'), ('clustered', 'VBD'), ('14', 'CD'), ('constructs', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['The enhanced model', 'concepts', 'constructs']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('enhanced', 'enhanc'), ('model', 'model'), ('consists', 'consist'), ('65', '65'), ('concepts', 'concept'), ('clustered', 'cluster'), ('14', '14'), ('constructs', 'construct'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('enhanced', 'enhanc'), ('model', 'model'), ('consists', 'consist'), ('65', '65'), ('concepts', 'concept'), ('clustered', 'cluster'), ('14', '14'), ('constructs', 'construct'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('enhanced', 'enhanced'), ('model', 'model'), ('consists', 'consists'), ('65', '65'), ('concepts', 'concept'), ('clustered', 'clustered'), ('14', '14'), ('constructs', 'construct'), ('.', '.')]


------------------- Sentence 3 -------------------

The

>> Tokens are: 
 ['The']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('The', 'DT')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the')]

>> Lemmatization: 
 [('The', 'The')]



========================================== PARAGRAPH 565 ===========================================

framework requires additional refinement and evaluation to determine its relevance and  

------------------- Sentence 1 -------------------

framework requires additional refinement and evaluation to determine its relevance and

>> Tokens are: 
 ['framework', 'requires', 'additional', 'refinement', 'evaluation', 'determine', 'relevance']

>> Bigrams are: 
 [('framework', 'requires'), ('requires', 'additional'), ('additional', 'refinement'), ('refinement', 'evaluation'), ('evaluation', 'determine'), ('determine', 'relevance')]

>> Trigrams are: 
 [('framework', 'requires', 'additional'), ('requires', 'additional', 'refinement'), ('additional', 'refinement', 'evaluation'), ('refinement', 'evaluation', 'determine'), ('evaluation', 'determine', 'relevance')]

>> POS Tags are: 
 [('framework', 'NN'), ('requires', 'VBZ'), ('additional', 'JJ'), ('refinement', 'NN'), ('evaluation', 'NN'), ('determine', 'NN'), ('relevance', 'NN')]

>> Noun Phrases are: 
 ['framework', 'additional refinement evaluation determine relevance']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('framework', 'framework'), ('requires', 'requir'), ('additional', 'addit'), ('refinement', 'refin'), ('evaluation', 'evalu'), ('determine', 'determin'), ('relevance', 'relev')]

>> Stemming using Snowball Stemmer: 
 [('framework', 'framework'), ('requires', 'requir'), ('additional', 'addit'), ('refinement', 'refin'), ('evaluation', 'evalu'), ('determine', 'determin'), ('relevance', 'relev')]

>> Lemmatization: 
 [('framework', 'framework'), ('requires', 'requires'), ('additional', 'additional'), ('refinement', 'refinement'), ('evaluation', 'evaluation'), ('determine', 'determine'), ('relevance', 'relevance')]



========================================== PARAGRAPH 566 ===========================================

applicability across a broad audience including underserved settings.  

------------------- Sentence 1 -------------------

applicability across a broad audience including underserved settings.

>> Tokens are: 
 ['applicability', 'across', 'broad', 'audience', 'including', 'underserved', 'settings', '.']

>> Bigrams are: 
 [('applicability', 'across'), ('across', 'broad'), ('broad', 'audience'), ('audience', 'including'), ('including', 'underserved'), ('underserved', 'settings'), ('settings', '.')]

>> Trigrams are: 
 [('applicability', 'across', 'broad'), ('across', 'broad', 'audience'), ('broad', 'audience', 'including'), ('audience', 'including', 'underserved'), ('including', 'underserved', 'settings'), ('underserved', 'settings', '.')]

>> POS Tags are: 
 [('applicability', 'NN'), ('across', 'IN'), ('broad', 'JJ'), ('audience', 'NN'), ('including', 'VBG'), ('underserved', 'JJ'), ('settings', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['applicability', 'broad audience', 'underserved settings']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('applicability', 'applic'), ('across', 'across'), ('broad', 'broad'), ('audience', 'audienc'), ('including', 'includ'), ('underserved', 'underserv'), ('settings', 'set'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('applicability', 'applic'), ('across', 'across'), ('broad', 'broad'), ('audience', 'audienc'), ('including', 'includ'), ('underserved', 'underserv'), ('settings', 'set'), ('.', '.')]

>> Lemmatization: 
 [('applicability', 'applicability'), ('across', 'across'), ('broad', 'broad'), ('audience', 'audience'), ('including', 'including'), ('underserved', 'underserved'), ('settings', 'setting'), ('.', '.')]



========================================== PARAGRAPH 567 ===========================================

Link: https://www.ncbi.nlm.nih.gov/pubmed/28269895?dopt=Abstract  

------------------- Sentence 1 -------------------

Link: https://www.ncbi.nlm.nih.gov/pubmed/28269895?dopt=Abstract

>> Tokens are: 
 ['Link', ':', 'https', ':', '//www.ncbi.nlm.nih.gov/pubmed/28269895', '?', 'dopt=Abstract']

>> Bigrams are: 
 [('Link', ':'), (':', 'https'), ('https', ':'), (':', '//www.ncbi.nlm.nih.gov/pubmed/28269895'), ('//www.ncbi.nlm.nih.gov/pubmed/28269895', '?'), ('?', 'dopt=Abstract')]

>> Trigrams are: 
 [('Link', ':', 'https'), (':', 'https', ':'), ('https', ':', '//www.ncbi.nlm.nih.gov/pubmed/28269895'), (':', '//www.ncbi.nlm.nih.gov/pubmed/28269895', '?'), ('//www.ncbi.nlm.nih.gov/pubmed/28269895', '?', 'dopt=Abstract')]

>> POS Tags are: 
 [('Link', 'NN'), (':', ':'), ('https', 'NN'), (':', ':'), ('//www.ncbi.nlm.nih.gov/pubmed/28269895', 'NN'), ('?', '.'), ('dopt=Abstract', 'NN')]

>> Noun Phrases are: 
 ['Link', 'https', '//www.ncbi.nlm.nih.gov/pubmed/28269895', 'dopt=Abstract']

>> Named Entities are: 
 [('GPE', 'Link')] 

>> Stemming using Porter Stemmer: 
 [('Link', 'link'), (':', ':'), ('https', 'http'), (':', ':'), ('//www.ncbi.nlm.nih.gov/pubmed/28269895', '//www.ncbi.nlm.nih.gov/pubmed/28269895'), ('?', '?'), ('dopt=Abstract', 'dopt=abstract')]

>> Stemming using Snowball Stemmer: 
 [('Link', 'link'), (':', ':'), ('https', 'https'), (':', ':'), ('//www.ncbi.nlm.nih.gov/pubmed/28269895', '//www.ncbi.nlm.nih.gov/pubmed/28269895'), ('?', '?'), ('dopt=Abstract', 'dopt=abstract')]

>> Lemmatization: 
 [('Link', 'Link'), (':', ':'), ('https', 'http'), (':', ':'), ('//www.ncbi.nlm.nih.gov/pubmed/28269895', '//www.ncbi.nlm.nih.gov/pubmed/28269895'), ('?', '?'), ('dopt=Abstract', 'dopt=Abstract')]



========================================== PARAGRAPH 568 ===========================================

8.5 Meet the Pilot, world’s first language translating earbuds [108]  

------------------- Sentence 1 -------------------

8.5 Meet the Pilot, world’s first language translating earbuds [108]

>> Tokens are: 
 ['8.5', 'Meet', 'Pilot', ',', 'world', '’', 'first', 'language', 'translating', 'earbuds', '[', '108', ']']

>> Bigrams are: 
 [('8.5', 'Meet'), ('Meet', 'Pilot'), ('Pilot', ','), (',', 'world'), ('world', '’'), ('’', 'first'), ('first', 'language'), ('language', 'translating'), ('translating', 'earbuds'), ('earbuds', '['), ('[', '108'), ('108', ']')]

>> Trigrams are: 
 [('8.5', 'Meet', 'Pilot'), ('Meet', 'Pilot', ','), ('Pilot', ',', 'world'), (',', 'world', '’'), ('world', '’', 'first'), ('’', 'first', 'language'), ('first', 'language', 'translating'), ('language', 'translating', 'earbuds'), ('translating', 'earbuds', '['), ('earbuds', '[', '108'), ('[', '108', ']')]

>> POS Tags are: 
 [('8.5', 'CD'), ('Meet', 'NNP'), ('Pilot', 'NNP'), (',', ','), ('world', 'NN'), ('’', 'NN'), ('first', 'JJ'), ('language', 'NN'), ('translating', 'VBG'), ('earbuds', 'JJ'), ('[', '$'), ('108', 'CD'), (']', 'NN')]

>> Noun Phrases are: 
 ['Meet Pilot', 'world ’', 'first language', ']']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('8.5', '8.5'), ('Meet', 'meet'), ('Pilot', 'pilot'), (',', ','), ('world', 'world'), ('’', '’'), ('first', 'first'), ('language', 'languag'), ('translating', 'translat'), ('earbuds', 'earbud'), ('[', '['), ('108', '108'), (']', ']')]

>> Stemming using Snowball Stemmer: 
 [('8.5', '8.5'), ('Meet', 'meet'), ('Pilot', 'pilot'), (',', ','), ('world', 'world'), ('’', '’'), ('first', 'first'), ('language', 'languag'), ('translating', 'translat'), ('earbuds', 'earbud'), ('[', '['), ('108', '108'), (']', ']')]

>> Lemmatization: 
 [('8.5', '8.5'), ('Meet', 'Meet'), ('Pilot', 'Pilot'), (',', ','), ('world', 'world'), ('’', '’'), ('first', 'first'), ('language', 'language'), ('translating', 'translating'), ('earbuds', 'earbuds'), ('[', '['), ('108', '108'), (']', ']')]



========================================== PARAGRAPH 569 ===========================================

The world’s first smart earpiece Pilot will soon be transcribed over 15 languages. According  

------------------- Sentence 1 -------------------

The world’s first smart earpiece Pilot will soon be transcribed over 15 languages.

>> Tokens are: 
 ['The', 'world', '’', 'first', 'smart', 'earpiece', 'Pilot', 'soon', 'transcribed', '15', 'languages', '.']

>> Bigrams are: 
 [('The', 'world'), ('world', '’'), ('’', 'first'), ('first', 'smart'), ('smart', 'earpiece'), ('earpiece', 'Pilot'), ('Pilot', 'soon'), ('soon', 'transcribed'), ('transcribed', '15'), ('15', 'languages'), ('languages', '.')]

>> Trigrams are: 
 [('The', 'world', '’'), ('world', '’', 'first'), ('’', 'first', 'smart'), ('first', 'smart', 'earpiece'), ('smart', 'earpiece', 'Pilot'), ('earpiece', 'Pilot', 'soon'), ('Pilot', 'soon', 'transcribed'), ('soon', 'transcribed', '15'), ('transcribed', '15', 'languages'), ('15', 'languages', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('world', 'NN'), ('’', 'NN'), ('first', 'RB'), ('smart', 'JJ'), ('earpiece', 'NN'), ('Pilot', 'NNP'), ('soon', 'RB'), ('transcribed', 'VBD'), ('15', 'CD'), ('languages', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['The world ’', 'smart earpiece Pilot', 'languages']

>> Named Entities are: 
 [('PERSON', 'Pilot')] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('world', 'world'), ('’', '’'), ('first', 'first'), ('smart', 'smart'), ('earpiece', 'earpiec'), ('Pilot', 'pilot'), ('soon', 'soon'), ('transcribed', 'transcrib'), ('15', '15'), ('languages', 'languag'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('world', 'world'), ('’', '’'), ('first', 'first'), ('smart', 'smart'), ('earpiece', 'earpiec'), ('Pilot', 'pilot'), ('soon', 'soon'), ('transcribed', 'transcrib'), ('15', '15'), ('languages', 'languag'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('world', 'world'), ('’', '’'), ('first', 'first'), ('smart', 'smart'), ('earpiece', 'earpiece'), ('Pilot', 'Pilot'), ('soon', 'soon'), ('transcribed', 'transcribed'), ('15', '15'), ('languages', 'language'), ('.', '.')]


------------------- Sentence 2 -------------------

According

>> Tokens are: 
 ['According']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('According', 'VBG')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('According', 'accord')]

>> Stemming using Snowball Stemmer: 
 [('According', 'accord')]

>> Lemmatization: 
 [('According', 'According')]



========================================== PARAGRAPH 570 ===========================================

to Spring wise, Waverly Labs’ Pilot can already transliterate five spoken languages, English,  

------------------- Sentence 1 -------------------

to Spring wise, Waverly Labs’ Pilot can already transliterate five spoken languages, English,

>> Tokens are: 
 ['Spring', 'wise', ',', 'Waverly', 'Labs', '’', 'Pilot', 'already', 'transliterate', 'five', 'spoken', 'languages', ',', 'English', ',']

>> Bigrams are: 
 [('Spring', 'wise'), ('wise', ','), (',', 'Waverly'), ('Waverly', 'Labs'), ('Labs', '’'), ('’', 'Pilot'), ('Pilot', 'already'), ('already', 'transliterate'), ('transliterate', 'five'), ('five', 'spoken'), ('spoken', 'languages'), ('languages', ','), (',', 'English'), ('English', ',')]

>> Trigrams are: 
 [('Spring', 'wise', ','), ('wise', ',', 'Waverly'), (',', 'Waverly', 'Labs'), ('Waverly', 'Labs', '’'), ('Labs', '’', 'Pilot'), ('’', 'Pilot', 'already'), ('Pilot', 'already', 'transliterate'), ('already', 'transliterate', 'five'), ('transliterate', 'five', 'spoken'), ('five', 'spoken', 'languages'), ('spoken', 'languages', ','), ('languages', ',', 'English'), (',', 'English', ',')]

>> POS Tags are: 
 [('Spring', 'NN'), ('wise', 'NN'), (',', ','), ('Waverly', 'NNP'), ('Labs', 'NNP'), ('’', 'NNP'), ('Pilot', 'NNP'), ('already', 'RB'), ('transliterate', 'VBP'), ('five', 'CD'), ('spoken', 'JJ'), ('languages', 'NNS'), (',', ','), ('English', 'NNP'), (',', ',')]

>> Noun Phrases are: 
 ['Spring wise', 'Waverly Labs ’ Pilot', 'spoken languages', 'English']

>> Named Entities are: 
 [('GPE', 'Spring'), ('PERSON', 'Waverly Labs'), ('GPE', 'English')] 

>> Stemming using Porter Stemmer: 
 [('Spring', 'spring'), ('wise', 'wise'), (',', ','), ('Waverly', 'waverli'), ('Labs', 'lab'), ('’', '’'), ('Pilot', 'pilot'), ('already', 'alreadi'), ('transliterate', 'transliter'), ('five', 'five'), ('spoken', 'spoken'), ('languages', 'languag'), (',', ','), ('English', 'english'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('Spring', 'spring'), ('wise', 'wise'), (',', ','), ('Waverly', 'waver'), ('Labs', 'lab'), ('’', '’'), ('Pilot', 'pilot'), ('already', 'alreadi'), ('transliterate', 'transliter'), ('five', 'five'), ('spoken', 'spoken'), ('languages', 'languag'), (',', ','), ('English', 'english'), (',', ',')]

>> Lemmatization: 
 [('Spring', 'Spring'), ('wise', 'wise'), (',', ','), ('Waverly', 'Waverly'), ('Labs', 'Labs'), ('’', '’'), ('Pilot', 'Pilot'), ('already', 'already'), ('transliterate', 'transliterate'), ('five', 'five'), ('spoken', 'spoken'), ('languages', 'language'), (',', ','), ('English', 'English'), (',', ',')]



========================================== PARAGRAPH 571 ===========================================

French, Italian, Portuguese and Spanish, and seven written affixed languages, German, Hindi,  

------------------- Sentence 1 -------------------

French, Italian, Portuguese and Spanish, and seven written affixed languages, German, Hindi,

>> Tokens are: 
 ['French', ',', 'Italian', ',', 'Portuguese', 'Spanish', ',', 'seven', 'written', 'affixed', 'languages', ',', 'German', ',', 'Hindi', ',']

>> Bigrams are: 
 [('French', ','), (',', 'Italian'), ('Italian', ','), (',', 'Portuguese'), ('Portuguese', 'Spanish'), ('Spanish', ','), (',', 'seven'), ('seven', 'written'), ('written', 'affixed'), ('affixed', 'languages'), ('languages', ','), (',', 'German'), ('German', ','), (',', 'Hindi'), ('Hindi', ',')]

>> Trigrams are: 
 [('French', ',', 'Italian'), (',', 'Italian', ','), ('Italian', ',', 'Portuguese'), (',', 'Portuguese', 'Spanish'), ('Portuguese', 'Spanish', ','), ('Spanish', ',', 'seven'), (',', 'seven', 'written'), ('seven', 'written', 'affixed'), ('written', 'affixed', 'languages'), ('affixed', 'languages', ','), ('languages', ',', 'German'), (',', 'German', ','), ('German', ',', 'Hindi'), (',', 'Hindi', ',')]

>> POS Tags are: 
 [('French', 'JJ'), (',', ','), ('Italian', 'JJ'), (',', ','), ('Portuguese', 'JJ'), ('Spanish', 'JJ'), (',', ','), ('seven', 'CD'), ('written', 'VBN'), ('affixed', 'JJ'), ('languages', 'NNS'), (',', ','), ('German', 'JJ'), (',', ','), ('Hindi', 'NNP'), (',', ',')]

>> Noun Phrases are: 
 ['affixed languages', 'Hindi']

>> Named Entities are: 
 [('GPE', 'French'), ('GPE', 'Italian'), ('GPE', 'Portuguese'), ('GPE', 'Spanish'), ('GPE', 'German'), ('PERSON', 'Hindi')] 

>> Stemming using Porter Stemmer: 
 [('French', 'french'), (',', ','), ('Italian', 'italian'), (',', ','), ('Portuguese', 'portugues'), ('Spanish', 'spanish'), (',', ','), ('seven', 'seven'), ('written', 'written'), ('affixed', 'affix'), ('languages', 'languag'), (',', ','), ('German', 'german'), (',', ','), ('Hindi', 'hindi'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('French', 'french'), (',', ','), ('Italian', 'italian'), (',', ','), ('Portuguese', 'portugues'), ('Spanish', 'spanish'), (',', ','), ('seven', 'seven'), ('written', 'written'), ('affixed', 'affix'), ('languages', 'languag'), (',', ','), ('German', 'german'), (',', ','), ('Hindi', 'hindi'), (',', ',')]

>> Lemmatization: 
 [('French', 'French'), (',', ','), ('Italian', 'Italian'), (',', ','), ('Portuguese', 'Portuguese'), ('Spanish', 'Spanish'), (',', ','), ('seven', 'seven'), ('written', 'written'), ('affixed', 'affixed'), ('languages', 'language'), (',', ','), ('German', 'German'), (',', ','), ('Hindi', 'Hindi'), (',', ',')]



========================================== PARAGRAPH 572 ===========================================

Russian, Japanese, Arabic, Korean and Mandarin Chinese. The Pilot earpiece is connected  

------------------- Sentence 1 -------------------

Russian, Japanese, Arabic, Korean and Mandarin Chinese.

>> Tokens are: 
 ['Russian', ',', 'Japanese', ',', 'Arabic', ',', 'Korean', 'Mandarin', 'Chinese', '.']

>> Bigrams are: 
 [('Russian', ','), (',', 'Japanese'), ('Japanese', ','), (',', 'Arabic'), ('Arabic', ','), (',', 'Korean'), ('Korean', 'Mandarin'), ('Mandarin', 'Chinese'), ('Chinese', '.')]

>> Trigrams are: 
 [('Russian', ',', 'Japanese'), (',', 'Japanese', ','), ('Japanese', ',', 'Arabic'), (',', 'Arabic', ','), ('Arabic', ',', 'Korean'), (',', 'Korean', 'Mandarin'), ('Korean', 'Mandarin', 'Chinese'), ('Mandarin', 'Chinese', '.')]

>> POS Tags are: 
 [('Russian', 'JJ'), (',', ','), ('Japanese', 'JJ'), (',', ','), ('Arabic', 'NNP'), (',', ','), ('Korean', 'NNP'), ('Mandarin', 'NNP'), ('Chinese', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Arabic', 'Korean Mandarin Chinese']

>> Named Entities are: 
 [('GPE', 'Russian'), ('GPE', 'Japanese'), ('PERSON', 'Arabic'), ('PERSON', 'Korean Mandarin Chinese')] 

>> Stemming using Porter Stemmer: 
 [('Russian', 'russian'), (',', ','), ('Japanese', 'japanes'), (',', ','), ('Arabic', 'arab'), (',', ','), ('Korean', 'korean'), ('Mandarin', 'mandarin'), ('Chinese', 'chines'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Russian', 'russian'), (',', ','), ('Japanese', 'japanes'), (',', ','), ('Arabic', 'arab'), (',', ','), ('Korean', 'korean'), ('Mandarin', 'mandarin'), ('Chinese', 'chines'), ('.', '.')]

>> Lemmatization: 
 [('Russian', 'Russian'), (',', ','), ('Japanese', 'Japanese'), (',', ','), ('Arabic', 'Arabic'), (',', ','), ('Korean', 'Korean'), ('Mandarin', 'Mandarin'), ('Chinese', 'Chinese'), ('.', '.')]


------------------- Sentence 2 -------------------

The Pilot earpiece is connected

>> Tokens are: 
 ['The', 'Pilot', 'earpiece', 'connected']

>> Bigrams are: 
 [('The', 'Pilot'), ('Pilot', 'earpiece'), ('earpiece', 'connected')]

>> Trigrams are: 
 [('The', 'Pilot', 'earpiece'), ('Pilot', 'earpiece', 'connected')]

>> POS Tags are: 
 [('The', 'DT'), ('Pilot', 'NNP'), ('earpiece', 'NN'), ('connected', 'VBD')]

>> Noun Phrases are: 
 ['The Pilot earpiece']

>> Named Entities are: 
 [('ORGANIZATION', 'Pilot')] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('Pilot', 'pilot'), ('earpiece', 'earpiec'), ('connected', 'connect')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('Pilot', 'pilot'), ('earpiece', 'earpiec'), ('connected', 'connect')]

>> Lemmatization: 
 [('The', 'The'), ('Pilot', 'Pilot'), ('earpiece', 'earpiece'), ('connected', 'connected')]



========================================== PARAGRAPH 573 ===========================================

via Bluetooth to the Pilot speech translation app, which uses speech recognition, machine  

------------------- Sentence 1 -------------------

via Bluetooth to the Pilot speech translation app, which uses speech recognition, machine

>> Tokens are: 
 ['via', 'Bluetooth', 'Pilot', 'speech', 'translation', 'app', ',', 'uses', 'speech', 'recognition', ',', 'machine']

>> Bigrams are: 
 [('via', 'Bluetooth'), ('Bluetooth', 'Pilot'), ('Pilot', 'speech'), ('speech', 'translation'), ('translation', 'app'), ('app', ','), (',', 'uses'), ('uses', 'speech'), ('speech', 'recognition'), ('recognition', ','), (',', 'machine')]

>> Trigrams are: 
 [('via', 'Bluetooth', 'Pilot'), ('Bluetooth', 'Pilot', 'speech'), ('Pilot', 'speech', 'translation'), ('speech', 'translation', 'app'), ('translation', 'app', ','), ('app', ',', 'uses'), (',', 'uses', 'speech'), ('uses', 'speech', 'recognition'), ('speech', 'recognition', ','), ('recognition', ',', 'machine')]

>> POS Tags are: 
 [('via', 'IN'), ('Bluetooth', 'NNP'), ('Pilot', 'NNP'), ('speech', 'NN'), ('translation', 'NN'), ('app', 'NN'), (',', ','), ('uses', 'VBZ'), ('speech', 'JJ'), ('recognition', 'NN'), (',', ','), ('machine', 'NN')]

>> Noun Phrases are: 
 ['Bluetooth Pilot speech translation app', 'speech recognition', 'machine']

>> Named Entities are: 
 [('PERSON', 'Bluetooth Pilot')] 

>> Stemming using Porter Stemmer: 
 [('via', 'via'), ('Bluetooth', 'bluetooth'), ('Pilot', 'pilot'), ('speech', 'speech'), ('translation', 'translat'), ('app', 'app'), (',', ','), ('uses', 'use'), ('speech', 'speech'), ('recognition', 'recognit'), (',', ','), ('machine', 'machin')]

>> Stemming using Snowball Stemmer: 
 [('via', 'via'), ('Bluetooth', 'bluetooth'), ('Pilot', 'pilot'), ('speech', 'speech'), ('translation', 'translat'), ('app', 'app'), (',', ','), ('uses', 'use'), ('speech', 'speech'), ('recognition', 'recognit'), (',', ','), ('machine', 'machin')]

>> Lemmatization: 
 [('via', 'via'), ('Bluetooth', 'Bluetooth'), ('Pilot', 'Pilot'), ('speech', 'speech'), ('translation', 'translation'), ('app', 'app'), (',', ','), ('uses', 'us'), ('speech', 'speech'), ('recognition', 'recognition'), (',', ','), ('machine', 'machine')]



========================================== PARAGRAPH 574 ===========================================

translation and machine learning and speech synthesis technology.  

------------------- Sentence 1 -------------------

translation and machine learning and speech synthesis technology.

>> Tokens are: 
 ['translation', 'machine', 'learning', 'speech', 'synthesis', 'technology', '.']

>> Bigrams are: 
 [('translation', 'machine'), ('machine', 'learning'), ('learning', 'speech'), ('speech', 'synthesis'), ('synthesis', 'technology'), ('technology', '.')]

>> Trigrams are: 
 [('translation', 'machine', 'learning'), ('machine', 'learning', 'speech'), ('learning', 'speech', 'synthesis'), ('speech', 'synthesis', 'technology'), ('synthesis', 'technology', '.')]

>> POS Tags are: 
 [('translation', 'NN'), ('machine', 'NN'), ('learning', 'VBG'), ('speech', 'JJ'), ('synthesis', 'NN'), ('technology', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['translation machine', 'speech synthesis technology']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('translation', 'translat'), ('machine', 'machin'), ('learning', 'learn'), ('speech', 'speech'), ('synthesis', 'synthesi'), ('technology', 'technolog'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('translation', 'translat'), ('machine', 'machin'), ('learning', 'learn'), ('speech', 'speech'), ('synthesis', 'synthesi'), ('technology', 'technolog'), ('.', '.')]

>> Lemmatization: 
 [('translation', 'translation'), ('machine', 'machine'), ('learning', 'learning'), ('speech', 'speech'), ('synthesis', 'synthesis'), ('technology', 'technology'), ('.', '.')]



========================================== PARAGRAPH 575 ===========================================

Simultaneously, the user will hear the translated version of the speech on the second earpiece.  

------------------- Sentence 1 -------------------

Simultaneously, the user will hear the translated version of the speech on the second earpiece.

>> Tokens are: 
 ['Simultaneously', ',', 'user', 'hear', 'translated', 'version', 'speech', 'second', 'earpiece', '.']

>> Bigrams are: 
 [('Simultaneously', ','), (',', 'user'), ('user', 'hear'), ('hear', 'translated'), ('translated', 'version'), ('version', 'speech'), ('speech', 'second'), ('second', 'earpiece'), ('earpiece', '.')]

>> Trigrams are: 
 [('Simultaneously', ',', 'user'), (',', 'user', 'hear'), ('user', 'hear', 'translated'), ('hear', 'translated', 'version'), ('translated', 'version', 'speech'), ('version', 'speech', 'second'), ('speech', 'second', 'earpiece'), ('second', 'earpiece', '.')]

>> POS Tags are: 
 [('Simultaneously', 'RB'), (',', ','), ('user', 'JJ'), ('hear', 'NN'), ('translated', 'VBN'), ('version', 'NN'), ('speech', 'NN'), ('second', 'JJ'), ('earpiece', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['user hear', 'version speech', 'second earpiece']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Simultaneously', 'simultan'), (',', ','), ('user', 'user'), ('hear', 'hear'), ('translated', 'translat'), ('version', 'version'), ('speech', 'speech'), ('second', 'second'), ('earpiece', 'earpiec'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Simultaneously', 'simultan'), (',', ','), ('user', 'user'), ('hear', 'hear'), ('translated', 'translat'), ('version', 'version'), ('speech', 'speech'), ('second', 'second'), ('earpiece', 'earpiec'), ('.', '.')]

>> Lemmatization: 
 [('Simultaneously', 'Simultaneously'), (',', ','), ('user', 'user'), ('hear', 'hear'), ('translated', 'translated'), ('version', 'version'), ('speech', 'speech'), ('second', 'second'), ('earpiece', 'earpiece'), ('.', '.')]



========================================== PARAGRAPH 576 ===========================================

Moreover, it is not necessary that conversation would be taking place between two people  

------------------- Sentence 1 -------------------

Moreover, it is not necessary that conversation would be taking place between two people

>> Tokens are: 
 ['Moreover', ',', 'necessary', 'conversation', 'would', 'taking', 'place', 'two', 'people']

>> Bigrams are: 
 [('Moreover', ','), (',', 'necessary'), ('necessary', 'conversation'), ('conversation', 'would'), ('would', 'taking'), ('taking', 'place'), ('place', 'two'), ('two', 'people')]

>> Trigrams are: 
 [('Moreover', ',', 'necessary'), (',', 'necessary', 'conversation'), ('necessary', 'conversation', 'would'), ('conversation', 'would', 'taking'), ('would', 'taking', 'place'), ('taking', 'place', 'two'), ('place', 'two', 'people')]

>> POS Tags are: 
 [('Moreover', 'RB'), (',', ','), ('necessary', 'JJ'), ('conversation', 'NN'), ('would', 'MD'), ('taking', 'VBG'), ('place', 'NN'), ('two', 'CD'), ('people', 'NNS')]

>> Noun Phrases are: 
 ['necessary conversation', 'place', 'people']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Moreover', 'moreov'), (',', ','), ('necessary', 'necessari'), ('conversation', 'convers'), ('would', 'would'), ('taking', 'take'), ('place', 'place'), ('two', 'two'), ('people', 'peopl')]

>> Stemming using Snowball Stemmer: 
 [('Moreover', 'moreov'), (',', ','), ('necessary', 'necessari'), ('conversation', 'convers'), ('would', 'would'), ('taking', 'take'), ('place', 'place'), ('two', 'two'), ('people', 'peopl')]

>> Lemmatization: 
 [('Moreover', 'Moreover'), (',', ','), ('necessary', 'necessary'), ('conversation', 'conversation'), ('would', 'would'), ('taking', 'taking'), ('place', 'place'), ('two', 'two'), ('people', 'people')]



========================================== PARAGRAPH 577 ===========================================

only the users can join in and discuss as a group. As if now the user may experience a few  

------------------- Sentence 1 -------------------

only the users can join in and discuss as a group.

>> Tokens are: 
 ['users', 'join', 'discuss', 'group', '.']

>> Bigrams are: 
 [('users', 'join'), ('join', 'discuss'), ('discuss', 'group'), ('group', '.')]

>> Trigrams are: 
 [('users', 'join', 'discuss'), ('join', 'discuss', 'group'), ('discuss', 'group', '.')]

>> POS Tags are: 
 [('users', 'NNS'), ('join', 'VBP'), ('discuss', 'JJ'), ('group', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['users', 'discuss group']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('users', 'user'), ('join', 'join'), ('discuss', 'discuss'), ('group', 'group'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('users', 'user'), ('join', 'join'), ('discuss', 'discuss'), ('group', 'group'), ('.', '.')]

>> Lemmatization: 
 [('users', 'user'), ('join', 'join'), ('discuss', 'discus'), ('group', 'group'), ('.', '.')]


------------------- Sentence 2 -------------------

As if now the user may experience a few

>> Tokens are: 
 ['As', 'user', 'may', 'experience']

>> Bigrams are: 
 [('As', 'user'), ('user', 'may'), ('may', 'experience')]

>> Trigrams are: 
 [('As', 'user', 'may'), ('user', 'may', 'experience')]

>> POS Tags are: 
 [('As', 'IN'), ('user', 'NN'), ('may', 'MD'), ('experience', 'VB')]

>> Noun Phrases are: 
 ['user']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('As', 'as'), ('user', 'user'), ('may', 'may'), ('experience', 'experi')]

>> Stemming using Snowball Stemmer: 
 [('As', 'as'), ('user', 'user'), ('may', 'may'), ('experience', 'experi')]

>> Lemmatization: 
 [('As', 'As'), ('user', 'user'), ('may', 'may'), ('experience', 'experience')]



========================================== PARAGRAPH 578 ===========================================

second lag interpolated the speech and translation, which Waverly Labs pursue to reduce.  

------------------- Sentence 1 -------------------

second lag interpolated the speech and translation, which Waverly Labs pursue to reduce.

>> Tokens are: 
 ['second', 'lag', 'interpolated', 'speech', 'translation', ',', 'Waverly', 'Labs', 'pursue', 'reduce', '.']

>> Bigrams are: 
 [('second', 'lag'), ('lag', 'interpolated'), ('interpolated', 'speech'), ('speech', 'translation'), ('translation', ','), (',', 'Waverly'), ('Waverly', 'Labs'), ('Labs', 'pursue'), ('pursue', 'reduce'), ('reduce', '.')]

>> Trigrams are: 
 [('second', 'lag', 'interpolated'), ('lag', 'interpolated', 'speech'), ('interpolated', 'speech', 'translation'), ('speech', 'translation', ','), ('translation', ',', 'Waverly'), (',', 'Waverly', 'Labs'), ('Waverly', 'Labs', 'pursue'), ('Labs', 'pursue', 'reduce'), ('pursue', 'reduce', '.')]

>> POS Tags are: 
 [('second', 'JJ'), ('lag', 'NN'), ('interpolated', 'VBD'), ('speech', 'JJ'), ('translation', 'NN'), (',', ','), ('Waverly', 'NNP'), ('Labs', 'NNP'), ('pursue', 'NN'), ('reduce', 'VB'), ('.', '.')]

>> Noun Phrases are: 
 ['second lag', 'speech translation', 'Waverly Labs pursue']

>> Named Entities are: 
 [('PERSON', 'Waverly Labs')] 

>> Stemming using Porter Stemmer: 
 [('second', 'second'), ('lag', 'lag'), ('interpolated', 'interpol'), ('speech', 'speech'), ('translation', 'translat'), (',', ','), ('Waverly', 'waverli'), ('Labs', 'lab'), ('pursue', 'pursu'), ('reduce', 'reduc'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('second', 'second'), ('lag', 'lag'), ('interpolated', 'interpol'), ('speech', 'speech'), ('translation', 'translat'), (',', ','), ('Waverly', 'waver'), ('Labs', 'lab'), ('pursue', 'pursu'), ('reduce', 'reduc'), ('.', '.')]

>> Lemmatization: 
 [('second', 'second'), ('lag', 'lag'), ('interpolated', 'interpolated'), ('speech', 'speech'), ('translation', 'translation'), (',', ','), ('Waverly', 'Waverly'), ('Labs', 'Labs'), ('pursue', 'pursue'), ('reduce', 'reduce'), ('.', '.')]



========================================== PARAGRAPH 579 ===========================================

The Pilot earpiece will be available from September, but can be pre-ordered now for $249.  

------------------- Sentence 1 -------------------

The Pilot earpiece will be available from September, but can be pre-ordered now for $249.

>> Tokens are: 
 ['The', 'Pilot', 'earpiece', 'available', 'September', ',', 'pre-ordered', '$', '249', '.']

>> Bigrams are: 
 [('The', 'Pilot'), ('Pilot', 'earpiece'), ('earpiece', 'available'), ('available', 'September'), ('September', ','), (',', 'pre-ordered'), ('pre-ordered', '$'), ('$', '249'), ('249', '.')]

>> Trigrams are: 
 [('The', 'Pilot', 'earpiece'), ('Pilot', 'earpiece', 'available'), ('earpiece', 'available', 'September'), ('available', 'September', ','), ('September', ',', 'pre-ordered'), (',', 'pre-ordered', '$'), ('pre-ordered', '$', '249'), ('$', '249', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('Pilot', 'NNP'), ('earpiece', 'NN'), ('available', 'JJ'), ('September', 'NNP'), (',', ','), ('pre-ordered', 'JJ'), ('$', '$'), ('249', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['The Pilot earpiece', 'available September']

>> Named Entities are: 
 [('ORGANIZATION', 'Pilot')] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('Pilot', 'pilot'), ('earpiece', 'earpiec'), ('available', 'avail'), ('September', 'septemb'), (',', ','), ('pre-ordered', 'pre-ord'), ('$', '$'), ('249', '249'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('Pilot', 'pilot'), ('earpiece', 'earpiec'), ('available', 'avail'), ('September', 'septemb'), (',', ','), ('pre-ordered', 'pre-ord'), ('$', '$'), ('249', '249'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('Pilot', 'Pilot'), ('earpiece', 'earpiece'), ('available', 'available'), ('September', 'September'), (',', ','), ('pre-ordered', 'pre-ordered'), ('$', '$'), ('249', '249'), ('.', '.')]



========================================== PARAGRAPH 580 ===========================================

The earpieces can also be used for streaming music, answering voice calls and getting audio  

------------------- Sentence 1 -------------------

The earpieces can also be used for streaming music, answering voice calls and getting audio

>> Tokens are: 
 ['The', 'earpieces', 'also', 'used', 'streaming', 'music', ',', 'answering', 'voice', 'calls', 'getting', 'audio']

>> Bigrams are: 
 [('The', 'earpieces'), ('earpieces', 'also'), ('also', 'used'), ('used', 'streaming'), ('streaming', 'music'), ('music', ','), (',', 'answering'), ('answering', 'voice'), ('voice', 'calls'), ('calls', 'getting'), ('getting', 'audio')]

>> Trigrams are: 
 [('The', 'earpieces', 'also'), ('earpieces', 'also', 'used'), ('also', 'used', 'streaming'), ('used', 'streaming', 'music'), ('streaming', 'music', ','), ('music', ',', 'answering'), (',', 'answering', 'voice'), ('answering', 'voice', 'calls'), ('voice', 'calls', 'getting'), ('calls', 'getting', 'audio')]

>> POS Tags are: 
 [('The', 'DT'), ('earpieces', 'NNS'), ('also', 'RB'), ('used', 'VBD'), ('streaming', 'VBG'), ('music', 'NN'), (',', ','), ('answering', 'VBG'), ('voice', 'NN'), ('calls', 'VBZ'), ('getting', 'VBG'), ('audio', 'NN')]

>> Noun Phrases are: 
 ['The earpieces', 'music', 'voice', 'audio']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('earpieces', 'earpiec'), ('also', 'also'), ('used', 'use'), ('streaming', 'stream'), ('music', 'music'), (',', ','), ('answering', 'answer'), ('voice', 'voic'), ('calls', 'call'), ('getting', 'get'), ('audio', 'audio')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('earpieces', 'earpiec'), ('also', 'also'), ('used', 'use'), ('streaming', 'stream'), ('music', 'music'), (',', ','), ('answering', 'answer'), ('voice', 'voic'), ('calls', 'call'), ('getting', 'get'), ('audio', 'audio')]

>> Lemmatization: 
 [('The', 'The'), ('earpieces', 'earpiece'), ('also', 'also'), ('used', 'used'), ('streaming', 'streaming'), ('music', 'music'), (',', ','), ('answering', 'answering'), ('voice', 'voice'), ('calls', 'call'), ('getting', 'getting'), ('audio', 'audio')]



========================================== PARAGRAPH 581 ===========================================

notifications.  

------------------- Sentence 1 -------------------

notifications.

>> Tokens are: 
 ['notifications', '.']

>> Bigrams are: 
 [('notifications', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('notifications', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['notifications']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('notifications', 'notif'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('notifications', 'notif'), ('.', '.')]

>> Lemmatization: 
 [('notifications', 'notification'), ('.', '.')]



========================================== PARAGRAPH 582 ===========================================

Link:https://www.indiegogo.com/projects/meet-the-pilot-smart-earpiece-language-translator- 

------------------- Sentence 1 -------------------

Link:https://www.indiegogo.com/projects/meet-the-pilot-smart-earpiece-language-translator-

>> Tokens are: 
 ['Link', ':', 'https', ':', '//www.indiegogo.com/projects/meet-the-pilot-smart-earpiece-language-translator-']

>> Bigrams are: 
 [('Link', ':'), (':', 'https'), ('https', ':'), (':', '//www.indiegogo.com/projects/meet-the-pilot-smart-earpiece-language-translator-')]

>> Trigrams are: 
 [('Link', ':', 'https'), (':', 'https', ':'), ('https', ':', '//www.indiegogo.com/projects/meet-the-pilot-smart-earpiece-language-translator-')]

>> POS Tags are: 
 [('Link', 'NN'), (':', ':'), ('https', 'NN'), (':', ':'), ('//www.indiegogo.com/projects/meet-the-pilot-smart-earpiece-language-translator-', 'JJ')]

>> Noun Phrases are: 
 ['Link', 'https']

>> Named Entities are: 
 [('GPE', 'Link')] 

>> Stemming using Porter Stemmer: 
 [('Link', 'link'), (':', ':'), ('https', 'http'), (':', ':'), ('//www.indiegogo.com/projects/meet-the-pilot-smart-earpiece-language-translator-', '//www.indiegogo.com/projects/meet-the-pilot-smart-earpiece-language-translator-')]

>> Stemming using Snowball Stemmer: 
 [('Link', 'link'), (':', ':'), ('https', 'https'), (':', ':'), ('//www.indiegogo.com/projects/meet-the-pilot-smart-earpiece-language-translator-', '//www.indiegogo.com/projects/meet-the-pilot-smart-earpiece-language-translator-')]

>> Lemmatization: 
 [('Link', 'Link'), (':', ':'), ('https', 'http'), (':', ':'), ('//www.indiegogo.com/projects/meet-the-pilot-smart-earpiece-language-translator-', '//www.indiegogo.com/projects/meet-the-pilot-smart-earpiece-language-translator-')]



========================================== PARAGRAPH 583 ===========================================

headphones-travel#/  

------------------- Sentence 1 -------------------

headphones-travel#/

>> Tokens are: 
 ['headphones-travel', '#', '/']

>> Bigrams are: 
 [('headphones-travel', '#'), ('#', '/')]

>> Trigrams are: 
 [('headphones-travel', '#', '/')]

>> POS Tags are: 
 [('headphones-travel', 'JJ'), ('#', '#'), ('/', 'NN')]

>> Noun Phrases are: 
 ['/']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('headphones-travel', 'headphones-travel'), ('#', '#'), ('/', '/')]

>> Stemming using Snowball Stemmer: 
 [('headphones-travel', 'headphones-travel'), ('#', '#'), ('/', '/')]

>> Lemmatization: 
 [('headphones-travel', 'headphones-travel'), ('#', '#'), ('/', '/')]



========================================== PARAGRAPH 584 ===========================================

  


========================================== PARAGRAPH 585 ===========================================

REFRENCES  

------------------- Sentence 1 -------------------

REFRENCES

>> Tokens are: 
 ['REFRENCES']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('REFRENCES', 'NNS')]

>> Noun Phrases are: 
 ['REFRENCES']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('REFRENCES', 'refrenc')]

>> Stemming using Snowball Stemmer: 
 [('REFRENCES', 'refrenc')]

>> Lemmatization: 
 [('REFRENCES', 'REFRENCES')]



========================================== PARAGRAPH 586 ===========================================

[1] Chomsky, Noam, 1965, Aspects of the Theory of Syntax, Cambridge, Massachusetts:  

------------------- Sentence 1 -------------------

[1] Chomsky, Noam, 1965, Aspects of the Theory of Syntax, Cambridge, Massachusetts:

>> Tokens are: 
 ['[', '1', ']', 'Chomsky', ',', 'Noam', ',', '1965', ',', 'Aspects', 'Theory', 'Syntax', ',', 'Cambridge', ',', 'Massachusetts', ':']

>> Bigrams are: 
 [('[', '1'), ('1', ']'), (']', 'Chomsky'), ('Chomsky', ','), (',', 'Noam'), ('Noam', ','), (',', '1965'), ('1965', ','), (',', 'Aspects'), ('Aspects', 'Theory'), ('Theory', 'Syntax'), ('Syntax', ','), (',', 'Cambridge'), ('Cambridge', ','), (',', 'Massachusetts'), ('Massachusetts', ':')]

>> Trigrams are: 
 [('[', '1', ']'), ('1', ']', 'Chomsky'), (']', 'Chomsky', ','), ('Chomsky', ',', 'Noam'), (',', 'Noam', ','), ('Noam', ',', '1965'), (',', '1965', ','), ('1965', ',', 'Aspects'), (',', 'Aspects', 'Theory'), ('Aspects', 'Theory', 'Syntax'), ('Theory', 'Syntax', ','), ('Syntax', ',', 'Cambridge'), (',', 'Cambridge', ','), ('Cambridge', ',', 'Massachusetts'), (',', 'Massachusetts', ':')]

>> POS Tags are: 
 [('[', 'RB'), ('1', 'CD'), (']', 'JJ'), ('Chomsky', 'NNP'), (',', ','), ('Noam', 'NNP'), (',', ','), ('1965', 'CD'), (',', ','), ('Aspects', 'NNP'), ('Theory', 'NNP'), ('Syntax', 'NNP'), (',', ','), ('Cambridge', 'NNP'), (',', ','), ('Massachusetts', 'NNP'), (':', ':')]

>> Noun Phrases are: 
 ['] Chomsky', 'Noam', 'Aspects Theory Syntax', 'Cambridge', 'Massachusetts']

>> Named Entities are: 
 [('PERSON', 'Chomsky'), ('PERSON', 'Noam'), ('PERSON', 'Aspects Theory Syntax'), ('GPE', 'Cambridge'), ('GPE', 'Massachusetts')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('1', '1'), (']', ']'), ('Chomsky', 'chomski'), (',', ','), ('Noam', 'noam'), (',', ','), ('1965', '1965'), (',', ','), ('Aspects', 'aspect'), ('Theory', 'theori'), ('Syntax', 'syntax'), (',', ','), ('Cambridge', 'cambridg'), (',', ','), ('Massachusetts', 'massachusett'), (':', ':')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('1', '1'), (']', ']'), ('Chomsky', 'chomski'), (',', ','), ('Noam', 'noam'), (',', ','), ('1965', '1965'), (',', ','), ('Aspects', 'aspect'), ('Theory', 'theori'), ('Syntax', 'syntax'), (',', ','), ('Cambridge', 'cambridg'), (',', ','), ('Massachusetts', 'massachusett'), (':', ':')]

>> Lemmatization: 
 [('[', '['), ('1', '1'), (']', ']'), ('Chomsky', 'Chomsky'), (',', ','), ('Noam', 'Noam'), (',', ','), ('1965', '1965'), (',', ','), ('Aspects', 'Aspects'), ('Theory', 'Theory'), ('Syntax', 'Syntax'), (',', ','), ('Cambridge', 'Cambridge'), (',', ','), ('Massachusetts', 'Massachusetts'), (':', ':')]



========================================== PARAGRAPH 587 ===========================================

MIT Press.   

------------------- Sentence 1 -------------------

MIT Press.

>> Tokens are: 
 ['MIT', 'Press', '.']

>> Bigrams are: 
 [('MIT', 'Press'), ('Press', '.')]

>> Trigrams are: 
 [('MIT', 'Press', '.')]

>> POS Tags are: 
 [('MIT', 'NNP'), ('Press', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['MIT Press']

>> Named Entities are: 
 [('ORGANIZATION', 'MIT')] 

>> Stemming using Porter Stemmer: 
 [('MIT', 'mit'), ('Press', 'press'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('MIT', 'mit'), ('Press', 'press'), ('.', '.')]

>> Lemmatization: 
 [('MIT', 'MIT'), ('Press', 'Press'), ('.', '.')]



========================================== PARAGRAPH 588 ===========================================

 [2] Rospocher, M., van Erp, M., Vossen, P., Fokkens, A., Aldabe,I., Rigau, G., Soroa, A.,  

------------------- Sentence 1 -------------------

 [2] Rospocher, M., van Erp, M., Vossen, P., Fokkens, A., Aldabe,I., Rigau, G., Soroa, A.,

>> Tokens are: 
 ['[', '2', ']', 'Rospocher', ',', 'M.', ',', 'van', 'Erp', ',', 'M.', ',', 'Vossen', ',', 'P.', ',', 'Fokkens', ',', 'A.', ',', 'Aldabe', ',', 'I.', ',', 'Rigau', ',', 'G.', ',', 'Soroa', ',', 'A.', ',']

>> Bigrams are: 
 [('[', '2'), ('2', ']'), (']', 'Rospocher'), ('Rospocher', ','), (',', 'M.'), ('M.', ','), (',', 'van'), ('van', 'Erp'), ('Erp', ','), (',', 'M.'), ('M.', ','), (',', 'Vossen'), ('Vossen', ','), (',', 'P.'), ('P.', ','), (',', 'Fokkens'), ('Fokkens', ','), (',', 'A.'), ('A.', ','), (',', 'Aldabe'), ('Aldabe', ','), (',', 'I.'), ('I.', ','), (',', 'Rigau'), ('Rigau', ','), (',', 'G.'), ('G.', ','), (',', 'Soroa'), ('Soroa', ','), (',', 'A.'), ('A.', ',')]

>> Trigrams are: 
 [('[', '2', ']'), ('2', ']', 'Rospocher'), (']', 'Rospocher', ','), ('Rospocher', ',', 'M.'), (',', 'M.', ','), ('M.', ',', 'van'), (',', 'van', 'Erp'), ('van', 'Erp', ','), ('Erp', ',', 'M.'), (',', 'M.', ','), ('M.', ',', 'Vossen'), (',', 'Vossen', ','), ('Vossen', ',', 'P.'), (',', 'P.', ','), ('P.', ',', 'Fokkens'), (',', 'Fokkens', ','), ('Fokkens', ',', 'A.'), (',', 'A.', ','), ('A.', ',', 'Aldabe'), (',', 'Aldabe', ','), ('Aldabe', ',', 'I.'), (',', 'I.', ','), ('I.', ',', 'Rigau'), (',', 'Rigau', ','), ('Rigau', ',', 'G.'), (',', 'G.', ','), ('G.', ',', 'Soroa'), (',', 'Soroa', ','), ('Soroa', ',', 'A.'), (',', 'A.', ',')]

>> POS Tags are: 
 [('[', 'RB'), ('2', 'CD'), (']', 'NN'), ('Rospocher', 'NNP'), (',', ','), ('M.', 'NNP'), (',', ','), ('van', 'NN'), ('Erp', 'NNP'), (',', ','), ('M.', 'NNP'), (',', ','), ('Vossen', 'NNP'), (',', ','), ('P.', 'NNP'), (',', ','), ('Fokkens', 'NNP'), (',', ','), ('A.', 'NNP'), (',', ','), ('Aldabe', 'NNP'), (',', ','), ('I.', 'NNP'), (',', ','), ('Rigau', 'NNP'), (',', ','), ('G.', 'NNP'), (',', ','), ('Soroa', 'NNP'), (',', ','), ('A.', 'NNP'), (',', ',')]

>> Noun Phrases are: 
 ['] Rospocher', 'M.', 'van Erp', 'M.', 'Vossen', 'P.', 'Fokkens', 'A.', 'Aldabe', 'I.', 'Rigau', 'G.', 'Soroa', 'A.']

>> Named Entities are: 
 [('PERSON', 'Rospocher'), ('PERSON', 'Erp'), ('GPE', 'Vossen'), ('GPE', 'Fokkens'), ('PERSON', 'Aldabe'), ('PERSON', 'Rigau'), ('PERSON', 'Soroa')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('2', '2'), (']', ']'), ('Rospocher', 'rospoch'), (',', ','), ('M.', 'm.'), (',', ','), ('van', 'van'), ('Erp', 'erp'), (',', ','), ('M.', 'm.'), (',', ','), ('Vossen', 'vossen'), (',', ','), ('P.', 'p.'), (',', ','), ('Fokkens', 'fokken'), (',', ','), ('A.', 'a.'), (',', ','), ('Aldabe', 'aldab'), (',', ','), ('I.', 'i.'), (',', ','), ('Rigau', 'rigau'), (',', ','), ('G.', 'g.'), (',', ','), ('Soroa', 'soroa'), (',', ','), ('A.', 'a.'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('2', '2'), (']', ']'), ('Rospocher', 'rospoch'), (',', ','), ('M.', 'm.'), (',', ','), ('van', 'van'), ('Erp', 'erp'), (',', ','), ('M.', 'm.'), (',', ','), ('Vossen', 'vossen'), (',', ','), ('P.', 'p.'), (',', ','), ('Fokkens', 'fokken'), (',', ','), ('A.', 'a.'), (',', ','), ('Aldabe', 'aldab'), (',', ','), ('I.', 'i.'), (',', ','), ('Rigau', 'rigau'), (',', ','), ('G.', 'g.'), (',', ','), ('Soroa', 'soroa'), (',', ','), ('A.', 'a.'), (',', ',')]

>> Lemmatization: 
 [('[', '['), ('2', '2'), (']', ']'), ('Rospocher', 'Rospocher'), (',', ','), ('M.', 'M.'), (',', ','), ('van', 'van'), ('Erp', 'Erp'), (',', ','), ('M.', 'M.'), (',', ','), ('Vossen', 'Vossen'), (',', ','), ('P.', 'P.'), (',', ','), ('Fokkens', 'Fokkens'), (',', ','), ('A.', 'A.'), (',', ','), ('Aldabe', 'Aldabe'), (',', ','), ('I.', 'I.'), (',', ','), ('Rigau', 'Rigau'), (',', ','), ('G.', 'G.'), (',', ','), ('Soroa', 'Soroa'), (',', ','), ('A.', 'A.'), (',', ',')]



========================================== PARAGRAPH 589 ===========================================

Ploeger, T., and Bogaard, T.(2016). Building event-centric knowledge graphs from news.  

------------------- Sentence 1 -------------------

Ploeger, T., and Bogaard, T.(2016).

>> Tokens are: 
 ['Ploeger', ',', 'T.', ',', 'Bogaard', ',', 'T.', '(', '2016', ')', '.']

>> Bigrams are: 
 [('Ploeger', ','), (',', 'T.'), ('T.', ','), (',', 'Bogaard'), ('Bogaard', ','), (',', 'T.'), ('T.', '('), ('(', '2016'), ('2016', ')'), (')', '.')]

>> Trigrams are: 
 [('Ploeger', ',', 'T.'), (',', 'T.', ','), ('T.', ',', 'Bogaard'), (',', 'Bogaard', ','), ('Bogaard', ',', 'T.'), (',', 'T.', '('), ('T.', '(', '2016'), ('(', '2016', ')'), ('2016', ')', '.')]

>> POS Tags are: 
 [('Ploeger', 'NNP'), (',', ','), ('T.', 'NNP'), (',', ','), ('Bogaard', 'NNP'), (',', ','), ('T.', 'NNP'), ('(', '('), ('2016', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['Ploeger', 'T.', 'Bogaard', 'T.']

>> Named Entities are: 
 [('GPE', 'Ploeger'), ('PERSON', 'Bogaard')] 

>> Stemming using Porter Stemmer: 
 [('Ploeger', 'ploeger'), (',', ','), ('T.', 't.'), (',', ','), ('Bogaard', 'bogaard'), (',', ','), ('T.', 't.'), ('(', '('), ('2016', '2016'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Ploeger', 'ploeger'), (',', ','), ('T.', 't.'), (',', ','), ('Bogaard', 'bogaard'), (',', ','), ('T.', 't.'), ('(', '('), ('2016', '2016'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Ploeger', 'Ploeger'), (',', ','), ('T.', 'T.'), (',', ','), ('Bogaard', 'Bogaard'), (',', ','), ('T.', 'T.'), ('(', '('), ('2016', '2016'), (')', ')'), ('.', '.')]


------------------- Sentence 2 -------------------

Building event-centric knowledge graphs from news.

>> Tokens are: 
 ['Building', 'event-centric', 'knowledge', 'graphs', 'news', '.']

>> Bigrams are: 
 [('Building', 'event-centric'), ('event-centric', 'knowledge'), ('knowledge', 'graphs'), ('graphs', 'news'), ('news', '.')]

>> Trigrams are: 
 [('Building', 'event-centric', 'knowledge'), ('event-centric', 'knowledge', 'graphs'), ('knowledge', 'graphs', 'news'), ('graphs', 'news', '.')]

>> POS Tags are: 
 [('Building', 'VBG'), ('event-centric', 'JJ'), ('knowledge', 'NN'), ('graphs', 'NN'), ('news', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['event-centric knowledge graphs news']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Building', 'build'), ('event-centric', 'event-centr'), ('knowledge', 'knowledg'), ('graphs', 'graph'), ('news', 'news'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Building', 'build'), ('event-centric', 'event-centr'), ('knowledge', 'knowledg'), ('graphs', 'graph'), ('news', 'news'), ('.', '.')]

>> Lemmatization: 
 [('Building', 'Building'), ('event-centric', 'event-centric'), ('knowledge', 'knowledge'), ('graphs', 'graph'), ('news', 'news'), ('.', '.')]



========================================== PARAGRAPH 590 ===========================================

Web Semantics: Science, Services and Agents on the World Wide Web, In Press.  

------------------- Sentence 1 -------------------

Web Semantics: Science, Services and Agents on the World Wide Web, In Press.

>> Tokens are: 
 ['Web', 'Semantics', ':', 'Science', ',', 'Services', 'Agents', 'World', 'Wide', 'Web', ',', 'In', 'Press', '.']

>> Bigrams are: 
 [('Web', 'Semantics'), ('Semantics', ':'), (':', 'Science'), ('Science', ','), (',', 'Services'), ('Services', 'Agents'), ('Agents', 'World'), ('World', 'Wide'), ('Wide', 'Web'), ('Web', ','), (',', 'In'), ('In', 'Press'), ('Press', '.')]

>> Trigrams are: 
 [('Web', 'Semantics', ':'), ('Semantics', ':', 'Science'), (':', 'Science', ','), ('Science', ',', 'Services'), (',', 'Services', 'Agents'), ('Services', 'Agents', 'World'), ('Agents', 'World', 'Wide'), ('World', 'Wide', 'Web'), ('Wide', 'Web', ','), ('Web', ',', 'In'), (',', 'In', 'Press'), ('In', 'Press', '.')]

>> POS Tags are: 
 [('Web', 'JJ'), ('Semantics', 'NNS'), (':', ':'), ('Science', 'NN'), (',', ','), ('Services', 'NNPS'), ('Agents', 'NNP'), ('World', 'NNP'), ('Wide', 'NNP'), ('Web', 'NNP'), (',', ','), ('In', 'IN'), ('Press', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Web Semantics', 'Science', 'Agents World Wide Web', 'Press']

>> Named Entities are: 
 [('ORGANIZATION', 'Services Agents'), ('GPE', 'Press')] 

>> Stemming using Porter Stemmer: 
 [('Web', 'web'), ('Semantics', 'semant'), (':', ':'), ('Science', 'scienc'), (',', ','), ('Services', 'servic'), ('Agents', 'agent'), ('World', 'world'), ('Wide', 'wide'), ('Web', 'web'), (',', ','), ('In', 'in'), ('Press', 'press'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Web', 'web'), ('Semantics', 'semant'), (':', ':'), ('Science', 'scienc'), (',', ','), ('Services', 'servic'), ('Agents', 'agent'), ('World', 'world'), ('Wide', 'wide'), ('Web', 'web'), (',', ','), ('In', 'in'), ('Press', 'press'), ('.', '.')]

>> Lemmatization: 
 [('Web', 'Web'), ('Semantics', 'Semantics'), (':', ':'), ('Science', 'Science'), (',', ','), ('Services', 'Services'), ('Agents', 'Agents'), ('World', 'World'), ('Wide', 'Wide'), ('Web', 'Web'), (',', ','), ('In', 'In'), ('Press', 'Press'), ('.', '.')]



========================================== PARAGRAPH 591 ===========================================

[3] Shemtov, H. (1997). Ambiguity management in natural language generation. Stanford  

------------------- Sentence 1 -------------------

[3] Shemtov, H. (1997).

>> Tokens are: 
 ['[', '3', ']', 'Shemtov', ',', 'H.', '(', '1997', ')', '.']

>> Bigrams are: 
 [('[', '3'), ('3', ']'), (']', 'Shemtov'), ('Shemtov', ','), (',', 'H.'), ('H.', '('), ('(', '1997'), ('1997', ')'), (')', '.')]

>> Trigrams are: 
 [('[', '3', ']'), ('3', ']', 'Shemtov'), (']', 'Shemtov', ','), ('Shemtov', ',', 'H.'), (',', 'H.', '('), ('H.', '(', '1997'), ('(', '1997', ')'), ('1997', ')', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('3', 'CD'), (']', 'JJ'), ('Shemtov', 'NNP'), (',', ','), ('H.', 'NNP'), ('(', '('), ('1997', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['] Shemtov', 'H.']

>> Named Entities are: 
 [('ORGANIZATION', 'Shemtov')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('3', '3'), (']', ']'), ('Shemtov', 'shemtov'), (',', ','), ('H.', 'h.'), ('(', '('), ('1997', '1997'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('3', '3'), (']', ']'), ('Shemtov', 'shemtov'), (',', ','), ('H.', 'h.'), ('(', '('), ('1997', '1997'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('3', '3'), (']', ']'), ('Shemtov', 'Shemtov'), (',', ','), ('H.', 'H.'), ('(', '('), ('1997', '1997'), (')', ')'), ('.', '.')]


------------------- Sentence 2 -------------------

Ambiguity management in natural language generation.

>> Tokens are: 
 ['Ambiguity', 'management', 'natural', 'language', 'generation', '.']

>> Bigrams are: 
 [('Ambiguity', 'management'), ('management', 'natural'), ('natural', 'language'), ('language', 'generation'), ('generation', '.')]

>> Trigrams are: 
 [('Ambiguity', 'management', 'natural'), ('management', 'natural', 'language'), ('natural', 'language', 'generation'), ('language', 'generation', '.')]

>> POS Tags are: 
 [('Ambiguity', 'NNP'), ('management', 'NN'), ('natural', 'JJ'), ('language', 'NN'), ('generation', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Ambiguity management', 'natural language generation']

>> Named Entities are: 
 [('GPE', 'Ambiguity')] 

>> Stemming using Porter Stemmer: 
 [('Ambiguity', 'ambigu'), ('management', 'manag'), ('natural', 'natur'), ('language', 'languag'), ('generation', 'gener'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Ambiguity', 'ambigu'), ('management', 'manag'), ('natural', 'natur'), ('language', 'languag'), ('generation', 'generat'), ('.', '.')]

>> Lemmatization: 
 [('Ambiguity', 'Ambiguity'), ('management', 'management'), ('natural', 'natural'), ('language', 'language'), ('generation', 'generation'), ('.', '.')]


------------------- Sentence 3 -------------------

Stanford

>> Tokens are: 
 ['Stanford']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Stanford', 'NN')]

>> Noun Phrases are: 
 ['Stanford']

>> Named Entities are: 
 [('GSP', 'Stanford')] 

>> Stemming using Porter Stemmer: 
 [('Stanford', 'stanford')]

>> Stemming using Snowball Stemmer: 
 [('Stanford', 'stanford')]

>> Lemmatization: 
 [('Stanford', 'Stanford')]



========================================== PARAGRAPH 592 ===========================================

University.   

------------------- Sentence 1 -------------------

University.

>> Tokens are: 
 ['University', '.']

>> Bigrams are: 
 [('University', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('University', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['University']

>> Named Entities are: 
 [('GPE', 'University')] 

>> Stemming using Porter Stemmer: 
 [('University', 'univers'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('University', 'univers'), ('.', '.')]

>> Lemmatization: 
 [('University', 'University'), ('.', '.')]



========================================== PARAGRAPH 593 ===========================================

[4] Emele, M. C., & Dorna, M. (1998, August). Ambiguity preserving machine translation  

------------------- Sentence 1 -------------------

[4] Emele, M. C., & Dorna, M. (1998, August).

>> Tokens are: 
 ['[', '4', ']', 'Emele', ',', 'M.', 'C.', ',', '&', 'Dorna', ',', 'M.', '(', '1998', ',', 'August', ')', '.']

>> Bigrams are: 
 [('[', '4'), ('4', ']'), (']', 'Emele'), ('Emele', ','), (',', 'M.'), ('M.', 'C.'), ('C.', ','), (',', '&'), ('&', 'Dorna'), ('Dorna', ','), (',', 'M.'), ('M.', '('), ('(', '1998'), ('1998', ','), (',', 'August'), ('August', ')'), (')', '.')]

>> Trigrams are: 
 [('[', '4', ']'), ('4', ']', 'Emele'), (']', 'Emele', ','), ('Emele', ',', 'M.'), (',', 'M.', 'C.'), ('M.', 'C.', ','), ('C.', ',', '&'), (',', '&', 'Dorna'), ('&', 'Dorna', ','), ('Dorna', ',', 'M.'), (',', 'M.', '('), ('M.', '(', '1998'), ('(', '1998', ','), ('1998', ',', 'August'), (',', 'August', ')'), ('August', ')', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('4', 'CD'), (']', 'JJ'), ('Emele', 'NNP'), (',', ','), ('M.', 'NNP'), ('C.', 'NNP'), (',', ','), ('&', 'CC'), ('Dorna', 'NNP'), (',', ','), ('M.', 'NNP'), ('(', '('), ('1998', 'CD'), (',', ','), ('August', 'NNP'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['] Emele', 'M. C.', 'Dorna', 'M.', 'August']

>> Named Entities are: 
 [('PERSON', 'Emele'), ('PERSON', 'Dorna'), ('GPE', 'August')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('4', '4'), (']', ']'), ('Emele', 'emel'), (',', ','), ('M.', 'm.'), ('C.', 'c.'), (',', ','), ('&', '&'), ('Dorna', 'dorna'), (',', ','), ('M.', 'm.'), ('(', '('), ('1998', '1998'), (',', ','), ('August', 'august'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('4', '4'), (']', ']'), ('Emele', 'emel'), (',', ','), ('M.', 'm.'), ('C.', 'c.'), (',', ','), ('&', '&'), ('Dorna', 'dorna'), (',', ','), ('M.', 'm.'), ('(', '('), ('1998', '1998'), (',', ','), ('August', 'august'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('4', '4'), (']', ']'), ('Emele', 'Emele'), (',', ','), ('M.', 'M.'), ('C.', 'C.'), (',', ','), ('&', '&'), ('Dorna', 'Dorna'), (',', ','), ('M.', 'M.'), ('(', '('), ('1998', '1998'), (',', ','), ('August', 'August'), (')', ')'), ('.', '.')]


------------------- Sentence 2 -------------------

Ambiguity preserving machine translation

>> Tokens are: 
 ['Ambiguity', 'preserving', 'machine', 'translation']

>> Bigrams are: 
 [('Ambiguity', 'preserving'), ('preserving', 'machine'), ('machine', 'translation')]

>> Trigrams are: 
 [('Ambiguity', 'preserving', 'machine'), ('preserving', 'machine', 'translation')]

>> POS Tags are: 
 [('Ambiguity', 'NNP'), ('preserving', 'VBG'), ('machine', 'NN'), ('translation', 'NN')]

>> Noun Phrases are: 
 ['Ambiguity', 'machine translation']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Ambiguity', 'ambigu'), ('preserving', 'preserv'), ('machine', 'machin'), ('translation', 'translat')]

>> Stemming using Snowball Stemmer: 
 [('Ambiguity', 'ambigu'), ('preserving', 'preserv'), ('machine', 'machin'), ('translation', 'translat')]

>> Lemmatization: 
 [('Ambiguity', 'Ambiguity'), ('preserving', 'preserving'), ('machine', 'machine'), ('translation', 'translation')]



========================================== PARAGRAPH 594 ===========================================

using packed representations. In Proceedings of the 36th Annual Meeting of the Association 

------------------- Sentence 1 -------------------

using packed representations.

>> Tokens are: 
 ['using', 'packed', 'representations', '.']

>> Bigrams are: 
 [('using', 'packed'), ('packed', 'representations'), ('representations', '.')]

>> Trigrams are: 
 [('using', 'packed', 'representations'), ('packed', 'representations', '.')]

>> POS Tags are: 
 [('using', 'VBG'), ('packed', 'JJ'), ('representations', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['packed representations']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('using', 'use'), ('packed', 'pack'), ('representations', 'represent'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('using', 'use'), ('packed', 'pack'), ('representations', 'represent'), ('.', '.')]

>> Lemmatization: 
 [('using', 'using'), ('packed', 'packed'), ('representations', 'representation'), ('.', '.')]


------------------- Sentence 2 -------------------

In Proceedings of the 36th Annual Meeting of the Association

>> Tokens are: 
 ['In', 'Proceedings', '36th', 'Annual', 'Meeting', 'Association']

>> Bigrams are: 
 [('In', 'Proceedings'), ('Proceedings', '36th'), ('36th', 'Annual'), ('Annual', 'Meeting'), ('Meeting', 'Association')]

>> Trigrams are: 
 [('In', 'Proceedings', '36th'), ('Proceedings', '36th', 'Annual'), ('36th', 'Annual', 'Meeting'), ('Annual', 'Meeting', 'Association')]

>> POS Tags are: 
 [('In', 'IN'), ('Proceedings', 'NNP'), ('36th', 'CD'), ('Annual', 'NNP'), ('Meeting', 'NNP'), ('Association', 'NNP')]

>> Noun Phrases are: 
 ['Proceedings', 'Annual Meeting Association']

>> Named Entities are: 
 [('PERSON', 'Annual Meeting')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('Proceedings', 'proceed'), ('36th', '36th'), ('Annual', 'annual'), ('Meeting', 'meet'), ('Association', 'associ')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('Proceedings', 'proceed'), ('36th', '36th'), ('Annual', 'annual'), ('Meeting', 'meet'), ('Association', 'associ')]

>> Lemmatization: 
 [('In', 'In'), ('Proceedings', 'Proceedings'), ('36th', '36th'), ('Annual', 'Annual'), ('Meeting', 'Meeting'), ('Association', 'Association')]



========================================== PARAGRAPH 595 ===========================================

for Computational Linguistics and 17th International Conference on Computational  

------------------- Sentence 1 -------------------

for Computational Linguistics and 17th International Conference on Computational

>> Tokens are: 
 ['Computational', 'Linguistics', '17th', 'International', 'Conference', 'Computational']

>> Bigrams are: 
 [('Computational', 'Linguistics'), ('Linguistics', '17th'), ('17th', 'International'), ('International', 'Conference'), ('Conference', 'Computational')]

>> Trigrams are: 
 [('Computational', 'Linguistics', '17th'), ('Linguistics', '17th', 'International'), ('17th', 'International', 'Conference'), ('International', 'Conference', 'Computational')]

>> POS Tags are: 
 [('Computational', 'JJ'), ('Linguistics', 'NNP'), ('17th', 'CD'), ('International', 'NNP'), ('Conference', 'NNP'), ('Computational', 'NNP')]

>> Noun Phrases are: 
 ['Computational Linguistics', 'International Conference Computational']

>> Named Entities are: 
 [('ORGANIZATION', 'International Conference')] 

>> Stemming using Porter Stemmer: 
 [('Computational', 'comput'), ('Linguistics', 'linguist'), ('17th', '17th'), ('International', 'intern'), ('Conference', 'confer'), ('Computational', 'comput')]

>> Stemming using Snowball Stemmer: 
 [('Computational', 'comput'), ('Linguistics', 'linguist'), ('17th', '17th'), ('International', 'intern'), ('Conference', 'confer'), ('Computational', 'comput')]

>> Lemmatization: 
 [('Computational', 'Computational'), ('Linguistics', 'Linguistics'), ('17th', '17th'), ('International', 'International'), ('Conference', 'Conference'), ('Computational', 'Computational')]



========================================== PARAGRAPH 596 ===========================================

Linguistics-Volume 1 (pp. 365-371). Association for Computational Linguistics.  

------------------- Sentence 1 -------------------

Linguistics-Volume 1 (pp.

>> Tokens are: 
 ['Linguistics-Volume', '1', '(', 'pp', '.']

>> Bigrams are: 
 [('Linguistics-Volume', '1'), ('1', '('), ('(', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('Linguistics-Volume', '1', '('), ('1', '(', 'pp'), ('(', 'pp', '.')]

>> POS Tags are: 
 [('Linguistics-Volume', 'JJ'), ('1', 'CD'), ('(', '('), ('pp', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['pp']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Linguistics-Volume', 'linguistics-volum'), ('1', '1'), ('(', '('), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Linguistics-Volume', 'linguistics-volum'), ('1', '1'), ('(', '('), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('Linguistics-Volume', 'Linguistics-Volume'), ('1', '1'), ('(', '('), ('pp', 'pp'), ('.', '.')]


------------------- Sentence 2 -------------------

365-371).

>> Tokens are: 
 ['365-371', ')', '.']

>> Bigrams are: 
 [('365-371', ')'), (')', '.')]

>> Trigrams are: 
 [('365-371', ')', '.')]

>> POS Tags are: 
 [('365-371', 'JJ'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('365-371', '365-371'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('365-371', '365-371'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('365-371', '365-371'), (')', ')'), ('.', '.')]


------------------- Sentence 3 -------------------

Association for Computational Linguistics.

>> Tokens are: 
 ['Association', 'Computational', 'Linguistics', '.']

>> Bigrams are: 
 [('Association', 'Computational'), ('Computational', 'Linguistics'), ('Linguistics', '.')]

>> Trigrams are: 
 [('Association', 'Computational', 'Linguistics'), ('Computational', 'Linguistics', '.')]

>> POS Tags are: 
 [('Association', 'NNP'), ('Computational', 'NNP'), ('Linguistics', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Association Computational Linguistics']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Association', 'associ'), ('Computational', 'comput'), ('Linguistics', 'linguist'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Association', 'associ'), ('Computational', 'comput'), ('Linguistics', 'linguist'), ('.', '.')]

>> Lemmatization: 
 [('Association', 'Association'), ('Computational', 'Computational'), ('Linguistics', 'Linguistics'), ('.', '.')]



========================================== PARAGRAPH 597 ===========================================

[5] Knight, K., & Langkilde, I. (2000, July). Preserving ambiguities in generation via  

------------------- Sentence 1 -------------------

[5] Knight, K., & Langkilde, I.

>> Tokens are: 
 ['[', '5', ']', 'Knight', ',', 'K.', ',', '&', 'Langkilde', ',', 'I', '.']

>> Bigrams are: 
 [('[', '5'), ('5', ']'), (']', 'Knight'), ('Knight', ','), (',', 'K.'), ('K.', ','), (',', '&'), ('&', 'Langkilde'), ('Langkilde', ','), (',', 'I'), ('I', '.')]

>> Trigrams are: 
 [('[', '5', ']'), ('5', ']', 'Knight'), (']', 'Knight', ','), ('Knight', ',', 'K.'), (',', 'K.', ','), ('K.', ',', '&'), (',', '&', 'Langkilde'), ('&', 'Langkilde', ','), ('Langkilde', ',', 'I'), (',', 'I', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('5', 'CD'), (']', 'JJ'), ('Knight', 'NNP'), (',', ','), ('K.', 'NNP'), (',', ','), ('&', 'CC'), ('Langkilde', 'NNP'), (',', ','), ('I', 'PRP'), ('.', '.')]

>> Noun Phrases are: 
 ['] Knight', 'K.', 'Langkilde']

>> Named Entities are: 
 [('PERSON', 'Langkilde')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('5', '5'), (']', ']'), ('Knight', 'knight'), (',', ','), ('K.', 'k.'), (',', ','), ('&', '&'), ('Langkilde', 'langkild'), (',', ','), ('I', 'i'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('5', '5'), (']', ']'), ('Knight', 'knight'), (',', ','), ('K.', 'k.'), (',', ','), ('&', '&'), ('Langkilde', 'langkild'), (',', ','), ('I', 'i'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('5', '5'), (']', ']'), ('Knight', 'Knight'), (',', ','), ('K.', 'K.'), (',', ','), ('&', '&'), ('Langkilde', 'Langkilde'), (',', ','), ('I', 'I'), ('.', '.')]


------------------- Sentence 2 -------------------

(2000, July).

>> Tokens are: 
 ['(', '2000', ',', 'July', ')', '.']

>> Bigrams are: 
 [('(', '2000'), ('2000', ','), (',', 'July'), ('July', ')'), (')', '.')]

>> Trigrams are: 
 [('(', '2000', ','), ('2000', ',', 'July'), (',', 'July', ')'), ('July', ')', '.')]

>> POS Tags are: 
 [('(', '('), ('2000', 'CD'), (',', ','), ('July', 'NNP'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['July']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('2000', '2000'), (',', ','), ('July', 'juli'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('2000', '2000'), (',', ','), ('July', 'juli'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('(', '('), ('2000', '2000'), (',', ','), ('July', 'July'), (')', ')'), ('.', '.')]


------------------- Sentence 3 -------------------

Preserving ambiguities in generation via

>> Tokens are: 
 ['Preserving', 'ambiguities', 'generation', 'via']

>> Bigrams are: 
 [('Preserving', 'ambiguities'), ('ambiguities', 'generation'), ('generation', 'via')]

>> Trigrams are: 
 [('Preserving', 'ambiguities', 'generation'), ('ambiguities', 'generation', 'via')]

>> POS Tags are: 
 [('Preserving', 'VBG'), ('ambiguities', 'NNS'), ('generation', 'NN'), ('via', 'IN')]

>> Noun Phrases are: 
 ['ambiguities generation']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Preserving', 'preserv'), ('ambiguities', 'ambigu'), ('generation', 'gener'), ('via', 'via')]

>> Stemming using Snowball Stemmer: 
 [('Preserving', 'preserv'), ('ambiguities', 'ambigu'), ('generation', 'generat'), ('via', 'via')]

>> Lemmatization: 
 [('Preserving', 'Preserving'), ('ambiguities', 'ambiguity'), ('generation', 'generation'), ('via', 'via')]



========================================== PARAGRAPH 598 ===========================================

automata intersection. In AAAI/IAAI (pp. 697-702).  

------------------- Sentence 1 -------------------

automata intersection.

>> Tokens are: 
 ['automata', 'intersection', '.']

>> Bigrams are: 
 [('automata', 'intersection'), ('intersection', '.')]

>> Trigrams are: 
 [('automata', 'intersection', '.')]

>> POS Tags are: 
 [('automata', 'DT'), ('intersection', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['automata intersection']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('automata', 'automata'), ('intersection', 'intersect'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('automata', 'automata'), ('intersection', 'intersect'), ('.', '.')]

>> Lemmatization: 
 [('automata', 'automaton'), ('intersection', 'intersection'), ('.', '.')]


------------------- Sentence 2 -------------------

In AAAI/IAAI (pp.

>> Tokens are: 
 ['In', 'AAAI/IAAI', '(', 'pp', '.']

>> Bigrams are: 
 [('In', 'AAAI/IAAI'), ('AAAI/IAAI', '('), ('(', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('In', 'AAAI/IAAI', '('), ('AAAI/IAAI', '(', 'pp'), ('(', 'pp', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('AAAI/IAAI', 'NNP'), ('(', '('), ('pp', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['AAAI/IAAI', 'pp']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('AAAI/IAAI', 'aaai/iaai'), ('(', '('), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('AAAI/IAAI', 'aaai/iaai'), ('(', '('), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('AAAI/IAAI', 'AAAI/IAAI'), ('(', '('), ('pp', 'pp'), ('.', '.')]


------------------- Sentence 3 -------------------

697-702).

>> Tokens are: 
 ['697-702', ')', '.']

>> Bigrams are: 
 [('697-702', ')'), (')', '.')]

>> Trigrams are: 
 [('697-702', ')', '.')]

>> POS Tags are: 
 [('697-702', 'JJ'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('697-702', '697-702'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('697-702', '697-702'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('697-702', '697-702'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 599 ===========================================

[6] Nation, K., Snowling, M. J., & Clarke, P. (2007). Dissecting the relationship between  

------------------- Sentence 1 -------------------

[6] Nation, K., Snowling, M. J., & Clarke, P. (2007).

>> Tokens are: 
 ['[', '6', ']', 'Nation', ',', 'K.', ',', 'Snowling', ',', 'M.', 'J.', ',', '&', 'Clarke', ',', 'P.', '(', '2007', ')', '.']

>> Bigrams are: 
 [('[', '6'), ('6', ']'), (']', 'Nation'), ('Nation', ','), (',', 'K.'), ('K.', ','), (',', 'Snowling'), ('Snowling', ','), (',', 'M.'), ('M.', 'J.'), ('J.', ','), (',', '&'), ('&', 'Clarke'), ('Clarke', ','), (',', 'P.'), ('P.', '('), ('(', '2007'), ('2007', ')'), (')', '.')]

>> Trigrams are: 
 [('[', '6', ']'), ('6', ']', 'Nation'), (']', 'Nation', ','), ('Nation', ',', 'K.'), (',', 'K.', ','), ('K.', ',', 'Snowling'), (',', 'Snowling', ','), ('Snowling', ',', 'M.'), (',', 'M.', 'J.'), ('M.', 'J.', ','), ('J.', ',', '&'), (',', '&', 'Clarke'), ('&', 'Clarke', ','), ('Clarke', ',', 'P.'), (',', 'P.', '('), ('P.', '(', '2007'), ('(', '2007', ')'), ('2007', ')', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('6', 'CD'), (']', 'JJ'), ('Nation', 'NN'), (',', ','), ('K.', 'NNP'), (',', ','), ('Snowling', 'NNP'), (',', ','), ('M.', 'NNP'), ('J.', 'NNP'), (',', ','), ('&', 'CC'), ('Clarke', 'NNP'), (',', ','), ('P.', 'NNP'), ('(', '('), ('2007', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['] Nation', 'K.', 'Snowling', 'M. J.', 'Clarke', 'P.']

>> Named Entities are: 
 [('GPE', 'Snowling'), ('PERSON', 'Clarke')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('6', '6'), (']', ']'), ('Nation', 'nation'), (',', ','), ('K.', 'k.'), (',', ','), ('Snowling', 'snowl'), (',', ','), ('M.', 'm.'), ('J.', 'j.'), (',', ','), ('&', '&'), ('Clarke', 'clark'), (',', ','), ('P.', 'p.'), ('(', '('), ('2007', '2007'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('6', '6'), (']', ']'), ('Nation', 'nation'), (',', ','), ('K.', 'k.'), (',', ','), ('Snowling', 'snowl'), (',', ','), ('M.', 'm.'), ('J.', 'j.'), (',', ','), ('&', '&'), ('Clarke', 'clark'), (',', ','), ('P.', 'p.'), ('(', '('), ('2007', '2007'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('6', '6'), (']', ']'), ('Nation', 'Nation'), (',', ','), ('K.', 'K.'), (',', ','), ('Snowling', 'Snowling'), (',', ','), ('M.', 'M.'), ('J.', 'J.'), (',', ','), ('&', '&'), ('Clarke', 'Clarke'), (',', ','), ('P.', 'P.'), ('(', '('), ('2007', '2007'), (')', ')'), ('.', '.')]


------------------- Sentence 2 -------------------

Dissecting the relationship between

>> Tokens are: 
 ['Dissecting', 'relationship']

>> Bigrams are: 
 [('Dissecting', 'relationship')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Dissecting', 'VBG'), ('relationship', 'NN')]

>> Noun Phrases are: 
 ['relationship']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Dissecting', 'dissect'), ('relationship', 'relationship')]

>> Stemming using Snowball Stemmer: 
 [('Dissecting', 'dissect'), ('relationship', 'relationship')]

>> Lemmatization: 
 [('Dissecting', 'Dissecting'), ('relationship', 'relationship')]



========================================== PARAGRAPH 600 ===========================================

language skills and learning to read: Semantic and phonological contributions to new  

------------------- Sentence 1 -------------------

language skills and learning to read: Semantic and phonological contributions to new

>> Tokens are: 
 ['language', 'skills', 'learning', 'read', ':', 'Semantic', 'phonological', 'contributions', 'new']

>> Bigrams are: 
 [('language', 'skills'), ('skills', 'learning'), ('learning', 'read'), ('read', ':'), (':', 'Semantic'), ('Semantic', 'phonological'), ('phonological', 'contributions'), ('contributions', 'new')]

>> Trigrams are: 
 [('language', 'skills', 'learning'), ('skills', 'learning', 'read'), ('learning', 'read', ':'), ('read', ':', 'Semantic'), (':', 'Semantic', 'phonological'), ('Semantic', 'phonological', 'contributions'), ('phonological', 'contributions', 'new')]

>> POS Tags are: 
 [('language', 'NN'), ('skills', 'NNS'), ('learning', 'VBG'), ('read', 'NN'), (':', ':'), ('Semantic', 'JJ'), ('phonological', 'JJ'), ('contributions', 'NNS'), ('new', 'JJ')]

>> Noun Phrases are: 
 ['language skills', 'read', 'Semantic phonological contributions']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('language', 'languag'), ('skills', 'skill'), ('learning', 'learn'), ('read', 'read'), (':', ':'), ('Semantic', 'semant'), ('phonological', 'phonolog'), ('contributions', 'contribut'), ('new', 'new')]

>> Stemming using Snowball Stemmer: 
 [('language', 'languag'), ('skills', 'skill'), ('learning', 'learn'), ('read', 'read'), (':', ':'), ('Semantic', 'semant'), ('phonological', 'phonolog'), ('contributions', 'contribut'), ('new', 'new')]

>> Lemmatization: 
 [('language', 'language'), ('skills', 'skill'), ('learning', 'learning'), ('read', 'read'), (':', ':'), ('Semantic', 'Semantic'), ('phonological', 'phonological'), ('contributions', 'contribution'), ('new', 'new')]



========================================== PARAGRAPH 601 ===========================================

vocabulary learning in children with poor reading comprehension. Advances in Speech  

------------------- Sentence 1 -------------------

vocabulary learning in children with poor reading comprehension.

>> Tokens are: 
 ['vocabulary', 'learning', 'children', 'poor', 'reading', 'comprehension', '.']

>> Bigrams are: 
 [('vocabulary', 'learning'), ('learning', 'children'), ('children', 'poor'), ('poor', 'reading'), ('reading', 'comprehension'), ('comprehension', '.')]

>> Trigrams are: 
 [('vocabulary', 'learning', 'children'), ('learning', 'children', 'poor'), ('children', 'poor', 'reading'), ('poor', 'reading', 'comprehension'), ('reading', 'comprehension', '.')]

>> POS Tags are: 
 [('vocabulary', 'JJ'), ('learning', 'VBG'), ('children', 'NNS'), ('poor', 'JJ'), ('reading', 'VBG'), ('comprehension', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['children', 'comprehension']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('vocabulary', 'vocabulari'), ('learning', 'learn'), ('children', 'children'), ('poor', 'poor'), ('reading', 'read'), ('comprehension', 'comprehens'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('vocabulary', 'vocabulari'), ('learning', 'learn'), ('children', 'children'), ('poor', 'poor'), ('reading', 'read'), ('comprehension', 'comprehens'), ('.', '.')]

>> Lemmatization: 
 [('vocabulary', 'vocabulary'), ('learning', 'learning'), ('children', 'child'), ('poor', 'poor'), ('reading', 'reading'), ('comprehension', 'comprehension'), ('.', '.')]


------------------- Sentence 2 -------------------

Advances in Speech

>> Tokens are: 
 ['Advances', 'Speech']

>> Bigrams are: 
 [('Advances', 'Speech')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Advances', 'NNS'), ('Speech', 'NNP')]

>> Noun Phrases are: 
 ['Advances Speech']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Advances', 'advanc'), ('Speech', 'speech')]

>> Stemming using Snowball Stemmer: 
 [('Advances', 'advanc'), ('Speech', 'speech')]

>> Lemmatization: 
 [('Advances', 'Advances'), ('Speech', 'Speech')]



========================================== PARAGRAPH 602 ===========================================

Language Pathology, 9(2), 131-139.  

------------------- Sentence 1 -------------------

Language Pathology, 9(2), 131-139.

>> Tokens are: 
 ['Language', 'Pathology', ',', '9', '(', '2', ')', ',', '131-139', '.']

>> Bigrams are: 
 [('Language', 'Pathology'), ('Pathology', ','), (',', '9'), ('9', '('), ('(', '2'), ('2', ')'), (')', ','), (',', '131-139'), ('131-139', '.')]

>> Trigrams are: 
 [('Language', 'Pathology', ','), ('Pathology', ',', '9'), (',', '9', '('), ('9', '(', '2'), ('(', '2', ')'), ('2', ')', ','), (')', ',', '131-139'), (',', '131-139', '.')]

>> POS Tags are: 
 [('Language', 'NNP'), ('Pathology', 'NNP'), (',', ','), ('9', 'CD'), ('(', '('), ('2', 'CD'), (')', ')'), (',', ','), ('131-139', 'JJ'), ('.', '.')]

>> Noun Phrases are: 
 ['Language Pathology']

>> Named Entities are: 
 [('PERSON', 'Language Pathology')] 

>> Stemming using Porter Stemmer: 
 [('Language', 'languag'), ('Pathology', 'patholog'), (',', ','), ('9', '9'), ('(', '('), ('2', '2'), (')', ')'), (',', ','), ('131-139', '131-139'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Language', 'languag'), ('Pathology', 'patholog'), (',', ','), ('9', '9'), ('(', '('), ('2', '2'), (')', ')'), (',', ','), ('131-139', '131-139'), ('.', '.')]

>> Lemmatization: 
 [('Language', 'Language'), ('Pathology', 'Pathology'), (',', ','), ('9', '9'), ('(', '('), ('2', '2'), (')', ')'), (',', ','), ('131-139', '131-139'), ('.', '.')]



========================================== PARAGRAPH 603 ===========================================

[7] Liddy, E. D. (2001). Natural language processing.  

------------------- Sentence 1 -------------------

[7] Liddy, E. D. (2001).

>> Tokens are: 
 ['[', '7', ']', 'Liddy', ',', 'E.', 'D.', '(', '2001', ')', '.']

>> Bigrams are: 
 [('[', '7'), ('7', ']'), (']', 'Liddy'), ('Liddy', ','), (',', 'E.'), ('E.', 'D.'), ('D.', '('), ('(', '2001'), ('2001', ')'), (')', '.')]

>> Trigrams are: 
 [('[', '7', ']'), ('7', ']', 'Liddy'), (']', 'Liddy', ','), ('Liddy', ',', 'E.'), (',', 'E.', 'D.'), ('E.', 'D.', '('), ('D.', '(', '2001'), ('(', '2001', ')'), ('2001', ')', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('7', 'CD'), (']', 'NN'), ('Liddy', 'NNP'), (',', ','), ('E.', 'NNP'), ('D.', 'NNP'), ('(', '('), ('2001', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['] Liddy', 'E. D.']

>> Named Entities are: 
 [('PERSON', 'Liddy')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('7', '7'), (']', ']'), ('Liddy', 'liddi'), (',', ','), ('E.', 'e.'), ('D.', 'd.'), ('(', '('), ('2001', '2001'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('7', '7'), (']', ']'), ('Liddy', 'liddi'), (',', ','), ('E.', 'e.'), ('D.', 'd.'), ('(', '('), ('2001', '2001'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('7', '7'), (']', ']'), ('Liddy', 'Liddy'), (',', ','), ('E.', 'E.'), ('D.', 'D.'), ('(', '('), ('2001', '2001'), (')', ')'), ('.', '.')]


------------------- Sentence 2 -------------------

Natural language processing.

>> Tokens are: 
 ['Natural', 'language', 'processing', '.']

>> Bigrams are: 
 [('Natural', 'language'), ('language', 'processing'), ('processing', '.')]

>> Trigrams are: 
 [('Natural', 'language', 'processing'), ('language', 'processing', '.')]

>> POS Tags are: 
 [('Natural', 'JJ'), ('language', 'NN'), ('processing', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Natural language processing']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Natural', 'natur'), ('language', 'languag'), ('processing', 'process'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Natural', 'natur'), ('language', 'languag'), ('processing', 'process'), ('.', '.')]

>> Lemmatization: 
 [('Natural', 'Natural'), ('language', 'language'), ('processing', 'processing'), ('.', '.')]



========================================== PARAGRAPH 604 ===========================================

[8] Feldman, S. (1999). NLP Meets the Jabberwocky: Natural Language Processing in  

------------------- Sentence 1 -------------------

[8] Feldman, S. (1999).

>> Tokens are: 
 ['[', '8', ']', 'Feldman', ',', 'S.', '(', '1999', ')', '.']

>> Bigrams are: 
 [('[', '8'), ('8', ']'), (']', 'Feldman'), ('Feldman', ','), (',', 'S.'), ('S.', '('), ('(', '1999'), ('1999', ')'), (')', '.')]

>> Trigrams are: 
 [('[', '8', ']'), ('8', ']', 'Feldman'), (']', 'Feldman', ','), ('Feldman', ',', 'S.'), (',', 'S.', '('), ('S.', '(', '1999'), ('(', '1999', ')'), ('1999', ')', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('8', 'CD'), (']', 'JJ'), ('Feldman', 'NNP'), (',', ','), ('S.', 'NNP'), ('(', '('), ('1999', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['] Feldman', 'S.']

>> Named Entities are: 
 [('PERSON', 'Feldman')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('8', '8'), (']', ']'), ('Feldman', 'feldman'), (',', ','), ('S.', 's.'), ('(', '('), ('1999', '1999'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('8', '8'), (']', ']'), ('Feldman', 'feldman'), (',', ','), ('S.', 's.'), ('(', '('), ('1999', '1999'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('8', '8'), (']', ']'), ('Feldman', 'Feldman'), (',', ','), ('S.', 'S.'), ('(', '('), ('1999', '1999'), (')', ')'), ('.', '.')]


------------------- Sentence 2 -------------------

NLP Meets the Jabberwocky: Natural Language Processing in

>> Tokens are: 
 ['NLP', 'Meets', 'Jabberwocky', ':', 'Natural', 'Language', 'Processing']

>> Bigrams are: 
 [('NLP', 'Meets'), ('Meets', 'Jabberwocky'), ('Jabberwocky', ':'), (':', 'Natural'), ('Natural', 'Language'), ('Language', 'Processing')]

>> Trigrams are: 
 [('NLP', 'Meets', 'Jabberwocky'), ('Meets', 'Jabberwocky', ':'), ('Jabberwocky', ':', 'Natural'), (':', 'Natural', 'Language'), ('Natural', 'Language', 'Processing')]

>> POS Tags are: 
 [('NLP', 'NNP'), ('Meets', 'NNP'), ('Jabberwocky', 'NNP'), (':', ':'), ('Natural', 'JJ'), ('Language', 'NNP'), ('Processing', 'NN')]

>> Noun Phrases are: 
 ['NLP Meets Jabberwocky', 'Natural Language Processing']

>> Named Entities are: 
 [('ORGANIZATION', 'NLP'), ('PERSON', 'Meets Jabberwocky')] 

>> Stemming using Porter Stemmer: 
 [('NLP', 'nlp'), ('Meets', 'meet'), ('Jabberwocky', 'jabberwocki'), (':', ':'), ('Natural', 'natur'), ('Language', 'languag'), ('Processing', 'process')]

>> Stemming using Snowball Stemmer: 
 [('NLP', 'nlp'), ('Meets', 'meet'), ('Jabberwocky', 'jabberwocki'), (':', ':'), ('Natural', 'natur'), ('Language', 'languag'), ('Processing', 'process')]

>> Lemmatization: 
 [('NLP', 'NLP'), ('Meets', 'Meets'), ('Jabberwocky', 'Jabberwocky'), (':', ':'), ('Natural', 'Natural'), ('Language', 'Language'), ('Processing', 'Processing')]



========================================== PARAGRAPH 605 ===========================================

Information Retrieval. ONLINE-WESTON THEN WILTON-, 23, 62-73.  

------------------- Sentence 1 -------------------

Information Retrieval.

>> Tokens are: 
 ['Information', 'Retrieval', '.']

>> Bigrams are: 
 [('Information', 'Retrieval'), ('Retrieval', '.')]

>> Trigrams are: 
 [('Information', 'Retrieval', '.')]

>> POS Tags are: 
 [('Information', 'NN'), ('Retrieval', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Information Retrieval']

>> Named Entities are: 
 [('PERSON', 'Retrieval')] 

>> Stemming using Porter Stemmer: 
 [('Information', 'inform'), ('Retrieval', 'retriev'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Information', 'inform'), ('Retrieval', 'retriev'), ('.', '.')]

>> Lemmatization: 
 [('Information', 'Information'), ('Retrieval', 'Retrieval'), ('.', '.')]


------------------- Sentence 2 -------------------

ONLINE-WESTON THEN WILTON-, 23, 62-73.

>> Tokens are: 
 ['ONLINE-WESTON', 'THEN', 'WILTON-', ',', '23', ',', '62-73', '.']

>> Bigrams are: 
 [('ONLINE-WESTON', 'THEN'), ('THEN', 'WILTON-'), ('WILTON-', ','), (',', '23'), ('23', ','), (',', '62-73'), ('62-73', '.')]

>> Trigrams are: 
 [('ONLINE-WESTON', 'THEN', 'WILTON-'), ('THEN', 'WILTON-', ','), ('WILTON-', ',', '23'), (',', '23', ','), ('23', ',', '62-73'), (',', '62-73', '.')]

>> POS Tags are: 
 [('ONLINE-WESTON', 'JJ'), ('THEN', 'NNP'), ('WILTON-', 'NNP'), (',', ','), ('23', 'CD'), (',', ','), ('62-73', 'JJ'), ('.', '.')]

>> Noun Phrases are: 
 ['ONLINE-WESTON THEN WILTON-']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('ONLINE-WESTON', 'online-weston'), ('THEN', 'then'), ('WILTON-', 'wilton-'), (',', ','), ('23', '23'), (',', ','), ('62-73', '62-73'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('ONLINE-WESTON', 'online-weston'), ('THEN', 'then'), ('WILTON-', 'wilton-'), (',', ','), ('23', '23'), (',', ','), ('62-73', '62-73'), ('.', '.')]

>> Lemmatization: 
 [('ONLINE-WESTON', 'ONLINE-WESTON'), ('THEN', 'THEN'), ('WILTON-', 'WILTON-'), (',', ','), ('23', '23'), (',', ','), ('62-73', '62-73'), ('.', '.')]



========================================== PARAGRAPH 606 ===========================================

[9] "Natural Language Processing." Natural Language Processing RSS. N.p., n.d. Web. 25  

------------------- Sentence 1 -------------------

[9] "Natural Language Processing."

>> Tokens are: 
 ['[', '9', ']', '``', 'Natural', 'Language', 'Processing', '.', "''"]

>> Bigrams are: 
 [('[', '9'), ('9', ']'), (']', '``'), ('``', 'Natural'), ('Natural', 'Language'), ('Language', 'Processing'), ('Processing', '.'), ('.', "''")]

>> Trigrams are: 
 [('[', '9', ']'), ('9', ']', '``'), (']', '``', 'Natural'), ('``', 'Natural', 'Language'), ('Natural', 'Language', 'Processing'), ('Language', 'Processing', '.'), ('Processing', '.', "''")]

>> POS Tags are: 
 [('[', 'RB'), ('9', 'CD'), (']', 'NN'), ('``', '``'), ('Natural', 'JJ'), ('Language', 'NN'), ('Processing', 'NN'), ('.', '.'), ("''", "''")]

>> Noun Phrases are: 
 [']', 'Natural Language Processing']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('9', '9'), (']', ']'), ('``', '``'), ('Natural', 'natur'), ('Language', 'languag'), ('Processing', 'process'), ('.', '.'), ("''", "''")]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('9', '9'), (']', ']'), ('``', '``'), ('Natural', 'natur'), ('Language', 'languag'), ('Processing', 'process'), ('.', '.'), ("''", "''")]

>> Lemmatization: 
 [('[', '['), ('9', '9'), (']', ']'), ('``', '``'), ('Natural', 'Natural'), ('Language', 'Language'), ('Processing', 'Processing'), ('.', '.'), ("''", "''")]


------------------- Sentence 2 -------------------

Natural Language Processing RSS.

>> Tokens are: 
 ['Natural', 'Language', 'Processing', 'RSS', '.']

>> Bigrams are: 
 [('Natural', 'Language'), ('Language', 'Processing'), ('Processing', 'RSS'), ('RSS', '.')]

>> Trigrams are: 
 [('Natural', 'Language', 'Processing'), ('Language', 'Processing', 'RSS'), ('Processing', 'RSS', '.')]

>> POS Tags are: 
 [('Natural', 'JJ'), ('Language', 'NNP'), ('Processing', 'NNP'), ('RSS', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Natural Language Processing RSS']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Natural', 'natur'), ('Language', 'languag'), ('Processing', 'process'), ('RSS', 'rss'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Natural', 'natur'), ('Language', 'languag'), ('Processing', 'process'), ('RSS', 'rss'), ('.', '.')]

>> Lemmatization: 
 [('Natural', 'Natural'), ('Language', 'Language'), ('Processing', 'Processing'), ('RSS', 'RSS'), ('.', '.')]


------------------- Sentence 3 -------------------

N.p., n.d.

>> Tokens are: 
 ['N.p.', ',', 'n.d', '.']

>> Bigrams are: 
 [('N.p.', ','), (',', 'n.d'), ('n.d', '.')]

>> Trigrams are: 
 [('N.p.', ',', 'n.d'), (',', 'n.d', '.')]

>> POS Tags are: 
 [('N.p.', 'NNP'), (',', ','), ('n.d', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['N.p.', 'n.d']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('N.p.', 'n.p.'), (',', ','), ('n.d', 'n.d'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('N.p.', 'n.p.'), (',', ','), ('n.d', 'n.d'), ('.', '.')]

>> Lemmatization: 
 [('N.p.', 'N.p.'), (',', ','), ('n.d', 'n.d'), ('.', '.')]


------------------- Sentence 4 -------------------

Web.

>> Tokens are: 
 ['Web', '.']

>> Bigrams are: 
 [('Web', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Web', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Web']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Web', 'web'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Web', 'web'), ('.', '.')]

>> Lemmatization: 
 [('Web', 'Web'), ('.', '.')]


------------------- Sentence 5 -------------------

25

>> Tokens are: 
 ['25']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('25', 'CD')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('25', '25')]

>> Stemming using Snowball Stemmer: 
 [('25', '25')]

>> Lemmatization: 
 [('25', '25')]



========================================== PARAGRAPH 607 ===========================================

Mar. 2017  

------------------- Sentence 1 -------------------

Mar.

>> Tokens are: 
 ['Mar', '.']

>> Bigrams are: 
 [('Mar', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Mar', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Mar']

>> Named Entities are: 
 [('PERSON', 'Mar')] 

>> Stemming using Porter Stemmer: 
 [('Mar', 'mar'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Mar', 'mar'), ('.', '.')]

>> Lemmatization: 
 [('Mar', 'Mar'), ('.', '.')]


------------------- Sentence 2 -------------------

2017

>> Tokens are: 
 ['2017']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('2017', 'CD')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('2017', '2017')]

>> Stemming using Snowball Stemmer: 
 [('2017', '2017')]

>> Lemmatization: 
 [('2017', '2017')]



========================================== PARAGRAPH 608 ===========================================

[10] Hutchins, W. J. (1986). Machine translation: past, present, future (p. 66). Chichester:  

------------------- Sentence 1 -------------------

[10] Hutchins, W. J.

>> Tokens are: 
 ['[', '10', ']', 'Hutchins', ',', 'W.', 'J', '.']

>> Bigrams are: 
 [('[', '10'), ('10', ']'), (']', 'Hutchins'), ('Hutchins', ','), (',', 'W.'), ('W.', 'J'), ('J', '.')]

>> Trigrams are: 
 [('[', '10', ']'), ('10', ']', 'Hutchins'), (']', 'Hutchins', ','), ('Hutchins', ',', 'W.'), (',', 'W.', 'J'), ('W.', 'J', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('10', 'CD'), (']', 'NN'), ('Hutchins', 'NNP'), (',', ','), ('W.', 'NNP'), ('J', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['] Hutchins', 'W. J']

>> Named Entities are: 
 [('PERSON', 'Hutchins')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('10', '10'), (']', ']'), ('Hutchins', 'hutchin'), (',', ','), ('W.', 'w.'), ('J', 'j'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('10', '10'), (']', ']'), ('Hutchins', 'hutchin'), (',', ','), ('W.', 'w.'), ('J', 'j'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('10', '10'), (']', ']'), ('Hutchins', 'Hutchins'), (',', ','), ('W.', 'W.'), ('J', 'J'), ('.', '.')]


------------------- Sentence 2 -------------------

(1986).

>> Tokens are: 
 ['(', '1986', ')', '.']

>> Bigrams are: 
 [('(', '1986'), ('1986', ')'), (')', '.')]

>> Trigrams are: 
 [('(', '1986', ')'), ('1986', ')', '.')]

>> POS Tags are: 
 [('(', '('), ('1986', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('1986', '1986'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('1986', '1986'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('(', '('), ('1986', '1986'), (')', ')'), ('.', '.')]


------------------- Sentence 3 -------------------

Machine translation: past, present, future (p. 66).

>> Tokens are: 
 ['Machine', 'translation', ':', 'past', ',', 'present', ',', 'future', '(', 'p.', '66', ')', '.']

>> Bigrams are: 
 [('Machine', 'translation'), ('translation', ':'), (':', 'past'), ('past', ','), (',', 'present'), ('present', ','), (',', 'future'), ('future', '('), ('(', 'p.'), ('p.', '66'), ('66', ')'), (')', '.')]

>> Trigrams are: 
 [('Machine', 'translation', ':'), ('translation', ':', 'past'), (':', 'past', ','), ('past', ',', 'present'), (',', 'present', ','), ('present', ',', 'future'), (',', 'future', '('), ('future', '(', 'p.'), ('(', 'p.', '66'), ('p.', '66', ')'), ('66', ')', '.')]

>> POS Tags are: 
 [('Machine', 'NN'), ('translation', 'NN'), (':', ':'), ('past', 'NN'), (',', ','), ('present', 'NN'), (',', ','), ('future', 'NN'), ('(', '('), ('p.', 'JJ'), ('66', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['Machine translation', 'past', 'present', 'future']

>> Named Entities are: 
 [('GPE', 'Machine')] 

>> Stemming using Porter Stemmer: 
 [('Machine', 'machin'), ('translation', 'translat'), (':', ':'), ('past', 'past'), (',', ','), ('present', 'present'), (',', ','), ('future', 'futur'), ('(', '('), ('p.', 'p.'), ('66', '66'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Machine', 'machin'), ('translation', 'translat'), (':', ':'), ('past', 'past'), (',', ','), ('present', 'present'), (',', ','), ('future', 'futur'), ('(', '('), ('p.', 'p.'), ('66', '66'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Machine', 'Machine'), ('translation', 'translation'), (':', ':'), ('past', 'past'), (',', ','), ('present', 'present'), (',', ','), ('future', 'future'), ('(', '('), ('p.', 'p.'), ('66', '66'), (')', ')'), ('.', '.')]


------------------- Sentence 4 -------------------

Chichester:

>> Tokens are: 
 ['Chichester', ':']

>> Bigrams are: 
 [('Chichester', ':')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Chichester', 'NN'), (':', ':')]

>> Noun Phrases are: 
 ['Chichester']

>> Named Entities are: 
 [('GPE', 'Chichester')] 

>> Stemming using Porter Stemmer: 
 [('Chichester', 'chichest'), (':', ':')]

>> Stemming using Snowball Stemmer: 
 [('Chichester', 'chichest'), (':', ':')]

>> Lemmatization: 
 [('Chichester', 'Chichester'), (':', ':')]



========================================== PARAGRAPH 609 ===========================================

Ellis Horwood.  

------------------- Sentence 1 -------------------

Ellis Horwood.

>> Tokens are: 
 ['Ellis', 'Horwood', '.']

>> Bigrams are: 
 [('Ellis', 'Horwood'), ('Horwood', '.')]

>> Trigrams are: 
 [('Ellis', 'Horwood', '.')]

>> POS Tags are: 
 [('Ellis', 'NNP'), ('Horwood', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Ellis Horwood']

>> Named Entities are: 
 [('PERSON', 'Ellis'), ('ORGANIZATION', 'Horwood')] 

>> Stemming using Porter Stemmer: 
 [('Ellis', 'elli'), ('Horwood', 'horwood'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Ellis', 'elli'), ('Horwood', 'horwood'), ('.', '.')]

>> Lemmatization: 
 [('Ellis', 'Ellis'), ('Horwood', 'Horwood'), ('.', '.')]



========================================== PARAGRAPH 610 ===========================================

[11] Hutchins, W. J. (Ed.). (2000). Early years in machine translation: memoirs and  

------------------- Sentence 1 -------------------

[11] Hutchins, W. J.

>> Tokens are: 
 ['[', '11', ']', 'Hutchins', ',', 'W.', 'J', '.']

>> Bigrams are: 
 [('[', '11'), ('11', ']'), (']', 'Hutchins'), ('Hutchins', ','), (',', 'W.'), ('W.', 'J'), ('J', '.')]

>> Trigrams are: 
 [('[', '11', ']'), ('11', ']', 'Hutchins'), (']', 'Hutchins', ','), ('Hutchins', ',', 'W.'), (',', 'W.', 'J'), ('W.', 'J', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('11', 'CD'), (']', 'NN'), ('Hutchins', 'NNP'), (',', ','), ('W.', 'NNP'), ('J', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['] Hutchins', 'W. J']

>> Named Entities are: 
 [('PERSON', 'Hutchins')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('11', '11'), (']', ']'), ('Hutchins', 'hutchin'), (',', ','), ('W.', 'w.'), ('J', 'j'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('11', '11'), (']', ']'), ('Hutchins', 'hutchin'), (',', ','), ('W.', 'w.'), ('J', 'j'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('11', '11'), (']', ']'), ('Hutchins', 'Hutchins'), (',', ','), ('W.', 'W.'), ('J', 'J'), ('.', '.')]


------------------- Sentence 2 -------------------

(Ed.).

>> Tokens are: 
 ['(', 'Ed', '.', ')', '.']

>> Bigrams are: 
 [('(', 'Ed'), ('Ed', '.'), ('.', ')'), (')', '.')]

>> Trigrams are: 
 [('(', 'Ed', '.'), ('Ed', '.', ')'), ('.', ')', '.')]

>> POS Tags are: 
 [('(', '('), ('Ed', 'NNP'), ('.', '.'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['Ed']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('Ed', 'ed'), ('.', '.'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('Ed', 'ed'), ('.', '.'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('(', '('), ('Ed', 'Ed'), ('.', '.'), (')', ')'), ('.', '.')]


------------------- Sentence 3 -------------------

(2000).

>> Tokens are: 
 ['(', '2000', ')', '.']

>> Bigrams are: 
 [('(', '2000'), ('2000', ')'), (')', '.')]

>> Trigrams are: 
 [('(', '2000', ')'), ('2000', ')', '.')]

>> POS Tags are: 
 [('(', '('), ('2000', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('2000', '2000'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('2000', '2000'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('(', '('), ('2000', '2000'), (')', ')'), ('.', '.')]


------------------- Sentence 4 -------------------

Early years in machine translation: memoirs and

>> Tokens are: 
 ['Early', 'years', 'machine', 'translation', ':', 'memoirs']

>> Bigrams are: 
 [('Early', 'years'), ('years', 'machine'), ('machine', 'translation'), ('translation', ':'), (':', 'memoirs')]

>> Trigrams are: 
 [('Early', 'years', 'machine'), ('years', 'machine', 'translation'), ('machine', 'translation', ':'), ('translation', ':', 'memoirs')]

>> POS Tags are: 
 [('Early', 'JJ'), ('years', 'NNS'), ('machine', 'NN'), ('translation', 'NN'), (':', ':'), ('memoirs', 'NNS')]

>> Noun Phrases are: 
 ['Early years machine translation', 'memoirs']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Early', 'earli'), ('years', 'year'), ('machine', 'machin'), ('translation', 'translat'), (':', ':'), ('memoirs', 'memoir')]

>> Stemming using Snowball Stemmer: 
 [('Early', 'earli'), ('years', 'year'), ('machine', 'machin'), ('translation', 'translat'), (':', ':'), ('memoirs', 'memoir')]

>> Lemmatization: 
 [('Early', 'Early'), ('years', 'year'), ('machine', 'machine'), ('translation', 'translation'), (':', ':'), ('memoirs', 'memoir')]



========================================== PARAGRAPH 611 ===========================================

biographies of pioneers (Vol. 97). John Benjamins Publishing.  

------------------- Sentence 1 -------------------

biographies of pioneers (Vol.

>> Tokens are: 
 ['biographies', 'pioneers', '(', 'Vol', '.']

>> Bigrams are: 
 [('biographies', 'pioneers'), ('pioneers', '('), ('(', 'Vol'), ('Vol', '.')]

>> Trigrams are: 
 [('biographies', 'pioneers', '('), ('pioneers', '(', 'Vol'), ('(', 'Vol', '.')]

>> POS Tags are: 
 [('biographies', 'NNS'), ('pioneers', 'NNS'), ('(', '('), ('Vol', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['biographies pioneers', 'Vol']

>> Named Entities are: 
 [('ORGANIZATION', 'Vol')] 

>> Stemming using Porter Stemmer: 
 [('biographies', 'biographi'), ('pioneers', 'pioneer'), ('(', '('), ('Vol', 'vol'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('biographies', 'biographi'), ('pioneers', 'pioneer'), ('(', '('), ('Vol', 'vol'), ('.', '.')]

>> Lemmatization: 
 [('biographies', 'biography'), ('pioneers', 'pioneer'), ('(', '('), ('Vol', 'Vol'), ('.', '.')]


------------------- Sentence 2 -------------------

97).

>> Tokens are: 
 ['97', ')', '.']

>> Bigrams are: 
 [('97', ')'), (')', '.')]

>> Trigrams are: 
 [('97', ')', '.')]

>> POS Tags are: 
 [('97', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('97', '97'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('97', '97'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('97', '97'), (')', ')'), ('.', '.')]


------------------- Sentence 3 -------------------

John Benjamins Publishing.

>> Tokens are: 
 ['John', 'Benjamins', 'Publishing', '.']

>> Bigrams are: 
 [('John', 'Benjamins'), ('Benjamins', 'Publishing'), ('Publishing', '.')]

>> Trigrams are: 
 [('John', 'Benjamins', 'Publishing'), ('Benjamins', 'Publishing', '.')]

>> POS Tags are: 
 [('John', 'NNP'), ('Benjamins', 'NNP'), ('Publishing', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['John Benjamins Publishing']

>> Named Entities are: 
 [('PERSON', 'John'), ('PERSON', 'Benjamins Publishing')] 

>> Stemming using Porter Stemmer: 
 [('John', 'john'), ('Benjamins', 'benjamin'), ('Publishing', 'publish'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('John', 'john'), ('Benjamins', 'benjamin'), ('Publishing', 'publish'), ('.', '.')]

>> Lemmatization: 
 [('John', 'John'), ('Benjamins', 'Benjamins'), ('Publishing', 'Publishing'), ('.', '.')]



========================================== PARAGRAPH 612 ===========================================

[12] Green Jr, B. F., Wolf, A. K., Chomsky, C., & Laughery, K. (1961, May). Baseball: an  

------------------- Sentence 1 -------------------

[12] Green Jr, B. F., Wolf, A. K., Chomsky, C., & Laughery, K. (1961, May).

>> Tokens are: 
 ['[', '12', ']', 'Green', 'Jr', ',', 'B.', 'F.', ',', 'Wolf', ',', 'A.', 'K.', ',', 'Chomsky', ',', 'C.', ',', '&', 'Laughery', ',', 'K.', '(', '1961', ',', 'May', ')', '.']

>> Bigrams are: 
 [('[', '12'), ('12', ']'), (']', 'Green'), ('Green', 'Jr'), ('Jr', ','), (',', 'B.'), ('B.', 'F.'), ('F.', ','), (',', 'Wolf'), ('Wolf', ','), (',', 'A.'), ('A.', 'K.'), ('K.', ','), (',', 'Chomsky'), ('Chomsky', ','), (',', 'C.'), ('C.', ','), (',', '&'), ('&', 'Laughery'), ('Laughery', ','), (',', 'K.'), ('K.', '('), ('(', '1961'), ('1961', ','), (',', 'May'), ('May', ')'), (')', '.')]

>> Trigrams are: 
 [('[', '12', ']'), ('12', ']', 'Green'), (']', 'Green', 'Jr'), ('Green', 'Jr', ','), ('Jr', ',', 'B.'), (',', 'B.', 'F.'), ('B.', 'F.', ','), ('F.', ',', 'Wolf'), (',', 'Wolf', ','), ('Wolf', ',', 'A.'), (',', 'A.', 'K.'), ('A.', 'K.', ','), ('K.', ',', 'Chomsky'), (',', 'Chomsky', ','), ('Chomsky', ',', 'C.'), (',', 'C.', ','), ('C.', ',', '&'), (',', '&', 'Laughery'), ('&', 'Laughery', ','), ('Laughery', ',', 'K.'), (',', 'K.', '('), ('K.', '(', '1961'), ('(', '1961', ','), ('1961', ',', 'May'), (',', 'May', ')'), ('May', ')', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('12', 'CD'), (']', 'NNS'), ('Green', 'NNP'), ('Jr', 'NNP'), (',', ','), ('B.', 'NNP'), ('F.', 'NNP'), (',', ','), ('Wolf', 'NNP'), (',', ','), ('A.', 'NNP'), ('K.', 'NNP'), (',', ','), ('Chomsky', 'NNP'), (',', ','), ('C.', 'NNP'), (',', ','), ('&', 'CC'), ('Laughery', 'NNP'), (',', ','), ('K.', 'NNP'), ('(', '('), ('1961', 'CD'), (',', ','), ('May', 'NNP'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['] Green Jr', 'B. F.', 'Wolf', 'A. K.', 'Chomsky', 'C.', 'Laughery', 'K.', 'May']

>> Named Entities are: 
 [('PERSON', 'Green Jr'), ('PERSON', 'Wolf'), ('PERSON', 'Chomsky'), ('PERSON', 'Laughery')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('12', '12'), (']', ']'), ('Green', 'green'), ('Jr', 'jr'), (',', ','), ('B.', 'b.'), ('F.', 'f.'), (',', ','), ('Wolf', 'wolf'), (',', ','), ('A.', 'a.'), ('K.', 'k.'), (',', ','), ('Chomsky', 'chomski'), (',', ','), ('C.', 'c.'), (',', ','), ('&', '&'), ('Laughery', 'laugheri'), (',', ','), ('K.', 'k.'), ('(', '('), ('1961', '1961'), (',', ','), ('May', 'may'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('12', '12'), (']', ']'), ('Green', 'green'), ('Jr', 'jr'), (',', ','), ('B.', 'b.'), ('F.', 'f.'), (',', ','), ('Wolf', 'wolf'), (',', ','), ('A.', 'a.'), ('K.', 'k.'), (',', ','), ('Chomsky', 'chomski'), (',', ','), ('C.', 'c.'), (',', ','), ('&', '&'), ('Laughery', 'laugheri'), (',', ','), ('K.', 'k.'), ('(', '('), ('1961', '1961'), (',', ','), ('May', 'may'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('12', '12'), (']', ']'), ('Green', 'Green'), ('Jr', 'Jr'), (',', ','), ('B.', 'B.'), ('F.', 'F.'), (',', ','), ('Wolf', 'Wolf'), (',', ','), ('A.', 'A.'), ('K.', 'K.'), (',', ','), ('Chomsky', 'Chomsky'), (',', ','), ('C.', 'C.'), (',', ','), ('&', '&'), ('Laughery', 'Laughery'), (',', ','), ('K.', 'K.'), ('(', '('), ('1961', '1961'), (',', ','), ('May', 'May'), (')', ')'), ('.', '.')]


------------------- Sentence 2 -------------------

Baseball: an

>> Tokens are: 
 ['Baseball', ':']

>> Bigrams are: 
 [('Baseball', ':')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Baseball', 'NN'), (':', ':')]

>> Noun Phrases are: 
 ['Baseball']

>> Named Entities are: 
 [('GPE', 'Baseball')] 

>> Stemming using Porter Stemmer: 
 [('Baseball', 'basebal'), (':', ':')]

>> Stemming using Snowball Stemmer: 
 [('Baseball', 'basebal'), (':', ':')]

>> Lemmatization: 
 [('Baseball', 'Baseball'), (':', ':')]



========================================== PARAGRAPH 613 ===========================================

automatic question-answerer. In Papers presented at the May 9-11, 1961, western joint IRE- 

------------------- Sentence 1 -------------------

automatic question-answerer.

>> Tokens are: 
 ['automatic', 'question-answerer', '.']

>> Bigrams are: 
 [('automatic', 'question-answerer'), ('question-answerer', '.')]

>> Trigrams are: 
 [('automatic', 'question-answerer', '.')]

>> POS Tags are: 
 [('automatic', 'JJ'), ('question-answerer', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['automatic question-answerer']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('automatic', 'automat'), ('question-answerer', 'question-answer'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('automatic', 'automat'), ('question-answerer', 'question-answer'), ('.', '.')]

>> Lemmatization: 
 [('automatic', 'automatic'), ('question-answerer', 'question-answerer'), ('.', '.')]


------------------- Sentence 2 -------------------

In Papers presented at the May 9-11, 1961, western joint IRE-

>> Tokens are: 
 ['In', 'Papers', 'presented', 'May', '9-11', ',', '1961', ',', 'western', 'joint', 'IRE-']

>> Bigrams are: 
 [('In', 'Papers'), ('Papers', 'presented'), ('presented', 'May'), ('May', '9-11'), ('9-11', ','), (',', '1961'), ('1961', ','), (',', 'western'), ('western', 'joint'), ('joint', 'IRE-')]

>> Trigrams are: 
 [('In', 'Papers', 'presented'), ('Papers', 'presented', 'May'), ('presented', 'May', '9-11'), ('May', '9-11', ','), ('9-11', ',', '1961'), (',', '1961', ','), ('1961', ',', 'western'), (',', 'western', 'joint'), ('western', 'joint', 'IRE-')]

>> POS Tags are: 
 [('In', 'IN'), ('Papers', 'NNP'), ('presented', 'VBD'), ('May', 'NNP'), ('9-11', 'CD'), (',', ','), ('1961', 'CD'), (',', ','), ('western', 'JJ'), ('joint', 'JJ'), ('IRE-', 'NNS')]

>> Noun Phrases are: 
 ['Papers', 'May', 'western joint IRE-']

>> Named Entities are: 
 [('GPE', 'Papers')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('Papers', 'paper'), ('presented', 'present'), ('May', 'may'), ('9-11', '9-11'), (',', ','), ('1961', '1961'), (',', ','), ('western', 'western'), ('joint', 'joint'), ('IRE-', 'ire-')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('Papers', 'paper'), ('presented', 'present'), ('May', 'may'), ('9-11', '9-11'), (',', ','), ('1961', '1961'), (',', ','), ('western', 'western'), ('joint', 'joint'), ('IRE-', 'ire-')]

>> Lemmatization: 
 [('In', 'In'), ('Papers', 'Papers'), ('presented', 'presented'), ('May', 'May'), ('9-11', '9-11'), (',', ','), ('1961', '1961'), (',', ','), ('western', 'western'), ('joint', 'joint'), ('IRE-', 'IRE-')]



========================================== PARAGRAPH 614 ===========================================

AIEE-ACM computer conference (pp. 219-224). ACM.  

------------------- Sentence 1 -------------------

AIEE-ACM computer conference (pp.

>> Tokens are: 
 ['AIEE-ACM', 'computer', 'conference', '(', 'pp', '.']

>> Bigrams are: 
 [('AIEE-ACM', 'computer'), ('computer', 'conference'), ('conference', '('), ('(', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('AIEE-ACM', 'computer', 'conference'), ('computer', 'conference', '('), ('conference', '(', 'pp'), ('(', 'pp', '.')]

>> POS Tags are: 
 [('AIEE-ACM', 'NNP'), ('computer', 'NN'), ('conference', 'NN'), ('(', '('), ('pp', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['AIEE-ACM computer conference', 'pp']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('AIEE-ACM', 'aiee-acm'), ('computer', 'comput'), ('conference', 'confer'), ('(', '('), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('AIEE-ACM', 'aiee-acm'), ('computer', 'comput'), ('conference', 'confer'), ('(', '('), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('AIEE-ACM', 'AIEE-ACM'), ('computer', 'computer'), ('conference', 'conference'), ('(', '('), ('pp', 'pp'), ('.', '.')]


------------------- Sentence 2 -------------------

219-224).

>> Tokens are: 
 ['219-224', ')', '.']

>> Bigrams are: 
 [('219-224', ')'), (')', '.')]

>> Trigrams are: 
 [('219-224', ')', '.')]

>> POS Tags are: 
 [('219-224', 'JJ'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('219-224', '219-224'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('219-224', '219-224'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('219-224', '219-224'), (')', ')'), ('.', '.')]


------------------- Sentence 3 -------------------

ACM.

>> Tokens are: 
 ['ACM', '.']

>> Bigrams are: 
 [('ACM', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('ACM', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['ACM']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('ACM', 'acm'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('ACM', 'acm'), ('.', '.')]

>> Lemmatization: 
 [('ACM', 'ACM'), ('.', '.')]



========================================== PARAGRAPH 615 ===========================================

[13] Woods, W. A. (1978). Semantics and quantification in natural language question  

------------------- Sentence 1 -------------------

[13] Woods, W. A.

>> Tokens are: 
 ['[', '13', ']', 'Woods', ',', 'W.', 'A', '.']

>> Bigrams are: 
 [('[', '13'), ('13', ']'), (']', 'Woods'), ('Woods', ','), (',', 'W.'), ('W.', 'A'), ('A', '.')]

>> Trigrams are: 
 [('[', '13', ']'), ('13', ']', 'Woods'), (']', 'Woods', ','), ('Woods', ',', 'W.'), (',', 'W.', 'A'), ('W.', 'A', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('13', 'CD'), (']', 'JJ'), ('Woods', 'NNP'), (',', ','), ('W.', 'NNP'), ('A', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['] Woods', 'W. A']

>> Named Entities are: 
 [('PERSON', 'Woods')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('13', '13'), (']', ']'), ('Woods', 'wood'), (',', ','), ('W.', 'w.'), ('A', 'a'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('13', '13'), (']', ']'), ('Woods', 'wood'), (',', ','), ('W.', 'w.'), ('A', 'a'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('13', '13'), (']', ']'), ('Woods', 'Woods'), (',', ','), ('W.', 'W.'), ('A', 'A'), ('.', '.')]


------------------- Sentence 2 -------------------

(1978).

>> Tokens are: 
 ['(', '1978', ')', '.']

>> Bigrams are: 
 [('(', '1978'), ('1978', ')'), (')', '.')]

>> Trigrams are: 
 [('(', '1978', ')'), ('1978', ')', '.')]

>> POS Tags are: 
 [('(', '('), ('1978', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('1978', '1978'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('1978', '1978'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('(', '('), ('1978', '1978'), (')', ')'), ('.', '.')]


------------------- Sentence 3 -------------------

Semantics and quantification in natural language question

>> Tokens are: 
 ['Semantics', 'quantification', 'natural', 'language', 'question']

>> Bigrams are: 
 [('Semantics', 'quantification'), ('quantification', 'natural'), ('natural', 'language'), ('language', 'question')]

>> Trigrams are: 
 [('Semantics', 'quantification', 'natural'), ('quantification', 'natural', 'language'), ('natural', 'language', 'question')]

>> POS Tags are: 
 [('Semantics', 'NNS'), ('quantification', 'VBP'), ('natural', 'JJ'), ('language', 'NN'), ('question', 'NN')]

>> Noun Phrases are: 
 ['Semantics', 'natural language question']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Semantics', 'semant'), ('quantification', 'quantif'), ('natural', 'natur'), ('language', 'languag'), ('question', 'question')]

>> Stemming using Snowball Stemmer: 
 [('Semantics', 'semant'), ('quantification', 'quantif'), ('natural', 'natur'), ('language', 'languag'), ('question', 'question')]

>> Lemmatization: 
 [('Semantics', 'Semantics'), ('quantification', 'quantification'), ('natural', 'natural'), ('language', 'language'), ('question', 'question')]



========================================== PARAGRAPH 616 ===========================================

answering. Advances in computers, 17, 1-87.  

------------------- Sentence 1 -------------------

answering.

>> Tokens are: 
 ['answering', '.']

>> Bigrams are: 
 [('answering', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('answering', 'VBG'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('answering', 'answer'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('answering', 'answer'), ('.', '.')]

>> Lemmatization: 
 [('answering', 'answering'), ('.', '.')]


------------------- Sentence 2 -------------------

Advances in computers, 17, 1-87.

>> Tokens are: 
 ['Advances', 'computers', ',', '17', ',', '1-87', '.']

>> Bigrams are: 
 [('Advances', 'computers'), ('computers', ','), (',', '17'), ('17', ','), (',', '1-87'), ('1-87', '.')]

>> Trigrams are: 
 [('Advances', 'computers', ','), ('computers', ',', '17'), (',', '17', ','), ('17', ',', '1-87'), (',', '1-87', '.')]

>> POS Tags are: 
 [('Advances', 'NNS'), ('computers', 'NNS'), (',', ','), ('17', 'CD'), (',', ','), ('1-87', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Advances computers']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Advances', 'advanc'), ('computers', 'comput'), (',', ','), ('17', '17'), (',', ','), ('1-87', '1-87'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Advances', 'advanc'), ('computers', 'comput'), (',', ','), ('17', '17'), (',', ','), ('1-87', '1-87'), ('.', '.')]

>> Lemmatization: 
 [('Advances', 'Advances'), ('computers', 'computer'), (',', ','), ('17', '17'), (',', ','), ('1-87', '1-87'), ('.', '.')]



========================================== PARAGRAPH 617 ===========================================

[14] Hendrix, G. G., Sacerdoti, E. D., Sagalowicz, D., & Slocum, J. (1978). Developing a  

------------------- Sentence 1 -------------------

[14] Hendrix, G. G., Sacerdoti, E. D., Sagalowicz, D., & Slocum, J.

>> Tokens are: 
 ['[', '14', ']', 'Hendrix', ',', 'G.', 'G.', ',', 'Sacerdoti', ',', 'E.', 'D.', ',', 'Sagalowicz', ',', 'D.', ',', '&', 'Slocum', ',', 'J', '.']

>> Bigrams are: 
 [('[', '14'), ('14', ']'), (']', 'Hendrix'), ('Hendrix', ','), (',', 'G.'), ('G.', 'G.'), ('G.', ','), (',', 'Sacerdoti'), ('Sacerdoti', ','), (',', 'E.'), ('E.', 'D.'), ('D.', ','), (',', 'Sagalowicz'), ('Sagalowicz', ','), (',', 'D.'), ('D.', ','), (',', '&'), ('&', 'Slocum'), ('Slocum', ','), (',', 'J'), ('J', '.')]

>> Trigrams are: 
 [('[', '14', ']'), ('14', ']', 'Hendrix'), (']', 'Hendrix', ','), ('Hendrix', ',', 'G.'), (',', 'G.', 'G.'), ('G.', 'G.', ','), ('G.', ',', 'Sacerdoti'), (',', 'Sacerdoti', ','), ('Sacerdoti', ',', 'E.'), (',', 'E.', 'D.'), ('E.', 'D.', ','), ('D.', ',', 'Sagalowicz'), (',', 'Sagalowicz', ','), ('Sagalowicz', ',', 'D.'), (',', 'D.', ','), ('D.', ',', '&'), (',', '&', 'Slocum'), ('&', 'Slocum', ','), ('Slocum', ',', 'J'), (',', 'J', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('14', 'CD'), (']', 'JJ'), ('Hendrix', 'NNP'), (',', ','), ('G.', 'NNP'), ('G.', 'NNP'), (',', ','), ('Sacerdoti', 'NNP'), (',', ','), ('E.', 'NNP'), ('D.', 'NNP'), (',', ','), ('Sagalowicz', 'NNP'), (',', ','), ('D.', 'NNP'), (',', ','), ('&', 'CC'), ('Slocum', 'NNP'), (',', ','), ('J', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['] Hendrix', 'G. G.', 'Sacerdoti', 'E. D.', 'Sagalowicz', 'D.', 'Slocum', 'J']

>> Named Entities are: 
 [('PERSON', 'Hendrix'), ('PERSON', 'Sacerdoti'), ('GPE', 'Sagalowicz'), ('PERSON', 'Slocum')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('14', '14'), (']', ']'), ('Hendrix', 'hendrix'), (',', ','), ('G.', 'g.'), ('G.', 'g.'), (',', ','), ('Sacerdoti', 'sacerdoti'), (',', ','), ('E.', 'e.'), ('D.', 'd.'), (',', ','), ('Sagalowicz', 'sagalowicz'), (',', ','), ('D.', 'd.'), (',', ','), ('&', '&'), ('Slocum', 'slocum'), (',', ','), ('J', 'j'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('14', '14'), (']', ']'), ('Hendrix', 'hendrix'), (',', ','), ('G.', 'g.'), ('G.', 'g.'), (',', ','), ('Sacerdoti', 'sacerdoti'), (',', ','), ('E.', 'e.'), ('D.', 'd.'), (',', ','), ('Sagalowicz', 'sagalowicz'), (',', ','), ('D.', 'd.'), (',', ','), ('&', '&'), ('Slocum', 'slocum'), (',', ','), ('J', 'j'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('14', '14'), (']', ']'), ('Hendrix', 'Hendrix'), (',', ','), ('G.', 'G.'), ('G.', 'G.'), (',', ','), ('Sacerdoti', 'Sacerdoti'), (',', ','), ('E.', 'E.'), ('D.', 'D.'), (',', ','), ('Sagalowicz', 'Sagalowicz'), (',', ','), ('D.', 'D.'), (',', ','), ('&', '&'), ('Slocum', 'Slocum'), (',', ','), ('J', 'J'), ('.', '.')]


------------------- Sentence 2 -------------------

(1978).

>> Tokens are: 
 ['(', '1978', ')', '.']

>> Bigrams are: 
 [('(', '1978'), ('1978', ')'), (')', '.')]

>> Trigrams are: 
 [('(', '1978', ')'), ('1978', ')', '.')]

>> POS Tags are: 
 [('(', '('), ('1978', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('1978', '1978'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('1978', '1978'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('(', '('), ('1978', '1978'), (')', ')'), ('.', '.')]


------------------- Sentence 3 -------------------

Developing a

>> Tokens are: 
 ['Developing']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Developing', 'VBG')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Developing', 'develop')]

>> Stemming using Snowball Stemmer: 
 [('Developing', 'develop')]

>> Lemmatization: 
 [('Developing', 'Developing')]



========================================== PARAGRAPH 618 ===========================================

natural language interface to complex data. ACM Transactions on Database Systems  

------------------- Sentence 1 -------------------

natural language interface to complex data.

>> Tokens are: 
 ['natural', 'language', 'interface', 'complex', 'data', '.']

>> Bigrams are: 
 [('natural', 'language'), ('language', 'interface'), ('interface', 'complex'), ('complex', 'data'), ('data', '.')]

>> Trigrams are: 
 [('natural', 'language', 'interface'), ('language', 'interface', 'complex'), ('interface', 'complex', 'data'), ('complex', 'data', '.')]

>> POS Tags are: 
 [('natural', 'JJ'), ('language', 'NN'), ('interface', 'NN'), ('complex', 'JJ'), ('data', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['natural language interface', 'complex data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('natural', 'natur'), ('language', 'languag'), ('interface', 'interfac'), ('complex', 'complex'), ('data', 'data'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('natural', 'natur'), ('language', 'languag'), ('interface', 'interfac'), ('complex', 'complex'), ('data', 'data'), ('.', '.')]

>> Lemmatization: 
 [('natural', 'natural'), ('language', 'language'), ('interface', 'interface'), ('complex', 'complex'), ('data', 'data'), ('.', '.')]


------------------- Sentence 2 -------------------

ACM Transactions on Database Systems

>> Tokens are: 
 ['ACM', 'Transactions', 'Database', 'Systems']

>> Bigrams are: 
 [('ACM', 'Transactions'), ('Transactions', 'Database'), ('Database', 'Systems')]

>> Trigrams are: 
 [('ACM', 'Transactions', 'Database'), ('Transactions', 'Database', 'Systems')]

>> POS Tags are: 
 [('ACM', 'NNP'), ('Transactions', 'NNP'), ('Database', 'NNP'), ('Systems', 'NNP')]

>> Noun Phrases are: 
 ['ACM Transactions Database Systems']

>> Named Entities are: 
 [('ORGANIZATION', 'ACM Transactions Database Systems')] 

>> Stemming using Porter Stemmer: 
 [('ACM', 'acm'), ('Transactions', 'transact'), ('Database', 'databas'), ('Systems', 'system')]

>> Stemming using Snowball Stemmer: 
 [('ACM', 'acm'), ('Transactions', 'transact'), ('Database', 'databas'), ('Systems', 'system')]

>> Lemmatization: 
 [('ACM', 'ACM'), ('Transactions', 'Transactions'), ('Database', 'Database'), ('Systems', 'Systems')]



========================================== PARAGRAPH 619 ===========================================

(TODS), 3(2), 105-147.  

------------------- Sentence 1 -------------------

(TODS), 3(2), 105-147.

>> Tokens are: 
 ['(', 'TODS', ')', ',', '3', '(', '2', ')', ',', '105-147', '.']

>> Bigrams are: 
 [('(', 'TODS'), ('TODS', ')'), (')', ','), (',', '3'), ('3', '('), ('(', '2'), ('2', ')'), (')', ','), (',', '105-147'), ('105-147', '.')]

>> Trigrams are: 
 [('(', 'TODS', ')'), ('TODS', ')', ','), (')', ',', '3'), (',', '3', '('), ('3', '(', '2'), ('(', '2', ')'), ('2', ')', ','), (')', ',', '105-147'), (',', '105-147', '.')]

>> POS Tags are: 
 [('(', '('), ('TODS', 'NNP'), (')', ')'), (',', ','), ('3', 'CD'), ('(', '('), ('2', 'CD'), (')', ')'), (',', ','), ('105-147', 'JJ'), ('.', '.')]

>> Noun Phrases are: 
 ['TODS']

>> Named Entities are: 
 [('ORGANIZATION', 'TODS')] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('TODS', 'tod'), (')', ')'), (',', ','), ('3', '3'), ('(', '('), ('2', '2'), (')', ')'), (',', ','), ('105-147', '105-147'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('TODS', 'tod'), (')', ')'), (',', ','), ('3', '3'), ('(', '('), ('2', '2'), (')', ')'), (',', ','), ('105-147', '105-147'), ('.', '.')]

>> Lemmatization: 
 [('(', '('), ('TODS', 'TODS'), (')', ')'), (',', ','), ('3', '3'), ('(', '('), ('2', '2'), (')', ')'), (',', ','), ('105-147', '105-147'), ('.', '.')]



========================================== PARAGRAPH 620 ===========================================

[15] Alshawi, H. (1992). The core language engine. MIT press.  

------------------- Sentence 1 -------------------

[15] Alshawi, H. (1992).

>> Tokens are: 
 ['[', '15', ']', 'Alshawi', ',', 'H.', '(', '1992', ')', '.']

>> Bigrams are: 
 [('[', '15'), ('15', ']'), (']', 'Alshawi'), ('Alshawi', ','), (',', 'H.'), ('H.', '('), ('(', '1992'), ('1992', ')'), (')', '.')]

>> Trigrams are: 
 [('[', '15', ']'), ('15', ']', 'Alshawi'), (']', 'Alshawi', ','), ('Alshawi', ',', 'H.'), (',', 'H.', '('), ('H.', '(', '1992'), ('(', '1992', ')'), ('1992', ')', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('15', 'CD'), (']', 'JJ'), ('Alshawi', 'NNP'), (',', ','), ('H.', 'NNP'), ('(', '('), ('1992', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['] Alshawi', 'H.']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('15', '15'), (']', ']'), ('Alshawi', 'alshawi'), (',', ','), ('H.', 'h.'), ('(', '('), ('1992', '1992'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('15', '15'), (']', ']'), ('Alshawi', 'alshawi'), (',', ','), ('H.', 'h.'), ('(', '('), ('1992', '1992'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('15', '15'), (']', ']'), ('Alshawi', 'Alshawi'), (',', ','), ('H.', 'H.'), ('(', '('), ('1992', '1992'), (')', ')'), ('.', '.')]


------------------- Sentence 2 -------------------

The core language engine.

>> Tokens are: 
 ['The', 'core', 'language', 'engine', '.']

>> Bigrams are: 
 [('The', 'core'), ('core', 'language'), ('language', 'engine'), ('engine', '.')]

>> Trigrams are: 
 [('The', 'core', 'language'), ('core', 'language', 'engine'), ('language', 'engine', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('core', 'NN'), ('language', 'NN'), ('engine', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['The core language engine']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('core', 'core'), ('language', 'languag'), ('engine', 'engin'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('core', 'core'), ('language', 'languag'), ('engine', 'engin'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('core', 'core'), ('language', 'language'), ('engine', 'engine'), ('.', '.')]


------------------- Sentence 3 -------------------

MIT press.

>> Tokens are: 
 ['MIT', 'press', '.']

>> Bigrams are: 
 [('MIT', 'press'), ('press', '.')]

>> Trigrams are: 
 [('MIT', 'press', '.')]

>> POS Tags are: 
 [('MIT', 'NNP'), ('press', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['MIT press']

>> Named Entities are: 
 [('ORGANIZATION', 'MIT')] 

>> Stemming using Porter Stemmer: 
 [('MIT', 'mit'), ('press', 'press'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('MIT', 'mit'), ('press', 'press'), ('.', '.')]

>> Lemmatization: 
 [('MIT', 'MIT'), ('press', 'press'), ('.', '.')]



========================================== PARAGRAPH 621 ===========================================

[16] Kamp, H., & Reyle, U. (1993). Tense and Aspect. In From Discourse to Logic (pp. 483- 

------------------- Sentence 1 -------------------

[16] Kamp, H., & Reyle, U.

>> Tokens are: 
 ['[', '16', ']', 'Kamp', ',', 'H.', ',', '&', 'Reyle', ',', 'U', '.']

>> Bigrams are: 
 [('[', '16'), ('16', ']'), (']', 'Kamp'), ('Kamp', ','), (',', 'H.'), ('H.', ','), (',', '&'), ('&', 'Reyle'), ('Reyle', ','), (',', 'U'), ('U', '.')]

>> Trigrams are: 
 [('[', '16', ']'), ('16', ']', 'Kamp'), (']', 'Kamp', ','), ('Kamp', ',', 'H.'), (',', 'H.', ','), ('H.', ',', '&'), (',', '&', 'Reyle'), ('&', 'Reyle', ','), ('Reyle', ',', 'U'), (',', 'U', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('16', 'CD'), (']', 'JJ'), ('Kamp', 'NNP'), (',', ','), ('H.', 'NNP'), (',', ','), ('&', 'CC'), ('Reyle', 'NNP'), (',', ','), ('U', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['] Kamp', 'H.', 'Reyle', 'U']

>> Named Entities are: 
 [('PERSON', 'Reyle')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('16', '16'), (']', ']'), ('Kamp', 'kamp'), (',', ','), ('H.', 'h.'), (',', ','), ('&', '&'), ('Reyle', 'reyl'), (',', ','), ('U', 'u'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('16', '16'), (']', ']'), ('Kamp', 'kamp'), (',', ','), ('H.', 'h.'), (',', ','), ('&', '&'), ('Reyle', 'reyl'), (',', ','), ('U', 'u'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('16', '16'), (']', ']'), ('Kamp', 'Kamp'), (',', ','), ('H.', 'H.'), (',', ','), ('&', '&'), ('Reyle', 'Reyle'), (',', ','), ('U', 'U'), ('.', '.')]


------------------- Sentence 2 -------------------

(1993).

>> Tokens are: 
 ['(', '1993', ')', '.']

>> Bigrams are: 
 [('(', '1993'), ('1993', ')'), (')', '.')]

>> Trigrams are: 
 [('(', '1993', ')'), ('1993', ')', '.')]

>> POS Tags are: 
 [('(', '('), ('1993', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('1993', '1993'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('1993', '1993'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('(', '('), ('1993', '1993'), (')', ')'), ('.', '.')]


------------------- Sentence 3 -------------------

Tense and Aspect.

>> Tokens are: 
 ['Tense', 'Aspect', '.']

>> Bigrams are: 
 [('Tense', 'Aspect'), ('Aspect', '.')]

>> Trigrams are: 
 [('Tense', 'Aspect', '.')]

>> POS Tags are: 
 [('Tense', 'NNP'), ('Aspect', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Tense Aspect']

>> Named Entities are: 
 [('PERSON', 'Tense'), ('ORGANIZATION', 'Aspect')] 

>> Stemming using Porter Stemmer: 
 [('Tense', 'tens'), ('Aspect', 'aspect'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Tense', 'tens'), ('Aspect', 'aspect'), ('.', '.')]

>> Lemmatization: 
 [('Tense', 'Tense'), ('Aspect', 'Aspect'), ('.', '.')]


------------------- Sentence 4 -------------------

In From Discourse to Logic (pp.

>> Tokens are: 
 ['In', 'From', 'Discourse', 'Logic', '(', 'pp', '.']

>> Bigrams are: 
 [('In', 'From'), ('From', 'Discourse'), ('Discourse', 'Logic'), ('Logic', '('), ('(', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('In', 'From', 'Discourse'), ('From', 'Discourse', 'Logic'), ('Discourse', 'Logic', '('), ('Logic', '(', 'pp'), ('(', 'pp', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('From', 'NNP'), ('Discourse', 'NNP'), ('Logic', 'NNP'), ('(', '('), ('pp', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['From Discourse Logic', 'pp']

>> Named Entities are: 
 [('PERSON', 'Discourse Logic')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('From', 'from'), ('Discourse', 'discours'), ('Logic', 'logic'), ('(', '('), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('From', 'from'), ('Discourse', 'discours'), ('Logic', 'logic'), ('(', '('), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('From', 'From'), ('Discourse', 'Discourse'), ('Logic', 'Logic'), ('(', '('), ('pp', 'pp'), ('.', '.')]


------------------- Sentence 5 -------------------

483-

>> Tokens are: 
 ['483-']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('483-', 'JJ')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('483-', '483-')]

>> Stemming using Snowball Stemmer: 
 [('483-', '483-')]

>> Lemmatization: 
 [('483-', '483-')]



========================================== PARAGRAPH 622 ===========================================

689). Springer Netherlands.  

------------------- Sentence 1 -------------------

689).

>> Tokens are: 
 ['689', ')', '.']

>> Bigrams are: 
 [('689', ')'), (')', '.')]

>> Trigrams are: 
 [('689', ')', '.')]

>> POS Tags are: 
 [('689', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('689', '689'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('689', '689'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('689', '689'), (')', ')'), ('.', '.')]


------------------- Sentence 2 -------------------

Springer Netherlands.

>> Tokens are: 
 ['Springer', 'Netherlands', '.']

>> Bigrams are: 
 [('Springer', 'Netherlands'), ('Netherlands', '.')]

>> Trigrams are: 
 [('Springer', 'Netherlands', '.')]

>> POS Tags are: 
 [('Springer', 'NNP'), ('Netherlands', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Springer Netherlands']

>> Named Entities are: 
 [('PERSON', 'Springer'), ('ORGANIZATION', 'Netherlands')] 

>> Stemming using Porter Stemmer: 
 [('Springer', 'springer'), ('Netherlands', 'netherland'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Springer', 'springer'), ('Netherlands', 'netherland'), ('.', '.')]

>> Lemmatization: 
 [('Springer', 'Springer'), ('Netherlands', 'Netherlands'), ('.', '.')]



========================================== PARAGRAPH 623 ===========================================

[17] Lea , W.A Trends in speech recognition , Englewoods Cliffs , NJ: Prentice Hall , 1980.  

------------------- Sentence 1 -------------------

[17] Lea , W.A Trends in speech recognition , Englewoods Cliffs , NJ: Prentice Hall , 1980.

>> Tokens are: 
 ['[', '17', ']', 'Lea', ',', 'W.A', 'Trends', 'speech', 'recognition', ',', 'Englewoods', 'Cliffs', ',', 'NJ', ':', 'Prentice', 'Hall', ',', '1980', '.']

>> Bigrams are: 
 [('[', '17'), ('17', ']'), (']', 'Lea'), ('Lea', ','), (',', 'W.A'), ('W.A', 'Trends'), ('Trends', 'speech'), ('speech', 'recognition'), ('recognition', ','), (',', 'Englewoods'), ('Englewoods', 'Cliffs'), ('Cliffs', ','), (',', 'NJ'), ('NJ', ':'), (':', 'Prentice'), ('Prentice', 'Hall'), ('Hall', ','), (',', '1980'), ('1980', '.')]

>> Trigrams are: 
 [('[', '17', ']'), ('17', ']', 'Lea'), (']', 'Lea', ','), ('Lea', ',', 'W.A'), (',', 'W.A', 'Trends'), ('W.A', 'Trends', 'speech'), ('Trends', 'speech', 'recognition'), ('speech', 'recognition', ','), ('recognition', ',', 'Englewoods'), (',', 'Englewoods', 'Cliffs'), ('Englewoods', 'Cliffs', ','), ('Cliffs', ',', 'NJ'), (',', 'NJ', ':'), ('NJ', ':', 'Prentice'), (':', 'Prentice', 'Hall'), ('Prentice', 'Hall', ','), ('Hall', ',', '1980'), (',', '1980', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('17', 'CD'), (']', 'JJ'), ('Lea', 'NNP'), (',', ','), ('W.A', 'NNP'), ('Trends', 'NNP'), ('speech', 'NN'), ('recognition', 'NN'), (',', ','), ('Englewoods', 'NNP'), ('Cliffs', 'NNP'), (',', ','), ('NJ', 'NNP'), (':', ':'), ('Prentice', 'NNP'), ('Hall', 'NNP'), (',', ','), ('1980', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['] Lea', 'W.A Trends speech recognition', 'Englewoods Cliffs', 'NJ', 'Prentice Hall']

>> Named Entities are: 
 [('PERSON', 'Englewoods Cliffs')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('17', '17'), (']', ']'), ('Lea', 'lea'), (',', ','), ('W.A', 'w.a'), ('Trends', 'trend'), ('speech', 'speech'), ('recognition', 'recognit'), (',', ','), ('Englewoods', 'englewood'), ('Cliffs', 'cliff'), (',', ','), ('NJ', 'nj'), (':', ':'), ('Prentice', 'prentic'), ('Hall', 'hall'), (',', ','), ('1980', '1980'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('17', '17'), (']', ']'), ('Lea', 'lea'), (',', ','), ('W.A', 'w.a'), ('Trends', 'trend'), ('speech', 'speech'), ('recognition', 'recognit'), (',', ','), ('Englewoods', 'englewood'), ('Cliffs', 'cliff'), (',', ','), ('NJ', 'nj'), (':', ':'), ('Prentice', 'prentic'), ('Hall', 'hall'), (',', ','), ('1980', '1980'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('17', '17'), (']', ']'), ('Lea', 'Lea'), (',', ','), ('W.A', 'W.A'), ('Trends', 'Trends'), ('speech', 'speech'), ('recognition', 'recognition'), (',', ','), ('Englewoods', 'Englewoods'), ('Cliffs', 'Cliffs'), (',', ','), ('NJ', 'NJ'), (':', ':'), ('Prentice', 'Prentice'), ('Hall', 'Hall'), (',', ','), ('1980', '1980'), ('.', '.')]



========================================== PARAGRAPH 624 ===========================================

[18] Young, S. J., & Chase, L. L. (1998). Speech recognition evaluation: a review of the US  

------------------- Sentence 1 -------------------

[18] Young, S. J., & Chase, L. L. (1998).

>> Tokens are: 
 ['[', '18', ']', 'Young', ',', 'S.', 'J.', ',', '&', 'Chase', ',', 'L.', 'L.', '(', '1998', ')', '.']

>> Bigrams are: 
 [('[', '18'), ('18', ']'), (']', 'Young'), ('Young', ','), (',', 'S.'), ('S.', 'J.'), ('J.', ','), (',', '&'), ('&', 'Chase'), ('Chase', ','), (',', 'L.'), ('L.', 'L.'), ('L.', '('), ('(', '1998'), ('1998', ')'), (')', '.')]

>> Trigrams are: 
 [('[', '18', ']'), ('18', ']', 'Young'), (']', 'Young', ','), ('Young', ',', 'S.'), (',', 'S.', 'J.'), ('S.', 'J.', ','), ('J.', ',', '&'), (',', '&', 'Chase'), ('&', 'Chase', ','), ('Chase', ',', 'L.'), (',', 'L.', 'L.'), ('L.', 'L.', '('), ('L.', '(', '1998'), ('(', '1998', ')'), ('1998', ')', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('18', 'CD'), (']', 'JJ'), ('Young', 'NNP'), (',', ','), ('S.', 'NNP'), ('J.', 'NNP'), (',', ','), ('&', 'CC'), ('Chase', 'NNP'), (',', ','), ('L.', 'NNP'), ('L.', 'NNP'), ('(', '('), ('1998', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['] Young', 'S. J.', 'Chase', 'L. L.']

>> Named Entities are: 
 [('PERSON', 'Chase')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('18', '18'), (']', ']'), ('Young', 'young'), (',', ','), ('S.', 's.'), ('J.', 'j.'), (',', ','), ('&', '&'), ('Chase', 'chase'), (',', ','), ('L.', 'l.'), ('L.', 'l.'), ('(', '('), ('1998', '1998'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('18', '18'), (']', ']'), ('Young', 'young'), (',', ','), ('S.', 's.'), ('J.', 'j.'), (',', ','), ('&', '&'), ('Chase', 'chase'), (',', ','), ('L.', 'l.'), ('L.', 'l.'), ('(', '('), ('1998', '1998'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('18', '18'), (']', ']'), ('Young', 'Young'), (',', ','), ('S.', 'S.'), ('J.', 'J.'), (',', ','), ('&', '&'), ('Chase', 'Chase'), (',', ','), ('L.', 'L.'), ('L.', 'L.'), ('(', '('), ('1998', '1998'), (')', ')'), ('.', '.')]


------------------- Sentence 2 -------------------

Speech recognition evaluation: a review of the US

>> Tokens are: 
 ['Speech', 'recognition', 'evaluation', ':', 'review', 'US']

>> Bigrams are: 
 [('Speech', 'recognition'), ('recognition', 'evaluation'), ('evaluation', ':'), (':', 'review'), ('review', 'US')]

>> Trigrams are: 
 [('Speech', 'recognition', 'evaluation'), ('recognition', 'evaluation', ':'), ('evaluation', ':', 'review'), (':', 'review', 'US')]

>> POS Tags are: 
 [('Speech', 'NNP'), ('recognition', 'NN'), ('evaluation', 'NN'), (':', ':'), ('review', 'NN'), ('US', 'IN')]

>> Noun Phrases are: 
 ['Speech recognition evaluation', 'review']

>> Named Entities are: 
 [('GPE', 'Speech')] 

>> Stemming using Porter Stemmer: 
 [('Speech', 'speech'), ('recognition', 'recognit'), ('evaluation', 'evalu'), (':', ':'), ('review', 'review'), ('US', 'us')]

>> Stemming using Snowball Stemmer: 
 [('Speech', 'speech'), ('recognition', 'recognit'), ('evaluation', 'evalu'), (':', ':'), ('review', 'review'), ('US', 'us')]

>> Lemmatization: 
 [('Speech', 'Speech'), ('recognition', 'recognition'), ('evaluation', 'evaluation'), (':', ':'), ('review', 'review'), ('US', 'US')]



========================================== PARAGRAPH 625 ===========================================

CSR and LVCSR programmes. Computer Speech & Language, 12(4), 263-279.  

------------------- Sentence 1 -------------------

CSR and LVCSR programmes.

>> Tokens are: 
 ['CSR', 'LVCSR', 'programmes', '.']

>> Bigrams are: 
 [('CSR', 'LVCSR'), ('LVCSR', 'programmes'), ('programmes', '.')]

>> Trigrams are: 
 [('CSR', 'LVCSR', 'programmes'), ('LVCSR', 'programmes', '.')]

>> POS Tags are: 
 [('CSR', 'NNP'), ('LVCSR', 'NNP'), ('programmes', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['CSR LVCSR programmes']

>> Named Entities are: 
 [('ORGANIZATION', 'CSR'), ('ORGANIZATION', 'LVCSR')] 

>> Stemming using Porter Stemmer: 
 [('CSR', 'csr'), ('LVCSR', 'lvcsr'), ('programmes', 'programm'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('CSR', 'csr'), ('LVCSR', 'lvcsr'), ('programmes', 'programm'), ('.', '.')]

>> Lemmatization: 
 [('CSR', 'CSR'), ('LVCSR', 'LVCSR'), ('programmes', 'programme'), ('.', '.')]


------------------- Sentence 2 -------------------

Computer Speech & Language, 12(4), 263-279.

>> Tokens are: 
 ['Computer', 'Speech', '&', 'Language', ',', '12', '(', '4', ')', ',', '263-279', '.']

>> Bigrams are: 
 [('Computer', 'Speech'), ('Speech', '&'), ('&', 'Language'), ('Language', ','), (',', '12'), ('12', '('), ('(', '4'), ('4', ')'), (')', ','), (',', '263-279'), ('263-279', '.')]

>> Trigrams are: 
 [('Computer', 'Speech', '&'), ('Speech', '&', 'Language'), ('&', 'Language', ','), ('Language', ',', '12'), (',', '12', '('), ('12', '(', '4'), ('(', '4', ')'), ('4', ')', ','), (')', ',', '263-279'), (',', '263-279', '.')]

>> POS Tags are: 
 [('Computer', 'NNP'), ('Speech', 'NNP'), ('&', 'CC'), ('Language', 'NNP'), (',', ','), ('12', 'CD'), ('(', '('), ('4', 'CD'), (')', ')'), (',', ','), ('263-279', 'JJ'), ('.', '.')]

>> Noun Phrases are: 
 ['Computer Speech', 'Language']

>> Named Entities are: 
 [('ORGANIZATION', 'Computer Speech'), ('PERSON', 'Language')] 

>> Stemming using Porter Stemmer: 
 [('Computer', 'comput'), ('Speech', 'speech'), ('&', '&'), ('Language', 'languag'), (',', ','), ('12', '12'), ('(', '('), ('4', '4'), (')', ')'), (',', ','), ('263-279', '263-279'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Computer', 'comput'), ('Speech', 'speech'), ('&', '&'), ('Language', 'languag'), (',', ','), ('12', '12'), ('(', '('), ('4', '4'), (')', ')'), (',', ','), ('263-279', '263-279'), ('.', '.')]

>> Lemmatization: 
 [('Computer', 'Computer'), ('Speech', 'Speech'), ('&', '&'), ('Language', 'Language'), (',', ','), ('12', '12'), ('(', '('), ('4', '4'), (')', ')'), (',', ','), ('263-279', '263-279'), ('.', '.')]



========================================== PARAGRAPH 626 ===========================================

[19] Sundheim, B. M., & Chinchor, N. A. (1993, March). Survey of the message  

------------------- Sentence 1 -------------------

[19] Sundheim, B. M., & Chinchor, N. A.

>> Tokens are: 
 ['[', '19', ']', 'Sundheim', ',', 'B.', 'M.', ',', '&', 'Chinchor', ',', 'N.', 'A', '.']

>> Bigrams are: 
 [('[', '19'), ('19', ']'), (']', 'Sundheim'), ('Sundheim', ','), (',', 'B.'), ('B.', 'M.'), ('M.', ','), (',', '&'), ('&', 'Chinchor'), ('Chinchor', ','), (',', 'N.'), ('N.', 'A'), ('A', '.')]

>> Trigrams are: 
 [('[', '19', ']'), ('19', ']', 'Sundheim'), (']', 'Sundheim', ','), ('Sundheim', ',', 'B.'), (',', 'B.', 'M.'), ('B.', 'M.', ','), ('M.', ',', '&'), (',', '&', 'Chinchor'), ('&', 'Chinchor', ','), ('Chinchor', ',', 'N.'), (',', 'N.', 'A'), ('N.', 'A', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('19', 'CD'), (']', 'JJ'), ('Sundheim', 'NNP'), (',', ','), ('B.', 'NNP'), ('M.', 'NNP'), (',', ','), ('&', 'CC'), ('Chinchor', 'NNP'), (',', ','), ('N.', 'NNP'), ('A', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['] Sundheim', 'B. M.', 'Chinchor', 'N. A']

>> Named Entities are: 
 [('ORGANIZATION', 'Sundheim'), ('GPE', 'Chinchor')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('19', '19'), (']', ']'), ('Sundheim', 'sundheim'), (',', ','), ('B.', 'b.'), ('M.', 'm.'), (',', ','), ('&', '&'), ('Chinchor', 'chinchor'), (',', ','), ('N.', 'n.'), ('A', 'a'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('19', '19'), (']', ']'), ('Sundheim', 'sundheim'), (',', ','), ('B.', 'b.'), ('M.', 'm.'), (',', ','), ('&', '&'), ('Chinchor', 'chinchor'), (',', ','), ('N.', 'n.'), ('A', 'a'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('19', '19'), (']', ']'), ('Sundheim', 'Sundheim'), (',', ','), ('B.', 'B.'), ('M.', 'M.'), (',', ','), ('&', '&'), ('Chinchor', 'Chinchor'), (',', ','), ('N.', 'N.'), ('A', 'A'), ('.', '.')]


------------------- Sentence 2 -------------------

(1993, March).

>> Tokens are: 
 ['(', '1993', ',', 'March', ')', '.']

>> Bigrams are: 
 [('(', '1993'), ('1993', ','), (',', 'March'), ('March', ')'), (')', '.')]

>> Trigrams are: 
 [('(', '1993', ','), ('1993', ',', 'March'), (',', 'March', ')'), ('March', ')', '.')]

>> POS Tags are: 
 [('(', '('), ('1993', 'CD'), (',', ','), ('March', 'NNP'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['March']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('1993', '1993'), (',', ','), ('March', 'march'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('1993', '1993'), (',', ','), ('March', 'march'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('(', '('), ('1993', '1993'), (',', ','), ('March', 'March'), (')', ')'), ('.', '.')]


------------------- Sentence 3 -------------------

Survey of the message

>> Tokens are: 
 ['Survey', 'message']

>> Bigrams are: 
 [('Survey', 'message')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Survey', 'NNP'), ('message', 'NN')]

>> Noun Phrases are: 
 ['Survey message']

>> Named Entities are: 
 [('GPE', 'Survey')] 

>> Stemming using Porter Stemmer: 
 [('Survey', 'survey'), ('message', 'messag')]

>> Stemming using Snowball Stemmer: 
 [('Survey', 'survey'), ('message', 'messag')]

>> Lemmatization: 
 [('Survey', 'Survey'), ('message', 'message')]



========================================== PARAGRAPH 627 ===========================================

understanding conferences. In Proceedings of the workshop on Human Language  

------------------- Sentence 1 -------------------

understanding conferences.

>> Tokens are: 
 ['understanding', 'conferences', '.']

>> Bigrams are: 
 [('understanding', 'conferences'), ('conferences', '.')]

>> Trigrams are: 
 [('understanding', 'conferences', '.')]

>> POS Tags are: 
 [('understanding', 'JJ'), ('conferences', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['understanding conferences']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('understanding', 'understand'), ('conferences', 'confer'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('understanding', 'understand'), ('conferences', 'confer'), ('.', '.')]

>> Lemmatization: 
 [('understanding', 'understanding'), ('conferences', 'conference'), ('.', '.')]


------------------- Sentence 2 -------------------

In Proceedings of the workshop on Human Language

>> Tokens are: 
 ['In', 'Proceedings', 'workshop', 'Human', 'Language']

>> Bigrams are: 
 [('In', 'Proceedings'), ('Proceedings', 'workshop'), ('workshop', 'Human'), ('Human', 'Language')]

>> Trigrams are: 
 [('In', 'Proceedings', 'workshop'), ('Proceedings', 'workshop', 'Human'), ('workshop', 'Human', 'Language')]

>> POS Tags are: 
 [('In', 'IN'), ('Proceedings', 'NNP'), ('workshop', 'NN'), ('Human', 'NNP'), ('Language', 'NN')]

>> Noun Phrases are: 
 ['Proceedings workshop Human Language']

>> Named Entities are: 
 [('GPE', 'Proceedings'), ('PERSON', 'Human')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('Proceedings', 'proceed'), ('workshop', 'workshop'), ('Human', 'human'), ('Language', 'languag')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('Proceedings', 'proceed'), ('workshop', 'workshop'), ('Human', 'human'), ('Language', 'languag')]

>> Lemmatization: 
 [('In', 'In'), ('Proceedings', 'Proceedings'), ('workshop', 'workshop'), ('Human', 'Human'), ('Language', 'Language')]



========================================== PARAGRAPH 628 ===========================================

Technology (pp. 56-60). Association for Computational Linguistics. 

------------------- Sentence 1 -------------------

Technology (pp.

>> Tokens are: 
 ['Technology', '(', 'pp', '.']

>> Bigrams are: 
 [('Technology', '('), ('(', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('Technology', '(', 'pp'), ('(', 'pp', '.')]

>> POS Tags are: 
 [('Technology', 'NN'), ('(', '('), ('pp', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Technology', 'pp']

>> Named Entities are: 
 [('GPE', 'Technology')] 

>> Stemming using Porter Stemmer: 
 [('Technology', 'technolog'), ('(', '('), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Technology', 'technolog'), ('(', '('), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('Technology', 'Technology'), ('(', '('), ('pp', 'pp'), ('.', '.')]


------------------- Sentence 2 -------------------

56-60).

>> Tokens are: 
 ['56-60', ')', '.']

>> Bigrams are: 
 [('56-60', ')'), (')', '.')]

>> Trigrams are: 
 [('56-60', ')', '.')]

>> POS Tags are: 
 [('56-60', 'JJ'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('56-60', '56-60'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('56-60', '56-60'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('56-60', '56-60'), (')', ')'), ('.', '.')]


------------------- Sentence 3 -------------------

Association for Computational Linguistics.

>> Tokens are: 
 ['Association', 'Computational', 'Linguistics', '.']

>> Bigrams are: 
 [('Association', 'Computational'), ('Computational', 'Linguistics'), ('Linguistics', '.')]

>> Trigrams are: 
 [('Association', 'Computational', 'Linguistics'), ('Computational', 'Linguistics', '.')]

>> POS Tags are: 
 [('Association', 'NNP'), ('Computational', 'NNP'), ('Linguistics', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Association Computational Linguistics']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Association', 'associ'), ('Computational', 'comput'), ('Linguistics', 'linguist'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Association', 'associ'), ('Computational', 'comput'), ('Linguistics', 'linguist'), ('.', '.')]

>> Lemmatization: 
 [('Association', 'Association'), ('Computational', 'Computational'), ('Linguistics', 'Linguistics'), ('.', '.')]



========================================== PARAGRAPH 629 ===========================================

[20] Wahlster, W., & Kobsa, A. (1989). User models in dialog systems. In User models in  

------------------- Sentence 1 -------------------

[20] Wahlster, W., & Kobsa, A.

>> Tokens are: 
 ['[', '20', ']', 'Wahlster', ',', 'W.', ',', '&', 'Kobsa', ',', 'A', '.']

>> Bigrams are: 
 [('[', '20'), ('20', ']'), (']', 'Wahlster'), ('Wahlster', ','), (',', 'W.'), ('W.', ','), (',', '&'), ('&', 'Kobsa'), ('Kobsa', ','), (',', 'A'), ('A', '.')]

>> Trigrams are: 
 [('[', '20', ']'), ('20', ']', 'Wahlster'), (']', 'Wahlster', ','), ('Wahlster', ',', 'W.'), (',', 'W.', ','), ('W.', ',', '&'), (',', '&', 'Kobsa'), ('&', 'Kobsa', ','), ('Kobsa', ',', 'A'), (',', 'A', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('20', 'CD'), (']', 'JJ'), ('Wahlster', 'NNP'), (',', ','), ('W.', 'NNP'), (',', ','), ('&', 'CC'), ('Kobsa', 'NNP'), (',', ','), ('A', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['] Wahlster', 'W.', 'Kobsa', 'A']

>> Named Entities are: 
 [('PERSON', 'Kobsa')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('20', '20'), (']', ']'), ('Wahlster', 'wahlster'), (',', ','), ('W.', 'w.'), (',', ','), ('&', '&'), ('Kobsa', 'kobsa'), (',', ','), ('A', 'a'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('20', '20'), (']', ']'), ('Wahlster', 'wahlster'), (',', ','), ('W.', 'w.'), (',', ','), ('&', '&'), ('Kobsa', 'kobsa'), (',', ','), ('A', 'a'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('20', '20'), (']', ']'), ('Wahlster', 'Wahlster'), (',', ','), ('W.', 'W.'), (',', ','), ('&', '&'), ('Kobsa', 'Kobsa'), (',', ','), ('A', 'A'), ('.', '.')]


------------------- Sentence 2 -------------------

(1989).

>> Tokens are: 
 ['(', '1989', ')', '.']

>> Bigrams are: 
 [('(', '1989'), ('1989', ')'), (')', '.')]

>> Trigrams are: 
 [('(', '1989', ')'), ('1989', ')', '.')]

>> POS Tags are: 
 [('(', '('), ('1989', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('1989', '1989'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('1989', '1989'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('(', '('), ('1989', '1989'), (')', ')'), ('.', '.')]


------------------- Sentence 3 -------------------

User models in dialog systems.

>> Tokens are: 
 ['User', 'models', 'dialog', 'systems', '.']

>> Bigrams are: 
 [('User', 'models'), ('models', 'dialog'), ('dialog', 'systems'), ('systems', '.')]

>> Trigrams are: 
 [('User', 'models', 'dialog'), ('models', 'dialog', 'systems'), ('dialog', 'systems', '.')]

>> POS Tags are: 
 [('User', 'NNP'), ('models', 'NNS'), ('dialog', 'VBP'), ('systems', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['User models', 'systems']

>> Named Entities are: 
 [('GPE', 'User')] 

>> Stemming using Porter Stemmer: 
 [('User', 'user'), ('models', 'model'), ('dialog', 'dialog'), ('systems', 'system'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('User', 'user'), ('models', 'model'), ('dialog', 'dialog'), ('systems', 'system'), ('.', '.')]

>> Lemmatization: 
 [('User', 'User'), ('models', 'model'), ('dialog', 'dialog'), ('systems', 'system'), ('.', '.')]


------------------- Sentence 4 -------------------

In User models in

>> Tokens are: 
 ['In', 'User', 'models']

>> Bigrams are: 
 [('In', 'User'), ('User', 'models')]

>> Trigrams are: 
 [('In', 'User', 'models')]

>> POS Tags are: 
 [('In', 'IN'), ('User', 'NNP'), ('models', 'NNS')]

>> Noun Phrases are: 
 ['User models']

>> Named Entities are: 
 [('GPE', 'User')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('User', 'user'), ('models', 'model')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('User', 'user'), ('models', 'model')]

>> Lemmatization: 
 [('In', 'In'), ('User', 'User'), ('models', 'model')]



========================================== PARAGRAPH 630 ===========================================

dialog systems (pp. 4-34). Springer Berlin Heidelberg.  

------------------- Sentence 1 -------------------

dialog systems (pp.

>> Tokens are: 
 ['dialog', 'systems', '(', 'pp', '.']

>> Bigrams are: 
 [('dialog', 'systems'), ('systems', '('), ('(', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('dialog', 'systems', '('), ('systems', '(', 'pp'), ('(', 'pp', '.')]

>> POS Tags are: 
 [('dialog', 'NN'), ('systems', 'NNS'), ('(', '('), ('pp', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['dialog systems', 'pp']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('dialog', 'dialog'), ('systems', 'system'), ('(', '('), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('dialog', 'dialog'), ('systems', 'system'), ('(', '('), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('dialog', 'dialog'), ('systems', 'system'), ('(', '('), ('pp', 'pp'), ('.', '.')]


------------------- Sentence 2 -------------------

4-34).

>> Tokens are: 
 ['4-34', ')', '.']

>> Bigrams are: 
 [('4-34', ')'), (')', '.')]

>> Trigrams are: 
 [('4-34', ')', '.')]

>> POS Tags are: 
 [('4-34', 'JJ'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('4-34', '4-34'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('4-34', '4-34'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('4-34', '4-34'), (')', ')'), ('.', '.')]


------------------- Sentence 3 -------------------

Springer Berlin Heidelberg.

>> Tokens are: 
 ['Springer', 'Berlin', 'Heidelberg', '.']

>> Bigrams are: 
 [('Springer', 'Berlin'), ('Berlin', 'Heidelberg'), ('Heidelberg', '.')]

>> Trigrams are: 
 [('Springer', 'Berlin', 'Heidelberg'), ('Berlin', 'Heidelberg', '.')]

>> POS Tags are: 
 [('Springer', 'NNP'), ('Berlin', 'NNP'), ('Heidelberg', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Springer Berlin Heidelberg']

>> Named Entities are: 
 [('PERSON', 'Springer'), ('PERSON', 'Berlin Heidelberg')] 

>> Stemming using Porter Stemmer: 
 [('Springer', 'springer'), ('Berlin', 'berlin'), ('Heidelberg', 'heidelberg'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Springer', 'springer'), ('Berlin', 'berlin'), ('Heidelberg', 'heidelberg'), ('.', '.')]

>> Lemmatization: 
 [('Springer', 'Springer'), ('Berlin', 'Berlin'), ('Heidelberg', 'Heidelberg'), ('.', '.')]



========================================== PARAGRAPH 631 ===========================================

[21] McKeown, K.R. Text generation , Cambridge: Cambridge University Press , 1985.  

------------------- Sentence 1 -------------------

[21] McKeown, K.R.

>> Tokens are: 
 ['[', '21', ']', 'McKeown', ',', 'K.R', '.']

>> Bigrams are: 
 [('[', '21'), ('21', ']'), (']', 'McKeown'), ('McKeown', ','), (',', 'K.R'), ('K.R', '.')]

>> Trigrams are: 
 [('[', '21', ']'), ('21', ']', 'McKeown'), (']', 'McKeown', ','), ('McKeown', ',', 'K.R'), (',', 'K.R', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('21', 'CD'), (']', 'JJ'), ('McKeown', 'NNP'), (',', ','), ('K.R', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['] McKeown', 'K.R']

>> Named Entities are: 
 [('ORGANIZATION', 'McKeown')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('21', '21'), (']', ']'), ('McKeown', 'mckeown'), (',', ','), ('K.R', 'k.r'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('21', '21'), (']', ']'), ('McKeown', 'mckeown'), (',', ','), ('K.R', 'k.r'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('21', '21'), (']', ']'), ('McKeown', 'McKeown'), (',', ','), ('K.R', 'K.R'), ('.', '.')]


------------------- Sentence 2 -------------------

Text generation , Cambridge: Cambridge University Press , 1985.

>> Tokens are: 
 ['Text', 'generation', ',', 'Cambridge', ':', 'Cambridge', 'University', 'Press', ',', '1985', '.']

>> Bigrams are: 
 [('Text', 'generation'), ('generation', ','), (',', 'Cambridge'), ('Cambridge', ':'), (':', 'Cambridge'), ('Cambridge', 'University'), ('University', 'Press'), ('Press', ','), (',', '1985'), ('1985', '.')]

>> Trigrams are: 
 [('Text', 'generation', ','), ('generation', ',', 'Cambridge'), (',', 'Cambridge', ':'), ('Cambridge', ':', 'Cambridge'), (':', 'Cambridge', 'University'), ('Cambridge', 'University', 'Press'), ('University', 'Press', ','), ('Press', ',', '1985'), (',', '1985', '.')]

>> POS Tags are: 
 [('Text', 'NNP'), ('generation', 'NN'), (',', ','), ('Cambridge', 'NNP'), (':', ':'), ('Cambridge', 'NNP'), ('University', 'NNP'), ('Press', 'NNP'), (',', ','), ('1985', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Text generation', 'Cambridge', 'Cambridge University Press']

>> Named Entities are: 
 [('GPE', 'Text'), ('PERSON', 'Cambridge'), ('PERSON', 'Cambridge University Press')] 

>> Stemming using Porter Stemmer: 
 [('Text', 'text'), ('generation', 'gener'), (',', ','), ('Cambridge', 'cambridg'), (':', ':'), ('Cambridge', 'cambridg'), ('University', 'univers'), ('Press', 'press'), (',', ','), ('1985', '1985'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Text', 'text'), ('generation', 'generat'), (',', ','), ('Cambridge', 'cambridg'), (':', ':'), ('Cambridge', 'cambridg'), ('University', 'univers'), ('Press', 'press'), (',', ','), ('1985', '1985'), ('.', '.')]

>> Lemmatization: 
 [('Text', 'Text'), ('generation', 'generation'), (',', ','), ('Cambridge', 'Cambridge'), (':', ':'), ('Cambridge', 'Cambridge'), ('University', 'University'), ('Press', 'Press'), (',', ','), ('1985', '1985'), ('.', '.')]



========================================== PARAGRAPH 632 ===========================================

[22] Small S.L., Cortell G.W., and Tanenhaus , M.K. Lexical Ambiguity Resolutions , San  

------------------- Sentence 1 -------------------

[22] Small S.L., Cortell G.W., and Tanenhaus , M.K.

>> Tokens are: 
 ['[', '22', ']', 'Small', 'S.L.', ',', 'Cortell', 'G.W.', ',', 'Tanenhaus', ',', 'M.K', '.']

>> Bigrams are: 
 [('[', '22'), ('22', ']'), (']', 'Small'), ('Small', 'S.L.'), ('S.L.', ','), (',', 'Cortell'), ('Cortell', 'G.W.'), ('G.W.', ','), (',', 'Tanenhaus'), ('Tanenhaus', ','), (',', 'M.K'), ('M.K', '.')]

>> Trigrams are: 
 [('[', '22', ']'), ('22', ']', 'Small'), (']', 'Small', 'S.L.'), ('Small', 'S.L.', ','), ('S.L.', ',', 'Cortell'), (',', 'Cortell', 'G.W.'), ('Cortell', 'G.W.', ','), ('G.W.', ',', 'Tanenhaus'), (',', 'Tanenhaus', ','), ('Tanenhaus', ',', 'M.K'), (',', 'M.K', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('22', 'CD'), (']', 'NNP'), ('Small', 'NNP'), ('S.L.', 'NNP'), (',', ','), ('Cortell', 'NNP'), ('G.W.', 'NNP'), (',', ','), ('Tanenhaus', 'NNP'), (',', ','), ('M.K', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['] Small S.L.', 'Cortell G.W.', 'Tanenhaus', 'M.K']

>> Named Entities are: 
 [('ORGANIZATION', 'Cortell'), ('PERSON', 'Tanenhaus')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('22', '22'), (']', ']'), ('Small', 'small'), ('S.L.', 's.l.'), (',', ','), ('Cortell', 'cortel'), ('G.W.', 'g.w.'), (',', ','), ('Tanenhaus', 'tanenhau'), (',', ','), ('M.K', 'm.k'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('22', '22'), (']', ']'), ('Small', 'small'), ('S.L.', 's.l.'), (',', ','), ('Cortell', 'cortel'), ('G.W.', 'g.w.'), (',', ','), ('Tanenhaus', 'tanenhaus'), (',', ','), ('M.K', 'm.k'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('22', '22'), (']', ']'), ('Small', 'Small'), ('S.L.', 'S.L.'), (',', ','), ('Cortell', 'Cortell'), ('G.W.', 'G.W.'), (',', ','), ('Tanenhaus', 'Tanenhaus'), (',', ','), ('M.K', 'M.K'), ('.', '.')]


------------------- Sentence 2 -------------------

Lexical Ambiguity Resolutions , San

>> Tokens are: 
 ['Lexical', 'Ambiguity', 'Resolutions', ',', 'San']

>> Bigrams are: 
 [('Lexical', 'Ambiguity'), ('Ambiguity', 'Resolutions'), ('Resolutions', ','), (',', 'San')]

>> Trigrams are: 
 [('Lexical', 'Ambiguity', 'Resolutions'), ('Ambiguity', 'Resolutions', ','), ('Resolutions', ',', 'San')]

>> POS Tags are: 
 [('Lexical', 'JJ'), ('Ambiguity', 'NNP'), ('Resolutions', 'NNP'), (',', ','), ('San', 'NNP')]

>> Noun Phrases are: 
 ['Lexical Ambiguity Resolutions', 'San']

>> Named Entities are: 
 [('PERSON', 'Lexical'), ('ORGANIZATION', 'Ambiguity Resolutions'), ('GPE', 'San')] 

>> Stemming using Porter Stemmer: 
 [('Lexical', 'lexic'), ('Ambiguity', 'ambigu'), ('Resolutions', 'resolut'), (',', ','), ('San', 'san')]

>> Stemming using Snowball Stemmer: 
 [('Lexical', 'lexic'), ('Ambiguity', 'ambigu'), ('Resolutions', 'resolut'), (',', ','), ('San', 'san')]

>> Lemmatization: 
 [('Lexical', 'Lexical'), ('Ambiguity', 'Ambiguity'), ('Resolutions', 'Resolutions'), (',', ','), ('San', 'San')]



========================================== PARAGRAPH 633 ===========================================

Mateo , CA : Morgan Kauffman, 1988.  

------------------- Sentence 1 -------------------

Mateo , CA : Morgan Kauffman, 1988.

>> Tokens are: 
 ['Mateo', ',', 'CA', ':', 'Morgan', 'Kauffman', ',', '1988', '.']

>> Bigrams are: 
 [('Mateo', ','), (',', 'CA'), ('CA', ':'), (':', 'Morgan'), ('Morgan', 'Kauffman'), ('Kauffman', ','), (',', '1988'), ('1988', '.')]

>> Trigrams are: 
 [('Mateo', ',', 'CA'), (',', 'CA', ':'), ('CA', ':', 'Morgan'), (':', 'Morgan', 'Kauffman'), ('Morgan', 'Kauffman', ','), ('Kauffman', ',', '1988'), (',', '1988', '.')]

>> POS Tags are: 
 [('Mateo', 'NNP'), (',', ','), ('CA', 'NNP'), (':', ':'), ('Morgan', 'NNP'), ('Kauffman', 'NNP'), (',', ','), ('1988', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Mateo', 'CA', 'Morgan Kauffman']

>> Named Entities are: 
 [('GPE', 'Mateo'), ('PERSON', 'Morgan Kauffman')] 

>> Stemming using Porter Stemmer: 
 [('Mateo', 'mateo'), (',', ','), ('CA', 'ca'), (':', ':'), ('Morgan', 'morgan'), ('Kauffman', 'kauffman'), (',', ','), ('1988', '1988'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Mateo', 'mateo'), (',', ','), ('CA', 'ca'), (':', ':'), ('Morgan', 'morgan'), ('Kauffman', 'kauffman'), (',', ','), ('1988', '1988'), ('.', '.')]

>> Lemmatization: 
 [('Mateo', 'Mateo'), (',', ','), ('CA', 'CA'), (':', ':'), ('Morgan', 'Morgan'), ('Kauffman', 'Kauffman'), (',', ','), ('1988', '1988'), ('.', '.')]



========================================== PARAGRAPH 634 ===========================================

[23] Manning, C. D., & Schütze, H. (1999). Foundations of statistical natural language  

------------------- Sentence 1 -------------------

[23] Manning, C. D., & Schütze, H. (1999).

>> Tokens are: 
 ['[', '23', ']', 'Manning', ',', 'C.', 'D.', ',', '&', 'Schütze', ',', 'H.', '(', '1999', ')', '.']

>> Bigrams are: 
 [('[', '23'), ('23', ']'), (']', 'Manning'), ('Manning', ','), (',', 'C.'), ('C.', 'D.'), ('D.', ','), (',', '&'), ('&', 'Schütze'), ('Schütze', ','), (',', 'H.'), ('H.', '('), ('(', '1999'), ('1999', ')'), (')', '.')]

>> Trigrams are: 
 [('[', '23', ']'), ('23', ']', 'Manning'), (']', 'Manning', ','), ('Manning', ',', 'C.'), (',', 'C.', 'D.'), ('C.', 'D.', ','), ('D.', ',', '&'), (',', '&', 'Schütze'), ('&', 'Schütze', ','), ('Schütze', ',', 'H.'), (',', 'H.', '('), ('H.', '(', '1999'), ('(', '1999', ')'), ('1999', ')', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('23', 'CD'), (']', 'JJ'), ('Manning', 'NNP'), (',', ','), ('C.', 'NNP'), ('D.', 'NNP'), (',', ','), ('&', 'CC'), ('Schütze', 'NNP'), (',', ','), ('H.', 'NNP'), ('(', '('), ('1999', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['] Manning', 'C. D.', 'Schütze', 'H.']

>> Named Entities are: 
 [('PERSON', 'Schütze')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('23', '23'), (']', ']'), ('Manning', 'man'), (',', ','), ('C.', 'c.'), ('D.', 'd.'), (',', ','), ('&', '&'), ('Schütze', 'schütze'), (',', ','), ('H.', 'h.'), ('(', '('), ('1999', '1999'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('23', '23'), (']', ']'), ('Manning', 'man'), (',', ','), ('C.', 'c.'), ('D.', 'd.'), (',', ','), ('&', '&'), ('Schütze', 'schütze'), (',', ','), ('H.', 'h.'), ('(', '('), ('1999', '1999'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('23', '23'), (']', ']'), ('Manning', 'Manning'), (',', ','), ('C.', 'C.'), ('D.', 'D.'), (',', ','), ('&', '&'), ('Schütze', 'Schütze'), (',', ','), ('H.', 'H.'), ('(', '('), ('1999', '1999'), (')', ')'), ('.', '.')]


------------------- Sentence 2 -------------------

Foundations of statistical natural language

>> Tokens are: 
 ['Foundations', 'statistical', 'natural', 'language']

>> Bigrams are: 
 [('Foundations', 'statistical'), ('statistical', 'natural'), ('natural', 'language')]

>> Trigrams are: 
 [('Foundations', 'statistical', 'natural'), ('statistical', 'natural', 'language')]

>> POS Tags are: 
 [('Foundations', 'NNS'), ('statistical', 'JJ'), ('natural', 'JJ'), ('language', 'NN')]

>> Noun Phrases are: 
 ['Foundations', 'statistical natural language']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Foundations', 'foundat'), ('statistical', 'statist'), ('natural', 'natur'), ('language', 'languag')]

>> Stemming using Snowball Stemmer: 
 [('Foundations', 'foundat'), ('statistical', 'statist'), ('natural', 'natur'), ('language', 'languag')]

>> Lemmatization: 
 [('Foundations', 'Foundations'), ('statistical', 'statistical'), ('natural', 'natural'), ('language', 'language')]



========================================== PARAGRAPH 635 ===========================================

processing (Vol. 999). Cambridge: MIT press.  

------------------- Sentence 1 -------------------

processing (Vol.

>> Tokens are: 
 ['processing', '(', 'Vol', '.']

>> Bigrams are: 
 [('processing', '('), ('(', 'Vol'), ('Vol', '.')]

>> Trigrams are: 
 [('processing', '(', 'Vol'), ('(', 'Vol', '.')]

>> POS Tags are: 
 [('processing', 'NN'), ('(', '('), ('Vol', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['processing', 'Vol']

>> Named Entities are: 
 [('ORGANIZATION', 'Vol')] 

>> Stemming using Porter Stemmer: 
 [('processing', 'process'), ('(', '('), ('Vol', 'vol'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('processing', 'process'), ('(', '('), ('Vol', 'vol'), ('.', '.')]

>> Lemmatization: 
 [('processing', 'processing'), ('(', '('), ('Vol', 'Vol'), ('.', '.')]


------------------- Sentence 2 -------------------

999).

>> Tokens are: 
 ['999', ')', '.']

>> Bigrams are: 
 [('999', ')'), (')', '.')]

>> Trigrams are: 
 [('999', ')', '.')]

>> POS Tags are: 
 [('999', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('999', '999'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('999', '999'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('999', '999'), (')', ')'), ('.', '.')]


------------------- Sentence 3 -------------------

Cambridge: MIT press.

>> Tokens are: 
 ['Cambridge', ':', 'MIT', 'press', '.']

>> Bigrams are: 
 [('Cambridge', ':'), (':', 'MIT'), ('MIT', 'press'), ('press', '.')]

>> Trigrams are: 
 [('Cambridge', ':', 'MIT'), (':', 'MIT', 'press'), ('MIT', 'press', '.')]

>> POS Tags are: 
 [('Cambridge', 'NN'), (':', ':'), ('MIT', 'NNP'), ('press', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Cambridge', 'MIT press']

>> Named Entities are: 
 [('GPE', 'Cambridge'), ('ORGANIZATION', 'MIT')] 

>> Stemming using Porter Stemmer: 
 [('Cambridge', 'cambridg'), (':', ':'), ('MIT', 'mit'), ('press', 'press'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Cambridge', 'cambridg'), (':', ':'), ('MIT', 'mit'), ('press', 'press'), ('.', '.')]

>> Lemmatization: 
 [('Cambridge', 'Cambridge'), (':', ':'), ('MIT', 'MIT'), ('press', 'press'), ('.', '.')]



========================================== PARAGRAPH 636 ===========================================

[24] Mani, I., & Maybury, M. T. (Eds.). (1999). Advances in automatic text  

------------------- Sentence 1 -------------------

[24] Mani, I., & Maybury, M. T.

>> Tokens are: 
 ['[', '24', ']', 'Mani', ',', 'I.', ',', '&', 'Maybury', ',', 'M.', 'T', '.']

>> Bigrams are: 
 [('[', '24'), ('24', ']'), (']', 'Mani'), ('Mani', ','), (',', 'I.'), ('I.', ','), (',', '&'), ('&', 'Maybury'), ('Maybury', ','), (',', 'M.'), ('M.', 'T'), ('T', '.')]

>> Trigrams are: 
 [('[', '24', ']'), ('24', ']', 'Mani'), (']', 'Mani', ','), ('Mani', ',', 'I.'), (',', 'I.', ','), ('I.', ',', '&'), (',', '&', 'Maybury'), ('&', 'Maybury', ','), ('Maybury', ',', 'M.'), (',', 'M.', 'T'), ('M.', 'T', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('24', 'CD'), (']', 'JJ'), ('Mani', 'NNP'), (',', ','), ('I.', 'NNP'), (',', ','), ('&', 'CC'), ('Maybury', 'NNP'), (',', ','), ('M.', 'NNP'), ('T', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['] Mani', 'I.', 'Maybury', 'M. T']

>> Named Entities are: 
 [('PERSON', 'Maybury')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('24', '24'), (']', ']'), ('Mani', 'mani'), (',', ','), ('I.', 'i.'), (',', ','), ('&', '&'), ('Maybury', 'mayburi'), (',', ','), ('M.', 'm.'), ('T', 't'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('24', '24'), (']', ']'), ('Mani', 'mani'), (',', ','), ('I.', 'i.'), (',', ','), ('&', '&'), ('Maybury', 'mayburi'), (',', ','), ('M.', 'm.'), ('T', 't'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('24', '24'), (']', ']'), ('Mani', 'Mani'), (',', ','), ('I.', 'I.'), (',', ','), ('&', '&'), ('Maybury', 'Maybury'), (',', ','), ('M.', 'M.'), ('T', 'T'), ('.', '.')]


------------------- Sentence 2 -------------------

(Eds.).

>> Tokens are: 
 ['(', 'Eds', '.', ')', '.']

>> Bigrams are: 
 [('(', 'Eds'), ('Eds', '.'), ('.', ')'), (')', '.')]

>> Trigrams are: 
 [('(', 'Eds', '.'), ('Eds', '.', ')'), ('.', ')', '.')]

>> POS Tags are: 
 [('(', '('), ('Eds', 'NNP'), ('.', '.'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['Eds']

>> Named Entities are: 
 [('ORGANIZATION', 'Eds')] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('Eds', 'ed'), ('.', '.'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('Eds', 'ed'), ('.', '.'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('(', '('), ('Eds', 'Eds'), ('.', '.'), (')', ')'), ('.', '.')]


------------------- Sentence 3 -------------------

(1999).

>> Tokens are: 
 ['(', '1999', ')', '.']

>> Bigrams are: 
 [('(', '1999'), ('1999', ')'), (')', '.')]

>> Trigrams are: 
 [('(', '1999', ')'), ('1999', ')', '.')]

>> POS Tags are: 
 [('(', '('), ('1999', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('1999', '1999'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('1999', '1999'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('(', '('), ('1999', '1999'), (')', ')'), ('.', '.')]


------------------- Sentence 4 -------------------

Advances in automatic text

>> Tokens are: 
 ['Advances', 'automatic', 'text']

>> Bigrams are: 
 [('Advances', 'automatic'), ('automatic', 'text')]

>> Trigrams are: 
 [('Advances', 'automatic', 'text')]

>> POS Tags are: 
 [('Advances', 'NNS'), ('automatic', 'JJ'), ('text', 'NN')]

>> Noun Phrases are: 
 ['Advances', 'automatic text']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Advances', 'advanc'), ('automatic', 'automat'), ('text', 'text')]

>> Stemming using Snowball Stemmer: 
 [('Advances', 'advanc'), ('automatic', 'automat'), ('text', 'text')]

>> Lemmatization: 
 [('Advances', 'Advances'), ('automatic', 'automatic'), ('text', 'text')]



========================================== PARAGRAPH 637 ===========================================

summarization (Vol. 293). Cambridge, MA: MIT press.  

------------------- Sentence 1 -------------------

summarization (Vol.

>> Tokens are: 
 ['summarization', '(', 'Vol', '.']

>> Bigrams are: 
 [('summarization', '('), ('(', 'Vol'), ('Vol', '.')]

>> Trigrams are: 
 [('summarization', '(', 'Vol'), ('(', 'Vol', '.')]

>> POS Tags are: 
 [('summarization', 'NN'), ('(', '('), ('Vol', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['summarization', 'Vol']

>> Named Entities are: 
 [('ORGANIZATION', 'Vol')] 

>> Stemming using Porter Stemmer: 
 [('summarization', 'summar'), ('(', '('), ('Vol', 'vol'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('summarization', 'summar'), ('(', '('), ('Vol', 'vol'), ('.', '.')]

>> Lemmatization: 
 [('summarization', 'summarization'), ('(', '('), ('Vol', 'Vol'), ('.', '.')]


------------------- Sentence 2 -------------------

293).

>> Tokens are: 
 ['293', ')', '.']

>> Bigrams are: 
 [('293', ')'), (')', '.')]

>> Trigrams are: 
 [('293', ')', '.')]

>> POS Tags are: 
 [('293', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('293', '293'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('293', '293'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('293', '293'), (')', ')'), ('.', '.')]


------------------- Sentence 3 -------------------

Cambridge, MA: MIT press.

>> Tokens are: 
 ['Cambridge', ',', 'MA', ':', 'MIT', 'press', '.']

>> Bigrams are: 
 [('Cambridge', ','), (',', 'MA'), ('MA', ':'), (':', 'MIT'), ('MIT', 'press'), ('press', '.')]

>> Trigrams are: 
 [('Cambridge', ',', 'MA'), (',', 'MA', ':'), ('MA', ':', 'MIT'), (':', 'MIT', 'press'), ('MIT', 'press', '.')]

>> POS Tags are: 
 [('Cambridge', 'NNP'), (',', ','), ('MA', 'NNP'), (':', ':'), ('MIT', 'NNP'), ('press', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Cambridge', 'MA', 'MIT press']

>> Named Entities are: 
 [('GPE', 'Cambridge'), ('ORGANIZATION', 'MIT')] 

>> Stemming using Porter Stemmer: 
 [('Cambridge', 'cambridg'), (',', ','), ('MA', 'ma'), (':', ':'), ('MIT', 'mit'), ('press', 'press'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Cambridge', 'cambridg'), (',', ','), ('MA', 'ma'), (':', ':'), ('MIT', 'mit'), ('press', 'press'), ('.', '.')]

>> Lemmatization: 
 [('Cambridge', 'Cambridge'), (',', ','), ('MA', 'MA'), (':', ':'), ('MIT', 'MIT'), ('press', 'press'), ('.', '.')]



========================================== PARAGRAPH 638 ===========================================

[25] Yi, J., Nasukawa, T., Bunescu, R., & Niblack, W. (2003, November). Sentiment  

------------------- Sentence 1 -------------------

[25] Yi, J., Nasukawa, T., Bunescu, R., & Niblack, W. (2003, November).

>> Tokens are: 
 ['[', '25', ']', 'Yi', ',', 'J.', ',', 'Nasukawa', ',', 'T.', ',', 'Bunescu', ',', 'R.', ',', '&', 'Niblack', ',', 'W.', '(', '2003', ',', 'November', ')', '.']

>> Bigrams are: 
 [('[', '25'), ('25', ']'), (']', 'Yi'), ('Yi', ','), (',', 'J.'), ('J.', ','), (',', 'Nasukawa'), ('Nasukawa', ','), (',', 'T.'), ('T.', ','), (',', 'Bunescu'), ('Bunescu', ','), (',', 'R.'), ('R.', ','), (',', '&'), ('&', 'Niblack'), ('Niblack', ','), (',', 'W.'), ('W.', '('), ('(', '2003'), ('2003', ','), (',', 'November'), ('November', ')'), (')', '.')]

>> Trigrams are: 
 [('[', '25', ']'), ('25', ']', 'Yi'), (']', 'Yi', ','), ('Yi', ',', 'J.'), (',', 'J.', ','), ('J.', ',', 'Nasukawa'), (',', 'Nasukawa', ','), ('Nasukawa', ',', 'T.'), (',', 'T.', ','), ('T.', ',', 'Bunescu'), (',', 'Bunescu', ','), ('Bunescu', ',', 'R.'), (',', 'R.', ','), ('R.', ',', '&'), (',', '&', 'Niblack'), ('&', 'Niblack', ','), ('Niblack', ',', 'W.'), (',', 'W.', '('), ('W.', '(', '2003'), ('(', '2003', ','), ('2003', ',', 'November'), (',', 'November', ')'), ('November', ')', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('25', 'CD'), (']', 'JJ'), ('Yi', 'NNP'), (',', ','), ('J.', 'NNP'), (',', ','), ('Nasukawa', 'NNP'), (',', ','), ('T.', 'NNP'), (',', ','), ('Bunescu', 'NNP'), (',', ','), ('R.', 'NNP'), (',', ','), ('&', 'CC'), ('Niblack', 'NNP'), (',', ','), ('W.', 'NNP'), ('(', '('), ('2003', 'CD'), (',', ','), ('November', 'NNP'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['] Yi', 'J.', 'Nasukawa', 'T.', 'Bunescu', 'R.', 'Niblack', 'W.', 'November']

>> Named Entities are: 
 [('GPE', 'Nasukawa'), ('PERSON', 'Bunescu'), ('PERSON', 'Niblack')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('25', '25'), (']', ']'), ('Yi', 'yi'), (',', ','), ('J.', 'j.'), (',', ','), ('Nasukawa', 'nasukawa'), (',', ','), ('T.', 't.'), (',', ','), ('Bunescu', 'bunescu'), (',', ','), ('R.', 'r.'), (',', ','), ('&', '&'), ('Niblack', 'niblack'), (',', ','), ('W.', 'w.'), ('(', '('), ('2003', '2003'), (',', ','), ('November', 'novemb'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('25', '25'), (']', ']'), ('Yi', 'yi'), (',', ','), ('J.', 'j.'), (',', ','), ('Nasukawa', 'nasukawa'), (',', ','), ('T.', 't.'), (',', ','), ('Bunescu', 'bunescu'), (',', ','), ('R.', 'r.'), (',', ','), ('&', '&'), ('Niblack', 'niblack'), (',', ','), ('W.', 'w.'), ('(', '('), ('2003', '2003'), (',', ','), ('November', 'novemb'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('25', '25'), (']', ']'), ('Yi', 'Yi'), (',', ','), ('J.', 'J.'), (',', ','), ('Nasukawa', 'Nasukawa'), (',', ','), ('T.', 'T.'), (',', ','), ('Bunescu', 'Bunescu'), (',', ','), ('R.', 'R.'), (',', ','), ('&', '&'), ('Niblack', 'Niblack'), (',', ','), ('W.', 'W.'), ('(', '('), ('2003', '2003'), (',', ','), ('November', 'November'), (')', ')'), ('.', '.')]


------------------- Sentence 2 -------------------

Sentiment

>> Tokens are: 
 ['Sentiment']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Sentiment', 'NN')]

>> Noun Phrases are: 
 ['Sentiment']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Sentiment', 'sentiment')]

>> Stemming using Snowball Stemmer: 
 [('Sentiment', 'sentiment')]

>> Lemmatization: 
 [('Sentiment', 'Sentiment')]



========================================== PARAGRAPH 639 ===========================================

analyzer: Extracting sentiments about a given topic using natural language processing  

------------------- Sentence 1 -------------------

analyzer: Extracting sentiments about a given topic using natural language processing

>> Tokens are: 
 ['analyzer', ':', 'Extracting', 'sentiments', 'given', 'topic', 'using', 'natural', 'language', 'processing']

>> Bigrams are: 
 [('analyzer', ':'), (':', 'Extracting'), ('Extracting', 'sentiments'), ('sentiments', 'given'), ('given', 'topic'), ('topic', 'using'), ('using', 'natural'), ('natural', 'language'), ('language', 'processing')]

>> Trigrams are: 
 [('analyzer', ':', 'Extracting'), (':', 'Extracting', 'sentiments'), ('Extracting', 'sentiments', 'given'), ('sentiments', 'given', 'topic'), ('given', 'topic', 'using'), ('topic', 'using', 'natural'), ('using', 'natural', 'language'), ('natural', 'language', 'processing')]

>> POS Tags are: 
 [('analyzer', 'NN'), (':', ':'), ('Extracting', 'JJ'), ('sentiments', 'NNS'), ('given', 'VBN'), ('topic', 'RP'), ('using', 'VBG'), ('natural', 'JJ'), ('language', 'NN'), ('processing', 'NN')]

>> Noun Phrases are: 
 ['analyzer', 'Extracting sentiments', 'natural language processing']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('analyzer', 'analyz'), (':', ':'), ('Extracting', 'extract'), ('sentiments', 'sentiment'), ('given', 'given'), ('topic', 'topic'), ('using', 'use'), ('natural', 'natur'), ('language', 'languag'), ('processing', 'process')]

>> Stemming using Snowball Stemmer: 
 [('analyzer', 'analyz'), (':', ':'), ('Extracting', 'extract'), ('sentiments', 'sentiment'), ('given', 'given'), ('topic', 'topic'), ('using', 'use'), ('natural', 'natur'), ('language', 'languag'), ('processing', 'process')]

>> Lemmatization: 
 [('analyzer', 'analyzer'), (':', ':'), ('Extracting', 'Extracting'), ('sentiments', 'sentiment'), ('given', 'given'), ('topic', 'topic'), ('using', 'using'), ('natural', 'natural'), ('language', 'language'), ('processing', 'processing')]



========================================== PARAGRAPH 640 ===========================================

techniques. In Data Mining, 2003. ICDM 2003. Third IEEE International Conference on (pp.  

------------------- Sentence 1 -------------------

techniques.

>> Tokens are: 
 ['techniques', '.']

>> Bigrams are: 
 [('techniques', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('techniques', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['techniques']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('techniques', 'techniqu'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('techniques', 'techniqu'), ('.', '.')]

>> Lemmatization: 
 [('techniques', 'technique'), ('.', '.')]


------------------- Sentence 2 -------------------

In Data Mining, 2003.

>> Tokens are: 
 ['In', 'Data', 'Mining', ',', '2003', '.']

>> Bigrams are: 
 [('In', 'Data'), ('Data', 'Mining'), ('Mining', ','), (',', '2003'), ('2003', '.')]

>> Trigrams are: 
 [('In', 'Data', 'Mining'), ('Data', 'Mining', ','), ('Mining', ',', '2003'), (',', '2003', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('Data', 'NNP'), ('Mining', 'NNP'), (',', ','), ('2003', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Data Mining']

>> Named Entities are: 
 [('GPE', 'Data')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('Data', 'data'), ('Mining', 'mine'), (',', ','), ('2003', '2003'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('Data', 'data'), ('Mining', 'mine'), (',', ','), ('2003', '2003'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('Data', 'Data'), ('Mining', 'Mining'), (',', ','), ('2003', '2003'), ('.', '.')]


------------------- Sentence 3 -------------------

ICDM 2003.

>> Tokens are: 
 ['ICDM', '2003', '.']

>> Bigrams are: 
 [('ICDM', '2003'), ('2003', '.')]

>> Trigrams are: 
 [('ICDM', '2003', '.')]

>> POS Tags are: 
 [('ICDM', 'JJ'), ('2003', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('ICDM', 'icdm'), ('2003', '2003'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('ICDM', 'icdm'), ('2003', '2003'), ('.', '.')]

>> Lemmatization: 
 [('ICDM', 'ICDM'), ('2003', '2003'), ('.', '.')]


------------------- Sentence 4 -------------------

Third IEEE International Conference on (pp.

>> Tokens are: 
 ['Third', 'IEEE', 'International', 'Conference', '(', 'pp', '.']

>> Bigrams are: 
 [('Third', 'IEEE'), ('IEEE', 'International'), ('International', 'Conference'), ('Conference', '('), ('(', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('Third', 'IEEE', 'International'), ('IEEE', 'International', 'Conference'), ('International', 'Conference', '('), ('Conference', '(', 'pp'), ('(', 'pp', '.')]

>> POS Tags are: 
 [('Third', 'NNP'), ('IEEE', 'NNP'), ('International', 'NNP'), ('Conference', 'NNP'), ('(', '('), ('pp', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Third IEEE International Conference', 'pp']

>> Named Entities are: 
 [('PERSON', 'Third'), ('ORGANIZATION', 'IEEE International Conference')] 

>> Stemming using Porter Stemmer: 
 [('Third', 'third'), ('IEEE', 'ieee'), ('International', 'intern'), ('Conference', 'confer'), ('(', '('), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Third', 'third'), ('IEEE', 'ieee'), ('International', 'intern'), ('Conference', 'confer'), ('(', '('), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('Third', 'Third'), ('IEEE', 'IEEE'), ('International', 'International'), ('Conference', 'Conference'), ('(', '('), ('pp', 'pp'), ('.', '.')]



========================================== PARAGRAPH 641 ===========================================

427-434). IEEE.  

------------------- Sentence 1 -------------------

427-434).

>> Tokens are: 
 ['427-434', ')', '.']

>> Bigrams are: 
 [('427-434', ')'), (')', '.')]

>> Trigrams are: 
 [('427-434', ')', '.')]

>> POS Tags are: 
 [('427-434', 'JJ'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('427-434', '427-434'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('427-434', '427-434'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('427-434', '427-434'), (')', ')'), ('.', '.')]


------------------- Sentence 2 -------------------

IEEE.

>> Tokens are: 
 ['IEEE', '.']

>> Bigrams are: 
 [('IEEE', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('IEEE', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['IEEE']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('IEEE', 'ieee'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('IEEE', 'ieee'), ('.', '.')]

>> Lemmatization: 
 [('IEEE', 'IEEE'), ('.', '.')]



========================================== PARAGRAPH 642 ===========================================

[26] Yi, J., Nasukawa, T., Bunescu, R., & Niblack, W. (2003, November). Sentiment  

------------------- Sentence 1 -------------------

[26] Yi, J., Nasukawa, T., Bunescu, R., & Niblack, W. (2003, November).

>> Tokens are: 
 ['[', '26', ']', 'Yi', ',', 'J.', ',', 'Nasukawa', ',', 'T.', ',', 'Bunescu', ',', 'R.', ',', '&', 'Niblack', ',', 'W.', '(', '2003', ',', 'November', ')', '.']

>> Bigrams are: 
 [('[', '26'), ('26', ']'), (']', 'Yi'), ('Yi', ','), (',', 'J.'), ('J.', ','), (',', 'Nasukawa'), ('Nasukawa', ','), (',', 'T.'), ('T.', ','), (',', 'Bunescu'), ('Bunescu', ','), (',', 'R.'), ('R.', ','), (',', '&'), ('&', 'Niblack'), ('Niblack', ','), (',', 'W.'), ('W.', '('), ('(', '2003'), ('2003', ','), (',', 'November'), ('November', ')'), (')', '.')]

>> Trigrams are: 
 [('[', '26', ']'), ('26', ']', 'Yi'), (']', 'Yi', ','), ('Yi', ',', 'J.'), (',', 'J.', ','), ('J.', ',', 'Nasukawa'), (',', 'Nasukawa', ','), ('Nasukawa', ',', 'T.'), (',', 'T.', ','), ('T.', ',', 'Bunescu'), (',', 'Bunescu', ','), ('Bunescu', ',', 'R.'), (',', 'R.', ','), ('R.', ',', '&'), (',', '&', 'Niblack'), ('&', 'Niblack', ','), ('Niblack', ',', 'W.'), (',', 'W.', '('), ('W.', '(', '2003'), ('(', '2003', ','), ('2003', ',', 'November'), (',', 'November', ')'), ('November', ')', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('26', 'CD'), (']', 'JJ'), ('Yi', 'NNP'), (',', ','), ('J.', 'NNP'), (',', ','), ('Nasukawa', 'NNP'), (',', ','), ('T.', 'NNP'), (',', ','), ('Bunescu', 'NNP'), (',', ','), ('R.', 'NNP'), (',', ','), ('&', 'CC'), ('Niblack', 'NNP'), (',', ','), ('W.', 'NNP'), ('(', '('), ('2003', 'CD'), (',', ','), ('November', 'NNP'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['] Yi', 'J.', 'Nasukawa', 'T.', 'Bunescu', 'R.', 'Niblack', 'W.', 'November']

>> Named Entities are: 
 [('GPE', 'Nasukawa'), ('PERSON', 'Bunescu'), ('PERSON', 'Niblack')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('26', '26'), (']', ']'), ('Yi', 'yi'), (',', ','), ('J.', 'j.'), (',', ','), ('Nasukawa', 'nasukawa'), (',', ','), ('T.', 't.'), (',', ','), ('Bunescu', 'bunescu'), (',', ','), ('R.', 'r.'), (',', ','), ('&', '&'), ('Niblack', 'niblack'), (',', ','), ('W.', 'w.'), ('(', '('), ('2003', '2003'), (',', ','), ('November', 'novemb'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('26', '26'), (']', ']'), ('Yi', 'yi'), (',', ','), ('J.', 'j.'), (',', ','), ('Nasukawa', 'nasukawa'), (',', ','), ('T.', 't.'), (',', ','), ('Bunescu', 'bunescu'), (',', ','), ('R.', 'r.'), (',', ','), ('&', '&'), ('Niblack', 'niblack'), (',', ','), ('W.', 'w.'), ('(', '('), ('2003', '2003'), (',', ','), ('November', 'novemb'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('26', '26'), (']', ']'), ('Yi', 'Yi'), (',', ','), ('J.', 'J.'), (',', ','), ('Nasukawa', 'Nasukawa'), (',', ','), ('T.', 'T.'), (',', ','), ('Bunescu', 'Bunescu'), (',', ','), ('R.', 'R.'), (',', ','), ('&', '&'), ('Niblack', 'Niblack'), (',', ','), ('W.', 'W.'), ('(', '('), ('2003', '2003'), (',', ','), ('November', 'November'), (')', ')'), ('.', '.')]


------------------- Sentence 2 -------------------

Sentiment

>> Tokens are: 
 ['Sentiment']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Sentiment', 'NN')]

>> Noun Phrases are: 
 ['Sentiment']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Sentiment', 'sentiment')]

>> Stemming using Snowball Stemmer: 
 [('Sentiment', 'sentiment')]

>> Lemmatization: 
 [('Sentiment', 'Sentiment')]



========================================== PARAGRAPH 643 ===========================================

analyzer: Extracting sentiments about a given topic using natural language processing  

------------------- Sentence 1 -------------------

analyzer: Extracting sentiments about a given topic using natural language processing

>> Tokens are: 
 ['analyzer', ':', 'Extracting', 'sentiments', 'given', 'topic', 'using', 'natural', 'language', 'processing']

>> Bigrams are: 
 [('analyzer', ':'), (':', 'Extracting'), ('Extracting', 'sentiments'), ('sentiments', 'given'), ('given', 'topic'), ('topic', 'using'), ('using', 'natural'), ('natural', 'language'), ('language', 'processing')]

>> Trigrams are: 
 [('analyzer', ':', 'Extracting'), (':', 'Extracting', 'sentiments'), ('Extracting', 'sentiments', 'given'), ('sentiments', 'given', 'topic'), ('given', 'topic', 'using'), ('topic', 'using', 'natural'), ('using', 'natural', 'language'), ('natural', 'language', 'processing')]

>> POS Tags are: 
 [('analyzer', 'NN'), (':', ':'), ('Extracting', 'JJ'), ('sentiments', 'NNS'), ('given', 'VBN'), ('topic', 'RP'), ('using', 'VBG'), ('natural', 'JJ'), ('language', 'NN'), ('processing', 'NN')]

>> Noun Phrases are: 
 ['analyzer', 'Extracting sentiments', 'natural language processing']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('analyzer', 'analyz'), (':', ':'), ('Extracting', 'extract'), ('sentiments', 'sentiment'), ('given', 'given'), ('topic', 'topic'), ('using', 'use'), ('natural', 'natur'), ('language', 'languag'), ('processing', 'process')]

>> Stemming using Snowball Stemmer: 
 [('analyzer', 'analyz'), (':', ':'), ('Extracting', 'extract'), ('sentiments', 'sentiment'), ('given', 'given'), ('topic', 'topic'), ('using', 'use'), ('natural', 'natur'), ('language', 'languag'), ('processing', 'process')]

>> Lemmatization: 
 [('analyzer', 'analyzer'), (':', ':'), ('Extracting', 'Extracting'), ('sentiments', 'sentiment'), ('given', 'given'), ('topic', 'topic'), ('using', 'using'), ('natural', 'natural'), ('language', 'language'), ('processing', 'processing')]



========================================== PARAGRAPH 644 ===========================================

techniques. In Data Mining, 2003. ICDM 2003. Third IEEE International Conference on (pp.  

------------------- Sentence 1 -------------------

techniques.

>> Tokens are: 
 ['techniques', '.']

>> Bigrams are: 
 [('techniques', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('techniques', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['techniques']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('techniques', 'techniqu'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('techniques', 'techniqu'), ('.', '.')]

>> Lemmatization: 
 [('techniques', 'technique'), ('.', '.')]


------------------- Sentence 2 -------------------

In Data Mining, 2003.

>> Tokens are: 
 ['In', 'Data', 'Mining', ',', '2003', '.']

>> Bigrams are: 
 [('In', 'Data'), ('Data', 'Mining'), ('Mining', ','), (',', '2003'), ('2003', '.')]

>> Trigrams are: 
 [('In', 'Data', 'Mining'), ('Data', 'Mining', ','), ('Mining', ',', '2003'), (',', '2003', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('Data', 'NNP'), ('Mining', 'NNP'), (',', ','), ('2003', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Data Mining']

>> Named Entities are: 
 [('GPE', 'Data')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('Data', 'data'), ('Mining', 'mine'), (',', ','), ('2003', '2003'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('Data', 'data'), ('Mining', 'mine'), (',', ','), ('2003', '2003'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('Data', 'Data'), ('Mining', 'Mining'), (',', ','), ('2003', '2003'), ('.', '.')]


------------------- Sentence 3 -------------------

ICDM 2003.

>> Tokens are: 
 ['ICDM', '2003', '.']

>> Bigrams are: 
 [('ICDM', '2003'), ('2003', '.')]

>> Trigrams are: 
 [('ICDM', '2003', '.')]

>> POS Tags are: 
 [('ICDM', 'JJ'), ('2003', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('ICDM', 'icdm'), ('2003', '2003'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('ICDM', 'icdm'), ('2003', '2003'), ('.', '.')]

>> Lemmatization: 
 [('ICDM', 'ICDM'), ('2003', '2003'), ('.', '.')]


------------------- Sentence 4 -------------------

Third IEEE International Conference on (pp.

>> Tokens are: 
 ['Third', 'IEEE', 'International', 'Conference', '(', 'pp', '.']

>> Bigrams are: 
 [('Third', 'IEEE'), ('IEEE', 'International'), ('International', 'Conference'), ('Conference', '('), ('(', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('Third', 'IEEE', 'International'), ('IEEE', 'International', 'Conference'), ('International', 'Conference', '('), ('Conference', '(', 'pp'), ('(', 'pp', '.')]

>> POS Tags are: 
 [('Third', 'NNP'), ('IEEE', 'NNP'), ('International', 'NNP'), ('Conference', 'NNP'), ('(', '('), ('pp', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Third IEEE International Conference', 'pp']

>> Named Entities are: 
 [('PERSON', 'Third'), ('ORGANIZATION', 'IEEE International Conference')] 

>> Stemming using Porter Stemmer: 
 [('Third', 'third'), ('IEEE', 'ieee'), ('International', 'intern'), ('Conference', 'confer'), ('(', '('), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Third', 'third'), ('IEEE', 'ieee'), ('International', 'intern'), ('Conference', 'confer'), ('(', '('), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('Third', 'Third'), ('IEEE', 'IEEE'), ('International', 'International'), ('Conference', 'Conference'), ('(', '('), ('pp', 'pp'), ('.', '.')]



========================================== PARAGRAPH 645 ===========================================

427-434). IEEE.  

------------------- Sentence 1 -------------------

427-434).

>> Tokens are: 
 ['427-434', ')', '.']

>> Bigrams are: 
 [('427-434', ')'), (')', '.')]

>> Trigrams are: 
 [('427-434', ')', '.')]

>> POS Tags are: 
 [('427-434', 'JJ'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('427-434', '427-434'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('427-434', '427-434'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('427-434', '427-434'), (')', ')'), ('.', '.')]


------------------- Sentence 2 -------------------

IEEE.

>> Tokens are: 
 ['IEEE', '.']

>> Bigrams are: 
 [('IEEE', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('IEEE', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['IEEE']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('IEEE', 'ieee'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('IEEE', 'ieee'), ('.', '.')]

>> Lemmatization: 
 [('IEEE', 'IEEE'), ('.', '.')]



========================================== PARAGRAPH 646 ===========================================

[27] Tapaswi, N., & Jain, S. (2012, September). Treebank based deep grammar acquisition  

------------------- Sentence 1 -------------------

[27] Tapaswi, N., & Jain, S. (2012, September).

>> Tokens are: 
 ['[', '27', ']', 'Tapaswi', ',', 'N.', ',', '&', 'Jain', ',', 'S.', '(', '2012', ',', 'September', ')', '.']

>> Bigrams are: 
 [('[', '27'), ('27', ']'), (']', 'Tapaswi'), ('Tapaswi', ','), (',', 'N.'), ('N.', ','), (',', '&'), ('&', 'Jain'), ('Jain', ','), (',', 'S.'), ('S.', '('), ('(', '2012'), ('2012', ','), (',', 'September'), ('September', ')'), (')', '.')]

>> Trigrams are: 
 [('[', '27', ']'), ('27', ']', 'Tapaswi'), (']', 'Tapaswi', ','), ('Tapaswi', ',', 'N.'), (',', 'N.', ','), ('N.', ',', '&'), (',', '&', 'Jain'), ('&', 'Jain', ','), ('Jain', ',', 'S.'), (',', 'S.', '('), ('S.', '(', '2012'), ('(', '2012', ','), ('2012', ',', 'September'), (',', 'September', ')'), ('September', ')', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('27', 'CD'), (']', 'JJ'), ('Tapaswi', 'NNP'), (',', ','), ('N.', 'NNP'), (',', ','), ('&', 'CC'), ('Jain', 'NNP'), (',', ','), ('S.', 'NNP'), ('(', '('), ('2012', 'CD'), (',', ','), ('September', 'NNP'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['] Tapaswi', 'N.', 'Jain', 'S.', 'September']

>> Named Entities are: 
 [('GPE', 'Jain')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('27', '27'), (']', ']'), ('Tapaswi', 'tapaswi'), (',', ','), ('N.', 'n.'), (',', ','), ('&', '&'), ('Jain', 'jain'), (',', ','), ('S.', 's.'), ('(', '('), ('2012', '2012'), (',', ','), ('September', 'septemb'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('27', '27'), (']', ']'), ('Tapaswi', 'tapaswi'), (',', ','), ('N.', 'n.'), (',', ','), ('&', '&'), ('Jain', 'jain'), (',', ','), ('S.', 's.'), ('(', '('), ('2012', '2012'), (',', ','), ('September', 'septemb'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('27', '27'), (']', ']'), ('Tapaswi', 'Tapaswi'), (',', ','), ('N.', 'N.'), (',', ','), ('&', '&'), ('Jain', 'Jain'), (',', ','), ('S.', 'S.'), ('(', '('), ('2012', '2012'), (',', ','), ('September', 'September'), (')', ')'), ('.', '.')]


------------------- Sentence 2 -------------------

Treebank based deep grammar acquisition

>> Tokens are: 
 ['Treebank', 'based', 'deep', 'grammar', 'acquisition']

>> Bigrams are: 
 [('Treebank', 'based'), ('based', 'deep'), ('deep', 'grammar'), ('grammar', 'acquisition')]

>> Trigrams are: 
 [('Treebank', 'based', 'deep'), ('based', 'deep', 'grammar'), ('deep', 'grammar', 'acquisition')]

>> POS Tags are: 
 [('Treebank', 'NNP'), ('based', 'VBN'), ('deep', 'JJ'), ('grammar', 'NN'), ('acquisition', 'NN')]

>> Noun Phrases are: 
 ['Treebank', 'deep grammar acquisition']

>> Named Entities are: 
 [('GPE', 'Treebank')] 

>> Stemming using Porter Stemmer: 
 [('Treebank', 'treebank'), ('based', 'base'), ('deep', 'deep'), ('grammar', 'grammar'), ('acquisition', 'acquisit')]

>> Stemming using Snowball Stemmer: 
 [('Treebank', 'treebank'), ('based', 'base'), ('deep', 'deep'), ('grammar', 'grammar'), ('acquisition', 'acquisit')]

>> Lemmatization: 
 [('Treebank', 'Treebank'), ('based', 'based'), ('deep', 'deep'), ('grammar', 'grammar'), ('acquisition', 'acquisition')]



========================================== PARAGRAPH 647 ===========================================

and Part-Of-Speech Tagging for Sanskrit sentences. In Software Engineering (CONSEG),  

------------------- Sentence 1 -------------------

and Part-Of-Speech Tagging for Sanskrit sentences.

>> Tokens are: 
 ['Part-Of-Speech', 'Tagging', 'Sanskrit', 'sentences', '.']

>> Bigrams are: 
 [('Part-Of-Speech', 'Tagging'), ('Tagging', 'Sanskrit'), ('Sanskrit', 'sentences'), ('sentences', '.')]

>> Trigrams are: 
 [('Part-Of-Speech', 'Tagging', 'Sanskrit'), ('Tagging', 'Sanskrit', 'sentences'), ('Sanskrit', 'sentences', '.')]

>> POS Tags are: 
 [('Part-Of-Speech', 'JJ'), ('Tagging', 'NNP'), ('Sanskrit', 'NNP'), ('sentences', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['Part-Of-Speech Tagging Sanskrit sentences']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Part-Of-Speech', 'part-of-speech'), ('Tagging', 'tag'), ('Sanskrit', 'sanskrit'), ('sentences', 'sentenc'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Part-Of-Speech', 'part-of-speech'), ('Tagging', 'tag'), ('Sanskrit', 'sanskrit'), ('sentences', 'sentenc'), ('.', '.')]

>> Lemmatization: 
 [('Part-Of-Speech', 'Part-Of-Speech'), ('Tagging', 'Tagging'), ('Sanskrit', 'Sanskrit'), ('sentences', 'sentence'), ('.', '.')]


------------------- Sentence 2 -------------------

In Software Engineering (CONSEG),

>> Tokens are: 
 ['In', 'Software', 'Engineering', '(', 'CONSEG', ')', ',']

>> Bigrams are: 
 [('In', 'Software'), ('Software', 'Engineering'), ('Engineering', '('), ('(', 'CONSEG'), ('CONSEG', ')'), (')', ',')]

>> Trigrams are: 
 [('In', 'Software', 'Engineering'), ('Software', 'Engineering', '('), ('Engineering', '(', 'CONSEG'), ('(', 'CONSEG', ')'), ('CONSEG', ')', ',')]

>> POS Tags are: 
 [('In', 'IN'), ('Software', 'NNP'), ('Engineering', 'NNP'), ('(', '('), ('CONSEG', 'NNP'), (')', ')'), (',', ',')]

>> Noun Phrases are: 
 ['Software Engineering', 'CONSEG']

>> Named Entities are: 
 [('GPE', 'Software'), ('ORGANIZATION', 'CONSEG')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('Software', 'softwar'), ('Engineering', 'engin'), ('(', '('), ('CONSEG', 'conseg'), (')', ')'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('Software', 'softwar'), ('Engineering', 'engin'), ('(', '('), ('CONSEG', 'conseg'), (')', ')'), (',', ',')]

>> Lemmatization: 
 [('In', 'In'), ('Software', 'Software'), ('Engineering', 'Engineering'), ('(', '('), ('CONSEG', 'CONSEG'), (')', ')'), (',', ',')]



========================================== PARAGRAPH 648 ===========================================

2012 CSI Sixth International Conference on (pp. 1-4). IEEE.  

------------------- Sentence 1 -------------------

2012 CSI Sixth International Conference on (pp.

>> Tokens are: 
 ['2012', 'CSI', 'Sixth', 'International', 'Conference', '(', 'pp', '.']

>> Bigrams are: 
 [('2012', 'CSI'), ('CSI', 'Sixth'), ('Sixth', 'International'), ('International', 'Conference'), ('Conference', '('), ('(', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('2012', 'CSI', 'Sixth'), ('CSI', 'Sixth', 'International'), ('Sixth', 'International', 'Conference'), ('International', 'Conference', '('), ('Conference', '(', 'pp'), ('(', 'pp', '.')]

>> POS Tags are: 
 [('2012', 'CD'), ('CSI', 'NNP'), ('Sixth', 'NNP'), ('International', 'NNP'), ('Conference', 'NNP'), ('(', '('), ('pp', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['CSI Sixth International Conference', 'pp']

>> Named Entities are: 
 [('ORGANIZATION', 'CSI Sixth International Conference')] 

>> Stemming using Porter Stemmer: 
 [('2012', '2012'), ('CSI', 'csi'), ('Sixth', 'sixth'), ('International', 'intern'), ('Conference', 'confer'), ('(', '('), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('2012', '2012'), ('CSI', 'csi'), ('Sixth', 'sixth'), ('International', 'intern'), ('Conference', 'confer'), ('(', '('), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('2012', '2012'), ('CSI', 'CSI'), ('Sixth', 'Sixth'), ('International', 'International'), ('Conference', 'Conference'), ('(', '('), ('pp', 'pp'), ('.', '.')]


------------------- Sentence 2 -------------------

1-4).

>> Tokens are: 
 ['1-4', ')', '.']

>> Bigrams are: 
 [('1-4', ')'), (')', '.')]

>> Trigrams are: 
 [('1-4', ')', '.')]

>> POS Tags are: 
 [('1-4', 'JJ'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('1-4', '1-4'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('1-4', '1-4'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('1-4', '1-4'), (')', ')'), ('.', '.')]


------------------- Sentence 3 -------------------

IEEE.

>> Tokens are: 
 ['IEEE', '.']

>> Bigrams are: 
 [('IEEE', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('IEEE', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['IEEE']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('IEEE', 'ieee'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('IEEE', 'ieee'), ('.', '.')]

>> Lemmatization: 
 [('IEEE', 'IEEE'), ('.', '.')]



========================================== PARAGRAPH 649 ===========================================

[28] Ranjan, P., & Basu, H. V. S. S. A. (2003). Part of speech tagging and local word  

------------------- Sentence 1 -------------------

[28] Ranjan, P., & Basu, H. V. S. S. A.

>> Tokens are: 
 ['[', '28', ']', 'Ranjan', ',', 'P.', ',', '&', 'Basu', ',', 'H.', 'V.', 'S.', 'S.', 'A', '.']

>> Bigrams are: 
 [('[', '28'), ('28', ']'), (']', 'Ranjan'), ('Ranjan', ','), (',', 'P.'), ('P.', ','), (',', '&'), ('&', 'Basu'), ('Basu', ','), (',', 'H.'), ('H.', 'V.'), ('V.', 'S.'), ('S.', 'S.'), ('S.', 'A'), ('A', '.')]

>> Trigrams are: 
 [('[', '28', ']'), ('28', ']', 'Ranjan'), (']', 'Ranjan', ','), ('Ranjan', ',', 'P.'), (',', 'P.', ','), ('P.', ',', '&'), (',', '&', 'Basu'), ('&', 'Basu', ','), ('Basu', ',', 'H.'), (',', 'H.', 'V.'), ('H.', 'V.', 'S.'), ('V.', 'S.', 'S.'), ('S.', 'S.', 'A'), ('S.', 'A', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('28', 'CD'), (']', 'JJ'), ('Ranjan', 'NNP'), (',', ','), ('P.', 'NNP'), (',', ','), ('&', 'CC'), ('Basu', 'NNP'), (',', ','), ('H.', 'NNP'), ('V.', 'NNP'), ('S.', 'NNP'), ('S.', 'NNP'), ('A', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['] Ranjan', 'P.', 'Basu', 'H. V. S. S. A']

>> Named Entities are: 
 [('GPE', 'Ranjan'), ('PERSON', 'Basu')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('28', '28'), (']', ']'), ('Ranjan', 'ranjan'), (',', ','), ('P.', 'p.'), (',', ','), ('&', '&'), ('Basu', 'basu'), (',', ','), ('H.', 'h.'), ('V.', 'v.'), ('S.', 's.'), ('S.', 's.'), ('A', 'a'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('28', '28'), (']', ']'), ('Ranjan', 'ranjan'), (',', ','), ('P.', 'p.'), (',', ','), ('&', '&'), ('Basu', 'basu'), (',', ','), ('H.', 'h.'), ('V.', 'v.'), ('S.', 's.'), ('S.', 's.'), ('A', 'a'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('28', '28'), (']', ']'), ('Ranjan', 'Ranjan'), (',', ','), ('P.', 'P.'), (',', ','), ('&', '&'), ('Basu', 'Basu'), (',', ','), ('H.', 'H.'), ('V.', 'V.'), ('S.', 'S.'), ('S.', 'S.'), ('A', 'A'), ('.', '.')]


------------------- Sentence 2 -------------------

(2003).

>> Tokens are: 
 ['(', '2003', ')', '.']

>> Bigrams are: 
 [('(', '2003'), ('2003', ')'), (')', '.')]

>> Trigrams are: 
 [('(', '2003', ')'), ('2003', ')', '.')]

>> POS Tags are: 
 [('(', '('), ('2003', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('2003', '2003'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('2003', '2003'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('(', '('), ('2003', '2003'), (')', ')'), ('.', '.')]


------------------- Sentence 3 -------------------

Part of speech tagging and local word

>> Tokens are: 
 ['Part', 'speech', 'tagging', 'local', 'word']

>> Bigrams are: 
 [('Part', 'speech'), ('speech', 'tagging'), ('tagging', 'local'), ('local', 'word')]

>> Trigrams are: 
 [('Part', 'speech', 'tagging'), ('speech', 'tagging', 'local'), ('tagging', 'local', 'word')]

>> POS Tags are: 
 [('Part', 'NN'), ('speech', 'NN'), ('tagging', 'VBG'), ('local', 'JJ'), ('word', 'NN')]

>> Noun Phrases are: 
 ['Part speech', 'local word']

>> Named Entities are: 
 [('GPE', 'Part')] 

>> Stemming using Porter Stemmer: 
 [('Part', 'part'), ('speech', 'speech'), ('tagging', 'tag'), ('local', 'local'), ('word', 'word')]

>> Stemming using Snowball Stemmer: 
 [('Part', 'part'), ('speech', 'speech'), ('tagging', 'tag'), ('local', 'local'), ('word', 'word')]

>> Lemmatization: 
 [('Part', 'Part'), ('speech', 'speech'), ('tagging', 'tagging'), ('local', 'local'), ('word', 'word')]



========================================== PARAGRAPH 650 ===========================================

grouping techniques for natural language parsing in Hindi. In Proceedings of the 1st  

------------------- Sentence 1 -------------------

grouping techniques for natural language parsing in Hindi.

>> Tokens are: 
 ['grouping', 'techniques', 'natural', 'language', 'parsing', 'Hindi', '.']

>> Bigrams are: 
 [('grouping', 'techniques'), ('techniques', 'natural'), ('natural', 'language'), ('language', 'parsing'), ('parsing', 'Hindi'), ('Hindi', '.')]

>> Trigrams are: 
 [('grouping', 'techniques', 'natural'), ('techniques', 'natural', 'language'), ('natural', 'language', 'parsing'), ('language', 'parsing', 'Hindi'), ('parsing', 'Hindi', '.')]

>> POS Tags are: 
 [('grouping', 'VBG'), ('techniques', 'NNS'), ('natural', 'JJ'), ('language', 'NN'), ('parsing', 'VBG'), ('Hindi', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['techniques', 'natural language', 'Hindi']

>> Named Entities are: 
 [('PERSON', 'Hindi')] 

>> Stemming using Porter Stemmer: 
 [('grouping', 'group'), ('techniques', 'techniqu'), ('natural', 'natur'), ('language', 'languag'), ('parsing', 'pars'), ('Hindi', 'hindi'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('grouping', 'group'), ('techniques', 'techniqu'), ('natural', 'natur'), ('language', 'languag'), ('parsing', 'pars'), ('Hindi', 'hindi'), ('.', '.')]

>> Lemmatization: 
 [('grouping', 'grouping'), ('techniques', 'technique'), ('natural', 'natural'), ('language', 'language'), ('parsing', 'parsing'), ('Hindi', 'Hindi'), ('.', '.')]


------------------- Sentence 2 -------------------

In Proceedings of the 1st

>> Tokens are: 
 ['In', 'Proceedings', '1st']

>> Bigrams are: 
 [('In', 'Proceedings'), ('Proceedings', '1st')]

>> Trigrams are: 
 [('In', 'Proceedings', '1st')]

>> POS Tags are: 
 [('In', 'IN'), ('Proceedings', 'NNS'), ('1st', 'CD')]

>> Noun Phrases are: 
 ['Proceedings']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('Proceedings', 'proceed'), ('1st', '1st')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('Proceedings', 'proceed'), ('1st', '1st')]

>> Lemmatization: 
 [('In', 'In'), ('Proceedings', 'Proceedings'), ('1st', '1st')]



========================================== PARAGRAPH 651 ===========================================

International Conference on Natural Language Processing (ICON 2003).  

------------------- Sentence 1 -------------------

International Conference on Natural Language Processing (ICON 2003).

>> Tokens are: 
 ['International', 'Conference', 'Natural', 'Language', 'Processing', '(', 'ICON', '2003', ')', '.']

>> Bigrams are: 
 [('International', 'Conference'), ('Conference', 'Natural'), ('Natural', 'Language'), ('Language', 'Processing'), ('Processing', '('), ('(', 'ICON'), ('ICON', '2003'), ('2003', ')'), (')', '.')]

>> Trigrams are: 
 [('International', 'Conference', 'Natural'), ('Conference', 'Natural', 'Language'), ('Natural', 'Language', 'Processing'), ('Language', 'Processing', '('), ('Processing', '(', 'ICON'), ('(', 'ICON', '2003'), ('ICON', '2003', ')'), ('2003', ')', '.')]

>> POS Tags are: 
 [('International', 'NNP'), ('Conference', 'NNP'), ('Natural', 'NNP'), ('Language', 'NNP'), ('Processing', 'NNP'), ('(', '('), ('ICON', 'NNP'), ('2003', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['International Conference Natural Language Processing', 'ICON']

>> Named Entities are: 
 [('ORGANIZATION', 'International Conference Natural Language'), ('ORGANIZATION', 'ICON')] 

>> Stemming using Porter Stemmer: 
 [('International', 'intern'), ('Conference', 'confer'), ('Natural', 'natur'), ('Language', 'languag'), ('Processing', 'process'), ('(', '('), ('ICON', 'icon'), ('2003', '2003'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('International', 'intern'), ('Conference', 'confer'), ('Natural', 'natur'), ('Language', 'languag'), ('Processing', 'process'), ('(', '('), ('ICON', 'icon'), ('2003', '2003'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('International', 'International'), ('Conference', 'Conference'), ('Natural', 'Natural'), ('Language', 'Language'), ('Processing', 'Processing'), ('(', '('), ('ICON', 'ICON'), ('2003', '2003'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 652 ===========================================

[29] Diab, M., Hacioglu, K., & Jurafsky, D. (2004, May). Automatic tagging of Arabic text:  

------------------- Sentence 1 -------------------

[29] Diab, M., Hacioglu, K., & Jurafsky, D. (2004, May).

>> Tokens are: 
 ['[', '29', ']', 'Diab', ',', 'M.', ',', 'Hacioglu', ',', 'K.', ',', '&', 'Jurafsky', ',', 'D.', '(', '2004', ',', 'May', ')', '.']

>> Bigrams are: 
 [('[', '29'), ('29', ']'), (']', 'Diab'), ('Diab', ','), (',', 'M.'), ('M.', ','), (',', 'Hacioglu'), ('Hacioglu', ','), (',', 'K.'), ('K.', ','), (',', '&'), ('&', 'Jurafsky'), ('Jurafsky', ','), (',', 'D.'), ('D.', '('), ('(', '2004'), ('2004', ','), (',', 'May'), ('May', ')'), (')', '.')]

>> Trigrams are: 
 [('[', '29', ']'), ('29', ']', 'Diab'), (']', 'Diab', ','), ('Diab', ',', 'M.'), (',', 'M.', ','), ('M.', ',', 'Hacioglu'), (',', 'Hacioglu', ','), ('Hacioglu', ',', 'K.'), (',', 'K.', ','), ('K.', ',', '&'), (',', '&', 'Jurafsky'), ('&', 'Jurafsky', ','), ('Jurafsky', ',', 'D.'), (',', 'D.', '('), ('D.', '(', '2004'), ('(', '2004', ','), ('2004', ',', 'May'), (',', 'May', ')'), ('May', ')', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('29', 'CD'), (']', 'JJ'), ('Diab', 'NNP'), (',', ','), ('M.', 'NNP'), (',', ','), ('Hacioglu', 'NNP'), (',', ','), ('K.', 'NNP'), (',', ','), ('&', 'CC'), ('Jurafsky', 'NNP'), (',', ','), ('D.', 'NNP'), ('(', '('), ('2004', 'CD'), (',', ','), ('May', 'NNP'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['] Diab', 'M.', 'Hacioglu', 'K.', 'Jurafsky', 'D.', 'May']

>> Named Entities are: 
 [('PERSON', 'Diab'), ('GPE', 'Hacioglu'), ('PERSON', 'Jurafsky')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('29', '29'), (']', ']'), ('Diab', 'diab'), (',', ','), ('M.', 'm.'), (',', ','), ('Hacioglu', 'hacioglu'), (',', ','), ('K.', 'k.'), (',', ','), ('&', '&'), ('Jurafsky', 'jurafski'), (',', ','), ('D.', 'd.'), ('(', '('), ('2004', '2004'), (',', ','), ('May', 'may'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('29', '29'), (']', ']'), ('Diab', 'diab'), (',', ','), ('M.', 'm.'), (',', ','), ('Hacioglu', 'hacioglu'), (',', ','), ('K.', 'k.'), (',', ','), ('&', '&'), ('Jurafsky', 'jurafski'), (',', ','), ('D.', 'd.'), ('(', '('), ('2004', '2004'), (',', ','), ('May', 'may'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('29', '29'), (']', ']'), ('Diab', 'Diab'), (',', ','), ('M.', 'M.'), (',', ','), ('Hacioglu', 'Hacioglu'), (',', ','), ('K.', 'K.'), (',', ','), ('&', '&'), ('Jurafsky', 'Jurafsky'), (',', ','), ('D.', 'D.'), ('(', '('), ('2004', '2004'), (',', ','), ('May', 'May'), (')', ')'), ('.', '.')]


------------------- Sentence 2 -------------------

Automatic tagging of Arabic text:

>> Tokens are: 
 ['Automatic', 'tagging', 'Arabic', 'text', ':']

>> Bigrams are: 
 [('Automatic', 'tagging'), ('tagging', 'Arabic'), ('Arabic', 'text'), ('text', ':')]

>> Trigrams are: 
 [('Automatic', 'tagging', 'Arabic'), ('tagging', 'Arabic', 'text'), ('Arabic', 'text', ':')]

>> POS Tags are: 
 [('Automatic', 'JJ'), ('tagging', 'VBG'), ('Arabic', 'NNP'), ('text', 'NN'), (':', ':')]

>> Noun Phrases are: 
 ['Arabic text']

>> Named Entities are: 
 [('PERSON', 'Arabic')] 

>> Stemming using Porter Stemmer: 
 [('Automatic', 'automat'), ('tagging', 'tag'), ('Arabic', 'arab'), ('text', 'text'), (':', ':')]

>> Stemming using Snowball Stemmer: 
 [('Automatic', 'automat'), ('tagging', 'tag'), ('Arabic', 'arab'), ('text', 'text'), (':', ':')]

>> Lemmatization: 
 [('Automatic', 'Automatic'), ('tagging', 'tagging'), ('Arabic', 'Arabic'), ('text', 'text'), (':', ':')]



========================================== PARAGRAPH 653 ===========================================

From raw text to base phrase chunks. In Proceedings of HLT-NAACL 2004: Short  

------------------- Sentence 1 -------------------

From raw text to base phrase chunks.

>> Tokens are: 
 ['From', 'raw', 'text', 'base', 'phrase', 'chunks', '.']

>> Bigrams are: 
 [('From', 'raw'), ('raw', 'text'), ('text', 'base'), ('base', 'phrase'), ('phrase', 'chunks'), ('chunks', '.')]

>> Trigrams are: 
 [('From', 'raw', 'text'), ('raw', 'text', 'base'), ('text', 'base', 'phrase'), ('base', 'phrase', 'chunks'), ('phrase', 'chunks', '.')]

>> POS Tags are: 
 [('From', 'IN'), ('raw', 'JJ'), ('text', 'NN'), ('base', 'NN'), ('phrase', 'NN'), ('chunks', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['raw text base phrase chunks']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('From', 'from'), ('raw', 'raw'), ('text', 'text'), ('base', 'base'), ('phrase', 'phrase'), ('chunks', 'chunk'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('From', 'from'), ('raw', 'raw'), ('text', 'text'), ('base', 'base'), ('phrase', 'phrase'), ('chunks', 'chunk'), ('.', '.')]

>> Lemmatization: 
 [('From', 'From'), ('raw', 'raw'), ('text', 'text'), ('base', 'base'), ('phrase', 'phrase'), ('chunks', 'chunk'), ('.', '.')]


------------------- Sentence 2 -------------------

In Proceedings of HLT-NAACL 2004: Short

>> Tokens are: 
 ['In', 'Proceedings', 'HLT-NAACL', '2004', ':', 'Short']

>> Bigrams are: 
 [('In', 'Proceedings'), ('Proceedings', 'HLT-NAACL'), ('HLT-NAACL', '2004'), ('2004', ':'), (':', 'Short')]

>> Trigrams are: 
 [('In', 'Proceedings', 'HLT-NAACL'), ('Proceedings', 'HLT-NAACL', '2004'), ('HLT-NAACL', '2004', ':'), ('2004', ':', 'Short')]

>> POS Tags are: 
 [('In', 'IN'), ('Proceedings', 'NNP'), ('HLT-NAACL', 'JJ'), ('2004', 'CD'), (':', ':'), ('Short', 'JJ')]

>> Noun Phrases are: 
 ['Proceedings']

>> Named Entities are: 
 [('GPE', 'Proceedings')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('Proceedings', 'proceed'), ('HLT-NAACL', 'hlt-naacl'), ('2004', '2004'), (':', ':'), ('Short', 'short')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('Proceedings', 'proceed'), ('HLT-NAACL', 'hlt-naacl'), ('2004', '2004'), (':', ':'), ('Short', 'short')]

>> Lemmatization: 
 [('In', 'In'), ('Proceedings', 'Proceedings'), ('HLT-NAACL', 'HLT-NAACL'), ('2004', '2004'), (':', ':'), ('Short', 'Short')]



========================================== PARAGRAPH 654 ===========================================

papers (pp. 149-152). Association for Computational Linguistics.  

------------------- Sentence 1 -------------------

papers (pp.

>> Tokens are: 
 ['papers', '(', 'pp', '.']

>> Bigrams are: 
 [('papers', '('), ('(', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('papers', '(', 'pp'), ('(', 'pp', '.')]

>> POS Tags are: 
 [('papers', 'NNS'), ('(', '('), ('pp', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['papers', 'pp']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('papers', 'paper'), ('(', '('), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('papers', 'paper'), ('(', '('), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('papers', 'paper'), ('(', '('), ('pp', 'pp'), ('.', '.')]


------------------- Sentence 2 -------------------

149-152).

>> Tokens are: 
 ['149-152', ')', '.']

>> Bigrams are: 
 [('149-152', ')'), (')', '.')]

>> Trigrams are: 
 [('149-152', ')', '.')]

>> POS Tags are: 
 [('149-152', 'JJ'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('149-152', '149-152'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('149-152', '149-152'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('149-152', '149-152'), (')', ')'), ('.', '.')]


------------------- Sentence 3 -------------------

Association for Computational Linguistics.

>> Tokens are: 
 ['Association', 'Computational', 'Linguistics', '.']

>> Bigrams are: 
 [('Association', 'Computational'), ('Computational', 'Linguistics'), ('Linguistics', '.')]

>> Trigrams are: 
 [('Association', 'Computational', 'Linguistics'), ('Computational', 'Linguistics', '.')]

>> POS Tags are: 
 [('Association', 'NNP'), ('Computational', 'NNP'), ('Linguistics', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Association Computational Linguistics']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Association', 'associ'), ('Computational', 'comput'), ('Linguistics', 'linguist'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Association', 'associ'), ('Computational', 'comput'), ('Linguistics', 'linguist'), ('.', '.')]

>> Lemmatization: 
 [('Association', 'Association'), ('Computational', 'Computational'), ('Linguistics', 'Linguistics'), ('.', '.')]



========================================== PARAGRAPH 655 ===========================================

[30] Sha, F., & Pereira, F. (2003, May). Shallow parsing with conditional random fields.  

------------------- Sentence 1 -------------------

[30] Sha, F., & Pereira, F. (2003, May).

>> Tokens are: 
 ['[', '30', ']', 'Sha', ',', 'F.', ',', '&', 'Pereira', ',', 'F.', '(', '2003', ',', 'May', ')', '.']

>> Bigrams are: 
 [('[', '30'), ('30', ']'), (']', 'Sha'), ('Sha', ','), (',', 'F.'), ('F.', ','), (',', '&'), ('&', 'Pereira'), ('Pereira', ','), (',', 'F.'), ('F.', '('), ('(', '2003'), ('2003', ','), (',', 'May'), ('May', ')'), (')', '.')]

>> Trigrams are: 
 [('[', '30', ']'), ('30', ']', 'Sha'), (']', 'Sha', ','), ('Sha', ',', 'F.'), (',', 'F.', ','), ('F.', ',', '&'), (',', '&', 'Pereira'), ('&', 'Pereira', ','), ('Pereira', ',', 'F.'), (',', 'F.', '('), ('F.', '(', '2003'), ('(', '2003', ','), ('2003', ',', 'May'), (',', 'May', ')'), ('May', ')', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('30', 'CD'), (']', 'JJ'), ('Sha', 'NNP'), (',', ','), ('F.', 'NNP'), (',', ','), ('&', 'CC'), ('Pereira', 'NNP'), (',', ','), ('F.', 'NNP'), ('(', '('), ('2003', 'CD'), (',', ','), ('May', 'NNP'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['] Sha', 'F.', 'Pereira', 'F.', 'May']

>> Named Entities are: 
 [('PERSON', 'Pereira')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('30', '30'), (']', ']'), ('Sha', 'sha'), (',', ','), ('F.', 'f.'), (',', ','), ('&', '&'), ('Pereira', 'pereira'), (',', ','), ('F.', 'f.'), ('(', '('), ('2003', '2003'), (',', ','), ('May', 'may'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('30', '30'), (']', ']'), ('Sha', 'sha'), (',', ','), ('F.', 'f.'), (',', ','), ('&', '&'), ('Pereira', 'pereira'), (',', ','), ('F.', 'f.'), ('(', '('), ('2003', '2003'), (',', ','), ('May', 'may'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('30', '30'), (']', ']'), ('Sha', 'Sha'), (',', ','), ('F.', 'F.'), (',', ','), ('&', '&'), ('Pereira', 'Pereira'), (',', ','), ('F.', 'F.'), ('(', '('), ('2003', '2003'), (',', ','), ('May', 'May'), (')', ')'), ('.', '.')]


------------------- Sentence 2 -------------------

Shallow parsing with conditional random fields.

>> Tokens are: 
 ['Shallow', 'parsing', 'conditional', 'random', 'fields', '.']

>> Bigrams are: 
 [('Shallow', 'parsing'), ('parsing', 'conditional'), ('conditional', 'random'), ('random', 'fields'), ('fields', '.')]

>> Trigrams are: 
 [('Shallow', 'parsing', 'conditional'), ('parsing', 'conditional', 'random'), ('conditional', 'random', 'fields'), ('random', 'fields', '.')]

>> POS Tags are: 
 [('Shallow', 'NNP'), ('parsing', 'VBG'), ('conditional', 'JJ'), ('random', 'NN'), ('fields', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['Shallow', 'conditional random fields']

>> Named Entities are: 
 [('GPE', 'Shallow')] 

>> Stemming using Porter Stemmer: 
 [('Shallow', 'shallow'), ('parsing', 'pars'), ('conditional', 'condit'), ('random', 'random'), ('fields', 'field'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Shallow', 'shallow'), ('parsing', 'pars'), ('conditional', 'condit'), ('random', 'random'), ('fields', 'field'), ('.', '.')]

>> Lemmatization: 
 [('Shallow', 'Shallow'), ('parsing', 'parsing'), ('conditional', 'conditional'), ('random', 'random'), ('fields', 'field'), ('.', '.')]



========================================== PARAGRAPH 656 ===========================================

In Proceedings of the 2003 Conference of the North American Chapter of the Association for  

------------------- Sentence 1 -------------------

In Proceedings of the 2003 Conference of the North American Chapter of the Association for

>> Tokens are: 
 ['In', 'Proceedings', '2003', 'Conference', 'North', 'American', 'Chapter', 'Association']

>> Bigrams are: 
 [('In', 'Proceedings'), ('Proceedings', '2003'), ('2003', 'Conference'), ('Conference', 'North'), ('North', 'American'), ('American', 'Chapter'), ('Chapter', 'Association')]

>> Trigrams are: 
 [('In', 'Proceedings', '2003'), ('Proceedings', '2003', 'Conference'), ('2003', 'Conference', 'North'), ('Conference', 'North', 'American'), ('North', 'American', 'Chapter'), ('American', 'Chapter', 'Association')]

>> POS Tags are: 
 [('In', 'IN'), ('Proceedings', 'NNP'), ('2003', 'CD'), ('Conference', 'NNP'), ('North', 'NNP'), ('American', 'NNP'), ('Chapter', 'NNP'), ('Association', 'NNP')]

>> Noun Phrases are: 
 ['Proceedings', 'Conference North American Chapter Association']

>> Named Entities are: 
 [('ORGANIZATION', 'American')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('Proceedings', 'proceed'), ('2003', '2003'), ('Conference', 'confer'), ('North', 'north'), ('American', 'american'), ('Chapter', 'chapter'), ('Association', 'associ')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('Proceedings', 'proceed'), ('2003', '2003'), ('Conference', 'confer'), ('North', 'north'), ('American', 'american'), ('Chapter', 'chapter'), ('Association', 'associ')]

>> Lemmatization: 
 [('In', 'In'), ('Proceedings', 'Proceedings'), ('2003', '2003'), ('Conference', 'Conference'), ('North', 'North'), ('American', 'American'), ('Chapter', 'Chapter'), ('Association', 'Association')]



========================================== PARAGRAPH 657 ===========================================

Computational Linguistics on Human Language Technology-Volume 1 (pp. 134-141).  

------------------- Sentence 1 -------------------

Computational Linguistics on Human Language Technology-Volume 1 (pp.

>> Tokens are: 
 ['Computational', 'Linguistics', 'Human', 'Language', 'Technology-Volume', '1', '(', 'pp', '.']

>> Bigrams are: 
 [('Computational', 'Linguistics'), ('Linguistics', 'Human'), ('Human', 'Language'), ('Language', 'Technology-Volume'), ('Technology-Volume', '1'), ('1', '('), ('(', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('Computational', 'Linguistics', 'Human'), ('Linguistics', 'Human', 'Language'), ('Human', 'Language', 'Technology-Volume'), ('Language', 'Technology-Volume', '1'), ('Technology-Volume', '1', '('), ('1', '(', 'pp'), ('(', 'pp', '.')]

>> POS Tags are: 
 [('Computational', 'JJ'), ('Linguistics', 'NNP'), ('Human', 'NNP'), ('Language', 'NNP'), ('Technology-Volume', 'NNP'), ('1', 'CD'), ('(', '('), ('pp', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Computational Linguistics Human Language Technology-Volume', 'pp']

>> Named Entities are: 
 [('PERSON', 'Linguistics Human Language')] 

>> Stemming using Porter Stemmer: 
 [('Computational', 'comput'), ('Linguistics', 'linguist'), ('Human', 'human'), ('Language', 'languag'), ('Technology-Volume', 'technology-volum'), ('1', '1'), ('(', '('), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Computational', 'comput'), ('Linguistics', 'linguist'), ('Human', 'human'), ('Language', 'languag'), ('Technology-Volume', 'technology-volum'), ('1', '1'), ('(', '('), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('Computational', 'Computational'), ('Linguistics', 'Linguistics'), ('Human', 'Human'), ('Language', 'Language'), ('Technology-Volume', 'Technology-Volume'), ('1', '1'), ('(', '('), ('pp', 'pp'), ('.', '.')]


------------------- Sentence 2 -------------------

134-141).

>> Tokens are: 
 ['134-141', ')', '.']

>> Bigrams are: 
 [('134-141', ')'), (')', '.')]

>> Trigrams are: 
 [('134-141', ')', '.')]

>> POS Tags are: 
 [('134-141', 'JJ'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('134-141', '134-141'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('134-141', '134-141'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('134-141', '134-141'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 658 ===========================================

Association for Computational Linguistics.  

------------------- Sentence 1 -------------------

Association for Computational Linguistics.

>> Tokens are: 
 ['Association', 'Computational', 'Linguistics', '.']

>> Bigrams are: 
 [('Association', 'Computational'), ('Computational', 'Linguistics'), ('Linguistics', '.')]

>> Trigrams are: 
 [('Association', 'Computational', 'Linguistics'), ('Computational', 'Linguistics', '.')]

>> POS Tags are: 
 [('Association', 'NNP'), ('Computational', 'NNP'), ('Linguistics', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Association Computational Linguistics']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Association', 'associ'), ('Computational', 'comput'), ('Linguistics', 'linguist'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Association', 'associ'), ('Computational', 'comput'), ('Linguistics', 'linguist'), ('.', '.')]

>> Lemmatization: 
 [('Association', 'Association'), ('Computational', 'Computational'), ('Linguistics', 'Linguistics'), ('.', '.')]



========================================== PARAGRAPH 659 ===========================================

[31] McDonald, R., Crammer, K., & Pereira, F. (2005, October). Flexible text segmentation  

------------------- Sentence 1 -------------------

[31] McDonald, R., Crammer, K., & Pereira, F. (2005, October).

>> Tokens are: 
 ['[', '31', ']', 'McDonald', ',', 'R.', ',', 'Crammer', ',', 'K.', ',', '&', 'Pereira', ',', 'F.', '(', '2005', ',', 'October', ')', '.']

>> Bigrams are: 
 [('[', '31'), ('31', ']'), (']', 'McDonald'), ('McDonald', ','), (',', 'R.'), ('R.', ','), (',', 'Crammer'), ('Crammer', ','), (',', 'K.'), ('K.', ','), (',', '&'), ('&', 'Pereira'), ('Pereira', ','), (',', 'F.'), ('F.', '('), ('(', '2005'), ('2005', ','), (',', 'October'), ('October', ')'), (')', '.')]

>> Trigrams are: 
 [('[', '31', ']'), ('31', ']', 'McDonald'), (']', 'McDonald', ','), ('McDonald', ',', 'R.'), (',', 'R.', ','), ('R.', ',', 'Crammer'), (',', 'Crammer', ','), ('Crammer', ',', 'K.'), (',', 'K.', ','), ('K.', ',', '&'), (',', '&', 'Pereira'), ('&', 'Pereira', ','), ('Pereira', ',', 'F.'), (',', 'F.', '('), ('F.', '(', '2005'), ('(', '2005', ','), ('2005', ',', 'October'), (',', 'October', ')'), ('October', ')', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('31', 'CD'), (']', 'JJ'), ('McDonald', 'NNP'), (',', ','), ('R.', 'NNP'), (',', ','), ('Crammer', 'NNP'), (',', ','), ('K.', 'NNP'), (',', ','), ('&', 'CC'), ('Pereira', 'NNP'), (',', ','), ('F.', 'NNP'), ('(', '('), ('2005', 'CD'), (',', ','), ('October', 'NNP'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['] McDonald', 'R.', 'Crammer', 'K.', 'Pereira', 'F.', 'October']

>> Named Entities are: 
 [('ORGANIZATION', 'McDonald'), ('GPE', 'Crammer'), ('PERSON', 'Pereira')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('31', '31'), (']', ']'), ('McDonald', 'mcdonald'), (',', ','), ('R.', 'r.'), (',', ','), ('Crammer', 'crammer'), (',', ','), ('K.', 'k.'), (',', ','), ('&', '&'), ('Pereira', 'pereira'), (',', ','), ('F.', 'f.'), ('(', '('), ('2005', '2005'), (',', ','), ('October', 'octob'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('31', '31'), (']', ']'), ('McDonald', 'mcdonald'), (',', ','), ('R.', 'r.'), (',', ','), ('Crammer', 'crammer'), (',', ','), ('K.', 'k.'), (',', ','), ('&', '&'), ('Pereira', 'pereira'), (',', ','), ('F.', 'f.'), ('(', '('), ('2005', '2005'), (',', ','), ('October', 'octob'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('31', '31'), (']', ']'), ('McDonald', 'McDonald'), (',', ','), ('R.', 'R.'), (',', ','), ('Crammer', 'Crammer'), (',', ','), ('K.', 'K.'), (',', ','), ('&', '&'), ('Pereira', 'Pereira'), (',', ','), ('F.', 'F.'), ('(', '('), ('2005', '2005'), (',', ','), ('October', 'October'), (')', ')'), ('.', '.')]


------------------- Sentence 2 -------------------

Flexible text segmentation

>> Tokens are: 
 ['Flexible', 'text', 'segmentation']

>> Bigrams are: 
 [('Flexible', 'text'), ('text', 'segmentation')]

>> Trigrams are: 
 [('Flexible', 'text', 'segmentation')]

>> POS Tags are: 
 [('Flexible', 'JJ'), ('text', 'NN'), ('segmentation', 'NN')]

>> Noun Phrases are: 
 ['Flexible text segmentation']

>> Named Entities are: 
 [('GPE', 'Flexible')] 

>> Stemming using Porter Stemmer: 
 [('Flexible', 'flexibl'), ('text', 'text'), ('segmentation', 'segment')]

>> Stemming using Snowball Stemmer: 
 [('Flexible', 'flexibl'), ('text', 'text'), ('segmentation', 'segment')]

>> Lemmatization: 
 [('Flexible', 'Flexible'), ('text', 'text'), ('segmentation', 'segmentation')]



========================================== PARAGRAPH 660 ===========================================

with structured multilabel classification. In Proceedings of the conference on Human  

------------------- Sentence 1 -------------------

with structured multilabel classification.

>> Tokens are: 
 ['structured', 'multilabel', 'classification', '.']

>> Bigrams are: 
 [('structured', 'multilabel'), ('multilabel', 'classification'), ('classification', '.')]

>> Trigrams are: 
 [('structured', 'multilabel', 'classification'), ('multilabel', 'classification', '.')]

>> POS Tags are: 
 [('structured', 'VBN'), ('multilabel', 'JJ'), ('classification', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['multilabel classification']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('structured', 'structur'), ('multilabel', 'multilabel'), ('classification', 'classif'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('structured', 'structur'), ('multilabel', 'multilabel'), ('classification', 'classif'), ('.', '.')]

>> Lemmatization: 
 [('structured', 'structured'), ('multilabel', 'multilabel'), ('classification', 'classification'), ('.', '.')]


------------------- Sentence 2 -------------------

In Proceedings of the conference on Human

>> Tokens are: 
 ['In', 'Proceedings', 'conference', 'Human']

>> Bigrams are: 
 [('In', 'Proceedings'), ('Proceedings', 'conference'), ('conference', 'Human')]

>> Trigrams are: 
 [('In', 'Proceedings', 'conference'), ('Proceedings', 'conference', 'Human')]

>> POS Tags are: 
 [('In', 'IN'), ('Proceedings', 'NNP'), ('conference', 'NN'), ('Human', 'NNP')]

>> Noun Phrases are: 
 ['Proceedings conference Human']

>> Named Entities are: 
 [('GPE', 'Proceedings'), ('PERSON', 'Human')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('Proceedings', 'proceed'), ('conference', 'confer'), ('Human', 'human')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('Proceedings', 'proceed'), ('conference', 'confer'), ('Human', 'human')]

>> Lemmatization: 
 [('In', 'In'), ('Proceedings', 'Proceedings'), ('conference', 'conference'), ('Human', 'Human')]



========================================== PARAGRAPH 661 ===========================================

Language Technology and Empirical Methods in Natural Language Processing (pp. 987- 

------------------- Sentence 1 -------------------

Language Technology and Empirical Methods in Natural Language Processing (pp.

>> Tokens are: 
 ['Language', 'Technology', 'Empirical', 'Methods', 'Natural', 'Language', 'Processing', '(', 'pp', '.']

>> Bigrams are: 
 [('Language', 'Technology'), ('Technology', 'Empirical'), ('Empirical', 'Methods'), ('Methods', 'Natural'), ('Natural', 'Language'), ('Language', 'Processing'), ('Processing', '('), ('(', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('Language', 'Technology', 'Empirical'), ('Technology', 'Empirical', 'Methods'), ('Empirical', 'Methods', 'Natural'), ('Methods', 'Natural', 'Language'), ('Natural', 'Language', 'Processing'), ('Language', 'Processing', '('), ('Processing', '(', 'pp'), ('(', 'pp', '.')]

>> POS Tags are: 
 [('Language', 'NNP'), ('Technology', 'NNP'), ('Empirical', 'NNP'), ('Methods', 'NNP'), ('Natural', 'NNP'), ('Language', 'NNP'), ('Processing', 'NNP'), ('(', '('), ('pp', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Language Technology Empirical Methods Natural Language Processing', 'pp']

>> Named Entities are: 
 [('PERSON', 'Language'), ('ORGANIZATION', 'Technology Empirical Methods Natural Language')] 

>> Stemming using Porter Stemmer: 
 [('Language', 'languag'), ('Technology', 'technolog'), ('Empirical', 'empir'), ('Methods', 'method'), ('Natural', 'natur'), ('Language', 'languag'), ('Processing', 'process'), ('(', '('), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Language', 'languag'), ('Technology', 'technolog'), ('Empirical', 'empir'), ('Methods', 'method'), ('Natural', 'natur'), ('Language', 'languag'), ('Processing', 'process'), ('(', '('), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('Language', 'Language'), ('Technology', 'Technology'), ('Empirical', 'Empirical'), ('Methods', 'Methods'), ('Natural', 'Natural'), ('Language', 'Language'), ('Processing', 'Processing'), ('(', '('), ('pp', 'pp'), ('.', '.')]


------------------- Sentence 2 -------------------

987-

>> Tokens are: 
 ['987-']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('987-', 'CD')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('987-', '987-')]

>> Stemming using Snowball Stemmer: 
 [('987-', '987-')]

>> Lemmatization: 
 [('987-', '987-')]



========================================== PARAGRAPH 662 ===========================================

994). Association for Computational Linguistics.  

------------------- Sentence 1 -------------------

994).

>> Tokens are: 
 ['994', ')', '.']

>> Bigrams are: 
 [('994', ')'), (')', '.')]

>> Trigrams are: 
 [('994', ')', '.')]

>> POS Tags are: 
 [('994', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('994', '994'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('994', '994'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('994', '994'), (')', ')'), ('.', '.')]


------------------- Sentence 2 -------------------

Association for Computational Linguistics.

>> Tokens are: 
 ['Association', 'Computational', 'Linguistics', '.']

>> Bigrams are: 
 [('Association', 'Computational'), ('Computational', 'Linguistics'), ('Linguistics', '.')]

>> Trigrams are: 
 [('Association', 'Computational', 'Linguistics'), ('Computational', 'Linguistics', '.')]

>> POS Tags are: 
 [('Association', 'NNP'), ('Computational', 'NNP'), ('Linguistics', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Association Computational Linguistics']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Association', 'associ'), ('Computational', 'comput'), ('Linguistics', 'linguist'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Association', 'associ'), ('Computational', 'comput'), ('Linguistics', 'linguist'), ('.', '.')]

>> Lemmatization: 
 [('Association', 'Association'), ('Computational', 'Computational'), ('Linguistics', 'Linguistics'), ('.', '.')]



========================================== PARAGRAPH 663 ===========================================

[32] Sun, X., Morency, L. P., Okanohara, D., & Tsujii, J. I. (2008, August). Modeling latent- 

------------------- Sentence 1 -------------------

[32] Sun, X., Morency, L. P., Okanohara, D., & Tsujii, J. I.

>> Tokens are: 
 ['[', '32', ']', 'Sun', ',', 'X.', ',', 'Morency', ',', 'L.', 'P.', ',', 'Okanohara', ',', 'D.', ',', '&', 'Tsujii', ',', 'J.', 'I', '.']

>> Bigrams are: 
 [('[', '32'), ('32', ']'), (']', 'Sun'), ('Sun', ','), (',', 'X.'), ('X.', ','), (',', 'Morency'), ('Morency', ','), (',', 'L.'), ('L.', 'P.'), ('P.', ','), (',', 'Okanohara'), ('Okanohara', ','), (',', 'D.'), ('D.', ','), (',', '&'), ('&', 'Tsujii'), ('Tsujii', ','), (',', 'J.'), ('J.', 'I'), ('I', '.')]

>> Trigrams are: 
 [('[', '32', ']'), ('32', ']', 'Sun'), (']', 'Sun', ','), ('Sun', ',', 'X.'), (',', 'X.', ','), ('X.', ',', 'Morency'), (',', 'Morency', ','), ('Morency', ',', 'L.'), (',', 'L.', 'P.'), ('L.', 'P.', ','), ('P.', ',', 'Okanohara'), (',', 'Okanohara', ','), ('Okanohara', ',', 'D.'), (',', 'D.', ','), ('D.', ',', '&'), (',', '&', 'Tsujii'), ('&', 'Tsujii', ','), ('Tsujii', ',', 'J.'), (',', 'J.', 'I'), ('J.', 'I', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('32', 'CD'), (']', 'JJ'), ('Sun', 'NNP'), (',', ','), ('X.', 'NNP'), (',', ','), ('Morency', 'NNP'), (',', ','), ('L.', 'NNP'), ('P.', 'NNP'), (',', ','), ('Okanohara', 'NNP'), (',', ','), ('D.', 'NNP'), (',', ','), ('&', 'CC'), ('Tsujii', 'NNP'), (',', ','), ('J.', 'NNP'), ('I', 'PRP'), ('.', '.')]

>> Noun Phrases are: 
 ['] Sun', 'X.', 'Morency', 'L. P.', 'Okanohara', 'D.', 'Tsujii', 'J.']

>> Named Entities are: 
 [('PERSON', 'Morency'), ('GPE', 'Okanohara'), ('GPE', 'Tsujii')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('32', '32'), (']', ']'), ('Sun', 'sun'), (',', ','), ('X.', 'x.'), (',', ','), ('Morency', 'morenc'), (',', ','), ('L.', 'l.'), ('P.', 'p.'), (',', ','), ('Okanohara', 'okanohara'), (',', ','), ('D.', 'd.'), (',', ','), ('&', '&'), ('Tsujii', 'tsujii'), (',', ','), ('J.', 'j.'), ('I', 'i'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('32', '32'), (']', ']'), ('Sun', 'sun'), (',', ','), ('X.', 'x.'), (',', ','), ('Morency', 'morenc'), (',', ','), ('L.', 'l.'), ('P.', 'p.'), (',', ','), ('Okanohara', 'okanohara'), (',', ','), ('D.', 'd.'), (',', ','), ('&', '&'), ('Tsujii', 'tsujii'), (',', ','), ('J.', 'j.'), ('I', 'i'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('32', '32'), (']', ']'), ('Sun', 'Sun'), (',', ','), ('X.', 'X.'), (',', ','), ('Morency', 'Morency'), (',', ','), ('L.', 'L.'), ('P.', 'P.'), (',', ','), ('Okanohara', 'Okanohara'), (',', ','), ('D.', 'D.'), (',', ','), ('&', '&'), ('Tsujii', 'Tsujii'), (',', ','), ('J.', 'J.'), ('I', 'I'), ('.', '.')]


------------------- Sentence 2 -------------------

(2008, August).

>> Tokens are: 
 ['(', '2008', ',', 'August', ')', '.']

>> Bigrams are: 
 [('(', '2008'), ('2008', ','), (',', 'August'), ('August', ')'), (')', '.')]

>> Trigrams are: 
 [('(', '2008', ','), ('2008', ',', 'August'), (',', 'August', ')'), ('August', ')', '.')]

>> POS Tags are: 
 [('(', '('), ('2008', 'CD'), (',', ','), ('August', 'NNP'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['August']

>> Named Entities are: 
 [('GPE', 'August')] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('2008', '2008'), (',', ','), ('August', 'august'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('2008', '2008'), (',', ','), ('August', 'august'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('(', '('), ('2008', '2008'), (',', ','), ('August', 'August'), (')', ')'), ('.', '.')]


------------------- Sentence 3 -------------------

Modeling latent-

>> Tokens are: 
 ['Modeling', 'latent-']

>> Bigrams are: 
 [('Modeling', 'latent-')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Modeling', 'VBG'), ('latent-', 'NN')]

>> Noun Phrases are: 
 ['latent-']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Modeling', 'model'), ('latent-', 'latent-')]

>> Stemming using Snowball Stemmer: 
 [('Modeling', 'model'), ('latent-', 'latent-')]

>> Lemmatization: 
 [('Modeling', 'Modeling'), ('latent-', 'latent-')]



========================================== PARAGRAPH 664 ===========================================

dynamic in shallow parsing: a latent conditional model with improved inference. 

------------------- Sentence 1 -------------------

dynamic in shallow parsing: a latent conditional model with improved inference.

>> Tokens are: 
 ['dynamic', 'shallow', 'parsing', ':', 'latent', 'conditional', 'model', 'improved', 'inference', '.']

>> Bigrams are: 
 [('dynamic', 'shallow'), ('shallow', 'parsing'), ('parsing', ':'), (':', 'latent'), ('latent', 'conditional'), ('conditional', 'model'), ('model', 'improved'), ('improved', 'inference'), ('inference', '.')]

>> Trigrams are: 
 [('dynamic', 'shallow', 'parsing'), ('shallow', 'parsing', ':'), ('parsing', ':', 'latent'), (':', 'latent', 'conditional'), ('latent', 'conditional', 'model'), ('conditional', 'model', 'improved'), ('model', 'improved', 'inference'), ('improved', 'inference', '.')]

>> POS Tags are: 
 [('dynamic', 'JJ'), ('shallow', 'JJ'), ('parsing', 'NN'), (':', ':'), ('latent', 'JJ'), ('conditional', 'JJ'), ('model', 'NN'), ('improved', 'VBD'), ('inference', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['dynamic shallow parsing', 'latent conditional model', 'inference']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('dynamic', 'dynam'), ('shallow', 'shallow'), ('parsing', 'pars'), (':', ':'), ('latent', 'latent'), ('conditional', 'condit'), ('model', 'model'), ('improved', 'improv'), ('inference', 'infer'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('dynamic', 'dynam'), ('shallow', 'shallow'), ('parsing', 'pars'), (':', ':'), ('latent', 'latent'), ('conditional', 'condit'), ('model', 'model'), ('improved', 'improv'), ('inference', 'infer'), ('.', '.')]

>> Lemmatization: 
 [('dynamic', 'dynamic'), ('shallow', 'shallow'), ('parsing', 'parsing'), (':', ':'), ('latent', 'latent'), ('conditional', 'conditional'), ('model', 'model'), ('improved', 'improved'), ('inference', 'inference'), ('.', '.')]



========================================== PARAGRAPH 665 ===========================================

In Proceedings of the 22nd International Conference on Computational Linguistics-Volume  

------------------- Sentence 1 -------------------

In Proceedings of the 22nd International Conference on Computational Linguistics-Volume

>> Tokens are: 
 ['In', 'Proceedings', '22nd', 'International', 'Conference', 'Computational', 'Linguistics-Volume']

>> Bigrams are: 
 [('In', 'Proceedings'), ('Proceedings', '22nd'), ('22nd', 'International'), ('International', 'Conference'), ('Conference', 'Computational'), ('Computational', 'Linguistics-Volume')]

>> Trigrams are: 
 [('In', 'Proceedings', '22nd'), ('Proceedings', '22nd', 'International'), ('22nd', 'International', 'Conference'), ('International', 'Conference', 'Computational'), ('Conference', 'Computational', 'Linguistics-Volume')]

>> POS Tags are: 
 [('In', 'IN'), ('Proceedings', 'NNP'), ('22nd', 'CD'), ('International', 'NNP'), ('Conference', 'NNP'), ('Computational', 'NNP'), ('Linguistics-Volume', 'NNP')]

>> Noun Phrases are: 
 ['Proceedings', 'International Conference Computational Linguistics-Volume']

>> Named Entities are: 
 [('ORGANIZATION', 'International Conference Computational')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('Proceedings', 'proceed'), ('22nd', '22nd'), ('International', 'intern'), ('Conference', 'confer'), ('Computational', 'comput'), ('Linguistics-Volume', 'linguistics-volum')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('Proceedings', 'proceed'), ('22nd', '22nd'), ('International', 'intern'), ('Conference', 'confer'), ('Computational', 'comput'), ('Linguistics-Volume', 'linguistics-volum')]

>> Lemmatization: 
 [('In', 'In'), ('Proceedings', 'Proceedings'), ('22nd', '22nd'), ('International', 'International'), ('Conference', 'Conference'), ('Computational', 'Computational'), ('Linguistics-Volume', 'Linguistics-Volume')]



========================================== PARAGRAPH 666 ===========================================

1 (pp. 841-848). Association for Computational Linguistics.  

------------------- Sentence 1 -------------------

1 (pp.

>> Tokens are: 
 ['1', '(', 'pp', '.']

>> Bigrams are: 
 [('1', '('), ('(', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('1', '(', 'pp'), ('(', 'pp', '.')]

>> POS Tags are: 
 [('1', 'CD'), ('(', '('), ('pp', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['pp']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('1', '1'), ('(', '('), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('1', '1'), ('(', '('), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('1', '1'), ('(', '('), ('pp', 'pp'), ('.', '.')]


------------------- Sentence 2 -------------------

841-848).

>> Tokens are: 
 ['841-848', ')', '.']

>> Bigrams are: 
 [('841-848', ')'), (')', '.')]

>> Trigrams are: 
 [('841-848', ')', '.')]

>> POS Tags are: 
 [('841-848', 'JJ'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('841-848', '841-848'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('841-848', '841-848'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('841-848', '841-848'), (')', ')'), ('.', '.')]


------------------- Sentence 3 -------------------

Association for Computational Linguistics.

>> Tokens are: 
 ['Association', 'Computational', 'Linguistics', '.']

>> Bigrams are: 
 [('Association', 'Computational'), ('Computational', 'Linguistics'), ('Linguistics', '.')]

>> Trigrams are: 
 [('Association', 'Computational', 'Linguistics'), ('Computational', 'Linguistics', '.')]

>> POS Tags are: 
 [('Association', 'NNP'), ('Computational', 'NNP'), ('Linguistics', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Association Computational Linguistics']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Association', 'associ'), ('Computational', 'comput'), ('Linguistics', 'linguist'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Association', 'associ'), ('Computational', 'comput'), ('Linguistics', 'linguist'), ('.', '.')]

>> Lemmatization: 
 [('Association', 'Association'), ('Computational', 'Computational'), ('Linguistics', 'Linguistics'), ('.', '.')]



========================================== PARAGRAPH 667 ===========================================

[33] Ritter, A., Clark, S., & Etzioni, O. (2011, July). Named entity recognition in tweets: an  

------------------- Sentence 1 -------------------

[33] Ritter, A., Clark, S., & Etzioni, O.

>> Tokens are: 
 ['[', '33', ']', 'Ritter', ',', 'A.', ',', 'Clark', ',', 'S.', ',', '&', 'Etzioni', ',', 'O', '.']

>> Bigrams are: 
 [('[', '33'), ('33', ']'), (']', 'Ritter'), ('Ritter', ','), (',', 'A.'), ('A.', ','), (',', 'Clark'), ('Clark', ','), (',', 'S.'), ('S.', ','), (',', '&'), ('&', 'Etzioni'), ('Etzioni', ','), (',', 'O'), ('O', '.')]

>> Trigrams are: 
 [('[', '33', ']'), ('33', ']', 'Ritter'), (']', 'Ritter', ','), ('Ritter', ',', 'A.'), (',', 'A.', ','), ('A.', ',', 'Clark'), (',', 'Clark', ','), ('Clark', ',', 'S.'), (',', 'S.', ','), ('S.', ',', '&'), (',', '&', 'Etzioni'), ('&', 'Etzioni', ','), ('Etzioni', ',', 'O'), (',', 'O', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('33', 'CD'), (']', 'JJ'), ('Ritter', 'NNP'), (',', ','), ('A.', 'NNP'), (',', ','), ('Clark', 'NNP'), (',', ','), ('S.', 'NNP'), (',', ','), ('&', 'CC'), ('Etzioni', 'NNP'), (',', ','), ('O', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['] Ritter', 'A.', 'Clark', 'S.', 'Etzioni', 'O']

>> Named Entities are: 
 [('PERSON', 'Ritter'), ('PERSON', 'Clark'), ('GPE', 'Etzioni')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('33', '33'), (']', ']'), ('Ritter', 'ritter'), (',', ','), ('A.', 'a.'), (',', ','), ('Clark', 'clark'), (',', ','), ('S.', 's.'), (',', ','), ('&', '&'), ('Etzioni', 'etzioni'), (',', ','), ('O', 'o'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('33', '33'), (']', ']'), ('Ritter', 'ritter'), (',', ','), ('A.', 'a.'), (',', ','), ('Clark', 'clark'), (',', ','), ('S.', 's.'), (',', ','), ('&', '&'), ('Etzioni', 'etzioni'), (',', ','), ('O', 'o'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('33', '33'), (']', ']'), ('Ritter', 'Ritter'), (',', ','), ('A.', 'A.'), (',', ','), ('Clark', 'Clark'), (',', ','), ('S.', 'S.'), (',', ','), ('&', '&'), ('Etzioni', 'Etzioni'), (',', ','), ('O', 'O'), ('.', '.')]


------------------- Sentence 2 -------------------

(2011, July).

>> Tokens are: 
 ['(', '2011', ',', 'July', ')', '.']

>> Bigrams are: 
 [('(', '2011'), ('2011', ','), (',', 'July'), ('July', ')'), (')', '.')]

>> Trigrams are: 
 [('(', '2011', ','), ('2011', ',', 'July'), (',', 'July', ')'), ('July', ')', '.')]

>> POS Tags are: 
 [('(', '('), ('2011', 'CD'), (',', ','), ('July', 'NNP'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['July']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('2011', '2011'), (',', ','), ('July', 'juli'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('2011', '2011'), (',', ','), ('July', 'juli'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('(', '('), ('2011', '2011'), (',', ','), ('July', 'July'), (')', ')'), ('.', '.')]


------------------- Sentence 3 -------------------

Named entity recognition in tweets: an

>> Tokens are: 
 ['Named', 'entity', 'recognition', 'tweets', ':']

>> Bigrams are: 
 [('Named', 'entity'), ('entity', 'recognition'), ('recognition', 'tweets'), ('tweets', ':')]

>> Trigrams are: 
 [('Named', 'entity', 'recognition'), ('entity', 'recognition', 'tweets'), ('recognition', 'tweets', ':')]

>> POS Tags are: 
 [('Named', 'VBN'), ('entity', 'NN'), ('recognition', 'NN'), ('tweets', 'NNS'), (':', ':')]

>> Noun Phrases are: 
 ['entity recognition tweets']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Named', 'name'), ('entity', 'entiti'), ('recognition', 'recognit'), ('tweets', 'tweet'), (':', ':')]

>> Stemming using Snowball Stemmer: 
 [('Named', 'name'), ('entity', 'entiti'), ('recognition', 'recognit'), ('tweets', 'tweet'), (':', ':')]

>> Lemmatization: 
 [('Named', 'Named'), ('entity', 'entity'), ('recognition', 'recognition'), ('tweets', 'tweet'), (':', ':')]



========================================== PARAGRAPH 668 ===========================================

experimental study. In Proceedings of the Conference on Empirical Methods in Natural  

------------------- Sentence 1 -------------------

experimental study.

>> Tokens are: 
 ['experimental', 'study', '.']

>> Bigrams are: 
 [('experimental', 'study'), ('study', '.')]

>> Trigrams are: 
 [('experimental', 'study', '.')]

>> POS Tags are: 
 [('experimental', 'JJ'), ('study', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['experimental study']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('experimental', 'experiment'), ('study', 'studi'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('experimental', 'experiment'), ('study', 'studi'), ('.', '.')]

>> Lemmatization: 
 [('experimental', 'experimental'), ('study', 'study'), ('.', '.')]


------------------- Sentence 2 -------------------

In Proceedings of the Conference on Empirical Methods in Natural

>> Tokens are: 
 ['In', 'Proceedings', 'Conference', 'Empirical', 'Methods', 'Natural']

>> Bigrams are: 
 [('In', 'Proceedings'), ('Proceedings', 'Conference'), ('Conference', 'Empirical'), ('Empirical', 'Methods'), ('Methods', 'Natural')]

>> Trigrams are: 
 [('In', 'Proceedings', 'Conference'), ('Proceedings', 'Conference', 'Empirical'), ('Conference', 'Empirical', 'Methods'), ('Empirical', 'Methods', 'Natural')]

>> POS Tags are: 
 [('In', 'IN'), ('Proceedings', 'NNP'), ('Conference', 'NNP'), ('Empirical', 'NNP'), ('Methods', 'NNP'), ('Natural', 'NNP')]

>> Noun Phrases are: 
 ['Proceedings Conference Empirical Methods Natural']

>> Named Entities are: 
 [('GPE', 'Proceedings'), ('PERSON', 'Methods Natural')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('Proceedings', 'proceed'), ('Conference', 'confer'), ('Empirical', 'empir'), ('Methods', 'method'), ('Natural', 'natur')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('Proceedings', 'proceed'), ('Conference', 'confer'), ('Empirical', 'empir'), ('Methods', 'method'), ('Natural', 'natur')]

>> Lemmatization: 
 [('In', 'In'), ('Proceedings', 'Proceedings'), ('Conference', 'Conference'), ('Empirical', 'Empirical'), ('Methods', 'Methods'), ('Natural', 'Natural')]



========================================== PARAGRAPH 669 ===========================================

Language Processing (pp. 1524-1534). Association for Computational Linguistics.  

------------------- Sentence 1 -------------------

Language Processing (pp.

>> Tokens are: 
 ['Language', 'Processing', '(', 'pp', '.']

>> Bigrams are: 
 [('Language', 'Processing'), ('Processing', '('), ('(', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('Language', 'Processing', '('), ('Processing', '(', 'pp'), ('(', 'pp', '.')]

>> POS Tags are: 
 [('Language', 'NN'), ('Processing', 'NNP'), ('(', '('), ('pp', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Language Processing', 'pp']

>> Named Entities are: 
 [('PERSON', 'Language'), ('ORGANIZATION', 'Processing')] 

>> Stemming using Porter Stemmer: 
 [('Language', 'languag'), ('Processing', 'process'), ('(', '('), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Language', 'languag'), ('Processing', 'process'), ('(', '('), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('Language', 'Language'), ('Processing', 'Processing'), ('(', '('), ('pp', 'pp'), ('.', '.')]


------------------- Sentence 2 -------------------

1524-1534).

>> Tokens are: 
 ['1524-1534', ')', '.']

>> Bigrams are: 
 [('1524-1534', ')'), (')', '.')]

>> Trigrams are: 
 [('1524-1534', ')', '.')]

>> POS Tags are: 
 [('1524-1534', 'JJ'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('1524-1534', '1524-1534'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('1524-1534', '1524-1534'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('1524-1534', '1524-1534'), (')', ')'), ('.', '.')]


------------------- Sentence 3 -------------------

Association for Computational Linguistics.

>> Tokens are: 
 ['Association', 'Computational', 'Linguistics', '.']

>> Bigrams are: 
 [('Association', 'Computational'), ('Computational', 'Linguistics'), ('Linguistics', '.')]

>> Trigrams are: 
 [('Association', 'Computational', 'Linguistics'), ('Computational', 'Linguistics', '.')]

>> POS Tags are: 
 [('Association', 'NNP'), ('Computational', 'NNP'), ('Linguistics', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Association Computational Linguistics']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Association', 'associ'), ('Computational', 'comput'), ('Linguistics', 'linguist'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Association', 'associ'), ('Computational', 'comput'), ('Linguistics', 'linguist'), ('.', '.')]

>> Lemmatization: 
 [('Association', 'Association'), ('Computational', 'Computational'), ('Linguistics', 'Linguistics'), ('.', '.')]



========================================== PARAGRAPH 670 ===========================================

[34] Sharma, S., Srinivas, PYKL, & Balabantaray, RC (2016). Emotion Detection using  

------------------- Sentence 1 -------------------

[34] Sharma, S., Srinivas, PYKL, & Balabantaray, RC (2016).

>> Tokens are: 
 ['[', '34', ']', 'Sharma', ',', 'S.', ',', 'Srinivas', ',', 'PYKL', ',', '&', 'Balabantaray', ',', 'RC', '(', '2016', ')', '.']

>> Bigrams are: 
 [('[', '34'), ('34', ']'), (']', 'Sharma'), ('Sharma', ','), (',', 'S.'), ('S.', ','), (',', 'Srinivas'), ('Srinivas', ','), (',', 'PYKL'), ('PYKL', ','), (',', '&'), ('&', 'Balabantaray'), ('Balabantaray', ','), (',', 'RC'), ('RC', '('), ('(', '2016'), ('2016', ')'), (')', '.')]

>> Trigrams are: 
 [('[', '34', ']'), ('34', ']', 'Sharma'), (']', 'Sharma', ','), ('Sharma', ',', 'S.'), (',', 'S.', ','), ('S.', ',', 'Srinivas'), (',', 'Srinivas', ','), ('Srinivas', ',', 'PYKL'), (',', 'PYKL', ','), ('PYKL', ',', '&'), (',', '&', 'Balabantaray'), ('&', 'Balabantaray', ','), ('Balabantaray', ',', 'RC'), (',', 'RC', '('), ('RC', '(', '2016'), ('(', '2016', ')'), ('2016', ')', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('34', 'CD'), (']', 'JJ'), ('Sharma', 'NNP'), (',', ','), ('S.', 'NNP'), (',', ','), ('Srinivas', 'NNP'), (',', ','), ('PYKL', 'NNP'), (',', ','), ('&', 'CC'), ('Balabantaray', 'NNP'), (',', ','), ('RC', 'NNP'), ('(', '('), ('2016', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['] Sharma', 'S.', 'Srinivas', 'PYKL', 'Balabantaray', 'RC']

>> Named Entities are: 
 [('GPE', 'Sharma'), ('GPE', 'Srinivas'), ('ORGANIZATION', 'PYKL'), ('GPE', 'Balabantaray'), ('GPE', 'RC')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('34', '34'), (']', ']'), ('Sharma', 'sharma'), (',', ','), ('S.', 's.'), (',', ','), ('Srinivas', 'sriniva'), (',', ','), ('PYKL', 'pykl'), (',', ','), ('&', '&'), ('Balabantaray', 'balabantaray'), (',', ','), ('RC', 'rc'), ('(', '('), ('2016', '2016'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('34', '34'), (']', ']'), ('Sharma', 'sharma'), (',', ','), ('S.', 's.'), (',', ','), ('Srinivas', 'sriniva'), (',', ','), ('PYKL', 'pykl'), (',', ','), ('&', '&'), ('Balabantaray', 'balabantaray'), (',', ','), ('RC', 'rc'), ('(', '('), ('2016', '2016'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('34', '34'), (']', ']'), ('Sharma', 'Sharma'), (',', ','), ('S.', 'S.'), (',', ','), ('Srinivas', 'Srinivas'), (',', ','), ('PYKL', 'PYKL'), (',', ','), ('&', '&'), ('Balabantaray', 'Balabantaray'), (',', ','), ('RC', 'RC'), ('(', '('), ('2016', '2016'), (')', ')'), ('.', '.')]


------------------- Sentence 2 -------------------

Emotion Detection using

>> Tokens are: 
 ['Emotion', 'Detection', 'using']

>> Bigrams are: 
 [('Emotion', 'Detection'), ('Detection', 'using')]

>> Trigrams are: 
 [('Emotion', 'Detection', 'using')]

>> POS Tags are: 
 [('Emotion', 'NN'), ('Detection', 'NNP'), ('using', 'VBG')]

>> Noun Phrases are: 
 ['Emotion Detection']

>> Named Entities are: 
 [('PERSON', 'Emotion Detection')] 

>> Stemming using Porter Stemmer: 
 [('Emotion', 'emot'), ('Detection', 'detect'), ('using', 'use')]

>> Stemming using Snowball Stemmer: 
 [('Emotion', 'emot'), ('Detection', 'detect'), ('using', 'use')]

>> Lemmatization: 
 [('Emotion', 'Emotion'), ('Detection', 'Detection'), ('using', 'using')]



========================================== PARAGRAPH 671 ===========================================

Online Machine Learning Method and TLBO on Mixed Script. In Proceedings of Language  

------------------- Sentence 1 -------------------

Online Machine Learning Method and TLBO on Mixed Script.

>> Tokens are: 
 ['Online', 'Machine', 'Learning', 'Method', 'TLBO', 'Mixed', 'Script', '.']

>> Bigrams are: 
 [('Online', 'Machine'), ('Machine', 'Learning'), ('Learning', 'Method'), ('Method', 'TLBO'), ('TLBO', 'Mixed'), ('Mixed', 'Script'), ('Script', '.')]

>> Trigrams are: 
 [('Online', 'Machine', 'Learning'), ('Machine', 'Learning', 'Method'), ('Learning', 'Method', 'TLBO'), ('Method', 'TLBO', 'Mixed'), ('TLBO', 'Mixed', 'Script'), ('Mixed', 'Script', '.')]

>> POS Tags are: 
 [('Online', 'NNP'), ('Machine', 'NNP'), ('Learning', 'NNP'), ('Method', 'NNP'), ('TLBO', 'NNP'), ('Mixed', 'NNP'), ('Script', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Online Machine Learning Method TLBO Mixed Script']

>> Named Entities are: 
 [('PERSON', 'Online'), ('PERSON', 'Machine Learning Method')] 

>> Stemming using Porter Stemmer: 
 [('Online', 'onlin'), ('Machine', 'machin'), ('Learning', 'learn'), ('Method', 'method'), ('TLBO', 'tlbo'), ('Mixed', 'mix'), ('Script', 'script'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Online', 'onlin'), ('Machine', 'machin'), ('Learning', 'learn'), ('Method', 'method'), ('TLBO', 'tlbo'), ('Mixed', 'mix'), ('Script', 'script'), ('.', '.')]

>> Lemmatization: 
 [('Online', 'Online'), ('Machine', 'Machine'), ('Learning', 'Learning'), ('Method', 'Method'), ('TLBO', 'TLBO'), ('Mixed', 'Mixed'), ('Script', 'Script'), ('.', '.')]


------------------- Sentence 2 -------------------

In Proceedings of Language

>> Tokens are: 
 ['In', 'Proceedings', 'Language']

>> Bigrams are: 
 [('In', 'Proceedings'), ('Proceedings', 'Language')]

>> Trigrams are: 
 [('In', 'Proceedings', 'Language')]

>> POS Tags are: 
 [('In', 'IN'), ('Proceedings', 'NNP'), ('Language', 'NNP')]

>> Noun Phrases are: 
 ['Proceedings Language']

>> Named Entities are: 
 [('GPE', 'Proceedings')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('Proceedings', 'proceed'), ('Language', 'languag')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('Proceedings', 'proceed'), ('Language', 'languag')]

>> Lemmatization: 
 [('In', 'In'), ('Proceedings', 'Proceedings'), ('Language', 'Language')]



========================================== PARAGRAPH 672 ===========================================

Resources and Evaluation Conference 2016 (pp. 47-51).  

------------------- Sentence 1 -------------------

Resources and Evaluation Conference 2016 (pp.

>> Tokens are: 
 ['Resources', 'Evaluation', 'Conference', '2016', '(', 'pp', '.']

>> Bigrams are: 
 [('Resources', 'Evaluation'), ('Evaluation', 'Conference'), ('Conference', '2016'), ('2016', '('), ('(', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('Resources', 'Evaluation', 'Conference'), ('Evaluation', 'Conference', '2016'), ('Conference', '2016', '('), ('2016', '(', 'pp'), ('(', 'pp', '.')]

>> POS Tags are: 
 [('Resources', 'NNS'), ('Evaluation', 'NNP'), ('Conference', 'NNP'), ('2016', 'CD'), ('(', '('), ('pp', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Resources Evaluation Conference', 'pp']

>> Named Entities are: 
 [('PERSON', 'Evaluation Conference')] 

>> Stemming using Porter Stemmer: 
 [('Resources', 'resourc'), ('Evaluation', 'evalu'), ('Conference', 'confer'), ('2016', '2016'), ('(', '('), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Resources', 'resourc'), ('Evaluation', 'evalu'), ('Conference', 'confer'), ('2016', '2016'), ('(', '('), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('Resources', 'Resources'), ('Evaluation', 'Evaluation'), ('Conference', 'Conference'), ('2016', '2016'), ('(', '('), ('pp', 'pp'), ('.', '.')]


------------------- Sentence 2 -------------------

47-51).

>> Tokens are: 
 ['47-51', ')', '.']

>> Bigrams are: 
 [('47-51', ')'), (')', '.')]

>> Trigrams are: 
 [('47-51', ')', '.')]

>> POS Tags are: 
 [('47-51', 'JJ'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('47-51', '47-51'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('47-51', '47-51'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('47-51', '47-51'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 673 ===========================================

[35] Palmer, M., Gildea, D., & Kingsbury, P. (2005). The proposition bank: An annotated  

------------------- Sentence 1 -------------------

[35] Palmer, M., Gildea, D., & Kingsbury, P. (2005).

>> Tokens are: 
 ['[', '35', ']', 'Palmer', ',', 'M.', ',', 'Gildea', ',', 'D.', ',', '&', 'Kingsbury', ',', 'P.', '(', '2005', ')', '.']

>> Bigrams are: 
 [('[', '35'), ('35', ']'), (']', 'Palmer'), ('Palmer', ','), (',', 'M.'), ('M.', ','), (',', 'Gildea'), ('Gildea', ','), (',', 'D.'), ('D.', ','), (',', '&'), ('&', 'Kingsbury'), ('Kingsbury', ','), (',', 'P.'), ('P.', '('), ('(', '2005'), ('2005', ')'), (')', '.')]

>> Trigrams are: 
 [('[', '35', ']'), ('35', ']', 'Palmer'), (']', 'Palmer', ','), ('Palmer', ',', 'M.'), (',', 'M.', ','), ('M.', ',', 'Gildea'), (',', 'Gildea', ','), ('Gildea', ',', 'D.'), (',', 'D.', ','), ('D.', ',', '&'), (',', '&', 'Kingsbury'), ('&', 'Kingsbury', ','), ('Kingsbury', ',', 'P.'), (',', 'P.', '('), ('P.', '(', '2005'), ('(', '2005', ')'), ('2005', ')', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('35', 'CD'), (']', 'JJ'), ('Palmer', 'NNP'), (',', ','), ('M.', 'NNP'), (',', ','), ('Gildea', 'NNP'), (',', ','), ('D.', 'NNP'), (',', ','), ('&', 'CC'), ('Kingsbury', 'NNP'), (',', ','), ('P.', 'NNP'), ('(', '('), ('2005', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['] Palmer', 'M.', 'Gildea', 'D.', 'Kingsbury', 'P.']

>> Named Entities are: 
 [('GPE', 'Palmer'), ('GPE', 'Gildea'), ('PERSON', 'Kingsbury')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('35', '35'), (']', ']'), ('Palmer', 'palmer'), (',', ','), ('M.', 'm.'), (',', ','), ('Gildea', 'gildea'), (',', ','), ('D.', 'd.'), (',', ','), ('&', '&'), ('Kingsbury', 'kingsburi'), (',', ','), ('P.', 'p.'), ('(', '('), ('2005', '2005'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('35', '35'), (']', ']'), ('Palmer', 'palmer'), (',', ','), ('M.', 'm.'), (',', ','), ('Gildea', 'gildea'), (',', ','), ('D.', 'd.'), (',', ','), ('&', '&'), ('Kingsbury', 'kingsburi'), (',', ','), ('P.', 'p.'), ('(', '('), ('2005', '2005'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('35', '35'), (']', ']'), ('Palmer', 'Palmer'), (',', ','), ('M.', 'M.'), (',', ','), ('Gildea', 'Gildea'), (',', ','), ('D.', 'D.'), (',', ','), ('&', '&'), ('Kingsbury', 'Kingsbury'), (',', ','), ('P.', 'P.'), ('(', '('), ('2005', '2005'), (')', ')'), ('.', '.')]


------------------- Sentence 2 -------------------

The proposition bank: An annotated

>> Tokens are: 
 ['The', 'proposition', 'bank', ':', 'An', 'annotated']

>> Bigrams are: 
 [('The', 'proposition'), ('proposition', 'bank'), ('bank', ':'), (':', 'An'), ('An', 'annotated')]

>> Trigrams are: 
 [('The', 'proposition', 'bank'), ('proposition', 'bank', ':'), ('bank', ':', 'An'), (':', 'An', 'annotated')]

>> POS Tags are: 
 [('The', 'DT'), ('proposition', 'NN'), ('bank', 'NN'), (':', ':'), ('An', 'DT'), ('annotated', 'JJ')]

>> Noun Phrases are: 
 ['The proposition bank']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('proposition', 'proposit'), ('bank', 'bank'), (':', ':'), ('An', 'an'), ('annotated', 'annot')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('proposition', 'proposit'), ('bank', 'bank'), (':', ':'), ('An', 'an'), ('annotated', 'annot')]

>> Lemmatization: 
 [('The', 'The'), ('proposition', 'proposition'), ('bank', 'bank'), (':', ':'), ('An', 'An'), ('annotated', 'annotated')]



========================================== PARAGRAPH 674 ===========================================

corpus of semantic roles. Computational linguistics, 31(1), 71-106.  

------------------- Sentence 1 -------------------

corpus of semantic roles.

>> Tokens are: 
 ['corpus', 'semantic', 'roles', '.']

>> Bigrams are: 
 [('corpus', 'semantic'), ('semantic', 'roles'), ('roles', '.')]

>> Trigrams are: 
 [('corpus', 'semantic', 'roles'), ('semantic', 'roles', '.')]

>> POS Tags are: 
 [('corpus', 'NN'), ('semantic', 'JJ'), ('roles', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['corpus', 'semantic roles']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('corpus', 'corpu'), ('semantic', 'semant'), ('roles', 'role'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('corpus', 'corpus'), ('semantic', 'semant'), ('roles', 'role'), ('.', '.')]

>> Lemmatization: 
 [('corpus', 'corpus'), ('semantic', 'semantic'), ('roles', 'role'), ('.', '.')]


------------------- Sentence 2 -------------------

Computational linguistics, 31(1), 71-106.

>> Tokens are: 
 ['Computational', 'linguistics', ',', '31', '(', '1', ')', ',', '71-106', '.']

>> Bigrams are: 
 [('Computational', 'linguistics'), ('linguistics', ','), (',', '31'), ('31', '('), ('(', '1'), ('1', ')'), (')', ','), (',', '71-106'), ('71-106', '.')]

>> Trigrams are: 
 [('Computational', 'linguistics', ','), ('linguistics', ',', '31'), (',', '31', '('), ('31', '(', '1'), ('(', '1', ')'), ('1', ')', ','), (')', ',', '71-106'), (',', '71-106', '.')]

>> POS Tags are: 
 [('Computational', 'JJ'), ('linguistics', 'NNS'), (',', ','), ('31', 'CD'), ('(', '('), ('1', 'CD'), (')', ')'), (',', ','), ('71-106', 'JJ'), ('.', '.')]

>> Noun Phrases are: 
 ['Computational linguistics']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Computational', 'comput'), ('linguistics', 'linguist'), (',', ','), ('31', '31'), ('(', '('), ('1', '1'), (')', ')'), (',', ','), ('71-106', '71-106'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Computational', 'comput'), ('linguistics', 'linguist'), (',', ','), ('31', '31'), ('(', '('), ('1', '1'), (')', ')'), (',', ','), ('71-106', '71-106'), ('.', '.')]

>> Lemmatization: 
 [('Computational', 'Computational'), ('linguistics', 'linguistics'), (',', ','), ('31', '31'), ('(', '('), ('1', '1'), (')', ')'), (',', ','), ('71-106', '71-106'), ('.', '.')]



========================================== PARAGRAPH 675 ===========================================

[36] Benson, E., Haghighi, A., & Barzilay, R. (2011, June). Event discovery in social media  

------------------- Sentence 1 -------------------

[36] Benson, E., Haghighi, A., & Barzilay, R. (2011, June).

>> Tokens are: 
 ['[', '36', ']', 'Benson', ',', 'E.', ',', 'Haghighi', ',', 'A.', ',', '&', 'Barzilay', ',', 'R.', '(', '2011', ',', 'June', ')', '.']

>> Bigrams are: 
 [('[', '36'), ('36', ']'), (']', 'Benson'), ('Benson', ','), (',', 'E.'), ('E.', ','), (',', 'Haghighi'), ('Haghighi', ','), (',', 'A.'), ('A.', ','), (',', '&'), ('&', 'Barzilay'), ('Barzilay', ','), (',', 'R.'), ('R.', '('), ('(', '2011'), ('2011', ','), (',', 'June'), ('June', ')'), (')', '.')]

>> Trigrams are: 
 [('[', '36', ']'), ('36', ']', 'Benson'), (']', 'Benson', ','), ('Benson', ',', 'E.'), (',', 'E.', ','), ('E.', ',', 'Haghighi'), (',', 'Haghighi', ','), ('Haghighi', ',', 'A.'), (',', 'A.', ','), ('A.', ',', '&'), (',', '&', 'Barzilay'), ('&', 'Barzilay', ','), ('Barzilay', ',', 'R.'), (',', 'R.', '('), ('R.', '(', '2011'), ('(', '2011', ','), ('2011', ',', 'June'), (',', 'June', ')'), ('June', ')', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('36', 'CD'), (']', 'NNP'), ('Benson', 'NNP'), (',', ','), ('E.', 'NNP'), (',', ','), ('Haghighi', 'NNP'), (',', ','), ('A.', 'NNP'), (',', ','), ('&', 'CC'), ('Barzilay', 'NNP'), (',', ','), ('R.', 'NNP'), ('(', '('), ('2011', 'CD'), (',', ','), ('June', 'NNP'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['] Benson', 'E.', 'Haghighi', 'A.', 'Barzilay', 'R.', 'June']

>> Named Entities are: 
 [('PERSON', 'Benson'), ('GPE', 'Haghighi'), ('PERSON', 'Barzilay')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('36', '36'), (']', ']'), ('Benson', 'benson'), (',', ','), ('E.', 'e.'), (',', ','), ('Haghighi', 'haghighi'), (',', ','), ('A.', 'a.'), (',', ','), ('&', '&'), ('Barzilay', 'barzilay'), (',', ','), ('R.', 'r.'), ('(', '('), ('2011', '2011'), (',', ','), ('June', 'june'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('36', '36'), (']', ']'), ('Benson', 'benson'), (',', ','), ('E.', 'e.'), (',', ','), ('Haghighi', 'haghighi'), (',', ','), ('A.', 'a.'), (',', ','), ('&', '&'), ('Barzilay', 'barzilay'), (',', ','), ('R.', 'r.'), ('(', '('), ('2011', '2011'), (',', ','), ('June', 'june'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('36', '36'), (']', ']'), ('Benson', 'Benson'), (',', ','), ('E.', 'E.'), (',', ','), ('Haghighi', 'Haghighi'), (',', ','), ('A.', 'A.'), (',', ','), ('&', '&'), ('Barzilay', 'Barzilay'), (',', ','), ('R.', 'R.'), ('(', '('), ('2011', '2011'), (',', ','), ('June', 'June'), (')', ')'), ('.', '.')]


------------------- Sentence 2 -------------------

Event discovery in social media

>> Tokens are: 
 ['Event', 'discovery', 'social', 'media']

>> Bigrams are: 
 [('Event', 'discovery'), ('discovery', 'social'), ('social', 'media')]

>> Trigrams are: 
 [('Event', 'discovery', 'social'), ('discovery', 'social', 'media')]

>> POS Tags are: 
 [('Event', 'JJ'), ('discovery', 'NN'), ('social', 'JJ'), ('media', 'NNS')]

>> Noun Phrases are: 
 ['Event discovery', 'social media']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Event', 'event'), ('discovery', 'discoveri'), ('social', 'social'), ('media', 'media')]

>> Stemming using Snowball Stemmer: 
 [('Event', 'event'), ('discovery', 'discoveri'), ('social', 'social'), ('media', 'media')]

>> Lemmatization: 
 [('Event', 'Event'), ('discovery', 'discovery'), ('social', 'social'), ('media', 'medium')]



========================================== PARAGRAPH 676 ===========================================

feeds. In Proceedings of the 49th Annual Meeting of the Association for Computational  

------------------- Sentence 1 -------------------

feeds.

>> Tokens are: 
 ['feeds', '.']

>> Bigrams are: 
 [('feeds', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('feeds', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['feeds']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('feeds', 'feed'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('feeds', 'feed'), ('.', '.')]

>> Lemmatization: 
 [('feeds', 'feed'), ('.', '.')]


------------------- Sentence 2 -------------------

In Proceedings of the 49th Annual Meeting of the Association for Computational

>> Tokens are: 
 ['In', 'Proceedings', '49th', 'Annual', 'Meeting', 'Association', 'Computational']

>> Bigrams are: 
 [('In', 'Proceedings'), ('Proceedings', '49th'), ('49th', 'Annual'), ('Annual', 'Meeting'), ('Meeting', 'Association'), ('Association', 'Computational')]

>> Trigrams are: 
 [('In', 'Proceedings', '49th'), ('Proceedings', '49th', 'Annual'), ('49th', 'Annual', 'Meeting'), ('Annual', 'Meeting', 'Association'), ('Meeting', 'Association', 'Computational')]

>> POS Tags are: 
 [('In', 'IN'), ('Proceedings', 'NNP'), ('49th', 'CD'), ('Annual', 'NNP'), ('Meeting', 'NNP'), ('Association', 'NNP'), ('Computational', 'NNP')]

>> Noun Phrases are: 
 ['Proceedings', 'Annual Meeting Association Computational']

>> Named Entities are: 
 [('PERSON', 'Annual Meeting')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('Proceedings', 'proceed'), ('49th', '49th'), ('Annual', 'annual'), ('Meeting', 'meet'), ('Association', 'associ'), ('Computational', 'comput')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('Proceedings', 'proceed'), ('49th', '49th'), ('Annual', 'annual'), ('Meeting', 'meet'), ('Association', 'associ'), ('Computational', 'comput')]

>> Lemmatization: 
 [('In', 'In'), ('Proceedings', 'Proceedings'), ('49th', '49th'), ('Annual', 'Annual'), ('Meeting', 'Meeting'), ('Association', 'Association'), ('Computational', 'Computational')]



========================================== PARAGRAPH 677 ===========================================

Linguistics: Human Language Technologies-Volume 1 (pp. 389-398). Association for  

------------------- Sentence 1 -------------------

Linguistics: Human Language Technologies-Volume 1 (pp.

>> Tokens are: 
 ['Linguistics', ':', 'Human', 'Language', 'Technologies-Volume', '1', '(', 'pp', '.']

>> Bigrams are: 
 [('Linguistics', ':'), (':', 'Human'), ('Human', 'Language'), ('Language', 'Technologies-Volume'), ('Technologies-Volume', '1'), ('1', '('), ('(', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('Linguistics', ':', 'Human'), (':', 'Human', 'Language'), ('Human', 'Language', 'Technologies-Volume'), ('Language', 'Technologies-Volume', '1'), ('Technologies-Volume', '1', '('), ('1', '(', 'pp'), ('(', 'pp', '.')]

>> POS Tags are: 
 [('Linguistics', 'NNS'), (':', ':'), ('Human', 'JJ'), ('Language', 'NNP'), ('Technologies-Volume', 'NNP'), ('1', 'CD'), ('(', '('), ('pp', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Linguistics', 'Human Language Technologies-Volume', 'pp']

>> Named Entities are: 
 [('PERSON', 'Human Language')] 

>> Stemming using Porter Stemmer: 
 [('Linguistics', 'linguist'), (':', ':'), ('Human', 'human'), ('Language', 'languag'), ('Technologies-Volume', 'technologies-volum'), ('1', '1'), ('(', '('), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Linguistics', 'linguist'), (':', ':'), ('Human', 'human'), ('Language', 'languag'), ('Technologies-Volume', 'technologies-volum'), ('1', '1'), ('(', '('), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('Linguistics', 'Linguistics'), (':', ':'), ('Human', 'Human'), ('Language', 'Language'), ('Technologies-Volume', 'Technologies-Volume'), ('1', '1'), ('(', '('), ('pp', 'pp'), ('.', '.')]


------------------- Sentence 2 -------------------

389-398).

>> Tokens are: 
 ['389-398', ')', '.']

>> Bigrams are: 
 [('389-398', ')'), (')', '.')]

>> Trigrams are: 
 [('389-398', ')', '.')]

>> POS Tags are: 
 [('389-398', 'JJ'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('389-398', '389-398'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('389-398', '389-398'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('389-398', '389-398'), (')', ')'), ('.', '.')]


------------------- Sentence 3 -------------------

Association for

>> Tokens are: 
 ['Association']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Association', 'NNP')]

>> Noun Phrases are: 
 ['Association']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Association', 'associ')]

>> Stemming using Snowball Stemmer: 
 [('Association', 'associ')]

>> Lemmatization: 
 [('Association', 'Association')]



========================================== PARAGRAPH 678 ===========================================

Computational Linguistics.  

------------------- Sentence 1 -------------------

Computational Linguistics.

>> Tokens are: 
 ['Computational', 'Linguistics', '.']

>> Bigrams are: 
 [('Computational', 'Linguistics'), ('Linguistics', '.')]

>> Trigrams are: 
 [('Computational', 'Linguistics', '.')]

>> POS Tags are: 
 [('Computational', 'JJ'), ('Linguistics', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['Computational Linguistics']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Computational', 'comput'), ('Linguistics', 'linguist'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Computational', 'comput'), ('Linguistics', 'linguist'), ('.', '.')]

>> Lemmatization: 
 [('Computational', 'Computational'), ('Linguistics', 'Linguistics'), ('.', '.')]



========================================== PARAGRAPH 679 ===========================================

[37] Tillmann, C., Vogel, S., Ney, H., Zubiaga, A., & Sawaf, H. (1997, September).  

------------------- Sentence 1 -------------------

[37] Tillmann, C., Vogel, S., Ney, H., Zubiaga, A., & Sawaf, H. (1997, September).

>> Tokens are: 
 ['[', '37', ']', 'Tillmann', ',', 'C.', ',', 'Vogel', ',', 'S.', ',', 'Ney', ',', 'H.', ',', 'Zubiaga', ',', 'A.', ',', '&', 'Sawaf', ',', 'H.', '(', '1997', ',', 'September', ')', '.']

>> Bigrams are: 
 [('[', '37'), ('37', ']'), (']', 'Tillmann'), ('Tillmann', ','), (',', 'C.'), ('C.', ','), (',', 'Vogel'), ('Vogel', ','), (',', 'S.'), ('S.', ','), (',', 'Ney'), ('Ney', ','), (',', 'H.'), ('H.', ','), (',', 'Zubiaga'), ('Zubiaga', ','), (',', 'A.'), ('A.', ','), (',', '&'), ('&', 'Sawaf'), ('Sawaf', ','), (',', 'H.'), ('H.', '('), ('(', '1997'), ('1997', ','), (',', 'September'), ('September', ')'), (')', '.')]

>> Trigrams are: 
 [('[', '37', ']'), ('37', ']', 'Tillmann'), (']', 'Tillmann', ','), ('Tillmann', ',', 'C.'), (',', 'C.', ','), ('C.', ',', 'Vogel'), (',', 'Vogel', ','), ('Vogel', ',', 'S.'), (',', 'S.', ','), ('S.', ',', 'Ney'), (',', 'Ney', ','), ('Ney', ',', 'H.'), (',', 'H.', ','), ('H.', ',', 'Zubiaga'), (',', 'Zubiaga', ','), ('Zubiaga', ',', 'A.'), (',', 'A.', ','), ('A.', ',', '&'), (',', '&', 'Sawaf'), ('&', 'Sawaf', ','), ('Sawaf', ',', 'H.'), (',', 'H.', '('), ('H.', '(', '1997'), ('(', '1997', ','), ('1997', ',', 'September'), (',', 'September', ')'), ('September', ')', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('37', 'CD'), (']', 'JJ'), ('Tillmann', 'NNP'), (',', ','), ('C.', 'NNP'), (',', ','), ('Vogel', 'NNP'), (',', ','), ('S.', 'NNP'), (',', ','), ('Ney', 'NNP'), (',', ','), ('H.', 'NNP'), (',', ','), ('Zubiaga', 'NNP'), (',', ','), ('A.', 'NNP'), (',', ','), ('&', 'CC'), ('Sawaf', 'NNP'), (',', ','), ('H.', 'NNP'), ('(', '('), ('1997', 'CD'), (',', ','), ('September', 'NNP'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['] Tillmann', 'C.', 'Vogel', 'S.', 'Ney', 'H.', 'Zubiaga', 'A.', 'Sawaf', 'H.', 'September']

>> Named Entities are: 
 [('PERSON', 'Vogel'), ('PERSON', 'Ney'), ('PERSON', 'Zubiaga'), ('PERSON', 'Sawaf')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('37', '37'), (']', ']'), ('Tillmann', 'tillmann'), (',', ','), ('C.', 'c.'), (',', ','), ('Vogel', 'vogel'), (',', ','), ('S.', 's.'), (',', ','), ('Ney', 'ney'), (',', ','), ('H.', 'h.'), (',', ','), ('Zubiaga', 'zubiaga'), (',', ','), ('A.', 'a.'), (',', ','), ('&', '&'), ('Sawaf', 'sawaf'), (',', ','), ('H.', 'h.'), ('(', '('), ('1997', '1997'), (',', ','), ('September', 'septemb'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('37', '37'), (']', ']'), ('Tillmann', 'tillmann'), (',', ','), ('C.', 'c.'), (',', ','), ('Vogel', 'vogel'), (',', ','), ('S.', 's.'), (',', ','), ('Ney', 'ney'), (',', ','), ('H.', 'h.'), (',', ','), ('Zubiaga', 'zubiaga'), (',', ','), ('A.', 'a.'), (',', ','), ('&', '&'), ('Sawaf', 'sawaf'), (',', ','), ('H.', 'h.'), ('(', '('), ('1997', '1997'), (',', ','), ('September', 'septemb'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('37', '37'), (']', ']'), ('Tillmann', 'Tillmann'), (',', ','), ('C.', 'C.'), (',', ','), ('Vogel', 'Vogel'), (',', ','), ('S.', 'S.'), (',', ','), ('Ney', 'Ney'), (',', ','), ('H.', 'H.'), (',', ','), ('Zubiaga', 'Zubiaga'), (',', ','), ('A.', 'A.'), (',', ','), ('&', '&'), ('Sawaf', 'Sawaf'), (',', ','), ('H.', 'H.'), ('(', '('), ('1997', '1997'), (',', ','), ('September', 'September'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 680 ===========================================

Accelerated DP based search for statistical translation. In Eurospeech.  

------------------- Sentence 1 -------------------

Accelerated DP based search for statistical translation.

>> Tokens are: 
 ['Accelerated', 'DP', 'based', 'search', 'statistical', 'translation', '.']

>> Bigrams are: 
 [('Accelerated', 'DP'), ('DP', 'based'), ('based', 'search'), ('search', 'statistical'), ('statistical', 'translation'), ('translation', '.')]

>> Trigrams are: 
 [('Accelerated', 'DP', 'based'), ('DP', 'based', 'search'), ('based', 'search', 'statistical'), ('search', 'statistical', 'translation'), ('statistical', 'translation', '.')]

>> POS Tags are: 
 [('Accelerated', 'NNP'), ('DP', 'NNP'), ('based', 'VBN'), ('search', 'NN'), ('statistical', 'JJ'), ('translation', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Accelerated DP', 'search', 'statistical translation']

>> Named Entities are: 
 [('GPE', 'Accelerated')] 

>> Stemming using Porter Stemmer: 
 [('Accelerated', 'acceler'), ('DP', 'dp'), ('based', 'base'), ('search', 'search'), ('statistical', 'statist'), ('translation', 'translat'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Accelerated', 'acceler'), ('DP', 'dp'), ('based', 'base'), ('search', 'search'), ('statistical', 'statist'), ('translation', 'translat'), ('.', '.')]

>> Lemmatization: 
 [('Accelerated', 'Accelerated'), ('DP', 'DP'), ('based', 'based'), ('search', 'search'), ('statistical', 'statistical'), ('translation', 'translation'), ('.', '.')]


------------------- Sentence 2 -------------------

In Eurospeech.

>> Tokens are: 
 ['In', 'Eurospeech', '.']

>> Bigrams are: 
 [('In', 'Eurospeech'), ('Eurospeech', '.')]

>> Trigrams are: 
 [('In', 'Eurospeech', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('Eurospeech', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Eurospeech']

>> Named Entities are: 
 [('GPE', 'Eurospeech')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('Eurospeech', 'eurospeech'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('Eurospeech', 'eurospeech'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('Eurospeech', 'Eurospeech'), ('.', '.')]



========================================== PARAGRAPH 681 ===========================================

[38] Bangalore, S., Rambow, O., & Whittaker, S. (2000, June). Evaluation metrics for  

------------------- Sentence 1 -------------------

[38] Bangalore, S., Rambow, O., & Whittaker, S. (2000, June).

>> Tokens are: 
 ['[', '38', ']', 'Bangalore', ',', 'S.', ',', 'Rambow', ',', 'O.', ',', '&', 'Whittaker', ',', 'S.', '(', '2000', ',', 'June', ')', '.']

>> Bigrams are: 
 [('[', '38'), ('38', ']'), (']', 'Bangalore'), ('Bangalore', ','), (',', 'S.'), ('S.', ','), (',', 'Rambow'), ('Rambow', ','), (',', 'O.'), ('O.', ','), (',', '&'), ('&', 'Whittaker'), ('Whittaker', ','), (',', 'S.'), ('S.', '('), ('(', '2000'), ('2000', ','), (',', 'June'), ('June', ')'), (')', '.')]

>> Trigrams are: 
 [('[', '38', ']'), ('38', ']', 'Bangalore'), (']', 'Bangalore', ','), ('Bangalore', ',', 'S.'), (',', 'S.', ','), ('S.', ',', 'Rambow'), (',', 'Rambow', ','), ('Rambow', ',', 'O.'), (',', 'O.', ','), ('O.', ',', '&'), (',', '&', 'Whittaker'), ('&', 'Whittaker', ','), ('Whittaker', ',', 'S.'), (',', 'S.', '('), ('S.', '(', '2000'), ('(', '2000', ','), ('2000', ',', 'June'), (',', 'June', ')'), ('June', ')', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('38', 'CD'), (']', 'NNS'), ('Bangalore', 'NNP'), (',', ','), ('S.', 'NNP'), (',', ','), ('Rambow', 'NNP'), (',', ','), ('O.', 'NNP'), (',', ','), ('&', 'CC'), ('Whittaker', 'NNP'), (',', ','), ('S.', 'NNP'), ('(', '('), ('2000', 'CD'), (',', ','), ('June', 'NNP'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['] Bangalore', 'S.', 'Rambow', 'O.', 'Whittaker', 'S.', 'June']

>> Named Entities are: 
 [('GPE', 'Bangalore'), ('GPE', 'Rambow'), ('PERSON', 'Whittaker')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('38', '38'), (']', ']'), ('Bangalore', 'bangalor'), (',', ','), ('S.', 's.'), (',', ','), ('Rambow', 'rambow'), (',', ','), ('O.', 'o.'), (',', ','), ('&', '&'), ('Whittaker', 'whittak'), (',', ','), ('S.', 's.'), ('(', '('), ('2000', '2000'), (',', ','), ('June', 'june'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('38', '38'), (']', ']'), ('Bangalore', 'bangalor'), (',', ','), ('S.', 's.'), (',', ','), ('Rambow', 'rambow'), (',', ','), ('O.', 'o.'), (',', ','), ('&', '&'), ('Whittaker', 'whittak'), (',', ','), ('S.', 's.'), ('(', '('), ('2000', '2000'), (',', ','), ('June', 'june'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('38', '38'), (']', ']'), ('Bangalore', 'Bangalore'), (',', ','), ('S.', 'S.'), (',', ','), ('Rambow', 'Rambow'), (',', ','), ('O.', 'O.'), (',', ','), ('&', '&'), ('Whittaker', 'Whittaker'), (',', ','), ('S.', 'S.'), ('(', '('), ('2000', '2000'), (',', ','), ('June', 'June'), (')', ')'), ('.', '.')]


------------------- Sentence 2 -------------------

Evaluation metrics for

>> Tokens are: 
 ['Evaluation', 'metrics']

>> Bigrams are: 
 [('Evaluation', 'metrics')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Evaluation', 'NN'), ('metrics', 'NNS')]

>> Noun Phrases are: 
 ['Evaluation metrics']

>> Named Entities are: 
 [('GPE', 'Evaluation')] 

>> Stemming using Porter Stemmer: 
 [('Evaluation', 'evalu'), ('metrics', 'metric')]

>> Stemming using Snowball Stemmer: 
 [('Evaluation', 'evalu'), ('metrics', 'metric')]

>> Lemmatization: 
 [('Evaluation', 'Evaluation'), ('metrics', 'metric')]



========================================== PARAGRAPH 682 ===========================================

generation. In Proceedings of the first international conference on Natural language  

------------------- Sentence 1 -------------------

generation.

>> Tokens are: 
 ['generation', '.']

>> Bigrams are: 
 [('generation', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('generation', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['generation']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('generation', 'gener'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('generation', 'generat'), ('.', '.')]

>> Lemmatization: 
 [('generation', 'generation'), ('.', '.')]


------------------- Sentence 2 -------------------

In Proceedings of the first international conference on Natural language

>> Tokens are: 
 ['In', 'Proceedings', 'first', 'international', 'conference', 'Natural', 'language']

>> Bigrams are: 
 [('In', 'Proceedings'), ('Proceedings', 'first'), ('first', 'international'), ('international', 'conference'), ('conference', 'Natural'), ('Natural', 'language')]

>> Trigrams are: 
 [('In', 'Proceedings', 'first'), ('Proceedings', 'first', 'international'), ('first', 'international', 'conference'), ('international', 'conference', 'Natural'), ('conference', 'Natural', 'language')]

>> POS Tags are: 
 [('In', 'IN'), ('Proceedings', 'NNP'), ('first', 'JJ'), ('international', 'JJ'), ('conference', 'NN'), ('Natural', 'NNP'), ('language', 'NN')]

>> Noun Phrases are: 
 ['Proceedings', 'first international conference Natural language']

>> Named Entities are: 
 [('GPE', 'Proceedings')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('Proceedings', 'proceed'), ('first', 'first'), ('international', 'intern'), ('conference', 'confer'), ('Natural', 'natur'), ('language', 'languag')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('Proceedings', 'proceed'), ('first', 'first'), ('international', 'intern'), ('conference', 'confer'), ('Natural', 'natur'), ('language', 'languag')]

>> Lemmatization: 
 [('In', 'In'), ('Proceedings', 'Proceedings'), ('first', 'first'), ('international', 'international'), ('conference', 'conference'), ('Natural', 'Natural'), ('language', 'language')]



========================================== PARAGRAPH 683 ===========================================

generation-Volume 14 (pp. 1-8). Association for Computational Linguistics  

------------------- Sentence 1 -------------------

generation-Volume 14 (pp.

>> Tokens are: 
 ['generation-Volume', '14', '(', 'pp', '.']

>> Bigrams are: 
 [('generation-Volume', '14'), ('14', '('), ('(', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('generation-Volume', '14', '('), ('14', '(', 'pp'), ('(', 'pp', '.')]

>> POS Tags are: 
 [('generation-Volume', 'JJ'), ('14', 'CD'), ('(', '('), ('pp', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['pp']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('generation-Volume', 'generation-volum'), ('14', '14'), ('(', '('), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('generation-Volume', 'generation-volum'), ('14', '14'), ('(', '('), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('generation-Volume', 'generation-Volume'), ('14', '14'), ('(', '('), ('pp', 'pp'), ('.', '.')]


------------------- Sentence 2 -------------------

1-8).

>> Tokens are: 
 ['1-8', ')', '.']

>> Bigrams are: 
 [('1-8', ')'), (')', '.')]

>> Trigrams are: 
 [('1-8', ')', '.')]

>> POS Tags are: 
 [('1-8', 'JJ'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('1-8', '1-8'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('1-8', '1-8'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('1-8', '1-8'), (')', ')'), ('.', '.')]


------------------- Sentence 3 -------------------

Association for Computational Linguistics

>> Tokens are: 
 ['Association', 'Computational', 'Linguistics']

>> Bigrams are: 
 [('Association', 'Computational'), ('Computational', 'Linguistics')]

>> Trigrams are: 
 [('Association', 'Computational', 'Linguistics')]

>> POS Tags are: 
 [('Association', 'NNP'), ('Computational', 'NNP'), ('Linguistics', 'NNP')]

>> Noun Phrases are: 
 ['Association Computational Linguistics']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Association', 'associ'), ('Computational', 'comput'), ('Linguistics', 'linguist')]

>> Stemming using Snowball Stemmer: 
 [('Association', 'associ'), ('Computational', 'comput'), ('Linguistics', 'linguist')]

>> Lemmatization: 
 [('Association', 'Association'), ('Computational', 'Computational'), ('Linguistics', 'Linguistics')]



========================================== PARAGRAPH 684 ===========================================

[39] Nießen, S., Och, F. J., Leusch, G., & Ney, H. (2000, May). An Evaluation Tool for  

------------------- Sentence 1 -------------------

[39] Nießen, S., Och, F. J., Leusch, G., & Ney, H. (2000, May).

>> Tokens are: 
 ['[', '39', ']', 'Nießen', ',', 'S.', ',', 'Och', ',', 'F.', 'J.', ',', 'Leusch', ',', 'G.', ',', '&', 'Ney', ',', 'H.', '(', '2000', ',', 'May', ')', '.']

>> Bigrams are: 
 [('[', '39'), ('39', ']'), (']', 'Nießen'), ('Nießen', ','), (',', 'S.'), ('S.', ','), (',', 'Och'), ('Och', ','), (',', 'F.'), ('F.', 'J.'), ('J.', ','), (',', 'Leusch'), ('Leusch', ','), (',', 'G.'), ('G.', ','), (',', '&'), ('&', 'Ney'), ('Ney', ','), (',', 'H.'), ('H.', '('), ('(', '2000'), ('2000', ','), (',', 'May'), ('May', ')'), (')', '.')]

>> Trigrams are: 
 [('[', '39', ']'), ('39', ']', 'Nießen'), (']', 'Nießen', ','), ('Nießen', ',', 'S.'), (',', 'S.', ','), ('S.', ',', 'Och'), (',', 'Och', ','), ('Och', ',', 'F.'), (',', 'F.', 'J.'), ('F.', 'J.', ','), ('J.', ',', 'Leusch'), (',', 'Leusch', ','), ('Leusch', ',', 'G.'), (',', 'G.', ','), ('G.', ',', '&'), (',', '&', 'Ney'), ('&', 'Ney', ','), ('Ney', ',', 'H.'), (',', 'H.', '('), ('H.', '(', '2000'), ('(', '2000', ','), ('2000', ',', 'May'), (',', 'May', ')'), ('May', ')', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('39', 'CD'), (']', 'JJ'), ('Nießen', 'NNP'), (',', ','), ('S.', 'NNP'), (',', ','), ('Och', 'NNP'), (',', ','), ('F.', 'NNP'), ('J.', 'NNP'), (',', ','), ('Leusch', 'NNP'), (',', ','), ('G.', 'NNP'), (',', ','), ('&', 'CC'), ('Ney', 'NNP'), (',', ','), ('H.', 'NNP'), ('(', '('), ('2000', 'CD'), (',', ','), ('May', 'NNP'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['] Nießen', 'S.', 'Och', 'F. J.', 'Leusch', 'G.', 'Ney', 'H.', 'May']

>> Named Entities are: 
 [('GPE', 'Nießen'), ('PERSON', 'Och'), ('GPE', 'Leusch'), ('PERSON', 'Ney')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('39', '39'), (']', ']'), ('Nießen', 'nießen'), (',', ','), ('S.', 's.'), (',', ','), ('Och', 'och'), (',', ','), ('F.', 'f.'), ('J.', 'j.'), (',', ','), ('Leusch', 'leusch'), (',', ','), ('G.', 'g.'), (',', ','), ('&', '&'), ('Ney', 'ney'), (',', ','), ('H.', 'h.'), ('(', '('), ('2000', '2000'), (',', ','), ('May', 'may'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('39', '39'), (']', ']'), ('Nießen', 'nießen'), (',', ','), ('S.', 's.'), (',', ','), ('Och', 'och'), (',', ','), ('F.', 'f.'), ('J.', 'j.'), (',', ','), ('Leusch', 'leusch'), (',', ','), ('G.', 'g.'), (',', ','), ('&', '&'), ('Ney', 'ney'), (',', ','), ('H.', 'h.'), ('(', '('), ('2000', '2000'), (',', ','), ('May', 'may'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('39', '39'), (']', ']'), ('Nießen', 'Nießen'), (',', ','), ('S.', 'S.'), (',', ','), ('Och', 'Och'), (',', ','), ('F.', 'F.'), ('J.', 'J.'), (',', ','), ('Leusch', 'Leusch'), (',', ','), ('G.', 'G.'), (',', ','), ('&', '&'), ('Ney', 'Ney'), (',', ','), ('H.', 'H.'), ('(', '('), ('2000', '2000'), (',', ','), ('May', 'May'), (')', ')'), ('.', '.')]


------------------- Sentence 2 -------------------

An Evaluation Tool for

>> Tokens are: 
 ['An', 'Evaluation', 'Tool']

>> Bigrams are: 
 [('An', 'Evaluation'), ('Evaluation', 'Tool')]

>> Trigrams are: 
 [('An', 'Evaluation', 'Tool')]

>> POS Tags are: 
 [('An', 'DT'), ('Evaluation', 'NN'), ('Tool', 'NN')]

>> Noun Phrases are: 
 ['An Evaluation Tool']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('An', 'an'), ('Evaluation', 'evalu'), ('Tool', 'tool')]

>> Stemming using Snowball Stemmer: 
 [('An', 'an'), ('Evaluation', 'evalu'), ('Tool', 'tool')]

>> Lemmatization: 
 [('An', 'An'), ('Evaluation', 'Evaluation'), ('Tool', 'Tool')]



========================================== PARAGRAPH 685 ===========================================

Machine Translation: Fast Evaluation for MT Research. In LREC  

------------------- Sentence 1 -------------------

Machine Translation: Fast Evaluation for MT Research.

>> Tokens are: 
 ['Machine', 'Translation', ':', 'Fast', 'Evaluation', 'MT', 'Research', '.']

>> Bigrams are: 
 [('Machine', 'Translation'), ('Translation', ':'), (':', 'Fast'), ('Fast', 'Evaluation'), ('Evaluation', 'MT'), ('MT', 'Research'), ('Research', '.')]

>> Trigrams are: 
 [('Machine', 'Translation', ':'), ('Translation', ':', 'Fast'), (':', 'Fast', 'Evaluation'), ('Fast', 'Evaluation', 'MT'), ('Evaluation', 'MT', 'Research'), ('MT', 'Research', '.')]

>> POS Tags are: 
 [('Machine', 'NN'), ('Translation', 'NN'), (':', ':'), ('Fast', 'NNP'), ('Evaluation', 'NNP'), ('MT', 'NNP'), ('Research', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Machine Translation', 'Fast Evaluation MT Research']

>> Named Entities are: 
 [('GPE', 'Machine'), ('PERSON', 'Fast Evaluation MT Research')] 

>> Stemming using Porter Stemmer: 
 [('Machine', 'machin'), ('Translation', 'translat'), (':', ':'), ('Fast', 'fast'), ('Evaluation', 'evalu'), ('MT', 'mt'), ('Research', 'research'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Machine', 'machin'), ('Translation', 'translat'), (':', ':'), ('Fast', 'fast'), ('Evaluation', 'evalu'), ('MT', 'mt'), ('Research', 'research'), ('.', '.')]

>> Lemmatization: 
 [('Machine', 'Machine'), ('Translation', 'Translation'), (':', ':'), ('Fast', 'Fast'), ('Evaluation', 'Evaluation'), ('MT', 'MT'), ('Research', 'Research'), ('.', '.')]


------------------- Sentence 2 -------------------

In LREC

>> Tokens are: 
 ['In', 'LREC']

>> Bigrams are: 
 [('In', 'LREC')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('In', 'IN'), ('LREC', 'NNP')]

>> Noun Phrases are: 
 ['LREC']

>> Named Entities are: 
 [('ORGANIZATION', 'LREC')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('LREC', 'lrec')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('LREC', 'lrec')]

>> Lemmatization: 
 [('In', 'In'), ('LREC', 'LREC')]



========================================== PARAGRAPH 686 ===========================================

[40] Papineni, K., Roukos, S., Ward, T., & Zhu, W. J. (2002, July). BLEU: a method for  

------------------- Sentence 1 -------------------

[40] Papineni, K., Roukos, S., Ward, T., & Zhu, W. J.

>> Tokens are: 
 ['[', '40', ']', 'Papineni', ',', 'K.', ',', 'Roukos', ',', 'S.', ',', 'Ward', ',', 'T.', ',', '&', 'Zhu', ',', 'W.', 'J', '.']

>> Bigrams are: 
 [('[', '40'), ('40', ']'), (']', 'Papineni'), ('Papineni', ','), (',', 'K.'), ('K.', ','), (',', 'Roukos'), ('Roukos', ','), (',', 'S.'), ('S.', ','), (',', 'Ward'), ('Ward', ','), (',', 'T.'), ('T.', ','), (',', '&'), ('&', 'Zhu'), ('Zhu', ','), (',', 'W.'), ('W.', 'J'), ('J', '.')]

>> Trigrams are: 
 [('[', '40', ']'), ('40', ']', 'Papineni'), (']', 'Papineni', ','), ('Papineni', ',', 'K.'), (',', 'K.', ','), ('K.', ',', 'Roukos'), (',', 'Roukos', ','), ('Roukos', ',', 'S.'), (',', 'S.', ','), ('S.', ',', 'Ward'), (',', 'Ward', ','), ('Ward', ',', 'T.'), (',', 'T.', ','), ('T.', ',', '&'), (',', '&', 'Zhu'), ('&', 'Zhu', ','), ('Zhu', ',', 'W.'), (',', 'W.', 'J'), ('W.', 'J', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('40', 'CD'), (']', 'JJ'), ('Papineni', 'NNP'), (',', ','), ('K.', 'NNP'), (',', ','), ('Roukos', 'NNP'), (',', ','), ('S.', 'NNP'), (',', ','), ('Ward', 'NNP'), (',', ','), ('T.', 'NNP'), (',', ','), ('&', 'CC'), ('Zhu', 'NNP'), (',', ','), ('W.', 'NNP'), ('J', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['] Papineni', 'K.', 'Roukos', 'S.', 'Ward', 'T.', 'Zhu', 'W. J']

>> Named Entities are: 
 [('PERSON', 'Papineni'), ('GPE', 'Roukos'), ('PERSON', 'Ward'), ('PERSON', 'Zhu')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('40', '40'), (']', ']'), ('Papineni', 'papineni'), (',', ','), ('K.', 'k.'), (',', ','), ('Roukos', 'rouko'), (',', ','), ('S.', 's.'), (',', ','), ('Ward', 'ward'), (',', ','), ('T.', 't.'), (',', ','), ('&', '&'), ('Zhu', 'zhu'), (',', ','), ('W.', 'w.'), ('J', 'j'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('40', '40'), (']', ']'), ('Papineni', 'papineni'), (',', ','), ('K.', 'k.'), (',', ','), ('Roukos', 'rouko'), (',', ','), ('S.', 's.'), (',', ','), ('Ward', 'ward'), (',', ','), ('T.', 't.'), (',', ','), ('&', '&'), ('Zhu', 'zhu'), (',', ','), ('W.', 'w.'), ('J', 'j'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('40', '40'), (']', ']'), ('Papineni', 'Papineni'), (',', ','), ('K.', 'K.'), (',', ','), ('Roukos', 'Roukos'), (',', ','), ('S.', 'S.'), (',', ','), ('Ward', 'Ward'), (',', ','), ('T.', 'T.'), (',', ','), ('&', '&'), ('Zhu', 'Zhu'), (',', ','), ('W.', 'W.'), ('J', 'J'), ('.', '.')]


------------------- Sentence 2 -------------------

(2002, July).

>> Tokens are: 
 ['(', '2002', ',', 'July', ')', '.']

>> Bigrams are: 
 [('(', '2002'), ('2002', ','), (',', 'July'), ('July', ')'), (')', '.')]

>> Trigrams are: 
 [('(', '2002', ','), ('2002', ',', 'July'), (',', 'July', ')'), ('July', ')', '.')]

>> POS Tags are: 
 [('(', '('), ('2002', 'CD'), (',', ','), ('July', 'NNP'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['July']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('2002', '2002'), (',', ','), ('July', 'juli'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('2002', '2002'), (',', ','), ('July', 'juli'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('(', '('), ('2002', '2002'), (',', ','), ('July', 'July'), (')', ')'), ('.', '.')]


------------------- Sentence 3 -------------------

BLEU: a method for

>> Tokens are: 
 ['BLEU', ':', 'method']

>> Bigrams are: 
 [('BLEU', ':'), (':', 'method')]

>> Trigrams are: 
 [('BLEU', ':', 'method')]

>> POS Tags are: 
 [('BLEU', 'NN'), (':', ':'), ('method', 'NN')]

>> Noun Phrases are: 
 ['BLEU', 'method']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('BLEU', 'bleu'), (':', ':'), ('method', 'method')]

>> Stemming using Snowball Stemmer: 
 [('BLEU', 'bleu'), (':', ':'), ('method', 'method')]

>> Lemmatization: 
 [('BLEU', 'BLEU'), (':', ':'), ('method', 'method')]



========================================== PARAGRAPH 687 ===========================================

automatic evaluation of machine translation. In Proceedings of the 40th annual meeting on  

------------------- Sentence 1 -------------------

automatic evaluation of machine translation.

>> Tokens are: 
 ['automatic', 'evaluation', 'machine', 'translation', '.']

>> Bigrams are: 
 [('automatic', 'evaluation'), ('evaluation', 'machine'), ('machine', 'translation'), ('translation', '.')]

>> Trigrams are: 
 [('automatic', 'evaluation', 'machine'), ('evaluation', 'machine', 'translation'), ('machine', 'translation', '.')]

>> POS Tags are: 
 [('automatic', 'JJ'), ('evaluation', 'NN'), ('machine', 'NN'), ('translation', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['automatic evaluation machine translation']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('automatic', 'automat'), ('evaluation', 'evalu'), ('machine', 'machin'), ('translation', 'translat'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('automatic', 'automat'), ('evaluation', 'evalu'), ('machine', 'machin'), ('translation', 'translat'), ('.', '.')]

>> Lemmatization: 
 [('automatic', 'automatic'), ('evaluation', 'evaluation'), ('machine', 'machine'), ('translation', 'translation'), ('.', '.')]


------------------- Sentence 2 -------------------

In Proceedings of the 40th annual meeting on

>> Tokens are: 
 ['In', 'Proceedings', '40th', 'annual', 'meeting']

>> Bigrams are: 
 [('In', 'Proceedings'), ('Proceedings', '40th'), ('40th', 'annual'), ('annual', 'meeting')]

>> Trigrams are: 
 [('In', 'Proceedings', '40th'), ('Proceedings', '40th', 'annual'), ('40th', 'annual', 'meeting')]

>> POS Tags are: 
 [('In', 'IN'), ('Proceedings', 'NNP'), ('40th', 'CD'), ('annual', 'JJ'), ('meeting', 'NN')]

>> Noun Phrases are: 
 ['Proceedings', 'annual meeting']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('Proceedings', 'proceed'), ('40th', '40th'), ('annual', 'annual'), ('meeting', 'meet')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('Proceedings', 'proceed'), ('40th', '40th'), ('annual', 'annual'), ('meeting', 'meet')]

>> Lemmatization: 
 [('In', 'In'), ('Proceedings', 'Proceedings'), ('40th', '40th'), ('annual', 'annual'), ('meeting', 'meeting')]



========================================== PARAGRAPH 688 ===========================================

association for computational linguistics (pp. 311-318). Association for Computational  

------------------- Sentence 1 -------------------

association for computational linguistics (pp.

>> Tokens are: 
 ['association', 'computational', 'linguistics', '(', 'pp', '.']

>> Bigrams are: 
 [('association', 'computational'), ('computational', 'linguistics'), ('linguistics', '('), ('(', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('association', 'computational', 'linguistics'), ('computational', 'linguistics', '('), ('linguistics', '(', 'pp'), ('(', 'pp', '.')]

>> POS Tags are: 
 [('association', 'NN'), ('computational', 'JJ'), ('linguistics', 'NNS'), ('(', '('), ('pp', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['association', 'computational linguistics', 'pp']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('association', 'associ'), ('computational', 'comput'), ('linguistics', 'linguist'), ('(', '('), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('association', 'associ'), ('computational', 'comput'), ('linguistics', 'linguist'), ('(', '('), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('association', 'association'), ('computational', 'computational'), ('linguistics', 'linguistics'), ('(', '('), ('pp', 'pp'), ('.', '.')]


------------------- Sentence 2 -------------------

311-318).

>> Tokens are: 
 ['311-318', ')', '.']

>> Bigrams are: 
 [('311-318', ')'), (')', '.')]

>> Trigrams are: 
 [('311-318', ')', '.')]

>> POS Tags are: 
 [('311-318', 'JJ'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('311-318', '311-318'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('311-318', '311-318'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('311-318', '311-318'), (')', ')'), ('.', '.')]


------------------- Sentence 3 -------------------

Association for Computational

>> Tokens are: 
 ['Association', 'Computational']

>> Bigrams are: 
 [('Association', 'Computational')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Association', 'NNP'), ('Computational', 'NNP')]

>> Noun Phrases are: 
 ['Association Computational']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Association', 'associ'), ('Computational', 'comput')]

>> Stemming using Snowball Stemmer: 
 [('Association', 'associ'), ('Computational', 'comput')]

>> Lemmatization: 
 [('Association', 'Association'), ('Computational', 'Computational')]



========================================== PARAGRAPH 689 ===========================================

Linguistics  

------------------- Sentence 1 -------------------

Linguistics

>> Tokens are: 
 ['Linguistics']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Linguistics', 'NNS')]

>> Noun Phrases are: 
 ['Linguistics']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Linguistics', 'linguist')]

>> Stemming using Snowball Stemmer: 
 [('Linguistics', 'linguist')]

>> Lemmatization: 
 [('Linguistics', 'Linguistics')]



========================================== PARAGRAPH 690 ===========================================

[41] Doddington, G. (2002, March). Automatic evaluation of machine translation quality  

------------------- Sentence 1 -------------------

[41] Doddington, G. (2002, March).

>> Tokens are: 
 ['[', '41', ']', 'Doddington', ',', 'G.', '(', '2002', ',', 'March', ')', '.']

>> Bigrams are: 
 [('[', '41'), ('41', ']'), (']', 'Doddington'), ('Doddington', ','), (',', 'G.'), ('G.', '('), ('(', '2002'), ('2002', ','), (',', 'March'), ('March', ')'), (')', '.')]

>> Trigrams are: 
 [('[', '41', ']'), ('41', ']', 'Doddington'), (']', 'Doddington', ','), ('Doddington', ',', 'G.'), (',', 'G.', '('), ('G.', '(', '2002'), ('(', '2002', ','), ('2002', ',', 'March'), (',', 'March', ')'), ('March', ')', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('41', 'CD'), (']', 'JJ'), ('Doddington', 'NNP'), (',', ','), ('G.', 'NNP'), ('(', '('), ('2002', 'CD'), (',', ','), ('March', 'NNP'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['] Doddington', 'G.', 'March']

>> Named Entities are: 
 [('PERSON', 'Doddington')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('41', '41'), (']', ']'), ('Doddington', 'doddington'), (',', ','), ('G.', 'g.'), ('(', '('), ('2002', '2002'), (',', ','), ('March', 'march'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('41', '41'), (']', ']'), ('Doddington', 'doddington'), (',', ','), ('G.', 'g.'), ('(', '('), ('2002', '2002'), (',', ','), ('March', 'march'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('41', '41'), (']', ']'), ('Doddington', 'Doddington'), (',', ','), ('G.', 'G.'), ('(', '('), ('2002', '2002'), (',', ','), ('March', 'March'), (')', ')'), ('.', '.')]


------------------- Sentence 2 -------------------

Automatic evaluation of machine translation quality

>> Tokens are: 
 ['Automatic', 'evaluation', 'machine', 'translation', 'quality']

>> Bigrams are: 
 [('Automatic', 'evaluation'), ('evaluation', 'machine'), ('machine', 'translation'), ('translation', 'quality')]

>> Trigrams are: 
 [('Automatic', 'evaluation', 'machine'), ('evaluation', 'machine', 'translation'), ('machine', 'translation', 'quality')]

>> POS Tags are: 
 [('Automatic', 'JJ'), ('evaluation', 'NN'), ('machine', 'NN'), ('translation', 'NN'), ('quality', 'NN')]

>> Noun Phrases are: 
 ['Automatic evaluation machine translation quality']

>> Named Entities are: 
 [('GPE', 'Automatic')] 

>> Stemming using Porter Stemmer: 
 [('Automatic', 'automat'), ('evaluation', 'evalu'), ('machine', 'machin'), ('translation', 'translat'), ('quality', 'qualiti')]

>> Stemming using Snowball Stemmer: 
 [('Automatic', 'automat'), ('evaluation', 'evalu'), ('machine', 'machin'), ('translation', 'translat'), ('quality', 'qualiti')]

>> Lemmatization: 
 [('Automatic', 'Automatic'), ('evaluation', 'evaluation'), ('machine', 'machine'), ('translation', 'translation'), ('quality', 'quality')]



========================================== PARAGRAPH 691 ===========================================

using n-gram co-occurrence statistics. In Proceedings of the second international conference  

------------------- Sentence 1 -------------------

using n-gram co-occurrence statistics.

>> Tokens are: 
 ['using', 'n-gram', 'co-occurrence', 'statistics', '.']

>> Bigrams are: 
 [('using', 'n-gram'), ('n-gram', 'co-occurrence'), ('co-occurrence', 'statistics'), ('statistics', '.')]

>> Trigrams are: 
 [('using', 'n-gram', 'co-occurrence'), ('n-gram', 'co-occurrence', 'statistics'), ('co-occurrence', 'statistics', '.')]

>> POS Tags are: 
 [('using', 'VBG'), ('n-gram', 'JJ'), ('co-occurrence', 'NN'), ('statistics', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['n-gram co-occurrence statistics']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('using', 'use'), ('n-gram', 'n-gram'), ('co-occurrence', 'co-occurr'), ('statistics', 'statist'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('using', 'use'), ('n-gram', 'n-gram'), ('co-occurrence', 'co-occurr'), ('statistics', 'statist'), ('.', '.')]

>> Lemmatization: 
 [('using', 'using'), ('n-gram', 'n-gram'), ('co-occurrence', 'co-occurrence'), ('statistics', 'statistic'), ('.', '.')]


------------------- Sentence 2 -------------------

In Proceedings of the second international conference

>> Tokens are: 
 ['In', 'Proceedings', 'second', 'international', 'conference']

>> Bigrams are: 
 [('In', 'Proceedings'), ('Proceedings', 'second'), ('second', 'international'), ('international', 'conference')]

>> Trigrams are: 
 [('In', 'Proceedings', 'second'), ('Proceedings', 'second', 'international'), ('second', 'international', 'conference')]

>> POS Tags are: 
 [('In', 'IN'), ('Proceedings', 'NNP'), ('second', 'JJ'), ('international', 'JJ'), ('conference', 'NN')]

>> Noun Phrases are: 
 ['Proceedings', 'second international conference']

>> Named Entities are: 
 [('GPE', 'Proceedings')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('Proceedings', 'proceed'), ('second', 'second'), ('international', 'intern'), ('conference', 'confer')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('Proceedings', 'proceed'), ('second', 'second'), ('international', 'intern'), ('conference', 'confer')]

>> Lemmatization: 
 [('In', 'In'), ('Proceedings', 'Proceedings'), ('second', 'second'), ('international', 'international'), ('conference', 'conference')]



========================================== PARAGRAPH 692 ===========================================

on Human Language Technology Research (pp. 138-145). Morgan Kaufmann Publishers Inc   

------------------- Sentence 1 -------------------

on Human Language Technology Research (pp.

>> Tokens are: 
 ['Human', 'Language', 'Technology', 'Research', '(', 'pp', '.']

>> Bigrams are: 
 [('Human', 'Language'), ('Language', 'Technology'), ('Technology', 'Research'), ('Research', '('), ('(', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('Human', 'Language', 'Technology'), ('Language', 'Technology', 'Research'), ('Technology', 'Research', '('), ('Research', '(', 'pp'), ('(', 'pp', '.')]

>> POS Tags are: 
 [('Human', 'JJ'), ('Language', 'NNP'), ('Technology', 'NNP'), ('Research', 'NNP'), ('(', '('), ('pp', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Human Language Technology Research', 'pp']

>> Named Entities are: 
 [('PERSON', 'Human'), ('ORGANIZATION', 'Language Technology')] 

>> Stemming using Porter Stemmer: 
 [('Human', 'human'), ('Language', 'languag'), ('Technology', 'technolog'), ('Research', 'research'), ('(', '('), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Human', 'human'), ('Language', 'languag'), ('Technology', 'technolog'), ('Research', 'research'), ('(', '('), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('Human', 'Human'), ('Language', 'Language'), ('Technology', 'Technology'), ('Research', 'Research'), ('(', '('), ('pp', 'pp'), ('.', '.')]


------------------- Sentence 2 -------------------

138-145).

>> Tokens are: 
 ['138-145', ')', '.']

>> Bigrams are: 
 [('138-145', ')'), (')', '.')]

>> Trigrams are: 
 [('138-145', ')', '.')]

>> POS Tags are: 
 [('138-145', 'JJ'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('138-145', '138-145'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('138-145', '138-145'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('138-145', '138-145'), (')', ')'), ('.', '.')]


------------------- Sentence 3 -------------------

Morgan Kaufmann Publishers Inc

>> Tokens are: 
 ['Morgan', 'Kaufmann', 'Publishers', 'Inc']

>> Bigrams are: 
 [('Morgan', 'Kaufmann'), ('Kaufmann', 'Publishers'), ('Publishers', 'Inc')]

>> Trigrams are: 
 [('Morgan', 'Kaufmann', 'Publishers'), ('Kaufmann', 'Publishers', 'Inc')]

>> POS Tags are: 
 [('Morgan', 'NNP'), ('Kaufmann', 'NNP'), ('Publishers', 'NNP'), ('Inc', 'NNP')]

>> Noun Phrases are: 
 ['Morgan Kaufmann Publishers Inc']

>> Named Entities are: 
 [('PERSON', 'Morgan'), ('PERSON', 'Kaufmann Publishers Inc')] 

>> Stemming using Porter Stemmer: 
 [('Morgan', 'morgan'), ('Kaufmann', 'kaufmann'), ('Publishers', 'publish'), ('Inc', 'inc')]

>> Stemming using Snowball Stemmer: 
 [('Morgan', 'morgan'), ('Kaufmann', 'kaufmann'), ('Publishers', 'publish'), ('Inc', 'inc')]

>> Lemmatization: 
 [('Morgan', 'Morgan'), ('Kaufmann', 'Kaufmann'), ('Publishers', 'Publishers'), ('Inc', 'Inc')]



========================================== PARAGRAPH 693 ===========================================

[42] Papineni, K., Roukos, S., Ward, T., & Zhu, W. J. (2002, July). BLEU: a method for  

------------------- Sentence 1 -------------------

[42] Papineni, K., Roukos, S., Ward, T., & Zhu, W. J.

>> Tokens are: 
 ['[', '42', ']', 'Papineni', ',', 'K.', ',', 'Roukos', ',', 'S.', ',', 'Ward', ',', 'T.', ',', '&', 'Zhu', ',', 'W.', 'J', '.']

>> Bigrams are: 
 [('[', '42'), ('42', ']'), (']', 'Papineni'), ('Papineni', ','), (',', 'K.'), ('K.', ','), (',', 'Roukos'), ('Roukos', ','), (',', 'S.'), ('S.', ','), (',', 'Ward'), ('Ward', ','), (',', 'T.'), ('T.', ','), (',', '&'), ('&', 'Zhu'), ('Zhu', ','), (',', 'W.'), ('W.', 'J'), ('J', '.')]

>> Trigrams are: 
 [('[', '42', ']'), ('42', ']', 'Papineni'), (']', 'Papineni', ','), ('Papineni', ',', 'K.'), (',', 'K.', ','), ('K.', ',', 'Roukos'), (',', 'Roukos', ','), ('Roukos', ',', 'S.'), (',', 'S.', ','), ('S.', ',', 'Ward'), (',', 'Ward', ','), ('Ward', ',', 'T.'), (',', 'T.', ','), ('T.', ',', '&'), (',', '&', 'Zhu'), ('&', 'Zhu', ','), ('Zhu', ',', 'W.'), (',', 'W.', 'J'), ('W.', 'J', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('42', 'CD'), (']', 'JJ'), ('Papineni', 'NNP'), (',', ','), ('K.', 'NNP'), (',', ','), ('Roukos', 'NNP'), (',', ','), ('S.', 'NNP'), (',', ','), ('Ward', 'NNP'), (',', ','), ('T.', 'NNP'), (',', ','), ('&', 'CC'), ('Zhu', 'NNP'), (',', ','), ('W.', 'NNP'), ('J', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['] Papineni', 'K.', 'Roukos', 'S.', 'Ward', 'T.', 'Zhu', 'W. J']

>> Named Entities are: 
 [('PERSON', 'Papineni'), ('GPE', 'Roukos'), ('PERSON', 'Ward'), ('PERSON', 'Zhu')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('42', '42'), (']', ']'), ('Papineni', 'papineni'), (',', ','), ('K.', 'k.'), (',', ','), ('Roukos', 'rouko'), (',', ','), ('S.', 's.'), (',', ','), ('Ward', 'ward'), (',', ','), ('T.', 't.'), (',', ','), ('&', '&'), ('Zhu', 'zhu'), (',', ','), ('W.', 'w.'), ('J', 'j'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('42', '42'), (']', ']'), ('Papineni', 'papineni'), (',', ','), ('K.', 'k.'), (',', ','), ('Roukos', 'rouko'), (',', ','), ('S.', 's.'), (',', ','), ('Ward', 'ward'), (',', ','), ('T.', 't.'), (',', ','), ('&', '&'), ('Zhu', 'zhu'), (',', ','), ('W.', 'w.'), ('J', 'j'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('42', '42'), (']', ']'), ('Papineni', 'Papineni'), (',', ','), ('K.', 'K.'), (',', ','), ('Roukos', 'Roukos'), (',', ','), ('S.', 'S.'), (',', ','), ('Ward', 'Ward'), (',', ','), ('T.', 'T.'), (',', ','), ('&', '&'), ('Zhu', 'Zhu'), (',', ','), ('W.', 'W.'), ('J', 'J'), ('.', '.')]


------------------- Sentence 2 -------------------

(2002, July).

>> Tokens are: 
 ['(', '2002', ',', 'July', ')', '.']

>> Bigrams are: 
 [('(', '2002'), ('2002', ','), (',', 'July'), ('July', ')'), (')', '.')]

>> Trigrams are: 
 [('(', '2002', ','), ('2002', ',', 'July'), (',', 'July', ')'), ('July', ')', '.')]

>> POS Tags are: 
 [('(', '('), ('2002', 'CD'), (',', ','), ('July', 'NNP'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['July']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('2002', '2002'), (',', ','), ('July', 'juli'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('2002', '2002'), (',', ','), ('July', 'juli'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('(', '('), ('2002', '2002'), (',', ','), ('July', 'July'), (')', ')'), ('.', '.')]


------------------- Sentence 3 -------------------

BLEU: a method for

>> Tokens are: 
 ['BLEU', ':', 'method']

>> Bigrams are: 
 [('BLEU', ':'), (':', 'method')]

>> Trigrams are: 
 [('BLEU', ':', 'method')]

>> POS Tags are: 
 [('BLEU', 'NN'), (':', ':'), ('method', 'NN')]

>> Noun Phrases are: 
 ['BLEU', 'method']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('BLEU', 'bleu'), (':', ':'), ('method', 'method')]

>> Stemming using Snowball Stemmer: 
 [('BLEU', 'bleu'), (':', ':'), ('method', 'method')]

>> Lemmatization: 
 [('BLEU', 'BLEU'), (':', ':'), ('method', 'method')]



========================================== PARAGRAPH 694 ===========================================

automatic evaluation of machine translation. In Proceedings of the 40th annual meeting on  

------------------- Sentence 1 -------------------

automatic evaluation of machine translation.

>> Tokens are: 
 ['automatic', 'evaluation', 'machine', 'translation', '.']

>> Bigrams are: 
 [('automatic', 'evaluation'), ('evaluation', 'machine'), ('machine', 'translation'), ('translation', '.')]

>> Trigrams are: 
 [('automatic', 'evaluation', 'machine'), ('evaluation', 'machine', 'translation'), ('machine', 'translation', '.')]

>> POS Tags are: 
 [('automatic', 'JJ'), ('evaluation', 'NN'), ('machine', 'NN'), ('translation', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['automatic evaluation machine translation']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('automatic', 'automat'), ('evaluation', 'evalu'), ('machine', 'machin'), ('translation', 'translat'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('automatic', 'automat'), ('evaluation', 'evalu'), ('machine', 'machin'), ('translation', 'translat'), ('.', '.')]

>> Lemmatization: 
 [('automatic', 'automatic'), ('evaluation', 'evaluation'), ('machine', 'machine'), ('translation', 'translation'), ('.', '.')]


------------------- Sentence 2 -------------------

In Proceedings of the 40th annual meeting on

>> Tokens are: 
 ['In', 'Proceedings', '40th', 'annual', 'meeting']

>> Bigrams are: 
 [('In', 'Proceedings'), ('Proceedings', '40th'), ('40th', 'annual'), ('annual', 'meeting')]

>> Trigrams are: 
 [('In', 'Proceedings', '40th'), ('Proceedings', '40th', 'annual'), ('40th', 'annual', 'meeting')]

>> POS Tags are: 
 [('In', 'IN'), ('Proceedings', 'NNP'), ('40th', 'CD'), ('annual', 'JJ'), ('meeting', 'NN')]

>> Noun Phrases are: 
 ['Proceedings', 'annual meeting']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('Proceedings', 'proceed'), ('40th', '40th'), ('annual', 'annual'), ('meeting', 'meet')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('Proceedings', 'proceed'), ('40th', '40th'), ('annual', 'annual'), ('meeting', 'meet')]

>> Lemmatization: 
 [('In', 'In'), ('Proceedings', 'Proceedings'), ('40th', '40th'), ('annual', 'annual'), ('meeting', 'meeting')]



========================================== PARAGRAPH 695 ===========================================

association for computational linguistics (pp. 311-318). Association for Computational  

------------------- Sentence 1 -------------------

association for computational linguistics (pp.

>> Tokens are: 
 ['association', 'computational', 'linguistics', '(', 'pp', '.']

>> Bigrams are: 
 [('association', 'computational'), ('computational', 'linguistics'), ('linguistics', '('), ('(', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('association', 'computational', 'linguistics'), ('computational', 'linguistics', '('), ('linguistics', '(', 'pp'), ('(', 'pp', '.')]

>> POS Tags are: 
 [('association', 'NN'), ('computational', 'JJ'), ('linguistics', 'NNS'), ('(', '('), ('pp', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['association', 'computational linguistics', 'pp']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('association', 'associ'), ('computational', 'comput'), ('linguistics', 'linguist'), ('(', '('), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('association', 'associ'), ('computational', 'comput'), ('linguistics', 'linguist'), ('(', '('), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('association', 'association'), ('computational', 'computational'), ('linguistics', 'linguistics'), ('(', '('), ('pp', 'pp'), ('.', '.')]


------------------- Sentence 2 -------------------

311-318).

>> Tokens are: 
 ['311-318', ')', '.']

>> Bigrams are: 
 [('311-318', ')'), (')', '.')]

>> Trigrams are: 
 [('311-318', ')', '.')]

>> POS Tags are: 
 [('311-318', 'JJ'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('311-318', '311-318'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('311-318', '311-318'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('311-318', '311-318'), (')', ')'), ('.', '.')]


------------------- Sentence 3 -------------------

Association for Computational

>> Tokens are: 
 ['Association', 'Computational']

>> Bigrams are: 
 [('Association', 'Computational')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Association', 'NNP'), ('Computational', 'NNP')]

>> Noun Phrases are: 
 ['Association Computational']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Association', 'associ'), ('Computational', 'comput')]

>> Stemming using Snowball Stemmer: 
 [('Association', 'associ'), ('Computational', 'comput')]

>> Lemmatization: 
 [('Association', 'Association'), ('Computational', 'Computational')]



========================================== PARAGRAPH 696 ===========================================

Linguistics  

------------------- Sentence 1 -------------------

Linguistics

>> Tokens are: 
 ['Linguistics']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Linguistics', 'NNS')]

>> Noun Phrases are: 
 ['Linguistics']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Linguistics', 'linguist')]

>> Stemming using Snowball Stemmer: 
 [('Linguistics', 'linguist')]

>> Lemmatization: 
 [('Linguistics', 'Linguistics')]



========================================== PARAGRAPH 697 ===========================================

[43] Doddington, G. (2002, March). Automatic evaluation of machine translation quality  

------------------- Sentence 1 -------------------

[43] Doddington, G. (2002, March).

>> Tokens are: 
 ['[', '43', ']', 'Doddington', ',', 'G.', '(', '2002', ',', 'March', ')', '.']

>> Bigrams are: 
 [('[', '43'), ('43', ']'), (']', 'Doddington'), ('Doddington', ','), (',', 'G.'), ('G.', '('), ('(', '2002'), ('2002', ','), (',', 'March'), ('March', ')'), (')', '.')]

>> Trigrams are: 
 [('[', '43', ']'), ('43', ']', 'Doddington'), (']', 'Doddington', ','), ('Doddington', ',', 'G.'), (',', 'G.', '('), ('G.', '(', '2002'), ('(', '2002', ','), ('2002', ',', 'March'), (',', 'March', ')'), ('March', ')', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('43', 'CD'), (']', 'JJ'), ('Doddington', 'NNP'), (',', ','), ('G.', 'NNP'), ('(', '('), ('2002', 'CD'), (',', ','), ('March', 'NNP'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['] Doddington', 'G.', 'March']

>> Named Entities are: 
 [('PERSON', 'Doddington')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('43', '43'), (']', ']'), ('Doddington', 'doddington'), (',', ','), ('G.', 'g.'), ('(', '('), ('2002', '2002'), (',', ','), ('March', 'march'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('43', '43'), (']', ']'), ('Doddington', 'doddington'), (',', ','), ('G.', 'g.'), ('(', '('), ('2002', '2002'), (',', ','), ('March', 'march'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('43', '43'), (']', ']'), ('Doddington', 'Doddington'), (',', ','), ('G.', 'G.'), ('(', '('), ('2002', '2002'), (',', ','), ('March', 'March'), (')', ')'), ('.', '.')]


------------------- Sentence 2 -------------------

Automatic evaluation of machine translation quality

>> Tokens are: 
 ['Automatic', 'evaluation', 'machine', 'translation', 'quality']

>> Bigrams are: 
 [('Automatic', 'evaluation'), ('evaluation', 'machine'), ('machine', 'translation'), ('translation', 'quality')]

>> Trigrams are: 
 [('Automatic', 'evaluation', 'machine'), ('evaluation', 'machine', 'translation'), ('machine', 'translation', 'quality')]

>> POS Tags are: 
 [('Automatic', 'JJ'), ('evaluation', 'NN'), ('machine', 'NN'), ('translation', 'NN'), ('quality', 'NN')]

>> Noun Phrases are: 
 ['Automatic evaluation machine translation quality']

>> Named Entities are: 
 [('GPE', 'Automatic')] 

>> Stemming using Porter Stemmer: 
 [('Automatic', 'automat'), ('evaluation', 'evalu'), ('machine', 'machin'), ('translation', 'translat'), ('quality', 'qualiti')]

>> Stemming using Snowball Stemmer: 
 [('Automatic', 'automat'), ('evaluation', 'evalu'), ('machine', 'machin'), ('translation', 'translat'), ('quality', 'qualiti')]

>> Lemmatization: 
 [('Automatic', 'Automatic'), ('evaluation', 'evaluation'), ('machine', 'machine'), ('translation', 'translation'), ('quality', 'quality')]



========================================== PARAGRAPH 698 ===========================================

using n-gram co-occurrence statistics. In Proceedings of the second international conference  

------------------- Sentence 1 -------------------

using n-gram co-occurrence statistics.

>> Tokens are: 
 ['using', 'n-gram', 'co-occurrence', 'statistics', '.']

>> Bigrams are: 
 [('using', 'n-gram'), ('n-gram', 'co-occurrence'), ('co-occurrence', 'statistics'), ('statistics', '.')]

>> Trigrams are: 
 [('using', 'n-gram', 'co-occurrence'), ('n-gram', 'co-occurrence', 'statistics'), ('co-occurrence', 'statistics', '.')]

>> POS Tags are: 
 [('using', 'VBG'), ('n-gram', 'JJ'), ('co-occurrence', 'NN'), ('statistics', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['n-gram co-occurrence statistics']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('using', 'use'), ('n-gram', 'n-gram'), ('co-occurrence', 'co-occurr'), ('statistics', 'statist'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('using', 'use'), ('n-gram', 'n-gram'), ('co-occurrence', 'co-occurr'), ('statistics', 'statist'), ('.', '.')]

>> Lemmatization: 
 [('using', 'using'), ('n-gram', 'n-gram'), ('co-occurrence', 'co-occurrence'), ('statistics', 'statistic'), ('.', '.')]


------------------- Sentence 2 -------------------

In Proceedings of the second international conference

>> Tokens are: 
 ['In', 'Proceedings', 'second', 'international', 'conference']

>> Bigrams are: 
 [('In', 'Proceedings'), ('Proceedings', 'second'), ('second', 'international'), ('international', 'conference')]

>> Trigrams are: 
 [('In', 'Proceedings', 'second'), ('Proceedings', 'second', 'international'), ('second', 'international', 'conference')]

>> POS Tags are: 
 [('In', 'IN'), ('Proceedings', 'NNP'), ('second', 'JJ'), ('international', 'JJ'), ('conference', 'NN')]

>> Noun Phrases are: 
 ['Proceedings', 'second international conference']

>> Named Entities are: 
 [('GPE', 'Proceedings')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('Proceedings', 'proceed'), ('second', 'second'), ('international', 'intern'), ('conference', 'confer')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('Proceedings', 'proceed'), ('second', 'second'), ('international', 'intern'), ('conference', 'confer')]

>> Lemmatization: 
 [('In', 'In'), ('Proceedings', 'Proceedings'), ('second', 'second'), ('international', 'international'), ('conference', 'conference')]



========================================== PARAGRAPH 699 ===========================================

on Human Language Technology Research (pp. 138-145). Morgan Kaufmann Publishers Inc 

------------------- Sentence 1 -------------------

on Human Language Technology Research (pp.

>> Tokens are: 
 ['Human', 'Language', 'Technology', 'Research', '(', 'pp', '.']

>> Bigrams are: 
 [('Human', 'Language'), ('Language', 'Technology'), ('Technology', 'Research'), ('Research', '('), ('(', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('Human', 'Language', 'Technology'), ('Language', 'Technology', 'Research'), ('Technology', 'Research', '('), ('Research', '(', 'pp'), ('(', 'pp', '.')]

>> POS Tags are: 
 [('Human', 'JJ'), ('Language', 'NNP'), ('Technology', 'NNP'), ('Research', 'NNP'), ('(', '('), ('pp', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Human Language Technology Research', 'pp']

>> Named Entities are: 
 [('PERSON', 'Human'), ('ORGANIZATION', 'Language Technology')] 

>> Stemming using Porter Stemmer: 
 [('Human', 'human'), ('Language', 'languag'), ('Technology', 'technolog'), ('Research', 'research'), ('(', '('), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Human', 'human'), ('Language', 'languag'), ('Technology', 'technolog'), ('Research', 'research'), ('(', '('), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('Human', 'Human'), ('Language', 'Language'), ('Technology', 'Technology'), ('Research', 'Research'), ('(', '('), ('pp', 'pp'), ('.', '.')]


------------------- Sentence 2 -------------------

138-145).

>> Tokens are: 
 ['138-145', ')', '.']

>> Bigrams are: 
 [('138-145', ')'), (')', '.')]

>> Trigrams are: 
 [('138-145', ')', '.')]

>> POS Tags are: 
 [('138-145', 'JJ'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('138-145', '138-145'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('138-145', '138-145'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('138-145', '138-145'), (')', ')'), ('.', '.')]


------------------- Sentence 3 -------------------

Morgan Kaufmann Publishers Inc

>> Tokens are: 
 ['Morgan', 'Kaufmann', 'Publishers', 'Inc']

>> Bigrams are: 
 [('Morgan', 'Kaufmann'), ('Kaufmann', 'Publishers'), ('Publishers', 'Inc')]

>> Trigrams are: 
 [('Morgan', 'Kaufmann', 'Publishers'), ('Kaufmann', 'Publishers', 'Inc')]

>> POS Tags are: 
 [('Morgan', 'NNP'), ('Kaufmann', 'NNP'), ('Publishers', 'NNP'), ('Inc', 'NNP')]

>> Noun Phrases are: 
 ['Morgan Kaufmann Publishers Inc']

>> Named Entities are: 
 [('PERSON', 'Morgan'), ('PERSON', 'Kaufmann Publishers Inc')] 

>> Stemming using Porter Stemmer: 
 [('Morgan', 'morgan'), ('Kaufmann', 'kaufmann'), ('Publishers', 'publish'), ('Inc', 'inc')]

>> Stemming using Snowball Stemmer: 
 [('Morgan', 'morgan'), ('Kaufmann', 'kaufmann'), ('Publishers', 'publish'), ('Inc', 'inc')]

>> Lemmatization: 
 [('Morgan', 'Morgan'), ('Kaufmann', 'Kaufmann'), ('Publishers', 'Publishers'), ('Inc', 'Inc')]



========================================== PARAGRAPH 700 ===========================================

[44] Hayes, P. J. (1992). Intelligent high-volume text processing using shallow, domain- 

------------------- Sentence 1 -------------------

[44] Hayes, P. J.

>> Tokens are: 
 ['[', '44', ']', 'Hayes', ',', 'P.', 'J', '.']

>> Bigrams are: 
 [('[', '44'), ('44', ']'), (']', 'Hayes'), ('Hayes', ','), (',', 'P.'), ('P.', 'J'), ('J', '.')]

>> Trigrams are: 
 [('[', '44', ']'), ('44', ']', 'Hayes'), (']', 'Hayes', ','), ('Hayes', ',', 'P.'), (',', 'P.', 'J'), ('P.', 'J', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('44', 'CD'), (']', 'JJ'), ('Hayes', 'NNP'), (',', ','), ('P.', 'NNP'), ('J', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['] Hayes', 'P. J']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('44', '44'), (']', ']'), ('Hayes', 'hay'), (',', ','), ('P.', 'p.'), ('J', 'j'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('44', '44'), (']', ']'), ('Hayes', 'hay'), (',', ','), ('P.', 'p.'), ('J', 'j'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('44', '44'), (']', ']'), ('Hayes', 'Hayes'), (',', ','), ('P.', 'P.'), ('J', 'J'), ('.', '.')]


------------------- Sentence 2 -------------------

(1992).

>> Tokens are: 
 ['(', '1992', ')', '.']

>> Bigrams are: 
 [('(', '1992'), ('1992', ')'), (')', '.')]

>> Trigrams are: 
 [('(', '1992', ')'), ('1992', ')', '.')]

>> POS Tags are: 
 [('(', '('), ('1992', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('1992', '1992'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('1992', '1992'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('(', '('), ('1992', '1992'), (')', ')'), ('.', '.')]


------------------- Sentence 3 -------------------

Intelligent high-volume text processing using shallow, domain-

>> Tokens are: 
 ['Intelligent', 'high-volume', 'text', 'processing', 'using', 'shallow', ',', 'domain-']

>> Bigrams are: 
 [('Intelligent', 'high-volume'), ('high-volume', 'text'), ('text', 'processing'), ('processing', 'using'), ('using', 'shallow'), ('shallow', ','), (',', 'domain-')]

>> Trigrams are: 
 [('Intelligent', 'high-volume', 'text'), ('high-volume', 'text', 'processing'), ('text', 'processing', 'using'), ('processing', 'using', 'shallow'), ('using', 'shallow', ','), ('shallow', ',', 'domain-')]

>> POS Tags are: 
 [('Intelligent', 'JJ'), ('high-volume', 'JJ'), ('text', 'NN'), ('processing', 'NN'), ('using', 'VBG'), ('shallow', 'JJ'), (',', ','), ('domain-', 'JJ')]

>> Noun Phrases are: 
 ['Intelligent high-volume text processing']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Intelligent', 'intellig'), ('high-volume', 'high-volum'), ('text', 'text'), ('processing', 'process'), ('using', 'use'), ('shallow', 'shallow'), (',', ','), ('domain-', 'domain-')]

>> Stemming using Snowball Stemmer: 
 [('Intelligent', 'intellig'), ('high-volume', 'high-volum'), ('text', 'text'), ('processing', 'process'), ('using', 'use'), ('shallow', 'shallow'), (',', ','), ('domain-', 'domain-')]

>> Lemmatization: 
 [('Intelligent', 'Intelligent'), ('high-volume', 'high-volume'), ('text', 'text'), ('processing', 'processing'), ('using', 'using'), ('shallow', 'shallow'), (',', ','), ('domain-', 'domain-')]



========================================== PARAGRAPH 701 ===========================================

specific techniques. Text-based intelligent systems: Current research and practice in  

------------------- Sentence 1 -------------------

specific techniques.

>> Tokens are: 
 ['specific', 'techniques', '.']

>> Bigrams are: 
 [('specific', 'techniques'), ('techniques', '.')]

>> Trigrams are: 
 [('specific', 'techniques', '.')]

>> POS Tags are: 
 [('specific', 'JJ'), ('techniques', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['specific techniques']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('specific', 'specif'), ('techniques', 'techniqu'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('specific', 'specif'), ('techniques', 'techniqu'), ('.', '.')]

>> Lemmatization: 
 [('specific', 'specific'), ('techniques', 'technique'), ('.', '.')]


------------------- Sentence 2 -------------------

Text-based intelligent systems: Current research and practice in

>> Tokens are: 
 ['Text-based', 'intelligent', 'systems', ':', 'Current', 'research', 'practice']

>> Bigrams are: 
 [('Text-based', 'intelligent'), ('intelligent', 'systems'), ('systems', ':'), (':', 'Current'), ('Current', 'research'), ('research', 'practice')]

>> Trigrams are: 
 [('Text-based', 'intelligent', 'systems'), ('intelligent', 'systems', ':'), ('systems', ':', 'Current'), (':', 'Current', 'research'), ('Current', 'research', 'practice')]

>> POS Tags are: 
 [('Text-based', 'JJ'), ('intelligent', 'JJ'), ('systems', 'NNS'), (':', ':'), ('Current', 'NNP'), ('research', 'NN'), ('practice', 'NN')]

>> Noun Phrases are: 
 ['Text-based intelligent systems', 'Current research practice']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Text-based', 'text-bas'), ('intelligent', 'intellig'), ('systems', 'system'), (':', ':'), ('Current', 'current'), ('research', 'research'), ('practice', 'practic')]

>> Stemming using Snowball Stemmer: 
 [('Text-based', 'text-bas'), ('intelligent', 'intellig'), ('systems', 'system'), (':', ':'), ('Current', 'current'), ('research', 'research'), ('practice', 'practic')]

>> Lemmatization: 
 [('Text-based', 'Text-based'), ('intelligent', 'intelligent'), ('systems', 'system'), (':', ':'), ('Current', 'Current'), ('research', 'research'), ('practice', 'practice')]



========================================== PARAGRAPH 702 ===========================================

information extraction and retrieval, 227-242.  

------------------- Sentence 1 -------------------

information extraction and retrieval, 227-242.

>> Tokens are: 
 ['information', 'extraction', 'retrieval', ',', '227-242', '.']

>> Bigrams are: 
 [('information', 'extraction'), ('extraction', 'retrieval'), ('retrieval', ','), (',', '227-242'), ('227-242', '.')]

>> Trigrams are: 
 [('information', 'extraction', 'retrieval'), ('extraction', 'retrieval', ','), ('retrieval', ',', '227-242'), (',', '227-242', '.')]

>> POS Tags are: 
 [('information', 'NN'), ('extraction', 'NN'), ('retrieval', 'NN'), (',', ','), ('227-242', 'JJ'), ('.', '.')]

>> Noun Phrases are: 
 ['information extraction retrieval']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('information', 'inform'), ('extraction', 'extract'), ('retrieval', 'retriev'), (',', ','), ('227-242', '227-242'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('information', 'inform'), ('extraction', 'extract'), ('retrieval', 'retriev'), (',', ','), ('227-242', '227-242'), ('.', '.')]

>> Lemmatization: 
 [('information', 'information'), ('extraction', 'extraction'), ('retrieval', 'retrieval'), (',', ','), ('227-242', '227-242'), ('.', '.')]



========================================== PARAGRAPH 703 ===========================================

[45] Cohen, W. W. (1996, March). Learning rules that classify e-mail. In AAAI spring  

------------------- Sentence 1 -------------------

[45] Cohen, W. W. (1996, March).

>> Tokens are: 
 ['[', '45', ']', 'Cohen', ',', 'W.', 'W.', '(', '1996', ',', 'March', ')', '.']

>> Bigrams are: 
 [('[', '45'), ('45', ']'), (']', 'Cohen'), ('Cohen', ','), (',', 'W.'), ('W.', 'W.'), ('W.', '('), ('(', '1996'), ('1996', ','), (',', 'March'), ('March', ')'), (')', '.')]

>> Trigrams are: 
 [('[', '45', ']'), ('45', ']', 'Cohen'), (']', 'Cohen', ','), ('Cohen', ',', 'W.'), (',', 'W.', 'W.'), ('W.', 'W.', '('), ('W.', '(', '1996'), ('(', '1996', ','), ('1996', ',', 'March'), (',', 'March', ')'), ('March', ')', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('45', 'CD'), (']', 'NN'), ('Cohen', 'NNP'), (',', ','), ('W.', 'NNP'), ('W.', 'NNP'), ('(', '('), ('1996', 'CD'), (',', ','), ('March', 'NNP'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['] Cohen', 'W. W.', 'March']

>> Named Entities are: 
 [('PERSON', 'Cohen')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('45', '45'), (']', ']'), ('Cohen', 'cohen'), (',', ','), ('W.', 'w.'), ('W.', 'w.'), ('(', '('), ('1996', '1996'), (',', ','), ('March', 'march'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('45', '45'), (']', ']'), ('Cohen', 'cohen'), (',', ','), ('W.', 'w.'), ('W.', 'w.'), ('(', '('), ('1996', '1996'), (',', ','), ('March', 'march'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('45', '45'), (']', ']'), ('Cohen', 'Cohen'), (',', ','), ('W.', 'W.'), ('W.', 'W.'), ('(', '('), ('1996', '1996'), (',', ','), ('March', 'March'), (')', ')'), ('.', '.')]


------------------- Sentence 2 -------------------

Learning rules that classify e-mail.

>> Tokens are: 
 ['Learning', 'rules', 'classify', 'e-mail', '.']

>> Bigrams are: 
 [('Learning', 'rules'), ('rules', 'classify'), ('classify', 'e-mail'), ('e-mail', '.')]

>> Trigrams are: 
 [('Learning', 'rules', 'classify'), ('rules', 'classify', 'e-mail'), ('classify', 'e-mail', '.')]

>> POS Tags are: 
 [('Learning', 'VBG'), ('rules', 'NNS'), ('classify', 'VB'), ('e-mail', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['rules', 'e-mail']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Learning', 'learn'), ('rules', 'rule'), ('classify', 'classifi'), ('e-mail', 'e-mail'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Learning', 'learn'), ('rules', 'rule'), ('classify', 'classifi'), ('e-mail', 'e-mail'), ('.', '.')]

>> Lemmatization: 
 [('Learning', 'Learning'), ('rules', 'rule'), ('classify', 'classify'), ('e-mail', 'e-mail'), ('.', '.')]


------------------- Sentence 3 -------------------

In AAAI spring

>> Tokens are: 
 ['In', 'AAAI', 'spring']

>> Bigrams are: 
 [('In', 'AAAI'), ('AAAI', 'spring')]

>> Trigrams are: 
 [('In', 'AAAI', 'spring')]

>> POS Tags are: 
 [('In', 'IN'), ('AAAI', 'NNP'), ('spring', 'NN')]

>> Noun Phrases are: 
 ['AAAI spring']

>> Named Entities are: 
 [('GPE', 'AAAI')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('AAAI', 'aaai'), ('spring', 'spring')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('AAAI', 'aaai'), ('spring', 'spring')]

>> Lemmatization: 
 [('In', 'In'), ('AAAI', 'AAAI'), ('spring', 'spring')]



========================================== PARAGRAPH 704 ===========================================

symposium on machine learning in information access (Vol. 18, p. 25).  

------------------- Sentence 1 -------------------

symposium on machine learning in information access (Vol.

>> Tokens are: 
 ['symposium', 'machine', 'learning', 'information', 'access', '(', 'Vol', '.']

>> Bigrams are: 
 [('symposium', 'machine'), ('machine', 'learning'), ('learning', 'information'), ('information', 'access'), ('access', '('), ('(', 'Vol'), ('Vol', '.')]

>> Trigrams are: 
 [('symposium', 'machine', 'learning'), ('machine', 'learning', 'information'), ('learning', 'information', 'access'), ('information', 'access', '('), ('access', '(', 'Vol'), ('(', 'Vol', '.')]

>> POS Tags are: 
 [('symposium', 'NN'), ('machine', 'NN'), ('learning', 'VBG'), ('information', 'NN'), ('access', 'NN'), ('(', '('), ('Vol', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['symposium machine', 'information access', 'Vol']

>> Named Entities are: 
 [('ORGANIZATION', 'Vol')] 

>> Stemming using Porter Stemmer: 
 [('symposium', 'symposium'), ('machine', 'machin'), ('learning', 'learn'), ('information', 'inform'), ('access', 'access'), ('(', '('), ('Vol', 'vol'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('symposium', 'symposium'), ('machine', 'machin'), ('learning', 'learn'), ('information', 'inform'), ('access', 'access'), ('(', '('), ('Vol', 'vol'), ('.', '.')]

>> Lemmatization: 
 [('symposium', 'symposium'), ('machine', 'machine'), ('learning', 'learning'), ('information', 'information'), ('access', 'access'), ('(', '('), ('Vol', 'Vol'), ('.', '.')]


------------------- Sentence 2 -------------------

18, p. 25).

>> Tokens are: 
 ['18', ',', 'p.', '25', ')', '.']

>> Bigrams are: 
 [('18', ','), (',', 'p.'), ('p.', '25'), ('25', ')'), (')', '.')]

>> Trigrams are: 
 [('18', ',', 'p.'), (',', 'p.', '25'), ('p.', '25', ')'), ('25', ')', '.')]

>> POS Tags are: 
 [('18', 'CD'), (',', ','), ('p.', 'RB'), ('25', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('18', '18'), (',', ','), ('p.', 'p.'), ('25', '25'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('18', '18'), (',', ','), ('p.', 'p.'), ('25', '25'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('18', '18'), (',', ','), ('p.', 'p.'), ('25', '25'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 705 ===========================================

[46] Sahami, M., Dumais, S., Heckerman, D., & Horvitz, E. (1998, July). A Bayesian  

------------------- Sentence 1 -------------------

[46] Sahami, M., Dumais, S., Heckerman, D., & Horvitz, E. (1998, July).

>> Tokens are: 
 ['[', '46', ']', 'Sahami', ',', 'M.', ',', 'Dumais', ',', 'S.', ',', 'Heckerman', ',', 'D.', ',', '&', 'Horvitz', ',', 'E.', '(', '1998', ',', 'July', ')', '.']

>> Bigrams are: 
 [('[', '46'), ('46', ']'), (']', 'Sahami'), ('Sahami', ','), (',', 'M.'), ('M.', ','), (',', 'Dumais'), ('Dumais', ','), (',', 'S.'), ('S.', ','), (',', 'Heckerman'), ('Heckerman', ','), (',', 'D.'), ('D.', ','), (',', '&'), ('&', 'Horvitz'), ('Horvitz', ','), (',', 'E.'), ('E.', '('), ('(', '1998'), ('1998', ','), (',', 'July'), ('July', ')'), (')', '.')]

>> Trigrams are: 
 [('[', '46', ']'), ('46', ']', 'Sahami'), (']', 'Sahami', ','), ('Sahami', ',', 'M.'), (',', 'M.', ','), ('M.', ',', 'Dumais'), (',', 'Dumais', ','), ('Dumais', ',', 'S.'), (',', 'S.', ','), ('S.', ',', 'Heckerman'), (',', 'Heckerman', ','), ('Heckerman', ',', 'D.'), (',', 'D.', ','), ('D.', ',', '&'), (',', '&', 'Horvitz'), ('&', 'Horvitz', ','), ('Horvitz', ',', 'E.'), (',', 'E.', '('), ('E.', '(', '1998'), ('(', '1998', ','), ('1998', ',', 'July'), (',', 'July', ')'), ('July', ')', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('46', 'CD'), (']', 'NNP'), ('Sahami', 'NNP'), (',', ','), ('M.', 'NNP'), (',', ','), ('Dumais', 'NNP'), (',', ','), ('S.', 'NNP'), (',', ','), ('Heckerman', 'NNP'), (',', ','), ('D.', 'NNP'), (',', ','), ('&', 'CC'), ('Horvitz', 'NNP'), (',', ','), ('E.', 'NNP'), ('(', '('), ('1998', 'CD'), (',', ','), ('July', 'NNP'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['] Sahami', 'M.', 'Dumais', 'S.', 'Heckerman', 'D.', 'Horvitz', 'E.', 'July']

>> Named Entities are: 
 [('GPE', 'Dumais'), ('PERSON', 'Heckerman'), ('PERSON', 'Horvitz')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('46', '46'), (']', ']'), ('Sahami', 'sahami'), (',', ','), ('M.', 'm.'), (',', ','), ('Dumais', 'dumai'), (',', ','), ('S.', 's.'), (',', ','), ('Heckerman', 'heckerman'), (',', ','), ('D.', 'd.'), (',', ','), ('&', '&'), ('Horvitz', 'horvitz'), (',', ','), ('E.', 'e.'), ('(', '('), ('1998', '1998'), (',', ','), ('July', 'juli'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('46', '46'), (']', ']'), ('Sahami', 'sahami'), (',', ','), ('M.', 'm.'), (',', ','), ('Dumais', 'dumai'), (',', ','), ('S.', 's.'), (',', ','), ('Heckerman', 'heckerman'), (',', ','), ('D.', 'd.'), (',', ','), ('&', '&'), ('Horvitz', 'horvitz'), (',', ','), ('E.', 'e.'), ('(', '('), ('1998', '1998'), (',', ','), ('July', 'juli'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('46', '46'), (']', ']'), ('Sahami', 'Sahami'), (',', ','), ('M.', 'M.'), (',', ','), ('Dumais', 'Dumais'), (',', ','), ('S.', 'S.'), (',', ','), ('Heckerman', 'Heckerman'), (',', ','), ('D.', 'D.'), (',', ','), ('&', '&'), ('Horvitz', 'Horvitz'), (',', ','), ('E.', 'E.'), ('(', '('), ('1998', '1998'), (',', ','), ('July', 'July'), (')', ')'), ('.', '.')]


------------------- Sentence 2 -------------------

A Bayesian

>> Tokens are: 
 ['A', 'Bayesian']

>> Bigrams are: 
 [('A', 'Bayesian')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('A', 'DT'), ('Bayesian', 'JJ')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [('GPE', 'Bayesian')] 

>> Stemming using Porter Stemmer: 
 [('A', 'a'), ('Bayesian', 'bayesian')]

>> Stemming using Snowball Stemmer: 
 [('A', 'a'), ('Bayesian', 'bayesian')]

>> Lemmatization: 
 [('A', 'A'), ('Bayesian', 'Bayesian')]



========================================== PARAGRAPH 706 ===========================================

approach to filtering junk e-mail. In Learning for Text Categorization: Papers from the 1998  

------------------- Sentence 1 -------------------

approach to filtering junk e-mail.

>> Tokens are: 
 ['approach', 'filtering', 'junk', 'e-mail', '.']

>> Bigrams are: 
 [('approach', 'filtering'), ('filtering', 'junk'), ('junk', 'e-mail'), ('e-mail', '.')]

>> Trigrams are: 
 [('approach', 'filtering', 'junk'), ('filtering', 'junk', 'e-mail'), ('junk', 'e-mail', '.')]

>> POS Tags are: 
 [('approach', 'NN'), ('filtering', 'VBG'), ('junk', 'NN'), ('e-mail', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['approach', 'junk e-mail']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('approach', 'approach'), ('filtering', 'filter'), ('junk', 'junk'), ('e-mail', 'e-mail'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('approach', 'approach'), ('filtering', 'filter'), ('junk', 'junk'), ('e-mail', 'e-mail'), ('.', '.')]

>> Lemmatization: 
 [('approach', 'approach'), ('filtering', 'filtering'), ('junk', 'junk'), ('e-mail', 'e-mail'), ('.', '.')]


------------------- Sentence 2 -------------------

In Learning for Text Categorization: Papers from the 1998

>> Tokens are: 
 ['In', 'Learning', 'Text', 'Categorization', ':', 'Papers', '1998']

>> Bigrams are: 
 [('In', 'Learning'), ('Learning', 'Text'), ('Text', 'Categorization'), ('Categorization', ':'), (':', 'Papers'), ('Papers', '1998')]

>> Trigrams are: 
 [('In', 'Learning', 'Text'), ('Learning', 'Text', 'Categorization'), ('Text', 'Categorization', ':'), ('Categorization', ':', 'Papers'), (':', 'Papers', '1998')]

>> POS Tags are: 
 [('In', 'IN'), ('Learning', 'NNP'), ('Text', 'NNP'), ('Categorization', 'NNP'), (':', ':'), ('Papers', 'NNS'), ('1998', 'CD')]

>> Noun Phrases are: 
 ['Learning Text Categorization', 'Papers']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('Learning', 'learn'), ('Text', 'text'), ('Categorization', 'categor'), (':', ':'), ('Papers', 'paper'), ('1998', '1998')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('Learning', 'learn'), ('Text', 'text'), ('Categorization', 'categor'), (':', ':'), ('Papers', 'paper'), ('1998', '1998')]

>> Lemmatization: 
 [('In', 'In'), ('Learning', 'Learning'), ('Text', 'Text'), ('Categorization', 'Categorization'), (':', ':'), ('Papers', 'Papers'), ('1998', '1998')]



========================================== PARAGRAPH 707 ===========================================

workshop (Vol. 62, pp. 98-105).  

------------------- Sentence 1 -------------------

workshop (Vol.

>> Tokens are: 
 ['workshop', '(', 'Vol', '.']

>> Bigrams are: 
 [('workshop', '('), ('(', 'Vol'), ('Vol', '.')]

>> Trigrams are: 
 [('workshop', '(', 'Vol'), ('(', 'Vol', '.')]

>> POS Tags are: 
 [('workshop', 'NN'), ('(', '('), ('Vol', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['workshop', 'Vol']

>> Named Entities are: 
 [('ORGANIZATION', 'Vol')] 

>> Stemming using Porter Stemmer: 
 [('workshop', 'workshop'), ('(', '('), ('Vol', 'vol'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('workshop', 'workshop'), ('(', '('), ('Vol', 'vol'), ('.', '.')]

>> Lemmatization: 
 [('workshop', 'workshop'), ('(', '('), ('Vol', 'Vol'), ('.', '.')]


------------------- Sentence 2 -------------------

62, pp.

>> Tokens are: 
 ['62', ',', 'pp', '.']

>> Bigrams are: 
 [('62', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('62', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('62', 'CD'), (',', ','), ('pp', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['pp']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('62', '62'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('62', '62'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('62', '62'), (',', ','), ('pp', 'pp'), ('.', '.')]


------------------- Sentence 3 -------------------

98-105).

>> Tokens are: 
 ['98-105', ')', '.']

>> Bigrams are: 
 [('98-105', ')'), (')', '.')]

>> Trigrams are: 
 [('98-105', ')', '.')]

>> POS Tags are: 
 [('98-105', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('98-105', '98-105'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('98-105', '98-105'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('98-105', '98-105'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 708 ===========================================

[47] Androutsopoulos, I., Paliouras, G., Karkaletsis, V., Sakkis, G., Spyropoulos, C. D., &  

------------------- Sentence 1 -------------------

[47] Androutsopoulos, I., Paliouras, G., Karkaletsis, V., Sakkis, G., Spyropoulos, C. D., &

>> Tokens are: 
 ['[', '47', ']', 'Androutsopoulos', ',', 'I.', ',', 'Paliouras', ',', 'G.', ',', 'Karkaletsis', ',', 'V.', ',', 'Sakkis', ',', 'G.', ',', 'Spyropoulos', ',', 'C.', 'D.', ',', '&']

>> Bigrams are: 
 [('[', '47'), ('47', ']'), (']', 'Androutsopoulos'), ('Androutsopoulos', ','), (',', 'I.'), ('I.', ','), (',', 'Paliouras'), ('Paliouras', ','), (',', 'G.'), ('G.', ','), (',', 'Karkaletsis'), ('Karkaletsis', ','), (',', 'V.'), ('V.', ','), (',', 'Sakkis'), ('Sakkis', ','), (',', 'G.'), ('G.', ','), (',', 'Spyropoulos'), ('Spyropoulos', ','), (',', 'C.'), ('C.', 'D.'), ('D.', ','), (',', '&')]

>> Trigrams are: 
 [('[', '47', ']'), ('47', ']', 'Androutsopoulos'), (']', 'Androutsopoulos', ','), ('Androutsopoulos', ',', 'I.'), (',', 'I.', ','), ('I.', ',', 'Paliouras'), (',', 'Paliouras', ','), ('Paliouras', ',', 'G.'), (',', 'G.', ','), ('G.', ',', 'Karkaletsis'), (',', 'Karkaletsis', ','), ('Karkaletsis', ',', 'V.'), (',', 'V.', ','), ('V.', ',', 'Sakkis'), (',', 'Sakkis', ','), ('Sakkis', ',', 'G.'), (',', 'G.', ','), ('G.', ',', 'Spyropoulos'), (',', 'Spyropoulos', ','), ('Spyropoulos', ',', 'C.'), (',', 'C.', 'D.'), ('C.', 'D.', ','), ('D.', ',', '&')]

>> POS Tags are: 
 [('[', 'RB'), ('47', 'CD'), (']', 'JJ'), ('Androutsopoulos', 'NNP'), (',', ','), ('I.', 'NNP'), (',', ','), ('Paliouras', 'NNP'), (',', ','), ('G.', 'NNP'), (',', ','), ('Karkaletsis', 'NNP'), (',', ','), ('V.', 'NNP'), (',', ','), ('Sakkis', 'NNP'), (',', ','), ('G.', 'NNP'), (',', ','), ('Spyropoulos', 'NNP'), (',', ','), ('C.', 'NNP'), ('D.', 'NNP'), (',', ','), ('&', 'CC')]

>> Noun Phrases are: 
 ['] Androutsopoulos', 'I.', 'Paliouras', 'G.', 'Karkaletsis', 'V.', 'Sakkis', 'G.', 'Spyropoulos', 'C. D.']

>> Named Entities are: 
 [('GPE', 'Androutsopoulos'), ('GPE', 'Paliouras'), ('GPE', 'Karkaletsis'), ('GPE', 'Sakkis'), ('GPE', 'Spyropoulos')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('47', '47'), (']', ']'), ('Androutsopoulos', 'androutsopoulo'), (',', ','), ('I.', 'i.'), (',', ','), ('Paliouras', 'palioura'), (',', ','), ('G.', 'g.'), (',', ','), ('Karkaletsis', 'karkaletsi'), (',', ','), ('V.', 'v.'), (',', ','), ('Sakkis', 'sakki'), (',', ','), ('G.', 'g.'), (',', ','), ('Spyropoulos', 'spyropoulo'), (',', ','), ('C.', 'c.'), ('D.', 'd.'), (',', ','), ('&', '&')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('47', '47'), (']', ']'), ('Androutsopoulos', 'androutsopoulo'), (',', ','), ('I.', 'i.'), (',', ','), ('Paliouras', 'palioura'), (',', ','), ('G.', 'g.'), (',', ','), ('Karkaletsis', 'karkaletsi'), (',', ','), ('V.', 'v.'), (',', ','), ('Sakkis', 'sakki'), (',', ','), ('G.', 'g.'), (',', ','), ('Spyropoulos', 'spyropoulo'), (',', ','), ('C.', 'c.'), ('D.', 'd.'), (',', ','), ('&', '&')]

>> Lemmatization: 
 [('[', '['), ('47', '47'), (']', ']'), ('Androutsopoulos', 'Androutsopoulos'), (',', ','), ('I.', 'I.'), (',', ','), ('Paliouras', 'Paliouras'), (',', ','), ('G.', 'G.'), (',', ','), ('Karkaletsis', 'Karkaletsis'), (',', ','), ('V.', 'V.'), (',', ','), ('Sakkis', 'Sakkis'), (',', ','), ('G.', 'G.'), (',', ','), ('Spyropoulos', 'Spyropoulos'), (',', ','), ('C.', 'C.'), ('D.', 'D.'), (',', ','), ('&', '&')]



========================================== PARAGRAPH 709 ===========================================

Stamatopoulos, P. (2000). Learning to filter spam e-mail: A comparison of a naive bayesian  

------------------- Sentence 1 -------------------

Stamatopoulos, P. (2000).

>> Tokens are: 
 ['Stamatopoulos', ',', 'P.', '(', '2000', ')', '.']

>> Bigrams are: 
 [('Stamatopoulos', ','), (',', 'P.'), ('P.', '('), ('(', '2000'), ('2000', ')'), (')', '.')]

>> Trigrams are: 
 [('Stamatopoulos', ',', 'P.'), (',', 'P.', '('), ('P.', '(', '2000'), ('(', '2000', ')'), ('2000', ')', '.')]

>> POS Tags are: 
 [('Stamatopoulos', 'NNP'), (',', ','), ('P.', 'NNP'), ('(', '('), ('2000', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['Stamatopoulos', 'P.']

>> Named Entities are: 
 [('GPE', 'Stamatopoulos')] 

>> Stemming using Porter Stemmer: 
 [('Stamatopoulos', 'stamatopoulo'), (',', ','), ('P.', 'p.'), ('(', '('), ('2000', '2000'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Stamatopoulos', 'stamatopoulo'), (',', ','), ('P.', 'p.'), ('(', '('), ('2000', '2000'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Stamatopoulos', 'Stamatopoulos'), (',', ','), ('P.', 'P.'), ('(', '('), ('2000', '2000'), (')', ')'), ('.', '.')]


------------------- Sentence 2 -------------------

Learning to filter spam e-mail: A comparison of a naive bayesian

>> Tokens are: 
 ['Learning', 'filter', 'spam', 'e-mail', ':', 'A', 'comparison', 'naive', 'bayesian']

>> Bigrams are: 
 [('Learning', 'filter'), ('filter', 'spam'), ('spam', 'e-mail'), ('e-mail', ':'), (':', 'A'), ('A', 'comparison'), ('comparison', 'naive'), ('naive', 'bayesian')]

>> Trigrams are: 
 [('Learning', 'filter', 'spam'), ('filter', 'spam', 'e-mail'), ('spam', 'e-mail', ':'), ('e-mail', ':', 'A'), (':', 'A', 'comparison'), ('A', 'comparison', 'naive'), ('comparison', 'naive', 'bayesian')]

>> POS Tags are: 
 [('Learning', 'VBG'), ('filter', 'JJ'), ('spam', 'JJ'), ('e-mail', 'NN'), (':', ':'), ('A', 'DT'), ('comparison', 'NN'), ('naive', 'JJ'), ('bayesian', 'NN')]

>> Noun Phrases are: 
 ['filter spam e-mail', 'A comparison', 'naive bayesian']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Learning', 'learn'), ('filter', 'filter'), ('spam', 'spam'), ('e-mail', 'e-mail'), (':', ':'), ('A', 'a'), ('comparison', 'comparison'), ('naive', 'naiv'), ('bayesian', 'bayesian')]

>> Stemming using Snowball Stemmer: 
 [('Learning', 'learn'), ('filter', 'filter'), ('spam', 'spam'), ('e-mail', 'e-mail'), (':', ':'), ('A', 'a'), ('comparison', 'comparison'), ('naive', 'naiv'), ('bayesian', 'bayesian')]

>> Lemmatization: 
 [('Learning', 'Learning'), ('filter', 'filter'), ('spam', 'spam'), ('e-mail', 'e-mail'), (':', ':'), ('A', 'A'), ('comparison', 'comparison'), ('naive', 'naive'), ('bayesian', 'bayesian')]



========================================== PARAGRAPH 710 ===========================================

and a memory-based approach. arXiv preprint cs/0009009.  

------------------- Sentence 1 -------------------

and a memory-based approach.

>> Tokens are: 
 ['memory-based', 'approach', '.']

>> Bigrams are: 
 [('memory-based', 'approach'), ('approach', '.')]

>> Trigrams are: 
 [('memory-based', 'approach', '.')]

>> POS Tags are: 
 [('memory-based', 'JJ'), ('approach', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['memory-based approach']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('memory-based', 'memory-bas'), ('approach', 'approach'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('memory-based', 'memory-bas'), ('approach', 'approach'), ('.', '.')]

>> Lemmatization: 
 [('memory-based', 'memory-based'), ('approach', 'approach'), ('.', '.')]


------------------- Sentence 2 -------------------

arXiv preprint cs/0009009.

>> Tokens are: 
 ['arXiv', 'preprint', 'cs/0009009', '.']

>> Bigrams are: 
 [('arXiv', 'preprint'), ('preprint', 'cs/0009009'), ('cs/0009009', '.')]

>> Trigrams are: 
 [('arXiv', 'preprint', 'cs/0009009'), ('preprint', 'cs/0009009', '.')]

>> POS Tags are: 
 [('arXiv', 'JJ'), ('preprint', 'NN'), ('cs/0009009', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['arXiv preprint cs/0009009']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('arXiv', 'arxiv'), ('preprint', 'preprint'), ('cs/0009009', 'cs/0009009'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('arXiv', 'arxiv'), ('preprint', 'preprint'), ('cs/0009009', 'cs/0009009'), ('.', '.')]

>> Lemmatization: 
 [('arXiv', 'arXiv'), ('preprint', 'preprint'), ('cs/0009009', 'cs/0009009'), ('.', '.')]



========================================== PARAGRAPH 711 ===========================================

[48] Rennie, J. (2000, August). ifile: An application of machine learning to e-mail filtering.  

------------------- Sentence 1 -------------------

[48] Rennie, J.

>> Tokens are: 
 ['[', '48', ']', 'Rennie', ',', 'J', '.']

>> Bigrams are: 
 [('[', '48'), ('48', ']'), (']', 'Rennie'), ('Rennie', ','), (',', 'J'), ('J', '.')]

>> Trigrams are: 
 [('[', '48', ']'), ('48', ']', 'Rennie'), (']', 'Rennie', ','), ('Rennie', ',', 'J'), (',', 'J', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('48', 'CD'), (']', 'JJ'), ('Rennie', 'NNP'), (',', ','), ('J', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['] Rennie', 'J']

>> Named Entities are: 
 [('PERSON', 'Rennie')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('48', '48'), (']', ']'), ('Rennie', 'renni'), (',', ','), ('J', 'j'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('48', '48'), (']', ']'), ('Rennie', 'renni'), (',', ','), ('J', 'j'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('48', '48'), (']', ']'), ('Rennie', 'Rennie'), (',', ','), ('J', 'J'), ('.', '.')]


------------------- Sentence 2 -------------------

(2000, August).

>> Tokens are: 
 ['(', '2000', ',', 'August', ')', '.']

>> Bigrams are: 
 [('(', '2000'), ('2000', ','), (',', 'August'), ('August', ')'), (')', '.')]

>> Trigrams are: 
 [('(', '2000', ','), ('2000', ',', 'August'), (',', 'August', ')'), ('August', ')', '.')]

>> POS Tags are: 
 [('(', '('), ('2000', 'CD'), (',', ','), ('August', 'NNP'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['August']

>> Named Entities are: 
 [('GPE', 'August')] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('2000', '2000'), (',', ','), ('August', 'august'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('2000', '2000'), (',', ','), ('August', 'august'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('(', '('), ('2000', '2000'), (',', ','), ('August', 'August'), (')', ')'), ('.', '.')]


------------------- Sentence 3 -------------------

ifile: An application of machine learning to e-mail filtering.

>> Tokens are: 
 ['ifile', ':', 'An', 'application', 'machine', 'learning', 'e-mail', 'filtering', '.']

>> Bigrams are: 
 [('ifile', ':'), (':', 'An'), ('An', 'application'), ('application', 'machine'), ('machine', 'learning'), ('learning', 'e-mail'), ('e-mail', 'filtering'), ('filtering', '.')]

>> Trigrams are: 
 [('ifile', ':', 'An'), (':', 'An', 'application'), ('An', 'application', 'machine'), ('application', 'machine', 'learning'), ('machine', 'learning', 'e-mail'), ('learning', 'e-mail', 'filtering'), ('e-mail', 'filtering', '.')]

>> POS Tags are: 
 [('ifile', 'NN'), (':', ':'), ('An', 'DT'), ('application', 'NN'), ('machine', 'NN'), ('learning', 'VBG'), ('e-mail', 'JJ'), ('filtering', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['ifile', 'An application machine', 'e-mail filtering']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('ifile', 'ifil'), (':', ':'), ('An', 'an'), ('application', 'applic'), ('machine', 'machin'), ('learning', 'learn'), ('e-mail', 'e-mail'), ('filtering', 'filter'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('ifile', 'ifil'), (':', ':'), ('An', 'an'), ('application', 'applic'), ('machine', 'machin'), ('learning', 'learn'), ('e-mail', 'e-mail'), ('filtering', 'filter'), ('.', '.')]

>> Lemmatization: 
 [('ifile', 'ifile'), (':', ':'), ('An', 'An'), ('application', 'application'), ('machine', 'machine'), ('learning', 'learning'), ('e-mail', 'e-mail'), ('filtering', 'filtering'), ('.', '.')]



========================================== PARAGRAPH 712 ===========================================

In Proc. KDD 2000 Workshop on Text Mining, Boston, MA  

------------------- Sentence 1 -------------------

In Proc.

>> Tokens are: 
 ['In', 'Proc', '.']

>> Bigrams are: 
 [('In', 'Proc'), ('Proc', '.')]

>> Trigrams are: 
 [('In', 'Proc', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('Proc', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Proc']

>> Named Entities are: 
 [('GPE', 'Proc')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('Proc', 'proc'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('Proc', 'proc'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('Proc', 'Proc'), ('.', '.')]


------------------- Sentence 2 -------------------

KDD 2000 Workshop on Text Mining, Boston, MA

>> Tokens are: 
 ['KDD', '2000', 'Workshop', 'Text', 'Mining', ',', 'Boston', ',', 'MA']

>> Bigrams are: 
 [('KDD', '2000'), ('2000', 'Workshop'), ('Workshop', 'Text'), ('Text', 'Mining'), ('Mining', ','), (',', 'Boston'), ('Boston', ','), (',', 'MA')]

>> Trigrams are: 
 [('KDD', '2000', 'Workshop'), ('2000', 'Workshop', 'Text'), ('Workshop', 'Text', 'Mining'), ('Text', 'Mining', ','), ('Mining', ',', 'Boston'), (',', 'Boston', ','), ('Boston', ',', 'MA')]

>> POS Tags are: 
 [('KDD', 'NNP'), ('2000', 'CD'), ('Workshop', 'NNP'), ('Text', 'NNP'), ('Mining', 'NNP'), (',', ','), ('Boston', 'NNP'), (',', ','), ('MA', 'NNP')]

>> Noun Phrases are: 
 ['KDD', 'Workshop Text Mining', 'Boston', 'MA']

>> Named Entities are: 
 [('GPE', 'Boston'), ('ORGANIZATION', 'MA')] 

>> Stemming using Porter Stemmer: 
 [('KDD', 'kdd'), ('2000', '2000'), ('Workshop', 'workshop'), ('Text', 'text'), ('Mining', 'mine'), (',', ','), ('Boston', 'boston'), (',', ','), ('MA', 'ma')]

>> Stemming using Snowball Stemmer: 
 [('KDD', 'kdd'), ('2000', '2000'), ('Workshop', 'workshop'), ('Text', 'text'), ('Mining', 'mine'), (',', ','), ('Boston', 'boston'), (',', ','), ('MA', 'ma')]

>> Lemmatization: 
 [('KDD', 'KDD'), ('2000', '2000'), ('Workshop', 'Workshop'), ('Text', 'Text'), ('Mining', 'Mining'), (',', ','), ('Boston', 'Boston'), (',', ','), ('MA', 'MA')]



========================================== PARAGRAPH 713 ===========================================

[49] Drucker, H., Wu, D., & Vapnik, V. N. (1999). Support vector machines for spam  

------------------- Sentence 1 -------------------

[49] Drucker, H., Wu, D., & Vapnik, V. N. (1999).

>> Tokens are: 
 ['[', '49', ']', 'Drucker', ',', 'H.', ',', 'Wu', ',', 'D.', ',', '&', 'Vapnik', ',', 'V.', 'N.', '(', '1999', ')', '.']

>> Bigrams are: 
 [('[', '49'), ('49', ']'), (']', 'Drucker'), ('Drucker', ','), (',', 'H.'), ('H.', ','), (',', 'Wu'), ('Wu', ','), (',', 'D.'), ('D.', ','), (',', '&'), ('&', 'Vapnik'), ('Vapnik', ','), (',', 'V.'), ('V.', 'N.'), ('N.', '('), ('(', '1999'), ('1999', ')'), (')', '.')]

>> Trigrams are: 
 [('[', '49', ']'), ('49', ']', 'Drucker'), (']', 'Drucker', ','), ('Drucker', ',', 'H.'), (',', 'H.', ','), ('H.', ',', 'Wu'), (',', 'Wu', ','), ('Wu', ',', 'D.'), (',', 'D.', ','), ('D.', ',', '&'), (',', '&', 'Vapnik'), ('&', 'Vapnik', ','), ('Vapnik', ',', 'V.'), (',', 'V.', 'N.'), ('V.', 'N.', '('), ('N.', '(', '1999'), ('(', '1999', ')'), ('1999', ')', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('49', 'CD'), (']', 'JJ'), ('Drucker', 'NNP'), (',', ','), ('H.', 'NNP'), (',', ','), ('Wu', 'NNP'), (',', ','), ('D.', 'NNP'), (',', ','), ('&', 'CC'), ('Vapnik', 'NNP'), (',', ','), ('V.', 'NNP'), ('N.', 'NNP'), ('(', '('), ('1999', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['] Drucker', 'H.', 'Wu', 'D.', 'Vapnik', 'V. N.']

>> Named Entities are: 
 [('GPE', 'Wu'), ('PERSON', 'Vapnik')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('49', '49'), (']', ']'), ('Drucker', 'drucker'), (',', ','), ('H.', 'h.'), (',', ','), ('Wu', 'wu'), (',', ','), ('D.', 'd.'), (',', ','), ('&', '&'), ('Vapnik', 'vapnik'), (',', ','), ('V.', 'v.'), ('N.', 'n.'), ('(', '('), ('1999', '1999'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('49', '49'), (']', ']'), ('Drucker', 'drucker'), (',', ','), ('H.', 'h.'), (',', ','), ('Wu', 'wu'), (',', ','), ('D.', 'd.'), (',', ','), ('&', '&'), ('Vapnik', 'vapnik'), (',', ','), ('V.', 'v.'), ('N.', 'n.'), ('(', '('), ('1999', '1999'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('49', '49'), (']', ']'), ('Drucker', 'Drucker'), (',', ','), ('H.', 'H.'), (',', ','), ('Wu', 'Wu'), (',', ','), ('D.', 'D.'), (',', ','), ('&', '&'), ('Vapnik', 'Vapnik'), (',', ','), ('V.', 'V.'), ('N.', 'N.'), ('(', '('), ('1999', '1999'), (')', ')'), ('.', '.')]


------------------- Sentence 2 -------------------

Support vector machines for spam

>> Tokens are: 
 ['Support', 'vector', 'machines', 'spam']

>> Bigrams are: 
 [('Support', 'vector'), ('vector', 'machines'), ('machines', 'spam')]

>> Trigrams are: 
 [('Support', 'vector', 'machines'), ('vector', 'machines', 'spam')]

>> POS Tags are: 
 [('Support', 'NNP'), ('vector', 'NN'), ('machines', 'NNS'), ('spam', 'NN')]

>> Noun Phrases are: 
 ['Support vector machines spam']

>> Named Entities are: 
 [('GPE', 'Support')] 

>> Stemming using Porter Stemmer: 
 [('Support', 'support'), ('vector', 'vector'), ('machines', 'machin'), ('spam', 'spam')]

>> Stemming using Snowball Stemmer: 
 [('Support', 'support'), ('vector', 'vector'), ('machines', 'machin'), ('spam', 'spam')]

>> Lemmatization: 
 [('Support', 'Support'), ('vector', 'vector'), ('machines', 'machine'), ('spam', 'spam')]



========================================== PARAGRAPH 714 ===========================================

categorization. IEEE Transactions on Neural networks, 10(5), 1048-1054  

------------------- Sentence 1 -------------------

categorization.

>> Tokens are: 
 ['categorization', '.']

>> Bigrams are: 
 [('categorization', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('categorization', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['categorization']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('categorization', 'categor'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('categorization', 'categor'), ('.', '.')]

>> Lemmatization: 
 [('categorization', 'categorization'), ('.', '.')]


------------------- Sentence 2 -------------------

IEEE Transactions on Neural networks, 10(5), 1048-1054

>> Tokens are: 
 ['IEEE', 'Transactions', 'Neural', 'networks', ',', '10', '(', '5', ')', ',', '1048-1054']

>> Bigrams are: 
 [('IEEE', 'Transactions'), ('Transactions', 'Neural'), ('Neural', 'networks'), ('networks', ','), (',', '10'), ('10', '('), ('(', '5'), ('5', ')'), (')', ','), (',', '1048-1054')]

>> Trigrams are: 
 [('IEEE', 'Transactions', 'Neural'), ('Transactions', 'Neural', 'networks'), ('Neural', 'networks', ','), ('networks', ',', '10'), (',', '10', '('), ('10', '(', '5'), ('(', '5', ')'), ('5', ')', ','), (')', ',', '1048-1054')]

>> POS Tags are: 
 [('IEEE', 'NNP'), ('Transactions', 'NNP'), ('Neural', 'NNP'), ('networks', 'NNS'), (',', ','), ('10', 'CD'), ('(', '('), ('5', 'CD'), (')', ')'), (',', ','), ('1048-1054', 'JJ')]

>> Noun Phrases are: 
 ['IEEE Transactions Neural networks']

>> Named Entities are: 
 [('ORGANIZATION', 'IEEE Transactions')] 

>> Stemming using Porter Stemmer: 
 [('IEEE', 'ieee'), ('Transactions', 'transact'), ('Neural', 'neural'), ('networks', 'network'), (',', ','), ('10', '10'), ('(', '('), ('5', '5'), (')', ')'), (',', ','), ('1048-1054', '1048-1054')]

>> Stemming using Snowball Stemmer: 
 [('IEEE', 'ieee'), ('Transactions', 'transact'), ('Neural', 'neural'), ('networks', 'network'), (',', ','), ('10', '10'), ('(', '('), ('5', '5'), (')', ')'), (',', ','), ('1048-1054', '1048-1054')]

>> Lemmatization: 
 [('IEEE', 'IEEE'), ('Transactions', 'Transactions'), ('Neural', 'Neural'), ('networks', 'network'), (',', ','), ('10', '10'), ('(', '('), ('5', '5'), (')', ')'), (',', ','), ('1048-1054', '1048-1054')]



========================================== PARAGRAPH 715 ===========================================

[50] Carreras, X., & Marquez, L. (2001). Boosting trees for anti-spam email filtering. arXiv  

------------------- Sentence 1 -------------------

[50] Carreras, X., & Marquez, L. (2001).

>> Tokens are: 
 ['[', '50', ']', 'Carreras', ',', 'X.', ',', '&', 'Marquez', ',', 'L.', '(', '2001', ')', '.']

>> Bigrams are: 
 [('[', '50'), ('50', ']'), (']', 'Carreras'), ('Carreras', ','), (',', 'X.'), ('X.', ','), (',', '&'), ('&', 'Marquez'), ('Marquez', ','), (',', 'L.'), ('L.', '('), ('(', '2001'), ('2001', ')'), (')', '.')]

>> Trigrams are: 
 [('[', '50', ']'), ('50', ']', 'Carreras'), (']', 'Carreras', ','), ('Carreras', ',', 'X.'), (',', 'X.', ','), ('X.', ',', '&'), (',', '&', 'Marquez'), ('&', 'Marquez', ','), ('Marquez', ',', 'L.'), (',', 'L.', '('), ('L.', '(', '2001'), ('(', '2001', ')'), ('2001', ')', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('50', 'CD'), (']', 'JJ'), ('Carreras', 'NNP'), (',', ','), ('X.', 'NNP'), (',', ','), ('&', 'CC'), ('Marquez', 'NNP'), (',', ','), ('L.', 'NNP'), ('(', '('), ('2001', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['] Carreras', 'X.', 'Marquez', 'L.']

>> Named Entities are: 
 [('PERSON', 'Marquez')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('50', '50'), (']', ']'), ('Carreras', 'carrera'), (',', ','), ('X.', 'x.'), (',', ','), ('&', '&'), ('Marquez', 'marquez'), (',', ','), ('L.', 'l.'), ('(', '('), ('2001', '2001'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('50', '50'), (']', ']'), ('Carreras', 'carrera'), (',', ','), ('X.', 'x.'), (',', ','), ('&', '&'), ('Marquez', 'marquez'), (',', ','), ('L.', 'l.'), ('(', '('), ('2001', '2001'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('50', '50'), (']', ']'), ('Carreras', 'Carreras'), (',', ','), ('X.', 'X.'), (',', ','), ('&', '&'), ('Marquez', 'Marquez'), (',', ','), ('L.', 'L.'), ('(', '('), ('2001', '2001'), (')', ')'), ('.', '.')]


------------------- Sentence 2 -------------------

Boosting trees for anti-spam email filtering.

>> Tokens are: 
 ['Boosting', 'trees', 'anti-spam', 'email', 'filtering', '.']

>> Bigrams are: 
 [('Boosting', 'trees'), ('trees', 'anti-spam'), ('anti-spam', 'email'), ('email', 'filtering'), ('filtering', '.')]

>> Trigrams are: 
 [('Boosting', 'trees', 'anti-spam'), ('trees', 'anti-spam', 'email'), ('anti-spam', 'email', 'filtering'), ('email', 'filtering', '.')]

>> POS Tags are: 
 [('Boosting', 'VBG'), ('trees', 'NNS'), ('anti-spam', 'JJ'), ('email', 'NN'), ('filtering', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['trees', 'anti-spam email filtering']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Boosting', 'boost'), ('trees', 'tree'), ('anti-spam', 'anti-spam'), ('email', 'email'), ('filtering', 'filter'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Boosting', 'boost'), ('trees', 'tree'), ('anti-spam', 'anti-spam'), ('email', 'email'), ('filtering', 'filter'), ('.', '.')]

>> Lemmatization: 
 [('Boosting', 'Boosting'), ('trees', 'tree'), ('anti-spam', 'anti-spam'), ('email', 'email'), ('filtering', 'filtering'), ('.', '.')]


------------------- Sentence 3 -------------------

arXiv

>> Tokens are: 
 ['arXiv']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('arXiv', 'NN')]

>> Noun Phrases are: 
 ['arXiv']

>> Named Entities are: 
 [('GPE', 'arXiv')] 

>> Stemming using Porter Stemmer: 
 [('arXiv', 'arxiv')]

>> Stemming using Snowball Stemmer: 
 [('arXiv', 'arxiv')]

>> Lemmatization: 
 [('arXiv', 'arXiv')]



========================================== PARAGRAPH 716 ===========================================

preprint cs/0109015  

------------------- Sentence 1 -------------------

preprint cs/0109015

>> Tokens are: 
 ['preprint', 'cs/0109015']

>> Bigrams are: 
 [('preprint', 'cs/0109015')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('preprint', 'NN'), ('cs/0109015', 'NN')]

>> Noun Phrases are: 
 ['preprint cs/0109015']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('preprint', 'preprint'), ('cs/0109015', 'cs/0109015')]

>> Stemming using Snowball Stemmer: 
 [('preprint', 'preprint'), ('cs/0109015', 'cs/0109015')]

>> Lemmatization: 
 [('preprint', 'preprint'), ('cs/0109015', 'cs/0109015')]



========================================== PARAGRAPH 717 ===========================================

[51] BERGER, A. L., DELLA PIETRA, S. A., AND DELLA PIETRA, V. J. 1996. A  

------------------- Sentence 1 -------------------

[51] BERGER, A. L., DELLA PIETRA, S. A., AND DELLA PIETRA, V. J.

>> Tokens are: 
 ['[', '51', ']', 'BERGER', ',', 'A.', 'L.', ',', 'DELLA', 'PIETRA', ',', 'S.', 'A.', ',', 'AND', 'DELLA', 'PIETRA', ',', 'V.', 'J', '.']

>> Bigrams are: 
 [('[', '51'), ('51', ']'), (']', 'BERGER'), ('BERGER', ','), (',', 'A.'), ('A.', 'L.'), ('L.', ','), (',', 'DELLA'), ('DELLA', 'PIETRA'), ('PIETRA', ','), (',', 'S.'), ('S.', 'A.'), ('A.', ','), (',', 'AND'), ('AND', 'DELLA'), ('DELLA', 'PIETRA'), ('PIETRA', ','), (',', 'V.'), ('V.', 'J'), ('J', '.')]

>> Trigrams are: 
 [('[', '51', ']'), ('51', ']', 'BERGER'), (']', 'BERGER', ','), ('BERGER', ',', 'A.'), (',', 'A.', 'L.'), ('A.', 'L.', ','), ('L.', ',', 'DELLA'), (',', 'DELLA', 'PIETRA'), ('DELLA', 'PIETRA', ','), ('PIETRA', ',', 'S.'), (',', 'S.', 'A.'), ('S.', 'A.', ','), ('A.', ',', 'AND'), (',', 'AND', 'DELLA'), ('AND', 'DELLA', 'PIETRA'), ('DELLA', 'PIETRA', ','), ('PIETRA', ',', 'V.'), (',', 'V.', 'J'), ('V.', 'J', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('51', 'CD'), (']', 'JJ'), ('BERGER', 'NNP'), (',', ','), ('A.', 'NNP'), ('L.', 'NNP'), (',', ','), ('DELLA', 'NNP'), ('PIETRA', 'NNP'), (',', ','), ('S.', 'NNP'), ('A.', 'NNP'), (',', ','), ('AND', 'NNP'), ('DELLA', 'NNP'), ('PIETRA', 'NNP'), (',', ','), ('V.', 'NNP'), ('J', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['] BERGER', 'A. L.', 'DELLA PIETRA', 'S. A.', 'AND DELLA PIETRA', 'V. J']

>> Named Entities are: 
 [('ORGANIZATION', 'BERGER'), ('ORGANIZATION', 'DELLA'), ('ORGANIZATION', 'AND')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('51', '51'), (']', ']'), ('BERGER', 'berger'), (',', ','), ('A.', 'a.'), ('L.', 'l.'), (',', ','), ('DELLA', 'della'), ('PIETRA', 'pietra'), (',', ','), ('S.', 's.'), ('A.', 'a.'), (',', ','), ('AND', 'and'), ('DELLA', 'della'), ('PIETRA', 'pietra'), (',', ','), ('V.', 'v.'), ('J', 'j'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('51', '51'), (']', ']'), ('BERGER', 'berger'), (',', ','), ('A.', 'a.'), ('L.', 'l.'), (',', ','), ('DELLA', 'della'), ('PIETRA', 'pietra'), (',', ','), ('S.', 's.'), ('A.', 'a.'), (',', ','), ('AND', 'and'), ('DELLA', 'della'), ('PIETRA', 'pietra'), (',', ','), ('V.', 'v.'), ('J', 'j'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('51', '51'), (']', ']'), ('BERGER', 'BERGER'), (',', ','), ('A.', 'A.'), ('L.', 'L.'), (',', ','), ('DELLA', 'DELLA'), ('PIETRA', 'PIETRA'), (',', ','), ('S.', 'S.'), ('A.', 'A.'), (',', ','), ('AND', 'AND'), ('DELLA', 'DELLA'), ('PIETRA', 'PIETRA'), (',', ','), ('V.', 'V.'), ('J', 'J'), ('.', '.')]


------------------- Sentence 2 -------------------

1996.

>> Tokens are: 
 ['1996', '.']

>> Bigrams are: 
 [('1996', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('1996', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('1996', '1996'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('1996', '1996'), ('.', '.')]

>> Lemmatization: 
 [('1996', '1996'), ('.', '.')]


------------------- Sentence 3 -------------------

A

>> Tokens are: 
 ['A']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('A', 'DT')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('A', 'a')]

>> Stemming using Snowball Stemmer: 
 [('A', 'a')]

>> Lemmatization: 
 [('A', 'A')]



========================================== PARAGRAPH 718 ===========================================

maximum entropy approach to natural language processing. Computational Linguistics 22, 1,  

------------------- Sentence 1 -------------------

maximum entropy approach to natural language processing.

>> Tokens are: 
 ['maximum', 'entropy', 'approach', 'natural', 'language', 'processing', '.']

>> Bigrams are: 
 [('maximum', 'entropy'), ('entropy', 'approach'), ('approach', 'natural'), ('natural', 'language'), ('language', 'processing'), ('processing', '.')]

>> Trigrams are: 
 [('maximum', 'entropy', 'approach'), ('entropy', 'approach', 'natural'), ('approach', 'natural', 'language'), ('natural', 'language', 'processing'), ('language', 'processing', '.')]

>> POS Tags are: 
 [('maximum', 'JJ'), ('entropy', 'NN'), ('approach', 'NN'), ('natural', 'JJ'), ('language', 'NN'), ('processing', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['maximum entropy approach', 'natural language processing']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('maximum', 'maximum'), ('entropy', 'entropi'), ('approach', 'approach'), ('natural', 'natur'), ('language', 'languag'), ('processing', 'process'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('maximum', 'maximum'), ('entropy', 'entropi'), ('approach', 'approach'), ('natural', 'natur'), ('language', 'languag'), ('processing', 'process'), ('.', '.')]

>> Lemmatization: 
 [('maximum', 'maximum'), ('entropy', 'entropy'), ('approach', 'approach'), ('natural', 'natural'), ('language', 'language'), ('processing', 'processing'), ('.', '.')]


------------------- Sentence 2 -------------------

Computational Linguistics 22, 1,

>> Tokens are: 
 ['Computational', 'Linguistics', '22', ',', '1', ',']

>> Bigrams are: 
 [('Computational', 'Linguistics'), ('Linguistics', '22'), ('22', ','), (',', '1'), ('1', ',')]

>> Trigrams are: 
 [('Computational', 'Linguistics', '22'), ('Linguistics', '22', ','), ('22', ',', '1'), (',', '1', ',')]

>> POS Tags are: 
 [('Computational', 'JJ'), ('Linguistics', 'NNS'), ('22', 'CD'), (',', ','), ('1', 'CD'), (',', ',')]

>> Noun Phrases are: 
 ['Computational Linguistics']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Computational', 'comput'), ('Linguistics', 'linguist'), ('22', '22'), (',', ','), ('1', '1'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('Computational', 'comput'), ('Linguistics', 'linguist'), ('22', '22'), (',', ','), ('1', '1'), (',', ',')]

>> Lemmatization: 
 [('Computational', 'Computational'), ('Linguistics', 'Linguistics'), ('22', '22'), (',', ','), ('1', '1'), (',', ',')]



========================================== PARAGRAPH 719 ===========================================

39–71  

------------------- Sentence 1 -------------------

39–71

>> Tokens are: 
 ['39–71']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('39–71', 'CD')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('39–71', '39–71')]

>> Stemming using Snowball Stemmer: 
 [('39–71', '39–71')]

>> Lemmatization: 
 [('39–71', '39–71')]



========================================== PARAGRAPH 720 ===========================================

[52] Sakkis, G., Androutsopoulos, I., Paliouras, G., Karkaletsis, V., Spyropoulos, C. D., &  

------------------- Sentence 1 -------------------

[52] Sakkis, G., Androutsopoulos, I., Paliouras, G., Karkaletsis, V., Spyropoulos, C. D., &

>> Tokens are: 
 ['[', '52', ']', 'Sakkis', ',', 'G.', ',', 'Androutsopoulos', ',', 'I.', ',', 'Paliouras', ',', 'G.', ',', 'Karkaletsis', ',', 'V.', ',', 'Spyropoulos', ',', 'C.', 'D.', ',', '&']

>> Bigrams are: 
 [('[', '52'), ('52', ']'), (']', 'Sakkis'), ('Sakkis', ','), (',', 'G.'), ('G.', ','), (',', 'Androutsopoulos'), ('Androutsopoulos', ','), (',', 'I.'), ('I.', ','), (',', 'Paliouras'), ('Paliouras', ','), (',', 'G.'), ('G.', ','), (',', 'Karkaletsis'), ('Karkaletsis', ','), (',', 'V.'), ('V.', ','), (',', 'Spyropoulos'), ('Spyropoulos', ','), (',', 'C.'), ('C.', 'D.'), ('D.', ','), (',', '&')]

>> Trigrams are: 
 [('[', '52', ']'), ('52', ']', 'Sakkis'), (']', 'Sakkis', ','), ('Sakkis', ',', 'G.'), (',', 'G.', ','), ('G.', ',', 'Androutsopoulos'), (',', 'Androutsopoulos', ','), ('Androutsopoulos', ',', 'I.'), (',', 'I.', ','), ('I.', ',', 'Paliouras'), (',', 'Paliouras', ','), ('Paliouras', ',', 'G.'), (',', 'G.', ','), ('G.', ',', 'Karkaletsis'), (',', 'Karkaletsis', ','), ('Karkaletsis', ',', 'V.'), (',', 'V.', ','), ('V.', ',', 'Spyropoulos'), (',', 'Spyropoulos', ','), ('Spyropoulos', ',', 'C.'), (',', 'C.', 'D.'), ('C.', 'D.', ','), ('D.', ',', '&')]

>> POS Tags are: 
 [('[', 'RB'), ('52', 'CD'), (']', 'JJ'), ('Sakkis', 'NNP'), (',', ','), ('G.', 'NNP'), (',', ','), ('Androutsopoulos', 'NNP'), (',', ','), ('I.', 'NNP'), (',', ','), ('Paliouras', 'NNP'), (',', ','), ('G.', 'NNP'), (',', ','), ('Karkaletsis', 'NNP'), (',', ','), ('V.', 'NNP'), (',', ','), ('Spyropoulos', 'NNP'), (',', ','), ('C.', 'NNP'), ('D.', 'NNP'), (',', ','), ('&', 'CC')]

>> Noun Phrases are: 
 ['] Sakkis', 'G.', 'Androutsopoulos', 'I.', 'Paliouras', 'G.', 'Karkaletsis', 'V.', 'Spyropoulos', 'C. D.']

>> Named Entities are: 
 [('GPE', 'Sakkis'), ('GPE', 'Androutsopoulos'), ('GPE', 'Paliouras'), ('GPE', 'Karkaletsis'), ('GPE', 'Spyropoulos')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('52', '52'), (']', ']'), ('Sakkis', 'sakki'), (',', ','), ('G.', 'g.'), (',', ','), ('Androutsopoulos', 'androutsopoulo'), (',', ','), ('I.', 'i.'), (',', ','), ('Paliouras', 'palioura'), (',', ','), ('G.', 'g.'), (',', ','), ('Karkaletsis', 'karkaletsi'), (',', ','), ('V.', 'v.'), (',', ','), ('Spyropoulos', 'spyropoulo'), (',', ','), ('C.', 'c.'), ('D.', 'd.'), (',', ','), ('&', '&')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('52', '52'), (']', ']'), ('Sakkis', 'sakki'), (',', ','), ('G.', 'g.'), (',', ','), ('Androutsopoulos', 'androutsopoulo'), (',', ','), ('I.', 'i.'), (',', ','), ('Paliouras', 'palioura'), (',', ','), ('G.', 'g.'), (',', ','), ('Karkaletsis', 'karkaletsi'), (',', ','), ('V.', 'v.'), (',', ','), ('Spyropoulos', 'spyropoulo'), (',', ','), ('C.', 'c.'), ('D.', 'd.'), (',', ','), ('&', '&')]

>> Lemmatization: 
 [('[', '['), ('52', '52'), (']', ']'), ('Sakkis', 'Sakkis'), (',', ','), ('G.', 'G.'), (',', ','), ('Androutsopoulos', 'Androutsopoulos'), (',', ','), ('I.', 'I.'), (',', ','), ('Paliouras', 'Paliouras'), (',', ','), ('G.', 'G.'), (',', ','), ('Karkaletsis', 'Karkaletsis'), (',', ','), ('V.', 'V.'), (',', ','), ('Spyropoulos', 'Spyropoulos'), (',', ','), ('C.', 'C.'), ('D.', 'D.'), (',', ','), ('&', '&')]



========================================== PARAGRAPH 721 ===========================================

Stamatopoulos, P. (2001). Stacking classifiers for anti-spam filtering of e-mail. arXiv preprint  

------------------- Sentence 1 -------------------

Stamatopoulos, P. (2001).

>> Tokens are: 
 ['Stamatopoulos', ',', 'P.', '(', '2001', ')', '.']

>> Bigrams are: 
 [('Stamatopoulos', ','), (',', 'P.'), ('P.', '('), ('(', '2001'), ('2001', ')'), (')', '.')]

>> Trigrams are: 
 [('Stamatopoulos', ',', 'P.'), (',', 'P.', '('), ('P.', '(', '2001'), ('(', '2001', ')'), ('2001', ')', '.')]

>> POS Tags are: 
 [('Stamatopoulos', 'NNP'), (',', ','), ('P.', 'NNP'), ('(', '('), ('2001', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['Stamatopoulos', 'P.']

>> Named Entities are: 
 [('GPE', 'Stamatopoulos')] 

>> Stemming using Porter Stemmer: 
 [('Stamatopoulos', 'stamatopoulo'), (',', ','), ('P.', 'p.'), ('(', '('), ('2001', '2001'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Stamatopoulos', 'stamatopoulo'), (',', ','), ('P.', 'p.'), ('(', '('), ('2001', '2001'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Stamatopoulos', 'Stamatopoulos'), (',', ','), ('P.', 'P.'), ('(', '('), ('2001', '2001'), (')', ')'), ('.', '.')]


------------------- Sentence 2 -------------------

Stacking classifiers for anti-spam filtering of e-mail.

>> Tokens are: 
 ['Stacking', 'classifiers', 'anti-spam', 'filtering', 'e-mail', '.']

>> Bigrams are: 
 [('Stacking', 'classifiers'), ('classifiers', 'anti-spam'), ('anti-spam', 'filtering'), ('filtering', 'e-mail'), ('e-mail', '.')]

>> Trigrams are: 
 [('Stacking', 'classifiers', 'anti-spam'), ('classifiers', 'anti-spam', 'filtering'), ('anti-spam', 'filtering', 'e-mail'), ('filtering', 'e-mail', '.')]

>> POS Tags are: 
 [('Stacking', 'VBG'), ('classifiers', 'NNS'), ('anti-spam', 'JJ'), ('filtering', 'JJ'), ('e-mail', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['classifiers', 'anti-spam filtering e-mail']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Stacking', 'stack'), ('classifiers', 'classifi'), ('anti-spam', 'anti-spam'), ('filtering', 'filter'), ('e-mail', 'e-mail'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Stacking', 'stack'), ('classifiers', 'classifi'), ('anti-spam', 'anti-spam'), ('filtering', 'filter'), ('e-mail', 'e-mail'), ('.', '.')]

>> Lemmatization: 
 [('Stacking', 'Stacking'), ('classifiers', 'classifier'), ('anti-spam', 'anti-spam'), ('filtering', 'filtering'), ('e-mail', 'e-mail'), ('.', '.')]


------------------- Sentence 3 -------------------

arXiv preprint

>> Tokens are: 
 ['arXiv', 'preprint']

>> Bigrams are: 
 [('arXiv', 'preprint')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('arXiv', 'NNS'), ('preprint', 'NN')]

>> Noun Phrases are: 
 ['arXiv preprint']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('arXiv', 'arxiv'), ('preprint', 'preprint')]

>> Stemming using Snowball Stemmer: 
 [('arXiv', 'arxiv'), ('preprint', 'preprint')]

>> Lemmatization: 
 [('arXiv', 'arXiv'), ('preprint', 'preprint')]



========================================== PARAGRAPH 722 ===========================================

cs/0106040..  

------------------- Sentence 1 -------------------

cs/0106040..

>> Tokens are: 
 ['cs/0106040', '..']

>> Bigrams are: 
 [('cs/0106040', '..')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('cs/0106040', 'NN'), ('..', 'NN')]

>> Noun Phrases are: 
 ['cs/0106040 ..']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('cs/0106040', 'cs/0106040'), ('..', '..')]

>> Stemming using Snowball Stemmer: 
 [('cs/0106040', 'cs/0106040'), ('..', '..')]

>> Lemmatization: 
 [('cs/0106040', 'cs/0106040'), ('..', '..')]



========================================== PARAGRAPH 723 ===========================================

[53] Lewis, D. D. (1998, April). Naive (Bayes) at forty: The independence assumption in  

------------------- Sentence 1 -------------------

[53] Lewis, D. D. (1998, April).

>> Tokens are: 
 ['[', '53', ']', 'Lewis', ',', 'D.', 'D.', '(', '1998', ',', 'April', ')', '.']

>> Bigrams are: 
 [('[', '53'), ('53', ']'), (']', 'Lewis'), ('Lewis', ','), (',', 'D.'), ('D.', 'D.'), ('D.', '('), ('(', '1998'), ('1998', ','), (',', 'April'), ('April', ')'), (')', '.')]

>> Trigrams are: 
 [('[', '53', ']'), ('53', ']', 'Lewis'), (']', 'Lewis', ','), ('Lewis', ',', 'D.'), (',', 'D.', 'D.'), ('D.', 'D.', '('), ('D.', '(', '1998'), ('(', '1998', ','), ('1998', ',', 'April'), (',', 'April', ')'), ('April', ')', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('53', 'CD'), (']', 'JJ'), ('Lewis', 'NNP'), (',', ','), ('D.', 'NNP'), ('D.', 'NNP'), ('(', '('), ('1998', 'CD'), (',', ','), ('April', 'NNP'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['] Lewis', 'D. D.', 'April']

>> Named Entities are: 
 [('PERSON', 'Lewis')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('53', '53'), (']', ']'), ('Lewis', 'lewi'), (',', ','), ('D.', 'd.'), ('D.', 'd.'), ('(', '('), ('1998', '1998'), (',', ','), ('April', 'april'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('53', '53'), (']', ']'), ('Lewis', 'lewi'), (',', ','), ('D.', 'd.'), ('D.', 'd.'), ('(', '('), ('1998', '1998'), (',', ','), ('April', 'april'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('53', '53'), (']', ']'), ('Lewis', 'Lewis'), (',', ','), ('D.', 'D.'), ('D.', 'D.'), ('(', '('), ('1998', '1998'), (',', ','), ('April', 'April'), (')', ')'), ('.', '.')]


------------------- Sentence 2 -------------------

Naive (Bayes) at forty: The independence assumption in

>> Tokens are: 
 ['Naive', '(', 'Bayes', ')', 'forty', ':', 'The', 'independence', 'assumption']

>> Bigrams are: 
 [('Naive', '('), ('(', 'Bayes'), ('Bayes', ')'), (')', 'forty'), ('forty', ':'), (':', 'The'), ('The', 'independence'), ('independence', 'assumption')]

>> Trigrams are: 
 [('Naive', '(', 'Bayes'), ('(', 'Bayes', ')'), ('Bayes', ')', 'forty'), (')', 'forty', ':'), ('forty', ':', 'The'), (':', 'The', 'independence'), ('The', 'independence', 'assumption')]

>> POS Tags are: 
 [('Naive', 'NNP'), ('(', '('), ('Bayes', 'NNP'), (')', ')'), ('forty', 'NN'), (':', ':'), ('The', 'DT'), ('independence', 'NN'), ('assumption', 'NN')]

>> Noun Phrases are: 
 ['Naive', 'Bayes', 'forty', 'The independence assumption']

>> Named Entities are: 
 [('GPE', 'Naive')] 

>> Stemming using Porter Stemmer: 
 [('Naive', 'naiv'), ('(', '('), ('Bayes', 'bay'), (')', ')'), ('forty', 'forti'), (':', ':'), ('The', 'the'), ('independence', 'independ'), ('assumption', 'assumpt')]

>> Stemming using Snowball Stemmer: 
 [('Naive', 'naiv'), ('(', '('), ('Bayes', 'bay'), (')', ')'), ('forty', 'forti'), (':', ':'), ('The', 'the'), ('independence', 'independ'), ('assumption', 'assumpt')]

>> Lemmatization: 
 [('Naive', 'Naive'), ('(', '('), ('Bayes', 'Bayes'), (')', ')'), ('forty', 'forty'), (':', ':'), ('The', 'The'), ('independence', 'independence'), ('assumption', 'assumption')]



========================================== PARAGRAPH 724 ===========================================

information retrieval. In European conference on machine learning (pp. 4-15). Springer  

------------------- Sentence 1 -------------------

information retrieval.

>> Tokens are: 
 ['information', 'retrieval', '.']

>> Bigrams are: 
 [('information', 'retrieval'), ('retrieval', '.')]

>> Trigrams are: 
 [('information', 'retrieval', '.')]

>> POS Tags are: 
 [('information', 'NN'), ('retrieval', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['information retrieval']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('information', 'inform'), ('retrieval', 'retriev'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('information', 'inform'), ('retrieval', 'retriev'), ('.', '.')]

>> Lemmatization: 
 [('information', 'information'), ('retrieval', 'retrieval'), ('.', '.')]


------------------- Sentence 2 -------------------

In European conference on machine learning (pp.

>> Tokens are: 
 ['In', 'European', 'conference', 'machine', 'learning', '(', 'pp', '.']

>> Bigrams are: 
 [('In', 'European'), ('European', 'conference'), ('conference', 'machine'), ('machine', 'learning'), ('learning', '('), ('(', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('In', 'European', 'conference'), ('European', 'conference', 'machine'), ('conference', 'machine', 'learning'), ('machine', 'learning', '('), ('learning', '(', 'pp'), ('(', 'pp', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('European', 'JJ'), ('conference', 'NN'), ('machine', 'NN'), ('learning', 'NN'), ('(', '('), ('pp', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['European conference machine learning', 'pp']

>> Named Entities are: 
 [('GPE', 'European')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('European', 'european'), ('conference', 'confer'), ('machine', 'machin'), ('learning', 'learn'), ('(', '('), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('European', 'european'), ('conference', 'confer'), ('machine', 'machin'), ('learning', 'learn'), ('(', '('), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('European', 'European'), ('conference', 'conference'), ('machine', 'machine'), ('learning', 'learning'), ('(', '('), ('pp', 'pp'), ('.', '.')]


------------------- Sentence 3 -------------------

4-15).

>> Tokens are: 
 ['4-15', ')', '.']

>> Bigrams are: 
 [('4-15', ')'), (')', '.')]

>> Trigrams are: 
 [('4-15', ')', '.')]

>> POS Tags are: 
 [('4-15', 'JJ'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('4-15', '4-15'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('4-15', '4-15'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('4-15', '4-15'), (')', ')'), ('.', '.')]


------------------- Sentence 4 -------------------

Springer

>> Tokens are: 
 ['Springer']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Springer', 'NN')]

>> Noun Phrases are: 
 ['Springer']

>> Named Entities are: 
 [('GPE', 'Springer')] 

>> Stemming using Porter Stemmer: 
 [('Springer', 'springer')]

>> Stemming using Snowball Stemmer: 
 [('Springer', 'springer')]

>> Lemmatization: 
 [('Springer', 'Springer')]



========================================== PARAGRAPH 725 ===========================================

Berlin Heidelberg  

------------------- Sentence 1 -------------------

Berlin Heidelberg

>> Tokens are: 
 ['Berlin', 'Heidelberg']

>> Bigrams are: 
 [('Berlin', 'Heidelberg')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Berlin', 'NNP'), ('Heidelberg', 'NNP')]

>> Noun Phrases are: 
 ['Berlin Heidelberg']

>> Named Entities are: 
 [('PERSON', 'Berlin'), ('ORGANIZATION', 'Heidelberg')] 

>> Stemming using Porter Stemmer: 
 [('Berlin', 'berlin'), ('Heidelberg', 'heidelberg')]

>> Stemming using Snowball Stemmer: 
 [('Berlin', 'berlin'), ('Heidelberg', 'heidelberg')]

>> Lemmatization: 
 [('Berlin', 'Berlin'), ('Heidelberg', 'Heidelberg')]



========================================== PARAGRAPH 726 ===========================================

[54] McCallum, A., & Nigam, K. (1998, July). A comparison of event models for naive bayes  

------------------- Sentence 1 -------------------

[54] McCallum, A., & Nigam, K. (1998, July).

>> Tokens are: 
 ['[', '54', ']', 'McCallum', ',', 'A.', ',', '&', 'Nigam', ',', 'K.', '(', '1998', ',', 'July', ')', '.']

>> Bigrams are: 
 [('[', '54'), ('54', ']'), (']', 'McCallum'), ('McCallum', ','), (',', 'A.'), ('A.', ','), (',', '&'), ('&', 'Nigam'), ('Nigam', ','), (',', 'K.'), ('K.', '('), ('(', '1998'), ('1998', ','), (',', 'July'), ('July', ')'), (')', '.')]

>> Trigrams are: 
 [('[', '54', ']'), ('54', ']', 'McCallum'), (']', 'McCallum', ','), ('McCallum', ',', 'A.'), (',', 'A.', ','), ('A.', ',', '&'), (',', '&', 'Nigam'), ('&', 'Nigam', ','), ('Nigam', ',', 'K.'), (',', 'K.', '('), ('K.', '(', '1998'), ('(', '1998', ','), ('1998', ',', 'July'), (',', 'July', ')'), ('July', ')', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('54', 'CD'), (']', 'JJ'), ('McCallum', 'NNP'), (',', ','), ('A.', 'NNP'), (',', ','), ('&', 'CC'), ('Nigam', 'NNP'), (',', ','), ('K.', 'NNP'), ('(', '('), ('1998', 'CD'), (',', ','), ('July', 'NNP'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['] McCallum', 'A.', 'Nigam', 'K.', 'July']

>> Named Entities are: 
 [('ORGANIZATION', 'McCallum'), ('GPE', 'Nigam')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('54', '54'), (']', ']'), ('McCallum', 'mccallum'), (',', ','), ('A.', 'a.'), (',', ','), ('&', '&'), ('Nigam', 'nigam'), (',', ','), ('K.', 'k.'), ('(', '('), ('1998', '1998'), (',', ','), ('July', 'juli'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('54', '54'), (']', ']'), ('McCallum', 'mccallum'), (',', ','), ('A.', 'a.'), (',', ','), ('&', '&'), ('Nigam', 'nigam'), (',', ','), ('K.', 'k.'), ('(', '('), ('1998', '1998'), (',', ','), ('July', 'juli'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('54', '54'), (']', ']'), ('McCallum', 'McCallum'), (',', ','), ('A.', 'A.'), (',', ','), ('&', '&'), ('Nigam', 'Nigam'), (',', ','), ('K.', 'K.'), ('(', '('), ('1998', '1998'), (',', ','), ('July', 'July'), (')', ')'), ('.', '.')]


------------------- Sentence 2 -------------------

A comparison of event models for naive bayes

>> Tokens are: 
 ['A', 'comparison', 'event', 'models', 'naive', 'bayes']

>> Bigrams are: 
 [('A', 'comparison'), ('comparison', 'event'), ('event', 'models'), ('models', 'naive'), ('naive', 'bayes')]

>> Trigrams are: 
 [('A', 'comparison', 'event'), ('comparison', 'event', 'models'), ('event', 'models', 'naive'), ('models', 'naive', 'bayes')]

>> POS Tags are: 
 [('A', 'DT'), ('comparison', 'NN'), ('event', 'NN'), ('models', 'NNS'), ('naive', 'JJ'), ('bayes', 'NNS')]

>> Noun Phrases are: 
 ['A comparison event models', 'naive bayes']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('A', 'a'), ('comparison', 'comparison'), ('event', 'event'), ('models', 'model'), ('naive', 'naiv'), ('bayes', 'bay')]

>> Stemming using Snowball Stemmer: 
 [('A', 'a'), ('comparison', 'comparison'), ('event', 'event'), ('models', 'model'), ('naive', 'naiv'), ('bayes', 'bay')]

>> Lemmatization: 
 [('A', 'A'), ('comparison', 'comparison'), ('event', 'event'), ('models', 'model'), ('naive', 'naive'), ('bayes', 'bayes')]



========================================== PARAGRAPH 727 ===========================================

text classification. In AAAI-98 workshop on learning for text categorization (Vol. 752, pp.  

------------------- Sentence 1 -------------------

text classification.

>> Tokens are: 
 ['text', 'classification', '.']

>> Bigrams are: 
 [('text', 'classification'), ('classification', '.')]

>> Trigrams are: 
 [('text', 'classification', '.')]

>> POS Tags are: 
 [('text', 'JJ'), ('classification', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['text classification']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('text', 'text'), ('classification', 'classif'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('text', 'text'), ('classification', 'classif'), ('.', '.')]

>> Lemmatization: 
 [('text', 'text'), ('classification', 'classification'), ('.', '.')]


------------------- Sentence 2 -------------------

In AAAI-98 workshop on learning for text categorization (Vol.

>> Tokens are: 
 ['In', 'AAAI-98', 'workshop', 'learning', 'text', 'categorization', '(', 'Vol', '.']

>> Bigrams are: 
 [('In', 'AAAI-98'), ('AAAI-98', 'workshop'), ('workshop', 'learning'), ('learning', 'text'), ('text', 'categorization'), ('categorization', '('), ('(', 'Vol'), ('Vol', '.')]

>> Trigrams are: 
 [('In', 'AAAI-98', 'workshop'), ('AAAI-98', 'workshop', 'learning'), ('workshop', 'learning', 'text'), ('learning', 'text', 'categorization'), ('text', 'categorization', '('), ('categorization', '(', 'Vol'), ('(', 'Vol', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('AAAI-98', 'NNP'), ('workshop', 'NN'), ('learning', 'VBG'), ('text', 'JJ'), ('categorization', 'NN'), ('(', '('), ('Vol', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['AAAI-98 workshop', 'text categorization', 'Vol']

>> Named Entities are: 
 [('ORGANIZATION', 'Vol')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('AAAI-98', 'aaai-98'), ('workshop', 'workshop'), ('learning', 'learn'), ('text', 'text'), ('categorization', 'categor'), ('(', '('), ('Vol', 'vol'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('AAAI-98', 'aaai-98'), ('workshop', 'workshop'), ('learning', 'learn'), ('text', 'text'), ('categorization', 'categor'), ('(', '('), ('Vol', 'vol'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('AAAI-98', 'AAAI-98'), ('workshop', 'workshop'), ('learning', 'learning'), ('text', 'text'), ('categorization', 'categorization'), ('(', '('), ('Vol', 'Vol'), ('.', '.')]


------------------- Sentence 3 -------------------

752, pp.

>> Tokens are: 
 ['752', ',', 'pp', '.']

>> Bigrams are: 
 [('752', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('752', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('752', 'CD'), (',', ','), ('pp', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['pp']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('752', '752'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('752', '752'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('752', '752'), (',', ','), ('pp', 'pp'), ('.', '.')]



========================================== PARAGRAPH 728 ===========================================

41-48).  

------------------- Sentence 1 -------------------

41-48).

>> Tokens are: 
 ['41-48', ')', '.']

>> Bigrams are: 
 [('41-48', ')'), (')', '.')]

>> Trigrams are: 
 [('41-48', ')', '.')]

>> POS Tags are: 
 [('41-48', 'JJ'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('41-48', '41-48'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('41-48', '41-48'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('41-48', '41-48'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 729 ===========================================

[55] McCallum, A., & Nigam, K. (1998, July). A comparison of event models for naive bayes  

------------------- Sentence 1 -------------------

[55] McCallum, A., & Nigam, K. (1998, July).

>> Tokens are: 
 ['[', '55', ']', 'McCallum', ',', 'A.', ',', '&', 'Nigam', ',', 'K.', '(', '1998', ',', 'July', ')', '.']

>> Bigrams are: 
 [('[', '55'), ('55', ']'), (']', 'McCallum'), ('McCallum', ','), (',', 'A.'), ('A.', ','), (',', '&'), ('&', 'Nigam'), ('Nigam', ','), (',', 'K.'), ('K.', '('), ('(', '1998'), ('1998', ','), (',', 'July'), ('July', ')'), (')', '.')]

>> Trigrams are: 
 [('[', '55', ']'), ('55', ']', 'McCallum'), (']', 'McCallum', ','), ('McCallum', ',', 'A.'), (',', 'A.', ','), ('A.', ',', '&'), (',', '&', 'Nigam'), ('&', 'Nigam', ','), ('Nigam', ',', 'K.'), (',', 'K.', '('), ('K.', '(', '1998'), ('(', '1998', ','), ('1998', ',', 'July'), (',', 'July', ')'), ('July', ')', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('55', 'CD'), (']', 'JJ'), ('McCallum', 'NNP'), (',', ','), ('A.', 'NNP'), (',', ','), ('&', 'CC'), ('Nigam', 'NNP'), (',', ','), ('K.', 'NNP'), ('(', '('), ('1998', 'CD'), (',', ','), ('July', 'NNP'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['] McCallum', 'A.', 'Nigam', 'K.', 'July']

>> Named Entities are: 
 [('ORGANIZATION', 'McCallum'), ('GPE', 'Nigam')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('55', '55'), (']', ']'), ('McCallum', 'mccallum'), (',', ','), ('A.', 'a.'), (',', ','), ('&', '&'), ('Nigam', 'nigam'), (',', ','), ('K.', 'k.'), ('(', '('), ('1998', '1998'), (',', ','), ('July', 'juli'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('55', '55'), (']', ']'), ('McCallum', 'mccallum'), (',', ','), ('A.', 'a.'), (',', ','), ('&', '&'), ('Nigam', 'nigam'), (',', ','), ('K.', 'k.'), ('(', '('), ('1998', '1998'), (',', ','), ('July', 'juli'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('55', '55'), (']', ']'), ('McCallum', 'McCallum'), (',', ','), ('A.', 'A.'), (',', ','), ('&', '&'), ('Nigam', 'Nigam'), (',', ','), ('K.', 'K.'), ('(', '('), ('1998', '1998'), (',', ','), ('July', 'July'), (')', ')'), ('.', '.')]


------------------- Sentence 2 -------------------

A comparison of event models for naive bayes

>> Tokens are: 
 ['A', 'comparison', 'event', 'models', 'naive', 'bayes']

>> Bigrams are: 
 [('A', 'comparison'), ('comparison', 'event'), ('event', 'models'), ('models', 'naive'), ('naive', 'bayes')]

>> Trigrams are: 
 [('A', 'comparison', 'event'), ('comparison', 'event', 'models'), ('event', 'models', 'naive'), ('models', 'naive', 'bayes')]

>> POS Tags are: 
 [('A', 'DT'), ('comparison', 'NN'), ('event', 'NN'), ('models', 'NNS'), ('naive', 'JJ'), ('bayes', 'NNS')]

>> Noun Phrases are: 
 ['A comparison event models', 'naive bayes']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('A', 'a'), ('comparison', 'comparison'), ('event', 'event'), ('models', 'model'), ('naive', 'naiv'), ('bayes', 'bay')]

>> Stemming using Snowball Stemmer: 
 [('A', 'a'), ('comparison', 'comparison'), ('event', 'event'), ('models', 'model'), ('naive', 'naiv'), ('bayes', 'bay')]

>> Lemmatization: 
 [('A', 'A'), ('comparison', 'comparison'), ('event', 'event'), ('models', 'model'), ('naive', 'naive'), ('bayes', 'bayes')]



========================================== PARAGRAPH 730 ===========================================

text classification. In AAAI-98 workshop on learning for text categorization (Vol. 752, pp.  

------------------- Sentence 1 -------------------

text classification.

>> Tokens are: 
 ['text', 'classification', '.']

>> Bigrams are: 
 [('text', 'classification'), ('classification', '.')]

>> Trigrams are: 
 [('text', 'classification', '.')]

>> POS Tags are: 
 [('text', 'JJ'), ('classification', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['text classification']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('text', 'text'), ('classification', 'classif'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('text', 'text'), ('classification', 'classif'), ('.', '.')]

>> Lemmatization: 
 [('text', 'text'), ('classification', 'classification'), ('.', '.')]


------------------- Sentence 2 -------------------

In AAAI-98 workshop on learning for text categorization (Vol.

>> Tokens are: 
 ['In', 'AAAI-98', 'workshop', 'learning', 'text', 'categorization', '(', 'Vol', '.']

>> Bigrams are: 
 [('In', 'AAAI-98'), ('AAAI-98', 'workshop'), ('workshop', 'learning'), ('learning', 'text'), ('text', 'categorization'), ('categorization', '('), ('(', 'Vol'), ('Vol', '.')]

>> Trigrams are: 
 [('In', 'AAAI-98', 'workshop'), ('AAAI-98', 'workshop', 'learning'), ('workshop', 'learning', 'text'), ('learning', 'text', 'categorization'), ('text', 'categorization', '('), ('categorization', '(', 'Vol'), ('(', 'Vol', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('AAAI-98', 'NNP'), ('workshop', 'NN'), ('learning', 'VBG'), ('text', 'JJ'), ('categorization', 'NN'), ('(', '('), ('Vol', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['AAAI-98 workshop', 'text categorization', 'Vol']

>> Named Entities are: 
 [('ORGANIZATION', 'Vol')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('AAAI-98', 'aaai-98'), ('workshop', 'workshop'), ('learning', 'learn'), ('text', 'text'), ('categorization', 'categor'), ('(', '('), ('Vol', 'vol'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('AAAI-98', 'aaai-98'), ('workshop', 'workshop'), ('learning', 'learn'), ('text', 'text'), ('categorization', 'categor'), ('(', '('), ('Vol', 'vol'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('AAAI-98', 'AAAI-98'), ('workshop', 'workshop'), ('learning', 'learning'), ('text', 'text'), ('categorization', 'categorization'), ('(', '('), ('Vol', 'Vol'), ('.', '.')]


------------------- Sentence 3 -------------------

752, pp.

>> Tokens are: 
 ['752', ',', 'pp', '.']

>> Bigrams are: 
 [('752', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('752', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('752', 'CD'), (',', ','), ('pp', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['pp']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('752', '752'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('752', '752'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('752', '752'), (',', ','), ('pp', 'pp'), ('.', '.')]



========================================== PARAGRAPH 731 ===========================================

41-48).  

------------------- Sentence 1 -------------------

41-48).

>> Tokens are: 
 ['41-48', ')', '.']

>> Bigrams are: 
 [('41-48', ')'), (')', '.')]

>> Trigrams are: 
 [('41-48', ')', '.')]

>> POS Tags are: 
 [('41-48', 'JJ'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('41-48', '41-48'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('41-48', '41-48'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('41-48', '41-48'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 732 ===========================================

[56] Porter, M. F. (1980). An algorithm for suffix stripping. Program, 14(3), 130-137 

------------------- Sentence 1 -------------------

[56] Porter, M. F. (1980).

>> Tokens are: 
 ['[', '56', ']', 'Porter', ',', 'M.', 'F.', '(', '1980', ')', '.']

>> Bigrams are: 
 [('[', '56'), ('56', ']'), (']', 'Porter'), ('Porter', ','), (',', 'M.'), ('M.', 'F.'), ('F.', '('), ('(', '1980'), ('1980', ')'), (')', '.')]

>> Trigrams are: 
 [('[', '56', ']'), ('56', ']', 'Porter'), (']', 'Porter', ','), ('Porter', ',', 'M.'), (',', 'M.', 'F.'), ('M.', 'F.', '('), ('F.', '(', '1980'), ('(', '1980', ')'), ('1980', ')', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('56', 'CD'), (']', 'JJ'), ('Porter', 'NNP'), (',', ','), ('M.', 'NNP'), ('F.', 'NNP'), ('(', '('), ('1980', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['] Porter', 'M. F.']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('56', '56'), (']', ']'), ('Porter', 'porter'), (',', ','), ('M.', 'm.'), ('F.', 'f.'), ('(', '('), ('1980', '1980'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('56', '56'), (']', ']'), ('Porter', 'porter'), (',', ','), ('M.', 'm.'), ('F.', 'f.'), ('(', '('), ('1980', '1980'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('56', '56'), (']', ']'), ('Porter', 'Porter'), (',', ','), ('M.', 'M.'), ('F.', 'F.'), ('(', '('), ('1980', '1980'), (')', ')'), ('.', '.')]


------------------- Sentence 2 -------------------

An algorithm for suffix stripping.

>> Tokens are: 
 ['An', 'algorithm', 'suffix', 'stripping', '.']

>> Bigrams are: 
 [('An', 'algorithm'), ('algorithm', 'suffix'), ('suffix', 'stripping'), ('stripping', '.')]

>> Trigrams are: 
 [('An', 'algorithm', 'suffix'), ('algorithm', 'suffix', 'stripping'), ('suffix', 'stripping', '.')]

>> POS Tags are: 
 [('An', 'DT'), ('algorithm', 'JJ'), ('suffix', 'NN'), ('stripping', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['An algorithm suffix stripping']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('An', 'an'), ('algorithm', 'algorithm'), ('suffix', 'suffix'), ('stripping', 'strip'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('An', 'an'), ('algorithm', 'algorithm'), ('suffix', 'suffix'), ('stripping', 'strip'), ('.', '.')]

>> Lemmatization: 
 [('An', 'An'), ('algorithm', 'algorithm'), ('suffix', 'suffix'), ('stripping', 'stripping'), ('.', '.')]


------------------- Sentence 3 -------------------

Program, 14(3), 130-137

>> Tokens are: 
 ['Program', ',', '14', '(', '3', ')', ',', '130-137']

>> Bigrams are: 
 [('Program', ','), (',', '14'), ('14', '('), ('(', '3'), ('3', ')'), (')', ','), (',', '130-137')]

>> Trigrams are: 
 [('Program', ',', '14'), (',', '14', '('), ('14', '(', '3'), ('(', '3', ')'), ('3', ')', ','), (')', ',', '130-137')]

>> POS Tags are: 
 [('Program', 'NNP'), (',', ','), ('14', 'CD'), ('(', '('), ('3', 'CD'), (')', ')'), (',', ','), ('130-137', 'JJ')]

>> Noun Phrases are: 
 ['Program']

>> Named Entities are: 
 [('GPE', 'Program')] 

>> Stemming using Porter Stemmer: 
 [('Program', 'program'), (',', ','), ('14', '14'), ('(', '('), ('3', '3'), (')', ')'), (',', ','), ('130-137', '130-137')]

>> Stemming using Snowball Stemmer: 
 [('Program', 'program'), (',', ','), ('14', '14'), ('(', '('), ('3', '3'), (')', ')'), (',', ','), ('130-137', '130-137')]

>> Lemmatization: 
 [('Program', 'Program'), (',', ','), ('14', '14'), ('(', '('), ('3', '3'), (')', ')'), (',', ','), ('130-137', '130-137')]



========================================== PARAGRAPH 733 ===========================================

[57] Hayes, P. J. (1992). Intelligent high-volume text processing using shallow, domain- 

------------------- Sentence 1 -------------------

[57] Hayes, P. J.

>> Tokens are: 
 ['[', '57', ']', 'Hayes', ',', 'P.', 'J', '.']

>> Bigrams are: 
 [('[', '57'), ('57', ']'), (']', 'Hayes'), ('Hayes', ','), (',', 'P.'), ('P.', 'J'), ('J', '.')]

>> Trigrams are: 
 [('[', '57', ']'), ('57', ']', 'Hayes'), (']', 'Hayes', ','), ('Hayes', ',', 'P.'), (',', 'P.', 'J'), ('P.', 'J', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('57', 'CD'), (']', 'JJ'), ('Hayes', 'NNP'), (',', ','), ('P.', 'NNP'), ('J', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['] Hayes', 'P. J']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('57', '57'), (']', ']'), ('Hayes', 'hay'), (',', ','), ('P.', 'p.'), ('J', 'j'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('57', '57'), (']', ']'), ('Hayes', 'hay'), (',', ','), ('P.', 'p.'), ('J', 'j'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('57', '57'), (']', ']'), ('Hayes', 'Hayes'), (',', ','), ('P.', 'P.'), ('J', 'J'), ('.', '.')]


------------------- Sentence 2 -------------------

(1992).

>> Tokens are: 
 ['(', '1992', ')', '.']

>> Bigrams are: 
 [('(', '1992'), ('1992', ')'), (')', '.')]

>> Trigrams are: 
 [('(', '1992', ')'), ('1992', ')', '.')]

>> POS Tags are: 
 [('(', '('), ('1992', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('1992', '1992'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('1992', '1992'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('(', '('), ('1992', '1992'), (')', ')'), ('.', '.')]


------------------- Sentence 3 -------------------

Intelligent high-volume text processing using shallow, domain-

>> Tokens are: 
 ['Intelligent', 'high-volume', 'text', 'processing', 'using', 'shallow', ',', 'domain-']

>> Bigrams are: 
 [('Intelligent', 'high-volume'), ('high-volume', 'text'), ('text', 'processing'), ('processing', 'using'), ('using', 'shallow'), ('shallow', ','), (',', 'domain-')]

>> Trigrams are: 
 [('Intelligent', 'high-volume', 'text'), ('high-volume', 'text', 'processing'), ('text', 'processing', 'using'), ('processing', 'using', 'shallow'), ('using', 'shallow', ','), ('shallow', ',', 'domain-')]

>> POS Tags are: 
 [('Intelligent', 'JJ'), ('high-volume', 'JJ'), ('text', 'NN'), ('processing', 'NN'), ('using', 'VBG'), ('shallow', 'JJ'), (',', ','), ('domain-', 'JJ')]

>> Noun Phrases are: 
 ['Intelligent high-volume text processing']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Intelligent', 'intellig'), ('high-volume', 'high-volum'), ('text', 'text'), ('processing', 'process'), ('using', 'use'), ('shallow', 'shallow'), (',', ','), ('domain-', 'domain-')]

>> Stemming using Snowball Stemmer: 
 [('Intelligent', 'intellig'), ('high-volume', 'high-volum'), ('text', 'text'), ('processing', 'process'), ('using', 'use'), ('shallow', 'shallow'), (',', ','), ('domain-', 'domain-')]

>> Lemmatization: 
 [('Intelligent', 'Intelligent'), ('high-volume', 'high-volume'), ('text', 'text'), ('processing', 'processing'), ('using', 'using'), ('shallow', 'shallow'), (',', ','), ('domain-', 'domain-')]



========================================== PARAGRAPH 734 ===========================================

specific techniques. Text-based intelligent systems: Current research and practice in  

------------------- Sentence 1 -------------------

specific techniques.

>> Tokens are: 
 ['specific', 'techniques', '.']

>> Bigrams are: 
 [('specific', 'techniques'), ('techniques', '.')]

>> Trigrams are: 
 [('specific', 'techniques', '.')]

>> POS Tags are: 
 [('specific', 'JJ'), ('techniques', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['specific techniques']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('specific', 'specif'), ('techniques', 'techniqu'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('specific', 'specif'), ('techniques', 'techniqu'), ('.', '.')]

>> Lemmatization: 
 [('specific', 'specific'), ('techniques', 'technique'), ('.', '.')]


------------------- Sentence 2 -------------------

Text-based intelligent systems: Current research and practice in

>> Tokens are: 
 ['Text-based', 'intelligent', 'systems', ':', 'Current', 'research', 'practice']

>> Bigrams are: 
 [('Text-based', 'intelligent'), ('intelligent', 'systems'), ('systems', ':'), (':', 'Current'), ('Current', 'research'), ('research', 'practice')]

>> Trigrams are: 
 [('Text-based', 'intelligent', 'systems'), ('intelligent', 'systems', ':'), ('systems', ':', 'Current'), (':', 'Current', 'research'), ('Current', 'research', 'practice')]

>> POS Tags are: 
 [('Text-based', 'JJ'), ('intelligent', 'JJ'), ('systems', 'NNS'), (':', ':'), ('Current', 'NNP'), ('research', 'NN'), ('practice', 'NN')]

>> Noun Phrases are: 
 ['Text-based intelligent systems', 'Current research practice']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Text-based', 'text-bas'), ('intelligent', 'intellig'), ('systems', 'system'), (':', ':'), ('Current', 'current'), ('research', 'research'), ('practice', 'practic')]

>> Stemming using Snowball Stemmer: 
 [('Text-based', 'text-bas'), ('intelligent', 'intellig'), ('systems', 'system'), (':', ':'), ('Current', 'current'), ('research', 'research'), ('practice', 'practic')]

>> Lemmatization: 
 [('Text-based', 'Text-based'), ('intelligent', 'intelligent'), ('systems', 'system'), (':', ':'), ('Current', 'Current'), ('research', 'research'), ('practice', 'practice')]



========================================== PARAGRAPH 735 ===========================================

information extraction and retrieval, 227-242  

------------------- Sentence 1 -------------------

information extraction and retrieval, 227-242

>> Tokens are: 
 ['information', 'extraction', 'retrieval', ',', '227-242']

>> Bigrams are: 
 [('information', 'extraction'), ('extraction', 'retrieval'), ('retrieval', ','), (',', '227-242')]

>> Trigrams are: 
 [('information', 'extraction', 'retrieval'), ('extraction', 'retrieval', ','), ('retrieval', ',', '227-242')]

>> POS Tags are: 
 [('information', 'NN'), ('extraction', 'NN'), ('retrieval', 'NN'), (',', ','), ('227-242', 'JJ')]

>> Noun Phrases are: 
 ['information extraction retrieval']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('information', 'inform'), ('extraction', 'extract'), ('retrieval', 'retriev'), (',', ','), ('227-242', '227-242')]

>> Stemming using Snowball Stemmer: 
 [('information', 'inform'), ('extraction', 'extract'), ('retrieval', 'retriev'), (',', ','), ('227-242', '227-242')]

>> Lemmatization: 
 [('information', 'information'), ('extraction', 'extraction'), ('retrieval', 'retrieval'), (',', ','), ('227-242', '227-242')]



========================================== PARAGRAPH 736 ===========================================

[58] Morin, E. (1999, August). Automatic acquisition of semantic relations between terms  

------------------- Sentence 1 -------------------

[58] Morin, E. (1999, August).

>> Tokens are: 
 ['[', '58', ']', 'Morin', ',', 'E.', '(', '1999', ',', 'August', ')', '.']

>> Bigrams are: 
 [('[', '58'), ('58', ']'), (']', 'Morin'), ('Morin', ','), (',', 'E.'), ('E.', '('), ('(', '1999'), ('1999', ','), (',', 'August'), ('August', ')'), (')', '.')]

>> Trigrams are: 
 [('[', '58', ']'), ('58', ']', 'Morin'), (']', 'Morin', ','), ('Morin', ',', 'E.'), (',', 'E.', '('), ('E.', '(', '1999'), ('(', '1999', ','), ('1999', ',', 'August'), (',', 'August', ')'), ('August', ')', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('58', 'CD'), (']', 'JJ'), ('Morin', 'NNP'), (',', ','), ('E.', 'NNP'), ('(', '('), ('1999', 'CD'), (',', ','), ('August', 'NNP'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['] Morin', 'E.', 'August']

>> Named Entities are: 
 [('GPE', 'August')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('58', '58'), (']', ']'), ('Morin', 'morin'), (',', ','), ('E.', 'e.'), ('(', '('), ('1999', '1999'), (',', ','), ('August', 'august'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('58', '58'), (']', ']'), ('Morin', 'morin'), (',', ','), ('E.', 'e.'), ('(', '('), ('1999', '1999'), (',', ','), ('August', 'august'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('58', '58'), (']', ']'), ('Morin', 'Morin'), (',', ','), ('E.', 'E.'), ('(', '('), ('1999', '1999'), (',', ','), ('August', 'August'), (')', ')'), ('.', '.')]


------------------- Sentence 2 -------------------

Automatic acquisition of semantic relations between terms

>> Tokens are: 
 ['Automatic', 'acquisition', 'semantic', 'relations', 'terms']

>> Bigrams are: 
 [('Automatic', 'acquisition'), ('acquisition', 'semantic'), ('semantic', 'relations'), ('relations', 'terms')]

>> Trigrams are: 
 [('Automatic', 'acquisition', 'semantic'), ('acquisition', 'semantic', 'relations'), ('semantic', 'relations', 'terms')]

>> POS Tags are: 
 [('Automatic', 'JJ'), ('acquisition', 'NN'), ('semantic', 'JJ'), ('relations', 'NNS'), ('terms', 'NNS')]

>> Noun Phrases are: 
 ['Automatic acquisition', 'semantic relations terms']

>> Named Entities are: 
 [('GPE', 'Automatic')] 

>> Stemming using Porter Stemmer: 
 [('Automatic', 'automat'), ('acquisition', 'acquisit'), ('semantic', 'semant'), ('relations', 'relat'), ('terms', 'term')]

>> Stemming using Snowball Stemmer: 
 [('Automatic', 'automat'), ('acquisition', 'acquisit'), ('semantic', 'semant'), ('relations', 'relat'), ('terms', 'term')]

>> Lemmatization: 
 [('Automatic', 'Automatic'), ('acquisition', 'acquisition'), ('semantic', 'semantic'), ('relations', 'relation'), ('terms', 'term')]



========================================== PARAGRAPH 737 ===========================================

from technical corpora. In Proc. of the Fifth International Congress on Terminology and  

------------------- Sentence 1 -------------------

from technical corpora.

>> Tokens are: 
 ['technical', 'corpora', '.']

>> Bigrams are: 
 [('technical', 'corpora'), ('corpora', '.')]

>> Trigrams are: 
 [('technical', 'corpora', '.')]

>> POS Tags are: 
 [('technical', 'JJ'), ('corpora', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['technical corpora']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('technical', 'technic'), ('corpora', 'corpora'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('technical', 'technic'), ('corpora', 'corpora'), ('.', '.')]

>> Lemmatization: 
 [('technical', 'technical'), ('corpora', 'corpus'), ('.', '.')]


------------------- Sentence 2 -------------------

In Proc.

>> Tokens are: 
 ['In', 'Proc', '.']

>> Bigrams are: 
 [('In', 'Proc'), ('Proc', '.')]

>> Trigrams are: 
 [('In', 'Proc', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('Proc', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Proc']

>> Named Entities are: 
 [('GPE', 'Proc')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('Proc', 'proc'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('Proc', 'proc'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('Proc', 'Proc'), ('.', '.')]


------------------- Sentence 3 -------------------

of the Fifth International Congress on Terminology and

>> Tokens are: 
 ['Fifth', 'International', 'Congress', 'Terminology']

>> Bigrams are: 
 [('Fifth', 'International'), ('International', 'Congress'), ('Congress', 'Terminology')]

>> Trigrams are: 
 [('Fifth', 'International', 'Congress'), ('International', 'Congress', 'Terminology')]

>> POS Tags are: 
 [('Fifth', 'NNP'), ('International', 'NNP'), ('Congress', 'NNP'), ('Terminology', 'NNP')]

>> Noun Phrases are: 
 ['Fifth International Congress Terminology']

>> Named Entities are: 
 [('PERSON', 'Fifth'), ('ORGANIZATION', 'International Congress Terminology')] 

>> Stemming using Porter Stemmer: 
 [('Fifth', 'fifth'), ('International', 'intern'), ('Congress', 'congress'), ('Terminology', 'terminolog')]

>> Stemming using Snowball Stemmer: 
 [('Fifth', 'fifth'), ('International', 'intern'), ('Congress', 'congress'), ('Terminology', 'terminolog')]

>> Lemmatization: 
 [('Fifth', 'Fifth'), ('International', 'International'), ('Congress', 'Congress'), ('Terminology', 'Terminology')]



========================================== PARAGRAPH 738 ===========================================

Knowledge Engineering-TKE’99.  

------------------- Sentence 1 -------------------

Knowledge Engineering-TKE’99.

>> Tokens are: 
 ['Knowledge', 'Engineering-TKE', '’', '99', '.']

>> Bigrams are: 
 [('Knowledge', 'Engineering-TKE'), ('Engineering-TKE', '’'), ('’', '99'), ('99', '.')]

>> Trigrams are: 
 [('Knowledge', 'Engineering-TKE', '’'), ('Engineering-TKE', '’', '99'), ('’', '99', '.')]

>> POS Tags are: 
 [('Knowledge', 'NNP'), ('Engineering-TKE', 'NNP'), ('’', 'NNP'), ('99', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Knowledge Engineering-TKE ’']

>> Named Entities are: 
 [('PERSON', 'Knowledge')] 

>> Stemming using Porter Stemmer: 
 [('Knowledge', 'knowledg'), ('Engineering-TKE', 'engineering-tk'), ('’', '’'), ('99', '99'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Knowledge', 'knowledg'), ('Engineering-TKE', 'engineering-tk'), ('’', '’'), ('99', '99'), ('.', '.')]

>> Lemmatization: 
 [('Knowledge', 'Knowledge'), ('Engineering-TKE', 'Engineering-TKE'), ('’', '’'), ('99', '99'), ('.', '.')]



========================================== PARAGRAPH 739 ===========================================

[59] Bondale, N., Maloor, P., Vaidyanathan, A., Sengupta, S., & Rao, P. V. (1999).  

------------------- Sentence 1 -------------------

[59] Bondale, N., Maloor, P., Vaidyanathan, A., Sengupta, S., & Rao, P. V. (1999).

>> Tokens are: 
 ['[', '59', ']', 'Bondale', ',', 'N.', ',', 'Maloor', ',', 'P.', ',', 'Vaidyanathan', ',', 'A.', ',', 'Sengupta', ',', 'S.', ',', '&', 'Rao', ',', 'P.', 'V.', '(', '1999', ')', '.']

>> Bigrams are: 
 [('[', '59'), ('59', ']'), (']', 'Bondale'), ('Bondale', ','), (',', 'N.'), ('N.', ','), (',', 'Maloor'), ('Maloor', ','), (',', 'P.'), ('P.', ','), (',', 'Vaidyanathan'), ('Vaidyanathan', ','), (',', 'A.'), ('A.', ','), (',', 'Sengupta'), ('Sengupta', ','), (',', 'S.'), ('S.', ','), (',', '&'), ('&', 'Rao'), ('Rao', ','), (',', 'P.'), ('P.', 'V.'), ('V.', '('), ('(', '1999'), ('1999', ')'), (')', '.')]

>> Trigrams are: 
 [('[', '59', ']'), ('59', ']', 'Bondale'), (']', 'Bondale', ','), ('Bondale', ',', 'N.'), (',', 'N.', ','), ('N.', ',', 'Maloor'), (',', 'Maloor', ','), ('Maloor', ',', 'P.'), (',', 'P.', ','), ('P.', ',', 'Vaidyanathan'), (',', 'Vaidyanathan', ','), ('Vaidyanathan', ',', 'A.'), (',', 'A.', ','), ('A.', ',', 'Sengupta'), (',', 'Sengupta', ','), ('Sengupta', ',', 'S.'), (',', 'S.', ','), ('S.', ',', '&'), (',', '&', 'Rao'), ('&', 'Rao', ','), ('Rao', ',', 'P.'), (',', 'P.', 'V.'), ('P.', 'V.', '('), ('V.', '(', '1999'), ('(', '1999', ')'), ('1999', ')', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('59', 'CD'), (']', 'JJ'), ('Bondale', 'NNP'), (',', ','), ('N.', 'NNP'), (',', ','), ('Maloor', 'NNP'), (',', ','), ('P.', 'NNP'), (',', ','), ('Vaidyanathan', 'NNP'), (',', ','), ('A.', 'NNP'), (',', ','), ('Sengupta', 'NNP'), (',', ','), ('S.', 'NNP'), (',', ','), ('&', 'CC'), ('Rao', 'NNP'), (',', ','), ('P.', 'NNP'), ('V.', 'NNP'), ('(', '('), ('1999', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['] Bondale', 'N.', 'Maloor', 'P.', 'Vaidyanathan', 'A.', 'Sengupta', 'S.', 'Rao', 'P. V.']

>> Named Entities are: 
 [('GPE', 'Bondale'), ('GPE', 'Maloor'), ('GPE', 'Vaidyanathan'), ('GPE', 'Sengupta'), ('PERSON', 'Rao')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('59', '59'), (']', ']'), ('Bondale', 'bondal'), (',', ','), ('N.', 'n.'), (',', ','), ('Maloor', 'maloor'), (',', ','), ('P.', 'p.'), (',', ','), ('Vaidyanathan', 'vaidyanathan'), (',', ','), ('A.', 'a.'), (',', ','), ('Sengupta', 'sengupta'), (',', ','), ('S.', 's.'), (',', ','), ('&', '&'), ('Rao', 'rao'), (',', ','), ('P.', 'p.'), ('V.', 'v.'), ('(', '('), ('1999', '1999'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('59', '59'), (']', ']'), ('Bondale', 'bondal'), (',', ','), ('N.', 'n.'), (',', ','), ('Maloor', 'maloor'), (',', ','), ('P.', 'p.'), (',', ','), ('Vaidyanathan', 'vaidyanathan'), (',', ','), ('A.', 'a.'), (',', ','), ('Sengupta', 'sengupta'), (',', ','), ('S.', 's.'), (',', ','), ('&', '&'), ('Rao', 'rao'), (',', ','), ('P.', 'p.'), ('V.', 'v.'), ('(', '('), ('1999', '1999'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('59', '59'), (']', ']'), ('Bondale', 'Bondale'), (',', ','), ('N.', 'N.'), (',', ','), ('Maloor', 'Maloor'), (',', ','), ('P.', 'P.'), (',', ','), ('Vaidyanathan', 'Vaidyanathan'), (',', ','), ('A.', 'A.'), (',', ','), ('Sengupta', 'Sengupta'), (',', ','), ('S.', 'S.'), (',', ','), ('&', '&'), ('Rao', 'Rao'), (',', ','), ('P.', 'P.'), ('V.', 'V.'), ('(', '('), ('1999', '1999'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 740 ===========================================

Extraction of information from open-ended questionnaires using natural language processing  

------------------- Sentence 1 -------------------

Extraction of information from open-ended questionnaires using natural language processing

>> Tokens are: 
 ['Extraction', 'information', 'open-ended', 'questionnaires', 'using', 'natural', 'language', 'processing']

>> Bigrams are: 
 [('Extraction', 'information'), ('information', 'open-ended'), ('open-ended', 'questionnaires'), ('questionnaires', 'using'), ('using', 'natural'), ('natural', 'language'), ('language', 'processing')]

>> Trigrams are: 
 [('Extraction', 'information', 'open-ended'), ('information', 'open-ended', 'questionnaires'), ('open-ended', 'questionnaires', 'using'), ('questionnaires', 'using', 'natural'), ('using', 'natural', 'language'), ('natural', 'language', 'processing')]

>> POS Tags are: 
 [('Extraction', 'NN'), ('information', 'NN'), ('open-ended', 'JJ'), ('questionnaires', 'NNS'), ('using', 'VBG'), ('natural', 'JJ'), ('language', 'NN'), ('processing', 'NN')]

>> Noun Phrases are: 
 ['Extraction information', 'open-ended questionnaires', 'natural language processing']

>> Named Entities are: 
 [('GPE', 'Extraction')] 

>> Stemming using Porter Stemmer: 
 [('Extraction', 'extract'), ('information', 'inform'), ('open-ended', 'open-end'), ('questionnaires', 'questionnair'), ('using', 'use'), ('natural', 'natur'), ('language', 'languag'), ('processing', 'process')]

>> Stemming using Snowball Stemmer: 
 [('Extraction', 'extract'), ('information', 'inform'), ('open-ended', 'open-end'), ('questionnaires', 'questionnair'), ('using', 'use'), ('natural', 'natur'), ('language', 'languag'), ('processing', 'process')]

>> Lemmatization: 
 [('Extraction', 'Extraction'), ('information', 'information'), ('open-ended', 'open-ended'), ('questionnaires', 'questionnaire'), ('using', 'using'), ('natural', 'natural'), ('language', 'language'), ('processing', 'processing')]



========================================== PARAGRAPH 741 ===========================================

techniques. Computer Science and Informatics, 29(2), 15-22  

------------------- Sentence 1 -------------------

techniques.

>> Tokens are: 
 ['techniques', '.']

>> Bigrams are: 
 [('techniques', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('techniques', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['techniques']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('techniques', 'techniqu'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('techniques', 'techniqu'), ('.', '.')]

>> Lemmatization: 
 [('techniques', 'technique'), ('.', '.')]


------------------- Sentence 2 -------------------

Computer Science and Informatics, 29(2), 15-22

>> Tokens are: 
 ['Computer', 'Science', 'Informatics', ',', '29', '(', '2', ')', ',', '15-22']

>> Bigrams are: 
 [('Computer', 'Science'), ('Science', 'Informatics'), ('Informatics', ','), (',', '29'), ('29', '('), ('(', '2'), ('2', ')'), (')', ','), (',', '15-22')]

>> Trigrams are: 
 [('Computer', 'Science', 'Informatics'), ('Science', 'Informatics', ','), ('Informatics', ',', '29'), (',', '29', '('), ('29', '(', '2'), ('(', '2', ')'), ('2', ')', ','), (')', ',', '15-22')]

>> POS Tags are: 
 [('Computer', 'NNP'), ('Science', 'NNP'), ('Informatics', 'NNP'), (',', ','), ('29', 'CD'), ('(', '('), ('2', 'CD'), (')', ')'), (',', ','), ('15-22', 'JJ')]

>> Noun Phrases are: 
 ['Computer Science Informatics']

>> Named Entities are: 
 [('ORGANIZATION', 'Computer Science Informatics')] 

>> Stemming using Porter Stemmer: 
 [('Computer', 'comput'), ('Science', 'scienc'), ('Informatics', 'informat'), (',', ','), ('29', '29'), ('(', '('), ('2', '2'), (')', ')'), (',', ','), ('15-22', '15-22')]

>> Stemming using Snowball Stemmer: 
 [('Computer', 'comput'), ('Science', 'scienc'), ('Informatics', 'informat'), (',', ','), ('29', '29'), ('(', '('), ('2', '2'), (')', ')'), (',', ','), ('15-22', '15-22')]

>> Lemmatization: 
 [('Computer', 'Computer'), ('Science', 'Science'), ('Informatics', 'Informatics'), (',', ','), ('29', '29'), ('(', '('), ('2', '2'), (')', ')'), (',', ','), ('15-22', '15-22')]



========================================== PARAGRAPH 742 ===========================================

[60] Glasgow, B., Mandell, A., Binney, D., Ghemri, L., & Fisher, D. (1998). MITA: An  

------------------- Sentence 1 -------------------

[60] Glasgow, B., Mandell, A., Binney, D., Ghemri, L., & Fisher, D. (1998).

>> Tokens are: 
 ['[', '60', ']', 'Glasgow', ',', 'B.', ',', 'Mandell', ',', 'A.', ',', 'Binney', ',', 'D.', ',', 'Ghemri', ',', 'L.', ',', '&', 'Fisher', ',', 'D.', '(', '1998', ')', '.']

>> Bigrams are: 
 [('[', '60'), ('60', ']'), (']', 'Glasgow'), ('Glasgow', ','), (',', 'B.'), ('B.', ','), (',', 'Mandell'), ('Mandell', ','), (',', 'A.'), ('A.', ','), (',', 'Binney'), ('Binney', ','), (',', 'D.'), ('D.', ','), (',', 'Ghemri'), ('Ghemri', ','), (',', 'L.'), ('L.', ','), (',', '&'), ('&', 'Fisher'), ('Fisher', ','), (',', 'D.'), ('D.', '('), ('(', '1998'), ('1998', ')'), (')', '.')]

>> Trigrams are: 
 [('[', '60', ']'), ('60', ']', 'Glasgow'), (']', 'Glasgow', ','), ('Glasgow', ',', 'B.'), (',', 'B.', ','), ('B.', ',', 'Mandell'), (',', 'Mandell', ','), ('Mandell', ',', 'A.'), (',', 'A.', ','), ('A.', ',', 'Binney'), (',', 'Binney', ','), ('Binney', ',', 'D.'), (',', 'D.', ','), ('D.', ',', 'Ghemri'), (',', 'Ghemri', ','), ('Ghemri', ',', 'L.'), (',', 'L.', ','), ('L.', ',', '&'), (',', '&', 'Fisher'), ('&', 'Fisher', ','), ('Fisher', ',', 'D.'), (',', 'D.', '('), ('D.', '(', '1998'), ('(', '1998', ')'), ('1998', ')', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('60', 'CD'), (']', 'JJ'), ('Glasgow', 'NNP'), (',', ','), ('B.', 'NNP'), (',', ','), ('Mandell', 'NNP'), (',', ','), ('A.', 'NNP'), (',', ','), ('Binney', 'NNP'), (',', ','), ('D.', 'NNP'), (',', ','), ('Ghemri', 'NNP'), (',', ','), ('L.', 'NNP'), (',', ','), ('&', 'CC'), ('Fisher', 'NNP'), (',', ','), ('D.', 'NNP'), ('(', '('), ('1998', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['] Glasgow', 'B.', 'Mandell', 'A.', 'Binney', 'D.', 'Ghemri', 'L.', 'Fisher', 'D.']

>> Named Entities are: 
 [('PERSON', 'Mandell'), ('GPE', 'Binney'), ('GPE', 'Ghemri'), ('PERSON', 'Fisher')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('60', '60'), (']', ']'), ('Glasgow', 'glasgow'), (',', ','), ('B.', 'b.'), (',', ','), ('Mandell', 'mandel'), (',', ','), ('A.', 'a.'), (',', ','), ('Binney', 'binney'), (',', ','), ('D.', 'd.'), (',', ','), ('Ghemri', 'ghemri'), (',', ','), ('L.', 'l.'), (',', ','), ('&', '&'), ('Fisher', 'fisher'), (',', ','), ('D.', 'd.'), ('(', '('), ('1998', '1998'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('60', '60'), (']', ']'), ('Glasgow', 'glasgow'), (',', ','), ('B.', 'b.'), (',', ','), ('Mandell', 'mandel'), (',', ','), ('A.', 'a.'), (',', ','), ('Binney', 'binney'), (',', ','), ('D.', 'd.'), (',', ','), ('Ghemri', 'ghemri'), (',', ','), ('L.', 'l.'), (',', ','), ('&', '&'), ('Fisher', 'fisher'), (',', ','), ('D.', 'd.'), ('(', '('), ('1998', '1998'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('60', '60'), (']', ']'), ('Glasgow', 'Glasgow'), (',', ','), ('B.', 'B.'), (',', ','), ('Mandell', 'Mandell'), (',', ','), ('A.', 'A.'), (',', ','), ('Binney', 'Binney'), (',', ','), ('D.', 'D.'), (',', ','), ('Ghemri', 'Ghemri'), (',', ','), ('L.', 'L.'), (',', ','), ('&', '&'), ('Fisher', 'Fisher'), (',', ','), ('D.', 'D.'), ('(', '('), ('1998', '1998'), (')', ')'), ('.', '.')]


------------------- Sentence 2 -------------------

MITA: An

>> Tokens are: 
 ['MITA', ':', 'An']

>> Bigrams are: 
 [('MITA', ':'), (':', 'An')]

>> Trigrams are: 
 [('MITA', ':', 'An')]

>> POS Tags are: 
 [('MITA', 'NN'), (':', ':'), ('An', 'DT')]

>> Noun Phrases are: 
 ['MITA']

>> Named Entities are: 
 [('GPE', 'MITA')] 

>> Stemming using Porter Stemmer: 
 [('MITA', 'mita'), (':', ':'), ('An', 'an')]

>> Stemming using Snowball Stemmer: 
 [('MITA', 'mita'), (':', ':'), ('An', 'an')]

>> Lemmatization: 
 [('MITA', 'MITA'), (':', ':'), ('An', 'An')]



========================================== PARAGRAPH 743 ===========================================

information-extraction approach to the analysis of free-form text in life insurance  

------------------- Sentence 1 -------------------

information-extraction approach to the analysis of free-form text in life insurance

>> Tokens are: 
 ['information-extraction', 'approach', 'analysis', 'free-form', 'text', 'life', 'insurance']

>> Bigrams are: 
 [('information-extraction', 'approach'), ('approach', 'analysis'), ('analysis', 'free-form'), ('free-form', 'text'), ('text', 'life'), ('life', 'insurance')]

>> Trigrams are: 
 [('information-extraction', 'approach', 'analysis'), ('approach', 'analysis', 'free-form'), ('analysis', 'free-form', 'text'), ('free-form', 'text', 'life'), ('text', 'life', 'insurance')]

>> POS Tags are: 
 [('information-extraction', 'NN'), ('approach', 'NN'), ('analysis', 'NN'), ('free-form', 'JJ'), ('text', 'JJ'), ('life', 'NN'), ('insurance', 'NN')]

>> Noun Phrases are: 
 ['information-extraction approach analysis', 'free-form text life insurance']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('information-extraction', 'information-extract'), ('approach', 'approach'), ('analysis', 'analysi'), ('free-form', 'free-form'), ('text', 'text'), ('life', 'life'), ('insurance', 'insur')]

>> Stemming using Snowball Stemmer: 
 [('information-extraction', 'information-extract'), ('approach', 'approach'), ('analysis', 'analysi'), ('free-form', 'free-form'), ('text', 'text'), ('life', 'life'), ('insurance', 'insur')]

>> Lemmatization: 
 [('information-extraction', 'information-extraction'), ('approach', 'approach'), ('analysis', 'analysis'), ('free-form', 'free-form'), ('text', 'text'), ('life', 'life'), ('insurance', 'insurance')]



========================================== PARAGRAPH 744 ===========================================

applications. AI magazine, 19(1), 59.  

------------------- Sentence 1 -------------------

applications.

>> Tokens are: 
 ['applications', '.']

>> Bigrams are: 
 [('applications', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('applications', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['applications']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('applications', 'applic'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('applications', 'applic'), ('.', '.')]

>> Lemmatization: 
 [('applications', 'application'), ('.', '.')]


------------------- Sentence 2 -------------------

AI magazine, 19(1), 59.

>> Tokens are: 
 ['AI', 'magazine', ',', '19', '(', '1', ')', ',', '59', '.']

>> Bigrams are: 
 [('AI', 'magazine'), ('magazine', ','), (',', '19'), ('19', '('), ('(', '1'), ('1', ')'), (')', ','), (',', '59'), ('59', '.')]

>> Trigrams are: 
 [('AI', 'magazine', ','), ('magazine', ',', '19'), (',', '19', '('), ('19', '(', '1'), ('(', '1', ')'), ('1', ')', ','), (')', ',', '59'), (',', '59', '.')]

>> POS Tags are: 
 [('AI', 'NNP'), ('magazine', 'NN'), (',', ','), ('19', 'CD'), ('(', '('), ('1', 'CD'), (')', ')'), (',', ','), ('59', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['AI magazine']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('AI', 'ai'), ('magazine', 'magazin'), (',', ','), ('19', '19'), ('(', '('), ('1', '1'), (')', ')'), (',', ','), ('59', '59'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('AI', 'ai'), ('magazine', 'magazin'), (',', ','), ('19', '19'), ('(', '('), ('1', '1'), (')', ')'), (',', ','), ('59', '59'), ('.', '.')]

>> Lemmatization: 
 [('AI', 'AI'), ('magazine', 'magazine'), (',', ','), ('19', '19'), ('(', '('), ('1', '1'), (')', ')'), (',', ','), ('59', '59'), ('.', '.')]



========================================== PARAGRAPH 745 ===========================================

[61] Ahonen, H., Heinonen, O., Klemettinen, M., & Verkamo, A. I. (1998, April). Applying  

------------------- Sentence 1 -------------------

[61] Ahonen, H., Heinonen, O., Klemettinen, M., & Verkamo, A. I.

>> Tokens are: 
 ['[', '61', ']', 'Ahonen', ',', 'H.', ',', 'Heinonen', ',', 'O.', ',', 'Klemettinen', ',', 'M.', ',', '&', 'Verkamo', ',', 'A.', 'I', '.']

>> Bigrams are: 
 [('[', '61'), ('61', ']'), (']', 'Ahonen'), ('Ahonen', ','), (',', 'H.'), ('H.', ','), (',', 'Heinonen'), ('Heinonen', ','), (',', 'O.'), ('O.', ','), (',', 'Klemettinen'), ('Klemettinen', ','), (',', 'M.'), ('M.', ','), (',', '&'), ('&', 'Verkamo'), ('Verkamo', ','), (',', 'A.'), ('A.', 'I'), ('I', '.')]

>> Trigrams are: 
 [('[', '61', ']'), ('61', ']', 'Ahonen'), (']', 'Ahonen', ','), ('Ahonen', ',', 'H.'), (',', 'H.', ','), ('H.', ',', 'Heinonen'), (',', 'Heinonen', ','), ('Heinonen', ',', 'O.'), (',', 'O.', ','), ('O.', ',', 'Klemettinen'), (',', 'Klemettinen', ','), ('Klemettinen', ',', 'M.'), (',', 'M.', ','), ('M.', ',', '&'), (',', '&', 'Verkamo'), ('&', 'Verkamo', ','), ('Verkamo', ',', 'A.'), (',', 'A.', 'I'), ('A.', 'I', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('61', 'CD'), (']', 'JJ'), ('Ahonen', 'NNP'), (',', ','), ('H.', 'NNP'), (',', ','), ('Heinonen', 'NNP'), (',', ','), ('O.', 'NNP'), (',', ','), ('Klemettinen', 'NNP'), (',', ','), ('M.', 'NNP'), (',', ','), ('&', 'CC'), ('Verkamo', 'NNP'), (',', ','), ('A.', 'NNP'), ('I', 'PRP'), ('.', '.')]

>> Noun Phrases are: 
 ['] Ahonen', 'H.', 'Heinonen', 'O.', 'Klemettinen', 'M.', 'Verkamo', 'A.']

>> Named Entities are: 
 [('GPE', 'Ahonen'), ('GPE', 'Heinonen'), ('GPE', 'Klemettinen'), ('PERSON', 'Verkamo')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('61', '61'), (']', ']'), ('Ahonen', 'ahonen'), (',', ','), ('H.', 'h.'), (',', ','), ('Heinonen', 'heinonen'), (',', ','), ('O.', 'o.'), (',', ','), ('Klemettinen', 'klemettinen'), (',', ','), ('M.', 'm.'), (',', ','), ('&', '&'), ('Verkamo', 'verkamo'), (',', ','), ('A.', 'a.'), ('I', 'i'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('61', '61'), (']', ']'), ('Ahonen', 'ahonen'), (',', ','), ('H.', 'h.'), (',', ','), ('Heinonen', 'heinonen'), (',', ','), ('O.', 'o.'), (',', ','), ('Klemettinen', 'klemettinen'), (',', ','), ('M.', 'm.'), (',', ','), ('&', '&'), ('Verkamo', 'verkamo'), (',', ','), ('A.', 'a.'), ('I', 'i'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('61', '61'), (']', ']'), ('Ahonen', 'Ahonen'), (',', ','), ('H.', 'H.'), (',', ','), ('Heinonen', 'Heinonen'), (',', ','), ('O.', 'O.'), (',', ','), ('Klemettinen', 'Klemettinen'), (',', ','), ('M.', 'M.'), (',', ','), ('&', '&'), ('Verkamo', 'Verkamo'), (',', ','), ('A.', 'A.'), ('I', 'I'), ('.', '.')]


------------------- Sentence 2 -------------------

(1998, April).

>> Tokens are: 
 ['(', '1998', ',', 'April', ')', '.']

>> Bigrams are: 
 [('(', '1998'), ('1998', ','), (',', 'April'), ('April', ')'), (')', '.')]

>> Trigrams are: 
 [('(', '1998', ','), ('1998', ',', 'April'), (',', 'April', ')'), ('April', ')', '.')]

>> POS Tags are: 
 [('(', '('), ('1998', 'CD'), (',', ','), ('April', 'NNP'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['April']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('1998', '1998'), (',', ','), ('April', 'april'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('1998', '1998'), (',', ','), ('April', 'april'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('(', '('), ('1998', '1998'), (',', ','), ('April', 'April'), (')', ')'), ('.', '.')]


------------------- Sentence 3 -------------------

Applying

>> Tokens are: 
 ['Applying']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Applying', 'VBG')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Applying', 'appli')]

>> Stemming using Snowball Stemmer: 
 [('Applying', 'appli')]

>> Lemmatization: 
 [('Applying', 'Applying')]



========================================== PARAGRAPH 746 ===========================================

data mining techniques for descriptive phrase extraction in digital document collections.  

------------------- Sentence 1 -------------------

data mining techniques for descriptive phrase extraction in digital document collections.

>> Tokens are: 
 ['data', 'mining', 'techniques', 'descriptive', 'phrase', 'extraction', 'digital', 'document', 'collections', '.']

>> Bigrams are: 
 [('data', 'mining'), ('mining', 'techniques'), ('techniques', 'descriptive'), ('descriptive', 'phrase'), ('phrase', 'extraction'), ('extraction', 'digital'), ('digital', 'document'), ('document', 'collections'), ('collections', '.')]

>> Trigrams are: 
 [('data', 'mining', 'techniques'), ('mining', 'techniques', 'descriptive'), ('techniques', 'descriptive', 'phrase'), ('descriptive', 'phrase', 'extraction'), ('phrase', 'extraction', 'digital'), ('extraction', 'digital', 'document'), ('digital', 'document', 'collections'), ('document', 'collections', '.')]

>> POS Tags are: 
 [('data', 'NNS'), ('mining', 'NN'), ('techniques', 'NNS'), ('descriptive', 'JJ'), ('phrase', 'NN'), ('extraction', 'NN'), ('digital', 'JJ'), ('document', 'NN'), ('collections', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['data mining techniques', 'descriptive phrase extraction', 'digital document collections']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('data', 'data'), ('mining', 'mine'), ('techniques', 'techniqu'), ('descriptive', 'descript'), ('phrase', 'phrase'), ('extraction', 'extract'), ('digital', 'digit'), ('document', 'document'), ('collections', 'collect'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('data', 'data'), ('mining', 'mine'), ('techniques', 'techniqu'), ('descriptive', 'descript'), ('phrase', 'phrase'), ('extraction', 'extract'), ('digital', 'digit'), ('document', 'document'), ('collections', 'collect'), ('.', '.')]

>> Lemmatization: 
 [('data', 'data'), ('mining', 'mining'), ('techniques', 'technique'), ('descriptive', 'descriptive'), ('phrase', 'phrase'), ('extraction', 'extraction'), ('digital', 'digital'), ('document', 'document'), ('collections', 'collection'), ('.', '.')]



========================================== PARAGRAPH 747 ===========================================

In Research and Technology Advances in Digital Libraries, 1998. ADL 98. Proceedings.  

------------------- Sentence 1 -------------------

In Research and Technology Advances in Digital Libraries, 1998.

>> Tokens are: 
 ['In', 'Research', 'Technology', 'Advances', 'Digital', 'Libraries', ',', '1998', '.']

>> Bigrams are: 
 [('In', 'Research'), ('Research', 'Technology'), ('Technology', 'Advances'), ('Advances', 'Digital'), ('Digital', 'Libraries'), ('Libraries', ','), (',', '1998'), ('1998', '.')]

>> Trigrams are: 
 [('In', 'Research', 'Technology'), ('Research', 'Technology', 'Advances'), ('Technology', 'Advances', 'Digital'), ('Advances', 'Digital', 'Libraries'), ('Digital', 'Libraries', ','), ('Libraries', ',', '1998'), (',', '1998', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('Research', 'NNP'), ('Technology', 'NNP'), ('Advances', 'NNP'), ('Digital', 'NNP'), ('Libraries', 'NNP'), (',', ','), ('1998', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Research Technology Advances Digital Libraries']

>> Named Entities are: 
 [('GPE', 'Research'), ('ORGANIZATION', 'Digital Libraries')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('Research', 'research'), ('Technology', 'technolog'), ('Advances', 'advanc'), ('Digital', 'digit'), ('Libraries', 'librari'), (',', ','), ('1998', '1998'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('Research', 'research'), ('Technology', 'technolog'), ('Advances', 'advanc'), ('Digital', 'digit'), ('Libraries', 'librari'), (',', ','), ('1998', '1998'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('Research', 'Research'), ('Technology', 'Technology'), ('Advances', 'Advances'), ('Digital', 'Digital'), ('Libraries', 'Libraries'), (',', ','), ('1998', '1998'), ('.', '.')]


------------------- Sentence 2 -------------------

ADL 98.

>> Tokens are: 
 ['ADL', '98', '.']

>> Bigrams are: 
 [('ADL', '98'), ('98', '.')]

>> Trigrams are: 
 [('ADL', '98', '.')]

>> POS Tags are: 
 [('ADL', '$'), ('98', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('ADL', 'adl'), ('98', '98'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('ADL', 'adl'), ('98', '98'), ('.', '.')]

>> Lemmatization: 
 [('ADL', 'ADL'), ('98', '98'), ('.', '.')]


------------------- Sentence 3 -------------------

Proceedings.

>> Tokens are: 
 ['Proceedings', '.']

>> Bigrams are: 
 [('Proceedings', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Proceedings', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['Proceedings']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Proceedings', 'proceed'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Proceedings', 'proceed'), ('.', '.')]

>> Lemmatization: 
 [('Proceedings', 'Proceedings'), ('.', '.')]



========================================== PARAGRAPH 748 ===========================================

IEEE International Forum on (pp. 2-11). IEEE.  

------------------- Sentence 1 -------------------

IEEE International Forum on (pp.

>> Tokens are: 
 ['IEEE', 'International', 'Forum', '(', 'pp', '.']

>> Bigrams are: 
 [('IEEE', 'International'), ('International', 'Forum'), ('Forum', '('), ('(', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('IEEE', 'International', 'Forum'), ('International', 'Forum', '('), ('Forum', '(', 'pp'), ('(', 'pp', '.')]

>> POS Tags are: 
 [('IEEE', 'NNP'), ('International', 'NNP'), ('Forum', 'NNP'), ('(', '('), ('pp', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['IEEE International Forum', 'pp']

>> Named Entities are: 
 [('ORGANIZATION', 'IEEE'), ('ORGANIZATION', 'International Forum')] 

>> Stemming using Porter Stemmer: 
 [('IEEE', 'ieee'), ('International', 'intern'), ('Forum', 'forum'), ('(', '('), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('IEEE', 'ieee'), ('International', 'intern'), ('Forum', 'forum'), ('(', '('), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('IEEE', 'IEEE'), ('International', 'International'), ('Forum', 'Forum'), ('(', '('), ('pp', 'pp'), ('.', '.')]


------------------- Sentence 2 -------------------

2-11).

>> Tokens are: 
 ['2-11', ')', '.']

>> Bigrams are: 
 [('2-11', ')'), (')', '.')]

>> Trigrams are: 
 [('2-11', ')', '.')]

>> POS Tags are: 
 [('2-11', 'JJ'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('2-11', '2-11'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('2-11', '2-11'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('2-11', '2-11'), (')', ')'), ('.', '.')]


------------------- Sentence 3 -------------------

IEEE.

>> Tokens are: 
 ['IEEE', '.']

>> Bigrams are: 
 [('IEEE', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('IEEE', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['IEEE']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('IEEE', 'ieee'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('IEEE', 'ieee'), ('.', '.')]

>> Lemmatization: 
 [('IEEE', 'IEEE'), ('.', '.')]



========================================== PARAGRAPH 749 ===========================================

[62] Zajic, D. M., Dorr, B. J., & Lin, J. (2008). Single-document and multi-document  

------------------- Sentence 1 -------------------

[62] Zajic, D. M., Dorr, B. J., & Lin, J.

>> Tokens are: 
 ['[', '62', ']', 'Zajic', ',', 'D.', 'M.', ',', 'Dorr', ',', 'B.', 'J.', ',', '&', 'Lin', ',', 'J', '.']

>> Bigrams are: 
 [('[', '62'), ('62', ']'), (']', 'Zajic'), ('Zajic', ','), (',', 'D.'), ('D.', 'M.'), ('M.', ','), (',', 'Dorr'), ('Dorr', ','), (',', 'B.'), ('B.', 'J.'), ('J.', ','), (',', '&'), ('&', 'Lin'), ('Lin', ','), (',', 'J'), ('J', '.')]

>> Trigrams are: 
 [('[', '62', ']'), ('62', ']', 'Zajic'), (']', 'Zajic', ','), ('Zajic', ',', 'D.'), (',', 'D.', 'M.'), ('D.', 'M.', ','), ('M.', ',', 'Dorr'), (',', 'Dorr', ','), ('Dorr', ',', 'B.'), (',', 'B.', 'J.'), ('B.', 'J.', ','), ('J.', ',', '&'), (',', '&', 'Lin'), ('&', 'Lin', ','), ('Lin', ',', 'J'), (',', 'J', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('62', 'CD'), (']', 'JJ'), ('Zajic', 'NNP'), (',', ','), ('D.', 'NNP'), ('M.', 'NNP'), (',', ','), ('Dorr', 'NNP'), (',', ','), ('B.', 'NNP'), ('J.', 'NNP'), (',', ','), ('&', 'CC'), ('Lin', 'NNP'), (',', ','), ('J', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['] Zajic', 'D. M.', 'Dorr', 'B. J.', 'Lin', 'J']

>> Named Entities are: 
 [('PERSON', 'Dorr'), ('PERSON', 'Lin')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('62', '62'), (']', ']'), ('Zajic', 'zajic'), (',', ','), ('D.', 'd.'), ('M.', 'm.'), (',', ','), ('Dorr', 'dorr'), (',', ','), ('B.', 'b.'), ('J.', 'j.'), (',', ','), ('&', '&'), ('Lin', 'lin'), (',', ','), ('J', 'j'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('62', '62'), (']', ']'), ('Zajic', 'zajic'), (',', ','), ('D.', 'd.'), ('M.', 'm.'), (',', ','), ('Dorr', 'dorr'), (',', ','), ('B.', 'b.'), ('J.', 'j.'), (',', ','), ('&', '&'), ('Lin', 'lin'), (',', ','), ('J', 'j'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('62', '62'), (']', ']'), ('Zajic', 'Zajic'), (',', ','), ('D.', 'D.'), ('M.', 'M.'), (',', ','), ('Dorr', 'Dorr'), (',', ','), ('B.', 'B.'), ('J.', 'J.'), (',', ','), ('&', '&'), ('Lin', 'Lin'), (',', ','), ('J', 'J'), ('.', '.')]


------------------- Sentence 2 -------------------

(2008).

>> Tokens are: 
 ['(', '2008', ')', '.']

>> Bigrams are: 
 [('(', '2008'), ('2008', ')'), (')', '.')]

>> Trigrams are: 
 [('(', '2008', ')'), ('2008', ')', '.')]

>> POS Tags are: 
 [('(', '('), ('2008', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('2008', '2008'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('2008', '2008'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('(', '('), ('2008', '2008'), (')', ')'), ('.', '.')]


------------------- Sentence 3 -------------------

Single-document and multi-document

>> Tokens are: 
 ['Single-document', 'multi-document']

>> Bigrams are: 
 [('Single-document', 'multi-document')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Single-document', 'JJ'), ('multi-document', 'NN')]

>> Noun Phrases are: 
 ['Single-document multi-document']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Single-document', 'single-docu'), ('multi-document', 'multi-docu')]

>> Stemming using Snowball Stemmer: 
 [('Single-document', 'single-docu'), ('multi-document', 'multi-docu')]

>> Lemmatization: 
 [('Single-document', 'Single-document'), ('multi-document', 'multi-document')]



========================================== PARAGRAPH 750 ===========================================

summarization techniques for email threads using sentence compression. Information  

------------------- Sentence 1 -------------------

summarization techniques for email threads using sentence compression.

>> Tokens are: 
 ['summarization', 'techniques', 'email', 'threads', 'using', 'sentence', 'compression', '.']

>> Bigrams are: 
 [('summarization', 'techniques'), ('techniques', 'email'), ('email', 'threads'), ('threads', 'using'), ('using', 'sentence'), ('sentence', 'compression'), ('compression', '.')]

>> Trigrams are: 
 [('summarization', 'techniques', 'email'), ('techniques', 'email', 'threads'), ('email', 'threads', 'using'), ('threads', 'using', 'sentence'), ('using', 'sentence', 'compression'), ('sentence', 'compression', '.')]

>> POS Tags are: 
 [('summarization', 'NN'), ('techniques', 'NNS'), ('email', 'VBP'), ('threads', 'NNS'), ('using', 'VBG'), ('sentence', 'NN'), ('compression', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['summarization techniques', 'threads', 'sentence compression']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('summarization', 'summar'), ('techniques', 'techniqu'), ('email', 'email'), ('threads', 'thread'), ('using', 'use'), ('sentence', 'sentenc'), ('compression', 'compress'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('summarization', 'summar'), ('techniques', 'techniqu'), ('email', 'email'), ('threads', 'thread'), ('using', 'use'), ('sentence', 'sentenc'), ('compression', 'compress'), ('.', '.')]

>> Lemmatization: 
 [('summarization', 'summarization'), ('techniques', 'technique'), ('email', 'email'), ('threads', 'thread'), ('using', 'using'), ('sentence', 'sentence'), ('compression', 'compression'), ('.', '.')]


------------------- Sentence 2 -------------------

Information

>> Tokens are: 
 ['Information']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Information', 'NN')]

>> Noun Phrases are: 
 ['Information']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Information', 'inform')]

>> Stemming using Snowball Stemmer: 
 [('Information', 'inform')]

>> Lemmatization: 
 [('Information', 'Information')]



========================================== PARAGRAPH 751 ===========================================

Processing & Management, 44(4), 1600-1610.  

------------------- Sentence 1 -------------------

Processing & Management, 44(4), 1600-1610.

>> Tokens are: 
 ['Processing', '&', 'Management', ',', '44', '(', '4', ')', ',', '1600-1610', '.']

>> Bigrams are: 
 [('Processing', '&'), ('&', 'Management'), ('Management', ','), (',', '44'), ('44', '('), ('(', '4'), ('4', ')'), (')', ','), (',', '1600-1610'), ('1600-1610', '.')]

>> Trigrams are: 
 [('Processing', '&', 'Management'), ('&', 'Management', ','), ('Management', ',', '44'), (',', '44', '('), ('44', '(', '4'), ('(', '4', ')'), ('4', ')', ','), (')', ',', '1600-1610'), (',', '1600-1610', '.')]

>> POS Tags are: 
 [('Processing', 'VBG'), ('&', 'CC'), ('Management', 'NNP'), (',', ','), ('44', 'CD'), ('(', '('), ('4', 'CD'), (')', ')'), (',', ','), ('1600-1610', 'JJ'), ('.', '.')]

>> Noun Phrases are: 
 ['Management']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Processing', 'process'), ('&', '&'), ('Management', 'manag'), (',', ','), ('44', '44'), ('(', '('), ('4', '4'), (')', ')'), (',', ','), ('1600-1610', '1600-1610'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Processing', 'process'), ('&', '&'), ('Management', 'manag'), (',', ','), ('44', '44'), ('(', '('), ('4', '4'), (')', ')'), (',', ','), ('1600-1610', '1600-1610'), ('.', '.')]

>> Lemmatization: 
 [('Processing', 'Processing'), ('&', '&'), ('Management', 'Management'), (',', ','), ('44', '44'), ('(', '('), ('4', '4'), (')', ')'), (',', ','), ('1600-1610', '1600-1610'), ('.', '.')]



========================================== PARAGRAPH 752 ===========================================

[63] Fattah, M. A., & Ren, F. (2009). GA, MR, FFNN, PNN and GMM based models for  

------------------- Sentence 1 -------------------

[63] Fattah, M. A., & Ren, F. (2009).

>> Tokens are: 
 ['[', '63', ']', 'Fattah', ',', 'M.', 'A.', ',', '&', 'Ren', ',', 'F.', '(', '2009', ')', '.']

>> Bigrams are: 
 [('[', '63'), ('63', ']'), (']', 'Fattah'), ('Fattah', ','), (',', 'M.'), ('M.', 'A.'), ('A.', ','), (',', '&'), ('&', 'Ren'), ('Ren', ','), (',', 'F.'), ('F.', '('), ('(', '2009'), ('2009', ')'), (')', '.')]

>> Trigrams are: 
 [('[', '63', ']'), ('63', ']', 'Fattah'), (']', 'Fattah', ','), ('Fattah', ',', 'M.'), (',', 'M.', 'A.'), ('M.', 'A.', ','), ('A.', ',', '&'), (',', '&', 'Ren'), ('&', 'Ren', ','), ('Ren', ',', 'F.'), (',', 'F.', '('), ('F.', '(', '2009'), ('(', '2009', ')'), ('2009', ')', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('63', 'CD'), (']', 'JJ'), ('Fattah', 'NNP'), (',', ','), ('M.', 'NNP'), ('A.', 'NNP'), (',', ','), ('&', 'CC'), ('Ren', 'NNP'), (',', ','), ('F.', 'NNP'), ('(', '('), ('2009', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['] Fattah', 'M. A.', 'Ren', 'F.']

>> Named Entities are: 
 [('GPE', 'Fattah'), ('PERSON', 'Ren')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('63', '63'), (']', ']'), ('Fattah', 'fattah'), (',', ','), ('M.', 'm.'), ('A.', 'a.'), (',', ','), ('&', '&'), ('Ren', 'ren'), (',', ','), ('F.', 'f.'), ('(', '('), ('2009', '2009'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('63', '63'), (']', ']'), ('Fattah', 'fattah'), (',', ','), ('M.', 'm.'), ('A.', 'a.'), (',', ','), ('&', '&'), ('Ren', 'ren'), (',', ','), ('F.', 'f.'), ('(', '('), ('2009', '2009'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('63', '63'), (']', ']'), ('Fattah', 'Fattah'), (',', ','), ('M.', 'M.'), ('A.', 'A.'), (',', ','), ('&', '&'), ('Ren', 'Ren'), (',', ','), ('F.', 'F.'), ('(', '('), ('2009', '2009'), (')', ')'), ('.', '.')]


------------------- Sentence 2 -------------------

GA, MR, FFNN, PNN and GMM based models for

>> Tokens are: 
 ['GA', ',', 'MR', ',', 'FFNN', ',', 'PNN', 'GMM', 'based', 'models']

>> Bigrams are: 
 [('GA', ','), (',', 'MR'), ('MR', ','), (',', 'FFNN'), ('FFNN', ','), (',', 'PNN'), ('PNN', 'GMM'), ('GMM', 'based'), ('based', 'models')]

>> Trigrams are: 
 [('GA', ',', 'MR'), (',', 'MR', ','), ('MR', ',', 'FFNN'), (',', 'FFNN', ','), ('FFNN', ',', 'PNN'), (',', 'PNN', 'GMM'), ('PNN', 'GMM', 'based'), ('GMM', 'based', 'models')]

>> POS Tags are: 
 [('GA', 'NNP'), (',', ','), ('MR', 'NNP'), (',', ','), ('FFNN', 'NNP'), (',', ','), ('PNN', 'NNP'), ('GMM', 'NNP'), ('based', 'VBN'), ('models', 'NNS')]

>> Noun Phrases are: 
 ['GA', 'MR', 'FFNN', 'PNN GMM', 'models']

>> Named Entities are: 
 [('ORGANIZATION', 'FFNN'), ('ORGANIZATION', 'PNN')] 

>> Stemming using Porter Stemmer: 
 [('GA', 'ga'), (',', ','), ('MR', 'mr'), (',', ','), ('FFNN', 'ffnn'), (',', ','), ('PNN', 'pnn'), ('GMM', 'gmm'), ('based', 'base'), ('models', 'model')]

>> Stemming using Snowball Stemmer: 
 [('GA', 'ga'), (',', ','), ('MR', 'mr'), (',', ','), ('FFNN', 'ffnn'), (',', ','), ('PNN', 'pnn'), ('GMM', 'gmm'), ('based', 'base'), ('models', 'model')]

>> Lemmatization: 
 [('GA', 'GA'), (',', ','), ('MR', 'MR'), (',', ','), ('FFNN', 'FFNN'), (',', ','), ('PNN', 'PNN'), ('GMM', 'GMM'), ('based', 'based'), ('models', 'model')]



========================================== PARAGRAPH 753 ===========================================

automatic text summarization. Computer Speech & Language, 23(1), 126-144.  

------------------- Sentence 1 -------------------

automatic text summarization.

>> Tokens are: 
 ['automatic', 'text', 'summarization', '.']

>> Bigrams are: 
 [('automatic', 'text'), ('text', 'summarization'), ('summarization', '.')]

>> Trigrams are: 
 [('automatic', 'text', 'summarization'), ('text', 'summarization', '.')]

>> POS Tags are: 
 [('automatic', 'JJ'), ('text', 'NN'), ('summarization', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['automatic text summarization']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('automatic', 'automat'), ('text', 'text'), ('summarization', 'summar'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('automatic', 'automat'), ('text', 'text'), ('summarization', 'summar'), ('.', '.')]

>> Lemmatization: 
 [('automatic', 'automatic'), ('text', 'text'), ('summarization', 'summarization'), ('.', '.')]


------------------- Sentence 2 -------------------

Computer Speech & Language, 23(1), 126-144.

>> Tokens are: 
 ['Computer', 'Speech', '&', 'Language', ',', '23', '(', '1', ')', ',', '126-144', '.']

>> Bigrams are: 
 [('Computer', 'Speech'), ('Speech', '&'), ('&', 'Language'), ('Language', ','), (',', '23'), ('23', '('), ('(', '1'), ('1', ')'), (')', ','), (',', '126-144'), ('126-144', '.')]

>> Trigrams are: 
 [('Computer', 'Speech', '&'), ('Speech', '&', 'Language'), ('&', 'Language', ','), ('Language', ',', '23'), (',', '23', '('), ('23', '(', '1'), ('(', '1', ')'), ('1', ')', ','), (')', ',', '126-144'), (',', '126-144', '.')]

>> POS Tags are: 
 [('Computer', 'NNP'), ('Speech', 'NNP'), ('&', 'CC'), ('Language', 'NNP'), (',', ','), ('23', 'CD'), ('(', '('), ('1', 'CD'), (')', ')'), (',', ','), ('126-144', 'JJ'), ('.', '.')]

>> Noun Phrases are: 
 ['Computer Speech', 'Language']

>> Named Entities are: 
 [('ORGANIZATION', 'Computer Speech'), ('PERSON', 'Language')] 

>> Stemming using Porter Stemmer: 
 [('Computer', 'comput'), ('Speech', 'speech'), ('&', '&'), ('Language', 'languag'), (',', ','), ('23', '23'), ('(', '('), ('1', '1'), (')', ')'), (',', ','), ('126-144', '126-144'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Computer', 'comput'), ('Speech', 'speech'), ('&', '&'), ('Language', 'languag'), (',', ','), ('23', '23'), ('(', '('), ('1', '1'), (')', ')'), (',', ','), ('126-144', '126-144'), ('.', '.')]

>> Lemmatization: 
 [('Computer', 'Computer'), ('Speech', 'Speech'), ('&', '&'), ('Language', 'Language'), (',', ','), ('23', '23'), ('(', '('), ('1', '1'), (')', ')'), (',', ','), ('126-144', '126-144'), ('.', '.')]



========================================== PARAGRAPH 754 ===========================================

[64] Gong, Y., & Liu, X. (2001, September). Generic text summarization using relevance  

------------------- Sentence 1 -------------------

[64] Gong, Y., & Liu, X.

>> Tokens are: 
 ['[', '64', ']', 'Gong', ',', 'Y.', ',', '&', 'Liu', ',', 'X', '.']

>> Bigrams are: 
 [('[', '64'), ('64', ']'), (']', 'Gong'), ('Gong', ','), (',', 'Y.'), ('Y.', ','), (',', '&'), ('&', 'Liu'), ('Liu', ','), (',', 'X'), ('X', '.')]

>> Trigrams are: 
 [('[', '64', ']'), ('64', ']', 'Gong'), (']', 'Gong', ','), ('Gong', ',', 'Y.'), (',', 'Y.', ','), ('Y.', ',', '&'), (',', '&', 'Liu'), ('&', 'Liu', ','), ('Liu', ',', 'X'), (',', 'X', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('64', 'CD'), (']', 'NN'), ('Gong', 'NNP'), (',', ','), ('Y.', 'NNP'), (',', ','), ('&', 'CC'), ('Liu', 'NNP'), (',', ','), ('X', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['] Gong', 'Y.', 'Liu', 'X']

>> Named Entities are: 
 [('GPE', 'Gong'), ('PERSON', 'Liu')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('64', '64'), (']', ']'), ('Gong', 'gong'), (',', ','), ('Y.', 'y.'), (',', ','), ('&', '&'), ('Liu', 'liu'), (',', ','), ('X', 'x'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('64', '64'), (']', ']'), ('Gong', 'gong'), (',', ','), ('Y.', 'y.'), (',', ','), ('&', '&'), ('Liu', 'liu'), (',', ','), ('X', 'x'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('64', '64'), (']', ']'), ('Gong', 'Gong'), (',', ','), ('Y.', 'Y.'), (',', ','), ('&', '&'), ('Liu', 'Liu'), (',', ','), ('X', 'X'), ('.', '.')]


------------------- Sentence 2 -------------------

(2001, September).

>> Tokens are: 
 ['(', '2001', ',', 'September', ')', '.']

>> Bigrams are: 
 [('(', '2001'), ('2001', ','), (',', 'September'), ('September', ')'), (')', '.')]

>> Trigrams are: 
 [('(', '2001', ','), ('2001', ',', 'September'), (',', 'September', ')'), ('September', ')', '.')]

>> POS Tags are: 
 [('(', '('), ('2001', 'CD'), (',', ','), ('September', 'NNP'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['September']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('2001', '2001'), (',', ','), ('September', 'septemb'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('2001', '2001'), (',', ','), ('September', 'septemb'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('(', '('), ('2001', '2001'), (',', ','), ('September', 'September'), (')', ')'), ('.', '.')]


------------------- Sentence 3 -------------------

Generic text summarization using relevance

>> Tokens are: 
 ['Generic', 'text', 'summarization', 'using', 'relevance']

>> Bigrams are: 
 [('Generic', 'text'), ('text', 'summarization'), ('summarization', 'using'), ('using', 'relevance')]

>> Trigrams are: 
 [('Generic', 'text', 'summarization'), ('text', 'summarization', 'using'), ('summarization', 'using', 'relevance')]

>> POS Tags are: 
 [('Generic', 'NNP'), ('text', 'NN'), ('summarization', 'NN'), ('using', 'VBG'), ('relevance', 'NN')]

>> Noun Phrases are: 
 ['Generic text summarization', 'relevance']

>> Named Entities are: 
 [('GPE', 'Generic')] 

>> Stemming using Porter Stemmer: 
 [('Generic', 'gener'), ('text', 'text'), ('summarization', 'summar'), ('using', 'use'), ('relevance', 'relev')]

>> Stemming using Snowball Stemmer: 
 [('Generic', 'generic'), ('text', 'text'), ('summarization', 'summar'), ('using', 'use'), ('relevance', 'relev')]

>> Lemmatization: 
 [('Generic', 'Generic'), ('text', 'text'), ('summarization', 'summarization'), ('using', 'using'), ('relevance', 'relevance')]



========================================== PARAGRAPH 755 ===========================================

measure and latent semantic analysis. In Proceedings of the 24th annual international ACM  

------------------- Sentence 1 -------------------

measure and latent semantic analysis.

>> Tokens are: 
 ['measure', 'latent', 'semantic', 'analysis', '.']

>> Bigrams are: 
 [('measure', 'latent'), ('latent', 'semantic'), ('semantic', 'analysis'), ('analysis', '.')]

>> Trigrams are: 
 [('measure', 'latent', 'semantic'), ('latent', 'semantic', 'analysis'), ('semantic', 'analysis', '.')]

>> POS Tags are: 
 [('measure', 'NN'), ('latent', 'JJ'), ('semantic', 'JJ'), ('analysis', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['measure', 'latent semantic analysis']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('measure', 'measur'), ('latent', 'latent'), ('semantic', 'semant'), ('analysis', 'analysi'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('measure', 'measur'), ('latent', 'latent'), ('semantic', 'semant'), ('analysis', 'analysi'), ('.', '.')]

>> Lemmatization: 
 [('measure', 'measure'), ('latent', 'latent'), ('semantic', 'semantic'), ('analysis', 'analysis'), ('.', '.')]


------------------- Sentence 2 -------------------

In Proceedings of the 24th annual international ACM

>> Tokens are: 
 ['In', 'Proceedings', '24th', 'annual', 'international', 'ACM']

>> Bigrams are: 
 [('In', 'Proceedings'), ('Proceedings', '24th'), ('24th', 'annual'), ('annual', 'international'), ('international', 'ACM')]

>> Trigrams are: 
 [('In', 'Proceedings', '24th'), ('Proceedings', '24th', 'annual'), ('24th', 'annual', 'international'), ('annual', 'international', 'ACM')]

>> POS Tags are: 
 [('In', 'IN'), ('Proceedings', 'NNP'), ('24th', 'CD'), ('annual', 'JJ'), ('international', 'JJ'), ('ACM', 'NNP')]

>> Noun Phrases are: 
 ['Proceedings', 'annual international ACM']

>> Named Entities are: 
 [('ORGANIZATION', 'ACM')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('Proceedings', 'proceed'), ('24th', '24th'), ('annual', 'annual'), ('international', 'intern'), ('ACM', 'acm')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('Proceedings', 'proceed'), ('24th', '24th'), ('annual', 'annual'), ('international', 'intern'), ('ACM', 'acm')]

>> Lemmatization: 
 [('In', 'In'), ('Proceedings', 'Proceedings'), ('24th', '24th'), ('annual', 'annual'), ('international', 'international'), ('ACM', 'ACM')]



========================================== PARAGRAPH 756 ===========================================

SIGIR conference on Research and development in information retrieval (pp. 19-25). ACM.  

------------------- Sentence 1 -------------------

SIGIR conference on Research and development in information retrieval (pp.

>> Tokens are: 
 ['SIGIR', 'conference', 'Research', 'development', 'information', 'retrieval', '(', 'pp', '.']

>> Bigrams are: 
 [('SIGIR', 'conference'), ('conference', 'Research'), ('Research', 'development'), ('development', 'information'), ('information', 'retrieval'), ('retrieval', '('), ('(', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('SIGIR', 'conference', 'Research'), ('conference', 'Research', 'development'), ('Research', 'development', 'information'), ('development', 'information', 'retrieval'), ('information', 'retrieval', '('), ('retrieval', '(', 'pp'), ('(', 'pp', '.')]

>> POS Tags are: 
 [('SIGIR', 'NNP'), ('conference', 'NN'), ('Research', 'NNP'), ('development', 'NN'), ('information', 'NN'), ('retrieval', 'NN'), ('(', '('), ('pp', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['SIGIR conference Research development information retrieval', 'pp']

>> Named Entities are: 
 [('GPE', 'SIGIR')] 

>> Stemming using Porter Stemmer: 
 [('SIGIR', 'sigir'), ('conference', 'confer'), ('Research', 'research'), ('development', 'develop'), ('information', 'inform'), ('retrieval', 'retriev'), ('(', '('), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('SIGIR', 'sigir'), ('conference', 'confer'), ('Research', 'research'), ('development', 'develop'), ('information', 'inform'), ('retrieval', 'retriev'), ('(', '('), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('SIGIR', 'SIGIR'), ('conference', 'conference'), ('Research', 'Research'), ('development', 'development'), ('information', 'information'), ('retrieval', 'retrieval'), ('(', '('), ('pp', 'pp'), ('.', '.')]


------------------- Sentence 2 -------------------

19-25).

>> Tokens are: 
 ['19-25', ')', '.']

>> Bigrams are: 
 [('19-25', ')'), (')', '.')]

>> Trigrams are: 
 [('19-25', ')', '.')]

>> POS Tags are: 
 [('19-25', 'JJ'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('19-25', '19-25'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('19-25', '19-25'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('19-25', '19-25'), (')', ')'), ('.', '.')]


------------------- Sentence 3 -------------------

ACM.

>> Tokens are: 
 ['ACM', '.']

>> Bigrams are: 
 [('ACM', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('ACM', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['ACM']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('ACM', 'acm'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('ACM', 'acm'), ('.', '.')]

>> Lemmatization: 
 [('ACM', 'ACM'), ('.', '.')]



========================================== PARAGRAPH 757 ===========================================

[65] Dunlavy, D. M., O’Leary, D. P., Conroy, J. M., & Schlesinger, J. D. (2007). QCS: A  

------------------- Sentence 1 -------------------

[65] Dunlavy, D. M., O’Leary, D. P., Conroy, J. M., & Schlesinger, J. D. (2007).

>> Tokens are: 
 ['[', '65', ']', 'Dunlavy', ',', 'D.', 'M.', ',', 'O', '’', 'Leary', ',', 'D.', 'P.', ',', 'Conroy', ',', 'J.', 'M.', ',', '&', 'Schlesinger', ',', 'J.', 'D.', '(', '2007', ')', '.']

>> Bigrams are: 
 [('[', '65'), ('65', ']'), (']', 'Dunlavy'), ('Dunlavy', ','), (',', 'D.'), ('D.', 'M.'), ('M.', ','), (',', 'O'), ('O', '’'), ('’', 'Leary'), ('Leary', ','), (',', 'D.'), ('D.', 'P.'), ('P.', ','), (',', 'Conroy'), ('Conroy', ','), (',', 'J.'), ('J.', 'M.'), ('M.', ','), (',', '&'), ('&', 'Schlesinger'), ('Schlesinger', ','), (',', 'J.'), ('J.', 'D.'), ('D.', '('), ('(', '2007'), ('2007', ')'), (')', '.')]

>> Trigrams are: 
 [('[', '65', ']'), ('65', ']', 'Dunlavy'), (']', 'Dunlavy', ','), ('Dunlavy', ',', 'D.'), (',', 'D.', 'M.'), ('D.', 'M.', ','), ('M.', ',', 'O'), (',', 'O', '’'), ('O', '’', 'Leary'), ('’', 'Leary', ','), ('Leary', ',', 'D.'), (',', 'D.', 'P.'), ('D.', 'P.', ','), ('P.', ',', 'Conroy'), (',', 'Conroy', ','), ('Conroy', ',', 'J.'), (',', 'J.', 'M.'), ('J.', 'M.', ','), ('M.', ',', '&'), (',', '&', 'Schlesinger'), ('&', 'Schlesinger', ','), ('Schlesinger', ',', 'J.'), (',', 'J.', 'D.'), ('J.', 'D.', '('), ('D.', '(', '2007'), ('(', '2007', ')'), ('2007', ')', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('65', 'CD'), (']', 'JJ'), ('Dunlavy', 'NNP'), (',', ','), ('D.', 'NNP'), ('M.', 'NNP'), (',', ','), ('O', 'NNP'), ('’', 'NNP'), ('Leary', 'NNP'), (',', ','), ('D.', 'NNP'), ('P.', 'NNP'), (',', ','), ('Conroy', 'NNP'), (',', ','), ('J.', 'NNP'), ('M.', 'NNP'), (',', ','), ('&', 'CC'), ('Schlesinger', 'NNP'), (',', ','), ('J.', 'NNP'), ('D.', 'NNP'), ('(', '('), ('2007', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['] Dunlavy', 'D. M.', 'O ’ Leary', 'D. P.', 'Conroy', 'J. M.', 'Schlesinger', 'J. D.']

>> Named Entities are: 
 [('PERSON', 'O'), ('GSP', 'Conroy'), ('PERSON', 'J. M.'), ('PERSON', 'Schlesinger'), ('PERSON', 'J. D.')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('65', '65'), (']', ']'), ('Dunlavy', 'dunlavi'), (',', ','), ('D.', 'd.'), ('M.', 'm.'), (',', ','), ('O', 'o'), ('’', '’'), ('Leary', 'leari'), (',', ','), ('D.', 'd.'), ('P.', 'p.'), (',', ','), ('Conroy', 'conroy'), (',', ','), ('J.', 'j.'), ('M.', 'm.'), (',', ','), ('&', '&'), ('Schlesinger', 'schlesing'), (',', ','), ('J.', 'j.'), ('D.', 'd.'), ('(', '('), ('2007', '2007'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('65', '65'), (']', ']'), ('Dunlavy', 'dunlavi'), (',', ','), ('D.', 'd.'), ('M.', 'm.'), (',', ','), ('O', 'o'), ('’', '’'), ('Leary', 'leari'), (',', ','), ('D.', 'd.'), ('P.', 'p.'), (',', ','), ('Conroy', 'conroy'), (',', ','), ('J.', 'j.'), ('M.', 'm.'), (',', ','), ('&', '&'), ('Schlesinger', 'schlesing'), (',', ','), ('J.', 'j.'), ('D.', 'd.'), ('(', '('), ('2007', '2007'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('65', '65'), (']', ']'), ('Dunlavy', 'Dunlavy'), (',', ','), ('D.', 'D.'), ('M.', 'M.'), (',', ','), ('O', 'O'), ('’', '’'), ('Leary', 'Leary'), (',', ','), ('D.', 'D.'), ('P.', 'P.'), (',', ','), ('Conroy', 'Conroy'), (',', ','), ('J.', 'J.'), ('M.', 'M.'), (',', ','), ('&', '&'), ('Schlesinger', 'Schlesinger'), (',', ','), ('J.', 'J.'), ('D.', 'D.'), ('(', '('), ('2007', '2007'), (')', ')'), ('.', '.')]


------------------- Sentence 2 -------------------

QCS: A

>> Tokens are: 
 ['QCS', ':', 'A']

>> Bigrams are: 
 [('QCS', ':'), (':', 'A')]

>> Trigrams are: 
 [('QCS', ':', 'A')]

>> POS Tags are: 
 [('QCS', 'NN'), (':', ':'), ('A', 'DT')]

>> Noun Phrases are: 
 ['QCS']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('QCS', 'qc'), (':', ':'), ('A', 'a')]

>> Stemming using Snowball Stemmer: 
 [('QCS', 'qcs'), (':', ':'), ('A', 'a')]

>> Lemmatization: 
 [('QCS', 'QCS'), (':', ':'), ('A', 'A')]



========================================== PARAGRAPH 758 ===========================================

system for querying, clustering and summarizing documents. Information processing &  

------------------- Sentence 1 -------------------

system for querying, clustering and summarizing documents.

>> Tokens are: 
 ['system', 'querying', ',', 'clustering', 'summarizing', 'documents', '.']

>> Bigrams are: 
 [('system', 'querying'), ('querying', ','), (',', 'clustering'), ('clustering', 'summarizing'), ('summarizing', 'documents'), ('documents', '.')]

>> Trigrams are: 
 [('system', 'querying', ','), ('querying', ',', 'clustering'), (',', 'clustering', 'summarizing'), ('clustering', 'summarizing', 'documents'), ('summarizing', 'documents', '.')]

>> POS Tags are: 
 [('system', 'NN'), ('querying', 'VBG'), (',', ','), ('clustering', 'VBG'), ('summarizing', 'VBG'), ('documents', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['system', 'documents']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('system', 'system'), ('querying', 'queri'), (',', ','), ('clustering', 'cluster'), ('summarizing', 'summar'), ('documents', 'document'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('system', 'system'), ('querying', 'queri'), (',', ','), ('clustering', 'cluster'), ('summarizing', 'summar'), ('documents', 'document'), ('.', '.')]

>> Lemmatization: 
 [('system', 'system'), ('querying', 'querying'), (',', ','), ('clustering', 'clustering'), ('summarizing', 'summarizing'), ('documents', 'document'), ('.', '.')]


------------------- Sentence 2 -------------------

Information processing &

>> Tokens are: 
 ['Information', 'processing', '&']

>> Bigrams are: 
 [('Information', 'processing'), ('processing', '&')]

>> Trigrams are: 
 [('Information', 'processing', '&')]

>> POS Tags are: 
 [('Information', 'NNP'), ('processing', 'NN'), ('&', 'CC')]

>> Noun Phrases are: 
 ['Information processing']

>> Named Entities are: 
 [('GPE', 'Information')] 

>> Stemming using Porter Stemmer: 
 [('Information', 'inform'), ('processing', 'process'), ('&', '&')]

>> Stemming using Snowball Stemmer: 
 [('Information', 'inform'), ('processing', 'process'), ('&', '&')]

>> Lemmatization: 
 [('Information', 'Information'), ('processing', 'processing'), ('&', '&')]



========================================== PARAGRAPH 759 ===========================================

management, 43(6), 1588-1605.  

------------------- Sentence 1 -------------------

management, 43(6), 1588-1605.

>> Tokens are: 
 ['management', ',', '43', '(', '6', ')', ',', '1588-1605', '.']

>> Bigrams are: 
 [('management', ','), (',', '43'), ('43', '('), ('(', '6'), ('6', ')'), (')', ','), (',', '1588-1605'), ('1588-1605', '.')]

>> Trigrams are: 
 [('management', ',', '43'), (',', '43', '('), ('43', '(', '6'), ('(', '6', ')'), ('6', ')', ','), (')', ',', '1588-1605'), (',', '1588-1605', '.')]

>> POS Tags are: 
 [('management', 'NN'), (',', ','), ('43', 'CD'), ('(', '('), ('6', 'CD'), (')', ')'), (',', ','), ('1588-1605', 'JJ'), ('.', '.')]

>> Noun Phrases are: 
 ['management']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('management', 'manag'), (',', ','), ('43', '43'), ('(', '('), ('6', '6'), (')', ')'), (',', ','), ('1588-1605', '1588-1605'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('management', 'manag'), (',', ','), ('43', '43'), ('(', '('), ('6', '6'), (')', ')'), (',', ','), ('1588-1605', '1588-1605'), ('.', '.')]

>> Lemmatization: 
 [('management', 'management'), (',', ','), ('43', '43'), ('(', '('), ('6', '6'), (')', ')'), (',', ','), ('1588-1605', '1588-1605'), ('.', '.')]



========================================== PARAGRAPH 760 ===========================================

[66] Wan, X. (2008). Using only cross-document relationships for both generic and topic- 

------------------- Sentence 1 -------------------

[66] Wan, X.

>> Tokens are: 
 ['[', '66', ']', 'Wan', ',', 'X', '.']

>> Bigrams are: 
 [('[', '66'), ('66', ']'), (']', 'Wan'), ('Wan', ','), (',', 'X'), ('X', '.')]

>> Trigrams are: 
 [('[', '66', ']'), ('66', ']', 'Wan'), (']', 'Wan', ','), ('Wan', ',', 'X'), (',', 'X', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('66', 'CD'), (']', 'JJ'), ('Wan', 'NNP'), (',', ','), ('X', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['] Wan', 'X']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('66', '66'), (']', ']'), ('Wan', 'wan'), (',', ','), ('X', 'x'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('66', '66'), (']', ']'), ('Wan', 'wan'), (',', ','), ('X', 'x'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('66', '66'), (']', ']'), ('Wan', 'Wan'), (',', ','), ('X', 'X'), ('.', '.')]


------------------- Sentence 2 -------------------

(2008).

>> Tokens are: 
 ['(', '2008', ')', '.']

>> Bigrams are: 
 [('(', '2008'), ('2008', ')'), (')', '.')]

>> Trigrams are: 
 [('(', '2008', ')'), ('2008', ')', '.')]

>> POS Tags are: 
 [('(', '('), ('2008', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('2008', '2008'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('2008', '2008'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('(', '('), ('2008', '2008'), (')', ')'), ('.', '.')]


------------------- Sentence 3 -------------------

Using only cross-document relationships for both generic and topic-

>> Tokens are: 
 ['Using', 'cross-document', 'relationships', 'generic', 'topic-']

>> Bigrams are: 
 [('Using', 'cross-document'), ('cross-document', 'relationships'), ('relationships', 'generic'), ('generic', 'topic-')]

>> Trigrams are: 
 [('Using', 'cross-document', 'relationships'), ('cross-document', 'relationships', 'generic'), ('relationships', 'generic', 'topic-')]

>> POS Tags are: 
 [('Using', 'VBG'), ('cross-document', 'JJ'), ('relationships', 'NNS'), ('generic', 'JJ'), ('topic-', 'NN')]

>> Noun Phrases are: 
 ['cross-document relationships', 'generic topic-']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Using', 'use'), ('cross-document', 'cross-docu'), ('relationships', 'relationship'), ('generic', 'gener'), ('topic-', 'topic-')]

>> Stemming using Snowball Stemmer: 
 [('Using', 'use'), ('cross-document', 'cross-docu'), ('relationships', 'relationship'), ('generic', 'generic'), ('topic-', 'topic-')]

>> Lemmatization: 
 [('Using', 'Using'), ('cross-document', 'cross-document'), ('relationships', 'relationship'), ('generic', 'generic'), ('topic-', 'topic-')]



========================================== PARAGRAPH 761 ===========================================

focused multi-document summarizations. Information Retrieval, 11(1), 25-49.  

------------------- Sentence 1 -------------------

focused multi-document summarizations.

>> Tokens are: 
 ['focused', 'multi-document', 'summarizations', '.']

>> Bigrams are: 
 [('focused', 'multi-document'), ('multi-document', 'summarizations'), ('summarizations', '.')]

>> Trigrams are: 
 [('focused', 'multi-document', 'summarizations'), ('multi-document', 'summarizations', '.')]

>> POS Tags are: 
 [('focused', 'VBN'), ('multi-document', 'JJ'), ('summarizations', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['multi-document summarizations']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('focused', 'focus'), ('multi-document', 'multi-docu'), ('summarizations', 'summar'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('focused', 'focus'), ('multi-document', 'multi-docu'), ('summarizations', 'summar'), ('.', '.')]

>> Lemmatization: 
 [('focused', 'focused'), ('multi-document', 'multi-document'), ('summarizations', 'summarization'), ('.', '.')]


------------------- Sentence 2 -------------------

Information Retrieval, 11(1), 25-49.

>> Tokens are: 
 ['Information', 'Retrieval', ',', '11', '(', '1', ')', ',', '25-49', '.']

>> Bigrams are: 
 [('Information', 'Retrieval'), ('Retrieval', ','), (',', '11'), ('11', '('), ('(', '1'), ('1', ')'), (')', ','), (',', '25-49'), ('25-49', '.')]

>> Trigrams are: 
 [('Information', 'Retrieval', ','), ('Retrieval', ',', '11'), (',', '11', '('), ('11', '(', '1'), ('(', '1', ')'), ('1', ')', ','), (')', ',', '25-49'), (',', '25-49', '.')]

>> POS Tags are: 
 [('Information', 'NN'), ('Retrieval', 'NNP'), (',', ','), ('11', 'CD'), ('(', '('), ('1', 'CD'), (')', ')'), (',', ','), ('25-49', 'JJ'), ('.', '.')]

>> Noun Phrases are: 
 ['Information Retrieval']

>> Named Entities are: 
 [('PERSON', 'Retrieval')] 

>> Stemming using Porter Stemmer: 
 [('Information', 'inform'), ('Retrieval', 'retriev'), (',', ','), ('11', '11'), ('(', '('), ('1', '1'), (')', ')'), (',', ','), ('25-49', '25-49'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Information', 'inform'), ('Retrieval', 'retriev'), (',', ','), ('11', '11'), ('(', '('), ('1', '1'), (')', ')'), (',', ','), ('25-49', '25-49'), ('.', '.')]

>> Lemmatization: 
 [('Information', 'Information'), ('Retrieval', 'Retrieval'), (',', ','), ('11', '11'), ('(', '('), ('1', '1'), (')', ')'), (',', ','), ('25-49', '25-49'), ('.', '.')]



========================================== PARAGRAPH 762 ===========================================

[67] Ouyang, Y., Li, W., Li, S., & Lu, Q. (2011). Applying regression models to query- 

------------------- Sentence 1 -------------------

[67] Ouyang, Y., Li, W., Li, S., & Lu, Q.

>> Tokens are: 
 ['[', '67', ']', 'Ouyang', ',', 'Y.', ',', 'Li', ',', 'W.', ',', 'Li', ',', 'S.', ',', '&', 'Lu', ',', 'Q', '.']

>> Bigrams are: 
 [('[', '67'), ('67', ']'), (']', 'Ouyang'), ('Ouyang', ','), (',', 'Y.'), ('Y.', ','), (',', 'Li'), ('Li', ','), (',', 'W.'), ('W.', ','), (',', 'Li'), ('Li', ','), (',', 'S.'), ('S.', ','), (',', '&'), ('&', 'Lu'), ('Lu', ','), (',', 'Q'), ('Q', '.')]

>> Trigrams are: 
 [('[', '67', ']'), ('67', ']', 'Ouyang'), (']', 'Ouyang', ','), ('Ouyang', ',', 'Y.'), (',', 'Y.', ','), ('Y.', ',', 'Li'), (',', 'Li', ','), ('Li', ',', 'W.'), (',', 'W.', ','), ('W.', ',', 'Li'), (',', 'Li', ','), ('Li', ',', 'S.'), (',', 'S.', ','), ('S.', ',', '&'), (',', '&', 'Lu'), ('&', 'Lu', ','), ('Lu', ',', 'Q'), (',', 'Q', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('67', 'CD'), (']', 'NNP'), ('Ouyang', 'NNP'), (',', ','), ('Y.', 'NNP'), (',', ','), ('Li', 'NNP'), (',', ','), ('W.', 'NNP'), (',', ','), ('Li', 'NNP'), (',', ','), ('S.', 'NNP'), (',', ','), ('&', 'CC'), ('Lu', 'NNP'), (',', ','), ('Q', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['] Ouyang', 'Y.', 'Li', 'W.', 'Li', 'S.', 'Lu', 'Q']

>> Named Entities are: 
 [('PERSON', 'Ouyang'), ('PERSON', 'Li'), ('PERSON', 'Li')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('67', '67'), (']', ']'), ('Ouyang', 'ouyang'), (',', ','), ('Y.', 'y.'), (',', ','), ('Li', 'li'), (',', ','), ('W.', 'w.'), (',', ','), ('Li', 'li'), (',', ','), ('S.', 's.'), (',', ','), ('&', '&'), ('Lu', 'lu'), (',', ','), ('Q', 'q'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('67', '67'), (']', ']'), ('Ouyang', 'ouyang'), (',', ','), ('Y.', 'y.'), (',', ','), ('Li', 'li'), (',', ','), ('W.', 'w.'), (',', ','), ('Li', 'li'), (',', ','), ('S.', 's.'), (',', ','), ('&', '&'), ('Lu', 'lu'), (',', ','), ('Q', 'q'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('67', '67'), (']', ']'), ('Ouyang', 'Ouyang'), (',', ','), ('Y.', 'Y.'), (',', ','), ('Li', 'Li'), (',', ','), ('W.', 'W.'), (',', ','), ('Li', 'Li'), (',', ','), ('S.', 'S.'), (',', ','), ('&', '&'), ('Lu', 'Lu'), (',', ','), ('Q', 'Q'), ('.', '.')]


------------------- Sentence 2 -------------------

(2011).

>> Tokens are: 
 ['(', '2011', ')', '.']

>> Bigrams are: 
 [('(', '2011'), ('2011', ')'), (')', '.')]

>> Trigrams are: 
 [('(', '2011', ')'), ('2011', ')', '.')]

>> POS Tags are: 
 [('(', '('), ('2011', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('2011', '2011'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('2011', '2011'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('(', '('), ('2011', '2011'), (')', ')'), ('.', '.')]


------------------- Sentence 3 -------------------

Applying regression models to query-

>> Tokens are: 
 ['Applying', 'regression', 'models', 'query-']

>> Bigrams are: 
 [('Applying', 'regression'), ('regression', 'models'), ('models', 'query-')]

>> Trigrams are: 
 [('Applying', 'regression', 'models'), ('regression', 'models', 'query-')]

>> POS Tags are: 
 [('Applying', 'VBG'), ('regression', 'NN'), ('models', 'NNS'), ('query-', 'VBP')]

>> Noun Phrases are: 
 ['regression models']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Applying', 'appli'), ('regression', 'regress'), ('models', 'model'), ('query-', 'query-')]

>> Stemming using Snowball Stemmer: 
 [('Applying', 'appli'), ('regression', 'regress'), ('models', 'model'), ('query-', 'query-')]

>> Lemmatization: 
 [('Applying', 'Applying'), ('regression', 'regression'), ('models', 'model'), ('query-', 'query-')]



========================================== PARAGRAPH 763 ===========================================

focused multi-document summarization. Information Processing & Management, 47(2), 227- 

------------------- Sentence 1 -------------------

focused multi-document summarization.

>> Tokens are: 
 ['focused', 'multi-document', 'summarization', '.']

>> Bigrams are: 
 [('focused', 'multi-document'), ('multi-document', 'summarization'), ('summarization', '.')]

>> Trigrams are: 
 [('focused', 'multi-document', 'summarization'), ('multi-document', 'summarization', '.')]

>> POS Tags are: 
 [('focused', 'VBN'), ('multi-document', 'JJ'), ('summarization', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['multi-document summarization']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('focused', 'focus'), ('multi-document', 'multi-docu'), ('summarization', 'summar'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('focused', 'focus'), ('multi-document', 'multi-docu'), ('summarization', 'summar'), ('.', '.')]

>> Lemmatization: 
 [('focused', 'focused'), ('multi-document', 'multi-document'), ('summarization', 'summarization'), ('.', '.')]


------------------- Sentence 2 -------------------

Information Processing & Management, 47(2), 227-

>> Tokens are: 
 ['Information', 'Processing', '&', 'Management', ',', '47', '(', '2', ')', ',', '227-']

>> Bigrams are: 
 [('Information', 'Processing'), ('Processing', '&'), ('&', 'Management'), ('Management', ','), (',', '47'), ('47', '('), ('(', '2'), ('2', ')'), (')', ','), (',', '227-')]

>> Trigrams are: 
 [('Information', 'Processing', '&'), ('Processing', '&', 'Management'), ('&', 'Management', ','), ('Management', ',', '47'), (',', '47', '('), ('47', '(', '2'), ('(', '2', ')'), ('2', ')', ','), (')', ',', '227-')]

>> POS Tags are: 
 [('Information', 'NNP'), ('Processing', 'NNP'), ('&', 'CC'), ('Management', 'NNP'), (',', ','), ('47', 'CD'), ('(', '('), ('2', 'CD'), (')', ')'), (',', ','), ('227-', 'JJ')]

>> Noun Phrases are: 
 ['Information Processing', 'Management']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Information', 'inform'), ('Processing', 'process'), ('&', '&'), ('Management', 'manag'), (',', ','), ('47', '47'), ('(', '('), ('2', '2'), (')', ')'), (',', ','), ('227-', '227-')]

>> Stemming using Snowball Stemmer: 
 [('Information', 'inform'), ('Processing', 'process'), ('&', '&'), ('Management', 'manag'), (',', ','), ('47', '47'), ('(', '('), ('2', '2'), (')', ')'), (',', ','), ('227-', '227-')]

>> Lemmatization: 
 [('Information', 'Information'), ('Processing', 'Processing'), ('&', '&'), ('Management', 'Management'), (',', ','), ('47', '47'), ('(', '('), ('2', '2'), (')', ')'), (',', ','), ('227-', '227-')]



========================================== PARAGRAPH 764 ===========================================

237.  

------------------- Sentence 1 -------------------

237.

>> Tokens are: 
 ['237', '.']

>> Bigrams are: 
 [('237', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('237', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('237', '237'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('237', '237'), ('.', '.')]

>> Lemmatization: 
 [('237', '237'), ('.', '.')]



========================================== PARAGRAPH 765 ===========================================

[68] Mani, I., & Maybury, M. T. (Eds.). (1999). Advances in automatic text  

------------------- Sentence 1 -------------------

[68] Mani, I., & Maybury, M. T.

>> Tokens are: 
 ['[', '68', ']', 'Mani', ',', 'I.', ',', '&', 'Maybury', ',', 'M.', 'T', '.']

>> Bigrams are: 
 [('[', '68'), ('68', ']'), (']', 'Mani'), ('Mani', ','), (',', 'I.'), ('I.', ','), (',', '&'), ('&', 'Maybury'), ('Maybury', ','), (',', 'M.'), ('M.', 'T'), ('T', '.')]

>> Trigrams are: 
 [('[', '68', ']'), ('68', ']', 'Mani'), (']', 'Mani', ','), ('Mani', ',', 'I.'), (',', 'I.', ','), ('I.', ',', '&'), (',', '&', 'Maybury'), ('&', 'Maybury', ','), ('Maybury', ',', 'M.'), (',', 'M.', 'T'), ('M.', 'T', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('68', 'CD'), (']', 'JJ'), ('Mani', 'NNP'), (',', ','), ('I.', 'NNP'), (',', ','), ('&', 'CC'), ('Maybury', 'NNP'), (',', ','), ('M.', 'NNP'), ('T', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['] Mani', 'I.', 'Maybury', 'M. T']

>> Named Entities are: 
 [('PERSON', 'Maybury')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('68', '68'), (']', ']'), ('Mani', 'mani'), (',', ','), ('I.', 'i.'), (',', ','), ('&', '&'), ('Maybury', 'mayburi'), (',', ','), ('M.', 'm.'), ('T', 't'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('68', '68'), (']', ']'), ('Mani', 'mani'), (',', ','), ('I.', 'i.'), (',', ','), ('&', '&'), ('Maybury', 'mayburi'), (',', ','), ('M.', 'm.'), ('T', 't'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('68', '68'), (']', ']'), ('Mani', 'Mani'), (',', ','), ('I.', 'I.'), (',', ','), ('&', '&'), ('Maybury', 'Maybury'), (',', ','), ('M.', 'M.'), ('T', 'T'), ('.', '.')]


------------------- Sentence 2 -------------------

(Eds.).

>> Tokens are: 
 ['(', 'Eds', '.', ')', '.']

>> Bigrams are: 
 [('(', 'Eds'), ('Eds', '.'), ('.', ')'), (')', '.')]

>> Trigrams are: 
 [('(', 'Eds', '.'), ('Eds', '.', ')'), ('.', ')', '.')]

>> POS Tags are: 
 [('(', '('), ('Eds', 'NNP'), ('.', '.'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['Eds']

>> Named Entities are: 
 [('ORGANIZATION', 'Eds')] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('Eds', 'ed'), ('.', '.'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('Eds', 'ed'), ('.', '.'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('(', '('), ('Eds', 'Eds'), ('.', '.'), (')', ')'), ('.', '.')]


------------------- Sentence 3 -------------------

(1999).

>> Tokens are: 
 ['(', '1999', ')', '.']

>> Bigrams are: 
 [('(', '1999'), ('1999', ')'), (')', '.')]

>> Trigrams are: 
 [('(', '1999', ')'), ('1999', ')', '.')]

>> POS Tags are: 
 [('(', '('), ('1999', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('1999', '1999'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('1999', '1999'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('(', '('), ('1999', '1999'), (')', ')'), ('.', '.')]


------------------- Sentence 4 -------------------

Advances in automatic text

>> Tokens are: 
 ['Advances', 'automatic', 'text']

>> Bigrams are: 
 [('Advances', 'automatic'), ('automatic', 'text')]

>> Trigrams are: 
 [('Advances', 'automatic', 'text')]

>> POS Tags are: 
 [('Advances', 'NNS'), ('automatic', 'JJ'), ('text', 'NN')]

>> Noun Phrases are: 
 ['Advances', 'automatic text']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Advances', 'advanc'), ('automatic', 'automat'), ('text', 'text')]

>> Stemming using Snowball Stemmer: 
 [('Advances', 'advanc'), ('automatic', 'automat'), ('text', 'text')]

>> Lemmatization: 
 [('Advances', 'Advances'), ('automatic', 'automatic'), ('text', 'text')]



========================================== PARAGRAPH 766 ===========================================

summarization (Vol. 293). Cambridge, MA: MIT press. 

------------------- Sentence 1 -------------------

summarization (Vol.

>> Tokens are: 
 ['summarization', '(', 'Vol', '.']

>> Bigrams are: 
 [('summarization', '('), ('(', 'Vol'), ('Vol', '.')]

>> Trigrams are: 
 [('summarization', '(', 'Vol'), ('(', 'Vol', '.')]

>> POS Tags are: 
 [('summarization', 'NN'), ('(', '('), ('Vol', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['summarization', 'Vol']

>> Named Entities are: 
 [('ORGANIZATION', 'Vol')] 

>> Stemming using Porter Stemmer: 
 [('summarization', 'summar'), ('(', '('), ('Vol', 'vol'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('summarization', 'summar'), ('(', '('), ('Vol', 'vol'), ('.', '.')]

>> Lemmatization: 
 [('summarization', 'summarization'), ('(', '('), ('Vol', 'Vol'), ('.', '.')]


------------------- Sentence 2 -------------------

293).

>> Tokens are: 
 ['293', ')', '.']

>> Bigrams are: 
 [('293', ')'), (')', '.')]

>> Trigrams are: 
 [('293', ')', '.')]

>> POS Tags are: 
 [('293', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('293', '293'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('293', '293'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('293', '293'), (')', ')'), ('.', '.')]


------------------- Sentence 3 -------------------

Cambridge, MA: MIT press.

>> Tokens are: 
 ['Cambridge', ',', 'MA', ':', 'MIT', 'press', '.']

>> Bigrams are: 
 [('Cambridge', ','), (',', 'MA'), ('MA', ':'), (':', 'MIT'), ('MIT', 'press'), ('press', '.')]

>> Trigrams are: 
 [('Cambridge', ',', 'MA'), (',', 'MA', ':'), ('MA', ':', 'MIT'), (':', 'MIT', 'press'), ('MIT', 'press', '.')]

>> POS Tags are: 
 [('Cambridge', 'NNP'), (',', ','), ('MA', 'NNP'), (':', ':'), ('MIT', 'NNP'), ('press', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Cambridge', 'MA', 'MIT press']

>> Named Entities are: 
 [('GPE', 'Cambridge'), ('ORGANIZATION', 'MIT')] 

>> Stemming using Porter Stemmer: 
 [('Cambridge', 'cambridg'), (',', ','), ('MA', 'ma'), (':', ':'), ('MIT', 'mit'), ('press', 'press'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Cambridge', 'cambridg'), (',', ','), ('MA', 'ma'), (':', ':'), ('MIT', 'mit'), ('press', 'press'), ('.', '.')]

>> Lemmatization: 
 [('Cambridge', 'Cambridge'), (',', ','), ('MA', 'MA'), (':', ':'), ('MIT', 'MIT'), ('press', 'press'), ('.', '.')]



========================================== PARAGRAPH 767 ===========================================

[69] Riedhammer, K., Favre, B., & Hakkani-Tür, D. (2010). Long story short–global  

------------------- Sentence 1 -------------------

[69] Riedhammer, K., Favre, B., & Hakkani-Tür, D. (2010).

>> Tokens are: 
 ['[', '69', ']', 'Riedhammer', ',', 'K.', ',', 'Favre', ',', 'B.', ',', '&', 'Hakkani-Tür', ',', 'D.', '(', '2010', ')', '.']

>> Bigrams are: 
 [('[', '69'), ('69', ']'), (']', 'Riedhammer'), ('Riedhammer', ','), (',', 'K.'), ('K.', ','), (',', 'Favre'), ('Favre', ','), (',', 'B.'), ('B.', ','), (',', '&'), ('&', 'Hakkani-Tür'), ('Hakkani-Tür', ','), (',', 'D.'), ('D.', '('), ('(', '2010'), ('2010', ')'), (')', '.')]

>> Trigrams are: 
 [('[', '69', ']'), ('69', ']', 'Riedhammer'), (']', 'Riedhammer', ','), ('Riedhammer', ',', 'K.'), (',', 'K.', ','), ('K.', ',', 'Favre'), (',', 'Favre', ','), ('Favre', ',', 'B.'), (',', 'B.', ','), ('B.', ',', '&'), (',', '&', 'Hakkani-Tür'), ('&', 'Hakkani-Tür', ','), ('Hakkani-Tür', ',', 'D.'), (',', 'D.', '('), ('D.', '(', '2010'), ('(', '2010', ')'), ('2010', ')', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('69', 'CD'), (']', 'JJ'), ('Riedhammer', 'NNP'), (',', ','), ('K.', 'NNP'), (',', ','), ('Favre', 'NNP'), (',', ','), ('B.', 'NNP'), (',', ','), ('&', 'CC'), ('Hakkani-Tür', 'NNP'), (',', ','), ('D.', 'NNP'), ('(', '('), ('2010', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['] Riedhammer', 'K.', 'Favre', 'B.', 'Hakkani-Tür', 'D.']

>> Named Entities are: 
 [('PERSON', 'Favre')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('69', '69'), (']', ']'), ('Riedhammer', 'riedhamm'), (',', ','), ('K.', 'k.'), (',', ','), ('Favre', 'favr'), (',', ','), ('B.', 'b.'), (',', ','), ('&', '&'), ('Hakkani-Tür', 'hakkani-tür'), (',', ','), ('D.', 'd.'), ('(', '('), ('2010', '2010'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('69', '69'), (']', ']'), ('Riedhammer', 'riedhamm'), (',', ','), ('K.', 'k.'), (',', ','), ('Favre', 'favr'), (',', ','), ('B.', 'b.'), (',', ','), ('&', '&'), ('Hakkani-Tür', 'hakkani-tür'), (',', ','), ('D.', 'd.'), ('(', '('), ('2010', '2010'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('69', '69'), (']', ']'), ('Riedhammer', 'Riedhammer'), (',', ','), ('K.', 'K.'), (',', ','), ('Favre', 'Favre'), (',', ','), ('B.', 'B.'), (',', ','), ('&', '&'), ('Hakkani-Tür', 'Hakkani-Tür'), (',', ','), ('D.', 'D.'), ('(', '('), ('2010', '2010'), (')', ')'), ('.', '.')]


------------------- Sentence 2 -------------------

Long story short–global

>> Tokens are: 
 ['Long', 'story', 'short–global']

>> Bigrams are: 
 [('Long', 'story'), ('story', 'short–global')]

>> Trigrams are: 
 [('Long', 'story', 'short–global')]

>> POS Tags are: 
 [('Long', 'NNP'), ('story', 'NN'), ('short–global', 'NN')]

>> Noun Phrases are: 
 ['Long story short–global']

>> Named Entities are: 
 [('GPE', 'Long')] 

>> Stemming using Porter Stemmer: 
 [('Long', 'long'), ('story', 'stori'), ('short–global', 'short–glob')]

>> Stemming using Snowball Stemmer: 
 [('Long', 'long'), ('story', 'stori'), ('short–global', 'short–glob')]

>> Lemmatization: 
 [('Long', 'Long'), ('story', 'story'), ('short–global', 'short–global')]



========================================== PARAGRAPH 768 ===========================================

unsupervised models for keyphrase based meeting summarization. Speech  

------------------- Sentence 1 -------------------

unsupervised models for keyphrase based meeting summarization.

>> Tokens are: 
 ['unsupervised', 'models', 'keyphrase', 'based', 'meeting', 'summarization', '.']

>> Bigrams are: 
 [('unsupervised', 'models'), ('models', 'keyphrase'), ('keyphrase', 'based'), ('based', 'meeting'), ('meeting', 'summarization'), ('summarization', '.')]

>> Trigrams are: 
 [('unsupervised', 'models', 'keyphrase'), ('models', 'keyphrase', 'based'), ('keyphrase', 'based', 'meeting'), ('based', 'meeting', 'summarization'), ('meeting', 'summarization', '.')]

>> POS Tags are: 
 [('unsupervised', 'JJ'), ('models', 'NNS'), ('keyphrase', 'VBP'), ('based', 'VBN'), ('meeting', 'NN'), ('summarization', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['unsupervised models', 'meeting summarization']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('unsupervised', 'unsupervis'), ('models', 'model'), ('keyphrase', 'keyphras'), ('based', 'base'), ('meeting', 'meet'), ('summarization', 'summar'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('unsupervised', 'unsupervis'), ('models', 'model'), ('keyphrase', 'keyphras'), ('based', 'base'), ('meeting', 'meet'), ('summarization', 'summar'), ('.', '.')]

>> Lemmatization: 
 [('unsupervised', 'unsupervised'), ('models', 'model'), ('keyphrase', 'keyphrase'), ('based', 'based'), ('meeting', 'meeting'), ('summarization', 'summarization'), ('.', '.')]


------------------- Sentence 2 -------------------

Speech

>> Tokens are: 
 ['Speech']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Speech', 'NN')]

>> Noun Phrases are: 
 ['Speech']

>> Named Entities are: 
 [('GPE', 'Speech')] 

>> Stemming using Porter Stemmer: 
 [('Speech', 'speech')]

>> Stemming using Snowball Stemmer: 
 [('Speech', 'speech')]

>> Lemmatization: 
 [('Speech', 'Speech')]



========================================== PARAGRAPH 769 ===========================================

Communication, 52(10), 801-815.  

------------------- Sentence 1 -------------------

Communication, 52(10), 801-815.

>> Tokens are: 
 ['Communication', ',', '52', '(', '10', ')', ',', '801-815', '.']

>> Bigrams are: 
 [('Communication', ','), (',', '52'), ('52', '('), ('(', '10'), ('10', ')'), (')', ','), (',', '801-815'), ('801-815', '.')]

>> Trigrams are: 
 [('Communication', ',', '52'), (',', '52', '('), ('52', '(', '10'), ('(', '10', ')'), ('10', ')', ','), (')', ',', '801-815'), (',', '801-815', '.')]

>> POS Tags are: 
 [('Communication', 'NN'), (',', ','), ('52', 'CD'), ('(', '('), ('10', 'CD'), (')', ')'), (',', ','), ('801-815', 'JJ'), ('.', '.')]

>> Noun Phrases are: 
 ['Communication']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Communication', 'commun'), (',', ','), ('52', '52'), ('(', '('), ('10', '10'), (')', ')'), (',', ','), ('801-815', '801-815'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Communication', 'communic'), (',', ','), ('52', '52'), ('(', '('), ('10', '10'), (')', ')'), (',', ','), ('801-815', '801-815'), ('.', '.')]

>> Lemmatization: 
 [('Communication', 'Communication'), (',', ','), ('52', '52'), ('(', '('), ('10', '10'), (')', ')'), (',', ','), ('801-815', '801-815'), ('.', '.')]



========================================== PARAGRAPH 770 ===========================================

[70] Wang, D., Zhu, S., Li, T., & Gong, Y. (2009, August). Multi-document summarization  

------------------- Sentence 1 -------------------

[70] Wang, D., Zhu, S., Li, T., & Gong, Y.

>> Tokens are: 
 ['[', '70', ']', 'Wang', ',', 'D.', ',', 'Zhu', ',', 'S.', ',', 'Li', ',', 'T.', ',', '&', 'Gong', ',', 'Y', '.']

>> Bigrams are: 
 [('[', '70'), ('70', ']'), (']', 'Wang'), ('Wang', ','), (',', 'D.'), ('D.', ','), (',', 'Zhu'), ('Zhu', ','), (',', 'S.'), ('S.', ','), (',', 'Li'), ('Li', ','), (',', 'T.'), ('T.', ','), (',', '&'), ('&', 'Gong'), ('Gong', ','), (',', 'Y'), ('Y', '.')]

>> Trigrams are: 
 [('[', '70', ']'), ('70', ']', 'Wang'), (']', 'Wang', ','), ('Wang', ',', 'D.'), (',', 'D.', ','), ('D.', ',', 'Zhu'), (',', 'Zhu', ','), ('Zhu', ',', 'S.'), (',', 'S.', ','), ('S.', ',', 'Li'), (',', 'Li', ','), ('Li', ',', 'T.'), (',', 'T.', ','), ('T.', ',', '&'), (',', '&', 'Gong'), ('&', 'Gong', ','), ('Gong', ',', 'Y'), (',', 'Y', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('70', 'CD'), (']', 'NNP'), ('Wang', 'NNP'), (',', ','), ('D.', 'NNP'), (',', ','), ('Zhu', 'NNP'), (',', ','), ('S.', 'NNP'), (',', ','), ('Li', 'NNP'), (',', ','), ('T.', 'NNP'), (',', ','), ('&', 'CC'), ('Gong', 'NNP'), (',', ','), ('Y', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['] Wang', 'D.', 'Zhu', 'S.', 'Li', 'T.', 'Gong', 'Y']

>> Named Entities are: 
 [('PERSON', 'Wang'), ('PERSON', 'Zhu'), ('PERSON', 'Li'), ('GPE', 'Gong')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('70', '70'), (']', ']'), ('Wang', 'wang'), (',', ','), ('D.', 'd.'), (',', ','), ('Zhu', 'zhu'), (',', ','), ('S.', 's.'), (',', ','), ('Li', 'li'), (',', ','), ('T.', 't.'), (',', ','), ('&', '&'), ('Gong', 'gong'), (',', ','), ('Y', 'y'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('70', '70'), (']', ']'), ('Wang', 'wang'), (',', ','), ('D.', 'd.'), (',', ','), ('Zhu', 'zhu'), (',', ','), ('S.', 's.'), (',', ','), ('Li', 'li'), (',', ','), ('T.', 't.'), (',', ','), ('&', '&'), ('Gong', 'gong'), (',', ','), ('Y', 'y'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('70', '70'), (']', ']'), ('Wang', 'Wang'), (',', ','), ('D.', 'D.'), (',', ','), ('Zhu', 'Zhu'), (',', ','), ('S.', 'S.'), (',', ','), ('Li', 'Li'), (',', ','), ('T.', 'T.'), (',', ','), ('&', '&'), ('Gong', 'Gong'), (',', ','), ('Y', 'Y'), ('.', '.')]


------------------- Sentence 2 -------------------

(2009, August).

>> Tokens are: 
 ['(', '2009', ',', 'August', ')', '.']

>> Bigrams are: 
 [('(', '2009'), ('2009', ','), (',', 'August'), ('August', ')'), (')', '.')]

>> Trigrams are: 
 [('(', '2009', ','), ('2009', ',', 'August'), (',', 'August', ')'), ('August', ')', '.')]

>> POS Tags are: 
 [('(', '('), ('2009', 'CD'), (',', ','), ('August', 'NNP'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['August']

>> Named Entities are: 
 [('GPE', 'August')] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('2009', '2009'), (',', ','), ('August', 'august'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('2009', '2009'), (',', ','), ('August', 'august'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('(', '('), ('2009', '2009'), (',', ','), ('August', 'August'), (')', ')'), ('.', '.')]


------------------- Sentence 3 -------------------

Multi-document summarization

>> Tokens are: 
 ['Multi-document', 'summarization']

>> Bigrams are: 
 [('Multi-document', 'summarization')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Multi-document', 'JJ'), ('summarization', 'NN')]

>> Noun Phrases are: 
 ['Multi-document summarization']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Multi-document', 'multi-docu'), ('summarization', 'summar')]

>> Stemming using Snowball Stemmer: 
 [('Multi-document', 'multi-docu'), ('summarization', 'summar')]

>> Lemmatization: 
 [('Multi-document', 'Multi-document'), ('summarization', 'summarization')]



========================================== PARAGRAPH 771 ===========================================

using sentence-based topic models. In Proceedings of the ACL-IJCNLP 2009 Conference  

------------------- Sentence 1 -------------------

using sentence-based topic models.

>> Tokens are: 
 ['using', 'sentence-based', 'topic', 'models', '.']

>> Bigrams are: 
 [('using', 'sentence-based'), ('sentence-based', 'topic'), ('topic', 'models'), ('models', '.')]

>> Trigrams are: 
 [('using', 'sentence-based', 'topic'), ('sentence-based', 'topic', 'models'), ('topic', 'models', '.')]

>> POS Tags are: 
 [('using', 'VBG'), ('sentence-based', 'JJ'), ('topic', 'NN'), ('models', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['sentence-based topic models']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('using', 'use'), ('sentence-based', 'sentence-bas'), ('topic', 'topic'), ('models', 'model'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('using', 'use'), ('sentence-based', 'sentence-bas'), ('topic', 'topic'), ('models', 'model'), ('.', '.')]

>> Lemmatization: 
 [('using', 'using'), ('sentence-based', 'sentence-based'), ('topic', 'topic'), ('models', 'model'), ('.', '.')]


------------------- Sentence 2 -------------------

In Proceedings of the ACL-IJCNLP 2009 Conference

>> Tokens are: 
 ['In', 'Proceedings', 'ACL-IJCNLP', '2009', 'Conference']

>> Bigrams are: 
 [('In', 'Proceedings'), ('Proceedings', 'ACL-IJCNLP'), ('ACL-IJCNLP', '2009'), ('2009', 'Conference')]

>> Trigrams are: 
 [('In', 'Proceedings', 'ACL-IJCNLP'), ('Proceedings', 'ACL-IJCNLP', '2009'), ('ACL-IJCNLP', '2009', 'Conference')]

>> POS Tags are: 
 [('In', 'IN'), ('Proceedings', 'NNP'), ('ACL-IJCNLP', 'NNP'), ('2009', 'CD'), ('Conference', 'NN')]

>> Noun Phrases are: 
 ['Proceedings ACL-IJCNLP', 'Conference']

>> Named Entities are: 
 [('GPE', 'Proceedings')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('Proceedings', 'proceed'), ('ACL-IJCNLP', 'acl-ijcnlp'), ('2009', '2009'), ('Conference', 'confer')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('Proceedings', 'proceed'), ('ACL-IJCNLP', 'acl-ijcnlp'), ('2009', '2009'), ('Conference', 'confer')]

>> Lemmatization: 
 [('In', 'In'), ('Proceedings', 'Proceedings'), ('ACL-IJCNLP', 'ACL-IJCNLP'), ('2009', '2009'), ('Conference', 'Conference')]



========================================== PARAGRAPH 772 ===========================================

Short Papers (pp. 297-300). Association for Computational Linguistics.  

------------------- Sentence 1 -------------------

Short Papers (pp.

>> Tokens are: 
 ['Short', 'Papers', '(', 'pp', '.']

>> Bigrams are: 
 [('Short', 'Papers'), ('Papers', '('), ('(', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('Short', 'Papers', '('), ('Papers', '(', 'pp'), ('(', 'pp', '.')]

>> POS Tags are: 
 [('Short', 'JJ'), ('Papers', 'NNP'), ('(', '('), ('pp', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Short Papers', 'pp']

>> Named Entities are: 
 [('GPE', 'Papers')] 

>> Stemming using Porter Stemmer: 
 [('Short', 'short'), ('Papers', 'paper'), ('(', '('), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Short', 'short'), ('Papers', 'paper'), ('(', '('), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('Short', 'Short'), ('Papers', 'Papers'), ('(', '('), ('pp', 'pp'), ('.', '.')]


------------------- Sentence 2 -------------------

297-300).

>> Tokens are: 
 ['297-300', ')', '.']

>> Bigrams are: 
 [('297-300', ')'), (')', '.')]

>> Trigrams are: 
 [('297-300', ')', '.')]

>> POS Tags are: 
 [('297-300', 'JJ'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('297-300', '297-300'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('297-300', '297-300'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('297-300', '297-300'), (')', ')'), ('.', '.')]


------------------- Sentence 3 -------------------

Association for Computational Linguistics.

>> Tokens are: 
 ['Association', 'Computational', 'Linguistics', '.']

>> Bigrams are: 
 [('Association', 'Computational'), ('Computational', 'Linguistics'), ('Linguistics', '.')]

>> Trigrams are: 
 [('Association', 'Computational', 'Linguistics'), ('Computational', 'Linguistics', '.')]

>> POS Tags are: 
 [('Association', 'NNP'), ('Computational', 'NNP'), ('Linguistics', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Association Computational Linguistics']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Association', 'associ'), ('Computational', 'comput'), ('Linguistics', 'linguist'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Association', 'associ'), ('Computational', 'comput'), ('Linguistics', 'linguist'), ('.', '.')]

>> Lemmatization: 
 [('Association', 'Association'), ('Computational', 'Computational'), ('Linguistics', 'Linguistics'), ('.', '.')]



========================================== PARAGRAPH 773 ===========================================

[71] Wang, D., Zhu, S., Li, T., Chi, Y., & Gong, Y. (2011). Integrating document clustering  

------------------- Sentence 1 -------------------

[71] Wang, D., Zhu, S., Li, T., Chi, Y., & Gong, Y.

>> Tokens are: 
 ['[', '71', ']', 'Wang', ',', 'D.', ',', 'Zhu', ',', 'S.', ',', 'Li', ',', 'T.', ',', 'Chi', ',', 'Y.', ',', '&', 'Gong', ',', 'Y', '.']

>> Bigrams are: 
 [('[', '71'), ('71', ']'), (']', 'Wang'), ('Wang', ','), (',', 'D.'), ('D.', ','), (',', 'Zhu'), ('Zhu', ','), (',', 'S.'), ('S.', ','), (',', 'Li'), ('Li', ','), (',', 'T.'), ('T.', ','), (',', 'Chi'), ('Chi', ','), (',', 'Y.'), ('Y.', ','), (',', '&'), ('&', 'Gong'), ('Gong', ','), (',', 'Y'), ('Y', '.')]

>> Trigrams are: 
 [('[', '71', ']'), ('71', ']', 'Wang'), (']', 'Wang', ','), ('Wang', ',', 'D.'), (',', 'D.', ','), ('D.', ',', 'Zhu'), (',', 'Zhu', ','), ('Zhu', ',', 'S.'), (',', 'S.', ','), ('S.', ',', 'Li'), (',', 'Li', ','), ('Li', ',', 'T.'), (',', 'T.', ','), ('T.', ',', 'Chi'), (',', 'Chi', ','), ('Chi', ',', 'Y.'), (',', 'Y.', ','), ('Y.', ',', '&'), (',', '&', 'Gong'), ('&', 'Gong', ','), ('Gong', ',', 'Y'), (',', 'Y', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('71', 'CD'), (']', 'NNP'), ('Wang', 'NNP'), (',', ','), ('D.', 'NNP'), (',', ','), ('Zhu', 'NNP'), (',', ','), ('S.', 'NNP'), (',', ','), ('Li', 'NNP'), (',', ','), ('T.', 'NNP'), (',', ','), ('Chi', 'NNP'), (',', ','), ('Y.', 'NNP'), (',', ','), ('&', 'CC'), ('Gong', 'NNP'), (',', ','), ('Y', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['] Wang', 'D.', 'Zhu', 'S.', 'Li', 'T.', 'Chi', 'Y.', 'Gong', 'Y']

>> Named Entities are: 
 [('PERSON', 'Wang'), ('PERSON', 'Zhu'), ('PERSON', 'Li'), ('GPE', 'Chi'), ('GPE', 'Gong')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('71', '71'), (']', ']'), ('Wang', 'wang'), (',', ','), ('D.', 'd.'), (',', ','), ('Zhu', 'zhu'), (',', ','), ('S.', 's.'), (',', ','), ('Li', 'li'), (',', ','), ('T.', 't.'), (',', ','), ('Chi', 'chi'), (',', ','), ('Y.', 'y.'), (',', ','), ('&', '&'), ('Gong', 'gong'), (',', ','), ('Y', 'y'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('71', '71'), (']', ']'), ('Wang', 'wang'), (',', ','), ('D.', 'd.'), (',', ','), ('Zhu', 'zhu'), (',', ','), ('S.', 's.'), (',', ','), ('Li', 'li'), (',', ','), ('T.', 't.'), (',', ','), ('Chi', 'chi'), (',', ','), ('Y.', 'y.'), (',', ','), ('&', '&'), ('Gong', 'gong'), (',', ','), ('Y', 'y'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('71', '71'), (']', ']'), ('Wang', 'Wang'), (',', ','), ('D.', 'D.'), (',', ','), ('Zhu', 'Zhu'), (',', ','), ('S.', 'S.'), (',', ','), ('Li', 'Li'), (',', ','), ('T.', 'T.'), (',', ','), ('Chi', 'Chi'), (',', ','), ('Y.', 'Y.'), (',', ','), ('&', '&'), ('Gong', 'Gong'), (',', ','), ('Y', 'Y'), ('.', '.')]


------------------- Sentence 2 -------------------

(2011).

>> Tokens are: 
 ['(', '2011', ')', '.']

>> Bigrams are: 
 [('(', '2011'), ('2011', ')'), (')', '.')]

>> Trigrams are: 
 [('(', '2011', ')'), ('2011', ')', '.')]

>> POS Tags are: 
 [('(', '('), ('2011', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('2011', '2011'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('2011', '2011'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('(', '('), ('2011', '2011'), (')', ')'), ('.', '.')]


------------------- Sentence 3 -------------------

Integrating document clustering

>> Tokens are: 
 ['Integrating', 'document', 'clustering']

>> Bigrams are: 
 [('Integrating', 'document'), ('document', 'clustering')]

>> Trigrams are: 
 [('Integrating', 'document', 'clustering')]

>> POS Tags are: 
 [('Integrating', 'VBG'), ('document', 'NN'), ('clustering', 'NN')]

>> Noun Phrases are: 
 ['document clustering']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Integrating', 'integr'), ('document', 'document'), ('clustering', 'cluster')]

>> Stemming using Snowball Stemmer: 
 [('Integrating', 'integr'), ('document', 'document'), ('clustering', 'cluster')]

>> Lemmatization: 
 [('Integrating', 'Integrating'), ('document', 'document'), ('clustering', 'clustering')]



========================================== PARAGRAPH 774 ===========================================

and multidocument summarization. ACM Transactions on Knowledge Discovery from Data  

------------------- Sentence 1 -------------------

and multidocument summarization.

>> Tokens are: 
 ['multidocument', 'summarization', '.']

>> Bigrams are: 
 [('multidocument', 'summarization'), ('summarization', '.')]

>> Trigrams are: 
 [('multidocument', 'summarization', '.')]

>> POS Tags are: 
 [('multidocument', 'JJ'), ('summarization', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['multidocument summarization']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('multidocument', 'multidocu'), ('summarization', 'summar'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('multidocument', 'multidocu'), ('summarization', 'summar'), ('.', '.')]

>> Lemmatization: 
 [('multidocument', 'multidocument'), ('summarization', 'summarization'), ('.', '.')]


------------------- Sentence 2 -------------------

ACM Transactions on Knowledge Discovery from Data

>> Tokens are: 
 ['ACM', 'Transactions', 'Knowledge', 'Discovery', 'Data']

>> Bigrams are: 
 [('ACM', 'Transactions'), ('Transactions', 'Knowledge'), ('Knowledge', 'Discovery'), ('Discovery', 'Data')]

>> Trigrams are: 
 [('ACM', 'Transactions', 'Knowledge'), ('Transactions', 'Knowledge', 'Discovery'), ('Knowledge', 'Discovery', 'Data')]

>> POS Tags are: 
 [('ACM', 'NNP'), ('Transactions', 'NNP'), ('Knowledge', 'NNP'), ('Discovery', 'NNP'), ('Data', 'NNP')]

>> Noun Phrases are: 
 ['ACM Transactions Knowledge Discovery Data']

>> Named Entities are: 
 [('ORGANIZATION', 'ACM Transactions')] 

>> Stemming using Porter Stemmer: 
 [('ACM', 'acm'), ('Transactions', 'transact'), ('Knowledge', 'knowledg'), ('Discovery', 'discoveri'), ('Data', 'data')]

>> Stemming using Snowball Stemmer: 
 [('ACM', 'acm'), ('Transactions', 'transact'), ('Knowledge', 'knowledg'), ('Discovery', 'discoveri'), ('Data', 'data')]

>> Lemmatization: 
 [('ACM', 'ACM'), ('Transactions', 'Transactions'), ('Knowledge', 'Knowledge'), ('Discovery', 'Discovery'), ('Data', 'Data')]



========================================== PARAGRAPH 775 ===========================================

(TKDD), 5(3), 14.  

------------------- Sentence 1 -------------------

(TKDD), 5(3), 14.

>> Tokens are: 
 ['(', 'TKDD', ')', ',', '5', '(', '3', ')', ',', '14', '.']

>> Bigrams are: 
 [('(', 'TKDD'), ('TKDD', ')'), (')', ','), (',', '5'), ('5', '('), ('(', '3'), ('3', ')'), (')', ','), (',', '14'), ('14', '.')]

>> Trigrams are: 
 [('(', 'TKDD', ')'), ('TKDD', ')', ','), (')', ',', '5'), (',', '5', '('), ('5', '(', '3'), ('(', '3', ')'), ('3', ')', ','), (')', ',', '14'), (',', '14', '.')]

>> POS Tags are: 
 [('(', '('), ('TKDD', 'NNP'), (')', ')'), (',', ','), ('5', 'CD'), ('(', '('), ('3', 'CD'), (')', ')'), (',', ','), ('14', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['TKDD']

>> Named Entities are: 
 [('ORGANIZATION', 'TKDD')] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('TKDD', 'tkdd'), (')', ')'), (',', ','), ('5', '5'), ('(', '('), ('3', '3'), (')', ')'), (',', ','), ('14', '14'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('TKDD', 'tkdd'), (')', ')'), (',', ','), ('5', '5'), ('(', '('), ('3', '3'), (')', ')'), (',', ','), ('14', '14'), ('.', '.')]

>> Lemmatization: 
 [('(', '('), ('TKDD', 'TKDD'), (')', ')'), (',', ','), ('5', '5'), ('(', '('), ('3', '3'), (')', ')'), (',', ','), ('14', '14'), ('.', '.')]



========================================== PARAGRAPH 776 ===========================================

[72] Fang, H., Lu, W., Wu, F., Zhang, Y., Shang, X., Shao, J., & Zhuang, Y. (2015). Topic  

------------------- Sentence 1 -------------------

[72] Fang, H., Lu, W., Wu, F., Zhang, Y., Shang, X., Shao, J., & Zhuang, Y.

>> Tokens are: 
 ['[', '72', ']', 'Fang', ',', 'H.', ',', 'Lu', ',', 'W.', ',', 'Wu', ',', 'F.', ',', 'Zhang', ',', 'Y.', ',', 'Shang', ',', 'X.', ',', 'Shao', ',', 'J.', ',', '&', 'Zhuang', ',', 'Y', '.']

>> Bigrams are: 
 [('[', '72'), ('72', ']'), (']', 'Fang'), ('Fang', ','), (',', 'H.'), ('H.', ','), (',', 'Lu'), ('Lu', ','), (',', 'W.'), ('W.', ','), (',', 'Wu'), ('Wu', ','), (',', 'F.'), ('F.', ','), (',', 'Zhang'), ('Zhang', ','), (',', 'Y.'), ('Y.', ','), (',', 'Shang'), ('Shang', ','), (',', 'X.'), ('X.', ','), (',', 'Shao'), ('Shao', ','), (',', 'J.'), ('J.', ','), (',', '&'), ('&', 'Zhuang'), ('Zhuang', ','), (',', 'Y'), ('Y', '.')]

>> Trigrams are: 
 [('[', '72', ']'), ('72', ']', 'Fang'), (']', 'Fang', ','), ('Fang', ',', 'H.'), (',', 'H.', ','), ('H.', ',', 'Lu'), (',', 'Lu', ','), ('Lu', ',', 'W.'), (',', 'W.', ','), ('W.', ',', 'Wu'), (',', 'Wu', ','), ('Wu', ',', 'F.'), (',', 'F.', ','), ('F.', ',', 'Zhang'), (',', 'Zhang', ','), ('Zhang', ',', 'Y.'), (',', 'Y.', ','), ('Y.', ',', 'Shang'), (',', 'Shang', ','), ('Shang', ',', 'X.'), (',', 'X.', ','), ('X.', ',', 'Shao'), (',', 'Shao', ','), ('Shao', ',', 'J.'), (',', 'J.', ','), ('J.', ',', '&'), (',', '&', 'Zhuang'), ('&', 'Zhuang', ','), ('Zhuang', ',', 'Y'), (',', 'Y', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('72', 'CD'), (']', 'NNP'), ('Fang', 'NNP'), (',', ','), ('H.', 'NNP'), (',', ','), ('Lu', 'NNP'), (',', ','), ('W.', 'NNP'), (',', ','), ('Wu', 'NNP'), (',', ','), ('F.', 'NNP'), (',', ','), ('Zhang', 'NNP'), (',', ','), ('Y.', 'NNP'), (',', ','), ('Shang', 'NNP'), (',', ','), ('X.', 'NNP'), (',', ','), ('Shao', 'NNP'), (',', ','), ('J.', 'NNP'), (',', ','), ('&', 'CC'), ('Zhuang', 'NNP'), (',', ','), ('Y', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['] Fang', 'H.', 'Lu', 'W.', 'Wu', 'F.', 'Zhang', 'Y.', 'Shang', 'X.', 'Shao', 'J.', 'Zhuang', 'Y']

>> Named Entities are: 
 [('PERSON', 'Fang'), ('GPE', 'Lu'), ('GPE', 'Wu'), ('PERSON', 'Zhang'), ('PERSON', 'Shang'), ('PERSON', 'Shao'), ('PERSON', 'Zhuang')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('72', '72'), (']', ']'), ('Fang', 'fang'), (',', ','), ('H.', 'h.'), (',', ','), ('Lu', 'lu'), (',', ','), ('W.', 'w.'), (',', ','), ('Wu', 'wu'), (',', ','), ('F.', 'f.'), (',', ','), ('Zhang', 'zhang'), (',', ','), ('Y.', 'y.'), (',', ','), ('Shang', 'shang'), (',', ','), ('X.', 'x.'), (',', ','), ('Shao', 'shao'), (',', ','), ('J.', 'j.'), (',', ','), ('&', '&'), ('Zhuang', 'zhuang'), (',', ','), ('Y', 'y'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('72', '72'), (']', ']'), ('Fang', 'fang'), (',', ','), ('H.', 'h.'), (',', ','), ('Lu', 'lu'), (',', ','), ('W.', 'w.'), (',', ','), ('Wu', 'wu'), (',', ','), ('F.', 'f.'), (',', ','), ('Zhang', 'zhang'), (',', ','), ('Y.', 'y.'), (',', ','), ('Shang', 'shang'), (',', ','), ('X.', 'x.'), (',', ','), ('Shao', 'shao'), (',', ','), ('J.', 'j.'), (',', ','), ('&', '&'), ('Zhuang', 'zhuang'), (',', ','), ('Y', 'y'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('72', '72'), (']', ']'), ('Fang', 'Fang'), (',', ','), ('H.', 'H.'), (',', ','), ('Lu', 'Lu'), (',', ','), ('W.', 'W.'), (',', ','), ('Wu', 'Wu'), (',', ','), ('F.', 'F.'), (',', ','), ('Zhang', 'Zhang'), (',', ','), ('Y.', 'Y.'), (',', ','), ('Shang', 'Shang'), (',', ','), ('X.', 'X.'), (',', ','), ('Shao', 'Shao'), (',', ','), ('J.', 'J.'), (',', ','), ('&', '&'), ('Zhuang', 'Zhuang'), (',', ','), ('Y', 'Y'), ('.', '.')]


------------------- Sentence 2 -------------------

(2015).

>> Tokens are: 
 ['(', '2015', ')', '.']

>> Bigrams are: 
 [('(', '2015'), ('2015', ')'), (')', '.')]

>> Trigrams are: 
 [('(', '2015', ')'), ('2015', ')', '.')]

>> POS Tags are: 
 [('(', '('), ('2015', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('2015', '2015'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('2015', '2015'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('(', '('), ('2015', '2015'), (')', ')'), ('.', '.')]


------------------- Sentence 3 -------------------

Topic

>> Tokens are: 
 ['Topic']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Topic', 'NN')]

>> Noun Phrases are: 
 ['Topic']

>> Named Entities are: 
 [('GPE', 'Topic')] 

>> Stemming using Porter Stemmer: 
 [('Topic', 'topic')]

>> Stemming using Snowball Stemmer: 
 [('Topic', 'topic')]

>> Lemmatization: 
 [('Topic', 'Topic')]



========================================== PARAGRAPH 777 ===========================================

aspect-oriented summarization via group selection. Neurocomputing, 149, 1613-1619.  

------------------- Sentence 1 -------------------

aspect-oriented summarization via group selection.

>> Tokens are: 
 ['aspect-oriented', 'summarization', 'via', 'group', 'selection', '.']

>> Bigrams are: 
 [('aspect-oriented', 'summarization'), ('summarization', 'via'), ('via', 'group'), ('group', 'selection'), ('selection', '.')]

>> Trigrams are: 
 [('aspect-oriented', 'summarization', 'via'), ('summarization', 'via', 'group'), ('via', 'group', 'selection'), ('group', 'selection', '.')]

>> POS Tags are: 
 [('aspect-oriented', 'JJ'), ('summarization', 'NN'), ('via', 'IN'), ('group', 'NN'), ('selection', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['aspect-oriented summarization', 'group selection']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('aspect-oriented', 'aspect-ori'), ('summarization', 'summar'), ('via', 'via'), ('group', 'group'), ('selection', 'select'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('aspect-oriented', 'aspect-ori'), ('summarization', 'summar'), ('via', 'via'), ('group', 'group'), ('selection', 'select'), ('.', '.')]

>> Lemmatization: 
 [('aspect-oriented', 'aspect-oriented'), ('summarization', 'summarization'), ('via', 'via'), ('group', 'group'), ('selection', 'selection'), ('.', '.')]


------------------- Sentence 2 -------------------

Neurocomputing, 149, 1613-1619.

>> Tokens are: 
 ['Neurocomputing', ',', '149', ',', '1613-1619', '.']

>> Bigrams are: 
 [('Neurocomputing', ','), (',', '149'), ('149', ','), (',', '1613-1619'), ('1613-1619', '.')]

>> Trigrams are: 
 [('Neurocomputing', ',', '149'), (',', '149', ','), ('149', ',', '1613-1619'), (',', '1613-1619', '.')]

>> POS Tags are: 
 [('Neurocomputing', 'NNP'), (',', ','), ('149', 'CD'), (',', ','), ('1613-1619', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Neurocomputing']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Neurocomputing', 'neurocomput'), (',', ','), ('149', '149'), (',', ','), ('1613-1619', '1613-1619'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Neurocomputing', 'neurocomput'), (',', ','), ('149', '149'), (',', ','), ('1613-1619', '1613-1619'), ('.', '.')]

>> Lemmatization: 
 [('Neurocomputing', 'Neurocomputing'), (',', ','), ('149', '149'), (',', ','), ('1613-1619', '1613-1619'), ('.', '.')]



========================================== PARAGRAPH 778 ===========================================

[73] Sager, N., Lyman, M., Nhan, N. T., & Tick, L. J. (1995). Medical language processing:  

------------------- Sentence 1 -------------------

[73] Sager, N., Lyman, M., Nhan, N. T., & Tick, L. J.

>> Tokens are: 
 ['[', '73', ']', 'Sager', ',', 'N.', ',', 'Lyman', ',', 'M.', ',', 'Nhan', ',', 'N.', 'T.', ',', '&', 'Tick', ',', 'L.', 'J', '.']

>> Bigrams are: 
 [('[', '73'), ('73', ']'), (']', 'Sager'), ('Sager', ','), (',', 'N.'), ('N.', ','), (',', 'Lyman'), ('Lyman', ','), (',', 'M.'), ('M.', ','), (',', 'Nhan'), ('Nhan', ','), (',', 'N.'), ('N.', 'T.'), ('T.', ','), (',', '&'), ('&', 'Tick'), ('Tick', ','), (',', 'L.'), ('L.', 'J'), ('J', '.')]

>> Trigrams are: 
 [('[', '73', ']'), ('73', ']', 'Sager'), (']', 'Sager', ','), ('Sager', ',', 'N.'), (',', 'N.', ','), ('N.', ',', 'Lyman'), (',', 'Lyman', ','), ('Lyman', ',', 'M.'), (',', 'M.', ','), ('M.', ',', 'Nhan'), (',', 'Nhan', ','), ('Nhan', ',', 'N.'), (',', 'N.', 'T.'), ('N.', 'T.', ','), ('T.', ',', '&'), (',', '&', 'Tick'), ('&', 'Tick', ','), ('Tick', ',', 'L.'), (',', 'L.', 'J'), ('L.', 'J', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('73', 'CD'), (']', 'JJ'), ('Sager', 'NNP'), (',', ','), ('N.', 'NNP'), (',', ','), ('Lyman', 'NNP'), (',', ','), ('M.', 'NNP'), (',', ','), ('Nhan', 'NNP'), (',', ','), ('N.', 'NNP'), ('T.', 'NNP'), (',', ','), ('&', 'CC'), ('Tick', 'NNP'), (',', ','), ('L.', 'NNP'), ('J', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['] Sager', 'N.', 'Lyman', 'M.', 'Nhan', 'N. T.', 'Tick', 'L. J']

>> Named Entities are: 
 [('PERSON', 'Lyman'), ('PERSON', 'Nhan'), ('PERSON', 'Tick')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('73', '73'), (']', ']'), ('Sager', 'sager'), (',', ','), ('N.', 'n.'), (',', ','), ('Lyman', 'lyman'), (',', ','), ('M.', 'm.'), (',', ','), ('Nhan', 'nhan'), (',', ','), ('N.', 'n.'), ('T.', 't.'), (',', ','), ('&', '&'), ('Tick', 'tick'), (',', ','), ('L.', 'l.'), ('J', 'j'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('73', '73'), (']', ']'), ('Sager', 'sager'), (',', ','), ('N.', 'n.'), (',', ','), ('Lyman', 'lyman'), (',', ','), ('M.', 'm.'), (',', ','), ('Nhan', 'nhan'), (',', ','), ('N.', 'n.'), ('T.', 't.'), (',', ','), ('&', '&'), ('Tick', 'tick'), (',', ','), ('L.', 'l.'), ('J', 'j'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('73', '73'), (']', ']'), ('Sager', 'Sager'), (',', ','), ('N.', 'N.'), (',', ','), ('Lyman', 'Lyman'), (',', ','), ('M.', 'M.'), (',', ','), ('Nhan', 'Nhan'), (',', ','), ('N.', 'N.'), ('T.', 'T.'), (',', ','), ('&', '&'), ('Tick', 'Tick'), (',', ','), ('L.', 'L.'), ('J', 'J'), ('.', '.')]


------------------- Sentence 2 -------------------

(1995).

>> Tokens are: 
 ['(', '1995', ')', '.']

>> Bigrams are: 
 [('(', '1995'), ('1995', ')'), (')', '.')]

>> Trigrams are: 
 [('(', '1995', ')'), ('1995', ')', '.')]

>> POS Tags are: 
 [('(', '('), ('1995', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('1995', '1995'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('1995', '1995'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('(', '('), ('1995', '1995'), (')', ')'), ('.', '.')]


------------------- Sentence 3 -------------------

Medical language processing:

>> Tokens are: 
 ['Medical', 'language', 'processing', ':']

>> Bigrams are: 
 [('Medical', 'language'), ('language', 'processing'), ('processing', ':')]

>> Trigrams are: 
 [('Medical', 'language', 'processing'), ('language', 'processing', ':')]

>> POS Tags are: 
 [('Medical', 'JJ'), ('language', 'NN'), ('processing', 'NN'), (':', ':')]

>> Noun Phrases are: 
 ['Medical language processing']

>> Named Entities are: 
 [('GPE', 'Medical')] 

>> Stemming using Porter Stemmer: 
 [('Medical', 'medic'), ('language', 'languag'), ('processing', 'process'), (':', ':')]

>> Stemming using Snowball Stemmer: 
 [('Medical', 'medic'), ('language', 'languag'), ('processing', 'process'), (':', ':')]

>> Lemmatization: 
 [('Medical', 'Medical'), ('language', 'language'), ('processing', 'processing'), (':', ':')]



========================================== PARAGRAPH 779 ===========================================

applications to patient data representation and automatic encoding. Methods of information in  

------------------- Sentence 1 -------------------

applications to patient data representation and automatic encoding.

>> Tokens are: 
 ['applications', 'patient', 'data', 'representation', 'automatic', 'encoding', '.']

>> Bigrams are: 
 [('applications', 'patient'), ('patient', 'data'), ('data', 'representation'), ('representation', 'automatic'), ('automatic', 'encoding'), ('encoding', '.')]

>> Trigrams are: 
 [('applications', 'patient', 'data'), ('patient', 'data', 'representation'), ('data', 'representation', 'automatic'), ('representation', 'automatic', 'encoding'), ('automatic', 'encoding', '.')]

>> POS Tags are: 
 [('applications', 'NNS'), ('patient', 'JJ'), ('data', 'NNS'), ('representation', 'NN'), ('automatic', 'JJ'), ('encoding', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['applications', 'patient data representation', 'automatic encoding']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('applications', 'applic'), ('patient', 'patient'), ('data', 'data'), ('representation', 'represent'), ('automatic', 'automat'), ('encoding', 'encod'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('applications', 'applic'), ('patient', 'patient'), ('data', 'data'), ('representation', 'represent'), ('automatic', 'automat'), ('encoding', 'encod'), ('.', '.')]

>> Lemmatization: 
 [('applications', 'application'), ('patient', 'patient'), ('data', 'data'), ('representation', 'representation'), ('automatic', 'automatic'), ('encoding', 'encoding'), ('.', '.')]


------------------- Sentence 2 -------------------

Methods of information in

>> Tokens are: 
 ['Methods', 'information']

>> Bigrams are: 
 [('Methods', 'information')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Methods', 'NNS'), ('information', 'NN')]

>> Noun Phrases are: 
 ['Methods information']

>> Named Entities are: 
 [('GPE', 'Methods')] 

>> Stemming using Porter Stemmer: 
 [('Methods', 'method'), ('information', 'inform')]

>> Stemming using Snowball Stemmer: 
 [('Methods', 'method'), ('information', 'inform')]

>> Lemmatization: 
 [('Methods', 'Methods'), ('information', 'information')]



========================================== PARAGRAPH 780 ===========================================

medicine, 34(1-2), 140-146.  

------------------- Sentence 1 -------------------

medicine, 34(1-2), 140-146.

>> Tokens are: 
 ['medicine', ',', '34', '(', '1-2', ')', ',', '140-146', '.']

>> Bigrams are: 
 [('medicine', ','), (',', '34'), ('34', '('), ('(', '1-2'), ('1-2', ')'), (')', ','), (',', '140-146'), ('140-146', '.')]

>> Trigrams are: 
 [('medicine', ',', '34'), (',', '34', '('), ('34', '(', '1-2'), ('(', '1-2', ')'), ('1-2', ')', ','), (')', ',', '140-146'), (',', '140-146', '.')]

>> POS Tags are: 
 [('medicine', 'NN'), (',', ','), ('34', 'CD'), ('(', '('), ('1-2', 'JJ'), (')', ')'), (',', ','), ('140-146', 'JJ'), ('.', '.')]

>> Noun Phrases are: 
 ['medicine']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('medicine', 'medicin'), (',', ','), ('34', '34'), ('(', '('), ('1-2', '1-2'), (')', ')'), (',', ','), ('140-146', '140-146'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('medicine', 'medicin'), (',', ','), ('34', '34'), ('(', '('), ('1-2', '1-2'), (')', ')'), (',', ','), ('140-146', '140-146'), ('.', '.')]

>> Lemmatization: 
 [('medicine', 'medicine'), (',', ','), ('34', '34'), ('(', '('), ('1-2', '1-2'), (')', ')'), (',', ','), ('140-146', '140-146'), ('.', '.')]



========================================== PARAGRAPH 781 ===========================================

[74] Chi, E. C., Lyman, M. S., Sager, N., Friedman, C., & Macleod, C. (1985, November). A  

------------------- Sentence 1 -------------------

[74] Chi, E. C., Lyman, M. S., Sager, N., Friedman, C., & Macleod, C. (1985, November).

>> Tokens are: 
 ['[', '74', ']', 'Chi', ',', 'E.', 'C.', ',', 'Lyman', ',', 'M.', 'S.', ',', 'Sager', ',', 'N.', ',', 'Friedman', ',', 'C.', ',', '&', 'Macleod', ',', 'C.', '(', '1985', ',', 'November', ')', '.']

>> Bigrams are: 
 [('[', '74'), ('74', ']'), (']', 'Chi'), ('Chi', ','), (',', 'E.'), ('E.', 'C.'), ('C.', ','), (',', 'Lyman'), ('Lyman', ','), (',', 'M.'), ('M.', 'S.'), ('S.', ','), (',', 'Sager'), ('Sager', ','), (',', 'N.'), ('N.', ','), (',', 'Friedman'), ('Friedman', ','), (',', 'C.'), ('C.', ','), (',', '&'), ('&', 'Macleod'), ('Macleod', ','), (',', 'C.'), ('C.', '('), ('(', '1985'), ('1985', ','), (',', 'November'), ('November', ')'), (')', '.')]

>> Trigrams are: 
 [('[', '74', ']'), ('74', ']', 'Chi'), (']', 'Chi', ','), ('Chi', ',', 'E.'), (',', 'E.', 'C.'), ('E.', 'C.', ','), ('C.', ',', 'Lyman'), (',', 'Lyman', ','), ('Lyman', ',', 'M.'), (',', 'M.', 'S.'), ('M.', 'S.', ','), ('S.', ',', 'Sager'), (',', 'Sager', ','), ('Sager', ',', 'N.'), (',', 'N.', ','), ('N.', ',', 'Friedman'), (',', 'Friedman', ','), ('Friedman', ',', 'C.'), (',', 'C.', ','), ('C.', ',', '&'), (',', '&', 'Macleod'), ('&', 'Macleod', ','), ('Macleod', ',', 'C.'), (',', 'C.', '('), ('C.', '(', '1985'), ('(', '1985', ','), ('1985', ',', 'November'), (',', 'November', ')'), ('November', ')', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('74', 'CD'), (']', 'JJ'), ('Chi', 'NNP'), (',', ','), ('E.', 'NNP'), ('C.', 'NNP'), (',', ','), ('Lyman', 'NNP'), (',', ','), ('M.', 'NNP'), ('S.', 'NNP'), (',', ','), ('Sager', 'NNP'), (',', ','), ('N.', 'NNP'), (',', ','), ('Friedman', 'NNP'), (',', ','), ('C.', 'NNP'), (',', ','), ('&', 'CC'), ('Macleod', 'NNP'), (',', ','), ('C.', 'NNP'), ('(', '('), ('1985', 'CD'), (',', ','), ('November', 'NNP'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['] Chi', 'E. C.', 'Lyman', 'M. S.', 'Sager', 'N.', 'Friedman', 'C.', 'Macleod', 'C.', 'November']

>> Named Entities are: 
 [('GPE', 'Chi'), ('PERSON', 'Lyman'), ('PERSON', 'Sager'), ('PERSON', 'Friedman'), ('PERSON', 'Macleod')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('74', '74'), (']', ']'), ('Chi', 'chi'), (',', ','), ('E.', 'e.'), ('C.', 'c.'), (',', ','), ('Lyman', 'lyman'), (',', ','), ('M.', 'm.'), ('S.', 's.'), (',', ','), ('Sager', 'sager'), (',', ','), ('N.', 'n.'), (',', ','), ('Friedman', 'friedman'), (',', ','), ('C.', 'c.'), (',', ','), ('&', '&'), ('Macleod', 'macleod'), (',', ','), ('C.', 'c.'), ('(', '('), ('1985', '1985'), (',', ','), ('November', 'novemb'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('74', '74'), (']', ']'), ('Chi', 'chi'), (',', ','), ('E.', 'e.'), ('C.', 'c.'), (',', ','), ('Lyman', 'lyman'), (',', ','), ('M.', 'm.'), ('S.', 's.'), (',', ','), ('Sager', 'sager'), (',', ','), ('N.', 'n.'), (',', ','), ('Friedman', 'friedman'), (',', ','), ('C.', 'c.'), (',', ','), ('&', '&'), ('Macleod', 'macleod'), (',', ','), ('C.', 'c.'), ('(', '('), ('1985', '1985'), (',', ','), ('November', 'novemb'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('74', '74'), (']', ']'), ('Chi', 'Chi'), (',', ','), ('E.', 'E.'), ('C.', 'C.'), (',', ','), ('Lyman', 'Lyman'), (',', ','), ('M.', 'M.'), ('S.', 'S.'), (',', ','), ('Sager', 'Sager'), (',', ','), ('N.', 'N.'), (',', ','), ('Friedman', 'Friedman'), (',', ','), ('C.', 'C.'), (',', ','), ('&', '&'), ('Macleod', 'Macleod'), (',', ','), ('C.', 'C.'), ('(', '('), ('1985', '1985'), (',', ','), ('November', 'November'), (')', ')'), ('.', '.')]


------------------- Sentence 2 -------------------

A

>> Tokens are: 
 ['A']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('A', 'DT')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('A', 'a')]

>> Stemming using Snowball Stemmer: 
 [('A', 'a')]

>> Lemmatization: 
 [('A', 'A')]



========================================== PARAGRAPH 782 ===========================================

database of computer-structured narrative: methods of computing complex relations.  

------------------- Sentence 1 -------------------

database of computer-structured narrative: methods of computing complex relations.

>> Tokens are: 
 ['database', 'computer-structured', 'narrative', ':', 'methods', 'computing', 'complex', 'relations', '.']

>> Bigrams are: 
 [('database', 'computer-structured'), ('computer-structured', 'narrative'), ('narrative', ':'), (':', 'methods'), ('methods', 'computing'), ('computing', 'complex'), ('complex', 'relations'), ('relations', '.')]

>> Trigrams are: 
 [('database', 'computer-structured', 'narrative'), ('computer-structured', 'narrative', ':'), ('narrative', ':', 'methods'), (':', 'methods', 'computing'), ('methods', 'computing', 'complex'), ('computing', 'complex', 'relations'), ('complex', 'relations', '.')]

>> POS Tags are: 
 [('database', 'NN'), ('computer-structured', 'JJ'), ('narrative', 'JJ'), (':', ':'), ('methods', 'NNS'), ('computing', 'VBG'), ('complex', 'JJ'), ('relations', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['database', 'methods', 'complex relations']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('database', 'databas'), ('computer-structured', 'computer-structur'), ('narrative', 'narr'), (':', ':'), ('methods', 'method'), ('computing', 'comput'), ('complex', 'complex'), ('relations', 'relat'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('database', 'databas'), ('computer-structured', 'computer-structur'), ('narrative', 'narrat'), (':', ':'), ('methods', 'method'), ('computing', 'comput'), ('complex', 'complex'), ('relations', 'relat'), ('.', '.')]

>> Lemmatization: 
 [('database', 'database'), ('computer-structured', 'computer-structured'), ('narrative', 'narrative'), (':', ':'), ('methods', 'method'), ('computing', 'computing'), ('complex', 'complex'), ('relations', 'relation'), ('.', '.')]



========================================== PARAGRAPH 783 ===========================================

In Proceedings of the Annual Symposium on Computer Application in Medical Care (p. 221).  

------------------- Sentence 1 -------------------

In Proceedings of the Annual Symposium on Computer Application in Medical Care (p. 221).

>> Tokens are: 
 ['In', 'Proceedings', 'Annual', 'Symposium', 'Computer', 'Application', 'Medical', 'Care', '(', 'p.', '221', ')', '.']

>> Bigrams are: 
 [('In', 'Proceedings'), ('Proceedings', 'Annual'), ('Annual', 'Symposium'), ('Symposium', 'Computer'), ('Computer', 'Application'), ('Application', 'Medical'), ('Medical', 'Care'), ('Care', '('), ('(', 'p.'), ('p.', '221'), ('221', ')'), (')', '.')]

>> Trigrams are: 
 [('In', 'Proceedings', 'Annual'), ('Proceedings', 'Annual', 'Symposium'), ('Annual', 'Symposium', 'Computer'), ('Symposium', 'Computer', 'Application'), ('Computer', 'Application', 'Medical'), ('Application', 'Medical', 'Care'), ('Medical', 'Care', '('), ('Care', '(', 'p.'), ('(', 'p.', '221'), ('p.', '221', ')'), ('221', ')', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('Proceedings', 'NNP'), ('Annual', 'NNP'), ('Symposium', 'NNP'), ('Computer', 'NNP'), ('Application', 'NNP'), ('Medical', 'NNP'), ('Care', 'NNP'), ('(', '('), ('p.', 'VB'), ('221', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['Proceedings Annual Symposium Computer Application Medical Care']

>> Named Entities are: 
 [('GPE', 'Proceedings'), ('PERSON', 'Annual Symposium Computer')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('Proceedings', 'proceed'), ('Annual', 'annual'), ('Symposium', 'symposium'), ('Computer', 'comput'), ('Application', 'applic'), ('Medical', 'medic'), ('Care', 'care'), ('(', '('), ('p.', 'p.'), ('221', '221'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('Proceedings', 'proceed'), ('Annual', 'annual'), ('Symposium', 'symposium'), ('Computer', 'comput'), ('Application', 'applic'), ('Medical', 'medic'), ('Care', 'care'), ('(', '('), ('p.', 'p.'), ('221', '221'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('Proceedings', 'Proceedings'), ('Annual', 'Annual'), ('Symposium', 'Symposium'), ('Computer', 'Computer'), ('Application', 'Application'), ('Medical', 'Medical'), ('Care', 'Care'), ('(', '('), ('p.', 'p.'), ('221', '221'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 784 ===========================================

American Medical Informatics Association.  

------------------- Sentence 1 -------------------

American Medical Informatics Association.

>> Tokens are: 
 ['American', 'Medical', 'Informatics', 'Association', '.']

>> Bigrams are: 
 [('American', 'Medical'), ('Medical', 'Informatics'), ('Informatics', 'Association'), ('Association', '.')]

>> Trigrams are: 
 [('American', 'Medical', 'Informatics'), ('Medical', 'Informatics', 'Association'), ('Informatics', 'Association', '.')]

>> POS Tags are: 
 [('American', 'NNP'), ('Medical', 'NNP'), ('Informatics', 'NNP'), ('Association', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['American Medical Informatics Association']

>> Named Entities are: 
 [('GPE', 'American'), ('ORGANIZATION', 'Medical Informatics Association')] 

>> Stemming using Porter Stemmer: 
 [('American', 'american'), ('Medical', 'medic'), ('Informatics', 'informat'), ('Association', 'associ'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('American', 'american'), ('Medical', 'medic'), ('Informatics', 'informat'), ('Association', 'associ'), ('.', '.')]

>> Lemmatization: 
 [('American', 'American'), ('Medical', 'Medical'), ('Informatics', 'Informatics'), ('Association', 'Association'), ('.', '.')]



========================================== PARAGRAPH 785 ===========================================

[75] Grishman, R., Sager, N., Raze, C., & Bookchin, B. (1973, June). The linguistic string  

------------------- Sentence 1 -------------------

[75] Grishman, R., Sager, N., Raze, C., & Bookchin, B.

>> Tokens are: 
 ['[', '75', ']', 'Grishman', ',', 'R.', ',', 'Sager', ',', 'N.', ',', 'Raze', ',', 'C.', ',', '&', 'Bookchin', ',', 'B', '.']

>> Bigrams are: 
 [('[', '75'), ('75', ']'), (']', 'Grishman'), ('Grishman', ','), (',', 'R.'), ('R.', ','), (',', 'Sager'), ('Sager', ','), (',', 'N.'), ('N.', ','), (',', 'Raze'), ('Raze', ','), (',', 'C.'), ('C.', ','), (',', '&'), ('&', 'Bookchin'), ('Bookchin', ','), (',', 'B'), ('B', '.')]

>> Trigrams are: 
 [('[', '75', ']'), ('75', ']', 'Grishman'), (']', 'Grishman', ','), ('Grishman', ',', 'R.'), (',', 'R.', ','), ('R.', ',', 'Sager'), (',', 'Sager', ','), ('Sager', ',', 'N.'), (',', 'N.', ','), ('N.', ',', 'Raze'), (',', 'Raze', ','), ('Raze', ',', 'C.'), (',', 'C.', ','), ('C.', ',', '&'), (',', '&', 'Bookchin'), ('&', 'Bookchin', ','), ('Bookchin', ',', 'B'), (',', 'B', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('75', 'CD'), (']', 'JJ'), ('Grishman', 'NNP'), (',', ','), ('R.', 'NNP'), (',', ','), ('Sager', 'NNP'), (',', ','), ('N.', 'NNP'), (',', ','), ('Raze', 'NNP'), (',', ','), ('C.', 'NNP'), (',', ','), ('&', 'CC'), ('Bookchin', 'NNP'), (',', ','), ('B', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['] Grishman', 'R.', 'Sager', 'N.', 'Raze', 'C.', 'Bookchin', 'B']

>> Named Entities are: 
 [('PERSON', 'Sager'), ('PERSON', 'Raze'), ('PERSON', 'Bookchin')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('75', '75'), (']', ']'), ('Grishman', 'grishman'), (',', ','), ('R.', 'r.'), (',', ','), ('Sager', 'sager'), (',', ','), ('N.', 'n.'), (',', ','), ('Raze', 'raze'), (',', ','), ('C.', 'c.'), (',', ','), ('&', '&'), ('Bookchin', 'bookchin'), (',', ','), ('B', 'b'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('75', '75'), (']', ']'), ('Grishman', 'grishman'), (',', ','), ('R.', 'r.'), (',', ','), ('Sager', 'sager'), (',', ','), ('N.', 'n.'), (',', ','), ('Raze', 'raze'), (',', ','), ('C.', 'c.'), (',', ','), ('&', '&'), ('Bookchin', 'bookchin'), (',', ','), ('B', 'b'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('75', '75'), (']', ']'), ('Grishman', 'Grishman'), (',', ','), ('R.', 'R.'), (',', ','), ('Sager', 'Sager'), (',', ','), ('N.', 'N.'), (',', ','), ('Raze', 'Raze'), (',', ','), ('C.', 'C.'), (',', ','), ('&', '&'), ('Bookchin', 'Bookchin'), (',', ','), ('B', 'B'), ('.', '.')]


------------------- Sentence 2 -------------------

(1973, June).

>> Tokens are: 
 ['(', '1973', ',', 'June', ')', '.']

>> Bigrams are: 
 [('(', '1973'), ('1973', ','), (',', 'June'), ('June', ')'), (')', '.')]

>> Trigrams are: 
 [('(', '1973', ','), ('1973', ',', 'June'), (',', 'June', ')'), ('June', ')', '.')]

>> POS Tags are: 
 [('(', '('), ('1973', 'CD'), (',', ','), ('June', 'NNP'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['June']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('1973', '1973'), (',', ','), ('June', 'june'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('1973', '1973'), (',', ','), ('June', 'june'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('(', '('), ('1973', '1973'), (',', ','), ('June', 'June'), (')', ')'), ('.', '.')]


------------------- Sentence 3 -------------------

The linguistic string

>> Tokens are: 
 ['The', 'linguistic', 'string']

>> Bigrams are: 
 [('The', 'linguistic'), ('linguistic', 'string')]

>> Trigrams are: 
 [('The', 'linguistic', 'string')]

>> POS Tags are: 
 [('The', 'DT'), ('linguistic', 'JJ'), ('string', 'NN')]

>> Noun Phrases are: 
 ['The linguistic string']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('linguistic', 'linguist'), ('string', 'string')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('linguistic', 'linguist'), ('string', 'string')]

>> Lemmatization: 
 [('The', 'The'), ('linguistic', 'linguistic'), ('string', 'string')]



========================================== PARAGRAPH 786 ===========================================

parser. In Proceedings of the June 4-8, 1973, national computer conference and  

------------------- Sentence 1 -------------------

parser.

>> Tokens are: 
 ['parser', '.']

>> Bigrams are: 
 [('parser', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('parser', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['parser']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('parser', 'parser'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('parser', 'parser'), ('.', '.')]

>> Lemmatization: 
 [('parser', 'parser'), ('.', '.')]


------------------- Sentence 2 -------------------

In Proceedings of the June 4-8, 1973, national computer conference and

>> Tokens are: 
 ['In', 'Proceedings', 'June', '4-8', ',', '1973', ',', 'national', 'computer', 'conference']

>> Bigrams are: 
 [('In', 'Proceedings'), ('Proceedings', 'June'), ('June', '4-8'), ('4-8', ','), (',', '1973'), ('1973', ','), (',', 'national'), ('national', 'computer'), ('computer', 'conference')]

>> Trigrams are: 
 [('In', 'Proceedings', 'June'), ('Proceedings', 'June', '4-8'), ('June', '4-8', ','), ('4-8', ',', '1973'), (',', '1973', ','), ('1973', ',', 'national'), (',', 'national', 'computer'), ('national', 'computer', 'conference')]

>> POS Tags are: 
 [('In', 'IN'), ('Proceedings', 'NNP'), ('June', 'NNP'), ('4-8', 'CD'), (',', ','), ('1973', 'CD'), (',', ','), ('national', 'JJ'), ('computer', 'NN'), ('conference', 'NN')]

>> Noun Phrases are: 
 ['Proceedings June', 'national computer conference']

>> Named Entities are: 
 [('GPE', 'Proceedings')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('Proceedings', 'proceed'), ('June', 'june'), ('4-8', '4-8'), (',', ','), ('1973', '1973'), (',', ','), ('national', 'nation'), ('computer', 'comput'), ('conference', 'confer')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('Proceedings', 'proceed'), ('June', 'june'), ('4-8', '4-8'), (',', ','), ('1973', '1973'), (',', ','), ('national', 'nation'), ('computer', 'comput'), ('conference', 'confer')]

>> Lemmatization: 
 [('In', 'In'), ('Proceedings', 'Proceedings'), ('June', 'June'), ('4-8', '4-8'), (',', ','), ('1973', '1973'), (',', ','), ('national', 'national'), ('computer', 'computer'), ('conference', 'conference')]



========================================== PARAGRAPH 787 ===========================================

exposition (pp. 427-434). ACM.  

------------------- Sentence 1 -------------------

exposition (pp.

>> Tokens are: 
 ['exposition', '(', 'pp', '.']

>> Bigrams are: 
 [('exposition', '('), ('(', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('exposition', '(', 'pp'), ('(', 'pp', '.')]

>> POS Tags are: 
 [('exposition', 'NN'), ('(', '('), ('pp', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['exposition', 'pp']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('exposition', 'exposit'), ('(', '('), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('exposition', 'exposit'), ('(', '('), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('exposition', 'exposition'), ('(', '('), ('pp', 'pp'), ('.', '.')]


------------------- Sentence 2 -------------------

427-434).

>> Tokens are: 
 ['427-434', ')', '.']

>> Bigrams are: 
 [('427-434', ')'), (')', '.')]

>> Trigrams are: 
 [('427-434', ')', '.')]

>> POS Tags are: 
 [('427-434', 'JJ'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('427-434', '427-434'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('427-434', '427-434'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('427-434', '427-434'), (')', ')'), ('.', '.')]


------------------- Sentence 3 -------------------

ACM.

>> Tokens are: 
 ['ACM', '.']

>> Bigrams are: 
 [('ACM', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('ACM', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['ACM']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('ACM', 'acm'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('ACM', 'acm'), ('.', '.')]

>> Lemmatization: 
 [('ACM', 'ACM'), ('.', '.')]



========================================== PARAGRAPH 788 ===========================================

[76] Hirschman, L., Grishman, R., & Sager, N. (1976, June). From text to structured  

------------------- Sentence 1 -------------------

[76] Hirschman, L., Grishman, R., & Sager, N. (1976, June).

>> Tokens are: 
 ['[', '76', ']', 'Hirschman', ',', 'L.', ',', 'Grishman', ',', 'R.', ',', '&', 'Sager', ',', 'N.', '(', '1976', ',', 'June', ')', '.']

>> Bigrams are: 
 [('[', '76'), ('76', ']'), (']', 'Hirschman'), ('Hirschman', ','), (',', 'L.'), ('L.', ','), (',', 'Grishman'), ('Grishman', ','), (',', 'R.'), ('R.', ','), (',', '&'), ('&', 'Sager'), ('Sager', ','), (',', 'N.'), ('N.', '('), ('(', '1976'), ('1976', ','), (',', 'June'), ('June', ')'), (')', '.')]

>> Trigrams are: 
 [('[', '76', ']'), ('76', ']', 'Hirschman'), (']', 'Hirschman', ','), ('Hirschman', ',', 'L.'), (',', 'L.', ','), ('L.', ',', 'Grishman'), (',', 'Grishman', ','), ('Grishman', ',', 'R.'), (',', 'R.', ','), ('R.', ',', '&'), (',', '&', 'Sager'), ('&', 'Sager', ','), ('Sager', ',', 'N.'), (',', 'N.', '('), ('N.', '(', '1976'), ('(', '1976', ','), ('1976', ',', 'June'), (',', 'June', ')'), ('June', ')', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('76', 'CD'), (']', 'JJ'), ('Hirschman', 'NNP'), (',', ','), ('L.', 'NNP'), (',', ','), ('Grishman', 'NNP'), (',', ','), ('R.', 'NNP'), (',', ','), ('&', 'CC'), ('Sager', 'NNP'), (',', ','), ('N.', 'NNP'), ('(', '('), ('1976', 'CD'), (',', ','), ('June', 'NNP'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['] Hirschman', 'L.', 'Grishman', 'R.', 'Sager', 'N.', 'June']

>> Named Entities are: 
 [('PERSON', 'Grishman'), ('PERSON', 'Sager')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('76', '76'), (']', ']'), ('Hirschman', 'hirschman'), (',', ','), ('L.', 'l.'), (',', ','), ('Grishman', 'grishman'), (',', ','), ('R.', 'r.'), (',', ','), ('&', '&'), ('Sager', 'sager'), (',', ','), ('N.', 'n.'), ('(', '('), ('1976', '1976'), (',', ','), ('June', 'june'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('76', '76'), (']', ']'), ('Hirschman', 'hirschman'), (',', ','), ('L.', 'l.'), (',', ','), ('Grishman', 'grishman'), (',', ','), ('R.', 'r.'), (',', ','), ('&', '&'), ('Sager', 'sager'), (',', ','), ('N.', 'n.'), ('(', '('), ('1976', '1976'), (',', ','), ('June', 'june'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('76', '76'), (']', ']'), ('Hirschman', 'Hirschman'), (',', ','), ('L.', 'L.'), (',', ','), ('Grishman', 'Grishman'), (',', ','), ('R.', 'R.'), (',', ','), ('&', '&'), ('Sager', 'Sager'), (',', ','), ('N.', 'N.'), ('(', '('), ('1976', '1976'), (',', ','), ('June', 'June'), (')', ')'), ('.', '.')]


------------------- Sentence 2 -------------------

From text to structured

>> Tokens are: 
 ['From', 'text', 'structured']

>> Bigrams are: 
 [('From', 'text'), ('text', 'structured')]

>> Trigrams are: 
 [('From', 'text', 'structured')]

>> POS Tags are: 
 [('From', 'IN'), ('text', 'NN'), ('structured', 'VBN')]

>> Noun Phrases are: 
 ['text']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('From', 'from'), ('text', 'text'), ('structured', 'structur')]

>> Stemming using Snowball Stemmer: 
 [('From', 'from'), ('text', 'text'), ('structured', 'structur')]

>> Lemmatization: 
 [('From', 'From'), ('text', 'text'), ('structured', 'structured')]



========================================== PARAGRAPH 789 ===========================================

information: automatic processing of medical reports. In Proceedings of the June 7-10, 1976,  

------------------- Sentence 1 -------------------

information: automatic processing of medical reports.

>> Tokens are: 
 ['information', ':', 'automatic', 'processing', 'medical', 'reports', '.']

>> Bigrams are: 
 [('information', ':'), (':', 'automatic'), ('automatic', 'processing'), ('processing', 'medical'), ('medical', 'reports'), ('reports', '.')]

>> Trigrams are: 
 [('information', ':', 'automatic'), (':', 'automatic', 'processing'), ('automatic', 'processing', 'medical'), ('processing', 'medical', 'reports'), ('medical', 'reports', '.')]

>> POS Tags are: 
 [('information', 'NN'), (':', ':'), ('automatic', 'JJ'), ('processing', 'NN'), ('medical', 'JJ'), ('reports', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['information', 'automatic processing', 'medical reports']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('information', 'inform'), (':', ':'), ('automatic', 'automat'), ('processing', 'process'), ('medical', 'medic'), ('reports', 'report'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('information', 'inform'), (':', ':'), ('automatic', 'automat'), ('processing', 'process'), ('medical', 'medic'), ('reports', 'report'), ('.', '.')]

>> Lemmatization: 
 [('information', 'information'), (':', ':'), ('automatic', 'automatic'), ('processing', 'processing'), ('medical', 'medical'), ('reports', 'report'), ('.', '.')]


------------------- Sentence 2 -------------------

In Proceedings of the June 7-10, 1976,

>> Tokens are: 
 ['In', 'Proceedings', 'June', '7-10', ',', '1976', ',']

>> Bigrams are: 
 [('In', 'Proceedings'), ('Proceedings', 'June'), ('June', '7-10'), ('7-10', ','), (',', '1976'), ('1976', ',')]

>> Trigrams are: 
 [('In', 'Proceedings', 'June'), ('Proceedings', 'June', '7-10'), ('June', '7-10', ','), ('7-10', ',', '1976'), (',', '1976', ',')]

>> POS Tags are: 
 [('In', 'IN'), ('Proceedings', 'NNP'), ('June', 'NNP'), ('7-10', 'CD'), (',', ','), ('1976', 'CD'), (',', ',')]

>> Noun Phrases are: 
 ['Proceedings June']

>> Named Entities are: 
 [('GPE', 'Proceedings')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('Proceedings', 'proceed'), ('June', 'june'), ('7-10', '7-10'), (',', ','), ('1976', '1976'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('Proceedings', 'proceed'), ('June', 'june'), ('7-10', '7-10'), (',', ','), ('1976', '1976'), (',', ',')]

>> Lemmatization: 
 [('In', 'In'), ('Proceedings', 'Proceedings'), ('June', 'June'), ('7-10', '7-10'), (',', ','), ('1976', '1976'), (',', ',')]



========================================== PARAGRAPH 790 ===========================================

national computer conference and exposition (pp. 267-275). ACM.  

------------------- Sentence 1 -------------------

national computer conference and exposition (pp.

>> Tokens are: 
 ['national', 'computer', 'conference', 'exposition', '(', 'pp', '.']

>> Bigrams are: 
 [('national', 'computer'), ('computer', 'conference'), ('conference', 'exposition'), ('exposition', '('), ('(', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('national', 'computer', 'conference'), ('computer', 'conference', 'exposition'), ('conference', 'exposition', '('), ('exposition', '(', 'pp'), ('(', 'pp', '.')]

>> POS Tags are: 
 [('national', 'JJ'), ('computer', 'NN'), ('conference', 'NN'), ('exposition', 'NN'), ('(', '('), ('pp', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['national computer conference exposition', 'pp']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('national', 'nation'), ('computer', 'comput'), ('conference', 'confer'), ('exposition', 'exposit'), ('(', '('), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('national', 'nation'), ('computer', 'comput'), ('conference', 'confer'), ('exposition', 'exposit'), ('(', '('), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('national', 'national'), ('computer', 'computer'), ('conference', 'conference'), ('exposition', 'exposition'), ('(', '('), ('pp', 'pp'), ('.', '.')]


------------------- Sentence 2 -------------------

267-275).

>> Tokens are: 
 ['267-275', ')', '.']

>> Bigrams are: 
 [('267-275', ')'), (')', '.')]

>> Trigrams are: 
 [('267-275', ')', '.')]

>> POS Tags are: 
 [('267-275', 'JJ'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('267-275', '267-275'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('267-275', '267-275'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('267-275', '267-275'), (')', ')'), ('.', '.')]


------------------- Sentence 3 -------------------

ACM.

>> Tokens are: 
 ['ACM', '.']

>> Bigrams are: 
 [('ACM', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('ACM', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['ACM']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('ACM', 'acm'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('ACM', 'acm'), ('.', '.')]

>> Lemmatization: 
 [('ACM', 'ACM'), ('.', '.')]



========================================== PARAGRAPH 791 ===========================================

[77] Sager, N. (1981). Natural language information processing. Addison-Wesley Publishing  

------------------- Sentence 1 -------------------

[77] Sager, N. (1981).

>> Tokens are: 
 ['[', '77', ']', 'Sager', ',', 'N.', '(', '1981', ')', '.']

>> Bigrams are: 
 [('[', '77'), ('77', ']'), (']', 'Sager'), ('Sager', ','), (',', 'N.'), ('N.', '('), ('(', '1981'), ('1981', ')'), (')', '.')]

>> Trigrams are: 
 [('[', '77', ']'), ('77', ']', 'Sager'), (']', 'Sager', ','), ('Sager', ',', 'N.'), (',', 'N.', '('), ('N.', '(', '1981'), ('(', '1981', ')'), ('1981', ')', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('77', 'CD'), (']', 'JJ'), ('Sager', 'NNP'), (',', ','), ('N.', 'NNP'), ('(', '('), ('1981', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['] Sager', 'N.']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('77', '77'), (']', ']'), ('Sager', 'sager'), (',', ','), ('N.', 'n.'), ('(', '('), ('1981', '1981'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('77', '77'), (']', ']'), ('Sager', 'sager'), (',', ','), ('N.', 'n.'), ('(', '('), ('1981', '1981'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('77', '77'), (']', ']'), ('Sager', 'Sager'), (',', ','), ('N.', 'N.'), ('(', '('), ('1981', '1981'), (')', ')'), ('.', '.')]


------------------- Sentence 2 -------------------

Natural language information processing.

>> Tokens are: 
 ['Natural', 'language', 'information', 'processing', '.']

>> Bigrams are: 
 [('Natural', 'language'), ('language', 'information'), ('information', 'processing'), ('processing', '.')]

>> Trigrams are: 
 [('Natural', 'language', 'information'), ('language', 'information', 'processing'), ('information', 'processing', '.')]

>> POS Tags are: 
 [('Natural', 'JJ'), ('language', 'NN'), ('information', 'NN'), ('processing', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Natural language information processing']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Natural', 'natur'), ('language', 'languag'), ('information', 'inform'), ('processing', 'process'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Natural', 'natur'), ('language', 'languag'), ('information', 'inform'), ('processing', 'process'), ('.', '.')]

>> Lemmatization: 
 [('Natural', 'Natural'), ('language', 'language'), ('information', 'information'), ('processing', 'processing'), ('.', '.')]


------------------- Sentence 3 -------------------

Addison-Wesley Publishing

>> Tokens are: 
 ['Addison-Wesley', 'Publishing']

>> Bigrams are: 
 [('Addison-Wesley', 'Publishing')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Addison-Wesley', 'NNP'), ('Publishing', 'NN')]

>> Noun Phrases are: 
 ['Addison-Wesley Publishing']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Addison-Wesley', 'addison-wesley'), ('Publishing', 'publish')]

>> Stemming using Snowball Stemmer: 
 [('Addison-Wesley', 'addison-wesley'), ('Publishing', 'publish')]

>> Lemmatization: 
 [('Addison-Wesley', 'Addison-Wesley'), ('Publishing', 'Publishing')]



========================================== PARAGRAPH 792 ===========================================

Company, Advanced Book Program.  

------------------- Sentence 1 -------------------

Company, Advanced Book Program.

>> Tokens are: 
 ['Company', ',', 'Advanced', 'Book', 'Program', '.']

>> Bigrams are: 
 [('Company', ','), (',', 'Advanced'), ('Advanced', 'Book'), ('Book', 'Program'), ('Program', '.')]

>> Trigrams are: 
 [('Company', ',', 'Advanced'), (',', 'Advanced', 'Book'), ('Advanced', 'Book', 'Program'), ('Book', 'Program', '.')]

>> POS Tags are: 
 [('Company', 'NN'), (',', ','), ('Advanced', 'NNP'), ('Book', 'NNP'), ('Program', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Company', 'Advanced Book Program']

>> Named Entities are: 
 [('GPE', 'Company'), ('PERSON', 'Advanced Book Program')] 

>> Stemming using Porter Stemmer: 
 [('Company', 'compani'), (',', ','), ('Advanced', 'advanc'), ('Book', 'book'), ('Program', 'program'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Company', 'compani'), (',', ','), ('Advanced', 'advanc'), ('Book', 'book'), ('Program', 'program'), ('.', '.')]

>> Lemmatization: 
 [('Company', 'Company'), (',', ','), ('Advanced', 'Advanced'), ('Book', 'Book'), ('Program', 'Program'), ('.', '.')]



========================================== PARAGRAPH 793 ===========================================

[78] Lyman, M., Sager, N., Friedman, C., & Chi, E. (1985, November). Computer-structured  

------------------- Sentence 1 -------------------

[78] Lyman, M., Sager, N., Friedman, C., & Chi, E. (1985, November).

>> Tokens are: 
 ['[', '78', ']', 'Lyman', ',', 'M.', ',', 'Sager', ',', 'N.', ',', 'Friedman', ',', 'C.', ',', '&', 'Chi', ',', 'E.', '(', '1985', ',', 'November', ')', '.']

>> Bigrams are: 
 [('[', '78'), ('78', ']'), (']', 'Lyman'), ('Lyman', ','), (',', 'M.'), ('M.', ','), (',', 'Sager'), ('Sager', ','), (',', 'N.'), ('N.', ','), (',', 'Friedman'), ('Friedman', ','), (',', 'C.'), ('C.', ','), (',', '&'), ('&', 'Chi'), ('Chi', ','), (',', 'E.'), ('E.', '('), ('(', '1985'), ('1985', ','), (',', 'November'), ('November', ')'), (')', '.')]

>> Trigrams are: 
 [('[', '78', ']'), ('78', ']', 'Lyman'), (']', 'Lyman', ','), ('Lyman', ',', 'M.'), (',', 'M.', ','), ('M.', ',', 'Sager'), (',', 'Sager', ','), ('Sager', ',', 'N.'), (',', 'N.', ','), ('N.', ',', 'Friedman'), (',', 'Friedman', ','), ('Friedman', ',', 'C.'), (',', 'C.', ','), ('C.', ',', '&'), (',', '&', 'Chi'), ('&', 'Chi', ','), ('Chi', ',', 'E.'), (',', 'E.', '('), ('E.', '(', '1985'), ('(', '1985', ','), ('1985', ',', 'November'), (',', 'November', ')'), ('November', ')', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('78', 'CD'), (']', 'JJ'), ('Lyman', 'NNP'), (',', ','), ('M.', 'NNP'), (',', ','), ('Sager', 'NNP'), (',', ','), ('N.', 'NNP'), (',', ','), ('Friedman', 'NNP'), (',', ','), ('C.', 'NNP'), (',', ','), ('&', 'CC'), ('Chi', 'NNP'), (',', ','), ('E.', 'NNP'), ('(', '('), ('1985', 'CD'), (',', ','), ('November', 'NNP'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['] Lyman', 'M.', 'Sager', 'N.', 'Friedman', 'C.', 'Chi', 'E.', 'November']

>> Named Entities are: 
 [('PERSON', 'Lyman'), ('PERSON', 'Sager'), ('PERSON', 'Friedman'), ('GPE', 'Chi')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('78', '78'), (']', ']'), ('Lyman', 'lyman'), (',', ','), ('M.', 'm.'), (',', ','), ('Sager', 'sager'), (',', ','), ('N.', 'n.'), (',', ','), ('Friedman', 'friedman'), (',', ','), ('C.', 'c.'), (',', ','), ('&', '&'), ('Chi', 'chi'), (',', ','), ('E.', 'e.'), ('(', '('), ('1985', '1985'), (',', ','), ('November', 'novemb'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('78', '78'), (']', ']'), ('Lyman', 'lyman'), (',', ','), ('M.', 'm.'), (',', ','), ('Sager', 'sager'), (',', ','), ('N.', 'n.'), (',', ','), ('Friedman', 'friedman'), (',', ','), ('C.', 'c.'), (',', ','), ('&', '&'), ('Chi', 'chi'), (',', ','), ('E.', 'e.'), ('(', '('), ('1985', '1985'), (',', ','), ('November', 'novemb'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('78', '78'), (']', ']'), ('Lyman', 'Lyman'), (',', ','), ('M.', 'M.'), (',', ','), ('Sager', 'Sager'), (',', ','), ('N.', 'N.'), (',', ','), ('Friedman', 'Friedman'), (',', ','), ('C.', 'C.'), (',', ','), ('&', '&'), ('Chi', 'Chi'), (',', ','), ('E.', 'E.'), ('(', '('), ('1985', '1985'), (',', ','), ('November', 'November'), (')', ')'), ('.', '.')]


------------------- Sentence 2 -------------------

Computer-structured

>> Tokens are: 
 ['Computer-structured']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Computer-structured', 'JJ')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Computer-structured', 'computer-structur')]

>> Stemming using Snowball Stemmer: 
 [('Computer-structured', 'computer-structur')]

>> Lemmatization: 
 [('Computer-structured', 'Computer-structured')]



========================================== PARAGRAPH 794 ===========================================

narrative in ambulatory care: its use in longitudinal review of clinical data. In Proceedings of  

------------------- Sentence 1 -------------------

narrative in ambulatory care: its use in longitudinal review of clinical data.

>> Tokens are: 
 ['narrative', 'ambulatory', 'care', ':', 'use', 'longitudinal', 'review', 'clinical', 'data', '.']

>> Bigrams are: 
 [('narrative', 'ambulatory'), ('ambulatory', 'care'), ('care', ':'), (':', 'use'), ('use', 'longitudinal'), ('longitudinal', 'review'), ('review', 'clinical'), ('clinical', 'data'), ('data', '.')]

>> Trigrams are: 
 [('narrative', 'ambulatory', 'care'), ('ambulatory', 'care', ':'), ('care', ':', 'use'), (':', 'use', 'longitudinal'), ('use', 'longitudinal', 'review'), ('longitudinal', 'review', 'clinical'), ('review', 'clinical', 'data'), ('clinical', 'data', '.')]

>> POS Tags are: 
 [('narrative', 'JJ'), ('ambulatory', 'NN'), ('care', 'NN'), (':', ':'), ('use', 'NN'), ('longitudinal', 'JJ'), ('review', 'NN'), ('clinical', 'JJ'), ('data', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['narrative ambulatory care', 'use', 'longitudinal review', 'clinical data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('narrative', 'narr'), ('ambulatory', 'ambulatori'), ('care', 'care'), (':', ':'), ('use', 'use'), ('longitudinal', 'longitudin'), ('review', 'review'), ('clinical', 'clinic'), ('data', 'data'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('narrative', 'narrat'), ('ambulatory', 'ambulatori'), ('care', 'care'), (':', ':'), ('use', 'use'), ('longitudinal', 'longitudin'), ('review', 'review'), ('clinical', 'clinic'), ('data', 'data'), ('.', '.')]

>> Lemmatization: 
 [('narrative', 'narrative'), ('ambulatory', 'ambulatory'), ('care', 'care'), (':', ':'), ('use', 'use'), ('longitudinal', 'longitudinal'), ('review', 'review'), ('clinical', 'clinical'), ('data', 'data'), ('.', '.')]


------------------- Sentence 2 -------------------

In Proceedings of

>> Tokens are: 
 ['In', 'Proceedings']

>> Bigrams are: 
 [('In', 'Proceedings')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('In', 'IN'), ('Proceedings', 'NNS')]

>> Noun Phrases are: 
 ['Proceedings']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('Proceedings', 'proceed')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('Proceedings', 'proceed')]

>> Lemmatization: 
 [('In', 'In'), ('Proceedings', 'Proceedings')]



========================================== PARAGRAPH 795 ===========================================

the Annual Symposium on Computer Application in Medical Care (p. 82). American Medical  

------------------- Sentence 1 -------------------

the Annual Symposium on Computer Application in Medical Care (p. 82).

>> Tokens are: 
 ['Annual', 'Symposium', 'Computer', 'Application', 'Medical', 'Care', '(', 'p.', '82', ')', '.']

>> Bigrams are: 
 [('Annual', 'Symposium'), ('Symposium', 'Computer'), ('Computer', 'Application'), ('Application', 'Medical'), ('Medical', 'Care'), ('Care', '('), ('(', 'p.'), ('p.', '82'), ('82', ')'), (')', '.')]

>> Trigrams are: 
 [('Annual', 'Symposium', 'Computer'), ('Symposium', 'Computer', 'Application'), ('Computer', 'Application', 'Medical'), ('Application', 'Medical', 'Care'), ('Medical', 'Care', '('), ('Care', '(', 'p.'), ('(', 'p.', '82'), ('p.', '82', ')'), ('82', ')', '.')]

>> POS Tags are: 
 [('Annual', 'JJ'), ('Symposium', 'NNP'), ('Computer', 'NNP'), ('Application', 'NNP'), ('Medical', 'NNP'), ('Care', 'NNP'), ('(', '('), ('p.', 'VB'), ('82', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['Annual Symposium Computer Application Medical Care']

>> Named Entities are: 
 [('PERSON', 'Annual'), ('ORGANIZATION', 'Symposium Computer Application Medical Care')] 

>> Stemming using Porter Stemmer: 
 [('Annual', 'annual'), ('Symposium', 'symposium'), ('Computer', 'comput'), ('Application', 'applic'), ('Medical', 'medic'), ('Care', 'care'), ('(', '('), ('p.', 'p.'), ('82', '82'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Annual', 'annual'), ('Symposium', 'symposium'), ('Computer', 'comput'), ('Application', 'applic'), ('Medical', 'medic'), ('Care', 'care'), ('(', '('), ('p.', 'p.'), ('82', '82'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Annual', 'Annual'), ('Symposium', 'Symposium'), ('Computer', 'Computer'), ('Application', 'Application'), ('Medical', 'Medical'), ('Care', 'Care'), ('(', '('), ('p.', 'p.'), ('82', '82'), (')', ')'), ('.', '.')]


------------------- Sentence 2 -------------------

American Medical

>> Tokens are: 
 ['American', 'Medical']

>> Bigrams are: 
 [('American', 'Medical')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('American', 'NNP'), ('Medical', 'NNP')]

>> Noun Phrases are: 
 ['American Medical']

>> Named Entities are: 
 [('GPE', 'American'), ('ORGANIZATION', 'Medical')] 

>> Stemming using Porter Stemmer: 
 [('American', 'american'), ('Medical', 'medic')]

>> Stemming using Snowball Stemmer: 
 [('American', 'american'), ('Medical', 'medic')]

>> Lemmatization: 
 [('American', 'American'), ('Medical', 'Medical')]



========================================== PARAGRAPH 796 ===========================================

Informatics Association.  

------------------- Sentence 1 -------------------

Informatics Association.

>> Tokens are: 
 ['Informatics', 'Association', '.']

>> Bigrams are: 
 [('Informatics', 'Association'), ('Association', '.')]

>> Trigrams are: 
 [('Informatics', 'Association', '.')]

>> POS Tags are: 
 [('Informatics', 'NNS'), ('Association', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Informatics Association']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Informatics', 'informat'), ('Association', 'associ'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Informatics', 'informat'), ('Association', 'associ'), ('.', '.')]

>> Lemmatization: 
 [('Informatics', 'Informatics'), ('Association', 'Association'), ('.', '.')]



========================================== PARAGRAPH 797 ===========================================

[79] McCray, A. T., & Nelson, S. J. (1995). The representation of meaning in the  

------------------- Sentence 1 -------------------

[79] McCray, A. T., & Nelson, S. J.

>> Tokens are: 
 ['[', '79', ']', 'McCray', ',', 'A.', 'T.', ',', '&', 'Nelson', ',', 'S.', 'J', '.']

>> Bigrams are: 
 [('[', '79'), ('79', ']'), (']', 'McCray'), ('McCray', ','), (',', 'A.'), ('A.', 'T.'), ('T.', ','), (',', '&'), ('&', 'Nelson'), ('Nelson', ','), (',', 'S.'), ('S.', 'J'), ('J', '.')]

>> Trigrams are: 
 [('[', '79', ']'), ('79', ']', 'McCray'), (']', 'McCray', ','), ('McCray', ',', 'A.'), (',', 'A.', 'T.'), ('A.', 'T.', ','), ('T.', ',', '&'), (',', '&', 'Nelson'), ('&', 'Nelson', ','), ('Nelson', ',', 'S.'), (',', 'S.', 'J'), ('S.', 'J', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('79', 'CD'), (']', 'JJ'), ('McCray', 'NNP'), (',', ','), ('A.', 'NNP'), ('T.', 'NNP'), (',', ','), ('&', 'CC'), ('Nelson', 'NNP'), (',', ','), ('S.', 'NNP'), ('J', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['] McCray', 'A. T.', 'Nelson', 'S. J']

>> Named Entities are: 
 [('ORGANIZATION', 'McCray'), ('PERSON', 'Nelson')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('79', '79'), (']', ']'), ('McCray', 'mccray'), (',', ','), ('A.', 'a.'), ('T.', 't.'), (',', ','), ('&', '&'), ('Nelson', 'nelson'), (',', ','), ('S.', 's.'), ('J', 'j'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('79', '79'), (']', ']'), ('McCray', 'mccray'), (',', ','), ('A.', 'a.'), ('T.', 't.'), (',', ','), ('&', '&'), ('Nelson', 'nelson'), (',', ','), ('S.', 's.'), ('J', 'j'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('79', '79'), (']', ']'), ('McCray', 'McCray'), (',', ','), ('A.', 'A.'), ('T.', 'T.'), (',', ','), ('&', '&'), ('Nelson', 'Nelson'), (',', ','), ('S.', 'S.'), ('J', 'J'), ('.', '.')]


------------------- Sentence 2 -------------------

(1995).

>> Tokens are: 
 ['(', '1995', ')', '.']

>> Bigrams are: 
 [('(', '1995'), ('1995', ')'), (')', '.')]

>> Trigrams are: 
 [('(', '1995', ')'), ('1995', ')', '.')]

>> POS Tags are: 
 [('(', '('), ('1995', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('1995', '1995'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('1995', '1995'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('(', '('), ('1995', '1995'), (')', ')'), ('.', '.')]


------------------- Sentence 3 -------------------

The representation of meaning in the

>> Tokens are: 
 ['The', 'representation', 'meaning']

>> Bigrams are: 
 [('The', 'representation'), ('representation', 'meaning')]

>> Trigrams are: 
 [('The', 'representation', 'meaning')]

>> POS Tags are: 
 [('The', 'DT'), ('representation', 'NN'), ('meaning', 'NN')]

>> Noun Phrases are: 
 ['The representation meaning']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('representation', 'represent'), ('meaning', 'mean')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('representation', 'represent'), ('meaning', 'mean')]

>> Lemmatization: 
 [('The', 'The'), ('representation', 'representation'), ('meaning', 'meaning')]



========================================== PARAGRAPH 798 ===========================================

UMLS. Methods of information in medicine, 34(1-2), 193-201.  

------------------- Sentence 1 -------------------

UMLS.

>> Tokens are: 
 ['UMLS', '.']

>> Bigrams are: 
 [('UMLS', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('UMLS', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['UMLS']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('UMLS', 'uml'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('UMLS', 'uml'), ('.', '.')]

>> Lemmatization: 
 [('UMLS', 'UMLS'), ('.', '.')]


------------------- Sentence 2 -------------------

Methods of information in medicine, 34(1-2), 193-201.

>> Tokens are: 
 ['Methods', 'information', 'medicine', ',', '34', '(', '1-2', ')', ',', '193-201', '.']

>> Bigrams are: 
 [('Methods', 'information'), ('information', 'medicine'), ('medicine', ','), (',', '34'), ('34', '('), ('(', '1-2'), ('1-2', ')'), (')', ','), (',', '193-201'), ('193-201', '.')]

>> Trigrams are: 
 [('Methods', 'information', 'medicine'), ('information', 'medicine', ','), ('medicine', ',', '34'), (',', '34', '('), ('34', '(', '1-2'), ('(', '1-2', ')'), ('1-2', ')', ','), (')', ',', '193-201'), (',', '193-201', '.')]

>> POS Tags are: 
 [('Methods', 'NNS'), ('information', 'NN'), ('medicine', 'NN'), (',', ','), ('34', 'CD'), ('(', '('), ('1-2', 'JJ'), (')', ')'), (',', ','), ('193-201', 'JJ'), ('.', '.')]

>> Noun Phrases are: 
 ['Methods information medicine']

>> Named Entities are: 
 [('GPE', 'Methods')] 

>> Stemming using Porter Stemmer: 
 [('Methods', 'method'), ('information', 'inform'), ('medicine', 'medicin'), (',', ','), ('34', '34'), ('(', '('), ('1-2', '1-2'), (')', ')'), (',', ','), ('193-201', '193-201'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Methods', 'method'), ('information', 'inform'), ('medicine', 'medicin'), (',', ','), ('34', '34'), ('(', '('), ('1-2', '1-2'), (')', ')'), (',', ','), ('193-201', '193-201'), ('.', '.')]

>> Lemmatization: 
 [('Methods', 'Methods'), ('information', 'information'), ('medicine', 'medicine'), (',', ','), ('34', '34'), ('(', '('), ('1-2', '1-2'), (')', ')'), (',', ','), ('193-201', '193-201'), ('.', '.')]



========================================== PARAGRAPH 799 ===========================================

[80] McGray, A. T., Sponsler, J. L., Brylawski, B., & Browne, A. C. (1987, November). The  

------------------- Sentence 1 -------------------

[80] McGray, A. T., Sponsler, J. L., Brylawski, B., & Browne, A. C. (1987, November).

>> Tokens are: 
 ['[', '80', ']', 'McGray', ',', 'A.', 'T.', ',', 'Sponsler', ',', 'J.', 'L.', ',', 'Brylawski', ',', 'B.', ',', '&', 'Browne', ',', 'A.', 'C.', '(', '1987', ',', 'November', ')', '.']

>> Bigrams are: 
 [('[', '80'), ('80', ']'), (']', 'McGray'), ('McGray', ','), (',', 'A.'), ('A.', 'T.'), ('T.', ','), (',', 'Sponsler'), ('Sponsler', ','), (',', 'J.'), ('J.', 'L.'), ('L.', ','), (',', 'Brylawski'), ('Brylawski', ','), (',', 'B.'), ('B.', ','), (',', '&'), ('&', 'Browne'), ('Browne', ','), (',', 'A.'), ('A.', 'C.'), ('C.', '('), ('(', '1987'), ('1987', ','), (',', 'November'), ('November', ')'), (')', '.')]

>> Trigrams are: 
 [('[', '80', ']'), ('80', ']', 'McGray'), (']', 'McGray', ','), ('McGray', ',', 'A.'), (',', 'A.', 'T.'), ('A.', 'T.', ','), ('T.', ',', 'Sponsler'), (',', 'Sponsler', ','), ('Sponsler', ',', 'J.'), (',', 'J.', 'L.'), ('J.', 'L.', ','), ('L.', ',', 'Brylawski'), (',', 'Brylawski', ','), ('Brylawski', ',', 'B.'), (',', 'B.', ','), ('B.', ',', '&'), (',', '&', 'Browne'), ('&', 'Browne', ','), ('Browne', ',', 'A.'), (',', 'A.', 'C.'), ('A.', 'C.', '('), ('C.', '(', '1987'), ('(', '1987', ','), ('1987', ',', 'November'), (',', 'November', ')'), ('November', ')', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('80', 'CD'), (']', 'JJ'), ('McGray', 'NNP'), (',', ','), ('A.', 'NNP'), ('T.', 'NNP'), (',', ','), ('Sponsler', 'NNP'), (',', ','), ('J.', 'NNP'), ('L.', 'NNP'), (',', ','), ('Brylawski', 'NNP'), (',', ','), ('B.', 'NNP'), (',', ','), ('&', 'CC'), ('Browne', 'NNP'), (',', ','), ('A.', 'NNP'), ('C.', 'NNP'), ('(', '('), ('1987', 'CD'), (',', ','), ('November', 'NNP'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['] McGray', 'A. T.', 'Sponsler', 'J. L.', 'Brylawski', 'B.', 'Browne', 'A. C.', 'November']

>> Named Entities are: 
 [('ORGANIZATION', 'McGray'), ('PERSON', 'Sponsler'), ('PERSON', 'J. L.'), ('PERSON', 'Brylawski'), ('PERSON', 'Browne')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('80', '80'), (']', ']'), ('McGray', 'mcgray'), (',', ','), ('A.', 'a.'), ('T.', 't.'), (',', ','), ('Sponsler', 'sponsler'), (',', ','), ('J.', 'j.'), ('L.', 'l.'), (',', ','), ('Brylawski', 'brylawski'), (',', ','), ('B.', 'b.'), (',', ','), ('&', '&'), ('Browne', 'brown'), (',', ','), ('A.', 'a.'), ('C.', 'c.'), ('(', '('), ('1987', '1987'), (',', ','), ('November', 'novemb'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('80', '80'), (']', ']'), ('McGray', 'mcgray'), (',', ','), ('A.', 'a.'), ('T.', 't.'), (',', ','), ('Sponsler', 'sponsler'), (',', ','), ('J.', 'j.'), ('L.', 'l.'), (',', ','), ('Brylawski', 'brylawski'), (',', ','), ('B.', 'b.'), (',', ','), ('&', '&'), ('Browne', 'brown'), (',', ','), ('A.', 'a.'), ('C.', 'c.'), ('(', '('), ('1987', '1987'), (',', ','), ('November', 'novemb'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('80', '80'), (']', ']'), ('McGray', 'McGray'), (',', ','), ('A.', 'A.'), ('T.', 'T.'), (',', ','), ('Sponsler', 'Sponsler'), (',', ','), ('J.', 'J.'), ('L.', 'L.'), (',', ','), ('Brylawski', 'Brylawski'), (',', ','), ('B.', 'B.'), (',', ','), ('&', '&'), ('Browne', 'Browne'), (',', ','), ('A.', 'A.'), ('C.', 'C.'), ('(', '('), ('1987', '1987'), (',', ','), ('November', 'November'), (')', ')'), ('.', '.')]


------------------- Sentence 2 -------------------

The

>> Tokens are: 
 ['The']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('The', 'DT')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the')]

>> Lemmatization: 
 [('The', 'The')]



========================================== PARAGRAPH 800 ===========================================

role of lexical knowledge in biomedical text understanding. In Proceedings of the Annual  

------------------- Sentence 1 -------------------

role of lexical knowledge in biomedical text understanding.

>> Tokens are: 
 ['role', 'lexical', 'knowledge', 'biomedical', 'text', 'understanding', '.']

>> Bigrams are: 
 [('role', 'lexical'), ('lexical', 'knowledge'), ('knowledge', 'biomedical'), ('biomedical', 'text'), ('text', 'understanding'), ('understanding', '.')]

>> Trigrams are: 
 [('role', 'lexical', 'knowledge'), ('lexical', 'knowledge', 'biomedical'), ('knowledge', 'biomedical', 'text'), ('biomedical', 'text', 'understanding'), ('text', 'understanding', '.')]

>> POS Tags are: 
 [('role', 'NN'), ('lexical', 'JJ'), ('knowledge', 'NN'), ('biomedical', 'JJ'), ('text', 'NN'), ('understanding', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['role', 'lexical knowledge', 'biomedical text understanding']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('role', 'role'), ('lexical', 'lexic'), ('knowledge', 'knowledg'), ('biomedical', 'biomed'), ('text', 'text'), ('understanding', 'understand'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('role', 'role'), ('lexical', 'lexic'), ('knowledge', 'knowledg'), ('biomedical', 'biomed'), ('text', 'text'), ('understanding', 'understand'), ('.', '.')]

>> Lemmatization: 
 [('role', 'role'), ('lexical', 'lexical'), ('knowledge', 'knowledge'), ('biomedical', 'biomedical'), ('text', 'text'), ('understanding', 'understanding'), ('.', '.')]


------------------- Sentence 2 -------------------

In Proceedings of the Annual

>> Tokens are: 
 ['In', 'Proceedings', 'Annual']

>> Bigrams are: 
 [('In', 'Proceedings'), ('Proceedings', 'Annual')]

>> Trigrams are: 
 [('In', 'Proceedings', 'Annual')]

>> POS Tags are: 
 [('In', 'IN'), ('Proceedings', 'NNP'), ('Annual', 'NNP')]

>> Noun Phrases are: 
 ['Proceedings Annual']

>> Named Entities are: 
 [('GPE', 'Proceedings')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('Proceedings', 'proceed'), ('Annual', 'annual')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('Proceedings', 'proceed'), ('Annual', 'annual')]

>> Lemmatization: 
 [('In', 'In'), ('Proceedings', 'Proceedings'), ('Annual', 'Annual')]



========================================== PARAGRAPH 801 ===========================================

Symposium on Computer Application in Medical Care (p. 103). American Medical  

------------------- Sentence 1 -------------------

Symposium on Computer Application in Medical Care (p. 103).

>> Tokens are: 
 ['Symposium', 'Computer', 'Application', 'Medical', 'Care', '(', 'p.', '103', ')', '.']

>> Bigrams are: 
 [('Symposium', 'Computer'), ('Computer', 'Application'), ('Application', 'Medical'), ('Medical', 'Care'), ('Care', '('), ('(', 'p.'), ('p.', '103'), ('103', ')'), (')', '.')]

>> Trigrams are: 
 [('Symposium', 'Computer', 'Application'), ('Computer', 'Application', 'Medical'), ('Application', 'Medical', 'Care'), ('Medical', 'Care', '('), ('Care', '(', 'p.'), ('(', 'p.', '103'), ('p.', '103', ')'), ('103', ')', '.')]

>> POS Tags are: 
 [('Symposium', 'NNP'), ('Computer', 'NNP'), ('Application', 'NNP'), ('Medical', 'NNP'), ('Care', 'NNP'), ('(', '('), ('p.', 'VB'), ('103', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['Symposium Computer Application Medical Care']

>> Named Entities are: 
 [('PERSON', 'Symposium'), ('ORGANIZATION', 'Computer Application Medical Care')] 

>> Stemming using Porter Stemmer: 
 [('Symposium', 'symposium'), ('Computer', 'comput'), ('Application', 'applic'), ('Medical', 'medic'), ('Care', 'care'), ('(', '('), ('p.', 'p.'), ('103', '103'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Symposium', 'symposium'), ('Computer', 'comput'), ('Application', 'applic'), ('Medical', 'medic'), ('Care', 'care'), ('(', '('), ('p.', 'p.'), ('103', '103'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Symposium', 'Symposium'), ('Computer', 'Computer'), ('Application', 'Application'), ('Medical', 'Medical'), ('Care', 'Care'), ('(', '('), ('p.', 'p.'), ('103', '103'), (')', ')'), ('.', '.')]


------------------- Sentence 2 -------------------

American Medical

>> Tokens are: 
 ['American', 'Medical']

>> Bigrams are: 
 [('American', 'Medical')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('American', 'NNP'), ('Medical', 'NNP')]

>> Noun Phrases are: 
 ['American Medical']

>> Named Entities are: 
 [('GPE', 'American'), ('ORGANIZATION', 'Medical')] 

>> Stemming using Porter Stemmer: 
 [('American', 'american'), ('Medical', 'medic')]

>> Stemming using Snowball Stemmer: 
 [('American', 'american'), ('Medical', 'medic')]

>> Lemmatization: 
 [('American', 'American'), ('Medical', 'Medical')]



========================================== PARAGRAPH 802 ===========================================

Informatics Association. 

------------------- Sentence 1 -------------------

Informatics Association.

>> Tokens are: 
 ['Informatics', 'Association', '.']

>> Bigrams are: 
 [('Informatics', 'Association'), ('Association', '.')]

>> Trigrams are: 
 [('Informatics', 'Association', '.')]

>> POS Tags are: 
 [('Informatics', 'NNS'), ('Association', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Informatics Association']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Informatics', 'informat'), ('Association', 'associ'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Informatics', 'informat'), ('Association', 'associ'), ('.', '.')]

>> Lemmatization: 
 [('Informatics', 'Informatics'), ('Association', 'Association'), ('.', '.')]



========================================== PARAGRAPH 803 ===========================================

[81] McCray, A. T. (1991). Natural language processing for intelligent information retrieval.  

------------------- Sentence 1 -------------------

[81] McCray, A. T. (1991).

>> Tokens are: 
 ['[', '81', ']', 'McCray', ',', 'A.', 'T.', '(', '1991', ')', '.']

>> Bigrams are: 
 [('[', '81'), ('81', ']'), (']', 'McCray'), ('McCray', ','), (',', 'A.'), ('A.', 'T.'), ('T.', '('), ('(', '1991'), ('1991', ')'), (')', '.')]

>> Trigrams are: 
 [('[', '81', ']'), ('81', ']', 'McCray'), (']', 'McCray', ','), ('McCray', ',', 'A.'), (',', 'A.', 'T.'), ('A.', 'T.', '('), ('T.', '(', '1991'), ('(', '1991', ')'), ('1991', ')', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('81', 'CD'), (']', 'JJ'), ('McCray', 'NNP'), (',', ','), ('A.', 'NNP'), ('T.', 'NNP'), ('(', '('), ('1991', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['] McCray', 'A. T.']

>> Named Entities are: 
 [('ORGANIZATION', 'McCray')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('81', '81'), (']', ']'), ('McCray', 'mccray'), (',', ','), ('A.', 'a.'), ('T.', 't.'), ('(', '('), ('1991', '1991'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('81', '81'), (']', ']'), ('McCray', 'mccray'), (',', ','), ('A.', 'a.'), ('T.', 't.'), ('(', '('), ('1991', '1991'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('81', '81'), (']', ']'), ('McCray', 'McCray'), (',', ','), ('A.', 'A.'), ('T.', 'T.'), ('(', '('), ('1991', '1991'), (')', ')'), ('.', '.')]


------------------- Sentence 2 -------------------

Natural language processing for intelligent information retrieval.

>> Tokens are: 
 ['Natural', 'language', 'processing', 'intelligent', 'information', 'retrieval', '.']

>> Bigrams are: 
 [('Natural', 'language'), ('language', 'processing'), ('processing', 'intelligent'), ('intelligent', 'information'), ('information', 'retrieval'), ('retrieval', '.')]

>> Trigrams are: 
 [('Natural', 'language', 'processing'), ('language', 'processing', 'intelligent'), ('processing', 'intelligent', 'information'), ('intelligent', 'information', 'retrieval'), ('information', 'retrieval', '.')]

>> POS Tags are: 
 [('Natural', 'JJ'), ('language', 'NN'), ('processing', 'NN'), ('intelligent', 'JJ'), ('information', 'NN'), ('retrieval', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Natural language processing', 'intelligent information retrieval']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Natural', 'natur'), ('language', 'languag'), ('processing', 'process'), ('intelligent', 'intellig'), ('information', 'inform'), ('retrieval', 'retriev'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Natural', 'natur'), ('language', 'languag'), ('processing', 'process'), ('intelligent', 'intellig'), ('information', 'inform'), ('retrieval', 'retriev'), ('.', '.')]

>> Lemmatization: 
 [('Natural', 'Natural'), ('language', 'language'), ('processing', 'processing'), ('intelligent', 'intelligent'), ('information', 'information'), ('retrieval', 'retrieval'), ('.', '.')]



========================================== PARAGRAPH 804 ===========================================

In Engineering in Medicine and Biology Society, 1991. Vol. 13: 1991., Proceedings of the  

------------------- Sentence 1 -------------------

In Engineering in Medicine and Biology Society, 1991.

>> Tokens are: 
 ['In', 'Engineering', 'Medicine', 'Biology', 'Society', ',', '1991', '.']

>> Bigrams are: 
 [('In', 'Engineering'), ('Engineering', 'Medicine'), ('Medicine', 'Biology'), ('Biology', 'Society'), ('Society', ','), (',', '1991'), ('1991', '.')]

>> Trigrams are: 
 [('In', 'Engineering', 'Medicine'), ('Engineering', 'Medicine', 'Biology'), ('Medicine', 'Biology', 'Society'), ('Biology', 'Society', ','), ('Society', ',', '1991'), (',', '1991', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('Engineering', 'NNP'), ('Medicine', 'NNP'), ('Biology', 'NNP'), ('Society', 'NNP'), (',', ','), ('1991', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Engineering Medicine Biology Society']

>> Named Entities are: 
 [('GPE', 'Engineering'), ('PERSON', 'Biology Society')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('Engineering', 'engin'), ('Medicine', 'medicin'), ('Biology', 'biolog'), ('Society', 'societi'), (',', ','), ('1991', '1991'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('Engineering', 'engin'), ('Medicine', 'medicin'), ('Biology', 'biolog'), ('Society', 'societi'), (',', ','), ('1991', '1991'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('Engineering', 'Engineering'), ('Medicine', 'Medicine'), ('Biology', 'Biology'), ('Society', 'Society'), (',', ','), ('1991', '1991'), ('.', '.')]


------------------- Sentence 2 -------------------

Vol.

>> Tokens are: 
 ['Vol', '.']

>> Bigrams are: 
 [('Vol', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Vol', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Vol']

>> Named Entities are: 
 [('GPE', 'Vol')] 

>> Stemming using Porter Stemmer: 
 [('Vol', 'vol'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Vol', 'vol'), ('.', '.')]

>> Lemmatization: 
 [('Vol', 'Vol'), ('.', '.')]


------------------- Sentence 3 -------------------

13: 1991., Proceedings of the

>> Tokens are: 
 ['13', ':', '1991.', ',', 'Proceedings']

>> Bigrams are: 
 [('13', ':'), (':', '1991.'), ('1991.', ','), (',', 'Proceedings')]

>> Trigrams are: 
 [('13', ':', '1991.'), (':', '1991.', ','), ('1991.', ',', 'Proceedings')]

>> POS Tags are: 
 [('13', 'CD'), (':', ':'), ('1991.', 'CD'), (',', ','), ('Proceedings', 'NNS')]

>> Noun Phrases are: 
 ['Proceedings']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('13', '13'), (':', ':'), ('1991.', '1991.'), (',', ','), ('Proceedings', 'proceed')]

>> Stemming using Snowball Stemmer: 
 [('13', '13'), (':', ':'), ('1991.', '1991.'), (',', ','), ('Proceedings', 'proceed')]

>> Lemmatization: 
 [('13', '13'), (':', ':'), ('1991.', '1991.'), (',', ','), ('Proceedings', 'Proceedings')]



========================================== PARAGRAPH 805 ===========================================

Annual International Conference of the IEEE (pp. 1160-1161). IEEE.  

------------------- Sentence 1 -------------------

Annual International Conference of the IEEE (pp.

>> Tokens are: 
 ['Annual', 'International', 'Conference', 'IEEE', '(', 'pp', '.']

>> Bigrams are: 
 [('Annual', 'International'), ('International', 'Conference'), ('Conference', 'IEEE'), ('IEEE', '('), ('(', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('Annual', 'International', 'Conference'), ('International', 'Conference', 'IEEE'), ('Conference', 'IEEE', '('), ('IEEE', '(', 'pp'), ('(', 'pp', '.')]

>> POS Tags are: 
 [('Annual', 'JJ'), ('International', 'NNP'), ('Conference', 'NNP'), ('IEEE', 'NNP'), ('(', '('), ('pp', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Annual International Conference IEEE', 'pp']

>> Named Entities are: 
 [('PERSON', 'Annual'), ('ORGANIZATION', 'International Conference')] 

>> Stemming using Porter Stemmer: 
 [('Annual', 'annual'), ('International', 'intern'), ('Conference', 'confer'), ('IEEE', 'ieee'), ('(', '('), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Annual', 'annual'), ('International', 'intern'), ('Conference', 'confer'), ('IEEE', 'ieee'), ('(', '('), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('Annual', 'Annual'), ('International', 'International'), ('Conference', 'Conference'), ('IEEE', 'IEEE'), ('(', '('), ('pp', 'pp'), ('.', '.')]


------------------- Sentence 2 -------------------

1160-1161).

>> Tokens are: 
 ['1160-1161', ')', '.']

>> Bigrams are: 
 [('1160-1161', ')'), (')', '.')]

>> Trigrams are: 
 [('1160-1161', ')', '.')]

>> POS Tags are: 
 [('1160-1161', 'JJ'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('1160-1161', '1160-1161'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('1160-1161', '1160-1161'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('1160-1161', '1160-1161'), (')', ')'), ('.', '.')]


------------------- Sentence 3 -------------------

IEEE.

>> Tokens are: 
 ['IEEE', '.']

>> Bigrams are: 
 [('IEEE', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('IEEE', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['IEEE']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('IEEE', 'ieee'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('IEEE', 'ieee'), ('.', '.')]

>> Lemmatization: 
 [('IEEE', 'IEEE'), ('.', '.')]



========================================== PARAGRAPH 806 ===========================================

[82] McCray, A. T. (1991). Extending a natural language parser with UMLS knowledge.  

------------------- Sentence 1 -------------------

[82] McCray, A. T. (1991).

>> Tokens are: 
 ['[', '82', ']', 'McCray', ',', 'A.', 'T.', '(', '1991', ')', '.']

>> Bigrams are: 
 [('[', '82'), ('82', ']'), (']', 'McCray'), ('McCray', ','), (',', 'A.'), ('A.', 'T.'), ('T.', '('), ('(', '1991'), ('1991', ')'), (')', '.')]

>> Trigrams are: 
 [('[', '82', ']'), ('82', ']', 'McCray'), (']', 'McCray', ','), ('McCray', ',', 'A.'), (',', 'A.', 'T.'), ('A.', 'T.', '('), ('T.', '(', '1991'), ('(', '1991', ')'), ('1991', ')', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('82', 'CD'), (']', 'JJ'), ('McCray', 'NNP'), (',', ','), ('A.', 'NNP'), ('T.', 'NNP'), ('(', '('), ('1991', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['] McCray', 'A. T.']

>> Named Entities are: 
 [('ORGANIZATION', 'McCray')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('82', '82'), (']', ']'), ('McCray', 'mccray'), (',', ','), ('A.', 'a.'), ('T.', 't.'), ('(', '('), ('1991', '1991'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('82', '82'), (']', ']'), ('McCray', 'mccray'), (',', ','), ('A.', 'a.'), ('T.', 't.'), ('(', '('), ('1991', '1991'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('82', '82'), (']', ']'), ('McCray', 'McCray'), (',', ','), ('A.', 'A.'), ('T.', 'T.'), ('(', '('), ('1991', '1991'), (')', ')'), ('.', '.')]


------------------- Sentence 2 -------------------

Extending a natural language parser with UMLS knowledge.

>> Tokens are: 
 ['Extending', 'natural', 'language', 'parser', 'UMLS', 'knowledge', '.']

>> Bigrams are: 
 [('Extending', 'natural'), ('natural', 'language'), ('language', 'parser'), ('parser', 'UMLS'), ('UMLS', 'knowledge'), ('knowledge', '.')]

>> Trigrams are: 
 [('Extending', 'natural', 'language'), ('natural', 'language', 'parser'), ('language', 'parser', 'UMLS'), ('parser', 'UMLS', 'knowledge'), ('UMLS', 'knowledge', '.')]

>> POS Tags are: 
 [('Extending', 'VBG'), ('natural', 'JJ'), ('language', 'NN'), ('parser', 'NN'), ('UMLS', 'NNP'), ('knowledge', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['natural language parser UMLS knowledge']

>> Named Entities are: 
 [('ORGANIZATION', 'UMLS')] 

>> Stemming using Porter Stemmer: 
 [('Extending', 'extend'), ('natural', 'natur'), ('language', 'languag'), ('parser', 'parser'), ('UMLS', 'uml'), ('knowledge', 'knowledg'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Extending', 'extend'), ('natural', 'natur'), ('language', 'languag'), ('parser', 'parser'), ('UMLS', 'uml'), ('knowledge', 'knowledg'), ('.', '.')]

>> Lemmatization: 
 [('Extending', 'Extending'), ('natural', 'natural'), ('language', 'language'), ('parser', 'parser'), ('UMLS', 'UMLS'), ('knowledge', 'knowledge'), ('.', '.')]



========================================== PARAGRAPH 807 ===========================================

In Proceedings of the Annual Symposium on Computer Application in Medical Care (p. 194).  

------------------- Sentence 1 -------------------

In Proceedings of the Annual Symposium on Computer Application in Medical Care (p. 194).

>> Tokens are: 
 ['In', 'Proceedings', 'Annual', 'Symposium', 'Computer', 'Application', 'Medical', 'Care', '(', 'p.', '194', ')', '.']

>> Bigrams are: 
 [('In', 'Proceedings'), ('Proceedings', 'Annual'), ('Annual', 'Symposium'), ('Symposium', 'Computer'), ('Computer', 'Application'), ('Application', 'Medical'), ('Medical', 'Care'), ('Care', '('), ('(', 'p.'), ('p.', '194'), ('194', ')'), (')', '.')]

>> Trigrams are: 
 [('In', 'Proceedings', 'Annual'), ('Proceedings', 'Annual', 'Symposium'), ('Annual', 'Symposium', 'Computer'), ('Symposium', 'Computer', 'Application'), ('Computer', 'Application', 'Medical'), ('Application', 'Medical', 'Care'), ('Medical', 'Care', '('), ('Care', '(', 'p.'), ('(', 'p.', '194'), ('p.', '194', ')'), ('194', ')', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('Proceedings', 'NNP'), ('Annual', 'NNP'), ('Symposium', 'NNP'), ('Computer', 'NNP'), ('Application', 'NNP'), ('Medical', 'NNP'), ('Care', 'NNP'), ('(', '('), ('p.', 'VB'), ('194', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['Proceedings Annual Symposium Computer Application Medical Care']

>> Named Entities are: 
 [('GPE', 'Proceedings'), ('PERSON', 'Annual Symposium Computer')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('Proceedings', 'proceed'), ('Annual', 'annual'), ('Symposium', 'symposium'), ('Computer', 'comput'), ('Application', 'applic'), ('Medical', 'medic'), ('Care', 'care'), ('(', '('), ('p.', 'p.'), ('194', '194'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('Proceedings', 'proceed'), ('Annual', 'annual'), ('Symposium', 'symposium'), ('Computer', 'comput'), ('Application', 'applic'), ('Medical', 'medic'), ('Care', 'care'), ('(', '('), ('p.', 'p.'), ('194', '194'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('Proceedings', 'Proceedings'), ('Annual', 'Annual'), ('Symposium', 'Symposium'), ('Computer', 'Computer'), ('Application', 'Application'), ('Medical', 'Medical'), ('Care', 'Care'), ('(', '('), ('p.', 'p.'), ('194', '194'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 808 ===========================================

American Medical Informatics Association.  

------------------- Sentence 1 -------------------

American Medical Informatics Association.

>> Tokens are: 
 ['American', 'Medical', 'Informatics', 'Association', '.']

>> Bigrams are: 
 [('American', 'Medical'), ('Medical', 'Informatics'), ('Informatics', 'Association'), ('Association', '.')]

>> Trigrams are: 
 [('American', 'Medical', 'Informatics'), ('Medical', 'Informatics', 'Association'), ('Informatics', 'Association', '.')]

>> POS Tags are: 
 [('American', 'NNP'), ('Medical', 'NNP'), ('Informatics', 'NNP'), ('Association', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['American Medical Informatics Association']

>> Named Entities are: 
 [('GPE', 'American'), ('ORGANIZATION', 'Medical Informatics Association')] 

>> Stemming using Porter Stemmer: 
 [('American', 'american'), ('Medical', 'medic'), ('Informatics', 'informat'), ('Association', 'associ'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('American', 'american'), ('Medical', 'medic'), ('Informatics', 'informat'), ('Association', 'associ'), ('.', '.')]

>> Lemmatization: 
 [('American', 'American'), ('Medical', 'Medical'), ('Informatics', 'Informatics'), ('Association', 'Association'), ('.', '.')]



========================================== PARAGRAPH 809 ===========================================

[83] McCray, A. T., Srinivasan, S., & Browne, A. C. (1994). Lexical methods for managing  

------------------- Sentence 1 -------------------

[83] McCray, A. T., Srinivasan, S., & Browne, A. C. (1994).

>> Tokens are: 
 ['[', '83', ']', 'McCray', ',', 'A.', 'T.', ',', 'Srinivasan', ',', 'S.', ',', '&', 'Browne', ',', 'A.', 'C.', '(', '1994', ')', '.']

>> Bigrams are: 
 [('[', '83'), ('83', ']'), (']', 'McCray'), ('McCray', ','), (',', 'A.'), ('A.', 'T.'), ('T.', ','), (',', 'Srinivasan'), ('Srinivasan', ','), (',', 'S.'), ('S.', ','), (',', '&'), ('&', 'Browne'), ('Browne', ','), (',', 'A.'), ('A.', 'C.'), ('C.', '('), ('(', '1994'), ('1994', ')'), (')', '.')]

>> Trigrams are: 
 [('[', '83', ']'), ('83', ']', 'McCray'), (']', 'McCray', ','), ('McCray', ',', 'A.'), (',', 'A.', 'T.'), ('A.', 'T.', ','), ('T.', ',', 'Srinivasan'), (',', 'Srinivasan', ','), ('Srinivasan', ',', 'S.'), (',', 'S.', ','), ('S.', ',', '&'), (',', '&', 'Browne'), ('&', 'Browne', ','), ('Browne', ',', 'A.'), (',', 'A.', 'C.'), ('A.', 'C.', '('), ('C.', '(', '1994'), ('(', '1994', ')'), ('1994', ')', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('83', 'CD'), (']', 'JJ'), ('McCray', 'NNP'), (',', ','), ('A.', 'NNP'), ('T.', 'NNP'), (',', ','), ('Srinivasan', 'NNP'), (',', ','), ('S.', 'NNP'), (',', ','), ('&', 'CC'), ('Browne', 'NNP'), (',', ','), ('A.', 'NNP'), ('C.', 'NNP'), ('(', '('), ('1994', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['] McCray', 'A. T.', 'Srinivasan', 'S.', 'Browne', 'A. C.']

>> Named Entities are: 
 [('ORGANIZATION', 'McCray'), ('GPE', 'Srinivasan'), ('PERSON', 'Browne')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('83', '83'), (']', ']'), ('McCray', 'mccray'), (',', ','), ('A.', 'a.'), ('T.', 't.'), (',', ','), ('Srinivasan', 'srinivasan'), (',', ','), ('S.', 's.'), (',', ','), ('&', '&'), ('Browne', 'brown'), (',', ','), ('A.', 'a.'), ('C.', 'c.'), ('(', '('), ('1994', '1994'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('83', '83'), (']', ']'), ('McCray', 'mccray'), (',', ','), ('A.', 'a.'), ('T.', 't.'), (',', ','), ('Srinivasan', 'srinivasan'), (',', ','), ('S.', 's.'), (',', ','), ('&', '&'), ('Browne', 'brown'), (',', ','), ('A.', 'a.'), ('C.', 'c.'), ('(', '('), ('1994', '1994'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('83', '83'), (']', ']'), ('McCray', 'McCray'), (',', ','), ('A.', 'A.'), ('T.', 'T.'), (',', ','), ('Srinivasan', 'Srinivasan'), (',', ','), ('S.', 'S.'), (',', ','), ('&', '&'), ('Browne', 'Browne'), (',', ','), ('A.', 'A.'), ('C.', 'C.'), ('(', '('), ('1994', '1994'), (')', ')'), ('.', '.')]


------------------- Sentence 2 -------------------

Lexical methods for managing

>> Tokens are: 
 ['Lexical', 'methods', 'managing']

>> Bigrams are: 
 [('Lexical', 'methods'), ('methods', 'managing')]

>> Trigrams are: 
 [('Lexical', 'methods', 'managing')]

>> POS Tags are: 
 [('Lexical', 'JJ'), ('methods', 'NNS'), ('managing', 'VBG')]

>> Noun Phrases are: 
 ['Lexical methods']

>> Named Entities are: 
 [('GPE', 'Lexical')] 

>> Stemming using Porter Stemmer: 
 [('Lexical', 'lexic'), ('methods', 'method'), ('managing', 'manag')]

>> Stemming using Snowball Stemmer: 
 [('Lexical', 'lexic'), ('methods', 'method'), ('managing', 'manag')]

>> Lemmatization: 
 [('Lexical', 'Lexical'), ('methods', 'method'), ('managing', 'managing')]



========================================== PARAGRAPH 810 ===========================================

variation in biomedical terminologies. In Proceedings of the Annual Symposium on  

------------------- Sentence 1 -------------------

variation in biomedical terminologies.

>> Tokens are: 
 ['variation', 'biomedical', 'terminologies', '.']

>> Bigrams are: 
 [('variation', 'biomedical'), ('biomedical', 'terminologies'), ('terminologies', '.')]

>> Trigrams are: 
 [('variation', 'biomedical', 'terminologies'), ('biomedical', 'terminologies', '.')]

>> POS Tags are: 
 [('variation', 'NN'), ('biomedical', 'JJ'), ('terminologies', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['variation', 'biomedical terminologies']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('variation', 'variat'), ('biomedical', 'biomed'), ('terminologies', 'terminolog'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('variation', 'variat'), ('biomedical', 'biomed'), ('terminologies', 'terminolog'), ('.', '.')]

>> Lemmatization: 
 [('variation', 'variation'), ('biomedical', 'biomedical'), ('terminologies', 'terminology'), ('.', '.')]


------------------- Sentence 2 -------------------

In Proceedings of the Annual Symposium on

>> Tokens are: 
 ['In', 'Proceedings', 'Annual', 'Symposium']

>> Bigrams are: 
 [('In', 'Proceedings'), ('Proceedings', 'Annual'), ('Annual', 'Symposium')]

>> Trigrams are: 
 [('In', 'Proceedings', 'Annual'), ('Proceedings', 'Annual', 'Symposium')]

>> POS Tags are: 
 [('In', 'IN'), ('Proceedings', 'NNP'), ('Annual', 'NNP'), ('Symposium', 'NNP')]

>> Noun Phrases are: 
 ['Proceedings Annual Symposium']

>> Named Entities are: 
 [('GPE', 'Proceedings'), ('PERSON', 'Annual Symposium')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('Proceedings', 'proceed'), ('Annual', 'annual'), ('Symposium', 'symposium')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('Proceedings', 'proceed'), ('Annual', 'annual'), ('Symposium', 'symposium')]

>> Lemmatization: 
 [('In', 'In'), ('Proceedings', 'Proceedings'), ('Annual', 'Annual'), ('Symposium', 'Symposium')]



========================================== PARAGRAPH 811 ===========================================

Computer Application in Medical Care (p. 235). American Medical Informatics Association.  

------------------- Sentence 1 -------------------

Computer Application in Medical Care (p. 235).

>> Tokens are: 
 ['Computer', 'Application', 'Medical', 'Care', '(', 'p.', '235', ')', '.']

>> Bigrams are: 
 [('Computer', 'Application'), ('Application', 'Medical'), ('Medical', 'Care'), ('Care', '('), ('(', 'p.'), ('p.', '235'), ('235', ')'), (')', '.')]

>> Trigrams are: 
 [('Computer', 'Application', 'Medical'), ('Application', 'Medical', 'Care'), ('Medical', 'Care', '('), ('Care', '(', 'p.'), ('(', 'p.', '235'), ('p.', '235', ')'), ('235', ')', '.')]

>> POS Tags are: 
 [('Computer', 'NNP'), ('Application', 'NNP'), ('Medical', 'NNP'), ('Care', 'NNP'), ('(', '('), ('p.', 'VB'), ('235', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['Computer Application Medical Care']

>> Named Entities are: 
 [('ORGANIZATION', 'Computer Application Medical Care')] 

>> Stemming using Porter Stemmer: 
 [('Computer', 'comput'), ('Application', 'applic'), ('Medical', 'medic'), ('Care', 'care'), ('(', '('), ('p.', 'p.'), ('235', '235'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Computer', 'comput'), ('Application', 'applic'), ('Medical', 'medic'), ('Care', 'care'), ('(', '('), ('p.', 'p.'), ('235', '235'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Computer', 'Computer'), ('Application', 'Application'), ('Medical', 'Medical'), ('Care', 'Care'), ('(', '('), ('p.', 'p.'), ('235', '235'), (')', ')'), ('.', '.')]


------------------- Sentence 2 -------------------

American Medical Informatics Association.

>> Tokens are: 
 ['American', 'Medical', 'Informatics', 'Association', '.']

>> Bigrams are: 
 [('American', 'Medical'), ('Medical', 'Informatics'), ('Informatics', 'Association'), ('Association', '.')]

>> Trigrams are: 
 [('American', 'Medical', 'Informatics'), ('Medical', 'Informatics', 'Association'), ('Informatics', 'Association', '.')]

>> POS Tags are: 
 [('American', 'NNP'), ('Medical', 'NNP'), ('Informatics', 'NNP'), ('Association', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['American Medical Informatics Association']

>> Named Entities are: 
 [('GPE', 'American'), ('ORGANIZATION', 'Medical Informatics Association')] 

>> Stemming using Porter Stemmer: 
 [('American', 'american'), ('Medical', 'medic'), ('Informatics', 'informat'), ('Association', 'associ'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('American', 'american'), ('Medical', 'medic'), ('Informatics', 'informat'), ('Association', 'associ'), ('.', '.')]

>> Lemmatization: 
 [('American', 'American'), ('Medical', 'Medical'), ('Informatics', 'Informatics'), ('Association', 'Association'), ('.', '.')]



========================================== PARAGRAPH 812 ===========================================

[84] McCray, A. T., & Razi, A. (1994). The UMLS Knowledge Source server. Medinfo.  

------------------- Sentence 1 -------------------

[84] McCray, A. T., & Razi, A.

>> Tokens are: 
 ['[', '84', ']', 'McCray', ',', 'A.', 'T.', ',', '&', 'Razi', ',', 'A', '.']

>> Bigrams are: 
 [('[', '84'), ('84', ']'), (']', 'McCray'), ('McCray', ','), (',', 'A.'), ('A.', 'T.'), ('T.', ','), (',', '&'), ('&', 'Razi'), ('Razi', ','), (',', 'A'), ('A', '.')]

>> Trigrams are: 
 [('[', '84', ']'), ('84', ']', 'McCray'), (']', 'McCray', ','), ('McCray', ',', 'A.'), (',', 'A.', 'T.'), ('A.', 'T.', ','), ('T.', ',', '&'), (',', '&', 'Razi'), ('&', 'Razi', ','), ('Razi', ',', 'A'), (',', 'A', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('84', 'CD'), (']', 'JJ'), ('McCray', 'NNP'), (',', ','), ('A.', 'NNP'), ('T.', 'NNP'), (',', ','), ('&', 'CC'), ('Razi', 'NNP'), (',', ','), ('A', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['] McCray', 'A. T.', 'Razi', 'A']

>> Named Entities are: 
 [('ORGANIZATION', 'McCray'), ('PERSON', 'Razi')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('84', '84'), (']', ']'), ('McCray', 'mccray'), (',', ','), ('A.', 'a.'), ('T.', 't.'), (',', ','), ('&', '&'), ('Razi', 'razi'), (',', ','), ('A', 'a'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('84', '84'), (']', ']'), ('McCray', 'mccray'), (',', ','), ('A.', 'a.'), ('T.', 't.'), (',', ','), ('&', '&'), ('Razi', 'razi'), (',', ','), ('A', 'a'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('84', '84'), (']', ']'), ('McCray', 'McCray'), (',', ','), ('A.', 'A.'), ('T.', 'T.'), (',', ','), ('&', '&'), ('Razi', 'Razi'), (',', ','), ('A', 'A'), ('.', '.')]


------------------- Sentence 2 -------------------

(1994).

>> Tokens are: 
 ['(', '1994', ')', '.']

>> Bigrams are: 
 [('(', '1994'), ('1994', ')'), (')', '.')]

>> Trigrams are: 
 [('(', '1994', ')'), ('1994', ')', '.')]

>> POS Tags are: 
 [('(', '('), ('1994', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('1994', '1994'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('1994', '1994'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('(', '('), ('1994', '1994'), (')', ')'), ('.', '.')]


------------------- Sentence 3 -------------------

The UMLS Knowledge Source server.

>> Tokens are: 
 ['The', 'UMLS', 'Knowledge', 'Source', 'server', '.']

>> Bigrams are: 
 [('The', 'UMLS'), ('UMLS', 'Knowledge'), ('Knowledge', 'Source'), ('Source', 'server'), ('server', '.')]

>> Trigrams are: 
 [('The', 'UMLS', 'Knowledge'), ('UMLS', 'Knowledge', 'Source'), ('Knowledge', 'Source', 'server'), ('Source', 'server', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('UMLS', 'NNP'), ('Knowledge', 'NNP'), ('Source', 'NNP'), ('server', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['The UMLS Knowledge Source server']

>> Named Entities are: 
 [('ORGANIZATION', 'UMLS')] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('UMLS', 'uml'), ('Knowledge', 'knowledg'), ('Source', 'sourc'), ('server', 'server'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('UMLS', 'uml'), ('Knowledge', 'knowledg'), ('Source', 'sourc'), ('server', 'server'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('UMLS', 'UMLS'), ('Knowledge', 'Knowledge'), ('Source', 'Source'), ('server', 'server'), ('.', '.')]


------------------- Sentence 4 -------------------

Medinfo.

>> Tokens are: 
 ['Medinfo', '.']

>> Bigrams are: 
 [('Medinfo', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Medinfo', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Medinfo']

>> Named Entities are: 
 [('GPE', 'Medinfo')] 

>> Stemming using Porter Stemmer: 
 [('Medinfo', 'medinfo'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Medinfo', 'medinfo'), ('.', '.')]

>> Lemmatization: 
 [('Medinfo', 'Medinfo'), ('.', '.')]



========================================== PARAGRAPH 813 ===========================================

MEDINFO, 8, 144-147.  

------------------- Sentence 1 -------------------

MEDINFO, 8, 144-147.

>> Tokens are: 
 ['MEDINFO', ',', '8', ',', '144-147', '.']

>> Bigrams are: 
 [('MEDINFO', ','), (',', '8'), ('8', ','), (',', '144-147'), ('144-147', '.')]

>> Trigrams are: 
 [('MEDINFO', ',', '8'), (',', '8', ','), ('8', ',', '144-147'), (',', '144-147', '.')]

>> POS Tags are: 
 [('MEDINFO', 'NNP'), (',', ','), ('8', 'CD'), (',', ','), ('144-147', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['MEDINFO']

>> Named Entities are: 
 [('GPE', 'MEDINFO')] 

>> Stemming using Porter Stemmer: 
 [('MEDINFO', 'medinfo'), (',', ','), ('8', '8'), (',', ','), ('144-147', '144-147'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('MEDINFO', 'medinfo'), (',', ','), ('8', '8'), (',', ','), ('144-147', '144-147'), ('.', '.')]

>> Lemmatization: 
 [('MEDINFO', 'MEDINFO'), (',', ','), ('8', '8'), (',', ','), ('144-147', '144-147'), ('.', '.')]



========================================== PARAGRAPH 814 ===========================================

[85] Scherrer, J. R., Revillard, C., Borst, F., Berthoud, M., & Lovis, C. (1994). Medical office  

------------------- Sentence 1 -------------------

[85] Scherrer, J. R., Revillard, C., Borst, F., Berthoud, M., & Lovis, C. (1994).

>> Tokens are: 
 ['[', '85', ']', 'Scherrer', ',', 'J.', 'R.', ',', 'Revillard', ',', 'C.', ',', 'Borst', ',', 'F.', ',', 'Berthoud', ',', 'M.', ',', '&', 'Lovis', ',', 'C.', '(', '1994', ')', '.']

>> Bigrams are: 
 [('[', '85'), ('85', ']'), (']', 'Scherrer'), ('Scherrer', ','), (',', 'J.'), ('J.', 'R.'), ('R.', ','), (',', 'Revillard'), ('Revillard', ','), (',', 'C.'), ('C.', ','), (',', 'Borst'), ('Borst', ','), (',', 'F.'), ('F.', ','), (',', 'Berthoud'), ('Berthoud', ','), (',', 'M.'), ('M.', ','), (',', '&'), ('&', 'Lovis'), ('Lovis', ','), (',', 'C.'), ('C.', '('), ('(', '1994'), ('1994', ')'), (')', '.')]

>> Trigrams are: 
 [('[', '85', ']'), ('85', ']', 'Scherrer'), (']', 'Scherrer', ','), ('Scherrer', ',', 'J.'), (',', 'J.', 'R.'), ('J.', 'R.', ','), ('R.', ',', 'Revillard'), (',', 'Revillard', ','), ('Revillard', ',', 'C.'), (',', 'C.', ','), ('C.', ',', 'Borst'), (',', 'Borst', ','), ('Borst', ',', 'F.'), (',', 'F.', ','), ('F.', ',', 'Berthoud'), (',', 'Berthoud', ','), ('Berthoud', ',', 'M.'), (',', 'M.', ','), ('M.', ',', '&'), (',', '&', 'Lovis'), ('&', 'Lovis', ','), ('Lovis', ',', 'C.'), (',', 'C.', '('), ('C.', '(', '1994'), ('(', '1994', ')'), ('1994', ')', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('85', 'CD'), (']', 'JJ'), ('Scherrer', 'NNP'), (',', ','), ('J.', 'NNP'), ('R.', 'NNP'), (',', ','), ('Revillard', 'NNP'), (',', ','), ('C.', 'NNP'), (',', ','), ('Borst', 'NNP'), (',', ','), ('F.', 'NNP'), (',', ','), ('Berthoud', 'NNP'), (',', ','), ('M.', 'NNP'), (',', ','), ('&', 'CC'), ('Lovis', 'NNP'), (',', ','), ('C.', 'NNP'), ('(', '('), ('1994', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['] Scherrer', 'J. R.', 'Revillard', 'C.', 'Borst', 'F.', 'Berthoud', 'M.', 'Lovis', 'C.']

>> Named Entities are: 
 [('PERSON', 'J. R.'), ('PERSON', 'Revillard'), ('PERSON', 'Borst'), ('PERSON', 'Berthoud'), ('PERSON', 'Lovis')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('85', '85'), (']', ']'), ('Scherrer', 'scherrer'), (',', ','), ('J.', 'j.'), ('R.', 'r.'), (',', ','), ('Revillard', 'revillard'), (',', ','), ('C.', 'c.'), (',', ','), ('Borst', 'borst'), (',', ','), ('F.', 'f.'), (',', ','), ('Berthoud', 'berthoud'), (',', ','), ('M.', 'm.'), (',', ','), ('&', '&'), ('Lovis', 'lovi'), (',', ','), ('C.', 'c.'), ('(', '('), ('1994', '1994'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('85', '85'), (']', ']'), ('Scherrer', 'scherrer'), (',', ','), ('J.', 'j.'), ('R.', 'r.'), (',', ','), ('Revillard', 'revillard'), (',', ','), ('C.', 'c.'), (',', ','), ('Borst', 'borst'), (',', ','), ('F.', 'f.'), (',', ','), ('Berthoud', 'berthoud'), (',', ','), ('M.', 'm.'), (',', ','), ('&', '&'), ('Lovis', 'lovi'), (',', ','), ('C.', 'c.'), ('(', '('), ('1994', '1994'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('85', '85'), (']', ']'), ('Scherrer', 'Scherrer'), (',', ','), ('J.', 'J.'), ('R.', 'R.'), (',', ','), ('Revillard', 'Revillard'), (',', ','), ('C.', 'C.'), (',', ','), ('Borst', 'Borst'), (',', ','), ('F.', 'F.'), (',', ','), ('Berthoud', 'Berthoud'), (',', ','), ('M.', 'M.'), (',', ','), ('&', '&'), ('Lovis', 'Lovis'), (',', ','), ('C.', 'C.'), ('(', '('), ('1994', '1994'), (')', ')'), ('.', '.')]


------------------- Sentence 2 -------------------

Medical office

>> Tokens are: 
 ['Medical', 'office']

>> Bigrams are: 
 [('Medical', 'office')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Medical', 'JJ'), ('office', 'NN')]

>> Noun Phrases are: 
 ['Medical office']

>> Named Entities are: 
 [('GPE', 'Medical')] 

>> Stemming using Porter Stemmer: 
 [('Medical', 'medic'), ('office', 'offic')]

>> Stemming using Snowball Stemmer: 
 [('Medical', 'medic'), ('office', 'offic')]

>> Lemmatization: 
 [('Medical', 'Medical'), ('office', 'office')]



========================================== PARAGRAPH 815 ===========================================

automation integrated into the distributed architecture of a hospital information  

------------------- Sentence 1 -------------------

automation integrated into the distributed architecture of a hospital information

>> Tokens are: 
 ['automation', 'integrated', 'distributed', 'architecture', 'hospital', 'information']

>> Bigrams are: 
 [('automation', 'integrated'), ('integrated', 'distributed'), ('distributed', 'architecture'), ('architecture', 'hospital'), ('hospital', 'information')]

>> Trigrams are: 
 [('automation', 'integrated', 'distributed'), ('integrated', 'distributed', 'architecture'), ('distributed', 'architecture', 'hospital'), ('architecture', 'hospital', 'information')]

>> POS Tags are: 
 [('automation', 'NN'), ('integrated', 'VBN'), ('distributed', 'JJ'), ('architecture', 'NN'), ('hospital', 'NN'), ('information', 'NN')]

>> Noun Phrases are: 
 ['automation', 'distributed architecture hospital information']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('automation', 'autom'), ('integrated', 'integr'), ('distributed', 'distribut'), ('architecture', 'architectur'), ('hospital', 'hospit'), ('information', 'inform')]

>> Stemming using Snowball Stemmer: 
 [('automation', 'autom'), ('integrated', 'integr'), ('distributed', 'distribut'), ('architecture', 'architectur'), ('hospital', 'hospit'), ('information', 'inform')]

>> Lemmatization: 
 [('automation', 'automation'), ('integrated', 'integrated'), ('distributed', 'distributed'), ('architecture', 'architecture'), ('hospital', 'hospital'), ('information', 'information')]



========================================== PARAGRAPH 816 ===========================================

system. Methods of information in medicine, 33(2), 174-179.  

------------------- Sentence 1 -------------------

system.

>> Tokens are: 
 ['system', '.']

>> Bigrams are: 
 [('system', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('system', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['system']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('system', 'system'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('system', 'system'), ('.', '.')]

>> Lemmatization: 
 [('system', 'system'), ('.', '.')]


------------------- Sentence 2 -------------------

Methods of information in medicine, 33(2), 174-179.

>> Tokens are: 
 ['Methods', 'information', 'medicine', ',', '33', '(', '2', ')', ',', '174-179', '.']

>> Bigrams are: 
 [('Methods', 'information'), ('information', 'medicine'), ('medicine', ','), (',', '33'), ('33', '('), ('(', '2'), ('2', ')'), (')', ','), (',', '174-179'), ('174-179', '.')]

>> Trigrams are: 
 [('Methods', 'information', 'medicine'), ('information', 'medicine', ','), ('medicine', ',', '33'), (',', '33', '('), ('33', '(', '2'), ('(', '2', ')'), ('2', ')', ','), (')', ',', '174-179'), (',', '174-179', '.')]

>> POS Tags are: 
 [('Methods', 'NNS'), ('information', 'NN'), ('medicine', 'NN'), (',', ','), ('33', 'CD'), ('(', '('), ('2', 'CD'), (')', ')'), (',', ','), ('174-179', 'JJ'), ('.', '.')]

>> Noun Phrases are: 
 ['Methods information medicine']

>> Named Entities are: 
 [('GPE', 'Methods')] 

>> Stemming using Porter Stemmer: 
 [('Methods', 'method'), ('information', 'inform'), ('medicine', 'medicin'), (',', ','), ('33', '33'), ('(', '('), ('2', '2'), (')', ')'), (',', ','), ('174-179', '174-179'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Methods', 'method'), ('information', 'inform'), ('medicine', 'medicin'), (',', ','), ('33', '33'), ('(', '('), ('2', '2'), (')', ')'), (',', ','), ('174-179', '174-179'), ('.', '.')]

>> Lemmatization: 
 [('Methods', 'Methods'), ('information', 'information'), ('medicine', 'medicine'), (',', ','), ('33', '33'), ('(', '('), ('2', '2'), (')', ')'), (',', ','), ('174-179', '174-179'), ('.', '.')]



========================================== PARAGRAPH 817 ===========================================

[86] Baud, R. H., Rassinoux, A. M., & Scherrer, J. R. (1992). Natural language processing  

------------------- Sentence 1 -------------------

[86] Baud, R. H., Rassinoux, A. M., & Scherrer, J. R. (1992).

>> Tokens are: 
 ['[', '86', ']', 'Baud', ',', 'R.', 'H.', ',', 'Rassinoux', ',', 'A.', 'M.', ',', '&', 'Scherrer', ',', 'J.', 'R.', '(', '1992', ')', '.']

>> Bigrams are: 
 [('[', '86'), ('86', ']'), (']', 'Baud'), ('Baud', ','), (',', 'R.'), ('R.', 'H.'), ('H.', ','), (',', 'Rassinoux'), ('Rassinoux', ','), (',', 'A.'), ('A.', 'M.'), ('M.', ','), (',', '&'), ('&', 'Scherrer'), ('Scherrer', ','), (',', 'J.'), ('J.', 'R.'), ('R.', '('), ('(', '1992'), ('1992', ')'), (')', '.')]

>> Trigrams are: 
 [('[', '86', ']'), ('86', ']', 'Baud'), (']', 'Baud', ','), ('Baud', ',', 'R.'), (',', 'R.', 'H.'), ('R.', 'H.', ','), ('H.', ',', 'Rassinoux'), (',', 'Rassinoux', ','), ('Rassinoux', ',', 'A.'), (',', 'A.', 'M.'), ('A.', 'M.', ','), ('M.', ',', '&'), (',', '&', 'Scherrer'), ('&', 'Scherrer', ','), ('Scherrer', ',', 'J.'), (',', 'J.', 'R.'), ('J.', 'R.', '('), ('R.', '(', '1992'), ('(', '1992', ')'), ('1992', ')', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('86', 'CD'), (']', 'JJ'), ('Baud', 'NNP'), (',', ','), ('R.', 'NNP'), ('H.', 'NNP'), (',', ','), ('Rassinoux', 'NNP'), (',', ','), ('A.', 'NNP'), ('M.', 'NNP'), (',', ','), ('&', 'CC'), ('Scherrer', 'NNP'), (',', ','), ('J.', 'NNP'), ('R.', 'NNP'), ('(', '('), ('1992', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['] Baud', 'R. H.', 'Rassinoux', 'A. M.', 'Scherrer', 'J. R.']

>> Named Entities are: 
 [('PERSON', 'Rassinoux'), ('PERSON', 'Scherrer'), ('PERSON', 'J. R.')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('86', '86'), (']', ']'), ('Baud', 'baud'), (',', ','), ('R.', 'r.'), ('H.', 'h.'), (',', ','), ('Rassinoux', 'rassinoux'), (',', ','), ('A.', 'a.'), ('M.', 'm.'), (',', ','), ('&', '&'), ('Scherrer', 'scherrer'), (',', ','), ('J.', 'j.'), ('R.', 'r.'), ('(', '('), ('1992', '1992'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('86', '86'), (']', ']'), ('Baud', 'baud'), (',', ','), ('R.', 'r.'), ('H.', 'h.'), (',', ','), ('Rassinoux', 'rassinoux'), (',', ','), ('A.', 'a.'), ('M.', 'm.'), (',', ','), ('&', '&'), ('Scherrer', 'scherrer'), (',', ','), ('J.', 'j.'), ('R.', 'r.'), ('(', '('), ('1992', '1992'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('86', '86'), (']', ']'), ('Baud', 'Baud'), (',', ','), ('R.', 'R.'), ('H.', 'H.'), (',', ','), ('Rassinoux', 'Rassinoux'), (',', ','), ('A.', 'A.'), ('M.', 'M.'), (',', ','), ('&', '&'), ('Scherrer', 'Scherrer'), (',', ','), ('J.', 'J.'), ('R.', 'R.'), ('(', '('), ('1992', '1992'), (')', ')'), ('.', '.')]


------------------- Sentence 2 -------------------

Natural language processing

>> Tokens are: 
 ['Natural', 'language', 'processing']

>> Bigrams are: 
 [('Natural', 'language'), ('language', 'processing')]

>> Trigrams are: 
 [('Natural', 'language', 'processing')]

>> POS Tags are: 
 [('Natural', 'JJ'), ('language', 'NN'), ('processing', 'NN')]

>> Noun Phrases are: 
 ['Natural language processing']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Natural', 'natur'), ('language', 'languag'), ('processing', 'process')]

>> Stemming using Snowball Stemmer: 
 [('Natural', 'natur'), ('language', 'languag'), ('processing', 'process')]

>> Lemmatization: 
 [('Natural', 'Natural'), ('language', 'language'), ('processing', 'processing')]



========================================== PARAGRAPH 818 ===========================================

and semantical representation of medical texts. Methods of information in medicine, 31(2),  

------------------- Sentence 1 -------------------

and semantical representation of medical texts.

>> Tokens are: 
 ['semantical', 'representation', 'medical', 'texts', '.']

>> Bigrams are: 
 [('semantical', 'representation'), ('representation', 'medical'), ('medical', 'texts'), ('texts', '.')]

>> Trigrams are: 
 [('semantical', 'representation', 'medical'), ('representation', 'medical', 'texts'), ('medical', 'texts', '.')]

>> POS Tags are: 
 [('semantical', 'JJ'), ('representation', 'NN'), ('medical', 'JJ'), ('texts', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['semantical representation', 'medical texts']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('semantical', 'semant'), ('representation', 'represent'), ('medical', 'medic'), ('texts', 'text'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('semantical', 'semant'), ('representation', 'represent'), ('medical', 'medic'), ('texts', 'text'), ('.', '.')]

>> Lemmatization: 
 [('semantical', 'semantical'), ('representation', 'representation'), ('medical', 'medical'), ('texts', 'text'), ('.', '.')]


------------------- Sentence 2 -------------------

Methods of information in medicine, 31(2),

>> Tokens are: 
 ['Methods', 'information', 'medicine', ',', '31', '(', '2', ')', ',']

>> Bigrams are: 
 [('Methods', 'information'), ('information', 'medicine'), ('medicine', ','), (',', '31'), ('31', '('), ('(', '2'), ('2', ')'), (')', ',')]

>> Trigrams are: 
 [('Methods', 'information', 'medicine'), ('information', 'medicine', ','), ('medicine', ',', '31'), (',', '31', '('), ('31', '(', '2'), ('(', '2', ')'), ('2', ')', ',')]

>> POS Tags are: 
 [('Methods', 'NNS'), ('information', 'NN'), ('medicine', 'NN'), (',', ','), ('31', 'CD'), ('(', '('), ('2', 'CD'), (')', ')'), (',', ',')]

>> Noun Phrases are: 
 ['Methods information medicine']

>> Named Entities are: 
 [('GPE', 'Methods')] 

>> Stemming using Porter Stemmer: 
 [('Methods', 'method'), ('information', 'inform'), ('medicine', 'medicin'), (',', ','), ('31', '31'), ('(', '('), ('2', '2'), (')', ')'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('Methods', 'method'), ('information', 'inform'), ('medicine', 'medicin'), (',', ','), ('31', '31'), ('(', '('), ('2', '2'), (')', ')'), (',', ',')]

>> Lemmatization: 
 [('Methods', 'Methods'), ('information', 'information'), ('medicine', 'medicine'), (',', ','), ('31', '31'), ('(', '('), ('2', '2'), (')', ')'), (',', ',')]



========================================== PARAGRAPH 819 ===========================================

117-125.  

------------------- Sentence 1 -------------------

117-125.

>> Tokens are: 
 ['117-125', '.']

>> Bigrams are: 
 [('117-125', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('117-125', 'JJ'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('117-125', '117-125'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('117-125', '117-125'), ('.', '.')]

>> Lemmatization: 
 [('117-125', '117-125'), ('.', '.')]



========================================== PARAGRAPH 820 ===========================================

[87] Lyman, M., Sager, N., Chi, E. C., Tick, L. J., Nhan, N. T., Su, Y., ... & Scherrer, J.  

------------------- Sentence 1 -------------------

[87] Lyman, M., Sager, N., Chi, E. C., Tick, L. J., Nhan, N. T., Su, Y., ... & Scherrer, J.

>> Tokens are: 
 ['[', '87', ']', 'Lyman', ',', 'M.', ',', 'Sager', ',', 'N.', ',', 'Chi', ',', 'E.', 'C.', ',', 'Tick', ',', 'L.', 'J.', ',', 'Nhan', ',', 'N.', 'T.', ',', 'Su', ',', 'Y.', ',', '...', '&', 'Scherrer', ',', 'J', '.']

>> Bigrams are: 
 [('[', '87'), ('87', ']'), (']', 'Lyman'), ('Lyman', ','), (',', 'M.'), ('M.', ','), (',', 'Sager'), ('Sager', ','), (',', 'N.'), ('N.', ','), (',', 'Chi'), ('Chi', ','), (',', 'E.'), ('E.', 'C.'), ('C.', ','), (',', 'Tick'), ('Tick', ','), (',', 'L.'), ('L.', 'J.'), ('J.', ','), (',', 'Nhan'), ('Nhan', ','), (',', 'N.'), ('N.', 'T.'), ('T.', ','), (',', 'Su'), ('Su', ','), (',', 'Y.'), ('Y.', ','), (',', '...'), ('...', '&'), ('&', 'Scherrer'), ('Scherrer', ','), (',', 'J'), ('J', '.')]

>> Trigrams are: 
 [('[', '87', ']'), ('87', ']', 'Lyman'), (']', 'Lyman', ','), ('Lyman', ',', 'M.'), (',', 'M.', ','), ('M.', ',', 'Sager'), (',', 'Sager', ','), ('Sager', ',', 'N.'), (',', 'N.', ','), ('N.', ',', 'Chi'), (',', 'Chi', ','), ('Chi', ',', 'E.'), (',', 'E.', 'C.'), ('E.', 'C.', ','), ('C.', ',', 'Tick'), (',', 'Tick', ','), ('Tick', ',', 'L.'), (',', 'L.', 'J.'), ('L.', 'J.', ','), ('J.', ',', 'Nhan'), (',', 'Nhan', ','), ('Nhan', ',', 'N.'), (',', 'N.', 'T.'), ('N.', 'T.', ','), ('T.', ',', 'Su'), (',', 'Su', ','), ('Su', ',', 'Y.'), (',', 'Y.', ','), ('Y.', ',', '...'), (',', '...', '&'), ('...', '&', 'Scherrer'), ('&', 'Scherrer', ','), ('Scherrer', ',', 'J'), (',', 'J', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('87', 'CD'), (']', 'JJ'), ('Lyman', 'NNP'), (',', ','), ('M.', 'NNP'), (',', ','), ('Sager', 'NNP'), (',', ','), ('N.', 'NNP'), (',', ','), ('Chi', 'NNP'), (',', ','), ('E.', 'NNP'), ('C.', 'NNP'), (',', ','), ('Tick', 'NNP'), (',', ','), ('L.', 'NNP'), ('J.', 'NNP'), (',', ','), ('Nhan', 'NNP'), (',', ','), ('N.', 'NNP'), ('T.', 'NNP'), (',', ','), ('Su', 'NNP'), (',', ','), ('Y.', 'NNP'), (',', ','), ('...', ':'), ('&', 'CC'), ('Scherrer', 'NNP'), (',', ','), ('J', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['] Lyman', 'M.', 'Sager', 'N.', 'Chi', 'E. C.', 'Tick', 'L. J.', 'Nhan', 'N. T.', 'Su', 'Y.', 'Scherrer', 'J']

>> Named Entities are: 
 [('PERSON', 'Lyman'), ('PERSON', 'Sager'), ('GPE', 'Chi'), ('PERSON', 'Tick'), ('PERSON', 'Nhan'), ('GPE', 'Su'), ('PERSON', 'Scherrer')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('87', '87'), (']', ']'), ('Lyman', 'lyman'), (',', ','), ('M.', 'm.'), (',', ','), ('Sager', 'sager'), (',', ','), ('N.', 'n.'), (',', ','), ('Chi', 'chi'), (',', ','), ('E.', 'e.'), ('C.', 'c.'), (',', ','), ('Tick', 'tick'), (',', ','), ('L.', 'l.'), ('J.', 'j.'), (',', ','), ('Nhan', 'nhan'), (',', ','), ('N.', 'n.'), ('T.', 't.'), (',', ','), ('Su', 'su'), (',', ','), ('Y.', 'y.'), (',', ','), ('...', '...'), ('&', '&'), ('Scherrer', 'scherrer'), (',', ','), ('J', 'j'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('87', '87'), (']', ']'), ('Lyman', 'lyman'), (',', ','), ('M.', 'm.'), (',', ','), ('Sager', 'sager'), (',', ','), ('N.', 'n.'), (',', ','), ('Chi', 'chi'), (',', ','), ('E.', 'e.'), ('C.', 'c.'), (',', ','), ('Tick', 'tick'), (',', ','), ('L.', 'l.'), ('J.', 'j.'), (',', ','), ('Nhan', 'nhan'), (',', ','), ('N.', 'n.'), ('T.', 't.'), (',', ','), ('Su', 'su'), (',', ','), ('Y.', 'y.'), (',', ','), ('...', '...'), ('&', '&'), ('Scherrer', 'scherrer'), (',', ','), ('J', 'j'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('87', '87'), (']', ']'), ('Lyman', 'Lyman'), (',', ','), ('M.', 'M.'), (',', ','), ('Sager', 'Sager'), (',', ','), ('N.', 'N.'), (',', ','), ('Chi', 'Chi'), (',', ','), ('E.', 'E.'), ('C.', 'C.'), (',', ','), ('Tick', 'Tick'), (',', ','), ('L.', 'L.'), ('J.', 'J.'), (',', ','), ('Nhan', 'Nhan'), (',', ','), ('N.', 'N.'), ('T.', 'T.'), (',', ','), ('Su', 'Su'), (',', ','), ('Y.', 'Y.'), (',', ','), ('...', '...'), ('&', '&'), ('Scherrer', 'Scherrer'), (',', ','), ('J', 'J'), ('.', '.')]



========================================== PARAGRAPH 821 ===========================================

(1989, November). Medical Language Processing for Knowledge Representation and  

------------------- Sentence 1 -------------------

(1989, November).

>> Tokens are: 
 ['(', '1989', ',', 'November', ')', '.']

>> Bigrams are: 
 [('(', '1989'), ('1989', ','), (',', 'November'), ('November', ')'), (')', '.')]

>> Trigrams are: 
 [('(', '1989', ','), ('1989', ',', 'November'), (',', 'November', ')'), ('November', ')', '.')]

>> POS Tags are: 
 [('(', '('), ('1989', 'CD'), (',', ','), ('November', 'NNP'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['November']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('1989', '1989'), (',', ','), ('November', 'novemb'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('1989', '1989'), (',', ','), ('November', 'novemb'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('(', '('), ('1989', '1989'), (',', ','), ('November', 'November'), (')', ')'), ('.', '.')]


------------------- Sentence 2 -------------------

Medical Language Processing for Knowledge Representation and

>> Tokens are: 
 ['Medical', 'Language', 'Processing', 'Knowledge', 'Representation']

>> Bigrams are: 
 [('Medical', 'Language'), ('Language', 'Processing'), ('Processing', 'Knowledge'), ('Knowledge', 'Representation')]

>> Trigrams are: 
 [('Medical', 'Language', 'Processing'), ('Language', 'Processing', 'Knowledge'), ('Processing', 'Knowledge', 'Representation')]

>> POS Tags are: 
 [('Medical', 'JJ'), ('Language', 'NNP'), ('Processing', 'NNP'), ('Knowledge', 'NNP'), ('Representation', 'NNP')]

>> Noun Phrases are: 
 ['Medical Language Processing Knowledge Representation']

>> Named Entities are: 
 [('PERSON', 'Medical'), ('ORGANIZATION', 'Language')] 

>> Stemming using Porter Stemmer: 
 [('Medical', 'medic'), ('Language', 'languag'), ('Processing', 'process'), ('Knowledge', 'knowledg'), ('Representation', 'represent')]

>> Stemming using Snowball Stemmer: 
 [('Medical', 'medic'), ('Language', 'languag'), ('Processing', 'process'), ('Knowledge', 'knowledg'), ('Representation', 'represent')]

>> Lemmatization: 
 [('Medical', 'Medical'), ('Language', 'Language'), ('Processing', 'Processing'), ('Knowledge', 'Knowledge'), ('Representation', 'Representation')]



========================================== PARAGRAPH 822 ===========================================

Retrievals. In Proceedings. Symposium on Computer Applications in Medical Care (pp. 548- 

------------------- Sentence 1 -------------------

Retrievals.

>> Tokens are: 
 ['Retrievals', '.']

>> Bigrams are: 
 [('Retrievals', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Retrievals', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['Retrievals']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Retrievals', 'retriev'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Retrievals', 'retriev'), ('.', '.')]

>> Lemmatization: 
 [('Retrievals', 'Retrievals'), ('.', '.')]


------------------- Sentence 2 -------------------

In Proceedings.

>> Tokens are: 
 ['In', 'Proceedings', '.']

>> Bigrams are: 
 [('In', 'Proceedings'), ('Proceedings', '.')]

>> Trigrams are: 
 [('In', 'Proceedings', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('Proceedings', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Proceedings']

>> Named Entities are: 
 [('GPE', 'Proceedings')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('Proceedings', 'proceed'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('Proceedings', 'proceed'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('Proceedings', 'Proceedings'), ('.', '.')]


------------------- Sentence 3 -------------------

Symposium on Computer Applications in Medical Care (pp.

>> Tokens are: 
 ['Symposium', 'Computer', 'Applications', 'Medical', 'Care', '(', 'pp', '.']

>> Bigrams are: 
 [('Symposium', 'Computer'), ('Computer', 'Applications'), ('Applications', 'Medical'), ('Medical', 'Care'), ('Care', '('), ('(', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('Symposium', 'Computer', 'Applications'), ('Computer', 'Applications', 'Medical'), ('Applications', 'Medical', 'Care'), ('Medical', 'Care', '('), ('Care', '(', 'pp'), ('(', 'pp', '.')]

>> POS Tags are: 
 [('Symposium', 'NNP'), ('Computer', 'NNP'), ('Applications', 'NNP'), ('Medical', 'NNP'), ('Care', 'NNP'), ('(', '('), ('pp', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Symposium Computer Applications Medical Care', 'pp']

>> Named Entities are: 
 [('PERSON', 'Symposium'), ('ORGANIZATION', 'Computer Applications Medical Care')] 

>> Stemming using Porter Stemmer: 
 [('Symposium', 'symposium'), ('Computer', 'comput'), ('Applications', 'applic'), ('Medical', 'medic'), ('Care', 'care'), ('(', '('), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Symposium', 'symposium'), ('Computer', 'comput'), ('Applications', 'applic'), ('Medical', 'medic'), ('Care', 'care'), ('(', '('), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('Symposium', 'Symposium'), ('Computer', 'Computer'), ('Applications', 'Applications'), ('Medical', 'Medical'), ('Care', 'Care'), ('(', '('), ('pp', 'pp'), ('.', '.')]


------------------- Sentence 4 -------------------

548-

>> Tokens are: 
 ['548-']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('548-', 'JJ')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('548-', '548-')]

>> Stemming using Snowball Stemmer: 
 [('548-', '548-')]

>> Lemmatization: 
 [('548-', '548-')]



========================================== PARAGRAPH 823 ===========================================

553). American Medical Informatics Association.  

------------------- Sentence 1 -------------------

553).

>> Tokens are: 
 ['553', ')', '.']

>> Bigrams are: 
 [('553', ')'), (')', '.')]

>> Trigrams are: 
 [('553', ')', '.')]

>> POS Tags are: 
 [('553', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('553', '553'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('553', '553'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('553', '553'), (')', ')'), ('.', '.')]


------------------- Sentence 2 -------------------

American Medical Informatics Association.

>> Tokens are: 
 ['American', 'Medical', 'Informatics', 'Association', '.']

>> Bigrams are: 
 [('American', 'Medical'), ('Medical', 'Informatics'), ('Informatics', 'Association'), ('Association', '.')]

>> Trigrams are: 
 [('American', 'Medical', 'Informatics'), ('Medical', 'Informatics', 'Association'), ('Informatics', 'Association', '.')]

>> POS Tags are: 
 [('American', 'NNP'), ('Medical', 'NNP'), ('Informatics', 'NNP'), ('Association', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['American Medical Informatics Association']

>> Named Entities are: 
 [('GPE', 'American'), ('ORGANIZATION', 'Medical Informatics Association')] 

>> Stemming using Porter Stemmer: 
 [('American', 'american'), ('Medical', 'medic'), ('Informatics', 'informat'), ('Association', 'associ'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('American', 'american'), ('Medical', 'medic'), ('Informatics', 'informat'), ('Association', 'associ'), ('.', '.')]

>> Lemmatization: 
 [('American', 'American'), ('Medical', 'Medical'), ('Informatics', 'Informatics'), ('Association', 'Association'), ('.', '.')]



========================================== PARAGRAPH 824 ===========================================

[88] Nhàn, N. T., Sager, N., Lyman, M., Tick, L. J., Borst, F., & Su, Y. (1989, November). A  

------------------- Sentence 1 -------------------

[88] Nhàn, N. T., Sager, N., Lyman, M., Tick, L. J., Borst, F., & Su, Y.

>> Tokens are: 
 ['[', '88', ']', 'Nhàn', ',', 'N.', 'T.', ',', 'Sager', ',', 'N.', ',', 'Lyman', ',', 'M.', ',', 'Tick', ',', 'L.', 'J.', ',', 'Borst', ',', 'F.', ',', '&', 'Su', ',', 'Y', '.']

>> Bigrams are: 
 [('[', '88'), ('88', ']'), (']', 'Nhàn'), ('Nhàn', ','), (',', 'N.'), ('N.', 'T.'), ('T.', ','), (',', 'Sager'), ('Sager', ','), (',', 'N.'), ('N.', ','), (',', 'Lyman'), ('Lyman', ','), (',', 'M.'), ('M.', ','), (',', 'Tick'), ('Tick', ','), (',', 'L.'), ('L.', 'J.'), ('J.', ','), (',', 'Borst'), ('Borst', ','), (',', 'F.'), ('F.', ','), (',', '&'), ('&', 'Su'), ('Su', ','), (',', 'Y'), ('Y', '.')]

>> Trigrams are: 
 [('[', '88', ']'), ('88', ']', 'Nhàn'), (']', 'Nhàn', ','), ('Nhàn', ',', 'N.'), (',', 'N.', 'T.'), ('N.', 'T.', ','), ('T.', ',', 'Sager'), (',', 'Sager', ','), ('Sager', ',', 'N.'), (',', 'N.', ','), ('N.', ',', 'Lyman'), (',', 'Lyman', ','), ('Lyman', ',', 'M.'), (',', 'M.', ','), ('M.', ',', 'Tick'), (',', 'Tick', ','), ('Tick', ',', 'L.'), (',', 'L.', 'J.'), ('L.', 'J.', ','), ('J.', ',', 'Borst'), (',', 'Borst', ','), ('Borst', ',', 'F.'), (',', 'F.', ','), ('F.', ',', '&'), (',', '&', 'Su'), ('&', 'Su', ','), ('Su', ',', 'Y'), (',', 'Y', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('88', 'CD'), (']', 'JJ'), ('Nhàn', 'NNP'), (',', ','), ('N.', 'NNP'), ('T.', 'NNP'), (',', ','), ('Sager', 'NNP'), (',', ','), ('N.', 'NNP'), (',', ','), ('Lyman', 'NNP'), (',', ','), ('M.', 'NNP'), (',', ','), ('Tick', 'NNP'), (',', ','), ('L.', 'NNP'), ('J.', 'NNP'), (',', ','), ('Borst', 'NNP'), (',', ','), ('F.', 'NNP'), (',', ','), ('&', 'CC'), ('Su', 'NNP'), (',', ','), ('Y', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['] Nhàn', 'N. T.', 'Sager', 'N.', 'Lyman', 'M.', 'Tick', 'L. J.', 'Borst', 'F.', 'Su', 'Y']

>> Named Entities are: 
 [('PERSON', 'Sager'), ('PERSON', 'Lyman'), ('PERSON', 'Tick'), ('PERSON', 'Borst')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('88', '88'), (']', ']'), ('Nhàn', 'nhàn'), (',', ','), ('N.', 'n.'), ('T.', 't.'), (',', ','), ('Sager', 'sager'), (',', ','), ('N.', 'n.'), (',', ','), ('Lyman', 'lyman'), (',', ','), ('M.', 'm.'), (',', ','), ('Tick', 'tick'), (',', ','), ('L.', 'l.'), ('J.', 'j.'), (',', ','), ('Borst', 'borst'), (',', ','), ('F.', 'f.'), (',', ','), ('&', '&'), ('Su', 'su'), (',', ','), ('Y', 'y'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('88', '88'), (']', ']'), ('Nhàn', 'nhàn'), (',', ','), ('N.', 'n.'), ('T.', 't.'), (',', ','), ('Sager', 'sager'), (',', ','), ('N.', 'n.'), (',', ','), ('Lyman', 'lyman'), (',', ','), ('M.', 'm.'), (',', ','), ('Tick', 'tick'), (',', ','), ('L.', 'l.'), ('J.', 'j.'), (',', ','), ('Borst', 'borst'), (',', ','), ('F.', 'f.'), (',', ','), ('&', '&'), ('Su', 'su'), (',', ','), ('Y', 'y'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('88', '88'), (']', ']'), ('Nhàn', 'Nhàn'), (',', ','), ('N.', 'N.'), ('T.', 'T.'), (',', ','), ('Sager', 'Sager'), (',', ','), ('N.', 'N.'), (',', ','), ('Lyman', 'Lyman'), (',', ','), ('M.', 'M.'), (',', ','), ('Tick', 'Tick'), (',', ','), ('L.', 'L.'), ('J.', 'J.'), (',', ','), ('Borst', 'Borst'), (',', ','), ('F.', 'F.'), (',', ','), ('&', '&'), ('Su', 'Su'), (',', ','), ('Y', 'Y'), ('.', '.')]


------------------- Sentence 2 -------------------

(1989, November).

>> Tokens are: 
 ['(', '1989', ',', 'November', ')', '.']

>> Bigrams are: 
 [('(', '1989'), ('1989', ','), (',', 'November'), ('November', ')'), (')', '.')]

>> Trigrams are: 
 [('(', '1989', ','), ('1989', ',', 'November'), (',', 'November', ')'), ('November', ')', '.')]

>> POS Tags are: 
 [('(', '('), ('1989', 'CD'), (',', ','), ('November', 'NNP'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['November']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('1989', '1989'), (',', ','), ('November', 'novemb'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('1989', '1989'), (',', ','), ('November', 'novemb'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('(', '('), ('1989', '1989'), (',', ','), ('November', 'November'), (')', ')'), ('.', '.')]


------------------- Sentence 3 -------------------

A

>> Tokens are: 
 ['A']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('A', 'DT')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('A', 'a')]

>> Stemming using Snowball Stemmer: 
 [('A', 'a')]

>> Lemmatization: 
 [('A', 'A')]



========================================== PARAGRAPH 825 ===========================================

Medical Language Processor for Two Indo-European Languages. In Proceedings.  

------------------- Sentence 1 -------------------

Medical Language Processor for Two Indo-European Languages.

>> Tokens are: 
 ['Medical', 'Language', 'Processor', 'Two', 'Indo-European', 'Languages', '.']

>> Bigrams are: 
 [('Medical', 'Language'), ('Language', 'Processor'), ('Processor', 'Two'), ('Two', 'Indo-European'), ('Indo-European', 'Languages'), ('Languages', '.')]

>> Trigrams are: 
 [('Medical', 'Language', 'Processor'), ('Language', 'Processor', 'Two'), ('Processor', 'Two', 'Indo-European'), ('Two', 'Indo-European', 'Languages'), ('Indo-European', 'Languages', '.')]

>> POS Tags are: 
 [('Medical', 'JJ'), ('Language', 'NNP'), ('Processor', 'NNP'), ('Two', 'CD'), ('Indo-European', 'JJ'), ('Languages', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['Medical Language Processor', 'Indo-European Languages']

>> Named Entities are: 
 [('PERSON', 'Medical'), ('ORGANIZATION', 'Language')] 

>> Stemming using Porter Stemmer: 
 [('Medical', 'medic'), ('Language', 'languag'), ('Processor', 'processor'), ('Two', 'two'), ('Indo-European', 'indo-european'), ('Languages', 'languag'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Medical', 'medic'), ('Language', 'languag'), ('Processor', 'processor'), ('Two', 'two'), ('Indo-European', 'indo-european'), ('Languages', 'languag'), ('.', '.')]

>> Lemmatization: 
 [('Medical', 'Medical'), ('Language', 'Language'), ('Processor', 'Processor'), ('Two', 'Two'), ('Indo-European', 'Indo-European'), ('Languages', 'Languages'), ('.', '.')]


------------------- Sentence 2 -------------------

In Proceedings.

>> Tokens are: 
 ['In', 'Proceedings', '.']

>> Bigrams are: 
 [('In', 'Proceedings'), ('Proceedings', '.')]

>> Trigrams are: 
 [('In', 'Proceedings', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('Proceedings', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Proceedings']

>> Named Entities are: 
 [('GPE', 'Proceedings')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('Proceedings', 'proceed'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('Proceedings', 'proceed'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('Proceedings', 'Proceedings'), ('.', '.')]



========================================== PARAGRAPH 826 ===========================================

Symposium on Computer Applications in Medical Care (pp. 554-558). American Medical  

------------------- Sentence 1 -------------------

Symposium on Computer Applications in Medical Care (pp.

>> Tokens are: 
 ['Symposium', 'Computer', 'Applications', 'Medical', 'Care', '(', 'pp', '.']

>> Bigrams are: 
 [('Symposium', 'Computer'), ('Computer', 'Applications'), ('Applications', 'Medical'), ('Medical', 'Care'), ('Care', '('), ('(', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('Symposium', 'Computer', 'Applications'), ('Computer', 'Applications', 'Medical'), ('Applications', 'Medical', 'Care'), ('Medical', 'Care', '('), ('Care', '(', 'pp'), ('(', 'pp', '.')]

>> POS Tags are: 
 [('Symposium', 'NNP'), ('Computer', 'NNP'), ('Applications', 'NNP'), ('Medical', 'NNP'), ('Care', 'NNP'), ('(', '('), ('pp', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Symposium Computer Applications Medical Care', 'pp']

>> Named Entities are: 
 [('PERSON', 'Symposium'), ('ORGANIZATION', 'Computer Applications Medical Care')] 

>> Stemming using Porter Stemmer: 
 [('Symposium', 'symposium'), ('Computer', 'comput'), ('Applications', 'applic'), ('Medical', 'medic'), ('Care', 'care'), ('(', '('), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Symposium', 'symposium'), ('Computer', 'comput'), ('Applications', 'applic'), ('Medical', 'medic'), ('Care', 'care'), ('(', '('), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('Symposium', 'Symposium'), ('Computer', 'Computer'), ('Applications', 'Applications'), ('Medical', 'Medical'), ('Care', 'Care'), ('(', '('), ('pp', 'pp'), ('.', '.')]


------------------- Sentence 2 -------------------

554-558).

>> Tokens are: 
 ['554-558', ')', '.']

>> Bigrams are: 
 [('554-558', ')'), (')', '.')]

>> Trigrams are: 
 [('554-558', ')', '.')]

>> POS Tags are: 
 [('554-558', 'JJ'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('554-558', '554-558'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('554-558', '554-558'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('554-558', '554-558'), (')', ')'), ('.', '.')]


------------------- Sentence 3 -------------------

American Medical

>> Tokens are: 
 ['American', 'Medical']

>> Bigrams are: 
 [('American', 'Medical')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('American', 'NNP'), ('Medical', 'NNP')]

>> Noun Phrases are: 
 ['American Medical']

>> Named Entities are: 
 [('GPE', 'American'), ('ORGANIZATION', 'Medical')] 

>> Stemming using Porter Stemmer: 
 [('American', 'american'), ('Medical', 'medic')]

>> Stemming using Snowball Stemmer: 
 [('American', 'american'), ('Medical', 'medic')]

>> Lemmatization: 
 [('American', 'American'), ('Medical', 'Medical')]



========================================== PARAGRAPH 827 ===========================================

Informatics Association.  

------------------- Sentence 1 -------------------

Informatics Association.

>> Tokens are: 
 ['Informatics', 'Association', '.']

>> Bigrams are: 
 [('Informatics', 'Association'), ('Association', '.')]

>> Trigrams are: 
 [('Informatics', 'Association', '.')]

>> POS Tags are: 
 [('Informatics', 'NNS'), ('Association', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Informatics Association']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Informatics', 'informat'), ('Association', 'associ'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Informatics', 'informat'), ('Association', 'associ'), ('.', '.')]

>> Lemmatization: 
 [('Informatics', 'Informatics'), ('Association', 'Association'), ('.', '.')]



========================================== PARAGRAPH 828 ===========================================

[89] Sager, N., Lyman, M., Tick, L. J., Borst, F., Nhan, N. T., Revillard, C., ... & Scherrer, J.  

------------------- Sentence 1 -------------------

[89] Sager, N., Lyman, M., Tick, L. J., Borst, F., Nhan, N. T., Revillard, C., ... & Scherrer, J.

>> Tokens are: 
 ['[', '89', ']', 'Sager', ',', 'N.', ',', 'Lyman', ',', 'M.', ',', 'Tick', ',', 'L.', 'J.', ',', 'Borst', ',', 'F.', ',', 'Nhan', ',', 'N.', 'T.', ',', 'Revillard', ',', 'C.', ',', '...', '&', 'Scherrer', ',', 'J', '.']

>> Bigrams are: 
 [('[', '89'), ('89', ']'), (']', 'Sager'), ('Sager', ','), (',', 'N.'), ('N.', ','), (',', 'Lyman'), ('Lyman', ','), (',', 'M.'), ('M.', ','), (',', 'Tick'), ('Tick', ','), (',', 'L.'), ('L.', 'J.'), ('J.', ','), (',', 'Borst'), ('Borst', ','), (',', 'F.'), ('F.', ','), (',', 'Nhan'), ('Nhan', ','), (',', 'N.'), ('N.', 'T.'), ('T.', ','), (',', 'Revillard'), ('Revillard', ','), (',', 'C.'), ('C.', ','), (',', '...'), ('...', '&'), ('&', 'Scherrer'), ('Scherrer', ','), (',', 'J'), ('J', '.')]

>> Trigrams are: 
 [('[', '89', ']'), ('89', ']', 'Sager'), (']', 'Sager', ','), ('Sager', ',', 'N.'), (',', 'N.', ','), ('N.', ',', 'Lyman'), (',', 'Lyman', ','), ('Lyman', ',', 'M.'), (',', 'M.', ','), ('M.', ',', 'Tick'), (',', 'Tick', ','), ('Tick', ',', 'L.'), (',', 'L.', 'J.'), ('L.', 'J.', ','), ('J.', ',', 'Borst'), (',', 'Borst', ','), ('Borst', ',', 'F.'), (',', 'F.', ','), ('F.', ',', 'Nhan'), (',', 'Nhan', ','), ('Nhan', ',', 'N.'), (',', 'N.', 'T.'), ('N.', 'T.', ','), ('T.', ',', 'Revillard'), (',', 'Revillard', ','), ('Revillard', ',', 'C.'), (',', 'C.', ','), ('C.', ',', '...'), (',', '...', '&'), ('...', '&', 'Scherrer'), ('&', 'Scherrer', ','), ('Scherrer', ',', 'J'), (',', 'J', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('89', 'CD'), (']', 'JJ'), ('Sager', 'NNP'), (',', ','), ('N.', 'NNP'), (',', ','), ('Lyman', 'NNP'), (',', ','), ('M.', 'NNP'), (',', ','), ('Tick', 'NNP'), (',', ','), ('L.', 'NNP'), ('J.', 'NNP'), (',', ','), ('Borst', 'NNP'), (',', ','), ('F.', 'NNP'), (',', ','), ('Nhan', 'NNP'), (',', ','), ('N.', 'NNP'), ('T.', 'NNP'), (',', ','), ('Revillard', 'NNP'), (',', ','), ('C.', 'NNP'), (',', ','), ('...', ':'), ('&', 'CC'), ('Scherrer', 'NNP'), (',', ','), ('J', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['] Sager', 'N.', 'Lyman', 'M.', 'Tick', 'L. J.', 'Borst', 'F.', 'Nhan', 'N. T.', 'Revillard', 'C.', 'Scherrer', 'J']

>> Named Entities are: 
 [('PERSON', 'Lyman'), ('PERSON', 'Tick'), ('PERSON', 'Borst'), ('PERSON', 'Nhan'), ('PERSON', 'Revillard'), ('PERSON', 'Scherrer')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('89', '89'), (']', ']'), ('Sager', 'sager'), (',', ','), ('N.', 'n.'), (',', ','), ('Lyman', 'lyman'), (',', ','), ('M.', 'm.'), (',', ','), ('Tick', 'tick'), (',', ','), ('L.', 'l.'), ('J.', 'j.'), (',', ','), ('Borst', 'borst'), (',', ','), ('F.', 'f.'), (',', ','), ('Nhan', 'nhan'), (',', ','), ('N.', 'n.'), ('T.', 't.'), (',', ','), ('Revillard', 'revillard'), (',', ','), ('C.', 'c.'), (',', ','), ('...', '...'), ('&', '&'), ('Scherrer', 'scherrer'), (',', ','), ('J', 'j'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('89', '89'), (']', ']'), ('Sager', 'sager'), (',', ','), ('N.', 'n.'), (',', ','), ('Lyman', 'lyman'), (',', ','), ('M.', 'm.'), (',', ','), ('Tick', 'tick'), (',', ','), ('L.', 'l.'), ('J.', 'j.'), (',', ','), ('Borst', 'borst'), (',', ','), ('F.', 'f.'), (',', ','), ('Nhan', 'nhan'), (',', ','), ('N.', 'n.'), ('T.', 't.'), (',', ','), ('Revillard', 'revillard'), (',', ','), ('C.', 'c.'), (',', ','), ('...', '...'), ('&', '&'), ('Scherrer', 'scherrer'), (',', ','), ('J', 'j'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('89', '89'), (']', ']'), ('Sager', 'Sager'), (',', ','), ('N.', 'N.'), (',', ','), ('Lyman', 'Lyman'), (',', ','), ('M.', 'M.'), (',', ','), ('Tick', 'Tick'), (',', ','), ('L.', 'L.'), ('J.', 'J.'), (',', ','), ('Borst', 'Borst'), (',', ','), ('F.', 'F.'), (',', ','), ('Nhan', 'Nhan'), (',', ','), ('N.', 'N.'), ('T.', 'T.'), (',', ','), ('Revillard', 'Revillard'), (',', ','), ('C.', 'C.'), (',', ','), ('...', '...'), ('&', '&'), ('Scherrer', 'Scherrer'), (',', ','), ('J', 'J'), ('.', '.')]



========================================== PARAGRAPH 829 ===========================================

R. (1989). Adapting a medical language processor from English to French. Medinfo, 89, 795- 

------------------- Sentence 1 -------------------

R. (1989).

>> Tokens are: 
 ['R.', '(', '1989', ')', '.']

>> Bigrams are: 
 [('R.', '('), ('(', '1989'), ('1989', ')'), (')', '.')]

>> Trigrams are: 
 [('R.', '(', '1989'), ('(', '1989', ')'), ('1989', ')', '.')]

>> POS Tags are: 
 [('R.', 'NNP'), ('(', '('), ('1989', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['R.']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('R.', 'r.'), ('(', '('), ('1989', '1989'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('R.', 'r.'), ('(', '('), ('1989', '1989'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('R.', 'R.'), ('(', '('), ('1989', '1989'), (')', ')'), ('.', '.')]


------------------- Sentence 2 -------------------

Adapting a medical language processor from English to French.

>> Tokens are: 
 ['Adapting', 'medical', 'language', 'processor', 'English', 'French', '.']

>> Bigrams are: 
 [('Adapting', 'medical'), ('medical', 'language'), ('language', 'processor'), ('processor', 'English'), ('English', 'French'), ('French', '.')]

>> Trigrams are: 
 [('Adapting', 'medical', 'language'), ('medical', 'language', 'processor'), ('language', 'processor', 'English'), ('processor', 'English', 'French'), ('English', 'French', '.')]

>> POS Tags are: 
 [('Adapting', 'NNP'), ('medical', 'JJ'), ('language', 'NN'), ('processor', 'NN'), ('English', 'NNP'), ('French', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Adapting', 'medical language processor English French']

>> Named Entities are: 
 [('PERSON', 'English French')] 

>> Stemming using Porter Stemmer: 
 [('Adapting', 'adapt'), ('medical', 'medic'), ('language', 'languag'), ('processor', 'processor'), ('English', 'english'), ('French', 'french'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Adapting', 'adapt'), ('medical', 'medic'), ('language', 'languag'), ('processor', 'processor'), ('English', 'english'), ('French', 'french'), ('.', '.')]

>> Lemmatization: 
 [('Adapting', 'Adapting'), ('medical', 'medical'), ('language', 'language'), ('processor', 'processor'), ('English', 'English'), ('French', 'French'), ('.', '.')]


------------------- Sentence 3 -------------------

Medinfo, 89, 795-

>> Tokens are: 
 ['Medinfo', ',', '89', ',', '795-']

>> Bigrams are: 
 [('Medinfo', ','), (',', '89'), ('89', ','), (',', '795-')]

>> Trigrams are: 
 [('Medinfo', ',', '89'), (',', '89', ','), ('89', ',', '795-')]

>> POS Tags are: 
 [('Medinfo', 'NNP'), (',', ','), ('89', 'CD'), (',', ','), ('795-', 'JJ')]

>> Noun Phrases are: 
 ['Medinfo']

>> Named Entities are: 
 [('GPE', 'Medinfo')] 

>> Stemming using Porter Stemmer: 
 [('Medinfo', 'medinfo'), (',', ','), ('89', '89'), (',', ','), ('795-', '795-')]

>> Stemming using Snowball Stemmer: 
 [('Medinfo', 'medinfo'), (',', ','), ('89', '89'), (',', ','), ('795-', '795-')]

>> Lemmatization: 
 [('Medinfo', 'Medinfo'), (',', ','), ('89', '89'), (',', ','), ('795-', '795-')]



========================================== PARAGRAPH 830 ===========================================

799.  

------------------- Sentence 1 -------------------

799.

>> Tokens are: 
 ['799', '.']

>> Bigrams are: 
 [('799', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('799', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('799', '799'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('799', '799'), ('.', '.')]

>> Lemmatization: 
 [('799', '799'), ('.', '.')]



========================================== PARAGRAPH 831 ===========================================

[90] Borst, F., Sager, N., Nhàn, N. T., Su, Y., Lyman, M., Tick, L. J., ... & Scherrer, J. R.  

------------------- Sentence 1 -------------------

[90] Borst, F., Sager, N., Nhàn, N. T., Su, Y., Lyman, M., Tick, L. J., ... & Scherrer, J. R.

>> Tokens are: 
 ['[', '90', ']', 'Borst', ',', 'F.', ',', 'Sager', ',', 'N.', ',', 'Nhàn', ',', 'N.', 'T.', ',', 'Su', ',', 'Y.', ',', 'Lyman', ',', 'M.', ',', 'Tick', ',', 'L.', 'J.', ',', '...', '&', 'Scherrer', ',', 'J.', 'R', '.']

>> Bigrams are: 
 [('[', '90'), ('90', ']'), (']', 'Borst'), ('Borst', ','), (',', 'F.'), ('F.', ','), (',', 'Sager'), ('Sager', ','), (',', 'N.'), ('N.', ','), (',', 'Nhàn'), ('Nhàn', ','), (',', 'N.'), ('N.', 'T.'), ('T.', ','), (',', 'Su'), ('Su', ','), (',', 'Y.'), ('Y.', ','), (',', 'Lyman'), ('Lyman', ','), (',', 'M.'), ('M.', ','), (',', 'Tick'), ('Tick', ','), (',', 'L.'), ('L.', 'J.'), ('J.', ','), (',', '...'), ('...', '&'), ('&', 'Scherrer'), ('Scherrer', ','), (',', 'J.'), ('J.', 'R'), ('R', '.')]

>> Trigrams are: 
 [('[', '90', ']'), ('90', ']', 'Borst'), (']', 'Borst', ','), ('Borst', ',', 'F.'), (',', 'F.', ','), ('F.', ',', 'Sager'), (',', 'Sager', ','), ('Sager', ',', 'N.'), (',', 'N.', ','), ('N.', ',', 'Nhàn'), (',', 'Nhàn', ','), ('Nhàn', ',', 'N.'), (',', 'N.', 'T.'), ('N.', 'T.', ','), ('T.', ',', 'Su'), (',', 'Su', ','), ('Su', ',', 'Y.'), (',', 'Y.', ','), ('Y.', ',', 'Lyman'), (',', 'Lyman', ','), ('Lyman', ',', 'M.'), (',', 'M.', ','), ('M.', ',', 'Tick'), (',', 'Tick', ','), ('Tick', ',', 'L.'), (',', 'L.', 'J.'), ('L.', 'J.', ','), ('J.', ',', '...'), (',', '...', '&'), ('...', '&', 'Scherrer'), ('&', 'Scherrer', ','), ('Scherrer', ',', 'J.'), (',', 'J.', 'R'), ('J.', 'R', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('90', 'CD'), (']', 'JJ'), ('Borst', 'NNP'), (',', ','), ('F.', 'NNP'), (',', ','), ('Sager', 'NNP'), (',', ','), ('N.', 'NNP'), (',', ','), ('Nhàn', 'NNP'), (',', ','), ('N.', 'NNP'), ('T.', 'NNP'), (',', ','), ('Su', 'NNP'), (',', ','), ('Y.', 'NNP'), (',', ','), ('Lyman', 'NNP'), (',', ','), ('M.', 'NNP'), (',', ','), ('Tick', 'NNP'), (',', ','), ('L.', 'NNP'), ('J.', 'NNP'), (',', ','), ('...', ':'), ('&', 'CC'), ('Scherrer', 'NNP'), (',', ','), ('J.', 'NNP'), ('R', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['] Borst', 'F.', 'Sager', 'N.', 'Nhàn', 'N. T.', 'Su', 'Y.', 'Lyman', 'M.', 'Tick', 'L. J.', 'Scherrer', 'J. R']

>> Named Entities are: 
 [('PERSON', 'Sager'), ('PERSON', 'Nhàn'), ('GPE', 'Su'), ('PERSON', 'Lyman'), ('PERSON', 'Tick'), ('PERSON', 'Scherrer'), ('PERSON', 'J. R')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('90', '90'), (']', ']'), ('Borst', 'borst'), (',', ','), ('F.', 'f.'), (',', ','), ('Sager', 'sager'), (',', ','), ('N.', 'n.'), (',', ','), ('Nhàn', 'nhàn'), (',', ','), ('N.', 'n.'), ('T.', 't.'), (',', ','), ('Su', 'su'), (',', ','), ('Y.', 'y.'), (',', ','), ('Lyman', 'lyman'), (',', ','), ('M.', 'm.'), (',', ','), ('Tick', 'tick'), (',', ','), ('L.', 'l.'), ('J.', 'j.'), (',', ','), ('...', '...'), ('&', '&'), ('Scherrer', 'scherrer'), (',', ','), ('J.', 'j.'), ('R', 'r'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('90', '90'), (']', ']'), ('Borst', 'borst'), (',', ','), ('F.', 'f.'), (',', ','), ('Sager', 'sager'), (',', ','), ('N.', 'n.'), (',', ','), ('Nhàn', 'nhàn'), (',', ','), ('N.', 'n.'), ('T.', 't.'), (',', ','), ('Su', 'su'), (',', ','), ('Y.', 'y.'), (',', ','), ('Lyman', 'lyman'), (',', ','), ('M.', 'm.'), (',', ','), ('Tick', 'tick'), (',', ','), ('L.', 'l.'), ('J.', 'j.'), (',', ','), ('...', '...'), ('&', '&'), ('Scherrer', 'scherrer'), (',', ','), ('J.', 'j.'), ('R', 'r'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('90', '90'), (']', ']'), ('Borst', 'Borst'), (',', ','), ('F.', 'F.'), (',', ','), ('Sager', 'Sager'), (',', ','), ('N.', 'N.'), (',', ','), ('Nhàn', 'Nhàn'), (',', ','), ('N.', 'N.'), ('T.', 'T.'), (',', ','), ('Su', 'Su'), (',', ','), ('Y.', 'Y.'), (',', ','), ('Lyman', 'Lyman'), (',', ','), ('M.', 'M.'), (',', ','), ('Tick', 'Tick'), (',', ','), ('L.', 'L.'), ('J.', 'J.'), (',', ','), ('...', '...'), ('&', '&'), ('Scherrer', 'Scherrer'), (',', ','), ('J.', 'J.'), ('R', 'R'), ('.', '.')]



========================================== PARAGRAPH 832 ===========================================

(1989). Analyse automatique de comptes rendus d'hospitalisation. In Degoulet P, Stephan JC,  

------------------- Sentence 1 -------------------

(1989).

>> Tokens are: 
 ['(', '1989', ')', '.']

>> Bigrams are: 
 [('(', '1989'), ('1989', ')'), (')', '.')]

>> Trigrams are: 
 [('(', '1989', ')'), ('1989', ')', '.')]

>> POS Tags are: 
 [('(', '('), ('1989', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('1989', '1989'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('1989', '1989'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('(', '('), ('1989', '1989'), (')', ')'), ('.', '.')]


------------------- Sentence 2 -------------------

Analyse automatique de comptes rendus d'hospitalisation.

>> Tokens are: 
 ['Analyse', 'automatique', 'de', 'comptes', 'rendus', "d'hospitalisation", '.']

>> Bigrams are: 
 [('Analyse', 'automatique'), ('automatique', 'de'), ('de', 'comptes'), ('comptes', 'rendus'), ('rendus', "d'hospitalisation"), ("d'hospitalisation", '.')]

>> Trigrams are: 
 [('Analyse', 'automatique', 'de'), ('automatique', 'de', 'comptes'), ('de', 'comptes', 'rendus'), ('comptes', 'rendus', "d'hospitalisation"), ('rendus', "d'hospitalisation", '.')]

>> POS Tags are: 
 [('Analyse', 'NNP'), ('automatique', 'NN'), ('de', 'FW'), ('comptes', 'VBZ'), ('rendus', 'JJ'), ("d'hospitalisation", 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Analyse automatique', "rendus d'hospitalisation"]

>> Named Entities are: 
 [('GPE', 'Analyse')] 

>> Stemming using Porter Stemmer: 
 [('Analyse', 'analys'), ('automatique', 'automatiqu'), ('de', 'de'), ('comptes', 'compt'), ('rendus', 'rendu'), ("d'hospitalisation", "d'hospitalis"), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Analyse', 'analys'), ('automatique', 'automatiqu'), ('de', 'de'), ('comptes', 'compt'), ('rendus', 'rendus'), ("d'hospitalisation", "d'hospitalis"), ('.', '.')]

>> Lemmatization: 
 [('Analyse', 'Analyse'), ('automatique', 'automatique'), ('de', 'de'), ('comptes', 'comptes'), ('rendus', 'rendus'), ("d'hospitalisation", "d'hospitalisation"), ('.', '.')]


------------------- Sentence 3 -------------------

In Degoulet P, Stephan JC,

>> Tokens are: 
 ['In', 'Degoulet', 'P', ',', 'Stephan', 'JC', ',']

>> Bigrams are: 
 [('In', 'Degoulet'), ('Degoulet', 'P'), ('P', ','), (',', 'Stephan'), ('Stephan', 'JC'), ('JC', ',')]

>> Trigrams are: 
 [('In', 'Degoulet', 'P'), ('Degoulet', 'P', ','), ('P', ',', 'Stephan'), (',', 'Stephan', 'JC'), ('Stephan', 'JC', ',')]

>> POS Tags are: 
 [('In', 'IN'), ('Degoulet', 'NNP'), ('P', 'NNP'), (',', ','), ('Stephan', 'NNP'), ('JC', 'NNP'), (',', ',')]

>> Noun Phrases are: 
 ['Degoulet P', 'Stephan JC']

>> Named Entities are: 
 [('GPE', 'Degoulet'), ('PERSON', 'Stephan JC')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('Degoulet', 'degoulet'), ('P', 'p'), (',', ','), ('Stephan', 'stephan'), ('JC', 'jc'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('Degoulet', 'degoulet'), ('P', 'p'), (',', ','), ('Stephan', 'stephan'), ('JC', 'jc'), (',', ',')]

>> Lemmatization: 
 [('In', 'In'), ('Degoulet', 'Degoulet'), ('P', 'P'), (',', ','), ('Stephan', 'Stephan'), ('JC', 'JC'), (',', ',')]



========================================== PARAGRAPH 833 ===========================================

Venot A, Yvon PJ, rédacteurs. Informatique et Santé, Informatique et Gestion des Unités de  

------------------- Sentence 1 -------------------

Venot A, Yvon PJ, rédacteurs.

>> Tokens are: 
 ['Venot', 'A', ',', 'Yvon', 'PJ', ',', 'rédacteurs', '.']

>> Bigrams are: 
 [('Venot', 'A'), ('A', ','), (',', 'Yvon'), ('Yvon', 'PJ'), ('PJ', ','), (',', 'rédacteurs'), ('rédacteurs', '.')]

>> Trigrams are: 
 [('Venot', 'A', ','), ('A', ',', 'Yvon'), (',', 'Yvon', 'PJ'), ('Yvon', 'PJ', ','), ('PJ', ',', 'rédacteurs'), (',', 'rédacteurs', '.')]

>> POS Tags are: 
 [('Venot', 'NNP'), ('A', 'NNP'), (',', ','), ('Yvon', 'NNP'), ('PJ', 'NNP'), (',', ','), ('rédacteurs', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Venot A', 'Yvon PJ', 'rédacteurs']

>> Named Entities are: 
 [('PERSON', 'Venot'), ('PERSON', 'Yvon PJ')] 

>> Stemming using Porter Stemmer: 
 [('Venot', 'venot'), ('A', 'a'), (',', ','), ('Yvon', 'yvon'), ('PJ', 'pj'), (',', ','), ('rédacteurs', 'rédacteur'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Venot', 'venot'), ('A', 'a'), (',', ','), ('Yvon', 'yvon'), ('PJ', 'pj'), (',', ','), ('rédacteurs', 'rédacteur'), ('.', '.')]

>> Lemmatization: 
 [('Venot', 'Venot'), ('A', 'A'), (',', ','), ('Yvon', 'Yvon'), ('PJ', 'PJ'), (',', ','), ('rédacteurs', 'rédacteurs'), ('.', '.')]


------------------- Sentence 2 -------------------

Informatique et Santé, Informatique et Gestion des Unités de

>> Tokens are: 
 ['Informatique', 'et', 'Santé', ',', 'Informatique', 'et', 'Gestion', 'des', 'Unités', 'de']

>> Bigrams are: 
 [('Informatique', 'et'), ('et', 'Santé'), ('Santé', ','), (',', 'Informatique'), ('Informatique', 'et'), ('et', 'Gestion'), ('Gestion', 'des'), ('des', 'Unités'), ('Unités', 'de')]

>> Trigrams are: 
 [('Informatique', 'et', 'Santé'), ('et', 'Santé', ','), ('Santé', ',', 'Informatique'), (',', 'Informatique', 'et'), ('Informatique', 'et', 'Gestion'), ('et', 'Gestion', 'des'), ('Gestion', 'des', 'Unités'), ('des', 'Unités', 'de')]

>> POS Tags are: 
 [('Informatique', 'NNP'), ('et', 'CC'), ('Santé', 'NNP'), (',', ','), ('Informatique', 'NNP'), ('et', 'CC'), ('Gestion', 'NNP'), ('des', 'FW'), ('Unités', 'NNP'), ('de', 'FW')]

>> Noun Phrases are: 
 ['Informatique', 'Santé', 'Informatique', 'Gestion', 'Unités']

>> Named Entities are: 
 [('GPE', 'Informatique'), ('PERSON', 'Santé'), ('PERSON', 'Informatique'), ('PERSON', 'Unités')] 

>> Stemming using Porter Stemmer: 
 [('Informatique', 'informatiqu'), ('et', 'et'), ('Santé', 'santé'), (',', ','), ('Informatique', 'informatiqu'), ('et', 'et'), ('Gestion', 'gestion'), ('des', 'de'), ('Unités', 'unité'), ('de', 'de')]

>> Stemming using Snowball Stemmer: 
 [('Informatique', 'informatiqu'), ('et', 'et'), ('Santé', 'santé'), (',', ','), ('Informatique', 'informatiqu'), ('et', 'et'), ('Gestion', 'gestion'), ('des', 'des'), ('Unités', 'unité'), ('de', 'de')]

>> Lemmatization: 
 [('Informatique', 'Informatique'), ('et', 'et'), ('Santé', 'Santé'), (',', ','), ('Informatique', 'Informatique'), ('et', 'et'), ('Gestion', 'Gestion'), ('des', 'de'), ('Unités', 'Unités'), ('de', 'de')]



========================================== PARAGRAPH 834 ===========================================

Soins, Comptes Rendus du Colloque AIM-IF, Paris (pp. 246-56). [5]  

------------------- Sentence 1 -------------------

Soins, Comptes Rendus du Colloque AIM-IF, Paris (pp.

>> Tokens are: 
 ['Soins', ',', 'Comptes', 'Rendus', 'du', 'Colloque', 'AIM-IF', ',', 'Paris', '(', 'pp', '.']

>> Bigrams are: 
 [('Soins', ','), (',', 'Comptes'), ('Comptes', 'Rendus'), ('Rendus', 'du'), ('du', 'Colloque'), ('Colloque', 'AIM-IF'), ('AIM-IF', ','), (',', 'Paris'), ('Paris', '('), ('(', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('Soins', ',', 'Comptes'), (',', 'Comptes', 'Rendus'), ('Comptes', 'Rendus', 'du'), ('Rendus', 'du', 'Colloque'), ('du', 'Colloque', 'AIM-IF'), ('Colloque', 'AIM-IF', ','), ('AIM-IF', ',', 'Paris'), (',', 'Paris', '('), ('Paris', '(', 'pp'), ('(', 'pp', '.')]

>> POS Tags are: 
 [('Soins', 'NNS'), (',', ','), ('Comptes', 'NNP'), ('Rendus', 'NNP'), ('du', 'NN'), ('Colloque', 'NNP'), ('AIM-IF', 'NNP'), (',', ','), ('Paris', 'NNP'), ('(', '('), ('pp', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Soins', 'Comptes Rendus du Colloque AIM-IF', 'Paris', 'pp']

>> Named Entities are: 
 [('ORGANIZATION', 'Comptes Rendus'), ('PERSON', 'Colloque AIM-IF'), ('GPE', 'Paris')] 

>> Stemming using Porter Stemmer: 
 [('Soins', 'soin'), (',', ','), ('Comptes', 'compt'), ('Rendus', 'rendu'), ('du', 'du'), ('Colloque', 'colloqu'), ('AIM-IF', 'aim-if'), (',', ','), ('Paris', 'pari'), ('(', '('), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Soins', 'soin'), (',', ','), ('Comptes', 'compt'), ('Rendus', 'rendus'), ('du', 'du'), ('Colloque', 'colloqu'), ('AIM-IF', 'aim-if'), (',', ','), ('Paris', 'pari'), ('(', '('), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('Soins', 'Soins'), (',', ','), ('Comptes', 'Comptes'), ('Rendus', 'Rendus'), ('du', 'du'), ('Colloque', 'Colloque'), ('AIM-IF', 'AIM-IF'), (',', ','), ('Paris', 'Paris'), ('(', '('), ('pp', 'pp'), ('.', '.')]


------------------- Sentence 2 -------------------

246-56).

>> Tokens are: 
 ['246-56', ')', '.']

>> Bigrams are: 
 [('246-56', ')'), (')', '.')]

>> Trigrams are: 
 [('246-56', ')', '.')]

>> POS Tags are: 
 [('246-56', 'JJ'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('246-56', '246-56'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('246-56', '246-56'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('246-56', '246-56'), (')', ')'), ('.', '.')]


------------------- Sentence 3 -------------------

[5]

>> Tokens are: 
 ['[', '5', ']']

>> Bigrams are: 
 [('[', '5'), ('5', ']')]

>> Trigrams are: 
 [('[', '5', ']')]

>> POS Tags are: 
 [('[', 'RB'), ('5', 'CD'), (']', 'NNS')]

>> Noun Phrases are: 
 [']']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('5', '5'), (']', ']')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('5', '5'), (']', ']')]

>> Lemmatization: 
 [('[', '['), ('5', '5'), (']', ']')]



========================================== PARAGRAPH 835 ===========================================

[91] Baud, R. H., Rassinoux, A. M., & Scherrer, J. R. (1991). Knowledge representation of  

------------------- Sentence 1 -------------------

[91] Baud, R. H., Rassinoux, A. M., & Scherrer, J. R. (1991).

>> Tokens are: 
 ['[', '91', ']', 'Baud', ',', 'R.', 'H.', ',', 'Rassinoux', ',', 'A.', 'M.', ',', '&', 'Scherrer', ',', 'J.', 'R.', '(', '1991', ')', '.']

>> Bigrams are: 
 [('[', '91'), ('91', ']'), (']', 'Baud'), ('Baud', ','), (',', 'R.'), ('R.', 'H.'), ('H.', ','), (',', 'Rassinoux'), ('Rassinoux', ','), (',', 'A.'), ('A.', 'M.'), ('M.', ','), (',', '&'), ('&', 'Scherrer'), ('Scherrer', ','), (',', 'J.'), ('J.', 'R.'), ('R.', '('), ('(', '1991'), ('1991', ')'), (')', '.')]

>> Trigrams are: 
 [('[', '91', ']'), ('91', ']', 'Baud'), (']', 'Baud', ','), ('Baud', ',', 'R.'), (',', 'R.', 'H.'), ('R.', 'H.', ','), ('H.', ',', 'Rassinoux'), (',', 'Rassinoux', ','), ('Rassinoux', ',', 'A.'), (',', 'A.', 'M.'), ('A.', 'M.', ','), ('M.', ',', '&'), (',', '&', 'Scherrer'), ('&', 'Scherrer', ','), ('Scherrer', ',', 'J.'), (',', 'J.', 'R.'), ('J.', 'R.', '('), ('R.', '(', '1991'), ('(', '1991', ')'), ('1991', ')', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('91', 'CD'), (']', 'JJ'), ('Baud', 'NNP'), (',', ','), ('R.', 'NNP'), ('H.', 'NNP'), (',', ','), ('Rassinoux', 'NNP'), (',', ','), ('A.', 'NNP'), ('M.', 'NNP'), (',', ','), ('&', 'CC'), ('Scherrer', 'NNP'), (',', ','), ('J.', 'NNP'), ('R.', 'NNP'), ('(', '('), ('1991', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['] Baud', 'R. H.', 'Rassinoux', 'A. M.', 'Scherrer', 'J. R.']

>> Named Entities are: 
 [('PERSON', 'Rassinoux'), ('PERSON', 'Scherrer'), ('PERSON', 'J. R.')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('91', '91'), (']', ']'), ('Baud', 'baud'), (',', ','), ('R.', 'r.'), ('H.', 'h.'), (',', ','), ('Rassinoux', 'rassinoux'), (',', ','), ('A.', 'a.'), ('M.', 'm.'), (',', ','), ('&', '&'), ('Scherrer', 'scherrer'), (',', ','), ('J.', 'j.'), ('R.', 'r.'), ('(', '('), ('1991', '1991'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('91', '91'), (']', ']'), ('Baud', 'baud'), (',', ','), ('R.', 'r.'), ('H.', 'h.'), (',', ','), ('Rassinoux', 'rassinoux'), (',', ','), ('A.', 'a.'), ('M.', 'm.'), (',', ','), ('&', '&'), ('Scherrer', 'scherrer'), (',', ','), ('J.', 'j.'), ('R.', 'r.'), ('(', '('), ('1991', '1991'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('91', '91'), (']', ']'), ('Baud', 'Baud'), (',', ','), ('R.', 'R.'), ('H.', 'H.'), (',', ','), ('Rassinoux', 'Rassinoux'), (',', ','), ('A.', 'A.'), ('M.', 'M.'), (',', ','), ('&', '&'), ('Scherrer', 'Scherrer'), (',', ','), ('J.', 'J.'), ('R.', 'R.'), ('(', '('), ('1991', '1991'), (')', ')'), ('.', '.')]


------------------- Sentence 2 -------------------

Knowledge representation of

>> Tokens are: 
 ['Knowledge', 'representation']

>> Bigrams are: 
 [('Knowledge', 'representation')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Knowledge', 'NNP'), ('representation', 'NN')]

>> Noun Phrases are: 
 ['Knowledge representation']

>> Named Entities are: 
 [('GPE', 'Knowledge')] 

>> Stemming using Porter Stemmer: 
 [('Knowledge', 'knowledg'), ('representation', 'represent')]

>> Stemming using Snowball Stemmer: 
 [('Knowledge', 'knowledg'), ('representation', 'represent')]

>> Lemmatization: 
 [('Knowledge', 'Knowledge'), ('representation', 'representation')]



========================================== PARAGRAPH 836 ===========================================

discharge summaries. In AIME 91 (pp. 173-182). Springer Berlin Heidelberg.  

------------------- Sentence 1 -------------------

discharge summaries.

>> Tokens are: 
 ['discharge', 'summaries', '.']

>> Bigrams are: 
 [('discharge', 'summaries'), ('summaries', '.')]

>> Trigrams are: 
 [('discharge', 'summaries', '.')]

>> POS Tags are: 
 [('discharge', 'NN'), ('summaries', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['discharge summaries']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('discharge', 'discharg'), ('summaries', 'summari'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('discharge', 'discharg'), ('summaries', 'summari'), ('.', '.')]

>> Lemmatization: 
 [('discharge', 'discharge'), ('summaries', 'summary'), ('.', '.')]


------------------- Sentence 2 -------------------

In AIME 91 (pp.

>> Tokens are: 
 ['In', 'AIME', '91', '(', 'pp', '.']

>> Bigrams are: 
 [('In', 'AIME'), ('AIME', '91'), ('91', '('), ('(', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('In', 'AIME', '91'), ('AIME', '91', '('), ('91', '(', 'pp'), ('(', 'pp', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('AIME', 'NNP'), ('91', 'CD'), ('(', '('), ('pp', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['AIME', 'pp']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('AIME', 'aim'), ('91', '91'), ('(', '('), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('AIME', 'aim'), ('91', '91'), ('(', '('), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('AIME', 'AIME'), ('91', '91'), ('(', '('), ('pp', 'pp'), ('.', '.')]


------------------- Sentence 3 -------------------

173-182).

>> Tokens are: 
 ['173-182', ')', '.']

>> Bigrams are: 
 [('173-182', ')'), (')', '.')]

>> Trigrams are: 
 [('173-182', ')', '.')]

>> POS Tags are: 
 [('173-182', 'JJ'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('173-182', '173-182'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('173-182', '173-182'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('173-182', '173-182'), (')', ')'), ('.', '.')]


------------------- Sentence 4 -------------------

Springer Berlin Heidelberg.

>> Tokens are: 
 ['Springer', 'Berlin', 'Heidelberg', '.']

>> Bigrams are: 
 [('Springer', 'Berlin'), ('Berlin', 'Heidelberg'), ('Heidelberg', '.')]

>> Trigrams are: 
 [('Springer', 'Berlin', 'Heidelberg'), ('Berlin', 'Heidelberg', '.')]

>> POS Tags are: 
 [('Springer', 'NNP'), ('Berlin', 'NNP'), ('Heidelberg', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Springer Berlin Heidelberg']

>> Named Entities are: 
 [('PERSON', 'Springer'), ('PERSON', 'Berlin Heidelberg')] 

>> Stemming using Porter Stemmer: 
 [('Springer', 'springer'), ('Berlin', 'berlin'), ('Heidelberg', 'heidelberg'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Springer', 'springer'), ('Berlin', 'berlin'), ('Heidelberg', 'heidelberg'), ('.', '.')]

>> Lemmatization: 
 [('Springer', 'Springer'), ('Berlin', 'Berlin'), ('Heidelberg', 'Heidelberg'), ('.', '.')]



========================================== PARAGRAPH 837 ===========================================

[92] Baud, R. H., Alpay, L., & Lovis, C. (1994). Let’s Meet the Users with Natural Language  

------------------- Sentence 1 -------------------

[92] Baud, R. H., Alpay, L., & Lovis, C. (1994).

>> Tokens are: 
 ['[', '92', ']', 'Baud', ',', 'R.', 'H.', ',', 'Alpay', ',', 'L.', ',', '&', 'Lovis', ',', 'C.', '(', '1994', ')', '.']

>> Bigrams are: 
 [('[', '92'), ('92', ']'), (']', 'Baud'), ('Baud', ','), (',', 'R.'), ('R.', 'H.'), ('H.', ','), (',', 'Alpay'), ('Alpay', ','), (',', 'L.'), ('L.', ','), (',', '&'), ('&', 'Lovis'), ('Lovis', ','), (',', 'C.'), ('C.', '('), ('(', '1994'), ('1994', ')'), (')', '.')]

>> Trigrams are: 
 [('[', '92', ']'), ('92', ']', 'Baud'), (']', 'Baud', ','), ('Baud', ',', 'R.'), (',', 'R.', 'H.'), ('R.', 'H.', ','), ('H.', ',', 'Alpay'), (',', 'Alpay', ','), ('Alpay', ',', 'L.'), (',', 'L.', ','), ('L.', ',', '&'), (',', '&', 'Lovis'), ('&', 'Lovis', ','), ('Lovis', ',', 'C.'), (',', 'C.', '('), ('C.', '(', '1994'), ('(', '1994', ')'), ('1994', ')', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('92', 'CD'), (']', 'JJ'), ('Baud', 'NNP'), (',', ','), ('R.', 'NNP'), ('H.', 'NNP'), (',', ','), ('Alpay', 'NNP'), (',', ','), ('L.', 'NNP'), (',', ','), ('&', 'CC'), ('Lovis', 'NNP'), (',', ','), ('C.', 'NNP'), ('(', '('), ('1994', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['] Baud', 'R. H.', 'Alpay', 'L.', 'Lovis', 'C.']

>> Named Entities are: 
 [('PERSON', 'Alpay'), ('PERSON', 'Lovis')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('92', '92'), (']', ']'), ('Baud', 'baud'), (',', ','), ('R.', 'r.'), ('H.', 'h.'), (',', ','), ('Alpay', 'alpay'), (',', ','), ('L.', 'l.'), (',', ','), ('&', '&'), ('Lovis', 'lovi'), (',', ','), ('C.', 'c.'), ('(', '('), ('1994', '1994'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('92', '92'), (']', ']'), ('Baud', 'baud'), (',', ','), ('R.', 'r.'), ('H.', 'h.'), (',', ','), ('Alpay', 'alpay'), (',', ','), ('L.', 'l.'), (',', ','), ('&', '&'), ('Lovis', 'lovi'), (',', ','), ('C.', 'c.'), ('(', '('), ('1994', '1994'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('92', '92'), (']', ']'), ('Baud', 'Baud'), (',', ','), ('R.', 'R.'), ('H.', 'H.'), (',', ','), ('Alpay', 'Alpay'), (',', ','), ('L.', 'L.'), (',', ','), ('&', '&'), ('Lovis', 'Lovis'), (',', ','), ('C.', 'C.'), ('(', '('), ('1994', '1994'), (')', ')'), ('.', '.')]


------------------- Sentence 2 -------------------

Let’s Meet the Users with Natural Language

>> Tokens are: 
 ['Let', '’', 'Meet', 'Users', 'Natural', 'Language']

>> Bigrams are: 
 [('Let', '’'), ('’', 'Meet'), ('Meet', 'Users'), ('Users', 'Natural'), ('Natural', 'Language')]

>> Trigrams are: 
 [('Let', '’', 'Meet'), ('’', 'Meet', 'Users'), ('Meet', 'Users', 'Natural'), ('Users', 'Natural', 'Language')]

>> POS Tags are: 
 [('Let', 'VB'), ('’', 'NNP'), ('Meet', 'NNP'), ('Users', 'NNP'), ('Natural', 'NNP'), ('Language', 'NNP')]

>> Noun Phrases are: 
 ['’ Meet Users Natural Language']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Let', 'let'), ('’', '’'), ('Meet', 'meet'), ('Users', 'user'), ('Natural', 'natur'), ('Language', 'languag')]

>> Stemming using Snowball Stemmer: 
 [('Let', 'let'), ('’', '’'), ('Meet', 'meet'), ('Users', 'user'), ('Natural', 'natur'), ('Language', 'languag')]

>> Lemmatization: 
 [('Let', 'Let'), ('’', '’'), ('Meet', 'Meet'), ('Users', 'Users'), ('Natural', 'Natural'), ('Language', 'Language')]



========================================== PARAGRAPH 838 ===========================================

Understanding. Knowledge and Decisions in Health Telematics: The Next Decade, 12, 103. 

------------------- Sentence 1 -------------------

Understanding.

>> Tokens are: 
 ['Understanding', '.']

>> Bigrams are: 
 [('Understanding', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Understanding', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Understanding']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Understanding', 'understand'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Understanding', 'understand'), ('.', '.')]

>> Lemmatization: 
 [('Understanding', 'Understanding'), ('.', '.')]


------------------- Sentence 2 -------------------

Knowledge and Decisions in Health Telematics: The Next Decade, 12, 103.

>> Tokens are: 
 ['Knowledge', 'Decisions', 'Health', 'Telematics', ':', 'The', 'Next', 'Decade', ',', '12', ',', '103', '.']

>> Bigrams are: 
 [('Knowledge', 'Decisions'), ('Decisions', 'Health'), ('Health', 'Telematics'), ('Telematics', ':'), (':', 'The'), ('The', 'Next'), ('Next', 'Decade'), ('Decade', ','), (',', '12'), ('12', ','), (',', '103'), ('103', '.')]

>> Trigrams are: 
 [('Knowledge', 'Decisions', 'Health'), ('Decisions', 'Health', 'Telematics'), ('Health', 'Telematics', ':'), ('Telematics', ':', 'The'), (':', 'The', 'Next'), ('The', 'Next', 'Decade'), ('Next', 'Decade', ','), ('Decade', ',', '12'), (',', '12', ','), ('12', ',', '103'), (',', '103', '.')]

>> POS Tags are: 
 [('Knowledge', 'NNP'), ('Decisions', 'NNP'), ('Health', 'NNP'), ('Telematics', 'NNS'), (':', ':'), ('The', 'DT'), ('Next', 'NNP'), ('Decade', 'NNP'), (',', ','), ('12', 'CD'), (',', ','), ('103', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Knowledge Decisions Health Telematics', 'The Next Decade']

>> Named Entities are: 
 [('PERSON', 'Knowledge'), ('PERSON', 'Decisions Health'), ('ORGANIZATION', 'Next Decade')] 

>> Stemming using Porter Stemmer: 
 [('Knowledge', 'knowledg'), ('Decisions', 'decis'), ('Health', 'health'), ('Telematics', 'telemat'), (':', ':'), ('The', 'the'), ('Next', 'next'), ('Decade', 'decad'), (',', ','), ('12', '12'), (',', ','), ('103', '103'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Knowledge', 'knowledg'), ('Decisions', 'decis'), ('Health', 'health'), ('Telematics', 'telemat'), (':', ':'), ('The', 'the'), ('Next', 'next'), ('Decade', 'decad'), (',', ','), ('12', '12'), (',', ','), ('103', '103'), ('.', '.')]

>> Lemmatization: 
 [('Knowledge', 'Knowledge'), ('Decisions', 'Decisions'), ('Health', 'Health'), ('Telematics', 'Telematics'), (':', ':'), ('The', 'The'), ('Next', 'Next'), ('Decade', 'Decade'), (',', ','), ('12', '12'), (',', ','), ('103', '103'), ('.', '.')]



========================================== PARAGRAPH 839 ===========================================

[93] Rassinoux, A. M., Baud, R. H., & Scherrer, J. R. (1992). Conceptual graphs model  

------------------- Sentence 1 -------------------

[93] Rassinoux, A. M., Baud, R. H., & Scherrer, J. R. (1992).

>> Tokens are: 
 ['[', '93', ']', 'Rassinoux', ',', 'A.', 'M.', ',', 'Baud', ',', 'R.', 'H.', ',', '&', 'Scherrer', ',', 'J.', 'R.', '(', '1992', ')', '.']

>> Bigrams are: 
 [('[', '93'), ('93', ']'), (']', 'Rassinoux'), ('Rassinoux', ','), (',', 'A.'), ('A.', 'M.'), ('M.', ','), (',', 'Baud'), ('Baud', ','), (',', 'R.'), ('R.', 'H.'), ('H.', ','), (',', '&'), ('&', 'Scherrer'), ('Scherrer', ','), (',', 'J.'), ('J.', 'R.'), ('R.', '('), ('(', '1992'), ('1992', ')'), (')', '.')]

>> Trigrams are: 
 [('[', '93', ']'), ('93', ']', 'Rassinoux'), (']', 'Rassinoux', ','), ('Rassinoux', ',', 'A.'), (',', 'A.', 'M.'), ('A.', 'M.', ','), ('M.', ',', 'Baud'), (',', 'Baud', ','), ('Baud', ',', 'R.'), (',', 'R.', 'H.'), ('R.', 'H.', ','), ('H.', ',', '&'), (',', '&', 'Scherrer'), ('&', 'Scherrer', ','), ('Scherrer', ',', 'J.'), (',', 'J.', 'R.'), ('J.', 'R.', '('), ('R.', '(', '1992'), ('(', '1992', ')'), ('1992', ')', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('93', 'CD'), (']', 'JJ'), ('Rassinoux', 'NNP'), (',', ','), ('A.', 'NNP'), ('M.', 'NNP'), (',', ','), ('Baud', 'NNP'), (',', ','), ('R.', 'NNP'), ('H.', 'NNP'), (',', ','), ('&', 'CC'), ('Scherrer', 'NNP'), (',', ','), ('J.', 'NNP'), ('R.', 'NNP'), ('(', '('), ('1992', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['] Rassinoux', 'A. M.', 'Baud', 'R. H.', 'Scherrer', 'J. R.']

>> Named Entities are: 
 [('PERSON', 'Baud'), ('PERSON', 'Scherrer'), ('PERSON', 'J. R.')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('93', '93'), (']', ']'), ('Rassinoux', 'rassinoux'), (',', ','), ('A.', 'a.'), ('M.', 'm.'), (',', ','), ('Baud', 'baud'), (',', ','), ('R.', 'r.'), ('H.', 'h.'), (',', ','), ('&', '&'), ('Scherrer', 'scherrer'), (',', ','), ('J.', 'j.'), ('R.', 'r.'), ('(', '('), ('1992', '1992'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('93', '93'), (']', ']'), ('Rassinoux', 'rassinoux'), (',', ','), ('A.', 'a.'), ('M.', 'm.'), (',', ','), ('Baud', 'baud'), (',', ','), ('R.', 'r.'), ('H.', 'h.'), (',', ','), ('&', '&'), ('Scherrer', 'scherrer'), (',', ','), ('J.', 'j.'), ('R.', 'r.'), ('(', '('), ('1992', '1992'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('93', '93'), (']', ']'), ('Rassinoux', 'Rassinoux'), (',', ','), ('A.', 'A.'), ('M.', 'M.'), (',', ','), ('Baud', 'Baud'), (',', ','), ('R.', 'R.'), ('H.', 'H.'), (',', ','), ('&', '&'), ('Scherrer', 'Scherrer'), (',', ','), ('J.', 'J.'), ('R.', 'R.'), ('(', '('), ('1992', '1992'), (')', ')'), ('.', '.')]


------------------- Sentence 2 -------------------

Conceptual graphs model

>> Tokens are: 
 ['Conceptual', 'graphs', 'model']

>> Bigrams are: 
 [('Conceptual', 'graphs'), ('graphs', 'model')]

>> Trigrams are: 
 [('Conceptual', 'graphs', 'model')]

>> POS Tags are: 
 [('Conceptual', 'JJ'), ('graphs', 'NN'), ('model', 'NN')]

>> Noun Phrases are: 
 ['Conceptual graphs model']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Conceptual', 'conceptu'), ('graphs', 'graph'), ('model', 'model')]

>> Stemming using Snowball Stemmer: 
 [('Conceptual', 'conceptu'), ('graphs', 'graph'), ('model', 'model')]

>> Lemmatization: 
 [('Conceptual', 'Conceptual'), ('graphs', 'graph'), ('model', 'model')]



========================================== PARAGRAPH 840 ===========================================

extension for knowledge representation of medical texts. MEDINFO, 92, 1368-1374.  

------------------- Sentence 1 -------------------

extension for knowledge representation of medical texts.

>> Tokens are: 
 ['extension', 'knowledge', 'representation', 'medical', 'texts', '.']

>> Bigrams are: 
 [('extension', 'knowledge'), ('knowledge', 'representation'), ('representation', 'medical'), ('medical', 'texts'), ('texts', '.')]

>> Trigrams are: 
 [('extension', 'knowledge', 'representation'), ('knowledge', 'representation', 'medical'), ('representation', 'medical', 'texts'), ('medical', 'texts', '.')]

>> POS Tags are: 
 [('extension', 'NN'), ('knowledge', 'NN'), ('representation', 'NN'), ('medical', 'JJ'), ('texts', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['extension knowledge representation', 'medical texts']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('extension', 'extens'), ('knowledge', 'knowledg'), ('representation', 'represent'), ('medical', 'medic'), ('texts', 'text'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('extension', 'extens'), ('knowledge', 'knowledg'), ('representation', 'represent'), ('medical', 'medic'), ('texts', 'text'), ('.', '.')]

>> Lemmatization: 
 [('extension', 'extension'), ('knowledge', 'knowledge'), ('representation', 'representation'), ('medical', 'medical'), ('texts', 'text'), ('.', '.')]


------------------- Sentence 2 -------------------

MEDINFO, 92, 1368-1374.

>> Tokens are: 
 ['MEDINFO', ',', '92', ',', '1368-1374', '.']

>> Bigrams are: 
 [('MEDINFO', ','), (',', '92'), ('92', ','), (',', '1368-1374'), ('1368-1374', '.')]

>> Trigrams are: 
 [('MEDINFO', ',', '92'), (',', '92', ','), ('92', ',', '1368-1374'), (',', '1368-1374', '.')]

>> POS Tags are: 
 [('MEDINFO', 'NNP'), (',', ','), ('92', 'CD'), (',', ','), ('1368-1374', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['MEDINFO']

>> Named Entities are: 
 [('GPE', 'MEDINFO')] 

>> Stemming using Porter Stemmer: 
 [('MEDINFO', 'medinfo'), (',', ','), ('92', '92'), (',', ','), ('1368-1374', '1368-1374'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('MEDINFO', 'medinfo'), (',', ','), ('92', '92'), (',', ','), ('1368-1374', '1368-1374'), ('.', '.')]

>> Lemmatization: 
 [('MEDINFO', 'MEDINFO'), (',', ','), ('92', '92'), (',', ','), ('1368-1374', '1368-1374'), ('.', '.')]



========================================== PARAGRAPH 841 ===========================================

[94] Morel-Guillemaz, A. M., Baud, R. H., & Scherrer, J. R. (1990). Proximity Processing of  

------------------- Sentence 1 -------------------

[94] Morel-Guillemaz, A. M., Baud, R. H., & Scherrer, J. R. (1990).

>> Tokens are: 
 ['[', '94', ']', 'Morel-Guillemaz', ',', 'A.', 'M.', ',', 'Baud', ',', 'R.', 'H.', ',', '&', 'Scherrer', ',', 'J.', 'R.', '(', '1990', ')', '.']

>> Bigrams are: 
 [('[', '94'), ('94', ']'), (']', 'Morel-Guillemaz'), ('Morel-Guillemaz', ','), (',', 'A.'), ('A.', 'M.'), ('M.', ','), (',', 'Baud'), ('Baud', ','), (',', 'R.'), ('R.', 'H.'), ('H.', ','), (',', '&'), ('&', 'Scherrer'), ('Scherrer', ','), (',', 'J.'), ('J.', 'R.'), ('R.', '('), ('(', '1990'), ('1990', ')'), (')', '.')]

>> Trigrams are: 
 [('[', '94', ']'), ('94', ']', 'Morel-Guillemaz'), (']', 'Morel-Guillemaz', ','), ('Morel-Guillemaz', ',', 'A.'), (',', 'A.', 'M.'), ('A.', 'M.', ','), ('M.', ',', 'Baud'), (',', 'Baud', ','), ('Baud', ',', 'R.'), (',', 'R.', 'H.'), ('R.', 'H.', ','), ('H.', ',', '&'), (',', '&', 'Scherrer'), ('&', 'Scherrer', ','), ('Scherrer', ',', 'J.'), (',', 'J.', 'R.'), ('J.', 'R.', '('), ('R.', '(', '1990'), ('(', '1990', ')'), ('1990', ')', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('94', 'CD'), (']', 'JJ'), ('Morel-Guillemaz', 'NNP'), (',', ','), ('A.', 'NNP'), ('M.', 'NNP'), (',', ','), ('Baud', 'NNP'), (',', ','), ('R.', 'NNP'), ('H.', 'NNP'), (',', ','), ('&', 'CC'), ('Scherrer', 'NNP'), (',', ','), ('J.', 'NNP'), ('R.', 'NNP'), ('(', '('), ('1990', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['] Morel-Guillemaz', 'A. M.', 'Baud', 'R. H.', 'Scherrer', 'J. R.']

>> Named Entities are: 
 [('PERSON', 'Baud'), ('PERSON', 'Scherrer'), ('PERSON', 'J. R.')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('94', '94'), (']', ']'), ('Morel-Guillemaz', 'morel-guillemaz'), (',', ','), ('A.', 'a.'), ('M.', 'm.'), (',', ','), ('Baud', 'baud'), (',', ','), ('R.', 'r.'), ('H.', 'h.'), (',', ','), ('&', '&'), ('Scherrer', 'scherrer'), (',', ','), ('J.', 'j.'), ('R.', 'r.'), ('(', '('), ('1990', '1990'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('94', '94'), (']', ']'), ('Morel-Guillemaz', 'morel-guillemaz'), (',', ','), ('A.', 'a.'), ('M.', 'm.'), (',', ','), ('Baud', 'baud'), (',', ','), ('R.', 'r.'), ('H.', 'h.'), (',', ','), ('&', '&'), ('Scherrer', 'scherrer'), (',', ','), ('J.', 'j.'), ('R.', 'r.'), ('(', '('), ('1990', '1990'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('94', '94'), (']', ']'), ('Morel-Guillemaz', 'Morel-Guillemaz'), (',', ','), ('A.', 'A.'), ('M.', 'M.'), (',', ','), ('Baud', 'Baud'), (',', ','), ('R.', 'R.'), ('H.', 'H.'), (',', ','), ('&', '&'), ('Scherrer', 'Scherrer'), (',', ','), ('J.', 'J.'), ('R.', 'R.'), ('(', '('), ('1990', '1990'), (')', ')'), ('.', '.')]


------------------- Sentence 2 -------------------

Proximity Processing of

>> Tokens are: 
 ['Proximity', 'Processing']

>> Bigrams are: 
 [('Proximity', 'Processing')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Proximity', 'NN'), ('Processing', 'NN')]

>> Noun Phrases are: 
 ['Proximity Processing']

>> Named Entities are: 
 [('GPE', 'Proximity'), ('ORGANIZATION', 'Processing')] 

>> Stemming using Porter Stemmer: 
 [('Proximity', 'proxim'), ('Processing', 'process')]

>> Stemming using Snowball Stemmer: 
 [('Proximity', 'proxim'), ('Processing', 'process')]

>> Lemmatization: 
 [('Proximity', 'Proximity'), ('Processing', 'Processing')]



========================================== PARAGRAPH 842 ===========================================

Medical Text. In Medical Informatics Europe’90 (pp. 625-630). Springer Berlin Heidelberg.  

------------------- Sentence 1 -------------------

Medical Text.

>> Tokens are: 
 ['Medical', 'Text', '.']

>> Bigrams are: 
 [('Medical', 'Text'), ('Text', '.')]

>> Trigrams are: 
 [('Medical', 'Text', '.')]

>> POS Tags are: 
 [('Medical', 'JJ'), ('Text', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Medical Text']

>> Named Entities are: 
 [('PERSON', 'Medical'), ('ORGANIZATION', 'Text')] 

>> Stemming using Porter Stemmer: 
 [('Medical', 'medic'), ('Text', 'text'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Medical', 'medic'), ('Text', 'text'), ('.', '.')]

>> Lemmatization: 
 [('Medical', 'Medical'), ('Text', 'Text'), ('.', '.')]


------------------- Sentence 2 -------------------

In Medical Informatics Europe’90 (pp.

>> Tokens are: 
 ['In', 'Medical', 'Informatics', 'Europe', '’', '90', '(', 'pp', '.']

>> Bigrams are: 
 [('In', 'Medical'), ('Medical', 'Informatics'), ('Informatics', 'Europe'), ('Europe', '’'), ('’', '90'), ('90', '('), ('(', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('In', 'Medical', 'Informatics'), ('Medical', 'Informatics', 'Europe'), ('Informatics', 'Europe', '’'), ('Europe', '’', '90'), ('’', '90', '('), ('90', '(', 'pp'), ('(', 'pp', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('Medical', 'NNP'), ('Informatics', 'NNP'), ('Europe', 'NNP'), ('’', 'VBZ'), ('90', 'CD'), ('(', '('), ('pp', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Medical Informatics Europe', 'pp']

>> Named Entities are: 
 [('ORGANIZATION', 'Medical Informatics Europe')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('Medical', 'medic'), ('Informatics', 'informat'), ('Europe', 'europ'), ('’', '’'), ('90', '90'), ('(', '('), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('Medical', 'medic'), ('Informatics', 'informat'), ('Europe', 'europ'), ('’', '’'), ('90', '90'), ('(', '('), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('Medical', 'Medical'), ('Informatics', 'Informatics'), ('Europe', 'Europe'), ('’', '’'), ('90', '90'), ('(', '('), ('pp', 'pp'), ('.', '.')]


------------------- Sentence 3 -------------------

625-630).

>> Tokens are: 
 ['625-630', ')', '.']

>> Bigrams are: 
 [('625-630', ')'), (')', '.')]

>> Trigrams are: 
 [('625-630', ')', '.')]

>> POS Tags are: 
 [('625-630', 'JJ'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('625-630', '625-630'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('625-630', '625-630'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('625-630', '625-630'), (')', ')'), ('.', '.')]


------------------- Sentence 4 -------------------

Springer Berlin Heidelberg.

>> Tokens are: 
 ['Springer', 'Berlin', 'Heidelberg', '.']

>> Bigrams are: 
 [('Springer', 'Berlin'), ('Berlin', 'Heidelberg'), ('Heidelberg', '.')]

>> Trigrams are: 
 [('Springer', 'Berlin', 'Heidelberg'), ('Berlin', 'Heidelberg', '.')]

>> POS Tags are: 
 [('Springer', 'NNP'), ('Berlin', 'NNP'), ('Heidelberg', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Springer Berlin Heidelberg']

>> Named Entities are: 
 [('PERSON', 'Springer'), ('PERSON', 'Berlin Heidelberg')] 

>> Stemming using Porter Stemmer: 
 [('Springer', 'springer'), ('Berlin', 'berlin'), ('Heidelberg', 'heidelberg'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Springer', 'springer'), ('Berlin', 'berlin'), ('Heidelberg', 'heidelberg'), ('.', '.')]

>> Lemmatization: 
 [('Springer', 'Springer'), ('Berlin', 'Berlin'), ('Heidelberg', 'Heidelberg'), ('.', '.')]



========================================== PARAGRAPH 843 ===========================================

[95] Rassinoux, A. M., Michel, P. A., Juge, C., Baud, R., & Scherrer, J. R. (1994). Natural  

------------------- Sentence 1 -------------------

[95] Rassinoux, A. M., Michel, P. A., Juge, C., Baud, R., & Scherrer, J. R. (1994).

>> Tokens are: 
 ['[', '95', ']', 'Rassinoux', ',', 'A.', 'M.', ',', 'Michel', ',', 'P.', 'A.', ',', 'Juge', ',', 'C.', ',', 'Baud', ',', 'R.', ',', '&', 'Scherrer', ',', 'J.', 'R.', '(', '1994', ')', '.']

>> Bigrams are: 
 [('[', '95'), ('95', ']'), (']', 'Rassinoux'), ('Rassinoux', ','), (',', 'A.'), ('A.', 'M.'), ('M.', ','), (',', 'Michel'), ('Michel', ','), (',', 'P.'), ('P.', 'A.'), ('A.', ','), (',', 'Juge'), ('Juge', ','), (',', 'C.'), ('C.', ','), (',', 'Baud'), ('Baud', ','), (',', 'R.'), ('R.', ','), (',', '&'), ('&', 'Scherrer'), ('Scherrer', ','), (',', 'J.'), ('J.', 'R.'), ('R.', '('), ('(', '1994'), ('1994', ')'), (')', '.')]

>> Trigrams are: 
 [('[', '95', ']'), ('95', ']', 'Rassinoux'), (']', 'Rassinoux', ','), ('Rassinoux', ',', 'A.'), (',', 'A.', 'M.'), ('A.', 'M.', ','), ('M.', ',', 'Michel'), (',', 'Michel', ','), ('Michel', ',', 'P.'), (',', 'P.', 'A.'), ('P.', 'A.', ','), ('A.', ',', 'Juge'), (',', 'Juge', ','), ('Juge', ',', 'C.'), (',', 'C.', ','), ('C.', ',', 'Baud'), (',', 'Baud', ','), ('Baud', ',', 'R.'), (',', 'R.', ','), ('R.', ',', '&'), (',', '&', 'Scherrer'), ('&', 'Scherrer', ','), ('Scherrer', ',', 'J.'), (',', 'J.', 'R.'), ('J.', 'R.', '('), ('R.', '(', '1994'), ('(', '1994', ')'), ('1994', ')', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('95', 'CD'), (']', 'JJ'), ('Rassinoux', 'NNP'), (',', ','), ('A.', 'NNP'), ('M.', 'NNP'), (',', ','), ('Michel', 'NNP'), (',', ','), ('P.', 'NNP'), ('A.', 'NN'), (',', ','), ('Juge', 'NNP'), (',', ','), ('C.', 'NNP'), (',', ','), ('Baud', 'NNP'), (',', ','), ('R.', 'NNP'), (',', ','), ('&', 'CC'), ('Scherrer', 'NNP'), (',', ','), ('J.', 'NNP'), ('R.', 'NNP'), ('(', '('), ('1994', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['] Rassinoux', 'A. M.', 'Michel', 'P. A.', 'Juge', 'C.', 'Baud', 'R.', 'Scherrer', 'J. R.']

>> Named Entities are: 
 [('PERSON', 'Michel'), ('PERSON', 'Juge'), ('PERSON', 'Baud'), ('PERSON', 'Scherrer'), ('PERSON', 'J. R.')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('95', '95'), (']', ']'), ('Rassinoux', 'rassinoux'), (',', ','), ('A.', 'a.'), ('M.', 'm.'), (',', ','), ('Michel', 'michel'), (',', ','), ('P.', 'p.'), ('A.', 'a.'), (',', ','), ('Juge', 'juge'), (',', ','), ('C.', 'c.'), (',', ','), ('Baud', 'baud'), (',', ','), ('R.', 'r.'), (',', ','), ('&', '&'), ('Scherrer', 'scherrer'), (',', ','), ('J.', 'j.'), ('R.', 'r.'), ('(', '('), ('1994', '1994'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('95', '95'), (']', ']'), ('Rassinoux', 'rassinoux'), (',', ','), ('A.', 'a.'), ('M.', 'm.'), (',', ','), ('Michel', 'michel'), (',', ','), ('P.', 'p.'), ('A.', 'a.'), (',', ','), ('Juge', 'juge'), (',', ','), ('C.', 'c.'), (',', ','), ('Baud', 'baud'), (',', ','), ('R.', 'r.'), (',', ','), ('&', '&'), ('Scherrer', 'scherrer'), (',', ','), ('J.', 'j.'), ('R.', 'r.'), ('(', '('), ('1994', '1994'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('95', '95'), (']', ']'), ('Rassinoux', 'Rassinoux'), (',', ','), ('A.', 'A.'), ('M.', 'M.'), (',', ','), ('Michel', 'Michel'), (',', ','), ('P.', 'P.'), ('A.', 'A.'), (',', ','), ('Juge', 'Juge'), (',', ','), ('C.', 'C.'), (',', ','), ('Baud', 'Baud'), (',', ','), ('R.', 'R.'), (',', ','), ('&', '&'), ('Scherrer', 'Scherrer'), (',', ','), ('J.', 'J.'), ('R.', 'R.'), ('(', '('), ('1994', '1994'), (')', ')'), ('.', '.')]


------------------- Sentence 2 -------------------

Natural

>> Tokens are: 
 ['Natural']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Natural', 'JJ')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Natural', 'natur')]

>> Stemming using Snowball Stemmer: 
 [('Natural', 'natur')]

>> Lemmatization: 
 [('Natural', 'Natural')]



========================================== PARAGRAPH 844 ===========================================

language processing of medical texts within the HELIOS environment. Computer methods  

------------------- Sentence 1 -------------------

language processing of medical texts within the HELIOS environment.

>> Tokens are: 
 ['language', 'processing', 'medical', 'texts', 'within', 'HELIOS', 'environment', '.']

>> Bigrams are: 
 [('language', 'processing'), ('processing', 'medical'), ('medical', 'texts'), ('texts', 'within'), ('within', 'HELIOS'), ('HELIOS', 'environment'), ('environment', '.')]

>> Trigrams are: 
 [('language', 'processing', 'medical'), ('processing', 'medical', 'texts'), ('medical', 'texts', 'within'), ('texts', 'within', 'HELIOS'), ('within', 'HELIOS', 'environment'), ('HELIOS', 'environment', '.')]

>> POS Tags are: 
 [('language', 'NN'), ('processing', 'VBG'), ('medical', 'JJ'), ('texts', 'NN'), ('within', 'IN'), ('HELIOS', 'NNP'), ('environment', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['language', 'medical texts', 'HELIOS environment']

>> Named Entities are: 
 [('ORGANIZATION', 'HELIOS')] 

>> Stemming using Porter Stemmer: 
 [('language', 'languag'), ('processing', 'process'), ('medical', 'medic'), ('texts', 'text'), ('within', 'within'), ('HELIOS', 'helio'), ('environment', 'environ'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('language', 'languag'), ('processing', 'process'), ('medical', 'medic'), ('texts', 'text'), ('within', 'within'), ('HELIOS', 'helio'), ('environment', 'environ'), ('.', '.')]

>> Lemmatization: 
 [('language', 'language'), ('processing', 'processing'), ('medical', 'medical'), ('texts', 'text'), ('within', 'within'), ('HELIOS', 'HELIOS'), ('environment', 'environment'), ('.', '.')]


------------------- Sentence 2 -------------------

Computer methods

>> Tokens are: 
 ['Computer', 'methods']

>> Bigrams are: 
 [('Computer', 'methods')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Computer', 'NNP'), ('methods', 'NNS')]

>> Noun Phrases are: 
 ['Computer methods']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Computer', 'comput'), ('methods', 'method')]

>> Stemming using Snowball Stemmer: 
 [('Computer', 'comput'), ('methods', 'method')]

>> Lemmatization: 
 [('Computer', 'Computer'), ('methods', 'method')]



========================================== PARAGRAPH 845 ===========================================

and programs in biomedicine, 45, S79-96.  

------------------- Sentence 1 -------------------

and programs in biomedicine, 45, S79-96.

>> Tokens are: 
 ['programs', 'biomedicine', ',', '45', ',', 'S79-96', '.']

>> Bigrams are: 
 [('programs', 'biomedicine'), ('biomedicine', ','), (',', '45'), ('45', ','), (',', 'S79-96'), ('S79-96', '.')]

>> Trigrams are: 
 [('programs', 'biomedicine', ','), ('biomedicine', ',', '45'), (',', '45', ','), ('45', ',', 'S79-96'), (',', 'S79-96', '.')]

>> POS Tags are: 
 [('programs', 'NNS'), ('biomedicine', 'VBP'), (',', ','), ('45', 'CD'), (',', ','), ('S79-96', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['programs', 'S79-96']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('programs', 'program'), ('biomedicine', 'biomedicin'), (',', ','), ('45', '45'), (',', ','), ('S79-96', 's79-96'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('programs', 'program'), ('biomedicine', 'biomedicin'), (',', ','), ('45', '45'), (',', ','), ('S79-96', 's79-96'), ('.', '.')]

>> Lemmatization: 
 [('programs', 'program'), ('biomedicine', 'biomedicine'), (',', ','), ('45', '45'), (',', ','), ('S79-96', 'S79-96'), ('.', '.')]



========================================== PARAGRAPH 846 ===========================================

[96] Rassinoux, A. M., Juge, C., Michel, P. A., Baud, R. H., Lemaitre, D., Jean, F. C., ... &  

------------------- Sentence 1 -------------------

[96] Rassinoux, A. M., Juge, C., Michel, P. A., Baud, R. H., Lemaitre, D., Jean, F. C., ... &

>> Tokens are: 
 ['[', '96', ']', 'Rassinoux', ',', 'A.', 'M.', ',', 'Juge', ',', 'C.', ',', 'Michel', ',', 'P.', 'A.', ',', 'Baud', ',', 'R.', 'H.', ',', 'Lemaitre', ',', 'D.', ',', 'Jean', ',', 'F.', 'C.', ',', '...', '&']

>> Bigrams are: 
 [('[', '96'), ('96', ']'), (']', 'Rassinoux'), ('Rassinoux', ','), (',', 'A.'), ('A.', 'M.'), ('M.', ','), (',', 'Juge'), ('Juge', ','), (',', 'C.'), ('C.', ','), (',', 'Michel'), ('Michel', ','), (',', 'P.'), ('P.', 'A.'), ('A.', ','), (',', 'Baud'), ('Baud', ','), (',', 'R.'), ('R.', 'H.'), ('H.', ','), (',', 'Lemaitre'), ('Lemaitre', ','), (',', 'D.'), ('D.', ','), (',', 'Jean'), ('Jean', ','), (',', 'F.'), ('F.', 'C.'), ('C.', ','), (',', '...'), ('...', '&')]

>> Trigrams are: 
 [('[', '96', ']'), ('96', ']', 'Rassinoux'), (']', 'Rassinoux', ','), ('Rassinoux', ',', 'A.'), (',', 'A.', 'M.'), ('A.', 'M.', ','), ('M.', ',', 'Juge'), (',', 'Juge', ','), ('Juge', ',', 'C.'), (',', 'C.', ','), ('C.', ',', 'Michel'), (',', 'Michel', ','), ('Michel', ',', 'P.'), (',', 'P.', 'A.'), ('P.', 'A.', ','), ('A.', ',', 'Baud'), (',', 'Baud', ','), ('Baud', ',', 'R.'), (',', 'R.', 'H.'), ('R.', 'H.', ','), ('H.', ',', 'Lemaitre'), (',', 'Lemaitre', ','), ('Lemaitre', ',', 'D.'), (',', 'D.', ','), ('D.', ',', 'Jean'), (',', 'Jean', ','), ('Jean', ',', 'F.'), (',', 'F.', 'C.'), ('F.', 'C.', ','), ('C.', ',', '...'), (',', '...', '&')]

>> POS Tags are: 
 [('[', 'RB'), ('96', 'CD'), (']', 'JJ'), ('Rassinoux', 'NNP'), (',', ','), ('A.', 'NNP'), ('M.', 'NNP'), (',', ','), ('Juge', 'NNP'), (',', ','), ('C.', 'NNP'), (',', ','), ('Michel', 'NNP'), (',', ','), ('P.', 'NNP'), ('A.', 'NN'), (',', ','), ('Baud', 'NNP'), (',', ','), ('R.', 'NNP'), ('H.', 'NNP'), (',', ','), ('Lemaitre', 'NNP'), (',', ','), ('D.', 'NNP'), (',', ','), ('Jean', 'NNP'), (',', ','), ('F.', 'NNP'), ('C.', 'NNP'), (',', ','), ('...', ':'), ('&', 'CC')]

>> Noun Phrases are: 
 ['] Rassinoux', 'A. M.', 'Juge', 'C.', 'Michel', 'P. A.', 'Baud', 'R. H.', 'Lemaitre', 'D.', 'Jean', 'F. C.']

>> Named Entities are: 
 [('PERSON', 'Juge'), ('PERSON', 'Michel'), ('PERSON', 'Baud'), ('GPE', 'Lemaitre'), ('GPE', 'Jean')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('96', '96'), (']', ']'), ('Rassinoux', 'rassinoux'), (',', ','), ('A.', 'a.'), ('M.', 'm.'), (',', ','), ('Juge', 'juge'), (',', ','), ('C.', 'c.'), (',', ','), ('Michel', 'michel'), (',', ','), ('P.', 'p.'), ('A.', 'a.'), (',', ','), ('Baud', 'baud'), (',', ','), ('R.', 'r.'), ('H.', 'h.'), (',', ','), ('Lemaitre', 'lemaitr'), (',', ','), ('D.', 'd.'), (',', ','), ('Jean', 'jean'), (',', ','), ('F.', 'f.'), ('C.', 'c.'), (',', ','), ('...', '...'), ('&', '&')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('96', '96'), (']', ']'), ('Rassinoux', 'rassinoux'), (',', ','), ('A.', 'a.'), ('M.', 'm.'), (',', ','), ('Juge', 'juge'), (',', ','), ('C.', 'c.'), (',', ','), ('Michel', 'michel'), (',', ','), ('P.', 'p.'), ('A.', 'a.'), (',', ','), ('Baud', 'baud'), (',', ','), ('R.', 'r.'), ('H.', 'h.'), (',', ','), ('Lemaitre', 'lemaitr'), (',', ','), ('D.', 'd.'), (',', ','), ('Jean', 'jean'), (',', ','), ('F.', 'f.'), ('C.', 'c.'), (',', ','), ('...', '...'), ('&', '&')]

>> Lemmatization: 
 [('[', '['), ('96', '96'), (']', ']'), ('Rassinoux', 'Rassinoux'), (',', ','), ('A.', 'A.'), ('M.', 'M.'), (',', ','), ('Juge', 'Juge'), (',', ','), ('C.', 'C.'), (',', ','), ('Michel', 'Michel'), (',', ','), ('P.', 'P.'), ('A.', 'A.'), (',', ','), ('Baud', 'Baud'), (',', ','), ('R.', 'R.'), ('H.', 'H.'), (',', ','), ('Lemaitre', 'Lemaitre'), (',', ','), ('D.', 'D.'), (',', ','), ('Jean', 'Jean'), (',', ','), ('F.', 'F.'), ('C.', 'C.'), (',', ','), ('...', '...'), ('&', '&')]



========================================== PARAGRAPH 847 ===========================================

Scherrer, J. R. (1995, June). Analysis of medical jargon: The RECIT system. In Conference  

------------------- Sentence 1 -------------------

Scherrer, J. R. (1995, June).

>> Tokens are: 
 ['Scherrer', ',', 'J.', 'R.', '(', '1995', ',', 'June', ')', '.']

>> Bigrams are: 
 [('Scherrer', ','), (',', 'J.'), ('J.', 'R.'), ('R.', '('), ('(', '1995'), ('1995', ','), (',', 'June'), ('June', ')'), (')', '.')]

>> Trigrams are: 
 [('Scherrer', ',', 'J.'), (',', 'J.', 'R.'), ('J.', 'R.', '('), ('R.', '(', '1995'), ('(', '1995', ','), ('1995', ',', 'June'), (',', 'June', ')'), ('June', ')', '.')]

>> POS Tags are: 
 [('Scherrer', 'NNP'), (',', ','), ('J.', 'NNP'), ('R.', 'NNP'), ('(', '('), ('1995', 'CD'), (',', ','), ('June', 'NNP'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['Scherrer', 'J. R.', 'June']

>> Named Entities are: 
 [('GPE', 'Scherrer'), ('PERSON', 'J. R.')] 

>> Stemming using Porter Stemmer: 
 [('Scherrer', 'scherrer'), (',', ','), ('J.', 'j.'), ('R.', 'r.'), ('(', '('), ('1995', '1995'), (',', ','), ('June', 'june'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Scherrer', 'scherrer'), (',', ','), ('J.', 'j.'), ('R.', 'r.'), ('(', '('), ('1995', '1995'), (',', ','), ('June', 'june'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Scherrer', 'Scherrer'), (',', ','), ('J.', 'J.'), ('R.', 'R.'), ('(', '('), ('1995', '1995'), (',', ','), ('June', 'June'), (')', ')'), ('.', '.')]


------------------- Sentence 2 -------------------

Analysis of medical jargon: The RECIT system.

>> Tokens are: 
 ['Analysis', 'medical', 'jargon', ':', 'The', 'RECIT', 'system', '.']

>> Bigrams are: 
 [('Analysis', 'medical'), ('medical', 'jargon'), ('jargon', ':'), (':', 'The'), ('The', 'RECIT'), ('RECIT', 'system'), ('system', '.')]

>> Trigrams are: 
 [('Analysis', 'medical', 'jargon'), ('medical', 'jargon', ':'), ('jargon', ':', 'The'), (':', 'The', 'RECIT'), ('The', 'RECIT', 'system'), ('RECIT', 'system', '.')]

>> POS Tags are: 
 [('Analysis', 'NNP'), ('medical', 'JJ'), ('jargon', 'NN'), (':', ':'), ('The', 'DT'), ('RECIT', 'NNP'), ('system', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Analysis', 'medical jargon', 'The RECIT system']

>> Named Entities are: 
 [('GPE', 'Analysis'), ('ORGANIZATION', 'RECIT')] 

>> Stemming using Porter Stemmer: 
 [('Analysis', 'analysi'), ('medical', 'medic'), ('jargon', 'jargon'), (':', ':'), ('The', 'the'), ('RECIT', 'recit'), ('system', 'system'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Analysis', 'analysi'), ('medical', 'medic'), ('jargon', 'jargon'), (':', ':'), ('The', 'the'), ('RECIT', 'recit'), ('system', 'system'), ('.', '.')]

>> Lemmatization: 
 [('Analysis', 'Analysis'), ('medical', 'medical'), ('jargon', 'jargon'), (':', ':'), ('The', 'The'), ('RECIT', 'RECIT'), ('system', 'system'), ('.', '.')]


------------------- Sentence 3 -------------------

In Conference

>> Tokens are: 
 ['In', 'Conference']

>> Bigrams are: 
 [('In', 'Conference')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('In', 'IN'), ('Conference', 'NNP')]

>> Noun Phrases are: 
 ['Conference']

>> Named Entities are: 
 [('GSP', 'Conference')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('Conference', 'confer')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('Conference', 'confer')]

>> Lemmatization: 
 [('In', 'In'), ('Conference', 'Conference')]



========================================== PARAGRAPH 848 ===========================================

on Artificial Intelligence in Medicine in Europe (pp. 42-52). Springer Berlin Heidelberg.  

------------------- Sentence 1 -------------------

on Artificial Intelligence in Medicine in Europe (pp.

>> Tokens are: 
 ['Artificial', 'Intelligence', 'Medicine', 'Europe', '(', 'pp', '.']

>> Bigrams are: 
 [('Artificial', 'Intelligence'), ('Intelligence', 'Medicine'), ('Medicine', 'Europe'), ('Europe', '('), ('(', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('Artificial', 'Intelligence', 'Medicine'), ('Intelligence', 'Medicine', 'Europe'), ('Medicine', 'Europe', '('), ('Europe', '(', 'pp'), ('(', 'pp', '.')]

>> POS Tags are: 
 [('Artificial', 'JJ'), ('Intelligence', 'NNP'), ('Medicine', 'NNP'), ('Europe', 'NNP'), ('(', '('), ('pp', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Artificial Intelligence Medicine Europe', 'pp']

>> Named Entities are: 
 [('ORGANIZATION', 'Intelligence Medicine Europe')] 

>> Stemming using Porter Stemmer: 
 [('Artificial', 'artifici'), ('Intelligence', 'intellig'), ('Medicine', 'medicin'), ('Europe', 'europ'), ('(', '('), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Artificial', 'artifici'), ('Intelligence', 'intellig'), ('Medicine', 'medicin'), ('Europe', 'europ'), ('(', '('), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('Artificial', 'Artificial'), ('Intelligence', 'Intelligence'), ('Medicine', 'Medicine'), ('Europe', 'Europe'), ('(', '('), ('pp', 'pp'), ('.', '.')]


------------------- Sentence 2 -------------------

42-52).

>> Tokens are: 
 ['42-52', ')', '.']

>> Bigrams are: 
 [('42-52', ')'), (')', '.')]

>> Trigrams are: 
 [('42-52', ')', '.')]

>> POS Tags are: 
 [('42-52', 'JJ'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('42-52', '42-52'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('42-52', '42-52'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('42-52', '42-52'), (')', ')'), ('.', '.')]


------------------- Sentence 3 -------------------

Springer Berlin Heidelberg.

>> Tokens are: 
 ['Springer', 'Berlin', 'Heidelberg', '.']

>> Bigrams are: 
 [('Springer', 'Berlin'), ('Berlin', 'Heidelberg'), ('Heidelberg', '.')]

>> Trigrams are: 
 [('Springer', 'Berlin', 'Heidelberg'), ('Berlin', 'Heidelberg', '.')]

>> POS Tags are: 
 [('Springer', 'NNP'), ('Berlin', 'NNP'), ('Heidelberg', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Springer Berlin Heidelberg']

>> Named Entities are: 
 [('PERSON', 'Springer'), ('PERSON', 'Berlin Heidelberg')] 

>> Stemming using Porter Stemmer: 
 [('Springer', 'springer'), ('Berlin', 'berlin'), ('Heidelberg', 'heidelberg'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Springer', 'springer'), ('Berlin', 'berlin'), ('Heidelberg', 'heidelberg'), ('.', '.')]

>> Lemmatization: 
 [('Springer', 'Springer'), ('Berlin', 'Berlin'), ('Heidelberg', 'Heidelberg'), ('.', '.')]



========================================== PARAGRAPH 849 ===========================================

[97] Friedman, C., Cimino, J. J., & Johnson, S. B. (1993). A conceptual model for clinical  

------------------- Sentence 1 -------------------

[97] Friedman, C., Cimino, J. J., & Johnson, S. B.

>> Tokens are: 
 ['[', '97', ']', 'Friedman', ',', 'C.', ',', 'Cimino', ',', 'J.', 'J.', ',', '&', 'Johnson', ',', 'S.', 'B', '.']

>> Bigrams are: 
 [('[', '97'), ('97', ']'), (']', 'Friedman'), ('Friedman', ','), (',', 'C.'), ('C.', ','), (',', 'Cimino'), ('Cimino', ','), (',', 'J.'), ('J.', 'J.'), ('J.', ','), (',', '&'), ('&', 'Johnson'), ('Johnson', ','), (',', 'S.'), ('S.', 'B'), ('B', '.')]

>> Trigrams are: 
 [('[', '97', ']'), ('97', ']', 'Friedman'), (']', 'Friedman', ','), ('Friedman', ',', 'C.'), (',', 'C.', ','), ('C.', ',', 'Cimino'), (',', 'Cimino', ','), ('Cimino', ',', 'J.'), (',', 'J.', 'J.'), ('J.', 'J.', ','), ('J.', ',', '&'), (',', '&', 'Johnson'), ('&', 'Johnson', ','), ('Johnson', ',', 'S.'), (',', 'S.', 'B'), ('S.', 'B', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('97', 'CD'), (']', 'JJ'), ('Friedman', 'NNP'), (',', ','), ('C.', 'NNP'), (',', ','), ('Cimino', 'NNP'), (',', ','), ('J.', 'NNP'), ('J.', 'NNP'), (',', ','), ('&', 'CC'), ('Johnson', 'NNP'), (',', ','), ('S.', 'NNP'), ('B', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['] Friedman', 'C.', 'Cimino', 'J. J.', 'Johnson', 'S. B']

>> Named Entities are: 
 [('GPE', 'Cimino'), ('PERSON', 'J. J.'), ('PERSON', 'Johnson')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('97', '97'), (']', ']'), ('Friedman', 'friedman'), (',', ','), ('C.', 'c.'), (',', ','), ('Cimino', 'cimino'), (',', ','), ('J.', 'j.'), ('J.', 'j.'), (',', ','), ('&', '&'), ('Johnson', 'johnson'), (',', ','), ('S.', 's.'), ('B', 'b'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('97', '97'), (']', ']'), ('Friedman', 'friedman'), (',', ','), ('C.', 'c.'), (',', ','), ('Cimino', 'cimino'), (',', ','), ('J.', 'j.'), ('J.', 'j.'), (',', ','), ('&', '&'), ('Johnson', 'johnson'), (',', ','), ('S.', 's.'), ('B', 'b'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('97', '97'), (']', ']'), ('Friedman', 'Friedman'), (',', ','), ('C.', 'C.'), (',', ','), ('Cimino', 'Cimino'), (',', ','), ('J.', 'J.'), ('J.', 'J.'), (',', ','), ('&', '&'), ('Johnson', 'Johnson'), (',', ','), ('S.', 'S.'), ('B', 'B'), ('.', '.')]


------------------- Sentence 2 -------------------

(1993).

>> Tokens are: 
 ['(', '1993', ')', '.']

>> Bigrams are: 
 [('(', '1993'), ('1993', ')'), (')', '.')]

>> Trigrams are: 
 [('(', '1993', ')'), ('1993', ')', '.')]

>> POS Tags are: 
 [('(', '('), ('1993', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('1993', '1993'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('1993', '1993'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('(', '('), ('1993', '1993'), (')', ')'), ('.', '.')]


------------------- Sentence 3 -------------------

A conceptual model for clinical

>> Tokens are: 
 ['A', 'conceptual', 'model', 'clinical']

>> Bigrams are: 
 [('A', 'conceptual'), ('conceptual', 'model'), ('model', 'clinical')]

>> Trigrams are: 
 [('A', 'conceptual', 'model'), ('conceptual', 'model', 'clinical')]

>> POS Tags are: 
 [('A', 'DT'), ('conceptual', 'JJ'), ('model', 'NN'), ('clinical', 'JJ')]

>> Noun Phrases are: 
 ['A conceptual model']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('A', 'a'), ('conceptual', 'conceptu'), ('model', 'model'), ('clinical', 'clinic')]

>> Stemming using Snowball Stemmer: 
 [('A', 'a'), ('conceptual', 'conceptu'), ('model', 'model'), ('clinical', 'clinic')]

>> Lemmatization: 
 [('A', 'A'), ('conceptual', 'conceptual'), ('model', 'model'), ('clinical', 'clinical')]



========================================== PARAGRAPH 850 ===========================================

radiology reports. In Proceedings of the Annual Symposium on Computer Application in  

------------------- Sentence 1 -------------------

radiology reports.

>> Tokens are: 
 ['radiology', 'reports', '.']

>> Bigrams are: 
 [('radiology', 'reports'), ('reports', '.')]

>> Trigrams are: 
 [('radiology', 'reports', '.')]

>> POS Tags are: 
 [('radiology', 'NN'), ('reports', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['radiology reports']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('radiology', 'radiolog'), ('reports', 'report'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('radiology', 'radiolog'), ('reports', 'report'), ('.', '.')]

>> Lemmatization: 
 [('radiology', 'radiology'), ('reports', 'report'), ('.', '.')]


------------------- Sentence 2 -------------------

In Proceedings of the Annual Symposium on Computer Application in

>> Tokens are: 
 ['In', 'Proceedings', 'Annual', 'Symposium', 'Computer', 'Application']

>> Bigrams are: 
 [('In', 'Proceedings'), ('Proceedings', 'Annual'), ('Annual', 'Symposium'), ('Symposium', 'Computer'), ('Computer', 'Application')]

>> Trigrams are: 
 [('In', 'Proceedings', 'Annual'), ('Proceedings', 'Annual', 'Symposium'), ('Annual', 'Symposium', 'Computer'), ('Symposium', 'Computer', 'Application')]

>> POS Tags are: 
 [('In', 'IN'), ('Proceedings', 'NNP'), ('Annual', 'NNP'), ('Symposium', 'NNP'), ('Computer', 'NNP'), ('Application', 'NNP')]

>> Noun Phrases are: 
 ['Proceedings Annual Symposium Computer Application']

>> Named Entities are: 
 [('GPE', 'Proceedings'), ('PERSON', 'Annual Symposium Computer')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('Proceedings', 'proceed'), ('Annual', 'annual'), ('Symposium', 'symposium'), ('Computer', 'comput'), ('Application', 'applic')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('Proceedings', 'proceed'), ('Annual', 'annual'), ('Symposium', 'symposium'), ('Computer', 'comput'), ('Application', 'applic')]

>> Lemmatization: 
 [('In', 'In'), ('Proceedings', 'Proceedings'), ('Annual', 'Annual'), ('Symposium', 'Symposium'), ('Computer', 'Computer'), ('Application', 'Application')]



========================================== PARAGRAPH 851 ===========================================

Medical Care (p. 829). American Medical Informatics Association.  

------------------- Sentence 1 -------------------

Medical Care (p. 829).

>> Tokens are: 
 ['Medical', 'Care', '(', 'p.', '829', ')', '.']

>> Bigrams are: 
 [('Medical', 'Care'), ('Care', '('), ('(', 'p.'), ('p.', '829'), ('829', ')'), (')', '.')]

>> Trigrams are: 
 [('Medical', 'Care', '('), ('Care', '(', 'p.'), ('(', 'p.', '829'), ('p.', '829', ')'), ('829', ')', '.')]

>> POS Tags are: 
 [('Medical', 'NNP'), ('Care', 'NNP'), ('(', '('), ('p.', 'VB'), ('829', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['Medical Care']

>> Named Entities are: 
 [('PERSON', 'Medical'), ('ORGANIZATION', 'Care')] 

>> Stemming using Porter Stemmer: 
 [('Medical', 'medic'), ('Care', 'care'), ('(', '('), ('p.', 'p.'), ('829', '829'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Medical', 'medic'), ('Care', 'care'), ('(', '('), ('p.', 'p.'), ('829', '829'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Medical', 'Medical'), ('Care', 'Care'), ('(', '('), ('p.', 'p.'), ('829', '829'), (')', ')'), ('.', '.')]


------------------- Sentence 2 -------------------

American Medical Informatics Association.

>> Tokens are: 
 ['American', 'Medical', 'Informatics', 'Association', '.']

>> Bigrams are: 
 [('American', 'Medical'), ('Medical', 'Informatics'), ('Informatics', 'Association'), ('Association', '.')]

>> Trigrams are: 
 [('American', 'Medical', 'Informatics'), ('Medical', 'Informatics', 'Association'), ('Informatics', 'Association', '.')]

>> POS Tags are: 
 [('American', 'NNP'), ('Medical', 'NNP'), ('Informatics', 'NNP'), ('Association', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['American Medical Informatics Association']

>> Named Entities are: 
 [('GPE', 'American'), ('ORGANIZATION', 'Medical Informatics Association')] 

>> Stemming using Porter Stemmer: 
 [('American', 'american'), ('Medical', 'medic'), ('Informatics', 'informat'), ('Association', 'associ'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('American', 'american'), ('Medical', 'medic'), ('Informatics', 'informat'), ('Association', 'associ'), ('.', '.')]

>> Lemmatization: 
 [('American', 'American'), ('Medical', 'Medical'), ('Informatics', 'Informatics'), ('Association', 'Association'), ('.', '.')]



========================================== PARAGRAPH 852 ===========================================

[98] "Natural Language Processing." Natural Language Processing RSS. N.p., n.d. Web. 23  

------------------- Sentence 1 -------------------

[98] "Natural Language Processing."

>> Tokens are: 
 ['[', '98', ']', '``', 'Natural', 'Language', 'Processing', '.', "''"]

>> Bigrams are: 
 [('[', '98'), ('98', ']'), (']', '``'), ('``', 'Natural'), ('Natural', 'Language'), ('Language', 'Processing'), ('Processing', '.'), ('.', "''")]

>> Trigrams are: 
 [('[', '98', ']'), ('98', ']', '``'), (']', '``', 'Natural'), ('``', 'Natural', 'Language'), ('Natural', 'Language', 'Processing'), ('Language', 'Processing', '.'), ('Processing', '.', "''")]

>> POS Tags are: 
 [('[', 'RB'), ('98', 'CD'), (']', 'NN'), ('``', '``'), ('Natural', 'JJ'), ('Language', 'NN'), ('Processing', 'NN'), ('.', '.'), ("''", "''")]

>> Noun Phrases are: 
 [']', 'Natural Language Processing']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('98', '98'), (']', ']'), ('``', '``'), ('Natural', 'natur'), ('Language', 'languag'), ('Processing', 'process'), ('.', '.'), ("''", "''")]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('98', '98'), (']', ']'), ('``', '``'), ('Natural', 'natur'), ('Language', 'languag'), ('Processing', 'process'), ('.', '.'), ("''", "''")]

>> Lemmatization: 
 [('[', '['), ('98', '98'), (']', ']'), ('``', '``'), ('Natural', 'Natural'), ('Language', 'Language'), ('Processing', 'Processing'), ('.', '.'), ("''", "''")]


------------------- Sentence 2 -------------------

Natural Language Processing RSS.

>> Tokens are: 
 ['Natural', 'Language', 'Processing', 'RSS', '.']

>> Bigrams are: 
 [('Natural', 'Language'), ('Language', 'Processing'), ('Processing', 'RSS'), ('RSS', '.')]

>> Trigrams are: 
 [('Natural', 'Language', 'Processing'), ('Language', 'Processing', 'RSS'), ('Processing', 'RSS', '.')]

>> POS Tags are: 
 [('Natural', 'JJ'), ('Language', 'NNP'), ('Processing', 'NNP'), ('RSS', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Natural Language Processing RSS']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Natural', 'natur'), ('Language', 'languag'), ('Processing', 'process'), ('RSS', 'rss'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Natural', 'natur'), ('Language', 'languag'), ('Processing', 'process'), ('RSS', 'rss'), ('.', '.')]

>> Lemmatization: 
 [('Natural', 'Natural'), ('Language', 'Language'), ('Processing', 'Processing'), ('RSS', 'RSS'), ('.', '.')]


------------------- Sentence 3 -------------------

N.p., n.d.

>> Tokens are: 
 ['N.p.', ',', 'n.d', '.']

>> Bigrams are: 
 [('N.p.', ','), (',', 'n.d'), ('n.d', '.')]

>> Trigrams are: 
 [('N.p.', ',', 'n.d'), (',', 'n.d', '.')]

>> POS Tags are: 
 [('N.p.', 'NNP'), (',', ','), ('n.d', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['N.p.', 'n.d']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('N.p.', 'n.p.'), (',', ','), ('n.d', 'n.d'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('N.p.', 'n.p.'), (',', ','), ('n.d', 'n.d'), ('.', '.')]

>> Lemmatization: 
 [('N.p.', 'N.p.'), (',', ','), ('n.d', 'n.d'), ('.', '.')]


------------------- Sentence 4 -------------------

Web.

>> Tokens are: 
 ['Web', '.']

>> Bigrams are: 
 [('Web', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Web', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Web']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Web', 'web'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Web', 'web'), ('.', '.')]

>> Lemmatization: 
 [('Web', 'Web'), ('.', '.')]


------------------- Sentence 5 -------------------

23

>> Tokens are: 
 ['23']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('23', 'CD')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('23', '23')]

>> Stemming using Snowball Stemmer: 
 [('23', '23')]

>> Lemmatization: 
 [('23', '23')]



========================================== PARAGRAPH 853 ===========================================

Mar. 2017.    

------------------- Sentence 1 -------------------

Mar.

>> Tokens are: 
 ['Mar', '.']

>> Bigrams are: 
 [('Mar', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Mar', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Mar']

>> Named Entities are: 
 [('PERSON', 'Mar')] 

>> Stemming using Porter Stemmer: 
 [('Mar', 'mar'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Mar', 'mar'), ('.', '.')]

>> Lemmatization: 
 [('Mar', 'Mar'), ('.', '.')]


------------------- Sentence 2 -------------------

2017.

>> Tokens are: 
 ['2017', '.']

>> Bigrams are: 
 [('2017', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('2017', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('2017', '2017'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('2017', '2017'), ('.', '.')]

>> Lemmatization: 
 [('2017', '2017'), ('.', '.')]



========================================== PARAGRAPH 854 ===========================================

[99] [Srihari S. Machine Learning: Generative and Discriminative Models. 2010. http://  

------------------- Sentence 1 -------------------

[99] [Srihari S. Machine Learning: Generative and Discriminative Models.

>> Tokens are: 
 ['[', '99', ']', '[', 'Srihari', 'S.', 'Machine', 'Learning', ':', 'Generative', 'Discriminative', 'Models', '.']

>> Bigrams are: 
 [('[', '99'), ('99', ']'), (']', '['), ('[', 'Srihari'), ('Srihari', 'S.'), ('S.', 'Machine'), ('Machine', 'Learning'), ('Learning', ':'), (':', 'Generative'), ('Generative', 'Discriminative'), ('Discriminative', 'Models'), ('Models', '.')]

>> Trigrams are: 
 [('[', '99', ']'), ('99', ']', '['), (']', '[', 'Srihari'), ('[', 'Srihari', 'S.'), ('Srihari', 'S.', 'Machine'), ('S.', 'Machine', 'Learning'), ('Machine', 'Learning', ':'), ('Learning', ':', 'Generative'), (':', 'Generative', 'Discriminative'), ('Generative', 'Discriminative', 'Models'), ('Discriminative', 'Models', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('99', 'CD'), (']', 'JJ'), ('[', 'NNP'), ('Srihari', 'NNP'), ('S.', 'NNP'), ('Machine', 'NNP'), ('Learning', 'NNP'), (':', ':'), ('Generative', 'JJ'), ('Discriminative', 'NNP'), ('Models', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['] [ Srihari S. Machine Learning', 'Generative Discriminative Models']

>> Named Entities are: 
 [('PERSON', 'Srihari S. Machine')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('99', '99'), (']', ']'), ('[', '['), ('Srihari', 'srihari'), ('S.', 's.'), ('Machine', 'machin'), ('Learning', 'learn'), (':', ':'), ('Generative', 'gener'), ('Discriminative', 'discrimin'), ('Models', 'model'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('99', '99'), (']', ']'), ('[', '['), ('Srihari', 'srihari'), ('S.', 's.'), ('Machine', 'machin'), ('Learning', 'learn'), (':', ':'), ('Generative', 'generat'), ('Discriminative', 'discrimin'), ('Models', 'model'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('99', '99'), (']', ']'), ('[', '['), ('Srihari', 'Srihari'), ('S.', 'S.'), ('Machine', 'Machine'), ('Learning', 'Learning'), (':', ':'), ('Generative', 'Generative'), ('Discriminative', 'Discriminative'), ('Models', 'Models'), ('.', '.')]


------------------- Sentence 2 -------------------

2010. http://

>> Tokens are: 
 ['2010.', 'http', ':', '//']

>> Bigrams are: 
 [('2010.', 'http'), ('http', ':'), (':', '//')]

>> Trigrams are: 
 [('2010.', 'http', ':'), ('http', ':', '//')]

>> POS Tags are: 
 [('2010.', 'CD'), ('http', 'NN'), (':', ':'), ('//', 'NN')]

>> Noun Phrases are: 
 ['http', '//']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('2010.', '2010.'), ('http', 'http'), (':', ':'), ('//', '//')]

>> Stemming using Snowball Stemmer: 
 [('2010.', '2010.'), ('http', 'http'), (':', ':'), ('//', '//')]

>> Lemmatization: 
 [('2010.', '2010.'), ('http', 'http'), (':', ':'), ('//', '//')]



========================================== PARAGRAPH 855 ===========================================

www.cedar.buffalo.edu/wsrihari/CSE574/Discriminative-Generative.pdf (accessed 31 May  

------------------- Sentence 1 -------------------

www.cedar.buffalo.edu/wsrihari/CSE574/Discriminative-Generative.pdf (accessed 31 May

>> Tokens are: 
 ['www.cedar.buffalo.edu/wsrihari/CSE574/Discriminative-Generative.pdf', '(', 'accessed', '31', 'May']

>> Bigrams are: 
 [('www.cedar.buffalo.edu/wsrihari/CSE574/Discriminative-Generative.pdf', '('), ('(', 'accessed'), ('accessed', '31'), ('31', 'May')]

>> Trigrams are: 
 [('www.cedar.buffalo.edu/wsrihari/CSE574/Discriminative-Generative.pdf', '(', 'accessed'), ('(', 'accessed', '31'), ('accessed', '31', 'May')]

>> POS Tags are: 
 [('www.cedar.buffalo.edu/wsrihari/CSE574/Discriminative-Generative.pdf', 'NN'), ('(', '('), ('accessed', 'JJ'), ('31', 'CD'), ('May', 'NNP')]

>> Noun Phrases are: 
 ['www.cedar.buffalo.edu/wsrihari/CSE574/Discriminative-Generative.pdf', 'May']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('www.cedar.buffalo.edu/wsrihari/CSE574/Discriminative-Generative.pdf', 'www.cedar.buffalo.edu/wsrihari/cse574/discriminative-generative.pdf'), ('(', '('), ('accessed', 'access'), ('31', '31'), ('May', 'may')]

>> Stemming using Snowball Stemmer: 
 [('www.cedar.buffalo.edu/wsrihari/CSE574/Discriminative-Generative.pdf', 'www.cedar.buffalo.edu/wsrihari/cse574/discriminative-generative.pdf'), ('(', '('), ('accessed', 'access'), ('31', '31'), ('May', 'may')]

>> Lemmatization: 
 [('www.cedar.buffalo.edu/wsrihari/CSE574/Discriminative-Generative.pdf', 'www.cedar.buffalo.edu/wsrihari/CSE574/Discriminative-Generative.pdf'), ('(', '('), ('accessed', 'accessed'), ('31', '31'), ('May', 'May')]



========================================== PARAGRAPH 856 ===========================================

2011).]  

------------------- Sentence 1 -------------------

2011).]

>> Tokens are: 
 ['2011', ')', '.', ']']

>> Bigrams are: 
 [('2011', ')'), (')', '.'), ('.', ']')]

>> Trigrams are: 
 [('2011', ')', '.'), (')', '.', ']')]

>> POS Tags are: 
 [('2011', 'CD'), (')', ')'), ('.', '.'), (']', 'NN')]

>> Noun Phrases are: 
 [']']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('2011', '2011'), (')', ')'), ('.', '.'), (']', ']')]

>> Stemming using Snowball Stemmer: 
 [('2011', '2011'), (')', ')'), ('.', '.'), (']', ']')]

>> Lemmatization: 
 [('2011', '2011'), (')', ')'), ('.', '.'), (']', ']')]



========================================== PARAGRAPH 857 ===========================================

[100] [Elkan C. Log-Linear Models and Conditional Random Fields. 2008. http://cseweb.  

------------------- Sentence 1 -------------------

[100] [Elkan C. Log-Linear Models and Conditional Random Fields.

>> Tokens are: 
 ['[', '100', ']', '[', 'Elkan', 'C.', 'Log-Linear', 'Models', 'Conditional', 'Random', 'Fields', '.']

>> Bigrams are: 
 [('[', '100'), ('100', ']'), (']', '['), ('[', 'Elkan'), ('Elkan', 'C.'), ('C.', 'Log-Linear'), ('Log-Linear', 'Models'), ('Models', 'Conditional'), ('Conditional', 'Random'), ('Random', 'Fields'), ('Fields', '.')]

>> Trigrams are: 
 [('[', '100', ']'), ('100', ']', '['), (']', '[', 'Elkan'), ('[', 'Elkan', 'C.'), ('Elkan', 'C.', 'Log-Linear'), ('C.', 'Log-Linear', 'Models'), ('Log-Linear', 'Models', 'Conditional'), ('Models', 'Conditional', 'Random'), ('Conditional', 'Random', 'Fields'), ('Random', 'Fields', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('100', 'CD'), (']', 'JJ'), ('[', 'NNP'), ('Elkan', 'NNP'), ('C.', 'NNP'), ('Log-Linear', 'NNP'), ('Models', 'NNP'), ('Conditional', 'NNP'), ('Random', 'NNP'), ('Fields', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['] [ Elkan C. Log-Linear Models Conditional Random Fields']

>> Named Entities are: 
 [('PERSON', 'Elkan C.'), ('PERSON', 'Random Fields')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('100', '100'), (']', ']'), ('[', '['), ('Elkan', 'elkan'), ('C.', 'c.'), ('Log-Linear', 'log-linear'), ('Models', 'model'), ('Conditional', 'condit'), ('Random', 'random'), ('Fields', 'field'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('100', '100'), (']', ']'), ('[', '['), ('Elkan', 'elkan'), ('C.', 'c.'), ('Log-Linear', 'log-linear'), ('Models', 'model'), ('Conditional', 'condit'), ('Random', 'random'), ('Fields', 'field'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('100', '100'), (']', ']'), ('[', '['), ('Elkan', 'Elkan'), ('C.', 'C.'), ('Log-Linear', 'Log-Linear'), ('Models', 'Models'), ('Conditional', 'Conditional'), ('Random', 'Random'), ('Fields', 'Fields'), ('.', '.')]


------------------- Sentence 2 -------------------

2008. http://cseweb.

>> Tokens are: 
 ['2008.', 'http', ':', '//cseweb', '.']

>> Bigrams are: 
 [('2008.', 'http'), ('http', ':'), (':', '//cseweb'), ('//cseweb', '.')]

>> Trigrams are: 
 [('2008.', 'http', ':'), ('http', ':', '//cseweb'), (':', '//cseweb', '.')]

>> POS Tags are: 
 [('2008.', 'CD'), ('http', 'NN'), (':', ':'), ('//cseweb', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['http', '//cseweb']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('2008.', '2008.'), ('http', 'http'), (':', ':'), ('//cseweb', '//cseweb'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('2008.', '2008.'), ('http', 'http'), (':', ':'), ('//cseweb', '//cseweb'), ('.', '.')]

>> Lemmatization: 
 [('2008.', '2008.'), ('http', 'http'), (':', ':'), ('//cseweb', '//cseweb'), ('.', '.')]



========================================== PARAGRAPH 858 ===========================================

ucsd.edu/welkan/250B/cikmtutorial.pdf (accessed 28 Jun 2011). 62. Hearst MA, Dumais ST,  

------------------- Sentence 1 -------------------

ucsd.edu/welkan/250B/cikmtutorial.pdf (accessed 28 Jun 2011).

>> Tokens are: 
 ['ucsd.edu/welkan/250B/cikmtutorial.pdf', '(', 'accessed', '28', 'Jun', '2011', ')', '.']

>> Bigrams are: 
 [('ucsd.edu/welkan/250B/cikmtutorial.pdf', '('), ('(', 'accessed'), ('accessed', '28'), ('28', 'Jun'), ('Jun', '2011'), ('2011', ')'), (')', '.')]

>> Trigrams are: 
 [('ucsd.edu/welkan/250B/cikmtutorial.pdf', '(', 'accessed'), ('(', 'accessed', '28'), ('accessed', '28', 'Jun'), ('28', 'Jun', '2011'), ('Jun', '2011', ')'), ('2011', ')', '.')]

>> POS Tags are: 
 [('ucsd.edu/welkan/250B/cikmtutorial.pdf', 'NN'), ('(', '('), ('accessed', 'JJ'), ('28', 'CD'), ('Jun', 'NNP'), ('2011', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['ucsd.edu/welkan/250B/cikmtutorial.pdf', 'Jun']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('ucsd.edu/welkan/250B/cikmtutorial.pdf', 'ucsd.edu/welkan/250b/cikmtutorial.pdf'), ('(', '('), ('accessed', 'access'), ('28', '28'), ('Jun', 'jun'), ('2011', '2011'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('ucsd.edu/welkan/250B/cikmtutorial.pdf', 'ucsd.edu/welkan/250b/cikmtutorial.pdf'), ('(', '('), ('accessed', 'access'), ('28', '28'), ('Jun', 'jun'), ('2011', '2011'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('ucsd.edu/welkan/250B/cikmtutorial.pdf', 'ucsd.edu/welkan/250B/cikmtutorial.pdf'), ('(', '('), ('accessed', 'accessed'), ('28', '28'), ('Jun', 'Jun'), ('2011', '2011'), (')', ')'), ('.', '.')]


------------------- Sentence 2 -------------------

62.

>> Tokens are: 
 ['62', '.']

>> Bigrams are: 
 [('62', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('62', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('62', '62'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('62', '62'), ('.', '.')]

>> Lemmatization: 
 [('62', '62'), ('.', '.')]


------------------- Sentence 3 -------------------

Hearst MA, Dumais ST,

>> Tokens are: 
 ['Hearst', 'MA', ',', 'Dumais', 'ST', ',']

>> Bigrams are: 
 [('Hearst', 'MA'), ('MA', ','), (',', 'Dumais'), ('Dumais', 'ST'), ('ST', ',')]

>> Trigrams are: 
 [('Hearst', 'MA', ','), ('MA', ',', 'Dumais'), (',', 'Dumais', 'ST'), ('Dumais', 'ST', ',')]

>> POS Tags are: 
 [('Hearst', 'NNP'), ('MA', 'NNP'), (',', ','), ('Dumais', 'NNP'), ('ST', 'NNP'), (',', ',')]

>> Noun Phrases are: 
 ['Hearst MA', 'Dumais ST']

>> Named Entities are: 
 [('PERSON', 'Hearst'), ('GPE', 'MA'), ('PERSON', 'Dumais ST')] 

>> Stemming using Porter Stemmer: 
 [('Hearst', 'hearst'), ('MA', 'ma'), (',', ','), ('Dumais', 'dumai'), ('ST', 'st'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('Hearst', 'hearst'), ('MA', 'ma'), (',', ','), ('Dumais', 'dumai'), ('ST', 'st'), (',', ',')]

>> Lemmatization: 
 [('Hearst', 'Hearst'), ('MA', 'MA'), (',', ','), ('Dumais', 'Dumais'), ('ST', 'ST'), (',', ',')]



========================================== PARAGRAPH 859 ===========================================

Osman E, et al. Support vector machines]  

------------------- Sentence 1 -------------------

Osman E, et al.

>> Tokens are: 
 ['Osman', 'E', ',', 'et', 'al', '.']

>> Bigrams are: 
 [('Osman', 'E'), ('E', ','), (',', 'et'), ('et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('Osman', 'E', ','), ('E', ',', 'et'), (',', 'et', 'al'), ('et', 'al', '.')]

>> POS Tags are: 
 [('Osman', 'NNP'), ('E', 'NNP'), (',', ','), ('et', 'RB'), ('al', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Osman E', 'al']

>> Named Entities are: 
 [('PERSON', 'Osman'), ('ORGANIZATION', 'E')] 

>> Stemming using Porter Stemmer: 
 [('Osman', 'osman'), ('E', 'e'), (',', ','), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Osman', 'osman'), ('E', 'e'), (',', ','), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('Osman', 'Osman'), ('E', 'E'), (',', ','), ('et', 'et'), ('al', 'al'), ('.', '.')]


------------------- Sentence 2 -------------------

Support vector machines]

>> Tokens are: 
 ['Support', 'vector', 'machines', ']']

>> Bigrams are: 
 [('Support', 'vector'), ('vector', 'machines'), ('machines', ']')]

>> Trigrams are: 
 [('Support', 'vector', 'machines'), ('vector', 'machines', ']')]

>> POS Tags are: 
 [('Support', 'NNP'), ('vector', 'NN'), ('machines', 'NNS'), (']', 'VBP')]

>> Noun Phrases are: 
 ['Support vector machines']

>> Named Entities are: 
 [('GPE', 'Support')] 

>> Stemming using Porter Stemmer: 
 [('Support', 'support'), ('vector', 'vector'), ('machines', 'machin'), (']', ']')]

>> Stemming using Snowball Stemmer: 
 [('Support', 'support'), ('vector', 'vector'), ('machines', 'machin'), (']', ']')]

>> Lemmatization: 
 [('Support', 'Support'), ('vector', 'vector'), ('machines', 'machine'), (']', ']')]



========================================== PARAGRAPH 860 ===========================================

[101] [Jurafsky D, Martin JH. Speech and Language Processing. 2nd edn. Englewood Cliffs,  

------------------- Sentence 1 -------------------

[101] [Jurafsky D, Martin JH.

>> Tokens are: 
 ['[', '101', ']', '[', 'Jurafsky', 'D', ',', 'Martin', 'JH', '.']

>> Bigrams are: 
 [('[', '101'), ('101', ']'), (']', '['), ('[', 'Jurafsky'), ('Jurafsky', 'D'), ('D', ','), (',', 'Martin'), ('Martin', 'JH'), ('JH', '.')]

>> Trigrams are: 
 [('[', '101', ']'), ('101', ']', '['), (']', '[', 'Jurafsky'), ('[', 'Jurafsky', 'D'), ('Jurafsky', 'D', ','), ('D', ',', 'Martin'), (',', 'Martin', 'JH'), ('Martin', 'JH', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('101', 'CD'), (']', 'JJ'), ('[', 'NNP'), ('Jurafsky', 'NNP'), ('D', 'NNP'), (',', ','), ('Martin', 'NNP'), ('JH', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['] [ Jurafsky D', 'Martin JH']

>> Named Entities are: 
 [('PERSON', 'Martin JH')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('101', '101'), (']', ']'), ('[', '['), ('Jurafsky', 'jurafski'), ('D', 'd'), (',', ','), ('Martin', 'martin'), ('JH', 'jh'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('101', '101'), (']', ']'), ('[', '['), ('Jurafsky', 'jurafski'), ('D', 'd'), (',', ','), ('Martin', 'martin'), ('JH', 'jh'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('101', '101'), (']', ']'), ('[', '['), ('Jurafsky', 'Jurafsky'), ('D', 'D'), (',', ','), ('Martin', 'Martin'), ('JH', 'JH'), ('.', '.')]


------------------- Sentence 2 -------------------

Speech and Language Processing.

>> Tokens are: 
 ['Speech', 'Language', 'Processing', '.']

>> Bigrams are: 
 [('Speech', 'Language'), ('Language', 'Processing'), ('Processing', '.')]

>> Trigrams are: 
 [('Speech', 'Language', 'Processing'), ('Language', 'Processing', '.')]

>> POS Tags are: 
 [('Speech', 'NNP'), ('Language', 'NNP'), ('Processing', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Speech Language Processing']

>> Named Entities are: 
 [('PERSON', 'Speech'), ('PERSON', 'Language Processing')] 

>> Stemming using Porter Stemmer: 
 [('Speech', 'speech'), ('Language', 'languag'), ('Processing', 'process'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Speech', 'speech'), ('Language', 'languag'), ('Processing', 'process'), ('.', '.')]

>> Lemmatization: 
 [('Speech', 'Speech'), ('Language', 'Language'), ('Processing', 'Processing'), ('.', '.')]


------------------- Sentence 3 -------------------

2nd edn.

>> Tokens are: 
 ['2nd', 'edn', '.']

>> Bigrams are: 
 [('2nd', 'edn'), ('edn', '.')]

>> Trigrams are: 
 [('2nd', 'edn', '.')]

>> POS Tags are: 
 [('2nd', 'CD'), ('edn', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['edn']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('2nd', '2nd'), ('edn', 'edn'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('2nd', '2nd'), ('edn', 'edn'), ('.', '.')]

>> Lemmatization: 
 [('2nd', '2nd'), ('edn', 'edn'), ('.', '.')]


------------------- Sentence 4 -------------------

Englewood Cliffs,

>> Tokens are: 
 ['Englewood', 'Cliffs', ',']

>> Bigrams are: 
 [('Englewood', 'Cliffs'), ('Cliffs', ',')]

>> Trigrams are: 
 [('Englewood', 'Cliffs', ',')]

>> POS Tags are: 
 [('Englewood', 'NNP'), ('Cliffs', 'NNP'), (',', ',')]

>> Noun Phrases are: 
 ['Englewood Cliffs']

>> Named Entities are: 
 [('PERSON', 'Englewood'), ('PERSON', 'Cliffs')] 

>> Stemming using Porter Stemmer: 
 [('Englewood', 'englewood'), ('Cliffs', 'cliff'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('Englewood', 'englewood'), ('Cliffs', 'cliff'), (',', ',')]

>> Lemmatization: 
 [('Englewood', 'Englewood'), ('Cliffs', 'Cliffs'), (',', ',')]



========================================== PARAGRAPH 861 ===========================================

NJ: Prentice-Hall, 2008.]  

------------------- Sentence 1 -------------------

NJ: Prentice-Hall, 2008.]

>> Tokens are: 
 ['NJ', ':', 'Prentice-Hall', ',', '2008', '.', ']']

>> Bigrams are: 
 [('NJ', ':'), (':', 'Prentice-Hall'), ('Prentice-Hall', ','), (',', '2008'), ('2008', '.'), ('.', ']')]

>> Trigrams are: 
 [('NJ', ':', 'Prentice-Hall'), (':', 'Prentice-Hall', ','), ('Prentice-Hall', ',', '2008'), (',', '2008', '.'), ('2008', '.', ']')]

>> POS Tags are: 
 [('NJ', 'NN'), (':', ':'), ('Prentice-Hall', 'NN'), (',', ','), ('2008', 'CD'), ('.', '.'), (']', 'VB')]

>> Noun Phrases are: 
 ['NJ', 'Prentice-Hall']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('NJ', 'nj'), (':', ':'), ('Prentice-Hall', 'prentice-hal'), (',', ','), ('2008', '2008'), ('.', '.'), (']', ']')]

>> Stemming using Snowball Stemmer: 
 [('NJ', 'nj'), (':', ':'), ('Prentice-Hall', 'prentice-hal'), (',', ','), ('2008', '2008'), ('.', '.'), (']', ']')]

>> Lemmatization: 
 [('NJ', 'NJ'), (':', ':'), ('Prentice-Hall', 'Prentice-Hall'), (',', ','), ('2008', '2008'), ('.', '.'), (']', ']')]



========================================== PARAGRAPH 862 ===========================================

[102] [Sonnhammer ELL, Eddy SR, Birney E, et al. Pfam: Multiple sequence alignments and  

------------------- Sentence 1 -------------------

[102] [Sonnhammer ELL, Eddy SR, Birney E, et al.

>> Tokens are: 
 ['[', '102', ']', '[', 'Sonnhammer', 'ELL', ',', 'Eddy', 'SR', ',', 'Birney', 'E', ',', 'et', 'al', '.']

>> Bigrams are: 
 [('[', '102'), ('102', ']'), (']', '['), ('[', 'Sonnhammer'), ('Sonnhammer', 'ELL'), ('ELL', ','), (',', 'Eddy'), ('Eddy', 'SR'), ('SR', ','), (',', 'Birney'), ('Birney', 'E'), ('E', ','), (',', 'et'), ('et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('[', '102', ']'), ('102', ']', '['), (']', '[', 'Sonnhammer'), ('[', 'Sonnhammer', 'ELL'), ('Sonnhammer', 'ELL', ','), ('ELL', ',', 'Eddy'), (',', 'Eddy', 'SR'), ('Eddy', 'SR', ','), ('SR', ',', 'Birney'), (',', 'Birney', 'E'), ('Birney', 'E', ','), ('E', ',', 'et'), (',', 'et', 'al'), ('et', 'al', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('102', 'CD'), (']', 'JJ'), ('[', 'NNP'), ('Sonnhammer', 'NNP'), ('ELL', 'NNP'), (',', ','), ('Eddy', 'NNP'), ('SR', 'NNP'), (',', ','), ('Birney', 'NNP'), ('E', 'NNP'), (',', ','), ('et', 'RB'), ('al', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['] [ Sonnhammer ELL', 'Eddy SR', 'Birney E', 'al']

>> Named Entities are: 
 [('PERSON', 'Eddy SR'), ('PERSON', 'Birney E')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('102', '102'), (']', ']'), ('[', '['), ('Sonnhammer', 'sonnhamm'), ('ELL', 'ell'), (',', ','), ('Eddy', 'eddi'), ('SR', 'sr'), (',', ','), ('Birney', 'birney'), ('E', 'e'), (',', ','), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('102', '102'), (']', ']'), ('[', '['), ('Sonnhammer', 'sonnhamm'), ('ELL', 'ell'), (',', ','), ('Eddy', 'eddi'), ('SR', 'sr'), (',', ','), ('Birney', 'birney'), ('E', 'e'), (',', ','), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('102', '102'), (']', ']'), ('[', '['), ('Sonnhammer', 'Sonnhammer'), ('ELL', 'ELL'), (',', ','), ('Eddy', 'Eddy'), ('SR', 'SR'), (',', ','), ('Birney', 'Birney'), ('E', 'E'), (',', ','), ('et', 'et'), ('al', 'al'), ('.', '.')]


------------------- Sentence 2 -------------------

Pfam: Multiple sequence alignments and

>> Tokens are: 
 ['Pfam', ':', 'Multiple', 'sequence', 'alignments']

>> Bigrams are: 
 [('Pfam', ':'), (':', 'Multiple'), ('Multiple', 'sequence'), ('sequence', 'alignments')]

>> Trigrams are: 
 [('Pfam', ':', 'Multiple'), (':', 'Multiple', 'sequence'), ('Multiple', 'sequence', 'alignments')]

>> POS Tags are: 
 [('Pfam', 'NN'), (':', ':'), ('Multiple', 'JJ'), ('sequence', 'NN'), ('alignments', 'NNS')]

>> Noun Phrases are: 
 ['Pfam', 'Multiple sequence alignments']

>> Named Entities are: 
 [('GPE', 'Pfam')] 

>> Stemming using Porter Stemmer: 
 [('Pfam', 'pfam'), (':', ':'), ('Multiple', 'multipl'), ('sequence', 'sequenc'), ('alignments', 'align')]

>> Stemming using Snowball Stemmer: 
 [('Pfam', 'pfam'), (':', ':'), ('Multiple', 'multipl'), ('sequence', 'sequenc'), ('alignments', 'align')]

>> Lemmatization: 
 [('Pfam', 'Pfam'), (':', ':'), ('Multiple', 'Multiple'), ('sequence', 'sequence'), ('alignments', 'alignment')]



========================================== PARAGRAPH 863 ===========================================

HMM-profiles of protein domains. Nucleic Acids Res 1998;26:320]  

------------------- Sentence 1 -------------------

HMM-profiles of protein domains.

>> Tokens are: 
 ['HMM-profiles', 'protein', 'domains', '.']

>> Bigrams are: 
 [('HMM-profiles', 'protein'), ('protein', 'domains'), ('domains', '.')]

>> Trigrams are: 
 [('HMM-profiles', 'protein', 'domains'), ('protein', 'domains', '.')]

>> POS Tags are: 
 [('HMM-profiles', 'NNP'), ('protein', 'NN'), ('domains', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['HMM-profiles protein domains']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('HMM-profiles', 'hmm-profil'), ('protein', 'protein'), ('domains', 'domain'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('HMM-profiles', 'hmm-profil'), ('protein', 'protein'), ('domains', 'domain'), ('.', '.')]

>> Lemmatization: 
 [('HMM-profiles', 'HMM-profiles'), ('protein', 'protein'), ('domains', 'domain'), ('.', '.')]


------------------- Sentence 2 -------------------

Nucleic Acids Res 1998;26:320]

>> Tokens are: 
 ['Nucleic', 'Acids', 'Res', '1998', ';', '26:320', ']']

>> Bigrams are: 
 [('Nucleic', 'Acids'), ('Acids', 'Res'), ('Res', '1998'), ('1998', ';'), (';', '26:320'), ('26:320', ']')]

>> Trigrams are: 
 [('Nucleic', 'Acids', 'Res'), ('Acids', 'Res', '1998'), ('Res', '1998', ';'), ('1998', ';', '26:320'), (';', '26:320', ']')]

>> POS Tags are: 
 [('Nucleic', 'NNP'), ('Acids', 'NNP'), ('Res', 'NNP'), ('1998', 'CD'), (';', ':'), ('26:320', 'CD'), (']', 'NN')]

>> Noun Phrases are: 
 ['Nucleic Acids Res', ']']

>> Named Entities are: 
 [('PERSON', 'Nucleic'), ('PERSON', 'Acids Res')] 

>> Stemming using Porter Stemmer: 
 [('Nucleic', 'nucleic'), ('Acids', 'acid'), ('Res', 're'), ('1998', '1998'), (';', ';'), ('26:320', '26:320'), (']', ']')]

>> Stemming using Snowball Stemmer: 
 [('Nucleic', 'nucleic'), ('Acids', 'acid'), ('Res', 'res'), ('1998', '1998'), (';', ';'), ('26:320', '26:320'), (']', ']')]

>> Lemmatization: 
 [('Nucleic', 'Nucleic'), ('Acids', 'Acids'), ('Res', 'Res'), ('1998', '1998'), (';', ';'), ('26:320', '26:320'), (']', ']')]



========================================== PARAGRAPH 864 ===========================================

[103] [Sonnhammer, E. L., Eddy, S. R., Birney, E., Bateman, A., & Durbin, R. (1998). Pfam:  

------------------- Sentence 1 -------------------

[103] [Sonnhammer, E. L., Eddy, S. R., Birney, E., Bateman, A., & Durbin, R. (1998).

>> Tokens are: 
 ['[', '103', ']', '[', 'Sonnhammer', ',', 'E.', 'L.', ',', 'Eddy', ',', 'S.', 'R.', ',', 'Birney', ',', 'E.', ',', 'Bateman', ',', 'A.', ',', '&', 'Durbin', ',', 'R.', '(', '1998', ')', '.']

>> Bigrams are: 
 [('[', '103'), ('103', ']'), (']', '['), ('[', 'Sonnhammer'), ('Sonnhammer', ','), (',', 'E.'), ('E.', 'L.'), ('L.', ','), (',', 'Eddy'), ('Eddy', ','), (',', 'S.'), ('S.', 'R.'), ('R.', ','), (',', 'Birney'), ('Birney', ','), (',', 'E.'), ('E.', ','), (',', 'Bateman'), ('Bateman', ','), (',', 'A.'), ('A.', ','), (',', '&'), ('&', 'Durbin'), ('Durbin', ','), (',', 'R.'), ('R.', '('), ('(', '1998'), ('1998', ')'), (')', '.')]

>> Trigrams are: 
 [('[', '103', ']'), ('103', ']', '['), (']', '[', 'Sonnhammer'), ('[', 'Sonnhammer', ','), ('Sonnhammer', ',', 'E.'), (',', 'E.', 'L.'), ('E.', 'L.', ','), ('L.', ',', 'Eddy'), (',', 'Eddy', ','), ('Eddy', ',', 'S.'), (',', 'S.', 'R.'), ('S.', 'R.', ','), ('R.', ',', 'Birney'), (',', 'Birney', ','), ('Birney', ',', 'E.'), (',', 'E.', ','), ('E.', ',', 'Bateman'), (',', 'Bateman', ','), ('Bateman', ',', 'A.'), (',', 'A.', ','), ('A.', ',', '&'), (',', '&', 'Durbin'), ('&', 'Durbin', ','), ('Durbin', ',', 'R.'), (',', 'R.', '('), ('R.', '(', '1998'), ('(', '1998', ')'), ('1998', ')', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('103', 'CD'), (']', 'JJ'), ('[', 'NNP'), ('Sonnhammer', 'NNP'), (',', ','), ('E.', 'NNP'), ('L.', 'NNP'), (',', ','), ('Eddy', 'NNP'), (',', ','), ('S.', 'NNP'), ('R.', 'NNP'), (',', ','), ('Birney', 'NNP'), (',', ','), ('E.', 'NNP'), (',', ','), ('Bateman', 'NNP'), (',', ','), ('A.', 'NNP'), (',', ','), ('&', 'CC'), ('Durbin', 'NNP'), (',', ','), ('R.', 'NNP'), ('(', '('), ('1998', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['] [ Sonnhammer', 'E. L.', 'Eddy', 'S. R.', 'Birney', 'E.', 'Bateman', 'A.', 'Durbin', 'R.']

>> Named Entities are: 
 [('PERSON', 'Eddy'), ('GPE', 'Birney'), ('PERSON', 'Bateman'), ('PERSON', 'Durbin')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('103', '103'), (']', ']'), ('[', '['), ('Sonnhammer', 'sonnhamm'), (',', ','), ('E.', 'e.'), ('L.', 'l.'), (',', ','), ('Eddy', 'eddi'), (',', ','), ('S.', 's.'), ('R.', 'r.'), (',', ','), ('Birney', 'birney'), (',', ','), ('E.', 'e.'), (',', ','), ('Bateman', 'bateman'), (',', ','), ('A.', 'a.'), (',', ','), ('&', '&'), ('Durbin', 'durbin'), (',', ','), ('R.', 'r.'), ('(', '('), ('1998', '1998'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('103', '103'), (']', ']'), ('[', '['), ('Sonnhammer', 'sonnhamm'), (',', ','), ('E.', 'e.'), ('L.', 'l.'), (',', ','), ('Eddy', 'eddi'), (',', ','), ('S.', 's.'), ('R.', 'r.'), (',', ','), ('Birney', 'birney'), (',', ','), ('E.', 'e.'), (',', ','), ('Bateman', 'bateman'), (',', ','), ('A.', 'a.'), (',', ','), ('&', '&'), ('Durbin', 'durbin'), (',', ','), ('R.', 'r.'), ('(', '('), ('1998', '1998'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('103', '103'), (']', ']'), ('[', '['), ('Sonnhammer', 'Sonnhammer'), (',', ','), ('E.', 'E.'), ('L.', 'L.'), (',', ','), ('Eddy', 'Eddy'), (',', ','), ('S.', 'S.'), ('R.', 'R.'), (',', ','), ('Birney', 'Birney'), (',', ','), ('E.', 'E.'), (',', ','), ('Bateman', 'Bateman'), (',', ','), ('A.', 'A.'), (',', ','), ('&', '&'), ('Durbin', 'Durbin'), (',', ','), ('R.', 'R.'), ('(', '('), ('1998', '1998'), (')', ')'), ('.', '.')]


------------------- Sentence 2 -------------------

Pfam:

>> Tokens are: 
 ['Pfam', ':']

>> Bigrams are: 
 [('Pfam', ':')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Pfam', 'NN'), (':', ':')]

>> Noun Phrases are: 
 ['Pfam']

>> Named Entities are: 
 [('GPE', 'Pfam')] 

>> Stemming using Porter Stemmer: 
 [('Pfam', 'pfam'), (':', ':')]

>> Stemming using Snowball Stemmer: 
 [('Pfam', 'pfam'), (':', ':')]

>> Lemmatization: 
 [('Pfam', 'Pfam'), (':', ':')]



========================================== PARAGRAPH 865 ===========================================

multiple sequence alignments and HMM-profiles of protein domains. Nucleic acids  

------------------- Sentence 1 -------------------

multiple sequence alignments and HMM-profiles of protein domains.

>> Tokens are: 
 ['multiple', 'sequence', 'alignments', 'HMM-profiles', 'protein', 'domains', '.']

>> Bigrams are: 
 [('multiple', 'sequence'), ('sequence', 'alignments'), ('alignments', 'HMM-profiles'), ('HMM-profiles', 'protein'), ('protein', 'domains'), ('domains', '.')]

>> Trigrams are: 
 [('multiple', 'sequence', 'alignments'), ('sequence', 'alignments', 'HMM-profiles'), ('alignments', 'HMM-profiles', 'protein'), ('HMM-profiles', 'protein', 'domains'), ('protein', 'domains', '.')]

>> POS Tags are: 
 [('multiple', 'JJ'), ('sequence', 'NN'), ('alignments', 'NNS'), ('HMM-profiles', 'NNP'), ('protein', 'NN'), ('domains', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['multiple sequence alignments HMM-profiles protein domains']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('multiple', 'multipl'), ('sequence', 'sequenc'), ('alignments', 'align'), ('HMM-profiles', 'hmm-profil'), ('protein', 'protein'), ('domains', 'domain'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('multiple', 'multipl'), ('sequence', 'sequenc'), ('alignments', 'align'), ('HMM-profiles', 'hmm-profil'), ('protein', 'protein'), ('domains', 'domain'), ('.', '.')]

>> Lemmatization: 
 [('multiple', 'multiple'), ('sequence', 'sequence'), ('alignments', 'alignment'), ('HMM-profiles', 'HMM-profiles'), ('protein', 'protein'), ('domains', 'domain'), ('.', '.')]


------------------- Sentence 2 -------------------

Nucleic acids

>> Tokens are: 
 ['Nucleic', 'acids']

>> Bigrams are: 
 [('Nucleic', 'acids')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Nucleic', 'NNP'), ('acids', 'NNS')]

>> Noun Phrases are: 
 ['Nucleic acids']

>> Named Entities are: 
 [('GPE', 'Nucleic')] 

>> Stemming using Porter Stemmer: 
 [('Nucleic', 'nucleic'), ('acids', 'acid')]

>> Stemming using Snowball Stemmer: 
 [('Nucleic', 'nucleic'), ('acids', 'acid')]

>> Lemmatization: 
 [('Nucleic', 'Nucleic'), ('acids', 'acid')]



========================================== PARAGRAPH 866 ===========================================

research, 26(1), 320-322]  

------------------- Sentence 1 -------------------

research, 26(1), 320-322]

>> Tokens are: 
 ['research', ',', '26', '(', '1', ')', ',', '320-322', ']']

>> Bigrams are: 
 [('research', ','), (',', '26'), ('26', '('), ('(', '1'), ('1', ')'), (')', ','), (',', '320-322'), ('320-322', ']')]

>> Trigrams are: 
 [('research', ',', '26'), (',', '26', '('), ('26', '(', '1'), ('(', '1', ')'), ('1', ')', ','), (')', ',', '320-322'), (',', '320-322', ']')]

>> POS Tags are: 
 [('research', 'NN'), (',', ','), ('26', 'CD'), ('(', '('), ('1', 'CD'), (')', ')'), (',', ','), ('320-322', 'JJ'), (']', 'NN')]

>> Noun Phrases are: 
 ['research', '320-322 ]']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('research', 'research'), (',', ','), ('26', '26'), ('(', '('), ('1', '1'), (')', ')'), (',', ','), ('320-322', '320-322'), (']', ']')]

>> Stemming using Snowball Stemmer: 
 [('research', 'research'), (',', ','), ('26', '26'), ('(', '('), ('1', '1'), (')', ')'), (',', ','), ('320-322', '320-322'), (']', ']')]

>> Lemmatization: 
 [('research', 'research'), (',', ','), ('26', '26'), ('(', '('), ('1', '1'), (')', ')'), (',', ','), ('320-322', '320-322'), (']', ']')]



========================================== PARAGRAPH 867 ===========================================

[104] Systems, RAVN. "RAVN Systems Launch the ACE Powered GDPR Robot - Artificial  

------------------- Sentence 1 -------------------

[104] Systems, RAVN.

>> Tokens are: 
 ['[', '104', ']', 'Systems', ',', 'RAVN', '.']

>> Bigrams are: 
 [('[', '104'), ('104', ']'), (']', 'Systems'), ('Systems', ','), (',', 'RAVN'), ('RAVN', '.')]

>> Trigrams are: 
 [('[', '104', ']'), ('104', ']', 'Systems'), (']', 'Systems', ','), ('Systems', ',', 'RAVN'), (',', 'RAVN', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('104', 'CD'), (']', 'JJ'), ('Systems', 'NNPS'), (',', ','), ('RAVN', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['RAVN']

>> Named Entities are: 
 [('ORGANIZATION', 'RAVN')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('104', '104'), (']', ']'), ('Systems', 'system'), (',', ','), ('RAVN', 'ravn'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('104', '104'), (']', ']'), ('Systems', 'system'), (',', ','), ('RAVN', 'ravn'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('104', '104'), (']', ']'), ('Systems', 'Systems'), (',', ','), ('RAVN', 'RAVN'), ('.', '.')]


------------------- Sentence 2 -------------------

"RAVN Systems Launch the ACE Powered GDPR Robot - Artificial

>> Tokens are: 
 ['``', 'RAVN', 'Systems', 'Launch', 'ACE', 'Powered', 'GDPR', 'Robot', '-', 'Artificial']

>> Bigrams are: 
 [('``', 'RAVN'), ('RAVN', 'Systems'), ('Systems', 'Launch'), ('Launch', 'ACE'), ('ACE', 'Powered'), ('Powered', 'GDPR'), ('GDPR', 'Robot'), ('Robot', '-'), ('-', 'Artificial')]

>> Trigrams are: 
 [('``', 'RAVN', 'Systems'), ('RAVN', 'Systems', 'Launch'), ('Systems', 'Launch', 'ACE'), ('Launch', 'ACE', 'Powered'), ('ACE', 'Powered', 'GDPR'), ('Powered', 'GDPR', 'Robot'), ('GDPR', 'Robot', '-'), ('Robot', '-', 'Artificial')]

>> POS Tags are: 
 [('``', '``'), ('RAVN', 'JJ'), ('Systems', 'NNP'), ('Launch', 'NNP'), ('ACE', 'NNP'), ('Powered', 'NNP'), ('GDPR', 'NNP'), ('Robot', 'NNP'), ('-', ':'), ('Artificial', 'NN')]

>> Noun Phrases are: 
 ['RAVN Systems Launch ACE Powered GDPR Robot', 'Artificial']

>> Named Entities are: 
 [('ORGANIZATION', 'RAVN Systems Launch'), ('PERSON', 'Robot'), ('ORGANIZATION', 'Artificial')] 

>> Stemming using Porter Stemmer: 
 [('``', '``'), ('RAVN', 'ravn'), ('Systems', 'system'), ('Launch', 'launch'), ('ACE', 'ace'), ('Powered', 'power'), ('GDPR', 'gdpr'), ('Robot', 'robot'), ('-', '-'), ('Artificial', 'artifici')]

>> Stemming using Snowball Stemmer: 
 [('``', '``'), ('RAVN', 'ravn'), ('Systems', 'system'), ('Launch', 'launch'), ('ACE', 'ace'), ('Powered', 'power'), ('GDPR', 'gdpr'), ('Robot', 'robot'), ('-', '-'), ('Artificial', 'artifici')]

>> Lemmatization: 
 [('``', '``'), ('RAVN', 'RAVN'), ('Systems', 'Systems'), ('Launch', 'Launch'), ('ACE', 'ACE'), ('Powered', 'Powered'), ('GDPR', 'GDPR'), ('Robot', 'Robot'), ('-', '-'), ('Artificial', 'Artificial')]



========================================== PARAGRAPH 868 ===========================================

Intelligence to Expedite GDPR Compliance." Stock Market. PR Newswire, n.d. Web. 19  

------------------- Sentence 1 -------------------

Intelligence to Expedite GDPR Compliance."

>> Tokens are: 
 ['Intelligence', 'Expedite', 'GDPR', 'Compliance', '.', "''"]

>> Bigrams are: 
 [('Intelligence', 'Expedite'), ('Expedite', 'GDPR'), ('GDPR', 'Compliance'), ('Compliance', '.'), ('.', "''")]

>> Trigrams are: 
 [('Intelligence', 'Expedite', 'GDPR'), ('Expedite', 'GDPR', 'Compliance'), ('GDPR', 'Compliance', '.'), ('Compliance', '.', "''")]

>> POS Tags are: 
 [('Intelligence', 'NNP'), ('Expedite', 'NNP'), ('GDPR', 'NNP'), ('Compliance', 'NNP'), ('.', '.'), ("''", "''")]

>> Noun Phrases are: 
 ['Intelligence Expedite GDPR Compliance']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Intelligence', 'intellig'), ('Expedite', 'expedit'), ('GDPR', 'gdpr'), ('Compliance', 'complianc'), ('.', '.'), ("''", "''")]

>> Stemming using Snowball Stemmer: 
 [('Intelligence', 'intellig'), ('Expedite', 'expedit'), ('GDPR', 'gdpr'), ('Compliance', 'complianc'), ('.', '.'), ("''", "''")]

>> Lemmatization: 
 [('Intelligence', 'Intelligence'), ('Expedite', 'Expedite'), ('GDPR', 'GDPR'), ('Compliance', 'Compliance'), ('.', '.'), ("''", "''")]


------------------- Sentence 2 -------------------

Stock Market.

>> Tokens are: 
 ['Stock', 'Market', '.']

>> Bigrams are: 
 [('Stock', 'Market'), ('Market', '.')]

>> Trigrams are: 
 [('Stock', 'Market', '.')]

>> POS Tags are: 
 [('Stock', 'NN'), ('Market', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Stock Market']

>> Named Entities are: 
 [('GPE', 'Stock'), ('ORGANIZATION', 'Market')] 

>> Stemming using Porter Stemmer: 
 [('Stock', 'stock'), ('Market', 'market'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Stock', 'stock'), ('Market', 'market'), ('.', '.')]

>> Lemmatization: 
 [('Stock', 'Stock'), ('Market', 'Market'), ('.', '.')]


------------------- Sentence 3 -------------------

PR Newswire, n.d.

>> Tokens are: 
 ['PR', 'Newswire', ',', 'n.d', '.']

>> Bigrams are: 
 [('PR', 'Newswire'), ('Newswire', ','), (',', 'n.d'), ('n.d', '.')]

>> Trigrams are: 
 [('PR', 'Newswire', ','), ('Newswire', ',', 'n.d'), (',', 'n.d', '.')]

>> POS Tags are: 
 [('PR', 'NNP'), ('Newswire', 'NNP'), (',', ','), ('n.d', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['PR Newswire', 'n.d']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('PR', 'pr'), ('Newswire', 'newswir'), (',', ','), ('n.d', 'n.d'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('PR', 'pr'), ('Newswire', 'newswir'), (',', ','), ('n.d', 'n.d'), ('.', '.')]

>> Lemmatization: 
 [('PR', 'PR'), ('Newswire', 'Newswire'), (',', ','), ('n.d', 'n.d'), ('.', '.')]


------------------- Sentence 4 -------------------

Web.

>> Tokens are: 
 ['Web', '.']

>> Bigrams are: 
 [('Web', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Web', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Web']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Web', 'web'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Web', 'web'), ('.', '.')]

>> Lemmatization: 
 [('Web', 'Web'), ('.', '.')]


------------------- Sentence 5 -------------------

19

>> Tokens are: 
 ['19']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('19', 'CD')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('19', '19')]

>> Stemming using Snowball Stemmer: 
 [('19', '19')]

>> Lemmatization: 
 [('19', '19')]



========================================== PARAGRAPH 869 ===========================================

Mar. 2017.  

------------------- Sentence 1 -------------------

Mar.

>> Tokens are: 
 ['Mar', '.']

>> Bigrams are: 
 [('Mar', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Mar', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Mar']

>> Named Entities are: 
 [('PERSON', 'Mar')] 

>> Stemming using Porter Stemmer: 
 [('Mar', 'mar'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Mar', 'mar'), ('.', '.')]

>> Lemmatization: 
 [('Mar', 'Mar'), ('.', '.')]


------------------- Sentence 2 -------------------

2017.

>> Tokens are: 
 ['2017', '.']

>> Bigrams are: 
 [('2017', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('2017', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('2017', '2017'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('2017', '2017'), ('.', '.')]

>> Lemmatization: 
 [('2017', '2017'), ('.', '.')]



========================================== PARAGRAPH 870 ===========================================

 [105] "Here's Why Natural Language Processing is the Future of BI." SmartData Collective.  

------------------- Sentence 1 -------------------

 [105] "Here's Why Natural Language Processing is the Future of BI."

>> Tokens are: 
 ['[', '105', ']', '``', 'Here', "'s", 'Why', 'Natural', 'Language', 'Processing', 'Future', 'BI', '.', "''"]

>> Bigrams are: 
 [('[', '105'), ('105', ']'), (']', '``'), ('``', 'Here'), ('Here', "'s"), ("'s", 'Why'), ('Why', 'Natural'), ('Natural', 'Language'), ('Language', 'Processing'), ('Processing', 'Future'), ('Future', 'BI'), ('BI', '.'), ('.', "''")]

>> Trigrams are: 
 [('[', '105', ']'), ('105', ']', '``'), (']', '``', 'Here'), ('``', 'Here', "'s"), ('Here', "'s", 'Why'), ("'s", 'Why', 'Natural'), ('Why', 'Natural', 'Language'), ('Natural', 'Language', 'Processing'), ('Language', 'Processing', 'Future'), ('Processing', 'Future', 'BI'), ('Future', 'BI', '.'), ('BI', '.', "''")]

>> POS Tags are: 
 [('[', 'RB'), ('105', 'CD'), (']', 'JJ'), ('``', '``'), ('Here', 'RB'), ("'s", 'VBZ'), ('Why', 'WRB'), ('Natural', 'JJ'), ('Language', 'NN'), ('Processing', 'NNP'), ('Future', 'NNP'), ('BI', 'NNP'), ('.', '.'), ("''", "''")]

>> Noun Phrases are: 
 ['Natural Language Processing Future BI']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('105', '105'), (']', ']'), ('``', '``'), ('Here', 'here'), ("'s", "'s"), ('Why', 'whi'), ('Natural', 'natur'), ('Language', 'languag'), ('Processing', 'process'), ('Future', 'futur'), ('BI', 'bi'), ('.', '.'), ("''", "''")]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('105', '105'), (']', ']'), ('``', '``'), ('Here', 'here'), ("'s", "'s"), ('Why', 'whi'), ('Natural', 'natur'), ('Language', 'languag'), ('Processing', 'process'), ('Future', 'futur'), ('BI', 'bi'), ('.', '.'), ("''", "''")]

>> Lemmatization: 
 [('[', '['), ('105', '105'), (']', ']'), ('``', '``'), ('Here', 'Here'), ("'s", "'s"), ('Why', 'Why'), ('Natural', 'Natural'), ('Language', 'Language'), ('Processing', 'Processing'), ('Future', 'Future'), ('BI', 'BI'), ('.', '.'), ("''", "''")]


------------------- Sentence 2 -------------------

SmartData Collective.

>> Tokens are: 
 ['SmartData', 'Collective', '.']

>> Bigrams are: 
 [('SmartData', 'Collective'), ('Collective', '.')]

>> Trigrams are: 
 [('SmartData', 'Collective', '.')]

>> POS Tags are: 
 [('SmartData', 'NNP'), ('Collective', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['SmartData Collective']

>> Named Entities are: 
 [('ORGANIZATION', 'SmartData Collective')] 

>> Stemming using Porter Stemmer: 
 [('SmartData', 'smartdata'), ('Collective', 'collect'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('SmartData', 'smartdata'), ('Collective', 'collect'), ('.', '.')]

>> Lemmatization: 
 [('SmartData', 'SmartData'), ('Collective', 'Collective'), ('.', '.')]



========================================== PARAGRAPH 871 ===========================================

N.p., n.d. Web. 19 Mar. 2017 

------------------- Sentence 1 -------------------

N.p., n.d.

>> Tokens are: 
 ['N.p.', ',', 'n.d', '.']

>> Bigrams are: 
 [('N.p.', ','), (',', 'n.d'), ('n.d', '.')]

>> Trigrams are: 
 [('N.p.', ',', 'n.d'), (',', 'n.d', '.')]

>> POS Tags are: 
 [('N.p.', 'NNP'), (',', ','), ('n.d', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['N.p.', 'n.d']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('N.p.', 'n.p.'), (',', ','), ('n.d', 'n.d'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('N.p.', 'n.p.'), (',', ','), ('n.d', 'n.d'), ('.', '.')]

>> Lemmatization: 
 [('N.p.', 'N.p.'), (',', ','), ('n.d', 'n.d'), ('.', '.')]


------------------- Sentence 2 -------------------

Web.

>> Tokens are: 
 ['Web', '.']

>> Bigrams are: 
 [('Web', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Web', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Web']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Web', 'web'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Web', 'web'), ('.', '.')]

>> Lemmatization: 
 [('Web', 'Web'), ('.', '.')]


------------------- Sentence 3 -------------------

19 Mar.

>> Tokens are: 
 ['19', 'Mar', '.']

>> Bigrams are: 
 [('19', 'Mar'), ('Mar', '.')]

>> Trigrams are: 
 [('19', 'Mar', '.')]

>> POS Tags are: 
 [('19', 'CD'), ('Mar', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Mar']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('19', '19'), ('Mar', 'mar'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('19', '19'), ('Mar', 'mar'), ('.', '.')]

>> Lemmatization: 
 [('19', '19'), ('Mar', 'Mar'), ('.', '.')]


------------------- Sentence 4 -------------------

2017

>> Tokens are: 
 ['2017']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('2017', 'CD')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('2017', '2017')]

>> Stemming using Snowball Stemmer: 
 [('2017', '2017')]

>> Lemmatization: 
 [('2017', '2017')]



========================================== PARAGRAPH 872 ===========================================

[106] "Using Natural Language Processing and Network Analysis to Develop a Conceptual  

------------------- Sentence 1 -------------------

[106] "Using Natural Language Processing and Network Analysis to Develop a Conceptual

>> Tokens are: 
 ['[', '106', ']', '``', 'Using', 'Natural', 'Language', 'Processing', 'Network', 'Analysis', 'Develop', 'Conceptual']

>> Bigrams are: 
 [('[', '106'), ('106', ']'), (']', '``'), ('``', 'Using'), ('Using', 'Natural'), ('Natural', 'Language'), ('Language', 'Processing'), ('Processing', 'Network'), ('Network', 'Analysis'), ('Analysis', 'Develop'), ('Develop', 'Conceptual')]

>> Trigrams are: 
 [('[', '106', ']'), ('106', ']', '``'), (']', '``', 'Using'), ('``', 'Using', 'Natural'), ('Using', 'Natural', 'Language'), ('Natural', 'Language', 'Processing'), ('Language', 'Processing', 'Network'), ('Processing', 'Network', 'Analysis'), ('Network', 'Analysis', 'Develop'), ('Analysis', 'Develop', 'Conceptual')]

>> POS Tags are: 
 [('[', 'RB'), ('106', 'CD'), (']', 'JJ'), ('``', '``'), ('Using', 'NNP'), ('Natural', 'NNP'), ('Language', 'NNP'), ('Processing', 'NNP'), ('Network', 'NNP'), ('Analysis', 'NNP'), ('Develop', 'NNP'), ('Conceptual', 'NNP')]

>> Noun Phrases are: 
 ['Using Natural Language Processing Network Analysis Develop Conceptual']

>> Named Entities are: 
 [('PERSON', 'Network Analysis Develop Conceptual')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('106', '106'), (']', ']'), ('``', '``'), ('Using', 'use'), ('Natural', 'natur'), ('Language', 'languag'), ('Processing', 'process'), ('Network', 'network'), ('Analysis', 'analysi'), ('Develop', 'develop'), ('Conceptual', 'conceptu')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('106', '106'), (']', ']'), ('``', '``'), ('Using', 'use'), ('Natural', 'natur'), ('Language', 'languag'), ('Processing', 'process'), ('Network', 'network'), ('Analysis', 'analysi'), ('Develop', 'develop'), ('Conceptual', 'conceptu')]

>> Lemmatization: 
 [('[', '['), ('106', '106'), (']', ']'), ('``', '``'), ('Using', 'Using'), ('Natural', 'Natural'), ('Language', 'Language'), ('Processing', 'Processing'), ('Network', 'Network'), ('Analysis', 'Analysis'), ('Develop', 'Develop'), ('Conceptual', 'Conceptual')]



========================================== PARAGRAPH 873 ===========================================

Framework for Medication Therapy Management Research." AMIA ... Annual Symposium  

------------------- Sentence 1 -------------------

Framework for Medication Therapy Management Research."

>> Tokens are: 
 ['Framework', 'Medication', 'Therapy', 'Management', 'Research', '.', "''"]

>> Bigrams are: 
 [('Framework', 'Medication'), ('Medication', 'Therapy'), ('Therapy', 'Management'), ('Management', 'Research'), ('Research', '.'), ('.', "''")]

>> Trigrams are: 
 [('Framework', 'Medication', 'Therapy'), ('Medication', 'Therapy', 'Management'), ('Therapy', 'Management', 'Research'), ('Management', 'Research', '.'), ('Research', '.', "''")]

>> POS Tags are: 
 [('Framework', 'NNP'), ('Medication', 'NNP'), ('Therapy', 'NNP'), ('Management', 'NNP'), ('Research', 'NNP'), ('.', '.'), ("''", "''")]

>> Noun Phrases are: 
 ['Framework Medication Therapy Management Research']

>> Named Entities are: 
 [('PERSON', 'Framework'), ('ORGANIZATION', 'Medication')] 

>> Stemming using Porter Stemmer: 
 [('Framework', 'framework'), ('Medication', 'medic'), ('Therapy', 'therapi'), ('Management', 'manag'), ('Research', 'research'), ('.', '.'), ("''", "''")]

>> Stemming using Snowball Stemmer: 
 [('Framework', 'framework'), ('Medication', 'medic'), ('Therapy', 'therapi'), ('Management', 'manag'), ('Research', 'research'), ('.', '.'), ("''", "''")]

>> Lemmatization: 
 [('Framework', 'Framework'), ('Medication', 'Medication'), ('Therapy', 'Therapy'), ('Management', 'Management'), ('Research', 'Research'), ('.', '.'), ("''", "''")]


------------------- Sentence 2 -------------------

AMIA ...

>> Tokens are: 
 ['AMIA', '...']

>> Bigrams are: 
 [('AMIA', '...')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('AMIA', 'NNS'), ('...', ':')]

>> Noun Phrases are: 
 ['AMIA']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('AMIA', 'amia'), ('...', '...')]

>> Stemming using Snowball Stemmer: 
 [('AMIA', 'amia'), ('...', '...')]

>> Lemmatization: 
 [('AMIA', 'AMIA'), ('...', '...')]


------------------- Sentence 3 -------------------

Annual Symposium

>> Tokens are: 
 ['Annual', 'Symposium']

>> Bigrams are: 
 [('Annual', 'Symposium')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Annual', 'JJ'), ('Symposium', 'NN')]

>> Noun Phrases are: 
 ['Annual Symposium']

>> Named Entities are: 
 [('GPE', 'Annual'), ('ORGANIZATION', 'Symposium')] 

>> Stemming using Porter Stemmer: 
 [('Annual', 'annual'), ('Symposium', 'symposium')]

>> Stemming using Snowball Stemmer: 
 [('Annual', 'annual'), ('Symposium', 'symposium')]

>> Lemmatization: 
 [('Annual', 'Annual'), ('Symposium', 'Symposium')]



========================================== PARAGRAPH 874 ===========================================

proceedings. AMIA Symposium. U.S. National Library of Medicine, n.d. Web. 19 Mar. 2017  

------------------- Sentence 1 -------------------

proceedings.

>> Tokens are: 
 ['proceedings', '.']

>> Bigrams are: 
 [('proceedings', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('proceedings', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['proceedings']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('proceedings', 'proceed'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('proceedings', 'proceed'), ('.', '.')]

>> Lemmatization: 
 [('proceedings', 'proceeding'), ('.', '.')]


------------------- Sentence 2 -------------------

AMIA Symposium.

>> Tokens are: 
 ['AMIA', 'Symposium', '.']

>> Bigrams are: 
 [('AMIA', 'Symposium'), ('Symposium', '.')]

>> Trigrams are: 
 [('AMIA', 'Symposium', '.')]

>> POS Tags are: 
 [('AMIA', 'NNP'), ('Symposium', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['AMIA Symposium']

>> Named Entities are: 
 [('ORGANIZATION', 'AMIA Symposium')] 

>> Stemming using Porter Stemmer: 
 [('AMIA', 'amia'), ('Symposium', 'symposium'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('AMIA', 'amia'), ('Symposium', 'symposium'), ('.', '.')]

>> Lemmatization: 
 [('AMIA', 'AMIA'), ('Symposium', 'Symposium'), ('.', '.')]


------------------- Sentence 3 -------------------

U.S. National Library of Medicine, n.d.

>> Tokens are: 
 ['U.S.', 'National', 'Library', 'Medicine', ',', 'n.d', '.']

>> Bigrams are: 
 [('U.S.', 'National'), ('National', 'Library'), ('Library', 'Medicine'), ('Medicine', ','), (',', 'n.d'), ('n.d', '.')]

>> Trigrams are: 
 [('U.S.', 'National', 'Library'), ('National', 'Library', 'Medicine'), ('Library', 'Medicine', ','), ('Medicine', ',', 'n.d'), (',', 'n.d', '.')]

>> POS Tags are: 
 [('U.S.', 'NNP'), ('National', 'NNP'), ('Library', 'NNP'), ('Medicine', 'NNP'), (',', ','), ('n.d', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['U.S. National Library Medicine', 'n.d']

>> Named Entities are: 
 [('GPE', 'U.S.'), ('ORGANIZATION', 'National Library Medicine')] 

>> Stemming using Porter Stemmer: 
 [('U.S.', 'u.s.'), ('National', 'nation'), ('Library', 'librari'), ('Medicine', 'medicin'), (',', ','), ('n.d', 'n.d'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('U.S.', 'u.s.'), ('National', 'nation'), ('Library', 'librari'), ('Medicine', 'medicin'), (',', ','), ('n.d', 'n.d'), ('.', '.')]

>> Lemmatization: 
 [('U.S.', 'U.S.'), ('National', 'National'), ('Library', 'Library'), ('Medicine', 'Medicine'), (',', ','), ('n.d', 'n.d'), ('.', '.')]


------------------- Sentence 4 -------------------

Web.

>> Tokens are: 
 ['Web', '.']

>> Bigrams are: 
 [('Web', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Web', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Web']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Web', 'web'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Web', 'web'), ('.', '.')]

>> Lemmatization: 
 [('Web', 'Web'), ('.', '.')]


------------------- Sentence 5 -------------------

19 Mar.

>> Tokens are: 
 ['19', 'Mar', '.']

>> Bigrams are: 
 [('19', 'Mar'), ('Mar', '.')]

>> Trigrams are: 
 [('19', 'Mar', '.')]

>> POS Tags are: 
 [('19', 'CD'), ('Mar', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Mar']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('19', '19'), ('Mar', 'mar'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('19', '19'), ('Mar', 'mar'), ('.', '.')]

>> Lemmatization: 
 [('19', '19'), ('Mar', 'Mar'), ('.', '.')]


------------------- Sentence 6 -------------------

2017

>> Tokens are: 
 ['2017']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('2017', 'CD')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('2017', '2017')]

>> Stemming using Snowball Stemmer: 
 [('2017', '2017')]

>> Lemmatization: 
 [('2017', '2017')]



========================================== PARAGRAPH 875 ===========================================

[107] Ogallo, W., & Kanter, A. S. (2017, February 10). Using Natural Language Processing  

------------------- Sentence 1 -------------------

[107] Ogallo, W., & Kanter, A. S. (2017, February 10).

>> Tokens are: 
 ['[', '107', ']', 'Ogallo', ',', 'W.', ',', '&', 'Kanter', ',', 'A.', 'S.', '(', '2017', ',', 'February', '10', ')', '.']

>> Bigrams are: 
 [('[', '107'), ('107', ']'), (']', 'Ogallo'), ('Ogallo', ','), (',', 'W.'), ('W.', ','), (',', '&'), ('&', 'Kanter'), ('Kanter', ','), (',', 'A.'), ('A.', 'S.'), ('S.', '('), ('(', '2017'), ('2017', ','), (',', 'February'), ('February', '10'), ('10', ')'), (')', '.')]

>> Trigrams are: 
 [('[', '107', ']'), ('107', ']', 'Ogallo'), (']', 'Ogallo', ','), ('Ogallo', ',', 'W.'), (',', 'W.', ','), ('W.', ',', '&'), (',', '&', 'Kanter'), ('&', 'Kanter', ','), ('Kanter', ',', 'A.'), (',', 'A.', 'S.'), ('A.', 'S.', '('), ('S.', '(', '2017'), ('(', '2017', ','), ('2017', ',', 'February'), (',', 'February', '10'), ('February', '10', ')'), ('10', ')', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('107', 'CD'), (']', 'JJ'), ('Ogallo', 'NNP'), (',', ','), ('W.', 'NNP'), (',', ','), ('&', 'CC'), ('Kanter', 'NNP'), (',', ','), ('A.', 'NNP'), ('S.', 'NNP'), ('(', '('), ('2017', 'CD'), (',', ','), ('February', 'NNP'), ('10', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['] Ogallo', 'W.', 'Kanter', 'A. S.', 'February']

>> Named Entities are: 
 [('GPE', 'Ogallo'), ('PERSON', 'Kanter')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('107', '107'), (']', ']'), ('Ogallo', 'ogallo'), (',', ','), ('W.', 'w.'), (',', ','), ('&', '&'), ('Kanter', 'kanter'), (',', ','), ('A.', 'a.'), ('S.', 's.'), ('(', '('), ('2017', '2017'), (',', ','), ('February', 'februari'), ('10', '10'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('107', '107'), (']', ']'), ('Ogallo', 'ogallo'), (',', ','), ('W.', 'w.'), (',', ','), ('&', '&'), ('Kanter', 'kanter'), (',', ','), ('A.', 'a.'), ('S.', 's.'), ('(', '('), ('2017', '2017'), (',', ','), ('February', 'februari'), ('10', '10'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('107', '107'), (']', ']'), ('Ogallo', 'Ogallo'), (',', ','), ('W.', 'W.'), (',', ','), ('&', '&'), ('Kanter', 'Kanter'), (',', ','), ('A.', 'A.'), ('S.', 'S.'), ('(', '('), ('2017', '2017'), (',', ','), ('February', 'February'), ('10', '10'), (')', ')'), ('.', '.')]


------------------- Sentence 2 -------------------

Using Natural Language Processing

>> Tokens are: 
 ['Using', 'Natural', 'Language', 'Processing']

>> Bigrams are: 
 [('Using', 'Natural'), ('Natural', 'Language'), ('Language', 'Processing')]

>> Trigrams are: 
 [('Using', 'Natural', 'Language'), ('Natural', 'Language', 'Processing')]

>> POS Tags are: 
 [('Using', 'VBG'), ('Natural', 'NNP'), ('Language', 'NNP'), ('Processing', 'NNP')]

>> Noun Phrases are: 
 ['Natural Language Processing']

>> Named Entities are: 
 [('ORGANIZATION', 'Natural Language')] 

>> Stemming using Porter Stemmer: 
 [('Using', 'use'), ('Natural', 'natur'), ('Language', 'languag'), ('Processing', 'process')]

>> Stemming using Snowball Stemmer: 
 [('Using', 'use'), ('Natural', 'natur'), ('Language', 'languag'), ('Processing', 'process')]

>> Lemmatization: 
 [('Using', 'Using'), ('Natural', 'Natural'), ('Language', 'Language'), ('Processing', 'Processing')]



========================================== PARAGRAPH 876 ===========================================

and Network Analysis to Develop a Conceptual Framework for Medication Therapy  

------------------- Sentence 1 -------------------

and Network Analysis to Develop a Conceptual Framework for Medication Therapy

>> Tokens are: 
 ['Network', 'Analysis', 'Develop', 'Conceptual', 'Framework', 'Medication', 'Therapy']

>> Bigrams are: 
 [('Network', 'Analysis'), ('Analysis', 'Develop'), ('Develop', 'Conceptual'), ('Conceptual', 'Framework'), ('Framework', 'Medication'), ('Medication', 'Therapy')]

>> Trigrams are: 
 [('Network', 'Analysis', 'Develop'), ('Analysis', 'Develop', 'Conceptual'), ('Develop', 'Conceptual', 'Framework'), ('Conceptual', 'Framework', 'Medication'), ('Framework', 'Medication', 'Therapy')]

>> POS Tags are: 
 [('Network', 'NNP'), ('Analysis', 'NNP'), ('Develop', 'NNP'), ('Conceptual', 'NNP'), ('Framework', 'NNP'), ('Medication', 'NNP'), ('Therapy', 'NNP')]

>> Noun Phrases are: 
 ['Network Analysis Develop Conceptual Framework Medication Therapy']

>> Named Entities are: 
 [('PERSON', 'Network'), ('PERSON', 'Analysis Develop Conceptual Framework Medication Therapy')] 

>> Stemming using Porter Stemmer: 
 [('Network', 'network'), ('Analysis', 'analysi'), ('Develop', 'develop'), ('Conceptual', 'conceptu'), ('Framework', 'framework'), ('Medication', 'medic'), ('Therapy', 'therapi')]

>> Stemming using Snowball Stemmer: 
 [('Network', 'network'), ('Analysis', 'analysi'), ('Develop', 'develop'), ('Conceptual', 'conceptu'), ('Framework', 'framework'), ('Medication', 'medic'), ('Therapy', 'therapi')]

>> Lemmatization: 
 [('Network', 'Network'), ('Analysis', 'Analysis'), ('Develop', 'Develop'), ('Conceptual', 'Conceptual'), ('Framework', 'Framework'), ('Medication', 'Medication'), ('Therapy', 'Therapy')]



========================================== PARAGRAPH 877 ===========================================

Management Research. Retrieved April 10, 2017, from  

------------------- Sentence 1 -------------------

Management Research.

>> Tokens are: 
 ['Management', 'Research', '.']

>> Bigrams are: 
 [('Management', 'Research'), ('Research', '.')]

>> Trigrams are: 
 [('Management', 'Research', '.')]

>> POS Tags are: 
 [('Management', 'NNP'), ('Research', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Management Research']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Management', 'manag'), ('Research', 'research'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Management', 'manag'), ('Research', 'research'), ('.', '.')]

>> Lemmatization: 
 [('Management', 'Management'), ('Research', 'Research'), ('.', '.')]


------------------- Sentence 2 -------------------

Retrieved April 10, 2017, from

>> Tokens are: 
 ['Retrieved', 'April', '10', ',', '2017', ',']

>> Bigrams are: 
 [('Retrieved', 'April'), ('April', '10'), ('10', ','), (',', '2017'), ('2017', ',')]

>> Trigrams are: 
 [('Retrieved', 'April', '10'), ('April', '10', ','), ('10', ',', '2017'), (',', '2017', ',')]

>> POS Tags are: 
 [('Retrieved', 'VBN'), ('April', 'NNP'), ('10', 'CD'), (',', ','), ('2017', 'CD'), (',', ',')]

>> Noun Phrases are: 
 ['April']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Retrieved', 'retriev'), ('April', 'april'), ('10', '10'), (',', ','), ('2017', '2017'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('Retrieved', 'retriev'), ('April', 'april'), ('10', '10'), (',', ','), ('2017', '2017'), (',', ',')]

>> Lemmatization: 
 [('Retrieved', 'Retrieved'), ('April', 'April'), ('10', '10'), (',', ','), ('2017', '2017'), (',', ',')]



========================================== PARAGRAPH 878 ===========================================

https://www.ncbi.nlm.nih.gov/pubmed/28269895?dopt=Abstract  

------------------- Sentence 1 -------------------

https://www.ncbi.nlm.nih.gov/pubmed/28269895?dopt=Abstract

>> Tokens are: 
 ['https', ':', '//www.ncbi.nlm.nih.gov/pubmed/28269895', '?', 'dopt=Abstract']

>> Bigrams are: 
 [('https', ':'), (':', '//www.ncbi.nlm.nih.gov/pubmed/28269895'), ('//www.ncbi.nlm.nih.gov/pubmed/28269895', '?'), ('?', 'dopt=Abstract')]

>> Trigrams are: 
 [('https', ':', '//www.ncbi.nlm.nih.gov/pubmed/28269895'), (':', '//www.ncbi.nlm.nih.gov/pubmed/28269895', '?'), ('//www.ncbi.nlm.nih.gov/pubmed/28269895', '?', 'dopt=Abstract')]

>> POS Tags are: 
 [('https', 'NN'), (':', ':'), ('//www.ncbi.nlm.nih.gov/pubmed/28269895', 'NN'), ('?', '.'), ('dopt=Abstract', 'NN')]

>> Noun Phrases are: 
 ['https', '//www.ncbi.nlm.nih.gov/pubmed/28269895', 'dopt=Abstract']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('https', 'http'), (':', ':'), ('//www.ncbi.nlm.nih.gov/pubmed/28269895', '//www.ncbi.nlm.nih.gov/pubmed/28269895'), ('?', '?'), ('dopt=Abstract', 'dopt=abstract')]

>> Stemming using Snowball Stemmer: 
 [('https', 'https'), (':', ':'), ('//www.ncbi.nlm.nih.gov/pubmed/28269895', '//www.ncbi.nlm.nih.gov/pubmed/28269895'), ('?', '?'), ('dopt=Abstract', 'dopt=abstract')]

>> Lemmatization: 
 [('https', 'http'), (':', ':'), ('//www.ncbi.nlm.nih.gov/pubmed/28269895', '//www.ncbi.nlm.nih.gov/pubmed/28269895'), ('?', '?'), ('dopt=Abstract', 'dopt=Abstract')]



========================================== PARAGRAPH 879 ===========================================

[108] Ochoa, A. (2016, May 25). Meet the Pilot: Smart Earpiece Language Translator.  

------------------- Sentence 1 -------------------

[108] Ochoa, A.

>> Tokens are: 
 ['[', '108', ']', 'Ochoa', ',', 'A', '.']

>> Bigrams are: 
 [('[', '108'), ('108', ']'), (']', 'Ochoa'), ('Ochoa', ','), (',', 'A'), ('A', '.')]

>> Trigrams are: 
 [('[', '108', ']'), ('108', ']', 'Ochoa'), (']', 'Ochoa', ','), ('Ochoa', ',', 'A'), (',', 'A', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('108', 'CD'), (']', 'JJ'), ('Ochoa', 'NNP'), (',', ','), ('A', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['] Ochoa', 'A']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('108', '108'), (']', ']'), ('Ochoa', 'ochoa'), (',', ','), ('A', 'a'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('108', '108'), (']', ']'), ('Ochoa', 'ochoa'), (',', ','), ('A', 'a'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('108', '108'), (']', ']'), ('Ochoa', 'Ochoa'), (',', ','), ('A', 'A'), ('.', '.')]


------------------- Sentence 2 -------------------

(2016, May 25).

>> Tokens are: 
 ['(', '2016', ',', 'May', '25', ')', '.']

>> Bigrams are: 
 [('(', '2016'), ('2016', ','), (',', 'May'), ('May', '25'), ('25', ')'), (')', '.')]

>> Trigrams are: 
 [('(', '2016', ','), ('2016', ',', 'May'), (',', 'May', '25'), ('May', '25', ')'), ('25', ')', '.')]

>> POS Tags are: 
 [('(', '('), ('2016', 'CD'), (',', ','), ('May', 'NNP'), ('25', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['May']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('2016', '2016'), (',', ','), ('May', 'may'), ('25', '25'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('2016', '2016'), (',', ','), ('May', 'may'), ('25', '25'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('(', '('), ('2016', '2016'), (',', ','), ('May', 'May'), ('25', '25'), (')', ')'), ('.', '.')]


------------------- Sentence 3 -------------------

Meet the Pilot: Smart Earpiece Language Translator.

>> Tokens are: 
 ['Meet', 'Pilot', ':', 'Smart', 'Earpiece', 'Language', 'Translator', '.']

>> Bigrams are: 
 [('Meet', 'Pilot'), ('Pilot', ':'), (':', 'Smart'), ('Smart', 'Earpiece'), ('Earpiece', 'Language'), ('Language', 'Translator'), ('Translator', '.')]

>> Trigrams are: 
 [('Meet', 'Pilot', ':'), ('Pilot', ':', 'Smart'), (':', 'Smart', 'Earpiece'), ('Smart', 'Earpiece', 'Language'), ('Earpiece', 'Language', 'Translator'), ('Language', 'Translator', '.')]

>> POS Tags are: 
 [('Meet', 'NNP'), ('Pilot', 'NNP'), (':', ':'), ('Smart', 'NNP'), ('Earpiece', 'NNP'), ('Language', 'NNP'), ('Translator', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Meet Pilot', 'Smart Earpiece Language Translator']

>> Named Entities are: 
 [('PERSON', 'Meet'), ('PERSON', 'Pilot'), ('PERSON', 'Smart Earpiece Language Translator')] 

>> Stemming using Porter Stemmer: 
 [('Meet', 'meet'), ('Pilot', 'pilot'), (':', ':'), ('Smart', 'smart'), ('Earpiece', 'earpiec'), ('Language', 'languag'), ('Translator', 'translat'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Meet', 'meet'), ('Pilot', 'pilot'), (':', ':'), ('Smart', 'smart'), ('Earpiece', 'earpiec'), ('Language', 'languag'), ('Translator', 'translat'), ('.', '.')]

>> Lemmatization: 
 [('Meet', 'Meet'), ('Pilot', 'Pilot'), (':', ':'), ('Smart', 'Smart'), ('Earpiece', 'Earpiece'), ('Language', 'Language'), ('Translator', 'Translator'), ('.', '.')]



========================================== PARAGRAPH 880 ===========================================

Retrieved April 10, 2017, from https://www.indiegogo.com/projects/meet-the-pilot-smart- 

------------------- Sentence 1 -------------------

Retrieved April 10, 2017, from https://www.indiegogo.com/projects/meet-the-pilot-smart-

>> Tokens are: 
 ['Retrieved', 'April', '10', ',', '2017', ',', 'https', ':', '//www.indiegogo.com/projects/meet-the-pilot-smart-']

>> Bigrams are: 
 [('Retrieved', 'April'), ('April', '10'), ('10', ','), (',', '2017'), ('2017', ','), (',', 'https'), ('https', ':'), (':', '//www.indiegogo.com/projects/meet-the-pilot-smart-')]

>> Trigrams are: 
 [('Retrieved', 'April', '10'), ('April', '10', ','), ('10', ',', '2017'), (',', '2017', ','), ('2017', ',', 'https'), (',', 'https', ':'), ('https', ':', '//www.indiegogo.com/projects/meet-the-pilot-smart-')]

>> POS Tags are: 
 [('Retrieved', 'VBN'), ('April', 'NNP'), ('10', 'CD'), (',', ','), ('2017', 'CD'), (',', ','), ('https', 'NN'), (':', ':'), ('//www.indiegogo.com/projects/meet-the-pilot-smart-', 'JJ')]

>> Noun Phrases are: 
 ['April', 'https']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Retrieved', 'retriev'), ('April', 'april'), ('10', '10'), (',', ','), ('2017', '2017'), (',', ','), ('https', 'http'), (':', ':'), ('//www.indiegogo.com/projects/meet-the-pilot-smart-', '//www.indiegogo.com/projects/meet-the-pilot-smart-')]

>> Stemming using Snowball Stemmer: 
 [('Retrieved', 'retriev'), ('April', 'april'), ('10', '10'), (',', ','), ('2017', '2017'), (',', ','), ('https', 'https'), (':', ':'), ('//www.indiegogo.com/projects/meet-the-pilot-smart-', '//www.indiegogo.com/projects/meet-the-pilot-smart-')]

>> Lemmatization: 
 [('Retrieved', 'Retrieved'), ('April', 'April'), ('10', '10'), (',', ','), ('2017', '2017'), (',', ','), ('https', 'http'), (':', ':'), ('//www.indiegogo.com/projects/meet-the-pilot-smart-', '//www.indiegogo.com/projects/meet-the-pilot-smart-')]



========================================== PARAGRAPH 881 ===========================================

earpiece-language-translator-headphones-travel 

------------------- Sentence 1 -------------------

earpiece-language-translator-headphones-travel

>> Tokens are: 
 ['earpiece-language-translator-headphones-travel']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('earpiece-language-translator-headphones-travel', 'NN')]

>> Noun Phrases are: 
 ['earpiece-language-translator-headphones-travel']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('earpiece-language-translator-headphones-travel', 'earpiece-language-translator-headphones-travel')]

>> Stemming using Snowball Stemmer: 
 [('earpiece-language-translator-headphones-travel', 'earpiece-language-translator-headphones-travel')]

>> Lemmatization: 
 [('earpiece-language-translator-headphones-travel', 'earpiece-language-translator-headphones-travel')]

