				 *** Text Processing using NLTK *** 


========================================== PARAGRAPH 1 ===========================================

IQBAL MUHAMMAD AND ZHU YAN: SUPERVISED MACHINE LEARNING APPROACHES: A SURVEY  

------------------- Sentence 1 -------------------

IQBAL MUHAMMAD AND ZHU YAN: SUPERVISED MACHINE LEARNING APPROACHES: A SURVEY

>> Tokens are: 
 ['IQBAL', 'MUHAMMAD', 'AND', 'ZHU', 'YAN', ':', 'SUPERVISED', 'MACHINE', 'LEARNING', 'APPROACHES', ':', 'A', 'SURVEY']

>> Bigrams are: 
 [('IQBAL', 'MUHAMMAD'), ('MUHAMMAD', 'AND'), ('AND', 'ZHU'), ('ZHU', 'YAN'), ('YAN', ':'), (':', 'SUPERVISED'), ('SUPERVISED', 'MACHINE'), ('MACHINE', 'LEARNING'), ('LEARNING', 'APPROACHES'), ('APPROACHES', ':'), (':', 'A'), ('A', 'SURVEY')]

>> Trigrams are: 
 [('IQBAL', 'MUHAMMAD', 'AND'), ('MUHAMMAD', 'AND', 'ZHU'), ('AND', 'ZHU', 'YAN'), ('ZHU', 'YAN', ':'), ('YAN', ':', 'SUPERVISED'), (':', 'SUPERVISED', 'MACHINE'), ('SUPERVISED', 'MACHINE', 'LEARNING'), ('MACHINE', 'LEARNING', 'APPROACHES'), ('LEARNING', 'APPROACHES', ':'), ('APPROACHES', ':', 'A'), (':', 'A', 'SURVEY')]

>> POS Tags are: 
 [('IQBAL', 'NNP'), ('MUHAMMAD', 'NNP'), ('AND', 'NNP'), ('ZHU', 'NNP'), ('YAN', 'NNP'), (':', ':'), ('SUPERVISED', 'NNP'), ('MACHINE', 'NNP'), ('LEARNING', 'NNP'), ('APPROACHES', 'NNP'), (':', ':'), ('A', 'DT'), ('SURVEY', 'NN')]

>> Noun Phrases are: 
 ['IQBAL MUHAMMAD AND ZHU YAN', 'SUPERVISED MACHINE LEARNING APPROACHES', 'A SURVEY']

>> Named Entities are: 
 [('ORGANIZATION', 'IQBAL'), ('ORGANIZATION', 'MUHAMMAD'), ('ORGANIZATION', 'SUPERVISED'), ('ORGANIZATION', 'MACHINE')] 

>> Stemming using Porter Stemmer: 
 [('IQBAL', 'iqbal'), ('MUHAMMAD', 'muhammad'), ('AND', 'and'), ('ZHU', 'zhu'), ('YAN', 'yan'), (':', ':'), ('SUPERVISED', 'supervis'), ('MACHINE', 'machin'), ('LEARNING', 'learn'), ('APPROACHES', 'approach'), (':', ':'), ('A', 'a'), ('SURVEY', 'survey')]

>> Stemming using Snowball Stemmer: 
 [('IQBAL', 'iqbal'), ('MUHAMMAD', 'muhammad'), ('AND', 'and'), ('ZHU', 'zhu'), ('YAN', 'yan'), (':', ':'), ('SUPERVISED', 'supervis'), ('MACHINE', 'machin'), ('LEARNING', 'learn'), ('APPROACHES', 'approach'), (':', ':'), ('A', 'a'), ('SURVEY', 'survey')]

>> Lemmatization: 
 [('IQBAL', 'IQBAL'), ('MUHAMMAD', 'MUHAMMAD'), ('AND', 'AND'), ('ZHU', 'ZHU'), ('YAN', 'YAN'), (':', ':'), ('SUPERVISED', 'SUPERVISED'), ('MACHINE', 'MACHINE'), ('LEARNING', 'LEARNING'), ('APPROACHES', 'APPROACHES'), (':', ':'), ('A', 'A'), ('SURVEY', 'SURVEY')]



========================================== PARAGRAPH 2 ===========================================

DOI: 10.21917/ijsc.2015.0133 

------------------- Sentence 1 -------------------

DOI: 10.21917/ijsc.2015.0133

>> Tokens are: 
 ['DOI', ':', '10.21917/ijsc.2015.0133']

>> Bigrams are: 
 [('DOI', ':'), (':', '10.21917/ijsc.2015.0133')]

>> Trigrams are: 
 [('DOI', ':', '10.21917/ijsc.2015.0133')]

>> POS Tags are: 
 [('DOI', 'NN'), (':', ':'), ('10.21917/ijsc.2015.0133', 'CD')]

>> Noun Phrases are: 
 ['DOI']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('DOI', 'doi'), (':', ':'), ('10.21917/ijsc.2015.0133', '10.21917/ijsc.2015.0133')]

>> Stemming using Snowball Stemmer: 
 [('DOI', 'doi'), (':', ':'), ('10.21917/ijsc.2015.0133', '10.21917/ijsc.2015.0133')]

>> Lemmatization: 
 [('DOI', 'DOI'), (':', ':'), ('10.21917/ijsc.2015.0133', '10.21917/ijsc.2015.0133')]



========================================== PARAGRAPH 3 ===========================================

946  

------------------- Sentence 1 -------------------

946

>> Tokens are: 
 ['946']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('946', 'CD')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('946', '946')]

>> Stemming using Snowball Stemmer: 
 [('946', '946')]

>> Lemmatization: 
 [('946', '946')]



========================================== PARAGRAPH 4 ===========================================

SUPERVISED MACHINE LEARNING APPROACHES: A SURVEY  

------------------- Sentence 1 -------------------

SUPERVISED MACHINE LEARNING APPROACHES: A SURVEY

>> Tokens are: 
 ['SUPERVISED', 'MACHINE', 'LEARNING', 'APPROACHES', ':', 'A', 'SURVEY']

>> Bigrams are: 
 [('SUPERVISED', 'MACHINE'), ('MACHINE', 'LEARNING'), ('LEARNING', 'APPROACHES'), ('APPROACHES', ':'), (':', 'A'), ('A', 'SURVEY')]

>> Trigrams are: 
 [('SUPERVISED', 'MACHINE', 'LEARNING'), ('MACHINE', 'LEARNING', 'APPROACHES'), ('LEARNING', 'APPROACHES', ':'), ('APPROACHES', ':', 'A'), (':', 'A', 'SURVEY')]

>> POS Tags are: 
 [('SUPERVISED', 'NNP'), ('MACHINE', 'NNP'), ('LEARNING', 'NNP'), ('APPROACHES', 'NNP'), (':', ':'), ('A', 'DT'), ('SURVEY', 'NN')]

>> Noun Phrases are: 
 ['SUPERVISED MACHINE LEARNING APPROACHES', 'A SURVEY']

>> Named Entities are: 
 [('ORGANIZATION', 'SUPERVISED'), ('ORGANIZATION', 'MACHINE')] 

>> Stemming using Porter Stemmer: 
 [('SUPERVISED', 'supervis'), ('MACHINE', 'machin'), ('LEARNING', 'learn'), ('APPROACHES', 'approach'), (':', ':'), ('A', 'a'), ('SURVEY', 'survey')]

>> Stemming using Snowball Stemmer: 
 [('SUPERVISED', 'supervis'), ('MACHINE', 'machin'), ('LEARNING', 'learn'), ('APPROACHES', 'approach'), (':', ':'), ('A', 'a'), ('SURVEY', 'survey')]

>> Lemmatization: 
 [('SUPERVISED', 'SUPERVISED'), ('MACHINE', 'MACHINE'), ('LEARNING', 'LEARNING'), ('APPROACHES', 'APPROACHES'), (':', ':'), ('A', 'A'), ('SURVEY', 'SURVEY')]



========================================== PARAGRAPH 5 ===========================================

Iqbal Muhammad 1  and Zhu Yan 

------------------- Sentence 1 -------------------

Iqbal Muhammad 1  and Zhu Yan

>> Tokens are: 
 ['Iqbal', 'Muhammad', '1', 'Zhu', 'Yan']

>> Bigrams are: 
 [('Iqbal', 'Muhammad'), ('Muhammad', '1'), ('1', 'Zhu'), ('Zhu', 'Yan')]

>> Trigrams are: 
 [('Iqbal', 'Muhammad', '1'), ('Muhammad', '1', 'Zhu'), ('1', 'Zhu', 'Yan')]

>> POS Tags are: 
 [('Iqbal', 'NNP'), ('Muhammad', 'NNP'), ('1', 'CD'), ('Zhu', 'NNP'), ('Yan', 'NNP')]

>> Noun Phrases are: 
 ['Iqbal Muhammad', 'Zhu Yan']

>> Named Entities are: 
 [('PERSON', 'Iqbal'), ('PERSON', 'Zhu Yan')] 

>> Stemming using Porter Stemmer: 
 [('Iqbal', 'iqbal'), ('Muhammad', 'muhammad'), ('1', '1'), ('Zhu', 'zhu'), ('Yan', 'yan')]

>> Stemming using Snowball Stemmer: 
 [('Iqbal', 'iqbal'), ('Muhammad', 'muhammad'), ('1', '1'), ('Zhu', 'zhu'), ('Yan', 'yan')]

>> Lemmatization: 
 [('Iqbal', 'Iqbal'), ('Muhammad', 'Muhammad'), ('1', '1'), ('Zhu', 'Zhu'), ('Yan', 'Yan')]



========================================== PARAGRAPH 6 ===========================================

2 

------------------- Sentence 1 -------------------

2

>> Tokens are: 
 ['2']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('2', 'CD')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('2', '2')]

>> Stemming using Snowball Stemmer: 
 [('2', '2')]

>> Lemmatization: 
 [('2', '2')]



========================================== PARAGRAPH 7 ===========================================

School of Information Sciences and Technology, Southwest Jiaotong University, China  

------------------- Sentence 1 -------------------

School of Information Sciences and Technology, Southwest Jiaotong University, China

>> Tokens are: 
 ['School', 'Information', 'Sciences', 'Technology', ',', 'Southwest', 'Jiaotong', 'University', ',', 'China']

>> Bigrams are: 
 [('School', 'Information'), ('Information', 'Sciences'), ('Sciences', 'Technology'), ('Technology', ','), (',', 'Southwest'), ('Southwest', 'Jiaotong'), ('Jiaotong', 'University'), ('University', ','), (',', 'China')]

>> Trigrams are: 
 [('School', 'Information', 'Sciences'), ('Information', 'Sciences', 'Technology'), ('Sciences', 'Technology', ','), ('Technology', ',', 'Southwest'), (',', 'Southwest', 'Jiaotong'), ('Southwest', 'Jiaotong', 'University'), ('Jiaotong', 'University', ','), ('University', ',', 'China')]

>> POS Tags are: 
 [('School', 'NNP'), ('Information', 'NNP'), ('Sciences', 'NNP'), ('Technology', 'NNP'), (',', ','), ('Southwest', 'NNP'), ('Jiaotong', 'NNP'), ('University', 'NNP'), (',', ','), ('China', 'NNP')]

>> Noun Phrases are: 
 ['School Information Sciences Technology', 'Southwest Jiaotong University', 'China']

>> Named Entities are: 
 [('PERSON', 'School'), ('ORGANIZATION', 'Information Sciences Technology'), ('PERSON', 'Southwest Jiaotong University'), ('GPE', 'China')] 

>> Stemming using Porter Stemmer: 
 [('School', 'school'), ('Information', 'inform'), ('Sciences', 'scienc'), ('Technology', 'technolog'), (',', ','), ('Southwest', 'southwest'), ('Jiaotong', 'jiaotong'), ('University', 'univers'), (',', ','), ('China', 'china')]

>> Stemming using Snowball Stemmer: 
 [('School', 'school'), ('Information', 'inform'), ('Sciences', 'scienc'), ('Technology', 'technolog'), (',', ','), ('Southwest', 'southwest'), ('Jiaotong', 'jiaotong'), ('University', 'univers'), (',', ','), ('China', 'china')]

>> Lemmatization: 
 [('School', 'School'), ('Information', 'Information'), ('Sciences', 'Sciences'), ('Technology', 'Technology'), (',', ','), ('Southwest', 'Southwest'), ('Jiaotong', 'Jiaotong'), ('University', 'University'), (',', ','), ('China', 'China')]



========================================== PARAGRAPH 8 ===========================================

E-mail:  1 muhammadiqbal72@yahoo.com,  

------------------- Sentence 1 -------------------

E-mail:  1 muhammadiqbal72@yahoo.com,

>> Tokens are: 
 ['E-mail', ':', '1', 'muhammadiqbal72', '@', 'yahoo.com', ',']

>> Bigrams are: 
 [('E-mail', ':'), (':', '1'), ('1', 'muhammadiqbal72'), ('muhammadiqbal72', '@'), ('@', 'yahoo.com'), ('yahoo.com', ',')]

>> Trigrams are: 
 [('E-mail', ':', '1'), (':', '1', 'muhammadiqbal72'), ('1', 'muhammadiqbal72', '@'), ('muhammadiqbal72', '@', 'yahoo.com'), ('@', 'yahoo.com', ',')]

>> POS Tags are: 
 [('E-mail', 'NN'), (':', ':'), ('1', 'CD'), ('muhammadiqbal72', 'NN'), ('@', 'NNP'), ('yahoo.com', 'NN'), (',', ',')]

>> Noun Phrases are: 
 ['E-mail', 'muhammadiqbal72 @ yahoo.com']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('E-mail', 'e-mail'), (':', ':'), ('1', '1'), ('muhammadiqbal72', 'muhammadiqbal72'), ('@', '@'), ('yahoo.com', 'yahoo.com'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('E-mail', 'e-mail'), (':', ':'), ('1', '1'), ('muhammadiqbal72', 'muhammadiqbal72'), ('@', '@'), ('yahoo.com', 'yahoo.com'), (',', ',')]

>> Lemmatization: 
 [('E-mail', 'E-mail'), (':', ':'), ('1', '1'), ('muhammadiqbal72', 'muhammadiqbal72'), ('@', '@'), ('yahoo.com', 'yahoo.com'), (',', ',')]



========================================== PARAGRAPH 9 ===========================================

2 yzhu@swjtu.edu.cn  

------------------- Sentence 1 -------------------

2 yzhu@swjtu.edu.cn

>> Tokens are: 
 ['2', 'yzhu', '@', 'swjtu.edu.cn']

>> Bigrams are: 
 [('2', 'yzhu'), ('yzhu', '@'), ('@', 'swjtu.edu.cn')]

>> Trigrams are: 
 [('2', 'yzhu', '@'), ('yzhu', '@', 'swjtu.edu.cn')]

>> POS Tags are: 
 [('2', 'CD'), ('yzhu', 'JJ'), ('@', 'NN'), ('swjtu.edu.cn', 'NN')]

>> Noun Phrases are: 
 ['yzhu @ swjtu.edu.cn']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('2', '2'), ('yzhu', 'yzhu'), ('@', '@'), ('swjtu.edu.cn', 'swjtu.edu.cn')]

>> Stemming using Snowball Stemmer: 
 [('2', '2'), ('yzhu', 'yzhu'), ('@', '@'), ('swjtu.edu.cn', 'swjtu.edu.cn')]

>> Lemmatization: 
 [('2', '2'), ('yzhu', 'yzhu'), ('@', '@'), ('swjtu.edu.cn', 'swjtu.edu.cn')]



========================================== PARAGRAPH 10 ===========================================

Abstract  

------------------- Sentence 1 -------------------

Abstract

>> Tokens are: 
 ['Abstract']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Abstract', 'NN')]

>> Noun Phrases are: 
 ['Abstract']

>> Named Entities are: 
 [('GPE', 'Abstract')] 

>> Stemming using Porter Stemmer: 
 [('Abstract', 'abstract')]

>> Stemming using Snowball Stemmer: 
 [('Abstract', 'abstract')]

>> Lemmatization: 
 [('Abstract', 'Abstract')]



========================================== PARAGRAPH 11 ===========================================

One of the core objectives of machine learning is to instruct  

------------------- Sentence 1 -------------------

One of the core objectives of machine learning is to instruct

>> Tokens are: 
 ['One', 'core', 'objectives', 'machine', 'learning', 'instruct']

>> Bigrams are: 
 [('One', 'core'), ('core', 'objectives'), ('objectives', 'machine'), ('machine', 'learning'), ('learning', 'instruct')]

>> Trigrams are: 
 [('One', 'core', 'objectives'), ('core', 'objectives', 'machine'), ('objectives', 'machine', 'learning'), ('machine', 'learning', 'instruct')]

>> POS Tags are: 
 [('One', 'CD'), ('core', 'NN'), ('objectives', 'NNS'), ('machine', 'NN'), ('learning', 'VBG'), ('instruct', 'NN')]

>> Noun Phrases are: 
 ['core objectives machine', 'instruct']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('One', 'one'), ('core', 'core'), ('objectives', 'object'), ('machine', 'machin'), ('learning', 'learn'), ('instruct', 'instruct')]

>> Stemming using Snowball Stemmer: 
 [('One', 'one'), ('core', 'core'), ('objectives', 'object'), ('machine', 'machin'), ('learning', 'learn'), ('instruct', 'instruct')]

>> Lemmatization: 
 [('One', 'One'), ('core', 'core'), ('objectives', 'objective'), ('machine', 'machine'), ('learning', 'learning'), ('instruct', 'instruct')]



========================================== PARAGRAPH 12 ===========================================

computers to use data or past experience to solve a given problem. A  

------------------- Sentence 1 -------------------

computers to use data or past experience to solve a given problem.

>> Tokens are: 
 ['computers', 'use', 'data', 'past', 'experience', 'solve', 'given', 'problem', '.']

>> Bigrams are: 
 [('computers', 'use'), ('use', 'data'), ('data', 'past'), ('past', 'experience'), ('experience', 'solve'), ('solve', 'given'), ('given', 'problem'), ('problem', '.')]

>> Trigrams are: 
 [('computers', 'use', 'data'), ('use', 'data', 'past'), ('data', 'past', 'experience'), ('past', 'experience', 'solve'), ('experience', 'solve', 'given'), ('solve', 'given', 'problem'), ('given', 'problem', '.')]

>> POS Tags are: 
 [('computers', 'NNS'), ('use', 'VBP'), ('data', 'NNS'), ('past', 'JJ'), ('experience', 'NN'), ('solve', 'NN'), ('given', 'VBN'), ('problem', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['computers', 'data', 'past experience solve', 'problem']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('computers', 'comput'), ('use', 'use'), ('data', 'data'), ('past', 'past'), ('experience', 'experi'), ('solve', 'solv'), ('given', 'given'), ('problem', 'problem'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('computers', 'comput'), ('use', 'use'), ('data', 'data'), ('past', 'past'), ('experience', 'experi'), ('solve', 'solv'), ('given', 'given'), ('problem', 'problem'), ('.', '.')]

>> Lemmatization: 
 [('computers', 'computer'), ('use', 'use'), ('data', 'data'), ('past', 'past'), ('experience', 'experience'), ('solve', 'solve'), ('given', 'given'), ('problem', 'problem'), ('.', '.')]


------------------- Sentence 2 -------------------

A

>> Tokens are: 
 ['A']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('A', 'DT')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('A', 'a')]

>> Stemming using Snowball Stemmer: 
 [('A', 'a')]

>> Lemmatization: 
 [('A', 'A')]



========================================== PARAGRAPH 13 ===========================================

good number of successful applications of machine learning exist  

------------------- Sentence 1 -------------------

good number of successful applications of machine learning exist

>> Tokens are: 
 ['good', 'number', 'successful', 'applications', 'machine', 'learning', 'exist']

>> Bigrams are: 
 [('good', 'number'), ('number', 'successful'), ('successful', 'applications'), ('applications', 'machine'), ('machine', 'learning'), ('learning', 'exist')]

>> Trigrams are: 
 [('good', 'number', 'successful'), ('number', 'successful', 'applications'), ('successful', 'applications', 'machine'), ('applications', 'machine', 'learning'), ('machine', 'learning', 'exist')]

>> POS Tags are: 
 [('good', 'JJ'), ('number', 'NN'), ('successful', 'JJ'), ('applications', 'NNS'), ('machine', 'NN'), ('learning', 'VBG'), ('exist', 'VBP')]

>> Noun Phrases are: 
 ['good number', 'successful applications machine']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('good', 'good'), ('number', 'number'), ('successful', 'success'), ('applications', 'applic'), ('machine', 'machin'), ('learning', 'learn'), ('exist', 'exist')]

>> Stemming using Snowball Stemmer: 
 [('good', 'good'), ('number', 'number'), ('successful', 'success'), ('applications', 'applic'), ('machine', 'machin'), ('learning', 'learn'), ('exist', 'exist')]

>> Lemmatization: 
 [('good', 'good'), ('number', 'number'), ('successful', 'successful'), ('applications', 'application'), ('machine', 'machine'), ('learning', 'learning'), ('exist', 'exist')]



========================================== PARAGRAPH 14 ===========================================

already, including classifier to be trained on email messages to learn  

------------------- Sentence 1 -------------------

already, including classifier to be trained on email messages to learn

>> Tokens are: 
 ['already', ',', 'including', 'classifier', 'trained', 'email', 'messages', 'learn']

>> Bigrams are: 
 [('already', ','), (',', 'including'), ('including', 'classifier'), ('classifier', 'trained'), ('trained', 'email'), ('email', 'messages'), ('messages', 'learn')]

>> Trigrams are: 
 [('already', ',', 'including'), (',', 'including', 'classifier'), ('including', 'classifier', 'trained'), ('classifier', 'trained', 'email'), ('trained', 'email', 'messages'), ('email', 'messages', 'learn')]

>> POS Tags are: 
 [('already', 'RB'), (',', ','), ('including', 'VBG'), ('classifier', 'NN'), ('trained', 'VBD'), ('email', 'JJ'), ('messages', 'NNS'), ('learn', 'VBP')]

>> Noun Phrases are: 
 ['classifier', 'email messages']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('already', 'alreadi'), (',', ','), ('including', 'includ'), ('classifier', 'classifi'), ('trained', 'train'), ('email', 'email'), ('messages', 'messag'), ('learn', 'learn')]

>> Stemming using Snowball Stemmer: 
 [('already', 'alreadi'), (',', ','), ('including', 'includ'), ('classifier', 'classifi'), ('trained', 'train'), ('email', 'email'), ('messages', 'messag'), ('learn', 'learn')]

>> Lemmatization: 
 [('already', 'already'), (',', ','), ('including', 'including'), ('classifier', 'classifier'), ('trained', 'trained'), ('email', 'email'), ('messages', 'message'), ('learn', 'learn')]



========================================== PARAGRAPH 15 ===========================================

in order to distinguish between spam and non-spam messages,  

------------------- Sentence 1 -------------------

in order to distinguish between spam and non-spam messages,

>> Tokens are: 
 ['order', 'distinguish', 'spam', 'non-spam', 'messages', ',']

>> Bigrams are: 
 [('order', 'distinguish'), ('distinguish', 'spam'), ('spam', 'non-spam'), ('non-spam', 'messages'), ('messages', ',')]

>> Trigrams are: 
 [('order', 'distinguish', 'spam'), ('distinguish', 'spam', 'non-spam'), ('spam', 'non-spam', 'messages'), ('non-spam', 'messages', ',')]

>> POS Tags are: 
 [('order', 'NN'), ('distinguish', 'JJ'), ('spam', 'NN'), ('non-spam', 'JJ'), ('messages', 'NNS'), (',', ',')]

>> Noun Phrases are: 
 ['order', 'distinguish spam', 'non-spam messages']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('order', 'order'), ('distinguish', 'distinguish'), ('spam', 'spam'), ('non-spam', 'non-spam'), ('messages', 'messag'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('order', 'order'), ('distinguish', 'distinguish'), ('spam', 'spam'), ('non-spam', 'non-spam'), ('messages', 'messag'), (',', ',')]

>> Lemmatization: 
 [('order', 'order'), ('distinguish', 'distinguish'), ('spam', 'spam'), ('non-spam', 'non-spam'), ('messages', 'message'), (',', ',')]



========================================== PARAGRAPH 16 ===========================================

systems that analyze past sales data to predict customer buying  

------------------- Sentence 1 -------------------

systems that analyze past sales data to predict customer buying

>> Tokens are: 
 ['systems', 'analyze', 'past', 'sales', 'data', 'predict', 'customer', 'buying']

>> Bigrams are: 
 [('systems', 'analyze'), ('analyze', 'past'), ('past', 'sales'), ('sales', 'data'), ('data', 'predict'), ('predict', 'customer'), ('customer', 'buying')]

>> Trigrams are: 
 [('systems', 'analyze', 'past'), ('analyze', 'past', 'sales'), ('past', 'sales', 'data'), ('sales', 'data', 'predict'), ('data', 'predict', 'customer'), ('predict', 'customer', 'buying')]

>> POS Tags are: 
 [('systems', 'NNS'), ('analyze', 'VBP'), ('past', 'JJ'), ('sales', 'NNS'), ('data', 'NNS'), ('predict', 'VBP'), ('customer', 'NN'), ('buying', 'NN')]

>> Noun Phrases are: 
 ['systems', 'past sales data', 'customer buying']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('systems', 'system'), ('analyze', 'analyz'), ('past', 'past'), ('sales', 'sale'), ('data', 'data'), ('predict', 'predict'), ('customer', 'custom'), ('buying', 'buy')]

>> Stemming using Snowball Stemmer: 
 [('systems', 'system'), ('analyze', 'analyz'), ('past', 'past'), ('sales', 'sale'), ('data', 'data'), ('predict', 'predict'), ('customer', 'custom'), ('buying', 'buy')]

>> Lemmatization: 
 [('systems', 'system'), ('analyze', 'analyze'), ('past', 'past'), ('sales', 'sale'), ('data', 'data'), ('predict', 'predict'), ('customer', 'customer'), ('buying', 'buying')]



========================================== PARAGRAPH 17 ===========================================

behavior, fraud detection etc. Machine learning can be applied as  

------------------- Sentence 1 -------------------

behavior, fraud detection etc.

>> Tokens are: 
 ['behavior', ',', 'fraud', 'detection', 'etc', '.']

>> Bigrams are: 
 [('behavior', ','), (',', 'fraud'), ('fraud', 'detection'), ('detection', 'etc'), ('etc', '.')]

>> Trigrams are: 
 [('behavior', ',', 'fraud'), (',', 'fraud', 'detection'), ('fraud', 'detection', 'etc'), ('detection', 'etc', '.')]

>> POS Tags are: 
 [('behavior', 'NN'), (',', ','), ('fraud', 'NN'), ('detection', 'NN'), ('etc', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['behavior', 'fraud detection etc']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('behavior', 'behavior'), (',', ','), ('fraud', 'fraud'), ('detection', 'detect'), ('etc', 'etc'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('behavior', 'behavior'), (',', ','), ('fraud', 'fraud'), ('detection', 'detect'), ('etc', 'etc'), ('.', '.')]

>> Lemmatization: 
 [('behavior', 'behavior'), (',', ','), ('fraud', 'fraud'), ('detection', 'detection'), ('etc', 'etc'), ('.', '.')]


------------------- Sentence 2 -------------------

Machine learning can be applied as

>> Tokens are: 
 ['Machine', 'learning', 'applied']

>> Bigrams are: 
 [('Machine', 'learning'), ('learning', 'applied')]

>> Trigrams are: 
 [('Machine', 'learning', 'applied')]

>> POS Tags are: 
 [('Machine', 'NN'), ('learning', 'NN'), ('applied', 'VBD')]

>> Noun Phrases are: 
 ['Machine learning']

>> Named Entities are: 
 [('GPE', 'Machine')] 

>> Stemming using Porter Stemmer: 
 [('Machine', 'machin'), ('learning', 'learn'), ('applied', 'appli')]

>> Stemming using Snowball Stemmer: 
 [('Machine', 'machin'), ('learning', 'learn'), ('applied', 'appli')]

>> Lemmatization: 
 [('Machine', 'Machine'), ('learning', 'learning'), ('applied', 'applied')]



========================================== PARAGRAPH 18 ===========================================

association analysis through Supervised learning, Unsupervised  

------------------- Sentence 1 -------------------

association analysis through Supervised learning, Unsupervised

>> Tokens are: 
 ['association', 'analysis', 'Supervised', 'learning', ',', 'Unsupervised']

>> Bigrams are: 
 [('association', 'analysis'), ('analysis', 'Supervised'), ('Supervised', 'learning'), ('learning', ','), (',', 'Unsupervised')]

>> Trigrams are: 
 [('association', 'analysis', 'Supervised'), ('analysis', 'Supervised', 'learning'), ('Supervised', 'learning', ','), ('learning', ',', 'Unsupervised')]

>> POS Tags are: 
 [('association', 'NN'), ('analysis', 'NN'), ('Supervised', 'VBD'), ('learning', 'NN'), (',', ','), ('Unsupervised', 'VBD')]

>> Noun Phrases are: 
 ['association analysis', 'learning']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('association', 'associ'), ('analysis', 'analysi'), ('Supervised', 'supervis'), ('learning', 'learn'), (',', ','), ('Unsupervised', 'unsupervis')]

>> Stemming using Snowball Stemmer: 
 [('association', 'associ'), ('analysis', 'analysi'), ('Supervised', 'supervis'), ('learning', 'learn'), (',', ','), ('Unsupervised', 'unsupervis')]

>> Lemmatization: 
 [('association', 'association'), ('analysis', 'analysis'), ('Supervised', 'Supervised'), ('learning', 'learning'), (',', ','), ('Unsupervised', 'Unsupervised')]



========================================== PARAGRAPH 19 ===========================================

learning and Reinforcement Learning but in this study we will focus  

------------------- Sentence 1 -------------------

learning and Reinforcement Learning but in this study we will focus

>> Tokens are: 
 ['learning', 'Reinforcement', 'Learning', 'study', 'focus']

>> Bigrams are: 
 [('learning', 'Reinforcement'), ('Reinforcement', 'Learning'), ('Learning', 'study'), ('study', 'focus')]

>> Trigrams are: 
 [('learning', 'Reinforcement', 'Learning'), ('Reinforcement', 'Learning', 'study'), ('Learning', 'study', 'focus')]

>> POS Tags are: 
 [('learning', 'VBG'), ('Reinforcement', 'NNP'), ('Learning', 'NNP'), ('study', 'NN'), ('focus', 'NN')]

>> Noun Phrases are: 
 ['Reinforcement Learning study focus']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('learning', 'learn'), ('Reinforcement', 'reinforc'), ('Learning', 'learn'), ('study', 'studi'), ('focus', 'focu')]

>> Stemming using Snowball Stemmer: 
 [('learning', 'learn'), ('Reinforcement', 'reinforc'), ('Learning', 'learn'), ('study', 'studi'), ('focus', 'focus')]

>> Lemmatization: 
 [('learning', 'learning'), ('Reinforcement', 'Reinforcement'), ('Learning', 'Learning'), ('study', 'study'), ('focus', 'focus')]



========================================== PARAGRAPH 20 ===========================================

on strength and weakness of supervised learning classification  

------------------- Sentence 1 -------------------

on strength and weakness of supervised learning classification

>> Tokens are: 
 ['strength', 'weakness', 'supervised', 'learning', 'classification']

>> Bigrams are: 
 [('strength', 'weakness'), ('weakness', 'supervised'), ('supervised', 'learning'), ('learning', 'classification')]

>> Trigrams are: 
 [('strength', 'weakness', 'supervised'), ('weakness', 'supervised', 'learning'), ('supervised', 'learning', 'classification')]

>> POS Tags are: 
 [('strength', 'NN'), ('weakness', 'NN'), ('supervised', 'VBD'), ('learning', 'JJ'), ('classification', 'NN')]

>> Noun Phrases are: 
 ['strength weakness', 'learning classification']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('strength', 'strength'), ('weakness', 'weak'), ('supervised', 'supervis'), ('learning', 'learn'), ('classification', 'classif')]

>> Stemming using Snowball Stemmer: 
 [('strength', 'strength'), ('weakness', 'weak'), ('supervised', 'supervis'), ('learning', 'learn'), ('classification', 'classif')]

>> Lemmatization: 
 [('strength', 'strength'), ('weakness', 'weakness'), ('supervised', 'supervised'), ('learning', 'learning'), ('classification', 'classification')]



========================================== PARAGRAPH 21 ===========================================

algorithms. The goal of supervised learning is to build a concise  

------------------- Sentence 1 -------------------

algorithms.

>> Tokens are: 
 ['algorithms', '.']

>> Bigrams are: 
 [('algorithms', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('algorithms', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['algorithms']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('algorithms', 'algorithm'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('algorithms', 'algorithm'), ('.', '.')]

>> Lemmatization: 
 [('algorithms', 'algorithm'), ('.', '.')]


------------------- Sentence 2 -------------------

The goal of supervised learning is to build a concise

>> Tokens are: 
 ['The', 'goal', 'supervised', 'learning', 'build', 'concise']

>> Bigrams are: 
 [('The', 'goal'), ('goal', 'supervised'), ('supervised', 'learning'), ('learning', 'build'), ('build', 'concise')]

>> Trigrams are: 
 [('The', 'goal', 'supervised'), ('goal', 'supervised', 'learning'), ('supervised', 'learning', 'build'), ('learning', 'build', 'concise')]

>> POS Tags are: 
 [('The', 'DT'), ('goal', 'NN'), ('supervised', 'VBD'), ('learning', 'VBG'), ('build', 'NN'), ('concise', 'NN')]

>> Noun Phrases are: 
 ['The goal', 'build concise']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('goal', 'goal'), ('supervised', 'supervis'), ('learning', 'learn'), ('build', 'build'), ('concise', 'concis')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('goal', 'goal'), ('supervised', 'supervis'), ('learning', 'learn'), ('build', 'build'), ('concise', 'concis')]

>> Lemmatization: 
 [('The', 'The'), ('goal', 'goal'), ('supervised', 'supervised'), ('learning', 'learning'), ('build', 'build'), ('concise', 'concise')]



========================================== PARAGRAPH 22 ===========================================

model of the distribution of class labels in terms of predictor features.  

------------------- Sentence 1 -------------------

model of the distribution of class labels in terms of predictor features.

>> Tokens are: 
 ['model', 'distribution', 'class', 'labels', 'terms', 'predictor', 'features', '.']

>> Bigrams are: 
 [('model', 'distribution'), ('distribution', 'class'), ('class', 'labels'), ('labels', 'terms'), ('terms', 'predictor'), ('predictor', 'features'), ('features', '.')]

>> Trigrams are: 
 [('model', 'distribution', 'class'), ('distribution', 'class', 'labels'), ('class', 'labels', 'terms'), ('labels', 'terms', 'predictor'), ('terms', 'predictor', 'features'), ('predictor', 'features', '.')]

>> POS Tags are: 
 [('model', 'NN'), ('distribution', 'NN'), ('class', 'NN'), ('labels', 'NNS'), ('terms', 'NNS'), ('predictor', 'NN'), ('features', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['model distribution class labels terms predictor features']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('model', 'model'), ('distribution', 'distribut'), ('class', 'class'), ('labels', 'label'), ('terms', 'term'), ('predictor', 'predictor'), ('features', 'featur'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('model', 'model'), ('distribution', 'distribut'), ('class', 'class'), ('labels', 'label'), ('terms', 'term'), ('predictor', 'predictor'), ('features', 'featur'), ('.', '.')]

>> Lemmatization: 
 [('model', 'model'), ('distribution', 'distribution'), ('class', 'class'), ('labels', 'label'), ('terms', 'term'), ('predictor', 'predictor'), ('features', 'feature'), ('.', '.')]



========================================== PARAGRAPH 23 ===========================================

The resulting classifier is then used to assign class labels to the testing  

------------------- Sentence 1 -------------------

The resulting classifier is then used to assign class labels to the testing

>> Tokens are: 
 ['The', 'resulting', 'classifier', 'used', 'assign', 'class', 'labels', 'testing']

>> Bigrams are: 
 [('The', 'resulting'), ('resulting', 'classifier'), ('classifier', 'used'), ('used', 'assign'), ('assign', 'class'), ('class', 'labels'), ('labels', 'testing')]

>> Trigrams are: 
 [('The', 'resulting', 'classifier'), ('resulting', 'classifier', 'used'), ('classifier', 'used', 'assign'), ('used', 'assign', 'class'), ('assign', 'class', 'labels'), ('class', 'labels', 'testing')]

>> POS Tags are: 
 [('The', 'DT'), ('resulting', 'VBG'), ('classifier', 'NN'), ('used', 'VBN'), ('assign', 'JJ'), ('class', 'NN'), ('labels', 'NNS'), ('testing', 'VBG')]

>> Noun Phrases are: 
 ['classifier', 'assign class labels']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('resulting', 'result'), ('classifier', 'classifi'), ('used', 'use'), ('assign', 'assign'), ('class', 'class'), ('labels', 'label'), ('testing', 'test')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('resulting', 'result'), ('classifier', 'classifi'), ('used', 'use'), ('assign', 'assign'), ('class', 'class'), ('labels', 'label'), ('testing', 'test')]

>> Lemmatization: 
 [('The', 'The'), ('resulting', 'resulting'), ('classifier', 'classifier'), ('used', 'used'), ('assign', 'assign'), ('class', 'class'), ('labels', 'label'), ('testing', 'testing')]



========================================== PARAGRAPH 24 ===========================================

instances where the values of the predictor features are known, but  

------------------- Sentence 1 -------------------

instances where the values of the predictor features are known, but

>> Tokens are: 
 ['instances', 'values', 'predictor', 'features', 'known', ',']

>> Bigrams are: 
 [('instances', 'values'), ('values', 'predictor'), ('predictor', 'features'), ('features', 'known'), ('known', ',')]

>> Trigrams are: 
 [('instances', 'values', 'predictor'), ('values', 'predictor', 'features'), ('predictor', 'features', 'known'), ('features', 'known', ',')]

>> POS Tags are: 
 [('instances', 'NNS'), ('values', 'NNS'), ('predictor', 'VBP'), ('features', 'NNS'), ('known', 'VBN'), (',', ',')]

>> Noun Phrases are: 
 ['instances values', 'features']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('instances', 'instanc'), ('values', 'valu'), ('predictor', 'predictor'), ('features', 'featur'), ('known', 'known'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('instances', 'instanc'), ('values', 'valu'), ('predictor', 'predictor'), ('features', 'featur'), ('known', 'known'), (',', ',')]

>> Lemmatization: 
 [('instances', 'instance'), ('values', 'value'), ('predictor', 'predictor'), ('features', 'feature'), ('known', 'known'), (',', ',')]



========================================== PARAGRAPH 25 ===========================================

the value of the class label is unknown. We are optimistic that this  

------------------- Sentence 1 -------------------

the value of the class label is unknown.

>> Tokens are: 
 ['value', 'class', 'label', 'unknown', '.']

>> Bigrams are: 
 [('value', 'class'), ('class', 'label'), ('label', 'unknown'), ('unknown', '.')]

>> Trigrams are: 
 [('value', 'class', 'label'), ('class', 'label', 'unknown'), ('label', 'unknown', '.')]

>> POS Tags are: 
 [('value', 'NN'), ('class', 'NN'), ('label', 'NN'), ('unknown', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['value class label unknown']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('value', 'valu'), ('class', 'class'), ('label', 'label'), ('unknown', 'unknown'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('value', 'valu'), ('class', 'class'), ('label', 'label'), ('unknown', 'unknown'), ('.', '.')]

>> Lemmatization: 
 [('value', 'value'), ('class', 'class'), ('label', 'label'), ('unknown', 'unknown'), ('.', '.')]


------------------- Sentence 2 -------------------

We are optimistic that this

>> Tokens are: 
 ['We', 'optimistic']

>> Bigrams are: 
 [('We', 'optimistic')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('We', 'PRP'), ('optimistic', 'JJ')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('We', 'we'), ('optimistic', 'optimist')]

>> Stemming using Snowball Stemmer: 
 [('We', 'we'), ('optimistic', 'optimist')]

>> Lemmatization: 
 [('We', 'We'), ('optimistic', 'optimistic')]



========================================== PARAGRAPH 26 ===========================================

study will help new researchers to guiding new research areas and to  

------------------- Sentence 1 -------------------

study will help new researchers to guiding new research areas and to

>> Tokens are: 
 ['study', 'help', 'new', 'researchers', 'guiding', 'new', 'research', 'areas']

>> Bigrams are: 
 [('study', 'help'), ('help', 'new'), ('new', 'researchers'), ('researchers', 'guiding'), ('guiding', 'new'), ('new', 'research'), ('research', 'areas')]

>> Trigrams are: 
 [('study', 'help', 'new'), ('help', 'new', 'researchers'), ('new', 'researchers', 'guiding'), ('researchers', 'guiding', 'new'), ('guiding', 'new', 'research'), ('new', 'research', 'areas')]

>> POS Tags are: 
 [('study', 'NN'), ('help', 'VB'), ('new', 'JJ'), ('researchers', 'NNS'), ('guiding', 'VBG'), ('new', 'JJ'), ('research', 'NN'), ('areas', 'NNS')]

>> Noun Phrases are: 
 ['study', 'new researchers', 'new research areas']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('study', 'studi'), ('help', 'help'), ('new', 'new'), ('researchers', 'research'), ('guiding', 'guid'), ('new', 'new'), ('research', 'research'), ('areas', 'area')]

>> Stemming using Snowball Stemmer: 
 [('study', 'studi'), ('help', 'help'), ('new', 'new'), ('researchers', 'research'), ('guiding', 'guid'), ('new', 'new'), ('research', 'research'), ('areas', 'area')]

>> Lemmatization: 
 [('study', 'study'), ('help', 'help'), ('new', 'new'), ('researchers', 'researcher'), ('guiding', 'guiding'), ('new', 'new'), ('research', 'research'), ('areas', 'area')]



========================================== PARAGRAPH 27 ===========================================

compare the effectiveness and impuissance of supervised learning  

------------------- Sentence 1 -------------------

compare the effectiveness and impuissance of supervised learning

>> Tokens are: 
 ['compare', 'effectiveness', 'impuissance', 'supervised', 'learning']

>> Bigrams are: 
 [('compare', 'effectiveness'), ('effectiveness', 'impuissance'), ('impuissance', 'supervised'), ('supervised', 'learning')]

>> Trigrams are: 
 [('compare', 'effectiveness', 'impuissance'), ('effectiveness', 'impuissance', 'supervised'), ('impuissance', 'supervised', 'learning')]

>> POS Tags are: 
 [('compare', 'NN'), ('effectiveness', 'NN'), ('impuissance', 'NN'), ('supervised', 'VBD'), ('learning', 'NN')]

>> Noun Phrases are: 
 ['compare effectiveness impuissance', 'learning']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('compare', 'compar'), ('effectiveness', 'effect'), ('impuissance', 'impuiss'), ('supervised', 'supervis'), ('learning', 'learn')]

>> Stemming using Snowball Stemmer: 
 [('compare', 'compar'), ('effectiveness', 'effect'), ('impuissance', 'impuiss'), ('supervised', 'supervis'), ('learning', 'learn')]

>> Lemmatization: 
 [('compare', 'compare'), ('effectiveness', 'effectiveness'), ('impuissance', 'impuissance'), ('supervised', 'supervised'), ('learning', 'learning')]



========================================== PARAGRAPH 28 ===========================================

algorithms.  

------------------- Sentence 1 -------------------

algorithms.

>> Tokens are: 
 ['algorithms', '.']

>> Bigrams are: 
 [('algorithms', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('algorithms', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['algorithms']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('algorithms', 'algorithm'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('algorithms', 'algorithm'), ('.', '.')]

>> Lemmatization: 
 [('algorithms', 'algorithm'), ('.', '.')]



========================================== PARAGRAPH 29 ===========================================

Keywords:  

------------------- Sentence 1 -------------------

Keywords:

>> Tokens are: 
 ['Keywords', ':']

>> Bigrams are: 
 [('Keywords', ':')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Keywords', 'NNS'), (':', ':')]

>> Noun Phrases are: 
 ['Keywords']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Keywords', 'keyword'), (':', ':')]

>> Stemming using Snowball Stemmer: 
 [('Keywords', 'keyword'), (':', ':')]

>> Lemmatization: 
 [('Keywords', 'Keywords'), (':', ':')]



========================================== PARAGRAPH 30 ===========================================

Supervised Machine Learning, SVM, DT, Classifier  

------------------- Sentence 1 -------------------

Supervised Machine Learning, SVM, DT, Classifier

>> Tokens are: 
 ['Supervised', 'Machine', 'Learning', ',', 'SVM', ',', 'DT', ',', 'Classifier']

>> Bigrams are: 
 [('Supervised', 'Machine'), ('Machine', 'Learning'), ('Learning', ','), (',', 'SVM'), ('SVM', ','), (',', 'DT'), ('DT', ','), (',', 'Classifier')]

>> Trigrams are: 
 [('Supervised', 'Machine', 'Learning'), ('Machine', 'Learning', ','), ('Learning', ',', 'SVM'), (',', 'SVM', ','), ('SVM', ',', 'DT'), (',', 'DT', ','), ('DT', ',', 'Classifier')]

>> POS Tags are: 
 [('Supervised', 'VBN'), ('Machine', 'NNP'), ('Learning', 'NNP'), (',', ','), ('SVM', 'NNP'), (',', ','), ('DT', 'NNP'), (',', ','), ('Classifier', 'NNP')]

>> Noun Phrases are: 
 ['Machine Learning', 'SVM', 'DT', 'Classifier']

>> Named Entities are: 
 [('PERSON', 'Machine Learning'), ('ORGANIZATION', 'SVM'), ('ORGANIZATION', 'DT'), ('PERSON', 'Classifier')] 

>> Stemming using Porter Stemmer: 
 [('Supervised', 'supervis'), ('Machine', 'machin'), ('Learning', 'learn'), (',', ','), ('SVM', 'svm'), (',', ','), ('DT', 'dt'), (',', ','), ('Classifier', 'classifi')]

>> Stemming using Snowball Stemmer: 
 [('Supervised', 'supervis'), ('Machine', 'machin'), ('Learning', 'learn'), (',', ','), ('SVM', 'svm'), (',', ','), ('DT', 'dt'), (',', ','), ('Classifier', 'classifi')]

>> Lemmatization: 
 [('Supervised', 'Supervised'), ('Machine', 'Machine'), ('Learning', 'Learning'), (',', ','), ('SVM', 'SVM'), (',', ','), ('DT', 'DT'), (',', ','), ('Classifier', 'Classifier')]



========================================== PARAGRAPH 31 ===========================================

1. INTRODUCTION 

------------------- Sentence 1 -------------------

1.

>> Tokens are: 
 ['1', '.']

>> Bigrams are: 
 [('1', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('1', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('1', '1'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('1', '1'), ('.', '.')]

>> Lemmatization: 
 [('1', '1'), ('.', '.')]


------------------- Sentence 2 -------------------

INTRODUCTION

>> Tokens are: 
 ['INTRODUCTION']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('INTRODUCTION', 'NN')]

>> Noun Phrases are: 
 ['INTRODUCTION']

>> Named Entities are: 
 [('ORGANIZATION', 'INTRODUCTION')] 

>> Stemming using Porter Stemmer: 
 [('INTRODUCTION', 'introduct')]

>> Stemming using Snowball Stemmer: 
 [('INTRODUCTION', 'introduct')]

>> Lemmatization: 
 [('INTRODUCTION', 'INTRODUCTION')]



========================================== PARAGRAPH 32 ===========================================

Machine Learning (ML) can be considered as a subfield of  

------------------- Sentence 1 -------------------

Machine Learning (ML) can be considered as a subfield of

>> Tokens are: 
 ['Machine', 'Learning', '(', 'ML', ')', 'considered', 'subfield']

>> Bigrams are: 
 [('Machine', 'Learning'), ('Learning', '('), ('(', 'ML'), ('ML', ')'), (')', 'considered'), ('considered', 'subfield')]

>> Trigrams are: 
 [('Machine', 'Learning', '('), ('Learning', '(', 'ML'), ('(', 'ML', ')'), ('ML', ')', 'considered'), (')', 'considered', 'subfield')]

>> POS Tags are: 
 [('Machine', 'NN'), ('Learning', 'NNP'), ('(', '('), ('ML', 'NNP'), (')', ')'), ('considered', 'VBD'), ('subfield', 'NN')]

>> Noun Phrases are: 
 ['Machine Learning', 'ML', 'subfield']

>> Named Entities are: 
 [('PERSON', 'Machine Learning')] 

>> Stemming using Porter Stemmer: 
 [('Machine', 'machin'), ('Learning', 'learn'), ('(', '('), ('ML', 'ml'), (')', ')'), ('considered', 'consid'), ('subfield', 'subfield')]

>> Stemming using Snowball Stemmer: 
 [('Machine', 'machin'), ('Learning', 'learn'), ('(', '('), ('ML', 'ml'), (')', ')'), ('considered', 'consid'), ('subfield', 'subfield')]

>> Lemmatization: 
 [('Machine', 'Machine'), ('Learning', 'Learning'), ('(', '('), ('ML', 'ML'), (')', ')'), ('considered', 'considered'), ('subfield', 'subfield')]



========================================== PARAGRAPH 33 ===========================================

Artificial Intelligence since those algorithms can be seen as  

------------------- Sentence 1 -------------------

Artificial Intelligence since those algorithms can be seen as

>> Tokens are: 
 ['Artificial', 'Intelligence', 'since', 'algorithms', 'seen']

>> Bigrams are: 
 [('Artificial', 'Intelligence'), ('Intelligence', 'since'), ('since', 'algorithms'), ('algorithms', 'seen')]

>> Trigrams are: 
 [('Artificial', 'Intelligence', 'since'), ('Intelligence', 'since', 'algorithms'), ('since', 'algorithms', 'seen')]

>> POS Tags are: 
 [('Artificial', 'JJ'), ('Intelligence', 'NNP'), ('since', 'IN'), ('algorithms', 'NN'), ('seen', 'VBN')]

>> Noun Phrases are: 
 ['Artificial Intelligence', 'algorithms']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Artificial', 'artifici'), ('Intelligence', 'intellig'), ('since', 'sinc'), ('algorithms', 'algorithm'), ('seen', 'seen')]

>> Stemming using Snowball Stemmer: 
 [('Artificial', 'artifici'), ('Intelligence', 'intellig'), ('since', 'sinc'), ('algorithms', 'algorithm'), ('seen', 'seen')]

>> Lemmatization: 
 [('Artificial', 'Artificial'), ('Intelligence', 'Intelligence'), ('since', 'since'), ('algorithms', 'algorithm'), ('seen', 'seen')]



========================================== PARAGRAPH 34 ===========================================

building blocks to make computers learn to behave more  

------------------- Sentence 1 -------------------

building blocks to make computers learn to behave more

>> Tokens are: 
 ['building', 'blocks', 'make', 'computers', 'learn', 'behave']

>> Bigrams are: 
 [('building', 'blocks'), ('blocks', 'make'), ('make', 'computers'), ('computers', 'learn'), ('learn', 'behave')]

>> Trigrams are: 
 [('building', 'blocks', 'make'), ('blocks', 'make', 'computers'), ('make', 'computers', 'learn'), ('computers', 'learn', 'behave')]

>> POS Tags are: 
 [('building', 'NN'), ('blocks', 'NNS'), ('make', 'VBP'), ('computers', 'NNS'), ('learn', 'RBR'), ('behave', 'VBP')]

>> Noun Phrases are: 
 ['building blocks', 'computers']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('building', 'build'), ('blocks', 'block'), ('make', 'make'), ('computers', 'comput'), ('learn', 'learn'), ('behave', 'behav')]

>> Stemming using Snowball Stemmer: 
 [('building', 'build'), ('blocks', 'block'), ('make', 'make'), ('computers', 'comput'), ('learn', 'learn'), ('behave', 'behav')]

>> Lemmatization: 
 [('building', 'building'), ('blocks', 'block'), ('make', 'make'), ('computers', 'computer'), ('learn', 'learn'), ('behave', 'behave')]



========================================== PARAGRAPH 35 ===========================================

intelligently by somehow generalizing rather that just storing  

------------------- Sentence 1 -------------------

intelligently by somehow generalizing rather that just storing

>> Tokens are: 
 ['intelligently', 'somehow', 'generalizing', 'rather', 'storing']

>> Bigrams are: 
 [('intelligently', 'somehow'), ('somehow', 'generalizing'), ('generalizing', 'rather'), ('rather', 'storing')]

>> Trigrams are: 
 [('intelligently', 'somehow', 'generalizing'), ('somehow', 'generalizing', 'rather'), ('generalizing', 'rather', 'storing')]

>> POS Tags are: 
 [('intelligently', 'RB'), ('somehow', 'RB'), ('generalizing', 'VBG'), ('rather', 'RB'), ('storing', 'VBG')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('intelligently', 'intellig'), ('somehow', 'somehow'), ('generalizing', 'gener'), ('rather', 'rather'), ('storing', 'store')]

>> Stemming using Snowball Stemmer: 
 [('intelligently', 'intellig'), ('somehow', 'somehow'), ('generalizing', 'general'), ('rather', 'rather'), ('storing', 'store')]

>> Lemmatization: 
 [('intelligently', 'intelligently'), ('somehow', 'somehow'), ('generalizing', 'generalizing'), ('rather', 'rather'), ('storing', 'storing')]



========================================== PARAGRAPH 36 ===========================================

and retrieving data items like a database system and other  

------------------- Sentence 1 -------------------

and retrieving data items like a database system and other

>> Tokens are: 
 ['retrieving', 'data', 'items', 'like', 'database', 'system']

>> Bigrams are: 
 [('retrieving', 'data'), ('data', 'items'), ('items', 'like'), ('like', 'database'), ('database', 'system')]

>> Trigrams are: 
 [('retrieving', 'data', 'items'), ('data', 'items', 'like'), ('items', 'like', 'database'), ('like', 'database', 'system')]

>> POS Tags are: 
 [('retrieving', 'VBG'), ('data', 'NNS'), ('items', 'NNS'), ('like', 'IN'), ('database', 'NN'), ('system', 'NN')]

>> Noun Phrases are: 
 ['data items', 'database system']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('retrieving', 'retriev'), ('data', 'data'), ('items', 'item'), ('like', 'like'), ('database', 'databas'), ('system', 'system')]

>> Stemming using Snowball Stemmer: 
 [('retrieving', 'retriev'), ('data', 'data'), ('items', 'item'), ('like', 'like'), ('database', 'databas'), ('system', 'system')]

>> Lemmatization: 
 [('retrieving', 'retrieving'), ('data', 'data'), ('items', 'item'), ('like', 'like'), ('database', 'database'), ('system', 'system')]



========================================== PARAGRAPH 37 ===========================================

applications would do. Machine learning has got its inspiration  

------------------- Sentence 1 -------------------

applications would do.

>> Tokens are: 
 ['applications', 'would', '.']

>> Bigrams are: 
 [('applications', 'would'), ('would', '.')]

>> Trigrams are: 
 [('applications', 'would', '.')]

>> POS Tags are: 
 [('applications', 'NNS'), ('would', 'MD'), ('.', '.')]

>> Noun Phrases are: 
 ['applications']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('applications', 'applic'), ('would', 'would'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('applications', 'applic'), ('would', 'would'), ('.', '.')]

>> Lemmatization: 
 [('applications', 'application'), ('would', 'would'), ('.', '.')]


------------------- Sentence 2 -------------------

Machine learning has got its inspiration

>> Tokens are: 
 ['Machine', 'learning', 'got', 'inspiration']

>> Bigrams are: 
 [('Machine', 'learning'), ('learning', 'got'), ('got', 'inspiration')]

>> Trigrams are: 
 [('Machine', 'learning', 'got'), ('learning', 'got', 'inspiration')]

>> POS Tags are: 
 [('Machine', 'NN'), ('learning', 'VBG'), ('got', 'VBD'), ('inspiration', 'NN')]

>> Noun Phrases are: 
 ['Machine', 'inspiration']

>> Named Entities are: 
 [('GPE', 'Machine')] 

>> Stemming using Porter Stemmer: 
 [('Machine', 'machin'), ('learning', 'learn'), ('got', 'got'), ('inspiration', 'inspir')]

>> Stemming using Snowball Stemmer: 
 [('Machine', 'machin'), ('learning', 'learn'), ('got', 'got'), ('inspiration', 'inspir')]

>> Lemmatization: 
 [('Machine', 'Machine'), ('learning', 'learning'), ('got', 'got'), ('inspiration', 'inspiration')]



========================================== PARAGRAPH 38 ===========================================

from a variety of academic disciplines, including computer  

------------------- Sentence 1 -------------------

from a variety of academic disciplines, including computer

>> Tokens are: 
 ['variety', 'academic', 'disciplines', ',', 'including', 'computer']

>> Bigrams are: 
 [('variety', 'academic'), ('academic', 'disciplines'), ('disciplines', ','), (',', 'including'), ('including', 'computer')]

>> Trigrams are: 
 [('variety', 'academic', 'disciplines'), ('academic', 'disciplines', ','), ('disciplines', ',', 'including'), (',', 'including', 'computer')]

>> POS Tags are: 
 [('variety', 'NN'), ('academic', 'JJ'), ('disciplines', 'NNS'), (',', ','), ('including', 'VBG'), ('computer', 'NN')]

>> Noun Phrases are: 
 ['variety', 'academic disciplines', 'computer']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('variety', 'varieti'), ('academic', 'academ'), ('disciplines', 'disciplin'), (',', ','), ('including', 'includ'), ('computer', 'comput')]

>> Stemming using Snowball Stemmer: 
 [('variety', 'varieti'), ('academic', 'academ'), ('disciplines', 'disciplin'), (',', ','), ('including', 'includ'), ('computer', 'comput')]

>> Lemmatization: 
 [('variety', 'variety'), ('academic', 'academic'), ('disciplines', 'discipline'), (',', ','), ('including', 'including'), ('computer', 'computer')]



========================================== PARAGRAPH 39 ===========================================

science, statistics, biology, and psychology. The core function of  

------------------- Sentence 1 -------------------

science, statistics, biology, and psychology.

>> Tokens are: 
 ['science', ',', 'statistics', ',', 'biology', ',', 'psychology', '.']

>> Bigrams are: 
 [('science', ','), (',', 'statistics'), ('statistics', ','), (',', 'biology'), ('biology', ','), (',', 'psychology'), ('psychology', '.')]

>> Trigrams are: 
 [('science', ',', 'statistics'), (',', 'statistics', ','), ('statistics', ',', 'biology'), (',', 'biology', ','), ('biology', ',', 'psychology'), (',', 'psychology', '.')]

>> POS Tags are: 
 [('science', 'NN'), (',', ','), ('statistics', 'NNS'), (',', ','), ('biology', 'NN'), (',', ','), ('psychology', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['science', 'statistics', 'biology', 'psychology']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('science', 'scienc'), (',', ','), ('statistics', 'statist'), (',', ','), ('biology', 'biolog'), (',', ','), ('psychology', 'psycholog'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('science', 'scienc'), (',', ','), ('statistics', 'statist'), (',', ','), ('biology', 'biolog'), (',', ','), ('psychology', 'psycholog'), ('.', '.')]

>> Lemmatization: 
 [('science', 'science'), (',', ','), ('statistics', 'statistic'), (',', ','), ('biology', 'biology'), (',', ','), ('psychology', 'psychology'), ('.', '.')]


------------------- Sentence 2 -------------------

The core function of

>> Tokens are: 
 ['The', 'core', 'function']

>> Bigrams are: 
 [('The', 'core'), ('core', 'function')]

>> Trigrams are: 
 [('The', 'core', 'function')]

>> POS Tags are: 
 [('The', 'DT'), ('core', 'NN'), ('function', 'NN')]

>> Noun Phrases are: 
 ['The core function']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('core', 'core'), ('function', 'function')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('core', 'core'), ('function', 'function')]

>> Lemmatization: 
 [('The', 'The'), ('core', 'core'), ('function', 'function')]



========================================== PARAGRAPH 40 ===========================================

Machine learning attempts is to tell computers how to  

------------------- Sentence 1 -------------------

Machine learning attempts is to tell computers how to

>> Tokens are: 
 ['Machine', 'learning', 'attempts', 'tell', 'computers']

>> Bigrams are: 
 [('Machine', 'learning'), ('learning', 'attempts'), ('attempts', 'tell'), ('tell', 'computers')]

>> Trigrams are: 
 [('Machine', 'learning', 'attempts'), ('learning', 'attempts', 'tell'), ('attempts', 'tell', 'computers')]

>> POS Tags are: 
 [('Machine', 'NN'), ('learning', 'VBG'), ('attempts', 'NNS'), ('tell', 'VBP'), ('computers', 'NNS')]

>> Noun Phrases are: 
 ['Machine', 'attempts', 'computers']

>> Named Entities are: 
 [('GPE', 'Machine')] 

>> Stemming using Porter Stemmer: 
 [('Machine', 'machin'), ('learning', 'learn'), ('attempts', 'attempt'), ('tell', 'tell'), ('computers', 'comput')]

>> Stemming using Snowball Stemmer: 
 [('Machine', 'machin'), ('learning', 'learn'), ('attempts', 'attempt'), ('tell', 'tell'), ('computers', 'comput')]

>> Lemmatization: 
 [('Machine', 'Machine'), ('learning', 'learning'), ('attempts', 'attempt'), ('tell', 'tell'), ('computers', 'computer')]



========================================== PARAGRAPH 41 ===========================================

automatically find a good predictor based on past experiences  

------------------- Sentence 1 -------------------

automatically find a good predictor based on past experiences

>> Tokens are: 
 ['automatically', 'find', 'good', 'predictor', 'based', 'past', 'experiences']

>> Bigrams are: 
 [('automatically', 'find'), ('find', 'good'), ('good', 'predictor'), ('predictor', 'based'), ('based', 'past'), ('past', 'experiences')]

>> Trigrams are: 
 [('automatically', 'find', 'good'), ('find', 'good', 'predictor'), ('good', 'predictor', 'based'), ('predictor', 'based', 'past'), ('based', 'past', 'experiences')]

>> POS Tags are: 
 [('automatically', 'RB'), ('find', 'VB'), ('good', 'JJ'), ('predictor', 'NN'), ('based', 'VBN'), ('past', 'JJ'), ('experiences', 'NNS')]

>> Noun Phrases are: 
 ['good predictor', 'past experiences']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('automatically', 'automat'), ('find', 'find'), ('good', 'good'), ('predictor', 'predictor'), ('based', 'base'), ('past', 'past'), ('experiences', 'experi')]

>> Stemming using Snowball Stemmer: 
 [('automatically', 'automat'), ('find', 'find'), ('good', 'good'), ('predictor', 'predictor'), ('based', 'base'), ('past', 'past'), ('experiences', 'experi')]

>> Lemmatization: 
 [('automatically', 'automatically'), ('find', 'find'), ('good', 'good'), ('predictor', 'predictor'), ('based', 'based'), ('past', 'past'), ('experiences', 'experience')]



========================================== PARAGRAPH 42 ===========================================

and this job is done by good classifier. Classification is the  

------------------- Sentence 1 -------------------

and this job is done by good classifier.

>> Tokens are: 
 ['job', 'done', 'good', 'classifier', '.']

>> Bigrams are: 
 [('job', 'done'), ('done', 'good'), ('good', 'classifier'), ('classifier', '.')]

>> Trigrams are: 
 [('job', 'done', 'good'), ('done', 'good', 'classifier'), ('good', 'classifier', '.')]

>> POS Tags are: 
 [('job', 'NN'), ('done', 'VBN'), ('good', 'JJ'), ('classifier', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['job', 'good classifier']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('job', 'job'), ('done', 'done'), ('good', 'good'), ('classifier', 'classifi'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('job', 'job'), ('done', 'done'), ('good', 'good'), ('classifier', 'classifi'), ('.', '.')]

>> Lemmatization: 
 [('job', 'job'), ('done', 'done'), ('good', 'good'), ('classifier', 'classifier'), ('.', '.')]


------------------- Sentence 2 -------------------

Classification is the

>> Tokens are: 
 ['Classification']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Classification', 'NN')]

>> Noun Phrases are: 
 ['Classification']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Classification', 'classif')]

>> Stemming using Snowball Stemmer: 
 [('Classification', 'classif')]

>> Lemmatization: 
 [('Classification', 'Classification')]



========================================== PARAGRAPH 43 ===========================================

process of using a model to predict unknown values (output  

------------------- Sentence 1 -------------------

process of using a model to predict unknown values (output

>> Tokens are: 
 ['process', 'using', 'model', 'predict', 'unknown', 'values', '(', 'output']

>> Bigrams are: 
 [('process', 'using'), ('using', 'model'), ('model', 'predict'), ('predict', 'unknown'), ('unknown', 'values'), ('values', '('), ('(', 'output')]

>> Trigrams are: 
 [('process', 'using', 'model'), ('using', 'model', 'predict'), ('model', 'predict', 'unknown'), ('predict', 'unknown', 'values'), ('unknown', 'values', '('), ('values', '(', 'output')]

>> POS Tags are: 
 [('process', 'NN'), ('using', 'VBG'), ('model', 'NN'), ('predict', 'JJ'), ('unknown', 'JJ'), ('values', 'NNS'), ('(', '('), ('output', 'NN')]

>> Noun Phrases are: 
 ['process', 'model', 'predict unknown values', 'output']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('process', 'process'), ('using', 'use'), ('model', 'model'), ('predict', 'predict'), ('unknown', 'unknown'), ('values', 'valu'), ('(', '('), ('output', 'output')]

>> Stemming using Snowball Stemmer: 
 [('process', 'process'), ('using', 'use'), ('model', 'model'), ('predict', 'predict'), ('unknown', 'unknown'), ('values', 'valu'), ('(', '('), ('output', 'output')]

>> Lemmatization: 
 [('process', 'process'), ('using', 'using'), ('model', 'model'), ('predict', 'predict'), ('unknown', 'unknown'), ('values', 'value'), ('(', '('), ('output', 'output')]



========================================== PARAGRAPH 44 ===========================================

variables), using a number of known values (input variables).  

------------------- Sentence 1 -------------------

variables), using a number of known values (input variables).

>> Tokens are: 
 ['variables', ')', ',', 'using', 'number', 'known', 'values', '(', 'input', 'variables', ')', '.']

>> Bigrams are: 
 [('variables', ')'), (')', ','), (',', 'using'), ('using', 'number'), ('number', 'known'), ('known', 'values'), ('values', '('), ('(', 'input'), ('input', 'variables'), ('variables', ')'), (')', '.')]

>> Trigrams are: 
 [('variables', ')', ','), (')', ',', 'using'), (',', 'using', 'number'), ('using', 'number', 'known'), ('number', 'known', 'values'), ('known', 'values', '('), ('values', '(', 'input'), ('(', 'input', 'variables'), ('input', 'variables', ')'), ('variables', ')', '.')]

>> POS Tags are: 
 [('variables', 'NNS'), (')', ')'), (',', ','), ('using', 'VBG'), ('number', 'NN'), ('known', 'VBN'), ('values', 'NNS'), ('(', '('), ('input', 'VB'), ('variables', 'NNS'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['variables', 'number', 'values', 'variables']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('variables', 'variabl'), (')', ')'), (',', ','), ('using', 'use'), ('number', 'number'), ('known', 'known'), ('values', 'valu'), ('(', '('), ('input', 'input'), ('variables', 'variabl'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('variables', 'variabl'), (')', ')'), (',', ','), ('using', 'use'), ('number', 'number'), ('known', 'known'), ('values', 'valu'), ('(', '('), ('input', 'input'), ('variables', 'variabl'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('variables', 'variable'), (')', ')'), (',', ','), ('using', 'using'), ('number', 'number'), ('known', 'known'), ('values', 'value'), ('(', '('), ('input', 'input'), ('variables', 'variable'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 45 ===========================================

The classification process is performed on data set D which  

------------------- Sentence 1 -------------------

The classification process is performed on data set D which

>> Tokens are: 
 ['The', 'classification', 'process', 'performed', 'data', 'set', 'D']

>> Bigrams are: 
 [('The', 'classification'), ('classification', 'process'), ('process', 'performed'), ('performed', 'data'), ('data', 'set'), ('set', 'D')]

>> Trigrams are: 
 [('The', 'classification', 'process'), ('classification', 'process', 'performed'), ('process', 'performed', 'data'), ('performed', 'data', 'set'), ('data', 'set', 'D')]

>> POS Tags are: 
 [('The', 'DT'), ('classification', 'NN'), ('process', 'NN'), ('performed', 'VBD'), ('data', 'NNS'), ('set', 'NN'), ('D', 'NNP')]

>> Noun Phrases are: 
 ['The classification process', 'data set D']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('classification', 'classif'), ('process', 'process'), ('performed', 'perform'), ('data', 'data'), ('set', 'set'), ('D', 'd')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('classification', 'classif'), ('process', 'process'), ('performed', 'perform'), ('data', 'data'), ('set', 'set'), ('D', 'd')]

>> Lemmatization: 
 [('The', 'The'), ('classification', 'classification'), ('process', 'process'), ('performed', 'performed'), ('data', 'data'), ('set', 'set'), ('D', 'D')]



========================================== PARAGRAPH 46 ===========================================

holds following objects:  

------------------- Sentence 1 -------------------

holds following objects:

>> Tokens are: 
 ['holds', 'following', 'objects', ':']

>> Bigrams are: 
 [('holds', 'following'), ('following', 'objects'), ('objects', ':')]

>> Trigrams are: 
 [('holds', 'following', 'objects'), ('following', 'objects', ':')]

>> POS Tags are: 
 [('holds', 'VBZ'), ('following', 'VBG'), ('objects', 'NNS'), (':', ':')]

>> Noun Phrases are: 
 ['objects']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('holds', 'hold'), ('following', 'follow'), ('objects', 'object'), (':', ':')]

>> Stemming using Snowball Stemmer: 
 [('holds', 'hold'), ('following', 'follow'), ('objects', 'object'), (':', ':')]

>> Lemmatization: 
 [('holds', 'hold'), ('following', 'following'), ('objects', 'object'), (':', ':')]



========================================== PARAGRAPH 47 ===========================================

 Set size   AAAAA ,,2,1  , where A  denotes the number of attributes or the size of the set A. 

------------------- Sentence 1 -------------------

 Set size   AAAAA ,,2,1  , where A  denotes the number of attributes or the size of the set A.

>> Tokens are: 
 ['\uf0b7', 'Set', 'size', '', '\uf07b', '\uf07dAAAAA', ',', ',2,1', '\uf04b\uf03d', ',', 'A', 'denotes', 'number', 'attributes', 'size', 'set', 'A', '.']

>> Bigrams are: 
 [('\uf0b7', 'Set'), ('Set', 'size'), ('size', ''), ('', '\uf07b'), ('\uf07b', '\uf07dAAAAA'), ('\uf07dAAAAA', ','), (',', ',2,1'), (',2,1', '\uf04b\uf03d'), ('\uf04b\uf03d', ','), (',', 'A'), ('A', 'denotes'), ('denotes', 'number'), ('number', 'attributes'), ('attributes', 'size'), ('size', 'set'), ('set', 'A'), ('A', '.')]

>> Trigrams are: 
 [('\uf0b7', 'Set', 'size'), ('Set', 'size', ''), ('size', '', '\uf07b'), ('', '\uf07b', '\uf07dAAAAA'), ('\uf07b', '\uf07dAAAAA', ','), ('\uf07dAAAAA', ',', ',2,1'), (',', ',2,1', '\uf04b\uf03d'), (',2,1', '\uf04b\uf03d', ','), ('\uf04b\uf03d', ',', 'A'), (',', 'A', 'denotes'), ('A', 'denotes', 'number'), ('denotes', 'number', 'attributes'), ('number', 'attributes', 'size'), ('attributes', 'size', 'set'), ('size', 'set', 'A'), ('set', 'A', '.')]

>> POS Tags are: 
 [('\uf0b7', 'NN'), ('Set', 'NNP'), ('size', 'NN'), ('', 'NNP'), ('\uf07b', 'NNP'), ('\uf07dAAAAA', 'NNP'), (',', ','), (',2,1', 'NNP'), ('\uf04b\uf03d', 'NNP'), (',', ','), ('A', 'NNP'), ('denotes', 'VBZ'), ('number', 'NN'), ('attributes', 'NNS'), ('size', 'NN'), ('set', 'VBN'), ('A', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['\uf0b7 Set size  \uf07b \uf07dAAAAA', ',2,1 \uf04b\uf03d', 'A', 'number attributes size', 'A']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('\uf0b7', '\uf0b7'), ('Set', 'set'), ('size', 'size'), ('', ''), ('\uf07b', '\uf07b'), ('\uf07dAAAAA', '\uf07daaaaa'), (',', ','), (',2,1', ',2,1'), ('\uf04b\uf03d', '\uf04b\uf03d'), (',', ','), ('A', 'a'), ('denotes', 'denot'), ('number', 'number'), ('attributes', 'attribut'), ('size', 'size'), ('set', 'set'), ('A', 'a'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('\uf0b7', '\uf0b7'), ('Set', 'set'), ('size', 'size'), ('', ''), ('\uf07b', '\uf07b'), ('\uf07dAAAAA', '\uf07daaaaa'), (',', ','), (',2,1', ',2,1'), ('\uf04b\uf03d', '\uf04b\uf03d'), (',', ','), ('A', 'a'), ('denotes', 'denot'), ('number', 'number'), ('attributes', 'attribut'), ('size', 'size'), ('set', 'set'), ('A', 'a'), ('.', '.')]

>> Lemmatization: 
 [('\uf0b7', '\uf0b7'), ('Set', 'Set'), ('size', 'size'), ('', ''), ('\uf07b', '\uf07b'), ('\uf07dAAAAA', '\uf07dAAAAA'), (',', ','), (',2,1', ',2,1'), ('\uf04b\uf03d', '\uf04b\uf03d'), (',', ','), ('A', 'A'), ('denotes', 'denotes'), ('number', 'number'), ('attributes', 'attribute'), ('size', 'size'), ('set', 'set'), ('A', 'A'), ('.', '.')]



========================================== PARAGRAPH 48 ===========================================

 Class label C: Target attribute;  CcccC ,,2,1  , where C  is the number of classes and 2C . 

------------------- Sentence 1 -------------------

 Class label C: Target attribute;  CcccC ,,2,1  , where C  is the number of classes and 2C .

>> Tokens are: 
 ['\uf0b7', 'Class', 'label', 'C', ':', 'Target', 'attribute', ';', '\uf07b', '\uf07dCcccC', ',', ',2,1', '\uf04b\uf03d', ',', 'C', 'number', 'classes', '2\uf0b3C', '.']

>> Bigrams are: 
 [('\uf0b7', 'Class'), ('Class', 'label'), ('label', 'C'), ('C', ':'), (':', 'Target'), ('Target', 'attribute'), ('attribute', ';'), (';', '\uf07b'), ('\uf07b', '\uf07dCcccC'), ('\uf07dCcccC', ','), (',', ',2,1'), (',2,1', '\uf04b\uf03d'), ('\uf04b\uf03d', ','), (',', 'C'), ('C', 'number'), ('number', 'classes'), ('classes', '2\uf0b3C'), ('2\uf0b3C', '.')]

>> Trigrams are: 
 [('\uf0b7', 'Class', 'label'), ('Class', 'label', 'C'), ('label', 'C', ':'), ('C', ':', 'Target'), (':', 'Target', 'attribute'), ('Target', 'attribute', ';'), ('attribute', ';', '\uf07b'), (';', '\uf07b', '\uf07dCcccC'), ('\uf07b', '\uf07dCcccC', ','), ('\uf07dCcccC', ',', ',2,1'), (',', ',2,1', '\uf04b\uf03d'), (',2,1', '\uf04b\uf03d', ','), ('\uf04b\uf03d', ',', 'C'), (',', 'C', 'number'), ('C', 'number', 'classes'), ('number', 'classes', '2\uf0b3C'), ('classes', '2\uf0b3C', '.')]

>> POS Tags are: 
 [('\uf0b7', 'JJ'), ('Class', 'NNP'), ('label', 'NN'), ('C', 'NNP'), (':', ':'), ('Target', 'NNP'), ('attribute', 'NN'), (';', ':'), ('\uf07b', 'CC'), ('\uf07dCcccC', 'VB'), (',', ','), (',2,1', 'NNP'), ('\uf04b\uf03d', 'NNP'), (',', ','), ('C', 'NNP'), ('number', 'NN'), ('classes', 'VBZ'), ('2\uf0b3C', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['\uf0b7 Class label C', 'Target attribute', ',2,1 \uf04b\uf03d', 'C number']

>> Named Entities are: 
 [('PERSON', 'Target')] 

>> Stemming using Porter Stemmer: 
 [('\uf0b7', '\uf0b7'), ('Class', 'class'), ('label', 'label'), ('C', 'c'), (':', ':'), ('Target', 'target'), ('attribute', 'attribut'), (';', ';'), ('\uf07b', '\uf07b'), ('\uf07dCcccC', '\uf07dccccc'), (',', ','), (',2,1', ',2,1'), ('\uf04b\uf03d', '\uf04b\uf03d'), (',', ','), ('C', 'c'), ('number', 'number'), ('classes', 'class'), ('2\uf0b3C', '2\uf0b3c'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('\uf0b7', '\uf0b7'), ('Class', 'class'), ('label', 'label'), ('C', 'c'), (':', ':'), ('Target', 'target'), ('attribute', 'attribut'), (';', ';'), ('\uf07b', '\uf07b'), ('\uf07dCcccC', '\uf07dccccc'), (',', ','), (',2,1', ',2,1'), ('\uf04b\uf03d', '\uf04b\uf03d'), (',', ','), ('C', 'c'), ('number', 'number'), ('classes', 'class'), ('2\uf0b3C', '2\uf0b3c'), ('.', '.')]

>> Lemmatization: 
 [('\uf0b7', '\uf0b7'), ('Class', 'Class'), ('label', 'label'), ('C', 'C'), (':', ':'), ('Target', 'Target'), ('attribute', 'attribute'), (';', ';'), ('\uf07b', '\uf07b'), ('\uf07dCcccC', '\uf07dCcccC'), (',', ','), (',2,1', ',2,1'), ('\uf04b\uf03d', '\uf04b\uf03d'), (',', ','), ('C', 'C'), ('number', 'number'), ('classes', 'class'), ('2\uf0b3C', '2\uf0b3C'), ('.', '.')]



========================================== PARAGRAPH 49 ===========================================

Given a data set D, the core objective of ML is to produce a  

------------------- Sentence 1 -------------------

Given a data set D, the core objective of ML is to produce a

>> Tokens are: 
 ['Given', 'data', 'set', 'D', ',', 'core', 'objective', 'ML', 'produce']

>> Bigrams are: 
 [('Given', 'data'), ('data', 'set'), ('set', 'D'), ('D', ','), (',', 'core'), ('core', 'objective'), ('objective', 'ML'), ('ML', 'produce')]

>> Trigrams are: 
 [('Given', 'data', 'set'), ('data', 'set', 'D'), ('set', 'D', ','), ('D', ',', 'core'), (',', 'core', 'objective'), ('core', 'objective', 'ML'), ('objective', 'ML', 'produce')]

>> POS Tags are: 
 [('Given', 'VBN'), ('data', 'NNS'), ('set', 'VBD'), ('D', 'NNP'), (',', ','), ('core', 'RB'), ('objective', 'JJ'), ('ML', 'NNP'), ('produce', 'NN')]

>> Noun Phrases are: 
 ['data', 'D', 'objective ML produce']

>> Named Entities are: 
 [('PERSON', 'D')] 

>> Stemming using Porter Stemmer: 
 [('Given', 'given'), ('data', 'data'), ('set', 'set'), ('D', 'd'), (',', ','), ('core', 'core'), ('objective', 'object'), ('ML', 'ml'), ('produce', 'produc')]

>> Stemming using Snowball Stemmer: 
 [('Given', 'given'), ('data', 'data'), ('set', 'set'), ('D', 'd'), (',', ','), ('core', 'core'), ('objective', 'object'), ('ML', 'ml'), ('produce', 'produc')]

>> Lemmatization: 
 [('Given', 'Given'), ('data', 'data'), ('set', 'set'), ('D', 'D'), (',', ','), ('core', 'core'), ('objective', 'objective'), ('ML', 'ML'), ('produce', 'produce')]



========================================== PARAGRAPH 50 ===========================================

prediction/classification function to relate values of attributes in  

------------------- Sentence 1 -------------------

prediction/classification function to relate values of attributes in

>> Tokens are: 
 ['prediction/classification', 'function', 'relate', 'values', 'attributes']

>> Bigrams are: 
 [('prediction/classification', 'function'), ('function', 'relate'), ('relate', 'values'), ('values', 'attributes')]

>> Trigrams are: 
 [('prediction/classification', 'function', 'relate'), ('function', 'relate', 'values'), ('relate', 'values', 'attributes')]

>> POS Tags are: 
 [('prediction/classification', 'NN'), ('function', 'NN'), ('relate', 'NN'), ('values', 'NNS'), ('attributes', 'NNS')]

>> Noun Phrases are: 
 ['prediction/classification function relate values attributes']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('prediction/classification', 'prediction/classif'), ('function', 'function'), ('relate', 'relat'), ('values', 'valu'), ('attributes', 'attribut')]

>> Stemming using Snowball Stemmer: 
 [('prediction/classification', 'prediction/classif'), ('function', 'function'), ('relate', 'relat'), ('values', 'valu'), ('attributes', 'attribut')]

>> Lemmatization: 
 [('prediction/classification', 'prediction/classification'), ('function', 'function'), ('relate', 'relate'), ('values', 'value'), ('attributes', 'attribute')]



========================================== PARAGRAPH 51 ===========================================

A and classes in C.  

------------------- Sentence 1 -------------------

A and classes in C.

>> Tokens are: 
 ['A', 'classes', 'C', '.']

>> Bigrams are: 
 [('A', 'classes'), ('classes', 'C'), ('C', '.')]

>> Trigrams are: 
 [('A', 'classes', 'C'), ('classes', 'C', '.')]

>> POS Tags are: 
 [('A', 'DT'), ('classes', 'NNS'), ('C', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['A classes C']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('A', 'a'), ('classes', 'class'), ('C', 'c'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('A', 'a'), ('classes', 'class'), ('C', 'c'), ('.', '.')]

>> Lemmatization: 
 [('A', 'A'), ('classes', 'class'), ('C', 'C'), ('.', '.')]



========================================== PARAGRAPH 52 ===========================================

Data mining is one of the most tools of machine learning  

------------------- Sentence 1 -------------------

Data mining is one of the most tools of machine learning

>> Tokens are: 
 ['Data', 'mining', 'one', 'tools', 'machine', 'learning']

>> Bigrams are: 
 [('Data', 'mining'), ('mining', 'one'), ('one', 'tools'), ('tools', 'machine'), ('machine', 'learning')]

>> Trigrams are: 
 [('Data', 'mining', 'one'), ('mining', 'one', 'tools'), ('one', 'tools', 'machine'), ('tools', 'machine', 'learning')]

>> POS Tags are: 
 [('Data', 'NNP'), ('mining', 'NN'), ('one', 'CD'), ('tools', 'VBZ'), ('machine', 'NN'), ('learning', 'NN')]

>> Noun Phrases are: 
 ['Data mining', 'machine learning']

>> Named Entities are: 
 [('GPE', 'Data')] 

>> Stemming using Porter Stemmer: 
 [('Data', 'data'), ('mining', 'mine'), ('one', 'one'), ('tools', 'tool'), ('machine', 'machin'), ('learning', 'learn')]

>> Stemming using Snowball Stemmer: 
 [('Data', 'data'), ('mining', 'mine'), ('one', 'one'), ('tools', 'tool'), ('machine', 'machin'), ('learning', 'learn')]

>> Lemmatization: 
 [('Data', 'Data'), ('mining', 'mining'), ('one', 'one'), ('tools', 'tool'), ('machine', 'machine'), ('learning', 'learning')]



========================================== PARAGRAPH 53 ===========================================

among the number of different applications. It is common that  

------------------- Sentence 1 -------------------

among the number of different applications.

>> Tokens are: 
 ['among', 'number', 'different', 'applications', '.']

>> Bigrams are: 
 [('among', 'number'), ('number', 'different'), ('different', 'applications'), ('applications', '.')]

>> Trigrams are: 
 [('among', 'number', 'different'), ('number', 'different', 'applications'), ('different', 'applications', '.')]

>> POS Tags are: 
 [('among', 'IN'), ('number', 'NN'), ('different', 'JJ'), ('applications', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['number', 'different applications']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('among', 'among'), ('number', 'number'), ('different', 'differ'), ('applications', 'applic'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('among', 'among'), ('number', 'number'), ('different', 'differ'), ('applications', 'applic'), ('.', '.')]

>> Lemmatization: 
 [('among', 'among'), ('number', 'number'), ('different', 'different'), ('applications', 'application'), ('.', '.')]


------------------- Sentence 2 -------------------

It is common that

>> Tokens are: 
 ['It', 'common']

>> Bigrams are: 
 [('It', 'common')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('It', 'PRP'), ('common', 'JJ')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('It', 'it'), ('common', 'common')]

>> Stemming using Snowball Stemmer: 
 [('It', 'it'), ('common', 'common')]

>> Lemmatization: 
 [('It', 'It'), ('common', 'common')]



========================================== PARAGRAPH 54 ===========================================

people are often choosing a wrong choices during analysis phase  

------------------- Sentence 1 -------------------

people are often choosing a wrong choices during analysis phase

>> Tokens are: 
 ['people', 'often', 'choosing', 'wrong', 'choices', 'analysis', 'phase']

>> Bigrams are: 
 [('people', 'often'), ('often', 'choosing'), ('choosing', 'wrong'), ('wrong', 'choices'), ('choices', 'analysis'), ('analysis', 'phase')]

>> Trigrams are: 
 [('people', 'often', 'choosing'), ('often', 'choosing', 'wrong'), ('choosing', 'wrong', 'choices'), ('wrong', 'choices', 'analysis'), ('choices', 'analysis', 'phase')]

>> POS Tags are: 
 [('people', 'NNS'), ('often', 'RB'), ('choosing', 'VBG'), ('wrong', 'JJ'), ('choices', 'NNS'), ('analysis', 'NN'), ('phase', 'NN')]

>> Noun Phrases are: 
 ['people', 'wrong choices analysis phase']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('people', 'peopl'), ('often', 'often'), ('choosing', 'choos'), ('wrong', 'wrong'), ('choices', 'choic'), ('analysis', 'analysi'), ('phase', 'phase')]

>> Stemming using Snowball Stemmer: 
 [('people', 'peopl'), ('often', 'often'), ('choosing', 'choos'), ('wrong', 'wrong'), ('choices', 'choic'), ('analysis', 'analysi'), ('phase', 'phase')]

>> Lemmatization: 
 [('people', 'people'), ('often', 'often'), ('choosing', 'choosing'), ('wrong', 'wrong'), ('choices', 'choice'), ('analysis', 'analysis'), ('phase', 'phase')]



========================================== PARAGRAPH 55 ===========================================

or, possibly, when trying to establish relationships between  

------------------- Sentence 1 -------------------

or, possibly, when trying to establish relationships between

>> Tokens are: 
 [',', 'possibly', ',', 'trying', 'establish', 'relationships']

>> Bigrams are: 
 [(',', 'possibly'), ('possibly', ','), (',', 'trying'), ('trying', 'establish'), ('establish', 'relationships')]

>> Trigrams are: 
 [(',', 'possibly', ','), ('possibly', ',', 'trying'), (',', 'trying', 'establish'), ('trying', 'establish', 'relationships')]

>> POS Tags are: 
 [(',', ','), ('possibly', 'RB'), (',', ','), ('trying', 'VBG'), ('establish', 'VB'), ('relationships', 'NNS')]

>> Noun Phrases are: 
 ['relationships']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [(',', ','), ('possibly', 'possibl'), (',', ','), ('trying', 'tri'), ('establish', 'establish'), ('relationships', 'relationship')]

>> Stemming using Snowball Stemmer: 
 [(',', ','), ('possibly', 'possibl'), (',', ','), ('trying', 'tri'), ('establish', 'establish'), ('relationships', 'relationship')]

>> Lemmatization: 
 [(',', ','), ('possibly', 'possibly'), (',', ','), ('trying', 'trying'), ('establish', 'establish'), ('relationships', 'relationship')]



========================================== PARAGRAPH 56 ===========================================

multiple features. Ultimately this makes it difficult for them to  

------------------- Sentence 1 -------------------

multiple features.

>> Tokens are: 
 ['multiple', 'features', '.']

>> Bigrams are: 
 [('multiple', 'features'), ('features', '.')]

>> Trigrams are: 
 [('multiple', 'features', '.')]

>> POS Tags are: 
 [('multiple', 'JJ'), ('features', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['multiple features']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('multiple', 'multipl'), ('features', 'featur'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('multiple', 'multipl'), ('features', 'featur'), ('.', '.')]

>> Lemmatization: 
 [('multiple', 'multiple'), ('features', 'feature'), ('.', '.')]


------------------- Sentence 2 -------------------

Ultimately this makes it difficult for them to

>> Tokens are: 
 ['Ultimately', 'makes', 'difficult']

>> Bigrams are: 
 [('Ultimately', 'makes'), ('makes', 'difficult')]

>> Trigrams are: 
 [('Ultimately', 'makes', 'difficult')]

>> POS Tags are: 
 [('Ultimately', 'RB'), ('makes', 'VBZ'), ('difficult', 'JJ')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Ultimately', 'ultim'), ('makes', 'make'), ('difficult', 'difficult')]

>> Stemming using Snowball Stemmer: 
 [('Ultimately', 'ultim'), ('makes', 'make'), ('difficult', 'difficult')]

>> Lemmatization: 
 [('Ultimately', 'Ultimately'), ('makes', 'make'), ('difficult', 'difficult')]



========================================== PARAGRAPH 57 ===========================================

explore solutions to certain problems. Machine learning can  

------------------- Sentence 1 -------------------

explore solutions to certain problems.

>> Tokens are: 
 ['explore', 'solutions', 'certain', 'problems', '.']

>> Bigrams are: 
 [('explore', 'solutions'), ('solutions', 'certain'), ('certain', 'problems'), ('problems', '.')]

>> Trigrams are: 
 [('explore', 'solutions', 'certain'), ('solutions', 'certain', 'problems'), ('certain', 'problems', '.')]

>> POS Tags are: 
 [('explore', 'IN'), ('solutions', 'NNS'), ('certain', 'JJ'), ('problems', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['solutions', 'certain problems']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('explore', 'explor'), ('solutions', 'solut'), ('certain', 'certain'), ('problems', 'problem'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('explore', 'explor'), ('solutions', 'solut'), ('certain', 'certain'), ('problems', 'problem'), ('.', '.')]

>> Lemmatization: 
 [('explore', 'explore'), ('solutions', 'solution'), ('certain', 'certain'), ('problems', 'problem'), ('.', '.')]


------------------- Sentence 2 -------------------

Machine learning can

>> Tokens are: 
 ['Machine', 'learning']

>> Bigrams are: 
 [('Machine', 'learning')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Machine', 'NN'), ('learning', 'NN')]

>> Noun Phrases are: 
 ['Machine learning']

>> Named Entities are: 
 [('GPE', 'Machine')] 

>> Stemming using Porter Stemmer: 
 [('Machine', 'machin'), ('learning', 'learn')]

>> Stemming using Snowball Stemmer: 
 [('Machine', 'machin'), ('learning', 'learn')]

>> Lemmatization: 
 [('Machine', 'Machine'), ('learning', 'learning')]



========================================== PARAGRAPH 58 ===========================================

often be successfully applied to these problems, improving the  

------------------- Sentence 1 -------------------

often be successfully applied to these problems, improving the

>> Tokens are: 
 ['often', 'successfully', 'applied', 'problems', ',', 'improving']

>> Bigrams are: 
 [('often', 'successfully'), ('successfully', 'applied'), ('applied', 'problems'), ('problems', ','), (',', 'improving')]

>> Trigrams are: 
 [('often', 'successfully', 'applied'), ('successfully', 'applied', 'problems'), ('applied', 'problems', ','), ('problems', ',', 'improving')]

>> POS Tags are: 
 [('often', 'RB'), ('successfully', 'RB'), ('applied', 'VBN'), ('problems', 'NNS'), (',', ','), ('improving', 'VBG')]

>> Noun Phrases are: 
 ['problems']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('often', 'often'), ('successfully', 'success'), ('applied', 'appli'), ('problems', 'problem'), (',', ','), ('improving', 'improv')]

>> Stemming using Snowball Stemmer: 
 [('often', 'often'), ('successfully', 'success'), ('applied', 'appli'), ('problems', 'problem'), (',', ','), ('improving', 'improv')]

>> Lemmatization: 
 [('often', 'often'), ('successfully', 'successfully'), ('applied', 'applied'), ('problems', 'problem'), (',', ','), ('improving', 'improving')]



========================================== PARAGRAPH 59 ===========================================

efficiency of systems and the designs of machines [1]. In  

------------------- Sentence 1 -------------------

efficiency of systems and the designs of machines [1].

>> Tokens are: 
 ['efficiency', 'systems', 'designs', 'machines', '[', '1', ']', '.']

>> Bigrams are: 
 [('efficiency', 'systems'), ('systems', 'designs'), ('designs', 'machines'), ('machines', '['), ('[', '1'), ('1', ']'), (']', '.')]

>> Trigrams are: 
 [('efficiency', 'systems', 'designs'), ('systems', 'designs', 'machines'), ('designs', 'machines', '['), ('machines', '[', '1'), ('[', '1', ']'), ('1', ']', '.')]

>> POS Tags are: 
 [('efficiency', 'NN'), ('systems', 'NNS'), ('designs', 'VBZ'), ('machines', 'NNS'), ('[', '$'), ('1', 'CD'), (']', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['efficiency systems', 'machines', ']']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('efficiency', 'effici'), ('systems', 'system'), ('designs', 'design'), ('machines', 'machin'), ('[', '['), ('1', '1'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('efficiency', 'effici'), ('systems', 'system'), ('designs', 'design'), ('machines', 'machin'), ('[', '['), ('1', '1'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('efficiency', 'efficiency'), ('systems', 'system'), ('designs', 'design'), ('machines', 'machine'), ('[', '['), ('1', '1'), (']', ']'), ('.', '.')]


------------------- Sentence 2 -------------------

In

>> Tokens are: 
 ['In']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('In', 'IN')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('In', 'in')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in')]

>> Lemmatization: 
 [('In', 'In')]



========================================== PARAGRAPH 60 ===========================================

machine learning algorithms every instance of particular dataset  

------------------- Sentence 1 -------------------

machine learning algorithms every instance of particular dataset

>> Tokens are: 
 ['machine', 'learning', 'algorithms', 'every', 'instance', 'particular', 'dataset']

>> Bigrams are: 
 [('machine', 'learning'), ('learning', 'algorithms'), ('algorithms', 'every'), ('every', 'instance'), ('instance', 'particular'), ('particular', 'dataset')]

>> Trigrams are: 
 [('machine', 'learning', 'algorithms'), ('learning', 'algorithms', 'every'), ('algorithms', 'every', 'instance'), ('every', 'instance', 'particular'), ('instance', 'particular', 'dataset')]

>> POS Tags are: 
 [('machine', 'NN'), ('learning', 'VBG'), ('algorithms', 'JJ'), ('every', 'DT'), ('instance', 'NN'), ('particular', 'JJ'), ('dataset', 'NN')]

>> Noun Phrases are: 
 ['machine', 'every instance', 'particular dataset']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('machine', 'machin'), ('learning', 'learn'), ('algorithms', 'algorithm'), ('every', 'everi'), ('instance', 'instanc'), ('particular', 'particular'), ('dataset', 'dataset')]

>> Stemming using Snowball Stemmer: 
 [('machine', 'machin'), ('learning', 'learn'), ('algorithms', 'algorithm'), ('every', 'everi'), ('instance', 'instanc'), ('particular', 'particular'), ('dataset', 'dataset')]

>> Lemmatization: 
 [('machine', 'machine'), ('learning', 'learning'), ('algorithms', 'algorithm'), ('every', 'every'), ('instance', 'instance'), ('particular', 'particular'), ('dataset', 'dataset')]



========================================== PARAGRAPH 61 ===========================================

is represented by using the same set of features. The nature of  

------------------- Sentence 1 -------------------

is represented by using the same set of features.

>> Tokens are: 
 ['represented', 'using', 'set', 'features', '.']

>> Bigrams are: 
 [('represented', 'using'), ('using', 'set'), ('set', 'features'), ('features', '.')]

>> Trigrams are: 
 [('represented', 'using', 'set'), ('using', 'set', 'features'), ('set', 'features', '.')]

>> POS Tags are: 
 [('represented', 'VBN'), ('using', 'VBG'), ('set', 'NN'), ('features', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['set features']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('represented', 'repres'), ('using', 'use'), ('set', 'set'), ('features', 'featur'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('represented', 'repres'), ('using', 'use'), ('set', 'set'), ('features', 'featur'), ('.', '.')]

>> Lemmatization: 
 [('represented', 'represented'), ('using', 'using'), ('set', 'set'), ('features', 'feature'), ('.', '.')]


------------------- Sentence 2 -------------------

The nature of

>> Tokens are: 
 ['The', 'nature']

>> Bigrams are: 
 [('The', 'nature')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('The', 'DT'), ('nature', 'NN')]

>> Noun Phrases are: 
 ['The nature']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('nature', 'natur')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('nature', 'natur')]

>> Lemmatization: 
 [('The', 'The'), ('nature', 'nature')]



========================================== PARAGRAPH 62 ===========================================

these features could be continuous, categorical or binary. If  

------------------- Sentence 1 -------------------

these features could be continuous, categorical or binary.

>> Tokens are: 
 ['features', 'could', 'continuous', ',', 'categorical', 'binary', '.']

>> Bigrams are: 
 [('features', 'could'), ('could', 'continuous'), ('continuous', ','), (',', 'categorical'), ('categorical', 'binary'), ('binary', '.')]

>> Trigrams are: 
 [('features', 'could', 'continuous'), ('could', 'continuous', ','), ('continuous', ',', 'categorical'), (',', 'categorical', 'binary'), ('categorical', 'binary', '.')]

>> POS Tags are: 
 [('features', 'NNS'), ('could', 'MD'), ('continuous', 'VB'), (',', ','), ('categorical', 'JJ'), ('binary', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['features', 'categorical binary']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('features', 'featur'), ('could', 'could'), ('continuous', 'continu'), (',', ','), ('categorical', 'categor'), ('binary', 'binari'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('features', 'featur'), ('could', 'could'), ('continuous', 'continu'), (',', ','), ('categorical', 'categor'), ('binary', 'binari'), ('.', '.')]

>> Lemmatization: 
 [('features', 'feature'), ('could', 'could'), ('continuous', 'continuous'), (',', ','), ('categorical', 'categorical'), ('binary', 'binary'), ('.', '.')]


------------------- Sentence 2 -------------------

If

>> Tokens are: 
 ['If']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('If', 'IN')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('If', 'if')]

>> Stemming using Snowball Stemmer: 
 [('If', 'if')]

>> Lemmatization: 
 [('If', 'If')]



========================================== PARAGRAPH 63 ===========================================

instances are given with known labels (i.e.- the corresponding  

------------------- Sentence 1 -------------------

instances are given with known labels (i.e.- the corresponding

>> Tokens are: 
 ['instances', 'given', 'known', 'labels', '(', 'i.e.-', 'corresponding']

>> Bigrams are: 
 [('instances', 'given'), ('given', 'known'), ('known', 'labels'), ('labels', '('), ('(', 'i.e.-'), ('i.e.-', 'corresponding')]

>> Trigrams are: 
 [('instances', 'given', 'known'), ('given', 'known', 'labels'), ('known', 'labels', '('), ('labels', '(', 'i.e.-'), ('(', 'i.e.-', 'corresponding')]

>> POS Tags are: 
 [('instances', 'NNS'), ('given', 'VBN'), ('known', 'VBN'), ('labels', 'NNS'), ('(', '('), ('i.e.-', 'JJ'), ('corresponding', 'NN')]

>> Noun Phrases are: 
 ['instances', 'labels', 'i.e.- corresponding']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('instances', 'instanc'), ('given', 'given'), ('known', 'known'), ('labels', 'label'), ('(', '('), ('i.e.-', 'i.e.-'), ('corresponding', 'correspond')]

>> Stemming using Snowball Stemmer: 
 [('instances', 'instanc'), ('given', 'given'), ('known', 'known'), ('labels', 'label'), ('(', '('), ('i.e.-', 'i.e.-'), ('corresponding', 'correspond')]

>> Lemmatization: 
 [('instances', 'instance'), ('given', 'given'), ('known', 'known'), ('labels', 'label'), ('(', '('), ('i.e.-', 'i.e.-'), ('corresponding', 'corresponding')]



========================================== PARAGRAPH 64 ===========================================

correct outputs) then the learning scheme is known as supervised  

------------------- Sentence 1 -------------------

correct outputs) then the learning scheme is known as supervised

>> Tokens are: 
 ['correct', 'outputs', ')', 'learning', 'scheme', 'known', 'supervised']

>> Bigrams are: 
 [('correct', 'outputs'), ('outputs', ')'), (')', 'learning'), ('learning', 'scheme'), ('scheme', 'known'), ('known', 'supervised')]

>> Trigrams are: 
 [('correct', 'outputs', ')'), ('outputs', ')', 'learning'), (')', 'learning', 'scheme'), ('learning', 'scheme', 'known'), ('scheme', 'known', 'supervised')]

>> POS Tags are: 
 [('correct', 'JJ'), ('outputs', 'NNS'), (')', ')'), ('learning', 'VBG'), ('scheme', 'JJ'), ('known', 'VBN'), ('supervised', 'VBD')]

>> Noun Phrases are: 
 ['correct outputs']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('correct', 'correct'), ('outputs', 'output'), (')', ')'), ('learning', 'learn'), ('scheme', 'scheme'), ('known', 'known'), ('supervised', 'supervis')]

>> Stemming using Snowball Stemmer: 
 [('correct', 'correct'), ('outputs', 'output'), (')', ')'), ('learning', 'learn'), ('scheme', 'scheme'), ('known', 'known'), ('supervised', 'supervis')]

>> Lemmatization: 
 [('correct', 'correct'), ('outputs', 'output'), (')', ')'), ('learning', 'learning'), ('scheme', 'scheme'), ('known', 'known'), ('supervised', 'supervised')]



========================================== PARAGRAPH 65 ===========================================

(see Table.1), while in unsupervised learning approach the  

------------------- Sentence 1 -------------------

(see Table.1), while in unsupervised learning approach the

>> Tokens are: 
 ['(', 'see', 'Table.1', ')', ',', 'unsupervised', 'learning', 'approach']

>> Bigrams are: 
 [('(', 'see'), ('see', 'Table.1'), ('Table.1', ')'), (')', ','), (',', 'unsupervised'), ('unsupervised', 'learning'), ('learning', 'approach')]

>> Trigrams are: 
 [('(', 'see', 'Table.1'), ('see', 'Table.1', ')'), ('Table.1', ')', ','), (')', ',', 'unsupervised'), (',', 'unsupervised', 'learning'), ('unsupervised', 'learning', 'approach')]

>> POS Tags are: 
 [('(', '('), ('see', 'VB'), ('Table.1', 'NNP'), (')', ')'), (',', ','), ('unsupervised', 'JJ'), ('learning', 'NN'), ('approach', 'NN')]

>> Noun Phrases are: 
 ['Table.1', 'unsupervised learning approach']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('see', 'see'), ('Table.1', 'table.1'), (')', ')'), (',', ','), ('unsupervised', 'unsupervis'), ('learning', 'learn'), ('approach', 'approach')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('see', 'see'), ('Table.1', 'table.1'), (')', ')'), (',', ','), ('unsupervised', 'unsupervis'), ('learning', 'learn'), ('approach', 'approach')]

>> Lemmatization: 
 [('(', '('), ('see', 'see'), ('Table.1', 'Table.1'), (')', ')'), (',', ','), ('unsupervised', 'unsupervised'), ('learning', 'learning'), ('approach', 'approach')]



========================================== PARAGRAPH 66 ===========================================

instances are unlabeled. Through applying these unsupervised  

------------------- Sentence 1 -------------------

instances are unlabeled.

>> Tokens are: 
 ['instances', 'unlabeled', '.']

>> Bigrams are: 
 [('instances', 'unlabeled'), ('unlabeled', '.')]

>> Trigrams are: 
 [('instances', 'unlabeled', '.')]

>> POS Tags are: 
 [('instances', 'NNS'), ('unlabeled', 'VBD'), ('.', '.')]

>> Noun Phrases are: 
 ['instances']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('instances', 'instanc'), ('unlabeled', 'unlabel'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('instances', 'instanc'), ('unlabeled', 'unlabel'), ('.', '.')]

>> Lemmatization: 
 [('instances', 'instance'), ('unlabeled', 'unlabeled'), ('.', '.')]


------------------- Sentence 2 -------------------

Through applying these unsupervised

>> Tokens are: 
 ['Through', 'applying', 'unsupervised']

>> Bigrams are: 
 [('Through', 'applying'), ('applying', 'unsupervised')]

>> Trigrams are: 
 [('Through', 'applying', 'unsupervised')]

>> POS Tags are: 
 [('Through', 'IN'), ('applying', 'VBG'), ('unsupervised', 'JJ')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Through', 'through'), ('applying', 'appli'), ('unsupervised', 'unsupervis')]

>> Stemming using Snowball Stemmer: 
 [('Through', 'through'), ('applying', 'appli'), ('unsupervised', 'unsupervis')]

>> Lemmatization: 
 [('Through', 'Through'), ('applying', 'applying'), ('unsupervised', 'unsupervised')]



========================================== PARAGRAPH 67 ===========================================

(clustering) algorithms, researchers are optimistic to discover  

------------------- Sentence 1 -------------------

(clustering) algorithms, researchers are optimistic to discover

>> Tokens are: 
 ['(', 'clustering', ')', 'algorithms', ',', 'researchers', 'optimistic', 'discover']

>> Bigrams are: 
 [('(', 'clustering'), ('clustering', ')'), (')', 'algorithms'), ('algorithms', ','), (',', 'researchers'), ('researchers', 'optimistic'), ('optimistic', 'discover')]

>> Trigrams are: 
 [('(', 'clustering', ')'), ('clustering', ')', 'algorithms'), (')', 'algorithms', ','), ('algorithms', ',', 'researchers'), (',', 'researchers', 'optimistic'), ('researchers', 'optimistic', 'discover')]

>> POS Tags are: 
 [('(', '('), ('clustering', 'VBG'), (')', ')'), ('algorithms', 'NN'), (',', ','), ('researchers', 'NNS'), ('optimistic', 'JJ'), ('discover', 'NN')]

>> Noun Phrases are: 
 ['algorithms', 'researchers', 'optimistic discover']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('clustering', 'cluster'), (')', ')'), ('algorithms', 'algorithm'), (',', ','), ('researchers', 'research'), ('optimistic', 'optimist'), ('discover', 'discov')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('clustering', 'cluster'), (')', ')'), ('algorithms', 'algorithm'), (',', ','), ('researchers', 'research'), ('optimistic', 'optimist'), ('discover', 'discov')]

>> Lemmatization: 
 [('(', '('), ('clustering', 'clustering'), (')', ')'), ('algorithms', 'algorithm'), (',', ','), ('researchers', 'researcher'), ('optimistic', 'optimistic'), ('discover', 'discover')]



========================================== PARAGRAPH 68 ===========================================

unknown, but useful, classes of items [3]. Another kind of  

------------------- Sentence 1 -------------------

unknown, but useful, classes of items [3].

>> Tokens are: 
 ['unknown', ',', 'useful', ',', 'classes', 'items', '[', '3', ']', '.']

>> Bigrams are: 
 [('unknown', ','), (',', 'useful'), ('useful', ','), (',', 'classes'), ('classes', 'items'), ('items', '['), ('[', '3'), ('3', ']'), (']', '.')]

>> Trigrams are: 
 [('unknown', ',', 'useful'), (',', 'useful', ','), ('useful', ',', 'classes'), (',', 'classes', 'items'), ('classes', 'items', '['), ('items', '[', '3'), ('[', '3', ']'), ('3', ']', '.')]

>> POS Tags are: 
 [('unknown', 'JJ'), (',', ','), ('useful', 'JJ'), (',', ','), ('classes', 'VBZ'), ('items', 'NNS'), ('[', '$'), ('3', 'CD'), (']', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['items', ']']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('unknown', 'unknown'), (',', ','), ('useful', 'use'), (',', ','), ('classes', 'class'), ('items', 'item'), ('[', '['), ('3', '3'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('unknown', 'unknown'), (',', ','), ('useful', 'use'), (',', ','), ('classes', 'class'), ('items', 'item'), ('[', '['), ('3', '3'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('unknown', 'unknown'), (',', ','), ('useful', 'useful'), (',', ','), ('classes', 'class'), ('items', 'item'), ('[', '['), ('3', '3'), (']', ']'), ('.', '.')]


------------------- Sentence 2 -------------------

Another kind of

>> Tokens are: 
 ['Another', 'kind']

>> Bigrams are: 
 [('Another', 'kind')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Another', 'DT'), ('kind', 'NN')]

>> Noun Phrases are: 
 ['Another kind']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Another', 'anoth'), ('kind', 'kind')]

>> Stemming using Snowball Stemmer: 
 [('Another', 'anoth'), ('kind', 'kind')]

>> Lemmatization: 
 [('Another', 'Another'), ('kind', 'kind')]



========================================== PARAGRAPH 69 ===========================================

machine learning is reinforcement learning. Here the training  

------------------- Sentence 1 -------------------

machine learning is reinforcement learning.

>> Tokens are: 
 ['machine', 'learning', 'reinforcement', 'learning', '.']

>> Bigrams are: 
 [('machine', 'learning'), ('learning', 'reinforcement'), ('reinforcement', 'learning'), ('learning', '.')]

>> Trigrams are: 
 [('machine', 'learning', 'reinforcement'), ('learning', 'reinforcement', 'learning'), ('reinforcement', 'learning', '.')]

>> POS Tags are: 
 [('machine', 'NN'), ('learning', 'VBG'), ('reinforcement', 'JJ'), ('learning', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['machine', 'reinforcement learning']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('machine', 'machin'), ('learning', 'learn'), ('reinforcement', 'reinforc'), ('learning', 'learn'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('machine', 'machin'), ('learning', 'learn'), ('reinforcement', 'reinforc'), ('learning', 'learn'), ('.', '.')]

>> Lemmatization: 
 [('machine', 'machine'), ('learning', 'learning'), ('reinforcement', 'reinforcement'), ('learning', 'learning'), ('.', '.')]


------------------- Sentence 2 -------------------

Here the training

>> Tokens are: 
 ['Here', 'training']

>> Bigrams are: 
 [('Here', 'training')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Here', 'RB'), ('training', 'VBG')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Here', 'here'), ('training', 'train')]

>> Stemming using Snowball Stemmer: 
 [('Here', 'here'), ('training', 'train')]

>> Lemmatization: 
 [('Here', 'Here'), ('training', 'training')]



========================================== PARAGRAPH 70 ===========================================

information provided to the learning system by the environment  

------------------- Sentence 1 -------------------

information provided to the learning system by the environment

>> Tokens are: 
 ['information', 'provided', 'learning', 'system', 'environment']

>> Bigrams are: 
 [('information', 'provided'), ('provided', 'learning'), ('learning', 'system'), ('system', 'environment')]

>> Trigrams are: 
 [('information', 'provided', 'learning'), ('provided', 'learning', 'system'), ('learning', 'system', 'environment')]

>> POS Tags are: 
 [('information', 'NN'), ('provided', 'VBD'), ('learning', 'NN'), ('system', 'NN'), ('environment', 'NN')]

>> Noun Phrases are: 
 ['information', 'learning system environment']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('information', 'inform'), ('provided', 'provid'), ('learning', 'learn'), ('system', 'system'), ('environment', 'environ')]

>> Stemming using Snowball Stemmer: 
 [('information', 'inform'), ('provided', 'provid'), ('learning', 'learn'), ('system', 'system'), ('environment', 'environ')]

>> Lemmatization: 
 [('information', 'information'), ('provided', 'provided'), ('learning', 'learning'), ('system', 'system'), ('environment', 'environment')]



========================================== PARAGRAPH 71 ===========================================

(i.e.- external trainer) is in the form of a scalar reinforcement  

------------------- Sentence 1 -------------------

(i.e.- external trainer) is in the form of a scalar reinforcement

>> Tokens are: 
 ['(', 'i.e.-', 'external', 'trainer', ')', 'form', 'scalar', 'reinforcement']

>> Bigrams are: 
 [('(', 'i.e.-'), ('i.e.-', 'external'), ('external', 'trainer'), ('trainer', ')'), (')', 'form'), ('form', 'scalar'), ('scalar', 'reinforcement')]

>> Trigrams are: 
 [('(', 'i.e.-', 'external'), ('i.e.-', 'external', 'trainer'), ('external', 'trainer', ')'), ('trainer', ')', 'form'), (')', 'form', 'scalar'), ('form', 'scalar', 'reinforcement')]

>> POS Tags are: 
 [('(', '('), ('i.e.-', 'JJ'), ('external', 'JJ'), ('trainer', 'NN'), (')', ')'), ('form', 'NN'), ('scalar', 'JJ'), ('reinforcement', 'NN')]

>> Noun Phrases are: 
 ['i.e.- external trainer', 'form', 'scalar reinforcement']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('i.e.-', 'i.e.-'), ('external', 'extern'), ('trainer', 'trainer'), (')', ')'), ('form', 'form'), ('scalar', 'scalar'), ('reinforcement', 'reinforc')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('i.e.-', 'i.e.-'), ('external', 'extern'), ('trainer', 'trainer'), (')', ')'), ('form', 'form'), ('scalar', 'scalar'), ('reinforcement', 'reinforc')]

>> Lemmatization: 
 [('(', '('), ('i.e.-', 'i.e.-'), ('external', 'external'), ('trainer', 'trainer'), (')', ')'), ('form', 'form'), ('scalar', 'scalar'), ('reinforcement', 'reinforcement')]



========================================== PARAGRAPH 72 ===========================================

signal that constitutes a measure of how well the system  

------------------- Sentence 1 -------------------

signal that constitutes a measure of how well the system

>> Tokens are: 
 ['signal', 'constitutes', 'measure', 'well', 'system']

>> Bigrams are: 
 [('signal', 'constitutes'), ('constitutes', 'measure'), ('measure', 'well'), ('well', 'system')]

>> Trigrams are: 
 [('signal', 'constitutes', 'measure'), ('constitutes', 'measure', 'well'), ('measure', 'well', 'system')]

>> POS Tags are: 
 [('signal', 'JJ'), ('constitutes', 'NNS'), ('measure', 'VBP'), ('well', 'RB'), ('system', 'NN')]

>> Noun Phrases are: 
 ['signal constitutes', 'system']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('signal', 'signal'), ('constitutes', 'constitut'), ('measure', 'measur'), ('well', 'well'), ('system', 'system')]

>> Stemming using Snowball Stemmer: 
 [('signal', 'signal'), ('constitutes', 'constitut'), ('measure', 'measur'), ('well', 'well'), ('system', 'system')]

>> Lemmatization: 
 [('signal', 'signal'), ('constitutes', 'constitutes'), ('measure', 'measure'), ('well', 'well'), ('system', 'system')]



========================================== PARAGRAPH 73 ===========================================

operates. The learner is not told which action has to take, as in  

------------------- Sentence 1 -------------------

operates.

>> Tokens are: 
 ['operates', '.']

>> Bigrams are: 
 [('operates', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('operates', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['operates']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('operates', 'oper'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('operates', 'oper'), ('.', '.')]

>> Lemmatization: 
 [('operates', 'operates'), ('.', '.')]


------------------- Sentence 2 -------------------

The learner is not told which action has to take, as in

>> Tokens are: 
 ['The', 'learner', 'told', 'action', 'take', ',']

>> Bigrams are: 
 [('The', 'learner'), ('learner', 'told'), ('told', 'action'), ('action', 'take'), ('take', ',')]

>> Trigrams are: 
 [('The', 'learner', 'told'), ('learner', 'told', 'action'), ('told', 'action', 'take'), ('action', 'take', ',')]

>> POS Tags are: 
 [('The', 'DT'), ('learner', 'NN'), ('told', 'VBD'), ('action', 'NN'), ('take', 'NN'), (',', ',')]

>> Noun Phrases are: 
 ['The learner', 'action take']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('learner', 'learner'), ('told', 'told'), ('action', 'action'), ('take', 'take'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('learner', 'learner'), ('told', 'told'), ('action', 'action'), ('take', 'take'), (',', ',')]

>> Lemmatization: 
 [('The', 'The'), ('learner', 'learner'), ('told', 'told'), ('action', 'action'), ('take', 'take'), (',', ',')]



========================================== PARAGRAPH 74 ===========================================

most forms of machine learning, but instead must discover  

------------------- Sentence 1 -------------------

most forms of machine learning, but instead must discover

>> Tokens are: 
 ['forms', 'machine', 'learning', ',', 'instead', 'must', 'discover']

>> Bigrams are: 
 [('forms', 'machine'), ('machine', 'learning'), ('learning', ','), (',', 'instead'), ('instead', 'must'), ('must', 'discover')]

>> Trigrams are: 
 [('forms', 'machine', 'learning'), ('machine', 'learning', ','), ('learning', ',', 'instead'), (',', 'instead', 'must'), ('instead', 'must', 'discover')]

>> POS Tags are: 
 [('forms', 'NNS'), ('machine', 'NN'), ('learning', 'NN'), (',', ','), ('instead', 'RB'), ('must', 'MD'), ('discover', 'VB')]

>> Noun Phrases are: 
 ['forms machine learning']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('forms', 'form'), ('machine', 'machin'), ('learning', 'learn'), (',', ','), ('instead', 'instead'), ('must', 'must'), ('discover', 'discov')]

>> Stemming using Snowball Stemmer: 
 [('forms', 'form'), ('machine', 'machin'), ('learning', 'learn'), (',', ','), ('instead', 'instead'), ('must', 'must'), ('discover', 'discov')]

>> Lemmatization: 
 [('forms', 'form'), ('machine', 'machine'), ('learning', 'learning'), (',', ','), ('instead', 'instead'), ('must', 'must'), ('discover', 'discover')]



========================================== PARAGRAPH 75 ===========================================

which actions yield the most reward by trying them [1]. A  

------------------- Sentence 1 -------------------

which actions yield the most reward by trying them [1].

>> Tokens are: 
 ['actions', 'yield', 'reward', 'trying', '[', '1', ']', '.']

>> Bigrams are: 
 [('actions', 'yield'), ('yield', 'reward'), ('reward', 'trying'), ('trying', '['), ('[', '1'), ('1', ']'), (']', '.')]

>> Trigrams are: 
 [('actions', 'yield', 'reward'), ('yield', 'reward', 'trying'), ('reward', 'trying', '['), ('trying', '[', '1'), ('[', '1', ']'), ('1', ']', '.')]

>> POS Tags are: 
 [('actions', 'NNS'), ('yield', 'VBP'), ('reward', 'RB'), ('trying', 'VBG'), ('[', 'PRP'), ('1', 'CD'), (']', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['actions', ']']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('actions', 'action'), ('yield', 'yield'), ('reward', 'reward'), ('trying', 'tri'), ('[', '['), ('1', '1'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('actions', 'action'), ('yield', 'yield'), ('reward', 'reward'), ('trying', 'tri'), ('[', '['), ('1', '1'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('actions', 'action'), ('yield', 'yield'), ('reward', 'reward'), ('trying', 'trying'), ('[', '['), ('1', '1'), (']', ']'), ('.', '.')]


------------------- Sentence 2 -------------------

A

>> Tokens are: 
 ['A']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('A', 'DT')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('A', 'a')]

>> Stemming using Snowball Stemmer: 
 [('A', 'a')]

>> Lemmatization: 
 [('A', 'A')]



========================================== PARAGRAPH 76 ===========================================

number of ML applications involve tasks that can be set up as  

------------------- Sentence 1 -------------------

number of ML applications involve tasks that can be set up as

>> Tokens are: 
 ['number', 'ML', 'applications', 'involve', 'tasks', 'set']

>> Bigrams are: 
 [('number', 'ML'), ('ML', 'applications'), ('applications', 'involve'), ('involve', 'tasks'), ('tasks', 'set')]

>> Trigrams are: 
 [('number', 'ML', 'applications'), ('ML', 'applications', 'involve'), ('applications', 'involve', 'tasks'), ('involve', 'tasks', 'set')]

>> POS Tags are: 
 [('number', 'NN'), ('ML', 'NNP'), ('applications', 'NNS'), ('involve', 'VBP'), ('tasks', 'NNS'), ('set', 'VBD')]

>> Noun Phrases are: 
 ['number ML applications', 'tasks']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('number', 'number'), ('ML', 'ml'), ('applications', 'applic'), ('involve', 'involv'), ('tasks', 'task'), ('set', 'set')]

>> Stemming using Snowball Stemmer: 
 [('number', 'number'), ('ML', 'ml'), ('applications', 'applic'), ('involve', 'involv'), ('tasks', 'task'), ('set', 'set')]

>> Lemmatization: 
 [('number', 'number'), ('ML', 'ML'), ('applications', 'application'), ('involve', 'involve'), ('tasks', 'task'), ('set', 'set')]



========================================== PARAGRAPH 77 ===========================================

supervised. The below figure depicts the general classification  

------------------- Sentence 1 -------------------

supervised.

>> Tokens are: 
 ['supervised', '.']

>> Bigrams are: 
 [('supervised', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('supervised', 'VBN'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('supervised', 'supervis'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('supervised', 'supervis'), ('.', '.')]

>> Lemmatization: 
 [('supervised', 'supervised'), ('.', '.')]


------------------- Sentence 2 -------------------

The below figure depicts the general classification

>> Tokens are: 
 ['The', 'figure', 'depicts', 'general', 'classification']

>> Bigrams are: 
 [('The', 'figure'), ('figure', 'depicts'), ('depicts', 'general'), ('general', 'classification')]

>> Trigrams are: 
 [('The', 'figure', 'depicts'), ('figure', 'depicts', 'general'), ('depicts', 'general', 'classification')]

>> POS Tags are: 
 [('The', 'DT'), ('figure', 'NN'), ('depicts', 'VBZ'), ('general', 'JJ'), ('classification', 'NN')]

>> Noun Phrases are: 
 ['The figure', 'general classification']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('figure', 'figur'), ('depicts', 'depict'), ('general', 'gener'), ('classification', 'classif')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('figure', 'figur'), ('depicts', 'depict'), ('general', 'general'), ('classification', 'classif')]

>> Lemmatization: 
 [('The', 'The'), ('figure', 'figure'), ('depicts', 'depicts'), ('general', 'general'), ('classification', 'classification')]



========================================== PARAGRAPH 78 ===========================================

architecture.  

------------------- Sentence 1 -------------------

architecture.

>> Tokens are: 
 ['architecture', '.']

>> Bigrams are: 
 [('architecture', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('architecture', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['architecture']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('architecture', 'architectur'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('architecture', 'architectur'), ('.', '.')]

>> Lemmatization: 
 [('architecture', 'architecture'), ('.', '.')]



========================================== PARAGRAPH 79 ===========================================

Fig.1. Classification Architecture  

------------------- Sentence 1 -------------------

Fig.1.

>> Tokens are: 
 ['Fig.1', '.']

>> Bigrams are: 
 [('Fig.1', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Fig.1', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Fig.1']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Fig.1', 'fig.1'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Fig.1', 'fig.1'), ('.', '.')]

>> Lemmatization: 
 [('Fig.1', 'Fig.1'), ('.', '.')]


------------------- Sentence 2 -------------------

Classification Architecture

>> Tokens are: 
 ['Classification', 'Architecture']

>> Bigrams are: 
 [('Classification', 'Architecture')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Classification', 'NN'), ('Architecture', 'NN')]

>> Noun Phrases are: 
 ['Classification Architecture']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Classification', 'classif'), ('Architecture', 'architectur')]

>> Stemming using Snowball Stemmer: 
 [('Classification', 'classif'), ('Architecture', 'architectur')]

>> Lemmatization: 
 [('Classification', 'Classification'), ('Architecture', 'Architecture')]



========================================== PARAGRAPH 80 ===========================================

In this study, we will focus our attention on the methods  

------------------- Sentence 1 -------------------

In this study, we will focus our attention on the methods

>> Tokens are: 
 ['In', 'study', ',', 'focus', 'attention', 'methods']

>> Bigrams are: 
 [('In', 'study'), ('study', ','), (',', 'focus'), ('focus', 'attention'), ('attention', 'methods')]

>> Trigrams are: 
 [('In', 'study', ','), ('study', ',', 'focus'), (',', 'focus', 'attention'), ('focus', 'attention', 'methods')]

>> POS Tags are: 
 [('In', 'IN'), ('study', 'NN'), (',', ','), ('focus', 'VB'), ('attention', 'NN'), ('methods', 'NNS')]

>> Noun Phrases are: 
 ['study', 'attention methods']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('study', 'studi'), (',', ','), ('focus', 'focu'), ('attention', 'attent'), ('methods', 'method')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('study', 'studi'), (',', ','), ('focus', 'focus'), ('attention', 'attent'), ('methods', 'method')]

>> Lemmatization: 
 [('In', 'In'), ('study', 'study'), (',', ','), ('focus', 'focus'), ('attention', 'attention'), ('methods', 'method')]



========================================== PARAGRAPH 81 ===========================================

which are being used for supervised learning. This study will  

------------------- Sentence 1 -------------------

which are being used for supervised learning.

>> Tokens are: 
 ['used', 'supervised', 'learning', '.']

>> Bigrams are: 
 [('used', 'supervised'), ('supervised', 'learning'), ('learning', '.')]

>> Trigrams are: 
 [('used', 'supervised', 'learning'), ('supervised', 'learning', '.')]

>> POS Tags are: 
 [('used', 'VBN'), ('supervised', 'VBD'), ('learning', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['learning']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('used', 'use'), ('supervised', 'supervis'), ('learning', 'learn'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('used', 'use'), ('supervised', 'supervis'), ('learning', 'learn'), ('.', '.')]

>> Lemmatization: 
 [('used', 'used'), ('supervised', 'supervised'), ('learning', 'learning'), ('.', '.')]


------------------- Sentence 2 -------------------

This study will

>> Tokens are: 
 ['This', 'study']

>> Bigrams are: 
 [('This', 'study')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('This', 'DT'), ('study', 'NN')]

>> Noun Phrases are: 
 ['This study']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('This', 'thi'), ('study', 'studi')]

>> Stemming using Snowball Stemmer: 
 [('This', 'this'), ('study', 'studi')]

>> Lemmatization: 
 [('This', 'This'), ('study', 'study')]



========================================== PARAGRAPH 82 ===========================================

contribute to new researchers for getting up-to-date knowledge  

------------------- Sentence 1 -------------------

contribute to new researchers for getting up-to-date knowledge

>> Tokens are: 
 ['contribute', 'new', 'researchers', 'getting', 'up-to-date', 'knowledge']

>> Bigrams are: 
 [('contribute', 'new'), ('new', 'researchers'), ('researchers', 'getting'), ('getting', 'up-to-date'), ('up-to-date', 'knowledge')]

>> Trigrams are: 
 [('contribute', 'new', 'researchers'), ('new', 'researchers', 'getting'), ('researchers', 'getting', 'up-to-date'), ('getting', 'up-to-date', 'knowledge')]

>> POS Tags are: 
 [('contribute', 'VB'), ('new', 'JJ'), ('researchers', 'NNS'), ('getting', 'VBG'), ('up-to-date', 'JJ'), ('knowledge', 'NN')]

>> Noun Phrases are: 
 ['new researchers', 'up-to-date knowledge']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('contribute', 'contribut'), ('new', 'new'), ('researchers', 'research'), ('getting', 'get'), ('up-to-date', 'up-to-d'), ('knowledge', 'knowledg')]

>> Stemming using Snowball Stemmer: 
 [('contribute', 'contribut'), ('new', 'new'), ('researchers', 'research'), ('getting', 'get'), ('up-to-date', 'up-to-d'), ('knowledge', 'knowledg')]

>> Lemmatization: 
 [('contribute', 'contribute'), ('new', 'new'), ('researchers', 'researcher'), ('getting', 'getting'), ('up-to-date', 'up-to-date'), ('knowledge', 'knowledge')]



========================================== PARAGRAPH 83 ===========================================

about supervised ML approaches.  

------------------- Sentence 1 -------------------

about supervised ML approaches.

>> Tokens are: 
 ['supervised', 'ML', 'approaches', '.']

>> Bigrams are: 
 [('supervised', 'ML'), ('ML', 'approaches'), ('approaches', '.')]

>> Trigrams are: 
 [('supervised', 'ML', 'approaches'), ('ML', 'approaches', '.')]

>> POS Tags are: 
 [('supervised', 'VBN'), ('ML', 'NNP'), ('approaches', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['ML approaches']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('supervised', 'supervis'), ('ML', 'ml'), ('approaches', 'approach'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('supervised', 'supervis'), ('ML', 'ml'), ('approaches', 'approach'), ('.', '.')]

>> Lemmatization: 
 [('supervised', 'supervised'), ('ML', 'ML'), ('approaches', 'approach'), ('.', '.')]



========================================== PARAGRAPH 84 ===========================================

Table.1. Instances with known labels  

------------------- Sentence 1 -------------------

Table.1.

>> Tokens are: 
 ['Table.1', '.']

>> Bigrams are: 
 [('Table.1', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Table.1', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Table.1']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Table.1', 'table.1'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Table.1', 'table.1'), ('.', '.')]

>> Lemmatization: 
 [('Table.1', 'Table.1'), ('.', '.')]


------------------- Sentence 2 -------------------

Instances with known labels

>> Tokens are: 
 ['Instances', 'known', 'labels']

>> Bigrams are: 
 [('Instances', 'known'), ('known', 'labels')]

>> Trigrams are: 
 [('Instances', 'known', 'labels')]

>> POS Tags are: 
 [('Instances', 'NNS'), ('known', 'VBN'), ('labels', 'NNS')]

>> Noun Phrases are: 
 ['Instances', 'labels']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Instances', 'instanc'), ('known', 'known'), ('labels', 'label')]

>> Stemming using Snowball Stemmer: 
 [('Instances', 'instanc'), ('known', 'known'), ('labels', 'label')]

>> Lemmatization: 
 [('Instances', 'Instances'), ('known', 'known'), ('labels', 'label')]



========================================== PARAGRAPH 85 ===========================================

Data in standard Format  

------------------- Sentence 1 -------------------

Data in standard Format

>> Tokens are: 
 ['Data', 'standard', 'Format']

>> Bigrams are: 
 [('Data', 'standard'), ('standard', 'Format')]

>> Trigrams are: 
 [('Data', 'standard', 'Format')]

>> POS Tags are: 
 [('Data', 'NNP'), ('standard', 'NN'), ('Format', 'NNP')]

>> Noun Phrases are: 
 ['Data standard Format']

>> Named Entities are: 
 [('GPE', 'Data')] 

>> Stemming using Porter Stemmer: 
 [('Data', 'data'), ('standard', 'standard'), ('Format', 'format')]

>> Stemming using Snowball Stemmer: 
 [('Data', 'data'), ('standard', 'standard'), ('Format', 'format')]

>> Lemmatization: 
 [('Data', 'Data'), ('standard', 'standard'), ('Format', 'Format')]



========================================== PARAGRAPH 86 ===========================================

Case Feature 1 Feature 2  Feature n Class  

------------------- Sentence 1 -------------------

Case Feature 1 Feature 2  Feature n Class

>> Tokens are: 
 ['Case', 'Feature', '1', 'Feature', '2', '', 'Feature', 'n', 'Class']

>> Bigrams are: 
 [('Case', 'Feature'), ('Feature', '1'), ('1', 'Feature'), ('Feature', '2'), ('2', ''), ('', 'Feature'), ('Feature', 'n'), ('n', 'Class')]

>> Trigrams are: 
 [('Case', 'Feature', '1'), ('Feature', '1', 'Feature'), ('1', 'Feature', '2'), ('Feature', '2', ''), ('2', '', 'Feature'), ('', 'Feature', 'n'), ('Feature', 'n', 'Class')]

>> POS Tags are: 
 [('Case', 'NNP'), ('Feature', 'NNP'), ('1', 'CD'), ('Feature', 'NNP'), ('2', 'CD'), ('', 'NNP'), ('Feature', 'NNP'), ('n', 'JJ'), ('Class', 'NN')]

>> Noun Phrases are: 
 ['Case Feature', 'Feature', ' Feature', 'n Class']

>> Named Entities are: 
 [('PERSON', 'Case')] 

>> Stemming using Porter Stemmer: 
 [('Case', 'case'), ('Feature', 'featur'), ('1', '1'), ('Feature', 'featur'), ('2', '2'), ('', ''), ('Feature', 'featur'), ('n', 'n'), ('Class', 'class')]

>> Stemming using Snowball Stemmer: 
 [('Case', 'case'), ('Feature', 'featur'), ('1', '1'), ('Feature', 'featur'), ('2', '2'), ('', ''), ('Feature', 'featur'), ('n', 'n'), ('Class', 'class')]

>> Lemmatization: 
 [('Case', 'Case'), ('Feature', 'Feature'), ('1', '1'), ('Feature', 'Feature'), ('2', '2'), ('', ''), ('Feature', 'Feature'), ('n', 'n'), ('Class', 'Class')]



========================================== PARAGRAPH 87 ===========================================

1 aaa bbb  nnn Yes  

------------------- Sentence 1 -------------------

1 aaa bbb  nnn Yes

>> Tokens are: 
 ['1', 'aaa', 'bbb', '', 'nnn', 'Yes']

>> Bigrams are: 
 [('1', 'aaa'), ('aaa', 'bbb'), ('bbb', ''), ('', 'nnn'), ('nnn', 'Yes')]

>> Trigrams are: 
 [('1', 'aaa', 'bbb'), ('aaa', 'bbb', ''), ('bbb', '', 'nnn'), ('', 'nnn', 'Yes')]

>> POS Tags are: 
 [('1', 'CD'), ('aaa', 'JJ'), ('bbb', 'NN'), ('', 'NNP'), ('nnn', 'VBZ'), ('Yes', 'UH')]

>> Noun Phrases are: 
 ['aaa bbb ']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('1', '1'), ('aaa', 'aaa'), ('bbb', 'bbb'), ('', ''), ('nnn', 'nnn'), ('Yes', 'ye')]

>> Stemming using Snowball Stemmer: 
 [('1', '1'), ('aaa', 'aaa'), ('bbb', 'bbb'), ('', ''), ('nnn', 'nnn'), ('Yes', 'yes')]

>> Lemmatization: 
 [('1', '1'), ('aaa', 'aaa'), ('bbb', 'bbb'), ('', ''), ('nnn', 'nnn'), ('Yes', 'Yes')]



========================================== PARAGRAPH 88 ===========================================

2 aaa bbb  nnn Yes  

------------------- Sentence 1 -------------------

2 aaa bbb  nnn Yes

>> Tokens are: 
 ['2', 'aaa', 'bbb', '', 'nnn', 'Yes']

>> Bigrams are: 
 [('2', 'aaa'), ('aaa', 'bbb'), ('bbb', ''), ('', 'nnn'), ('nnn', 'Yes')]

>> Trigrams are: 
 [('2', 'aaa', 'bbb'), ('aaa', 'bbb', ''), ('bbb', '', 'nnn'), ('', 'nnn', 'Yes')]

>> POS Tags are: 
 [('2', 'CD'), ('aaa', 'JJ'), ('bbb', 'NN'), ('', 'NNP'), ('nnn', 'VBZ'), ('Yes', 'UH')]

>> Noun Phrases are: 
 ['aaa bbb ']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('2', '2'), ('aaa', 'aaa'), ('bbb', 'bbb'), ('', ''), ('nnn', 'nnn'), ('Yes', 'ye')]

>> Stemming using Snowball Stemmer: 
 [('2', '2'), ('aaa', 'aaa'), ('bbb', 'bbb'), ('', ''), ('nnn', 'nnn'), ('Yes', 'yes')]

>> Lemmatization: 
 [('2', '2'), ('aaa', 'aaa'), ('bbb', 'bbb'), ('', ''), ('nnn', 'nnn'), ('Yes', 'Yes')]



========================================== PARAGRAPH 89 ===========================================

3 aaa bbb  nnn No  

------------------- Sentence 1 -------------------

3 aaa bbb  nnn No

>> Tokens are: 
 ['3', 'aaa', 'bbb', '', 'nnn', 'No']

>> Bigrams are: 
 [('3', 'aaa'), ('aaa', 'bbb'), ('bbb', ''), ('', 'nnn'), ('nnn', 'No')]

>> Trigrams are: 
 [('3', 'aaa', 'bbb'), ('aaa', 'bbb', ''), ('bbb', '', 'nnn'), ('', 'nnn', 'No')]

>> POS Tags are: 
 [('3', 'CD'), ('aaa', 'JJ'), ('bbb', 'NN'), ('', 'NNP'), ('nnn', 'VBZ'), ('No', 'DT')]

>> Noun Phrases are: 
 ['aaa bbb ']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('3', '3'), ('aaa', 'aaa'), ('bbb', 'bbb'), ('', ''), ('nnn', 'nnn'), ('No', 'no')]

>> Stemming using Snowball Stemmer: 
 [('3', '3'), ('aaa', 'aaa'), ('bbb', 'bbb'), ('', ''), ('nnn', 'nnn'), ('No', 'no')]

>> Lemmatization: 
 [('3', '3'), ('aaa', 'aaa'), ('bbb', 'bbb'), ('', ''), ('nnn', 'nnn'), ('No', 'No')]



========================================== PARAGRAPH 90 ===========================================

       

------------------- Sentence 1 -------------------

     

>> Tokens are: 
 ['', '', '', '', '', '']

>> Bigrams are: 
 [('', ''), ('', ''), ('', ''), ('', ''), ('', '')]

>> Trigrams are: 
 [('', '', ''), ('', '', ''), ('', '', ''), ('', '', '')]

>> POS Tags are: 
 [('', 'JJ'), ('', 'NNP'), ('', 'NNP'), ('', 'NNP'), ('', 'NNP'), ('', 'NN')]

>> Noun Phrases are: 
 ['     ']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('', ''), ('', ''), ('', ''), ('', ''), ('', ''), ('', '')]

>> Stemming using Snowball Stemmer: 
 [('', ''), ('', ''), ('', ''), ('', ''), ('', ''), ('', '')]

>> Lemmatization: 
 [('', ''), ('', ''), ('', ''), ('', ''), ('', ''), ('', '')]



========================================== PARAGRAPH 91 ===========================================

In this work we have limited our references to refereed  

------------------- Sentence 1 -------------------

In this work we have limited our references to refereed

>> Tokens are: 
 ['In', 'work', 'limited', 'references', 'refereed']

>> Bigrams are: 
 [('In', 'work'), ('work', 'limited'), ('limited', 'references'), ('references', 'refereed')]

>> Trigrams are: 
 [('In', 'work', 'limited'), ('work', 'limited', 'references'), ('limited', 'references', 'refereed')]

>> POS Tags are: 
 [('In', 'IN'), ('work', 'NN'), ('limited', 'JJ'), ('references', 'NNS'), ('refereed', 'VBP')]

>> Noun Phrases are: 
 ['work', 'limited references']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('work', 'work'), ('limited', 'limit'), ('references', 'refer'), ('refereed', 'refere')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('work', 'work'), ('limited', 'limit'), ('references', 'refer'), ('refereed', 'refere')]

>> Lemmatization: 
 [('In', 'In'), ('work', 'work'), ('limited', 'limited'), ('references', 'reference'), ('refereed', 'refereed')]



========================================== PARAGRAPH 92 ===========================================

journals, published books, web data and conferences. Our major  

------------------- Sentence 1 -------------------

journals, published books, web data and conferences.

>> Tokens are: 
 ['journals', ',', 'published', 'books', ',', 'web', 'data', 'conferences', '.']

>> Bigrams are: 
 [('journals', ','), (',', 'published'), ('published', 'books'), ('books', ','), (',', 'web'), ('web', 'data'), ('data', 'conferences'), ('conferences', '.')]

>> Trigrams are: 
 [('journals', ',', 'published'), (',', 'published', 'books'), ('published', 'books', ','), ('books', ',', 'web'), (',', 'web', 'data'), ('web', 'data', 'conferences'), ('data', 'conferences', '.')]

>> POS Tags are: 
 [('journals', 'NNS'), (',', ','), ('published', 'VBN'), ('books', 'NNS'), (',', ','), ('web', 'NN'), ('data', 'NNS'), ('conferences', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['journals', 'books', 'web data conferences']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('journals', 'journal'), (',', ','), ('published', 'publish'), ('books', 'book'), (',', ','), ('web', 'web'), ('data', 'data'), ('conferences', 'confer'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('journals', 'journal'), (',', ','), ('published', 'publish'), ('books', 'book'), (',', ','), ('web', 'web'), ('data', 'data'), ('conferences', 'confer'), ('.', '.')]

>> Lemmatization: 
 [('journals', 'journal'), (',', ','), ('published', 'published'), ('books', 'book'), (',', ','), ('web', 'web'), ('data', 'data'), ('conferences', 'conference'), ('.', '.')]


------------------- Sentence 2 -------------------

Our major

>> Tokens are: 
 ['Our', 'major']

>> Bigrams are: 
 [('Our', 'major')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Our', 'PRP$'), ('major', 'JJ')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Our', 'our'), ('major', 'major')]

>> Stemming using Snowball Stemmer: 
 [('Our', 'our'), ('major', 'major')]

>> Lemmatization: 
 [('Our', 'Our'), ('major', 'major')]



========================================== PARAGRAPH 93 ===========================================

goal for this work has been to provide a representative sample of  

------------------- Sentence 1 -------------------

goal for this work has been to provide a representative sample of

>> Tokens are: 
 ['goal', 'work', 'provide', 'representative', 'sample']

>> Bigrams are: 
 [('goal', 'work'), ('work', 'provide'), ('provide', 'representative'), ('representative', 'sample')]

>> Trigrams are: 
 [('goal', 'work', 'provide'), ('work', 'provide', 'representative'), ('provide', 'representative', 'sample')]

>> POS Tags are: 
 [('goal', 'NN'), ('work', 'NN'), ('provide', 'RB'), ('representative', 'JJ'), ('sample', 'NN')]

>> Noun Phrases are: 
 ['goal work', 'representative sample']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('goal', 'goal'), ('work', 'work'), ('provide', 'provid'), ('representative', 'repres'), ('sample', 'sampl')]

>> Stemming using Snowball Stemmer: 
 [('goal', 'goal'), ('work', 'work'), ('provide', 'provid'), ('representative', 'repres'), ('sample', 'sampl')]

>> Lemmatization: 
 [('goal', 'goal'), ('work', 'work'), ('provide', 'provide'), ('representative', 'representative'), ('sample', 'sample')]



========================================== PARAGRAPH 94 ===========================================

Training  

------------------- Sentence 1 -------------------

Training

>> Tokens are: 
 ['Training']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Training', 'NN')]

>> Noun Phrases are: 
 ['Training']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Training', 'train')]

>> Stemming using Snowball Stemmer: 
 [('Training', 'train')]

>> Lemmatization: 
 [('Training', 'Training')]



========================================== PARAGRAPH 95 ===========================================

Data  

------------------- Sentence 1 -------------------

Data

>> Tokens are: 
 ['Data']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Data', 'NNS')]

>> Noun Phrases are: 
 ['Data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Data', 'data')]

>> Stemming using Snowball Stemmer: 
 [('Data', 'data')]

>> Lemmatization: 
 [('Data', 'Data')]



========================================== PARAGRAPH 96 ===========================================

Machine  

------------------- Sentence 1 -------------------

Machine

>> Tokens are: 
 ['Machine']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Machine', 'NN')]

>> Noun Phrases are: 
 ['Machine']

>> Named Entities are: 
 [('GPE', 'Machine')] 

>> Stemming using Porter Stemmer: 
 [('Machine', 'machin')]

>> Stemming using Snowball Stemmer: 
 [('Machine', 'machin')]

>> Lemmatization: 
 [('Machine', 'Machine')]



========================================== PARAGRAPH 97 ===========================================

Learning  

------------------- Sentence 1 -------------------

Learning

>> Tokens are: 
 ['Learning']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Learning', 'VBG')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Learning', 'learn')]

>> Stemming using Snowball Stemmer: 
 [('Learning', 'learn')]

>> Lemmatization: 
 [('Learning', 'Learning')]



========================================== PARAGRAPH 98 ===========================================

Program  

------------------- Sentence 1 -------------------

Program

>> Tokens are: 
 ['Program']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Program', 'NN')]

>> Noun Phrases are: 
 ['Program']

>> Named Entities are: 
 [('GPE', 'Program')] 

>> Stemming using Porter Stemmer: 
 [('Program', 'program')]

>> Stemming using Snowball Stemmer: 
 [('Program', 'program')]

>> Lemmatization: 
 [('Program', 'Program')]



========================================== PARAGRAPH 99 ===========================================

Classification  

------------------- Sentence 1 -------------------

Classification

>> Tokens are: 
 ['Classification']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Classification', 'NN')]

>> Noun Phrases are: 
 ['Classification']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Classification', 'classif')]

>> Stemming using Snowball Stemmer: 
 [('Classification', 'classif')]

>> Lemmatization: 
 [('Classification', 'Classification')]



========================================== PARAGRAPH 100 ===========================================

Rules  

------------------- Sentence 1 -------------------

Rules

>> Tokens are: 
 ['Rules']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Rules', 'NNS')]

>> Noun Phrases are: 
 ['Rules']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Rules', 'rule')]

>> Stemming using Snowball Stemmer: 
 [('Rules', 'rule')]

>> Lemmatization: 
 [('Rules', 'Rules')]



========================================== PARAGRAPH 101 ===========================================

Predicted  

------------------- Sentence 1 -------------------

Predicted

>> Tokens are: 
 ['Predicted']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Predicted', 'VBD')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Predicted', 'predict')]

>> Stemming using Snowball Stemmer: 
 [('Predicted', 'predict')]

>> Lemmatization: 
 [('Predicted', 'Predicted')]



========================================== PARAGRAPH 102 ===========================================

Classification  

------------------- Sentence 1 -------------------

Classification

>> Tokens are: 
 ['Classification']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Classification', 'NN')]

>> Noun Phrases are: 
 ['Classification']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Classification', 'classif')]

>> Stemming using Snowball Stemmer: 
 [('Classification', 'classif')]

>> Lemmatization: 
 [('Classification', 'Classification')]



========================================== PARAGRAPH 103 ===========================================

Testing Data 

------------------- Sentence 1 -------------------

Testing Data

>> Tokens are: 
 ['Testing', 'Data']

>> Bigrams are: 
 [('Testing', 'Data')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Testing', 'VBG'), ('Data', 'NNS')]

>> Noun Phrases are: 
 ['Data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Testing', 'test'), ('Data', 'data')]

>> Stemming using Snowball Stemmer: 
 [('Testing', 'test'), ('Data', 'data')]

>> Lemmatization: 
 [('Testing', 'Testing'), ('Data', 'Data')]



========================================== PARAGRAPH 104 ===========================================

ISSN: 2229-6956(ONLINE)                                                                                                                             ICTACT JOURNAL ON SOFT COMPUTING, APRIL 2015, VOLUME: 05, ISSUE: 03  

------------------- Sentence 1 -------------------

ISSN: 2229-6956(ONLINE)                                                                                                                             ICTACT JOURNAL ON SOFT COMPUTING, APRIL 2015, VOLUME: 05, ISSUE: 03

>> Tokens are: 
 ['ISSN', ':', '2229-6956', '(', 'ONLINE', ')', 'ICTACT', 'JOURNAL', 'ON', 'SOFT', 'COMPUTING', ',', 'APRIL', '2015', ',', 'VOLUME', ':', '05', ',', 'ISSUE', ':', '03']

>> Bigrams are: 
 [('ISSN', ':'), (':', '2229-6956'), ('2229-6956', '('), ('(', 'ONLINE'), ('ONLINE', ')'), (')', 'ICTACT'), ('ICTACT', 'JOURNAL'), ('JOURNAL', 'ON'), ('ON', 'SOFT'), ('SOFT', 'COMPUTING'), ('COMPUTING', ','), (',', 'APRIL'), ('APRIL', '2015'), ('2015', ','), (',', 'VOLUME'), ('VOLUME', ':'), (':', '05'), ('05', ','), (',', 'ISSUE'), ('ISSUE', ':'), (':', '03')]

>> Trigrams are: 
 [('ISSN', ':', '2229-6956'), (':', '2229-6956', '('), ('2229-6956', '(', 'ONLINE'), ('(', 'ONLINE', ')'), ('ONLINE', ')', 'ICTACT'), (')', 'ICTACT', 'JOURNAL'), ('ICTACT', 'JOURNAL', 'ON'), ('JOURNAL', 'ON', 'SOFT'), ('ON', 'SOFT', 'COMPUTING'), ('SOFT', 'COMPUTING', ','), ('COMPUTING', ',', 'APRIL'), (',', 'APRIL', '2015'), ('APRIL', '2015', ','), ('2015', ',', 'VOLUME'), (',', 'VOLUME', ':'), ('VOLUME', ':', '05'), (':', '05', ','), ('05', ',', 'ISSUE'), (',', 'ISSUE', ':'), ('ISSUE', ':', '03')]

>> POS Tags are: 
 [('ISSN', 'NN'), (':', ':'), ('2229-6956', 'JJ'), ('(', '('), ('ONLINE', 'NNP'), (')', ')'), ('ICTACT', 'NNP'), ('JOURNAL', 'NNP'), ('ON', 'NNP'), ('SOFT', 'NNP'), ('COMPUTING', 'NNP'), (',', ','), ('APRIL', 'NNP'), ('2015', 'CD'), (',', ','), ('VOLUME', 'NNP'), (':', ':'), ('05', 'CD'), (',', ','), ('ISSUE', 'NNP'), (':', ':'), ('03', 'CD')]

>> Noun Phrases are: 
 ['ISSN', 'ONLINE', 'ICTACT JOURNAL ON SOFT COMPUTING', 'APRIL', 'VOLUME', 'ISSUE']

>> Named Entities are: 
 [('ORGANIZATION', 'ONLINE'), ('ORGANIZATION', 'ICTACT'), ('ORGANIZATION', 'VOLUME'), ('ORGANIZATION', 'ISSUE')] 

>> Stemming using Porter Stemmer: 
 [('ISSN', 'issn'), (':', ':'), ('2229-6956', '2229-6956'), ('(', '('), ('ONLINE', 'onlin'), (')', ')'), ('ICTACT', 'ictact'), ('JOURNAL', 'journal'), ('ON', 'on'), ('SOFT', 'soft'), ('COMPUTING', 'comput'), (',', ','), ('APRIL', 'april'), ('2015', '2015'), (',', ','), ('VOLUME', 'volum'), (':', ':'), ('05', '05'), (',', ','), ('ISSUE', 'issu'), (':', ':'), ('03', '03')]

>> Stemming using Snowball Stemmer: 
 [('ISSN', 'issn'), (':', ':'), ('2229-6956', '2229-6956'), ('(', '('), ('ONLINE', 'onlin'), (')', ')'), ('ICTACT', 'ictact'), ('JOURNAL', 'journal'), ('ON', 'on'), ('SOFT', 'soft'), ('COMPUTING', 'comput'), (',', ','), ('APRIL', 'april'), ('2015', '2015'), (',', ','), ('VOLUME', 'volum'), (':', ':'), ('05', '05'), (',', ','), ('ISSUE', 'issu'), (':', ':'), ('03', '03')]

>> Lemmatization: 
 [('ISSN', 'ISSN'), (':', ':'), ('2229-6956', '2229-6956'), ('(', '('), ('ONLINE', 'ONLINE'), (')', ')'), ('ICTACT', 'ICTACT'), ('JOURNAL', 'JOURNAL'), ('ON', 'ON'), ('SOFT', 'SOFT'), ('COMPUTING', 'COMPUTING'), (',', ','), ('APRIL', 'APRIL'), ('2015', '2015'), (',', ','), ('VOLUME', 'VOLUME'), (':', ':'), ('05', '05'), (',', ','), ('ISSUE', 'ISSUE'), (':', ':'), ('03', '03')]



========================================== PARAGRAPH 105 ===========================================

947  

------------------- Sentence 1 -------------------

947

>> Tokens are: 
 ['947']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('947', 'CD')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('947', '947')]

>> Stemming using Snowball Stemmer: 
 [('947', '947')]

>> Lemmatization: 
 [('947', '947')]



========================================== PARAGRAPH 106 ===========================================

existing lines of research in each learning technique. In each of  

------------------- Sentence 1 -------------------

existing lines of research in each learning technique.

>> Tokens are: 
 ['existing', 'lines', 'research', 'learning', 'technique', '.']

>> Bigrams are: 
 [('existing', 'lines'), ('lines', 'research'), ('research', 'learning'), ('learning', 'technique'), ('technique', '.')]

>> Trigrams are: 
 [('existing', 'lines', 'research'), ('lines', 'research', 'learning'), ('research', 'learning', 'technique'), ('learning', 'technique', '.')]

>> POS Tags are: 
 [('existing', 'VBG'), ('lines', 'NNS'), ('research', 'NN'), ('learning', 'NN'), ('technique', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['lines research learning technique']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('existing', 'exist'), ('lines', 'line'), ('research', 'research'), ('learning', 'learn'), ('technique', 'techniqu'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('existing', 'exist'), ('lines', 'line'), ('research', 'research'), ('learning', 'learn'), ('technique', 'techniqu'), ('.', '.')]

>> Lemmatization: 
 [('existing', 'existing'), ('lines', 'line'), ('research', 'research'), ('learning', 'learning'), ('technique', 'technique'), ('.', '.')]


------------------- Sentence 2 -------------------

In each of

>> Tokens are: 
 ['In']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('In', 'IN')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('In', 'in')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in')]

>> Lemmatization: 
 [('In', 'In')]



========================================== PARAGRAPH 107 ===========================================

our listed areas, there are many other papers/books that could be  

------------------- Sentence 1 -------------------

our listed areas, there are many other papers/books that could be

>> Tokens are: 
 ['listed', 'areas', ',', 'many', 'papers/books', 'could']

>> Bigrams are: 
 [('listed', 'areas'), ('areas', ','), (',', 'many'), ('many', 'papers/books'), ('papers/books', 'could')]

>> Trigrams are: 
 [('listed', 'areas', ','), ('areas', ',', 'many'), (',', 'many', 'papers/books'), ('many', 'papers/books', 'could')]

>> POS Tags are: 
 [('listed', 'VBN'), ('areas', 'NNS'), (',', ','), ('many', 'JJ'), ('papers/books', 'NNS'), ('could', 'MD')]

>> Noun Phrases are: 
 ['areas', 'many papers/books']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('listed', 'list'), ('areas', 'area'), (',', ','), ('many', 'mani'), ('papers/books', 'papers/book'), ('could', 'could')]

>> Stemming using Snowball Stemmer: 
 [('listed', 'list'), ('areas', 'area'), (',', ','), ('many', 'mani'), ('papers/books', 'papers/book'), ('could', 'could')]

>> Lemmatization: 
 [('listed', 'listed'), ('areas', 'area'), (',', ','), ('many', 'many'), ('papers/books', 'papers/books'), ('could', 'could')]



========================================== PARAGRAPH 108 ===========================================

more comprehensively help the interested readers.  

------------------- Sentence 1 -------------------

more comprehensively help the interested readers.

>> Tokens are: 
 ['comprehensively', 'help', 'interested', 'readers', '.']

>> Bigrams are: 
 [('comprehensively', 'help'), ('help', 'interested'), ('interested', 'readers'), ('readers', '.')]

>> Trigrams are: 
 [('comprehensively', 'help', 'interested'), ('help', 'interested', 'readers'), ('interested', 'readers', '.')]

>> POS Tags are: 
 [('comprehensively', 'RB'), ('help', 'NN'), ('interested', 'JJ'), ('readers', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['help', 'interested readers']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('comprehensively', 'comprehens'), ('help', 'help'), ('interested', 'interest'), ('readers', 'reader'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('comprehensively', 'comprehens'), ('help', 'help'), ('interested', 'interest'), ('readers', 'reader'), ('.', '.')]

>> Lemmatization: 
 [('comprehensively', 'comprehensively'), ('help', 'help'), ('interested', 'interested'), ('readers', 'reader'), ('.', '.')]



========================================== PARAGRAPH 109 ===========================================

In the next section, we will cover wide-ranging issues of  

------------------- Sentence 1 -------------------

In the next section, we will cover wide-ranging issues of

>> Tokens are: 
 ['In', 'next', 'section', ',', 'cover', 'wide-ranging', 'issues']

>> Bigrams are: 
 [('In', 'next'), ('next', 'section'), ('section', ','), (',', 'cover'), ('cover', 'wide-ranging'), ('wide-ranging', 'issues')]

>> Trigrams are: 
 [('In', 'next', 'section'), ('next', 'section', ','), ('section', ',', 'cover'), (',', 'cover', 'wide-ranging'), ('cover', 'wide-ranging', 'issues')]

>> POS Tags are: 
 [('In', 'IN'), ('next', 'JJ'), ('section', 'NN'), (',', ','), ('cover', 'VB'), ('wide-ranging', 'JJ'), ('issues', 'NNS')]

>> Noun Phrases are: 
 ['next section', 'wide-ranging issues']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('next', 'next'), ('section', 'section'), (',', ','), ('cover', 'cover'), ('wide-ranging', 'wide-rang'), ('issues', 'issu')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('next', 'next'), ('section', 'section'), (',', ','), ('cover', 'cover'), ('wide-ranging', 'wide-rang'), ('issues', 'issu')]

>> Lemmatization: 
 [('In', 'In'), ('next', 'next'), ('section', 'section'), (',', ','), ('cover', 'cover'), ('wide-ranging', 'wide-ranging'), ('issues', 'issue')]



========================================== PARAGRAPH 110 ===========================================

supervised machine learning such as selection of features and  

------------------- Sentence 1 -------------------

supervised machine learning such as selection of features and

>> Tokens are: 
 ['supervised', 'machine', 'learning', 'selection', 'features']

>> Bigrams are: 
 [('supervised', 'machine'), ('machine', 'learning'), ('learning', 'selection'), ('selection', 'features')]

>> Trigrams are: 
 [('supervised', 'machine', 'learning'), ('machine', 'learning', 'selection'), ('learning', 'selection', 'features')]

>> POS Tags are: 
 [('supervised', 'VBN'), ('machine', 'NN'), ('learning', 'VBG'), ('selection', 'NN'), ('features', 'NNS')]

>> Noun Phrases are: 
 ['machine', 'selection features']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('supervised', 'supervis'), ('machine', 'machin'), ('learning', 'learn'), ('selection', 'select'), ('features', 'featur')]

>> Stemming using Snowball Stemmer: 
 [('supervised', 'supervis'), ('machine', 'machin'), ('learning', 'learn'), ('selection', 'select'), ('features', 'featur')]

>> Lemmatization: 
 [('supervised', 'supervised'), ('machine', 'machine'), ('learning', 'learning'), ('selection', 'selection'), ('features', 'feature')]



========================================== PARAGRAPH 111 ===========================================

data pre-processing. Logical/Symbolic techniques are being  

------------------- Sentence 1 -------------------

data pre-processing.

>> Tokens are: 
 ['data', 'pre-processing', '.']

>> Bigrams are: 
 [('data', 'pre-processing'), ('pre-processing', '.')]

>> Trigrams are: 
 [('data', 'pre-processing', '.')]

>> POS Tags are: 
 [('data', 'NNS'), ('pre-processing', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['data pre-processing']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('data', 'data'), ('pre-processing', 'pre-process'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('data', 'data'), ('pre-processing', 'pre-process'), ('.', '.')]

>> Lemmatization: 
 [('data', 'data'), ('pre-processing', 'pre-processing'), ('.', '.')]


------------------- Sentence 2 -------------------

Logical/Symbolic techniques are being

>> Tokens are: 
 ['Logical/Symbolic', 'techniques']

>> Bigrams are: 
 [('Logical/Symbolic', 'techniques')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Logical/Symbolic', 'NNP'), ('techniques', 'NNS')]

>> Noun Phrases are: 
 ['Logical/Symbolic techniques']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Logical/Symbolic', 'logical/symbol'), ('techniques', 'techniqu')]

>> Stemming using Snowball Stemmer: 
 [('Logical/Symbolic', 'logical/symbol'), ('techniques', 'techniqu')]

>> Lemmatization: 
 [('Logical/Symbolic', 'Logical/Symbolic'), ('techniques', 'technique')]



========================================== PARAGRAPH 112 ===========================================

described in section 3, whereas statistical techniques for ML are  

------------------- Sentence 1 -------------------

described in section 3, whereas statistical techniques for ML are

>> Tokens are: 
 ['described', 'section', '3', ',', 'whereas', 'statistical', 'techniques', 'ML']

>> Bigrams are: 
 [('described', 'section'), ('section', '3'), ('3', ','), (',', 'whereas'), ('whereas', 'statistical'), ('statistical', 'techniques'), ('techniques', 'ML')]

>> Trigrams are: 
 [('described', 'section', '3'), ('section', '3', ','), ('3', ',', 'whereas'), (',', 'whereas', 'statistical'), ('whereas', 'statistical', 'techniques'), ('statistical', 'techniques', 'ML')]

>> POS Tags are: 
 [('described', 'VBN'), ('section', 'NN'), ('3', 'CD'), (',', ','), ('whereas', 'RB'), ('statistical', 'JJ'), ('techniques', 'NNS'), ('ML', 'NNP')]

>> Noun Phrases are: 
 ['section', 'statistical techniques ML']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('described', 'describ'), ('section', 'section'), ('3', '3'), (',', ','), ('whereas', 'wherea'), ('statistical', 'statist'), ('techniques', 'techniqu'), ('ML', 'ml')]

>> Stemming using Snowball Stemmer: 
 [('described', 'describ'), ('section', 'section'), ('3', '3'), (',', ','), ('whereas', 'wherea'), ('statistical', 'statist'), ('techniques', 'techniqu'), ('ML', 'ml')]

>> Lemmatization: 
 [('described', 'described'), ('section', 'section'), ('3', '3'), (',', ','), ('whereas', 'whereas'), ('statistical', 'statistical'), ('techniques', 'technique'), ('ML', 'ML')]



========================================== PARAGRAPH 113 ===========================================

discussed in section 4. Section 5 will cover instance based  

------------------- Sentence 1 -------------------

discussed in section 4.

>> Tokens are: 
 ['discussed', 'section', '4', '.']

>> Bigrams are: 
 [('discussed', 'section'), ('section', '4'), ('4', '.')]

>> Trigrams are: 
 [('discussed', 'section', '4'), ('section', '4', '.')]

>> POS Tags are: 
 [('discussed', 'VBN'), ('section', 'NN'), ('4', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['section']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('discussed', 'discuss'), ('section', 'section'), ('4', '4'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('discussed', 'discuss'), ('section', 'section'), ('4', '4'), ('.', '.')]

>> Lemmatization: 
 [('discussed', 'discussed'), ('section', 'section'), ('4', '4'), ('.', '.')]


------------------- Sentence 2 -------------------

Section 5 will cover instance based

>> Tokens are: 
 ['Section', '5', 'cover', 'instance', 'based']

>> Bigrams are: 
 [('Section', '5'), ('5', 'cover'), ('cover', 'instance'), ('instance', 'based')]

>> Trigrams are: 
 [('Section', '5', 'cover'), ('5', 'cover', 'instance'), ('cover', 'instance', 'based')]

>> POS Tags are: 
 [('Section', 'NN'), ('5', 'CD'), ('cover', 'NN'), ('instance', 'NN'), ('based', 'VBN')]

>> Noun Phrases are: 
 ['Section', 'cover instance']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Section', 'section'), ('5', '5'), ('cover', 'cover'), ('instance', 'instanc'), ('based', 'base')]

>> Stemming using Snowball Stemmer: 
 [('Section', 'section'), ('5', '5'), ('cover', 'cover'), ('instance', 'instanc'), ('based', 'base')]

>> Lemmatization: 
 [('Section', 'Section'), ('5', '5'), ('cover', 'cover'), ('instance', 'instance'), ('based', 'based')]



========================================== PARAGRAPH 114 ===========================================

learners, SVM is discussed in section 6. The last section  

------------------- Sentence 1 -------------------

learners, SVM is discussed in section 6.

>> Tokens are: 
 ['learners', ',', 'SVM', 'discussed', 'section', '6', '.']

>> Bigrams are: 
 [('learners', ','), (',', 'SVM'), ('SVM', 'discussed'), ('discussed', 'section'), ('section', '6'), ('6', '.')]

>> Trigrams are: 
 [('learners', ',', 'SVM'), (',', 'SVM', 'discussed'), ('SVM', 'discussed', 'section'), ('discussed', 'section', '6'), ('section', '6', '.')]

>> POS Tags are: 
 [('learners', 'NNS'), (',', ','), ('SVM', 'NNP'), ('discussed', 'VBD'), ('section', 'NN'), ('6', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['learners', 'SVM', 'section']

>> Named Entities are: 
 [('ORGANIZATION', 'SVM')] 

>> Stemming using Porter Stemmer: 
 [('learners', 'learner'), (',', ','), ('SVM', 'svm'), ('discussed', 'discuss'), ('section', 'section'), ('6', '6'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('learners', 'learner'), (',', ','), ('SVM', 'svm'), ('discussed', 'discuss'), ('section', 'section'), ('6', '6'), ('.', '.')]

>> Lemmatization: 
 [('learners', 'learner'), (',', ','), ('SVM', 'SVM'), ('discussed', 'discussed'), ('section', 'section'), ('6', '6'), ('.', '.')]


------------------- Sentence 2 -------------------

The last section

>> Tokens are: 
 ['The', 'last', 'section']

>> Bigrams are: 
 [('The', 'last'), ('last', 'section')]

>> Trigrams are: 
 [('The', 'last', 'section')]

>> POS Tags are: 
 [('The', 'DT'), ('last', 'JJ'), ('section', 'NN')]

>> Noun Phrases are: 
 ['The last section']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('last', 'last'), ('section', 'section')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('last', 'last'), ('section', 'section')]

>> Lemmatization: 
 [('The', 'The'), ('last', 'last'), ('section', 'section')]



========================================== PARAGRAPH 115 ===========================================

concludes this work.  

------------------- Sentence 1 -------------------

concludes this work.

>> Tokens are: 
 ['concludes', 'work', '.']

>> Bigrams are: 
 [('concludes', 'work'), ('work', '.')]

>> Trigrams are: 
 [('concludes', 'work', '.')]

>> POS Tags are: 
 [('concludes', 'NNS'), ('work', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['concludes work']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('concludes', 'conclud'), ('work', 'work'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('concludes', 'conclud'), ('work', 'work'), ('.', '.')]

>> Lemmatization: 
 [('concludes', 'concludes'), ('work', 'work'), ('.', '.')]



========================================== PARAGRAPH 116 ===========================================

2. ISSUES OF SUPERVISED LEARNING  ALGORITHMS  

------------------- Sentence 1 -------------------

2.

>> Tokens are: 
 ['2', '.']

>> Bigrams are: 
 [('2', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('2', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('2', '2'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('2', '2'), ('.', '.')]

>> Lemmatization: 
 [('2', '2'), ('.', '.')]


------------------- Sentence 2 -------------------

ISSUES OF SUPERVISED LEARNING  ALGORITHMS

>> Tokens are: 
 ['ISSUES', 'OF', 'SUPERVISED', 'LEARNING', 'ALGORITHMS']

>> Bigrams are: 
 [('ISSUES', 'OF'), ('OF', 'SUPERVISED'), ('SUPERVISED', 'LEARNING'), ('LEARNING', 'ALGORITHMS')]

>> Trigrams are: 
 [('ISSUES', 'OF', 'SUPERVISED'), ('OF', 'SUPERVISED', 'LEARNING'), ('SUPERVISED', 'LEARNING', 'ALGORITHMS')]

>> POS Tags are: 
 [('ISSUES', 'NNP'), ('OF', 'NNP'), ('SUPERVISED', 'NNP'), ('LEARNING', 'NNP'), ('ALGORITHMS', 'NNP')]

>> Noun Phrases are: 
 ['ISSUES OF SUPERVISED LEARNING ALGORITHMS']

>> Named Entities are: 
 [('ORGANIZATION', 'ISSUES'), ('ORGANIZATION', 'OF')] 

>> Stemming using Porter Stemmer: 
 [('ISSUES', 'issu'), ('OF', 'of'), ('SUPERVISED', 'supervis'), ('LEARNING', 'learn'), ('ALGORITHMS', 'algorithm')]

>> Stemming using Snowball Stemmer: 
 [('ISSUES', 'issu'), ('OF', 'of'), ('SUPERVISED', 'supervis'), ('LEARNING', 'learn'), ('ALGORITHMS', 'algorithm')]

>> Lemmatization: 
 [('ISSUES', 'ISSUES'), ('OF', 'OF'), ('SUPERVISED', 'SUPERVISED'), ('LEARNING', 'LEARNING'), ('ALGORITHMS', 'ALGORITHMS')]



========================================== PARAGRAPH 117 ===========================================

Learning from the past experiences is an attribute of humans  

------------------- Sentence 1 -------------------

Learning from the past experiences is an attribute of humans

>> Tokens are: 
 ['Learning', 'past', 'experiences', 'attribute', 'humans']

>> Bigrams are: 
 [('Learning', 'past'), ('past', 'experiences'), ('experiences', 'attribute'), ('attribute', 'humans')]

>> Trigrams are: 
 [('Learning', 'past', 'experiences'), ('past', 'experiences', 'attribute'), ('experiences', 'attribute', 'humans')]

>> POS Tags are: 
 [('Learning', 'VBG'), ('past', 'JJ'), ('experiences', 'NNS'), ('attribute', 'VBP'), ('humans', 'NNS')]

>> Noun Phrases are: 
 ['past experiences', 'humans']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Learning', 'learn'), ('past', 'past'), ('experiences', 'experi'), ('attribute', 'attribut'), ('humans', 'human')]

>> Stemming using Snowball Stemmer: 
 [('Learning', 'learn'), ('past', 'past'), ('experiences', 'experi'), ('attribute', 'attribut'), ('humans', 'human')]

>> Lemmatization: 
 [('Learning', 'Learning'), ('past', 'past'), ('experiences', 'experience'), ('attribute', 'attribute'), ('humans', 'human')]



========================================== PARAGRAPH 118 ===========================================

while the computers do not have this ability. In supervised or  

------------------- Sentence 1 -------------------

while the computers do not have this ability.

>> Tokens are: 
 ['computers', 'ability', '.']

>> Bigrams are: 
 [('computers', 'ability'), ('ability', '.')]

>> Trigrams are: 
 [('computers', 'ability', '.')]

>> POS Tags are: 
 [('computers', 'NNS'), ('ability', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['computers ability']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('computers', 'comput'), ('ability', 'abil'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('computers', 'comput'), ('ability', 'abil'), ('.', '.')]

>> Lemmatization: 
 [('computers', 'computer'), ('ability', 'ability'), ('.', '.')]


------------------- Sentence 2 -------------------

In supervised or

>> Tokens are: 
 ['In', 'supervised']

>> Bigrams are: 
 [('In', 'supervised')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('In', 'IN'), ('supervised', 'JJ')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('supervised', 'supervis')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('supervised', 'supervis')]

>> Lemmatization: 
 [('In', 'In'), ('supervised', 'supervised')]



========================================== PARAGRAPH 119 ===========================================

Inductive machine learning, our main goal is to learn a target  

------------------- Sentence 1 -------------------

Inductive machine learning, our main goal is to learn a target

>> Tokens are: 
 ['Inductive', 'machine', 'learning', ',', 'main', 'goal', 'learn', 'target']

>> Bigrams are: 
 [('Inductive', 'machine'), ('machine', 'learning'), ('learning', ','), (',', 'main'), ('main', 'goal'), ('goal', 'learn'), ('learn', 'target')]

>> Trigrams are: 
 [('Inductive', 'machine', 'learning'), ('machine', 'learning', ','), ('learning', ',', 'main'), (',', 'main', 'goal'), ('main', 'goal', 'learn'), ('goal', 'learn', 'target')]

>> POS Tags are: 
 [('Inductive', 'JJ'), ('machine', 'NN'), ('learning', 'NN'), (',', ','), ('main', 'JJ'), ('goal', 'NN'), ('learn', 'NN'), ('target', 'NN')]

>> Noun Phrases are: 
 ['Inductive machine learning', 'main goal learn target']

>> Named Entities are: 
 [('GPE', 'Inductive')] 

>> Stemming using Porter Stemmer: 
 [('Inductive', 'induct'), ('machine', 'machin'), ('learning', 'learn'), (',', ','), ('main', 'main'), ('goal', 'goal'), ('learn', 'learn'), ('target', 'target')]

>> Stemming using Snowball Stemmer: 
 [('Inductive', 'induct'), ('machine', 'machin'), ('learning', 'learn'), (',', ','), ('main', 'main'), ('goal', 'goal'), ('learn', 'learn'), ('target', 'target')]

>> Lemmatization: 
 [('Inductive', 'Inductive'), ('machine', 'machine'), ('learning', 'learning'), (',', ','), ('main', 'main'), ('goal', 'goal'), ('learn', 'learn'), ('target', 'target')]



========================================== PARAGRAPH 120 ===========================================

function that can be used to predict the values of a class. The  

------------------- Sentence 1 -------------------

function that can be used to predict the values of a class.

>> Tokens are: 
 ['function', 'used', 'predict', 'values', 'class', '.']

>> Bigrams are: 
 [('function', 'used'), ('used', 'predict'), ('predict', 'values'), ('values', 'class'), ('class', '.')]

>> Trigrams are: 
 [('function', 'used', 'predict'), ('used', 'predict', 'values'), ('predict', 'values', 'class'), ('values', 'class', '.')]

>> POS Tags are: 
 [('function', 'NN'), ('used', 'VBN'), ('predict', 'NN'), ('values', 'NNS'), ('class', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['function', 'predict values class']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('function', 'function'), ('used', 'use'), ('predict', 'predict'), ('values', 'valu'), ('class', 'class'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('function', 'function'), ('used', 'use'), ('predict', 'predict'), ('values', 'valu'), ('class', 'class'), ('.', '.')]

>> Lemmatization: 
 [('function', 'function'), ('used', 'used'), ('predict', 'predict'), ('values', 'value'), ('class', 'class'), ('.', '.')]


------------------- Sentence 2 -------------------

The

>> Tokens are: 
 ['The']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('The', 'DT')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the')]

>> Lemmatization: 
 [('The', 'The')]



========================================== PARAGRAPH 121 ===========================================

process of applying supervised ML to a real-world problem is  

------------------- Sentence 1 -------------------

process of applying supervised ML to a real-world problem is

>> Tokens are: 
 ['process', 'applying', 'supervised', 'ML', 'real-world', 'problem']

>> Bigrams are: 
 [('process', 'applying'), ('applying', 'supervised'), ('supervised', 'ML'), ('ML', 'real-world'), ('real-world', 'problem')]

>> Trigrams are: 
 [('process', 'applying', 'supervised'), ('applying', 'supervised', 'ML'), ('supervised', 'ML', 'real-world'), ('ML', 'real-world', 'problem')]

>> POS Tags are: 
 [('process', 'NN'), ('applying', 'VBG'), ('supervised', 'VBN'), ('ML', 'NNP'), ('real-world', 'NN'), ('problem', 'NN')]

>> Noun Phrases are: 
 ['process', 'ML real-world problem']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('process', 'process'), ('applying', 'appli'), ('supervised', 'supervis'), ('ML', 'ml'), ('real-world', 'real-world'), ('problem', 'problem')]

>> Stemming using Snowball Stemmer: 
 [('process', 'process'), ('applying', 'appli'), ('supervised', 'supervis'), ('ML', 'ml'), ('real-world', 'real-world'), ('problem', 'problem')]

>> Lemmatization: 
 [('process', 'process'), ('applying', 'applying'), ('supervised', 'supervised'), ('ML', 'ML'), ('real-world', 'real-world'), ('problem', 'problem')]



========================================== PARAGRAPH 122 ===========================================

described in below figure.  

------------------- Sentence 1 -------------------

described in below figure.

>> Tokens are: 
 ['described', 'figure', '.']

>> Bigrams are: 
 [('described', 'figure'), ('figure', '.')]

>> Trigrams are: 
 [('described', 'figure', '.')]

>> POS Tags are: 
 [('described', 'JJ'), ('figure', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['described figure']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('described', 'describ'), ('figure', 'figur'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('described', 'describ'), ('figure', 'figur'), ('.', '.')]

>> Lemmatization: 
 [('described', 'described'), ('figure', 'figure'), ('.', '.')]



========================================== PARAGRAPH 123 ===========================================

  


========================================== PARAGRAPH 124 ===========================================

Fig.2. Supervised Machine Learning Model  

------------------- Sentence 1 -------------------

Fig.2.

>> Tokens are: 
 ['Fig.2', '.']

>> Bigrams are: 
 [('Fig.2', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Fig.2', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Fig.2']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Fig.2', 'fig.2'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Fig.2', 'fig.2'), ('.', '.')]

>> Lemmatization: 
 [('Fig.2', 'Fig.2'), ('.', '.')]


------------------- Sentence 2 -------------------

Supervised Machine Learning Model

>> Tokens are: 
 ['Supervised', 'Machine', 'Learning', 'Model']

>> Bigrams are: 
 [('Supervised', 'Machine'), ('Machine', 'Learning'), ('Learning', 'Model')]

>> Trigrams are: 
 [('Supervised', 'Machine', 'Learning'), ('Machine', 'Learning', 'Model')]

>> POS Tags are: 
 [('Supervised', 'VBN'), ('Machine', 'NNP'), ('Learning', 'NNP'), ('Model', 'NNP')]

>> Noun Phrases are: 
 ['Machine Learning Model']

>> Named Entities are: 
 [('PERSON', 'Machine Learning Model')] 

>> Stemming using Porter Stemmer: 
 [('Supervised', 'supervis'), ('Machine', 'machin'), ('Learning', 'learn'), ('Model', 'model')]

>> Stemming using Snowball Stemmer: 
 [('Supervised', 'supervis'), ('Machine', 'machin'), ('Learning', 'learn'), ('Model', 'model')]

>> Lemmatization: 
 [('Supervised', 'Supervised'), ('Machine', 'Machine'), ('Learning', 'Learning'), ('Model', 'Model')]



========================================== PARAGRAPH 125 ===========================================

In supervised learning the first step is dealing with dataset. In  

------------------- Sentence 1 -------------------

In supervised learning the first step is dealing with dataset.

>> Tokens are: 
 ['In', 'supervised', 'learning', 'first', 'step', 'dealing', 'dataset', '.']

>> Bigrams are: 
 [('In', 'supervised'), ('supervised', 'learning'), ('learning', 'first'), ('first', 'step'), ('step', 'dealing'), ('dealing', 'dataset'), ('dataset', '.')]

>> Trigrams are: 
 [('In', 'supervised', 'learning'), ('supervised', 'learning', 'first'), ('learning', 'first', 'step'), ('first', 'step', 'dealing'), ('step', 'dealing', 'dataset'), ('dealing', 'dataset', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('supervised', 'JJ'), ('learning', 'NN'), ('first', 'JJ'), ('step', 'NN'), ('dealing', 'VBG'), ('dataset', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['supervised learning', 'first step', 'dataset']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('supervised', 'supervis'), ('learning', 'learn'), ('first', 'first'), ('step', 'step'), ('dealing', 'deal'), ('dataset', 'dataset'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('supervised', 'supervis'), ('learning', 'learn'), ('first', 'first'), ('step', 'step'), ('dealing', 'deal'), ('dataset', 'dataset'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('supervised', 'supervised'), ('learning', 'learning'), ('first', 'first'), ('step', 'step'), ('dealing', 'dealing'), ('dataset', 'dataset'), ('.', '.')]


------------------- Sentence 2 -------------------

In

>> Tokens are: 
 ['In']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('In', 'IN')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('In', 'in')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in')]

>> Lemmatization: 
 [('In', 'In')]



========================================== PARAGRAPH 126 ===========================================

order to perform a better training on data set an appropriate  

------------------- Sentence 1 -------------------

order to perform a better training on data set an appropriate

>> Tokens are: 
 ['order', 'perform', 'better', 'training', 'data', 'set', 'appropriate']

>> Bigrams are: 
 [('order', 'perform'), ('perform', 'better'), ('better', 'training'), ('training', 'data'), ('data', 'set'), ('set', 'appropriate')]

>> Trigrams are: 
 [('order', 'perform', 'better'), ('perform', 'better', 'training'), ('better', 'training', 'data'), ('training', 'data', 'set'), ('data', 'set', 'appropriate')]

>> POS Tags are: 
 [('order', 'NN'), ('perform', 'NN'), ('better', 'RBR'), ('training', 'NN'), ('data', 'NNS'), ('set', 'VBD'), ('appropriate', 'JJ')]

>> Noun Phrases are: 
 ['order perform', 'training data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('order', 'order'), ('perform', 'perform'), ('better', 'better'), ('training', 'train'), ('data', 'data'), ('set', 'set'), ('appropriate', 'appropri')]

>> Stemming using Snowball Stemmer: 
 [('order', 'order'), ('perform', 'perform'), ('better', 'better'), ('training', 'train'), ('data', 'data'), ('set', 'set'), ('appropriate', 'appropri')]

>> Lemmatization: 
 [('order', 'order'), ('perform', 'perform'), ('better', 'better'), ('training', 'training'), ('data', 'data'), ('set', 'set'), ('appropriate', 'appropriate')]



========================================== PARAGRAPH 127 ===========================================

expert could suggest better selection of features. If concerned  

------------------- Sentence 1 -------------------

expert could suggest better selection of features.

>> Tokens are: 
 ['expert', 'could', 'suggest', 'better', 'selection', 'features', '.']

>> Bigrams are: 
 [('expert', 'could'), ('could', 'suggest'), ('suggest', 'better'), ('better', 'selection'), ('selection', 'features'), ('features', '.')]

>> Trigrams are: 
 [('expert', 'could', 'suggest'), ('could', 'suggest', 'better'), ('suggest', 'better', 'selection'), ('better', 'selection', 'features'), ('selection', 'features', '.')]

>> POS Tags are: 
 [('expert', 'NN'), ('could', 'MD'), ('suggest', 'VB'), ('better', 'JJR'), ('selection', 'NN'), ('features', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['expert', 'selection features']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('expert', 'expert'), ('could', 'could'), ('suggest', 'suggest'), ('better', 'better'), ('selection', 'select'), ('features', 'featur'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('expert', 'expert'), ('could', 'could'), ('suggest', 'suggest'), ('better', 'better'), ('selection', 'select'), ('features', 'featur'), ('.', '.')]

>> Lemmatization: 
 [('expert', 'expert'), ('could', 'could'), ('suggest', 'suggest'), ('better', 'better'), ('selection', 'selection'), ('features', 'feature'), ('.', '.')]


------------------- Sentence 2 -------------------

If concerned

>> Tokens are: 
 ['If', 'concerned']

>> Bigrams are: 
 [('If', 'concerned')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('If', 'IN'), ('concerned', 'VBN')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('If', 'if'), ('concerned', 'concern')]

>> Stemming using Snowball Stemmer: 
 [('If', 'if'), ('concerned', 'concern')]

>> Lemmatization: 
 [('If', 'If'), ('concerned', 'concerned')]



========================================== PARAGRAPH 128 ===========================================

expert is not in reach, then the other approach is brute-force,  

------------------- Sentence 1 -------------------

expert is not in reach, then the other approach is brute-force,

>> Tokens are: 
 ['expert', 'reach', ',', 'approach', '', 'brute-force', '', ',']

>> Bigrams are: 
 [('expert', 'reach'), ('reach', ','), (',', 'approach'), ('approach', ''), ('', 'brute-force'), ('brute-force', ''), ('', ',')]

>> Trigrams are: 
 [('expert', 'reach', ','), ('reach', ',', 'approach'), (',', 'approach', ''), ('approach', '', 'brute-force'), ('', 'brute-force', ''), ('brute-force', '', ',')]

>> POS Tags are: 
 [('expert', 'JJ'), ('reach', 'NN'), (',', ','), ('approach', 'NN'), ('', 'VBD'), ('brute-force', 'JJ'), ('', 'NN'), (',', ',')]

>> Noun Phrases are: 
 ['expert reach', 'approach', 'brute-force ']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('expert', 'expert'), ('reach', 'reach'), (',', ','), ('approach', 'approach'), ('', ''), ('brute-force', 'brute-forc'), ('', ''), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('expert', 'expert'), ('reach', 'reach'), (',', ','), ('approach', 'approach'), ('', ''), ('brute-force', 'brute-forc'), ('', ''), (',', ',')]

>> Lemmatization: 
 [('expert', 'expert'), ('reach', 'reach'), (',', ','), ('approach', 'approach'), ('', ''), ('brute-force', 'brute-force'), ('', ''), (',', ',')]



========================================== PARAGRAPH 129 ===========================================

which means measuring everything available in the hope that the  

------------------- Sentence 1 -------------------

which means measuring everything available in the hope that the

>> Tokens are: 
 ['means', 'measuring', 'everything', 'available', 'hope']

>> Bigrams are: 
 [('means', 'measuring'), ('measuring', 'everything'), ('everything', 'available'), ('available', 'hope')]

>> Trigrams are: 
 [('means', 'measuring', 'everything'), ('measuring', 'everything', 'available'), ('everything', 'available', 'hope')]

>> POS Tags are: 
 [('means', 'NNS'), ('measuring', 'VBG'), ('everything', 'NN'), ('available', 'JJ'), ('hope', 'NN')]

>> Noun Phrases are: 
 ['means', 'everything', 'available hope']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('means', 'mean'), ('measuring', 'measur'), ('everything', 'everyth'), ('available', 'avail'), ('hope', 'hope')]

>> Stemming using Snowball Stemmer: 
 [('means', 'mean'), ('measuring', 'measur'), ('everything', 'everyth'), ('available', 'avail'), ('hope', 'hope')]

>> Lemmatization: 
 [('means', 'mean'), ('measuring', 'measuring'), ('everything', 'everything'), ('available', 'available'), ('hope', 'hope')]



========================================== PARAGRAPH 130 ===========================================

right (informative, relevant) features can be isolated. However, a  

------------------- Sentence 1 -------------------

right (informative, relevant) features can be isolated.

>> Tokens are: 
 ['right', '(', 'informative', ',', 'relevant', ')', 'features', 'isolated', '.']

>> Bigrams are: 
 [('right', '('), ('(', 'informative'), ('informative', ','), (',', 'relevant'), ('relevant', ')'), (')', 'features'), ('features', 'isolated'), ('isolated', '.')]

>> Trigrams are: 
 [('right', '(', 'informative'), ('(', 'informative', ','), ('informative', ',', 'relevant'), (',', 'relevant', ')'), ('relevant', ')', 'features'), (')', 'features', 'isolated'), ('features', 'isolated', '.')]

>> POS Tags are: 
 [('right', 'RB'), ('(', '('), ('informative', 'JJ'), (',', ','), ('relevant', 'JJ'), (')', ')'), ('features', 'NNS'), ('isolated', 'VBN'), ('.', '.')]

>> Noun Phrases are: 
 ['features']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('right', 'right'), ('(', '('), ('informative', 'inform'), (',', ','), ('relevant', 'relev'), (')', ')'), ('features', 'featur'), ('isolated', 'isol'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('right', 'right'), ('(', '('), ('informative', 'inform'), (',', ','), ('relevant', 'relev'), (')', ')'), ('features', 'featur'), ('isolated', 'isol'), ('.', '.')]

>> Lemmatization: 
 [('right', 'right'), ('(', '('), ('informative', 'informative'), (',', ','), ('relevant', 'relevant'), (')', ')'), ('features', 'feature'), ('isolated', 'isolated'), ('.', '.')]


------------------- Sentence 2 -------------------

However, a

>> Tokens are: 
 ['However', ',']

>> Bigrams are: 
 [('However', ',')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('However', 'RB'), (',', ',')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('However', 'howev'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('However', 'howev'), (',', ',')]

>> Lemmatization: 
 [('However', 'However'), (',', ',')]



========================================== PARAGRAPH 131 ===========================================

dataset collected by the brute-force method is not directly  

------------------- Sentence 1 -------------------

dataset collected by the brute-force method is not directly

>> Tokens are: 
 ['dataset', 'collected', '', 'brute-force', '', 'method', 'directly']

>> Bigrams are: 
 [('dataset', 'collected'), ('collected', ''), ('', 'brute-force'), ('brute-force', ''), ('', 'method'), ('method', 'directly')]

>> Trigrams are: 
 [('dataset', 'collected', ''), ('collected', '', 'brute-force'), ('', 'brute-force', ''), ('brute-force', '', 'method'), ('', 'method', 'directly')]

>> POS Tags are: 
 [('dataset', 'NN'), ('collected', 'VBD'), ('', 'JJ'), ('brute-force', 'JJ'), ('', 'NN'), ('method', 'NN'), ('directly', 'RB')]

>> Noun Phrases are: 
 ['dataset', ' brute-force  method']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('dataset', 'dataset'), ('collected', 'collect'), ('', ''), ('brute-force', 'brute-forc'), ('', ''), ('method', 'method'), ('directly', 'directli')]

>> Stemming using Snowball Stemmer: 
 [('dataset', 'dataset'), ('collected', 'collect'), ('', ''), ('brute-force', 'brute-forc'), ('', ''), ('method', 'method'), ('directly', 'direct')]

>> Lemmatization: 
 [('dataset', 'dataset'), ('collected', 'collected'), ('', ''), ('brute-force', 'brute-force'), ('', ''), ('method', 'method'), ('directly', 'directly')]



========================================== PARAGRAPH 132 ===========================================

suitable for induction. Ultimately, in most cases it contains noise  

------------------- Sentence 1 -------------------

suitable for induction.

>> Tokens are: 
 ['suitable', 'induction', '.']

>> Bigrams are: 
 [('suitable', 'induction'), ('induction', '.')]

>> Trigrams are: 
 [('suitable', 'induction', '.')]

>> POS Tags are: 
 [('suitable', 'JJ'), ('induction', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['suitable induction']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('suitable', 'suitabl'), ('induction', 'induct'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('suitable', 'suitabl'), ('induction', 'induct'), ('.', '.')]

>> Lemmatization: 
 [('suitable', 'suitable'), ('induction', 'induction'), ('.', '.')]


------------------- Sentence 2 -------------------

Ultimately, in most cases it contains noise

>> Tokens are: 
 ['Ultimately', ',', 'cases', 'contains', 'noise']

>> Bigrams are: 
 [('Ultimately', ','), (',', 'cases'), ('cases', 'contains'), ('contains', 'noise')]

>> Trigrams are: 
 [('Ultimately', ',', 'cases'), (',', 'cases', 'contains'), ('cases', 'contains', 'noise')]

>> POS Tags are: 
 [('Ultimately', 'RB'), (',', ','), ('cases', 'NNS'), ('contains', 'NNS'), ('noise', 'VBP')]

>> Noun Phrases are: 
 ['cases contains']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Ultimately', 'ultim'), (',', ','), ('cases', 'case'), ('contains', 'contain'), ('noise', 'nois')]

>> Stemming using Snowball Stemmer: 
 [('Ultimately', 'ultim'), (',', ','), ('cases', 'case'), ('contains', 'contain'), ('noise', 'nois')]

>> Lemmatization: 
 [('Ultimately', 'Ultimately'), (',', ','), ('cases', 'case'), ('contains', 'contains'), ('noise', 'noise')]



========================================== PARAGRAPH 133 ===========================================

and missing feature values, and therefore requires significant  

------------------- Sentence 1 -------------------

and missing feature values, and therefore requires significant

>> Tokens are: 
 ['missing', 'feature', 'values', ',', 'therefore', 'requires', 'significant']

>> Bigrams are: 
 [('missing', 'feature'), ('feature', 'values'), ('values', ','), (',', 'therefore'), ('therefore', 'requires'), ('requires', 'significant')]

>> Trigrams are: 
 [('missing', 'feature', 'values'), ('feature', 'values', ','), ('values', ',', 'therefore'), (',', 'therefore', 'requires'), ('therefore', 'requires', 'significant')]

>> POS Tags are: 
 [('missing', 'VBG'), ('feature', 'NN'), ('values', 'NNS'), (',', ','), ('therefore', 'RB'), ('requires', 'VBZ'), ('significant', 'JJ')]

>> Noun Phrases are: 
 ['feature values']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('missing', 'miss'), ('feature', 'featur'), ('values', 'valu'), (',', ','), ('therefore', 'therefor'), ('requires', 'requir'), ('significant', 'signific')]

>> Stemming using Snowball Stemmer: 
 [('missing', 'miss'), ('feature', 'featur'), ('values', 'valu'), (',', ','), ('therefore', 'therefor'), ('requires', 'requir'), ('significant', 'signific')]

>> Lemmatization: 
 [('missing', 'missing'), ('feature', 'feature'), ('values', 'value'), (',', ','), ('therefore', 'therefore'), ('requires', 'requires'), ('significant', 'significant')]



========================================== PARAGRAPH 134 ===========================================

pre-processing [1]. In the next step, data preparation and data  

------------------- Sentence 1 -------------------

pre-processing [1].

>> Tokens are: 
 ['pre-processing', '[', '1', ']', '.']

>> Bigrams are: 
 [('pre-processing', '['), ('[', '1'), ('1', ']'), (']', '.')]

>> Trigrams are: 
 [('pre-processing', '[', '1'), ('[', '1', ']'), ('1', ']', '.')]

>> POS Tags are: 
 [('pre-processing', 'JJ'), ('[', 'NN'), ('1', 'CD'), (']', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['pre-processing [', ']']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('pre-processing', 'pre-process'), ('[', '['), ('1', '1'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('pre-processing', 'pre-process'), ('[', '['), ('1', '1'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('pre-processing', 'pre-processing'), ('[', '['), ('1', '1'), (']', ']'), ('.', '.')]


------------------- Sentence 2 -------------------

In the next step, data preparation and data

>> Tokens are: 
 ['In', 'next', 'step', ',', 'data', 'preparation', 'data']

>> Bigrams are: 
 [('In', 'next'), ('next', 'step'), ('step', ','), (',', 'data'), ('data', 'preparation'), ('preparation', 'data')]

>> Trigrams are: 
 [('In', 'next', 'step'), ('next', 'step', ','), ('step', ',', 'data'), (',', 'data', 'preparation'), ('data', 'preparation', 'data')]

>> POS Tags are: 
 [('In', 'IN'), ('next', 'JJ'), ('step', 'NN'), (',', ','), ('data', 'NNS'), ('preparation', 'NN'), ('data', 'NNS')]

>> Noun Phrases are: 
 ['next step', 'data preparation data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('next', 'next'), ('step', 'step'), (',', ','), ('data', 'data'), ('preparation', 'prepar'), ('data', 'data')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('next', 'next'), ('step', 'step'), (',', ','), ('data', 'data'), ('preparation', 'prepar'), ('data', 'data')]

>> Lemmatization: 
 [('In', 'In'), ('next', 'next'), ('step', 'step'), (',', ','), ('data', 'data'), ('preparation', 'preparation'), ('data', 'data')]



========================================== PARAGRAPH 135 ===========================================

preprocessing is a key function of researcher in Supervised  

------------------- Sentence 1 -------------------

preprocessing is a key function of researcher in Supervised

>> Tokens are: 
 ['preprocessing', 'key', 'function', 'researcher', 'Supervised']

>> Bigrams are: 
 [('preprocessing', 'key'), ('key', 'function'), ('function', 'researcher'), ('researcher', 'Supervised')]

>> Trigrams are: 
 [('preprocessing', 'key', 'function'), ('key', 'function', 'researcher'), ('function', 'researcher', 'Supervised')]

>> POS Tags are: 
 [('preprocessing', 'VBG'), ('key', 'JJ'), ('function', 'NN'), ('researcher', 'NN'), ('Supervised', 'VBD')]

>> Noun Phrases are: 
 ['key function researcher']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('preprocessing', 'preprocess'), ('key', 'key'), ('function', 'function'), ('researcher', 'research'), ('Supervised', 'supervis')]

>> Stemming using Snowball Stemmer: 
 [('preprocessing', 'preprocess'), ('key', 'key'), ('function', 'function'), ('researcher', 'research'), ('Supervised', 'supervis')]

>> Lemmatization: 
 [('preprocessing', 'preprocessing'), ('key', 'key'), ('function', 'function'), ('researcher', 'researcher'), ('Supervised', 'Supervised')]



========================================== PARAGRAPH 136 ===========================================

Machine Learning (SML). A number of techniques have been  

------------------- Sentence 1 -------------------

Machine Learning (SML).

>> Tokens are: 
 ['Machine', 'Learning', '(', 'SML', ')', '.']

>> Bigrams are: 
 [('Machine', 'Learning'), ('Learning', '('), ('(', 'SML'), ('SML', ')'), (')', '.')]

>> Trigrams are: 
 [('Machine', 'Learning', '('), ('Learning', '(', 'SML'), ('(', 'SML', ')'), ('SML', ')', '.')]

>> POS Tags are: 
 [('Machine', 'NN'), ('Learning', 'NNP'), ('(', '('), ('SML', 'NNP'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['Machine Learning', 'SML']

>> Named Entities are: 
 [('PERSON', 'Machine Learning'), ('ORGANIZATION', 'SML')] 

>> Stemming using Porter Stemmer: 
 [('Machine', 'machin'), ('Learning', 'learn'), ('(', '('), ('SML', 'sml'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Machine', 'machin'), ('Learning', 'learn'), ('(', '('), ('SML', 'sml'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Machine', 'Machine'), ('Learning', 'Learning'), ('(', '('), ('SML', 'SML'), (')', ')'), ('.', '.')]


------------------- Sentence 2 -------------------

A number of techniques have been

>> Tokens are: 
 ['A', 'number', 'techniques']

>> Bigrams are: 
 [('A', 'number'), ('number', 'techniques')]

>> Trigrams are: 
 [('A', 'number', 'techniques')]

>> POS Tags are: 
 [('A', 'DT'), ('number', 'NN'), ('techniques', 'NNS')]

>> Noun Phrases are: 
 ['A number techniques']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('A', 'a'), ('number', 'number'), ('techniques', 'techniqu')]

>> Stemming using Snowball Stemmer: 
 [('A', 'a'), ('number', 'number'), ('techniques', 'techniqu')]

>> Lemmatization: 
 [('A', 'A'), ('number', 'number'), ('techniques', 'technique')]



========================================== PARAGRAPH 137 ===========================================

introduced by different researchers to deal with missing data  

------------------- Sentence 1 -------------------

introduced by different researchers to deal with missing data

>> Tokens are: 
 ['introduced', 'different', 'researchers', 'deal', 'missing', 'data']

>> Bigrams are: 
 [('introduced', 'different'), ('different', 'researchers'), ('researchers', 'deal'), ('deal', 'missing'), ('missing', 'data')]

>> Trigrams are: 
 [('introduced', 'different', 'researchers'), ('different', 'researchers', 'deal'), ('researchers', 'deal', 'missing'), ('deal', 'missing', 'data')]

>> POS Tags are: 
 [('introduced', 'VBN'), ('different', 'JJ'), ('researchers', 'NNS'), ('deal', 'VBP'), ('missing', 'VBG'), ('data', 'NNS')]

>> Noun Phrases are: 
 ['different researchers', 'data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('introduced', 'introduc'), ('different', 'differ'), ('researchers', 'research'), ('deal', 'deal'), ('missing', 'miss'), ('data', 'data')]

>> Stemming using Snowball Stemmer: 
 [('introduced', 'introduc'), ('different', 'differ'), ('researchers', 'research'), ('deal', 'deal'), ('missing', 'miss'), ('data', 'data')]

>> Lemmatization: 
 [('introduced', 'introduced'), ('different', 'different'), ('researchers', 'researcher'), ('deal', 'deal'), ('missing', 'missing'), ('data', 'data')]



========================================== PARAGRAPH 138 ===========================================

issue. Hodge & Austin [4] have conducted a survey of  

------------------- Sentence 1 -------------------

issue.

>> Tokens are: 
 ['issue', '.']

>> Bigrams are: 
 [('issue', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('issue', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['issue']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('issue', 'issu'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('issue', 'issu'), ('.', '.')]

>> Lemmatization: 
 [('issue', 'issue'), ('.', '.')]


------------------- Sentence 2 -------------------

Hodge & Austin [4] have conducted a survey of

>> Tokens are: 
 ['Hodge', '&', 'Austin', '[', '4', ']', 'conducted', 'survey']

>> Bigrams are: 
 [('Hodge', '&'), ('&', 'Austin'), ('Austin', '['), ('[', '4'), ('4', ']'), (']', 'conducted'), ('conducted', 'survey')]

>> Trigrams are: 
 [('Hodge', '&', 'Austin'), ('&', 'Austin', '['), ('Austin', '[', '4'), ('[', '4', ']'), ('4', ']', 'conducted'), (']', 'conducted', 'survey')]

>> POS Tags are: 
 [('Hodge', 'NNP'), ('&', 'CC'), ('Austin', 'NNP'), ('[', 'VBZ'), ('4', 'CD'), (']', 'NN'), ('conducted', 'VBN'), ('survey', 'NN')]

>> Noun Phrases are: 
 ['Hodge', 'Austin', ']', 'survey']

>> Named Entities are: 
 [('PERSON', 'Austin')] 

>> Stemming using Porter Stemmer: 
 [('Hodge', 'hodg'), ('&', '&'), ('Austin', 'austin'), ('[', '['), ('4', '4'), (']', ']'), ('conducted', 'conduct'), ('survey', 'survey')]

>> Stemming using Snowball Stemmer: 
 [('Hodge', 'hodg'), ('&', '&'), ('Austin', 'austin'), ('[', '['), ('4', '4'), (']', ']'), ('conducted', 'conduct'), ('survey', 'survey')]

>> Lemmatization: 
 [('Hodge', 'Hodge'), ('&', '&'), ('Austin', 'Austin'), ('[', '['), ('4', '4'), (']', ']'), ('conducted', 'conducted'), ('survey', 'survey')]



========================================== PARAGRAPH 139 ===========================================

contemporary techniques for outlier (noise) detection. Karanjit  

------------------- Sentence 1 -------------------

contemporary techniques for outlier (noise) detection.

>> Tokens are: 
 ['contemporary', 'techniques', 'outlier', '(', 'noise', ')', 'detection', '.']

>> Bigrams are: 
 [('contemporary', 'techniques'), ('techniques', 'outlier'), ('outlier', '('), ('(', 'noise'), ('noise', ')'), (')', 'detection'), ('detection', '.')]

>> Trigrams are: 
 [('contemporary', 'techniques', 'outlier'), ('techniques', 'outlier', '('), ('outlier', '(', 'noise'), ('(', 'noise', ')'), ('noise', ')', 'detection'), (')', 'detection', '.')]

>> POS Tags are: 
 [('contemporary', 'JJ'), ('techniques', 'NNS'), ('outlier', 'MD'), ('(', '('), ('noise', 'NN'), (')', ')'), ('detection', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['contemporary techniques', 'noise', 'detection']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('contemporary', 'contemporari'), ('techniques', 'techniqu'), ('outlier', 'outlier'), ('(', '('), ('noise', 'nois'), (')', ')'), ('detection', 'detect'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('contemporary', 'contemporari'), ('techniques', 'techniqu'), ('outlier', 'outlier'), ('(', '('), ('noise', 'nois'), (')', ')'), ('detection', 'detect'), ('.', '.')]

>> Lemmatization: 
 [('contemporary', 'contemporary'), ('techniques', 'technique'), ('outlier', 'outlier'), ('(', '('), ('noise', 'noise'), (')', ')'), ('detection', 'detection'), ('.', '.')]


------------------- Sentence 2 -------------------

Karanjit

>> Tokens are: 
 ['Karanjit']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Karanjit', 'NNP')]

>> Noun Phrases are: 
 ['Karanjit']

>> Named Entities are: 
 [('GPE', 'Karanjit')] 

>> Stemming using Porter Stemmer: 
 [('Karanjit', 'karanjit')]

>> Stemming using Snowball Stemmer: 
 [('Karanjit', 'karanjit')]

>> Lemmatization: 
 [('Karanjit', 'Karanjit')]



========================================== PARAGRAPH 140 ===========================================

& Shuchita [5] have also discussed different outlier detection  

------------------- Sentence 1 -------------------

& Shuchita [5] have also discussed different outlier detection

>> Tokens are: 
 ['&', 'Shuchita', '[', '5', ']', 'also', 'discussed', 'different', 'outlier', 'detection']

>> Bigrams are: 
 [('&', 'Shuchita'), ('Shuchita', '['), ('[', '5'), ('5', ']'), (']', 'also'), ('also', 'discussed'), ('discussed', 'different'), ('different', 'outlier'), ('outlier', 'detection')]

>> Trigrams are: 
 [('&', 'Shuchita', '['), ('Shuchita', '[', '5'), ('[', '5', ']'), ('5', ']', 'also'), (']', 'also', 'discussed'), ('also', 'discussed', 'different'), ('discussed', 'different', 'outlier'), ('different', 'outlier', 'detection')]

>> POS Tags are: 
 [('&', 'CC'), ('Shuchita', 'NNP'), ('[', 'VBZ'), ('5', 'CD'), (']', 'NN'), ('also', 'RB'), ('discussed', 'VBD'), ('different', 'JJ'), ('outlier', 'JJR'), ('detection', 'NN')]

>> Noun Phrases are: 
 ['Shuchita', ']', 'detection']

>> Named Entities are: 
 [('PERSON', 'Shuchita')] 

>> Stemming using Porter Stemmer: 
 [('&', '&'), ('Shuchita', 'shuchita'), ('[', '['), ('5', '5'), (']', ']'), ('also', 'also'), ('discussed', 'discuss'), ('different', 'differ'), ('outlier', 'outlier'), ('detection', 'detect')]

>> Stemming using Snowball Stemmer: 
 [('&', '&'), ('Shuchita', 'shuchita'), ('[', '['), ('5', '5'), (']', ']'), ('also', 'also'), ('discussed', 'discuss'), ('different', 'differ'), ('outlier', 'outlier'), ('detection', 'detect')]

>> Lemmatization: 
 [('&', '&'), ('Shuchita', 'Shuchita'), ('[', '['), ('5', '5'), (']', ']'), ('also', 'also'), ('discussed', 'discussed'), ('different', 'different'), ('outlier', 'outlier'), ('detection', 'detection')]



========================================== PARAGRAPH 141 ===========================================

methods which are being used in different machine learning. H.  

------------------- Sentence 1 -------------------

methods which are being used in different machine learning.

>> Tokens are: 
 ['methods', 'used', 'different', 'machine', 'learning', '.']

>> Bigrams are: 
 [('methods', 'used'), ('used', 'different'), ('different', 'machine'), ('machine', 'learning'), ('learning', '.')]

>> Trigrams are: 
 [('methods', 'used', 'different'), ('used', 'different', 'machine'), ('different', 'machine', 'learning'), ('machine', 'learning', '.')]

>> POS Tags are: 
 [('methods', 'NNS'), ('used', 'VBN'), ('different', 'JJ'), ('machine', 'NN'), ('learning', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['methods', 'different machine learning']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('methods', 'method'), ('used', 'use'), ('different', 'differ'), ('machine', 'machin'), ('learning', 'learn'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('methods', 'method'), ('used', 'use'), ('different', 'differ'), ('machine', 'machin'), ('learning', 'learn'), ('.', '.')]

>> Lemmatization: 
 [('methods', 'method'), ('used', 'used'), ('different', 'different'), ('machine', 'machine'), ('learning', 'learning'), ('.', '.')]


------------------- Sentence 2 -------------------

H.

>> Tokens are: 
 ['H', '.']

>> Bigrams are: 
 [('H', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('H', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['H']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('H', 'h'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('H', 'h'), ('.', '.')]

>> Lemmatization: 
 [('H', 'H'), ('.', '.')]



========================================== PARAGRAPH 142 ===========================================

Jair [6] has done comparison on 6 different outlier detection  

------------------- Sentence 1 -------------------

Jair [6] has done comparison on 6 different outlier detection

>> Tokens are: 
 ['Jair', '[', '6', ']', 'done', 'comparison', '6', 'different', 'outlier', 'detection']

>> Bigrams are: 
 [('Jair', '['), ('[', '6'), ('6', ']'), (']', 'done'), ('done', 'comparison'), ('comparison', '6'), ('6', 'different'), ('different', 'outlier'), ('outlier', 'detection')]

>> Trigrams are: 
 [('Jair', '[', '6'), ('[', '6', ']'), ('6', ']', 'done'), (']', 'done', 'comparison'), ('done', 'comparison', '6'), ('comparison', '6', 'different'), ('6', 'different', 'outlier'), ('different', 'outlier', 'detection')]

>> POS Tags are: 
 [('Jair', 'NNP'), ('[', 'VBZ'), ('6', 'CD'), (']', 'NN'), ('done', 'VBN'), ('comparison', 'NN'), ('6', 'CD'), ('different', 'JJ'), ('outlier', 'JJR'), ('detection', 'NN')]

>> Noun Phrases are: 
 ['Jair', ']', 'comparison', 'detection']

>> Named Entities are: 
 [('GPE', 'Jair')] 

>> Stemming using Porter Stemmer: 
 [('Jair', 'jair'), ('[', '['), ('6', '6'), (']', ']'), ('done', 'done'), ('comparison', 'comparison'), ('6', '6'), ('different', 'differ'), ('outlier', 'outlier'), ('detection', 'detect')]

>> Stemming using Snowball Stemmer: 
 [('Jair', 'jair'), ('[', '['), ('6', '6'), (']', ']'), ('done', 'done'), ('comparison', 'comparison'), ('6', '6'), ('different', 'differ'), ('outlier', 'outlier'), ('detection', 'detect')]

>> Lemmatization: 
 [('Jair', 'Jair'), ('[', '['), ('6', '6'), (']', ']'), ('done', 'done'), ('comparison', 'comparison'), ('6', '6'), ('different', 'different'), ('outlier', 'outlier'), ('detection', 'detection')]



========================================== PARAGRAPH 143 ===========================================

methods by performing experiment on benchmark datasets and a  

------------------- Sentence 1 -------------------

methods by performing experiment on benchmark datasets and a

>> Tokens are: 
 ['methods', 'performing', 'experiment', 'benchmark', 'datasets']

>> Bigrams are: 
 [('methods', 'performing'), ('performing', 'experiment'), ('experiment', 'benchmark'), ('benchmark', 'datasets')]

>> Trigrams are: 
 [('methods', 'performing', 'experiment'), ('performing', 'experiment', 'benchmark'), ('experiment', 'benchmark', 'datasets')]

>> POS Tags are: 
 [('methods', 'NNS'), ('performing', 'VBG'), ('experiment', 'JJ'), ('benchmark', 'NN'), ('datasets', 'NNS')]

>> Noun Phrases are: 
 ['methods', 'experiment benchmark datasets']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('methods', 'method'), ('performing', 'perform'), ('experiment', 'experi'), ('benchmark', 'benchmark'), ('datasets', 'dataset')]

>> Stemming using Snowball Stemmer: 
 [('methods', 'method'), ('performing', 'perform'), ('experiment', 'experi'), ('benchmark', 'benchmark'), ('datasets', 'dataset')]

>> Lemmatization: 
 [('methods', 'method'), ('performing', 'performing'), ('experiment', 'experiment'), ('benchmark', 'benchmark'), ('datasets', 'datasets')]



========================================== PARAGRAPH 144 ===========================================

synthetic astronomical domain.  

------------------- Sentence 1 -------------------

synthetic astronomical domain.

>> Tokens are: 
 ['synthetic', 'astronomical', 'domain', '.']

>> Bigrams are: 
 [('synthetic', 'astronomical'), ('astronomical', 'domain'), ('domain', '.')]

>> Trigrams are: 
 [('synthetic', 'astronomical', 'domain'), ('astronomical', 'domain', '.')]

>> POS Tags are: 
 [('synthetic', 'JJ'), ('astronomical', 'JJ'), ('domain', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['synthetic astronomical domain']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('synthetic', 'synthet'), ('astronomical', 'astronom'), ('domain', 'domain'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('synthetic', 'synthet'), ('astronomical', 'astronom'), ('domain', 'domain'), ('.', '.')]

>> Lemmatization: 
 [('synthetic', 'synthetic'), ('astronomical', 'astronomical'), ('domain', 'domain'), ('.', '.')]



========================================== PARAGRAPH 145 ===========================================

2.1 ALGORITHM SELECTION  

------------------- Sentence 1 -------------------

2.1 ALGORITHM SELECTION

>> Tokens are: 
 ['2.1', 'ALGORITHM', 'SELECTION']

>> Bigrams are: 
 [('2.1', 'ALGORITHM'), ('ALGORITHM', 'SELECTION')]

>> Trigrams are: 
 [('2.1', 'ALGORITHM', 'SELECTION')]

>> POS Tags are: 
 [('2.1', 'CD'), ('ALGORITHM', 'NNP'), ('SELECTION', 'NNP')]

>> Noun Phrases are: 
 ['ALGORITHM SELECTION']

>> Named Entities are: 
 [('ORGANIZATION', 'ALGORITHM')] 

>> Stemming using Porter Stemmer: 
 [('2.1', '2.1'), ('ALGORITHM', 'algorithm'), ('SELECTION', 'select')]

>> Stemming using Snowball Stemmer: 
 [('2.1', '2.1'), ('ALGORITHM', 'algorithm'), ('SELECTION', 'select')]

>> Lemmatization: 
 [('2.1', '2.1'), ('ALGORITHM', 'ALGORITHM'), ('SELECTION', 'SELECTION')]



========================================== PARAGRAPH 146 ===========================================

The selection of algorithm for achieving good results is an  

------------------- Sentence 1 -------------------

The selection of algorithm for achieving good results is an

>> Tokens are: 
 ['The', 'selection', 'algorithm', 'achieving', 'good', 'results']

>> Bigrams are: 
 [('The', 'selection'), ('selection', 'algorithm'), ('algorithm', 'achieving'), ('achieving', 'good'), ('good', 'results')]

>> Trigrams are: 
 [('The', 'selection', 'algorithm'), ('selection', 'algorithm', 'achieving'), ('algorithm', 'achieving', 'good'), ('achieving', 'good', 'results')]

>> POS Tags are: 
 [('The', 'DT'), ('selection', 'NN'), ('algorithm', 'IN'), ('achieving', 'VBG'), ('good', 'JJ'), ('results', 'NNS')]

>> Noun Phrases are: 
 ['The selection', 'good results']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('selection', 'select'), ('algorithm', 'algorithm'), ('achieving', 'achiev'), ('good', 'good'), ('results', 'result')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('selection', 'select'), ('algorithm', 'algorithm'), ('achieving', 'achiev'), ('good', 'good'), ('results', 'result')]

>> Lemmatization: 
 [('The', 'The'), ('selection', 'selection'), ('algorithm', 'algorithm'), ('achieving', 'achieving'), ('good', 'good'), ('results', 'result')]



========================================== PARAGRAPH 147 ===========================================

important step. The algorithm evaluation is mostly judge by  

------------------- Sentence 1 -------------------

important step.

>> Tokens are: 
 ['important', 'step', '.']

>> Bigrams are: 
 [('important', 'step'), ('step', '.')]

>> Trigrams are: 
 [('important', 'step', '.')]

>> POS Tags are: 
 [('important', 'JJ'), ('step', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['important step']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('important', 'import'), ('step', 'step'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('important', 'import'), ('step', 'step'), ('.', '.')]

>> Lemmatization: 
 [('important', 'important'), ('step', 'step'), ('.', '.')]


------------------- Sentence 2 -------------------

The algorithm evaluation is mostly judge by

>> Tokens are: 
 ['The', 'algorithm', 'evaluation', 'mostly', 'judge']

>> Bigrams are: 
 [('The', 'algorithm'), ('algorithm', 'evaluation'), ('evaluation', 'mostly'), ('mostly', 'judge')]

>> Trigrams are: 
 [('The', 'algorithm', 'evaluation'), ('algorithm', 'evaluation', 'mostly'), ('evaluation', 'mostly', 'judge')]

>> POS Tags are: 
 [('The', 'DT'), ('algorithm', 'JJ'), ('evaluation', 'NN'), ('mostly', 'RB'), ('judge', 'NN')]

>> Noun Phrases are: 
 ['The algorithm evaluation', 'judge']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('algorithm', 'algorithm'), ('evaluation', 'evalu'), ('mostly', 'mostli'), ('judge', 'judg')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('algorithm', 'algorithm'), ('evaluation', 'evalu'), ('mostly', 'most'), ('judge', 'judg')]

>> Lemmatization: 
 [('The', 'The'), ('algorithm', 'algorithm'), ('evaluation', 'evaluation'), ('mostly', 'mostly'), ('judge', 'judge')]



========================================== PARAGRAPH 148 ===========================================

prediction accuracy. The classifiers (Algorithm) evaluation is  

------------------- Sentence 1 -------------------

prediction accuracy.

>> Tokens are: 
 ['prediction', 'accuracy', '.']

>> Bigrams are: 
 [('prediction', 'accuracy'), ('accuracy', '.')]

>> Trigrams are: 
 [('prediction', 'accuracy', '.')]

>> POS Tags are: 
 [('prediction', 'NN'), ('accuracy', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['prediction accuracy']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('prediction', 'predict'), ('accuracy', 'accuraci'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('prediction', 'predict'), ('accuracy', 'accuraci'), ('.', '.')]

>> Lemmatization: 
 [('prediction', 'prediction'), ('accuracy', 'accuracy'), ('.', '.')]


------------------- Sentence 2 -------------------

The classifiers (Algorithm) evaluation is

>> Tokens are: 
 ['The', 'classifier', '', '(', 'Algorithm', ')', 'evaluation']

>> Bigrams are: 
 [('The', 'classifier'), ('classifier', ''), ('', '('), ('(', 'Algorithm'), ('Algorithm', ')'), (')', 'evaluation')]

>> Trigrams are: 
 [('The', 'classifier', ''), ('classifier', '', '('), ('', '(', 'Algorithm'), ('(', 'Algorithm', ')'), ('Algorithm', ')', 'evaluation')]

>> POS Tags are: 
 [('The', 'DT'), ('classifier', 'NN'), ('', 'NNP'), ('(', '('), ('Algorithm', 'NNP'), (')', ')'), ('evaluation', 'NN')]

>> Noun Phrases are: 
 ['The classifier ', 'Algorithm', 'evaluation']

>> Named Entities are: 
 [('ORGANIZATION', 'Algorithm')] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('classifier', 'classifi'), ('', ''), ('(', '('), ('Algorithm', 'algorithm'), (')', ')'), ('evaluation', 'evalu')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('classifier', 'classifi'), ('', ''), ('(', '('), ('Algorithm', 'algorithm'), (')', ')'), ('evaluation', 'evalu')]

>> Lemmatization: 
 [('The', 'The'), ('classifier', 'classifier'), ('', ''), ('(', '('), ('Algorithm', 'Algorithm'), (')', ')'), ('evaluation', 'evaluation')]



========================================== PARAGRAPH 149 ===========================================

most often based on prediction accuracy and it can be measured  

------------------- Sentence 1 -------------------

most often based on prediction accuracy and it can be measured

>> Tokens are: 
 ['often', 'based', 'prediction', 'accuracy', 'measured']

>> Bigrams are: 
 [('often', 'based'), ('based', 'prediction'), ('prediction', 'accuracy'), ('accuracy', 'measured')]

>> Trigrams are: 
 [('often', 'based', 'prediction'), ('based', 'prediction', 'accuracy'), ('prediction', 'accuracy', 'measured')]

>> POS Tags are: 
 [('often', 'RB'), ('based', 'VBN'), ('prediction', 'NN'), ('accuracy', 'NN'), ('measured', 'VBD')]

>> Noun Phrases are: 
 ['prediction accuracy']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('often', 'often'), ('based', 'base'), ('prediction', 'predict'), ('accuracy', 'accuraci'), ('measured', 'measur')]

>> Stemming using Snowball Stemmer: 
 [('often', 'often'), ('based', 'base'), ('prediction', 'predict'), ('accuracy', 'accuraci'), ('measured', 'measur')]

>> Lemmatization: 
 [('often', 'often'), ('based', 'based'), ('prediction', 'prediction'), ('accuracy', 'accuracy'), ('measured', 'measured')]



========================================== PARAGRAPH 150 ===========================================

by given below formula  

------------------- Sentence 1 -------------------

by given below formula

>> Tokens are: 
 ['given', 'formula']

>> Bigrams are: 
 [('given', 'formula')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('given', 'VBN'), ('formula', 'NN')]

>> Noun Phrases are: 
 ['formula']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('given', 'given'), ('formula', 'formula')]

>> Stemming using Snowball Stemmer: 
 [('given', 'given'), ('formula', 'formula')]

>> Lemmatization: 
 [('given', 'given'), ('formula', 'formula')]



========================================== PARAGRAPH 151 ===========================================

  cases test of number Total 

------------------- Sentence 1 -------------------

  cases test of number Total

>> Tokens are: 
 ['cases', 'test', 'number', 'Total']

>> Bigrams are: 
 [('cases', 'test'), ('test', 'number'), ('number', 'Total')]

>> Trigrams are: 
 [('cases', 'test', 'number'), ('test', 'number', 'Total')]

>> POS Tags are: 
 [('cases', 'NNS'), ('test', 'VBP'), ('number', 'NN'), ('Total', 'NN')]

>> Noun Phrases are: 
 ['cases', 'number Total']

>> Named Entities are: 
 [('ORGANIZATION', 'Total')] 

>> Stemming using Porter Stemmer: 
 [('cases', 'case'), ('test', 'test'), ('number', 'number'), ('Total', 'total')]

>> Stemming using Snowball Stemmer: 
 [('cases', 'case'), ('test', 'test'), ('number', 'number'), ('Total', 'total')]

>> Lemmatization: 
 [('cases', 'case'), ('test', 'test'), ('number', 'number'), ('Total', 'Total')]



========================================== PARAGRAPH 152 ===========================================

tionsclassifica Correct of Number Accuracy   (1)  

------------------- Sentence 1 -------------------

tionsclassifica Correct of Number Accuracy   (1)

>> Tokens are: 
 ['tionsclassifica', 'Correct', 'Number', 'Accuracy', '\uf03d', '(', '1', ')']

>> Bigrams are: 
 [('tionsclassifica', 'Correct'), ('Correct', 'Number'), ('Number', 'Accuracy'), ('Accuracy', '\uf03d'), ('\uf03d', '('), ('(', '1'), ('1', ')')]

>> Trigrams are: 
 [('tionsclassifica', 'Correct', 'Number'), ('Correct', 'Number', 'Accuracy'), ('Number', 'Accuracy', '\uf03d'), ('Accuracy', '\uf03d', '('), ('\uf03d', '(', '1'), ('(', '1', ')')]

>> POS Tags are: 
 [('tionsclassifica', 'NN'), ('Correct', 'NNP'), ('Number', 'NNP'), ('Accuracy', 'NNP'), ('\uf03d', 'NNP'), ('(', '('), ('1', 'CD'), (')', ')')]

>> Noun Phrases are: 
 ['tionsclassifica Correct Number Accuracy \uf03d']

>> Named Entities are: 
 [('PERSON', 'Correct Number Accuracy')] 

>> Stemming using Porter Stemmer: 
 [('tionsclassifica', 'tionsclassifica'), ('Correct', 'correct'), ('Number', 'number'), ('Accuracy', 'accuraci'), ('\uf03d', '\uf03d'), ('(', '('), ('1', '1'), (')', ')')]

>> Stemming using Snowball Stemmer: 
 [('tionsclassifica', 'tionsclassifica'), ('Correct', 'correct'), ('Number', 'number'), ('Accuracy', 'accuraci'), ('\uf03d', '\uf03d'), ('(', '('), ('1', '1'), (')', ')')]

>> Lemmatization: 
 [('tionsclassifica', 'tionsclassifica'), ('Correct', 'Correct'), ('Number', 'Number'), ('Accuracy', 'Accuracy'), ('\uf03d', '\uf03d'), ('(', '('), ('1', '1'), (')', ')')]



========================================== PARAGRAPH 153 ===========================================

There are number of methods which are being used by  

------------------- Sentence 1 -------------------

There are number of methods which are being used by

>> Tokens are: 
 ['There', 'number', 'methods', 'used']

>> Bigrams are: 
 [('There', 'number'), ('number', 'methods'), ('methods', 'used')]

>> Trigrams are: 
 [('There', 'number', 'methods'), ('number', 'methods', 'used')]

>> POS Tags are: 
 [('There', 'EX'), ('number', 'NN'), ('methods', 'NNS'), ('used', 'VBD')]

>> Noun Phrases are: 
 ['number methods']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('There', 'there'), ('number', 'number'), ('methods', 'method'), ('used', 'use')]

>> Stemming using Snowball Stemmer: 
 [('There', 'there'), ('number', 'number'), ('methods', 'method'), ('used', 'use')]

>> Lemmatization: 
 [('There', 'There'), ('number', 'number'), ('methods', 'method'), ('used', 'used')]



========================================== PARAGRAPH 154 ===========================================

different researchers to calculate classifiers accuracy. Some  

------------------- Sentence 1 -------------------

different researchers to calculate classifiers accuracy.

>> Tokens are: 
 ['different', 'researchers', 'calculate', 'classifier', '', 'accuracy', '.']

>> Bigrams are: 
 [('different', 'researchers'), ('researchers', 'calculate'), ('calculate', 'classifier'), ('classifier', ''), ('', 'accuracy'), ('accuracy', '.')]

>> Trigrams are: 
 [('different', 'researchers', 'calculate'), ('researchers', 'calculate', 'classifier'), ('calculate', 'classifier', ''), ('classifier', '', 'accuracy'), ('', 'accuracy', '.')]

>> POS Tags are: 
 [('different', 'JJ'), ('researchers', 'NNS'), ('calculate', 'VBP'), ('classifier', 'JJR'), ('', 'JJ'), ('accuracy', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['different researchers', ' accuracy']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('different', 'differ'), ('researchers', 'research'), ('calculate', 'calcul'), ('classifier', 'classifi'), ('', ''), ('accuracy', 'accuraci'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('different', 'differ'), ('researchers', 'research'), ('calculate', 'calcul'), ('classifier', 'classifi'), ('', ''), ('accuracy', 'accuraci'), ('.', '.')]

>> Lemmatization: 
 [('different', 'different'), ('researchers', 'researcher'), ('calculate', 'calculate'), ('classifier', 'classifier'), ('', ''), ('accuracy', 'accuracy'), ('.', '.')]


------------------- Sentence 2 -------------------

Some

>> Tokens are: 
 ['Some']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Some', 'DT')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Some', 'some')]

>> Stemming using Snowball Stemmer: 
 [('Some', 'some')]

>> Lemmatization: 
 [('Some', 'Some')]



========================================== PARAGRAPH 155 ===========================================

researchers splits the training set in such a way that, two-thirds  

------------------- Sentence 1 -------------------

researchers splits the training set in such a way that, two-thirds

>> Tokens are: 
 ['researcher', '', 'splits', 'training', 'set', 'way', ',', 'two-thirds']

>> Bigrams are: 
 [('researcher', ''), ('', 'splits'), ('splits', 'training'), ('training', 'set'), ('set', 'way'), ('way', ','), (',', 'two-thirds')]

>> Trigrams are: 
 [('researcher', '', 'splits'), ('', 'splits', 'training'), ('splits', 'training', 'set'), ('training', 'set', 'way'), ('set', 'way', ','), ('way', ',', 'two-thirds')]

>> POS Tags are: 
 [('researcher', 'NN'), ('', 'NN'), ('splits', 'NNS'), ('training', 'VBG'), ('set', 'JJ'), ('way', 'NN'), (',', ','), ('two-thirds', 'NNS')]

>> Noun Phrases are: 
 ['researcher  splits', 'set way', 'two-thirds']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('researcher', 'research'), ('', ''), ('splits', 'split'), ('training', 'train'), ('set', 'set'), ('way', 'way'), (',', ','), ('two-thirds', 'two-third')]

>> Stemming using Snowball Stemmer: 
 [('researcher', 'research'), ('', ''), ('splits', 'split'), ('training', 'train'), ('set', 'set'), ('way', 'way'), (',', ','), ('two-thirds', 'two-third')]

>> Lemmatization: 
 [('researcher', 'researcher'), ('', ''), ('splits', 'split'), ('training', 'training'), ('set', 'set'), ('way', 'way'), (',', ','), ('two-thirds', 'two-thirds')]



========================================== PARAGRAPH 156 ===========================================

retain for training and the other third for estimating performance.  

------------------- Sentence 1 -------------------

retain for training and the other third for estimating performance.

>> Tokens are: 
 ['retain', 'training', 'third', 'estimating', 'performance', '.']

>> Bigrams are: 
 [('retain', 'training'), ('training', 'third'), ('third', 'estimating'), ('estimating', 'performance'), ('performance', '.')]

>> Trigrams are: 
 [('retain', 'training', 'third'), ('training', 'third', 'estimating'), ('third', 'estimating', 'performance'), ('estimating', 'performance', '.')]

>> POS Tags are: 
 [('retain', 'NN'), ('training', 'NN'), ('third', 'JJ'), ('estimating', 'VBG'), ('performance', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['retain training', 'performance']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('retain', 'retain'), ('training', 'train'), ('third', 'third'), ('estimating', 'estim'), ('performance', 'perform'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('retain', 'retain'), ('training', 'train'), ('third', 'third'), ('estimating', 'estim'), ('performance', 'perform'), ('.', '.')]

>> Lemmatization: 
 [('retain', 'retain'), ('training', 'training'), ('third', 'third'), ('estimating', 'estimating'), ('performance', 'performance'), ('.', '.')]



========================================== PARAGRAPH 157 ===========================================

Cross-Validation (CV) or Rotation Estimation is another  

------------------- Sentence 1 -------------------

Cross-Validation (CV) or Rotation Estimation is another

>> Tokens are: 
 ['Cross-Validation', '(', 'CV', ')', 'Rotation', 'Estimation', 'another']

>> Bigrams are: 
 [('Cross-Validation', '('), ('(', 'CV'), ('CV', ')'), (')', 'Rotation'), ('Rotation', 'Estimation'), ('Estimation', 'another')]

>> Trigrams are: 
 [('Cross-Validation', '(', 'CV'), ('(', 'CV', ')'), ('CV', ')', 'Rotation'), (')', 'Rotation', 'Estimation'), ('Rotation', 'Estimation', 'another')]

>> POS Tags are: 
 [('Cross-Validation', 'NN'), ('(', '('), ('CV', 'NNP'), (')', ')'), ('Rotation', 'NNP'), ('Estimation', 'NNP'), ('another', 'DT')]

>> Noun Phrases are: 
 ['Cross-Validation', 'CV', 'Rotation Estimation']

>> Named Entities are: 
 [('PERSON', 'Rotation Estimation')] 

>> Stemming using Porter Stemmer: 
 [('Cross-Validation', 'cross-valid'), ('(', '('), ('CV', 'cv'), (')', ')'), ('Rotation', 'rotat'), ('Estimation', 'estim'), ('another', 'anoth')]

>> Stemming using Snowball Stemmer: 
 [('Cross-Validation', 'cross-valid'), ('(', '('), ('CV', 'cv'), (')', ')'), ('Rotation', 'rotat'), ('Estimation', 'estim'), ('another', 'anoth')]

>> Lemmatization: 
 [('Cross-Validation', 'Cross-Validation'), ('(', '('), ('CV', 'CV'), (')', ')'), ('Rotation', 'Rotation'), ('Estimation', 'Estimation'), ('another', 'another')]



========================================== PARAGRAPH 158 ===========================================

approach. CV provides a way to make a better use of the  

------------------- Sentence 1 -------------------

approach.

>> Tokens are: 
 ['approach', '.']

>> Bigrams are: 
 [('approach', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('approach', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['approach']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('approach', 'approach'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('approach', 'approach'), ('.', '.')]

>> Lemmatization: 
 [('approach', 'approach'), ('.', '.')]


------------------- Sentence 2 -------------------

CV provides a way to make a better use of the

>> Tokens are: 
 ['CV', 'provides', 'way', 'make', 'better', 'use']

>> Bigrams are: 
 [('CV', 'provides'), ('provides', 'way'), ('way', 'make'), ('make', 'better'), ('better', 'use')]

>> Trigrams are: 
 [('CV', 'provides', 'way'), ('provides', 'way', 'make'), ('way', 'make', 'better'), ('make', 'better', 'use')]

>> POS Tags are: 
 [('CV', 'NNP'), ('provides', 'VBZ'), ('way', 'NN'), ('make', 'VBP'), ('better', 'JJR'), ('use', 'NN')]

>> Noun Phrases are: 
 ['CV', 'way', 'use']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('CV', 'cv'), ('provides', 'provid'), ('way', 'way'), ('make', 'make'), ('better', 'better'), ('use', 'use')]

>> Stemming using Snowball Stemmer: 
 [('CV', 'cv'), ('provides', 'provid'), ('way', 'way'), ('make', 'make'), ('better', 'better'), ('use', 'use')]

>> Lemmatization: 
 [('CV', 'CV'), ('provides', 'provides'), ('way', 'way'), ('make', 'make'), ('better', 'better'), ('use', 'use')]



========================================== PARAGRAPH 159 ===========================================

available sample. In k-fold cross-validation scheme, we divide  

------------------- Sentence 1 -------------------

available sample.

>> Tokens are: 
 ['available', 'sample', '.']

>> Bigrams are: 
 [('available', 'sample'), ('sample', '.')]

>> Trigrams are: 
 [('available', 'sample', '.')]

>> POS Tags are: 
 [('available', 'JJ'), ('sample', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['available sample']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('available', 'avail'), ('sample', 'sampl'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('available', 'avail'), ('sample', 'sampl'), ('.', '.')]

>> Lemmatization: 
 [('available', 'available'), ('sample', 'sample'), ('.', '.')]


------------------- Sentence 2 -------------------

In k-fold cross-validation scheme, we divide

>> Tokens are: 
 ['In', 'k-fold', 'cross-validation', 'scheme', ',', 'divide']

>> Bigrams are: 
 [('In', 'k-fold'), ('k-fold', 'cross-validation'), ('cross-validation', 'scheme'), ('scheme', ','), (',', 'divide')]

>> Trigrams are: 
 [('In', 'k-fold', 'cross-validation'), ('k-fold', 'cross-validation', 'scheme'), ('cross-validation', 'scheme', ','), ('scheme', ',', 'divide')]

>> POS Tags are: 
 [('In', 'IN'), ('k-fold', 'JJ'), ('cross-validation', 'NN'), ('scheme', 'NN'), (',', ','), ('divide', 'NN')]

>> Noun Phrases are: 
 ['k-fold cross-validation scheme', 'divide']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('k-fold', 'k-fold'), ('cross-validation', 'cross-valid'), ('scheme', 'scheme'), (',', ','), ('divide', 'divid')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('k-fold', 'k-fold'), ('cross-validation', 'cross-valid'), ('scheme', 'scheme'), (',', ','), ('divide', 'divid')]

>> Lemmatization: 
 [('In', 'In'), ('k-fold', 'k-fold'), ('cross-validation', 'cross-validation'), ('scheme', 'scheme'), (',', ','), ('divide', 'divide')]



========================================== PARAGRAPH 160 ===========================================

the learning sample into k disjoint subsets of the same size, i.e.-  

------------------- Sentence 1 -------------------

the learning sample into k disjoint subsets of the same size, i.e.-

>> Tokens are: 
 ['learning', 'sample', 'k', 'disjoint', 'subsets', 'size', ',', 'i.e.-']

>> Bigrams are: 
 [('learning', 'sample'), ('sample', 'k'), ('k', 'disjoint'), ('disjoint', 'subsets'), ('subsets', 'size'), ('size', ','), (',', 'i.e.-')]

>> Trigrams are: 
 [('learning', 'sample', 'k'), ('sample', 'k', 'disjoint'), ('k', 'disjoint', 'subsets'), ('disjoint', 'subsets', 'size'), ('subsets', 'size', ','), ('size', ',', 'i.e.-')]

>> POS Tags are: 
 [('learning', 'VBG'), ('sample', 'JJ'), ('k', 'NNS'), ('disjoint', 'JJ'), ('subsets', 'NNS'), ('size', 'NN'), (',', ','), ('i.e.-', 'JJ')]

>> Noun Phrases are: 
 ['sample k', 'disjoint subsets size']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('learning', 'learn'), ('sample', 'sampl'), ('k', 'k'), ('disjoint', 'disjoint'), ('subsets', 'subset'), ('size', 'size'), (',', ','), ('i.e.-', 'i.e.-')]

>> Stemming using Snowball Stemmer: 
 [('learning', 'learn'), ('sample', 'sampl'), ('k', 'k'), ('disjoint', 'disjoint'), ('subsets', 'subset'), ('size', 'size'), (',', ','), ('i.e.-', 'i.e.-')]

>> Lemmatization: 
 [('learning', 'learning'), ('sample', 'sample'), ('k', 'k'), ('disjoint', 'disjoint'), ('subsets', 'subset'), ('size', 'size'), (',', ','), ('i.e.-', 'i.e.-')]



========================================== PARAGRAPH 161 ===========================================

 klslslsls  211  (2)  

------------------- Sentence 1 -------------------

 klslslsls  211  (2)

>> Tokens are: 
 ['klslslsls', '\uf0c8\uf0c8\uf03d', '211', '(', '2', ')']

>> Bigrams are: 
 [('klslslsls', '\uf0c8\uf0c8\uf03d'), ('\uf0c8\uf0c8\uf03d', '211'), ('211', '('), ('(', '2'), ('2', ')')]

>> Trigrams are: 
 [('klslslsls', '\uf0c8\uf0c8\uf03d', '211'), ('\uf0c8\uf0c8\uf03d', '211', '('), ('211', '(', '2'), ('(', '2', ')')]

>> POS Tags are: 
 [('klslslsls', 'NN'), ('\uf0c8\uf0c8\uf03d', 'VBZ'), ('211', 'CD'), ('(', '('), ('2', 'CD'), (')', ')')]

>> Noun Phrases are: 
 ['klslslsls']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('klslslsls', 'klslslsl'), ('\uf0c8\uf0c8\uf03d', '\uf0c8\uf0c8\uf03d'), ('211', '211'), ('(', '('), ('2', '2'), (')', ')')]

>> Stemming using Snowball Stemmer: 
 [('klslslsls', 'klslslsls'), ('\uf0c8\uf0c8\uf03d', '\uf0c8\uf0c8\uf03d'), ('211', '211'), ('(', '('), ('2', '2'), (')', ')')]

>> Lemmatization: 
 [('klslslsls', 'klslslsls'), ('\uf0c8\uf0c8\uf03d', '\uf0c8\uf0c8\uf03d'), ('211', '211'), ('(', '('), ('2', '2'), (')', ')')]



========================================== PARAGRAPH 162 ===========================================

A model is then inferred by the learning algorithm from each  

------------------- Sentence 1 -------------------

A model is then inferred by the learning algorithm from each

>> Tokens are: 
 ['A', 'model', 'inferred', 'learning', 'algorithm']

>> Bigrams are: 
 [('A', 'model'), ('model', 'inferred'), ('inferred', 'learning'), ('learning', 'algorithm')]

>> Trigrams are: 
 [('A', 'model', 'inferred'), ('model', 'inferred', 'learning'), ('inferred', 'learning', 'algorithm')]

>> POS Tags are: 
 [('A', 'DT'), ('model', 'NN'), ('inferred', 'JJ'), ('learning', 'NN'), ('algorithm', 'NN')]

>> Noun Phrases are: 
 ['A model', 'inferred learning algorithm']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('A', 'a'), ('model', 'model'), ('inferred', 'infer'), ('learning', 'learn'), ('algorithm', 'algorithm')]

>> Stemming using Snowball Stemmer: 
 [('A', 'a'), ('model', 'model'), ('inferred', 'infer'), ('learning', 'learn'), ('algorithm', 'algorithm')]

>> Lemmatization: 
 [('A', 'A'), ('model', 'model'), ('inferred', 'inferred'), ('learning', 'learning'), ('algorithm', 'algorithm')]



========================================== PARAGRAPH 163 ===========================================

sample ls\ls, i = 1,..,k and its performance is determined on the  

------------------- Sentence 1 -------------------

sample ls\ls, i = 1,..,k and its performance is determined on the

>> Tokens are: 
 ['sample', 'ls\\ls', ',', '=', '1', ',', '..', ',', 'k', 'performance', 'determined']

>> Bigrams are: 
 [('sample', 'ls\\ls'), ('ls\\ls', ','), (',', '='), ('=', '1'), ('1', ','), (',', '..'), ('..', ','), (',', 'k'), ('k', 'performance'), ('performance', 'determined')]

>> Trigrams are: 
 [('sample', 'ls\\ls', ','), ('ls\\ls', ',', '='), (',', '=', '1'), ('=', '1', ','), ('1', ',', '..'), (',', '..', ','), ('..', ',', 'k'), (',', 'k', 'performance'), ('k', 'performance', 'determined')]

>> POS Tags are: 
 [('sample', 'NN'), ('ls\\ls', 'NN'), (',', ','), ('=', "''"), ('1', 'CD'), (',', ','), ('..', 'NNP'), (',', ','), ('k', 'VBD'), ('performance', 'NN'), ('determined', 'VBD')]

>> Noun Phrases are: 
 ['sample ls\\ls', '..', 'performance']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('sample', 'sampl'), ('ls\\ls', 'ls\\l'), (',', ','), ('=', '='), ('1', '1'), (',', ','), ('..', '..'), (',', ','), ('k', 'k'), ('performance', 'perform'), ('determined', 'determin')]

>> Stemming using Snowball Stemmer: 
 [('sample', 'sampl'), ('ls\\ls', 'ls\\ls'), (',', ','), ('=', '='), ('1', '1'), (',', ','), ('..', '..'), (',', ','), ('k', 'k'), ('performance', 'perform'), ('determined', 'determin')]

>> Lemmatization: 
 [('sample', 'sample'), ('ls\\ls', 'ls\\ls'), (',', ','), ('=', '='), ('1', '1'), (',', ','), ('..', '..'), (',', ','), ('k', 'k'), ('performance', 'performance'), ('determined', 'determined')]



========================================== PARAGRAPH 164 ===========================================

held out sample lsi. Final performance is computed as the  

------------------- Sentence 1 -------------------

held out sample lsi.

>> Tokens are: 
 ['held', 'sample', 'lsi', '.']

>> Bigrams are: 
 [('held', 'sample'), ('sample', 'lsi'), ('lsi', '.')]

>> Trigrams are: 
 [('held', 'sample', 'lsi'), ('sample', 'lsi', '.')]

>> POS Tags are: 
 [('held', 'VBN'), ('sample', 'JJ'), ('lsi', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['sample lsi']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('held', 'held'), ('sample', 'sampl'), ('lsi', 'lsi'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('held', 'held'), ('sample', 'sampl'), ('lsi', 'lsi'), ('.', '.')]

>> Lemmatization: 
 [('held', 'held'), ('sample', 'sample'), ('lsi', 'lsi'), ('.', '.')]


------------------- Sentence 2 -------------------

Final performance is computed as the

>> Tokens are: 
 ['Final', 'performance', 'computed']

>> Bigrams are: 
 [('Final', 'performance'), ('performance', 'computed')]

>> Trigrams are: 
 [('Final', 'performance', 'computed')]

>> POS Tags are: 
 [('Final', 'JJ'), ('performance', 'NN'), ('computed', 'VBD')]

>> Noun Phrases are: 
 ['Final performance']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Final', 'final'), ('performance', 'perform'), ('computed', 'comput')]

>> Stemming using Snowball Stemmer: 
 [('Final', 'final'), ('performance', 'perform'), ('computed', 'comput')]

>> Lemmatization: 
 [('Final', 'Final'), ('performance', 'performance'), ('computed', 'computed')]



========================================== PARAGRAPH 165 ===========================================

average performance over all these models. Notice that when k is  

------------------- Sentence 1 -------------------

average performance over all these models.

>> Tokens are: 
 ['average', 'performance', 'models', '.']

>> Bigrams are: 
 [('average', 'performance'), ('performance', 'models'), ('models', '.')]

>> Trigrams are: 
 [('average', 'performance', 'models'), ('performance', 'models', '.')]

>> POS Tags are: 
 [('average', 'JJ'), ('performance', 'NN'), ('models', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['average performance models']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('average', 'averag'), ('performance', 'perform'), ('models', 'model'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('average', 'averag'), ('performance', 'perform'), ('models', 'model'), ('.', '.')]

>> Lemmatization: 
 [('average', 'average'), ('performance', 'performance'), ('models', 'model'), ('.', '.')]


------------------- Sentence 2 -------------------

Notice that when k is

>> Tokens are: 
 ['Notice', 'k']

>> Bigrams are: 
 [('Notice', 'k')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Notice', 'NNP'), ('k', 'NN')]

>> Noun Phrases are: 
 ['Notice k']

>> Named Entities are: 
 [('GPE', 'Notice')] 

>> Stemming using Porter Stemmer: 
 [('Notice', 'notic'), ('k', 'k')]

>> Stemming using Snowball Stemmer: 
 [('Notice', 'notic'), ('k', 'k')]

>> Lemmatization: 
 [('Notice', 'Notice'), ('k', 'k')]



========================================== PARAGRAPH 166 ===========================================

equal to the number of objects in the learning sample, this  

------------------- Sentence 1 -------------------

equal to the number of objects in the learning sample, this

>> Tokens are: 
 ['equal', 'number', 'objects', 'learning', 'sample', ',']

>> Bigrams are: 
 [('equal', 'number'), ('number', 'objects'), ('objects', 'learning'), ('learning', 'sample'), ('sample', ',')]

>> Trigrams are: 
 [('equal', 'number', 'objects'), ('number', 'objects', 'learning'), ('objects', 'learning', 'sample'), ('learning', 'sample', ',')]

>> POS Tags are: 
 [('equal', 'JJ'), ('number', 'NN'), ('objects', 'NNS'), ('learning', 'VBG'), ('sample', 'NN'), (',', ',')]

>> Noun Phrases are: 
 ['equal number objects', 'sample']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('equal', 'equal'), ('number', 'number'), ('objects', 'object'), ('learning', 'learn'), ('sample', 'sampl'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('equal', 'equal'), ('number', 'number'), ('objects', 'object'), ('learning', 'learn'), ('sample', 'sampl'), (',', ',')]

>> Lemmatization: 
 [('equal', 'equal'), ('number', 'number'), ('objects', 'object'), ('learning', 'learning'), ('sample', 'sample'), (',', ',')]



========================================== PARAGRAPH 167 ===========================================

method is called leave-one-out. Typically, smaller values of k  

------------------- Sentence 1 -------------------

method is called leave-one-out.

>> Tokens are: 
 ['method', 'called', 'leave-one-out', '.']

>> Bigrams are: 
 [('method', 'called'), ('called', 'leave-one-out'), ('leave-one-out', '.')]

>> Trigrams are: 
 [('method', 'called', 'leave-one-out'), ('called', 'leave-one-out', '.')]

>> POS Tags are: 
 [('method', 'NN'), ('called', 'VBN'), ('leave-one-out', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['method', 'leave-one-out']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('method', 'method'), ('called', 'call'), ('leave-one-out', 'leave-one-out'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('method', 'method'), ('called', 'call'), ('leave-one-out', 'leave-one-out'), ('.', '.')]

>> Lemmatization: 
 [('method', 'method'), ('called', 'called'), ('leave-one-out', 'leave-one-out'), ('.', '.')]


------------------- Sentence 2 -------------------

Typically, smaller values of k

>> Tokens are: 
 ['Typically', ',', 'smaller', 'values', 'k']

>> Bigrams are: 
 [('Typically', ','), (',', 'smaller'), ('smaller', 'values'), ('values', 'k')]

>> Trigrams are: 
 [('Typically', ',', 'smaller'), (',', 'smaller', 'values'), ('smaller', 'values', 'k')]

>> POS Tags are: 
 [('Typically', 'RB'), (',', ','), ('smaller', 'JJR'), ('values', 'NNS'), ('k', 'VBP')]

>> Noun Phrases are: 
 ['values']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Typically', 'typic'), (',', ','), ('smaller', 'smaller'), ('values', 'valu'), ('k', 'k')]

>> Stemming using Snowball Stemmer: 
 [('Typically', 'typic'), (',', ','), ('smaller', 'smaller'), ('values', 'valu'), ('k', 'k')]

>> Lemmatization: 
 [('Typically', 'Typically'), (',', ','), ('smaller', 'smaller'), ('values', 'value'), ('k', 'k')]



========================================== PARAGRAPH 168 ===========================================

(10 or 20) are however preferred for computational reasons [7].  

------------------- Sentence 1 -------------------

(10 or 20) are however preferred for computational reasons [7].

>> Tokens are: 
 ['(', '10', '20', ')', 'however', 'preferred', 'computational', 'reasons', '[', '7', ']', '.']

>> Bigrams are: 
 [('(', '10'), ('10', '20'), ('20', ')'), (')', 'however'), ('however', 'preferred'), ('preferred', 'computational'), ('computational', 'reasons'), ('reasons', '['), ('[', '7'), ('7', ']'), (']', '.')]

>> Trigrams are: 
 [('(', '10', '20'), ('10', '20', ')'), ('20', ')', 'however'), (')', 'however', 'preferred'), ('however', 'preferred', 'computational'), ('preferred', 'computational', 'reasons'), ('computational', 'reasons', '['), ('reasons', '[', '7'), ('[', '7', ']'), ('7', ']', '.')]

>> POS Tags are: 
 [('(', '('), ('10', 'CD'), ('20', 'CD'), (')', ')'), ('however', 'RB'), ('preferred', 'JJ'), ('computational', 'JJ'), ('reasons', 'NNS'), ('[', 'VBP'), ('7', 'CD'), (']', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['preferred computational reasons', ']']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('10', '10'), ('20', '20'), (')', ')'), ('however', 'howev'), ('preferred', 'prefer'), ('computational', 'comput'), ('reasons', 'reason'), ('[', '['), ('7', '7'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('10', '10'), ('20', '20'), (')', ')'), ('however', 'howev'), ('preferred', 'prefer'), ('computational', 'comput'), ('reasons', 'reason'), ('[', '['), ('7', '7'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('(', '('), ('10', '10'), ('20', '20'), (')', ')'), ('however', 'however'), ('preferred', 'preferred'), ('computational', 'computational'), ('reasons', 'reason'), ('[', '['), ('7', '7'), (']', ']'), ('.', '.')]



========================================== PARAGRAPH 169 ===========================================

The comparison between supervised ML methods can be done  

------------------- Sentence 1 -------------------

The comparison between supervised ML methods can be done

>> Tokens are: 
 ['The', 'comparison', 'supervised', 'ML', 'methods', 'done']

>> Bigrams are: 
 [('The', 'comparison'), ('comparison', 'supervised'), ('supervised', 'ML'), ('ML', 'methods'), ('methods', 'done')]

>> Trigrams are: 
 [('The', 'comparison', 'supervised'), ('comparison', 'supervised', 'ML'), ('supervised', 'ML', 'methods'), ('ML', 'methods', 'done')]

>> POS Tags are: 
 [('The', 'DT'), ('comparison', 'NN'), ('supervised', 'VBD'), ('ML', 'NNP'), ('methods', 'NNS'), ('done', 'VBN')]

>> Noun Phrases are: 
 ['The comparison', 'ML methods']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('comparison', 'comparison'), ('supervised', 'supervis'), ('ML', 'ml'), ('methods', 'method'), ('done', 'done')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('comparison', 'comparison'), ('supervised', 'supervis'), ('ML', 'ml'), ('methods', 'method'), ('done', 'done')]

>> Lemmatization: 
 [('The', 'The'), ('comparison', 'comparison'), ('supervised', 'supervised'), ('ML', 'ML'), ('methods', 'method'), ('done', 'done')]



========================================== PARAGRAPH 170 ===========================================

through to perform statistical comparisons of the accuracies of  

------------------- Sentence 1 -------------------

through to perform statistical comparisons of the accuracies of

>> Tokens are: 
 ['perform', 'statistical', 'comparisons', 'accuracies']

>> Bigrams are: 
 [('perform', 'statistical'), ('statistical', 'comparisons'), ('comparisons', 'accuracies')]

>> Trigrams are: 
 [('perform', 'statistical', 'comparisons'), ('statistical', 'comparisons', 'accuracies')]

>> POS Tags are: 
 [('perform', 'VB'), ('statistical', 'JJ'), ('comparisons', 'NNS'), ('accuracies', 'NNS')]

>> Noun Phrases are: 
 ['statistical comparisons accuracies']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('perform', 'perform'), ('statistical', 'statist'), ('comparisons', 'comparison'), ('accuracies', 'accuraci')]

>> Stemming using Snowball Stemmer: 
 [('perform', 'perform'), ('statistical', 'statist'), ('comparisons', 'comparison'), ('accuracies', 'accuraci')]

>> Lemmatization: 
 [('perform', 'perform'), ('statistical', 'statistical'), ('comparisons', 'comparison'), ('accuracies', 'accuracy')]



========================================== PARAGRAPH 171 ===========================================

trained classifiers on specific datasets. For doing this we can run  

------------------- Sentence 1 -------------------

trained classifiers on specific datasets.

>> Tokens are: 
 ['trained', 'classifiers', 'specific', 'datasets', '.']

>> Bigrams are: 
 [('trained', 'classifiers'), ('classifiers', 'specific'), ('specific', 'datasets'), ('datasets', '.')]

>> Trigrams are: 
 [('trained', 'classifiers', 'specific'), ('classifiers', 'specific', 'datasets'), ('specific', 'datasets', '.')]

>> POS Tags are: 
 [('trained', 'JJ'), ('classifiers', 'NNS'), ('specific', 'JJ'), ('datasets', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['trained classifiers', 'specific datasets']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('trained', 'train'), ('classifiers', 'classifi'), ('specific', 'specif'), ('datasets', 'dataset'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('trained', 'train'), ('classifiers', 'classifi'), ('specific', 'specif'), ('datasets', 'dataset'), ('.', '.')]

>> Lemmatization: 
 [('trained', 'trained'), ('classifiers', 'classifier'), ('specific', 'specific'), ('datasets', 'datasets'), ('.', '.')]


------------------- Sentence 2 -------------------

For doing this we can run

>> Tokens are: 
 ['For', 'run']

>> Bigrams are: 
 [('For', 'run')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('For', 'IN'), ('run', 'NN')]

>> Noun Phrases are: 
 ['run']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('For', 'for'), ('run', 'run')]

>> Stemming using Snowball Stemmer: 
 [('For', 'for'), ('run', 'run')]

>> Lemmatization: 
 [('For', 'For'), ('run', 'run')]



========================================== PARAGRAPH 172 ===========================================

two different learning algorithms on samples of training set of size  

------------------- Sentence 1 -------------------

two different learning algorithms on samples of training set of size

>> Tokens are: 
 ['two', 'different', 'learning', 'algorithms', 'samples', 'training', 'set', 'size']

>> Bigrams are: 
 [('two', 'different'), ('different', 'learning'), ('learning', 'algorithms'), ('algorithms', 'samples'), ('samples', 'training'), ('training', 'set'), ('set', 'size')]

>> Trigrams are: 
 [('two', 'different', 'learning'), ('different', 'learning', 'algorithms'), ('learning', 'algorithms', 'samples'), ('algorithms', 'samples', 'training'), ('samples', 'training', 'set'), ('training', 'set', 'size')]

>> POS Tags are: 
 [('two', 'CD'), ('different', 'JJ'), ('learning', 'VBG'), ('algorithms', 'JJ'), ('samples', 'NNS'), ('training', 'VBG'), ('set', 'NN'), ('size', 'NN')]

>> Noun Phrases are: 
 ['algorithms samples', 'set size']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('two', 'two'), ('different', 'differ'), ('learning', 'learn'), ('algorithms', 'algorithm'), ('samples', 'sampl'), ('training', 'train'), ('set', 'set'), ('size', 'size')]

>> Stemming using Snowball Stemmer: 
 [('two', 'two'), ('different', 'differ'), ('learning', 'learn'), ('algorithms', 'algorithm'), ('samples', 'sampl'), ('training', 'train'), ('set', 'set'), ('size', 'size')]

>> Lemmatization: 
 [('two', 'two'), ('different', 'different'), ('learning', 'learning'), ('algorithms', 'algorithm'), ('samples', 'sample'), ('training', 'training'), ('set', 'set'), ('size', 'size')]



========================================== PARAGRAPH 173 ===========================================

N, estimate the difference in accuracy for each pair of classifiers  

------------------- Sentence 1 -------------------

N, estimate the difference in accuracy for each pair of classifiers

>> Tokens are: 
 ['N', ',', 'estimate', 'difference', 'accuracy', 'pair', 'classifiers']

>> Bigrams are: 
 [('N', ','), (',', 'estimate'), ('estimate', 'difference'), ('difference', 'accuracy'), ('accuracy', 'pair'), ('pair', 'classifiers')]

>> Trigrams are: 
 [('N', ',', 'estimate'), (',', 'estimate', 'difference'), ('estimate', 'difference', 'accuracy'), ('difference', 'accuracy', 'pair'), ('accuracy', 'pair', 'classifiers')]

>> POS Tags are: 
 [('N', 'NNP'), (',', ','), ('estimate', 'NN'), ('difference', 'NN'), ('accuracy', 'NN'), ('pair', 'NN'), ('classifiers', 'NNS')]

>> Noun Phrases are: 
 ['N', 'estimate difference accuracy pair classifiers']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('N', 'n'), (',', ','), ('estimate', 'estim'), ('difference', 'differ'), ('accuracy', 'accuraci'), ('pair', 'pair'), ('classifiers', 'classifi')]

>> Stemming using Snowball Stemmer: 
 [('N', 'n'), (',', ','), ('estimate', 'estim'), ('difference', 'differ'), ('accuracy', 'accuraci'), ('pair', 'pair'), ('classifiers', 'classifi')]

>> Lemmatization: 
 [('N', 'N'), (',', ','), ('estimate', 'estimate'), ('difference', 'difference'), ('accuracy', 'accuracy'), ('pair', 'pair'), ('classifiers', 'classifier')]



========================================== PARAGRAPH 174 ===========================================

on a large test set[1]. For classification of data, a good number of  

------------------- Sentence 1 -------------------

on a large test set[1].

>> Tokens are: 
 ['large', 'test', 'set', '[', '1', ']', '.']

>> Bigrams are: 
 [('large', 'test'), ('test', 'set'), ('set', '['), ('[', '1'), ('1', ']'), (']', '.')]

>> Trigrams are: 
 [('large', 'test', 'set'), ('test', 'set', '['), ('set', '[', '1'), ('[', '1', ']'), ('1', ']', '.')]

>> POS Tags are: 
 [('large', 'JJ'), ('test', 'NN'), ('set', 'VBN'), ('[', '$'), ('1', 'CD'), (']', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['large test', ']']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('large', 'larg'), ('test', 'test'), ('set', 'set'), ('[', '['), ('1', '1'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('large', 'larg'), ('test', 'test'), ('set', 'set'), ('[', '['), ('1', '1'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('large', 'large'), ('test', 'test'), ('set', 'set'), ('[', '['), ('1', '1'), (']', ']'), ('.', '.')]


------------------- Sentence 2 -------------------

For classification of data, a good number of

>> Tokens are: 
 ['For', 'classification', 'data', ',', 'good', 'number']

>> Bigrams are: 
 [('For', 'classification'), ('classification', 'data'), ('data', ','), (',', 'good'), ('good', 'number')]

>> Trigrams are: 
 [('For', 'classification', 'data'), ('classification', 'data', ','), ('data', ',', 'good'), (',', 'good', 'number')]

>> POS Tags are: 
 [('For', 'IN'), ('classification', 'NN'), ('data', 'NNS'), (',', ','), ('good', 'JJ'), ('number', 'NN')]

>> Noun Phrases are: 
 ['classification data', 'good number']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('For', 'for'), ('classification', 'classif'), ('data', 'data'), (',', ','), ('good', 'good'), ('number', 'number')]

>> Stemming using Snowball Stemmer: 
 [('For', 'for'), ('classification', 'classif'), ('data', 'data'), (',', ','), ('good', 'good'), ('number', 'number')]

>> Lemmatization: 
 [('For', 'For'), ('classification', 'classification'), ('data', 'data'), (',', ','), ('good', 'good'), ('number', 'number')]



========================================== PARAGRAPH 175 ===========================================

techniques have been developed by researchers, such as logical  

------------------- Sentence 1 -------------------

techniques have been developed by researchers, such as logical

>> Tokens are: 
 ['techniques', 'developed', 'researchers', ',', 'logical']

>> Bigrams are: 
 [('techniques', 'developed'), ('developed', 'researchers'), ('researchers', ','), (',', 'logical')]

>> Trigrams are: 
 [('techniques', 'developed', 'researchers'), ('developed', 'researchers', ','), ('researchers', ',', 'logical')]

>> POS Tags are: 
 [('techniques', 'NNS'), ('developed', 'VBD'), ('researchers', 'NNS'), (',', ','), ('logical', 'JJ')]

>> Noun Phrases are: 
 ['techniques', 'researchers']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('techniques', 'techniqu'), ('developed', 'develop'), ('researchers', 'research'), (',', ','), ('logical', 'logic')]

>> Stemming using Snowball Stemmer: 
 [('techniques', 'techniqu'), ('developed', 'develop'), ('researchers', 'research'), (',', ','), ('logical', 'logic')]

>> Lemmatization: 
 [('techniques', 'technique'), ('developed', 'developed'), ('researchers', 'researcher'), (',', ','), ('logical', 'logical')]



========================================== PARAGRAPH 176 ===========================================

statistics based techniques. In next sections, we will precisely  

------------------- Sentence 1 -------------------

statistics based techniques.

>> Tokens are: 
 ['statistics', 'based', 'techniques', '.']

>> Bigrams are: 
 [('statistics', 'based'), ('based', 'techniques'), ('techniques', '.')]

>> Trigrams are: 
 [('statistics', 'based', 'techniques'), ('based', 'techniques', '.')]

>> POS Tags are: 
 [('statistics', 'NNS'), ('based', 'VBN'), ('techniques', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['statistics', 'techniques']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('statistics', 'statist'), ('based', 'base'), ('techniques', 'techniqu'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('statistics', 'statist'), ('based', 'base'), ('techniques', 'techniqu'), ('.', '.')]

>> Lemmatization: 
 [('statistics', 'statistic'), ('based', 'based'), ('techniques', 'technique'), ('.', '.')]


------------------- Sentence 2 -------------------

In next sections, we will precisely

>> Tokens are: 
 ['In', 'next', 'sections', ',', 'precisely']

>> Bigrams are: 
 [('In', 'next'), ('next', 'sections'), ('sections', ','), (',', 'precisely')]

>> Trigrams are: 
 [('In', 'next', 'sections'), ('next', 'sections', ','), ('sections', ',', 'precisely')]

>> POS Tags are: 
 [('In', 'IN'), ('next', 'JJ'), ('sections', 'NNS'), (',', ','), ('precisely', 'RB')]

>> Noun Phrases are: 
 ['next sections']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('next', 'next'), ('sections', 'section'), (',', ','), ('precisely', 'precis')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('next', 'next'), ('sections', 'section'), (',', ','), ('precisely', 'precis')]

>> Lemmatization: 
 [('In', 'In'), ('next', 'next'), ('sections', 'section'), (',', ','), ('precisely', 'precisely')]



========================================== PARAGRAPH 177 ===========================================

discuss the most important supervised machine learning  

------------------- Sentence 1 -------------------

discuss the most important supervised machine learning

>> Tokens are: 
 ['discuss', 'important', 'supervised', 'machine', 'learning']

>> Bigrams are: 
 [('discuss', 'important'), ('important', 'supervised'), ('supervised', 'machine'), ('machine', 'learning')]

>> Trigrams are: 
 [('discuss', 'important', 'supervised'), ('important', 'supervised', 'machine'), ('supervised', 'machine', 'learning')]

>> POS Tags are: 
 [('discuss', 'NN'), ('important', 'JJ'), ('supervised', 'VBD'), ('machine', 'NN'), ('learning', 'NN')]

>> Noun Phrases are: 
 ['discuss', 'machine learning']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('discuss', 'discuss'), ('important', 'import'), ('supervised', 'supervis'), ('machine', 'machin'), ('learning', 'learn')]

>> Stemming using Snowball Stemmer: 
 [('discuss', 'discuss'), ('important', 'import'), ('supervised', 'supervis'), ('machine', 'machin'), ('learning', 'learn')]

>> Lemmatization: 
 [('discuss', 'discus'), ('important', 'important'), ('supervised', 'supervised'), ('machine', 'machine'), ('learning', 'learning')]



========================================== PARAGRAPH 178 ===========================================

techniques, starting with logical techniques [1].  

------------------- Sentence 1 -------------------

techniques, starting with logical techniques [1].

>> Tokens are: 
 ['techniques', ',', 'starting', 'logical', 'techniques', '[', '1', ']', '.']

>> Bigrams are: 
 [('techniques', ','), (',', 'starting'), ('starting', 'logical'), ('logical', 'techniques'), ('techniques', '['), ('[', '1'), ('1', ']'), (']', '.')]

>> Trigrams are: 
 [('techniques', ',', 'starting'), (',', 'starting', 'logical'), ('starting', 'logical', 'techniques'), ('logical', 'techniques', '['), ('techniques', '[', '1'), ('[', '1', ']'), ('1', ']', '.')]

>> POS Tags are: 
 [('techniques', 'NNS'), (',', ','), ('starting', 'VBG'), ('logical', 'JJ'), ('techniques', 'NNS'), ('[', 'VBP'), ('1', 'CD'), (']', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['techniques', 'logical techniques', ']']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('techniques', 'techniqu'), (',', ','), ('starting', 'start'), ('logical', 'logic'), ('techniques', 'techniqu'), ('[', '['), ('1', '1'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('techniques', 'techniqu'), (',', ','), ('starting', 'start'), ('logical', 'logic'), ('techniques', 'techniqu'), ('[', '['), ('1', '1'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('techniques', 'technique'), (',', ','), ('starting', 'starting'), ('logical', 'logical'), ('techniques', 'technique'), ('[', '['), ('1', '1'), (']', ']'), ('.', '.')]



========================================== PARAGRAPH 179 ===========================================

3. LOGIC BASED ALGORITHMS   

------------------- Sentence 1 -------------------

3.

>> Tokens are: 
 ['3', '.']

>> Bigrams are: 
 [('3', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('3', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('3', '3'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('3', '3'), ('.', '.')]

>> Lemmatization: 
 [('3', '3'), ('.', '.')]


------------------- Sentence 2 -------------------

LOGIC BASED ALGORITHMS

>> Tokens are: 
 ['LOGIC', 'BASED', 'ALGORITHMS']

>> Bigrams are: 
 [('LOGIC', 'BASED'), ('BASED', 'ALGORITHMS')]

>> Trigrams are: 
 [('LOGIC', 'BASED', 'ALGORITHMS')]

>> POS Tags are: 
 [('LOGIC', 'NNP'), ('BASED', 'NNP'), ('ALGORITHMS', 'NNP')]

>> Noun Phrases are: 
 ['LOGIC BASED ALGORITHMS']

>> Named Entities are: 
 [('ORGANIZATION', 'LOGIC'), ('ORGANIZATION', 'BASED')] 

>> Stemming using Porter Stemmer: 
 [('LOGIC', 'logic'), ('BASED', 'base'), ('ALGORITHMS', 'algorithm')]

>> Stemming using Snowball Stemmer: 
 [('LOGIC', 'logic'), ('BASED', 'base'), ('ALGORITHMS', 'algorithm')]

>> Lemmatization: 
 [('LOGIC', 'LOGIC'), ('BASED', 'BASED'), ('ALGORITHMS', 'ALGORITHMS')]



========================================== PARAGRAPH 180 ===========================================

In this section we will discuss two logical (symbolic)  

------------------- Sentence 1 -------------------

In this section we will discuss two logical (symbolic)

>> Tokens are: 
 ['In', 'section', 'discuss', 'two', 'logical', '(', 'symbolic', ')']

>> Bigrams are: 
 [('In', 'section'), ('section', 'discuss'), ('discuss', 'two'), ('two', 'logical'), ('logical', '('), ('(', 'symbolic'), ('symbolic', ')')]

>> Trigrams are: 
 [('In', 'section', 'discuss'), ('section', 'discuss', 'two'), ('discuss', 'two', 'logical'), ('two', 'logical', '('), ('logical', '(', 'symbolic'), ('(', 'symbolic', ')')]

>> POS Tags are: 
 [('In', 'IN'), ('section', 'NN'), ('discuss', 'NN'), ('two', 'CD'), ('logical', 'JJ'), ('(', '('), ('symbolic', 'JJ'), (')', ')')]

>> Noun Phrases are: 
 ['section discuss']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('section', 'section'), ('discuss', 'discuss'), ('two', 'two'), ('logical', 'logic'), ('(', '('), ('symbolic', 'symbol'), (')', ')')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('section', 'section'), ('discuss', 'discuss'), ('two', 'two'), ('logical', 'logic'), ('(', '('), ('symbolic', 'symbol'), (')', ')')]

>> Lemmatization: 
 [('In', 'In'), ('section', 'section'), ('discuss', 'discus'), ('two', 'two'), ('logical', 'logical'), ('(', '('), ('symbolic', 'symbolic'), (')', ')')]



========================================== PARAGRAPH 181 ===========================================

learning methods: decision trees and rule-based classifiers.  

------------------- Sentence 1 -------------------

learning methods: decision trees and rule-based classifiers.

>> Tokens are: 
 ['learning', 'methods', ':', 'decision', 'trees', 'rule-based', 'classifiers', '.']

>> Bigrams are: 
 [('learning', 'methods'), ('methods', ':'), (':', 'decision'), ('decision', 'trees'), ('trees', 'rule-based'), ('rule-based', 'classifiers'), ('classifiers', '.')]

>> Trigrams are: 
 [('learning', 'methods', ':'), ('methods', ':', 'decision'), (':', 'decision', 'trees'), ('decision', 'trees', 'rule-based'), ('trees', 'rule-based', 'classifiers'), ('rule-based', 'classifiers', '.')]

>> POS Tags are: 
 [('learning', 'VBG'), ('methods', 'NNS'), (':', ':'), ('decision', 'NN'), ('trees', 'NNS'), ('rule-based', 'JJ'), ('classifiers', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['methods', 'decision trees', 'rule-based classifiers']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('learning', 'learn'), ('methods', 'method'), (':', ':'), ('decision', 'decis'), ('trees', 'tree'), ('rule-based', 'rule-bas'), ('classifiers', 'classifi'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('learning', 'learn'), ('methods', 'method'), (':', ':'), ('decision', 'decis'), ('trees', 'tree'), ('rule-based', 'rule-bas'), ('classifiers', 'classifi'), ('.', '.')]

>> Lemmatization: 
 [('learning', 'learning'), ('methods', 'method'), (':', ':'), ('decision', 'decision'), ('trees', 'tree'), ('rule-based', 'rule-based'), ('classifiers', 'classifier'), ('.', '.')]



========================================== PARAGRAPH 182 ===========================================

3.1 DECISION TREES  

------------------- Sentence 1 -------------------

3.1 DECISION TREES

>> Tokens are: 
 ['3.1', 'DECISION', 'TREES']

>> Bigrams are: 
 [('3.1', 'DECISION'), ('DECISION', 'TREES')]

>> Trigrams are: 
 [('3.1', 'DECISION', 'TREES')]

>> POS Tags are: 
 [('3.1', 'CD'), ('DECISION', 'NNP'), ('TREES', 'NNP')]

>> Noun Phrases are: 
 ['DECISION TREES']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('3.1', '3.1'), ('DECISION', 'decis'), ('TREES', 'tree')]

>> Stemming using Snowball Stemmer: 
 [('3.1', '3.1'), ('DECISION', 'decis'), ('TREES', 'tree')]

>> Lemmatization: 
 [('3.1', '3.1'), ('DECISION', 'DECISION'), ('TREES', 'TREES')]



========================================== PARAGRAPH 183 ===========================================

In machine learning domain the Decision Tree Induction [8,  

------------------- Sentence 1 -------------------

In machine learning domain the Decision Tree Induction [8,

>> Tokens are: 
 ['In', 'machine', 'learning', 'domain', 'Decision', 'Tree', 'Induction', '[', '8', ',']

>> Bigrams are: 
 [('In', 'machine'), ('machine', 'learning'), ('learning', 'domain'), ('domain', 'Decision'), ('Decision', 'Tree'), ('Tree', 'Induction'), ('Induction', '['), ('[', '8'), ('8', ',')]

>> Trigrams are: 
 [('In', 'machine', 'learning'), ('machine', 'learning', 'domain'), ('learning', 'domain', 'Decision'), ('domain', 'Decision', 'Tree'), ('Decision', 'Tree', 'Induction'), ('Tree', 'Induction', '['), ('Induction', '[', '8'), ('[', '8', ',')]

>> POS Tags are: 
 [('In', 'IN'), ('machine', 'NN'), ('learning', 'NN'), ('domain', 'NN'), ('Decision', 'NNP'), ('Tree', 'NNP'), ('Induction', 'NNP'), ('[', 'NNP'), ('8', 'CD'), (',', ',')]

>> Noun Phrases are: 
 ['machine learning domain Decision Tree Induction [']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('machine', 'machin'), ('learning', 'learn'), ('domain', 'domain'), ('Decision', 'decis'), ('Tree', 'tree'), ('Induction', 'induct'), ('[', '['), ('8', '8'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('machine', 'machin'), ('learning', 'learn'), ('domain', 'domain'), ('Decision', 'decis'), ('Tree', 'tree'), ('Induction', 'induct'), ('[', '['), ('8', '8'), (',', ',')]

>> Lemmatization: 
 [('In', 'In'), ('machine', 'machine'), ('learning', 'learning'), ('domain', 'domain'), ('Decision', 'Decision'), ('Tree', 'Tree'), ('Induction', 'Induction'), ('[', '['), ('8', '8'), (',', ',')]



========================================== PARAGRAPH 184 ===========================================

9] is currently one of the most important supervised learning  

------------------- Sentence 1 -------------------

9] is currently one of the most important supervised learning

>> Tokens are: 
 ['9', ']', 'currently', 'one', 'important', 'supervised', 'learning']

>> Bigrams are: 
 [('9', ']'), (']', 'currently'), ('currently', 'one'), ('one', 'important'), ('important', 'supervised'), ('supervised', 'learning')]

>> Trigrams are: 
 [('9', ']', 'currently'), (']', 'currently', 'one'), ('currently', 'one', 'important'), ('one', 'important', 'supervised'), ('important', 'supervised', 'learning')]

>> POS Tags are: 
 [('9', 'CD'), (']', 'NNS'), ('currently', 'RB'), ('one', 'CD'), ('important', 'JJ'), ('supervised', 'VBD'), ('learning', 'NN')]

>> Noun Phrases are: 
 [']', 'learning']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('9', '9'), (']', ']'), ('currently', 'current'), ('one', 'one'), ('important', 'import'), ('supervised', 'supervis'), ('learning', 'learn')]

>> Stemming using Snowball Stemmer: 
 [('9', '9'), (']', ']'), ('currently', 'current'), ('one', 'one'), ('important', 'import'), ('supervised', 'supervis'), ('learning', 'learn')]

>> Lemmatization: 
 [('9', '9'), (']', ']'), ('currently', 'currently'), ('one', 'one'), ('important', 'important'), ('supervised', 'supervised'), ('learning', 'learning')]



========================================== PARAGRAPH 185 ===========================================

algorithms. In Artificial Intelligence (AI) field, Quinlan has  

------------------- Sentence 1 -------------------

algorithms.

>> Tokens are: 
 ['algorithms', '.']

>> Bigrams are: 
 [('algorithms', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('algorithms', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['algorithms']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('algorithms', 'algorithm'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('algorithms', 'algorithm'), ('.', '.')]

>> Lemmatization: 
 [('algorithms', 'algorithm'), ('.', '.')]


------------------- Sentence 2 -------------------

In Artificial Intelligence (AI) field, Quinlan has

>> Tokens are: 
 ['In', 'Artificial', 'Intelligence', '(', 'AI', ')', 'field', ',', 'Quinlan']

>> Bigrams are: 
 [('In', 'Artificial'), ('Artificial', 'Intelligence'), ('Intelligence', '('), ('(', 'AI'), ('AI', ')'), (')', 'field'), ('field', ','), (',', 'Quinlan')]

>> Trigrams are: 
 [('In', 'Artificial', 'Intelligence'), ('Artificial', 'Intelligence', '('), ('Intelligence', '(', 'AI'), ('(', 'AI', ')'), ('AI', ')', 'field'), (')', 'field', ','), ('field', ',', 'Quinlan')]

>> POS Tags are: 
 [('In', 'IN'), ('Artificial', 'NNP'), ('Intelligence', 'NNP'), ('(', '('), ('AI', 'NNP'), (')', ')'), ('field', 'NN'), (',', ','), ('Quinlan', 'NNP')]

>> Noun Phrases are: 
 ['Artificial Intelligence', 'AI', 'field', 'Quinlan']

>> Named Entities are: 
 [('ORGANIZATION', 'Artificial Intelligence'), ('PERSON', 'Quinlan')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('Artificial', 'artifici'), ('Intelligence', 'intellig'), ('(', '('), ('AI', 'ai'), (')', ')'), ('field', 'field'), (',', ','), ('Quinlan', 'quinlan')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('Artificial', 'artifici'), ('Intelligence', 'intellig'), ('(', '('), ('AI', 'ai'), (')', ')'), ('field', 'field'), (',', ','), ('Quinlan', 'quinlan')]

>> Lemmatization: 
 [('In', 'In'), ('Artificial', 'Artificial'), ('Intelligence', 'Intelligence'), ('(', '('), ('AI', 'AI'), (')', ')'), ('field', 'field'), (',', ','), ('Quinlan', 'Quinlan')]



========================================== PARAGRAPH 186 ===========================================

contributed through his ID3 and C4.5 algorithms. C4.5 is one of  

------------------- Sentence 1 -------------------

contributed through his ID3 and C4.5 algorithms.

>> Tokens are: 
 ['contributed', 'ID3', 'C4.5', 'algorithms', '.']

>> Bigrams are: 
 [('contributed', 'ID3'), ('ID3', 'C4.5'), ('C4.5', 'algorithms'), ('algorithms', '.')]

>> Trigrams are: 
 [('contributed', 'ID3', 'C4.5'), ('ID3', 'C4.5', 'algorithms'), ('C4.5', 'algorithms', '.')]

>> POS Tags are: 
 [('contributed', 'VBN'), ('ID3', 'NNP'), ('C4.5', 'NNP'), ('algorithms', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['ID3 C4.5 algorithms']

>> Named Entities are: 
 [('ORGANIZATION', 'ID3')] 

>> Stemming using Porter Stemmer: 
 [('contributed', 'contribut'), ('ID3', 'id3'), ('C4.5', 'c4.5'), ('algorithms', 'algorithm'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('contributed', 'contribut'), ('ID3', 'id3'), ('C4.5', 'c4.5'), ('algorithms', 'algorithm'), ('.', '.')]

>> Lemmatization: 
 [('contributed', 'contributed'), ('ID3', 'ID3'), ('C4.5', 'C4.5'), ('algorithms', 'algorithm'), ('.', '.')]


------------------- Sentence 2 -------------------

C4.5 is one of

>> Tokens are: 
 ['C4.5', 'one']

>> Bigrams are: 
 [('C4.5', 'one')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('C4.5', 'NNP'), ('one', 'CD')]

>> Noun Phrases are: 
 ['C4.5']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('C4.5', 'c4.5'), ('one', 'one')]

>> Stemming using Snowball Stemmer: 
 [('C4.5', 'c4.5'), ('one', 'one')]

>> Lemmatization: 
 [('C4.5', 'C4.5'), ('one', 'one')]



========================================== PARAGRAPH 187 ===========================================

the most popular and the efficient method in decision tree-based  

------------------- Sentence 1 -------------------

the most popular and the efficient method in decision tree-based

>> Tokens are: 
 ['popular', 'efficient', 'method', 'decision', 'tree-based']

>> Bigrams are: 
 [('popular', 'efficient'), ('efficient', 'method'), ('method', 'decision'), ('decision', 'tree-based')]

>> Trigrams are: 
 [('popular', 'efficient', 'method'), ('efficient', 'method', 'decision'), ('method', 'decision', 'tree-based')]

>> POS Tags are: 
 [('popular', 'JJ'), ('efficient', 'NN'), ('method', 'NN'), ('decision', 'NN'), ('tree-based', 'JJ')]

>> Noun Phrases are: 
 ['popular efficient method decision']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('popular', 'popular'), ('efficient', 'effici'), ('method', 'method'), ('decision', 'decis'), ('tree-based', 'tree-bas')]

>> Stemming using Snowball Stemmer: 
 [('popular', 'popular'), ('efficient', 'effici'), ('method', 'method'), ('decision', 'decis'), ('tree-based', 'tree-bas')]

>> Lemmatization: 
 [('popular', 'popular'), ('efficient', 'efficient'), ('method', 'method'), ('decision', 'decision'), ('tree-based', 'tree-based')]



========================================== PARAGRAPH 188 ===========================================

approach. Here C4.5 algorithm creates a tree model by using  

------------------- Sentence 1 -------------------

approach.

>> Tokens are: 
 ['approach', '.']

>> Bigrams are: 
 [('approach', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('approach', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['approach']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('approach', 'approach'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('approach', 'approach'), ('.', '.')]

>> Lemmatization: 
 [('approach', 'approach'), ('.', '.')]


------------------- Sentence 2 -------------------

Here C4.5 algorithm creates a tree model by using

>> Tokens are: 
 ['Here', 'C4.5', 'algorithm', 'creates', 'tree', 'model', 'using']

>> Bigrams are: 
 [('Here', 'C4.5'), ('C4.5', 'algorithm'), ('algorithm', 'creates'), ('creates', 'tree'), ('tree', 'model'), ('model', 'using')]

>> Trigrams are: 
 [('Here', 'C4.5', 'algorithm'), ('C4.5', 'algorithm', 'creates'), ('algorithm', 'creates', 'tree'), ('creates', 'tree', 'model'), ('tree', 'model', 'using')]

>> POS Tags are: 
 [('Here', 'RB'), ('C4.5', 'NNP'), ('algorithm', 'NN'), ('creates', 'VBZ'), ('tree', 'JJ'), ('model', 'NN'), ('using', 'VBG')]

>> Noun Phrases are: 
 ['C4.5 algorithm', 'tree model']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Here', 'here'), ('C4.5', 'c4.5'), ('algorithm', 'algorithm'), ('creates', 'creat'), ('tree', 'tree'), ('model', 'model'), ('using', 'use')]

>> Stemming using Snowball Stemmer: 
 [('Here', 'here'), ('C4.5', 'c4.5'), ('algorithm', 'algorithm'), ('creates', 'creat'), ('tree', 'tree'), ('model', 'model'), ('using', 'use')]

>> Lemmatization: 
 [('Here', 'Here'), ('C4.5', 'C4.5'), ('algorithm', 'algorithm'), ('creates', 'creates'), ('tree', 'tree'), ('model', 'model'), ('using', 'using')]



========================================== PARAGRAPH 189 ===========================================

values of only one attribute at a time [10]. According to authors  

------------------- Sentence 1 -------------------

values of only one attribute at a time [10].

>> Tokens are: 
 ['values', 'one', 'attribute', 'time', '[', '10', ']', '.']

>> Bigrams are: 
 [('values', 'one'), ('one', 'attribute'), ('attribute', 'time'), ('time', '['), ('[', '10'), ('10', ']'), (']', '.')]

>> Trigrams are: 
 [('values', 'one', 'attribute'), ('one', 'attribute', 'time'), ('attribute', 'time', '['), ('time', '[', '10'), ('[', '10', ']'), ('10', ']', '.')]

>> POS Tags are: 
 [('values', 'NNS'), ('one', 'CD'), ('attribute', 'NN'), ('time', 'NN'), ('[', 'VBZ'), ('10', 'CD'), (']', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['values', 'attribute time', ']']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('values', 'valu'), ('one', 'one'), ('attribute', 'attribut'), ('time', 'time'), ('[', '['), ('10', '10'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('values', 'valu'), ('one', 'one'), ('attribute', 'attribut'), ('time', 'time'), ('[', '['), ('10', '10'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('values', 'value'), ('one', 'one'), ('attribute', 'attribute'), ('time', 'time'), ('[', '['), ('10', '10'), (']', ']'), ('.', '.')]


------------------- Sentence 2 -------------------

According to authors

>> Tokens are: 
 ['According', 'authors']

>> Bigrams are: 
 [('According', 'authors')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('According', 'VBG'), ('authors', 'NNS')]

>> Noun Phrases are: 
 ['authors']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('According', 'accord'), ('authors', 'author')]

>> Stemming using Snowball Stemmer: 
 [('According', 'accord'), ('authors', 'author')]

>> Lemmatization: 
 [('According', 'According'), ('authors', 'author')]



========================================== PARAGRAPH 190 ===========================================

[7], the decision tree induction, which was initially designed to  

------------------- Sentence 1 -------------------

[7], the decision tree induction, which was initially designed to

>> Tokens are: 
 ['[', '7', ']', ',', 'decision', 'tree', 'induction', ',', 'initially', 'designed']

>> Bigrams are: 
 [('[', '7'), ('7', ']'), (']', ','), (',', 'decision'), ('decision', 'tree'), ('tree', 'induction'), ('induction', ','), (',', 'initially'), ('initially', 'designed')]

>> Trigrams are: 
 [('[', '7', ']'), ('7', ']', ','), (']', ',', 'decision'), (',', 'decision', 'tree'), ('decision', 'tree', 'induction'), ('tree', 'induction', ','), ('induction', ',', 'initially'), (',', 'initially', 'designed')]

>> POS Tags are: 
 [('[', 'RB'), ('7', 'CD'), (']', 'NNS'), (',', ','), ('decision', 'NN'), ('tree', 'NN'), ('induction', 'NN'), (',', ','), ('initially', 'RB'), ('designed', 'VBN')]

>> Noun Phrases are: 
 [']', 'decision tree induction']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('7', '7'), (']', ']'), (',', ','), ('decision', 'decis'), ('tree', 'tree'), ('induction', 'induct'), (',', ','), ('initially', 'initi'), ('designed', 'design')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('7', '7'), (']', ']'), (',', ','), ('decision', 'decis'), ('tree', 'tree'), ('induction', 'induct'), (',', ','), ('initially', 'initi'), ('designed', 'design')]

>> Lemmatization: 
 [('[', '['), ('7', '7'), (']', ']'), (',', ','), ('decision', 'decision'), ('tree', 'tree'), ('induction', 'induction'), (',', ','), ('initially', 'initially'), ('designed', 'designed')]



========================================== PARAGRAPH 191 ===========================================

solve classification problems, has been extended to deal with  

------------------- Sentence 1 -------------------

solve classification problems, has been extended to deal with

>> Tokens are: 
 ['solve', 'classification', 'problems', ',', 'extended', 'deal']

>> Bigrams are: 
 [('solve', 'classification'), ('classification', 'problems'), ('problems', ','), (',', 'extended'), ('extended', 'deal')]

>> Trigrams are: 
 [('solve', 'classification', 'problems'), ('classification', 'problems', ','), ('problems', ',', 'extended'), (',', 'extended', 'deal')]

>> POS Tags are: 
 [('solve', 'VB'), ('classification', 'NN'), ('problems', 'NNS'), (',', ','), ('extended', 'VBD'), ('deal', 'NN')]

>> Noun Phrases are: 
 ['classification problems', 'deal']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('solve', 'solv'), ('classification', 'classif'), ('problems', 'problem'), (',', ','), ('extended', 'extend'), ('deal', 'deal')]

>> Stemming using Snowball Stemmer: 
 [('solve', 'solv'), ('classification', 'classif'), ('problems', 'problem'), (',', ','), ('extended', 'extend'), ('deal', 'deal')]

>> Lemmatization: 
 [('solve', 'solve'), ('classification', 'classification'), ('problems', 'problem'), (',', ','), ('extended', 'extended'), ('deal', 'deal')]



========================================== PARAGRAPH 192 ===========================================

single or multi-dimensional regression. The major benefits of  

------------------- Sentence 1 -------------------

single or multi-dimensional regression.

>> Tokens are: 
 ['single', 'multi-dimensional', 'regression', '.']

>> Bigrams are: 
 [('single', 'multi-dimensional'), ('multi-dimensional', 'regression'), ('regression', '.')]

>> Trigrams are: 
 [('single', 'multi-dimensional', 'regression'), ('multi-dimensional', 'regression', '.')]

>> POS Tags are: 
 [('single', 'JJ'), ('multi-dimensional', 'JJ'), ('regression', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['single multi-dimensional regression']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('single', 'singl'), ('multi-dimensional', 'multi-dimension'), ('regression', 'regress'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('single', 'singl'), ('multi-dimensional', 'multi-dimension'), ('regression', 'regress'), ('.', '.')]

>> Lemmatization: 
 [('single', 'single'), ('multi-dimensional', 'multi-dimensional'), ('regression', 'regression'), ('.', '.')]


------------------- Sentence 2 -------------------

The major benefits of

>> Tokens are: 
 ['The', 'major', 'benefits']

>> Bigrams are: 
 [('The', 'major'), ('major', 'benefits')]

>> Trigrams are: 
 [('The', 'major', 'benefits')]

>> POS Tags are: 
 [('The', 'DT'), ('major', 'JJ'), ('benefits', 'NNS')]

>> Noun Phrases are: 
 ['The major benefits']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('major', 'major'), ('benefits', 'benefit')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('major', 'major'), ('benefits', 'benefit')]

>> Lemmatization: 
 [('The', 'The'), ('major', 'major'), ('benefits', 'benefit')]



========================================== PARAGRAPH 193 ===========================================

decision trees are i) produce intensive results, ii) easy to  

------------------- Sentence 1 -------------------

decision trees are i) produce intensive results, ii) easy to

>> Tokens are: 
 ['decision', 'trees', ')', 'produce', 'intensive', 'results', ',', 'ii', ')', 'easy']

>> Bigrams are: 
 [('decision', 'trees'), ('trees', ')'), (')', 'produce'), ('produce', 'intensive'), ('intensive', 'results'), ('results', ','), (',', 'ii'), ('ii', ')'), (')', 'easy')]

>> Trigrams are: 
 [('decision', 'trees', ')'), ('trees', ')', 'produce'), (')', 'produce', 'intensive'), ('produce', 'intensive', 'results'), ('intensive', 'results', ','), ('results', ',', 'ii'), (',', 'ii', ')'), ('ii', ')', 'easy')]

>> POS Tags are: 
 [('decision', 'NN'), ('trees', 'NNS'), (')', ')'), ('produce', 'VBP'), ('intensive', 'JJ'), ('results', 'NNS'), (',', ','), ('ii', 'NN'), (')', ')'), ('easy', 'NN')]

>> Noun Phrases are: 
 ['decision trees', 'intensive results', 'ii', 'easy']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('decision', 'decis'), ('trees', 'tree'), (')', ')'), ('produce', 'produc'), ('intensive', 'intens'), ('results', 'result'), (',', ','), ('ii', 'ii'), (')', ')'), ('easy', 'easi')]

>> Stemming using Snowball Stemmer: 
 [('decision', 'decis'), ('trees', 'tree'), (')', ')'), ('produce', 'produc'), ('intensive', 'intens'), ('results', 'result'), (',', ','), ('ii', 'ii'), (')', ')'), ('easy', 'easi')]

>> Lemmatization: 
 [('decision', 'decision'), ('trees', 'tree'), (')', ')'), ('produce', 'produce'), ('intensive', 'intensive'), ('results', 'result'), (',', ','), ('ii', 'ii'), (')', ')'), ('easy', 'easy')]



========================================== PARAGRAPH 194 ===========================================

understand, iii) and holds well-organized knowledge structure  

------------------- Sentence 1 -------------------

understand, iii) and holds well-organized knowledge structure

>> Tokens are: 
 ['understand', ',', 'iii', ')', 'holds', 'well-organized', 'knowledge', 'structure']

>> Bigrams are: 
 [('understand', ','), (',', 'iii'), ('iii', ')'), (')', 'holds'), ('holds', 'well-organized'), ('well-organized', 'knowledge'), ('knowledge', 'structure')]

>> Trigrams are: 
 [('understand', ',', 'iii'), (',', 'iii', ')'), ('iii', ')', 'holds'), (')', 'holds', 'well-organized'), ('holds', 'well-organized', 'knowledge'), ('well-organized', 'knowledge', 'structure')]

>> POS Tags are: 
 [('understand', 'NN'), (',', ','), ('iii', 'NN'), (')', ')'), ('holds', 'VBZ'), ('well-organized', 'JJ'), ('knowledge', 'NN'), ('structure', 'NN')]

>> Noun Phrases are: 
 ['understand', 'iii', 'well-organized knowledge structure']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('understand', 'understand'), (',', ','), ('iii', 'iii'), (')', ')'), ('holds', 'hold'), ('well-organized', 'well-organ'), ('knowledge', 'knowledg'), ('structure', 'structur')]

>> Stemming using Snowball Stemmer: 
 [('understand', 'understand'), (',', ','), ('iii', 'iii'), (')', ')'), ('holds', 'hold'), ('well-organized', 'well-organ'), ('knowledge', 'knowledg'), ('structure', 'structur')]

>> Lemmatization: 
 [('understand', 'understand'), (',', ','), ('iii', 'iii'), (')', ')'), ('holds', 'hold'), ('well-organized', 'well-organized'), ('knowledge', 'knowledge'), ('structure', 'structure')]



========================================== PARAGRAPH 195 ===========================================

[28].  

------------------- Sentence 1 -------------------

[28].

>> Tokens are: 
 ['[', '28', ']', '.']

>> Bigrams are: 
 [('[', '28'), ('28', ']'), (']', '.')]

>> Trigrams are: 
 [('[', '28', ']'), ('28', ']', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('28', 'CD'), (']', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 [']']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('28', '28'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('28', '28'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('28', '28'), (']', ']'), ('.', '.')]



========================================== PARAGRAPH 196 ===========================================

Decision Trees (DT) are trees that classify instances by  

------------------- Sentence 1 -------------------

Decision Trees (DT) are trees that classify instances by

>> Tokens are: 
 ['Decision', 'Trees', '(', 'DT', ')', 'trees', 'classify', 'instances']

>> Bigrams are: 
 [('Decision', 'Trees'), ('Trees', '('), ('(', 'DT'), ('DT', ')'), (')', 'trees'), ('trees', 'classify'), ('classify', 'instances')]

>> Trigrams are: 
 [('Decision', 'Trees', '('), ('Trees', '(', 'DT'), ('(', 'DT', ')'), ('DT', ')', 'trees'), (')', 'trees', 'classify'), ('trees', 'classify', 'instances')]

>> POS Tags are: 
 [('Decision', 'NN'), ('Trees', 'NNP'), ('(', '('), ('DT', 'NNP'), (')', ')'), ('trees', 'VBZ'), ('classify', 'JJ'), ('instances', 'NNS')]

>> Noun Phrases are: 
 ['Decision Trees', 'DT', 'classify instances']

>> Named Entities are: 
 [('GPE', 'Trees')] 

>> Stemming using Porter Stemmer: 
 [('Decision', 'decis'), ('Trees', 'tree'), ('(', '('), ('DT', 'dt'), (')', ')'), ('trees', 'tree'), ('classify', 'classifi'), ('instances', 'instanc')]

>> Stemming using Snowball Stemmer: 
 [('Decision', 'decis'), ('Trees', 'tree'), ('(', '('), ('DT', 'dt'), (')', ')'), ('trees', 'tree'), ('classify', 'classifi'), ('instances', 'instanc')]

>> Lemmatization: 
 [('Decision', 'Decision'), ('Trees', 'Trees'), ('(', '('), ('DT', 'DT'), (')', ')'), ('trees', 'tree'), ('classify', 'classify'), ('instances', 'instance')]



========================================== PARAGRAPH 197 ===========================================

sorting them based on feature values, where each node in a  

------------------- Sentence 1 -------------------

sorting them based on feature values, where each node in a

>> Tokens are: 
 ['sorting', 'based', 'feature', 'values', ',', 'node']

>> Bigrams are: 
 [('sorting', 'based'), ('based', 'feature'), ('feature', 'values'), ('values', ','), (',', 'node')]

>> Trigrams are: 
 [('sorting', 'based', 'feature'), ('based', 'feature', 'values'), ('feature', 'values', ','), ('values', ',', 'node')]

>> POS Tags are: 
 [('sorting', 'VBG'), ('based', 'VBN'), ('feature', 'NN'), ('values', 'NNS'), (',', ','), ('node', 'NN')]

>> Noun Phrases are: 
 ['feature values', 'node']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('sorting', 'sort'), ('based', 'base'), ('feature', 'featur'), ('values', 'valu'), (',', ','), ('node', 'node')]

>> Stemming using Snowball Stemmer: 
 [('sorting', 'sort'), ('based', 'base'), ('feature', 'featur'), ('values', 'valu'), (',', ','), ('node', 'node')]

>> Lemmatization: 
 [('sorting', 'sorting'), ('based', 'based'), ('feature', 'feature'), ('values', 'value'), (',', ','), ('node', 'node')]



========================================== PARAGRAPH 198 ===========================================

decision tree represents a feature in an instance to be classified,  

------------------- Sentence 1 -------------------

decision tree represents a feature in an instance to be classified,

>> Tokens are: 
 ['decision', 'tree', 'represents', 'feature', 'instance', 'classified', ',']

>> Bigrams are: 
 [('decision', 'tree'), ('tree', 'represents'), ('represents', 'feature'), ('feature', 'instance'), ('instance', 'classified'), ('classified', ',')]

>> Trigrams are: 
 [('decision', 'tree', 'represents'), ('tree', 'represents', 'feature'), ('represents', 'feature', 'instance'), ('feature', 'instance', 'classified'), ('instance', 'classified', ',')]

>> POS Tags are: 
 [('decision', 'NN'), ('tree', 'NN'), ('represents', 'VBZ'), ('feature', 'JJ'), ('instance', 'NN'), ('classified', 'VBD'), (',', ',')]

>> Noun Phrases are: 
 ['decision tree', 'feature instance']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('decision', 'decis'), ('tree', 'tree'), ('represents', 'repres'), ('feature', 'featur'), ('instance', 'instanc'), ('classified', 'classifi'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('decision', 'decis'), ('tree', 'tree'), ('represents', 'repres'), ('feature', 'featur'), ('instance', 'instanc'), ('classified', 'classifi'), (',', ',')]

>> Lemmatization: 
 [('decision', 'decision'), ('tree', 'tree'), ('represents', 'represents'), ('feature', 'feature'), ('instance', 'instance'), ('classified', 'classified'), (',', ',')]



========================================== PARAGRAPH 199 ===========================================

and each branch represents a value that the node can assume [1].  

------------------- Sentence 1 -------------------

and each branch represents a value that the node can assume [1].

>> Tokens are: 
 ['branch', 'represents', 'value', 'node', 'assume', '[', '1', ']', '.']

>> Bigrams are: 
 [('branch', 'represents'), ('represents', 'value'), ('value', 'node'), ('node', 'assume'), ('assume', '['), ('[', '1'), ('1', ']'), (']', '.')]

>> Trigrams are: 
 [('branch', 'represents', 'value'), ('represents', 'value', 'node'), ('value', 'node', 'assume'), ('node', 'assume', '['), ('assume', '[', '1'), ('[', '1', ']'), ('1', ']', '.')]

>> POS Tags are: 
 [('branch', 'NN'), ('represents', 'VBZ'), ('value', 'NN'), ('node', 'NN'), ('assume', 'VBP'), ('[', '$'), ('1', 'CD'), (']', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['branch', 'value node', ']']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('branch', 'branch'), ('represents', 'repres'), ('value', 'valu'), ('node', 'node'), ('assume', 'assum'), ('[', '['), ('1', '1'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('branch', 'branch'), ('represents', 'repres'), ('value', 'valu'), ('node', 'node'), ('assume', 'assum'), ('[', '['), ('1', '1'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('branch', 'branch'), ('represents', 'represents'), ('value', 'value'), ('node', 'node'), ('assume', 'assume'), ('[', '['), ('1', '1'), (']', ']'), ('.', '.')]



========================================== PARAGRAPH 200 ===========================================

Instances are classified starting at the root node and sorted based  

------------------- Sentence 1 -------------------

Instances are classified starting at the root node and sorted based

>> Tokens are: 
 ['Instances', 'classified', 'starting', 'root', 'node', 'sorted', 'based']

>> Bigrams are: 
 [('Instances', 'classified'), ('classified', 'starting'), ('starting', 'root'), ('root', 'node'), ('node', 'sorted'), ('sorted', 'based')]

>> Trigrams are: 
 [('Instances', 'classified', 'starting'), ('classified', 'starting', 'root'), ('starting', 'root', 'node'), ('root', 'node', 'sorted'), ('node', 'sorted', 'based')]

>> POS Tags are: 
 [('Instances', 'NNS'), ('classified', 'VBD'), ('starting', 'VBG'), ('root', 'NN'), ('node', 'RB'), ('sorted', 'VBD'), ('based', 'VBN')]

>> Noun Phrases are: 
 ['Instances', 'root']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Instances', 'instanc'), ('classified', 'classifi'), ('starting', 'start'), ('root', 'root'), ('node', 'node'), ('sorted', 'sort'), ('based', 'base')]

>> Stemming using Snowball Stemmer: 
 [('Instances', 'instanc'), ('classified', 'classifi'), ('starting', 'start'), ('root', 'root'), ('node', 'node'), ('sorted', 'sort'), ('based', 'base')]

>> Lemmatization: 
 [('Instances', 'Instances'), ('classified', 'classified'), ('starting', 'starting'), ('root', 'root'), ('node', 'node'), ('sorted', 'sorted'), ('based', 'based')]



========================================== PARAGRAPH 201 ===========================================

on their feature values. 

------------------- Sentence 1 -------------------

on their feature values.

>> Tokens are: 
 ['feature', 'values', '.']

>> Bigrams are: 
 [('feature', 'values'), ('values', '.')]

>> Trigrams are: 
 [('feature', 'values', '.')]

>> POS Tags are: 
 [('feature', 'NN'), ('values', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['feature values']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('feature', 'featur'), ('values', 'valu'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('feature', 'featur'), ('values', 'valu'), ('.', '.')]

>> Lemmatization: 
 [('feature', 'feature'), ('values', 'value'), ('.', '.')]



========================================== PARAGRAPH 202 ===========================================

IQBAL MUHAMMAD AND ZHU YAN: SUPERVISED MACHINE LEARNING APPROACHES: A SURVEY  

------------------- Sentence 1 -------------------

IQBAL MUHAMMAD AND ZHU YAN: SUPERVISED MACHINE LEARNING APPROACHES: A SURVEY

>> Tokens are: 
 ['IQBAL', 'MUHAMMAD', 'AND', 'ZHU', 'YAN', ':', 'SUPERVISED', 'MACHINE', 'LEARNING', 'APPROACHES', ':', 'A', 'SURVEY']

>> Bigrams are: 
 [('IQBAL', 'MUHAMMAD'), ('MUHAMMAD', 'AND'), ('AND', 'ZHU'), ('ZHU', 'YAN'), ('YAN', ':'), (':', 'SUPERVISED'), ('SUPERVISED', 'MACHINE'), ('MACHINE', 'LEARNING'), ('LEARNING', 'APPROACHES'), ('APPROACHES', ':'), (':', 'A'), ('A', 'SURVEY')]

>> Trigrams are: 
 [('IQBAL', 'MUHAMMAD', 'AND'), ('MUHAMMAD', 'AND', 'ZHU'), ('AND', 'ZHU', 'YAN'), ('ZHU', 'YAN', ':'), ('YAN', ':', 'SUPERVISED'), (':', 'SUPERVISED', 'MACHINE'), ('SUPERVISED', 'MACHINE', 'LEARNING'), ('MACHINE', 'LEARNING', 'APPROACHES'), ('LEARNING', 'APPROACHES', ':'), ('APPROACHES', ':', 'A'), (':', 'A', 'SURVEY')]

>> POS Tags are: 
 [('IQBAL', 'NNP'), ('MUHAMMAD', 'NNP'), ('AND', 'NNP'), ('ZHU', 'NNP'), ('YAN', 'NNP'), (':', ':'), ('SUPERVISED', 'NNP'), ('MACHINE', 'NNP'), ('LEARNING', 'NNP'), ('APPROACHES', 'NNP'), (':', ':'), ('A', 'DT'), ('SURVEY', 'NN')]

>> Noun Phrases are: 
 ['IQBAL MUHAMMAD AND ZHU YAN', 'SUPERVISED MACHINE LEARNING APPROACHES', 'A SURVEY']

>> Named Entities are: 
 [('ORGANIZATION', 'IQBAL'), ('ORGANIZATION', 'MUHAMMAD'), ('ORGANIZATION', 'SUPERVISED'), ('ORGANIZATION', 'MACHINE')] 

>> Stemming using Porter Stemmer: 
 [('IQBAL', 'iqbal'), ('MUHAMMAD', 'muhammad'), ('AND', 'and'), ('ZHU', 'zhu'), ('YAN', 'yan'), (':', ':'), ('SUPERVISED', 'supervis'), ('MACHINE', 'machin'), ('LEARNING', 'learn'), ('APPROACHES', 'approach'), (':', ':'), ('A', 'a'), ('SURVEY', 'survey')]

>> Stemming using Snowball Stemmer: 
 [('IQBAL', 'iqbal'), ('MUHAMMAD', 'muhammad'), ('AND', 'and'), ('ZHU', 'zhu'), ('YAN', 'yan'), (':', ':'), ('SUPERVISED', 'supervis'), ('MACHINE', 'machin'), ('LEARNING', 'learn'), ('APPROACHES', 'approach'), (':', ':'), ('A', 'a'), ('SURVEY', 'survey')]

>> Lemmatization: 
 [('IQBAL', 'IQBAL'), ('MUHAMMAD', 'MUHAMMAD'), ('AND', 'AND'), ('ZHU', 'ZHU'), ('YAN', 'YAN'), (':', ':'), ('SUPERVISED', 'SUPERVISED'), ('MACHINE', 'MACHINE'), ('LEARNING', 'LEARNING'), ('APPROACHES', 'APPROACHES'), (':', ':'), ('A', 'A'), ('SURVEY', 'SURVEY')]



========================================== PARAGRAPH 203 ===========================================

948  

------------------- Sentence 1 -------------------

948

>> Tokens are: 
 ['948']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('948', 'CD')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('948', '948')]

>> Stemming using Snowball Stemmer: 
 [('948', '948')]

>> Lemmatization: 
 [('948', '948')]



========================================== PARAGRAPH 204 ===========================================

The Fig.3 is an example of a decision tree for the training set  

------------------- Sentence 1 -------------------

The Fig.3 is an example of a decision tree for the training set

>> Tokens are: 
 ['The', 'Fig.3', 'example', 'decision', 'tree', 'training', 'set']

>> Bigrams are: 
 [('The', 'Fig.3'), ('Fig.3', 'example'), ('example', 'decision'), ('decision', 'tree'), ('tree', 'training'), ('training', 'set')]

>> Trigrams are: 
 [('The', 'Fig.3', 'example'), ('Fig.3', 'example', 'decision'), ('example', 'decision', 'tree'), ('decision', 'tree', 'training'), ('tree', 'training', 'set')]

>> POS Tags are: 
 [('The', 'DT'), ('Fig.3', 'NNP'), ('example', 'NN'), ('decision', 'NN'), ('tree', 'IN'), ('training', 'NN'), ('set', 'NN')]

>> Noun Phrases are: 
 ['The Fig.3 example decision', 'training set']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('Fig.3', 'fig.3'), ('example', 'exampl'), ('decision', 'decis'), ('tree', 'tree'), ('training', 'train'), ('set', 'set')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('Fig.3', 'fig.3'), ('example', 'exampl'), ('decision', 'decis'), ('tree', 'tree'), ('training', 'train'), ('set', 'set')]

>> Lemmatization: 
 [('The', 'The'), ('Fig.3', 'Fig.3'), ('example', 'example'), ('decision', 'decision'), ('tree', 'tree'), ('training', 'training'), ('set', 'set')]



========================================== PARAGRAPH 205 ===========================================

of Table.2. DT are extensively used is different computational  

------------------- Sentence 1 -------------------

of Table.2.

>> Tokens are: 
 ['Table.2', '.']

>> Bigrams are: 
 [('Table.2', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Table.2', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Table.2']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Table.2', 'table.2'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Table.2', 'table.2'), ('.', '.')]

>> Lemmatization: 
 [('Table.2', 'Table.2'), ('.', '.')]


------------------- Sentence 2 -------------------

DT are extensively used is different computational

>> Tokens are: 
 ['DT', 'extensively', 'used', 'different', 'computational']

>> Bigrams are: 
 [('DT', 'extensively'), ('extensively', 'used'), ('used', 'different'), ('different', 'computational')]

>> Trigrams are: 
 [('DT', 'extensively', 'used'), ('extensively', 'used', 'different'), ('used', 'different', 'computational')]

>> POS Tags are: 
 [('DT', 'NNP'), ('extensively', 'RB'), ('used', 'VBD'), ('different', 'JJ'), ('computational', 'JJ')]

>> Noun Phrases are: 
 ['DT']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('DT', 'dt'), ('extensively', 'extens'), ('used', 'use'), ('different', 'differ'), ('computational', 'comput')]

>> Stemming using Snowball Stemmer: 
 [('DT', 'dt'), ('extensively', 'extens'), ('used', 'use'), ('different', 'differ'), ('computational', 'comput')]

>> Lemmatization: 
 [('DT', 'DT'), ('extensively', 'extensively'), ('used', 'used'), ('different', 'different'), ('computational', 'computational')]



========================================== PARAGRAPH 206 ===========================================

fields to classify data. The reasons behinds the widely  

------------------- Sentence 1 -------------------

fields to classify data.

>> Tokens are: 
 ['fields', 'classify', 'data', '.']

>> Bigrams are: 
 [('fields', 'classify'), ('classify', 'data'), ('data', '.')]

>> Trigrams are: 
 [('fields', 'classify', 'data'), ('classify', 'data', '.')]

>> POS Tags are: 
 [('fields', 'NNS'), ('classify', 'VBP'), ('data', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['fields', 'data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('fields', 'field'), ('classify', 'classifi'), ('data', 'data'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('fields', 'field'), ('classify', 'classifi'), ('data', 'data'), ('.', '.')]

>> Lemmatization: 
 [('fields', 'field'), ('classify', 'classify'), ('data', 'data'), ('.', '.')]


------------------- Sentence 2 -------------------

The reasons behinds the widely

>> Tokens are: 
 ['The', 'reasons', 'behinds', 'widely']

>> Bigrams are: 
 [('The', 'reasons'), ('reasons', 'behinds'), ('behinds', 'widely')]

>> Trigrams are: 
 [('The', 'reasons', 'behinds'), ('reasons', 'behinds', 'widely')]

>> POS Tags are: 
 [('The', 'DT'), ('reasons', 'NNS'), ('behinds', 'VBZ'), ('widely', 'RB')]

>> Noun Phrases are: 
 ['The reasons']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('reasons', 'reason'), ('behinds', 'behind'), ('widely', 'wide')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('reasons', 'reason'), ('behinds', 'behind'), ('widely', 'wide')]

>> Lemmatization: 
 [('The', 'The'), ('reasons', 'reason'), ('behinds', 'behind'), ('widely', 'widely')]



========================================== PARAGRAPH 207 ===========================================

acceptability of DT learning algorithms are their flexibility to  

------------------- Sentence 1 -------------------

acceptability of DT learning algorithms are their flexibility to

>> Tokens are: 
 ['acceptability', 'DT', 'learning', 'algorithms', 'flexibility']

>> Bigrams are: 
 [('acceptability', 'DT'), ('DT', 'learning'), ('learning', 'algorithms'), ('algorithms', 'flexibility')]

>> Trigrams are: 
 [('acceptability', 'DT', 'learning'), ('DT', 'learning', 'algorithms'), ('learning', 'algorithms', 'flexibility')]

>> POS Tags are: 
 [('acceptability', 'NN'), ('DT', 'NNP'), ('learning', 'VBG'), ('algorithms', 'JJ'), ('flexibility', 'NN')]

>> Noun Phrases are: 
 ['acceptability DT', 'algorithms flexibility']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('acceptability', 'accept'), ('DT', 'dt'), ('learning', 'learn'), ('algorithms', 'algorithm'), ('flexibility', 'flexibl')]

>> Stemming using Snowball Stemmer: 
 [('acceptability', 'accept'), ('DT', 'dt'), ('learning', 'learn'), ('algorithms', 'algorithm'), ('flexibility', 'flexibl')]

>> Lemmatization: 
 [('acceptability', 'acceptability'), ('DT', 'DT'), ('learning', 'learning'), ('algorithms', 'algorithm'), ('flexibility', 'flexibility')]



========================================== PARAGRAPH 208 ===========================================

apply in wide range of problems. An interesting and important  

------------------- Sentence 1 -------------------

apply in wide range of problems.

>> Tokens are: 
 ['apply', 'wide', 'range', 'problems', '.']

>> Bigrams are: 
 [('apply', 'wide'), ('wide', 'range'), ('range', 'problems'), ('problems', '.')]

>> Trigrams are: 
 [('apply', 'wide', 'range'), ('wide', 'range', 'problems'), ('range', 'problems', '.')]

>> POS Tags are: 
 [('apply', 'VB'), ('wide', 'JJ'), ('range', 'NN'), ('problems', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['wide range problems']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('apply', 'appli'), ('wide', 'wide'), ('range', 'rang'), ('problems', 'problem'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('apply', 'appli'), ('wide', 'wide'), ('range', 'rang'), ('problems', 'problem'), ('.', '.')]

>> Lemmatization: 
 [('apply', 'apply'), ('wide', 'wide'), ('range', 'range'), ('problems', 'problem'), ('.', '.')]


------------------- Sentence 2 -------------------

An interesting and important

>> Tokens are: 
 ['An', 'interesting', 'important']

>> Bigrams are: 
 [('An', 'interesting'), ('interesting', 'important')]

>> Trigrams are: 
 [('An', 'interesting', 'important')]

>> POS Tags are: 
 [('An', 'DT'), ('interesting', 'JJ'), ('important', 'JJ')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('An', 'an'), ('interesting', 'interest'), ('important', 'import')]

>> Stemming using Snowball Stemmer: 
 [('An', 'an'), ('interesting', 'interest'), ('important', 'import')]

>> Lemmatization: 
 [('An', 'An'), ('interesting', 'interesting'), ('important', 'important')]



========================================== PARAGRAPH 209 ===========================================

property of a decision tree and its resulting set of rules is that the  

------------------- Sentence 1 -------------------

property of a decision tree and its resulting set of rules is that the

>> Tokens are: 
 ['property', 'decision', 'tree', 'resulting', 'set', 'rules']

>> Bigrams are: 
 [('property', 'decision'), ('decision', 'tree'), ('tree', 'resulting'), ('resulting', 'set'), ('set', 'rules')]

>> Trigrams are: 
 [('property', 'decision', 'tree'), ('decision', 'tree', 'resulting'), ('tree', 'resulting', 'set'), ('resulting', 'set', 'rules')]

>> POS Tags are: 
 [('property', 'NN'), ('decision', 'NN'), ('tree', 'NN'), ('resulting', 'VBG'), ('set', 'VBN'), ('rules', 'NNS')]

>> Noun Phrases are: 
 ['property decision tree', 'rules']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('property', 'properti'), ('decision', 'decis'), ('tree', 'tree'), ('resulting', 'result'), ('set', 'set'), ('rules', 'rule')]

>> Stemming using Snowball Stemmer: 
 [('property', 'properti'), ('decision', 'decis'), ('tree', 'tree'), ('resulting', 'result'), ('set', 'set'), ('rules', 'rule')]

>> Lemmatization: 
 [('property', 'property'), ('decision', 'decision'), ('tree', 'tree'), ('resulting', 'resulting'), ('set', 'set'), ('rules', 'rule')]



========================================== PARAGRAPH 210 ===========================================

tree paths or the rules are mutually exclusive and exhaustive.  

------------------- Sentence 1 -------------------

tree paths or the rules are mutually exclusive and exhaustive.

>> Tokens are: 
 ['tree', 'paths', 'rules', 'mutually', 'exclusive', 'exhaustive', '.']

>> Bigrams are: 
 [('tree', 'paths'), ('paths', 'rules'), ('rules', 'mutually'), ('mutually', 'exclusive'), ('exclusive', 'exhaustive'), ('exhaustive', '.')]

>> Trigrams are: 
 [('tree', 'paths', 'rules'), ('paths', 'rules', 'mutually'), ('rules', 'mutually', 'exclusive'), ('mutually', 'exclusive', 'exhaustive'), ('exclusive', 'exhaustive', '.')]

>> POS Tags are: 
 [('tree', 'JJ'), ('paths', 'NNS'), ('rules', 'NNS'), ('mutually', 'RB'), ('exclusive', 'JJ'), ('exhaustive', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['tree paths rules', 'exclusive exhaustive']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('tree', 'tree'), ('paths', 'path'), ('rules', 'rule'), ('mutually', 'mutual'), ('exclusive', 'exclus'), ('exhaustive', 'exhaust'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('tree', 'tree'), ('paths', 'path'), ('rules', 'rule'), ('mutually', 'mutual'), ('exclusive', 'exclus'), ('exhaustive', 'exhaust'), ('.', '.')]

>> Lemmatization: 
 [('tree', 'tree'), ('paths', 'path'), ('rules', 'rule'), ('mutually', 'mutually'), ('exclusive', 'exclusive'), ('exhaustive', 'exhaustive'), ('.', '.')]



========================================== PARAGRAPH 211 ===========================================

This means that every data instance/record/example/vector/case  

------------------- Sentence 1 -------------------

This means that every data instance/record/example/vector/case

>> Tokens are: 
 ['This', 'means', 'every', 'data', 'instance/record/example/vector/case']

>> Bigrams are: 
 [('This', 'means'), ('means', 'every'), ('every', 'data'), ('data', 'instance/record/example/vector/case')]

>> Trigrams are: 
 [('This', 'means', 'every'), ('means', 'every', 'data'), ('every', 'data', 'instance/record/example/vector/case')]

>> POS Tags are: 
 [('This', 'DT'), ('means', 'VBZ'), ('every', 'DT'), ('data', 'NN'), ('instance/record/example/vector/case', 'NN')]

>> Noun Phrases are: 
 ['every data instance/record/example/vector/case']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('This', 'thi'), ('means', 'mean'), ('every', 'everi'), ('data', 'data'), ('instance/record/example/vector/case', 'instance/record/example/vector/cas')]

>> Stemming using Snowball Stemmer: 
 [('This', 'this'), ('means', 'mean'), ('every', 'everi'), ('data', 'data'), ('instance/record/example/vector/case', 'instance/record/example/vector/cas')]

>> Lemmatization: 
 [('This', 'This'), ('means', 'mean'), ('every', 'every'), ('data', 'data'), ('instance/record/example/vector/case', 'instance/record/example/vector/case')]



========================================== PARAGRAPH 212 ===========================================

is covered by a single rule. According to Pierre et al. [7], DT  

------------------- Sentence 1 -------------------

is covered by a single rule.

>> Tokens are: 
 ['covered', 'single', 'rule', '.']

>> Bigrams are: 
 [('covered', 'single'), ('single', 'rule'), ('rule', '.')]

>> Trigrams are: 
 [('covered', 'single', 'rule'), ('single', 'rule', '.')]

>> POS Tags are: 
 [('covered', 'VBN'), ('single', 'JJ'), ('rule', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['single rule']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('covered', 'cover'), ('single', 'singl'), ('rule', 'rule'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('covered', 'cover'), ('single', 'singl'), ('rule', 'rule'), ('.', '.')]

>> Lemmatization: 
 [('covered', 'covered'), ('single', 'single'), ('rule', 'rule'), ('.', '.')]


------------------- Sentence 2 -------------------

According to Pierre et al.

>> Tokens are: 
 ['According', 'Pierre', 'et', 'al', '.']

>> Bigrams are: 
 [('According', 'Pierre'), ('Pierre', 'et'), ('et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('According', 'Pierre', 'et'), ('Pierre', 'et', 'al'), ('et', 'al', '.')]

>> POS Tags are: 
 [('According', 'VBG'), ('Pierre', 'NNP'), ('et', 'NN'), ('al', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Pierre et al']

>> Named Entities are: 
 [('PERSON', 'Pierre')] 

>> Stemming using Porter Stemmer: 
 [('According', 'accord'), ('Pierre', 'pierr'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('According', 'accord'), ('Pierre', 'pierr'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('According', 'According'), ('Pierre', 'Pierre'), ('et', 'et'), ('al', 'al'), ('.', '.')]


------------------- Sentence 3 -------------------

[7], DT

>> Tokens are: 
 ['[', '7', ']', ',', 'DT']

>> Bigrams are: 
 [('[', '7'), ('7', ']'), (']', ','), (',', 'DT')]

>> Trigrams are: 
 [('[', '7', ']'), ('7', ']', ','), (']', ',', 'DT')]

>> POS Tags are: 
 [('[', 'RB'), ('7', 'CD'), (']', 'NNS'), (',', ','), ('DT', 'NNP')]

>> Noun Phrases are: 
 [']', 'DT']

>> Named Entities are: 
 [('ORGANIZATION', 'DT')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('7', '7'), (']', ']'), (',', ','), ('DT', 'dt')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('7', '7'), (']', ']'), (',', ','), ('DT', 'dt')]

>> Lemmatization: 
 [('[', '['), ('7', '7'), (']', ']'), (',', ','), ('DT', 'DT')]



========================================== PARAGRAPH 213 ===========================================

algorithms combined with ensemble methods, can provide better  

------------------- Sentence 1 -------------------

algorithms combined with ensemble methods, can provide better

>> Tokens are: 
 ['algorithms', 'combined', 'ensemble', 'methods', ',', 'provide', 'better']

>> Bigrams are: 
 [('algorithms', 'combined'), ('combined', 'ensemble'), ('ensemble', 'methods'), ('methods', ','), (',', 'provide'), ('provide', 'better')]

>> Trigrams are: 
 [('algorithms', 'combined', 'ensemble'), ('combined', 'ensemble', 'methods'), ('ensemble', 'methods', ','), ('methods', ',', 'provide'), (',', 'provide', 'better')]

>> POS Tags are: 
 [('algorithms', 'NN'), ('combined', 'VBD'), ('ensemble', 'JJ'), ('methods', 'NNS'), (',', ','), ('provide', 'VBP'), ('better', 'JJR')]

>> Noun Phrases are: 
 ['algorithms', 'ensemble methods']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('algorithms', 'algorithm'), ('combined', 'combin'), ('ensemble', 'ensembl'), ('methods', 'method'), (',', ','), ('provide', 'provid'), ('better', 'better')]

>> Stemming using Snowball Stemmer: 
 [('algorithms', 'algorithm'), ('combined', 'combin'), ('ensemble', 'ensembl'), ('methods', 'method'), (',', ','), ('provide', 'provid'), ('better', 'better')]

>> Lemmatization: 
 [('algorithms', 'algorithm'), ('combined', 'combined'), ('ensemble', 'ensemble'), ('methods', 'method'), (',', ','), ('provide', 'provide'), ('better', 'better')]



========================================== PARAGRAPH 214 ===========================================

results in terms of predictive accuracy and significantly in the  

------------------- Sentence 1 -------------------

results in terms of predictive accuracy and significantly in the

>> Tokens are: 
 ['results', 'terms', 'predictive', 'accuracy', 'significantly']

>> Bigrams are: 
 [('results', 'terms'), ('terms', 'predictive'), ('predictive', 'accuracy'), ('accuracy', 'significantly')]

>> Trigrams are: 
 [('results', 'terms', 'predictive'), ('terms', 'predictive', 'accuracy'), ('predictive', 'accuracy', 'significantly')]

>> POS Tags are: 
 [('results', 'NNS'), ('terms', 'NNS'), ('predictive', 'JJ'), ('accuracy', 'NN'), ('significantly', 'RB')]

>> Noun Phrases are: 
 ['results terms', 'predictive accuracy']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('results', 'result'), ('terms', 'term'), ('predictive', 'predict'), ('accuracy', 'accuraci'), ('significantly', 'significantli')]

>> Stemming using Snowball Stemmer: 
 [('results', 'result'), ('terms', 'term'), ('predictive', 'predict'), ('accuracy', 'accuraci'), ('significantly', 'signific')]

>> Lemmatization: 
 [('results', 'result'), ('terms', 'term'), ('predictive', 'predictive'), ('accuracy', 'accuracy'), ('significantly', 'significantly')]



========================================== PARAGRAPH 215 ===========================================

context of high-throughput data sets, tree-based methods are also  

------------------- Sentence 1 -------------------

context of high-throughput data sets, tree-based methods are also

>> Tokens are: 
 ['context', 'high-throughput', 'data', 'sets', ',', 'tree-based', 'methods', 'also']

>> Bigrams are: 
 [('context', 'high-throughput'), ('high-throughput', 'data'), ('data', 'sets'), ('sets', ','), (',', 'tree-based'), ('tree-based', 'methods'), ('methods', 'also')]

>> Trigrams are: 
 [('context', 'high-throughput', 'data'), ('high-throughput', 'data', 'sets'), ('data', 'sets', ','), ('sets', ',', 'tree-based'), (',', 'tree-based', 'methods'), ('tree-based', 'methods', 'also')]

>> POS Tags are: 
 [('context', 'JJ'), ('high-throughput', 'JJ'), ('data', 'NNS'), ('sets', 'NNS'), (',', ','), ('tree-based', 'JJ'), ('methods', 'NNS'), ('also', 'RB')]

>> Noun Phrases are: 
 ['context high-throughput data sets', 'tree-based methods']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('context', 'context'), ('high-throughput', 'high-throughput'), ('data', 'data'), ('sets', 'set'), (',', ','), ('tree-based', 'tree-bas'), ('methods', 'method'), ('also', 'also')]

>> Stemming using Snowball Stemmer: 
 [('context', 'context'), ('high-throughput', 'high-throughput'), ('data', 'data'), ('sets', 'set'), (',', ','), ('tree-based', 'tree-bas'), ('methods', 'method'), ('also', 'also')]

>> Lemmatization: 
 [('context', 'context'), ('high-throughput', 'high-throughput'), ('data', 'data'), ('sets', 'set'), (',', ','), ('tree-based', 'tree-based'), ('methods', 'method'), ('also', 'also')]



========================================== PARAGRAPH 216 ===========================================

highly scalable from a computational point of view.  

------------------- Sentence 1 -------------------

highly scalable from a computational point of view.

>> Tokens are: 
 ['highly', 'scalable', 'computational', 'point', 'view', '.']

>> Bigrams are: 
 [('highly', 'scalable'), ('scalable', 'computational'), ('computational', 'point'), ('point', 'view'), ('view', '.')]

>> Trigrams are: 
 [('highly', 'scalable', 'computational'), ('scalable', 'computational', 'point'), ('computational', 'point', 'view'), ('point', 'view', '.')]

>> POS Tags are: 
 [('highly', 'RB'), ('scalable', 'JJ'), ('computational', 'JJ'), ('point', 'NN'), ('view', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['scalable computational point view']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('highly', 'highli'), ('scalable', 'scalabl'), ('computational', 'comput'), ('point', 'point'), ('view', 'view'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('highly', 'high'), ('scalable', 'scalabl'), ('computational', 'comput'), ('point', 'point'), ('view', 'view'), ('.', '.')]

>> Lemmatization: 
 [('highly', 'highly'), ('scalable', 'scalable'), ('computational', 'computational'), ('point', 'point'), ('view', 'view'), ('.', '.')]



========================================== PARAGRAPH 217 ===========================================

  


========================================== PARAGRAPH 218 ===========================================

Fig.3. A Sample Decision Tree  

------------------- Sentence 1 -------------------

Fig.3.

>> Tokens are: 
 ['Fig.3', '.']

>> Bigrams are: 
 [('Fig.3', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Fig.3', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Fig.3']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Fig.3', 'fig.3'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Fig.3', 'fig.3'), ('.', '.')]

>> Lemmatization: 
 [('Fig.3', 'Fig.3'), ('.', '.')]


------------------- Sentence 2 -------------------

A Sample Decision Tree

>> Tokens are: 
 ['A', 'Sample', 'Decision', 'Tree']

>> Bigrams are: 
 [('A', 'Sample'), ('Sample', 'Decision'), ('Decision', 'Tree')]

>> Trigrams are: 
 [('A', 'Sample', 'Decision'), ('Sample', 'Decision', 'Tree')]

>> POS Tags are: 
 [('A', 'DT'), ('Sample', 'NNP'), ('Decision', 'NNP'), ('Tree', 'NNP')]

>> Noun Phrases are: 
 ['A Sample Decision Tree']

>> Named Entities are: 
 [('ORGANIZATION', 'Sample Decision Tree')] 

>> Stemming using Porter Stemmer: 
 [('A', 'a'), ('Sample', 'sampl'), ('Decision', 'decis'), ('Tree', 'tree')]

>> Stemming using Snowball Stemmer: 
 [('A', 'a'), ('Sample', 'sampl'), ('Decision', 'decis'), ('Tree', 'tree')]

>> Lemmatization: 
 [('A', 'A'), ('Sample', 'Sample'), ('Decision', 'Decision'), ('Tree', 'Tree')]



========================================== PARAGRAPH 219 ===========================================

By using the DT depicted in Fig.3 as an example, the  

------------------- Sentence 1 -------------------

By using the DT depicted in Fig.3 as an example, the

>> Tokens are: 
 ['By', 'using', 'DT', 'depicted', 'Fig.3', 'example', ',']

>> Bigrams are: 
 [('By', 'using'), ('using', 'DT'), ('DT', 'depicted'), ('depicted', 'Fig.3'), ('Fig.3', 'example'), ('example', ',')]

>> Trigrams are: 
 [('By', 'using', 'DT'), ('using', 'DT', 'depicted'), ('DT', 'depicted', 'Fig.3'), ('depicted', 'Fig.3', 'example'), ('Fig.3', 'example', ',')]

>> POS Tags are: 
 [('By', 'IN'), ('using', 'VBG'), ('DT', 'NNP'), ('depicted', 'VBD'), ('Fig.3', 'NNP'), ('example', 'NN'), (',', ',')]

>> Noun Phrases are: 
 ['DT', 'Fig.3 example']

>> Named Entities are: 
 [('ORGANIZATION', 'DT')] 

>> Stemming using Porter Stemmer: 
 [('By', 'by'), ('using', 'use'), ('DT', 'dt'), ('depicted', 'depict'), ('Fig.3', 'fig.3'), ('example', 'exampl'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('By', 'by'), ('using', 'use'), ('DT', 'dt'), ('depicted', 'depict'), ('Fig.3', 'fig.3'), ('example', 'exampl'), (',', ',')]

>> Lemmatization: 
 [('By', 'By'), ('using', 'using'), ('DT', 'DT'), ('depicted', 'depicted'), ('Fig.3', 'Fig.3'), ('example', 'example'), (',', ',')]



========================================== PARAGRAPH 220 ===========================================

instance (at1 = a1, at2 = b2, at3 = a3, at4 = b4) would sort to the  

------------------- Sentence 1 -------------------

instance (at1 = a1, at2 = b2, at3 = a3, at4 = b4) would sort to the

>> Tokens are: 
 ['instance', '(', 'at1', '=', 'a1', ',', 'at2', '=', 'b2', ',', 'at3', '=', 'a3', ',', 'at4', '=', 'b4', ')', 'would', 'sort']

>> Bigrams are: 
 [('instance', '('), ('(', 'at1'), ('at1', '='), ('=', 'a1'), ('a1', ','), (',', 'at2'), ('at2', '='), ('=', 'b2'), ('b2', ','), (',', 'at3'), ('at3', '='), ('=', 'a3'), ('a3', ','), (',', 'at4'), ('at4', '='), ('=', 'b4'), ('b4', ')'), (')', 'would'), ('would', 'sort')]

>> Trigrams are: 
 [('instance', '(', 'at1'), ('(', 'at1', '='), ('at1', '=', 'a1'), ('=', 'a1', ','), ('a1', ',', 'at2'), (',', 'at2', '='), ('at2', '=', 'b2'), ('=', 'b2', ','), ('b2', ',', 'at3'), (',', 'at3', '='), ('at3', '=', 'a3'), ('=', 'a3', ','), ('a3', ',', 'at4'), (',', 'at4', '='), ('at4', '=', 'b4'), ('=', 'b4', ')'), ('b4', ')', 'would'), (')', 'would', 'sort')]

>> POS Tags are: 
 [('instance', 'NN'), ('(', '('), ('at1', 'JJ'), ('=', 'NNP'), ('a1', 'NN'), (',', ','), ('at2', 'JJ'), ('=', 'NNP'), ('b2', 'NN'), (',', ','), ('at3', 'JJ'), ('=', 'NNP'), ('a3', 'NN'), (',', ','), ('at4', 'JJ'), ('=', 'NNP'), ('b4', 'NN'), (')', ')'), ('would', 'MD'), ('sort', 'VB')]

>> Noun Phrases are: 
 ['instance', 'at1 = a1', 'at2 = b2', 'at3 = a3', 'at4 = b4']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('instance', 'instanc'), ('(', '('), ('at1', 'at1'), ('=', '='), ('a1', 'a1'), (',', ','), ('at2', 'at2'), ('=', '='), ('b2', 'b2'), (',', ','), ('at3', 'at3'), ('=', '='), ('a3', 'a3'), (',', ','), ('at4', 'at4'), ('=', '='), ('b4', 'b4'), (')', ')'), ('would', 'would'), ('sort', 'sort')]

>> Stemming using Snowball Stemmer: 
 [('instance', 'instanc'), ('(', '('), ('at1', 'at1'), ('=', '='), ('a1', 'a1'), (',', ','), ('at2', 'at2'), ('=', '='), ('b2', 'b2'), (',', ','), ('at3', 'at3'), ('=', '='), ('a3', 'a3'), (',', ','), ('at4', 'at4'), ('=', '='), ('b4', 'b4'), (')', ')'), ('would', 'would'), ('sort', 'sort')]

>> Lemmatization: 
 [('instance', 'instance'), ('(', '('), ('at1', 'at1'), ('=', '='), ('a1', 'a1'), (',', ','), ('at2', 'at2'), ('=', '='), ('b2', 'b2'), (',', ','), ('at3', 'at3'), ('=', '='), ('a3', 'a3'), (',', ','), ('at4', 'at4'), ('=', '='), ('b4', 'b4'), (')', ')'), ('would', 'would'), ('sort', 'sort')]



========================================== PARAGRAPH 221 ===========================================

nodes: at1, at2, and finally at3, which would classify the instance  

------------------- Sentence 1 -------------------

nodes: at1, at2, and finally at3, which would classify the instance

>> Tokens are: 
 ['nodes', ':', 'at1', ',', 'at2', ',', 'finally', 'at3', ',', 'would', 'classify', 'instance']

>> Bigrams are: 
 [('nodes', ':'), (':', 'at1'), ('at1', ','), (',', 'at2'), ('at2', ','), (',', 'finally'), ('finally', 'at3'), ('at3', ','), (',', 'would'), ('would', 'classify'), ('classify', 'instance')]

>> Trigrams are: 
 [('nodes', ':', 'at1'), (':', 'at1', ','), ('at1', ',', 'at2'), (',', 'at2', ','), ('at2', ',', 'finally'), (',', 'finally', 'at3'), ('finally', 'at3', ','), ('at3', ',', 'would'), (',', 'would', 'classify'), ('would', 'classify', 'instance')]

>> POS Tags are: 
 [('nodes', 'NNS'), (':', ':'), ('at1', 'NN'), (',', ','), ('at2', 'NN'), (',', ','), ('finally', 'RB'), ('at3', 'JJ'), (',', ','), ('would', 'MD'), ('classify', 'VB'), ('instance', 'NN')]

>> Noun Phrases are: 
 ['nodes', 'at1', 'at2', 'instance']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('nodes', 'node'), (':', ':'), ('at1', 'at1'), (',', ','), ('at2', 'at2'), (',', ','), ('finally', 'final'), ('at3', 'at3'), (',', ','), ('would', 'would'), ('classify', 'classifi'), ('instance', 'instanc')]

>> Stemming using Snowball Stemmer: 
 [('nodes', 'node'), (':', ':'), ('at1', 'at1'), (',', ','), ('at2', 'at2'), (',', ','), ('finally', 'final'), ('at3', 'at3'), (',', ','), ('would', 'would'), ('classify', 'classifi'), ('instance', 'instanc')]

>> Lemmatization: 
 [('nodes', 'node'), (':', ':'), ('at1', 'at1'), (',', ','), ('at2', 'at2'), (',', ','), ('finally', 'finally'), ('at3', 'at3'), (',', ','), ('would', 'would'), ('classify', 'classify'), ('instance', 'instance')]



========================================== PARAGRAPH 222 ===========================================

as being positive (represented by the values Yes).  

------------------- Sentence 1 -------------------

as being positive (represented by the values Yes).

>> Tokens are: 
 ['positive', '(', 'represented', 'values', '', 'Yes', '', ')', '.']

>> Bigrams are: 
 [('positive', '('), ('(', 'represented'), ('represented', 'values'), ('values', ''), ('', 'Yes'), ('Yes', ''), ('', ')'), (')', '.')]

>> Trigrams are: 
 [('positive', '(', 'represented'), ('(', 'represented', 'values'), ('represented', 'values', ''), ('values', '', 'Yes'), ('', 'Yes', ''), ('Yes', '', ')'), ('', ')', '.')]

>> POS Tags are: 
 [('positive', 'JJ'), ('(', '('), ('represented', 'VBN'), ('values', 'NNS'), ('', 'VB'), ('Yes', 'NNP'), ('', 'NNP'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['values', 'Yes ']

>> Named Entities are: 
 [('PERSON', 'Yes')] 

>> Stemming using Porter Stemmer: 
 [('positive', 'posit'), ('(', '('), ('represented', 'repres'), ('values', 'valu'), ('', ''), ('Yes', 'ye'), ('', ''), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('positive', 'posit'), ('(', '('), ('represented', 'repres'), ('values', 'valu'), ('', ''), ('Yes', 'yes'), ('', ''), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('positive', 'positive'), ('(', '('), ('represented', 'represented'), ('values', 'value'), ('', ''), ('Yes', 'Yes'), ('', ''), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 223 ===========================================

Table.2. Sample Training set  

------------------- Sentence 1 -------------------

Table.2.

>> Tokens are: 
 ['Table.2', '.']

>> Bigrams are: 
 [('Table.2', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Table.2', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Table.2']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Table.2', 'table.2'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Table.2', 'table.2'), ('.', '.')]

>> Lemmatization: 
 [('Table.2', 'Table.2'), ('.', '.')]


------------------- Sentence 2 -------------------

Sample Training set

>> Tokens are: 
 ['Sample', 'Training', 'set']

>> Bigrams are: 
 [('Sample', 'Training'), ('Training', 'set')]

>> Trigrams are: 
 [('Sample', 'Training', 'set')]

>> POS Tags are: 
 [('Sample', 'JJ'), ('Training', 'NNP'), ('set', 'NN')]

>> Noun Phrases are: 
 ['Sample Training set']

>> Named Entities are: 
 [('PERSON', 'Sample'), ('ORGANIZATION', 'Training')] 

>> Stemming using Porter Stemmer: 
 [('Sample', 'sampl'), ('Training', 'train'), ('set', 'set')]

>> Stemming using Snowball Stemmer: 
 [('Sample', 'sampl'), ('Training', 'train'), ('set', 'set')]

>> Lemmatization: 
 [('Sample', 'Sample'), ('Training', 'Training'), ('set', 'set')]



========================================== PARAGRAPH 224 ===========================================

at1 at2 at3 at4 Class  

------------------- Sentence 1 -------------------

at1 at2 at3 at4 Class

>> Tokens are: 
 ['at1', 'at2', 'at3', 'at4', 'Class']

>> Bigrams are: 
 [('at1', 'at2'), ('at2', 'at3'), ('at3', 'at4'), ('at4', 'Class')]

>> Trigrams are: 
 [('at1', 'at2', 'at3'), ('at2', 'at3', 'at4'), ('at3', 'at4', 'Class')]

>> POS Tags are: 
 [('at1', 'NN'), ('at2', 'NN'), ('at3', 'NN'), ('at4', 'NN'), ('Class', 'NN')]

>> Noun Phrases are: 
 ['at1 at2 at3 at4 Class']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('at1', 'at1'), ('at2', 'at2'), ('at3', 'at3'), ('at4', 'at4'), ('Class', 'class')]

>> Stemming using Snowball Stemmer: 
 [('at1', 'at1'), ('at2', 'at2'), ('at3', 'at3'), ('at4', 'at4'), ('Class', 'class')]

>> Lemmatization: 
 [('at1', 'at1'), ('at2', 'at2'), ('at3', 'at3'), ('at4', 'at4'), ('Class', 'Class')]



========================================== PARAGRAPH 225 ===========================================

a1 a2 a3 a4 Yes  

------------------- Sentence 1 -------------------

a1 a2 a3 a4 Yes

>> Tokens are: 
 ['a1', 'a2', 'a3', 'a4', 'Yes']

>> Bigrams are: 
 [('a1', 'a2'), ('a2', 'a3'), ('a3', 'a4'), ('a4', 'Yes')]

>> Trigrams are: 
 [('a1', 'a2', 'a3'), ('a2', 'a3', 'a4'), ('a3', 'a4', 'Yes')]

>> POS Tags are: 
 [('a1', 'NN'), ('a2', 'NN'), ('a3', 'JJ'), ('a4', 'JJ'), ('Yes', 'NN')]

>> Noun Phrases are: 
 ['a1 a2', 'a3 a4 Yes']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('a1', 'a1'), ('a2', 'a2'), ('a3', 'a3'), ('a4', 'a4'), ('Yes', 'ye')]

>> Stemming using Snowball Stemmer: 
 [('a1', 'a1'), ('a2', 'a2'), ('a3', 'a3'), ('a4', 'a4'), ('Yes', 'yes')]

>> Lemmatization: 
 [('a1', 'a1'), ('a2', 'a2'), ('a3', 'a3'), ('a4', 'a4'), ('Yes', 'Yes')]



========================================== PARAGRAPH 226 ===========================================

a1 a2 a3 b4 Yes  

------------------- Sentence 1 -------------------

a1 a2 a3 b4 Yes

>> Tokens are: 
 ['a1', 'a2', 'a3', 'b4', 'Yes']

>> Bigrams are: 
 [('a1', 'a2'), ('a2', 'a3'), ('a3', 'b4'), ('b4', 'Yes')]

>> Trigrams are: 
 [('a1', 'a2', 'a3'), ('a2', 'a3', 'b4'), ('a3', 'b4', 'Yes')]

>> POS Tags are: 
 [('a1', 'NN'), ('a2', 'NN'), ('a3', 'JJ'), ('b4', 'NN'), ('Yes', 'NN')]

>> Noun Phrases are: 
 ['a1 a2', 'a3 b4 Yes']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('a1', 'a1'), ('a2', 'a2'), ('a3', 'a3'), ('b4', 'b4'), ('Yes', 'ye')]

>> Stemming using Snowball Stemmer: 
 [('a1', 'a1'), ('a2', 'a2'), ('a3', 'a3'), ('b4', 'b4'), ('Yes', 'yes')]

>> Lemmatization: 
 [('a1', 'a1'), ('a2', 'a2'), ('a3', 'a3'), ('b4', 'b4'), ('Yes', 'Yes')]



========================================== PARAGRAPH 227 ===========================================

a1 b2 a3 a4 Yes  

------------------- Sentence 1 -------------------

a1 b2 a3 a4 Yes

>> Tokens are: 
 ['a1', 'b2', 'a3', 'a4', 'Yes']

>> Bigrams are: 
 [('a1', 'b2'), ('b2', 'a3'), ('a3', 'a4'), ('a4', 'Yes')]

>> Trigrams are: 
 [('a1', 'b2', 'a3'), ('b2', 'a3', 'a4'), ('a3', 'a4', 'Yes')]

>> POS Tags are: 
 [('a1', 'NN'), ('b2', 'NN'), ('a3', 'JJ'), ('a4', 'JJ'), ('Yes', 'NN')]

>> Noun Phrases are: 
 ['a1 b2', 'a3 a4 Yes']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('a1', 'a1'), ('b2', 'b2'), ('a3', 'a3'), ('a4', 'a4'), ('Yes', 'ye')]

>> Stemming using Snowball Stemmer: 
 [('a1', 'a1'), ('b2', 'b2'), ('a3', 'a3'), ('a4', 'a4'), ('Yes', 'yes')]

>> Lemmatization: 
 [('a1', 'a1'), ('b2', 'b2'), ('a3', 'a3'), ('a4', 'a4'), ('Yes', 'Yes')]



========================================== PARAGRAPH 228 ===========================================

a1 b2 b3 b4 No  

------------------- Sentence 1 -------------------

a1 b2 b3 b4 No

>> Tokens are: 
 ['a1', 'b2', 'b3', 'b4', 'No']

>> Bigrams are: 
 [('a1', 'b2'), ('b2', 'b3'), ('b3', 'b4'), ('b4', 'No')]

>> Trigrams are: 
 [('a1', 'b2', 'b3'), ('b2', 'b3', 'b4'), ('b3', 'b4', 'No')]

>> POS Tags are: 
 [('a1', 'NN'), ('b2', 'NN'), ('b3', 'NN'), ('b4', 'VBZ'), ('No', 'DT')]

>> Noun Phrases are: 
 ['a1 b2 b3']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('a1', 'a1'), ('b2', 'b2'), ('b3', 'b3'), ('b4', 'b4'), ('No', 'no')]

>> Stemming using Snowball Stemmer: 
 [('a1', 'a1'), ('b2', 'b2'), ('b3', 'b3'), ('b4', 'b4'), ('No', 'no')]

>> Lemmatization: 
 [('a1', 'a1'), ('b2', 'b2'), ('b3', 'b3'), ('b4', 'b4'), ('No', 'No')]



========================================== PARAGRAPH 229 ===========================================

a1 c2 a3 a4 Yes  

------------------- Sentence 1 -------------------

a1 c2 a3 a4 Yes

>> Tokens are: 
 ['a1', 'c2', 'a3', 'a4', 'Yes']

>> Bigrams are: 
 [('a1', 'c2'), ('c2', 'a3'), ('a3', 'a4'), ('a4', 'Yes')]

>> Trigrams are: 
 [('a1', 'c2', 'a3'), ('c2', 'a3', 'a4'), ('a3', 'a4', 'Yes')]

>> POS Tags are: 
 [('a1', 'NN'), ('c2', 'NN'), ('a3', 'JJ'), ('a4', 'JJ'), ('Yes', 'NN')]

>> Noun Phrases are: 
 ['a1 c2', 'a3 a4 Yes']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('a1', 'a1'), ('c2', 'c2'), ('a3', 'a3'), ('a4', 'a4'), ('Yes', 'ye')]

>> Stemming using Snowball Stemmer: 
 [('a1', 'a1'), ('c2', 'c2'), ('a3', 'a3'), ('a4', 'a4'), ('Yes', 'yes')]

>> Lemmatization: 
 [('a1', 'a1'), ('c2', 'c2'), ('a3', 'a3'), ('a4', 'a4'), ('Yes', 'Yes')]



========================================== PARAGRAPH 230 ===========================================

a1 c2 a3 b4 No  

------------------- Sentence 1 -------------------

a1 c2 a3 b4 No

>> Tokens are: 
 ['a1', 'c2', 'a3', 'b4', 'No']

>> Bigrams are: 
 [('a1', 'c2'), ('c2', 'a3'), ('a3', 'b4'), ('b4', 'No')]

>> Trigrams are: 
 [('a1', 'c2', 'a3'), ('c2', 'a3', 'b4'), ('a3', 'b4', 'No')]

>> POS Tags are: 
 [('a1', 'NN'), ('c2', 'NN'), ('a3', 'NN'), ('b4', 'VBZ'), ('No', 'DT')]

>> Noun Phrases are: 
 ['a1 c2 a3']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('a1', 'a1'), ('c2', 'c2'), ('a3', 'a3'), ('b4', 'b4'), ('No', 'no')]

>> Stemming using Snowball Stemmer: 
 [('a1', 'a1'), ('c2', 'c2'), ('a3', 'a3'), ('b4', 'b4'), ('No', 'no')]

>> Lemmatization: 
 [('a1', 'a1'), ('c2', 'c2'), ('a3', 'a3'), ('b4', 'b4'), ('No', 'No')]



========================================== PARAGRAPH 231 ===========================================

b1 b2 b3 b4 No  

------------------- Sentence 1 -------------------

b1 b2 b3 b4 No

>> Tokens are: 
 ['b1', 'b2', 'b3', 'b4', 'No']

>> Bigrams are: 
 [('b1', 'b2'), ('b2', 'b3'), ('b3', 'b4'), ('b4', 'No')]

>> Trigrams are: 
 [('b1', 'b2', 'b3'), ('b2', 'b3', 'b4'), ('b3', 'b4', 'No')]

>> POS Tags are: 
 [('b1', 'NN'), ('b2', 'NN'), ('b3', 'NN'), ('b4', 'VBZ'), ('No', 'DT')]

>> Noun Phrases are: 
 ['b1 b2 b3']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('b1', 'b1'), ('b2', 'b2'), ('b3', 'b3'), ('b4', 'b4'), ('No', 'no')]

>> Stemming using Snowball Stemmer: 
 [('b1', 'b1'), ('b2', 'b2'), ('b3', 'b3'), ('b4', 'b4'), ('No', 'no')]

>> Lemmatization: 
 [('b1', 'b1'), ('b2', 'b2'), ('b3', 'b3'), ('b4', 'b4'), ('No', 'No')]



========================================== PARAGRAPH 232 ===========================================

c1 b2 b3 b4 No  

------------------- Sentence 1 -------------------

c1 b2 b3 b4 No

>> Tokens are: 
 ['c1', 'b2', 'b3', 'b4', 'No']

>> Bigrams are: 
 [('c1', 'b2'), ('b2', 'b3'), ('b3', 'b4'), ('b4', 'No')]

>> Trigrams are: 
 [('c1', 'b2', 'b3'), ('b2', 'b3', 'b4'), ('b3', 'b4', 'No')]

>> POS Tags are: 
 [('c1', 'NN'), ('b2', 'NN'), ('b3', 'NN'), ('b4', 'VBZ'), ('No', 'DT')]

>> Noun Phrases are: 
 ['c1 b2 b3']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('c1', 'c1'), ('b2', 'b2'), ('b3', 'b3'), ('b4', 'b4'), ('No', 'no')]

>> Stemming using Snowball Stemmer: 
 [('c1', 'c1'), ('b2', 'b2'), ('b3', 'b3'), ('b4', 'b4'), ('No', 'no')]

>> Lemmatization: 
 [('c1', 'c1'), ('b2', 'b2'), ('b3', 'b3'), ('b4', 'b4'), ('No', 'No')]



========================================== PARAGRAPH 233 ===========================================

The feature that best divides the training data would be the  

------------------- Sentence 1 -------------------

The feature that best divides the training data would be the

>> Tokens are: 
 ['The', 'feature', 'best', 'divides', 'training', 'data', 'would']

>> Bigrams are: 
 [('The', 'feature'), ('feature', 'best'), ('best', 'divides'), ('divides', 'training'), ('training', 'data'), ('data', 'would')]

>> Trigrams are: 
 [('The', 'feature', 'best'), ('feature', 'best', 'divides'), ('best', 'divides', 'training'), ('divides', 'training', 'data'), ('training', 'data', 'would')]

>> POS Tags are: 
 [('The', 'DT'), ('feature', 'NN'), ('best', 'JJS'), ('divides', 'NNS'), ('training', 'VBG'), ('data', 'NNS'), ('would', 'MD')]

>> Noun Phrases are: 
 ['The feature', 'divides', 'data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('feature', 'featur'), ('best', 'best'), ('divides', 'divid'), ('training', 'train'), ('data', 'data'), ('would', 'would')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('feature', 'featur'), ('best', 'best'), ('divides', 'divid'), ('training', 'train'), ('data', 'data'), ('would', 'would')]

>> Lemmatization: 
 [('The', 'The'), ('feature', 'feature'), ('best', 'best'), ('divides', 'divide'), ('training', 'training'), ('data', 'data'), ('would', 'would')]



========================================== PARAGRAPH 234 ===========================================

root node of the tree. There are different methods to extract the  

------------------- Sentence 1 -------------------

root node of the tree.

>> Tokens are: 
 ['root', 'node', 'tree', '.']

>> Bigrams are: 
 [('root', 'node'), ('node', 'tree'), ('tree', '.')]

>> Trigrams are: 
 [('root', 'node', 'tree'), ('node', 'tree', '.')]

>> POS Tags are: 
 [('root', 'NN'), ('node', 'DT'), ('tree', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['root', 'node tree']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('root', 'root'), ('node', 'node'), ('tree', 'tree'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('root', 'root'), ('node', 'node'), ('tree', 'tree'), ('.', '.')]

>> Lemmatization: 
 [('root', 'root'), ('node', 'node'), ('tree', 'tree'), ('.', '.')]


------------------- Sentence 2 -------------------

There are different methods to extract the

>> Tokens are: 
 ['There', 'different', 'methods', 'extract']

>> Bigrams are: 
 [('There', 'different'), ('different', 'methods'), ('methods', 'extract')]

>> Trigrams are: 
 [('There', 'different', 'methods'), ('different', 'methods', 'extract')]

>> POS Tags are: 
 [('There', 'EX'), ('different', 'JJ'), ('methods', 'NNS'), ('extract', 'NN')]

>> Noun Phrases are: 
 ['different methods extract']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('There', 'there'), ('different', 'differ'), ('methods', 'method'), ('extract', 'extract')]

>> Stemming using Snowball Stemmer: 
 [('There', 'there'), ('different', 'differ'), ('methods', 'method'), ('extract', 'extract')]

>> Lemmatization: 
 [('There', 'There'), ('different', 'different'), ('methods', 'method'), ('extract', 'extract')]



========================================== PARAGRAPH 235 ===========================================

features that best divides the training data such as information  

------------------- Sentence 1 -------------------

features that best divides the training data such as information

>> Tokens are: 
 ['features', 'best', 'divides', 'training', 'data', 'information']

>> Bigrams are: 
 [('features', 'best'), ('best', 'divides'), ('divides', 'training'), ('training', 'data'), ('data', 'information')]

>> Trigrams are: 
 [('features', 'best', 'divides'), ('best', 'divides', 'training'), ('divides', 'training', 'data'), ('training', 'data', 'information')]

>> POS Tags are: 
 [('features', 'NNS'), ('best', 'JJS'), ('divides', 'NNS'), ('training', 'VBG'), ('data', 'NNS'), ('information', 'NN')]

>> Noun Phrases are: 
 ['features', 'divides', 'data information']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('features', 'featur'), ('best', 'best'), ('divides', 'divid'), ('training', 'train'), ('data', 'data'), ('information', 'inform')]

>> Stemming using Snowball Stemmer: 
 [('features', 'featur'), ('best', 'best'), ('divides', 'divid'), ('training', 'train'), ('data', 'data'), ('information', 'inform')]

>> Lemmatization: 
 [('features', 'feature'), ('best', 'best'), ('divides', 'divide'), ('training', 'training'), ('data', 'data'), ('information', 'information')]



========================================== PARAGRAPH 236 ===========================================

gain [11] and gini index [12].  

------------------- Sentence 1 -------------------

gain [11] and gini index [12].

>> Tokens are: 
 ['gain', '[', '11', ']', 'gini', 'index', '[', '12', ']', '.']

>> Bigrams are: 
 [('gain', '['), ('[', '11'), ('11', ']'), (']', 'gini'), ('gini', 'index'), ('index', '['), ('[', '12'), ('12', ']'), (']', '.')]

>> Trigrams are: 
 [('gain', '[', '11'), ('[', '11', ']'), ('11', ']', 'gini'), (']', 'gini', 'index'), ('gini', 'index', '['), ('index', '[', '12'), ('[', '12', ']'), ('12', ']', '.')]

>> POS Tags are: 
 [('gain', 'NN'), ('[', '$'), ('11', 'CD'), (']', 'NNP'), ('gini', 'NN'), ('index', 'NN'), ('[', 'VBD'), ('12', 'CD'), (']', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['gain', '] gini index', ']']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('gain', 'gain'), ('[', '['), ('11', '11'), (']', ']'), ('gini', 'gini'), ('index', 'index'), ('[', '['), ('12', '12'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('gain', 'gain'), ('[', '['), ('11', '11'), (']', ']'), ('gini', 'gini'), ('index', 'index'), ('[', '['), ('12', '12'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('gain', 'gain'), ('[', '['), ('11', '11'), (']', ']'), ('gini', 'gini'), ('index', 'index'), ('[', '['), ('12', '12'), (']', ']'), ('.', '.')]



========================================== PARAGRAPH 237 ===========================================

  


========================================== PARAGRAPH 238 ===========================================

Fig.4. General pseudo-code for building decision trees  

------------------- Sentence 1 -------------------

Fig.4.

>> Tokens are: 
 ['Fig.4', '.']

>> Bigrams are: 
 [('Fig.4', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Fig.4', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Fig.4']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Fig.4', 'fig.4'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Fig.4', 'fig.4'), ('.', '.')]

>> Lemmatization: 
 [('Fig.4', 'Fig.4'), ('.', '.')]


------------------- Sentence 2 -------------------

General pseudo-code for building decision trees

>> Tokens are: 
 ['General', 'pseudo-code', 'building', 'decision', 'trees']

>> Bigrams are: 
 [('General', 'pseudo-code'), ('pseudo-code', 'building'), ('building', 'decision'), ('decision', 'trees')]

>> Trigrams are: 
 [('General', 'pseudo-code', 'building'), ('pseudo-code', 'building', 'decision'), ('building', 'decision', 'trees')]

>> POS Tags are: 
 [('General', 'NNP'), ('pseudo-code', 'NN'), ('building', 'NN'), ('decision', 'NN'), ('trees', 'NNS')]

>> Noun Phrases are: 
 ['General pseudo-code building decision trees']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('General', 'gener'), ('pseudo-code', 'pseudo-cod'), ('building', 'build'), ('decision', 'decis'), ('trees', 'tree')]

>> Stemming using Snowball Stemmer: 
 [('General', 'general'), ('pseudo-code', 'pseudo-cod'), ('building', 'build'), ('decision', 'decis'), ('trees', 'tree')]

>> Lemmatization: 
 [('General', 'General'), ('pseudo-code', 'pseudo-code'), ('building', 'building'), ('decision', 'decision'), ('trees', 'tree')]



========================================== PARAGRAPH 239 ===========================================

3.2 LEARNING SET OF RULES  

------------------- Sentence 1 -------------------

3.2 LEARNING SET OF RULES

>> Tokens are: 
 ['3.2', 'LEARNING', 'SET', 'OF', 'RULES']

>> Bigrams are: 
 [('3.2', 'LEARNING'), ('LEARNING', 'SET'), ('SET', 'OF'), ('OF', 'RULES')]

>> Trigrams are: 
 [('3.2', 'LEARNING', 'SET'), ('LEARNING', 'SET', 'OF'), ('SET', 'OF', 'RULES')]

>> POS Tags are: 
 [('3.2', 'CD'), ('LEARNING', 'NNP'), ('SET', 'NNP'), ('OF', 'NNP'), ('RULES', 'NNP')]

>> Noun Phrases are: 
 ['LEARNING SET OF RULES']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('3.2', '3.2'), ('LEARNING', 'learn'), ('SET', 'set'), ('OF', 'of'), ('RULES', 'rule')]

>> Stemming using Snowball Stemmer: 
 [('3.2', '3.2'), ('LEARNING', 'learn'), ('SET', 'set'), ('OF', 'of'), ('RULES', 'rule')]

>> Lemmatization: 
 [('3.2', '3.2'), ('LEARNING', 'LEARNING'), ('SET', 'SET'), ('OF', 'OF'), ('RULES', 'RULES')]



========================================== PARAGRAPH 240 ===========================================

It is also possible that decision trees can be translated into a  

------------------- Sentence 1 -------------------

It is also possible that decision trees can be translated into a

>> Tokens are: 
 ['It', 'also', 'possible', 'decision', 'trees', 'translated']

>> Bigrams are: 
 [('It', 'also'), ('also', 'possible'), ('possible', 'decision'), ('decision', 'trees'), ('trees', 'translated')]

>> Trigrams are: 
 [('It', 'also', 'possible'), ('also', 'possible', 'decision'), ('possible', 'decision', 'trees'), ('decision', 'trees', 'translated')]

>> POS Tags are: 
 [('It', 'PRP'), ('also', 'RB'), ('possible', 'JJ'), ('decision', 'NN'), ('trees', 'NNS'), ('translated', 'VBD')]

>> Noun Phrases are: 
 ['possible decision trees']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('It', 'it'), ('also', 'also'), ('possible', 'possibl'), ('decision', 'decis'), ('trees', 'tree'), ('translated', 'translat')]

>> Stemming using Snowball Stemmer: 
 [('It', 'it'), ('also', 'also'), ('possible', 'possibl'), ('decision', 'decis'), ('trees', 'tree'), ('translated', 'translat')]

>> Lemmatization: 
 [('It', 'It'), ('also', 'also'), ('possible', 'possible'), ('decision', 'decision'), ('trees', 'tree'), ('translated', 'translated')]



========================================== PARAGRAPH 241 ===========================================

set of rules by creating a separate rule for each path from the  

------------------- Sentence 1 -------------------

set of rules by creating a separate rule for each path from the

>> Tokens are: 
 ['set', 'rules', 'creating', 'separate', 'rule', 'path']

>> Bigrams are: 
 [('set', 'rules'), ('rules', 'creating'), ('creating', 'separate'), ('separate', 'rule'), ('rule', 'path')]

>> Trigrams are: 
 [('set', 'rules', 'creating'), ('rules', 'creating', 'separate'), ('creating', 'separate', 'rule'), ('separate', 'rule', 'path')]

>> POS Tags are: 
 [('set', 'NN'), ('rules', 'NNS'), ('creating', 'VBG'), ('separate', 'JJ'), ('rule', 'NN'), ('path', 'NN')]

>> Noun Phrases are: 
 ['set rules', 'separate rule path']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('set', 'set'), ('rules', 'rule'), ('creating', 'creat'), ('separate', 'separ'), ('rule', 'rule'), ('path', 'path')]

>> Stemming using Snowball Stemmer: 
 [('set', 'set'), ('rules', 'rule'), ('creating', 'creat'), ('separate', 'separ'), ('rule', 'rule'), ('path', 'path')]

>> Lemmatization: 
 [('set', 'set'), ('rules', 'rule'), ('creating', 'creating'), ('separate', 'separate'), ('rule', 'rule'), ('path', 'path')]



========================================== PARAGRAPH 242 ===========================================

root to a leaf in the tree [13]. However, rules can also be directly  

------------------- Sentence 1 -------------------

root to a leaf in the tree [13].

>> Tokens are: 
 ['root', 'leaf', 'tree', '[', '13', ']', '.']

>> Bigrams are: 
 [('root', 'leaf'), ('leaf', 'tree'), ('tree', '['), ('[', '13'), ('13', ']'), (']', '.')]

>> Trigrams are: 
 [('root', 'leaf', 'tree'), ('leaf', 'tree', '['), ('tree', '[', '13'), ('[', '13', ']'), ('13', ']', '.')]

>> POS Tags are: 
 [('root', 'NN'), ('leaf', 'NN'), ('tree', 'NN'), ('[', 'VBD'), ('13', 'CD'), (']', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['root leaf tree', ']']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('root', 'root'), ('leaf', 'leaf'), ('tree', 'tree'), ('[', '['), ('13', '13'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('root', 'root'), ('leaf', 'leaf'), ('tree', 'tree'), ('[', '['), ('13', '13'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('root', 'root'), ('leaf', 'leaf'), ('tree', 'tree'), ('[', '['), ('13', '13'), (']', ']'), ('.', '.')]


------------------- Sentence 2 -------------------

However, rules can also be directly

>> Tokens are: 
 ['However', ',', 'rules', 'also', 'directly']

>> Bigrams are: 
 [('However', ','), (',', 'rules'), ('rules', 'also'), ('also', 'directly')]

>> Trigrams are: 
 [('However', ',', 'rules'), (',', 'rules', 'also'), ('rules', 'also', 'directly')]

>> POS Tags are: 
 [('However', 'RB'), (',', ','), ('rules', 'NNS'), ('also', 'RB'), ('directly', 'RB')]

>> Noun Phrases are: 
 ['rules']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('However', 'howev'), (',', ','), ('rules', 'rule'), ('also', 'also'), ('directly', 'directli')]

>> Stemming using Snowball Stemmer: 
 [('However', 'howev'), (',', ','), ('rules', 'rule'), ('also', 'also'), ('directly', 'direct')]

>> Lemmatization: 
 [('However', 'However'), (',', ','), ('rules', 'rule'), ('also', 'also'), ('directly', 'directly')]



========================================== PARAGRAPH 243 ===========================================

induced from training data using a variety of rule-based  

------------------- Sentence 1 -------------------

induced from training data using a variety of rule-based

>> Tokens are: 
 ['induced', 'training', 'data', 'using', 'variety', 'rule-based']

>> Bigrams are: 
 [('induced', 'training'), ('training', 'data'), ('data', 'using'), ('using', 'variety'), ('variety', 'rule-based')]

>> Trigrams are: 
 [('induced', 'training', 'data'), ('training', 'data', 'using'), ('data', 'using', 'variety'), ('using', 'variety', 'rule-based')]

>> POS Tags are: 
 [('induced', 'JJ'), ('training', 'NN'), ('data', 'NNS'), ('using', 'VBG'), ('variety', 'NN'), ('rule-based', 'JJ')]

>> Noun Phrases are: 
 ['induced training data', 'variety']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('induced', 'induc'), ('training', 'train'), ('data', 'data'), ('using', 'use'), ('variety', 'varieti'), ('rule-based', 'rule-bas')]

>> Stemming using Snowball Stemmer: 
 [('induced', 'induc'), ('training', 'train'), ('data', 'data'), ('using', 'use'), ('variety', 'varieti'), ('rule-based', 'rule-bas')]

>> Lemmatization: 
 [('induced', 'induced'), ('training', 'training'), ('data', 'data'), ('using', 'using'), ('variety', 'variety'), ('rule-based', 'rule-based')]



========================================== PARAGRAPH 244 ===========================================

algorithms. In [14], the author has provided an excellent  

------------------- Sentence 1 -------------------

algorithms.

>> Tokens are: 
 ['algorithms', '.']

>> Bigrams are: 
 [('algorithms', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('algorithms', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['algorithms']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('algorithms', 'algorithm'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('algorithms', 'algorithm'), ('.', '.')]

>> Lemmatization: 
 [('algorithms', 'algorithm'), ('.', '.')]


------------------- Sentence 2 -------------------

In [14], the author has provided an excellent

>> Tokens are: 
 ['In', '[', '14', ']', ',', 'author', 'provided', 'excellent']

>> Bigrams are: 
 [('In', '['), ('[', '14'), ('14', ']'), (']', ','), (',', 'author'), ('author', 'provided'), ('provided', 'excellent')]

>> Trigrams are: 
 [('In', '[', '14'), ('[', '14', ']'), ('14', ']', ','), (']', ',', 'author'), (',', 'author', 'provided'), ('author', 'provided', 'excellent')]

>> POS Tags are: 
 [('In', 'IN'), ('[', '$'), ('14', 'CD'), (']', 'NNP'), (',', ','), ('author', 'NN'), ('provided', 'VBD'), ('excellent', 'JJ')]

>> Noun Phrases are: 
 [']', 'author']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('[', '['), ('14', '14'), (']', ']'), (',', ','), ('author', 'author'), ('provided', 'provid'), ('excellent', 'excel')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('[', '['), ('14', '14'), (']', ']'), (',', ','), ('author', 'author'), ('provided', 'provid'), ('excellent', 'excel')]

>> Lemmatization: 
 [('In', 'In'), ('[', '['), ('14', '14'), (']', ']'), (',', ','), ('author', 'author'), ('provided', 'provided'), ('excellent', 'excellent')]



========================================== PARAGRAPH 245 ===========================================

overview of existing work in rule-based methods. The  

------------------- Sentence 1 -------------------

overview of existing work in rule-based methods.

>> Tokens are: 
 ['overview', 'existing', 'work', 'rule-based', 'methods', '.']

>> Bigrams are: 
 [('overview', 'existing'), ('existing', 'work'), ('work', 'rule-based'), ('rule-based', 'methods'), ('methods', '.')]

>> Trigrams are: 
 [('overview', 'existing', 'work'), ('existing', 'work', 'rule-based'), ('work', 'rule-based', 'methods'), ('rule-based', 'methods', '.')]

>> POS Tags are: 
 [('overview', 'NN'), ('existing', 'VBG'), ('work', 'NN'), ('rule-based', 'JJ'), ('methods', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['overview', 'work', 'rule-based methods']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('overview', 'overview'), ('existing', 'exist'), ('work', 'work'), ('rule-based', 'rule-bas'), ('methods', 'method'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('overview', 'overview'), ('existing', 'exist'), ('work', 'work'), ('rule-based', 'rule-bas'), ('methods', 'method'), ('.', '.')]

>> Lemmatization: 
 [('overview', 'overview'), ('existing', 'existing'), ('work', 'work'), ('rule-based', 'rule-based'), ('methods', 'method'), ('.', '.')]


------------------- Sentence 2 -------------------

The

>> Tokens are: 
 ['The']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('The', 'DT')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the')]

>> Lemmatization: 
 [('The', 'The')]



========================================== PARAGRAPH 246 ===========================================

classification rules represent each class by Disjunctive Normal  

------------------- Sentence 1 -------------------

classification rules represent each class by Disjunctive Normal

>> Tokens are: 
 ['classification', 'rules', 'represent', 'class', 'Disjunctive', 'Normal']

>> Bigrams are: 
 [('classification', 'rules'), ('rules', 'represent'), ('represent', 'class'), ('class', 'Disjunctive'), ('Disjunctive', 'Normal')]

>> Trigrams are: 
 [('classification', 'rules', 'represent'), ('rules', 'represent', 'class'), ('represent', 'class', 'Disjunctive'), ('class', 'Disjunctive', 'Normal')]

>> POS Tags are: 
 [('classification', 'NN'), ('rules', 'NNS'), ('represent', 'VBP'), ('class', 'NN'), ('Disjunctive', 'NNP'), ('Normal', 'NNP')]

>> Noun Phrases are: 
 ['classification rules', 'class Disjunctive Normal']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('classification', 'classif'), ('rules', 'rule'), ('represent', 'repres'), ('class', 'class'), ('Disjunctive', 'disjunct'), ('Normal', 'normal')]

>> Stemming using Snowball Stemmer: 
 [('classification', 'classif'), ('rules', 'rule'), ('represent', 'repres'), ('class', 'class'), ('Disjunctive', 'disjunct'), ('Normal', 'normal')]

>> Lemmatization: 
 [('classification', 'classification'), ('rules', 'rule'), ('represent', 'represent'), ('class', 'class'), ('Disjunctive', 'Disjunctive'), ('Normal', 'Normal')]



========================================== PARAGRAPH 247 ===========================================

Form (DNF). A statement is in DNF if it is a disjunction  

------------------- Sentence 1 -------------------

Form (DNF).

>> Tokens are: 
 ['Form', '(', 'DNF', ')', '.']

>> Bigrams are: 
 [('Form', '('), ('(', 'DNF'), ('DNF', ')'), (')', '.')]

>> Trigrams are: 
 [('Form', '(', 'DNF'), ('(', 'DNF', ')'), ('DNF', ')', '.')]

>> POS Tags are: 
 [('Form', 'NNP'), ('(', '('), ('DNF', 'NNP'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['Form', 'DNF']

>> Named Entities are: 
 [('GPE', 'Form'), ('ORGANIZATION', 'DNF')] 

>> Stemming using Porter Stemmer: 
 [('Form', 'form'), ('(', '('), ('DNF', 'dnf'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Form', 'form'), ('(', '('), ('DNF', 'dnf'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Form', 'Form'), ('(', '('), ('DNF', 'DNF'), (')', ')'), ('.', '.')]


------------------- Sentence 2 -------------------

A statement is in DNF if it is a disjunction

>> Tokens are: 
 ['A', 'statement', 'DNF', 'disjunction']

>> Bigrams are: 
 [('A', 'statement'), ('statement', 'DNF'), ('DNF', 'disjunction')]

>> Trigrams are: 
 [('A', 'statement', 'DNF'), ('statement', 'DNF', 'disjunction')]

>> POS Tags are: 
 [('A', 'DT'), ('statement', 'NN'), ('DNF', 'NNP'), ('disjunction', 'NN')]

>> Noun Phrases are: 
 ['A statement DNF disjunction']

>> Named Entities are: 
 [('ORGANIZATION', 'DNF')] 

>> Stemming using Porter Stemmer: 
 [('A', 'a'), ('statement', 'statement'), ('DNF', 'dnf'), ('disjunction', 'disjunct')]

>> Stemming using Snowball Stemmer: 
 [('A', 'a'), ('statement', 'statement'), ('DNF', 'dnf'), ('disjunction', 'disjunct')]

>> Lemmatization: 
 [('A', 'A'), ('statement', 'statement'), ('DNF', 'DNF'), ('disjunction', 'disjunction')]



========================================== PARAGRAPH 248 ===========================================

(sequence of ORs) consisting of one or more disjuncts, each of  

------------------- Sentence 1 -------------------

(sequence of ORs) consisting of one or more disjuncts, each of

>> Tokens are: 
 ['(', 'sequence', 'ORs', ')', 'consisting', 'one', 'disjuncts', ',']

>> Bigrams are: 
 [('(', 'sequence'), ('sequence', 'ORs'), ('ORs', ')'), (')', 'consisting'), ('consisting', 'one'), ('one', 'disjuncts'), ('disjuncts', ',')]

>> Trigrams are: 
 [('(', 'sequence', 'ORs'), ('sequence', 'ORs', ')'), ('ORs', ')', 'consisting'), (')', 'consisting', 'one'), ('consisting', 'one', 'disjuncts'), ('one', 'disjuncts', ',')]

>> POS Tags are: 
 [('(', '('), ('sequence', 'NN'), ('ORs', 'NNP'), (')', ')'), ('consisting', 'VBG'), ('one', 'CD'), ('disjuncts', 'NNS'), (',', ',')]

>> Noun Phrases are: 
 ['sequence ORs', 'disjuncts']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('sequence', 'sequenc'), ('ORs', 'or'), (')', ')'), ('consisting', 'consist'), ('one', 'one'), ('disjuncts', 'disjunct'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('sequence', 'sequenc'), ('ORs', 'or'), (')', ')'), ('consisting', 'consist'), ('one', 'one'), ('disjuncts', 'disjunct'), (',', ',')]

>> Lemmatization: 
 [('(', '('), ('sequence', 'sequence'), ('ORs', 'ORs'), (')', ')'), ('consisting', 'consisting'), ('one', 'one'), ('disjuncts', 'disjuncts'), (',', ',')]



========================================== PARAGRAPH 249 ===========================================

which is a conjunction (AND) of one or more literals. Below is  

------------------- Sentence 1 -------------------

which is a conjunction (AND) of one or more literals.

>> Tokens are: 
 ['conjunction', '(', 'AND', ')', 'one', 'literals', '.']

>> Bigrams are: 
 [('conjunction', '('), ('(', 'AND'), ('AND', ')'), (')', 'one'), ('one', 'literals'), ('literals', '.')]

>> Trigrams are: 
 [('conjunction', '(', 'AND'), ('(', 'AND', ')'), ('AND', ')', 'one'), (')', 'one', 'literals'), ('one', 'literals', '.')]

>> POS Tags are: 
 [('conjunction', 'NN'), ('(', '('), ('AND', 'CC'), (')', ')'), ('one', 'CD'), ('literals', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['conjunction', 'literals']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('conjunction', 'conjunct'), ('(', '('), ('AND', 'and'), (')', ')'), ('one', 'one'), ('literals', 'liter'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('conjunction', 'conjunct'), ('(', '('), ('AND', 'and'), (')', ')'), ('one', 'one'), ('literals', 'liter'), ('.', '.')]

>> Lemmatization: 
 [('conjunction', 'conjunction'), ('(', '('), ('AND', 'AND'), (')', ')'), ('one', 'one'), ('literals', 'literal'), ('.', '.')]


------------------- Sentence 2 -------------------

Below is

>> Tokens are: 
 ['Below']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Below', 'IN')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Below', 'below')]

>> Stemming using Snowball Stemmer: 
 [('Below', 'below')]

>> Lemmatization: 
 [('Below', 'Below')]



========================================== PARAGRAPH 250 ===========================================

an example of disjunctive normal forms.  

------------------- Sentence 1 -------------------

an example of disjunctive normal forms.

>> Tokens are: 
 ['example', 'disjunctive', 'normal', 'forms', '.']

>> Bigrams are: 
 [('example', 'disjunctive'), ('disjunctive', 'normal'), ('normal', 'forms'), ('forms', '.')]

>> Trigrams are: 
 [('example', 'disjunctive', 'normal'), ('disjunctive', 'normal', 'forms'), ('normal', 'forms', '.')]

>> POS Tags are: 
 [('example', 'NN'), ('disjunctive', 'JJ'), ('normal', 'JJ'), ('forms', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['example', 'disjunctive normal forms']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('example', 'exampl'), ('disjunctive', 'disjunct'), ('normal', 'normal'), ('forms', 'form'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('example', 'exampl'), ('disjunctive', 'disjunct'), ('normal', 'normal'), ('forms', 'form'), ('.', '.')]

>> Lemmatization: 
 [('example', 'example'), ('disjunctive', 'disjunctive'), ('normal', 'normal'), ('forms', 'form'), ('.', '.')]



========================================== PARAGRAPH 251 ===========================================

A k-DNF expression is of the form:  

------------------- Sentence 1 -------------------

A k-DNF expression is of the form:

>> Tokens are: 
 ['A', 'k-DNF', 'expression', 'form', ':']

>> Bigrams are: 
 [('A', 'k-DNF'), ('k-DNF', 'expression'), ('expression', 'form'), ('form', ':')]

>> Trigrams are: 
 [('A', 'k-DNF', 'expression'), ('k-DNF', 'expression', 'form'), ('expression', 'form', ':')]

>> POS Tags are: 
 [('A', 'DT'), ('k-DNF', 'JJ'), ('expression', 'NN'), ('form', 'NN'), (':', ':')]

>> Noun Phrases are: 
 ['A k-DNF expression form']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('A', 'a'), ('k-DNF', 'k-dnf'), ('expression', 'express'), ('form', 'form'), (':', ':')]

>> Stemming using Snowball Stemmer: 
 [('A', 'a'), ('k-DNF', 'k-dnf'), ('expression', 'express'), ('form', 'form'), (':', ':')]

>> Lemmatization: 
 [('A', 'A'), ('k-DNF', 'k-DNF'), ('expression', 'expression'), ('form', 'form'), (':', ':')]



========================================== PARAGRAPH 252 ===========================================

       nnnn AAAAAA 22121     knnknk AAA   2111 , where k is the number of  

------------------- Sentence 1 -------------------

       nnnn AAAAAA 22121     knnknk AAA   2111 , where k is the number of

>> Tokens are: 
 ['\uf028', '\uf029', '\uf028', '\uf029\uf028', '\uf029\uf0da\uf0da\uf0d9\uf0d9\uf0da\uf0d9\uf0d9', '\uf02b\uf02b', '\uf04b\uf04b\uf04b', 'nnnn', 'AAAAAA', '22121', '\uf028', '\uf029', '\uf028', '\uf029\uf028', '\uf029knnknk', 'AAA', '\uf0d9\uf0d9\uf0d9', '\uf02b\uf02d\uf02b\uf02d', '\uf04b2111', ',', 'k', 'number']

>> Bigrams are: 
 [('\uf028', '\uf029'), ('\uf029', '\uf028'), ('\uf028', '\uf029\uf028'), ('\uf029\uf028', '\uf029\uf0da\uf0da\uf0d9\uf0d9\uf0da\uf0d9\uf0d9'), ('\uf029\uf0da\uf0da\uf0d9\uf0d9\uf0da\uf0d9\uf0d9', '\uf02b\uf02b'), ('\uf02b\uf02b', '\uf04b\uf04b\uf04b'), ('\uf04b\uf04b\uf04b', 'nnnn'), ('nnnn', 'AAAAAA'), ('AAAAAA', '22121'), ('22121', '\uf028'), ('\uf028', '\uf029'), ('\uf029', '\uf028'), ('\uf028', '\uf029\uf028'), ('\uf029\uf028', '\uf029knnknk'), ('\uf029knnknk', 'AAA'), ('AAA', '\uf0d9\uf0d9\uf0d9'), ('\uf0d9\uf0d9\uf0d9', '\uf02b\uf02d\uf02b\uf02d'), ('\uf02b\uf02d\uf02b\uf02d', '\uf04b2111'), ('\uf04b2111', ','), (',', 'k'), ('k', 'number')]

>> Trigrams are: 
 [('\uf028', '\uf029', '\uf028'), ('\uf029', '\uf028', '\uf029\uf028'), ('\uf028', '\uf029\uf028', '\uf029\uf0da\uf0da\uf0d9\uf0d9\uf0da\uf0d9\uf0d9'), ('\uf029\uf028', '\uf029\uf0da\uf0da\uf0d9\uf0d9\uf0da\uf0d9\uf0d9', '\uf02b\uf02b'), ('\uf029\uf0da\uf0da\uf0d9\uf0d9\uf0da\uf0d9\uf0d9', '\uf02b\uf02b', '\uf04b\uf04b\uf04b'), ('\uf02b\uf02b', '\uf04b\uf04b\uf04b', 'nnnn'), ('\uf04b\uf04b\uf04b', 'nnnn', 'AAAAAA'), ('nnnn', 'AAAAAA', '22121'), ('AAAAAA', '22121', '\uf028'), ('22121', '\uf028', '\uf029'), ('\uf028', '\uf029', '\uf028'), ('\uf029', '\uf028', '\uf029\uf028'), ('\uf028', '\uf029\uf028', '\uf029knnknk'), ('\uf029\uf028', '\uf029knnknk', 'AAA'), ('\uf029knnknk', 'AAA', '\uf0d9\uf0d9\uf0d9'), ('AAA', '\uf0d9\uf0d9\uf0d9', '\uf02b\uf02d\uf02b\uf02d'), ('\uf0d9\uf0d9\uf0d9', '\uf02b\uf02d\uf02b\uf02d', '\uf04b2111'), ('\uf02b\uf02d\uf02b\uf02d', '\uf04b2111', ','), ('\uf04b2111', ',', 'k'), (',', 'k', 'number')]

>> POS Tags are: 
 [('\uf028', 'JJ'), ('\uf029', 'NNP'), ('\uf028', 'NNP'), ('\uf029\uf028', 'NNP'), ('\uf029\uf0da\uf0da\uf0d9\uf0d9\uf0da\uf0d9\uf0d9', 'NNP'), ('\uf02b\uf02b', 'NNP'), ('\uf04b\uf04b\uf04b', 'NNP'), ('nnnn', 'VBD'), ('AAAAAA', 'NNP'), ('22121', 'CD'), ('\uf028', 'NNP'), ('\uf029', 'NNP'), ('\uf028', 'NNP'), ('\uf029\uf028', 'NNP'), ('\uf029knnknk', 'NNP'), ('AAA', 'NNP'), ('\uf0d9\uf0d9\uf0d9', 'NNP'), ('\uf02b\uf02d\uf02b\uf02d', 'NNP'), ('\uf04b2111', 'NNP'), (',', ','), ('k', 'VBZ'), ('number', 'NN')]

>> Noun Phrases are: 
 ['\uf028 \uf029 \uf028 \uf029\uf028 \uf029\uf0da\uf0da\uf0d9\uf0d9\uf0da\uf0d9\uf0d9 \uf02b\uf02b \uf04b\uf04b\uf04b', 'AAAAAA', '\uf028 \uf029 \uf028 \uf029\uf028 \uf029knnknk AAA \uf0d9\uf0d9\uf0d9 \uf02b\uf02d\uf02b\uf02d \uf04b2111', 'number']

>> Named Entities are: 
 [('ORGANIZATION', 'AAAAAA')] 

>> Stemming using Porter Stemmer: 
 [('\uf028', '\uf028'), ('\uf029', '\uf029'), ('\uf028', '\uf028'), ('\uf029\uf028', '\uf029\uf028'), ('\uf029\uf0da\uf0da\uf0d9\uf0d9\uf0da\uf0d9\uf0d9', '\uf029\uf0da\uf0da\uf0d9\uf0d9\uf0da\uf0d9\uf0d9'), ('\uf02b\uf02b', '\uf02b\uf02b'), ('\uf04b\uf04b\uf04b', '\uf04b\uf04b\uf04b'), ('nnnn', 'nnnn'), ('AAAAAA', 'aaaaaa'), ('22121', '22121'), ('\uf028', '\uf028'), ('\uf029', '\uf029'), ('\uf028', '\uf028'), ('\uf029\uf028', '\uf029\uf028'), ('\uf029knnknk', '\uf029knnknk'), ('AAA', 'aaa'), ('\uf0d9\uf0d9\uf0d9', '\uf0d9\uf0d9\uf0d9'), ('\uf02b\uf02d\uf02b\uf02d', '\uf02b\uf02d\uf02b\uf02d'), ('\uf04b2111', '\uf04b2111'), (',', ','), ('k', 'k'), ('number', 'number')]

>> Stemming using Snowball Stemmer: 
 [('\uf028', '\uf028'), ('\uf029', '\uf029'), ('\uf028', '\uf028'), ('\uf029\uf028', '\uf029\uf028'), ('\uf029\uf0da\uf0da\uf0d9\uf0d9\uf0da\uf0d9\uf0d9', '\uf029\uf0da\uf0da\uf0d9\uf0d9\uf0da\uf0d9\uf0d9'), ('\uf02b\uf02b', '\uf02b\uf02b'), ('\uf04b\uf04b\uf04b', '\uf04b\uf04b\uf04b'), ('nnnn', 'nnnn'), ('AAAAAA', 'aaaaaa'), ('22121', '22121'), ('\uf028', '\uf028'), ('\uf029', '\uf029'), ('\uf028', '\uf028'), ('\uf029\uf028', '\uf029\uf028'), ('\uf029knnknk', '\uf029knnknk'), ('AAA', 'aaa'), ('\uf0d9\uf0d9\uf0d9', '\uf0d9\uf0d9\uf0d9'), ('\uf02b\uf02d\uf02b\uf02d', '\uf02b\uf02d\uf02b\uf02d'), ('\uf04b2111', '\uf04b2111'), (',', ','), ('k', 'k'), ('number', 'number')]

>> Lemmatization: 
 [('\uf028', '\uf028'), ('\uf029', '\uf029'), ('\uf028', '\uf028'), ('\uf029\uf028', '\uf029\uf028'), ('\uf029\uf0da\uf0da\uf0d9\uf0d9\uf0da\uf0d9\uf0d9', '\uf029\uf0da\uf0da\uf0d9\uf0d9\uf0da\uf0d9\uf0d9'), ('\uf02b\uf02b', '\uf02b\uf02b'), ('\uf04b\uf04b\uf04b', '\uf04b\uf04b\uf04b'), ('nnnn', 'nnnn'), ('AAAAAA', 'AAAAAA'), ('22121', '22121'), ('\uf028', '\uf028'), ('\uf029', '\uf029'), ('\uf028', '\uf028'), ('\uf029\uf028', '\uf029\uf028'), ('\uf029knnknk', '\uf029knnknk'), ('AAA', 'AAA'), ('\uf0d9\uf0d9\uf0d9', '\uf0d9\uf0d9\uf0d9'), ('\uf02b\uf02d\uf02b\uf02d', '\uf02b\uf02d\uf02b\uf02d'), ('\uf04b2111', '\uf04b2111'), (',', ','), ('k', 'k'), ('number', 'number')]



========================================== PARAGRAPH 253 ===========================================

disjunctions, n is the number of conjunctions in each disjunction,  

------------------- Sentence 1 -------------------

disjunctions, n is the number of conjunctions in each disjunction,

>> Tokens are: 
 ['disjunctions', ',', 'n', 'number', 'conjunctions', 'disjunction', ',']

>> Bigrams are: 
 [('disjunctions', ','), (',', 'n'), ('n', 'number'), ('number', 'conjunctions'), ('conjunctions', 'disjunction'), ('disjunction', ',')]

>> Trigrams are: 
 [('disjunctions', ',', 'n'), (',', 'n', 'number'), ('n', 'number', 'conjunctions'), ('number', 'conjunctions', 'disjunction'), ('conjunctions', 'disjunction', ',')]

>> POS Tags are: 
 [('disjunctions', 'NNS'), (',', ','), ('n', 'JJ'), ('number', 'NN'), ('conjunctions', 'NNS'), ('disjunction', 'NN'), (',', ',')]

>> Noun Phrases are: 
 ['disjunctions', 'n number conjunctions disjunction']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('disjunctions', 'disjunct'), (',', ','), ('n', 'n'), ('number', 'number'), ('conjunctions', 'conjunct'), ('disjunction', 'disjunct'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('disjunctions', 'disjunct'), (',', ','), ('n', 'n'), ('number', 'number'), ('conjunctions', 'conjunct'), ('disjunction', 'disjunct'), (',', ',')]

>> Lemmatization: 
 [('disjunctions', 'disjunction'), (',', ','), ('n', 'n'), ('number', 'number'), ('conjunctions', 'conjunction'), ('disjunction', 'disjunction'), (',', ',')]



========================================== PARAGRAPH 254 ===========================================

and An is defined over the alphabet  

------------------- Sentence 1 -------------------

and An is defined over the alphabet

>> Tokens are: 
 ['An', 'defined', 'alphabet']

>> Bigrams are: 
 [('An', 'defined'), ('defined', 'alphabet')]

>> Trigrams are: 
 [('An', 'defined', 'alphabet')]

>> POS Tags are: 
 [('An', 'DT'), ('defined', 'JJ'), ('alphabet', 'NN')]

>> Noun Phrases are: 
 ['An defined alphabet']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('An', 'an'), ('defined', 'defin'), ('alphabet', 'alphabet')]

>> Stemming using Snowball Stemmer: 
 [('An', 'an'), ('defined', 'defin'), ('alphabet', 'alphabet')]

>> Lemmatization: 
 [('An', 'An'), ('defined', 'defined'), ('alphabet', 'alphabet')]



========================================== PARAGRAPH 255 ===========================================

jj AAAAAA  2121 ~,~,,,,  . Here the objective is to build  

------------------- Sentence 1 -------------------

jj AAAAAA  2121 ~,~,,,,  .

>> Tokens are: 
 ['jj', 'AAAAAA', '\uf04b\uf04b', '2121', '~', ',', '~', ',', ',', ',', ',', '\uf04a', '.']

>> Bigrams are: 
 [('jj', 'AAAAAA'), ('AAAAAA', '\uf04b\uf04b'), ('\uf04b\uf04b', '2121'), ('2121', '~'), ('~', ','), (',', '~'), ('~', ','), (',', ','), (',', ','), (',', ','), (',', '\uf04a'), ('\uf04a', '.')]

>> Trigrams are: 
 [('jj', 'AAAAAA', '\uf04b\uf04b'), ('AAAAAA', '\uf04b\uf04b', '2121'), ('\uf04b\uf04b', '2121', '~'), ('2121', '~', ','), ('~', ',', '~'), (',', '~', ','), ('~', ',', ','), (',', ',', ','), (',', ',', ','), (',', ',', '\uf04a'), (',', '\uf04a', '.')]

>> POS Tags are: 
 [('jj', 'NN'), ('AAAAAA', 'NNP'), ('\uf04b\uf04b', 'NN'), ('2121', 'CD'), ('~', 'NN'), (',', ','), ('~', 'NNP'), (',', ','), (',', ','), (',', ','), (',', ','), ('\uf04a', 'UH'), ('.', '.')]

>> Noun Phrases are: 
 ['jj AAAAAA \uf04b\uf04b', '~', '~']

>> Named Entities are: 
 [('ORGANIZATION', 'AAAAAA')] 

>> Stemming using Porter Stemmer: 
 [('jj', 'jj'), ('AAAAAA', 'aaaaaa'), ('\uf04b\uf04b', '\uf04b\uf04b'), ('2121', '2121'), ('~', '~'), (',', ','), ('~', '~'), (',', ','), (',', ','), (',', ','), (',', ','), ('\uf04a', '\uf04a'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('jj', 'jj'), ('AAAAAA', 'aaaaaa'), ('\uf04b\uf04b', '\uf04b\uf04b'), ('2121', '2121'), ('~', '~'), (',', ','), ('~', '~'), (',', ','), (',', ','), (',', ','), (',', ','), ('\uf04a', '\uf04a'), ('.', '.')]

>> Lemmatization: 
 [('jj', 'jj'), ('AAAAAA', 'AAAAAA'), ('\uf04b\uf04b', '\uf04b\uf04b'), ('2121', '2121'), ('~', '~'), (',', ','), ('~', '~'), (',', ','), (',', ','), (',', ','), (',', ','), ('\uf04a', '\uf04a'), ('.', '.')]


------------------- Sentence 2 -------------------

Here the objective is to build

>> Tokens are: 
 ['Here', 'objective', 'build']

>> Bigrams are: 
 [('Here', 'objective'), ('objective', 'build')]

>> Trigrams are: 
 [('Here', 'objective', 'build')]

>> POS Tags are: 
 [('Here', 'RB'), ('objective', 'JJ'), ('build', 'NN')]

>> Noun Phrases are: 
 ['objective build']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Here', 'here'), ('objective', 'object'), ('build', 'build')]

>> Stemming using Snowball Stemmer: 
 [('Here', 'here'), ('objective', 'object'), ('build', 'build')]

>> Lemmatization: 
 [('Here', 'Here'), ('objective', 'objective'), ('build', 'build')]



========================================== PARAGRAPH 256 ===========================================

the smallest rule-set that is consistent with the training data [1].  

------------------- Sentence 1 -------------------

the smallest rule-set that is consistent with the training data [1].

>> Tokens are: 
 ['smallest', 'rule-set', 'consistent', 'training', 'data', '[', '1', ']', '.']

>> Bigrams are: 
 [('smallest', 'rule-set'), ('rule-set', 'consistent'), ('consistent', 'training'), ('training', 'data'), ('data', '['), ('[', '1'), ('1', ']'), (']', '.')]

>> Trigrams are: 
 [('smallest', 'rule-set', 'consistent'), ('rule-set', 'consistent', 'training'), ('consistent', 'training', 'data'), ('training', 'data', '['), ('data', '[', '1'), ('[', '1', ']'), ('1', ']', '.')]

>> POS Tags are: 
 [('smallest', 'JJS'), ('rule-set', 'JJ'), ('consistent', 'JJ'), ('training', 'NN'), ('data', 'NNS'), ('[', '$'), ('1', 'CD'), (']', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['rule-set consistent training data', ']']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('smallest', 'smallest'), ('rule-set', 'rule-set'), ('consistent', 'consist'), ('training', 'train'), ('data', 'data'), ('[', '['), ('1', '1'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('smallest', 'smallest'), ('rule-set', 'rule-set'), ('consistent', 'consist'), ('training', 'train'), ('data', 'data'), ('[', '['), ('1', '1'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('smallest', 'smallest'), ('rule-set', 'rule-set'), ('consistent', 'consistent'), ('training', 'training'), ('data', 'data'), ('[', '['), ('1', '1'), (']', ']'), ('.', '.')]



========================================== PARAGRAPH 257 ===========================================

A good number of learned rules is usually a positive sign that the  

------------------- Sentence 1 -------------------

A good number of learned rules is usually a positive sign that the

>> Tokens are: 
 ['A', 'good', 'number', 'learned', 'rules', 'usually', 'positive', 'sign']

>> Bigrams are: 
 [('A', 'good'), ('good', 'number'), ('number', 'learned'), ('learned', 'rules'), ('rules', 'usually'), ('usually', 'positive'), ('positive', 'sign')]

>> Trigrams are: 
 [('A', 'good', 'number'), ('good', 'number', 'learned'), ('number', 'learned', 'rules'), ('learned', 'rules', 'usually'), ('rules', 'usually', 'positive'), ('usually', 'positive', 'sign')]

>> POS Tags are: 
 [('A', 'DT'), ('good', 'JJ'), ('number', 'NN'), ('learned', 'VBN'), ('rules', 'NNS'), ('usually', 'RB'), ('positive', 'JJ'), ('sign', 'NN')]

>> Noun Phrases are: 
 ['A good number', 'rules', 'positive sign']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('A', 'a'), ('good', 'good'), ('number', 'number'), ('learned', 'learn'), ('rules', 'rule'), ('usually', 'usual'), ('positive', 'posit'), ('sign', 'sign')]

>> Stemming using Snowball Stemmer: 
 [('A', 'a'), ('good', 'good'), ('number', 'number'), ('learned', 'learn'), ('rules', 'rule'), ('usually', 'usual'), ('positive', 'posit'), ('sign', 'sign')]

>> Lemmatization: 
 [('A', 'A'), ('good', 'good'), ('number', 'number'), ('learned', 'learned'), ('rules', 'rule'), ('usually', 'usually'), ('positive', 'positive'), ('sign', 'sign')]



========================================== PARAGRAPH 258 ===========================================

learning algorithm is attempting to remember the training set,  

------------------- Sentence 1 -------------------

learning algorithm is attempting to remember the training set,

>> Tokens are: 
 ['learning', 'algorithm', 'attempting', 'remember', 'training', 'set', ',']

>> Bigrams are: 
 [('learning', 'algorithm'), ('algorithm', 'attempting'), ('attempting', 'remember'), ('remember', 'training'), ('training', 'set'), ('set', ',')]

>> Trigrams are: 
 [('learning', 'algorithm', 'attempting'), ('algorithm', 'attempting', 'remember'), ('attempting', 'remember', 'training'), ('remember', 'training', 'set'), ('training', 'set', ',')]

>> POS Tags are: 
 [('learning', 'VBG'), ('algorithm', 'RP'), ('attempting', 'VBG'), ('remember', 'VB'), ('training', 'NN'), ('set', 'NN'), (',', ',')]

>> Noun Phrases are: 
 ['training set']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('learning', 'learn'), ('algorithm', 'algorithm'), ('attempting', 'attempt'), ('remember', 'rememb'), ('training', 'train'), ('set', 'set'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('learning', 'learn'), ('algorithm', 'algorithm'), ('attempting', 'attempt'), ('remember', 'rememb'), ('training', 'train'), ('set', 'set'), (',', ',')]

>> Lemmatization: 
 [('learning', 'learning'), ('algorithm', 'algorithm'), ('attempting', 'attempting'), ('remember', 'remember'), ('training', 'training'), ('set', 'set'), (',', ',')]



========================================== PARAGRAPH 259 ===========================================

instead of discovering the assumptions that govern it. A  

------------------- Sentence 1 -------------------

instead of discovering the assumptions that govern it.

>> Tokens are: 
 ['instead', 'discovering', 'assumptions', 'govern', '.']

>> Bigrams are: 
 [('instead', 'discovering'), ('discovering', 'assumptions'), ('assumptions', 'govern'), ('govern', '.')]

>> Trigrams are: 
 [('instead', 'discovering', 'assumptions'), ('discovering', 'assumptions', 'govern'), ('assumptions', 'govern', '.')]

>> POS Tags are: 
 [('instead', 'RB'), ('discovering', 'VBG'), ('assumptions', 'NNS'), ('govern', 'VBP'), ('.', '.')]

>> Noun Phrases are: 
 ['assumptions']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('instead', 'instead'), ('discovering', 'discov'), ('assumptions', 'assumpt'), ('govern', 'govern'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('instead', 'instead'), ('discovering', 'discov'), ('assumptions', 'assumpt'), ('govern', 'govern'), ('.', '.')]

>> Lemmatization: 
 [('instead', 'instead'), ('discovering', 'discovering'), ('assumptions', 'assumption'), ('govern', 'govern'), ('.', '.')]


------------------- Sentence 2 -------------------

A

>> Tokens are: 
 ['A']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('A', 'DT')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('A', 'a')]

>> Stemming using Snowball Stemmer: 
 [('A', 'a')]

>> Lemmatization: 
 [('A', 'A')]



========================================== PARAGRAPH 260 ===========================================

separate-and-conquer algorithm (recursively breaking down a  

------------------- Sentence 1 -------------------

separate-and-conquer algorithm (recursively breaking down a

>> Tokens are: 
 ['separate-and-conquer', 'algorithm', '(', 'recursively', 'breaking']

>> Bigrams are: 
 [('separate-and-conquer', 'algorithm'), ('algorithm', '('), ('(', 'recursively'), ('recursively', 'breaking')]

>> Trigrams are: 
 [('separate-and-conquer', 'algorithm', '('), ('algorithm', '(', 'recursively'), ('(', 'recursively', 'breaking')]

>> POS Tags are: 
 [('separate-and-conquer', 'JJ'), ('algorithm', 'NN'), ('(', '('), ('recursively', 'RB'), ('breaking', 'VBG')]

>> Noun Phrases are: 
 ['separate-and-conquer algorithm']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('separate-and-conquer', 'separate-and-conqu'), ('algorithm', 'algorithm'), ('(', '('), ('recursively', 'recurs'), ('breaking', 'break')]

>> Stemming using Snowball Stemmer: 
 [('separate-and-conquer', 'separate-and-conqu'), ('algorithm', 'algorithm'), ('(', '('), ('recursively', 'recurs'), ('breaking', 'break')]

>> Lemmatization: 
 [('separate-and-conquer', 'separate-and-conquer'), ('algorithm', 'algorithm'), ('(', '('), ('recursively', 'recursively'), ('breaking', 'breaking')]



========================================== PARAGRAPH 261 ===========================================

problem into sub-problems) search for a rule that explains a part  

------------------- Sentence 1 -------------------

problem into sub-problems) search for a rule that explains a part

>> Tokens are: 
 ['problem', 'sub-problems', ')', 'search', 'rule', 'explains', 'part']

>> Bigrams are: 
 [('problem', 'sub-problems'), ('sub-problems', ')'), (')', 'search'), ('search', 'rule'), ('rule', 'explains'), ('explains', 'part')]

>> Trigrams are: 
 [('problem', 'sub-problems', ')'), ('sub-problems', ')', 'search'), (')', 'search', 'rule'), ('search', 'rule', 'explains'), ('rule', 'explains', 'part')]

>> POS Tags are: 
 [('problem', 'NN'), ('sub-problems', 'NNS'), (')', ')'), ('search', 'NN'), ('rule', 'NN'), ('explains', 'VBZ'), ('part', 'NN')]

>> Noun Phrases are: 
 ['problem sub-problems', 'search rule', 'part']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('problem', 'problem'), ('sub-problems', 'sub-problem'), (')', ')'), ('search', 'search'), ('rule', 'rule'), ('explains', 'explain'), ('part', 'part')]

>> Stemming using Snowball Stemmer: 
 [('problem', 'problem'), ('sub-problems', 'sub-problem'), (')', ')'), ('search', 'search'), ('rule', 'rule'), ('explains', 'explain'), ('part', 'part')]

>> Lemmatization: 
 [('problem', 'problem'), ('sub-problems', 'sub-problems'), (')', ')'), ('search', 'search'), ('rule', 'rule'), ('explains', 'explains'), ('part', 'part')]



========================================== PARAGRAPH 262 ===========================================

of its training instances, separates these instances and recursively  

------------------- Sentence 1 -------------------

of its training instances, separates these instances and recursively

>> Tokens are: 
 ['training', 'instances', ',', 'separates', 'instances', 'recursively']

>> Bigrams are: 
 [('training', 'instances'), ('instances', ','), (',', 'separates'), ('separates', 'instances'), ('instances', 'recursively')]

>> Trigrams are: 
 [('training', 'instances', ','), ('instances', ',', 'separates'), (',', 'separates', 'instances'), ('separates', 'instances', 'recursively')]

>> POS Tags are: 
 [('training', 'NN'), ('instances', 'NNS'), (',', ','), ('separates', 'NNS'), ('instances', 'NNS'), ('recursively', 'RB')]

>> Noun Phrases are: 
 ['training instances', 'separates instances']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('training', 'train'), ('instances', 'instanc'), (',', ','), ('separates', 'separ'), ('instances', 'instanc'), ('recursively', 'recurs')]

>> Stemming using Snowball Stemmer: 
 [('training', 'train'), ('instances', 'instanc'), (',', ','), ('separates', 'separ'), ('instances', 'instanc'), ('recursively', 'recurs')]

>> Lemmatization: 
 [('training', 'training'), ('instances', 'instance'), (',', ','), ('separates', 'separate'), ('instances', 'instance'), ('recursively', 'recursively')]



========================================== PARAGRAPH 263 ===========================================

conquers the remaining instances by learning more rules, until  

------------------- Sentence 1 -------------------

conquers the remaining instances by learning more rules, until

>> Tokens are: 
 ['conquers', 'remaining', 'instances', 'learning', 'rules', ',']

>> Bigrams are: 
 [('conquers', 'remaining'), ('remaining', 'instances'), ('instances', 'learning'), ('learning', 'rules'), ('rules', ',')]

>> Trigrams are: 
 [('conquers', 'remaining', 'instances'), ('remaining', 'instances', 'learning'), ('instances', 'learning', 'rules'), ('learning', 'rules', ',')]

>> POS Tags are: 
 [('conquers', 'NNS'), ('remaining', 'VBG'), ('instances', 'NNS'), ('learning', 'VBG'), ('rules', 'NNS'), (',', ',')]

>> Noun Phrases are: 
 ['conquers', 'instances', 'rules']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('conquers', 'conquer'), ('remaining', 'remain'), ('instances', 'instanc'), ('learning', 'learn'), ('rules', 'rule'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('conquers', 'conquer'), ('remaining', 'remain'), ('instances', 'instanc'), ('learning', 'learn'), ('rules', 'rule'), (',', ',')]

>> Lemmatization: 
 [('conquers', 'conquers'), ('remaining', 'remaining'), ('instances', 'instance'), ('learning', 'learning'), ('rules', 'rule'), (',', ',')]



========================================== PARAGRAPH 264 ===========================================

no instances remain [1]. In below Fig.5, a general pseudo-code  

------------------- Sentence 1 -------------------

no instances remain [1].

>> Tokens are: 
 ['instances', 'remain', '[', '1', ']', '.']

>> Bigrams are: 
 [('instances', 'remain'), ('remain', '['), ('[', '1'), ('1', ']'), (']', '.')]

>> Trigrams are: 
 [('instances', 'remain', '['), ('remain', '[', '1'), ('[', '1', ']'), ('1', ']', '.')]

>> POS Tags are: 
 [('instances', 'NNS'), ('remain', 'VBP'), ('[', 'JJ'), ('1', 'CD'), (']', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['instances', ']']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('instances', 'instanc'), ('remain', 'remain'), ('[', '['), ('1', '1'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('instances', 'instanc'), ('remain', 'remain'), ('[', '['), ('1', '1'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('instances', 'instance'), ('remain', 'remain'), ('[', '['), ('1', '1'), (']', ']'), ('.', '.')]


------------------- Sentence 2 -------------------

In below Fig.5, a general pseudo-code

>> Tokens are: 
 ['In', 'Fig.5', ',', 'general', 'pseudo-code']

>> Bigrams are: 
 [('In', 'Fig.5'), ('Fig.5', ','), (',', 'general'), ('general', 'pseudo-code')]

>> Trigrams are: 
 [('In', 'Fig.5', ','), ('Fig.5', ',', 'general'), (',', 'general', 'pseudo-code')]

>> POS Tags are: 
 [('In', 'IN'), ('Fig.5', 'NNP'), (',', ','), ('general', 'JJ'), ('pseudo-code', 'NN')]

>> Noun Phrases are: 
 ['Fig.5', 'general pseudo-code']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('Fig.5', 'fig.5'), (',', ','), ('general', 'gener'), ('pseudo-code', 'pseudo-cod')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('Fig.5', 'fig.5'), (',', ','), ('general', 'general'), ('pseudo-code', 'pseudo-cod')]

>> Lemmatization: 
 [('In', 'In'), ('Fig.5', 'Fig.5'), (',', ','), ('general', 'general'), ('pseudo-code', 'pseudo-code')]



========================================== PARAGRAPH 265 ===========================================

for rule learners is presented.  

------------------- Sentence 1 -------------------

for rule learners is presented.

>> Tokens are: 
 ['rule', 'learners', 'presented', '.']

>> Bigrams are: 
 [('rule', 'learners'), ('learners', 'presented'), ('presented', '.')]

>> Trigrams are: 
 [('rule', 'learners', 'presented'), ('learners', 'presented', '.')]

>> POS Tags are: 
 [('rule', 'NN'), ('learners', 'NNS'), ('presented', 'VBD'), ('.', '.')]

>> Noun Phrases are: 
 ['rule learners']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('rule', 'rule'), ('learners', 'learner'), ('presented', 'present'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('rule', 'rule'), ('learners', 'learner'), ('presented', 'present'), ('.', '.')]

>> Lemmatization: 
 [('rule', 'rule'), ('learners', 'learner'), ('presented', 'presented'), ('.', '.')]



========================================== PARAGRAPH 266 ===========================================

  


========================================== PARAGRAPH 267 ===========================================

Fig.5. A general Pseudo code for rule learners  

------------------- Sentence 1 -------------------

Fig.5.

>> Tokens are: 
 ['Fig.5', '.']

>> Bigrams are: 
 [('Fig.5', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Fig.5', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Fig.5']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Fig.5', 'fig.5'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Fig.5', 'fig.5'), ('.', '.')]

>> Lemmatization: 
 [('Fig.5', 'Fig.5'), ('.', '.')]


------------------- Sentence 2 -------------------

A general Pseudo code for rule learners

>> Tokens are: 
 ['A', 'general', 'Pseudo', 'code', 'rule', 'learners']

>> Bigrams are: 
 [('A', 'general'), ('general', 'Pseudo'), ('Pseudo', 'code'), ('code', 'rule'), ('rule', 'learners')]

>> Trigrams are: 
 [('A', 'general', 'Pseudo'), ('general', 'Pseudo', 'code'), ('Pseudo', 'code', 'rule'), ('code', 'rule', 'learners')]

>> POS Tags are: 
 [('A', 'DT'), ('general', 'JJ'), ('Pseudo', 'NNP'), ('code', 'NN'), ('rule', 'NN'), ('learners', 'NNS')]

>> Noun Phrases are: 
 ['A general Pseudo code rule learners']

>> Named Entities are: 
 [('PERSON', 'Pseudo')] 

>> Stemming using Porter Stemmer: 
 [('A', 'a'), ('general', 'gener'), ('Pseudo', 'pseudo'), ('code', 'code'), ('rule', 'rule'), ('learners', 'learner')]

>> Stemming using Snowball Stemmer: 
 [('A', 'a'), ('general', 'general'), ('Pseudo', 'pseudo'), ('code', 'code'), ('rule', 'rule'), ('learners', 'learner')]

>> Lemmatization: 
 [('A', 'A'), ('general', 'general'), ('Pseudo', 'Pseudo'), ('code', 'code'), ('rule', 'rule'), ('learners', 'learner')]



========================================== PARAGRAPH 268 ===========================================

The core difference between heuristics for rule learning  

------------------- Sentence 1 -------------------

The core difference between heuristics for rule learning

>> Tokens are: 
 ['The', 'core', 'difference', 'heuristics', 'rule', 'learning']

>> Bigrams are: 
 [('The', 'core'), ('core', 'difference'), ('difference', 'heuristics'), ('heuristics', 'rule'), ('rule', 'learning')]

>> Trigrams are: 
 [('The', 'core', 'difference'), ('core', 'difference', 'heuristics'), ('difference', 'heuristics', 'rule'), ('heuristics', 'rule', 'learning')]

>> POS Tags are: 
 [('The', 'DT'), ('core', 'NN'), ('difference', 'NN'), ('heuristics', 'NNS'), ('rule', 'NN'), ('learning', 'VBG')]

>> Noun Phrases are: 
 ['The core difference heuristics rule']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('core', 'core'), ('difference', 'differ'), ('heuristics', 'heurist'), ('rule', 'rule'), ('learning', 'learn')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('core', 'core'), ('difference', 'differ'), ('heuristics', 'heurist'), ('rule', 'rule'), ('learning', 'learn')]

>> Lemmatization: 
 [('The', 'The'), ('core', 'core'), ('difference', 'difference'), ('heuristics', 'heuristic'), ('rule', 'rule'), ('learning', 'learning')]



========================================== PARAGRAPH 269 ===========================================

algorithms and heuristics for decision trees algorithms is that the  

------------------- Sentence 1 -------------------

algorithms and heuristics for decision trees algorithms is that the

>> Tokens are: 
 ['algorithms', 'heuristics', 'decision', 'trees', 'algorithms']

>> Bigrams are: 
 [('algorithms', 'heuristics'), ('heuristics', 'decision'), ('decision', 'trees'), ('trees', 'algorithms')]

>> Trigrams are: 
 [('algorithms', 'heuristics', 'decision'), ('heuristics', 'decision', 'trees'), ('decision', 'trees', 'algorithms')]

>> POS Tags are: 
 [('algorithms', 'NN'), ('heuristics', 'NNS'), ('decision', 'NN'), ('trees', 'NNS'), ('algorithms', 'VBP')]

>> Noun Phrases are: 
 ['algorithms heuristics decision trees']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('algorithms', 'algorithm'), ('heuristics', 'heurist'), ('decision', 'decis'), ('trees', 'tree'), ('algorithms', 'algorithm')]

>> Stemming using Snowball Stemmer: 
 [('algorithms', 'algorithm'), ('heuristics', 'heurist'), ('decision', 'decis'), ('trees', 'tree'), ('algorithms', 'algorithm')]

>> Lemmatization: 
 [('algorithms', 'algorithm'), ('heuristics', 'heuristic'), ('decision', 'decision'), ('trees', 'tree'), ('algorithms', 'algorithm')]



========================================== PARAGRAPH 270 ===========================================

latter evaluate the average quality of a number of disjointed sets,  

------------------- Sentence 1 -------------------

latter evaluate the average quality of a number of disjointed sets,

>> Tokens are: 
 ['latter', 'evaluate', 'average', 'quality', 'number', 'disjointed', 'sets', ',']

>> Bigrams are: 
 [('latter', 'evaluate'), ('evaluate', 'average'), ('average', 'quality'), ('quality', 'number'), ('number', 'disjointed'), ('disjointed', 'sets'), ('sets', ',')]

>> Trigrams are: 
 [('latter', 'evaluate', 'average'), ('evaluate', 'average', 'quality'), ('average', 'quality', 'number'), ('quality', 'number', 'disjointed'), ('number', 'disjointed', 'sets'), ('disjointed', 'sets', ',')]

>> POS Tags are: 
 [('latter', 'JJ'), ('evaluate', 'JJ'), ('average', 'JJ'), ('quality', 'NN'), ('number', 'NN'), ('disjointed', 'VBN'), ('sets', 'NNS'), (',', ',')]

>> Noun Phrases are: 
 ['latter evaluate average quality number', 'sets']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('latter', 'latter'), ('evaluate', 'evalu'), ('average', 'averag'), ('quality', 'qualiti'), ('number', 'number'), ('disjointed', 'disjoint'), ('sets', 'set'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('latter', 'latter'), ('evaluate', 'evalu'), ('average', 'averag'), ('quality', 'qualiti'), ('number', 'number'), ('disjointed', 'disjoint'), ('sets', 'set'), (',', ',')]

>> Lemmatization: 
 [('latter', 'latter'), ('evaluate', 'evaluate'), ('average', 'average'), ('quality', 'quality'), ('number', 'number'), ('disjointed', 'disjointed'), ('sets', 'set'), (',', ',')]



========================================== PARAGRAPH 271 ===========================================

while rule learners only evaluate the quality of the set of  

------------------- Sentence 1 -------------------

while rule learners only evaluate the quality of the set of

>> Tokens are: 
 ['rule', 'learners', 'evaluate', 'quality', 'set']

>> Bigrams are: 
 [('rule', 'learners'), ('learners', 'evaluate'), ('evaluate', 'quality'), ('quality', 'set')]

>> Trigrams are: 
 [('rule', 'learners', 'evaluate'), ('learners', 'evaluate', 'quality'), ('evaluate', 'quality', 'set')]

>> POS Tags are: 
 [('rule', 'NN'), ('learners', 'NNS'), ('evaluate', 'VBP'), ('quality', 'NN'), ('set', 'NN')]

>> Noun Phrases are: 
 ['rule learners', 'quality set']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('rule', 'rule'), ('learners', 'learner'), ('evaluate', 'evalu'), ('quality', 'qualiti'), ('set', 'set')]

>> Stemming using Snowball Stemmer: 
 [('rule', 'rule'), ('learners', 'learner'), ('evaluate', 'evalu'), ('quality', 'qualiti'), ('set', 'set')]

>> Lemmatization: 
 [('rule', 'rule'), ('learners', 'learner'), ('evaluate', 'evaluate'), ('quality', 'quality'), ('set', 'set')]



========================================== PARAGRAPH 272 ===========================================

instances that is covered by the candidate rule [1]. One of the  

------------------- Sentence 1 -------------------

instances that is covered by the candidate rule [1].

>> Tokens are: 
 ['instances', 'covered', 'candidate', 'rule', '[', '1', ']', '.']

>> Bigrams are: 
 [('instances', 'covered'), ('covered', 'candidate'), ('candidate', 'rule'), ('rule', '['), ('[', '1'), ('1', ']'), (']', '.')]

>> Trigrams are: 
 [('instances', 'covered', 'candidate'), ('covered', 'candidate', 'rule'), ('candidate', 'rule', '['), ('rule', '[', '1'), ('[', '1', ']'), ('1', ']', '.')]

>> POS Tags are: 
 [('instances', 'NNS'), ('covered', 'VBD'), ('candidate', 'NN'), ('rule', 'NN'), ('[', 'VBD'), ('1', 'CD'), (']', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['instances', 'candidate rule', ']']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('instances', 'instanc'), ('covered', 'cover'), ('candidate', 'candid'), ('rule', 'rule'), ('[', '['), ('1', '1'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('instances', 'instanc'), ('covered', 'cover'), ('candidate', 'candid'), ('rule', 'rule'), ('[', '['), ('1', '1'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('instances', 'instance'), ('covered', 'covered'), ('candidate', 'candidate'), ('rule', 'rule'), ('[', '['), ('1', '1'), (']', ']'), ('.', '.')]


------------------- Sentence 2 -------------------

One of the

>> Tokens are: 
 ['One']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('One', 'CD')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('One', 'one')]

>> Stemming using Snowball Stemmer: 
 [('One', 'one')]

>> Lemmatization: 
 [('One', 'One')]



========================================== PARAGRAPH 273 ===========================================

most useful characteristic of rule based classifiers is their  

------------------- Sentence 1 -------------------

most useful characteristic of rule based classifiers is their

>> Tokens are: 
 ['useful', 'characteristic', 'rule', 'based', 'classifiers']

>> Bigrams are: 
 [('useful', 'characteristic'), ('characteristic', 'rule'), ('rule', 'based'), ('based', 'classifiers')]

>> Trigrams are: 
 [('useful', 'characteristic', 'rule'), ('characteristic', 'rule', 'based'), ('rule', 'based', 'classifiers')]

>> POS Tags are: 
 [('useful', 'JJ'), ('characteristic', 'JJ'), ('rule', 'NN'), ('based', 'VBN'), ('classifiers', 'NNS')]

>> Noun Phrases are: 
 ['useful characteristic rule', 'classifiers']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('useful', 'use'), ('characteristic', 'characterist'), ('rule', 'rule'), ('based', 'base'), ('classifiers', 'classifi')]

>> Stemming using Snowball Stemmer: 
 [('useful', 'use'), ('characteristic', 'characterist'), ('rule', 'rule'), ('based', 'base'), ('classifiers', 'classifi')]

>> Lemmatization: 
 [('useful', 'useful'), ('characteristic', 'characteristic'), ('rule', 'rule'), ('based', 'based'), ('classifiers', 'classifier')]



========================================== PARAGRAPH 274 ===========================================

comprehensibility. In order to achieve better performance, even  

------------------- Sentence 1 -------------------

comprehensibility.

>> Tokens are: 
 ['comprehensibility', '.']

>> Bigrams are: 
 [('comprehensibility', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('comprehensibility', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['comprehensibility']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('comprehensibility', 'comprehens'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('comprehensibility', 'comprehens'), ('.', '.')]

>> Lemmatization: 
 [('comprehensibility', 'comprehensibility'), ('.', '.')]


------------------- Sentence 2 -------------------

In order to achieve better performance, even

>> Tokens are: 
 ['In', 'order', 'achieve', 'better', 'performance', ',', 'even']

>> Bigrams are: 
 [('In', 'order'), ('order', 'achieve'), ('achieve', 'better'), ('better', 'performance'), ('performance', ','), (',', 'even')]

>> Trigrams are: 
 [('In', 'order', 'achieve'), ('order', 'achieve', 'better'), ('achieve', 'better', 'performance'), ('better', 'performance', ','), ('performance', ',', 'even')]

>> POS Tags are: 
 [('In', 'IN'), ('order', 'NN'), ('achieve', 'VBP'), ('better', 'JJR'), ('performance', 'NN'), (',', ','), ('even', 'RB')]

>> Noun Phrases are: 
 ['order', 'performance']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('order', 'order'), ('achieve', 'achiev'), ('better', 'better'), ('performance', 'perform'), (',', ','), ('even', 'even')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('order', 'order'), ('achieve', 'achiev'), ('better', 'better'), ('performance', 'perform'), (',', ','), ('even', 'even')]

>> Lemmatization: 
 [('In', 'In'), ('order', 'order'), ('achieve', 'achieve'), ('better', 'better'), ('performance', 'performance'), (',', ','), ('even', 'even')]



========================================== PARAGRAPH 275 ===========================================

though some rule-based classifiers can deal with numerical  

------------------- Sentence 1 -------------------

though some rule-based classifiers can deal with numerical

>> Tokens are: 
 ['though', 'rule-based', 'classifiers', 'deal', 'numerical']

>> Bigrams are: 
 [('though', 'rule-based'), ('rule-based', 'classifiers'), ('classifiers', 'deal'), ('deal', 'numerical')]

>> Trigrams are: 
 [('though', 'rule-based', 'classifiers'), ('rule-based', 'classifiers', 'deal'), ('classifiers', 'deal', 'numerical')]

>> POS Tags are: 
 [('though', 'IN'), ('rule-based', 'JJ'), ('classifiers', 'NNS'), ('deal', 'VB'), ('numerical', 'JJ')]

>> Noun Phrases are: 
 ['rule-based classifiers']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('though', 'though'), ('rule-based', 'rule-bas'), ('classifiers', 'classifi'), ('deal', 'deal'), ('numerical', 'numer')]

>> Stemming using Snowball Stemmer: 
 [('though', 'though'), ('rule-based', 'rule-bas'), ('classifiers', 'classifi'), ('deal', 'deal'), ('numerical', 'numer')]

>> Lemmatization: 
 [('though', 'though'), ('rule-based', 'rule-based'), ('classifiers', 'classifier'), ('deal', 'deal'), ('numerical', 'numerical')]



========================================== PARAGRAPH 276 ===========================================

features, some experts propose these features should be  

------------------- Sentence 1 -------------------

features, some experts propose these features should be

>> Tokens are: 
 ['features', ',', 'experts', 'propose', 'features']

>> Bigrams are: 
 [('features', ','), (',', 'experts'), ('experts', 'propose'), ('propose', 'features')]

>> Trigrams are: 
 [('features', ',', 'experts'), (',', 'experts', 'propose'), ('experts', 'propose', 'features')]

>> POS Tags are: 
 [('features', 'NNS'), (',', ','), ('experts', 'NNS'), ('propose', 'VBP'), ('features', 'NNS')]

>> Noun Phrases are: 
 ['features', 'experts', 'features']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('features', 'featur'), (',', ','), ('experts', 'expert'), ('propose', 'propos'), ('features', 'featur')]

>> Stemming using Snowball Stemmer: 
 [('features', 'featur'), (',', ','), ('experts', 'expert'), ('propose', 'propos'), ('features', 'featur')]

>> Lemmatization: 
 [('features', 'feature'), (',', ','), ('experts', 'expert'), ('propose', 'propose'), ('features', 'feature')]



========================================== PARAGRAPH 277 ===========================================

discredited before induction, so as to reduce training time and  

------------------- Sentence 1 -------------------

discredited before induction, so as to reduce training time and

>> Tokens are: 
 ['discredited', 'induction', ',', 'reduce', 'training', 'time']

>> Bigrams are: 
 [('discredited', 'induction'), ('induction', ','), (',', 'reduce'), ('reduce', 'training'), ('training', 'time')]

>> Trigrams are: 
 [('discredited', 'induction', ','), ('induction', ',', 'reduce'), (',', 'reduce', 'training'), ('reduce', 'training', 'time')]

>> POS Tags are: 
 [('discredited', 'VBN'), ('induction', 'NN'), (',', ','), ('reduce', 'VB'), ('training', 'NN'), ('time', 'NN')]

>> Noun Phrases are: 
 ['induction', 'training time']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('discredited', 'discredit'), ('induction', 'induct'), (',', ','), ('reduce', 'reduc'), ('training', 'train'), ('time', 'time')]

>> Stemming using Snowball Stemmer: 
 [('discredited', 'discredit'), ('induction', 'induct'), (',', ','), ('reduce', 'reduc'), ('training', 'train'), ('time', 'time')]

>> Lemmatization: 
 [('discredited', 'discredited'), ('induction', 'induction'), (',', ','), ('reduce', 'reduce'), ('training', 'training'), ('time', 'time')]



========================================== PARAGRAPH 278 ===========================================

increase classification accuracy [15].  

------------------- Sentence 1 -------------------

increase classification accuracy [15].

>> Tokens are: 
 ['increase', 'classification', 'accuracy', '[', '15', ']', '.']

>> Bigrams are: 
 [('increase', 'classification'), ('classification', 'accuracy'), ('accuracy', '['), ('[', '15'), ('15', ']'), (']', '.')]

>> Trigrams are: 
 [('increase', 'classification', 'accuracy'), ('classification', 'accuracy', '['), ('accuracy', '[', '15'), ('[', '15', ']'), ('15', ']', '.')]

>> POS Tags are: 
 [('increase', 'NN'), ('classification', 'NN'), ('accuracy', 'NN'), ('[', 'VBD'), ('15', 'CD'), (']', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['increase classification accuracy', ']']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('increase', 'increas'), ('classification', 'classif'), ('accuracy', 'accuraci'), ('[', '['), ('15', '15'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('increase', 'increas'), ('classification', 'classif'), ('accuracy', 'accuraci'), ('[', '['), ('15', '15'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('increase', 'increase'), ('classification', 'classification'), ('accuracy', 'accuracy'), ('[', '['), ('15', '15'), (']', ']'), ('.', '.')]



========================================== PARAGRAPH 279 ===========================================

4. STATISTICAL LEARNING ALGORITHMS  

------------------- Sentence 1 -------------------

4.

>> Tokens are: 
 ['4', '.']

>> Bigrams are: 
 [('4', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('4', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('4', '4'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('4', '4'), ('.', '.')]

>> Lemmatization: 
 [('4', '4'), ('.', '.')]


------------------- Sentence 2 -------------------

STATISTICAL LEARNING ALGORITHMS

>> Tokens are: 
 ['STATISTICAL', 'LEARNING', 'ALGORITHMS']

>> Bigrams are: 
 [('STATISTICAL', 'LEARNING'), ('LEARNING', 'ALGORITHMS')]

>> Trigrams are: 
 [('STATISTICAL', 'LEARNING', 'ALGORITHMS')]

>> POS Tags are: 
 [('STATISTICAL', 'NNP'), ('LEARNING', 'NNP'), ('ALGORITHMS', 'NNP')]

>> Noun Phrases are: 
 ['STATISTICAL LEARNING ALGORITHMS']

>> Named Entities are: 
 [('ORGANIZATION', 'STATISTICAL'), ('ORGANIZATION', 'LEARNING')] 

>> Stemming using Porter Stemmer: 
 [('STATISTICAL', 'statist'), ('LEARNING', 'learn'), ('ALGORITHMS', 'algorithm')]

>> Stemming using Snowball Stemmer: 
 [('STATISTICAL', 'statist'), ('LEARNING', 'learn'), ('ALGORITHMS', 'algorithm')]

>> Lemmatization: 
 [('STATISTICAL', 'STATISTICAL'), ('LEARNING', 'LEARNING'), ('ALGORITHMS', 'ALGORITHMS')]



========================================== PARAGRAPH 280 ===========================================

Statistical learning is a framework for machine learning  

------------------- Sentence 1 -------------------

Statistical learning is a framework for machine learning

>> Tokens are: 
 ['Statistical', 'learning', 'framework', 'machine', 'learning']

>> Bigrams are: 
 [('Statistical', 'learning'), ('learning', 'framework'), ('framework', 'machine'), ('machine', 'learning')]

>> Trigrams are: 
 [('Statistical', 'learning', 'framework'), ('learning', 'framework', 'machine'), ('framework', 'machine', 'learning')]

>> POS Tags are: 
 [('Statistical', 'JJ'), ('learning', 'NN'), ('framework', 'NN'), ('machine', 'NN'), ('learning', 'NN')]

>> Noun Phrases are: 
 ['Statistical learning framework machine learning']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Statistical', 'statist'), ('learning', 'learn'), ('framework', 'framework'), ('machine', 'machin'), ('learning', 'learn')]

>> Stemming using Snowball Stemmer: 
 [('Statistical', 'statist'), ('learning', 'learn'), ('framework', 'framework'), ('machine', 'machin'), ('learning', 'learn')]

>> Lemmatization: 
 [('Statistical', 'Statistical'), ('learning', 'learning'), ('framework', 'framework'), ('machine', 'machine'), ('learning', 'learning')]



========================================== PARAGRAPH 281 ===========================================

drawing from the fields of statistics and functional analysis [16].  

------------------- Sentence 1 -------------------

drawing from the fields of statistics and functional analysis [16].

>> Tokens are: 
 ['drawing', 'fields', 'statistics', 'functional', 'analysis', '[', '16', ']', '.']

>> Bigrams are: 
 [('drawing', 'fields'), ('fields', 'statistics'), ('statistics', 'functional'), ('functional', 'analysis'), ('analysis', '['), ('[', '16'), ('16', ']'), (']', '.')]

>> Trigrams are: 
 [('drawing', 'fields', 'statistics'), ('fields', 'statistics', 'functional'), ('statistics', 'functional', 'analysis'), ('functional', 'analysis', '['), ('analysis', '[', '16'), ('[', '16', ']'), ('16', ']', '.')]

>> POS Tags are: 
 [('drawing', 'VBG'), ('fields', 'NNS'), ('statistics', 'NNS'), ('functional', 'JJ'), ('analysis', 'NN'), ('[', 'VBD'), ('16', 'CD'), (']', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['fields statistics', 'functional analysis', ']']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('drawing', 'draw'), ('fields', 'field'), ('statistics', 'statist'), ('functional', 'function'), ('analysis', 'analysi'), ('[', '['), ('16', '16'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('drawing', 'draw'), ('fields', 'field'), ('statistics', 'statist'), ('functional', 'function'), ('analysis', 'analysi'), ('[', '['), ('16', '16'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('drawing', 'drawing'), ('fields', 'field'), ('statistics', 'statistic'), ('functional', 'functional'), ('analysis', 'analysis'), ('[', '['), ('16', '16'), (']', ']'), ('.', '.')]



========================================== PARAGRAPH 282 ===========================================

1. Initialize rule set to a default   2. Initialize examples to either all available examples  

------------------- Sentence 1 -------------------

1.

>> Tokens are: 
 ['1', '.']

>> Bigrams are: 
 [('1', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('1', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('1', '1'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('1', '1'), ('.', '.')]

>> Lemmatization: 
 [('1', '1'), ('.', '.')]


------------------- Sentence 2 -------------------

Initialize rule set to a default   2.

>> Tokens are: 
 ['Initialize', 'rule', 'set', 'default', '2', '.']

>> Bigrams are: 
 [('Initialize', 'rule'), ('rule', 'set'), ('set', 'default'), ('default', '2'), ('2', '.')]

>> Trigrams are: 
 [('Initialize', 'rule', 'set'), ('rule', 'set', 'default'), ('set', 'default', '2'), ('default', '2', '.')]

>> POS Tags are: 
 [('Initialize', 'NNP'), ('rule', 'NN'), ('set', 'VBN'), ('default', 'NN'), ('2', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Initialize rule', 'default']

>> Named Entities are: 
 [('GPE', 'Initialize')] 

>> Stemming using Porter Stemmer: 
 [('Initialize', 'initi'), ('rule', 'rule'), ('set', 'set'), ('default', 'default'), ('2', '2'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Initialize', 'initi'), ('rule', 'rule'), ('set', 'set'), ('default', 'default'), ('2', '2'), ('.', '.')]

>> Lemmatization: 
 [('Initialize', 'Initialize'), ('rule', 'rule'), ('set', 'set'), ('default', 'default'), ('2', '2'), ('.', '.')]


------------------- Sentence 3 -------------------

Initialize examples to either all available examples

>> Tokens are: 
 ['Initialize', 'examples', 'either', 'available', 'examples']

>> Bigrams are: 
 [('Initialize', 'examples'), ('examples', 'either'), ('either', 'available'), ('available', 'examples')]

>> Trigrams are: 
 [('Initialize', 'examples', 'either'), ('examples', 'either', 'available'), ('either', 'available', 'examples')]

>> POS Tags are: 
 [('Initialize', 'NNP'), ('examples', 'VBZ'), ('either', 'CC'), ('available', 'JJ'), ('examples', 'NNS')]

>> Noun Phrases are: 
 ['Initialize', 'available examples']

>> Named Entities are: 
 [('GPE', 'Initialize')] 

>> Stemming using Porter Stemmer: 
 [('Initialize', 'initi'), ('examples', 'exampl'), ('either', 'either'), ('available', 'avail'), ('examples', 'exampl')]

>> Stemming using Snowball Stemmer: 
 [('Initialize', 'initi'), ('examples', 'exampl'), ('either', 'either'), ('available', 'avail'), ('examples', 'exampl')]

>> Lemmatization: 
 [('Initialize', 'Initialize'), ('examples', 'example'), ('either', 'either'), ('available', 'available'), ('examples', 'example')]



========================================== PARAGRAPH 283 ===========================================

or all examples not correctly handled by rule set.   

------------------- Sentence 1 -------------------

or all examples not correctly handled by rule set.

>> Tokens are: 
 ['examples', 'correctly', 'handled', 'rule', 'set', '.']

>> Bigrams are: 
 [('examples', 'correctly'), ('correctly', 'handled'), ('handled', 'rule'), ('rule', 'set'), ('set', '.')]

>> Trigrams are: 
 [('examples', 'correctly', 'handled'), ('correctly', 'handled', 'rule'), ('handled', 'rule', 'set'), ('rule', 'set', '.')]

>> POS Tags are: 
 [('examples', 'NNS'), ('correctly', 'RB'), ('handled', 'VBD'), ('rule', 'NN'), ('set', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['examples', 'rule set']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('examples', 'exampl'), ('correctly', 'correctli'), ('handled', 'handl'), ('rule', 'rule'), ('set', 'set'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('examples', 'exampl'), ('correctly', 'correct'), ('handled', 'handl'), ('rule', 'rule'), ('set', 'set'), ('.', '.')]

>> Lemmatization: 
 [('examples', 'example'), ('correctly', 'correctly'), ('handled', 'handled'), ('rule', 'rule'), ('set', 'set'), ('.', '.')]



========================================== PARAGRAPH 284 ===========================================

3. Repeat   

------------------- Sentence 1 -------------------

3.

>> Tokens are: 
 ['3', '.']

>> Bigrams are: 
 [('3', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('3', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('3', '3'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('3', '3'), ('.', '.')]

>> Lemmatization: 
 [('3', '3'), ('.', '.')]


------------------- Sentence 2 -------------------

Repeat

>> Tokens are: 
 ['Repeat']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Repeat', 'NN')]

>> Noun Phrases are: 
 ['Repeat']

>> Named Entities are: 
 [('GPE', 'Repeat')] 

>> Stemming using Porter Stemmer: 
 [('Repeat', 'repeat')]

>> Stemming using Snowball Stemmer: 
 [('Repeat', 'repeat')]

>> Lemmatization: 
 [('Repeat', 'Repeat')]



========================================== PARAGRAPH 285 ===========================================

     (a) Find best, the best rule with respect to examples.   

------------------- Sentence 1 -------------------

     (a) Find best, the best rule with respect to examples.

>> Tokens are: 
 ['(', ')', 'Find', 'best', ',', 'best', 'rule', 'respect', 'examples', '.']

>> Bigrams are: 
 [('(', ')'), (')', 'Find'), ('Find', 'best'), ('best', ','), (',', 'best'), ('best', 'rule'), ('rule', 'respect'), ('respect', 'examples'), ('examples', '.')]

>> Trigrams are: 
 [('(', ')', 'Find'), (')', 'Find', 'best'), ('Find', 'best', ','), ('best', ',', 'best'), (',', 'best', 'rule'), ('best', 'rule', 'respect'), ('rule', 'respect', 'examples'), ('respect', 'examples', '.')]

>> POS Tags are: 
 [('(', '('), (')', ')'), ('Find', 'NNP'), ('best', 'JJS'), (',', ','), ('best', 'JJS'), ('rule', 'NN'), ('respect', 'NN'), ('examples', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['Find', 'rule respect examples']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('(', '('), (')', ')'), ('Find', 'find'), ('best', 'best'), (',', ','), ('best', 'best'), ('rule', 'rule'), ('respect', 'respect'), ('examples', 'exampl'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), (')', ')'), ('Find', 'find'), ('best', 'best'), (',', ','), ('best', 'best'), ('rule', 'rule'), ('respect', 'respect'), ('examples', 'exampl'), ('.', '.')]

>> Lemmatization: 
 [('(', '('), (')', ')'), ('Find', 'Find'), ('best', 'best'), (',', ','), ('best', 'best'), ('rule', 'rule'), ('respect', 'respect'), ('examples', 'example'), ('.', '.')]



========================================== PARAGRAPH 286 ===========================================

     (b) If such a rule can be found   

------------------- Sentence 1 -------------------

     (b) If such a rule can be found

>> Tokens are: 
 ['(', 'b', ')', 'If', 'rule', 'found']

>> Bigrams are: 
 [('(', 'b'), ('b', ')'), (')', 'If'), ('If', 'rule'), ('rule', 'found')]

>> Trigrams are: 
 [('(', 'b', ')'), ('b', ')', 'If'), (')', 'If', 'rule'), ('If', 'rule', 'found')]

>> POS Tags are: 
 [('(', '('), ('b', 'NN'), (')', ')'), ('If', 'IN'), ('rule', 'NN'), ('found', 'VBD')]

>> Noun Phrases are: 
 ['b', 'rule']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('b', 'b'), (')', ')'), ('If', 'if'), ('rule', 'rule'), ('found', 'found')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('b', 'b'), (')', ')'), ('If', 'if'), ('rule', 'rule'), ('found', 'found')]

>> Lemmatization: 
 [('(', '('), ('b', 'b'), (')', ')'), ('If', 'If'), ('rule', 'rule'), ('found', 'found')]



========================================== PARAGRAPH 287 ===========================================

i. Add best to rule set.   ii. Set examples to all examples not handled  

------------------- Sentence 1 -------------------

i.

>> Tokens are: 
 ['.']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('.', '.')]

>> Lemmatization: 
 [('.', '.')]


------------------- Sentence 2 -------------------

Add best to rule set.

>> Tokens are: 
 ['Add', 'best', 'rule', 'set', '.']

>> Bigrams are: 
 [('Add', 'best'), ('best', 'rule'), ('rule', 'set'), ('set', '.')]

>> Trigrams are: 
 [('Add', 'best', 'rule'), ('best', 'rule', 'set'), ('rule', 'set', '.')]

>> POS Tags are: 
 [('Add', 'NNP'), ('best', 'JJS'), ('rule', 'NN'), ('set', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Add', 'rule set']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Add', 'add'), ('best', 'best'), ('rule', 'rule'), ('set', 'set'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Add', 'add'), ('best', 'best'), ('rule', 'rule'), ('set', 'set'), ('.', '.')]

>> Lemmatization: 
 [('Add', 'Add'), ('best', 'best'), ('rule', 'rule'), ('set', 'set'), ('.', '.')]


------------------- Sentence 3 -------------------

ii.

>> Tokens are: 
 ['ii', '.']

>> Bigrams are: 
 [('ii', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('ii', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['ii']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('ii', 'ii'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('ii', 'ii'), ('.', '.')]

>> Lemmatization: 
 [('ii', 'ii'), ('.', '.')]


------------------- Sentence 4 -------------------

Set examples to all examples not handled

>> Tokens are: 
 ['Set', 'examples', 'examples', 'handled']

>> Bigrams are: 
 [('Set', 'examples'), ('examples', 'examples'), ('examples', 'handled')]

>> Trigrams are: 
 [('Set', 'examples', 'examples'), ('examples', 'examples', 'handled')]

>> POS Tags are: 
 [('Set', 'NNP'), ('examples', 'NNS'), ('examples', 'NNS'), ('handled', 'VBD')]

>> Noun Phrases are: 
 ['Set examples examples']

>> Named Entities are: 
 [('GPE', 'Set')] 

>> Stemming using Porter Stemmer: 
 [('Set', 'set'), ('examples', 'exampl'), ('examples', 'exampl'), ('handled', 'handl')]

>> Stemming using Snowball Stemmer: 
 [('Set', 'set'), ('examples', 'exampl'), ('examples', 'exampl'), ('handled', 'handl')]

>> Lemmatization: 
 [('Set', 'Set'), ('examples', 'example'), ('examples', 'example'), ('handled', 'handled')]



========================================== PARAGRAPH 288 ===========================================

correctly by rule set.          

------------------- Sentence 1 -------------------

correctly by rule set.

>> Tokens are: 
 ['correctly', 'rule', 'set', '.']

>> Bigrams are: 
 [('correctly', 'rule'), ('rule', 'set'), ('set', '.')]

>> Trigrams are: 
 [('correctly', 'rule', 'set'), ('rule', 'set', '.')]

>> POS Tags are: 
 [('correctly', 'RB'), ('rule', 'NN'), ('set', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['rule set']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('correctly', 'correctli'), ('rule', 'rule'), ('set', 'set'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('correctly', 'correct'), ('rule', 'rule'), ('set', 'set'), ('.', '.')]

>> Lemmatization: 
 [('correctly', 'correctly'), ('rule', 'rule'), ('set', 'set'), ('.', '.')]



========================================== PARAGRAPH 289 ===========================================

4. Until no rule best can be found   

------------------- Sentence 1 -------------------

4.

>> Tokens are: 
 ['4', '.']

>> Bigrams are: 
 [('4', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('4', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('4', '4'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('4', '4'), ('.', '.')]

>> Lemmatization: 
 [('4', '4'), ('.', '.')]


------------------- Sentence 2 -------------------

Until no rule best can be found

>> Tokens are: 
 ['Until', 'rule', 'best', 'found']

>> Bigrams are: 
 [('Until', 'rule'), ('rule', 'best'), ('best', 'found')]

>> Trigrams are: 
 [('Until', 'rule', 'best'), ('rule', 'best', 'found')]

>> POS Tags are: 
 [('Until', 'IN'), ('rule', 'NN'), ('best', 'RB'), ('found', 'VBD')]

>> Noun Phrases are: 
 ['rule']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Until', 'until'), ('rule', 'rule'), ('best', 'best'), ('found', 'found')]

>> Stemming using Snowball Stemmer: 
 [('Until', 'until'), ('rule', 'rule'), ('best', 'best'), ('found', 'found')]

>> Lemmatization: 
 [('Until', 'Until'), ('rule', 'rule'), ('best', 'best'), ('found', 'found')]



========================================== PARAGRAPH 290 ===========================================

1. Check for base cases   2. For each attribute a  calculate  

------------------- Sentence 1 -------------------

1.

>> Tokens are: 
 ['1', '.']

>> Bigrams are: 
 [('1', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('1', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('1', '1'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('1', '1'), ('.', '.')]

>> Lemmatization: 
 [('1', '1'), ('.', '.')]


------------------- Sentence 2 -------------------

Check for base cases   2.

>> Tokens are: 
 ['Check', 'base', 'cases', '2', '.']

>> Bigrams are: 
 [('Check', 'base'), ('base', 'cases'), ('cases', '2'), ('2', '.')]

>> Trigrams are: 
 [('Check', 'base', 'cases'), ('base', 'cases', '2'), ('cases', '2', '.')]

>> POS Tags are: 
 [('Check', 'NNP'), ('base', 'NN'), ('cases', 'NNS'), ('2', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Check base cases']

>> Named Entities are: 
 [('GPE', 'Check')] 

>> Stemming using Porter Stemmer: 
 [('Check', 'check'), ('base', 'base'), ('cases', 'case'), ('2', '2'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Check', 'check'), ('base', 'base'), ('cases', 'case'), ('2', '2'), ('.', '.')]

>> Lemmatization: 
 [('Check', 'Check'), ('base', 'base'), ('cases', 'case'), ('2', '2'), ('.', '.')]


------------------- Sentence 3 -------------------

For each attribute a  calculate

>> Tokens are: 
 ['For', 'attribute', '', '', 'calculate']

>> Bigrams are: 
 [('For', 'attribute'), ('attribute', ''), ('', ''), ('', 'calculate')]

>> Trigrams are: 
 [('For', 'attribute', ''), ('attribute', '', ''), ('', '', 'calculate')]

>> POS Tags are: 
 [('For', 'IN'), ('attribute', 'JJ'), ('', 'NNP'), ('', 'NNP'), ('calculate', 'NN')]

>> Noun Phrases are: 
 ['attribute   calculate']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('For', 'for'), ('attribute', 'attribut'), ('', ''), ('', ''), ('calculate', 'calcul')]

>> Stemming using Snowball Stemmer: 
 [('For', 'for'), ('attribute', 'attribut'), ('', ''), ('', ''), ('calculate', 'calcul')]

>> Lemmatization: 
 [('For', 'For'), ('attribute', 'attribute'), ('', ''), ('', ''), ('calculate', 'calculate')]



========================================== PARAGRAPH 291 ===========================================

i. Normalized the information gain (IG) from splitting  on attribute a.  

------------------- Sentence 1 -------------------

i. Normalized the information gain (IG) from splitting  on attribute a.

>> Tokens are: 
 ['i.', 'Normalized', 'information', 'gain', '(', 'IG', ')', 'splitting', 'attribute', '', '', '.']

>> Bigrams are: 
 [('i.', 'Normalized'), ('Normalized', 'information'), ('information', 'gain'), ('gain', '('), ('(', 'IG'), ('IG', ')'), (')', 'splitting'), ('splitting', 'attribute'), ('attribute', ''), ('', ''), ('', '.')]

>> Trigrams are: 
 [('i.', 'Normalized', 'information'), ('Normalized', 'information', 'gain'), ('information', 'gain', '('), ('gain', '(', 'IG'), ('(', 'IG', ')'), ('IG', ')', 'splitting'), (')', 'splitting', 'attribute'), ('splitting', 'attribute', ''), ('attribute', '', ''), ('', '', '.')]

>> POS Tags are: 
 [('i.', 'NN'), ('Normalized', 'NNP'), ('information', 'NN'), ('gain', 'NN'), ('(', '('), ('IG', 'NNP'), (')', ')'), ('splitting', 'VBG'), ('attribute', 'JJ'), ('', 'JJ'), ('', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['i. Normalized information gain', 'IG', 'attribute  ']

>> Named Entities are: 
 [('GPE', 'Normalized')] 

>> Stemming using Porter Stemmer: 
 [('i.', 'i.'), ('Normalized', 'normal'), ('information', 'inform'), ('gain', 'gain'), ('(', '('), ('IG', 'ig'), (')', ')'), ('splitting', 'split'), ('attribute', 'attribut'), ('', ''), ('', ''), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('i.', 'i.'), ('Normalized', 'normal'), ('information', 'inform'), ('gain', 'gain'), ('(', '('), ('IG', 'ig'), (')', ')'), ('splitting', 'split'), ('attribute', 'attribut'), ('', ''), ('', ''), ('.', '.')]

>> Lemmatization: 
 [('i.', 'i.'), ('Normalized', 'Normalized'), ('information', 'information'), ('gain', 'gain'), ('(', '('), ('IG', 'IG'), (')', ')'), ('splitting', 'splitting'), ('attribute', 'attribute'), ('', ''), ('', ''), ('.', '.')]



========================================== PARAGRAPH 292 ===========================================

3. Find the best a, attribute that has highest IG   4. Create a decision node: node that splits on best of a  5. Recurse on the sub-lists obtained by Splitting on a best  

------------------- Sentence 1 -------------------

3.

>> Tokens are: 
 ['3', '.']

>> Bigrams are: 
 [('3', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('3', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('3', '3'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('3', '3'), ('.', '.')]

>> Lemmatization: 
 [('3', '3'), ('.', '.')]


------------------- Sentence 2 -------------------

Find the best a, attribute that has highest IG   4.

>> Tokens are: 
 ['Find', 'best', '', '', ',', 'attribute', 'highest', 'IG', '4', '.']

>> Bigrams are: 
 [('Find', 'best'), ('best', ''), ('', ''), ('', ','), (',', 'attribute'), ('attribute', 'highest'), ('highest', 'IG'), ('IG', '4'), ('4', '.')]

>> Trigrams are: 
 [('Find', 'best', ''), ('best', '', ''), ('', '', ','), ('', ',', 'attribute'), (',', 'attribute', 'highest'), ('attribute', 'highest', 'IG'), ('highest', 'IG', '4'), ('IG', '4', '.')]

>> POS Tags are: 
 [('Find', 'NNP'), ('best', 'JJS'), ('', 'NN'), ('', 'NN'), (',', ','), ('attribute', 'JJ'), ('highest', 'JJS'), ('IG', 'JJ'), ('4', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Find', ' ']

>> Named Entities are: 
 [('GPE', 'Find')] 

>> Stemming using Porter Stemmer: 
 [('Find', 'find'), ('best', 'best'), ('', ''), ('', ''), (',', ','), ('attribute', 'attribut'), ('highest', 'highest'), ('IG', 'ig'), ('4', '4'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Find', 'find'), ('best', 'best'), ('', ''), ('', ''), (',', ','), ('attribute', 'attribut'), ('highest', 'highest'), ('IG', 'ig'), ('4', '4'), ('.', '.')]

>> Lemmatization: 
 [('Find', 'Find'), ('best', 'best'), ('', ''), ('', ''), (',', ','), ('attribute', 'attribute'), ('highest', 'highest'), ('IG', 'IG'), ('4', '4'), ('.', '.')]


------------------- Sentence 3 -------------------

Create a decision node: node that splits on best of a  5.

>> Tokens are: 
 ['Create', 'decision', 'node', ':', 'node', 'splits', 'best', '', '', '5', '.']

>> Bigrams are: 
 [('Create', 'decision'), ('decision', 'node'), ('node', ':'), (':', 'node'), ('node', 'splits'), ('splits', 'best'), ('best', ''), ('', ''), ('', '5'), ('5', '.')]

>> Trigrams are: 
 [('Create', 'decision', 'node'), ('decision', 'node', ':'), ('node', ':', 'node'), (':', 'node', 'splits'), ('node', 'splits', 'best'), ('splits', 'best', ''), ('best', '', ''), ('', '', '5'), ('', '5', '.')]

>> POS Tags are: 
 [('Create', 'NNP'), ('decision', 'NN'), ('node', 'NN'), (':', ':'), ('node', 'JJ'), ('splits', 'NNS'), ('best', 'JJS'), ('', 'NN'), ('', 'NN'), ('5', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Create decision node', 'node splits', ' ']

>> Named Entities are: 
 [('GPE', 'Create')] 

>> Stemming using Porter Stemmer: 
 [('Create', 'creat'), ('decision', 'decis'), ('node', 'node'), (':', ':'), ('node', 'node'), ('splits', 'split'), ('best', 'best'), ('', ''), ('', ''), ('5', '5'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Create', 'creat'), ('decision', 'decis'), ('node', 'node'), (':', ':'), ('node', 'node'), ('splits', 'split'), ('best', 'best'), ('', ''), ('', ''), ('5', '5'), ('.', '.')]

>> Lemmatization: 
 [('Create', 'Create'), ('decision', 'decision'), ('node', 'node'), (':', ':'), ('node', 'node'), ('splits', 'split'), ('best', 'best'), ('', ''), ('', ''), ('5', '5'), ('.', '.')]


------------------- Sentence 4 -------------------

Recurse on the sub-lists obtained by Splitting on a best

>> Tokens are: 
 ['Recurse', 'sub-lists', 'obtained', 'Splitting', 'best']

>> Bigrams are: 
 [('Recurse', 'sub-lists'), ('sub-lists', 'obtained'), ('obtained', 'Splitting'), ('Splitting', 'best')]

>> Trigrams are: 
 [('Recurse', 'sub-lists', 'obtained'), ('sub-lists', 'obtained', 'Splitting'), ('obtained', 'Splitting', 'best')]

>> POS Tags are: 
 [('Recurse', 'JJ'), ('sub-lists', 'NNS'), ('obtained', 'VBD'), ('Splitting', 'NNP'), ('best', 'JJS')]

>> Noun Phrases are: 
 ['Recurse sub-lists', 'Splitting']

>> Named Entities are: 
 [('GPE', 'Recurse')] 

>> Stemming using Porter Stemmer: 
 [('Recurse', 'recurs'), ('sub-lists', 'sub-list'), ('obtained', 'obtain'), ('Splitting', 'split'), ('best', 'best')]

>> Stemming using Snowball Stemmer: 
 [('Recurse', 'recurs'), ('sub-lists', 'sub-list'), ('obtained', 'obtain'), ('Splitting', 'split'), ('best', 'best')]

>> Lemmatization: 
 [('Recurse', 'Recurse'), ('sub-lists', 'sub-lists'), ('obtained', 'obtained'), ('Splitting', 'Splitting'), ('best', 'best')]



========================================== PARAGRAPH 293 ===========================================

and add those nodes as children of node  

------------------- Sentence 1 -------------------

and add those nodes as children of node

>> Tokens are: 
 ['add', 'nodes', 'children', 'node']

>> Bigrams are: 
 [('add', 'nodes'), ('nodes', 'children'), ('children', 'node')]

>> Trigrams are: 
 [('add', 'nodes', 'children'), ('nodes', 'children', 'node')]

>> POS Tags are: 
 [('add', 'VB'), ('nodes', 'NNS'), ('children', 'NNS'), ('node', 'RB')]

>> Noun Phrases are: 
 ['nodes children']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('add', 'add'), ('nodes', 'node'), ('children', 'children'), ('node', 'node')]

>> Stemming using Snowball Stemmer: 
 [('add', 'add'), ('nodes', 'node'), ('children', 'children'), ('node', 'node')]

>> Lemmatization: 
 [('add', 'add'), ('nodes', 'node'), ('children', 'child'), ('node', 'node')]



========================================== PARAGRAPH 294 ===========================================

at1  

------------------- Sentence 1 -------------------

at1

>> Tokens are: 
 ['at1']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('at1', 'NN')]

>> Noun Phrases are: 
 ['at1']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('at1', 'at1')]

>> Stemming using Snowball Stemmer: 
 [('at1', 'at1')]

>> Lemmatization: 
 [('at1', 'at1')]



========================================== PARAGRAPH 295 ===========================================

at2 No No  

------------------- Sentence 1 -------------------

at2 No No

>> Tokens are: 
 ['at2', 'No', 'No']

>> Bigrams are: 
 [('at2', 'No'), ('No', 'No')]

>> Trigrams are: 
 [('at2', 'No', 'No')]

>> POS Tags are: 
 [('at2', 'IN'), ('No', 'DT'), ('No', 'NNP')]

>> Noun Phrases are: 
 ['No No']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('at2', 'at2'), ('No', 'no'), ('No', 'no')]

>> Stemming using Snowball Stemmer: 
 [('at2', 'at2'), ('No', 'no'), ('No', 'no')]

>> Lemmatization: 
 [('at2', 'at2'), ('No', 'No'), ('No', 'No')]



========================================== PARAGRAPH 296 ===========================================

  


========================================== PARAGRAPH 297 ===========================================

at4 at3  No  

------------------- Sentence 1 -------------------

at4 at3  No

>> Tokens are: 
 ['at4', 'at3', 'No']

>> Bigrams are: 
 [('at4', 'at3'), ('at3', 'No')]

>> Trigrams are: 
 [('at4', 'at3', 'No')]

>> POS Tags are: 
 [('at4', 'NN'), ('at3', 'VBZ'), ('No', 'DT')]

>> Noun Phrases are: 
 ['at4']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('at4', 'at4'), ('at3', 'at3'), ('No', 'no')]

>> Stemming using Snowball Stemmer: 
 [('at4', 'at4'), ('at3', 'at3'), ('No', 'no')]

>> Lemmatization: 
 [('at4', 'at4'), ('at3', 'at3'), ('No', 'No')]



========================================== PARAGRAPH 298 ===========================================

Yes  

------------------- Sentence 1 -------------------

Yes

>> Tokens are: 
 ['Yes']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Yes', 'UH')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Yes', 'ye')]

>> Stemming using Snowball Stemmer: 
 [('Yes', 'yes')]

>> Lemmatization: 
 [('Yes', 'Yes')]



========================================== PARAGRAPH 299 ===========================================

No    

------------------- Sentence 1 -------------------

No

>> Tokens are: 
 ['No']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('No', 'DT')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('No', 'no')]

>> Stemming using Snowball Stemmer: 
 [('No', 'no')]

>> Lemmatization: 
 [('No', 'No')]



========================================== PARAGRAPH 300 ===========================================

Yes No 

------------------- Sentence 1 -------------------

Yes No

>> Tokens are: 
 ['Yes', 'No']

>> Bigrams are: 
 [('Yes', 'No')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Yes', 'UH'), ('No', 'DT')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Yes', 'ye'), ('No', 'no')]

>> Stemming using Snowball Stemmer: 
 [('Yes', 'yes'), ('No', 'no')]

>> Lemmatization: 
 [('Yes', 'Yes'), ('No', 'No')]



========================================== PARAGRAPH 301 ===========================================

ISSN: 2229-6956(ONLINE)                                                                                                                             ICTACT JOURNAL ON SOFT COMPUTING, APRIL 2015, VOLUME: 05, ISSUE: 03  

------------------- Sentence 1 -------------------

ISSN: 2229-6956(ONLINE)                                                                                                                             ICTACT JOURNAL ON SOFT COMPUTING, APRIL 2015, VOLUME: 05, ISSUE: 03

>> Tokens are: 
 ['ISSN', ':', '2229-6956', '(', 'ONLINE', ')', 'ICTACT', 'JOURNAL', 'ON', 'SOFT', 'COMPUTING', ',', 'APRIL', '2015', ',', 'VOLUME', ':', '05', ',', 'ISSUE', ':', '03']

>> Bigrams are: 
 [('ISSN', ':'), (':', '2229-6956'), ('2229-6956', '('), ('(', 'ONLINE'), ('ONLINE', ')'), (')', 'ICTACT'), ('ICTACT', 'JOURNAL'), ('JOURNAL', 'ON'), ('ON', 'SOFT'), ('SOFT', 'COMPUTING'), ('COMPUTING', ','), (',', 'APRIL'), ('APRIL', '2015'), ('2015', ','), (',', 'VOLUME'), ('VOLUME', ':'), (':', '05'), ('05', ','), (',', 'ISSUE'), ('ISSUE', ':'), (':', '03')]

>> Trigrams are: 
 [('ISSN', ':', '2229-6956'), (':', '2229-6956', '('), ('2229-6956', '(', 'ONLINE'), ('(', 'ONLINE', ')'), ('ONLINE', ')', 'ICTACT'), (')', 'ICTACT', 'JOURNAL'), ('ICTACT', 'JOURNAL', 'ON'), ('JOURNAL', 'ON', 'SOFT'), ('ON', 'SOFT', 'COMPUTING'), ('SOFT', 'COMPUTING', ','), ('COMPUTING', ',', 'APRIL'), (',', 'APRIL', '2015'), ('APRIL', '2015', ','), ('2015', ',', 'VOLUME'), (',', 'VOLUME', ':'), ('VOLUME', ':', '05'), (':', '05', ','), ('05', ',', 'ISSUE'), (',', 'ISSUE', ':'), ('ISSUE', ':', '03')]

>> POS Tags are: 
 [('ISSN', 'NN'), (':', ':'), ('2229-6956', 'JJ'), ('(', '('), ('ONLINE', 'NNP'), (')', ')'), ('ICTACT', 'NNP'), ('JOURNAL', 'NNP'), ('ON', 'NNP'), ('SOFT', 'NNP'), ('COMPUTING', 'NNP'), (',', ','), ('APRIL', 'NNP'), ('2015', 'CD'), (',', ','), ('VOLUME', 'NNP'), (':', ':'), ('05', 'CD'), (',', ','), ('ISSUE', 'NNP'), (':', ':'), ('03', 'CD')]

>> Noun Phrases are: 
 ['ISSN', 'ONLINE', 'ICTACT JOURNAL ON SOFT COMPUTING', 'APRIL', 'VOLUME', 'ISSUE']

>> Named Entities are: 
 [('ORGANIZATION', 'ONLINE'), ('ORGANIZATION', 'ICTACT'), ('ORGANIZATION', 'VOLUME'), ('ORGANIZATION', 'ISSUE')] 

>> Stemming using Porter Stemmer: 
 [('ISSN', 'issn'), (':', ':'), ('2229-6956', '2229-6956'), ('(', '('), ('ONLINE', 'onlin'), (')', ')'), ('ICTACT', 'ictact'), ('JOURNAL', 'journal'), ('ON', 'on'), ('SOFT', 'soft'), ('COMPUTING', 'comput'), (',', ','), ('APRIL', 'april'), ('2015', '2015'), (',', ','), ('VOLUME', 'volum'), (':', ':'), ('05', '05'), (',', ','), ('ISSUE', 'issu'), (':', ':'), ('03', '03')]

>> Stemming using Snowball Stemmer: 
 [('ISSN', 'issn'), (':', ':'), ('2229-6956', '2229-6956'), ('(', '('), ('ONLINE', 'onlin'), (')', ')'), ('ICTACT', 'ictact'), ('JOURNAL', 'journal'), ('ON', 'on'), ('SOFT', 'soft'), ('COMPUTING', 'comput'), (',', ','), ('APRIL', 'april'), ('2015', '2015'), (',', ','), ('VOLUME', 'volum'), (':', ':'), ('05', '05'), (',', ','), ('ISSUE', 'issu'), (':', ':'), ('03', '03')]

>> Lemmatization: 
 [('ISSN', 'ISSN'), (':', ':'), ('2229-6956', '2229-6956'), ('(', '('), ('ONLINE', 'ONLINE'), (')', ')'), ('ICTACT', 'ICTACT'), ('JOURNAL', 'JOURNAL'), ('ON', 'ON'), ('SOFT', 'SOFT'), ('COMPUTING', 'COMPUTING'), (',', ','), ('APRIL', 'APRIL'), ('2015', '2015'), (',', ','), ('VOLUME', 'VOLUME'), (':', ':'), ('05', '05'), (',', ','), ('ISSUE', 'ISSUE'), (':', ':'), ('03', '03')]



========================================== PARAGRAPH 302 ===========================================

949  

------------------- Sentence 1 -------------------

949

>> Tokens are: 
 ['949']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('949', 'CD')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('949', '949')]

>> Stemming using Snowball Stemmer: 
 [('949', '949')]

>> Lemmatization: 
 [('949', '949')]



========================================== PARAGRAPH 303 ===========================================

Statistical learning theory deals with the problem of finding a  

------------------- Sentence 1 -------------------

Statistical learning theory deals with the problem of finding a

>> Tokens are: 
 ['Statistical', 'learning', 'theory', 'deals', 'problem', 'finding']

>> Bigrams are: 
 [('Statistical', 'learning'), ('learning', 'theory'), ('theory', 'deals'), ('deals', 'problem'), ('problem', 'finding')]

>> Trigrams are: 
 [('Statistical', 'learning', 'theory'), ('learning', 'theory', 'deals'), ('theory', 'deals', 'problem'), ('deals', 'problem', 'finding')]

>> POS Tags are: 
 [('Statistical', 'JJ'), ('learning', 'VBG'), ('theory', 'JJ'), ('deals', 'NNS'), ('problem', 'NN'), ('finding', 'NN')]

>> Noun Phrases are: 
 ['theory deals problem finding']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Statistical', 'statist'), ('learning', 'learn'), ('theory', 'theori'), ('deals', 'deal'), ('problem', 'problem'), ('finding', 'find')]

>> Stemming using Snowball Stemmer: 
 [('Statistical', 'statist'), ('learning', 'learn'), ('theory', 'theori'), ('deals', 'deal'), ('problem', 'problem'), ('finding', 'find')]

>> Lemmatization: 
 [('Statistical', 'Statistical'), ('learning', 'learning'), ('theory', 'theory'), ('deals', 'deal'), ('problem', 'problem'), ('finding', 'finding')]



========================================== PARAGRAPH 304 ===========================================

predictive function based on data and it has a good number of  

------------------- Sentence 1 -------------------

predictive function based on data and it has a good number of

>> Tokens are: 
 ['predictive', 'function', 'based', 'data', 'good', 'number']

>> Bigrams are: 
 [('predictive', 'function'), ('function', 'based'), ('based', 'data'), ('data', 'good'), ('good', 'number')]

>> Trigrams are: 
 [('predictive', 'function', 'based'), ('function', 'based', 'data'), ('based', 'data', 'good'), ('data', 'good', 'number')]

>> POS Tags are: 
 [('predictive', 'JJ'), ('function', 'NN'), ('based', 'VBN'), ('data', 'NNS'), ('good', 'JJ'), ('number', 'NN')]

>> Noun Phrases are: 
 ['predictive function', 'data', 'good number']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('predictive', 'predict'), ('function', 'function'), ('based', 'base'), ('data', 'data'), ('good', 'good'), ('number', 'number')]

>> Stemming using Snowball Stemmer: 
 [('predictive', 'predict'), ('function', 'function'), ('based', 'base'), ('data', 'data'), ('good', 'good'), ('number', 'number')]

>> Lemmatization: 
 [('predictive', 'predictive'), ('function', 'function'), ('based', 'based'), ('data', 'data'), ('good', 'good'), ('number', 'number')]



========================================== PARAGRAPH 305 ===========================================

applications in the field of AI. The major of goal of statistical  

------------------- Sentence 1 -------------------

applications in the field of AI.

>> Tokens are: 
 ['applications', 'field', 'AI', '.']

>> Bigrams are: 
 [('applications', 'field'), ('field', 'AI'), ('AI', '.')]

>> Trigrams are: 
 [('applications', 'field', 'AI'), ('field', 'AI', '.')]

>> POS Tags are: 
 [('applications', 'NNS'), ('field', 'NN'), ('AI', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['applications field AI']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('applications', 'applic'), ('field', 'field'), ('AI', 'ai'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('applications', 'applic'), ('field', 'field'), ('AI', 'ai'), ('.', '.')]

>> Lemmatization: 
 [('applications', 'application'), ('field', 'field'), ('AI', 'AI'), ('.', '.')]


------------------- Sentence 2 -------------------

The major of goal of statistical

>> Tokens are: 
 ['The', 'major', 'goal', 'statistical']

>> Bigrams are: 
 [('The', 'major'), ('major', 'goal'), ('goal', 'statistical')]

>> Trigrams are: 
 [('The', 'major', 'goal'), ('major', 'goal', 'statistical')]

>> POS Tags are: 
 [('The', 'DT'), ('major', 'JJ'), ('goal', 'NN'), ('statistical', 'NN')]

>> Noun Phrases are: 
 ['The major goal statistical']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('major', 'major'), ('goal', 'goal'), ('statistical', 'statist')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('major', 'major'), ('goal', 'goal'), ('statistical', 'statist')]

>> Lemmatization: 
 [('The', 'The'), ('major', 'major'), ('goal', 'goal'), ('statistical', 'statistical')]



========================================== PARAGRAPH 306 ===========================================

learning algorithms is to provide a framework for studying the  

------------------- Sentence 1 -------------------

learning algorithms is to provide a framework for studying the

>> Tokens are: 
 ['learning', 'algorithms', 'provide', 'framework', 'studying']

>> Bigrams are: 
 [('learning', 'algorithms'), ('algorithms', 'provide'), ('provide', 'framework'), ('framework', 'studying')]

>> Trigrams are: 
 [('learning', 'algorithms', 'provide'), ('algorithms', 'provide', 'framework'), ('provide', 'framework', 'studying')]

>> POS Tags are: 
 [('learning', 'VBG'), ('algorithms', 'JJ'), ('provide', 'NN'), ('framework', 'NN'), ('studying', 'VBG')]

>> Noun Phrases are: 
 ['algorithms provide framework']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('learning', 'learn'), ('algorithms', 'algorithm'), ('provide', 'provid'), ('framework', 'framework'), ('studying', 'studi')]

>> Stemming using Snowball Stemmer: 
 [('learning', 'learn'), ('algorithms', 'algorithm'), ('provide', 'provid'), ('framework', 'framework'), ('studying', 'studi')]

>> Lemmatization: 
 [('learning', 'learning'), ('algorithms', 'algorithm'), ('provide', 'provide'), ('framework', 'framework'), ('studying', 'studying')]



========================================== PARAGRAPH 307 ===========================================

problem of inference that is obtaining knowledge, making  

------------------- Sentence 1 -------------------

problem of inference that is obtaining knowledge, making

>> Tokens are: 
 ['problem', 'inference', 'obtaining', 'knowledge', ',', 'making']

>> Bigrams are: 
 [('problem', 'inference'), ('inference', 'obtaining'), ('obtaining', 'knowledge'), ('knowledge', ','), (',', 'making')]

>> Trigrams are: 
 [('problem', 'inference', 'obtaining'), ('inference', 'obtaining', 'knowledge'), ('obtaining', 'knowledge', ','), ('knowledge', ',', 'making')]

>> POS Tags are: 
 [('problem', 'NN'), ('inference', 'NN'), ('obtaining', 'VBG'), ('knowledge', 'NN'), (',', ','), ('making', 'VBG')]

>> Noun Phrases are: 
 ['problem inference', 'knowledge']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('problem', 'problem'), ('inference', 'infer'), ('obtaining', 'obtain'), ('knowledge', 'knowledg'), (',', ','), ('making', 'make')]

>> Stemming using Snowball Stemmer: 
 [('problem', 'problem'), ('inference', 'infer'), ('obtaining', 'obtain'), ('knowledge', 'knowledg'), (',', ','), ('making', 'make')]

>> Lemmatization: 
 [('problem', 'problem'), ('inference', 'inference'), ('obtaining', 'obtaining'), ('knowledge', 'knowledge'), (',', ','), ('making', 'making')]



========================================== PARAGRAPH 308 ===========================================

predictions and making decision by constructing model from a  

------------------- Sentence 1 -------------------

predictions and making decision by constructing model from a

>> Tokens are: 
 ['predictions', 'making', 'decision', 'constructing', 'model']

>> Bigrams are: 
 [('predictions', 'making'), ('making', 'decision'), ('decision', 'constructing'), ('constructing', 'model')]

>> Trigrams are: 
 [('predictions', 'making', 'decision'), ('making', 'decision', 'constructing'), ('decision', 'constructing', 'model')]

>> POS Tags are: 
 [('predictions', 'NNS'), ('making', 'VBG'), ('decision', 'NN'), ('constructing', 'VBG'), ('model', 'NN')]

>> Noun Phrases are: 
 ['predictions', 'decision', 'model']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('predictions', 'predict'), ('making', 'make'), ('decision', 'decis'), ('constructing', 'construct'), ('model', 'model')]

>> Stemming using Snowball Stemmer: 
 [('predictions', 'predict'), ('making', 'make'), ('decision', 'decis'), ('constructing', 'construct'), ('model', 'model')]

>> Lemmatization: 
 [('predictions', 'prediction'), ('making', 'making'), ('decision', 'decision'), ('constructing', 'constructing'), ('model', 'model')]



========================================== PARAGRAPH 309 ===========================================

set of data [17].  

------------------- Sentence 1 -------------------

set of data [17].

>> Tokens are: 
 ['set', 'data', '[', '17', ']', '.']

>> Bigrams are: 
 [('set', 'data'), ('data', '['), ('[', '17'), ('17', ']'), (']', '.')]

>> Trigrams are: 
 [('set', 'data', '['), ('data', '[', '17'), ('[', '17', ']'), ('17', ']', '.')]

>> POS Tags are: 
 [('set', 'VBN'), ('data', 'NNS'), ('[', '$'), ('17', 'CD'), (']', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['data', ']']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('set', 'set'), ('data', 'data'), ('[', '['), ('17', '17'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('set', 'set'), ('data', 'data'), ('[', '['), ('17', '17'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('set', 'set'), ('data', 'data'), ('[', '['), ('17', '17'), (']', ']'), ('.', '.')]



========================================== PARAGRAPH 310 ===========================================

Bayesian networks are the most well known representative of  

------------------- Sentence 1 -------------------

Bayesian networks are the most well known representative of

>> Tokens are: 
 ['Bayesian', 'networks', 'well', 'known', 'representative']

>> Bigrams are: 
 [('Bayesian', 'networks'), ('networks', 'well'), ('well', 'known'), ('known', 'representative')]

>> Trigrams are: 
 [('Bayesian', 'networks', 'well'), ('networks', 'well', 'known'), ('well', 'known', 'representative')]

>> POS Tags are: 
 [('Bayesian', 'JJ'), ('networks', 'NNS'), ('well', 'RB'), ('known', 'VBN'), ('representative', 'NN')]

>> Noun Phrases are: 
 ['Bayesian networks', 'representative']

>> Named Entities are: 
 [('GPE', 'Bayesian')] 

>> Stemming using Porter Stemmer: 
 [('Bayesian', 'bayesian'), ('networks', 'network'), ('well', 'well'), ('known', 'known'), ('representative', 'repres')]

>> Stemming using Snowball Stemmer: 
 [('Bayesian', 'bayesian'), ('networks', 'network'), ('well', 'well'), ('known', 'known'), ('representative', 'repres')]

>> Lemmatization: 
 [('Bayesian', 'Bayesian'), ('networks', 'network'), ('well', 'well'), ('known', 'known'), ('representative', 'representative')]



========================================== PARAGRAPH 311 ===========================================

statistical learning algorithms. A good source for learning  

------------------- Sentence 1 -------------------

statistical learning algorithms.

>> Tokens are: 
 ['statistical', 'learning', 'algorithms', '.']

>> Bigrams are: 
 [('statistical', 'learning'), ('learning', 'algorithms'), ('algorithms', '.')]

>> Trigrams are: 
 [('statistical', 'learning', 'algorithms'), ('learning', 'algorithms', '.')]

>> POS Tags are: 
 [('statistical', 'JJ'), ('learning', 'VBG'), ('algorithms', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['algorithms']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('statistical', 'statist'), ('learning', 'learn'), ('algorithms', 'algorithm'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('statistical', 'statist'), ('learning', 'learn'), ('algorithms', 'algorithm'), ('.', '.')]

>> Lemmatization: 
 [('statistical', 'statistical'), ('learning', 'learning'), ('algorithms', 'algorithm'), ('.', '.')]


------------------- Sentence 2 -------------------

A good source for learning

>> Tokens are: 
 ['A', 'good', 'source', 'learning']

>> Bigrams are: 
 [('A', 'good'), ('good', 'source'), ('source', 'learning')]

>> Trigrams are: 
 [('A', 'good', 'source'), ('good', 'source', 'learning')]

>> POS Tags are: 
 [('A', 'DT'), ('good', 'JJ'), ('source', 'NN'), ('learning', 'NN')]

>> Noun Phrases are: 
 ['A good source learning']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('A', 'a'), ('good', 'good'), ('source', 'sourc'), ('learning', 'learn')]

>> Stemming using Snowball Stemmer: 
 [('A', 'a'), ('good', 'good'), ('source', 'sourc'), ('learning', 'learn')]

>> Lemmatization: 
 [('A', 'A'), ('good', 'good'), ('source', 'source'), ('learning', 'learning')]



========================================== PARAGRAPH 312 ===========================================

Bayesian Networks (BN) theory is [18], where readers can learn  

------------------- Sentence 1 -------------------

Bayesian Networks (BN) theory is [18], where readers can learn

>> Tokens are: 
 ['Bayesian', 'Networks', '(', 'BN', ')', 'theory', '[', '18', ']', ',', 'readers', 'learn']

>> Bigrams are: 
 [('Bayesian', 'Networks'), ('Networks', '('), ('(', 'BN'), ('BN', ')'), (')', 'theory'), ('theory', '['), ('[', '18'), ('18', ']'), (']', ','), (',', 'readers'), ('readers', 'learn')]

>> Trigrams are: 
 [('Bayesian', 'Networks', '('), ('Networks', '(', 'BN'), ('(', 'BN', ')'), ('BN', ')', 'theory'), (')', 'theory', '['), ('theory', '[', '18'), ('[', '18', ']'), ('18', ']', ','), (']', ',', 'readers'), (',', 'readers', 'learn')]

>> POS Tags are: 
 [('Bayesian', 'JJ'), ('Networks', 'NNP'), ('(', '('), ('BN', 'NNP'), (')', ')'), ('theory', 'NN'), ('[', '$'), ('18', 'CD'), (']', 'NNP'), (',', ','), ('readers', 'NNS'), ('learn', 'VBP')]

>> Noun Phrases are: 
 ['Bayesian Networks', 'BN', 'theory', ']', 'readers']

>> Named Entities are: 
 [('GPE', 'Bayesian'), ('PERSON', 'Networks')] 

>> Stemming using Porter Stemmer: 
 [('Bayesian', 'bayesian'), ('Networks', 'network'), ('(', '('), ('BN', 'bn'), (')', ')'), ('theory', 'theori'), ('[', '['), ('18', '18'), (']', ']'), (',', ','), ('readers', 'reader'), ('learn', 'learn')]

>> Stemming using Snowball Stemmer: 
 [('Bayesian', 'bayesian'), ('Networks', 'network'), ('(', '('), ('BN', 'bn'), (')', ')'), ('theory', 'theori'), ('[', '['), ('18', '18'), (']', ']'), (',', ','), ('readers', 'reader'), ('learn', 'learn')]

>> Lemmatization: 
 [('Bayesian', 'Bayesian'), ('Networks', 'Networks'), ('(', '('), ('BN', 'BN'), (')', ')'), ('theory', 'theory'), ('[', '['), ('18', '18'), (']', ']'), (',', ','), ('readers', 'reader'), ('learn', 'learn')]



========================================== PARAGRAPH 313 ===========================================

applications of BN.  

------------------- Sentence 1 -------------------

applications of BN.

>> Tokens are: 
 ['applications', 'BN', '.']

>> Bigrams are: 
 [('applications', 'BN'), ('BN', '.')]

>> Trigrams are: 
 [('applications', 'BN', '.')]

>> POS Tags are: 
 [('applications', 'NNS'), ('BN', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['applications BN']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('applications', 'applic'), ('BN', 'bn'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('applications', 'applic'), ('BN', 'bn'), ('.', '.')]

>> Lemmatization: 
 [('applications', 'application'), ('BN', 'BN'), ('.', '.')]



========================================== PARAGRAPH 314 ===========================================

Statistical methods are characterized by having an explicit  

------------------- Sentence 1 -------------------

Statistical methods are characterized by having an explicit

>> Tokens are: 
 ['Statistical', 'methods', 'characterized', 'explicit']

>> Bigrams are: 
 [('Statistical', 'methods'), ('methods', 'characterized'), ('characterized', 'explicit')]

>> Trigrams are: 
 [('Statistical', 'methods', 'characterized'), ('methods', 'characterized', 'explicit')]

>> POS Tags are: 
 [('Statistical', 'JJ'), ('methods', 'NNS'), ('characterized', 'VBN'), ('explicit', 'NN')]

>> Noun Phrases are: 
 ['Statistical methods', 'explicit']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Statistical', 'statist'), ('methods', 'method'), ('characterized', 'character'), ('explicit', 'explicit')]

>> Stemming using Snowball Stemmer: 
 [('Statistical', 'statist'), ('methods', 'method'), ('characterized', 'character'), ('explicit', 'explicit')]

>> Lemmatization: 
 [('Statistical', 'Statistical'), ('methods', 'method'), ('characterized', 'characterized'), ('explicit', 'explicit')]



========================================== PARAGRAPH 315 ===========================================

underlying probability model, which provides a probability that an  

------------------- Sentence 1 -------------------

underlying probability model, which provides a probability that an

>> Tokens are: 
 ['underlying', 'probability', 'model', ',', 'provides', 'probability']

>> Bigrams are: 
 [('underlying', 'probability'), ('probability', 'model'), ('model', ','), (',', 'provides'), ('provides', 'probability')]

>> Trigrams are: 
 [('underlying', 'probability', 'model'), ('probability', 'model', ','), ('model', ',', 'provides'), (',', 'provides', 'probability')]

>> POS Tags are: 
 [('underlying', 'VBG'), ('probability', 'NN'), ('model', 'NN'), (',', ','), ('provides', 'VBZ'), ('probability', 'NN')]

>> Noun Phrases are: 
 ['probability model', 'probability']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('underlying', 'underli'), ('probability', 'probabl'), ('model', 'model'), (',', ','), ('provides', 'provid'), ('probability', 'probabl')]

>> Stemming using Snowball Stemmer: 
 [('underlying', 'under'), ('probability', 'probabl'), ('model', 'model'), (',', ','), ('provides', 'provid'), ('probability', 'probabl')]

>> Lemmatization: 
 [('underlying', 'underlying'), ('probability', 'probability'), ('model', 'model'), (',', ','), ('provides', 'provides'), ('probability', 'probability')]



========================================== PARAGRAPH 316 ===========================================

instance belongs in each class, rather than simply a classification.  

------------------- Sentence 1 -------------------

instance belongs in each class, rather than simply a classification.

>> Tokens are: 
 ['instance', 'belongs', 'class', ',', 'rather', 'simply', 'classification', '.']

>> Bigrams are: 
 [('instance', 'belongs'), ('belongs', 'class'), ('class', ','), (',', 'rather'), ('rather', 'simply'), ('simply', 'classification'), ('classification', '.')]

>> Trigrams are: 
 [('instance', 'belongs', 'class'), ('belongs', 'class', ','), ('class', ',', 'rather'), (',', 'rather', 'simply'), ('rather', 'simply', 'classification'), ('simply', 'classification', '.')]

>> POS Tags are: 
 [('instance', 'NN'), ('belongs', 'NNS'), ('class', 'NN'), (',', ','), ('rather', 'RB'), ('simply', 'RB'), ('classification', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['instance belongs class', 'classification']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('instance', 'instanc'), ('belongs', 'belong'), ('class', 'class'), (',', ','), ('rather', 'rather'), ('simply', 'simpli'), ('classification', 'classif'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('instance', 'instanc'), ('belongs', 'belong'), ('class', 'class'), (',', ','), ('rather', 'rather'), ('simply', 'simpli'), ('classification', 'classif'), ('.', '.')]

>> Lemmatization: 
 [('instance', 'instance'), ('belongs', 'belongs'), ('class', 'class'), (',', ','), ('rather', 'rather'), ('simply', 'simply'), ('classification', 'classification'), ('.', '.')]



========================================== PARAGRAPH 317 ===========================================

Linear Discriminate Analysis (LDA),which was developed in  

------------------- Sentence 1 -------------------

Linear Discriminate Analysis (LDA),which was developed in

>> Tokens are: 
 ['Linear', 'Discriminate', 'Analysis', '(', 'LDA', ')', ',', 'developed']

>> Bigrams are: 
 [('Linear', 'Discriminate'), ('Discriminate', 'Analysis'), ('Analysis', '('), ('(', 'LDA'), ('LDA', ')'), (')', ','), (',', 'developed')]

>> Trigrams are: 
 [('Linear', 'Discriminate', 'Analysis'), ('Discriminate', 'Analysis', '('), ('Analysis', '(', 'LDA'), ('(', 'LDA', ')'), ('LDA', ')', ','), (')', ',', 'developed')]

>> POS Tags are: 
 [('Linear', 'JJ'), ('Discriminate', 'NNP'), ('Analysis', 'NNP'), ('(', '('), ('LDA', 'NNP'), (')', ')'), (',', ','), ('developed', 'VBD')]

>> Noun Phrases are: 
 ['Linear Discriminate Analysis', 'LDA']

>> Named Entities are: 
 [('PERSON', 'Linear'), ('ORGANIZATION', 'Discriminate Analysis'), ('ORGANIZATION', 'LDA')] 

>> Stemming using Porter Stemmer: 
 [('Linear', 'linear'), ('Discriminate', 'discrimin'), ('Analysis', 'analysi'), ('(', '('), ('LDA', 'lda'), (')', ')'), (',', ','), ('developed', 'develop')]

>> Stemming using Snowball Stemmer: 
 [('Linear', 'linear'), ('Discriminate', 'discrimin'), ('Analysis', 'analysi'), ('(', '('), ('LDA', 'lda'), (')', ')'), (',', ','), ('developed', 'develop')]

>> Lemmatization: 
 [('Linear', 'Linear'), ('Discriminate', 'Discriminate'), ('Analysis', 'Analysis'), ('(', '('), ('LDA', 'LDA'), (')', ')'), (',', ','), ('developed', 'developed')]



========================================== PARAGRAPH 318 ===========================================

1936, and the related Fishers linear discriminate are famous  

------------------- Sentence 1 -------------------

1936, and the related Fishers linear discriminate are famous

>> Tokens are: 
 ['1936', ',', 'related', 'Fisher', '', 'linear', 'discriminate', 'famous']

>> Bigrams are: 
 [('1936', ','), (',', 'related'), ('related', 'Fisher'), ('Fisher', ''), ('', 'linear'), ('linear', 'discriminate'), ('discriminate', 'famous')]

>> Trigrams are: 
 [('1936', ',', 'related'), (',', 'related', 'Fisher'), ('related', 'Fisher', ''), ('Fisher', '', 'linear'), ('', 'linear', 'discriminate'), ('linear', 'discriminate', 'famous')]

>> POS Tags are: 
 [('1936', 'CD'), (',', ','), ('related', 'VBN'), ('Fisher', 'NNP'), ('', 'JJ'), ('linear', 'JJ'), ('discriminate', 'NN'), ('famous', 'JJ')]

>> Noun Phrases are: 
 ['Fisher', ' linear discriminate']

>> Named Entities are: 
 [('PERSON', 'Fisher')] 

>> Stemming using Porter Stemmer: 
 [('1936', '1936'), (',', ','), ('related', 'relat'), ('Fisher', 'fisher'), ('', ''), ('linear', 'linear'), ('discriminate', 'discrimin'), ('famous', 'famou')]

>> Stemming using Snowball Stemmer: 
 [('1936', '1936'), (',', ','), ('related', 'relat'), ('Fisher', 'fisher'), ('', ''), ('linear', 'linear'), ('discriminate', 'discrimin'), ('famous', 'famous')]

>> Lemmatization: 
 [('1936', '1936'), (',', ','), ('related', 'related'), ('Fisher', 'Fisher'), ('', ''), ('linear', 'linear'), ('discriminate', 'discriminate'), ('famous', 'famous')]



========================================== PARAGRAPH 319 ===========================================

methods used in statistics and machine learning to retrieve the  

------------------- Sentence 1 -------------------

methods used in statistics and machine learning to retrieve the

>> Tokens are: 
 ['methods', 'used', 'statistics', 'machine', 'learning', 'retrieve']

>> Bigrams are: 
 [('methods', 'used'), ('used', 'statistics'), ('statistics', 'machine'), ('machine', 'learning'), ('learning', 'retrieve')]

>> Trigrams are: 
 [('methods', 'used', 'statistics'), ('used', 'statistics', 'machine'), ('statistics', 'machine', 'learning'), ('machine', 'learning', 'retrieve')]

>> POS Tags are: 
 [('methods', 'NNS'), ('used', 'VBN'), ('statistics', 'NNS'), ('machine', 'NN'), ('learning', 'NN'), ('retrieve', 'NN')]

>> Noun Phrases are: 
 ['methods', 'statistics machine learning retrieve']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('methods', 'method'), ('used', 'use'), ('statistics', 'statist'), ('machine', 'machin'), ('learning', 'learn'), ('retrieve', 'retriev')]

>> Stemming using Snowball Stemmer: 
 [('methods', 'method'), ('used', 'use'), ('statistics', 'statist'), ('machine', 'machin'), ('learning', 'learn'), ('retrieve', 'retriev')]

>> Lemmatization: 
 [('methods', 'method'), ('used', 'used'), ('statistics', 'statistic'), ('machine', 'machine'), ('learning', 'learning'), ('retrieve', 'retrieve')]



========================================== PARAGRAPH 320 ===========================================

linear combination of features which best separate two or more  

------------------- Sentence 1 -------------------

linear combination of features which best separate two or more

>> Tokens are: 
 ['linear', 'combination', 'features', 'best', 'separate', 'two']

>> Bigrams are: 
 [('linear', 'combination'), ('combination', 'features'), ('features', 'best'), ('best', 'separate'), ('separate', 'two')]

>> Trigrams are: 
 [('linear', 'combination', 'features'), ('combination', 'features', 'best'), ('features', 'best', 'separate'), ('best', 'separate', 'two')]

>> POS Tags are: 
 [('linear', 'JJ'), ('combination', 'NN'), ('features', 'NNS'), ('best', 'RB'), ('separate', 'VBP'), ('two', 'CD')]

>> Noun Phrases are: 
 ['linear combination features']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('linear', 'linear'), ('combination', 'combin'), ('features', 'featur'), ('best', 'best'), ('separate', 'separ'), ('two', 'two')]

>> Stemming using Snowball Stemmer: 
 [('linear', 'linear'), ('combination', 'combin'), ('features', 'featur'), ('best', 'best'), ('separate', 'separ'), ('two', 'two')]

>> Lemmatization: 
 [('linear', 'linear'), ('combination', 'combination'), ('features', 'feature'), ('best', 'best'), ('separate', 'separate'), ('two', 'two')]



========================================== PARAGRAPH 321 ===========================================

classes of object [1]. The purpose of discriminate analysis is to  

------------------- Sentence 1 -------------------

classes of object [1].

>> Tokens are: 
 ['classes', 'object', '[', '1', ']', '.']

>> Bigrams are: 
 [('classes', 'object'), ('object', '['), ('[', '1'), ('1', ']'), (']', '.')]

>> Trigrams are: 
 [('classes', 'object', '['), ('object', '[', '1'), ('[', '1', ']'), ('1', ']', '.')]

>> POS Tags are: 
 [('classes', 'NNS'), ('object', 'VBP'), ('[', '$'), ('1', 'CD'), (']', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['classes', ']']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('classes', 'class'), ('object', 'object'), ('[', '['), ('1', '1'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('classes', 'class'), ('object', 'object'), ('[', '['), ('1', '1'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('classes', 'class'), ('object', 'object'), ('[', '['), ('1', '1'), (']', ']'), ('.', '.')]


------------------- Sentence 2 -------------------

The purpose of discriminate analysis is to

>> Tokens are: 
 ['The', 'purpose', 'discriminate', 'analysis']

>> Bigrams are: 
 [('The', 'purpose'), ('purpose', 'discriminate'), ('discriminate', 'analysis')]

>> Trigrams are: 
 [('The', 'purpose', 'discriminate'), ('purpose', 'discriminate', 'analysis')]

>> POS Tags are: 
 [('The', 'DT'), ('purpose', 'JJ'), ('discriminate', 'NN'), ('analysis', 'NN')]

>> Noun Phrases are: 
 ['The purpose discriminate analysis']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('purpose', 'purpos'), ('discriminate', 'discrimin'), ('analysis', 'analysi')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('purpose', 'purpos'), ('discriminate', 'discrimin'), ('analysis', 'analysi')]

>> Lemmatization: 
 [('The', 'The'), ('purpose', 'purpose'), ('discriminate', 'discriminate'), ('analysis', 'analysis')]



========================================== PARAGRAPH 322 ===========================================

classify objects (nations, people, customers) into one of two or  

------------------- Sentence 1 -------------------

classify objects (nations, people, customers) into one of two or

>> Tokens are: 
 ['classify', 'objects', '(', 'nations', ',', 'people', ',', 'customers', ')', 'one', 'two']

>> Bigrams are: 
 [('classify', 'objects'), ('objects', '('), ('(', 'nations'), ('nations', ','), (',', 'people'), ('people', ','), (',', 'customers'), ('customers', ')'), (')', 'one'), ('one', 'two')]

>> Trigrams are: 
 [('classify', 'objects', '('), ('objects', '(', 'nations'), ('(', 'nations', ','), ('nations', ',', 'people'), (',', 'people', ','), ('people', ',', 'customers'), (',', 'customers', ')'), ('customers', ')', 'one'), (')', 'one', 'two')]

>> POS Tags are: 
 [('classify', 'NN'), ('objects', 'NNS'), ('(', '('), ('nations', 'NNS'), (',', ','), ('people', 'NNS'), (',', ','), ('customers', 'NN'), (')', ')'), ('one', 'CD'), ('two', 'CD')]

>> Noun Phrases are: 
 ['classify objects', 'nations', 'people', 'customers']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('classify', 'classifi'), ('objects', 'object'), ('(', '('), ('nations', 'nation'), (',', ','), ('people', 'peopl'), (',', ','), ('customers', 'customers'), (')', ')'), ('one', 'one'), ('two', 'two')]

>> Stemming using Snowball Stemmer: 
 [('classify', 'classifi'), ('objects', 'object'), ('(', '('), ('nations', 'nation'), (',', ','), ('people', 'peopl'), (',', ','), ('customers', 'customers'), (')', ')'), ('one', 'one'), ('two', 'two')]

>> Lemmatization: 
 [('classify', 'classify'), ('objects', 'object'), ('(', '('), ('nations', 'nation'), (',', ','), ('people', 'people'), (',', ','), ('customers', 'customers'), (')', ')'), ('one', 'one'), ('two', 'two')]



========================================== PARAGRAPH 323 ===========================================

more groups based on set of features that describe the objects (e.g.-  

------------------- Sentence 1 -------------------

more groups based on set of features that describe the objects (e.g.-

>> Tokens are: 
 ['groups', 'based', 'set', 'features', 'describe', 'objects', '(', 'e.g.-']

>> Bigrams are: 
 [('groups', 'based'), ('based', 'set'), ('set', 'features'), ('features', 'describe'), ('describe', 'objects'), ('objects', '('), ('(', 'e.g.-')]

>> Trigrams are: 
 [('groups', 'based', 'set'), ('based', 'set', 'features'), ('set', 'features', 'describe'), ('features', 'describe', 'objects'), ('describe', 'objects', '('), ('objects', '(', 'e.g.-')]

>> POS Tags are: 
 [('groups', 'NNS'), ('based', 'VBN'), ('set', 'VBN'), ('features', 'NNS'), ('describe', 'JJ'), ('objects', 'NNS'), ('(', '('), ('e.g.-', 'JJ')]

>> Noun Phrases are: 
 ['groups', 'features', 'describe objects']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('groups', 'group'), ('based', 'base'), ('set', 'set'), ('features', 'featur'), ('describe', 'describ'), ('objects', 'object'), ('(', '('), ('e.g.-', 'e.g.-')]

>> Stemming using Snowball Stemmer: 
 [('groups', 'group'), ('based', 'base'), ('set', 'set'), ('features', 'featur'), ('describe', 'describ'), ('objects', 'object'), ('(', '('), ('e.g.-', 'e.g.-')]

>> Lemmatization: 
 [('groups', 'group'), ('based', 'based'), ('set', 'set'), ('features', 'feature'), ('describe', 'describe'), ('objects', 'object'), ('(', '('), ('e.g.-', 'e.g.-')]



========================================== PARAGRAPH 324 ===========================================

gender, marital status, income, height, weight...). The another  

------------------- Sentence 1 -------------------

gender, marital status, income, height, weight...).

>> Tokens are: 
 ['gender', ',', 'marital', 'status', ',', 'income', ',', 'height', ',', 'weight', '...', ')', '.']

>> Bigrams are: 
 [('gender', ','), (',', 'marital'), ('marital', 'status'), ('status', ','), (',', 'income'), ('income', ','), (',', 'height'), ('height', ','), (',', 'weight'), ('weight', '...'), ('...', ')'), (')', '.')]

>> Trigrams are: 
 [('gender', ',', 'marital'), (',', 'marital', 'status'), ('marital', 'status', ','), ('status', ',', 'income'), (',', 'income', ','), ('income', ',', 'height'), (',', 'height', ','), ('height', ',', 'weight'), (',', 'weight', '...'), ('weight', '...', ')'), ('...', ')', '.')]

>> POS Tags are: 
 [('gender', 'NN'), (',', ','), ('marital', 'JJ'), ('status', 'NN'), (',', ','), ('income', 'NN'), (',', ','), ('height', 'NN'), (',', ','), ('weight', 'NN'), ('...', ':'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['gender', 'marital status', 'income', 'height', 'weight']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('gender', 'gender'), (',', ','), ('marital', 'marit'), ('status', 'statu'), (',', ','), ('income', 'incom'), (',', ','), ('height', 'height'), (',', ','), ('weight', 'weight'), ('...', '...'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('gender', 'gender'), (',', ','), ('marital', 'marit'), ('status', 'status'), (',', ','), ('income', 'incom'), (',', ','), ('height', 'height'), (',', ','), ('weight', 'weight'), ('...', '...'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('gender', 'gender'), (',', ','), ('marital', 'marital'), ('status', 'status'), (',', ','), ('income', 'income'), (',', ','), ('height', 'height'), (',', ','), ('weight', 'weight'), ('...', '...'), (')', ')'), ('.', '.')]


------------------- Sentence 2 -------------------

The another

>> Tokens are: 
 ['The', 'another']

>> Bigrams are: 
 [('The', 'another')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('The', 'DT'), ('another', 'DT')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('another', 'anoth')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('another', 'anoth')]

>> Lemmatization: 
 [('The', 'The'), ('another', 'another')]



========================================== PARAGRAPH 325 ===========================================

method for estimating probability distributions from data is  

------------------- Sentence 1 -------------------

method for estimating probability distributions from data is

>> Tokens are: 
 ['method', 'estimating', 'probability', 'distributions', 'data']

>> Bigrams are: 
 [('method', 'estimating'), ('estimating', 'probability'), ('probability', 'distributions'), ('distributions', 'data')]

>> Trigrams are: 
 [('method', 'estimating', 'probability'), ('estimating', 'probability', 'distributions'), ('probability', 'distributions', 'data')]

>> POS Tags are: 
 [('method', 'NN'), ('estimating', 'VBG'), ('probability', 'NN'), ('distributions', 'NNS'), ('data', 'NNS')]

>> Noun Phrases are: 
 ['method', 'probability distributions data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('method', 'method'), ('estimating', 'estim'), ('probability', 'probabl'), ('distributions', 'distribut'), ('data', 'data')]

>> Stemming using Snowball Stemmer: 
 [('method', 'method'), ('estimating', 'estim'), ('probability', 'probabl'), ('distributions', 'distribut'), ('data', 'data')]

>> Lemmatization: 
 [('method', 'method'), ('estimating', 'estimating'), ('probability', 'probability'), ('distributions', 'distribution'), ('data', 'data')]



========================================== PARAGRAPH 326 ===========================================

maximum entropy. According to the base theory of maximum  

------------------- Sentence 1 -------------------

maximum entropy.

>> Tokens are: 
 ['maximum', 'entropy', '.']

>> Bigrams are: 
 [('maximum', 'entropy'), ('entropy', '.')]

>> Trigrams are: 
 [('maximum', 'entropy', '.')]

>> POS Tags are: 
 [('maximum', 'JJ'), ('entropy', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['maximum entropy']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('maximum', 'maximum'), ('entropy', 'entropi'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('maximum', 'maximum'), ('entropy', 'entropi'), ('.', '.')]

>> Lemmatization: 
 [('maximum', 'maximum'), ('entropy', 'entropy'), ('.', '.')]


------------------- Sentence 2 -------------------

According to the base theory of maximum

>> Tokens are: 
 ['According', 'base', 'theory', 'maximum']

>> Bigrams are: 
 [('According', 'base'), ('base', 'theory'), ('theory', 'maximum')]

>> Trigrams are: 
 [('According', 'base', 'theory'), ('base', 'theory', 'maximum')]

>> POS Tags are: 
 [('According', 'VBG'), ('base', 'NN'), ('theory', 'NN'), ('maximum', 'NN')]

>> Noun Phrases are: 
 ['base theory maximum']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('According', 'accord'), ('base', 'base'), ('theory', 'theori'), ('maximum', 'maximum')]

>> Stemming using Snowball Stemmer: 
 [('According', 'accord'), ('base', 'base'), ('theory', 'theori'), ('maximum', 'maximum')]

>> Lemmatization: 
 [('According', 'According'), ('base', 'base'), ('theory', 'theory'), ('maximum', 'maximum')]



========================================== PARAGRAPH 327 ===========================================

entropy, if nothing is known about a distribution except that it  

------------------- Sentence 1 -------------------

entropy, if nothing is known about a distribution except that it

>> Tokens are: 
 ['entropy', ',', 'nothing', 'known', 'distribution', 'except']

>> Bigrams are: 
 [('entropy', ','), (',', 'nothing'), ('nothing', 'known'), ('known', 'distribution'), ('distribution', 'except')]

>> Trigrams are: 
 [('entropy', ',', 'nothing'), (',', 'nothing', 'known'), ('nothing', 'known', 'distribution'), ('known', 'distribution', 'except')]

>> POS Tags are: 
 [('entropy', 'NN'), (',', ','), ('nothing', 'NN'), ('known', 'VBN'), ('distribution', 'NN'), ('except', 'IN')]

>> Noun Phrases are: 
 ['entropy', 'nothing', 'distribution']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('entropy', 'entropi'), (',', ','), ('nothing', 'noth'), ('known', 'known'), ('distribution', 'distribut'), ('except', 'except')]

>> Stemming using Snowball Stemmer: 
 [('entropy', 'entropi'), (',', ','), ('nothing', 'noth'), ('known', 'known'), ('distribution', 'distribut'), ('except', 'except')]

>> Lemmatization: 
 [('entropy', 'entropy'), (',', ','), ('nothing', 'nothing'), ('known', 'known'), ('distribution', 'distribution'), ('except', 'except')]



========================================== PARAGRAPH 328 ===========================================

belongs to a certain class, then the distribution with the largest  

------------------- Sentence 1 -------------------

belongs to a certain class, then the distribution with the largest

>> Tokens are: 
 ['belongs', 'certain', 'class', ',', 'distribution', 'largest']

>> Bigrams are: 
 [('belongs', 'certain'), ('certain', 'class'), ('class', ','), (',', 'distribution'), ('distribution', 'largest')]

>> Trigrams are: 
 [('belongs', 'certain', 'class'), ('certain', 'class', ','), ('class', ',', 'distribution'), (',', 'distribution', 'largest')]

>> POS Tags are: 
 [('belongs', 'NNS'), ('certain', 'JJ'), ('class', 'NN'), (',', ','), ('distribution', 'NN'), ('largest', 'JJS')]

>> Noun Phrases are: 
 ['belongs', 'certain class', 'distribution']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('belongs', 'belong'), ('certain', 'certain'), ('class', 'class'), (',', ','), ('distribution', 'distribut'), ('largest', 'largest')]

>> Stemming using Snowball Stemmer: 
 [('belongs', 'belong'), ('certain', 'certain'), ('class', 'class'), (',', ','), ('distribution', 'distribut'), ('largest', 'largest')]

>> Lemmatization: 
 [('belongs', 'belongs'), ('certain', 'certain'), ('class', 'class'), (',', ','), ('distribution', 'distribution'), ('largest', 'largest')]



========================================== PARAGRAPH 329 ===========================================

entropy should be chosen as the default.  

------------------- Sentence 1 -------------------

entropy should be chosen as the default.

>> Tokens are: 
 ['entropy', 'chosen', 'default', '.']

>> Bigrams are: 
 [('entropy', 'chosen'), ('chosen', 'default'), ('default', '.')]

>> Trigrams are: 
 [('entropy', 'chosen', 'default'), ('chosen', 'default', '.')]

>> POS Tags are: 
 [('entropy', 'NN'), ('chosen', 'VBN'), ('default', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['entropy', 'default']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('entropy', 'entropi'), ('chosen', 'chosen'), ('default', 'default'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('entropy', 'entropi'), ('chosen', 'chosen'), ('default', 'default'), ('.', '.')]

>> Lemmatization: 
 [('entropy', 'entropy'), ('chosen', 'chosen'), ('default', 'default'), ('.', '.')]



========================================== PARAGRAPH 330 ===========================================

4.1 NAIVE BAYES CLASSIFIERS  

------------------- Sentence 1 -------------------

4.1 NAIVE BAYES CLASSIFIERS

>> Tokens are: 
 ['4.1', 'NAIVE', 'BAYES', 'CLASSIFIERS']

>> Bigrams are: 
 [('4.1', 'NAIVE'), ('NAIVE', 'BAYES'), ('BAYES', 'CLASSIFIERS')]

>> Trigrams are: 
 [('4.1', 'NAIVE', 'BAYES'), ('NAIVE', 'BAYES', 'CLASSIFIERS')]

>> POS Tags are: 
 [('4.1', 'CD'), ('NAIVE', 'NNP'), ('BAYES', 'NNP'), ('CLASSIFIERS', 'NNP')]

>> Noun Phrases are: 
 ['NAIVE BAYES CLASSIFIERS']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('4.1', '4.1'), ('NAIVE', 'naiv'), ('BAYES', 'bay'), ('CLASSIFIERS', 'classifi')]

>> Stemming using Snowball Stemmer: 
 [('4.1', '4.1'), ('NAIVE', 'naiv'), ('BAYES', 'bay'), ('CLASSIFIERS', 'classifi')]

>> Lemmatization: 
 [('4.1', '4.1'), ('NAIVE', 'NAIVE'), ('BAYES', 'BAYES'), ('CLASSIFIERS', 'CLASSIFIERS')]



========================================== PARAGRAPH 331 ===========================================

Bayesian networks are widely used to perform classification  

------------------- Sentence 1 -------------------

Bayesian networks are widely used to perform classification

>> Tokens are: 
 ['Bayesian', 'networks', 'widely', 'used', 'perform', 'classification']

>> Bigrams are: 
 [('Bayesian', 'networks'), ('networks', 'widely'), ('widely', 'used'), ('used', 'perform'), ('perform', 'classification')]

>> Trigrams are: 
 [('Bayesian', 'networks', 'widely'), ('networks', 'widely', 'used'), ('widely', 'used', 'perform'), ('used', 'perform', 'classification')]

>> POS Tags are: 
 [('Bayesian', 'JJ'), ('networks', 'NNS'), ('widely', 'RB'), ('used', 'VBD'), ('perform', 'NN'), ('classification', 'NN')]

>> Noun Phrases are: 
 ['Bayesian networks', 'perform classification']

>> Named Entities are: 
 [('GPE', 'Bayesian')] 

>> Stemming using Porter Stemmer: 
 [('Bayesian', 'bayesian'), ('networks', 'network'), ('widely', 'wide'), ('used', 'use'), ('perform', 'perform'), ('classification', 'classif')]

>> Stemming using Snowball Stemmer: 
 [('Bayesian', 'bayesian'), ('networks', 'network'), ('widely', 'wide'), ('used', 'use'), ('perform', 'perform'), ('classification', 'classif')]

>> Lemmatization: 
 [('Bayesian', 'Bayesian'), ('networks', 'network'), ('widely', 'widely'), ('used', 'used'), ('perform', 'perform'), ('classification', 'classification')]



========================================== PARAGRAPH 332 ===========================================

tasks. Naive Bayesian Networks (NBN) are very simple  

------------------- Sentence 1 -------------------

tasks.

>> Tokens are: 
 ['tasks', '.']

>> Bigrams are: 
 [('tasks', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('tasks', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['tasks']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('tasks', 'task'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('tasks', 'task'), ('.', '.')]

>> Lemmatization: 
 [('tasks', 'task'), ('.', '.')]


------------------- Sentence 2 -------------------

Naive Bayesian Networks (NBN) are very simple

>> Tokens are: 
 ['Naive', 'Bayesian', 'Networks', '(', 'NBN', ')', 'simple']

>> Bigrams are: 
 [('Naive', 'Bayesian'), ('Bayesian', 'Networks'), ('Networks', '('), ('(', 'NBN'), ('NBN', ')'), (')', 'simple')]

>> Trigrams are: 
 [('Naive', 'Bayesian', 'Networks'), ('Bayesian', 'Networks', '('), ('Networks', '(', 'NBN'), ('(', 'NBN', ')'), ('NBN', ')', 'simple')]

>> POS Tags are: 
 [('Naive', 'JJ'), ('Bayesian', 'JJ'), ('Networks', 'NNP'), ('(', '('), ('NBN', 'NNP'), (')', ')'), ('simple', 'NN')]

>> Noun Phrases are: 
 ['Naive Bayesian Networks', 'NBN', 'simple']

>> Named Entities are: 
 [('PERSON', 'Bayesian Networks'), ('ORGANIZATION', 'NBN')] 

>> Stemming using Porter Stemmer: 
 [('Naive', 'naiv'), ('Bayesian', 'bayesian'), ('Networks', 'network'), ('(', '('), ('NBN', 'nbn'), (')', ')'), ('simple', 'simpl')]

>> Stemming using Snowball Stemmer: 
 [('Naive', 'naiv'), ('Bayesian', 'bayesian'), ('Networks', 'network'), ('(', '('), ('NBN', 'nbn'), (')', ')'), ('simple', 'simpl')]

>> Lemmatization: 
 [('Naive', 'Naive'), ('Bayesian', 'Bayesian'), ('Networks', 'Networks'), ('(', '('), ('NBN', 'NBN'), (')', ')'), ('simple', 'simple')]



========================================== PARAGRAPH 333 ===========================================

Bayesian networks which are composed of directed acyclic  

------------------- Sentence 1 -------------------

Bayesian networks which are composed of directed acyclic

>> Tokens are: 
 ['Bayesian', 'networks', 'composed', 'directed', 'acyclic']

>> Bigrams are: 
 [('Bayesian', 'networks'), ('networks', 'composed'), ('composed', 'directed'), ('directed', 'acyclic')]

>> Trigrams are: 
 [('Bayesian', 'networks', 'composed'), ('networks', 'composed', 'directed'), ('composed', 'directed', 'acyclic')]

>> POS Tags are: 
 [('Bayesian', 'JJ'), ('networks', 'NNS'), ('composed', 'VBD'), ('directed', 'VBN'), ('acyclic', 'JJ')]

>> Noun Phrases are: 
 ['Bayesian networks']

>> Named Entities are: 
 [('GPE', 'Bayesian')] 

>> Stemming using Porter Stemmer: 
 [('Bayesian', 'bayesian'), ('networks', 'network'), ('composed', 'compos'), ('directed', 'direct'), ('acyclic', 'acycl')]

>> Stemming using Snowball Stemmer: 
 [('Bayesian', 'bayesian'), ('networks', 'network'), ('composed', 'compos'), ('directed', 'direct'), ('acyclic', 'acycl')]

>> Lemmatization: 
 [('Bayesian', 'Bayesian'), ('networks', 'network'), ('composed', 'composed'), ('directed', 'directed'), ('acyclic', 'acyclic')]



========================================== PARAGRAPH 334 ===========================================

graphs with only one parent (representing the unobserved node)  

------------------- Sentence 1 -------------------

graphs with only one parent (representing the unobserved node)

>> Tokens are: 
 ['graphs', 'one', 'parent', '(', 'representing', 'unobserved', 'node', ')']

>> Bigrams are: 
 [('graphs', 'one'), ('one', 'parent'), ('parent', '('), ('(', 'representing'), ('representing', 'unobserved'), ('unobserved', 'node'), ('node', ')')]

>> Trigrams are: 
 [('graphs', 'one', 'parent'), ('one', 'parent', '('), ('parent', '(', 'representing'), ('(', 'representing', 'unobserved'), ('representing', 'unobserved', 'node'), ('unobserved', 'node', ')')]

>> POS Tags are: 
 [('graphs', 'NN'), ('one', 'CD'), ('parent', 'NN'), ('(', '('), ('representing', 'VBG'), ('unobserved', 'JJ'), ('node', 'NN'), (')', ')')]

>> Noun Phrases are: 
 ['graphs', 'parent', 'unobserved node']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('graphs', 'graph'), ('one', 'one'), ('parent', 'parent'), ('(', '('), ('representing', 'repres'), ('unobserved', 'unobserv'), ('node', 'node'), (')', ')')]

>> Stemming using Snowball Stemmer: 
 [('graphs', 'graph'), ('one', 'one'), ('parent', 'parent'), ('(', '('), ('representing', 'repres'), ('unobserved', 'unobserv'), ('node', 'node'), (')', ')')]

>> Lemmatization: 
 [('graphs', 'graph'), ('one', 'one'), ('parent', 'parent'), ('(', '('), ('representing', 'representing'), ('unobserved', 'unobserved'), ('node', 'node'), (')', ')')]



========================================== PARAGRAPH 335 ===========================================

and several children (corresponding to observed nodes) with a  

------------------- Sentence 1 -------------------

and several children (corresponding to observed nodes) with a

>> Tokens are: 
 ['several', 'children', '(', 'corresponding', 'observed', 'nodes', ')']

>> Bigrams are: 
 [('several', 'children'), ('children', '('), ('(', 'corresponding'), ('corresponding', 'observed'), ('observed', 'nodes'), ('nodes', ')')]

>> Trigrams are: 
 [('several', 'children', '('), ('children', '(', 'corresponding'), ('(', 'corresponding', 'observed'), ('corresponding', 'observed', 'nodes'), ('observed', 'nodes', ')')]

>> POS Tags are: 
 [('several', 'JJ'), ('children', 'NNS'), ('(', '('), ('corresponding', 'VBG'), ('observed', 'VBN'), ('nodes', 'NNS'), (')', ')')]

>> Noun Phrases are: 
 ['several children', 'nodes']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('several', 'sever'), ('children', 'children'), ('(', '('), ('corresponding', 'correspond'), ('observed', 'observ'), ('nodes', 'node'), (')', ')')]

>> Stemming using Snowball Stemmer: 
 [('several', 'sever'), ('children', 'children'), ('(', '('), ('corresponding', 'correspond'), ('observed', 'observ'), ('nodes', 'node'), (')', ')')]

>> Lemmatization: 
 [('several', 'several'), ('children', 'child'), ('(', '('), ('corresponding', 'corresponding'), ('observed', 'observed'), ('nodes', 'node'), (')', ')')]



========================================== PARAGRAPH 336 ===========================================

strong assumption of independence among child nodes in the  

------------------- Sentence 1 -------------------

strong assumption of independence among child nodes in the

>> Tokens are: 
 ['strong', 'assumption', 'independence', 'among', 'child', 'nodes']

>> Bigrams are: 
 [('strong', 'assumption'), ('assumption', 'independence'), ('independence', 'among'), ('among', 'child'), ('child', 'nodes')]

>> Trigrams are: 
 [('strong', 'assumption', 'independence'), ('assumption', 'independence', 'among'), ('independence', 'among', 'child'), ('among', 'child', 'nodes')]

>> POS Tags are: 
 [('strong', 'JJ'), ('assumption', 'NN'), ('independence', 'NN'), ('among', 'IN'), ('child', 'JJ'), ('nodes', 'NNS')]

>> Noun Phrases are: 
 ['strong assumption independence', 'child nodes']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('strong', 'strong'), ('assumption', 'assumpt'), ('independence', 'independ'), ('among', 'among'), ('child', 'child'), ('nodes', 'node')]

>> Stemming using Snowball Stemmer: 
 [('strong', 'strong'), ('assumption', 'assumpt'), ('independence', 'independ'), ('among', 'among'), ('child', 'child'), ('nodes', 'node')]

>> Lemmatization: 
 [('strong', 'strong'), ('assumption', 'assumption'), ('independence', 'independence'), ('among', 'among'), ('child', 'child'), ('nodes', 'node')]



========================================== PARAGRAPH 337 ===========================================

context of their parent [21]. According to author [20] the  

------------------- Sentence 1 -------------------

context of their parent [21].

>> Tokens are: 
 ['context', 'parent', '[', '21', ']', '.']

>> Bigrams are: 
 [('context', 'parent'), ('parent', '['), ('[', '21'), ('21', ']'), (']', '.')]

>> Trigrams are: 
 [('context', 'parent', '['), ('parent', '[', '21'), ('[', '21', ']'), ('21', ']', '.')]

>> POS Tags are: 
 [('context', 'JJ'), ('parent', 'NN'), ('[', 'VBD'), ('21', 'CD'), (']', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['context parent', ']']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('context', 'context'), ('parent', 'parent'), ('[', '['), ('21', '21'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('context', 'context'), ('parent', 'parent'), ('[', '['), ('21', '21'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('context', 'context'), ('parent', 'parent'), ('[', '['), ('21', '21'), (']', ']'), ('.', '.')]


------------------- Sentence 2 -------------------

According to author [20] the

>> Tokens are: 
 ['According', 'author', '[', '20', ']']

>> Bigrams are: 
 [('According', 'author'), ('author', '['), ('[', '20'), ('20', ']')]

>> Trigrams are: 
 [('According', 'author', '['), ('author', '[', '20'), ('[', '20', ']')]

>> POS Tags are: 
 [('According', 'VBG'), ('author', 'NN'), ('[', 'NN'), ('20', 'CD'), (']', 'NN')]

>> Noun Phrases are: 
 ['author [', ']']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('According', 'accord'), ('author', 'author'), ('[', '['), ('20', '20'), (']', ']')]

>> Stemming using Snowball Stemmer: 
 [('According', 'accord'), ('author', 'author'), ('[', '['), ('20', '20'), (']', ']')]

>> Lemmatization: 
 [('According', 'According'), ('author', 'author'), ('[', '['), ('20', '20'), (']', ']')]



========================================== PARAGRAPH 338 ===========================================

independence model (Naive Bayes) is based on estimating:  

------------------- Sentence 1 -------------------

independence model (Naive Bayes) is based on estimating:

>> Tokens are: 
 ['independence', 'model', '(', 'Naive', 'Bayes', ')', 'based', 'estimating', ':']

>> Bigrams are: 
 [('independence', 'model'), ('model', '('), ('(', 'Naive'), ('Naive', 'Bayes'), ('Bayes', ')'), (')', 'based'), ('based', 'estimating'), ('estimating', ':')]

>> Trigrams are: 
 [('independence', 'model', '('), ('model', '(', 'Naive'), ('(', 'Naive', 'Bayes'), ('Naive', 'Bayes', ')'), ('Bayes', ')', 'based'), (')', 'based', 'estimating'), ('based', 'estimating', ':')]

>> POS Tags are: 
 [('independence', 'NN'), ('model', 'NN'), ('(', '('), ('Naive', 'JJ'), ('Bayes', 'NNP'), (')', ')'), ('based', 'VBN'), ('estimating', 'NN'), (':', ':')]

>> Noun Phrases are: 
 ['independence model', 'Naive Bayes', 'estimating']

>> Named Entities are: 
 [('ORGANIZATION', 'Naive Bayes')] 

>> Stemming using Porter Stemmer: 
 [('independence', 'independ'), ('model', 'model'), ('(', '('), ('Naive', 'naiv'), ('Bayes', 'bay'), (')', ')'), ('based', 'base'), ('estimating', 'estim'), (':', ':')]

>> Stemming using Snowball Stemmer: 
 [('independence', 'independ'), ('model', 'model'), ('(', '('), ('Naive', 'naiv'), ('Bayes', 'bay'), (')', ')'), ('based', 'base'), ('estimating', 'estim'), (':', ':')]

>> Lemmatization: 
 [('independence', 'independence'), ('model', 'model'), ('(', '('), ('Naive', 'Naive'), ('Bayes', 'Bayes'), (')', ')'), ('based', 'based'), ('estimating', 'estimating'), (':', ':')]



========================================== PARAGRAPH 339 ===========================================

      

------------------- Sentence 1 -------------------

     

>> Tokens are: 
 ['\uf028', '\uf029', '\uf028', '\uf029']

>> Bigrams are: 
 [('\uf028', '\uf029'), ('\uf029', '\uf028'), ('\uf028', '\uf029')]

>> Trigrams are: 
 [('\uf028', '\uf029', '\uf028'), ('\uf029', '\uf028', '\uf029')]

>> POS Tags are: 
 [('\uf028', 'JJ'), ('\uf029', 'NNP'), ('\uf028', 'NNP'), ('\uf029', 'NN')]

>> Noun Phrases are: 
 ['\uf028 \uf029 \uf028 \uf029']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('\uf028', '\uf028'), ('\uf029', '\uf029'), ('\uf028', '\uf028'), ('\uf029', '\uf029')]

>> Stemming using Snowball Stemmer: 
 [('\uf028', '\uf028'), ('\uf029', '\uf029'), ('\uf028', '\uf028'), ('\uf029', '\uf029')]

>> Lemmatization: 
 [('\uf028', '\uf028'), ('\uf029', '\uf029'), ('\uf028', '\uf028'), ('\uf029', '\uf029')]



========================================== PARAGRAPH 340 ===========================================

        

------------------- Sentence 1 -------------------

       

>> Tokens are: 
 ['\uf028', '\uf029', '\uf028', '\uf029', '\uf028', '\uf029', '\uf028', '\uf029']

>> Bigrams are: 
 [('\uf028', '\uf029'), ('\uf029', '\uf028'), ('\uf028', '\uf029'), ('\uf029', '\uf028'), ('\uf028', '\uf029'), ('\uf029', '\uf028'), ('\uf028', '\uf029')]

>> Trigrams are: 
 [('\uf028', '\uf029', '\uf028'), ('\uf029', '\uf028', '\uf029'), ('\uf028', '\uf029', '\uf028'), ('\uf029', '\uf028', '\uf029'), ('\uf028', '\uf029', '\uf028'), ('\uf029', '\uf028', '\uf029')]

>> POS Tags are: 
 [('\uf028', 'JJ'), ('\uf029', 'NNP'), ('\uf028', 'NNP'), ('\uf029', 'NNP'), ('\uf028', 'NNP'), ('\uf029', 'NNP'), ('\uf028', 'NNP'), ('\uf029', 'NN')]

>> Noun Phrases are: 
 ['\uf028 \uf029 \uf028 \uf029 \uf028 \uf029 \uf028 \uf029']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('\uf028', '\uf028'), ('\uf029', '\uf029'), ('\uf028', '\uf028'), ('\uf029', '\uf029'), ('\uf028', '\uf028'), ('\uf029', '\uf029'), ('\uf028', '\uf028'), ('\uf029', '\uf029')]

>> Stemming using Snowball Stemmer: 
 [('\uf028', '\uf028'), ('\uf029', '\uf029'), ('\uf028', '\uf028'), ('\uf029', '\uf029'), ('\uf028', '\uf028'), ('\uf029', '\uf029'), ('\uf028', '\uf028'), ('\uf029', '\uf029')]

>> Lemmatization: 
 [('\uf028', '\uf028'), ('\uf029', '\uf029'), ('\uf028', '\uf028'), ('\uf029', '\uf029'), ('\uf028', '\uf028'), ('\uf029', '\uf029'), ('\uf028', '\uf028'), ('\uf029', '\uf029')]



========================================== PARAGRAPH 341 ===========================================

       JXPjP 

------------------- Sentence 1 -------------------

       JXPjP

>> Tokens are: 
 ['\uf028', '\uf029', '\uf028', '\uf029', '\uf028', '\uf029', '\uf028', '\uf029JXPjP']

>> Bigrams are: 
 [('\uf028', '\uf029'), ('\uf029', '\uf028'), ('\uf028', '\uf029'), ('\uf029', '\uf028'), ('\uf028', '\uf029'), ('\uf029', '\uf028'), ('\uf028', '\uf029JXPjP')]

>> Trigrams are: 
 [('\uf028', '\uf029', '\uf028'), ('\uf029', '\uf028', '\uf029'), ('\uf028', '\uf029', '\uf028'), ('\uf029', '\uf028', '\uf029'), ('\uf028', '\uf029', '\uf028'), ('\uf029', '\uf028', '\uf029JXPjP')]

>> POS Tags are: 
 [('\uf028', 'JJ'), ('\uf029', 'NNP'), ('\uf028', 'NNP'), ('\uf029', 'NNP'), ('\uf028', 'NNP'), ('\uf029', 'NNP'), ('\uf028', 'NNP'), ('\uf029JXPjP', 'NN')]

>> Noun Phrases are: 
 ['\uf028 \uf029 \uf028 \uf029 \uf028 \uf029 \uf028 \uf029JXPjP']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('\uf028', '\uf028'), ('\uf029', '\uf029'), ('\uf028', '\uf028'), ('\uf029', '\uf029'), ('\uf028', '\uf028'), ('\uf029', '\uf029'), ('\uf028', '\uf028'), ('\uf029JXPjP', '\uf029jxpjp')]

>> Stemming using Snowball Stemmer: 
 [('\uf028', '\uf028'), ('\uf029', '\uf029'), ('\uf028', '\uf028'), ('\uf029', '\uf029'), ('\uf028', '\uf028'), ('\uf029', '\uf029'), ('\uf028', '\uf028'), ('\uf029JXPjP', '\uf029jxpjp')]

>> Lemmatization: 
 [('\uf028', '\uf028'), ('\uf029', '\uf029'), ('\uf028', '\uf028'), ('\uf029', '\uf029'), ('\uf028', '\uf028'), ('\uf029', '\uf029'), ('\uf028', '\uf028'), ('\uf029JXPjP', '\uf029JXPjP')]



========================================== PARAGRAPH 342 ===========================================

XPPiP 

------------------- Sentence 1 -------------------

XPPiP

>> Tokens are: 
 ['XPPiP']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('XPPiP', 'NN')]

>> Noun Phrases are: 
 ['XPPiP']

>> Named Entities are: 
 [('GPE', 'XPPiP')] 

>> Stemming using Porter Stemmer: 
 [('XPPiP', 'xppip')]

>> Stemming using Snowball Stemmer: 
 [('XPPiP', 'xppip')]

>> Lemmatization: 
 [('XPPiP', 'XPPiP')]



========================================== PARAGRAPH 343 ===========================================

JXPjP 

------------------- Sentence 1 -------------------

JXPjP

>> Tokens are: 
 ['JXPjP']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('JXPjP', 'NN')]

>> Noun Phrases are: 
 ['JXPjP']

>> Named Entities are: 
 [('GPE', 'JXPjP')] 

>> Stemming using Porter Stemmer: 
 [('JXPjP', 'jxpjp')]

>> Stemming using Snowball Stemmer: 
 [('JXPjP', 'jxpjp')]

>> Lemmatization: 
 [('JXPjP', 'JXPjP')]



========================================== PARAGRAPH 344 ===========================================

XPiP 

------------------- Sentence 1 -------------------

XPiP

>> Tokens are: 
 ['XPiP']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('XPiP', 'NN')]

>> Noun Phrases are: 
 ['XPiP']

>> Named Entities are: 
 [('ORGANIZATION', 'XPiP')] 

>> Stemming using Porter Stemmer: 
 [('XPiP', 'xpip')]

>> Stemming using Snowball Stemmer: 
 [('XPiP', 'xpip')]

>> Lemmatization: 
 [('XPiP', 'XPiP')]



========================================== PARAGRAPH 345 ===========================================

XJP 

------------------- Sentence 1 -------------------

XJP

>> Tokens are: 
 ['XJP']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('XJP', 'NN')]

>> Noun Phrases are: 
 ['XJP']

>> Named Entities are: 
 [('ORGANIZATION', 'XJP')] 

>> Stemming using Porter Stemmer: 
 [('XJP', 'xjp')]

>> Stemming using Snowball Stemmer: 
 [('XJP', 'xjp')]

>> Lemmatization: 
 [('XJP', 'XJP')]



========================================== PARAGRAPH 346 ===========================================

XP R 

------------------- Sentence 1 -------------------

XP R

>> Tokens are: 
 ['XP', 'R']

>> Bigrams are: 
 [('XP', 'R')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('XP', 'NN'), ('R', 'NN')]

>> Noun Phrases are: 
 ['XP R']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('XP', 'xp'), ('R', 'r')]

>> Stemming using Snowball Stemmer: 
 [('XP', 'xp'), ('R', 'r')]

>> Lemmatization: 
 [('XP', 'XP'), ('R', 'R')]



========================================== PARAGRAPH 347 ===========================================

r 

------------------- Sentence 1 -------------------

r

>> Tokens are: 
 ['r']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('r', 'NN')]

>> Noun Phrases are: 
 ['r']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('r', 'r')]

>> Stemming using Snowball Stemmer: 
 [('r', 'r')]

>> Lemmatization: 
 [('r', 'r')]



========================================== PARAGRAPH 348 ===========================================

r | 

------------------- Sentence 1 -------------------

r |

>> Tokens are: 
 ['r', '|']

>> Bigrams are: 
 [('r', '|')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('r', 'NN'), ('|', 'NN')]

>> Noun Phrases are: 
 ['r |']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('r', 'r'), ('|', '|')]

>> Stemming using Snowball Stemmer: 
 [('r', 'r'), ('|', '|')]

>> Lemmatization: 
 [('r', 'r'), ('|', '|')]



========================================== PARAGRAPH 349 ===========================================

| 

------------------- Sentence 1 -------------------

|

>> Tokens are: 
 ['|']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('|', 'NN')]

>> Noun Phrases are: 
 ['|']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('|', '|')]

>> Stemming using Snowball Stemmer: 
 [('|', '|')]

>> Lemmatization: 
 [('|', '|')]



========================================== PARAGRAPH 350 ===========================================

| 

------------------- Sentence 1 -------------------

|

>> Tokens are: 
 ['|']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('|', 'NN')]

>> Noun Phrases are: 
 ['|']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('|', '|')]

>> Stemming using Snowball Stemmer: 
 [('|', '|')]

>> Lemmatization: 
 [('|', '|')]



========================================== PARAGRAPH 351 ===========================================

| 

------------------- Sentence 1 -------------------

|

>> Tokens are: 
 ['|']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('|', 'NN')]

>> Noun Phrases are: 
 ['|']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('|', '|')]

>> Stemming using Snowball Stemmer: 
 [('|', '|')]

>> Lemmatization: 
 [('|', '|')]



========================================== PARAGRAPH 352 ===========================================

| 

------------------- Sentence 1 -------------------

|

>> Tokens are: 
 ['|']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('|', 'NN')]

>> Noun Phrases are: 
 ['|']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('|', '|')]

>> Stemming using Snowball Stemmer: 
 [('|', '|')]

>> Lemmatization: 
 [('|', '|')]



========================================== PARAGRAPH 353 ===========================================

| 

------------------- Sentence 1 -------------------

|

>> Tokens are: 
 ['|']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('|', 'NN')]

>> Noun Phrases are: 
 ['|']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('|', '|')]

>> Stemming using Snowball Stemmer: 
 [('|', '|')]

>> Lemmatization: 
 [('|', '|')]



========================================== PARAGRAPH 354 ===========================================

 

------------------- Sentence 1 -------------------



>> Tokens are: 
 ['\uf050']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('\uf050', 'NN')]

>> Noun Phrases are: 
 ['\uf050']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('\uf050', '\uf050')]

>> Stemming using Snowball Stemmer: 
 [('\uf050', '\uf050')]

>> Lemmatization: 
 [('\uf050', '\uf050')]



========================================== PARAGRAPH 355 ===========================================

  

------------------- Sentence 1 -------------------

 

>> Tokens are: 
 ['\uf050', '\uf03d\uf03d\uf03d']

>> Bigrams are: 
 [('\uf050', '\uf03d\uf03d\uf03d')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('\uf050', 'NN'), ('\uf03d\uf03d\uf03d', 'NN')]

>> Noun Phrases are: 
 ['\uf050 \uf03d\uf03d\uf03d']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('\uf050', '\uf050'), ('\uf03d\uf03d\uf03d', '\uf03d\uf03d\uf03d')]

>> Stemming using Snowball Stemmer: 
 [('\uf050', '\uf050'), ('\uf03d\uf03d\uf03d', '\uf03d\uf03d\uf03d')]

>> Lemmatization: 
 [('\uf050', '\uf050'), ('\uf03d\uf03d\uf03d', '\uf03d\uf03d\uf03d')]



========================================== PARAGRAPH 356 ===========================================

  (3)  

------------------- Sentence 1 -------------------

  (3)

>> Tokens are: 
 ['\uf069\uf069\uf069', '(', '3', ')']

>> Bigrams are: 
 [('\uf069\uf069\uf069', '('), ('(', '3'), ('3', ')')]

>> Trigrams are: 
 [('\uf069\uf069\uf069', '(', '3'), ('(', '3', ')')]

>> POS Tags are: 
 [('\uf069\uf069\uf069', 'NN'), ('(', '('), ('3', 'CD'), (')', ')')]

>> Noun Phrases are: 
 ['\uf069\uf069\uf069']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('\uf069\uf069\uf069', '\uf069\uf069\uf069'), ('(', '('), ('3', '3'), (')', ')')]

>> Stemming using Snowball Stemmer: 
 [('\uf069\uf069\uf069', '\uf069\uf069\uf069'), ('(', '('), ('3', '3'), (')', ')')]

>> Lemmatization: 
 [('\uf069\uf069\uf069', '\uf069\uf069\uf069'), ('(', '('), ('3', '3'), (')', ')')]



========================================== PARAGRAPH 357 ===========================================

Here comparing these two probabilities, the larger  

------------------- Sentence 1 -------------------

Here comparing these two probabilities, the larger

>> Tokens are: 
 ['Here', 'comparing', 'two', 'probabilities', ',', 'larger']

>> Bigrams are: 
 [('Here', 'comparing'), ('comparing', 'two'), ('two', 'probabilities'), ('probabilities', ','), (',', 'larger')]

>> Trigrams are: 
 [('Here', 'comparing', 'two'), ('comparing', 'two', 'probabilities'), ('two', 'probabilities', ','), ('probabilities', ',', 'larger')]

>> POS Tags are: 
 [('Here', 'RB'), ('comparing', 'VBG'), ('two', 'CD'), ('probabilities', 'NNS'), (',', ','), ('larger', 'JJR')]

>> Noun Phrases are: 
 ['probabilities']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Here', 'here'), ('comparing', 'compar'), ('two', 'two'), ('probabilities', 'probabl'), (',', ','), ('larger', 'larger')]

>> Stemming using Snowball Stemmer: 
 [('Here', 'here'), ('comparing', 'compar'), ('two', 'two'), ('probabilities', 'probabl'), (',', ','), ('larger', 'larger')]

>> Lemmatization: 
 [('Here', 'Here'), ('comparing', 'comparing'), ('two', 'two'), ('probabilities', 'probability'), (',', ','), ('larger', 'larger')]



========================================== PARAGRAPH 358 ===========================================

probability indicates that the class label value that is more likely  

------------------- Sentence 1 -------------------

probability indicates that the class label value that is more likely

>> Tokens are: 
 ['probability', 'indicates', 'class', 'label', 'value', 'likely']

>> Bigrams are: 
 [('probability', 'indicates'), ('indicates', 'class'), ('class', 'label'), ('label', 'value'), ('value', 'likely')]

>> Trigrams are: 
 [('probability', 'indicates', 'class'), ('indicates', 'class', 'label'), ('class', 'label', 'value'), ('label', 'value', 'likely')]

>> POS Tags are: 
 [('probability', 'NN'), ('indicates', 'VBZ'), ('class', 'NN'), ('label', 'NN'), ('value', 'NN'), ('likely', 'RB')]

>> Noun Phrases are: 
 ['probability', 'class label value']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('probability', 'probabl'), ('indicates', 'indic'), ('class', 'class'), ('label', 'label'), ('value', 'valu'), ('likely', 'like')]

>> Stemming using Snowball Stemmer: 
 [('probability', 'probabl'), ('indicates', 'indic'), ('class', 'class'), ('label', 'label'), ('value', 'valu'), ('likely', 'like')]

>> Lemmatization: 
 [('probability', 'probability'), ('indicates', 'indicates'), ('class', 'class'), ('label', 'label'), ('value', 'value'), ('likely', 'likely')]



========================================== PARAGRAPH 359 ===========================================

to be the actual label (if R>1: predict i else predict j) [1]. As  

------------------- Sentence 1 -------------------

to be the actual label (if R>1: predict i else predict j) [1].

>> Tokens are: 
 ['actual', 'label', '(', 'R', '>', '1', ':', 'predict', 'else', 'predict', 'j', ')', '[', '1', ']', '.']

>> Bigrams are: 
 [('actual', 'label'), ('label', '('), ('(', 'R'), ('R', '>'), ('>', '1'), ('1', ':'), (':', 'predict'), ('predict', 'else'), ('else', 'predict'), ('predict', 'j'), ('j', ')'), (')', '['), ('[', '1'), ('1', ']'), (']', '.')]

>> Trigrams are: 
 [('actual', 'label', '('), ('label', '(', 'R'), ('(', 'R', '>'), ('R', '>', '1'), ('>', '1', ':'), ('1', ':', 'predict'), (':', 'predict', 'else'), ('predict', 'else', 'predict'), ('else', 'predict', 'j'), ('predict', 'j', ')'), ('j', ')', '['), (')', '[', '1'), ('[', '1', ']'), ('1', ']', '.')]

>> POS Tags are: 
 [('actual', 'JJ'), ('label', 'NN'), ('(', '('), ('R', 'NNP'), ('>', 'VBZ'), ('1', 'CD'), (':', ':'), ('predict', 'NN'), ('else', 'RB'), ('predict', 'VBP'), ('j', 'NN'), (')', ')'), ('[', 'VBZ'), ('1', 'CD'), (']', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['actual label', 'R', 'predict', 'j', ']']

>> Named Entities are: 
 [('ORGANIZATION', 'R')] 

>> Stemming using Porter Stemmer: 
 [('actual', 'actual'), ('label', 'label'), ('(', '('), ('R', 'r'), ('>', '>'), ('1', '1'), (':', ':'), ('predict', 'predict'), ('else', 'els'), ('predict', 'predict'), ('j', 'j'), (')', ')'), ('[', '['), ('1', '1'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('actual', 'actual'), ('label', 'label'), ('(', '('), ('R', 'r'), ('>', '>'), ('1', '1'), (':', ':'), ('predict', 'predict'), ('else', 'els'), ('predict', 'predict'), ('j', 'j'), (')', ')'), ('[', '['), ('1', '1'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('actual', 'actual'), ('label', 'label'), ('(', '('), ('R', 'R'), ('>', '>'), ('1', '1'), (':', ':'), ('predict', 'predict'), ('else', 'else'), ('predict', 'predict'), ('j', 'j'), (')', ')'), ('[', '['), ('1', '1'), (']', ']'), ('.', '.')]


------------------- Sentence 2 -------------------

As

>> Tokens are: 
 ['As']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('As', 'IN')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('As', 'as')]

>> Stemming using Snowball Stemmer: 
 [('As', 'as')]

>> Lemmatization: 
 [('As', 'As')]



========================================== PARAGRAPH 360 ===========================================

shown in the below figure, the links in a Naive Bayes model are  

------------------- Sentence 1 -------------------

shown in the below figure, the links in a Naive Bayes model are

>> Tokens are: 
 ['shown', 'figure', ',', 'links', 'Naive', 'Bayes', 'model']

>> Bigrams are: 
 [('shown', 'figure'), ('figure', ','), (',', 'links'), ('links', 'Naive'), ('Naive', 'Bayes'), ('Bayes', 'model')]

>> Trigrams are: 
 [('shown', 'figure', ','), ('figure', ',', 'links'), (',', 'links', 'Naive'), ('links', 'Naive', 'Bayes'), ('Naive', 'Bayes', 'model')]

>> POS Tags are: 
 [('shown', 'VBN'), ('figure', 'NN'), (',', ','), ('links', 'VBZ'), ('Naive', 'NNP'), ('Bayes', 'NNP'), ('model', 'NN')]

>> Noun Phrases are: 
 ['figure', 'Naive Bayes model']

>> Named Entities are: 
 [('PERSON', 'Naive Bayes')] 

>> Stemming using Porter Stemmer: 
 [('shown', 'shown'), ('figure', 'figur'), (',', ','), ('links', 'link'), ('Naive', 'naiv'), ('Bayes', 'bay'), ('model', 'model')]

>> Stemming using Snowball Stemmer: 
 [('shown', 'shown'), ('figure', 'figur'), (',', ','), ('links', 'link'), ('Naive', 'naiv'), ('Bayes', 'bay'), ('model', 'model')]

>> Lemmatization: 
 [('shown', 'shown'), ('figure', 'figure'), (',', ','), ('links', 'link'), ('Naive', 'Naive'), ('Bayes', 'Bayes'), ('model', 'model')]



========================================== PARAGRAPH 361 ===========================================

directed from output to input, which gives the model its  

------------------- Sentence 1 -------------------

directed from output to input, which gives the model its

>> Tokens are: 
 ['directed', 'output', 'input', ',', 'gives', 'model']

>> Bigrams are: 
 [('directed', 'output'), ('output', 'input'), ('input', ','), (',', 'gives'), ('gives', 'model')]

>> Trigrams are: 
 [('directed', 'output', 'input'), ('output', 'input', ','), ('input', ',', 'gives'), (',', 'gives', 'model')]

>> POS Tags are: 
 [('directed', 'VBN'), ('output', 'NN'), ('input', 'NN'), (',', ','), ('gives', 'VBZ'), ('model', 'NN')]

>> Noun Phrases are: 
 ['output input', 'model']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('directed', 'direct'), ('output', 'output'), ('input', 'input'), (',', ','), ('gives', 'give'), ('model', 'model')]

>> Stemming using Snowball Stemmer: 
 [('directed', 'direct'), ('output', 'output'), ('input', 'input'), (',', ','), ('gives', 'give'), ('model', 'model')]

>> Lemmatization: 
 [('directed', 'directed'), ('output', 'output'), ('input', 'input'), (',', ','), ('gives', 'give'), ('model', 'model')]



========================================== PARAGRAPH 362 ===========================================

simplicity, as there are no interactions between the inputs, except  

------------------- Sentence 1 -------------------

simplicity, as there are no interactions between the inputs, except

>> Tokens are: 
 ['simplicity', ',', 'interactions', 'inputs', ',', 'except']

>> Bigrams are: 
 [('simplicity', ','), (',', 'interactions'), ('interactions', 'inputs'), ('inputs', ','), (',', 'except')]

>> Trigrams are: 
 [('simplicity', ',', 'interactions'), (',', 'interactions', 'inputs'), ('interactions', 'inputs', ','), ('inputs', ',', 'except')]

>> POS Tags are: 
 [('simplicity', 'NN'), (',', ','), ('interactions', 'NNS'), ('inputs', 'NNS'), (',', ','), ('except', 'IN')]

>> Noun Phrases are: 
 ['simplicity', 'interactions inputs']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('simplicity', 'simplic'), (',', ','), ('interactions', 'interact'), ('inputs', 'input'), (',', ','), ('except', 'except')]

>> Stemming using Snowball Stemmer: 
 [('simplicity', 'simplic'), (',', ','), ('interactions', 'interact'), ('inputs', 'input'), (',', ','), ('except', 'except')]

>> Lemmatization: 
 [('simplicity', 'simplicity'), (',', ','), ('interactions', 'interaction'), ('inputs', 'input'), (',', ','), ('except', 'except')]



========================================== PARAGRAPH 363 ===========================================

indirectly via the output.  

------------------- Sentence 1 -------------------

indirectly via the output.

>> Tokens are: 
 ['indirectly', 'via', 'output', '.']

>> Bigrams are: 
 [('indirectly', 'via'), ('via', 'output'), ('output', '.')]

>> Trigrams are: 
 [('indirectly', 'via', 'output'), ('via', 'output', '.')]

>> POS Tags are: 
 [('indirectly', 'RB'), ('via', 'IN'), ('output', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['output']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('indirectly', 'indirectli'), ('via', 'via'), ('output', 'output'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('indirectly', 'indirect'), ('via', 'via'), ('output', 'output'), ('.', '.')]

>> Lemmatization: 
 [('indirectly', 'indirectly'), ('via', 'via'), ('output', 'output'), ('.', '.')]



========================================== PARAGRAPH 364 ===========================================

  


========================================== PARAGRAPH 365 ===========================================

Fig.6. Naive Bayes model  

------------------- Sentence 1 -------------------

Fig.6.

>> Tokens are: 
 ['Fig.6', '.']

>> Bigrams are: 
 [('Fig.6', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Fig.6', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Fig.6']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Fig.6', 'fig.6'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Fig.6', 'fig.6'), ('.', '.')]

>> Lemmatization: 
 [('Fig.6', 'Fig.6'), ('.', '.')]


------------------- Sentence 2 -------------------

Naive Bayes model

>> Tokens are: 
 ['Naive', 'Bayes', 'model']

>> Bigrams are: 
 [('Naive', 'Bayes'), ('Bayes', 'model')]

>> Trigrams are: 
 [('Naive', 'Bayes', 'model')]

>> POS Tags are: 
 [('Naive', 'JJ'), ('Bayes', 'NNP'), ('model', 'NN')]

>> Noun Phrases are: 
 ['Naive Bayes model']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Naive', 'naiv'), ('Bayes', 'bay'), ('model', 'model')]

>> Stemming using Snowball Stemmer: 
 [('Naive', 'naiv'), ('Bayes', 'bay'), ('model', 'model')]

>> Lemmatization: 
 [('Naive', 'Naive'), ('Bayes', 'Bayes'), ('model', 'model')]



========================================== PARAGRAPH 366 ===========================================

An advantage of the Naive Bayes classifier is that it requires  

------------------- Sentence 1 -------------------

An advantage of the Naive Bayes classifier is that it requires

>> Tokens are: 
 ['An', 'advantage', 'Naive', 'Bayes', 'classifier', 'requires']

>> Bigrams are: 
 [('An', 'advantage'), ('advantage', 'Naive'), ('Naive', 'Bayes'), ('Bayes', 'classifier'), ('classifier', 'requires')]

>> Trigrams are: 
 [('An', 'advantage', 'Naive'), ('advantage', 'Naive', 'Bayes'), ('Naive', 'Bayes', 'classifier'), ('Bayes', 'classifier', 'requires')]

>> POS Tags are: 
 [('An', 'DT'), ('advantage', 'NN'), ('Naive', 'JJ'), ('Bayes', 'NNP'), ('classifier', 'NN'), ('requires', 'VBZ')]

>> Noun Phrases are: 
 ['An advantage', 'Naive Bayes classifier']

>> Named Entities are: 
 [('PERSON', 'Naive Bayes')] 

>> Stemming using Porter Stemmer: 
 [('An', 'an'), ('advantage', 'advantag'), ('Naive', 'naiv'), ('Bayes', 'bay'), ('classifier', 'classifi'), ('requires', 'requir')]

>> Stemming using Snowball Stemmer: 
 [('An', 'an'), ('advantage', 'advantag'), ('Naive', 'naiv'), ('Bayes', 'bay'), ('classifier', 'classifi'), ('requires', 'requir')]

>> Lemmatization: 
 [('An', 'An'), ('advantage', 'advantage'), ('Naive', 'Naive'), ('Bayes', 'Bayes'), ('classifier', 'classifier'), ('requires', 'requires')]



========================================== PARAGRAPH 367 ===========================================

a small amount of training data to estimate the parameters  

------------------- Sentence 1 -------------------

a small amount of training data to estimate the parameters

>> Tokens are: 
 ['small', 'amount', 'training', 'data', 'estimate', 'parameters']

>> Bigrams are: 
 [('small', 'amount'), ('amount', 'training'), ('training', 'data'), ('data', 'estimate'), ('estimate', 'parameters')]

>> Trigrams are: 
 [('small', 'amount', 'training'), ('amount', 'training', 'data'), ('training', 'data', 'estimate'), ('data', 'estimate', 'parameters')]

>> POS Tags are: 
 [('small', 'JJ'), ('amount', 'NN'), ('training', 'NN'), ('data', 'NNS'), ('estimate', 'NN'), ('parameters', 'NNS')]

>> Noun Phrases are: 
 ['small amount training data estimate parameters']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('small', 'small'), ('amount', 'amount'), ('training', 'train'), ('data', 'data'), ('estimate', 'estim'), ('parameters', 'paramet')]

>> Stemming using Snowball Stemmer: 
 [('small', 'small'), ('amount', 'amount'), ('training', 'train'), ('data', 'data'), ('estimate', 'estim'), ('parameters', 'paramet')]

>> Lemmatization: 
 [('small', 'small'), ('amount', 'amount'), ('training', 'training'), ('data', 'data'), ('estimate', 'estimate'), ('parameters', 'parameter')]



========================================== PARAGRAPH 368 ===========================================

necessary for classification.  

------------------- Sentence 1 -------------------

necessary for classification.

>> Tokens are: 
 ['necessary', 'classification', '.']

>> Bigrams are: 
 [('necessary', 'classification'), ('classification', '.')]

>> Trigrams are: 
 [('necessary', 'classification', '.')]

>> POS Tags are: 
 [('necessary', 'JJ'), ('classification', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['necessary classification']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('necessary', 'necessari'), ('classification', 'classif'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('necessary', 'necessari'), ('classification', 'classif'), ('.', '.')]

>> Lemmatization: 
 [('necessary', 'necessary'), ('classification', 'classification'), ('.', '.')]



========================================== PARAGRAPH 369 ===========================================

4.2 BAYESIAN NETWORKS  

------------------- Sentence 1 -------------------

4.2 BAYESIAN NETWORKS

>> Tokens are: 
 ['4.2', 'BAYESIAN', 'NETWORKS']

>> Bigrams are: 
 [('4.2', 'BAYESIAN'), ('BAYESIAN', 'NETWORKS')]

>> Trigrams are: 
 [('4.2', 'BAYESIAN', 'NETWORKS')]

>> POS Tags are: 
 [('4.2', 'CD'), ('BAYESIAN', 'NNP'), ('NETWORKS', 'NNP')]

>> Noun Phrases are: 
 ['BAYESIAN NETWORKS']

>> Named Entities are: 
 [('ORGANIZATION', 'BAYESIAN'), ('ORGANIZATION', 'NETWORKS')] 

>> Stemming using Porter Stemmer: 
 [('4.2', '4.2'), ('BAYESIAN', 'bayesian'), ('NETWORKS', 'network')]

>> Stemming using Snowball Stemmer: 
 [('4.2', '4.2'), ('BAYESIAN', 'bayesian'), ('NETWORKS', 'network')]

>> Lemmatization: 
 [('4.2', '4.2'), ('BAYESIAN', 'BAYESIAN'), ('NETWORKS', 'NETWORKS')]



========================================== PARAGRAPH 370 ===========================================

Bayesian Networks (BN) are graphical models that are used  

------------------- Sentence 1 -------------------

Bayesian Networks (BN) are graphical models that are used

>> Tokens are: 
 ['Bayesian', 'Networks', '(', 'BN', ')', 'graphical', 'models', 'used']

>> Bigrams are: 
 [('Bayesian', 'Networks'), ('Networks', '('), ('(', 'BN'), ('BN', ')'), (')', 'graphical'), ('graphical', 'models'), ('models', 'used')]

>> Trigrams are: 
 [('Bayesian', 'Networks', '('), ('Networks', '(', 'BN'), ('(', 'BN', ')'), ('BN', ')', 'graphical'), (')', 'graphical', 'models'), ('graphical', 'models', 'used')]

>> POS Tags are: 
 [('Bayesian', 'JJ'), ('Networks', 'NNP'), ('(', '('), ('BN', 'NNP'), (')', ')'), ('graphical', 'JJ'), ('models', 'NNS'), ('used', 'VBN')]

>> Noun Phrases are: 
 ['Bayesian Networks', 'BN', 'graphical models']

>> Named Entities are: 
 [('GPE', 'Bayesian'), ('PERSON', 'Networks')] 

>> Stemming using Porter Stemmer: 
 [('Bayesian', 'bayesian'), ('Networks', 'network'), ('(', '('), ('BN', 'bn'), (')', ')'), ('graphical', 'graphic'), ('models', 'model'), ('used', 'use')]

>> Stemming using Snowball Stemmer: 
 [('Bayesian', 'bayesian'), ('Networks', 'network'), ('(', '('), ('BN', 'bn'), (')', ')'), ('graphical', 'graphic'), ('models', 'model'), ('used', 'use')]

>> Lemmatization: 
 [('Bayesian', 'Bayesian'), ('Networks', 'Networks'), ('(', '('), ('BN', 'BN'), (')', ')'), ('graphical', 'graphical'), ('models', 'model'), ('used', 'used')]



========================================== PARAGRAPH 371 ===========================================

to illustrate relationships between events or ideas to infer  

------------------- Sentence 1 -------------------

to illustrate relationships between events or ideas to infer

>> Tokens are: 
 ['illustrate', 'relationships', 'events', 'ideas', 'infer']

>> Bigrams are: 
 [('illustrate', 'relationships'), ('relationships', 'events'), ('events', 'ideas'), ('ideas', 'infer')]

>> Trigrams are: 
 [('illustrate', 'relationships', 'events'), ('relationships', 'events', 'ideas'), ('events', 'ideas', 'infer')]

>> POS Tags are: 
 [('illustrate', 'JJ'), ('relationships', 'NNS'), ('events', 'NNS'), ('ideas', 'NNS'), ('infer', 'VBP')]

>> Noun Phrases are: 
 ['illustrate relationships events ideas']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('illustrate', 'illustr'), ('relationships', 'relationship'), ('events', 'event'), ('ideas', 'idea'), ('infer', 'infer')]

>> Stemming using Snowball Stemmer: 
 [('illustrate', 'illustr'), ('relationships', 'relationship'), ('events', 'event'), ('ideas', 'idea'), ('infer', 'infer')]

>> Lemmatization: 
 [('illustrate', 'illustrate'), ('relationships', 'relationship'), ('events', 'event'), ('ideas', 'idea'), ('infer', 'infer')]



========================================== PARAGRAPH 372 ===========================================

probabilities or uncertainties associated with those ideas or  

------------------- Sentence 1 -------------------

probabilities or uncertainties associated with those ideas or

>> Tokens are: 
 ['probabilities', 'uncertainties', 'associated', 'ideas']

>> Bigrams are: 
 [('probabilities', 'uncertainties'), ('uncertainties', 'associated'), ('associated', 'ideas')]

>> Trigrams are: 
 [('probabilities', 'uncertainties', 'associated'), ('uncertainties', 'associated', 'ideas')]

>> POS Tags are: 
 [('probabilities', 'NNS'), ('uncertainties', 'NNS'), ('associated', 'VBN'), ('ideas', 'NNS')]

>> Noun Phrases are: 
 ['probabilities uncertainties', 'ideas']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('probabilities', 'probabl'), ('uncertainties', 'uncertainti'), ('associated', 'associ'), ('ideas', 'idea')]

>> Stemming using Snowball Stemmer: 
 [('probabilities', 'probabl'), ('uncertainties', 'uncertainti'), ('associated', 'associ'), ('ideas', 'idea')]

>> Lemmatization: 
 [('probabilities', 'probability'), ('uncertainties', 'uncertainty'), ('associated', 'associated'), ('ideas', 'idea')]



========================================== PARAGRAPH 373 ===========================================

events. Information retrieval, predictions based on limited input  

------------------- Sentence 1 -------------------

events.

>> Tokens are: 
 ['events', '.']

>> Bigrams are: 
 [('events', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('events', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['events']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('events', 'event'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('events', 'event'), ('.', '.')]

>> Lemmatization: 
 [('events', 'event'), ('.', '.')]


------------------- Sentence 2 -------------------

Information retrieval, predictions based on limited input

>> Tokens are: 
 ['Information', 'retrieval', ',', 'predictions', 'based', 'limited', 'input']

>> Bigrams are: 
 [('Information', 'retrieval'), ('retrieval', ','), (',', 'predictions'), ('predictions', 'based'), ('based', 'limited'), ('limited', 'input')]

>> Trigrams are: 
 [('Information', 'retrieval', ','), ('retrieval', ',', 'predictions'), (',', 'predictions', 'based'), ('predictions', 'based', 'limited'), ('based', 'limited', 'input')]

>> POS Tags are: 
 [('Information', 'NN'), ('retrieval', 'NN'), (',', ','), ('predictions', 'NNS'), ('based', 'VBN'), ('limited', 'JJ'), ('input', 'NN')]

>> Noun Phrases are: 
 ['Information retrieval', 'predictions', 'limited input']

>> Named Entities are: 
 [('GPE', 'Information')] 

>> Stemming using Porter Stemmer: 
 [('Information', 'inform'), ('retrieval', 'retriev'), (',', ','), ('predictions', 'predict'), ('based', 'base'), ('limited', 'limit'), ('input', 'input')]

>> Stemming using Snowball Stemmer: 
 [('Information', 'inform'), ('retrieval', 'retriev'), (',', ','), ('predictions', 'predict'), ('based', 'base'), ('limited', 'limit'), ('input', 'input')]

>> Lemmatization: 
 [('Information', 'Information'), ('retrieval', 'retrieval'), (',', ','), ('predictions', 'prediction'), ('based', 'based'), ('limited', 'limited'), ('input', 'input')]



========================================== PARAGRAPH 374 ===========================================

or recognition software is some main applications of BN.  

------------------- Sentence 1 -------------------

or recognition software is some main applications of BN.

>> Tokens are: 
 ['recognition', 'software', 'main', 'applications', 'BN', '.']

>> Bigrams are: 
 [('recognition', 'software'), ('software', 'main'), ('main', 'applications'), ('applications', 'BN'), ('BN', '.')]

>> Trigrams are: 
 [('recognition', 'software', 'main'), ('software', 'main', 'applications'), ('main', 'applications', 'BN'), ('applications', 'BN', '.')]

>> POS Tags are: 
 [('recognition', 'NN'), ('software', 'NN'), ('main', 'JJ'), ('applications', 'NNS'), ('BN', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['recognition software', 'main applications BN']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('recognition', 'recognit'), ('software', 'softwar'), ('main', 'main'), ('applications', 'applic'), ('BN', 'bn'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('recognition', 'recognit'), ('software', 'softwar'), ('main', 'main'), ('applications', 'applic'), ('BN', 'bn'), ('.', '.')]

>> Lemmatization: 
 [('recognition', 'recognition'), ('software', 'software'), ('main', 'main'), ('applications', 'application'), ('BN', 'BN'), ('.', '.')]



========================================== PARAGRAPH 375 ===========================================

The Bayesian network structure S is a directed acyclic graph  

------------------- Sentence 1 -------------------

The Bayesian network structure S is a directed acyclic graph

>> Tokens are: 
 ['The', 'Bayesian', 'network', 'structure', 'S', 'directed', 'acyclic', 'graph']

>> Bigrams are: 
 [('The', 'Bayesian'), ('Bayesian', 'network'), ('network', 'structure'), ('structure', 'S'), ('S', 'directed'), ('directed', 'acyclic'), ('acyclic', 'graph')]

>> Trigrams are: 
 [('The', 'Bayesian', 'network'), ('Bayesian', 'network', 'structure'), ('network', 'structure', 'S'), ('structure', 'S', 'directed'), ('S', 'directed', 'acyclic'), ('directed', 'acyclic', 'graph')]

>> POS Tags are: 
 [('The', 'DT'), ('Bayesian', 'JJ'), ('network', 'NN'), ('structure', 'NN'), ('S', 'NNP'), ('directed', 'VBD'), ('acyclic', 'JJ'), ('graph', 'NN')]

>> Noun Phrases are: 
 ['The Bayesian network structure S', 'acyclic graph']

>> Named Entities are: 
 [('GPE', 'Bayesian')] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('Bayesian', 'bayesian'), ('network', 'network'), ('structure', 'structur'), ('S', 's'), ('directed', 'direct'), ('acyclic', 'acycl'), ('graph', 'graph')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('Bayesian', 'bayesian'), ('network', 'network'), ('structure', 'structur'), ('S', 's'), ('directed', 'direct'), ('acyclic', 'acycl'), ('graph', 'graph')]

>> Lemmatization: 
 [('The', 'The'), ('Bayesian', 'Bayesian'), ('network', 'network'), ('structure', 'structure'), ('S', 'S'), ('directed', 'directed'), ('acyclic', 'acyclic'), ('graph', 'graph')]



========================================== PARAGRAPH 376 ===========================================

(DAG) and the nodes in S are in one-to-one correspondence with  

------------------- Sentence 1 -------------------

(DAG) and the nodes in S are in one-to-one correspondence with

>> Tokens are: 
 ['(', 'DAG', ')', 'nodes', 'S', 'one-to-one', 'correspondence']

>> Bigrams are: 
 [('(', 'DAG'), ('DAG', ')'), (')', 'nodes'), ('nodes', 'S'), ('S', 'one-to-one'), ('one-to-one', 'correspondence')]

>> Trigrams are: 
 [('(', 'DAG', ')'), ('DAG', ')', 'nodes'), (')', 'nodes', 'S'), ('nodes', 'S', 'one-to-one'), ('S', 'one-to-one', 'correspondence')]

>> POS Tags are: 
 [('(', '('), ('DAG', 'NNP'), (')', ')'), ('nodes', 'VBZ'), ('S', 'JJ'), ('one-to-one', 'JJ'), ('correspondence', 'NN')]

>> Noun Phrases are: 
 ['DAG', 'S one-to-one correspondence']

>> Named Entities are: 
 [('ORGANIZATION', 'DAG')] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('DAG', 'dag'), (')', ')'), ('nodes', 'node'), ('S', 's'), ('one-to-one', 'one-to-on'), ('correspondence', 'correspond')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('DAG', 'dag'), (')', ')'), ('nodes', 'node'), ('S', 's'), ('one-to-one', 'one-to-on'), ('correspondence', 'correspond')]

>> Lemmatization: 
 [('(', '('), ('DAG', 'DAG'), (')', ')'), ('nodes', 'node'), ('S', 'S'), ('one-to-one', 'one-to-one'), ('correspondence', 'correspondence')]



========================================== PARAGRAPH 377 ===========================================

the features X. The arcs represent casual influences among the  

------------------- Sentence 1 -------------------

the features X.

>> Tokens are: 
 ['features', 'X', '.']

>> Bigrams are: 
 [('features', 'X'), ('X', '.')]

>> Trigrams are: 
 [('features', 'X', '.')]

>> POS Tags are: 
 [('features', 'NNS'), ('X', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['features X']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('features', 'featur'), ('X', 'x'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('features', 'featur'), ('X', 'x'), ('.', '.')]

>> Lemmatization: 
 [('features', 'feature'), ('X', 'X'), ('.', '.')]


------------------- Sentence 2 -------------------

The arcs represent casual influences among the

>> Tokens are: 
 ['The', 'arcs', 'represent', 'casual', 'influences', 'among']

>> Bigrams are: 
 [('The', 'arcs'), ('arcs', 'represent'), ('represent', 'casual'), ('casual', 'influences'), ('influences', 'among')]

>> Trigrams are: 
 [('The', 'arcs', 'represent'), ('arcs', 'represent', 'casual'), ('represent', 'casual', 'influences'), ('casual', 'influences', 'among')]

>> POS Tags are: 
 [('The', 'DT'), ('arcs', 'JJ'), ('represent', 'NN'), ('casual', 'JJ'), ('influences', 'NNS'), ('among', 'IN')]

>> Noun Phrases are: 
 ['The arcs represent', 'casual influences']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('arcs', 'arc'), ('represent', 'repres'), ('casual', 'casual'), ('influences', 'influenc'), ('among', 'among')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('arcs', 'arc'), ('represent', 'repres'), ('casual', 'casual'), ('influences', 'influenc'), ('among', 'among')]

>> Lemmatization: 
 [('The', 'The'), ('arcs', 'arc'), ('represent', 'represent'), ('casual', 'casual'), ('influences', 'influence'), ('among', 'among')]



========================================== PARAGRAPH 378 ===========================================

features while the lack of possible arcs in S encodes conditional  

------------------- Sentence 1 -------------------

features while the lack of possible arcs in S encodes conditional

>> Tokens are: 
 ['features', 'lack', 'possible', 'arcs', 'S', 'encodes', 'conditional']

>> Bigrams are: 
 [('features', 'lack'), ('lack', 'possible'), ('possible', 'arcs'), ('arcs', 'S'), ('S', 'encodes'), ('encodes', 'conditional')]

>> Trigrams are: 
 [('features', 'lack', 'possible'), ('lack', 'possible', 'arcs'), ('possible', 'arcs', 'S'), ('arcs', 'S', 'encodes'), ('S', 'encodes', 'conditional')]

>> POS Tags are: 
 [('features', 'NNS'), ('lack', 'VBP'), ('possible', 'JJ'), ('arcs', 'NN'), ('S', 'NNP'), ('encodes', 'VBZ'), ('conditional', 'JJ')]

>> Noun Phrases are: 
 ['features', 'possible arcs S']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('features', 'featur'), ('lack', 'lack'), ('possible', 'possibl'), ('arcs', 'arc'), ('S', 's'), ('encodes', 'encod'), ('conditional', 'condit')]

>> Stemming using Snowball Stemmer: 
 [('features', 'featur'), ('lack', 'lack'), ('possible', 'possibl'), ('arcs', 'arc'), ('S', 's'), ('encodes', 'encod'), ('conditional', 'condit')]

>> Lemmatization: 
 [('features', 'feature'), ('lack', 'lack'), ('possible', 'possible'), ('arcs', 'arc'), ('S', 'S'), ('encodes', 'encodes'), ('conditional', 'conditional')]



========================================== PARAGRAPH 379 ===========================================

independencies. Moreover, a feature (node) is conditionally  

------------------- Sentence 1 -------------------

independencies.

>> Tokens are: 
 ['independencies', '.']

>> Bigrams are: 
 [('independencies', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('independencies', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['independencies']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('independencies', 'independ'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('independencies', 'independ'), ('.', '.')]

>> Lemmatization: 
 [('independencies', 'independency'), ('.', '.')]


------------------- Sentence 2 -------------------

Moreover, a feature (node) is conditionally

>> Tokens are: 
 ['Moreover', ',', 'feature', '(', 'node', ')', 'conditionally']

>> Bigrams are: 
 [('Moreover', ','), (',', 'feature'), ('feature', '('), ('(', 'node'), ('node', ')'), (')', 'conditionally')]

>> Trigrams are: 
 [('Moreover', ',', 'feature'), (',', 'feature', '('), ('feature', '(', 'node'), ('(', 'node', ')'), ('node', ')', 'conditionally')]

>> POS Tags are: 
 [('Moreover', 'RB'), (',', ','), ('feature', 'NN'), ('(', '('), ('node', 'NN'), (')', ')'), ('conditionally', 'RB')]

>> Noun Phrases are: 
 ['feature', 'node']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Moreover', 'moreov'), (',', ','), ('feature', 'featur'), ('(', '('), ('node', 'node'), (')', ')'), ('conditionally', 'condit')]

>> Stemming using Snowball Stemmer: 
 [('Moreover', 'moreov'), (',', ','), ('feature', 'featur'), ('(', '('), ('node', 'node'), (')', ')'), ('conditionally', 'condit')]

>> Lemmatization: 
 [('Moreover', 'Moreover'), (',', ','), ('feature', 'feature'), ('(', '('), ('node', 'node'), (')', ')'), ('conditionally', 'conditionally')]



========================================== PARAGRAPH 380 ===========================================

independent from its non-descendants given its parents (X1 is  

------------------- Sentence 1 -------------------

independent from its non-descendants given its parents (X1 is

>> Tokens are: 
 ['independent', 'non-descendants', 'given', 'parents', '(', 'X1']

>> Bigrams are: 
 [('independent', 'non-descendants'), ('non-descendants', 'given'), ('given', 'parents'), ('parents', '('), ('(', 'X1')]

>> Trigrams are: 
 [('independent', 'non-descendants', 'given'), ('non-descendants', 'given', 'parents'), ('given', 'parents', '('), ('parents', '(', 'X1')]

>> POS Tags are: 
 [('independent', 'JJ'), ('non-descendants', 'NNS'), ('given', 'VBN'), ('parents', 'NNS'), ('(', '('), ('X1', 'NN')]

>> Noun Phrases are: 
 ['independent non-descendants', 'parents', 'X1']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('independent', 'independ'), ('non-descendants', 'non-descend'), ('given', 'given'), ('parents', 'parent'), ('(', '('), ('X1', 'x1')]

>> Stemming using Snowball Stemmer: 
 [('independent', 'independ'), ('non-descendants', 'non-descend'), ('given', 'given'), ('parents', 'parent'), ('(', '('), ('X1', 'x1')]

>> Lemmatization: 
 [('independent', 'independent'), ('non-descendants', 'non-descendants'), ('given', 'given'), ('parents', 'parent'), ('(', '('), ('X1', 'X1')]



========================================== PARAGRAPH 381 ===========================================

conditionally independent from X2).   

------------------- Sentence 1 -------------------

conditionally independent from X2).

>> Tokens are: 
 ['conditionally', 'independent', 'X2', ')', '.']

>> Bigrams are: 
 [('conditionally', 'independent'), ('independent', 'X2'), ('X2', ')'), (')', '.')]

>> Trigrams are: 
 [('conditionally', 'independent', 'X2'), ('independent', 'X2', ')'), ('X2', ')', '.')]

>> POS Tags are: 
 [('conditionally', 'RB'), ('independent', 'JJ'), ('X2', 'NN'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['independent X2']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('conditionally', 'condit'), ('independent', 'independ'), ('X2', 'x2'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('conditionally', 'condit'), ('independent', 'independ'), ('X2', 'x2'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('conditionally', 'conditionally'), ('independent', 'independent'), ('X2', 'X2'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 382 ===========================================

The below example shows that there are two events which  

------------------- Sentence 1 -------------------

The below example shows that there are two events which

>> Tokens are: 
 ['The', 'example', 'shows', 'two', 'events']

>> Bigrams are: 
 [('The', 'example'), ('example', 'shows'), ('shows', 'two'), ('two', 'events')]

>> Trigrams are: 
 [('The', 'example', 'shows'), ('example', 'shows', 'two'), ('shows', 'two', 'events')]

>> POS Tags are: 
 [('The', 'DT'), ('example', 'NN'), ('shows', 'VBZ'), ('two', 'CD'), ('events', 'NNS')]

>> Noun Phrases are: 
 ['The example', 'events']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('example', 'exampl'), ('shows', 'show'), ('two', 'two'), ('events', 'event')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('example', 'exampl'), ('shows', 'show'), ('two', 'two'), ('events', 'event')]

>> Lemmatization: 
 [('The', 'The'), ('example', 'example'), ('shows', 'show'), ('two', 'two'), ('events', 'event')]



========================================== PARAGRAPH 383 ===========================================

could cause grass to be wet i.e.- either the sprinkler is on or its  

------------------- Sentence 1 -------------------

could cause grass to be wet i.e.- either the sprinkler is on or its

>> Tokens are: 
 ['could', 'cause', 'grass', 'wet', 'i.e.-', 'either', 'sprinkler', '']

>> Bigrams are: 
 [('could', 'cause'), ('cause', 'grass'), ('grass', 'wet'), ('wet', 'i.e.-'), ('i.e.-', 'either'), ('either', 'sprinkler'), ('sprinkler', '')]

>> Trigrams are: 
 [('could', 'cause', 'grass'), ('cause', 'grass', 'wet'), ('grass', 'wet', 'i.e.-'), ('wet', 'i.e.-', 'either'), ('i.e.-', 'either', 'sprinkler'), ('either', 'sprinkler', '')]

>> POS Tags are: 
 [('could', 'MD'), ('cause', 'VB'), ('grass', 'NN'), ('wet', 'IN'), ('i.e.-', 'JJ'), ('either', 'DT'), ('sprinkler', 'NN'), ('', 'NN')]

>> Noun Phrases are: 
 ['grass', 'either sprinkler ']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('could', 'could'), ('cause', 'caus'), ('grass', 'grass'), ('wet', 'wet'), ('i.e.-', 'i.e.-'), ('either', 'either'), ('sprinkler', 'sprinkler'), ('', '')]

>> Stemming using Snowball Stemmer: 
 [('could', 'could'), ('cause', 'caus'), ('grass', 'grass'), ('wet', 'wet'), ('i.e.-', 'i.e.-'), ('either', 'either'), ('sprinkler', 'sprinkler'), ('', '')]

>> Lemmatization: 
 [('could', 'could'), ('cause', 'cause'), ('grass', 'grass'), ('wet', 'wet'), ('i.e.-', 'i.e.-'), ('either', 'either'), ('sprinkler', 'sprinkler'), ('', '')]



========================================== PARAGRAPH 384 ===========================================

raining. Additionally here we also, suppose that the rain has a  

------------------- Sentence 1 -------------------

raining.

>> Tokens are: 
 ['raining', '.']

>> Bigrams are: 
 [('raining', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('raining', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['raining']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('raining', 'rain'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('raining', 'rain'), ('.', '.')]

>> Lemmatization: 
 [('raining', 'raining'), ('.', '.')]


------------------- Sentence 2 -------------------

Additionally here we also, suppose that the rain has a

>> Tokens are: 
 ['Additionally', 'also', ',', 'suppose', 'rain']

>> Bigrams are: 
 [('Additionally', 'also'), ('also', ','), (',', 'suppose'), ('suppose', 'rain')]

>> Trigrams are: 
 [('Additionally', 'also', ','), ('also', ',', 'suppose'), (',', 'suppose', 'rain')]

>> POS Tags are: 
 [('Additionally', 'RB'), ('also', 'RB'), (',', ','), ('suppose', 'VBD'), ('rain', 'NN')]

>> Noun Phrases are: 
 ['rain']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Additionally', 'addit'), ('also', 'also'), (',', ','), ('suppose', 'suppos'), ('rain', 'rain')]

>> Stemming using Snowball Stemmer: 
 [('Additionally', 'addit'), ('also', 'also'), (',', ','), ('suppose', 'suppos'), ('rain', 'rain')]

>> Lemmatization: 
 [('Additionally', 'Additionally'), ('also', 'also'), (',', ','), ('suppose', 'suppose'), ('rain', 'rain')]



========================================== PARAGRAPH 385 ===========================================

direct effect on the use of the sprinkler (namely that when it  

------------------- Sentence 1 -------------------

direct effect on the use of the sprinkler (namely that when it

>> Tokens are: 
 ['direct', 'effect', 'use', 'sprinkler', '(', 'namely']

>> Bigrams are: 
 [('direct', 'effect'), ('effect', 'use'), ('use', 'sprinkler'), ('sprinkler', '('), ('(', 'namely')]

>> Trigrams are: 
 [('direct', 'effect', 'use'), ('effect', 'use', 'sprinkler'), ('use', 'sprinkler', '('), ('sprinkler', '(', 'namely')]

>> POS Tags are: 
 [('direct', 'JJ'), ('effect', 'NN'), ('use', 'NN'), ('sprinkler', 'NN'), ('(', '('), ('namely', 'RB')]

>> Noun Phrases are: 
 ['direct effect use sprinkler']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('direct', 'direct'), ('effect', 'effect'), ('use', 'use'), ('sprinkler', 'sprinkler'), ('(', '('), ('namely', 'name')]

>> Stemming using Snowball Stemmer: 
 [('direct', 'direct'), ('effect', 'effect'), ('use', 'use'), ('sprinkler', 'sprinkler'), ('(', '('), ('namely', 'name')]

>> Lemmatization: 
 [('direct', 'direct'), ('effect', 'effect'), ('use', 'use'), ('sprinkler', 'sprinkler'), ('(', '('), ('namely', 'namely')]



========================================== PARAGRAPH 386 ===========================================

rains, the sprinkler is usually not turned on). Then the situation  

------------------- Sentence 1 -------------------

rains, the sprinkler is usually not turned on).

>> Tokens are: 
 ['rains', ',', 'sprinkler', 'usually', 'turned', ')', '.']

>> Bigrams are: 
 [('rains', ','), (',', 'sprinkler'), ('sprinkler', 'usually'), ('usually', 'turned'), ('turned', ')'), (')', '.')]

>> Trigrams are: 
 [('rains', ',', 'sprinkler'), (',', 'sprinkler', 'usually'), ('sprinkler', 'usually', 'turned'), ('usually', 'turned', ')'), ('turned', ')', '.')]

>> POS Tags are: 
 [('rains', 'NNS'), (',', ','), ('sprinkler', 'NN'), ('usually', 'RB'), ('turned', 'VBN'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['rains', 'sprinkler']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('rains', 'rain'), (',', ','), ('sprinkler', 'sprinkler'), ('usually', 'usual'), ('turned', 'turn'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('rains', 'rain'), (',', ','), ('sprinkler', 'sprinkler'), ('usually', 'usual'), ('turned', 'turn'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('rains', 'rain'), (',', ','), ('sprinkler', 'sprinkler'), ('usually', 'usually'), ('turned', 'turned'), (')', ')'), ('.', '.')]


------------------- Sentence 2 -------------------

Then the situation

>> Tokens are: 
 ['Then', 'situation']

>> Bigrams are: 
 [('Then', 'situation')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Then', 'RB'), ('situation', 'NN')]

>> Noun Phrases are: 
 ['situation']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Then', 'then'), ('situation', 'situat')]

>> Stemming using Snowball Stemmer: 
 [('Then', 'then'), ('situation', 'situat')]

>> Lemmatization: 
 [('Then', 'Then'), ('situation', 'situation')]



========================================== PARAGRAPH 387 ===========================================

can be modeled with a Bayesian network. All three variables  

------------------- Sentence 1 -------------------

can be modeled with a Bayesian network.

>> Tokens are: 
 ['modeled', 'Bayesian', 'network', '.']

>> Bigrams are: 
 [('modeled', 'Bayesian'), ('Bayesian', 'network'), ('network', '.')]

>> Trigrams are: 
 [('modeled', 'Bayesian', 'network'), ('Bayesian', 'network', '.')]

>> POS Tags are: 
 [('modeled', 'VBN'), ('Bayesian', 'JJ'), ('network', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Bayesian network']

>> Named Entities are: 
 [('GPE', 'Bayesian')] 

>> Stemming using Porter Stemmer: 
 [('modeled', 'model'), ('Bayesian', 'bayesian'), ('network', 'network'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('modeled', 'model'), ('Bayesian', 'bayesian'), ('network', 'network'), ('.', '.')]

>> Lemmatization: 
 [('modeled', 'modeled'), ('Bayesian', 'Bayesian'), ('network', 'network'), ('.', '.')]


------------------- Sentence 2 -------------------

All three variables

>> Tokens are: 
 ['All', 'three', 'variables']

>> Bigrams are: 
 [('All', 'three'), ('three', 'variables')]

>> Trigrams are: 
 [('All', 'three', 'variables')]

>> POS Tags are: 
 [('All', 'DT'), ('three', 'CD'), ('variables', 'NNS')]

>> Noun Phrases are: 
 ['variables']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('All', 'all'), ('three', 'three'), ('variables', 'variabl')]

>> Stemming using Snowball Stemmer: 
 [('All', 'all'), ('three', 'three'), ('variables', 'variabl')]

>> Lemmatization: 
 [('All', 'All'), ('three', 'three'), ('variables', 'variable')]



========================================== PARAGRAPH 388 ===========================================

have two possible values, T (for true) and F (for false) [22].  

------------------- Sentence 1 -------------------

have two possible values, T (for true) and F (for false) [22].

>> Tokens are: 
 ['two', 'possible', 'values', ',', 'T', '(', 'true', ')', 'F', '(', 'false', ')', '[', '22', ']', '.']

>> Bigrams are: 
 [('two', 'possible'), ('possible', 'values'), ('values', ','), (',', 'T'), ('T', '('), ('(', 'true'), ('true', ')'), (')', 'F'), ('F', '('), ('(', 'false'), ('false', ')'), (')', '['), ('[', '22'), ('22', ']'), (']', '.')]

>> Trigrams are: 
 [('two', 'possible', 'values'), ('possible', 'values', ','), ('values', ',', 'T'), (',', 'T', '('), ('T', '(', 'true'), ('(', 'true', ')'), ('true', ')', 'F'), (')', 'F', '('), ('F', '(', 'false'), ('(', 'false', ')'), ('false', ')', '['), (')', '[', '22'), ('[', '22', ']'), ('22', ']', '.')]

>> POS Tags are: 
 [('two', 'CD'), ('possible', 'JJ'), ('values', 'NNS'), (',', ','), ('T', 'NNP'), ('(', '('), ('true', 'JJ'), (')', ')'), ('F', 'NNP'), ('(', '('), ('false', 'JJ'), (')', ')'), ('[', 'VBP'), ('22', 'CD'), (']', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['possible values', 'T', 'F', ']']

>> Named Entities are: 
 [('GPE', 'T')] 

>> Stemming using Porter Stemmer: 
 [('two', 'two'), ('possible', 'possibl'), ('values', 'valu'), (',', ','), ('T', 't'), ('(', '('), ('true', 'true'), (')', ')'), ('F', 'f'), ('(', '('), ('false', 'fals'), (')', ')'), ('[', '['), ('22', '22'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('two', 'two'), ('possible', 'possibl'), ('values', 'valu'), (',', ','), ('T', 't'), ('(', '('), ('true', 'true'), (')', ')'), ('F', 'f'), ('(', '('), ('false', 'fals'), (')', ')'), ('[', '['), ('22', '22'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('two', 'two'), ('possible', 'possible'), ('values', 'value'), (',', ','), ('T', 'T'), ('(', '('), ('true', 'true'), (')', ')'), ('F', 'F'), ('(', '('), ('false', 'false'), (')', ')'), ('[', '['), ('22', '22'), (']', ']'), ('.', '.')]



========================================== PARAGRAPH 389 ===========================================

  


========================================== PARAGRAPH 390 ===========================================

Fig.7. Bayesian network with conditional probability tables  

------------------- Sentence 1 -------------------

Fig.7.

>> Tokens are: 
 ['Fig.7', '.']

>> Bigrams are: 
 [('Fig.7', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Fig.7', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Fig.7']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Fig.7', 'fig.7'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Fig.7', 'fig.7'), ('.', '.')]

>> Lemmatization: 
 [('Fig.7', 'Fig.7'), ('.', '.')]


------------------- Sentence 2 -------------------

Bayesian network with conditional probability tables

>> Tokens are: 
 ['Bayesian', 'network', 'conditional', 'probability', 'tables']

>> Bigrams are: 
 [('Bayesian', 'network'), ('network', 'conditional'), ('conditional', 'probability'), ('probability', 'tables')]

>> Trigrams are: 
 [('Bayesian', 'network', 'conditional'), ('network', 'conditional', 'probability'), ('conditional', 'probability', 'tables')]

>> POS Tags are: 
 [('Bayesian', 'JJ'), ('network', 'NN'), ('conditional', 'JJ'), ('probability', 'NN'), ('tables', 'NNS')]

>> Noun Phrases are: 
 ['Bayesian network', 'conditional probability tables']

>> Named Entities are: 
 [('GPE', 'Bayesian')] 

>> Stemming using Porter Stemmer: 
 [('Bayesian', 'bayesian'), ('network', 'network'), ('conditional', 'condit'), ('probability', 'probabl'), ('tables', 'tabl')]

>> Stemming using Snowball Stemmer: 
 [('Bayesian', 'bayesian'), ('network', 'network'), ('conditional', 'condit'), ('probability', 'probabl'), ('tables', 'tabl')]

>> Lemmatization: 
 [('Bayesian', 'Bayesian'), ('network', 'network'), ('conditional', 'conditional'), ('probability', 'probability'), ('tables', 'table')]



========================================== PARAGRAPH 391 ===========================================

The below is a joint probability function:  

------------------- Sentence 1 -------------------

The below is a joint probability function:

>> Tokens are: 
 ['The', 'joint', 'probability', 'function', ':']

>> Bigrams are: 
 [('The', 'joint'), ('joint', 'probability'), ('probability', 'function'), ('function', ':')]

>> Trigrams are: 
 [('The', 'joint', 'probability'), ('joint', 'probability', 'function'), ('probability', 'function', ':')]

>> POS Tags are: 
 [('The', 'DT'), ('joint', 'JJ'), ('probability', 'NN'), ('function', 'NN'), (':', ':')]

>> Noun Phrases are: 
 ['The joint probability function']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('joint', 'joint'), ('probability', 'probabl'), ('function', 'function'), (':', ':')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('joint', 'joint'), ('probability', 'probabl'), ('function', 'function'), (':', ':')]

>> Lemmatization: 
 [('The', 'The'), ('joint', 'joint'), ('probability', 'probability'), ('function', 'function'), (':', ':')]



========================================== PARAGRAPH 392 ===========================================

        RPRSPRSGPRSGP ,,,   (4)  where, the names of the variables have been abbreviated to:  

------------------- Sentence 1 -------------------

        RPRSPRSGPRSGP ,,,   (4)  where, the names of the variables have been abbreviated to:

>> Tokens are: 
 ['\uf028', '\uf029', '\uf028', '\uf029', '\uf028', '\uf029', '\uf028', '\uf029RPRSPRSGPRSGP', ',', ',', ',', '\uf03d', '(', '4', ')', ',', 'names', 'variables', 'abbreviated', ':']

>> Bigrams are: 
 [('\uf028', '\uf029'), ('\uf029', '\uf028'), ('\uf028', '\uf029'), ('\uf029', '\uf028'), ('\uf028', '\uf029'), ('\uf029', '\uf028'), ('\uf028', '\uf029RPRSPRSGPRSGP'), ('\uf029RPRSPRSGPRSGP', ','), (',', ','), (',', ','), (',', '\uf03d'), ('\uf03d', '('), ('(', '4'), ('4', ')'), (')', ','), (',', 'names'), ('names', 'variables'), ('variables', 'abbreviated'), ('abbreviated', ':')]

>> Trigrams are: 
 [('\uf028', '\uf029', '\uf028'), ('\uf029', '\uf028', '\uf029'), ('\uf028', '\uf029', '\uf028'), ('\uf029', '\uf028', '\uf029'), ('\uf028', '\uf029', '\uf028'), ('\uf029', '\uf028', '\uf029RPRSPRSGPRSGP'), ('\uf028', '\uf029RPRSPRSGPRSGP', ','), ('\uf029RPRSPRSGPRSGP', ',', ','), (',', ',', ','), (',', ',', '\uf03d'), (',', '\uf03d', '('), ('\uf03d', '(', '4'), ('(', '4', ')'), ('4', ')', ','), (')', ',', 'names'), (',', 'names', 'variables'), ('names', 'variables', 'abbreviated'), ('variables', 'abbreviated', ':')]

>> POS Tags are: 
 [('\uf028', 'JJ'), ('\uf029', 'NNP'), ('\uf028', 'NNP'), ('\uf029', 'NNP'), ('\uf028', 'NNP'), ('\uf029', 'NNP'), ('\uf028', 'NNP'), ('\uf029RPRSPRSGPRSGP', 'NNP'), (',', ','), (',', ','), (',', ','), ('\uf03d', 'NNP'), ('(', '('), ('4', 'CD'), (')', ')'), (',', ','), ('names', 'JJ'), ('variables', 'NNS'), ('abbreviated', 'VBN'), (':', ':')]

>> Noun Phrases are: 
 ['\uf028 \uf029 \uf028 \uf029 \uf028 \uf029 \uf028 \uf029RPRSPRSGPRSGP', '\uf03d', 'names variables']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('\uf028', '\uf028'), ('\uf029', '\uf029'), ('\uf028', '\uf028'), ('\uf029', '\uf029'), ('\uf028', '\uf028'), ('\uf029', '\uf029'), ('\uf028', '\uf028'), ('\uf029RPRSPRSGPRSGP', '\uf029rprsprsgprsgp'), (',', ','), (',', ','), (',', ','), ('\uf03d', '\uf03d'), ('(', '('), ('4', '4'), (')', ')'), (',', ','), ('names', 'name'), ('variables', 'variabl'), ('abbreviated', 'abbrevi'), (':', ':')]

>> Stemming using Snowball Stemmer: 
 [('\uf028', '\uf028'), ('\uf029', '\uf029'), ('\uf028', '\uf028'), ('\uf029', '\uf029'), ('\uf028', '\uf028'), ('\uf029', '\uf029'), ('\uf028', '\uf028'), ('\uf029RPRSPRSGPRSGP', '\uf029rprsprsgprsgp'), (',', ','), (',', ','), (',', ','), ('\uf03d', '\uf03d'), ('(', '('), ('4', '4'), (')', ')'), (',', ','), ('names', 'name'), ('variables', 'variabl'), ('abbreviated', 'abbrevi'), (':', ':')]

>> Lemmatization: 
 [('\uf028', '\uf028'), ('\uf029', '\uf029'), ('\uf028', '\uf028'), ('\uf029', '\uf029'), ('\uf028', '\uf028'), ('\uf029', '\uf029'), ('\uf028', '\uf028'), ('\uf029RPRSPRSGPRSGP', '\uf029RPRSPRSGPRSGP'), (',', ','), (',', ','), (',', ','), ('\uf03d', '\uf03d'), ('(', '('), ('4', '4'), (')', ')'), (',', ','), ('names', 'name'), ('variables', 'variable'), ('abbreviated', 'abbreviated'), (':', ':')]



========================================== PARAGRAPH 393 ===========================================

G = Grass wet (yes/no)  

------------------- Sentence 1 -------------------

G = Grass wet (yes/no)

>> Tokens are: 
 ['G', '=', 'Grass', 'wet', '(', 'yes/no', ')']

>> Bigrams are: 
 [('G', '='), ('=', 'Grass'), ('Grass', 'wet'), ('wet', '('), ('(', 'yes/no'), ('yes/no', ')')]

>> Trigrams are: 
 [('G', '=', 'Grass'), ('=', 'Grass', 'wet'), ('Grass', 'wet', '('), ('wet', '(', 'yes/no'), ('(', 'yes/no', ')')]

>> POS Tags are: 
 [('G', 'NNP'), ('=', 'NNP'), ('Grass', 'NNP'), ('wet', 'NN'), ('(', '('), ('yes/no', 'NN'), (')', ')')]

>> Noun Phrases are: 
 ['G = Grass wet', 'yes/no']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('G', 'g'), ('=', '='), ('Grass', 'grass'), ('wet', 'wet'), ('(', '('), ('yes/no', 'yes/no'), (')', ')')]

>> Stemming using Snowball Stemmer: 
 [('G', 'g'), ('=', '='), ('Grass', 'grass'), ('wet', 'wet'), ('(', '('), ('yes/no', 'yes/no'), (')', ')')]

>> Lemmatization: 
 [('G', 'G'), ('=', '='), ('Grass', 'Grass'), ('wet', 'wet'), ('(', '('), ('yes/no', 'yes/no'), (')', ')')]



========================================== PARAGRAPH 394 ===========================================

S = Sprinkler turned on (yes/no)  

------------------- Sentence 1 -------------------

S = Sprinkler turned on (yes/no)

>> Tokens are: 
 ['S', '=', 'Sprinkler', 'turned', '(', 'yes/no', ')']

>> Bigrams are: 
 [('S', '='), ('=', 'Sprinkler'), ('Sprinkler', 'turned'), ('turned', '('), ('(', 'yes/no'), ('yes/no', ')')]

>> Trigrams are: 
 [('S', '=', 'Sprinkler'), ('=', 'Sprinkler', 'turned'), ('Sprinkler', 'turned', '('), ('turned', '(', 'yes/no'), ('(', 'yes/no', ')')]

>> POS Tags are: 
 [('S', 'NNP'), ('=', 'NNP'), ('Sprinkler', 'NNP'), ('turned', 'VBD'), ('(', '('), ('yes/no', 'NN'), (')', ')')]

>> Noun Phrases are: 
 ['S = Sprinkler', 'yes/no']

>> Named Entities are: 
 [('PERSON', 'Sprinkler')] 

>> Stemming using Porter Stemmer: 
 [('S', 's'), ('=', '='), ('Sprinkler', 'sprinkler'), ('turned', 'turn'), ('(', '('), ('yes/no', 'yes/no'), (')', ')')]

>> Stemming using Snowball Stemmer: 
 [('S', 's'), ('=', '='), ('Sprinkler', 'sprinkler'), ('turned', 'turn'), ('(', '('), ('yes/no', 'yes/no'), (')', ')')]

>> Lemmatization: 
 [('S', 'S'), ('=', '='), ('Sprinkler', 'Sprinkler'), ('turned', 'turned'), ('(', '('), ('yes/no', 'yes/no'), (')', ')')]



========================================== PARAGRAPH 395 ===========================================

R = Raining (yes/no).  

------------------- Sentence 1 -------------------

R = Raining (yes/no).

>> Tokens are: 
 ['R', '=', 'Raining', '(', 'yes/no', ')', '.']

>> Bigrams are: 
 [('R', '='), ('=', 'Raining'), ('Raining', '('), ('(', 'yes/no'), ('yes/no', ')'), (')', '.')]

>> Trigrams are: 
 [('R', '=', 'Raining'), ('=', 'Raining', '('), ('Raining', '(', 'yes/no'), ('(', 'yes/no', ')'), ('yes/no', ')', '.')]

>> POS Tags are: 
 [('R', 'NNP'), ('=', 'NNP'), ('Raining', 'NNP'), ('(', '('), ('yes/no', 'NN'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['R = Raining', 'yes/no']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('R', 'r'), ('=', '='), ('Raining', 'rain'), ('(', '('), ('yes/no', 'yes/no'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('R', 'r'), ('=', '='), ('Raining', 'rain'), ('(', '('), ('yes/no', 'yes/no'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('R', 'R'), ('=', '='), ('Raining', 'Raining'), ('(', '('), ('yes/no', 'yes/no'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 396 ===========================================

Cheng et al. draw the attention of a problem of BN classifiers  

------------------- Sentence 1 -------------------

Cheng et al.

>> Tokens are: 
 ['Cheng', 'et', 'al', '.']

>> Bigrams are: 
 [('Cheng', 'et'), ('et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('Cheng', 'et', 'al'), ('et', 'al', '.')]

>> POS Tags are: 
 [('Cheng', 'NNP'), ('et', 'CC'), ('al', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Cheng', 'al']

>> Named Entities are: 
 [('GPE', 'Cheng')] 

>> Stemming using Porter Stemmer: 
 [('Cheng', 'cheng'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Cheng', 'cheng'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('Cheng', 'Cheng'), ('et', 'et'), ('al', 'al'), ('.', '.')]


------------------- Sentence 2 -------------------

draw the attention of a problem of BN classifiers

>> Tokens are: 
 ['draw', 'attention', 'problem', 'BN', 'classifiers']

>> Bigrams are: 
 [('draw', 'attention'), ('attention', 'problem'), ('problem', 'BN'), ('BN', 'classifiers')]

>> Trigrams are: 
 [('draw', 'attention', 'problem'), ('attention', 'problem', 'BN'), ('problem', 'BN', 'classifiers')]

>> POS Tags are: 
 [('draw', 'JJ'), ('attention', 'NN'), ('problem', 'NN'), ('BN', 'NNP'), ('classifiers', 'NNS')]

>> Noun Phrases are: 
 ['draw attention problem BN classifiers']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('draw', 'draw'), ('attention', 'attent'), ('problem', 'problem'), ('BN', 'bn'), ('classifiers', 'classifi')]

>> Stemming using Snowball Stemmer: 
 [('draw', 'draw'), ('attention', 'attent'), ('problem', 'problem'), ('BN', 'bn'), ('classifiers', 'classifi')]

>> Lemmatization: 
 [('draw', 'draw'), ('attention', 'attention'), ('problem', 'problem'), ('BN', 'BN'), ('classifiers', 'classifier')]



========================================== PARAGRAPH 397 ===========================================

that it is not suitable for datasets with many features. The reason  

------------------- Sentence 1 -------------------

that it is not suitable for datasets with many features.

>> Tokens are: 
 ['suitable', 'datasets', 'many', 'features', '.']

>> Bigrams are: 
 [('suitable', 'datasets'), ('datasets', 'many'), ('many', 'features'), ('features', '.')]

>> Trigrams are: 
 [('suitable', 'datasets', 'many'), ('datasets', 'many', 'features'), ('many', 'features', '.')]

>> POS Tags are: 
 [('suitable', 'JJ'), ('datasets', 'NNS'), ('many', 'JJ'), ('features', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['suitable datasets', 'many features']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('suitable', 'suitabl'), ('datasets', 'dataset'), ('many', 'mani'), ('features', 'featur'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('suitable', 'suitabl'), ('datasets', 'dataset'), ('many', 'mani'), ('features', 'featur'), ('.', '.')]

>> Lemmatization: 
 [('suitable', 'suitable'), ('datasets', 'datasets'), ('many', 'many'), ('features', 'feature'), ('.', '.')]


------------------- Sentence 2 -------------------

The reason

>> Tokens are: 
 ['The', 'reason']

>> Bigrams are: 
 [('The', 'reason')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('The', 'DT'), ('reason', 'NN')]

>> Noun Phrases are: 
 ['The reason']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('reason', 'reason')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('reason', 'reason')]

>> Lemmatization: 
 [('The', 'The'), ('reason', 'reason')]



========================================== PARAGRAPH 398 ===========================================

for this is that trying to construct a very large network is simply  

------------------- Sentence 1 -------------------

for this is that trying to construct a very large network is simply

>> Tokens are: 
 ['trying', 'construct', 'large', 'network', 'simply']

>> Bigrams are: 
 [('trying', 'construct'), ('construct', 'large'), ('large', 'network'), ('network', 'simply')]

>> Trigrams are: 
 [('trying', 'construct', 'large'), ('construct', 'large', 'network'), ('large', 'network', 'simply')]

>> POS Tags are: 
 [('trying', 'VBG'), ('construct', 'NN'), ('large', 'JJ'), ('network', 'NN'), ('simply', 'RB')]

>> Noun Phrases are: 
 ['construct', 'large network']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('trying', 'tri'), ('construct', 'construct'), ('large', 'larg'), ('network', 'network'), ('simply', 'simpli')]

>> Stemming using Snowball Stemmer: 
 [('trying', 'tri'), ('construct', 'construct'), ('large', 'larg'), ('network', 'network'), ('simply', 'simpli')]

>> Lemmatization: 
 [('trying', 'trying'), ('construct', 'construct'), ('large', 'large'), ('network', 'network'), ('simply', 'simply')]



========================================== PARAGRAPH 399 ===========================================

not feasible in terms of time and space [23]. The pseudo code of  

------------------- Sentence 1 -------------------

not feasible in terms of time and space [23].

>> Tokens are: 
 ['feasible', 'terms', 'time', 'space', '[', '23', ']', '.']

>> Bigrams are: 
 [('feasible', 'terms'), ('terms', 'time'), ('time', 'space'), ('space', '['), ('[', '23'), ('23', ']'), (']', '.')]

>> Trigrams are: 
 [('feasible', 'terms', 'time'), ('terms', 'time', 'space'), ('time', 'space', '['), ('space', '[', '23'), ('[', '23', ']'), ('23', ']', '.')]

>> POS Tags are: 
 [('feasible', 'JJ'), ('terms', 'NNS'), ('time', 'NN'), ('space', 'NN'), ('[', 'NNP'), ('23', 'CD'), (']', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['feasible terms time space [', ']']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('feasible', 'feasibl'), ('terms', 'term'), ('time', 'time'), ('space', 'space'), ('[', '['), ('23', '23'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('feasible', 'feasibl'), ('terms', 'term'), ('time', 'time'), ('space', 'space'), ('[', '['), ('23', '23'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('feasible', 'feasible'), ('terms', 'term'), ('time', 'time'), ('space', 'space'), ('[', '['), ('23', '23'), (']', ']'), ('.', '.')]


------------------- Sentence 2 -------------------

The pseudo code of

>> Tokens are: 
 ['The', 'pseudo', 'code']

>> Bigrams are: 
 [('The', 'pseudo'), ('pseudo', 'code')]

>> Trigrams are: 
 [('The', 'pseudo', 'code')]

>> POS Tags are: 
 [('The', 'DT'), ('pseudo', 'NN'), ('code', 'NN')]

>> Noun Phrases are: 
 ['The pseudo code']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('pseudo', 'pseudo'), ('code', 'code')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('pseudo', 'pseudo'), ('code', 'code')]

>> Lemmatization: 
 [('The', 'The'), ('pseudo', 'pseudo'), ('code', 'code')]



========================================== PARAGRAPH 400 ===========================================

training BN is shown in below figure:  

------------------- Sentence 1 -------------------

training BN is shown in below figure:

>> Tokens are: 
 ['training', 'BN', 'shown', 'figure', ':']

>> Bigrams are: 
 [('training', 'BN'), ('BN', 'shown'), ('shown', 'figure'), ('figure', ':')]

>> Trigrams are: 
 [('training', 'BN', 'shown'), ('BN', 'shown', 'figure'), ('shown', 'figure', ':')]

>> POS Tags are: 
 [('training', 'VBG'), ('BN', 'NNP'), ('shown', 'VBN'), ('figure', 'NN'), (':', ':')]

>> Noun Phrases are: 
 ['BN', 'figure']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('training', 'train'), ('BN', 'bn'), ('shown', 'shown'), ('figure', 'figur'), (':', ':')]

>> Stemming using Snowball Stemmer: 
 [('training', 'train'), ('BN', 'bn'), ('shown', 'shown'), ('figure', 'figur'), (':', ':')]

>> Lemmatization: 
 [('training', 'training'), ('BN', 'BN'), ('shown', 'shown'), ('figure', 'figure'), (':', ':')]



========================================== PARAGRAPH 401 ===========================================

Input 1  

------------------- Sentence 1 -------------------

Input 1

>> Tokens are: 
 ['Input', '1']

>> Bigrams are: 
 [('Input', '1')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Input', '$'), ('1', 'CD')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Input', 'input'), ('1', '1')]

>> Stemming using Snowball Stemmer: 
 [('Input', 'input'), ('1', '1')]

>> Lemmatization: 
 [('Input', 'Input'), ('1', '1')]



========================================== PARAGRAPH 402 ===========================================

Input 2  

------------------- Sentence 1 -------------------

Input 2

>> Tokens are: 
 ['Input', '2']

>> Bigrams are: 
 [('Input', '2')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Input', '$'), ('2', 'CD')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Input', 'input'), ('2', '2')]

>> Stemming using Snowball Stemmer: 
 [('Input', 'input'), ('2', '2')]

>> Lemmatization: 
 [('Input', 'Input'), ('2', '2')]



========================================== PARAGRAPH 403 ===========================================

Input 3  

------------------- Sentence 1 -------------------

Input 3

>> Tokens are: 
 ['Input', '3']

>> Bigrams are: 
 [('Input', '3')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Input', '$'), ('3', 'CD')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Input', 'input'), ('3', '3')]

>> Stemming using Snowball Stemmer: 
 [('Input', 'input'), ('3', '3')]

>> Lemmatization: 
 [('Input', 'Input'), ('3', '3')]



========================================== PARAGRAPH 404 ===========================================

Input 4  

------------------- Sentence 1 -------------------

Input 4

>> Tokens are: 
 ['Input', '4']

>> Bigrams are: 
 [('Input', '4')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Input', '$'), ('4', 'CD')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Input', 'input'), ('4', '4')]

>> Stemming using Snowball Stemmer: 
 [('Input', 'input'), ('4', '4')]

>> Lemmatization: 
 [('Input', 'Input'), ('4', '4')]



========================================== PARAGRAPH 405 ===========================================

Output 1 

------------------- Sentence 1 -------------------

Output 1

>> Tokens are: 
 ['Output', '1']

>> Bigrams are: 
 [('Output', '1')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Output', '$'), ('1', 'CD')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Output', 'output'), ('1', '1')]

>> Stemming using Snowball Stemmer: 
 [('Output', 'output'), ('1', '1')]

>> Lemmatization: 
 [('Output', 'Output'), ('1', '1')]



========================================== PARAGRAPH 406 ===========================================

IQBAL MUHAMMAD AND ZHU YAN: SUPERVISED MACHINE LEARNING APPROACHES: A SURVEY  

------------------- Sentence 1 -------------------

IQBAL MUHAMMAD AND ZHU YAN: SUPERVISED MACHINE LEARNING APPROACHES: A SURVEY

>> Tokens are: 
 ['IQBAL', 'MUHAMMAD', 'AND', 'ZHU', 'YAN', ':', 'SUPERVISED', 'MACHINE', 'LEARNING', 'APPROACHES', ':', 'A', 'SURVEY']

>> Bigrams are: 
 [('IQBAL', 'MUHAMMAD'), ('MUHAMMAD', 'AND'), ('AND', 'ZHU'), ('ZHU', 'YAN'), ('YAN', ':'), (':', 'SUPERVISED'), ('SUPERVISED', 'MACHINE'), ('MACHINE', 'LEARNING'), ('LEARNING', 'APPROACHES'), ('APPROACHES', ':'), (':', 'A'), ('A', 'SURVEY')]

>> Trigrams are: 
 [('IQBAL', 'MUHAMMAD', 'AND'), ('MUHAMMAD', 'AND', 'ZHU'), ('AND', 'ZHU', 'YAN'), ('ZHU', 'YAN', ':'), ('YAN', ':', 'SUPERVISED'), (':', 'SUPERVISED', 'MACHINE'), ('SUPERVISED', 'MACHINE', 'LEARNING'), ('MACHINE', 'LEARNING', 'APPROACHES'), ('LEARNING', 'APPROACHES', ':'), ('APPROACHES', ':', 'A'), (':', 'A', 'SURVEY')]

>> POS Tags are: 
 [('IQBAL', 'NNP'), ('MUHAMMAD', 'NNP'), ('AND', 'NNP'), ('ZHU', 'NNP'), ('YAN', 'NNP'), (':', ':'), ('SUPERVISED', 'NNP'), ('MACHINE', 'NNP'), ('LEARNING', 'NNP'), ('APPROACHES', 'NNP'), (':', ':'), ('A', 'DT'), ('SURVEY', 'NN')]

>> Noun Phrases are: 
 ['IQBAL MUHAMMAD AND ZHU YAN', 'SUPERVISED MACHINE LEARNING APPROACHES', 'A SURVEY']

>> Named Entities are: 
 [('ORGANIZATION', 'IQBAL'), ('ORGANIZATION', 'MUHAMMAD'), ('ORGANIZATION', 'SUPERVISED'), ('ORGANIZATION', 'MACHINE')] 

>> Stemming using Porter Stemmer: 
 [('IQBAL', 'iqbal'), ('MUHAMMAD', 'muhammad'), ('AND', 'and'), ('ZHU', 'zhu'), ('YAN', 'yan'), (':', ':'), ('SUPERVISED', 'supervis'), ('MACHINE', 'machin'), ('LEARNING', 'learn'), ('APPROACHES', 'approach'), (':', ':'), ('A', 'a'), ('SURVEY', 'survey')]

>> Stemming using Snowball Stemmer: 
 [('IQBAL', 'iqbal'), ('MUHAMMAD', 'muhammad'), ('AND', 'and'), ('ZHU', 'zhu'), ('YAN', 'yan'), (':', ':'), ('SUPERVISED', 'supervis'), ('MACHINE', 'machin'), ('LEARNING', 'learn'), ('APPROACHES', 'approach'), (':', ':'), ('A', 'a'), ('SURVEY', 'survey')]

>> Lemmatization: 
 [('IQBAL', 'IQBAL'), ('MUHAMMAD', 'MUHAMMAD'), ('AND', 'AND'), ('ZHU', 'ZHU'), ('YAN', 'YAN'), (':', ':'), ('SUPERVISED', 'SUPERVISED'), ('MACHINE', 'MACHINE'), ('LEARNING', 'LEARNING'), ('APPROACHES', 'APPROACHES'), (':', ':'), ('A', 'A'), ('SURVEY', 'SURVEY')]



========================================== PARAGRAPH 407 ===========================================

950  

------------------- Sentence 1 -------------------

950

>> Tokens are: 
 ['950']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('950', 'CD')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('950', '950')]

>> Stemming using Snowball Stemmer: 
 [('950', '950')]

>> Lemmatization: 
 [('950', '950')]



========================================== PARAGRAPH 408 ===========================================

  


========================================== PARAGRAPH 409 ===========================================

Fig.8. Pseudo-code for training of BN  

------------------- Sentence 1 -------------------

Fig.8.

>> Tokens are: 
 ['Fig.8', '.']

>> Bigrams are: 
 [('Fig.8', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Fig.8', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Fig.8']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Fig.8', 'fig.8'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Fig.8', 'fig.8'), ('.', '.')]

>> Lemmatization: 
 [('Fig.8', 'Fig.8'), ('.', '.')]


------------------- Sentence 2 -------------------

Pseudo-code for training of BN

>> Tokens are: 
 ['Pseudo-code', 'training', 'BN']

>> Bigrams are: 
 [('Pseudo-code', 'training'), ('training', 'BN')]

>> Trigrams are: 
 [('Pseudo-code', 'training', 'BN')]

>> POS Tags are: 
 [('Pseudo-code', 'JJ'), ('training', 'NN'), ('BN', 'NNP')]

>> Noun Phrases are: 
 ['Pseudo-code training BN']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Pseudo-code', 'pseudo-cod'), ('training', 'train'), ('BN', 'bn')]

>> Stemming using Snowball Stemmer: 
 [('Pseudo-code', 'pseudo-cod'), ('training', 'train'), ('BN', 'bn')]

>> Lemmatization: 
 [('Pseudo-code', 'Pseudo-code'), ('training', 'training'), ('BN', 'BN')]



========================================== PARAGRAPH 410 ===========================================

5. INSTANCE-BASED LEARNING  

------------------- Sentence 1 -------------------

5.

>> Tokens are: 
 ['5', '.']

>> Bigrams are: 
 [('5', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('5', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('5', '5'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('5', '5'), ('.', '.')]

>> Lemmatization: 
 [('5', '5'), ('.', '.')]


------------------- Sentence 2 -------------------

INSTANCE-BASED LEARNING

>> Tokens are: 
 ['INSTANCE-BASED', 'LEARNING']

>> Bigrams are: 
 [('INSTANCE-BASED', 'LEARNING')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('INSTANCE-BASED', 'NNP'), ('LEARNING', 'NNP')]

>> Noun Phrases are: 
 ['INSTANCE-BASED LEARNING']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('INSTANCE-BASED', 'instance-bas'), ('LEARNING', 'learn')]

>> Stemming using Snowball Stemmer: 
 [('INSTANCE-BASED', 'instance-bas'), ('LEARNING', 'learn')]

>> Lemmatization: 
 [('INSTANCE-BASED', 'INSTANCE-BASED'), ('LEARNING', 'LEARNING')]



========================================== PARAGRAPH 411 ===========================================

About this learning scheme, the author [24] describes it as  

------------------- Sentence 1 -------------------

About this learning scheme, the author [24] describes it as

>> Tokens are: 
 ['About', 'learning', 'scheme', ',', 'author', '[', '24', ']', 'describes']

>> Bigrams are: 
 [('About', 'learning'), ('learning', 'scheme'), ('scheme', ','), (',', 'author'), ('author', '['), ('[', '24'), ('24', ']'), (']', 'describes')]

>> Trigrams are: 
 [('About', 'learning', 'scheme'), ('learning', 'scheme', ','), ('scheme', ',', 'author'), (',', 'author', '['), ('author', '[', '24'), ('[', '24', ']'), ('24', ']', 'describes')]

>> POS Tags are: 
 [('About', 'IN'), ('learning', 'VBG'), ('scheme', 'NN'), (',', ','), ('author', 'NN'), ('[', 'VBD'), ('24', 'CD'), (']', 'NNP'), ('describes', 'NNS')]

>> Noun Phrases are: 
 ['scheme', 'author', '] describes']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('About', 'about'), ('learning', 'learn'), ('scheme', 'scheme'), (',', ','), ('author', 'author'), ('[', '['), ('24', '24'), (']', ']'), ('describes', 'describ')]

>> Stemming using Snowball Stemmer: 
 [('About', 'about'), ('learning', 'learn'), ('scheme', 'scheme'), (',', ','), ('author', 'author'), ('[', '['), ('24', '24'), (']', ']'), ('describes', 'describ')]

>> Lemmatization: 
 [('About', 'About'), ('learning', 'learning'), ('scheme', 'scheme'), (',', ','), ('author', 'author'), ('[', '['), ('24', '24'), (']', ']'), ('describes', 'describes')]



========================================== PARAGRAPH 412 ===========================================

lazy-learning algorithms, as they delay the induction or  

------------------- Sentence 1 -------------------

lazy-learning algorithms, as they delay the induction or

>> Tokens are: 
 ['lazy-learning', 'algorithms', ',', 'delay', 'induction']

>> Bigrams are: 
 [('lazy-learning', 'algorithms'), ('algorithms', ','), (',', 'delay'), ('delay', 'induction')]

>> Trigrams are: 
 [('lazy-learning', 'algorithms', ','), ('algorithms', ',', 'delay'), (',', 'delay', 'induction')]

>> POS Tags are: 
 [('lazy-learning', 'JJ'), ('algorithms', 'NN'), (',', ','), ('delay', 'NN'), ('induction', 'NN')]

>> Noun Phrases are: 
 ['lazy-learning algorithms', 'delay induction']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('lazy-learning', 'lazy-learn'), ('algorithms', 'algorithm'), (',', ','), ('delay', 'delay'), ('induction', 'induct')]

>> Stemming using Snowball Stemmer: 
 [('lazy-learning', 'lazy-learn'), ('algorithms', 'algorithm'), (',', ','), ('delay', 'delay'), ('induction', 'induct')]

>> Lemmatization: 
 [('lazy-learning', 'lazy-learning'), ('algorithms', 'algorithm'), (',', ','), ('delay', 'delay'), ('induction', 'induction')]



========================================== PARAGRAPH 413 ===========================================

generalization process until classification is performed. These  

------------------- Sentence 1 -------------------

generalization process until classification is performed.

>> Tokens are: 
 ['generalization', 'process', 'classification', 'performed', '.']

>> Bigrams are: 
 [('generalization', 'process'), ('process', 'classification'), ('classification', 'performed'), ('performed', '.')]

>> Trigrams are: 
 [('generalization', 'process', 'classification'), ('process', 'classification', 'performed'), ('classification', 'performed', '.')]

>> POS Tags are: 
 [('generalization', 'NN'), ('process', 'NN'), ('classification', 'NN'), ('performed', 'VBD'), ('.', '.')]

>> Noun Phrases are: 
 ['generalization process classification']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('generalization', 'gener'), ('process', 'process'), ('classification', 'classif'), ('performed', 'perform'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('generalization', 'general'), ('process', 'process'), ('classification', 'classif'), ('performed', 'perform'), ('.', '.')]

>> Lemmatization: 
 [('generalization', 'generalization'), ('process', 'process'), ('classification', 'classification'), ('performed', 'performed'), ('.', '.')]


------------------- Sentence 2 -------------------

These

>> Tokens are: 
 ['These']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('These', 'DT')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('These', 'these')]

>> Stemming using Snowball Stemmer: 
 [('These', 'these')]

>> Lemmatization: 
 [('These', 'These')]



========================================== PARAGRAPH 414 ===========================================

algorithms require less computational time during the training  

------------------- Sentence 1 -------------------

algorithms require less computational time during the training

>> Tokens are: 
 ['algorithms', 'require', 'less', 'computational', 'time', 'training']

>> Bigrams are: 
 [('algorithms', 'require'), ('require', 'less'), ('less', 'computational'), ('computational', 'time'), ('time', 'training')]

>> Trigrams are: 
 [('algorithms', 'require', 'less'), ('require', 'less', 'computational'), ('less', 'computational', 'time'), ('computational', 'time', 'training')]

>> POS Tags are: 
 [('algorithms', 'JJ'), ('require', 'NN'), ('less', 'JJR'), ('computational', 'JJ'), ('time', 'NN'), ('training', 'NN')]

>> Noun Phrases are: 
 ['algorithms require', 'computational time training']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('algorithms', 'algorithm'), ('require', 'requir'), ('less', 'less'), ('computational', 'comput'), ('time', 'time'), ('training', 'train')]

>> Stemming using Snowball Stemmer: 
 [('algorithms', 'algorithm'), ('require', 'requir'), ('less', 'less'), ('computational', 'comput'), ('time', 'time'), ('training', 'train')]

>> Lemmatization: 
 [('algorithms', 'algorithm'), ('require', 'require'), ('less', 'le'), ('computational', 'computational'), ('time', 'time'), ('training', 'training')]



========================================== PARAGRAPH 415 ===========================================

phase than other eager-learning algorithms (such as decision trees,  

------------------- Sentence 1 -------------------

phase than other eager-learning algorithms (such as decision trees,

>> Tokens are: 
 ['phase', 'eager-learning', 'algorithms', '(', 'decision', 'trees', ',']

>> Bigrams are: 
 [('phase', 'eager-learning'), ('eager-learning', 'algorithms'), ('algorithms', '('), ('(', 'decision'), ('decision', 'trees'), ('trees', ',')]

>> Trigrams are: 
 [('phase', 'eager-learning', 'algorithms'), ('eager-learning', 'algorithms', '('), ('algorithms', '(', 'decision'), ('(', 'decision', 'trees'), ('decision', 'trees', ',')]

>> POS Tags are: 
 [('phase', 'NN'), ('eager-learning', 'JJ'), ('algorithms', 'NN'), ('(', '('), ('decision', 'NN'), ('trees', 'NNS'), (',', ',')]

>> Noun Phrases are: 
 ['phase', 'eager-learning algorithms', 'decision trees']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('phase', 'phase'), ('eager-learning', 'eager-learn'), ('algorithms', 'algorithm'), ('(', '('), ('decision', 'decis'), ('trees', 'tree'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('phase', 'phase'), ('eager-learning', 'eager-learn'), ('algorithms', 'algorithm'), ('(', '('), ('decision', 'decis'), ('trees', 'tree'), (',', ',')]

>> Lemmatization: 
 [('phase', 'phase'), ('eager-learning', 'eager-learning'), ('algorithms', 'algorithm'), ('(', '('), ('decision', 'decision'), ('trees', 'tree'), (',', ',')]



========================================== PARAGRAPH 416 ===========================================

neural and Bayes nets) but need more computation time during the  

------------------- Sentence 1 -------------------

neural and Bayes nets) but need more computation time during the

>> Tokens are: 
 ['neural', 'Bayes', 'nets', ')', 'need', 'computation', 'time']

>> Bigrams are: 
 [('neural', 'Bayes'), ('Bayes', 'nets'), ('nets', ')'), (')', 'need'), ('need', 'computation'), ('computation', 'time')]

>> Trigrams are: 
 [('neural', 'Bayes', 'nets'), ('Bayes', 'nets', ')'), ('nets', ')', 'need'), (')', 'need', 'computation'), ('need', 'computation', 'time')]

>> POS Tags are: 
 [('neural', 'JJ'), ('Bayes', 'NNP'), ('nets', 'NNS'), (')', ')'), ('need', 'VBP'), ('computation', 'NN'), ('time', 'NN')]

>> Noun Phrases are: 
 ['neural Bayes nets', 'computation time']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('neural', 'neural'), ('Bayes', 'bay'), ('nets', 'net'), (')', ')'), ('need', 'need'), ('computation', 'comput'), ('time', 'time')]

>> Stemming using Snowball Stemmer: 
 [('neural', 'neural'), ('Bayes', 'bay'), ('nets', 'net'), (')', ')'), ('need', 'need'), ('computation', 'comput'), ('time', 'time')]

>> Lemmatization: 
 [('neural', 'neural'), ('Bayes', 'Bayes'), ('nets', 'net'), (')', ')'), ('need', 'need'), ('computation', 'computation'), ('time', 'time')]



========================================== PARAGRAPH 417 ===========================================

classification process. Nearest Neighbor algorithm is an example  

------------------- Sentence 1 -------------------

classification process.

>> Tokens are: 
 ['classification', 'process', '.']

>> Bigrams are: 
 [('classification', 'process'), ('process', '.')]

>> Trigrams are: 
 [('classification', 'process', '.')]

>> POS Tags are: 
 [('classification', 'NN'), ('process', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['classification process']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('classification', 'classif'), ('process', 'process'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('classification', 'classif'), ('process', 'process'), ('.', '.')]

>> Lemmatization: 
 [('classification', 'classification'), ('process', 'process'), ('.', '.')]


------------------- Sentence 2 -------------------

Nearest Neighbor algorithm is an example

>> Tokens are: 
 ['Nearest', 'Neighbor', 'algorithm', 'example']

>> Bigrams are: 
 [('Nearest', 'Neighbor'), ('Neighbor', 'algorithm'), ('algorithm', 'example')]

>> Trigrams are: 
 [('Nearest', 'Neighbor', 'algorithm'), ('Neighbor', 'algorithm', 'example')]

>> POS Tags are: 
 [('Nearest', 'JJS'), ('Neighbor', 'NN'), ('algorithm', 'NN'), ('example', 'NN')]

>> Noun Phrases are: 
 ['Neighbor algorithm example']

>> Named Entities are: 
 [('GPE', 'Nearest'), ('ORGANIZATION', 'Neighbor')] 

>> Stemming using Porter Stemmer: 
 [('Nearest', 'nearest'), ('Neighbor', 'neighbor'), ('algorithm', 'algorithm'), ('example', 'exampl')]

>> Stemming using Snowball Stemmer: 
 [('Nearest', 'nearest'), ('Neighbor', 'neighbor'), ('algorithm', 'algorithm'), ('example', 'exampl')]

>> Lemmatization: 
 [('Nearest', 'Nearest'), ('Neighbor', 'Neighbor'), ('algorithm', 'algorithm'), ('example', 'example')]



========================================== PARAGRAPH 418 ===========================================

of instance-based learning algorithms [1]. Aha [25] and De et. al  

------------------- Sentence 1 -------------------

of instance-based learning algorithms [1].

>> Tokens are: 
 ['instance-based', 'learning', 'algorithms', '[', '1', ']', '.']

>> Bigrams are: 
 [('instance-based', 'learning'), ('learning', 'algorithms'), ('algorithms', '['), ('[', '1'), ('1', ']'), (']', '.')]

>> Trigrams are: 
 [('instance-based', 'learning', 'algorithms'), ('learning', 'algorithms', '['), ('algorithms', '[', '1'), ('[', '1', ']'), ('1', ']', '.')]

>> POS Tags are: 
 [('instance-based', 'JJ'), ('learning', 'VBG'), ('algorithms', 'JJ'), ('[', '$'), ('1', 'CD'), (']', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 [']']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('instance-based', 'instance-bas'), ('learning', 'learn'), ('algorithms', 'algorithm'), ('[', '['), ('1', '1'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('instance-based', 'instance-bas'), ('learning', 'learn'), ('algorithms', 'algorithm'), ('[', '['), ('1', '1'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('instance-based', 'instance-based'), ('learning', 'learning'), ('algorithms', 'algorithm'), ('[', '['), ('1', '1'), (']', ']'), ('.', '.')]


------------------- Sentence 2 -------------------

Aha [25] and De et.

>> Tokens are: 
 ['Aha', '[', '25', ']', 'De', 'et', '.']

>> Bigrams are: 
 [('Aha', '['), ('[', '25'), ('25', ']'), (']', 'De'), ('De', 'et'), ('et', '.')]

>> Trigrams are: 
 [('Aha', '[', '25'), ('[', '25', ']'), ('25', ']', 'De'), (']', 'De', 'et'), ('De', 'et', '.')]

>> POS Tags are: 
 [('Aha', 'NNP'), ('[', 'VBD'), ('25', 'CD'), (']', 'NNP'), ('De', 'NNP'), ('et', 'FW'), ('.', '.')]

>> Noun Phrases are: 
 ['Aha', '] De']

>> Named Entities are: 
 [('PERSON', 'Aha')] 

>> Stemming using Porter Stemmer: 
 [('Aha', 'aha'), ('[', '['), ('25', '25'), (']', ']'), ('De', 'de'), ('et', 'et'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Aha', 'aha'), ('[', '['), ('25', '25'), (']', ']'), ('De', 'de'), ('et', 'et'), ('.', '.')]

>> Lemmatization: 
 [('Aha', 'Aha'), ('[', '['), ('25', '25'), (']', ']'), ('De', 'De'), ('et', 'et'), ('.', '.')]


------------------- Sentence 3 -------------------

al

>> Tokens are: 
 ['al']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('al', 'NN')]

>> Noun Phrases are: 
 ['al']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('al', 'al')]

>> Stemming using Snowball Stemmer: 
 [('al', 'al')]

>> Lemmatization: 
 [('al', 'al')]



========================================== PARAGRAPH 419 ===========================================

[26] discussed the instance-based learning classifiers.  

------------------- Sentence 1 -------------------

[26] discussed the instance-based learning classifiers.

>> Tokens are: 
 ['[', '26', ']', 'discussed', 'instance-based', 'learning', 'classifiers', '.']

>> Bigrams are: 
 [('[', '26'), ('26', ']'), (']', 'discussed'), ('discussed', 'instance-based'), ('instance-based', 'learning'), ('learning', 'classifiers'), ('classifiers', '.')]

>> Trigrams are: 
 [('[', '26', ']'), ('26', ']', 'discussed'), (']', 'discussed', 'instance-based'), ('discussed', 'instance-based', 'learning'), ('instance-based', 'learning', 'classifiers'), ('learning', 'classifiers', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('26', 'CD'), (']', 'NNS'), ('discussed', 'VBN'), ('instance-based', 'JJ'), ('learning', 'NN'), ('classifiers', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 [']', 'instance-based learning classifiers']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('26', '26'), (']', ']'), ('discussed', 'discuss'), ('instance-based', 'instance-bas'), ('learning', 'learn'), ('classifiers', 'classifi'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('26', '26'), (']', ']'), ('discussed', 'discuss'), ('instance-based', 'instance-bas'), ('learning', 'learn'), ('classifiers', 'classifi'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('26', '26'), (']', ']'), ('discussed', 'discussed'), ('instance-based', 'instance-based'), ('learning', 'learning'), ('classifiers', 'classifier'), ('.', '.')]



========================================== PARAGRAPH 420 ===========================================

k-Nearest-Neighbor (kNN) classification  is one of the most  

------------------- Sentence 1 -------------------

k-Nearest-Neighbor (kNN) classification  is one of the most

>> Tokens are: 
 ['k-Nearest-Neighbor', '(', 'kNN', ')', 'classification', 'one']

>> Bigrams are: 
 [('k-Nearest-Neighbor', '('), ('(', 'kNN'), ('kNN', ')'), (')', 'classification'), ('classification', 'one')]

>> Trigrams are: 
 [('k-Nearest-Neighbor', '(', 'kNN'), ('(', 'kNN', ')'), ('kNN', ')', 'classification'), (')', 'classification', 'one')]

>> POS Tags are: 
 [('k-Nearest-Neighbor', 'NN'), ('(', '('), ('kNN', 'NN'), (')', ')'), ('classification', 'NN'), ('one', 'CD')]

>> Noun Phrases are: 
 ['k-Nearest-Neighbor', 'kNN', 'classification']

>> Named Entities are: 
 [('ORGANIZATION', 'kNN')] 

>> Stemming using Porter Stemmer: 
 [('k-Nearest-Neighbor', 'k-nearest-neighbor'), ('(', '('), ('kNN', 'knn'), (')', ')'), ('classification', 'classif'), ('one', 'one')]

>> Stemming using Snowball Stemmer: 
 [('k-Nearest-Neighbor', 'k-nearest-neighbor'), ('(', '('), ('kNN', 'knn'), (')', ')'), ('classification', 'classif'), ('one', 'one')]

>> Lemmatization: 
 [('k-Nearest-Neighbor', 'k-Nearest-Neighbor'), ('(', '('), ('kNN', 'kNN'), (')', ')'), ('classification', 'classification'), ('one', 'one')]



========================================== PARAGRAPH 421 ===========================================

widely used method for a classification of objects when there is  

------------------- Sentence 1 -------------------

widely used method for a classification of objects when there is

>> Tokens are: 
 ['widely', 'used', 'method', 'classification', 'objects']

>> Bigrams are: 
 [('widely', 'used'), ('used', 'method'), ('method', 'classification'), ('classification', 'objects')]

>> Trigrams are: 
 [('widely', 'used', 'method'), ('used', 'method', 'classification'), ('method', 'classification', 'objects')]

>> POS Tags are: 
 [('widely', 'RB'), ('used', 'VBN'), ('method', 'NN'), ('classification', 'NN'), ('objects', 'NNS')]

>> Noun Phrases are: 
 ['method classification objects']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('widely', 'wide'), ('used', 'use'), ('method', 'method'), ('classification', 'classif'), ('objects', 'object')]

>> Stemming using Snowball Stemmer: 
 [('widely', 'wide'), ('used', 'use'), ('method', 'method'), ('classification', 'classif'), ('objects', 'object')]

>> Lemmatization: 
 [('widely', 'widely'), ('used', 'used'), ('method', 'method'), ('classification', 'classification'), ('objects', 'object')]



========================================== PARAGRAPH 422 ===========================================

little or no prior knowledge about the distribution of the data.  

------------------- Sentence 1 -------------------

little or no prior knowledge about the distribution of the data.

>> Tokens are: 
 ['little', 'prior', 'knowledge', 'distribution', 'data', '.']

>> Bigrams are: 
 [('little', 'prior'), ('prior', 'knowledge'), ('knowledge', 'distribution'), ('distribution', 'data'), ('data', '.')]

>> Trigrams are: 
 [('little', 'prior', 'knowledge'), ('prior', 'knowledge', 'distribution'), ('knowledge', 'distribution', 'data'), ('distribution', 'data', '.')]

>> POS Tags are: 
 [('little', 'JJ'), ('prior', 'JJ'), ('knowledge', 'NN'), ('distribution', 'NN'), ('data', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['little prior knowledge distribution data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('little', 'littl'), ('prior', 'prior'), ('knowledge', 'knowledg'), ('distribution', 'distribut'), ('data', 'data'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('little', 'littl'), ('prior', 'prior'), ('knowledge', 'knowledg'), ('distribution', 'distribut'), ('data', 'data'), ('.', '.')]

>> Lemmatization: 
 [('little', 'little'), ('prior', 'prior'), ('knowledge', 'knowledge'), ('distribution', 'distribution'), ('data', 'data'), ('.', '.')]



========================================== PARAGRAPH 423 ===========================================

kNN is a good choice to perform discriminate analysis when  

------------------- Sentence 1 -------------------

kNN is a good choice to perform discriminate analysis when

>> Tokens are: 
 ['kNN', 'good', 'choice', 'perform', 'discriminate', 'analysis']

>> Bigrams are: 
 [('kNN', 'good'), ('good', 'choice'), ('choice', 'perform'), ('perform', 'discriminate'), ('discriminate', 'analysis')]

>> Trigrams are: 
 [('kNN', 'good', 'choice'), ('good', 'choice', 'perform'), ('choice', 'perform', 'discriminate'), ('perform', 'discriminate', 'analysis')]

>> POS Tags are: 
 [('kNN', 'RB'), ('good', 'JJ'), ('choice', 'NN'), ('perform', 'NN'), ('discriminate', 'NN'), ('analysis', 'NN')]

>> Noun Phrases are: 
 ['good choice perform discriminate analysis']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('kNN', 'knn'), ('good', 'good'), ('choice', 'choic'), ('perform', 'perform'), ('discriminate', 'discrimin'), ('analysis', 'analysi')]

>> Stemming using Snowball Stemmer: 
 [('kNN', 'knn'), ('good', 'good'), ('choice', 'choic'), ('perform', 'perform'), ('discriminate', 'discrimin'), ('analysis', 'analysi')]

>> Lemmatization: 
 [('kNN', 'kNN'), ('good', 'good'), ('choice', 'choice'), ('perform', 'perform'), ('discriminate', 'discriminate'), ('analysis', 'analysis')]



========================================== PARAGRAPH 424 ===========================================

reliable parametric estimates of probability densities are  

------------------- Sentence 1 -------------------

reliable parametric estimates of probability densities are

>> Tokens are: 
 ['reliable', 'parametric', 'estimates', 'probability', 'densities']

>> Bigrams are: 
 [('reliable', 'parametric'), ('parametric', 'estimates'), ('estimates', 'probability'), ('probability', 'densities')]

>> Trigrams are: 
 [('reliable', 'parametric', 'estimates'), ('parametric', 'estimates', 'probability'), ('estimates', 'probability', 'densities')]

>> POS Tags are: 
 [('reliable', 'JJ'), ('parametric', 'NN'), ('estimates', 'NNS'), ('probability', 'NN'), ('densities', 'NNS')]

>> Noun Phrases are: 
 ['reliable parametric estimates probability densities']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('reliable', 'reliabl'), ('parametric', 'parametr'), ('estimates', 'estim'), ('probability', 'probabl'), ('densities', 'densiti')]

>> Stemming using Snowball Stemmer: 
 [('reliable', 'reliabl'), ('parametric', 'parametr'), ('estimates', 'estim'), ('probability', 'probabl'), ('densities', 'densiti')]

>> Lemmatization: 
 [('reliable', 'reliable'), ('parametric', 'parametric'), ('estimates', 'estimate'), ('probability', 'probability'), ('densities', 'density')]



========================================== PARAGRAPH 425 ===========================================

unknown or difficult to determine[27].  

------------------- Sentence 1 -------------------

unknown or difficult to determine[27].

>> Tokens are: 
 ['unknown', 'difficult', 'determine', '[', '27', ']', '.']

>> Bigrams are: 
 [('unknown', 'difficult'), ('difficult', 'determine'), ('determine', '['), ('[', '27'), ('27', ']'), (']', '.')]

>> Trigrams are: 
 [('unknown', 'difficult', 'determine'), ('difficult', 'determine', '['), ('determine', '[', '27'), ('[', '27', ']'), ('27', ']', '.')]

>> POS Tags are: 
 [('unknown', 'JJ'), ('difficult', 'JJ'), ('determine', 'NN'), ('[', '$'), ('27', 'CD'), (']', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['unknown difficult determine', ']']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('unknown', 'unknown'), ('difficult', 'difficult'), ('determine', 'determin'), ('[', '['), ('27', '27'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('unknown', 'unknown'), ('difficult', 'difficult'), ('determine', 'determin'), ('[', '['), ('27', '27'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('unknown', 'unknown'), ('difficult', 'difficult'), ('determine', 'determine'), ('[', '['), ('27', '27'), (']', ']'), ('.', '.')]



========================================== PARAGRAPH 426 ===========================================

kNN is a example of supervised learning algorithm  in which  

------------------- Sentence 1 -------------------

kNN is a example of supervised learning algorithm  in which

>> Tokens are: 
 ['kNN', 'example', 'supervised', 'learning', 'algorithm']

>> Bigrams are: 
 [('kNN', 'example'), ('example', 'supervised'), ('supervised', 'learning'), ('learning', 'algorithm')]

>> Trigrams are: 
 [('kNN', 'example', 'supervised'), ('example', 'supervised', 'learning'), ('supervised', 'learning', 'algorithm')]

>> POS Tags are: 
 [('kNN', 'JJ'), ('example', 'NN'), ('supervised', 'VBD'), ('learning', 'VBG'), ('algorithm', 'NN')]

>> Noun Phrases are: 
 ['kNN example', 'algorithm']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('kNN', 'knn'), ('example', 'exampl'), ('supervised', 'supervis'), ('learning', 'learn'), ('algorithm', 'algorithm')]

>> Stemming using Snowball Stemmer: 
 [('kNN', 'knn'), ('example', 'exampl'), ('supervised', 'supervis'), ('learning', 'learn'), ('algorithm', 'algorithm')]

>> Lemmatization: 
 [('kNN', 'kNN'), ('example', 'example'), ('supervised', 'supervised'), ('learning', 'learning'), ('algorithm', 'algorithm')]



========================================== PARAGRAPH 427 ===========================================

the result of new instance query is classified based on majority  

------------------- Sentence 1 -------------------

the result of new instance query is classified based on majority

>> Tokens are: 
 ['result', 'new', 'instance', 'query', 'classified', 'based', 'majority']

>> Bigrams are: 
 [('result', 'new'), ('new', 'instance'), ('instance', 'query'), ('query', 'classified'), ('classified', 'based'), ('based', 'majority')]

>> Trigrams are: 
 [('result', 'new', 'instance'), ('new', 'instance', 'query'), ('instance', 'query', 'classified'), ('query', 'classified', 'based'), ('classified', 'based', 'majority')]

>> POS Tags are: 
 [('result', 'VB'), ('new', 'JJ'), ('instance', 'NN'), ('query', 'NN'), ('classified', 'VBD'), ('based', 'VBN'), ('majority', 'NN')]

>> Noun Phrases are: 
 ['new instance query', 'majority']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('result', 'result'), ('new', 'new'), ('instance', 'instanc'), ('query', 'queri'), ('classified', 'classifi'), ('based', 'base'), ('majority', 'major')]

>> Stemming using Snowball Stemmer: 
 [('result', 'result'), ('new', 'new'), ('instance', 'instanc'), ('query', 'queri'), ('classified', 'classifi'), ('based', 'base'), ('majority', 'major')]

>> Lemmatization: 
 [('result', 'result'), ('new', 'new'), ('instance', 'instance'), ('query', 'query'), ('classified', 'classified'), ('based', 'based'), ('majority', 'majority')]



========================================== PARAGRAPH 428 ===========================================

of k-nearest neighbor category. The core function of algorithm is  

------------------- Sentence 1 -------------------

of k-nearest neighbor category.

>> Tokens are: 
 ['k-nearest', 'neighbor', 'category', '.']

>> Bigrams are: 
 [('k-nearest', 'neighbor'), ('neighbor', 'category'), ('category', '.')]

>> Trigrams are: 
 [('k-nearest', 'neighbor', 'category'), ('neighbor', 'category', '.')]

>> POS Tags are: 
 [('k-nearest', 'JJ'), ('neighbor', 'NN'), ('category', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['k-nearest neighbor category']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('k-nearest', 'k-nearest'), ('neighbor', 'neighbor'), ('category', 'categori'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('k-nearest', 'k-nearest'), ('neighbor', 'neighbor'), ('category', 'categori'), ('.', '.')]

>> Lemmatization: 
 [('k-nearest', 'k-nearest'), ('neighbor', 'neighbor'), ('category', 'category'), ('.', '.')]


------------------- Sentence 2 -------------------

The core function of algorithm is

>> Tokens are: 
 ['The', 'core', 'function', 'algorithm']

>> Bigrams are: 
 [('The', 'core'), ('core', 'function'), ('function', 'algorithm')]

>> Trigrams are: 
 [('The', 'core', 'function'), ('core', 'function', 'algorithm')]

>> POS Tags are: 
 [('The', 'DT'), ('core', 'NN'), ('function', 'NN'), ('algorithm', 'NN')]

>> Noun Phrases are: 
 ['The core function algorithm']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('core', 'core'), ('function', 'function'), ('algorithm', 'algorithm')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('core', 'core'), ('function', 'function'), ('algorithm', 'algorithm')]

>> Lemmatization: 
 [('The', 'The'), ('core', 'core'), ('function', 'function'), ('algorithm', 'algorithm')]



========================================== PARAGRAPH 429 ===========================================

to classify a new object based on attributes and training samples.  

------------------- Sentence 1 -------------------

to classify a new object based on attributes and training samples.

>> Tokens are: 
 ['classify', 'new', 'object', 'based', 'attributes', 'training', 'samples', '.']

>> Bigrams are: 
 [('classify', 'new'), ('new', 'object'), ('object', 'based'), ('based', 'attributes'), ('attributes', 'training'), ('training', 'samples'), ('samples', '.')]

>> Trigrams are: 
 [('classify', 'new', 'object'), ('new', 'object', 'based'), ('object', 'based', 'attributes'), ('based', 'attributes', 'training'), ('attributes', 'training', 'samples'), ('training', 'samples', '.')]

>> POS Tags are: 
 [('classify', 'VB'), ('new', 'JJ'), ('object', 'NN'), ('based', 'VBN'), ('attributes', 'VBZ'), ('training', 'VBG'), ('samples', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['new object', 'samples']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('classify', 'classifi'), ('new', 'new'), ('object', 'object'), ('based', 'base'), ('attributes', 'attribut'), ('training', 'train'), ('samples', 'sampl'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('classify', 'classifi'), ('new', 'new'), ('object', 'object'), ('based', 'base'), ('attributes', 'attribut'), ('training', 'train'), ('samples', 'sampl'), ('.', '.')]

>> Lemmatization: 
 [('classify', 'classify'), ('new', 'new'), ('object', 'object'), ('based', 'based'), ('attributes', 'attribute'), ('training', 'training'), ('samples', 'sample'), ('.', '.')]



========================================== PARAGRAPH 430 ===========================================

Here the classification is using majority vote among the  

------------------- Sentence 1 -------------------

Here the classification is using majority vote among the

>> Tokens are: 
 ['Here', 'classification', 'using', 'majority', 'vote', 'among']

>> Bigrams are: 
 [('Here', 'classification'), ('classification', 'using'), ('using', 'majority'), ('majority', 'vote'), ('vote', 'among')]

>> Trigrams are: 
 [('Here', 'classification', 'using'), ('classification', 'using', 'majority'), ('using', 'majority', 'vote'), ('majority', 'vote', 'among')]

>> POS Tags are: 
 [('Here', 'RB'), ('classification', 'NN'), ('using', 'VBG'), ('majority', 'NN'), ('vote', 'NN'), ('among', 'IN')]

>> Noun Phrases are: 
 ['classification', 'majority vote']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Here', 'here'), ('classification', 'classif'), ('using', 'use'), ('majority', 'major'), ('vote', 'vote'), ('among', 'among')]

>> Stemming using Snowball Stemmer: 
 [('Here', 'here'), ('classification', 'classif'), ('using', 'use'), ('majority', 'major'), ('vote', 'vote'), ('among', 'among')]

>> Lemmatization: 
 [('Here', 'Here'), ('classification', 'classification'), ('using', 'using'), ('majority', 'majority'), ('vote', 'vote'), ('among', 'among')]



========================================== PARAGRAPH 431 ===========================================

classification of the k objects. For example we have conducted a  

------------------- Sentence 1 -------------------

classification of the k objects.

>> Tokens are: 
 ['classification', 'k', 'objects', '.']

>> Bigrams are: 
 [('classification', 'k'), ('k', 'objects'), ('objects', '.')]

>> Trigrams are: 
 [('classification', 'k', 'objects'), ('k', 'objects', '.')]

>> POS Tags are: 
 [('classification', 'NN'), ('k', 'NN'), ('objects', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['classification k objects']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('classification', 'classif'), ('k', 'k'), ('objects', 'object'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('classification', 'classif'), ('k', 'k'), ('objects', 'object'), ('.', '.')]

>> Lemmatization: 
 [('classification', 'classification'), ('k', 'k'), ('objects', 'object'), ('.', '.')]


------------------- Sentence 2 -------------------

For example we have conducted a

>> Tokens are: 
 ['For', 'example', 'conducted']

>> Bigrams are: 
 [('For', 'example'), ('example', 'conducted')]

>> Trigrams are: 
 [('For', 'example', 'conducted')]

>> POS Tags are: 
 [('For', 'IN'), ('example', 'NN'), ('conducted', 'VBN')]

>> Noun Phrases are: 
 ['example']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('For', 'for'), ('example', 'exampl'), ('conducted', 'conduct')]

>> Stemming using Snowball Stemmer: 
 [('For', 'for'), ('example', 'exampl'), ('conducted', 'conduct')]

>> Lemmatization: 
 [('For', 'For'), ('example', 'example'), ('conducted', 'conducted')]



========================================== PARAGRAPH 432 ===========================================

survey on consumption of any particular item to know its worth  

------------------- Sentence 1 -------------------

survey on consumption of any particular item to know its worth

>> Tokens are: 
 ['survey', 'consumption', 'particular', 'item', 'know', '', 'worth']

>> Bigrams are: 
 [('survey', 'consumption'), ('consumption', 'particular'), ('particular', 'item'), ('item', 'know'), ('know', ''), ('', 'worth')]

>> Trigrams are: 
 [('survey', 'consumption', 'particular'), ('consumption', 'particular', 'item'), ('particular', 'item', 'know'), ('item', 'know', ''), ('know', '', 'worth')]

>> POS Tags are: 
 [('survey', 'NN'), ('consumption', 'NN'), ('particular', 'JJ'), ('item', 'NN'), ('know', 'VBP'), ('', 'CD'), ('worth', 'NN')]

>> Noun Phrases are: 
 ['survey consumption', 'particular item', 'worth']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('survey', 'survey'), ('consumption', 'consumpt'), ('particular', 'particular'), ('item', 'item'), ('know', 'know'), ('', ''), ('worth', 'worth')]

>> Stemming using Snowball Stemmer: 
 [('survey', 'survey'), ('consumption', 'consumpt'), ('particular', 'particular'), ('item', 'item'), ('know', 'know'), ('', ''), ('worth', 'worth')]

>> Lemmatization: 
 [('survey', 'survey'), ('consumption', 'consumption'), ('particular', 'particular'), ('item', 'item'), ('know', 'know'), ('', ''), ('worth', 'worth')]



========================================== PARAGRAPH 433 ===========================================

in the market. Below is a sample training table.  

------------------- Sentence 1 -------------------

in the market.

>> Tokens are: 
 ['market', '.']

>> Bigrams are: 
 [('market', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('market', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['market']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('market', 'market'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('market', 'market'), ('.', '.')]

>> Lemmatization: 
 [('market', 'market'), ('.', '.')]


------------------- Sentence 2 -------------------

Below is a sample training table.

>> Tokens are: 
 ['Below', 'sample', 'training', 'table', '.']

>> Bigrams are: 
 [('Below', 'sample'), ('sample', 'training'), ('training', 'table'), ('table', '.')]

>> Trigrams are: 
 [('Below', 'sample', 'training'), ('sample', 'training', 'table'), ('training', 'table', '.')]

>> POS Tags are: 
 [('Below', 'IN'), ('sample', 'JJ'), ('training', 'NN'), ('table', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['sample training table']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Below', 'below'), ('sample', 'sampl'), ('training', 'train'), ('table', 'tabl'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Below', 'below'), ('sample', 'sampl'), ('training', 'train'), ('table', 'tabl'), ('.', '.')]

>> Lemmatization: 
 [('Below', 'Below'), ('sample', 'sample'), ('training', 'training'), ('table', 'table'), ('.', '.')]



========================================== PARAGRAPH 434 ===========================================

Table.3. Training sample  

------------------- Sentence 1 -------------------

Table.3.

>> Tokens are: 
 ['Table.3', '.']

>> Bigrams are: 
 [('Table.3', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Table.3', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Table.3']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Table.3', 'table.3'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Table.3', 'table.3'), ('.', '.')]

>> Lemmatization: 
 [('Table.3', 'Table.3'), ('.', '.')]


------------------- Sentence 2 -------------------

Training sample

>> Tokens are: 
 ['Training', 'sample']

>> Bigrams are: 
 [('Training', 'sample')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Training', 'VBG'), ('sample', 'NN')]

>> Noun Phrases are: 
 ['sample']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Training', 'train'), ('sample', 'sampl')]

>> Stemming using Snowball Stemmer: 
 [('Training', 'train'), ('sample', 'sampl')]

>> Lemmatization: 
 [('Training', 'Training'), ('sample', 'sample')]



========================================== PARAGRAPH 435 ===========================================

X1 X2 Result  

------------------- Sentence 1 -------------------

X1 X2 Result

>> Tokens are: 
 ['X1', 'X2', 'Result']

>> Bigrams are: 
 [('X1', 'X2'), ('X2', 'Result')]

>> Trigrams are: 
 [('X1', 'X2', 'Result')]

>> POS Tags are: 
 [('X1', 'NN'), ('X2', 'NNP'), ('Result', 'NNP')]

>> Noun Phrases are: 
 ['X1 X2 Result']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('X1', 'x1'), ('X2', 'x2'), ('Result', 'result')]

>> Stemming using Snowball Stemmer: 
 [('X1', 'x1'), ('X2', 'x2'), ('Result', 'result')]

>> Lemmatization: 
 [('X1', 'X1'), ('X2', 'X2'), ('Result', 'Result')]



========================================== PARAGRAPH 436 ===========================================

8 8 NO  

------------------- Sentence 1 -------------------

8 8 NO

>> Tokens are: 
 ['8', '8', 'NO']

>> Bigrams are: 
 [('8', '8'), ('8', 'NO')]

>> Trigrams are: 
 [('8', '8', 'NO')]

>> POS Tags are: 
 [('8', 'CD'), ('8', 'CD'), ('NO', 'NN')]

>> Noun Phrases are: 
 ['NO']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('8', '8'), ('8', '8'), ('NO', 'no')]

>> Stemming using Snowball Stemmer: 
 [('8', '8'), ('8', '8'), ('NO', 'no')]

>> Lemmatization: 
 [('8', '8'), ('8', '8'), ('NO', 'NO')]



========================================== PARAGRAPH 437 ===========================================

8 5 NO  

------------------- Sentence 1 -------------------

8 5 NO

>> Tokens are: 
 ['8', '5', 'NO']

>> Bigrams are: 
 [('8', '5'), ('5', 'NO')]

>> Trigrams are: 
 [('8', '5', 'NO')]

>> POS Tags are: 
 [('8', 'CD'), ('5', 'CD'), ('NO', 'NN')]

>> Noun Phrases are: 
 ['NO']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('8', '8'), ('5', '5'), ('NO', 'no')]

>> Stemming using Snowball Stemmer: 
 [('8', '8'), ('5', '5'), ('NO', 'no')]

>> Lemmatization: 
 [('8', '8'), ('5', '5'), ('NO', 'NO')]



========================================== PARAGRAPH 438 ===========================================

4 5 Yes  

------------------- Sentence 1 -------------------

4 5 Yes

>> Tokens are: 
 ['4', '5', 'Yes']

>> Bigrams are: 
 [('4', '5'), ('5', 'Yes')]

>> Trigrams are: 
 [('4', '5', 'Yes')]

>> POS Tags are: 
 [('4', 'CD'), ('5', 'CD'), ('Yes', 'NN')]

>> Noun Phrases are: 
 ['Yes']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('4', '4'), ('5', '5'), ('Yes', 'ye')]

>> Stemming using Snowball Stemmer: 
 [('4', '4'), ('5', '5'), ('Yes', 'yes')]

>> Lemmatization: 
 [('4', '4'), ('5', '5'), ('Yes', 'Yes')]



========================================== PARAGRAPH 439 ===========================================

1 5 Yes  

------------------- Sentence 1 -------------------

1 5 Yes

>> Tokens are: 
 ['1', '5', 'Yes']

>> Bigrams are: 
 [('1', '5'), ('5', 'Yes')]

>> Trigrams are: 
 [('1', '5', 'Yes')]

>> POS Tags are: 
 [('1', 'CD'), ('5', 'CD'), ('Yes', 'NN')]

>> Noun Phrases are: 
 ['Yes']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('1', '1'), ('5', '5'), ('Yes', 'ye')]

>> Stemming using Snowball Stemmer: 
 [('1', '1'), ('5', '5'), ('Yes', 'yes')]

>> Lemmatization: 
 [('1', '1'), ('5', '5'), ('Yes', 'Yes')]



========================================== PARAGRAPH 440 ===========================================

The outcome Yes or No is depended on the variable  

------------------- Sentence 1 -------------------

The outcome Yes or No is depended on the variable

>> Tokens are: 
 ['The', 'outcome', '', 'Yes', '', '', 'No', '', 'depended', 'variable']

>> Bigrams are: 
 [('The', 'outcome'), ('outcome', ''), ('', 'Yes'), ('Yes', ''), ('', ''), ('', 'No'), ('No', ''), ('', 'depended'), ('depended', 'variable')]

>> Trigrams are: 
 [('The', 'outcome', ''), ('outcome', '', 'Yes'), ('', 'Yes', ''), ('Yes', '', ''), ('', '', 'No'), ('', 'No', ''), ('No', '', 'depended'), ('', 'depended', 'variable')]

>> POS Tags are: 
 [('The', 'DT'), ('outcome', 'NN'), ('', 'NNP'), ('Yes', 'NNP'), ('', 'NNP'), ('', 'NNP'), ('No', 'NNP'), ('', 'NNP'), ('depended', 'VBD'), ('variable', 'JJ')]

>> Noun Phrases are: 
 ['The outcome  Yes   No ']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('outcome', 'outcom'), ('', ''), ('Yes', 'ye'), ('', ''), ('', ''), ('No', 'no'), ('', ''), ('depended', 'depend'), ('variable', 'variabl')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('outcome', 'outcom'), ('', ''), ('Yes', 'yes'), ('', ''), ('', ''), ('No', 'no'), ('', ''), ('depended', 'depend'), ('variable', 'variabl')]

>> Lemmatization: 
 [('The', 'The'), ('outcome', 'outcome'), ('', ''), ('Yes', 'Yes'), ('', ''), ('', ''), ('No', 'No'), ('', ''), ('depended', 'depended'), ('variable', 'variable')]



========================================== PARAGRAPH 441 ===========================================

values of X1 and X2, so if we want to know the outcome of that  

------------------- Sentence 1 -------------------

values of X1 and X2, so if we want to know the outcome of that

>> Tokens are: 
 ['values', 'X1', 'X2', ',', 'want', 'know', 'outcome']

>> Bigrams are: 
 [('values', 'X1'), ('X1', 'X2'), ('X2', ','), (',', 'want'), ('want', 'know'), ('know', 'outcome')]

>> Trigrams are: 
 [('values', 'X1', 'X2'), ('X1', 'X2', ','), ('X2', ',', 'want'), (',', 'want', 'know'), ('want', 'know', 'outcome')]

>> POS Tags are: 
 [('values', 'NNS'), ('X1', 'NNP'), ('X2', 'NNP'), (',', ','), ('want', 'VBP'), ('know', 'JJ'), ('outcome', 'NN')]

>> Noun Phrases are: 
 ['values X1 X2', 'know outcome']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('values', 'valu'), ('X1', 'x1'), ('X2', 'x2'), (',', ','), ('want', 'want'), ('know', 'know'), ('outcome', 'outcom')]

>> Stemming using Snowball Stemmer: 
 [('values', 'valu'), ('X1', 'x1'), ('X2', 'x2'), (',', ','), ('want', 'want'), ('know', 'know'), ('outcome', 'outcom')]

>> Lemmatization: 
 [('values', 'value'), ('X1', 'X1'), ('X2', 'X2'), (',', ','), ('want', 'want'), ('know', 'know'), ('outcome', 'outcome')]



========================================== PARAGRAPH 442 ===========================================

combination which is not available in data table, for example,  

------------------- Sentence 1 -------------------

combination which is not available in data table, for example,

>> Tokens are: 
 ['combination', 'available', 'data', 'table', ',', 'example', ',']

>> Bigrams are: 
 [('combination', 'available'), ('available', 'data'), ('data', 'table'), ('table', ','), (',', 'example'), ('example', ',')]

>> Trigrams are: 
 [('combination', 'available', 'data'), ('available', 'data', 'table'), ('data', 'table', ','), ('table', ',', 'example'), (',', 'example', ',')]

>> POS Tags are: 
 [('combination', 'NN'), ('available', 'JJ'), ('data', 'NNS'), ('table', 'NN'), (',', ','), ('example', 'NN'), (',', ',')]

>> Noun Phrases are: 
 ['combination', 'available data table', 'example']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('combination', 'combin'), ('available', 'avail'), ('data', 'data'), ('table', 'tabl'), (',', ','), ('example', 'exampl'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('combination', 'combin'), ('available', 'avail'), ('data', 'data'), ('table', 'tabl'), (',', ','), ('example', 'exampl'), (',', ',')]

>> Lemmatization: 
 [('combination', 'combination'), ('available', 'available'), ('data', 'data'), ('table', 'table'), (',', ','), ('example', 'example'), (',', ',')]



========================================== PARAGRAPH 443 ===========================================

when  x1 = 4, and x2 = 8 then without doing lengthy exercise of  

------------------- Sentence 1 -------------------

when  x1 = 4, and x2 = 8 then without doing lengthy exercise of

>> Tokens are: 
 ['x1', '=', '4', ',', 'x2', '=', '8', 'without', 'lengthy', 'exercise']

>> Bigrams are: 
 [('x1', '='), ('=', '4'), ('4', ','), (',', 'x2'), ('x2', '='), ('=', '8'), ('8', 'without'), ('without', 'lengthy'), ('lengthy', 'exercise')]

>> Trigrams are: 
 [('x1', '=', '4'), ('=', '4', ','), ('4', ',', 'x2'), (',', 'x2', '='), ('x2', '=', '8'), ('=', '8', 'without'), ('8', 'without', 'lengthy'), ('without', 'lengthy', 'exercise')]

>> POS Tags are: 
 [('x1', 'JJ'), ('=', 'NN'), ('4', 'CD'), (',', ','), ('x2', 'NNP'), ('=', 'NNP'), ('8', 'CD'), ('without', 'IN'), ('lengthy', 'JJ'), ('exercise', 'NN')]

>> Noun Phrases are: 
 ['x1 =', 'x2 =', 'lengthy exercise']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('x1', 'x1'), ('=', '='), ('4', '4'), (',', ','), ('x2', 'x2'), ('=', '='), ('8', '8'), ('without', 'without'), ('lengthy', 'lengthi'), ('exercise', 'exercis')]

>> Stemming using Snowball Stemmer: 
 [('x1', 'x1'), ('=', '='), ('4', '4'), (',', ','), ('x2', 'x2'), ('=', '='), ('8', '8'), ('without', 'without'), ('lengthy', 'lengthi'), ('exercise', 'exercis')]

>> Lemmatization: 
 [('x1', 'x1'), ('=', '='), ('4', '4'), (',', ','), ('x2', 'x2'), ('=', '='), ('8', '8'), ('without', 'without'), ('lengthy', 'lengthy'), ('exercise', 'exercise')]



========================================== PARAGRAPH 444 ===========================================

conducting surveys, we can predict the results by using kNN  

------------------- Sentence 1 -------------------

conducting surveys, we can predict the results by using kNN

>> Tokens are: 
 ['conducting', 'surveys', ',', 'predict', 'results', 'using', 'kNN']

>> Bigrams are: 
 [('conducting', 'surveys'), ('surveys', ','), (',', 'predict'), ('predict', 'results'), ('results', 'using'), ('using', 'kNN')]

>> Trigrams are: 
 [('conducting', 'surveys', ','), ('surveys', ',', 'predict'), (',', 'predict', 'results'), ('predict', 'results', 'using'), ('results', 'using', 'kNN')]

>> POS Tags are: 
 [('conducting', 'VBG'), ('surveys', 'NNS'), (',', ','), ('predict', 'VBP'), ('results', 'NNS'), ('using', 'VBG'), ('kNN', 'NN')]

>> Noun Phrases are: 
 ['surveys', 'results', 'kNN']

>> Named Entities are: 
 [('ORGANIZATION', 'kNN')] 

>> Stemming using Porter Stemmer: 
 [('conducting', 'conduct'), ('surveys', 'survey'), (',', ','), ('predict', 'predict'), ('results', 'result'), ('using', 'use'), ('kNN', 'knn')]

>> Stemming using Snowball Stemmer: 
 [('conducting', 'conduct'), ('surveys', 'survey'), (',', ','), ('predict', 'predict'), ('results', 'result'), ('using', 'use'), ('kNN', 'knn')]

>> Lemmatization: 
 [('conducting', 'conducting'), ('surveys', 'survey'), (',', ','), ('predict', 'predict'), ('results', 'result'), ('using', 'using'), ('kNN', 'kNN')]



========================================== PARAGRAPH 445 ===========================================

classification method.  

------------------- Sentence 1 -------------------

classification method.

>> Tokens are: 
 ['classification', 'method', '.']

>> Bigrams are: 
 [('classification', 'method'), ('method', '.')]

>> Trigrams are: 
 [('classification', 'method', '.')]

>> POS Tags are: 
 [('classification', 'NN'), ('method', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['classification method']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('classification', 'classif'), ('method', 'method'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('classification', 'classif'), ('method', 'method'), ('.', '.')]

>> Lemmatization: 
 [('classification', 'classification'), ('method', 'method'), ('.', '.')]



========================================== PARAGRAPH 446 ===========================================

The below pseudo code is an example for the instance base  

------------------- Sentence 1 -------------------

The below pseudo code is an example for the instance base

>> Tokens are: 
 ['The', 'pseudo', 'code', 'example', 'instance', 'base']

>> Bigrams are: 
 [('The', 'pseudo'), ('pseudo', 'code'), ('code', 'example'), ('example', 'instance'), ('instance', 'base')]

>> Trigrams are: 
 [('The', 'pseudo', 'code'), ('pseudo', 'code', 'example'), ('code', 'example', 'instance'), ('example', 'instance', 'base')]

>> POS Tags are: 
 [('The', 'DT'), ('pseudo', 'NN'), ('code', 'NN'), ('example', 'NN'), ('instance', 'NN'), ('base', 'NN')]

>> Noun Phrases are: 
 ['The pseudo code example instance base']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('pseudo', 'pseudo'), ('code', 'code'), ('example', 'exampl'), ('instance', 'instanc'), ('base', 'base')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('pseudo', 'pseudo'), ('code', 'code'), ('example', 'exampl'), ('instance', 'instanc'), ('base', 'base')]

>> Lemmatization: 
 [('The', 'The'), ('pseudo', 'pseudo'), ('code', 'code'), ('example', 'example'), ('instance', 'instance'), ('base', 'base')]



========================================== PARAGRAPH 447 ===========================================

learning methods.  

------------------- Sentence 1 -------------------

learning methods.

>> Tokens are: 
 ['learning', 'methods', '.']

>> Bigrams are: 
 [('learning', 'methods'), ('methods', '.')]

>> Trigrams are: 
 [('learning', 'methods', '.')]

>> POS Tags are: 
 [('learning', 'VBG'), ('methods', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['methods']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('learning', 'learn'), ('methods', 'method'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('learning', 'learn'), ('methods', 'method'), ('.', '.')]

>> Lemmatization: 
 [('learning', 'learning'), ('methods', 'method'), ('.', '.')]



========================================== PARAGRAPH 448 ===========================================

  


========================================== PARAGRAPH 449 ===========================================

Fig.9. Pseudo-code for instance-based learners  

------------------- Sentence 1 -------------------

Fig.9.

>> Tokens are: 
 ['Fig.9', '.']

>> Bigrams are: 
 [('Fig.9', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Fig.9', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Fig.9']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Fig.9', 'fig.9'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Fig.9', 'fig.9'), ('.', '.')]

>> Lemmatization: 
 [('Fig.9', 'Fig.9'), ('.', '.')]


------------------- Sentence 2 -------------------

Pseudo-code for instance-based learners

>> Tokens are: 
 ['Pseudo-code', 'instance-based', 'learners']

>> Bigrams are: 
 [('Pseudo-code', 'instance-based'), ('instance-based', 'learners')]

>> Trigrams are: 
 [('Pseudo-code', 'instance-based', 'learners')]

>> POS Tags are: 
 [('Pseudo-code', 'JJ'), ('instance-based', 'JJ'), ('learners', 'NNS')]

>> Noun Phrases are: 
 ['Pseudo-code instance-based learners']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Pseudo-code', 'pseudo-cod'), ('instance-based', 'instance-bas'), ('learners', 'learner')]

>> Stemming using Snowball Stemmer: 
 [('Pseudo-code', 'pseudo-cod'), ('instance-based', 'instance-bas'), ('learners', 'learner')]

>> Lemmatization: 
 [('Pseudo-code', 'Pseudo-code'), ('instance-based', 'instance-based'), ('learners', 'learner')]



========================================== PARAGRAPH 450 ===========================================

6. SUPPORT VECTOR MACHINES  

------------------- Sentence 1 -------------------

6.

>> Tokens are: 
 ['6', '.']

>> Bigrams are: 
 [('6', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('6', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('6', '6'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('6', '6'), ('.', '.')]

>> Lemmatization: 
 [('6', '6'), ('.', '.')]


------------------- Sentence 2 -------------------

SUPPORT VECTOR MACHINES

>> Tokens are: 
 ['SUPPORT', 'VECTOR', 'MACHINES']

>> Bigrams are: 
 [('SUPPORT', 'VECTOR'), ('VECTOR', 'MACHINES')]

>> Trigrams are: 
 [('SUPPORT', 'VECTOR', 'MACHINES')]

>> POS Tags are: 
 [('SUPPORT', 'NNP'), ('VECTOR', 'NNP'), ('MACHINES', 'NNP')]

>> Noun Phrases are: 
 ['SUPPORT VECTOR MACHINES']

>> Named Entities are: 
 [('ORGANIZATION', 'SUPPORT'), ('ORGANIZATION', 'VECTOR')] 

>> Stemming using Porter Stemmer: 
 [('SUPPORT', 'support'), ('VECTOR', 'vector'), ('MACHINES', 'machin')]

>> Stemming using Snowball Stemmer: 
 [('SUPPORT', 'support'), ('VECTOR', 'vector'), ('MACHINES', 'machin')]

>> Lemmatization: 
 [('SUPPORT', 'SUPPORT'), ('VECTOR', 'VECTOR'), ('MACHINES', 'MACHINES')]



========================================== PARAGRAPH 451 ===========================================

Support Vector Machines (SVMs) are a set of supervised  

------------------- Sentence 1 -------------------

Support Vector Machines (SVMs) are a set of supervised

>> Tokens are: 
 ['Support', 'Vector', 'Machines', '(', 'SVMs', ')', 'set', 'supervised']

>> Bigrams are: 
 [('Support', 'Vector'), ('Vector', 'Machines'), ('Machines', '('), ('(', 'SVMs'), ('SVMs', ')'), (')', 'set'), ('set', 'supervised')]

>> Trigrams are: 
 [('Support', 'Vector', 'Machines'), ('Vector', 'Machines', '('), ('Machines', '(', 'SVMs'), ('(', 'SVMs', ')'), ('SVMs', ')', 'set'), (')', 'set', 'supervised')]

>> POS Tags are: 
 [('Support', 'NNP'), ('Vector', 'NNP'), ('Machines', 'NNP'), ('(', '('), ('SVMs', 'NNP'), (')', ')'), ('set', 'VBD'), ('supervised', 'VBN')]

>> Noun Phrases are: 
 ['Support Vector Machines', 'SVMs']

>> Named Entities are: 
 [('PERSON', 'Support'), ('PERSON', 'Vector Machines'), ('ORGANIZATION', 'SVMs')] 

>> Stemming using Porter Stemmer: 
 [('Support', 'support'), ('Vector', 'vector'), ('Machines', 'machin'), ('(', '('), ('SVMs', 'svm'), (')', ')'), ('set', 'set'), ('supervised', 'supervis')]

>> Stemming using Snowball Stemmer: 
 [('Support', 'support'), ('Vector', 'vector'), ('Machines', 'machin'), ('(', '('), ('SVMs', 'svms'), (')', ')'), ('set', 'set'), ('supervised', 'supervis')]

>> Lemmatization: 
 [('Support', 'Support'), ('Vector', 'Vector'), ('Machines', 'Machines'), ('(', '('), ('SVMs', 'SVMs'), (')', ')'), ('set', 'set'), ('supervised', 'supervised')]



========================================== PARAGRAPH 452 ===========================================

learning methods which have been used for classification,  

------------------- Sentence 1 -------------------

learning methods which have been used for classification,

>> Tokens are: 
 ['learning', 'methods', 'used', 'classification', ',']

>> Bigrams are: 
 [('learning', 'methods'), ('methods', 'used'), ('used', 'classification'), ('classification', ',')]

>> Trigrams are: 
 [('learning', 'methods', 'used'), ('methods', 'used', 'classification'), ('used', 'classification', ',')]

>> POS Tags are: 
 [('learning', 'VBG'), ('methods', 'NNS'), ('used', 'VBN'), ('classification', 'NN'), (',', ',')]

>> Noun Phrases are: 
 ['methods', 'classification']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('learning', 'learn'), ('methods', 'method'), ('used', 'use'), ('classification', 'classif'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('learning', 'learn'), ('methods', 'method'), ('used', 'use'), ('classification', 'classif'), (',', ',')]

>> Lemmatization: 
 [('learning', 'learning'), ('methods', 'method'), ('used', 'used'), ('classification', 'classification'), (',', ',')]



========================================== PARAGRAPH 453 ===========================================

regression and outliers detection. There are number of benefits  

------------------- Sentence 1 -------------------

regression and outliers detection.

>> Tokens are: 
 ['regression', 'outlier', '', 'detection', '.']

>> Bigrams are: 
 [('regression', 'outlier'), ('outlier', ''), ('', 'detection'), ('detection', '.')]

>> Trigrams are: 
 [('regression', 'outlier', ''), ('outlier', '', 'detection'), ('', 'detection', '.')]

>> POS Tags are: 
 [('regression', 'NN'), ('outlier', 'PRP'), ('', 'JJ'), ('detection', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['regression', ' detection']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('regression', 'regress'), ('outlier', 'outlier'), ('', ''), ('detection', 'detect'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('regression', 'regress'), ('outlier', 'outlier'), ('', ''), ('detection', 'detect'), ('.', '.')]

>> Lemmatization: 
 [('regression', 'regression'), ('outlier', 'outlier'), ('', ''), ('detection', 'detection'), ('.', '.')]


------------------- Sentence 2 -------------------

There are number of benefits

>> Tokens are: 
 ['There', 'number', 'benefits']

>> Bigrams are: 
 [('There', 'number'), ('number', 'benefits')]

>> Trigrams are: 
 [('There', 'number', 'benefits')]

>> POS Tags are: 
 [('There', 'EX'), ('number', 'NN'), ('benefits', 'NNS')]

>> Noun Phrases are: 
 ['number benefits']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('There', 'there'), ('number', 'number'), ('benefits', 'benefit')]

>> Stemming using Snowball Stemmer: 
 [('There', 'there'), ('number', 'number'), ('benefits', 'benefit')]

>> Lemmatization: 
 [('There', 'There'), ('number', 'number'), ('benefits', 'benefit')]



========================================== PARAGRAPH 454 ===========================================

for using SVM such as: i) It is effective is high dimensional  

------------------- Sentence 1 -------------------

for using SVM such as: i) It is effective is high dimensional

>> Tokens are: 
 ['using', 'SVM', ':', ')', 'It', 'effective', 'high', 'dimensional']

>> Bigrams are: 
 [('using', 'SVM'), ('SVM', ':'), (':', ')'), (')', 'It'), ('It', 'effective'), ('effective', 'high'), ('high', 'dimensional')]

>> Trigrams are: 
 [('using', 'SVM', ':'), ('SVM', ':', ')'), (':', ')', 'It'), (')', 'It', 'effective'), ('It', 'effective', 'high'), ('effective', 'high', 'dimensional')]

>> POS Tags are: 
 [('using', 'VBG'), ('SVM', 'NNP'), (':', ':'), (')', ')'), ('It', 'PRP'), ('effective', 'JJ'), ('high', 'JJ'), ('dimensional', 'NN')]

>> Noun Phrases are: 
 ['SVM', 'effective high dimensional']

>> Named Entities are: 
 [('ORGANIZATION', 'SVM')] 

>> Stemming using Porter Stemmer: 
 [('using', 'use'), ('SVM', 'svm'), (':', ':'), (')', ')'), ('It', 'it'), ('effective', 'effect'), ('high', 'high'), ('dimensional', 'dimension')]

>> Stemming using Snowball Stemmer: 
 [('using', 'use'), ('SVM', 'svm'), (':', ':'), (')', ')'), ('It', 'it'), ('effective', 'effect'), ('high', 'high'), ('dimensional', 'dimension')]

>> Lemmatization: 
 [('using', 'using'), ('SVM', 'SVM'), (':', ':'), (')', ')'), ('It', 'It'), ('effective', 'effective'), ('high', 'high'), ('dimensional', 'dimensional')]



========================================== PARAGRAPH 455 ===========================================

space, ii) Uses a subset of training points in the decision function  

------------------- Sentence 1 -------------------

space, ii) Uses a subset of training points in the decision function

>> Tokens are: 
 ['space', ',', 'ii', ')', 'Uses', 'subset', 'training', 'points', 'decision', 'function']

>> Bigrams are: 
 [('space', ','), (',', 'ii'), ('ii', ')'), (')', 'Uses'), ('Uses', 'subset'), ('subset', 'training'), ('training', 'points'), ('points', 'decision'), ('decision', 'function')]

>> Trigrams are: 
 [('space', ',', 'ii'), (',', 'ii', ')'), ('ii', ')', 'Uses'), (')', 'Uses', 'subset'), ('Uses', 'subset', 'training'), ('subset', 'training', 'points'), ('training', 'points', 'decision'), ('points', 'decision', 'function')]

>> POS Tags are: 
 [('space', 'NN'), (',', ','), ('ii', 'NN'), (')', ')'), ('Uses', 'VBZ'), ('subset', 'JJ'), ('training', 'NN'), ('points', 'NNS'), ('decision', 'NN'), ('function', 'NN')]

>> Noun Phrases are: 
 ['space', 'ii', 'subset training points decision function']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('space', 'space'), (',', ','), ('ii', 'ii'), (')', ')'), ('Uses', 'use'), ('subset', 'subset'), ('training', 'train'), ('points', 'point'), ('decision', 'decis'), ('function', 'function')]

>> Stemming using Snowball Stemmer: 
 [('space', 'space'), (',', ','), ('ii', 'ii'), (')', ')'), ('Uses', 'use'), ('subset', 'subset'), ('training', 'train'), ('points', 'point'), ('decision', 'decis'), ('function', 'function')]

>> Lemmatization: 
 [('space', 'space'), (',', ','), ('ii', 'ii'), (')', ')'), ('Uses', 'Uses'), ('subset', 'subset'), ('training', 'training'), ('points', 'point'), ('decision', 'decision'), ('function', 'function')]



========================================== PARAGRAPH 456 ===========================================

(called support vectors), so it is also memory efficient, iii) It is  

------------------- Sentence 1 -------------------

(called support vectors), so it is also memory efficient, iii) It is

>> Tokens are: 
 ['(', 'called', 'support', 'vectors', ')', ',', 'also', 'memory', 'efficient', ',', 'iii', ')', 'It']

>> Bigrams are: 
 [('(', 'called'), ('called', 'support'), ('support', 'vectors'), ('vectors', ')'), (')', ','), (',', 'also'), ('also', 'memory'), ('memory', 'efficient'), ('efficient', ','), (',', 'iii'), ('iii', ')'), (')', 'It')]

>> Trigrams are: 
 [('(', 'called', 'support'), ('called', 'support', 'vectors'), ('support', 'vectors', ')'), ('vectors', ')', ','), (')', ',', 'also'), (',', 'also', 'memory'), ('also', 'memory', 'efficient'), ('memory', 'efficient', ','), ('efficient', ',', 'iii'), (',', 'iii', ')'), ('iii', ')', 'It')]

>> POS Tags are: 
 [('(', '('), ('called', 'VBN'), ('support', 'NN'), ('vectors', 'NNS'), (')', ')'), (',', ','), ('also', 'RB'), ('memory', 'NN'), ('efficient', 'NN'), (',', ','), ('iii', 'NN'), (')', ')'), ('It', 'PRP')]

>> Noun Phrases are: 
 ['support vectors', 'memory efficient', 'iii']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('called', 'call'), ('support', 'support'), ('vectors', 'vector'), (')', ')'), (',', ','), ('also', 'also'), ('memory', 'memori'), ('efficient', 'effici'), (',', ','), ('iii', 'iii'), (')', ')'), ('It', 'it')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('called', 'call'), ('support', 'support'), ('vectors', 'vector'), (')', ')'), (',', ','), ('also', 'also'), ('memory', 'memori'), ('efficient', 'effici'), (',', ','), ('iii', 'iii'), (')', ')'), ('It', 'it')]

>> Lemmatization: 
 [('(', '('), ('called', 'called'), ('support', 'support'), ('vectors', 'vector'), (')', ')'), (',', ','), ('also', 'also'), ('memory', 'memory'), ('efficient', 'efficient'), (',', ','), ('iii', 'iii'), (')', ')'), ('It', 'It')]



========================================== PARAGRAPH 457 ===========================================

versatile because holds different kernel functions can be  

------------------- Sentence 1 -------------------

versatile because holds different kernel functions can be

>> Tokens are: 
 ['versatile', 'holds', 'different', 'kernel', 'functions']

>> Bigrams are: 
 [('versatile', 'holds'), ('holds', 'different'), ('different', 'kernel'), ('kernel', 'functions')]

>> Trigrams are: 
 [('versatile', 'holds', 'different'), ('holds', 'different', 'kernel'), ('different', 'kernel', 'functions')]

>> POS Tags are: 
 [('versatile', 'JJ'), ('holds', 'VBZ'), ('different', 'JJ'), ('kernel', 'NNS'), ('functions', 'NNS')]

>> Noun Phrases are: 
 ['different kernel functions']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('versatile', 'versatil'), ('holds', 'hold'), ('different', 'differ'), ('kernel', 'kernel'), ('functions', 'function')]

>> Stemming using Snowball Stemmer: 
 [('versatile', 'versatil'), ('holds', 'hold'), ('different', 'differ'), ('kernel', 'kernel'), ('functions', 'function')]

>> Lemmatization: 
 [('versatile', 'versatile'), ('holds', 'hold'), ('different', 'different'), ('kernel', 'kernel'), ('functions', 'function')]



========================================== PARAGRAPH 458 ===========================================

specified for the decision function. Common kernels are  

------------------- Sentence 1 -------------------

specified for the decision function.

>> Tokens are: 
 ['specified', 'decision', 'function', '.']

>> Bigrams are: 
 [('specified', 'decision'), ('decision', 'function'), ('function', '.')]

>> Trigrams are: 
 [('specified', 'decision', 'function'), ('decision', 'function', '.')]

>> POS Tags are: 
 [('specified', 'VBN'), ('decision', 'NN'), ('function', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['decision function']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('specified', 'specifi'), ('decision', 'decis'), ('function', 'function'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('specified', 'specifi'), ('decision', 'decis'), ('function', 'function'), ('.', '.')]

>> Lemmatization: 
 [('specified', 'specified'), ('decision', 'decision'), ('function', 'function'), ('.', '.')]


------------------- Sentence 2 -------------------

Common kernels are

>> Tokens are: 
 ['Common', 'kernels']

>> Bigrams are: 
 [('Common', 'kernels')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Common', 'JJ'), ('kernels', 'NNS')]

>> Noun Phrases are: 
 ['Common kernels']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Common', 'common'), ('kernels', 'kernel')]

>> Stemming using Snowball Stemmer: 
 [('Common', 'common'), ('kernels', 'kernel')]

>> Lemmatization: 
 [('Common', 'Common'), ('kernels', 'kernel')]



========================================== PARAGRAPH 459 ===========================================

provided, but it is also possible to specify custom kernels.  

------------------- Sentence 1 -------------------

provided, but it is also possible to specify custom kernels.

>> Tokens are: 
 ['provided', ',', 'also', 'possible', 'specify', 'custom', 'kernels', '.']

>> Bigrams are: 
 [('provided', ','), (',', 'also'), ('also', 'possible'), ('possible', 'specify'), ('specify', 'custom'), ('custom', 'kernels'), ('kernels', '.')]

>> Trigrams are: 
 [('provided', ',', 'also'), (',', 'also', 'possible'), ('also', 'possible', 'specify'), ('possible', 'specify', 'custom'), ('specify', 'custom', 'kernels'), ('custom', 'kernels', '.')]

>> POS Tags are: 
 [('provided', 'VBN'), (',', ','), ('also', 'RB'), ('possible', 'JJ'), ('specify', 'NN'), ('custom', 'NN'), ('kernels', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['possible specify custom kernels']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('provided', 'provid'), (',', ','), ('also', 'also'), ('possible', 'possibl'), ('specify', 'specifi'), ('custom', 'custom'), ('kernels', 'kernel'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('provided', 'provid'), (',', ','), ('also', 'also'), ('possible', 'possibl'), ('specify', 'specifi'), ('custom', 'custom'), ('kernels', 'kernel'), ('.', '.')]

>> Lemmatization: 
 [('provided', 'provided'), (',', ','), ('also', 'also'), ('possible', 'possible'), ('specify', 'specify'), ('custom', 'custom'), ('kernels', 'kernel'), ('.', '.')]



========================================== PARAGRAPH 460 ===========================================

Most real-world problems involve non-separable data for  

------------------- Sentence 1 -------------------

Most real-world problems involve non-separable data for

>> Tokens are: 
 ['Most', 'real-world', 'problems', 'involve', 'non-separable', 'data']

>> Bigrams are: 
 [('Most', 'real-world'), ('real-world', 'problems'), ('problems', 'involve'), ('involve', 'non-separable'), ('non-separable', 'data')]

>> Trigrams are: 
 [('Most', 'real-world', 'problems'), ('real-world', 'problems', 'involve'), ('problems', 'involve', 'non-separable'), ('involve', 'non-separable', 'data')]

>> POS Tags are: 
 [('Most', 'JJS'), ('real-world', 'JJ'), ('problems', 'NNS'), ('involve', 'VBP'), ('non-separable', 'JJ'), ('data', 'NNS')]

>> Noun Phrases are: 
 ['real-world problems', 'non-separable data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Most', 'most'), ('real-world', 'real-world'), ('problems', 'problem'), ('involve', 'involv'), ('non-separable', 'non-separ'), ('data', 'data')]

>> Stemming using Snowball Stemmer: 
 [('Most', 'most'), ('real-world', 'real-world'), ('problems', 'problem'), ('involve', 'involv'), ('non-separable', 'non-separ'), ('data', 'data')]

>> Lemmatization: 
 [('Most', 'Most'), ('real-world', 'real-world'), ('problems', 'problem'), ('involve', 'involve'), ('non-separable', 'non-separable'), ('data', 'data')]



========================================== PARAGRAPH 461 ===========================================

which no hyperplane exists that successfully separates the  

------------------- Sentence 1 -------------------

which no hyperplane exists that successfully separates the

>> Tokens are: 
 ['hyperplane', 'exists', 'successfully', 'separates']

>> Bigrams are: 
 [('hyperplane', 'exists'), ('exists', 'successfully'), ('successfully', 'separates')]

>> Trigrams are: 
 [('hyperplane', 'exists', 'successfully'), ('exists', 'successfully', 'separates')]

>> POS Tags are: 
 [('hyperplane', 'NN'), ('exists', 'VBZ'), ('successfully', 'RB'), ('separates', 'NNS')]

>> Noun Phrases are: 
 ['hyperplane', 'separates']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('hyperplane', 'hyperplan'), ('exists', 'exist'), ('successfully', 'success'), ('separates', 'separ')]

>> Stemming using Snowball Stemmer: 
 [('hyperplane', 'hyperplan'), ('exists', 'exist'), ('successfully', 'success'), ('separates', 'separ')]

>> Lemmatization: 
 [('hyperplane', 'hyperplane'), ('exists', 'exists'), ('successfully', 'successfully'), ('separates', 'separate')]



========================================== PARAGRAPH 462 ===========================================

positive from negative instances in the training set. One good  

------------------- Sentence 1 -------------------

positive from negative instances in the training set.

>> Tokens are: 
 ['positive', 'negative', 'instances', 'training', 'set', '.']

>> Bigrams are: 
 [('positive', 'negative'), ('negative', 'instances'), ('instances', 'training'), ('training', 'set'), ('set', '.')]

>> Trigrams are: 
 [('positive', 'negative', 'instances'), ('negative', 'instances', 'training'), ('instances', 'training', 'set'), ('training', 'set', '.')]

>> POS Tags are: 
 [('positive', 'JJ'), ('negative', 'JJ'), ('instances', 'NNS'), ('training', 'VBG'), ('set', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['positive negative instances', 'set']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('positive', 'posit'), ('negative', 'neg'), ('instances', 'instanc'), ('training', 'train'), ('set', 'set'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('positive', 'posit'), ('negative', 'negat'), ('instances', 'instanc'), ('training', 'train'), ('set', 'set'), ('.', '.')]

>> Lemmatization: 
 [('positive', 'positive'), ('negative', 'negative'), ('instances', 'instance'), ('training', 'training'), ('set', 'set'), ('.', '.')]


------------------- Sentence 2 -------------------

One good

>> Tokens are: 
 ['One', 'good']

>> Bigrams are: 
 [('One', 'good')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('One', 'CD'), ('good', 'JJ')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('One', 'one'), ('good', 'good')]

>> Stemming using Snowball Stemmer: 
 [('One', 'one'), ('good', 'good')]

>> Lemmatization: 
 [('One', 'One'), ('good', 'good')]



========================================== PARAGRAPH 463 ===========================================

solution to this inseparability problem is to map the data onto a  

------------------- Sentence 1 -------------------

solution to this inseparability problem is to map the data onto a

>> Tokens are: 
 ['solution', 'inseparability', 'problem', 'map', 'data', 'onto']

>> Bigrams are: 
 [('solution', 'inseparability'), ('inseparability', 'problem'), ('problem', 'map'), ('map', 'data'), ('data', 'onto')]

>> Trigrams are: 
 [('solution', 'inseparability', 'problem'), ('inseparability', 'problem', 'map'), ('problem', 'map', 'data'), ('map', 'data', 'onto')]

>> POS Tags are: 
 [('solution', 'NN'), ('inseparability', 'NN'), ('problem', 'NN'), ('map', 'NN'), ('data', 'NNS'), ('onto', 'IN')]

>> Noun Phrases are: 
 ['solution inseparability problem map data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('solution', 'solut'), ('inseparability', 'insepar'), ('problem', 'problem'), ('map', 'map'), ('data', 'data'), ('onto', 'onto')]

>> Stemming using Snowball Stemmer: 
 [('solution', 'solut'), ('inseparability', 'insepar'), ('problem', 'problem'), ('map', 'map'), ('data', 'data'), ('onto', 'onto')]

>> Lemmatization: 
 [('solution', 'solution'), ('inseparability', 'inseparability'), ('problem', 'problem'), ('map', 'map'), ('data', 'data'), ('onto', 'onto')]



========================================== PARAGRAPH 464 ===========================================

higher dimensional space and define a separating hyperplane  

------------------- Sentence 1 -------------------

higher dimensional space and define a separating hyperplane

>> Tokens are: 
 ['higher', 'dimensional', 'space', 'define', 'separating', 'hyperplane']

>> Bigrams are: 
 [('higher', 'dimensional'), ('dimensional', 'space'), ('space', 'define'), ('define', 'separating'), ('separating', 'hyperplane')]

>> Trigrams are: 
 [('higher', 'dimensional', 'space'), ('dimensional', 'space', 'define'), ('space', 'define', 'separating'), ('define', 'separating', 'hyperplane')]

>> POS Tags are: 
 [('higher', 'JJR'), ('dimensional', 'JJ'), ('space', 'NN'), ('define', 'NN'), ('separating', 'VBG'), ('hyperplane', 'NN')]

>> Noun Phrases are: 
 ['dimensional space define', 'hyperplane']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('higher', 'higher'), ('dimensional', 'dimension'), ('space', 'space'), ('define', 'defin'), ('separating', 'separ'), ('hyperplane', 'hyperplan')]

>> Stemming using Snowball Stemmer: 
 [('higher', 'higher'), ('dimensional', 'dimension'), ('space', 'space'), ('define', 'defin'), ('separating', 'separ'), ('hyperplane', 'hyperplan')]

>> Lemmatization: 
 [('higher', 'higher'), ('dimensional', 'dimensional'), ('space', 'space'), ('define', 'define'), ('separating', 'separating'), ('hyperplane', 'hyperplane')]



========================================== PARAGRAPH 465 ===========================================

there. This higher-dimensional space is called the transformed  

------------------- Sentence 1 -------------------

there.

>> Tokens are: 
 ['.']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('.', '.')]

>> Lemmatization: 
 [('.', '.')]


------------------- Sentence 2 -------------------

This higher-dimensional space is called the transformed

>> Tokens are: 
 ['This', 'higher-dimensional', 'space', 'called', 'transformed']

>> Bigrams are: 
 [('This', 'higher-dimensional'), ('higher-dimensional', 'space'), ('space', 'called'), ('called', 'transformed')]

>> Trigrams are: 
 [('This', 'higher-dimensional', 'space'), ('higher-dimensional', 'space', 'called'), ('space', 'called', 'transformed')]

>> POS Tags are: 
 [('This', 'DT'), ('higher-dimensional', 'JJ'), ('space', 'NN'), ('called', 'VBN'), ('transformed', 'VBD')]

>> Noun Phrases are: 
 ['This higher-dimensional space']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('This', 'thi'), ('higher-dimensional', 'higher-dimension'), ('space', 'space'), ('called', 'call'), ('transformed', 'transform')]

>> Stemming using Snowball Stemmer: 
 [('This', 'this'), ('higher-dimensional', 'higher-dimension'), ('space', 'space'), ('called', 'call'), ('transformed', 'transform')]

>> Lemmatization: 
 [('This', 'This'), ('higher-dimensional', 'higher-dimensional'), ('space', 'space'), ('called', 'called'), ('transformed', 'transformed')]



========================================== PARAGRAPH 466 ===========================================

feature space, as opposed to the input space occupied by the  

------------------- Sentence 1 -------------------

feature space, as opposed to the input space occupied by the

>> Tokens are: 
 ['feature', 'space', ',', 'opposed', 'input', 'space', 'occupied']

>> Bigrams are: 
 [('feature', 'space'), ('space', ','), (',', 'opposed'), ('opposed', 'input'), ('input', 'space'), ('space', 'occupied')]

>> Trigrams are: 
 [('feature', 'space', ','), ('space', ',', 'opposed'), (',', 'opposed', 'input'), ('opposed', 'input', 'space'), ('input', 'space', 'occupied')]

>> POS Tags are: 
 [('feature', 'NN'), ('space', 'NN'), (',', ','), ('opposed', 'VBD'), ('input', 'JJ'), ('space', 'NN'), ('occupied', 'VBD')]

>> Noun Phrases are: 
 ['feature space', 'input space']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('feature', 'featur'), ('space', 'space'), (',', ','), ('opposed', 'oppos'), ('input', 'input'), ('space', 'space'), ('occupied', 'occupi')]

>> Stemming using Snowball Stemmer: 
 [('feature', 'featur'), ('space', 'space'), (',', ','), ('opposed', 'oppos'), ('input', 'input'), ('space', 'space'), ('occupied', 'occupi')]

>> Lemmatization: 
 [('feature', 'feature'), ('space', 'space'), (',', ','), ('opposed', 'opposed'), ('input', 'input'), ('space', 'space'), ('occupied', 'occupied')]



========================================== PARAGRAPH 467 ===========================================

training instances [1].  

------------------- Sentence 1 -------------------

training instances [1].

>> Tokens are: 
 ['training', 'instances', '[', '1', ']', '.']

>> Bigrams are: 
 [('training', 'instances'), ('instances', '['), ('[', '1'), ('1', ']'), (']', '.')]

>> Trigrams are: 
 [('training', 'instances', '['), ('instances', '[', '1'), ('[', '1', ']'), ('1', ']', '.')]

>> POS Tags are: 
 [('training', 'NN'), ('instances', 'NNS'), ('[', 'VBP'), ('1', 'CD'), (']', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['training instances', ']']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('training', 'train'), ('instances', 'instanc'), ('[', '['), ('1', '1'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('training', 'train'), ('instances', 'instanc'), ('[', '['), ('1', '1'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('training', 'training'), ('instances', 'instance'), ('[', '['), ('1', '1'), (']', ']'), ('.', '.')]



========================================== PARAGRAPH 468 ===========================================

  


========================================== PARAGRAPH 469 ===========================================

Fig.10. Maximum margin through SVM  

------------------- Sentence 1 -------------------

Fig.10.

>> Tokens are: 
 ['Fig.10', '.']

>> Bigrams are: 
 [('Fig.10', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Fig.10', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Fig.10']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Fig.10', 'fig.10'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Fig.10', 'fig.10'), ('.', '.')]

>> Lemmatization: 
 [('Fig.10', 'Fig.10'), ('.', '.')]


------------------- Sentence 2 -------------------

Maximum margin through SVM

>> Tokens are: 
 ['Maximum', 'margin', 'SVM']

>> Bigrams are: 
 [('Maximum', 'margin'), ('margin', 'SVM')]

>> Trigrams are: 
 [('Maximum', 'margin', 'SVM')]

>> POS Tags are: 
 [('Maximum', 'NNP'), ('margin', 'NN'), ('SVM', 'NNP')]

>> Noun Phrases are: 
 ['Maximum margin SVM']

>> Named Entities are: 
 [('GPE', 'Maximum'), ('ORGANIZATION', 'SVM')] 

>> Stemming using Porter Stemmer: 
 [('Maximum', 'maximum'), ('margin', 'margin'), ('SVM', 'svm')]

>> Stemming using Snowball Stemmer: 
 [('Maximum', 'maximum'), ('margin', 'margin'), ('SVM', 'svm')]

>> Lemmatization: 
 [('Maximum', 'Maximum'), ('margin', 'margin'), ('SVM', 'SVM')]



========================================== PARAGRAPH 470 ===========================================

In order to get better results the selection of an appropriate  

------------------- Sentence 1 -------------------

In order to get better results the selection of an appropriate

>> Tokens are: 
 ['In', 'order', 'get', 'better', 'results', 'selection', 'appropriate']

>> Bigrams are: 
 [('In', 'order'), ('order', 'get'), ('get', 'better'), ('better', 'results'), ('results', 'selection'), ('selection', 'appropriate')]

>> Trigrams are: 
 [('In', 'order', 'get'), ('order', 'get', 'better'), ('get', 'better', 'results'), ('better', 'results', 'selection'), ('results', 'selection', 'appropriate')]

>> POS Tags are: 
 [('In', 'IN'), ('order', 'NN'), ('get', 'VBP'), ('better', 'JJR'), ('results', 'NNS'), ('selection', 'NN'), ('appropriate', 'VBP')]

>> Noun Phrases are: 
 ['order', 'results selection']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('order', 'order'), ('get', 'get'), ('better', 'better'), ('results', 'result'), ('selection', 'select'), ('appropriate', 'appropri')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('order', 'order'), ('get', 'get'), ('better', 'better'), ('results', 'result'), ('selection', 'select'), ('appropriate', 'appropri')]

>> Lemmatization: 
 [('In', 'In'), ('order', 'order'), ('get', 'get'), ('better', 'better'), ('results', 'result'), ('selection', 'selection'), ('appropriate', 'appropriate')]



========================================== PARAGRAPH 471 ===========================================

kernel function is important, since the kernel function defines  

------------------- Sentence 1 -------------------

kernel function is important, since the kernel function defines

>> Tokens are: 
 ['kernel', 'function', 'important', ',', 'since', 'kernel', 'function', 'defines']

>> Bigrams are: 
 [('kernel', 'function'), ('function', 'important'), ('important', ','), (',', 'since'), ('since', 'kernel'), ('kernel', 'function'), ('function', 'defines')]

>> Trigrams are: 
 [('kernel', 'function', 'important'), ('function', 'important', ','), ('important', ',', 'since'), (',', 'since', 'kernel'), ('since', 'kernel', 'function'), ('kernel', 'function', 'defines')]

>> POS Tags are: 
 [('kernel', 'NNS'), ('function', 'NN'), ('important', 'JJ'), (',', ','), ('since', 'IN'), ('kernel', 'NN'), ('function', 'NN'), ('defines', 'NNS')]

>> Noun Phrases are: 
 ['kernel function', 'kernel function defines']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('kernel', 'kernel'), ('function', 'function'), ('important', 'import'), (',', ','), ('since', 'sinc'), ('kernel', 'kernel'), ('function', 'function'), ('defines', 'defin')]

>> Stemming using Snowball Stemmer: 
 [('kernel', 'kernel'), ('function', 'function'), ('important', 'import'), (',', ','), ('since', 'sinc'), ('kernel', 'kernel'), ('function', 'function'), ('defines', 'defin')]

>> Lemmatization: 
 [('kernel', 'kernel'), ('function', 'function'), ('important', 'important'), (',', ','), ('since', 'since'), ('kernel', 'kernel'), ('function', 'function'), ('defines', 'defines')]



========================================== PARAGRAPH 472 ===========================================

the transformed feature space in which the training set instances  

------------------- Sentence 1 -------------------

the transformed feature space in which the training set instances

>> Tokens are: 
 ['transformed', 'feature', 'space', 'training', 'set', 'instances']

>> Bigrams are: 
 [('transformed', 'feature'), ('feature', 'space'), ('space', 'training'), ('training', 'set'), ('set', 'instances')]

>> Trigrams are: 
 [('transformed', 'feature', 'space'), ('feature', 'space', 'training'), ('space', 'training', 'set'), ('training', 'set', 'instances')]

>> POS Tags are: 
 [('transformed', 'JJ'), ('feature', 'NN'), ('space', 'NN'), ('training', 'NN'), ('set', 'VBN'), ('instances', 'NNS')]

>> Noun Phrases are: 
 ['transformed feature space training', 'instances']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('transformed', 'transform'), ('feature', 'featur'), ('space', 'space'), ('training', 'train'), ('set', 'set'), ('instances', 'instanc')]

>> Stemming using Snowball Stemmer: 
 [('transformed', 'transform'), ('feature', 'featur'), ('space', 'space'), ('training', 'train'), ('set', 'set'), ('instances', 'instanc')]

>> Lemmatization: 
 [('transformed', 'transformed'), ('feature', 'feature'), ('space', 'space'), ('training', 'training'), ('set', 'set'), ('instances', 'instance')]



========================================== PARAGRAPH 473 ===========================================

Procedure InstanceBaseLearner (Testing Instances)  

------------------- Sentence 1 -------------------

Procedure InstanceBaseLearner (Testing Instances)

>> Tokens are: 
 ['Procedure', 'InstanceBaseLearner', '(', 'Testing', 'Instances', ')']

>> Bigrams are: 
 [('Procedure', 'InstanceBaseLearner'), ('InstanceBaseLearner', '('), ('(', 'Testing'), ('Testing', 'Instances'), ('Instances', ')')]

>> Trigrams are: 
 [('Procedure', 'InstanceBaseLearner', '('), ('InstanceBaseLearner', '(', 'Testing'), ('(', 'Testing', 'Instances'), ('Testing', 'Instances', ')')]

>> POS Tags are: 
 [('Procedure', 'NN'), ('InstanceBaseLearner', 'NNP'), ('(', '('), ('Testing', 'NNP'), ('Instances', 'NNP'), (')', ')')]

>> Noun Phrases are: 
 ['Procedure InstanceBaseLearner', 'Testing Instances']

>> Named Entities are: 
 [('ORGANIZATION', 'InstanceBaseLearner'), ('ORGANIZATION', 'Testing')] 

>> Stemming using Porter Stemmer: 
 [('Procedure', 'procedur'), ('InstanceBaseLearner', 'instancebaselearn'), ('(', '('), ('Testing', 'test'), ('Instances', 'instanc'), (')', ')')]

>> Stemming using Snowball Stemmer: 
 [('Procedure', 'procedur'), ('InstanceBaseLearner', 'instancebaselearn'), ('(', '('), ('Testing', 'test'), ('Instances', 'instanc'), (')', ')')]

>> Lemmatization: 
 [('Procedure', 'Procedure'), ('InstanceBaseLearner', 'InstanceBaseLearner'), ('(', '('), ('Testing', 'Testing'), ('Instances', 'Instances'), (')', ')')]



========================================== PARAGRAPH 474 ===========================================

   for each testing instance  

------------------- Sentence 1 -------------------

   for each testing instance

>> Tokens are: 
 ['testing', 'instance']

>> Bigrams are: 
 [('testing', 'instance')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('testing', 'VBG'), ('instance', 'NN')]

>> Noun Phrases are: 
 ['instance']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('testing', 'test'), ('instance', 'instanc')]

>> Stemming using Snowball Stemmer: 
 [('testing', 'test'), ('instance', 'instanc')]

>> Lemmatization: 
 [('testing', 'testing'), ('instance', 'instance')]



========================================== PARAGRAPH 475 ===========================================

   {  

------------------- Sentence 1 -------------------

   {

>> Tokens are: 
 ['{']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('{', '(')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('{', '{')]

>> Stemming using Snowball Stemmer: 
 [('{', '{')]

>> Lemmatization: 
 [('{', '{')]



========================================== PARAGRAPH 476 ===========================================

find the k most nearest instances of the  

------------------- Sentence 1 -------------------

find the k most nearest instances of the

>> Tokens are: 
 ['find', 'k', 'nearest', 'instances']

>> Bigrams are: 
 [('find', 'k'), ('k', 'nearest'), ('nearest', 'instances')]

>> Trigrams are: 
 [('find', 'k', 'nearest'), ('k', 'nearest', 'instances')]

>> POS Tags are: 
 [('find', 'VB'), ('k', 'JJ'), ('nearest', 'JJS'), ('instances', 'NNS')]

>> Noun Phrases are: 
 ['instances']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('find', 'find'), ('k', 'k'), ('nearest', 'nearest'), ('instances', 'instanc')]

>> Stemming using Snowball Stemmer: 
 [('find', 'find'), ('k', 'k'), ('nearest', 'nearest'), ('instances', 'instanc')]

>> Lemmatization: 
 [('find', 'find'), ('k', 'k'), ('nearest', 'nearest'), ('instances', 'instance')]



========================================== PARAGRAPH 477 ===========================================

training set according to a distance metric  

------------------- Sentence 1 -------------------

training set according to a distance metric

>> Tokens are: 
 ['training', 'set', 'according', 'distance', 'metric']

>> Bigrams are: 
 [('training', 'set'), ('set', 'according'), ('according', 'distance'), ('distance', 'metric')]

>> Trigrams are: 
 [('training', 'set', 'according'), ('set', 'according', 'distance'), ('according', 'distance', 'metric')]

>> POS Tags are: 
 [('training', 'NN'), ('set', 'VBN'), ('according', 'VBG'), ('distance', 'NN'), ('metric', 'JJ')]

>> Noun Phrases are: 
 ['training', 'distance']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('training', 'train'), ('set', 'set'), ('according', 'accord'), ('distance', 'distanc'), ('metric', 'metric')]

>> Stemming using Snowball Stemmer: 
 [('training', 'train'), ('set', 'set'), ('according', 'accord'), ('distance', 'distanc'), ('metric', 'metric')]

>> Lemmatization: 
 [('training', 'training'), ('set', 'set'), ('according', 'according'), ('distance', 'distance'), ('metric', 'metric')]



========================================== PARAGRAPH 478 ===========================================

     Resulting Class: most frequent class  

------------------- Sentence 1 -------------------

     Resulting Class: most frequent class

>> Tokens are: 
 ['Resulting', 'Class', ':', 'frequent', 'class']

>> Bigrams are: 
 [('Resulting', 'Class'), ('Class', ':'), (':', 'frequent'), ('frequent', 'class')]

>> Trigrams are: 
 [('Resulting', 'Class', ':'), ('Class', ':', 'frequent'), (':', 'frequent', 'class')]

>> POS Tags are: 
 [('Resulting', 'VBG'), ('Class', 'NN'), (':', ':'), ('frequent', 'JJ'), ('class', 'NN')]

>> Noun Phrases are: 
 ['Class', 'frequent class']

>> Named Entities are: 
 [('PERSON', 'Class')] 

>> Stemming using Porter Stemmer: 
 [('Resulting', 'result'), ('Class', 'class'), (':', ':'), ('frequent', 'frequent'), ('class', 'class')]

>> Stemming using Snowball Stemmer: 
 [('Resulting', 'result'), ('Class', 'class'), (':', ':'), ('frequent', 'frequent'), ('class', 'class')]

>> Lemmatization: 
 [('Resulting', 'Resulting'), ('Class', 'Class'), (':', ':'), ('frequent', 'frequent'), ('class', 'class')]



========================================== PARAGRAPH 479 ===========================================

     label of the k nearest instances  

------------------- Sentence 1 -------------------

     label of the k nearest instances

>> Tokens are: 
 ['label', 'k', 'nearest', 'instances']

>> Bigrams are: 
 [('label', 'k'), ('k', 'nearest'), ('nearest', 'instances')]

>> Trigrams are: 
 [('label', 'k', 'nearest'), ('k', 'nearest', 'instances')]

>> POS Tags are: 
 [('label', 'NN'), ('k', 'NN'), ('nearest', 'JJS'), ('instances', 'NNS')]

>> Noun Phrases are: 
 ['label k', 'instances']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('label', 'label'), ('k', 'k'), ('nearest', 'nearest'), ('instances', 'instanc')]

>> Stemming using Snowball Stemmer: 
 [('label', 'label'), ('k', 'k'), ('nearest', 'nearest'), ('instances', 'instanc')]

>> Lemmatization: 
 [('label', 'label'), ('k', 'k'), ('nearest', 'nearest'), ('instances', 'instance')]



========================================== PARAGRAPH 480 ===========================================

   }  

------------------- Sentence 1 -------------------

   }

>> Tokens are: 
 ['}']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('}', ')')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('}', '}')]

>> Stemming using Snowball Stemmer: 
 [('}', '}')]

>> Lemmatization: 
 [('}', '}')]



========================================== PARAGRAPH 481 ===========================================

  


========================================== PARAGRAPH 482 ===========================================

Initialize an Empty Bayesian Network G containing n  

------------------- Sentence 1 -------------------

Initialize an Empty Bayesian Network G containing n

>> Tokens are: 
 ['Initialize', 'Empty', 'Bayesian', 'Network', 'G', 'containing', 'n']

>> Bigrams are: 
 [('Initialize', 'Empty'), ('Empty', 'Bayesian'), ('Bayesian', 'Network'), ('Network', 'G'), ('G', 'containing'), ('containing', 'n')]

>> Trigrams are: 
 [('Initialize', 'Empty', 'Bayesian'), ('Empty', 'Bayesian', 'Network'), ('Bayesian', 'Network', 'G'), ('Network', 'G', 'containing'), ('G', 'containing', 'n')]

>> POS Tags are: 
 [('Initialize', 'NNP'), ('Empty', 'NNP'), ('Bayesian', 'NNP'), ('Network', 'NNP'), ('G', 'NNP'), ('containing', 'VBG'), ('n', 'NN')]

>> Noun Phrases are: 
 ['Initialize Empty Bayesian Network G', 'n']

>> Named Entities are: 
 [('PERSON', 'Initialize'), ('PERSON', 'Empty Bayesian Network')] 

>> Stemming using Porter Stemmer: 
 [('Initialize', 'initi'), ('Empty', 'empti'), ('Bayesian', 'bayesian'), ('Network', 'network'), ('G', 'g'), ('containing', 'contain'), ('n', 'n')]

>> Stemming using Snowball Stemmer: 
 [('Initialize', 'initi'), ('Empty', 'empti'), ('Bayesian', 'bayesian'), ('Network', 'network'), ('G', 'g'), ('containing', 'contain'), ('n', 'n')]

>> Lemmatization: 
 [('Initialize', 'Initialize'), ('Empty', 'Empty'), ('Bayesian', 'Bayesian'), ('Network', 'Network'), ('G', 'G'), ('containing', 'containing'), ('n', 'n')]



========================================== PARAGRAPH 483 ===========================================

nodes (i.e.-, a BN with n nodes but no edges)     

------------------- Sentence 1 -------------------

nodes (i.e.-, a BN with n nodes but no edges)

>> Tokens are: 
 ['nodes', '(', 'i.e.-', ',', 'BN', 'n', 'nodes', 'edges', ')']

>> Bigrams are: 
 [('nodes', '('), ('(', 'i.e.-'), ('i.e.-', ','), (',', 'BN'), ('BN', 'n'), ('n', 'nodes'), ('nodes', 'edges'), ('edges', ')')]

>> Trigrams are: 
 [('nodes', '(', 'i.e.-'), ('(', 'i.e.-', ','), ('i.e.-', ',', 'BN'), (',', 'BN', 'n'), ('BN', 'n', 'nodes'), ('n', 'nodes', 'edges'), ('nodes', 'edges', ')')]

>> POS Tags are: 
 [('nodes', 'NNS'), ('(', '('), ('i.e.-', 'JJ'), (',', ','), ('BN', 'NNP'), ('n', 'FW'), ('nodes', 'NNS'), ('edges', 'NNS'), (')', ')')]

>> Noun Phrases are: 
 ['nodes', 'BN', 'nodes edges']

>> Named Entities are: 
 [('ORGANIZATION', 'BN')] 

>> Stemming using Porter Stemmer: 
 [('nodes', 'node'), ('(', '('), ('i.e.-', 'i.e.-'), (',', ','), ('BN', 'bn'), ('n', 'n'), ('nodes', 'node'), ('edges', 'edg'), (')', ')')]

>> Stemming using Snowball Stemmer: 
 [('nodes', 'node'), ('(', '('), ('i.e.-', 'i.e.-'), (',', ','), ('BN', 'bn'), ('n', 'n'), ('nodes', 'node'), ('edges', 'edg'), (')', ')')]

>> Lemmatization: 
 [('nodes', 'node'), ('(', '('), ('i.e.-', 'i.e.-'), (',', ','), ('BN', 'BN'), ('n', 'n'), ('nodes', 'node'), ('edges', 'edge'), (')', ')')]



========================================== PARAGRAPH 484 ===========================================

1) Evaluate the score of G: Score (G)   2) G = G   3) for i = 1 to n do   4) for j = 1 to n do   5) if i  j then   6) if there is no edge between the nodes i and  

------------------- Sentence 1 -------------------

1) Evaluate the score of G: Score (G)   2) G = G   3) for i = 1 to n do   4) for j = 1 to n do   5) if i  j then   6) if there is no edge between the nodes i and

>> Tokens are: 
 ['1', ')', 'Evaluate', 'score', 'G', ':', 'Score', '(', 'G', ')', '2', ')', 'G', '', '=', 'G', '3', ')', '=', '1', 'n', '4', ')', 'j', '=', '1', 'n', '5', ')', '', 'j', '6', ')', 'edge', 'nodes']

>> Bigrams are: 
 [('1', ')'), (')', 'Evaluate'), ('Evaluate', 'score'), ('score', 'G'), ('G', ':'), (':', 'Score'), ('Score', '('), ('(', 'G'), ('G', ')'), (')', '2'), ('2', ')'), (')', 'G'), ('G', ''), ('', '='), ('=', 'G'), ('G', '3'), ('3', ')'), (')', '='), ('=', '1'), ('1', 'n'), ('n', '4'), ('4', ')'), (')', 'j'), ('j', '='), ('=', '1'), ('1', 'n'), ('n', '5'), ('5', ')'), (')', ''), ('', 'j'), ('j', '6'), ('6', ')'), (')', 'edge'), ('edge', 'nodes')]

>> Trigrams are: 
 [('1', ')', 'Evaluate'), (')', 'Evaluate', 'score'), ('Evaluate', 'score', 'G'), ('score', 'G', ':'), ('G', ':', 'Score'), (':', 'Score', '('), ('Score', '(', 'G'), ('(', 'G', ')'), ('G', ')', '2'), (')', '2', ')'), ('2', ')', 'G'), (')', 'G', ''), ('G', '', '='), ('', '=', 'G'), ('=', 'G', '3'), ('G', '3', ')'), ('3', ')', '='), (')', '=', '1'), ('=', '1', 'n'), ('1', 'n', '4'), ('n', '4', ')'), ('4', ')', 'j'), (')', 'j', '='), ('j', '=', '1'), ('=', '1', 'n'), ('1', 'n', '5'), ('n', '5', ')'), ('5', ')', ''), (')', '', 'j'), ('', 'j', '6'), ('j', '6', ')'), ('6', ')', 'edge'), (')', 'edge', 'nodes')]

>> POS Tags are: 
 [('1', 'CD'), (')', ')'), ('Evaluate', 'NNP'), ('score', 'NN'), ('G', 'NNP'), (':', ':'), ('Score', 'NN'), ('(', '('), ('G', 'NNP'), (')', ')'), ('2', 'CD'), (')', ')'), ('G', 'NNP'), ('', 'NNP'), ('=', 'NNP'), ('G', 'NNP'), ('3', 'CD'), (')', ')'), ('=', 'VBD'), ('1', 'CD'), ('n', 'RB'), ('4', 'CD'), (')', ')'), ('j', 'NN'), ('=', '$'), ('1', 'CD'), ('n', 'RB'), ('5', 'CD'), (')', ')'), ('', 'NN'), ('j', '$'), ('6', 'CD'), (')', ')'), ('edge', 'NN'), ('nodes', 'NNS')]

>> Noun Phrases are: 
 ['Evaluate score G', 'Score', 'G', 'G  = G', 'j', '', 'edge nodes']

>> Named Entities are: 
 [('ORGANIZATION', 'Evaluate')] 

>> Stemming using Porter Stemmer: 
 [('1', '1'), (')', ')'), ('Evaluate', 'evalu'), ('score', 'score'), ('G', 'g'), (':', ':'), ('Score', 'score'), ('(', '('), ('G', 'g'), (')', ')'), ('2', '2'), (')', ')'), ('G', 'g'), ('', ''), ('=', '='), ('G', 'g'), ('3', '3'), (')', ')'), ('=', '='), ('1', '1'), ('n', 'n'), ('4', '4'), (')', ')'), ('j', 'j'), ('=', '='), ('1', '1'), ('n', 'n'), ('5', '5'), (')', ')'), ('', ''), ('j', 'j'), ('6', '6'), (')', ')'), ('edge', 'edg'), ('nodes', 'node')]

>> Stemming using Snowball Stemmer: 
 [('1', '1'), (')', ')'), ('Evaluate', 'evalu'), ('score', 'score'), ('G', 'g'), (':', ':'), ('Score', 'score'), ('(', '('), ('G', 'g'), (')', ')'), ('2', '2'), (')', ')'), ('G', 'g'), ('', ''), ('=', '='), ('G', 'g'), ('3', '3'), (')', ')'), ('=', '='), ('1', '1'), ('n', 'n'), ('4', '4'), (')', ')'), ('j', 'j'), ('=', '='), ('1', '1'), ('n', 'n'), ('5', '5'), (')', ')'), ('', ''), ('j', 'j'), ('6', '6'), (')', ')'), ('edge', 'edg'), ('nodes', 'node')]

>> Lemmatization: 
 [('1', '1'), (')', ')'), ('Evaluate', 'Evaluate'), ('score', 'score'), ('G', 'G'), (':', ':'), ('Score', 'Score'), ('(', '('), ('G', 'G'), (')', ')'), ('2', '2'), (')', ')'), ('G', 'G'), ('', ''), ('=', '='), ('G', 'G'), ('3', '3'), (')', ')'), ('=', '='), ('1', '1'), ('n', 'n'), ('4', '4'), (')', ')'), ('j', 'j'), ('=', '='), ('1', '1'), ('n', 'n'), ('5', '5'), (')', ')'), ('', ''), ('j', 'j'), ('6', '6'), (')', ')'), ('edge', 'edge'), ('nodes', 'node')]



========================================== PARAGRAPH 485 ===========================================

j in G then   

------------------- Sentence 1 -------------------

j in G then

>> Tokens are: 
 ['j', 'G']

>> Bigrams are: 
 [('j', 'G')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('j', 'NN'), ('G', 'NNP')]

>> Noun Phrases are: 
 ['j G']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('j', 'j'), ('G', 'g')]

>> Stemming using Snowball Stemmer: 
 [('j', 'j'), ('G', 'g')]

>> Lemmatization: 
 [('j', 'j'), ('G', 'G')]



========================================== PARAGRAPH 486 ===========================================

7) Modify G by adding an edge between  the nodes i and j in G such that i is a  

------------------- Sentence 1 -------------------

7) Modify G by adding an edge between  the nodes i and j in G such that i is a

>> Tokens are: 
 ['7', ')', 'Modify', 'G', '', 'adding', 'edge', 'nodes', 'j', 'G']

>> Bigrams are: 
 [('7', ')'), (')', 'Modify'), ('Modify', 'G'), ('G', ''), ('', 'adding'), ('adding', 'edge'), ('edge', 'nodes'), ('nodes', 'j'), ('j', 'G')]

>> Trigrams are: 
 [('7', ')', 'Modify'), (')', 'Modify', 'G'), ('Modify', 'G', ''), ('G', '', 'adding'), ('', 'adding', 'edge'), ('adding', 'edge', 'nodes'), ('edge', 'nodes', 'j'), ('nodes', 'j', 'G')]

>> POS Tags are: 
 [('7', 'CD'), (')', ')'), ('Modify', 'NNP'), ('G', 'NNP'), ('', 'NNP'), ('adding', 'VBG'), ('edge', 'NN'), ('nodes', 'NNS'), ('j', 'VBP'), ('G', 'NNP')]

>> Noun Phrases are: 
 ['Modify G ', 'edge nodes', 'G']

>> Named Entities are: 
 [('PERSON', 'Modify G')] 

>> Stemming using Porter Stemmer: 
 [('7', '7'), (')', ')'), ('Modify', 'modifi'), ('G', 'g'), ('', ''), ('adding', 'ad'), ('edge', 'edg'), ('nodes', 'node'), ('j', 'j'), ('G', 'g')]

>> Stemming using Snowball Stemmer: 
 [('7', '7'), (')', ')'), ('Modify', 'modifi'), ('G', 'g'), ('', ''), ('adding', 'ad'), ('edge', 'edg'), ('nodes', 'node'), ('j', 'j'), ('G', 'g')]

>> Lemmatization: 
 [('7', '7'), (')', ')'), ('Modify', 'Modify'), ('G', 'G'), ('', ''), ('adding', 'adding'), ('edge', 'edge'), ('nodes', 'node'), ('j', 'j'), ('G', 'G')]



========================================== PARAGRAPH 487 ===========================================

parent of j: (i  j)   

------------------- Sentence 1 -------------------

parent of j: (i  j)

>> Tokens are: 
 ['parent', 'j', ':', '(', '', 'j', ')']

>> Bigrams are: 
 [('parent', 'j'), ('j', ':'), (':', '('), ('(', ''), ('', 'j'), ('j', ')')]

>> Trigrams are: 
 [('parent', 'j', ':'), ('j', ':', '('), (':', '(', ''), ('(', '', 'j'), ('', 'j', ')')]

>> POS Tags are: 
 [('parent', 'NN'), ('j', 'NN'), (':', ':'), ('(', '('), ('', 'NNP'), ('j', 'NN'), (')', ')')]

>> Noun Phrases are: 
 ['parent j', ' j']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('parent', 'parent'), ('j', 'j'), (':', ':'), ('(', '('), ('', ''), ('j', 'j'), (')', ')')]

>> Stemming using Snowball Stemmer: 
 [('parent', 'parent'), ('j', 'j'), (':', ':'), ('(', '('), ('', ''), ('j', 'j'), (')', ')')]

>> Lemmatization: 
 [('parent', 'parent'), ('j', 'j'), (':', ':'), ('(', '('), ('', ''), ('j', 'j'), (')', ')')]



========================================== PARAGRAPH 488 ===========================================

8) if the resulting G is a DAG then   9) if (Score(G) > Score (G)) then   10) G = G   11) end if   12) end if   13) end if   14) end if   15) G = G   16) end for   

------------------- Sentence 1 -------------------

8) if the resulting G is a DAG then   9) if (Score(G) > Score (G)) then   10) G = G   11) end if   12) end if   13) end if   14) end if   15) G = G   16) end for

>> Tokens are: 
 ['8', ')', 'resulting', 'G', '', 'DAG', '9', ')', '(', 'Score', '(', 'G', '', ')', '>', 'Score', '(', 'G', ')', ')', '10', ')', 'G', '=', 'G', '', '11', ')', 'end', '12', ')', 'end', '13', ')', 'end', '14', ')', 'end', '15', ')', 'G', '', '=', 'G', '16', ')', 'end']

>> Bigrams are: 
 [('8', ')'), (')', 'resulting'), ('resulting', 'G'), ('G', ''), ('', 'DAG'), ('DAG', '9'), ('9', ')'), (')', '('), ('(', 'Score'), ('Score', '('), ('(', 'G'), ('G', ''), ('', ')'), (')', '>'), ('>', 'Score'), ('Score', '('), ('(', 'G'), ('G', ')'), (')', ')'), (')', '10'), ('10', ')'), (')', 'G'), ('G', '='), ('=', 'G'), ('G', ''), ('', '11'), ('11', ')'), (')', 'end'), ('end', '12'), ('12', ')'), (')', 'end'), ('end', '13'), ('13', ')'), (')', 'end'), ('end', '14'), ('14', ')'), (')', 'end'), ('end', '15'), ('15', ')'), (')', 'G'), ('G', ''), ('', '='), ('=', 'G'), ('G', '16'), ('16', ')'), (')', 'end')]

>> Trigrams are: 
 [('8', ')', 'resulting'), (')', 'resulting', 'G'), ('resulting', 'G', ''), ('G', '', 'DAG'), ('', 'DAG', '9'), ('DAG', '9', ')'), ('9', ')', '('), (')', '(', 'Score'), ('(', 'Score', '('), ('Score', '(', 'G'), ('(', 'G', ''), ('G', '', ')'), ('', ')', '>'), (')', '>', 'Score'), ('>', 'Score', '('), ('Score', '(', 'G'), ('(', 'G', ')'), ('G', ')', ')'), (')', ')', '10'), (')', '10', ')'), ('10', ')', 'G'), (')', 'G', '='), ('G', '=', 'G'), ('=', 'G', ''), ('G', '', '11'), ('', '11', ')'), ('11', ')', 'end'), (')', 'end', '12'), ('end', '12', ')'), ('12', ')', 'end'), (')', 'end', '13'), ('end', '13', ')'), ('13', ')', 'end'), (')', 'end', '14'), ('end', '14', ')'), ('14', ')', 'end'), (')', 'end', '15'), ('end', '15', ')'), ('15', ')', 'G'), (')', 'G', ''), ('G', '', '='), ('', '=', 'G'), ('=', 'G', '16'), ('G', '16', ')'), ('16', ')', 'end')]

>> POS Tags are: 
 [('8', 'CD'), (')', ')'), ('resulting', 'VBG'), ('G', 'NNP'), ('', 'NNP'), ('DAG', 'NNP'), ('9', 'CD'), (')', ')'), ('(', '('), ('Score', 'NNP'), ('(', '('), ('G', 'NNP'), ('', 'NNP'), (')', ')'), ('>', 'VBZ'), ('Score', 'NNP'), ('(', '('), ('G', 'NNP'), (')', ')'), (')', ')'), ('10', 'CD'), (')', ')'), ('G', 'NNP'), ('=', 'NNP'), ('G', 'NNP'), ('', 'NNP'), ('11', 'CD'), (')', ')'), ('end', 'VB'), ('12', 'CD'), (')', ')'), ('end', 'VB'), ('13', 'CD'), (')', ')'), ('end', 'VB'), ('14', 'CD'), (')', ')'), ('end', 'VB'), ('15', 'CD'), (')', ')'), ('G', 'NNP'), ('', 'NNP'), ('=', 'NNP'), ('G', 'NNP'), ('16', 'CD'), (')', ')'), ('end', 'NN')]

>> Noun Phrases are: 
 ['G  DAG', 'Score', 'G ', 'Score', 'G', 'G = G ', 'G  = G', 'end']

>> Named Entities are: 
 [('PERSON', 'G'), ('GPE', 'Score'), ('GPE', 'Score')] 

>> Stemming using Porter Stemmer: 
 [('8', '8'), (')', ')'), ('resulting', 'result'), ('G', 'g'), ('', ''), ('DAG', 'dag'), ('9', '9'), (')', ')'), ('(', '('), ('Score', 'score'), ('(', '('), ('G', 'g'), ('', ''), (')', ')'), ('>', '>'), ('Score', 'score'), ('(', '('), ('G', 'g'), (')', ')'), (')', ')'), ('10', '10'), (')', ')'), ('G', 'g'), ('=', '='), ('G', 'g'), ('', ''), ('11', '11'), (')', ')'), ('end', 'end'), ('12', '12'), (')', ')'), ('end', 'end'), ('13', '13'), (')', ')'), ('end', 'end'), ('14', '14'), (')', ')'), ('end', 'end'), ('15', '15'), (')', ')'), ('G', 'g'), ('', ''), ('=', '='), ('G', 'g'), ('16', '16'), (')', ')'), ('end', 'end')]

>> Stemming using Snowball Stemmer: 
 [('8', '8'), (')', ')'), ('resulting', 'result'), ('G', 'g'), ('', ''), ('DAG', 'dag'), ('9', '9'), (')', ')'), ('(', '('), ('Score', 'score'), ('(', '('), ('G', 'g'), ('', ''), (')', ')'), ('>', '>'), ('Score', 'score'), ('(', '('), ('G', 'g'), (')', ')'), (')', ')'), ('10', '10'), (')', ')'), ('G', 'g'), ('=', '='), ('G', 'g'), ('', ''), ('11', '11'), (')', ')'), ('end', 'end'), ('12', '12'), (')', ')'), ('end', 'end'), ('13', '13'), (')', ')'), ('end', 'end'), ('14', '14'), (')', ')'), ('end', 'end'), ('15', '15'), (')', ')'), ('G', 'g'), ('', ''), ('=', '='), ('G', 'g'), ('16', '16'), (')', ')'), ('end', 'end')]

>> Lemmatization: 
 [('8', '8'), (')', ')'), ('resulting', 'resulting'), ('G', 'G'), ('', ''), ('DAG', 'DAG'), ('9', '9'), (')', ')'), ('(', '('), ('Score', 'Score'), ('(', '('), ('G', 'G'), ('', ''), (')', ')'), ('>', '>'), ('Score', 'Score'), ('(', '('), ('G', 'G'), (')', ')'), (')', ')'), ('10', '10'), (')', ')'), ('G', 'G'), ('=', '='), ('G', 'G'), ('', ''), ('11', '11'), (')', ')'), ('end', 'end'), ('12', '12'), (')', ')'), ('end', 'end'), ('13', '13'), (')', ')'), ('end', 'end'), ('14', '14'), (')', ')'), ('end', 'end'), ('15', '15'), (')', ')'), ('G', 'G'), ('', ''), ('=', '='), ('G', 'G'), ('16', '16'), (')', ')'), ('end', 'end')]



========================================== PARAGRAPH 489 ===========================================

17) end for  

------------------- Sentence 1 -------------------

17) end for

>> Tokens are: 
 ['17', ')', 'end']

>> Bigrams are: 
 [('17', ')'), (')', 'end')]

>> Trigrams are: 
 [('17', ')', 'end')]

>> POS Tags are: 
 [('17', 'CD'), (')', ')'), ('end', 'NN')]

>> Noun Phrases are: 
 ['end']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('17', '17'), (')', ')'), ('end', 'end')]

>> Stemming using Snowball Stemmer: 
 [('17', '17'), (')', ')'), ('end', 'end')]

>> Lemmatization: 
 [('17', '17'), (')', ')'), ('end', 'end')]



========================================== PARAGRAPH 490 ===========================================

f(x) 

------------------- Sentence 1 -------------------

f(x)

>> Tokens are: 
 ['f', '(', 'x', ')']

>> Bigrams are: 
 [('f', '('), ('(', 'x'), ('x', ')')]

>> Trigrams are: 
 [('f', '(', 'x'), ('(', 'x', ')')]

>> POS Tags are: 
 [('f', 'NN'), ('(', '('), ('x', 'NN'), (')', ')')]

>> Noun Phrases are: 
 ['f', 'x']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('f', 'f'), ('(', '('), ('x', 'x'), (')', ')')]

>> Stemming using Snowball Stemmer: 
 [('f', 'f'), ('(', '('), ('x', 'x'), (')', ')')]

>> Lemmatization: 
 [('f', 'f'), ('(', '('), ('x', 'x'), (')', ')')]



========================================== PARAGRAPH 491 ===========================================

ISSN: 2229-6956(ONLINE)                                                                                                                             ICTACT JOURNAL ON SOFT COMPUTING, APRIL 2015, VOLUME: 05, ISSUE: 03  

------------------- Sentence 1 -------------------

ISSN: 2229-6956(ONLINE)                                                                                                                             ICTACT JOURNAL ON SOFT COMPUTING, APRIL 2015, VOLUME: 05, ISSUE: 03

>> Tokens are: 
 ['ISSN', ':', '2229-6956', '(', 'ONLINE', ')', 'ICTACT', 'JOURNAL', 'ON', 'SOFT', 'COMPUTING', ',', 'APRIL', '2015', ',', 'VOLUME', ':', '05', ',', 'ISSUE', ':', '03']

>> Bigrams are: 
 [('ISSN', ':'), (':', '2229-6956'), ('2229-6956', '('), ('(', 'ONLINE'), ('ONLINE', ')'), (')', 'ICTACT'), ('ICTACT', 'JOURNAL'), ('JOURNAL', 'ON'), ('ON', 'SOFT'), ('SOFT', 'COMPUTING'), ('COMPUTING', ','), (',', 'APRIL'), ('APRIL', '2015'), ('2015', ','), (',', 'VOLUME'), ('VOLUME', ':'), (':', '05'), ('05', ','), (',', 'ISSUE'), ('ISSUE', ':'), (':', '03')]

>> Trigrams are: 
 [('ISSN', ':', '2229-6956'), (':', '2229-6956', '('), ('2229-6956', '(', 'ONLINE'), ('(', 'ONLINE', ')'), ('ONLINE', ')', 'ICTACT'), (')', 'ICTACT', 'JOURNAL'), ('ICTACT', 'JOURNAL', 'ON'), ('JOURNAL', 'ON', 'SOFT'), ('ON', 'SOFT', 'COMPUTING'), ('SOFT', 'COMPUTING', ','), ('COMPUTING', ',', 'APRIL'), (',', 'APRIL', '2015'), ('APRIL', '2015', ','), ('2015', ',', 'VOLUME'), (',', 'VOLUME', ':'), ('VOLUME', ':', '05'), (':', '05', ','), ('05', ',', 'ISSUE'), (',', 'ISSUE', ':'), ('ISSUE', ':', '03')]

>> POS Tags are: 
 [('ISSN', 'NN'), (':', ':'), ('2229-6956', 'JJ'), ('(', '('), ('ONLINE', 'NNP'), (')', ')'), ('ICTACT', 'NNP'), ('JOURNAL', 'NNP'), ('ON', 'NNP'), ('SOFT', 'NNP'), ('COMPUTING', 'NNP'), (',', ','), ('APRIL', 'NNP'), ('2015', 'CD'), (',', ','), ('VOLUME', 'NNP'), (':', ':'), ('05', 'CD'), (',', ','), ('ISSUE', 'NNP'), (':', ':'), ('03', 'CD')]

>> Noun Phrases are: 
 ['ISSN', 'ONLINE', 'ICTACT JOURNAL ON SOFT COMPUTING', 'APRIL', 'VOLUME', 'ISSUE']

>> Named Entities are: 
 [('ORGANIZATION', 'ONLINE'), ('ORGANIZATION', 'ICTACT'), ('ORGANIZATION', 'VOLUME'), ('ORGANIZATION', 'ISSUE')] 

>> Stemming using Porter Stemmer: 
 [('ISSN', 'issn'), (':', ':'), ('2229-6956', '2229-6956'), ('(', '('), ('ONLINE', 'onlin'), (')', ')'), ('ICTACT', 'ictact'), ('JOURNAL', 'journal'), ('ON', 'on'), ('SOFT', 'soft'), ('COMPUTING', 'comput'), (',', ','), ('APRIL', 'april'), ('2015', '2015'), (',', ','), ('VOLUME', 'volum'), (':', ':'), ('05', '05'), (',', ','), ('ISSUE', 'issu'), (':', ':'), ('03', '03')]

>> Stemming using Snowball Stemmer: 
 [('ISSN', 'issn'), (':', ':'), ('2229-6956', '2229-6956'), ('(', '('), ('ONLINE', 'onlin'), (')', ')'), ('ICTACT', 'ictact'), ('JOURNAL', 'journal'), ('ON', 'on'), ('SOFT', 'soft'), ('COMPUTING', 'comput'), (',', ','), ('APRIL', 'april'), ('2015', '2015'), (',', ','), ('VOLUME', 'volum'), (':', ':'), ('05', '05'), (',', ','), ('ISSUE', 'issu'), (':', ':'), ('03', '03')]

>> Lemmatization: 
 [('ISSN', 'ISSN'), (':', ':'), ('2229-6956', '2229-6956'), ('(', '('), ('ONLINE', 'ONLINE'), (')', ')'), ('ICTACT', 'ICTACT'), ('JOURNAL', 'JOURNAL'), ('ON', 'ON'), ('SOFT', 'SOFT'), ('COMPUTING', 'COMPUTING'), (',', ','), ('APRIL', 'APRIL'), ('2015', '2015'), (',', ','), ('VOLUME', 'VOLUME'), (':', ':'), ('05', '05'), (',', ','), ('ISSUE', 'ISSUE'), (':', ':'), ('03', '03')]



========================================== PARAGRAPH 492 ===========================================

951  

------------------- Sentence 1 -------------------

951

>> Tokens are: 
 ['951']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('951', 'CD')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('951', '951')]

>> Stemming using Snowball Stemmer: 
 [('951', '951')]

>> Lemmatization: 
 [('951', '951')]



========================================== PARAGRAPH 493 ===========================================

will be classified. Some new kernels are being proposed by  

------------------- Sentence 1 -------------------

will be classified.

>> Tokens are: 
 ['classified', '.']

>> Bigrams are: 
 [('classified', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('classified', 'VBN'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('classified', 'classifi'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('classified', 'classifi'), ('.', '.')]

>> Lemmatization: 
 [('classified', 'classified'), ('.', '.')]


------------------- Sentence 2 -------------------

Some new kernels are being proposed by

>> Tokens are: 
 ['Some', 'new', 'kernels', 'proposed']

>> Bigrams are: 
 [('Some', 'new'), ('new', 'kernels'), ('kernels', 'proposed')]

>> Trigrams are: 
 [('Some', 'new', 'kernels'), ('new', 'kernels', 'proposed')]

>> POS Tags are: 
 [('Some', 'DT'), ('new', 'JJ'), ('kernels', 'NNS'), ('proposed', 'VBN')]

>> Noun Phrases are: 
 ['Some new kernels']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Some', 'some'), ('new', 'new'), ('kernels', 'kernel'), ('proposed', 'propos')]

>> Stemming using Snowball Stemmer: 
 [('Some', 'some'), ('new', 'new'), ('kernels', 'kernel'), ('proposed', 'propos')]

>> Lemmatization: 
 [('Some', 'Some'), ('new', 'new'), ('kernels', 'kernel'), ('proposed', 'proposed')]



========================================== PARAGRAPH 494 ===========================================

researchers but given bellow is list of some popular kernels:  

------------------- Sentence 1 -------------------

researchers but given bellow is list of some popular kernels:

>> Tokens are: 
 ['researchers', 'given', 'bellow', 'list', 'popular', 'kernels', ':']

>> Bigrams are: 
 [('researchers', 'given'), ('given', 'bellow'), ('bellow', 'list'), ('list', 'popular'), ('popular', 'kernels'), ('kernels', ':')]

>> Trigrams are: 
 [('researchers', 'given', 'bellow'), ('given', 'bellow', 'list'), ('bellow', 'list', 'popular'), ('list', 'popular', 'kernels'), ('popular', 'kernels', ':')]

>> POS Tags are: 
 [('researchers', 'NNS'), ('given', 'VBN'), ('bellow', 'JJ'), ('list', 'NN'), ('popular', 'JJ'), ('kernels', 'NNS'), (':', ':')]

>> Noun Phrases are: 
 ['researchers', 'bellow list', 'popular kernels']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('researchers', 'research'), ('given', 'given'), ('bellow', 'bellow'), ('list', 'list'), ('popular', 'popular'), ('kernels', 'kernel'), (':', ':')]

>> Stemming using Snowball Stemmer: 
 [('researchers', 'research'), ('given', 'given'), ('bellow', 'bellow'), ('list', 'list'), ('popular', 'popular'), ('kernels', 'kernel'), (':', ':')]

>> Lemmatization: 
 [('researchers', 'researcher'), ('given', 'given'), ('bellow', 'bellow'), ('list', 'list'), ('popular', 'popular'), ('kernels', 'kernel'), (':', ':')]



========================================== PARAGRAPH 495 ===========================================

 Linear:   j T iji XXXXK ,   

------------------- Sentence 1 -------------------

 Linear:   j T iji XXXXK ,

>> Tokens are: 
 ['\uf0b7', 'Linear', ':', '\uf028', '\uf029', 'j', 'T', 'iji', 'XXXXK', '\uf03d', ',']

>> Bigrams are: 
 [('\uf0b7', 'Linear'), ('Linear', ':'), (':', '\uf028'), ('\uf028', '\uf029'), ('\uf029', 'j'), ('j', 'T'), ('T', 'iji'), ('iji', 'XXXXK'), ('XXXXK', '\uf03d'), ('\uf03d', ',')]

>> Trigrams are: 
 [('\uf0b7', 'Linear', ':'), ('Linear', ':', '\uf028'), (':', '\uf028', '\uf029'), ('\uf028', '\uf029', 'j'), ('\uf029', 'j', 'T'), ('j', 'T', 'iji'), ('T', 'iji', 'XXXXK'), ('iji', 'XXXXK', '\uf03d'), ('XXXXK', '\uf03d', ',')]

>> POS Tags are: 
 [('\uf0b7', 'JJ'), ('Linear', 'NNP'), (':', ':'), ('\uf028', 'NN'), ('\uf029', 'NNP'), ('j', 'NN'), ('T', 'NNP'), ('iji', 'NN'), ('XXXXK', 'NNP'), ('\uf03d', 'NNP'), (',', ',')]

>> Noun Phrases are: 
 ['\uf0b7 Linear', '\uf028 \uf029 j T iji XXXXK \uf03d']

>> Named Entities are: 
 [('ORGANIZATION', 'XXXXK')] 

>> Stemming using Porter Stemmer: 
 [('\uf0b7', '\uf0b7'), ('Linear', 'linear'), (':', ':'), ('\uf028', '\uf028'), ('\uf029', '\uf029'), ('j', 'j'), ('T', 't'), ('iji', 'iji'), ('XXXXK', 'xxxxk'), ('\uf03d', '\uf03d'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('\uf0b7', '\uf0b7'), ('Linear', 'linear'), (':', ':'), ('\uf028', '\uf028'), ('\uf029', '\uf029'), ('j', 'j'), ('T', 't'), ('iji', 'iji'), ('XXXXK', 'xxxxk'), ('\uf03d', '\uf03d'), (',', ',')]

>> Lemmatization: 
 [('\uf0b7', '\uf0b7'), ('Linear', 'Linear'), (':', ':'), ('\uf028', '\uf028'), ('\uf029', '\uf029'), ('j', 'j'), ('T', 'T'), ('iji', 'iji'), ('XXXXK', 'XXXXK'), ('\uf03d', '\uf03d'), (',', ',')]



========================================== PARAGRAPH 496 ===========================================

 Polynomial:     0,,   djTiji rXXXXK    Radial Basis Function (RBF):  

------------------- Sentence 1 -------------------

 Polynomial:     0,,   djTiji rXXXXK    Radial Basis Function (RBF):

>> Tokens are: 
 ['\uf0b7', 'Polynomial', ':', '\uf028', '\uf029', '\uf028', '\uf029', '0', ',', ',', '\uf03e\uf02b\uf03d', '\uf067\uf067', 'djTiji', 'rXXXXK', '\uf0b7', 'Radial', 'Basis', 'Function', '(', 'RBF', ')', ':']

>> Bigrams are: 
 [('\uf0b7', 'Polynomial'), ('Polynomial', ':'), (':', '\uf028'), ('\uf028', '\uf029'), ('\uf029', '\uf028'), ('\uf028', '\uf029'), ('\uf029', '0'), ('0', ','), (',', ','), (',', '\uf03e\uf02b\uf03d'), ('\uf03e\uf02b\uf03d', '\uf067\uf067'), ('\uf067\uf067', 'djTiji'), ('djTiji', 'rXXXXK'), ('rXXXXK', '\uf0b7'), ('\uf0b7', 'Radial'), ('Radial', 'Basis'), ('Basis', 'Function'), ('Function', '('), ('(', 'RBF'), ('RBF', ')'), (')', ':')]

>> Trigrams are: 
 [('\uf0b7', 'Polynomial', ':'), ('Polynomial', ':', '\uf028'), (':', '\uf028', '\uf029'), ('\uf028', '\uf029', '\uf028'), ('\uf029', '\uf028', '\uf029'), ('\uf028', '\uf029', '0'), ('\uf029', '0', ','), ('0', ',', ','), (',', ',', '\uf03e\uf02b\uf03d'), (',', '\uf03e\uf02b\uf03d', '\uf067\uf067'), ('\uf03e\uf02b\uf03d', '\uf067\uf067', 'djTiji'), ('\uf067\uf067', 'djTiji', 'rXXXXK'), ('djTiji', 'rXXXXK', '\uf0b7'), ('rXXXXK', '\uf0b7', 'Radial'), ('\uf0b7', 'Radial', 'Basis'), ('Radial', 'Basis', 'Function'), ('Basis', 'Function', '('), ('Function', '(', 'RBF'), ('(', 'RBF', ')'), ('RBF', ')', ':')]

>> POS Tags are: 
 [('\uf0b7', 'JJ'), ('Polynomial', 'NNP'), (':', ':'), ('\uf028', 'NN'), ('\uf029', 'NNP'), ('\uf028', 'NNP'), ('\uf029', 'NNP'), ('0', 'CD'), (',', ','), (',', ','), ('\uf03e\uf02b\uf03d', 'NNP'), ('\uf067\uf067', 'NNP'), ('djTiji', 'NN'), ('rXXXXK', 'NN'), ('\uf0b7', 'NNP'), ('Radial', 'NNP'), ('Basis', 'NNP'), ('Function', 'NNP'), ('(', '('), ('RBF', 'NNP'), (')', ')'), (':', ':')]

>> Noun Phrases are: 
 ['\uf0b7 Polynomial', '\uf028 \uf029 \uf028 \uf029', '\uf03e\uf02b\uf03d \uf067\uf067 djTiji rXXXXK \uf0b7 Radial Basis Function', 'RBF']

>> Named Entities are: 
 [('ORGANIZATION', 'rXXXXK'), ('ORGANIZATION', 'RBF')] 

>> Stemming using Porter Stemmer: 
 [('\uf0b7', '\uf0b7'), ('Polynomial', 'polynomi'), (':', ':'), ('\uf028', '\uf028'), ('\uf029', '\uf029'), ('\uf028', '\uf028'), ('\uf029', '\uf029'), ('0', '0'), (',', ','), (',', ','), ('\uf03e\uf02b\uf03d', '\uf03e\uf02b\uf03d'), ('\uf067\uf067', '\uf067\uf067'), ('djTiji', 'djtiji'), ('rXXXXK', 'rxxxxk'), ('\uf0b7', '\uf0b7'), ('Radial', 'radial'), ('Basis', 'basi'), ('Function', 'function'), ('(', '('), ('RBF', 'rbf'), (')', ')'), (':', ':')]

>> Stemming using Snowball Stemmer: 
 [('\uf0b7', '\uf0b7'), ('Polynomial', 'polynomi'), (':', ':'), ('\uf028', '\uf028'), ('\uf029', '\uf029'), ('\uf028', '\uf028'), ('\uf029', '\uf029'), ('0', '0'), (',', ','), (',', ','), ('\uf03e\uf02b\uf03d', '\uf03e\uf02b\uf03d'), ('\uf067\uf067', '\uf067\uf067'), ('djTiji', 'djtiji'), ('rXXXXK', 'rxxxxk'), ('\uf0b7', '\uf0b7'), ('Radial', 'radial'), ('Basis', 'basi'), ('Function', 'function'), ('(', '('), ('RBF', 'rbf'), (')', ')'), (':', ':')]

>> Lemmatization: 
 [('\uf0b7', '\uf0b7'), ('Polynomial', 'Polynomial'), (':', ':'), ('\uf028', '\uf028'), ('\uf029', '\uf029'), ('\uf028', '\uf028'), ('\uf029', '\uf029'), ('0', '0'), (',', ','), (',', ','), ('\uf03e\uf02b\uf03d', '\uf03e\uf02b\uf03d'), ('\uf067\uf067', '\uf067\uf067'), ('djTiji', 'djTiji'), ('rXXXXK', 'rXXXXK'), ('\uf0b7', '\uf0b7'), ('Radial', 'Radial'), ('Basis', 'Basis'), ('Function', 'Function'), ('(', '('), ('RBF', 'RBF'), (')', ')'), (':', ':')]



========================================== PARAGRAPH 497 ===========================================

  0,exp, 2 

------------------- Sentence 1 -------------------

  0,exp, 2

>> Tokens are: 
 ['\uf028', '\uf029', '0', ',', 'exp', ',', '2']

>> Bigrams are: 
 [('\uf028', '\uf029'), ('\uf029', '0'), ('0', ','), (',', 'exp'), ('exp', ','), (',', '2')]

>> Trigrams are: 
 [('\uf028', '\uf029', '0'), ('\uf029', '0', ','), ('0', ',', 'exp'), (',', 'exp', ','), ('exp', ',', '2')]

>> POS Tags are: 
 [('\uf028', 'JJ'), ('\uf029', 'NN'), ('0', 'CD'), (',', ','), ('exp', 'NN'), (',', ','), ('2', 'CD')]

>> Noun Phrases are: 
 ['\uf028 \uf029', 'exp']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('\uf028', '\uf028'), ('\uf029', '\uf029'), ('0', '0'), (',', ','), ('exp', 'exp'), (',', ','), ('2', '2')]

>> Stemming using Snowball Stemmer: 
 [('\uf028', '\uf028'), ('\uf029', '\uf029'), ('0', '0'), (',', ','), ('exp', 'exp'), (',', ','), ('2', '2')]

>> Lemmatization: 
 [('\uf028', '\uf028'), ('\uf029', '\uf029'), ('0', '0'), (',', ','), ('exp', 'exp'), (',', ','), ('2', '2')]



========================================== PARAGRAPH 498 ===========================================

  

------------------- Sentence 1 -------------------

 

>> Tokens are: 
 ['\uf03e\uf0f7', '\uf0f8']

>> Bigrams are: 
 [('\uf03e\uf0f7', '\uf0f8')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('\uf03e\uf0f7', 'NN'), ('\uf0f8', 'NN')]

>> Noun Phrases are: 
 ['\uf03e\uf0f7 \uf0f8']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('\uf03e\uf0f7', '\uf03e\uf0f7'), ('\uf0f8', '\uf0f8')]

>> Stemming using Snowball Stemmer: 
 [('\uf03e\uf0f7', '\uf03e\uf0f7'), ('\uf0f8', '\uf0f8')]

>> Lemmatization: 
 [('\uf03e\uf0f7', '\uf03e\uf0f7'), ('\uf0f8', '\uf0f8')]



========================================== PARAGRAPH 499 ===========================================

   

------------------- Sentence 1 -------------------

  

>> Tokens are: 
 ['\uf0f6', '\uf0e7', '\uf0e8']

>> Bigrams are: 
 [('\uf0f6', '\uf0e7'), ('\uf0e7', '\uf0e8')]

>> Trigrams are: 
 [('\uf0f6', '\uf0e7', '\uf0e8')]

>> POS Tags are: 
 [('\uf0f6', 'JJ'), ('\uf0e7', 'NNP'), ('\uf0e8', 'NN')]

>> Noun Phrases are: 
 ['\uf0f6 \uf0e7 \uf0e8']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('\uf0f6', '\uf0f6'), ('\uf0e7', '\uf0e7'), ('\uf0e8', '\uf0e8')]

>> Stemming using Snowball Stemmer: 
 [('\uf0f6', '\uf0f6'), ('\uf0e7', '\uf0e7'), ('\uf0e8', '\uf0e8')]

>> Lemmatization: 
 [('\uf0f6', '\uf0f6'), ('\uf0e7', '\uf0e7'), ('\uf0e8', '\uf0e8')]



========================================== PARAGRAPH 500 ===========================================

   jiji XXXXK   

------------------- Sentence 1 -------------------

   jiji XXXXK

>> Tokens are: 
 ['\uf0e6', '\uf02d\uf02d\uf03d', '\uf067\uf067', 'jiji', 'XXXXK']

>> Bigrams are: 
 [('\uf0e6', '\uf02d\uf02d\uf03d'), ('\uf02d\uf02d\uf03d', '\uf067\uf067'), ('\uf067\uf067', 'jiji'), ('jiji', 'XXXXK')]

>> Trigrams are: 
 [('\uf0e6', '\uf02d\uf02d\uf03d', '\uf067\uf067'), ('\uf02d\uf02d\uf03d', '\uf067\uf067', 'jiji'), ('\uf067\uf067', 'jiji', 'XXXXK')]

>> POS Tags are: 
 [('\uf0e6', 'JJ'), ('\uf02d\uf02d\uf03d', 'NNP'), ('\uf067\uf067', 'NNP'), ('jiji', 'NN'), ('XXXXK', 'NN')]

>> Noun Phrases are: 
 ['\uf0e6 \uf02d\uf02d\uf03d \uf067\uf067 jiji XXXXK']

>> Named Entities are: 
 [('ORGANIZATION', 'XXXXK')] 

>> Stemming using Porter Stemmer: 
 [('\uf0e6', '\uf0e6'), ('\uf02d\uf02d\uf03d', '\uf02d\uf02d\uf03d'), ('\uf067\uf067', '\uf067\uf067'), ('jiji', 'jiji'), ('XXXXK', 'xxxxk')]

>> Stemming using Snowball Stemmer: 
 [('\uf0e6', '\uf0e6'), ('\uf02d\uf02d\uf03d', '\uf02d\uf02d\uf03d'), ('\uf067\uf067', '\uf067\uf067'), ('jiji', 'jiji'), ('XXXXK', 'xxxxk')]

>> Lemmatization: 
 [('\uf0e6', '\uf0e6'), ('\uf02d\uf02d\uf03d', '\uf02d\uf02d\uf03d'), ('\uf067\uf067', '\uf067\uf067'), ('jiji', 'jiji'), ('XXXXK', 'XXXXK')]



========================================== PARAGRAPH 501 ===========================================

 Sigmoid:    rXXXXK jTiji  tanh,   Here dr  and ,  are the kernel parameters. Where, iX is a  

------------------- Sentence 1 -------------------

 Sigmoid:    rXXXXK jTiji  tanh,   Here dr  and ,  are the kernel parameters.

>> Tokens are: 
 ['\uf0b7', 'Sigmoid', ':', '\uf028', '\uf029', '\uf028', '\uf029rXXXXK', 'jTiji', '\uf02b\uf03d', '\uf067tanh', ',', 'Here', 'dr', ',', '\uf067', 'kernel', 'parameters', '.']

>> Bigrams are: 
 [('\uf0b7', 'Sigmoid'), ('Sigmoid', ':'), (':', '\uf028'), ('\uf028', '\uf029'), ('\uf029', '\uf028'), ('\uf028', '\uf029rXXXXK'), ('\uf029rXXXXK', 'jTiji'), ('jTiji', '\uf02b\uf03d'), ('\uf02b\uf03d', '\uf067tanh'), ('\uf067tanh', ','), (',', 'Here'), ('Here', 'dr'), ('dr', ','), (',', '\uf067'), ('\uf067', 'kernel'), ('kernel', 'parameters'), ('parameters', '.')]

>> Trigrams are: 
 [('\uf0b7', 'Sigmoid', ':'), ('Sigmoid', ':', '\uf028'), (':', '\uf028', '\uf029'), ('\uf028', '\uf029', '\uf028'), ('\uf029', '\uf028', '\uf029rXXXXK'), ('\uf028', '\uf029rXXXXK', 'jTiji'), ('\uf029rXXXXK', 'jTiji', '\uf02b\uf03d'), ('jTiji', '\uf02b\uf03d', '\uf067tanh'), ('\uf02b\uf03d', '\uf067tanh', ','), ('\uf067tanh', ',', 'Here'), (',', 'Here', 'dr'), ('Here', 'dr', ','), ('dr', ',', '\uf067'), (',', '\uf067', 'kernel'), ('\uf067', 'kernel', 'parameters'), ('kernel', 'parameters', '.')]

>> POS Tags are: 
 [('\uf0b7', 'JJ'), ('Sigmoid', 'NNP'), (':', ':'), ('\uf028', 'NN'), ('\uf029', 'NNP'), ('\uf028', 'NNP'), ('\uf029rXXXXK', 'NNP'), ('jTiji', 'NN'), ('\uf02b\uf03d', 'NNP'), ('\uf067tanh', 'NNP'), (',', ','), ('Here', 'RB'), ('dr', 'NN'), (',', ','), ('\uf067', 'NNP'), ('kernel', 'NN'), ('parameters', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['\uf0b7 Sigmoid', '\uf028 \uf029 \uf028 \uf029rXXXXK jTiji \uf02b\uf03d \uf067tanh', 'dr', '\uf067 kernel parameters']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('\uf0b7', '\uf0b7'), ('Sigmoid', 'sigmoid'), (':', ':'), ('\uf028', '\uf028'), ('\uf029', '\uf029'), ('\uf028', '\uf028'), ('\uf029rXXXXK', '\uf029rxxxxk'), ('jTiji', 'jtiji'), ('\uf02b\uf03d', '\uf02b\uf03d'), ('\uf067tanh', '\uf067tanh'), (',', ','), ('Here', 'here'), ('dr', 'dr'), (',', ','), ('\uf067', '\uf067'), ('kernel', 'kernel'), ('parameters', 'paramet'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('\uf0b7', '\uf0b7'), ('Sigmoid', 'sigmoid'), (':', ':'), ('\uf028', '\uf028'), ('\uf029', '\uf029'), ('\uf028', '\uf028'), ('\uf029rXXXXK', '\uf029rxxxxk'), ('jTiji', 'jtiji'), ('\uf02b\uf03d', '\uf02b\uf03d'), ('\uf067tanh', '\uf067tanh'), (',', ','), ('Here', 'here'), ('dr', 'dr'), (',', ','), ('\uf067', '\uf067'), ('kernel', 'kernel'), ('parameters', 'paramet'), ('.', '.')]

>> Lemmatization: 
 [('\uf0b7', '\uf0b7'), ('Sigmoid', 'Sigmoid'), (':', ':'), ('\uf028', '\uf028'), ('\uf029', '\uf029'), ('\uf028', '\uf028'), ('\uf029rXXXXK', '\uf029rXXXXK'), ('jTiji', 'jTiji'), ('\uf02b\uf03d', '\uf02b\uf03d'), ('\uf067tanh', '\uf067tanh'), (',', ','), ('Here', 'Here'), ('dr', 'dr'), (',', ','), ('\uf067', '\uf067'), ('kernel', 'kernel'), ('parameters', 'parameter'), ('.', '.')]


------------------- Sentence 2 -------------------

Where, iX is a

>> Tokens are: 
 ['Where', ',', 'iX']

>> Bigrams are: 
 [('Where', ','), (',', 'iX')]

>> Trigrams are: 
 [('Where', ',', 'iX')]

>> POS Tags are: 
 [('Where', 'WRB'), (',', ','), ('iX', 'VB')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Where', 'where'), (',', ','), ('iX', 'ix')]

>> Stemming using Snowball Stemmer: 
 [('Where', 'where'), (',', ','), ('iX', 'ix')]

>> Lemmatization: 
 [('Where', 'Where'), (',', ','), ('iX', 'iX')]



========================================== PARAGRAPH 502 ===========================================

training vector and mapped into a high dimensional space by the  function  and    jji XXXK ,  is known as kernel function.  

------------------- Sentence 1 -------------------

training vector and mapped into a high dimensional space by the  function  and    jji XXXK ,  is known as kernel function.

>> Tokens are: 
 ['training', 'vector', 'mapped', 'high', 'dimensional', 'space', 'function', '\uf066', '\uf028', '\uf029', '\uf028', '\uf029jji', 'XXXK', '\uf066\uf0ba', ',', 'known', 'kernel', 'function', '.']

>> Bigrams are: 
 [('training', 'vector'), ('vector', 'mapped'), ('mapped', 'high'), ('high', 'dimensional'), ('dimensional', 'space'), ('space', 'function'), ('function', '\uf066'), ('\uf066', '\uf028'), ('\uf028', '\uf029'), ('\uf029', '\uf028'), ('\uf028', '\uf029jji'), ('\uf029jji', 'XXXK'), ('XXXK', '\uf066\uf0ba'), ('\uf066\uf0ba', ','), (',', 'known'), ('known', 'kernel'), ('kernel', 'function'), ('function', '.')]

>> Trigrams are: 
 [('training', 'vector', 'mapped'), ('vector', 'mapped', 'high'), ('mapped', 'high', 'dimensional'), ('high', 'dimensional', 'space'), ('dimensional', 'space', 'function'), ('space', 'function', '\uf066'), ('function', '\uf066', '\uf028'), ('\uf066', '\uf028', '\uf029'), ('\uf028', '\uf029', '\uf028'), ('\uf029', '\uf028', '\uf029jji'), ('\uf028', '\uf029jji', 'XXXK'), ('\uf029jji', 'XXXK', '\uf066\uf0ba'), ('XXXK', '\uf066\uf0ba', ','), ('\uf066\uf0ba', ',', 'known'), (',', 'known', 'kernel'), ('known', 'kernel', 'function'), ('kernel', 'function', '.')]

>> POS Tags are: 
 [('training', 'VBG'), ('vector', 'NN'), ('mapped', 'VBD'), ('high', 'JJ'), ('dimensional', 'JJ'), ('space', 'NN'), ('function', 'NN'), ('\uf066', 'NNP'), ('\uf028', 'NNP'), ('\uf029', 'NNP'), ('\uf028', 'NNP'), ('\uf029jji', 'NNP'), ('XXXK', 'NNP'), ('\uf066\uf0ba', 'NNP'), (',', ','), ('known', 'VBN'), ('kernel', 'NN'), ('function', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['vector', 'high dimensional space function \uf066 \uf028 \uf029 \uf028 \uf029jji XXXK \uf066\uf0ba', 'kernel function']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('training', 'train'), ('vector', 'vector'), ('mapped', 'map'), ('high', 'high'), ('dimensional', 'dimension'), ('space', 'space'), ('function', 'function'), ('\uf066', '\uf066'), ('\uf028', '\uf028'), ('\uf029', '\uf029'), ('\uf028', '\uf028'), ('\uf029jji', '\uf029jji'), ('XXXK', 'xxxk'), ('\uf066\uf0ba', '\uf066\uf0ba'), (',', ','), ('known', 'known'), ('kernel', 'kernel'), ('function', 'function'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('training', 'train'), ('vector', 'vector'), ('mapped', 'map'), ('high', 'high'), ('dimensional', 'dimension'), ('space', 'space'), ('function', 'function'), ('\uf066', '\uf066'), ('\uf028', '\uf028'), ('\uf029', '\uf029'), ('\uf028', '\uf028'), ('\uf029jji', '\uf029jji'), ('XXXK', 'xxxk'), ('\uf066\uf0ba', '\uf066\uf0ba'), (',', ','), ('known', 'known'), ('kernel', 'kernel'), ('function', 'function'), ('.', '.')]

>> Lemmatization: 
 [('training', 'training'), ('vector', 'vector'), ('mapped', 'mapped'), ('high', 'high'), ('dimensional', 'dimensional'), ('space', 'space'), ('function', 'function'), ('\uf066', '\uf066'), ('\uf028', '\uf028'), ('\uf029', '\uf029'), ('\uf028', '\uf028'), ('\uf029jji', '\uf029jji'), ('XXXK', 'XXXK'), ('\uf066\uf0ba', '\uf066\uf0ba'), (',', ','), ('known', 'known'), ('kernel', 'kernel'), ('function', 'function'), ('.', '.')]



========================================== PARAGRAPH 503 ===========================================

7. DEEP LEARNING   

------------------- Sentence 1 -------------------

7.

>> Tokens are: 
 ['7', '.']

>> Bigrams are: 
 [('7', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('7', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('7', '7'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('7', '7'), ('.', '.')]

>> Lemmatization: 
 [('7', '7'), ('.', '.')]


------------------- Sentence 2 -------------------

DEEP LEARNING

>> Tokens are: 
 ['DEEP', 'LEARNING']

>> Bigrams are: 
 [('DEEP', 'LEARNING')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('DEEP', 'NNP'), ('LEARNING', 'NN')]

>> Noun Phrases are: 
 ['DEEP LEARNING']

>> Named Entities are: 
 [('GPE', 'DEEP')] 

>> Stemming using Porter Stemmer: 
 [('DEEP', 'deep'), ('LEARNING', 'learn')]

>> Stemming using Snowball Stemmer: 
 [('DEEP', 'deep'), ('LEARNING', 'learn')]

>> Lemmatization: 
 [('DEEP', 'DEEP'), ('LEARNING', 'LEARNING')]



========================================== PARAGRAPH 504 ===========================================

The use of deep artificial neural networks has gain popularity  

------------------- Sentence 1 -------------------

The use of deep artificial neural networks has gain popularity

>> Tokens are: 
 ['The', 'use', 'deep', 'artificial', 'neural', 'networks', 'gain', 'popularity']

>> Bigrams are: 
 [('The', 'use'), ('use', 'deep'), ('deep', 'artificial'), ('artificial', 'neural'), ('neural', 'networks'), ('networks', 'gain'), ('gain', 'popularity')]

>> Trigrams are: 
 [('The', 'use', 'deep'), ('use', 'deep', 'artificial'), ('deep', 'artificial', 'neural'), ('artificial', 'neural', 'networks'), ('neural', 'networks', 'gain'), ('networks', 'gain', 'popularity')]

>> POS Tags are: 
 [('The', 'DT'), ('use', 'NN'), ('deep', 'JJ'), ('artificial', 'JJ'), ('neural', 'JJ'), ('networks', 'NNS'), ('gain', 'VBP'), ('popularity', 'NN')]

>> Noun Phrases are: 
 ['The use', 'deep artificial neural networks', 'popularity']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('use', 'use'), ('deep', 'deep'), ('artificial', 'artifici'), ('neural', 'neural'), ('networks', 'network'), ('gain', 'gain'), ('popularity', 'popular')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('use', 'use'), ('deep', 'deep'), ('artificial', 'artifici'), ('neural', 'neural'), ('networks', 'network'), ('gain', 'gain'), ('popularity', 'popular')]

>> Lemmatization: 
 [('The', 'The'), ('use', 'use'), ('deep', 'deep'), ('artificial', 'artificial'), ('neural', 'neural'), ('networks', 'network'), ('gain', 'gain'), ('popularity', 'popularity')]



========================================== PARAGRAPH 505 ===========================================

for the last few years in pattern recognition and machine  

------------------- Sentence 1 -------------------

for the last few years in pattern recognition and machine

>> Tokens are: 
 ['last', 'years', 'pattern', 'recognition', 'machine']

>> Bigrams are: 
 [('last', 'years'), ('years', 'pattern'), ('pattern', 'recognition'), ('recognition', 'machine')]

>> Trigrams are: 
 [('last', 'years', 'pattern'), ('years', 'pattern', 'recognition'), ('pattern', 'recognition', 'machine')]

>> POS Tags are: 
 [('last', 'JJ'), ('years', 'NNS'), ('pattern', 'JJ'), ('recognition', 'NN'), ('machine', 'NN')]

>> Noun Phrases are: 
 ['last years', 'pattern recognition machine']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('last', 'last'), ('years', 'year'), ('pattern', 'pattern'), ('recognition', 'recognit'), ('machine', 'machin')]

>> Stemming using Snowball Stemmer: 
 [('last', 'last'), ('years', 'year'), ('pattern', 'pattern'), ('recognition', 'recognit'), ('machine', 'machin')]

>> Lemmatization: 
 [('last', 'last'), ('years', 'year'), ('pattern', 'pattern'), ('recognition', 'recognition'), ('machine', 'machine')]



========================================== PARAGRAPH 506 ===========================================

learning. Most of the popular Deep Learning Techniques are  

------------------- Sentence 1 -------------------

learning.

>> Tokens are: 
 ['learning', '.']

>> Bigrams are: 
 [('learning', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('learning', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['learning']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('learning', 'learn'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('learning', 'learn'), ('.', '.')]

>> Lemmatization: 
 [('learning', 'learning'), ('.', '.')]


------------------- Sentence 2 -------------------

Most of the popular Deep Learning Techniques are

>> Tokens are: 
 ['Most', 'popular', 'Deep', 'Learning', 'Techniques']

>> Bigrams are: 
 [('Most', 'popular'), ('popular', 'Deep'), ('Deep', 'Learning'), ('Learning', 'Techniques')]

>> Trigrams are: 
 [('Most', 'popular', 'Deep'), ('popular', 'Deep', 'Learning'), ('Deep', 'Learning', 'Techniques')]

>> POS Tags are: 
 [('Most', 'RBS'), ('popular', 'JJ'), ('Deep', 'NNP'), ('Learning', 'NNP'), ('Techniques', 'NNP')]

>> Noun Phrases are: 
 ['popular Deep Learning Techniques']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Most', 'most'), ('popular', 'popular'), ('Deep', 'deep'), ('Learning', 'learn'), ('Techniques', 'techniqu')]

>> Stemming using Snowball Stemmer: 
 [('Most', 'most'), ('popular', 'popular'), ('Deep', 'deep'), ('Learning', 'learn'), ('Techniques', 'techniqu')]

>> Lemmatization: 
 [('Most', 'Most'), ('popular', 'popular'), ('Deep', 'Deep'), ('Learning', 'Learning'), ('Techniques', 'Techniques')]



========================================== PARAGRAPH 507 ===========================================

built from Artificial Neural Network (ANN). Deep learning can  

------------------- Sentence 1 -------------------

built from Artificial Neural Network (ANN).

>> Tokens are: 
 ['built', 'Artificial', 'Neural', 'Network', '(', 'ANN', ')', '.']

>> Bigrams are: 
 [('built', 'Artificial'), ('Artificial', 'Neural'), ('Neural', 'Network'), ('Network', '('), ('(', 'ANN'), ('ANN', ')'), (')', '.')]

>> Trigrams are: 
 [('built', 'Artificial', 'Neural'), ('Artificial', 'Neural', 'Network'), ('Neural', 'Network', '('), ('Network', '(', 'ANN'), ('(', 'ANN', ')'), ('ANN', ')', '.')]

>> POS Tags are: 
 [('built', 'VBN'), ('Artificial', 'NNP'), ('Neural', 'NNP'), ('Network', 'NNP'), ('(', '('), ('ANN', 'NNP'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['Artificial Neural Network', 'ANN']

>> Named Entities are: 
 [('PERSON', 'Artificial Neural Network'), ('ORGANIZATION', 'ANN')] 

>> Stemming using Porter Stemmer: 
 [('built', 'built'), ('Artificial', 'artifici'), ('Neural', 'neural'), ('Network', 'network'), ('(', '('), ('ANN', 'ann'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('built', 'built'), ('Artificial', 'artifici'), ('Neural', 'neural'), ('Network', 'network'), ('(', '('), ('ANN', 'ann'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('built', 'built'), ('Artificial', 'Artificial'), ('Neural', 'Neural'), ('Network', 'Network'), ('(', '('), ('ANN', 'ANN'), (')', ')'), ('.', '.')]


------------------- Sentence 2 -------------------

Deep learning can

>> Tokens are: 
 ['Deep', 'learning']

>> Bigrams are: 
 [('Deep', 'learning')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Deep', 'NNP'), ('learning', 'NN')]

>> Noun Phrases are: 
 ['Deep learning']

>> Named Entities are: 
 [('GPE', 'Deep')] 

>> Stemming using Porter Stemmer: 
 [('Deep', 'deep'), ('learning', 'learn')]

>> Stemming using Snowball Stemmer: 
 [('Deep', 'deep'), ('learning', 'learn')]

>> Lemmatization: 
 [('Deep', 'Deep'), ('learning', 'learning')]



========================================== PARAGRAPH 508 ===========================================

be defined as a model (e.g.-, neural network) with many layers,  

------------------- Sentence 1 -------------------

be defined as a model (e.g.-, neural network) with many layers,

>> Tokens are: 
 ['defined', 'model', '(', 'e.g.-', ',', 'neural', 'network', ')', 'many', 'layers', ',']

>> Bigrams are: 
 [('defined', 'model'), ('model', '('), ('(', 'e.g.-'), ('e.g.-', ','), (',', 'neural'), ('neural', 'network'), ('network', ')'), (')', 'many'), ('many', 'layers'), ('layers', ',')]

>> Trigrams are: 
 [('defined', 'model', '('), ('model', '(', 'e.g.-'), ('(', 'e.g.-', ','), ('e.g.-', ',', 'neural'), (',', 'neural', 'network'), ('neural', 'network', ')'), ('network', ')', 'many'), (')', 'many', 'layers'), ('many', 'layers', ',')]

>> POS Tags are: 
 [('defined', 'VBN'), ('model', 'NN'), ('(', '('), ('e.g.-', 'JJ'), (',', ','), ('neural', 'JJ'), ('network', 'NN'), (')', ')'), ('many', 'JJ'), ('layers', 'NNS'), (',', ',')]

>> Noun Phrases are: 
 ['model', 'neural network', 'many layers']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('defined', 'defin'), ('model', 'model'), ('(', '('), ('e.g.-', 'e.g.-'), (',', ','), ('neural', 'neural'), ('network', 'network'), (')', ')'), ('many', 'mani'), ('layers', 'layer'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('defined', 'defin'), ('model', 'model'), ('(', '('), ('e.g.-', 'e.g.-'), (',', ','), ('neural', 'neural'), ('network', 'network'), (')', ')'), ('many', 'mani'), ('layers', 'layer'), (',', ',')]

>> Lemmatization: 
 [('defined', 'defined'), ('model', 'model'), ('(', '('), ('e.g.-', 'e.g.-'), (',', ','), ('neural', 'neural'), ('network', 'network'), (')', ')'), ('many', 'many'), ('layers', 'layer'), (',', ',')]



========================================== PARAGRAPH 509 ===========================================

trained in a layer- wise fashion. Deep learning has had a  

------------------- Sentence 1 -------------------

trained in a layer- wise fashion.

>> Tokens are: 
 ['trained', 'layer-', 'wise', 'fashion', '.']

>> Bigrams are: 
 [('trained', 'layer-'), ('layer-', 'wise'), ('wise', 'fashion'), ('fashion', '.')]

>> Trigrams are: 
 [('trained', 'layer-', 'wise'), ('layer-', 'wise', 'fashion'), ('wise', 'fashion', '.')]

>> POS Tags are: 
 [('trained', 'VBN'), ('layer-', 'JJ'), ('wise', 'NN'), ('fashion', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['layer- wise fashion']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('trained', 'train'), ('layer-', 'layer-'), ('wise', 'wise'), ('fashion', 'fashion'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('trained', 'train'), ('layer-', 'layer-'), ('wise', 'wise'), ('fashion', 'fashion'), ('.', '.')]

>> Lemmatization: 
 [('trained', 'trained'), ('layer-', 'layer-'), ('wise', 'wise'), ('fashion', 'fashion'), ('.', '.')]


------------------- Sentence 2 -------------------

Deep learning has had a

>> Tokens are: 
 ['Deep', 'learning']

>> Bigrams are: 
 [('Deep', 'learning')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Deep', 'NNP'), ('learning', 'NN')]

>> Noun Phrases are: 
 ['Deep learning']

>> Named Entities are: 
 [('GPE', 'Deep')] 

>> Stemming using Porter Stemmer: 
 [('Deep', 'deep'), ('learning', 'learn')]

>> Stemming using Snowball Stemmer: 
 [('Deep', 'deep'), ('learning', 'learn')]

>> Lemmatization: 
 [('Deep', 'Deep'), ('learning', 'learning')]



========================================== PARAGRAPH 510 ===========================================

tremendous impact on various applications such as computer  

------------------- Sentence 1 -------------------

tremendous impact on various applications such as computer

>> Tokens are: 
 ['tremendous', 'impact', 'various', 'applications', 'computer']

>> Bigrams are: 
 [('tremendous', 'impact'), ('impact', 'various'), ('various', 'applications'), ('applications', 'computer')]

>> Trigrams are: 
 [('tremendous', 'impact', 'various'), ('impact', 'various', 'applications'), ('various', 'applications', 'computer')]

>> POS Tags are: 
 [('tremendous', 'JJ'), ('impact', 'NN'), ('various', 'JJ'), ('applications', 'NNS'), ('computer', 'NN')]

>> Noun Phrases are: 
 ['tremendous impact', 'various applications computer']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('tremendous', 'tremend'), ('impact', 'impact'), ('various', 'variou'), ('applications', 'applic'), ('computer', 'comput')]

>> Stemming using Snowball Stemmer: 
 [('tremendous', 'tremend'), ('impact', 'impact'), ('various', 'various'), ('applications', 'applic'), ('computer', 'comput')]

>> Lemmatization: 
 [('tremendous', 'tremendous'), ('impact', 'impact'), ('various', 'various'), ('applications', 'application'), ('computer', 'computer')]



========================================== PARAGRAPH 511 ===========================================

vision, speech recognition, natural language processing [29], and  

------------------- Sentence 1 -------------------

vision, speech recognition, natural language processing [29], and

>> Tokens are: 
 ['vision', ',', 'speech', 'recognition', ',', 'natural', 'language', 'processing', '[', '29', ']', ',']

>> Bigrams are: 
 [('vision', ','), (',', 'speech'), ('speech', 'recognition'), ('recognition', ','), (',', 'natural'), ('natural', 'language'), ('language', 'processing'), ('processing', '['), ('[', '29'), ('29', ']'), (']', ',')]

>> Trigrams are: 
 [('vision', ',', 'speech'), (',', 'speech', 'recognition'), ('speech', 'recognition', ','), ('recognition', ',', 'natural'), (',', 'natural', 'language'), ('natural', 'language', 'processing'), ('language', 'processing', '['), ('processing', '[', '29'), ('[', '29', ']'), ('29', ']', ',')]

>> POS Tags are: 
 [('vision', 'NN'), (',', ','), ('speech', 'NN'), ('recognition', 'NN'), (',', ','), ('natural', 'JJ'), ('language', 'NN'), ('processing', 'NN'), ('[', '$'), ('29', 'CD'), (']', 'NN'), (',', ',')]

>> Noun Phrases are: 
 ['vision', 'speech recognition', 'natural language processing', ']']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('vision', 'vision'), (',', ','), ('speech', 'speech'), ('recognition', 'recognit'), (',', ','), ('natural', 'natur'), ('language', 'languag'), ('processing', 'process'), ('[', '['), ('29', '29'), (']', ']'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('vision', 'vision'), (',', ','), ('speech', 'speech'), ('recognition', 'recognit'), (',', ','), ('natural', 'natur'), ('language', 'languag'), ('processing', 'process'), ('[', '['), ('29', '29'), (']', ']'), (',', ',')]

>> Lemmatization: 
 [('vision', 'vision'), (',', ','), ('speech', 'speech'), ('recognition', 'recognition'), (',', ','), ('natural', 'natural'), ('language', 'language'), ('processing', 'processing'), ('[', '['), ('29', '29'), (']', ']'), (',', ',')]



========================================== PARAGRAPH 512 ===========================================

crawling deep web [30]. Samy et al. [29] have discussed  

------------------- Sentence 1 -------------------

crawling deep web [30].

>> Tokens are: 
 ['crawling', 'deep', 'web', '[', '30', ']', '.']

>> Bigrams are: 
 [('crawling', 'deep'), ('deep', 'web'), ('web', '['), ('[', '30'), ('30', ']'), (']', '.')]

>> Trigrams are: 
 [('crawling', 'deep', 'web'), ('deep', 'web', '['), ('web', '[', '30'), ('[', '30', ']'), ('30', ']', '.')]

>> POS Tags are: 
 [('crawling', 'VBG'), ('deep', 'JJ'), ('web', 'NN'), ('[', 'VBD'), ('30', 'CD'), (']', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['deep web', ']']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('crawling', 'crawl'), ('deep', 'deep'), ('web', 'web'), ('[', '['), ('30', '30'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('crawling', 'crawl'), ('deep', 'deep'), ('web', 'web'), ('[', '['), ('30', '30'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('crawling', 'crawling'), ('deep', 'deep'), ('web', 'web'), ('[', '['), ('30', '30'), (']', ']'), ('.', '.')]


------------------- Sentence 2 -------------------

Samy et al.

>> Tokens are: 
 ['Samy', 'et', 'al', '.']

>> Bigrams are: 
 [('Samy', 'et'), ('et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('Samy', 'et', 'al'), ('et', 'al', '.')]

>> POS Tags are: 
 [('Samy', 'NNP'), ('et', 'CC'), ('al', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Samy', 'al']

>> Named Entities are: 
 [('GPE', 'Samy')] 

>> Stemming using Porter Stemmer: 
 [('Samy', 'sami'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Samy', 'sami'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('Samy', 'Samy'), ('et', 'et'), ('al', 'al'), ('.', '.')]


------------------- Sentence 3 -------------------

[29] have discussed

>> Tokens are: 
 ['[', '29', ']', 'discussed']

>> Bigrams are: 
 [('[', '29'), ('29', ']'), (']', 'discussed')]

>> Trigrams are: 
 [('[', '29', ']'), ('29', ']', 'discussed')]

>> POS Tags are: 
 [('[', 'RB'), ('29', 'CD'), (']', 'NNS'), ('discussed', 'VBD')]

>> Noun Phrases are: 
 [']']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('29', '29'), (']', ']'), ('discussed', 'discuss')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('29', '29'), (']', ']'), ('discussed', 'discuss')]

>> Lemmatization: 
 [('[', '['), ('29', '29'), (']', ']'), ('discussed', 'discussed')]



========================================== PARAGRAPH 513 ===========================================

challenges and new applications of deep learning in their study.  

------------------- Sentence 1 -------------------

challenges and new applications of deep learning in their study.

>> Tokens are: 
 ['challenges', 'new', 'applications', 'deep', 'learning', 'study', '.']

>> Bigrams are: 
 [('challenges', 'new'), ('new', 'applications'), ('applications', 'deep'), ('deep', 'learning'), ('learning', 'study'), ('study', '.')]

>> Trigrams are: 
 [('challenges', 'new', 'applications'), ('new', 'applications', 'deep'), ('applications', 'deep', 'learning'), ('deep', 'learning', 'study'), ('learning', 'study', '.')]

>> POS Tags are: 
 [('challenges', 'NNS'), ('new', 'JJ'), ('applications', 'NNS'), ('deep', 'VBP'), ('learning', 'VBG'), ('study', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['challenges', 'new applications', 'study']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('challenges', 'challeng'), ('new', 'new'), ('applications', 'applic'), ('deep', 'deep'), ('learning', 'learn'), ('study', 'studi'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('challenges', 'challeng'), ('new', 'new'), ('applications', 'applic'), ('deep', 'deep'), ('learning', 'learn'), ('study', 'studi'), ('.', '.')]

>> Lemmatization: 
 [('challenges', 'challenge'), ('new', 'new'), ('applications', 'application'), ('deep', 'deep'), ('learning', 'learning'), ('study', 'study'), ('.', '.')]



========================================== PARAGRAPH 514 ===========================================

  


========================================== PARAGRAPH 515 ===========================================

Fig.11. Deep network Architecture  

------------------- Sentence 1 -------------------

Fig.11.

>> Tokens are: 
 ['Fig.11', '.']

>> Bigrams are: 
 [('Fig.11', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Fig.11', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Fig.11']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Fig.11', 'fig.11'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Fig.11', 'fig.11'), ('.', '.')]

>> Lemmatization: 
 [('Fig.11', 'Fig.11'), ('.', '.')]


------------------- Sentence 2 -------------------

Deep network Architecture

>> Tokens are: 
 ['Deep', 'network', 'Architecture']

>> Bigrams are: 
 [('Deep', 'network'), ('network', 'Architecture')]

>> Trigrams are: 
 [('Deep', 'network', 'Architecture')]

>> POS Tags are: 
 [('Deep', 'JJ'), ('network', 'NN'), ('Architecture', 'NN')]

>> Noun Phrases are: 
 ['Deep network Architecture']

>> Named Entities are: 
 [('GPE', 'Deep')] 

>> Stemming using Porter Stemmer: 
 [('Deep', 'deep'), ('network', 'network'), ('Architecture', 'architectur')]

>> Stemming using Snowball Stemmer: 
 [('Deep', 'deep'), ('network', 'network'), ('Architecture', 'architectur')]

>> Lemmatization: 
 [('Deep', 'Deep'), ('network', 'network'), ('Architecture', 'Architecture')]



========================================== PARAGRAPH 516 ===========================================

The Fig.11 depicts the deep learning network architecture  

------------------- Sentence 1 -------------------

The Fig.11 depicts the deep learning network architecture

>> Tokens are: 
 ['The', 'Fig.11', 'depicts', 'deep', 'learning', 'network', 'architecture']

>> Bigrams are: 
 [('The', 'Fig.11'), ('Fig.11', 'depicts'), ('depicts', 'deep'), ('deep', 'learning'), ('learning', 'network'), ('network', 'architecture')]

>> Trigrams are: 
 [('The', 'Fig.11', 'depicts'), ('Fig.11', 'depicts', 'deep'), ('depicts', 'deep', 'learning'), ('deep', 'learning', 'network'), ('learning', 'network', 'architecture')]

>> POS Tags are: 
 [('The', 'DT'), ('Fig.11', 'NNP'), ('depicts', 'VBZ'), ('deep', 'JJ'), ('learning', 'NN'), ('network', 'NN'), ('architecture', 'NN')]

>> Noun Phrases are: 
 ['The Fig.11', 'deep learning network architecture']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('Fig.11', 'fig.11'), ('depicts', 'depict'), ('deep', 'deep'), ('learning', 'learn'), ('network', 'network'), ('architecture', 'architectur')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('Fig.11', 'fig.11'), ('depicts', 'depict'), ('deep', 'deep'), ('learning', 'learn'), ('network', 'network'), ('architecture', 'architectur')]

>> Lemmatization: 
 [('The', 'The'), ('Fig.11', 'Fig.11'), ('depicts', 'depicts'), ('deep', 'deep'), ('learning', 'learning'), ('network', 'network'), ('architecture', 'architecture')]



========================================== PARAGRAPH 517 ===========================================

with one 3-unit input layer, one 2-unit output layer, and two 5- 

------------------- Sentence 1 -------------------

with one 3-unit input layer, one 2-unit output layer, and two 5-

>> Tokens are: 
 ['one', '3-unit', 'input', 'layer', ',', 'one', '2-unit', 'output', 'layer', ',', 'two', '5-']

>> Bigrams are: 
 [('one', '3-unit'), ('3-unit', 'input'), ('input', 'layer'), ('layer', ','), (',', 'one'), ('one', '2-unit'), ('2-unit', 'output'), ('output', 'layer'), ('layer', ','), (',', 'two'), ('two', '5-')]

>> Trigrams are: 
 [('one', '3-unit', 'input'), ('3-unit', 'input', 'layer'), ('input', 'layer', ','), ('layer', ',', 'one'), (',', 'one', '2-unit'), ('one', '2-unit', 'output'), ('2-unit', 'output', 'layer'), ('output', 'layer', ','), ('layer', ',', 'two'), (',', 'two', '5-')]

>> POS Tags are: 
 [('one', 'CD'), ('3-unit', 'JJ'), ('input', 'NN'), ('layer', 'NN'), (',', ','), ('one', 'CD'), ('2-unit', 'JJ'), ('output', 'NN'), ('layer', 'NN'), (',', ','), ('two', 'CD'), ('5-', 'JJ')]

>> Noun Phrases are: 
 ['3-unit input layer', '2-unit output layer']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('one', 'one'), ('3-unit', '3-unit'), ('input', 'input'), ('layer', 'layer'), (',', ','), ('one', 'one'), ('2-unit', '2-unit'), ('output', 'output'), ('layer', 'layer'), (',', ','), ('two', 'two'), ('5-', '5-')]

>> Stemming using Snowball Stemmer: 
 [('one', 'one'), ('3-unit', '3-unit'), ('input', 'input'), ('layer', 'layer'), (',', ','), ('one', 'one'), ('2-unit', '2-unit'), ('output', 'output'), ('layer', 'layer'), (',', ','), ('two', 'two'), ('5-', '5-')]

>> Lemmatization: 
 [('one', 'one'), ('3-unit', '3-unit'), ('input', 'input'), ('layer', 'layer'), (',', ','), ('one', 'one'), ('2-unit', '2-unit'), ('output', 'output'), ('layer', 'layer'), (',', ','), ('two', 'two'), ('5-', '5-')]



========================================== PARAGRAPH 518 ===========================================

unit hidden layers.    

------------------- Sentence 1 -------------------

unit hidden layers.

>> Tokens are: 
 ['unit', 'hidden', 'layers', '.']

>> Bigrams are: 
 [('unit', 'hidden'), ('hidden', 'layers'), ('layers', '.')]

>> Trigrams are: 
 [('unit', 'hidden', 'layers'), ('hidden', 'layers', '.')]

>> POS Tags are: 
 [('unit', 'NN'), ('hidden', 'JJ'), ('layers', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['unit', 'hidden layers']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('unit', 'unit'), ('hidden', 'hidden'), ('layers', 'layer'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('unit', 'unit'), ('hidden', 'hidden'), ('layers', 'layer'), ('.', '.')]

>> Lemmatization: 
 [('unit', 'unit'), ('hidden', 'hidden'), ('layers', 'layer'), ('.', '.')]



========================================== PARAGRAPH 519 ===========================================

Deep learning has also been successfully implemented in  

------------------- Sentence 1 -------------------

Deep learning has also been successfully implemented in

>> Tokens are: 
 ['Deep', 'learning', 'also', 'successfully', 'implemented']

>> Bigrams are: 
 [('Deep', 'learning'), ('learning', 'also'), ('also', 'successfully'), ('successfully', 'implemented')]

>> Trigrams are: 
 [('Deep', 'learning', 'also'), ('learning', 'also', 'successfully'), ('also', 'successfully', 'implemented')]

>> POS Tags are: 
 [('Deep', 'NNP'), ('learning', 'NN'), ('also', 'RB'), ('successfully', 'RB'), ('implemented', 'VBN')]

>> Noun Phrases are: 
 ['Deep learning']

>> Named Entities are: 
 [('GPE', 'Deep')] 

>> Stemming using Porter Stemmer: 
 [('Deep', 'deep'), ('learning', 'learn'), ('also', 'also'), ('successfully', 'success'), ('implemented', 'implement')]

>> Stemming using Snowball Stemmer: 
 [('Deep', 'deep'), ('learning', 'learn'), ('also', 'also'), ('successfully', 'success'), ('implemented', 'implement')]

>> Lemmatization: 
 [('Deep', 'Deep'), ('learning', 'learning'), ('also', 'also'), ('successfully', 'successfully'), ('implemented', 'implemented')]



========================================== PARAGRAPH 520 ===========================================

industry products that ultimately take advantage of the large  

------------------- Sentence 1 -------------------

industry products that ultimately take advantage of the large

>> Tokens are: 
 ['industry', 'products', 'ultimately', 'take', 'advantage', 'large']

>> Bigrams are: 
 [('industry', 'products'), ('products', 'ultimately'), ('ultimately', 'take'), ('take', 'advantage'), ('advantage', 'large')]

>> Trigrams are: 
 [('industry', 'products', 'ultimately'), ('products', 'ultimately', 'take'), ('ultimately', 'take', 'advantage'), ('take', 'advantage', 'large')]

>> POS Tags are: 
 [('industry', 'NN'), ('products', 'NNS'), ('ultimately', 'RB'), ('take', 'VBP'), ('advantage', 'NN'), ('large', 'JJ')]

>> Noun Phrases are: 
 ['industry products', 'advantage']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('industry', 'industri'), ('products', 'product'), ('ultimately', 'ultim'), ('take', 'take'), ('advantage', 'advantag'), ('large', 'larg')]

>> Stemming using Snowball Stemmer: 
 [('industry', 'industri'), ('products', 'product'), ('ultimately', 'ultim'), ('take', 'take'), ('advantage', 'advantag'), ('large', 'larg')]

>> Lemmatization: 
 [('industry', 'industry'), ('products', 'product'), ('ultimately', 'ultimately'), ('take', 'take'), ('advantage', 'advantage'), ('large', 'large')]



========================================== PARAGRAPH 521 ===========================================

volume of data. Top Information Technology (IT) companies  

------------------- Sentence 1 -------------------

volume of data.

>> Tokens are: 
 ['volume', 'data', '.']

>> Bigrams are: 
 [('volume', 'data'), ('data', '.')]

>> Trigrams are: 
 [('volume', 'data', '.')]

>> POS Tags are: 
 [('volume', 'NN'), ('data', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['volume data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('volume', 'volum'), ('data', 'data'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('volume', 'volum'), ('data', 'data'), ('.', '.')]

>> Lemmatization: 
 [('volume', 'volume'), ('data', 'data'), ('.', '.')]


------------------- Sentence 2 -------------------

Top Information Technology (IT) companies

>> Tokens are: 
 ['Top', 'Information', 'Technology', '(', 'IT', ')', 'companies']

>> Bigrams are: 
 [('Top', 'Information'), ('Information', 'Technology'), ('Technology', '('), ('(', 'IT'), ('IT', ')'), (')', 'companies')]

>> Trigrams are: 
 [('Top', 'Information', 'Technology'), ('Information', 'Technology', '('), ('Technology', '(', 'IT'), ('(', 'IT', ')'), ('IT', ')', 'companies')]

>> POS Tags are: 
 [('Top', 'JJ'), ('Information', 'NNP'), ('Technology', 'NNP'), ('(', '('), ('IT', 'NNP'), (')', ')'), ('companies', 'NNS')]

>> Noun Phrases are: 
 ['Top Information Technology', 'IT', 'companies']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Top', 'top'), ('Information', 'inform'), ('Technology', 'technolog'), ('(', '('), ('IT', 'it'), (')', ')'), ('companies', 'compani')]

>> Stemming using Snowball Stemmer: 
 [('Top', 'top'), ('Information', 'inform'), ('Technology', 'technolog'), ('(', '('), ('IT', 'it'), (')', ')'), ('companies', 'compani')]

>> Lemmatization: 
 [('Top', 'Top'), ('Information', 'Information'), ('Technology', 'Technology'), ('(', '('), ('IT', 'IT'), (')', ')'), ('companies', 'company')]



========================================== PARAGRAPH 522 ===========================================

like Microsoft, Google, Apple, Yahoo, Baidu, Amazon and  

------------------- Sentence 1 -------------------

like Microsoft, Google, Apple, Yahoo, Baidu, Amazon and

>> Tokens are: 
 ['like', 'Microsoft', ',', 'Google', ',', 'Apple', ',', 'Yahoo', ',', 'Baidu', ',', 'Amazon']

>> Bigrams are: 
 [('like', 'Microsoft'), ('Microsoft', ','), (',', 'Google'), ('Google', ','), (',', 'Apple'), ('Apple', ','), (',', 'Yahoo'), ('Yahoo', ','), (',', 'Baidu'), ('Baidu', ','), (',', 'Amazon')]

>> Trigrams are: 
 [('like', 'Microsoft', ','), ('Microsoft', ',', 'Google'), (',', 'Google', ','), ('Google', ',', 'Apple'), (',', 'Apple', ','), ('Apple', ',', 'Yahoo'), (',', 'Yahoo', ','), ('Yahoo', ',', 'Baidu'), (',', 'Baidu', ','), ('Baidu', ',', 'Amazon')]

>> POS Tags are: 
 [('like', 'IN'), ('Microsoft', 'NNP'), (',', ','), ('Google', 'NNP'), (',', ','), ('Apple', 'NNP'), (',', ','), ('Yahoo', 'NNP'), (',', ','), ('Baidu', 'NNP'), (',', ','), ('Amazon', 'NNP')]

>> Noun Phrases are: 
 ['Microsoft', 'Google', 'Apple', 'Yahoo', 'Baidu', 'Amazon']

>> Named Entities are: 
 [('ORGANIZATION', 'Microsoft'), ('GPE', 'Google'), ('PERSON', 'Apple'), ('PERSON', 'Yahoo'), ('PERSON', 'Baidu'), ('PERSON', 'Amazon')] 

>> Stemming using Porter Stemmer: 
 [('like', 'like'), ('Microsoft', 'microsoft'), (',', ','), ('Google', 'googl'), (',', ','), ('Apple', 'appl'), (',', ','), ('Yahoo', 'yahoo'), (',', ','), ('Baidu', 'baidu'), (',', ','), ('Amazon', 'amazon')]

>> Stemming using Snowball Stemmer: 
 [('like', 'like'), ('Microsoft', 'microsoft'), (',', ','), ('Google', 'googl'), (',', ','), ('Apple', 'appl'), (',', ','), ('Yahoo', 'yahoo'), (',', ','), ('Baidu', 'baidu'), (',', ','), ('Amazon', 'amazon')]

>> Lemmatization: 
 [('like', 'like'), ('Microsoft', 'Microsoft'), (',', ','), ('Google', 'Google'), (',', ','), ('Apple', 'Apple'), (',', ','), ('Yahoo', 'Yahoo'), (',', ','), ('Baidu', 'Baidu'), (',', ','), ('Amazon', 'Amazon')]



========================================== PARAGRAPH 523 ===========================================

Facebook, who collect and analyze massive amounts of data on a  

------------------- Sentence 1 -------------------

Facebook, who collect and analyze massive amounts of data on a

>> Tokens are: 
 ['Facebook', ',', 'collect', 'analyze', 'massive', 'amounts', 'data']

>> Bigrams are: 
 [('Facebook', ','), (',', 'collect'), ('collect', 'analyze'), ('analyze', 'massive'), ('massive', 'amounts'), ('amounts', 'data')]

>> Trigrams are: 
 [('Facebook', ',', 'collect'), (',', 'collect', 'analyze'), ('collect', 'analyze', 'massive'), ('analyze', 'massive', 'amounts'), ('massive', 'amounts', 'data')]

>> POS Tags are: 
 [('Facebook', 'NNP'), (',', ','), ('collect', 'VBP'), ('analyze', 'JJ'), ('massive', 'JJ'), ('amounts', 'NNS'), ('data', 'NNS')]

>> Noun Phrases are: 
 ['Facebook', 'analyze massive amounts data']

>> Named Entities are: 
 [('GPE', 'Facebook')] 

>> Stemming using Porter Stemmer: 
 [('Facebook', 'facebook'), (',', ','), ('collect', 'collect'), ('analyze', 'analyz'), ('massive', 'massiv'), ('amounts', 'amount'), ('data', 'data')]

>> Stemming using Snowball Stemmer: 
 [('Facebook', 'facebook'), (',', ','), ('collect', 'collect'), ('analyze', 'analyz'), ('massive', 'massiv'), ('amounts', 'amount'), ('data', 'data')]

>> Lemmatization: 
 [('Facebook', 'Facebook'), (',', ','), ('collect', 'collect'), ('analyze', 'analyze'), ('massive', 'massive'), ('amounts', 'amount'), ('data', 'data')]



========================================== PARAGRAPH 524 ===========================================

daily basis, have been investing a good share on finances on  

------------------- Sentence 1 -------------------

daily basis, have been investing a good share on finances on

>> Tokens are: 
 ['daily', 'basis', ',', 'investing', 'good', 'share', 'finances']

>> Bigrams are: 
 [('daily', 'basis'), ('basis', ','), (',', 'investing'), ('investing', 'good'), ('good', 'share'), ('share', 'finances')]

>> Trigrams are: 
 [('daily', 'basis', ','), ('basis', ',', 'investing'), (',', 'investing', 'good'), ('investing', 'good', 'share'), ('good', 'share', 'finances')]

>> POS Tags are: 
 [('daily', 'JJ'), ('basis', 'NN'), (',', ','), ('investing', 'VBG'), ('good', 'JJ'), ('share', 'NN'), ('finances', 'NNS')]

>> Noun Phrases are: 
 ['daily basis', 'good share finances']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('daily', 'daili'), ('basis', 'basi'), (',', ','), ('investing', 'invest'), ('good', 'good'), ('share', 'share'), ('finances', 'financ')]

>> Stemming using Snowball Stemmer: 
 [('daily', 'daili'), ('basis', 'basi'), (',', ','), ('investing', 'invest'), ('good', 'good'), ('share', 'share'), ('finances', 'financ')]

>> Lemmatization: 
 [('daily', 'daily'), ('basis', 'basis'), (',', ','), ('investing', 'investing'), ('good', 'good'), ('share', 'share'), ('finances', 'finance')]



========================================== PARAGRAPH 525 ===========================================

deep learning related projects. For example, Apple's Siri and  

------------------- Sentence 1 -------------------

deep learning related projects.

>> Tokens are: 
 ['deep', 'learning', 'related', 'projects', '.']

>> Bigrams are: 
 [('deep', 'learning'), ('learning', 'related'), ('related', 'projects'), ('projects', '.')]

>> Trigrams are: 
 [('deep', 'learning', 'related'), ('learning', 'related', 'projects'), ('related', 'projects', '.')]

>> POS Tags are: 
 [('deep', 'JJ'), ('learning', 'NN'), ('related', 'JJ'), ('projects', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['deep learning', 'related projects']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('deep', 'deep'), ('learning', 'learn'), ('related', 'relat'), ('projects', 'project'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('deep', 'deep'), ('learning', 'learn'), ('related', 'relat'), ('projects', 'project'), ('.', '.')]

>> Lemmatization: 
 [('deep', 'deep'), ('learning', 'learning'), ('related', 'related'), ('projects', 'project'), ('.', '.')]


------------------- Sentence 2 -------------------

For example, Apple's Siri and

>> Tokens are: 
 ['For', 'example', ',', 'Apple', "'s", 'Siri']

>> Bigrams are: 
 [('For', 'example'), ('example', ','), (',', 'Apple'), ('Apple', "'s"), ("'s", 'Siri')]

>> Trigrams are: 
 [('For', 'example', ','), ('example', ',', 'Apple'), (',', 'Apple', "'s"), ('Apple', "'s", 'Siri')]

>> POS Tags are: 
 [('For', 'IN'), ('example', 'NN'), (',', ','), ('Apple', 'NNP'), ("'s", 'POS'), ('Siri', 'NNP')]

>> Noun Phrases are: 
 ['example', 'Apple', 'Siri']

>> Named Entities are: 
 [('PERSON', 'Apple')] 

>> Stemming using Porter Stemmer: 
 [('For', 'for'), ('example', 'exampl'), (',', ','), ('Apple', 'appl'), ("'s", "'s"), ('Siri', 'siri')]

>> Stemming using Snowball Stemmer: 
 [('For', 'for'), ('example', 'exampl'), (',', ','), ('Apple', 'appl'), ("'s", "'s"), ('Siri', 'siri')]

>> Lemmatization: 
 [('For', 'For'), ('example', 'example'), (',', ','), ('Apple', 'Apple'), ("'s", "'s"), ('Siri', 'Siri')]



========================================== PARAGRAPH 526 ===========================================

Google Voice Search offer a wide variety of services including  

------------------- Sentence 1 -------------------

Google Voice Search offer a wide variety of services including

>> Tokens are: 
 ['Google', 'Voice', 'Search', 'offer', 'wide', 'variety', 'services', 'including']

>> Bigrams are: 
 [('Google', 'Voice'), ('Voice', 'Search'), ('Search', 'offer'), ('offer', 'wide'), ('wide', 'variety'), ('variety', 'services'), ('services', 'including')]

>> Trigrams are: 
 [('Google', 'Voice', 'Search'), ('Voice', 'Search', 'offer'), ('Search', 'offer', 'wide'), ('offer', 'wide', 'variety'), ('wide', 'variety', 'services'), ('variety', 'services', 'including')]

>> POS Tags are: 
 [('Google', 'NNP'), ('Voice', 'NNP'), ('Search', 'NNP'), ('offer', 'NN'), ('wide', 'JJ'), ('variety', 'NN'), ('services', 'NNS'), ('including', 'VBG')]

>> Noun Phrases are: 
 ['Google Voice Search offer', 'wide variety services']

>> Named Entities are: 
 [('PERSON', 'Google')] 

>> Stemming using Porter Stemmer: 
 [('Google', 'googl'), ('Voice', 'voic'), ('Search', 'search'), ('offer', 'offer'), ('wide', 'wide'), ('variety', 'varieti'), ('services', 'servic'), ('including', 'includ')]

>> Stemming using Snowball Stemmer: 
 [('Google', 'googl'), ('Voice', 'voic'), ('Search', 'search'), ('offer', 'offer'), ('wide', 'wide'), ('variety', 'varieti'), ('services', 'servic'), ('including', 'includ')]

>> Lemmatization: 
 [('Google', 'Google'), ('Voice', 'Voice'), ('Search', 'Search'), ('offer', 'offer'), ('wide', 'wide'), ('variety', 'variety'), ('services', 'service'), ('including', 'including')]



========================================== PARAGRAPH 527 ===========================================

weather reports, sport news, answers to users questions, and  

------------------- Sentence 1 -------------------

weather reports, sport news, answers to users questions, and

>> Tokens are: 
 ['weather', 'reports', ',', 'sport', 'news', ',', 'answers', 'user', '', 'questions', ',']

>> Bigrams are: 
 [('weather', 'reports'), ('reports', ','), (',', 'sport'), ('sport', 'news'), ('news', ','), (',', 'answers'), ('answers', 'user'), ('user', ''), ('', 'questions'), ('questions', ',')]

>> Trigrams are: 
 [('weather', 'reports', ','), ('reports', ',', 'sport'), (',', 'sport', 'news'), ('sport', 'news', ','), ('news', ',', 'answers'), (',', 'answers', 'user'), ('answers', 'user', ''), ('user', '', 'questions'), ('', 'questions', ',')]

>> POS Tags are: 
 [('weather', 'NN'), ('reports', 'NNS'), (',', ','), ('sport', 'NN'), ('news', 'NN'), (',', ','), ('answers', 'NNS'), ('user', 'VBP'), ('', 'JJ'), ('questions', 'NNS'), (',', ',')]

>> Noun Phrases are: 
 ['weather reports', 'sport news', 'answers', ' questions']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('weather', 'weather'), ('reports', 'report'), (',', ','), ('sport', 'sport'), ('news', 'news'), (',', ','), ('answers', 'answer'), ('user', 'user'), ('', ''), ('questions', 'question'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('weather', 'weather'), ('reports', 'report'), (',', ','), ('sport', 'sport'), ('news', 'news'), (',', ','), ('answers', 'answer'), ('user', 'user'), ('', ''), ('questions', 'question'), (',', ',')]

>> Lemmatization: 
 [('weather', 'weather'), ('reports', 'report'), (',', ','), ('sport', 'sport'), ('news', 'news'), (',', ','), ('answers', 'answer'), ('user', 'user'), ('', ''), ('questions', 'question'), (',', ',')]



========================================== PARAGRAPH 528 ===========================================

reminders etc., by utilizing deep learning algorithms [31].  

------------------- Sentence 1 -------------------

reminders etc., by utilizing deep learning algorithms [31].

>> Tokens are: 
 ['reminders', 'etc.', ',', 'utilizing', 'deep', 'learning', 'algorithms', '[', '31', ']', '.']

>> Bigrams are: 
 [('reminders', 'etc.'), ('etc.', ','), (',', 'utilizing'), ('utilizing', 'deep'), ('deep', 'learning'), ('learning', 'algorithms'), ('algorithms', '['), ('[', '31'), ('31', ']'), (']', '.')]

>> Trigrams are: 
 [('reminders', 'etc.', ','), ('etc.', ',', 'utilizing'), (',', 'utilizing', 'deep'), ('utilizing', 'deep', 'learning'), ('deep', 'learning', 'algorithms'), ('learning', 'algorithms', '['), ('algorithms', '[', '31'), ('[', '31', ']'), ('31', ']', '.')]

>> POS Tags are: 
 [('reminders', 'NNS'), ('etc.', 'VBP'), (',', ','), ('utilizing', 'JJ'), ('deep', 'JJ'), ('learning', 'NN'), ('algorithms', 'JJ'), ('[', '$'), ('31', 'CD'), (']', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['reminders', 'utilizing deep learning', ']']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('reminders', 'remind'), ('etc.', 'etc.'), (',', ','), ('utilizing', 'util'), ('deep', 'deep'), ('learning', 'learn'), ('algorithms', 'algorithm'), ('[', '['), ('31', '31'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('reminders', 'remind'), ('etc.', 'etc.'), (',', ','), ('utilizing', 'util'), ('deep', 'deep'), ('learning', 'learn'), ('algorithms', 'algorithm'), ('[', '['), ('31', '31'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('reminders', 'reminder'), ('etc.', 'etc.'), (',', ','), ('utilizing', 'utilizing'), ('deep', 'deep'), ('learning', 'learning'), ('algorithms', 'algorithm'), ('[', '['), ('31', '31'), (']', ']'), ('.', '.')]



========================================== PARAGRAPH 529 ===========================================

Currently, these two applications support wide range spoken  

------------------- Sentence 1 -------------------

Currently, these two applications support wide range spoken

>> Tokens are: 
 ['Currently', ',', 'two', 'applications', 'support', 'wide', 'range', 'spoken']

>> Bigrams are: 
 [('Currently', ','), (',', 'two'), ('two', 'applications'), ('applications', 'support'), ('support', 'wide'), ('wide', 'range'), ('range', 'spoken')]

>> Trigrams are: 
 [('Currently', ',', 'two'), (',', 'two', 'applications'), ('two', 'applications', 'support'), ('applications', 'support', 'wide'), ('support', 'wide', 'range'), ('wide', 'range', 'spoken')]

>> POS Tags are: 
 [('Currently', 'RB'), (',', ','), ('two', 'CD'), ('applications', 'NNS'), ('support', 'NN'), ('wide', 'JJ'), ('range', 'NN'), ('spoken', 'NN')]

>> Noun Phrases are: 
 ['applications support', 'wide range spoken']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Currently', 'current'), (',', ','), ('two', 'two'), ('applications', 'applic'), ('support', 'support'), ('wide', 'wide'), ('range', 'rang'), ('spoken', 'spoken')]

>> Stemming using Snowball Stemmer: 
 [('Currently', 'current'), (',', ','), ('two', 'two'), ('applications', 'applic'), ('support', 'support'), ('wide', 'wide'), ('range', 'rang'), ('spoken', 'spoken')]

>> Lemmatization: 
 [('Currently', 'Currently'), (',', ','), ('two', 'two'), ('applications', 'application'), ('support', 'support'), ('wide', 'wide'), ('range', 'range'), ('spoken', 'spoken')]



========================================== PARAGRAPH 530 ===========================================

languages.  

------------------- Sentence 1 -------------------

languages.

>> Tokens are: 
 ['languages', '.']

>> Bigrams are: 
 [('languages', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('languages', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['languages']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('languages', 'languag'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('languages', 'languag'), ('.', '.')]

>> Lemmatization: 
 [('languages', 'language'), ('.', '.')]



========================================== PARAGRAPH 531 ===========================================

Table.4. Large scale deep learning research progress  

------------------- Sentence 1 -------------------

Table.4.

>> Tokens are: 
 ['Table.4', '.']

>> Bigrams are: 
 [('Table.4', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Table.4', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Table.4']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Table.4', 'table.4'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Table.4', 'table.4'), ('.', '.')]

>> Lemmatization: 
 [('Table.4', 'Table.4'), ('.', '.')]


------------------- Sentence 2 -------------------

Large scale deep learning research progress

>> Tokens are: 
 ['Large', 'scale', 'deep', 'learning', 'research', 'progress']

>> Bigrams are: 
 [('Large', 'scale'), ('scale', 'deep'), ('deep', 'learning'), ('learning', 'research'), ('research', 'progress')]

>> Trigrams are: 
 [('Large', 'scale', 'deep'), ('scale', 'deep', 'learning'), ('deep', 'learning', 'research'), ('learning', 'research', 'progress')]

>> POS Tags are: 
 [('Large', 'JJ'), ('scale', 'NN'), ('deep', 'JJ'), ('learning', 'NN'), ('research', 'NN'), ('progress', 'NN')]

>> Noun Phrases are: 
 ['Large scale', 'deep learning research progress']

>> Named Entities are: 
 [('GPE', 'Large')] 

>> Stemming using Porter Stemmer: 
 [('Large', 'larg'), ('scale', 'scale'), ('deep', 'deep'), ('learning', 'learn'), ('research', 'research'), ('progress', 'progress')]

>> Stemming using Snowball Stemmer: 
 [('Large', 'larg'), ('scale', 'scale'), ('deep', 'deep'), ('learning', 'learn'), ('research', 'research'), ('progress', 'progress')]

>> Lemmatization: 
 [('Large', 'Large'), ('scale', 'scale'), ('deep', 'deep'), ('learning', 'learning'), ('research', 'research'), ('progress', 'progress')]



========================================== PARAGRAPH 532 ===========================================

Method Computing power  # of examples and  

------------------- Sentence 1 -------------------

Method Computing power  # of examples and

>> Tokens are: 
 ['Method', 'Computing', 'power', '#', 'examples']

>> Bigrams are: 
 [('Method', 'Computing'), ('Computing', 'power'), ('power', '#'), ('#', 'examples')]

>> Trigrams are: 
 [('Method', 'Computing', 'power'), ('Computing', 'power', '#'), ('power', '#', 'examples')]

>> POS Tags are: 
 [('Method', 'NNP'), ('Computing', 'NNP'), ('power', 'NN'), ('#', '#'), ('examples', 'NNS')]

>> Noun Phrases are: 
 ['Method Computing power', 'examples']

>> Named Entities are: 
 [('PERSON', 'Method')] 

>> Stemming using Porter Stemmer: 
 [('Method', 'method'), ('Computing', 'comput'), ('power', 'power'), ('#', '#'), ('examples', 'exampl')]

>> Stemming using Snowball Stemmer: 
 [('Method', 'method'), ('Computing', 'comput'), ('power', 'power'), ('#', '#'), ('examples', 'exampl')]

>> Lemmatization: 
 [('Method', 'Method'), ('Computing', 'Computing'), ('power', 'power'), ('#', '#'), ('examples', 'example')]



========================================== PARAGRAPH 533 ===========================================

parameters  

------------------- Sentence 1 -------------------

parameters

>> Tokens are: 
 ['parameters']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('parameters', 'NNS')]

>> Noun Phrases are: 
 ['parameters']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('parameters', 'paramet')]

>> Stemming using Snowball Stemmer: 
 [('parameters', 'paramet')]

>> Lemmatization: 
 [('parameters', 'parameter')]



========================================== PARAGRAPH 534 ===========================================

Average  

------------------- Sentence 1 -------------------

Average

>> Tokens are: 
 ['Average']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Average', 'JJ')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Average', 'averag')]

>> Stemming using Snowball Stemmer: 
 [('Average', 'averag')]

>> Lemmatization: 
 [('Average', 'Average')]



========================================== PARAGRAPH 535 ===========================================

running  

------------------- Sentence 1 -------------------

running

>> Tokens are: 
 ['running']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('running', 'VBG')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('running', 'run')]

>> Stemming using Snowball Stemmer: 
 [('running', 'run')]

>> Lemmatization: 
 [('running', 'running')]



========================================== PARAGRAPH 536 ===========================================

Time  

------------------- Sentence 1 -------------------

Time

>> Tokens are: 
 ['Time']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Time', 'NN')]

>> Noun Phrases are: 
 ['Time']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Time', 'time')]

>> Stemming using Snowball Stemmer: 
 [('Time', 'time')]

>> Lemmatization: 
 [('Time', 'Time')]



========================================== PARAGRAPH 537 ===========================================

DBN [32]  NVIDIA GTX 280  

------------------- Sentence 1 -------------------

DBN [32]  NVIDIA GTX 280

>> Tokens are: 
 ['DBN', '[', '32', ']', 'NVIDIA', 'GTX', '280']

>> Bigrams are: 
 [('DBN', '['), ('[', '32'), ('32', ']'), (']', 'NVIDIA'), ('NVIDIA', 'GTX'), ('GTX', '280')]

>> Trigrams are: 
 [('DBN', '[', '32'), ('[', '32', ']'), ('32', ']', 'NVIDIA'), (']', 'NVIDIA', 'GTX'), ('NVIDIA', 'GTX', '280')]

>> POS Tags are: 
 [('DBN', 'NNP'), ('[', 'VBD'), ('32', 'CD'), (']', 'JJ'), ('NVIDIA', 'NNP'), ('GTX', 'NNP'), ('280', 'CD')]

>> Noun Phrases are: 
 ['DBN', '] NVIDIA GTX']

>> Named Entities are: 
 [('ORGANIZATION', 'DBN'), ('ORGANIZATION', 'NVIDIA')] 

>> Stemming using Porter Stemmer: 
 [('DBN', 'dbn'), ('[', '['), ('32', '32'), (']', ']'), ('NVIDIA', 'nvidia'), ('GTX', 'gtx'), ('280', '280')]

>> Stemming using Snowball Stemmer: 
 [('DBN', 'dbn'), ('[', '['), ('32', '32'), (']', ']'), ('NVIDIA', 'nvidia'), ('GTX', 'gtx'), ('280', '280')]

>> Lemmatization: 
 [('DBN', 'DBN'), ('[', '['), ('32', '32'), (']', ']'), ('NVIDIA', 'NVIDIA'), ('GTX', 'GTX'), ('280', '280')]



========================================== PARAGRAPH 538 ===========================================

GPU (1 GB RAM)  

------------------- Sentence 1 -------------------

GPU (1 GB RAM)

>> Tokens are: 
 ['GPU', '(', '1', 'GB', 'RAM', ')']

>> Bigrams are: 
 [('GPU', '('), ('(', '1'), ('1', 'GB'), ('GB', 'RAM'), ('RAM', ')')]

>> Trigrams are: 
 [('GPU', '(', '1'), ('(', '1', 'GB'), ('1', 'GB', 'RAM'), ('GB', 'RAM', ')')]

>> POS Tags are: 
 [('GPU', 'NNP'), ('(', '('), ('1', 'CD'), ('GB', 'NNP'), ('RAM', 'NNP'), (')', ')')]

>> Noun Phrases are: 
 ['GPU', 'GB RAM']

>> Named Entities are: 
 [('GPE', 'GPU')] 

>> Stemming using Porter Stemmer: 
 [('GPU', 'gpu'), ('(', '('), ('1', '1'), ('GB', 'gb'), ('RAM', 'ram'), (')', ')')]

>> Stemming using Snowball Stemmer: 
 [('GPU', 'gpu'), ('(', '('), ('1', '1'), ('GB', 'gb'), ('RAM', 'ram'), (')', ')')]

>> Lemmatization: 
 [('GPU', 'GPU'), ('(', '('), ('1', '1'), ('GB', 'GB'), ('RAM', 'RAM'), (')', ')')]



========================================== PARAGRAPH 539 ===========================================

1million images and  

------------------- Sentence 1 -------------------

1million images and

>> Tokens are: 
 ['1million', 'images']

>> Bigrams are: 
 [('1million', 'images')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('1million', 'CD'), ('images', 'NNS')]

>> Noun Phrases are: 
 ['images']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('1million', '1million'), ('images', 'imag')]

>> Stemming using Snowball Stemmer: 
 [('1million', '1million'), ('images', 'imag')]

>> Lemmatization: 
 [('1million', '1million'), ('images', 'image')]



========================================== PARAGRAPH 540 ===========================================

1006 parameters  ~ 1 day  

------------------- Sentence 1 -------------------

1006 parameters  ~ 1 day

>> Tokens are: 
 ['1006', 'parameters', '~', '1', 'day']

>> Bigrams are: 
 [('1006', 'parameters'), ('parameters', '~'), ('~', '1'), ('1', 'day')]

>> Trigrams are: 
 [('1006', 'parameters', '~'), ('parameters', '~', '1'), ('~', '1', 'day')]

>> POS Tags are: 
 [('1006', 'CD'), ('parameters', 'NNS'), ('~', 'VBP'), ('1', 'CD'), ('day', 'NN')]

>> Noun Phrases are: 
 ['parameters', 'day']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('1006', '1006'), ('parameters', 'paramet'), ('~', '~'), ('1', '1'), ('day', 'day')]

>> Stemming using Snowball Stemmer: 
 [('1006', '1006'), ('parameters', 'paramet'), ('~', '~'), ('1', '1'), ('day', 'day')]

>> Lemmatization: 
 [('1006', '1006'), ('parameters', 'parameter'), ('~', '~'), ('1', '1'), ('day', 'day')]



========================================== PARAGRAPH 541 ===========================================

CNN [33]  Two GTX 580  

------------------- Sentence 1 -------------------

CNN [33]  Two GTX 580

>> Tokens are: 
 ['CNN', '[', '33', ']', 'Two', 'GTX', '580']

>> Bigrams are: 
 [('CNN', '['), ('[', '33'), ('33', ']'), (']', 'Two'), ('Two', 'GTX'), ('GTX', '580')]

>> Trigrams are: 
 [('CNN', '[', '33'), ('[', '33', ']'), ('33', ']', 'Two'), (']', 'Two', 'GTX'), ('Two', 'GTX', '580')]

>> POS Tags are: 
 [('CNN', 'NNP'), ('[', 'VBD'), ('33', 'CD'), (']', 'JJ'), ('Two', 'CD'), ('GTX', 'NNP'), ('580', 'CD')]

>> Noun Phrases are: 
 ['CNN', 'GTX']

>> Named Entities are: 
 [('ORGANIZATION', 'CNN')] 

>> Stemming using Porter Stemmer: 
 [('CNN', 'cnn'), ('[', '['), ('33', '33'), (']', ']'), ('Two', 'two'), ('GTX', 'gtx'), ('580', '580')]

>> Stemming using Snowball Stemmer: 
 [('CNN', 'cnn'), ('[', '['), ('33', '33'), (']', ']'), ('Two', 'two'), ('GTX', 'gtx'), ('580', '580')]

>> Lemmatization: 
 [('CNN', 'CNN'), ('[', '['), ('33', '33'), (']', ']'), ('Two', 'Two'), ('GTX', 'GTX'), ('580', '580')]



========================================== PARAGRAPH 542 ===========================================

GPUs( 6 GB RAM)  

------------------- Sentence 1 -------------------

GPUs( 6 GB RAM)

>> Tokens are: 
 ['GPUs', '(', '6', 'GB', 'RAM', ')']

>> Bigrams are: 
 [('GPUs', '('), ('(', '6'), ('6', 'GB'), ('GB', 'RAM'), ('RAM', ')')]

>> Trigrams are: 
 [('GPUs', '(', '6'), ('(', '6', 'GB'), ('6', 'GB', 'RAM'), ('GB', 'RAM', ')')]

>> POS Tags are: 
 [('GPUs', 'NNP'), ('(', '('), ('6', 'CD'), ('GB', 'NNP'), ('RAM', 'NNP'), (')', ')')]

>> Noun Phrases are: 
 ['GPUs', 'GB RAM']

>> Named Entities are: 
 [('GPE', 'GPUs')] 

>> Stemming using Porter Stemmer: 
 [('GPUs', 'gpu'), ('(', '('), ('6', '6'), ('GB', 'gb'), ('RAM', 'ram'), (')', ')')]

>> Stemming using Snowball Stemmer: 
 [('GPUs', 'gpus'), ('(', '('), ('6', '6'), ('GB', 'gb'), ('RAM', 'ram'), (')', ')')]

>> Lemmatization: 
 [('GPUs', 'GPUs'), ('(', '('), ('6', '6'), ('GB', 'GB'), ('RAM', 'RAM'), (')', ')')]



========================================== PARAGRAPH 543 ===========================================

1.2 million high  resolution (256  256)  

------------------- Sentence 1 -------------------

1.2 million high  resolution (256  256)

>> Tokens are: 
 ['1.2', 'million', 'high', 'resolution', '(', '256', '', '256', ')']

>> Bigrams are: 
 [('1.2', 'million'), ('million', 'high'), ('high', 'resolution'), ('resolution', '('), ('(', '256'), ('256', ''), ('', '256'), ('256', ')')]

>> Trigrams are: 
 [('1.2', 'million', 'high'), ('million', 'high', 'resolution'), ('high', 'resolution', '('), ('resolution', '(', '256'), ('(', '256', ''), ('256', '', '256'), ('', '256', ')')]

>> POS Tags are: 
 [('1.2', 'CD'), ('million', 'CD'), ('high', 'JJ'), ('resolution', 'NN'), ('(', '('), ('256', 'CD'), ('', 'RB'), ('256', 'CD'), (')', ')')]

>> Noun Phrases are: 
 ['high resolution']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('1.2', '1.2'), ('million', 'million'), ('high', 'high'), ('resolution', 'resolut'), ('(', '('), ('256', '256'), ('', ''), ('256', '256'), (')', ')')]

>> Stemming using Snowball Stemmer: 
 [('1.2', '1.2'), ('million', 'million'), ('high', 'high'), ('resolution', 'resolut'), ('(', '('), ('256', '256'), ('', ''), ('256', '256'), (')', ')')]

>> Lemmatization: 
 [('1.2', '1.2'), ('million', 'million'), ('high', 'high'), ('resolution', 'resolution'), ('(', '('), ('256', '256'), ('', ''), ('256', '256'), (')', ')')]



========================================== PARAGRAPH 544 ===========================================

images and 606  

------------------- Sentence 1 -------------------

images and 606

>> Tokens are: 
 ['images', '606']

>> Bigrams are: 
 [('images', '606')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('images', 'NNS'), ('606', 'CD')]

>> Noun Phrases are: 
 ['images']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('images', 'imag'), ('606', '606')]

>> Stemming using Snowball Stemmer: 
 [('images', 'imag'), ('606', '606')]

>> Lemmatization: 
 [('images', 'image'), ('606', '606')]



========================================== PARAGRAPH 545 ===========================================

parameters  

------------------- Sentence 1 -------------------

parameters

>> Tokens are: 
 ['parameters']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('parameters', 'NNS')]

>> Noun Phrases are: 
 ['parameters']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('parameters', 'paramet')]

>> Stemming using Snowball Stemmer: 
 [('parameters', 'paramet')]

>> Lemmatization: 
 [('parameters', 'parameter')]



========================================== PARAGRAPH 546 ===========================================

~ 5-6 days  

------------------- Sentence 1 -------------------

~ 5-6 days

>> Tokens are: 
 ['~', '5-6', 'days']

>> Bigrams are: 
 [('~', '5-6'), ('5-6', 'days')]

>> Trigrams are: 
 [('~', '5-6', 'days')]

>> POS Tags are: 
 [('~', 'JJ'), ('5-6', 'JJ'), ('days', 'NNS')]

>> Noun Phrases are: 
 ['~ 5-6 days']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('~', '~'), ('5-6', '5-6'), ('days', 'day')]

>> Stemming using Snowball Stemmer: 
 [('~', '~'), ('5-6', '5-6'), ('days', 'day')]

>> Lemmatization: 
 [('~', '~'), ('5-6', '5-6'), ('days', 'day')]



========================================== PARAGRAPH 547 ===========================================

DisBelief [34]  

------------------- Sentence 1 -------------------

DisBelief [34]

>> Tokens are: 
 ['DisBelief', '[', '34', ']']

>> Bigrams are: 
 [('DisBelief', '['), ('[', '34'), ('34', ']')]

>> Trigrams are: 
 [('DisBelief', '[', '34'), ('[', '34', ']')]

>> POS Tags are: 
 [('DisBelief', 'NNP'), ('[', 'VBZ'), ('34', 'CD'), (']', 'NN')]

>> Noun Phrases are: 
 ['DisBelief', ']']

>> Named Entities are: 
 [('ORGANIZATION', 'DisBelief')] 

>> Stemming using Porter Stemmer: 
 [('DisBelief', 'disbelief'), ('[', '['), ('34', '34'), (']', ']')]

>> Stemming using Snowball Stemmer: 
 [('DisBelief', 'disbelief'), ('[', '['), ('34', '34'), (']', ']')]

>> Lemmatization: 
 [('DisBelief', 'DisBelief'), ('[', '['), ('34', '34'), (']', ']')]



========================================== PARAGRAPH 548 ===========================================

1000 CPUs with  

------------------- Sentence 1 -------------------

1000 CPUs with

>> Tokens are: 
 ['1000', 'CPUs']

>> Bigrams are: 
 [('1000', 'CPUs')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('1000', 'CD'), ('CPUs', 'NNP')]

>> Noun Phrases are: 
 ['CPUs']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('1000', '1000'), ('CPUs', 'cpu')]

>> Stemming using Snowball Stemmer: 
 [('1000', '1000'), ('CPUs', 'cpus')]

>> Lemmatization: 
 [('1000', '1000'), ('CPUs', 'CPUs')]



========================================== PARAGRAPH 549 ===========================================

Downpour SGD with  

------------------- Sentence 1 -------------------

Downpour SGD with

>> Tokens are: 
 ['Downpour', 'SGD']

>> Bigrams are: 
 [('Downpour', 'SGD')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Downpour', 'NNP'), ('SGD', 'NNP')]

>> Noun Phrases are: 
 ['Downpour SGD']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Downpour', 'downpour'), ('SGD', 'sgd')]

>> Stemming using Snowball Stemmer: 
 [('Downpour', 'downpour'), ('SGD', 'sgd')]

>> Lemmatization: 
 [('Downpour', 'Downpour'), ('SGD', 'SGD')]



========================================== PARAGRAPH 550 ===========================================

Adagrad  

------------------- Sentence 1 -------------------

Adagrad

>> Tokens are: 
 ['Adagrad']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Adagrad', 'NN')]

>> Noun Phrases are: 
 ['Adagrad']

>> Named Entities are: 
 [('GPE', 'Adagrad')] 

>> Stemming using Porter Stemmer: 
 [('Adagrad', 'adagrad')]

>> Stemming using Snowball Stemmer: 
 [('Adagrad', 'adagrad')]

>> Lemmatization: 
 [('Adagrad', 'Adagrad')]



========================================== PARAGRAPH 551 ===========================================

1.1 billion audio  

------------------- Sentence 1 -------------------

1.1 billion audio

>> Tokens are: 
 ['1.1', 'billion', 'audio']

>> Bigrams are: 
 [('1.1', 'billion'), ('billion', 'audio')]

>> Trigrams are: 
 [('1.1', 'billion', 'audio')]

>> POS Tags are: 
 [('1.1', 'CD'), ('billion', 'CD'), ('audio', 'NNS')]

>> Noun Phrases are: 
 ['audio']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('1.1', '1.1'), ('billion', 'billion'), ('audio', 'audio')]

>> Stemming using Snowball Stemmer: 
 [('1.1', '1.1'), ('billion', 'billion'), ('audio', 'audio')]

>> Lemmatization: 
 [('1.1', '1.1'), ('billion', 'billion'), ('audio', 'audio')]



========================================== PARAGRAPH 552 ===========================================

examples with 42 million  

------------------- Sentence 1 -------------------

examples with 42 million

>> Tokens are: 
 ['examples', '42', 'million']

>> Bigrams are: 
 [('examples', '42'), ('42', 'million')]

>> Trigrams are: 
 [('examples', '42', 'million')]

>> POS Tags are: 
 [('examples', 'NNS'), ('42', 'CD'), ('million', 'CD')]

>> Noun Phrases are: 
 ['examples']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('examples', 'exampl'), ('42', '42'), ('million', 'million')]

>> Stemming using Snowball Stemmer: 
 [('examples', 'exampl'), ('42', '42'), ('million', 'million')]

>> Lemmatization: 
 [('examples', 'example'), ('42', '42'), ('million', 'million')]



========================================== PARAGRAPH 553 ===========================================

parameters  

------------------- Sentence 1 -------------------

parameters

>> Tokens are: 
 ['parameters']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('parameters', 'NNS')]

>> Noun Phrases are: 
 ['parameters']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('parameters', 'paramet')]

>> Stemming using Snowball Stemmer: 
 [('parameters', 'paramet')]

>> Lemmatization: 
 [('parameters', 'parameter')]



========================================== PARAGRAPH 554 ===========================================

~ 16 hours  

------------------- Sentence 1 -------------------

~ 16 hours

>> Tokens are: 
 ['~', '16', 'hours']

>> Bigrams are: 
 [('~', '16'), ('16', 'hours')]

>> Trigrams are: 
 [('~', '16', 'hours')]

>> POS Tags are: 
 [('~', 'RB'), ('16', 'CD'), ('hours', 'NNS')]

>> Noun Phrases are: 
 ['hours']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('~', '~'), ('16', '16'), ('hours', 'hour')]

>> Stemming using Snowball Stemmer: 
 [('~', '~'), ('16', '16'), ('hours', 'hour')]

>> Lemmatization: 
 [('~', '~'), ('16', '16'), ('hours', 'hour')]



========================================== PARAGRAPH 555 ===========================================

Sparse  Autoencoder  

------------------- Sentence 1 -------------------

Sparse  Autoencoder

>> Tokens are: 
 ['Sparse', 'Autoencoder']

>> Bigrams are: 
 [('Sparse', 'Autoencoder')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Sparse', 'NNP'), ('Autoencoder', 'NNP')]

>> Noun Phrases are: 
 ['Sparse Autoencoder']

>> Named Entities are: 
 [('GPE', 'Sparse')] 

>> Stemming using Porter Stemmer: 
 [('Sparse', 'spars'), ('Autoencoder', 'autoencod')]

>> Stemming using Snowball Stemmer: 
 [('Sparse', 'spars'), ('Autoencoder', 'autoencod')]

>> Lemmatization: 
 [('Sparse', 'Sparse'), ('Autoencoder', 'Autoencoder')]



========================================== PARAGRAPH 556 ===========================================

[35]  

------------------- Sentence 1 -------------------

[35]

>> Tokens are: 
 ['[', '35', ']']

>> Bigrams are: 
 [('[', '35'), ('35', ']')]

>> Trigrams are: 
 [('[', '35', ']')]

>> POS Tags are: 
 [('[', 'RB'), ('35', 'CD'), (']', 'NNS')]

>> Noun Phrases are: 
 [']']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('35', '35'), (']', ']')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('35', '35'), (']', ']')]

>> Lemmatization: 
 [('[', '['), ('35', '35'), (']', ']')]



========================================== PARAGRAPH 557 ===========================================

1000 CPUs with  

------------------- Sentence 1 -------------------

1000 CPUs with

>> Tokens are: 
 ['1000', 'CPUs']

>> Bigrams are: 
 [('1000', 'CPUs')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('1000', 'CD'), ('CPUs', 'NNP')]

>> Noun Phrases are: 
 ['CPUs']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('1000', '1000'), ('CPUs', 'cpu')]

>> Stemming using Snowball Stemmer: 
 [('1000', '1000'), ('CPUs', 'cpus')]

>> Lemmatization: 
 [('1000', '1000'), ('CPUs', 'CPUs')]



========================================== PARAGRAPH 558 ===========================================

16,000 core  

------------------- Sentence 1 -------------------

16,000 core

>> Tokens are: 
 ['16,000', 'core']

>> Bigrams are: 
 [('16,000', 'core')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('16,000', 'CD'), ('core', 'NN')]

>> Noun Phrases are: 
 ['core']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('16,000', '16,000'), ('core', 'core')]

>> Stemming using Snowball Stemmer: 
 [('16,000', '16,000'), ('core', 'core')]

>> Lemmatization: 
 [('16,000', '16,000'), ('core', 'core')]



========================================== PARAGRAPH 559 ===========================================

10 million (200  200 )  Images and 1 billion  

------------------- Sentence 1 -------------------

10 million (200  200 )  Images and 1 billion

>> Tokens are: 
 ['10', 'million', '(', '200', '', '200', ')', 'Images', '1', 'billion']

>> Bigrams are: 
 [('10', 'million'), ('million', '('), ('(', '200'), ('200', ''), ('', '200'), ('200', ')'), (')', 'Images'), ('Images', '1'), ('1', 'billion')]

>> Trigrams are: 
 [('10', 'million', '('), ('million', '(', '200'), ('(', '200', ''), ('200', '', '200'), ('', '200', ')'), ('200', ')', 'Images'), (')', 'Images', '1'), ('Images', '1', 'billion')]

>> POS Tags are: 
 [('10', 'CD'), ('million', 'CD'), ('(', '('), ('200', 'CD'), ('', 'RB'), ('200', 'CD'), (')', ')'), ('Images', 'VBZ'), ('1', 'CD'), ('billion', 'CD')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('10', '10'), ('million', 'million'), ('(', '('), ('200', '200'), ('', ''), ('200', '200'), (')', ')'), ('Images', 'imag'), ('1', '1'), ('billion', 'billion')]

>> Stemming using Snowball Stemmer: 
 [('10', '10'), ('million', 'million'), ('(', '('), ('200', '200'), ('', ''), ('200', '200'), (')', ')'), ('Images', 'imag'), ('1', '1'), ('billion', 'billion')]

>> Lemmatization: 
 [('10', '10'), ('million', 'million'), ('(', '('), ('200', '200'), ('', ''), ('200', '200'), (')', ')'), ('Images', 'Images'), ('1', '1'), ('billion', 'billion')]



========================================== PARAGRAPH 560 ===========================================

parameters  

------------------- Sentence 1 -------------------

parameters

>> Tokens are: 
 ['parameters']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('parameters', 'NNS')]

>> Noun Phrases are: 
 ['parameters']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('parameters', 'paramet')]

>> Stemming using Snowball Stemmer: 
 [('parameters', 'paramet')]

>> Lemmatization: 
 [('parameters', 'parameter')]



========================================== PARAGRAPH 561 ===========================================

~ 3Days  

------------------- Sentence 1 -------------------

~ 3Days

>> Tokens are: 
 ['~', '3Days']

>> Bigrams are: 
 [('~', '3Days')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('~', '$'), ('3Days', 'CD')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('~', '~'), ('3Days', '3day')]

>> Stemming using Snowball Stemmer: 
 [('~', '~'), ('3Days', '3day')]

>> Lemmatization: 
 [('~', '~'), ('3Days', '3Days')]



========================================== PARAGRAPH 562 ===========================================

COTS HPC  

------------------- Sentence 1 -------------------

COTS HPC

>> Tokens are: 
 ['COTS', 'HPC']

>> Bigrams are: 
 [('COTS', 'HPC')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('COTS', 'NNP'), ('HPC', 'NNP')]

>> Noun Phrases are: 
 ['COTS HPC']

>> Named Entities are: 
 [('ORGANIZATION', 'COTS'), ('ORGANIZATION', 'HPC')] 

>> Stemming using Porter Stemmer: 
 [('COTS', 'cot'), ('HPC', 'hpc')]

>> Stemming using Snowball Stemmer: 
 [('COTS', 'cot'), ('HPC', 'hpc')]

>> Lemmatization: 
 [('COTS', 'COTS'), ('HPC', 'HPC')]



========================================== PARAGRAPH 563 ===========================================

[36]  

------------------- Sentence 1 -------------------

[36]

>> Tokens are: 
 ['[', '36', ']']

>> Bigrams are: 
 [('[', '36'), ('36', ']')]

>> Trigrams are: 
 [('[', '36', ']')]

>> POS Tags are: 
 [('[', 'RB'), ('36', 'CD'), (']', 'NNS')]

>> Noun Phrases are: 
 [']']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('36', '36'), (']', ']')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('36', '36'), (']', ']')]

>> Lemmatization: 
 [('[', '['), ('36', '36'), (']', ']')]



========================================== PARAGRAPH 564 ===========================================

64 NVIDIA GTX  680 GPUs  

------------------- Sentence 1 -------------------

64 NVIDIA GTX  680 GPUs

>> Tokens are: 
 ['64', 'NVIDIA', 'GTX', '680', 'GPUs']

>> Bigrams are: 
 [('64', 'NVIDIA'), ('NVIDIA', 'GTX'), ('GTX', '680'), ('680', 'GPUs')]

>> Trigrams are: 
 [('64', 'NVIDIA', 'GTX'), ('NVIDIA', 'GTX', '680'), ('GTX', '680', 'GPUs')]

>> POS Tags are: 
 [('64', 'CD'), ('NVIDIA', 'NNP'), ('GTX', 'NNP'), ('680', 'CD'), ('GPUs', 'NNP')]

>> Noun Phrases are: 
 ['NVIDIA GTX', 'GPUs']

>> Named Entities are: 
 [('ORGANIZATION', 'NVIDIA')] 

>> Stemming using Porter Stemmer: 
 [('64', '64'), ('NVIDIA', 'nvidia'), ('GTX', 'gtx'), ('680', '680'), ('GPUs', 'gpu')]

>> Stemming using Snowball Stemmer: 
 [('64', '64'), ('NVIDIA', 'nvidia'), ('GTX', 'gtx'), ('680', '680'), ('GPUs', 'gpus')]

>> Lemmatization: 
 [('64', '64'), ('NVIDIA', 'NVIDIA'), ('GTX', 'GTX'), ('680', '680'), ('GPUs', 'GPUs')]



========================================== PARAGRAPH 565 ===========================================

(256 GB RAM)  

------------------- Sentence 1 -------------------

(256 GB RAM)

>> Tokens are: 
 ['(', '256', 'GB', 'RAM', ')']

>> Bigrams are: 
 [('(', '256'), ('256', 'GB'), ('GB', 'RAM'), ('RAM', ')')]

>> Trigrams are: 
 [('(', '256', 'GB'), ('256', 'GB', 'RAM'), ('GB', 'RAM', ')')]

>> POS Tags are: 
 [('(', '('), ('256', 'CD'), ('GB', 'NNP'), ('RAM', 'NNP'), (')', ')')]

>> Noun Phrases are: 
 ['GB RAM']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('256', '256'), ('GB', 'gb'), ('RAM', 'ram'), (')', ')')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('256', '256'), ('GB', 'gb'), ('RAM', 'ram'), (')', ')')]

>> Lemmatization: 
 [('(', '('), ('256', '256'), ('GB', 'GB'), ('RAM', 'RAM'), (')', ')')]



========================================== PARAGRAPH 566 ===========================================

10 million (200  200 )  Images and 11 billion  

------------------- Sentence 1 -------------------

10 million (200  200 )  Images and 11 billion

>> Tokens are: 
 ['10', 'million', '(', '200', '', '200', ')', 'Images', '11', 'billion']

>> Bigrams are: 
 [('10', 'million'), ('million', '('), ('(', '200'), ('200', ''), ('', '200'), ('200', ')'), (')', 'Images'), ('Images', '11'), ('11', 'billion')]

>> Trigrams are: 
 [('10', 'million', '('), ('million', '(', '200'), ('(', '200', ''), ('200', '', '200'), ('', '200', ')'), ('200', ')', 'Images'), (')', 'Images', '11'), ('Images', '11', 'billion')]

>> POS Tags are: 
 [('10', 'CD'), ('million', 'CD'), ('(', '('), ('200', 'CD'), ('', 'RB'), ('200', 'CD'), (')', ')'), ('Images', 'VBZ'), ('11', 'CD'), ('billion', 'CD')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('10', '10'), ('million', 'million'), ('(', '('), ('200', '200'), ('', ''), ('200', '200'), (')', ')'), ('Images', 'imag'), ('11', '11'), ('billion', 'billion')]

>> Stemming using Snowball Stemmer: 
 [('10', '10'), ('million', 'million'), ('(', '('), ('200', '200'), ('', ''), ('200', '200'), (')', ')'), ('Images', 'imag'), ('11', '11'), ('billion', 'billion')]

>> Lemmatization: 
 [('10', '10'), ('million', 'million'), ('(', '('), ('200', '200'), ('', ''), ('200', '200'), (')', ')'), ('Images', 'Images'), ('11', '11'), ('billion', 'billion')]



========================================== PARAGRAPH 567 ===========================================

parameters  

------------------- Sentence 1 -------------------

parameters

>> Tokens are: 
 ['parameters']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('parameters', 'NNS')]

>> Noun Phrases are: 
 ['parameters']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('parameters', 'paramet')]

>> Stemming using Snowball Stemmer: 
 [('parameters', 'paramet')]

>> Lemmatization: 
 [('parameters', 'parameter')]



========================================== PARAGRAPH 568 ===========================================

~ 3Days  

------------------- Sentence 1 -------------------

~ 3Days

>> Tokens are: 
 ['~', '3Days']

>> Bigrams are: 
 [('~', '3Days')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('~', '$'), ('3Days', 'CD')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('~', '~'), ('3Days', '3day')]

>> Stemming using Snowball Stemmer: 
 [('~', '~'), ('3Days', '3day')]

>> Lemmatization: 
 [('~', '~'), ('3Days', '3Days')]



========================================== PARAGRAPH 569 ===========================================

The Table.4 summarizes the current progress in deep  

------------------- Sentence 1 -------------------

The Table.4 summarizes the current progress in deep

>> Tokens are: 
 ['The', 'Table.4', 'summarizes', 'current', 'progress', 'deep']

>> Bigrams are: 
 [('The', 'Table.4'), ('Table.4', 'summarizes'), ('summarizes', 'current'), ('current', 'progress'), ('progress', 'deep')]

>> Trigrams are: 
 [('The', 'Table.4', 'summarizes'), ('Table.4', 'summarizes', 'current'), ('summarizes', 'current', 'progress'), ('current', 'progress', 'deep')]

>> POS Tags are: 
 [('The', 'DT'), ('Table.4', 'NNP'), ('summarizes', 'VBZ'), ('current', 'JJ'), ('progress', 'NN'), ('deep', 'NN')]

>> Noun Phrases are: 
 ['The Table.4', 'current progress deep']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('Table.4', 'table.4'), ('summarizes', 'summar'), ('current', 'current'), ('progress', 'progress'), ('deep', 'deep')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('Table.4', 'table.4'), ('summarizes', 'summar'), ('current', 'current'), ('progress', 'progress'), ('deep', 'deep')]

>> Lemmatization: 
 [('The', 'The'), ('Table.4', 'Table.4'), ('summarizes', 'summarizes'), ('current', 'current'), ('progress', 'progress'), ('deep', 'deep')]



========================================== PARAGRAPH 570 ===========================================

learning algorithms. It has been observed that different deep  

------------------- Sentence 1 -------------------

learning algorithms.

>> Tokens are: 
 ['learning', 'algorithms', '.']

>> Bigrams are: 
 [('learning', 'algorithms'), ('algorithms', '.')]

>> Trigrams are: 
 [('learning', 'algorithms', '.')]

>> POS Tags are: 
 [('learning', 'VBG'), ('algorithms', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['algorithms']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('learning', 'learn'), ('algorithms', 'algorithm'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('learning', 'learn'), ('algorithms', 'algorithm'), ('.', '.')]

>> Lemmatization: 
 [('learning', 'learning'), ('algorithms', 'algorithm'), ('.', '.')]


------------------- Sentence 2 -------------------

It has been observed that different deep

>> Tokens are: 
 ['It', 'observed', 'different', 'deep']

>> Bigrams are: 
 [('It', 'observed'), ('observed', 'different'), ('different', 'deep')]

>> Trigrams are: 
 [('It', 'observed', 'different'), ('observed', 'different', 'deep')]

>> POS Tags are: 
 [('It', 'PRP'), ('observed', 'VBD'), ('different', 'JJ'), ('deep', 'NN')]

>> Noun Phrases are: 
 ['different deep']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('It', 'it'), ('observed', 'observ'), ('different', 'differ'), ('deep', 'deep')]

>> Stemming using Snowball Stemmer: 
 [('It', 'it'), ('observed', 'observ'), ('different', 'differ'), ('deep', 'deep')]

>> Lemmatization: 
 [('It', 'It'), ('observed', 'observed'), ('different', 'different'), ('deep', 'deep')]



========================================== PARAGRAPH 571 ===========================================

learning technologies [32-36] required huge computational  

------------------- Sentence 1 -------------------

learning technologies [32-36] required huge computational

>> Tokens are: 
 ['learning', 'technologies', '[', '32-36', ']', 'required', 'huge', 'computational']

>> Bigrams are: 
 [('learning', 'technologies'), ('technologies', '['), ('[', '32-36'), ('32-36', ']'), (']', 'required'), ('required', 'huge'), ('huge', 'computational')]

>> Trigrams are: 
 [('learning', 'technologies', '['), ('technologies', '[', '32-36'), ('[', '32-36', ']'), ('32-36', ']', 'required'), (']', 'required', 'huge'), ('required', 'huge', 'computational')]

>> POS Tags are: 
 [('learning', 'VBG'), ('technologies', 'NNS'), ('[', 'VBP'), ('32-36', 'JJ'), (']', 'NN'), ('required', 'VBN'), ('huge', 'JJ'), ('computational', 'NN')]

>> Noun Phrases are: 
 ['technologies', '32-36 ]', 'huge computational']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('learning', 'learn'), ('technologies', 'technolog'), ('[', '['), ('32-36', '32-36'), (']', ']'), ('required', 'requir'), ('huge', 'huge'), ('computational', 'comput')]

>> Stemming using Snowball Stemmer: 
 [('learning', 'learn'), ('technologies', 'technolog'), ('[', '['), ('32-36', '32-36'), (']', ']'), ('required', 'requir'), ('huge', 'huge'), ('computational', 'comput')]

>> Lemmatization: 
 [('learning', 'learning'), ('technologies', 'technology'), ('[', '['), ('32-36', '32-36'), (']', ']'), ('required', 'required'), ('huge', 'huge'), ('computational', 'computational')]



========================================== PARAGRAPH 572 ===========================================

resources to achieve significant results.  

------------------- Sentence 1 -------------------

resources to achieve significant results.

>> Tokens are: 
 ['resources', 'achieve', 'significant', 'results', '.']

>> Bigrams are: 
 [('resources', 'achieve'), ('achieve', 'significant'), ('significant', 'results'), ('results', '.')]

>> Trigrams are: 
 [('resources', 'achieve', 'significant'), ('achieve', 'significant', 'results'), ('significant', 'results', '.')]

>> POS Tags are: 
 [('resources', 'NNS'), ('achieve', 'VBP'), ('significant', 'JJ'), ('results', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['resources', 'significant results']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('resources', 'resourc'), ('achieve', 'achiev'), ('significant', 'signific'), ('results', 'result'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('resources', 'resourc'), ('achieve', 'achiev'), ('significant', 'signific'), ('results', 'result'), ('.', '.')]

>> Lemmatization: 
 [('resources', 'resource'), ('achieve', 'achieve'), ('significant', 'significant'), ('results', 'result'), ('.', '.')]



========================================== PARAGRAPH 573 ===========================================

8. CONCLUSION  

------------------- Sentence 1 -------------------

8.

>> Tokens are: 
 ['8', '.']

>> Bigrams are: 
 [('8', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('8', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('8', '8'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('8', '8'), ('.', '.')]

>> Lemmatization: 
 [('8', '8'), ('.', '.')]


------------------- Sentence 2 -------------------

CONCLUSION

>> Tokens are: 
 ['CONCLUSION']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('CONCLUSION', 'NN')]

>> Noun Phrases are: 
 ['CONCLUSION']

>> Named Entities are: 
 [('ORGANIZATION', 'CONCLUSION')] 

>> Stemming using Porter Stemmer: 
 [('CONCLUSION', 'conclus')]

>> Stemming using Snowball Stemmer: 
 [('CONCLUSION', 'conclus')]

>> Lemmatization: 
 [('CONCLUSION', 'CONCLUSION')]



========================================== PARAGRAPH 574 ===========================================

Supervised machine learning methods are being applied in  

------------------- Sentence 1 -------------------

Supervised machine learning methods are being applied in

>> Tokens are: 
 ['Supervised', 'machine', 'learning', 'methods', 'applied']

>> Bigrams are: 
 [('Supervised', 'machine'), ('machine', 'learning'), ('learning', 'methods'), ('methods', 'applied')]

>> Trigrams are: 
 [('Supervised', 'machine', 'learning'), ('machine', 'learning', 'methods'), ('learning', 'methods', 'applied')]

>> POS Tags are: 
 [('Supervised', 'VBN'), ('machine', 'NN'), ('learning', 'VBG'), ('methods', 'NNS'), ('applied', 'VBN')]

>> Noun Phrases are: 
 ['machine', 'methods']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Supervised', 'supervis'), ('machine', 'machin'), ('learning', 'learn'), ('methods', 'method'), ('applied', 'appli')]

>> Stemming using Snowball Stemmer: 
 [('Supervised', 'supervis'), ('machine', 'machin'), ('learning', 'learn'), ('methods', 'method'), ('applied', 'appli')]

>> Lemmatization: 
 [('Supervised', 'Supervised'), ('machine', 'machine'), ('learning', 'learning'), ('methods', 'method'), ('applied', 'applied')]



========================================== PARAGRAPH 575 ===========================================

different domains. Due to scope of this paper, it is very difficult to  

------------------- Sentence 1 -------------------

different domains.

>> Tokens are: 
 ['different', 'domains', '.']

>> Bigrams are: 
 [('different', 'domains'), ('domains', '.')]

>> Trigrams are: 
 [('different', 'domains', '.')]

>> POS Tags are: 
 [('different', 'JJ'), ('domains', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['different domains']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('different', 'differ'), ('domains', 'domain'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('different', 'differ'), ('domains', 'domain'), ('.', '.')]

>> Lemmatization: 
 [('different', 'different'), ('domains', 'domain'), ('.', '.')]


------------------- Sentence 2 -------------------

Due to scope of this paper, it is very difficult to

>> Tokens are: 
 ['Due', 'scope', 'paper', ',', 'difficult']

>> Bigrams are: 
 [('Due', 'scope'), ('scope', 'paper'), ('paper', ','), (',', 'difficult')]

>> Trigrams are: 
 [('Due', 'scope', 'paper'), ('scope', 'paper', ','), ('paper', ',', 'difficult')]

>> POS Tags are: 
 [('Due', 'NNP'), ('scope', 'NN'), ('paper', 'NN'), (',', ','), ('difficult', 'JJ')]

>> Noun Phrases are: 
 ['Due scope paper']

>> Named Entities are: 
 [('GPE', 'Due')] 

>> Stemming using Porter Stemmer: 
 [('Due', 'due'), ('scope', 'scope'), ('paper', 'paper'), (',', ','), ('difficult', 'difficult')]

>> Stemming using Snowball Stemmer: 
 [('Due', 'due'), ('scope', 'scope'), ('paper', 'paper'), (',', ','), ('difficult', 'difficult')]

>> Lemmatization: 
 [('Due', 'Due'), ('scope', 'scope'), ('paper', 'paper'), (',', ','), ('difficult', 'difficult')]



========================================== PARAGRAPH 576 ===========================================

discuss the strength and weaknesses of each algorithm of ML. The  

------------------- Sentence 1 -------------------

discuss the strength and weaknesses of each algorithm of ML.

>> Tokens are: 
 ['discuss', 'strength', 'weaknesses', 'algorithm', 'ML', '.']

>> Bigrams are: 
 [('discuss', 'strength'), ('strength', 'weaknesses'), ('weaknesses', 'algorithm'), ('algorithm', 'ML'), ('ML', '.')]

>> Trigrams are: 
 [('discuss', 'strength', 'weaknesses'), ('strength', 'weaknesses', 'algorithm'), ('weaknesses', 'algorithm', 'ML'), ('algorithm', 'ML', '.')]

>> POS Tags are: 
 [('discuss', 'JJ'), ('strength', 'NN'), ('weaknesses', 'NNS'), ('algorithm', 'VBP'), ('ML', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['discuss strength weaknesses', 'ML']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('discuss', 'discuss'), ('strength', 'strength'), ('weaknesses', 'weak'), ('algorithm', 'algorithm'), ('ML', 'ml'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('discuss', 'discuss'), ('strength', 'strength'), ('weaknesses', 'weak'), ('algorithm', 'algorithm'), ('ML', 'ml'), ('.', '.')]

>> Lemmatization: 
 [('discuss', 'discus'), ('strength', 'strength'), ('weaknesses', 'weakness'), ('algorithm', 'algorithm'), ('ML', 'ML'), ('.', '.')]


------------------- Sentence 2 -------------------

The

>> Tokens are: 
 ['The']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('The', 'DT')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the')]

>> Lemmatization: 
 [('The', 'The')]



========================================== PARAGRAPH 577 ===========================================

selection of algorithm in ML is mainly depends on task nature. The  

------------------- Sentence 1 -------------------

selection of algorithm in ML is mainly depends on task nature.

>> Tokens are: 
 ['selection', 'algorithm', 'ML', 'mainly', 'depends', 'task', 'nature', '.']

>> Bigrams are: 
 [('selection', 'algorithm'), ('algorithm', 'ML'), ('ML', 'mainly'), ('mainly', 'depends'), ('depends', 'task'), ('task', 'nature'), ('nature', '.')]

>> Trigrams are: 
 [('selection', 'algorithm', 'ML'), ('algorithm', 'ML', 'mainly'), ('ML', 'mainly', 'depends'), ('mainly', 'depends', 'task'), ('depends', 'task', 'nature'), ('task', 'nature', '.')]

>> POS Tags are: 
 [('selection', 'NN'), ('algorithm', 'VBZ'), ('ML', 'NNP'), ('mainly', 'RB'), ('depends', 'VBZ'), ('task', 'JJ'), ('nature', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['selection', 'ML', 'task nature']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('selection', 'select'), ('algorithm', 'algorithm'), ('ML', 'ml'), ('mainly', 'mainli'), ('depends', 'depend'), ('task', 'task'), ('nature', 'natur'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('selection', 'select'), ('algorithm', 'algorithm'), ('ML', 'ml'), ('mainly', 'main'), ('depends', 'depend'), ('task', 'task'), ('nature', 'natur'), ('.', '.')]

>> Lemmatization: 
 [('selection', 'selection'), ('algorithm', 'algorithm'), ('ML', 'ML'), ('mainly', 'mainly'), ('depends', 'depends'), ('task', 'task'), ('nature', 'nature'), ('.', '.')]


------------------- Sentence 2 -------------------

The

>> Tokens are: 
 ['The']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('The', 'DT')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the')]

>> Lemmatization: 
 [('The', 'The')]



========================================== PARAGRAPH 578 ===========================================

performance of SVM and Neural Networks is better when dealing  

------------------- Sentence 1 -------------------

performance of SVM and Neural Networks is better when dealing

>> Tokens are: 
 ['performance', 'SVM', 'Neural', 'Networks', 'better', 'dealing']

>> Bigrams are: 
 [('performance', 'SVM'), ('SVM', 'Neural'), ('Neural', 'Networks'), ('Networks', 'better'), ('better', 'dealing')]

>> Trigrams are: 
 [('performance', 'SVM', 'Neural'), ('SVM', 'Neural', 'Networks'), ('Neural', 'Networks', 'better'), ('Networks', 'better', 'dealing')]

>> POS Tags are: 
 [('performance', 'NN'), ('SVM', 'NNP'), ('Neural', 'NNP'), ('Networks', 'NNP'), ('better', 'RBR'), ('dealing', 'VBG')]

>> Noun Phrases are: 
 ['performance SVM Neural Networks']

>> Named Entities are: 
 [('ORGANIZATION', 'SVM Neural Networks')] 

>> Stemming using Porter Stemmer: 
 [('performance', 'perform'), ('SVM', 'svm'), ('Neural', 'neural'), ('Networks', 'network'), ('better', 'better'), ('dealing', 'deal')]

>> Stemming using Snowball Stemmer: 
 [('performance', 'perform'), ('SVM', 'svm'), ('Neural', 'neural'), ('Networks', 'network'), ('better', 'better'), ('dealing', 'deal')]

>> Lemmatization: 
 [('performance', 'performance'), ('SVM', 'SVM'), ('Neural', 'Neural'), ('Networks', 'Networks'), ('better', 'better'), ('dealing', 'dealing')]



========================================== PARAGRAPH 579 ===========================================

with multidimensions and continuous features. While logic-based  

------------------- Sentence 1 -------------------

with multidimensions and continuous features.

>> Tokens are: 
 ['multidimensions', 'continuous', 'features', '.']

>> Bigrams are: 
 [('multidimensions', 'continuous'), ('continuous', 'features'), ('features', '.')]

>> Trigrams are: 
 [('multidimensions', 'continuous', 'features'), ('continuous', 'features', '.')]

>> POS Tags are: 
 [('multidimensions', 'NNS'), ('continuous', 'JJ'), ('features', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['multidimensions', 'continuous features']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('multidimensions', 'multidimens'), ('continuous', 'continu'), ('features', 'featur'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('multidimensions', 'multidimens'), ('continuous', 'continu'), ('features', 'featur'), ('.', '.')]

>> Lemmatization: 
 [('multidimensions', 'multidimensions'), ('continuous', 'continuous'), ('features', 'feature'), ('.', '.')]


------------------- Sentence 2 -------------------

While logic-based

>> Tokens are: 
 ['While', 'logic-based']

>> Bigrams are: 
 [('While', 'logic-based')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('While', 'IN'), ('logic-based', 'JJ')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('While', 'while'), ('logic-based', 'logic-bas')]

>> Stemming using Snowball Stemmer: 
 [('While', 'while'), ('logic-based', 'logic-bas')]

>> Lemmatization: 
 [('While', 'While'), ('logic-based', 'logic-based')]



========================================== PARAGRAPH 580 ===========================================

systems tend to perform better when dealing with  

------------------- Sentence 1 -------------------

systems tend to perform better when dealing with

>> Tokens are: 
 ['systems', 'tend', 'perform', 'better', 'dealing']

>> Bigrams are: 
 [('systems', 'tend'), ('tend', 'perform'), ('perform', 'better'), ('better', 'dealing')]

>> Trigrams are: 
 [('systems', 'tend', 'perform'), ('tend', 'perform', 'better'), ('perform', 'better', 'dealing')]

>> POS Tags are: 
 [('systems', 'NNS'), ('tend', 'VBP'), ('perform', 'VB'), ('better', 'JJR'), ('dealing', 'VBG')]

>> Noun Phrases are: 
 ['systems']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('systems', 'system'), ('tend', 'tend'), ('perform', 'perform'), ('better', 'better'), ('dealing', 'deal')]

>> Stemming using Snowball Stemmer: 
 [('systems', 'system'), ('tend', 'tend'), ('perform', 'perform'), ('better', 'better'), ('dealing', 'deal')]

>> Lemmatization: 
 [('systems', 'system'), ('tend', 'tend'), ('perform', 'perform'), ('better', 'better'), ('dealing', 'dealing')]



========================================== PARAGRAPH 581 ===========================================

discrete/categorical features. For neural network models and SVMs,  

------------------- Sentence 1 -------------------

discrete/categorical features.

>> Tokens are: 
 ['discrete/categorical', 'features', '.']

>> Bigrams are: 
 [('discrete/categorical', 'features'), ('features', '.')]

>> Trigrams are: 
 [('discrete/categorical', 'features', '.')]

>> POS Tags are: 
 [('discrete/categorical', 'JJ'), ('features', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['discrete/categorical features']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('discrete/categorical', 'discrete/categor'), ('features', 'featur'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('discrete/categorical', 'discrete/categor'), ('features', 'featur'), ('.', '.')]

>> Lemmatization: 
 [('discrete/categorical', 'discrete/categorical'), ('features', 'feature'), ('.', '.')]


------------------- Sentence 2 -------------------

For neural network models and SVMs,

>> Tokens are: 
 ['For', 'neural', 'network', 'models', 'SVMs', ',']

>> Bigrams are: 
 [('For', 'neural'), ('neural', 'network'), ('network', 'models'), ('models', 'SVMs'), ('SVMs', ',')]

>> Trigrams are: 
 [('For', 'neural', 'network'), ('neural', 'network', 'models'), ('network', 'models', 'SVMs'), ('models', 'SVMs', ',')]

>> POS Tags are: 
 [('For', 'IN'), ('neural', 'JJ'), ('network', 'NN'), ('models', 'NNS'), ('SVMs', 'NNP'), (',', ',')]

>> Noun Phrases are: 
 ['neural network models SVMs']

>> Named Entities are: 
 [('ORGANIZATION', 'SVMs')] 

>> Stemming using Porter Stemmer: 
 [('For', 'for'), ('neural', 'neural'), ('network', 'network'), ('models', 'model'), ('SVMs', 'svm'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('For', 'for'), ('neural', 'neural'), ('network', 'network'), ('models', 'model'), ('SVMs', 'svms'), (',', ',')]

>> Lemmatization: 
 [('For', 'For'), ('neural', 'neural'), ('network', 'network'), ('models', 'model'), ('SVMs', 'SVMs'), (',', ',')]



========================================== PARAGRAPH 582 ===========================================

a large sample size is required in order to achieve its maximum  

------------------- Sentence 1 -------------------

a large sample size is required in order to achieve its maximum

>> Tokens are: 
 ['large', 'sample', 'size', 'required', 'order', 'achieve', 'maximum']

>> Bigrams are: 
 [('large', 'sample'), ('sample', 'size'), ('size', 'required'), ('required', 'order'), ('order', 'achieve'), ('achieve', 'maximum')]

>> Trigrams are: 
 [('large', 'sample', 'size'), ('sample', 'size', 'required'), ('size', 'required', 'order'), ('required', 'order', 'achieve'), ('order', 'achieve', 'maximum')]

>> POS Tags are: 
 [('large', 'JJ'), ('sample', 'JJ'), ('size', 'NN'), ('required', 'VBN'), ('order', 'NN'), ('achieve', 'NNS'), ('maximum', 'NN')]

>> Noun Phrases are: 
 ['large sample size', 'order achieve maximum']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('large', 'larg'), ('sample', 'sampl'), ('size', 'size'), ('required', 'requir'), ('order', 'order'), ('achieve', 'achiev'), ('maximum', 'maximum')]

>> Stemming using Snowball Stemmer: 
 [('large', 'larg'), ('sample', 'sampl'), ('size', 'size'), ('required', 'requir'), ('order', 'order'), ('achieve', 'achiev'), ('maximum', 'maximum')]

>> Lemmatization: 
 [('large', 'large'), ('sample', 'sample'), ('size', 'size'), ('required', 'required'), ('order', 'order'), ('achieve', 'achieve'), ('maximum', 'maximum')]



========================================== PARAGRAPH 583 ===========================================

prediction accuracy whereas NB may need a relatively small  

------------------- Sentence 1 -------------------

prediction accuracy whereas NB may need a relatively small

>> Tokens are: 
 ['prediction', 'accuracy', 'whereas', 'NB', 'may', 'need', 'relatively', 'small']

>> Bigrams are: 
 [('prediction', 'accuracy'), ('accuracy', 'whereas'), ('whereas', 'NB'), ('NB', 'may'), ('may', 'need'), ('need', 'relatively'), ('relatively', 'small')]

>> Trigrams are: 
 [('prediction', 'accuracy', 'whereas'), ('accuracy', 'whereas', 'NB'), ('whereas', 'NB', 'may'), ('NB', 'may', 'need'), ('may', 'need', 'relatively'), ('need', 'relatively', 'small')]

>> POS Tags are: 
 [('prediction', 'NN'), ('accuracy', 'NN'), ('whereas', 'IN'), ('NB', 'NNP'), ('may', 'MD'), ('need', 'VB'), ('relatively', 'RB'), ('small', 'JJ')]

>> Noun Phrases are: 
 ['prediction accuracy', 'NB']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('prediction', 'predict'), ('accuracy', 'accuraci'), ('whereas', 'wherea'), ('NB', 'nb'), ('may', 'may'), ('need', 'need'), ('relatively', 'rel'), ('small', 'small')]

>> Stemming using Snowball Stemmer: 
 [('prediction', 'predict'), ('accuracy', 'accuraci'), ('whereas', 'wherea'), ('NB', 'nb'), ('may', 'may'), ('need', 'need'), ('relatively', 'relat'), ('small', 'small')]

>> Lemmatization: 
 [('prediction', 'prediction'), ('accuracy', 'accuracy'), ('whereas', 'whereas'), ('NB', 'NB'), ('may', 'may'), ('need', 'need'), ('relatively', 'relatively'), ('small', 'small')]



========================================== PARAGRAPH 584 ===========================================

dataset. For the last few years deep learning is becoming a  

------------------- Sentence 1 -------------------

dataset.

>> Tokens are: 
 ['dataset', '.']

>> Bigrams are: 
 [('dataset', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('dataset', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['dataset']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('dataset', 'dataset'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('dataset', 'dataset'), ('.', '.')]

>> Lemmatization: 
 [('dataset', 'dataset'), ('.', '.')]


------------------- Sentence 2 -------------------

For the last few years deep learning is becoming a

>> Tokens are: 
 ['For', 'last', 'years', 'deep', 'learning', 'becoming']

>> Bigrams are: 
 [('For', 'last'), ('last', 'years'), ('years', 'deep'), ('deep', 'learning'), ('learning', 'becoming')]

>> Trigrams are: 
 [('For', 'last', 'years'), ('last', 'years', 'deep'), ('years', 'deep', 'learning'), ('deep', 'learning', 'becoming')]

>> POS Tags are: 
 [('For', 'IN'), ('last', 'JJ'), ('years', 'NNS'), ('deep', 'RB'), ('learning', 'VBG'), ('becoming', 'VBG')]

>> Noun Phrases are: 
 ['last years']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('For', 'for'), ('last', 'last'), ('years', 'year'), ('deep', 'deep'), ('learning', 'learn'), ('becoming', 'becom')]

>> Stemming using Snowball Stemmer: 
 [('For', 'for'), ('last', 'last'), ('years', 'year'), ('deep', 'deep'), ('learning', 'learn'), ('becoming', 'becom')]

>> Lemmatization: 
 [('For', 'For'), ('last', 'last'), ('years', 'year'), ('deep', 'deep'), ('learning', 'learning'), ('becoming', 'becoming')]



========================================== PARAGRAPH 585 ===========================================

mainstream technology for variety of application domains, like face  

------------------- Sentence 1 -------------------

mainstream technology for variety of application domains, like face

>> Tokens are: 
 ['mainstream', 'technology', 'variety', 'application', 'domains', ',', 'like', 'face']

>> Bigrams are: 
 [('mainstream', 'technology'), ('technology', 'variety'), ('variety', 'application'), ('application', 'domains'), ('domains', ','), (',', 'like'), ('like', 'face')]

>> Trigrams are: 
 [('mainstream', 'technology', 'variety'), ('technology', 'variety', 'application'), ('variety', 'application', 'domains'), ('application', 'domains', ','), ('domains', ',', 'like'), (',', 'like', 'face')]

>> POS Tags are: 
 [('mainstream', 'NN'), ('technology', 'NN'), ('variety', 'NN'), ('application', 'NN'), ('domains', 'NNS'), (',', ','), ('like', 'IN'), ('face', 'NN')]

>> Noun Phrases are: 
 ['mainstream technology variety application domains', 'face']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('mainstream', 'mainstream'), ('technology', 'technolog'), ('variety', 'varieti'), ('application', 'applic'), ('domains', 'domain'), (',', ','), ('like', 'like'), ('face', 'face')]

>> Stemming using Snowball Stemmer: 
 [('mainstream', 'mainstream'), ('technology', 'technolog'), ('variety', 'varieti'), ('application', 'applic'), ('domains', 'domain'), (',', ','), ('like', 'like'), ('face', 'face')]

>> Lemmatization: 
 [('mainstream', 'mainstream'), ('technology', 'technology'), ('variety', 'variety'), ('application', 'application'), ('domains', 'domain'), (',', ','), ('like', 'like'), ('face', 'face')]



========================================== PARAGRAPH 586 ===========================================

detection, speech recognition and detection, object recognition,  

------------------- Sentence 1 -------------------

detection, speech recognition and detection, object recognition,

>> Tokens are: 
 ['detection', ',', 'speech', 'recognition', 'detection', ',', 'object', 'recognition', ',']

>> Bigrams are: 
 [('detection', ','), (',', 'speech'), ('speech', 'recognition'), ('recognition', 'detection'), ('detection', ','), (',', 'object'), ('object', 'recognition'), ('recognition', ',')]

>> Trigrams are: 
 [('detection', ',', 'speech'), (',', 'speech', 'recognition'), ('speech', 'recognition', 'detection'), ('recognition', 'detection', ','), ('detection', ',', 'object'), (',', 'object', 'recognition'), ('object', 'recognition', ',')]

>> POS Tags are: 
 [('detection', 'NN'), (',', ','), ('speech', 'NN'), ('recognition', 'NN'), ('detection', 'NN'), (',', ','), ('object', 'JJ'), ('recognition', 'NN'), (',', ',')]

>> Noun Phrases are: 
 ['detection', 'speech recognition detection', 'object recognition']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('detection', 'detect'), (',', ','), ('speech', 'speech'), ('recognition', 'recognit'), ('detection', 'detect'), (',', ','), ('object', 'object'), ('recognition', 'recognit'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('detection', 'detect'), (',', ','), ('speech', 'speech'), ('recognition', 'recognit'), ('detection', 'detect'), (',', ','), ('object', 'object'), ('recognition', 'recognit'), (',', ',')]

>> Lemmatization: 
 [('detection', 'detection'), (',', ','), ('speech', 'speech'), ('recognition', 'recognition'), ('detection', 'detection'), (',', ','), ('object', 'object'), ('recognition', 'recognition'), (',', ',')]



========================================== PARAGRAPH 587 ===========================================

natural language processing and robotics. We believe that the  

------------------- Sentence 1 -------------------

natural language processing and robotics.

>> Tokens are: 
 ['natural', 'language', 'processing', 'robotics', '.']

>> Bigrams are: 
 [('natural', 'language'), ('language', 'processing'), ('processing', 'robotics'), ('robotics', '.')]

>> Trigrams are: 
 [('natural', 'language', 'processing'), ('language', 'processing', 'robotics'), ('processing', 'robotics', '.')]

>> POS Tags are: 
 [('natural', 'JJ'), ('language', 'NN'), ('processing', 'NN'), ('robotics', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['natural language processing robotics']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('natural', 'natur'), ('language', 'languag'), ('processing', 'process'), ('robotics', 'robot'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('natural', 'natur'), ('language', 'languag'), ('processing', 'process'), ('robotics', 'robot'), ('.', '.')]

>> Lemmatization: 
 [('natural', 'natural'), ('language', 'language'), ('processing', 'processing'), ('robotics', 'robotics'), ('.', '.')]


------------------- Sentence 2 -------------------

We believe that the

>> Tokens are: 
 ['We', 'believe']

>> Bigrams are: 
 [('We', 'believe')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('We', 'PRP'), ('believe', 'VBP')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('We', 'we'), ('believe', 'believ')]

>> Stemming using Snowball Stemmer: 
 [('We', 'we'), ('believe', 'believ')]

>> Lemmatization: 
 [('We', 'We'), ('believe', 'believe')]



========================================== PARAGRAPH 588 ===========================================

challenges posed by big data will bring ample opportunities for ML  

------------------- Sentence 1 -------------------

challenges posed by big data will bring ample opportunities for ML

>> Tokens are: 
 ['challenges', 'posed', 'big', 'data', 'bring', 'ample', 'opportunities', 'ML']

>> Bigrams are: 
 [('challenges', 'posed'), ('posed', 'big'), ('big', 'data'), ('data', 'bring'), ('bring', 'ample'), ('ample', 'opportunities'), ('opportunities', 'ML')]

>> Trigrams are: 
 [('challenges', 'posed', 'big'), ('posed', 'big', 'data'), ('big', 'data', 'bring'), ('data', 'bring', 'ample'), ('bring', 'ample', 'opportunities'), ('ample', 'opportunities', 'ML')]

>> POS Tags are: 
 [('challenges', 'NNS'), ('posed', 'VBD'), ('big', 'JJ'), ('data', 'NNS'), ('bring', 'VBP'), ('ample', 'JJ'), ('opportunities', 'NNS'), ('ML', 'NNP')]

>> Noun Phrases are: 
 ['challenges', 'big data', 'ample opportunities ML']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('challenges', 'challeng'), ('posed', 'pose'), ('big', 'big'), ('data', 'data'), ('bring', 'bring'), ('ample', 'ampl'), ('opportunities', 'opportun'), ('ML', 'ml')]

>> Stemming using Snowball Stemmer: 
 [('challenges', 'challeng'), ('posed', 'pose'), ('big', 'big'), ('data', 'data'), ('bring', 'bring'), ('ample', 'ampl'), ('opportunities', 'opportun'), ('ML', 'ml')]

>> Lemmatization: 
 [('challenges', 'challenge'), ('posed', 'posed'), ('big', 'big'), ('data', 'data'), ('bring', 'bring'), ('ample', 'ample'), ('opportunities', 'opportunity'), ('ML', 'ML')]



========================================== PARAGRAPH 589 ===========================================

algorithms and especially to deep learning methods.   

------------------- Sentence 1 -------------------

algorithms and especially to deep learning methods.

>> Tokens are: 
 ['algorithms', 'especially', 'deep', 'learning', 'methods', '.']

>> Bigrams are: 
 [('algorithms', 'especially'), ('especially', 'deep'), ('deep', 'learning'), ('learning', 'methods'), ('methods', '.')]

>> Trigrams are: 
 [('algorithms', 'especially', 'deep'), ('especially', 'deep', 'learning'), ('deep', 'learning', 'methods'), ('learning', 'methods', '.')]

>> POS Tags are: 
 [('algorithms', 'NN'), ('especially', 'RB'), ('deep', 'JJ'), ('learning', 'VBG'), ('methods', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['algorithms', 'methods']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('algorithms', 'algorithm'), ('especially', 'especi'), ('deep', 'deep'), ('learning', 'learn'), ('methods', 'method'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('algorithms', 'algorithm'), ('especially', 'especi'), ('deep', 'deep'), ('learning', 'learn'), ('methods', 'method'), ('.', '.')]

>> Lemmatization: 
 [('algorithms', 'algorithm'), ('especially', 'especially'), ('deep', 'deep'), ('learning', 'learning'), ('methods', 'method'), ('.', '.')]



========================================== PARAGRAPH 590 ===========================================

ACKNOWLEDGEMENT  

------------------- Sentence 1 -------------------

ACKNOWLEDGEMENT

>> Tokens are: 
 ['ACKNOWLEDGEMENT']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('ACKNOWLEDGEMENT', 'NN')]

>> Noun Phrases are: 
 ['ACKNOWLEDGEMENT']

>> Named Entities are: 
 [('ORGANIZATION', 'ACKNOWLEDGEMENT')] 

>> Stemming using Porter Stemmer: 
 [('ACKNOWLEDGEMENT', 'acknowledg')]

>> Stemming using Snowball Stemmer: 
 [('ACKNOWLEDGEMENT', 'acknowledg')]

>> Lemmatization: 
 [('ACKNOWLEDGEMENT', 'ACKNOWLEDGEMENT')]



========================================== PARAGRAPH 591 ===========================================

I would like to express my gratitude to my teacher, Dr. Wang  

------------------- Sentence 1 -------------------

I would like to express my gratitude to my teacher, Dr. Wang

>> Tokens are: 
 ['I', 'would', 'like', 'express', 'gratitude', 'teacher', ',', 'Dr.', 'Wang']

>> Bigrams are: 
 [('I', 'would'), ('would', 'like'), ('like', 'express'), ('express', 'gratitude'), ('gratitude', 'teacher'), ('teacher', ','), (',', 'Dr.'), ('Dr.', 'Wang')]

>> Trigrams are: 
 [('I', 'would', 'like'), ('would', 'like', 'express'), ('like', 'express', 'gratitude'), ('express', 'gratitude', 'teacher'), ('gratitude', 'teacher', ','), ('teacher', ',', 'Dr.'), (',', 'Dr.', 'Wang')]

>> POS Tags are: 
 [('I', 'PRP'), ('would', 'MD'), ('like', 'VB'), ('express', 'JJ'), ('gratitude', 'NN'), ('teacher', 'NN'), (',', ','), ('Dr.', 'NNP'), ('Wang', 'NNP')]

>> Noun Phrases are: 
 ['express gratitude teacher', 'Dr. Wang']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('I', 'i'), ('would', 'would'), ('like', 'like'), ('express', 'express'), ('gratitude', 'gratitud'), ('teacher', 'teacher'), (',', ','), ('Dr.', 'dr.'), ('Wang', 'wang')]

>> Stemming using Snowball Stemmer: 
 [('I', 'i'), ('would', 'would'), ('like', 'like'), ('express', 'express'), ('gratitude', 'gratitud'), ('teacher', 'teacher'), (',', ','), ('Dr.', 'dr.'), ('Wang', 'wang')]

>> Lemmatization: 
 [('I', 'I'), ('would', 'would'), ('like', 'like'), ('express', 'express'), ('gratitude', 'gratitude'), ('teacher', 'teacher'), (',', ','), ('Dr.', 'Dr.'), ('Wang', 'Wang')]



========================================== PARAGRAPH 592 ===========================================

Hongjun, whose expertise and guidance added considerably to  

------------------- Sentence 1 -------------------

Hongjun, whose expertise and guidance added considerably to

>> Tokens are: 
 ['Hongjun', ',', 'whose', 'expertise', 'guidance', 'added', 'considerably']

>> Bigrams are: 
 [('Hongjun', ','), (',', 'whose'), ('whose', 'expertise'), ('expertise', 'guidance'), ('guidance', 'added'), ('added', 'considerably')]

>> Trigrams are: 
 [('Hongjun', ',', 'whose'), (',', 'whose', 'expertise'), ('whose', 'expertise', 'guidance'), ('expertise', 'guidance', 'added'), ('guidance', 'added', 'considerably')]

>> POS Tags are: 
 [('Hongjun', 'NNP'), (',', ','), ('whose', 'WP$'), ('expertise', 'NN'), ('guidance', 'NN'), ('added', 'VBD'), ('considerably', 'RB')]

>> Noun Phrases are: 
 ['Hongjun', 'expertise guidance']

>> Named Entities are: 
 [('GPE', 'Hongjun')] 

>> Stemming using Porter Stemmer: 
 [('Hongjun', 'hongjun'), (',', ','), ('whose', 'whose'), ('expertise', 'expertis'), ('guidance', 'guidanc'), ('added', 'ad'), ('considerably', 'consider')]

>> Stemming using Snowball Stemmer: 
 [('Hongjun', 'hongjun'), (',', ','), ('whose', 'whose'), ('expertise', 'expertis'), ('guidance', 'guidanc'), ('added', 'ad'), ('considerably', 'consider')]

>> Lemmatization: 
 [('Hongjun', 'Hongjun'), (',', ','), ('whose', 'whose'), ('expertise', 'expertise'), ('guidance', 'guidance'), ('added', 'added'), ('considerably', 'considerably')]



========================================== PARAGRAPH 593 ===========================================

my graduate experience. I appreciate his vast knowledge and his  

------------------- Sentence 1 -------------------

my graduate experience.

>> Tokens are: 
 ['graduate', 'experience', '.']

>> Bigrams are: 
 [('graduate', 'experience'), ('experience', '.')]

>> Trigrams are: 
 [('graduate', 'experience', '.')]

>> POS Tags are: 
 [('graduate', 'NN'), ('experience', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['graduate experience']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('graduate', 'graduat'), ('experience', 'experi'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('graduate', 'graduat'), ('experience', 'experi'), ('.', '.')]

>> Lemmatization: 
 [('graduate', 'graduate'), ('experience', 'experience'), ('.', '.')]


------------------- Sentence 2 -------------------

I appreciate his vast knowledge and his

>> Tokens are: 
 ['I', 'appreciate', 'vast', 'knowledge']

>> Bigrams are: 
 [('I', 'appreciate'), ('appreciate', 'vast'), ('vast', 'knowledge')]

>> Trigrams are: 
 [('I', 'appreciate', 'vast'), ('appreciate', 'vast', 'knowledge')]

>> POS Tags are: 
 [('I', 'PRP'), ('appreciate', 'VBP'), ('vast', 'JJ'), ('knowledge', 'NN')]

>> Noun Phrases are: 
 ['vast knowledge']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('I', 'i'), ('appreciate', 'appreci'), ('vast', 'vast'), ('knowledge', 'knowledg')]

>> Stemming using Snowball Stemmer: 
 [('I', 'i'), ('appreciate', 'appreci'), ('vast', 'vast'), ('knowledge', 'knowledg')]

>> Lemmatization: 
 [('I', 'I'), ('appreciate', 'appreciate'), ('vast', 'vast'), ('knowledge', 'knowledge')]



========================================== PARAGRAPH 594 ===========================================

consistent assistance in completing this work. I would also like  

------------------- Sentence 1 -------------------

consistent assistance in completing this work.

>> Tokens are: 
 ['consistent', 'assistance', 'completing', 'work', '.']

>> Bigrams are: 
 [('consistent', 'assistance'), ('assistance', 'completing'), ('completing', 'work'), ('work', '.')]

>> Trigrams are: 
 [('consistent', 'assistance', 'completing'), ('assistance', 'completing', 'work'), ('completing', 'work', '.')]

>> POS Tags are: 
 [('consistent', 'JJ'), ('assistance', 'NN'), ('completing', 'VBG'), ('work', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['consistent assistance', 'work']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('consistent', 'consist'), ('assistance', 'assist'), ('completing', 'complet'), ('work', 'work'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('consistent', 'consist'), ('assistance', 'assist'), ('completing', 'complet'), ('work', 'work'), ('.', '.')]

>> Lemmatization: 
 [('consistent', 'consistent'), ('assistance', 'assistance'), ('completing', 'completing'), ('work', 'work'), ('.', '.')]


------------------- Sentence 2 -------------------

I would also like

>> Tokens are: 
 ['I', 'would', 'also', 'like']

>> Bigrams are: 
 [('I', 'would'), ('would', 'also'), ('also', 'like')]

>> Trigrams are: 
 [('I', 'would', 'also'), ('would', 'also', 'like')]

>> POS Tags are: 
 [('I', 'PRP'), ('would', 'MD'), ('also', 'RB'), ('like', 'VB')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('I', 'i'), ('would', 'would'), ('also', 'also'), ('like', 'like')]

>> Stemming using Snowball Stemmer: 
 [('I', 'i'), ('would', 'would'), ('also', 'also'), ('like', 'like')]

>> Lemmatization: 
 [('I', 'I'), ('would', 'would'), ('also', 'also'), ('like', 'like')]



========================================== PARAGRAPH 595 ===========================================

to thank the other PhD Scholars of my school, Mr. Amjad  

------------------- Sentence 1 -------------------

to thank the other PhD Scholars of my school, Mr. Amjad

>> Tokens are: 
 ['thank', 'PhD', 'Scholars', 'school', ',', 'Mr.', 'Amjad']

>> Bigrams are: 
 [('thank', 'PhD'), ('PhD', 'Scholars'), ('Scholars', 'school'), ('school', ','), (',', 'Mr.'), ('Mr.', 'Amjad')]

>> Trigrams are: 
 [('thank', 'PhD', 'Scholars'), ('PhD', 'Scholars', 'school'), ('Scholars', 'school', ','), ('school', ',', 'Mr.'), (',', 'Mr.', 'Amjad')]

>> POS Tags are: 
 [('thank', 'NN'), ('PhD', 'NNP'), ('Scholars', 'NNP'), ('school', 'NN'), (',', ','), ('Mr.', 'NNP'), ('Amjad', 'NNP')]

>> Noun Phrases are: 
 ['thank PhD Scholars school', 'Mr. Amjad']

>> Named Entities are: 
 [('ORGANIZATION', 'PhD Scholars'), ('PERSON', 'Mr. Amjad')] 

>> Stemming using Porter Stemmer: 
 [('thank', 'thank'), ('PhD', 'phd'), ('Scholars', 'scholar'), ('school', 'school'), (',', ','), ('Mr.', 'mr.'), ('Amjad', 'amjad')]

>> Stemming using Snowball Stemmer: 
 [('thank', 'thank'), ('PhD', 'phd'), ('Scholars', 'scholar'), ('school', 'school'), (',', ','), ('Mr.', 'mr.'), ('Amjad', 'amjad')]

>> Lemmatization: 
 [('thank', 'thank'), ('PhD', 'PhD'), ('Scholars', 'Scholars'), ('school', 'school'), (',', ','), ('Mr.', 'Mr.'), ('Amjad', 'Amjad')]



========================================== PARAGRAPH 596 ===========================================

Ahmed, and Mr. Mehtab Afzal for the assistance they provided  

------------------- Sentence 1 -------------------

Ahmed, and Mr. Mehtab Afzal for the assistance they provided

>> Tokens are: 
 ['Ahmed', ',', 'Mr.', 'Mehtab', 'Afzal', 'assistance', 'provided']

>> Bigrams are: 
 [('Ahmed', ','), (',', 'Mr.'), ('Mr.', 'Mehtab'), ('Mehtab', 'Afzal'), ('Afzal', 'assistance'), ('assistance', 'provided')]

>> Trigrams are: 
 [('Ahmed', ',', 'Mr.'), (',', 'Mr.', 'Mehtab'), ('Mr.', 'Mehtab', 'Afzal'), ('Mehtab', 'Afzal', 'assistance'), ('Afzal', 'assistance', 'provided')]

>> POS Tags are: 
 [('Ahmed', 'NNP'), (',', ','), ('Mr.', 'NNP'), ('Mehtab', 'NNP'), ('Afzal', 'NNP'), ('assistance', 'NN'), ('provided', 'VBD')]

>> Noun Phrases are: 
 ['Ahmed', 'Mr. Mehtab Afzal assistance']

>> Named Entities are: 
 [('GPE', 'Ahmed'), ('PERSON', 'Mr. Mehtab Afzal')] 

>> Stemming using Porter Stemmer: 
 [('Ahmed', 'ahm'), (',', ','), ('Mr.', 'mr.'), ('Mehtab', 'mehtab'), ('Afzal', 'afzal'), ('assistance', 'assist'), ('provided', 'provid')]

>> Stemming using Snowball Stemmer: 
 [('Ahmed', 'ahm'), (',', ','), ('Mr.', 'mr.'), ('Mehtab', 'mehtab'), ('Afzal', 'afzal'), ('assistance', 'assist'), ('provided', 'provid')]

>> Lemmatization: 
 [('Ahmed', 'Ahmed'), (',', ','), ('Mr.', 'Mr.'), ('Mehtab', 'Mehtab'), ('Afzal', 'Afzal'), ('assistance', 'assistance'), ('provided', 'provided')]



========================================== PARAGRAPH 597 ===========================================

to understand machine learning. Very special thanks goes to Dr.  

------------------- Sentence 1 -------------------

to understand machine learning.

>> Tokens are: 
 ['understand', 'machine', 'learning', '.']

>> Bigrams are: 
 [('understand', 'machine'), ('machine', 'learning'), ('learning', '.')]

>> Trigrams are: 
 [('understand', 'machine', 'learning'), ('machine', 'learning', '.')]

>> POS Tags are: 
 [('understand', 'JJ'), ('machine', 'NN'), ('learning', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['understand machine learning']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('understand', 'understand'), ('machine', 'machin'), ('learning', 'learn'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('understand', 'understand'), ('machine', 'machin'), ('learning', 'learn'), ('.', '.')]

>> Lemmatization: 
 [('understand', 'understand'), ('machine', 'machine'), ('learning', 'learning'), ('.', '.')]


------------------- Sentence 2 -------------------

Very special thanks goes to Dr.

>> Tokens are: 
 ['Very', 'special', 'thanks', 'goes', 'Dr', '.']

>> Bigrams are: 
 [('Very', 'special'), ('special', 'thanks'), ('thanks', 'goes'), ('goes', 'Dr'), ('Dr', '.')]

>> Trigrams are: 
 [('Very', 'special', 'thanks'), ('special', 'thanks', 'goes'), ('thanks', 'goes', 'Dr'), ('goes', 'Dr', '.')]

>> POS Tags are: 
 [('Very', 'RB'), ('special', 'JJ'), ('thanks', 'NNS'), ('goes', 'VBZ'), ('Dr', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['special thanks', 'Dr']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Very', 'veri'), ('special', 'special'), ('thanks', 'thank'), ('goes', 'goe'), ('Dr', 'dr'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Very', 'veri'), ('special', 'special'), ('thanks', 'thank'), ('goes', 'goe'), ('Dr', 'dr'), ('.', '.')]

>> Lemmatization: 
 [('Very', 'Very'), ('special', 'special'), ('thanks', 'thanks'), ('goes', 'go'), ('Dr', 'Dr'), ('.', '.')]



========================================== PARAGRAPH 598 ===========================================

Zhu Yan, without whose motivation and encouragement, I  

------------------- Sentence 1 -------------------

Zhu Yan, without whose motivation and encouragement, I

>> Tokens are: 
 ['Zhu', 'Yan', ',', 'without', 'whose', 'motivation', 'encouragement', ',', 'I']

>> Bigrams are: 
 [('Zhu', 'Yan'), ('Yan', ','), (',', 'without'), ('without', 'whose'), ('whose', 'motivation'), ('motivation', 'encouragement'), ('encouragement', ','), (',', 'I')]

>> Trigrams are: 
 [('Zhu', 'Yan', ','), ('Yan', ',', 'without'), (',', 'without', 'whose'), ('without', 'whose', 'motivation'), ('whose', 'motivation', 'encouragement'), ('motivation', 'encouragement', ','), ('encouragement', ',', 'I')]

>> POS Tags are: 
 [('Zhu', 'NNP'), ('Yan', 'NNP'), (',', ','), ('without', 'IN'), ('whose', 'WP$'), ('motivation', 'NN'), ('encouragement', 'NN'), (',', ','), ('I', 'PRP')]

>> Noun Phrases are: 
 ['Zhu Yan', 'motivation encouragement']

>> Named Entities are: 
 [('PERSON', 'Zhu'), ('ORGANIZATION', 'Yan')] 

>> Stemming using Porter Stemmer: 
 [('Zhu', 'zhu'), ('Yan', 'yan'), (',', ','), ('without', 'without'), ('whose', 'whose'), ('motivation', 'motiv'), ('encouragement', 'encourag'), (',', ','), ('I', 'i')]

>> Stemming using Snowball Stemmer: 
 [('Zhu', 'zhu'), ('Yan', 'yan'), (',', ','), ('without', 'without'), ('whose', 'whose'), ('motivation', 'motiv'), ('encouragement', 'encourag'), (',', ','), ('I', 'i')]

>> Lemmatization: 
 [('Zhu', 'Zhu'), ('Yan', 'Yan'), (',', ','), ('without', 'without'), ('whose', 'whose'), ('motivation', 'motivation'), ('encouragement', 'encouragement'), (',', ','), ('I', 'I')]



========================================== PARAGRAPH 599 ===========================================

confess that it would be difficult for me to move forward in my  

------------------- Sentence 1 -------------------

confess that it would be difficult for me to move forward in my

>> Tokens are: 
 ['confess', 'would', 'difficult', 'move', 'forward']

>> Bigrams are: 
 [('confess', 'would'), ('would', 'difficult'), ('difficult', 'move'), ('move', 'forward')]

>> Trigrams are: 
 [('confess', 'would', 'difficult'), ('would', 'difficult', 'move'), ('difficult', 'move', 'forward')]

>> POS Tags are: 
 [('confess', 'NN'), ('would', 'MD'), ('difficult', 'JJ'), ('move', 'VB'), ('forward', 'RB')]

>> Noun Phrases are: 
 ['confess']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('confess', 'confess'), ('would', 'would'), ('difficult', 'difficult'), ('move', 'move'), ('forward', 'forward')]

>> Stemming using Snowball Stemmer: 
 [('confess', 'confess'), ('would', 'would'), ('difficult', 'difficult'), ('move', 'move'), ('forward', 'forward')]

>> Lemmatization: 
 [('confess', 'confess'), ('would', 'would'), ('difficult', 'difficult'), ('move', 'move'), ('forward', 'forward')]



========================================== PARAGRAPH 600 ===========================================

PhD Program.  

------------------- Sentence 1 -------------------

PhD Program.

>> Tokens are: 
 ['PhD', 'Program', '.']

>> Bigrams are: 
 [('PhD', 'Program'), ('Program', '.')]

>> Trigrams are: 
 [('PhD', 'Program', '.')]

>> POS Tags are: 
 [('PhD', 'NNP'), ('Program', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['PhD Program']

>> Named Entities are: 
 [('ORGANIZATION', 'PhD Program')] 

>> Stemming using Porter Stemmer: 
 [('PhD', 'phd'), ('Program', 'program'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('PhD', 'phd'), ('Program', 'program'), ('.', '.')]

>> Lemmatization: 
 [('PhD', 'PhD'), ('Program', 'Program'), ('.', '.')]



========================================== PARAGRAPH 601 ===========================================

REFERENCES  

------------------- Sentence 1 -------------------

REFERENCES

>> Tokens are: 
 ['REFERENCES']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('REFERENCES', 'NNS')]

>> Noun Phrases are: 
 ['REFERENCES']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('REFERENCES', 'refer')]

>> Stemming using Snowball Stemmer: 
 [('REFERENCES', 'refer')]

>> Lemmatization: 
 [('REFERENCES', 'REFERENCES')]



========================================== PARAGRAPH 602 ===========================================

[1] S. B. Kotsiantis, Supervised Machine Learning: A Review  of Classification Techniques, Informatica, Vol. 31, No. 3,  

------------------- Sentence 1 -------------------

[1] S. B. Kotsiantis, Supervised Machine Learning: A Review  of Classification Techniques, Informatica, Vol.

>> Tokens are: 
 ['[', '1', ']', 'S.', 'B.', 'Kotsiantis', ',', '', 'Supervised', 'Machine', 'Learning', ':', 'A', 'Review', 'Classification', 'Techniques', '', ',', 'Informatica', ',', 'Vol', '.']

>> Bigrams are: 
 [('[', '1'), ('1', ']'), (']', 'S.'), ('S.', 'B.'), ('B.', 'Kotsiantis'), ('Kotsiantis', ','), (',', ''), ('', 'Supervised'), ('Supervised', 'Machine'), ('Machine', 'Learning'), ('Learning', ':'), (':', 'A'), ('A', 'Review'), ('Review', 'Classification'), ('Classification', 'Techniques'), ('Techniques', ''), ('', ','), (',', 'Informatica'), ('Informatica', ','), (',', 'Vol'), ('Vol', '.')]

>> Trigrams are: 
 [('[', '1', ']'), ('1', ']', 'S.'), (']', 'S.', 'B.'), ('S.', 'B.', 'Kotsiantis'), ('B.', 'Kotsiantis', ','), ('Kotsiantis', ',', ''), (',', '', 'Supervised'), ('', 'Supervised', 'Machine'), ('Supervised', 'Machine', 'Learning'), ('Machine', 'Learning', ':'), ('Learning', ':', 'A'), (':', 'A', 'Review'), ('A', 'Review', 'Classification'), ('Review', 'Classification', 'Techniques'), ('Classification', 'Techniques', ''), ('Techniques', '', ','), ('', ',', 'Informatica'), (',', 'Informatica', ','), ('Informatica', ',', 'Vol'), (',', 'Vol', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('1', 'CD'), (']', 'NNP'), ('S.', 'NNP'), ('B.', 'NNP'), ('Kotsiantis', 'NNP'), (',', ','), ('', 'NNP'), ('Supervised', 'VBD'), ('Machine', 'NNP'), ('Learning', 'NNP'), (':', ':'), ('A', 'DT'), ('Review', 'NNP'), ('Classification', 'NNP'), ('Techniques', 'NNP'), ('', 'NNP'), (',', ','), ('Informatica', 'NNP'), (',', ','), ('Vol', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['] S. B. Kotsiantis', '', 'Machine Learning', 'A Review Classification Techniques ', 'Informatica', 'Vol']

>> Named Entities are: 
 [('PERSON', 'Machine Learning'), ('ORGANIZATION', 'Review Classification Techniques'), ('GPE', 'Informatica'), ('PERSON', 'Vol')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('1', '1'), (']', ']'), ('S.', 's.'), ('B.', 'b.'), ('Kotsiantis', 'kotsianti'), (',', ','), ('', ''), ('Supervised', 'supervis'), ('Machine', 'machin'), ('Learning', 'learn'), (':', ':'), ('A', 'a'), ('Review', 'review'), ('Classification', 'classif'), ('Techniques', 'techniqu'), ('', ''), (',', ','), ('Informatica', 'informatica'), (',', ','), ('Vol', 'vol'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('1', '1'), (']', ']'), ('S.', 's.'), ('B.', 'b.'), ('Kotsiantis', 'kotsianti'), (',', ','), ('', ''), ('Supervised', 'supervis'), ('Machine', 'machin'), ('Learning', 'learn'), (':', ':'), ('A', 'a'), ('Review', 'review'), ('Classification', 'classif'), ('Techniques', 'techniqu'), ('', ''), (',', ','), ('Informatica', 'informatica'), (',', ','), ('Vol', 'vol'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('1', '1'), (']', ']'), ('S.', 'S.'), ('B.', 'B.'), ('Kotsiantis', 'Kotsiantis'), (',', ','), ('', ''), ('Supervised', 'Supervised'), ('Machine', 'Machine'), ('Learning', 'Learning'), (':', ':'), ('A', 'A'), ('Review', 'Review'), ('Classification', 'Classification'), ('Techniques', 'Techniques'), ('', ''), (',', ','), ('Informatica', 'Informatica'), (',', ','), ('Vol', 'Vol'), ('.', '.')]


------------------- Sentence 2 -------------------

31, No.

>> Tokens are: 
 ['31', ',', 'No', '.']

>> Bigrams are: 
 [('31', ','), (',', 'No'), ('No', '.')]

>> Trigrams are: 
 [('31', ',', 'No'), (',', 'No', '.')]

>> POS Tags are: 
 [('31', 'CD'), (',', ','), ('No', 'DT'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('31', '31'), (',', ','), ('No', 'no'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('31', '31'), (',', ','), ('No', 'no'), ('.', '.')]

>> Lemmatization: 
 [('31', '31'), (',', ','), ('No', 'No'), ('.', '.')]


------------------- Sentence 3 -------------------

3,

>> Tokens are: 
 ['3', ',']

>> Bigrams are: 
 [('3', ',')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('3', 'CD'), (',', ',')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('3', '3'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('3', '3'), (',', ',')]

>> Lemmatization: 
 [('3', '3'), (',', ',')]



========================================== PARAGRAPH 603 ===========================================

pp. 249-268, 2007. 

------------------- Sentence 1 -------------------

pp.

>> Tokens are: 
 ['pp', '.']

>> Bigrams are: 
 [('pp', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('pp', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['pp']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('pp', 'pp'), ('.', '.')]


------------------- Sentence 2 -------------------

249-268, 2007.

>> Tokens are: 
 ['249-268', ',', '2007', '.']

>> Bigrams are: 
 [('249-268', ','), (',', '2007'), ('2007', '.')]

>> Trigrams are: 
 [('249-268', ',', '2007'), (',', '2007', '.')]

>> POS Tags are: 
 [('249-268', 'CD'), (',', ','), ('2007', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('249-268', '249-268'), (',', ','), ('2007', '2007'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('249-268', '249-268'), (',', ','), ('2007', '2007'), ('.', '.')]

>> Lemmatization: 
 [('249-268', '249-268'), (',', ','), ('2007', '2007'), ('.', '.')]



========================================== PARAGRAPH 604 ===========================================

IQBAL MUHAMMAD AND ZHU YAN: SUPERVISED MACHINE LEARNING APPROACHES: A SURVEY  

------------------- Sentence 1 -------------------

IQBAL MUHAMMAD AND ZHU YAN: SUPERVISED MACHINE LEARNING APPROACHES: A SURVEY

>> Tokens are: 
 ['IQBAL', 'MUHAMMAD', 'AND', 'ZHU', 'YAN', ':', 'SUPERVISED', 'MACHINE', 'LEARNING', 'APPROACHES', ':', 'A', 'SURVEY']

>> Bigrams are: 
 [('IQBAL', 'MUHAMMAD'), ('MUHAMMAD', 'AND'), ('AND', 'ZHU'), ('ZHU', 'YAN'), ('YAN', ':'), (':', 'SUPERVISED'), ('SUPERVISED', 'MACHINE'), ('MACHINE', 'LEARNING'), ('LEARNING', 'APPROACHES'), ('APPROACHES', ':'), (':', 'A'), ('A', 'SURVEY')]

>> Trigrams are: 
 [('IQBAL', 'MUHAMMAD', 'AND'), ('MUHAMMAD', 'AND', 'ZHU'), ('AND', 'ZHU', 'YAN'), ('ZHU', 'YAN', ':'), ('YAN', ':', 'SUPERVISED'), (':', 'SUPERVISED', 'MACHINE'), ('SUPERVISED', 'MACHINE', 'LEARNING'), ('MACHINE', 'LEARNING', 'APPROACHES'), ('LEARNING', 'APPROACHES', ':'), ('APPROACHES', ':', 'A'), (':', 'A', 'SURVEY')]

>> POS Tags are: 
 [('IQBAL', 'NNP'), ('MUHAMMAD', 'NNP'), ('AND', 'NNP'), ('ZHU', 'NNP'), ('YAN', 'NNP'), (':', ':'), ('SUPERVISED', 'NNP'), ('MACHINE', 'NNP'), ('LEARNING', 'NNP'), ('APPROACHES', 'NNP'), (':', ':'), ('A', 'DT'), ('SURVEY', 'NN')]

>> Noun Phrases are: 
 ['IQBAL MUHAMMAD AND ZHU YAN', 'SUPERVISED MACHINE LEARNING APPROACHES', 'A SURVEY']

>> Named Entities are: 
 [('ORGANIZATION', 'IQBAL'), ('ORGANIZATION', 'MUHAMMAD'), ('ORGANIZATION', 'SUPERVISED'), ('ORGANIZATION', 'MACHINE')] 

>> Stemming using Porter Stemmer: 
 [('IQBAL', 'iqbal'), ('MUHAMMAD', 'muhammad'), ('AND', 'and'), ('ZHU', 'zhu'), ('YAN', 'yan'), (':', ':'), ('SUPERVISED', 'supervis'), ('MACHINE', 'machin'), ('LEARNING', 'learn'), ('APPROACHES', 'approach'), (':', ':'), ('A', 'a'), ('SURVEY', 'survey')]

>> Stemming using Snowball Stemmer: 
 [('IQBAL', 'iqbal'), ('MUHAMMAD', 'muhammad'), ('AND', 'and'), ('ZHU', 'zhu'), ('YAN', 'yan'), (':', ':'), ('SUPERVISED', 'supervis'), ('MACHINE', 'machin'), ('LEARNING', 'learn'), ('APPROACHES', 'approach'), (':', ':'), ('A', 'a'), ('SURVEY', 'survey')]

>> Lemmatization: 
 [('IQBAL', 'IQBAL'), ('MUHAMMAD', 'MUHAMMAD'), ('AND', 'AND'), ('ZHU', 'ZHU'), ('YAN', 'YAN'), (':', ':'), ('SUPERVISED', 'SUPERVISED'), ('MACHINE', 'MACHINE'), ('LEARNING', 'LEARNING'), ('APPROACHES', 'APPROACHES'), (':', ':'), ('A', 'A'), ('SURVEY', 'SURVEY')]



========================================== PARAGRAPH 605 ===========================================

952  

------------------- Sentence 1 -------------------

952

>> Tokens are: 
 ['952']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('952', 'CD')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('952', '952')]

>> Stemming using Snowball Stemmer: 
 [('952', '952')]

>> Lemmatization: 
 [('952', '952')]



========================================== PARAGRAPH 606 ===========================================

[2] James Cussens, Machine Learning, IEEE Journal of  Computing and Control, Vol. 7, No. 4, pp 164-168, 1996.  

------------------- Sentence 1 -------------------

[2] James Cussens, Machine Learning, IEEE Journal of  Computing and Control, Vol.

>> Tokens are: 
 ['[', '2', ']', 'James', 'Cussens', ',', '', 'Machine', 'Learning', '', ',', 'IEEE', 'Journal', 'Computing', 'Control', ',', 'Vol', '.']

>> Bigrams are: 
 [('[', '2'), ('2', ']'), (']', 'James'), ('James', 'Cussens'), ('Cussens', ','), (',', ''), ('', 'Machine'), ('Machine', 'Learning'), ('Learning', ''), ('', ','), (',', 'IEEE'), ('IEEE', 'Journal'), ('Journal', 'Computing'), ('Computing', 'Control'), ('Control', ','), (',', 'Vol'), ('Vol', '.')]

>> Trigrams are: 
 [('[', '2', ']'), ('2', ']', 'James'), (']', 'James', 'Cussens'), ('James', 'Cussens', ','), ('Cussens', ',', ''), (',', '', 'Machine'), ('', 'Machine', 'Learning'), ('Machine', 'Learning', ''), ('Learning', '', ','), ('', ',', 'IEEE'), (',', 'IEEE', 'Journal'), ('IEEE', 'Journal', 'Computing'), ('Journal', 'Computing', 'Control'), ('Computing', 'Control', ','), ('Control', ',', 'Vol'), (',', 'Vol', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('2', 'CD'), (']', 'JJ'), ('James', 'NNP'), ('Cussens', 'NNP'), (',', ','), ('', 'NNP'), ('Machine', 'NNP'), ('Learning', 'NNP'), ('', 'NNP'), (',', ','), ('IEEE', 'NNP'), ('Journal', 'NNP'), ('Computing', 'NNP'), ('Control', 'NNP'), (',', ','), ('Vol', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['] James Cussens', ' Machine Learning ', 'IEEE Journal Computing Control', 'Vol']

>> Named Entities are: 
 [('PERSON', 'James Cussens'), ('PERSON', 'Machine Learning'), ('ORGANIZATION', 'IEEE Journal'), ('PERSON', 'Vol')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('2', '2'), (']', ']'), ('James', 'jame'), ('Cussens', 'cussen'), (',', ','), ('', ''), ('Machine', 'machin'), ('Learning', 'learn'), ('', ''), (',', ','), ('IEEE', 'ieee'), ('Journal', 'journal'), ('Computing', 'comput'), ('Control', 'control'), (',', ','), ('Vol', 'vol'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('2', '2'), (']', ']'), ('James', 'jame'), ('Cussens', 'cussen'), (',', ','), ('', ''), ('Machine', 'machin'), ('Learning', 'learn'), ('', ''), (',', ','), ('IEEE', 'ieee'), ('Journal', 'journal'), ('Computing', 'comput'), ('Control', 'control'), (',', ','), ('Vol', 'vol'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('2', '2'), (']', ']'), ('James', 'James'), ('Cussens', 'Cussens'), (',', ','), ('', ''), ('Machine', 'Machine'), ('Learning', 'Learning'), ('', ''), (',', ','), ('IEEE', 'IEEE'), ('Journal', 'Journal'), ('Computing', 'Computing'), ('Control', 'Control'), (',', ','), ('Vol', 'Vol'), ('.', '.')]


------------------- Sentence 2 -------------------

7, No.

>> Tokens are: 
 ['7', ',', 'No', '.']

>> Bigrams are: 
 [('7', ','), (',', 'No'), ('No', '.')]

>> Trigrams are: 
 [('7', ',', 'No'), (',', 'No', '.')]

>> POS Tags are: 
 [('7', 'CD'), (',', ','), ('No', 'DT'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('7', '7'), (',', ','), ('No', 'no'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('7', '7'), (',', ','), ('No', 'no'), ('.', '.')]

>> Lemmatization: 
 [('7', '7'), (',', ','), ('No', 'No'), ('.', '.')]


------------------- Sentence 3 -------------------

4, pp 164-168, 1996.

>> Tokens are: 
 ['4', ',', 'pp', '164-168', ',', '1996', '.']

>> Bigrams are: 
 [('4', ','), (',', 'pp'), ('pp', '164-168'), ('164-168', ','), (',', '1996'), ('1996', '.')]

>> Trigrams are: 
 [('4', ',', 'pp'), (',', 'pp', '164-168'), ('pp', '164-168', ','), ('164-168', ',', '1996'), (',', '1996', '.')]

>> POS Tags are: 
 [('4', 'CD'), (',', ','), ('pp', 'JJ'), ('164-168', 'CD'), (',', ','), ('1996', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('4', '4'), (',', ','), ('pp', 'pp'), ('164-168', '164-168'), (',', ','), ('1996', '1996'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('4', '4'), (',', ','), ('pp', 'pp'), ('164-168', '164-168'), (',', ','), ('1996', '1996'), ('.', '.')]

>> Lemmatization: 
 [('4', '4'), (',', ','), ('pp', 'pp'), ('164-168', '164-168'), (',', ','), ('1996', '1996'), ('.', '.')]



========================================== PARAGRAPH 607 ===========================================

[3] Richard S. Sutton and Andrew G. Barto, Reinforcement  Learning: An Introduction, Cambridge, MA: MIT Press, 1998.  

------------------- Sentence 1 -------------------

[3] Richard S. Sutton and Andrew G. Barto, Reinforcement  Learning: An Introduction, Cambridge, MA: MIT Press, 1998.

>> Tokens are: 
 ['[', '3', ']', 'Richard', 'S.', 'Sutton', 'Andrew', 'G.', 'Barto', ',', '', 'Reinforcement', 'Learning', ':', 'An', 'Introduction', '', ',', 'Cambridge', ',', 'MA', ':', 'MIT', 'Press', ',', '1998', '.']

>> Bigrams are: 
 [('[', '3'), ('3', ']'), (']', 'Richard'), ('Richard', 'S.'), ('S.', 'Sutton'), ('Sutton', 'Andrew'), ('Andrew', 'G.'), ('G.', 'Barto'), ('Barto', ','), (',', ''), ('', 'Reinforcement'), ('Reinforcement', 'Learning'), ('Learning', ':'), (':', 'An'), ('An', 'Introduction'), ('Introduction', ''), ('', ','), (',', 'Cambridge'), ('Cambridge', ','), (',', 'MA'), ('MA', ':'), (':', 'MIT'), ('MIT', 'Press'), ('Press', ','), (',', '1998'), ('1998', '.')]

>> Trigrams are: 
 [('[', '3', ']'), ('3', ']', 'Richard'), (']', 'Richard', 'S.'), ('Richard', 'S.', 'Sutton'), ('S.', 'Sutton', 'Andrew'), ('Sutton', 'Andrew', 'G.'), ('Andrew', 'G.', 'Barto'), ('G.', 'Barto', ','), ('Barto', ',', ''), (',', '', 'Reinforcement'), ('', 'Reinforcement', 'Learning'), ('Reinforcement', 'Learning', ':'), ('Learning', ':', 'An'), (':', 'An', 'Introduction'), ('An', 'Introduction', ''), ('Introduction', '', ','), ('', ',', 'Cambridge'), (',', 'Cambridge', ','), ('Cambridge', ',', 'MA'), (',', 'MA', ':'), ('MA', ':', 'MIT'), (':', 'MIT', 'Press'), ('MIT', 'Press', ','), ('Press', ',', '1998'), (',', '1998', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('3', 'CD'), (']', 'JJ'), ('Richard', 'NNP'), ('S.', 'NNP'), ('Sutton', 'NNP'), ('Andrew', 'NNP'), ('G.', 'NNP'), ('Barto', 'NNP'), (',', ','), ('', 'NNP'), ('Reinforcement', 'NNP'), ('Learning', 'NNP'), (':', ':'), ('An', 'DT'), ('Introduction', 'NNP'), ('', 'NN'), (',', ','), ('Cambridge', 'NNP'), (',', ','), ('MA', 'NNP'), (':', ':'), ('MIT', 'NNP'), ('Press', 'NNP'), (',', ','), ('1998', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['] Richard S. Sutton Andrew G. Barto', ' Reinforcement Learning', 'An Introduction ', 'Cambridge', 'MA', 'MIT Press']

>> Named Entities are: 
 [('PERSON', 'Richard S. Sutton'), ('PERSON', 'Andrew G. Barto'), ('GPE', 'Cambridge'), ('ORGANIZATION', 'MIT')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('3', '3'), (']', ']'), ('Richard', 'richard'), ('S.', 's.'), ('Sutton', 'sutton'), ('Andrew', 'andrew'), ('G.', 'g.'), ('Barto', 'barto'), (',', ','), ('', ''), ('Reinforcement', 'reinforc'), ('Learning', 'learn'), (':', ':'), ('An', 'an'), ('Introduction', 'introduct'), ('', ''), (',', ','), ('Cambridge', 'cambridg'), (',', ','), ('MA', 'ma'), (':', ':'), ('MIT', 'mit'), ('Press', 'press'), (',', ','), ('1998', '1998'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('3', '3'), (']', ']'), ('Richard', 'richard'), ('S.', 's.'), ('Sutton', 'sutton'), ('Andrew', 'andrew'), ('G.', 'g.'), ('Barto', 'barto'), (',', ','), ('', ''), ('Reinforcement', 'reinforc'), ('Learning', 'learn'), (':', ':'), ('An', 'an'), ('Introduction', 'introduct'), ('', ''), (',', ','), ('Cambridge', 'cambridg'), (',', ','), ('MA', 'ma'), (':', ':'), ('MIT', 'mit'), ('Press', 'press'), (',', ','), ('1998', '1998'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('3', '3'), (']', ']'), ('Richard', 'Richard'), ('S.', 'S.'), ('Sutton', 'Sutton'), ('Andrew', 'Andrew'), ('G.', 'G.'), ('Barto', 'Barto'), (',', ','), ('', ''), ('Reinforcement', 'Reinforcement'), ('Learning', 'Learning'), (':', ':'), ('An', 'An'), ('Introduction', 'Introduction'), ('', ''), (',', ','), ('Cambridge', 'Cambridge'), (',', ','), ('MA', 'MA'), (':', ':'), ('MIT', 'MIT'), ('Press', 'Press'), (',', ','), ('1998', '1998'), ('.', '.')]



========================================== PARAGRAPH 608 ===========================================

[4] Victoria J. Hodge and Jim Austin, A Survey of Outlier  Detection Methodologies, Artificial Intelligence Review,  

------------------- Sentence 1 -------------------

[4] Victoria J. Hodge and Jim Austin, A Survey of Outlier  Detection Methodologies, Artificial Intelligence Review,

>> Tokens are: 
 ['[', '4', ']', 'Victoria', 'J.', 'Hodge', 'Jim', 'Austin', ',', '', 'A', 'Survey', 'Outlier', 'Detection', 'Methodologies', '', ',', 'Artificial', 'Intelligence', 'Review', ',']

>> Bigrams are: 
 [('[', '4'), ('4', ']'), (']', 'Victoria'), ('Victoria', 'J.'), ('J.', 'Hodge'), ('Hodge', 'Jim'), ('Jim', 'Austin'), ('Austin', ','), (',', ''), ('', 'A'), ('A', 'Survey'), ('Survey', 'Outlier'), ('Outlier', 'Detection'), ('Detection', 'Methodologies'), ('Methodologies', ''), ('', ','), (',', 'Artificial'), ('Artificial', 'Intelligence'), ('Intelligence', 'Review'), ('Review', ',')]

>> Trigrams are: 
 [('[', '4', ']'), ('4', ']', 'Victoria'), (']', 'Victoria', 'J.'), ('Victoria', 'J.', 'Hodge'), ('J.', 'Hodge', 'Jim'), ('Hodge', 'Jim', 'Austin'), ('Jim', 'Austin', ','), ('Austin', ',', ''), (',', '', 'A'), ('', 'A', 'Survey'), ('A', 'Survey', 'Outlier'), ('Survey', 'Outlier', 'Detection'), ('Outlier', 'Detection', 'Methodologies'), ('Detection', 'Methodologies', ''), ('Methodologies', '', ','), ('', ',', 'Artificial'), (',', 'Artificial', 'Intelligence'), ('Artificial', 'Intelligence', 'Review'), ('Intelligence', 'Review', ',')]

>> POS Tags are: 
 [('[', 'RB'), ('4', 'CD'), (']', 'JJ'), ('Victoria', 'NNP'), ('J.', 'NNP'), ('Hodge', 'NNP'), ('Jim', 'NNP'), ('Austin', 'NNP'), (',', ','), ('', 'VBZ'), ('A', 'NNP'), ('Survey', 'NNP'), ('Outlier', 'NNP'), ('Detection', 'NNP'), ('Methodologies', 'NNP'), ('', 'NNP'), (',', ','), ('Artificial', 'NNP'), ('Intelligence', 'NNP'), ('Review', 'NNP'), (',', ',')]

>> Noun Phrases are: 
 ['] Victoria J. Hodge Jim Austin', 'A Survey Outlier Detection Methodologies ', 'Artificial Intelligence Review']

>> Named Entities are: 
 [('ORGANIZATION', 'Victoria'), ('PERSON', 'Jim Austin'), ('ORGANIZATION', 'Artificial Intelligence Review')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('4', '4'), (']', ']'), ('Victoria', 'victoria'), ('J.', 'j.'), ('Hodge', 'hodg'), ('Jim', 'jim'), ('Austin', 'austin'), (',', ','), ('', ''), ('A', 'a'), ('Survey', 'survey'), ('Outlier', 'outlier'), ('Detection', 'detect'), ('Methodologies', 'methodolog'), ('', ''), (',', ','), ('Artificial', 'artifici'), ('Intelligence', 'intellig'), ('Review', 'review'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('4', '4'), (']', ']'), ('Victoria', 'victoria'), ('J.', 'j.'), ('Hodge', 'hodg'), ('Jim', 'jim'), ('Austin', 'austin'), (',', ','), ('', ''), ('A', 'a'), ('Survey', 'survey'), ('Outlier', 'outlier'), ('Detection', 'detect'), ('Methodologies', 'methodolog'), ('', ''), (',', ','), ('Artificial', 'artifici'), ('Intelligence', 'intellig'), ('Review', 'review'), (',', ',')]

>> Lemmatization: 
 [('[', '['), ('4', '4'), (']', ']'), ('Victoria', 'Victoria'), ('J.', 'J.'), ('Hodge', 'Hodge'), ('Jim', 'Jim'), ('Austin', 'Austin'), (',', ','), ('', ''), ('A', 'A'), ('Survey', 'Survey'), ('Outlier', 'Outlier'), ('Detection', 'Detection'), ('Methodologies', 'Methodologies'), ('', ''), (',', ','), ('Artificial', 'Artificial'), ('Intelligence', 'Intelligence'), ('Review', 'Review'), (',', ',')]



========================================== PARAGRAPH 609 ===========================================

Vol. 22, No. 2, pp. 85-126, 2004.  

------------------- Sentence 1 -------------------

Vol.

>> Tokens are: 
 ['Vol', '.']

>> Bigrams are: 
 [('Vol', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Vol', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Vol']

>> Named Entities are: 
 [('GPE', 'Vol')] 

>> Stemming using Porter Stemmer: 
 [('Vol', 'vol'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Vol', 'vol'), ('.', '.')]

>> Lemmatization: 
 [('Vol', 'Vol'), ('.', '.')]


------------------- Sentence 2 -------------------

22, No.

>> Tokens are: 
 ['22', ',', 'No', '.']

>> Bigrams are: 
 [('22', ','), (',', 'No'), ('No', '.')]

>> Trigrams are: 
 [('22', ',', 'No'), (',', 'No', '.')]

>> POS Tags are: 
 [('22', 'CD'), (',', ','), ('No', 'DT'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('22', '22'), (',', ','), ('No', 'no'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('22', '22'), (',', ','), ('No', 'no'), ('.', '.')]

>> Lemmatization: 
 [('22', '22'), (',', ','), ('No', 'No'), ('.', '.')]


------------------- Sentence 3 -------------------

2, pp.

>> Tokens are: 
 ['2', ',', 'pp', '.']

>> Bigrams are: 
 [('2', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('2', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('2', 'CD'), (',', ','), ('pp', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['pp']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('2', '2'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('2', '2'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('2', '2'), (',', ','), ('pp', 'pp'), ('.', '.')]


------------------- Sentence 4 -------------------

85-126, 2004.

>> Tokens are: 
 ['85-126', ',', '2004', '.']

>> Bigrams are: 
 [('85-126', ','), (',', '2004'), ('2004', '.')]

>> Trigrams are: 
 [('85-126', ',', '2004'), (',', '2004', '.')]

>> POS Tags are: 
 [('85-126', 'CD'), (',', ','), ('2004', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('85-126', '85-126'), (',', ','), ('2004', '2004'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('85-126', '85-126'), (',', ','), ('2004', '2004'), ('.', '.')]

>> Lemmatization: 
 [('85-126', '85-126'), (',', ','), ('2004', '2004'), ('.', '.')]



========================================== PARAGRAPH 610 ===========================================

[5] Karanjit Singh and Shuchita Upadhyaya, Outlier Detection:  Applications and Techniques, International Journal of Computer  

------------------- Sentence 1 -------------------

[5] Karanjit Singh and Shuchita Upadhyaya, Outlier Detection:  Applications and Techniques, International Journal of Computer

>> Tokens are: 
 ['[', '5', ']', 'Karanjit', 'Singh', 'Shuchita', 'Upadhyaya', ',', '', 'Outlier', 'Detection', ':', 'Applications', 'Techniques', '', ',', 'International', 'Journal', 'Computer']

>> Bigrams are: 
 [('[', '5'), ('5', ']'), (']', 'Karanjit'), ('Karanjit', 'Singh'), ('Singh', 'Shuchita'), ('Shuchita', 'Upadhyaya'), ('Upadhyaya', ','), (',', ''), ('', 'Outlier'), ('Outlier', 'Detection'), ('Detection', ':'), (':', 'Applications'), ('Applications', 'Techniques'), ('Techniques', ''), ('', ','), (',', 'International'), ('International', 'Journal'), ('Journal', 'Computer')]

>> Trigrams are: 
 [('[', '5', ']'), ('5', ']', 'Karanjit'), (']', 'Karanjit', 'Singh'), ('Karanjit', 'Singh', 'Shuchita'), ('Singh', 'Shuchita', 'Upadhyaya'), ('Shuchita', 'Upadhyaya', ','), ('Upadhyaya', ',', ''), (',', '', 'Outlier'), ('', 'Outlier', 'Detection'), ('Outlier', 'Detection', ':'), ('Detection', ':', 'Applications'), (':', 'Applications', 'Techniques'), ('Applications', 'Techniques', ''), ('Techniques', '', ','), ('', ',', 'International'), (',', 'International', 'Journal'), ('International', 'Journal', 'Computer')]

>> POS Tags are: 
 [('[', 'RB'), ('5', 'CD'), (']', 'JJ'), ('Karanjit', 'NNP'), ('Singh', 'NNP'), ('Shuchita', 'NNP'), ('Upadhyaya', 'NNP'), (',', ','), ('', 'NNP'), ('Outlier', 'NNP'), ('Detection', 'NNP'), (':', ':'), ('Applications', 'NNS'), ('Techniques', 'NNP'), ('', 'NNP'), (',', ','), ('International', 'NNP'), ('Journal', 'NNP'), ('Computer', 'NNP')]

>> Noun Phrases are: 
 ['] Karanjit Singh Shuchita Upadhyaya', ' Outlier Detection', 'Applications Techniques ', 'International Journal Computer']

>> Named Entities are: 
 [('PERSON', 'Karanjit Singh Shuchita Upadhyaya'), ('PERSON', 'Techniques'), ('ORGANIZATION', 'International Journal')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('5', '5'), (']', ']'), ('Karanjit', 'karanjit'), ('Singh', 'singh'), ('Shuchita', 'shuchita'), ('Upadhyaya', 'upadhyaya'), (',', ','), ('', ''), ('Outlier', 'outlier'), ('Detection', 'detect'), (':', ':'), ('Applications', 'applic'), ('Techniques', 'techniqu'), ('', ''), (',', ','), ('International', 'intern'), ('Journal', 'journal'), ('Computer', 'comput')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('5', '5'), (']', ']'), ('Karanjit', 'karanjit'), ('Singh', 'singh'), ('Shuchita', 'shuchita'), ('Upadhyaya', 'upadhyaya'), (',', ','), ('', ''), ('Outlier', 'outlier'), ('Detection', 'detect'), (':', ':'), ('Applications', 'applic'), ('Techniques', 'techniqu'), ('', ''), (',', ','), ('International', 'intern'), ('Journal', 'journal'), ('Computer', 'comput')]

>> Lemmatization: 
 [('[', '['), ('5', '5'), (']', ']'), ('Karanjit', 'Karanjit'), ('Singh', 'Singh'), ('Shuchita', 'Shuchita'), ('Upadhyaya', 'Upadhyaya'), (',', ','), ('', ''), ('Outlier', 'Outlier'), ('Detection', 'Detection'), (':', ':'), ('Applications', 'Applications'), ('Techniques', 'Techniques'), ('', ''), (',', ','), ('International', 'International'), ('Journal', 'Journal'), ('Computer', 'Computer')]



========================================== PARAGRAPH 611 ===========================================

Science Issues, Vol. 9, Issue. 1, No. 3, pp. 307-323, 2012.  

------------------- Sentence 1 -------------------

Science Issues, Vol.

>> Tokens are: 
 ['Science', 'Issues', ',', 'Vol', '.']

>> Bigrams are: 
 [('Science', 'Issues'), ('Issues', ','), (',', 'Vol'), ('Vol', '.')]

>> Trigrams are: 
 [('Science', 'Issues', ','), ('Issues', ',', 'Vol'), (',', 'Vol', '.')]

>> POS Tags are: 
 [('Science', 'NNP'), ('Issues', 'NNP'), (',', ','), ('Vol', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Science Issues', 'Vol']

>> Named Entities are: 
 [('GPE', 'Science'), ('ORGANIZATION', 'Issues'), ('PERSON', 'Vol')] 

>> Stemming using Porter Stemmer: 
 [('Science', 'scienc'), ('Issues', 'issu'), (',', ','), ('Vol', 'vol'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Science', 'scienc'), ('Issues', 'issu'), (',', ','), ('Vol', 'vol'), ('.', '.')]

>> Lemmatization: 
 [('Science', 'Science'), ('Issues', 'Issues'), (',', ','), ('Vol', 'Vol'), ('.', '.')]


------------------- Sentence 2 -------------------

9, Issue.

>> Tokens are: 
 ['9', ',', 'Issue', '.']

>> Bigrams are: 
 [('9', ','), (',', 'Issue'), ('Issue', '.')]

>> Trigrams are: 
 [('9', ',', 'Issue'), (',', 'Issue', '.')]

>> POS Tags are: 
 [('9', 'CD'), (',', ','), ('Issue', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Issue']

>> Named Entities are: 
 [('PERSON', 'Issue')] 

>> Stemming using Porter Stemmer: 
 [('9', '9'), (',', ','), ('Issue', 'issu'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('9', '9'), (',', ','), ('Issue', 'issu'), ('.', '.')]

>> Lemmatization: 
 [('9', '9'), (',', ','), ('Issue', 'Issue'), ('.', '.')]


------------------- Sentence 3 -------------------

1, No.

>> Tokens are: 
 ['1', ',', 'No', '.']

>> Bigrams are: 
 [('1', ','), (',', 'No'), ('No', '.')]

>> Trigrams are: 
 [('1', ',', 'No'), (',', 'No', '.')]

>> POS Tags are: 
 [('1', 'CD'), (',', ','), ('No', 'DT'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('1', '1'), (',', ','), ('No', 'no'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('1', '1'), (',', ','), ('No', 'no'), ('.', '.')]

>> Lemmatization: 
 [('1', '1'), (',', ','), ('No', 'No'), ('.', '.')]


------------------- Sentence 4 -------------------

3, pp.

>> Tokens are: 
 ['3', ',', 'pp', '.']

>> Bigrams are: 
 [('3', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('3', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('3', 'CD'), (',', ','), ('pp', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['pp']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('3', '3'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('3', '3'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('3', '3'), (',', ','), ('pp', 'pp'), ('.', '.')]


------------------- Sentence 5 -------------------

307-323, 2012.

>> Tokens are: 
 ['307-323', ',', '2012', '.']

>> Bigrams are: 
 [('307-323', ','), (',', '2012'), ('2012', '.')]

>> Trigrams are: 
 [('307-323', ',', '2012'), (',', '2012', '.')]

>> POS Tags are: 
 [('307-323', 'CD'), (',', ','), ('2012', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('307-323', '307-323'), (',', ','), ('2012', '2012'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('307-323', '307-323'), (',', ','), ('2012', '2012'), ('.', '.')]

>> Lemmatization: 
 [('307-323', '307-323'), (',', ','), ('2012', '2012'), ('.', '.')]



========================================== PARAGRAPH 612 ===========================================

[6] Hugo Jair Escalante, A Comparison of Outlier Detection  Algorithms for Machine Learning, CIC-2005 Congreso  

------------------- Sentence 1 -------------------

[6] Hugo Jair Escalante, A Comparison of Outlier Detection  Algorithms for Machine Learning, CIC-2005 Congreso

>> Tokens are: 
 ['[', '6', ']', 'Hugo', 'Jair', 'Escalante', ',', '', 'A', 'Comparison', 'Outlier', 'Detection', 'Algorithms', 'Machine', 'Learning', '', ',', 'CIC-2005', 'Congreso']

>> Bigrams are: 
 [('[', '6'), ('6', ']'), (']', 'Hugo'), ('Hugo', 'Jair'), ('Jair', 'Escalante'), ('Escalante', ','), (',', ''), ('', 'A'), ('A', 'Comparison'), ('Comparison', 'Outlier'), ('Outlier', 'Detection'), ('Detection', 'Algorithms'), ('Algorithms', 'Machine'), ('Machine', 'Learning'), ('Learning', ''), ('', ','), (',', 'CIC-2005'), ('CIC-2005', 'Congreso')]

>> Trigrams are: 
 [('[', '6', ']'), ('6', ']', 'Hugo'), (']', 'Hugo', 'Jair'), ('Hugo', 'Jair', 'Escalante'), ('Jair', 'Escalante', ','), ('Escalante', ',', ''), (',', '', 'A'), ('', 'A', 'Comparison'), ('A', 'Comparison', 'Outlier'), ('Comparison', 'Outlier', 'Detection'), ('Outlier', 'Detection', 'Algorithms'), ('Detection', 'Algorithms', 'Machine'), ('Algorithms', 'Machine', 'Learning'), ('Machine', 'Learning', ''), ('Learning', '', ','), ('', ',', 'CIC-2005'), (',', 'CIC-2005', 'Congreso')]

>> POS Tags are: 
 [('[', 'RB'), ('6', 'CD'), (']', 'JJ'), ('Hugo', 'NNP'), ('Jair', 'NNP'), ('Escalante', 'NNP'), (',', ','), ('', 'VBZ'), ('A', 'NNP'), ('Comparison', 'NNP'), ('Outlier', 'NNP'), ('Detection', 'NNP'), ('Algorithms', 'NNP'), ('Machine', 'NNP'), ('Learning', 'NNP'), ('', 'NNP'), (',', ','), ('CIC-2005', 'NNP'), ('Congreso', 'NNP')]

>> Noun Phrases are: 
 ['] Hugo Jair Escalante', 'A Comparison Outlier Detection Algorithms Machine Learning ', 'CIC-2005 Congreso']

>> Named Entities are: 
 [('PERSON', 'Hugo Jair Escalante'), ('ORGANIZATION', 'Comparison Outlier'), ('PERSON', 'Machine Learning')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('6', '6'), (']', ']'), ('Hugo', 'hugo'), ('Jair', 'jair'), ('Escalante', 'escalant'), (',', ','), ('', ''), ('A', 'a'), ('Comparison', 'comparison'), ('Outlier', 'outlier'), ('Detection', 'detect'), ('Algorithms', 'algorithm'), ('Machine', 'machin'), ('Learning', 'learn'), ('', ''), (',', ','), ('CIC-2005', 'cic-2005'), ('Congreso', 'congreso')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('6', '6'), (']', ']'), ('Hugo', 'hugo'), ('Jair', 'jair'), ('Escalante', 'escalant'), (',', ','), ('', ''), ('A', 'a'), ('Comparison', 'comparison'), ('Outlier', 'outlier'), ('Detection', 'detect'), ('Algorithms', 'algorithm'), ('Machine', 'machin'), ('Learning', 'learn'), ('', ''), (',', ','), ('CIC-2005', 'cic-2005'), ('Congreso', 'congreso')]

>> Lemmatization: 
 [('[', '['), ('6', '6'), (']', ']'), ('Hugo', 'Hugo'), ('Jair', 'Jair'), ('Escalante', 'Escalante'), (',', ','), ('', ''), ('A', 'A'), ('Comparison', 'Comparison'), ('Outlier', 'Outlier'), ('Detection', 'Detection'), ('Algorithms', 'Algorithms'), ('Machine', 'Machine'), ('Learning', 'Learning'), ('', ''), (',', ','), ('CIC-2005', 'CIC-2005'), ('Congreso', 'Congreso')]



========================================== PARAGRAPH 613 ===========================================

Internacional en Computacion-IPN, 2005.  

------------------- Sentence 1 -------------------

Internacional en Computacion-IPN, 2005.

>> Tokens are: 
 ['Internacional', 'en', 'Computacion-IPN', ',', '2005', '.']

>> Bigrams are: 
 [('Internacional', 'en'), ('en', 'Computacion-IPN'), ('Computacion-IPN', ','), (',', '2005'), ('2005', '.')]

>> Trigrams are: 
 [('Internacional', 'en', 'Computacion-IPN'), ('en', 'Computacion-IPN', ','), ('Computacion-IPN', ',', '2005'), (',', '2005', '.')]

>> POS Tags are: 
 [('Internacional', 'JJ'), ('en', 'IN'), ('Computacion-IPN', 'NNP'), (',', ','), ('2005', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Computacion-IPN']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Internacional', 'internacion'), ('en', 'en'), ('Computacion-IPN', 'computacion-ipn'), (',', ','), ('2005', '2005'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Internacional', 'internacion'), ('en', 'en'), ('Computacion-IPN', 'computacion-ipn'), (',', ','), ('2005', '2005'), ('.', '.')]

>> Lemmatization: 
 [('Internacional', 'Internacional'), ('en', 'en'), ('Computacion-IPN', 'Computacion-IPN'), (',', ','), ('2005', '2005'), ('.', '.')]



========================================== PARAGRAPH 614 ===========================================

[7] Pierre Geurts, Alexandre Irrthum, Louis Wehenkel,  Supervised learning with decision tree-based methods in  

------------------- Sentence 1 -------------------

[7] Pierre Geurts, Alexandre Irrthum, Louis Wehenkel,  Supervised learning with decision tree-based methods in

>> Tokens are: 
 ['[', '7', ']', 'Pierre', 'Geurts', ',', 'Alexandre', 'Irrthum', ',', 'Louis', 'Wehenkel', ',', '', 'Supervised', 'learning', 'decision', 'tree-based', 'methods']

>> Bigrams are: 
 [('[', '7'), ('7', ']'), (']', 'Pierre'), ('Pierre', 'Geurts'), ('Geurts', ','), (',', 'Alexandre'), ('Alexandre', 'Irrthum'), ('Irrthum', ','), (',', 'Louis'), ('Louis', 'Wehenkel'), ('Wehenkel', ','), (',', ''), ('', 'Supervised'), ('Supervised', 'learning'), ('learning', 'decision'), ('decision', 'tree-based'), ('tree-based', 'methods')]

>> Trigrams are: 
 [('[', '7', ']'), ('7', ']', 'Pierre'), (']', 'Pierre', 'Geurts'), ('Pierre', 'Geurts', ','), ('Geurts', ',', 'Alexandre'), (',', 'Alexandre', 'Irrthum'), ('Alexandre', 'Irrthum', ','), ('Irrthum', ',', 'Louis'), (',', 'Louis', 'Wehenkel'), ('Louis', 'Wehenkel', ','), ('Wehenkel', ',', ''), (',', '', 'Supervised'), ('', 'Supervised', 'learning'), ('Supervised', 'learning', 'decision'), ('learning', 'decision', 'tree-based'), ('decision', 'tree-based', 'methods')]

>> POS Tags are: 
 [('[', 'RB'), ('7', 'CD'), (']', 'JJ'), ('Pierre', 'NNP'), ('Geurts', 'NNP'), (',', ','), ('Alexandre', 'NNP'), ('Irrthum', 'NNP'), (',', ','), ('Louis', 'NNP'), ('Wehenkel', 'NNP'), (',', ','), ('', 'NNP'), ('Supervised', 'VBD'), ('learning', 'VBG'), ('decision', 'NN'), ('tree-based', 'JJ'), ('methods', 'NNS')]

>> Noun Phrases are: 
 ['] Pierre Geurts', 'Alexandre Irrthum', 'Louis Wehenkel', '', 'decision', 'tree-based methods']

>> Named Entities are: 
 [('PERSON', 'Pierre Geurts'), ('PERSON', 'Alexandre Irrthum'), ('PERSON', 'Louis Wehenkel')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('7', '7'), (']', ']'), ('Pierre', 'pierr'), ('Geurts', 'geurt'), (',', ','), ('Alexandre', 'alexandr'), ('Irrthum', 'irrthum'), (',', ','), ('Louis', 'loui'), ('Wehenkel', 'wehenkel'), (',', ','), ('', ''), ('Supervised', 'supervis'), ('learning', 'learn'), ('decision', 'decis'), ('tree-based', 'tree-bas'), ('methods', 'method')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('7', '7'), (']', ']'), ('Pierre', 'pierr'), ('Geurts', 'geurt'), (',', ','), ('Alexandre', 'alexandr'), ('Irrthum', 'irrthum'), (',', ','), ('Louis', 'loui'), ('Wehenkel', 'wehenkel'), (',', ','), ('', ''), ('Supervised', 'supervis'), ('learning', 'learn'), ('decision', 'decis'), ('tree-based', 'tree-bas'), ('methods', 'method')]

>> Lemmatization: 
 [('[', '['), ('7', '7'), (']', ']'), ('Pierre', 'Pierre'), ('Geurts', 'Geurts'), (',', ','), ('Alexandre', 'Alexandre'), ('Irrthum', 'Irrthum'), (',', ','), ('Louis', 'Louis'), ('Wehenkel', 'Wehenkel'), (',', ','), ('', ''), ('Supervised', 'Supervised'), ('learning', 'learning'), ('decision', 'decision'), ('tree-based', 'tree-based'), ('methods', 'method')]



========================================== PARAGRAPH 615 ===========================================

computational and systems biology, Molecular  

------------------- Sentence 1 -------------------

computational and systems biology, Molecular

>> Tokens are: 
 ['computational', 'systems', 'biology', '', ',', 'Molecular']

>> Bigrams are: 
 [('computational', 'systems'), ('systems', 'biology'), ('biology', ''), ('', ','), (',', 'Molecular')]

>> Trigrams are: 
 [('computational', 'systems', 'biology'), ('systems', 'biology', ''), ('biology', '', ','), ('', ',', 'Molecular')]

>> POS Tags are: 
 [('computational', 'JJ'), ('systems', 'NNS'), ('biology', 'NN'), ('', 'NNP'), (',', ','), ('Molecular', 'NNP')]

>> Noun Phrases are: 
 ['computational systems biology ', 'Molecular']

>> Named Entities are: 
 [('PERSON', 'Molecular')] 

>> Stemming using Porter Stemmer: 
 [('computational', 'comput'), ('systems', 'system'), ('biology', 'biolog'), ('', ''), (',', ','), ('Molecular', 'molecular')]

>> Stemming using Snowball Stemmer: 
 [('computational', 'comput'), ('systems', 'system'), ('biology', 'biolog'), ('', ''), (',', ','), ('Molecular', 'molecular')]

>> Lemmatization: 
 [('computational', 'computational'), ('systems', 'system'), ('biology', 'biology'), ('', ''), (',', ','), ('Molecular', 'Molecular')]



========================================== PARAGRAPH 616 ===========================================

BioSystems, Vol. 5, No. 12, pp. 1593-1605, 2009.  

------------------- Sentence 1 -------------------

BioSystems, Vol.

>> Tokens are: 
 ['BioSystems', ',', 'Vol', '.']

>> Bigrams are: 
 [('BioSystems', ','), (',', 'Vol'), ('Vol', '.')]

>> Trigrams are: 
 [('BioSystems', ',', 'Vol'), (',', 'Vol', '.')]

>> POS Tags are: 
 [('BioSystems', 'NNS'), (',', ','), ('Vol', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['BioSystems', 'Vol']

>> Named Entities are: 
 [('PERSON', 'Vol')] 

>> Stemming using Porter Stemmer: 
 [('BioSystems', 'biosystem'), (',', ','), ('Vol', 'vol'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('BioSystems', 'biosystem'), (',', ','), ('Vol', 'vol'), ('.', '.')]

>> Lemmatization: 
 [('BioSystems', 'BioSystems'), (',', ','), ('Vol', 'Vol'), ('.', '.')]


------------------- Sentence 2 -------------------

5, No.

>> Tokens are: 
 ['5', ',', 'No', '.']

>> Bigrams are: 
 [('5', ','), (',', 'No'), ('No', '.')]

>> Trigrams are: 
 [('5', ',', 'No'), (',', 'No', '.')]

>> POS Tags are: 
 [('5', 'CD'), (',', ','), ('No', 'DT'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('5', '5'), (',', ','), ('No', 'no'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('5', '5'), (',', ','), ('No', 'no'), ('.', '.')]

>> Lemmatization: 
 [('5', '5'), (',', ','), ('No', 'No'), ('.', '.')]


------------------- Sentence 3 -------------------

12, pp.

>> Tokens are: 
 ['12', ',', 'pp', '.']

>> Bigrams are: 
 [('12', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('12', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('12', 'CD'), (',', ','), ('pp', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['pp']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('12', '12'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('12', '12'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('12', '12'), (',', ','), ('pp', 'pp'), ('.', '.')]


------------------- Sentence 4 -------------------

1593-1605, 2009.

>> Tokens are: 
 ['1593-1605', ',', '2009', '.']

>> Bigrams are: 
 [('1593-1605', ','), (',', '2009'), ('2009', '.')]

>> Trigrams are: 
 [('1593-1605', ',', '2009'), (',', '2009', '.')]

>> POS Tags are: 
 [('1593-1605', 'CD'), (',', ','), ('2009', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('1593-1605', '1593-1605'), (',', ','), ('2009', '2009'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('1593-1605', '1593-1605'), (',', ','), ('2009', '2009'), ('.', '.')]

>> Lemmatization: 
 [('1593-1605', '1593-1605'), (',', ','), ('2009', '2009'), ('.', '.')]



========================================== PARAGRAPH 617 ===========================================

[8] L. Breiman, J. Friedman, R. A. Olsen and C. J. Stone,  Classification and Regression Trees, Belmont,  

------------------- Sentence 1 -------------------

[8] L. Breiman, J. Friedman, R. A. Olsen and C. J.

>> Tokens are: 
 ['[', '8', ']', 'L.', 'Breiman', ',', 'J.', 'Friedman', ',', 'R.', 'A.', 'Olsen', 'C.', 'J', '.']

>> Bigrams are: 
 [('[', '8'), ('8', ']'), (']', 'L.'), ('L.', 'Breiman'), ('Breiman', ','), (',', 'J.'), ('J.', 'Friedman'), ('Friedman', ','), (',', 'R.'), ('R.', 'A.'), ('A.', 'Olsen'), ('Olsen', 'C.'), ('C.', 'J'), ('J', '.')]

>> Trigrams are: 
 [('[', '8', ']'), ('8', ']', 'L.'), (']', 'L.', 'Breiman'), ('L.', 'Breiman', ','), ('Breiman', ',', 'J.'), (',', 'J.', 'Friedman'), ('J.', 'Friedman', ','), ('Friedman', ',', 'R.'), (',', 'R.', 'A.'), ('R.', 'A.', 'Olsen'), ('A.', 'Olsen', 'C.'), ('Olsen', 'C.', 'J'), ('C.', 'J', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('8', 'CD'), (']', 'JJ'), ('L.', 'NNP'), ('Breiman', 'NNP'), (',', ','), ('J.', 'NNP'), ('Friedman', 'NNP'), (',', ','), ('R.', 'NNP'), ('A.', 'NNP'), ('Olsen', 'NNP'), ('C.', 'NNP'), ('J', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['] L. Breiman', 'J. Friedman', 'R. A. Olsen C. J']

>> Named Entities are: 
 [('PERSON', 'J. Friedman')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('8', '8'), (']', ']'), ('L.', 'l.'), ('Breiman', 'breiman'), (',', ','), ('J.', 'j.'), ('Friedman', 'friedman'), (',', ','), ('R.', 'r.'), ('A.', 'a.'), ('Olsen', 'olsen'), ('C.', 'c.'), ('J', 'j'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('8', '8'), (']', ']'), ('L.', 'l.'), ('Breiman', 'breiman'), (',', ','), ('J.', 'j.'), ('Friedman', 'friedman'), (',', ','), ('R.', 'r.'), ('A.', 'a.'), ('Olsen', 'olsen'), ('C.', 'c.'), ('J', 'j'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('8', '8'), (']', ']'), ('L.', 'L.'), ('Breiman', 'Breiman'), (',', ','), ('J.', 'J.'), ('Friedman', 'Friedman'), (',', ','), ('R.', 'R.'), ('A.', 'A.'), ('Olsen', 'Olsen'), ('C.', 'C.'), ('J', 'J'), ('.', '.')]


------------------- Sentence 2 -------------------

Stone,  Classification and Regression Trees, Belmont,

>> Tokens are: 
 ['Stone', ',', '', 'Classification', 'Regression', 'Trees', '', ',', 'Belmont', ',']

>> Bigrams are: 
 [('Stone', ','), (',', ''), ('', 'Classification'), ('Classification', 'Regression'), ('Regression', 'Trees'), ('Trees', ''), ('', ','), (',', 'Belmont'), ('Belmont', ',')]

>> Trigrams are: 
 [('Stone', ',', ''), (',', '', 'Classification'), ('', 'Classification', 'Regression'), ('Classification', 'Regression', 'Trees'), ('Regression', 'Trees', ''), ('Trees', '', ','), ('', ',', 'Belmont'), (',', 'Belmont', ',')]

>> POS Tags are: 
 [('Stone', 'NN'), (',', ','), ('', 'JJ'), ('Classification', 'NNP'), ('Regression', 'NNP'), ('Trees', 'NNP'), ('', 'NNP'), (',', ','), ('Belmont', 'NNP'), (',', ',')]

>> Noun Phrases are: 
 ['Stone', ' Classification Regression Trees ', 'Belmont']

>> Named Entities are: 
 [('GPE', 'Stone'), ('PERSON', 'Trees'), ('GPE', 'Belmont')] 

>> Stemming using Porter Stemmer: 
 [('Stone', 'stone'), (',', ','), ('', ''), ('Classification', 'classif'), ('Regression', 'regress'), ('Trees', 'tree'), ('', ''), (',', ','), ('Belmont', 'belmont'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('Stone', 'stone'), (',', ','), ('', ''), ('Classification', 'classif'), ('Regression', 'regress'), ('Trees', 'tree'), ('', ''), (',', ','), ('Belmont', 'belmont'), (',', ',')]

>> Lemmatization: 
 [('Stone', 'Stone'), (',', ','), ('', ''), ('Classification', 'Classification'), ('Regression', 'Regression'), ('Trees', 'Trees'), ('', ''), (',', ','), ('Belmont', 'Belmont'), (',', ',')]



========================================== PARAGRAPH 618 ===========================================

California: Wadsworth International Group, 1984.  

------------------- Sentence 1 -------------------

California: Wadsworth International Group, 1984.

>> Tokens are: 
 ['California', ':', 'Wadsworth', 'International', 'Group', ',', '1984', '.']

>> Bigrams are: 
 [('California', ':'), (':', 'Wadsworth'), ('Wadsworth', 'International'), ('International', 'Group'), ('Group', ','), (',', '1984'), ('1984', '.')]

>> Trigrams are: 
 [('California', ':', 'Wadsworth'), (':', 'Wadsworth', 'International'), ('Wadsworth', 'International', 'Group'), ('International', 'Group', ','), ('Group', ',', '1984'), (',', '1984', '.')]

>> POS Tags are: 
 [('California', 'NNP'), (':', ':'), ('Wadsworth', 'JJ'), ('International', 'NNP'), ('Group', 'NNP'), (',', ','), ('1984', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['California', 'Wadsworth International Group']

>> Named Entities are: 
 [('GPE', 'California'), ('PERSON', 'Wadsworth'), ('ORGANIZATION', 'International Group')] 

>> Stemming using Porter Stemmer: 
 [('California', 'california'), (':', ':'), ('Wadsworth', 'wadsworth'), ('International', 'intern'), ('Group', 'group'), (',', ','), ('1984', '1984'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('California', 'california'), (':', ':'), ('Wadsworth', 'wadsworth'), ('International', 'intern'), ('Group', 'group'), (',', ','), ('1984', '1984'), ('.', '.')]

>> Lemmatization: 
 [('California', 'California'), (':', ':'), ('Wadsworth', 'Wadsworth'), ('International', 'International'), ('Group', 'Group'), (',', ','), ('1984', '1984'), ('.', '.')]



========================================== PARAGRAPH 619 ===========================================

[9] J. Quinlan, C4.5: Programs for machine learning, San  Francisco, CA: Morgan Kaufmann, 1986.  

------------------- Sentence 1 -------------------

[9] J. Quinlan, C4.5: Programs for machine learning, San  Francisco, CA: Morgan Kaufmann, 1986.

>> Tokens are: 
 ['[', '9', ']', 'J.', 'Quinlan', ',', '', 'C4.5', ':', 'Programs', 'machine', 'learning', '', ',', 'San', 'Francisco', ',', 'CA', ':', 'Morgan', 'Kaufmann', ',', '1986', '.']

>> Bigrams are: 
 [('[', '9'), ('9', ']'), (']', 'J.'), ('J.', 'Quinlan'), ('Quinlan', ','), (',', ''), ('', 'C4.5'), ('C4.5', ':'), (':', 'Programs'), ('Programs', 'machine'), ('machine', 'learning'), ('learning', ''), ('', ','), (',', 'San'), ('San', 'Francisco'), ('Francisco', ','), (',', 'CA'), ('CA', ':'), (':', 'Morgan'), ('Morgan', 'Kaufmann'), ('Kaufmann', ','), (',', '1986'), ('1986', '.')]

>> Trigrams are: 
 [('[', '9', ']'), ('9', ']', 'J.'), (']', 'J.', 'Quinlan'), ('J.', 'Quinlan', ','), ('Quinlan', ',', ''), (',', '', 'C4.5'), ('', 'C4.5', ':'), ('C4.5', ':', 'Programs'), (':', 'Programs', 'machine'), ('Programs', 'machine', 'learning'), ('machine', 'learning', ''), ('learning', '', ','), ('', ',', 'San'), (',', 'San', 'Francisco'), ('San', 'Francisco', ','), ('Francisco', ',', 'CA'), (',', 'CA', ':'), ('CA', ':', 'Morgan'), (':', 'Morgan', 'Kaufmann'), ('Morgan', 'Kaufmann', ','), ('Kaufmann', ',', '1986'), (',', '1986', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('9', 'CD'), (']', 'NNP'), ('J.', 'NNP'), ('Quinlan', 'NNP'), (',', ','), ('', 'NNP'), ('C4.5', 'NNP'), (':', ':'), ('Programs', 'NNP'), ('machine', 'NN'), ('learning', 'VBG'), ('', 'NN'), (',', ','), ('San', 'NNP'), ('Francisco', 'NNP'), (',', ','), ('CA', 'NNP'), (':', ':'), ('Morgan', 'NNP'), ('Kaufmann', 'NNP'), (',', ','), ('1986', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['] J. Quinlan', ' C4.5', 'Programs machine', '', 'San Francisco', 'CA', 'Morgan Kaufmann']

>> Named Entities are: 
 [('PERSON', 'Quinlan'), ('PERSON', 'San Francisco'), ('PERSON', 'Morgan Kaufmann')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('9', '9'), (']', ']'), ('J.', 'j.'), ('Quinlan', 'quinlan'), (',', ','), ('', ''), ('C4.5', 'c4.5'), (':', ':'), ('Programs', 'program'), ('machine', 'machin'), ('learning', 'learn'), ('', ''), (',', ','), ('San', 'san'), ('Francisco', 'francisco'), (',', ','), ('CA', 'ca'), (':', ':'), ('Morgan', 'morgan'), ('Kaufmann', 'kaufmann'), (',', ','), ('1986', '1986'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('9', '9'), (']', ']'), ('J.', 'j.'), ('Quinlan', 'quinlan'), (',', ','), ('', ''), ('C4.5', 'c4.5'), (':', ':'), ('Programs', 'program'), ('machine', 'machin'), ('learning', 'learn'), ('', ''), (',', ','), ('San', 'san'), ('Francisco', 'francisco'), (',', ','), ('CA', 'ca'), (':', ':'), ('Morgan', 'morgan'), ('Kaufmann', 'kaufmann'), (',', ','), ('1986', '1986'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('9', '9'), (']', ']'), ('J.', 'J.'), ('Quinlan', 'Quinlan'), (',', ','), ('', ''), ('C4.5', 'C4.5'), (':', ':'), ('Programs', 'Programs'), ('machine', 'machine'), ('learning', 'learning'), ('', ''), (',', ','), ('San', 'San'), ('Francisco', 'Francisco'), (',', ','), ('CA', 'CA'), (':', ':'), ('Morgan', 'Morgan'), ('Kaufmann', 'Kaufmann'), (',', ','), ('1986', '1986'), ('.', '.')]



========================================== PARAGRAPH 620 ===========================================

[10] Masud Karim and Rashedur M. Rahman, Decision Tree  and Nave Bayes Algorithm for Classification and  

------------------- Sentence 1 -------------------

[10] Masud Karim and Rashedur M. Rahman, Decision Tree  and Nave Bayes Algorithm for Classification and

>> Tokens are: 
 ['[', '10', ']', 'Masud', 'Karim', 'Rashedur', 'M.', 'Rahman', ',', '', 'Decision', 'Tree', 'Nave', 'Bayes', 'Algorithm', 'Classification']

>> Bigrams are: 
 [('[', '10'), ('10', ']'), (']', 'Masud'), ('Masud', 'Karim'), ('Karim', 'Rashedur'), ('Rashedur', 'M.'), ('M.', 'Rahman'), ('Rahman', ','), (',', ''), ('', 'Decision'), ('Decision', 'Tree'), ('Tree', 'Nave'), ('Nave', 'Bayes'), ('Bayes', 'Algorithm'), ('Algorithm', 'Classification')]

>> Trigrams are: 
 [('[', '10', ']'), ('10', ']', 'Masud'), (']', 'Masud', 'Karim'), ('Masud', 'Karim', 'Rashedur'), ('Karim', 'Rashedur', 'M.'), ('Rashedur', 'M.', 'Rahman'), ('M.', 'Rahman', ','), ('Rahman', ',', ''), (',', '', 'Decision'), ('', 'Decision', 'Tree'), ('Decision', 'Tree', 'Nave'), ('Tree', 'Nave', 'Bayes'), ('Nave', 'Bayes', 'Algorithm'), ('Bayes', 'Algorithm', 'Classification')]

>> POS Tags are: 
 [('[', 'RB'), ('10', 'CD'), (']', 'JJ'), ('Masud', 'NNP'), ('Karim', 'NNP'), ('Rashedur', 'NNP'), ('M.', 'NNP'), ('Rahman', 'NNP'), (',', ','), ('', 'NNP'), ('Decision', 'NNP'), ('Tree', 'NNP'), ('Nave', 'NNP'), ('Bayes', 'NNP'), ('Algorithm', 'NNP'), ('Classification', 'NNP')]

>> Noun Phrases are: 
 ['] Masud Karim Rashedur M. Rahman', ' Decision Tree Nave Bayes Algorithm Classification']

>> Named Entities are: 
 [('PERSON', 'Masud Karim Rashedur'), ('PERSON', 'Rahman')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('10', '10'), (']', ']'), ('Masud', 'masud'), ('Karim', 'karim'), ('Rashedur', 'rashedur'), ('M.', 'm.'), ('Rahman', 'rahman'), (',', ','), ('', ''), ('Decision', 'decis'), ('Tree', 'tree'), ('Nave', 'nav'), ('Bayes', 'bay'), ('Algorithm', 'algorithm'), ('Classification', 'classif')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('10', '10'), (']', ']'), ('Masud', 'masud'), ('Karim', 'karim'), ('Rashedur', 'rashedur'), ('M.', 'm.'), ('Rahman', 'rahman'), (',', ','), ('', ''), ('Decision', 'decis'), ('Tree', 'tree'), ('Nave', 'nav'), ('Bayes', 'bay'), ('Algorithm', 'algorithm'), ('Classification', 'classif')]

>> Lemmatization: 
 [('[', '['), ('10', '10'), (']', ']'), ('Masud', 'Masud'), ('Karim', 'Karim'), ('Rashedur', 'Rashedur'), ('M.', 'M.'), ('Rahman', 'Rahman'), (',', ','), ('', ''), ('Decision', 'Decision'), ('Tree', 'Tree'), ('Nave', 'Nave'), ('Bayes', 'Bayes'), ('Algorithm', 'Algorithm'), ('Classification', 'Classification')]



========================================== PARAGRAPH 621 ===========================================

Generation of Actionable Knowledge for Direct  

------------------- Sentence 1 -------------------

Generation of Actionable Knowledge for Direct

>> Tokens are: 
 ['Generation', 'Actionable', 'Knowledge', 'Direct']

>> Bigrams are: 
 [('Generation', 'Actionable'), ('Actionable', 'Knowledge'), ('Knowledge', 'Direct')]

>> Trigrams are: 
 [('Generation', 'Actionable', 'Knowledge'), ('Actionable', 'Knowledge', 'Direct')]

>> POS Tags are: 
 [('Generation', 'NNP'), ('Actionable', 'NNP'), ('Knowledge', 'NNP'), ('Direct', 'NNP')]

>> Noun Phrases are: 
 ['Generation Actionable Knowledge Direct']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Generation', 'gener'), ('Actionable', 'action'), ('Knowledge', 'knowledg'), ('Direct', 'direct')]

>> Stemming using Snowball Stemmer: 
 [('Generation', 'generat'), ('Actionable', 'action'), ('Knowledge', 'knowledg'), ('Direct', 'direct')]

>> Lemmatization: 
 [('Generation', 'Generation'), ('Actionable', 'Actionable'), ('Knowledge', 'Knowledge'), ('Direct', 'Direct')]



========================================== PARAGRAPH 622 ===========================================

Marketing, Journal of Software Engineering and  

------------------- Sentence 1 -------------------

Marketing, Journal of Software Engineering and

>> Tokens are: 
 ['Marketing', '', ',', 'Journal', 'Software', 'Engineering']

>> Bigrams are: 
 [('Marketing', ''), ('', ','), (',', 'Journal'), ('Journal', 'Software'), ('Software', 'Engineering')]

>> Trigrams are: 
 [('Marketing', '', ','), ('', ',', 'Journal'), (',', 'Journal', 'Software'), ('Journal', 'Software', 'Engineering')]

>> POS Tags are: 
 [('Marketing', 'VBG'), ('', 'NN'), (',', ','), ('Journal', 'NNP'), ('Software', 'NNP'), ('Engineering', 'NNP')]

>> Noun Phrases are: 
 ['', 'Journal Software Engineering']

>> Named Entities are: 
 [('PERSON', 'Journal Software')] 

>> Stemming using Porter Stemmer: 
 [('Marketing', 'market'), ('', ''), (',', ','), ('Journal', 'journal'), ('Software', 'softwar'), ('Engineering', 'engin')]

>> Stemming using Snowball Stemmer: 
 [('Marketing', 'market'), ('', ''), (',', ','), ('Journal', 'journal'), ('Software', 'softwar'), ('Engineering', 'engin')]

>> Lemmatization: 
 [('Marketing', 'Marketing'), ('', ''), (',', ','), ('Journal', 'Journal'), ('Software', 'Software'), ('Engineering', 'Engineering')]



========================================== PARAGRAPH 623 ===========================================

Applications, Vol. 6, No. 4, pp. 196-206, 2013.  

------------------- Sentence 1 -------------------

Applications, Vol.

>> Tokens are: 
 ['Applications', ',', 'Vol', '.']

>> Bigrams are: 
 [('Applications', ','), (',', 'Vol'), ('Vol', '.')]

>> Trigrams are: 
 [('Applications', ',', 'Vol'), (',', 'Vol', '.')]

>> POS Tags are: 
 [('Applications', 'NNS'), (',', ','), ('Vol', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Applications', 'Vol']

>> Named Entities are: 
 [('PERSON', 'Vol')] 

>> Stemming using Porter Stemmer: 
 [('Applications', 'applic'), (',', ','), ('Vol', 'vol'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Applications', 'applic'), (',', ','), ('Vol', 'vol'), ('.', '.')]

>> Lemmatization: 
 [('Applications', 'Applications'), (',', ','), ('Vol', 'Vol'), ('.', '.')]


------------------- Sentence 2 -------------------

6, No.

>> Tokens are: 
 ['6', ',', 'No', '.']

>> Bigrams are: 
 [('6', ','), (',', 'No'), ('No', '.')]

>> Trigrams are: 
 [('6', ',', 'No'), (',', 'No', '.')]

>> POS Tags are: 
 [('6', 'CD'), (',', ','), ('No', 'DT'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('6', '6'), (',', ','), ('No', 'no'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('6', '6'), (',', ','), ('No', 'no'), ('.', '.')]

>> Lemmatization: 
 [('6', '6'), (',', ','), ('No', 'No'), ('.', '.')]


------------------- Sentence 3 -------------------

4, pp.

>> Tokens are: 
 ['4', ',', 'pp', '.']

>> Bigrams are: 
 [('4', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('4', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('4', 'CD'), (',', ','), ('pp', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['pp']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('4', '4'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('4', '4'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('4', '4'), (',', ','), ('pp', 'pp'), ('.', '.')]


------------------- Sentence 4 -------------------

196-206, 2013.

>> Tokens are: 
 ['196-206', ',', '2013', '.']

>> Bigrams are: 
 [('196-206', ','), (',', '2013'), ('2013', '.')]

>> Trigrams are: 
 [('196-206', ',', '2013'), (',', '2013', '.')]

>> POS Tags are: 
 [('196-206', 'CD'), (',', ','), ('2013', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('196-206', '196-206'), (',', ','), ('2013', '2013'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('196-206', '196-206'), (',', ','), ('2013', '2013'), ('.', '.')]

>> Lemmatization: 
 [('196-206', '196-206'), (',', ','), ('2013', '2013'), ('.', '.')]



========================================== PARAGRAPH 624 ===========================================

[11] Earl B. Hunt, Janet Marin and Philip J. Stone, Experiments  in Induction, New York: Academic Press, 1966.  

------------------- Sentence 1 -------------------

[11] Earl B.

>> Tokens are: 
 ['[', '11', ']', 'Earl', 'B', '.']

>> Bigrams are: 
 [('[', '11'), ('11', ']'), (']', 'Earl'), ('Earl', 'B'), ('B', '.')]

>> Trigrams are: 
 [('[', '11', ']'), ('11', ']', 'Earl'), (']', 'Earl', 'B'), ('Earl', 'B', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('11', 'CD'), (']', 'JJ'), ('Earl', 'NNP'), ('B', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['] Earl B']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('11', '11'), (']', ']'), ('Earl', 'earl'), ('B', 'b'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('11', '11'), (']', ']'), ('Earl', 'earl'), ('B', 'b'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('11', '11'), (']', ']'), ('Earl', 'Earl'), ('B', 'B'), ('.', '.')]


------------------- Sentence 2 -------------------

Hunt, Janet Marin and Philip J.

>> Tokens are: 
 ['Hunt', ',', 'Janet', 'Marin', 'Philip', 'J', '.']

>> Bigrams are: 
 [('Hunt', ','), (',', 'Janet'), ('Janet', 'Marin'), ('Marin', 'Philip'), ('Philip', 'J'), ('J', '.')]

>> Trigrams are: 
 [('Hunt', ',', 'Janet'), (',', 'Janet', 'Marin'), ('Janet', 'Marin', 'Philip'), ('Marin', 'Philip', 'J'), ('Philip', 'J', '.')]

>> POS Tags are: 
 [('Hunt', 'NNP'), (',', ','), ('Janet', 'NNP'), ('Marin', 'NNP'), ('Philip', 'NNP'), ('J', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Hunt', 'Janet Marin Philip J']

>> Named Entities are: 
 [('GPE', 'Hunt'), ('PERSON', 'Janet Marin Philip J')] 

>> Stemming using Porter Stemmer: 
 [('Hunt', 'hunt'), (',', ','), ('Janet', 'janet'), ('Marin', 'marin'), ('Philip', 'philip'), ('J', 'j'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Hunt', 'hunt'), (',', ','), ('Janet', 'janet'), ('Marin', 'marin'), ('Philip', 'philip'), ('J', 'j'), ('.', '.')]

>> Lemmatization: 
 [('Hunt', 'Hunt'), (',', ','), ('Janet', 'Janet'), ('Marin', 'Marin'), ('Philip', 'Philip'), ('J', 'J'), ('.', '.')]


------------------- Sentence 3 -------------------

Stone, Experiments  in Induction, New York: Academic Press, 1966.

>> Tokens are: 
 ['Stone', ',', '', 'Experiments', 'Induction', '', ',', 'New', 'York', ':', 'Academic', 'Press', ',', '1966', '.']

>> Bigrams are: 
 [('Stone', ','), (',', ''), ('', 'Experiments'), ('Experiments', 'Induction'), ('Induction', ''), ('', ','), (',', 'New'), ('New', 'York'), ('York', ':'), (':', 'Academic'), ('Academic', 'Press'), ('Press', ','), (',', '1966'), ('1966', '.')]

>> Trigrams are: 
 [('Stone', ',', ''), (',', '', 'Experiments'), ('', 'Experiments', 'Induction'), ('Experiments', 'Induction', ''), ('Induction', '', ','), ('', ',', 'New'), (',', 'New', 'York'), ('New', 'York', ':'), ('York', ':', 'Academic'), (':', 'Academic', 'Press'), ('Academic', 'Press', ','), ('Press', ',', '1966'), (',', '1966', '.')]

>> POS Tags are: 
 [('Stone', 'NN'), (',', ','), ('', 'JJ'), ('Experiments', 'NNPS'), ('Induction', 'NNP'), ('', 'NNP'), (',', ','), ('New', 'NNP'), ('York', 'NNP'), (':', ':'), ('Academic', 'JJ'), ('Press', 'NNP'), (',', ','), ('1966', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Stone', 'Induction ', 'New York', 'Academic Press']

>> Named Entities are: 
 [('GPE', 'Stone'), ('ORGANIZATION', 'Experiments Induction'), ('GPE', 'New York'), ('ORGANIZATION', 'Academic Press')] 

>> Stemming using Porter Stemmer: 
 [('Stone', 'stone'), (',', ','), ('', ''), ('Experiments', 'experi'), ('Induction', 'induct'), ('', ''), (',', ','), ('New', 'new'), ('York', 'york'), (':', ':'), ('Academic', 'academ'), ('Press', 'press'), (',', ','), ('1966', '1966'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Stone', 'stone'), (',', ','), ('', ''), ('Experiments', 'experi'), ('Induction', 'induct'), ('', ''), (',', ','), ('New', 'new'), ('York', 'york'), (':', ':'), ('Academic', 'academ'), ('Press', 'press'), (',', ','), ('1966', '1966'), ('.', '.')]

>> Lemmatization: 
 [('Stone', 'Stone'), (',', ','), ('', ''), ('Experiments', 'Experiments'), ('Induction', 'Induction'), ('', ''), (',', ','), ('New', 'New'), ('York', 'York'), (':', ':'), ('Academic', 'Academic'), ('Press', 'Press'), (',', ','), ('1966', '1966'), ('.', '.')]



========================================== PARAGRAPH 625 ===========================================

[12] Leo Breiman, Jerome Friedman, Charles J. Stone and R. A.  Olshen, Classification and Regression Trees (Wadsworth  

------------------- Sentence 1 -------------------

[12] Leo Breiman, Jerome Friedman, Charles J.

>> Tokens are: 
 ['[', '12', ']', 'Leo', 'Breiman', ',', 'Jerome', 'Friedman', ',', 'Charles', 'J', '.']

>> Bigrams are: 
 [('[', '12'), ('12', ']'), (']', 'Leo'), ('Leo', 'Breiman'), ('Breiman', ','), (',', 'Jerome'), ('Jerome', 'Friedman'), ('Friedman', ','), (',', 'Charles'), ('Charles', 'J'), ('J', '.')]

>> Trigrams are: 
 [('[', '12', ']'), ('12', ']', 'Leo'), (']', 'Leo', 'Breiman'), ('Leo', 'Breiman', ','), ('Breiman', ',', 'Jerome'), (',', 'Jerome', 'Friedman'), ('Jerome', 'Friedman', ','), ('Friedman', ',', 'Charles'), (',', 'Charles', 'J'), ('Charles', 'J', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('12', 'CD'), (']', 'JJ'), ('Leo', 'NNP'), ('Breiman', 'NNP'), (',', ','), ('Jerome', 'NNP'), ('Friedman', 'NNP'), (',', ','), ('Charles', 'NNP'), ('J', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['] Leo Breiman', 'Jerome Friedman', 'Charles J']

>> Named Entities are: 
 [('PERSON', 'Leo Breiman'), ('PERSON', 'Jerome Friedman'), ('PERSON', 'Charles J')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('12', '12'), (']', ']'), ('Leo', 'leo'), ('Breiman', 'breiman'), (',', ','), ('Jerome', 'jerom'), ('Friedman', 'friedman'), (',', ','), ('Charles', 'charl'), ('J', 'j'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('12', '12'), (']', ']'), ('Leo', 'leo'), ('Breiman', 'breiman'), (',', ','), ('Jerome', 'jerom'), ('Friedman', 'friedman'), (',', ','), ('Charles', 'charl'), ('J', 'j'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('12', '12'), (']', ']'), ('Leo', 'Leo'), ('Breiman', 'Breiman'), (',', ','), ('Jerome', 'Jerome'), ('Friedman', 'Friedman'), (',', ','), ('Charles', 'Charles'), ('J', 'J'), ('.', '.')]


------------------- Sentence 2 -------------------

Stone and R. A.  Olshen, Classification and Regression Trees (Wadsworth

>> Tokens are: 
 ['Stone', 'R.', 'A.', 'Olshen', ',', '', 'Classification', 'Regression', 'Trees', '(', 'Wadsworth']

>> Bigrams are: 
 [('Stone', 'R.'), ('R.', 'A.'), ('A.', 'Olshen'), ('Olshen', ','), (',', ''), ('', 'Classification'), ('Classification', 'Regression'), ('Regression', 'Trees'), ('Trees', '('), ('(', 'Wadsworth')]

>> Trigrams are: 
 [('Stone', 'R.', 'A.'), ('R.', 'A.', 'Olshen'), ('A.', 'Olshen', ','), ('Olshen', ',', ''), (',', '', 'Classification'), ('', 'Classification', 'Regression'), ('Classification', 'Regression', 'Trees'), ('Regression', 'Trees', '('), ('Trees', '(', 'Wadsworth')]

>> POS Tags are: 
 [('Stone', 'NNP'), ('R.', 'NNP'), ('A.', 'NN'), ('Olshen', 'NNP'), (',', ','), ('', 'NNP'), ('Classification', 'NNP'), ('Regression', 'NNP'), ('Trees', 'NNP'), ('(', '('), ('Wadsworth', 'NNP')]

>> Noun Phrases are: 
 ['Stone R. A. Olshen', ' Classification Regression Trees', 'Wadsworth']

>> Named Entities are: 
 [('PERSON', 'Stone'), ('PERSON', 'Olshen'), ('ORGANIZATION', 'Wadsworth')] 

>> Stemming using Porter Stemmer: 
 [('Stone', 'stone'), ('R.', 'r.'), ('A.', 'a.'), ('Olshen', 'olshen'), (',', ','), ('', ''), ('Classification', 'classif'), ('Regression', 'regress'), ('Trees', 'tree'), ('(', '('), ('Wadsworth', 'wadsworth')]

>> Stemming using Snowball Stemmer: 
 [('Stone', 'stone'), ('R.', 'r.'), ('A.', 'a.'), ('Olshen', 'olshen'), (',', ','), ('', ''), ('Classification', 'classif'), ('Regression', 'regress'), ('Trees', 'tree'), ('(', '('), ('Wadsworth', 'wadsworth')]

>> Lemmatization: 
 [('Stone', 'Stone'), ('R.', 'R.'), ('A.', 'A.'), ('Olshen', 'Olshen'), (',', ','), ('', ''), ('Classification', 'Classification'), ('Regression', 'Regression'), ('Trees', 'Trees'), ('(', '('), ('Wadsworth', 'Wadsworth')]



========================================== PARAGRAPH 626 ===========================================

Statistics/Probability), Chapman and Hall/CRC, 1984.  

------------------- Sentence 1 -------------------

Statistics/Probability), Chapman and Hall/CRC, 1984.

>> Tokens are: 
 ['Statistics/Probability', ')', '', ',', 'Chapman', 'Hall/CRC', ',', '1984', '.']

>> Bigrams are: 
 [('Statistics/Probability', ')'), (')', ''), ('', ','), (',', 'Chapman'), ('Chapman', 'Hall/CRC'), ('Hall/CRC', ','), (',', '1984'), ('1984', '.')]

>> Trigrams are: 
 [('Statistics/Probability', ')', ''), (')', '', ','), ('', ',', 'Chapman'), (',', 'Chapman', 'Hall/CRC'), ('Chapman', 'Hall/CRC', ','), ('Hall/CRC', ',', '1984'), (',', '1984', '.')]

>> POS Tags are: 
 [('Statistics/Probability', 'NN'), (')', ')'), ('', 'NN'), (',', ','), ('Chapman', 'NNP'), ('Hall/CRC', 'NNP'), (',', ','), ('1984', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Statistics/Probability', '', 'Chapman Hall/CRC']

>> Named Entities are: 
 [('PERSON', 'Chapman Hall/CRC')] 

>> Stemming using Porter Stemmer: 
 [('Statistics/Probability', 'statistics/prob'), (')', ')'), ('', ''), (',', ','), ('Chapman', 'chapman'), ('Hall/CRC', 'hall/crc'), (',', ','), ('1984', '1984'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Statistics/Probability', 'statistics/prob'), (')', ')'), ('', ''), (',', ','), ('Chapman', 'chapman'), ('Hall/CRC', 'hall/crc'), (',', ','), ('1984', '1984'), ('.', '.')]

>> Lemmatization: 
 [('Statistics/Probability', 'Statistics/Probability'), (')', ')'), ('', ''), (',', ','), ('Chapman', 'Chapman'), ('Hall/CRC', 'Hall/CRC'), (',', ','), ('1984', '1984'), ('.', '.')]



========================================== PARAGRAPH 627 ===========================================

[13] Steven L. Salzberg, Book Review: C4.5: Programs for  Machine Learning by J. Ross Quinlan. Inc., 1993,  

------------------- Sentence 1 -------------------

[13] Steven L. Salzberg, Book Review: C4.5: Programs for  Machine Learning by J. Ross Quinlan.

>> Tokens are: 
 ['[', '13', ']', 'Steven', 'L.', 'Salzberg', ',', '', 'Book', 'Review', ':', 'C4.5', ':', 'Programs', 'Machine', 'Learning', 'J.', 'Ross', 'Quinlan', '.']

>> Bigrams are: 
 [('[', '13'), ('13', ']'), (']', 'Steven'), ('Steven', 'L.'), ('L.', 'Salzberg'), ('Salzberg', ','), (',', ''), ('', 'Book'), ('Book', 'Review'), ('Review', ':'), (':', 'C4.5'), ('C4.5', ':'), (':', 'Programs'), ('Programs', 'Machine'), ('Machine', 'Learning'), ('Learning', 'J.'), ('J.', 'Ross'), ('Ross', 'Quinlan'), ('Quinlan', '.')]

>> Trigrams are: 
 [('[', '13', ']'), ('13', ']', 'Steven'), (']', 'Steven', 'L.'), ('Steven', 'L.', 'Salzberg'), ('L.', 'Salzberg', ','), ('Salzberg', ',', ''), (',', '', 'Book'), ('', 'Book', 'Review'), ('Book', 'Review', ':'), ('Review', ':', 'C4.5'), (':', 'C4.5', ':'), ('C4.5', ':', 'Programs'), (':', 'Programs', 'Machine'), ('Programs', 'Machine', 'Learning'), ('Machine', 'Learning', 'J.'), ('Learning', 'J.', 'Ross'), ('J.', 'Ross', 'Quinlan'), ('Ross', 'Quinlan', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('13', 'CD'), (']', 'JJ'), ('Steven', 'NNP'), ('L.', 'NNP'), ('Salzberg', 'NNP'), (',', ','), ('', 'NNP'), ('Book', 'NNP'), ('Review', 'NNP'), (':', ':'), ('C4.5', 'NN'), (':', ':'), ('Programs', 'NNP'), ('Machine', 'NNP'), ('Learning', 'NNP'), ('J.', 'NNP'), ('Ross', 'NNP'), ('Quinlan', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['] Steven L. Salzberg', ' Book Review', 'C4.5', 'Programs Machine Learning J. Ross Quinlan']

>> Named Entities are: 
 [('PERSON', 'Steven L. Salzberg'), ('PERSON', 'Machine Learning J. Ross Quinlan')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('13', '13'), (']', ']'), ('Steven', 'steven'), ('L.', 'l.'), ('Salzberg', 'salzberg'), (',', ','), ('', ''), ('Book', 'book'), ('Review', 'review'), (':', ':'), ('C4.5', 'c4.5'), (':', ':'), ('Programs', 'program'), ('Machine', 'machin'), ('Learning', 'learn'), ('J.', 'j.'), ('Ross', 'ross'), ('Quinlan', 'quinlan'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('13', '13'), (']', ']'), ('Steven', 'steven'), ('L.', 'l.'), ('Salzberg', 'salzberg'), (',', ','), ('', ''), ('Book', 'book'), ('Review', 'review'), (':', ':'), ('C4.5', 'c4.5'), (':', ':'), ('Programs', 'program'), ('Machine', 'machin'), ('Learning', 'learn'), ('J.', 'j.'), ('Ross', 'ross'), ('Quinlan', 'quinlan'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('13', '13'), (']', ']'), ('Steven', 'Steven'), ('L.', 'L.'), ('Salzberg', 'Salzberg'), (',', ','), ('', ''), ('Book', 'Book'), ('Review', 'Review'), (':', ':'), ('C4.5', 'C4.5'), (':', ':'), ('Programs', 'Programs'), ('Machine', 'Machine'), ('Learning', 'Learning'), ('J.', 'J.'), ('Ross', 'Ross'), ('Quinlan', 'Quinlan'), ('.', '.')]


------------------- Sentence 2 -------------------

Inc., 1993,

>> Tokens are: 
 ['Inc.', ',', '1993', '', ',']

>> Bigrams are: 
 [('Inc.', ','), (',', '1993'), ('1993', ''), ('', ',')]

>> Trigrams are: 
 [('Inc.', ',', '1993'), (',', '1993', ''), ('1993', '', ',')]

>> POS Tags are: 
 [('Inc.', 'NNP'), (',', ','), ('1993', 'CD'), ('', 'NN'), (',', ',')]

>> Noun Phrases are: 
 ['Inc.', '']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Inc.', 'inc.'), (',', ','), ('1993', '1993'), ('', ''), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('Inc.', 'inc.'), (',', ','), ('1993', '1993'), ('', ''), (',', ',')]

>> Lemmatization: 
 [('Inc.', 'Inc.'), (',', ','), ('1993', '1993'), ('', ''), (',', ',')]



========================================== PARAGRAPH 628 ===========================================

Machine Learning, Vol. 16, No. 3, pp. 235-240, 1994.  

------------------- Sentence 1 -------------------

Machine Learning, Vol.

>> Tokens are: 
 ['Machine', 'Learning', ',', 'Vol', '.']

>> Bigrams are: 
 [('Machine', 'Learning'), ('Learning', ','), (',', 'Vol'), ('Vol', '.')]

>> Trigrams are: 
 [('Machine', 'Learning', ','), ('Learning', ',', 'Vol'), (',', 'Vol', '.')]

>> POS Tags are: 
 [('Machine', 'NN'), ('Learning', 'NNP'), (',', ','), ('Vol', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Machine Learning', 'Vol']

>> Named Entities are: 
 [('PERSON', 'Machine Learning'), ('PERSON', 'Vol')] 

>> Stemming using Porter Stemmer: 
 [('Machine', 'machin'), ('Learning', 'learn'), (',', ','), ('Vol', 'vol'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Machine', 'machin'), ('Learning', 'learn'), (',', ','), ('Vol', 'vol'), ('.', '.')]

>> Lemmatization: 
 [('Machine', 'Machine'), ('Learning', 'Learning'), (',', ','), ('Vol', 'Vol'), ('.', '.')]


------------------- Sentence 2 -------------------

16, No.

>> Tokens are: 
 ['16', ',', 'No', '.']

>> Bigrams are: 
 [('16', ','), (',', 'No'), ('No', '.')]

>> Trigrams are: 
 [('16', ',', 'No'), (',', 'No', '.')]

>> POS Tags are: 
 [('16', 'CD'), (',', ','), ('No', 'DT'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('16', '16'), (',', ','), ('No', 'no'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('16', '16'), (',', ','), ('No', 'no'), ('.', '.')]

>> Lemmatization: 
 [('16', '16'), (',', ','), ('No', 'No'), ('.', '.')]


------------------- Sentence 3 -------------------

3, pp.

>> Tokens are: 
 ['3', ',', 'pp', '.']

>> Bigrams are: 
 [('3', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('3', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('3', 'CD'), (',', ','), ('pp', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['pp']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('3', '3'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('3', '3'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('3', '3'), (',', ','), ('pp', 'pp'), ('.', '.')]


------------------- Sentence 4 -------------------

235-240, 1994.

>> Tokens are: 
 ['235-240', ',', '1994', '.']

>> Bigrams are: 
 [('235-240', ','), (',', '1994'), ('1994', '.')]

>> Trigrams are: 
 [('235-240', ',', '1994'), (',', '1994', '.')]

>> POS Tags are: 
 [('235-240', 'CD'), (',', ','), ('1994', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('235-240', '235-240'), (',', ','), ('1994', '1994'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('235-240', '235-240'), (',', ','), ('1994', '1994'), ('.', '.')]

>> Lemmatization: 
 [('235-240', '235-240'), (',', ','), ('1994', '1994'), ('.', '.')]



========================================== PARAGRAPH 629 ===========================================

[14] Johannes Frnkranz, Separate-and-Conquer Rule Learning,  Artificial Intelligence Review, Vol. 13, pp. 3-54, 1999.  

------------------- Sentence 1 -------------------

[14] Johannes Frnkranz, Separate-and-Conquer Rule Learning,  Artificial Intelligence Review, Vol.

>> Tokens are: 
 ['[', '14', ']', 'Johannes', 'Frnkranz', ',', '', 'Separate-and-Conquer', 'Rule', 'Learning', '', ',', 'Artificial', 'Intelligence', 'Review', ',', 'Vol', '.']

>> Bigrams are: 
 [('[', '14'), ('14', ']'), (']', 'Johannes'), ('Johannes', 'Frnkranz'), ('Frnkranz', ','), (',', ''), ('', 'Separate-and-Conquer'), ('Separate-and-Conquer', 'Rule'), ('Rule', 'Learning'), ('Learning', ''), ('', ','), (',', 'Artificial'), ('Artificial', 'Intelligence'), ('Intelligence', 'Review'), ('Review', ','), (',', 'Vol'), ('Vol', '.')]

>> Trigrams are: 
 [('[', '14', ']'), ('14', ']', 'Johannes'), (']', 'Johannes', 'Frnkranz'), ('Johannes', 'Frnkranz', ','), ('Frnkranz', ',', ''), (',', '', 'Separate-and-Conquer'), ('', 'Separate-and-Conquer', 'Rule'), ('Separate-and-Conquer', 'Rule', 'Learning'), ('Rule', 'Learning', ''), ('Learning', '', ','), ('', ',', 'Artificial'), (',', 'Artificial', 'Intelligence'), ('Artificial', 'Intelligence', 'Review'), ('Intelligence', 'Review', ','), ('Review', ',', 'Vol'), (',', 'Vol', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('14', 'CD'), (']', 'JJ'), ('Johannes', 'NNPS'), ('Frnkranz', 'NNP'), (',', ','), ('', 'NNP'), ('Separate-and-Conquer', 'NNP'), ('Rule', 'NNP'), ('Learning', 'NNP'), ('', 'NNP'), (',', ','), ('Artificial', 'NNP'), ('Intelligence', 'NNP'), ('Review', 'NNP'), (',', ','), ('Vol', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Frnkranz', ' Separate-and-Conquer Rule Learning ', 'Artificial Intelligence Review', 'Vol']

>> Named Entities are: 
 [('PERSON', 'Johannes Frnkranz'), ('ORGANIZATION', 'Artificial Intelligence Review'), ('PERSON', 'Vol')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('14', '14'), (']', ']'), ('Johannes', 'johann'), ('Frnkranz', 'frnkranz'), (',', ','), ('', ''), ('Separate-and-Conquer', 'separate-and-conqu'), ('Rule', 'rule'), ('Learning', 'learn'), ('', ''), (',', ','), ('Artificial', 'artifici'), ('Intelligence', 'intellig'), ('Review', 'review'), (',', ','), ('Vol', 'vol'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('14', '14'), (']', ']'), ('Johannes', 'johann'), ('Frnkranz', 'frnkranz'), (',', ','), ('', ''), ('Separate-and-Conquer', 'separate-and-conqu'), ('Rule', 'rule'), ('Learning', 'learn'), ('', ''), (',', ','), ('Artificial', 'artifici'), ('Intelligence', 'intellig'), ('Review', 'review'), (',', ','), ('Vol', 'vol'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('14', '14'), (']', ']'), ('Johannes', 'Johannes'), ('Frnkranz', 'Frnkranz'), (',', ','), ('', ''), ('Separate-and-Conquer', 'Separate-and-Conquer'), ('Rule', 'Rule'), ('Learning', 'Learning'), ('', ''), (',', ','), ('Artificial', 'Artificial'), ('Intelligence', 'Intelligence'), ('Review', 'Review'), (',', ','), ('Vol', 'Vol'), ('.', '.')]


------------------- Sentence 2 -------------------

13, pp.

>> Tokens are: 
 ['13', ',', 'pp', '.']

>> Bigrams are: 
 [('13', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('13', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('13', 'CD'), (',', ','), ('pp', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['pp']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('13', '13'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('13', '13'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('13', '13'), (',', ','), ('pp', 'pp'), ('.', '.')]


------------------- Sentence 3 -------------------

3-54, 1999.

>> Tokens are: 
 ['3-54', ',', '1999', '.']

>> Bigrams are: 
 [('3-54', ','), (',', '1999'), ('1999', '.')]

>> Trigrams are: 
 [('3-54', ',', '1999'), (',', '1999', '.')]

>> POS Tags are: 
 [('3-54', 'CD'), (',', ','), ('1999', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('3-54', '3-54'), (',', ','), ('1999', '1999'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('3-54', '3-54'), (',', ','), ('1999', '1999'), ('.', '.')]

>> Lemmatization: 
 [('3-54', '3-54'), (',', ','), ('1999', '1999'), ('.', '.')]



========================================== PARAGRAPH 630 ===========================================

[15] Aijun An and Nick Cercone, Discretization of continuous  attributes for learning classification rules, Third Pacific- 

------------------- Sentence 1 -------------------

[15] Aijun An and Nick Cercone, Discretization of continuous  attributes for learning classification rules, Third Pacific-

>> Tokens are: 
 ['[', '15', ']', 'Aijun', 'An', 'Nick', 'Cercone', ',', '', 'Discretization', 'continuous', 'attributes', 'learning', 'classification', 'rules', '', ',', 'Third', 'Pacific-']

>> Bigrams are: 
 [('[', '15'), ('15', ']'), (']', 'Aijun'), ('Aijun', 'An'), ('An', 'Nick'), ('Nick', 'Cercone'), ('Cercone', ','), (',', ''), ('', 'Discretization'), ('Discretization', 'continuous'), ('continuous', 'attributes'), ('attributes', 'learning'), ('learning', 'classification'), ('classification', 'rules'), ('rules', ''), ('', ','), (',', 'Third'), ('Third', 'Pacific-')]

>> Trigrams are: 
 [('[', '15', ']'), ('15', ']', 'Aijun'), (']', 'Aijun', 'An'), ('Aijun', 'An', 'Nick'), ('An', 'Nick', 'Cercone'), ('Nick', 'Cercone', ','), ('Cercone', ',', ''), (',', '', 'Discretization'), ('', 'Discretization', 'continuous'), ('Discretization', 'continuous', 'attributes'), ('continuous', 'attributes', 'learning'), ('attributes', 'learning', 'classification'), ('learning', 'classification', 'rules'), ('classification', 'rules', ''), ('rules', '', ','), ('', ',', 'Third'), (',', 'Third', 'Pacific-')]

>> POS Tags are: 
 [('[', 'RB'), ('15', 'CD'), (']', 'NNP'), ('Aijun', 'NNP'), ('An', 'DT'), ('Nick', 'NNP'), ('Cercone', 'NNP'), (',', ','), ('', 'NNP'), ('Discretization', 'NNP'), ('continuous', 'JJ'), ('attributes', 'NNS'), ('learning', 'VBG'), ('classification', 'NN'), ('rules', 'NNS'), ('', 'VBP'), (',', ','), ('Third', 'JJ'), ('Pacific-', 'NNP')]

>> Noun Phrases are: 
 ['] Aijun', 'An Nick Cercone', ' Discretization', 'continuous attributes', 'classification rules', 'Third Pacific-']

>> Named Entities are: 
 [('PERSON', 'Nick Cercone'), ('PERSON', 'Third Pacific-')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('15', '15'), (']', ']'), ('Aijun', 'aijun'), ('An', 'an'), ('Nick', 'nick'), ('Cercone', 'cercon'), (',', ','), ('', ''), ('Discretization', 'discret'), ('continuous', 'continu'), ('attributes', 'attribut'), ('learning', 'learn'), ('classification', 'classif'), ('rules', 'rule'), ('', ''), (',', ','), ('Third', 'third'), ('Pacific-', 'pacific-')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('15', '15'), (']', ']'), ('Aijun', 'aijun'), ('An', 'an'), ('Nick', 'nick'), ('Cercone', 'cercon'), (',', ','), ('', ''), ('Discretization', 'discret'), ('continuous', 'continu'), ('attributes', 'attribut'), ('learning', 'learn'), ('classification', 'classif'), ('rules', 'rule'), ('', ''), (',', ','), ('Third', 'third'), ('Pacific-', 'pacific-')]

>> Lemmatization: 
 [('[', '['), ('15', '15'), (']', ']'), ('Aijun', 'Aijun'), ('An', 'An'), ('Nick', 'Nick'), ('Cercone', 'Cercone'), (',', ','), ('', ''), ('Discretization', 'Discretization'), ('continuous', 'continuous'), ('attributes', 'attribute'), ('learning', 'learning'), ('classification', 'classification'), ('rules', 'rule'), ('', ''), (',', ','), ('Third', 'Third'), ('Pacific-', 'Pacific-')]



========================================== PARAGRAPH 631 ===========================================

Asia Conference on Methodologies for Knowledge  

------------------- Sentence 1 -------------------

Asia Conference on Methodologies for Knowledge

>> Tokens are: 
 ['Asia', 'Conference', 'Methodologies', 'Knowledge']

>> Bigrams are: 
 [('Asia', 'Conference'), ('Conference', 'Methodologies'), ('Methodologies', 'Knowledge')]

>> Trigrams are: 
 [('Asia', 'Conference', 'Methodologies'), ('Conference', 'Methodologies', 'Knowledge')]

>> POS Tags are: 
 [('Asia', 'NNP'), ('Conference', 'NNP'), ('Methodologies', 'NNP'), ('Knowledge', 'NNP')]

>> Noun Phrases are: 
 ['Asia Conference Methodologies Knowledge']

>> Named Entities are: 
 [('GPE', 'Asia'), ('ORGANIZATION', 'Conference Methodologies')] 

>> Stemming using Porter Stemmer: 
 [('Asia', 'asia'), ('Conference', 'confer'), ('Methodologies', 'methodolog'), ('Knowledge', 'knowledg')]

>> Stemming using Snowball Stemmer: 
 [('Asia', 'asia'), ('Conference', 'confer'), ('Methodologies', 'methodolog'), ('Knowledge', 'knowledg')]

>> Lemmatization: 
 [('Asia', 'Asia'), ('Conference', 'Conference'), ('Methodologies', 'Methodologies'), ('Knowledge', 'Knowledge')]



========================================== PARAGRAPH 632 ===========================================

Discovery & Data Mining, Vol. 1574, pp. 509-514, 1999.  

------------------- Sentence 1 -------------------

Discovery & Data Mining, Vol.

>> Tokens are: 
 ['Discovery', '&', 'Data', 'Mining', ',', 'Vol', '.']

>> Bigrams are: 
 [('Discovery', '&'), ('&', 'Data'), ('Data', 'Mining'), ('Mining', ','), (',', 'Vol'), ('Vol', '.')]

>> Trigrams are: 
 [('Discovery', '&', 'Data'), ('&', 'Data', 'Mining'), ('Data', 'Mining', ','), ('Mining', ',', 'Vol'), (',', 'Vol', '.')]

>> POS Tags are: 
 [('Discovery', 'NNP'), ('&', 'CC'), ('Data', 'NNP'), ('Mining', 'NNP'), (',', ','), ('Vol', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Discovery', 'Data Mining', 'Vol']

>> Named Entities are: 
 [('GPE', 'Discovery'), ('PERSON', 'Data Mining'), ('PERSON', 'Vol')] 

>> Stemming using Porter Stemmer: 
 [('Discovery', 'discoveri'), ('&', '&'), ('Data', 'data'), ('Mining', 'mine'), (',', ','), ('Vol', 'vol'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Discovery', 'discoveri'), ('&', '&'), ('Data', 'data'), ('Mining', 'mine'), (',', ','), ('Vol', 'vol'), ('.', '.')]

>> Lemmatization: 
 [('Discovery', 'Discovery'), ('&', '&'), ('Data', 'Data'), ('Mining', 'Mining'), (',', ','), ('Vol', 'Vol'), ('.', '.')]


------------------- Sentence 2 -------------------

1574, pp.

>> Tokens are: 
 ['1574', ',', 'pp', '.']

>> Bigrams are: 
 [('1574', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('1574', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('1574', 'CD'), (',', ','), ('pp', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['pp']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('1574', '1574'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('1574', '1574'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('1574', '1574'), (',', ','), ('pp', 'pp'), ('.', '.')]


------------------- Sentence 3 -------------------

509-514, 1999.

>> Tokens are: 
 ['509-514', ',', '1999', '.']

>> Bigrams are: 
 [('509-514', ','), (',', '1999'), ('1999', '.')]

>> Trigrams are: 
 [('509-514', ',', '1999'), (',', '1999', '.')]

>> POS Tags are: 
 [('509-514', 'CD'), (',', ','), ('1999', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('509-514', '509-514'), (',', ','), ('1999', '1999'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('509-514', '509-514'), (',', ','), ('1999', '1999'), ('.', '.')]

>> Lemmatization: 
 [('509-514', '509-514'), (',', ','), ('1999', '1999'), ('.', '.')]



========================================== PARAGRAPH 633 ===========================================

[16] Mehryar Mohri, Afshin Rostamizadeh and Ameet  Talwalkar, Foundations of Machine Learning, One  

------------------- Sentence 1 -------------------

[16] Mehryar Mohri, Afshin Rostamizadeh and Ameet  Talwalkar, Foundations of Machine Learning, One

>> Tokens are: 
 ['[', '16', ']', 'Mehryar', 'Mohri', ',', 'Afshin', 'Rostamizadeh', 'Ameet', 'Talwalkar', ',', '', 'Foundations', 'Machine', 'Learning', '', ',', 'One']

>> Bigrams are: 
 [('[', '16'), ('16', ']'), (']', 'Mehryar'), ('Mehryar', 'Mohri'), ('Mohri', ','), (',', 'Afshin'), ('Afshin', 'Rostamizadeh'), ('Rostamizadeh', 'Ameet'), ('Ameet', 'Talwalkar'), ('Talwalkar', ','), (',', ''), ('', 'Foundations'), ('Foundations', 'Machine'), ('Machine', 'Learning'), ('Learning', ''), ('', ','), (',', 'One')]

>> Trigrams are: 
 [('[', '16', ']'), ('16', ']', 'Mehryar'), (']', 'Mehryar', 'Mohri'), ('Mehryar', 'Mohri', ','), ('Mohri', ',', 'Afshin'), (',', 'Afshin', 'Rostamizadeh'), ('Afshin', 'Rostamizadeh', 'Ameet'), ('Rostamizadeh', 'Ameet', 'Talwalkar'), ('Ameet', 'Talwalkar', ','), ('Talwalkar', ',', ''), (',', '', 'Foundations'), ('', 'Foundations', 'Machine'), ('Foundations', 'Machine', 'Learning'), ('Machine', 'Learning', ''), ('Learning', '', ','), ('', ',', 'One')]

>> POS Tags are: 
 [('[', 'RB'), ('16', 'CD'), (']', 'JJ'), ('Mehryar', 'NNP'), ('Mohri', 'NNP'), (',', ','), ('Afshin', 'NNP'), ('Rostamizadeh', 'NNP'), ('Ameet', 'NNP'), ('Talwalkar', 'NNP'), (',', ','), ('', 'JJ'), ('Foundations', 'NNP'), ('Machine', 'NNP'), ('Learning', 'NNP'), ('', 'NNP'), (',', ','), ('One', 'CD')]

>> Noun Phrases are: 
 ['] Mehryar Mohri', 'Afshin Rostamizadeh Ameet Talwalkar', ' Foundations Machine Learning ']

>> Named Entities are: 
 [('PERSON', 'Mehryar Mohri'), ('PERSON', 'Afshin Rostamizadeh Ameet Talwalkar'), ('PERSON', 'Machine Learning')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('16', '16'), (']', ']'), ('Mehryar', 'mehryar'), ('Mohri', 'mohri'), (',', ','), ('Afshin', 'afshin'), ('Rostamizadeh', 'rostamizadeh'), ('Ameet', 'ameet'), ('Talwalkar', 'talwalkar'), (',', ','), ('', ''), ('Foundations', 'foundat'), ('Machine', 'machin'), ('Learning', 'learn'), ('', ''), (',', ','), ('One', 'one')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('16', '16'), (']', ']'), ('Mehryar', 'mehryar'), ('Mohri', 'mohri'), (',', ','), ('Afshin', 'afshin'), ('Rostamizadeh', 'rostamizadeh'), ('Ameet', 'ameet'), ('Talwalkar', 'talwalkar'), (',', ','), ('', ''), ('Foundations', 'foundat'), ('Machine', 'machin'), ('Learning', 'learn'), ('', ''), (',', ','), ('One', 'one')]

>> Lemmatization: 
 [('[', '['), ('16', '16'), (']', ']'), ('Mehryar', 'Mehryar'), ('Mohri', 'Mohri'), (',', ','), ('Afshin', 'Afshin'), ('Rostamizadeh', 'Rostamizadeh'), ('Ameet', 'Ameet'), ('Talwalkar', 'Talwalkar'), (',', ','), ('', ''), ('Foundations', 'Foundations'), ('Machine', 'Machine'), ('Learning', 'Learning'), ('', ''), (',', ','), ('One', 'One')]



========================================== PARAGRAPH 634 ===========================================

Rogers Street Cambridge MA: The MIT Press, 2012.  

------------------- Sentence 1 -------------------

Rogers Street Cambridge MA: The MIT Press, 2012.

>> Tokens are: 
 ['Rogers', 'Street', 'Cambridge', 'MA', ':', 'The', 'MIT', 'Press', ',', '2012', '.']

>> Bigrams are: 
 [('Rogers', 'Street'), ('Street', 'Cambridge'), ('Cambridge', 'MA'), ('MA', ':'), (':', 'The'), ('The', 'MIT'), ('MIT', 'Press'), ('Press', ','), (',', '2012'), ('2012', '.')]

>> Trigrams are: 
 [('Rogers', 'Street', 'Cambridge'), ('Street', 'Cambridge', 'MA'), ('Cambridge', 'MA', ':'), ('MA', ':', 'The'), (':', 'The', 'MIT'), ('The', 'MIT', 'Press'), ('MIT', 'Press', ','), ('Press', ',', '2012'), (',', '2012', '.')]

>> POS Tags are: 
 [('Rogers', 'NNP'), ('Street', 'NNP'), ('Cambridge', 'NNP'), ('MA', 'NNP'), (':', ':'), ('The', 'DT'), ('MIT', 'NNP'), ('Press', 'NNP'), (',', ','), ('2012', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Rogers Street Cambridge MA', 'The MIT Press']

>> Named Entities are: 
 [('GPE', 'Rogers'), ('PERSON', 'Street Cambridge'), ('ORGANIZATION', 'MIT')] 

>> Stemming using Porter Stemmer: 
 [('Rogers', 'roger'), ('Street', 'street'), ('Cambridge', 'cambridg'), ('MA', 'ma'), (':', ':'), ('The', 'the'), ('MIT', 'mit'), ('Press', 'press'), (',', ','), ('2012', '2012'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Rogers', 'roger'), ('Street', 'street'), ('Cambridge', 'cambridg'), ('MA', 'ma'), (':', ':'), ('The', 'the'), ('MIT', 'mit'), ('Press', 'press'), (',', ','), ('2012', '2012'), ('.', '.')]

>> Lemmatization: 
 [('Rogers', 'Rogers'), ('Street', 'Street'), ('Cambridge', 'Cambridge'), ('MA', 'MA'), (':', ':'), ('The', 'The'), ('MIT', 'MIT'), ('Press', 'Press'), (',', ','), ('2012', '2012'), ('.', '.')]



========================================== PARAGRAPH 635 ===========================================

[17] Olivier Bousquet, Stephane Boucheron and Gabor  Lugosi, Introduction to Statistical Learning Theory,  

------------------- Sentence 1 -------------------

[17] Olivier Bousquet, Stephane Boucheron and Gabor  Lugosi, Introduction to Statistical Learning Theory,

>> Tokens are: 
 ['[', '17', ']', 'Olivier', 'Bousquet', ',', 'Stephane', 'Boucheron', 'Gabor', 'Lugosi', ',', '', 'Introduction', 'Statistical', 'Learning', 'Theory', '', ',']

>> Bigrams are: 
 [('[', '17'), ('17', ']'), (']', 'Olivier'), ('Olivier', 'Bousquet'), ('Bousquet', ','), (',', 'Stephane'), ('Stephane', 'Boucheron'), ('Boucheron', 'Gabor'), ('Gabor', 'Lugosi'), ('Lugosi', ','), (',', ''), ('', 'Introduction'), ('Introduction', 'Statistical'), ('Statistical', 'Learning'), ('Learning', 'Theory'), ('Theory', ''), ('', ',')]

>> Trigrams are: 
 [('[', '17', ']'), ('17', ']', 'Olivier'), (']', 'Olivier', 'Bousquet'), ('Olivier', 'Bousquet', ','), ('Bousquet', ',', 'Stephane'), (',', 'Stephane', 'Boucheron'), ('Stephane', 'Boucheron', 'Gabor'), ('Boucheron', 'Gabor', 'Lugosi'), ('Gabor', 'Lugosi', ','), ('Lugosi', ',', ''), (',', '', 'Introduction'), ('', 'Introduction', 'Statistical'), ('Introduction', 'Statistical', 'Learning'), ('Statistical', 'Learning', 'Theory'), ('Learning', 'Theory', ''), ('Theory', '', ',')]

>> POS Tags are: 
 [('[', 'RB'), ('17', 'CD'), (']', 'NNS'), ('Olivier', 'NNP'), ('Bousquet', 'NNP'), (',', ','), ('Stephane', 'NNP'), ('Boucheron', 'NNP'), ('Gabor', 'NNP'), ('Lugosi', 'NNP'), (',', ','), ('', 'NNP'), ('Introduction', 'NNP'), ('Statistical', 'NNP'), ('Learning', 'NNP'), ('Theory', 'NNP'), ('', 'NNP'), (',', ',')]

>> Noun Phrases are: 
 ['] Olivier Bousquet', 'Stephane Boucheron Gabor Lugosi', ' Introduction Statistical Learning Theory ']

>> Named Entities are: 
 [('PERSON', 'Olivier Bousquet'), ('PERSON', 'Boucheron')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('17', '17'), (']', ']'), ('Olivier', 'olivi'), ('Bousquet', 'bousquet'), (',', ','), ('Stephane', 'stephan'), ('Boucheron', 'boucheron'), ('Gabor', 'gabor'), ('Lugosi', 'lugosi'), (',', ','), ('', ''), ('Introduction', 'introduct'), ('Statistical', 'statist'), ('Learning', 'learn'), ('Theory', 'theori'), ('', ''), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('17', '17'), (']', ']'), ('Olivier', 'olivi'), ('Bousquet', 'bousquet'), (',', ','), ('Stephane', 'stephan'), ('Boucheron', 'boucheron'), ('Gabor', 'gabor'), ('Lugosi', 'lugosi'), (',', ','), ('', ''), ('Introduction', 'introduct'), ('Statistical', 'statist'), ('Learning', 'learn'), ('Theory', 'theori'), ('', ''), (',', ',')]

>> Lemmatization: 
 [('[', '['), ('17', '17'), (']', ']'), ('Olivier', 'Olivier'), ('Bousquet', 'Bousquet'), (',', ','), ('Stephane', 'Stephane'), ('Boucheron', 'Boucheron'), ('Gabor', 'Gabor'), ('Lugosi', 'Lugosi'), (',', ','), ('', ''), ('Introduction', 'Introduction'), ('Statistical', 'Statistical'), ('Learning', 'Learning'), ('Theory', 'Theory'), ('', ''), (',', ',')]



========================================== PARAGRAPH 636 ===========================================

Lecture Notes in Computer Science, Vol. 3176, pp. 175- 

------------------- Sentence 1 -------------------

Lecture Notes in Computer Science, Vol.

>> Tokens are: 
 ['Lecture', 'Notes', 'Computer', 'Science', ',', 'Vol', '.']

>> Bigrams are: 
 [('Lecture', 'Notes'), ('Notes', 'Computer'), ('Computer', 'Science'), ('Science', ','), (',', 'Vol'), ('Vol', '.')]

>> Trigrams are: 
 [('Lecture', 'Notes', 'Computer'), ('Notes', 'Computer', 'Science'), ('Computer', 'Science', ','), ('Science', ',', 'Vol'), (',', 'Vol', '.')]

>> POS Tags are: 
 [('Lecture', 'NN'), ('Notes', 'VBZ'), ('Computer', 'NNP'), ('Science', 'NNP'), (',', ','), ('Vol', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Lecture', 'Computer Science', 'Vol']

>> Named Entities are: 
 [('GPE', 'Lecture'), ('PERSON', 'Notes Computer Science'), ('PERSON', 'Vol')] 

>> Stemming using Porter Stemmer: 
 [('Lecture', 'lectur'), ('Notes', 'note'), ('Computer', 'comput'), ('Science', 'scienc'), (',', ','), ('Vol', 'vol'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Lecture', 'lectur'), ('Notes', 'note'), ('Computer', 'comput'), ('Science', 'scienc'), (',', ','), ('Vol', 'vol'), ('.', '.')]

>> Lemmatization: 
 [('Lecture', 'Lecture'), ('Notes', 'Notes'), ('Computer', 'Computer'), ('Science', 'Science'), (',', ','), ('Vol', 'Vol'), ('.', '.')]


------------------- Sentence 2 -------------------

3176, pp.

>> Tokens are: 
 ['3176', ',', 'pp', '.']

>> Bigrams are: 
 [('3176', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('3176', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('3176', 'CD'), (',', ','), ('pp', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['pp']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('3176', '3176'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('3176', '3176'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('3176', '3176'), (',', ','), ('pp', 'pp'), ('.', '.')]


------------------- Sentence 3 -------------------

175-

>> Tokens are: 
 ['175-']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('175-', 'JJ')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('175-', '175-')]

>> Stemming using Snowball Stemmer: 
 [('175-', '175-')]

>> Lemmatization: 
 [('175-', '175-')]



========================================== PARAGRAPH 637 ===========================================

213, 2004.  

------------------- Sentence 1 -------------------

213, 2004.

>> Tokens are: 
 ['213', ',', '2004', '.']

>> Bigrams are: 
 [('213', ','), (',', '2004'), ('2004', '.')]

>> Trigrams are: 
 [('213', ',', '2004'), (',', '2004', '.')]

>> POS Tags are: 
 [('213', 'CD'), (',', ','), ('2004', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('213', '213'), (',', ','), ('2004', '2004'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('213', '213'), (',', ','), ('2004', '2004'), ('.', '.')]

>> Lemmatization: 
 [('213', '213'), (',', ','), ('2004', '2004'), ('.', '.')]



========================================== PARAGRAPH 638 ===========================================

[18] Olivier Pourret, Patrick Naim and Bruce Marcot, Bayesian  Networks: A Practical Guide to Applications, Wiley  

------------------- Sentence 1 -------------------

[18] Olivier Pourret, Patrick Naim and Bruce Marcot, Bayesian  Networks: A Practical Guide to Applications, Wiley

>> Tokens are: 
 ['[', '18', ']', 'Olivier', 'Pourret', ',', 'Patrick', 'Naim', 'Bruce', 'Marcot', ',', '', 'Bayesian', 'Networks', ':', 'A', 'Practical', 'Guide', 'Applications', '', ',', 'Wiley']

>> Bigrams are: 
 [('[', '18'), ('18', ']'), (']', 'Olivier'), ('Olivier', 'Pourret'), ('Pourret', ','), (',', 'Patrick'), ('Patrick', 'Naim'), ('Naim', 'Bruce'), ('Bruce', 'Marcot'), ('Marcot', ','), (',', ''), ('', 'Bayesian'), ('Bayesian', 'Networks'), ('Networks', ':'), (':', 'A'), ('A', 'Practical'), ('Practical', 'Guide'), ('Guide', 'Applications'), ('Applications', ''), ('', ','), (',', 'Wiley')]

>> Trigrams are: 
 [('[', '18', ']'), ('18', ']', 'Olivier'), (']', 'Olivier', 'Pourret'), ('Olivier', 'Pourret', ','), ('Pourret', ',', 'Patrick'), (',', 'Patrick', 'Naim'), ('Patrick', 'Naim', 'Bruce'), ('Naim', 'Bruce', 'Marcot'), ('Bruce', 'Marcot', ','), ('Marcot', ',', ''), (',', '', 'Bayesian'), ('', 'Bayesian', 'Networks'), ('Bayesian', 'Networks', ':'), ('Networks', ':', 'A'), (':', 'A', 'Practical'), ('A', 'Practical', 'Guide'), ('Practical', 'Guide', 'Applications'), ('Guide', 'Applications', ''), ('Applications', '', ','), ('', ',', 'Wiley')]

>> POS Tags are: 
 [('[', 'RB'), ('18', 'CD'), (']', 'NNS'), ('Olivier', 'NNP'), ('Pourret', 'NNP'), (',', ','), ('Patrick', 'NNP'), ('Naim', 'NNP'), ('Bruce', 'NNP'), ('Marcot', 'NNP'), (',', ','), ('', 'NNP'), ('Bayesian', 'NNP'), ('Networks', 'NNP'), (':', ':'), ('A', 'DT'), ('Practical', 'NNP'), ('Guide', 'NNP'), ('Applications', 'NNP'), ('', 'NNP'), (',', ','), ('Wiley', 'NNP')]

>> Noun Phrases are: 
 ['] Olivier Pourret', 'Patrick Naim Bruce Marcot', ' Bayesian Networks', 'A Practical Guide Applications ', 'Wiley']

>> Named Entities are: 
 [('PERSON', 'Olivier Pourret'), ('PERSON', 'Patrick Naim Bruce Marcot'), ('PERSON', 'Bayesian Networks'), ('ORGANIZATION', 'Practical Guide Applications'), ('PERSON', 'Wiley')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('18', '18'), (']', ']'), ('Olivier', 'olivi'), ('Pourret', 'pourret'), (',', ','), ('Patrick', 'patrick'), ('Naim', 'naim'), ('Bruce', 'bruce'), ('Marcot', 'marcot'), (',', ','), ('', ''), ('Bayesian', 'bayesian'), ('Networks', 'network'), (':', ':'), ('A', 'a'), ('Practical', 'practic'), ('Guide', 'guid'), ('Applications', 'applic'), ('', ''), (',', ','), ('Wiley', 'wiley')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('18', '18'), (']', ']'), ('Olivier', 'olivi'), ('Pourret', 'pourret'), (',', ','), ('Patrick', 'patrick'), ('Naim', 'naim'), ('Bruce', 'bruce'), ('Marcot', 'marcot'), (',', ','), ('', ''), ('Bayesian', 'bayesian'), ('Networks', 'network'), (':', ':'), ('A', 'a'), ('Practical', 'practic'), ('Guide', 'guid'), ('Applications', 'applic'), ('', ''), (',', ','), ('Wiley', 'wiley')]

>> Lemmatization: 
 [('[', '['), ('18', '18'), (']', ']'), ('Olivier', 'Olivier'), ('Pourret', 'Pourret'), (',', ','), ('Patrick', 'Patrick'), ('Naim', 'Naim'), ('Bruce', 'Bruce'), ('Marcot', 'Marcot'), (',', ','), ('', ''), ('Bayesian', 'Bayesian'), ('Networks', 'Networks'), (':', ':'), ('A', 'A'), ('Practical', 'Practical'), ('Guide', 'Guide'), ('Applications', 'Applications'), ('', ''), (',', ','), ('Wiley', 'Wiley')]



========================================== PARAGRAPH 639 ===========================================

Publishers, 2008.  

------------------- Sentence 1 -------------------

Publishers, 2008.

>> Tokens are: 
 ['Publishers', ',', '2008', '.']

>> Bigrams are: 
 [('Publishers', ','), (',', '2008'), ('2008', '.')]

>> Trigrams are: 
 [('Publishers', ',', '2008'), (',', '2008', '.')]

>> POS Tags are: 
 [('Publishers', 'NNS'), (',', ','), ('2008', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Publishers']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Publishers', 'publish'), (',', ','), ('2008', '2008'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Publishers', 'publish'), (',', ','), ('2008', '2008'), ('.', '.')]

>> Lemmatization: 
 [('Publishers', 'Publishers'), (',', ','), ('2008', '2008'), ('.', '.')]



========================================== PARAGRAPH 640 ===========================================

[19] Kamal Nigam, John Lafferty and Andrew McCallum,  Using Maximum Entropy for Text Classification,  

------------------- Sentence 1 -------------------

[19] Kamal Nigam, John Lafferty and Andrew McCallum,  Using Maximum Entropy for Text Classification,

>> Tokens are: 
 ['[', '19', ']', 'Kamal', 'Nigam', ',', 'John', 'Lafferty', 'Andrew', 'McCallum', ',', '', 'Using', 'Maximum', 'Entropy', 'Text', 'Classification', '', ',']

>> Bigrams are: 
 [('[', '19'), ('19', ']'), (']', 'Kamal'), ('Kamal', 'Nigam'), ('Nigam', ','), (',', 'John'), ('John', 'Lafferty'), ('Lafferty', 'Andrew'), ('Andrew', 'McCallum'), ('McCallum', ','), (',', ''), ('', 'Using'), ('Using', 'Maximum'), ('Maximum', 'Entropy'), ('Entropy', 'Text'), ('Text', 'Classification'), ('Classification', ''), ('', ',')]

>> Trigrams are: 
 [('[', '19', ']'), ('19', ']', 'Kamal'), (']', 'Kamal', 'Nigam'), ('Kamal', 'Nigam', ','), ('Nigam', ',', 'John'), (',', 'John', 'Lafferty'), ('John', 'Lafferty', 'Andrew'), ('Lafferty', 'Andrew', 'McCallum'), ('Andrew', 'McCallum', ','), ('McCallum', ',', ''), (',', '', 'Using'), ('', 'Using', 'Maximum'), ('Using', 'Maximum', 'Entropy'), ('Maximum', 'Entropy', 'Text'), ('Entropy', 'Text', 'Classification'), ('Text', 'Classification', ''), ('Classification', '', ',')]

>> POS Tags are: 
 [('[', 'RB'), ('19', 'CD'), (']', 'NNS'), ('Kamal', 'NNP'), ('Nigam', 'NNP'), (',', ','), ('John', 'NNP'), ('Lafferty', 'NNP'), ('Andrew', 'NNP'), ('McCallum', 'NNP'), (',', ','), ('', 'NNP'), ('Using', 'NNP'), ('Maximum', 'NNP'), ('Entropy', 'NNP'), ('Text', 'NNP'), ('Classification', 'NNP'), ('', 'NNP'), (',', ',')]

>> Noun Phrases are: 
 ['] Kamal Nigam', 'John Lafferty Andrew McCallum', ' Using Maximum Entropy Text Classification ']

>> Named Entities are: 
 [('PERSON', 'Kamal Nigam'), ('PERSON', 'John Lafferty'), ('PERSON', 'Andrew McCallum'), ('PERSON', 'Maximum Entropy Text')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('19', '19'), (']', ']'), ('Kamal', 'kamal'), ('Nigam', 'nigam'), (',', ','), ('John', 'john'), ('Lafferty', 'lafferti'), ('Andrew', 'andrew'), ('McCallum', 'mccallum'), (',', ','), ('', ''), ('Using', 'use'), ('Maximum', 'maximum'), ('Entropy', 'entropi'), ('Text', 'text'), ('Classification', 'classif'), ('', ''), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('19', '19'), (']', ']'), ('Kamal', 'kamal'), ('Nigam', 'nigam'), (',', ','), ('John', 'john'), ('Lafferty', 'lafferti'), ('Andrew', 'andrew'), ('McCallum', 'mccallum'), (',', ','), ('', ''), ('Using', 'use'), ('Maximum', 'maximum'), ('Entropy', 'entropi'), ('Text', 'text'), ('Classification', 'classif'), ('', ''), (',', ',')]

>> Lemmatization: 
 [('[', '['), ('19', '19'), (']', ']'), ('Kamal', 'Kamal'), ('Nigam', 'Nigam'), (',', ','), ('John', 'John'), ('Lafferty', 'Lafferty'), ('Andrew', 'Andrew'), ('McCallum', 'McCallum'), (',', ','), ('', ''), ('Using', 'Using'), ('Maximum', 'Maximum'), ('Entropy', 'Entropy'), ('Text', 'Text'), ('Classification', 'Classification'), ('', ''), (',', ',')]



========================================== PARAGRAPH 641 ===========================================

Workshop on Machine Learning for Information Filtering,  

------------------- Sentence 1 -------------------

Workshop on Machine Learning for Information Filtering,

>> Tokens are: 
 ['Workshop', 'Machine', 'Learning', 'Information', 'Filtering', ',']

>> Bigrams are: 
 [('Workshop', 'Machine'), ('Machine', 'Learning'), ('Learning', 'Information'), ('Information', 'Filtering'), ('Filtering', ',')]

>> Trigrams are: 
 [('Workshop', 'Machine', 'Learning'), ('Machine', 'Learning', 'Information'), ('Learning', 'Information', 'Filtering'), ('Information', 'Filtering', ',')]

>> POS Tags are: 
 [('Workshop', 'NNP'), ('Machine', 'NNP'), ('Learning', 'NNP'), ('Information', 'NNP'), ('Filtering', 'NNP'), (',', ',')]

>> Noun Phrases are: 
 ['Workshop Machine Learning Information Filtering']

>> Named Entities are: 
 [('PERSON', 'Workshop'), ('PERSON', 'Machine Learning')] 

>> Stemming using Porter Stemmer: 
 [('Workshop', 'workshop'), ('Machine', 'machin'), ('Learning', 'learn'), ('Information', 'inform'), ('Filtering', 'filter'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('Workshop', 'workshop'), ('Machine', 'machin'), ('Learning', 'learn'), ('Information', 'inform'), ('Filtering', 'filter'), (',', ',')]

>> Lemmatization: 
 [('Workshop', 'Workshop'), ('Machine', 'Machine'), ('Learning', 'Learning'), ('Information', 'Information'), ('Filtering', 'Filtering'), (',', ',')]



========================================== PARAGRAPH 642 ===========================================

pp. 61-67, 1999.  

------------------- Sentence 1 -------------------

pp.

>> Tokens are: 
 ['pp', '.']

>> Bigrams are: 
 [('pp', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('pp', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['pp']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('pp', 'pp'), ('.', '.')]


------------------- Sentence 2 -------------------

61-67, 1999.

>> Tokens are: 
 ['61-67', ',', '1999', '.']

>> Bigrams are: 
 [('61-67', ','), (',', '1999'), ('1999', '.')]

>> Trigrams are: 
 [('61-67', ',', '1999'), (',', '1999', '.')]

>> POS Tags are: 
 [('61-67', 'CD'), (',', ','), ('1999', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('61-67', '61-67'), (',', ','), ('1999', '1999'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('61-67', '61-67'), (',', ','), ('1999', '1999'), ('.', '.')]

>> Lemmatization: 
 [('61-67', '61-67'), (',', ','), ('1999', '1999'), ('.', '.')]



========================================== PARAGRAPH 643 ===========================================

[20] N. J. Nilsson, Learning Machines: Foundations of  Trainable Pattern-Classifying Systems, First Edition, New  

------------------- Sentence 1 -------------------

[20] N. J. Nilsson, Learning Machines: Foundations of  Trainable Pattern-Classifying Systems, First Edition, New

>> Tokens are: 
 ['[', '20', ']', 'N.', 'J.', 'Nilsson', ',', '', 'Learning', 'Machines', ':', 'Foundations', 'Trainable', 'Pattern-Classifying', 'Systems', '', ',', 'First', 'Edition', ',', 'New']

>> Bigrams are: 
 [('[', '20'), ('20', ']'), (']', 'N.'), ('N.', 'J.'), ('J.', 'Nilsson'), ('Nilsson', ','), (',', ''), ('', 'Learning'), ('Learning', 'Machines'), ('Machines', ':'), (':', 'Foundations'), ('Foundations', 'Trainable'), ('Trainable', 'Pattern-Classifying'), ('Pattern-Classifying', 'Systems'), ('Systems', ''), ('', ','), (',', 'First'), ('First', 'Edition'), ('Edition', ','), (',', 'New')]

>> Trigrams are: 
 [('[', '20', ']'), ('20', ']', 'N.'), (']', 'N.', 'J.'), ('N.', 'J.', 'Nilsson'), ('J.', 'Nilsson', ','), ('Nilsson', ',', ''), (',', '', 'Learning'), ('', 'Learning', 'Machines'), ('Learning', 'Machines', ':'), ('Machines', ':', 'Foundations'), (':', 'Foundations', 'Trainable'), ('Foundations', 'Trainable', 'Pattern-Classifying'), ('Trainable', 'Pattern-Classifying', 'Systems'), ('Pattern-Classifying', 'Systems', ''), ('Systems', '', ','), ('', ',', 'First'), (',', 'First', 'Edition'), ('First', 'Edition', ','), ('Edition', ',', 'New')]

>> POS Tags are: 
 [('[', 'RB'), ('20', 'CD'), (']', 'JJ'), ('N.', 'NNP'), ('J.', 'NNP'), ('Nilsson', 'NNP'), (',', ','), ('', 'NNP'), ('Learning', 'NNP'), ('Machines', 'NNS'), (':', ':'), ('Foundations', 'NNS'), ('Trainable', 'JJ'), ('Pattern-Classifying', 'JJ'), ('Systems', 'NNPS'), ('', 'NNP'), (',', ','), ('First', 'NNP'), ('Edition', 'NNP'), (',', ','), ('New', 'NNP')]

>> Noun Phrases are: 
 ['] N. J. Nilsson', ' Learning Machines', 'Foundations', '', 'First Edition', 'New']

>> Named Entities are: 
 [('PERSON', 'Nilsson'), ('ORGANIZATION', 'Systems'), ('PERSON', 'First Edition'), ('GPE', 'New')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('20', '20'), (']', ']'), ('N.', 'n.'), ('J.', 'j.'), ('Nilsson', 'nilsson'), (',', ','), ('', ''), ('Learning', 'learn'), ('Machines', 'machin'), (':', ':'), ('Foundations', 'foundat'), ('Trainable', 'trainabl'), ('Pattern-Classifying', 'pattern-classifi'), ('Systems', 'system'), ('', ''), (',', ','), ('First', 'first'), ('Edition', 'edit'), (',', ','), ('New', 'new')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('20', '20'), (']', ']'), ('N.', 'n.'), ('J.', 'j.'), ('Nilsson', 'nilsson'), (',', ','), ('', ''), ('Learning', 'learn'), ('Machines', 'machin'), (':', ':'), ('Foundations', 'foundat'), ('Trainable', 'trainabl'), ('Pattern-Classifying', 'pattern-classifi'), ('Systems', 'system'), ('', ''), (',', ','), ('First', 'first'), ('Edition', 'edit'), (',', ','), ('New', 'new')]

>> Lemmatization: 
 [('[', '['), ('20', '20'), (']', ']'), ('N.', 'N.'), ('J.', 'J.'), ('Nilsson', 'Nilsson'), (',', ','), ('', ''), ('Learning', 'Learning'), ('Machines', 'Machines'), (':', ':'), ('Foundations', 'Foundations'), ('Trainable', 'Trainable'), ('Pattern-Classifying', 'Pattern-Classifying'), ('Systems', 'Systems'), ('', ''), (',', ','), ('First', 'First'), ('Edition', 'Edition'), (',', ','), ('New', 'New')]



========================================== PARAGRAPH 644 ===========================================

York: McGraw-Hill, 1965.  

------------------- Sentence 1 -------------------

York: McGraw-Hill, 1965.

>> Tokens are: 
 ['York', ':', 'McGraw-Hill', ',', '1965', '.']

>> Bigrams are: 
 [('York', ':'), (':', 'McGraw-Hill'), ('McGraw-Hill', ','), (',', '1965'), ('1965', '.')]

>> Trigrams are: 
 [('York', ':', 'McGraw-Hill'), (':', 'McGraw-Hill', ','), ('McGraw-Hill', ',', '1965'), (',', '1965', '.')]

>> POS Tags are: 
 [('York', 'NNP'), (':', ':'), ('McGraw-Hill', 'NN'), (',', ','), ('1965', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['York', 'McGraw-Hill']

>> Named Entities are: 
 [('GPE', 'York')] 

>> Stemming using Porter Stemmer: 
 [('York', 'york'), (':', ':'), ('McGraw-Hill', 'mcgraw-hil'), (',', ','), ('1965', '1965'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('York', 'york'), (':', ':'), ('McGraw-Hill', 'mcgraw-hil'), (',', ','), ('1965', '1965'), ('.', '.')]

>> Lemmatization: 
 [('York', 'York'), (':', ':'), ('McGraw-Hill', 'McGraw-Hill'), (',', ','), ('1965', '1965'), ('.', '.')]



========================================== PARAGRAPH 645 ===========================================

[21] Isidore Jacob Good, Probability and the Weighing of  Evidence, The University of Wisconsin - Madison:  

------------------- Sentence 1 -------------------

[21] Isidore Jacob Good, Probability and the Weighing of  Evidence, The University of Wisconsin - Madison:

>> Tokens are: 
 ['[', '21', ']', 'Isidore', 'Jacob', 'Good', ',', '', 'Probability', 'Weighing', 'Evidence', '', ',', 'The', 'University', 'Wisconsin', '-', 'Madison', ':']

>> Bigrams are: 
 [('[', '21'), ('21', ']'), (']', 'Isidore'), ('Isidore', 'Jacob'), ('Jacob', 'Good'), ('Good', ','), (',', ''), ('', 'Probability'), ('Probability', 'Weighing'), ('Weighing', 'Evidence'), ('Evidence', ''), ('', ','), (',', 'The'), ('The', 'University'), ('University', 'Wisconsin'), ('Wisconsin', '-'), ('-', 'Madison'), ('Madison', ':')]

>> Trigrams are: 
 [('[', '21', ']'), ('21', ']', 'Isidore'), (']', 'Isidore', 'Jacob'), ('Isidore', 'Jacob', 'Good'), ('Jacob', 'Good', ','), ('Good', ',', ''), (',', '', 'Probability'), ('', 'Probability', 'Weighing'), ('Probability', 'Weighing', 'Evidence'), ('Weighing', 'Evidence', ''), ('Evidence', '', ','), ('', ',', 'The'), (',', 'The', 'University'), ('The', 'University', 'Wisconsin'), ('University', 'Wisconsin', '-'), ('Wisconsin', '-', 'Madison'), ('-', 'Madison', ':')]

>> POS Tags are: 
 [('[', 'RB'), ('21', 'CD'), (']', 'NNS'), ('Isidore', 'NNP'), ('Jacob', 'NNP'), ('Good', 'NNP'), (',', ','), ('', 'NNP'), ('Probability', 'NNP'), ('Weighing', 'NNP'), ('Evidence', 'NNP'), ('', 'NNP'), (',', ','), ('The', 'DT'), ('University', 'NNP'), ('Wisconsin', 'NNP'), ('-', ':'), ('Madison', 'NN'), (':', ':')]

>> Noun Phrases are: 
 ['] Isidore Jacob Good', ' Probability Weighing Evidence ', 'The University Wisconsin', 'Madison']

>> Named Entities are: 
 [('PERSON', 'Isidore Jacob Good'), ('ORGANIZATION', 'The University Wisconsin'), ('PERSON', 'Madison')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('21', '21'), (']', ']'), ('Isidore', 'isidor'), ('Jacob', 'jacob'), ('Good', 'good'), (',', ','), ('', ''), ('Probability', 'probabl'), ('Weighing', 'weigh'), ('Evidence', 'evid'), ('', ''), (',', ','), ('The', 'the'), ('University', 'univers'), ('Wisconsin', 'wisconsin'), ('-', '-'), ('Madison', 'madison'), (':', ':')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('21', '21'), (']', ']'), ('Isidore', 'isidor'), ('Jacob', 'jacob'), ('Good', 'good'), (',', ','), ('', ''), ('Probability', 'probabl'), ('Weighing', 'weigh'), ('Evidence', 'evid'), ('', ''), (',', ','), ('The', 'the'), ('University', 'univers'), ('Wisconsin', 'wisconsin'), ('-', '-'), ('Madison', 'madison'), (':', ':')]

>> Lemmatization: 
 [('[', '['), ('21', '21'), (']', ']'), ('Isidore', 'Isidore'), ('Jacob', 'Jacob'), ('Good', 'Good'), (',', ','), ('', ''), ('Probability', 'Probability'), ('Weighing', 'Weighing'), ('Evidence', 'Evidence'), ('', ''), (',', ','), ('The', 'The'), ('University', 'University'), ('Wisconsin', 'Wisconsin'), ('-', '-'), ('Madison', 'Madison'), (':', ':')]



========================================== PARAGRAPH 646 ===========================================

Charles Griffin, 1950.  

------------------- Sentence 1 -------------------

Charles Griffin, 1950.

>> Tokens are: 
 ['Charles', 'Griffin', ',', '1950', '.']

>> Bigrams are: 
 [('Charles', 'Griffin'), ('Griffin', ','), (',', '1950'), ('1950', '.')]

>> Trigrams are: 
 [('Charles', 'Griffin', ','), ('Griffin', ',', '1950'), (',', '1950', '.')]

>> POS Tags are: 
 [('Charles', 'NNP'), ('Griffin', 'NNP'), (',', ','), ('1950', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Charles Griffin']

>> Named Entities are: 
 [('PERSON', 'Charles Griffin')] 

>> Stemming using Porter Stemmer: 
 [('Charles', 'charl'), ('Griffin', 'griffin'), (',', ','), ('1950', '1950'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Charles', 'charl'), ('Griffin', 'griffin'), (',', ','), ('1950', '1950'), ('.', '.')]

>> Lemmatization: 
 [('Charles', 'Charles'), ('Griffin', 'Griffin'), (',', ','), ('1950', '1950'), ('.', '.')]



========================================== PARAGRAPH 647 ===========================================

[22] Shiliang Sun, Changshui Zhang and Guoqiang Yu, A  Bayesian Network Approach to Traffic Flow Forecasting,  

------------------- Sentence 1 -------------------

[22] Shiliang Sun, Changshui Zhang and Guoqiang Yu, A  Bayesian Network Approach to Traffic Flow Forecasting,

>> Tokens are: 
 ['[', '22', ']', 'Shiliang', 'Sun', ',', 'Changshui', 'Zhang', 'Guoqiang', 'Yu', ',', '', 'A', 'Bayesian', 'Network', 'Approach', 'Traffic', 'Flow', 'Forecasting', '', ',']

>> Bigrams are: 
 [('[', '22'), ('22', ']'), (']', 'Shiliang'), ('Shiliang', 'Sun'), ('Sun', ','), (',', 'Changshui'), ('Changshui', 'Zhang'), ('Zhang', 'Guoqiang'), ('Guoqiang', 'Yu'), ('Yu', ','), (',', ''), ('', 'A'), ('A', 'Bayesian'), ('Bayesian', 'Network'), ('Network', 'Approach'), ('Approach', 'Traffic'), ('Traffic', 'Flow'), ('Flow', 'Forecasting'), ('Forecasting', ''), ('', ',')]

>> Trigrams are: 
 [('[', '22', ']'), ('22', ']', 'Shiliang'), (']', 'Shiliang', 'Sun'), ('Shiliang', 'Sun', ','), ('Sun', ',', 'Changshui'), (',', 'Changshui', 'Zhang'), ('Changshui', 'Zhang', 'Guoqiang'), ('Zhang', 'Guoqiang', 'Yu'), ('Guoqiang', 'Yu', ','), ('Yu', ',', ''), (',', '', 'A'), ('', 'A', 'Bayesian'), ('A', 'Bayesian', 'Network'), ('Bayesian', 'Network', 'Approach'), ('Network', 'Approach', 'Traffic'), ('Approach', 'Traffic', 'Flow'), ('Traffic', 'Flow', 'Forecasting'), ('Flow', 'Forecasting', ''), ('Forecasting', '', ',')]

>> POS Tags are: 
 [('[', 'RB'), ('22', 'CD'), (']', 'NNS'), ('Shiliang', 'NNP'), ('Sun', 'NNP'), (',', ','), ('Changshui', 'NNP'), ('Zhang', 'NNP'), ('Guoqiang', 'NNP'), ('Yu', 'NNP'), (',', ','), ('', 'VBZ'), ('A', 'NNP'), ('Bayesian', 'NNP'), ('Network', 'NNP'), ('Approach', 'NNP'), ('Traffic', 'NNP'), ('Flow', 'NNP'), ('Forecasting', 'NNP'), ('', 'NNP'), (',', ',')]

>> Noun Phrases are: 
 ['] Shiliang Sun', 'Changshui Zhang Guoqiang Yu', 'A Bayesian Network Approach Traffic Flow Forecasting ']

>> Named Entities are: 
 [('PERSON', 'Shiliang Sun'), ('PERSON', 'Changshui Zhang Guoqiang Yu'), ('PERSON', 'Network Approach Traffic Flow')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('22', '22'), (']', ']'), ('Shiliang', 'shiliang'), ('Sun', 'sun'), (',', ','), ('Changshui', 'changshui'), ('Zhang', 'zhang'), ('Guoqiang', 'guoqiang'), ('Yu', 'yu'), (',', ','), ('', ''), ('A', 'a'), ('Bayesian', 'bayesian'), ('Network', 'network'), ('Approach', 'approach'), ('Traffic', 'traffic'), ('Flow', 'flow'), ('Forecasting', 'forecast'), ('', ''), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('22', '22'), (']', ']'), ('Shiliang', 'shiliang'), ('Sun', 'sun'), (',', ','), ('Changshui', 'changshui'), ('Zhang', 'zhang'), ('Guoqiang', 'guoqiang'), ('Yu', 'yu'), (',', ','), ('', ''), ('A', 'a'), ('Bayesian', 'bayesian'), ('Network', 'network'), ('Approach', 'approach'), ('Traffic', 'traffic'), ('Flow', 'flow'), ('Forecasting', 'forecast'), ('', ''), (',', ',')]

>> Lemmatization: 
 [('[', '['), ('22', '22'), (']', ']'), ('Shiliang', 'Shiliang'), ('Sun', 'Sun'), (',', ','), ('Changshui', 'Changshui'), ('Zhang', 'Zhang'), ('Guoqiang', 'Guoqiang'), ('Yu', 'Yu'), (',', ','), ('', ''), ('A', 'A'), ('Bayesian', 'Bayesian'), ('Network', 'Network'), ('Approach', 'Approach'), ('Traffic', 'Traffic'), ('Flow', 'Flow'), ('Forecasting', 'Forecasting'), ('', ''), (',', ',')]



========================================== PARAGRAPH 648 ===========================================

IEEE Transactions on Intelligent Transportation Systems,  

------------------- Sentence 1 -------------------

IEEE Transactions on Intelligent Transportation Systems,

>> Tokens are: 
 ['IEEE', 'Transactions', 'Intelligent', 'Transportation', 'Systems', ',']

>> Bigrams are: 
 [('IEEE', 'Transactions'), ('Transactions', 'Intelligent'), ('Intelligent', 'Transportation'), ('Transportation', 'Systems'), ('Systems', ',')]

>> Trigrams are: 
 [('IEEE', 'Transactions', 'Intelligent'), ('Transactions', 'Intelligent', 'Transportation'), ('Intelligent', 'Transportation', 'Systems'), ('Transportation', 'Systems', ',')]

>> POS Tags are: 
 [('IEEE', 'NNP'), ('Transactions', 'NNP'), ('Intelligent', 'NNP'), ('Transportation', 'NNP'), ('Systems', 'NNP'), (',', ',')]

>> Noun Phrases are: 
 ['IEEE Transactions Intelligent Transportation Systems']

>> Named Entities are: 
 [('ORGANIZATION', 'IEEE Transactions')] 

>> Stemming using Porter Stemmer: 
 [('IEEE', 'ieee'), ('Transactions', 'transact'), ('Intelligent', 'intellig'), ('Transportation', 'transport'), ('Systems', 'system'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('IEEE', 'ieee'), ('Transactions', 'transact'), ('Intelligent', 'intellig'), ('Transportation', 'transport'), ('Systems', 'system'), (',', ',')]

>> Lemmatization: 
 [('IEEE', 'IEEE'), ('Transactions', 'Transactions'), ('Intelligent', 'Intelligent'), ('Transportation', 'Transportation'), ('Systems', 'Systems'), (',', ',')]



========================================== PARAGRAPH 649 ===========================================

Vol. 7, No. 1, pp. 124-132, 2006.  

------------------- Sentence 1 -------------------

Vol.

>> Tokens are: 
 ['Vol', '.']

>> Bigrams are: 
 [('Vol', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Vol', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Vol']

>> Named Entities are: 
 [('GPE', 'Vol')] 

>> Stemming using Porter Stemmer: 
 [('Vol', 'vol'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Vol', 'vol'), ('.', '.')]

>> Lemmatization: 
 [('Vol', 'Vol'), ('.', '.')]


------------------- Sentence 2 -------------------

7, No.

>> Tokens are: 
 ['7', ',', 'No', '.']

>> Bigrams are: 
 [('7', ','), (',', 'No'), ('No', '.')]

>> Trigrams are: 
 [('7', ',', 'No'), (',', 'No', '.')]

>> POS Tags are: 
 [('7', 'CD'), (',', ','), ('No', 'DT'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('7', '7'), (',', ','), ('No', 'no'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('7', '7'), (',', ','), ('No', 'no'), ('.', '.')]

>> Lemmatization: 
 [('7', '7'), (',', ','), ('No', 'No'), ('.', '.')]


------------------- Sentence 3 -------------------

1, pp.

>> Tokens are: 
 ['1', ',', 'pp', '.']

>> Bigrams are: 
 [('1', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('1', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('1', 'CD'), (',', ','), ('pp', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['pp']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('1', '1'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('1', '1'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('1', '1'), (',', ','), ('pp', 'pp'), ('.', '.')]


------------------- Sentence 4 -------------------

124-132, 2006.

>> Tokens are: 
 ['124-132', ',', '2006', '.']

>> Bigrams are: 
 [('124-132', ','), (',', '2006'), ('2006', '.')]

>> Trigrams are: 
 [('124-132', ',', '2006'), (',', '2006', '.')]

>> POS Tags are: 
 [('124-132', 'CD'), (',', ','), ('2006', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('124-132', '124-132'), (',', ','), ('2006', '2006'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('124-132', '124-132'), (',', ','), ('2006', '2006'), ('.', '.')]

>> Lemmatization: 
 [('124-132', '124-132'), (',', ','), ('2006', '2006'), ('.', '.')]



========================================== PARAGRAPH 650 ===========================================

[23] Jie Cheng, Russell Greiner, Jonathan Kelly, David Bell and  Weiru Liu, Learning Bayesian networks from data: An  

------------------- Sentence 1 -------------------

[23] Jie Cheng, Russell Greiner, Jonathan Kelly, David Bell and  Weiru Liu, Learning Bayesian networks from data: An

>> Tokens are: 
 ['[', '23', ']', 'Jie', 'Cheng', ',', 'Russell', 'Greiner', ',', 'Jonathan', 'Kelly', ',', 'David', 'Bell', 'Weiru', 'Liu', ',', '', 'Learning', 'Bayesian', 'networks', 'data', ':', 'An']

>> Bigrams are: 
 [('[', '23'), ('23', ']'), (']', 'Jie'), ('Jie', 'Cheng'), ('Cheng', ','), (',', 'Russell'), ('Russell', 'Greiner'), ('Greiner', ','), (',', 'Jonathan'), ('Jonathan', 'Kelly'), ('Kelly', ','), (',', 'David'), ('David', 'Bell'), ('Bell', 'Weiru'), ('Weiru', 'Liu'), ('Liu', ','), (',', ''), ('', 'Learning'), ('Learning', 'Bayesian'), ('Bayesian', 'networks'), ('networks', 'data'), ('data', ':'), (':', 'An')]

>> Trigrams are: 
 [('[', '23', ']'), ('23', ']', 'Jie'), (']', 'Jie', 'Cheng'), ('Jie', 'Cheng', ','), ('Cheng', ',', 'Russell'), (',', 'Russell', 'Greiner'), ('Russell', 'Greiner', ','), ('Greiner', ',', 'Jonathan'), (',', 'Jonathan', 'Kelly'), ('Jonathan', 'Kelly', ','), ('Kelly', ',', 'David'), (',', 'David', 'Bell'), ('David', 'Bell', 'Weiru'), ('Bell', 'Weiru', 'Liu'), ('Weiru', 'Liu', ','), ('Liu', ',', ''), (',', '', 'Learning'), ('', 'Learning', 'Bayesian'), ('Learning', 'Bayesian', 'networks'), ('Bayesian', 'networks', 'data'), ('networks', 'data', ':'), ('data', ':', 'An')]

>> POS Tags are: 
 [('[', 'RB'), ('23', 'CD'), (']', 'JJ'), ('Jie', 'NNP'), ('Cheng', 'NNP'), (',', ','), ('Russell', 'NNP'), ('Greiner', 'NNP'), (',', ','), ('Jonathan', 'NNP'), ('Kelly', 'NNP'), (',', ','), ('David', 'NNP'), ('Bell', 'NNP'), ('Weiru', 'NNP'), ('Liu', 'NNP'), (',', ','), ('', 'NNP'), ('Learning', 'NNP'), ('Bayesian', 'NNP'), ('networks', 'NNS'), ('data', 'NNS'), (':', ':'), ('An', 'DT')]

>> Noun Phrases are: 
 ['] Jie Cheng', 'Russell Greiner', 'Jonathan Kelly', 'David Bell Weiru Liu', ' Learning Bayesian networks data']

>> Named Entities are: 
 [('ORGANIZATION', 'Russell Greiner'), ('PERSON', 'Jonathan Kelly'), ('PERSON', 'David Bell Weiru Liu')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('23', '23'), (']', ']'), ('Jie', 'jie'), ('Cheng', 'cheng'), (',', ','), ('Russell', 'russel'), ('Greiner', 'greiner'), (',', ','), ('Jonathan', 'jonathan'), ('Kelly', 'kelli'), (',', ','), ('David', 'david'), ('Bell', 'bell'), ('Weiru', 'weiru'), ('Liu', 'liu'), (',', ','), ('', ''), ('Learning', 'learn'), ('Bayesian', 'bayesian'), ('networks', 'network'), ('data', 'data'), (':', ':'), ('An', 'an')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('23', '23'), (']', ']'), ('Jie', 'jie'), ('Cheng', 'cheng'), (',', ','), ('Russell', 'russel'), ('Greiner', 'greiner'), (',', ','), ('Jonathan', 'jonathan'), ('Kelly', 'kelli'), (',', ','), ('David', 'david'), ('Bell', 'bell'), ('Weiru', 'weiru'), ('Liu', 'liu'), (',', ','), ('', ''), ('Learning', 'learn'), ('Bayesian', 'bayesian'), ('networks', 'network'), ('data', 'data'), (':', ':'), ('An', 'an')]

>> Lemmatization: 
 [('[', '['), ('23', '23'), (']', ']'), ('Jie', 'Jie'), ('Cheng', 'Cheng'), (',', ','), ('Russell', 'Russell'), ('Greiner', 'Greiner'), (',', ','), ('Jonathan', 'Jonathan'), ('Kelly', 'Kelly'), (',', ','), ('David', 'David'), ('Bell', 'Bell'), ('Weiru', 'Weiru'), ('Liu', 'Liu'), (',', ','), ('', ''), ('Learning', 'Learning'), ('Bayesian', 'Bayesian'), ('networks', 'network'), ('data', 'data'), (':', ':'), ('An', 'An')]



========================================== PARAGRAPH 651 ===========================================

information-Theory based approach, The Artificial  

------------------- Sentence 1 -------------------

information-Theory based approach, The Artificial

>> Tokens are: 
 ['information-Theory', 'based', 'approach', '', ',', 'The', 'Artificial']

>> Bigrams are: 
 [('information-Theory', 'based'), ('based', 'approach'), ('approach', ''), ('', ','), (',', 'The'), ('The', 'Artificial')]

>> Trigrams are: 
 [('information-Theory', 'based', 'approach'), ('based', 'approach', ''), ('approach', '', ','), ('', ',', 'The'), (',', 'The', 'Artificial')]

>> POS Tags are: 
 [('information-Theory', 'NN'), ('based', 'VBN'), ('approach', 'NN'), ('', 'NN'), (',', ','), ('The', 'DT'), ('Artificial', 'NNP')]

>> Noun Phrases are: 
 ['information-Theory', 'approach ', 'The Artificial']

>> Named Entities are: 
 [('ORGANIZATION', 'Artificial')] 

>> Stemming using Porter Stemmer: 
 [('information-Theory', 'information-theori'), ('based', 'base'), ('approach', 'approach'), ('', ''), (',', ','), ('The', 'the'), ('Artificial', 'artifici')]

>> Stemming using Snowball Stemmer: 
 [('information-Theory', 'information-theori'), ('based', 'base'), ('approach', 'approach'), ('', ''), (',', ','), ('The', 'the'), ('Artificial', 'artifici')]

>> Lemmatization: 
 [('information-Theory', 'information-Theory'), ('based', 'based'), ('approach', 'approach'), ('', ''), (',', ','), ('The', 'The'), ('Artificial', 'Artificial')]



========================================== PARAGRAPH 652 ===========================================

Intelligence Journal, Vol. 137, pp. 43-90, 2002.  

------------------- Sentence 1 -------------------

Intelligence Journal, Vol.

>> Tokens are: 
 ['Intelligence', 'Journal', ',', 'Vol', '.']

>> Bigrams are: 
 [('Intelligence', 'Journal'), ('Journal', ','), (',', 'Vol'), ('Vol', '.')]

>> Trigrams are: 
 [('Intelligence', 'Journal', ','), ('Journal', ',', 'Vol'), (',', 'Vol', '.')]

>> POS Tags are: 
 [('Intelligence', 'NNP'), ('Journal', 'NNP'), (',', ','), ('Vol', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Intelligence Journal', 'Vol']

>> Named Entities are: 
 [('PERSON', 'Vol')] 

>> Stemming using Porter Stemmer: 
 [('Intelligence', 'intellig'), ('Journal', 'journal'), (',', ','), ('Vol', 'vol'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Intelligence', 'intellig'), ('Journal', 'journal'), (',', ','), ('Vol', 'vol'), ('.', '.')]

>> Lemmatization: 
 [('Intelligence', 'Intelligence'), ('Journal', 'Journal'), (',', ','), ('Vol', 'Vol'), ('.', '.')]


------------------- Sentence 2 -------------------

137, pp.

>> Tokens are: 
 ['137', ',', 'pp', '.']

>> Bigrams are: 
 [('137', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('137', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('137', 'CD'), (',', ','), ('pp', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['pp']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('137', '137'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('137', '137'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('137', '137'), (',', ','), ('pp', 'pp'), ('.', '.')]


------------------- Sentence 3 -------------------

43-90, 2002.

>> Tokens are: 
 ['43-90', ',', '2002', '.']

>> Bigrams are: 
 [('43-90', ','), (',', '2002'), ('2002', '.')]

>> Trigrams are: 
 [('43-90', ',', '2002'), (',', '2002', '.')]

>> POS Tags are: 
 [('43-90', 'CD'), (',', ','), ('2002', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('43-90', '43-90'), (',', ','), ('2002', '2002'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('43-90', '43-90'), (',', ','), ('2002', '2002'), ('.', '.')]

>> Lemmatization: 
 [('43-90', '43-90'), (',', ','), ('2002', '2002'), ('.', '.')]



========================================== PARAGRAPH 653 ===========================================

[24] Tom M. Mitchell, Machine Learning: A Guide to Current  Research, The Springer International Series in Engineering  

------------------- Sentence 1 -------------------

[24] Tom M. Mitchell, Machine Learning: A Guide to Current  Research, The Springer International Series in Engineering

>> Tokens are: 
 ['[', '24', ']', 'Tom', 'M.', 'Mitchell', ',', '', 'Machine', 'Learning', ':', 'A', 'Guide', 'Current', 'Research', '', ',', 'The', 'Springer', 'International', 'Series', 'Engineering']

>> Bigrams are: 
 [('[', '24'), ('24', ']'), (']', 'Tom'), ('Tom', 'M.'), ('M.', 'Mitchell'), ('Mitchell', ','), (',', ''), ('', 'Machine'), ('Machine', 'Learning'), ('Learning', ':'), (':', 'A'), ('A', 'Guide'), ('Guide', 'Current'), ('Current', 'Research'), ('Research', ''), ('', ','), (',', 'The'), ('The', 'Springer'), ('Springer', 'International'), ('International', 'Series'), ('Series', 'Engineering')]

>> Trigrams are: 
 [('[', '24', ']'), ('24', ']', 'Tom'), (']', 'Tom', 'M.'), ('Tom', 'M.', 'Mitchell'), ('M.', 'Mitchell', ','), ('Mitchell', ',', ''), (',', '', 'Machine'), ('', 'Machine', 'Learning'), ('Machine', 'Learning', ':'), ('Learning', ':', 'A'), (':', 'A', 'Guide'), ('A', 'Guide', 'Current'), ('Guide', 'Current', 'Research'), ('Current', 'Research', ''), ('Research', '', ','), ('', ',', 'The'), (',', 'The', 'Springer'), ('The', 'Springer', 'International'), ('Springer', 'International', 'Series'), ('International', 'Series', 'Engineering')]

>> POS Tags are: 
 [('[', 'RB'), ('24', 'CD'), (']', 'JJ'), ('Tom', 'NNP'), ('M.', 'NNP'), ('Mitchell', 'NNP'), (',', ','), ('', 'NNP'), ('Machine', 'NNP'), ('Learning', 'NNP'), (':', ':'), ('A', 'DT'), ('Guide', 'NNP'), ('Current', 'NNP'), ('Research', 'NNP'), ('', 'NNP'), (',', ','), ('The', 'DT'), ('Springer', 'NNP'), ('International', 'NNP'), ('Series', 'NNP'), ('Engineering', 'NNP')]

>> Noun Phrases are: 
 ['] Tom M. Mitchell', ' Machine Learning', 'A Guide Current Research ', 'The Springer International Series Engineering']

>> Named Entities are: 
 [('PERSON', 'Tom M. Mitchell'), ('PERSON', 'Machine Learning'), ('ORGANIZATION', 'Springer International Series')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('24', '24'), (']', ']'), ('Tom', 'tom'), ('M.', 'm.'), ('Mitchell', 'mitchel'), (',', ','), ('', ''), ('Machine', 'machin'), ('Learning', 'learn'), (':', ':'), ('A', 'a'), ('Guide', 'guid'), ('Current', 'current'), ('Research', 'research'), ('', ''), (',', ','), ('The', 'the'), ('Springer', 'springer'), ('International', 'intern'), ('Series', 'seri'), ('Engineering', 'engin')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('24', '24'), (']', ']'), ('Tom', 'tom'), ('M.', 'm.'), ('Mitchell', 'mitchel'), (',', ','), ('', ''), ('Machine', 'machin'), ('Learning', 'learn'), (':', ':'), ('A', 'a'), ('Guide', 'guid'), ('Current', 'current'), ('Research', 'research'), ('', ''), (',', ','), ('The', 'the'), ('Springer', 'springer'), ('International', 'intern'), ('Series', 'seri'), ('Engineering', 'engin')]

>> Lemmatization: 
 [('[', '['), ('24', '24'), (']', ']'), ('Tom', 'Tom'), ('M.', 'M.'), ('Mitchell', 'Mitchell'), (',', ','), ('', ''), ('Machine', 'Machine'), ('Learning', 'Learning'), (':', ':'), ('A', 'A'), ('Guide', 'Guide'), ('Current', 'Current'), ('Research', 'Research'), ('', ''), (',', ','), ('The', 'The'), ('Springer', 'Springer'), ('International', 'International'), ('Series', 'Series'), ('Engineering', 'Engineering')]



========================================== PARAGRAPH 654 ===========================================

and Computer Science Series, McGraw Hill, 1997.  

------------------- Sentence 1 -------------------

and Computer Science Series, McGraw Hill, 1997.

>> Tokens are: 
 ['Computer', 'Science', 'Series', ',', 'McGraw', 'Hill', ',', '1997', '.']

>> Bigrams are: 
 [('Computer', 'Science'), ('Science', 'Series'), ('Series', ','), (',', 'McGraw'), ('McGraw', 'Hill'), ('Hill', ','), (',', '1997'), ('1997', '.')]

>> Trigrams are: 
 [('Computer', 'Science', 'Series'), ('Science', 'Series', ','), ('Series', ',', 'McGraw'), (',', 'McGraw', 'Hill'), ('McGraw', 'Hill', ','), ('Hill', ',', '1997'), (',', '1997', '.')]

>> POS Tags are: 
 [('Computer', 'NNP'), ('Science', 'NNP'), ('Series', 'NNP'), (',', ','), ('McGraw', 'NNP'), ('Hill', 'NNP'), (',', ','), ('1997', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Computer Science Series', 'McGraw Hill']

>> Named Entities are: 
 [('ORGANIZATION', 'Computer Science Series'), ('ORGANIZATION', 'McGraw Hill')] 

>> Stemming using Porter Stemmer: 
 [('Computer', 'comput'), ('Science', 'scienc'), ('Series', 'seri'), (',', ','), ('McGraw', 'mcgraw'), ('Hill', 'hill'), (',', ','), ('1997', '1997'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Computer', 'comput'), ('Science', 'scienc'), ('Series', 'seri'), (',', ','), ('McGraw', 'mcgraw'), ('Hill', 'hill'), (',', ','), ('1997', '1997'), ('.', '.')]

>> Lemmatization: 
 [('Computer', 'Computer'), ('Science', 'Science'), ('Series', 'Series'), (',', ','), ('McGraw', 'McGraw'), ('Hill', 'Hill'), (',', ','), ('1997', '1997'), ('.', '.')]



========================================== PARAGRAPH 655 ===========================================

[25] D. Aha, Lazy Learning, Dordrecht: Kluwer Academic  Publishers, 1997.  

------------------- Sentence 1 -------------------

[25] D. Aha, Lazy Learning, Dordrecht: Kluwer Academic  Publishers, 1997.

>> Tokens are: 
 ['[', '25', ']', 'D.', 'Aha', ',', '', 'Lazy', 'Learning', '', ',', 'Dordrecht', ':', 'Kluwer', 'Academic', 'Publishers', ',', '1997', '.']

>> Bigrams are: 
 [('[', '25'), ('25', ']'), (']', 'D.'), ('D.', 'Aha'), ('Aha', ','), (',', ''), ('', 'Lazy'), ('Lazy', 'Learning'), ('Learning', ''), ('', ','), (',', 'Dordrecht'), ('Dordrecht', ':'), (':', 'Kluwer'), ('Kluwer', 'Academic'), ('Academic', 'Publishers'), ('Publishers', ','), (',', '1997'), ('1997', '.')]

>> Trigrams are: 
 [('[', '25', ']'), ('25', ']', 'D.'), (']', 'D.', 'Aha'), ('D.', 'Aha', ','), ('Aha', ',', ''), (',', '', 'Lazy'), ('', 'Lazy', 'Learning'), ('Lazy', 'Learning', ''), ('Learning', '', ','), ('', ',', 'Dordrecht'), (',', 'Dordrecht', ':'), ('Dordrecht', ':', 'Kluwer'), (':', 'Kluwer', 'Academic'), ('Kluwer', 'Academic', 'Publishers'), ('Academic', 'Publishers', ','), ('Publishers', ',', '1997'), (',', '1997', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('25', 'CD'), (']', 'JJ'), ('D.', 'NNP'), ('Aha', 'NNP'), (',', ','), ('', 'NNP'), ('Lazy', 'NNP'), ('Learning', 'NNP'), ('', 'NNP'), (',', ','), ('Dordrecht', 'NNP'), (':', ':'), ('Kluwer', 'NNP'), ('Academic', 'NNP'), ('Publishers', 'NNP'), (',', ','), ('1997', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['] D. Aha', ' Lazy Learning ', 'Dordrecht', 'Kluwer Academic Publishers']

>> Named Entities are: 
 [('PERSON', 'Dordrecht'), ('PERSON', 'Kluwer Academic Publishers')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('25', '25'), (']', ']'), ('D.', 'd.'), ('Aha', 'aha'), (',', ','), ('', ''), ('Lazy', 'lazi'), ('Learning', 'learn'), ('', ''), (',', ','), ('Dordrecht', 'dordrecht'), (':', ':'), ('Kluwer', 'kluwer'), ('Academic', 'academ'), ('Publishers', 'publish'), (',', ','), ('1997', '1997'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('25', '25'), (']', ']'), ('D.', 'd.'), ('Aha', 'aha'), (',', ','), ('', ''), ('Lazy', 'lazi'), ('Learning', 'learn'), ('', ''), (',', ','), ('Dordrecht', 'dordrecht'), (':', ':'), ('Kluwer', 'kluwer'), ('Academic', 'academ'), ('Publishers', 'publish'), (',', ','), ('1997', '1997'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('25', '25'), (']', ']'), ('D.', 'D.'), ('Aha', 'Aha'), (',', ','), ('', ''), ('Lazy', 'Lazy'), ('Learning', 'Learning'), ('', ''), (',', ','), ('Dordrecht', 'Dordrecht'), (':', ':'), ('Kluwer', 'Kluwer'), ('Academic', 'Academic'), ('Publishers', 'Publishers'), (',', ','), ('1997', '1997'), ('.', '.')]



========================================== PARAGRAPH 656 ===========================================

[26] Ramon Lopez De Mantaras and Eva Armengol, Machine  learning from examples: Inductive and Lazy methods, Data and  

------------------- Sentence 1 -------------------

[26] Ramon Lopez De Mantaras and Eva Armengol, Machine  learning from examples: Inductive and Lazy methods, Data and

>> Tokens are: 
 ['[', '26', ']', 'Ramon', 'Lopez', 'De', 'Mantaras', 'Eva', 'Armengol', ',', '', 'Machine', 'learning', 'examples', ':', 'Inductive', 'Lazy', 'methods', '', ',', 'Data']

>> Bigrams are: 
 [('[', '26'), ('26', ']'), (']', 'Ramon'), ('Ramon', 'Lopez'), ('Lopez', 'De'), ('De', 'Mantaras'), ('Mantaras', 'Eva'), ('Eva', 'Armengol'), ('Armengol', ','), (',', ''), ('', 'Machine'), ('Machine', 'learning'), ('learning', 'examples'), ('examples', ':'), (':', 'Inductive'), ('Inductive', 'Lazy'), ('Lazy', 'methods'), ('methods', ''), ('', ','), (',', 'Data')]

>> Trigrams are: 
 [('[', '26', ']'), ('26', ']', 'Ramon'), (']', 'Ramon', 'Lopez'), ('Ramon', 'Lopez', 'De'), ('Lopez', 'De', 'Mantaras'), ('De', 'Mantaras', 'Eva'), ('Mantaras', 'Eva', 'Armengol'), ('Eva', 'Armengol', ','), ('Armengol', ',', ''), (',', '', 'Machine'), ('', 'Machine', 'learning'), ('Machine', 'learning', 'examples'), ('learning', 'examples', ':'), ('examples', ':', 'Inductive'), (':', 'Inductive', 'Lazy'), ('Inductive', 'Lazy', 'methods'), ('Lazy', 'methods', ''), ('methods', '', ','), ('', ',', 'Data')]

>> POS Tags are: 
 [('[', 'RB'), ('26', 'CD'), (']', 'JJ'), ('Ramon', 'NNP'), ('Lopez', 'NNP'), ('De', 'NNP'), ('Mantaras', 'NNP'), ('Eva', 'NNP'), ('Armengol', 'NNP'), (',', ','), ('', 'NNP'), ('Machine', 'NNP'), ('learning', 'VBG'), ('examples', 'NNS'), (':', ':'), ('Inductive', 'JJ'), ('Lazy', 'NNP'), ('methods', 'NNS'), ('', 'NNP'), (',', ','), ('Data', 'NNP')]

>> Noun Phrases are: 
 ['] Ramon Lopez De Mantaras Eva Armengol', ' Machine', 'examples', 'Inductive Lazy methods ', 'Data']

>> Named Entities are: 
 [('PERSON', 'Ramon Lopez De Mantaras Eva Armengol'), ('PERSON', 'Data')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('26', '26'), (']', ']'), ('Ramon', 'ramon'), ('Lopez', 'lopez'), ('De', 'de'), ('Mantaras', 'mantara'), ('Eva', 'eva'), ('Armengol', 'armengol'), (',', ','), ('', ''), ('Machine', 'machin'), ('learning', 'learn'), ('examples', 'exampl'), (':', ':'), ('Inductive', 'induct'), ('Lazy', 'lazi'), ('methods', 'method'), ('', ''), (',', ','), ('Data', 'data')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('26', '26'), (']', ']'), ('Ramon', 'ramon'), ('Lopez', 'lopez'), ('De', 'de'), ('Mantaras', 'mantara'), ('Eva', 'eva'), ('Armengol', 'armengol'), (',', ','), ('', ''), ('Machine', 'machin'), ('learning', 'learn'), ('examples', 'exampl'), (':', ':'), ('Inductive', 'induct'), ('Lazy', 'lazi'), ('methods', 'method'), ('', ''), (',', ','), ('Data', 'data')]

>> Lemmatization: 
 [('[', '['), ('26', '26'), (']', ']'), ('Ramon', 'Ramon'), ('Lopez', 'Lopez'), ('De', 'De'), ('Mantaras', 'Mantaras'), ('Eva', 'Eva'), ('Armengol', 'Armengol'), (',', ','), ('', ''), ('Machine', 'Machine'), ('learning', 'learning'), ('examples', 'example'), (':', ':'), ('Inductive', 'Inductive'), ('Lazy', 'Lazy'), ('methods', 'method'), ('', ''), (',', ','), ('Data', 'Data')]



========================================== PARAGRAPH 657 ===========================================

Knowledge Engineering, Vol. 25, No. 1-2, pp. 99-123, 1998.  

------------------- Sentence 1 -------------------

Knowledge Engineering, Vol.

>> Tokens are: 
 ['Knowledge', 'Engineering', ',', 'Vol', '.']

>> Bigrams are: 
 [('Knowledge', 'Engineering'), ('Engineering', ','), (',', 'Vol'), ('Vol', '.')]

>> Trigrams are: 
 [('Knowledge', 'Engineering', ','), ('Engineering', ',', 'Vol'), (',', 'Vol', '.')]

>> POS Tags are: 
 [('Knowledge', 'NNP'), ('Engineering', 'NNP'), (',', ','), ('Vol', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Knowledge Engineering', 'Vol']

>> Named Entities are: 
 [('PERSON', 'Knowledge'), ('PERSON', 'Vol')] 

>> Stemming using Porter Stemmer: 
 [('Knowledge', 'knowledg'), ('Engineering', 'engin'), (',', ','), ('Vol', 'vol'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Knowledge', 'knowledg'), ('Engineering', 'engin'), (',', ','), ('Vol', 'vol'), ('.', '.')]

>> Lemmatization: 
 [('Knowledge', 'Knowledge'), ('Engineering', 'Engineering'), (',', ','), ('Vol', 'Vol'), ('.', '.')]


------------------- Sentence 2 -------------------

25, No.

>> Tokens are: 
 ['25', ',', 'No', '.']

>> Bigrams are: 
 [('25', ','), (',', 'No'), ('No', '.')]

>> Trigrams are: 
 [('25', ',', 'No'), (',', 'No', '.')]

>> POS Tags are: 
 [('25', 'CD'), (',', ','), ('No', 'DT'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('25', '25'), (',', ','), ('No', 'no'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('25', '25'), (',', ','), ('No', 'no'), ('.', '.')]

>> Lemmatization: 
 [('25', '25'), (',', ','), ('No', 'No'), ('.', '.')]


------------------- Sentence 3 -------------------

1-2, pp.

>> Tokens are: 
 ['1-2', ',', 'pp', '.']

>> Bigrams are: 
 [('1-2', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('1-2', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('1-2', 'JJ'), (',', ','), ('pp', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['pp']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('1-2', '1-2'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('1-2', '1-2'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('1-2', '1-2'), (',', ','), ('pp', 'pp'), ('.', '.')]


------------------- Sentence 4 -------------------

99-123, 1998.

>> Tokens are: 
 ['99-123', ',', '1998', '.']

>> Bigrams are: 
 [('99-123', ','), (',', '1998'), ('1998', '.')]

>> Trigrams are: 
 [('99-123', ',', '1998'), (',', '1998', '.')]

>> POS Tags are: 
 [('99-123', 'CD'), (',', ','), ('1998', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('99-123', '99-123'), (',', ','), ('1998', '1998'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('99-123', '99-123'), (',', ','), ('1998', '1998'), ('.', '.')]

>> Lemmatization: 
 [('99-123', '99-123'), (',', ','), ('1998', '1998'), ('.', '.')]



========================================== PARAGRAPH 658 ===========================================

[27] Hamid Parvin, Hoseinali Alizadeh and Behrouz Minati, A  Modification on K-Nearest Neighbor Classifier, Global  

------------------- Sentence 1 -------------------

[27] Hamid Parvin, Hoseinali Alizadeh and Behrouz Minati, A  Modification on K-Nearest Neighbor Classifier, Global

>> Tokens are: 
 ['[', '27', ']', 'Hamid', 'Parvin', ',', 'Hoseinali', 'Alizadeh', 'Behrouz', 'Minati', ',', '', 'A', 'Modification', 'K-Nearest', 'Neighbor', 'Classifier', '', ',', 'Global']

>> Bigrams are: 
 [('[', '27'), ('27', ']'), (']', 'Hamid'), ('Hamid', 'Parvin'), ('Parvin', ','), (',', 'Hoseinali'), ('Hoseinali', 'Alizadeh'), ('Alizadeh', 'Behrouz'), ('Behrouz', 'Minati'), ('Minati', ','), (',', ''), ('', 'A'), ('A', 'Modification'), ('Modification', 'K-Nearest'), ('K-Nearest', 'Neighbor'), ('Neighbor', 'Classifier'), ('Classifier', ''), ('', ','), (',', 'Global')]

>> Trigrams are: 
 [('[', '27', ']'), ('27', ']', 'Hamid'), (']', 'Hamid', 'Parvin'), ('Hamid', 'Parvin', ','), ('Parvin', ',', 'Hoseinali'), (',', 'Hoseinali', 'Alizadeh'), ('Hoseinali', 'Alizadeh', 'Behrouz'), ('Alizadeh', 'Behrouz', 'Minati'), ('Behrouz', 'Minati', ','), ('Minati', ',', ''), (',', '', 'A'), ('', 'A', 'Modification'), ('A', 'Modification', 'K-Nearest'), ('Modification', 'K-Nearest', 'Neighbor'), ('K-Nearest', 'Neighbor', 'Classifier'), ('Neighbor', 'Classifier', ''), ('Classifier', '', ','), ('', ',', 'Global')]

>> POS Tags are: 
 [('[', 'RB'), ('27', 'CD'), (']', 'NNS'), ('Hamid', 'NNP'), ('Parvin', 'NNP'), (',', ','), ('Hoseinali', 'NNP'), ('Alizadeh', 'NNP'), ('Behrouz', 'NNP'), ('Minati', 'NNP'), (',', ','), ('', 'VBZ'), ('A', 'DT'), ('Modification', 'NNP'), ('K-Nearest', 'NNP'), ('Neighbor', 'NNP'), ('Classifier', 'NNP'), ('', 'NNP'), (',', ','), ('Global', 'NNP')]

>> Noun Phrases are: 
 ['] Hamid Parvin', 'Hoseinali Alizadeh Behrouz Minati', 'A Modification K-Nearest Neighbor Classifier ', 'Global']

>> Named Entities are: 
 [('PERSON', 'Hamid Parvin'), ('PERSON', 'Hoseinali Alizadeh Behrouz Minati'), ('PERSON', 'Global')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('27', '27'), (']', ']'), ('Hamid', 'hamid'), ('Parvin', 'parvin'), (',', ','), ('Hoseinali', 'hoseinali'), ('Alizadeh', 'alizadeh'), ('Behrouz', 'behrouz'), ('Minati', 'minati'), (',', ','), ('', ''), ('A', 'a'), ('Modification', 'modif'), ('K-Nearest', 'k-nearest'), ('Neighbor', 'neighbor'), ('Classifier', 'classifi'), ('', ''), (',', ','), ('Global', 'global')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('27', '27'), (']', ']'), ('Hamid', 'hamid'), ('Parvin', 'parvin'), (',', ','), ('Hoseinali', 'hoseinali'), ('Alizadeh', 'alizadeh'), ('Behrouz', 'behrouz'), ('Minati', 'minati'), (',', ','), ('', ''), ('A', 'a'), ('Modification', 'modif'), ('K-Nearest', 'k-nearest'), ('Neighbor', 'neighbor'), ('Classifier', 'classifi'), ('', ''), (',', ','), ('Global', 'global')]

>> Lemmatization: 
 [('[', '['), ('27', '27'), (']', ']'), ('Hamid', 'Hamid'), ('Parvin', 'Parvin'), (',', ','), ('Hoseinali', 'Hoseinali'), ('Alizadeh', 'Alizadeh'), ('Behrouz', 'Behrouz'), ('Minati', 'Minati'), (',', ','), ('', ''), ('A', 'A'), ('Modification', 'Modification'), ('K-Nearest', 'K-Nearest'), ('Neighbor', 'Neighbor'), ('Classifier', 'Classifier'), ('', ''), (',', ','), ('Global', 'Global')]



========================================== PARAGRAPH 659 ===========================================

Journal of Computer Science and Technology, Vol. 10, No.  

------------------- Sentence 1 -------------------

Journal of Computer Science and Technology, Vol.

>> Tokens are: 
 ['Journal', 'Computer', 'Science', 'Technology', ',', 'Vol', '.']

>> Bigrams are: 
 [('Journal', 'Computer'), ('Computer', 'Science'), ('Science', 'Technology'), ('Technology', ','), (',', 'Vol'), ('Vol', '.')]

>> Trigrams are: 
 [('Journal', 'Computer', 'Science'), ('Computer', 'Science', 'Technology'), ('Science', 'Technology', ','), ('Technology', ',', 'Vol'), (',', 'Vol', '.')]

>> POS Tags are: 
 [('Journal', 'NNP'), ('Computer', 'NNP'), ('Science', 'NNP'), ('Technology', 'NNP'), (',', ','), ('Vol', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Journal Computer Science Technology', 'Vol']

>> Named Entities are: 
 [('PERSON', 'Journal'), ('ORGANIZATION', 'Computer Science Technology'), ('PERSON', 'Vol')] 

>> Stemming using Porter Stemmer: 
 [('Journal', 'journal'), ('Computer', 'comput'), ('Science', 'scienc'), ('Technology', 'technolog'), (',', ','), ('Vol', 'vol'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Journal', 'journal'), ('Computer', 'comput'), ('Science', 'scienc'), ('Technology', 'technolog'), (',', ','), ('Vol', 'vol'), ('.', '.')]

>> Lemmatization: 
 [('Journal', 'Journal'), ('Computer', 'Computer'), ('Science', 'Science'), ('Technology', 'Technology'), (',', ','), ('Vol', 'Vol'), ('.', '.')]


------------------- Sentence 2 -------------------

10, No.

>> Tokens are: 
 ['10', ',', 'No', '.']

>> Bigrams are: 
 [('10', ','), (',', 'No'), ('No', '.')]

>> Trigrams are: 
 [('10', ',', 'No'), (',', 'No', '.')]

>> POS Tags are: 
 [('10', 'CD'), (',', ','), ('No', 'DT'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('10', '10'), (',', ','), ('No', 'no'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('10', '10'), (',', ','), ('No', 'no'), ('.', '.')]

>> Lemmatization: 
 [('10', '10'), (',', ','), ('No', 'No'), ('.', '.')]



========================================== PARAGRAPH 660 ===========================================

14 (Ver.1.0), pp. 37-41, 2010.  

------------------- Sentence 1 -------------------

14 (Ver.1.0), pp.

>> Tokens are: 
 ['14', '(', 'Ver.1.0', ')', ',', 'pp', '.']

>> Bigrams are: 
 [('14', '('), ('(', 'Ver.1.0'), ('Ver.1.0', ')'), (')', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('14', '(', 'Ver.1.0'), ('(', 'Ver.1.0', ')'), ('Ver.1.0', ')', ','), (')', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('14', 'CD'), ('(', '('), ('Ver.1.0', 'NNP'), (')', ')'), (',', ','), ('pp', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Ver.1.0', 'pp']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('14', '14'), ('(', '('), ('Ver.1.0', 'ver.1.0'), (')', ')'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('14', '14'), ('(', '('), ('Ver.1.0', 'ver.1.0'), (')', ')'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('14', '14'), ('(', '('), ('Ver.1.0', 'Ver.1.0'), (')', ')'), (',', ','), ('pp', 'pp'), ('.', '.')]


------------------- Sentence 2 -------------------

37-41, 2010.

>> Tokens are: 
 ['37-41', ',', '2010', '.']

>> Bigrams are: 
 [('37-41', ','), (',', '2010'), ('2010', '.')]

>> Trigrams are: 
 [('37-41', ',', '2010'), (',', '2010', '.')]

>> POS Tags are: 
 [('37-41', 'CD'), (',', ','), ('2010', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('37-41', '37-41'), (',', ','), ('2010', '2010'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('37-41', '37-41'), (',', ','), ('2010', '2010'), ('.', '.')]

>> Lemmatization: 
 [('37-41', '37-41'), (',', ','), ('2010', '2010'), ('.', '.')]



========================================== PARAGRAPH 661 ===========================================

[28] Yen-Liang Chen and Lucas Tzu-Hsuan Hung, Using  decision trees to summarize associative classification  

------------------- Sentence 1 -------------------

[28] Yen-Liang Chen and Lucas Tzu-Hsuan Hung, Using  decision trees to summarize associative classification

>> Tokens are: 
 ['[', '28', ']', 'Yen-Liang', 'Chen', 'Lucas', 'Tzu-Hsuan', 'Hung', ',', '', 'Using', 'decision', 'trees', 'summarize', 'associative', 'classification']

>> Bigrams are: 
 [('[', '28'), ('28', ']'), (']', 'Yen-Liang'), ('Yen-Liang', 'Chen'), ('Chen', 'Lucas'), ('Lucas', 'Tzu-Hsuan'), ('Tzu-Hsuan', 'Hung'), ('Hung', ','), (',', ''), ('', 'Using'), ('Using', 'decision'), ('decision', 'trees'), ('trees', 'summarize'), ('summarize', 'associative'), ('associative', 'classification')]

>> Trigrams are: 
 [('[', '28', ']'), ('28', ']', 'Yen-Liang'), (']', 'Yen-Liang', 'Chen'), ('Yen-Liang', 'Chen', 'Lucas'), ('Chen', 'Lucas', 'Tzu-Hsuan'), ('Lucas', 'Tzu-Hsuan', 'Hung'), ('Tzu-Hsuan', 'Hung', ','), ('Hung', ',', ''), (',', '', 'Using'), ('', 'Using', 'decision'), ('Using', 'decision', 'trees'), ('decision', 'trees', 'summarize'), ('trees', 'summarize', 'associative'), ('summarize', 'associative', 'classification')]

>> POS Tags are: 
 [('[', 'RB'), ('28', 'CD'), (']', 'JJ'), ('Yen-Liang', 'NNP'), ('Chen', 'NNP'), ('Lucas', 'NNP'), ('Tzu-Hsuan', 'NNP'), ('Hung', 'NNP'), (',', ','), ('', 'NNP'), ('Using', 'NNP'), ('decision', 'NN'), ('trees', 'NNS'), ('summarize', 'VBP'), ('associative', 'JJ'), ('classification', 'NN')]

>> Noun Phrases are: 
 ['] Yen-Liang Chen Lucas Tzu-Hsuan Hung', ' Using decision trees', 'associative classification']

>> Named Entities are: 
 [('PERSON', 'Chen Lucas')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('28', '28'), (']', ']'), ('Yen-Liang', 'yen-liang'), ('Chen', 'chen'), ('Lucas', 'luca'), ('Tzu-Hsuan', 'tzu-hsuan'), ('Hung', 'hung'), (',', ','), ('', ''), ('Using', 'use'), ('decision', 'decis'), ('trees', 'tree'), ('summarize', 'summar'), ('associative', 'associ'), ('classification', 'classif')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('28', '28'), (']', ']'), ('Yen-Liang', 'yen-liang'), ('Chen', 'chen'), ('Lucas', 'luca'), ('Tzu-Hsuan', 'tzu-hsuan'), ('Hung', 'hung'), (',', ','), ('', ''), ('Using', 'use'), ('decision', 'decis'), ('trees', 'tree'), ('summarize', 'summar'), ('associative', 'associ'), ('classification', 'classif')]

>> Lemmatization: 
 [('[', '['), ('28', '28'), (']', ']'), ('Yen-Liang', 'Yen-Liang'), ('Chen', 'Chen'), ('Lucas', 'Lucas'), ('Tzu-Hsuan', 'Tzu-Hsuan'), ('Hung', 'Hung'), (',', ','), ('', ''), ('Using', 'Using'), ('decision', 'decision'), ('trees', 'tree'), ('summarize', 'summarize'), ('associative', 'associative'), ('classification', 'classification')]



========================================== PARAGRAPH 662 ===========================================

rules, Expert Systems with Applications, Vol. 36, No. 2,  

------------------- Sentence 1 -------------------

rules, Expert Systems with Applications, Vol.

>> Tokens are: 
 ['rules', '', ',', 'Expert', 'Systems', 'Applications', ',', 'Vol', '.']

>> Bigrams are: 
 [('rules', ''), ('', ','), (',', 'Expert'), ('Expert', 'Systems'), ('Systems', 'Applications'), ('Applications', ','), (',', 'Vol'), ('Vol', '.')]

>> Trigrams are: 
 [('rules', '', ','), ('', ',', 'Expert'), (',', 'Expert', 'Systems'), ('Expert', 'Systems', 'Applications'), ('Systems', 'Applications', ','), ('Applications', ',', 'Vol'), (',', 'Vol', '.')]

>> POS Tags are: 
 [('rules', 'NNS'), ('', 'VBP'), (',', ','), ('Expert', 'NNP'), ('Systems', 'NNP'), ('Applications', 'NNP'), (',', ','), ('Vol', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['rules', 'Expert Systems Applications', 'Vol']

>> Named Entities are: 
 [('PERSON', 'Expert Systems Applications'), ('PERSON', 'Vol')] 

>> Stemming using Porter Stemmer: 
 [('rules', 'rule'), ('', ''), (',', ','), ('Expert', 'expert'), ('Systems', 'system'), ('Applications', 'applic'), (',', ','), ('Vol', 'vol'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('rules', 'rule'), ('', ''), (',', ','), ('Expert', 'expert'), ('Systems', 'system'), ('Applications', 'applic'), (',', ','), ('Vol', 'vol'), ('.', '.')]

>> Lemmatization: 
 [('rules', 'rule'), ('', ''), (',', ','), ('Expert', 'Expert'), ('Systems', 'Systems'), ('Applications', 'Applications'), (',', ','), ('Vol', 'Vol'), ('.', '.')]


------------------- Sentence 2 -------------------

36, No.

>> Tokens are: 
 ['36', ',', 'No', '.']

>> Bigrams are: 
 [('36', ','), (',', 'No'), ('No', '.')]

>> Trigrams are: 
 [('36', ',', 'No'), (',', 'No', '.')]

>> POS Tags are: 
 [('36', 'CD'), (',', ','), ('No', 'DT'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('36', '36'), (',', ','), ('No', 'no'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('36', '36'), (',', ','), ('No', 'no'), ('.', '.')]

>> Lemmatization: 
 [('36', '36'), (',', ','), ('No', 'No'), ('.', '.')]


------------------- Sentence 3 -------------------

2,

>> Tokens are: 
 ['2', ',']

>> Bigrams are: 
 [('2', ',')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('2', 'CD'), (',', ',')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('2', '2'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('2', '2'), (',', ',')]

>> Lemmatization: 
 [('2', '2'), (',', ',')]



========================================== PARAGRAPH 663 ===========================================

Part 1, pp. 2338-2351, 2009.  

------------------- Sentence 1 -------------------

Part 1, pp.

>> Tokens are: 
 ['Part', '1', ',', 'pp', '.']

>> Bigrams are: 
 [('Part', '1'), ('1', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('Part', '1', ','), ('1', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('Part', 'NN'), ('1', 'CD'), (',', ','), ('pp', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Part', 'pp']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Part', 'part'), ('1', '1'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Part', 'part'), ('1', '1'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('Part', 'Part'), ('1', '1'), (',', ','), ('pp', 'pp'), ('.', '.')]


------------------- Sentence 2 -------------------

2338-2351, 2009.

>> Tokens are: 
 ['2338-2351', ',', '2009', '.']

>> Bigrams are: 
 [('2338-2351', ','), (',', '2009'), ('2009', '.')]

>> Trigrams are: 
 [('2338-2351', ',', '2009'), (',', '2009', '.')]

>> POS Tags are: 
 [('2338-2351', 'CD'), (',', ','), ('2009', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('2338-2351', '2338-2351'), (',', ','), ('2009', '2009'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('2338-2351', '2338-2351'), (',', ','), ('2009', '2009'), ('.', '.')]

>> Lemmatization: 
 [('2338-2351', '2338-2351'), (',', ','), ('2009', '2009'), ('.', '.')]



========================================== PARAGRAPH 664 ===========================================

[29] Samy Bengio, Li Deng, Hugo Larochelle, Honglak Lee, and  Ruslan Salakhutdinov, Guest Editors Introduction: Special  

------------------- Sentence 1 -------------------

[29] Samy Bengio, Li Deng, Hugo Larochelle, Honglak Lee, and  Ruslan Salakhutdinov, Guest Editors Introduction: Special

>> Tokens are: 
 ['[', '29', ']', 'Samy', 'Bengio', ',', 'Li', 'Deng', ',', 'Hugo', 'Larochelle', ',', 'Honglak', 'Lee', ',', 'Ruslan', 'Salakhutdinov', ',', '', 'Guest', 'Editors', '', 'Introduction', ':', 'Special']

>> Bigrams are: 
 [('[', '29'), ('29', ']'), (']', 'Samy'), ('Samy', 'Bengio'), ('Bengio', ','), (',', 'Li'), ('Li', 'Deng'), ('Deng', ','), (',', 'Hugo'), ('Hugo', 'Larochelle'), ('Larochelle', ','), (',', 'Honglak'), ('Honglak', 'Lee'), ('Lee', ','), (',', 'Ruslan'), ('Ruslan', 'Salakhutdinov'), ('Salakhutdinov', ','), (',', ''), ('', 'Guest'), ('Guest', 'Editors'), ('Editors', ''), ('', 'Introduction'), ('Introduction', ':'), (':', 'Special')]

>> Trigrams are: 
 [('[', '29', ']'), ('29', ']', 'Samy'), (']', 'Samy', 'Bengio'), ('Samy', 'Bengio', ','), ('Bengio', ',', 'Li'), (',', 'Li', 'Deng'), ('Li', 'Deng', ','), ('Deng', ',', 'Hugo'), (',', 'Hugo', 'Larochelle'), ('Hugo', 'Larochelle', ','), ('Larochelle', ',', 'Honglak'), (',', 'Honglak', 'Lee'), ('Honglak', 'Lee', ','), ('Lee', ',', 'Ruslan'), (',', 'Ruslan', 'Salakhutdinov'), ('Ruslan', 'Salakhutdinov', ','), ('Salakhutdinov', ',', ''), (',', '', 'Guest'), ('', 'Guest', 'Editors'), ('Guest', 'Editors', ''), ('Editors', '', 'Introduction'), ('', 'Introduction', ':'), ('Introduction', ':', 'Special')]

>> POS Tags are: 
 [('[', 'RB'), ('29', 'CD'), (']', 'JJ'), ('Samy', 'NNP'), ('Bengio', 'NNP'), (',', ','), ('Li', 'NNP'), ('Deng', 'NNP'), (',', ','), ('Hugo', 'NNP'), ('Larochelle', 'NNP'), (',', ','), ('Honglak', 'NNP'), ('Lee', 'NNP'), (',', ','), ('Ruslan', 'NNP'), ('Salakhutdinov', 'NNP'), (',', ','), ('', 'NNP'), ('Guest', 'NNP'), ('Editors', 'NNPS'), ('', 'NNP'), ('Introduction', 'NNP'), (':', ':'), ('Special', 'JJ')]

>> Noun Phrases are: 
 ['] Samy Bengio', 'Li Deng', 'Hugo Larochelle', 'Honglak Lee', 'Ruslan Salakhutdinov', ' Guest', ' Introduction']

>> Named Entities are: 
 [('PERSON', 'Samy Bengio'), ('PERSON', 'Li Deng'), ('PERSON', 'Hugo Larochelle'), ('PERSON', 'Honglak Lee'), ('PERSON', 'Ruslan Salakhutdinov')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('29', '29'), (']', ']'), ('Samy', 'sami'), ('Bengio', 'bengio'), (',', ','), ('Li', 'li'), ('Deng', 'deng'), (',', ','), ('Hugo', 'hugo'), ('Larochelle', 'larochel'), (',', ','), ('Honglak', 'honglak'), ('Lee', 'lee'), (',', ','), ('Ruslan', 'ruslan'), ('Salakhutdinov', 'salakhutdinov'), (',', ','), ('', ''), ('Guest', 'guest'), ('Editors', 'editor'), ('', ''), ('Introduction', 'introduct'), (':', ':'), ('Special', 'special')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('29', '29'), (']', ']'), ('Samy', 'sami'), ('Bengio', 'bengio'), (',', ','), ('Li', 'li'), ('Deng', 'deng'), (',', ','), ('Hugo', 'hugo'), ('Larochelle', 'larochell'), (',', ','), ('Honglak', 'honglak'), ('Lee', 'lee'), (',', ','), ('Ruslan', 'ruslan'), ('Salakhutdinov', 'salakhutdinov'), (',', ','), ('', ''), ('Guest', 'guest'), ('Editors', 'editor'), ('', ''), ('Introduction', 'introduct'), (':', ':'), ('Special', 'special')]

>> Lemmatization: 
 [('[', '['), ('29', '29'), (']', ']'), ('Samy', 'Samy'), ('Bengio', 'Bengio'), (',', ','), ('Li', 'Li'), ('Deng', 'Deng'), (',', ','), ('Hugo', 'Hugo'), ('Larochelle', 'Larochelle'), (',', ','), ('Honglak', 'Honglak'), ('Lee', 'Lee'), (',', ','), ('Ruslan', 'Ruslan'), ('Salakhutdinov', 'Salakhutdinov'), (',', ','), ('', ''), ('Guest', 'Guest'), ('Editors', 'Editors'), ('', ''), ('Introduction', 'Introduction'), (':', ':'), ('Special', 'Special')]



========================================== PARAGRAPH 665 ===========================================

Section on Learning Deep Architectures, IEEE  

------------------- Sentence 1 -------------------

Section on Learning Deep Architectures, IEEE

>> Tokens are: 
 ['Section', 'Learning', 'Deep', 'Architectures', '', ',', 'IEEE']

>> Bigrams are: 
 [('Section', 'Learning'), ('Learning', 'Deep'), ('Deep', 'Architectures'), ('Architectures', ''), ('', ','), (',', 'IEEE')]

>> Trigrams are: 
 [('Section', 'Learning', 'Deep'), ('Learning', 'Deep', 'Architectures'), ('Deep', 'Architectures', ''), ('Architectures', '', ','), ('', ',', 'IEEE')]

>> POS Tags are: 
 [('Section', 'NN'), ('Learning', 'NNP'), ('Deep', 'NNP'), ('Architectures', 'NNP'), ('', 'NNP'), (',', ','), ('IEEE', 'NNP')]

>> Noun Phrases are: 
 ['Section Learning Deep Architectures ', 'IEEE']

>> Named Entities are: 
 [('ORGANIZATION', 'IEEE')] 

>> Stemming using Porter Stemmer: 
 [('Section', 'section'), ('Learning', 'learn'), ('Deep', 'deep'), ('Architectures', 'architectur'), ('', ''), (',', ','), ('IEEE', 'ieee')]

>> Stemming using Snowball Stemmer: 
 [('Section', 'section'), ('Learning', 'learn'), ('Deep', 'deep'), ('Architectures', 'architectur'), ('', ''), (',', ','), ('IEEE', 'ieee')]

>> Lemmatization: 
 [('Section', 'Section'), ('Learning', 'Learning'), ('Deep', 'Deep'), ('Architectures', 'Architectures'), ('', ''), (',', ','), ('IEEE', 'IEEE')]



========================================== PARAGRAPH 666 ===========================================

Transactions on   Pattern Analysis and Machine  

------------------- Sentence 1 -------------------

Transactions on   Pattern Analysis and Machine

>> Tokens are: 
 ['Transactions', 'Pattern', 'Analysis', 'Machine']

>> Bigrams are: 
 [('Transactions', 'Pattern'), ('Pattern', 'Analysis'), ('Analysis', 'Machine')]

>> Trigrams are: 
 [('Transactions', 'Pattern', 'Analysis'), ('Pattern', 'Analysis', 'Machine')]

>> POS Tags are: 
 [('Transactions', 'NNS'), ('Pattern', 'NNP'), ('Analysis', 'NNP'), ('Machine', 'NNP')]

>> Noun Phrases are: 
 ['Transactions Pattern Analysis Machine']

>> Named Entities are: 
 [('PERSON', 'Pattern Analysis Machine')] 

>> Stemming using Porter Stemmer: 
 [('Transactions', 'transact'), ('Pattern', 'pattern'), ('Analysis', 'analysi'), ('Machine', 'machin')]

>> Stemming using Snowball Stemmer: 
 [('Transactions', 'transact'), ('Pattern', 'pattern'), ('Analysis', 'analysi'), ('Machine', 'machin')]

>> Lemmatization: 
 [('Transactions', 'Transactions'), ('Pattern', 'Pattern'), ('Analysis', 'Analysis'), ('Machine', 'Machine')]



========================================== PARAGRAPH 667 ===========================================

Intelligence, Vol. 35, No. 8, pp. 1795-1797, 2013.  

------------------- Sentence 1 -------------------

Intelligence, Vol.

>> Tokens are: 
 ['Intelligence', ',', 'Vol', '.']

>> Bigrams are: 
 [('Intelligence', ','), (',', 'Vol'), ('Vol', '.')]

>> Trigrams are: 
 [('Intelligence', ',', 'Vol'), (',', 'Vol', '.')]

>> POS Tags are: 
 [('Intelligence', 'NN'), (',', ','), ('Vol', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Intelligence', 'Vol']

>> Named Entities are: 
 [('GPE', 'Intelligence'), ('PERSON', 'Vol')] 

>> Stemming using Porter Stemmer: 
 [('Intelligence', 'intellig'), (',', ','), ('Vol', 'vol'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Intelligence', 'intellig'), (',', ','), ('Vol', 'vol'), ('.', '.')]

>> Lemmatization: 
 [('Intelligence', 'Intelligence'), (',', ','), ('Vol', 'Vol'), ('.', '.')]


------------------- Sentence 2 -------------------

35, No.

>> Tokens are: 
 ['35', ',', 'No', '.']

>> Bigrams are: 
 [('35', ','), (',', 'No'), ('No', '.')]

>> Trigrams are: 
 [('35', ',', 'No'), (',', 'No', '.')]

>> POS Tags are: 
 [('35', 'CD'), (',', ','), ('No', 'DT'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('35', '35'), (',', ','), ('No', 'no'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('35', '35'), (',', ','), ('No', 'no'), ('.', '.')]

>> Lemmatization: 
 [('35', '35'), (',', ','), ('No', 'No'), ('.', '.')]


------------------- Sentence 3 -------------------

8, pp.

>> Tokens are: 
 ['8', ',', 'pp', '.']

>> Bigrams are: 
 [('8', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('8', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('8', 'CD'), (',', ','), ('pp', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['pp']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('8', '8'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('8', '8'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('8', '8'), (',', ','), ('pp', 'pp'), ('.', '.')]


------------------- Sentence 4 -------------------

1795-1797, 2013.

>> Tokens are: 
 ['1795-1797', ',', '2013', '.']

>> Bigrams are: 
 [('1795-1797', ','), (',', '2013'), ('2013', '.')]

>> Trigrams are: 
 [('1795-1797', ',', '2013'), (',', '2013', '.')]

>> POS Tags are: 
 [('1795-1797', 'CD'), (',', ','), ('2013', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('1795-1797', '1795-1797'), (',', ','), ('2013', '2013'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('1795-1797', '1795-1797'), (',', ','), ('2013', '2013'), ('.', '.')]

>> Lemmatization: 
 [('1795-1797', '1795-1797'), (',', ','), ('2013', '2013'), ('.', '.')]



========================================== PARAGRAPH 668 ===========================================

[30] Qinghua Zheng, Zhaohui Wu, Xiaocheng Cheng, Lu Jiang  and Jun Liu, Learning to crawl deep web, Information  

------------------- Sentence 1 -------------------

[30] Qinghua Zheng, Zhaohui Wu, Xiaocheng Cheng, Lu Jiang  and Jun Liu, Learning to crawl deep web, Information

>> Tokens are: 
 ['[', '30', ']', 'Qinghua', 'Zheng', ',', 'Zhaohui', 'Wu', ',', 'Xiaocheng', 'Cheng', ',', 'Lu', 'Jiang', 'Jun', 'Liu', ',', '', 'Learning', 'crawl', 'deep', 'web', '', ',', 'Information']

>> Bigrams are: 
 [('[', '30'), ('30', ']'), (']', 'Qinghua'), ('Qinghua', 'Zheng'), ('Zheng', ','), (',', 'Zhaohui'), ('Zhaohui', 'Wu'), ('Wu', ','), (',', 'Xiaocheng'), ('Xiaocheng', 'Cheng'), ('Cheng', ','), (',', 'Lu'), ('Lu', 'Jiang'), ('Jiang', 'Jun'), ('Jun', 'Liu'), ('Liu', ','), (',', ''), ('', 'Learning'), ('Learning', 'crawl'), ('crawl', 'deep'), ('deep', 'web'), ('web', ''), ('', ','), (',', 'Information')]

>> Trigrams are: 
 [('[', '30', ']'), ('30', ']', 'Qinghua'), (']', 'Qinghua', 'Zheng'), ('Qinghua', 'Zheng', ','), ('Zheng', ',', 'Zhaohui'), (',', 'Zhaohui', 'Wu'), ('Zhaohui', 'Wu', ','), ('Wu', ',', 'Xiaocheng'), (',', 'Xiaocheng', 'Cheng'), ('Xiaocheng', 'Cheng', ','), ('Cheng', ',', 'Lu'), (',', 'Lu', 'Jiang'), ('Lu', 'Jiang', 'Jun'), ('Jiang', 'Jun', 'Liu'), ('Jun', 'Liu', ','), ('Liu', ',', ''), (',', '', 'Learning'), ('', 'Learning', 'crawl'), ('Learning', 'crawl', 'deep'), ('crawl', 'deep', 'web'), ('deep', 'web', ''), ('web', '', ','), ('', ',', 'Information')]

>> POS Tags are: 
 [('[', 'RB'), ('30', 'CD'), (']', 'JJ'), ('Qinghua', 'NNP'), ('Zheng', 'NNP'), (',', ','), ('Zhaohui', 'NNP'), ('Wu', 'NNP'), (',', ','), ('Xiaocheng', 'NNP'), ('Cheng', 'NNP'), (',', ','), ('Lu', 'NNP'), ('Jiang', 'NNP'), ('Jun', 'NNP'), ('Liu', 'NNP'), (',', ','), ('', 'NNP'), ('Learning', 'NNP'), ('crawl', 'JJ'), ('deep', 'JJ'), ('web', 'NN'), ('', 'NNP'), (',', ','), ('Information', 'NNP')]

>> Noun Phrases are: 
 ['] Qinghua Zheng', 'Zhaohui Wu', 'Xiaocheng Cheng', 'Lu Jiang Jun Liu', ' Learning', 'crawl deep web ', 'Information']

>> Named Entities are: 
 [('PERSON', 'Qinghua Zheng'), ('PERSON', 'Zhaohui Wu'), ('PERSON', 'Xiaocheng Cheng'), ('PERSON', 'Lu Jiang Jun Liu')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('30', '30'), (']', ']'), ('Qinghua', 'qinghua'), ('Zheng', 'zheng'), (',', ','), ('Zhaohui', 'zhaohui'), ('Wu', 'wu'), (',', ','), ('Xiaocheng', 'xiaocheng'), ('Cheng', 'cheng'), (',', ','), ('Lu', 'lu'), ('Jiang', 'jiang'), ('Jun', 'jun'), ('Liu', 'liu'), (',', ','), ('', ''), ('Learning', 'learn'), ('crawl', 'crawl'), ('deep', 'deep'), ('web', 'web'), ('', ''), (',', ','), ('Information', 'inform')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('30', '30'), (']', ']'), ('Qinghua', 'qinghua'), ('Zheng', 'zheng'), (',', ','), ('Zhaohui', 'zhaohui'), ('Wu', 'wu'), (',', ','), ('Xiaocheng', 'xiaocheng'), ('Cheng', 'cheng'), (',', ','), ('Lu', 'lu'), ('Jiang', 'jiang'), ('Jun', 'jun'), ('Liu', 'liu'), (',', ','), ('', ''), ('Learning', 'learn'), ('crawl', 'crawl'), ('deep', 'deep'), ('web', 'web'), ('', ''), (',', ','), ('Information', 'inform')]

>> Lemmatization: 
 [('[', '['), ('30', '30'), (']', ']'), ('Qinghua', 'Qinghua'), ('Zheng', 'Zheng'), (',', ','), ('Zhaohui', 'Zhaohui'), ('Wu', 'Wu'), (',', ','), ('Xiaocheng', 'Xiaocheng'), ('Cheng', 'Cheng'), (',', ','), ('Lu', 'Lu'), ('Jiang', 'Jiang'), ('Jun', 'Jun'), ('Liu', 'Liu'), (',', ','), ('', ''), ('Learning', 'Learning'), ('crawl', 'crawl'), ('deep', 'deep'), ('web', 'web'), ('', ''), (',', ','), ('Information', 'Information')]



========================================== PARAGRAPH 669 ===========================================

Systems, Vol. 38, No. 6, pp. 801-819, 2013.  

------------------- Sentence 1 -------------------

Systems, Vol.

>> Tokens are: 
 ['Systems', ',', 'Vol', '.']

>> Bigrams are: 
 [('Systems', ','), (',', 'Vol'), ('Vol', '.')]

>> Trigrams are: 
 [('Systems', ',', 'Vol'), (',', 'Vol', '.')]

>> POS Tags are: 
 [('Systems', 'NNS'), (',', ','), ('Vol', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Systems', 'Vol']

>> Named Entities are: 
 [('PERSON', 'Vol')] 

>> Stemming using Porter Stemmer: 
 [('Systems', 'system'), (',', ','), ('Vol', 'vol'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Systems', 'system'), (',', ','), ('Vol', 'vol'), ('.', '.')]

>> Lemmatization: 
 [('Systems', 'Systems'), (',', ','), ('Vol', 'Vol'), ('.', '.')]


------------------- Sentence 2 -------------------

38, No.

>> Tokens are: 
 ['38', ',', 'No', '.']

>> Bigrams are: 
 [('38', ','), (',', 'No'), ('No', '.')]

>> Trigrams are: 
 [('38', ',', 'No'), (',', 'No', '.')]

>> POS Tags are: 
 [('38', 'CD'), (',', ','), ('No', 'DT'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('38', '38'), (',', ','), ('No', 'no'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('38', '38'), (',', ','), ('No', 'no'), ('.', '.')]

>> Lemmatization: 
 [('38', '38'), (',', ','), ('No', 'No'), ('.', '.')]


------------------- Sentence 3 -------------------

6, pp.

>> Tokens are: 
 ['6', ',', 'pp', '.']

>> Bigrams are: 
 [('6', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('6', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('6', 'CD'), (',', ','), ('pp', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['pp']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('6', '6'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('6', '6'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('6', '6'), (',', ','), ('pp', 'pp'), ('.', '.')]


------------------- Sentence 4 -------------------

801-819, 2013.

>> Tokens are: 
 ['801-819', ',', '2013', '.']

>> Bigrams are: 
 [('801-819', ','), (',', '2013'), ('2013', '.')]

>> Trigrams are: 
 [('801-819', ',', '2013'), (',', '2013', '.')]

>> POS Tags are: 
 [('801-819', 'CD'), (',', ','), ('2013', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('801-819', '801-819'), (',', ','), ('2013', '2013'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('801-819', '801-819'), (',', ','), ('2013', '2013'), ('.', '.')]

>> Lemmatization: 
 [('801-819', '801-819'), (',', ','), ('2013', '2013'), ('.', '.')]



========================================== PARAGRAPH 670 ===========================================

[31] Xue-Wen Chen and Xiaotong Lin, Big Data Deep  Learning: Challenges and Perspectives, IEEE Access  

------------------- Sentence 1 -------------------

[31] Xue-Wen Chen and Xiaotong Lin, Big Data Deep  Learning: Challenges and Perspectives, IEEE Access

>> Tokens are: 
 ['[', '31', ']', 'Xue-Wen', 'Chen', 'Xiaotong', 'Lin', ',', '', 'Big', 'Data', 'Deep', 'Learning', ':', 'Challenges', 'Perspectives', '', ',', 'IEEE', 'Access']

>> Bigrams are: 
 [('[', '31'), ('31', ']'), (']', 'Xue-Wen'), ('Xue-Wen', 'Chen'), ('Chen', 'Xiaotong'), ('Xiaotong', 'Lin'), ('Lin', ','), (',', ''), ('', 'Big'), ('Big', 'Data'), ('Data', 'Deep'), ('Deep', 'Learning'), ('Learning', ':'), (':', 'Challenges'), ('Challenges', 'Perspectives'), ('Perspectives', ''), ('', ','), (',', 'IEEE'), ('IEEE', 'Access')]

>> Trigrams are: 
 [('[', '31', ']'), ('31', ']', 'Xue-Wen'), (']', 'Xue-Wen', 'Chen'), ('Xue-Wen', 'Chen', 'Xiaotong'), ('Chen', 'Xiaotong', 'Lin'), ('Xiaotong', 'Lin', ','), ('Lin', ',', ''), (',', '', 'Big'), ('', 'Big', 'Data'), ('Big', 'Data', 'Deep'), ('Data', 'Deep', 'Learning'), ('Deep', 'Learning', ':'), ('Learning', ':', 'Challenges'), (':', 'Challenges', 'Perspectives'), ('Challenges', 'Perspectives', ''), ('Perspectives', '', ','), ('', ',', 'IEEE'), (',', 'IEEE', 'Access')]

>> POS Tags are: 
 [('[', 'RB'), ('31', 'CD'), (']', 'JJ'), ('Xue-Wen', 'JJ'), ('Chen', 'NNP'), ('Xiaotong', 'NNP'), ('Lin', 'NNP'), (',', ','), ('', 'NNP'), ('Big', 'NNP'), ('Data', 'NNP'), ('Deep', 'NNP'), ('Learning', 'NNP'), (':', ':'), ('Challenges', 'VBZ'), ('Perspectives', 'NNS'), ('', 'NNP'), (',', ','), ('IEEE', 'NNP'), ('Access', 'NNP')]

>> Noun Phrases are: 
 ['] Xue-Wen Chen Xiaotong Lin', ' Big Data Deep Learning', 'Perspectives ', 'IEEE Access']

>> Named Entities are: 
 [('PERSON', 'Chen Xiaotong Lin'), ('ORGANIZATION', 'IEEE Access')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('31', '31'), (']', ']'), ('Xue-Wen', 'xue-wen'), ('Chen', 'chen'), ('Xiaotong', 'xiaotong'), ('Lin', 'lin'), (',', ','), ('', ''), ('Big', 'big'), ('Data', 'data'), ('Deep', 'deep'), ('Learning', 'learn'), (':', ':'), ('Challenges', 'challeng'), ('Perspectives', 'perspect'), ('', ''), (',', ','), ('IEEE', 'ieee'), ('Access', 'access')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('31', '31'), (']', ']'), ('Xue-Wen', 'xue-wen'), ('Chen', 'chen'), ('Xiaotong', 'xiaotong'), ('Lin', 'lin'), (',', ','), ('', ''), ('Big', 'big'), ('Data', 'data'), ('Deep', 'deep'), ('Learning', 'learn'), (':', ':'), ('Challenges', 'challeng'), ('Perspectives', 'perspect'), ('', ''), (',', ','), ('IEEE', 'ieee'), ('Access', 'access')]

>> Lemmatization: 
 [('[', '['), ('31', '31'), (']', ']'), ('Xue-Wen', 'Xue-Wen'), ('Chen', 'Chen'), ('Xiaotong', 'Xiaotong'), ('Lin', 'Lin'), (',', ','), ('', ''), ('Big', 'Big'), ('Data', 'Data'), ('Deep', 'Deep'), ('Learning', 'Learning'), (':', ':'), ('Challenges', 'Challenges'), ('Perspectives', 'Perspectives'), ('', ''), (',', ','), ('IEEE', 'IEEE'), ('Access', 'Access')]



========================================== PARAGRAPH 671 ===========================================

Practical Innovations: Open Solutions and Access and  

------------------- Sentence 1 -------------------

Practical Innovations: Open Solutions and Access and

>> Tokens are: 
 ['Practical', 'Innovations', ':', 'Open', 'Solutions', 'Access']

>> Bigrams are: 
 [('Practical', 'Innovations'), ('Innovations', ':'), (':', 'Open'), ('Open', 'Solutions'), ('Solutions', 'Access')]

>> Trigrams are: 
 [('Practical', 'Innovations', ':'), ('Innovations', ':', 'Open'), (':', 'Open', 'Solutions'), ('Open', 'Solutions', 'Access')]

>> POS Tags are: 
 [('Practical', 'JJ'), ('Innovations', 'NNS'), (':', ':'), ('Open', 'JJ'), ('Solutions', 'NNP'), ('Access', 'NNP')]

>> Noun Phrases are: 
 ['Practical Innovations', 'Open Solutions Access']

>> Named Entities are: 
 [('GPE', 'Practical')] 

>> Stemming using Porter Stemmer: 
 [('Practical', 'practic'), ('Innovations', 'innov'), (':', ':'), ('Open', 'open'), ('Solutions', 'solut'), ('Access', 'access')]

>> Stemming using Snowball Stemmer: 
 [('Practical', 'practic'), ('Innovations', 'innov'), (':', ':'), ('Open', 'open'), ('Solutions', 'solut'), ('Access', 'access')]

>> Lemmatization: 
 [('Practical', 'Practical'), ('Innovations', 'Innovations'), (':', ':'), ('Open', 'Open'), ('Solutions', 'Solutions'), ('Access', 'Access')]



========================================== PARAGRAPH 672 ===========================================

IEEE, Vol. 2, pp. 514-525, 2014.  

------------------- Sentence 1 -------------------

IEEE, Vol.

>> Tokens are: 
 ['IEEE', ',', 'Vol', '.']

>> Bigrams are: 
 [('IEEE', ','), (',', 'Vol'), ('Vol', '.')]

>> Trigrams are: 
 [('IEEE', ',', 'Vol'), (',', 'Vol', '.')]

>> POS Tags are: 
 [('IEEE', 'NNP'), (',', ','), ('Vol', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['IEEE', 'Vol']

>> Named Entities are: 
 [('GPE', 'IEEE'), ('PERSON', 'Vol')] 

>> Stemming using Porter Stemmer: 
 [('IEEE', 'ieee'), (',', ','), ('Vol', 'vol'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('IEEE', 'ieee'), (',', ','), ('Vol', 'vol'), ('.', '.')]

>> Lemmatization: 
 [('IEEE', 'IEEE'), (',', ','), ('Vol', 'Vol'), ('.', '.')]


------------------- Sentence 2 -------------------

2, pp.

>> Tokens are: 
 ['2', ',', 'pp', '.']

>> Bigrams are: 
 [('2', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('2', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('2', 'CD'), (',', ','), ('pp', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['pp']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('2', '2'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('2', '2'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('2', '2'), (',', ','), ('pp', 'pp'), ('.', '.')]


------------------- Sentence 3 -------------------

514-525, 2014.

>> Tokens are: 
 ['514-525', ',', '2014', '.']

>> Bigrams are: 
 [('514-525', ','), (',', '2014'), ('2014', '.')]

>> Trigrams are: 
 [('514-525', ',', '2014'), (',', '2014', '.')]

>> POS Tags are: 
 [('514-525', 'CD'), (',', ','), ('2014', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('514-525', '514-525'), (',', ','), ('2014', '2014'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('514-525', '514-525'), (',', ','), ('2014', '2014'), ('.', '.')]

>> Lemmatization: 
 [('514-525', '514-525'), (',', ','), ('2014', '2014'), ('.', '.')]



========================================== PARAGRAPH 673 ===========================================

[32] Rajat Raina, Anand Madhavan and Andrew Yg, Large- scale Deep Unsupervised Learning using Graphics  

------------------- Sentence 1 -------------------

[32] Rajat Raina, Anand Madhavan and Andrew Yg, Large- scale Deep Unsupervised Learning using Graphics

>> Tokens are: 
 ['[', '32', ']', 'Rajat', 'Raina', ',', 'Anand', 'Madhavan', 'Andrew', 'Yg', ',', '', 'Large-', 'scale', 'Deep', 'Unsupervised', 'Learning', 'using', 'Graphics']

>> Bigrams are: 
 [('[', '32'), ('32', ']'), (']', 'Rajat'), ('Rajat', 'Raina'), ('Raina', ','), (',', 'Anand'), ('Anand', 'Madhavan'), ('Madhavan', 'Andrew'), ('Andrew', 'Yg'), ('Yg', ','), (',', ''), ('', 'Large-'), ('Large-', 'scale'), ('scale', 'Deep'), ('Deep', 'Unsupervised'), ('Unsupervised', 'Learning'), ('Learning', 'using'), ('using', 'Graphics')]

>> Trigrams are: 
 [('[', '32', ']'), ('32', ']', 'Rajat'), (']', 'Rajat', 'Raina'), ('Rajat', 'Raina', ','), ('Raina', ',', 'Anand'), (',', 'Anand', 'Madhavan'), ('Anand', 'Madhavan', 'Andrew'), ('Madhavan', 'Andrew', 'Yg'), ('Andrew', 'Yg', ','), ('Yg', ',', ''), (',', '', 'Large-'), ('', 'Large-', 'scale'), ('Large-', 'scale', 'Deep'), ('scale', 'Deep', 'Unsupervised'), ('Deep', 'Unsupervised', 'Learning'), ('Unsupervised', 'Learning', 'using'), ('Learning', 'using', 'Graphics')]

>> POS Tags are: 
 [('[', 'RB'), ('32', 'CD'), (']', 'JJ'), ('Rajat', 'NNP'), ('Raina', 'NNP'), (',', ','), ('Anand', 'NNP'), ('Madhavan', 'NNP'), ('Andrew', 'NNP'), ('Yg', 'NNP'), (',', ','), ('', 'NNP'), ('Large-', 'NNP'), ('scale', 'NN'), ('Deep', 'NNP'), ('Unsupervised', 'VBD'), ('Learning', 'NNP'), ('using', 'VBG'), ('Graphics', 'NNS')]

>> Noun Phrases are: 
 ['] Rajat Raina', 'Anand Madhavan Andrew Yg', ' Large- scale Deep', 'Learning', 'Graphics']

>> Named Entities are: 
 [('PERSON', 'Rajat Raina'), ('PERSON', 'Anand Madhavan'), ('PERSON', 'Andrew Yg'), ('PERSON', 'Deep')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('32', '32'), (']', ']'), ('Rajat', 'rajat'), ('Raina', 'raina'), (',', ','), ('Anand', 'anand'), ('Madhavan', 'madhavan'), ('Andrew', 'andrew'), ('Yg', 'yg'), (',', ','), ('', ''), ('Large-', 'large-'), ('scale', 'scale'), ('Deep', 'deep'), ('Unsupervised', 'unsupervis'), ('Learning', 'learn'), ('using', 'use'), ('Graphics', 'graphic')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('32', '32'), (']', ']'), ('Rajat', 'rajat'), ('Raina', 'raina'), (',', ','), ('Anand', 'anand'), ('Madhavan', 'madhavan'), ('Andrew', 'andrew'), ('Yg', 'yg'), (',', ','), ('', ''), ('Large-', 'large-'), ('scale', 'scale'), ('Deep', 'deep'), ('Unsupervised', 'unsupervis'), ('Learning', 'learn'), ('using', 'use'), ('Graphics', 'graphic')]

>> Lemmatization: 
 [('[', '['), ('32', '32'), (']', ']'), ('Rajat', 'Rajat'), ('Raina', 'Raina'), (',', ','), ('Anand', 'Anand'), ('Madhavan', 'Madhavan'), ('Andrew', 'Andrew'), ('Yg', 'Yg'), (',', ','), ('', ''), ('Large-', 'Large-'), ('scale', 'scale'), ('Deep', 'Deep'), ('Unsupervised', 'Unsupervised'), ('Learning', 'Learning'), ('using', 'using'), ('Graphics', 'Graphics')]



========================================== PARAGRAPH 674 ===========================================

Processors, 26 th  International Conference on Machine  

------------------- Sentence 1 -------------------

Processors, 26 th  International Conference on Machine

>> Tokens are: 
 ['Processors', '', ',', '26', 'th', 'International', 'Conference', 'Machine']

>> Bigrams are: 
 [('Processors', ''), ('', ','), (',', '26'), ('26', 'th'), ('th', 'International'), ('International', 'Conference'), ('Conference', 'Machine')]

>> Trigrams are: 
 [('Processors', '', ','), ('', ',', '26'), (',', '26', 'th'), ('26', 'th', 'International'), ('th', 'International', 'Conference'), ('International', 'Conference', 'Machine')]

>> POS Tags are: 
 [('Processors', 'NNS'), ('', 'VBP'), (',', ','), ('26', 'CD'), ('th', 'JJ'), ('International', 'NNP'), ('Conference', 'NNP'), ('Machine', 'NNP')]

>> Noun Phrases are: 
 ['Processors', 'th International Conference Machine']

>> Named Entities are: 
 [('ORGANIZATION', 'International Conference Machine')] 

>> Stemming using Porter Stemmer: 
 [('Processors', 'processor'), ('', ''), (',', ','), ('26', '26'), ('th', 'th'), ('International', 'intern'), ('Conference', 'confer'), ('Machine', 'machin')]

>> Stemming using Snowball Stemmer: 
 [('Processors', 'processor'), ('', ''), (',', ','), ('26', '26'), ('th', 'th'), ('International', 'intern'), ('Conference', 'confer'), ('Machine', 'machin')]

>> Lemmatization: 
 [('Processors', 'Processors'), ('', ''), (',', ','), ('26', '26'), ('th', 'th'), ('International', 'International'), ('Conference', 'Conference'), ('Machine', 'Machine')]



========================================== PARAGRAPH 675 ===========================================

Learning, pp. 609-616, 2009.  

------------------- Sentence 1 -------------------

Learning, pp.

>> Tokens are: 
 ['Learning', ',', 'pp', '.']

>> Bigrams are: 
 [('Learning', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('Learning', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('Learning', 'NNP'), (',', ','), ('pp', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Learning', 'pp']

>> Named Entities are: 
 [('GPE', 'Learning')] 

>> Stemming using Porter Stemmer: 
 [('Learning', 'learn'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Learning', 'learn'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('Learning', 'Learning'), (',', ','), ('pp', 'pp'), ('.', '.')]


------------------- Sentence 2 -------------------

609-616, 2009.

>> Tokens are: 
 ['609-616', ',', '2009', '.']

>> Bigrams are: 
 [('609-616', ','), (',', '2009'), ('2009', '.')]

>> Trigrams are: 
 [('609-616', ',', '2009'), (',', '2009', '.')]

>> POS Tags are: 
 [('609-616', 'CD'), (',', ','), ('2009', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('609-616', '609-616'), (',', ','), ('2009', '2009'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('609-616', '609-616'), (',', ','), ('2009', '2009'), ('.', '.')]

>> Lemmatization: 
 [('609-616', '609-616'), (',', ','), ('2009', '2009'), ('.', '.')]



========================================== PARAGRAPH 676 ===========================================

[33] Alex Krizhevsky, Ilya Sutskever and Geoffrey E. Hinton,  ImageNet Classification with Deep Convolutional Neural  

------------------- Sentence 1 -------------------

[33] Alex Krizhevsky, Ilya Sutskever and Geoffrey E. Hinton,  ImageNet Classification with Deep Convolutional Neural

>> Tokens are: 
 ['[', '33', ']', 'Alex', 'Krizhevsky', ',', 'Ilya', 'Sutskever', 'Geoffrey', 'E.', 'Hinton', ',', '', 'ImageNet', 'Classification', 'Deep', 'Convolutional', 'Neural']

>> Bigrams are: 
 [('[', '33'), ('33', ']'), (']', 'Alex'), ('Alex', 'Krizhevsky'), ('Krizhevsky', ','), (',', 'Ilya'), ('Ilya', 'Sutskever'), ('Sutskever', 'Geoffrey'), ('Geoffrey', 'E.'), ('E.', 'Hinton'), ('Hinton', ','), (',', ''), ('', 'ImageNet'), ('ImageNet', 'Classification'), ('Classification', 'Deep'), ('Deep', 'Convolutional'), ('Convolutional', 'Neural')]

>> Trigrams are: 
 [('[', '33', ']'), ('33', ']', 'Alex'), (']', 'Alex', 'Krizhevsky'), ('Alex', 'Krizhevsky', ','), ('Krizhevsky', ',', 'Ilya'), (',', 'Ilya', 'Sutskever'), ('Ilya', 'Sutskever', 'Geoffrey'), ('Sutskever', 'Geoffrey', 'E.'), ('Geoffrey', 'E.', 'Hinton'), ('E.', 'Hinton', ','), ('Hinton', ',', ''), (',', '', 'ImageNet'), ('', 'ImageNet', 'Classification'), ('ImageNet', 'Classification', 'Deep'), ('Classification', 'Deep', 'Convolutional'), ('Deep', 'Convolutional', 'Neural')]

>> POS Tags are: 
 [('[', 'RB'), ('33', 'CD'), (']', 'JJ'), ('Alex', 'NNP'), ('Krizhevsky', 'NNP'), (',', ','), ('Ilya', 'NNP'), ('Sutskever', 'NNP'), ('Geoffrey', 'NNP'), ('E.', 'NNP'), ('Hinton', 'NNP'), (',', ','), ('', 'NNP'), ('ImageNet', 'NNP'), ('Classification', 'NNP'), ('Deep', 'NNP'), ('Convolutional', 'NNP'), ('Neural', 'NNP')]

>> Noun Phrases are: 
 ['] Alex Krizhevsky', 'Ilya Sutskever Geoffrey E. Hinton', ' ImageNet Classification Deep Convolutional Neural']

>> Named Entities are: 
 [('PERSON', 'Alex Krizhevsky'), ('PERSON', 'Ilya Sutskever Geoffrey'), ('PERSON', 'Hinton')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('33', '33'), (']', ']'), ('Alex', 'alex'), ('Krizhevsky', 'krizhevski'), (',', ','), ('Ilya', 'ilya'), ('Sutskever', 'sutskev'), ('Geoffrey', 'geoffrey'), ('E.', 'e.'), ('Hinton', 'hinton'), (',', ','), ('', ''), ('ImageNet', 'imagenet'), ('Classification', 'classif'), ('Deep', 'deep'), ('Convolutional', 'convolut'), ('Neural', 'neural')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('33', '33'), (']', ']'), ('Alex', 'alex'), ('Krizhevsky', 'krizhevski'), (',', ','), ('Ilya', 'ilya'), ('Sutskever', 'sutskev'), ('Geoffrey', 'geoffrey'), ('E.', 'e.'), ('Hinton', 'hinton'), (',', ','), ('', ''), ('ImageNet', 'imagenet'), ('Classification', 'classif'), ('Deep', 'deep'), ('Convolutional', 'convolut'), ('Neural', 'neural')]

>> Lemmatization: 
 [('[', '['), ('33', '33'), (']', ']'), ('Alex', 'Alex'), ('Krizhevsky', 'Krizhevsky'), (',', ','), ('Ilya', 'Ilya'), ('Sutskever', 'Sutskever'), ('Geoffrey', 'Geoffrey'), ('E.', 'E.'), ('Hinton', 'Hinton'), (',', ','), ('', ''), ('ImageNet', 'ImageNet'), ('Classification', 'Classification'), ('Deep', 'Deep'), ('Convolutional', 'Convolutional'), ('Neural', 'Neural')]



========================================== PARAGRAPH 677 ===========================================

Networks, Advances in Neural Information Processing  

------------------- Sentence 1 -------------------

Networks, Advances in Neural Information Processing

>> Tokens are: 
 ['Networks', '', ',', 'Advances', 'Neural', 'Information', 'Processing']

>> Bigrams are: 
 [('Networks', ''), ('', ','), (',', 'Advances'), ('Advances', 'Neural'), ('Neural', 'Information'), ('Information', 'Processing')]

>> Trigrams are: 
 [('Networks', '', ','), ('', ',', 'Advances'), (',', 'Advances', 'Neural'), ('Advances', 'Neural', 'Information'), ('Neural', 'Information', 'Processing')]

>> POS Tags are: 
 [('Networks', 'NNS'), ('', 'VBP'), (',', ','), ('Advances', 'NNP'), ('Neural', 'NNP'), ('Information', 'NNP'), ('Processing', 'NNP')]

>> Noun Phrases are: 
 ['Networks', 'Advances Neural Information Processing']

>> Named Entities are: 
 [('PERSON', 'Advances Neural')] 

>> Stemming using Porter Stemmer: 
 [('Networks', 'network'), ('', ''), (',', ','), ('Advances', 'advanc'), ('Neural', 'neural'), ('Information', 'inform'), ('Processing', 'process')]

>> Stemming using Snowball Stemmer: 
 [('Networks', 'network'), ('', ''), (',', ','), ('Advances', 'advanc'), ('Neural', 'neural'), ('Information', 'inform'), ('Processing', 'process')]

>> Lemmatization: 
 [('Networks', 'Networks'), ('', ''), (',', ','), ('Advances', 'Advances'), ('Neural', 'Neural'), ('Information', 'Information'), ('Processing', 'Processing')]



========================================== PARAGRAPH 678 ===========================================

System, pp. 1106-1114, 2012.  

------------------- Sentence 1 -------------------

System, pp.

>> Tokens are: 
 ['System', ',', 'pp', '.']

>> Bigrams are: 
 [('System', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('System', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('System', 'NN'), (',', ','), ('pp', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['System', 'pp']

>> Named Entities are: 
 [('GPE', 'System')] 

>> Stemming using Porter Stemmer: 
 [('System', 'system'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('System', 'system'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('System', 'System'), (',', ','), ('pp', 'pp'), ('.', '.')]


------------------- Sentence 2 -------------------

1106-1114, 2012.

>> Tokens are: 
 ['1106-1114', ',', '2012', '.']

>> Bigrams are: 
 [('1106-1114', ','), (',', '2012'), ('2012', '.')]

>> Trigrams are: 
 [('1106-1114', ',', '2012'), (',', '2012', '.')]

>> POS Tags are: 
 [('1106-1114', 'CD'), (',', ','), ('2012', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('1106-1114', '1106-1114'), (',', ','), ('2012', '2012'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('1106-1114', '1106-1114'), (',', ','), ('2012', '2012'), ('.', '.')]

>> Lemmatization: 
 [('1106-1114', '1106-1114'), (',', ','), ('2012', '2012'), ('.', '.')]



========================================== PARAGRAPH 679 ===========================================

[34] Jeffrey Dean, Greg S. Corrado and Rajat Monga Kai, Large  Scale Distributed Deep Networks, Advances in Neural  

------------------- Sentence 1 -------------------

[34] Jeffrey Dean, Greg S. Corrado and Rajat Monga Kai, Large  Scale Distributed Deep Networks, Advances in Neural

>> Tokens are: 
 ['[', '34', ']', 'Jeffrey', 'Dean', ',', 'Greg', 'S.', 'Corrado', 'Rajat', 'Monga', 'Kai', ',', '', 'Large', 'Scale', 'Distributed', 'Deep', 'Networks', '', ',', 'Advances', 'Neural']

>> Bigrams are: 
 [('[', '34'), ('34', ']'), (']', 'Jeffrey'), ('Jeffrey', 'Dean'), ('Dean', ','), (',', 'Greg'), ('Greg', 'S.'), ('S.', 'Corrado'), ('Corrado', 'Rajat'), ('Rajat', 'Monga'), ('Monga', 'Kai'), ('Kai', ','), (',', ''), ('', 'Large'), ('Large', 'Scale'), ('Scale', 'Distributed'), ('Distributed', 'Deep'), ('Deep', 'Networks'), ('Networks', ''), ('', ','), (',', 'Advances'), ('Advances', 'Neural')]

>> Trigrams are: 
 [('[', '34', ']'), ('34', ']', 'Jeffrey'), (']', 'Jeffrey', 'Dean'), ('Jeffrey', 'Dean', ','), ('Dean', ',', 'Greg'), (',', 'Greg', 'S.'), ('Greg', 'S.', 'Corrado'), ('S.', 'Corrado', 'Rajat'), ('Corrado', 'Rajat', 'Monga'), ('Rajat', 'Monga', 'Kai'), ('Monga', 'Kai', ','), ('Kai', ',', ''), (',', '', 'Large'), ('', 'Large', 'Scale'), ('Large', 'Scale', 'Distributed'), ('Scale', 'Distributed', 'Deep'), ('Distributed', 'Deep', 'Networks'), ('Deep', 'Networks', ''), ('Networks', '', ','), ('', ',', 'Advances'), (',', 'Advances', 'Neural')]

>> POS Tags are: 
 [('[', 'RB'), ('34', 'CD'), (']', 'JJ'), ('Jeffrey', 'NNP'), ('Dean', 'NNP'), (',', ','), ('Greg', 'NNP'), ('S.', 'NNP'), ('Corrado', 'NNP'), ('Rajat', 'NNP'), ('Monga', 'NNP'), ('Kai', 'NNP'), (',', ','), ('', 'NNP'), ('Large', 'NNP'), ('Scale', 'NNP'), ('Distributed', 'NNP'), ('Deep', 'NNP'), ('Networks', 'NNP'), ('', 'NNP'), (',', ','), ('Advances', 'NNP'), ('Neural', 'NNP')]

>> Noun Phrases are: 
 ['] Jeffrey Dean', 'Greg S. Corrado Rajat Monga Kai', ' Large Scale Distributed Deep Networks ', 'Advances Neural']

>> Named Entities are: 
 [('PERSON', 'Jeffrey Dean'), ('PERSON', 'Greg S. Corrado Rajat Monga Kai'), ('PERSON', 'Large Scale Distributed Deep Networks'), ('PERSON', 'Advances Neural')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('34', '34'), (']', ']'), ('Jeffrey', 'jeffrey'), ('Dean', 'dean'), (',', ','), ('Greg', 'greg'), ('S.', 's.'), ('Corrado', 'corrado'), ('Rajat', 'rajat'), ('Monga', 'monga'), ('Kai', 'kai'), (',', ','), ('', ''), ('Large', 'larg'), ('Scale', 'scale'), ('Distributed', 'distribut'), ('Deep', 'deep'), ('Networks', 'network'), ('', ''), (',', ','), ('Advances', 'advanc'), ('Neural', 'neural')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('34', '34'), (']', ']'), ('Jeffrey', 'jeffrey'), ('Dean', 'dean'), (',', ','), ('Greg', 'greg'), ('S.', 's.'), ('Corrado', 'corrado'), ('Rajat', 'rajat'), ('Monga', 'monga'), ('Kai', 'kai'), (',', ','), ('', ''), ('Large', 'larg'), ('Scale', 'scale'), ('Distributed', 'distribut'), ('Deep', 'deep'), ('Networks', 'network'), ('', ''), (',', ','), ('Advances', 'advanc'), ('Neural', 'neural')]

>> Lemmatization: 
 [('[', '['), ('34', '34'), (']', ']'), ('Jeffrey', 'Jeffrey'), ('Dean', 'Dean'), (',', ','), ('Greg', 'Greg'), ('S.', 'S.'), ('Corrado', 'Corrado'), ('Rajat', 'Rajat'), ('Monga', 'Monga'), ('Kai', 'Kai'), (',', ','), ('', ''), ('Large', 'Large'), ('Scale', 'Scale'), ('Distributed', 'Distributed'), ('Deep', 'Deep'), ('Networks', 'Networks'), ('', ''), (',', ','), ('Advances', 'Advances'), ('Neural', 'Neural')]



========================================== PARAGRAPH 680 ===========================================

Information Processing System, pp. 1232-1240, 2012.  

------------------- Sentence 1 -------------------

Information Processing System, pp.

>> Tokens are: 
 ['Information', 'Processing', 'System', ',', 'pp', '.']

>> Bigrams are: 
 [('Information', 'Processing'), ('Processing', 'System'), ('System', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('Information', 'Processing', 'System'), ('Processing', 'System', ','), ('System', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('Information', 'NN'), ('Processing', 'NNP'), ('System', 'NNP'), (',', ','), ('pp', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Information Processing System', 'pp']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Information', 'inform'), ('Processing', 'process'), ('System', 'system'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Information', 'inform'), ('Processing', 'process'), ('System', 'system'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('Information', 'Information'), ('Processing', 'Processing'), ('System', 'System'), (',', ','), ('pp', 'pp'), ('.', '.')]


------------------- Sentence 2 -------------------

1232-1240, 2012.

>> Tokens are: 
 ['1232-1240', ',', '2012', '.']

>> Bigrams are: 
 [('1232-1240', ','), (',', '2012'), ('2012', '.')]

>> Trigrams are: 
 [('1232-1240', ',', '2012'), (',', '2012', '.')]

>> POS Tags are: 
 [('1232-1240', 'CD'), (',', ','), ('2012', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('1232-1240', '1232-1240'), (',', ','), ('2012', '2012'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('1232-1240', '1232-1240'), (',', ','), ('2012', '2012'), ('.', '.')]

>> Lemmatization: 
 [('1232-1240', '1232-1240'), (',', ','), ('2012', '2012'), ('.', '.')]



========================================== PARAGRAPH 681 ===========================================

[35] Quoc V. Le, MarcAurelio Ranzato, Rajat Monga, Matthieu  Devin, Kai Chen, Greg S. Corrado, Jeffrey  Dean, and  

------------------- Sentence 1 -------------------

[35] Quoc V. Le, MarcAurelio Ranzato, Rajat Monga, Matthieu  Devin, Kai Chen, Greg S. Corrado, Jeffrey  Dean, and

>> Tokens are: 
 ['[', '35', ']', 'Quoc', 'V.', 'Le', ',', 'Marc', '', 'Aurelio', 'Ranzato', ',', 'Rajat', 'Monga', ',', 'Matthieu', 'Devin', ',', 'Kai', 'Chen', ',', 'Greg', 'S.', 'Corrado', ',', 'Jeffrey', 'Dean', ',']

>> Bigrams are: 
 [('[', '35'), ('35', ']'), (']', 'Quoc'), ('Quoc', 'V.'), ('V.', 'Le'), ('Le', ','), (',', 'Marc'), ('Marc', ''), ('', 'Aurelio'), ('Aurelio', 'Ranzato'), ('Ranzato', ','), (',', 'Rajat'), ('Rajat', 'Monga'), ('Monga', ','), (',', 'Matthieu'), ('Matthieu', 'Devin'), ('Devin', ','), (',', 'Kai'), ('Kai', 'Chen'), ('Chen', ','), (',', 'Greg'), ('Greg', 'S.'), ('S.', 'Corrado'), ('Corrado', ','), (',', 'Jeffrey'), ('Jeffrey', 'Dean'), ('Dean', ',')]

>> Trigrams are: 
 [('[', '35', ']'), ('35', ']', 'Quoc'), (']', 'Quoc', 'V.'), ('Quoc', 'V.', 'Le'), ('V.', 'Le', ','), ('Le', ',', 'Marc'), (',', 'Marc', ''), ('Marc', '', 'Aurelio'), ('', 'Aurelio', 'Ranzato'), ('Aurelio', 'Ranzato', ','), ('Ranzato', ',', 'Rajat'), (',', 'Rajat', 'Monga'), ('Rajat', 'Monga', ','), ('Monga', ',', 'Matthieu'), (',', 'Matthieu', 'Devin'), ('Matthieu', 'Devin', ','), ('Devin', ',', 'Kai'), (',', 'Kai', 'Chen'), ('Kai', 'Chen', ','), ('Chen', ',', 'Greg'), (',', 'Greg', 'S.'), ('Greg', 'S.', 'Corrado'), ('S.', 'Corrado', ','), ('Corrado', ',', 'Jeffrey'), (',', 'Jeffrey', 'Dean'), ('Jeffrey', 'Dean', ',')]

>> POS Tags are: 
 [('[', 'RB'), ('35', 'CD'), (']', 'JJ'), ('Quoc', 'NNP'), ('V.', 'NNP'), ('Le', 'NNP'), (',', ','), ('Marc', 'NNP'), ('', 'NNP'), ('Aurelio', 'NNP'), ('Ranzato', 'NNP'), (',', ','), ('Rajat', 'NNP'), ('Monga', 'NNP'), (',', ','), ('Matthieu', 'NNP'), ('Devin', 'NNP'), (',', ','), ('Kai', 'NNP'), ('Chen', 'NNP'), (',', ','), ('Greg', 'NNP'), ('S.', 'NNP'), ('Corrado', 'NNP'), (',', ','), ('Jeffrey', 'NNP'), ('Dean', 'NNP'), (',', ',')]

>> Noun Phrases are: 
 ['] Quoc V. Le', 'Marc  Aurelio Ranzato', 'Rajat Monga', 'Matthieu Devin', 'Kai Chen', 'Greg S. Corrado', 'Jeffrey Dean']

>> Named Entities are: 
 [('PERSON', 'Quoc V. Le'), ('PERSON', 'Marc'), ('PERSON', 'Aurelio Ranzato'), ('PERSON', 'Rajat Monga'), ('PERSON', 'Matthieu Devin'), ('PERSON', 'Kai Chen'), ('PERSON', 'Greg S. Corrado'), ('PERSON', 'Jeffrey Dean')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('35', '35'), (']', ']'), ('Quoc', 'quoc'), ('V.', 'v.'), ('Le', 'le'), (',', ','), ('Marc', 'marc'), ('', ''), ('Aurelio', 'aurelio'), ('Ranzato', 'ranzato'), (',', ','), ('Rajat', 'rajat'), ('Monga', 'monga'), (',', ','), ('Matthieu', 'matthieu'), ('Devin', 'devin'), (',', ','), ('Kai', 'kai'), ('Chen', 'chen'), (',', ','), ('Greg', 'greg'), ('S.', 's.'), ('Corrado', 'corrado'), (',', ','), ('Jeffrey', 'jeffrey'), ('Dean', 'dean'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('35', '35'), (']', ']'), ('Quoc', 'quoc'), ('V.', 'v.'), ('Le', 'le'), (',', ','), ('Marc', 'marc'), ('', ''), ('Aurelio', 'aurelio'), ('Ranzato', 'ranzato'), (',', ','), ('Rajat', 'rajat'), ('Monga', 'monga'), (',', ','), ('Matthieu', 'matthieu'), ('Devin', 'devin'), (',', ','), ('Kai', 'kai'), ('Chen', 'chen'), (',', ','), ('Greg', 'greg'), ('S.', 's.'), ('Corrado', 'corrado'), (',', ','), ('Jeffrey', 'jeffrey'), ('Dean', 'dean'), (',', ',')]

>> Lemmatization: 
 [('[', '['), ('35', '35'), (']', ']'), ('Quoc', 'Quoc'), ('V.', 'V.'), ('Le', 'Le'), (',', ','), ('Marc', 'Marc'), ('', ''), ('Aurelio', 'Aurelio'), ('Ranzato', 'Ranzato'), (',', ','), ('Rajat', 'Rajat'), ('Monga', 'Monga'), (',', ','), ('Matthieu', 'Matthieu'), ('Devin', 'Devin'), (',', ','), ('Kai', 'Kai'), ('Chen', 'Chen'), (',', ','), ('Greg', 'Greg'), ('S.', 'S.'), ('Corrado', 'Corrado'), (',', ','), ('Jeffrey', 'Jeffrey'), ('Dean', 'Dean'), (',', ',')]



========================================== PARAGRAPH 682 ===========================================

Andrew Y. Ng, Building High-level Features Using Large  

------------------- Sentence 1 -------------------

Andrew Y. Ng, Building High-level Features Using Large

>> Tokens are: 
 ['Andrew', 'Y.', 'Ng', ',', '', 'Building', 'High-level', 'Features', 'Using', 'Large']

>> Bigrams are: 
 [('Andrew', 'Y.'), ('Y.', 'Ng'), ('Ng', ','), (',', ''), ('', 'Building'), ('Building', 'High-level'), ('High-level', 'Features'), ('Features', 'Using'), ('Using', 'Large')]

>> Trigrams are: 
 [('Andrew', 'Y.', 'Ng'), ('Y.', 'Ng', ','), ('Ng', ',', ''), (',', '', 'Building'), ('', 'Building', 'High-level'), ('Building', 'High-level', 'Features'), ('High-level', 'Features', 'Using'), ('Features', 'Using', 'Large')]

>> POS Tags are: 
 [('Andrew', 'NNP'), ('Y.', 'NNP'), ('Ng', 'NNP'), (',', ','), ('', 'NNP'), ('Building', 'NNP'), ('High-level', 'NNP'), ('Features', 'NNP'), ('Using', 'NNP'), ('Large', 'NNP')]

>> Noun Phrases are: 
 ['Andrew Y. Ng', ' Building High-level Features Using Large']

>> Named Entities are: 
 [('PERSON', 'Andrew'), ('PERSON', 'Features Using Large')] 

>> Stemming using Porter Stemmer: 
 [('Andrew', 'andrew'), ('Y.', 'y.'), ('Ng', 'ng'), (',', ','), ('', ''), ('Building', 'build'), ('High-level', 'high-level'), ('Features', 'featur'), ('Using', 'use'), ('Large', 'larg')]

>> Stemming using Snowball Stemmer: 
 [('Andrew', 'andrew'), ('Y.', 'y.'), ('Ng', 'ng'), (',', ','), ('', ''), ('Building', 'build'), ('High-level', 'high-level'), ('Features', 'featur'), ('Using', 'use'), ('Large', 'larg')]

>> Lemmatization: 
 [('Andrew', 'Andrew'), ('Y.', 'Y.'), ('Ng', 'Ng'), (',', ','), ('', ''), ('Building', 'Building'), ('High-level', 'High-level'), ('Features', 'Features'), ('Using', 'Using'), ('Large', 'Large')]



========================================== PARAGRAPH 683 ===========================================

Scale Unsupervised Learning, Proceedings of the 29 th   

------------------- Sentence 1 -------------------

Scale Unsupervised Learning, Proceedings of the 29 th

>> Tokens are: 
 ['Scale', 'Unsupervised', 'Learning', '', ',', 'Proceedings', '29', 'th']

>> Bigrams are: 
 [('Scale', 'Unsupervised'), ('Unsupervised', 'Learning'), ('Learning', ''), ('', ','), (',', 'Proceedings'), ('Proceedings', '29'), ('29', 'th')]

>> Trigrams are: 
 [('Scale', 'Unsupervised', 'Learning'), ('Unsupervised', 'Learning', ''), ('Learning', '', ','), ('', ',', 'Proceedings'), (',', 'Proceedings', '29'), ('Proceedings', '29', 'th')]

>> POS Tags are: 
 [('Scale', 'NNP'), ('Unsupervised', 'VBD'), ('Learning', 'NNP'), ('', 'NNP'), (',', ','), ('Proceedings', 'NNP'), ('29', 'CD'), ('th', 'NN')]

>> Noun Phrases are: 
 ['Scale', 'Learning ', 'Proceedings', 'th']

>> Named Entities are: 
 [('PERSON', 'Scale')] 

>> Stemming using Porter Stemmer: 
 [('Scale', 'scale'), ('Unsupervised', 'unsupervis'), ('Learning', 'learn'), ('', ''), (',', ','), ('Proceedings', 'proceed'), ('29', '29'), ('th', 'th')]

>> Stemming using Snowball Stemmer: 
 [('Scale', 'scale'), ('Unsupervised', 'unsupervis'), ('Learning', 'learn'), ('', ''), (',', ','), ('Proceedings', 'proceed'), ('29', '29'), ('th', 'th')]

>> Lemmatization: 
 [('Scale', 'Scale'), ('Unsupervised', 'Unsupervised'), ('Learning', 'Learning'), ('', ''), (',', ','), ('Proceedings', 'Proceedings'), ('29', '29'), ('th', 'th')]



========================================== PARAGRAPH 684 ===========================================

International Conference on Machine Learning, 2012.  

------------------- Sentence 1 -------------------

International Conference on Machine Learning, 2012.

>> Tokens are: 
 ['International', 'Conference', 'Machine', 'Learning', ',', '2012', '.']

>> Bigrams are: 
 [('International', 'Conference'), ('Conference', 'Machine'), ('Machine', 'Learning'), ('Learning', ','), (',', '2012'), ('2012', '.')]

>> Trigrams are: 
 [('International', 'Conference', 'Machine'), ('Conference', 'Machine', 'Learning'), ('Machine', 'Learning', ','), ('Learning', ',', '2012'), (',', '2012', '.')]

>> POS Tags are: 
 [('International', 'NNP'), ('Conference', 'NNP'), ('Machine', 'NNP'), ('Learning', 'NNP'), (',', ','), ('2012', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['International Conference Machine Learning']

>> Named Entities are: 
 [('ORGANIZATION', 'International Conference Machine Learning')] 

>> Stemming using Porter Stemmer: 
 [('International', 'intern'), ('Conference', 'confer'), ('Machine', 'machin'), ('Learning', 'learn'), (',', ','), ('2012', '2012'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('International', 'intern'), ('Conference', 'confer'), ('Machine', 'machin'), ('Learning', 'learn'), (',', ','), ('2012', '2012'), ('.', '.')]

>> Lemmatization: 
 [('International', 'International'), ('Conference', 'Conference'), ('Machine', 'Machine'), ('Learning', 'Learning'), (',', ','), ('2012', '2012'), ('.', '.')]



========================================== PARAGRAPH 685 ===========================================

[36] A. Coats and B. Huval, Deep Learning with COTS HPS  systems, Journal of Machine Learning Research, Vol. 28,  

------------------- Sentence 1 -------------------

[36] A. Coats and B. Huval, Deep Learning with COTS HPS  systems, Journal of Machine Learning Research, Vol.

>> Tokens are: 
 ['[', '36', ']', 'A.', 'Coats', 'B.', 'Huval', ',', '', 'Deep', 'Learning', 'COTS', 'HPS', 'systems', '', ',', 'Journal', 'Machine', 'Learning', 'Research', ',', 'Vol', '.']

>> Bigrams are: 
 [('[', '36'), ('36', ']'), (']', 'A.'), ('A.', 'Coats'), ('Coats', 'B.'), ('B.', 'Huval'), ('Huval', ','), (',', ''), ('', 'Deep'), ('Deep', 'Learning'), ('Learning', 'COTS'), ('COTS', 'HPS'), ('HPS', 'systems'), ('systems', ''), ('', ','), (',', 'Journal'), ('Journal', 'Machine'), ('Machine', 'Learning'), ('Learning', 'Research'), ('Research', ','), (',', 'Vol'), ('Vol', '.')]

>> Trigrams are: 
 [('[', '36', ']'), ('36', ']', 'A.'), (']', 'A.', 'Coats'), ('A.', 'Coats', 'B.'), ('Coats', 'B.', 'Huval'), ('B.', 'Huval', ','), ('Huval', ',', ''), (',', '', 'Deep'), ('', 'Deep', 'Learning'), ('Deep', 'Learning', 'COTS'), ('Learning', 'COTS', 'HPS'), ('COTS', 'HPS', 'systems'), ('HPS', 'systems', ''), ('systems', '', ','), ('', ',', 'Journal'), (',', 'Journal', 'Machine'), ('Journal', 'Machine', 'Learning'), ('Machine', 'Learning', 'Research'), ('Learning', 'Research', ','), ('Research', ',', 'Vol'), (',', 'Vol', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('36', 'CD'), (']', 'JJ'), ('A.', 'NN'), ('Coats', 'NNP'), ('B.', 'NNP'), ('Huval', 'NNP'), (',', ','), ('', 'NNP'), ('Deep', 'NNP'), ('Learning', 'NNP'), ('COTS', 'NNP'), ('HPS', 'NNP'), ('systems', 'NNS'), ('', 'NNP'), (',', ','), ('Journal', 'NNP'), ('Machine', 'NNP'), ('Learning', 'NNP'), ('Research', 'NNP'), (',', ','), ('Vol', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['] A. Coats B. Huval', ' Deep Learning COTS HPS systems ', 'Journal Machine Learning Research', 'Vol']

>> Named Entities are: 
 [('PERSON', 'Coats B. Huval'), ('PERSON', 'Journal Machine Learning Research'), ('PERSON', 'Vol')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('36', '36'), (']', ']'), ('A.', 'a.'), ('Coats', 'coat'), ('B.', 'b.'), ('Huval', 'huval'), (',', ','), ('', ''), ('Deep', 'deep'), ('Learning', 'learn'), ('COTS', 'cot'), ('HPS', 'hp'), ('systems', 'system'), ('', ''), (',', ','), ('Journal', 'journal'), ('Machine', 'machin'), ('Learning', 'learn'), ('Research', 'research'), (',', ','), ('Vol', 'vol'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('36', '36'), (']', ']'), ('A.', 'a.'), ('Coats', 'coat'), ('B.', 'b.'), ('Huval', 'huval'), (',', ','), ('', ''), ('Deep', 'deep'), ('Learning', 'learn'), ('COTS', 'cot'), ('HPS', 'hps'), ('systems', 'system'), ('', ''), (',', ','), ('Journal', 'journal'), ('Machine', 'machin'), ('Learning', 'learn'), ('Research', 'research'), (',', ','), ('Vol', 'vol'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('36', '36'), (']', ']'), ('A.', 'A.'), ('Coats', 'Coats'), ('B.', 'B.'), ('Huval', 'Huval'), (',', ','), ('', ''), ('Deep', 'Deep'), ('Learning', 'Learning'), ('COTS', 'COTS'), ('HPS', 'HPS'), ('systems', 'system'), ('', ''), (',', ','), ('Journal', 'Journal'), ('Machine', 'Machine'), ('Learning', 'Learning'), ('Research', 'Research'), (',', ','), ('Vol', 'Vol'), ('.', '.')]


------------------- Sentence 2 -------------------

28,

>> Tokens are: 
 ['28', ',']

>> Bigrams are: 
 [('28', ',')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('28', 'CD'), (',', ',')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('28', '28'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('28', '28'), (',', ',')]

>> Lemmatization: 
 [('28', '28'), (',', ',')]



========================================== PARAGRAPH 686 ===========================================

No. 3, pp. 1337-1345, 2013.  

------------------- Sentence 1 -------------------

No.

>> Tokens are: 
 ['No', '.']

>> Bigrams are: 
 [('No', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('No', 'DT'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('No', 'no'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('No', 'no'), ('.', '.')]

>> Lemmatization: 
 [('No', 'No'), ('.', '.')]


------------------- Sentence 2 -------------------

3, pp.

>> Tokens are: 
 ['3', ',', 'pp', '.']

>> Bigrams are: 
 [('3', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('3', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('3', 'CD'), (',', ','), ('pp', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['pp']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('3', '3'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('3', '3'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('3', '3'), (',', ','), ('pp', 'pp'), ('.', '.')]


------------------- Sentence 3 -------------------

1337-1345, 2013.

>> Tokens are: 
 ['1337-1345', ',', '2013', '.']

>> Bigrams are: 
 [('1337-1345', ','), (',', '2013'), ('2013', '.')]

>> Trigrams are: 
 [('1337-1345', ',', '2013'), (',', '2013', '.')]

>> POS Tags are: 
 [('1337-1345', 'CD'), (',', ','), ('2013', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('1337-1345', '1337-1345'), (',', ','), ('2013', '2013'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('1337-1345', '1337-1345'), (',', ','), ('2013', '2013'), ('.', '.')]

>> Lemmatization: 
 [('1337-1345', '1337-1345'), (',', ','), ('2013', '2013'), ('.', '.')]



========================================== PARAGRAPH 687 ===========================================

 
