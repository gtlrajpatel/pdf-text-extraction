				 *** Text Processing using Spacy *** 


================================ Paragraph 1 =================================

W H I T E  P A P E R 

------------------- Sentence 1 -------------------

W H 


>> Tokens are: 
[W, H] 

>> PoS Tags are: 
[('W', 'NOUN'), ('H', 'NOUN')] 

>> Dependency Tags are: 
[('W', 'compound'), ('H', 'ROOT')]

>> Bigrams: 
[[W, H]]

>> Trigrams: 
[]

>> Noun Phrases are: 
[W H]

>> Named Entities are: 
[] 

------------------- Sentence 2 -------------------

I T 


>> Tokens are: 
[T] 

>> PoS Tags are: 
[('T', 'NOUN')] 

>> Dependency Tags are: 
[('T', 'appos')]

>> Bigrams: 
[]

>> Trigrams: 
[]

>> Noun Phrases are: 
[I, T]

>> Named Entities are: 
[] 

------------------- Sentence 3 -------------------

E   


>> Tokens are: 
[E,  ] 

>> PoS Tags are: 
[('E', 'NOUN'), (' ', 'SPACE')] 

>> Dependency Tags are: 
[('E', 'ROOT'), (' ', 'appos')]

>> Bigrams: 
[[E,  ]]

>> Trigrams: 
[]

>> Noun Phrases are: 
[E]

>> Named Entities are: 
[] 

------------------- Sentence 4 -------------------

P A P E R 


>> Tokens are: 
[P, P, E, R] 

>> PoS Tags are: 
[('P', 'NOUN'), ('P', 'NOUN'), ('E', 'NOUN'), ('R', 'NOUN')] 

>> Dependency Tags are: 
[('P', 'compound'), ('P', 'compound'), ('E', 'compound'), ('R', 'ROOT')]

>> Bigrams: 
[[P, P], [P, E], [E, R]]

>> Trigrams: 
[[P, P, E], [P, E, R]]

>> Noun Phrases are: 
[P A P E R]

>> Named Entities are: 
[] 


================================ Paragraph 2 =================================

sentiment 

------------------- Sentence 1 -------------------

sentiment 


>> Tokens are: 
[sentiment] 

>> PoS Tags are: 
[('sentiment', 'NOUN')] 

>> Dependency Tags are: 
[('sentiment', 'ROOT')]

>> Bigrams: 
[]

>> Trigrams: 
[]

>> Noun Phrases are: 
[sentiment]

>> Named Entities are: 
[] 


================================ Paragraph 3 =================================

recall 

------------------- Sentence 1 -------------------

recall 


>> Tokens are: 
[recall] 

>> PoS Tags are: 
[('recall', 'VERB')] 

>> Dependency Tags are: 
[('recall', 'ROOT')]

>> Bigrams: 
[]

>> Trigrams: 
[]

>> Noun Phrases are: 
[]

>> Named Entities are: 
[] 


================================ Paragraph 4 =================================

precision 

------------------- Sentence 1 -------------------

precision 


>> Tokens are: 
[precision] 

>> PoS Tags are: 
[('precision', 'NOUN')] 

>> Dependency Tags are: 
[('precision', 'ROOT')]

>> Bigrams: 
[]

>> Trigrams: 
[]

>> Noun Phrases are: 
[precision]

>> Named Entities are: 
[] 


================================ Paragraph 5 =================================

part of speech 

------------------- Sentence 1 -------------------

part of speech 


>> Tokens are: 
[speech] 

>> PoS Tags are: 
[('speech', 'NOUN')] 

>> Dependency Tags are: 
[('speech', 'pobj')]

>> Bigrams: 
[]

>> Trigrams: 
[]

>> Noun Phrases are: 
[part, speech]

>> Named Entities are: 
[] 


================================ Paragraph 6 =================================

machine learning 

------------------- Sentence 1 -------------------

machine learning 


>> Tokens are: 
[machine, learning] 

>> PoS Tags are: 
[('machine', 'NOUN'), ('learning', 'NOUN')] 

>> Dependency Tags are: 
[('machine', 'compound'), ('learning', 'ROOT')]

>> Bigrams: 
[[machine, learning]]

>> Trigrams: 
[]

>> Noun Phrases are: 
[machine learning]

>> Named Entities are: 
[] 


================================ Paragraph 7 =================================

data ratio 

------------------- Sentence 1 -------------------

data ratio 


>> Tokens are: 
[data, ratio] 

>> PoS Tags are: 
[('data', 'NOUN'), ('ratio', 'NOUN')] 

>> Dependency Tags are: 
[('data', 'compound'), ('ratio', 'ROOT')]

>> Bigrams: 
[[data, ratio]]

>> Trigrams: 
[]

>> Noun Phrases are: 
[data ratio]

>> Named Entities are: 
[] 


================================ Paragraph 8 =================================

NLP 

------------------- Sentence 1 -------------------

NLP 


>> Tokens are: 
[NLP] 

>> PoS Tags are: 
[('NLP', 'PROPN')] 

>> Dependency Tags are: 
[('NLP', 'ROOT')]

>> Bigrams: 
[]

>> Trigrams: 
[]

>> Noun Phrases are: 
[NLP]

>> Named Entities are: 
[('NLP', 'ORG')] 


================================ Paragraph 9 =================================

syntax tuning 

------------------- Sentence 1 -------------------

syntax tuning 


>> Tokens are: 
[syntax, tuning] 

>> PoS Tags are: 
[('syntax', 'NOUN'), ('tuning', 'NOUN')] 

>> Dependency Tags are: 
[('syntax', 'compound'), ('tuning', 'ROOT')]

>> Bigrams: 
[[syntax, tuning]]

>> Trigrams: 
[]

>> Noun Phrases are: 
[syntax tuning]

>> Named Entities are: 
[] 


================================ Paragraph 10 =================================

themes 

------------------- Sentence 1 -------------------

themes 


>> Tokens are: 
[themes] 

>> PoS Tags are: 
[('themes', 'NOUN')] 

>> Dependency Tags are: 
[('themes', 'ROOT')]

>> Bigrams: 
[]

>> Trigrams: 
[]

>> Noun Phrases are: 
[themes]

>> Named Entities are: 
[] 


================================ Paragraph 11 =================================

named entity extraction 

------------------- Sentence 1 -------------------

named entity extraction 


>> Tokens are: 
[named, entity, extraction] 

>> PoS Tags are: 
[('named', 'VERB'), ('entity', 'NOUN'), ('extraction', 'NOUN')] 

>> Dependency Tags are: 
[('named', 'ROOT'), ('entity', 'compound'), ('extraction', 'dobj')]

>> Bigrams: 
[[named, entity], [entity, extraction]]

>> Trigrams: 
[[named, entity, extraction]]

>> Noun Phrases are: 
[entity extraction]

>> Named Entities are: 
[] 


================================ Paragraph 12 =================================

accuracy 

------------------- Sentence 1 -------------------

accuracy 


>> Tokens are: 
[accuracy] 

>> PoS Tags are: 
[('accuracy', 'NOUN')] 

>> Dependency Tags are: 
[('accuracy', 'ROOT')]

>> Bigrams: 
[]

>> Trigrams: 
[]

>> Noun Phrases are: 
[accuracy]

>> Named Entities are: 
[] 


================================ Paragraph 13 =================================

training 

------------------- Sentence 1 -------------------

training 


>> Tokens are: 
[training] 

>> PoS Tags are: 
[('training', 'NOUN')] 

>> Dependency Tags are: 
[('training', 'ROOT')]

>> Bigrams: 
[]

>> Trigrams: 
[]

>> Noun Phrases are: 
[training]

>> Named Entities are: 
[] 


================================ Paragraph 14 =================================

AI 

------------------- Sentence 1 -------------------

AI 


>> Tokens are: 
[AI] 

>> PoS Tags are: 
[('AI', 'NOUN')] 

>> Dependency Tags are: 
[('AI', 'ROOT')]

>> Bigrams: 
[]

>> Trigrams: 
[]

>> Noun Phrases are: 
[AI]

>> Named Entities are: 
[('AI', 'ORG')] 


================================ Paragraph 15 =================================

Lexalytics, Inc., 48 North Pleasant St. Unit 301, Amherst MA 01002 USA | 1-800-377-8036 | www.lexalytics.com 

------------------- Sentence 1 -------------------

Lexalytics, Inc., 48 North Pleasant St. Unit 301, Amherst MA 01002 USA | 1-800-377-8036 | www.lexalytics.com 


>> Tokens are: 
[Lexalytics, ,, Inc., ,, 48, North, Pleasant, St., Unit, 301, ,, Amherst, MA, 01002, USA, |, 1, -, 800, -, 377, -, 8036, |, www.lexalytics.com] 

>> PoS Tags are: 
[('Lexalytics', 'PROPN'), (',', 'PUNCT'), ('Inc.', 'PROPN'), (',', 'PUNCT'), ('48', 'NUM'), ('North', 'PROPN'), ('Pleasant', 'PROPN'), ('St.', 'PROPN'), ('Unit', 'PROPN'), ('301', 'NUM'), (',', 'PUNCT'), ('Amherst', 'PROPN'), ('MA', 'PROPN'), ('01002', 'NUM'), ('USA', 'PROPN'), ('|', 'NOUN'), ('1', 'NUM'), ('-', 'NUM'), ('800', 'NUM'), ('-', 'NUM'), ('377', 'NUM'), ('-', 'PUNCT'), ('8036', 'NUM'), ('|', 'NOUN'), ('www.lexalytics.com', 'X')] 

>> Dependency Tags are: 
[('Lexalytics', 'nmod'), (',', 'punct'), ('Inc.', 'ROOT'), (',', 'punct'), ('48', 'nummod'), ('North', 'compound'), ('Pleasant', 'compound'), ('St.', 'compound'), ('Unit', 'appos'), ('301', 'nummod'), (',', 'punct'), ('Amherst', 'compound'), ('MA', 'appos'), ('01002', 'nummod'), ('USA', 'appos'), ('|', 'punct'), ('1', 'nummod'), ('-', 'punct'), ('800', 'prep'), ('-', 'punct'), ('377', 'nummod'), ('-', 'punct'), ('8036', 'nummod'), ('|', 'appos'), ('www.lexalytics.com', 'punct')]

>> Bigrams: 
[[Lexalytics, ,], [,, Inc.], [Inc., ,], [,, 48], [48, North], [North, Pleasant], [Pleasant, St.], [St., Unit], [Unit, 301], [301, ,], [,, Amherst], [Amherst, MA], [MA, 01002], [01002, USA], [USA, |], [|, 1], [1, -], [-, 800], [800, -], [-, 377], [377, -], [-, 8036], [8036, |], [|, www.lexalytics.com]]

>> Trigrams: 
[[Lexalytics, ,, Inc.], [,, Inc., ,], [Inc., ,, 48], [,, 48, North], [48, North, Pleasant], [North, Pleasant, St.], [Pleasant, St., Unit], [St., Unit, 301], [Unit, 301, ,], [301, ,, Amherst], [,, Amherst, MA], [Amherst, MA, 01002], [MA, 01002, USA], [01002, USA, |], [USA, |, 1], [|, 1, -], [1, -, 800], [-, 800, -], [800, -, 377], [-, 377, -], [377, -, 8036], [-, 8036, |], [8036, |, www.lexalytics.com]]

>> Noun Phrases are: 
[Lexalytics, Inc., 48 North Pleasant St. Unit, Amherst MA, USA, 377-8036 |]

>> Named Entities are: 
[('Lexalytics, Inc.', 'ORG'), ('48', 'CARDINAL'), ('North Pleasant St. Unit 301', 'ORG'), ('Amherst MA 01002 USA | 1-800-377-8036', 'ORG')] 


================================ Paragraph 16 =================================

 Machine Learning for   Natural Language Processing   

------------------- Sentence 1 -------------------

 Machine Learning for   Natural Language Processing    


>> Tokens are: 
[ , Machine, Learning,   , Natural, Language, Processing,   ] 

>> PoS Tags are: 
[(' ', 'SPACE'), ('Machine', 'PROPN'), ('Learning', 'PROPN'), ('  ', 'SPACE'), ('Natural', 'PROPN'), ('Language', 'PROPN'), ('Processing', 'NOUN'), ('  ', 'SPACE')] 

>> Dependency Tags are: 
[(' ', 'compound'), ('Machine', 'compound'), ('Learning', 'ROOT'), ('  ', 'nummod'), ('Natural', 'compound'), ('Language', 'compound'), ('Processing', 'pobj'), ('  ', 'appos')]

>> Bigrams: 
[[ , Machine], [Machine, Learning], [Learning,   ], [  , Natural], [Natural, Language], [Language, Processing], [Processing,   ]]

>> Trigrams: 
[[ , Machine, Learning], [Machine, Learning,   ], [Learning,   , Natural], [  , Natural, Language], [Natural, Language, Processing], [Language, Processing,   ]]

>> Noun Phrases are: 
[ Machine Learning,   Natural Language Processing]

>> Named Entities are: 
[] 


================================ Paragraph 17 =================================

and Text Analytics

------------------- Sentence 1 -------------------

and 


>> Tokens are: 
[] 

>> PoS Tags are: 
[] 

>> Dependency Tags are: 
[]

>> Bigrams: 
[]

>> Trigrams: 
[]

>> Noun Phrases are: 
[]

>> Named Entities are: 
[] 

------------------- Sentence 2 -------------------

Text Analytics 


>> Tokens are: 
[Text, Analytics] 

>> PoS Tags are: 
[('Text', 'PROPN'), ('Analytics', 'NOUN')] 

>> Dependency Tags are: 
[('Text', 'compound'), ('Analytics', 'ROOT')]

>> Bigrams: 
[[Text, Analytics]]

>> Trigrams: 
[]

>> Noun Phrases are: 
[Text Analytics]

>> Named Entities are: 
[] 


================================ Paragraph 18 =================================

W H I T E  P A P E R 

------------------- Sentence 1 -------------------

W H 


>> Tokens are: 
[W, H] 

>> PoS Tags are: 
[('W', 'NOUN'), ('H', 'NOUN')] 

>> Dependency Tags are: 
[('W', 'compound'), ('H', 'ROOT')]

>> Bigrams: 
[[W, H]]

>> Trigrams: 
[]

>> Noun Phrases are: 
[W H]

>> Named Entities are: 
[] 

------------------- Sentence 2 -------------------

I T 


>> Tokens are: 
[T] 

>> PoS Tags are: 
[('T', 'NOUN')] 

>> Dependency Tags are: 
[('T', 'appos')]

>> Bigrams: 
[]

>> Trigrams: 
[]

>> Noun Phrases are: 
[I, T]

>> Named Entities are: 
[] 

------------------- Sentence 3 -------------------

E   


>> Tokens are: 
[E,  ] 

>> PoS Tags are: 
[('E', 'NOUN'), (' ', 'SPACE')] 

>> Dependency Tags are: 
[('E', 'ROOT'), (' ', 'appos')]

>> Bigrams: 
[[E,  ]]

>> Trigrams: 
[]

>> Noun Phrases are: 
[E]

>> Named Entities are: 
[] 

------------------- Sentence 4 -------------------

P A P E R 


>> Tokens are: 
[P, P, E, R] 

>> PoS Tags are: 
[('P', 'NOUN'), ('P', 'NOUN'), ('E', 'NOUN'), ('R', 'NOUN')] 

>> Dependency Tags are: 
[('P', 'compound'), ('P', 'compound'), ('E', 'compound'), ('R', 'ROOT')]

>> Bigrams: 
[[P, P], [P, E], [E, R]]

>> Trigrams: 
[[P, P, E], [P, E, R]]

>> Noun Phrases are: 
[P A P E R]

>> Named Entities are: 
[] 


================================ Paragraph 19 =================================

T A B L E  O F  C O N T E N T S 

------------------- Sentence 1 -------------------

T A B L E   


>> Tokens are: 
[T, B, L, E,  ] 

>> PoS Tags are: 
[('T', 'PROPN'), ('B', 'PROPN'), ('L', 'PROPN'), ('E', 'PROPN'), (' ', 'SPACE')] 

>> Dependency Tags are: 
[('T', 'compound'), ('B', 'compound'), ('L', 'compound'), ('E', 'ROOT'), (' ', 'appos')]

>> Bigrams: 
[[T, B], [B, L], [L, E], [E,  ]]

>> Trigrams: 
[[T, B, L], [B, L, E], [L, E,  ]]

>> Noun Phrases are: 
[T A B L E]

>> Named Entities are: 
[] 

------------------- Sentence 2 -------------------

O F  C O N T E N T S 


>> Tokens are: 
[O, F,  , C, O, N, T, E, N, T, S] 

>> PoS Tags are: 
[('O', 'INTJ'), ('F', 'NOUN'), (' ', 'SPACE'), ('C', 'PROPN'), ('O', 'NOUN'), ('N', 'PROPN'), ('T', 'PROPN'), ('E', 'NOUN'), ('N', 'NOUN'), ('T', 'NOUN'), ('S', 'PROPN')] 

>> Dependency Tags are: 
[('O', 'intj'), ('F', 'compound'), (' ', 'compound'), ('C', 'compound'), ('O', 'nmod'), ('N', 'compound'), ('T', 'compound'), ('E', 'compound'), ('N', 'compound'), ('T', 'compound'), ('S', 'ROOT')]

>> Bigrams: 
[[O, F], [F,  ], [ , C], [C, O], [O, N], [N, T], [T, E], [E, N], [N, T], [T, S]]

>> Trigrams: 
[[O, F,  ], [F,  , C], [ , C, O], [C, O, N], [O, N, T], [N, T, E], [T, E, N], [E, N, T], [N, T, S]]

>> Noun Phrases are: 
[O F  C O N T E N T S]

>> Named Entities are: 
[] 


================================ Paragraph 20 =================================

2|       |   Lexalytics, Inc., 48 North Pleasant St. Unit 301, Amherst MA 01002 USA   |   1-800-377-8036 |   www.lexalytics.com 

------------------- Sentence 1 -------------------

2|       |   Lexalytics, Inc., 48 North Pleasant St. Unit 301, Amherst MA 01002 


>> Tokens are: 
[2|,       , |,   , Lexalytics, ,, Inc., ,, 48, North, Pleasant, St., Unit, 301, ,, Amherst, MA, 01002] 

>> PoS Tags are: 
[('2|', 'PRON'), ('      ', 'SPACE'), ('|', 'NOUN'), ('  ', 'SPACE'), ('Lexalytics', 'PROPN'), (',', 'PUNCT'), ('Inc.', 'PROPN'), (',', 'PUNCT'), ('48', 'NUM'), ('North', 'PROPN'), ('Pleasant', 'PROPN'), ('St.', 'PROPN'), ('Unit', 'PROPN'), ('301', 'NUM'), (',', 'PUNCT'), ('Amherst', 'PROPN'), ('MA', 'PROPN'), ('01002', 'NUM')] 

>> Dependency Tags are: 
[('2|', 'nmod'), ('      ', 'appos'), ('|', 'appos'), ('  ', 'nmod'), ('Lexalytics', 'nmod'), (',', 'punct'), ('Inc.', 'ROOT'), (',', 'punct'), ('48', 'nummod'), ('North', 'compound'), ('Pleasant', 'compound'), ('St.', 'compound'), ('Unit', 'appos'), ('301', 'nummod'), (',', 'punct'), ('Amherst', 'compound'), ('MA', 'appos'), ('01002', 'punct')]

>> Bigrams: 
[[2|,       ], [      , |], [|,   ], [  , Lexalytics], [Lexalytics, ,], [,, Inc.], [Inc., ,], [,, 48], [48, North], [North, Pleasant], [Pleasant, St.], [St., Unit], [Unit, 301], [301, ,], [,, Amherst], [Amherst, MA], [MA, 01002]]

>> Trigrams: 
[[2|,       , |], [      , |,   ], [|,   , Lexalytics], [  , Lexalytics, ,], [Lexalytics, ,, Inc.], [,, Inc., ,], [Inc., ,, 48], [,, 48, North], [48, North, Pleasant], [North, Pleasant, St.], [Pleasant, St., Unit], [St., Unit, 301], [Unit, 301, ,], [301, ,, Amherst], [,, Amherst, MA], [Amherst, MA, 01002]]

>> Noun Phrases are: 
[|, 48 North Pleasant St. Unit, Amherst MA]

>> Named Entities are: 
[('2|', 'CARDINAL'), ('Lexalytics, Inc.', 'ORG'), ('48', 'CARDINAL'), ('North Pleasant St. Unit 301', 'ORG'), ('Amherst MA', 'ORG')] 

------------------- Sentence 2 -------------------

USA 


>> Tokens are: 
[USA] 

>> PoS Tags are: 
[('USA', 'PROPN')] 

>> Dependency Tags are: 
[('USA', 'ROOT')]

>> Bigrams: 
[]

>> Trigrams: 
[]

>> Noun Phrases are: 
[USA]

>> Named Entities are: 
[] 

------------------- Sentence 3 -------------------

  |   1-800-377-8036 |   www.lexalytics.com 


>> Tokens are: 
[  , |,   , 1, -, 800, -, 377, -, 8036, |,   , www.lexalytics.com] 

>> PoS Tags are: 
[('  ', 'SPACE'), ('|', 'NOUN'), ('  ', 'SPACE'), ('1', 'NUM'), ('-', 'SYM'), ('800', 'NUM'), ('-', 'NUM'), ('377', 'NUM'), ('-', 'PUNCT'), ('8036', 'NUM'), ('|', 'NOUN'), ('  ', 'SPACE'), ('www.lexalytics.com', 'X')] 

>> Dependency Tags are: 
[('  ', 'compound'), ('|', 'npadvmod'), ('  ', 'dep'), ('1', 'npadvmod'), ('-', 'punct'), ('800', 'prep'), ('-', 'punct'), ('377', 'nummod'), ('-', 'punct'), ('8036', 'nummod'), ('|', 'npadvmod'), ('  ', 'ROOT'), ('www.lexalytics.com', 'punct')]

>> Bigrams: 
[[  , |], [|,   ], [  , 1], [1, -], [-, 800], [800, -], [-, 377], [377, -], [-, 8036], [8036, |], [|,   ], [  , www.lexalytics.com]]

>> Trigrams: 
[[  , |,   ], [|,   , 1], [  , 1, -], [1, -, 800], [-, 800, -], [800, -, 377], [-, 377, -], [377, -, 8036], [-, 8036, |], [8036, |,   ], [|,   , www.lexalytics.com]]

>> Noun Phrases are: 
[]

>> Named Entities are: 
[] 


================================ Paragraph 21 =================================

Introduction Machine learning is everywhere, from helping us make better toast to  researching drug discovery and designs. Sometimes the term is used  interchangeably with artificial intelligence (AI), but they’re not the same  thing. While all AI involves machine learning, not all machine learning is AI.  

------------------- Sentence 1 -------------------

Introduction Machine learning is everywhere, from helping us make better toast to  researching drug discovery and designs. 


>> Tokens are: 
[Introduction, Machine, learning, ,, helping, better, toast,  , researching, drug, discovery, designs, .] 

>> PoS Tags are: 
[('Introduction', 'NOUN'), ('Machine', 'NOUN'), ('learning', 'NOUN'), (',', 'PUNCT'), ('helping', 'VERB'), ('better', 'ADJ'), ('toast', 'NOUN'), (' ', 'SPACE'), ('researching', 'VERB'), ('drug', 'NOUN'), ('discovery', 'NOUN'), ('designs', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('Introduction', 'compound'), ('Machine', 'compound'), ('learning', 'nsubj'), (',', 'punct'), ('helping', 'pcomp'), ('better', 'amod'), ('toast', 'dobj'), (' ', 'pobj'), ('researching', 'acl'), ('drug', 'compound'), ('discovery', 'dobj'), ('designs', 'conj'), ('.', 'punct')]

>> Bigrams: 
[[Introduction, Machine], [Machine, learning], [learning, ,], [,, helping], [helping, better], [better, toast], [toast,  ], [ , researching], [researching, drug], [drug, discovery], [discovery, designs], [designs, .]]

>> Trigrams: 
[[Introduction, Machine, learning], [Machine, learning, ,], [learning, ,, helping], [,, helping, better], [helping, better, toast], [better, toast,  ], [toast,  , researching], [ , researching, drug], [researching, drug, discovery], [drug, discovery, designs], [discovery, designs, .]]

>> Noun Phrases are: 
[Introduction Machine learning, us, better toast, drug discovery, designs]

>> Named Entities are: 
[] 

------------------- Sentence 2 -------------------

Sometimes the term is used  interchangeably with artificial intelligence (AI), but they’re not the same  thing. 


>> Tokens are: 
[term,  , interchangeably, artificial, intelligence, (, AI, ), ,,  , thing, .] 

>> PoS Tags are: 
[('term', 'NOUN'), (' ', 'SPACE'), ('interchangeably', 'ADV'), ('artificial', 'ADJ'), ('intelligence', 'NOUN'), ('(', 'PUNCT'), ('AI', 'PROPN'), (')', 'PUNCT'), (',', 'PUNCT'), (' ', 'SPACE'), ('thing', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('term', 'nsubjpass'), (' ', 'dobj'), ('interchangeably', 'advmod'), ('artificial', 'amod'), ('intelligence', 'pobj'), ('(', 'punct'), ('AI', 'appos'), (')', 'punct'), (',', 'punct'), (' ', 'compound'), ('thing', 'attr'), ('.', 'punct')]

>> Bigrams: 
[[term,  ], [ , interchangeably], [interchangeably, artificial], [artificial, intelligence], [intelligence, (], [(, AI], [AI, )], [), ,], [,,  ], [ , thing], [thing, .]]

>> Trigrams: 
[[term,  , interchangeably], [ , interchangeably, artificial], [interchangeably, artificial, intelligence], [artificial, intelligence, (], [intelligence, (, AI], [(, AI, )], [AI, ), ,], [), ,,  ], [,,  , thing], [ , thing, .]]

>> Noun Phrases are: 
[the term, artificial intelligence, (AI, they, the same  thing]

>> Named Entities are: 
[('AI', 'ORG')] 

------------------- Sentence 3 -------------------

While all AI involves machine learning, not all machine learning is AI. 


>> Tokens are: 
[AI, involves, machine, learning, ,, machine, learning, AI, .] 

>> PoS Tags are: 
[('AI', 'PROPN'), ('involves', 'VERB'), ('machine', 'NOUN'), ('learning', 'NOUN'), (',', 'PUNCT'), ('machine', 'NOUN'), ('learning', 'NOUN'), ('AI', 'PROPN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('AI', 'nsubj'), ('involves', 'advcl'), ('machine', 'compound'), ('learning', 'dobj'), (',', 'punct'), ('machine', 'compound'), ('learning', 'nsubj'), ('AI', 'attr'), ('.', 'punct')]

>> Bigrams: 
[[AI, involves], [involves, machine], [machine, learning], [learning, ,], [,, machine], [machine, learning], [learning, AI], [AI, .]]

>> Trigrams: 
[[AI, involves, machine], [involves, machine, learning], [machine, learning, ,], [learning, ,, machine], [,, machine, learning], [machine, learning, AI], [learning, AI, .]]

>> Noun Phrases are: 
[all AI, machine learning, not all machine learning, AI]

>> Named Entities are: 
[('AI', 'ORG'), ('AI', 'ORG')] 

------------------- Sentence 4 -------------------

  


>> Tokens are: 
[ ] 

>> PoS Tags are: 
[(' ', 'SPACE')] 

>> Dependency Tags are: 
[(' ', 'ROOT')]

>> Bigrams: 
[]

>> Trigrams: 
[]

>> Noun Phrases are: 
[]

>> Named Entities are: 
[] 


================================ Paragraph 22 =================================

Lexalytics’ core text analytics engine, Salience, can be considered a  “narrow” AI: It uses many different types of machine learning to solve  the task of understanding and analyzing text, but is focused exclusively  on text. We’ll be looking at the machine learning and natural language  processing (NLP) elements that Salience is built upon. 

------------------- Sentence 1 -------------------

Lexalytics’ core text analytics engine, Salience, can be considered a  “narrow” AI: It uses many different types of machine learning to solve  the task of understanding and analyzing text, but is focused exclusively  on text. 


>> Tokens are: 
[Lexalytics, ’, core, text, analytics, engine, ,, Salience, ,, considered,  , “, narrow, ”, AI, :, uses, different, types, machine, learning, solve,  , task, understanding, analyzing, text, ,, focused, exclusively,  , text, .] 

>> PoS Tags are: 
[('Lexalytics', 'PROPN'), ('’', 'PUNCT'), ('core', 'NOUN'), ('text', 'NOUN'), ('analytics', 'NOUN'), ('engine', 'NOUN'), (',', 'PUNCT'), ('Salience', 'PROPN'), (',', 'PUNCT'), ('considered', 'VERB'), (' ', 'SPACE'), ('“', 'PUNCT'), ('narrow', 'ADJ'), ('”', 'PUNCT'), ('AI', 'PROPN'), (':', 'PUNCT'), ('uses', 'VERB'), ('different', 'ADJ'), ('types', 'NOUN'), ('machine', 'NOUN'), ('learning', 'VERB'), ('solve', 'VERB'), (' ', 'SPACE'), ('task', 'NOUN'), ('understanding', 'NOUN'), ('analyzing', 'VERB'), ('text', 'NOUN'), (',', 'PUNCT'), ('focused', 'VERB'), ('exclusively', 'ADV'), (' ', 'SPACE'), ('text', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('Lexalytics', 'nmod'), ('’', 'punct'), ('core', 'compound'), ('text', 'compound'), ('analytics', 'compound'), ('engine', 'nsubjpass'), (',', 'punct'), ('Salience', 'appos'), (',', 'punct'), ('considered', 'ccomp'), (' ', 'nmod'), ('“', 'punct'), ('narrow', 'amod'), ('”', 'punct'), ('AI', 'oprd'), (':', 'punct'), ('uses', 'ROOT'), ('different', 'amod'), ('types', 'dobj'), ('machine', 'compound'), ('learning', 'pobj'), ('solve', 'xcomp'), (' ', 'dative'), ('task', 'dobj'), ('understanding', 'pobj'), ('analyzing', 'conj'), ('text', 'dobj'), (',', 'punct'), ('focused', 'conj'), ('exclusively', 'advmod'), (' ', 'npadvmod'), ('text', 'pobj'), ('.', 'punct')]

>> Bigrams: 
[[Lexalytics, ’], [’, core], [core, text], [text, analytics], [analytics, engine], [engine, ,], [,, Salience], [Salience, ,], [,, considered], [considered,  ], [ , “], [“, narrow], [narrow, ”], [”, AI], [AI, :], [:, uses], [uses, different], [different, types], [types, machine], [machine, learning], [learning, solve], [solve,  ], [ , task], [task, understanding], [understanding, analyzing], [analyzing, text], [text, ,], [,, focused], [focused, exclusively], [exclusively,  ], [ , text], [text, .]]

>> Trigrams: 
[[Lexalytics, ’, core], [’, core, text], [core, text, analytics], [text, analytics, engine], [analytics, engine, ,], [engine, ,, Salience], [,, Salience, ,], [Salience, ,, considered], [,, considered,  ], [considered,  , “], [ , “, narrow], [“, narrow, ”], [narrow, ”, AI], [”, AI, :], [AI, :, uses], [:, uses, different], [uses, different, types], [different, types, machine], [types, machine, learning], [machine, learning, solve], [learning, solve,  ], [solve,  , task], [ , task, understanding], [task, understanding, analyzing], [understanding, analyzing, text], [analyzing, text, ,], [text, ,, focused], [,, focused, exclusively], [focused, exclusively,  ], [exclusively,  , text], [ , text, .]]

>> Noun Phrases are: 
[Lexalytics’ core text analytics engine, Salience, a  “narrow” AI, It, many different types, the task, understanding, text, text]

>> Named Entities are: 
[('Salience', 'PERSON')] 

------------------- Sentence 2 -------------------

We’ll be looking at the machine learning and natural language  processing (NLP) elements that Salience is built upon. 


>> Tokens are: 
[looking, machine, learning, natural, language,  , processing, (, NLP, ), elements, Salience, built, .] 

>> PoS Tags are: 
[('looking', 'VERB'), ('machine', 'NOUN'), ('learning', 'NOUN'), ('natural', 'ADJ'), ('language', 'NOUN'), (' ', 'SPACE'), ('processing', 'NOUN'), ('(', 'PUNCT'), ('NLP', 'PROPN'), (')', 'PUNCT'), ('elements', 'NOUN'), ('Salience', 'PROPN'), ('built', 'VERB'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('looking', 'ROOT'), ('machine', 'compound'), ('learning', 'pobj'), ('natural', 'amod'), ('language', 'conj'), (' ', 'compound'), ('processing', 'nmod'), ('(', 'punct'), ('NLP', 'appos'), (')', 'punct'), ('elements', 'dobj'), ('Salience', 'nsubjpass'), ('built', 'relcl'), ('.', 'punct')]

>> Bigrams: 
[[looking, machine], [machine, learning], [learning, natural], [natural, language], [language,  ], [ , processing], [processing, (], [(, NLP], [NLP, )], [), elements], [elements, Salience], [Salience, built], [built, .]]

>> Trigrams: 
[[looking, machine, learning], [machine, learning, natural], [learning, natural, language], [natural, language,  ], [language,  , processing], [ , processing, (], [processing, (, NLP], [(, NLP, )], [NLP, ), elements], [), elements, Salience], [elements, Salience, built], [Salience, built, .]]

>> Noun Phrases are: 
[We, the machine learning, natural language, NLP, Salience]

>> Named Entities are: 
[('NLP', 'ORG'), ('Salience', 'ORG')] 


================================ Paragraph 23 =================================

We’ll discuss the different aspects of text analytics and how Lexalytics,  a company with more than a decade of experience in machine learning,  applies machine learning to solve problems in natural language processing.  

------------------- Sentence 1 -------------------

We’ll discuss the different aspects of text analytics and how Lexalytics,  a company with more than a decade of experience in machine learning,  applies machine learning to solve problems in natural language processing. 


>> Tokens are: 
[discuss, different, aspects, text, analytics, Lexalytics, ,,  , company, decade, experience, machine, learning, ,,  , applies, machine, learning, solve, problems, natural, language, processing, .] 

>> PoS Tags are: 
[('discuss', 'VERB'), ('different', 'ADJ'), ('aspects', 'NOUN'), ('text', 'NOUN'), ('analytics', 'NOUN'), ('Lexalytics', 'PROPN'), (',', 'PUNCT'), (' ', 'SPACE'), ('company', 'NOUN'), ('decade', 'NOUN'), ('experience', 'NOUN'), ('machine', 'NOUN'), ('learning', 'NOUN'), (',', 'PUNCT'), (' ', 'SPACE'), ('applies', 'VERB'), ('machine', 'NOUN'), ('learning', 'VERB'), ('solve', 'VERB'), ('problems', 'NOUN'), ('natural', 'ADJ'), ('language', 'NOUN'), ('processing', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('discuss', 'ccomp'), ('different', 'amod'), ('aspects', 'dobj'), ('text', 'compound'), ('analytics', 'pobj'), ('Lexalytics', 'conj'), (',', 'punct'), (' ', 'conj'), ('company', 'appos'), ('decade', 'pobj'), ('experience', 'pobj'), ('machine', 'compound'), ('learning', 'pobj'), (',', 'punct'), (' ', 'nsubj'), ('applies', 'ROOT'), ('machine', 'dobj'), ('learning', 'advcl'), ('solve', 'xcomp'), ('problems', 'dobj'), ('natural', 'amod'), ('language', 'compound'), ('processing', 'pobj'), ('.', 'punct')]

>> Bigrams: 
[[discuss, different], [different, aspects], [aspects, text], [text, analytics], [analytics, Lexalytics], [Lexalytics, ,], [,,  ], [ , company], [company, decade], [decade, experience], [experience, machine], [machine, learning], [learning, ,], [,,  ], [ , applies], [applies, machine], [machine, learning], [learning, solve], [solve, problems], [problems, natural], [natural, language], [language, processing], [processing, .]]

>> Trigrams: 
[[discuss, different, aspects], [different, aspects, text], [aspects, text, analytics], [text, analytics, Lexalytics], [analytics, Lexalytics, ,], [Lexalytics, ,,  ], [,,  , company], [ , company, decade], [company, decade, experience], [decade, experience, machine], [experience, machine, learning], [machine, learning, ,], [learning, ,,  ], [,,  , applies], [ , applies, machine], [applies, machine, learning], [machine, learning, solve], [learning, solve, problems], [solve, problems, natural], [problems, natural, language], [natural, language, processing], [language, processing, .]]

>> Noun Phrases are: 
[We, the different aspects, text analytics, how Lexalytics, a company, more than a decade, experience, machine learning, machine, problems, natural language processing]

>> Named Entities are: 
[('Lexalytics', 'ORG'), ('more than a decade', 'DATE')] 

------------------- Sentence 2 -------------------

  


>> Tokens are: 
[ ] 

>> PoS Tags are: 
[(' ', 'SPACE')] 

>> Dependency Tags are: 
[(' ', 'ROOT')]

>> Bigrams: 
[]

>> Trigrams: 
[]

>> Noun Phrases are: 
[]

>> Named Entities are: 
[] 


================================ Paragraph 24 =================================

    3 KINDS OF TEXT ANALYTICS SYSTEMS  

------------------- Sentence 1 -------------------

    3 KINDS OF TEXT ANALYTICS SYSTEMS   


>> Tokens are: 
[    , 3, KINDS, TEXT, ANALYTICS, SYSTEMS,  ] 

>> PoS Tags are: 
[('    ', 'SPACE'), ('3', 'NUM'), ('KINDS', 'NOUN'), ('TEXT', 'PROPN'), ('ANALYTICS', 'PROPN'), ('SYSTEMS', 'PROPN'), (' ', 'SPACE')] 

>> Dependency Tags are: 
[('    ', 'nummod'), ('3', 'nummod'), ('KINDS', 'ROOT'), ('TEXT', 'compound'), ('ANALYTICS', 'nmod'), ('SYSTEMS', 'pobj'), (' ', 'pobj')]

>> Bigrams: 
[[    , 3], [3, KINDS], [KINDS, TEXT], [TEXT, ANALYTICS], [ANALYTICS, SYSTEMS], [SYSTEMS,  ]]

>> Trigrams: 
[[    , 3, KINDS], [3, KINDS, TEXT], [KINDS, TEXT, ANALYTICS], [TEXT, ANALYTICS, SYSTEMS], [ANALYTICS, SYSTEMS,  ]]

>> Noun Phrases are: 
[    3 KINDS, TEXT ANALYTICS SYSTEMS]

>> Named Entities are: 
[('3', 'CARDINAL'), ('KINDS', 'ORG')] 


================================ Paragraph 25 =================================

 Rules-based (pure NLP)   

------------------- Sentence 1 -------------------

 Rules-based (pure NLP)    


>> Tokens are: 
[ , Rules, -, based, (, pure, NLP, ),   ] 

>> PoS Tags are: 
[(' ', 'SPACE'), ('Rules', 'NOUN'), ('-', 'PUNCT'), ('based', 'VERB'), ('(', 'PUNCT'), ('pure', 'ADJ'), ('NLP', 'PROPN'), (')', 'PUNCT'), ('  ', 'SPACE')] 

>> Dependency Tags are: 
[(' ', 'dep'), ('Rules', 'npadvmod'), ('-', 'punct'), ('based', 'amod'), ('(', 'punct'), ('pure', 'amod'), ('NLP', 'ROOT'), (')', 'punct'), ('  ', 'appos')]

>> Bigrams: 
[[ , Rules], [Rules, -], [-, based], [based, (], [(, pure], [pure, NLP], [NLP, )], [),   ]]

>> Trigrams: 
[[ , Rules, -], [Rules, -, based], [-, based, (], [based, (, pure], [(, pure, NLP], [pure, NLP, )], [NLP, ),   ]]

>> Noun Phrases are: 
[ Rules-based (pure NLP]

>> Named Entities are: 
[('NLP', 'ORG')] 


================================ Paragraph 26 =================================

 Machine learning-based (pure ML)  

------------------- Sentence 1 -------------------

 Machine learning-based (pure ML) 


>> Tokens are: 
[ , Machine, learning, -, based, (, pure, ML, )] 

>> PoS Tags are: 
[(' ', 'SPACE'), ('Machine', 'NOUN'), ('learning', 'NOUN'), ('-', 'PUNCT'), ('based', 'VERB'), ('(', 'PUNCT'), ('pure', 'ADJ'), ('ML', 'PROPN'), (')', 'PUNCT')] 

>> Dependency Tags are: 
[(' ', 'ROOT'), ('Machine', 'compound'), ('learning', 'npadvmod'), ('-', 'punct'), ('based', 'amod'), ('(', 'punct'), ('pure', 'amod'), ('ML', 'npadvmod'), (')', 'punct')]

>> Bigrams: 
[[ , Machine], [Machine, learning], [learning, -], [-, based], [based, (], [(, pure], [pure, ML], [ML, )]]

>> Trigrams: 
[[ , Machine, learning], [Machine, learning, -], [learning, -, based], [-, based, (], [based, (, pure], [(, pure, ML], [pure, ML, )]]

>> Noun Phrases are: 
[]

>> Named Entities are: 
[('ML', 'FAC')] 

------------------- Sentence 2 -------------------

  


>> Tokens are: 
[ ] 

>> PoS Tags are: 
[(' ', 'SPACE')] 

>> Dependency Tags are: 
[(' ', 'ROOT')]

>> Bigrams: 
[]

>> Trigrams: 
[]

>> Noun Phrases are: 
[]

>> Named Entities are: 
[] 


================================ Paragraph 27 =================================

 Hybrid (a combination of ML and NLP) 

------------------- Sentence 1 -------------------

 Hybrid (a combination of ML and NLP) 


>> Tokens are: 
[ , Hybrid, (, combination, ML, NLP, )] 

>> PoS Tags are: 
[(' ', 'SPACE'), ('Hybrid', 'NOUN'), ('(', 'PUNCT'), ('combination', 'NOUN'), ('ML', 'PROPN'), ('NLP', 'PROPN'), (')', 'PUNCT')] 

>> Dependency Tags are: 
[(' ', 'amod'), ('Hybrid', 'ROOT'), ('(', 'punct'), ('combination', 'appos'), ('ML', 'pobj'), ('NLP', 'conj'), (')', 'punct')]

>> Bigrams: 
[[ , Hybrid], [Hybrid, (], [(, combination], [combination, ML], [ML, NLP], [NLP, )]]

>> Trigrams: 
[[ , Hybrid, (], [Hybrid, (, combination], [(, combination, ML], [combination, ML, NLP], [ML, NLP, )]]

>> Noun Phrases are: 
[ Hybrid, a combination, ML, NLP]

>> Named Entities are: 
[('ML', 'ORG'), ('NLP', 'ORG')] 


================================ Paragraph 28 =================================

For further reading, you can consult our white papers “Build vs. Buy,”  which talks about the economics of machine learning in a text analytics  context, and “Tune First, Then Train,” which discusses our philosophy   of customization for better accuracy and more-relevant results. When  taken together with this paper, these resources offer a more complete  view of text analytics solutions. 

------------------- Sentence 1 -------------------

For further reading, you can consult our white papers “Build vs. Buy,”  which talks about the economics of machine learning in a text analytics  context, and “Tune First, Then Train,” which discusses our philosophy   of customization for better accuracy and more-relevant results. 


>> Tokens are: 
[reading, ,, consult, white, papers, “, Build, vs., Buy, ,, ”,  , talks, economics, machine, learning, text, analytics,  , context, ,, “, Tune, ,, Train, ,, ”, discusses, philosophy,   , customization, better, accuracy, -, relevant, results, .] 

>> PoS Tags are: 
[('reading', 'NOUN'), (',', 'PUNCT'), ('consult', 'VERB'), ('white', 'ADJ'), ('papers', 'NOUN'), ('“', 'PUNCT'), ('Build', 'VERB'), ('vs.', 'ADP'), ('Buy', 'PROPN'), (',', 'PUNCT'), ('”', 'PUNCT'), (' ', 'SPACE'), ('talks', 'VERB'), ('economics', 'NOUN'), ('machine', 'NOUN'), ('learning', 'VERB'), ('text', 'NOUN'), ('analytics', 'NOUN'), (' ', 'SPACE'), ('context', 'NOUN'), (',', 'PUNCT'), ('“', 'PUNCT'), ('Tune', 'PROPN'), (',', 'PUNCT'), ('Train', 'NOUN'), (',', 'PUNCT'), ('”', 'PUNCT'), ('discusses', 'VERB'), ('philosophy', 'NOUN'), ('  ', 'SPACE'), ('customization', 'NOUN'), ('better', 'ADJ'), ('accuracy', 'NOUN'), ('-', 'PUNCT'), ('relevant', 'ADJ'), ('results', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('reading', 'pobj'), (',', 'punct'), ('consult', 'ROOT'), ('white', 'amod'), ('papers', 'dobj'), ('“', 'punct'), ('Build', 'appos'), ('vs.', 'prep'), ('Buy', 'pobj'), (',', 'punct'), ('”', 'punct'), (' ', 'appos'), ('talks', 'relcl'), ('economics', 'pobj'), ('machine', 'compound'), ('learning', 'pobj'), ('text', 'compound'), ('analytics', 'pobj'), (' ', 'prep'), ('context', 'pobj'), (',', 'punct'), ('“', 'punct'), ('Tune', 'compound'), (',', 'punct'), ('Train', 'conj'), (',', 'punct'), ('”', 'punct'), ('discusses', 'relcl'), ('philosophy', 'dobj'), ('  ', 'dobj'), ('customization', 'pobj'), ('better', 'amod'), ('accuracy', 'pobj'), ('-', 'punct'), ('relevant', 'amod'), ('results', 'conj'), ('.', 'punct')]

>> Bigrams: 
[[reading, ,], [,, consult], [consult, white], [white, papers], [papers, “], [“, Build], [Build, vs.], [vs., Buy], [Buy, ,], [,, ”], [”,  ], [ , talks], [talks, economics], [economics, machine], [machine, learning], [learning, text], [text, analytics], [analytics,  ], [ , context], [context, ,], [,, “], [“, Tune], [Tune, ,], [,, Train], [Train, ,], [,, ”], [”, discusses], [discusses, philosophy], [philosophy,   ], [  , customization], [customization, better], [better, accuracy], [accuracy, -], [-, relevant], [relevant, results], [results, .]]

>> Trigrams: 
[[reading, ,, consult], [,, consult, white], [consult, white, papers], [white, papers, “], [papers, “, Build], [“, Build, vs.], [Build, vs., Buy], [vs., Buy, ,], [Buy, ,, ”], [,, ”,  ], [”,  , talks], [ , talks, economics], [talks, economics, machine], [economics, machine, learning], [machine, learning, text], [learning, text, analytics], [text, analytics,  ], [analytics,  , context], [ , context, ,], [context, ,, “], [,, “, Tune], [“, Tune, ,], [Tune, ,, Train], [,, Train, ,], [Train, ,, ”], [,, ”, discusses], [”, discusses, philosophy], [discusses, philosophy,   ], [philosophy,   , customization], [  , customization, better], [customization, better, accuracy], [better, accuracy, -], [accuracy, -, relevant], [-, relevant, results], [relevant, results, .]]

>> Noun Phrases are: 
[further reading, you, our white papers, Buy, the economics, a text analytics, context, “Tune First, Then Train, our philosophy, customization, better accuracy, more-relevant results]

>> Named Entities are: 
[('Build', 'PERSON'), ('Tune First, Then Train', 'WORK_OF_ART')] 

------------------- Sentence 2 -------------------

When  taken together with this paper, these resources offer a more complete  view of text analytics solutions. 


>> Tokens are: 
[ , taken, paper, ,, resources, offer, complete,  , view, text, analytics, solutions, .] 

>> PoS Tags are: 
[(' ', 'SPACE'), ('taken', 'VERB'), ('paper', 'NOUN'), (',', 'PUNCT'), ('resources', 'NOUN'), ('offer', 'VERB'), ('complete', 'ADJ'), (' ', 'SPACE'), ('view', 'NOUN'), ('text', 'NOUN'), ('analytics', 'NOUN'), ('solutions', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[(' ', 'nsubj'), ('taken', 'advcl'), ('paper', 'pobj'), (',', 'punct'), ('resources', 'nsubj'), ('offer', 'ROOT'), ('complete', 'amod'), (' ', 'compound'), ('view', 'dobj'), ('text', 'compound'), ('analytics', 'compound'), ('solutions', 'pobj'), ('.', 'punct')]

>> Bigrams: 
[[ , taken], [taken, paper], [paper, ,], [,, resources], [resources, offer], [offer, complete], [complete,  ], [ , view], [view, text], [text, analytics], [analytics, solutions], [solutions, .]]

>> Trigrams: 
[[ , taken, paper], [taken, paper, ,], [paper, ,, resources], [,, resources, offer], [resources, offer, complete], [offer, complete,  ], [complete,  , view], [ , view, text], [view, text, analytics], [text, analytics, solutions], [analytics, solutions, .]]

>> Noun Phrases are: 
[this paper, these resources, a more complete  view, text analytics solutions]

>> Named Entities are: 
[] 


================================ Paragraph 29 =================================

Machine Learning   is Really Machine Teaching  .........................3   Supervised, Semi-Supervised and  Unsupervised Machine Learning   Supervised Learning ..............................5  Semi-Supervised Learning ................6  Unsupervised Learning ........................6 

------------------- Sentence 1 -------------------

Machine Learning   is Really Machine Teaching  .........................3   Supervised, Semi-Supervised and   


>> Tokens are: 
[Machine, Learning,   , Machine, Teaching,  , ........................., 3,   , Supervised, ,, Semi, -, Supervised,  ] 

>> PoS Tags are: 
[('Machine', 'PROPN'), ('Learning', 'PROPN'), ('  ', 'SPACE'), ('Machine', 'PROPN'), ('Teaching', 'PROPN'), (' ', 'SPACE'), ('.........................', 'PUNCT'), ('3', 'NUM'), ('  ', 'SPACE'), ('Supervised', 'VERB'), (',', 'PUNCT'), ('Semi', 'ADJ'), ('-', 'ADJ'), ('Supervised', 'ADJ'), (' ', 'SPACE')] 

>> Dependency Tags are: 
[('Machine', 'compound'), ('Learning', 'nsubj'), ('  ', 'appos'), ('Machine', 'compound'), ('Teaching', 'attr'), (' ', 'appos'), ('.........................', 'punct'), ('3', 'nummod'), ('  ', 'appos'), ('Supervised', 'ccomp'), (',', 'punct'), ('Semi', 'conj'), ('-', 'punct'), ('Supervised', 'conj'), (' ', 'conj')]

>> Bigrams: 
[[Machine, Learning], [Learning,   ], [  , Machine], [Machine, Teaching], [Teaching,  ], [ , .........................], [........................., 3], [3,   ], [  , Supervised], [Supervised, ,], [,, Semi], [Semi, -], [-, Supervised], [Supervised,  ]]

>> Trigrams: 
[[Machine, Learning,   ], [Learning,   , Machine], [  , Machine, Teaching], [Machine, Teaching,  ], [Teaching,  , .........................], [ , ........................., 3], [........................., 3,   ], [3,   , Supervised], [  , Supervised, ,], [Supervised, ,, Semi], [,, Semi, -], [Semi, -, Supervised], [-, Supervised,  ]]

>> Noun Phrases are: 
[Machine Learning, Machine Teaching]

>> Named Entities are: 
[('3', 'CARDINAL')] 

------------------- Sentence 2 -------------------

Unsupervised Machine Learning   Supervised Learning .............................. 


>> Tokens are: 
[Unsupervised, Machine, Learning,   , Supervised, Learning, ..............................] 

>> PoS Tags are: 
[('Unsupervised', 'PROPN'), ('Machine', 'PROPN'), ('Learning', 'PROPN'), ('  ', 'SPACE'), ('Supervised', 'PROPN'), ('Learning', 'PROPN'), ('..............................', 'PUNCT')] 

>> Dependency Tags are: 
[('Unsupervised', 'compound'), ('Machine', 'compound'), ('Learning', 'dep'), ('  ', 'appos'), ('Supervised', 'compound'), ('Learning', 'ROOT'), ('..............................', 'punct')]

>> Bigrams: 
[[Unsupervised, Machine], [Machine, Learning], [Learning,   ], [  , Supervised], [Supervised, Learning], [Learning, ..............................]]

>> Trigrams: 
[[Unsupervised, Machine, Learning], [Machine, Learning,   ], [Learning,   , Supervised], [  , Supervised, Learning], [Supervised, Learning, ..............................]]

>> Noun Phrases are: 
[Unsupervised Machine Learning   Supervised Learning]

>> Named Entities are: 
[] 

------------------- Sentence 3 -------------------

5  Semi-Supervised Learning ................6   


>> Tokens are: 
[5,  , Semi, -, Supervised, Learning, ................, 6,  ] 

>> PoS Tags are: 
[('5', 'NUM'), (' ', 'SPACE'), ('Semi', 'ADJ'), ('-', 'ADJ'), ('Supervised', 'ADJ'), ('Learning', 'NOUN'), ('................', 'PUNCT'), ('6', 'NUM'), (' ', 'SPACE')] 

>> Dependency Tags are: 
[('5', 'nummod'), (' ', 'dep'), ('Semi', 'amod'), ('-', 'amod'), ('Supervised', 'amod'), ('Learning', 'ROOT'), ('................', 'punct'), ('6', 'nummod'), (' ', 'appos')]

>> Bigrams: 
[[5,  ], [ , Semi], [Semi, -], [-, Supervised], [Supervised, Learning], [Learning, ................], [................, 6], [6,  ]]

>> Trigrams: 
[[5,  , Semi], [ , Semi, -], [Semi, -, Supervised], [-, Supervised, Learning], [Supervised, Learning, ................], [Learning, ................, 6], [................, 6,  ]]

>> Noun Phrases are: 
[5  Semi-Supervised Learning]

>> Named Entities are: 
[] 

------------------- Sentence 4 -------------------

Unsupervised Learning ........................ 


>> Tokens are: 
[Unsupervised, Learning, ........................] 

>> PoS Tags are: 
[('Unsupervised', 'PROPN'), ('Learning', 'PROPN'), ('........................', 'PUNCT')] 

>> Dependency Tags are: 
[('Unsupervised', 'compound'), ('Learning', 'ROOT'), ('........................', 'punct')]

>> Bigrams: 
[[Unsupervised, Learning], [Learning, ........................]]

>> Trigrams: 
[[Unsupervised, Learning, ........................]]

>> Noun Phrases are: 
[Unsupervised Learning]

>> Named Entities are: 
[] 

------------------- Sentence 5 -------------------

6 


>> Tokens are: 
[6] 

>> PoS Tags are: 
[('6', 'NUM')] 

>> Dependency Tags are: 
[('6', 'ROOT')]

>> Bigrams: 
[]

>> Trigrams: 
[]

>> Noun Phrases are: 
[]

>> Named Entities are: 
[] 


================================ Paragraph 30 =================================

Happier by the Dozen:   The More Models, the Merrier .................... 7 

------------------- Sentence 1 -------------------

Happier by the Dozen:   The More Models, the Merrier .................... 


>> Tokens are: 
[Happier, Dozen, :,   , Models, ,, Merrier, ....................] 

>> PoS Tags are: 
[('Happier', 'ADJ'), ('Dozen', 'NOUN'), (':', 'PUNCT'), ('  ', 'SPACE'), ('Models', 'PROPN'), (',', 'PUNCT'), ('Merrier', 'PROPN'), ('....................', 'PUNCT')] 

>> Dependency Tags are: 
[('Happier', 'amod'), ('Dozen', 'pobj'), (':', 'punct'), ('  ', 'appos'), ('Models', 'ROOT'), (',', 'punct'), ('Merrier', 'npadvmod'), ('....................', 'punct')]

>> Bigrams: 
[[Happier, Dozen], [Dozen, :], [:,   ], [  , Models], [Models, ,], [,, Merrier], [Merrier, ....................]]

>> Trigrams: 
[[Happier, Dozen, :], [Dozen, :,   ], [:,   , Models], [  , Models, ,], [Models, ,, Merrier], [,, Merrier, ....................]]

>> Noun Phrases are: 
[the Dozen]

>> Named Entities are: 
[('Models', 'PRODUCT'), ('Merrier', 'ORG')] 

------------------- Sentence 2 -------------------

7 


>> Tokens are: 
[7] 

>> PoS Tags are: 
[('7', 'NUM')] 

>> Dependency Tags are: 
[('7', 'ROOT')]

>> Bigrams: 
[]

>> Trigrams: 
[]

>> Noun Phrases are: 
[]

>> Named Entities are: 
[] 


================================ Paragraph 31 =================================

Coding vs. Learning:   Making the Case for Each ............................9 

------------------- Sentence 1 -------------------

Coding vs. Learning:   Making the Case for Each ............................ 


>> Tokens are: 
[Coding, vs., Learning, :,   , Making, Case, ............................] 

>> PoS Tags are: 
[('Coding', 'VERB'), ('vs.', 'ADP'), ('Learning', 'PROPN'), (':', 'PUNCT'), ('  ', 'SPACE'), ('Making', 'VERB'), ('Case', 'NOUN'), ('............................', 'SYM')] 

>> Dependency Tags are: 
[('Coding', 'ROOT'), ('vs.', 'prep'), ('Learning', 'pobj'), (':', 'punct'), ('  ', 'appos'), ('Making', 'acl'), ('Case', 'dobj'), ('............................', 'punct')]

>> Bigrams: 
[[Coding, vs.], [vs., Learning], [Learning, :], [:,   ], [  , Making], [Making, Case], [Case, ............................]]

>> Trigrams: 
[[Coding, vs., Learning], [vs., Learning, :], [Learning, :,   ], [:,   , Making], [  , Making, Case], [Making, Case, ............................]]

>> Noun Phrases are: 
[Learning, the Case]

>> Named Entities are: 
[] 

------------------- Sentence 2 -------------------

9 


>> Tokens are: 
[9] 

>> PoS Tags are: 
[('9', 'NUM')] 

>> Dependency Tags are: 
[('9', 'ROOT')]

>> Bigrams: 
[]

>> Trigrams: 
[]

>> Noun Phrases are: 
[]

>> Named Entities are: 
[] 


================================ Paragraph 32 =================================

Black Box/Clear Box:   Looking Inside the Data ............................... 10 

------------------- Sentence 1 -------------------

Black Box/Clear Box:    


>> Tokens are: 
[Black, Box, /, Clear, Box, :,   ] 

>> PoS Tags are: 
[('Black', 'PROPN'), ('Box', 'PROPN'), ('/', 'SYM'), ('Clear', 'PROPN'), ('Box', 'PROPN'), (':', 'PUNCT'), ('  ', 'SPACE')] 

>> Dependency Tags are: 
[('Black', 'nmod'), ('Box', 'nmod'), ('/', 'punct'), ('Clear', 'compound'), ('Box', 'ROOT'), (':', 'punct'), ('  ', 'appos')]

>> Bigrams: 
[[Black, Box], [Box, /], [/, Clear], [Clear, Box], [Box, :], [:,   ]]

>> Trigrams: 
[[Black, Box, /], [Box, /, Clear], [/, Clear, Box], [Clear, Box, :], [Box, :,   ]]

>> Noun Phrases are: 
[Black Box/Clear Box]

>> Named Entities are: 
[('Box', 'PERSON')] 

------------------- Sentence 2 -------------------

Looking Inside the Data ............................... 10 


>> Tokens are: 
[Looking, Inside, Data, ..............................., 10] 

>> PoS Tags are: 
[('Looking', 'VERB'), ('Inside', 'ADP'), ('Data', 'PROPN'), ('...............................', 'PUNCT'), ('10', 'NUM')] 

>> Dependency Tags are: 
[('Looking', 'ROOT'), ('Inside', 'prep'), ('Data', 'pobj'), ('...............................', 'punct'), ('10', 'npadvmod')]

>> Bigrams: 
[[Looking, Inside], [Inside, Data], [Data, ...............................], [..............................., 10]]

>> Trigrams: 
[[Looking, Inside, Data], [Inside, Data, ...............................], [Data, ..............................., 10]]

>> Noun Phrases are: 
[the Data]

>> Named Entities are: 
[('10', 'CARDINAL')] 


================================ Paragraph 33 =================================

Tune First, Then Train:   Efficiency before Complexity ....................12 

------------------- Sentence 1 -------------------

Tune First, Then Train:   Efficiency before Complexity ....................12 


>> Tokens are: 
[Tune, ,, Train, :,   , Efficiency, Complexity, ...................., 12] 

>> PoS Tags are: 
[('Tune', 'PROPN'), (',', 'PUNCT'), ('Train', 'NOUN'), (':', 'PUNCT'), ('  ', 'SPACE'), ('Efficiency', 'NOUN'), ('Complexity', 'PROPN'), ('....................', 'PUNCT'), ('12', 'NUM')] 

>> Dependency Tags are: 
[('Tune', 'compound'), (',', 'punct'), ('Train', 'ROOT'), (':', 'punct'), ('  ', 'compound'), ('Efficiency', 'appos'), ('Complexity', 'pobj'), ('....................', 'punct'), ('12', 'nummod')]

>> Bigrams: 
[[Tune, ,], [,, Train], [Train, :], [:,   ], [  , Efficiency], [Efficiency, Complexity], [Complexity, ....................], [...................., 12]]

>> Trigrams: 
[[Tune, ,, Train], [,, Train, :], [Train, :,   ], [:,   , Efficiency], [  , Efficiency, Complexity], [Efficiency, Complexity, ....................], [Complexity, ...................., 12]]

>> Noun Phrases are: 
[Tune First, Then Train,   Efficiency, Complexity]

>> Named Entities are: 
[] 


================================ Paragraph 34 =================================

Summary/Conclusion .................................. 14

------------------- Sentence 1 -------------------

Summary/Conclusion .................................. 


>> Tokens are: 
[Summary, /, Conclusion, ..................................] 

>> PoS Tags are: 
[('Summary', 'PROPN'), ('/', 'SYM'), ('Conclusion', 'PROPN'), ('..................................', 'PUNCT')] 

>> Dependency Tags are: 
[('Summary', 'nmod'), ('/', 'punct'), ('Conclusion', 'ROOT'), ('..................................', 'punct')]

>> Bigrams: 
[[Summary, /], [/, Conclusion], [Conclusion, ..................................]]

>> Trigrams: 
[[Summary, /, Conclusion], [/, Conclusion, ..................................]]

>> Noun Phrases are: 
[Summary/Conclusion]

>> Named Entities are: 
[] 

------------------- Sentence 2 -------------------

14 


>> Tokens are: 
[14] 

>> PoS Tags are: 
[('14', 'NUM')] 

>> Dependency Tags are: 
[('14', 'ROOT')]

>> Bigrams: 
[]

>> Trigrams: 
[]

>> Noun Phrases are: 
[]

>> Named Entities are: 
[] 


================================ Paragraph 35 =================================

W H I T E  P A P E R 

------------------- Sentence 1 -------------------

W H 


>> Tokens are: 
[W, H] 

>> PoS Tags are: 
[('W', 'NOUN'), ('H', 'NOUN')] 

>> Dependency Tags are: 
[('W', 'compound'), ('H', 'ROOT')]

>> Bigrams: 
[[W, H]]

>> Trigrams: 
[]

>> Noun Phrases are: 
[W H]

>> Named Entities are: 
[] 

------------------- Sentence 2 -------------------

I T 


>> Tokens are: 
[T] 

>> PoS Tags are: 
[('T', 'NOUN')] 

>> Dependency Tags are: 
[('T', 'appos')]

>> Bigrams: 
[]

>> Trigrams: 
[]

>> Noun Phrases are: 
[I, T]

>> Named Entities are: 
[] 

------------------- Sentence 3 -------------------

E   


>> Tokens are: 
[E,  ] 

>> PoS Tags are: 
[('E', 'NOUN'), (' ', 'SPACE')] 

>> Dependency Tags are: 
[('E', 'ROOT'), (' ', 'appos')]

>> Bigrams: 
[[E,  ]]

>> Trigrams: 
[]

>> Noun Phrases are: 
[E]

>> Named Entities are: 
[] 

------------------- Sentence 4 -------------------

P A P E R 


>> Tokens are: 
[P, P, E, R] 

>> PoS Tags are: 
[('P', 'NOUN'), ('P', 'NOUN'), ('E', 'NOUN'), ('R', 'NOUN')] 

>> Dependency Tags are: 
[('P', 'compound'), ('P', 'compound'), ('E', 'compound'), ('R', 'ROOT')]

>> Bigrams: 
[[P, P], [P, E], [E, R]]

>> Trigrams: 
[[P, P, E], [P, E, R]]

>> Noun Phrases are: 
[P A P E R]

>> Named Entities are: 
[] 


================================ Paragraph 36 =================================

3|       |   Lexalytics, Inc., 48 North Pleasant St. Unit 301, Amherst MA 01002 USA   |   1-800-377-8036 |   www.lexalytics.com 

------------------- Sentence 1 -------------------

3|       |   Lexalytics, Inc., 48 North Pleasant St. Unit 301, Amherst MA 01002 


>> Tokens are: 
[3|,       , |,   , Lexalytics, ,, Inc., ,, 48, North, Pleasant, St., Unit, 301, ,, Amherst, MA, 01002] 

>> PoS Tags are: 
[('3|', 'NUM'), ('      ', 'SPACE'), ('|', 'NOUN'), ('  ', 'SPACE'), ('Lexalytics', 'PROPN'), (',', 'PUNCT'), ('Inc.', 'PROPN'), (',', 'PUNCT'), ('48', 'NUM'), ('North', 'PROPN'), ('Pleasant', 'PROPN'), ('St.', 'PROPN'), ('Unit', 'PROPN'), ('301', 'NUM'), (',', 'PUNCT'), ('Amherst', 'PROPN'), ('MA', 'PROPN'), ('01002', 'NUM')] 

>> Dependency Tags are: 
[('3|', 'nummod'), ('      ', 'compound'), ('|', 'ROOT'), ('  ', 'nmod'), ('Lexalytics', 'nmod'), (',', 'punct'), ('Inc.', 'appos'), (',', 'punct'), ('48', 'nummod'), ('North', 'compound'), ('Pleasant', 'compound'), ('St.', 'compound'), ('Unit', 'appos'), ('301', 'nummod'), (',', 'punct'), ('Amherst', 'compound'), ('MA', 'appos'), ('01002', 'punct')]

>> Bigrams: 
[[3|,       ], [      , |], [|,   ], [  , Lexalytics], [Lexalytics, ,], [,, Inc.], [Inc., ,], [,, 48], [48, North], [North, Pleasant], [Pleasant, St.], [St., Unit], [Unit, 301], [301, ,], [,, Amherst], [Amherst, MA], [MA, 01002]]

>> Trigrams: 
[[3|,       , |], [      , |,   ], [|,   , Lexalytics], [  , Lexalytics, ,], [Lexalytics, ,, Inc.], [,, Inc., ,], [Inc., ,, 48], [,, 48, North], [48, North, Pleasant], [North, Pleasant, St.], [Pleasant, St., Unit], [St., Unit, 301], [Unit, 301, ,], [301, ,, Amherst], [,, Amherst, MA], [Amherst, MA, 01002]]

>> Noun Phrases are: 
[3|       |,   Lexalytics, Inc., 48 North Pleasant St. Unit, Amherst MA]

>> Named Entities are: 
[('3|', 'MONEY'), ('Lexalytics, Inc.', 'ORG'), ('48', 'CARDINAL'), ('North Pleasant St. Unit 301', 'ORG'), ('Amherst MA', 'ORG')] 

------------------- Sentence 2 -------------------

USA 


>> Tokens are: 
[USA] 

>> PoS Tags are: 
[('USA', 'PROPN')] 

>> Dependency Tags are: 
[('USA', 'ROOT')]

>> Bigrams: 
[]

>> Trigrams: 
[]

>> Noun Phrases are: 
[USA]

>> Named Entities are: 
[] 

------------------- Sentence 3 -------------------

  |   1-800-377-8036 |   www.lexalytics.com 


>> Tokens are: 
[  , |,   , 1, -, 800, -, 377, -, 8036, |,   , www.lexalytics.com] 

>> PoS Tags are: 
[('  ', 'SPACE'), ('|', 'NOUN'), ('  ', 'SPACE'), ('1', 'NUM'), ('-', 'SYM'), ('800', 'NUM'), ('-', 'NUM'), ('377', 'NUM'), ('-', 'PUNCT'), ('8036', 'NUM'), ('|', 'NOUN'), ('  ', 'SPACE'), ('www.lexalytics.com', 'X')] 

>> Dependency Tags are: 
[('  ', 'compound'), ('|', 'npadvmod'), ('  ', 'dep'), ('1', 'npadvmod'), ('-', 'punct'), ('800', 'prep'), ('-', 'punct'), ('377', 'nummod'), ('-', 'punct'), ('8036', 'nummod'), ('|', 'npadvmod'), ('  ', 'ROOT'), ('www.lexalytics.com', 'punct')]

>> Bigrams: 
[[  , |], [|,   ], [  , 1], [1, -], [-, 800], [800, -], [-, 377], [377, -], [-, 8036], [8036, |], [|,   ], [  , www.lexalytics.com]]

>> Trigrams: 
[[  , |,   ], [|,   , 1], [  , 1, -], [1, -, 800], [-, 800, -], [800, -, 377], [-, 377, -], [377, -, 8036], [-, 8036, |], [8036, |,   ], [|,   , www.lexalytics.com]]

>> Noun Phrases are: 
[]

>> Named Entities are: 
[] 


================================ Paragraph 37 =================================

M A C H I N E  L E A R N I N G   I S  R E A L L Y  M A C H I N E  T E A C H I N G  Before we start delving into the different aspects of text analytics, let’s clarify  some basic machine learning concepts.  

------------------- Sentence 1 -------------------

M A C H 


>> Tokens are: 
[M, C, H] 

>> PoS Tags are: 
[('M', 'NOUN'), ('C', 'NOUN'), ('H', 'NOUN')] 

>> Dependency Tags are: 
[('M', 'compound'), ('C', 'compound'), ('H', 'ROOT')]

>> Bigrams: 
[[M, C], [C, H]]

>> Trigrams: 
[[M, C, H]]

>> Noun Phrases are: 
[M A C H]

>> Named Entities are: 
[] 

------------------- Sentence 2 -------------------

I N E  L E 


>> Tokens are: 
[N, E,  , L, E] 

>> PoS Tags are: 
[('N', 'PROPN'), ('E', 'NOUN'), (' ', 'SPACE'), ('L', 'NOUN'), ('E', 'PROPN')] 

>> Dependency Tags are: 
[('N', 'appos'), ('E', 'conj'), (' ', 'appos'), ('L', 'compound'), ('E', 'appos')]

>> Bigrams: 
[[N, E], [E,  ], [ , L], [L, E]]

>> Trigrams: 
[[N, E,  ], [E,  , L], [ , L, E]]

>> Noun Phrases are: 
[I, N, E, L E]

>> Named Entities are: 
[] 

------------------- Sentence 3 -------------------

A R N I N G    


>> Tokens are: 
[R, N, N, G,   ] 

>> PoS Tags are: 
[('R', 'NOUN'), ('N', 'PROPN'), ('N', 'PROPN'), ('G', 'PROPN'), ('  ', 'SPACE')] 

>> Dependency Tags are: 
[('R', 'compound'), ('N', 'compound'), ('N', 'compound'), ('G', 'appos'), ('  ', 'ROOT')]

>> Bigrams: 
[[R, N], [N, N], [N, G], [G,   ]]

>> Trigrams: 
[[R, N, N], [N, N, G], [N, G,   ]]

>> Noun Phrases are: 
[A R N I, N G]

>> Named Entities are: 
[] 

------------------- Sentence 4 -------------------

I 


>> Tokens are: 
[] 

>> PoS Tags are: 
[] 

>> Dependency Tags are: 
[]

>> Bigrams: 
[]

>> Trigrams: 
[]

>> Noun Phrases are: 
[I]

>> Named Entities are: 
[] 

------------------- Sentence 5 -------------------

S   


>> Tokens are: 
[S,  ] 

>> PoS Tags are: 
[('S', 'NOUN'), (' ', 'SPACE')] 

>> Dependency Tags are: 
[('S', 'ROOT'), (' ', 'punct')]

>> Bigrams: 
[[S,  ]]

>> Trigrams: 
[]

>> Noun Phrases are: 
[S]

>> Named Entities are: 
[] 

------------------- Sentence 6 -------------------

R E A L L Y   


>> Tokens are: 
[R, E, L, L, Y,  ] 

>> PoS Tags are: 
[('R', 'NOUN'), ('E', 'NOUN'), ('L', 'PROPN'), ('L', 'PROPN'), ('Y', 'PROPN'), (' ', 'SPACE')] 

>> Dependency Tags are: 
[('R', 'compound'), ('E', 'compound'), ('L', 'compound'), ('L', 'compound'), ('Y', 'ROOT'), (' ', 'punct')]

>> Bigrams: 
[[R, E], [E, L], [L, L], [L, Y], [Y,  ]]

>> Trigrams: 
[[R, E, L], [E, L, L], [L, L, Y], [L, Y,  ]]

>> Noun Phrases are: 
[R E A L L Y]

>> Named Entities are: 
[] 

------------------- Sentence 7 -------------------

M A C H 


>> Tokens are: 
[M, C, H] 

>> PoS Tags are: 
[('M', 'PROPN'), ('C', 'NOUN'), ('H', 'NOUN')] 

>> Dependency Tags are: 
[('M', 'compound'), ('C', 'compound'), ('H', 'ROOT')]

>> Bigrams: 
[[M, C], [C, H]]

>> Trigrams: 
[[M, C, H]]

>> Noun Phrases are: 
[M A C H]

>> Named Entities are: 
[] 

------------------- Sentence 8 -------------------

I N E   


>> Tokens are: 
[N, E,  ] 

>> PoS Tags are: 
[('N', 'PROPN'), ('E', 'NOUN'), (' ', 'SPACE')] 

>> Dependency Tags are: 
[('N', 'appos'), ('E', 'conj'), (' ', 'appos')]

>> Bigrams: 
[[N, E], [E,  ]]

>> Trigrams: 
[[N, E,  ]]

>> Noun Phrases are: 
[I, N, E]

>> Named Entities are: 
[] 

------------------- Sentence 9 -------------------

T E 


>> Tokens are: 
[T, E] 

>> PoS Tags are: 
[('T', 'NOUN'), ('E', 'NOUN')] 

>> Dependency Tags are: 
[('T', 'compound'), ('E', 'ROOT')]

>> Bigrams: 
[[T, E]]

>> Trigrams: 
[]

>> Noun Phrases are: 
[T E]

>> Named Entities are: 
[] 

------------------- Sentence 10 -------------------

A C H 


>> Tokens are: 
[C, H] 

>> PoS Tags are: 
[('C', 'NOUN'), ('H', 'NOUN')] 

>> Dependency Tags are: 
[('C', 'compound'), ('H', 'ROOT')]

>> Bigrams: 
[[C, H]]

>> Trigrams: 
[]

>> Noun Phrases are: 
[A C H]

>> Named Entities are: 
[] 

------------------- Sentence 11 -------------------

I N G  Before we start delving into the different aspects of text analytics, let’s clarify  some basic machine learning concepts. 


>> Tokens are: 
[N, G,  , start, delving, different, aspects, text, analytics, ,, let, clarify,  , basic, machine, learning, concepts, .] 

>> PoS Tags are: 
[('N', 'PROPN'), ('G', 'PROPN'), (' ', 'SPACE'), ('start', 'VERB'), ('delving', 'VERB'), ('different', 'ADJ'), ('aspects', 'NOUN'), ('text', 'NOUN'), ('analytics', 'NOUN'), (',', 'PUNCT'), ('let', 'VERB'), ('clarify', 'VERB'), (' ', 'SPACE'), ('basic', 'ADJ'), ('machine', 'NOUN'), ('learning', 'NOUN'), ('concepts', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('N', 'compound'), ('G', 'appos'), (' ', 'nsubj'), ('start', 'advcl'), ('delving', 'xcomp'), ('different', 'amod'), ('aspects', 'pobj'), ('text', 'compound'), ('analytics', 'pobj'), (',', 'punct'), ('let', 'ROOT'), ('clarify', 'ccomp'), (' ', 'dobj'), ('basic', 'amod'), ('machine', 'compound'), ('learning', 'compound'), ('concepts', 'dobj'), ('.', 'punct')]

>> Bigrams: 
[[N, G], [G,  ], [ , start], [start, delving], [delving, different], [different, aspects], [aspects, text], [text, analytics], [analytics, ,], [,, let], [let, clarify], [clarify,  ], [ , basic], [basic, machine], [machine, learning], [learning, concepts], [concepts, .]]

>> Trigrams: 
[[N, G,  ], [G,  , start], [ , start, delving], [start, delving, different], [delving, different, aspects], [different, aspects, text], [aspects, text, analytics], [text, analytics, ,], [analytics, ,, let], [,, let, clarify], [let, clarify,  ], [clarify,  , basic], [ , basic, machine], [basic, machine, learning], [machine, learning, concepts], [learning, concepts, .]]

>> Noun Phrases are: 
[I, N G, we, the different aspects, text analytics, ’s, some basic machine learning concepts]

>> Named Entities are: 
[('’s', 'GPE')] 

------------------- Sentence 12 -------------------

  


>> Tokens are: 
[ ] 

>> PoS Tags are: 
[(' ', 'SPACE')] 

>> Dependency Tags are: 
[(' ', 'ROOT')]

>> Bigrams: 
[]

>> Trigrams: 
[]

>> Noun Phrases are: 
[]

>> Named Entities are: 
[] 


================================ Paragraph 38 =================================

Most importantly, “machine learning” really means “machine teaching.” We  know what the machine needs to learn, so our task is to create a learning  framework and provide properly-formatted, relevant, clean data that the  machine can learn from. 

------------------- Sentence 1 -------------------

Most importantly, “machine learning” really means “machine teaching.” 


>> Tokens are: 
[importantly, ,, “, machine, learning, ”, means, “, machine, teaching, ., ”] 

>> PoS Tags are: 
[('importantly', 'ADV'), (',', 'PUNCT'), ('“', 'PUNCT'), ('machine', 'NOUN'), ('learning', 'NOUN'), ('”', 'PUNCT'), ('means', 'VERB'), ('“', 'PUNCT'), ('machine', 'NOUN'), ('teaching', 'NOUN'), ('.', 'PUNCT'), ('”', 'PUNCT')] 

>> Dependency Tags are: 
[('importantly', 'advmod'), (',', 'punct'), ('“', 'punct'), ('machine', 'compound'), ('learning', 'nsubj'), ('”', 'punct'), ('means', 'ROOT'), ('“', 'punct'), ('machine', 'compound'), ('teaching', 'dobj'), ('.', 'punct'), ('”', 'punct')]

>> Bigrams: 
[[importantly, ,], [,, “], [“, machine], [machine, learning], [learning, ”], [”, means], [means, “], [“, machine], [machine, teaching], [teaching, .], [., ”]]

>> Trigrams: 
[[importantly, ,, “], [,, “, machine], [“, machine, learning], [machine, learning, ”], [learning, ”, means], [”, means, “], [means, “, machine], [“, machine, teaching], [machine, teaching, .], [teaching, ., ”]]

>> Noun Phrases are: 
[machine learning, machine teaching]

>> Named Entities are: 
[] 

------------------- Sentence 2 -------------------

We  know what the machine needs to learn, so our task is to create a learning  framework and provide properly-formatted, relevant, clean data that the  machine can learn from. 


>> Tokens are: 
[ , know, machine, needs, learn, ,, task, create, learning,  , framework, provide, properly, -, formatted, ,, relevant, ,, clean, data,  , machine, learn, .] 

>> PoS Tags are: 
[(' ', 'SPACE'), ('know', 'VERB'), ('machine', 'NOUN'), ('needs', 'VERB'), ('learn', 'VERB'), (',', 'PUNCT'), ('task', 'NOUN'), ('create', 'VERB'), ('learning', 'NOUN'), (' ', 'SPACE'), ('framework', 'NOUN'), ('provide', 'VERB'), ('properly', 'ADV'), ('-', 'PUNCT'), ('formatted', 'VERB'), (',', 'PUNCT'), ('relevant', 'ADJ'), (',', 'PUNCT'), ('clean', 'ADJ'), ('data', 'NOUN'), (' ', 'SPACE'), ('machine', 'NOUN'), ('learn', 'VERB'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[(' ', 'appos'), ('know', 'ccomp'), ('machine', 'nsubj'), ('needs', 'ccomp'), ('learn', 'xcomp'), (',', 'punct'), ('task', 'nsubj'), ('create', 'xcomp'), ('learning', 'nmod'), (' ', 'punct'), ('framework', 'dobj'), ('provide', 'conj'), ('properly', 'advmod'), ('-', 'punct'), ('formatted', 'amod'), (',', 'punct'), ('relevant', 'amod'), (',', 'punct'), ('clean', 'amod'), ('data', 'dobj'), (' ', 'compound'), ('machine', 'nsubj'), ('learn', 'relcl'), ('.', 'punct')]

>> Bigrams: 
[[ , know], [know, machine], [machine, needs], [needs, learn], [learn, ,], [,, task], [task, create], [create, learning], [learning,  ], [ , framework], [framework, provide], [provide, properly], [properly, -], [-, formatted], [formatted, ,], [,, relevant], [relevant, ,], [,, clean], [clean, data], [data,  ], [ , machine], [machine, learn], [learn, .]]

>> Trigrams: 
[[ , know, machine], [know, machine, needs], [machine, needs, learn], [needs, learn, ,], [learn, ,, task], [,, task, create], [task, create, learning], [create, learning,  ], [learning,  , framework], [ , framework, provide], [framework, provide, properly], [provide, properly, -], [properly, -, formatted], [-, formatted, ,], [formatted, ,, relevant], [,, relevant, ,], [relevant, ,, clean], [,, clean, data], [clean, data,  ], [data,  , machine], [ , machine, learn], [machine, learn, .]]

>> Noun Phrases are: 
[We, what, the machine, our task, a learning  framework, properly-formatted, relevant, clean data, the  machine]

>> Named Entities are: 
[] 


================================ Paragraph 39 =================================

The goal is to create a system where the model continuously improves  at the task you’ve set it. Input is key. Unlike algorithmic programming, a  machine learning model is able to generalize and deal with novel cases. If a  case resembles something the model has seen before, the model can use  this prior “learning” to evaluate the case. 

------------------- Sentence 1 -------------------

The goal is to create a system where the model continuously improves  at the task you’ve set it. 


>> Tokens are: 
[goal, create, system, model, continuously, improves,  , task, set, .] 

>> PoS Tags are: 
[('goal', 'NOUN'), ('create', 'VERB'), ('system', 'NOUN'), ('model', 'NOUN'), ('continuously', 'ADV'), ('improves', 'VERB'), (' ', 'SPACE'), ('task', 'NOUN'), ('set', 'VERB'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('goal', 'nsubj'), ('create', 'xcomp'), ('system', 'dobj'), ('model', 'nsubj'), ('continuously', 'advmod'), ('improves', 'relcl'), (' ', 'dobj'), ('task', 'pobj'), ('set', 'relcl'), ('.', 'punct')]

>> Bigrams: 
[[goal, create], [create, system], [system, model], [model, continuously], [continuously, improves], [improves,  ], [ , task], [task, set], [set, .]]

>> Trigrams: 
[[goal, create, system], [create, system, model], [system, model, continuously], [model, continuously, improves], [continuously, improves,  ], [improves,  , task], [ , task, set], [task, set, .]]

>> Noun Phrases are: 
[The goal, a system, the model, the task, you, it]

>> Named Entities are: 
[] 

------------------- Sentence 2 -------------------

Input is key. 


>> Tokens are: 
[Input, key, .] 

>> PoS Tags are: 
[('Input', 'NOUN'), ('key', 'ADJ'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('Input', 'nsubj'), ('key', 'acomp'), ('.', 'punct')]

>> Bigrams: 
[[Input, key], [key, .]]

>> Trigrams: 
[[Input, key, .]]

>> Noun Phrases are: 
[Input]

>> Named Entities are: 
[] 

------------------- Sentence 3 -------------------

Unlike algorithmic programming, a  machine learning model is able to generalize and deal with novel cases. 


>> Tokens are: 
[Unlike, algorithmic, programming, ,,  , machine, learning, model, able, generalize, deal, novel, cases, .] 

>> PoS Tags are: 
[('Unlike', 'ADP'), ('algorithmic', 'ADJ'), ('programming', 'NOUN'), (',', 'PUNCT'), (' ', 'SPACE'), ('machine', 'NOUN'), ('learning', 'NOUN'), ('model', 'NOUN'), ('able', 'ADJ'), ('generalize', 'VERB'), ('deal', 'VERB'), ('novel', 'ADJ'), ('cases', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('Unlike', 'prep'), ('algorithmic', 'amod'), ('programming', 'pobj'), (',', 'punct'), (' ', 'compound'), ('machine', 'compound'), ('learning', 'compound'), ('model', 'nsubj'), ('able', 'acomp'), ('generalize', 'xcomp'), ('deal', 'conj'), ('novel', 'amod'), ('cases', 'pobj'), ('.', 'punct')]

>> Bigrams: 
[[Unlike, algorithmic], [algorithmic, programming], [programming, ,], [,,  ], [ , machine], [machine, learning], [learning, model], [model, able], [able, generalize], [generalize, deal], [deal, novel], [novel, cases], [cases, .]]

>> Trigrams: 
[[Unlike, algorithmic, programming], [algorithmic, programming, ,], [programming, ,,  ], [,,  , machine], [ , machine, learning], [machine, learning, model], [learning, model, able], [model, able, generalize], [able, generalize, deal], [generalize, deal, novel], [deal, novel, cases], [novel, cases, .]]

>> Noun Phrases are: 
[algorithmic programming, a  machine learning model, novel cases]

>> Named Entities are: 
[] 

------------------- Sentence 4 -------------------

If a  case resembles something the model has seen before, the model can use  this prior “learning” to evaluate the case. 


>> Tokens are: 
[ , case, resembles, model, seen, ,, model, use,  , prior, “, learning, ”, evaluate, case, .] 

>> PoS Tags are: 
[(' ', 'SPACE'), ('case', 'NOUN'), ('resembles', 'VERB'), ('model', 'NOUN'), ('seen', 'VERB'), (',', 'PUNCT'), ('model', 'NOUN'), ('use', 'VERB'), (' ', 'SPACE'), ('prior', 'ADV'), ('“', 'PUNCT'), ('learning', 'NOUN'), ('”', 'PUNCT'), ('evaluate', 'VERB'), ('case', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[(' ', 'compound'), ('case', 'nsubj'), ('resembles', 'advcl'), ('model', 'nsubj'), ('seen', 'relcl'), (',', 'punct'), ('model', 'nsubj'), ('use', 'ROOT'), (' ', 'dobj'), ('prior', 'amod'), ('“', 'punct'), ('learning', 'dobj'), ('”', 'punct'), ('evaluate', 'relcl'), ('case', 'dobj'), ('.', 'punct')]

>> Bigrams: 
[[ , case], [case, resembles], [resembles, model], [model, seen], [seen, ,], [,, model], [model, use], [use,  ], [ , prior], [prior, “], [“, learning], [learning, ”], [”, evaluate], [evaluate, case], [case, .]]

>> Trigrams: 
[[ , case, resembles], [case, resembles, model], [resembles, model, seen], [model, seen, ,], [seen, ,, model], [,, model, use], [model, use,  ], [use,  , prior], [ , prior, “], [prior, “, learning], [“, learning, ”], [learning, ”, evaluate], [”, evaluate, case], [evaluate, case, .]]

>> Noun Phrases are: 
[a  case, something, the model, the model, this prior “learning, the case]

>> Named Entities are: 
[] 


================================ Paragraph 40 =================================

When we talk about a “model,” we’re talking about a mathematical  representation. A machine learning model is the sum of the learning  that has been acquired from the training data. The model changes as  more learning is acquired. 

------------------- Sentence 1 -------------------

When we talk about a “model,” we’re talking about a mathematical  representation. 


>> Tokens are: 
[talk, “, model, ,, ”, talking, mathematical,  , representation, .] 

>> PoS Tags are: 
[('talk', 'VERB'), ('“', 'PUNCT'), ('model', 'NOUN'), (',', 'PUNCT'), ('”', 'PUNCT'), ('talking', 'VERB'), ('mathematical', 'ADJ'), (' ', 'SPACE'), ('representation', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('talk', 'advcl'), ('“', 'punct'), ('model', 'pobj'), (',', 'punct'), ('”', 'punct'), ('talking', 'ROOT'), ('mathematical', 'amod'), (' ', 'compound'), ('representation', 'pobj'), ('.', 'punct')]

>> Bigrams: 
[[talk, “], [“, model], [model, ,], [,, ”], [”, talking], [talking, mathematical], [mathematical,  ], [ , representation], [representation, .]]

>> Trigrams: 
[[talk, “, model], [“, model, ,], [model, ,, ”], [,, ”, talking], [”, talking, mathematical], [talking, mathematical,  ], [mathematical,  , representation], [ , representation, .]]

>> Noun Phrases are: 
[we, a “model, we, a mathematical  representation]

>> Named Entities are: 
[] 

------------------- Sentence 2 -------------------

A machine learning model is the sum of the learning  that has been acquired from the training data. 


>> Tokens are: 
[machine, learning, model, sum, learning,  , acquired, training, data, .] 

>> PoS Tags are: 
[('machine', 'NOUN'), ('learning', 'NOUN'), ('model', 'NOUN'), ('sum', 'NOUN'), ('learning', 'NOUN'), (' ', 'SPACE'), ('acquired', 'VERB'), ('training', 'NOUN'), ('data', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('machine', 'compound'), ('learning', 'compound'), ('model', 'nsubj'), ('sum', 'attr'), ('learning', 'amod'), (' ', 'pobj'), ('acquired', 'relcl'), ('training', 'compound'), ('data', 'pobj'), ('.', 'punct')]

>> Bigrams: 
[[machine, learning], [learning, model], [model, sum], [sum, learning], [learning,  ], [ , acquired], [acquired, training], [training, data], [data, .]]

>> Trigrams: 
[[machine, learning, model], [learning, model, sum], [model, sum, learning], [sum, learning,  ], [learning,  , acquired], [ , acquired, training], [acquired, training, data], [training, data, .]]

>> Noun Phrases are: 
[A machine learning model, the sum, the training data]

>> Named Entities are: 
[] 

------------------- Sentence 3 -------------------

The model changes as  more learning is acquired. 


>> Tokens are: 
[model, changes,  , learning, acquired, .] 

>> PoS Tags are: 
[('model', 'NOUN'), ('changes', 'NOUN'), (' ', 'SPACE'), ('learning', 'NOUN'), ('acquired', 'VERB'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('model', 'compound'), ('changes', 'ROOT'), (' ', 'nsubj'), ('learning', 'nsubjpass'), ('acquired', 'advcl'), ('.', 'punct')]

>> Bigrams: 
[[model, changes], [changes,  ], [ , learning], [learning, acquired], [acquired, .]]

>> Trigrams: 
[[model, changes,  ], [changes,  , learning], [ , learning, acquired], [learning, acquired, .]]

>> Noun Phrases are: 
[The model changes,  more learning]

>> Named Entities are: 
[] 


================================ Paragraph 41 =================================

3 MAJOR PARTS TO MACHINE LEARNING 

------------------- Sentence 1 -------------------

3 MAJOR PARTS TO MACHINE LEARNING 


>> Tokens are: 
[3, MAJOR, PARTS, MACHINE, LEARNING] 

>> PoS Tags are: 
[('3', 'NUM'), ('MAJOR', 'PROPN'), ('PARTS', 'PROPN'), ('MACHINE', 'PROPN'), ('LEARNING', 'NOUN')] 

>> Dependency Tags are: 
[('3', 'nummod'), ('MAJOR', 'compound'), ('PARTS', 'nmod'), ('MACHINE', 'compound'), ('LEARNING', 'ROOT')]

>> Bigrams: 
[[3, MAJOR], [MAJOR, PARTS], [PARTS, MACHINE], [MACHINE, LEARNING]]

>> Trigrams: 
[[3, MAJOR, PARTS], [MAJOR, PARTS, MACHINE], [PARTS, MACHINE, LEARNING]]

>> Noun Phrases are: 
[3 MAJOR PARTS TO MACHINE LEARNING]

>> Named Entities are: 
[('3', 'CARDINAL')] 


================================ Paragraph 42 =================================

 Training data  

------------------- Sentence 1 -------------------

 Training data   


>> Tokens are: 
[ , Training, data,  ] 

>> PoS Tags are: 
[(' ', 'SPACE'), ('Training', 'VERB'), ('data', 'NOUN'), (' ', 'SPACE')] 

>> Dependency Tags are: 
[(' ', 'dep'), ('Training', 'compound'), ('data', 'ROOT'), (' ', 'nummod')]

>> Bigrams: 
[[ , Training], [Training, data], [data,  ]]

>> Trigrams: 
[[ , Training, data], [Training, data,  ]]

>> Noun Phrases are: 
[ Training data]

>> Named Entities are: 
[] 


================================ Paragraph 43 =================================

 Model algorithm  

------------------- Sentence 1 -------------------

  


>> Tokens are: 
[ ] 

>> PoS Tags are: 
[(' ', 'SPACE')] 

>> Dependency Tags are: 
[(' ', 'ROOT')]

>> Bigrams: 
[]

>> Trigrams: 
[]

>> Noun Phrases are: 
[]

>> Named Entities are: 
[] 

------------------- Sentence 2 -------------------

Model algorithm 


>> Tokens are: 
[Model, algorithm] 

>> PoS Tags are: 
[('Model', 'PROPN'), ('algorithm', 'NOUN')] 

>> Dependency Tags are: 
[('Model', 'npadvmod'), ('algorithm', 'ROOT')]

>> Bigrams: 
[[Model, algorithm]]

>> Trigrams: 
[]

>> Noun Phrases are: 
[Model algorithm]

>> Named Entities are: 
[('Model', 'PRODUCT')] 

------------------- Sentence 3 -------------------

  


>> Tokens are: 
[ ] 

>> PoS Tags are: 
[(' ', 'SPACE')] 

>> Dependency Tags are: 
[(' ', 'ROOT')]

>> Bigrams: 
[]

>> Trigrams: 
[]

>> Noun Phrases are: 
[]

>> Named Entities are: 
[] 


================================ Paragraph 44 =================================

 Hyper-parameters 

------------------- Sentence 1 -------------------

 Hyper-parameters 


>> Tokens are: 
[ , Hyper, -, parameters] 

>> PoS Tags are: 
[(' ', 'SPACE'), ('Hyper', 'PROPN'), ('-', 'PUNCT'), ('parameters', 'NOUN')] 

>> Dependency Tags are: 
[(' ', 'nummod'), ('Hyper', 'compound'), ('-', 'punct'), ('parameters', 'ROOT')]

>> Bigrams: 
[[ , Hyper], [Hyper, -], [-, parameters]]

>> Trigrams: 
[[ , Hyper, -], [Hyper, -, parameters]]

>> Noun Phrases are: 
[ Hyper-parameters]

>> Named Entities are: 
[] 


================================ Paragraph 45 =================================

creates a learning framework   

------------------- Sentence 1 -------------------

creates a learning framework    


>> Tokens are: 
[creates, learning, framework,   ] 

>> PoS Tags are: 
[('creates', 'VERB'), ('learning', 'VERB'), ('framework', 'NOUN'), ('  ', 'SPACE')] 

>> Dependency Tags are: 
[('creates', 'ROOT'), ('learning', 'amod'), ('framework', 'dobj'), ('  ', 'npadvmod')]

>> Bigrams: 
[[creates, learning], [learning, framework], [framework,   ]]

>> Trigrams: 
[[creates, learning, framework], [learning, framework,   ]]

>> Noun Phrases are: 
[a learning framework]

>> Named Entities are: 
[] 


================================ Paragraph 46 =================================

and provides data that the  

------------------- Sentence 1 -------------------

and provides data that 


>> Tokens are: 
[provides, data] 

>> PoS Tags are: 
[('provides', 'VERB'), ('data', 'NOUN')] 

>> Dependency Tags are: 
[('provides', 'ROOT'), ('data', 'dobj')]

>> Bigrams: 
[[provides, data]]

>> Trigrams: 
[]

>> Noun Phrases are: 
[data]

>> Named Entities are: 
[] 

------------------- Sentence 2 -------------------

the   


>> Tokens are: 
[ ] 

>> PoS Tags are: 
[(' ', 'SPACE')] 

>> Dependency Tags are: 
[(' ', 'ROOT')]

>> Bigrams: 
[]

>> Trigrams: 
[]

>> Noun Phrases are: 
[]

>> Named Entities are: 
[] 


================================ Paragraph 47 =================================

machine can learn from. 

------------------- Sentence 1 -------------------

machine can learn from. 


>> Tokens are: 
[machine, learn, .] 

>> PoS Tags are: 
[('machine', 'NOUN'), ('learn', 'VERB'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('machine', 'nsubj'), ('learn', 'ROOT'), ('.', 'punct')]

>> Bigrams: 
[[machine, learn], [learn, .]]

>> Trigrams: 
[[machine, learn, .]]

>> Noun Phrases are: 
[machine]

>> Named Entities are: 
[] 


================================ Paragraph 48 =================================

Machine  teaching   

------------------- Sentence 1 -------------------

Machine  teaching    


>> Tokens are: 
[Machine,  , teaching,   ] 

>> PoS Tags are: 
[('Machine', 'NOUN'), (' ', 'SPACE'), ('teaching', 'VERB'), ('  ', 'SPACE')] 

>> Dependency Tags are: 
[('Machine', 'ROOT'), (' ', 'nummod'), ('teaching', 'acl'), ('  ', 'dobj')]

>> Bigrams: 
[[Machine,  ], [ , teaching], [teaching,   ]]

>> Trigrams: 
[[Machine,  , teaching], [ , teaching,   ]]

>> Noun Phrases are: 
[Machine]

>> Named Entities are: 
[] 


================================ Paragraph 49 =================================

(aka learning)

------------------- Sentence 1 -------------------

(aka learning) 


>> Tokens are: 
[(, aka, learning, )] 

>> PoS Tags are: 
[('(', 'PUNCT'), ('aka', 'ADV'), ('learning', 'VERB'), (')', 'PUNCT')] 

>> Dependency Tags are: 
[('(', 'punct'), ('aka', 'advmod'), ('learning', 'ROOT'), (')', 'punct')]

>> Bigrams: 
[[(, aka], [aka, learning], [learning, )]]

>> Trigrams: 
[[(, aka, learning], [aka, learning, )]]

>> Noun Phrases are: 
[]

>> Named Entities are: 
[] 


================================ Paragraph 50 =================================

W H I T E  P A P E R 

------------------- Sentence 1 -------------------

W H 


>> Tokens are: 
[W, H] 

>> PoS Tags are: 
[('W', 'NOUN'), ('H', 'NOUN')] 

>> Dependency Tags are: 
[('W', 'compound'), ('H', 'ROOT')]

>> Bigrams: 
[[W, H]]

>> Trigrams: 
[]

>> Noun Phrases are: 
[W H]

>> Named Entities are: 
[] 

------------------- Sentence 2 -------------------

I T 


>> Tokens are: 
[T] 

>> PoS Tags are: 
[('T', 'NOUN')] 

>> Dependency Tags are: 
[('T', 'appos')]

>> Bigrams: 
[]

>> Trigrams: 
[]

>> Noun Phrases are: 
[I, T]

>> Named Entities are: 
[] 

------------------- Sentence 3 -------------------

E   


>> Tokens are: 
[E,  ] 

>> PoS Tags are: 
[('E', 'NOUN'), (' ', 'SPACE')] 

>> Dependency Tags are: 
[('E', 'ROOT'), (' ', 'appos')]

>> Bigrams: 
[[E,  ]]

>> Trigrams: 
[]

>> Noun Phrases are: 
[E]

>> Named Entities are: 
[] 

------------------- Sentence 4 -------------------

P A P E R 


>> Tokens are: 
[P, P, E, R] 

>> PoS Tags are: 
[('P', 'NOUN'), ('P', 'NOUN'), ('E', 'NOUN'), ('R', 'NOUN')] 

>> Dependency Tags are: 
[('P', 'compound'), ('P', 'compound'), ('E', 'compound'), ('R', 'ROOT')]

>> Bigrams: 
[[P, P], [P, E], [E, R]]

>> Trigrams: 
[[P, P, E], [P, E, R]]

>> Noun Phrases are: 
[P A P E R]

>> Named Entities are: 
[] 


================================ Paragraph 51 =================================

4|       |   Lexalytics, Inc., 48 North Pleasant St. Unit 301, Amherst MA 01002 USA   |   1-800-377-8036 |   www.lexalytics.com 

------------------- Sentence 1 -------------------

4|       |   Lexalytics, Inc., 48 North Pleasant St. Unit 301, Amherst MA 01002 


>> Tokens are: 
[4|,       , |,   , Lexalytics, ,, Inc., ,, 48, North, Pleasant, St., Unit, 301, ,, Amherst, MA, 01002] 

>> PoS Tags are: 
[('4|', 'NUM'), ('      ', 'SPACE'), ('|', 'NOUN'), ('  ', 'SPACE'), ('Lexalytics', 'PROPN'), (',', 'PUNCT'), ('Inc.', 'PROPN'), (',', 'PUNCT'), ('48', 'NUM'), ('North', 'PROPN'), ('Pleasant', 'PROPN'), ('St.', 'PROPN'), ('Unit', 'PROPN'), ('301', 'NUM'), (',', 'PUNCT'), ('Amherst', 'PROPN'), ('MA', 'PROPN'), ('01002', 'NUM')] 

>> Dependency Tags are: 
[('4|', 'nummod'), ('      ', 'compound'), ('|', 'ROOT'), ('  ', 'nmod'), ('Lexalytics', 'nmod'), (',', 'punct'), ('Inc.', 'appos'), (',', 'punct'), ('48', 'nummod'), ('North', 'compound'), ('Pleasant', 'compound'), ('St.', 'compound'), ('Unit', 'appos'), ('301', 'nummod'), (',', 'punct'), ('Amherst', 'compound'), ('MA', 'appos'), ('01002', 'punct')]

>> Bigrams: 
[[4|,       ], [      , |], [|,   ], [  , Lexalytics], [Lexalytics, ,], [,, Inc.], [Inc., ,], [,, 48], [48, North], [North, Pleasant], [Pleasant, St.], [St., Unit], [Unit, 301], [301, ,], [,, Amherst], [Amherst, MA], [MA, 01002]]

>> Trigrams: 
[[4|,       , |], [      , |,   ], [|,   , Lexalytics], [  , Lexalytics, ,], [Lexalytics, ,, Inc.], [,, Inc., ,], [Inc., ,, 48], [,, 48, North], [48, North, Pleasant], [North, Pleasant, St.], [Pleasant, St., Unit], [St., Unit, 301], [Unit, 301, ,], [301, ,, Amherst], [,, Amherst, MA], [Amherst, MA, 01002]]

>> Noun Phrases are: 
[4|       |,   Lexalytics, Inc., 48 North Pleasant St. Unit, Amherst MA]

>> Named Entities are: 
[('4|', 'CARDINAL'), ('Lexalytics, Inc.', 'ORG'), ('48', 'CARDINAL'), ('North Pleasant St. Unit 301', 'ORG'), ('Amherst MA', 'ORG')] 

------------------- Sentence 2 -------------------

USA 


>> Tokens are: 
[USA] 

>> PoS Tags are: 
[('USA', 'PROPN')] 

>> Dependency Tags are: 
[('USA', 'ROOT')]

>> Bigrams: 
[]

>> Trigrams: 
[]

>> Noun Phrases are: 
[USA]

>> Named Entities are: 
[] 

------------------- Sentence 3 -------------------

  |   1-800-377-8036 |   www.lexalytics.com 


>> Tokens are: 
[  , |,   , 1, -, 800, -, 377, -, 8036, |,   , www.lexalytics.com] 

>> PoS Tags are: 
[('  ', 'SPACE'), ('|', 'NOUN'), ('  ', 'SPACE'), ('1', 'NUM'), ('-', 'SYM'), ('800', 'NUM'), ('-', 'NUM'), ('377', 'NUM'), ('-', 'PUNCT'), ('8036', 'NUM'), ('|', 'NOUN'), ('  ', 'SPACE'), ('www.lexalytics.com', 'X')] 

>> Dependency Tags are: 
[('  ', 'compound'), ('|', 'npadvmod'), ('  ', 'dep'), ('1', 'npadvmod'), ('-', 'punct'), ('800', 'prep'), ('-', 'punct'), ('377', 'nummod'), ('-', 'punct'), ('8036', 'nummod'), ('|', 'npadvmod'), ('  ', 'ROOT'), ('www.lexalytics.com', 'punct')]

>> Bigrams: 
[[  , |], [|,   ], [  , 1], [1, -], [-, 800], [800, -], [-, 377], [377, -], [-, 8036], [8036, |], [|,   ], [  , www.lexalytics.com]]

>> Trigrams: 
[[  , |,   ], [|,   , 1], [  , 1, -], [1, -, 800], [-, 800, -], [800, -, 377], [-, 377, -], [377, -, 8036], [-, 8036, |], [8036, |,   ], [|,   , www.lexalytics.com]]

>> Noun Phrases are: 
[]

>> Named Entities are: 
[] 


================================ Paragraph 52 =================================

The output of this system is a machine learning model.  

------------------- Sentence 1 -------------------

The output of this system is a machine learning model. 


>> Tokens are: 
[output, system, machine, learning, model, .] 

>> PoS Tags are: 
[('output', 'NOUN'), ('system', 'NOUN'), ('machine', 'NOUN'), ('learning', 'NOUN'), ('model', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('output', 'nsubj'), ('system', 'pobj'), ('machine', 'compound'), ('learning', 'compound'), ('model', 'attr'), ('.', 'punct')]

>> Bigrams: 
[[output, system], [system, machine], [machine, learning], [learning, model], [model, .]]

>> Trigrams: 
[[output, system, machine], [system, machine, learning], [machine, learning, model], [learning, model, .]]

>> Noun Phrases are: 
[The output, this system, a machine learning model]

>> Named Entities are: 
[] 

------------------- Sentence 2 -------------------

  


>> Tokens are: 
[ ] 

>> PoS Tags are: 
[(' ', 'SPACE')] 

>> Dependency Tags are: 
[(' ', 'ROOT')]

>> Bigrams: 
[]

>> Trigrams: 
[]

>> Noun Phrases are: 
[]

>> Named Entities are: 
[] 


================================ Paragraph 53 =================================

If you were baking a cake: 

------------------- Sentence 1 -------------------

If you were baking a cake: 


>> Tokens are: 
[baking, cake, :] 

>> PoS Tags are: 
[('baking', 'VERB'), ('cake', 'NOUN'), (':', 'PUNCT')] 

>> Dependency Tags are: 
[('baking', 'ROOT'), ('cake', 'dobj'), (':', 'punct')]

>> Bigrams: 
[[baking, cake], [cake, :]]

>> Trigrams: 
[[baking, cake, :]]

>> Noun Phrases are: 
[you, a cake]

>> Named Entities are: 
[] 


================================ Paragraph 54 =================================

• the training data would be the ingredients  • the time and temperature would be the hyper-parameters  • the cake would be the model 

------------------- Sentence 1 -------------------

• the training data would be the ingredients  • the time and temperature would be the hyper-parameters   


>> Tokens are: 
[•, training, data, ingredients,  , •, time, temperature, hyper, -, parameters,  ] 

>> PoS Tags are: 
[('•', 'INTJ'), ('training', 'NOUN'), ('data', 'NOUN'), ('ingredients', 'NOUN'), (' ', 'SPACE'), ('•', 'X'), ('time', 'NOUN'), ('temperature', 'NOUN'), ('hyper', 'NOUN'), ('-', 'NOUN'), ('parameters', 'NOUN'), (' ', 'SPACE')] 

>> Dependency Tags are: 
[('•', 'cc'), ('training', 'compound'), ('data', 'nsubj'), ('ingredients', 'attr'), (' ', 'punct'), ('•', 'dep'), ('time', 'npadvmod'), ('temperature', 'conj'), ('hyper', 'attr'), ('-', 'nsubj'), ('parameters', 'attr'), (' ', 'attr')]

>> Bigrams: 
[[•, training], [training, data], [data, ingredients], [ingredients,  ], [ , •], [•, time], [time, temperature], [temperature, hyper], [hyper, -], [-, parameters], [parameters,  ]]

>> Trigrams: 
[[•, training, data], [training, data, ingredients], [data, ingredients,  ], [ingredients,  , •], [ , •, time], [•, time, temperature], [time, temperature, hyper], [temperature, hyper, -], [hyper, -, parameters], [-, parameters,  ]]

>> Noun Phrases are: 
[the training data, the ingredients, the hyper, -, parameters]

>> Named Entities are: 
[] 

------------------- Sentence 2 -------------------

• the cake 


>> Tokens are: 
[•, cake] 

>> PoS Tags are: 
[('•', 'CCONJ'), ('cake', 'NOUN')] 

>> Dependency Tags are: 
[('•', 'ROOT'), ('cake', 'pobj')]

>> Bigrams: 
[[•, cake]]

>> Trigrams: 
[]

>> Noun Phrases are: 
[the cake]

>> Named Entities are: 
[] 

------------------- Sentence 3 -------------------

would be the model 


>> Tokens are: 
[model] 

>> PoS Tags are: 
[('model', 'NOUN')] 

>> Dependency Tags are: 
[('model', 'attr')]

>> Bigrams: 
[]

>> Trigrams: 
[]

>> Noun Phrases are: 
[the model]

>> Named Entities are: 
[] 


================================ Paragraph 55 =================================

 Lexalytics Hyper-Parameter Optimization Video  |  3:35 

------------------- Sentence 1 -------------------

 Lexalytics Hyper-Parameter Optimization Video  |  3:35 


>> Tokens are: 
[ , Lexalytics, Hyper, -, Parameter, Optimization, Video,  , |,  , 3:35] 

>> PoS Tags are: 
[(' ', 'SPACE'), ('Lexalytics', 'PROPN'), ('Hyper', 'PROPN'), ('-', 'PROPN'), ('Parameter', 'PROPN'), ('Optimization', 'PROPN'), ('Video', 'PROPN'), (' ', 'SPACE'), ('|', 'NOUN'), (' ', 'SPACE'), ('3:35', 'NUM')] 

>> Dependency Tags are: 
[(' ', 'nummod'), ('Lexalytics', 'compound'), ('Hyper', 'compound'), ('-', 'punct'), ('Parameter', 'compound'), ('Optimization', 'compound'), ('Video', 'nsubj'), (' ', 'appos'), ('|', 'appos'), (' ', 'ROOT'), ('3:35', 'npadvmod')]

>> Bigrams: 
[[ , Lexalytics], [Lexalytics, Hyper], [Hyper, -], [-, Parameter], [Parameter, Optimization], [Optimization, Video], [Video,  ], [ , |], [|,  ], [ , 3:35]]

>> Trigrams: 
[[ , Lexalytics, Hyper], [Lexalytics, Hyper, -], [Hyper, -, Parameter], [-, Parameter, Optimization], [Parameter, Optimization, Video], [Optimization, Video,  ], [Video,  , |], [ , |,  ], [|,  , 3:35]]

>> Noun Phrases are: 
[ Lexalytics Hyper-Parameter Optimization Video, |]

>> Named Entities are: 
[('3:35', 'CARDINAL')] 


================================ Paragraph 56 =================================

Once the model is created (baked), we can run it against new data  to evaluate what it’s learned, and whether further adjustments   are needed.  

------------------- Sentence 1 -------------------

Once the model is created (baked), we can run it against new data  to evaluate what it’s learned, and whether further adjustments   are needed. 


>> Tokens are: 
[model, created, (, baked, ), ,, run, new, data,  , evaluate, learned, ,, adjustments,   , needed, .] 

>> PoS Tags are: 
[('model', 'NOUN'), ('created', 'VERB'), ('(', 'PUNCT'), ('baked', 'ADJ'), (')', 'PUNCT'), (',', 'PUNCT'), ('run', 'VERB'), ('new', 'ADJ'), ('data', 'NOUN'), (' ', 'SPACE'), ('evaluate', 'VERB'), ('learned', 'VERB'), (',', 'PUNCT'), ('adjustments', 'NOUN'), ('  ', 'SPACE'), ('needed', 'VERB'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('model', 'nsubjpass'), ('created', 'advcl'), ('(', 'punct'), ('baked', 'parataxis'), (')', 'punct'), (',', 'punct'), ('run', 'ROOT'), ('new', 'amod'), ('data', 'pobj'), (' ', 'nsubj'), ('evaluate', 'relcl'), ('learned', 'ccomp'), (',', 'punct'), ('adjustments', 'nsubjpass'), ('  ', 'nsubjpass'), ('needed', 'conj'), ('.', 'punct')]

>> Bigrams: 
[[model, created], [created, (], [(, baked], [baked, )], [), ,], [,, run], [run, new], [new, data], [data,  ], [ , evaluate], [evaluate, learned], [learned, ,], [,, adjustments], [adjustments,   ], [  , needed], [needed, .]]

>> Trigrams: 
[[model, created, (], [created, (, baked], [(, baked, )], [baked, ), ,], [), ,, run], [,, run, new], [run, new, data], [new, data,  ], [data,  , evaluate], [ , evaluate, learned], [evaluate, learned, ,], [learned, ,, adjustments], [,, adjustments,   ], [adjustments,   , needed], [  , needed, .]]

>> Noun Phrases are: 
[the model, we, it, new data, what, it, further adjustments]

>> Named Entities are: 
[] 

------------------- Sentence 2 -------------------

  


>> Tokens are: 
[ ] 

>> PoS Tags are: 
[(' ', 'SPACE')] 

>> Dependency Tags are: 
[(' ', 'ROOT')]

>> Bigrams: 
[]

>> Trigrams: 
[]

>> Noun Phrases are: 
[]

>> Named Entities are: 
[] 


================================ Paragraph 57 =================================

However, making adjustments isn’t just a matter of writing a line   of code that tells the model what to do. That kind of direct approach is  known as “algorithmic programming” – what most people call “coding.”   With machine learning, we need to convince the model that it wants to do   what we want it to do.  

------------------- Sentence 1 -------------------

However, making adjustments isn’t just a matter of writing a line   of code that tells the model what to do. 


>> Tokens are: 
[,, making, adjustments, matter, writing, line,   , code, tells, model, .] 

>> PoS Tags are: 
[(',', 'PUNCT'), ('making', 'VERB'), ('adjustments', 'NOUN'), ('matter', 'NOUN'), ('writing', 'VERB'), ('line', 'NOUN'), ('  ', 'SPACE'), ('code', 'NOUN'), ('tells', 'VERB'), ('model', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[(',', 'punct'), ('making', 'csubj'), ('adjustments', 'dobj'), ('matter', 'attr'), ('writing', 'pcomp'), ('line', 'compound'), ('  ', 'dobj'), ('code', 'pobj'), ('tells', 'relcl'), ('model', 'dobj'), ('.', 'punct')]

>> Bigrams: 
[[,, making], [making, adjustments], [adjustments, matter], [matter, writing], [writing, line], [line,   ], [  , code], [code, tells], [tells, model], [model, .]]

>> Trigrams: 
[[,, making, adjustments], [making, adjustments, matter], [adjustments, matter, writing], [matter, writing, line], [writing, line,   ], [line,   , code], [  , code, tells], [code, tells, model], [tells, model, .]]

>> Noun Phrases are: 
[adjustments, just a matter, code, the model, what]

>> Named Entities are: 
[] 

------------------- Sentence 2 -------------------

That kind of direct approach is  known as “algorithmic programming” – what most people call “coding.” 


>> Tokens are: 
[kind, direct, approach,  , known, “, algorithmic, programming, ”, –, people, “, coding, ., ”] 

>> PoS Tags are: 
[('kind', 'NOUN'), ('direct', 'ADJ'), ('approach', 'NOUN'), (' ', 'SPACE'), ('known', 'VERB'), ('“', 'PUNCT'), ('algorithmic', 'ADJ'), ('programming', 'NOUN'), ('”', 'PUNCT'), ('–', 'PUNCT'), ('people', 'NOUN'), ('“', 'PUNCT'), ('coding', 'VERB'), ('.', 'PUNCT'), ('”', 'PUNCT')] 

>> Dependency Tags are: 
[('kind', 'nsubjpass'), ('direct', 'amod'), ('approach', 'pobj'), (' ', 'nsubjpass'), ('known', 'ROOT'), ('“', 'punct'), ('algorithmic', 'amod'), ('programming', 'pobj'), ('”', 'punct'), ('–', 'punct'), ('people', 'nsubj'), ('“', 'punct'), ('coding', 'oprd'), ('.', 'punct'), ('”', 'punct')]

>> Bigrams: 
[[kind, direct], [direct, approach], [approach,  ], [ , known], [known, “], [“, algorithmic], [algorithmic, programming], [programming, ”], [”, –], [–, people], [people, “], [“, coding], [coding, .], [., ”]]

>> Trigrams: 
[[kind, direct, approach], [direct, approach,  ], [approach,  , known], [ , known, “], [known, “, algorithmic], [“, algorithmic, programming], [algorithmic, programming, ”], [programming, ”, –], [”, –, people], [–, people, “], [people, “, coding], [“, coding, .], [coding, ., ”]]

>> Noun Phrases are: 
[That kind, direct approach, algorithmic programming, what, most people]

>> Named Entities are: 
[] 

------------------- Sentence 3 -------------------

  With machine learning, we need to convince the model that it wants to do   what we want it to do. 


>> Tokens are: 
[  , machine, learning, ,, need, convince, model, wants,   , want, .] 

>> PoS Tags are: 
[('  ', 'SPACE'), ('machine', 'NOUN'), ('learning', 'NOUN'), (',', 'PUNCT'), ('need', 'VERB'), ('convince', 'VERB'), ('model', 'NOUN'), ('wants', 'VERB'), ('  ', 'SPACE'), ('want', 'VERB'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('  ', 'dep'), ('machine', 'compound'), ('learning', 'pobj'), (',', 'punct'), ('need', 'ROOT'), ('convince', 'xcomp'), ('model', 'dobj'), ('wants', 'relcl'), ('  ', 'dobj'), ('want', 'ccomp'), ('.', 'punct')]

>> Bigrams: 
[[  , machine], [machine, learning], [learning, ,], [,, need], [need, convince], [convince, model], [model, wants], [wants,   ], [  , want], [want, .]]

>> Trigrams: 
[[  , machine, learning], [machine, learning, ,], [learning, ,, need], [,, need, convince], [need, convince, model], [convince, model, wants], [model, wants,   ], [wants,   , want], [  , want, .]]

>> Noun Phrases are: 
[machine learning, we, the model, it, what, we, it]

>> Named Entities are: 
[] 

------------------- Sentence 4 -------------------

  


>> Tokens are: 
[ ] 

>> PoS Tags are: 
[(' ', 'SPACE')] 

>> Dependency Tags are: 
[(' ', 'ROOT')]

>> Bigrams: 
[]

>> Trigrams: 
[]

>> Noun Phrases are: 
[]

>> Named Entities are: 
[] 


================================ Paragraph 58 =================================

Writing a line of code is clearly the more precise, concise approach –   and one that’s going to almost certainly be less work than machine   learning. We talk about this in the white paper “Tune First, Then Train.” 

------------------- Sentence 1 -------------------

Writing a line of code is clearly the more precise, concise approach –   and one that’s going to almost certainly be less work than machine   learning. 


>> Tokens are: 
[Writing, line, code, clearly, precise, ,, concise, approach, –,   , going, certainly, work, machine,   , learning, .] 

>> PoS Tags are: 
[('Writing', 'VERB'), ('line', 'NOUN'), ('code', 'NOUN'), ('clearly', 'ADV'), ('precise', 'ADJ'), (',', 'PUNCT'), ('concise', 'ADJ'), ('approach', 'NOUN'), ('–', 'PUNCT'), ('  ', 'SPACE'), ('going', 'VERB'), ('certainly', 'ADV'), ('work', 'NOUN'), ('machine', 'NOUN'), ('  ', 'SPACE'), ('learning', 'VERB'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('Writing', 'csubj'), ('line', 'dobj'), ('code', 'pobj'), ('clearly', 'advmod'), ('precise', 'amod'), (',', 'punct'), ('concise', 'amod'), ('approach', 'attr'), ('–', 'punct'), ('  ', 'appos'), ('going', 'relcl'), ('certainly', 'advmod'), ('work', 'attr'), ('machine', 'compound'), ('  ', 'nsubj'), ('learning', 'pcomp'), ('.', 'punct')]

>> Bigrams: 
[[Writing, line], [line, code], [code, clearly], [clearly, precise], [precise, ,], [,, concise], [concise, approach], [approach, –], [–,   ], [  , going], [going, certainly], [certainly, work], [work, machine], [machine,   ], [  , learning], [learning, .]]

>> Trigrams: 
[[Writing, line, code], [line, code, clearly], [code, clearly, precise], [clearly, precise, ,], [precise, ,, concise], [,, concise, approach], [concise, approach, –], [approach, –,   ], [–,   , going], [  , going, certainly], [going, certainly, work], [certainly, work, machine], [work, machine,   ], [machine,   , learning], [  , learning, .]]

>> Noun Phrases are: 
[a line, code, the more precise, concise approach, less work]

>> Named Entities are: 
[] 

------------------- Sentence 2 -------------------

We talk about this in the white paper “Tune First, Then Train.” 


>> Tokens are: 
[talk, white, paper, “, Tune, ,, Train, ., ”] 

>> PoS Tags are: 
[('talk', 'VERB'), ('white', 'ADJ'), ('paper', 'NOUN'), ('“', 'PUNCT'), ('Tune', 'PROPN'), (',', 'PUNCT'), ('Train', 'NOUN'), ('.', 'PUNCT'), ('”', 'PUNCT')] 

>> Dependency Tags are: 
[('talk', 'ROOT'), ('white', 'amod'), ('paper', 'pobj'), ('“', 'punct'), ('Tune', 'compound'), (',', 'punct'), ('Train', 'appos'), ('.', 'punct'), ('”', 'punct')]

>> Bigrams: 
[[talk, white], [white, paper], [paper, “], [“, Tune], [Tune, ,], [,, Train], [Train, .], [., ”]]

>> Trigrams: 
[[talk, white, paper], [white, paper, “], [paper, “, Tune], [“, Tune, ,], [Tune, ,, Train], [,, Train, .], [Train, ., ”]]

>> Noun Phrases are: 
[We, the white paper, Tune First, Train]

>> Named Entities are: 
[('Tune First, Then Train', 'WORK_OF_ART')] 


================================ Paragraph 59 =================================

However, coding isn’t always the right solution. Machine learning is   much better than coding at dealing with novel cases and learning   from the experience.  

------------------- Sentence 1 -------------------

However, coding isn’t always the right solution. 


>> Tokens are: 
[,, coding, right, solution, .] 

>> PoS Tags are: 
[(',', 'PUNCT'), ('coding', 'NOUN'), ('right', 'ADJ'), ('solution', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[(',', 'punct'), ('coding', 'nsubj'), ('right', 'amod'), ('solution', 'attr'), ('.', 'punct')]

>> Bigrams: 
[[,, coding], [coding, right], [right, solution], [solution, .]]

>> Trigrams: 
[[,, coding, right], [coding, right, solution], [right, solution, .]]

>> Noun Phrases are: 
[coding, the right solution]

>> Named Entities are: 
[] 

------------------- Sentence 2 -------------------

Machine learning is   much better than coding at dealing with novel cases and learning   from the experience. 


>> Tokens are: 
[Machine, learning,   , better, coding, dealing, novel, cases, learning,   , experience, .] 

>> PoS Tags are: 
[('Machine', 'NOUN'), ('learning', 'NOUN'), ('  ', 'SPACE'), ('better', 'ADJ'), ('coding', 'VERB'), ('dealing', 'VERB'), ('novel', 'ADJ'), ('cases', 'NOUN'), ('learning', 'VERB'), ('  ', 'SPACE'), ('experience', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('Machine', 'compound'), ('learning', 'nsubj'), ('  ', 'attr'), ('better', 'acomp'), ('coding', 'pcomp'), ('dealing', 'pcomp'), ('novel', 'amod'), ('cases', 'pobj'), ('learning', 'conj'), ('  ', 'dobj'), ('experience', 'pobj'), ('.', 'punct')]

>> Bigrams: 
[[Machine, learning], [learning,   ], [  , better], [better, coding], [coding, dealing], [dealing, novel], [novel, cases], [cases, learning], [learning,   ], [  , experience], [experience, .]]

>> Trigrams: 
[[Machine, learning,   ], [learning,   , better], [  , better, coding], [better, coding, dealing], [coding, dealing, novel], [dealing, novel, cases], [novel, cases, learning], [cases, learning,   ], [learning,   , experience], [  , experience, .]]

>> Noun Phrases are: 
[Machine learning, novel cases, the experience]

>> Named Entities are: 
[] 

------------------- Sentence 3 -------------------

  


>> Tokens are: 
[ ] 

>> PoS Tags are: 
[(' ', 'SPACE')] 

>> Dependency Tags are: 
[(' ', 'ROOT')]

>> Bigrams: 
[]

>> Trigrams: 
[]

>> Noun Phrases are: 
[]

>> Named Entities are: 
[] 


================================ Paragraph 60 =================================

In the next section we’ll review the main classes of machine learning. 

------------------- Sentence 1 -------------------

In the next section we’ll review the main classes of machine learning. 


>> Tokens are: 
[section, review, main, classes, machine, learning, .] 

>> PoS Tags are: 
[('section', 'NOUN'), ('review', 'VERB'), ('main', 'ADJ'), ('classes', 'NOUN'), ('machine', 'NOUN'), ('learning', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('section', 'pobj'), ('review', 'ROOT'), ('main', 'amod'), ('classes', 'dobj'), ('machine', 'compound'), ('learning', 'pobj'), ('.', 'punct')]

>> Bigrams: 
[[section, review], [review, main], [main, classes], [classes, machine], [machine, learning], [learning, .]]

>> Trigrams: 
[[section, review, main], [review, main, classes], [main, classes, machine], [classes, machine, learning], [machine, learning, .]]

>> Noun Phrases are: 
[the next section, we, the main classes, machine learning]

>> Named Entities are: 
[] 


================================ Paragraph 61 =================================

is simply a matter of writing   

------------------- Sentence 1 -------------------

is simply a matter of writing    


>> Tokens are: 
[simply, matter, writing,   ] 

>> PoS Tags are: 
[('simply', 'ADV'), ('matter', 'NOUN'), ('writing', 'VERB'), ('  ', 'SPACE')] 

>> Dependency Tags are: 
[('simply', 'advmod'), ('matter', 'attr'), ('writing', 'pcomp'), ('  ', 'dobj')]

>> Bigrams: 
[[simply, matter], [matter, writing], [writing,   ]]

>> Trigrams: 
[[simply, matter, writing], [matter, writing,   ]]

>> Noun Phrases are: 
[a matter]

>> Named Entities are: 
[] 


================================ Paragraph 62 =================================

a line of code that tells the   

------------------- Sentence 1 -------------------

a line of code that tells the    


>> Tokens are: 
[line, code, tells,   ] 

>> PoS Tags are: 
[('line', 'NOUN'), ('code', 'NOUN'), ('tells', 'VERB'), ('  ', 'SPACE')] 

>> Dependency Tags are: 
[('line', 'ROOT'), ('code', 'pobj'), ('tells', 'relcl'), ('  ', 'dobj')]

>> Bigrams: 
[[line, code], [code, tells], [tells,   ]]

>> Trigrams: 
[[line, code, tells], [code, tells,   ]]

>> Noun Phrases are: 
[a line, code]

>> Named Entities are: 
[] 


================================ Paragraph 63 =================================

model what to do. 

------------------- Sentence 1 -------------------

model what to do. 


>> Tokens are: 
[model, .] 

>> PoS Tags are: 
[('model', 'VERB'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('model', 'ROOT'), ('.', 'punct')]

>> Bigrams: 
[[model, .]]

>> Trigrams: 
[]

>> Noun Phrases are: 
[what]

>> Named Entities are: 
[] 


================================ Paragraph 64 =================================

Algorithmic  programming

------------------- Sentence 1 -------------------

Algorithmic  programming 


>> Tokens are: 
[Algorithmic,  , programming] 

>> PoS Tags are: 
[('Algorithmic', 'ADJ'), (' ', 'SPACE'), ('programming', 'NOUN')] 

>> Dependency Tags are: 
[('Algorithmic', 'amod'), (' ', 'compound'), ('programming', 'ROOT')]

>> Bigrams: 
[[Algorithmic,  ], [ , programming]]

>> Trigrams: 
[[Algorithmic,  , programming]]

>> Noun Phrases are: 
[Algorithmic  programming]

>> Named Entities are: 
[] 


================================ Paragraph 65 =================================

W H I T E  P A P E R 

------------------- Sentence 1 -------------------

W H 


>> Tokens are: 
[W, H] 

>> PoS Tags are: 
[('W', 'NOUN'), ('H', 'NOUN')] 

>> Dependency Tags are: 
[('W', 'compound'), ('H', 'ROOT')]

>> Bigrams: 
[[W, H]]

>> Trigrams: 
[]

>> Noun Phrases are: 
[W H]

>> Named Entities are: 
[] 

------------------- Sentence 2 -------------------

I T 


>> Tokens are: 
[T] 

>> PoS Tags are: 
[('T', 'NOUN')] 

>> Dependency Tags are: 
[('T', 'appos')]

>> Bigrams: 
[]

>> Trigrams: 
[]

>> Noun Phrases are: 
[I, T]

>> Named Entities are: 
[] 

------------------- Sentence 3 -------------------

E   


>> Tokens are: 
[E,  ] 

>> PoS Tags are: 
[('E', 'NOUN'), (' ', 'SPACE')] 

>> Dependency Tags are: 
[('E', 'ROOT'), (' ', 'appos')]

>> Bigrams: 
[[E,  ]]

>> Trigrams: 
[]

>> Noun Phrases are: 
[E]

>> Named Entities are: 
[] 

------------------- Sentence 4 -------------------

P A P E R 


>> Tokens are: 
[P, P, E, R] 

>> PoS Tags are: 
[('P', 'NOUN'), ('P', 'NOUN'), ('E', 'NOUN'), ('R', 'NOUN')] 

>> Dependency Tags are: 
[('P', 'compound'), ('P', 'compound'), ('E', 'compound'), ('R', 'ROOT')]

>> Bigrams: 
[[P, P], [P, E], [E, R]]

>> Trigrams: 
[[P, P, E], [P, E, R]]

>> Noun Phrases are: 
[P A P E R]

>> Named Entities are: 
[] 


================================ Paragraph 66 =================================

5|       |   Lexalytics, Inc., 48 North Pleasant St. Unit 301, Amherst MA 01002 USA   |   1-800-377-8036 |   www.lexalytics.com 

------------------- Sentence 1 -------------------

5|       |   Lexalytics, Inc., 48 North Pleasant St. Unit 301, Amherst MA 01002 


>> Tokens are: 
[5|,       , |,   , Lexalytics, ,, Inc., ,, 48, North, Pleasant, St., Unit, 301, ,, Amherst, MA, 01002] 

>> PoS Tags are: 
[('5|', 'NUM'), ('      ', 'SPACE'), ('|', 'NOUN'), ('  ', 'SPACE'), ('Lexalytics', 'PROPN'), (',', 'PUNCT'), ('Inc.', 'PROPN'), (',', 'PUNCT'), ('48', 'NUM'), ('North', 'PROPN'), ('Pleasant', 'PROPN'), ('St.', 'PROPN'), ('Unit', 'PROPN'), ('301', 'NUM'), (',', 'PUNCT'), ('Amherst', 'PROPN'), ('MA', 'PROPN'), ('01002', 'NUM')] 

>> Dependency Tags are: 
[('5|', 'nummod'), ('      ', 'compound'), ('|', 'ROOT'), ('  ', 'nmod'), ('Lexalytics', 'nmod'), (',', 'punct'), ('Inc.', 'appos'), (',', 'punct'), ('48', 'nummod'), ('North', 'compound'), ('Pleasant', 'compound'), ('St.', 'compound'), ('Unit', 'appos'), ('301', 'nummod'), (',', 'punct'), ('Amherst', 'compound'), ('MA', 'appos'), ('01002', 'punct')]

>> Bigrams: 
[[5|,       ], [      , |], [|,   ], [  , Lexalytics], [Lexalytics, ,], [,, Inc.], [Inc., ,], [,, 48], [48, North], [North, Pleasant], [Pleasant, St.], [St., Unit], [Unit, 301], [301, ,], [,, Amherst], [Amherst, MA], [MA, 01002]]

>> Trigrams: 
[[5|,       , |], [      , |,   ], [|,   , Lexalytics], [  , Lexalytics, ,], [Lexalytics, ,, Inc.], [,, Inc., ,], [Inc., ,, 48], [,, 48, North], [48, North, Pleasant], [North, Pleasant, St.], [Pleasant, St., Unit], [St., Unit, 301], [Unit, 301, ,], [301, ,, Amherst], [,, Amherst, MA], [Amherst, MA, 01002]]

>> Noun Phrases are: 
[5|       |,   Lexalytics, Inc., 48 North Pleasant St. Unit, Amherst MA]

>> Named Entities are: 
[('Lexalytics, Inc.', 'ORG'), ('48', 'CARDINAL'), ('North Pleasant St. Unit 301', 'ORG'), ('Amherst MA', 'ORG')] 

------------------- Sentence 2 -------------------

USA 


>> Tokens are: 
[USA] 

>> PoS Tags are: 
[('USA', 'PROPN')] 

>> Dependency Tags are: 
[('USA', 'ROOT')]

>> Bigrams: 
[]

>> Trigrams: 
[]

>> Noun Phrases are: 
[USA]

>> Named Entities are: 
[] 

------------------- Sentence 3 -------------------

  |   1-800-377-8036 |   www.lexalytics.com 


>> Tokens are: 
[  , |,   , 1, -, 800, -, 377, -, 8036, |,   , www.lexalytics.com] 

>> PoS Tags are: 
[('  ', 'SPACE'), ('|', 'NOUN'), ('  ', 'SPACE'), ('1', 'NUM'), ('-', 'SYM'), ('800', 'NUM'), ('-', 'NUM'), ('377', 'NUM'), ('-', 'PUNCT'), ('8036', 'NUM'), ('|', 'NOUN'), ('  ', 'SPACE'), ('www.lexalytics.com', 'X')] 

>> Dependency Tags are: 
[('  ', 'compound'), ('|', 'npadvmod'), ('  ', 'dep'), ('1', 'npadvmod'), ('-', 'punct'), ('800', 'prep'), ('-', 'punct'), ('377', 'nummod'), ('-', 'punct'), ('8036', 'nummod'), ('|', 'npadvmod'), ('  ', 'ROOT'), ('www.lexalytics.com', 'punct')]

>> Bigrams: 
[[  , |], [|,   ], [  , 1], [1, -], [-, 800], [800, -], [-, 377], [377, -], [-, 8036], [8036, |], [|,   ], [  , www.lexalytics.com]]

>> Trigrams: 
[[  , |,   ], [|,   , 1], [  , 1, -], [1, -, 800], [-, 800, -], [800, -, 377], [-, 377, -], [377, -, 8036], [-, 8036, |], [8036, |,   ], [|,   , www.lexalytics.com]]

>> Noun Phrases are: 
[]

>> Named Entities are: 
[] 


================================ Paragraph 67 =================================

means feeding a   

------------------- Sentence 1 -------------------

means feeding a    


>> Tokens are: 
[means, feeding,   ] 

>> PoS Tags are: 
[('means', 'VERB'), ('feeding', 'VERB'), ('  ', 'SPACE')] 

>> Dependency Tags are: 
[('means', 'ROOT'), ('feeding', 'xcomp'), ('  ', 'dobj')]

>> Bigrams: 
[[means, feeding], [feeding,   ]]

>> Trigrams: 
[[means, feeding,   ]]

>> Noun Phrases are: 
[]

>> Named Entities are: 
[] 


================================ Paragraph 68 =================================

machine learning model   

------------------- Sentence 1 -------------------

machine learning model    


>> Tokens are: 
[machine, learning, model,   ] 

>> PoS Tags are: 
[('machine', 'NOUN'), ('learning', 'NOUN'), ('model', 'NOUN'), ('  ', 'SPACE')] 

>> Dependency Tags are: 
[('machine', 'compound'), ('learning', 'compound'), ('model', 'compound'), ('  ', 'ROOT')]

>> Bigrams: 
[[machine, learning], [learning, model], [model,   ]]

>> Trigrams: 
[[machine, learning, model], [learning, model,   ]]

>> Noun Phrases are: 
[]

>> Named Entities are: 
[] 


================================ Paragraph 69 =================================

an annotated dataset. 

------------------- Sentence 1 -------------------

an annotated dataset. 


>> Tokens are: 
[annotated, dataset, .] 

>> PoS Tags are: 
[('annotated', 'ADJ'), ('dataset', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('annotated', 'amod'), ('dataset', 'ROOT'), ('.', 'punct')]

>> Bigrams: 
[[annotated, dataset], [dataset, .]]

>> Trigrams: 
[[annotated, dataset, .]]

>> Noun Phrases are: 
[an annotated dataset]

>> Named Entities are: 
[] 


================================ Paragraph 70 =================================

Supervised  learning 

------------------- Sentence 1 -------------------

Supervised  learning 


>> Tokens are: 
[Supervised,  , learning] 

>> PoS Tags are: 
[('Supervised', 'ADJ'), (' ', 'SPACE'), ('learning', 'VERB')] 

>> Dependency Tags are: 
[('Supervised', 'amod'), (' ', 'prep'), ('learning', 'ROOT')]

>> Bigrams: 
[[Supervised,  ], [ , learning]]

>> Trigrams: 
[[Supervised,  , learning]]

>> Noun Phrases are: 
[]

>> Named Entities are: 
[] 


================================ Paragraph 71 =================================

S U P E R V I S E D ,  U N S U P E R V I S E D ,   A N D  S E M I - S U P E R V I S E D   M A C H I N E  L E A R N I N G  There are three relevant classes of machine learning: supervised learning,  unsupervised learning, and semi-supervised learning. Lexalytics uses all  three depending on the problem we’re trying to solve. 

------------------- Sentence 1 -------------------

S U P E R V I S E D ,  U N S 


>> Tokens are: 
[S, U, P, E, R, V, S, E, D, ,,  , U, N, S] 

>> PoS Tags are: 
[('S', 'NOUN'), ('U', 'NOUN'), ('P', 'NOUN'), ('E', 'NOUN'), ('R', 'NOUN'), ('V', 'NOUN'), ('S', 'PROPN'), ('E', 'NOUN'), ('D', 'PROPN'), (',', 'PUNCT'), (' ', 'SPACE'), ('U', 'NOUN'), ('N', 'PROPN'), ('S', 'PROPN')] 

>> Dependency Tags are: 
[('S', 'compound'), ('U', 'compound'), ('P', 'compound'), ('E', 'compound'), ('R', 'compound'), ('V', 'compound'), ('S', 'compound'), ('E', 'compound'), ('D', 'ROOT'), (',', 'punct'), (' ', 'punct'), ('U', 'compound'), ('N', 'compound'), ('S', 'appos')]

>> Bigrams: 
[[S, U], [U, P], [P, E], [E, R], [R, V], [V, S], [S, E], [E, D], [D, ,], [,,  ], [ , U], [U, N], [N, S]]

>> Trigrams: 
[[S, U, P], [U, P, E], [P, E, R], [E, R, V], [R, V, S], [V, S, E], [S, E, D], [E, D, ,], [D, ,,  ], [,,  , U], [ , U, N], [U, N, S]]

>> Noun Phrases are: 
[S U P E R V I S E D, U N S]

>> Named Entities are: 
[('U N S', 'ORG')] 

------------------- Sentence 2 -------------------

U P E R V I S E D ,   A N D   


>> Tokens are: 
[U, P, E, R, V, S, E, D, ,,   , N, D,  ] 

>> PoS Tags are: 
[('U', 'NOUN'), ('P', 'NOUN'), ('E', 'NOUN'), ('R', 'NOUN'), ('V', 'NOUN'), ('S', 'PROPN'), ('E', 'NOUN'), ('D', 'PROPN'), (',', 'PUNCT'), ('  ', 'SPACE'), ('N', 'PROPN'), ('D', 'PROPN'), (' ', 'SPACE')] 

>> Dependency Tags are: 
[('U', 'compound'), ('P', 'compound'), ('E', 'compound'), ('R', 'compound'), ('V', 'compound'), ('S', 'compound'), ('E', 'compound'), ('D', 'ROOT'), (',', 'punct'), ('  ', 'appos'), ('N', 'nmod'), ('D', 'appos'), (' ', 'punct')]

>> Bigrams: 
[[U, P], [P, E], [E, R], [R, V], [V, S], [S, E], [E, D], [D, ,], [,,   ], [  , N], [N, D], [D,  ]]

>> Trigrams: 
[[U, P, E], [P, E, R], [E, R, V], [R, V, S], [V, S, E], [S, E, D], [E, D, ,], [D, ,,   ], [,,   , N], [  , N, D], [N, D,  ]]

>> Noun Phrases are: 
[U P E R V I S E D, A N D]

>> Named Entities are: 
[] 

------------------- Sentence 3 -------------------

S E M I - S U P E R V 


>> Tokens are: 
[S, E, M, -, S, U, P, E, R, V] 

>> PoS Tags are: 
[('S', 'PROPN'), ('E', 'NOUN'), ('M', 'NOUN'), ('-', 'PUNCT'), ('S', 'PROPN'), ('U', 'NOUN'), ('P', 'NOUN'), ('E', 'NOUN'), ('R', 'NOUN'), ('V', 'NOUN')] 

>> Dependency Tags are: 
[('S', 'compound'), ('E', 'compound'), ('M', 'compound'), ('-', 'punct'), ('S', 'compound'), ('U', 'compound'), ('P', 'compound'), ('E', 'compound'), ('R', 'compound'), ('V', 'ROOT')]

>> Bigrams: 
[[S, E], [E, M], [M, -], [-, S], [S, U], [U, P], [P, E], [E, R], [R, V]]

>> Trigrams: 
[[S, E, M], [E, M, -], [M, -, S], [-, S, U], [S, U, P], [U, P, E], [P, E, R], [E, R, V]]

>> Noun Phrases are: 
[S E M I - S U P E R V]

>> Named Entities are: 
[] 

------------------- Sentence 4 -------------------

I S E D   M A 


>> Tokens are: 
[S, E, D,   , M] 

>> PoS Tags are: 
[('S', 'PROPN'), ('E', 'NOUN'), ('D', 'NOUN'), ('  ', 'SPACE'), ('M', 'NOUN')] 

>> Dependency Tags are: 
[('S', 'compound'), ('E', 'compound'), ('D', 'ROOT'), ('  ', 'compound'), ('M', 'compound')]

>> Bigrams: 
[[S, E], [E, D], [D,   ], [  , M]]

>> Trigrams: 
[[S, E, D], [E, D,   ], [D,   , M]]

>> Noun Phrases are: 
[I S E D,   M A]

>> Named Entities are: 
[] 

------------------- Sentence 5 -------------------

C H 


>> Tokens are: 
[C, H] 

>> PoS Tags are: 
[('C', 'NOUN'), ('H', 'NOUN')] 

>> Dependency Tags are: 
[('C', 'compound'), ('H', 'ROOT')]

>> Bigrams: 
[[C, H]]

>> Trigrams: 
[]

>> Noun Phrases are: 
[C H]

>> Named Entities are: 
[] 

------------------- Sentence 6 -------------------

I N E  L E 


>> Tokens are: 
[N, E,  , L, E] 

>> PoS Tags are: 
[('N', 'PROPN'), ('E', 'NOUN'), (' ', 'SPACE'), ('L', 'NOUN'), ('E', 'PROPN')] 

>> Dependency Tags are: 
[('N', 'appos'), ('E', 'conj'), (' ', 'appos'), ('L', 'compound'), ('E', 'appos')]

>> Bigrams: 
[[N, E], [E,  ], [ , L], [L, E]]

>> Trigrams: 
[[N, E,  ], [E,  , L], [ , L, E]]

>> Noun Phrases are: 
[I, N, E, L E]

>> Named Entities are: 
[] 

------------------- Sentence 7 -------------------

A R N I N G   


>> Tokens are: 
[R, N, N, G,  ] 

>> PoS Tags are: 
[('R', 'NOUN'), ('N', 'PROPN'), ('N', 'PROPN'), ('G', 'PROPN'), (' ', 'SPACE')] 

>> Dependency Tags are: 
[('R', 'compound'), ('N', 'compound'), ('N', 'compound'), ('G', 'appos'), (' ', 'appos')]

>> Bigrams: 
[[R, N], [N, N], [N, G], [G,  ]]

>> Trigrams: 
[[R, N, N], [N, N, G], [N, G,  ]]

>> Noun Phrases are: 
[A R N I, N G]

>> Named Entities are: 
[] 

------------------- Sentence 8 -------------------

There are three relevant classes of machine learning: supervised learning,  unsupervised learning, and semi-supervised learning. 


>> Tokens are: 
[relevant, classes, machine, learning, :, supervised, learning, ,,  , unsupervised, learning, ,, semi, -, supervised, learning, .] 

>> PoS Tags are: 
[('relevant', 'ADJ'), ('classes', 'NOUN'), ('machine', 'NOUN'), ('learning', 'NOUN'), (':', 'PUNCT'), ('supervised', 'ADJ'), ('learning', 'NOUN'), (',', 'PUNCT'), (' ', 'SPACE'), ('unsupervised', 'ADJ'), ('learning', 'NOUN'), (',', 'PUNCT'), ('semi', 'ADJ'), ('-', 'ADJ'), ('supervised', 'ADJ'), ('learning', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('relevant', 'amod'), ('classes', 'attr'), ('machine', 'compound'), ('learning', 'pobj'), (':', 'punct'), ('supervised', 'amod'), ('learning', 'appos'), (',', 'punct'), (' ', 'nmod'), ('unsupervised', 'amod'), ('learning', 'conj'), (',', 'punct'), ('semi', 'amod'), ('-', 'amod'), ('supervised', 'amod'), ('learning', 'conj'), ('.', 'punct')]

>> Bigrams: 
[[relevant, classes], [classes, machine], [machine, learning], [learning, :], [:, supervised], [supervised, learning], [learning, ,], [,,  ], [ , unsupervised], [unsupervised, learning], [learning, ,], [,, semi], [semi, -], [-, supervised], [supervised, learning], [learning, .]]

>> Trigrams: 
[[relevant, classes, machine], [classes, machine, learning], [machine, learning, :], [learning, :, supervised], [:, supervised, learning], [supervised, learning, ,], [learning, ,,  ], [,,  , unsupervised], [ , unsupervised, learning], [unsupervised, learning, ,], [learning, ,, semi], [,, semi, -], [semi, -, supervised], [-, supervised, learning], [supervised, learning, .]]

>> Noun Phrases are: 
[three relevant classes, machine learning, supervised learning,  unsupervised learning, semi-supervised learning]

>> Named Entities are: 
[('three', 'CARDINAL')] 

------------------- Sentence 9 -------------------

Lexalytics uses all  three depending on the problem we’re trying to solve. 


>> Tokens are: 
[Lexalytics, uses,  , depending, problem, trying, solve, .] 

>> PoS Tags are: 
[('Lexalytics', 'NOUN'), ('uses', 'VERB'), (' ', 'SPACE'), ('depending', 'VERB'), ('problem', 'NOUN'), ('trying', 'VERB'), ('solve', 'VERB'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('Lexalytics', 'nsubj'), ('uses', 'ROOT'), (' ', 'dobj'), ('depending', 'xcomp'), ('problem', 'pobj'), ('trying', 'relcl'), ('solve', 'xcomp'), ('.', 'punct')]

>> Bigrams: 
[[Lexalytics, uses], [uses,  ], [ , depending], [depending, problem], [problem, trying], [trying, solve], [solve, .]]

>> Trigrams: 
[[Lexalytics, uses,  ], [uses,  , depending], [ , depending, problem], [depending, problem, trying], [problem, trying, solve], [trying, solve, .]]

>> Noun Phrases are: 
[Lexalytics, the problem, we]

>> Named Entities are: 
[('three', 'CARDINAL')] 


================================ Paragraph 72 =================================

Supervised learning  

------------------- Sentence 1 -------------------

Supervised learning   


>> Tokens are: 
[Supervised, learning,  ] 

>> PoS Tags are: 
[('Supervised', 'ADJ'), ('learning', 'NOUN'), (' ', 'SPACE')] 

>> Dependency Tags are: 
[('Supervised', 'amod'), ('learning', 'compound'), (' ', 'ROOT')]

>> Bigrams: 
[[Supervised, learning], [learning,  ]]

>> Trigrams: 
[[Supervised, learning,  ]]

>> Noun Phrases are: 
[]

>> Named Entities are: 
[] 


================================ Paragraph 73 =================================

Supervised learning means feeding a machine learning model a dataset   that has been annotated in some way. For example, we might collect 10,000  customer support comments and mark them up based on which are  related to software and which are related to hardware. In doing so, we’re  showing the machine what information it needs to evaluate each comment.  

------------------- Sentence 1 -------------------

Supervised learning means feeding a machine learning model a dataset   that has been annotated in some way. 


>> Tokens are: 
[Supervised, learning, means, feeding, machine, learning, model, dataset,   , annotated, way, .] 

>> PoS Tags are: 
[('Supervised', 'ADJ'), ('learning', 'NOUN'), ('means', 'VERB'), ('feeding', 'VERB'), ('machine', 'NOUN'), ('learning', 'NOUN'), ('model', 'NOUN'), ('dataset', 'NOUN'), ('  ', 'SPACE'), ('annotated', 'VERB'), ('way', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('Supervised', 'amod'), ('learning', 'nsubj'), ('means', 'ROOT'), ('feeding', 'xcomp'), ('machine', 'compound'), ('learning', 'compound'), ('model', 'dobj'), ('dataset', 'compound'), ('  ', 'dobj'), ('annotated', 'relcl'), ('way', 'pobj'), ('.', 'punct')]

>> Bigrams: 
[[Supervised, learning], [learning, means], [means, feeding], [feeding, machine], [machine, learning], [learning, model], [model, dataset], [dataset,   ], [  , annotated], [annotated, way], [way, .]]

>> Trigrams: 
[[Supervised, learning, means], [learning, means, feeding], [means, feeding, machine], [feeding, machine, learning], [machine, learning, model], [learning, model, dataset], [model, dataset,   ], [dataset,   , annotated], [  , annotated, way], [annotated, way, .]]

>> Noun Phrases are: 
[Supervised learning, a machine learning model, some way]

>> Named Entities are: 
[] 

------------------- Sentence 2 -------------------

For example, we might collect 10,000  customer support comments and mark them up based on which are  related to software and which are related to hardware. 


>> Tokens are: 
[example, ,, collect, 10,000,  , customer, support, comments, mark, based,  , related, software, related, hardware, .] 

>> PoS Tags are: 
[('example', 'NOUN'), (',', 'PUNCT'), ('collect', 'VERB'), ('10,000', 'NUM'), (' ', 'SPACE'), ('customer', 'NOUN'), ('support', 'NOUN'), ('comments', 'NOUN'), ('mark', 'VERB'), ('based', 'VERB'), (' ', 'SPACE'), ('related', 'VERB'), ('software', 'NOUN'), ('related', 'VERB'), ('hardware', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('example', 'pobj'), (',', 'punct'), ('collect', 'ROOT'), ('10,000', 'nummod'), (' ', 'compound'), ('customer', 'compound'), ('support', 'compound'), ('comments', 'dobj'), ('mark', 'conj'), ('based', 'prep'), (' ', 'nsubjpass'), ('related', 'acomp'), ('software', 'pobj'), ('related', 'conj'), ('hardware', 'pobj'), ('.', 'punct')]

>> Bigrams: 
[[example, ,], [,, collect], [collect, 10,000], [10,000,  ], [ , customer], [customer, support], [support, comments], [comments, mark], [mark, based], [based,  ], [ , related], [related, software], [software, related], [related, hardware], [hardware, .]]

>> Trigrams: 
[[example, ,, collect], [,, collect, 10,000], [collect, 10,000,  ], [10,000,  , customer], [ , customer, support], [customer, support, comments], [support, comments, mark], [comments, mark, based], [mark, based,  ], [based,  , related], [ , related, software], [related, software, related], [software, related, hardware], [related, hardware, .]]

>> Noun Phrases are: 
[example, we, 10,000  customer support comments, them, software, hardware]

>> Named Entities are: 
[('10,000', 'CARDINAL')] 

------------------- Sentence 3 -------------------

In doing so, we’re  showing the machine what information it needs to evaluate each comment.   


>> Tokens are: 
[,,  , showing, machine, information, needs, evaluate, comment, .,  ] 

>> PoS Tags are: 
[(',', 'PUNCT'), (' ', 'SPACE'), ('showing', 'VERB'), ('machine', 'NOUN'), ('information', 'NOUN'), ('needs', 'VERB'), ('evaluate', 'VERB'), ('comment', 'NOUN'), ('.', 'PUNCT'), (' ', 'SPACE')] 

>> Dependency Tags are: 
[(',', 'punct'), (' ', 'dep'), ('showing', 'ROOT'), ('machine', 'dobj'), ('information', 'dobj'), ('needs', 'relcl'), ('evaluate', 'xcomp'), ('comment', 'dobj'), ('.', 'punct'), (' ', 'dobj')]

>> Bigrams: 
[[,,  ], [ , showing], [showing, machine], [machine, information], [information, needs], [needs, evaluate], [evaluate, comment], [comment, .], [.,  ]]

>> Trigrams: 
[[,,  , showing], [ , showing, machine], [showing, machine, information], [machine, information, needs], [information, needs, evaluate], [needs, evaluate, comment], [evaluate, comment, .], [comment, .,  ]]

>> Noun Phrases are: 
[we, the machine, what information, it, each comment]

>> Named Entities are: 
[] 


================================ Paragraph 74 =================================

This is the most direct way of teaching a model what you want it to do. It’s  also the most work. At Lexalytics, we use supervised learning for NLP tasks  like sentiment analysis and for certain methods of categorization.  

------------------- Sentence 1 -------------------

This is the most direct way of teaching a model what you want it to do. 


>> Tokens are: 
[direct, way, teaching, model, want, .] 

>> PoS Tags are: 
[('direct', 'ADJ'), ('way', 'NOUN'), ('teaching', 'VERB'), ('model', 'NOUN'), ('want', 'VERB'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('direct', 'amod'), ('way', 'attr'), ('teaching', 'pcomp'), ('model', 'dobj'), ('want', 'ccomp'), ('.', 'punct')]

>> Bigrams: 
[[direct, way], [way, teaching], [teaching, model], [model, want], [want, .]]

>> Trigrams: 
[[direct, way, teaching], [way, teaching, model], [teaching, model, want], [model, want, .]]

>> Noun Phrases are: 
[the most direct way, a model, what, you, it]

>> Named Entities are: 
[] 

------------------- Sentence 2 -------------------

It’s  also the most work. 


>> Tokens are: 
[ , work, .] 

>> PoS Tags are: 
[(' ', 'SPACE'), ('work', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[(' ', 'attr'), ('work', 'attr'), ('.', 'punct')]

>> Bigrams: 
[[ , work], [work, .]]

>> Trigrams: 
[[ , work, .]]

>> Noun Phrases are: 
[It, also the most work]

>> Named Entities are: 
[] 

------------------- Sentence 3 -------------------

At Lexalytics, we use supervised learning for NLP tasks  like sentiment analysis and for certain methods of categorization.   


>> Tokens are: 
[Lexalytics, ,, use, supervised, learning, NLP, tasks,  , like, sentiment, analysis, certain, methods, categorization, .,  ] 

>> PoS Tags are: 
[('Lexalytics', 'PROPN'), (',', 'PUNCT'), ('use', 'VERB'), ('supervised', 'ADJ'), ('learning', 'NOUN'), ('NLP', 'PROPN'), ('tasks', 'NOUN'), (' ', 'SPACE'), ('like', 'ADP'), ('sentiment', 'NOUN'), ('analysis', 'NOUN'), ('certain', 'ADJ'), ('methods', 'NOUN'), ('categorization', 'NOUN'), ('.', 'PUNCT'), (' ', 'SPACE')] 

>> Dependency Tags are: 
[('Lexalytics', 'pobj'), (',', 'punct'), ('use', 'ROOT'), ('supervised', 'amod'), ('learning', 'dobj'), ('NLP', 'compound'), ('tasks', 'pobj'), (' ', 'dobj'), ('like', 'prep'), ('sentiment', 'compound'), ('analysis', 'pobj'), ('certain', 'amod'), ('methods', 'pobj'), ('categorization', 'pobj'), ('.', 'punct'), (' ', 'dobj')]

>> Bigrams: 
[[Lexalytics, ,], [,, use], [use, supervised], [supervised, learning], [learning, NLP], [NLP, tasks], [tasks,  ], [ , like], [like, sentiment], [sentiment, analysis], [analysis, certain], [certain, methods], [methods, categorization], [categorization, .], [.,  ]]

>> Trigrams: 
[[Lexalytics, ,, use], [,, use, supervised], [use, supervised, learning], [supervised, learning, NLP], [learning, NLP, tasks], [NLP, tasks,  ], [tasks,  , like], [ , like, sentiment], [like, sentiment, analysis], [sentiment, analysis, certain], [analysis, certain, methods], [certain, methods, categorization], [methods, categorization, .], [categorization, .,  ]]

>> Noun Phrases are: 
[Lexalytics, we, supervised learning, NLP tasks, sentiment analysis, certain methods, categorization]

>> Named Entities are: 
[('Lexalytics', 'ORG'), ('NLP', 'ORG')] 


================================ Paragraph 75 =================================

For example, we train sentiment analysis models on hand-scored examples  because the perspective of the sentiment analysis can change based on  context. Consider the following: 

------------------- Sentence 1 -------------------

For example, we train sentiment analysis models on hand-scored examples  because the perspective of the sentiment analysis can change based on  context. 


>> Tokens are: 
[example, ,, train, sentiment, analysis, models, hand, -, scored, examples,  , perspective, sentiment, analysis, change, based,  , context, .] 

>> PoS Tags are: 
[('example', 'NOUN'), (',', 'PUNCT'), ('train', 'VERB'), ('sentiment', 'NOUN'), ('analysis', 'NOUN'), ('models', 'NOUN'), ('hand', 'NOUN'), ('-', 'PUNCT'), ('scored', 'VERB'), ('examples', 'NOUN'), (' ', 'SPACE'), ('perspective', 'NOUN'), ('sentiment', 'NOUN'), ('analysis', 'NOUN'), ('change', 'VERB'), ('based', 'VERB'), (' ', 'SPACE'), ('context', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('example', 'pobj'), (',', 'punct'), ('train', 'ROOT'), ('sentiment', 'compound'), ('analysis', 'compound'), ('models', 'dobj'), ('hand', 'npadvmod'), ('-', 'punct'), ('scored', 'amod'), ('examples', 'pobj'), (' ', 'dobj'), ('perspective', 'nsubj'), ('sentiment', 'compound'), ('analysis', 'pobj'), ('change', 'advcl'), ('based', 'prep'), (' ', 'compound'), ('context', 'pobj'), ('.', 'punct')]

>> Bigrams: 
[[example, ,], [,, train], [train, sentiment], [sentiment, analysis], [analysis, models], [models, hand], [hand, -], [-, scored], [scored, examples], [examples,  ], [ , perspective], [perspective, sentiment], [sentiment, analysis], [analysis, change], [change, based], [based,  ], [ , context], [context, .]]

>> Trigrams: 
[[example, ,, train], [,, train, sentiment], [train, sentiment, analysis], [sentiment, analysis, models], [analysis, models, hand], [models, hand, -], [hand, -, scored], [-, scored, examples], [scored, examples,  ], [examples,  , perspective], [ , perspective, sentiment], [perspective, sentiment, analysis], [sentiment, analysis, change], [analysis, change, based], [change, based,  ], [based,  , context], [ , context, .]]

>> Noun Phrases are: 
[example, we, sentiment analysis models, hand-scored examples, the perspective, the sentiment analysis,  context]

>> Named Entities are: 
[] 

------------------- Sentence 2 -------------------

Consider the following: 


>> Tokens are: 
[Consider, following, :] 

>> PoS Tags are: 
[('Consider', 'VERB'), ('following', 'NOUN'), (':', 'PUNCT')] 

>> Dependency Tags are: 
[('Consider', 'ROOT'), ('following', 'dobj'), (':', 'punct')]

>> Bigrams: 
[[Consider, following], [following, :]]

>> Trigrams: 
[[Consider, following, :]]

>> Noun Phrases are: 
[the following]

>> Named Entities are: 
[] 


================================ Paragraph 76 =================================

“SuperBank lost US$100,000,000 last month.” 

------------------- Sentence 1 -------------------

“ 


>> Tokens are: 
[“] 

>> PoS Tags are: 
[('“', 'PUNCT')] 

>> Dependency Tags are: 
[('“', 'ROOT')]

>> Bigrams: 
[]

>> Trigrams: 
[]

>> Noun Phrases are: 
[]

>> Named Entities are: 
[] 

------------------- Sentence 2 -------------------

SuperBank lost US$100,000,000 last month.” 


>> Tokens are: 
[SuperBank, lost, US$, 100,000,000, month, ., ”] 

>> PoS Tags are: 
[('SuperBank', 'PROPN'), ('lost', 'VERB'), ('US$', 'SYM'), ('100,000,000', 'NUM'), ('month', 'NOUN'), ('.', 'PUNCT'), ('”', 'PUNCT')] 

>> Dependency Tags are: 
[('SuperBank', 'nsubj'), ('lost', 'ROOT'), ('US$', 'nmod'), ('100,000,000', 'dobj'), ('month', 'npadvmod'), ('.', 'punct'), ('”', 'punct')]

>> Bigrams: 
[[SuperBank, lost], [lost, US$], [US$, 100,000,000], [100,000,000, month], [month, .], [., ”]]

>> Trigrams: 
[[SuperBank, lost, US$], [lost, US$, 100,000,000], [US$, 100,000,000, month], [100,000,000, month, .], [month, ., ”]]

>> Noun Phrases are: 
[SuperBank]

>> Named Entities are: 
[('SuperBank', 'ORG'), ('100,000,000', 'MONEY'), ('last month', 'DATE')] 


================================ Paragraph 77 =================================

Well, were they expected to lose US$200,000,000? US$50,000,000? The  sentiment of this statement very much depends on who is looking at it.  

------------------- Sentence 1 -------------------

Well, were they expected to lose US$200,000,000? US$50,000,000? 


>> Tokens are: 
[,, expected, lose, US$, 200,000,000, ?, US$, 50,000,000, ?] 

>> PoS Tags are: 
[(',', 'PUNCT'), ('expected', 'VERB'), ('lose', 'VERB'), ('US$', 'SYM'), ('200,000,000', 'NUM'), ('?', 'PUNCT'), ('US$', 'SYM'), ('50,000,000', 'NUM'), ('?', 'PUNCT')] 

>> Dependency Tags are: 
[(',', 'punct'), ('expected', 'ROOT'), ('lose', 'xcomp'), ('US$', 'nmod'), ('200,000,000', 'dobj'), ('?', 'punct'), ('US$', 'nmod'), ('50,000,000', 'dobj'), ('?', 'punct')]

>> Bigrams: 
[[,, expected], [expected, lose], [lose, US$], [US$, 200,000,000], [200,000,000, ?], [?, US$], [US$, 50,000,000], [50,000,000, ?]]

>> Trigrams: 
[[,, expected, lose], [expected, lose, US$], [lose, US$, 200,000,000], [US$, 200,000,000, ?], [200,000,000, ?, US$], [?, US$, 50,000,000], [US$, 50,000,000, ?]]

>> Noun Phrases are: 
[they]

>> Named Entities are: 
[('US$200,000,000', 'MONEY'), ('50,000,000', 'MONEY')] 

------------------- Sentence 2 -------------------

The  sentiment of this statement very much depends on who is looking at it. 


>> Tokens are: 
[ , sentiment, statement, depends, looking, .] 

>> PoS Tags are: 
[(' ', 'SPACE'), ('sentiment', 'NOUN'), ('statement', 'NOUN'), ('depends', 'VERB'), ('looking', 'VERB'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[(' ', 'compound'), ('sentiment', 'nsubj'), ('statement', 'pobj'), ('depends', 'ROOT'), ('looking', 'pcomp'), ('.', 'punct')]

>> Bigrams: 
[[ , sentiment], [sentiment, statement], [statement, depends], [depends, looking], [looking, .]]

>> Trigrams: 
[[ , sentiment, statement], [sentiment, statement, depends], [statement, depends, looking], [depends, looking, .]]

>> Noun Phrases are: 
[The  sentiment, this statement, who, it]

>> Named Entities are: 
[] 

------------------- Sentence 3 -------------------

  


>> Tokens are: 
[ ] 

>> PoS Tags are: 
[(' ', 'SPACE')] 

>> Dependency Tags are: 
[(' ', 'ROOT')]

>> Bigrams: 
[]

>> Trigrams: 
[]

>> Noun Phrases are: 
[]

>> Named Entities are: 
[] 


================================ Paragraph 78 =================================

Another example would be “This perfume smells like my grandmother.”   Do you love your grandmother?  

------------------- Sentence 1 -------------------

Another example would be “This perfume smells like my grandmother.” 


>> Tokens are: 
[example, “, perfume, smells, like, grandmother, ., ”] 

>> PoS Tags are: 
[('example', 'NOUN'), ('“', 'PUNCT'), ('perfume', 'NOUN'), ('smells', 'VERB'), ('like', 'ADP'), ('grandmother', 'NOUN'), ('.', 'PUNCT'), ('”', 'PUNCT')] 

>> Dependency Tags are: 
[('example', 'nsubj'), ('“', 'punct'), ('perfume', 'nsubj'), ('smells', 'ccomp'), ('like', 'prep'), ('grandmother', 'pobj'), ('.', 'punct'), ('”', 'punct')]

>> Bigrams: 
[[example, “], [“, perfume], [perfume, smells], [smells, like], [like, grandmother], [grandmother, .], [., ”]]

>> Trigrams: 
[[example, “, perfume], [“, perfume, smells], [perfume, smells, like], [smells, like, grandmother], [like, grandmother, .], [grandmother, ., ”]]

>> Noun Phrases are: 
[Another example, This perfume, my grandmother]

>> Named Entities are: 
[] 

------------------- Sentence 2 -------------------

  Do you love your grandmother? 


>> Tokens are: 
[  , love, grandmother, ?] 

>> PoS Tags are: 
[('  ', 'SPACE'), ('love', 'VERB'), ('grandmother', 'NOUN'), ('?', 'PUNCT')] 

>> Dependency Tags are: 
[('  ', 'dep'), ('love', 'ROOT'), ('grandmother', 'dobj'), ('?', 'punct')]

>> Bigrams: 
[[  , love], [love, grandmother], [grandmother, ?]]

>> Trigrams: 
[[  , love, grandmother], [love, grandmother, ?]]

>> Noun Phrases are: 
[you, your grandmother]

>> Named Entities are: 
[] 

------------------- Sentence 3 -------------------

  


>> Tokens are: 
[ ] 

>> PoS Tags are: 
[(' ', 'SPACE')] 

>> Dependency Tags are: 
[(' ', 'ROOT')]

>> Bigrams: 
[]

>> Trigrams: 
[]

>> Noun Phrases are: 
[]

>> Named Entities are: 
[] 


================================ Paragraph 79 =================================

Ultimately, any extraction that requires that the machine understand   your perspective needs to be supervised somehow, and this requires   lots of work.

------------------- Sentence 1 -------------------

Ultimately, any extraction that requires that the machine understand   your perspective needs to be supervised somehow, and this requires   lots of work. 


>> Tokens are: 
[Ultimately, ,, extraction, requires, machine, understand,   , perspective, needs, supervised, ,, requires,   , lots, work, .] 

>> PoS Tags are: 
[('Ultimately', 'ADV'), (',', 'PUNCT'), ('extraction', 'NOUN'), ('requires', 'VERB'), ('machine', 'NOUN'), ('understand', 'VERB'), ('  ', 'SPACE'), ('perspective', 'NOUN'), ('needs', 'VERB'), ('supervised', 'VERB'), (',', 'PUNCT'), ('requires', 'VERB'), ('  ', 'SPACE'), ('lots', 'NOUN'), ('work', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('Ultimately', 'advmod'), (',', 'punct'), ('extraction', 'nsubj'), ('requires', 'relcl'), ('machine', 'nsubj'), ('understand', 'ccomp'), ('  ', 'dobj'), ('perspective', 'nsubj'), ('needs', 'ccomp'), ('supervised', 'xcomp'), (',', 'punct'), ('requires', 'ROOT'), ('  ', 'dobj'), ('lots', 'dobj'), ('work', 'pobj'), ('.', 'punct')]

>> Bigrams: 
[[Ultimately, ,], [,, extraction], [extraction, requires], [requires, machine], [machine, understand], [understand,   ], [  , perspective], [perspective, needs], [needs, supervised], [supervised, ,], [,, requires], [requires,   ], [  , lots], [lots, work], [work, .]]

>> Trigrams: 
[[Ultimately, ,, extraction], [,, extraction, requires], [extraction, requires, machine], [requires, machine, understand], [machine, understand,   ], [understand,   , perspective], [  , perspective, needs], [perspective, needs, supervised], [needs, supervised, ,], [supervised, ,, requires], [,, requires,   ], [requires,   , lots], [  , lots, work], [lots, work, .]]

>> Noun Phrases are: 
[any extraction, the machine, your perspective, lots, work]

>> Named Entities are: 
[] 


================================ Paragraph 80 =================================

W H I T E  P A P E R 

------------------- Sentence 1 -------------------

W H 


>> Tokens are: 
[W, H] 

>> PoS Tags are: 
[('W', 'NOUN'), ('H', 'NOUN')] 

>> Dependency Tags are: 
[('W', 'compound'), ('H', 'ROOT')]

>> Bigrams: 
[[W, H]]

>> Trigrams: 
[]

>> Noun Phrases are: 
[W H]

>> Named Entities are: 
[] 

------------------- Sentence 2 -------------------

I T 


>> Tokens are: 
[T] 

>> PoS Tags are: 
[('T', 'NOUN')] 

>> Dependency Tags are: 
[('T', 'appos')]

>> Bigrams: 
[]

>> Trigrams: 
[]

>> Noun Phrases are: 
[I, T]

>> Named Entities are: 
[] 

------------------- Sentence 3 -------------------

E   


>> Tokens are: 
[E,  ] 

>> PoS Tags are: 
[('E', 'NOUN'), (' ', 'SPACE')] 

>> Dependency Tags are: 
[('E', 'ROOT'), (' ', 'appos')]

>> Bigrams: 
[[E,  ]]

>> Trigrams: 
[]

>> Noun Phrases are: 
[E]

>> Named Entities are: 
[] 

------------------- Sentence 4 -------------------

P A P E R 


>> Tokens are: 
[P, P, E, R] 

>> PoS Tags are: 
[('P', 'NOUN'), ('P', 'NOUN'), ('E', 'NOUN'), ('R', 'NOUN')] 

>> Dependency Tags are: 
[('P', 'compound'), ('P', 'compound'), ('E', 'compound'), ('R', 'ROOT')]

>> Bigrams: 
[[P, P], [P, E], [E, R]]

>> Trigrams: 
[[P, P, E], [P, E, R]]

>> Noun Phrases are: 
[P A P E R]

>> Named Entities are: 
[] 


================================ Paragraph 81 =================================

6|       |   Lexalytics, Inc., 48 North Pleasant St. Unit 301, Amherst MA 01002 USA   |   1-800-377-8036 |   www.lexalytics.com 

------------------- Sentence 1 -------------------

6|       |   Lexalytics, Inc., 48 North Pleasant St. Unit 301, Amherst MA 01002 


>> Tokens are: 
[6|,       , |,   , Lexalytics, ,, Inc., ,, 48, North, Pleasant, St., Unit, 301, ,, Amherst, MA, 01002] 

>> PoS Tags are: 
[('6|', 'NUM'), ('      ', 'SPACE'), ('|', 'NOUN'), ('  ', 'SPACE'), ('Lexalytics', 'PROPN'), (',', 'PUNCT'), ('Inc.', 'PROPN'), (',', 'PUNCT'), ('48', 'NUM'), ('North', 'PROPN'), ('Pleasant', 'PROPN'), ('St.', 'PROPN'), ('Unit', 'PROPN'), ('301', 'NUM'), (',', 'PUNCT'), ('Amherst', 'PROPN'), ('MA', 'PROPN'), ('01002', 'NUM')] 

>> Dependency Tags are: 
[('6|', 'det'), ('      ', 'compound'), ('|', 'ROOT'), ('  ', 'nmod'), ('Lexalytics', 'nmod'), (',', 'punct'), ('Inc.', 'appos'), (',', 'punct'), ('48', 'nummod'), ('North', 'compound'), ('Pleasant', 'compound'), ('St.', 'compound'), ('Unit', 'appos'), ('301', 'nummod'), (',', 'punct'), ('Amherst', 'compound'), ('MA', 'appos'), ('01002', 'punct')]

>> Bigrams: 
[[6|,       ], [      , |], [|,   ], [  , Lexalytics], [Lexalytics, ,], [,, Inc.], [Inc., ,], [,, 48], [48, North], [North, Pleasant], [Pleasant, St.], [St., Unit], [Unit, 301], [301, ,], [,, Amherst], [Amherst, MA], [MA, 01002]]

>> Trigrams: 
[[6|,       , |], [      , |,   ], [|,   , Lexalytics], [  , Lexalytics, ,], [Lexalytics, ,, Inc.], [,, Inc., ,], [Inc., ,, 48], [,, 48, North], [48, North, Pleasant], [North, Pleasant, St.], [Pleasant, St., Unit], [St., Unit, 301], [Unit, 301, ,], [301, ,, Amherst], [,, Amherst, MA], [Amherst, MA, 01002]]

>> Noun Phrases are: 
[6|       |,   Lexalytics, Inc., 48 North Pleasant St. Unit, Amherst MA]

>> Named Entities are: 
[('Lexalytics, Inc.', 'ORG'), ('48', 'CARDINAL'), ('North Pleasant St. Unit 301', 'ORG'), ('Amherst MA', 'ORG')] 

------------------- Sentence 2 -------------------

USA 


>> Tokens are: 
[USA] 

>> PoS Tags are: 
[('USA', 'PROPN')] 

>> Dependency Tags are: 
[('USA', 'ROOT')]

>> Bigrams: 
[]

>> Trigrams: 
[]

>> Noun Phrases are: 
[USA]

>> Named Entities are: 
[] 

------------------- Sentence 3 -------------------

  |   1-800-377-8036 |   www.lexalytics.com 


>> Tokens are: 
[  , |,   , 1, -, 800, -, 377, -, 8036, |,   , www.lexalytics.com] 

>> PoS Tags are: 
[('  ', 'SPACE'), ('|', 'NOUN'), ('  ', 'SPACE'), ('1', 'NUM'), ('-', 'SYM'), ('800', 'NUM'), ('-', 'NUM'), ('377', 'NUM'), ('-', 'PUNCT'), ('8036', 'NUM'), ('|', 'NOUN'), ('  ', 'SPACE'), ('www.lexalytics.com', 'X')] 

>> Dependency Tags are: 
[('  ', 'compound'), ('|', 'npadvmod'), ('  ', 'dep'), ('1', 'npadvmod'), ('-', 'punct'), ('800', 'prep'), ('-', 'punct'), ('377', 'nummod'), ('-', 'punct'), ('8036', 'nummod'), ('|', 'npadvmod'), ('  ', 'ROOT'), ('www.lexalytics.com', 'punct')]

>> Bigrams: 
[[  , |], [|,   ], [  , 1], [1, -], [-, 800], [800, -], [-, 377], [377, -], [-, 8036], [8036, |], [|,   ], [  , www.lexalytics.com]]

>> Trigrams: 
[[  , |,   ], [|,   , 1], [  , 1, -], [1, -, 800], [-, 800, -], [800, -, 377], [-, 377, -], [377, -, 8036], [-, 8036, |], [8036, |,   ], [|,   , www.lexalytics.com]]

>> Noun Phrases are: 
[]

>> Named Entities are: 
[] 


================================ Paragraph 82 =================================

Unsupervised learning 

------------------- Sentence 1 -------------------

Unsupervised learning 


>> Tokens are: 
[Unsupervised, learning] 

>> PoS Tags are: 
[('Unsupervised', 'PROPN'), ('learning', 'NOUN')] 

>> Dependency Tags are: 
[('Unsupervised', 'amod'), ('learning', 'ROOT')]

>> Bigrams: 
[[Unsupervised, learning]]

>> Trigrams: 
[]

>> Noun Phrases are: 
[Unsupervised learning]

>> Named Entities are: 
[] 


================================ Paragraph 83 =================================

Unsupervised learning is where we hand the machine a whole bunch  of content and tell it to find the patterns. This is how we built the syntax parser in Salience: We took 40GB of text and had the parser analyze every  sentence to understand how subjects and verbs fit together. Consider   the following:  

------------------- Sentence 1 -------------------

Unsupervised learning is where we hand the machine a whole bunch  of content and tell it to find the patterns. 


>> Tokens are: 
[Unsupervised, learning, hand, machine, bunch,  , content, tell, find, patterns, .] 

>> PoS Tags are: 
[('Unsupervised', 'PROPN'), ('learning', 'NOUN'), ('hand', 'VERB'), ('machine', 'NOUN'), ('bunch', 'NOUN'), (' ', 'SPACE'), ('content', 'NOUN'), ('tell', 'VERB'), ('find', 'VERB'), ('patterns', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('Unsupervised', 'compound'), ('learning', 'nsubj'), ('hand', 'advcl'), ('machine', 'dobj'), ('bunch', 'dobj'), (' ', 'appos'), ('content', 'pobj'), ('tell', 'conj'), ('find', 'xcomp'), ('patterns', 'dobj'), ('.', 'punct')]

>> Bigrams: 
[[Unsupervised, learning], [learning, hand], [hand, machine], [machine, bunch], [bunch,  ], [ , content], [content, tell], [tell, find], [find, patterns], [patterns, .]]

>> Trigrams: 
[[Unsupervised, learning, hand], [learning, hand, machine], [hand, machine, bunch], [machine, bunch,  ], [bunch,  , content], [ , content, tell], [content, tell, find], [tell, find, patterns], [find, patterns, .]]

>> Noun Phrases are: 
[Unsupervised learning, we, the machine, a whole bunch, content, it, the patterns]

>> Named Entities are: 
[] 

------------------- Sentence 2 -------------------

This is how we built the syntax parser in Salience: We took 40GB of text and had the parser analyze every  sentence to understand how subjects and verbs fit together. 


>> Tokens are: 
[built, syntax, parser, Salience, :, took, 40, GB, text, parser, analyze,  , sentence, understand, subjects, verbs, fit, .] 

>> PoS Tags are: 
[('built', 'VERB'), ('syntax', 'NOUN'), ('parser', 'NOUN'), ('Salience', 'PROPN'), (':', 'PUNCT'), ('took', 'VERB'), ('40', 'NUM'), ('GB', 'PROPN'), ('text', 'NOUN'), ('parser', 'NOUN'), ('analyze', 'VERB'), (' ', 'SPACE'), ('sentence', 'NOUN'), ('understand', 'VERB'), ('subjects', 'NOUN'), ('verbs', 'NOUN'), ('fit', 'VERB'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('built', 'ccomp'), ('syntax', 'compound'), ('parser', 'dobj'), ('Salience', 'pobj'), (':', 'punct'), ('took', 'ROOT'), ('40', 'nummod'), ('GB', 'dobj'), ('text', 'pobj'), ('parser', 'nsubj'), ('analyze', 'ccomp'), (' ', 'compound'), ('sentence', 'nsubj'), ('understand', 'ccomp'), ('subjects', 'nsubj'), ('verbs', 'conj'), ('fit', 'ccomp'), ('.', 'punct')]

>> Bigrams: 
[[built, syntax], [syntax, parser], [parser, Salience], [Salience, :], [:, took], [took, 40], [40, GB], [GB, text], [text, parser], [parser, analyze], [analyze,  ], [ , sentence], [sentence, understand], [understand, subjects], [subjects, verbs], [verbs, fit], [fit, .]]

>> Trigrams: 
[[built, syntax, parser], [syntax, parser, Salience], [parser, Salience, :], [Salience, :, took], [:, took, 40], [took, 40, GB], [40, GB, text], [GB, text, parser], [text, parser, analyze], [parser, analyze,  ], [analyze,  , sentence], [ , sentence, understand], [sentence, understand, subjects], [understand, subjects, verbs], [subjects, verbs, fit], [verbs, fit, .]]

>> Noun Phrases are: 
[we, the syntax parser, Salience, We, 40GB, text, the parser, every  sentence, subjects, verbs]

>> Named Entities are: 
[('Salience', 'PERSON')] 

------------------- Sentence 3 -------------------

Consider   the following: 


>> Tokens are: 
[Consider,   , following, :] 

>> PoS Tags are: 
[('Consider', 'VERB'), ('  ', 'SPACE'), ('following', 'VERB'), (':', 'PUNCT')] 

>> Dependency Tags are: 
[('Consider', 'ROOT'), ('  ', 'dobj'), ('following', 'dobj'), (':', 'punct')]

>> Bigrams: 
[[Consider,   ], [  , following], [following, :]]

>> Trigrams: 
[[Consider,   , following], [  , following, :]]

>> Noun Phrases are: 
[]

>> Named Entities are: 
[] 

------------------- Sentence 4 -------------------

  


>> Tokens are: 
[ ] 

>> PoS Tags are: 
[(' ', 'SPACE')] 

>> Dependency Tags are: 
[(' ', 'ROOT')]

>> Bigrams: 
[]

>> Trigrams: 
[]

>> Noun Phrases are: 
[]

>> Named Entities are: 
[] 


================================ Paragraph 84 =================================

“I threw the ball over the mountain.” 

------------------- Sentence 1 -------------------

“ 


>> Tokens are: 
[“] 

>> PoS Tags are: 
[('“', 'PUNCT')] 

>> Dependency Tags are: 
[('“', 'ROOT')]

>> Bigrams: 
[]

>> Trigrams: 
[]

>> Noun Phrases are: 
[]

>> Named Entities are: 
[] 

------------------- Sentence 2 -------------------

I threw the ball over the mountain.” 


>> Tokens are: 
[threw, ball, mountain, ., ”] 

>> PoS Tags are: 
[('threw', 'VERB'), ('ball', 'NOUN'), ('mountain', 'NOUN'), ('.', 'PUNCT'), ('”', 'PUNCT')] 

>> Dependency Tags are: 
[('threw', 'ROOT'), ('ball', 'dobj'), ('mountain', 'pobj'), ('.', 'punct'), ('”', 'punct')]

>> Bigrams: 
[[threw, ball], [ball, mountain], [mountain, .], [., ”]]

>> Trigrams: 
[[threw, ball, mountain], [ball, mountain, .], [mountain, ., ”]]

>> Noun Phrases are: 
[I, the ball, the mountain]

>> Named Entities are: 
[] 


================================ Paragraph 85 =================================

One way to understand syntax is to parse the entire sentence, like   you’re doing a sentence diagram from 6th grade. Those are quite  computationally intensive (along with being irritating for 6th graders),   and so you can’t do that for high-volume content – it just takes too long  for each document to process. 

------------------- Sentence 1 -------------------

One way to understand syntax is to parse the entire sentence, like   you’re doing a sentence diagram from 6th grade. 


>> Tokens are: 
[way, understand, syntax, parse, entire, sentence, ,, like,   , sentence, diagram, 6th, grade, .] 

>> PoS Tags are: 
[('way', 'NOUN'), ('understand', 'VERB'), ('syntax', 'NOUN'), ('parse', 'VERB'), ('entire', 'ADJ'), ('sentence', 'NOUN'), (',', 'PUNCT'), ('like', 'ADP'), ('  ', 'SPACE'), ('sentence', 'NOUN'), ('diagram', 'NOUN'), ('6th', 'ADJ'), ('grade', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('way', 'nsubj'), ('understand', 'relcl'), ('syntax', 'dobj'), ('parse', 'xcomp'), ('entire', 'amod'), ('sentence', 'dobj'), (',', 'punct'), ('like', 'prep'), ('  ', 'pobj'), ('sentence', 'compound'), ('diagram', 'dobj'), ('6th', 'amod'), ('grade', 'pobj'), ('.', 'punct')]

>> Bigrams: 
[[way, understand], [understand, syntax], [syntax, parse], [parse, entire], [entire, sentence], [sentence, ,], [,, like], [like,   ], [  , sentence], [sentence, diagram], [diagram, 6th], [6th, grade], [grade, .]]

>> Trigrams: 
[[way, understand, syntax], [understand, syntax, parse], [syntax, parse, entire], [parse, entire, sentence], [entire, sentence, ,], [sentence, ,, like], [,, like,   ], [like,   , sentence], [  , sentence, diagram], [sentence, diagram, 6th], [diagram, 6th, grade], [6th, grade, .]]

>> Noun Phrases are: 
[One way, syntax, the entire sentence, you, a sentence diagram, 6th grade]

>> Named Entities are: 
[('One', 'CARDINAL'), ('6th', 'ORDINAL')] 

------------------- Sentence 2 -------------------

Those are quite  computationally intensive (along with being irritating for 6th graders),    


>> Tokens are: 
[ , computationally, intensive, (, irritating, 6th, graders, ), ,,   ] 

>> PoS Tags are: 
[(' ', 'SPACE'), ('computationally', 'ADV'), ('intensive', 'ADJ'), ('(', 'PUNCT'), ('irritating', 'VERB'), ('6th', 'ADJ'), ('graders', 'NOUN'), (')', 'PUNCT'), (',', 'PUNCT'), ('  ', 'SPACE')] 

>> Dependency Tags are: 
[(' ', 'attr'), ('computationally', 'advmod'), ('intensive', 'amod'), ('(', 'punct'), ('irritating', 'pcomp'), ('6th', 'amod'), ('graders', 'pobj'), (')', 'punct'), (',', 'punct'), ('  ', 'appos')]

>> Bigrams: 
[[ , computationally], [computationally, intensive], [intensive, (], [(, irritating], [irritating, 6th], [6th, graders], [graders, )], [), ,], [,,   ]]

>> Trigrams: 
[[ , computationally, intensive], [computationally, intensive, (], [intensive, (, irritating], [(, irritating, 6th], [irritating, 6th, graders], [6th, graders, )], [graders, ), ,], [), ,,   ]]

>> Noun Phrases are: 
[6th graders]

>> Named Entities are: 
[('6th', 'ORDINAL')] 

------------------- Sentence 3 -------------------

and so you can’t do that for high-volume content – it just takes too long  for each document to process. 


>> Tokens are: 
[high, -, volume, content, –, takes, long,  , document, process, .] 

>> PoS Tags are: 
[('high', 'ADJ'), ('-', 'PUNCT'), ('volume', 'NOUN'), ('content', 'NOUN'), ('–', 'PUNCT'), ('takes', 'VERB'), ('long', 'ADJ'), (' ', 'SPACE'), ('document', 'NOUN'), ('process', 'VERB'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('high', 'amod'), ('-', 'punct'), ('volume', 'compound'), ('content', 'pobj'), ('–', 'punct'), ('takes', 'ROOT'), ('long', 'amod'), (' ', 'dobj'), ('document', 'pobj'), ('process', 'xcomp'), ('.', 'punct')]

>> Bigrams: 
[[high, -], [-, volume], [volume, content], [content, –], [–, takes], [takes, long], [long,  ], [ , document], [document, process], [process, .]]

>> Trigrams: 
[[high, -, volume], [-, volume, content], [volume, content, –], [content, –, takes], [–, takes, long], [takes, long,  ], [long,  , document], [ , document, process], [document, process, .]]

>> Noun Phrases are: 
[you, high-volume content, it, each document]

>> Named Entities are: 
[] 


================================ Paragraph 86 =================================

But what if you were to process a bunch of content ahead of time to  come up with a set of relationships that shows how words like “ball,”  “threw” and “mountain” were typically related across millions and billions of  sentences.  

------------------- Sentence 1 -------------------

But what if you were to process a bunch of content ahead of time to  come up with a set of relationships that shows how words like “ball,”  “threw” and “mountain” were typically related across millions and billions of  sentences. 


>> Tokens are: 
[process, bunch, content, ahead, time,  , come, set, relationships, shows, words, like, “, ball, ,, ”,  , “, threw, ”, “, mountain, ”, typically, related, millions, billions,  , sentences, .] 

>> PoS Tags are: 
[('process', 'VERB'), ('bunch', 'NOUN'), ('content', 'NOUN'), ('ahead', 'ADV'), ('time', 'NOUN'), (' ', 'SPACE'), ('come', 'VERB'), ('set', 'NOUN'), ('relationships', 'NOUN'), ('shows', 'VERB'), ('words', 'NOUN'), ('like', 'ADP'), ('“', 'PUNCT'), ('ball', 'NOUN'), (',', 'PUNCT'), ('”', 'PUNCT'), (' ', 'SPACE'), ('“', 'PUNCT'), ('threw', 'VERB'), ('”', 'PUNCT'), ('“', 'PUNCT'), ('mountain', 'NOUN'), ('”', 'PUNCT'), ('typically', 'ADV'), ('related', 'VERB'), ('millions', 'NOUN'), ('billions', 'NOUN'), (' ', 'SPACE'), ('sentences', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('process', 'xcomp'), ('bunch', 'dobj'), ('content', 'pobj'), ('ahead', 'advmod'), ('time', 'pobj'), (' ', 'pobj'), ('come', 'advcl'), ('set', 'pobj'), ('relationships', 'pobj'), ('shows', 'relcl'), ('words', 'nsubj'), ('like', 'prep'), ('“', 'punct'), ('ball', 'pobj'), (',', 'punct'), ('”', 'punct'), (' ', 'appos'), ('“', 'punct'), ('threw', 'ccomp'), ('”', 'punct'), ('“', 'punct'), ('mountain', 'conj'), ('”', 'punct'), ('typically', 'advmod'), ('related', 'ROOT'), ('millions', 'pobj'), ('billions', 'conj'), (' ', 'compound'), ('sentences', 'pobj'), ('.', 'punct')]

>> Bigrams: 
[[process, bunch], [bunch, content], [content, ahead], [ahead, time], [time,  ], [ , come], [come, set], [set, relationships], [relationships, shows], [shows, words], [words, like], [like, “], [“, ball], [ball, ,], [,, ”], [”,  ], [ , “], [“, threw], [threw, ”], [”, “], [“, mountain], [mountain, ”], [”, typically], [typically, related], [related, millions], [millions, billions], [billions,  ], [ , sentences], [sentences, .]]

>> Trigrams: 
[[process, bunch, content], [bunch, content, ahead], [content, ahead, time], [ahead, time,  ], [time,  , come], [ , come, set], [come, set, relationships], [set, relationships, shows], [relationships, shows, words], [shows, words, like], [words, like, “], [like, “, ball], [“, ball, ,], [ball, ,, ”], [,, ”,  ], [”,  , “], [ , “, threw], [“, threw, ”], [threw, ”, “], [”, “, mountain], [“, mountain, ”], [mountain, ”, typically], [”, typically, related], [typically, related, millions], [related, millions, billions], [millions, billions,  ], [billions,  , sentences], [ , sentences, .]]

>> Noun Phrases are: 
[you, a bunch, content, time, a set, relationships, words, “ball, millions, billions,  sentences]

>> Named Entities are: 
[('millions and billions', 'MONEY')] 

------------------- Sentence 2 -------------------

  


>> Tokens are: 
[ ] 

>> PoS Tags are: 
[(' ', 'SPACE')] 

>> Dependency Tags are: 
[(' ', 'ROOT')]

>> Bigrams: 
[]

>> Trigrams: 
[]

>> Noun Phrases are: 
[]

>> Named Entities are: 
[] 


================================ Paragraph 87 =================================

As a human, you naturally know that it is far more likely that “threw”   is acting on “ball,” than it is likely that “threw” is acting on “mountain.”  You don’t throw mountains, you throw balls. 

------------------- Sentence 1 -------------------

As a human, you naturally know that it is far more likely that “threw”   is acting on “ball,” than it is likely that “threw” is acting on “mountain.” 


>> Tokens are: 
[human, ,, naturally, know, far, likely, “, threw, ”,   , acting, “, ball, ,, ”, likely, “, threw, ”, acting, “, mountain, ., ”] 

>> PoS Tags are: 
[('human', 'NOUN'), (',', 'PUNCT'), ('naturally', 'ADV'), ('know', 'VERB'), ('far', 'ADV'), ('likely', 'ADJ'), ('“', 'PUNCT'), ('threw', 'VERB'), ('”', 'PUNCT'), ('  ', 'SPACE'), ('acting', 'VERB'), ('“', 'PUNCT'), ('ball', 'NOUN'), (',', 'PUNCT'), ('”', 'PUNCT'), ('likely', 'ADJ'), ('“', 'PUNCT'), ('threw', 'VERB'), ('”', 'PUNCT'), ('acting', 'VERB'), ('“', 'PUNCT'), ('mountain', 'NOUN'), ('.', 'PUNCT'), ('”', 'PUNCT')] 

>> Dependency Tags are: 
[('human', 'pobj'), (',', 'punct'), ('naturally', 'advmod'), ('know', 'ROOT'), ('far', 'advmod'), ('likely', 'acomp'), ('“', 'punct'), ('threw', 'nsubj'), ('”', 'punct'), ('  ', 'dobj'), ('acting', 'ccomp'), ('“', 'punct'), ('ball', 'pobj'), (',', 'punct'), ('”', 'punct'), ('likely', 'acomp'), ('“', 'punct'), ('threw', 'nsubj'), ('”', 'punct'), ('acting', 'ccomp'), ('“', 'punct'), ('mountain', 'pobj'), ('.', 'punct'), ('”', 'punct')]

>> Bigrams: 
[[human, ,], [,, naturally], [naturally, know], [know, far], [far, likely], [likely, “], [“, threw], [threw, ”], [”,   ], [  , acting], [acting, “], [“, ball], [ball, ,], [,, ”], [”, likely], [likely, “], [“, threw], [threw, ”], [”, acting], [acting, “], [“, mountain], [mountain, .], [., ”]]

>> Trigrams: 
[[human, ,, naturally], [,, naturally, know], [naturally, know, far], [know, far, likely], [far, likely, “], [likely, “, threw], [“, threw, ”], [threw, ”,   ], [”,   , acting], [  , acting, “], [acting, “, ball], [“, ball, ,], [ball, ,, ”], [,, ”, likely], [”, likely, “], [likely, “, threw], [“, threw, ”], [threw, ”, acting], [”, acting, “], [acting, “, mountain], [“, mountain, .], [mountain, ., ”]]

>> Noun Phrases are: 
[a human, you, it, ball, it, mountain]

>> Named Entities are: 
[] 

------------------- Sentence 2 -------------------

  


>> Tokens are: 
[ ] 

>> PoS Tags are: 
[(' ', 'SPACE')] 

>> Dependency Tags are: 
[(' ', 'ROOT')]

>> Bigrams: 
[]

>> Trigrams: 
[]

>> Noun Phrases are: 
[]

>> Named Entities are: 
[] 

------------------- Sentence 3 -------------------

You don’t throw mountains, you throw balls. 


>> Tokens are: 
[throw, mountains, ,, throw, balls, .] 

>> PoS Tags are: 
[('throw', 'VERB'), ('mountains', 'NOUN'), (',', 'PUNCT'), ('throw', 'VERB'), ('balls', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('throw', 'ccomp'), ('mountains', 'dobj'), (',', 'punct'), ('throw', 'ROOT'), ('balls', 'dobj'), ('.', 'punct')]

>> Bigrams: 
[[throw, mountains], [mountains, ,], [,, throw], [throw, balls], [balls, .]]

>> Trigrams: 
[[throw, mountains, ,], [mountains, ,, throw], [,, throw, balls], [throw, balls, .]]

>> Noun Phrases are: 
[You, mountains, you, balls]

>> Named Entities are: 
[] 


================================ Paragraph 88 =================================

That sort of probabilistic relationship can be extracted using unsupervised  learning. The syntax matrix was an excellent candidate for unsupervised  learning, as it involved discovering generally applicable patterns from a very  large corpus of content. Because it is a matrix, it can be evaluated really fast  for each sentence, unlike a full parser. 

------------------- Sentence 1 -------------------

That sort of probabilistic relationship can be extracted using unsupervised  learning. 


>> Tokens are: 
[sort, probabilistic, relationship, extracted, unsupervised,  , learning, .] 

>> PoS Tags are: 
[('sort', 'NOUN'), ('probabilistic', 'ADJ'), ('relationship', 'NOUN'), ('extracted', 'VERB'), ('unsupervised', 'ADJ'), (' ', 'SPACE'), ('learning', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('sort', 'nsubjpass'), ('probabilistic', 'amod'), ('relationship', 'pobj'), ('extracted', 'ROOT'), ('unsupervised', 'amod'), (' ', 'compound'), ('learning', 'dobj'), ('.', 'punct')]

>> Bigrams: 
[[sort, probabilistic], [probabilistic, relationship], [relationship, extracted], [extracted, unsupervised], [unsupervised,  ], [ , learning], [learning, .]]

>> Trigrams: 
[[sort, probabilistic, relationship], [probabilistic, relationship, extracted], [relationship, extracted, unsupervised], [extracted, unsupervised,  ], [unsupervised,  , learning], [ , learning, .]]

>> Noun Phrases are: 
[That sort, probabilistic relationship, unsupervised  learning]

>> Named Entities are: 
[] 

------------------- Sentence 2 -------------------

The syntax matrix was an excellent candidate for unsupervised  learning, as it involved discovering generally applicable patterns from a very  large corpus of content. 


>> Tokens are: 
[syntax, matrix, excellent, candidate, unsupervised,  , learning, ,, involved, discovering, generally, applicable, patterns,  , large, corpus, content, .] 

>> PoS Tags are: 
[('syntax', 'NOUN'), ('matrix', 'NOUN'), ('excellent', 'ADJ'), ('candidate', 'NOUN'), ('unsupervised', 'ADJ'), (' ', 'SPACE'), ('learning', 'NOUN'), (',', 'PUNCT'), ('involved', 'VERB'), ('discovering', 'VERB'), ('generally', 'ADV'), ('applicable', 'ADJ'), ('patterns', 'NOUN'), (' ', 'SPACE'), ('large', 'ADJ'), ('corpus', 'NOUN'), ('content', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('syntax', 'compound'), ('matrix', 'nsubj'), ('excellent', 'amod'), ('candidate', 'attr'), ('unsupervised', 'amod'), (' ', 'compound'), ('learning', 'pobj'), (',', 'punct'), ('involved', 'advcl'), ('discovering', 'xcomp'), ('generally', 'advmod'), ('applicable', 'amod'), ('patterns', 'dobj'), (' ', 'nmod'), ('large', 'amod'), ('corpus', 'pobj'), ('content', 'pobj'), ('.', 'punct')]

>> Bigrams: 
[[syntax, matrix], [matrix, excellent], [excellent, candidate], [candidate, unsupervised], [unsupervised,  ], [ , learning], [learning, ,], [,, involved], [involved, discovering], [discovering, generally], [generally, applicable], [applicable, patterns], [patterns,  ], [ , large], [large, corpus], [corpus, content], [content, .]]

>> Trigrams: 
[[syntax, matrix, excellent], [matrix, excellent, candidate], [excellent, candidate, unsupervised], [candidate, unsupervised,  ], [unsupervised,  , learning], [ , learning, ,], [learning, ,, involved], [,, involved, discovering], [involved, discovering, generally], [discovering, generally, applicable], [generally, applicable, patterns], [applicable, patterns,  ], [patterns,  , large], [ , large, corpus], [large, corpus, content], [corpus, content, .]]

>> Noun Phrases are: 
[The syntax matrix, an excellent candidate, unsupervised  learning, it, generally applicable patterns, a very  large corpus, content]

>> Named Entities are: 
[] 

------------------- Sentence 3 -------------------

Because it is a matrix, it can be evaluated really fast  for each sentence, unlike a full parser. 


>> Tokens are: 
[matrix, ,, evaluated, fast,  , sentence, ,, unlike, parser, .] 

>> PoS Tags are: 
[('matrix', 'NOUN'), (',', 'PUNCT'), ('evaluated', 'VERB'), ('fast', 'ADJ'), (' ', 'SPACE'), ('sentence', 'NOUN'), (',', 'PUNCT'), ('unlike', 'ADP'), ('parser', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('matrix', 'attr'), (',', 'punct'), ('evaluated', 'ROOT'), ('fast', 'amod'), (' ', 'dobj'), ('sentence', 'pobj'), (',', 'punct'), ('unlike', 'prep'), ('parser', 'pobj'), ('.', 'punct')]

>> Bigrams: 
[[matrix, ,], [,, evaluated], [evaluated, fast], [fast,  ], [ , sentence], [sentence, ,], [,, unlike], [unlike, parser], [parser, .]]

>> Trigrams: 
[[matrix, ,, evaluated], [,, evaluated, fast], [evaluated, fast,  ], [fast,  , sentence], [ , sentence, ,], [sentence, ,, unlike], [,, unlike, parser], [unlike, parser, .]]

>> Noun Phrases are: 
[it, a matrix, it, each sentence, a full parser]

>> Named Entities are: 
[] 


================================ Paragraph 89 =================================

As the amount of content created every day grows exponentially,  unsupervised techniques become more and more valuable. 

------------------- Sentence 1 -------------------

As the amount of content created every day grows exponentially,  unsupervised techniques become more and more valuable. 


>> Tokens are: 
[content, created, day, grows, exponentially, ,,  , unsupervised, techniques, valuable, .] 

>> PoS Tags are: 
[('content', 'NOUN'), ('created', 'VERB'), ('day', 'NOUN'), ('grows', 'VERB'), ('exponentially', 'ADV'), (',', 'PUNCT'), (' ', 'SPACE'), ('unsupervised', 'ADJ'), ('techniques', 'NOUN'), ('valuable', 'ADJ'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('content', 'pobj'), ('created', 'acl'), ('day', 'npadvmod'), ('grows', 'advcl'), ('exponentially', 'advmod'), (',', 'punct'), (' ', 'nmod'), ('unsupervised', 'amod'), ('techniques', 'nsubj'), ('valuable', 'acomp'), ('.', 'punct')]

>> Bigrams: 
[[content, created], [created, day], [day, grows], [grows, exponentially], [exponentially, ,], [,,  ], [ , unsupervised], [unsupervised, techniques], [techniques, valuable], [valuable, .]]

>> Trigrams: 
[[content, created, day], [created, day, grows], [day, grows, exponentially], [grows, exponentially, ,], [exponentially, ,,  ], [,,  , unsupervised], [ , unsupervised, techniques], [unsupervised, techniques, valuable], [techniques, valuable, .]]

>> Noun Phrases are: 
[the amount, content,  unsupervised techniques]

>> Named Entities are: 
[('every day', 'DATE')] 


================================ Paragraph 90 =================================

Semi-supervised learning 

------------------- Sentence 1 -------------------

Semi-supervised learning 


>> Tokens are: 
[Semi, -, supervised, learning] 

>> PoS Tags are: 
[('Semi', 'ADJ'), ('-', 'ADJ'), ('supervised', 'ADJ'), ('learning', 'NOUN')] 

>> Dependency Tags are: 
[('Semi', 'amod'), ('-', 'amod'), ('supervised', 'amod'), ('learning', 'ROOT')]

>> Bigrams: 
[[Semi, -], [-, supervised], [supervised, learning]]

>> Trigrams: 
[[Semi, -, supervised], [-, supervised, learning]]

>> Noun Phrases are: 
[Semi-supervised learning]

>> Named Entities are: 
[] 


================================ Paragraph 91 =================================

Semi-supervised learning is a combination of unsupervised and supervised  learning techniques. With this approach we’ll have both marked-up  supervised content and un-marked data. The machine learning model   uses the marked-up content to generalize and make assertions about   the rest of the data.  

------------------- Sentence 1 -------------------

Semi-supervised learning is a combination of unsupervised and supervised  learning techniques. 


>> Tokens are: 
[Semi, -, supervised, learning, combination, unsupervised, supervised,  , learning, techniques, .] 

>> PoS Tags are: 
[('Semi', 'ADJ'), ('-', 'ADJ'), ('supervised', 'ADJ'), ('learning', 'NOUN'), ('combination', 'NOUN'), ('unsupervised', 'ADJ'), ('supervised', 'VERB'), (' ', 'SPACE'), ('learning', 'VERB'), ('techniques', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('Semi', 'amod'), ('-', 'amod'), ('supervised', 'amod'), ('learning', 'nsubj'), ('combination', 'attr'), ('unsupervised', 'pobj'), ('supervised', 'conj'), (' ', 'dobj'), ('learning', 'xcomp'), ('techniques', 'dobj'), ('.', 'punct')]

>> Bigrams: 
[[Semi, -], [-, supervised], [supervised, learning], [learning, combination], [combination, unsupervised], [unsupervised, supervised], [supervised,  ], [ , learning], [learning, techniques], [techniques, .]]

>> Trigrams: 
[[Semi, -, supervised], [-, supervised, learning], [supervised, learning, combination], [learning, combination, unsupervised], [combination, unsupervised, supervised], [unsupervised, supervised,  ], [supervised,  , learning], [ , learning, techniques], [learning, techniques, .]]

>> Noun Phrases are: 
[Semi-supervised learning, a combination, techniques]

>> Named Entities are: 
[] 

------------------- Sentence 2 -------------------

With this approach we’ll have both marked-up  supervised content and un-marked data. 


>> Tokens are: 
[approach, marked, -,  , supervised, content, un, -, marked, data, .] 

>> PoS Tags are: 
[('approach', 'NOUN'), ('marked', 'VERB'), ('-', 'PUNCT'), (' ', 'SPACE'), ('supervised', 'ADJ'), ('content', 'NOUN'), ('un', 'ADJ'), ('-', 'ADJ'), ('marked', 'ADJ'), ('data', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('approach', 'pobj'), ('marked', 'amod'), ('-', 'punct'), (' ', 'nmod'), ('supervised', 'amod'), ('content', 'dobj'), ('un', 'amod'), ('-', 'punct'), ('marked', 'amod'), ('data', 'conj'), ('.', 'punct')]

>> Bigrams: 
[[approach, marked], [marked, -], [-,  ], [ , supervised], [supervised, content], [content, un], [un, -], [-, marked], [marked, data], [data, .]]

>> Trigrams: 
[[approach, marked, -], [marked, -,  ], [-,  , supervised], [ , supervised, content], [supervised, content, un], [content, un, -], [un, -, marked], [-, marked, data], [marked, data, .]]

>> Noun Phrases are: 
[this approach, we, both marked-up  supervised content, un-marked data]

>> Named Entities are: 
[] 

------------------- Sentence 3 -------------------

The machine learning model   uses the marked-up content to generalize and make assertions about   the rest of the data. 


>> Tokens are: 
[machine, learning, model,   , uses, marked, -, content, generalize, assertions,   , rest, data, .] 

>> PoS Tags are: 
[('machine', 'NOUN'), ('learning', 'NOUN'), ('model', 'NOUN'), ('  ', 'SPACE'), ('uses', 'VERB'), ('marked', 'VERB'), ('-', 'PUNCT'), ('content', 'NOUN'), ('generalize', 'VERB'), ('assertions', 'NOUN'), ('  ', 'SPACE'), ('rest', 'NOUN'), ('data', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('machine', 'compound'), ('learning', 'compound'), ('model', 'nsubj'), ('  ', 'nsubj'), ('uses', 'ROOT'), ('marked', 'amod'), ('-', 'punct'), ('content', 'dobj'), ('generalize', 'acl'), ('assertions', 'dobj'), ('  ', 'pobj'), ('rest', 'dobj'), ('data', 'pobj'), ('.', 'punct')]

>> Bigrams: 
[[machine, learning], [learning, model], [model,   ], [  , uses], [uses, marked], [marked, -], [-, content], [content, generalize], [generalize, assertions], [assertions,   ], [  , rest], [rest, data], [data, .]]

>> Trigrams: 
[[machine, learning, model], [learning, model,   ], [model,   , uses], [  , uses, marked], [uses, marked, -], [marked, -, content], [-, content, generalize], [content, generalize, assertions], [generalize, assertions,   ], [assertions,   , rest], [  , rest, data], [rest, data, .]]

>> Noun Phrases are: 
[The machine learning model, the marked-up content, assertions, the rest, the data]

>> Named Entities are: 
[] 

------------------- Sentence 4 -------------------

  


>> Tokens are: 
[ ] 

>> PoS Tags are: 
[(' ', 'SPACE')] 

>> Dependency Tags are: 
[(' ', 'ROOT')]

>> Bigrams: 
[]

>> Trigrams: 
[]

>> Noun Phrases are: 
[]

>> Named Entities are: 
[] 


================================ Paragraph 92 =================================

Now that we’ve reviewed the machine learning essentials, let’s look at  how to combine machine learning and algorithmic natural language  processing to build a high-performing text analytics AI. 

------------------- Sentence 1 -------------------

Now that we’ve reviewed the machine learning essentials, let’s look at  how to combine machine learning and algorithmic natural language  processing to build a high-performing text analytics AI. 


>> Tokens are: 
[reviewed, machine, learning, essentials, ,, let, look,  , combine, machine, learning, algorithmic, natural, language,  , processing, build, high, -, performing, text, analytics, AI, .] 

>> PoS Tags are: 
[('reviewed', 'VERB'), ('machine', 'NOUN'), ('learning', 'NOUN'), ('essentials', 'NOUN'), (',', 'PUNCT'), ('let', 'VERB'), ('look', 'VERB'), (' ', 'SPACE'), ('combine', 'VERB'), ('machine', 'NOUN'), ('learning', 'NOUN'), ('algorithmic', 'ADJ'), ('natural', 'ADJ'), ('language', 'NOUN'), (' ', 'SPACE'), ('processing', 'NOUN'), ('build', 'VERB'), ('high', 'ADV'), ('-', 'PUNCT'), ('performing', 'VERB'), ('text', 'NOUN'), ('analytics', 'NOUN'), ('AI', 'PROPN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('reviewed', 'ccomp'), ('machine', 'compound'), ('learning', 'compound'), ('essentials', 'dobj'), (',', 'punct'), ('let', 'ROOT'), ('look', 'ccomp'), (' ', 'pobj'), ('combine', 'advcl'), ('machine', 'compound'), ('learning', 'dobj'), ('algorithmic', 'amod'), ('natural', 'amod'), ('language', 'conj'), (' ', 'compound'), ('processing', 'advcl'), ('build', 'advcl'), ('high', 'advmod'), ('-', 'punct'), ('performing', 'amod'), ('text', 'compound'), ('analytics', 'compound'), ('AI', 'dobj'), ('.', 'punct')]

>> Bigrams: 
[[reviewed, machine], [machine, learning], [learning, essentials], [essentials, ,], [,, let], [let, look], [look,  ], [ , combine], [combine, machine], [machine, learning], [learning, algorithmic], [algorithmic, natural], [natural, language], [language,  ], [ , processing], [processing, build], [build, high], [high, -], [-, performing], [performing, text], [text, analytics], [analytics, AI], [AI, .]]

>> Trigrams: 
[[reviewed, machine, learning], [machine, learning, essentials], [learning, essentials, ,], [essentials, ,, let], [,, let, look], [let, look,  ], [look,  , combine], [ , combine, machine], [combine, machine, learning], [machine, learning, algorithmic], [learning, algorithmic, natural], [algorithmic, natural, language], [natural, language,  ], [language,  , processing], [ , processing, build], [processing, build, high], [build, high, -], [high, -, performing], [-, performing, text], [performing, text, analytics], [text, analytics, AI], [analytics, AI, .]]

>> Noun Phrases are: 
[we, the machine learning essentials, ’s, machine learning, algorithmic natural language, a high-performing text analytics AI]

>> Named Entities are: 
[('AI', 'ORG')] 


================================ Paragraph 93 =================================

is the combination   

------------------- Sentence 1 -------------------

is the combination    


>> Tokens are: 
[combination,   ] 

>> PoS Tags are: 
[('combination', 'NOUN'), ('  ', 'SPACE')] 

>> Dependency Tags are: 
[('combination', 'attr'), ('  ', 'punct')]

>> Bigrams: 
[[combination,   ]]

>> Trigrams: 
[]

>> Noun Phrases are: 
[the combination]

>> Named Entities are: 
[] 


================================ Paragraph 94 =================================

of unsupervised and  

------------------- Sentence 1 -------------------

of unsupervised and   


>> Tokens are: 
[unsupervised,  ] 

>> PoS Tags are: 
[('unsupervised', 'ADJ'), (' ', 'SPACE')] 

>> Dependency Tags are: 
[('unsupervised', 'pobj'), (' ', 'conj')]

>> Bigrams: 
[[unsupervised,  ]]

>> Trigrams: 
[]

>> Noun Phrases are: 
[]

>> Named Entities are: 
[] 


================================ Paragraph 95 =================================

supervised learning. 

------------------- Sentence 1 -------------------

supervised learning. 


>> Tokens are: 
[supervised, learning, .] 

>> PoS Tags are: 
[('supervised', 'ADJ'), ('learning', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('supervised', 'amod'), ('learning', 'ROOT'), ('.', 'punct')]

>> Bigrams: 
[[supervised, learning], [learning, .]]

>> Trigrams: 
[[supervised, learning, .]]

>> Noun Phrases are: 
[supervised learning]

>> Named Entities are: 
[] 


================================ Paragraph 96 =================================

Semi-supervised  learning 

------------------- Sentence 1 -------------------

Semi-supervised  learning 


>> Tokens are: 
[Semi, -, supervised,  , learning] 

>> PoS Tags are: 
[('Semi', 'ADJ'), ('-', 'VERB'), ('supervised', 'ADJ'), (' ', 'SPACE'), ('learning', 'VERB')] 

>> Dependency Tags are: 
[('Semi', 'amod'), ('-', 'punct'), ('supervised', 'amod'), (' ', 'compound'), ('learning', 'ROOT')]

>> Bigrams: 
[[Semi, -], [-, supervised], [supervised,  ], [ , learning]]

>> Trigrams: 
[[Semi, -, supervised], [-, supervised,  ], [supervised,  , learning]]

>> Noun Phrases are: 
[]

>> Named Entities are: 
[] 


================================ Paragraph 97 =================================

is where the machine   

------------------- Sentence 1 -------------------

is where 


>> Tokens are: 
[] 

>> PoS Tags are: 
[] 

>> Dependency Tags are: 
[]

>> Bigrams: 
[]

>> Trigrams: 
[]

>> Noun Phrases are: 
[]

>> Named Entities are: 
[] 

------------------- Sentence 2 -------------------

the machine    


>> Tokens are: 
[machine,   ] 

>> PoS Tags are: 
[('machine', 'NOUN'), ('  ', 'SPACE')] 

>> Dependency Tags are: 
[('machine', 'ROOT'), ('  ', 'appos')]

>> Bigrams: 
[[machine,   ]]

>> Trigrams: 
[]

>> Noun Phrases are: 
[the machine]

>> Named Entities are: 
[] 


================================ Paragraph 98 =================================

takes content and is told to  

------------------- Sentence 1 -------------------

takes content and is told to   


>> Tokens are: 
[takes, content, told,  ] 

>> PoS Tags are: 
[('takes', 'VERB'), ('content', 'NOUN'), ('told', 'VERB'), (' ', 'SPACE')] 

>> Dependency Tags are: 
[('takes', 'ROOT'), ('content', 'dobj'), ('told', 'conj'), (' ', 'pobj')]

>> Bigrams: 
[[takes, content], [content, told], [told,  ]]

>> Trigrams: 
[[takes, content, told], [content, told,  ]]

>> Noun Phrases are: 
[content]

>> Named Entities are: 
[] 


================================ Paragraph 99 =================================

find patterns within it. 

------------------- Sentence 1 -------------------

find patterns within it. 


>> Tokens are: 
[find, patterns, .] 

>> PoS Tags are: 
[('find', 'VERB'), ('patterns', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('find', 'ROOT'), ('patterns', 'dobj'), ('.', 'punct')]

>> Bigrams: 
[[find, patterns], [patterns, .]]

>> Trigrams: 
[[find, patterns, .]]

>> Noun Phrases are: 
[patterns, it]

>> Named Entities are: 
[] 


================================ Paragraph 100 =================================

Unsupervised  learning

------------------- Sentence 1 -------------------

Unsupervised  learning 


>> Tokens are: 
[Unsupervised,  , learning] 

>> PoS Tags are: 
[('Unsupervised', 'ADJ'), (' ', 'SPACE'), ('learning', 'VERB')] 

>> Dependency Tags are: 
[('Unsupervised', 'amod'), (' ', 'compound'), ('learning', 'ROOT')]

>> Bigrams: 
[[Unsupervised,  ], [ , learning]]

>> Trigrams: 
[[Unsupervised,  , learning]]

>> Noun Phrases are: 
[]

>> Named Entities are: 
[] 


================================ Paragraph 101 =================================

W H I T E  P A P E R 

------------------- Sentence 1 -------------------

W H 


>> Tokens are: 
[W, H] 

>> PoS Tags are: 
[('W', 'NOUN'), ('H', 'NOUN')] 

>> Dependency Tags are: 
[('W', 'compound'), ('H', 'ROOT')]

>> Bigrams: 
[[W, H]]

>> Trigrams: 
[]

>> Noun Phrases are: 
[W H]

>> Named Entities are: 
[] 

------------------- Sentence 2 -------------------

I T 


>> Tokens are: 
[T] 

>> PoS Tags are: 
[('T', 'NOUN')] 

>> Dependency Tags are: 
[('T', 'appos')]

>> Bigrams: 
[]

>> Trigrams: 
[]

>> Noun Phrases are: 
[I, T]

>> Named Entities are: 
[] 

------------------- Sentence 3 -------------------

E   


>> Tokens are: 
[E,  ] 

>> PoS Tags are: 
[('E', 'NOUN'), (' ', 'SPACE')] 

>> Dependency Tags are: 
[('E', 'ROOT'), (' ', 'appos')]

>> Bigrams: 
[[E,  ]]

>> Trigrams: 
[]

>> Noun Phrases are: 
[E]

>> Named Entities are: 
[] 

------------------- Sentence 4 -------------------

P A P E R 


>> Tokens are: 
[P, P, E, R] 

>> PoS Tags are: 
[('P', 'NOUN'), ('P', 'NOUN'), ('E', 'NOUN'), ('R', 'NOUN')] 

>> Dependency Tags are: 
[('P', 'compound'), ('P', 'compound'), ('E', 'compound'), ('R', 'ROOT')]

>> Bigrams: 
[[P, P], [P, E], [E, R]]

>> Trigrams: 
[[P, P, E], [P, E, R]]

>> Noun Phrases are: 
[P A P E R]

>> Named Entities are: 
[] 


================================ Paragraph 102 =================================

7|       |   Lexalytics, Inc., 48 North Pleasant St. Unit 301, Amherst MA 01002 USA   |   1-800-377-8036 |   www.lexalytics.com 

------------------- Sentence 1 -------------------

7|       |   Lexalytics, Inc., 48 North Pleasant St. Unit 301, Amherst MA 01002 USA   |   1-800-377-8036 |   www.lexalytics.com 


>> Tokens are: 
[7|,       , |,   , Lexalytics, ,, Inc., ,, 48, North, Pleasant, St., Unit, 301, ,, Amherst, MA, 01002, USA,   , |,   , 1, -, 800, -, 377, -, 8036, |,   , www.lexalytics.com] 

>> PoS Tags are: 
[('7|', 'NUM'), ('      ', 'SPACE'), ('|', 'NOUN'), ('  ', 'SPACE'), ('Lexalytics', 'PROPN'), (',', 'PUNCT'), ('Inc.', 'PROPN'), (',', 'PUNCT'), ('48', 'NUM'), ('North', 'PROPN'), ('Pleasant', 'PROPN'), ('St.', 'PROPN'), ('Unit', 'PROPN'), ('301', 'NUM'), (',', 'PUNCT'), ('Amherst', 'PROPN'), ('MA', 'PROPN'), ('01002', 'NUM'), ('USA', 'PROPN'), ('  ', 'SPACE'), ('|', 'NOUN'), ('  ', 'SPACE'), ('1', 'NUM'), ('-', 'SYM'), ('800', 'NUM'), ('-', 'NUM'), ('377', 'NUM'), ('-', 'PUNCT'), ('8036', 'NUM'), ('|', 'NOUN'), ('  ', 'SPACE'), ('www.lexalytics.com', 'X')] 

>> Dependency Tags are: 
[('7|', 'nummod'), ('      ', 'compound'), ('|', 'nsubj'), ('  ', 'nmod'), ('Lexalytics', 'nmod'), (',', 'punct'), ('Inc.', 'appos'), (',', 'punct'), ('48', 'nummod'), ('North', 'compound'), ('Pleasant', 'compound'), ('St.', 'compound'), ('Unit', 'appos'), ('301', 'nummod'), (',', 'punct'), ('Amherst', 'compound'), ('MA', 'appos'), ('01002', 'punct'), ('USA', 'compound'), ('  ', 'compound'), ('|', 'npadvmod'), ('  ', 'appos'), ('1', 'npadvmod'), ('-', 'punct'), ('800', 'prep'), ('-', 'punct'), ('377', 'nummod'), ('-', 'punct'), ('8036', 'nummod'), ('|', 'appos'), ('  ', 'ROOT'), ('www.lexalytics.com', 'punct')]

>> Bigrams: 
[[7|,       ], [      , |], [|,   ], [  , Lexalytics], [Lexalytics, ,], [,, Inc.], [Inc., ,], [,, 48], [48, North], [North, Pleasant], [Pleasant, St.], [St., Unit], [Unit, 301], [301, ,], [,, Amherst], [Amherst, MA], [MA, 01002], [01002, USA], [USA,   ], [  , |], [|,   ], [  , 1], [1, -], [-, 800], [800, -], [-, 377], [377, -], [-, 8036], [8036, |], [|,   ], [  , www.lexalytics.com]]

>> Trigrams: 
[[7|,       , |], [      , |,   ], [|,   , Lexalytics], [  , Lexalytics, ,], [Lexalytics, ,, Inc.], [,, Inc., ,], [Inc., ,, 48], [,, 48, North], [48, North, Pleasant], [North, Pleasant, St.], [Pleasant, St., Unit], [St., Unit, 301], [Unit, 301, ,], [301, ,, Amherst], [,, Amherst, MA], [Amherst, MA, 01002], [MA, 01002, USA], [01002, USA,   ], [USA,   , |], [  , |,   ], [|,   , 1], [  , 1, -], [1, -, 800], [-, 800, -], [800, -, 377], [-, 377, -], [377, -, 8036], [-, 8036, |], [8036, |,   ], [|,   , www.lexalytics.com]]

>> Noun Phrases are: 
[7|       |,   Lexalytics, Inc., 48 North Pleasant St. Unit, Amherst MA, 377-8036 |]

>> Named Entities are: 
[('Lexalytics, Inc.', 'ORG'), ('48', 'CARDINAL'), ('North Pleasant St. Unit 301', 'ORG'), ('Amherst MA', 'ORG')] 


================================ Paragraph 103 =================================

H A P P I E R  B Y  T H E  D O Z E N :   T H E  M O R E  M O D E L S ,  T H E  M E R R I E R  Machine learning models are very good at performing single tasks, such   as determining the sentiment polarity of a document or the part-of-speech  for a given word. However, models are not good at tasks that require layers  of interpretation. Take the following sentence: 

------------------- Sentence 1 -------------------

H A P P I E R  B Y  T H 


>> Tokens are: 
[H, P, P, E, R,  , B, Y,  , T, H] 

>> PoS Tags are: 
[('H', 'NOUN'), ('P', 'NOUN'), ('P', 'NOUN'), ('E', 'NOUN'), ('R', 'NOUN'), (' ', 'SPACE'), ('B', 'PROPN'), ('Y', 'PROPN'), (' ', 'SPACE'), ('T', 'NOUN'), ('H', 'NOUN')] 

>> Dependency Tags are: 
[('H', 'compound'), ('P', 'compound'), ('P', 'nmod'), ('E', 'nmod'), ('R', 'nmod'), (' ', 'compound'), ('B', 'compound'), ('Y', 'nmod'), (' ', 'appos'), ('T', 'compound'), ('H', 'ROOT')]

>> Bigrams: 
[[H, P], [P, P], [P, E], [E, R], [R,  ], [ , B], [B, Y], [Y,  ], [ , T], [T, H]]

>> Trigrams: 
[[H, P, P], [P, P, E], [P, E, R], [E, R,  ], [R,  , B], [ , B, Y], [B, Y,  ], [Y,  , T], [ , T, H]]

>> Noun Phrases are: 
[H A P P I E R  B Y  T H]

>> Named Entities are: 
[] 

------------------- Sentence 2 -------------------

E   


>> Tokens are: 
[E,  ] 

>> PoS Tags are: 
[('E', 'NOUN'), (' ', 'SPACE')] 

>> Dependency Tags are: 
[('E', 'ROOT'), (' ', 'appos')]

>> Bigrams: 
[[E,  ]]

>> Trigrams: 
[]

>> Noun Phrases are: 
[E]

>> Named Entities are: 
[] 

------------------- Sentence 3 -------------------

D O Z E N :   T H 


>> Tokens are: 
[D, O, Z, E, N, :,   , T, H] 

>> PoS Tags are: 
[('D', 'NOUN'), ('O', 'NOUN'), ('Z', 'NOUN'), ('E', 'NOUN'), ('N', 'NOUN'), (':', 'PUNCT'), ('  ', 'SPACE'), ('T', 'NOUN'), ('H', 'NOUN')] 

>> Dependency Tags are: 
[('D', 'compound'), ('O', 'compound'), ('Z', 'compound'), ('E', 'ROOT'), ('N', 'appos'), (':', 'punct'), ('  ', 'compound'), ('T', 'compound'), ('H', 'appos')]

>> Bigrams: 
[[D, O], [O, Z], [Z, E], [E, N], [N, :], [:,   ], [  , T], [T, H]]

>> Trigrams: 
[[D, O, Z], [O, Z, E], [Z, E, N], [E, N, :], [N, :,   ], [:,   , T], [  , T, H]]

>> Noun Phrases are: 
[D O Z E, N,   T H]

>> Named Entities are: 
[] 

------------------- Sentence 4 -------------------

E  M O R E  M O D E L S ,  T H 


>> Tokens are: 
[E,  , M, O, R, E,  , M, O, D, E, L, S, ,,  , T, H] 

>> PoS Tags are: 
[('E', 'NOUN'), (' ', 'SPACE'), ('M', 'NOUN'), ('O', 'NOUN'), ('R', 'NOUN'), ('E', 'NOUN'), (' ', 'SPACE'), ('M', 'NOUN'), ('O', 'NOUN'), ('D', 'NOUN'), ('E', 'NOUN'), ('L', 'PROPN'), ('S', 'PROPN'), (',', 'PUNCT'), (' ', 'SPACE'), ('T', 'NOUN'), ('H', 'NOUN')] 

>> Dependency Tags are: 
[('E', 'compound'), (' ', 'compound'), ('M', 'compound'), ('O', 'compound'), ('R', 'nmod'), ('E', 'nmod'), (' ', 'appos'), ('M', 'compound'), ('O', 'compound'), ('D', 'compound'), ('E', 'compound'), ('L', 'compound'), ('S', 'ROOT'), (',', 'punct'), (' ', 'appos'), ('T', 'compound'), ('H', 'appos')]

>> Bigrams: 
[[E,  ], [ , M], [M, O], [O, R], [R, E], [E,  ], [ , M], [M, O], [O, D], [D, E], [E, L], [L, S], [S, ,], [,,  ], [ , T], [T, H]]

>> Trigrams: 
[[E,  , M], [ , M, O], [M, O, R], [O, R, E], [R, E,  ], [E,  , M], [ , M, O], [M, O, D], [O, D, E], [D, E, L], [E, L, S], [L, S, ,], [S, ,,  ], [,,  , T], [ , T, H]]

>> Noun Phrases are: 
[E  M O R E  M O D E L S, T H]

>> Named Entities are: 
[] 

------------------- Sentence 5 -------------------

E  M E R R I E R  Machine learning models are very good at performing single tasks, such   as determining the sentiment polarity of a document or the part-of-speech  for a given word. 


>> Tokens are: 
[E,  , M, E, R, R, E, R,  , Machine, learning, models, good, performing, single, tasks, ,,   , determining, sentiment, polarity, document, -, -, speech,  , given, word, .] 

>> PoS Tags are: 
[('E', 'NOUN'), (' ', 'SPACE'), ('M', 'PROPN'), ('E', 'NOUN'), ('R', 'NOUN'), ('R', 'NOUN'), ('E', 'NOUN'), ('R', 'NOUN'), (' ', 'SPACE'), ('Machine', 'NOUN'), ('learning', 'NOUN'), ('models', 'NOUN'), ('good', 'ADJ'), ('performing', 'VERB'), ('single', 'ADJ'), ('tasks', 'NOUN'), (',', 'PUNCT'), ('  ', 'SPACE'), ('determining', 'VERB'), ('sentiment', 'NOUN'), ('polarity', 'NOUN'), ('document', 'NOUN'), ('-', 'PUNCT'), ('-', 'PUNCT'), ('speech', 'NOUN'), (' ', 'SPACE'), ('given', 'VERB'), ('word', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('E', 'nmod'), (' ', 'compound'), ('M', 'compound'), ('E', 'compound'), ('R', 'compound'), ('R', 'compound'), ('E', 'nmod'), ('R', 'compound'), (' ', 'nmod'), ('Machine', 'compound'), ('learning', 'compound'), ('models', 'nsubj'), ('good', 'acomp'), ('performing', 'pcomp'), ('single', 'amod'), ('tasks', 'dobj'), (',', 'punct'), ('  ', 'npadvmod'), ('determining', 'pcomp'), ('sentiment', 'compound'), ('polarity', 'dobj'), ('document', 'pobj'), ('-', 'punct'), ('-', 'punct'), ('speech', 'pobj'), (' ', 'dobj'), ('given', 'amod'), ('word', 'pobj'), ('.', 'punct')]

>> Bigrams: 
[[E,  ], [ , M], [M, E], [E, R], [R, R], [R, E], [E, R], [R,  ], [ , Machine], [Machine, learning], [learning, models], [models, good], [good, performing], [performing, single], [single, tasks], [tasks, ,], [,,   ], [  , determining], [determining, sentiment], [sentiment, polarity], [polarity, document], [document, -], [-, -], [-, speech], [speech,  ], [ , given], [given, word], [word, .]]

>> Trigrams: 
[[E,  , M], [ , M, E], [M, E, R], [E, R, R], [R, R, E], [R, E, R], [E, R,  ], [R,  , Machine], [ , Machine, learning], [Machine, learning, models], [learning, models, good], [models, good, performing], [good, performing, single], [performing, single, tasks], [single, tasks, ,], [tasks, ,,   ], [,,   , determining], [  , determining, sentiment], [determining, sentiment, polarity], [sentiment, polarity, document], [polarity, document, -], [document, -, -], [-, -, speech], [-, speech,  ], [speech,  , given], [ , given, word], [given, word, .]]

>> Noun Phrases are: 
[E  M E R R I E R  Machine learning models, single tasks, the sentiment polarity, a document, speech, a given word]

>> Named Entities are: 
[] 

------------------- Sentence 6 -------------------

However, models are not good at tasks that require layers  of interpretation. 


>> Tokens are: 
[,, models, good, tasks, require, layers,  , interpretation, .] 

>> PoS Tags are: 
[(',', 'PUNCT'), ('models', 'NOUN'), ('good', 'ADJ'), ('tasks', 'NOUN'), ('require', 'VERB'), ('layers', 'NOUN'), (' ', 'SPACE'), ('interpretation', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[(',', 'punct'), ('models', 'nsubj'), ('good', 'acomp'), ('tasks', 'pobj'), ('require', 'relcl'), ('layers', 'dobj'), (' ', 'dobj'), ('interpretation', 'pobj'), ('.', 'punct')]

>> Bigrams: 
[[,, models], [models, good], [good, tasks], [tasks, require], [require, layers], [layers,  ], [ , interpretation], [interpretation, .]]

>> Trigrams: 
[[,, models, good], [models, good, tasks], [good, tasks, require], [tasks, require, layers], [require, layers,  ], [layers,  , interpretation], [ , interpretation, .]]

>> Noun Phrases are: 
[models, tasks, layers, interpretation]

>> Named Entities are: 
[] 

------------------- Sentence 7 -------------------

Take the following sentence: 


>> Tokens are: 
[following, sentence, :] 

>> PoS Tags are: 
[('following', 'ADJ'), ('sentence', 'NOUN'), (':', 'PUNCT')] 

>> Dependency Tags are: 
[('following', 'amod'), ('sentence', 'dobj'), (':', 'punct')]

>> Bigrams: 
[[following, sentence], [sentence, :]]

>> Trigrams: 
[[following, sentence, :]]

>> Noun Phrases are: 
[the following sentence]

>> Named Entities are: 
[] 


================================ Paragraph 104 =================================

“Lexalytics is the best text analytics company ever.”  

------------------- Sentence 1 -------------------

“Lexalytics is the best text analytics company ever.” 


>> Tokens are: 
[“, Lexalytics, best, text, analytics, company, ., ”] 

>> PoS Tags are: 
[('“', 'PUNCT'), ('Lexalytics', 'PROPN'), ('best', 'ADJ'), ('text', 'NOUN'), ('analytics', 'NOUN'), ('company', 'NOUN'), ('.', 'PUNCT'), ('”', 'PUNCT')] 

>> Dependency Tags are: 
[('“', 'punct'), ('Lexalytics', 'nsubj'), ('best', 'amod'), ('text', 'compound'), ('analytics', 'compound'), ('company', 'attr'), ('.', 'punct'), ('”', 'punct')]

>> Bigrams: 
[[“, Lexalytics], [Lexalytics, best], [best, text], [text, analytics], [analytics, company], [company, .], [., ”]]

>> Trigrams: 
[[“, Lexalytics, best], [Lexalytics, best, text], [best, text, analytics], [text, analytics, company], [analytics, company, .], [company, ., ”]]

>> Noun Phrases are: 
[Lexalytics, the best text analytics company]

>> Named Entities are: 
[] 

------------------- Sentence 2 -------------------

  


>> Tokens are: 
[ ] 

>> PoS Tags are: 
[(' ', 'SPACE')] 

>> Dependency Tags are: 
[(' ', 'ROOT')]

>> Bigrams: 
[]

>> Trigrams: 
[]

>> Noun Phrases are: 
[]

>> Named Entities are: 
[] 


================================ Paragraph 105 =================================

Besides agreeing with its obvious truth, what might we want to know   about this sentence? First, we want to know whether it contains any   entities (companies, people, products and so on). Second, we want to   know whether there’s any sentiment associated with those entities.   Third, we want to know whether a particular industry is being discussed.  Finally, we might ask whether any sentiment is being expressed   towards that industry. 

------------------- Sentence 1 -------------------

Besides agreeing with its obvious truth, what might we want to know   about this sentence? 


>> Tokens are: 
[agreeing, obvious, truth, ,, want, know,   , sentence, ?] 

>> PoS Tags are: 
[('agreeing', 'VERB'), ('obvious', 'ADJ'), ('truth', 'NOUN'), (',', 'PUNCT'), ('want', 'VERB'), ('know', 'VERB'), ('  ', 'SPACE'), ('sentence', 'NOUN'), ('?', 'PUNCT')] 

>> Dependency Tags are: 
[('agreeing', 'pcomp'), ('obvious', 'amod'), ('truth', 'pobj'), (',', 'punct'), ('want', 'ROOT'), ('know', 'xcomp'), ('  ', 'dobj'), ('sentence', 'pobj'), ('?', 'punct')]

>> Bigrams: 
[[agreeing, obvious], [obvious, truth], [truth, ,], [,, want], [want, know], [know,   ], [  , sentence], [sentence, ?]]

>> Trigrams: 
[[agreeing, obvious, truth], [obvious, truth, ,], [truth, ,, want], [,, want, know], [want, know,   ], [know,   , sentence], [  , sentence, ?]]

>> Noun Phrases are: 
[its obvious truth, what, we, this sentence]

>> Named Entities are: 
[] 

------------------- Sentence 2 -------------------

First, we want to know whether it contains any   entities (companies, people, products and so on). 


>> Tokens are: 
[,, want, know, contains,   , entities, (, companies, ,, people, ,, products, ), .] 

>> PoS Tags are: 
[(',', 'PUNCT'), ('want', 'VERB'), ('know', 'VERB'), ('contains', 'VERB'), ('  ', 'SPACE'), ('entities', 'NOUN'), ('(', 'PUNCT'), ('companies', 'NOUN'), (',', 'PUNCT'), ('people', 'NOUN'), (',', 'PUNCT'), ('products', 'NOUN'), (')', 'PUNCT'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[(',', 'punct'), ('want', 'ROOT'), ('know', 'xcomp'), ('contains', 'ccomp'), ('  ', 'compound'), ('entities', 'dobj'), ('(', 'punct'), ('companies', 'appos'), (',', 'punct'), ('people', 'conj'), (',', 'punct'), ('products', 'conj'), (')', 'punct'), ('.', 'punct')]

>> Bigrams: 
[[,, want], [want, know], [know, contains], [contains,   ], [  , entities], [entities, (], [(, companies], [companies, ,], [,, people], [people, ,], [,, products], [products, )], [), .]]

>> Trigrams: 
[[,, want, know], [want, know, contains], [know, contains,   ], [contains,   , entities], [  , entities, (], [entities, (, companies], [(, companies, ,], [companies, ,, people], [,, people, ,], [people, ,, products], [,, products, )], [products, ), .]]

>> Noun Phrases are: 
[we, it, any   entities, companies, people, products]

>> Named Entities are: 
[('First', 'ORDINAL')] 

------------------- Sentence 3 -------------------

Second, we want to   know whether there’s any sentiment associated with those entities. 


>> Tokens are: 
[Second, ,, want,   , know, sentiment, associated, entities, .] 

>> PoS Tags are: 
[('Second', 'ADV'), (',', 'PUNCT'), ('want', 'VERB'), ('  ', 'SPACE'), ('know', 'VERB'), ('sentiment', 'NOUN'), ('associated', 'VERB'), ('entities', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('Second', 'advmod'), (',', 'punct'), ('want', 'ROOT'), ('  ', 'pobj'), ('know', 'ccomp'), ('sentiment', 'attr'), ('associated', 'acl'), ('entities', 'pobj'), ('.', 'punct')]

>> Bigrams: 
[[Second, ,], [,, want], [want,   ], [  , know], [know, sentiment], [sentiment, associated], [associated, entities], [entities, .]]

>> Trigrams: 
[[Second, ,, want], [,, want,   ], [want,   , know], [  , know, sentiment], [know, sentiment, associated], [sentiment, associated, entities], [associated, entities, .]]

>> Noun Phrases are: 
[we, any sentiment, those entities]

>> Named Entities are: 
[('Second', 'ORDINAL')] 

------------------- Sentence 4 -------------------

   


>> Tokens are: 
[  ] 

>> PoS Tags are: 
[('  ', 'SPACE')] 

>> Dependency Tags are: 
[('  ', 'ROOT')]

>> Bigrams: 
[]

>> Trigrams: 
[]

>> Noun Phrases are: 
[]

>> Named Entities are: 
[] 

------------------- Sentence 5 -------------------

Third, we want to know whether a particular industry is being discussed. 


>> Tokens are: 
[,, want, know, particular, industry, discussed, .] 

>> PoS Tags are: 
[(',', 'PUNCT'), ('want', 'VERB'), ('know', 'VERB'), ('particular', 'ADJ'), ('industry', 'NOUN'), ('discussed', 'VERB'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[(',', 'punct'), ('want', 'ROOT'), ('know', 'xcomp'), ('particular', 'amod'), ('industry', 'nsubjpass'), ('discussed', 'ccomp'), ('.', 'punct')]

>> Bigrams: 
[[,, want], [want, know], [know, particular], [particular, industry], [industry, discussed], [discussed, .]]

>> Trigrams: 
[[,, want, know], [want, know, particular], [know, particular, industry], [particular, industry, discussed], [industry, discussed, .]]

>> Noun Phrases are: 
[we, a particular industry]

>> Named Entities are: 
[('Third', 'ORDINAL')] 

------------------- Sentence 6 -------------------

  


>> Tokens are: 
[ ] 

>> PoS Tags are: 
[(' ', 'SPACE')] 

>> Dependency Tags are: 
[(' ', 'ROOT')]

>> Bigrams: 
[]

>> Trigrams: 
[]

>> Noun Phrases are: 
[]

>> Named Entities are: 
[] 

------------------- Sentence 7 -------------------

Finally, we might ask whether any sentiment is being expressed   towards that industry. 


>> Tokens are: 
[Finally, ,, ask, sentiment, expressed,   , industry, .] 

>> PoS Tags are: 
[('Finally', 'ADV'), (',', 'PUNCT'), ('ask', 'VERB'), ('sentiment', 'NOUN'), ('expressed', 'VERB'), ('  ', 'SPACE'), ('industry', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('Finally', 'advmod'), (',', 'punct'), ('ask', 'ROOT'), ('sentiment', 'nsubjpass'), ('expressed', 'ccomp'), ('  ', 'dobj'), ('industry', 'pobj'), ('.', 'punct')]

>> Bigrams: 
[[Finally, ,], [,, ask], [ask, sentiment], [sentiment, expressed], [expressed,   ], [  , industry], [industry, .]]

>> Trigrams: 
[[Finally, ,, ask], [,, ask, sentiment], [ask, sentiment, expressed], [sentiment, expressed,   ], [expressed,   , industry], [  , industry, .]]

>> Noun Phrases are: 
[we, any sentiment, that industry]

>> Named Entities are: 
[] 


================================ Paragraph 106 =================================

One single machine learning model can’t do all of that. You’ll need at least  four separate models:  

------------------- Sentence 1 -------------------

One single machine learning model can’t do all of that. 


>> Tokens are: 
[single, machine, learning, model, .] 

>> PoS Tags are: 
[('single', 'ADJ'), ('machine', 'NOUN'), ('learning', 'NOUN'), ('model', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('single', 'amod'), ('machine', 'compound'), ('learning', 'compound'), ('model', 'nsubj'), ('.', 'punct')]

>> Bigrams: 
[[single, machine], [machine, learning], [learning, model], [model, .]]

>> Trigrams: 
[[single, machine, learning], [machine, learning, model], [learning, model, .]]

>> Noun Phrases are: 
[One single machine learning model]

>> Named Entities are: 
[('One', 'CARDINAL')] 

------------------- Sentence 2 -------------------

You’ll need at least  four separate models: 


>> Tokens are: 
[need,  , separate, models, :] 

>> PoS Tags are: 
[('need', 'VERB'), (' ', 'SPACE'), ('separate', 'ADJ'), ('models', 'NOUN'), (':', 'PUNCT')] 

>> Dependency Tags are: 
[('need', 'ROOT'), (' ', 'dobj'), ('separate', 'amod'), ('models', 'dobj'), (':', 'punct')]

>> Bigrams: 
[[need,  ], [ , separate], [separate, models], [models, :]]

>> Trigrams: 
[[need,  , separate], [ , separate, models], [separate, models, :]]

>> Noun Phrases are: 
[You, four separate models]

>> Named Entities are: 
[('four', 'CARDINAL')] 

------------------- Sentence 3 -------------------

  


>> Tokens are: 
[ ] 

>> PoS Tags are: 
[(' ', 'SPACE')] 

>> Dependency Tags are: 
[(' ', 'ROOT')]

>> Bigrams: 
[]

>> Trigrams: 
[]

>> Noun Phrases are: 
[]

>> Named Entities are: 
[] 


================================ Paragraph 107 =================================

Identify and name any entities (Lexalytics)  

------------------- Sentence 1 -------------------

Identify and name any entities (Lexalytics) 


>> Tokens are: 
[Identify, entities, (, Lexalytics, )] 

>> PoS Tags are: 
[('Identify', 'VERB'), ('entities', 'NOUN'), ('(', 'PUNCT'), ('Lexalytics', 'PROPN'), (')', 'PUNCT')] 

>> Dependency Tags are: 
[('Identify', 'ROOT'), ('entities', 'dobj'), ('(', 'punct'), ('Lexalytics', 'appos'), (')', 'punct')]

>> Bigrams: 
[[Identify, entities], [entities, (], [(, Lexalytics], [Lexalytics, )]]

>> Trigrams: 
[[Identify, entities, (], [entities, (, Lexalytics], [(, Lexalytics, )]]

>> Noun Phrases are: 
[any entities, Lexalytics]

>> Named Entities are: 
[('Lexalytics', 'WORK_OF_ART')] 

------------------- Sentence 2 -------------------

  


>> Tokens are: 
[ ] 

>> PoS Tags are: 
[(' ', 'SPACE')] 

>> Dependency Tags are: 
[(' ', 'ROOT')]

>> Bigrams: 
[]

>> Trigrams: 
[]

>> Noun Phrases are: 
[]

>> Named Entities are: 
[] 


================================ Paragraph 108 =================================

Determine the sentiment associated with that entity (positive)  

------------------- Sentence 1 -------------------

Determine the sentiment associated with that entity (positive)   


>> Tokens are: 
[Determine, sentiment, associated, entity, (, positive, ),  ] 

>> PoS Tags are: 
[('Determine', 'VERB'), ('sentiment', 'NOUN'), ('associated', 'VERB'), ('entity', 'NOUN'), ('(', 'PUNCT'), ('positive', 'ADJ'), (')', 'PUNCT'), (' ', 'SPACE')] 

>> Dependency Tags are: 
[('Determine', 'ROOT'), ('sentiment', 'dobj'), ('associated', 'acl'), ('entity', 'pobj'), ('(', 'punct'), ('positive', 'appos'), (')', 'punct'), (' ', 'dobj')]

>> Bigrams: 
[[Determine, sentiment], [sentiment, associated], [associated, entity], [entity, (], [(, positive], [positive, )], [),  ]]

>> Trigrams: 
[[Determine, sentiment, associated], [sentiment, associated, entity], [associated, entity, (], [entity, (, positive], [(, positive, )], [positive, ),  ]]

>> Noun Phrases are: 
[the sentiment, that entity]

>> Named Entities are: 
[] 


================================ Paragraph 109 =================================

Industry classification (text analytics)  

------------------- Sentence 1 -------------------

Industry classification (text analytics)   


>> Tokens are: 
[Industry, classification, (, text, analytics, ),  ] 

>> PoS Tags are: 
[('Industry', 'NOUN'), ('classification', 'NOUN'), ('(', 'PUNCT'), ('text', 'NOUN'), ('analytics', 'NOUN'), (')', 'PUNCT'), (' ', 'SPACE')] 

>> Dependency Tags are: 
[('Industry', 'compound'), ('classification', 'ROOT'), ('(', 'punct'), ('text', 'compound'), ('analytics', 'appos'), (')', 'punct'), (' ', 'appos')]

>> Bigrams: 
[[Industry, classification], [classification, (], [(, text], [text, analytics], [analytics, )], [),  ]]

>> Trigrams: 
[[Industry, classification, (], [classification, (, text], [(, text, analytics], [text, analytics, )], [analytics, ),  ]]

>> Noun Phrases are: 
[Industry classification, (text analytics]

>> Named Entities are: 
[] 


================================ Paragraph 110 =================================

Industry sentiment (neutral) 

------------------- Sentence 1 -------------------

Industry sentiment (neutral) 


>> Tokens are: 
[Industry, sentiment, (, neutral, )] 

>> PoS Tags are: 
[('Industry', 'NOUN'), ('sentiment', 'NOUN'), ('(', 'PUNCT'), ('neutral', 'ADJ'), (')', 'PUNCT')] 

>> Dependency Tags are: 
[('Industry', 'compound'), ('sentiment', 'ROOT'), ('(', 'punct'), ('neutral', 'amod'), (')', 'punct')]

>> Bigrams: 
[[Industry, sentiment], [sentiment, (], [(, neutral], [neutral, )]]

>> Trigrams: 
[[Industry, sentiment, (], [sentiment, (, neutral], [(, neutral, )]]

>> Noun Phrases are: 
[Industry sentiment]

>> Named Entities are: 
[] 


================================ Paragraph 111 =================================

If you just train a single model, you can only solve #1 or #3. Calculating the  sentiment needed for #2 or #4 requires first knowing which entity you’re  trying to associate the sentiment with. If you only have a single model for  sentiment, you’ll end up rating the whole sentence as positive. Additionally,  if you’re only using keywords to look for the term “text analytics,” you’ll rate  this sentence as positive for that phrase, which isn’t true. Depending on what’s optimal for  

------------------- Sentence 1 -------------------

If you just train a single model, you can only solve #1 or #3. 


>> Tokens are: 
[train, single, model, ,, solve, #, 1, #, 3, .] 

>> PoS Tags are: 
[('train', 'VERB'), ('single', 'ADJ'), ('model', 'NOUN'), (',', 'PUNCT'), ('solve', 'VERB'), ('#', 'SYM'), ('1', 'NUM'), ('#', 'SYM'), ('3', 'NUM'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('train', 'advcl'), ('single', 'amod'), ('model', 'dobj'), (',', 'punct'), ('solve', 'ROOT'), ('#', 'quantmod'), ('1', 'dobj'), ('#', 'quantmod'), ('3', 'conj'), ('.', 'punct')]

>> Bigrams: 
[[train, single], [single, model], [model, ,], [,, solve], [solve, #], [#, 1], [1, #], [#, 3], [3, .]]

>> Trigrams: 
[[train, single, model], [single, model, ,], [model, ,, solve], [,, solve, #], [solve, #, 1], [#, 1, #], [1, #, 3], [#, 3, .]]

>> Noun Phrases are: 
[you, a single model, you]

>> Named Entities are: 
[('3', 'MONEY')] 

------------------- Sentence 2 -------------------

Calculating the  sentiment needed for #2 or #4 requires first knowing which entity you’re  trying to associate the sentiment with. 


>> Tokens are: 
[Calculating,  , sentiment, needed, #, 2, #, 4, requires, knowing, entity,  , trying, associate, sentiment, .] 

>> PoS Tags are: 
[('Calculating', 'VERB'), (' ', 'SPACE'), ('sentiment', 'NOUN'), ('needed', 'VERB'), ('#', 'SYM'), ('2', 'NUM'), ('#', 'SYM'), ('4', 'NUM'), ('requires', 'VERB'), ('knowing', 'VERB'), ('entity', 'NOUN'), (' ', 'SPACE'), ('trying', 'VERB'), ('associate', 'VERB'), ('sentiment', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('Calculating', 'csubj'), (' ', 'compound'), ('sentiment', 'dobj'), ('needed', 'csubj'), ('#', 'quantmod'), ('2', 'pobj'), ('#', 'quantmod'), ('4', 'conj'), ('requires', 'ROOT'), ('knowing', 'xcomp'), ('entity', 'ccomp'), (' ', 'nsubj'), ('trying', 'ccomp'), ('associate', 'xcomp'), ('sentiment', 'dobj'), ('.', 'punct')]

>> Bigrams: 
[[Calculating,  ], [ , sentiment], [sentiment, needed], [needed, #], [#, 2], [2, #], [#, 4], [4, requires], [requires, knowing], [knowing, entity], [entity,  ], [ , trying], [trying, associate], [associate, sentiment], [sentiment, .]]

>> Trigrams: 
[[Calculating,  , sentiment], [ , sentiment, needed], [sentiment, needed, #], [needed, #, 2], [#, 2, #], [2, #, 4], [#, 4, requires], [4, requires, knowing], [requires, knowing, entity], [knowing, entity,  ], [entity,  , trying], [ , trying, associate], [trying, associate, sentiment], [associate, sentiment, .]]

>> Noun Phrases are: 
[the  sentiment, you, the sentiment]

>> Named Entities are: 
[('first', 'ORDINAL')] 

------------------- Sentence 3 -------------------

If you only have a single model for  sentiment, you’ll end up rating the whole sentence as positive. 


>> Tokens are: 
[single, model,  , sentiment, ,, end, rating, sentence, positive, .] 

>> PoS Tags are: 
[('single', 'ADJ'), ('model', 'NOUN'), (' ', 'SPACE'), ('sentiment', 'NOUN'), (',', 'PUNCT'), ('end', 'VERB'), ('rating', 'VERB'), ('sentence', 'NOUN'), ('positive', 'ADJ'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('single', 'amod'), ('model', 'dobj'), (' ', 'compound'), ('sentiment', 'pobj'), (',', 'punct'), ('end', 'ROOT'), ('rating', 'xcomp'), ('sentence', 'dobj'), ('positive', 'amod'), ('.', 'punct')]

>> Bigrams: 
[[single, model], [model,  ], [ , sentiment], [sentiment, ,], [,, end], [end, rating], [rating, sentence], [sentence, positive], [positive, .]]

>> Trigrams: 
[[single, model,  ], [model,  , sentiment], [ , sentiment, ,], [sentiment, ,, end], [,, end, rating], [end, rating, sentence], [rating, sentence, positive], [sentence, positive, .]]

>> Noun Phrases are: 
[you, a single model,  sentiment, you, the whole sentence]

>> Named Entities are: 
[] 

------------------- Sentence 4 -------------------

Additionally,  if you’re only using keywords to look for the term “text analytics,” you’ll rate  this sentence as positive for that phrase, which isn’t true. 


>> Tokens are: 
[Additionally, ,,  , keywords, look, term, “, text, analytics, ,, ”, rate,  , sentence, positive, phrase, ,, true, .] 

>> PoS Tags are: 
[('Additionally', 'ADV'), (',', 'PUNCT'), (' ', 'SPACE'), ('keywords', 'NOUN'), ('look', 'VERB'), ('term', 'NOUN'), ('“', 'PUNCT'), ('text', 'NOUN'), ('analytics', 'NOUN'), (',', 'PUNCT'), ('”', 'PUNCT'), ('rate', 'VERB'), (' ', 'SPACE'), ('sentence', 'NOUN'), ('positive', 'ADJ'), ('phrase', 'NOUN'), (',', 'PUNCT'), ('true', 'ADJ'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('Additionally', 'advmod'), (',', 'punct'), (' ', 'npadvmod'), ('keywords', 'dobj'), ('look', 'xcomp'), ('term', 'nmod'), ('“', 'punct'), ('text', 'compound'), ('analytics', 'pobj'), (',', 'punct'), ('”', 'punct'), ('rate', 'ROOT'), (' ', 'dobj'), ('sentence', 'dobj'), ('positive', 'amod'), ('phrase', 'pobj'), (',', 'punct'), ('true', 'acomp'), ('.', 'punct')]

>> Bigrams: 
[[Additionally, ,], [,,  ], [ , keywords], [keywords, look], [look, term], [term, “], [“, text], [text, analytics], [analytics, ,], [,, ”], [”, rate], [rate,  ], [ , sentence], [sentence, positive], [positive, phrase], [phrase, ,], [,, true], [true, .]]

>> Trigrams: 
[[Additionally, ,,  ], [,,  , keywords], [ , keywords, look], [keywords, look, term], [look, term, “], [term, “, text], [“, text, analytics], [text, analytics, ,], [analytics, ,, ”], [,, ”, rate], [”, rate,  ], [rate,  , sentence], [ , sentence, positive], [sentence, positive, phrase], [positive, phrase, ,], [phrase, ,, true], [,, true, .]]

>> Noun Phrases are: 
[you, keywords, the term “text analytics, you, this sentence, that phrase]

>> Named Entities are: 
[] 

------------------- Sentence 5 -------------------

Depending on what’s optimal for   


>> Tokens are: 
[Depending, optimal,  ] 

>> PoS Tags are: 
[('Depending', 'VERB'), ('optimal', 'ADJ'), (' ', 'SPACE')] 

>> Dependency Tags are: 
[('Depending', 'ROOT'), ('optimal', 'acomp'), (' ', 'pobj')]

>> Bigrams: 
[[Depending, optimal], [optimal,  ]]

>> Trigrams: 
[[Depending, optimal,  ]]

>> Noun Phrases are: 
[what]

>> Named Entities are: 
[] 


================================ Paragraph 112 =================================

the language, each of these steps is  machine learning or NLP code. 

------------------- Sentence 1 -------------------

the language, 


>> Tokens are: 
[language, ,] 

>> PoS Tags are: 
[('language', 'NOUN'), (',', 'PUNCT')] 

>> Dependency Tags are: 
[('language', 'ROOT'), (',', 'punct')]

>> Bigrams: 
[[language, ,]]

>> Trigrams: 
[]

>> Noun Phrases are: 
[the language]

>> Named Entities are: 
[] 

------------------- Sentence 2 -------------------

each of these steps is  machine learning or NLP code. 


>> Tokens are: 
[steps,  , machine, learning, NLP, code, .] 

>> PoS Tags are: 
[('steps', 'NOUN'), (' ', 'SPACE'), ('machine', 'NOUN'), ('learning', 'NOUN'), ('NLP', 'PROPN'), ('code', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('steps', 'pobj'), (' ', 'attr'), ('machine', 'compound'), ('learning', 'attr'), ('NLP', 'compound'), ('code', 'conj'), ('.', 'punct')]

>> Bigrams: 
[[steps,  ], [ , machine], [machine, learning], [learning, NLP], [NLP, code], [code, .]]

>> Trigrams: 
[[steps,  , machine], [ , machine, learning], [machine, learning, NLP], [learning, NLP, code], [NLP, code, .]]

>> Noun Phrases are: 
[these steps, machine learning, NLP code]

>> Named Entities are: 
[('NLP', 'ORG')] 


================================ Paragraph 113 =================================

TOKENS 

------------------- Sentence 1 -------------------

TOKENS 


>> Tokens are: 
[TOKENS] 

>> PoS Tags are: 
[('TOKENS', 'ADJ')] 

>> Dependency Tags are: 
[('TOKENS', 'ROOT')]

>> Bigrams: 
[]

>> Trigrams: 
[]

>> Noun Phrases are: 
[]

>> Named Entities are: 
[] 


================================ Paragraph 114 =================================

PHRASES 

------------------- Sentence 1 -------------------

PHRASES 


>> Tokens are: 
[PHRASES] 

>> PoS Tags are: 
[('PHRASES', 'NOUN')] 

>> Dependency Tags are: 
[('PHRASES', 'ROOT')]

>> Bigrams: 
[]

>> Trigrams: 
[]

>> Noun Phrases are: 
[PHRASES]

>> Named Entities are: 
[] 


================================ Paragraph 115 =================================

SYNTAX  TREES 

------------------- Sentence 1 -------------------

SYNTAX  TREES 


>> Tokens are: 
[SYNTAX,  , TREES] 

>> PoS Tags are: 
[('SYNTAX', 'PROPN'), (' ', 'SPACE'), ('TREES', 'PROPN')] 

>> Dependency Tags are: 
[('SYNTAX', 'ROOT'), (' ', 'appos'), ('TREES', 'appos')]

>> Bigrams: 
[[SYNTAX,  ], [ , TREES]]

>> Trigrams: 
[[SYNTAX,  , TREES]]

>> Noun Phrases are: 
[SYNTAX, TREES]

>> Named Entities are: 
[('SYNTAX', 'ORG')] 


================================ Paragraph 116 =================================

SENTENCES 

------------------- Sentence 1 -------------------

SENTENCES 


>> Tokens are: 
[SENTENCES] 

>> PoS Tags are: 
[('SENTENCES', 'NOUN')] 

>> Dependency Tags are: 
[('SENTENCES', 'ROOT')]

>> Bigrams: 
[]

>> Trigrams: 
[]

>> Noun Phrases are: 
[SENTENCES]

>> Named Entities are: 
[] 


================================ Paragraph 117 =================================

text  parsing (NLP) 

------------------- Sentence 1 -------------------

text  parsing (NLP) 


>> Tokens are: 
[text,  , parsing, (, NLP, )] 

>> PoS Tags are: 
[('text', 'NOUN'), (' ', 'SPACE'), ('parsing', 'VERB'), ('(', 'PUNCT'), ('NLP', 'PROPN'), (')', 'PUNCT')] 

>> Dependency Tags are: 
[('text', 'npadvmod'), (' ', 'punct'), ('parsing', 'ROOT'), ('(', 'punct'), ('NLP', 'dobj'), (')', 'punct')]

>> Bigrams: 
[[text,  ], [ , parsing], [parsing, (], [(, NLP], [NLP, )]]

>> Trigrams: 
[[text,  , parsing], [ , parsing, (], [parsing, (, NLP], [(, NLP, )]]

>> Noun Phrases are: 
[(NLP]

>> Named Entities are: 
[('NLP', 'ORG')] 


================================ Paragraph 118 =================================

PARTS  OF SPEECH 

------------------- Sentence 1 -------------------

PARTS  OF SPEECH 


>> Tokens are: 
[PARTS,  , SPEECH] 

>> PoS Tags are: 
[('PARTS', 'PROPN'), (' ', 'SPACE'), ('SPEECH', 'PROPN')] 

>> Dependency Tags are: 
[('PARTS', 'ROOT'), (' ', 'appos'), ('SPEECH', 'pobj')]

>> Bigrams: 
[[PARTS,  ], [ , SPEECH]]

>> Trigrams: 
[[PARTS,  , SPEECH]]

>> Noun Phrases are: 
[PARTS, SPEECH]

>> Named Entities are: 
[] 


================================ Paragraph 119 =================================

SEMANTIC  RELATIONSHIPS

------------------- Sentence 1 -------------------

SEMANTIC  RELATIONSHIPS 


>> Tokens are: 
[SEMANTIC,  , RELATIONSHIPS] 

>> PoS Tags are: 
[('SEMANTIC', 'ADJ'), (' ', 'SPACE'), ('RELATIONSHIPS', 'NOUN')] 

>> Dependency Tags are: 
[('SEMANTIC', 'amod'), (' ', 'nummod'), ('RELATIONSHIPS', 'ROOT')]

>> Bigrams: 
[[SEMANTIC,  ], [ , RELATIONSHIPS]]

>> Trigrams: 
[[SEMANTIC,  , RELATIONSHIPS]]

>> Noun Phrases are: 
[SEMANTIC  RELATIONSHIPS]

>> Named Entities are: 
[] 


================================ Paragraph 120 =================================

W H I T E  P A P E R 

------------------- Sentence 1 -------------------

W H 


>> Tokens are: 
[W, H] 

>> PoS Tags are: 
[('W', 'NOUN'), ('H', 'NOUN')] 

>> Dependency Tags are: 
[('W', 'compound'), ('H', 'ROOT')]

>> Bigrams: 
[[W, H]]

>> Trigrams: 
[]

>> Noun Phrases are: 
[W H]

>> Named Entities are: 
[] 

------------------- Sentence 2 -------------------

I T 


>> Tokens are: 
[T] 

>> PoS Tags are: 
[('T', 'NOUN')] 

>> Dependency Tags are: 
[('T', 'appos')]

>> Bigrams: 
[]

>> Trigrams: 
[]

>> Noun Phrases are: 
[I, T]

>> Named Entities are: 
[] 

------------------- Sentence 3 -------------------

E   


>> Tokens are: 
[E,  ] 

>> PoS Tags are: 
[('E', 'NOUN'), (' ', 'SPACE')] 

>> Dependency Tags are: 
[('E', 'ROOT'), (' ', 'appos')]

>> Bigrams: 
[[E,  ]]

>> Trigrams: 
[]

>> Noun Phrases are: 
[E]

>> Named Entities are: 
[] 

------------------- Sentence 4 -------------------

P A P E R 


>> Tokens are: 
[P, P, E, R] 

>> PoS Tags are: 
[('P', 'NOUN'), ('P', 'NOUN'), ('E', 'NOUN'), ('R', 'NOUN')] 

>> Dependency Tags are: 
[('P', 'compound'), ('P', 'compound'), ('E', 'compound'), ('R', 'ROOT')]

>> Bigrams: 
[[P, P], [P, E], [E, R]]

>> Trigrams: 
[[P, P, E], [P, E, R]]

>> Noun Phrases are: 
[P A P E R]

>> Named Entities are: 
[] 


================================ Paragraph 121 =================================

8|       |   Lexalytics, Inc., 48 North Pleasant St. Unit 301, Amherst MA 01002 USA   |   1-800-377-8036 |   www.lexalytics.com 

------------------- Sentence 1 -------------------

8|       |   Lexalytics, Inc., 48 North Pleasant St. Unit 301, Amherst MA 01002 


>> Tokens are: 
[8|,       , |,   , Lexalytics, ,, Inc., ,, 48, North, Pleasant, St., Unit, 301, ,, Amherst, MA, 01002] 

>> PoS Tags are: 
[('8|', 'NUM'), ('      ', 'SPACE'), ('|', 'NOUN'), ('  ', 'SPACE'), ('Lexalytics', 'PROPN'), (',', 'PUNCT'), ('Inc.', 'PROPN'), (',', 'PUNCT'), ('48', 'NUM'), ('North', 'PROPN'), ('Pleasant', 'PROPN'), ('St.', 'PROPN'), ('Unit', 'PROPN'), ('301', 'NUM'), (',', 'PUNCT'), ('Amherst', 'PROPN'), ('MA', 'PROPN'), ('01002', 'NUM')] 

>> Dependency Tags are: 
[('8|', 'nummod'), ('      ', 'compound'), ('|', 'ROOT'), ('  ', 'nmod'), ('Lexalytics', 'nmod'), (',', 'punct'), ('Inc.', 'appos'), (',', 'punct'), ('48', 'nummod'), ('North', 'compound'), ('Pleasant', 'compound'), ('St.', 'compound'), ('Unit', 'appos'), ('301', 'nummod'), (',', 'punct'), ('Amherst', 'compound'), ('MA', 'appos'), ('01002', 'punct')]

>> Bigrams: 
[[8|,       ], [      , |], [|,   ], [  , Lexalytics], [Lexalytics, ,], [,, Inc.], [Inc., ,], [,, 48], [48, North], [North, Pleasant], [Pleasant, St.], [St., Unit], [Unit, 301], [301, ,], [,, Amherst], [Amherst, MA], [MA, 01002]]

>> Trigrams: 
[[8|,       , |], [      , |,   ], [|,   , Lexalytics], [  , Lexalytics, ,], [Lexalytics, ,, Inc.], [,, Inc., ,], [Inc., ,, 48], [,, 48, North], [48, North, Pleasant], [North, Pleasant, St.], [Pleasant, St., Unit], [St., Unit, 301], [Unit, 301, ,], [301, ,, Amherst], [,, Amherst, MA], [Amherst, MA, 01002]]

>> Noun Phrases are: 
[8|       |,   Lexalytics, Inc., 48 North Pleasant St. Unit, Amherst MA]

>> Named Entities are: 
[('Lexalytics, Inc.', 'ORG'), ('48', 'CARDINAL'), ('North Pleasant St. Unit 301', 'ORG'), ('Amherst MA', 'ORG')] 

------------------- Sentence 2 -------------------

USA 


>> Tokens are: 
[USA] 

>> PoS Tags are: 
[('USA', 'PROPN')] 

>> Dependency Tags are: 
[('USA', 'ROOT')]

>> Bigrams: 
[]

>> Trigrams: 
[]

>> Noun Phrases are: 
[USA]

>> Named Entities are: 
[] 

------------------- Sentence 3 -------------------

  |   1-800-377-8036 |   www.lexalytics.com 


>> Tokens are: 
[  , |,   , 1, -, 800, -, 377, -, 8036, |,   , www.lexalytics.com] 

>> PoS Tags are: 
[('  ', 'SPACE'), ('|', 'NOUN'), ('  ', 'SPACE'), ('1', 'NUM'), ('-', 'SYM'), ('800', 'NUM'), ('-', 'NUM'), ('377', 'NUM'), ('-', 'PUNCT'), ('8036', 'NUM'), ('|', 'NOUN'), ('  ', 'SPACE'), ('www.lexalytics.com', 'X')] 

>> Dependency Tags are: 
[('  ', 'compound'), ('|', 'npadvmod'), ('  ', 'dep'), ('1', 'npadvmod'), ('-', 'punct'), ('800', 'prep'), ('-', 'punct'), ('377', 'nummod'), ('-', 'punct'), ('8036', 'nummod'), ('|', 'npadvmod'), ('  ', 'ROOT'), ('www.lexalytics.com', 'punct')]

>> Bigrams: 
[[  , |], [|,   ], [  , 1], [1, -], [-, 800], [800, -], [-, 377], [377, -], [-, 8036], [8036, |], [|,   ], [  , www.lexalytics.com]]

>> Trigrams: 
[[  , |,   ], [|,   , 1], [  , 1, -], [1, -, 800], [-, 800, -], [800, -, 377], [-, 377, -], [377, -, 8036], [-, 8036, |], [8036, |,   ], [|,   , www.lexalytics.com]]

>> Noun Phrases are: 
[]

>> Named Entities are: 
[] 


================================ Paragraph 122 =================================

Not only do you need at least four models to solve this task, but these  models are interdependent and have to interact with each other. To   create this kind of multi-model solution, we developed proprietary   AI building software.  

------------------- Sentence 1 -------------------

Not only do you need at least four models to solve this task, but these  models are interdependent and have to interact with each other. 


>> Tokens are: 
[need, models, solve, task, ,,  , models, interdependent, interact, .] 

>> PoS Tags are: 
[('need', 'VERB'), ('models', 'NOUN'), ('solve', 'VERB'), ('task', 'NOUN'), (',', 'PUNCT'), (' ', 'SPACE'), ('models', 'NOUN'), ('interdependent', 'ADJ'), ('interact', 'VERB'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('need', 'ROOT'), ('models', 'dobj'), ('solve', 'relcl'), ('task', 'dobj'), (',', 'punct'), (' ', 'compound'), ('models', 'nsubj'), ('interdependent', 'acomp'), ('interact', 'xcomp'), ('.', 'punct')]

>> Bigrams: 
[[need, models], [models, solve], [solve, task], [task, ,], [,,  ], [ , models], [models, interdependent], [interdependent, interact], [interact, .]]

>> Trigrams: 
[[need, models, solve], [models, solve, task], [solve, task, ,], [task, ,,  ], [,,  , models], [ , models, interdependent], [models, interdependent, interact], [interdependent, interact, .]]

>> Noun Phrases are: 
[you, at least four models, this task, these  models]

>> Named Entities are: 
[('at least four', 'CARDINAL')] 

------------------- Sentence 2 -------------------

To   create this kind of multi-model solution, we developed proprietary   AI building software. 


>> Tokens are: 
[  , create, kind, multi, -, model, solution, ,, developed, proprietary,   , AI, building, software, .] 

>> PoS Tags are: 
[('  ', 'SPACE'), ('create', 'VERB'), ('kind', 'NOUN'), ('multi', 'ADJ'), ('-', 'ADJ'), ('model', 'ADJ'), ('solution', 'NOUN'), (',', 'PUNCT'), ('developed', 'VERB'), ('proprietary', 'ADJ'), ('  ', 'SPACE'), ('AI', 'PROPN'), ('building', 'NOUN'), ('software', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('  ', 'pobj'), ('create', 'advcl'), ('kind', 'dobj'), ('multi', 'amod'), ('-', 'amod'), ('model', 'amod'), ('solution', 'pobj'), (',', 'punct'), ('developed', 'ROOT'), ('proprietary', 'amod'), ('  ', 'nummod'), ('AI', 'compound'), ('building', 'compound'), ('software', 'dobj'), ('.', 'punct')]

>> Bigrams: 
[[  , create], [create, kind], [kind, multi], [multi, -], [-, model], [model, solution], [solution, ,], [,, developed], [developed, proprietary], [proprietary,   ], [  , AI], [AI, building], [building, software], [software, .]]

>> Trigrams: 
[[  , create, kind], [create, kind, multi], [kind, multi, -], [multi, -, model], [-, model, solution], [model, solution, ,], [solution, ,, developed], [,, developed, proprietary], [developed, proprietary,   ], [proprietary,   , AI], [  , AI, building], [AI, building, software], [building, software, .]]

>> Noun Phrases are: 
[this kind, multi-model solution, we, proprietary   AI building software]

>> Named Entities are: 
[] 

------------------- Sentence 3 -------------------

  


>> Tokens are: 
[ ] 

>> PoS Tags are: 
[(' ', 'SPACE')] 

>> Dependency Tags are: 
[(' ', 'ROOT')]

>> Bigrams: 
[]

>> Trigrams: 
[]

>> Noun Phrases are: 
[]

>> Named Entities are: 
[] 


================================ Paragraph 123 =================================

This tool, “AI Assembler,” is used to build our features like sentiment,   named entity extraction, intention analysis and more. We also use AI  Assembler to build custom machine learning models used by our customers  and partners. Among other things, AI Assembler manages dependencies  between models, allowing us to easily upgrade one model and then   re-build other models as necessary. 

------------------- Sentence 1 -------------------

This tool, “AI Assembler,” is used to build our features like sentiment,   named entity extraction, intention analysis and more. 


>> Tokens are: 
[tool, ,, “, AI, Assembler, ,, ”, build, features, like, sentiment, ,,   , named, entity, extraction, ,, intention, analysis, .] 

>> PoS Tags are: 
[('tool', 'NOUN'), (',', 'PUNCT'), ('“', 'PUNCT'), ('AI', 'PROPN'), ('Assembler', 'PROPN'), (',', 'PUNCT'), ('”', 'PUNCT'), ('build', 'VERB'), ('features', 'NOUN'), ('like', 'ADP'), ('sentiment', 'NOUN'), (',', 'PUNCT'), ('  ', 'SPACE'), ('named', 'VERB'), ('entity', 'NOUN'), ('extraction', 'NOUN'), (',', 'PUNCT'), ('intention', 'NOUN'), ('analysis', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('tool', 'nsubjpass'), (',', 'punct'), ('“', 'punct'), ('AI', 'compound'), ('Assembler', 'appos'), (',', 'punct'), ('”', 'punct'), ('build', 'xcomp'), ('features', 'dobj'), ('like', 'prep'), ('sentiment', 'pobj'), (',', 'punct'), ('  ', 'nsubj'), ('named', 'ROOT'), ('entity', 'compound'), ('extraction', 'dobj'), (',', 'punct'), ('intention', 'compound'), ('analysis', 'conj'), ('.', 'punct')]

>> Bigrams: 
[[tool, ,], [,, “], [“, AI], [AI, Assembler], [Assembler, ,], [,, ”], [”, build], [build, features], [features, like], [like, sentiment], [sentiment, ,], [,,   ], [  , named], [named, entity], [entity, extraction], [extraction, ,], [,, intention], [intention, analysis], [analysis, .]]

>> Trigrams: 
[[tool, ,, “], [,, “, AI], [“, AI, Assembler], [AI, Assembler, ,], [Assembler, ,, ”], [,, ”, build], [”, build, features], [build, features, like], [features, like, sentiment], [like, sentiment, ,], [sentiment, ,,   ], [,,   , named], [  , named, entity], [named, entity, extraction], [entity, extraction, ,], [extraction, ,, intention], [,, intention, analysis], [intention, analysis, .]]

>> Noun Phrases are: 
[This tool, , “AI Assembler, our features, sentiment, entity extraction, intention analysis]

>> Named Entities are: 
[('AI Assembler', 'PERSON')] 

------------------- Sentence 2 -------------------

We also use AI  Assembler to build custom machine learning models used by our customers  and partners. 


>> Tokens are: 
[use, AI,  , Assembler, build, custom, machine, learning, models, customers,  , partners, .] 

>> PoS Tags are: 
[('use', 'VERB'), ('AI', 'PROPN'), (' ', 'SPACE'), ('Assembler', 'PROPN'), ('build', 'VERB'), ('custom', 'NOUN'), ('machine', 'NOUN'), ('learning', 'NOUN'), ('models', 'NOUN'), ('customers', 'NOUN'), (' ', 'SPACE'), ('partners', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('use', 'ROOT'), ('AI', 'compound'), (' ', 'compound'), ('Assembler', 'dobj'), ('build', 'xcomp'), ('custom', 'compound'), ('machine', 'compound'), ('learning', 'compound'), ('models', 'dobj'), ('customers', 'pobj'), (' ', 'appos'), ('partners', 'conj'), ('.', 'punct')]

>> Bigrams: 
[[use, AI], [AI,  ], [ , Assembler], [Assembler, build], [build, custom], [custom, machine], [machine, learning], [learning, models], [models, customers], [customers,  ], [ , partners], [partners, .]]

>> Trigrams: 
[[use, AI,  ], [AI,  , Assembler], [ , Assembler, build], [Assembler, build, custom], [build, custom, machine], [custom, machine, learning], [machine, learning, models], [learning, models, customers], [models, customers,  ], [customers,  , partners], [ , partners, .]]

>> Noun Phrases are: 
[We, AI  Assembler, custom machine learning models, our customers, partners]

>> Named Entities are: 
[('AI', 'ORG')] 

------------------- Sentence 3 -------------------

Among other things, AI Assembler manages dependencies  between models, allowing us to easily upgrade one model and then   re-build other models as necessary. 


>> Tokens are: 
[things, ,, AI, Assembler, manages, dependencies,  , models, ,, allowing, easily, upgrade, model,   , -, build, models, necessary, .] 

>> PoS Tags are: 
[('things', 'NOUN'), (',', 'PUNCT'), ('AI', 'PROPN'), ('Assembler', 'PROPN'), ('manages', 'VERB'), ('dependencies', 'NOUN'), (' ', 'SPACE'), ('models', 'NOUN'), (',', 'PUNCT'), ('allowing', 'VERB'), ('easily', 'ADV'), ('upgrade', 'VERB'), ('model', 'NOUN'), ('  ', 'SPACE'), ('-', 'VERB'), ('build', 'VERB'), ('models', 'NOUN'), ('necessary', 'ADJ'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('things', 'pobj'), (',', 'punct'), ('AI', 'compound'), ('Assembler', 'nsubj'), ('manages', 'ROOT'), ('dependencies', 'dobj'), (' ', 'nummod'), ('models', 'pobj'), (',', 'punct'), ('allowing', 'advcl'), ('easily', 'advmod'), ('upgrade', 'ccomp'), ('model', 'dobj'), ('  ', 'nsubj'), ('-', 'xcomp'), ('build', 'xcomp'), ('models', 'dobj'), ('necessary', 'amod'), ('.', 'punct')]

>> Bigrams: 
[[things, ,], [,, AI], [AI, Assembler], [Assembler, manages], [manages, dependencies], [dependencies,  ], [ , models], [models, ,], [,, allowing], [allowing, easily], [easily, upgrade], [upgrade, model], [model,   ], [  , -], [-, build], [build, models], [models, necessary], [necessary, .]]

>> Trigrams: 
[[things, ,, AI], [,, AI, Assembler], [AI, Assembler, manages], [Assembler, manages, dependencies], [manages, dependencies,  ], [dependencies,  , models], [ , models, ,], [models, ,, allowing], [,, allowing, easily], [allowing, easily, upgrade], [easily, upgrade, model], [upgrade, model,   ], [model,   , -], [  , -, build], [-, build, models], [build, models, necessary], [models, necessary, .]]

>> Noun Phrases are: 
[other things, AI Assembler, dependencies, models, us, one model, other models]

>> Named Entities are: 
[('AI Assembler', 'ORG')] 


================================ Paragraph 124 =================================

Multi-level granular sentiment analysis is difficult due to the model complexity   and dependencies. Lexalytics is one of the few companies that actually  provides this service – most companies simply provide document sentiment  and call it done. Truth is, solving for entity and category sentiment is very  difficult, and multiplies the amount of work required. We do it because our  customers are making business critical decisions, and they need context-rich  insights to make informed decisions that drive business growth. 

------------------- Sentence 1 -------------------

Multi-level granular sentiment analysis is difficult due to the model complexity   and dependencies. 


>> Tokens are: 
[Multi, -, level, granular, sentiment, analysis, difficult, model, complexity,   , dependencies, .] 

>> PoS Tags are: 
[('Multi', 'ADJ'), ('-', 'ADJ'), ('level', 'ADJ'), ('granular', 'ADJ'), ('sentiment', 'NOUN'), ('analysis', 'NOUN'), ('difficult', 'ADJ'), ('model', 'NOUN'), ('complexity', 'NOUN'), ('  ', 'SPACE'), ('dependencies', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('Multi', 'amod'), ('-', 'amod'), ('level', 'amod'), ('granular', 'amod'), ('sentiment', 'compound'), ('analysis', 'nsubj'), ('difficult', 'acomp'), ('model', 'compound'), ('complexity', 'compound'), ('  ', 'pobj'), ('dependencies', 'conj'), ('.', 'punct')]

>> Bigrams: 
[[Multi, -], [-, level], [level, granular], [granular, sentiment], [sentiment, analysis], [analysis, difficult], [difficult, model], [model, complexity], [complexity,   ], [  , dependencies], [dependencies, .]]

>> Trigrams: 
[[Multi, -, level], [-, level, granular], [level, granular, sentiment], [granular, sentiment, analysis], [sentiment, analysis, difficult], [analysis, difficult, model], [difficult, model, complexity], [model, complexity,   ], [complexity,   , dependencies], [  , dependencies, .]]

>> Noun Phrases are: 
[Multi-level granular sentiment analysis, dependencies]

>> Named Entities are: 
[] 

------------------- Sentence 2 -------------------

Lexalytics is one of the few companies that actually  provides this service – most companies simply provide document sentiment  and call it done. 


>> Tokens are: 
[Lexalytics, companies, actually,  , provides, service, –, companies, simply, provide, document, sentiment,  , .] 

>> PoS Tags are: 
[('Lexalytics', 'PROPN'), ('companies', 'NOUN'), ('actually', 'ADV'), (' ', 'SPACE'), ('provides', 'VERB'), ('service', 'NOUN'), ('–', 'PUNCT'), ('companies', 'NOUN'), ('simply', 'ADV'), ('provide', 'VERB'), ('document', 'NOUN'), ('sentiment', 'NOUN'), (' ', 'SPACE'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('Lexalytics', 'nsubj'), ('companies', 'pobj'), ('actually', 'advmod'), (' ', 'nsubj'), ('provides', 'relcl'), ('service', 'dobj'), ('–', 'punct'), ('companies', 'nsubj'), ('simply', 'advmod'), ('provide', 'ROOT'), ('document', 'compound'), ('sentiment', 'dobj'), (' ', 'appos'), ('.', 'punct')]

>> Bigrams: 
[[Lexalytics, companies], [companies, actually], [actually,  ], [ , provides], [provides, service], [service, –], [–, companies], [companies, simply], [simply, provide], [provide, document], [document, sentiment], [sentiment,  ], [ , .]]

>> Trigrams: 
[[Lexalytics, companies, actually], [companies, actually,  ], [actually,  , provides], [ , provides, service], [provides, service, –], [service, –, companies], [–, companies, simply], [companies, simply, provide], [simply, provide, document], [provide, document, sentiment], [document, sentiment,  ], [sentiment,  , .]]

>> Noun Phrases are: 
[Lexalytics, the few companies, this service, most companies, document sentiment, it]

>> Named Entities are: 
[] 

------------------- Sentence 3 -------------------

Truth is, solving for entity and category sentiment is very  difficult, and multiplies the amount of work required. 


>> Tokens are: 
[Truth, ,, solving, entity, category, sentiment,  , difficult, ,, multiplies, work, required, .] 

>> PoS Tags are: 
[('Truth', 'NOUN'), (',', 'PUNCT'), ('solving', 'VERB'), ('entity', 'NOUN'), ('category', 'NOUN'), ('sentiment', 'NOUN'), (' ', 'SPACE'), ('difficult', 'ADJ'), (',', 'PUNCT'), ('multiplies', 'VERB'), ('work', 'NOUN'), ('required', 'VERB'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('Truth', 'nsubj'), (',', 'punct'), ('solving', 'advcl'), ('entity', 'nmod'), ('category', 'conj'), ('sentiment', 'pobj'), (' ', 'npadvmod'), ('difficult', 'acomp'), (',', 'punct'), ('multiplies', 'conj'), ('work', 'pobj'), ('required', 'acl'), ('.', 'punct')]

>> Bigrams: 
[[Truth, ,], [,, solving], [solving, entity], [entity, category], [category, sentiment], [sentiment,  ], [ , difficult], [difficult, ,], [,, multiplies], [multiplies, work], [work, required], [required, .]]

>> Trigrams: 
[[Truth, ,, solving], [,, solving, entity], [solving, entity, category], [entity, category, sentiment], [category, sentiment,  ], [sentiment,  , difficult], [ , difficult, ,], [difficult, ,, multiplies], [,, multiplies, work], [multiplies, work, required], [work, required, .]]

>> Noun Phrases are: 
[Truth, entity and category sentiment, the amount, work]

>> Named Entities are: 
[] 

------------------- Sentence 4 -------------------

We do it because our  customers are making business critical decisions, and they need context-rich  insights to make informed decisions that drive business growth. 


>> Tokens are: 
[ , customers, making, business, critical, decisions, ,, need, context, -, rich,  , insights, informed, decisions, drive, business, growth, .] 

>> PoS Tags are: 
[(' ', 'SPACE'), ('customers', 'NOUN'), ('making', 'VERB'), ('business', 'NOUN'), ('critical', 'ADJ'), ('decisions', 'NOUN'), (',', 'PUNCT'), ('need', 'VERB'), ('context', 'NOUN'), ('-', 'PUNCT'), ('rich', 'ADJ'), (' ', 'SPACE'), ('insights', 'NOUN'), ('informed', 'ADJ'), ('decisions', 'NOUN'), ('drive', 'VERB'), ('business', 'NOUN'), ('growth', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[(' ', 'compound'), ('customers', 'nsubj'), ('making', 'advcl'), ('business', 'nmod'), ('critical', 'amod'), ('decisions', 'dobj'), (',', 'punct'), ('need', 'conj'), ('context', 'npadvmod'), ('-', 'punct'), ('rich', 'amod'), (' ', 'compound'), ('insights', 'dobj'), ('informed', 'amod'), ('decisions', 'dobj'), ('drive', 'relcl'), ('business', 'compound'), ('growth', 'dobj'), ('.', 'punct')]

>> Bigrams: 
[[ , customers], [customers, making], [making, business], [business, critical], [critical, decisions], [decisions, ,], [,, need], [need, context], [context, -], [-, rich], [rich,  ], [ , insights], [insights, informed], [informed, decisions], [decisions, drive], [drive, business], [business, growth], [growth, .]]

>> Trigrams: 
[[ , customers, making], [customers, making, business], [making, business, critical], [business, critical, decisions], [critical, decisions, ,], [decisions, ,, need], [,, need, context], [need, context, -], [context, -, rich], [-, rich,  ], [rich,  , insights], [ , insights, informed], [insights, informed, decisions], [informed, decisions, drive], [decisions, drive, business], [drive, business, growth], [business, growth, .]]

>> Noun Phrases are: 
[We, it, our  customers, business critical decisions, they, context-rich  insights, informed decisions, business growth]

>> Named Entities are: 
[] 


================================ Paragraph 125 =================================

To borrow from another industry, imagine if you have a wonderful spy  satellite. Do you want to just be able to say, “There are a bunch of people  there” or, “There’s a known terrorist there, and he’s holding a gun?” 

------------------- Sentence 1 -------------------

To borrow from another industry, imagine if you have a wonderful spy  satellite. 


>> Tokens are: 
[borrow, industry, ,, imagine, wonderful, spy,  , satellite, .] 

>> PoS Tags are: 
[('borrow', 'VERB'), ('industry', 'NOUN'), (',', 'PUNCT'), ('imagine', 'VERB'), ('wonderful', 'ADJ'), ('spy', 'NOUN'), (' ', 'SPACE'), ('satellite', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('borrow', 'advcl'), ('industry', 'pobj'), (',', 'punct'), ('imagine', 'ROOT'), ('wonderful', 'amod'), ('spy', 'nmod'), (' ', 'nummod'), ('satellite', 'dobj'), ('.', 'punct')]

>> Bigrams: 
[[borrow, industry], [industry, ,], [,, imagine], [imagine, wonderful], [wonderful, spy], [spy,  ], [ , satellite], [satellite, .]]

>> Trigrams: 
[[borrow, industry, ,], [industry, ,, imagine], [,, imagine, wonderful], [imagine, wonderful, spy], [wonderful, spy,  ], [spy,  , satellite], [ , satellite, .]]

>> Noun Phrases are: 
[another industry, you, a wonderful spy  satellite]

>> Named Entities are: 
[] 

------------------- Sentence 2 -------------------

Do you want to just be able to say, “There are a bunch of people  there” or, “There’s a known terrorist there, and he’s holding a gun?” 


>> Tokens are: 
[want, able, ,, “, bunch, people,  , ”, ,, “, known, terrorist, ,, holding, gun, ?, ”] 

>> PoS Tags are: 
[('want', 'VERB'), ('able', 'ADJ'), (',', 'PUNCT'), ('“', 'PUNCT'), ('bunch', 'NOUN'), ('people', 'NOUN'), (' ', 'SPACE'), ('”', 'PUNCT'), (',', 'PUNCT'), ('“', 'PUNCT'), ('known', 'VERB'), ('terrorist', 'NOUN'), (',', 'PUNCT'), ('holding', 'VERB'), ('gun', 'NOUN'), ('?', 'PUNCT'), ('”', 'PUNCT')] 

>> Dependency Tags are: 
[('want', 'ROOT'), ('able', 'acomp'), (',', 'punct'), ('“', 'punct'), ('bunch', 'attr'), ('people', 'pobj'), (' ', 'appos'), ('”', 'punct'), (',', 'punct'), ('“', 'punct'), ('known', 'amod'), ('terrorist', 'attr'), (',', 'punct'), ('holding', 'conj'), ('gun', 'dobj'), ('?', 'punct'), ('”', 'punct')]

>> Bigrams: 
[[want, able], [able, ,], [,, “], [“, bunch], [bunch, people], [people,  ], [ , ”], [”, ,], [,, “], [“, known], [known, terrorist], [terrorist, ,], [,, holding], [holding, gun], [gun, ?], [?, ”]]

>> Trigrams: 
[[want, able, ,], [able, ,, “], [,, “, bunch], [“, bunch, people], [bunch, people,  ], [people,  , ”], [ , ”, ,], [”, ,, “], [,, “, known], [“, known, terrorist], [known, terrorist, ,], [terrorist, ,, holding], [,, holding, gun], [holding, gun, ?], [gun, ?, ”]]

>> Noun Phrases are: 
[you, a bunch, people, a known terrorist, he, a gun]

>> Named Entities are: 
[] 


================================ Paragraph 126 =================================

builds NLP machine   

------------------- Sentence 1 -------------------

builds NLP machine    


>> Tokens are: 
[builds, NLP, machine,   ] 

>> PoS Tags are: 
[('builds', 'VERB'), ('NLP', 'PROPN'), ('machine', 'NOUN'), ('  ', 'SPACE')] 

>> Dependency Tags are: 
[('builds', 'ROOT'), ('NLP', 'compound'), ('machine', 'dobj'), ('  ', 'dobj')]

>> Bigrams: 
[[builds, NLP], [NLP, machine], [machine,   ]]

>> Trigrams: 
[[builds, NLP, machine], [NLP, machine,   ]]

>> Noun Phrases are: 
[NLP machine]

>> Named Entities are: 
[('NLP', 'ORG')] 


================================ Paragraph 127 =================================

learning models and manages   

------------------- Sentence 1 -------------------

learning models and manages    


>> Tokens are: 
[learning, models, manages,   ] 

>> PoS Tags are: 
[('learning', 'VERB'), ('models', 'NOUN'), ('manages', 'VERB'), ('  ', 'SPACE')] 

>> Dependency Tags are: 
[('learning', 'ROOT'), ('models', 'dobj'), ('manages', 'conj'), ('  ', 'dobj')]

>> Bigrams: 
[[learning, models], [models, manages], [manages,   ]]

>> Trigrams: 
[[learning, models, manages], [models, manages,   ]]

>> Noun Phrases are: 
[models]

>> Named Entities are: 
[] 


================================ Paragraph 128 =================================

dependencies between them. 

------------------- Sentence 1 -------------------

dependencies between them. 


>> Tokens are: 
[dependencies, .] 

>> PoS Tags are: 
[('dependencies', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('dependencies', 'ROOT'), ('.', 'punct')]

>> Bigrams: 
[[dependencies, .]]

>> Trigrams: 
[]

>> Noun Phrases are: 
[dependencies, them]

>> Named Entities are: 
[] 


================================ Paragraph 129 =================================

AI   Assembler  

------------------- Sentence 1 -------------------

AI   Assembler   


>> Tokens are: 
[AI,   , Assembler,  ] 

>> PoS Tags are: 
[('AI', 'PROPN'), ('  ', 'SPACE'), ('Assembler', 'PROPN'), (' ', 'SPACE')] 

>> Dependency Tags are: 
[('AI', 'ROOT'), ('  ', 'appos'), ('Assembler', 'npadvmod'), (' ', 'nummod')]

>> Bigrams: 
[[AI,   ], [  , Assembler], [Assembler,  ]]

>> Trigrams: 
[[AI,   , Assembler], [  , Assembler,  ]]

>> Noun Phrases are: 
[AI]

>> Named Entities are: 
[('Assembler', 'PERSON')] 


================================ Paragraph 130 =================================

(our proprietary   software)

------------------- Sentence 1 -------------------

(our proprietary   software) 


>> Tokens are: 
[(, proprietary,   , software, )] 

>> PoS Tags are: 
[('(', 'PUNCT'), ('proprietary', 'ADJ'), ('  ', 'SPACE'), ('software', 'NOUN'), (')', 'PUNCT')] 

>> Dependency Tags are: 
[('(', 'punct'), ('proprietary', 'amod'), ('  ', 'compound'), ('software', 'ROOT'), (')', 'punct')]

>> Bigrams: 
[[(, proprietary], [proprietary,   ], [  , software], [software, )]]

>> Trigrams: 
[[(, proprietary,   ], [proprietary,   , software], [  , software, )]]

>> Noun Phrases are: 
[(our proprietary   software]

>> Named Entities are: 
[] 


================================ Paragraph 131 =================================

W H I T E  P A P E R 

------------------- Sentence 1 -------------------

W H 


>> Tokens are: 
[W, H] 

>> PoS Tags are: 
[('W', 'NOUN'), ('H', 'NOUN')] 

>> Dependency Tags are: 
[('W', 'compound'), ('H', 'ROOT')]

>> Bigrams: 
[[W, H]]

>> Trigrams: 
[]

>> Noun Phrases are: 
[W H]

>> Named Entities are: 
[] 

------------------- Sentence 2 -------------------

I T 


>> Tokens are: 
[T] 

>> PoS Tags are: 
[('T', 'NOUN')] 

>> Dependency Tags are: 
[('T', 'appos')]

>> Bigrams: 
[]

>> Trigrams: 
[]

>> Noun Phrases are: 
[I, T]

>> Named Entities are: 
[] 

------------------- Sentence 3 -------------------

E   


>> Tokens are: 
[E,  ] 

>> PoS Tags are: 
[('E', 'NOUN'), (' ', 'SPACE')] 

>> Dependency Tags are: 
[('E', 'ROOT'), (' ', 'appos')]

>> Bigrams: 
[[E,  ]]

>> Trigrams: 
[]

>> Noun Phrases are: 
[E]

>> Named Entities are: 
[] 

------------------- Sentence 4 -------------------

P A P E R 


>> Tokens are: 
[P, P, E, R] 

>> PoS Tags are: 
[('P', 'NOUN'), ('P', 'NOUN'), ('E', 'NOUN'), ('R', 'NOUN')] 

>> Dependency Tags are: 
[('P', 'compound'), ('P', 'compound'), ('E', 'compound'), ('R', 'ROOT')]

>> Bigrams: 
[[P, P], [P, E], [E, R]]

>> Trigrams: 
[[P, P, E], [P, E, R]]

>> Noun Phrases are: 
[P A P E R]

>> Named Entities are: 
[] 


================================ Paragraph 132 =================================

9|       |   Lexalytics, Inc., 48 North Pleasant St. Unit 301, Amherst MA 01002 USA   |   1-800-377-8036 |   www.lexalytics.com 

------------------- Sentence 1 -------------------

9|       |   Lexalytics, Inc., 48 North Pleasant St. Unit 301, Amherst MA 01002 


>> Tokens are: 
[9|,       , |,   , Lexalytics, ,, Inc., ,, 48, North, Pleasant, St., Unit, 301, ,, Amherst, MA, 01002] 

>> PoS Tags are: 
[('9|', 'NOUN'), ('      ', 'SPACE'), ('|', 'NOUN'), ('  ', 'SPACE'), ('Lexalytics', 'PROPN'), (',', 'PUNCT'), ('Inc.', 'PROPN'), (',', 'PUNCT'), ('48', 'NUM'), ('North', 'PROPN'), ('Pleasant', 'PROPN'), ('St.', 'PROPN'), ('Unit', 'PROPN'), ('301', 'NUM'), (',', 'PUNCT'), ('Amherst', 'PROPN'), ('MA', 'PROPN'), ('01002', 'NUM')] 

>> Dependency Tags are: 
[('9|', 'compound'), ('      ', 'compound'), ('|', 'ROOT'), ('  ', 'nmod'), ('Lexalytics', 'nmod'), (',', 'punct'), ('Inc.', 'appos'), (',', 'punct'), ('48', 'nummod'), ('North', 'compound'), ('Pleasant', 'compound'), ('St.', 'compound'), ('Unit', 'appos'), ('301', 'nummod'), (',', 'punct'), ('Amherst', 'compound'), ('MA', 'appos'), ('01002', 'punct')]

>> Bigrams: 
[[9|,       ], [      , |], [|,   ], [  , Lexalytics], [Lexalytics, ,], [,, Inc.], [Inc., ,], [,, 48], [48, North], [North, Pleasant], [Pleasant, St.], [St., Unit], [Unit, 301], [301, ,], [,, Amherst], [Amherst, MA], [MA, 01002]]

>> Trigrams: 
[[9|,       , |], [      , |,   ], [|,   , Lexalytics], [  , Lexalytics, ,], [Lexalytics, ,, Inc.], [,, Inc., ,], [Inc., ,, 48], [,, 48, North], [48, North, Pleasant], [North, Pleasant, St.], [Pleasant, St., Unit], [St., Unit, 301], [Unit, 301, ,], [301, ,, Amherst], [,, Amherst, MA], [Amherst, MA, 01002]]

>> Noun Phrases are: 
[9|       |,   Lexalytics, Inc., 48 North Pleasant St. Unit, Amherst MA]

>> Named Entities are: 
[('Lexalytics, Inc.', 'ORG'), ('48', 'CARDINAL'), ('North Pleasant St. Unit 301', 'ORG'), ('Amherst MA', 'ORG')] 

------------------- Sentence 2 -------------------

USA 


>> Tokens are: 
[USA] 

>> PoS Tags are: 
[('USA', 'PROPN')] 

>> Dependency Tags are: 
[('USA', 'ROOT')]

>> Bigrams: 
[]

>> Trigrams: 
[]

>> Noun Phrases are: 
[USA]

>> Named Entities are: 
[] 

------------------- Sentence 3 -------------------

  |   1-800-377-8036 |   www.lexalytics.com 


>> Tokens are: 
[  , |,   , 1, -, 800, -, 377, -, 8036, |,   , www.lexalytics.com] 

>> PoS Tags are: 
[('  ', 'SPACE'), ('|', 'NOUN'), ('  ', 'SPACE'), ('1', 'NUM'), ('-', 'SYM'), ('800', 'NUM'), ('-', 'NUM'), ('377', 'NUM'), ('-', 'PUNCT'), ('8036', 'NUM'), ('|', 'NOUN'), ('  ', 'SPACE'), ('www.lexalytics.com', 'X')] 

>> Dependency Tags are: 
[('  ', 'compound'), ('|', 'npadvmod'), ('  ', 'dep'), ('1', 'npadvmod'), ('-', 'punct'), ('800', 'prep'), ('-', 'punct'), ('377', 'nummod'), ('-', 'punct'), ('8036', 'nummod'), ('|', 'npadvmod'), ('  ', 'ROOT'), ('www.lexalytics.com', 'punct')]

>> Bigrams: 
[[  , |], [|,   ], [  , 1], [1, -], [-, 800], [800, -], [-, 377], [377, -], [-, 8036], [8036, |], [|,   ], [  , www.lexalytics.com]]

>> Trigrams: 
[[  , |,   ], [|,   , 1], [  , 1, -], [1, -, 800], [-, 800, -], [800, -, 377], [-, 377, -], [377, -, 8036], [-, 8036, |], [8036, |,   ], [|,   , www.lexalytics.com]]

>> Noun Phrases are: 
[]

>> Named Entities are: 
[] 


================================ Paragraph 133 =================================

C O D I N G  V S .  L E A R N I N G :   M A K I N G  T H E  C A S E  F O R  E A C H  Let’s use the same sentence for this next example. Let me hear you say: 

------------------- Sentence 1 -------------------

C O D 


>> Tokens are: 
[C, O, D] 

>> PoS Tags are: 
[('C', 'NOUN'), ('O', 'NOUN'), ('D', 'NOUN')] 

>> Dependency Tags are: 
[('C', 'compound'), ('O', 'compound'), ('D', 'ROOT')]

>> Bigrams: 
[[C, O], [O, D]]

>> Trigrams: 
[[C, O, D]]

>> Noun Phrases are: 
[C O D]

>> Named Entities are: 
[] 

------------------- Sentence 2 -------------------

I N G  V S .   


>> Tokens are: 
[N, G,  , V, S, .,  ] 

>> PoS Tags are: 
[('N', 'PROPN'), ('G', 'PROPN'), (' ', 'SPACE'), ('V', 'PROPN'), ('S', 'PROPN'), ('.', 'PUNCT'), (' ', 'SPACE')] 

>> Dependency Tags are: 
[('N', 'dep'), ('G', 'nmod'), (' ', 'compound'), ('V', 'compound'), ('S', 'appos'), ('.', 'punct'), (' ', 'punct')]

>> Bigrams: 
[[N, G], [G,  ], [ , V], [V, S], [S, .], [.,  ]]

>> Trigrams: 
[[N, G,  ], [G,  , V], [ , V, S], [V, S, .], [S, .,  ]]

>> Noun Phrases are: 
[I, N G  V S]

>> Named Entities are: 
[] 

------------------- Sentence 3 -------------------

L E A R N I N G :   M A 


>> Tokens are: 
[L, E, R, N, N, G, :,   , M] 

>> PoS Tags are: 
[('L', 'NOUN'), ('E', 'PROPN'), ('R', 'NOUN'), ('N', 'PROPN'), ('N', 'PROPN'), ('G', 'NOUN'), (':', 'PUNCT'), ('  ', 'SPACE'), ('M', 'PROPN')] 

>> Dependency Tags are: 
[('L', 'compound'), ('E', 'compound'), ('R', 'compound'), ('N', 'compound'), ('N', 'compound'), ('G', 'appos'), (':', 'punct'), ('  ', 'compound'), ('M', 'compound')]

>> Bigrams: 
[[L, E], [E, R], [R, N], [N, N], [N, G], [G, :], [:,   ], [  , M]]

>> Trigrams: 
[[L, E, R], [E, R, N], [R, N, N], [N, N, G], [N, G, :], [G, :,   ], [:,   , M]]

>> Noun Phrases are: 
[L E A R N I, N G,   M A]

>> Named Entities are: 
[] 

------------------- Sentence 4 -------------------

K I N G  T H 


>> Tokens are: 
[K, N, G,  , T, H] 

>> PoS Tags are: 
[('K', 'NOUN'), ('N', 'PROPN'), ('G', 'PROPN'), (' ', 'SPACE'), ('T', 'NOUN'), ('H', 'NOUN')] 

>> Dependency Tags are: 
[('K', 'compound'), ('N', 'appos'), ('G', 'conj'), (' ', 'appos'), ('T', 'compound'), ('H', 'punct')]

>> Bigrams: 
[[K, N], [N, G], [G,  ], [ , T], [T, H]]

>> Trigrams: 
[[K, N, G], [N, G,  ], [G,  , T], [ , T, H]]

>> Noun Phrases are: 
[K I, N, G]

>> Named Entities are: 
[] 

------------------- Sentence 5 -------------------

E   


>> Tokens are: 
[E,  ] 

>> PoS Tags are: 
[('E', 'NOUN'), (' ', 'SPACE')] 

>> Dependency Tags are: 
[('E', 'ROOT'), (' ', 'appos')]

>> Bigrams: 
[[E,  ]]

>> Trigrams: 
[]

>> Noun Phrases are: 
[E]

>> Named Entities are: 
[] 

------------------- Sentence 6 -------------------

C A S E   


>> Tokens are: 
[C, S, E,  ] 

>> PoS Tags are: 
[('C', 'NOUN'), ('S', 'PROPN'), ('E', 'NOUN'), (' ', 'SPACE')] 

>> Dependency Tags are: 
[('C', 'compound'), ('S', 'ROOT'), ('E', 'compound'), (' ', 'punct')]

>> Bigrams: 
[[C, S], [S, E], [E,  ]]

>> Trigrams: 
[[C, S, E], [S, E,  ]]

>> Noun Phrases are: 
[C A S]

>> Named Entities are: 
[] 

------------------- Sentence 7 -------------------

F O R  E A C H   


>> Tokens are: 
[F, O, R,  , E, C, H,  ] 

>> PoS Tags are: 
[('F', 'NOUN'), ('O', 'INTJ'), ('R', 'NOUN'), (' ', 'SPACE'), ('E', 'NOUN'), ('C', 'NOUN'), ('H', 'NOUN'), (' ', 'SPACE')] 

>> Dependency Tags are: 
[('F', 'compound'), ('O', 'intj'), ('R', 'nmod'), (' ', 'compound'), ('E', 'nmod'), ('C', 'compound'), ('H', 'ROOT'), (' ', 'punct')]

>> Bigrams: 
[[F, O], [O, R], [R,  ], [ , E], [E, C], [C, H], [H,  ]]

>> Trigrams: 
[[F, O, R], [O, R,  ], [R,  , E], [ , E, C], [E, C, H], [C, H,  ]]

>> Noun Phrases are: 
[F O R  E A C H]

>> Named Entities are: 
[] 

------------------- Sentence 8 -------------------

Let’s use the same sentence for this next example. 


>> Tokens are: 
[Let, use, sentence, example, .] 

>> PoS Tags are: 
[('Let', 'VERB'), ('use', 'VERB'), ('sentence', 'NOUN'), ('example', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('Let', 'ROOT'), ('use', 'ccomp'), ('sentence', 'dobj'), ('example', 'pobj'), ('.', 'punct')]

>> Bigrams: 
[[Let, use], [use, sentence], [sentence, example], [example, .]]

>> Trigrams: 
[[Let, use, sentence], [use, sentence, example], [sentence, example, .]]

>> Noun Phrases are: 
[’s, the same sentence, this next example]

>> Named Entities are: 
[] 

------------------- Sentence 9 -------------------

Let me hear you say: 


>> Tokens are: 
[Let, hear, :] 

>> PoS Tags are: 
[('Let', 'VERB'), ('hear', 'VERB'), (':', 'PUNCT')] 

>> Dependency Tags are: 
[('Let', 'ROOT'), ('hear', 'ccomp'), (':', 'punct')]

>> Bigrams: 
[[Let, hear], [hear, :]]

>> Trigrams: 
[[Let, hear, :]]

>> Noun Phrases are: 
[me, you]

>> Named Entities are: 
[] 


================================ Paragraph 134 =================================

“Lexalytics is the best text analytics company ever.” 

------------------- Sentence 1 -------------------

“ 


>> Tokens are: 
[“] 

>> PoS Tags are: 
[('“', 'PUNCT')] 

>> Dependency Tags are: 
[('“', 'ROOT')]

>> Bigrams: 
[]

>> Trigrams: 
[]

>> Noun Phrases are: 
[]

>> Named Entities are: 
[] 

------------------- Sentence 2 -------------------

Lexalytics is the best text analytics company ever.” 


>> Tokens are: 
[Lexalytics, best, text, analytics, company, ., ”] 

>> PoS Tags are: 
[('Lexalytics', 'PROPN'), ('best', 'ADJ'), ('text', 'NOUN'), ('analytics', 'NOUN'), ('company', 'NOUN'), ('.', 'PUNCT'), ('”', 'PUNCT')] 

>> Dependency Tags are: 
[('Lexalytics', 'nsubj'), ('best', 'amod'), ('text', 'compound'), ('analytics', 'compound'), ('company', 'attr'), ('.', 'punct'), ('”', 'punct')]

>> Bigrams: 
[[Lexalytics, best], [best, text], [text, analytics], [analytics, company], [company, .], [., ”]]

>> Trigrams: 
[[Lexalytics, best, text], [best, text, analytics], [text, analytics, company], [analytics, company, .], [company, ., ”]]

>> Noun Phrases are: 
[Lexalytics, the best text analytics company]

>> Named Entities are: 
[] 


================================ Paragraph 135 =================================

Now look at the period at the end of the sentence. Periods are important   in English because they frequently denote the end of a sentence. It’s  important to be able to break sentences apart so that you can figure out  which statements go together.  

------------------- Sentence 1 -------------------

Now look at the period at the end of the sentence. 


>> Tokens are: 
[look, period, end, sentence, .] 

>> PoS Tags are: 
[('look', 'VERB'), ('period', 'NOUN'), ('end', 'NOUN'), ('sentence', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('look', 'ROOT'), ('period', 'pobj'), ('end', 'pobj'), ('sentence', 'pobj'), ('.', 'punct')]

>> Bigrams: 
[[look, period], [period, end], [end, sentence], [sentence, .]]

>> Trigrams: 
[[look, period, end], [period, end, sentence], [end, sentence, .]]

>> Noun Phrases are: 
[the period, the end, the sentence]

>> Named Entities are: 
[] 

------------------- Sentence 2 -------------------

Periods are important   in English because they frequently denote the end of a sentence. 


>> Tokens are: 
[Periods, important,   , English, frequently, denote, end, sentence, .] 

>> PoS Tags are: 
[('Periods', 'NOUN'), ('important', 'ADJ'), ('  ', 'SPACE'), ('English', 'PROPN'), ('frequently', 'ADV'), ('denote', 'VERB'), ('end', 'NOUN'), ('sentence', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('Periods', 'nsubj'), ('important', 'amod'), ('  ', 'attr'), ('English', 'pobj'), ('frequently', 'advmod'), ('denote', 'advcl'), ('end', 'dobj'), ('sentence', 'pobj'), ('.', 'punct')]

>> Bigrams: 
[[Periods, important], [important,   ], [  , English], [English, frequently], [frequently, denote], [denote, end], [end, sentence], [sentence, .]]

>> Trigrams: 
[[Periods, important,   ], [important,   , English], [  , English, frequently], [English, frequently, denote], [frequently, denote, end], [denote, end, sentence], [end, sentence, .]]

>> Noun Phrases are: 
[Periods, English, they, the end, a sentence]

>> Named Entities are: 
[('English', 'LANGUAGE')] 

------------------- Sentence 3 -------------------

It’s  important to be able to break sentences apart so that you can figure out  which statements go together. 


>> Tokens are: 
[ , important, able, break, sentences, apart, figure,  , statements, .] 

>> PoS Tags are: 
[(' ', 'SPACE'), ('important', 'ADJ'), ('able', 'ADJ'), ('break', 'VERB'), ('sentences', 'NOUN'), ('apart', 'ADV'), ('figure', 'VERB'), (' ', 'SPACE'), ('statements', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[(' ', 'attr'), ('important', 'acomp'), ('able', 'acomp'), ('break', 'xcomp'), ('sentences', 'dobj'), ('apart', 'advmod'), ('figure', 'advcl'), (' ', 'dobj'), ('statements', 'nsubj'), ('.', 'punct')]

>> Bigrams: 
[[ , important], [important, able], [able, break], [break, sentences], [sentences, apart], [apart, figure], [figure,  ], [ , statements], [statements, .]]

>> Trigrams: 
[[ , important, able], [important, able, break], [able, break, sentences], [break, sentences, apart], [sentences, apart, figure], [apart, figure,  ], [figure,  , statements], [ , statements, .]]

>> Noun Phrases are: 
[It, sentences, you, which statements]

>> Named Entities are: 
[] 

------------------- Sentence 4 -------------------

  


>> Tokens are: 
[ ] 

>> PoS Tags are: 
[(' ', 'SPACE')] 

>> Dependency Tags are: 
[(' ', 'ROOT')]

>> Bigrams: 
[]

>> Trigrams: 
[]

>> Noun Phrases are: 
[]

>> Named Entities are: 
[] 


================================ Paragraph 136 =================================

However, periods also denote other things, like “Dr.” for doctor, or “Mr.”   for mister. How can a machine tell whether the period is denoting the end   of a sentence or a form of address? We could train a machine learning model  for this task by marking up examples of each. But this isn’t necessarily the  most efficient approach. After all, there are only a few cases in the English  language where the period is used for anything other than denoting the end  of a sentence. It is more efficient, faster computationally, and more precise  to just hard-code these cases using NLP code or other algorithms.  

------------------- Sentence 1 -------------------

However, periods also denote other things, like “Dr.” for doctor, or “Mr.”   for mister. 


>> Tokens are: 
[,, periods, denote, things, ,, like, “, Dr., ”, doctor, ,, “, Mr., ”,   , mister, .] 

>> PoS Tags are: 
[(',', 'PUNCT'), ('periods', 'NOUN'), ('denote', 'VERB'), ('things', 'NOUN'), (',', 'PUNCT'), ('like', 'ADP'), ('“', 'PUNCT'), ('Dr.', 'PROPN'), ('”', 'PUNCT'), ('doctor', 'NOUN'), (',', 'PUNCT'), ('“', 'PUNCT'), ('Mr.', 'PROPN'), ('”', 'PUNCT'), ('  ', 'SPACE'), ('mister', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[(',', 'punct'), ('periods', 'nsubj'), ('denote', 'ROOT'), ('things', 'dobj'), (',', 'punct'), ('like', 'prep'), ('“', 'punct'), ('Dr.', 'pobj'), ('”', 'punct'), ('doctor', 'pobj'), (',', 'punct'), ('“', 'punct'), ('Mr.', 'conj'), ('”', 'punct'), ('  ', 'appos'), ('mister', 'pobj'), ('.', 'punct')]

>> Bigrams: 
[[,, periods], [periods, denote], [denote, things], [things, ,], [,, like], [like, “], [“, Dr.], [Dr., ”], [”, doctor], [doctor, ,], [,, “], [“, Mr.], [Mr., ”], [”,   ], [  , mister], [mister, .]]

>> Trigrams: 
[[,, periods, denote], [periods, denote, things], [denote, things, ,], [things, ,, like], [,, like, “], [like, “, Dr.], [“, Dr., ”], [Dr., ”, doctor], [”, doctor, ,], [doctor, ,, “], [,, “, Mr.], [“, Mr., ”], [Mr., ”,   ], [”,   , mister], [  , mister, .]]

>> Noun Phrases are: 
[periods, other things, “Dr., doctor, “Mr., mister]

>> Named Entities are: 
[] 

------------------- Sentence 2 -------------------

How can a machine tell whether the period is denoting the end   of a sentence or a form of address? 


>> Tokens are: 
[machine, tell, period, denoting, end,   , sentence, form, address, ?] 

>> PoS Tags are: 
[('machine', 'NOUN'), ('tell', 'VERB'), ('period', 'NOUN'), ('denoting', 'VERB'), ('end', 'NOUN'), ('  ', 'SPACE'), ('sentence', 'NOUN'), ('form', 'NOUN'), ('address', 'NOUN'), ('?', 'PUNCT')] 

>> Dependency Tags are: 
[('machine', 'nsubj'), ('tell', 'ROOT'), ('period', 'nsubj'), ('denoting', 'ccomp'), ('end', 'npadvmod'), ('  ', 'npadvmod'), ('sentence', 'pobj'), ('form', 'conj'), ('address', 'pobj'), ('?', 'punct')]

>> Bigrams: 
[[machine, tell], [tell, period], [period, denoting], [denoting, end], [end,   ], [  , sentence], [sentence, form], [form, address], [address, ?]]

>> Trigrams: 
[[machine, tell, period], [tell, period, denoting], [period, denoting, end], [denoting, end,   ], [end,   , sentence], [  , sentence, form], [sentence, form, address], [form, address, ?]]

>> Noun Phrases are: 
[a machine, the period, a sentence, address]

>> Named Entities are: 
[] 

------------------- Sentence 3 -------------------

We could train a machine learning model  for this task by marking up examples of each. 


>> Tokens are: 
[train, machine, learning, model,  , task, marking, examples, .] 

>> PoS Tags are: 
[('train', 'VERB'), ('machine', 'NOUN'), ('learning', 'NOUN'), ('model', 'NOUN'), (' ', 'SPACE'), ('task', 'NOUN'), ('marking', 'VERB'), ('examples', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('train', 'ROOT'), ('machine', 'compound'), ('learning', 'compound'), ('model', 'dobj'), (' ', 'dobj'), ('task', 'pobj'), ('marking', 'pcomp'), ('examples', 'dobj'), ('.', 'punct')]

>> Bigrams: 
[[train, machine], [machine, learning], [learning, model], [model,  ], [ , task], [task, marking], [marking, examples], [examples, .]]

>> Trigrams: 
[[train, machine, learning], [machine, learning, model], [learning, model,  ], [model,  , task], [ , task, marking], [task, marking, examples], [marking, examples, .]]

>> Noun Phrases are: 
[We, a machine learning model, this task, examples]

>> Named Entities are: 
[] 

------------------- Sentence 4 -------------------

But this isn’t necessarily the  most efficient approach. 


>> Tokens are: 
[necessarily,  , efficient, approach, .] 

>> PoS Tags are: 
[('necessarily', 'ADV'), (' ', 'SPACE'), ('efficient', 'ADJ'), ('approach', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('necessarily', 'advmod'), (' ', 'nmod'), ('efficient', 'amod'), ('approach', 'attr'), ('.', 'punct')]

>> Bigrams: 
[[necessarily,  ], [ , efficient], [efficient, approach], [approach, .]]

>> Trigrams: 
[[necessarily,  , efficient], [ , efficient, approach], [efficient, approach, .]]

>> Noun Phrases are: 
[the  most efficient approach]

>> Named Entities are: 
[] 

------------------- Sentence 5 -------------------

After all, there are only a few cases in the English  language where the period is used for anything other than denoting the end  of a sentence. 


>> Tokens are: 
[,, cases, English,  , language, period, denoting, end,  , sentence, .] 

>> PoS Tags are: 
[(',', 'PUNCT'), ('cases', 'NOUN'), ('English', 'ADJ'), (' ', 'SPACE'), ('language', 'NOUN'), ('period', 'NOUN'), ('denoting', 'VERB'), ('end', 'NOUN'), (' ', 'SPACE'), ('sentence', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[(',', 'punct'), ('cases', 'attr'), ('English', 'amod'), (' ', 'compound'), ('language', 'pobj'), ('period', 'nsubjpass'), ('denoting', 'pcomp'), ('end', 'dobj'), (' ', 'appos'), ('sentence', 'pobj'), ('.', 'punct')]

>> Bigrams: 
[[,, cases], [cases, English], [English,  ], [ , language], [language, period], [period, denoting], [denoting, end], [end,  ], [ , sentence], [sentence, .]]

>> Trigrams: 
[[,, cases, English], [cases, English,  ], [English,  , language], [ , language, period], [language, period, denoting], [period, denoting, end], [denoting, end,  ], [end,  , sentence], [ , sentence, .]]

>> Noun Phrases are: 
[only a few cases, the English  language, the period, anything, the end, a sentence]

>> Named Entities are: 
[('English', 'LANGUAGE')] 

------------------- Sentence 6 -------------------

It is more efficient, faster computationally, and more precise  to just hard-code these cases using NLP code or other algorithms. 


>> Tokens are: 
[efficient, ,, faster, computationally, ,, precise,  , hard, -, code, cases, NLP, code, algorithms, .] 

>> PoS Tags are: 
[('efficient', 'ADJ'), (',', 'PUNCT'), ('faster', 'ADV'), ('computationally', 'ADV'), (',', 'PUNCT'), ('precise', 'ADJ'), (' ', 'SPACE'), ('hard', 'ADJ'), ('-', 'PUNCT'), ('code', 'VERB'), ('cases', 'NOUN'), ('NLP', 'PROPN'), ('code', 'NOUN'), ('algorithms', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('efficient', 'acomp'), (',', 'punct'), ('faster', 'advmod'), ('computationally', 'advmod'), (',', 'punct'), ('precise', 'amod'), (' ', 'punct'), ('hard', 'amod'), ('-', 'punct'), ('code', 'pobj'), ('cases', 'pobj'), ('NLP', 'compound'), ('code', 'dobj'), ('algorithms', 'conj'), ('.', 'punct')]

>> Bigrams: 
[[efficient, ,], [,, faster], [faster, computationally], [computationally, ,], [,, precise], [precise,  ], [ , hard], [hard, -], [-, code], [code, cases], [cases, NLP], [NLP, code], [code, algorithms], [algorithms, .]]

>> Trigrams: 
[[efficient, ,, faster], [,, faster, computationally], [faster, computationally, ,], [computationally, ,, precise], [,, precise,  ], [precise,  , hard], [ , hard, -], [hard, -, code], [-, code, cases], [code, cases, NLP], [cases, NLP, code], [NLP, code, algorithms], [code, algorithms, .]]

>> Noun Phrases are: 
[It, these cases, NLP code, other algorithms]

>> Named Entities are: 
[('NLP', 'ORG')] 

------------------- Sentence 7 -------------------

  


>> Tokens are: 
[ ] 

>> PoS Tags are: 
[(' ', 'SPACE')] 

>> Dependency Tags are: 
[(' ', 'ROOT')]

>> Bigrams: 
[]

>> Trigrams: 
[]

>> Noun Phrases are: 
[]

>> Named Entities are: 
[] 


================================ Paragraph 137 =================================

Where there are cases that are best handled by NLP code, we write NLP  code or use rules. When we need to build models, we build models.  

------------------- Sentence 1 -------------------

Where there are cases that are best handled by NLP code, we write NLP  code or use rules. 


>> Tokens are: 
[cases, best, handled, NLP, code, ,, write, NLP,  , code, use, rules, .] 

>> PoS Tags are: 
[('cases', 'NOUN'), ('best', 'ADV'), ('handled', 'VERB'), ('NLP', 'PROPN'), ('code', 'NOUN'), (',', 'PUNCT'), ('write', 'VERB'), ('NLP', 'PROPN'), (' ', 'SPACE'), ('code', 'NOUN'), ('use', 'VERB'), ('rules', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('cases', 'attr'), ('best', 'advmod'), ('handled', 'relcl'), ('NLP', 'compound'), ('code', 'pobj'), (',', 'punct'), ('write', 'ROOT'), ('NLP', 'dobj'), (' ', 'compound'), ('code', 'appos'), ('use', 'conj'), ('rules', 'dobj'), ('.', 'punct')]

>> Bigrams: 
[[cases, best], [best, handled], [handled, NLP], [NLP, code], [code, ,], [,, write], [write, NLP], [NLP,  ], [ , code], [code, use], [use, rules], [rules, .]]

>> Trigrams: 
[[cases, best, handled], [best, handled, NLP], [handled, NLP, code], [NLP, code, ,], [code, ,, write], [,, write, NLP], [write, NLP,  ], [NLP,  , code], [ , code, use], [code, use, rules], [use, rules, .]]

>> Noun Phrases are: 
[cases, NLP code, we, NLP,  code, rules]

>> Named Entities are: 
[('NLP', 'ORG'), ('NLP', 'ORG')] 

------------------- Sentence 2 -------------------

When we need to build models, we build models. 


>> Tokens are: 
[need, build, models, ,, build, models, .] 

>> PoS Tags are: 
[('need', 'VERB'), ('build', 'VERB'), ('models', 'NOUN'), (',', 'PUNCT'), ('build', 'VERB'), ('models', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('need', 'advcl'), ('build', 'xcomp'), ('models', 'dobj'), (',', 'punct'), ('build', 'ROOT'), ('models', 'dobj'), ('.', 'punct')]

>> Bigrams: 
[[need, build], [build, models], [models, ,], [,, build], [build, models], [models, .]]

>> Trigrams: 
[[need, build, models], [build, models, ,], [models, ,, build], [,, build, models], [build, models, .]]

>> Noun Phrases are: 
[we, models, we, models]

>> Named Entities are: 
[] 

------------------- Sentence 3 -------------------

  


>> Tokens are: 
[ ] 

>> PoS Tags are: 
[(' ', 'SPACE')] 

>> Dependency Tags are: 
[(' ', 'ROOT')]

>> Bigrams: 
[]

>> Trigrams: 
[]

>> Noun Phrases are: 
[]

>> Named Entities are: 
[] 


================================ Paragraph 138 =================================

When we need NLP code or rules,   

------------------- Sentence 1 -------------------

When we need NLP code or rules, 


>> Tokens are: 
[need, NLP, code, rules, ,] 

>> PoS Tags are: 
[('need', 'VERB'), ('NLP', 'PROPN'), ('code', 'NOUN'), ('rules', 'NOUN'), (',', 'PUNCT')] 

>> Dependency Tags are: 
[('need', 'ROOT'), ('NLP', 'compound'), ('code', 'dobj'), ('rules', 'conj'), (',', 'punct')]

>> Bigrams: 
[[need, NLP], [NLP, code], [code, rules], [rules, ,]]

>> Trigrams: 
[[need, NLP, code], [NLP, code, rules], [code, rules, ,]]

>> Noun Phrases are: 
[we, NLP code, rules]

>> Named Entities are: 
[('NLP', 'ORG')] 

------------------- Sentence 2 -------------------

   


>> Tokens are: 
[  ] 

>> PoS Tags are: 
[('  ', 'SPACE')] 

>> Dependency Tags are: 
[('  ', 'ROOT')]

>> Bigrams: 
[]

>> Trigrams: 
[]

>> Noun Phrases are: 
[]

>> Named Entities are: 
[] 


================================ Paragraph 139 =================================

we write them; when we need   

------------------- Sentence 1 -------------------

we write them; 


>> Tokens are: 
[write, ;] 

>> PoS Tags are: 
[('write', 'VERB'), (';', 'PUNCT')] 

>> Dependency Tags are: 
[('write', 'ROOT'), (';', 'punct')]

>> Bigrams: 
[[write, ;]]

>> Trigrams: 
[]

>> Noun Phrases are: 
[we, them]

>> Named Entities are: 
[] 

------------------- Sentence 2 -------------------

when we need    


>> Tokens are: 
[need,   ] 

>> PoS Tags are: 
[('need', 'VERB'), ('  ', 'SPACE')] 

>> Dependency Tags are: 
[('need', 'ROOT'), ('  ', 'dobj')]

>> Bigrams: 
[[need,   ]]

>> Trigrams: 
[]

>> Noun Phrases are: 
[we]

>> Named Entities are: 
[] 


================================ Paragraph 140 =================================

models, we build them. 

------------------- Sentence 1 -------------------

models, we build them. 


>> Tokens are: 
[models, ,, build, .] 

>> PoS Tags are: 
[('models', 'NOUN'), (',', 'PUNCT'), ('build', 'VERB'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('models', 'npadvmod'), (',', 'punct'), ('build', 'ROOT'), ('.', 'punct')]

>> Bigrams: 
[[models, ,], [,, build], [build, .]]

>> Trigrams: 
[[models, ,, build], [,, build, .]]

>> Noun Phrases are: 
[we, them]

>> Named Entities are: 
[] 


================================ Paragraph 141 =================================

Practical   efficiencies:

------------------- Sentence 1 -------------------

Practical   efficiencies: 


>> Tokens are: 
[Practical,   , efficiencies, :] 

>> PoS Tags are: 
[('Practical', 'ADJ'), ('  ', 'SPACE'), ('efficiencies', 'NOUN'), (':', 'PUNCT')] 

>> Dependency Tags are: 
[('Practical', 'amod'), ('  ', 'compound'), ('efficiencies', 'ROOT'), (':', 'punct')]

>> Bigrams: 
[[Practical,   ], [  , efficiencies], [efficiencies, :]]

>> Trigrams: 
[[Practical,   , efficiencies], [  , efficiencies, :]]

>> Noun Phrases are: 
[Practical   efficiencies]

>> Named Entities are: 
[] 


================================ Paragraph 142 =================================

W H I T E  P A P E R 

------------------- Sentence 1 -------------------

W H 


>> Tokens are: 
[W, H] 

>> PoS Tags are: 
[('W', 'NOUN'), ('H', 'NOUN')] 

>> Dependency Tags are: 
[('W', 'compound'), ('H', 'ROOT')]

>> Bigrams: 
[[W, H]]

>> Trigrams: 
[]

>> Noun Phrases are: 
[W H]

>> Named Entities are: 
[] 

------------------- Sentence 2 -------------------

I T 


>> Tokens are: 
[T] 

>> PoS Tags are: 
[('T', 'NOUN')] 

>> Dependency Tags are: 
[('T', 'appos')]

>> Bigrams: 
[]

>> Trigrams: 
[]

>> Noun Phrases are: 
[I, T]

>> Named Entities are: 
[] 

------------------- Sentence 3 -------------------

E   


>> Tokens are: 
[E,  ] 

>> PoS Tags are: 
[('E', 'NOUN'), (' ', 'SPACE')] 

>> Dependency Tags are: 
[('E', 'ROOT'), (' ', 'appos')]

>> Bigrams: 
[[E,  ]]

>> Trigrams: 
[]

>> Noun Phrases are: 
[E]

>> Named Entities are: 
[] 

------------------- Sentence 4 -------------------

P A P E R 


>> Tokens are: 
[P, P, E, R] 

>> PoS Tags are: 
[('P', 'NOUN'), ('P', 'NOUN'), ('E', 'NOUN'), ('R', 'NOUN')] 

>> Dependency Tags are: 
[('P', 'compound'), ('P', 'compound'), ('E', 'compound'), ('R', 'ROOT')]

>> Bigrams: 
[[P, P], [P, E], [E, R]]

>> Trigrams: 
[[P, P, E], [P, E, R]]

>> Noun Phrases are: 
[P A P E R]

>> Named Entities are: 
[] 


================================ Paragraph 143 =================================

10|       |   Lexalytics, Inc., 48 North Pleasant St. Unit 301, Amherst MA 01002 USA   |   1-800-377-8036 |   www.lexalytics.com 

------------------- Sentence 1 -------------------

10|       |   Lexalytics, Inc., 48 North Pleasant St. Unit 301, Amherst MA 01002 USA   |   1-800-377-8036 |   www.lexalytics.com 


>> Tokens are: 
[10|,       , |,   , Lexalytics, ,, Inc., ,, 48, North, Pleasant, St., Unit, 301, ,, Amherst, MA, 01002, USA,   , |,   , 1, -, 800, -, 377, -, 8036, |,   , www.lexalytics.com] 

>> PoS Tags are: 
[('10|', 'NUM'), ('      ', 'SPACE'), ('|', 'NOUN'), ('  ', 'SPACE'), ('Lexalytics', 'PROPN'), (',', 'PUNCT'), ('Inc.', 'PROPN'), (',', 'PUNCT'), ('48', 'NUM'), ('North', 'PROPN'), ('Pleasant', 'PROPN'), ('St.', 'PROPN'), ('Unit', 'PROPN'), ('301', 'NUM'), (',', 'PUNCT'), ('Amherst', 'PROPN'), ('MA', 'PROPN'), ('01002', 'NUM'), ('USA', 'PROPN'), ('  ', 'SPACE'), ('|', 'NOUN'), ('  ', 'SPACE'), ('1', 'NUM'), ('-', 'SYM'), ('800', 'NUM'), ('-', 'NUM'), ('377', 'NUM'), ('-', 'PUNCT'), ('8036', 'NUM'), ('|', 'NOUN'), ('  ', 'SPACE'), ('www.lexalytics.com', 'X')] 

>> Dependency Tags are: 
[('10|', 'nummod'), ('      ', 'compound'), ('|', 'npadvmod'), ('  ', 'nmod'), ('Lexalytics', 'nmod'), (',', 'punct'), ('Inc.', 'appos'), (',', 'punct'), ('48', 'nummod'), ('North', 'compound'), ('Pleasant', 'compound'), ('St.', 'compound'), ('Unit', 'appos'), ('301', 'nummod'), (',', 'punct'), ('Amherst', 'compound'), ('MA', 'appos'), ('01002', 'punct'), ('USA', 'compound'), ('  ', 'compound'), ('|', 'punct'), ('  ', 'appos'), ('1', 'npadvmod'), ('-', 'punct'), ('800', 'prep'), ('-', 'punct'), ('377', 'nummod'), ('-', 'punct'), ('8036', 'nummod'), ('|', 'appos'), ('  ', 'ROOT'), ('www.lexalytics.com', 'punct')]

>> Bigrams: 
[[10|,       ], [      , |], [|,   ], [  , Lexalytics], [Lexalytics, ,], [,, Inc.], [Inc., ,], [,, 48], [48, North], [North, Pleasant], [Pleasant, St.], [St., Unit], [Unit, 301], [301, ,], [,, Amherst], [Amherst, MA], [MA, 01002], [01002, USA], [USA,   ], [  , |], [|,   ], [  , 1], [1, -], [-, 800], [800, -], [-, 377], [377, -], [-, 8036], [8036, |], [|,   ], [  , www.lexalytics.com]]

>> Trigrams: 
[[10|,       , |], [      , |,   ], [|,   , Lexalytics], [  , Lexalytics, ,], [Lexalytics, ,, Inc.], [,, Inc., ,], [Inc., ,, 48], [,, 48, North], [48, North, Pleasant], [North, Pleasant, St.], [Pleasant, St., Unit], [St., Unit, 301], [Unit, 301, ,], [301, ,, Amherst], [,, Amherst, MA], [Amherst, MA, 01002], [MA, 01002, USA], [01002, USA,   ], [USA,   , |], [  , |,   ], [|,   , 1], [  , 1, -], [1, -, 800], [-, 800, -], [800, -, 377], [-, 377, -], [377, -, 8036], [-, 8036, |], [8036, |,   ], [|,   , www.lexalytics.com]]

>> Noun Phrases are: 
[  Lexalytics, Inc., 48 North Pleasant St. Unit, Amherst MA, 377-8036 |]

>> Named Entities are: 
[('Lexalytics, Inc.', 'ORG'), ('48', 'CARDINAL'), ('North Pleasant St. Unit 301', 'ORG'), ('Amherst MA', 'ORG')] 


================================ Paragraph 144 =================================

B L A C K  B O X / C L E A R  B O X :   L O O K I N G  I N S I D E  T H E  D A T A  It is important to understand not just what decision a model has made,   but why it has made that decision. There are two reasons for this:  

------------------- Sentence 1 -------------------

B L A C K  B O X / C L E 


>> Tokens are: 
[B, L, C, K,  , B, O, X, /, C, L, E] 

>> PoS Tags are: 
[('B', 'PROPN'), ('L', 'NOUN'), ('C', 'PROPN'), ('K', 'PROPN'), (' ', 'SPACE'), ('B', 'NOUN'), ('O', 'PROPN'), ('X', 'NOUN'), ('/', 'SYM'), ('C', 'PROPN'), ('L', 'PROPN'), ('E', 'NOUN')] 

>> Dependency Tags are: 
[('B', 'compound'), ('L', 'compound'), ('C', 'nmod'), ('K', 'nmod'), (' ', 'compound'), ('B', 'compound'), ('O', 'nmod'), ('X', 'nmod'), ('/', 'punct'), ('C', 'compound'), ('L', 'compound'), ('E', 'appos')]

>> Bigrams: 
[[B, L], [L, C], [C, K], [K,  ], [ , B], [B, O], [O, X], [X, /], [/, C], [C, L], [L, E]]

>> Trigrams: 
[[B, L, C], [L, C, K], [C, K,  ], [K,  , B], [ , B, O], [B, O, X], [O, X, /], [X, /, C], [/, C, L], [C, L, E]]

>> Noun Phrases are: 
[B L A, C K  B O X / C L E]

>> Named Entities are: 
[] 

------------------- Sentence 2 -------------------

A R  B O X :    


>> Tokens are: 
[R,  , B, O, X, :,   ] 

>> PoS Tags are: 
[('R', 'NOUN'), (' ', 'SPACE'), ('B', 'NOUN'), ('O', 'NOUN'), ('X', 'NOUN'), (':', 'PUNCT'), ('  ', 'SPACE')] 

>> Dependency Tags are: 
[('R', 'nmod'), (' ', 'compound'), ('B', 'compound'), ('O', 'compound'), ('X', 'ROOT'), (':', 'punct'), ('  ', 'appos')]

>> Bigrams: 
[[R,  ], [ , B], [B, O], [O, X], [X, :], [:,   ]]

>> Trigrams: 
[[R,  , B], [ , B, O], [B, O, X], [O, X, :], [X, :,   ]]

>> Noun Phrases are: 
[A R  B O X]

>> Named Entities are: 
[] 

------------------- Sentence 3 -------------------

L O 


>> Tokens are: 
[L, O] 

>> PoS Tags are: 
[('L', 'NOUN'), ('O', 'NOUN')] 

>> Dependency Tags are: 
[('L', 'compound'), ('O', 'ROOT')]

>> Bigrams: 
[[L, O]]

>> Trigrams: 
[]

>> Noun Phrases are: 
[L O]

>> Named Entities are: 
[] 

------------------- Sentence 4 -------------------

O K I N G 


>> Tokens are: 
[O, K, N, G] 

>> PoS Tags are: 
[('O', 'INTJ'), ('K', 'NOUN'), ('N', 'PROPN'), ('G', 'PROPN')] 

>> Dependency Tags are: 
[('O', 'intj'), ('K', 'ROOT'), ('N', 'compound'), ('G', 'appos')]

>> Bigrams: 
[[O, K], [K, N], [N, G]]

>> Trigrams: 
[[O, K, N], [K, N, G]]

>> Noun Phrases are: 
[O K, I, N G]

>> Named Entities are: 
[] 

------------------- Sentence 5 -------------------

 I 


>> Tokens are: 
[ ] 

>> PoS Tags are: 
[(' ', 'SPACE')] 

>> Dependency Tags are: 
[(' ', 'ROOT')]

>> Bigrams: 
[]

>> Trigrams: 
[]

>> Noun Phrases are: 
[I]

>> Named Entities are: 
[] 

------------------- Sentence 6 -------------------

N S 


>> Tokens are: 
[N, S] 

>> PoS Tags are: 
[('N', 'PROPN'), ('S', 'NOUN')] 

>> Dependency Tags are: 
[('N', 'compound'), ('S', 'ROOT')]

>> Bigrams: 
[[N, S]]

>> Trigrams: 
[]

>> Noun Phrases are: 
[N S]

>> Named Entities are: 
[] 

------------------- Sentence 7 -------------------

I D 


>> Tokens are: 
[D] 

>> PoS Tags are: 
[('D', 'NOUN')] 

>> Dependency Tags are: 
[('D', 'ROOT')]

>> Bigrams: 
[]

>> Trigrams: 
[]

>> Noun Phrases are: 
[I D]

>> Named Entities are: 
[] 

------------------- Sentence 8 -------------------

E  T H 


>> Tokens are: 
[E,  , T, H] 

>> PoS Tags are: 
[('E', 'NOUN'), (' ', 'SPACE'), ('T', 'NOUN'), ('H', 'NOUN')] 

>> Dependency Tags are: 
[('E', 'nmod'), (' ', 'compound'), ('T', 'compound'), ('H', 'ROOT')]

>> Bigrams: 
[[E,  ], [ , T], [T, H]]

>> Trigrams: 
[[E,  , T], [ , T, H]]

>> Noun Phrases are: 
[E  T H]

>> Named Entities are: 
[] 

------------------- Sentence 9 -------------------

E   


>> Tokens are: 
[E,  ] 

>> PoS Tags are: 
[('E', 'NOUN'), (' ', 'SPACE')] 

>> Dependency Tags are: 
[('E', 'ROOT'), (' ', 'appos')]

>> Bigrams: 
[[E,  ]]

>> Trigrams: 
[]

>> Noun Phrases are: 
[E]

>> Named Entities are: 
[] 

------------------- Sentence 10 -------------------

D A T 


>> Tokens are: 
[D, T] 

>> PoS Tags are: 
[('D', 'NOUN'), ('T', 'NOUN')] 

>> Dependency Tags are: 
[('D', 'compound'), ('T', 'ROOT')]

>> Bigrams: 
[[D, T]]

>> Trigrams: 
[]

>> Noun Phrases are: 
[D A T]

>> Named Entities are: 
[] 

------------------- Sentence 11 -------------------

A   


>> Tokens are: 
[ ] 

>> PoS Tags are: 
[(' ', 'SPACE')] 

>> Dependency Tags are: 
[(' ', 'punct')]

>> Bigrams: 
[]

>> Trigrams: 
[]

>> Noun Phrases are: 
[A]

>> Named Entities are: 
[] 

------------------- Sentence 12 -------------------

It is important to understand not just what decision a model has made,   but why it has made that decision. 


>> Tokens are: 
[important, understand, decision, model, ,,   , decision, .] 

>> PoS Tags are: 
[('important', 'ADJ'), ('understand', 'VERB'), ('decision', 'NOUN'), ('model', 'NOUN'), (',', 'PUNCT'), ('  ', 'SPACE'), ('decision', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('important', 'acomp'), ('understand', 'xcomp'), ('decision', 'dobj'), ('model', 'nsubj'), (',', 'punct'), ('  ', 'dep'), ('decision', 'dobj'), ('.', 'punct')]

>> Bigrams: 
[[important, understand], [understand, decision], [decision, model], [model, ,], [,,   ], [  , decision], [decision, .]]

>> Trigrams: 
[[important, understand, decision], [understand, decision, model], [decision, model, ,], [model, ,,   ], [,,   , decision], [  , decision, .]]

>> Noun Phrases are: 
[It, what decision, a model, it, that decision]

>> Named Entities are: 
[] 

------------------- Sentence 13 -------------------

There are two reasons for this:   


>> Tokens are: 
[reasons, :,  ] 

>> PoS Tags are: 
[('reasons', 'NOUN'), (':', 'PUNCT'), (' ', 'SPACE')] 

>> Dependency Tags are: 
[('reasons', 'attr'), (':', 'punct'), (' ', 'attr')]

>> Bigrams: 
[[reasons, :], [:,  ]]

>> Trigrams: 
[[reasons, :,  ]]

>> Noun Phrases are: 
[two reasons]

>> Named Entities are: 
[('two', 'CARDINAL')] 


================================ Paragraph 145 =================================

There’s often other business-relevant information encoded   in the “why.” For example, knowing simply that certain survey  results are full of negative feedback is not particularly useful.   We want to know which phrases were scored negatively. 

------------------- Sentence 1 -------------------

There’s often other business-relevant information encoded   in the “why.” 


>> Tokens are: 
[business, -, relevant, information, encoded,   , “, ., ”] 

>> PoS Tags are: 
[('business', 'NOUN'), ('-', 'PUNCT'), ('relevant', 'ADJ'), ('information', 'NOUN'), ('encoded', 'VERB'), ('  ', 'SPACE'), ('“', 'PUNCT'), ('.', 'PUNCT'), ('”', 'PUNCT')] 

>> Dependency Tags are: 
[('business', 'npadvmod'), ('-', 'punct'), ('relevant', 'amod'), ('information', 'attr'), ('encoded', 'acl'), ('  ', 'dobj'), ('“', 'punct'), ('.', 'punct'), ('”', 'punct')]

>> Bigrams: 
[[business, -], [-, relevant], [relevant, information], [information, encoded], [encoded,   ], [  , “], [“, .], [., ”]]

>> Trigrams: 
[[business, -, relevant], [-, relevant, information], [relevant, information, encoded], [information, encoded,   ], [encoded,   , “], [  , “, .], [“, ., ”]]

>> Noun Phrases are: 
[other business-relevant information]

>> Named Entities are: 
[] 

------------------- Sentence 2 -------------------

For example, knowing simply that certain survey  results are full of negative feedback is not particularly useful. 


>> Tokens are: 
[example, ,, knowing, simply, certain, survey,  , results, negative, feedback, particularly, useful, .] 

>> PoS Tags are: 
[('example', 'NOUN'), (',', 'PUNCT'), ('knowing', 'VERB'), ('simply', 'ADV'), ('certain', 'ADJ'), ('survey', 'NOUN'), (' ', 'SPACE'), ('results', 'NOUN'), ('negative', 'ADJ'), ('feedback', 'NOUN'), ('particularly', 'ADV'), ('useful', 'ADJ'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('example', 'pobj'), (',', 'punct'), ('knowing', 'csubj'), ('simply', 'advmod'), ('certain', 'amod'), ('survey', 'nmod'), (' ', 'punct'), ('results', 'nsubj'), ('negative', 'amod'), ('feedback', 'pobj'), ('particularly', 'advmod'), ('useful', 'acomp'), ('.', 'punct')]

>> Bigrams: 
[[example, ,], [,, knowing], [knowing, simply], [simply, certain], [certain, survey], [survey,  ], [ , results], [results, negative], [negative, feedback], [feedback, particularly], [particularly, useful], [useful, .]]

>> Trigrams: 
[[example, ,, knowing], [,, knowing, simply], [knowing, simply, certain], [simply, certain, survey], [certain, survey,  ], [survey,  , results], [ , results, negative], [results, negative, feedback], [negative, feedback, particularly], [feedback, particularly, useful], [particularly, useful, .]]

>> Noun Phrases are: 
[example, certain survey  results, negative feedback]

>> Named Entities are: 
[] 

------------------- Sentence 3 -------------------

  We want to know which phrases were scored negatively. 


>> Tokens are: 
[  , want, know, phrases, scored, negatively, .] 

>> PoS Tags are: 
[('  ', 'SPACE'), ('want', 'VERB'), ('know', 'VERB'), ('phrases', 'NOUN'), ('scored', 'VERB'), ('negatively', 'ADV'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('  ', 'npadvmod'), ('want', 'ROOT'), ('know', 'xcomp'), ('phrases', 'nsubjpass'), ('scored', 'ccomp'), ('negatively', 'advmod'), ('.', 'punct')]

>> Bigrams: 
[[  , want], [want, know], [know, phrases], [phrases, scored], [scored, negatively], [negatively, .]]

>> Trigrams: 
[[  , want, know], [want, know, phrases], [know, phrases, scored], [phrases, scored, negatively], [scored, negatively, .]]

>> Noun Phrases are: 
[We, which phrases]

>> Named Entities are: 
[] 


================================ Paragraph 146 =================================

We might want to adjust the scoring somehow. If we can’t   see why the model is making a decision, we can’t really affect   the decision and it can be hard to figure out what to do next. 

------------------- Sentence 1 -------------------

We might want to adjust the scoring somehow. 


>> Tokens are: 
[want, adjust, scoring, .] 

>> PoS Tags are: 
[('want', 'VERB'), ('adjust', 'VERB'), ('scoring', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('want', 'ROOT'), ('adjust', 'xcomp'), ('scoring', 'dobj'), ('.', 'punct')]

>> Bigrams: 
[[want, adjust], [adjust, scoring], [scoring, .]]

>> Trigrams: 
[[want, adjust, scoring], [adjust, scoring, .]]

>> Noun Phrases are: 
[We, the scoring]

>> Named Entities are: 
[] 

------------------- Sentence 2 -------------------

If we can’t   see why the model is making a decision, we can’t really affect   the decision and it can be hard to figure out what to do next. 


>> Tokens are: 
[  , model, making, decision, ,, affect,   , decision, hard, figure, .] 

>> PoS Tags are: 
[('  ', 'SPACE'), ('model', 'NOUN'), ('making', 'VERB'), ('decision', 'NOUN'), (',', 'PUNCT'), ('affect', 'VERB'), ('  ', 'SPACE'), ('decision', 'NOUN'), ('hard', 'ADJ'), ('figure', 'VERB'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('  ', 'nsubj'), ('model', 'nsubj'), ('making', 'ccomp'), ('decision', 'dobj'), (',', 'punct'), ('affect', 'ROOT'), ('  ', 'dobj'), ('decision', 'dobj'), ('hard', 'acomp'), ('figure', 'xcomp'), ('.', 'punct')]

>> Bigrams: 
[[  , model], [model, making], [making, decision], [decision, ,], [,, affect], [affect,   ], [  , decision], [decision, hard], [hard, figure], [figure, .]]

>> Trigrams: 
[[  , model, making], [model, making, decision], [making, decision, ,], [decision, ,, affect], [,, affect,   ], [affect,   , decision], [  , decision, hard], [decision, hard, figure], [hard, figure, .]]

>> Noun Phrases are: 
[we, the model, a decision, we, the decision, it, what]

>> Named Entities are: 
[] 


================================ Paragraph 147 =================================

It’s often difficult to see how or why a model is making a decision. This is  particularly true of deep learning models. Despite their popularity, they   are profoundly black box algorithms.

------------------- Sentence 1 -------------------

It’s often difficult to see how or why a model is making a decision. 


>> Tokens are: 
[difficult, model, making, decision, .] 

>> PoS Tags are: 
[('difficult', 'ADJ'), ('model', 'NOUN'), ('making', 'VERB'), ('decision', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('difficult', 'acomp'), ('model', 'nsubj'), ('making', 'ccomp'), ('decision', 'dobj'), ('.', 'punct')]

>> Bigrams: 
[[difficult, model], [model, making], [making, decision], [decision, .]]

>> Trigrams: 
[[difficult, model, making], [model, making, decision], [making, decision, .]]

>> Noun Phrases are: 
[It, a model, a decision]

>> Named Entities are: 
[] 

------------------- Sentence 2 -------------------

This is  particularly true of deep learning models. 


>> Tokens are: 
[ , particularly, true, deep, learning, models, .] 

>> PoS Tags are: 
[(' ', 'SPACE'), ('particularly', 'ADV'), ('true', 'ADJ'), ('deep', 'ADJ'), ('learning', 'NOUN'), ('models', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[(' ', 'attr'), ('particularly', 'advmod'), ('true', 'acomp'), ('deep', 'amod'), ('learning', 'compound'), ('models', 'pobj'), ('.', 'punct')]

>> Bigrams: 
[[ , particularly], [particularly, true], [true, deep], [deep, learning], [learning, models], [models, .]]

>> Trigrams: 
[[ , particularly, true], [particularly, true, deep], [true, deep, learning], [deep, learning, models], [learning, models, .]]

>> Noun Phrases are: 
[deep learning models]

>> Named Entities are: 
[] 

------------------- Sentence 3 -------------------

Despite their popularity, they   are profoundly black box algorithms. 


>> Tokens are: 
[Despite, popularity, ,,   , profoundly, black, box, algorithms, .] 

>> PoS Tags are: 
[('Despite', 'SCONJ'), ('popularity', 'NOUN'), (',', 'PUNCT'), ('  ', 'SPACE'), ('profoundly', 'ADV'), ('black', 'ADJ'), ('box', 'NOUN'), ('algorithms', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('Despite', 'prep'), ('popularity', 'pobj'), (',', 'punct'), ('  ', 'appos'), ('profoundly', 'advmod'), ('black', 'amod'), ('box', 'compound'), ('algorithms', 'attr'), ('.', 'punct')]

>> Bigrams: 
[[Despite, popularity], [popularity, ,], [,,   ], [  , profoundly], [profoundly, black], [black, box], [box, algorithms], [algorithms, .]]

>> Trigrams: 
[[Despite, popularity, ,], [popularity, ,,   ], [,,   , profoundly], [  , profoundly, black], [profoundly, black, box], [black, box, algorithms], [box, algorithms, .]]

>> Noun Phrases are: 
[their popularity, they, profoundly black box algorithms]

>> Named Entities are: 
[] 


================================ Paragraph 148 =================================

W H I T E  P A P E R 

------------------- Sentence 1 -------------------

W H 


>> Tokens are: 
[W, H] 

>> PoS Tags are: 
[('W', 'NOUN'), ('H', 'NOUN')] 

>> Dependency Tags are: 
[('W', 'compound'), ('H', 'ROOT')]

>> Bigrams: 
[[W, H]]

>> Trigrams: 
[]

>> Noun Phrases are: 
[W H]

>> Named Entities are: 
[] 

------------------- Sentence 2 -------------------

I T 


>> Tokens are: 
[T] 

>> PoS Tags are: 
[('T', 'NOUN')] 

>> Dependency Tags are: 
[('T', 'appos')]

>> Bigrams: 
[]

>> Trigrams: 
[]

>> Noun Phrases are: 
[I, T]

>> Named Entities are: 
[] 

------------------- Sentence 3 -------------------

E   


>> Tokens are: 
[E,  ] 

>> PoS Tags are: 
[('E', 'NOUN'), (' ', 'SPACE')] 

>> Dependency Tags are: 
[('E', 'ROOT'), (' ', 'appos')]

>> Bigrams: 
[[E,  ]]

>> Trigrams: 
[]

>> Noun Phrases are: 
[E]

>> Named Entities are: 
[] 

------------------- Sentence 4 -------------------

P A P E R 


>> Tokens are: 
[P, P, E, R] 

>> PoS Tags are: 
[('P', 'NOUN'), ('P', 'NOUN'), ('E', 'NOUN'), ('R', 'NOUN')] 

>> Dependency Tags are: 
[('P', 'compound'), ('P', 'compound'), ('E', 'compound'), ('R', 'ROOT')]

>> Bigrams: 
[[P, P], [P, E], [E, R]]

>> Trigrams: 
[[P, P, E], [P, E, R]]

>> Noun Phrases are: 
[P A P E R]

>> Named Entities are: 
[] 


================================ Paragraph 149 =================================

1 1|       |   Lexalytics, Inc., 48 North Pleasant St. Unit 301, Amherst MA 01002 USA   |   1-800-377-8036 |   www.lexalytics.com 

------------------- Sentence 1 -------------------

1 1|       |   Lexalytics, Inc., 48 North Pleasant St. Unit 301, Amherst MA 01002 


>> Tokens are: 
[1, 1|,       , |,   , Lexalytics, ,, Inc., ,, 48, North, Pleasant, St., Unit, 301, ,, Amherst, MA, 01002] 

>> PoS Tags are: 
[('1', 'NUM'), ('1|', 'NUM'), ('      ', 'SPACE'), ('|', 'NOUN'), ('  ', 'SPACE'), ('Lexalytics', 'PROPN'), (',', 'PUNCT'), ('Inc.', 'PROPN'), (',', 'PUNCT'), ('48', 'NUM'), ('North', 'PROPN'), ('Pleasant', 'PROPN'), ('St.', 'PROPN'), ('Unit', 'PROPN'), ('301', 'NUM'), (',', 'PUNCT'), ('Amherst', 'PROPN'), ('MA', 'PROPN'), ('01002', 'NUM')] 

>> Dependency Tags are: 
[('1', 'nummod'), ('1|', 'nummod'), ('      ', 'compound'), ('|', 'ROOT'), ('  ', 'nmod'), ('Lexalytics', 'nmod'), (',', 'punct'), ('Inc.', 'appos'), (',', 'punct'), ('48', 'nummod'), ('North', 'compound'), ('Pleasant', 'compound'), ('St.', 'compound'), ('Unit', 'appos'), ('301', 'nummod'), (',', 'punct'), ('Amherst', 'compound'), ('MA', 'appos'), ('01002', 'punct')]

>> Bigrams: 
[[1, 1|], [1|,       ], [      , |], [|,   ], [  , Lexalytics], [Lexalytics, ,], [,, Inc.], [Inc., ,], [,, 48], [48, North], [North, Pleasant], [Pleasant, St.], [St., Unit], [Unit, 301], [301, ,], [,, Amherst], [Amherst, MA], [MA, 01002]]

>> Trigrams: 
[[1, 1|,       ], [1|,       , |], [      , |,   ], [|,   , Lexalytics], [  , Lexalytics, ,], [Lexalytics, ,, Inc.], [,, Inc., ,], [Inc., ,, 48], [,, 48, North], [48, North, Pleasant], [North, Pleasant, St.], [Pleasant, St., Unit], [St., Unit, 301], [Unit, 301, ,], [301, ,, Amherst], [,, Amherst, MA], [Amherst, MA, 01002]]

>> Noun Phrases are: 
[1 1|       |,   Lexalytics, Inc., 48 North Pleasant St. Unit, Amherst MA]

>> Named Entities are: 
[('1 1|', 'CARDINAL'), ('Lexalytics, Inc.', 'ORG'), ('48', 'CARDINAL'), ('North Pleasant St. Unit 301', 'ORG'), ('Amherst MA', 'ORG')] 

------------------- Sentence 2 -------------------

USA 


>> Tokens are: 
[USA] 

>> PoS Tags are: 
[('USA', 'PROPN')] 

>> Dependency Tags are: 
[('USA', 'ROOT')]

>> Bigrams: 
[]

>> Trigrams: 
[]

>> Noun Phrases are: 
[USA]

>> Named Entities are: 
[] 

------------------- Sentence 3 -------------------

  |   1-800-377-8036 |   www.lexalytics.com 


>> Tokens are: 
[  , |,   , 1, -, 800, -, 377, -, 8036, |,   , www.lexalytics.com] 

>> PoS Tags are: 
[('  ', 'SPACE'), ('|', 'NOUN'), ('  ', 'SPACE'), ('1', 'NUM'), ('-', 'SYM'), ('800', 'NUM'), ('-', 'NUM'), ('377', 'NUM'), ('-', 'PUNCT'), ('8036', 'NUM'), ('|', 'NOUN'), ('  ', 'SPACE'), ('www.lexalytics.com', 'X')] 

>> Dependency Tags are: 
[('  ', 'compound'), ('|', 'npadvmod'), ('  ', 'dep'), ('1', 'npadvmod'), ('-', 'punct'), ('800', 'prep'), ('-', 'punct'), ('377', 'nummod'), ('-', 'punct'), ('8036', 'nummod'), ('|', 'npadvmod'), ('  ', 'ROOT'), ('www.lexalytics.com', 'punct')]

>> Bigrams: 
[[  , |], [|,   ], [  , 1], [1, -], [-, 800], [800, -], [-, 377], [377, -], [-, 8036], [8036, |], [|,   ], [  , www.lexalytics.com]]

>> Trigrams: 
[[  , |,   ], [|,   , 1], [  , 1, -], [1, -, 800], [-, 800, -], [800, -, 377], [-, 377, -], [377, -, 8036], [-, 8036, |], [8036, |,   ], [|,   , www.lexalytics.com]]

>> Noun Phrases are: 
[]

>> Named Entities are: 
[] 


================================ Paragraph 150 =================================

One solution to this black box problem is to break big, general models   into smaller, targeted models. 

------------------- Sentence 1 -------------------

One solution to this black box problem is to break big, general models   into smaller, targeted models. 


>> Tokens are: 
[solution, black, box, problem, break, big, ,, general, models,   , smaller, ,, targeted, models, .] 

>> PoS Tags are: 
[('solution', 'NOUN'), ('black', 'ADJ'), ('box', 'NOUN'), ('problem', 'NOUN'), ('break', 'VERB'), ('big', 'ADJ'), (',', 'PUNCT'), ('general', 'ADJ'), ('models', 'NOUN'), ('  ', 'SPACE'), ('smaller', 'ADJ'), (',', 'PUNCT'), ('targeted', 'ADJ'), ('models', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('solution', 'nsubj'), ('black', 'amod'), ('box', 'compound'), ('problem', 'pobj'), ('break', 'xcomp'), ('big', 'amod'), (',', 'punct'), ('general', 'amod'), ('models', 'dobj'), ('  ', 'appos'), ('smaller', 'amod'), (',', 'punct'), ('targeted', 'amod'), ('models', 'pobj'), ('.', 'punct')]

>> Bigrams: 
[[solution, black], [black, box], [box, problem], [problem, break], [break, big], [big, ,], [,, general], [general, models], [models,   ], [  , smaller], [smaller, ,], [,, targeted], [targeted, models], [models, .]]

>> Trigrams: 
[[solution, black, box], [black, box, problem], [box, problem, break], [problem, break, big], [break, big, ,], [big, ,, general], [,, general, models], [general, models,   ], [models,   , smaller], [  , smaller, ,], [smaller, ,, targeted], [,, targeted, models], [targeted, models, .]]

>> Noun Phrases are: 
[One solution, this black box problem, big, general models, smaller, targeted models]

>> Named Entities are: 
[('One', 'CARDINAL')] 


================================ Paragraph 151 =================================

A model’s internal decisions are often hidden from view, so you should   make sure that the model isn’t doing too much in the first place.  

------------------- Sentence 1 -------------------

A model’s internal decisions are often hidden from view, so you should   make sure that the model isn’t doing too much in the first place. 


>> Tokens are: 
[model, internal, decisions, hidden, view, ,,   , sure, model, place, .] 

>> PoS Tags are: 
[('model', 'NOUN'), ('internal', 'ADJ'), ('decisions', 'NOUN'), ('hidden', 'VERB'), ('view', 'NOUN'), (',', 'PUNCT'), ('  ', 'SPACE'), ('sure', 'ADJ'), ('model', 'NOUN'), ('place', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('model', 'poss'), ('internal', 'amod'), ('decisions', 'nsubjpass'), ('hidden', 'ccomp'), ('view', 'pobj'), (',', 'punct'), ('  ', 'nsubj'), ('sure', 'ccomp'), ('model', 'nsubj'), ('place', 'pobj'), ('.', 'punct')]

>> Bigrams: 
[[model, internal], [internal, decisions], [decisions, hidden], [hidden, view], [view, ,], [,,   ], [  , sure], [sure, model], [model, place], [place, .]]

>> Trigrams: 
[[model, internal, decisions], [internal, decisions, hidden], [decisions, hidden, view], [hidden, view, ,], [view, ,,   ], [,,   , sure], [  , sure, model], [sure, model, place], [model, place, .]]

>> Noun Phrases are: 
[A model’s internal decisions, view, you, the model, the first place]

>> Named Entities are: 
[('first', 'ORDINAL')] 

------------------- Sentence 2 -------------------

  


>> Tokens are: 
[ ] 

>> PoS Tags are: 
[(' ', 'SPACE')] 

>> Dependency Tags are: 
[(' ', 'ROOT')]

>> Bigrams: 
[]

>> Trigrams: 
[]

>> Noun Phrases are: 
[]

>> Named Entities are: 
[] 


================================ Paragraph 152 =================================

For example, if we were using one big model that analyzes an entire  document at once, we’d only be able to work at the document level. 

------------------- Sentence 1 -------------------

For example, if we were using one big model that analyzes an entire  document at once, we’d only be able to work at the document level. 


>> Tokens are: 
[example, ,, big, model, analyzes, entire,  , document, ,, able, work, document, level, .] 

>> PoS Tags are: 
[('example', 'NOUN'), (',', 'PUNCT'), ('big', 'ADJ'), ('model', 'NOUN'), ('analyzes', 'VERB'), ('entire', 'ADJ'), (' ', 'SPACE'), ('document', 'NOUN'), (',', 'PUNCT'), ('able', 'ADJ'), ('work', 'VERB'), ('document', 'NOUN'), ('level', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('example', 'pobj'), (',', 'punct'), ('big', 'amod'), ('model', 'dobj'), ('analyzes', 'relcl'), ('entire', 'amod'), (' ', 'compound'), ('document', 'dobj'), (',', 'punct'), ('able', 'acomp'), ('work', 'xcomp'), ('document', 'compound'), ('level', 'pobj'), ('.', 'punct')]

>> Bigrams: 
[[example, ,], [,, big], [big, model], [model, analyzes], [analyzes, entire], [entire,  ], [ , document], [document, ,], [,, able], [able, work], [work, document], [document, level], [level, .]]

>> Trigrams: 
[[example, ,, big], [,, big, model], [big, model, analyzes], [model, analyzes, entire], [analyzes, entire,  ], [entire,  , document], [ , document, ,], [document, ,, able], [,, able, work], [able, work, document], [work, document, level], [document, level, .]]

>> Noun Phrases are: 
[example, we, one big model, an entire  document, we, the document level]

>> Named Entities are: 
[('one', 'CARDINAL')] 


================================ Paragraph 153 =================================

Instead, Lexalytics utilizes a pipeline interaction between our models.   We start with tokenization, move on to parts of speech, then to phrases,   and all the way up until we’ve deconstructed the document at every   level. When there’s an issue in the pipeline, this approach helps us  see exactly where it is. Then, we can make adjustments to individual  components, such as retraining the part of speech tagger or tuning  its configuration files. Using smaller models gives us more flexibility to  determine where an issue is, as well as how to fix it.  

------------------- Sentence 1 -------------------

Instead, Lexalytics utilizes a pipeline interaction between our models. 


>> Tokens are: 
[Instead, ,, Lexalytics, utilizes, pipeline, interaction, models, .] 

>> PoS Tags are: 
[('Instead', 'ADV'), (',', 'PUNCT'), ('Lexalytics', 'PROPN'), ('utilizes', 'VERB'), ('pipeline', 'NOUN'), ('interaction', 'NOUN'), ('models', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('Instead', 'advmod'), (',', 'punct'), ('Lexalytics', 'nsubj'), ('utilizes', 'ROOT'), ('pipeline', 'compound'), ('interaction', 'dobj'), ('models', 'pobj'), ('.', 'punct')]

>> Bigrams: 
[[Instead, ,], [,, Lexalytics], [Lexalytics, utilizes], [utilizes, pipeline], [pipeline, interaction], [interaction, models], [models, .]]

>> Trigrams: 
[[Instead, ,, Lexalytics], [,, Lexalytics, utilizes], [Lexalytics, utilizes, pipeline], [utilizes, pipeline, interaction], [pipeline, interaction, models], [interaction, models, .]]

>> Noun Phrases are: 
[Lexalytics, a pipeline interaction, our models]

>> Named Entities are: 
[('Lexalytics', 'ORG')] 

------------------- Sentence 2 -------------------

  We start with tokenization, move on to parts of speech, then to phrases,   and all the way up until we’ve deconstructed the document at every   level. 


>> Tokens are: 
[  , start, tokenization, ,, parts, speech, ,, phrases, ,,   , way, deconstructed, document,   , level, .] 

>> PoS Tags are: 
[('  ', 'SPACE'), ('start', 'VERB'), ('tokenization', 'NOUN'), (',', 'PUNCT'), ('parts', 'NOUN'), ('speech', 'NOUN'), (',', 'PUNCT'), ('phrases', 'NOUN'), (',', 'PUNCT'), ('  ', 'SPACE'), ('way', 'NOUN'), ('deconstructed', 'VERB'), ('document', 'NOUN'), ('  ', 'SPACE'), ('level', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('  ', 'npadvmod'), ('start', 'ROOT'), ('tokenization', 'pobj'), (',', 'punct'), ('parts', 'pobj'), ('speech', 'pobj'), (',', 'punct'), ('phrases', 'pobj'), (',', 'punct'), ('  ', 'conj'), ('way', 'npadvmod'), ('deconstructed', 'advcl'), ('document', 'dobj'), ('  ', 'nummod'), ('level', 'pobj'), ('.', 'punct')]

>> Bigrams: 
[[  , start], [start, tokenization], [tokenization, ,], [,, parts], [parts, speech], [speech, ,], [,, phrases], [phrases, ,], [,,   ], [  , way], [way, deconstructed], [deconstructed, document], [document,   ], [  , level], [level, .]]

>> Trigrams: 
[[  , start, tokenization], [start, tokenization, ,], [tokenization, ,, parts], [,, parts, speech], [parts, speech, ,], [speech, ,, phrases], [,, phrases, ,], [phrases, ,,   ], [,,   , way], [  , way, deconstructed], [way, deconstructed, document], [deconstructed, document,   ], [document,   , level], [  , level, .]]

>> Noun Phrases are: 
[We, tokenization, parts, speech, phrases, we, the document, every   level]

>> Named Entities are: 
[] 

------------------- Sentence 3 -------------------

When there’s an issue in the pipeline, this approach helps us  see exactly where it is. 


>> Tokens are: 
[issue, pipeline, ,, approach, helps,  , exactly, .] 

>> PoS Tags are: 
[('issue', 'NOUN'), ('pipeline', 'NOUN'), (',', 'PUNCT'), ('approach', 'NOUN'), ('helps', 'VERB'), (' ', 'SPACE'), ('exactly', 'ADV'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('issue', 'attr'), ('pipeline', 'pobj'), (',', 'punct'), ('approach', 'nsubj'), ('helps', 'ROOT'), (' ', 'nsubj'), ('exactly', 'advmod'), ('.', 'punct')]

>> Bigrams: 
[[issue, pipeline], [pipeline, ,], [,, approach], [approach, helps], [helps,  ], [ , exactly], [exactly, .]]

>> Trigrams: 
[[issue, pipeline, ,], [pipeline, ,, approach], [,, approach, helps], [approach, helps,  ], [helps,  , exactly], [ , exactly, .]]

>> Noun Phrases are: 
[an issue, the pipeline, this approach, us, it]

>> Named Entities are: 
[] 

------------------- Sentence 4 -------------------

Then, we can make adjustments to individual  components, such as retraining the part of speech tagger or tuning  its configuration files. 


>> Tokens are: 
[,, adjustments, individual,  , components, ,, retraining, speech, tagger, tuning,  , configuration, files, .] 

>> PoS Tags are: 
[(',', 'PUNCT'), ('adjustments', 'NOUN'), ('individual', 'ADJ'), (' ', 'SPACE'), ('components', 'NOUN'), (',', 'PUNCT'), ('retraining', 'VERB'), ('speech', 'NOUN'), ('tagger', 'NOUN'), ('tuning', 'VERB'), (' ', 'SPACE'), ('configuration', 'NOUN'), ('files', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[(',', 'punct'), ('adjustments', 'dobj'), ('individual', 'amod'), (' ', 'compound'), ('components', 'pobj'), (',', 'punct'), ('retraining', 'pcomp'), ('speech', 'compound'), ('tagger', 'pobj'), ('tuning', 'conj'), (' ', 'dobj'), ('configuration', 'compound'), ('files', 'dobj'), ('.', 'punct')]

>> Bigrams: 
[[,, adjustments], [adjustments, individual], [individual,  ], [ , components], [components, ,], [,, retraining], [retraining, speech], [speech, tagger], [tagger, tuning], [tuning,  ], [ , configuration], [configuration, files], [files, .]]

>> Trigrams: 
[[,, adjustments, individual], [adjustments, individual,  ], [individual,  , components], [ , components, ,], [components, ,, retraining], [,, retraining, speech], [retraining, speech, tagger], [speech, tagger, tuning], [tagger, tuning,  ], [tuning,  , configuration], [ , configuration, files], [configuration, files, .]]

>> Noun Phrases are: 
[we, adjustments, individual  components, the part, speech tagger, its configuration files]

>> Named Entities are: 
[] 

------------------- Sentence 5 -------------------

Using smaller models gives us more flexibility to  determine where an issue is, as well as how to fix it.   


>> Tokens are: 
[smaller, models, gives, flexibility,  , determine, issue, ,, fix, .,  ] 

>> PoS Tags are: 
[('smaller', 'ADJ'), ('models', 'NOUN'), ('gives', 'VERB'), ('flexibility', 'NOUN'), (' ', 'SPACE'), ('determine', 'VERB'), ('issue', 'NOUN'), (',', 'PUNCT'), ('fix', 'VERB'), ('.', 'PUNCT'), (' ', 'SPACE')] 

>> Dependency Tags are: 
[('smaller', 'amod'), ('models', 'dobj'), ('gives', 'ROOT'), ('flexibility', 'dobj'), (' ', 'pobj'), ('determine', 'conj'), ('issue', 'nsubj'), (',', 'punct'), ('fix', 'xcomp'), ('.', 'punct'), (' ', 'dobj')]

>> Bigrams: 
[[smaller, models], [models, gives], [gives, flexibility], [flexibility,  ], [ , determine], [determine, issue], [issue, ,], [,, fix], [fix, .], [.,  ]]

>> Trigrams: 
[[smaller, models, gives], [models, gives, flexibility], [gives, flexibility,  ], [flexibility,  , determine], [ , determine, issue], [determine, issue, ,], [issue, ,, fix], [,, fix, .], [fix, .,  ]]

>> Noun Phrases are: 
[smaller models, us, more flexibility, an issue, it]

>> Named Entities are: 
[] 


================================ Paragraph 154 =================================

Take the phrase “Good   Morning America.” It looks  innocuous, but it’s not. If your  part-of-speech tagger fails to  apply “proper noun” to the  phrase “Good Morning America,”  this phrase won’t be denoted   as being an entity. 

------------------- Sentence 1 -------------------

Take the phrase “Good   Morning America.” 


>> Tokens are: 
[phrase, “, Good,   , Morning, America, ., ”] 

>> PoS Tags are: 
[('phrase', 'NOUN'), ('“', 'PUNCT'), ('Good', 'ADJ'), ('  ', 'SPACE'), ('Morning', 'PROPN'), ('America', 'PROPN'), ('.', 'PUNCT'), ('”', 'PUNCT')] 

>> Dependency Tags are: 
[('phrase', 'dobj'), ('“', 'punct'), ('Good', 'amod'), ('  ', 'appos'), ('Morning', 'compound'), ('America', 'appos'), ('.', 'punct'), ('”', 'punct')]

>> Bigrams: 
[[phrase, “], [“, Good], [Good,   ], [  , Morning], [Morning, America], [America, .], [., ”]]

>> Trigrams: 
[[phrase, “, Good], [“, Good,   ], [Good,   , Morning], [  , Morning, America], [Morning, America, .], [America, ., ”]]

>> Noun Phrases are: 
[the phrase, Morning America]

>> Named Entities are: 
[] 

------------------- Sentence 2 -------------------

It looks  innocuous, but it’s not. 


>> Tokens are: 
[looks,  , innocuous, ,, .] 

>> PoS Tags are: 
[('looks', 'VERB'), (' ', 'SPACE'), ('innocuous', 'ADJ'), (',', 'PUNCT'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('looks', 'ROOT'), (' ', 'dobj'), ('innocuous', 'acomp'), (',', 'punct'), ('.', 'punct')]

>> Bigrams: 
[[looks,  ], [ , innocuous], [innocuous, ,], [,, .]]

>> Trigrams: 
[[looks,  , innocuous], [ , innocuous, ,], [innocuous, ,, .]]

>> Noun Phrases are: 
[It, it]

>> Named Entities are: 
[] 

------------------- Sentence 3 -------------------

If your  part-of-speech tagger fails to  apply “proper noun” to the  phrase “Good Morning America,”  this phrase won’t be denoted   as being an entity. 


>> Tokens are: 
[ , -, -, speech, tagger, fails,  , apply, “, proper, noun, ”,  , phrase, “, Good, Morning, America, ,, ”,  , phrase, wo, denoted,   , entity, .] 

>> PoS Tags are: 
[(' ', 'SPACE'), ('-', 'PUNCT'), ('-', 'PUNCT'), ('speech', 'NOUN'), ('tagger', 'NOUN'), ('fails', 'VERB'), (' ', 'SPACE'), ('apply', 'VERB'), ('“', 'PUNCT'), ('proper', 'ADJ'), ('noun', 'NOUN'), ('”', 'PUNCT'), (' ', 'SPACE'), ('phrase', 'NOUN'), ('“', 'PUNCT'), ('Good', 'PROPN'), ('Morning', 'PROPN'), ('America', 'PROPN'), (',', 'PUNCT'), ('”', 'PUNCT'), (' ', 'SPACE'), ('phrase', 'NOUN'), ('wo', 'AUX'), ('denoted', 'VERB'), ('  ', 'SPACE'), ('entity', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[(' ', 'nsubj'), ('-', 'punct'), ('-', 'punct'), ('speech', 'pobj'), ('tagger', 'nsubj'), ('fails', 'advcl'), (' ', 'nsubj'), ('apply', 'xcomp'), ('“', 'punct'), ('proper', 'amod'), ('noun', 'dobj'), ('”', 'punct'), (' ', 'compound'), ('phrase', 'pobj'), ('“', 'punct'), ('Good', 'compound'), ('Morning', 'compound'), ('America', 'appos'), (',', 'punct'), ('”', 'punct'), (' ', 'dep'), ('phrase', 'nsubjpass'), ('wo', 'aux'), ('denoted', 'ROOT'), ('  ', 'dobj'), ('entity', 'attr'), ('.', 'punct')]

>> Bigrams: 
[[ , -], [-, -], [-, speech], [speech, tagger], [tagger, fails], [fails,  ], [ , apply], [apply, “], [“, proper], [proper, noun], [noun, ”], [”,  ], [ , phrase], [phrase, “], [“, Good], [Good, Morning], [Morning, America], [America, ,], [,, ”], [”,  ], [ , phrase], [phrase, wo], [wo, denoted], [denoted,   ], [  , entity], [entity, .]]

>> Trigrams: 
[[ , -, -], [-, -, speech], [-, speech, tagger], [speech, tagger, fails], [tagger, fails,  ], [fails,  , apply], [ , apply, “], [apply, “, proper], [“, proper, noun], [proper, noun, ”], [noun, ”,  ], [”,  , phrase], [ , phrase, “], [phrase, “, Good], [“, Good, Morning], [Good, Morning, America], [Morning, America, ,], [America, ,, ”], [,, ”,  ], [”,  , phrase], [ , phrase, wo], [phrase, wo, denoted], [wo, denoted,   ], [denoted,   , entity], [  , entity, .]]

>> Noun Phrases are: 
[speech, “proper noun, the  phrase, Good Morning America, this phrase, an entity]

>> Named Entities are: 
[('Good Morning America', 'WORK_OF_ART')] 


================================ Paragraph 155 =================================

You have to know that it’s an entity (TV Show) and not a greeting. If you   don’t, you might interpret “good” as being positive, rather than just part   of the entity name. 

------------------- Sentence 1 -------------------

You have to know that it’s an entity (TV Show) and not a greeting. 


>> Tokens are: 
[know, entity, (, TV, ), greeting, .] 

>> PoS Tags are: 
[('know', 'VERB'), ('entity', 'NOUN'), ('(', 'PUNCT'), ('TV', 'PROPN'), (')', 'PUNCT'), ('greeting', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('know', 'xcomp'), ('entity', 'attr'), ('(', 'punct'), ('TV', 'compound'), (')', 'punct'), ('greeting', 'conj'), ('.', 'punct')]

>> Bigrams: 
[[know, entity], [entity, (], [(, TV], [TV, )], [), greeting], [greeting, .]]

>> Trigrams: 
[[know, entity, (], [entity, (, TV], [(, TV, )], [TV, ), greeting], [), greeting, .]]

>> Noun Phrases are: 
[You, it, an entity, (TV Show, not a greeting]

>> Named Entities are: 
[] 

------------------- Sentence 2 -------------------

If you   don’t, you might interpret “good” as being positive, rather than just part   of the entity name. 


>> Tokens are: 
[  , ,, interpret, “, good, ”, positive, ,,   , entity, .] 

>> PoS Tags are: 
[('  ', 'SPACE'), (',', 'PUNCT'), ('interpret', 'VERB'), ('“', 'PUNCT'), ('good', 'ADJ'), ('”', 'PUNCT'), ('positive', 'ADJ'), (',', 'PUNCT'), ('  ', 'SPACE'), ('entity', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('  ', 'appos'), (',', 'punct'), ('interpret', 'ROOT'), ('“', 'punct'), ('good', 'dobj'), ('”', 'punct'), ('positive', 'acomp'), (',', 'punct'), ('  ', 'dobj'), ('entity', 'compound'), ('.', 'punct')]

>> Bigrams: 
[[  , ,], [,, interpret], [interpret, “], [“, good], [good, ”], [”, positive], [positive, ,], [,,   ], [  , entity], [entity, .]]

>> Trigrams: 
[[  , ,, interpret], [,, interpret, “], [interpret, “, good], [“, good, ”], [good, ”, positive], [”, positive, ,], [positive, ,,   ], [,,   , entity], [  , entity, .]]

>> Noun Phrases are: 
[you, you, the entity name]

>> Named Entities are: 
[] 


================================ Paragraph 156 =================================

GOOD MORNING AMERICA is a registered trademark and brand of American Broadcasting Companies, Inc.  and is not affiliated with Lexalytics, Inc

------------------- Sentence 1 -------------------

GOOD MORNING AMERICA is a registered trademark and brand of American Broadcasting Companies, Inc.  and is not affiliated with Lexalytics, 


>> Tokens are: 
[GOOD, MORNING, AMERICA, registered, trademark, brand, American, Broadcasting, Companies, ,, Inc.,  , affiliated, Lexalytics, ,] 

>> PoS Tags are: 
[('GOOD', 'ADJ'), ('MORNING', 'NOUN'), ('AMERICA', 'PROPN'), ('registered', 'VERB'), ('trademark', 'NOUN'), ('brand', 'NOUN'), ('American', 'PROPN'), ('Broadcasting', 'PROPN'), ('Companies', 'PROPN'), (',', 'PUNCT'), ('Inc.', 'PROPN'), (' ', 'SPACE'), ('affiliated', 'VERB'), ('Lexalytics', 'PROPN'), (',', 'PUNCT')] 

>> Dependency Tags are: 
[('GOOD', 'amod'), ('MORNING', 'compound'), ('AMERICA', 'nsubj'), ('registered', 'amod'), ('trademark', 'attr'), ('brand', 'conj'), ('American', 'compound'), ('Broadcasting', 'compound'), ('Companies', 'pobj'), (',', 'punct'), ('Inc.', 'appos'), (' ', 'conj'), ('affiliated', 'conj'), ('Lexalytics', 'pobj'), (',', 'punct')]

>> Bigrams: 
[[GOOD, MORNING], [MORNING, AMERICA], [AMERICA, registered], [registered, trademark], [trademark, brand], [brand, American], [American, Broadcasting], [Broadcasting, Companies], [Companies, ,], [,, Inc.], [Inc.,  ], [ , affiliated], [affiliated, Lexalytics], [Lexalytics, ,]]

>> Trigrams: 
[[GOOD, MORNING, AMERICA], [MORNING, AMERICA, registered], [AMERICA, registered, trademark], [registered, trademark, brand], [trademark, brand, American], [brand, American, Broadcasting], [American, Broadcasting, Companies], [Broadcasting, Companies, ,], [Companies, ,, Inc.], [,, Inc.,  ], [Inc.,  , affiliated], [ , affiliated, Lexalytics], [affiliated, Lexalytics, ,]]

>> Noun Phrases are: 
[GOOD MORNING AMERICA, a registered trademark, brand, American Broadcasting Companies, Inc., Lexalytics]

>> Named Entities are: 
[('American Broadcasting Companies, Inc.', 'ORG'), ('Lexalytics', 'ORG')] 

------------------- Sentence 2 -------------------

Inc 


>> Tokens are: 
[Inc] 

>> PoS Tags are: 
[('Inc', 'PROPN')] 

>> Dependency Tags are: 
[('Inc', 'ROOT')]

>> Bigrams: 
[]

>> Trigrams: 
[]

>> Noun Phrases are: 
[Inc]

>> Named Entities are: 
[] 


================================ Paragraph 157 =================================

W H I T E  P A P E R 

------------------- Sentence 1 -------------------

W H 


>> Tokens are: 
[W, H] 

>> PoS Tags are: 
[('W', 'NOUN'), ('H', 'NOUN')] 

>> Dependency Tags are: 
[('W', 'compound'), ('H', 'ROOT')]

>> Bigrams: 
[[W, H]]

>> Trigrams: 
[]

>> Noun Phrases are: 
[W H]

>> Named Entities are: 
[] 

------------------- Sentence 2 -------------------

I T 


>> Tokens are: 
[T] 

>> PoS Tags are: 
[('T', 'NOUN')] 

>> Dependency Tags are: 
[('T', 'appos')]

>> Bigrams: 
[]

>> Trigrams: 
[]

>> Noun Phrases are: 
[I, T]

>> Named Entities are: 
[] 

------------------- Sentence 3 -------------------

E   


>> Tokens are: 
[E,  ] 

>> PoS Tags are: 
[('E', 'NOUN'), (' ', 'SPACE')] 

>> Dependency Tags are: 
[('E', 'ROOT'), (' ', 'appos')]

>> Bigrams: 
[[E,  ]]

>> Trigrams: 
[]

>> Noun Phrases are: 
[E]

>> Named Entities are: 
[] 

------------------- Sentence 4 -------------------

P A P E R 


>> Tokens are: 
[P, P, E, R] 

>> PoS Tags are: 
[('P', 'NOUN'), ('P', 'NOUN'), ('E', 'NOUN'), ('R', 'NOUN')] 

>> Dependency Tags are: 
[('P', 'compound'), ('P', 'compound'), ('E', 'compound'), ('R', 'ROOT')]

>> Bigrams: 
[[P, P], [P, E], [E, R]]

>> Trigrams: 
[[P, P, E], [P, E, R]]

>> Noun Phrases are: 
[P A P E R]

>> Named Entities are: 
[] 


================================ Paragraph 158 =================================

12|       |   Lexalytics, Inc., 48 North Pleasant St. Unit 301, Amherst MA 01002 USA   |   1-800-377-8036 |   www.lexalytics.com 

------------------- Sentence 1 -------------------

12|       |   Lexalytics, Inc., 48 North Pleasant St. Unit 301, Amherst MA 01002 


>> Tokens are: 
[12|,       , |,   , Lexalytics, ,, Inc., ,, 48, North, Pleasant, St., Unit, 301, ,, Amherst, MA, 01002] 

>> PoS Tags are: 
[('12|', 'NUM'), ('      ', 'SPACE'), ('|', 'NOUN'), ('  ', 'SPACE'), ('Lexalytics', 'PROPN'), (',', 'PUNCT'), ('Inc.', 'PROPN'), (',', 'PUNCT'), ('48', 'NUM'), ('North', 'PROPN'), ('Pleasant', 'PROPN'), ('St.', 'PROPN'), ('Unit', 'PROPN'), ('301', 'NUM'), (',', 'PUNCT'), ('Amherst', 'PROPN'), ('MA', 'PROPN'), ('01002', 'NUM')] 

>> Dependency Tags are: 
[('12|', 'nummod'), ('      ', 'compound'), ('|', 'ROOT'), ('  ', 'nmod'), ('Lexalytics', 'nmod'), (',', 'punct'), ('Inc.', 'appos'), (',', 'punct'), ('48', 'nummod'), ('North', 'compound'), ('Pleasant', 'compound'), ('St.', 'compound'), ('Unit', 'appos'), ('301', 'nummod'), (',', 'punct'), ('Amherst', 'compound'), ('MA', 'appos'), ('01002', 'punct')]

>> Bigrams: 
[[12|,       ], [      , |], [|,   ], [  , Lexalytics], [Lexalytics, ,], [,, Inc.], [Inc., ,], [,, 48], [48, North], [North, Pleasant], [Pleasant, St.], [St., Unit], [Unit, 301], [301, ,], [,, Amherst], [Amherst, MA], [MA, 01002]]

>> Trigrams: 
[[12|,       , |], [      , |,   ], [|,   , Lexalytics], [  , Lexalytics, ,], [Lexalytics, ,, Inc.], [,, Inc., ,], [Inc., ,, 48], [,, 48, North], [48, North, Pleasant], [North, Pleasant, St.], [Pleasant, St., Unit], [St., Unit, 301], [Unit, 301, ,], [301, ,, Amherst], [,, Amherst, MA], [Amherst, MA, 01002]]

>> Noun Phrases are: 
[12|       |,   Lexalytics, Inc., 48 North Pleasant St. Unit, Amherst MA]

>> Named Entities are: 
[('12|', 'CARDINAL'), ('Lexalytics, Inc.', 'ORG'), ('48', 'CARDINAL'), ('North Pleasant St. Unit 301', 'ORG'), ('Amherst MA', 'ORG')] 

------------------- Sentence 2 -------------------

USA 


>> Tokens are: 
[USA] 

>> PoS Tags are: 
[('USA', 'PROPN')] 

>> Dependency Tags are: 
[('USA', 'ROOT')]

>> Bigrams: 
[]

>> Trigrams: 
[]

>> Noun Phrases are: 
[USA]

>> Named Entities are: 
[] 

------------------- Sentence 3 -------------------

  |   1-800-377-8036 |   www.lexalytics.com 


>> Tokens are: 
[  , |,   , 1, -, 800, -, 377, -, 8036, |,   , www.lexalytics.com] 

>> PoS Tags are: 
[('  ', 'SPACE'), ('|', 'NOUN'), ('  ', 'SPACE'), ('1', 'NUM'), ('-', 'SYM'), ('800', 'NUM'), ('-', 'NUM'), ('377', 'NUM'), ('-', 'PUNCT'), ('8036', 'NUM'), ('|', 'NOUN'), ('  ', 'SPACE'), ('www.lexalytics.com', 'X')] 

>> Dependency Tags are: 
[('  ', 'compound'), ('|', 'npadvmod'), ('  ', 'dep'), ('1', 'npadvmod'), ('-', 'punct'), ('800', 'prep'), ('-', 'punct'), ('377', 'nummod'), ('-', 'punct'), ('8036', 'nummod'), ('|', 'npadvmod'), ('  ', 'ROOT'), ('www.lexalytics.com', 'punct')]

>> Bigrams: 
[[  , |], [|,   ], [  , 1], [1, -], [-, 800], [800, -], [-, 377], [377, -], [-, 8036], [8036, |], [|,   ], [  , www.lexalytics.com]]

>> Trigrams: 
[[  , |,   ], [|,   , 1], [  , 1, -], [1, -, 800], [-, 800, -], [800, -, 377], [-, 377, -], [377, -, 8036], [-, 8036, |], [8036, |,   ], [|,   , www.lexalytics.com]]

>> Noun Phrases are: 
[]

>> Named Entities are: 
[] 


================================ Paragraph 159 =================================

T U N E  F I R S T ,  T H E N  T R A I N :   E F F I C I E N C Y  B E F O R E  C O M P L E X I T Y  We have a whole white paper devoted to this discussion, but let’s review   the key points. We talked above about how machine learning is really  machine teaching, and how changing how a model interprets something  means having to convince it to do that. To achieve this, you have to have   data, and enough of it, that supports the changes needed to make the  model behave differently. 

------------------- Sentence 1 -------------------

T U N E  F I R S T ,  T H 


>> Tokens are: 
[T, U, N, E,  , F, R, S, T, ,,  , T, H] 

>> PoS Tags are: 
[('T', 'NOUN'), ('U', 'NOUN'), ('N', 'PROPN'), ('E', 'NOUN'), (' ', 'SPACE'), ('F', 'NOUN'), ('R', 'NOUN'), ('S', 'PROPN'), ('T', 'PROPN'), (',', 'PUNCT'), (' ', 'SPACE'), ('T', 'NOUN'), ('H', 'NOUN')] 

>> Dependency Tags are: 
[('T', 'compound'), ('U', 'ROOT'), ('N', 'compound'), ('E', 'appos'), (' ', 'appos'), ('F', 'compound'), ('R', 'compound'), ('S', 'compound'), ('T', 'appos'), (',', 'punct'), (' ', 'punct'), ('T', 'compound'), ('H', 'appos')]

>> Bigrams: 
[[T, U], [U, N], [N, E], [E,  ], [ , F], [F, R], [R, S], [S, T], [T, ,], [,,  ], [ , T], [T, H]]

>> Trigrams: 
[[T, U, N], [U, N, E], [N, E,  ], [E,  , F], [ , F, R], [F, R, S], [R, S, T], [S, T, ,], [T, ,,  ], [,,  , T], [ , T, H]]

>> Noun Phrases are: 
[T U, N E, F I R S T, T H]

>> Named Entities are: 
[('U N E  ', 'ORG')] 

------------------- Sentence 2 -------------------

E N  T R A 


>> Tokens are: 
[E, N,  , T, R] 

>> PoS Tags are: 
[('E', 'NOUN'), ('N', 'PROPN'), (' ', 'SPACE'), ('T', 'NOUN'), ('R', 'NOUN')] 

>> Dependency Tags are: 
[('E', 'ROOT'), ('N', 'npadvmod'), (' ', 'compound'), ('T', 'compound'), ('R', 'compound')]

>> Bigrams: 
[[E, N], [N,  ], [ , T], [T, R]]

>> Trigrams: 
[[E, N,  ], [N,  , T], [ , T, R]]

>> Noun Phrases are: 
[E,  T R A]

>> Named Entities are: 
[] 

------------------- Sentence 3 -------------------

I N :   E F F I C 


>> Tokens are: 
[N, :,   , E, F, F, C] 

>> PoS Tags are: 
[('N', 'NUM'), (':', 'PUNCT'), ('  ', 'SPACE'), ('E', 'NOUN'), ('F', 'NOUN'), ('F', 'NOUN'), ('C', 'NOUN')] 

>> Dependency Tags are: 
[('N', 'appos'), (':', 'punct'), ('  ', 'appos'), ('E', 'compound'), ('F', 'compound'), ('F', 'appos'), ('C', 'appos')]

>> Bigrams: 
[[N, :], [:,   ], [  , E], [E, F], [F, F], [F, C]]

>> Trigrams: 
[[N, :,   ], [:,   , E], [  , E, F], [E, F, F], [F, F, C]]

>> Noun Phrases are: 
[I, E F F, I]

>> Named Entities are: 
[] 

------------------- Sentence 4 -------------------

I E N C Y  B E F O R 


>> Tokens are: 
[E, N, C, Y,  , B, E, F, O, R] 

>> PoS Tags are: 
[('E', 'NOUN'), ('N', 'PROPN'), ('C', 'PROPN'), ('Y', 'PROPN'), (' ', 'SPACE'), ('B', 'NOUN'), ('E', 'NOUN'), ('F', 'NOUN'), ('O', 'NOUN'), ('R', 'NOUN')] 

>> Dependency Tags are: 
[('E', 'ROOT'), ('N', 'compound'), ('C', 'compound'), ('Y', 'compound'), (' ', 'compound'), ('B', 'compound'), ('E', 'compound'), ('F', 'compound'), ('O', 'compound'), ('R', 'appos')]

>> Bigrams: 
[[E, N], [N, C], [C, Y], [Y,  ], [ , B], [B, E], [E, F], [F, O], [O, R]]

>> Trigrams: 
[[E, N, C], [N, C, Y], [C, Y,  ], [Y,  , B], [ , B, E], [B, E, F], [E, F, O], [F, O, R]]

>> Noun Phrases are: 
[I E, N C Y  B E F O R]

>> Named Entities are: 
[] 

------------------- Sentence 5 -------------------

E  C O M P L E X 


>> Tokens are: 
[E,  , C, O, M, P, L, E, X] 

>> PoS Tags are: 
[('E', 'NOUN'), (' ', 'SPACE'), ('C', 'NOUN'), ('O', 'NOUN'), ('M', 'NOUN'), ('P', 'NOUN'), ('L', 'PROPN'), ('E', 'PROPN'), ('X', 'NOUN')] 

>> Dependency Tags are: 
[('E', 'nmod'), (' ', 'appos'), ('C', 'compound'), ('O', 'compound'), ('M', 'compound'), ('P', 'compound'), ('L', 'compound'), ('E', 'compound'), ('X', 'ROOT')]

>> Bigrams: 
[[E,  ], [ , C], [C, O], [O, M], [M, P], [P, L], [L, E], [E, X]]

>> Trigrams: 
[[E,  , C], [ , C, O], [C, O, M], [O, M, P], [M, P, L], [P, L, E], [L, E, X]]

>> Noun Phrases are: 
[E  C O M P L E X]

>> Named Entities are: 
[] 

------------------- Sentence 6 -------------------

I T Y   


>> Tokens are: 
[T, Y,  ] 

>> PoS Tags are: 
[('T', 'NOUN'), ('Y', 'PROPN'), (' ', 'SPACE')] 

>> Dependency Tags are: 
[('T', 'compound'), ('Y', 'ROOT'), (' ', 'punct')]

>> Bigrams: 
[[T, Y], [Y,  ]]

>> Trigrams: 
[[T, Y,  ]]

>> Noun Phrases are: 
[I T Y]

>> Named Entities are: 
[] 

------------------- Sentence 7 -------------------

We have a whole white paper devoted to this discussion, but let’s review   the key points. 


>> Tokens are: 
[white, paper, devoted, discussion, ,, let, review,   , key, points, .] 

>> PoS Tags are: 
[('white', 'ADJ'), ('paper', 'NOUN'), ('devoted', 'VERB'), ('discussion', 'NOUN'), (',', 'PUNCT'), ('let', 'VERB'), ('review', 'VERB'), ('  ', 'SPACE'), ('key', 'ADJ'), ('points', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('white', 'amod'), ('paper', 'dobj'), ('devoted', 'acl'), ('discussion', 'pobj'), (',', 'punct'), ('let', 'conj'), ('review', 'ccomp'), ('  ', 'dobj'), ('key', 'amod'), ('points', 'npadvmod'), ('.', 'punct')]

>> Bigrams: 
[[white, paper], [paper, devoted], [devoted, discussion], [discussion, ,], [,, let], [let, review], [review,   ], [  , key], [key, points], [points, .]]

>> Trigrams: 
[[white, paper, devoted], [paper, devoted, discussion], [devoted, discussion, ,], [discussion, ,, let], [,, let, review], [let, review,   ], [review,   , key], [  , key, points], [key, points, .]]

>> Noun Phrases are: 
[We, a whole white paper, this discussion, ’s]

>> Named Entities are: 
[('’s', 'GPE')] 

------------------- Sentence 8 -------------------

We talked above about how machine learning is really  machine teaching, and how changing how a model interprets something  means having to convince it to do that. 


>> Tokens are: 
[talked, machine, learning,  , machine, teaching, ,, changing, model, interprets,  , means, having, convince, .] 

>> PoS Tags are: 
[('talked', 'VERB'), ('machine', 'NOUN'), ('learning', 'NOUN'), (' ', 'SPACE'), ('machine', 'NOUN'), ('teaching', 'NOUN'), (',', 'PUNCT'), ('changing', 'VERB'), ('model', 'NOUN'), ('interprets', 'VERB'), (' ', 'SPACE'), ('means', 'VERB'), ('having', 'VERB'), ('convince', 'VERB'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('talked', 'ROOT'), ('machine', 'compound'), ('learning', 'nsubj'), (' ', 'amod'), ('machine', 'compound'), ('teaching', 'attr'), (',', 'punct'), ('changing', 'conj'), ('model', 'nsubj'), ('interprets', 'ccomp'), (' ', 'nsubj'), ('means', 'relcl'), ('having', 'xcomp'), ('convince', 'xcomp'), ('.', 'punct')]

>> Bigrams: 
[[talked, machine], [machine, learning], [learning,  ], [ , machine], [machine, teaching], [teaching, ,], [,, changing], [changing, model], [model, interprets], [interprets,  ], [ , means], [means, having], [having, convince], [convince, .]]

>> Trigrams: 
[[talked, machine, learning], [machine, learning,  ], [learning,  , machine], [ , machine, teaching], [machine, teaching, ,], [teaching, ,, changing], [,, changing, model], [changing, model, interprets], [model, interprets,  ], [interprets,  , means], [ , means, having], [means, having, convince], [having, convince, .]]

>> Noun Phrases are: 
[We, machine learning, really  machine teaching, a model, something, it]

>> Named Entities are: 
[] 

------------------- Sentence 9 -------------------

To achieve this, you have to have   data, and enough of it, that supports the changes needed to make the  model behave differently. 


>> Tokens are: 
[achieve, ,,   , data, ,, ,, supports, changes, needed,  , model, behave, differently, .] 

>> PoS Tags are: 
[('achieve', 'VERB'), (',', 'PUNCT'), ('  ', 'SPACE'), ('data', 'NOUN'), (',', 'PUNCT'), (',', 'PUNCT'), ('supports', 'VERB'), ('changes', 'NOUN'), ('needed', 'VERB'), (' ', 'SPACE'), ('model', 'NOUN'), ('behave', 'VERB'), ('differently', 'ADV'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('achieve', 'advcl'), (',', 'punct'), ('  ', 'nummod'), ('data', 'dobj'), (',', 'punct'), (',', 'punct'), ('supports', 'conj'), ('changes', 'dobj'), ('needed', 'acl'), (' ', 'compound'), ('model', 'nsubj'), ('behave', 'ccomp'), ('differently', 'advmod'), ('.', 'punct')]

>> Bigrams: 
[[achieve, ,], [,,   ], [  , data], [data, ,], [,, ,], [,, supports], [supports, changes], [changes, needed], [needed,  ], [ , model], [model, behave], [behave, differently], [differently, .]]

>> Trigrams: 
[[achieve, ,,   ], [,,   , data], [  , data, ,], [data, ,, ,], [,, ,, supports], [,, supports, changes], [supports, changes, needed], [changes, needed,  ], [needed,  , model], [ , model, behave], [model, behave, differently], [behave, differently, .]]

>> Noun Phrases are: 
[you,   data, it, the changes, the  model]

>> Named Entities are: 
[] 


================================ Paragraph 160 =================================

This is different than tuning. Tuning is a type of written instruction. With  tuning, you might tell a model that the airport term “gate change” carries   

------------------- Sentence 1 -------------------

This is different than tuning. 


>> Tokens are: 
[different, tuning, .] 

>> PoS Tags are: 
[('different', 'ADJ'), ('tuning', 'VERB'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('different', 'acomp'), ('tuning', 'pcomp'), ('.', 'punct')]

>> Bigrams: 
[[different, tuning], [tuning, .]]

>> Trigrams: 
[[different, tuning, .]]

>> Noun Phrases are: 
[]

>> Named Entities are: 
[] 

------------------- Sentence 2 -------------------

Tuning is a type of written instruction. 


>> Tokens are: 
[Tuning, type, written, instruction, .] 

>> PoS Tags are: 
[('Tuning', 'NOUN'), ('type', 'NOUN'), ('written', 'VERB'), ('instruction', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('Tuning', 'nsubj'), ('type', 'attr'), ('written', 'amod'), ('instruction', 'pobj'), ('.', 'punct')]

>> Bigrams: 
[[Tuning, type], [type, written], [written, instruction], [instruction, .]]

>> Trigrams: 
[[Tuning, type, written], [type, written, instruction], [written, instruction, .]]

>> Noun Phrases are: 
[Tuning, a type, written instruction]

>> Named Entities are: 
[] 

------------------- Sentence 3 -------------------

With  tuning, you might tell a model that the airport term “gate change” carries    


>> Tokens are: 
[ , tuning, ,, tell, model, airport, term, “, gate, change, ”, carries,   ] 

>> PoS Tags are: 
[(' ', 'SPACE'), ('tuning', 'VERB'), (',', 'PUNCT'), ('tell', 'VERB'), ('model', 'NOUN'), ('airport', 'NOUN'), ('term', 'NOUN'), ('“', 'PUNCT'), ('gate', 'NOUN'), ('change', 'NOUN'), ('”', 'PUNCT'), ('carries', 'VERB'), ('  ', 'SPACE')] 

>> Dependency Tags are: 
[(' ', 'nsubj'), ('tuning', 'pcomp'), (',', 'punct'), ('tell', 'ROOT'), ('model', 'dobj'), ('airport', 'nmod'), ('term', 'nmod'), ('“', 'punct'), ('gate', 'amod'), ('change', 'nsubj'), ('”', 'punct'), ('carries', 'ccomp'), ('  ', 'dobj')]

>> Bigrams: 
[[ , tuning], [tuning, ,], [,, tell], [tell, model], [model, airport], [airport, term], [term, “], [“, gate], [gate, change], [change, ”], [”, carries], [carries,   ]]

>> Trigrams: 
[[ , tuning, ,], [tuning, ,, tell], [,, tell, model], [tell, model, airport], [model, airport, term], [airport, term, “], [term, “, gate], [“, gate, change], [gate, change, ”], [change, ”, carries], [”, carries,   ]]

>> Noun Phrases are: 
[you, a model, the airport term “gate change]

>> Named Entities are: 
[] 


================================ Paragraph 161 =================================

-0.5 sentiment points, and that this value should be used every time the  model sees the phrase. This new command will instantly apply to everything  that matches the entry. Training, on the other hand, requires the model  to parse a significant amount of data before it starts to apply (“learn”) the  change. Additionally, the more the model “wants” to score something a  particular way, the more that you’re going to have to work to change it.   Old habits are hard to unlearn for machine learning systems, too. 

------------------- Sentence 1 -------------------

-0.5 sentiment points, and that this value should be used every time the  model sees the phrase. 


>> Tokens are: 
[-0.5, sentiment, points, ,, value, time,  , model, sees, phrase, .] 

>> PoS Tags are: 
[('-0.5', 'NOUN'), ('sentiment', 'NOUN'), ('points', 'NOUN'), (',', 'PUNCT'), ('value', 'NOUN'), ('time', 'NOUN'), (' ', 'SPACE'), ('model', 'NOUN'), ('sees', 'VERB'), ('phrase', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('-0.5', 'compound'), ('sentiment', 'compound'), ('points', 'ROOT'), (',', 'punct'), ('value', 'nsubjpass'), ('time', 'npadvmod'), (' ', 'compound'), ('model', 'nsubj'), ('sees', 'ccomp'), ('phrase', 'dobj'), ('.', 'punct')]

>> Bigrams: 
[[-0.5, sentiment], [sentiment, points], [points, ,], [,, value], [value, time], [time,  ], [ , model], [model, sees], [sees, phrase], [phrase, .]]

>> Trigrams: 
[[-0.5, sentiment, points], [sentiment, points, ,], [points, ,, value], [,, value, time], [value, time,  ], [time,  , model], [ , model, sees], [model, sees, phrase], [sees, phrase, .]]

>> Noun Phrases are: 
[-0.5 sentiment points, this value, the  model, the phrase]

>> Named Entities are: 
[] 

------------------- Sentence 2 -------------------

This new command will instantly apply to everything  that matches the entry. 


>> Tokens are: 
[new, command, instantly, apply,  , matches, entry, .] 

>> PoS Tags are: 
[('new', 'ADJ'), ('command', 'NOUN'), ('instantly', 'ADV'), ('apply', 'VERB'), (' ', 'SPACE'), ('matches', 'VERB'), ('entry', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('new', 'amod'), ('command', 'nsubj'), ('instantly', 'advmod'), ('apply', 'ROOT'), (' ', 'appos'), ('matches', 'relcl'), ('entry', 'dobj'), ('.', 'punct')]

>> Bigrams: 
[[new, command], [command, instantly], [instantly, apply], [apply,  ], [ , matches], [matches, entry], [entry, .]]

>> Trigrams: 
[[new, command, instantly], [command, instantly, apply], [instantly, apply,  ], [apply,  , matches], [ , matches, entry], [matches, entry, .]]

>> Noun Phrases are: 
[This new command, everything, the entry]

>> Named Entities are: 
[] 

------------------- Sentence 3 -------------------

Training, on the other hand, requires the model  to parse a significant amount of data before it starts to apply (“learn”) the  change. 


>> Tokens are: 
[Training, ,, hand, ,, requires, model,  , parse, significant, data, starts, apply, (, “, learn, ”, ),  , change, .] 

>> PoS Tags are: 
[('Training', 'NOUN'), (',', 'PUNCT'), ('hand', 'NOUN'), (',', 'PUNCT'), ('requires', 'VERB'), ('model', 'NOUN'), (' ', 'SPACE'), ('parse', 'VERB'), ('significant', 'ADJ'), ('data', 'NOUN'), ('starts', 'VERB'), ('apply', 'VERB'), ('(', 'PUNCT'), ('“', 'PUNCT'), ('learn', 'VERB'), ('”', 'PUNCT'), (')', 'PUNCT'), (' ', 'SPACE'), ('change', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('Training', 'nsubj'), (',', 'punct'), ('hand', 'pobj'), (',', 'punct'), ('requires', 'ROOT'), ('model', 'dobj'), (' ', 'appos'), ('parse', 'xcomp'), ('significant', 'amod'), ('data', 'pobj'), ('starts', 'advcl'), ('apply', 'xcomp'), ('(', 'punct'), ('“', 'punct'), ('learn', 'parataxis'), ('”', 'punct'), (')', 'punct'), (' ', 'compound'), ('change', 'dobj'), ('.', 'punct')]

>> Bigrams: 
[[Training, ,], [,, hand], [hand, ,], [,, requires], [requires, model], [model,  ], [ , parse], [parse, significant], [significant, data], [data, starts], [starts, apply], [apply, (], [(, “], [“, learn], [learn, ”], [”, )], [),  ], [ , change], [change, .]]

>> Trigrams: 
[[Training, ,, hand], [,, hand, ,], [hand, ,, requires], [,, requires, model], [requires, model,  ], [model,  , parse], [ , parse, significant], [parse, significant, data], [significant, data, starts], [data, starts, apply], [starts, apply, (], [apply, (, “], [(, “, learn], [“, learn, ”], [learn, ”, )], [”, ),  ], [),  , change], [ , change, .]]

>> Noun Phrases are: 
[Training, the other hand, the model, a significant amount, data, it, the  change]

>> Named Entities are: 
[] 

------------------- Sentence 4 -------------------

Additionally, the more the model “wants” to score something a  particular way, the more that you’re going to have to work to change it. 


>> Tokens are: 
[Additionally, ,, model, “, wants, ”, score,  , particular, way, ,, going, work, change, .] 

>> PoS Tags are: 
[('Additionally', 'ADV'), (',', 'PUNCT'), ('model', 'NOUN'), ('“', 'PUNCT'), ('wants', 'VERB'), ('”', 'PUNCT'), ('score', 'VERB'), (' ', 'SPACE'), ('particular', 'ADJ'), ('way', 'NOUN'), (',', 'PUNCT'), ('going', 'VERB'), ('work', 'VERB'), ('change', 'VERB'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('Additionally', 'advmod'), (',', 'punct'), ('model', 'nsubj'), ('“', 'punct'), ('wants', 'ROOT'), ('”', 'punct'), ('score', 'xcomp'), (' ', 'nmod'), ('particular', 'amod'), ('way', 'npadvmod'), (',', 'punct'), ('going', 'relcl'), ('work', 'xcomp'), ('change', 'advcl'), ('.', 'punct')]

>> Bigrams: 
[[Additionally, ,], [,, model], [model, “], [“, wants], [wants, ”], [”, score], [score,  ], [ , particular], [particular, way], [way, ,], [,, going], [going, work], [work, change], [change, .]]

>> Trigrams: 
[[Additionally, ,, model], [,, model, “], [model, “, wants], [“, wants, ”], [wants, ”, score], [”, score,  ], [score,  , particular], [ , particular, way], [particular, way, ,], [way, ,, going], [,, going, work], [going, work, change], [work, change, .]]

>> Noun Phrases are: 
[the model, something, you, it]

>> Named Entities are: 
[] 

------------------- Sentence 5 -------------------

  Old habits are hard to unlearn for machine learning systems, too. 


>> Tokens are: 
[  , Old, habits, hard, unlearn, machine, learning, systems, ,, .] 

>> PoS Tags are: 
[('  ', 'SPACE'), ('Old', 'ADJ'), ('habits', 'NOUN'), ('hard', 'ADJ'), ('unlearn', 'VERB'), ('machine', 'NOUN'), ('learning', 'NOUN'), ('systems', 'NOUN'), (',', 'PUNCT'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('  ', 'nummod'), ('Old', 'amod'), ('habits', 'nsubj'), ('hard', 'acomp'), ('unlearn', 'xcomp'), ('machine', 'compound'), ('learning', 'compound'), ('systems', 'pobj'), (',', 'punct'), ('.', 'punct')]

>> Bigrams: 
[[  , Old], [Old, habits], [habits, hard], [hard, unlearn], [unlearn, machine], [machine, learning], [learning, systems], [systems, ,], [,, .]]

>> Trigrams: 
[[  , Old, habits], [Old, habits, hard], [habits, hard, unlearn], [hard, unlearn, machine], [unlearn, machine, learning], [machine, learning, systems], [learning, systems, ,], [systems, ,, .]]

>> Noun Phrases are: 
[  Old habits, machine learning systems]

>> Named Entities are: 
[] 


================================ Paragraph 162 =================================

Assuming the right use case, tuning will always be faster.  But there are many cases when the use of a particular word    is so multifaceted or ambiguous that the number of tuning     rules we’d have to put into place is prohibitive. This is where       machine learning shines. Give the model enough examples,         and it figures out the rules for itself.

------------------- Sentence 1 -------------------

Assuming the right use case, tuning will always be faster. 


>> Tokens are: 
[Assuming, right, use, case, ,, tuning, faster, .] 

>> PoS Tags are: 
[('Assuming', 'VERB'), ('right', 'ADJ'), ('use', 'NOUN'), ('case', 'NOUN'), (',', 'PUNCT'), ('tuning', 'NOUN'), ('faster', 'ADJ'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('Assuming', 'advcl'), ('right', 'amod'), ('use', 'compound'), ('case', 'dobj'), (',', 'punct'), ('tuning', 'nsubj'), ('faster', 'acomp'), ('.', 'punct')]

>> Bigrams: 
[[Assuming, right], [right, use], [use, case], [case, ,], [,, tuning], [tuning, faster], [faster, .]]

>> Trigrams: 
[[Assuming, right, use], [right, use, case], [use, case, ,], [case, ,, tuning], [,, tuning, faster], [tuning, faster, .]]

>> Noun Phrases are: 
[the right use case, tuning]

>> Named Entities are: 
[] 

------------------- Sentence 2 -------------------

  


>> Tokens are: 
[ ] 

>> PoS Tags are: 
[(' ', 'SPACE')] 

>> Dependency Tags are: 
[(' ', 'ROOT')]

>> Bigrams: 
[]

>> Trigrams: 
[]

>> Noun Phrases are: 
[]

>> Named Entities are: 
[] 

------------------- Sentence 3 -------------------

But there are many cases when the use of a particular word    is so multifaceted or ambiguous that the number of tuning     rules we’d have to put into place is prohibitive. 


>> Tokens are: 
[cases, use, particular, word,    , multifaceted, ambiguous, number, tuning,     , rules, place, prohibitive, .] 

>> PoS Tags are: 
[('cases', 'NOUN'), ('use', 'NOUN'), ('particular', 'ADJ'), ('word', 'NOUN'), ('   ', 'SPACE'), ('multifaceted', 'ADJ'), ('ambiguous', 'ADJ'), ('number', 'NOUN'), ('tuning', 'VERB'), ('    ', 'SPACE'), ('rules', 'NOUN'), ('place', 'NOUN'), ('prohibitive', 'ADJ'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('cases', 'attr'), ('use', 'nsubj'), ('particular', 'amod'), ('word', 'pobj'), ('   ', 'nummod'), ('multifaceted', 'acomp'), ('ambiguous', 'conj'), ('number', 'nsubj'), ('tuning', 'pcomp'), ('    ', 'compound'), ('rules', 'dobj'), ('place', 'pobj'), ('prohibitive', 'acomp'), ('.', 'punct')]

>> Bigrams: 
[[cases, use], [use, particular], [particular, word], [word,    ], [   , multifaceted], [multifaceted, ambiguous], [ambiguous, number], [number, tuning], [tuning,     ], [    , rules], [rules, place], [place, prohibitive], [prohibitive, .]]

>> Trigrams: 
[[cases, use, particular], [use, particular, word], [particular, word,    ], [word,    , multifaceted], [   , multifaceted, ambiguous], [multifaceted, ambiguous, number], [ambiguous, number, tuning], [number, tuning,     ], [tuning,     , rules], [    , rules, place], [rules, place, prohibitive], [place, prohibitive, .]]

>> Noun Phrases are: 
[many cases, the use, a particular word, the number,     rules, we, place]

>> Named Entities are: 
[] 

------------------- Sentence 4 -------------------

This is where       machine learning shines. 


>> Tokens are: 
[      , machine, learning, shines, .] 

>> PoS Tags are: 
[('      ', 'SPACE'), ('machine', 'NOUN'), ('learning', 'NOUN'), ('shines', 'VERB'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('      ', 'compound'), ('machine', 'compound'), ('learning', 'nsubj'), ('shines', 'advcl'), ('.', 'punct')]

>> Bigrams: 
[[      , machine], [machine, learning], [learning, shines], [shines, .]]

>> Trigrams: 
[[      , machine, learning], [machine, learning, shines], [learning, shines, .]]

>> Noun Phrases are: 
[      machine learning]

>> Named Entities are: 
[] 

------------------- Sentence 5 -------------------

Give the model enough examples,         and it figures out the rules for itself. 


>> Tokens are: 
[model, examples, ,,         , figures, rules, .] 

>> PoS Tags are: 
[('model', 'NOUN'), ('examples', 'NOUN'), (',', 'PUNCT'), ('        ', 'SPACE'), ('figures', 'VERB'), ('rules', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('model', 'dative'), ('examples', 'dobj'), (',', 'punct'), ('        ', 'conj'), ('figures', 'conj'), ('rules', 'dobj'), ('.', 'punct')]

>> Bigrams: 
[[model, examples], [examples, ,], [,,         ], [        , figures], [figures, rules], [rules, .]]

>> Trigrams: 
[[model, examples, ,], [examples, ,,         ], [,,         , figures], [        , figures, rules], [figures, rules, .]]

>> Noun Phrases are: 
[the model, enough examples, it, the rules, itself]

>> Named Entities are: 
[] 


================================ Paragraph 163 =================================

W H I T E  P A P E R 

------------------- Sentence 1 -------------------

W H 


>> Tokens are: 
[W, H] 

>> PoS Tags are: 
[('W', 'NOUN'), ('H', 'NOUN')] 

>> Dependency Tags are: 
[('W', 'compound'), ('H', 'ROOT')]

>> Bigrams: 
[[W, H]]

>> Trigrams: 
[]

>> Noun Phrases are: 
[W H]

>> Named Entities are: 
[] 

------------------- Sentence 2 -------------------

I T 


>> Tokens are: 
[T] 

>> PoS Tags are: 
[('T', 'NOUN')] 

>> Dependency Tags are: 
[('T', 'appos')]

>> Bigrams: 
[]

>> Trigrams: 
[]

>> Noun Phrases are: 
[I, T]

>> Named Entities are: 
[] 

------------------- Sentence 3 -------------------

E   


>> Tokens are: 
[E,  ] 

>> PoS Tags are: 
[('E', 'NOUN'), (' ', 'SPACE')] 

>> Dependency Tags are: 
[('E', 'ROOT'), (' ', 'appos')]

>> Bigrams: 
[[E,  ]]

>> Trigrams: 
[]

>> Noun Phrases are: 
[E]

>> Named Entities are: 
[] 

------------------- Sentence 4 -------------------

P A P E R 


>> Tokens are: 
[P, P, E, R] 

>> PoS Tags are: 
[('P', 'NOUN'), ('P', 'NOUN'), ('E', 'NOUN'), ('R', 'NOUN')] 

>> Dependency Tags are: 
[('P', 'compound'), ('P', 'compound'), ('E', 'compound'), ('R', 'ROOT')]

>> Bigrams: 
[[P, P], [P, E], [E, R]]

>> Trigrams: 
[[P, P, E], [P, E, R]]

>> Noun Phrases are: 
[P A P E R]

>> Named Entities are: 
[] 


================================ Paragraph 164 =================================

13|       |   Lexalytics, Inc., 48 North Pleasant St. Unit 301, Amherst MA 01002 USA   |   1-800-377-8036 |   www.lexalytics.com 

------------------- Sentence 1 -------------------

13|       |   Lexalytics, Inc., 48 North Pleasant St. Unit 301, Amherst MA 01002 


>> Tokens are: 
[13|,       , |,   , Lexalytics, ,, Inc., ,, 48, North, Pleasant, St., Unit, 301, ,, Amherst, MA, 01002] 

>> PoS Tags are: 
[('13|', 'NUM'), ('      ', 'SPACE'), ('|', 'NOUN'), ('  ', 'SPACE'), ('Lexalytics', 'PROPN'), (',', 'PUNCT'), ('Inc.', 'PROPN'), (',', 'PUNCT'), ('48', 'NUM'), ('North', 'PROPN'), ('Pleasant', 'PROPN'), ('St.', 'PROPN'), ('Unit', 'PROPN'), ('301', 'NUM'), (',', 'PUNCT'), ('Amherst', 'PROPN'), ('MA', 'PROPN'), ('01002', 'NUM')] 

>> Dependency Tags are: 
[('13|', 'compound'), ('      ', 'compound'), ('|', 'ROOT'), ('  ', 'prep'), ('Lexalytics', 'nmod'), (',', 'punct'), ('Inc.', 'appos'), (',', 'punct'), ('48', 'nummod'), ('North', 'compound'), ('Pleasant', 'compound'), ('St.', 'compound'), ('Unit', 'appos'), ('301', 'nummod'), (',', 'punct'), ('Amherst', 'compound'), ('MA', 'appos'), ('01002', 'punct')]

>> Bigrams: 
[[13|,       ], [      , |], [|,   ], [  , Lexalytics], [Lexalytics, ,], [,, Inc.], [Inc., ,], [,, 48], [48, North], [North, Pleasant], [Pleasant, St.], [St., Unit], [Unit, 301], [301, ,], [,, Amherst], [Amherst, MA], [MA, 01002]]

>> Trigrams: 
[[13|,       , |], [      , |,   ], [|,   , Lexalytics], [  , Lexalytics, ,], [Lexalytics, ,, Inc.], [,, Inc., ,], [Inc., ,, 48], [,, 48, North], [48, North, Pleasant], [North, Pleasant, St.], [Pleasant, St., Unit], [St., Unit, 301], [Unit, 301, ,], [301, ,, Amherst], [,, Amherst, MA], [Amherst, MA, 01002]]

>> Noun Phrases are: 
[13|       |, Lexalytics, Inc., 48 North Pleasant St. Unit, Amherst MA]

>> Named Entities are: 
[('Lexalytics, Inc.', 'ORG'), ('48', 'CARDINAL'), ('North Pleasant St. Unit 301', 'ORG'), ('Amherst MA', 'ORG')] 

------------------- Sentence 2 -------------------

USA 


>> Tokens are: 
[USA] 

>> PoS Tags are: 
[('USA', 'PROPN')] 

>> Dependency Tags are: 
[('USA', 'ROOT')]

>> Bigrams: 
[]

>> Trigrams: 
[]

>> Noun Phrases are: 
[USA]

>> Named Entities are: 
[] 

------------------- Sentence 3 -------------------

  |   1-800-377-8036 |   www.lexalytics.com 


>> Tokens are: 
[  , |,   , 1, -, 800, -, 377, -, 8036, |,   , www.lexalytics.com] 

>> PoS Tags are: 
[('  ', 'SPACE'), ('|', 'NOUN'), ('  ', 'SPACE'), ('1', 'NUM'), ('-', 'SYM'), ('800', 'NUM'), ('-', 'NUM'), ('377', 'NUM'), ('-', 'PUNCT'), ('8036', 'NUM'), ('|', 'NOUN'), ('  ', 'SPACE'), ('www.lexalytics.com', 'X')] 

>> Dependency Tags are: 
[('  ', 'compound'), ('|', 'npadvmod'), ('  ', 'dep'), ('1', 'npadvmod'), ('-', 'punct'), ('800', 'prep'), ('-', 'punct'), ('377', 'nummod'), ('-', 'punct'), ('8036', 'nummod'), ('|', 'npadvmod'), ('  ', 'ROOT'), ('www.lexalytics.com', 'punct')]

>> Bigrams: 
[[  , |], [|,   ], [  , 1], [1, -], [-, 800], [800, -], [-, 377], [377, -], [-, 8036], [8036, |], [|,   ], [  , www.lexalytics.com]]

>> Trigrams: 
[[  , |,   ], [|,   , 1], [  , 1, -], [1, -, 800], [-, 800, -], [800, -, 377], [-, 377, -], [377, -, 8036], [-, 8036, |], [8036, |,   ], [|,   , www.lexalytics.com]]

>> Noun Phrases are: 
[]

>> Named Entities are: 
[] 


================================ Paragraph 165 =================================

There are more potential side-effects of training that you must be aware of.  

------------------- Sentence 1 -------------------

There are more potential side-effects of training that you must be aware of.   


>> Tokens are: 
[potential, -, effects, training, aware, .,  ] 

>> PoS Tags are: 
[('potential', 'ADJ'), ('-', 'PUNCT'), ('effects', 'NOUN'), ('training', 'NOUN'), ('aware', 'ADJ'), ('.', 'PUNCT'), (' ', 'SPACE')] 

>> Dependency Tags are: 
[('potential', 'amod'), ('-', 'punct'), ('effects', 'attr'), ('training', 'pobj'), ('aware', 'acomp'), ('.', 'punct'), (' ', 'attr')]

>> Bigrams: 
[[potential, -], [-, effects], [effects, training], [training, aware], [aware, .], [.,  ]]

>> Trigrams: 
[[potential, -, effects], [-, effects, training], [effects, training, aware], [training, aware, .], [aware, .,  ]]

>> Noun Phrases are: 
[more potential side-effects, training, you]

>> Named Entities are: 
[] 


================================ Paragraph 166 =================================

Say we’re scoring a bunch of documents to try to effect change on a  particular phrase. Each of those documents contains more than that one  phrase, and the other phrases in each document will also be affected by our  scoring and re-tuning. This is particularly true of common phrases, which  appear often enough that they end up influencing the model.  

------------------- Sentence 1 -------------------

Say we’re scoring a bunch of documents to try to effect change on a  particular phrase. 


>> Tokens are: 
[scoring, bunch, documents, try, effect, change,  , particular, phrase, .] 

>> PoS Tags are: 
[('scoring', 'VERB'), ('bunch', 'NOUN'), ('documents', 'NOUN'), ('try', 'VERB'), ('effect', 'VERB'), ('change', 'NOUN'), (' ', 'SPACE'), ('particular', 'ADJ'), ('phrase', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('scoring', 'ccomp'), ('bunch', 'dobj'), ('documents', 'pobj'), ('try', 'relcl'), ('effect', 'xcomp'), ('change', 'dobj'), (' ', 'nmod'), ('particular', 'amod'), ('phrase', 'pobj'), ('.', 'punct')]

>> Bigrams: 
[[scoring, bunch], [bunch, documents], [documents, try], [try, effect], [effect, change], [change,  ], [ , particular], [particular, phrase], [phrase, .]]

>> Trigrams: 
[[scoring, bunch, documents], [bunch, documents, try], [documents, try, effect], [try, effect, change], [effect, change,  ], [change,  , particular], [ , particular, phrase], [particular, phrase, .]]

>> Noun Phrases are: 
[we, a bunch, documents, change, a  particular phrase]

>> Named Entities are: 
[] 

------------------- Sentence 2 -------------------

Each of those documents contains more than that one  phrase, and the other phrases in each document will also be affected by our  scoring and re-tuning. 


>> Tokens are: 
[documents, contains,  , phrase, ,, phrases, document, affected,  , scoring, -, tuning, .] 

>> PoS Tags are: 
[('documents', 'NOUN'), ('contains', 'VERB'), (' ', 'SPACE'), ('phrase', 'NOUN'), (',', 'PUNCT'), ('phrases', 'NOUN'), ('document', 'NOUN'), ('affected', 'VERB'), (' ', 'SPACE'), ('scoring', 'NOUN'), ('-', 'NOUN'), ('tuning', 'VERB'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('documents', 'pobj'), ('contains', 'ROOT'), (' ', 'compound'), ('phrase', 'pobj'), (',', 'punct'), ('phrases', 'nsubjpass'), ('document', 'pobj'), ('affected', 'conj'), (' ', 'compound'), ('scoring', 'pobj'), ('-', 'conj'), ('tuning', 'pobj'), ('.', 'punct')]

>> Bigrams: 
[[documents, contains], [contains,  ], [ , phrase], [phrase, ,], [,, phrases], [phrases, document], [document, affected], [affected,  ], [ , scoring], [scoring, -], [-, tuning], [tuning, .]]

>> Trigrams: 
[[documents, contains,  ], [contains,  , phrase], [ , phrase, ,], [phrase, ,, phrases], [,, phrases, document], [phrases, document, affected], [document, affected,  ], [affected,  , scoring], [ , scoring, -], [scoring, -, tuning], [-, tuning, .]]

>> Noun Phrases are: 
[those documents, that one  phrase, the other phrases, each document, our  scoring, re, -]

>> Named Entities are: 
[] 

------------------- Sentence 3 -------------------

This is particularly true of common phrases, which  appear often enough that they end up influencing the model. 


>> Tokens are: 
[particularly, true, common, phrases, ,,  , appear, end, influencing, model, .] 

>> PoS Tags are: 
[('particularly', 'ADV'), ('true', 'ADJ'), ('common', 'ADJ'), ('phrases', 'NOUN'), (',', 'PUNCT'), (' ', 'SPACE'), ('appear', 'VERB'), ('end', 'VERB'), ('influencing', 'VERB'), ('model', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('particularly', 'advmod'), ('true', 'acomp'), ('common', 'amod'), ('phrases', 'pobj'), (',', 'punct'), (' ', 'nsubj'), ('appear', 'relcl'), ('end', 'ccomp'), ('influencing', 'xcomp'), ('model', 'dobj'), ('.', 'punct')]

>> Bigrams: 
[[particularly, true], [true, common], [common, phrases], [phrases, ,], [,,  ], [ , appear], [appear, end], [end, influencing], [influencing, model], [model, .]]

>> Trigrams: 
[[particularly, true, common], [true, common, phrases], [common, phrases, ,], [phrases, ,,  ], [,,  , appear], [ , appear, end], [appear, end, influencing], [end, influencing, model], [influencing, model, .]]

>> Noun Phrases are: 
[common phrases, they, the model]

>> Named Entities are: 
[] 

------------------- Sentence 4 -------------------

  


>> Tokens are: 
[ ] 

>> PoS Tags are: 
[(' ', 'SPACE')] 

>> Dependency Tags are: 
[(' ', 'ROOT')]

>> Bigrams: 
[]

>> Trigrams: 
[]

>> Noun Phrases are: 
[]

>> Named Entities are: 
[] 


================================ Paragraph 167 =================================

Imagine that you’re scoring news stories from 2008. 2008 was truly awful for  business and economics as a whole. If you are focused on scoring financial  results from businesses, you’ll be marking a lot of content as negative.  Then, machine learning algorithms will weigh the phrases in the content in  proportion to their occurrence.  

------------------- Sentence 1 -------------------

Imagine that you’re scoring news stories from 2008. 


>> Tokens are: 
[Imagine, scoring, news, stories, 2008, .] 

>> PoS Tags are: 
[('Imagine', 'VERB'), ('scoring', 'VERB'), ('news', 'NOUN'), ('stories', 'NOUN'), ('2008', 'NUM'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('Imagine', 'ROOT'), ('scoring', 'ccomp'), ('news', 'compound'), ('stories', 'dobj'), ('2008', 'pobj'), ('.', 'punct')]

>> Bigrams: 
[[Imagine, scoring], [scoring, news], [news, stories], [stories, 2008], [2008, .]]

>> Trigrams: 
[[Imagine, scoring, news], [scoring, news, stories], [news, stories, 2008], [stories, 2008, .]]

>> Noun Phrases are: 
[you, news stories]

>> Named Entities are: 
[('2008', 'DATE')] 

------------------- Sentence 2 -------------------

2008 was truly awful for  business and economics as a whole. 


>> Tokens are: 
[2008, truly, awful,  , business, economics, .] 

>> PoS Tags are: 
[('2008', 'NUM'), ('truly', 'ADV'), ('awful', 'ADJ'), (' ', 'SPACE'), ('business', 'NOUN'), ('economics', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('2008', 'nsubj'), ('truly', 'advmod'), ('awful', 'acomp'), (' ', 'pobj'), ('business', 'pobj'), ('economics', 'conj'), ('.', 'punct')]

>> Bigrams: 
[[2008, truly], [truly, awful], [awful,  ], [ , business], [business, economics], [economics, .]]

>> Trigrams: 
[[2008, truly, awful], [truly, awful,  ], [awful,  , business], [ , business, economics], [business, economics, .]]

>> Noun Phrases are: 
[business, economics, a whole]

>> Named Entities are: 
[] 

------------------- Sentence 3 -------------------

If you are focused on scoring financial  results from businesses, you’ll be marking a lot of content as negative. 


>> Tokens are: 
[focused, scoring, financial,  , results, businesses, ,, marking, lot, content, negative, .] 

>> PoS Tags are: 
[('focused', 'ADJ'), ('scoring', 'VERB'), ('financial', 'ADJ'), (' ', 'SPACE'), ('results', 'NOUN'), ('businesses', 'NOUN'), (',', 'PUNCT'), ('marking', 'VERB'), ('lot', 'NOUN'), ('content', 'NOUN'), ('negative', 'ADJ'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('focused', 'acomp'), ('scoring', 'pcomp'), ('financial', 'amod'), (' ', 'compound'), ('results', 'dobj'), ('businesses', 'pobj'), (',', 'punct'), ('marking', 'ROOT'), ('lot', 'dobj'), ('content', 'pobj'), ('negative', 'amod'), ('.', 'punct')]

>> Bigrams: 
[[focused, scoring], [scoring, financial], [financial,  ], [ , results], [results, businesses], [businesses, ,], [,, marking], [marking, lot], [lot, content], [content, negative], [negative, .]]

>> Trigrams: 
[[focused, scoring, financial], [scoring, financial,  ], [financial,  , results], [ , results, businesses], [results, businesses, ,], [businesses, ,, marking], [,, marking, lot], [marking, lot, content], [lot, content, negative], [content, negative, .]]

>> Noun Phrases are: 
[you, financial  results, businesses, you, a lot, content]

>> Named Entities are: 
[] 

------------------- Sentence 4 -------------------

  


>> Tokens are: 
[ ] 

>> PoS Tags are: 
[(' ', 'SPACE')] 

>> Dependency Tags are: 
[(' ', 'ROOT')]

>> Bigrams: 
[]

>> Trigrams: 
[]

>> Noun Phrases are: 
[]

>> Named Entities are: 
[] 

------------------- Sentence 5 -------------------

Then, machine learning algorithms will weigh the phrases in the content in  proportion to their occurrence. 


>> Tokens are: 
[,, machine, learning, algorithms, weigh, phrases, content,  , proportion, occurrence, .] 

>> PoS Tags are: 
[(',', 'PUNCT'), ('machine', 'NOUN'), ('learning', 'VERB'), ('algorithms', 'NOUN'), ('weigh', 'VERB'), ('phrases', 'NOUN'), ('content', 'NOUN'), (' ', 'SPACE'), ('proportion', 'NOUN'), ('occurrence', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[(',', 'punct'), ('machine', 'compound'), ('learning', 'amod'), ('algorithms', 'nsubj'), ('weigh', 'ROOT'), ('phrases', 'dobj'), ('content', 'pobj'), (' ', 'pobj'), ('proportion', 'dobj'), ('occurrence', 'pobj'), ('.', 'punct')]

>> Bigrams: 
[[,, machine], [machine, learning], [learning, algorithms], [algorithms, weigh], [weigh, phrases], [phrases, content], [content,  ], [ , proportion], [proportion, occurrence], [occurrence, .]]

>> Trigrams: 
[[,, machine, learning], [machine, learning, algorithms], [learning, algorithms, weigh], [algorithms, weigh, phrases], [weigh, phrases, content], [phrases, content,  ], [content,  , proportion], [ , proportion, occurrence], [proportion, occurrence, .]]

>> Noun Phrases are: 
[machine learning algorithms, the phrases, the content, proportion, their occurrence]

>> Named Entities are: 
[] 

------------------- Sentence 6 -------------------

  


>> Tokens are: 
[ ] 

>> PoS Tags are: 
[(' ', 'SPACE')] 

>> Dependency Tags are: 
[(' ', 'ROOT')]

>> Bigrams: 
[]

>> Trigrams: 
[]

>> Noun Phrases are: 
[]

>> Named Entities are: 
[] 


================================ Paragraph 168 =================================

Unfortunately, that leaves some collateral damage: “first quarter,” “second  quarter,” “third quarter,” and “fourth quarter.” These are neutral terms, but  they occurred in frequent conjunction with negative financial news. So, the  machine learning algorithm will weight those phrases as being negative.   That will end up negatively impacting your results for years to come. 

------------------- Sentence 1 -------------------

Unfortunately, that leaves some collateral damage: “first quarter,” “second  quarter,” “third quarter,” and “fourth quarter.” 


>> Tokens are: 
[Unfortunately, ,, leaves, collateral, damage, :, “, quarter, ,, ”, “, second,  , quarter, ,, ”, “, quarter, ,, ”, “, fourth, quarter, ., ”] 

>> PoS Tags are: 
[('Unfortunately', 'ADV'), (',', 'PUNCT'), ('leaves', 'VERB'), ('collateral', 'ADJ'), ('damage', 'NOUN'), (':', 'PUNCT'), ('“', 'PUNCT'), ('quarter', 'NOUN'), (',', 'PUNCT'), ('”', 'PUNCT'), ('“', 'PUNCT'), ('second', 'ADJ'), (' ', 'SPACE'), ('quarter', 'NOUN'), (',', 'PUNCT'), ('”', 'PUNCT'), ('“', 'PUNCT'), ('quarter', 'NOUN'), (',', 'PUNCT'), ('”', 'PUNCT'), ('“', 'PUNCT'), ('fourth', 'ADJ'), ('quarter', 'NOUN'), ('.', 'PUNCT'), ('”', 'PUNCT')] 

>> Dependency Tags are: 
[('Unfortunately', 'advmod'), (',', 'punct'), ('leaves', 'ROOT'), ('collateral', 'amod'), ('damage', 'dobj'), (':', 'punct'), ('“', 'punct'), ('quarter', 'npadvmod'), (',', 'punct'), ('”', 'punct'), ('“', 'punct'), ('second', 'amod'), (' ', 'compound'), ('quarter', 'npadvmod'), (',', 'punct'), ('”', 'punct'), ('“', 'punct'), ('quarter', 'dobj'), (',', 'punct'), ('”', 'punct'), ('“', 'punct'), ('fourth', 'amod'), ('quarter', 'conj'), ('.', 'punct'), ('”', 'punct')]

>> Bigrams: 
[[Unfortunately, ,], [,, leaves], [leaves, collateral], [collateral, damage], [damage, :], [:, “], [“, quarter], [quarter, ,], [,, ”], [”, “], [“, second], [second,  ], [ , quarter], [quarter, ,], [,, ”], [”, “], [“, quarter], [quarter, ,], [,, ”], [”, “], [“, fourth], [fourth, quarter], [quarter, .], [., ”]]

>> Trigrams: 
[[Unfortunately, ,, leaves], [,, leaves, collateral], [leaves, collateral, damage], [collateral, damage, :], [damage, :, “], [:, “, quarter], [“, quarter, ,], [quarter, ,, ”], [,, ”, “], [”, “, second], [“, second,  ], [second,  , quarter], [ , quarter, ,], [quarter, ,, ”], [,, ”, “], [”, “, quarter], [“, quarter, ,], [quarter, ,, ”], [,, ”, “], [”, “, fourth], [“, fourth, quarter], [fourth, quarter, .], [quarter, ., ”]]

>> Noun Phrases are: 
[some collateral damage, ” “third quarter, “fourth quarter]

>> Named Entities are: 
[('second', 'ORDINAL'), ('third', 'ORDINAL'), ('fourth', 'ORDINAL')] 

------------------- Sentence 2 -------------------

These are neutral terms, but  they occurred in frequent conjunction with negative financial news. 


>> Tokens are: 
[neutral, terms, ,,  , occurred, frequent, conjunction, negative, financial, news, .] 

>> PoS Tags are: 
[('neutral', 'ADJ'), ('terms', 'NOUN'), (',', 'PUNCT'), (' ', 'SPACE'), ('occurred', 'VERB'), ('frequent', 'ADJ'), ('conjunction', 'NOUN'), ('negative', 'ADJ'), ('financial', 'ADJ'), ('news', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('neutral', 'amod'), ('terms', 'attr'), (',', 'punct'), (' ', 'conj'), ('occurred', 'relcl'), ('frequent', 'amod'), ('conjunction', 'pobj'), ('negative', 'amod'), ('financial', 'amod'), ('news', 'pobj'), ('.', 'punct')]

>> Bigrams: 
[[neutral, terms], [terms, ,], [,,  ], [ , occurred], [occurred, frequent], [frequent, conjunction], [conjunction, negative], [negative, financial], [financial, news], [news, .]]

>> Trigrams: 
[[neutral, terms, ,], [terms, ,,  ], [,,  , occurred], [ , occurred, frequent], [occurred, frequent, conjunction], [frequent, conjunction, negative], [conjunction, negative, financial], [negative, financial, news], [financial, news, .]]

>> Noun Phrases are: 
[neutral terms, they, frequent conjunction, negative financial news]

>> Named Entities are: 
[] 

------------------- Sentence 3 -------------------

So, the  machine learning algorithm will weight those phrases as being negative. 


>> Tokens are: 
[,,  , machine, learning, algorithm, weight, phrases, negative, .] 

>> PoS Tags are: 
[(',', 'PUNCT'), (' ', 'SPACE'), ('machine', 'NOUN'), ('learning', 'NOUN'), ('algorithm', 'NOUN'), ('weight', 'VERB'), ('phrases', 'NOUN'), ('negative', 'ADJ'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[(',', 'punct'), (' ', 'compound'), ('machine', 'compound'), ('learning', 'amod'), ('algorithm', 'nsubj'), ('weight', 'ROOT'), ('phrases', 'dobj'), ('negative', 'acomp'), ('.', 'punct')]

>> Bigrams: 
[[,,  ], [ , machine], [machine, learning], [learning, algorithm], [algorithm, weight], [weight, phrases], [phrases, negative], [negative, .]]

>> Trigrams: 
[[,,  , machine], [ , machine, learning], [machine, learning, algorithm], [learning, algorithm, weight], [algorithm, weight, phrases], [weight, phrases, negative], [phrases, negative, .]]

>> Noun Phrases are: 
[the  machine learning algorithm, those phrases]

>> Named Entities are: 
[] 

------------------- Sentence 4 -------------------

  That will end up negatively impacting your results for years to come. 


>> Tokens are: 
[  , end, negatively, impacting, results, years, come, .] 

>> PoS Tags are: 
[('  ', 'SPACE'), ('end', 'VERB'), ('negatively', 'ADV'), ('impacting', 'VERB'), ('results', 'NOUN'), ('years', 'NOUN'), ('come', 'VERB'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('  ', 'ROOT'), ('end', 'relcl'), ('negatively', 'advmod'), ('impacting', 'xcomp'), ('results', 'dobj'), ('years', 'pobj'), ('come', 'relcl'), ('.', 'punct')]

>> Bigrams: 
[[  , end], [end, negatively], [negatively, impacting], [impacting, results], [results, years], [years, come], [come, .]]

>> Trigrams: 
[[  , end, negatively], [end, negatively, impacting], [negatively, impacting, results], [impacting, results, years], [results, years, come], [years, come, .]]

>> Noun Phrases are: 
[your results, years]

>> Named Entities are: 
[('years', 'DATE')] 


================================ Paragraph 169 =================================

Lexalytics has put a number of checks and balances into our text analytics  system to handle situations like this. Sometimes you just need to be able   to reach in and tell the software that “first quarter” is really just neutral,   despite what it might think. 

------------------- Sentence 1 -------------------

Lexalytics has put a number of checks and balances into our text analytics  system to handle situations like this. 


>> Tokens are: 
[Lexalytics, number, checks, balances, text, analytics,  , system, handle, situations, like, .] 

>> PoS Tags are: 
[('Lexalytics', 'PROPN'), ('number', 'NOUN'), ('checks', 'NOUN'), ('balances', 'NOUN'), ('text', 'NOUN'), ('analytics', 'NOUN'), (' ', 'SPACE'), ('system', 'NOUN'), ('handle', 'VERB'), ('situations', 'NOUN'), ('like', 'ADP'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('Lexalytics', 'nsubj'), ('number', 'dobj'), ('checks', 'pobj'), ('balances', 'conj'), ('text', 'compound'), ('analytics', 'pobj'), (' ', 'compound'), ('system', 'dobj'), ('handle', 'advcl'), ('situations', 'dobj'), ('like', 'prep'), ('.', 'punct')]

>> Bigrams: 
[[Lexalytics, number], [number, checks], [checks, balances], [balances, text], [text, analytics], [analytics,  ], [ , system], [system, handle], [handle, situations], [situations, like], [like, .]]

>> Trigrams: 
[[Lexalytics, number, checks], [number, checks, balances], [checks, balances, text], [balances, text, analytics], [text, analytics,  ], [analytics,  , system], [ , system, handle], [system, handle, situations], [handle, situations, like], [situations, like, .]]

>> Noun Phrases are: 
[Lexalytics, a number, checks, balances, our text analytics,  system, situations]

>> Named Entities are: 
[] 

------------------- Sentence 2 -------------------

Sometimes you just need to be able   to reach in and tell the software that “first quarter” is really just neutral,   despite what it might think. 


>> Tokens are: 
[need, able,   , reach, tell, software, “, quarter, ”, neutral, ,,   , despite, think, .] 

>> PoS Tags are: 
[('need', 'VERB'), ('able', 'ADJ'), ('  ', 'SPACE'), ('reach', 'VERB'), ('tell', 'VERB'), ('software', 'NOUN'), ('“', 'PUNCT'), ('quarter', 'NOUN'), ('”', 'PUNCT'), ('neutral', 'ADJ'), (',', 'PUNCT'), ('  ', 'SPACE'), ('despite', 'SCONJ'), ('think', 'VERB'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('need', 'ROOT'), ('able', 'acomp'), ('  ', 'nsubj'), ('reach', 'xcomp'), ('tell', 'conj'), ('software', 'dobj'), ('“', 'punct'), ('quarter', 'nsubj'), ('”', 'punct'), ('neutral', 'acomp'), (',', 'punct'), ('  ', 'npadvmod'), ('despite', 'prep'), ('think', 'pcomp'), ('.', 'punct')]

>> Bigrams: 
[[need, able], [able,   ], [  , reach], [reach, tell], [tell, software], [software, “], [“, quarter], [quarter, ”], [”, neutral], [neutral, ,], [,,   ], [  , despite], [despite, think], [think, .]]

>> Trigrams: 
[[need, able,   ], [able,   , reach], [  , reach, tell], [reach, tell, software], [tell, software, “], [software, “, quarter], [“, quarter, ”], [quarter, ”, neutral], [”, neutral, ,], [neutral, ,,   ], [,,   , despite], [  , despite, think], [despite, think, .]]

>> Noun Phrases are: 
[you, the software, “first quarter, what, it]

>> Named Entities are: 
[] 


================================ Paragraph 170 =================================

CHART SOURCE: ThomsonOne; Bullion Management Group Inc.,   http://bmg-group.com/2008-financial-crisis/ 

------------------- Sentence 1 -------------------

CHART SOURCE: ThomsonOne; Bullion Management Group Inc.,    


>> Tokens are: 
[CHART, SOURCE, :, ThomsonOne, ;, Bullion, Management, Group, Inc., ,,   ] 

>> PoS Tags are: 
[('CHART', 'PROPN'), ('SOURCE', 'NOUN'), (':', 'PUNCT'), ('ThomsonOne', 'PROPN'), (';', 'PUNCT'), ('Bullion', 'PROPN'), ('Management', 'PROPN'), ('Group', 'PROPN'), ('Inc.', 'PROPN'), (',', 'PUNCT'), ('  ', 'SPACE')] 

>> Dependency Tags are: 
[('CHART', 'compound'), ('SOURCE', 'ROOT'), (':', 'punct'), ('ThomsonOne', 'appos'), (';', 'punct'), ('Bullion', 'compound'), ('Management', 'compound'), ('Group', 'compound'), ('Inc.', 'conj'), (',', 'punct'), ('  ', 'appos')]

>> Bigrams: 
[[CHART, SOURCE], [SOURCE, :], [:, ThomsonOne], [ThomsonOne, ;], [;, Bullion], [Bullion, Management], [Management, Group], [Group, Inc.], [Inc., ,], [,,   ]]

>> Trigrams: 
[[CHART, SOURCE, :], [SOURCE, :, ThomsonOne], [:, ThomsonOne, ;], [ThomsonOne, ;, Bullion], [;, Bullion, Management], [Bullion, Management, Group], [Management, Group, Inc.], [Group, Inc., ,], [Inc., ,,   ]]

>> Noun Phrases are: 
[CHART SOURCE, ThomsonOne, Bullion Management Group Inc.]

>> Named Entities are: 
[('CHART', 'ORG'), ('ThomsonOne', 'ORG'), ('Bullion Management Group Inc.', 'ORG')] 

------------------- Sentence 2 -------------------

http://bmg-group.com/2008-financial-crisis/ 


>> Tokens are: 
[http://bmg-group.com/2008-financial-crisis/] 

>> PoS Tags are: 
[('http://bmg-group.com/2008-financial-crisis/', 'PROPN')] 

>> Dependency Tags are: 
[('http://bmg-group.com/2008-financial-crisis/', 'ROOT')]

>> Bigrams: 
[]

>> Trigrams: 
[]

>> Noun Phrases are: 
[http://bmg-group.com/2008-financial-crisis/]

>> Named Entities are: 
[] 


================================ Paragraph 171 =================================

can have many   

------------------- Sentence 1 -------------------

can have many    


>> Tokens are: 
[  ] 

>> PoS Tags are: 
[('  ', 'SPACE')] 

>> Dependency Tags are: 
[('  ', 'dobj')]

>> Bigrams: 
[]

>> Trigrams: 
[]

>> Noun Phrases are: 
[]

>> Named Entities are: 
[] 


================================ Paragraph 172 =================================

unforeseen side-effects. 

------------------- Sentence 1 -------------------

unforeseen side-effects. 


>> Tokens are: 
[unforeseen, -, effects, .] 

>> PoS Tags are: 
[('unforeseen', 'ADJ'), ('-', 'PUNCT'), ('effects', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('unforeseen', 'amod'), ('-', 'punct'), ('effects', 'ROOT'), ('.', 'punct')]

>> Bigrams: 
[[unforeseen, -], [-, effects], [effects, .]]

>> Trigrams: 
[[unforeseen, -, effects], [-, effects, .]]

>> Noun Phrases are: 
[unforeseen side-effects]

>> Named Entities are: 
[] 


================================ Paragraph 173 =================================

Training  a model

------------------- Sentence 1 -------------------

Training  a model 


>> Tokens are: 
[Training,  , model] 

>> PoS Tags are: 
[('Training', 'VERB'), (' ', 'SPACE'), ('model', 'NOUN')] 

>> Dependency Tags are: 
[('Training', 'ROOT'), (' ', 'dobj'), ('model', 'npadvmod')]

>> Bigrams: 
[[Training,  ], [ , model]]

>> Trigrams: 
[[Training,  , model]]

>> Noun Phrases are: 
[]

>> Named Entities are: 
[] 


================================ Paragraph 174 =================================

W H I T E  P A P E R 

------------------- Sentence 1 -------------------

W H 


>> Tokens are: 
[W, H] 

>> PoS Tags are: 
[('W', 'NOUN'), ('H', 'NOUN')] 

>> Dependency Tags are: 
[('W', 'compound'), ('H', 'ROOT')]

>> Bigrams: 
[[W, H]]

>> Trigrams: 
[]

>> Noun Phrases are: 
[W H]

>> Named Entities are: 
[] 

------------------- Sentence 2 -------------------

I T 


>> Tokens are: 
[T] 

>> PoS Tags are: 
[('T', 'NOUN')] 

>> Dependency Tags are: 
[('T', 'appos')]

>> Bigrams: 
[]

>> Trigrams: 
[]

>> Noun Phrases are: 
[I, T]

>> Named Entities are: 
[] 

------------------- Sentence 3 -------------------

E   


>> Tokens are: 
[E,  ] 

>> PoS Tags are: 
[('E', 'NOUN'), (' ', 'SPACE')] 

>> Dependency Tags are: 
[('E', 'ROOT'), (' ', 'appos')]

>> Bigrams: 
[[E,  ]]

>> Trigrams: 
[]

>> Noun Phrases are: 
[E]

>> Named Entities are: 
[] 

------------------- Sentence 4 -------------------

P A P E R 


>> Tokens are: 
[P, P, E, R] 

>> PoS Tags are: 
[('P', 'NOUN'), ('P', 'NOUN'), ('E', 'NOUN'), ('R', 'NOUN')] 

>> Dependency Tags are: 
[('P', 'compound'), ('P', 'compound'), ('E', 'compound'), ('R', 'ROOT')]

>> Bigrams: 
[[P, P], [P, E], [E, R]]

>> Trigrams: 
[[P, P, E], [P, E, R]]

>> Noun Phrases are: 
[P A P E R]

>> Named Entities are: 
[] 


================================ Paragraph 175 =================================

14|       |   Lexalytics, Inc., 48 North Pleasant St. Unit 301, Amherst MA 01002 USA   |   1-800-377-8036 |   www.lexalytics.com 

------------------- Sentence 1 -------------------

14|       |   Lexalytics, Inc., 48 North Pleasant St. Unit 301, Amherst MA 01002 USA   |   1-800-377-8036 |   www.lexalytics.com 


>> Tokens are: 
[14|,       , |,   , Lexalytics, ,, Inc., ,, 48, North, Pleasant, St., Unit, 301, ,, Amherst, MA, 01002, USA,   , |,   , 1, -, 800, -, 377, -, 8036, |,   , www.lexalytics.com] 

>> PoS Tags are: 
[('14|', 'NUM'), ('      ', 'SPACE'), ('|', 'NOUN'), ('  ', 'SPACE'), ('Lexalytics', 'PROPN'), (',', 'PUNCT'), ('Inc.', 'PROPN'), (',', 'PUNCT'), ('48', 'NUM'), ('North', 'PROPN'), ('Pleasant', 'PROPN'), ('St.', 'PROPN'), ('Unit', 'PROPN'), ('301', 'NUM'), (',', 'PUNCT'), ('Amherst', 'PROPN'), ('MA', 'PROPN'), ('01002', 'NUM'), ('USA', 'PROPN'), ('  ', 'SPACE'), ('|', 'NOUN'), ('  ', 'SPACE'), ('1', 'NUM'), ('-', 'SYM'), ('800', 'NUM'), ('-', 'NUM'), ('377', 'NUM'), ('-', 'PUNCT'), ('8036', 'NUM'), ('|', 'NOUN'), ('  ', 'SPACE'), ('www.lexalytics.com', 'X')] 

>> Dependency Tags are: 
[('14|', 'nummod'), ('      ', 'compound'), ('|', 'nsubj'), ('  ', 'nmod'), ('Lexalytics', 'nmod'), (',', 'punct'), ('Inc.', 'appos'), (',', 'punct'), ('48', 'nummod'), ('North', 'compound'), ('Pleasant', 'compound'), ('St.', 'compound'), ('Unit', 'appos'), ('301', 'nummod'), (',', 'punct'), ('Amherst', 'compound'), ('MA', 'appos'), ('01002', 'punct'), ('USA', 'compound'), ('  ', 'compound'), ('|', 'appos'), ('  ', 'appos'), ('1', 'npadvmod'), ('-', 'punct'), ('800', 'prep'), ('-', 'punct'), ('377', 'nummod'), ('-', 'punct'), ('8036', 'nummod'), ('|', 'appos'), ('  ', 'ROOT'), ('www.lexalytics.com', 'punct')]

>> Bigrams: 
[[14|,       ], [      , |], [|,   ], [  , Lexalytics], [Lexalytics, ,], [,, Inc.], [Inc., ,], [,, 48], [48, North], [North, Pleasant], [Pleasant, St.], [St., Unit], [Unit, 301], [301, ,], [,, Amherst], [Amherst, MA], [MA, 01002], [01002, USA], [USA,   ], [  , |], [|,   ], [  , 1], [1, -], [-, 800], [800, -], [-, 377], [377, -], [-, 8036], [8036, |], [|,   ], [  , www.lexalytics.com]]

>> Trigrams: 
[[14|,       , |], [      , |,   ], [|,   , Lexalytics], [  , Lexalytics, ,], [Lexalytics, ,, Inc.], [,, Inc., ,], [Inc., ,, 48], [,, 48, North], [48, North, Pleasant], [North, Pleasant, St.], [Pleasant, St., Unit], [St., Unit, 301], [Unit, 301, ,], [301, ,, Amherst], [,, Amherst, MA], [Amherst, MA, 01002], [MA, 01002, USA], [01002, USA,   ], [USA,   , |], [  , |,   ], [|,   , 1], [  , 1, -], [1, -, 800], [-, 800, -], [800, -, 377], [-, 377, -], [377, -, 8036], [-, 8036, |], [8036, |,   ], [|,   , www.lexalytics.com]]

>> Noun Phrases are: 
[14|       |,   Lexalytics, Inc., 48 North Pleasant St. Unit, Amherst MA, USA   |, 377-8036 |]

>> Named Entities are: 
[('14|', 'DATE'), ('Lexalytics, Inc.', 'ORG'), ('48', 'CARDINAL'), ('North Pleasant St. Unit 301', 'ORG'), ('Amherst MA', 'ORG')] 


================================ Paragraph 176 =================================

S U M M A R Y  /  C O N C L U S I O N  Text analytics is arguably one of the most complex tasks for an AI.   Language is messy and complex. Meaning varies from speaker to speaker  and listener to listener. Machine learning provides a rich solution set for  handling this complexity, but must be implemented in a way that’s relevant  to the problem – and hand-in-hand with natural language processing code. 

------------------- Sentence 1 -------------------

S U M M A R Y  /   


>> Tokens are: 
[S, U, M, M, R, Y,  , /,  ] 

>> PoS Tags are: 
[('S', 'NOUN'), ('U', 'NOUN'), ('M', 'PROPN'), ('M', 'NOUN'), ('R', 'NOUN'), ('Y', 'PROPN'), (' ', 'SPACE'), ('/', 'SYM'), (' ', 'SPACE')] 

>> Dependency Tags are: 
[('S', 'compound'), ('U', 'compound'), ('M', 'compound'), ('M', 'compound'), ('R', 'compound'), ('Y', 'dative'), (' ', 'appos'), ('/', 'punct'), (' ', 'appos')]

>> Bigrams: 
[[S, U], [U, M], [M, M], [M, R], [R, Y], [Y,  ], [ , /], [/,  ]]

>> Trigrams: 
[[S, U, M], [U, M, M], [M, M, R], [M, R, Y], [R, Y,  ], [Y,  , /], [ , /,  ]]

>> Noun Phrases are: 
[S U M M A, R Y]

>> Named Entities are: 
[] 

------------------- Sentence 2 -------------------

C O N C L U S 


>> Tokens are: 
[C, O, N, C, L, U, S] 

>> PoS Tags are: 
[('C', 'NOUN'), ('O', 'PROPN'), ('N', 'PROPN'), ('C', 'PROPN'), ('L', 'NOUN'), ('U', 'NOUN'), ('S', 'NOUN')] 

>> Dependency Tags are: 
[('C', 'compound'), ('O', 'nmod'), ('N', 'appos'), ('C', 'compound'), ('L', 'compound'), ('U', 'compound'), ('S', 'ROOT')]

>> Bigrams: 
[[C, O], [O, N], [N, C], [C, L], [L, U], [U, S]]

>> Trigrams: 
[[C, O, N], [O, N, C], [N, C, L], [C, L, U], [L, U, S]]

>> Noun Phrases are: 
[N]

>> Named Entities are: 
[] 

------------------- Sentence 3 -------------------

I O N  Text analytics is arguably one of the most complex tasks for an AI. 


>> Tokens are: 
[O, N,  , Text, analytics, arguably, complex, tasks, AI, .] 

>> PoS Tags are: 
[('O', 'INTJ'), ('N', 'NOUN'), (' ', 'SPACE'), ('Text', 'PROPN'), ('analytics', 'NOUN'), ('arguably', 'ADV'), ('complex', 'ADJ'), ('tasks', 'NOUN'), ('AI', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('O', 'appos'), ('N', 'nmod'), (' ', 'compound'), ('Text', 'compound'), ('analytics', 'nsubj'), ('arguably', 'advmod'), ('complex', 'amod'), ('tasks', 'pobj'), ('AI', 'pobj'), ('.', 'punct')]

>> Bigrams: 
[[O, N], [N,  ], [ , Text], [Text, analytics], [analytics, arguably], [arguably, complex], [complex, tasks], [tasks, AI], [AI, .]]

>> Trigrams: 
[[O, N,  ], [N,  , Text], [ , Text, analytics], [Text, analytics, arguably], [analytics, arguably, complex], [arguably, complex, tasks], [complex, tasks, AI], [tasks, AI, .]]

>> Noun Phrases are: 
[I O N  Text analytics, the most complex tasks, an AI]

>> Named Entities are: 
[] 

------------------- Sentence 4 -------------------

  Language is messy and complex. 


>> Tokens are: 
[  , Language, messy, complex, .] 

>> PoS Tags are: 
[('  ', 'SPACE'), ('Language', 'PROPN'), ('messy', 'ADJ'), ('complex', 'ADJ'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('  ', 'compound'), ('Language', 'nsubj'), ('messy', 'acomp'), ('complex', 'conj'), ('.', 'punct')]

>> Bigrams: 
[[  , Language], [Language, messy], [messy, complex], [complex, .]]

>> Trigrams: 
[[  , Language, messy], [Language, messy, complex], [messy, complex, .]]

>> Noun Phrases are: 
[  Language]

>> Named Entities are: 
[] 

------------------- Sentence 5 -------------------

Meaning varies from speaker to speaker  and listener to listener. 


>> Tokens are: 
[Meaning, varies, speaker, speaker,  , listener, listener, .] 

>> PoS Tags are: 
[('Meaning', 'VERB'), ('varies', 'NOUN'), ('speaker', 'NOUN'), ('speaker', 'NOUN'), (' ', 'SPACE'), ('listener', 'NOUN'), ('listener', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('Meaning', 'ROOT'), ('varies', 'dobj'), ('speaker', 'pobj'), ('speaker', 'compound'), (' ', 'pobj'), ('listener', 'conj'), ('listener', 'pobj'), ('.', 'punct')]

>> Bigrams: 
[[Meaning, varies], [varies, speaker], [speaker, speaker], [speaker,  ], [ , listener], [listener, listener], [listener, .]]

>> Trigrams: 
[[Meaning, varies, speaker], [varies, speaker, speaker], [speaker, speaker,  ], [speaker,  , listener], [ , listener, listener], [listener, listener, .]]

>> Noun Phrases are: 
[varies, speaker, listener, listener]

>> Named Entities are: 
[] 

------------------- Sentence 6 -------------------

Machine learning provides a rich solution set for  handling this complexity, but must be implemented in a way that’s relevant  to the problem – and hand-in-hand with natural language processing code. 


>> Tokens are: 
[Machine, learning, provides, rich, solution, set,  , handling, complexity, ,, implemented, way, relevant,  , problem, –, hand, -, -, hand, natural, language, processing, code, .] 

>> PoS Tags are: 
[('Machine', 'NOUN'), ('learning', 'NOUN'), ('provides', 'VERB'), ('rich', 'ADJ'), ('solution', 'NOUN'), ('set', 'VERB'), (' ', 'SPACE'), ('handling', 'VERB'), ('complexity', 'NOUN'), (',', 'PUNCT'), ('implemented', 'VERB'), ('way', 'NOUN'), ('relevant', 'ADJ'), (' ', 'SPACE'), ('problem', 'NOUN'), ('–', 'PUNCT'), ('hand', 'NOUN'), ('-', 'PUNCT'), ('-', 'PUNCT'), ('hand', 'NOUN'), ('natural', 'ADJ'), ('language', 'NOUN'), ('processing', 'NOUN'), ('code', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('Machine', 'compound'), ('learning', 'nsubj'), ('provides', 'ROOT'), ('rich', 'amod'), ('solution', 'dobj'), ('set', 'acl'), (' ', 'pobj'), ('handling', 'acl'), ('complexity', 'dobj'), (',', 'punct'), ('implemented', 'conj'), ('way', 'pobj'), ('relevant', 'amod'), (' ', 'attr'), ('problem', 'pobj'), ('–', 'punct'), ('hand', 'conj'), ('-', 'punct'), ('-', 'punct'), ('hand', 'pobj'), ('natural', 'amod'), ('language', 'compound'), ('processing', 'compound'), ('code', 'pobj'), ('.', 'punct')]

>> Bigrams: 
[[Machine, learning], [learning, provides], [provides, rich], [rich, solution], [solution, set], [set,  ], [ , handling], [handling, complexity], [complexity, ,], [,, implemented], [implemented, way], [way, relevant], [relevant,  ], [ , problem], [problem, –], [–, hand], [hand, -], [-, -], [-, hand], [hand, natural], [natural, language], [language, processing], [processing, code], [code, .]]

>> Trigrams: 
[[Machine, learning, provides], [learning, provides, rich], [provides, rich, solution], [rich, solution, set], [solution, set,  ], [set,  , handling], [ , handling, complexity], [handling, complexity, ,], [complexity, ,, implemented], [,, implemented, way], [implemented, way, relevant], [way, relevant,  ], [relevant,  , problem], [ , problem, –], [problem, –, hand], [–, hand, -], [hand, -, -], [-, -, hand], [-, hand, natural], [hand, natural, language], [natural, language, processing], [language, processing, code], [processing, code, .]]

>> Noun Phrases are: 
[Machine learning, a rich solution, this complexity, a way, the problem, hand, hand, natural language processing code]

>> Named Entities are: 
[] 


================================ Paragraph 177 =================================

Moreover, although it’s necessary to use machine learning, it’s not sufficient  to use a single type of model, like a big “unsupervised learning” system.  Certain aspects of machine learning are very subjective, and need to be  trained or tuned to match your perspective. Lexalytics combines many   types of machine learning along with pure natural language processing code.  We have no prejudice for one algorithm over another except in how they  help us provide the best possible text analytics system to our customers. 

------------------- Sentence 1 -------------------

Moreover, although it’s necessary to use machine learning, it’s not sufficient  to use a single type of model, like a big “unsupervised learning” system. 


>> Tokens are: 
[,, necessary, use, machine, learning, ,, sufficient,  , use, single, type, model, ,, like, big, “, unsupervised, learning, ”, system, .] 

>> PoS Tags are: 
[(',', 'PUNCT'), ('necessary', 'ADJ'), ('use', 'VERB'), ('machine', 'NOUN'), ('learning', 'NOUN'), (',', 'PUNCT'), ('sufficient', 'ADJ'), (' ', 'SPACE'), ('use', 'VERB'), ('single', 'ADJ'), ('type', 'NOUN'), ('model', 'NOUN'), (',', 'PUNCT'), ('like', 'ADP'), ('big', 'ADJ'), ('“', 'PUNCT'), ('unsupervised', 'ADJ'), ('learning', 'NOUN'), ('”', 'PUNCT'), ('system', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[(',', 'punct'), ('necessary', 'acomp'), ('use', 'xcomp'), ('machine', 'compound'), ('learning', 'dobj'), (',', 'punct'), ('sufficient', 'amod'), (' ', 'attr'), ('use', 'xcomp'), ('single', 'amod'), ('type', 'dobj'), ('model', 'pobj'), (',', 'punct'), ('like', 'prep'), ('big', 'amod'), ('“', 'punct'), ('unsupervised', 'amod'), ('learning', 'nmod'), ('”', 'punct'), ('system', 'pobj'), ('.', 'punct')]

>> Bigrams: 
[[,, necessary], [necessary, use], [use, machine], [machine, learning], [learning, ,], [,, sufficient], [sufficient,  ], [ , use], [use, single], [single, type], [type, model], [model, ,], [,, like], [like, big], [big, “], [“, unsupervised], [unsupervised, learning], [learning, ”], [”, system], [system, .]]

>> Trigrams: 
[[,, necessary, use], [necessary, use, machine], [use, machine, learning], [machine, learning, ,], [learning, ,, sufficient], [,, sufficient,  ], [sufficient,  , use], [ , use, single], [use, single, type], [single, type, model], [type, model, ,], [model, ,, like], [,, like, big], [like, big, “], [big, “, unsupervised], [“, unsupervised, learning], [unsupervised, learning, ”], [learning, ”, system], [”, system, .]]

>> Noun Phrases are: 
[it, machine learning, it, a single type, model, a big “unsupervised learning” system]

>> Named Entities are: 
[] 

------------------- Sentence 2 -------------------

  


>> Tokens are: 
[ ] 

>> PoS Tags are: 
[(' ', 'SPACE')] 

>> Dependency Tags are: 
[(' ', 'ROOT')]

>> Bigrams: 
[]

>> Trigrams: 
[]

>> Noun Phrases are: 
[]

>> Named Entities are: 
[] 

------------------- Sentence 3 -------------------

Certain aspects of machine learning are very subjective, and need to be  trained or tuned to match your perspective. 


>> Tokens are: 
[Certain, aspects, machine, learning, subjective, ,, need,  , trained, tuned, match, perspective, .] 

>> PoS Tags are: 
[('Certain', 'ADJ'), ('aspects', 'NOUN'), ('machine', 'NOUN'), ('learning', 'NOUN'), ('subjective', 'ADJ'), (',', 'PUNCT'), ('need', 'VERB'), (' ', 'SPACE'), ('trained', 'VERB'), ('tuned', 'VERB'), ('match', 'VERB'), ('perspective', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('Certain', 'amod'), ('aspects', 'nsubj'), ('machine', 'compound'), ('learning', 'pobj'), ('subjective', 'acomp'), (',', 'punct'), ('need', 'conj'), (' ', 'nsubjpass'), ('trained', 'xcomp'), ('tuned', 'conj'), ('match', 'advcl'), ('perspective', 'dobj'), ('.', 'punct')]

>> Bigrams: 
[[Certain, aspects], [aspects, machine], [machine, learning], [learning, subjective], [subjective, ,], [,, need], [need,  ], [ , trained], [trained, tuned], [tuned, match], [match, perspective], [perspective, .]]

>> Trigrams: 
[[Certain, aspects, machine], [aspects, machine, learning], [machine, learning, subjective], [learning, subjective, ,], [subjective, ,, need], [,, need,  ], [need,  , trained], [ , trained, tuned], [trained, tuned, match], [tuned, match, perspective], [match, perspective, .]]

>> Noun Phrases are: 
[Certain aspects, machine learning, your perspective]

>> Named Entities are: 
[] 

------------------- Sentence 4 -------------------

Lexalytics combines many   types of machine learning along with pure natural language processing code. 


>> Tokens are: 
[Lexalytics, combines,   , types, machine, learning, pure, natural, language, processing, code, .] 

>> PoS Tags are: 
[('Lexalytics', 'NOUN'), ('combines', 'VERB'), ('  ', 'SPACE'), ('types', 'NOUN'), ('machine', 'NOUN'), ('learning', 'VERB'), ('pure', 'ADJ'), ('natural', 'ADJ'), ('language', 'NOUN'), ('processing', 'NOUN'), ('code', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('Lexalytics', 'nsubj'), ('combines', 'ROOT'), ('  ', 'compound'), ('types', 'dobj'), ('machine', 'compound'), ('learning', 'pobj'), ('pure', 'amod'), ('natural', 'amod'), ('language', 'compound'), ('processing', 'compound'), ('code', 'pobj'), ('.', 'punct')]

>> Bigrams: 
[[Lexalytics, combines], [combines,   ], [  , types], [types, machine], [machine, learning], [learning, pure], [pure, natural], [natural, language], [language, processing], [processing, code], [code, .]]

>> Trigrams: 
[[Lexalytics, combines,   ], [combines,   , types], [  , types, machine], [types, machine, learning], [machine, learning, pure], [learning, pure, natural], [pure, natural, language], [natural, language, processing], [language, processing, code], [processing, code, .]]

>> Noun Phrases are: 
[Lexalytics, many   types, pure natural language processing code]

>> Named Entities are: 
[] 

------------------- Sentence 5 -------------------

  


>> Tokens are: 
[ ] 

>> PoS Tags are: 
[(' ', 'SPACE')] 

>> Dependency Tags are: 
[(' ', 'ROOT')]

>> Bigrams: 
[]

>> Trigrams: 
[]

>> Noun Phrases are: 
[]

>> Named Entities are: 
[] 

------------------- Sentence 6 -------------------

We have no prejudice for one algorithm over another except in how they  help us provide the best possible text analytics system to our customers. 


>> Tokens are: 
[prejudice, algorithm,  , help, provide, best, possible, text, analytics, system, customers, .] 

>> PoS Tags are: 
[('prejudice', 'NOUN'), ('algorithm', 'NOUN'), (' ', 'SPACE'), ('help', 'VERB'), ('provide', 'VERB'), ('best', 'ADJ'), ('possible', 'ADJ'), ('text', 'NOUN'), ('analytics', 'NOUN'), ('system', 'NOUN'), ('customers', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('prejudice', 'dobj'), ('algorithm', 'pobj'), (' ', 'nsubj'), ('help', 'pcomp'), ('provide', 'ccomp'), ('best', 'advmod'), ('possible', 'amod'), ('text', 'compound'), ('analytics', 'compound'), ('system', 'dobj'), ('customers', 'pobj'), ('.', 'punct')]

>> Bigrams: 
[[prejudice, algorithm], [algorithm,  ], [ , help], [help, provide], [provide, best], [best, possible], [possible, text], [text, analytics], [analytics, system], [system, customers], [customers, .]]

>> Trigrams: 
[[prejudice, algorithm,  ], [algorithm,  , help], [ , help, provide], [help, provide, best], [provide, best, possible], [best, possible, text], [possible, text, analytics], [text, analytics, system], [analytics, system, customers], [system, customers, .]]

>> Noun Phrases are: 
[We, no prejudice, one algorithm, they, us, the best possible text analytics system, our customers]

>> Named Entities are: 
[('one', 'CARDINAL')] 


================================ Paragraph 178 =================================

to explore how Lexalytics   

------------------- Sentence 1 -------------------

to explore how Lexalytics    


>> Tokens are: 
[explore, Lexalytics,   ] 

>> PoS Tags are: 
[('explore', 'VERB'), ('Lexalytics', 'PROPN'), ('  ', 'SPACE')] 

>> Dependency Tags are: 
[('explore', 'ROOT'), ('Lexalytics', 'dobj'), ('  ', 'ccomp')]

>> Bigrams: 
[[explore, Lexalytics], [Lexalytics,   ]]

>> Trigrams: 
[[explore, Lexalytics,   ]]

>> Noun Phrases are: 
[how Lexalytics]

>> Named Entities are: 
[] 


================================ Paragraph 179 =================================

can help your business at  

------------------- Sentence 1 -------------------

can help your business at   


>> Tokens are: 
[help, business,  ] 

>> PoS Tags are: 
[('help', 'VERB'), ('business', 'NOUN'), (' ', 'SPACE')] 

>> Dependency Tags are: 
[('help', 'ROOT'), ('business', 'dobj'), (' ', 'pobj')]

>> Bigrams: 
[[help, business], [business,  ]]

>> Trigrams: 
[[help, business,  ]]

>> Noun Phrases are: 
[your business]

>> Named Entities are: 
[] 


================================ Paragraph 180 =================================

lexalytics.com/contact 

------------------- Sentence 1 -------------------

lexalytics.com/contact 


>> Tokens are: 
[lexalytics.com/contact] 

>> PoS Tags are: 
[('lexalytics.com/contact', 'NOUN')] 

>> Dependency Tags are: 
[('lexalytics.com/contact', 'ROOT')]

>> Bigrams: 
[]

>> Trigrams: 
[]

>> Noun Phrases are: 
[lexalytics.com/contact]

>> Named Entities are: 
[] 


================================ Paragraph 181 =================================

Contact  us

------------------- Sentence 1 -------------------

Contact  us 


>> Tokens are: 
[Contact,  ] 

>> PoS Tags are: 
[('Contact', 'NOUN'), (' ', 'SPACE')] 

>> Dependency Tags are: 
[('Contact', 'ROOT'), (' ', 'nummod')]

>> Bigrams: 
[[Contact,  ]]

>> Trigrams: 
[]

>> Noun Phrases are: 
[Contact, us]

>> Named Entities are: 
[] 


================================ Paragraph 182 =================================

©  2019 Lexalytics, Inc. | M 

------------------- Sentence 1 -------------------

©  2019 Lexalytics, Inc. | M 


>> Tokens are: 
[©,  , 2019, Lexalytics, ,, Inc., |, M] 

>> PoS Tags are: 
[('©', 'ADJ'), (' ', 'SPACE'), ('2019', 'NUM'), ('Lexalytics', 'PROPN'), (',', 'PUNCT'), ('Inc.', 'PROPN'), ('|', 'NOUN'), ('M', 'PROPN')] 

>> Dependency Tags are: 
[('©', 'nmod'), (' ', 'nmod'), ('2019', 'nummod'), ('Lexalytics', 'nmod'), (',', 'punct'), ('Inc.', 'compound'), ('|', 'compound'), ('M', 'ROOT')]

>> Bigrams: 
[[©,  ], [ , 2019], [2019, Lexalytics], [Lexalytics, ,], [,, Inc.], [Inc., |], [|, M]]

>> Trigrams: 
[[©,  , 2019], [ , 2019, Lexalytics], [2019, Lexalytics, ,], [Lexalytics, ,, Inc.], [,, Inc., |], [Inc., |, M]]

>> Noun Phrases are: 
[©  2019 Lexalytics, Inc. | M]

>> Named Entities are: 
[('2019', 'DATE'), ('Lexalytics, Inc.', 'ORG')] 


================================ Paragraph 183 =================================

achine Learning W hite Paper | v3c 

------------------- Sentence 1 -------------------

achine Learning W hite Paper | v3c 


>> Tokens are: 
[achine, Learning, W, hite, Paper, |, v3c] 

>> PoS Tags are: 
[('achine', 'ADJ'), ('Learning', 'PROPN'), ('W', 'PROPN'), ('hite', 'NOUN'), ('Paper', 'PROPN'), ('|', 'NOUN'), ('v3c', 'VERB')] 

>> Dependency Tags are: 
[('achine', 'amod'), ('Learning', 'compound'), ('W', 'compound'), ('hite', 'compound'), ('Paper', 'compound'), ('|', 'compound'), ('v3c', 'ROOT')]

>> Bigrams: 
[[achine, Learning], [Learning, W], [W, hite], [hite, Paper], [Paper, |], [|, v3c]]

>> Trigrams: 
[[achine, Learning, W], [Learning, W, hite], [W, hite, Paper], [hite, Paper, |], [Paper, |, v3c]]

>> Noun Phrases are: 
[]

>> Named Entities are: 
[('Learning W', 'PERSON')] 


================================ Paragraph 184 =================================

Lexalytics processes BILLIONS of   unstructured documents every day, GLOBALLY. We transform unstructured text into usable data and powerful stories. 

------------------- Sentence 1 -------------------

Lexalytics processes BILLIONS of   unstructured documents every day, GLOBALLY. 


>> Tokens are: 
[Lexalytics, processes, BILLIONS,   , unstructured, documents, day, ,, GLOBALLY, .] 

>> PoS Tags are: 
[('Lexalytics', 'NOUN'), ('processes', 'VERB'), ('BILLIONS', 'NOUN'), ('  ', 'SPACE'), ('unstructured', 'ADJ'), ('documents', 'NOUN'), ('day', 'NOUN'), (',', 'PUNCT'), ('GLOBALLY', 'PROPN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('Lexalytics', 'nsubj'), ('processes', 'ROOT'), ('BILLIONS', 'dobj'), ('  ', 'nmod'), ('unstructured', 'amod'), ('documents', 'pobj'), ('day', 'npadvmod'), (',', 'punct'), ('GLOBALLY', 'npadvmod'), ('.', 'punct')]

>> Bigrams: 
[[Lexalytics, processes], [processes, BILLIONS], [BILLIONS,   ], [  , unstructured], [unstructured, documents], [documents, day], [day, ,], [,, GLOBALLY], [GLOBALLY, .]]

>> Trigrams: 
[[Lexalytics, processes, BILLIONS], [processes, BILLIONS,   ], [BILLIONS,   , unstructured], [  , unstructured, documents], [unstructured, documents, day], [documents, day, ,], [day, ,, GLOBALLY], [,, GLOBALLY, .]]

>> Noun Phrases are: 
[Lexalytics, BILLIONS,   unstructured documents]

>> Named Entities are: 
[('BILLIONS', 'ORG'), ('every day', 'DATE'), ('GLOBALLY', 'ORG')] 

------------------- Sentence 2 -------------------

We transform unstructured text into usable data and powerful stories. 


>> Tokens are: 
[transform, unstructured, text, usable, data, powerful, stories, .] 

>> PoS Tags are: 
[('transform', 'VERB'), ('unstructured', 'ADJ'), ('text', 'NOUN'), ('usable', 'ADJ'), ('data', 'NOUN'), ('powerful', 'ADJ'), ('stories', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('transform', 'ROOT'), ('unstructured', 'amod'), ('text', 'dobj'), ('usable', 'amod'), ('data', 'pobj'), ('powerful', 'amod'), ('stories', 'conj'), ('.', 'punct')]

>> Bigrams: 
[[transform, unstructured], [unstructured, text], [text, usable], [usable, data], [data, powerful], [powerful, stories], [stories, .]]

>> Trigrams: 
[[transform, unstructured, text], [unstructured, text, usable], [text, usable, data], [usable, data, powerful], [data, powerful, stories], [powerful, stories, .]]

>> Noun Phrases are: 
[We, unstructured text, usable data, powerful stories]

>> Named Entities are: 
[] 


================================ Paragraph 185 =================================

Our on-premise Salience® engine, SaaS Semantria® API, and end-to-end Lexalytics  Intelligence Platform® combine natural language processing with artificial intelligence  to reveal context-rich patterns and insights within comments, reviews, surveys, and   other text documents.  

------------------- Sentence 1 -------------------

Our on-premise Salience® engine, SaaS Semantria® API, and end-to-end Lexalytics   


>> Tokens are: 
[-, premise, Salience, ®, engine, ,, SaaS, Semantria, ®, API, ,, end, -, -, end, Lexalytics,  ] 

>> PoS Tags are: 
[('-', 'PUNCT'), ('premise', 'NOUN'), ('Salience', 'PROPN'), ('®', 'NOUN'), ('engine', 'NOUN'), (',', 'PUNCT'), ('SaaS', 'PROPN'), ('Semantria', 'PROPN'), ('®', 'NOUN'), ('API', 'NOUN'), (',', 'PUNCT'), ('end', 'NOUN'), ('-', 'PUNCT'), ('-', 'PUNCT'), ('end', 'NOUN'), ('Lexalytics', 'PROPN'), (' ', 'SPACE')] 

>> Dependency Tags are: 
[('-', 'punct'), ('premise', 'pobj'), ('Salience', 'compound'), ('®', 'compound'), ('engine', 'ROOT'), (',', 'punct'), ('SaaS', 'compound'), ('Semantria', 'compound'), ('®', 'compound'), ('API', 'appos'), (',', 'punct'), ('end', 'nmod'), ('-', 'punct'), ('-', 'punct'), ('end', 'pobj'), ('Lexalytics', 'compound'), (' ', 'appos')]

>> Bigrams: 
[[-, premise], [premise, Salience], [Salience, ®], [®, engine], [engine, ,], [,, SaaS], [SaaS, Semantria], [Semantria, ®], [®, API], [API, ,], [,, end], [end, -], [-, -], [-, end], [end, Lexalytics], [Lexalytics,  ]]

>> Trigrams: 
[[-, premise, Salience], [premise, Salience, ®], [Salience, ®, engine], [®, engine, ,], [engine, ,, SaaS], [,, SaaS, Semantria], [SaaS, Semantria, ®], [Semantria, ®, API], [®, API, ,], [API, ,, end], [,, end, -], [end, -, -], [-, -, end], [-, end, Lexalytics], [end, Lexalytics,  ]]

>> Noun Phrases are: 
[-premise, SaaS Semantria® API, end]

>> Named Entities are: 
[('Salience®', 'PRODUCT')] 

------------------- Sentence 2 -------------------

Intelligence Platform® combine natural language processing with artificial intelligence  to reveal context-rich patterns and insights within comments, reviews, surveys, and   other text documents. 


>> Tokens are: 
[Intelligence, Platform, ®, combine, natural, language, processing, artificial, intelligence,  , reveal, context, -, rich, patterns, insights, comments, ,, reviews, ,, surveys, ,,   , text, documents, .] 

>> PoS Tags are: 
[('Intelligence', 'PROPN'), ('Platform', 'PROPN'), ('®', 'NOUN'), ('combine', 'VERB'), ('natural', 'ADJ'), ('language', 'NOUN'), ('processing', 'NOUN'), ('artificial', 'ADJ'), ('intelligence', 'NOUN'), (' ', 'SPACE'), ('reveal', 'VERB'), ('context', 'NOUN'), ('-', 'PUNCT'), ('rich', 'ADJ'), ('patterns', 'NOUN'), ('insights', 'NOUN'), ('comments', 'NOUN'), (',', 'PUNCT'), ('reviews', 'NOUN'), (',', 'PUNCT'), ('surveys', 'NOUN'), (',', 'PUNCT'), ('  ', 'SPACE'), ('text', 'NOUN'), ('documents', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('Intelligence', 'compound'), ('Platform', 'compound'), ('®', 'nsubj'), ('combine', 'ROOT'), ('natural', 'amod'), ('language', 'compound'), ('processing', 'dobj'), ('artificial', 'amod'), ('intelligence', 'compound'), (' ', 'pobj'), ('reveal', 'advcl'), ('context', 'npadvmod'), ('-', 'punct'), ('rich', 'amod'), ('patterns', 'dobj'), ('insights', 'conj'), ('comments', 'pobj'), (',', 'punct'), ('reviews', 'conj'), (',', 'punct'), ('surveys', 'conj'), (',', 'punct'), ('  ', 'nmod'), ('text', 'compound'), ('documents', 'conj'), ('.', 'punct')]

>> Bigrams: 
[[Intelligence, Platform], [Platform, ®], [®, combine], [combine, natural], [natural, language], [language, processing], [processing, artificial], [artificial, intelligence], [intelligence,  ], [ , reveal], [reveal, context], [context, -], [-, rich], [rich, patterns], [patterns, insights], [insights, comments], [comments, ,], [,, reviews], [reviews, ,], [,, surveys], [surveys, ,], [,,   ], [  , text], [text, documents], [documents, .]]

>> Trigrams: 
[[Intelligence, Platform, ®], [Platform, ®, combine], [®, combine, natural], [combine, natural, language], [natural, language, processing], [language, processing, artificial], [processing, artificial, intelligence], [artificial, intelligence,  ], [intelligence,  , reveal], [ , reveal, context], [reveal, context, -], [context, -, rich], [-, rich, patterns], [rich, patterns, insights], [patterns, insights, comments], [insights, comments, ,], [comments, ,, reviews], [,, reviews, ,], [reviews, ,, surveys], [,, surveys, ,], [surveys, ,,   ], [,,   , text], [  , text, documents], [text, documents, .]]

>> Noun Phrases are: 
[Intelligence Platform®, natural language processing, context-rich patterns, insights, comments, reviews, surveys,   other text documents]

>> Named Entities are: 
[] 

------------------- Sentence 3 -------------------

  


>> Tokens are: 
[ ] 

>> PoS Tags are: 
[(' ', 'SPACE')] 

>> Dependency Tags are: 
[(' ', 'ROOT')]

>> Bigrams: 
[]

>> Trigrams: 
[]

>> Noun Phrases are: 
[]

>> Named Entities are: 
[] 


================================ Paragraph 186 =================================

Data analytics and data analyst companies rely on Lexalytics to build better  products, share insights between engineering, marketing, PR, and support teams,  and drive business growth. 

------------------- Sentence 1 -------------------

Data analytics and data analyst companies rely on Lexalytics to build better  products, share insights between engineering, marketing, PR, and support teams,  and drive business growth. 


>> Tokens are: 
[Data, analytics, data, analyst, companies, rely, Lexalytics, build, better,  , products, ,, share, insights, engineering, ,, marketing, ,, PR, ,, support, teams, ,,  , drive, business, growth, .] 

>> PoS Tags are: 
[('Data', 'NOUN'), ('analytics', 'NOUN'), ('data', 'NOUN'), ('analyst', 'NOUN'), ('companies', 'NOUN'), ('rely', 'VERB'), ('Lexalytics', 'PROPN'), ('build', 'VERB'), ('better', 'ADJ'), (' ', 'SPACE'), ('products', 'NOUN'), (',', 'PUNCT'), ('share', 'NOUN'), ('insights', 'NOUN'), ('engineering', 'NOUN'), (',', 'PUNCT'), ('marketing', 'NOUN'), (',', 'PUNCT'), ('PR', 'NOUN'), (',', 'PUNCT'), ('support', 'NOUN'), ('teams', 'NOUN'), (',', 'PUNCT'), (' ', 'SPACE'), ('drive', 'VERB'), ('business', 'NOUN'), ('growth', 'NOUN'), ('.', 'PUNCT')] 

>> Dependency Tags are: 
[('Data', 'compound'), ('analytics', 'nmod'), ('data', 'compound'), ('analyst', 'conj'), ('companies', 'nsubj'), ('rely', 'ROOT'), ('Lexalytics', 'pobj'), ('build', 'advcl'), ('better', 'amod'), (' ', 'compound'), ('products', 'dobj'), (',', 'punct'), ('share', 'conj'), ('insights', 'dobj'), ('engineering', 'pobj'), (',', 'punct'), ('marketing', 'conj'), (',', 'punct'), ('PR', 'conj'), (',', 'punct'), ('support', 'compound'), ('teams', 'conj'), (',', 'punct'), (' ', 'conj'), ('drive', 'conj'), ('business', 'compound'), ('growth', 'dobj'), ('.', 'punct')]

>> Bigrams: 
[[Data, analytics], [analytics, data], [data, analyst], [analyst, companies], [companies, rely], [rely, Lexalytics], [Lexalytics, build], [build, better], [better,  ], [ , products], [products, ,], [,, share], [share, insights], [insights, engineering], [engineering, ,], [,, marketing], [marketing, ,], [,, PR], [PR, ,], [,, support], [support, teams], [teams, ,], [,,  ], [ , drive], [drive, business], [business, growth], [growth, .]]

>> Trigrams: 
[[Data, analytics, data], [analytics, data, analyst], [data, analyst, companies], [analyst, companies, rely], [companies, rely, Lexalytics], [rely, Lexalytics, build], [Lexalytics, build, better], [build, better,  ], [better,  , products], [ , products, ,], [products, ,, share], [,, share, insights], [share, insights, engineering], [insights, engineering, ,], [engineering, ,, marketing], [,, marketing, ,], [marketing, ,, PR], [,, PR, ,], [PR, ,, support], [,, support, teams], [support, teams, ,], [teams, ,,  ], [,,  , drive], [ , drive, business], [drive, business, growth], [business, growth, .]]

>> Noun Phrases are: 
[Data analytics and data analyst companies, Lexalytics, better  products, share, insights, engineering, marketing, PR, support teams, business growth]

>> Named Entities are: 
[('Lexalytics', 'ORG')] 


================================ Paragraph 187 =================================

For more information, visit www.lexalytics.com or call 1-800-377-8036  

------------------- Sentence 1 -------------------

For more information, visit www.lexalytics.com or call 1-800-377-8036   


>> Tokens are: 
[information, ,, visit, www.lexalytics.com, 1, -, 800, -, 377, -, 8036,  ] 

>> PoS Tags are: 
[('information', 'NOUN'), (',', 'PUNCT'), ('visit', 'VERB'), ('www.lexalytics.com', 'X'), ('1', 'NUM'), ('-', 'SYM'), ('800', 'NUM'), ('-', 'NUM'), ('377', 'NUM'), ('-', 'NUM'), ('8036', 'NUM'), (' ', 'SPACE')] 

>> Dependency Tags are: 
[('information', 'pobj'), (',', 'punct'), ('visit', 'ROOT'), ('www.lexalytics.com', 'dobj'), ('1', 'dobj'), ('-', 'punct'), ('800', 'prep'), ('-', 'punct'), ('377', 'nummod'), ('-', 'punct'), ('8036', 'prep'), (' ', 'dobj')]

>> Bigrams: 
[[information, ,], [,, visit], [visit, www.lexalytics.com], [www.lexalytics.com, 1], [1, -], [-, 800], [800, -], [-, 377], [377, -], [-, 8036], [8036,  ]]

>> Trigrams: 
[[information, ,, visit], [,, visit, www.lexalytics.com], [visit, www.lexalytics.com, 1], [www.lexalytics.com, 1, -], [1, -, 800], [-, 800, -], [800, -, 377], [-, 377, -], [377, -, 8036], [-, 8036,  ]]

>> Noun Phrases are: 
[more information]

>> Named Entities are: 
[] 


================================ Paragraph 188 =================================

W H I T E  P A P E R 

------------------- Sentence 1 -------------------

W H 


>> Tokens are: 
[W, H] 

>> PoS Tags are: 
[('W', 'NOUN'), ('H', 'NOUN')] 

>> Dependency Tags are: 
[('W', 'compound'), ('H', 'ROOT')]

>> Bigrams: 
[[W, H]]

>> Trigrams: 
[]

>> Noun Phrases are: 
[W H]

>> Named Entities are: 
[] 

------------------- Sentence 2 -------------------

I T 


>> Tokens are: 
[T] 

>> PoS Tags are: 
[('T', 'NOUN')] 

>> Dependency Tags are: 
[('T', 'appos')]

>> Bigrams: 
[]

>> Trigrams: 
[]

>> Noun Phrases are: 
[I, T]

>> Named Entities are: 
[] 

------------------- Sentence 3 -------------------

E   


>> Tokens are: 
[E,  ] 

>> PoS Tags are: 
[('E', 'NOUN'), (' ', 'SPACE')] 

>> Dependency Tags are: 
[('E', 'ROOT'), (' ', 'appos')]

>> Bigrams: 
[[E,  ]]

>> Trigrams: 
[]

>> Noun Phrases are: 
[E]

>> Named Entities are: 
[] 

------------------- Sentence 4 -------------------

P A P E R 


>> Tokens are: 
[P, P, E, R] 

>> PoS Tags are: 
[('P', 'NOUN'), ('P', 'NOUN'), ('E', 'NOUN'), ('R', 'NOUN')] 

>> Dependency Tags are: 
[('P', 'compound'), ('P', 'compound'), ('E', 'compound'), ('R', 'ROOT')]

>> Bigrams: 
[[P, P], [P, E], [E, R]]

>> Trigrams: 
[[P, P, E], [P, E, R]]

>> Noun Phrases are: 
[P A P E R]

>> Named Entities are: 
[] 


================================ Paragraph 189 =================================

15|       | Lexalytics, Inc., 48 North Pleasant St. Unit 301, Amherst MA 01002 USA | 1-800-377-8036 | www.lexalytics.com

------------------- Sentence 1 -------------------

15|       | Lexalytics, Inc., 48 North Pleasant St. Unit 301, Amherst MA 01002 USA | 1-800-377-8036 | www.lexalytics.com 


>> Tokens are: 
[15|,       , |, Lexalytics, ,, Inc., ,, 48, North, Pleasant, St., Unit, 301, ,, Amherst, MA, 01002, USA, |, 1, -, 800, -, 377, -, 8036, |, www.lexalytics.com] 

>> PoS Tags are: 
[('15|', 'VERB'), ('      ', 'SPACE'), ('|', 'NOUN'), ('Lexalytics', 'PROPN'), (',', 'PUNCT'), ('Inc.', 'PROPN'), (',', 'PUNCT'), ('48', 'NUM'), ('North', 'PROPN'), ('Pleasant', 'PROPN'), ('St.', 'PROPN'), ('Unit', 'PROPN'), ('301', 'NUM'), (',', 'PUNCT'), ('Amherst', 'PROPN'), ('MA', 'PROPN'), ('01002', 'NUM'), ('USA', 'PROPN'), ('|', 'NOUN'), ('1', 'NUM'), ('-', 'NUM'), ('800', 'NUM'), ('-', 'NUM'), ('377', 'NUM'), ('-', 'PUNCT'), ('8036', 'NUM'), ('|', 'NOUN'), ('www.lexalytics.com', 'X')] 

>> Dependency Tags are: 
[('15|', 'ROOT'), ('      ', 'compound'), ('|', 'nmod'), ('Lexalytics', 'nmod'), (',', 'punct'), ('Inc.', 'npadvmod'), (',', 'punct'), ('48', 'nummod'), ('North', 'compound'), ('Pleasant', 'compound'), ('St.', 'compound'), ('Unit', 'appos'), ('301', 'nummod'), (',', 'punct'), ('Amherst', 'compound'), ('MA', 'appos'), ('01002', 'nummod'), ('USA', 'appos'), ('|', 'npadvmod'), ('1', 'nummod'), ('-', 'punct'), ('800', 'prep'), ('-', 'punct'), ('377', 'nummod'), ('-', 'punct'), ('8036', 'nummod'), ('|', 'npadvmod'), ('www.lexalytics.com', 'punct')]

>> Bigrams: 
[[15|,       ], [      , |], [|, Lexalytics], [Lexalytics, ,], [,, Inc.], [Inc., ,], [,, 48], [48, North], [North, Pleasant], [Pleasant, St.], [St., Unit], [Unit, 301], [301, ,], [,, Amherst], [Amherst, MA], [MA, 01002], [01002, USA], [USA, |], [|, 1], [1, -], [-, 800], [800, -], [-, 377], [377, -], [-, 8036], [8036, |], [|, www.lexalytics.com]]

>> Trigrams: 
[[15|,       , |], [      , |, Lexalytics], [|, Lexalytics, ,], [Lexalytics, ,, Inc.], [,, Inc., ,], [Inc., ,, 48], [,, 48, North], [48, North, Pleasant], [North, Pleasant, St.], [Pleasant, St., Unit], [St., Unit, 301], [Unit, 301, ,], [301, ,, Amherst], [,, Amherst, MA], [Amherst, MA, 01002], [MA, 01002, USA], [01002, USA, |], [USA, |, 1], [|, 1, -], [1, -, 800], [-, 800, -], [800, -, 377], [-, 377, -], [377, -, 8036], [-, 8036, |], [8036, |, www.lexalytics.com]]

>> Noun Phrases are: 
[48 North Pleasant St. Unit, Amherst MA, USA]

>> Named Entities are: 
[('Lexalytics, Inc.', 'ORG'), ('48', 'CARDINAL'), ('North Pleasant St. Unit 301', 'ORG'), ('Amherst MA 01002 USA | 1-800-377-8036', 'ORG')] 
