				 *** Text Processing using NLTK *** 


========================================== PARAGRAPH 1 ===========================================

Big data analytics: a survey Chun‑Wei Tsai1, Chin‑Feng Lai2, Han‑Chieh Chao1,3,4 and Athanasios V. Vasilakos5* 

------------------- Sentence 1 -------------------

Big data analytics: a survey Chun‑Wei Tsai1, Chin‑Feng Lai2, Han‑Chieh Chao1,3,4 and Athanasios V. Vasilakos5*

>> Tokens are: 
 ['Big', 'data', 'analytics', ':', 'survey', 'Chun‑Wei', 'Tsai1', ',', 'Chin‑Feng', 'Lai2', ',', 'Han‑Chieh', 'Chao1,3,4', 'Athanasios', 'V.', 'Vasilakos5', '*']

>> Bigrams are: 
 [('Big', 'data'), ('data', 'analytics'), ('analytics', ':'), (':', 'survey'), ('survey', 'Chun‑Wei'), ('Chun‑Wei', 'Tsai1'), ('Tsai1', ','), (',', 'Chin‑Feng'), ('Chin‑Feng', 'Lai2'), ('Lai2', ','), (',', 'Han‑Chieh'), ('Han‑Chieh', 'Chao1,3,4'), ('Chao1,3,4', 'Athanasios'), ('Athanasios', 'V.'), ('V.', 'Vasilakos5'), ('Vasilakos5', '*')]

>> Trigrams are: 
 [('Big', 'data', 'analytics'), ('data', 'analytics', ':'), ('analytics', ':', 'survey'), (':', 'survey', 'Chun‑Wei'), ('survey', 'Chun‑Wei', 'Tsai1'), ('Chun‑Wei', 'Tsai1', ','), ('Tsai1', ',', 'Chin‑Feng'), (',', 'Chin‑Feng', 'Lai2'), ('Chin‑Feng', 'Lai2', ','), ('Lai2', ',', 'Han‑Chieh'), (',', 'Han‑Chieh', 'Chao1,3,4'), ('Han‑Chieh', 'Chao1,3,4', 'Athanasios'), ('Chao1,3,4', 'Athanasios', 'V.'), ('Athanasios', 'V.', 'Vasilakos5'), ('V.', 'Vasilakos5', '*')]

>> POS Tags are: 
 [('Big', 'NNP'), ('data', 'NNS'), ('analytics', 'NNS'), (':', ':'), ('survey', 'NN'), ('Chun‑Wei', 'NNP'), ('Tsai1', 'NNP'), (',', ','), ('Chin‑Feng', 'NNP'), ('Lai2', 'NNP'), (',', ','), ('Han‑Chieh', 'NNP'), ('Chao1,3,4', 'NNP'), ('Athanasios', 'NNP'), ('V.', 'NNP'), ('Vasilakos5', 'NNP'), ('*', 'NN')]

>> Noun Phrases are: 
 ['Big data analytics', 'survey Chun‑Wei Tsai1', 'Chin‑Feng Lai2', 'Han‑Chieh Chao1,3,4 Athanasios V. Vasilakos5 *']

>> Named Entities are: 
 [('PERSON', 'Athanasios V. Vasilakos5')] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('analytics', 'analyt'), (':', ':'), ('survey', 'survey'), ('Chun‑Wei', 'chun‑wei'), ('Tsai1', 'tsai1'), (',', ','), ('Chin‑Feng', 'chin‑feng'), ('Lai2', 'lai2'), (',', ','), ('Han‑Chieh', 'han‑chieh'), ('Chao1,3,4', 'chao1,3,4'), ('Athanasios', 'athanasio'), ('V.', 'v.'), ('Vasilakos5', 'vasilakos5'), ('*', '*')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('analytics', 'analyt'), (':', ':'), ('survey', 'survey'), ('Chun‑Wei', 'chun‑wei'), ('Tsai1', 'tsai1'), (',', ','), ('Chin‑Feng', 'chin‑feng'), ('Lai2', 'lai2'), (',', ','), ('Han‑Chieh', 'han‑chieh'), ('Chao1,3,4', 'chao1,3,4'), ('Athanasios', 'athanasio'), ('V.', 'v.'), ('Vasilakos5', 'vasilakos5'), ('*', '*')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), ('analytics', 'analytics'), (':', ':'), ('survey', 'survey'), ('Chun‑Wei', 'Chun‑Wei'), ('Tsai1', 'Tsai1'), (',', ','), ('Chin‑Feng', 'Chin‑Feng'), ('Lai2', 'Lai2'), (',', ','), ('Han‑Chieh', 'Han‑Chieh'), ('Chao1,3,4', 'Chao1,3,4'), ('Athanasios', 'Athanasios'), ('V.', 'V.'), ('Vasilakos5', 'Vasilakos5'), ('*', '*')]



========================================== PARAGRAPH 2 ===========================================

Introduction As the information technology spreads fast, most of the data were born digital as well  as exchanged on internet today. According to the estimation of Lyman and Varian [1],  the new data stored in digital media devices have already been more than 92 % in 2002,  while the size of these new data was also more than five exabytes. In fact, the problems  of analyzing the large scale data were not suddenly occurred but have been there for sev- eral years because the creation of data is usually much easier than finding useful things  from the data. Even though computer systems today are much faster than those in the  1930s, the large scale data is a strain to analyze by the computers we have today. 

------------------- Sentence 1 -------------------

Introduction As the information technology spreads fast, most of the data were born digital as well  as exchanged on internet today.

>> Tokens are: 
 ['Introduction', 'As', 'information', 'technology', 'spreads', 'fast', ',', 'data', 'born', 'digital', 'well', 'exchanged', 'internet', 'today', '.']

>> Bigrams are: 
 [('Introduction', 'As'), ('As', 'information'), ('information', 'technology'), ('technology', 'spreads'), ('spreads', 'fast'), ('fast', ','), (',', 'data'), ('data', 'born'), ('born', 'digital'), ('digital', 'well'), ('well', 'exchanged'), ('exchanged', 'internet'), ('internet', 'today'), ('today', '.')]

>> Trigrams are: 
 [('Introduction', 'As', 'information'), ('As', 'information', 'technology'), ('information', 'technology', 'spreads'), ('technology', 'spreads', 'fast'), ('spreads', 'fast', ','), ('fast', ',', 'data'), (',', 'data', 'born'), ('data', 'born', 'digital'), ('born', 'digital', 'well'), ('digital', 'well', 'exchanged'), ('well', 'exchanged', 'internet'), ('exchanged', 'internet', 'today'), ('internet', 'today', '.')]

>> POS Tags are: 
 [('Introduction', 'NNP'), ('As', 'IN'), ('information', 'NN'), ('technology', 'NN'), ('spreads', 'VBZ'), ('fast', 'RB'), (',', ','), ('data', 'NNS'), ('born', 'VBP'), ('digital', 'JJ'), ('well', 'RB'), ('exchanged', 'VBN'), ('internet', 'NN'), ('today', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Introduction', 'information technology', 'data', 'internet today']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Introduction', 'introduct'), ('As', 'as'), ('information', 'inform'), ('technology', 'technolog'), ('spreads', 'spread'), ('fast', 'fast'), (',', ','), ('data', 'data'), ('born', 'born'), ('digital', 'digit'), ('well', 'well'), ('exchanged', 'exchang'), ('internet', 'internet'), ('today', 'today'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Introduction', 'introduct'), ('As', 'as'), ('information', 'inform'), ('technology', 'technolog'), ('spreads', 'spread'), ('fast', 'fast'), (',', ','), ('data', 'data'), ('born', 'born'), ('digital', 'digit'), ('well', 'well'), ('exchanged', 'exchang'), ('internet', 'internet'), ('today', 'today'), ('.', '.')]

>> Lemmatization: 
 [('Introduction', 'Introduction'), ('As', 'As'), ('information', 'information'), ('technology', 'technology'), ('spreads', 'spread'), ('fast', 'fast'), (',', ','), ('data', 'data'), ('born', 'born'), ('digital', 'digital'), ('well', 'well'), ('exchanged', 'exchanged'), ('internet', 'internet'), ('today', 'today'), ('.', '.')]


------------------- Sentence 2 -------------------

According to the estimation of Lyman and Varian [1],  the new data stored in digital media devices have already been more than 92 % in 2002,  while the size of these new data was also more than five exabytes.

>> Tokens are: 
 ['According', 'estimation', 'Lyman', 'Varian', '[', '1', ']', ',', 'new', 'data', 'stored', 'digital', 'media', 'devices', 'already', '92', '%', '2002', ',', 'size', 'new', 'data', 'also', 'five', 'exabytes', '.']

>> Bigrams are: 
 [('According', 'estimation'), ('estimation', 'Lyman'), ('Lyman', 'Varian'), ('Varian', '['), ('[', '1'), ('1', ']'), (']', ','), (',', 'new'), ('new', 'data'), ('data', 'stored'), ('stored', 'digital'), ('digital', 'media'), ('media', 'devices'), ('devices', 'already'), ('already', '92'), ('92', '%'), ('%', '2002'), ('2002', ','), (',', 'size'), ('size', 'new'), ('new', 'data'), ('data', 'also'), ('also', 'five'), ('five', 'exabytes'), ('exabytes', '.')]

>> Trigrams are: 
 [('According', 'estimation', 'Lyman'), ('estimation', 'Lyman', 'Varian'), ('Lyman', 'Varian', '['), ('Varian', '[', '1'), ('[', '1', ']'), ('1', ']', ','), (']', ',', 'new'), (',', 'new', 'data'), ('new', 'data', 'stored'), ('data', 'stored', 'digital'), ('stored', 'digital', 'media'), ('digital', 'media', 'devices'), ('media', 'devices', 'already'), ('devices', 'already', '92'), ('already', '92', '%'), ('92', '%', '2002'), ('%', '2002', ','), ('2002', ',', 'size'), (',', 'size', 'new'), ('size', 'new', 'data'), ('new', 'data', 'also'), ('data', 'also', 'five'), ('also', 'five', 'exabytes'), ('five', 'exabytes', '.')]

>> POS Tags are: 
 [('According', 'VBG'), ('estimation', 'NN'), ('Lyman', 'NNP'), ('Varian', 'NNP'), ('[', 'NNP'), ('1', 'CD'), (']', 'NNP'), (',', ','), ('new', 'JJ'), ('data', 'NNS'), ('stored', 'VBD'), ('digital', 'JJ'), ('media', 'NNS'), ('devices', 'NNS'), ('already', 'RB'), ('92', 'CD'), ('%', 'NN'), ('2002', 'CD'), (',', ','), ('size', 'NN'), ('new', 'JJ'), ('data', 'NNS'), ('also', 'RB'), ('five', 'CD'), ('exabytes', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['estimation Lyman Varian [', ']', 'new data', 'digital media devices', '%', 'size', 'new data', 'exabytes']

>> Named Entities are: 
 [('PERSON', 'Lyman Varian')] 

>> Stemming using Porter Stemmer: 
 [('According', 'accord'), ('estimation', 'estim'), ('Lyman', 'lyman'), ('Varian', 'varian'), ('[', '['), ('1', '1'), (']', ']'), (',', ','), ('new', 'new'), ('data', 'data'), ('stored', 'store'), ('digital', 'digit'), ('media', 'media'), ('devices', 'devic'), ('already', 'alreadi'), ('92', '92'), ('%', '%'), ('2002', '2002'), (',', ','), ('size', 'size'), ('new', 'new'), ('data', 'data'), ('also', 'also'), ('five', 'five'), ('exabytes', 'exabyt'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('According', 'accord'), ('estimation', 'estim'), ('Lyman', 'lyman'), ('Varian', 'varian'), ('[', '['), ('1', '1'), (']', ']'), (',', ','), ('new', 'new'), ('data', 'data'), ('stored', 'store'), ('digital', 'digit'), ('media', 'media'), ('devices', 'devic'), ('already', 'alreadi'), ('92', '92'), ('%', '%'), ('2002', '2002'), (',', ','), ('size', 'size'), ('new', 'new'), ('data', 'data'), ('also', 'also'), ('five', 'five'), ('exabytes', 'exabyt'), ('.', '.')]

>> Lemmatization: 
 [('According', 'According'), ('estimation', 'estimation'), ('Lyman', 'Lyman'), ('Varian', 'Varian'), ('[', '['), ('1', '1'), (']', ']'), (',', ','), ('new', 'new'), ('data', 'data'), ('stored', 'stored'), ('digital', 'digital'), ('media', 'medium'), ('devices', 'device'), ('already', 'already'), ('92', '92'), ('%', '%'), ('2002', '2002'), (',', ','), ('size', 'size'), ('new', 'new'), ('data', 'data'), ('also', 'also'), ('five', 'five'), ('exabytes', 'exabyte'), ('.', '.')]


------------------- Sentence 3 -------------------

In fact, the problems  of analyzing the large scale data were not suddenly occurred but have been there for sev- eral years because the creation of data is usually much easier than finding useful things  from the data.

>> Tokens are: 
 ['In', 'fact', ',', 'problems', 'analyzing', 'large', 'scale', 'data', 'suddenly', 'occurred', 'sev-', 'eral', 'years', 'creation', 'data', 'usually', 'much', 'easier', 'finding', 'useful', 'things', 'data', '.']

>> Bigrams are: 
 [('In', 'fact'), ('fact', ','), (',', 'problems'), ('problems', 'analyzing'), ('analyzing', 'large'), ('large', 'scale'), ('scale', 'data'), ('data', 'suddenly'), ('suddenly', 'occurred'), ('occurred', 'sev-'), ('sev-', 'eral'), ('eral', 'years'), ('years', 'creation'), ('creation', 'data'), ('data', 'usually'), ('usually', 'much'), ('much', 'easier'), ('easier', 'finding'), ('finding', 'useful'), ('useful', 'things'), ('things', 'data'), ('data', '.')]

>> Trigrams are: 
 [('In', 'fact', ','), ('fact', ',', 'problems'), (',', 'problems', 'analyzing'), ('problems', 'analyzing', 'large'), ('analyzing', 'large', 'scale'), ('large', 'scale', 'data'), ('scale', 'data', 'suddenly'), ('data', 'suddenly', 'occurred'), ('suddenly', 'occurred', 'sev-'), ('occurred', 'sev-', 'eral'), ('sev-', 'eral', 'years'), ('eral', 'years', 'creation'), ('years', 'creation', 'data'), ('creation', 'data', 'usually'), ('data', 'usually', 'much'), ('usually', 'much', 'easier'), ('much', 'easier', 'finding'), ('easier', 'finding', 'useful'), ('finding', 'useful', 'things'), ('useful', 'things', 'data'), ('things', 'data', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('fact', 'NN'), (',', ','), ('problems', 'NNS'), ('analyzing', 'VBG'), ('large', 'JJ'), ('scale', 'NN'), ('data', 'NNS'), ('suddenly', 'RB'), ('occurred', 'VBD'), ('sev-', 'JJ'), ('eral', 'JJ'), ('years', 'NNS'), ('creation', 'NN'), ('data', 'NNS'), ('usually', 'RB'), ('much', 'RB'), ('easier', 'JJR'), ('finding', 'VBG'), ('useful', 'JJ'), ('things', 'NNS'), ('data', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['fact', 'problems', 'large scale data', 'sev- eral years creation data', 'useful things data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('fact', 'fact'), (',', ','), ('problems', 'problem'), ('analyzing', 'analyz'), ('large', 'larg'), ('scale', 'scale'), ('data', 'data'), ('suddenly', 'suddenli'), ('occurred', 'occur'), ('sev-', 'sev-'), ('eral', 'eral'), ('years', 'year'), ('creation', 'creation'), ('data', 'data'), ('usually', 'usual'), ('much', 'much'), ('easier', 'easier'), ('finding', 'find'), ('useful', 'use'), ('things', 'thing'), ('data', 'data'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('fact', 'fact'), (',', ','), ('problems', 'problem'), ('analyzing', 'analyz'), ('large', 'larg'), ('scale', 'scale'), ('data', 'data'), ('suddenly', 'sudden'), ('occurred', 'occur'), ('sev-', 'sev-'), ('eral', 'eral'), ('years', 'year'), ('creation', 'creation'), ('data', 'data'), ('usually', 'usual'), ('much', 'much'), ('easier', 'easier'), ('finding', 'find'), ('useful', 'use'), ('things', 'thing'), ('data', 'data'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('fact', 'fact'), (',', ','), ('problems', 'problem'), ('analyzing', 'analyzing'), ('large', 'large'), ('scale', 'scale'), ('data', 'data'), ('suddenly', 'suddenly'), ('occurred', 'occurred'), ('sev-', 'sev-'), ('eral', 'eral'), ('years', 'year'), ('creation', 'creation'), ('data', 'data'), ('usually', 'usually'), ('much', 'much'), ('easier', 'easier'), ('finding', 'finding'), ('useful', 'useful'), ('things', 'thing'), ('data', 'data'), ('.', '.')]


------------------- Sentence 4 -------------------

Even though computer systems today are much faster than those in the  1930s, the large scale data is a strain to analyze by the computers we have today.

>> Tokens are: 
 ['Even', 'though', 'computer', 'systems', 'today', 'much', 'faster', '1930s', ',', 'large', 'scale', 'data', 'strain', 'analyze', 'computers', 'today', '.']

>> Bigrams are: 
 [('Even', 'though'), ('though', 'computer'), ('computer', 'systems'), ('systems', 'today'), ('today', 'much'), ('much', 'faster'), ('faster', '1930s'), ('1930s', ','), (',', 'large'), ('large', 'scale'), ('scale', 'data'), ('data', 'strain'), ('strain', 'analyze'), ('analyze', 'computers'), ('computers', 'today'), ('today', '.')]

>> Trigrams are: 
 [('Even', 'though', 'computer'), ('though', 'computer', 'systems'), ('computer', 'systems', 'today'), ('systems', 'today', 'much'), ('today', 'much', 'faster'), ('much', 'faster', '1930s'), ('faster', '1930s', ','), ('1930s', ',', 'large'), (',', 'large', 'scale'), ('large', 'scale', 'data'), ('scale', 'data', 'strain'), ('data', 'strain', 'analyze'), ('strain', 'analyze', 'computers'), ('analyze', 'computers', 'today'), ('computers', 'today', '.')]

>> POS Tags are: 
 [('Even', 'RB'), ('though', 'IN'), ('computer', 'NN'), ('systems', 'NNS'), ('today', 'NN'), ('much', 'JJ'), ('faster', 'JJR'), ('1930s', 'CD'), (',', ','), ('large', 'JJ'), ('scale', 'NN'), ('data', 'NNS'), ('strain', 'NN'), ('analyze', 'IN'), ('computers', 'NNS'), ('today', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['computer systems today', 'large scale data strain', 'computers today']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Even', 'even'), ('though', 'though'), ('computer', 'comput'), ('systems', 'system'), ('today', 'today'), ('much', 'much'), ('faster', 'faster'), ('1930s', '1930'), (',', ','), ('large', 'larg'), ('scale', 'scale'), ('data', 'data'), ('strain', 'strain'), ('analyze', 'analyz'), ('computers', 'comput'), ('today', 'today'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Even', 'even'), ('though', 'though'), ('computer', 'comput'), ('systems', 'system'), ('today', 'today'), ('much', 'much'), ('faster', 'faster'), ('1930s', '1930s'), (',', ','), ('large', 'larg'), ('scale', 'scale'), ('data', 'data'), ('strain', 'strain'), ('analyze', 'analyz'), ('computers', 'comput'), ('today', 'today'), ('.', '.')]

>> Lemmatization: 
 [('Even', 'Even'), ('though', 'though'), ('computer', 'computer'), ('systems', 'system'), ('today', 'today'), ('much', 'much'), ('faster', 'faster'), ('1930s', '1930s'), (',', ','), ('large', 'large'), ('scale', 'scale'), ('data', 'data'), ('strain', 'strain'), ('analyze', 'analyze'), ('computers', 'computer'), ('today', 'today'), ('.', '.')]



========================================== PARAGRAPH 3 ===========================================

In response to the problems of analyzing large-scale data, quite a few efficient meth- ods [2], such as sampling, data condensation, density-based approaches, grid-based  approaches, divide and conquer, incremental learning, and distributed computing, have  been presented. Of course, these methods are constantly used to improve the perfor- mance of the operators of data analytics process.1 The results of these methods illustrate  that with the efficient methods at hand, we may be able to analyze the large-scale data in  a reasonable time. The dimensional reduction method (e.g.-, principal components analy- sis; PCA [3]) is a typical example that is aimed at reducing the input data volume to  accelerate the process of data analytics. Another reduction method that reduces the data  computations of data clustering is sampling [4], which can also be used to speed up the  computation time of data analytics. 

------------------- Sentence 1 -------------------

In response to the problems of analyzing large-scale data, quite a few efficient meth- ods [2], such as sampling, data condensation, density-based approaches, grid-based  approaches, divide and conquer, incremental learning, and distributed computing, have  been presented.

>> Tokens are: 
 ['In', 'response', 'problems', 'analyzing', 'large-scale', 'data', ',', 'quite', 'efficient', 'meth-', 'ods', '[', '2', ']', ',', 'sampling', ',', 'data', 'condensation', ',', 'density-based', 'approaches', ',', 'grid-based', 'approaches', ',', 'divide', 'conquer', ',', 'incremental', 'learning', ',', 'distributed', 'computing', ',', 'presented', '.']

>> Bigrams are: 
 [('In', 'response'), ('response', 'problems'), ('problems', 'analyzing'), ('analyzing', 'large-scale'), ('large-scale', 'data'), ('data', ','), (',', 'quite'), ('quite', 'efficient'), ('efficient', 'meth-'), ('meth-', 'ods'), ('ods', '['), ('[', '2'), ('2', ']'), (']', ','), (',', 'sampling'), ('sampling', ','), (',', 'data'), ('data', 'condensation'), ('condensation', ','), (',', 'density-based'), ('density-based', 'approaches'), ('approaches', ','), (',', 'grid-based'), ('grid-based', 'approaches'), ('approaches', ','), (',', 'divide'), ('divide', 'conquer'), ('conquer', ','), (',', 'incremental'), ('incremental', 'learning'), ('learning', ','), (',', 'distributed'), ('distributed', 'computing'), ('computing', ','), (',', 'presented'), ('presented', '.')]

>> Trigrams are: 
 [('In', 'response', 'problems'), ('response', 'problems', 'analyzing'), ('problems', 'analyzing', 'large-scale'), ('analyzing', 'large-scale', 'data'), ('large-scale', 'data', ','), ('data', ',', 'quite'), (',', 'quite', 'efficient'), ('quite', 'efficient', 'meth-'), ('efficient', 'meth-', 'ods'), ('meth-', 'ods', '['), ('ods', '[', '2'), ('[', '2', ']'), ('2', ']', ','), (']', ',', 'sampling'), (',', 'sampling', ','), ('sampling', ',', 'data'), (',', 'data', 'condensation'), ('data', 'condensation', ','), ('condensation', ',', 'density-based'), (',', 'density-based', 'approaches'), ('density-based', 'approaches', ','), ('approaches', ',', 'grid-based'), (',', 'grid-based', 'approaches'), ('grid-based', 'approaches', ','), ('approaches', ',', 'divide'), (',', 'divide', 'conquer'), ('divide', 'conquer', ','), ('conquer', ',', 'incremental'), (',', 'incremental', 'learning'), ('incremental', 'learning', ','), ('learning', ',', 'distributed'), (',', 'distributed', 'computing'), ('distributed', 'computing', ','), ('computing', ',', 'presented'), (',', 'presented', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('response', 'NN'), ('problems', 'NNS'), ('analyzing', 'VBG'), ('large-scale', 'JJ'), ('data', 'NNS'), (',', ','), ('quite', 'RB'), ('efficient', 'JJ'), ('meth-', 'JJ'), ('ods', 'NNS'), ('[', '$'), ('2', 'CD'), (']', 'NNP'), (',', ','), ('sampling', 'VBG'), (',', ','), ('data', 'NNS'), ('condensation', 'NN'), (',', ','), ('density-based', 'JJ'), ('approaches', 'NNS'), (',', ','), ('grid-based', 'JJ'), ('approaches', 'NNS'), (',', ','), ('divide', 'JJ'), ('conquer', 'NN'), (',', ','), ('incremental', 'JJ'), ('learning', 'NN'), (',', ','), ('distributed', 'VBD'), ('computing', 'NN'), (',', ','), ('presented', 'VBN'), ('.', '.')]

>> Noun Phrases are: 
 ['response problems', 'large-scale data', 'efficient meth- ods', ']', 'data condensation', 'density-based approaches', 'grid-based approaches', 'divide conquer', 'incremental learning', 'computing']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('response', 'respons'), ('problems', 'problem'), ('analyzing', 'analyz'), ('large-scale', 'large-scal'), ('data', 'data'), (',', ','), ('quite', 'quit'), ('efficient', 'effici'), ('meth-', 'meth-'), ('ods', 'od'), ('[', '['), ('2', '2'), (']', ']'), (',', ','), ('sampling', 'sampl'), (',', ','), ('data', 'data'), ('condensation', 'condens'), (',', ','), ('density-based', 'density-bas'), ('approaches', 'approach'), (',', ','), ('grid-based', 'grid-bas'), ('approaches', 'approach'), (',', ','), ('divide', 'divid'), ('conquer', 'conquer'), (',', ','), ('incremental', 'increment'), ('learning', 'learn'), (',', ','), ('distributed', 'distribut'), ('computing', 'comput'), (',', ','), ('presented', 'present'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('response', 'respons'), ('problems', 'problem'), ('analyzing', 'analyz'), ('large-scale', 'large-scal'), ('data', 'data'), (',', ','), ('quite', 'quit'), ('efficient', 'effici'), ('meth-', 'meth-'), ('ods', 'od'), ('[', '['), ('2', '2'), (']', ']'), (',', ','), ('sampling', 'sampl'), (',', ','), ('data', 'data'), ('condensation', 'condens'), (',', ','), ('density-based', 'density-bas'), ('approaches', 'approach'), (',', ','), ('grid-based', 'grid-bas'), ('approaches', 'approach'), (',', ','), ('divide', 'divid'), ('conquer', 'conquer'), (',', ','), ('incremental', 'increment'), ('learning', 'learn'), (',', ','), ('distributed', 'distribut'), ('computing', 'comput'), (',', ','), ('presented', 'present'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('response', 'response'), ('problems', 'problem'), ('analyzing', 'analyzing'), ('large-scale', 'large-scale'), ('data', 'data'), (',', ','), ('quite', 'quite'), ('efficient', 'efficient'), ('meth-', 'meth-'), ('ods', 'od'), ('[', '['), ('2', '2'), (']', ']'), (',', ','), ('sampling', 'sampling'), (',', ','), ('data', 'data'), ('condensation', 'condensation'), (',', ','), ('density-based', 'density-based'), ('approaches', 'approach'), (',', ','), ('grid-based', 'grid-based'), ('approaches', 'approach'), (',', ','), ('divide', 'divide'), ('conquer', 'conquer'), (',', ','), ('incremental', 'incremental'), ('learning', 'learning'), (',', ','), ('distributed', 'distributed'), ('computing', 'computing'), (',', ','), ('presented', 'presented'), ('.', '.')]


------------------- Sentence 2 -------------------

Of course, these methods are constantly used to improve the perfor- mance of the operators of data analytics process.1 The results of these methods illustrate  that with the efficient methods at hand, we may be able to analyze the large-scale data in  a reasonable time.

>> Tokens are: 
 ['Of', 'course', ',', 'methods', 'constantly', 'used', 'improve', 'perfor-', 'mance', 'operators', 'data', 'analytics', 'process.1', 'The', 'results', 'methods', 'illustrate', 'efficient', 'methods', 'hand', ',', 'may', 'able', 'analyze', 'large-scale', 'data', 'reasonable', 'time', '.']

>> Bigrams are: 
 [('Of', 'course'), ('course', ','), (',', 'methods'), ('methods', 'constantly'), ('constantly', 'used'), ('used', 'improve'), ('improve', 'perfor-'), ('perfor-', 'mance'), ('mance', 'operators'), ('operators', 'data'), ('data', 'analytics'), ('analytics', 'process.1'), ('process.1', 'The'), ('The', 'results'), ('results', 'methods'), ('methods', 'illustrate'), ('illustrate', 'efficient'), ('efficient', 'methods'), ('methods', 'hand'), ('hand', ','), (',', 'may'), ('may', 'able'), ('able', 'analyze'), ('analyze', 'large-scale'), ('large-scale', 'data'), ('data', 'reasonable'), ('reasonable', 'time'), ('time', '.')]

>> Trigrams are: 
 [('Of', 'course', ','), ('course', ',', 'methods'), (',', 'methods', 'constantly'), ('methods', 'constantly', 'used'), ('constantly', 'used', 'improve'), ('used', 'improve', 'perfor-'), ('improve', 'perfor-', 'mance'), ('perfor-', 'mance', 'operators'), ('mance', 'operators', 'data'), ('operators', 'data', 'analytics'), ('data', 'analytics', 'process.1'), ('analytics', 'process.1', 'The'), ('process.1', 'The', 'results'), ('The', 'results', 'methods'), ('results', 'methods', 'illustrate'), ('methods', 'illustrate', 'efficient'), ('illustrate', 'efficient', 'methods'), ('efficient', 'methods', 'hand'), ('methods', 'hand', ','), ('hand', ',', 'may'), (',', 'may', 'able'), ('may', 'able', 'analyze'), ('able', 'analyze', 'large-scale'), ('analyze', 'large-scale', 'data'), ('large-scale', 'data', 'reasonable'), ('data', 'reasonable', 'time'), ('reasonable', 'time', '.')]

>> POS Tags are: 
 [('Of', 'IN'), ('course', 'NN'), (',', ','), ('methods', 'NNS'), ('constantly', 'RB'), ('used', 'VBN'), ('improve', 'VB'), ('perfor-', 'JJ'), ('mance', 'NN'), ('operators', 'NNS'), ('data', 'VBP'), ('analytics', 'NNS'), ('process.1', 'VBP'), ('The', 'DT'), ('results', 'NNS'), ('methods', 'NNS'), ('illustrate', 'VBP'), ('efficient', 'JJ'), ('methods', 'NNS'), ('hand', 'NN'), (',', ','), ('may', 'MD'), ('able', 'JJ'), ('analyze', 'VB'), ('large-scale', 'JJ'), ('data', 'NNS'), ('reasonable', 'JJ'), ('time', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['course', 'methods', 'perfor- mance operators', 'analytics', 'The results methods', 'efficient methods hand', 'large-scale data', 'reasonable time']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Of', 'of'), ('course', 'cours'), (',', ','), ('methods', 'method'), ('constantly', 'constantli'), ('used', 'use'), ('improve', 'improv'), ('perfor-', 'perfor-'), ('mance', 'manc'), ('operators', 'oper'), ('data', 'data'), ('analytics', 'analyt'), ('process.1', 'process.1'), ('The', 'the'), ('results', 'result'), ('methods', 'method'), ('illustrate', 'illustr'), ('efficient', 'effici'), ('methods', 'method'), ('hand', 'hand'), (',', ','), ('may', 'may'), ('able', 'abl'), ('analyze', 'analyz'), ('large-scale', 'large-scal'), ('data', 'data'), ('reasonable', 'reason'), ('time', 'time'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Of', 'of'), ('course', 'cours'), (',', ','), ('methods', 'method'), ('constantly', 'constant'), ('used', 'use'), ('improve', 'improv'), ('perfor-', 'perfor-'), ('mance', 'manc'), ('operators', 'oper'), ('data', 'data'), ('analytics', 'analyt'), ('process.1', 'process.1'), ('The', 'the'), ('results', 'result'), ('methods', 'method'), ('illustrate', 'illustr'), ('efficient', 'effici'), ('methods', 'method'), ('hand', 'hand'), (',', ','), ('may', 'may'), ('able', 'abl'), ('analyze', 'analyz'), ('large-scale', 'large-scal'), ('data', 'data'), ('reasonable', 'reason'), ('time', 'time'), ('.', '.')]

>> Lemmatization: 
 [('Of', 'Of'), ('course', 'course'), (',', ','), ('methods', 'method'), ('constantly', 'constantly'), ('used', 'used'), ('improve', 'improve'), ('perfor-', 'perfor-'), ('mance', 'mance'), ('operators', 'operator'), ('data', 'data'), ('analytics', 'analytics'), ('process.1', 'process.1'), ('The', 'The'), ('results', 'result'), ('methods', 'method'), ('illustrate', 'illustrate'), ('efficient', 'efficient'), ('methods', 'method'), ('hand', 'hand'), (',', ','), ('may', 'may'), ('able', 'able'), ('analyze', 'analyze'), ('large-scale', 'large-scale'), ('data', 'data'), ('reasonable', 'reasonable'), ('time', 'time'), ('.', '.')]


------------------- Sentence 3 -------------------

The dimensional reduction method (e.g.-, principal components analy- sis; PCA [3]) is a typical example that is aimed at reducing the input data volume to  accelerate the process of data analytics.

>> Tokens are: 
 ['The', 'dimensional', 'reduction', 'method', '(', 'e.g.-', ',', 'principal', 'components', 'analy-', 'sis', ';', 'PCA', '[', '3', ']', ')', 'typical', 'example', 'aimed', 'reducing', 'input', 'data', 'volume', 'accelerate', 'process', 'data', 'analytics', '.']

>> Bigrams are: 
 [('The', 'dimensional'), ('dimensional', 'reduction'), ('reduction', 'method'), ('method', '('), ('(', 'e.g.-'), ('e.g.-', ','), (',', 'principal'), ('principal', 'components'), ('components', 'analy-'), ('analy-', 'sis'), ('sis', ';'), (';', 'PCA'), ('PCA', '['), ('[', '3'), ('3', ']'), (']', ')'), (')', 'typical'), ('typical', 'example'), ('example', 'aimed'), ('aimed', 'reducing'), ('reducing', 'input'), ('input', 'data'), ('data', 'volume'), ('volume', 'accelerate'), ('accelerate', 'process'), ('process', 'data'), ('data', 'analytics'), ('analytics', '.')]

>> Trigrams are: 
 [('The', 'dimensional', 'reduction'), ('dimensional', 'reduction', 'method'), ('reduction', 'method', '('), ('method', '(', 'e.g.-'), ('(', 'e.g.-', ','), ('e.g.-', ',', 'principal'), (',', 'principal', 'components'), ('principal', 'components', 'analy-'), ('components', 'analy-', 'sis'), ('analy-', 'sis', ';'), ('sis', ';', 'PCA'), (';', 'PCA', '['), ('PCA', '[', '3'), ('[', '3', ']'), ('3', ']', ')'), (']', ')', 'typical'), (')', 'typical', 'example'), ('typical', 'example', 'aimed'), ('example', 'aimed', 'reducing'), ('aimed', 'reducing', 'input'), ('reducing', 'input', 'data'), ('input', 'data', 'volume'), ('data', 'volume', 'accelerate'), ('volume', 'accelerate', 'process'), ('accelerate', 'process', 'data'), ('process', 'data', 'analytics'), ('data', 'analytics', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('dimensional', 'JJ'), ('reduction', 'NN'), ('method', 'NN'), ('(', '('), ('e.g.-', 'JJ'), (',', ','), ('principal', 'JJ'), ('components', 'NNS'), ('analy-', 'JJ'), ('sis', 'NN'), (';', ':'), ('PCA', 'NNP'), ('[', 'VBD'), ('3', 'CD'), (']', 'NN'), (')', ')'), ('typical', 'JJ'), ('example', 'NN'), ('aimed', 'VBN'), ('reducing', 'VBG'), ('input', 'NN'), ('data', 'NNS'), ('volume', 'NN'), ('accelerate', 'VBP'), ('process', 'NN'), ('data', 'NNS'), ('analytics', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['The dimensional reduction method', 'principal components', 'analy- sis', 'PCA', ']', 'typical example', 'input data volume', 'process data analytics']

>> Named Entities are: 
 [('ORGANIZATION', 'PCA')] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('dimensional', 'dimension'), ('reduction', 'reduct'), ('method', 'method'), ('(', '('), ('e.g.-', 'e.g.-'), (',', ','), ('principal', 'princip'), ('components', 'compon'), ('analy-', 'analy-'), ('sis', 'si'), (';', ';'), ('PCA', 'pca'), ('[', '['), ('3', '3'), (']', ']'), (')', ')'), ('typical', 'typic'), ('example', 'exampl'), ('aimed', 'aim'), ('reducing', 'reduc'), ('input', 'input'), ('data', 'data'), ('volume', 'volum'), ('accelerate', 'acceler'), ('process', 'process'), ('data', 'data'), ('analytics', 'analyt'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('dimensional', 'dimension'), ('reduction', 'reduct'), ('method', 'method'), ('(', '('), ('e.g.-', 'e.g.-'), (',', ','), ('principal', 'princip'), ('components', 'compon'), ('analy-', 'analy-'), ('sis', 'sis'), (';', ';'), ('PCA', 'pca'), ('[', '['), ('3', '3'), (']', ']'), (')', ')'), ('typical', 'typic'), ('example', 'exampl'), ('aimed', 'aim'), ('reducing', 'reduc'), ('input', 'input'), ('data', 'data'), ('volume', 'volum'), ('accelerate', 'acceler'), ('process', 'process'), ('data', 'data'), ('analytics', 'analyt'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('dimensional', 'dimensional'), ('reduction', 'reduction'), ('method', 'method'), ('(', '('), ('e.g.-', 'e.g.-'), (',', ','), ('principal', 'principal'), ('components', 'component'), ('analy-', 'analy-'), ('sis', 'si'), (';', ';'), ('PCA', 'PCA'), ('[', '['), ('3', '3'), (']', ']'), (')', ')'), ('typical', 'typical'), ('example', 'example'), ('aimed', 'aimed'), ('reducing', 'reducing'), ('input', 'input'), ('data', 'data'), ('volume', 'volume'), ('accelerate', 'accelerate'), ('process', 'process'), ('data', 'data'), ('analytics', 'analytics'), ('.', '.')]


------------------- Sentence 4 -------------------

Another reduction method that reduces the data  computations of data clustering is sampling [4], which can also be used to speed up the  computation time of data analytics.

>> Tokens are: 
 ['Another', 'reduction', 'method', 'reduces', 'data', 'computations', 'data', 'clustering', 'sampling', '[', '4', ']', ',', 'also', 'used', 'speed', 'computation', 'time', 'data', 'analytics', '.']

>> Bigrams are: 
 [('Another', 'reduction'), ('reduction', 'method'), ('method', 'reduces'), ('reduces', 'data'), ('data', 'computations'), ('computations', 'data'), ('data', 'clustering'), ('clustering', 'sampling'), ('sampling', '['), ('[', '4'), ('4', ']'), (']', ','), (',', 'also'), ('also', 'used'), ('used', 'speed'), ('speed', 'computation'), ('computation', 'time'), ('time', 'data'), ('data', 'analytics'), ('analytics', '.')]

>> Trigrams are: 
 [('Another', 'reduction', 'method'), ('reduction', 'method', 'reduces'), ('method', 'reduces', 'data'), ('reduces', 'data', 'computations'), ('data', 'computations', 'data'), ('computations', 'data', 'clustering'), ('data', 'clustering', 'sampling'), ('clustering', 'sampling', '['), ('sampling', '[', '4'), ('[', '4', ']'), ('4', ']', ','), (']', ',', 'also'), (',', 'also', 'used'), ('also', 'used', 'speed'), ('used', 'speed', 'computation'), ('speed', 'computation', 'time'), ('computation', 'time', 'data'), ('time', 'data', 'analytics'), ('data', 'analytics', '.')]

>> POS Tags are: 
 [('Another', 'DT'), ('reduction', 'NN'), ('method', 'NN'), ('reduces', 'NNS'), ('data', 'VBP'), ('computations', 'NNS'), ('data', 'NNS'), ('clustering', 'VBG'), ('sampling', 'VBG'), ('[', 'JJ'), ('4', 'CD'), (']', 'NN'), (',', ','), ('also', 'RB'), ('used', 'VBD'), ('speed', 'NN'), ('computation', 'NN'), ('time', 'NN'), ('data', 'NNS'), ('analytics', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['Another reduction method reduces', 'computations data', ']', 'speed computation time data analytics']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Another', 'anoth'), ('reduction', 'reduct'), ('method', 'method'), ('reduces', 'reduc'), ('data', 'data'), ('computations', 'comput'), ('data', 'data'), ('clustering', 'cluster'), ('sampling', 'sampl'), ('[', '['), ('4', '4'), (']', ']'), (',', ','), ('also', 'also'), ('used', 'use'), ('speed', 'speed'), ('computation', 'comput'), ('time', 'time'), ('data', 'data'), ('analytics', 'analyt'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Another', 'anoth'), ('reduction', 'reduct'), ('method', 'method'), ('reduces', 'reduc'), ('data', 'data'), ('computations', 'comput'), ('data', 'data'), ('clustering', 'cluster'), ('sampling', 'sampl'), ('[', '['), ('4', '4'), (']', ']'), (',', ','), ('also', 'also'), ('used', 'use'), ('speed', 'speed'), ('computation', 'comput'), ('time', 'time'), ('data', 'data'), ('analytics', 'analyt'), ('.', '.')]

>> Lemmatization: 
 [('Another', 'Another'), ('reduction', 'reduction'), ('method', 'method'), ('reduces', 'reduces'), ('data', 'data'), ('computations', 'computation'), ('data', 'data'), ('clustering', 'clustering'), ('sampling', 'sampling'), ('[', '['), ('4', '4'), (']', ']'), (',', ','), ('also', 'also'), ('used', 'used'), ('speed', 'speed'), ('computation', 'computation'), ('time', 'time'), ('data', 'data'), ('analytics', 'analytics'), ('.', '.')]



========================================== PARAGRAPH 4 ===========================================

Although the advances of computer systems and internet technologies have witnessed  the development of computing hardware following the Moore’s law for several decades,  

------------------- Sentence 1 -------------------

Although the advances of computer systems and internet technologies have witnessed  the development of computing hardware following the Moore’s law for several decades,

>> Tokens are: 
 ['Although', 'advances', 'computer', 'systems', 'internet', 'technologies', 'witnessed', 'development', 'computing', 'hardware', 'following', 'Moore', '’', 'law', 'several', 'decades', ',']

>> Bigrams are: 
 [('Although', 'advances'), ('advances', 'computer'), ('computer', 'systems'), ('systems', 'internet'), ('internet', 'technologies'), ('technologies', 'witnessed'), ('witnessed', 'development'), ('development', 'computing'), ('computing', 'hardware'), ('hardware', 'following'), ('following', 'Moore'), ('Moore', '’'), ('’', 'law'), ('law', 'several'), ('several', 'decades'), ('decades', ',')]

>> Trigrams are: 
 [('Although', 'advances', 'computer'), ('advances', 'computer', 'systems'), ('computer', 'systems', 'internet'), ('systems', 'internet', 'technologies'), ('internet', 'technologies', 'witnessed'), ('technologies', 'witnessed', 'development'), ('witnessed', 'development', 'computing'), ('development', 'computing', 'hardware'), ('computing', 'hardware', 'following'), ('hardware', 'following', 'Moore'), ('following', 'Moore', '’'), ('Moore', '’', 'law'), ('’', 'law', 'several'), ('law', 'several', 'decades'), ('several', 'decades', ',')]

>> POS Tags are: 
 [('Although', 'IN'), ('advances', 'NNS'), ('computer', 'NN'), ('systems', 'NNS'), ('internet', 'JJ'), ('technologies', 'NNS'), ('witnessed', 'VBD'), ('development', 'NN'), ('computing', 'VBG'), ('hardware', 'NN'), ('following', 'VBG'), ('Moore', 'NNP'), ('’', 'NNP'), ('law', 'NN'), ('several', 'JJ'), ('decades', 'NNS'), (',', ',')]

>> Noun Phrases are: 
 ['advances computer systems', 'internet technologies', 'development', 'hardware', 'Moore ’ law', 'several decades']

>> Named Entities are: 
 [('PERSON', 'Moore')] 

>> Stemming using Porter Stemmer: 
 [('Although', 'although'), ('advances', 'advanc'), ('computer', 'comput'), ('systems', 'system'), ('internet', 'internet'), ('technologies', 'technolog'), ('witnessed', 'wit'), ('development', 'develop'), ('computing', 'comput'), ('hardware', 'hardwar'), ('following', 'follow'), ('Moore', 'moor'), ('’', '’'), ('law', 'law'), ('several', 'sever'), ('decades', 'decad'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('Although', 'although'), ('advances', 'advanc'), ('computer', 'comput'), ('systems', 'system'), ('internet', 'internet'), ('technologies', 'technolog'), ('witnessed', 'wit'), ('development', 'develop'), ('computing', 'comput'), ('hardware', 'hardwar'), ('following', 'follow'), ('Moore', 'moor'), ('’', '’'), ('law', 'law'), ('several', 'sever'), ('decades', 'decad'), (',', ',')]

>> Lemmatization: 
 [('Although', 'Although'), ('advances', 'advance'), ('computer', 'computer'), ('systems', 'system'), ('internet', 'internet'), ('technologies', 'technology'), ('witnessed', 'witnessed'), ('development', 'development'), ('computing', 'computing'), ('hardware', 'hardware'), ('following', 'following'), ('Moore', 'Moore'), ('’', '’'), ('law', 'law'), ('several', 'several'), ('decades', 'decade'), (',', ',')]



========================================== PARAGRAPH 5 ===========================================

1 In this paper, by the data analytics, we mean the whole KDD process, while by the data analysis, we mean the part of  data analytics that is aimed at finding the hidden information in the data, such as data mining. 

------------------- Sentence 1 -------------------

1 In this paper, by the data analytics, we mean the whole KDD process, while by the data analysis, we mean the part of  data analytics that is aimed at finding the hidden information in the data, such as data mining.

>> Tokens are: 
 ['1', 'In', 'paper', ',', 'data', 'analytics', ',', 'mean', 'whole', 'KDD', 'process', ',', 'data', 'analysis', ',', 'mean', 'part', 'data', 'analytics', 'aimed', 'finding', 'hidden', 'information', 'data', ',', 'data', 'mining', '.']

>> Bigrams are: 
 [('1', 'In'), ('In', 'paper'), ('paper', ','), (',', 'data'), ('data', 'analytics'), ('analytics', ','), (',', 'mean'), ('mean', 'whole'), ('whole', 'KDD'), ('KDD', 'process'), ('process', ','), (',', 'data'), ('data', 'analysis'), ('analysis', ','), (',', 'mean'), ('mean', 'part'), ('part', 'data'), ('data', 'analytics'), ('analytics', 'aimed'), ('aimed', 'finding'), ('finding', 'hidden'), ('hidden', 'information'), ('information', 'data'), ('data', ','), (',', 'data'), ('data', 'mining'), ('mining', '.')]

>> Trigrams are: 
 [('1', 'In', 'paper'), ('In', 'paper', ','), ('paper', ',', 'data'), (',', 'data', 'analytics'), ('data', 'analytics', ','), ('analytics', ',', 'mean'), (',', 'mean', 'whole'), ('mean', 'whole', 'KDD'), ('whole', 'KDD', 'process'), ('KDD', 'process', ','), ('process', ',', 'data'), (',', 'data', 'analysis'), ('data', 'analysis', ','), ('analysis', ',', 'mean'), (',', 'mean', 'part'), ('mean', 'part', 'data'), ('part', 'data', 'analytics'), ('data', 'analytics', 'aimed'), ('analytics', 'aimed', 'finding'), ('aimed', 'finding', 'hidden'), ('finding', 'hidden', 'information'), ('hidden', 'information', 'data'), ('information', 'data', ','), ('data', ',', 'data'), (',', 'data', 'mining'), ('data', 'mining', '.')]

>> POS Tags are: 
 [('1', 'CD'), ('In', 'IN'), ('paper', 'NN'), (',', ','), ('data', 'NNS'), ('analytics', 'NNS'), (',', ','), ('mean', 'JJ'), ('whole', 'JJ'), ('KDD', 'NNP'), ('process', 'NN'), (',', ','), ('data', 'NN'), ('analysis', 'NN'), (',', ','), ('mean', 'JJ'), ('part', 'NN'), ('data', 'NNS'), ('analytics', 'NNS'), ('aimed', 'VBD'), ('finding', 'VBG'), ('hidden', 'JJ'), ('information', 'NN'), ('data', 'NNS'), (',', ','), ('data', 'NNS'), ('mining', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['paper', 'data analytics', 'mean whole KDD process', 'data analysis', 'mean part data analytics', 'hidden information data', 'data mining']

>> Named Entities are: 
 [('ORGANIZATION', 'KDD')] 

>> Stemming using Porter Stemmer: 
 [('1', '1'), ('In', 'in'), ('paper', 'paper'), (',', ','), ('data', 'data'), ('analytics', 'analyt'), (',', ','), ('mean', 'mean'), ('whole', 'whole'), ('KDD', 'kdd'), ('process', 'process'), (',', ','), ('data', 'data'), ('analysis', 'analysi'), (',', ','), ('mean', 'mean'), ('part', 'part'), ('data', 'data'), ('analytics', 'analyt'), ('aimed', 'aim'), ('finding', 'find'), ('hidden', 'hidden'), ('information', 'inform'), ('data', 'data'), (',', ','), ('data', 'data'), ('mining', 'mine'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('1', '1'), ('In', 'in'), ('paper', 'paper'), (',', ','), ('data', 'data'), ('analytics', 'analyt'), (',', ','), ('mean', 'mean'), ('whole', 'whole'), ('KDD', 'kdd'), ('process', 'process'), (',', ','), ('data', 'data'), ('analysis', 'analysi'), (',', ','), ('mean', 'mean'), ('part', 'part'), ('data', 'data'), ('analytics', 'analyt'), ('aimed', 'aim'), ('finding', 'find'), ('hidden', 'hidden'), ('information', 'inform'), ('data', 'data'), (',', ','), ('data', 'data'), ('mining', 'mine'), ('.', '.')]

>> Lemmatization: 
 [('1', '1'), ('In', 'In'), ('paper', 'paper'), (',', ','), ('data', 'data'), ('analytics', 'analytics'), (',', ','), ('mean', 'mean'), ('whole', 'whole'), ('KDD', 'KDD'), ('process', 'process'), (',', ','), ('data', 'data'), ('analysis', 'analysis'), (',', ','), ('mean', 'mean'), ('part', 'part'), ('data', 'data'), ('analytics', 'analytics'), ('aimed', 'aimed'), ('finding', 'finding'), ('hidden', 'hidden'), ('information', 'information'), ('data', 'data'), (',', ','), ('data', 'data'), ('mining', 'mining'), ('.', '.')]



========================================== PARAGRAPH 6 ===========================================

Abstract  The age of big data is now coming. But the traditional data analytics may not be able  to handle such large quantities of data. The question that arises now is, how to develop  a high performance platform to efficiently analyze big data and how to design an  appropriate mining algorithm to find the useful things from big data. To deeply discuss  this issue, this paper begins with a brief introduction to data analytics, followed by the  discussions of big data analytics. Some important open issues and further research  directions will also be presented for the next step of big data analytics. 

------------------- Sentence 1 -------------------

Abstract  The age of big data is now coming.

>> Tokens are: 
 ['Abstract', 'The', 'age', 'big', 'data', 'coming', '.']

>> Bigrams are: 
 [('Abstract', 'The'), ('The', 'age'), ('age', 'big'), ('big', 'data'), ('data', 'coming'), ('coming', '.')]

>> Trigrams are: 
 [('Abstract', 'The', 'age'), ('The', 'age', 'big'), ('age', 'big', 'data'), ('big', 'data', 'coming'), ('data', 'coming', '.')]

>> POS Tags are: 
 [('Abstract', 'VB'), ('The', 'DT'), ('age', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('coming', 'VBG'), ('.', '.')]

>> Noun Phrases are: 
 ['The age', 'big data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Abstract', 'abstract'), ('The', 'the'), ('age', 'age'), ('big', 'big'), ('data', 'data'), ('coming', 'come'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Abstract', 'abstract'), ('The', 'the'), ('age', 'age'), ('big', 'big'), ('data', 'data'), ('coming', 'come'), ('.', '.')]

>> Lemmatization: 
 [('Abstract', 'Abstract'), ('The', 'The'), ('age', 'age'), ('big', 'big'), ('data', 'data'), ('coming', 'coming'), ('.', '.')]


------------------- Sentence 2 -------------------

But the traditional data analytics may not be able  to handle such large quantities of data.

>> Tokens are: 
 ['But', 'traditional', 'data', 'analytics', 'may', 'able', 'handle', 'large', 'quantities', 'data', '.']

>> Bigrams are: 
 [('But', 'traditional'), ('traditional', 'data'), ('data', 'analytics'), ('analytics', 'may'), ('may', 'able'), ('able', 'handle'), ('handle', 'large'), ('large', 'quantities'), ('quantities', 'data'), ('data', '.')]

>> Trigrams are: 
 [('But', 'traditional', 'data'), ('traditional', 'data', 'analytics'), ('data', 'analytics', 'may'), ('analytics', 'may', 'able'), ('may', 'able', 'handle'), ('able', 'handle', 'large'), ('handle', 'large', 'quantities'), ('large', 'quantities', 'data'), ('quantities', 'data', '.')]

>> POS Tags are: 
 [('But', 'CC'), ('traditional', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('may', 'MD'), ('able', 'JJ'), ('handle', 'VB'), ('large', 'JJ'), ('quantities', 'NNS'), ('data', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['traditional data analytics', 'large quantities data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('But', 'but'), ('traditional', 'tradit'), ('data', 'data'), ('analytics', 'analyt'), ('may', 'may'), ('able', 'abl'), ('handle', 'handl'), ('large', 'larg'), ('quantities', 'quantiti'), ('data', 'data'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('But', 'but'), ('traditional', 'tradit'), ('data', 'data'), ('analytics', 'analyt'), ('may', 'may'), ('able', 'abl'), ('handle', 'handl'), ('large', 'larg'), ('quantities', 'quantiti'), ('data', 'data'), ('.', '.')]

>> Lemmatization: 
 [('But', 'But'), ('traditional', 'traditional'), ('data', 'data'), ('analytics', 'analytics'), ('may', 'may'), ('able', 'able'), ('handle', 'handle'), ('large', 'large'), ('quantities', 'quantity'), ('data', 'data'), ('.', '.')]


------------------- Sentence 3 -------------------

The question that arises now is, how to develop  a high performance platform to efficiently analyze big data and how to design an  appropriate mining algorithm to find the useful things from big data.

>> Tokens are: 
 ['The', 'question', 'arises', ',', 'develop', 'high', 'performance', 'platform', 'efficiently', 'analyze', 'big', 'data', 'design', 'appropriate', 'mining', 'algorithm', 'find', 'useful', 'things', 'big', 'data', '.']

>> Bigrams are: 
 [('The', 'question'), ('question', 'arises'), ('arises', ','), (',', 'develop'), ('develop', 'high'), ('high', 'performance'), ('performance', 'platform'), ('platform', 'efficiently'), ('efficiently', 'analyze'), ('analyze', 'big'), ('big', 'data'), ('data', 'design'), ('design', 'appropriate'), ('appropriate', 'mining'), ('mining', 'algorithm'), ('algorithm', 'find'), ('find', 'useful'), ('useful', 'things'), ('things', 'big'), ('big', 'data'), ('data', '.')]

>> Trigrams are: 
 [('The', 'question', 'arises'), ('question', 'arises', ','), ('arises', ',', 'develop'), (',', 'develop', 'high'), ('develop', 'high', 'performance'), ('high', 'performance', 'platform'), ('performance', 'platform', 'efficiently'), ('platform', 'efficiently', 'analyze'), ('efficiently', 'analyze', 'big'), ('analyze', 'big', 'data'), ('big', 'data', 'design'), ('data', 'design', 'appropriate'), ('design', 'appropriate', 'mining'), ('appropriate', 'mining', 'algorithm'), ('mining', 'algorithm', 'find'), ('algorithm', 'find', 'useful'), ('find', 'useful', 'things'), ('useful', 'things', 'big'), ('things', 'big', 'data'), ('big', 'data', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('question', 'NN'), ('arises', 'VBZ'), (',', ','), ('develop', 'VB'), ('high', 'JJ'), ('performance', 'NN'), ('platform', 'NN'), ('efficiently', 'RB'), ('analyze', 'VBZ'), ('big', 'JJ'), ('data', 'NNS'), ('design', 'NN'), ('appropriate', 'JJ'), ('mining', 'NN'), ('algorithm', 'NN'), ('find', 'VBP'), ('useful', 'JJ'), ('things', 'NNS'), ('big', 'JJ'), ('data', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['The question', 'high performance platform', 'big data design', 'appropriate mining algorithm', 'useful things', 'big data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('question', 'question'), ('arises', 'aris'), (',', ','), ('develop', 'develop'), ('high', 'high'), ('performance', 'perform'), ('platform', 'platform'), ('efficiently', 'effici'), ('analyze', 'analyz'), ('big', 'big'), ('data', 'data'), ('design', 'design'), ('appropriate', 'appropri'), ('mining', 'mine'), ('algorithm', 'algorithm'), ('find', 'find'), ('useful', 'use'), ('things', 'thing'), ('big', 'big'), ('data', 'data'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('question', 'question'), ('arises', 'aris'), (',', ','), ('develop', 'develop'), ('high', 'high'), ('performance', 'perform'), ('platform', 'platform'), ('efficiently', 'effici'), ('analyze', 'analyz'), ('big', 'big'), ('data', 'data'), ('design', 'design'), ('appropriate', 'appropri'), ('mining', 'mine'), ('algorithm', 'algorithm'), ('find', 'find'), ('useful', 'use'), ('things', 'thing'), ('big', 'big'), ('data', 'data'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('question', 'question'), ('arises', 'arises'), (',', ','), ('develop', 'develop'), ('high', 'high'), ('performance', 'performance'), ('platform', 'platform'), ('efficiently', 'efficiently'), ('analyze', 'analyze'), ('big', 'big'), ('data', 'data'), ('design', 'design'), ('appropriate', 'appropriate'), ('mining', 'mining'), ('algorithm', 'algorithm'), ('find', 'find'), ('useful', 'useful'), ('things', 'thing'), ('big', 'big'), ('data', 'data'), ('.', '.')]


------------------- Sentence 4 -------------------

To deeply discuss  this issue, this paper begins with a brief introduction to data analytics, followed by the  discussions of big data analytics.

>> Tokens are: 
 ['To', 'deeply', 'discuss', 'issue', ',', 'paper', 'begins', 'brief', 'introduction', 'data', 'analytics', ',', 'followed', 'discussions', 'big', 'data', 'analytics', '.']

>> Bigrams are: 
 [('To', 'deeply'), ('deeply', 'discuss'), ('discuss', 'issue'), ('issue', ','), (',', 'paper'), ('paper', 'begins'), ('begins', 'brief'), ('brief', 'introduction'), ('introduction', 'data'), ('data', 'analytics'), ('analytics', ','), (',', 'followed'), ('followed', 'discussions'), ('discussions', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', '.')]

>> Trigrams are: 
 [('To', 'deeply', 'discuss'), ('deeply', 'discuss', 'issue'), ('discuss', 'issue', ','), ('issue', ',', 'paper'), (',', 'paper', 'begins'), ('paper', 'begins', 'brief'), ('begins', 'brief', 'introduction'), ('brief', 'introduction', 'data'), ('introduction', 'data', 'analytics'), ('data', 'analytics', ','), ('analytics', ',', 'followed'), (',', 'followed', 'discussions'), ('followed', 'discussions', 'big'), ('discussions', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', '.')]

>> POS Tags are: 
 [('To', 'TO'), ('deeply', 'VB'), ('discuss', 'JJ'), ('issue', 'NN'), (',', ','), ('paper', 'NN'), ('begins', 'VBZ'), ('brief', 'JJ'), ('introduction', 'NN'), ('data', 'NNS'), ('analytics', 'NNS'), (',', ','), ('followed', 'VBD'), ('discussions', 'NNS'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['discuss issue', 'paper', 'brief introduction data analytics', 'discussions', 'big data analytics']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('To', 'to'), ('deeply', 'deepli'), ('discuss', 'discuss'), ('issue', 'issu'), (',', ','), ('paper', 'paper'), ('begins', 'begin'), ('brief', 'brief'), ('introduction', 'introduct'), ('data', 'data'), ('analytics', 'analyt'), (',', ','), ('followed', 'follow'), ('discussions', 'discuss'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('To', 'to'), ('deeply', 'deepli'), ('discuss', 'discuss'), ('issue', 'issu'), (',', ','), ('paper', 'paper'), ('begins', 'begin'), ('brief', 'brief'), ('introduction', 'introduct'), ('data', 'data'), ('analytics', 'analyt'), (',', ','), ('followed', 'follow'), ('discussions', 'discuss'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('.', '.')]

>> Lemmatization: 
 [('To', 'To'), ('deeply', 'deeply'), ('discuss', 'discus'), ('issue', 'issue'), (',', ','), ('paper', 'paper'), ('begins', 'begin'), ('brief', 'brief'), ('introduction', 'introduction'), ('data', 'data'), ('analytics', 'analytics'), (',', ','), ('followed', 'followed'), ('discussions', 'discussion'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('.', '.')]


------------------- Sentence 5 -------------------

Some important open issues and further research  directions will also be presented for the next step of big data analytics.

>> Tokens are: 
 ['Some', 'important', 'open', 'issues', 'research', 'directions', 'also', 'presented', 'next', 'step', 'big', 'data', 'analytics', '.']

>> Bigrams are: 
 [('Some', 'important'), ('important', 'open'), ('open', 'issues'), ('issues', 'research'), ('research', 'directions'), ('directions', 'also'), ('also', 'presented'), ('presented', 'next'), ('next', 'step'), ('step', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', '.')]

>> Trigrams are: 
 [('Some', 'important', 'open'), ('important', 'open', 'issues'), ('open', 'issues', 'research'), ('issues', 'research', 'directions'), ('research', 'directions', 'also'), ('directions', 'also', 'presented'), ('also', 'presented', 'next'), ('presented', 'next', 'step'), ('next', 'step', 'big'), ('step', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', '.')]

>> POS Tags are: 
 [('Some', 'DT'), ('important', 'JJ'), ('open', 'JJ'), ('issues', 'NNS'), ('research', 'NN'), ('directions', 'NNS'), ('also', 'RB'), ('presented', 'VBD'), ('next', 'JJ'), ('step', 'NN'), ('big', 'JJ'), ('data', 'NN'), ('analytics', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['Some important open issues research directions', 'next step', 'big data analytics']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Some', 'some'), ('important', 'import'), ('open', 'open'), ('issues', 'issu'), ('research', 'research'), ('directions', 'direct'), ('also', 'also'), ('presented', 'present'), ('next', 'next'), ('step', 'step'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Some', 'some'), ('important', 'import'), ('open', 'open'), ('issues', 'issu'), ('research', 'research'), ('directions', 'direct'), ('also', 'also'), ('presented', 'present'), ('next', 'next'), ('step', 'step'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('.', '.')]

>> Lemmatization: 
 [('Some', 'Some'), ('important', 'important'), ('open', 'open'), ('issues', 'issue'), ('research', 'research'), ('directions', 'direction'), ('also', 'also'), ('presented', 'presented'), ('next', 'next'), ('step', 'step'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('.', '.')]



========================================== PARAGRAPH 7 ===========================================

Keywords: Big data, data analytics, data mining 

------------------- Sentence 1 -------------------

Keywords: Big data, data analytics, data mining

>> Tokens are: 
 ['Keywords', ':', 'Big', 'data', ',', 'data', 'analytics', ',', 'data', 'mining']

>> Bigrams are: 
 [('Keywords', ':'), (':', 'Big'), ('Big', 'data'), ('data', ','), (',', 'data'), ('data', 'analytics'), ('analytics', ','), (',', 'data'), ('data', 'mining')]

>> Trigrams are: 
 [('Keywords', ':', 'Big'), (':', 'Big', 'data'), ('Big', 'data', ','), ('data', ',', 'data'), (',', 'data', 'analytics'), ('data', 'analytics', ','), ('analytics', ',', 'data'), (',', 'data', 'mining')]

>> POS Tags are: 
 [('Keywords', 'NNS'), (':', ':'), ('Big', 'NNP'), ('data', 'NNS'), (',', ','), ('data', 'NNS'), ('analytics', 'NNS'), (',', ','), ('data', 'NNS'), ('mining', 'NN')]

>> Noun Phrases are: 
 ['Keywords', 'Big data', 'data analytics', 'data mining']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Keywords', 'keyword'), (':', ':'), ('Big', 'big'), ('data', 'data'), (',', ','), ('data', 'data'), ('analytics', 'analyt'), (',', ','), ('data', 'data'), ('mining', 'mine')]

>> Stemming using Snowball Stemmer: 
 [('Keywords', 'keyword'), (':', ':'), ('Big', 'big'), ('data', 'data'), (',', ','), ('data', 'data'), ('analytics', 'analyt'), (',', ','), ('data', 'data'), ('mining', 'mine')]

>> Lemmatization: 
 [('Keywords', 'Keywords'), (':', ':'), ('Big', 'Big'), ('data', 'data'), (',', ','), ('data', 'data'), ('analytics', 'analytics'), (',', ','), ('data', 'data'), ('mining', 'mining')]



========================================== PARAGRAPH 8 ===========================================

Open Access 

------------------- Sentence 1 -------------------

Open Access

>> Tokens are: 
 ['Open', 'Access']

>> Bigrams are: 
 [('Open', 'Access')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Open', 'JJ'), ('Access', 'NNP')]

>> Noun Phrases are: 
 ['Open Access']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Open', 'open'), ('Access', 'access')]

>> Stemming using Snowball Stemmer: 
 [('Open', 'open'), ('Access', 'access')]

>> Lemmatization: 
 [('Open', 'Open'), ('Access', 'Access')]



========================================== PARAGRAPH 9 ===========================================

© 2015 Tsai et al. This article is distributed under the terms of the Creative Commons Attribution 4.0 International License (http:// creativecommons.org/licenses/by/4.0/), which permits unrestricted use, distribution, and reproduction in any medium, provided  you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license, and indicate  if changes were made. 

------------------- Sentence 1 -------------------

© 2015 Tsai et al.

>> Tokens are: 
 ['©', '2015', 'Tsai', 'et', 'al', '.']

>> Bigrams are: 
 [('©', '2015'), ('2015', 'Tsai'), ('Tsai', 'et'), ('et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('©', '2015', 'Tsai'), ('2015', 'Tsai', 'et'), ('Tsai', 'et', 'al'), ('et', 'al', '.')]

>> POS Tags are: 
 [('©', 'NN'), ('2015', 'CD'), ('Tsai', 'NNP'), ('et', 'CC'), ('al', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['©', 'Tsai', 'al']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('©', '©'), ('2015', '2015'), ('Tsai', 'tsai'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('©', '©'), ('2015', '2015'), ('Tsai', 'tsai'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('©', '©'), ('2015', '2015'), ('Tsai', 'Tsai'), ('et', 'et'), ('al', 'al'), ('.', '.')]


------------------- Sentence 2 -------------------

This article is distributed under the terms of the Creative Commons Attribution 4.0 International License (http:// creativecommons.org/licenses/by/4.0/), which permits unrestricted use, distribution, and reproduction in any medium, provided  you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license, and indicate  if changes were made.

>> Tokens are: 
 ['This', 'article', 'distributed', 'terms', 'Creative', 'Commons', 'Attribution', '4.0', 'International', 'License', '(', 'http', ':', '//', 'creativecommons.org/licenses/by/4.0/', ')', ',', 'permits', 'unrestricted', 'use', ',', 'distribution', ',', 'reproduction', 'medium', ',', 'provided', 'give', 'appropriate', 'credit', 'original', 'author', '(', ')', 'source', ',', 'provide', 'link', 'Creative', 'Commons', 'license', ',', 'indicate', 'changes', 'made', '.']

>> Bigrams are: 
 [('This', 'article'), ('article', 'distributed'), ('distributed', 'terms'), ('terms', 'Creative'), ('Creative', 'Commons'), ('Commons', 'Attribution'), ('Attribution', '4.0'), ('4.0', 'International'), ('International', 'License'), ('License', '('), ('(', 'http'), ('http', ':'), (':', '//'), ('//', 'creativecommons.org/licenses/by/4.0/'), ('creativecommons.org/licenses/by/4.0/', ')'), (')', ','), (',', 'permits'), ('permits', 'unrestricted'), ('unrestricted', 'use'), ('use', ','), (',', 'distribution'), ('distribution', ','), (',', 'reproduction'), ('reproduction', 'medium'), ('medium', ','), (',', 'provided'), ('provided', 'give'), ('give', 'appropriate'), ('appropriate', 'credit'), ('credit', 'original'), ('original', 'author'), ('author', '('), ('(', ')'), (')', 'source'), ('source', ','), (',', 'provide'), ('provide', 'link'), ('link', 'Creative'), ('Creative', 'Commons'), ('Commons', 'license'), ('license', ','), (',', 'indicate'), ('indicate', 'changes'), ('changes', 'made'), ('made', '.')]

>> Trigrams are: 
 [('This', 'article', 'distributed'), ('article', 'distributed', 'terms'), ('distributed', 'terms', 'Creative'), ('terms', 'Creative', 'Commons'), ('Creative', 'Commons', 'Attribution'), ('Commons', 'Attribution', '4.0'), ('Attribution', '4.0', 'International'), ('4.0', 'International', 'License'), ('International', 'License', '('), ('License', '(', 'http'), ('(', 'http', ':'), ('http', ':', '//'), (':', '//', 'creativecommons.org/licenses/by/4.0/'), ('//', 'creativecommons.org/licenses/by/4.0/', ')'), ('creativecommons.org/licenses/by/4.0/', ')', ','), (')', ',', 'permits'), (',', 'permits', 'unrestricted'), ('permits', 'unrestricted', 'use'), ('unrestricted', 'use', ','), ('use', ',', 'distribution'), (',', 'distribution', ','), ('distribution', ',', 'reproduction'), (',', 'reproduction', 'medium'), ('reproduction', 'medium', ','), ('medium', ',', 'provided'), (',', 'provided', 'give'), ('provided', 'give', 'appropriate'), ('give', 'appropriate', 'credit'), ('appropriate', 'credit', 'original'), ('credit', 'original', 'author'), ('original', 'author', '('), ('author', '(', ')'), ('(', ')', 'source'), (')', 'source', ','), ('source', ',', 'provide'), (',', 'provide', 'link'), ('provide', 'link', 'Creative'), ('link', 'Creative', 'Commons'), ('Creative', 'Commons', 'license'), ('Commons', 'license', ','), ('license', ',', 'indicate'), (',', 'indicate', 'changes'), ('indicate', 'changes', 'made'), ('changes', 'made', '.')]

>> POS Tags are: 
 [('This', 'DT'), ('article', 'NN'), ('distributed', 'VBD'), ('terms', 'NNS'), ('Creative', 'JJ'), ('Commons', 'NNPS'), ('Attribution', 'NNP'), ('4.0', 'CD'), ('International', 'NNP'), ('License', 'NNP'), ('(', '('), ('http', 'NN'), (':', ':'), ('//', 'JJ'), ('creativecommons.org/licenses/by/4.0/', 'NN'), (')', ')'), (',', ','), ('permits', 'VBZ'), ('unrestricted', 'JJ'), ('use', 'NN'), (',', ','), ('distribution', 'NN'), (',', ','), ('reproduction', 'NN'), ('medium', 'NN'), (',', ','), ('provided', 'VBD'), ('give', 'JJ'), ('appropriate', 'JJ'), ('credit', 'NN'), ('original', 'JJ'), ('author', 'NN'), ('(', '('), (')', ')'), ('source', 'NN'), (',', ','), ('provide', 'VB'), ('link', 'VBP'), ('Creative', 'JJ'), ('Commons', 'NNP'), ('license', 'NN'), (',', ','), ('indicate', 'NN'), ('changes', 'NNS'), ('made', 'VBN'), ('.', '.')]

>> Noun Phrases are: 
 ['This article', 'terms', 'Attribution', 'International License', 'http', '// creativecommons.org/licenses/by/4.0/', 'unrestricted use', 'distribution', 'reproduction medium', 'give appropriate credit', 'original author', 'source', 'Creative Commons license', 'indicate changes']

>> Named Entities are: 
 [('ORGANIZATION', 'Creative Commons'), ('ORGANIZATION', 'International License'), ('ORGANIZATION', 'Creative Commons')] 

>> Stemming using Porter Stemmer: 
 [('This', 'thi'), ('article', 'articl'), ('distributed', 'distribut'), ('terms', 'term'), ('Creative', 'creativ'), ('Commons', 'common'), ('Attribution', 'attribut'), ('4.0', '4.0'), ('International', 'intern'), ('License', 'licens'), ('(', '('), ('http', 'http'), (':', ':'), ('//', '//'), ('creativecommons.org/licenses/by/4.0/', 'creativecommons.org/licenses/by/4.0/'), (')', ')'), (',', ','), ('permits', 'permit'), ('unrestricted', 'unrestrict'), ('use', 'use'), (',', ','), ('distribution', 'distribut'), (',', ','), ('reproduction', 'reproduct'), ('medium', 'medium'), (',', ','), ('provided', 'provid'), ('give', 'give'), ('appropriate', 'appropri'), ('credit', 'credit'), ('original', 'origin'), ('author', 'author'), ('(', '('), (')', ')'), ('source', 'sourc'), (',', ','), ('provide', 'provid'), ('link', 'link'), ('Creative', 'creativ'), ('Commons', 'common'), ('license', 'licens'), (',', ','), ('indicate', 'indic'), ('changes', 'chang'), ('made', 'made'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('This', 'this'), ('article', 'articl'), ('distributed', 'distribut'), ('terms', 'term'), ('Creative', 'creativ'), ('Commons', 'common'), ('Attribution', 'attribut'), ('4.0', '4.0'), ('International', 'intern'), ('License', 'licens'), ('(', '('), ('http', 'http'), (':', ':'), ('//', '//'), ('creativecommons.org/licenses/by/4.0/', 'creativecommons.org/licenses/by/4.0/'), (')', ')'), (',', ','), ('permits', 'permit'), ('unrestricted', 'unrestrict'), ('use', 'use'), (',', ','), ('distribution', 'distribut'), (',', ','), ('reproduction', 'reproduct'), ('medium', 'medium'), (',', ','), ('provided', 'provid'), ('give', 'give'), ('appropriate', 'appropri'), ('credit', 'credit'), ('original', 'origin'), ('author', 'author'), ('(', '('), (')', ')'), ('source', 'sourc'), (',', ','), ('provide', 'provid'), ('link', 'link'), ('Creative', 'creativ'), ('Commons', 'common'), ('license', 'licens'), (',', ','), ('indicate', 'indic'), ('changes', 'chang'), ('made', 'made'), ('.', '.')]

>> Lemmatization: 
 [('This', 'This'), ('article', 'article'), ('distributed', 'distributed'), ('terms', 'term'), ('Creative', 'Creative'), ('Commons', 'Commons'), ('Attribution', 'Attribution'), ('4.0', '4.0'), ('International', 'International'), ('License', 'License'), ('(', '('), ('http', 'http'), (':', ':'), ('//', '//'), ('creativecommons.org/licenses/by/4.0/', 'creativecommons.org/licenses/by/4.0/'), (')', ')'), (',', ','), ('permits', 'permit'), ('unrestricted', 'unrestricted'), ('use', 'use'), (',', ','), ('distribution', 'distribution'), (',', ','), ('reproduction', 'reproduction'), ('medium', 'medium'), (',', ','), ('provided', 'provided'), ('give', 'give'), ('appropriate', 'appropriate'), ('credit', 'credit'), ('original', 'original'), ('author', 'author'), ('(', '('), (')', ')'), ('source', 'source'), (',', ','), ('provide', 'provide'), ('link', 'link'), ('Creative', 'Creative'), ('Commons', 'Commons'), ('license', 'license'), (',', ','), ('indicate', 'indicate'), ('changes', 'change'), ('made', 'made'), ('.', '.')]



========================================== PARAGRAPH 10 ===========================================

SURVEY PAPER 

------------------- Sentence 1 -------------------

SURVEY PAPER

>> Tokens are: 
 ['SURVEY', 'PAPER']

>> Bigrams are: 
 [('SURVEY', 'PAPER')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('SURVEY', 'NNP'), ('PAPER', 'NNP')]

>> Noun Phrases are: 
 ['SURVEY PAPER']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('SURVEY', 'survey'), ('PAPER', 'paper')]

>> Stemming using Snowball Stemmer: 
 [('SURVEY', 'survey'), ('PAPER', 'paper')]

>> Lemmatization: 
 [('SURVEY', 'SURVEY'), ('PAPER', 'PAPER')]



========================================== PARAGRAPH 11 ===========================================

Tsai et al. Journal of Big Data  (2015) 2:21  DOI 10.1186/s40537-015-0030-3 

------------------- Sentence 1 -------------------

Tsai et al.

>> Tokens are: 
 ['Tsai', 'et', 'al', '.']

>> Bigrams are: 
 [('Tsai', 'et'), ('et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('Tsai', 'et', 'al'), ('et', 'al', '.')]

>> POS Tags are: 
 [('Tsai', 'NNP'), ('et', 'CC'), ('al', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Tsai', 'al']

>> Named Entities are: 
 [('GPE', 'Tsai')] 

>> Stemming using Porter Stemmer: 
 [('Tsai', 'tsai'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Tsai', 'tsai'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('Tsai', 'Tsai'), ('et', 'et'), ('al', 'al'), ('.', '.')]


------------------- Sentence 2 -------------------

Journal of Big Data  (2015) 2:21  DOI 10.1186/s40537-015-0030-3

>> Tokens are: 
 ['Journal', 'Big', 'Data', '(', '2015', ')', '2:21', 'DOI', '10.1186/s40537-015-0030-3']

>> Bigrams are: 
 [('Journal', 'Big'), ('Big', 'Data'), ('Data', '('), ('(', '2015'), ('2015', ')'), (')', '2:21'), ('2:21', 'DOI'), ('DOI', '10.1186/s40537-015-0030-3')]

>> Trigrams are: 
 [('Journal', 'Big', 'Data'), ('Big', 'Data', '('), ('Data', '(', '2015'), ('(', '2015', ')'), ('2015', ')', '2:21'), (')', '2:21', 'DOI'), ('2:21', 'DOI', '10.1186/s40537-015-0030-3')]

>> POS Tags are: 
 [('Journal', 'NNP'), ('Big', 'NNP'), ('Data', 'NNP'), ('(', '('), ('2015', 'CD'), (')', ')'), ('2:21', 'CD'), ('DOI', 'NNP'), ('10.1186/s40537-015-0030-3', 'JJ')]

>> Noun Phrases are: 
 ['Journal Big Data', 'DOI']

>> Named Entities are: 
 [('PERSON', 'Journal')] 

>> Stemming using Porter Stemmer: 
 [('Journal', 'journal'), ('Big', 'big'), ('Data', 'data'), ('(', '('), ('2015', '2015'), (')', ')'), ('2:21', '2:21'), ('DOI', 'doi'), ('10.1186/s40537-015-0030-3', '10.1186/s40537-015-0030-3')]

>> Stemming using Snowball Stemmer: 
 [('Journal', 'journal'), ('Big', 'big'), ('Data', 'data'), ('(', '('), ('2015', '2015'), (')', ')'), ('2:21', '2:21'), ('DOI', 'doi'), ('10.1186/s40537-015-0030-3', '10.1186/s40537-015-0030-3')]

>> Lemmatization: 
 [('Journal', 'Journal'), ('Big', 'Big'), ('Data', 'Data'), ('(', '('), ('2015', '2015'), (')', ')'), ('2:21', '2:21'), ('DOI', 'DOI'), ('10.1186/s40537-015-0030-3', '10.1186/s40537-015-0030-3')]



========================================== PARAGRAPH 12 ===========================================

*Correspondence:    th.vasilakos@gmail.com  5 Department of Computer  Science, Electrical and Space  Engineering, Luleå University  of Technology, SE‑931 87   Skellefteå, Sweden Full list of author information  is available at the end of the  article

------------------- Sentence 1 -------------------

*Correspondence:    th.vasilakos@gmail.com  5 Department of Computer  Science, Electrical and Space  Engineering, Luleå University  of Technology, SE‑931 87   Skellefteå, Sweden Full list of author information  is available at the end of the  article

>> Tokens are: 
 ['*', 'Correspondence', ':', 'th.vasilakos', '@', 'gmail.com', '5', 'Department', 'Computer', 'Science', ',', 'Electrical', 'Space', 'Engineering', ',', 'Luleå', 'University', 'Technology', ',', 'SE‑931', '87', 'Skellefteå', ',', 'Sweden', 'Full', 'list', 'author', 'information', 'available', 'end', 'article']

>> Bigrams are: 
 [('*', 'Correspondence'), ('Correspondence', ':'), (':', 'th.vasilakos'), ('th.vasilakos', '@'), ('@', 'gmail.com'), ('gmail.com', '5'), ('5', 'Department'), ('Department', 'Computer'), ('Computer', 'Science'), ('Science', ','), (',', 'Electrical'), ('Electrical', 'Space'), ('Space', 'Engineering'), ('Engineering', ','), (',', 'Luleå'), ('Luleå', 'University'), ('University', 'Technology'), ('Technology', ','), (',', 'SE‑931'), ('SE‑931', '87'), ('87', 'Skellefteå'), ('Skellefteå', ','), (',', 'Sweden'), ('Sweden', 'Full'), ('Full', 'list'), ('list', 'author'), ('author', 'information'), ('information', 'available'), ('available', 'end'), ('end', 'article')]

>> Trigrams are: 
 [('*', 'Correspondence', ':'), ('Correspondence', ':', 'th.vasilakos'), (':', 'th.vasilakos', '@'), ('th.vasilakos', '@', 'gmail.com'), ('@', 'gmail.com', '5'), ('gmail.com', '5', 'Department'), ('5', 'Department', 'Computer'), ('Department', 'Computer', 'Science'), ('Computer', 'Science', ','), ('Science', ',', 'Electrical'), (',', 'Electrical', 'Space'), ('Electrical', 'Space', 'Engineering'), ('Space', 'Engineering', ','), ('Engineering', ',', 'Luleå'), (',', 'Luleå', 'University'), ('Luleå', 'University', 'Technology'), ('University', 'Technology', ','), ('Technology', ',', 'SE‑931'), (',', 'SE‑931', '87'), ('SE‑931', '87', 'Skellefteå'), ('87', 'Skellefteå', ','), ('Skellefteå', ',', 'Sweden'), (',', 'Sweden', 'Full'), ('Sweden', 'Full', 'list'), ('Full', 'list', 'author'), ('list', 'author', 'information'), ('author', 'information', 'available'), ('information', 'available', 'end'), ('available', 'end', 'article')]

>> POS Tags are: 
 [('*', 'JJ'), ('Correspondence', 'NN'), (':', ':'), ('th.vasilakos', 'NN'), ('@', 'NNP'), ('gmail.com', 'VBD'), ('5', 'CD'), ('Department', 'NNP'), ('Computer', 'NNP'), ('Science', 'NNP'), (',', ','), ('Electrical', 'JJ'), ('Space', 'NNP'), ('Engineering', 'NNP'), (',', ','), ('Luleå', 'NNP'), ('University', 'NNP'), ('Technology', 'NNP'), (',', ','), ('SE‑931', 'NNP'), ('87', 'CD'), ('Skellefteå', 'NNP'), (',', ','), ('Sweden', 'NNP'), ('Full', 'NNP'), ('list', 'NN'), ('author', 'NN'), ('information', 'NN'), ('available', 'JJ'), ('end', 'NN'), ('article', 'NN')]

>> Noun Phrases are: 
 ['* Correspondence', 'th.vasilakos @', 'Department Computer Science', 'Electrical Space Engineering', 'Luleå University Technology', 'SE‑931', 'Skellefteå', 'Sweden Full list author information', 'available end article']

>> Named Entities are: 
 [('ORGANIZATION', 'Electrical Space Engineering'), ('PERSON', 'Luleå University Technology'), ('PERSON', 'Sweden Full')] 

>> Stemming using Porter Stemmer: 
 [('*', '*'), ('Correspondence', 'correspond'), (':', ':'), ('th.vasilakos', 'th.vasilako'), ('@', '@'), ('gmail.com', 'gmail.com'), ('5', '5'), ('Department', 'depart'), ('Computer', 'comput'), ('Science', 'scienc'), (',', ','), ('Electrical', 'electr'), ('Space', 'space'), ('Engineering', 'engin'), (',', ','), ('Luleå', 'luleå'), ('University', 'univers'), ('Technology', 'technolog'), (',', ','), ('SE‑931', 'se‑931'), ('87', '87'), ('Skellefteå', 'skellefteå'), (',', ','), ('Sweden', 'sweden'), ('Full', 'full'), ('list', 'list'), ('author', 'author'), ('information', 'inform'), ('available', 'avail'), ('end', 'end'), ('article', 'articl')]

>> Stemming using Snowball Stemmer: 
 [('*', '*'), ('Correspondence', 'correspond'), (':', ':'), ('th.vasilakos', 'th.vasilako'), ('@', '@'), ('gmail.com', 'gmail.com'), ('5', '5'), ('Department', 'depart'), ('Computer', 'comput'), ('Science', 'scienc'), (',', ','), ('Electrical', 'electr'), ('Space', 'space'), ('Engineering', 'engin'), (',', ','), ('Luleå', 'luleå'), ('University', 'univers'), ('Technology', 'technolog'), (',', ','), ('SE‑931', 'se‑931'), ('87', '87'), ('Skellefteå', 'skellefteå'), (',', ','), ('Sweden', 'sweden'), ('Full', 'full'), ('list', 'list'), ('author', 'author'), ('information', 'inform'), ('available', 'avail'), ('end', 'end'), ('article', 'articl')]

>> Lemmatization: 
 [('*', '*'), ('Correspondence', 'Correspondence'), (':', ':'), ('th.vasilakos', 'th.vasilakos'), ('@', '@'), ('gmail.com', 'gmail.com'), ('5', '5'), ('Department', 'Department'), ('Computer', 'Computer'), ('Science', 'Science'), (',', ','), ('Electrical', 'Electrical'), ('Space', 'Space'), ('Engineering', 'Engineering'), (',', ','), ('Luleå', 'Luleå'), ('University', 'University'), ('Technology', 'Technology'), (',', ','), ('SE‑931', 'SE‑931'), ('87', '87'), ('Skellefteå', 'Skellefteå'), (',', ','), ('Sweden', 'Sweden'), ('Full', 'Full'), ('list', 'list'), ('author', 'author'), ('information', 'information'), ('available', 'available'), ('end', 'end'), ('article', 'article')]



========================================== PARAGRAPH 13 ===========================================

Page 2 of 32Tsai et al. Journal of Big Data  (2015) 2:21  

------------------- Sentence 1 -------------------

Page 2 of 32Tsai et al.

>> Tokens are: 
 ['Page', '2', '32Tsai', 'et', 'al', '.']

>> Bigrams are: 
 [('Page', '2'), ('2', '32Tsai'), ('32Tsai', 'et'), ('et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('Page', '2', '32Tsai'), ('2', '32Tsai', 'et'), ('32Tsai', 'et', 'al'), ('et', 'al', '.')]

>> POS Tags are: 
 [('Page', 'NN'), ('2', 'CD'), ('32Tsai', 'CD'), ('et', 'NN'), ('al', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Page', 'et al']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Page', 'page'), ('2', '2'), ('32Tsai', '32tsai'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Page', 'page'), ('2', '2'), ('32Tsai', '32tsai'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('Page', 'Page'), ('2', '2'), ('32Tsai', '32Tsai'), ('et', 'et'), ('al', 'al'), ('.', '.')]


------------------- Sentence 2 -------------------

Journal of Big Data  (2015) 2:21

>> Tokens are: 
 ['Journal', 'Big', 'Data', '(', '2015', ')', '2:21']

>> Bigrams are: 
 [('Journal', 'Big'), ('Big', 'Data'), ('Data', '('), ('(', '2015'), ('2015', ')'), (')', '2:21')]

>> Trigrams are: 
 [('Journal', 'Big', 'Data'), ('Big', 'Data', '('), ('Data', '(', '2015'), ('(', '2015', ')'), ('2015', ')', '2:21')]

>> POS Tags are: 
 [('Journal', 'NNP'), ('Big', 'NNP'), ('Data', 'NNP'), ('(', '('), ('2015', 'CD'), (')', ')'), ('2:21', 'CD')]

>> Noun Phrases are: 
 ['Journal Big Data']

>> Named Entities are: 
 [('PERSON', 'Journal')] 

>> Stemming using Porter Stemmer: 
 [('Journal', 'journal'), ('Big', 'big'), ('Data', 'data'), ('(', '('), ('2015', '2015'), (')', ')'), ('2:21', '2:21')]

>> Stemming using Snowball Stemmer: 
 [('Journal', 'journal'), ('Big', 'big'), ('Data', 'data'), ('(', '('), ('2015', '2015'), (')', ')'), ('2:21', '2:21')]

>> Lemmatization: 
 [('Journal', 'Journal'), ('Big', 'Big'), ('Data', 'Data'), ('(', '('), ('2015', '2015'), (')', ')'), ('2:21', '2:21')]



========================================== PARAGRAPH 14 ===========================================

the problems of handling the large-scale data still exist when we are entering the age  of big data. That is why Fisher et al. [5] pointed out that big data means that the data is  unable to be handled and processed by most current information systems or methods  because data in the big data era will not only become too big to be loaded into a sin- gle machine, it also implies that most traditional data mining methods or data analytics  developed for a centralized data analysis process may not be able to be applied directly to  big data. In addition to the issues of data size, Laney [6] presented a well-known defini- tion (also called 3Vs) to explain what is the “big” data: volume, velocity, and variety. The  definition of 3Vs implies that the data size is large, the data will be created rapidly, and  the data will be existed in multiple types and captured from different sources, respec- tively. Later studies [7, 8] pointed out that the definition of 3Vs is insufficient to explain  the big data we face now. Thus, veracity, validity, value, variability, venue, vocabulary,  and vagueness were added to make some complement explanation of big data [8]. 

------------------- Sentence 1 -------------------

the problems of handling the large-scale data still exist when we are entering the age  of big data.

>> Tokens are: 
 ['problems', 'handling', 'large-scale', 'data', 'still', 'exist', 'entering', 'age', 'big', 'data', '.']

>> Bigrams are: 
 [('problems', 'handling'), ('handling', 'large-scale'), ('large-scale', 'data'), ('data', 'still'), ('still', 'exist'), ('exist', 'entering'), ('entering', 'age'), ('age', 'big'), ('big', 'data'), ('data', '.')]

>> Trigrams are: 
 [('problems', 'handling', 'large-scale'), ('handling', 'large-scale', 'data'), ('large-scale', 'data', 'still'), ('data', 'still', 'exist'), ('still', 'exist', 'entering'), ('exist', 'entering', 'age'), ('entering', 'age', 'big'), ('age', 'big', 'data'), ('big', 'data', '.')]

>> POS Tags are: 
 [('problems', 'NNS'), ('handling', 'VBG'), ('large-scale', 'JJ'), ('data', 'NNS'), ('still', 'RB'), ('exist', 'VBP'), ('entering', 'VBG'), ('age', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['problems', 'large-scale data', 'age', 'big data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('problems', 'problem'), ('handling', 'handl'), ('large-scale', 'large-scal'), ('data', 'data'), ('still', 'still'), ('exist', 'exist'), ('entering', 'enter'), ('age', 'age'), ('big', 'big'), ('data', 'data'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('problems', 'problem'), ('handling', 'handl'), ('large-scale', 'large-scal'), ('data', 'data'), ('still', 'still'), ('exist', 'exist'), ('entering', 'enter'), ('age', 'age'), ('big', 'big'), ('data', 'data'), ('.', '.')]

>> Lemmatization: 
 [('problems', 'problem'), ('handling', 'handling'), ('large-scale', 'large-scale'), ('data', 'data'), ('still', 'still'), ('exist', 'exist'), ('entering', 'entering'), ('age', 'age'), ('big', 'big'), ('data', 'data'), ('.', '.')]


------------------- Sentence 2 -------------------

That is why Fisher et al.

>> Tokens are: 
 ['That', 'Fisher', 'et', 'al', '.']

>> Bigrams are: 
 [('That', 'Fisher'), ('Fisher', 'et'), ('et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('That', 'Fisher', 'et'), ('Fisher', 'et', 'al'), ('et', 'al', '.')]

>> POS Tags are: 
 [('That', 'DT'), ('Fisher', 'NNP'), ('et', 'FW'), ('al', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['That Fisher', 'al']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('That', 'that'), ('Fisher', 'fisher'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('That', 'that'), ('Fisher', 'fisher'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('That', 'That'), ('Fisher', 'Fisher'), ('et', 'et'), ('al', 'al'), ('.', '.')]


------------------- Sentence 3 -------------------

[5] pointed out that big data means that the data is  unable to be handled and processed by most current information systems or methods  because data in the big data era will not only become too big to be loaded into a sin- gle machine, it also implies that most traditional data mining methods or data analytics  developed for a centralized data analysis process may not be able to be applied directly to  big data.

>> Tokens are: 
 ['[', '5', ']', 'pointed', 'big', 'data', 'means', 'data', 'unable', 'handled', 'processed', 'current', 'information', 'systems', 'methods', 'data', 'big', 'data', 'era', 'become', 'big', 'loaded', 'sin-', 'gle', 'machine', ',', 'also', 'implies', 'traditional', 'data', 'mining', 'methods', 'data', 'analytics', 'developed', 'centralized', 'data', 'analysis', 'process', 'may', 'able', 'applied', 'directly', 'big', 'data', '.']

>> Bigrams are: 
 [('[', '5'), ('5', ']'), (']', 'pointed'), ('pointed', 'big'), ('big', 'data'), ('data', 'means'), ('means', 'data'), ('data', 'unable'), ('unable', 'handled'), ('handled', 'processed'), ('processed', 'current'), ('current', 'information'), ('information', 'systems'), ('systems', 'methods'), ('methods', 'data'), ('data', 'big'), ('big', 'data'), ('data', 'era'), ('era', 'become'), ('become', 'big'), ('big', 'loaded'), ('loaded', 'sin-'), ('sin-', 'gle'), ('gle', 'machine'), ('machine', ','), (',', 'also'), ('also', 'implies'), ('implies', 'traditional'), ('traditional', 'data'), ('data', 'mining'), ('mining', 'methods'), ('methods', 'data'), ('data', 'analytics'), ('analytics', 'developed'), ('developed', 'centralized'), ('centralized', 'data'), ('data', 'analysis'), ('analysis', 'process'), ('process', 'may'), ('may', 'able'), ('able', 'applied'), ('applied', 'directly'), ('directly', 'big'), ('big', 'data'), ('data', '.')]

>> Trigrams are: 
 [('[', '5', ']'), ('5', ']', 'pointed'), (']', 'pointed', 'big'), ('pointed', 'big', 'data'), ('big', 'data', 'means'), ('data', 'means', 'data'), ('means', 'data', 'unable'), ('data', 'unable', 'handled'), ('unable', 'handled', 'processed'), ('handled', 'processed', 'current'), ('processed', 'current', 'information'), ('current', 'information', 'systems'), ('information', 'systems', 'methods'), ('systems', 'methods', 'data'), ('methods', 'data', 'big'), ('data', 'big', 'data'), ('big', 'data', 'era'), ('data', 'era', 'become'), ('era', 'become', 'big'), ('become', 'big', 'loaded'), ('big', 'loaded', 'sin-'), ('loaded', 'sin-', 'gle'), ('sin-', 'gle', 'machine'), ('gle', 'machine', ','), ('machine', ',', 'also'), (',', 'also', 'implies'), ('also', 'implies', 'traditional'), ('implies', 'traditional', 'data'), ('traditional', 'data', 'mining'), ('data', 'mining', 'methods'), ('mining', 'methods', 'data'), ('methods', 'data', 'analytics'), ('data', 'analytics', 'developed'), ('analytics', 'developed', 'centralized'), ('developed', 'centralized', 'data'), ('centralized', 'data', 'analysis'), ('data', 'analysis', 'process'), ('analysis', 'process', 'may'), ('process', 'may', 'able'), ('may', 'able', 'applied'), ('able', 'applied', 'directly'), ('applied', 'directly', 'big'), ('directly', 'big', 'data'), ('big', 'data', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('5', 'CD'), (']', 'NNS'), ('pointed', 'VBD'), ('big', 'JJ'), ('data', 'NNS'), ('means', 'VBZ'), ('data', 'NNS'), ('unable', 'JJ'), ('handled', 'VBD'), ('processed', 'JJ'), ('current', 'JJ'), ('information', 'NN'), ('systems', 'NNS'), ('methods', 'NNS'), ('data', 'NNS'), ('big', 'JJ'), ('data', 'NNS'), ('era', 'NN'), ('become', 'NN'), ('big', 'JJ'), ('loaded', 'VBD'), ('sin-', 'JJ'), ('gle', 'NN'), ('machine', 'NN'), (',', ','), ('also', 'RB'), ('implies', 'VBZ'), ('traditional', 'JJ'), ('data', 'NNS'), ('mining', 'NN'), ('methods', 'NNS'), ('data', 'VBP'), ('analytics', 'NNS'), ('developed', 'VBD'), ('centralized', 'VBN'), ('data', 'NNS'), ('analysis', 'NN'), ('process', 'NN'), ('may', 'MD'), ('able', 'JJ'), ('applied', 'VBN'), ('directly', 'RB'), ('big', 'JJ'), ('data', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 [']', 'big data', 'data', 'processed current information systems methods data', 'big data era become', 'sin- gle machine', 'traditional data mining methods', 'analytics', 'data analysis process', 'big data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('5', '5'), (']', ']'), ('pointed', 'point'), ('big', 'big'), ('data', 'data'), ('means', 'mean'), ('data', 'data'), ('unable', 'unabl'), ('handled', 'handl'), ('processed', 'process'), ('current', 'current'), ('information', 'inform'), ('systems', 'system'), ('methods', 'method'), ('data', 'data'), ('big', 'big'), ('data', 'data'), ('era', 'era'), ('become', 'becom'), ('big', 'big'), ('loaded', 'load'), ('sin-', 'sin-'), ('gle', 'gle'), ('machine', 'machin'), (',', ','), ('also', 'also'), ('implies', 'impli'), ('traditional', 'tradit'), ('data', 'data'), ('mining', 'mine'), ('methods', 'method'), ('data', 'data'), ('analytics', 'analyt'), ('developed', 'develop'), ('centralized', 'central'), ('data', 'data'), ('analysis', 'analysi'), ('process', 'process'), ('may', 'may'), ('able', 'abl'), ('applied', 'appli'), ('directly', 'directli'), ('big', 'big'), ('data', 'data'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('5', '5'), (']', ']'), ('pointed', 'point'), ('big', 'big'), ('data', 'data'), ('means', 'mean'), ('data', 'data'), ('unable', 'unabl'), ('handled', 'handl'), ('processed', 'process'), ('current', 'current'), ('information', 'inform'), ('systems', 'system'), ('methods', 'method'), ('data', 'data'), ('big', 'big'), ('data', 'data'), ('era', 'era'), ('become', 'becom'), ('big', 'big'), ('loaded', 'load'), ('sin-', 'sin-'), ('gle', 'gle'), ('machine', 'machin'), (',', ','), ('also', 'also'), ('implies', 'impli'), ('traditional', 'tradit'), ('data', 'data'), ('mining', 'mine'), ('methods', 'method'), ('data', 'data'), ('analytics', 'analyt'), ('developed', 'develop'), ('centralized', 'central'), ('data', 'data'), ('analysis', 'analysi'), ('process', 'process'), ('may', 'may'), ('able', 'abl'), ('applied', 'appli'), ('directly', 'direct'), ('big', 'big'), ('data', 'data'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('5', '5'), (']', ']'), ('pointed', 'pointed'), ('big', 'big'), ('data', 'data'), ('means', 'mean'), ('data', 'data'), ('unable', 'unable'), ('handled', 'handled'), ('processed', 'processed'), ('current', 'current'), ('information', 'information'), ('systems', 'system'), ('methods', 'method'), ('data', 'data'), ('big', 'big'), ('data', 'data'), ('era', 'era'), ('become', 'become'), ('big', 'big'), ('loaded', 'loaded'), ('sin-', 'sin-'), ('gle', 'gle'), ('machine', 'machine'), (',', ','), ('also', 'also'), ('implies', 'implies'), ('traditional', 'traditional'), ('data', 'data'), ('mining', 'mining'), ('methods', 'method'), ('data', 'data'), ('analytics', 'analytics'), ('developed', 'developed'), ('centralized', 'centralized'), ('data', 'data'), ('analysis', 'analysis'), ('process', 'process'), ('may', 'may'), ('able', 'able'), ('applied', 'applied'), ('directly', 'directly'), ('big', 'big'), ('data', 'data'), ('.', '.')]


------------------- Sentence 4 -------------------

In addition to the issues of data size, Laney [6] presented a well-known defini- tion (also called 3Vs) to explain what is the “big” data: volume, velocity, and variety.

>> Tokens are: 
 ['In', 'addition', 'issues', 'data', 'size', ',', 'Laney', '[', '6', ']', 'presented', 'well-known', 'defini-', 'tion', '(', 'also', 'called', '3Vs', ')', 'explain', '“', 'big', '”', 'data', ':', 'volume', ',', 'velocity', ',', 'variety', '.']

>> Bigrams are: 
 [('In', 'addition'), ('addition', 'issues'), ('issues', 'data'), ('data', 'size'), ('size', ','), (',', 'Laney'), ('Laney', '['), ('[', '6'), ('6', ']'), (']', 'presented'), ('presented', 'well-known'), ('well-known', 'defini-'), ('defini-', 'tion'), ('tion', '('), ('(', 'also'), ('also', 'called'), ('called', '3Vs'), ('3Vs', ')'), (')', 'explain'), ('explain', '“'), ('“', 'big'), ('big', '”'), ('”', 'data'), ('data', ':'), (':', 'volume'), ('volume', ','), (',', 'velocity'), ('velocity', ','), (',', 'variety'), ('variety', '.')]

>> Trigrams are: 
 [('In', 'addition', 'issues'), ('addition', 'issues', 'data'), ('issues', 'data', 'size'), ('data', 'size', ','), ('size', ',', 'Laney'), (',', 'Laney', '['), ('Laney', '[', '6'), ('[', '6', ']'), ('6', ']', 'presented'), (']', 'presented', 'well-known'), ('presented', 'well-known', 'defini-'), ('well-known', 'defini-', 'tion'), ('defini-', 'tion', '('), ('tion', '(', 'also'), ('(', 'also', 'called'), ('also', 'called', '3Vs'), ('called', '3Vs', ')'), ('3Vs', ')', 'explain'), (')', 'explain', '“'), ('explain', '“', 'big'), ('“', 'big', '”'), ('big', '”', 'data'), ('”', 'data', ':'), ('data', ':', 'volume'), (':', 'volume', ','), ('volume', ',', 'velocity'), (',', 'velocity', ','), ('velocity', ',', 'variety'), (',', 'variety', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('addition', 'NN'), ('issues', 'NNS'), ('data', 'NNS'), ('size', 'NN'), (',', ','), ('Laney', 'NNP'), ('[', 'VBZ'), ('6', 'CD'), (']', 'NN'), ('presented', 'VBN'), ('well-known', 'JJ'), ('defini-', 'JJ'), ('tion', 'NN'), ('(', '('), ('also', 'RB'), ('called', 'VBD'), ('3Vs', 'CD'), (')', ')'), ('explain', 'NN'), ('“', 'JJ'), ('big', 'JJ'), ('”', 'NN'), ('data', 'NNS'), (':', ':'), ('volume', 'NN'), (',', ','), ('velocity', 'NN'), (',', ','), ('variety', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['addition issues data size', 'Laney', ']', 'well-known defini- tion', 'explain', '“ big ” data', 'volume', 'velocity', 'variety']

>> Named Entities are: 
 [('PERSON', 'Laney')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('addition', 'addit'), ('issues', 'issu'), ('data', 'data'), ('size', 'size'), (',', ','), ('Laney', 'laney'), ('[', '['), ('6', '6'), (']', ']'), ('presented', 'present'), ('well-known', 'well-known'), ('defini-', 'defini-'), ('tion', 'tion'), ('(', '('), ('also', 'also'), ('called', 'call'), ('3Vs', '3v'), (')', ')'), ('explain', 'explain'), ('“', '“'), ('big', 'big'), ('”', '”'), ('data', 'data'), (':', ':'), ('volume', 'volum'), (',', ','), ('velocity', 'veloc'), (',', ','), ('variety', 'varieti'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('addition', 'addit'), ('issues', 'issu'), ('data', 'data'), ('size', 'size'), (',', ','), ('Laney', 'laney'), ('[', '['), ('6', '6'), (']', ']'), ('presented', 'present'), ('well-known', 'well-known'), ('defini-', 'defini-'), ('tion', 'tion'), ('(', '('), ('also', 'also'), ('called', 'call'), ('3Vs', '3vs'), (')', ')'), ('explain', 'explain'), ('“', '“'), ('big', 'big'), ('”', '”'), ('data', 'data'), (':', ':'), ('volume', 'volum'), (',', ','), ('velocity', 'veloc'), (',', ','), ('variety', 'varieti'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('addition', 'addition'), ('issues', 'issue'), ('data', 'data'), ('size', 'size'), (',', ','), ('Laney', 'Laney'), ('[', '['), ('6', '6'), (']', ']'), ('presented', 'presented'), ('well-known', 'well-known'), ('defini-', 'defini-'), ('tion', 'tion'), ('(', '('), ('also', 'also'), ('called', 'called'), ('3Vs', '3Vs'), (')', ')'), ('explain', 'explain'), ('“', '“'), ('big', 'big'), ('”', '”'), ('data', 'data'), (':', ':'), ('volume', 'volume'), (',', ','), ('velocity', 'velocity'), (',', ','), ('variety', 'variety'), ('.', '.')]


------------------- Sentence 5 -------------------

The  definition of 3Vs implies that the data size is large, the data will be created rapidly, and  the data will be existed in multiple types and captured from different sources, respec- tively.

>> Tokens are: 
 ['The', 'definition', '3Vs', 'implies', 'data', 'size', 'large', ',', 'data', 'created', 'rapidly', ',', 'data', 'existed', 'multiple', 'types', 'captured', 'different', 'sources', ',', 'respec-', 'tively', '.']

>> Bigrams are: 
 [('The', 'definition'), ('definition', '3Vs'), ('3Vs', 'implies'), ('implies', 'data'), ('data', 'size'), ('size', 'large'), ('large', ','), (',', 'data'), ('data', 'created'), ('created', 'rapidly'), ('rapidly', ','), (',', 'data'), ('data', 'existed'), ('existed', 'multiple'), ('multiple', 'types'), ('types', 'captured'), ('captured', 'different'), ('different', 'sources'), ('sources', ','), (',', 'respec-'), ('respec-', 'tively'), ('tively', '.')]

>> Trigrams are: 
 [('The', 'definition', '3Vs'), ('definition', '3Vs', 'implies'), ('3Vs', 'implies', 'data'), ('implies', 'data', 'size'), ('data', 'size', 'large'), ('size', 'large', ','), ('large', ',', 'data'), (',', 'data', 'created'), ('data', 'created', 'rapidly'), ('created', 'rapidly', ','), ('rapidly', ',', 'data'), (',', 'data', 'existed'), ('data', 'existed', 'multiple'), ('existed', 'multiple', 'types'), ('multiple', 'types', 'captured'), ('types', 'captured', 'different'), ('captured', 'different', 'sources'), ('different', 'sources', ','), ('sources', ',', 'respec-'), (',', 'respec-', 'tively'), ('respec-', 'tively', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('definition', 'NN'), ('3Vs', 'CD'), ('implies', 'NNS'), ('data', 'NNS'), ('size', 'NN'), ('large', 'JJ'), (',', ','), ('data', 'NNS'), ('created', 'VBD'), ('rapidly', 'RB'), (',', ','), ('data', 'NNS'), ('existed', 'VBD'), ('multiple', 'JJ'), ('types', 'NNS'), ('captured', 'VBD'), ('different', 'JJ'), ('sources', 'NNS'), (',', ','), ('respec-', 'JJ'), ('tively', 'RB'), ('.', '.')]

>> Noun Phrases are: 
 ['The definition', 'implies data size', 'data', 'data', 'multiple types', 'different sources']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('definition', 'definit'), ('3Vs', '3v'), ('implies', 'impli'), ('data', 'data'), ('size', 'size'), ('large', 'larg'), (',', ','), ('data', 'data'), ('created', 'creat'), ('rapidly', 'rapidli'), (',', ','), ('data', 'data'), ('existed', 'exist'), ('multiple', 'multipl'), ('types', 'type'), ('captured', 'captur'), ('different', 'differ'), ('sources', 'sourc'), (',', ','), ('respec-', 'respec-'), ('tively', 'tive'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('definition', 'definit'), ('3Vs', '3vs'), ('implies', 'impli'), ('data', 'data'), ('size', 'size'), ('large', 'larg'), (',', ','), ('data', 'data'), ('created', 'creat'), ('rapidly', 'rapid'), (',', ','), ('data', 'data'), ('existed', 'exist'), ('multiple', 'multipl'), ('types', 'type'), ('captured', 'captur'), ('different', 'differ'), ('sources', 'sourc'), (',', ','), ('respec-', 'respec-'), ('tively', 'tive'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('definition', 'definition'), ('3Vs', '3Vs'), ('implies', 'implies'), ('data', 'data'), ('size', 'size'), ('large', 'large'), (',', ','), ('data', 'data'), ('created', 'created'), ('rapidly', 'rapidly'), (',', ','), ('data', 'data'), ('existed', 'existed'), ('multiple', 'multiple'), ('types', 'type'), ('captured', 'captured'), ('different', 'different'), ('sources', 'source'), (',', ','), ('respec-', 'respec-'), ('tively', 'tively'), ('.', '.')]


------------------- Sentence 6 -------------------

Later studies [7, 8] pointed out that the definition of 3Vs is insufficient to explain  the big data we face now.

>> Tokens are: 
 ['Later', 'studies', '[', '7', ',', '8', ']', 'pointed', 'definition', '3Vs', 'insufficient', 'explain', 'big', 'data', 'face', '.']

>> Bigrams are: 
 [('Later', 'studies'), ('studies', '['), ('[', '7'), ('7', ','), (',', '8'), ('8', ']'), (']', 'pointed'), ('pointed', 'definition'), ('definition', '3Vs'), ('3Vs', 'insufficient'), ('insufficient', 'explain'), ('explain', 'big'), ('big', 'data'), ('data', 'face'), ('face', '.')]

>> Trigrams are: 
 [('Later', 'studies', '['), ('studies', '[', '7'), ('[', '7', ','), ('7', ',', '8'), (',', '8', ']'), ('8', ']', 'pointed'), (']', 'pointed', 'definition'), ('pointed', 'definition', '3Vs'), ('definition', '3Vs', 'insufficient'), ('3Vs', 'insufficient', 'explain'), ('insufficient', 'explain', 'big'), ('explain', 'big', 'data'), ('big', 'data', 'face'), ('data', 'face', '.')]

>> POS Tags are: 
 [('Later', 'RB'), ('studies', 'NNS'), ('[', 'VBP'), ('7', 'CD'), (',', ','), ('8', 'CD'), (']', 'NN'), ('pointed', 'VBD'), ('definition', 'NN'), ('3Vs', 'CD'), ('insufficient', 'NN'), ('explain', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('face', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['studies', ']', 'definition', 'insufficient explain', 'big data face']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Later', 'later'), ('studies', 'studi'), ('[', '['), ('7', '7'), (',', ','), ('8', '8'), (']', ']'), ('pointed', 'point'), ('definition', 'definit'), ('3Vs', '3v'), ('insufficient', 'insuffici'), ('explain', 'explain'), ('big', 'big'), ('data', 'data'), ('face', 'face'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Later', 'later'), ('studies', 'studi'), ('[', '['), ('7', '7'), (',', ','), ('8', '8'), (']', ']'), ('pointed', 'point'), ('definition', 'definit'), ('3Vs', '3vs'), ('insufficient', 'insuffici'), ('explain', 'explain'), ('big', 'big'), ('data', 'data'), ('face', 'face'), ('.', '.')]

>> Lemmatization: 
 [('Later', 'Later'), ('studies', 'study'), ('[', '['), ('7', '7'), (',', ','), ('8', '8'), (']', ']'), ('pointed', 'pointed'), ('definition', 'definition'), ('3Vs', '3Vs'), ('insufficient', 'insufficient'), ('explain', 'explain'), ('big', 'big'), ('data', 'data'), ('face', 'face'), ('.', '.')]


------------------- Sentence 7 -------------------

Thus, veracity, validity, value, variability, venue, vocabulary,  and vagueness were added to make some complement explanation of big data [8].

>> Tokens are: 
 ['Thus', ',', 'veracity', ',', 'validity', ',', 'value', ',', 'variability', ',', 'venue', ',', 'vocabulary', ',', 'vagueness', 'added', 'make', 'complement', 'explanation', 'big', 'data', '[', '8', ']', '.']

>> Bigrams are: 
 [('Thus', ','), (',', 'veracity'), ('veracity', ','), (',', 'validity'), ('validity', ','), (',', 'value'), ('value', ','), (',', 'variability'), ('variability', ','), (',', 'venue'), ('venue', ','), (',', 'vocabulary'), ('vocabulary', ','), (',', 'vagueness'), ('vagueness', 'added'), ('added', 'make'), ('make', 'complement'), ('complement', 'explanation'), ('explanation', 'big'), ('big', 'data'), ('data', '['), ('[', '8'), ('8', ']'), (']', '.')]

>> Trigrams are: 
 [('Thus', ',', 'veracity'), (',', 'veracity', ','), ('veracity', ',', 'validity'), (',', 'validity', ','), ('validity', ',', 'value'), (',', 'value', ','), ('value', ',', 'variability'), (',', 'variability', ','), ('variability', ',', 'venue'), (',', 'venue', ','), ('venue', ',', 'vocabulary'), (',', 'vocabulary', ','), ('vocabulary', ',', 'vagueness'), (',', 'vagueness', 'added'), ('vagueness', 'added', 'make'), ('added', 'make', 'complement'), ('make', 'complement', 'explanation'), ('complement', 'explanation', 'big'), ('explanation', 'big', 'data'), ('big', 'data', '['), ('data', '[', '8'), ('[', '8', ']'), ('8', ']', '.')]

>> POS Tags are: 
 [('Thus', 'RB'), (',', ','), ('veracity', 'NN'), (',', ','), ('validity', 'NN'), (',', ','), ('value', 'NN'), (',', ','), ('variability', 'NN'), (',', ','), ('venue', 'NN'), (',', ','), ('vocabulary', 'JJ'), (',', ','), ('vagueness', 'NN'), ('added', 'VBD'), ('make', 'JJ'), ('complement', 'JJ'), ('explanation', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('[', 'VBD'), ('8', 'CD'), (']', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['veracity', 'validity', 'value', 'variability', 'venue', 'vagueness', 'make complement explanation', 'big data', ']']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Thus', 'thu'), (',', ','), ('veracity', 'verac'), (',', ','), ('validity', 'valid'), (',', ','), ('value', 'valu'), (',', ','), ('variability', 'variabl'), (',', ','), ('venue', 'venu'), (',', ','), ('vocabulary', 'vocabulari'), (',', ','), ('vagueness', 'vagu'), ('added', 'ad'), ('make', 'make'), ('complement', 'complement'), ('explanation', 'explan'), ('big', 'big'), ('data', 'data'), ('[', '['), ('8', '8'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Thus', 'thus'), (',', ','), ('veracity', 'verac'), (',', ','), ('validity', 'valid'), (',', ','), ('value', 'valu'), (',', ','), ('variability', 'variabl'), (',', ','), ('venue', 'venu'), (',', ','), ('vocabulary', 'vocabulari'), (',', ','), ('vagueness', 'vagu'), ('added', 'ad'), ('make', 'make'), ('complement', 'complement'), ('explanation', 'explan'), ('big', 'big'), ('data', 'data'), ('[', '['), ('8', '8'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('Thus', 'Thus'), (',', ','), ('veracity', 'veracity'), (',', ','), ('validity', 'validity'), (',', ','), ('value', 'value'), (',', ','), ('variability', 'variability'), (',', ','), ('venue', 'venue'), (',', ','), ('vocabulary', 'vocabulary'), (',', ','), ('vagueness', 'vagueness'), ('added', 'added'), ('make', 'make'), ('complement', 'complement'), ('explanation', 'explanation'), ('big', 'big'), ('data', 'data'), ('[', '['), ('8', '8'), (']', ']'), ('.', '.')]



========================================== PARAGRAPH 15 ===========================================

The report of IDC [9] indicates that the marketing of big data is about $16.1 billion in  2014. Another report of IDC [10] forecasts that it will grow up to $32.4 billion by 2017.  The reports of [11] and [12] further pointed out that the marketing of big data will be  $46.34 billion and $114 billion by 2018, respectively. As shown in Fig. 1, even though the  marketing values of big data in these researches and technology reports [9–15] are dif- ferent, these forecasts usually indicate that the scope of big data will be grown rapidly in  the forthcoming future. 

------------------- Sentence 1 -------------------

The report of IDC [9] indicates that the marketing of big data is about $16.1 billion in  2014.

>> Tokens are: 
 ['The', 'report', 'IDC', '[', '9', ']', 'indicates', 'marketing', 'big', 'data', '$', '16.1', 'billion', '2014', '.']

>> Bigrams are: 
 [('The', 'report'), ('report', 'IDC'), ('IDC', '['), ('[', '9'), ('9', ']'), (']', 'indicates'), ('indicates', 'marketing'), ('marketing', 'big'), ('big', 'data'), ('data', '$'), ('$', '16.1'), ('16.1', 'billion'), ('billion', '2014'), ('2014', '.')]

>> Trigrams are: 
 [('The', 'report', 'IDC'), ('report', 'IDC', '['), ('IDC', '[', '9'), ('[', '9', ']'), ('9', ']', 'indicates'), (']', 'indicates', 'marketing'), ('indicates', 'marketing', 'big'), ('marketing', 'big', 'data'), ('big', 'data', '$'), ('data', '$', '16.1'), ('$', '16.1', 'billion'), ('16.1', 'billion', '2014'), ('billion', '2014', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('report', 'NN'), ('IDC', 'NNP'), ('[', 'VBZ'), ('9', 'CD'), (']', 'NN'), ('indicates', 'VBZ'), ('marketing', 'VBG'), ('big', 'JJ'), ('data', 'NNS'), ('$', '$'), ('16.1', 'CD'), ('billion', 'CD'), ('2014', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['The report IDC', ']', 'big data']

>> Named Entities are: 
 [('ORGANIZATION', 'IDC')] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('report', 'report'), ('IDC', 'idc'), ('[', '['), ('9', '9'), (']', ']'), ('indicates', 'indic'), ('marketing', 'market'), ('big', 'big'), ('data', 'data'), ('$', '$'), ('16.1', '16.1'), ('billion', 'billion'), ('2014', '2014'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('report', 'report'), ('IDC', 'idc'), ('[', '['), ('9', '9'), (']', ']'), ('indicates', 'indic'), ('marketing', 'market'), ('big', 'big'), ('data', 'data'), ('$', '$'), ('16.1', '16.1'), ('billion', 'billion'), ('2014', '2014'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('report', 'report'), ('IDC', 'IDC'), ('[', '['), ('9', '9'), (']', ']'), ('indicates', 'indicates'), ('marketing', 'marketing'), ('big', 'big'), ('data', 'data'), ('$', '$'), ('16.1', '16.1'), ('billion', 'billion'), ('2014', '2014'), ('.', '.')]


------------------- Sentence 2 -------------------

Another report of IDC [10] forecasts that it will grow up to $32.4 billion by 2017.

>> Tokens are: 
 ['Another', 'report', 'IDC', '[', '10', ']', 'forecasts', 'grow', '$', '32.4', 'billion', '2017', '.']

>> Bigrams are: 
 [('Another', 'report'), ('report', 'IDC'), ('IDC', '['), ('[', '10'), ('10', ']'), (']', 'forecasts'), ('forecasts', 'grow'), ('grow', '$'), ('$', '32.4'), ('32.4', 'billion'), ('billion', '2017'), ('2017', '.')]

>> Trigrams are: 
 [('Another', 'report', 'IDC'), ('report', 'IDC', '['), ('IDC', '[', '10'), ('[', '10', ']'), ('10', ']', 'forecasts'), (']', 'forecasts', 'grow'), ('forecasts', 'grow', '$'), ('grow', '$', '32.4'), ('$', '32.4', 'billion'), ('32.4', 'billion', '2017'), ('billion', '2017', '.')]

>> POS Tags are: 
 [('Another', 'DT'), ('report', 'NN'), ('IDC', 'NNP'), ('[', 'VBZ'), ('10', 'CD'), (']', 'JJ'), ('forecasts', 'NNS'), ('grow', 'VBP'), ('$', '$'), ('32.4', 'CD'), ('billion', 'CD'), ('2017', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Another report IDC', '] forecasts']

>> Named Entities are: 
 [('ORGANIZATION', 'IDC')] 

>> Stemming using Porter Stemmer: 
 [('Another', 'anoth'), ('report', 'report'), ('IDC', 'idc'), ('[', '['), ('10', '10'), (']', ']'), ('forecasts', 'forecast'), ('grow', 'grow'), ('$', '$'), ('32.4', '32.4'), ('billion', 'billion'), ('2017', '2017'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Another', 'anoth'), ('report', 'report'), ('IDC', 'idc'), ('[', '['), ('10', '10'), (']', ']'), ('forecasts', 'forecast'), ('grow', 'grow'), ('$', '$'), ('32.4', '32.4'), ('billion', 'billion'), ('2017', '2017'), ('.', '.')]

>> Lemmatization: 
 [('Another', 'Another'), ('report', 'report'), ('IDC', 'IDC'), ('[', '['), ('10', '10'), (']', ']'), ('forecasts', 'forecast'), ('grow', 'grow'), ('$', '$'), ('32.4', '32.4'), ('billion', 'billion'), ('2017', '2017'), ('.', '.')]


------------------- Sentence 3 -------------------

The reports of [11] and [12] further pointed out that the marketing of big data will be  $46.34 billion and $114 billion by 2018, respectively.

>> Tokens are: 
 ['The', 'reports', '[', '11', ']', '[', '12', ']', 'pointed', 'marketing', 'big', 'data', '$', '46.34', 'billion', '$', '114', 'billion', '2018', ',', 'respectively', '.']

>> Bigrams are: 
 [('The', 'reports'), ('reports', '['), ('[', '11'), ('11', ']'), (']', '['), ('[', '12'), ('12', ']'), (']', 'pointed'), ('pointed', 'marketing'), ('marketing', 'big'), ('big', 'data'), ('data', '$'), ('$', '46.34'), ('46.34', 'billion'), ('billion', '$'), ('$', '114'), ('114', 'billion'), ('billion', '2018'), ('2018', ','), (',', 'respectively'), ('respectively', '.')]

>> Trigrams are: 
 [('The', 'reports', '['), ('reports', '[', '11'), ('[', '11', ']'), ('11', ']', '['), (']', '[', '12'), ('[', '12', ']'), ('12', ']', 'pointed'), (']', 'pointed', 'marketing'), ('pointed', 'marketing', 'big'), ('marketing', 'big', 'data'), ('big', 'data', '$'), ('data', '$', '46.34'), ('$', '46.34', 'billion'), ('46.34', 'billion', '$'), ('billion', '$', '114'), ('$', '114', 'billion'), ('114', 'billion', '2018'), ('billion', '2018', ','), ('2018', ',', 'respectively'), (',', 'respectively', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('reports', 'NNS'), ('[', 'VBD'), ('11', 'CD'), (']', 'NNP'), ('[', 'VBD'), ('12', 'CD'), (']', 'NN'), ('pointed', 'VBD'), ('marketing', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('$', '$'), ('46.34', 'CD'), ('billion', 'CD'), ('$', '$'), ('114', 'CD'), ('billion', 'CD'), ('2018', 'CD'), (',', ','), ('respectively', 'RB'), ('.', '.')]

>> Noun Phrases are: 
 ['The reports', ']', ']', 'marketing', 'big data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('reports', 'report'), ('[', '['), ('11', '11'), (']', ']'), ('[', '['), ('12', '12'), (']', ']'), ('pointed', 'point'), ('marketing', 'market'), ('big', 'big'), ('data', 'data'), ('$', '$'), ('46.34', '46.34'), ('billion', 'billion'), ('$', '$'), ('114', '114'), ('billion', 'billion'), ('2018', '2018'), (',', ','), ('respectively', 'respect'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('reports', 'report'), ('[', '['), ('11', '11'), (']', ']'), ('[', '['), ('12', '12'), (']', ']'), ('pointed', 'point'), ('marketing', 'market'), ('big', 'big'), ('data', 'data'), ('$', '$'), ('46.34', '46.34'), ('billion', 'billion'), ('$', '$'), ('114', '114'), ('billion', 'billion'), ('2018', '2018'), (',', ','), ('respectively', 'respect'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('reports', 'report'), ('[', '['), ('11', '11'), (']', ']'), ('[', '['), ('12', '12'), (']', ']'), ('pointed', 'pointed'), ('marketing', 'marketing'), ('big', 'big'), ('data', 'data'), ('$', '$'), ('46.34', '46.34'), ('billion', 'billion'), ('$', '$'), ('114', '114'), ('billion', 'billion'), ('2018', '2018'), (',', ','), ('respectively', 'respectively'), ('.', '.')]


------------------- Sentence 4 -------------------

As shown in Fig.

>> Tokens are: 
 ['As', 'shown', 'Fig', '.']

>> Bigrams are: 
 [('As', 'shown'), ('shown', 'Fig'), ('Fig', '.')]

>> Trigrams are: 
 [('As', 'shown', 'Fig'), ('shown', 'Fig', '.')]

>> POS Tags are: 
 [('As', 'IN'), ('shown', 'VBN'), ('Fig', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Fig']

>> Named Entities are: 
 [('PERSON', 'Fig')] 

>> Stemming using Porter Stemmer: 
 [('As', 'as'), ('shown', 'shown'), ('Fig', 'fig'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('As', 'as'), ('shown', 'shown'), ('Fig', 'fig'), ('.', '.')]

>> Lemmatization: 
 [('As', 'As'), ('shown', 'shown'), ('Fig', 'Fig'), ('.', '.')]


------------------- Sentence 5 -------------------

1, even though the  marketing values of big data in these researches and technology reports [9–15] are dif- ferent, these forecasts usually indicate that the scope of big data will be grown rapidly in  the forthcoming future.

>> Tokens are: 
 ['1', ',', 'even', 'though', 'marketing', 'values', 'big', 'data', 'researches', 'technology', 'reports', '[', '9–15', ']', 'dif-', 'ferent', ',', 'forecasts', 'usually', 'indicate', 'scope', 'big', 'data', 'grown', 'rapidly', 'forthcoming', 'future', '.']

>> Bigrams are: 
 [('1', ','), (',', 'even'), ('even', 'though'), ('though', 'marketing'), ('marketing', 'values'), ('values', 'big'), ('big', 'data'), ('data', 'researches'), ('researches', 'technology'), ('technology', 'reports'), ('reports', '['), ('[', '9–15'), ('9–15', ']'), (']', 'dif-'), ('dif-', 'ferent'), ('ferent', ','), (',', 'forecasts'), ('forecasts', 'usually'), ('usually', 'indicate'), ('indicate', 'scope'), ('scope', 'big'), ('big', 'data'), ('data', 'grown'), ('grown', 'rapidly'), ('rapidly', 'forthcoming'), ('forthcoming', 'future'), ('future', '.')]

>> Trigrams are: 
 [('1', ',', 'even'), (',', 'even', 'though'), ('even', 'though', 'marketing'), ('though', 'marketing', 'values'), ('marketing', 'values', 'big'), ('values', 'big', 'data'), ('big', 'data', 'researches'), ('data', 'researches', 'technology'), ('researches', 'technology', 'reports'), ('technology', 'reports', '['), ('reports', '[', '9–15'), ('[', '9–15', ']'), ('9–15', ']', 'dif-'), (']', 'dif-', 'ferent'), ('dif-', 'ferent', ','), ('ferent', ',', 'forecasts'), (',', 'forecasts', 'usually'), ('forecasts', 'usually', 'indicate'), ('usually', 'indicate', 'scope'), ('indicate', 'scope', 'big'), ('scope', 'big', 'data'), ('big', 'data', 'grown'), ('data', 'grown', 'rapidly'), ('grown', 'rapidly', 'forthcoming'), ('rapidly', 'forthcoming', 'future'), ('forthcoming', 'future', '.')]

>> POS Tags are: 
 [('1', 'CD'), (',', ','), ('even', 'RB'), ('though', 'IN'), ('marketing', 'NN'), ('values', 'NNS'), ('big', 'JJ'), ('data', 'NNS'), ('researches', 'NNS'), ('technology', 'NN'), ('reports', 'NNS'), ('[', 'VBD'), ('9–15', 'CD'), (']', 'JJ'), ('dif-', 'JJ'), ('ferent', 'NN'), (',', ','), ('forecasts', 'VBZ'), ('usually', 'RB'), ('indicate', 'JJ'), ('scope', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('grown', 'NNS'), ('rapidly', 'RB'), ('forthcoming', 'JJ'), ('future', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['marketing values', 'big data researches technology reports', '] dif- ferent', 'indicate scope', 'big data grown', 'forthcoming future']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('1', '1'), (',', ','), ('even', 'even'), ('though', 'though'), ('marketing', 'market'), ('values', 'valu'), ('big', 'big'), ('data', 'data'), ('researches', 'research'), ('technology', 'technolog'), ('reports', 'report'), ('[', '['), ('9–15', '9–15'), (']', ']'), ('dif-', 'dif-'), ('ferent', 'ferent'), (',', ','), ('forecasts', 'forecast'), ('usually', 'usual'), ('indicate', 'indic'), ('scope', 'scope'), ('big', 'big'), ('data', 'data'), ('grown', 'grown'), ('rapidly', 'rapidli'), ('forthcoming', 'forthcom'), ('future', 'futur'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('1', '1'), (',', ','), ('even', 'even'), ('though', 'though'), ('marketing', 'market'), ('values', 'valu'), ('big', 'big'), ('data', 'data'), ('researches', 'research'), ('technology', 'technolog'), ('reports', 'report'), ('[', '['), ('9–15', '9–15'), (']', ']'), ('dif-', 'dif-'), ('ferent', 'ferent'), (',', ','), ('forecasts', 'forecast'), ('usually', 'usual'), ('indicate', 'indic'), ('scope', 'scope'), ('big', 'big'), ('data', 'data'), ('grown', 'grown'), ('rapidly', 'rapid'), ('forthcoming', 'forthcom'), ('future', 'futur'), ('.', '.')]

>> Lemmatization: 
 [('1', '1'), (',', ','), ('even', 'even'), ('though', 'though'), ('marketing', 'marketing'), ('values', 'value'), ('big', 'big'), ('data', 'data'), ('researches', 'research'), ('technology', 'technology'), ('reports', 'report'), ('[', '['), ('9–15', '9–15'), (']', ']'), ('dif-', 'dif-'), ('ferent', 'ferent'), (',', ','), ('forecasts', 'forecast'), ('usually', 'usually'), ('indicate', 'indicate'), ('scope', 'scope'), ('big', 'big'), ('data', 'data'), ('grown', 'grown'), ('rapidly', 'rapidly'), ('forthcoming', 'forthcoming'), ('future', 'future'), ('.', '.')]



========================================== PARAGRAPH 16 ===========================================

In addition to marketing, from the results of disease control and prevention [16], busi- ness intelligence [17], and smart city [18], we can easily understand that big data is of  vital importance everywhere. A numerous researches are therefore focusing on devel- oping effective technologies to analyze the big data. To discuss in deep the big data  analytics, this paper gives not only a systematic description of traditional large-scale  data analytics but also a detailed discussion about the differences between data and big  data analytics framework for the data scientists or researchers to focus on the big data  analytics. 

------------------- Sentence 1 -------------------

In addition to marketing, from the results of disease control and prevention [16], busi- ness intelligence [17], and smart city [18], we can easily understand that big data is of  vital importance everywhere.

>> Tokens are: 
 ['In', 'addition', 'marketing', ',', 'results', 'disease', 'control', 'prevention', '[', '16', ']', ',', 'busi-', 'ness', 'intelligence', '[', '17', ']', ',', 'smart', 'city', '[', '18', ']', ',', 'easily', 'understand', 'big', 'data', 'vital', 'importance', 'everywhere', '.']

>> Bigrams are: 
 [('In', 'addition'), ('addition', 'marketing'), ('marketing', ','), (',', 'results'), ('results', 'disease'), ('disease', 'control'), ('control', 'prevention'), ('prevention', '['), ('[', '16'), ('16', ']'), (']', ','), (',', 'busi-'), ('busi-', 'ness'), ('ness', 'intelligence'), ('intelligence', '['), ('[', '17'), ('17', ']'), (']', ','), (',', 'smart'), ('smart', 'city'), ('city', '['), ('[', '18'), ('18', ']'), (']', ','), (',', 'easily'), ('easily', 'understand'), ('understand', 'big'), ('big', 'data'), ('data', 'vital'), ('vital', 'importance'), ('importance', 'everywhere'), ('everywhere', '.')]

>> Trigrams are: 
 [('In', 'addition', 'marketing'), ('addition', 'marketing', ','), ('marketing', ',', 'results'), (',', 'results', 'disease'), ('results', 'disease', 'control'), ('disease', 'control', 'prevention'), ('control', 'prevention', '['), ('prevention', '[', '16'), ('[', '16', ']'), ('16', ']', ','), (']', ',', 'busi-'), (',', 'busi-', 'ness'), ('busi-', 'ness', 'intelligence'), ('ness', 'intelligence', '['), ('intelligence', '[', '17'), ('[', '17', ']'), ('17', ']', ','), (']', ',', 'smart'), (',', 'smart', 'city'), ('smart', 'city', '['), ('city', '[', '18'), ('[', '18', ']'), ('18', ']', ','), (']', ',', 'easily'), (',', 'easily', 'understand'), ('easily', 'understand', 'big'), ('understand', 'big', 'data'), ('big', 'data', 'vital'), ('data', 'vital', 'importance'), ('vital', 'importance', 'everywhere'), ('importance', 'everywhere', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('addition', 'NN'), ('marketing', 'NN'), (',', ','), ('results', 'NNS'), ('disease', 'VBD'), ('control', 'JJ'), ('prevention', 'NN'), ('[', 'VBD'), ('16', 'CD'), (']', 'NN'), (',', ','), ('busi-', 'JJ'), ('ness', 'JJ'), ('intelligence', 'NN'), ('[', 'VBD'), ('17', 'CD'), (']', 'NN'), (',', ','), ('smart', 'JJ'), ('city', 'NN'), ('[', '$'), ('18', 'CD'), (']', 'NNP'), (',', ','), ('easily', 'RB'), ('understand', 'VBP'), ('big', 'JJ'), ('data', 'NNS'), ('vital', 'JJ'), ('importance', 'NN'), ('everywhere', 'RB'), ('.', '.')]

>> Noun Phrases are: 
 ['addition marketing', 'results', 'control prevention', ']', 'busi- ness intelligence', ']', 'smart city', ']', 'big data', 'vital importance']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('addition', 'addit'), ('marketing', 'market'), (',', ','), ('results', 'result'), ('disease', 'diseas'), ('control', 'control'), ('prevention', 'prevent'), ('[', '['), ('16', '16'), (']', ']'), (',', ','), ('busi-', 'busi-'), ('ness', 'ness'), ('intelligence', 'intellig'), ('[', '['), ('17', '17'), (']', ']'), (',', ','), ('smart', 'smart'), ('city', 'citi'), ('[', '['), ('18', '18'), (']', ']'), (',', ','), ('easily', 'easili'), ('understand', 'understand'), ('big', 'big'), ('data', 'data'), ('vital', 'vital'), ('importance', 'import'), ('everywhere', 'everywher'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('addition', 'addit'), ('marketing', 'market'), (',', ','), ('results', 'result'), ('disease', 'diseas'), ('control', 'control'), ('prevention', 'prevent'), ('[', '['), ('16', '16'), (']', ']'), (',', ','), ('busi-', 'busi-'), ('ness', 'ness'), ('intelligence', 'intellig'), ('[', '['), ('17', '17'), (']', ']'), (',', ','), ('smart', 'smart'), ('city', 'citi'), ('[', '['), ('18', '18'), (']', ']'), (',', ','), ('easily', 'easili'), ('understand', 'understand'), ('big', 'big'), ('data', 'data'), ('vital', 'vital'), ('importance', 'import'), ('everywhere', 'everywher'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('addition', 'addition'), ('marketing', 'marketing'), (',', ','), ('results', 'result'), ('disease', 'disease'), ('control', 'control'), ('prevention', 'prevention'), ('[', '['), ('16', '16'), (']', ']'), (',', ','), ('busi-', 'busi-'), ('ness', 'ness'), ('intelligence', 'intelligence'), ('[', '['), ('17', '17'), (']', ']'), (',', ','), ('smart', 'smart'), ('city', 'city'), ('[', '['), ('18', '18'), (']', ']'), (',', ','), ('easily', 'easily'), ('understand', 'understand'), ('big', 'big'), ('data', 'data'), ('vital', 'vital'), ('importance', 'importance'), ('everywhere', 'everywhere'), ('.', '.')]


------------------- Sentence 2 -------------------

A numerous researches are therefore focusing on devel- oping effective technologies to analyze the big data.

>> Tokens are: 
 ['A', 'numerous', 'researches', 'therefore', 'focusing', 'devel-', 'oping', 'effective', 'technologies', 'analyze', 'big', 'data', '.']

>> Bigrams are: 
 [('A', 'numerous'), ('numerous', 'researches'), ('researches', 'therefore'), ('therefore', 'focusing'), ('focusing', 'devel-'), ('devel-', 'oping'), ('oping', 'effective'), ('effective', 'technologies'), ('technologies', 'analyze'), ('analyze', 'big'), ('big', 'data'), ('data', '.')]

>> Trigrams are: 
 [('A', 'numerous', 'researches'), ('numerous', 'researches', 'therefore'), ('researches', 'therefore', 'focusing'), ('therefore', 'focusing', 'devel-'), ('focusing', 'devel-', 'oping'), ('devel-', 'oping', 'effective'), ('oping', 'effective', 'technologies'), ('effective', 'technologies', 'analyze'), ('technologies', 'analyze', 'big'), ('analyze', 'big', 'data'), ('big', 'data', '.')]

>> POS Tags are: 
 [('A', 'DT'), ('numerous', 'JJ'), ('researches', 'NNS'), ('therefore', 'RB'), ('focusing', 'VBG'), ('devel-', 'JJ'), ('oping', 'VBG'), ('effective', 'JJ'), ('technologies', 'NNS'), ('analyze', 'VBP'), ('big', 'JJ'), ('data', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['A numerous researches', 'effective technologies', 'big data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('A', 'a'), ('numerous', 'numer'), ('researches', 'research'), ('therefore', 'therefor'), ('focusing', 'focus'), ('devel-', 'devel-'), ('oping', 'ope'), ('effective', 'effect'), ('technologies', 'technolog'), ('analyze', 'analyz'), ('big', 'big'), ('data', 'data'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('A', 'a'), ('numerous', 'numer'), ('researches', 'research'), ('therefore', 'therefor'), ('focusing', 'focus'), ('devel-', 'devel-'), ('oping', 'ope'), ('effective', 'effect'), ('technologies', 'technolog'), ('analyze', 'analyz'), ('big', 'big'), ('data', 'data'), ('.', '.')]

>> Lemmatization: 
 [('A', 'A'), ('numerous', 'numerous'), ('researches', 'research'), ('therefore', 'therefore'), ('focusing', 'focusing'), ('devel-', 'devel-'), ('oping', 'oping'), ('effective', 'effective'), ('technologies', 'technology'), ('analyze', 'analyze'), ('big', 'big'), ('data', 'data'), ('.', '.')]


------------------- Sentence 3 -------------------

To discuss in deep the big data  analytics, this paper gives not only a systematic description of traditional large-scale  data analytics but also a detailed discussion about the differences between data and big  data analytics framework for the data scientists or researchers to focus on the big data  analytics.

>> Tokens are: 
 ['To', 'discuss', 'deep', 'big', 'data', 'analytics', ',', 'paper', 'gives', 'systematic', 'description', 'traditional', 'large-scale', 'data', 'analytics', 'also', 'detailed', 'discussion', 'differences', 'data', 'big', 'data', 'analytics', 'framework', 'data', 'scientists', 'researchers', 'focus', 'big', 'data', 'analytics', '.']

>> Bigrams are: 
 [('To', 'discuss'), ('discuss', 'deep'), ('deep', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', ','), (',', 'paper'), ('paper', 'gives'), ('gives', 'systematic'), ('systematic', 'description'), ('description', 'traditional'), ('traditional', 'large-scale'), ('large-scale', 'data'), ('data', 'analytics'), ('analytics', 'also'), ('also', 'detailed'), ('detailed', 'discussion'), ('discussion', 'differences'), ('differences', 'data'), ('data', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', 'framework'), ('framework', 'data'), ('data', 'scientists'), ('scientists', 'researchers'), ('researchers', 'focus'), ('focus', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', '.')]

>> Trigrams are: 
 [('To', 'discuss', 'deep'), ('discuss', 'deep', 'big'), ('deep', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', ','), ('analytics', ',', 'paper'), (',', 'paper', 'gives'), ('paper', 'gives', 'systematic'), ('gives', 'systematic', 'description'), ('systematic', 'description', 'traditional'), ('description', 'traditional', 'large-scale'), ('traditional', 'large-scale', 'data'), ('large-scale', 'data', 'analytics'), ('data', 'analytics', 'also'), ('analytics', 'also', 'detailed'), ('also', 'detailed', 'discussion'), ('detailed', 'discussion', 'differences'), ('discussion', 'differences', 'data'), ('differences', 'data', 'big'), ('data', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', 'framework'), ('analytics', 'framework', 'data'), ('framework', 'data', 'scientists'), ('data', 'scientists', 'researchers'), ('scientists', 'researchers', 'focus'), ('researchers', 'focus', 'big'), ('focus', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', '.')]

>> POS Tags are: 
 [('To', 'TO'), ('discuss', 'VB'), ('deep', 'JJ'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), (',', ','), ('paper', 'NN'), ('gives', 'VBZ'), ('systematic', 'JJ'), ('description', 'NN'), ('traditional', 'JJ'), ('large-scale', 'JJ'), ('data', 'NN'), ('analytics', 'NNS'), ('also', 'RB'), ('detailed', 'JJ'), ('discussion', 'NN'), ('differences', 'NNS'), ('data', 'VBP'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('framework', 'VBP'), ('data', 'NNS'), ('scientists', 'NNS'), ('researchers', 'NNS'), ('focus', 'VBP'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['deep big data analytics', 'paper', 'systematic description', 'traditional large-scale data analytics', 'detailed discussion differences', 'big data analytics', 'data scientists researchers', 'big data analytics']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('To', 'to'), ('discuss', 'discuss'), ('deep', 'deep'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), (',', ','), ('paper', 'paper'), ('gives', 'give'), ('systematic', 'systemat'), ('description', 'descript'), ('traditional', 'tradit'), ('large-scale', 'large-scal'), ('data', 'data'), ('analytics', 'analyt'), ('also', 'also'), ('detailed', 'detail'), ('discussion', 'discuss'), ('differences', 'differ'), ('data', 'data'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('framework', 'framework'), ('data', 'data'), ('scientists', 'scientist'), ('researchers', 'research'), ('focus', 'focu'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('To', 'to'), ('discuss', 'discuss'), ('deep', 'deep'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), (',', ','), ('paper', 'paper'), ('gives', 'give'), ('systematic', 'systemat'), ('description', 'descript'), ('traditional', 'tradit'), ('large-scale', 'large-scal'), ('data', 'data'), ('analytics', 'analyt'), ('also', 'also'), ('detailed', 'detail'), ('discussion', 'discuss'), ('differences', 'differ'), ('data', 'data'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('framework', 'framework'), ('data', 'data'), ('scientists', 'scientist'), ('researchers', 'research'), ('focus', 'focus'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('.', '.')]

>> Lemmatization: 
 [('To', 'To'), ('discuss', 'discus'), ('deep', 'deep'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), (',', ','), ('paper', 'paper'), ('gives', 'give'), ('systematic', 'systematic'), ('description', 'description'), ('traditional', 'traditional'), ('large-scale', 'large-scale'), ('data', 'data'), ('analytics', 'analytics'), ('also', 'also'), ('detailed', 'detailed'), ('discussion', 'discussion'), ('differences', 'difference'), ('data', 'data'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('framework', 'framework'), ('data', 'data'), ('scientists', 'scientist'), ('researchers', 'researcher'), ('focus', 'focus'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('.', '.')]



========================================== PARAGRAPH 17 ===========================================

Moreover, although several data analytics and frameworks have been presented in  recent years, with their pros and cons being discussed in different studies, a complete  discussion from the perspective of data mining and knowledge discovery in data- bases still is needed. As a result, this paper is aimed at providing a brief review for the  

------------------- Sentence 1 -------------------

Moreover, although several data analytics and frameworks have been presented in  recent years, with their pros and cons being discussed in different studies, a complete  discussion from the perspective of data mining and knowledge discovery in data- bases still is needed.

>> Tokens are: 
 ['Moreover', ',', 'although', 'several', 'data', 'analytics', 'frameworks', 'presented', 'recent', 'years', ',', 'pros', 'cons', 'discussed', 'different', 'studies', ',', 'complete', 'discussion', 'perspective', 'data', 'mining', 'knowledge', 'discovery', 'data-', 'bases', 'still', 'needed', '.']

>> Bigrams are: 
 [('Moreover', ','), (',', 'although'), ('although', 'several'), ('several', 'data'), ('data', 'analytics'), ('analytics', 'frameworks'), ('frameworks', 'presented'), ('presented', 'recent'), ('recent', 'years'), ('years', ','), (',', 'pros'), ('pros', 'cons'), ('cons', 'discussed'), ('discussed', 'different'), ('different', 'studies'), ('studies', ','), (',', 'complete'), ('complete', 'discussion'), ('discussion', 'perspective'), ('perspective', 'data'), ('data', 'mining'), ('mining', 'knowledge'), ('knowledge', 'discovery'), ('discovery', 'data-'), ('data-', 'bases'), ('bases', 'still'), ('still', 'needed'), ('needed', '.')]

>> Trigrams are: 
 [('Moreover', ',', 'although'), (',', 'although', 'several'), ('although', 'several', 'data'), ('several', 'data', 'analytics'), ('data', 'analytics', 'frameworks'), ('analytics', 'frameworks', 'presented'), ('frameworks', 'presented', 'recent'), ('presented', 'recent', 'years'), ('recent', 'years', ','), ('years', ',', 'pros'), (',', 'pros', 'cons'), ('pros', 'cons', 'discussed'), ('cons', 'discussed', 'different'), ('discussed', 'different', 'studies'), ('different', 'studies', ','), ('studies', ',', 'complete'), (',', 'complete', 'discussion'), ('complete', 'discussion', 'perspective'), ('discussion', 'perspective', 'data'), ('perspective', 'data', 'mining'), ('data', 'mining', 'knowledge'), ('mining', 'knowledge', 'discovery'), ('knowledge', 'discovery', 'data-'), ('discovery', 'data-', 'bases'), ('data-', 'bases', 'still'), ('bases', 'still', 'needed'), ('still', 'needed', '.')]

>> POS Tags are: 
 [('Moreover', 'RB'), (',', ','), ('although', 'IN'), ('several', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('frameworks', 'NNS'), ('presented', 'VBN'), ('recent', 'JJ'), ('years', 'NNS'), (',', ','), ('pros', 'NNS'), ('cons', 'NNS'), ('discussed', 'VBD'), ('different', 'JJ'), ('studies', 'NNS'), (',', ','), ('complete', 'JJ'), ('discussion', 'NN'), ('perspective', 'NN'), ('data', 'NNS'), ('mining', 'NN'), ('knowledge', 'NN'), ('discovery', 'NN'), ('data-', 'NN'), ('bases', 'NNS'), ('still', 'RB'), ('needed', 'VBN'), ('.', '.')]

>> Noun Phrases are: 
 ['several data analytics frameworks', 'recent years', 'pros cons', 'different studies', 'complete discussion perspective data mining knowledge discovery data- bases']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Moreover', 'moreov'), (',', ','), ('although', 'although'), ('several', 'sever'), ('data', 'data'), ('analytics', 'analyt'), ('frameworks', 'framework'), ('presented', 'present'), ('recent', 'recent'), ('years', 'year'), (',', ','), ('pros', 'pro'), ('cons', 'con'), ('discussed', 'discuss'), ('different', 'differ'), ('studies', 'studi'), (',', ','), ('complete', 'complet'), ('discussion', 'discuss'), ('perspective', 'perspect'), ('data', 'data'), ('mining', 'mine'), ('knowledge', 'knowledg'), ('discovery', 'discoveri'), ('data-', 'data-'), ('bases', 'base'), ('still', 'still'), ('needed', 'need'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Moreover', 'moreov'), (',', ','), ('although', 'although'), ('several', 'sever'), ('data', 'data'), ('analytics', 'analyt'), ('frameworks', 'framework'), ('presented', 'present'), ('recent', 'recent'), ('years', 'year'), (',', ','), ('pros', 'pros'), ('cons', 'con'), ('discussed', 'discuss'), ('different', 'differ'), ('studies', 'studi'), (',', ','), ('complete', 'complet'), ('discussion', 'discuss'), ('perspective', 'perspect'), ('data', 'data'), ('mining', 'mine'), ('knowledge', 'knowledg'), ('discovery', 'discoveri'), ('data-', 'data-'), ('bases', 'base'), ('still', 'still'), ('needed', 'need'), ('.', '.')]

>> Lemmatization: 
 [('Moreover', 'Moreover'), (',', ','), ('although', 'although'), ('several', 'several'), ('data', 'data'), ('analytics', 'analytics'), ('frameworks', 'framework'), ('presented', 'presented'), ('recent', 'recent'), ('years', 'year'), (',', ','), ('pros', 'pro'), ('cons', 'con'), ('discussed', 'discussed'), ('different', 'different'), ('studies', 'study'), (',', ','), ('complete', 'complete'), ('discussion', 'discussion'), ('perspective', 'perspective'), ('data', 'data'), ('mining', 'mining'), ('knowledge', 'knowledge'), ('discovery', 'discovery'), ('data-', 'data-'), ('bases', 'base'), ('still', 'still'), ('needed', 'needed'), ('.', '.')]


------------------- Sentence 2 -------------------

As a result, this paper is aimed at providing a brief review for the

>> Tokens are: 
 ['As', 'result', ',', 'paper', 'aimed', 'providing', 'brief', 'review']

>> Bigrams are: 
 [('As', 'result'), ('result', ','), (',', 'paper'), ('paper', 'aimed'), ('aimed', 'providing'), ('providing', 'brief'), ('brief', 'review')]

>> Trigrams are: 
 [('As', 'result', ','), ('result', ',', 'paper'), (',', 'paper', 'aimed'), ('paper', 'aimed', 'providing'), ('aimed', 'providing', 'brief'), ('providing', 'brief', 'review')]

>> POS Tags are: 
 [('As', 'IN'), ('result', 'NN'), (',', ','), ('paper', 'NN'), ('aimed', 'VBN'), ('providing', 'VBG'), ('brief', 'JJ'), ('review', 'NN')]

>> Noun Phrases are: 
 ['result', 'paper', 'brief review']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('As', 'as'), ('result', 'result'), (',', ','), ('paper', 'paper'), ('aimed', 'aim'), ('providing', 'provid'), ('brief', 'brief'), ('review', 'review')]

>> Stemming using Snowball Stemmer: 
 [('As', 'as'), ('result', 'result'), (',', ','), ('paper', 'paper'), ('aimed', 'aim'), ('providing', 'provid'), ('brief', 'brief'), ('review', 'review')]

>> Lemmatization: 
 [('As', 'As'), ('result', 'result'), (',', ','), ('paper', 'paper'), ('aimed', 'aimed'), ('providing', 'providing'), ('brief', 'brief'), ('review', 'review')]



========================================== PARAGRAPH 18 ===========================================

 0 

------------------- Sentence 1 -------------------

 0

>> Tokens are: 
 ['0']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('0', 'CD')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('0', '0')]

>> Stemming using Snowball Stemmer: 
 [('0', '0')]

>> Lemmatization: 
 [('0', '0')]



========================================== PARAGRAPH 19 ===========================================

 25 

------------------- Sentence 1 -------------------

 25

>> Tokens are: 
 ['25']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('25', 'CD')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('25', '25')]

>> Stemming using Snowball Stemmer: 
 [('25', '25')]

>> Lemmatization: 
 [('25', '25')]



========================================== PARAGRAPH 20 ===========================================

 50 

------------------- Sentence 1 -------------------

 50

>> Tokens are: 
 ['50']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('50', 'CD')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('50', '50')]

>> Stemming using Snowball Stemmer: 
 [('50', '50')]

>> Lemmatization: 
 [('50', '50')]



========================================== PARAGRAPH 21 ===========================================

 75 

------------------- Sentence 1 -------------------

 75

>> Tokens are: 
 ['75']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('75', 'CD')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('75', '75')]

>> Stemming using Snowball Stemmer: 
 [('75', '75')]

>> Lemmatization: 
 [('75', '75')]



========================================== PARAGRAPH 22 ===========================================

 100 

------------------- Sentence 1 -------------------

 100

>> Tokens are: 
 ['100']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('100', 'CD')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('100', '100')]

>> Stemming using Snowball Stemmer: 
 [('100', '100')]

>> Lemmatization: 
 [('100', '100')]



========================================== PARAGRAPH 23 ===========================================

2012 2013 2014 2015 2016 2017 2018 

------------------- Sentence 1 -------------------

2012 2013 2014 2015 2016 2017 2018

>> Tokens are: 
 ['2012', '2013', '2014', '2015', '2016', '2017', '2018']

>> Bigrams are: 
 [('2012', '2013'), ('2013', '2014'), ('2014', '2015'), ('2015', '2016'), ('2016', '2017'), ('2017', '2018')]

>> Trigrams are: 
 [('2012', '2013', '2014'), ('2013', '2014', '2015'), ('2014', '2015', '2016'), ('2015', '2016', '2017'), ('2016', '2017', '2018')]

>> POS Tags are: 
 [('2012', 'CD'), ('2013', 'CD'), ('2014', 'CD'), ('2015', 'CD'), ('2016', 'CD'), ('2017', 'CD'), ('2018', 'CD')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('2012', '2012'), ('2013', '2013'), ('2014', '2014'), ('2015', '2015'), ('2016', '2016'), ('2017', '2017'), ('2018', '2018')]

>> Stemming using Snowball Stemmer: 
 [('2012', '2012'), ('2013', '2013'), ('2014', '2014'), ('2015', '2015'), ('2016', '2016'), ('2017', '2017'), ('2018', '2018')]

>> Lemmatization: 
 [('2012', '2012'), ('2013', '2013'), ('2014', '2014'), ('2015', '2015'), ('2016', '2016'), ('2017', '2017'), ('2018', '2018')]



========================================== PARAGRAPH 24 ===========================================

$U S 

------------------- Sentence 1 -------------------

$U S

>> Tokens are: 
 ['$', 'U', 'S']

>> Bigrams are: 
 [('$', 'U'), ('U', 'S')]

>> Trigrams are: 
 [('$', 'U', 'S')]

>> POS Tags are: 
 [('$', '$'), ('U', 'NNP'), ('S', 'NNP')]

>> Noun Phrases are: 
 ['U S']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('$', '$'), ('U', 'u'), ('S', 's')]

>> Stemming using Snowball Stemmer: 
 [('$', '$'), ('U', 'u'), ('S', 's')]

>> Lemmatization: 
 [('$', '$'), ('U', 'U'), ('S', 'S')]



========================================== PARAGRAPH 25 ===========================================

 B il 

------------------- Sentence 1 -------------------

 B il

>> Tokens are: 
 ['B', 'il']

>> Bigrams are: 
 [('B', 'il')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('B', 'NNP'), ('il', 'NN')]

>> Noun Phrases are: 
 ['B il']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('B', 'b'), ('il', 'il')]

>> Stemming using Snowball Stemmer: 
 [('B', 'b'), ('il', 'il')]

>> Lemmatization: 
 [('B', 'B'), ('il', 'il')]



========================================== PARAGRAPH 26 ===========================================

li on 

------------------- Sentence 1 -------------------

li on

>> Tokens are: 
 ['li']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('li', 'NN')]

>> Noun Phrases are: 
 ['li']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('li', 'li')]

>> Stemming using Snowball Stemmer: 
 [('li', 'li')]

>> Lemmatization: 
 [('li', 'li')]



========================================== PARAGRAPH 27 ===========================================

s 

------------------- Sentence 1 -------------------

s

>> Tokens are: 
 []

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 []

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 []

>> Stemming using Snowball Stemmer: 
 []

>> Lemmatization: 
 []



========================================== PARAGRAPH 28 ===========================================

[13] 

------------------- Sentence 1 -------------------

[13]

>> Tokens are: 
 ['[', '13', ']']

>> Bigrams are: 
 [('[', '13'), ('13', ']')]

>> Trigrams are: 
 [('[', '13', ']')]

>> POS Tags are: 
 [('[', 'RB'), ('13', 'CD'), (']', 'NNS')]

>> Noun Phrases are: 
 [']']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('13', '13'), (']', ']')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('13', '13'), (']', ']')]

>> Lemmatization: 
 [('[', '['), ('13', '13'), (']', ']')]



========================================== PARAGRAPH 29 ===========================================

[14] 

------------------- Sentence 1 -------------------

[14]

>> Tokens are: 
 ['[', '14', ']']

>> Bigrams are: 
 [('[', '14'), ('14', ']')]

>> Trigrams are: 
 [('[', '14', ']')]

>> POS Tags are: 
 [('[', 'RB'), ('14', 'CD'), (']', 'NNS')]

>> Noun Phrases are: 
 [']']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('14', '14'), (']', ']')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('14', '14'), (']', ']')]

>> Lemmatization: 
 [('[', '['), ('14', '14'), (']', ']')]



========================================== PARAGRAPH 30 ===========================================

[15] 

------------------- Sentence 1 -------------------

[15]

>> Tokens are: 
 ['[', '15', ']']

>> Bigrams are: 
 [('[', '15'), ('15', ']')]

>> Trigrams are: 
 [('[', '15', ']')]

>> POS Tags are: 
 [('[', 'RB'), ('15', 'CD'), (']', 'NNS')]

>> Noun Phrases are: 
 [']']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('15', '15'), (']', ']')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('15', '15'), (']', ']')]

>> Lemmatization: 
 [('[', '['), ('15', '15'), (']', ']')]



========================================== PARAGRAPH 31 ===========================================

[13] [15] [9] 

------------------- Sentence 1 -------------------

[13] [15] [9]

>> Tokens are: 
 ['[', '13', ']', '[', '15', ']', '[', '9', ']']

>> Bigrams are: 
 [('[', '13'), ('13', ']'), (']', '['), ('[', '15'), ('15', ']'), (']', '['), ('[', '9'), ('9', ']')]

>> Trigrams are: 
 [('[', '13', ']'), ('13', ']', '['), (']', '[', '15'), ('[', '15', ']'), ('15', ']', '['), (']', '[', '9'), ('[', '9', ']')]

>> POS Tags are: 
 [('[', 'RB'), ('13', 'CD'), (']', 'JJ'), ('[', '$'), ('15', 'CD'), (']', 'NNP'), ('[', 'VBD'), ('9', 'CD'), (']', 'NN')]

>> Noun Phrases are: 
 [']', ']']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('13', '13'), (']', ']'), ('[', '['), ('15', '15'), (']', ']'), ('[', '['), ('9', '9'), (']', ']')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('13', '13'), (']', ']'), ('[', '['), ('15', '15'), (']', ']'), ('[', '['), ('9', '9'), (']', ']')]

>> Lemmatization: 
 [('[', '['), ('13', '13'), (']', ']'), ('[', '['), ('15', '15'), (']', ']'), ('[', '['), ('9', '9'), (']', ']')]



========================================== PARAGRAPH 32 ===========================================

[15] 

------------------- Sentence 1 -------------------

[15]

>> Tokens are: 
 ['[', '15', ']']

>> Bigrams are: 
 [('[', '15'), ('15', ']')]

>> Trigrams are: 
 [('[', '15', ']')]

>> POS Tags are: 
 [('[', 'RB'), ('15', 'CD'), (']', 'NNS')]

>> Noun Phrases are: 
 [']']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('15', '15'), (']', ']')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('15', '15'), (']', ']')]

>> Lemmatization: 
 [('[', '['), ('15', '15'), (']', ']')]



========================================== PARAGRAPH 33 ===========================================

[15] 

------------------- Sentence 1 -------------------

[15]

>> Tokens are: 
 ['[', '15', ']']

>> Bigrams are: 
 [('[', '15'), ('15', ']')]

>> Trigrams are: 
 [('[', '15', ']')]

>> POS Tags are: 
 [('[', 'RB'), ('15', 'CD'), (']', 'NNS')]

>> Noun Phrases are: 
 [']']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('15', '15'), (']', ']')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('15', '15'), (']', ']')]

>> Lemmatization: 
 [('[', '['), ('15', '15'), (']', ']')]



========================================== PARAGRAPH 34 ===========================================

[15] 

------------------- Sentence 1 -------------------

[15]

>> Tokens are: 
 ['[', '15', ']']

>> Bigrams are: 
 [('[', '15'), ('15', ']')]

>> Trigrams are: 
 [('[', '15', ']')]

>> POS Tags are: 
 [('[', 'RB'), ('15', 'CD'), (']', 'NNS')]

>> Noun Phrases are: 
 [']']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('15', '15'), (']', ']')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('15', '15'), (']', ']')]

>> Lemmatization: 
 [('[', '['), ('15', '15'), (']', ']')]



========================================== PARAGRAPH 35 ===========================================

[10] 

------------------- Sentence 1 -------------------

[10]

>> Tokens are: 
 ['[', '10', ']']

>> Bigrams are: 
 [('[', '10'), ('10', ']')]

>> Trigrams are: 
 [('[', '10', ']')]

>> POS Tags are: 
 [('[', 'RB'), ('10', 'CD'), (']', 'NNS')]

>> Noun Phrases are: 
 [']']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('10', '10'), (']', ']')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('10', '10'), (']', ']')]

>> Lemmatization: 
 [('[', '['), ('10', '10'), (']', ']')]



========================================== PARAGRAPH 36 ===========================================

[13] [14] 

------------------- Sentence 1 -------------------

[13] [14]

>> Tokens are: 
 ['[', '13', ']', '[', '14', ']']

>> Bigrams are: 
 [('[', '13'), ('13', ']'), (']', '['), ('[', '14'), ('14', ']')]

>> Trigrams are: 
 [('[', '13', ']'), ('13', ']', '['), (']', '[', '14'), ('[', '14', ']')]

>> POS Tags are: 
 [('[', 'RB'), ('13', 'CD'), (']', 'JJ'), ('[', '$'), ('14', 'CD'), (']', 'NN')]

>> Noun Phrases are: 
 [']']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('13', '13'), (']', ']'), ('[', '['), ('14', '14'), (']', ']')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('13', '13'), (']', ']'), ('[', '['), ('14', '14'), (']', ']')]

>> Lemmatization: 
 [('[', '['), ('13', '13'), (']', ']'), ('[', '['), ('14', '14'), (']', ']')]



========================================== PARAGRAPH 37 ===========================================

[11] 

------------------- Sentence 1 -------------------

[11]

>> Tokens are: 
 ['[', '11', ']']

>> Bigrams are: 
 [('[', '11'), ('11', ']')]

>> Trigrams are: 
 [('[', '11', ']')]

>> POS Tags are: 
 [('[', 'RB'), ('11', 'CD'), (']', 'NNS')]

>> Noun Phrases are: 
 [']']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('11', '11'), (']', ']')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('11', '11'), (']', ']')]

>> Lemmatization: 
 [('[', '['), ('11', '11'), (']', ']')]



========================================== PARAGRAPH 38 ===========================================

[12] 

------------------- Sentence 1 -------------------

[12]

>> Tokens are: 
 ['[', '12', ']']

>> Bigrams are: 
 [('[', '12'), ('12', ']')]

>> Trigrams are: 
 [('[', '12', ']')]

>> POS Tags are: 
 [('[', 'RB'), ('12', 'CD'), (']', 'NNS')]

>> Noun Phrases are: 
 [']']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('12', '12'), (']', ']')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('12', '12'), (']', ']')]

>> Lemmatization: 
 [('[', '['), ('12', '12'), (']', ']')]



========================================== PARAGRAPH 39 ===========================================

Fig. 1 Expected trend of the marketing of big data between 2012 and 2018. Note that yellow, red, and blue of  different colored box represent the order of appearance of reference in this paper for particular year

------------------- Sentence 1 -------------------

Fig.

>> Tokens are: 
 ['Fig', '.']

>> Bigrams are: 
 [('Fig', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Fig', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Fig']

>> Named Entities are: 
 [('GPE', 'Fig')] 

>> Stemming using Porter Stemmer: 
 [('Fig', 'fig'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Fig', 'fig'), ('.', '.')]

>> Lemmatization: 
 [('Fig', 'Fig'), ('.', '.')]


------------------- Sentence 2 -------------------

1 Expected trend of the marketing of big data between 2012 and 2018.

>> Tokens are: 
 ['1', 'Expected', 'trend', 'marketing', 'big', 'data', '2012', '2018', '.']

>> Bigrams are: 
 [('1', 'Expected'), ('Expected', 'trend'), ('trend', 'marketing'), ('marketing', 'big'), ('big', 'data'), ('data', '2012'), ('2012', '2018'), ('2018', '.')]

>> Trigrams are: 
 [('1', 'Expected', 'trend'), ('Expected', 'trend', 'marketing'), ('trend', 'marketing', 'big'), ('marketing', 'big', 'data'), ('big', 'data', '2012'), ('data', '2012', '2018'), ('2012', '2018', '.')]

>> POS Tags are: 
 [('1', 'CD'), ('Expected', 'VBN'), ('trend', 'NN'), ('marketing', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('2012', 'CD'), ('2018', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['trend marketing', 'big data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('1', '1'), ('Expected', 'expect'), ('trend', 'trend'), ('marketing', 'market'), ('big', 'big'), ('data', 'data'), ('2012', '2012'), ('2018', '2018'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('1', '1'), ('Expected', 'expect'), ('trend', 'trend'), ('marketing', 'market'), ('big', 'big'), ('data', 'data'), ('2012', '2012'), ('2018', '2018'), ('.', '.')]

>> Lemmatization: 
 [('1', '1'), ('Expected', 'Expected'), ('trend', 'trend'), ('marketing', 'marketing'), ('big', 'big'), ('data', 'data'), ('2012', '2012'), ('2018', '2018'), ('.', '.')]


------------------- Sentence 3 -------------------

Note that yellow, red, and blue of  different colored box represent the order of appearance of reference in this paper for particular year

>> Tokens are: 
 ['Note', 'yellow', ',', 'red', ',', 'blue', 'different', 'colored', 'box', 'represent', 'order', 'appearance', 'reference', 'paper', 'particular', 'year']

>> Bigrams are: 
 [('Note', 'yellow'), ('yellow', ','), (',', 'red'), ('red', ','), (',', 'blue'), ('blue', 'different'), ('different', 'colored'), ('colored', 'box'), ('box', 'represent'), ('represent', 'order'), ('order', 'appearance'), ('appearance', 'reference'), ('reference', 'paper'), ('paper', 'particular'), ('particular', 'year')]

>> Trigrams are: 
 [('Note', 'yellow', ','), ('yellow', ',', 'red'), (',', 'red', ','), ('red', ',', 'blue'), (',', 'blue', 'different'), ('blue', 'different', 'colored'), ('different', 'colored', 'box'), ('colored', 'box', 'represent'), ('box', 'represent', 'order'), ('represent', 'order', 'appearance'), ('order', 'appearance', 'reference'), ('appearance', 'reference', 'paper'), ('reference', 'paper', 'particular'), ('paper', 'particular', 'year')]

>> POS Tags are: 
 [('Note', 'NNP'), ('yellow', 'NN'), (',', ','), ('red', 'JJ'), (',', ','), ('blue', 'JJ'), ('different', 'JJ'), ('colored', 'VBN'), ('box', 'NN'), ('represent', 'NN'), ('order', 'NN'), ('appearance', 'NN'), ('reference', 'NN'), ('paper', 'NN'), ('particular', 'JJ'), ('year', 'NN')]

>> Noun Phrases are: 
 ['Note yellow', 'box represent order appearance reference paper', 'particular year']

>> Named Entities are: 
 [('GPE', 'Note')] 

>> Stemming using Porter Stemmer: 
 [('Note', 'note'), ('yellow', 'yellow'), (',', ','), ('red', 'red'), (',', ','), ('blue', 'blue'), ('different', 'differ'), ('colored', 'color'), ('box', 'box'), ('represent', 'repres'), ('order', 'order'), ('appearance', 'appear'), ('reference', 'refer'), ('paper', 'paper'), ('particular', 'particular'), ('year', 'year')]

>> Stemming using Snowball Stemmer: 
 [('Note', 'note'), ('yellow', 'yellow'), (',', ','), ('red', 'red'), (',', ','), ('blue', 'blue'), ('different', 'differ'), ('colored', 'color'), ('box', 'box'), ('represent', 'repres'), ('order', 'order'), ('appearance', 'appear'), ('reference', 'refer'), ('paper', 'paper'), ('particular', 'particular'), ('year', 'year')]

>> Lemmatization: 
 [('Note', 'Note'), ('yellow', 'yellow'), (',', ','), ('red', 'red'), (',', ','), ('blue', 'blue'), ('different', 'different'), ('colored', 'colored'), ('box', 'box'), ('represent', 'represent'), ('order', 'order'), ('appearance', 'appearance'), ('reference', 'reference'), ('paper', 'paper'), ('particular', 'particular'), ('year', 'year')]



========================================== PARAGRAPH 40 ===========================================

Page 3 of 32Tsai et al. Journal of Big Data  (2015) 2:21  

------------------- Sentence 1 -------------------

Page 3 of 32Tsai et al.

>> Tokens are: 
 ['Page', '3', '32Tsai', 'et', 'al', '.']

>> Bigrams are: 
 [('Page', '3'), ('3', '32Tsai'), ('32Tsai', 'et'), ('et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('Page', '3', '32Tsai'), ('3', '32Tsai', 'et'), ('32Tsai', 'et', 'al'), ('et', 'al', '.')]

>> POS Tags are: 
 [('Page', 'NN'), ('3', 'CD'), ('32Tsai', 'CD'), ('et', 'NN'), ('al', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Page', 'et al']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Page', 'page'), ('3', '3'), ('32Tsai', '32tsai'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Page', 'page'), ('3', '3'), ('32Tsai', '32tsai'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('Page', 'Page'), ('3', '3'), ('32Tsai', '32Tsai'), ('et', 'et'), ('al', 'al'), ('.', '.')]


------------------- Sentence 2 -------------------

Journal of Big Data  (2015) 2:21

>> Tokens are: 
 ['Journal', 'Big', 'Data', '(', '2015', ')', '2:21']

>> Bigrams are: 
 [('Journal', 'Big'), ('Big', 'Data'), ('Data', '('), ('(', '2015'), ('2015', ')'), (')', '2:21')]

>> Trigrams are: 
 [('Journal', 'Big', 'Data'), ('Big', 'Data', '('), ('Data', '(', '2015'), ('(', '2015', ')'), ('2015', ')', '2:21')]

>> POS Tags are: 
 [('Journal', 'NNP'), ('Big', 'NNP'), ('Data', 'NNP'), ('(', '('), ('2015', 'CD'), (')', ')'), ('2:21', 'CD')]

>> Noun Phrases are: 
 ['Journal Big Data']

>> Named Entities are: 
 [('PERSON', 'Journal')] 

>> Stemming using Porter Stemmer: 
 [('Journal', 'journal'), ('Big', 'big'), ('Data', 'data'), ('(', '('), ('2015', '2015'), (')', ')'), ('2:21', '2:21')]

>> Stemming using Snowball Stemmer: 
 [('Journal', 'journal'), ('Big', 'big'), ('Data', 'data'), ('(', '('), ('2015', '2015'), (')', ')'), ('2:21', '2:21')]

>> Lemmatization: 
 [('Journal', 'Journal'), ('Big', 'Big'), ('Data', 'Data'), ('(', '('), ('2015', '2015'), (')', ')'), ('2:21', '2:21')]



========================================== PARAGRAPH 41 ===========================================

researchers on the data mining and distributed computing domains to have a basic idea  to use or develop data analytics for big data. 

------------------- Sentence 1 -------------------

researchers on the data mining and distributed computing domains to have a basic idea  to use or develop data analytics for big data.

>> Tokens are: 
 ['researchers', 'data', 'mining', 'distributed', 'computing', 'domains', 'basic', 'idea', 'use', 'develop', 'data', 'analytics', 'big', 'data', '.']

>> Bigrams are: 
 [('researchers', 'data'), ('data', 'mining'), ('mining', 'distributed'), ('distributed', 'computing'), ('computing', 'domains'), ('domains', 'basic'), ('basic', 'idea'), ('idea', 'use'), ('use', 'develop'), ('develop', 'data'), ('data', 'analytics'), ('analytics', 'big'), ('big', 'data'), ('data', '.')]

>> Trigrams are: 
 [('researchers', 'data', 'mining'), ('data', 'mining', 'distributed'), ('mining', 'distributed', 'computing'), ('distributed', 'computing', 'domains'), ('computing', 'domains', 'basic'), ('domains', 'basic', 'idea'), ('basic', 'idea', 'use'), ('idea', 'use', 'develop'), ('use', 'develop', 'data'), ('develop', 'data', 'analytics'), ('data', 'analytics', 'big'), ('analytics', 'big', 'data'), ('big', 'data', '.')]

>> POS Tags are: 
 [('researchers', 'NNS'), ('data', 'NNS'), ('mining', 'NN'), ('distributed', 'VBD'), ('computing', 'VBG'), ('domains', 'NNS'), ('basic', 'JJ'), ('idea', 'NN'), ('use', 'NN'), ('develop', 'VB'), ('data', 'NNS'), ('analytics', 'NNS'), ('big', 'JJ'), ('data', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['researchers data mining', 'domains', 'basic idea use', 'data analytics', 'big data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('researchers', 'research'), ('data', 'data'), ('mining', 'mine'), ('distributed', 'distribut'), ('computing', 'comput'), ('domains', 'domain'), ('basic', 'basic'), ('idea', 'idea'), ('use', 'use'), ('develop', 'develop'), ('data', 'data'), ('analytics', 'analyt'), ('big', 'big'), ('data', 'data'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('researchers', 'research'), ('data', 'data'), ('mining', 'mine'), ('distributed', 'distribut'), ('computing', 'comput'), ('domains', 'domain'), ('basic', 'basic'), ('idea', 'idea'), ('use', 'use'), ('develop', 'develop'), ('data', 'data'), ('analytics', 'analyt'), ('big', 'big'), ('data', 'data'), ('.', '.')]

>> Lemmatization: 
 [('researchers', 'researcher'), ('data', 'data'), ('mining', 'mining'), ('distributed', 'distributed'), ('computing', 'computing'), ('domains', 'domain'), ('basic', 'basic'), ('idea', 'idea'), ('use', 'use'), ('develop', 'develop'), ('data', 'data'), ('analytics', 'analytics'), ('big', 'big'), ('data', 'data'), ('.', '.')]



========================================== PARAGRAPH 42 ===========================================

Figure 2 shows the roadmap of this paper, and the remainder of the paper is organized  as follows. “Data analytics” begins with a brief introduction to the data analytics, and  then “Big data analytics” will turn to the discussion of big data analytics as well as state- of-the-art data analytics algorithms and frameworks. The open issues are discussed in  “The open issues” while the conclusions and future trends are drawn in “Conclusions”. 

------------------- Sentence 1 -------------------

Figure 2 shows the roadmap of this paper, and the remainder of the paper is organized  as follows.

>> Tokens are: 
 ['Figure', '2', 'shows', 'roadmap', 'paper', ',', 'remainder', 'paper', 'organized', 'follows', '.']

>> Bigrams are: 
 [('Figure', '2'), ('2', 'shows'), ('shows', 'roadmap'), ('roadmap', 'paper'), ('paper', ','), (',', 'remainder'), ('remainder', 'paper'), ('paper', 'organized'), ('organized', 'follows'), ('follows', '.')]

>> Trigrams are: 
 [('Figure', '2', 'shows'), ('2', 'shows', 'roadmap'), ('shows', 'roadmap', 'paper'), ('roadmap', 'paper', ','), ('paper', ',', 'remainder'), (',', 'remainder', 'paper'), ('remainder', 'paper', 'organized'), ('paper', 'organized', 'follows'), ('organized', 'follows', '.')]

>> POS Tags are: 
 [('Figure', 'NN'), ('2', 'CD'), ('shows', 'NNS'), ('roadmap', 'VBP'), ('paper', 'NN'), (',', ','), ('remainder', 'JJR'), ('paper', 'NN'), ('organized', 'VBN'), ('follows', 'VBZ'), ('.', '.')]

>> Noun Phrases are: 
 ['Figure', 'shows', 'paper', 'paper']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Figure', 'figur'), ('2', '2'), ('shows', 'show'), ('roadmap', 'roadmap'), ('paper', 'paper'), (',', ','), ('remainder', 'remaind'), ('paper', 'paper'), ('organized', 'organ'), ('follows', 'follow'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Figure', 'figur'), ('2', '2'), ('shows', 'show'), ('roadmap', 'roadmap'), ('paper', 'paper'), (',', ','), ('remainder', 'remaind'), ('paper', 'paper'), ('organized', 'organ'), ('follows', 'follow'), ('.', '.')]

>> Lemmatization: 
 [('Figure', 'Figure'), ('2', '2'), ('shows', 'show'), ('roadmap', 'roadmap'), ('paper', 'paper'), (',', ','), ('remainder', 'remainder'), ('paper', 'paper'), ('organized', 'organized'), ('follows', 'follows'), ('.', '.')]


------------------- Sentence 2 -------------------

“Data analytics” begins with a brief introduction to the data analytics, and  then “Big data analytics” will turn to the discussion of big data analytics as well as state- of-the-art data analytics algorithms and frameworks.

>> Tokens are: 
 ['“', 'Data', 'analytics', '”', 'begins', 'brief', 'introduction', 'data', 'analytics', ',', '“', 'Big', 'data', 'analytics', '”', 'turn', 'discussion', 'big', 'data', 'analytics', 'well', 'state-', 'of-the-art', 'data', 'analytics', 'algorithms', 'frameworks', '.']

>> Bigrams are: 
 [('“', 'Data'), ('Data', 'analytics'), ('analytics', '”'), ('”', 'begins'), ('begins', 'brief'), ('brief', 'introduction'), ('introduction', 'data'), ('data', 'analytics'), ('analytics', ','), (',', '“'), ('“', 'Big'), ('Big', 'data'), ('data', 'analytics'), ('analytics', '”'), ('”', 'turn'), ('turn', 'discussion'), ('discussion', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', 'well'), ('well', 'state-'), ('state-', 'of-the-art'), ('of-the-art', 'data'), ('data', 'analytics'), ('analytics', 'algorithms'), ('algorithms', 'frameworks'), ('frameworks', '.')]

>> Trigrams are: 
 [('“', 'Data', 'analytics'), ('Data', 'analytics', '”'), ('analytics', '”', 'begins'), ('”', 'begins', 'brief'), ('begins', 'brief', 'introduction'), ('brief', 'introduction', 'data'), ('introduction', 'data', 'analytics'), ('data', 'analytics', ','), ('analytics', ',', '“'), (',', '“', 'Big'), ('“', 'Big', 'data'), ('Big', 'data', 'analytics'), ('data', 'analytics', '”'), ('analytics', '”', 'turn'), ('”', 'turn', 'discussion'), ('turn', 'discussion', 'big'), ('discussion', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', 'well'), ('analytics', 'well', 'state-'), ('well', 'state-', 'of-the-art'), ('state-', 'of-the-art', 'data'), ('of-the-art', 'data', 'analytics'), ('data', 'analytics', 'algorithms'), ('analytics', 'algorithms', 'frameworks'), ('algorithms', 'frameworks', '.')]

>> POS Tags are: 
 [('“', 'NN'), ('Data', 'NNP'), ('analytics', 'NNS'), ('”', 'VBP'), ('begins', 'VBZ'), ('brief', 'JJ'), ('introduction', 'NN'), ('data', 'NNS'), ('analytics', 'NNS'), (',', ','), ('“', 'VBP'), ('Big', 'NNP'), ('data', 'NNS'), ('analytics', 'NNS'), ('”', 'JJ'), ('turn', 'VBP'), ('discussion', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('well', 'RB'), ('state-', 'JJ'), ('of-the-art', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('algorithms', 'JJ'), ('frameworks', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['“ Data analytics', 'brief introduction data analytics', 'Big data analytics', 'discussion', 'big data analytics', 'state- of-the-art data analytics', 'algorithms frameworks']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('“', '“'), ('Data', 'data'), ('analytics', 'analyt'), ('”', '”'), ('begins', 'begin'), ('brief', 'brief'), ('introduction', 'introduct'), ('data', 'data'), ('analytics', 'analyt'), (',', ','), ('“', '“'), ('Big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('”', '”'), ('turn', 'turn'), ('discussion', 'discuss'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('well', 'well'), ('state-', 'state-'), ('of-the-art', 'of-the-art'), ('data', 'data'), ('analytics', 'analyt'), ('algorithms', 'algorithm'), ('frameworks', 'framework'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('“', '“'), ('Data', 'data'), ('analytics', 'analyt'), ('”', '”'), ('begins', 'begin'), ('brief', 'brief'), ('introduction', 'introduct'), ('data', 'data'), ('analytics', 'analyt'), (',', ','), ('“', '“'), ('Big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('”', '”'), ('turn', 'turn'), ('discussion', 'discuss'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('well', 'well'), ('state-', 'state-'), ('of-the-art', 'of-the-art'), ('data', 'data'), ('analytics', 'analyt'), ('algorithms', 'algorithm'), ('frameworks', 'framework'), ('.', '.')]

>> Lemmatization: 
 [('“', '“'), ('Data', 'Data'), ('analytics', 'analytics'), ('”', '”'), ('begins', 'begin'), ('brief', 'brief'), ('introduction', 'introduction'), ('data', 'data'), ('analytics', 'analytics'), (',', ','), ('“', '“'), ('Big', 'Big'), ('data', 'data'), ('analytics', 'analytics'), ('”', '”'), ('turn', 'turn'), ('discussion', 'discussion'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('well', 'well'), ('state-', 'state-'), ('of-the-art', 'of-the-art'), ('data', 'data'), ('analytics', 'analytics'), ('algorithms', 'algorithm'), ('frameworks', 'framework'), ('.', '.')]


------------------- Sentence 3 -------------------

The open issues are discussed in  “The open issues” while the conclusions and future trends are drawn in “Conclusions”.

>> Tokens are: 
 ['The', 'open', 'issues', 'discussed', '“', 'The', 'open', 'issues', '”', 'conclusions', 'future', 'trends', 'drawn', '“', 'Conclusions', '”', '.']

>> Bigrams are: 
 [('The', 'open'), ('open', 'issues'), ('issues', 'discussed'), ('discussed', '“'), ('“', 'The'), ('The', 'open'), ('open', 'issues'), ('issues', '”'), ('”', 'conclusions'), ('conclusions', 'future'), ('future', 'trends'), ('trends', 'drawn'), ('drawn', '“'), ('“', 'Conclusions'), ('Conclusions', '”'), ('”', '.')]

>> Trigrams are: 
 [('The', 'open', 'issues'), ('open', 'issues', 'discussed'), ('issues', 'discussed', '“'), ('discussed', '“', 'The'), ('“', 'The', 'open'), ('The', 'open', 'issues'), ('open', 'issues', '”'), ('issues', '”', 'conclusions'), ('”', 'conclusions', 'future'), ('conclusions', 'future', 'trends'), ('future', 'trends', 'drawn'), ('trends', 'drawn', '“'), ('drawn', '“', 'Conclusions'), ('“', 'Conclusions', '”'), ('Conclusions', '”', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('open', 'JJ'), ('issues', 'NNS'), ('discussed', 'VBN'), ('“', 'IN'), ('The', 'DT'), ('open', 'JJ'), ('issues', 'NNS'), ('”', 'VBP'), ('conclusions', 'NNS'), ('future', 'JJ'), ('trends', 'NNS'), ('drawn', 'VBN'), ('“', 'JJ'), ('Conclusions', 'NNP'), ('”', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['The open issues', 'The open issues', 'conclusions', 'future trends', '“ Conclusions ”']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('open', 'open'), ('issues', 'issu'), ('discussed', 'discuss'), ('“', '“'), ('The', 'the'), ('open', 'open'), ('issues', 'issu'), ('”', '”'), ('conclusions', 'conclus'), ('future', 'futur'), ('trends', 'trend'), ('drawn', 'drawn'), ('“', '“'), ('Conclusions', 'conclus'), ('”', '”'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('open', 'open'), ('issues', 'issu'), ('discussed', 'discuss'), ('“', '“'), ('The', 'the'), ('open', 'open'), ('issues', 'issu'), ('”', '”'), ('conclusions', 'conclus'), ('future', 'futur'), ('trends', 'trend'), ('drawn', 'drawn'), ('“', '“'), ('Conclusions', 'conclus'), ('”', '”'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('open', 'open'), ('issues', 'issue'), ('discussed', 'discussed'), ('“', '“'), ('The', 'The'), ('open', 'open'), ('issues', 'issue'), ('”', '”'), ('conclusions', 'conclusion'), ('future', 'future'), ('trends', 'trend'), ('drawn', 'drawn'), ('“', '“'), ('Conclusions', 'Conclusions'), ('”', '”'), ('.', '.')]



========================================== PARAGRAPH 43 ===========================================

Data analytics To make the whole process of knowledge discovery in databases (KDD) more clear,  Fayyad and his colleagues summarized the KDD process by a few operations in [19],  which are selection, preprocessing, transformation, data mining, and interpretation/ evaluation. As shown in Fig. 3, with these operators at hand we will be able to build a  complete data analytics system to gather data first and then find information from the  data and display the knowledge to the user. According to our observation, the number of  research articles and technical reports that focus on data mining is typically more than  the number focusing on other operators, but it does not mean that the other operators  of KDD are unimportant. The other operators also play the vital roles in KDD process  because they will strongly impact the final result of KDD. To make the discussions on  the main operators of KDD process more concise, the following sections will focus on  those depicted in Fig. 3, which were simplified to three parts (input, data analytics, and  output) and seven operators (gathering, selection, preprocessing, transformation, data  mining, evaluation, and interpretation). 

------------------- Sentence 1 -------------------

Data analytics To make the whole process of knowledge discovery in databases (KDD) more clear,  Fayyad and his colleagues summarized the KDD process by a few operations in [19],  which are selection, preprocessing, transformation, data mining, and interpretation/ evaluation.

>> Tokens are: 
 ['Data', 'analytics', 'To', 'make', 'whole', 'process', 'knowledge', 'discovery', 'databases', '(', 'KDD', ')', 'clear', ',', 'Fayyad', 'colleagues', 'summarized', 'KDD', 'process', 'operations', '[', '19', ']', ',', 'selection', ',', 'preprocessing', ',', 'transformation', ',', 'data', 'mining', ',', 'interpretation/', 'evaluation', '.']

>> Bigrams are: 
 [('Data', 'analytics'), ('analytics', 'To'), ('To', 'make'), ('make', 'whole'), ('whole', 'process'), ('process', 'knowledge'), ('knowledge', 'discovery'), ('discovery', 'databases'), ('databases', '('), ('(', 'KDD'), ('KDD', ')'), (')', 'clear'), ('clear', ','), (',', 'Fayyad'), ('Fayyad', 'colleagues'), ('colleagues', 'summarized'), ('summarized', 'KDD'), ('KDD', 'process'), ('process', 'operations'), ('operations', '['), ('[', '19'), ('19', ']'), (']', ','), (',', 'selection'), ('selection', ','), (',', 'preprocessing'), ('preprocessing', ','), (',', 'transformation'), ('transformation', ','), (',', 'data'), ('data', 'mining'), ('mining', ','), (',', 'interpretation/'), ('interpretation/', 'evaluation'), ('evaluation', '.')]

>> Trigrams are: 
 [('Data', 'analytics', 'To'), ('analytics', 'To', 'make'), ('To', 'make', 'whole'), ('make', 'whole', 'process'), ('whole', 'process', 'knowledge'), ('process', 'knowledge', 'discovery'), ('knowledge', 'discovery', 'databases'), ('discovery', 'databases', '('), ('databases', '(', 'KDD'), ('(', 'KDD', ')'), ('KDD', ')', 'clear'), (')', 'clear', ','), ('clear', ',', 'Fayyad'), (',', 'Fayyad', 'colleagues'), ('Fayyad', 'colleagues', 'summarized'), ('colleagues', 'summarized', 'KDD'), ('summarized', 'KDD', 'process'), ('KDD', 'process', 'operations'), ('process', 'operations', '['), ('operations', '[', '19'), ('[', '19', ']'), ('19', ']', ','), (']', ',', 'selection'), (',', 'selection', ','), ('selection', ',', 'preprocessing'), (',', 'preprocessing', ','), ('preprocessing', ',', 'transformation'), (',', 'transformation', ','), ('transformation', ',', 'data'), (',', 'data', 'mining'), ('data', 'mining', ','), ('mining', ',', 'interpretation/'), (',', 'interpretation/', 'evaluation'), ('interpretation/', 'evaluation', '.')]

>> POS Tags are: 
 [('Data', 'NNP'), ('analytics', 'NNS'), ('To', 'TO'), ('make', 'VB'), ('whole', 'JJ'), ('process', 'NN'), ('knowledge', 'NN'), ('discovery', 'NN'), ('databases', 'NNS'), ('(', '('), ('KDD', 'NNP'), (')', ')'), ('clear', 'VBP'), (',', ','), ('Fayyad', 'NNP'), ('colleagues', 'NNS'), ('summarized', 'VBD'), ('KDD', 'NNP'), ('process', 'NN'), ('operations', 'NNS'), ('[', 'VBP'), ('19', 'CD'), (']', 'NN'), (',', ','), ('selection', 'NN'), (',', ','), ('preprocessing', 'NN'), (',', ','), ('transformation', 'NN'), (',', ','), ('data', 'NN'), ('mining', 'NN'), (',', ','), ('interpretation/', 'JJ'), ('evaluation', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Data analytics', 'whole process knowledge discovery databases', 'KDD', 'Fayyad colleagues', 'KDD process operations', ']', 'selection', 'preprocessing', 'transformation', 'data mining', 'interpretation/ evaluation']

>> Named Entities are: 
 [('GPE', 'Data'), ('ORGANIZATION', 'KDD'), ('GPE', 'Fayyad'), ('ORGANIZATION', 'KDD')] 

>> Stemming using Porter Stemmer: 
 [('Data', 'data'), ('analytics', 'analyt'), ('To', 'to'), ('make', 'make'), ('whole', 'whole'), ('process', 'process'), ('knowledge', 'knowledg'), ('discovery', 'discoveri'), ('databases', 'databas'), ('(', '('), ('KDD', 'kdd'), (')', ')'), ('clear', 'clear'), (',', ','), ('Fayyad', 'fayyad'), ('colleagues', 'colleagu'), ('summarized', 'summar'), ('KDD', 'kdd'), ('process', 'process'), ('operations', 'oper'), ('[', '['), ('19', '19'), (']', ']'), (',', ','), ('selection', 'select'), (',', ','), ('preprocessing', 'preprocess'), (',', ','), ('transformation', 'transform'), (',', ','), ('data', 'data'), ('mining', 'mine'), (',', ','), ('interpretation/', 'interpretation/'), ('evaluation', 'evalu'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Data', 'data'), ('analytics', 'analyt'), ('To', 'to'), ('make', 'make'), ('whole', 'whole'), ('process', 'process'), ('knowledge', 'knowledg'), ('discovery', 'discoveri'), ('databases', 'databas'), ('(', '('), ('KDD', 'kdd'), (')', ')'), ('clear', 'clear'), (',', ','), ('Fayyad', 'fayyad'), ('colleagues', 'colleagu'), ('summarized', 'summar'), ('KDD', 'kdd'), ('process', 'process'), ('operations', 'oper'), ('[', '['), ('19', '19'), (']', ']'), (',', ','), ('selection', 'select'), (',', ','), ('preprocessing', 'preprocess'), (',', ','), ('transformation', 'transform'), (',', ','), ('data', 'data'), ('mining', 'mine'), (',', ','), ('interpretation/', 'interpretation/'), ('evaluation', 'evalu'), ('.', '.')]

>> Lemmatization: 
 [('Data', 'Data'), ('analytics', 'analytics'), ('To', 'To'), ('make', 'make'), ('whole', 'whole'), ('process', 'process'), ('knowledge', 'knowledge'), ('discovery', 'discovery'), ('databases', 'database'), ('(', '('), ('KDD', 'KDD'), (')', ')'), ('clear', 'clear'), (',', ','), ('Fayyad', 'Fayyad'), ('colleagues', 'colleague'), ('summarized', 'summarized'), ('KDD', 'KDD'), ('process', 'process'), ('operations', 'operation'), ('[', '['), ('19', '19'), (']', ']'), (',', ','), ('selection', 'selection'), (',', ','), ('preprocessing', 'preprocessing'), (',', ','), ('transformation', 'transformation'), (',', ','), ('data', 'data'), ('mining', 'mining'), (',', ','), ('interpretation/', 'interpretation/'), ('evaluation', 'evaluation'), ('.', '.')]


------------------- Sentence 2 -------------------

As shown in Fig.

>> Tokens are: 
 ['As', 'shown', 'Fig', '.']

>> Bigrams are: 
 [('As', 'shown'), ('shown', 'Fig'), ('Fig', '.')]

>> Trigrams are: 
 [('As', 'shown', 'Fig'), ('shown', 'Fig', '.')]

>> POS Tags are: 
 [('As', 'IN'), ('shown', 'VBN'), ('Fig', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Fig']

>> Named Entities are: 
 [('PERSON', 'Fig')] 

>> Stemming using Porter Stemmer: 
 [('As', 'as'), ('shown', 'shown'), ('Fig', 'fig'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('As', 'as'), ('shown', 'shown'), ('Fig', 'fig'), ('.', '.')]

>> Lemmatization: 
 [('As', 'As'), ('shown', 'shown'), ('Fig', 'Fig'), ('.', '.')]


------------------- Sentence 3 -------------------

3, with these operators at hand we will be able to build a  complete data analytics system to gather data first and then find information from the  data and display the knowledge to the user.

>> Tokens are: 
 ['3', ',', 'operators', 'hand', 'able', 'build', 'complete', 'data', 'analytics', 'system', 'gather', 'data', 'first', 'find', 'information', 'data', 'display', 'knowledge', 'user', '.']

>> Bigrams are: 
 [('3', ','), (',', 'operators'), ('operators', 'hand'), ('hand', 'able'), ('able', 'build'), ('build', 'complete'), ('complete', 'data'), ('data', 'analytics'), ('analytics', 'system'), ('system', 'gather'), ('gather', 'data'), ('data', 'first'), ('first', 'find'), ('find', 'information'), ('information', 'data'), ('data', 'display'), ('display', 'knowledge'), ('knowledge', 'user'), ('user', '.')]

>> Trigrams are: 
 [('3', ',', 'operators'), (',', 'operators', 'hand'), ('operators', 'hand', 'able'), ('hand', 'able', 'build'), ('able', 'build', 'complete'), ('build', 'complete', 'data'), ('complete', 'data', 'analytics'), ('data', 'analytics', 'system'), ('analytics', 'system', 'gather'), ('system', 'gather', 'data'), ('gather', 'data', 'first'), ('data', 'first', 'find'), ('first', 'find', 'information'), ('find', 'information', 'data'), ('information', 'data', 'display'), ('data', 'display', 'knowledge'), ('display', 'knowledge', 'user'), ('knowledge', 'user', '.')]

>> POS Tags are: 
 [('3', 'CD'), (',', ','), ('operators', 'NNS'), ('hand', 'NN'), ('able', 'JJ'), ('build', 'NN'), ('complete', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('system', 'NN'), ('gather', 'NN'), ('data', 'NNS'), ('first', 'RB'), ('find', 'VBP'), ('information', 'NN'), ('data', 'NNS'), ('display', 'NN'), ('knowledge', 'NN'), ('user', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['operators hand', 'able build', 'complete data analytics system gather data', 'information data display knowledge user']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('3', '3'), (',', ','), ('operators', 'oper'), ('hand', 'hand'), ('able', 'abl'), ('build', 'build'), ('complete', 'complet'), ('data', 'data'), ('analytics', 'analyt'), ('system', 'system'), ('gather', 'gather'), ('data', 'data'), ('first', 'first'), ('find', 'find'), ('information', 'inform'), ('data', 'data'), ('display', 'display'), ('knowledge', 'knowledg'), ('user', 'user'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('3', '3'), (',', ','), ('operators', 'oper'), ('hand', 'hand'), ('able', 'abl'), ('build', 'build'), ('complete', 'complet'), ('data', 'data'), ('analytics', 'analyt'), ('system', 'system'), ('gather', 'gather'), ('data', 'data'), ('first', 'first'), ('find', 'find'), ('information', 'inform'), ('data', 'data'), ('display', 'display'), ('knowledge', 'knowledg'), ('user', 'user'), ('.', '.')]

>> Lemmatization: 
 [('3', '3'), (',', ','), ('operators', 'operator'), ('hand', 'hand'), ('able', 'able'), ('build', 'build'), ('complete', 'complete'), ('data', 'data'), ('analytics', 'analytics'), ('system', 'system'), ('gather', 'gather'), ('data', 'data'), ('first', 'first'), ('find', 'find'), ('information', 'information'), ('data', 'data'), ('display', 'display'), ('knowledge', 'knowledge'), ('user', 'user'), ('.', '.')]


------------------- Sentence 4 -------------------

According to our observation, the number of  research articles and technical reports that focus on data mining is typically more than  the number focusing on other operators, but it does not mean that the other operators  of KDD are unimportant.

>> Tokens are: 
 ['According', 'observation', ',', 'number', 'research', 'articles', 'technical', 'reports', 'focus', 'data', 'mining', 'typically', 'number', 'focusing', 'operators', ',', 'mean', 'operators', 'KDD', 'unimportant', '.']

>> Bigrams are: 
 [('According', 'observation'), ('observation', ','), (',', 'number'), ('number', 'research'), ('research', 'articles'), ('articles', 'technical'), ('technical', 'reports'), ('reports', 'focus'), ('focus', 'data'), ('data', 'mining'), ('mining', 'typically'), ('typically', 'number'), ('number', 'focusing'), ('focusing', 'operators'), ('operators', ','), (',', 'mean'), ('mean', 'operators'), ('operators', 'KDD'), ('KDD', 'unimportant'), ('unimportant', '.')]

>> Trigrams are: 
 [('According', 'observation', ','), ('observation', ',', 'number'), (',', 'number', 'research'), ('number', 'research', 'articles'), ('research', 'articles', 'technical'), ('articles', 'technical', 'reports'), ('technical', 'reports', 'focus'), ('reports', 'focus', 'data'), ('focus', 'data', 'mining'), ('data', 'mining', 'typically'), ('mining', 'typically', 'number'), ('typically', 'number', 'focusing'), ('number', 'focusing', 'operators'), ('focusing', 'operators', ','), ('operators', ',', 'mean'), (',', 'mean', 'operators'), ('mean', 'operators', 'KDD'), ('operators', 'KDD', 'unimportant'), ('KDD', 'unimportant', '.')]

>> POS Tags are: 
 [('According', 'VBG'), ('observation', 'NN'), (',', ','), ('number', 'NN'), ('research', 'NN'), ('articles', 'VBZ'), ('technical', 'JJ'), ('reports', 'NNS'), ('focus', 'NN'), ('data', 'NNS'), ('mining', 'NN'), ('typically', 'RB'), ('number', 'NN'), ('focusing', 'NN'), ('operators', 'NNS'), (',', ','), ('mean', 'NN'), ('operators', 'NNS'), ('KDD', 'NNP'), ('unimportant', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['observation', 'number research', 'technical reports focus data mining', 'number focusing operators', 'mean operators KDD unimportant']

>> Named Entities are: 
 [('ORGANIZATION', 'KDD')] 

>> Stemming using Porter Stemmer: 
 [('According', 'accord'), ('observation', 'observ'), (',', ','), ('number', 'number'), ('research', 'research'), ('articles', 'articl'), ('technical', 'technic'), ('reports', 'report'), ('focus', 'focu'), ('data', 'data'), ('mining', 'mine'), ('typically', 'typic'), ('number', 'number'), ('focusing', 'focus'), ('operators', 'oper'), (',', ','), ('mean', 'mean'), ('operators', 'oper'), ('KDD', 'kdd'), ('unimportant', 'unimport'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('According', 'accord'), ('observation', 'observ'), (',', ','), ('number', 'number'), ('research', 'research'), ('articles', 'articl'), ('technical', 'technic'), ('reports', 'report'), ('focus', 'focus'), ('data', 'data'), ('mining', 'mine'), ('typically', 'typic'), ('number', 'number'), ('focusing', 'focus'), ('operators', 'oper'), (',', ','), ('mean', 'mean'), ('operators', 'oper'), ('KDD', 'kdd'), ('unimportant', 'unimport'), ('.', '.')]

>> Lemmatization: 
 [('According', 'According'), ('observation', 'observation'), (',', ','), ('number', 'number'), ('research', 'research'), ('articles', 'article'), ('technical', 'technical'), ('reports', 'report'), ('focus', 'focus'), ('data', 'data'), ('mining', 'mining'), ('typically', 'typically'), ('number', 'number'), ('focusing', 'focusing'), ('operators', 'operator'), (',', ','), ('mean', 'mean'), ('operators', 'operator'), ('KDD', 'KDD'), ('unimportant', 'unimportant'), ('.', '.')]


------------------- Sentence 5 -------------------

The other operators also play the vital roles in KDD process  because they will strongly impact the final result of KDD.

>> Tokens are: 
 ['The', 'operators', 'also', 'play', 'vital', 'roles', 'KDD', 'process', 'strongly', 'impact', 'final', 'result', 'KDD', '.']

>> Bigrams are: 
 [('The', 'operators'), ('operators', 'also'), ('also', 'play'), ('play', 'vital'), ('vital', 'roles'), ('roles', 'KDD'), ('KDD', 'process'), ('process', 'strongly'), ('strongly', 'impact'), ('impact', 'final'), ('final', 'result'), ('result', 'KDD'), ('KDD', '.')]

>> Trigrams are: 
 [('The', 'operators', 'also'), ('operators', 'also', 'play'), ('also', 'play', 'vital'), ('play', 'vital', 'roles'), ('vital', 'roles', 'KDD'), ('roles', 'KDD', 'process'), ('KDD', 'process', 'strongly'), ('process', 'strongly', 'impact'), ('strongly', 'impact', 'final'), ('impact', 'final', 'result'), ('final', 'result', 'KDD'), ('result', 'KDD', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('operators', 'NNS'), ('also', 'RB'), ('play', 'VBP'), ('vital', 'JJ'), ('roles', 'NNS'), ('KDD', 'NNP'), ('process', 'NN'), ('strongly', 'RB'), ('impact', 'JJ'), ('final', 'JJ'), ('result', 'NN'), ('KDD', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['The operators', 'vital roles KDD process', 'impact final result KDD']

>> Named Entities are: 
 [('ORGANIZATION', 'KDD'), ('ORGANIZATION', 'KDD')] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('operators', 'oper'), ('also', 'also'), ('play', 'play'), ('vital', 'vital'), ('roles', 'role'), ('KDD', 'kdd'), ('process', 'process'), ('strongly', 'strongli'), ('impact', 'impact'), ('final', 'final'), ('result', 'result'), ('KDD', 'kdd'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('operators', 'oper'), ('also', 'also'), ('play', 'play'), ('vital', 'vital'), ('roles', 'role'), ('KDD', 'kdd'), ('process', 'process'), ('strongly', 'strong'), ('impact', 'impact'), ('final', 'final'), ('result', 'result'), ('KDD', 'kdd'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('operators', 'operator'), ('also', 'also'), ('play', 'play'), ('vital', 'vital'), ('roles', 'role'), ('KDD', 'KDD'), ('process', 'process'), ('strongly', 'strongly'), ('impact', 'impact'), ('final', 'final'), ('result', 'result'), ('KDD', 'KDD'), ('.', '.')]


------------------- Sentence 6 -------------------

To make the discussions on  the main operators of KDD process more concise, the following sections will focus on  those depicted in Fig.

>> Tokens are: 
 ['To', 'make', 'discussions', 'main', 'operators', 'KDD', 'process', 'concise', ',', 'following', 'sections', 'focus', 'depicted', 'Fig', '.']

>> Bigrams are: 
 [('To', 'make'), ('make', 'discussions'), ('discussions', 'main'), ('main', 'operators'), ('operators', 'KDD'), ('KDD', 'process'), ('process', 'concise'), ('concise', ','), (',', 'following'), ('following', 'sections'), ('sections', 'focus'), ('focus', 'depicted'), ('depicted', 'Fig'), ('Fig', '.')]

>> Trigrams are: 
 [('To', 'make', 'discussions'), ('make', 'discussions', 'main'), ('discussions', 'main', 'operators'), ('main', 'operators', 'KDD'), ('operators', 'KDD', 'process'), ('KDD', 'process', 'concise'), ('process', 'concise', ','), ('concise', ',', 'following'), (',', 'following', 'sections'), ('following', 'sections', 'focus'), ('sections', 'focus', 'depicted'), ('focus', 'depicted', 'Fig'), ('depicted', 'Fig', '.')]

>> POS Tags are: 
 [('To', 'TO'), ('make', 'VB'), ('discussions', 'NNS'), ('main', 'JJ'), ('operators', 'NNS'), ('KDD', 'NNP'), ('process', 'NN'), ('concise', 'NN'), (',', ','), ('following', 'VBG'), ('sections', 'NNS'), ('focus', 'RB'), ('depicted', 'VBD'), ('Fig', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['discussions', 'main operators KDD process concise', 'sections', 'Fig']

>> Named Entities are: 
 [('ORGANIZATION', 'KDD'), ('PERSON', 'Fig')] 

>> Stemming using Porter Stemmer: 
 [('To', 'to'), ('make', 'make'), ('discussions', 'discuss'), ('main', 'main'), ('operators', 'oper'), ('KDD', 'kdd'), ('process', 'process'), ('concise', 'concis'), (',', ','), ('following', 'follow'), ('sections', 'section'), ('focus', 'focu'), ('depicted', 'depict'), ('Fig', 'fig'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('To', 'to'), ('make', 'make'), ('discussions', 'discuss'), ('main', 'main'), ('operators', 'oper'), ('KDD', 'kdd'), ('process', 'process'), ('concise', 'concis'), (',', ','), ('following', 'follow'), ('sections', 'section'), ('focus', 'focus'), ('depicted', 'depict'), ('Fig', 'fig'), ('.', '.')]

>> Lemmatization: 
 [('To', 'To'), ('make', 'make'), ('discussions', 'discussion'), ('main', 'main'), ('operators', 'operator'), ('KDD', 'KDD'), ('process', 'process'), ('concise', 'concise'), (',', ','), ('following', 'following'), ('sections', 'section'), ('focus', 'focus'), ('depicted', 'depicted'), ('Fig', 'Fig'), ('.', '.')]


------------------- Sentence 7 -------------------

3, which were simplified to three parts (input, data analytics, and  output) and seven operators (gathering, selection, preprocessing, transformation, data  mining, evaluation, and interpretation).

>> Tokens are: 
 ['3', ',', 'simplified', 'three', 'parts', '(', 'input', ',', 'data', 'analytics', ',', 'output', ')', 'seven', 'operators', '(', 'gathering', ',', 'selection', ',', 'preprocessing', ',', 'transformation', ',', 'data', 'mining', ',', 'evaluation', ',', 'interpretation', ')', '.']

>> Bigrams are: 
 [('3', ','), (',', 'simplified'), ('simplified', 'three'), ('three', 'parts'), ('parts', '('), ('(', 'input'), ('input', ','), (',', 'data'), ('data', 'analytics'), ('analytics', ','), (',', 'output'), ('output', ')'), (')', 'seven'), ('seven', 'operators'), ('operators', '('), ('(', 'gathering'), ('gathering', ','), (',', 'selection'), ('selection', ','), (',', 'preprocessing'), ('preprocessing', ','), (',', 'transformation'), ('transformation', ','), (',', 'data'), ('data', 'mining'), ('mining', ','), (',', 'evaluation'), ('evaluation', ','), (',', 'interpretation'), ('interpretation', ')'), (')', '.')]

>> Trigrams are: 
 [('3', ',', 'simplified'), (',', 'simplified', 'three'), ('simplified', 'three', 'parts'), ('three', 'parts', '('), ('parts', '(', 'input'), ('(', 'input', ','), ('input', ',', 'data'), (',', 'data', 'analytics'), ('data', 'analytics', ','), ('analytics', ',', 'output'), (',', 'output', ')'), ('output', ')', 'seven'), (')', 'seven', 'operators'), ('seven', 'operators', '('), ('operators', '(', 'gathering'), ('(', 'gathering', ','), ('gathering', ',', 'selection'), (',', 'selection', ','), ('selection', ',', 'preprocessing'), (',', 'preprocessing', ','), ('preprocessing', ',', 'transformation'), (',', 'transformation', ','), ('transformation', ',', 'data'), (',', 'data', 'mining'), ('data', 'mining', ','), ('mining', ',', 'evaluation'), (',', 'evaluation', ','), ('evaluation', ',', 'interpretation'), (',', 'interpretation', ')'), ('interpretation', ')', '.')]

>> POS Tags are: 
 [('3', 'CD'), (',', ','), ('simplified', 'VBD'), ('three', 'CD'), ('parts', 'NNS'), ('(', '('), ('input', 'NN'), (',', ','), ('data', 'NN'), ('analytics', 'NNS'), (',', ','), ('output', 'NN'), (')', ')'), ('seven', 'CD'), ('operators', 'NNS'), ('(', '('), ('gathering', 'NN'), (',', ','), ('selection', 'NN'), (',', ','), ('preprocessing', 'NN'), (',', ','), ('transformation', 'NN'), (',', ','), ('data', 'NN'), ('mining', 'NN'), (',', ','), ('evaluation', 'NN'), (',', ','), ('interpretation', 'NN'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['parts', 'input', 'data analytics', 'output', 'operators', 'gathering', 'selection', 'preprocessing', 'transformation', 'data mining', 'evaluation', 'interpretation']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('3', '3'), (',', ','), ('simplified', 'simplifi'), ('three', 'three'), ('parts', 'part'), ('(', '('), ('input', 'input'), (',', ','), ('data', 'data'), ('analytics', 'analyt'), (',', ','), ('output', 'output'), (')', ')'), ('seven', 'seven'), ('operators', 'oper'), ('(', '('), ('gathering', 'gather'), (',', ','), ('selection', 'select'), (',', ','), ('preprocessing', 'preprocess'), (',', ','), ('transformation', 'transform'), (',', ','), ('data', 'data'), ('mining', 'mine'), (',', ','), ('evaluation', 'evalu'), (',', ','), ('interpretation', 'interpret'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('3', '3'), (',', ','), ('simplified', 'simplifi'), ('three', 'three'), ('parts', 'part'), ('(', '('), ('input', 'input'), (',', ','), ('data', 'data'), ('analytics', 'analyt'), (',', ','), ('output', 'output'), (')', ')'), ('seven', 'seven'), ('operators', 'oper'), ('(', '('), ('gathering', 'gather'), (',', ','), ('selection', 'select'), (',', ','), ('preprocessing', 'preprocess'), (',', ','), ('transformation', 'transform'), (',', ','), ('data', 'data'), ('mining', 'mine'), (',', ','), ('evaluation', 'evalu'), (',', ','), ('interpretation', 'interpret'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('3', '3'), (',', ','), ('simplified', 'simplified'), ('three', 'three'), ('parts', 'part'), ('(', '('), ('input', 'input'), (',', ','), ('data', 'data'), ('analytics', 'analytics'), (',', ','), ('output', 'output'), (')', ')'), ('seven', 'seven'), ('operators', 'operator'), ('(', '('), ('gathering', 'gathering'), (',', ','), ('selection', 'selection'), (',', ','), ('preprocessing', 'preprocessing'), (',', ','), ('transformation', 'transformation'), (',', ','), ('data', 'data'), ('mining', 'mining'), (',', ','), ('evaluation', 'evaluation'), (',', ','), ('interpretation', 'interpretation'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 44 ===========================================

Data input 

------------------- Sentence 1 -------------------

Data input

>> Tokens are: 
 ['Data', 'input']

>> Bigrams are: 
 [('Data', 'input')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Data', 'NNP'), ('input', 'NN')]

>> Noun Phrases are: 
 ['Data input']

>> Named Entities are: 
 [('GPE', 'Data')] 

>> Stemming using Porter Stemmer: 
 [('Data', 'data'), ('input', 'input')]

>> Stemming using Snowball Stemmer: 
 [('Data', 'data'), ('input', 'input')]

>> Lemmatization: 
 [('Data', 'Data'), ('input', 'input')]



========================================== PARAGRAPH 45 ===========================================

As shown in Fig. 3, the gathering, selection, preprocessing, and transformation opera- tors are in the input part. The selection operator usually plays the role of knowing which  

------------------- Sentence 1 -------------------

As shown in Fig.

>> Tokens are: 
 ['As', 'shown', 'Fig', '.']

>> Bigrams are: 
 [('As', 'shown'), ('shown', 'Fig'), ('Fig', '.')]

>> Trigrams are: 
 [('As', 'shown', 'Fig'), ('shown', 'Fig', '.')]

>> POS Tags are: 
 [('As', 'IN'), ('shown', 'VBN'), ('Fig', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Fig']

>> Named Entities are: 
 [('PERSON', 'Fig')] 

>> Stemming using Porter Stemmer: 
 [('As', 'as'), ('shown', 'shown'), ('Fig', 'fig'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('As', 'as'), ('shown', 'shown'), ('Fig', 'fig'), ('.', '.')]

>> Lemmatization: 
 [('As', 'As'), ('shown', 'shown'), ('Fig', 'Fig'), ('.', '.')]


------------------- Sentence 2 -------------------

3, the gathering, selection, preprocessing, and transformation opera- tors are in the input part.

>> Tokens are: 
 ['3', ',', 'gathering', ',', 'selection', ',', 'preprocessing', ',', 'transformation', 'opera-', 'tors', 'input', 'part', '.']

>> Bigrams are: 
 [('3', ','), (',', 'gathering'), ('gathering', ','), (',', 'selection'), ('selection', ','), (',', 'preprocessing'), ('preprocessing', ','), (',', 'transformation'), ('transformation', 'opera-'), ('opera-', 'tors'), ('tors', 'input'), ('input', 'part'), ('part', '.')]

>> Trigrams are: 
 [('3', ',', 'gathering'), (',', 'gathering', ','), ('gathering', ',', 'selection'), (',', 'selection', ','), ('selection', ',', 'preprocessing'), (',', 'preprocessing', ','), ('preprocessing', ',', 'transformation'), (',', 'transformation', 'opera-'), ('transformation', 'opera-', 'tors'), ('opera-', 'tors', 'input'), ('tors', 'input', 'part'), ('input', 'part', '.')]

>> POS Tags are: 
 [('3', 'CD'), (',', ','), ('gathering', 'NN'), (',', ','), ('selection', 'NN'), (',', ','), ('preprocessing', 'NN'), (',', ','), ('transformation', 'NN'), ('opera-', 'JJ'), ('tors', 'NNS'), ('input', 'VBP'), ('part', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['gathering', 'selection', 'preprocessing', 'transformation', 'opera- tors', 'part']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('3', '3'), (',', ','), ('gathering', 'gather'), (',', ','), ('selection', 'select'), (',', ','), ('preprocessing', 'preprocess'), (',', ','), ('transformation', 'transform'), ('opera-', 'opera-'), ('tors', 'tor'), ('input', 'input'), ('part', 'part'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('3', '3'), (',', ','), ('gathering', 'gather'), (',', ','), ('selection', 'select'), (',', ','), ('preprocessing', 'preprocess'), (',', ','), ('transformation', 'transform'), ('opera-', 'opera-'), ('tors', 'tor'), ('input', 'input'), ('part', 'part'), ('.', '.')]

>> Lemmatization: 
 [('3', '3'), (',', ','), ('gathering', 'gathering'), (',', ','), ('selection', 'selection'), (',', ','), ('preprocessing', 'preprocessing'), (',', ','), ('transformation', 'transformation'), ('opera-', 'opera-'), ('tors', 'tor'), ('input', 'input'), ('part', 'part'), ('.', '.')]


------------------- Sentence 3 -------------------

The selection operator usually plays the role of knowing which

>> Tokens are: 
 ['The', 'selection', 'operator', 'usually', 'plays', 'role', 'knowing']

>> Bigrams are: 
 [('The', 'selection'), ('selection', 'operator'), ('operator', 'usually'), ('usually', 'plays'), ('plays', 'role'), ('role', 'knowing')]

>> Trigrams are: 
 [('The', 'selection', 'operator'), ('selection', 'operator', 'usually'), ('operator', 'usually', 'plays'), ('usually', 'plays', 'role'), ('plays', 'role', 'knowing')]

>> POS Tags are: 
 [('The', 'DT'), ('selection', 'NN'), ('operator', 'NN'), ('usually', 'RB'), ('plays', 'VBZ'), ('role', 'NN'), ('knowing', 'VBG')]

>> Noun Phrases are: 
 ['The selection operator', 'role']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('selection', 'select'), ('operator', 'oper'), ('usually', 'usual'), ('plays', 'play'), ('role', 'role'), ('knowing', 'know')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('selection', 'select'), ('operator', 'oper'), ('usually', 'usual'), ('plays', 'play'), ('role', 'role'), ('knowing', 'know')]

>> Lemmatization: 
 [('The', 'The'), ('selection', 'selection'), ('operator', 'operator'), ('usually', 'usually'), ('plays', 'play'), ('role', 'role'), ('knowing', 'knowing')]



========================================== PARAGRAPH 46 ===========================================

Section II, III, and IV Section V and VI 

------------------- Sentence 1 -------------------

Section II, III, and IV Section V and VI

>> Tokens are: 
 ['Section', 'II', ',', 'III', ',', 'IV', 'Section', 'V', 'VI']

>> Bigrams are: 
 [('Section', 'II'), ('II', ','), (',', 'III'), ('III', ','), (',', 'IV'), ('IV', 'Section'), ('Section', 'V'), ('V', 'VI')]

>> Trigrams are: 
 [('Section', 'II', ','), ('II', ',', 'III'), (',', 'III', ','), ('III', ',', 'IV'), (',', 'IV', 'Section'), ('IV', 'Section', 'V'), ('Section', 'V', 'VI')]

>> POS Tags are: 
 [('Section', 'NN'), ('II', 'NNP'), (',', ','), ('III', 'NNP'), (',', ','), ('IV', 'NNP'), ('Section', 'NNP'), ('V', 'NNP'), ('VI', 'NNP')]

>> Noun Phrases are: 
 ['Section II', 'III', 'IV Section V VI']

>> Named Entities are: 
 [('ORGANIZATION', 'III'), ('ORGANIZATION', 'IV')] 

>> Stemming using Porter Stemmer: 
 [('Section', 'section'), ('II', 'ii'), (',', ','), ('III', 'iii'), (',', ','), ('IV', 'iv'), ('Section', 'section'), ('V', 'v'), ('VI', 'vi')]

>> Stemming using Snowball Stemmer: 
 [('Section', 'section'), ('II', 'ii'), (',', ','), ('III', 'iii'), (',', ','), ('IV', 'iv'), ('Section', 'section'), ('V', 'v'), ('VI', 'vi')]

>> Lemmatization: 
 [('Section', 'Section'), ('II', 'II'), (',', ','), ('III', 'III'), (',', ','), ('IV', 'IV'), ('Section', 'Section'), ('V', 'V'), ('VI', 'VI')]



========================================== PARAGRAPH 47 ===========================================

2. Solutions and Results sdnerTerutuFdnasammeliD.3smelborPdnasnoitavitoM.1 

------------------- Sentence 1 -------------------

2.

>> Tokens are: 
 ['2', '.']

>> Bigrams are: 
 [('2', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('2', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('2', '2'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('2', '2'), ('.', '.')]

>> Lemmatization: 
 [('2', '2'), ('.', '.')]


------------------- Sentence 2 -------------------

Solutions and Results sdnerTerutuFdnasammeliD.3smelborPdnasnoitavitoM.1

>> Tokens are: 
 ['Solutions', 'Results', 'sdnerTerutuFdnasammeliD.3smelborPdnasnoitavitoM.1']

>> Bigrams are: 
 [('Solutions', 'Results'), ('Results', 'sdnerTerutuFdnasammeliD.3smelborPdnasnoitavitoM.1')]

>> Trigrams are: 
 [('Solutions', 'Results', 'sdnerTerutuFdnasammeliD.3smelborPdnasnoitavitoM.1')]

>> POS Tags are: 
 [('Solutions', 'NNS'), ('Results', 'NNS'), ('sdnerTerutuFdnasammeliD.3smelborPdnasnoitavitoM.1', 'VBD')]

>> Noun Phrases are: 
 ['Solutions Results']

>> Named Entities are: 
 [('PERSON', 'Results')] 

>> Stemming using Porter Stemmer: 
 [('Solutions', 'solut'), ('Results', 'result'), ('sdnerTerutuFdnasammeliD.3smelborPdnasnoitavitoM.1', 'sdnerterutufdnasammelid.3smelborpdnasnoitavitom.1')]

>> Stemming using Snowball Stemmer: 
 [('Solutions', 'solut'), ('Results', 'result'), ('sdnerTerutuFdnasammeliD.3smelborPdnasnoitavitoM.1', 'sdnerterutufdnasammelid.3smelborpdnasnoitavitom.1')]

>> Lemmatization: 
 [('Solutions', 'Solutions'), ('Results', 'Results'), ('sdnerTerutuFdnasammeliD.3smelborPdnasnoitavitoM.1', 'sdnerTerutuFdnasammeliD.3smelborPdnasnoitavitoM.1')]



========================================== PARAGRAPH 48 ===========================================

Open Issues 

------------------- Sentence 1 -------------------

Open Issues

>> Tokens are: 
 ['Open', 'Issues']

>> Bigrams are: 
 [('Open', 'Issues')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Open', 'JJ'), ('Issues', 'NNP')]

>> Noun Phrases are: 
 ['Open Issues']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Open', 'open'), ('Issues', 'issu')]

>> Stemming using Snowball Stemmer: 
 [('Open', 'open'), ('Issues', 'issu')]

>> Lemmatization: 
 [('Open', 'Open'), ('Issues', 'Issues')]



========================================== PARAGRAPH 49 ===========================================

Future Trends 

------------------- Sentence 1 -------------------

Future Trends

>> Tokens are: 
 ['Future', 'Trends']

>> Bigrams are: 
 [('Future', 'Trends')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Future', 'JJ'), ('Trends', 'NNS')]

>> Noun Phrases are: 
 ['Future Trends']

>> Named Entities are: 
 [('GPE', 'Future'), ('ORGANIZATION', 'Trends')] 

>> Stemming using Porter Stemmer: 
 [('Future', 'futur'), ('Trends', 'trend')]

>> Stemming using Snowball Stemmer: 
 [('Future', 'futur'), ('Trends', 'trend')]

>> Lemmatization: 
 [('Future', 'Future'), ('Trends', 'Trends')]



========================================== PARAGRAPH 50 ===========================================

Big Data Analytics 

------------------- Sentence 1 -------------------

Big Data Analytics

>> Tokens are: 
 ['Big', 'Data', 'Analytics']

>> Bigrams are: 
 [('Big', 'Data'), ('Data', 'Analytics')]

>> Trigrams are: 
 [('Big', 'Data', 'Analytics')]

>> POS Tags are: 
 [('Big', 'NNP'), ('Data', 'NNP'), ('Analytics', 'NNS')]

>> Noun Phrases are: 
 ['Big Data Analytics']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('Data', 'data'), ('Analytics', 'analyt')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('Data', 'data'), ('Analytics', 'analyt')]

>> Lemmatization: 
 [('Big', 'Big'), ('Data', 'Data'), ('Analytics', 'Analytics')]



========================================== PARAGRAPH 51 ===========================================

Data analytics Data to Big Data 

------------------- Sentence 1 -------------------

Data analytics Data to Big Data

>> Tokens are: 
 ['Data', 'analytics', 'Data', 'Big', 'Data']

>> Bigrams are: 
 [('Data', 'analytics'), ('analytics', 'Data'), ('Data', 'Big'), ('Big', 'Data')]

>> Trigrams are: 
 [('Data', 'analytics', 'Data'), ('analytics', 'Data', 'Big'), ('Data', 'Big', 'Data')]

>> POS Tags are: 
 [('Data', 'NNP'), ('analytics', 'NNS'), ('Data', 'NNP'), ('Big', 'NNP'), ('Data', 'NNP')]

>> Noun Phrases are: 
 ['Data analytics Data Big Data']

>> Named Entities are: 
 [('GPE', 'Data'), ('PERSON', 'Data Big Data')] 

>> Stemming using Porter Stemmer: 
 [('Data', 'data'), ('analytics', 'analyt'), ('Data', 'data'), ('Big', 'big'), ('Data', 'data')]

>> Stemming using Snowball Stemmer: 
 [('Data', 'data'), ('analytics', 'analyt'), ('Data', 'data'), ('Big', 'big'), ('Data', 'data')]

>> Lemmatization: 
 [('Data', 'Data'), ('analytics', 'analytics'), ('Data', 'Data'), ('Big', 'Big'), ('Data', 'Data')]



========================================== PARAGRAPH 52 ===========================================

Importance of Big Data 

------------------- Sentence 1 -------------------

Importance of Big Data

>> Tokens are: 
 ['Importance', 'Big', 'Data']

>> Bigrams are: 
 [('Importance', 'Big'), ('Big', 'Data')]

>> Trigrams are: 
 [('Importance', 'Big', 'Data')]

>> POS Tags are: 
 [('Importance', 'NN'), ('Big', 'NNP'), ('Data', 'NNP')]

>> Noun Phrases are: 
 ['Importance Big Data']

>> Named Entities are: 
 [('GPE', 'Importance'), ('PERSON', 'Big Data')] 

>> Stemming using Porter Stemmer: 
 [('Importance', 'import'), ('Big', 'big'), ('Data', 'data')]

>> Stemming using Snowball Stemmer: 
 [('Importance', 'import'), ('Big', 'big'), ('Data', 'data')]

>> Lemmatization: 
 [('Importance', 'Importance'), ('Big', 'Big'), ('Data', 'Data')]



========================================== PARAGRAPH 53 ===========================================

Sections I 

------------------- Sentence 1 -------------------

Sections I

>> Tokens are: 
 ['Sections', 'I']

>> Bigrams are: 
 [('Sections', 'I')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Sections', 'NNS'), ('I', 'PRP')]

>> Noun Phrases are: 
 ['Sections']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Sections', 'section'), ('I', 'i')]

>> Stemming using Snowball Stemmer: 
 [('Sections', 'section'), ('I', 'i')]

>> Lemmatization: 
 [('Sections', 'Sections'), ('I', 'I')]



========================================== PARAGRAPH 54 ===========================================

Self−Learning Data Analytics 

------------------- Sentence 1 -------------------

Self−Learning Data Analytics

>> Tokens are: 
 ['Self−Learning', 'Data', 'Analytics']

>> Bigrams are: 
 [('Self−Learning', 'Data'), ('Data', 'Analytics')]

>> Trigrams are: 
 [('Self−Learning', 'Data', 'Analytics')]

>> POS Tags are: 
 [('Self−Learning', 'VBG'), ('Data', 'NNP'), ('Analytics', 'NNS')]

>> Noun Phrases are: 
 ['Data Analytics']

>> Named Entities are: 
 [('ORGANIZATION', 'Data')] 

>> Stemming using Porter Stemmer: 
 [('Self−Learning', 'self−learn'), ('Data', 'data'), ('Analytics', 'analyt')]

>> Stemming using Snowball Stemmer: 
 [('Self−Learning', 'self−learn'), ('Data', 'data'), ('Analytics', 'analyt')]

>> Lemmatization: 
 [('Self−Learning', 'Self−Learning'), ('Data', 'Data'), ('Analytics', 'Analytics')]



========================================== PARAGRAPH 55 ===========================================

Fig. 2 Roadmap of this paper 

------------------- Sentence 1 -------------------

Fig.

>> Tokens are: 
 ['Fig', '.']

>> Bigrams are: 
 [('Fig', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Fig', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Fig']

>> Named Entities are: 
 [('GPE', 'Fig')] 

>> Stemming using Porter Stemmer: 
 [('Fig', 'fig'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Fig', 'fig'), ('.', '.')]

>> Lemmatization: 
 [('Fig', 'Fig'), ('.', '.')]


------------------- Sentence 2 -------------------

2 Roadmap of this paper

>> Tokens are: 
 ['2', 'Roadmap', 'paper']

>> Bigrams are: 
 [('2', 'Roadmap'), ('Roadmap', 'paper')]

>> Trigrams are: 
 [('2', 'Roadmap', 'paper')]

>> POS Tags are: 
 [('2', 'CD'), ('Roadmap', 'NNP'), ('paper', 'NN')]

>> Noun Phrases are: 
 ['Roadmap paper']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('2', '2'), ('Roadmap', 'roadmap'), ('paper', 'paper')]

>> Stemming using Snowball Stemmer: 
 [('2', '2'), ('Roadmap', 'roadmap'), ('paper', 'paper')]

>> Lemmatization: 
 [('2', '2'), ('Roadmap', 'Roadmap'), ('paper', 'paper')]



========================================== PARAGRAPH 56 ===========================================

Selection Preprocessing 

------------------- Sentence 1 -------------------

Selection Preprocessing

>> Tokens are: 
 ['Selection', 'Preprocessing']

>> Bigrams are: 
 [('Selection', 'Preprocessing')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Selection', 'NN'), ('Preprocessing', 'VBG')]

>> Noun Phrases are: 
 ['Selection']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Selection', 'select'), ('Preprocessing', 'preprocess')]

>> Stemming using Snowball Stemmer: 
 [('Selection', 'select'), ('Preprocessing', 'preprocess')]

>> Lemmatization: 
 [('Selection', 'Selection'), ('Preprocessing', 'Preprocessing')]



========================================== PARAGRAPH 57 ===========================================

Transformation 2. Data Analysis 

------------------- Sentence 1 -------------------

Transformation 2.

>> Tokens are: 
 ['Transformation', '2', '.']

>> Bigrams are: 
 [('Transformation', '2'), ('2', '.')]

>> Trigrams are: 
 [('Transformation', '2', '.')]

>> POS Tags are: 
 [('Transformation', 'NN'), ('2', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Transformation']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Transformation', 'transform'), ('2', '2'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Transformation', 'transform'), ('2', '2'), ('.', '.')]

>> Lemmatization: 
 [('Transformation', 'Transformation'), ('2', '2'), ('.', '.')]


------------------- Sentence 2 -------------------

Data Analysis

>> Tokens are: 
 ['Data', 'Analysis']

>> Bigrams are: 
 [('Data', 'Analysis')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Data', 'NNS'), ('Analysis', 'NN')]

>> Noun Phrases are: 
 ['Data Analysis']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Data', 'data'), ('Analysis', 'analysi')]

>> Stemming using Snowball Stemmer: 
 [('Data', 'data'), ('Analysis', 'analysi')]

>> Lemmatization: 
 [('Data', 'Data'), ('Analysis', 'Analysis')]



========================================== PARAGRAPH 58 ===========================================

3. Output 

------------------- Sentence 1 -------------------

3.

>> Tokens are: 
 ['3', '.']

>> Bigrams are: 
 [('3', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('3', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('3', '3'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('3', '3'), ('.', '.')]

>> Lemmatization: 
 [('3', '3'), ('.', '.')]


------------------- Sentence 2 -------------------

Output

>> Tokens are: 
 ['Output']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Output', 'NN')]

>> Noun Phrases are: 
 ['Output']

>> Named Entities are: 
 [('GPE', 'Output')] 

>> Stemming using Porter Stemmer: 
 [('Output', 'output')]

>> Stemming using Snowball Stemmer: 
 [('Output', 'output')]

>> Lemmatization: 
 [('Output', 'Output')]



========================================== PARAGRAPH 59 ===========================================

1. Input 

------------------- Sentence 1 -------------------

1.

>> Tokens are: 
 ['1', '.']

>> Bigrams are: 
 [('1', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('1', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('1', '1'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('1', '1'), ('.', '.')]

>> Lemmatization: 
 [('1', '1'), ('.', '.')]


------------------- Sentence 2 -------------------

Input

>> Tokens are: 
 ['Input']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Input', 'NN')]

>> Noun Phrases are: 
 ['Input']

>> Named Entities are: 
 [('GPE', 'Input')] 

>> Stemming using Porter Stemmer: 
 [('Input', 'input')]

>> Stemming using Snowball Stemmer: 
 [('Input', 'input')]

>> Lemmatization: 
 [('Input', 'Input')]



========================================== PARAGRAPH 60 ===========================================

K n 

------------------- Sentence 1 -------------------

K n

>> Tokens are: 
 ['K', 'n']

>> Bigrams are: 
 [('K', 'n')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('K', 'NNP'), ('n', 'NN')]

>> Noun Phrases are: 
 ['K n']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('K', 'k'), ('n', 'n')]

>> Stemming using Snowball Stemmer: 
 [('K', 'k'), ('n', 'n')]

>> Lemmatization: 
 [('K', 'K'), ('n', 'n')]



========================================== PARAGRAPH 61 ===========================================

ow le 

------------------- Sentence 1 -------------------

ow le

>> Tokens are: 
 ['ow', 'le']

>> Bigrams are: 
 [('ow', 'le')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('ow', 'NN'), ('le', 'NN')]

>> Noun Phrases are: 
 ['ow le']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('ow', 'ow'), ('le', 'le')]

>> Stemming using Snowball Stemmer: 
 [('ow', 'ow'), ('le', 'le')]

>> Lemmatization: 
 [('ow', 'ow'), ('le', 'le')]



========================================== PARAGRAPH 62 ===========================================

d ge 

------------------- Sentence 1 -------------------

d ge

>> Tokens are: 
 ['ge']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('ge', 'NN')]

>> Noun Phrases are: 
 ['ge']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('ge', 'ge')]

>> Stemming using Snowball Stemmer: 
 [('ge', 'ge')]

>> Lemmatization: 
 [('ge', 'ge')]



========================================== PARAGRAPH 63 ===========================================

In fo 

------------------- Sentence 1 -------------------

In fo

>> Tokens are: 
 ['In', 'fo']

>> Bigrams are: 
 [('In', 'fo')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('In', 'IN'), ('fo', 'NN')]

>> Noun Phrases are: 
 ['fo']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('fo', 'fo')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('fo', 'fo')]

>> Lemmatization: 
 [('In', 'In'), ('fo', 'fo')]



========================================== PARAGRAPH 64 ===========================================

rm at 

------------------- Sentence 1 -------------------

rm at

>> Tokens are: 
 ['rm']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('rm', 'NN')]

>> Noun Phrases are: 
 ['rm']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('rm', 'rm')]

>> Stemming using Snowball Stemmer: 
 [('rm', 'rm')]

>> Lemmatization: 
 [('rm', 'rm')]



========================================== PARAGRAPH 65 ===========================================

io n 

------------------- Sentence 1 -------------------

io n

>> Tokens are: 
 ['io', 'n']

>> Bigrams are: 
 [('io', 'n')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('io', 'NN'), ('n', 'NN')]

>> Noun Phrases are: 
 ['io n']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('io', 'io'), ('n', 'n')]

>> Stemming using Snowball Stemmer: 
 [('io', 'io'), ('n', 'n')]

>> Lemmatization: 
 [('io', 'io'), ('n', 'n')]



========================================== PARAGRAPH 66 ===========================================

D at 

------------------- Sentence 1 -------------------

D at

>> Tokens are: 
 ['D']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('D', 'NN')]

>> Noun Phrases are: 
 ['D']

>> Named Entities are: 
 [('GPE', 'D')] 

>> Stemming using Porter Stemmer: 
 [('D', 'd')]

>> Stemming using Snowball Stemmer: 
 [('D', 'd')]

>> Lemmatization: 
 [('D', 'D')]



========================================== PARAGRAPH 67 ===========================================

a 

------------------- Sentence 1 -------------------

a

>> Tokens are: 
 []

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 []

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 []

>> Stemming using Snowball Stemmer: 
 []

>> Lemmatization: 
 []



========================================== PARAGRAPH 68 ===========================================

R aw 

------------------- Sentence 1 -------------------

R aw

>> Tokens are: 
 ['R', 'aw']

>> Bigrams are: 
 [('R', 'aw')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('R', 'NNP'), ('aw', 'NN')]

>> Noun Phrases are: 
 ['R aw']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('R', 'r'), ('aw', 'aw')]

>> Stemming using Snowball Stemmer: 
 [('R', 'r'), ('aw', 'aw')]

>> Lemmatization: 
 [('R', 'R'), ('aw', 'aw')]



========================================== PARAGRAPH 69 ===========================================

 D at 

------------------- Sentence 1 -------------------

 D at

>> Tokens are: 
 ['D']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('D', 'NN')]

>> Noun Phrases are: 
 ['D']

>> Named Entities are: 
 [('GPE', 'D')] 

>> Stemming using Porter Stemmer: 
 [('D', 'd')]

>> Stemming using Snowball Stemmer: 
 [('D', 'd')]

>> Lemmatization: 
 [('D', 'D')]



========================================== PARAGRAPH 70 ===========================================

a 

------------------- Sentence 1 -------------------

a

>> Tokens are: 
 []

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 []

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 []

>> Stemming using Snowball Stemmer: 
 []

>> Lemmatization: 
 []



========================================== PARAGRAPH 71 ===========================================

Evaluation InterpretationData Mining 

------------------- Sentence 1 -------------------

Evaluation InterpretationData Mining

>> Tokens are: 
 ['Evaluation', 'InterpretationData', 'Mining']

>> Bigrams are: 
 [('Evaluation', 'InterpretationData'), ('InterpretationData', 'Mining')]

>> Trigrams are: 
 [('Evaluation', 'InterpretationData', 'Mining')]

>> POS Tags are: 
 [('Evaluation', 'NN'), ('InterpretationData', 'NNP'), ('Mining', 'NNP')]

>> Noun Phrases are: 
 ['Evaluation InterpretationData Mining']

>> Named Entities are: 
 [('PERSON', 'Evaluation'), ('ORGANIZATION', 'InterpretationData')] 

>> Stemming using Porter Stemmer: 
 [('Evaluation', 'evalu'), ('InterpretationData', 'interpretationdata'), ('Mining', 'mine')]

>> Stemming using Snowball Stemmer: 
 [('Evaluation', 'evalu'), ('InterpretationData', 'interpretationdata'), ('Mining', 'mine')]

>> Lemmatization: 
 [('Evaluation', 'Evaluation'), ('InterpretationData', 'InterpretationData'), ('Mining', 'Mining')]



========================================== PARAGRAPH 72 ===========================================

Gathering 

------------------- Sentence 1 -------------------

Gathering

>> Tokens are: 
 ['Gathering']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Gathering', 'VBG')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Gathering', 'gather')]

>> Stemming using Snowball Stemmer: 
 [('Gathering', 'gather')]

>> Lemmatization: 
 [('Gathering', 'Gathering')]



========================================== PARAGRAPH 73 ===========================================

Fig. 3 The process of knowledge discovery in databases

------------------- Sentence 1 -------------------

Fig.

>> Tokens are: 
 ['Fig', '.']

>> Bigrams are: 
 [('Fig', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Fig', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Fig']

>> Named Entities are: 
 [('GPE', 'Fig')] 

>> Stemming using Porter Stemmer: 
 [('Fig', 'fig'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Fig', 'fig'), ('.', '.')]

>> Lemmatization: 
 [('Fig', 'Fig'), ('.', '.')]


------------------- Sentence 2 -------------------

3 The process of knowledge discovery in databases

>> Tokens are: 
 ['3', 'The', 'process', 'knowledge', 'discovery', 'databases']

>> Bigrams are: 
 [('3', 'The'), ('The', 'process'), ('process', 'knowledge'), ('knowledge', 'discovery'), ('discovery', 'databases')]

>> Trigrams are: 
 [('3', 'The', 'process'), ('The', 'process', 'knowledge'), ('process', 'knowledge', 'discovery'), ('knowledge', 'discovery', 'databases')]

>> POS Tags are: 
 [('3', 'CD'), ('The', 'DT'), ('process', 'NN'), ('knowledge', 'NN'), ('discovery', 'NN'), ('databases', 'NNS')]

>> Noun Phrases are: 
 ['The process knowledge discovery databases']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('3', '3'), ('The', 'the'), ('process', 'process'), ('knowledge', 'knowledg'), ('discovery', 'discoveri'), ('databases', 'databas')]

>> Stemming using Snowball Stemmer: 
 [('3', '3'), ('The', 'the'), ('process', 'process'), ('knowledge', 'knowledg'), ('discovery', 'discoveri'), ('databases', 'databas')]

>> Lemmatization: 
 [('3', '3'), ('The', 'The'), ('process', 'process'), ('knowledge', 'knowledge'), ('discovery', 'discovery'), ('databases', 'database')]



========================================== PARAGRAPH 74 ===========================================

Page 4 of 32Tsai et al. Journal of Big Data  (2015) 2:21  

------------------- Sentence 1 -------------------

Page 4 of 32Tsai et al.

>> Tokens are: 
 ['Page', '4', '32Tsai', 'et', 'al', '.']

>> Bigrams are: 
 [('Page', '4'), ('4', '32Tsai'), ('32Tsai', 'et'), ('et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('Page', '4', '32Tsai'), ('4', '32Tsai', 'et'), ('32Tsai', 'et', 'al'), ('et', 'al', '.')]

>> POS Tags are: 
 [('Page', 'NN'), ('4', 'CD'), ('32Tsai', 'CD'), ('et', 'NN'), ('al', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Page', 'et al']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Page', 'page'), ('4', '4'), ('32Tsai', '32tsai'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Page', 'page'), ('4', '4'), ('32Tsai', '32tsai'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('Page', 'Page'), ('4', '4'), ('32Tsai', '32Tsai'), ('et', 'et'), ('al', 'al'), ('.', '.')]


------------------- Sentence 2 -------------------

Journal of Big Data  (2015) 2:21

>> Tokens are: 
 ['Journal', 'Big', 'Data', '(', '2015', ')', '2:21']

>> Bigrams are: 
 [('Journal', 'Big'), ('Big', 'Data'), ('Data', '('), ('(', '2015'), ('2015', ')'), (')', '2:21')]

>> Trigrams are: 
 [('Journal', 'Big', 'Data'), ('Big', 'Data', '('), ('Data', '(', '2015'), ('(', '2015', ')'), ('2015', ')', '2:21')]

>> POS Tags are: 
 [('Journal', 'NNP'), ('Big', 'NNP'), ('Data', 'NNP'), ('(', '('), ('2015', 'CD'), (')', ')'), ('2:21', 'CD')]

>> Noun Phrases are: 
 ['Journal Big Data']

>> Named Entities are: 
 [('PERSON', 'Journal')] 

>> Stemming using Porter Stemmer: 
 [('Journal', 'journal'), ('Big', 'big'), ('Data', 'data'), ('(', '('), ('2015', '2015'), (')', ')'), ('2:21', '2:21')]

>> Stemming using Snowball Stemmer: 
 [('Journal', 'journal'), ('Big', 'big'), ('Data', 'data'), ('(', '('), ('2015', '2015'), (')', ')'), ('2:21', '2:21')]

>> Lemmatization: 
 [('Journal', 'Journal'), ('Big', 'Big'), ('Data', 'Data'), ('(', '('), ('2015', '2015'), (')', ')'), ('2:21', '2:21')]



========================================== PARAGRAPH 75 ===========================================

kind of data was required for data analysis and select the relevant information from the  gathered data or databases; thus, these gathered data from different data resources will  need to be integrated to the target data. The preprocessing operator plays a different role  in dealing with the input data which is aimed at detecting, cleaning, and filtering the  unnecessary, inconsistent, and incomplete data to make them the useful data. After the  selection and preprocessing operators, the characteristics of the secondary data still may  be in a number of different data formats; therefore, the KDD process needs to transform  them into a data-mining-capable format which is performed by the transformation oper- ator. The methods for reducing the complexity and downsizing the data scale to make  the data useful for data analysis part are usually employed in the transformation, such as  dimensional reduction, sampling, coding, or transformation. 

------------------- Sentence 1 -------------------

kind of data was required for data analysis and select the relevant information from the  gathered data or databases; thus, these gathered data from different data resources will  need to be integrated to the target data.

>> Tokens are: 
 ['kind', 'data', 'required', 'data', 'analysis', 'select', 'relevant', 'information', 'gathered', 'data', 'databases', ';', 'thus', ',', 'gathered', 'data', 'different', 'data', 'resources', 'need', 'integrated', 'target', 'data', '.']

>> Bigrams are: 
 [('kind', 'data'), ('data', 'required'), ('required', 'data'), ('data', 'analysis'), ('analysis', 'select'), ('select', 'relevant'), ('relevant', 'information'), ('information', 'gathered'), ('gathered', 'data'), ('data', 'databases'), ('databases', ';'), (';', 'thus'), ('thus', ','), (',', 'gathered'), ('gathered', 'data'), ('data', 'different'), ('different', 'data'), ('data', 'resources'), ('resources', 'need'), ('need', 'integrated'), ('integrated', 'target'), ('target', 'data'), ('data', '.')]

>> Trigrams are: 
 [('kind', 'data', 'required'), ('data', 'required', 'data'), ('required', 'data', 'analysis'), ('data', 'analysis', 'select'), ('analysis', 'select', 'relevant'), ('select', 'relevant', 'information'), ('relevant', 'information', 'gathered'), ('information', 'gathered', 'data'), ('gathered', 'data', 'databases'), ('data', 'databases', ';'), ('databases', ';', 'thus'), (';', 'thus', ','), ('thus', ',', 'gathered'), (',', 'gathered', 'data'), ('gathered', 'data', 'different'), ('data', 'different', 'data'), ('different', 'data', 'resources'), ('data', 'resources', 'need'), ('resources', 'need', 'integrated'), ('need', 'integrated', 'target'), ('integrated', 'target', 'data'), ('target', 'data', '.')]

>> POS Tags are: 
 [('kind', 'NN'), ('data', 'NNS'), ('required', 'VBN'), ('data', 'NNS'), ('analysis', 'NN'), ('select', 'NN'), ('relevant', 'JJ'), ('information', 'NN'), ('gathered', 'VBN'), ('data', 'NN'), ('databases', 'NNS'), (';', ':'), ('thus', 'RB'), (',', ','), ('gathered', 'VBD'), ('data', 'NNS'), ('different', 'JJ'), ('data', 'NNS'), ('resources', 'NNS'), ('need', 'VBP'), ('integrated', 'VBN'), ('target', 'NN'), ('data', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['kind data', 'data analysis select', 'relevant information', 'data databases', 'data', 'different data resources', 'target data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('kind', 'kind'), ('data', 'data'), ('required', 'requir'), ('data', 'data'), ('analysis', 'analysi'), ('select', 'select'), ('relevant', 'relev'), ('information', 'inform'), ('gathered', 'gather'), ('data', 'data'), ('databases', 'databas'), (';', ';'), ('thus', 'thu'), (',', ','), ('gathered', 'gather'), ('data', 'data'), ('different', 'differ'), ('data', 'data'), ('resources', 'resourc'), ('need', 'need'), ('integrated', 'integr'), ('target', 'target'), ('data', 'data'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('kind', 'kind'), ('data', 'data'), ('required', 'requir'), ('data', 'data'), ('analysis', 'analysi'), ('select', 'select'), ('relevant', 'relev'), ('information', 'inform'), ('gathered', 'gather'), ('data', 'data'), ('databases', 'databas'), (';', ';'), ('thus', 'thus'), (',', ','), ('gathered', 'gather'), ('data', 'data'), ('different', 'differ'), ('data', 'data'), ('resources', 'resourc'), ('need', 'need'), ('integrated', 'integr'), ('target', 'target'), ('data', 'data'), ('.', '.')]

>> Lemmatization: 
 [('kind', 'kind'), ('data', 'data'), ('required', 'required'), ('data', 'data'), ('analysis', 'analysis'), ('select', 'select'), ('relevant', 'relevant'), ('information', 'information'), ('gathered', 'gathered'), ('data', 'data'), ('databases', 'database'), (';', ';'), ('thus', 'thus'), (',', ','), ('gathered', 'gathered'), ('data', 'data'), ('different', 'different'), ('data', 'data'), ('resources', 'resource'), ('need', 'need'), ('integrated', 'integrated'), ('target', 'target'), ('data', 'data'), ('.', '.')]


------------------- Sentence 2 -------------------

The preprocessing operator plays a different role  in dealing with the input data which is aimed at detecting, cleaning, and filtering the  unnecessary, inconsistent, and incomplete data to make them the useful data.

>> Tokens are: 
 ['The', 'preprocessing', 'operator', 'plays', 'different', 'role', 'dealing', 'input', 'data', 'aimed', 'detecting', ',', 'cleaning', ',', 'filtering', 'unnecessary', ',', 'inconsistent', ',', 'incomplete', 'data', 'make', 'useful', 'data', '.']

>> Bigrams are: 
 [('The', 'preprocessing'), ('preprocessing', 'operator'), ('operator', 'plays'), ('plays', 'different'), ('different', 'role'), ('role', 'dealing'), ('dealing', 'input'), ('input', 'data'), ('data', 'aimed'), ('aimed', 'detecting'), ('detecting', ','), (',', 'cleaning'), ('cleaning', ','), (',', 'filtering'), ('filtering', 'unnecessary'), ('unnecessary', ','), (',', 'inconsistent'), ('inconsistent', ','), (',', 'incomplete'), ('incomplete', 'data'), ('data', 'make'), ('make', 'useful'), ('useful', 'data'), ('data', '.')]

>> Trigrams are: 
 [('The', 'preprocessing', 'operator'), ('preprocessing', 'operator', 'plays'), ('operator', 'plays', 'different'), ('plays', 'different', 'role'), ('different', 'role', 'dealing'), ('role', 'dealing', 'input'), ('dealing', 'input', 'data'), ('input', 'data', 'aimed'), ('data', 'aimed', 'detecting'), ('aimed', 'detecting', ','), ('detecting', ',', 'cleaning'), (',', 'cleaning', ','), ('cleaning', ',', 'filtering'), (',', 'filtering', 'unnecessary'), ('filtering', 'unnecessary', ','), ('unnecessary', ',', 'inconsistent'), (',', 'inconsistent', ','), ('inconsistent', ',', 'incomplete'), (',', 'incomplete', 'data'), ('incomplete', 'data', 'make'), ('data', 'make', 'useful'), ('make', 'useful', 'data'), ('useful', 'data', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('preprocessing', 'NN'), ('operator', 'NN'), ('plays', 'VBZ'), ('different', 'JJ'), ('role', 'NN'), ('dealing', 'VBG'), ('input', 'NN'), ('data', 'NNS'), ('aimed', 'VBD'), ('detecting', 'NN'), (',', ','), ('cleaning', 'NN'), (',', ','), ('filtering', 'VBG'), ('unnecessary', 'JJ'), (',', ','), ('inconsistent', 'JJ'), (',', ','), ('incomplete', 'JJ'), ('data', 'NNS'), ('make', 'VBP'), ('useful', 'JJ'), ('data', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['The preprocessing operator', 'different role', 'input data', 'detecting', 'cleaning', 'incomplete data', 'useful data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('preprocessing', 'preprocess'), ('operator', 'oper'), ('plays', 'play'), ('different', 'differ'), ('role', 'role'), ('dealing', 'deal'), ('input', 'input'), ('data', 'data'), ('aimed', 'aim'), ('detecting', 'detect'), (',', ','), ('cleaning', 'clean'), (',', ','), ('filtering', 'filter'), ('unnecessary', 'unnecessari'), (',', ','), ('inconsistent', 'inconsist'), (',', ','), ('incomplete', 'incomplet'), ('data', 'data'), ('make', 'make'), ('useful', 'use'), ('data', 'data'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('preprocessing', 'preprocess'), ('operator', 'oper'), ('plays', 'play'), ('different', 'differ'), ('role', 'role'), ('dealing', 'deal'), ('input', 'input'), ('data', 'data'), ('aimed', 'aim'), ('detecting', 'detect'), (',', ','), ('cleaning', 'clean'), (',', ','), ('filtering', 'filter'), ('unnecessary', 'unnecessari'), (',', ','), ('inconsistent', 'inconsist'), (',', ','), ('incomplete', 'incomplet'), ('data', 'data'), ('make', 'make'), ('useful', 'use'), ('data', 'data'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('preprocessing', 'preprocessing'), ('operator', 'operator'), ('plays', 'play'), ('different', 'different'), ('role', 'role'), ('dealing', 'dealing'), ('input', 'input'), ('data', 'data'), ('aimed', 'aimed'), ('detecting', 'detecting'), (',', ','), ('cleaning', 'cleaning'), (',', ','), ('filtering', 'filtering'), ('unnecessary', 'unnecessary'), (',', ','), ('inconsistent', 'inconsistent'), (',', ','), ('incomplete', 'incomplete'), ('data', 'data'), ('make', 'make'), ('useful', 'useful'), ('data', 'data'), ('.', '.')]


------------------- Sentence 3 -------------------

After the  selection and preprocessing operators, the characteristics of the secondary data still may  be in a number of different data formats; therefore, the KDD process needs to transform  them into a data-mining-capable format which is performed by the transformation oper- ator.

>> Tokens are: 
 ['After', 'selection', 'preprocessing', 'operators', ',', 'characteristics', 'secondary', 'data', 'still', 'may', 'number', 'different', 'data', 'formats', ';', 'therefore', ',', 'KDD', 'process', 'needs', 'transform', 'data-mining-capable', 'format', 'performed', 'transformation', 'oper-', 'ator', '.']

>> Bigrams are: 
 [('After', 'selection'), ('selection', 'preprocessing'), ('preprocessing', 'operators'), ('operators', ','), (',', 'characteristics'), ('characteristics', 'secondary'), ('secondary', 'data'), ('data', 'still'), ('still', 'may'), ('may', 'number'), ('number', 'different'), ('different', 'data'), ('data', 'formats'), ('formats', ';'), (';', 'therefore'), ('therefore', ','), (',', 'KDD'), ('KDD', 'process'), ('process', 'needs'), ('needs', 'transform'), ('transform', 'data-mining-capable'), ('data-mining-capable', 'format'), ('format', 'performed'), ('performed', 'transformation'), ('transformation', 'oper-'), ('oper-', 'ator'), ('ator', '.')]

>> Trigrams are: 
 [('After', 'selection', 'preprocessing'), ('selection', 'preprocessing', 'operators'), ('preprocessing', 'operators', ','), ('operators', ',', 'characteristics'), (',', 'characteristics', 'secondary'), ('characteristics', 'secondary', 'data'), ('secondary', 'data', 'still'), ('data', 'still', 'may'), ('still', 'may', 'number'), ('may', 'number', 'different'), ('number', 'different', 'data'), ('different', 'data', 'formats'), ('data', 'formats', ';'), ('formats', ';', 'therefore'), (';', 'therefore', ','), ('therefore', ',', 'KDD'), (',', 'KDD', 'process'), ('KDD', 'process', 'needs'), ('process', 'needs', 'transform'), ('needs', 'transform', 'data-mining-capable'), ('transform', 'data-mining-capable', 'format'), ('data-mining-capable', 'format', 'performed'), ('format', 'performed', 'transformation'), ('performed', 'transformation', 'oper-'), ('transformation', 'oper-', 'ator'), ('oper-', 'ator', '.')]

>> POS Tags are: 
 [('After', 'IN'), ('selection', 'NN'), ('preprocessing', 'NN'), ('operators', 'NNS'), (',', ','), ('characteristics', 'NNS'), ('secondary', 'JJ'), ('data', 'NNS'), ('still', 'RB'), ('may', 'MD'), ('number', 'NN'), ('different', 'JJ'), ('data', 'NNS'), ('formats', 'NNS'), (';', ':'), ('therefore', 'RB'), (',', ','), ('KDD', 'NNP'), ('process', 'NN'), ('needs', 'NNS'), ('transform', 'VB'), ('data-mining-capable', 'JJ'), ('format', 'NN'), ('performed', 'VBN'), ('transformation', 'NN'), ('oper-', 'JJ'), ('ator', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['selection preprocessing operators', 'characteristics', 'secondary data', 'number', 'different data formats', 'KDD process needs', 'data-mining-capable format', 'transformation', 'oper- ator']

>> Named Entities are: 
 [('ORGANIZATION', 'KDD')] 

>> Stemming using Porter Stemmer: 
 [('After', 'after'), ('selection', 'select'), ('preprocessing', 'preprocess'), ('operators', 'oper'), (',', ','), ('characteristics', 'characterist'), ('secondary', 'secondari'), ('data', 'data'), ('still', 'still'), ('may', 'may'), ('number', 'number'), ('different', 'differ'), ('data', 'data'), ('formats', 'format'), (';', ';'), ('therefore', 'therefor'), (',', ','), ('KDD', 'kdd'), ('process', 'process'), ('needs', 'need'), ('transform', 'transform'), ('data-mining-capable', 'data-mining-cap'), ('format', 'format'), ('performed', 'perform'), ('transformation', 'transform'), ('oper-', 'oper-'), ('ator', 'ator'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('After', 'after'), ('selection', 'select'), ('preprocessing', 'preprocess'), ('operators', 'oper'), (',', ','), ('characteristics', 'characterist'), ('secondary', 'secondari'), ('data', 'data'), ('still', 'still'), ('may', 'may'), ('number', 'number'), ('different', 'differ'), ('data', 'data'), ('formats', 'format'), (';', ';'), ('therefore', 'therefor'), (',', ','), ('KDD', 'kdd'), ('process', 'process'), ('needs', 'need'), ('transform', 'transform'), ('data-mining-capable', 'data-mining-cap'), ('format', 'format'), ('performed', 'perform'), ('transformation', 'transform'), ('oper-', 'oper-'), ('ator', 'ator'), ('.', '.')]

>> Lemmatization: 
 [('After', 'After'), ('selection', 'selection'), ('preprocessing', 'preprocessing'), ('operators', 'operator'), (',', ','), ('characteristics', 'characteristic'), ('secondary', 'secondary'), ('data', 'data'), ('still', 'still'), ('may', 'may'), ('number', 'number'), ('different', 'different'), ('data', 'data'), ('formats', 'format'), (';', ';'), ('therefore', 'therefore'), (',', ','), ('KDD', 'KDD'), ('process', 'process'), ('needs', 'need'), ('transform', 'transform'), ('data-mining-capable', 'data-mining-capable'), ('format', 'format'), ('performed', 'performed'), ('transformation', 'transformation'), ('oper-', 'oper-'), ('ator', 'ator'), ('.', '.')]


------------------- Sentence 4 -------------------

The methods for reducing the complexity and downsizing the data scale to make  the data useful for data analysis part are usually employed in the transformation, such as  dimensional reduction, sampling, coding, or transformation.

>> Tokens are: 
 ['The', 'methods', 'reducing', 'complexity', 'downsizing', 'data', 'scale', 'make', 'data', 'useful', 'data', 'analysis', 'part', 'usually', 'employed', 'transformation', ',', 'dimensional', 'reduction', ',', 'sampling', ',', 'coding', ',', 'transformation', '.']

>> Bigrams are: 
 [('The', 'methods'), ('methods', 'reducing'), ('reducing', 'complexity'), ('complexity', 'downsizing'), ('downsizing', 'data'), ('data', 'scale'), ('scale', 'make'), ('make', 'data'), ('data', 'useful'), ('useful', 'data'), ('data', 'analysis'), ('analysis', 'part'), ('part', 'usually'), ('usually', 'employed'), ('employed', 'transformation'), ('transformation', ','), (',', 'dimensional'), ('dimensional', 'reduction'), ('reduction', ','), (',', 'sampling'), ('sampling', ','), (',', 'coding'), ('coding', ','), (',', 'transformation'), ('transformation', '.')]

>> Trigrams are: 
 [('The', 'methods', 'reducing'), ('methods', 'reducing', 'complexity'), ('reducing', 'complexity', 'downsizing'), ('complexity', 'downsizing', 'data'), ('downsizing', 'data', 'scale'), ('data', 'scale', 'make'), ('scale', 'make', 'data'), ('make', 'data', 'useful'), ('data', 'useful', 'data'), ('useful', 'data', 'analysis'), ('data', 'analysis', 'part'), ('analysis', 'part', 'usually'), ('part', 'usually', 'employed'), ('usually', 'employed', 'transformation'), ('employed', 'transformation', ','), ('transformation', ',', 'dimensional'), (',', 'dimensional', 'reduction'), ('dimensional', 'reduction', ','), ('reduction', ',', 'sampling'), (',', 'sampling', ','), ('sampling', ',', 'coding'), (',', 'coding', ','), ('coding', ',', 'transformation'), (',', 'transformation', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('methods', 'NNS'), ('reducing', 'VBG'), ('complexity', 'NN'), ('downsizing', 'VBG'), ('data', 'NNS'), ('scale', 'NNS'), ('make', 'VBP'), ('data', 'NNS'), ('useful', 'JJ'), ('data', 'NNS'), ('analysis', 'NN'), ('part', 'NN'), ('usually', 'RB'), ('employed', 'VBN'), ('transformation', 'NN'), (',', ','), ('dimensional', 'JJ'), ('reduction', 'NN'), (',', ','), ('sampling', 'VBG'), (',', ','), ('coding', 'VBG'), (',', ','), ('transformation', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['The methods', 'complexity', 'data scale', 'data', 'useful data analysis part', 'transformation', 'dimensional reduction', 'transformation']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('methods', 'method'), ('reducing', 'reduc'), ('complexity', 'complex'), ('downsizing', 'downsiz'), ('data', 'data'), ('scale', 'scale'), ('make', 'make'), ('data', 'data'), ('useful', 'use'), ('data', 'data'), ('analysis', 'analysi'), ('part', 'part'), ('usually', 'usual'), ('employed', 'employ'), ('transformation', 'transform'), (',', ','), ('dimensional', 'dimension'), ('reduction', 'reduct'), (',', ','), ('sampling', 'sampl'), (',', ','), ('coding', 'code'), (',', ','), ('transformation', 'transform'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('methods', 'method'), ('reducing', 'reduc'), ('complexity', 'complex'), ('downsizing', 'downsiz'), ('data', 'data'), ('scale', 'scale'), ('make', 'make'), ('data', 'data'), ('useful', 'use'), ('data', 'data'), ('analysis', 'analysi'), ('part', 'part'), ('usually', 'usual'), ('employed', 'employ'), ('transformation', 'transform'), (',', ','), ('dimensional', 'dimension'), ('reduction', 'reduct'), (',', ','), ('sampling', 'sampl'), (',', ','), ('coding', 'code'), (',', ','), ('transformation', 'transform'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('methods', 'method'), ('reducing', 'reducing'), ('complexity', 'complexity'), ('downsizing', 'downsizing'), ('data', 'data'), ('scale', 'scale'), ('make', 'make'), ('data', 'data'), ('useful', 'useful'), ('data', 'data'), ('analysis', 'analysis'), ('part', 'part'), ('usually', 'usually'), ('employed', 'employed'), ('transformation', 'transformation'), (',', ','), ('dimensional', 'dimensional'), ('reduction', 'reduction'), (',', ','), ('sampling', 'sampling'), (',', ','), ('coding', 'coding'), (',', ','), ('transformation', 'transformation'), ('.', '.')]



========================================== PARAGRAPH 76 ===========================================

The data extraction, data cleaning, data integration, data transformation, and data  reduction operators can be regarded as the preprocessing processes of data analysis [20]  which attempts to extract useful data from the raw data (also called the primary data)  and refine them so that they can be used by the following data analyses. If the data are  a duplicate copy, incomplete, inconsistent, noisy, or outliers, then these operators have  to clean them up. If the data are too complex or too large to be handled, these operators  will also try to reduce them. If the raw data have errors or omissions, the roles of these  operators are to identify them and make them consistent. It can be expected that these  operators may affect the analytics result of KDD, be it positive or negative. In summary,  the systematic solutions are usually to reduce the complexity of data to accelerate the  computation time of KDD and to improve the accuracy of the analytics result. 

------------------- Sentence 1 -------------------

The data extraction, data cleaning, data integration, data transformation, and data  reduction operators can be regarded as the preprocessing processes of data analysis [20]  which attempts to extract useful data from the raw data (also called the primary data)  and refine them so that they can be used by the following data analyses.

>> Tokens are: 
 ['The', 'data', 'extraction', ',', 'data', 'cleaning', ',', 'data', 'integration', ',', 'data', 'transformation', ',', 'data', 'reduction', 'operators', 'regarded', 'preprocessing', 'processes', 'data', 'analysis', '[', '20', ']', 'attempts', 'extract', 'useful', 'data', 'raw', 'data', '(', 'also', 'called', 'primary', 'data', ')', 'refine', 'used', 'following', 'data', 'analyses', '.']

>> Bigrams are: 
 [('The', 'data'), ('data', 'extraction'), ('extraction', ','), (',', 'data'), ('data', 'cleaning'), ('cleaning', ','), (',', 'data'), ('data', 'integration'), ('integration', ','), (',', 'data'), ('data', 'transformation'), ('transformation', ','), (',', 'data'), ('data', 'reduction'), ('reduction', 'operators'), ('operators', 'regarded'), ('regarded', 'preprocessing'), ('preprocessing', 'processes'), ('processes', 'data'), ('data', 'analysis'), ('analysis', '['), ('[', '20'), ('20', ']'), (']', 'attempts'), ('attempts', 'extract'), ('extract', 'useful'), ('useful', 'data'), ('data', 'raw'), ('raw', 'data'), ('data', '('), ('(', 'also'), ('also', 'called'), ('called', 'primary'), ('primary', 'data'), ('data', ')'), (')', 'refine'), ('refine', 'used'), ('used', 'following'), ('following', 'data'), ('data', 'analyses'), ('analyses', '.')]

>> Trigrams are: 
 [('The', 'data', 'extraction'), ('data', 'extraction', ','), ('extraction', ',', 'data'), (',', 'data', 'cleaning'), ('data', 'cleaning', ','), ('cleaning', ',', 'data'), (',', 'data', 'integration'), ('data', 'integration', ','), ('integration', ',', 'data'), (',', 'data', 'transformation'), ('data', 'transformation', ','), ('transformation', ',', 'data'), (',', 'data', 'reduction'), ('data', 'reduction', 'operators'), ('reduction', 'operators', 'regarded'), ('operators', 'regarded', 'preprocessing'), ('regarded', 'preprocessing', 'processes'), ('preprocessing', 'processes', 'data'), ('processes', 'data', 'analysis'), ('data', 'analysis', '['), ('analysis', '[', '20'), ('[', '20', ']'), ('20', ']', 'attempts'), (']', 'attempts', 'extract'), ('attempts', 'extract', 'useful'), ('extract', 'useful', 'data'), ('useful', 'data', 'raw'), ('data', 'raw', 'data'), ('raw', 'data', '('), ('data', '(', 'also'), ('(', 'also', 'called'), ('also', 'called', 'primary'), ('called', 'primary', 'data'), ('primary', 'data', ')'), ('data', ')', 'refine'), (')', 'refine', 'used'), ('refine', 'used', 'following'), ('used', 'following', 'data'), ('following', 'data', 'analyses'), ('data', 'analyses', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('data', 'NN'), ('extraction', 'NN'), (',', ','), ('data', 'NNS'), ('cleaning', 'NN'), (',', ','), ('data', 'NNS'), ('integration', 'NN'), (',', ','), ('data', 'NNS'), ('transformation', 'NN'), (',', ','), ('data', 'NNS'), ('reduction', 'NN'), ('operators', 'NNS'), ('regarded', 'VBD'), ('preprocessing', 'VBG'), ('processes', 'NNS'), ('data', 'NNS'), ('analysis', 'NN'), ('[', 'VBP'), ('20', 'CD'), (']', 'JJ'), ('attempts', 'NNS'), ('extract', 'VBP'), ('useful', 'JJ'), ('data', 'NNS'), ('raw', 'JJ'), ('data', 'NNS'), ('(', '('), ('also', 'RB'), ('called', 'VBN'), ('primary', 'JJ'), ('data', 'NNS'), (')', ')'), ('refine', 'VBP'), ('used', 'VBN'), ('following', 'VBG'), ('data', 'NN'), ('analyses', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['The data extraction', 'data cleaning', 'data integration', 'data transformation', 'data reduction operators', 'processes data analysis', '] attempts', 'useful data', 'raw data', 'primary data', 'data analyses']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('data', 'data'), ('extraction', 'extract'), (',', ','), ('data', 'data'), ('cleaning', 'clean'), (',', ','), ('data', 'data'), ('integration', 'integr'), (',', ','), ('data', 'data'), ('transformation', 'transform'), (',', ','), ('data', 'data'), ('reduction', 'reduct'), ('operators', 'oper'), ('regarded', 'regard'), ('preprocessing', 'preprocess'), ('processes', 'process'), ('data', 'data'), ('analysis', 'analysi'), ('[', '['), ('20', '20'), (']', ']'), ('attempts', 'attempt'), ('extract', 'extract'), ('useful', 'use'), ('data', 'data'), ('raw', 'raw'), ('data', 'data'), ('(', '('), ('also', 'also'), ('called', 'call'), ('primary', 'primari'), ('data', 'data'), (')', ')'), ('refine', 'refin'), ('used', 'use'), ('following', 'follow'), ('data', 'data'), ('analyses', 'analys'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('data', 'data'), ('extraction', 'extract'), (',', ','), ('data', 'data'), ('cleaning', 'clean'), (',', ','), ('data', 'data'), ('integration', 'integr'), (',', ','), ('data', 'data'), ('transformation', 'transform'), (',', ','), ('data', 'data'), ('reduction', 'reduct'), ('operators', 'oper'), ('regarded', 'regard'), ('preprocessing', 'preprocess'), ('processes', 'process'), ('data', 'data'), ('analysis', 'analysi'), ('[', '['), ('20', '20'), (']', ']'), ('attempts', 'attempt'), ('extract', 'extract'), ('useful', 'use'), ('data', 'data'), ('raw', 'raw'), ('data', 'data'), ('(', '('), ('also', 'also'), ('called', 'call'), ('primary', 'primari'), ('data', 'data'), (')', ')'), ('refine', 'refin'), ('used', 'use'), ('following', 'follow'), ('data', 'data'), ('analyses', 'analys'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('data', 'data'), ('extraction', 'extraction'), (',', ','), ('data', 'data'), ('cleaning', 'cleaning'), (',', ','), ('data', 'data'), ('integration', 'integration'), (',', ','), ('data', 'data'), ('transformation', 'transformation'), (',', ','), ('data', 'data'), ('reduction', 'reduction'), ('operators', 'operator'), ('regarded', 'regarded'), ('preprocessing', 'preprocessing'), ('processes', 'process'), ('data', 'data'), ('analysis', 'analysis'), ('[', '['), ('20', '20'), (']', ']'), ('attempts', 'attempt'), ('extract', 'extract'), ('useful', 'useful'), ('data', 'data'), ('raw', 'raw'), ('data', 'data'), ('(', '('), ('also', 'also'), ('called', 'called'), ('primary', 'primary'), ('data', 'data'), (')', ')'), ('refine', 'refine'), ('used', 'used'), ('following', 'following'), ('data', 'data'), ('analyses', 'analysis'), ('.', '.')]


------------------- Sentence 2 -------------------

If the data are  a duplicate copy, incomplete, inconsistent, noisy, or outliers, then these operators have  to clean them up.

>> Tokens are: 
 ['If', 'data', 'duplicate', 'copy', ',', 'incomplete', ',', 'inconsistent', ',', 'noisy', ',', 'outliers', ',', 'operators', 'clean', '.']

>> Bigrams are: 
 [('If', 'data'), ('data', 'duplicate'), ('duplicate', 'copy'), ('copy', ','), (',', 'incomplete'), ('incomplete', ','), (',', 'inconsistent'), ('inconsistent', ','), (',', 'noisy'), ('noisy', ','), (',', 'outliers'), ('outliers', ','), (',', 'operators'), ('operators', 'clean'), ('clean', '.')]

>> Trigrams are: 
 [('If', 'data', 'duplicate'), ('data', 'duplicate', 'copy'), ('duplicate', 'copy', ','), ('copy', ',', 'incomplete'), (',', 'incomplete', ','), ('incomplete', ',', 'inconsistent'), (',', 'inconsistent', ','), ('inconsistent', ',', 'noisy'), (',', 'noisy', ','), ('noisy', ',', 'outliers'), (',', 'outliers', ','), ('outliers', ',', 'operators'), (',', 'operators', 'clean'), ('operators', 'clean', '.')]

>> POS Tags are: 
 [('If', 'IN'), ('data', 'NNS'), ('duplicate', 'NN'), ('copy', 'NN'), (',', ','), ('incomplete', 'JJ'), (',', ','), ('inconsistent', 'JJ'), (',', ','), ('noisy', 'JJ'), (',', ','), ('outliers', 'NNS'), (',', ','), ('operators', 'NNS'), ('clean', 'VBP'), ('.', '.')]

>> Noun Phrases are: 
 ['data duplicate copy', 'outliers', 'operators']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('If', 'if'), ('data', 'data'), ('duplicate', 'duplic'), ('copy', 'copi'), (',', ','), ('incomplete', 'incomplet'), (',', ','), ('inconsistent', 'inconsist'), (',', ','), ('noisy', 'noisi'), (',', ','), ('outliers', 'outlier'), (',', ','), ('operators', 'oper'), ('clean', 'clean'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('If', 'if'), ('data', 'data'), ('duplicate', 'duplic'), ('copy', 'copi'), (',', ','), ('incomplete', 'incomplet'), (',', ','), ('inconsistent', 'inconsist'), (',', ','), ('noisy', 'noisi'), (',', ','), ('outliers', 'outlier'), (',', ','), ('operators', 'oper'), ('clean', 'clean'), ('.', '.')]

>> Lemmatization: 
 [('If', 'If'), ('data', 'data'), ('duplicate', 'duplicate'), ('copy', 'copy'), (',', ','), ('incomplete', 'incomplete'), (',', ','), ('inconsistent', 'inconsistent'), (',', ','), ('noisy', 'noisy'), (',', ','), ('outliers', 'outlier'), (',', ','), ('operators', 'operator'), ('clean', 'clean'), ('.', '.')]


------------------- Sentence 3 -------------------

If the data are too complex or too large to be handled, these operators  will also try to reduce them.

>> Tokens are: 
 ['If', 'data', 'complex', 'large', 'handled', ',', 'operators', 'also', 'try', 'reduce', '.']

>> Bigrams are: 
 [('If', 'data'), ('data', 'complex'), ('complex', 'large'), ('large', 'handled'), ('handled', ','), (',', 'operators'), ('operators', 'also'), ('also', 'try'), ('try', 'reduce'), ('reduce', '.')]

>> Trigrams are: 
 [('If', 'data', 'complex'), ('data', 'complex', 'large'), ('complex', 'large', 'handled'), ('large', 'handled', ','), ('handled', ',', 'operators'), (',', 'operators', 'also'), ('operators', 'also', 'try'), ('also', 'try', 'reduce'), ('try', 'reduce', '.')]

>> POS Tags are: 
 [('If', 'IN'), ('data', 'NNS'), ('complex', 'JJ'), ('large', 'JJ'), ('handled', 'VBN'), (',', ','), ('operators', 'NNS'), ('also', 'RB'), ('try', 'VBP'), ('reduce', 'VB'), ('.', '.')]

>> Noun Phrases are: 
 ['data', 'operators']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('If', 'if'), ('data', 'data'), ('complex', 'complex'), ('large', 'larg'), ('handled', 'handl'), (',', ','), ('operators', 'oper'), ('also', 'also'), ('try', 'tri'), ('reduce', 'reduc'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('If', 'if'), ('data', 'data'), ('complex', 'complex'), ('large', 'larg'), ('handled', 'handl'), (',', ','), ('operators', 'oper'), ('also', 'also'), ('try', 'tri'), ('reduce', 'reduc'), ('.', '.')]

>> Lemmatization: 
 [('If', 'If'), ('data', 'data'), ('complex', 'complex'), ('large', 'large'), ('handled', 'handled'), (',', ','), ('operators', 'operator'), ('also', 'also'), ('try', 'try'), ('reduce', 'reduce'), ('.', '.')]


------------------- Sentence 4 -------------------

If the raw data have errors or omissions, the roles of these  operators are to identify them and make them consistent.

>> Tokens are: 
 ['If', 'raw', 'data', 'errors', 'omissions', ',', 'roles', 'operators', 'identify', 'make', 'consistent', '.']

>> Bigrams are: 
 [('If', 'raw'), ('raw', 'data'), ('data', 'errors'), ('errors', 'omissions'), ('omissions', ','), (',', 'roles'), ('roles', 'operators'), ('operators', 'identify'), ('identify', 'make'), ('make', 'consistent'), ('consistent', '.')]

>> Trigrams are: 
 [('If', 'raw', 'data'), ('raw', 'data', 'errors'), ('data', 'errors', 'omissions'), ('errors', 'omissions', ','), ('omissions', ',', 'roles'), (',', 'roles', 'operators'), ('roles', 'operators', 'identify'), ('operators', 'identify', 'make'), ('identify', 'make', 'consistent'), ('make', 'consistent', '.')]

>> POS Tags are: 
 [('If', 'IN'), ('raw', 'JJ'), ('data', 'NN'), ('errors', 'NNS'), ('omissions', 'NNS'), (',', ','), ('roles', 'NNS'), ('operators', 'NNS'), ('identify', 'VBP'), ('make', 'VBP'), ('consistent', 'JJ'), ('.', '.')]

>> Noun Phrases are: 
 ['raw data errors omissions', 'roles operators']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('If', 'if'), ('raw', 'raw'), ('data', 'data'), ('errors', 'error'), ('omissions', 'omiss'), (',', ','), ('roles', 'role'), ('operators', 'oper'), ('identify', 'identifi'), ('make', 'make'), ('consistent', 'consist'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('If', 'if'), ('raw', 'raw'), ('data', 'data'), ('errors', 'error'), ('omissions', 'omiss'), (',', ','), ('roles', 'role'), ('operators', 'oper'), ('identify', 'identifi'), ('make', 'make'), ('consistent', 'consist'), ('.', '.')]

>> Lemmatization: 
 [('If', 'If'), ('raw', 'raw'), ('data', 'data'), ('errors', 'error'), ('omissions', 'omission'), (',', ','), ('roles', 'role'), ('operators', 'operator'), ('identify', 'identify'), ('make', 'make'), ('consistent', 'consistent'), ('.', '.')]


------------------- Sentence 5 -------------------

It can be expected that these  operators may affect the analytics result of KDD, be it positive or negative.

>> Tokens are: 
 ['It', 'expected', 'operators', 'may', 'affect', 'analytics', 'result', 'KDD', ',', 'positive', 'negative', '.']

>> Bigrams are: 
 [('It', 'expected'), ('expected', 'operators'), ('operators', 'may'), ('may', 'affect'), ('affect', 'analytics'), ('analytics', 'result'), ('result', 'KDD'), ('KDD', ','), (',', 'positive'), ('positive', 'negative'), ('negative', '.')]

>> Trigrams are: 
 [('It', 'expected', 'operators'), ('expected', 'operators', 'may'), ('operators', 'may', 'affect'), ('may', 'affect', 'analytics'), ('affect', 'analytics', 'result'), ('analytics', 'result', 'KDD'), ('result', 'KDD', ','), ('KDD', ',', 'positive'), (',', 'positive', 'negative'), ('positive', 'negative', '.')]

>> POS Tags are: 
 [('It', 'PRP'), ('expected', 'VBD'), ('operators', 'NNS'), ('may', 'MD'), ('affect', 'VB'), ('analytics', 'NNS'), ('result', 'VBP'), ('KDD', 'NNP'), (',', ','), ('positive', 'JJ'), ('negative', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['operators', 'analytics', 'KDD', 'positive negative']

>> Named Entities are: 
 [('ORGANIZATION', 'KDD')] 

>> Stemming using Porter Stemmer: 
 [('It', 'it'), ('expected', 'expect'), ('operators', 'oper'), ('may', 'may'), ('affect', 'affect'), ('analytics', 'analyt'), ('result', 'result'), ('KDD', 'kdd'), (',', ','), ('positive', 'posit'), ('negative', 'neg'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('It', 'it'), ('expected', 'expect'), ('operators', 'oper'), ('may', 'may'), ('affect', 'affect'), ('analytics', 'analyt'), ('result', 'result'), ('KDD', 'kdd'), (',', ','), ('positive', 'posit'), ('negative', 'negat'), ('.', '.')]

>> Lemmatization: 
 [('It', 'It'), ('expected', 'expected'), ('operators', 'operator'), ('may', 'may'), ('affect', 'affect'), ('analytics', 'analytics'), ('result', 'result'), ('KDD', 'KDD'), (',', ','), ('positive', 'positive'), ('negative', 'negative'), ('.', '.')]


------------------- Sentence 6 -------------------

In summary,  the systematic solutions are usually to reduce the complexity of data to accelerate the  computation time of KDD and to improve the accuracy of the analytics result.

>> Tokens are: 
 ['In', 'summary', ',', 'systematic', 'solutions', 'usually', 'reduce', 'complexity', 'data', 'accelerate', 'computation', 'time', 'KDD', 'improve', 'accuracy', 'analytics', 'result', '.']

>> Bigrams are: 
 [('In', 'summary'), ('summary', ','), (',', 'systematic'), ('systematic', 'solutions'), ('solutions', 'usually'), ('usually', 'reduce'), ('reduce', 'complexity'), ('complexity', 'data'), ('data', 'accelerate'), ('accelerate', 'computation'), ('computation', 'time'), ('time', 'KDD'), ('KDD', 'improve'), ('improve', 'accuracy'), ('accuracy', 'analytics'), ('analytics', 'result'), ('result', '.')]

>> Trigrams are: 
 [('In', 'summary', ','), ('summary', ',', 'systematic'), (',', 'systematic', 'solutions'), ('systematic', 'solutions', 'usually'), ('solutions', 'usually', 'reduce'), ('usually', 'reduce', 'complexity'), ('reduce', 'complexity', 'data'), ('complexity', 'data', 'accelerate'), ('data', 'accelerate', 'computation'), ('accelerate', 'computation', 'time'), ('computation', 'time', 'KDD'), ('time', 'KDD', 'improve'), ('KDD', 'improve', 'accuracy'), ('improve', 'accuracy', 'analytics'), ('accuracy', 'analytics', 'result'), ('analytics', 'result', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('summary', 'JJ'), (',', ','), ('systematic', 'JJ'), ('solutions', 'NNS'), ('usually', 'RB'), ('reduce', 'VB'), ('complexity', 'NN'), ('data', 'NNS'), ('accelerate', 'VB'), ('computation', 'NN'), ('time', 'NN'), ('KDD', 'NNP'), ('improve', 'VB'), ('accuracy', 'NN'), ('analytics', 'NNS'), ('result', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['systematic solutions', 'complexity data', 'computation time KDD', 'accuracy analytics result']

>> Named Entities are: 
 [('ORGANIZATION', 'KDD')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('summary', 'summari'), (',', ','), ('systematic', 'systemat'), ('solutions', 'solut'), ('usually', 'usual'), ('reduce', 'reduc'), ('complexity', 'complex'), ('data', 'data'), ('accelerate', 'acceler'), ('computation', 'comput'), ('time', 'time'), ('KDD', 'kdd'), ('improve', 'improv'), ('accuracy', 'accuraci'), ('analytics', 'analyt'), ('result', 'result'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('summary', 'summari'), (',', ','), ('systematic', 'systemat'), ('solutions', 'solut'), ('usually', 'usual'), ('reduce', 'reduc'), ('complexity', 'complex'), ('data', 'data'), ('accelerate', 'acceler'), ('computation', 'comput'), ('time', 'time'), ('KDD', 'kdd'), ('improve', 'improv'), ('accuracy', 'accuraci'), ('analytics', 'analyt'), ('result', 'result'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('summary', 'summary'), (',', ','), ('systematic', 'systematic'), ('solutions', 'solution'), ('usually', 'usually'), ('reduce', 'reduce'), ('complexity', 'complexity'), ('data', 'data'), ('accelerate', 'accelerate'), ('computation', 'computation'), ('time', 'time'), ('KDD', 'KDD'), ('improve', 'improve'), ('accuracy', 'accuracy'), ('analytics', 'analytics'), ('result', 'result'), ('.', '.')]



========================================== PARAGRAPH 77 ===========================================

Data analysis 

------------------- Sentence 1 -------------------

Data analysis

>> Tokens are: 
 ['Data', 'analysis']

>> Bigrams are: 
 [('Data', 'analysis')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Data', 'NNS'), ('analysis', 'NN')]

>> Noun Phrases are: 
 ['Data analysis']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Data', 'data'), ('analysis', 'analysi')]

>> Stemming using Snowball Stemmer: 
 [('Data', 'data'), ('analysis', 'analysi')]

>> Lemmatization: 
 [('Data', 'Data'), ('analysis', 'analysis')]



========================================== PARAGRAPH 78 ===========================================

Since the data analysis (as shown in Fig. 3) in KDD is responsible for finding the hid- den patterns/rules/information from the data, most researchers in this field use the term  data mining to describe how they refine the “ground” (i.e, raw data) into “gold nugget”  (i.e.-, information or knowledge). The data mining methods [20] are not limited to data  problem specific methods. In fact, other technologies (e.g.-, statistical or machine learn- ing technologies) have also been used to analyze the data for many years. In the early  stages of data analysis, the statistical methods were used for analyzing the data to help  us understand the situation we are facing, such as public opinion poll or TV programme  rating. Like the statistical analysis, the problem specific methods for data mining also  attempted to understand the meaning from the collected data. 

------------------- Sentence 1 -------------------

Since the data analysis (as shown in Fig.

>> Tokens are: 
 ['Since', 'data', 'analysis', '(', 'shown', 'Fig', '.']

>> Bigrams are: 
 [('Since', 'data'), ('data', 'analysis'), ('analysis', '('), ('(', 'shown'), ('shown', 'Fig'), ('Fig', '.')]

>> Trigrams are: 
 [('Since', 'data', 'analysis'), ('data', 'analysis', '('), ('analysis', '(', 'shown'), ('(', 'shown', 'Fig'), ('shown', 'Fig', '.')]

>> POS Tags are: 
 [('Since', 'IN'), ('data', 'NNS'), ('analysis', 'NN'), ('(', '('), ('shown', 'VBN'), ('Fig', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['data analysis', 'Fig']

>> Named Entities are: 
 [('PERSON', 'Fig')] 

>> Stemming using Porter Stemmer: 
 [('Since', 'sinc'), ('data', 'data'), ('analysis', 'analysi'), ('(', '('), ('shown', 'shown'), ('Fig', 'fig'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Since', 'sinc'), ('data', 'data'), ('analysis', 'analysi'), ('(', '('), ('shown', 'shown'), ('Fig', 'fig'), ('.', '.')]

>> Lemmatization: 
 [('Since', 'Since'), ('data', 'data'), ('analysis', 'analysis'), ('(', '('), ('shown', 'shown'), ('Fig', 'Fig'), ('.', '.')]


------------------- Sentence 2 -------------------

3) in KDD is responsible for finding the hid- den patterns/rules/information from the data, most researchers in this field use the term  data mining to describe how they refine the “ground” (i.e, raw data) into “gold nugget”  (i.e.-, information or knowledge).

>> Tokens are: 
 ['3', ')', 'KDD', 'responsible', 'finding', 'hid-', 'den', 'patterns/rules/information', 'data', ',', 'researchers', 'field', 'use', 'term', 'data', 'mining', 'describe', 'refine', '“', 'ground', '”', '(', 'i.e', ',', 'raw', 'data', ')', '“', 'gold', 'nugget', '”', '(', 'i.e.-', ',', 'information', 'knowledge', ')', '.']

>> Bigrams are: 
 [('3', ')'), (')', 'KDD'), ('KDD', 'responsible'), ('responsible', 'finding'), ('finding', 'hid-'), ('hid-', 'den'), ('den', 'patterns/rules/information'), ('patterns/rules/information', 'data'), ('data', ','), (',', 'researchers'), ('researchers', 'field'), ('field', 'use'), ('use', 'term'), ('term', 'data'), ('data', 'mining'), ('mining', 'describe'), ('describe', 'refine'), ('refine', '“'), ('“', 'ground'), ('ground', '”'), ('”', '('), ('(', 'i.e'), ('i.e', ','), (',', 'raw'), ('raw', 'data'), ('data', ')'), (')', '“'), ('“', 'gold'), ('gold', 'nugget'), ('nugget', '”'), ('”', '('), ('(', 'i.e.-'), ('i.e.-', ','), (',', 'information'), ('information', 'knowledge'), ('knowledge', ')'), (')', '.')]

>> Trigrams are: 
 [('3', ')', 'KDD'), (')', 'KDD', 'responsible'), ('KDD', 'responsible', 'finding'), ('responsible', 'finding', 'hid-'), ('finding', 'hid-', 'den'), ('hid-', 'den', 'patterns/rules/information'), ('den', 'patterns/rules/information', 'data'), ('patterns/rules/information', 'data', ','), ('data', ',', 'researchers'), (',', 'researchers', 'field'), ('researchers', 'field', 'use'), ('field', 'use', 'term'), ('use', 'term', 'data'), ('term', 'data', 'mining'), ('data', 'mining', 'describe'), ('mining', 'describe', 'refine'), ('describe', 'refine', '“'), ('refine', '“', 'ground'), ('“', 'ground', '”'), ('ground', '”', '('), ('”', '(', 'i.e'), ('(', 'i.e', ','), ('i.e', ',', 'raw'), (',', 'raw', 'data'), ('raw', 'data', ')'), ('data', ')', '“'), (')', '“', 'gold'), ('“', 'gold', 'nugget'), ('gold', 'nugget', '”'), ('nugget', '”', '('), ('”', '(', 'i.e.-'), ('(', 'i.e.-', ','), ('i.e.-', ',', 'information'), (',', 'information', 'knowledge'), ('information', 'knowledge', ')'), ('knowledge', ')', '.')]

>> POS Tags are: 
 [('3', 'LS'), (')', ')'), ('KDD', 'NNP'), ('responsible', 'JJ'), ('finding', 'VBG'), ('hid-', 'JJ'), ('den', 'JJ'), ('patterns/rules/information', 'NN'), ('data', 'NNS'), (',', ','), ('researchers', 'NNS'), ('field', 'NN'), ('use', 'VBP'), ('term', 'NN'), ('data', 'NNS'), ('mining', 'NN'), ('describe', 'NN'), ('refine', 'NN'), ('“', 'NNP'), ('ground', 'NN'), ('”', 'NNP'), ('(', '('), ('i.e', 'NN'), (',', ','), ('raw', 'JJ'), ('data', 'NN'), (')', ')'), ('“', 'NNP'), ('gold', 'NN'), ('nugget', 'NN'), ('”', 'NNP'), ('(', '('), ('i.e.-', 'JJ'), (',', ','), ('information', 'NN'), ('knowledge', 'NN'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['KDD', 'hid- den patterns/rules/information data', 'researchers field', 'term data mining describe refine “ ground ”', 'i.e', 'raw data', '“ gold nugget ”', 'information knowledge']

>> Named Entities are: 
 [('ORGANIZATION', 'KDD')] 

>> Stemming using Porter Stemmer: 
 [('3', '3'), (')', ')'), ('KDD', 'kdd'), ('responsible', 'respons'), ('finding', 'find'), ('hid-', 'hid-'), ('den', 'den'), ('patterns/rules/information', 'patterns/rules/inform'), ('data', 'data'), (',', ','), ('researchers', 'research'), ('field', 'field'), ('use', 'use'), ('term', 'term'), ('data', 'data'), ('mining', 'mine'), ('describe', 'describ'), ('refine', 'refin'), ('“', '“'), ('ground', 'ground'), ('”', '”'), ('(', '('), ('i.e', 'i.e'), (',', ','), ('raw', 'raw'), ('data', 'data'), (')', ')'), ('“', '“'), ('gold', 'gold'), ('nugget', 'nugget'), ('”', '”'), ('(', '('), ('i.e.-', 'i.e.-'), (',', ','), ('information', 'inform'), ('knowledge', 'knowledg'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('3', '3'), (')', ')'), ('KDD', 'kdd'), ('responsible', 'respons'), ('finding', 'find'), ('hid-', 'hid-'), ('den', 'den'), ('patterns/rules/information', 'patterns/rules/inform'), ('data', 'data'), (',', ','), ('researchers', 'research'), ('field', 'field'), ('use', 'use'), ('term', 'term'), ('data', 'data'), ('mining', 'mine'), ('describe', 'describ'), ('refine', 'refin'), ('“', '“'), ('ground', 'ground'), ('”', '”'), ('(', '('), ('i.e', 'i.e'), (',', ','), ('raw', 'raw'), ('data', 'data'), (')', ')'), ('“', '“'), ('gold', 'gold'), ('nugget', 'nugget'), ('”', '”'), ('(', '('), ('i.e.-', 'i.e.-'), (',', ','), ('information', 'inform'), ('knowledge', 'knowledg'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('3', '3'), (')', ')'), ('KDD', 'KDD'), ('responsible', 'responsible'), ('finding', 'finding'), ('hid-', 'hid-'), ('den', 'den'), ('patterns/rules/information', 'patterns/rules/information'), ('data', 'data'), (',', ','), ('researchers', 'researcher'), ('field', 'field'), ('use', 'use'), ('term', 'term'), ('data', 'data'), ('mining', 'mining'), ('describe', 'describe'), ('refine', 'refine'), ('“', '“'), ('ground', 'ground'), ('”', '”'), ('(', '('), ('i.e', 'i.e'), (',', ','), ('raw', 'raw'), ('data', 'data'), (')', ')'), ('“', '“'), ('gold', 'gold'), ('nugget', 'nugget'), ('”', '”'), ('(', '('), ('i.e.-', 'i.e.-'), (',', ','), ('information', 'information'), ('knowledge', 'knowledge'), (')', ')'), ('.', '.')]


------------------- Sentence 3 -------------------

The data mining methods [20] are not limited to data  problem specific methods.

>> Tokens are: 
 ['The', 'data', 'mining', 'methods', '[', '20', ']', 'limited', 'data', 'problem', 'specific', 'methods', '.']

>> Bigrams are: 
 [('The', 'data'), ('data', 'mining'), ('mining', 'methods'), ('methods', '['), ('[', '20'), ('20', ']'), (']', 'limited'), ('limited', 'data'), ('data', 'problem'), ('problem', 'specific'), ('specific', 'methods'), ('methods', '.')]

>> Trigrams are: 
 [('The', 'data', 'mining'), ('data', 'mining', 'methods'), ('mining', 'methods', '['), ('methods', '[', '20'), ('[', '20', ']'), ('20', ']', 'limited'), (']', 'limited', 'data'), ('limited', 'data', 'problem'), ('data', 'problem', 'specific'), ('problem', 'specific', 'methods'), ('specific', 'methods', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('data', 'NN'), ('mining', 'NN'), ('methods', 'NNS'), ('[', 'VBP'), ('20', 'CD'), (']', 'NN'), ('limited', 'VBN'), ('data', 'NN'), ('problem', 'NN'), ('specific', 'JJ'), ('methods', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['The data mining methods', ']', 'data problem', 'specific methods']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('data', 'data'), ('mining', 'mine'), ('methods', 'method'), ('[', '['), ('20', '20'), (']', ']'), ('limited', 'limit'), ('data', 'data'), ('problem', 'problem'), ('specific', 'specif'), ('methods', 'method'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('data', 'data'), ('mining', 'mine'), ('methods', 'method'), ('[', '['), ('20', '20'), (']', ']'), ('limited', 'limit'), ('data', 'data'), ('problem', 'problem'), ('specific', 'specif'), ('methods', 'method'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('data', 'data'), ('mining', 'mining'), ('methods', 'method'), ('[', '['), ('20', '20'), (']', ']'), ('limited', 'limited'), ('data', 'data'), ('problem', 'problem'), ('specific', 'specific'), ('methods', 'method'), ('.', '.')]


------------------- Sentence 4 -------------------

In fact, other technologies (e.g.-, statistical or machine learn- ing technologies) have also been used to analyze the data for many years.

>> Tokens are: 
 ['In', 'fact', ',', 'technologies', '(', 'e.g.-', ',', 'statistical', 'machine', 'learn-', 'ing', 'technologies', ')', 'also', 'used', 'analyze', 'data', 'many', 'years', '.']

>> Bigrams are: 
 [('In', 'fact'), ('fact', ','), (',', 'technologies'), ('technologies', '('), ('(', 'e.g.-'), ('e.g.-', ','), (',', 'statistical'), ('statistical', 'machine'), ('machine', 'learn-'), ('learn-', 'ing'), ('ing', 'technologies'), ('technologies', ')'), (')', 'also'), ('also', 'used'), ('used', 'analyze'), ('analyze', 'data'), ('data', 'many'), ('many', 'years'), ('years', '.')]

>> Trigrams are: 
 [('In', 'fact', ','), ('fact', ',', 'technologies'), (',', 'technologies', '('), ('technologies', '(', 'e.g.-'), ('(', 'e.g.-', ','), ('e.g.-', ',', 'statistical'), (',', 'statistical', 'machine'), ('statistical', 'machine', 'learn-'), ('machine', 'learn-', 'ing'), ('learn-', 'ing', 'technologies'), ('ing', 'technologies', ')'), ('technologies', ')', 'also'), (')', 'also', 'used'), ('also', 'used', 'analyze'), ('used', 'analyze', 'data'), ('analyze', 'data', 'many'), ('data', 'many', 'years'), ('many', 'years', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('fact', 'NN'), (',', ','), ('technologies', 'NNS'), ('(', '('), ('e.g.-', 'JJ'), (',', ','), ('statistical', 'JJ'), ('machine', 'NN'), ('learn-', 'JJ'), ('ing', 'NN'), ('technologies', 'NNS'), (')', ')'), ('also', 'RB'), ('used', 'VBN'), ('analyze', 'RB'), ('data', 'RB'), ('many', 'JJ'), ('years', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['fact', 'technologies', 'statistical machine', 'learn- ing technologies', 'many years']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('fact', 'fact'), (',', ','), ('technologies', 'technolog'), ('(', '('), ('e.g.-', 'e.g.-'), (',', ','), ('statistical', 'statist'), ('machine', 'machin'), ('learn-', 'learn-'), ('ing', 'ing'), ('technologies', 'technolog'), (')', ')'), ('also', 'also'), ('used', 'use'), ('analyze', 'analyz'), ('data', 'data'), ('many', 'mani'), ('years', 'year'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('fact', 'fact'), (',', ','), ('technologies', 'technolog'), ('(', '('), ('e.g.-', 'e.g.-'), (',', ','), ('statistical', 'statist'), ('machine', 'machin'), ('learn-', 'learn-'), ('ing', 'ing'), ('technologies', 'technolog'), (')', ')'), ('also', 'also'), ('used', 'use'), ('analyze', 'analyz'), ('data', 'data'), ('many', 'mani'), ('years', 'year'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('fact', 'fact'), (',', ','), ('technologies', 'technology'), ('(', '('), ('e.g.-', 'e.g.-'), (',', ','), ('statistical', 'statistical'), ('machine', 'machine'), ('learn-', 'learn-'), ('ing', 'ing'), ('technologies', 'technology'), (')', ')'), ('also', 'also'), ('used', 'used'), ('analyze', 'analyze'), ('data', 'data'), ('many', 'many'), ('years', 'year'), ('.', '.')]


------------------- Sentence 5 -------------------

In the early  stages of data analysis, the statistical methods were used for analyzing the data to help  us understand the situation we are facing, such as public opinion poll or TV programme  rating.

>> Tokens are: 
 ['In', 'early', 'stages', 'data', 'analysis', ',', 'statistical', 'methods', 'used', 'analyzing', 'data', 'help', 'us', 'understand', 'situation', 'facing', ',', 'public', 'opinion', 'poll', 'TV', 'programme', 'rating', '.']

>> Bigrams are: 
 [('In', 'early'), ('early', 'stages'), ('stages', 'data'), ('data', 'analysis'), ('analysis', ','), (',', 'statistical'), ('statistical', 'methods'), ('methods', 'used'), ('used', 'analyzing'), ('analyzing', 'data'), ('data', 'help'), ('help', 'us'), ('us', 'understand'), ('understand', 'situation'), ('situation', 'facing'), ('facing', ','), (',', 'public'), ('public', 'opinion'), ('opinion', 'poll'), ('poll', 'TV'), ('TV', 'programme'), ('programme', 'rating'), ('rating', '.')]

>> Trigrams are: 
 [('In', 'early', 'stages'), ('early', 'stages', 'data'), ('stages', 'data', 'analysis'), ('data', 'analysis', ','), ('analysis', ',', 'statistical'), (',', 'statistical', 'methods'), ('statistical', 'methods', 'used'), ('methods', 'used', 'analyzing'), ('used', 'analyzing', 'data'), ('analyzing', 'data', 'help'), ('data', 'help', 'us'), ('help', 'us', 'understand'), ('us', 'understand', 'situation'), ('understand', 'situation', 'facing'), ('situation', 'facing', ','), ('facing', ',', 'public'), (',', 'public', 'opinion'), ('public', 'opinion', 'poll'), ('opinion', 'poll', 'TV'), ('poll', 'TV', 'programme'), ('TV', 'programme', 'rating'), ('programme', 'rating', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('early', 'JJ'), ('stages', 'NNS'), ('data', 'NNS'), ('analysis', 'NN'), (',', ','), ('statistical', 'JJ'), ('methods', 'NNS'), ('used', 'VBN'), ('analyzing', 'VBG'), ('data', 'NNS'), ('help', 'VBP'), ('us', 'PRP'), ('understand', 'VB'), ('situation', 'NN'), ('facing', 'NN'), (',', ','), ('public', 'JJ'), ('opinion', 'NN'), ('poll', 'NN'), ('TV', 'NN'), ('programme', 'NN'), ('rating', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['early stages data analysis', 'statistical methods', 'data', 'situation facing', 'public opinion poll TV programme rating']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('early', 'earli'), ('stages', 'stage'), ('data', 'data'), ('analysis', 'analysi'), (',', ','), ('statistical', 'statist'), ('methods', 'method'), ('used', 'use'), ('analyzing', 'analyz'), ('data', 'data'), ('help', 'help'), ('us', 'us'), ('understand', 'understand'), ('situation', 'situat'), ('facing', 'face'), (',', ','), ('public', 'public'), ('opinion', 'opinion'), ('poll', 'poll'), ('TV', 'tv'), ('programme', 'programm'), ('rating', 'rate'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('early', 'earli'), ('stages', 'stage'), ('data', 'data'), ('analysis', 'analysi'), (',', ','), ('statistical', 'statist'), ('methods', 'method'), ('used', 'use'), ('analyzing', 'analyz'), ('data', 'data'), ('help', 'help'), ('us', 'us'), ('understand', 'understand'), ('situation', 'situat'), ('facing', 'face'), (',', ','), ('public', 'public'), ('opinion', 'opinion'), ('poll', 'poll'), ('TV', 'tv'), ('programme', 'programm'), ('rating', 'rate'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('early', 'early'), ('stages', 'stage'), ('data', 'data'), ('analysis', 'analysis'), (',', ','), ('statistical', 'statistical'), ('methods', 'method'), ('used', 'used'), ('analyzing', 'analyzing'), ('data', 'data'), ('help', 'help'), ('us', 'u'), ('understand', 'understand'), ('situation', 'situation'), ('facing', 'facing'), (',', ','), ('public', 'public'), ('opinion', 'opinion'), ('poll', 'poll'), ('TV', 'TV'), ('programme', 'programme'), ('rating', 'rating'), ('.', '.')]


------------------- Sentence 6 -------------------

Like the statistical analysis, the problem specific methods for data mining also  attempted to understand the meaning from the collected data.

>> Tokens are: 
 ['Like', 'statistical', 'analysis', ',', 'problem', 'specific', 'methods', 'data', 'mining', 'also', 'attempted', 'understand', 'meaning', 'collected', 'data', '.']

>> Bigrams are: 
 [('Like', 'statistical'), ('statistical', 'analysis'), ('analysis', ','), (',', 'problem'), ('problem', 'specific'), ('specific', 'methods'), ('methods', 'data'), ('data', 'mining'), ('mining', 'also'), ('also', 'attempted'), ('attempted', 'understand'), ('understand', 'meaning'), ('meaning', 'collected'), ('collected', 'data'), ('data', '.')]

>> Trigrams are: 
 [('Like', 'statistical', 'analysis'), ('statistical', 'analysis', ','), ('analysis', ',', 'problem'), (',', 'problem', 'specific'), ('problem', 'specific', 'methods'), ('specific', 'methods', 'data'), ('methods', 'data', 'mining'), ('data', 'mining', 'also'), ('mining', 'also', 'attempted'), ('also', 'attempted', 'understand'), ('attempted', 'understand', 'meaning'), ('understand', 'meaning', 'collected'), ('meaning', 'collected', 'data'), ('collected', 'data', '.')]

>> POS Tags are: 
 [('Like', 'IN'), ('statistical', 'JJ'), ('analysis', 'NN'), (',', ','), ('problem', 'NN'), ('specific', 'JJ'), ('methods', 'NNS'), ('data', 'NNS'), ('mining', 'NN'), ('also', 'RB'), ('attempted', 'VBD'), ('understand', 'JJ'), ('meaning', 'NN'), ('collected', 'VBN'), ('data', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['statistical analysis', 'problem', 'specific methods data mining', 'understand meaning', 'data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Like', 'like'), ('statistical', 'statist'), ('analysis', 'analysi'), (',', ','), ('problem', 'problem'), ('specific', 'specif'), ('methods', 'method'), ('data', 'data'), ('mining', 'mine'), ('also', 'also'), ('attempted', 'attempt'), ('understand', 'understand'), ('meaning', 'mean'), ('collected', 'collect'), ('data', 'data'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Like', 'like'), ('statistical', 'statist'), ('analysis', 'analysi'), (',', ','), ('problem', 'problem'), ('specific', 'specif'), ('methods', 'method'), ('data', 'data'), ('mining', 'mine'), ('also', 'also'), ('attempted', 'attempt'), ('understand', 'understand'), ('meaning', 'mean'), ('collected', 'collect'), ('data', 'data'), ('.', '.')]

>> Lemmatization: 
 [('Like', 'Like'), ('statistical', 'statistical'), ('analysis', 'analysis'), (',', ','), ('problem', 'problem'), ('specific', 'specific'), ('methods', 'method'), ('data', 'data'), ('mining', 'mining'), ('also', 'also'), ('attempted', 'attempted'), ('understand', 'understand'), ('meaning', 'meaning'), ('collected', 'collected'), ('data', 'data'), ('.', '.')]



========================================== PARAGRAPH 79 ===========================================

After the data mining problem was presented, some of the domain specific algorithms  are also developed. An example is the apriori algorithm [21] which is one of the useful algo- rithms designed for the association rules problem. Although most definitions of data min- ing problems are simple, the computation costs are quite high. To speed up the response  time of a data mining operator, machine learning [22], metaheuristic algorithms [23], and  distributed computing [24] were used alone or combined with the traditional data mining  algorithms to provide more efficient ways for solving the data mining problem. One of the  well-known combinations can be found in [25], Krishna and Murty attempted to combine  genetic algorithm and k-means to get better clustering result than k-means alone does. 

------------------- Sentence 1 -------------------

After the data mining problem was presented, some of the domain specific algorithms  are also developed.

>> Tokens are: 
 ['After', 'data', 'mining', 'problem', 'presented', ',', 'domain', 'specific', 'algorithms', 'also', 'developed', '.']

>> Bigrams are: 
 [('After', 'data'), ('data', 'mining'), ('mining', 'problem'), ('problem', 'presented'), ('presented', ','), (',', 'domain'), ('domain', 'specific'), ('specific', 'algorithms'), ('algorithms', 'also'), ('also', 'developed'), ('developed', '.')]

>> Trigrams are: 
 [('After', 'data', 'mining'), ('data', 'mining', 'problem'), ('mining', 'problem', 'presented'), ('problem', 'presented', ','), ('presented', ',', 'domain'), (',', 'domain', 'specific'), ('domain', 'specific', 'algorithms'), ('specific', 'algorithms', 'also'), ('algorithms', 'also', 'developed'), ('also', 'developed', '.')]

>> POS Tags are: 
 [('After', 'IN'), ('data', 'NNS'), ('mining', 'NN'), ('problem', 'NN'), ('presented', 'VBN'), (',', ','), ('domain', 'VBP'), ('specific', 'JJ'), ('algorithms', 'NN'), ('also', 'RB'), ('developed', 'VBD'), ('.', '.')]

>> Noun Phrases are: 
 ['data mining problem', 'specific algorithms']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('After', 'after'), ('data', 'data'), ('mining', 'mine'), ('problem', 'problem'), ('presented', 'present'), (',', ','), ('domain', 'domain'), ('specific', 'specif'), ('algorithms', 'algorithm'), ('also', 'also'), ('developed', 'develop'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('After', 'after'), ('data', 'data'), ('mining', 'mine'), ('problem', 'problem'), ('presented', 'present'), (',', ','), ('domain', 'domain'), ('specific', 'specif'), ('algorithms', 'algorithm'), ('also', 'also'), ('developed', 'develop'), ('.', '.')]

>> Lemmatization: 
 [('After', 'After'), ('data', 'data'), ('mining', 'mining'), ('problem', 'problem'), ('presented', 'presented'), (',', ','), ('domain', 'domain'), ('specific', 'specific'), ('algorithms', 'algorithm'), ('also', 'also'), ('developed', 'developed'), ('.', '.')]


------------------- Sentence 2 -------------------

An example is the apriori algorithm [21] which is one of the useful algo- rithms designed for the association rules problem.

>> Tokens are: 
 ['An', 'example', 'apriori', 'algorithm', '[', '21', ']', 'one', 'useful', 'algo-', 'rithms', 'designed', 'association', 'rules', 'problem', '.']

>> Bigrams are: 
 [('An', 'example'), ('example', 'apriori'), ('apriori', 'algorithm'), ('algorithm', '['), ('[', '21'), ('21', ']'), (']', 'one'), ('one', 'useful'), ('useful', 'algo-'), ('algo-', 'rithms'), ('rithms', 'designed'), ('designed', 'association'), ('association', 'rules'), ('rules', 'problem'), ('problem', '.')]

>> Trigrams are: 
 [('An', 'example', 'apriori'), ('example', 'apriori', 'algorithm'), ('apriori', 'algorithm', '['), ('algorithm', '[', '21'), ('[', '21', ']'), ('21', ']', 'one'), (']', 'one', 'useful'), ('one', 'useful', 'algo-'), ('useful', 'algo-', 'rithms'), ('algo-', 'rithms', 'designed'), ('rithms', 'designed', 'association'), ('designed', 'association', 'rules'), ('association', 'rules', 'problem'), ('rules', 'problem', '.')]

>> POS Tags are: 
 [('An', 'DT'), ('example', 'NN'), ('apriori', 'NN'), ('algorithm', 'VBZ'), ('[', '$'), ('21', 'CD'), (']', 'NNP'), ('one', 'CD'), ('useful', 'JJ'), ('algo-', 'JJ'), ('rithms', 'NN'), ('designed', 'VBN'), ('association', 'NN'), ('rules', 'NNS'), ('problem', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['An example apriori', ']', 'useful algo- rithms', 'association rules problem']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('An', 'an'), ('example', 'exampl'), ('apriori', 'apriori'), ('algorithm', 'algorithm'), ('[', '['), ('21', '21'), (']', ']'), ('one', 'one'), ('useful', 'use'), ('algo-', 'algo-'), ('rithms', 'rithm'), ('designed', 'design'), ('association', 'associ'), ('rules', 'rule'), ('problem', 'problem'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('An', 'an'), ('example', 'exampl'), ('apriori', 'apriori'), ('algorithm', 'algorithm'), ('[', '['), ('21', '21'), (']', ']'), ('one', 'one'), ('useful', 'use'), ('algo-', 'algo-'), ('rithms', 'rithm'), ('designed', 'design'), ('association', 'associ'), ('rules', 'rule'), ('problem', 'problem'), ('.', '.')]

>> Lemmatization: 
 [('An', 'An'), ('example', 'example'), ('apriori', 'apriori'), ('algorithm', 'algorithm'), ('[', '['), ('21', '21'), (']', ']'), ('one', 'one'), ('useful', 'useful'), ('algo-', 'algo-'), ('rithms', 'rithms'), ('designed', 'designed'), ('association', 'association'), ('rules', 'rule'), ('problem', 'problem'), ('.', '.')]


------------------- Sentence 3 -------------------

Although most definitions of data min- ing problems are simple, the computation costs are quite high.

>> Tokens are: 
 ['Although', 'definitions', 'data', 'min-', 'ing', 'problems', 'simple', ',', 'computation', 'costs', 'quite', 'high', '.']

>> Bigrams are: 
 [('Although', 'definitions'), ('definitions', 'data'), ('data', 'min-'), ('min-', 'ing'), ('ing', 'problems'), ('problems', 'simple'), ('simple', ','), (',', 'computation'), ('computation', 'costs'), ('costs', 'quite'), ('quite', 'high'), ('high', '.')]

>> Trigrams are: 
 [('Although', 'definitions', 'data'), ('definitions', 'data', 'min-'), ('data', 'min-', 'ing'), ('min-', 'ing', 'problems'), ('ing', 'problems', 'simple'), ('problems', 'simple', ','), ('simple', ',', 'computation'), (',', 'computation', 'costs'), ('computation', 'costs', 'quite'), ('costs', 'quite', 'high'), ('quite', 'high', '.')]

>> POS Tags are: 
 [('Although', 'IN'), ('definitions', 'NNS'), ('data', 'NNS'), ('min-', 'NNS'), ('ing', 'VBG'), ('problems', 'NNS'), ('simple', 'JJ'), (',', ','), ('computation', 'NN'), ('costs', 'NNS'), ('quite', 'RB'), ('high', 'JJ'), ('.', '.')]

>> Noun Phrases are: 
 ['definitions data min-', 'problems', 'computation costs']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Although', 'although'), ('definitions', 'definit'), ('data', 'data'), ('min-', 'min-'), ('ing', 'ing'), ('problems', 'problem'), ('simple', 'simpl'), (',', ','), ('computation', 'comput'), ('costs', 'cost'), ('quite', 'quit'), ('high', 'high'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Although', 'although'), ('definitions', 'definit'), ('data', 'data'), ('min-', 'min-'), ('ing', 'ing'), ('problems', 'problem'), ('simple', 'simpl'), (',', ','), ('computation', 'comput'), ('costs', 'cost'), ('quite', 'quit'), ('high', 'high'), ('.', '.')]

>> Lemmatization: 
 [('Although', 'Although'), ('definitions', 'definition'), ('data', 'data'), ('min-', 'min-'), ('ing', 'ing'), ('problems', 'problem'), ('simple', 'simple'), (',', ','), ('computation', 'computation'), ('costs', 'cost'), ('quite', 'quite'), ('high', 'high'), ('.', '.')]


------------------- Sentence 4 -------------------

To speed up the response  time of a data mining operator, machine learning [22], metaheuristic algorithms [23], and  distributed computing [24] were used alone or combined with the traditional data mining  algorithms to provide more efficient ways for solving the data mining problem.

>> Tokens are: 
 ['To', 'speed', 'response', 'time', 'data', 'mining', 'operator', ',', 'machine', 'learning', '[', '22', ']', ',', 'metaheuristic', 'algorithms', '[', '23', ']', ',', 'distributed', 'computing', '[', '24', ']', 'used', 'alone', 'combined', 'traditional', 'data', 'mining', 'algorithms', 'provide', 'efficient', 'ways', 'solving', 'data', 'mining', 'problem', '.']

>> Bigrams are: 
 [('To', 'speed'), ('speed', 'response'), ('response', 'time'), ('time', 'data'), ('data', 'mining'), ('mining', 'operator'), ('operator', ','), (',', 'machine'), ('machine', 'learning'), ('learning', '['), ('[', '22'), ('22', ']'), (']', ','), (',', 'metaheuristic'), ('metaheuristic', 'algorithms'), ('algorithms', '['), ('[', '23'), ('23', ']'), (']', ','), (',', 'distributed'), ('distributed', 'computing'), ('computing', '['), ('[', '24'), ('24', ']'), (']', 'used'), ('used', 'alone'), ('alone', 'combined'), ('combined', 'traditional'), ('traditional', 'data'), ('data', 'mining'), ('mining', 'algorithms'), ('algorithms', 'provide'), ('provide', 'efficient'), ('efficient', 'ways'), ('ways', 'solving'), ('solving', 'data'), ('data', 'mining'), ('mining', 'problem'), ('problem', '.')]

>> Trigrams are: 
 [('To', 'speed', 'response'), ('speed', 'response', 'time'), ('response', 'time', 'data'), ('time', 'data', 'mining'), ('data', 'mining', 'operator'), ('mining', 'operator', ','), ('operator', ',', 'machine'), (',', 'machine', 'learning'), ('machine', 'learning', '['), ('learning', '[', '22'), ('[', '22', ']'), ('22', ']', ','), (']', ',', 'metaheuristic'), (',', 'metaheuristic', 'algorithms'), ('metaheuristic', 'algorithms', '['), ('algorithms', '[', '23'), ('[', '23', ']'), ('23', ']', ','), (']', ',', 'distributed'), (',', 'distributed', 'computing'), ('distributed', 'computing', '['), ('computing', '[', '24'), ('[', '24', ']'), ('24', ']', 'used'), (']', 'used', 'alone'), ('used', 'alone', 'combined'), ('alone', 'combined', 'traditional'), ('combined', 'traditional', 'data'), ('traditional', 'data', 'mining'), ('data', 'mining', 'algorithms'), ('mining', 'algorithms', 'provide'), ('algorithms', 'provide', 'efficient'), ('provide', 'efficient', 'ways'), ('efficient', 'ways', 'solving'), ('ways', 'solving', 'data'), ('solving', 'data', 'mining'), ('data', 'mining', 'problem'), ('mining', 'problem', '.')]

>> POS Tags are: 
 [('To', 'TO'), ('speed', 'VB'), ('response', 'NN'), ('time', 'NN'), ('data', 'NNS'), ('mining', 'NN'), ('operator', 'NN'), (',', ','), ('machine', 'NN'), ('learning', 'VBG'), ('[', 'JJ'), ('22', 'CD'), (']', 'NN'), (',', ','), ('metaheuristic', 'JJ'), ('algorithms', 'NN'), ('[', 'VBD'), ('23', 'CD'), (']', 'NN'), (',', ','), ('distributed', 'VBD'), ('computing', 'VBG'), ('[', 'JJ'), ('24', 'CD'), (']', 'NNS'), ('used', 'VBN'), ('alone', 'RB'), ('combined', 'JJ'), ('traditional', 'JJ'), ('data', 'NNS'), ('mining', 'NN'), ('algorithms', 'NN'), ('provide', 'VBP'), ('efficient', 'JJ'), ('ways', 'NNS'), ('solving', 'VBG'), ('data', 'NNS'), ('mining', 'NN'), ('problem', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['response time data mining operator', 'machine', ']', 'metaheuristic algorithms', ']', ']', 'combined traditional data mining algorithms', 'efficient ways', 'data mining problem']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('To', 'to'), ('speed', 'speed'), ('response', 'respons'), ('time', 'time'), ('data', 'data'), ('mining', 'mine'), ('operator', 'oper'), (',', ','), ('machine', 'machin'), ('learning', 'learn'), ('[', '['), ('22', '22'), (']', ']'), (',', ','), ('metaheuristic', 'metaheurist'), ('algorithms', 'algorithm'), ('[', '['), ('23', '23'), (']', ']'), (',', ','), ('distributed', 'distribut'), ('computing', 'comput'), ('[', '['), ('24', '24'), (']', ']'), ('used', 'use'), ('alone', 'alon'), ('combined', 'combin'), ('traditional', 'tradit'), ('data', 'data'), ('mining', 'mine'), ('algorithms', 'algorithm'), ('provide', 'provid'), ('efficient', 'effici'), ('ways', 'way'), ('solving', 'solv'), ('data', 'data'), ('mining', 'mine'), ('problem', 'problem'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('To', 'to'), ('speed', 'speed'), ('response', 'respons'), ('time', 'time'), ('data', 'data'), ('mining', 'mine'), ('operator', 'oper'), (',', ','), ('machine', 'machin'), ('learning', 'learn'), ('[', '['), ('22', '22'), (']', ']'), (',', ','), ('metaheuristic', 'metaheurist'), ('algorithms', 'algorithm'), ('[', '['), ('23', '23'), (']', ']'), (',', ','), ('distributed', 'distribut'), ('computing', 'comput'), ('[', '['), ('24', '24'), (']', ']'), ('used', 'use'), ('alone', 'alon'), ('combined', 'combin'), ('traditional', 'tradit'), ('data', 'data'), ('mining', 'mine'), ('algorithms', 'algorithm'), ('provide', 'provid'), ('efficient', 'effici'), ('ways', 'way'), ('solving', 'solv'), ('data', 'data'), ('mining', 'mine'), ('problem', 'problem'), ('.', '.')]

>> Lemmatization: 
 [('To', 'To'), ('speed', 'speed'), ('response', 'response'), ('time', 'time'), ('data', 'data'), ('mining', 'mining'), ('operator', 'operator'), (',', ','), ('machine', 'machine'), ('learning', 'learning'), ('[', '['), ('22', '22'), (']', ']'), (',', ','), ('metaheuristic', 'metaheuristic'), ('algorithms', 'algorithm'), ('[', '['), ('23', '23'), (']', ']'), (',', ','), ('distributed', 'distributed'), ('computing', 'computing'), ('[', '['), ('24', '24'), (']', ']'), ('used', 'used'), ('alone', 'alone'), ('combined', 'combined'), ('traditional', 'traditional'), ('data', 'data'), ('mining', 'mining'), ('algorithms', 'algorithm'), ('provide', 'provide'), ('efficient', 'efficient'), ('ways', 'way'), ('solving', 'solving'), ('data', 'data'), ('mining', 'mining'), ('problem', 'problem'), ('.', '.')]


------------------- Sentence 5 -------------------

One of the  well-known combinations can be found in [25], Krishna and Murty attempted to combine  genetic algorithm and k-means to get better clustering result than k-means alone does.

>> Tokens are: 
 ['One', 'well-known', 'combinations', 'found', '[', '25', ']', ',', 'Krishna', 'Murty', 'attempted', 'combine', 'genetic', 'algorithm', 'k-means', 'get', 'better', 'clustering', 'result', 'k-means', 'alone', '.']

>> Bigrams are: 
 [('One', 'well-known'), ('well-known', 'combinations'), ('combinations', 'found'), ('found', '['), ('[', '25'), ('25', ']'), (']', ','), (',', 'Krishna'), ('Krishna', 'Murty'), ('Murty', 'attempted'), ('attempted', 'combine'), ('combine', 'genetic'), ('genetic', 'algorithm'), ('algorithm', 'k-means'), ('k-means', 'get'), ('get', 'better'), ('better', 'clustering'), ('clustering', 'result'), ('result', 'k-means'), ('k-means', 'alone'), ('alone', '.')]

>> Trigrams are: 
 [('One', 'well-known', 'combinations'), ('well-known', 'combinations', 'found'), ('combinations', 'found', '['), ('found', '[', '25'), ('[', '25', ']'), ('25', ']', ','), (']', ',', 'Krishna'), (',', 'Krishna', 'Murty'), ('Krishna', 'Murty', 'attempted'), ('Murty', 'attempted', 'combine'), ('attempted', 'combine', 'genetic'), ('combine', 'genetic', 'algorithm'), ('genetic', 'algorithm', 'k-means'), ('algorithm', 'k-means', 'get'), ('k-means', 'get', 'better'), ('get', 'better', 'clustering'), ('better', 'clustering', 'result'), ('clustering', 'result', 'k-means'), ('result', 'k-means', 'alone'), ('k-means', 'alone', '.')]

>> POS Tags are: 
 [('One', 'CD'), ('well-known', 'JJ'), ('combinations', 'NNS'), ('found', 'VBD'), ('[', 'RB'), ('25', 'CD'), (']', 'NN'), (',', ','), ('Krishna', 'NNP'), ('Murty', 'NNP'), ('attempted', 'VBD'), ('combine', 'JJ'), ('genetic', 'JJ'), ('algorithm', 'NN'), ('k-means', 'NNS'), ('get', 'VBP'), ('better', 'JJR'), ('clustering', 'VBG'), ('result', 'JJ'), ('k-means', 'NNS'), ('alone', 'RB'), ('.', '.')]

>> Noun Phrases are: 
 ['well-known combinations', ']', 'Krishna Murty', 'combine genetic algorithm k-means', 'result k-means']

>> Named Entities are: 
 [('PERSON', 'Krishna Murty')] 

>> Stemming using Porter Stemmer: 
 [('One', 'one'), ('well-known', 'well-known'), ('combinations', 'combin'), ('found', 'found'), ('[', '['), ('25', '25'), (']', ']'), (',', ','), ('Krishna', 'krishna'), ('Murty', 'murti'), ('attempted', 'attempt'), ('combine', 'combin'), ('genetic', 'genet'), ('algorithm', 'algorithm'), ('k-means', 'k-mean'), ('get', 'get'), ('better', 'better'), ('clustering', 'cluster'), ('result', 'result'), ('k-means', 'k-mean'), ('alone', 'alon'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('One', 'one'), ('well-known', 'well-known'), ('combinations', 'combin'), ('found', 'found'), ('[', '['), ('25', '25'), (']', ']'), (',', ','), ('Krishna', 'krishna'), ('Murty', 'murti'), ('attempted', 'attempt'), ('combine', 'combin'), ('genetic', 'genet'), ('algorithm', 'algorithm'), ('k-means', 'k-mean'), ('get', 'get'), ('better', 'better'), ('clustering', 'cluster'), ('result', 'result'), ('k-means', 'k-mean'), ('alone', 'alon'), ('.', '.')]

>> Lemmatization: 
 [('One', 'One'), ('well-known', 'well-known'), ('combinations', 'combination'), ('found', 'found'), ('[', '['), ('25', '25'), (']', ']'), (',', ','), ('Krishna', 'Krishna'), ('Murty', 'Murty'), ('attempted', 'attempted'), ('combine', 'combine'), ('genetic', 'genetic'), ('algorithm', 'algorithm'), ('k-means', 'k-means'), ('get', 'get'), ('better', 'better'), ('clustering', 'clustering'), ('result', 'result'), ('k-means', 'k-means'), ('alone', 'alone'), ('.', '.')]



========================================== PARAGRAPH 80 ===========================================

As Fig.  4 shows, most data mining algorithms contain the initialization, data input  and output, data scan, rules construction, and rules update operators [26]. In Fig. 4, D 

------------------- Sentence 1 -------------------

As Fig.

>> Tokens are: 
 ['As', 'Fig', '.']

>> Bigrams are: 
 [('As', 'Fig'), ('Fig', '.')]

>> Trigrams are: 
 [('As', 'Fig', '.')]

>> POS Tags are: 
 [('As', 'IN'), ('Fig', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Fig']

>> Named Entities are: 
 [('PERSON', 'Fig')] 

>> Stemming using Porter Stemmer: 
 [('As', 'as'), ('Fig', 'fig'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('As', 'as'), ('Fig', 'fig'), ('.', '.')]

>> Lemmatization: 
 [('As', 'As'), ('Fig', 'Fig'), ('.', '.')]


------------------- Sentence 2 -------------------

4 shows, most data mining algorithms contain the initialization, data input  and output, data scan, rules construction, and rules update operators [26].

>> Tokens are: 
 ['4', 'shows', ',', 'data', 'mining', 'algorithms', 'contain', 'initialization', ',', 'data', 'input', 'output', ',', 'data', 'scan', ',', 'rules', 'construction', ',', 'rules', 'update', 'operators', '[', '26', ']', '.']

>> Bigrams are: 
 [('4', 'shows'), ('shows', ','), (',', 'data'), ('data', 'mining'), ('mining', 'algorithms'), ('algorithms', 'contain'), ('contain', 'initialization'), ('initialization', ','), (',', 'data'), ('data', 'input'), ('input', 'output'), ('output', ','), (',', 'data'), ('data', 'scan'), ('scan', ','), (',', 'rules'), ('rules', 'construction'), ('construction', ','), (',', 'rules'), ('rules', 'update'), ('update', 'operators'), ('operators', '['), ('[', '26'), ('26', ']'), (']', '.')]

>> Trigrams are: 
 [('4', 'shows', ','), ('shows', ',', 'data'), (',', 'data', 'mining'), ('data', 'mining', 'algorithms'), ('mining', 'algorithms', 'contain'), ('algorithms', 'contain', 'initialization'), ('contain', 'initialization', ','), ('initialization', ',', 'data'), (',', 'data', 'input'), ('data', 'input', 'output'), ('input', 'output', ','), ('output', ',', 'data'), (',', 'data', 'scan'), ('data', 'scan', ','), ('scan', ',', 'rules'), (',', 'rules', 'construction'), ('rules', 'construction', ','), ('construction', ',', 'rules'), (',', 'rules', 'update'), ('rules', 'update', 'operators'), ('update', 'operators', '['), ('operators', '[', '26'), ('[', '26', ']'), ('26', ']', '.')]

>> POS Tags are: 
 [('4', 'CD'), ('shows', 'NNS'), (',', ','), ('data', 'NNS'), ('mining', 'NN'), ('algorithms', 'NN'), ('contain', 'NN'), ('initialization', 'NN'), (',', ','), ('data', 'NNS'), ('input', 'NN'), ('output', 'NN'), (',', ','), ('data', 'NNS'), ('scan', 'NNS'), (',', ','), ('rules', 'NNS'), ('construction', 'NN'), (',', ','), ('rules', 'NNS'), ('update', 'VBP'), ('operators', 'NNS'), ('[', 'VBP'), ('26', 'CD'), (']', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['shows', 'data mining algorithms contain initialization', 'data input output', 'data scan', 'rules construction', 'rules', 'operators', ']']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('4', '4'), ('shows', 'show'), (',', ','), ('data', 'data'), ('mining', 'mine'), ('algorithms', 'algorithm'), ('contain', 'contain'), ('initialization', 'initi'), (',', ','), ('data', 'data'), ('input', 'input'), ('output', 'output'), (',', ','), ('data', 'data'), ('scan', 'scan'), (',', ','), ('rules', 'rule'), ('construction', 'construct'), (',', ','), ('rules', 'rule'), ('update', 'updat'), ('operators', 'oper'), ('[', '['), ('26', '26'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('4', '4'), ('shows', 'show'), (',', ','), ('data', 'data'), ('mining', 'mine'), ('algorithms', 'algorithm'), ('contain', 'contain'), ('initialization', 'initi'), (',', ','), ('data', 'data'), ('input', 'input'), ('output', 'output'), (',', ','), ('data', 'data'), ('scan', 'scan'), (',', ','), ('rules', 'rule'), ('construction', 'construct'), (',', ','), ('rules', 'rule'), ('update', 'updat'), ('operators', 'oper'), ('[', '['), ('26', '26'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('4', '4'), ('shows', 'show'), (',', ','), ('data', 'data'), ('mining', 'mining'), ('algorithms', 'algorithm'), ('contain', 'contain'), ('initialization', 'initialization'), (',', ','), ('data', 'data'), ('input', 'input'), ('output', 'output'), (',', ','), ('data', 'data'), ('scan', 'scan'), (',', ','), ('rules', 'rule'), ('construction', 'construction'), (',', ','), ('rules', 'rule'), ('update', 'update'), ('operators', 'operator'), ('[', '['), ('26', '26'), (']', ']'), ('.', '.')]


------------------- Sentence 3 -------------------

In Fig.

>> Tokens are: 
 ['In', 'Fig', '.']

>> Bigrams are: 
 [('In', 'Fig'), ('Fig', '.')]

>> Trigrams are: 
 [('In', 'Fig', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('Fig', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Fig']

>> Named Entities are: 
 [('GPE', 'Fig')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('Fig', 'fig'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('Fig', 'fig'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('Fig', 'Fig'), ('.', '.')]


------------------- Sentence 4 -------------------

4, D

>> Tokens are: 
 ['4', ',', 'D']

>> Bigrams are: 
 [('4', ','), (',', 'D')]

>> Trigrams are: 
 [('4', ',', 'D')]

>> POS Tags are: 
 [('4', 'CD'), (',', ','), ('D', 'NNP')]

>> Noun Phrases are: 
 ['D']

>> Named Entities are: 
 [('PERSON', 'D')] 

>> Stemming using Porter Stemmer: 
 [('4', '4'), (',', ','), ('D', 'd')]

>> Stemming using Snowball Stemmer: 
 [('4', '4'), (',', ','), ('D', 'd')]

>> Lemmatization: 
 [('4', '4'), (',', ','), ('D', 'D')]



========================================== PARAGRAPH 81 ===========================================

Page 5 of 32Tsai et al. Journal of Big Data  (2015) 2:21  

------------------- Sentence 1 -------------------

Page 5 of 32Tsai et al.

>> Tokens are: 
 ['Page', '5', '32Tsai', 'et', 'al', '.']

>> Bigrams are: 
 [('Page', '5'), ('5', '32Tsai'), ('32Tsai', 'et'), ('et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('Page', '5', '32Tsai'), ('5', '32Tsai', 'et'), ('32Tsai', 'et', 'al'), ('et', 'al', '.')]

>> POS Tags are: 
 [('Page', 'NN'), ('5', 'CD'), ('32Tsai', 'CD'), ('et', 'NN'), ('al', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Page', 'et al']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Page', 'page'), ('5', '5'), ('32Tsai', '32tsai'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Page', 'page'), ('5', '5'), ('32Tsai', '32tsai'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('Page', 'Page'), ('5', '5'), ('32Tsai', '32Tsai'), ('et', 'et'), ('al', 'al'), ('.', '.')]


------------------- Sentence 2 -------------------

Journal of Big Data  (2015) 2:21

>> Tokens are: 
 ['Journal', 'Big', 'Data', '(', '2015', ')', '2:21']

>> Bigrams are: 
 [('Journal', 'Big'), ('Big', 'Data'), ('Data', '('), ('(', '2015'), ('2015', ')'), (')', '2:21')]

>> Trigrams are: 
 [('Journal', 'Big', 'Data'), ('Big', 'Data', '('), ('Data', '(', '2015'), ('(', '2015', ')'), ('2015', ')', '2:21')]

>> POS Tags are: 
 [('Journal', 'NNP'), ('Big', 'NNP'), ('Data', 'NNP'), ('(', '('), ('2015', 'CD'), (')', ')'), ('2:21', 'CD')]

>> Noun Phrases are: 
 ['Journal Big Data']

>> Named Entities are: 
 [('PERSON', 'Journal')] 

>> Stemming using Porter Stemmer: 
 [('Journal', 'journal'), ('Big', 'big'), ('Data', 'data'), ('(', '('), ('2015', '2015'), (')', ')'), ('2:21', '2:21')]

>> Stemming using Snowball Stemmer: 
 [('Journal', 'journal'), ('Big', 'big'), ('Data', 'data'), ('(', '('), ('2015', '2015'), (')', ')'), ('2:21', '2:21')]

>> Lemmatization: 
 [('Journal', 'Journal'), ('Big', 'Big'), ('Data', 'Data'), ('(', '('), ('2015', '2015'), (')', ')'), ('2:21', '2:21')]



========================================== PARAGRAPH 82 ===========================================

represents the raw data, d the data from the scan operator, r the rules, o the predefined  measurement, and v the candidate rules. The scan, construct, and update operators will  be performed repeatedly until the termination criterion is met. The timing to employ the  scan operator depends on the design of the data mining algorithm; thus, it can be con- sidered as an optional operator. Most of the data algorithms can be described by Fig. 4 in  which it also shows that the representative algorithms—clustering, classification, associ- ation rules, and sequential patterns—will apply these operators to find the hidden infor- mation from the raw data. Thus, modifying these operators will be one of the possible  ways for enhancing the performance of the data analysis. 

------------------- Sentence 1 -------------------

represents the raw data, d the data from the scan operator, r the rules, o the predefined  measurement, and v the candidate rules.

>> Tokens are: 
 ['represents', 'raw', 'data', ',', 'data', 'scan', 'operator', ',', 'r', 'rules', ',', 'predefined', 'measurement', ',', 'v', 'candidate', 'rules', '.']

>> Bigrams are: 
 [('represents', 'raw'), ('raw', 'data'), ('data', ','), (',', 'data'), ('data', 'scan'), ('scan', 'operator'), ('operator', ','), (',', 'r'), ('r', 'rules'), ('rules', ','), (',', 'predefined'), ('predefined', 'measurement'), ('measurement', ','), (',', 'v'), ('v', 'candidate'), ('candidate', 'rules'), ('rules', '.')]

>> Trigrams are: 
 [('represents', 'raw', 'data'), ('raw', 'data', ','), ('data', ',', 'data'), (',', 'data', 'scan'), ('data', 'scan', 'operator'), ('scan', 'operator', ','), ('operator', ',', 'r'), (',', 'r', 'rules'), ('r', 'rules', ','), ('rules', ',', 'predefined'), (',', 'predefined', 'measurement'), ('predefined', 'measurement', ','), ('measurement', ',', 'v'), (',', 'v', 'candidate'), ('v', 'candidate', 'rules'), ('candidate', 'rules', '.')]

>> POS Tags are: 
 [('represents', 'VBZ'), ('raw', 'JJ'), ('data', 'NNS'), (',', ','), ('data', 'NNS'), ('scan', 'NN'), ('operator', 'NN'), (',', ','), ('r', 'NN'), ('rules', 'NNS'), (',', ','), ('predefined', 'VBD'), ('measurement', 'NN'), (',', ','), ('v', 'JJ'), ('candidate', 'NN'), ('rules', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['raw data', 'data scan operator', 'r rules', 'measurement', 'v candidate rules']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('represents', 'repres'), ('raw', 'raw'), ('data', 'data'), (',', ','), ('data', 'data'), ('scan', 'scan'), ('operator', 'oper'), (',', ','), ('r', 'r'), ('rules', 'rule'), (',', ','), ('predefined', 'predefin'), ('measurement', 'measur'), (',', ','), ('v', 'v'), ('candidate', 'candid'), ('rules', 'rule'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('represents', 'repres'), ('raw', 'raw'), ('data', 'data'), (',', ','), ('data', 'data'), ('scan', 'scan'), ('operator', 'oper'), (',', ','), ('r', 'r'), ('rules', 'rule'), (',', ','), ('predefined', 'predefin'), ('measurement', 'measur'), (',', ','), ('v', 'v'), ('candidate', 'candid'), ('rules', 'rule'), ('.', '.')]

>> Lemmatization: 
 [('represents', 'represents'), ('raw', 'raw'), ('data', 'data'), (',', ','), ('data', 'data'), ('scan', 'scan'), ('operator', 'operator'), (',', ','), ('r', 'r'), ('rules', 'rule'), (',', ','), ('predefined', 'predefined'), ('measurement', 'measurement'), (',', ','), ('v', 'v'), ('candidate', 'candidate'), ('rules', 'rule'), ('.', '.')]


------------------- Sentence 2 -------------------

The scan, construct, and update operators will  be performed repeatedly until the termination criterion is met.

>> Tokens are: 
 ['The', 'scan', ',', 'construct', ',', 'update', 'operators', 'performed', 'repeatedly', 'termination', 'criterion', 'met', '.']

>> Bigrams are: 
 [('The', 'scan'), ('scan', ','), (',', 'construct'), ('construct', ','), (',', 'update'), ('update', 'operators'), ('operators', 'performed'), ('performed', 'repeatedly'), ('repeatedly', 'termination'), ('termination', 'criterion'), ('criterion', 'met'), ('met', '.')]

>> Trigrams are: 
 [('The', 'scan', ','), ('scan', ',', 'construct'), (',', 'construct', ','), ('construct', ',', 'update'), (',', 'update', 'operators'), ('update', 'operators', 'performed'), ('operators', 'performed', 'repeatedly'), ('performed', 'repeatedly', 'termination'), ('repeatedly', 'termination', 'criterion'), ('termination', 'criterion', 'met'), ('criterion', 'met', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('scan', 'JJ'), (',', ','), ('construct', 'NN'), (',', ','), ('update', 'NN'), ('operators', 'NNS'), ('performed', 'VBD'), ('repeatedly', 'RB'), ('termination', 'JJ'), ('criterion', 'NN'), ('met', 'VBD'), ('.', '.')]

>> Noun Phrases are: 
 ['construct', 'update operators', 'termination criterion']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('scan', 'scan'), (',', ','), ('construct', 'construct'), (',', ','), ('update', 'updat'), ('operators', 'oper'), ('performed', 'perform'), ('repeatedly', 'repeatedli'), ('termination', 'termin'), ('criterion', 'criterion'), ('met', 'met'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('scan', 'scan'), (',', ','), ('construct', 'construct'), (',', ','), ('update', 'updat'), ('operators', 'oper'), ('performed', 'perform'), ('repeatedly', 'repeat'), ('termination', 'termin'), ('criterion', 'criterion'), ('met', 'met'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('scan', 'scan'), (',', ','), ('construct', 'construct'), (',', ','), ('update', 'update'), ('operators', 'operator'), ('performed', 'performed'), ('repeatedly', 'repeatedly'), ('termination', 'termination'), ('criterion', 'criterion'), ('met', 'met'), ('.', '.')]


------------------- Sentence 3 -------------------

The timing to employ the  scan operator depends on the design of the data mining algorithm; thus, it can be con- sidered as an optional operator.

>> Tokens are: 
 ['The', 'timing', 'employ', 'scan', 'operator', 'depends', 'design', 'data', 'mining', 'algorithm', ';', 'thus', ',', 'con-', 'sidered', 'optional', 'operator', '.']

>> Bigrams are: 
 [('The', 'timing'), ('timing', 'employ'), ('employ', 'scan'), ('scan', 'operator'), ('operator', 'depends'), ('depends', 'design'), ('design', 'data'), ('data', 'mining'), ('mining', 'algorithm'), ('algorithm', ';'), (';', 'thus'), ('thus', ','), (',', 'con-'), ('con-', 'sidered'), ('sidered', 'optional'), ('optional', 'operator'), ('operator', '.')]

>> Trigrams are: 
 [('The', 'timing', 'employ'), ('timing', 'employ', 'scan'), ('employ', 'scan', 'operator'), ('scan', 'operator', 'depends'), ('operator', 'depends', 'design'), ('depends', 'design', 'data'), ('design', 'data', 'mining'), ('data', 'mining', 'algorithm'), ('mining', 'algorithm', ';'), ('algorithm', ';', 'thus'), (';', 'thus', ','), ('thus', ',', 'con-'), (',', 'con-', 'sidered'), ('con-', 'sidered', 'optional'), ('sidered', 'optional', 'operator'), ('optional', 'operator', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('timing', 'NN'), ('employ', 'JJ'), ('scan', 'JJ'), ('operator', 'NN'), ('depends', 'VBZ'), ('design', 'NN'), ('data', 'NNS'), ('mining', 'NN'), ('algorithm', 'NN'), (';', ':'), ('thus', 'RB'), (',', ','), ('con-', 'JJ'), ('sidered', 'VBD'), ('optional', 'JJ'), ('operator', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['The timing', 'employ scan operator', 'design data mining algorithm', 'optional operator']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('timing', 'time'), ('employ', 'employ'), ('scan', 'scan'), ('operator', 'oper'), ('depends', 'depend'), ('design', 'design'), ('data', 'data'), ('mining', 'mine'), ('algorithm', 'algorithm'), (';', ';'), ('thus', 'thu'), (',', ','), ('con-', 'con-'), ('sidered', 'sider'), ('optional', 'option'), ('operator', 'oper'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('timing', 'time'), ('employ', 'employ'), ('scan', 'scan'), ('operator', 'oper'), ('depends', 'depend'), ('design', 'design'), ('data', 'data'), ('mining', 'mine'), ('algorithm', 'algorithm'), (';', ';'), ('thus', 'thus'), (',', ','), ('con-', 'con-'), ('sidered', 'sider'), ('optional', 'option'), ('operator', 'oper'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('timing', 'timing'), ('employ', 'employ'), ('scan', 'scan'), ('operator', 'operator'), ('depends', 'depends'), ('design', 'design'), ('data', 'data'), ('mining', 'mining'), ('algorithm', 'algorithm'), (';', ';'), ('thus', 'thus'), (',', ','), ('con-', 'con-'), ('sidered', 'sidered'), ('optional', 'optional'), ('operator', 'operator'), ('.', '.')]


------------------- Sentence 4 -------------------

Most of the data algorithms can be described by Fig.

>> Tokens are: 
 ['Most', 'data', 'algorithms', 'described', 'Fig', '.']

>> Bigrams are: 
 [('Most', 'data'), ('data', 'algorithms'), ('algorithms', 'described'), ('described', 'Fig'), ('Fig', '.')]

>> Trigrams are: 
 [('Most', 'data', 'algorithms'), ('data', 'algorithms', 'described'), ('algorithms', 'described', 'Fig'), ('described', 'Fig', '.')]

>> POS Tags are: 
 [('Most', 'JJS'), ('data', 'NNS'), ('algorithms', 'RB'), ('described', 'VBD'), ('Fig', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['data', 'Fig']

>> Named Entities are: 
 [('PERSON', 'Fig')] 

>> Stemming using Porter Stemmer: 
 [('Most', 'most'), ('data', 'data'), ('algorithms', 'algorithm'), ('described', 'describ'), ('Fig', 'fig'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Most', 'most'), ('data', 'data'), ('algorithms', 'algorithm'), ('described', 'describ'), ('Fig', 'fig'), ('.', '.')]

>> Lemmatization: 
 [('Most', 'Most'), ('data', 'data'), ('algorithms', 'algorithm'), ('described', 'described'), ('Fig', 'Fig'), ('.', '.')]


------------------- Sentence 5 -------------------

4 in  which it also shows that the representative algorithms—clustering, classification, associ- ation rules, and sequential patterns—will apply these operators to find the hidden infor- mation from the raw data.

>> Tokens are: 
 ['4', 'also', 'shows', 'representative', 'algorithms—clustering', ',', 'classification', ',', 'associ-', 'ation', 'rules', ',', 'sequential', 'patterns—will', 'apply', 'operators', 'find', 'hidden', 'infor-', 'mation', 'raw', 'data', '.']

>> Bigrams are: 
 [('4', 'also'), ('also', 'shows'), ('shows', 'representative'), ('representative', 'algorithms—clustering'), ('algorithms—clustering', ','), (',', 'classification'), ('classification', ','), (',', 'associ-'), ('associ-', 'ation'), ('ation', 'rules'), ('rules', ','), (',', 'sequential'), ('sequential', 'patterns—will'), ('patterns—will', 'apply'), ('apply', 'operators'), ('operators', 'find'), ('find', 'hidden'), ('hidden', 'infor-'), ('infor-', 'mation'), ('mation', 'raw'), ('raw', 'data'), ('data', '.')]

>> Trigrams are: 
 [('4', 'also', 'shows'), ('also', 'shows', 'representative'), ('shows', 'representative', 'algorithms—clustering'), ('representative', 'algorithms—clustering', ','), ('algorithms—clustering', ',', 'classification'), (',', 'classification', ','), ('classification', ',', 'associ-'), (',', 'associ-', 'ation'), ('associ-', 'ation', 'rules'), ('ation', 'rules', ','), ('rules', ',', 'sequential'), (',', 'sequential', 'patterns—will'), ('sequential', 'patterns—will', 'apply'), ('patterns—will', 'apply', 'operators'), ('apply', 'operators', 'find'), ('operators', 'find', 'hidden'), ('find', 'hidden', 'infor-'), ('hidden', 'infor-', 'mation'), ('infor-', 'mation', 'raw'), ('mation', 'raw', 'data'), ('raw', 'data', '.')]

>> POS Tags are: 
 [('4', 'CD'), ('also', 'RB'), ('shows', 'VBZ'), ('representative', 'JJ'), ('algorithms—clustering', 'NN'), (',', ','), ('classification', 'NN'), (',', ','), ('associ-', 'JJ'), ('ation', 'NN'), ('rules', 'NNS'), (',', ','), ('sequential', 'JJ'), ('patterns—will', 'NN'), ('apply', 'NN'), ('operators', 'NNS'), ('find', 'VBP'), ('hidden', 'JJ'), ('infor-', 'JJ'), ('mation', 'NN'), ('raw', 'JJ'), ('data', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['representative algorithms—clustering', 'classification', 'associ- ation rules', 'sequential patterns—will apply operators', 'hidden infor- mation', 'raw data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('4', '4'), ('also', 'also'), ('shows', 'show'), ('representative', 'repres'), ('algorithms—clustering', 'algorithms—clust'), (',', ','), ('classification', 'classif'), (',', ','), ('associ-', 'associ-'), ('ation', 'ation'), ('rules', 'rule'), (',', ','), ('sequential', 'sequenti'), ('patterns—will', 'patterns—wil'), ('apply', 'appli'), ('operators', 'oper'), ('find', 'find'), ('hidden', 'hidden'), ('infor-', 'infor-'), ('mation', 'mation'), ('raw', 'raw'), ('data', 'data'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('4', '4'), ('also', 'also'), ('shows', 'show'), ('representative', 'repres'), ('algorithms—clustering', 'algorithms—clust'), (',', ','), ('classification', 'classif'), (',', ','), ('associ-', 'associ-'), ('ation', 'ation'), ('rules', 'rule'), (',', ','), ('sequential', 'sequenti'), ('patterns—will', 'patterns—wil'), ('apply', 'appli'), ('operators', 'oper'), ('find', 'find'), ('hidden', 'hidden'), ('infor-', 'infor-'), ('mation', 'mation'), ('raw', 'raw'), ('data', 'data'), ('.', '.')]

>> Lemmatization: 
 [('4', '4'), ('also', 'also'), ('shows', 'show'), ('representative', 'representative'), ('algorithms—clustering', 'algorithms—clustering'), (',', ','), ('classification', 'classification'), (',', ','), ('associ-', 'associ-'), ('ation', 'ation'), ('rules', 'rule'), (',', ','), ('sequential', 'sequential'), ('patterns—will', 'patterns—will'), ('apply', 'apply'), ('operators', 'operator'), ('find', 'find'), ('hidden', 'hidden'), ('infor-', 'infor-'), ('mation', 'mation'), ('raw', 'raw'), ('data', 'data'), ('.', '.')]


------------------- Sentence 6 -------------------

Thus, modifying these operators will be one of the possible  ways for enhancing the performance of the data analysis.

>> Tokens are: 
 ['Thus', ',', 'modifying', 'operators', 'one', 'possible', 'ways', 'enhancing', 'performance', 'data', 'analysis', '.']

>> Bigrams are: 
 [('Thus', ','), (',', 'modifying'), ('modifying', 'operators'), ('operators', 'one'), ('one', 'possible'), ('possible', 'ways'), ('ways', 'enhancing'), ('enhancing', 'performance'), ('performance', 'data'), ('data', 'analysis'), ('analysis', '.')]

>> Trigrams are: 
 [('Thus', ',', 'modifying'), (',', 'modifying', 'operators'), ('modifying', 'operators', 'one'), ('operators', 'one', 'possible'), ('one', 'possible', 'ways'), ('possible', 'ways', 'enhancing'), ('ways', 'enhancing', 'performance'), ('enhancing', 'performance', 'data'), ('performance', 'data', 'analysis'), ('data', 'analysis', '.')]

>> POS Tags are: 
 [('Thus', 'RB'), (',', ','), ('modifying', 'VBG'), ('operators', 'NNS'), ('one', 'CD'), ('possible', 'JJ'), ('ways', 'NNS'), ('enhancing', 'VBG'), ('performance', 'NN'), ('data', 'NNS'), ('analysis', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['operators', 'possible ways', 'performance data analysis']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Thus', 'thu'), (',', ','), ('modifying', 'modifi'), ('operators', 'oper'), ('one', 'one'), ('possible', 'possibl'), ('ways', 'way'), ('enhancing', 'enhanc'), ('performance', 'perform'), ('data', 'data'), ('analysis', 'analysi'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Thus', 'thus'), (',', ','), ('modifying', 'modifi'), ('operators', 'oper'), ('one', 'one'), ('possible', 'possibl'), ('ways', 'way'), ('enhancing', 'enhanc'), ('performance', 'perform'), ('data', 'data'), ('analysis', 'analysi'), ('.', '.')]

>> Lemmatization: 
 [('Thus', 'Thus'), (',', ','), ('modifying', 'modifying'), ('operators', 'operator'), ('one', 'one'), ('possible', 'possible'), ('ways', 'way'), ('enhancing', 'enhancing'), ('performance', 'performance'), ('data', 'data'), ('analysis', 'analysis'), ('.', '.')]



========================================== PARAGRAPH 83 ===========================================

Clustering is one of the well-known data mining problems because it can be used to  understand the “new” input data. The basic idea of this problem [27] is to separate a set  of unlabeled input data2 to k different groups, e.g.-, such as k-means [28]. Classification  [20] is the opposite of clustering because it relies on a set of labeled input data to con- struct a set of classifiers (i.e.-, groups) which will then be used to classify the unlabeled  input data to the groups to which they belong. To solve the classification problem, the  decision tree-based algorithm [29], naïve Bayesian classification [30], and support vector  machine (SVM) [31] are widely used in recent years. 

------------------- Sentence 1 -------------------

Clustering is one of the well-known data mining problems because it can be used to  understand the “new” input data.

>> Tokens are: 
 ['Clustering', 'one', 'well-known', 'data', 'mining', 'problems', 'used', 'understand', '“', 'new', '”', 'input', 'data', '.']

>> Bigrams are: 
 [('Clustering', 'one'), ('one', 'well-known'), ('well-known', 'data'), ('data', 'mining'), ('mining', 'problems'), ('problems', 'used'), ('used', 'understand'), ('understand', '“'), ('“', 'new'), ('new', '”'), ('”', 'input'), ('input', 'data'), ('data', '.')]

>> Trigrams are: 
 [('Clustering', 'one', 'well-known'), ('one', 'well-known', 'data'), ('well-known', 'data', 'mining'), ('data', 'mining', 'problems'), ('mining', 'problems', 'used'), ('problems', 'used', 'understand'), ('used', 'understand', '“'), ('understand', '“', 'new'), ('“', 'new', '”'), ('new', '”', 'input'), ('”', 'input', 'data'), ('input', 'data', '.')]

>> POS Tags are: 
 [('Clustering', 'VBG'), ('one', 'CD'), ('well-known', 'JJ'), ('data', 'NNS'), ('mining', 'NN'), ('problems', 'NNS'), ('used', 'VBN'), ('understand', 'RB'), ('“', 'JJ'), ('new', 'JJ'), ('”', 'NN'), ('input', 'NN'), ('data', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['well-known data mining problems', '“ new ” input data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Clustering', 'cluster'), ('one', 'one'), ('well-known', 'well-known'), ('data', 'data'), ('mining', 'mine'), ('problems', 'problem'), ('used', 'use'), ('understand', 'understand'), ('“', '“'), ('new', 'new'), ('”', '”'), ('input', 'input'), ('data', 'data'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Clustering', 'cluster'), ('one', 'one'), ('well-known', 'well-known'), ('data', 'data'), ('mining', 'mine'), ('problems', 'problem'), ('used', 'use'), ('understand', 'understand'), ('“', '“'), ('new', 'new'), ('”', '”'), ('input', 'input'), ('data', 'data'), ('.', '.')]

>> Lemmatization: 
 [('Clustering', 'Clustering'), ('one', 'one'), ('well-known', 'well-known'), ('data', 'data'), ('mining', 'mining'), ('problems', 'problem'), ('used', 'used'), ('understand', 'understand'), ('“', '“'), ('new', 'new'), ('”', '”'), ('input', 'input'), ('data', 'data'), ('.', '.')]


------------------- Sentence 2 -------------------

The basic idea of this problem [27] is to separate a set  of unlabeled input data2 to k different groups, e.g.-, such as k-means [28].

>> Tokens are: 
 ['The', 'basic', 'idea', 'problem', '[', '27', ']', 'separate', 'set', 'unlabeled', 'input', 'data2', 'k', 'different', 'groups', ',', 'e.g.-', ',', 'k-means', '[', '28', ']', '.']

>> Bigrams are: 
 [('The', 'basic'), ('basic', 'idea'), ('idea', 'problem'), ('problem', '['), ('[', '27'), ('27', ']'), (']', 'separate'), ('separate', 'set'), ('set', 'unlabeled'), ('unlabeled', 'input'), ('input', 'data2'), ('data2', 'k'), ('k', 'different'), ('different', 'groups'), ('groups', ','), (',', 'e.g.-'), ('e.g.-', ','), (',', 'k-means'), ('k-means', '['), ('[', '28'), ('28', ']'), (']', '.')]

>> Trigrams are: 
 [('The', 'basic', 'idea'), ('basic', 'idea', 'problem'), ('idea', 'problem', '['), ('problem', '[', '27'), ('[', '27', ']'), ('27', ']', 'separate'), (']', 'separate', 'set'), ('separate', 'set', 'unlabeled'), ('set', 'unlabeled', 'input'), ('unlabeled', 'input', 'data2'), ('input', 'data2', 'k'), ('data2', 'k', 'different'), ('k', 'different', 'groups'), ('different', 'groups', ','), ('groups', ',', 'e.g.-'), (',', 'e.g.-', ','), ('e.g.-', ',', 'k-means'), (',', 'k-means', '['), ('k-means', '[', '28'), ('[', '28', ']'), ('28', ']', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('basic', 'JJ'), ('idea', 'NN'), ('problem', 'NN'), ('[', 'VBZ'), ('27', 'CD'), (']', 'NN'), ('separate', 'JJ'), ('set', 'NN'), ('unlabeled', 'VBD'), ('input', 'NN'), ('data2', 'NN'), ('k', 'FW'), ('different', 'JJ'), ('groups', 'NNS'), (',', ','), ('e.g.-', 'JJ'), (',', ','), ('k-means', 'JJ'), ('[', 'NN'), ('28', 'CD'), (']', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['The basic idea problem', ']', 'separate set', 'input data2', 'different groups', 'k-means [', ']']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('basic', 'basic'), ('idea', 'idea'), ('problem', 'problem'), ('[', '['), ('27', '27'), (']', ']'), ('separate', 'separ'), ('set', 'set'), ('unlabeled', 'unlabel'), ('input', 'input'), ('data2', 'data2'), ('k', 'k'), ('different', 'differ'), ('groups', 'group'), (',', ','), ('e.g.-', 'e.g.-'), (',', ','), ('k-means', 'k-mean'), ('[', '['), ('28', '28'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('basic', 'basic'), ('idea', 'idea'), ('problem', 'problem'), ('[', '['), ('27', '27'), (']', ']'), ('separate', 'separ'), ('set', 'set'), ('unlabeled', 'unlabel'), ('input', 'input'), ('data2', 'data2'), ('k', 'k'), ('different', 'differ'), ('groups', 'group'), (',', ','), ('e.g.-', 'e.g.-'), (',', ','), ('k-means', 'k-mean'), ('[', '['), ('28', '28'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('basic', 'basic'), ('idea', 'idea'), ('problem', 'problem'), ('[', '['), ('27', '27'), (']', ']'), ('separate', 'separate'), ('set', 'set'), ('unlabeled', 'unlabeled'), ('input', 'input'), ('data2', 'data2'), ('k', 'k'), ('different', 'different'), ('groups', 'group'), (',', ','), ('e.g.-', 'e.g.-'), (',', ','), ('k-means', 'k-means'), ('[', '['), ('28', '28'), (']', ']'), ('.', '.')]


------------------- Sentence 3 -------------------

Classification  [20] is the opposite of clustering because it relies on a set of labeled input data to con- struct a set of classifiers (i.e.-, groups) which will then be used to classify the unlabeled  input data to the groups to which they belong.

>> Tokens are: 
 ['Classification', '[', '20', ']', 'opposite', 'clustering', 'relies', 'set', 'labeled', 'input', 'data', 'con-', 'struct', 'set', 'classifiers', '(', 'i.e.-', ',', 'groups', ')', 'used', 'classify', 'unlabeled', 'input', 'data', 'groups', 'belong', '.']

>> Bigrams are: 
 [('Classification', '['), ('[', '20'), ('20', ']'), (']', 'opposite'), ('opposite', 'clustering'), ('clustering', 'relies'), ('relies', 'set'), ('set', 'labeled'), ('labeled', 'input'), ('input', 'data'), ('data', 'con-'), ('con-', 'struct'), ('struct', 'set'), ('set', 'classifiers'), ('classifiers', '('), ('(', 'i.e.-'), ('i.e.-', ','), (',', 'groups'), ('groups', ')'), (')', 'used'), ('used', 'classify'), ('classify', 'unlabeled'), ('unlabeled', 'input'), ('input', 'data'), ('data', 'groups'), ('groups', 'belong'), ('belong', '.')]

>> Trigrams are: 
 [('Classification', '[', '20'), ('[', '20', ']'), ('20', ']', 'opposite'), (']', 'opposite', 'clustering'), ('opposite', 'clustering', 'relies'), ('clustering', 'relies', 'set'), ('relies', 'set', 'labeled'), ('set', 'labeled', 'input'), ('labeled', 'input', 'data'), ('input', 'data', 'con-'), ('data', 'con-', 'struct'), ('con-', 'struct', 'set'), ('struct', 'set', 'classifiers'), ('set', 'classifiers', '('), ('classifiers', '(', 'i.e.-'), ('(', 'i.e.-', ','), ('i.e.-', ',', 'groups'), (',', 'groups', ')'), ('groups', ')', 'used'), (')', 'used', 'classify'), ('used', 'classify', 'unlabeled'), ('classify', 'unlabeled', 'input'), ('unlabeled', 'input', 'data'), ('input', 'data', 'groups'), ('data', 'groups', 'belong'), ('groups', 'belong', '.')]

>> POS Tags are: 
 [('Classification', 'NNP'), ('[', 'VBD'), ('20', 'CD'), (']', 'NNP'), ('opposite', 'JJ'), ('clustering', 'NN'), ('relies', 'NNS'), ('set', 'VBD'), ('labeled', 'VBN'), ('input', 'NN'), ('data', 'NNS'), ('con-', 'JJ'), ('struct', 'NN'), ('set', 'VBN'), ('classifiers', 'NNS'), ('(', '('), ('i.e.-', 'JJ'), (',', ','), ('groups', 'NNS'), (')', ')'), ('used', 'VBD'), ('classify', 'NN'), ('unlabeled', 'JJ'), ('input', 'NN'), ('data', 'NNS'), ('groups', 'NNS'), ('belong', 'RB'), ('.', '.')]

>> Noun Phrases are: 
 ['Classification', ']', 'opposite clustering relies', 'input data', 'con- struct', 'classifiers', 'groups', 'classify', 'unlabeled input data groups']

>> Named Entities are: 
 [('PERSON', 'Classification')] 

>> Stemming using Porter Stemmer: 
 [('Classification', 'classif'), ('[', '['), ('20', '20'), (']', ']'), ('opposite', 'opposit'), ('clustering', 'cluster'), ('relies', 'reli'), ('set', 'set'), ('labeled', 'label'), ('input', 'input'), ('data', 'data'), ('con-', 'con-'), ('struct', 'struct'), ('set', 'set'), ('classifiers', 'classifi'), ('(', '('), ('i.e.-', 'i.e.-'), (',', ','), ('groups', 'group'), (')', ')'), ('used', 'use'), ('classify', 'classifi'), ('unlabeled', 'unlabel'), ('input', 'input'), ('data', 'data'), ('groups', 'group'), ('belong', 'belong'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Classification', 'classif'), ('[', '['), ('20', '20'), (']', ']'), ('opposite', 'opposit'), ('clustering', 'cluster'), ('relies', 'reli'), ('set', 'set'), ('labeled', 'label'), ('input', 'input'), ('data', 'data'), ('con-', 'con-'), ('struct', 'struct'), ('set', 'set'), ('classifiers', 'classifi'), ('(', '('), ('i.e.-', 'i.e.-'), (',', ','), ('groups', 'group'), (')', ')'), ('used', 'use'), ('classify', 'classifi'), ('unlabeled', 'unlabel'), ('input', 'input'), ('data', 'data'), ('groups', 'group'), ('belong', 'belong'), ('.', '.')]

>> Lemmatization: 
 [('Classification', 'Classification'), ('[', '['), ('20', '20'), (']', ']'), ('opposite', 'opposite'), ('clustering', 'clustering'), ('relies', 'relies'), ('set', 'set'), ('labeled', 'labeled'), ('input', 'input'), ('data', 'data'), ('con-', 'con-'), ('struct', 'struct'), ('set', 'set'), ('classifiers', 'classifier'), ('(', '('), ('i.e.-', 'i.e.-'), (',', ','), ('groups', 'group'), (')', ')'), ('used', 'used'), ('classify', 'classify'), ('unlabeled', 'unlabeled'), ('input', 'input'), ('data', 'data'), ('groups', 'group'), ('belong', 'belong'), ('.', '.')]


------------------- Sentence 4 -------------------

To solve the classification problem, the  decision tree-based algorithm [29], naïve Bayesian classification [30], and support vector  machine (SVM) [31] are widely used in recent years.

>> Tokens are: 
 ['To', 'solve', 'classification', 'problem', ',', 'decision', 'tree-based', 'algorithm', '[', '29', ']', ',', 'naïve', 'Bayesian', 'classification', '[', '30', ']', ',', 'support', 'vector', 'machine', '(', 'SVM', ')', '[', '31', ']', 'widely', 'used', 'recent', 'years', '.']

>> Bigrams are: 
 [('To', 'solve'), ('solve', 'classification'), ('classification', 'problem'), ('problem', ','), (',', 'decision'), ('decision', 'tree-based'), ('tree-based', 'algorithm'), ('algorithm', '['), ('[', '29'), ('29', ']'), (']', ','), (',', 'naïve'), ('naïve', 'Bayesian'), ('Bayesian', 'classification'), ('classification', '['), ('[', '30'), ('30', ']'), (']', ','), (',', 'support'), ('support', 'vector'), ('vector', 'machine'), ('machine', '('), ('(', 'SVM'), ('SVM', ')'), (')', '['), ('[', '31'), ('31', ']'), (']', 'widely'), ('widely', 'used'), ('used', 'recent'), ('recent', 'years'), ('years', '.')]

>> Trigrams are: 
 [('To', 'solve', 'classification'), ('solve', 'classification', 'problem'), ('classification', 'problem', ','), ('problem', ',', 'decision'), (',', 'decision', 'tree-based'), ('decision', 'tree-based', 'algorithm'), ('tree-based', 'algorithm', '['), ('algorithm', '[', '29'), ('[', '29', ']'), ('29', ']', ','), (']', ',', 'naïve'), (',', 'naïve', 'Bayesian'), ('naïve', 'Bayesian', 'classification'), ('Bayesian', 'classification', '['), ('classification', '[', '30'), ('[', '30', ']'), ('30', ']', ','), (']', ',', 'support'), (',', 'support', 'vector'), ('support', 'vector', 'machine'), ('vector', 'machine', '('), ('machine', '(', 'SVM'), ('(', 'SVM', ')'), ('SVM', ')', '['), (')', '[', '31'), ('[', '31', ']'), ('31', ']', 'widely'), (']', 'widely', 'used'), ('widely', 'used', 'recent'), ('used', 'recent', 'years'), ('recent', 'years', '.')]

>> POS Tags are: 
 [('To', 'TO'), ('solve', 'VB'), ('classification', 'NN'), ('problem', 'NN'), (',', ','), ('decision', 'NN'), ('tree-based', 'JJ'), ('algorithm', 'NN'), ('[', '$'), ('29', 'CD'), (']', 'NNP'), (',', ','), ('naïve', 'JJ'), ('Bayesian', 'JJ'), ('classification', 'NN'), ('[', 'VBD'), ('30', 'CD'), (']', 'NN'), (',', ','), ('support', 'NN'), ('vector', 'NN'), ('machine', 'NN'), ('(', '('), ('SVM', 'NNP'), (')', ')'), ('[', 'VBD'), ('31', 'CD'), (']', 'NNP'), ('widely', 'RB'), ('used', 'VBD'), ('recent', 'JJ'), ('years', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['classification problem', 'decision', 'tree-based algorithm', ']', 'naïve Bayesian classification', ']', 'support vector machine', 'SVM', ']', 'recent years']

>> Named Entities are: 
 [('GPE', 'Bayesian'), ('ORGANIZATION', 'SVM')] 

>> Stemming using Porter Stemmer: 
 [('To', 'to'), ('solve', 'solv'), ('classification', 'classif'), ('problem', 'problem'), (',', ','), ('decision', 'decis'), ('tree-based', 'tree-bas'), ('algorithm', 'algorithm'), ('[', '['), ('29', '29'), (']', ']'), (',', ','), ('naïve', 'naïv'), ('Bayesian', 'bayesian'), ('classification', 'classif'), ('[', '['), ('30', '30'), (']', ']'), (',', ','), ('support', 'support'), ('vector', 'vector'), ('machine', 'machin'), ('(', '('), ('SVM', 'svm'), (')', ')'), ('[', '['), ('31', '31'), (']', ']'), ('widely', 'wide'), ('used', 'use'), ('recent', 'recent'), ('years', 'year'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('To', 'to'), ('solve', 'solv'), ('classification', 'classif'), ('problem', 'problem'), (',', ','), ('decision', 'decis'), ('tree-based', 'tree-bas'), ('algorithm', 'algorithm'), ('[', '['), ('29', '29'), (']', ']'), (',', ','), ('naïve', 'naïv'), ('Bayesian', 'bayesian'), ('classification', 'classif'), ('[', '['), ('30', '30'), (']', ']'), (',', ','), ('support', 'support'), ('vector', 'vector'), ('machine', 'machin'), ('(', '('), ('SVM', 'svm'), (')', ')'), ('[', '['), ('31', '31'), (']', ']'), ('widely', 'wide'), ('used', 'use'), ('recent', 'recent'), ('years', 'year'), ('.', '.')]

>> Lemmatization: 
 [('To', 'To'), ('solve', 'solve'), ('classification', 'classification'), ('problem', 'problem'), (',', ','), ('decision', 'decision'), ('tree-based', 'tree-based'), ('algorithm', 'algorithm'), ('[', '['), ('29', '29'), (']', ']'), (',', ','), ('naïve', 'naïve'), ('Bayesian', 'Bayesian'), ('classification', 'classification'), ('[', '['), ('30', '30'), (']', ']'), (',', ','), ('support', 'support'), ('vector', 'vector'), ('machine', 'machine'), ('(', '('), ('SVM', 'SVM'), (')', ')'), ('[', '['), ('31', '31'), (']', ']'), ('widely', 'widely'), ('used', 'used'), ('recent', 'recent'), ('years', 'year'), ('.', '.')]



========================================== PARAGRAPH 84 ===========================================

Unlike clustering and classification that attempt to classify the input data to k groups,  association rules and sequential patterns are focused on finding out the “relationships”  between the input data. The basic idea of association rules [21] is find all the co-occur- rence relationships between the input data. For the association rules problem, the apriori  algorithm [21] is one of the most popular methods. Nevertheless, because it is compu- tationally very expensive, later studies [32] have attempted to use different approaches  to reducing the cost of the apriori algorithm, such as applying the genetic algorithm to  this problem [33]. In addition to considering the relationships between the input data, if  we also consider the sequence or time series of the input data, then it will be referred to  as the sequential pattern mining problem [34]. Several apriori-like algorithms were pre- sented for solving it, such as generalized sequential pattern [34] and sequential pattern  discovery using equivalence classes [35]. 

------------------- Sentence 1 -------------------

Unlike clustering and classification that attempt to classify the input data to k groups,  association rules and sequential patterns are focused on finding out the “relationships”  between the input data.

>> Tokens are: 
 ['Unlike', 'clustering', 'classification', 'attempt', 'classify', 'input', 'data', 'k', 'groups', ',', 'association', 'rules', 'sequential', 'patterns', 'focused', 'finding', '“', 'relationships', '”', 'input', 'data', '.']

>> Bigrams are: 
 [('Unlike', 'clustering'), ('clustering', 'classification'), ('classification', 'attempt'), ('attempt', 'classify'), ('classify', 'input'), ('input', 'data'), ('data', 'k'), ('k', 'groups'), ('groups', ','), (',', 'association'), ('association', 'rules'), ('rules', 'sequential'), ('sequential', 'patterns'), ('patterns', 'focused'), ('focused', 'finding'), ('finding', '“'), ('“', 'relationships'), ('relationships', '”'), ('”', 'input'), ('input', 'data'), ('data', '.')]

>> Trigrams are: 
 [('Unlike', 'clustering', 'classification'), ('clustering', 'classification', 'attempt'), ('classification', 'attempt', 'classify'), ('attempt', 'classify', 'input'), ('classify', 'input', 'data'), ('input', 'data', 'k'), ('data', 'k', 'groups'), ('k', 'groups', ','), ('groups', ',', 'association'), (',', 'association', 'rules'), ('association', 'rules', 'sequential'), ('rules', 'sequential', 'patterns'), ('sequential', 'patterns', 'focused'), ('patterns', 'focused', 'finding'), ('focused', 'finding', '“'), ('finding', '“', 'relationships'), ('“', 'relationships', '”'), ('relationships', '”', 'input'), ('”', 'input', 'data'), ('input', 'data', '.')]

>> POS Tags are: 
 [('Unlike', 'IN'), ('clustering', 'VBG'), ('classification', 'NN'), ('attempt', 'NN'), ('classify', 'NN'), ('input', 'NN'), ('data', 'NNS'), ('k', 'NN'), ('groups', 'NNS'), (',', ','), ('association', 'NN'), ('rules', 'NNS'), ('sequential', 'JJ'), ('patterns', 'NNS'), ('focused', 'VBD'), ('finding', 'VBG'), ('“', 'JJ'), ('relationships', 'NNS'), ('”', 'VBP'), ('input', 'NN'), ('data', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['classification attempt classify input data k groups', 'association rules', 'sequential patterns', '“ relationships', 'input data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Unlike', 'unlik'), ('clustering', 'cluster'), ('classification', 'classif'), ('attempt', 'attempt'), ('classify', 'classifi'), ('input', 'input'), ('data', 'data'), ('k', 'k'), ('groups', 'group'), (',', ','), ('association', 'associ'), ('rules', 'rule'), ('sequential', 'sequenti'), ('patterns', 'pattern'), ('focused', 'focus'), ('finding', 'find'), ('“', '“'), ('relationships', 'relationship'), ('”', '”'), ('input', 'input'), ('data', 'data'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Unlike', 'unlik'), ('clustering', 'cluster'), ('classification', 'classif'), ('attempt', 'attempt'), ('classify', 'classifi'), ('input', 'input'), ('data', 'data'), ('k', 'k'), ('groups', 'group'), (',', ','), ('association', 'associ'), ('rules', 'rule'), ('sequential', 'sequenti'), ('patterns', 'pattern'), ('focused', 'focus'), ('finding', 'find'), ('“', '“'), ('relationships', 'relationship'), ('”', '”'), ('input', 'input'), ('data', 'data'), ('.', '.')]

>> Lemmatization: 
 [('Unlike', 'Unlike'), ('clustering', 'clustering'), ('classification', 'classification'), ('attempt', 'attempt'), ('classify', 'classify'), ('input', 'input'), ('data', 'data'), ('k', 'k'), ('groups', 'group'), (',', ','), ('association', 'association'), ('rules', 'rule'), ('sequential', 'sequential'), ('patterns', 'pattern'), ('focused', 'focused'), ('finding', 'finding'), ('“', '“'), ('relationships', 'relationship'), ('”', '”'), ('input', 'input'), ('data', 'data'), ('.', '.')]


------------------- Sentence 2 -------------------

The basic idea of association rules [21] is find all the co-occur- rence relationships between the input data.

>> Tokens are: 
 ['The', 'basic', 'idea', 'association', 'rules', '[', '21', ']', 'find', 'co-occur-', 'rence', 'relationships', 'input', 'data', '.']

>> Bigrams are: 
 [('The', 'basic'), ('basic', 'idea'), ('idea', 'association'), ('association', 'rules'), ('rules', '['), ('[', '21'), ('21', ']'), (']', 'find'), ('find', 'co-occur-'), ('co-occur-', 'rence'), ('rence', 'relationships'), ('relationships', 'input'), ('input', 'data'), ('data', '.')]

>> Trigrams are: 
 [('The', 'basic', 'idea'), ('basic', 'idea', 'association'), ('idea', 'association', 'rules'), ('association', 'rules', '['), ('rules', '[', '21'), ('[', '21', ']'), ('21', ']', 'find'), (']', 'find', 'co-occur-'), ('find', 'co-occur-', 'rence'), ('co-occur-', 'rence', 'relationships'), ('rence', 'relationships', 'input'), ('relationships', 'input', 'data'), ('input', 'data', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('basic', 'JJ'), ('idea', 'NN'), ('association', 'NN'), ('rules', 'NNS'), ('[', 'VBP'), ('21', 'CD'), (']', 'JJ'), ('find', 'VB'), ('co-occur-', 'JJ'), ('rence', 'NN'), ('relationships', 'NNS'), ('input', 'VBP'), ('data', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['The basic idea association rules', 'co-occur- rence relationships', 'data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('basic', 'basic'), ('idea', 'idea'), ('association', 'associ'), ('rules', 'rule'), ('[', '['), ('21', '21'), (']', ']'), ('find', 'find'), ('co-occur-', 'co-occur-'), ('rence', 'renc'), ('relationships', 'relationship'), ('input', 'input'), ('data', 'data'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('basic', 'basic'), ('idea', 'idea'), ('association', 'associ'), ('rules', 'rule'), ('[', '['), ('21', '21'), (']', ']'), ('find', 'find'), ('co-occur-', 'co-occur-'), ('rence', 'renc'), ('relationships', 'relationship'), ('input', 'input'), ('data', 'data'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('basic', 'basic'), ('idea', 'idea'), ('association', 'association'), ('rules', 'rule'), ('[', '['), ('21', '21'), (']', ']'), ('find', 'find'), ('co-occur-', 'co-occur-'), ('rence', 'rence'), ('relationships', 'relationship'), ('input', 'input'), ('data', 'data'), ('.', '.')]


------------------- Sentence 3 -------------------

For the association rules problem, the apriori  algorithm [21] is one of the most popular methods.

>> Tokens are: 
 ['For', 'association', 'rules', 'problem', ',', 'apriori', 'algorithm', '[', '21', ']', 'one', 'popular', 'methods', '.']

>> Bigrams are: 
 [('For', 'association'), ('association', 'rules'), ('rules', 'problem'), ('problem', ','), (',', 'apriori'), ('apriori', 'algorithm'), ('algorithm', '['), ('[', '21'), ('21', ']'), (']', 'one'), ('one', 'popular'), ('popular', 'methods'), ('methods', '.')]

>> Trigrams are: 
 [('For', 'association', 'rules'), ('association', 'rules', 'problem'), ('rules', 'problem', ','), ('problem', ',', 'apriori'), (',', 'apriori', 'algorithm'), ('apriori', 'algorithm', '['), ('algorithm', '[', '21'), ('[', '21', ']'), ('21', ']', 'one'), (']', 'one', 'popular'), ('one', 'popular', 'methods'), ('popular', 'methods', '.')]

>> POS Tags are: 
 [('For', 'IN'), ('association', 'NN'), ('rules', 'NNS'), ('problem', 'NN'), (',', ','), ('apriori', 'FW'), ('algorithm', 'VBP'), ('[', '$'), ('21', 'CD'), (']', 'NNP'), ('one', 'CD'), ('popular', 'JJ'), ('methods', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['association rules problem', ']', 'popular methods']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('For', 'for'), ('association', 'associ'), ('rules', 'rule'), ('problem', 'problem'), (',', ','), ('apriori', 'apriori'), ('algorithm', 'algorithm'), ('[', '['), ('21', '21'), (']', ']'), ('one', 'one'), ('popular', 'popular'), ('methods', 'method'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('For', 'for'), ('association', 'associ'), ('rules', 'rule'), ('problem', 'problem'), (',', ','), ('apriori', 'apriori'), ('algorithm', 'algorithm'), ('[', '['), ('21', '21'), (']', ']'), ('one', 'one'), ('popular', 'popular'), ('methods', 'method'), ('.', '.')]

>> Lemmatization: 
 [('For', 'For'), ('association', 'association'), ('rules', 'rule'), ('problem', 'problem'), (',', ','), ('apriori', 'apriori'), ('algorithm', 'algorithm'), ('[', '['), ('21', '21'), (']', ']'), ('one', 'one'), ('popular', 'popular'), ('methods', 'method'), ('.', '.')]


------------------- Sentence 4 -------------------

Nevertheless, because it is compu- tationally very expensive, later studies [32] have attempted to use different approaches  to reducing the cost of the apriori algorithm, such as applying the genetic algorithm to  this problem [33].

>> Tokens are: 
 ['Nevertheless', ',', 'compu-', 'tationally', 'expensive', ',', 'later', 'studies', '[', '32', ']', 'attempted', 'use', 'different', 'approaches', 'reducing', 'cost', 'apriori', 'algorithm', ',', 'applying', 'genetic', 'algorithm', 'problem', '[', '33', ']', '.']

>> Bigrams are: 
 [('Nevertheless', ','), (',', 'compu-'), ('compu-', 'tationally'), ('tationally', 'expensive'), ('expensive', ','), (',', 'later'), ('later', 'studies'), ('studies', '['), ('[', '32'), ('32', ']'), (']', 'attempted'), ('attempted', 'use'), ('use', 'different'), ('different', 'approaches'), ('approaches', 'reducing'), ('reducing', 'cost'), ('cost', 'apriori'), ('apriori', 'algorithm'), ('algorithm', ','), (',', 'applying'), ('applying', 'genetic'), ('genetic', 'algorithm'), ('algorithm', 'problem'), ('problem', '['), ('[', '33'), ('33', ']'), (']', '.')]

>> Trigrams are: 
 [('Nevertheless', ',', 'compu-'), (',', 'compu-', 'tationally'), ('compu-', 'tationally', 'expensive'), ('tationally', 'expensive', ','), ('expensive', ',', 'later'), (',', 'later', 'studies'), ('later', 'studies', '['), ('studies', '[', '32'), ('[', '32', ']'), ('32', ']', 'attempted'), (']', 'attempted', 'use'), ('attempted', 'use', 'different'), ('use', 'different', 'approaches'), ('different', 'approaches', 'reducing'), ('approaches', 'reducing', 'cost'), ('reducing', 'cost', 'apriori'), ('cost', 'apriori', 'algorithm'), ('apriori', 'algorithm', ','), ('algorithm', ',', 'applying'), (',', 'applying', 'genetic'), ('applying', 'genetic', 'algorithm'), ('genetic', 'algorithm', 'problem'), ('algorithm', 'problem', '['), ('problem', '[', '33'), ('[', '33', ']'), ('33', ']', '.')]

>> POS Tags are: 
 [('Nevertheless', 'RB'), (',', ','), ('compu-', 'JJ'), ('tationally', 'RB'), ('expensive', 'JJ'), (',', ','), ('later', 'JJ'), ('studies', 'NNS'), ('[', 'VBP'), ('32', 'CD'), (']', 'NN'), ('attempted', 'VBN'), ('use', 'IN'), ('different', 'JJ'), ('approaches', 'NNS'), ('reducing', 'VBG'), ('cost', 'NN'), ('apriori', 'NNS'), ('algorithm', 'RB'), (',', ','), ('applying', 'VBG'), ('genetic', 'JJ'), ('algorithm', 'NN'), ('problem', 'NN'), ('[', 'VBZ'), ('33', 'CD'), (']', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['later studies', ']', 'different approaches', 'cost apriori', 'genetic algorithm problem', ']']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Nevertheless', 'nevertheless'), (',', ','), ('compu-', 'compu-'), ('tationally', 'tation'), ('expensive', 'expens'), (',', ','), ('later', 'later'), ('studies', 'studi'), ('[', '['), ('32', '32'), (']', ']'), ('attempted', 'attempt'), ('use', 'use'), ('different', 'differ'), ('approaches', 'approach'), ('reducing', 'reduc'), ('cost', 'cost'), ('apriori', 'apriori'), ('algorithm', 'algorithm'), (',', ','), ('applying', 'appli'), ('genetic', 'genet'), ('algorithm', 'algorithm'), ('problem', 'problem'), ('[', '['), ('33', '33'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Nevertheless', 'nevertheless'), (',', ','), ('compu-', 'compu-'), ('tationally', 'tation'), ('expensive', 'expens'), (',', ','), ('later', 'later'), ('studies', 'studi'), ('[', '['), ('32', '32'), (']', ']'), ('attempted', 'attempt'), ('use', 'use'), ('different', 'differ'), ('approaches', 'approach'), ('reducing', 'reduc'), ('cost', 'cost'), ('apriori', 'apriori'), ('algorithm', 'algorithm'), (',', ','), ('applying', 'appli'), ('genetic', 'genet'), ('algorithm', 'algorithm'), ('problem', 'problem'), ('[', '['), ('33', '33'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('Nevertheless', 'Nevertheless'), (',', ','), ('compu-', 'compu-'), ('tationally', 'tationally'), ('expensive', 'expensive'), (',', ','), ('later', 'later'), ('studies', 'study'), ('[', '['), ('32', '32'), (']', ']'), ('attempted', 'attempted'), ('use', 'use'), ('different', 'different'), ('approaches', 'approach'), ('reducing', 'reducing'), ('cost', 'cost'), ('apriori', 'apriori'), ('algorithm', 'algorithm'), (',', ','), ('applying', 'applying'), ('genetic', 'genetic'), ('algorithm', 'algorithm'), ('problem', 'problem'), ('[', '['), ('33', '33'), (']', ']'), ('.', '.')]


------------------- Sentence 5 -------------------

In addition to considering the relationships between the input data, if  we also consider the sequence or time series of the input data, then it will be referred to  as the sequential pattern mining problem [34].

>> Tokens are: 
 ['In', 'addition', 'considering', 'relationships', 'input', 'data', ',', 'also', 'consider', 'sequence', 'time', 'series', 'input', 'data', ',', 'referred', 'sequential', 'pattern', 'mining', 'problem', '[', '34', ']', '.']

>> Bigrams are: 
 [('In', 'addition'), ('addition', 'considering'), ('considering', 'relationships'), ('relationships', 'input'), ('input', 'data'), ('data', ','), (',', 'also'), ('also', 'consider'), ('consider', 'sequence'), ('sequence', 'time'), ('time', 'series'), ('series', 'input'), ('input', 'data'), ('data', ','), (',', 'referred'), ('referred', 'sequential'), ('sequential', 'pattern'), ('pattern', 'mining'), ('mining', 'problem'), ('problem', '['), ('[', '34'), ('34', ']'), (']', '.')]

>> Trigrams are: 
 [('In', 'addition', 'considering'), ('addition', 'considering', 'relationships'), ('considering', 'relationships', 'input'), ('relationships', 'input', 'data'), ('input', 'data', ','), ('data', ',', 'also'), (',', 'also', 'consider'), ('also', 'consider', 'sequence'), ('consider', 'sequence', 'time'), ('sequence', 'time', 'series'), ('time', 'series', 'input'), ('series', 'input', 'data'), ('input', 'data', ','), ('data', ',', 'referred'), (',', 'referred', 'sequential'), ('referred', 'sequential', 'pattern'), ('sequential', 'pattern', 'mining'), ('pattern', 'mining', 'problem'), ('mining', 'problem', '['), ('problem', '[', '34'), ('[', '34', ']'), ('34', ']', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('addition', 'NN'), ('considering', 'VBG'), ('relationships', 'NNS'), ('input', 'NN'), ('data', 'NNS'), (',', ','), ('also', 'RB'), ('consider', 'VB'), ('sequence', 'NN'), ('time', 'NN'), ('series', 'NN'), ('input', 'NN'), ('data', 'NNS'), (',', ','), ('referred', 'VBD'), ('sequential', 'JJ'), ('pattern', 'NN'), ('mining', 'NN'), ('problem', 'NN'), ('[', 'VBZ'), ('34', 'CD'), (']', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['addition', 'relationships input data', 'sequence time series input data', 'sequential pattern mining problem', ']']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('addition', 'addit'), ('considering', 'consid'), ('relationships', 'relationship'), ('input', 'input'), ('data', 'data'), (',', ','), ('also', 'also'), ('consider', 'consid'), ('sequence', 'sequenc'), ('time', 'time'), ('series', 'seri'), ('input', 'input'), ('data', 'data'), (',', ','), ('referred', 'refer'), ('sequential', 'sequenti'), ('pattern', 'pattern'), ('mining', 'mine'), ('problem', 'problem'), ('[', '['), ('34', '34'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('addition', 'addit'), ('considering', 'consid'), ('relationships', 'relationship'), ('input', 'input'), ('data', 'data'), (',', ','), ('also', 'also'), ('consider', 'consid'), ('sequence', 'sequenc'), ('time', 'time'), ('series', 'seri'), ('input', 'input'), ('data', 'data'), (',', ','), ('referred', 'refer'), ('sequential', 'sequenti'), ('pattern', 'pattern'), ('mining', 'mine'), ('problem', 'problem'), ('[', '['), ('34', '34'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('addition', 'addition'), ('considering', 'considering'), ('relationships', 'relationship'), ('input', 'input'), ('data', 'data'), (',', ','), ('also', 'also'), ('consider', 'consider'), ('sequence', 'sequence'), ('time', 'time'), ('series', 'series'), ('input', 'input'), ('data', 'data'), (',', ','), ('referred', 'referred'), ('sequential', 'sequential'), ('pattern', 'pattern'), ('mining', 'mining'), ('problem', 'problem'), ('[', '['), ('34', '34'), (']', ']'), ('.', '.')]


------------------- Sentence 6 -------------------

Several apriori-like algorithms were pre- sented for solving it, such as generalized sequential pattern [34] and sequential pattern  discovery using equivalence classes [35].

>> Tokens are: 
 ['Several', 'apriori-like', 'algorithms', 'pre-', 'sented', 'solving', ',', 'generalized', 'sequential', 'pattern', '[', '34', ']', 'sequential', 'pattern', 'discovery', 'using', 'equivalence', 'classes', '[', '35', ']', '.']

>> Bigrams are: 
 [('Several', 'apriori-like'), ('apriori-like', 'algorithms'), ('algorithms', 'pre-'), ('pre-', 'sented'), ('sented', 'solving'), ('solving', ','), (',', 'generalized'), ('generalized', 'sequential'), ('sequential', 'pattern'), ('pattern', '['), ('[', '34'), ('34', ']'), (']', 'sequential'), ('sequential', 'pattern'), ('pattern', 'discovery'), ('discovery', 'using'), ('using', 'equivalence'), ('equivalence', 'classes'), ('classes', '['), ('[', '35'), ('35', ']'), (']', '.')]

>> Trigrams are: 
 [('Several', 'apriori-like', 'algorithms'), ('apriori-like', 'algorithms', 'pre-'), ('algorithms', 'pre-', 'sented'), ('pre-', 'sented', 'solving'), ('sented', 'solving', ','), ('solving', ',', 'generalized'), (',', 'generalized', 'sequential'), ('generalized', 'sequential', 'pattern'), ('sequential', 'pattern', '['), ('pattern', '[', '34'), ('[', '34', ']'), ('34', ']', 'sequential'), (']', 'sequential', 'pattern'), ('sequential', 'pattern', 'discovery'), ('pattern', 'discovery', 'using'), ('discovery', 'using', 'equivalence'), ('using', 'equivalence', 'classes'), ('equivalence', 'classes', '['), ('classes', '[', '35'), ('[', '35', ']'), ('35', ']', '.')]

>> POS Tags are: 
 [('Several', 'JJ'), ('apriori-like', 'JJ'), ('algorithms', 'JJ'), ('pre-', 'NN'), ('sented', 'VBD'), ('solving', 'NN'), (',', ','), ('generalized', 'VBN'), ('sequential', 'JJ'), ('pattern', 'NN'), ('[', '$'), ('34', 'CD'), (']', 'NNP'), ('sequential', 'JJ'), ('pattern', 'NN'), ('discovery', 'NN'), ('using', 'VBG'), ('equivalence', 'NN'), ('classes', 'NNS'), ('[', 'VBP'), ('35', 'CD'), (']', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Several apriori-like algorithms pre-', 'solving', 'sequential pattern', ']', 'sequential pattern discovery', 'equivalence classes', ']']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Several', 'sever'), ('apriori-like', 'apriori-lik'), ('algorithms', 'algorithm'), ('pre-', 'pre-'), ('sented', 'sent'), ('solving', 'solv'), (',', ','), ('generalized', 'gener'), ('sequential', 'sequenti'), ('pattern', 'pattern'), ('[', '['), ('34', '34'), (']', ']'), ('sequential', 'sequenti'), ('pattern', 'pattern'), ('discovery', 'discoveri'), ('using', 'use'), ('equivalence', 'equival'), ('classes', 'class'), ('[', '['), ('35', '35'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Several', 'sever'), ('apriori-like', 'apriori-lik'), ('algorithms', 'algorithm'), ('pre-', 'pre-'), ('sented', 'sent'), ('solving', 'solv'), (',', ','), ('generalized', 'general'), ('sequential', 'sequenti'), ('pattern', 'pattern'), ('[', '['), ('34', '34'), (']', ']'), ('sequential', 'sequenti'), ('pattern', 'pattern'), ('discovery', 'discoveri'), ('using', 'use'), ('equivalence', 'equival'), ('classes', 'class'), ('[', '['), ('35', '35'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('Several', 'Several'), ('apriori-like', 'apriori-like'), ('algorithms', 'algorithm'), ('pre-', 'pre-'), ('sented', 'sented'), ('solving', 'solving'), (',', ','), ('generalized', 'generalized'), ('sequential', 'sequential'), ('pattern', 'pattern'), ('[', '['), ('34', '34'), (']', ']'), ('sequential', 'sequential'), ('pattern', 'pattern'), ('discovery', 'discovery'), ('using', 'using'), ('equivalence', 'equivalence'), ('classes', 'class'), ('[', '['), ('35', '35'), (']', ']'), ('.', '.')]



========================================== PARAGRAPH 85 ===========================================

Output the result 

------------------- Sentence 1 -------------------

Output the result

>> Tokens are: 
 ['Output', 'result']

>> Bigrams are: 
 [('Output', 'result')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Output', 'NNP'), ('result', 'NN')]

>> Noun Phrases are: 
 ['Output result']

>> Named Entities are: 
 [('GPE', 'Output')] 

>> Stemming using Porter Stemmer: 
 [('Output', 'output'), ('result', 'result')]

>> Stemming using Snowball Stemmer: 
 [('Output', 'output'), ('result', 'result')]

>> Lemmatization: 
 [('Output', 'Output'), ('result', 'result')]



========================================== PARAGRAPH 86 ===========================================

Evaluation and interpretation are two vital operators of the output. Evaluation typically  plays the role of measuring the results. It can also be one of the operators for the data  

------------------- Sentence 1 -------------------

Evaluation and interpretation are two vital operators of the output.

>> Tokens are: 
 ['Evaluation', 'interpretation', 'two', 'vital', 'operators', 'output', '.']

>> Bigrams are: 
 [('Evaluation', 'interpretation'), ('interpretation', 'two'), ('two', 'vital'), ('vital', 'operators'), ('operators', 'output'), ('output', '.')]

>> Trigrams are: 
 [('Evaluation', 'interpretation', 'two'), ('interpretation', 'two', 'vital'), ('two', 'vital', 'operators'), ('vital', 'operators', 'output'), ('operators', 'output', '.')]

>> POS Tags are: 
 [('Evaluation', 'NNP'), ('interpretation', 'NN'), ('two', 'CD'), ('vital', 'NN'), ('operators', 'NNS'), ('output', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Evaluation interpretation', 'vital operators output']

>> Named Entities are: 
 [('GPE', 'Evaluation')] 

>> Stemming using Porter Stemmer: 
 [('Evaluation', 'evalu'), ('interpretation', 'interpret'), ('two', 'two'), ('vital', 'vital'), ('operators', 'oper'), ('output', 'output'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Evaluation', 'evalu'), ('interpretation', 'interpret'), ('two', 'two'), ('vital', 'vital'), ('operators', 'oper'), ('output', 'output'), ('.', '.')]

>> Lemmatization: 
 [('Evaluation', 'Evaluation'), ('interpretation', 'interpretation'), ('two', 'two'), ('vital', 'vital'), ('operators', 'operator'), ('output', 'output'), ('.', '.')]


------------------- Sentence 2 -------------------

Evaluation typically  plays the role of measuring the results.

>> Tokens are: 
 ['Evaluation', 'typically', 'plays', 'role', 'measuring', 'results', '.']

>> Bigrams are: 
 [('Evaluation', 'typically'), ('typically', 'plays'), ('plays', 'role'), ('role', 'measuring'), ('measuring', 'results'), ('results', '.')]

>> Trigrams are: 
 [('Evaluation', 'typically', 'plays'), ('typically', 'plays', 'role'), ('plays', 'role', 'measuring'), ('role', 'measuring', 'results'), ('measuring', 'results', '.')]

>> POS Tags are: 
 [('Evaluation', 'NN'), ('typically', 'RB'), ('plays', 'VBZ'), ('role', 'NN'), ('measuring', 'VBG'), ('results', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['Evaluation', 'role', 'results']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Evaluation', 'evalu'), ('typically', 'typic'), ('plays', 'play'), ('role', 'role'), ('measuring', 'measur'), ('results', 'result'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Evaluation', 'evalu'), ('typically', 'typic'), ('plays', 'play'), ('role', 'role'), ('measuring', 'measur'), ('results', 'result'), ('.', '.')]

>> Lemmatization: 
 [('Evaluation', 'Evaluation'), ('typically', 'typically'), ('plays', 'play'), ('role', 'role'), ('measuring', 'measuring'), ('results', 'result'), ('.', '.')]


------------------- Sentence 3 -------------------

It can also be one of the operators for the data

>> Tokens are: 
 ['It', 'also', 'one', 'operators', 'data']

>> Bigrams are: 
 [('It', 'also'), ('also', 'one'), ('one', 'operators'), ('operators', 'data')]

>> Trigrams are: 
 [('It', 'also', 'one'), ('also', 'one', 'operators'), ('one', 'operators', 'data')]

>> POS Tags are: 
 [('It', 'PRP'), ('also', 'RB'), ('one', 'CD'), ('operators', 'NNS'), ('data', 'VBP')]

>> Noun Phrases are: 
 ['operators']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('It', 'it'), ('also', 'also'), ('one', 'one'), ('operators', 'oper'), ('data', 'data')]

>> Stemming using Snowball Stemmer: 
 [('It', 'it'), ('also', 'also'), ('one', 'one'), ('operators', 'oper'), ('data', 'data')]

>> Lemmatization: 
 [('It', 'It'), ('also', 'also'), ('one', 'one'), ('operators', 'operator'), ('data', 'data')]



========================================== PARAGRAPH 87 ===========================================

2 In this paper, by an unlabeled input data, we mean that it is unknown to which group the input data belongs. If all the  input data are unlabeled, it means that the distribution of the input data is unknown. 

------------------- Sentence 1 -------------------

2 In this paper, by an unlabeled input data, we mean that it is unknown to which group the input data belongs.

>> Tokens are: 
 ['2', 'In', 'paper', ',', 'unlabeled', 'input', 'data', ',', 'mean', 'unknown', 'group', 'input', 'data', 'belongs', '.']

>> Bigrams are: 
 [('2', 'In'), ('In', 'paper'), ('paper', ','), (',', 'unlabeled'), ('unlabeled', 'input'), ('input', 'data'), ('data', ','), (',', 'mean'), ('mean', 'unknown'), ('unknown', 'group'), ('group', 'input'), ('input', 'data'), ('data', 'belongs'), ('belongs', '.')]

>> Trigrams are: 
 [('2', 'In', 'paper'), ('In', 'paper', ','), ('paper', ',', 'unlabeled'), (',', 'unlabeled', 'input'), ('unlabeled', 'input', 'data'), ('input', 'data', ','), ('data', ',', 'mean'), (',', 'mean', 'unknown'), ('mean', 'unknown', 'group'), ('unknown', 'group', 'input'), ('group', 'input', 'data'), ('input', 'data', 'belongs'), ('data', 'belongs', '.')]

>> POS Tags are: 
 [('2', 'CD'), ('In', 'IN'), ('paper', 'NN'), (',', ','), ('unlabeled', 'JJ'), ('input', 'NN'), ('data', 'NNS'), (',', ','), ('mean', 'JJ'), ('unknown', 'JJ'), ('group', 'NN'), ('input', 'NN'), ('data', 'NNS'), ('belongs', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['paper', 'unlabeled input data', 'mean unknown group input data belongs']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('2', '2'), ('In', 'in'), ('paper', 'paper'), (',', ','), ('unlabeled', 'unlabel'), ('input', 'input'), ('data', 'data'), (',', ','), ('mean', 'mean'), ('unknown', 'unknown'), ('group', 'group'), ('input', 'input'), ('data', 'data'), ('belongs', 'belong'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('2', '2'), ('In', 'in'), ('paper', 'paper'), (',', ','), ('unlabeled', 'unlabel'), ('input', 'input'), ('data', 'data'), (',', ','), ('mean', 'mean'), ('unknown', 'unknown'), ('group', 'group'), ('input', 'input'), ('data', 'data'), ('belongs', 'belong'), ('.', '.')]

>> Lemmatization: 
 [('2', '2'), ('In', 'In'), ('paper', 'paper'), (',', ','), ('unlabeled', 'unlabeled'), ('input', 'input'), ('data', 'data'), (',', ','), ('mean', 'mean'), ('unknown', 'unknown'), ('group', 'group'), ('input', 'input'), ('data', 'data'), ('belongs', 'belongs'), ('.', '.')]


------------------- Sentence 2 -------------------

If all the  input data are unlabeled, it means that the distribution of the input data is unknown.

>> Tokens are: 
 ['If', 'input', 'data', 'unlabeled', ',', 'means', 'distribution', 'input', 'data', 'unknown', '.']

>> Bigrams are: 
 [('If', 'input'), ('input', 'data'), ('data', 'unlabeled'), ('unlabeled', ','), (',', 'means'), ('means', 'distribution'), ('distribution', 'input'), ('input', 'data'), ('data', 'unknown'), ('unknown', '.')]

>> Trigrams are: 
 [('If', 'input', 'data'), ('input', 'data', 'unlabeled'), ('data', 'unlabeled', ','), ('unlabeled', ',', 'means'), (',', 'means', 'distribution'), ('means', 'distribution', 'input'), ('distribution', 'input', 'data'), ('input', 'data', 'unknown'), ('data', 'unknown', '.')]

>> POS Tags are: 
 [('If', 'IN'), ('input', 'VBN'), ('data', 'NNS'), ('unlabeled', 'VBD'), (',', ','), ('means', 'VBZ'), ('distribution', 'NN'), ('input', 'NN'), ('data', 'NNS'), ('unknown', 'RB'), ('.', '.')]

>> Noun Phrases are: 
 ['data', 'distribution input data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('If', 'if'), ('input', 'input'), ('data', 'data'), ('unlabeled', 'unlabel'), (',', ','), ('means', 'mean'), ('distribution', 'distribut'), ('input', 'input'), ('data', 'data'), ('unknown', 'unknown'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('If', 'if'), ('input', 'input'), ('data', 'data'), ('unlabeled', 'unlabel'), (',', ','), ('means', 'mean'), ('distribution', 'distribut'), ('input', 'input'), ('data', 'data'), ('unknown', 'unknown'), ('.', '.')]

>> Lemmatization: 
 [('If', 'If'), ('input', 'input'), ('data', 'data'), ('unlabeled', 'unlabeled'), (',', ','), ('means', 'mean'), ('distribution', 'distribution'), ('input', 'input'), ('data', 'data'), ('unknown', 'unknown'), ('.', '.')]



========================================== PARAGRAPH 88 ===========================================

1 Input data D 2 Initialize candidate solutions r 3 While the termination criterion is not met 4 d = Scan(D) 5 v = Construct(d, r, o) 6 r = Update(v) 7 End 8 Output rules r 

------------------- Sentence 1 -------------------

1 Input data D 2 Initialize candidate solutions r 3 While the termination criterion is not met 4 d = Scan(D) 5 v = Construct(d, r, o) 6 r = Update(v) 7 End 8 Output rules r

>> Tokens are: 
 ['1', 'Input', 'data', 'D', '2', 'Initialize', 'candidate', 'solutions', 'r', '3', 'While', 'termination', 'criterion', 'met', '4', '=', 'Scan', '(', 'D', ')', '5', 'v', '=', 'Construct', '(', ',', 'r', ',', ')', '6', 'r', '=', 'Update', '(', 'v', ')', '7', 'End', '8', 'Output', 'rules', 'r']

>> Bigrams are: 
 [('1', 'Input'), ('Input', 'data'), ('data', 'D'), ('D', '2'), ('2', 'Initialize'), ('Initialize', 'candidate'), ('candidate', 'solutions'), ('solutions', 'r'), ('r', '3'), ('3', 'While'), ('While', 'termination'), ('termination', 'criterion'), ('criterion', 'met'), ('met', '4'), ('4', '='), ('=', 'Scan'), ('Scan', '('), ('(', 'D'), ('D', ')'), (')', '5'), ('5', 'v'), ('v', '='), ('=', 'Construct'), ('Construct', '('), ('(', ','), (',', 'r'), ('r', ','), (',', ')'), (')', '6'), ('6', 'r'), ('r', '='), ('=', 'Update'), ('Update', '('), ('(', 'v'), ('v', ')'), (')', '7'), ('7', 'End'), ('End', '8'), ('8', 'Output'), ('Output', 'rules'), ('rules', 'r')]

>> Trigrams are: 
 [('1', 'Input', 'data'), ('Input', 'data', 'D'), ('data', 'D', '2'), ('D', '2', 'Initialize'), ('2', 'Initialize', 'candidate'), ('Initialize', 'candidate', 'solutions'), ('candidate', 'solutions', 'r'), ('solutions', 'r', '3'), ('r', '3', 'While'), ('3', 'While', 'termination'), ('While', 'termination', 'criterion'), ('termination', 'criterion', 'met'), ('criterion', 'met', '4'), ('met', '4', '='), ('4', '=', 'Scan'), ('=', 'Scan', '('), ('Scan', '(', 'D'), ('(', 'D', ')'), ('D', ')', '5'), (')', '5', 'v'), ('5', 'v', '='), ('v', '=', 'Construct'), ('=', 'Construct', '('), ('Construct', '(', ','), ('(', ',', 'r'), (',', 'r', ','), ('r', ',', ')'), (',', ')', '6'), (')', '6', 'r'), ('6', 'r', '='), ('r', '=', 'Update'), ('=', 'Update', '('), ('Update', '(', 'v'), ('(', 'v', ')'), ('v', ')', '7'), (')', '7', 'End'), ('7', 'End', '8'), ('End', '8', 'Output'), ('8', 'Output', 'rules'), ('Output', 'rules', 'r')]

>> POS Tags are: 
 [('1', 'CD'), ('Input', 'NNP'), ('data', 'NNS'), ('D', 'NNP'), ('2', 'CD'), ('Initialize', 'NNP'), ('candidate', 'NN'), ('solutions', 'NNS'), ('r', 'VBP'), ('3', 'CD'), ('While', 'IN'), ('termination', 'NN'), ('criterion', 'NN'), ('met', 'VBD'), ('4', 'CD'), ('=', 'NNS'), ('Scan', 'NNP'), ('(', '('), ('D', 'NNP'), (')', ')'), ('5', 'CD'), ('v', 'JJ'), ('=', 'JJ'), ('Construct', 'NNP'), ('(', '('), (',', ','), ('r', 'NN'), (',', ','), (')', ')'), ('6', 'CD'), ('r', 'NN'), ('=', 'NN'), ('Update', 'NNP'), ('(', '('), ('v', 'NN'), (')', ')'), ('7', 'CD'), ('End', 'NN'), ('8', 'CD'), ('Output', 'NNP'), ('rules', 'NNS'), ('r', 'VBP')]

>> Noun Phrases are: 
 ['Input data D', 'Initialize candidate solutions', 'termination criterion', '= Scan', 'D', 'v = Construct', 'r', 'r = Update', 'v', 'End', 'Output rules']

>> Named Entities are: 
 [('GPE', 'Scan'), ('GPE', 'Update')] 

>> Stemming using Porter Stemmer: 
 [('1', '1'), ('Input', 'input'), ('data', 'data'), ('D', 'd'), ('2', '2'), ('Initialize', 'initi'), ('candidate', 'candid'), ('solutions', 'solut'), ('r', 'r'), ('3', '3'), ('While', 'while'), ('termination', 'termin'), ('criterion', 'criterion'), ('met', 'met'), ('4', '4'), ('=', '='), ('Scan', 'scan'), ('(', '('), ('D', 'd'), (')', ')'), ('5', '5'), ('v', 'v'), ('=', '='), ('Construct', 'construct'), ('(', '('), (',', ','), ('r', 'r'), (',', ','), (')', ')'), ('6', '6'), ('r', 'r'), ('=', '='), ('Update', 'updat'), ('(', '('), ('v', 'v'), (')', ')'), ('7', '7'), ('End', 'end'), ('8', '8'), ('Output', 'output'), ('rules', 'rule'), ('r', 'r')]

>> Stemming using Snowball Stemmer: 
 [('1', '1'), ('Input', 'input'), ('data', 'data'), ('D', 'd'), ('2', '2'), ('Initialize', 'initi'), ('candidate', 'candid'), ('solutions', 'solut'), ('r', 'r'), ('3', '3'), ('While', 'while'), ('termination', 'termin'), ('criterion', 'criterion'), ('met', 'met'), ('4', '4'), ('=', '='), ('Scan', 'scan'), ('(', '('), ('D', 'd'), (')', ')'), ('5', '5'), ('v', 'v'), ('=', '='), ('Construct', 'construct'), ('(', '('), (',', ','), ('r', 'r'), (',', ','), (')', ')'), ('6', '6'), ('r', 'r'), ('=', '='), ('Update', 'updat'), ('(', '('), ('v', 'v'), (')', ')'), ('7', '7'), ('End', 'end'), ('8', '8'), ('Output', 'output'), ('rules', 'rule'), ('r', 'r')]

>> Lemmatization: 
 [('1', '1'), ('Input', 'Input'), ('data', 'data'), ('D', 'D'), ('2', '2'), ('Initialize', 'Initialize'), ('candidate', 'candidate'), ('solutions', 'solution'), ('r', 'r'), ('3', '3'), ('While', 'While'), ('termination', 'termination'), ('criterion', 'criterion'), ('met', 'met'), ('4', '4'), ('=', '='), ('Scan', 'Scan'), ('(', '('), ('D', 'D'), (')', ')'), ('5', '5'), ('v', 'v'), ('=', '='), ('Construct', 'Construct'), ('(', '('), (',', ','), ('r', 'r'), (',', ','), (')', ')'), ('6', '6'), ('r', 'r'), ('=', '='), ('Update', 'Update'), ('(', '('), ('v', 'v'), (')', ')'), ('7', '7'), ('End', 'End'), ('8', '8'), ('Output', 'Output'), ('rules', 'rule'), ('r', 'r')]



========================================== PARAGRAPH 89 ===========================================

Fig. 4 Data mining algorithm

------------------- Sentence 1 -------------------

Fig.

>> Tokens are: 
 ['Fig', '.']

>> Bigrams are: 
 [('Fig', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Fig', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Fig']

>> Named Entities are: 
 [('GPE', 'Fig')] 

>> Stemming using Porter Stemmer: 
 [('Fig', 'fig'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Fig', 'fig'), ('.', '.')]

>> Lemmatization: 
 [('Fig', 'Fig'), ('.', '.')]


------------------- Sentence 2 -------------------

4 Data mining algorithm

>> Tokens are: 
 ['4', 'Data', 'mining', 'algorithm']

>> Bigrams are: 
 [('4', 'Data'), ('Data', 'mining'), ('mining', 'algorithm')]

>> Trigrams are: 
 [('4', 'Data', 'mining'), ('Data', 'mining', 'algorithm')]

>> POS Tags are: 
 [('4', 'CD'), ('Data', 'NNP'), ('mining', 'NN'), ('algorithm', 'NN')]

>> Noun Phrases are: 
 ['Data mining algorithm']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('4', '4'), ('Data', 'data'), ('mining', 'mine'), ('algorithm', 'algorithm')]

>> Stemming using Snowball Stemmer: 
 [('4', '4'), ('Data', 'data'), ('mining', 'mine'), ('algorithm', 'algorithm')]

>> Lemmatization: 
 [('4', '4'), ('Data', 'Data'), ('mining', 'mining'), ('algorithm', 'algorithm')]



========================================== PARAGRAPH 90 ===========================================

Page 6 of 32Tsai et al. Journal of Big Data  (2015) 2:21  

------------------- Sentence 1 -------------------

Page 6 of 32Tsai et al.

>> Tokens are: 
 ['Page', '6', '32Tsai', 'et', 'al', '.']

>> Bigrams are: 
 [('Page', '6'), ('6', '32Tsai'), ('32Tsai', 'et'), ('et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('Page', '6', '32Tsai'), ('6', '32Tsai', 'et'), ('32Tsai', 'et', 'al'), ('et', 'al', '.')]

>> POS Tags are: 
 [('Page', 'NN'), ('6', 'CD'), ('32Tsai', 'CD'), ('et', 'NN'), ('al', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Page', 'et al']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Page', 'page'), ('6', '6'), ('32Tsai', '32tsai'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Page', 'page'), ('6', '6'), ('32Tsai', '32tsai'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('Page', 'Page'), ('6', '6'), ('32Tsai', '32Tsai'), ('et', 'et'), ('al', 'al'), ('.', '.')]


------------------- Sentence 2 -------------------

Journal of Big Data  (2015) 2:21

>> Tokens are: 
 ['Journal', 'Big', 'Data', '(', '2015', ')', '2:21']

>> Bigrams are: 
 [('Journal', 'Big'), ('Big', 'Data'), ('Data', '('), ('(', '2015'), ('2015', ')'), (')', '2:21')]

>> Trigrams are: 
 [('Journal', 'Big', 'Data'), ('Big', 'Data', '('), ('Data', '(', '2015'), ('(', '2015', ')'), ('2015', ')', '2:21')]

>> POS Tags are: 
 [('Journal', 'NNP'), ('Big', 'NNP'), ('Data', 'NNP'), ('(', '('), ('2015', 'CD'), (')', ')'), ('2:21', 'CD')]

>> Noun Phrases are: 
 ['Journal Big Data']

>> Named Entities are: 
 [('PERSON', 'Journal')] 

>> Stemming using Porter Stemmer: 
 [('Journal', 'journal'), ('Big', 'big'), ('Data', 'data'), ('(', '('), ('2015', '2015'), (')', ')'), ('2:21', '2:21')]

>> Stemming using Snowball Stemmer: 
 [('Journal', 'journal'), ('Big', 'big'), ('Data', 'data'), ('(', '('), ('2015', '2015'), (')', ')'), ('2:21', '2:21')]

>> Lemmatization: 
 [('Journal', 'Journal'), ('Big', 'Big'), ('Data', 'Data'), ('(', '('), ('2015', '2015'), (')', ')'), ('2:21', '2:21')]



========================================== PARAGRAPH 91 ===========================================

mining algorithm, such as the sum of squared errors which was used by the selection  operator of the genetic algorithm for the clustering problem [25]. 

------------------- Sentence 1 -------------------

mining algorithm, such as the sum of squared errors which was used by the selection  operator of the genetic algorithm for the clustering problem [25].

>> Tokens are: 
 ['mining', 'algorithm', ',', 'sum', 'squared', 'errors', 'used', 'selection', 'operator', 'genetic', 'algorithm', 'clustering', 'problem', '[', '25', ']', '.']

>> Bigrams are: 
 [('mining', 'algorithm'), ('algorithm', ','), (',', 'sum'), ('sum', 'squared'), ('squared', 'errors'), ('errors', 'used'), ('used', 'selection'), ('selection', 'operator'), ('operator', 'genetic'), ('genetic', 'algorithm'), ('algorithm', 'clustering'), ('clustering', 'problem'), ('problem', '['), ('[', '25'), ('25', ']'), (']', '.')]

>> Trigrams are: 
 [('mining', 'algorithm', ','), ('algorithm', ',', 'sum'), (',', 'sum', 'squared'), ('sum', 'squared', 'errors'), ('squared', 'errors', 'used'), ('errors', 'used', 'selection'), ('used', 'selection', 'operator'), ('selection', 'operator', 'genetic'), ('operator', 'genetic', 'algorithm'), ('genetic', 'algorithm', 'clustering'), ('algorithm', 'clustering', 'problem'), ('clustering', 'problem', '['), ('problem', '[', '25'), ('[', '25', ']'), ('25', ']', '.')]

>> POS Tags are: 
 [('mining', 'NN'), ('algorithm', 'NN'), (',', ','), ('sum', 'NN'), ('squared', 'VBD'), ('errors', 'NNS'), ('used', 'VBN'), ('selection', 'NN'), ('operator', 'NN'), ('genetic', 'JJ'), ('algorithm', 'NN'), ('clustering', 'NN'), ('problem', 'NN'), ('[', 'VBZ'), ('25', 'CD'), (']', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['mining algorithm', 'sum', 'errors', 'selection operator', 'genetic algorithm clustering problem', ']']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('mining', 'mine'), ('algorithm', 'algorithm'), (',', ','), ('sum', 'sum'), ('squared', 'squar'), ('errors', 'error'), ('used', 'use'), ('selection', 'select'), ('operator', 'oper'), ('genetic', 'genet'), ('algorithm', 'algorithm'), ('clustering', 'cluster'), ('problem', 'problem'), ('[', '['), ('25', '25'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('mining', 'mine'), ('algorithm', 'algorithm'), (',', ','), ('sum', 'sum'), ('squared', 'squar'), ('errors', 'error'), ('used', 'use'), ('selection', 'select'), ('operator', 'oper'), ('genetic', 'genet'), ('algorithm', 'algorithm'), ('clustering', 'cluster'), ('problem', 'problem'), ('[', '['), ('25', '25'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('mining', 'mining'), ('algorithm', 'algorithm'), (',', ','), ('sum', 'sum'), ('squared', 'squared'), ('errors', 'error'), ('used', 'used'), ('selection', 'selection'), ('operator', 'operator'), ('genetic', 'genetic'), ('algorithm', 'algorithm'), ('clustering', 'clustering'), ('problem', 'problem'), ('[', '['), ('25', '25'), (']', ']'), ('.', '.')]



========================================== PARAGRAPH 92 ===========================================

To solve the data mining problems that attempt to classify the input data, two of the  major goals are: (1) cohesion—the distance between each data and the centroid (mean)  of its cluster should be as small as possible, and (2) coupling—the distance between data  which belong to different clusters should be as large as possible. In most studies of data  clustering or classification problems, the sum of squared errors (SSE), which was used to  measure the cohesion of the data mining results, can be defined as 

------------------- Sentence 1 -------------------

To solve the data mining problems that attempt to classify the input data, two of the  major goals are: (1) cohesion—the distance between each data and the centroid (mean)  of its cluster should be as small as possible, and (2) coupling—the distance between data  which belong to different clusters should be as large as possible.

>> Tokens are: 
 ['To', 'solve', 'data', 'mining', 'problems', 'attempt', 'classify', 'input', 'data', ',', 'two', 'major', 'goals', ':', '(', '1', ')', 'cohesion—the', 'distance', 'data', 'centroid', '(', 'mean', ')', 'cluster', 'small', 'possible', ',', '(', '2', ')', 'coupling—the', 'distance', 'data', 'belong', 'different', 'clusters', 'large', 'possible', '.']

>> Bigrams are: 
 [('To', 'solve'), ('solve', 'data'), ('data', 'mining'), ('mining', 'problems'), ('problems', 'attempt'), ('attempt', 'classify'), ('classify', 'input'), ('input', 'data'), ('data', ','), (',', 'two'), ('two', 'major'), ('major', 'goals'), ('goals', ':'), (':', '('), ('(', '1'), ('1', ')'), (')', 'cohesion—the'), ('cohesion—the', 'distance'), ('distance', 'data'), ('data', 'centroid'), ('centroid', '('), ('(', 'mean'), ('mean', ')'), (')', 'cluster'), ('cluster', 'small'), ('small', 'possible'), ('possible', ','), (',', '('), ('(', '2'), ('2', ')'), (')', 'coupling—the'), ('coupling—the', 'distance'), ('distance', 'data'), ('data', 'belong'), ('belong', 'different'), ('different', 'clusters'), ('clusters', 'large'), ('large', 'possible'), ('possible', '.')]

>> Trigrams are: 
 [('To', 'solve', 'data'), ('solve', 'data', 'mining'), ('data', 'mining', 'problems'), ('mining', 'problems', 'attempt'), ('problems', 'attempt', 'classify'), ('attempt', 'classify', 'input'), ('classify', 'input', 'data'), ('input', 'data', ','), ('data', ',', 'two'), (',', 'two', 'major'), ('two', 'major', 'goals'), ('major', 'goals', ':'), ('goals', ':', '('), (':', '(', '1'), ('(', '1', ')'), ('1', ')', 'cohesion—the'), (')', 'cohesion—the', 'distance'), ('cohesion—the', 'distance', 'data'), ('distance', 'data', 'centroid'), ('data', 'centroid', '('), ('centroid', '(', 'mean'), ('(', 'mean', ')'), ('mean', ')', 'cluster'), (')', 'cluster', 'small'), ('cluster', 'small', 'possible'), ('small', 'possible', ','), ('possible', ',', '('), (',', '(', '2'), ('(', '2', ')'), ('2', ')', 'coupling—the'), (')', 'coupling—the', 'distance'), ('coupling—the', 'distance', 'data'), ('distance', 'data', 'belong'), ('data', 'belong', 'different'), ('belong', 'different', 'clusters'), ('different', 'clusters', 'large'), ('clusters', 'large', 'possible'), ('large', 'possible', '.')]

>> POS Tags are: 
 [('To', 'TO'), ('solve', 'VB'), ('data', 'NNS'), ('mining', 'NN'), ('problems', 'NNS'), ('attempt', 'VBP'), ('classify', 'VB'), ('input', 'NN'), ('data', 'NNS'), (',', ','), ('two', 'CD'), ('major', 'JJ'), ('goals', 'NNS'), (':', ':'), ('(', '('), ('1', 'CD'), (')', ')'), ('cohesion—the', 'NN'), ('distance', 'NN'), ('data', 'NNS'), ('centroid', 'NN'), ('(', '('), ('mean', 'JJ'), (')', ')'), ('cluster', 'NN'), ('small', 'JJ'), ('possible', 'JJ'), (',', ','), ('(', '('), ('2', 'CD'), (')', ')'), ('coupling—the', 'NN'), ('distance', 'NN'), ('data', 'NNS'), ('belong', 'RB'), ('different', 'JJ'), ('clusters', 'NNS'), ('large', 'JJ'), ('possible', 'JJ'), ('.', '.')]

>> Noun Phrases are: 
 ['data mining problems', 'input data', 'major goals', 'cohesion—the distance data centroid', 'cluster', 'coupling—the distance data', 'different clusters']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('To', 'to'), ('solve', 'solv'), ('data', 'data'), ('mining', 'mine'), ('problems', 'problem'), ('attempt', 'attempt'), ('classify', 'classifi'), ('input', 'input'), ('data', 'data'), (',', ','), ('two', 'two'), ('major', 'major'), ('goals', 'goal'), (':', ':'), ('(', '('), ('1', '1'), (')', ')'), ('cohesion—the', 'cohesion—th'), ('distance', 'distanc'), ('data', 'data'), ('centroid', 'centroid'), ('(', '('), ('mean', 'mean'), (')', ')'), ('cluster', 'cluster'), ('small', 'small'), ('possible', 'possibl'), (',', ','), ('(', '('), ('2', '2'), (')', ')'), ('coupling—the', 'coupling—th'), ('distance', 'distanc'), ('data', 'data'), ('belong', 'belong'), ('different', 'differ'), ('clusters', 'cluster'), ('large', 'larg'), ('possible', 'possibl'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('To', 'to'), ('solve', 'solv'), ('data', 'data'), ('mining', 'mine'), ('problems', 'problem'), ('attempt', 'attempt'), ('classify', 'classifi'), ('input', 'input'), ('data', 'data'), (',', ','), ('two', 'two'), ('major', 'major'), ('goals', 'goal'), (':', ':'), ('(', '('), ('1', '1'), (')', ')'), ('cohesion—the', 'cohesion—th'), ('distance', 'distanc'), ('data', 'data'), ('centroid', 'centroid'), ('(', '('), ('mean', 'mean'), (')', ')'), ('cluster', 'cluster'), ('small', 'small'), ('possible', 'possibl'), (',', ','), ('(', '('), ('2', '2'), (')', ')'), ('coupling—the', 'coupling—th'), ('distance', 'distanc'), ('data', 'data'), ('belong', 'belong'), ('different', 'differ'), ('clusters', 'cluster'), ('large', 'larg'), ('possible', 'possibl'), ('.', '.')]

>> Lemmatization: 
 [('To', 'To'), ('solve', 'solve'), ('data', 'data'), ('mining', 'mining'), ('problems', 'problem'), ('attempt', 'attempt'), ('classify', 'classify'), ('input', 'input'), ('data', 'data'), (',', ','), ('two', 'two'), ('major', 'major'), ('goals', 'goal'), (':', ':'), ('(', '('), ('1', '1'), (')', ')'), ('cohesion—the', 'cohesion—the'), ('distance', 'distance'), ('data', 'data'), ('centroid', 'centroid'), ('(', '('), ('mean', 'mean'), (')', ')'), ('cluster', 'cluster'), ('small', 'small'), ('possible', 'possible'), (',', ','), ('(', '('), ('2', '2'), (')', ')'), ('coupling—the', 'coupling—the'), ('distance', 'distance'), ('data', 'data'), ('belong', 'belong'), ('different', 'different'), ('clusters', 'cluster'), ('large', 'large'), ('possible', 'possible'), ('.', '.')]


------------------- Sentence 2 -------------------

In most studies of data  clustering or classification problems, the sum of squared errors (SSE), which was used to  measure the cohesion of the data mining results, can be defined as

>> Tokens are: 
 ['In', 'studies', 'data', 'clustering', 'classification', 'problems', ',', 'sum', 'squared', 'errors', '(', 'SSE', ')', ',', 'used', 'measure', 'cohesion', 'data', 'mining', 'results', ',', 'defined']

>> Bigrams are: 
 [('In', 'studies'), ('studies', 'data'), ('data', 'clustering'), ('clustering', 'classification'), ('classification', 'problems'), ('problems', ','), (',', 'sum'), ('sum', 'squared'), ('squared', 'errors'), ('errors', '('), ('(', 'SSE'), ('SSE', ')'), (')', ','), (',', 'used'), ('used', 'measure'), ('measure', 'cohesion'), ('cohesion', 'data'), ('data', 'mining'), ('mining', 'results'), ('results', ','), (',', 'defined')]

>> Trigrams are: 
 [('In', 'studies', 'data'), ('studies', 'data', 'clustering'), ('data', 'clustering', 'classification'), ('clustering', 'classification', 'problems'), ('classification', 'problems', ','), ('problems', ',', 'sum'), (',', 'sum', 'squared'), ('sum', 'squared', 'errors'), ('squared', 'errors', '('), ('errors', '(', 'SSE'), ('(', 'SSE', ')'), ('SSE', ')', ','), (')', ',', 'used'), (',', 'used', 'measure'), ('used', 'measure', 'cohesion'), ('measure', 'cohesion', 'data'), ('cohesion', 'data', 'mining'), ('data', 'mining', 'results'), ('mining', 'results', ','), ('results', ',', 'defined')]

>> POS Tags are: 
 [('In', 'IN'), ('studies', 'NNS'), ('data', 'NNS'), ('clustering', 'VBG'), ('classification', 'NN'), ('problems', 'NNS'), (',', ','), ('sum', 'RB'), ('squared', 'JJ'), ('errors', 'NNS'), ('(', '('), ('SSE', 'NNP'), (')', ')'), (',', ','), ('used', 'VBN'), ('measure', 'NN'), ('cohesion', 'NN'), ('data', 'NNS'), ('mining', 'NN'), ('results', 'NNS'), (',', ','), ('defined', 'VBD')]

>> Noun Phrases are: 
 ['studies data', 'classification problems', 'squared errors', 'SSE', 'measure cohesion data mining results']

>> Named Entities are: 
 [('ORGANIZATION', 'SSE')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('studies', 'studi'), ('data', 'data'), ('clustering', 'cluster'), ('classification', 'classif'), ('problems', 'problem'), (',', ','), ('sum', 'sum'), ('squared', 'squar'), ('errors', 'error'), ('(', '('), ('SSE', 'sse'), (')', ')'), (',', ','), ('used', 'use'), ('measure', 'measur'), ('cohesion', 'cohes'), ('data', 'data'), ('mining', 'mine'), ('results', 'result'), (',', ','), ('defined', 'defin')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('studies', 'studi'), ('data', 'data'), ('clustering', 'cluster'), ('classification', 'classif'), ('problems', 'problem'), (',', ','), ('sum', 'sum'), ('squared', 'squar'), ('errors', 'error'), ('(', '('), ('SSE', 'sse'), (')', ')'), (',', ','), ('used', 'use'), ('measure', 'measur'), ('cohesion', 'cohes'), ('data', 'data'), ('mining', 'mine'), ('results', 'result'), (',', ','), ('defined', 'defin')]

>> Lemmatization: 
 [('In', 'In'), ('studies', 'study'), ('data', 'data'), ('clustering', 'clustering'), ('classification', 'classification'), ('problems', 'problem'), (',', ','), ('sum', 'sum'), ('squared', 'squared'), ('errors', 'error'), ('(', '('), ('SSE', 'SSE'), (')', ')'), (',', ','), ('used', 'used'), ('measure', 'measure'), ('cohesion', 'cohesion'), ('data', 'data'), ('mining', 'mining'), ('results', 'result'), (',', ','), ('defined', 'defined')]



========================================== PARAGRAPH 93 ===========================================

where k is the number of clusters which is typically given by the user; ni the number of  data in the ith cluster; xij the jth datum in the ith cluster; ci is the mean of the ith cluster;  and n = 

------------------- Sentence 1 -------------------

where k is the number of clusters which is typically given by the user; ni the number of  data in the ith cluster; xij the jth datum in the ith cluster; ci is the mean of the ith cluster;  and n =

>> Tokens are: 
 ['k', 'number', 'clusters', 'typically', 'given', 'user', ';', 'ni', 'number', 'data', 'ith', 'cluster', ';', 'xij', 'jth', 'datum', 'ith', 'cluster', ';', 'ci', 'mean', 'ith', 'cluster', ';', 'n', '=']

>> Bigrams are: 
 [('k', 'number'), ('number', 'clusters'), ('clusters', 'typically'), ('typically', 'given'), ('given', 'user'), ('user', ';'), (';', 'ni'), ('ni', 'number'), ('number', 'data'), ('data', 'ith'), ('ith', 'cluster'), ('cluster', ';'), (';', 'xij'), ('xij', 'jth'), ('jth', 'datum'), ('datum', 'ith'), ('ith', 'cluster'), ('cluster', ';'), (';', 'ci'), ('ci', 'mean'), ('mean', 'ith'), ('ith', 'cluster'), ('cluster', ';'), (';', 'n'), ('n', '=')]

>> Trigrams are: 
 [('k', 'number', 'clusters'), ('number', 'clusters', 'typically'), ('clusters', 'typically', 'given'), ('typically', 'given', 'user'), ('given', 'user', ';'), ('user', ';', 'ni'), (';', 'ni', 'number'), ('ni', 'number', 'data'), ('number', 'data', 'ith'), ('data', 'ith', 'cluster'), ('ith', 'cluster', ';'), ('cluster', ';', 'xij'), (';', 'xij', 'jth'), ('xij', 'jth', 'datum'), ('jth', 'datum', 'ith'), ('datum', 'ith', 'cluster'), ('ith', 'cluster', ';'), ('cluster', ';', 'ci'), (';', 'ci', 'mean'), ('ci', 'mean', 'ith'), ('mean', 'ith', 'cluster'), ('ith', 'cluster', ';'), ('cluster', ';', 'n'), (';', 'n', '=')]

>> POS Tags are: 
 [('k', 'NN'), ('number', 'NN'), ('clusters', 'NNS'), ('typically', 'RB'), ('given', 'VBN'), ('user', 'NN'), (';', ':'), ('ni', 'CC'), ('number', 'NN'), ('data', 'NNS'), ('ith', 'VBP'), ('cluster', 'NN'), (';', ':'), ('xij', 'CC'), ('jth', 'NN'), ('datum', 'NN'), ('ith', 'NN'), ('cluster', 'NN'), (';', ':'), ('ci', 'JJ'), ('mean', 'NN'), ('ith', 'NN'), ('cluster', 'NN'), (';', ':'), ('n', 'CC'), ('=', 'VB')]

>> Noun Phrases are: 
 ['k number clusters', 'user', 'number data', 'cluster', 'jth datum ith cluster', 'ci mean ith cluster']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('k', 'k'), ('number', 'number'), ('clusters', 'cluster'), ('typically', 'typic'), ('given', 'given'), ('user', 'user'), (';', ';'), ('ni', 'ni'), ('number', 'number'), ('data', 'data'), ('ith', 'ith'), ('cluster', 'cluster'), (';', ';'), ('xij', 'xij'), ('jth', 'jth'), ('datum', 'datum'), ('ith', 'ith'), ('cluster', 'cluster'), (';', ';'), ('ci', 'ci'), ('mean', 'mean'), ('ith', 'ith'), ('cluster', 'cluster'), (';', ';'), ('n', 'n'), ('=', '=')]

>> Stemming using Snowball Stemmer: 
 [('k', 'k'), ('number', 'number'), ('clusters', 'cluster'), ('typically', 'typic'), ('given', 'given'), ('user', 'user'), (';', ';'), ('ni', 'ni'), ('number', 'number'), ('data', 'data'), ('ith', 'ith'), ('cluster', 'cluster'), (';', ';'), ('xij', 'xij'), ('jth', 'jth'), ('datum', 'datum'), ('ith', 'ith'), ('cluster', 'cluster'), (';', ';'), ('ci', 'ci'), ('mean', 'mean'), ('ith', 'ith'), ('cluster', 'cluster'), (';', ';'), ('n', 'n'), ('=', '=')]

>> Lemmatization: 
 [('k', 'k'), ('number', 'number'), ('clusters', 'cluster'), ('typically', 'typically'), ('given', 'given'), ('user', 'user'), (';', ';'), ('ni', 'ni'), ('number', 'number'), ('data', 'data'), ('ith', 'ith'), ('cluster', 'cluster'), (';', ';'), ('xij', 'xij'), ('jth', 'jth'), ('datum', 'datum'), ('ith', 'ith'), ('cluster', 'cluster'), (';', ';'), ('ci', 'ci'), ('mean', 'mean'), ('ith', 'ith'), ('cluster', 'cluster'), (';', ';'), ('n', 'n'), ('=', '=')]



========================================== PARAGRAPH 94 ===========================================

∑k i=1 ni is the number of data. The most commonly used distance measure for  

------------------- Sentence 1 -------------------

∑k i=1 ni is the number of data.

>> Tokens are: 
 ['∑k', 'i=1', 'ni', 'number', 'data', '.']

>> Bigrams are: 
 [('∑k', 'i=1'), ('i=1', 'ni'), ('ni', 'number'), ('number', 'data'), ('data', '.')]

>> Trigrams are: 
 [('∑k', 'i=1', 'ni'), ('i=1', 'ni', 'number'), ('ni', 'number', 'data'), ('number', 'data', '.')]

>> POS Tags are: 
 [('∑k', 'JJ'), ('i=1', 'NN'), ('ni', 'JJ'), ('number', 'NN'), ('data', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['∑k i=1', 'ni number data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('∑k', '∑k'), ('i=1', 'i=1'), ('ni', 'ni'), ('number', 'number'), ('data', 'data'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('∑k', '∑k'), ('i=1', 'i=1'), ('ni', 'ni'), ('number', 'number'), ('data', 'data'), ('.', '.')]

>> Lemmatization: 
 [('∑k', '∑k'), ('i=1', 'i=1'), ('ni', 'ni'), ('number', 'number'), ('data', 'data'), ('.', '.')]


------------------- Sentence 2 -------------------

The most commonly used distance measure for

>> Tokens are: 
 ['The', 'commonly', 'used', 'distance', 'measure']

>> Bigrams are: 
 [('The', 'commonly'), ('commonly', 'used'), ('used', 'distance'), ('distance', 'measure')]

>> Trigrams are: 
 [('The', 'commonly', 'used'), ('commonly', 'used', 'distance'), ('used', 'distance', 'measure')]

>> POS Tags are: 
 [('The', 'DT'), ('commonly', 'NN'), ('used', 'VBN'), ('distance', 'NN'), ('measure', 'NN')]

>> Noun Phrases are: 
 ['The commonly', 'distance measure']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('commonly', 'commonli'), ('used', 'use'), ('distance', 'distanc'), ('measure', 'measur')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('commonly', 'common'), ('used', 'use'), ('distance', 'distanc'), ('measure', 'measur')]

>> Lemmatization: 
 [('The', 'The'), ('commonly', 'commonly'), ('used', 'used'), ('distance', 'distance'), ('measure', 'measure')]



========================================== PARAGRAPH 95 ===========================================

the data mining problem is the Euclidean distance, which is defined as 

------------------- Sentence 1 -------------------

the data mining problem is the Euclidean distance, which is defined as

>> Tokens are: 
 ['data', 'mining', 'problem', 'Euclidean', 'distance', ',', 'defined']

>> Bigrams are: 
 [('data', 'mining'), ('mining', 'problem'), ('problem', 'Euclidean'), ('Euclidean', 'distance'), ('distance', ','), (',', 'defined')]

>> Trigrams are: 
 [('data', 'mining', 'problem'), ('mining', 'problem', 'Euclidean'), ('problem', 'Euclidean', 'distance'), ('Euclidean', 'distance', ','), ('distance', ',', 'defined')]

>> POS Tags are: 
 [('data', 'NNS'), ('mining', 'NN'), ('problem', 'NN'), ('Euclidean', 'NNP'), ('distance', 'NN'), (',', ','), ('defined', 'VBD')]

>> Noun Phrases are: 
 ['data mining problem Euclidean distance']

>> Named Entities are: 
 [('LOCATION', 'Euclidean')] 

>> Stemming using Porter Stemmer: 
 [('data', 'data'), ('mining', 'mine'), ('problem', 'problem'), ('Euclidean', 'euclidean'), ('distance', 'distanc'), (',', ','), ('defined', 'defin')]

>> Stemming using Snowball Stemmer: 
 [('data', 'data'), ('mining', 'mine'), ('problem', 'problem'), ('Euclidean', 'euclidean'), ('distance', 'distanc'), (',', ','), ('defined', 'defin')]

>> Lemmatization: 
 [('data', 'data'), ('mining', 'mining'), ('problem', 'problem'), ('Euclidean', 'Euclidean'), ('distance', 'distance'), (',', ','), ('defined', 'defined')]



========================================== PARAGRAPH 96 ===========================================

where pi and pj are the positions of two different data. For solving different data min- ing problems, the distance measurement D(pi, pj) can be the Manhattan distance, the  Minkowski distance, or even the cosine similarity [36] between two different documents. 

------------------- Sentence 1 -------------------

where pi and pj are the positions of two different data.

>> Tokens are: 
 ['pi', 'pj', 'positions', 'two', 'different', 'data', '.']

>> Bigrams are: 
 [('pi', 'pj'), ('pj', 'positions'), ('positions', 'two'), ('two', 'different'), ('different', 'data'), ('data', '.')]

>> Trigrams are: 
 [('pi', 'pj', 'positions'), ('pj', 'positions', 'two'), ('positions', 'two', 'different'), ('two', 'different', 'data'), ('different', 'data', '.')]

>> POS Tags are: 
 [('pi', 'NN'), ('pj', 'NN'), ('positions', 'NNS'), ('two', 'CD'), ('different', 'JJ'), ('data', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['pi pj positions', 'different data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('pi', 'pi'), ('pj', 'pj'), ('positions', 'posit'), ('two', 'two'), ('different', 'differ'), ('data', 'data'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('pi', 'pi'), ('pj', 'pj'), ('positions', 'posit'), ('two', 'two'), ('different', 'differ'), ('data', 'data'), ('.', '.')]

>> Lemmatization: 
 [('pi', 'pi'), ('pj', 'pj'), ('positions', 'position'), ('two', 'two'), ('different', 'different'), ('data', 'data'), ('.', '.')]


------------------- Sentence 2 -------------------

For solving different data min- ing problems, the distance measurement D(pi, pj) can be the Manhattan distance, the  Minkowski distance, or even the cosine similarity [36] between two different documents.

>> Tokens are: 
 ['For', 'solving', 'different', 'data', 'min-', 'ing', 'problems', ',', 'distance', 'measurement', 'D', '(', 'pi', ',', 'pj', ')', 'Manhattan', 'distance', ',', 'Minkowski', 'distance', ',', 'even', 'cosine', 'similarity', '[', '36', ']', 'two', 'different', 'documents', '.']

>> Bigrams are: 
 [('For', 'solving'), ('solving', 'different'), ('different', 'data'), ('data', 'min-'), ('min-', 'ing'), ('ing', 'problems'), ('problems', ','), (',', 'distance'), ('distance', 'measurement'), ('measurement', 'D'), ('D', '('), ('(', 'pi'), ('pi', ','), (',', 'pj'), ('pj', ')'), (')', 'Manhattan'), ('Manhattan', 'distance'), ('distance', ','), (',', 'Minkowski'), ('Minkowski', 'distance'), ('distance', ','), (',', 'even'), ('even', 'cosine'), ('cosine', 'similarity'), ('similarity', '['), ('[', '36'), ('36', ']'), (']', 'two'), ('two', 'different'), ('different', 'documents'), ('documents', '.')]

>> Trigrams are: 
 [('For', 'solving', 'different'), ('solving', 'different', 'data'), ('different', 'data', 'min-'), ('data', 'min-', 'ing'), ('min-', 'ing', 'problems'), ('ing', 'problems', ','), ('problems', ',', 'distance'), (',', 'distance', 'measurement'), ('distance', 'measurement', 'D'), ('measurement', 'D', '('), ('D', '(', 'pi'), ('(', 'pi', ','), ('pi', ',', 'pj'), (',', 'pj', ')'), ('pj', ')', 'Manhattan'), (')', 'Manhattan', 'distance'), ('Manhattan', 'distance', ','), ('distance', ',', 'Minkowski'), (',', 'Minkowski', 'distance'), ('Minkowski', 'distance', ','), ('distance', ',', 'even'), (',', 'even', 'cosine'), ('even', 'cosine', 'similarity'), ('cosine', 'similarity', '['), ('similarity', '[', '36'), ('[', '36', ']'), ('36', ']', 'two'), (']', 'two', 'different'), ('two', 'different', 'documents'), ('different', 'documents', '.')]

>> POS Tags are: 
 [('For', 'IN'), ('solving', 'VBG'), ('different', 'JJ'), ('data', 'NNS'), ('min-', 'NNS'), ('ing', 'VBG'), ('problems', 'NNS'), (',', ','), ('distance', 'NN'), ('measurement', 'NN'), ('D', 'NNP'), ('(', '('), ('pi', 'NN'), (',', ','), ('pj', 'NN'), (')', ')'), ('Manhattan', 'NNP'), ('distance', 'NN'), (',', ','), ('Minkowski', 'NNP'), ('distance', 'NN'), (',', ','), ('even', 'RB'), ('cosine', 'VBP'), ('similarity', 'NN'), ('[', 'VBP'), ('36', 'CD'), (']', 'JJ'), ('two', 'CD'), ('different', 'JJ'), ('documents', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['different data min-', 'problems', 'distance measurement D', 'pi', 'pj', 'Manhattan distance', 'Minkowski distance', 'similarity', 'different documents']

>> Named Entities are: 
 [('GPE', 'Manhattan'), ('PERSON', 'Minkowski')] 

>> Stemming using Porter Stemmer: 
 [('For', 'for'), ('solving', 'solv'), ('different', 'differ'), ('data', 'data'), ('min-', 'min-'), ('ing', 'ing'), ('problems', 'problem'), (',', ','), ('distance', 'distanc'), ('measurement', 'measur'), ('D', 'd'), ('(', '('), ('pi', 'pi'), (',', ','), ('pj', 'pj'), (')', ')'), ('Manhattan', 'manhattan'), ('distance', 'distanc'), (',', ','), ('Minkowski', 'minkowski'), ('distance', 'distanc'), (',', ','), ('even', 'even'), ('cosine', 'cosin'), ('similarity', 'similar'), ('[', '['), ('36', '36'), (']', ']'), ('two', 'two'), ('different', 'differ'), ('documents', 'document'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('For', 'for'), ('solving', 'solv'), ('different', 'differ'), ('data', 'data'), ('min-', 'min-'), ('ing', 'ing'), ('problems', 'problem'), (',', ','), ('distance', 'distanc'), ('measurement', 'measur'), ('D', 'd'), ('(', '('), ('pi', 'pi'), (',', ','), ('pj', 'pj'), (')', ')'), ('Manhattan', 'manhattan'), ('distance', 'distanc'), (',', ','), ('Minkowski', 'minkowski'), ('distance', 'distanc'), (',', ','), ('even', 'even'), ('cosine', 'cosin'), ('similarity', 'similar'), ('[', '['), ('36', '36'), (']', ']'), ('two', 'two'), ('different', 'differ'), ('documents', 'document'), ('.', '.')]

>> Lemmatization: 
 [('For', 'For'), ('solving', 'solving'), ('different', 'different'), ('data', 'data'), ('min-', 'min-'), ('ing', 'ing'), ('problems', 'problem'), (',', ','), ('distance', 'distance'), ('measurement', 'measurement'), ('D', 'D'), ('(', '('), ('pi', 'pi'), (',', ','), ('pj', 'pj'), (')', ')'), ('Manhattan', 'Manhattan'), ('distance', 'distance'), (',', ','), ('Minkowski', 'Minkowski'), ('distance', 'distance'), (',', ','), ('even', 'even'), ('cosine', 'cosine'), ('similarity', 'similarity'), ('[', '['), ('36', '36'), (']', ']'), ('two', 'two'), ('different', 'different'), ('documents', 'document'), ('.', '.')]



========================================== PARAGRAPH 97 ===========================================

Accuracy (ACC) is another well-known measurement [37] which is defined as 

------------------- Sentence 1 -------------------

Accuracy (ACC) is another well-known measurement [37] which is defined as

>> Tokens are: 
 ['Accuracy', '(', 'ACC', ')', 'another', 'well-known', 'measurement', '[', '37', ']', 'defined']

>> Bigrams are: 
 [('Accuracy', '('), ('(', 'ACC'), ('ACC', ')'), (')', 'another'), ('another', 'well-known'), ('well-known', 'measurement'), ('measurement', '['), ('[', '37'), ('37', ']'), (']', 'defined')]

>> Trigrams are: 
 [('Accuracy', '(', 'ACC'), ('(', 'ACC', ')'), ('ACC', ')', 'another'), (')', 'another', 'well-known'), ('another', 'well-known', 'measurement'), ('well-known', 'measurement', '['), ('measurement', '[', '37'), ('[', '37', ']'), ('37', ']', 'defined')]

>> POS Tags are: 
 [('Accuracy', 'NNP'), ('(', '('), ('ACC', 'NNP'), (')', ')'), ('another', 'DT'), ('well-known', 'JJ'), ('measurement', 'NN'), ('[', '$'), ('37', 'CD'), (']', 'NN'), ('defined', 'VBD')]

>> Noun Phrases are: 
 ['Accuracy', 'ACC', 'another well-known measurement', ']']

>> Named Entities are: 
 [('GPE', 'Accuracy'), ('ORGANIZATION', 'ACC')] 

>> Stemming using Porter Stemmer: 
 [('Accuracy', 'accuraci'), ('(', '('), ('ACC', 'acc'), (')', ')'), ('another', 'anoth'), ('well-known', 'well-known'), ('measurement', 'measur'), ('[', '['), ('37', '37'), (']', ']'), ('defined', 'defin')]

>> Stemming using Snowball Stemmer: 
 [('Accuracy', 'accuraci'), ('(', '('), ('ACC', 'acc'), (')', ')'), ('another', 'anoth'), ('well-known', 'well-known'), ('measurement', 'measur'), ('[', '['), ('37', '37'), (']', ']'), ('defined', 'defin')]

>> Lemmatization: 
 [('Accuracy', 'Accuracy'), ('(', '('), ('ACC', 'ACC'), (')', ')'), ('another', 'another'), ('well-known', 'well-known'), ('measurement', 'measurement'), ('[', '['), ('37', '37'), (']', ']'), ('defined', 'defined')]



========================================== PARAGRAPH 98 ===========================================

To evaluate the classification results, precision (p), recall (r), and F-measure can be used  to measure how many data that do not belong to group A are incorrectly classified into  group A; and how many data that belong to group A are not classified into group A. A  simple confusion matrix of a classifier [37] as given in Table 1 can be used to cover all  the situations of the classification results. In Table 1, TP and TN indicate the numbers  of positive examples and negative examples that are correctly classified, respectively; FN  and FP indicate the numbers of positive examples and negative examples that are incor- rectly classified, respectively. With the confusion matrix at hand, it is much easier to  describe the meaning of precision (p), which is defined as 

------------------- Sentence 1 -------------------

To evaluate the classification results, precision (p), recall (r), and F-measure can be used  to measure how many data that do not belong to group A are incorrectly classified into  group A; and how many data that belong to group A are not classified into group A.

>> Tokens are: 
 ['To', 'evaluate', 'classification', 'results', ',', 'precision', '(', 'p', ')', ',', 'recall', '(', 'r', ')', ',', 'F-measure', 'used', 'measure', 'many', 'data', 'belong', 'group', 'A', 'incorrectly', 'classified', 'group', 'A', ';', 'many', 'data', 'belong', 'group', 'A', 'classified', 'group', 'A', '.']

>> Bigrams are: 
 [('To', 'evaluate'), ('evaluate', 'classification'), ('classification', 'results'), ('results', ','), (',', 'precision'), ('precision', '('), ('(', 'p'), ('p', ')'), (')', ','), (',', 'recall'), ('recall', '('), ('(', 'r'), ('r', ')'), (')', ','), (',', 'F-measure'), ('F-measure', 'used'), ('used', 'measure'), ('measure', 'many'), ('many', 'data'), ('data', 'belong'), ('belong', 'group'), ('group', 'A'), ('A', 'incorrectly'), ('incorrectly', 'classified'), ('classified', 'group'), ('group', 'A'), ('A', ';'), (';', 'many'), ('many', 'data'), ('data', 'belong'), ('belong', 'group'), ('group', 'A'), ('A', 'classified'), ('classified', 'group'), ('group', 'A'), ('A', '.')]

>> Trigrams are: 
 [('To', 'evaluate', 'classification'), ('evaluate', 'classification', 'results'), ('classification', 'results', ','), ('results', ',', 'precision'), (',', 'precision', '('), ('precision', '(', 'p'), ('(', 'p', ')'), ('p', ')', ','), (')', ',', 'recall'), (',', 'recall', '('), ('recall', '(', 'r'), ('(', 'r', ')'), ('r', ')', ','), (')', ',', 'F-measure'), (',', 'F-measure', 'used'), ('F-measure', 'used', 'measure'), ('used', 'measure', 'many'), ('measure', 'many', 'data'), ('many', 'data', 'belong'), ('data', 'belong', 'group'), ('belong', 'group', 'A'), ('group', 'A', 'incorrectly'), ('A', 'incorrectly', 'classified'), ('incorrectly', 'classified', 'group'), ('classified', 'group', 'A'), ('group', 'A', ';'), ('A', ';', 'many'), (';', 'many', 'data'), ('many', 'data', 'belong'), ('data', 'belong', 'group'), ('belong', 'group', 'A'), ('group', 'A', 'classified'), ('A', 'classified', 'group'), ('classified', 'group', 'A'), ('group', 'A', '.')]

>> POS Tags are: 
 [('To', 'TO'), ('evaluate', 'VB'), ('classification', 'NN'), ('results', 'NNS'), (',', ','), ('precision', 'NN'), ('(', '('), ('p', 'NN'), (')', ')'), (',', ','), ('recall', 'NN'), ('(', '('), ('r', 'NN'), (')', ')'), (',', ','), ('F-measure', 'NNP'), ('used', 'VBD'), ('measure', 'NN'), ('many', 'JJ'), ('data', 'NNS'), ('belong', 'NNS'), ('group', 'NN'), ('A', 'NNP'), ('incorrectly', 'RB'), ('classified', 'VBD'), ('group', 'NN'), ('A', 'NNP'), (';', ':'), ('many', 'JJ'), ('data', 'NNS'), ('belong', 'NNS'), ('group', 'NN'), ('A', 'NNP'), ('classified', 'VBD'), ('group', 'NN'), ('A', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['classification results', 'precision', 'p', 'recall', 'r', 'F-measure', 'measure', 'many data belong group A', 'group A', 'many data belong group A', 'group A']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('To', 'to'), ('evaluate', 'evalu'), ('classification', 'classif'), ('results', 'result'), (',', ','), ('precision', 'precis'), ('(', '('), ('p', 'p'), (')', ')'), (',', ','), ('recall', 'recal'), ('(', '('), ('r', 'r'), (')', ')'), (',', ','), ('F-measure', 'f-measur'), ('used', 'use'), ('measure', 'measur'), ('many', 'mani'), ('data', 'data'), ('belong', 'belong'), ('group', 'group'), ('A', 'a'), ('incorrectly', 'incorrectli'), ('classified', 'classifi'), ('group', 'group'), ('A', 'a'), (';', ';'), ('many', 'mani'), ('data', 'data'), ('belong', 'belong'), ('group', 'group'), ('A', 'a'), ('classified', 'classifi'), ('group', 'group'), ('A', 'a'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('To', 'to'), ('evaluate', 'evalu'), ('classification', 'classif'), ('results', 'result'), (',', ','), ('precision', 'precis'), ('(', '('), ('p', 'p'), (')', ')'), (',', ','), ('recall', 'recal'), ('(', '('), ('r', 'r'), (')', ')'), (',', ','), ('F-measure', 'f-measur'), ('used', 'use'), ('measure', 'measur'), ('many', 'mani'), ('data', 'data'), ('belong', 'belong'), ('group', 'group'), ('A', 'a'), ('incorrectly', 'incorrect'), ('classified', 'classifi'), ('group', 'group'), ('A', 'a'), (';', ';'), ('many', 'mani'), ('data', 'data'), ('belong', 'belong'), ('group', 'group'), ('A', 'a'), ('classified', 'classifi'), ('group', 'group'), ('A', 'a'), ('.', '.')]

>> Lemmatization: 
 [('To', 'To'), ('evaluate', 'evaluate'), ('classification', 'classification'), ('results', 'result'), (',', ','), ('precision', 'precision'), ('(', '('), ('p', 'p'), (')', ')'), (',', ','), ('recall', 'recall'), ('(', '('), ('r', 'r'), (')', ')'), (',', ','), ('F-measure', 'F-measure'), ('used', 'used'), ('measure', 'measure'), ('many', 'many'), ('data', 'data'), ('belong', 'belong'), ('group', 'group'), ('A', 'A'), ('incorrectly', 'incorrectly'), ('classified', 'classified'), ('group', 'group'), ('A', 'A'), (';', ';'), ('many', 'many'), ('data', 'data'), ('belong', 'belong'), ('group', 'group'), ('A', 'A'), ('classified', 'classified'), ('group', 'group'), ('A', 'A'), ('.', '.')]


------------------- Sentence 2 -------------------

A  simple confusion matrix of a classifier [37] as given in Table 1 can be used to cover all  the situations of the classification results.

>> Tokens are: 
 ['A', 'simple', 'confusion', 'matrix', 'classifier', '[', '37', ']', 'given', 'Table', '1', 'used', 'cover', 'situations', 'classification', 'results', '.']

>> Bigrams are: 
 [('A', 'simple'), ('simple', 'confusion'), ('confusion', 'matrix'), ('matrix', 'classifier'), ('classifier', '['), ('[', '37'), ('37', ']'), (']', 'given'), ('given', 'Table'), ('Table', '1'), ('1', 'used'), ('used', 'cover'), ('cover', 'situations'), ('situations', 'classification'), ('classification', 'results'), ('results', '.')]

>> Trigrams are: 
 [('A', 'simple', 'confusion'), ('simple', 'confusion', 'matrix'), ('confusion', 'matrix', 'classifier'), ('matrix', 'classifier', '['), ('classifier', '[', '37'), ('[', '37', ']'), ('37', ']', 'given'), (']', 'given', 'Table'), ('given', 'Table', '1'), ('Table', '1', 'used'), ('1', 'used', 'cover'), ('used', 'cover', 'situations'), ('cover', 'situations', 'classification'), ('situations', 'classification', 'results'), ('classification', 'results', '.')]

>> POS Tags are: 
 [('A', 'DT'), ('simple', 'JJ'), ('confusion', 'NN'), ('matrix', 'NNS'), ('classifier', 'VBP'), ('[', '$'), ('37', 'CD'), (']', 'NNP'), ('given', 'VBN'), ('Table', 'NNP'), ('1', 'CD'), ('used', 'VBD'), ('cover', 'NN'), ('situations', 'NNS'), ('classification', 'NN'), ('results', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['A simple confusion matrix', ']', 'Table', 'cover situations classification results']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('A', 'a'), ('simple', 'simpl'), ('confusion', 'confus'), ('matrix', 'matrix'), ('classifier', 'classifi'), ('[', '['), ('37', '37'), (']', ']'), ('given', 'given'), ('Table', 'tabl'), ('1', '1'), ('used', 'use'), ('cover', 'cover'), ('situations', 'situat'), ('classification', 'classif'), ('results', 'result'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('A', 'a'), ('simple', 'simpl'), ('confusion', 'confus'), ('matrix', 'matrix'), ('classifier', 'classifi'), ('[', '['), ('37', '37'), (']', ']'), ('given', 'given'), ('Table', 'tabl'), ('1', '1'), ('used', 'use'), ('cover', 'cover'), ('situations', 'situat'), ('classification', 'classif'), ('results', 'result'), ('.', '.')]

>> Lemmatization: 
 [('A', 'A'), ('simple', 'simple'), ('confusion', 'confusion'), ('matrix', 'matrix'), ('classifier', 'classifier'), ('[', '['), ('37', '37'), (']', ']'), ('given', 'given'), ('Table', 'Table'), ('1', '1'), ('used', 'used'), ('cover', 'cover'), ('situations', 'situation'), ('classification', 'classification'), ('results', 'result'), ('.', '.')]


------------------- Sentence 3 -------------------

In Table 1, TP and TN indicate the numbers  of positive examples and negative examples that are correctly classified, respectively; FN  and FP indicate the numbers of positive examples and negative examples that are incor- rectly classified, respectively.

>> Tokens are: 
 ['In', 'Table', '1', ',', 'TP', 'TN', 'indicate', 'numbers', 'positive', 'examples', 'negative', 'examples', 'correctly', 'classified', ',', 'respectively', ';', 'FN', 'FP', 'indicate', 'numbers', 'positive', 'examples', 'negative', 'examples', 'incor-', 'rectly', 'classified', ',', 'respectively', '.']

>> Bigrams are: 
 [('In', 'Table'), ('Table', '1'), ('1', ','), (',', 'TP'), ('TP', 'TN'), ('TN', 'indicate'), ('indicate', 'numbers'), ('numbers', 'positive'), ('positive', 'examples'), ('examples', 'negative'), ('negative', 'examples'), ('examples', 'correctly'), ('correctly', 'classified'), ('classified', ','), (',', 'respectively'), ('respectively', ';'), (';', 'FN'), ('FN', 'FP'), ('FP', 'indicate'), ('indicate', 'numbers'), ('numbers', 'positive'), ('positive', 'examples'), ('examples', 'negative'), ('negative', 'examples'), ('examples', 'incor-'), ('incor-', 'rectly'), ('rectly', 'classified'), ('classified', ','), (',', 'respectively'), ('respectively', '.')]

>> Trigrams are: 
 [('In', 'Table', '1'), ('Table', '1', ','), ('1', ',', 'TP'), (',', 'TP', 'TN'), ('TP', 'TN', 'indicate'), ('TN', 'indicate', 'numbers'), ('indicate', 'numbers', 'positive'), ('numbers', 'positive', 'examples'), ('positive', 'examples', 'negative'), ('examples', 'negative', 'examples'), ('negative', 'examples', 'correctly'), ('examples', 'correctly', 'classified'), ('correctly', 'classified', ','), ('classified', ',', 'respectively'), (',', 'respectively', ';'), ('respectively', ';', 'FN'), (';', 'FN', 'FP'), ('FN', 'FP', 'indicate'), ('FP', 'indicate', 'numbers'), ('indicate', 'numbers', 'positive'), ('numbers', 'positive', 'examples'), ('positive', 'examples', 'negative'), ('examples', 'negative', 'examples'), ('negative', 'examples', 'incor-'), ('examples', 'incor-', 'rectly'), ('incor-', 'rectly', 'classified'), ('rectly', 'classified', ','), ('classified', ',', 'respectively'), (',', 'respectively', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('Table', 'NNP'), ('1', 'CD'), (',', ','), ('TP', 'NNP'), ('TN', 'NNP'), ('indicate', 'VBP'), ('numbers', 'NNS'), ('positive', 'JJ'), ('examples', 'NNS'), ('negative', 'JJ'), ('examples', 'NNS'), ('correctly', 'RB'), ('classified', 'VBD'), (',', ','), ('respectively', 'RB'), (';', ':'), ('FN', 'NNP'), ('FP', 'NNP'), ('indicate', 'VBP'), ('numbers', 'NNS'), ('positive', 'JJ'), ('examples', 'NNS'), ('negative', 'JJ'), ('examples', 'NNS'), ('incor-', 'RB'), ('rectly', 'RB'), ('classified', 'VBN'), (',', ','), ('respectively', 'RB'), ('.', '.')]

>> Noun Phrases are: 
 ['Table', 'TP TN', 'numbers', 'positive examples', 'negative examples', 'FN FP', 'numbers', 'positive examples', 'negative examples']

>> Named Entities are: 
 [('ORGANIZATION', 'TP'), ('ORGANIZATION', 'FN')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('Table', 'tabl'), ('1', '1'), (',', ','), ('TP', 'tp'), ('TN', 'tn'), ('indicate', 'indic'), ('numbers', 'number'), ('positive', 'posit'), ('examples', 'exampl'), ('negative', 'neg'), ('examples', 'exampl'), ('correctly', 'correctli'), ('classified', 'classifi'), (',', ','), ('respectively', 'respect'), (';', ';'), ('FN', 'fn'), ('FP', 'fp'), ('indicate', 'indic'), ('numbers', 'number'), ('positive', 'posit'), ('examples', 'exampl'), ('negative', 'neg'), ('examples', 'exampl'), ('incor-', 'incor-'), ('rectly', 'rectli'), ('classified', 'classifi'), (',', ','), ('respectively', 'respect'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('Table', 'tabl'), ('1', '1'), (',', ','), ('TP', 'tp'), ('TN', 'tn'), ('indicate', 'indic'), ('numbers', 'number'), ('positive', 'posit'), ('examples', 'exampl'), ('negative', 'negat'), ('examples', 'exampl'), ('correctly', 'correct'), ('classified', 'classifi'), (',', ','), ('respectively', 'respect'), (';', ';'), ('FN', 'fn'), ('FP', 'fp'), ('indicate', 'indic'), ('numbers', 'number'), ('positive', 'posit'), ('examples', 'exampl'), ('negative', 'negat'), ('examples', 'exampl'), ('incor-', 'incor-'), ('rectly', 'rect'), ('classified', 'classifi'), (',', ','), ('respectively', 'respect'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('Table', 'Table'), ('1', '1'), (',', ','), ('TP', 'TP'), ('TN', 'TN'), ('indicate', 'indicate'), ('numbers', 'number'), ('positive', 'positive'), ('examples', 'example'), ('negative', 'negative'), ('examples', 'example'), ('correctly', 'correctly'), ('classified', 'classified'), (',', ','), ('respectively', 'respectively'), (';', ';'), ('FN', 'FN'), ('FP', 'FP'), ('indicate', 'indicate'), ('numbers', 'number'), ('positive', 'positive'), ('examples', 'example'), ('negative', 'negative'), ('examples', 'example'), ('incor-', 'incor-'), ('rectly', 'rectly'), ('classified', 'classified'), (',', ','), ('respectively', 'respectively'), ('.', '.')]


------------------- Sentence 4 -------------------

With the confusion matrix at hand, it is much easier to  describe the meaning of precision (p), which is defined as

>> Tokens are: 
 ['With', 'confusion', 'matrix', 'hand', ',', 'much', 'easier', 'describe', 'meaning', 'precision', '(', 'p', ')', ',', 'defined']

>> Bigrams are: 
 [('With', 'confusion'), ('confusion', 'matrix'), ('matrix', 'hand'), ('hand', ','), (',', 'much'), ('much', 'easier'), ('easier', 'describe'), ('describe', 'meaning'), ('meaning', 'precision'), ('precision', '('), ('(', 'p'), ('p', ')'), (')', ','), (',', 'defined')]

>> Trigrams are: 
 [('With', 'confusion', 'matrix'), ('confusion', 'matrix', 'hand'), ('matrix', 'hand', ','), ('hand', ',', 'much'), (',', 'much', 'easier'), ('much', 'easier', 'describe'), ('easier', 'describe', 'meaning'), ('describe', 'meaning', 'precision'), ('meaning', 'precision', '('), ('precision', '(', 'p'), ('(', 'p', ')'), ('p', ')', ','), (')', ',', 'defined')]

>> POS Tags are: 
 [('With', 'IN'), ('confusion', 'NN'), ('matrix', 'NN'), ('hand', 'NN'), (',', ','), ('much', 'RB'), ('easier', 'JJR'), ('describe', 'JJ'), ('meaning', 'NN'), ('precision', 'NN'), ('(', '('), ('p', 'NN'), (')', ')'), (',', ','), ('defined', 'VBD')]

>> Noun Phrases are: 
 ['confusion matrix hand', 'describe meaning precision', 'p']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('With', 'with'), ('confusion', 'confus'), ('matrix', 'matrix'), ('hand', 'hand'), (',', ','), ('much', 'much'), ('easier', 'easier'), ('describe', 'describ'), ('meaning', 'mean'), ('precision', 'precis'), ('(', '('), ('p', 'p'), (')', ')'), (',', ','), ('defined', 'defin')]

>> Stemming using Snowball Stemmer: 
 [('With', 'with'), ('confusion', 'confus'), ('matrix', 'matrix'), ('hand', 'hand'), (',', ','), ('much', 'much'), ('easier', 'easier'), ('describe', 'describ'), ('meaning', 'mean'), ('precision', 'precis'), ('(', '('), ('p', 'p'), (')', ')'), (',', ','), ('defined', 'defin')]

>> Lemmatization: 
 [('With', 'With'), ('confusion', 'confusion'), ('matrix', 'matrix'), ('hand', 'hand'), (',', ','), ('much', 'much'), ('easier', 'easier'), ('describe', 'describe'), ('meaning', 'meaning'), ('precision', 'precision'), ('(', '('), ('p', 'p'), (')', ')'), (',', ','), ('defined', 'defined')]



========================================== PARAGRAPH 99 ===========================================

and the meaning of recall (r), which is defined as 

------------------- Sentence 1 -------------------

and the meaning of recall (r), which is defined as

>> Tokens are: 
 ['meaning', 'recall', '(', 'r', ')', ',', 'defined']

>> Bigrams are: 
 [('meaning', 'recall'), ('recall', '('), ('(', 'r'), ('r', ')'), (')', ','), (',', 'defined')]

>> Trigrams are: 
 [('meaning', 'recall', '('), ('recall', '(', 'r'), ('(', 'r', ')'), ('r', ')', ','), (')', ',', 'defined')]

>> POS Tags are: 
 [('meaning', 'VBG'), ('recall', 'NN'), ('(', '('), ('r', 'NN'), (')', ')'), (',', ','), ('defined', 'VBD')]

>> Noun Phrases are: 
 ['recall', 'r']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('meaning', 'mean'), ('recall', 'recal'), ('(', '('), ('r', 'r'), (')', ')'), (',', ','), ('defined', 'defin')]

>> Stemming using Snowball Stemmer: 
 [('meaning', 'mean'), ('recall', 'recal'), ('(', '('), ('r', 'r'), (')', ')'), (',', ','), ('defined', 'defin')]

>> Lemmatization: 
 [('meaning', 'meaning'), ('recall', 'recall'), ('(', '('), ('r', 'r'), (')', ')'), (',', ','), ('defined', 'defined')]



========================================== PARAGRAPH 100 ===========================================

(1)SSE = k 

------------------- Sentence 1 -------------------

(1)SSE = k

>> Tokens are: 
 ['(', '1', ')', 'SSE', '=', 'k']

>> Bigrams are: 
 [('(', '1'), ('1', ')'), (')', 'SSE'), ('SSE', '='), ('=', 'k')]

>> Trigrams are: 
 [('(', '1', ')'), ('1', ')', 'SSE'), (')', 'SSE', '='), ('SSE', '=', 'k')]

>> POS Tags are: 
 [('(', '('), ('1', 'CD'), (')', ')'), ('SSE', 'NNP'), ('=', 'NNP'), ('k', 'NN')]

>> Noun Phrases are: 
 ['SSE = k']

>> Named Entities are: 
 [('ORGANIZATION', 'SSE')] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('1', '1'), (')', ')'), ('SSE', 'sse'), ('=', '='), ('k', 'k')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('1', '1'), (')', ')'), ('SSE', 'sse'), ('=', '='), ('k', 'k')]

>> Lemmatization: 
 [('(', '('), ('1', '1'), (')', ')'), ('SSE', 'SSE'), ('=', '='), ('k', 'k')]



========================================== PARAGRAPH 101 ===========================================

∑ 

------------------- Sentence 1 -------------------

∑

>> Tokens are: 
 ['∑']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('∑', 'NN')]

>> Noun Phrases are: 
 ['∑']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('∑', '∑')]

>> Stemming using Snowball Stemmer: 
 [('∑', '∑')]

>> Lemmatization: 
 [('∑', '∑')]



========================================== PARAGRAPH 102 ===========================================

i=1 

------------------- Sentence 1 -------------------

i=1

>> Tokens are: 
 ['i=1']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('i=1', 'NN')]

>> Noun Phrases are: 
 ['i=1']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('i=1', 'i=1')]

>> Stemming using Snowball Stemmer: 
 [('i=1', 'i=1')]

>> Lemmatization: 
 [('i=1', 'i=1')]



========================================== PARAGRAPH 103 ===========================================

ni ∑ 

------------------- Sentence 1 -------------------

ni ∑

>> Tokens are: 
 ['ni', '∑']

>> Bigrams are: 
 [('ni', '∑')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('ni', 'NNS'), ('∑', 'VBP')]

>> Noun Phrases are: 
 ['ni']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('ni', 'ni'), ('∑', '∑')]

>> Stemming using Snowball Stemmer: 
 [('ni', 'ni'), ('∑', '∑')]

>> Lemmatization: 
 [('ni', 'ni'), ('∑', '∑')]



========================================== PARAGRAPH 104 ===========================================

j=1 

------------------- Sentence 1 -------------------

j=1

>> Tokens are: 
 ['j=1']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('j=1', 'NN')]

>> Noun Phrases are: 
 ['j=1']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('j=1', 'j=1')]

>> Stemming using Snowball Stemmer: 
 [('j=1', 'j=1')]

>> Lemmatization: 
 [('j=1', 'j=1')]



========================================== PARAGRAPH 105 ===========================================

D(xij − ci), 

------------------- Sentence 1 -------------------

D(xij − ci),

>> Tokens are: 
 ['D', '(', 'xij', '−', 'ci', ')', ',']

>> Bigrams are: 
 [('D', '('), ('(', 'xij'), ('xij', '−'), ('−', 'ci'), ('ci', ')'), (')', ',')]

>> Trigrams are: 
 [('D', '(', 'xij'), ('(', 'xij', '−'), ('xij', '−', 'ci'), ('−', 'ci', ')'), ('ci', ')', ',')]

>> POS Tags are: 
 [('D', 'NNP'), ('(', '('), ('xij', 'NNP'), ('−', 'NNP'), ('ci', 'NN'), (')', ')'), (',', ',')]

>> Noun Phrases are: 
 ['D', 'xij − ci']

>> Named Entities are: 
 [('GPE', 'D')] 

>> Stemming using Porter Stemmer: 
 [('D', 'd'), ('(', '('), ('xij', 'xij'), ('−', '−'), ('ci', 'ci'), (')', ')'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('D', 'd'), ('(', '('), ('xij', 'xij'), ('−', '−'), ('ci', 'ci'), (')', ')'), (',', ',')]

>> Lemmatization: 
 [('D', 'D'), ('(', '('), ('xij', 'xij'), ('−', '−'), ('ci', 'ci'), (')', ')'), (',', ',')]



========================================== PARAGRAPH 106 ===========================================

(2) ci = 

------------------- Sentence 1 -------------------

(2) ci =

>> Tokens are: 
 ['(', '2', ')', 'ci', '=']

>> Bigrams are: 
 [('(', '2'), ('2', ')'), (')', 'ci'), ('ci', '=')]

>> Trigrams are: 
 [('(', '2', ')'), ('2', ')', 'ci'), (')', 'ci', '=')]

>> POS Tags are: 
 [('(', '('), ('2', 'CD'), (')', ')'), ('ci', 'NN'), ('=', 'NN')]

>> Noun Phrases are: 
 ['ci =']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('2', '2'), (')', ')'), ('ci', 'ci'), ('=', '=')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('2', '2'), (')', ')'), ('ci', 'ci'), ('=', '=')]

>> Lemmatization: 
 [('(', '('), ('2', '2'), (')', ')'), ('ci', 'ci'), ('=', '=')]



========================================== PARAGRAPH 107 ===========================================

1 

------------------- Sentence 1 -------------------

1

>> Tokens are: 
 ['1']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('1', 'CD')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('1', '1')]

>> Stemming using Snowball Stemmer: 
 [('1', '1')]

>> Lemmatization: 
 [('1', '1')]



========================================== PARAGRAPH 108 ===========================================

ni 

------------------- Sentence 1 -------------------

ni

>> Tokens are: 
 ['ni']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('ni', 'NN')]

>> Noun Phrases are: 
 ['ni']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('ni', 'ni')]

>> Stemming using Snowball Stemmer: 
 [('ni', 'ni')]

>> Lemmatization: 
 [('ni', 'ni')]



========================================== PARAGRAPH 109 ===========================================

ni ∑ 

------------------- Sentence 1 -------------------

ni ∑

>> Tokens are: 
 ['ni', '∑']

>> Bigrams are: 
 [('ni', '∑')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('ni', 'NNS'), ('∑', 'VBP')]

>> Noun Phrases are: 
 ['ni']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('ni', 'ni'), ('∑', '∑')]

>> Stemming using Snowball Stemmer: 
 [('ni', 'ni'), ('∑', '∑')]

>> Lemmatization: 
 [('ni', 'ni'), ('∑', '∑')]



========================================== PARAGRAPH 110 ===========================================

j=1 

------------------- Sentence 1 -------------------

j=1

>> Tokens are: 
 ['j=1']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('j=1', 'NN')]

>> Noun Phrases are: 
 ['j=1']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('j=1', 'j=1')]

>> Stemming using Snowball Stemmer: 
 [('j=1', 'j=1')]

>> Lemmatization: 
 [('j=1', 'j=1')]



========================================== PARAGRAPH 111 ===========================================

xij , 

------------------- Sentence 1 -------------------

xij ,

>> Tokens are: 
 ['xij', ',']

>> Bigrams are: 
 [('xij', ',')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('xij', 'NN'), (',', ',')]

>> Noun Phrases are: 
 ['xij']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('xij', 'xij'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('xij', 'xij'), (',', ',')]

>> Lemmatization: 
 [('xij', 'xij'), (',', ',')]



========================================== PARAGRAPH 112 ===========================================

(3)D(pi, pj) = 

------------------- Sentence 1 -------------------

(3)D(pi, pj) =

>> Tokens are: 
 ['(', '3', ')', 'D', '(', 'pi', ',', 'pj', ')', '=']

>> Bigrams are: 
 [('(', '3'), ('3', ')'), (')', 'D'), ('D', '('), ('(', 'pi'), ('pi', ','), (',', 'pj'), ('pj', ')'), (')', '=')]

>> Trigrams are: 
 [('(', '3', ')'), ('3', ')', 'D'), (')', 'D', '('), ('D', '(', 'pi'), ('(', 'pi', ','), ('pi', ',', 'pj'), (',', 'pj', ')'), ('pj', ')', '=')]

>> POS Tags are: 
 [('(', '('), ('3', 'CD'), (')', ')'), ('D', 'NNP'), ('(', '('), ('pi', 'NN'), (',', ','), ('pj', 'NN'), (')', ')'), ('=', 'NN')]

>> Noun Phrases are: 
 ['D', 'pi', 'pj', '=']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('3', '3'), (')', ')'), ('D', 'd'), ('(', '('), ('pi', 'pi'), (',', ','), ('pj', 'pj'), (')', ')'), ('=', '=')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('3', '3'), (')', ')'), ('D', 'd'), ('(', '('), ('pi', 'pi'), (',', ','), ('pj', 'pj'), (')', ')'), ('=', '=')]

>> Lemmatization: 
 [('(', '('), ('3', '3'), (')', ')'), ('D', 'D'), ('(', '('), ('pi', 'pi'), (',', ','), ('pj', 'pj'), (')', ')'), ('=', '=')]



========================================== PARAGRAPH 113 ===========================================

( 

------------------- Sentence 1 -------------------

(

>> Tokens are: 
 ['(']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('(', '(')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('(', '(')]

>> Stemming using Snowball Stemmer: 
 [('(', '(')]

>> Lemmatization: 
 [('(', '(')]



========================================== PARAGRAPH 114 ===========================================

d ∑ 

------------------- Sentence 1 -------------------

d ∑

>> Tokens are: 
 ['∑']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('∑', 'NN')]

>> Noun Phrases are: 
 ['∑']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('∑', '∑')]

>> Stemming using Snowball Stemmer: 
 [('∑', '∑')]

>> Lemmatization: 
 [('∑', '∑')]



========================================== PARAGRAPH 115 ===========================================

l=1 

------------------- Sentence 1 -------------------

l=1

>> Tokens are: 
 ['l=1']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('l=1', 'NN')]

>> Noun Phrases are: 
 ['l=1']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('l=1', 'l=1')]

>> Stemming using Snowball Stemmer: 
 [('l=1', 'l=1')]

>> Lemmatization: 
 [('l=1', 'l=1')]



========================================== PARAGRAPH 116 ===========================================

|pil , pjl | 2 

------------------- Sentence 1 -------------------

|pil , pjl | 2

>> Tokens are: 
 ['|pil', ',', 'pjl', '|', '2']

>> Bigrams are: 
 [('|pil', ','), (',', 'pjl'), ('pjl', '|'), ('|', '2')]

>> Trigrams are: 
 [('|pil', ',', 'pjl'), (',', 'pjl', '|'), ('pjl', '|', '2')]

>> POS Tags are: 
 [('|pil', 'NN'), (',', ','), ('pjl', 'NN'), ('|', 'VBD'), ('2', 'CD')]

>> Noun Phrases are: 
 ['|pil', 'pjl']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('|pil', '|pil'), (',', ','), ('pjl', 'pjl'), ('|', '|'), ('2', '2')]

>> Stemming using Snowball Stemmer: 
 [('|pil', '|pil'), (',', ','), ('pjl', 'pjl'), ('|', '|'), ('2', '2')]

>> Lemmatization: 
 [('|pil', '|pil'), (',', ','), ('pjl', 'pjl'), ('|', '|'), ('2', '2')]



========================================== PARAGRAPH 117 ===========================================

)1/2 

------------------- Sentence 1 -------------------

)1/2

>> Tokens are: 
 [')', '1/2']

>> Bigrams are: 
 [(')', '1/2')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [(')', ')'), ('1/2', 'CD')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [(')', ')'), ('1/2', '1/2')]

>> Stemming using Snowball Stemmer: 
 [(')', ')'), ('1/2', '1/2')]

>> Lemmatization: 
 [(')', ')'), ('1/2', '1/2')]



========================================== PARAGRAPH 118 ===========================================

, 

------------------- Sentence 1 -------------------

,

>> Tokens are: 
 [',']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [(',', ',')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [(',', ',')]

>> Stemming using Snowball Stemmer: 
 [(',', ',')]

>> Lemmatization: 
 [(',', ',')]



========================================== PARAGRAPH 119 ===========================================

(4)ACC = Number of cases correctly classified 

------------------- Sentence 1 -------------------

(4)ACC = Number of cases correctly classified

>> Tokens are: 
 ['(', '4', ')', 'ACC', '=', 'Number', 'cases', 'correctly', 'classified']

>> Bigrams are: 
 [('(', '4'), ('4', ')'), (')', 'ACC'), ('ACC', '='), ('=', 'Number'), ('Number', 'cases'), ('cases', 'correctly'), ('correctly', 'classified')]

>> Trigrams are: 
 [('(', '4', ')'), ('4', ')', 'ACC'), (')', 'ACC', '='), ('ACC', '=', 'Number'), ('=', 'Number', 'cases'), ('Number', 'cases', 'correctly'), ('cases', 'correctly', 'classified')]

>> POS Tags are: 
 [('(', '('), ('4', 'CD'), (')', ')'), ('ACC', 'NNP'), ('=', 'NNP'), ('Number', 'NNP'), ('cases', 'NNS'), ('correctly', 'RB'), ('classified', 'VBD')]

>> Noun Phrases are: 
 ['ACC = Number cases']

>> Named Entities are: 
 [('ORGANIZATION', 'ACC')] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('4', '4'), (')', ')'), ('ACC', 'acc'), ('=', '='), ('Number', 'number'), ('cases', 'case'), ('correctly', 'correctli'), ('classified', 'classifi')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('4', '4'), (')', ')'), ('ACC', 'acc'), ('=', '='), ('Number', 'number'), ('cases', 'case'), ('correctly', 'correct'), ('classified', 'classifi')]

>> Lemmatization: 
 [('(', '('), ('4', '4'), (')', ')'), ('ACC', 'ACC'), ('=', '='), ('Number', 'Number'), ('cases', 'case'), ('correctly', 'correctly'), ('classified', 'classified')]



========================================== PARAGRAPH 120 ===========================================

Total number of test cases . 

------------------- Sentence 1 -------------------

Total number of test cases .

>> Tokens are: 
 ['Total', 'number', 'test', 'cases', '.']

>> Bigrams are: 
 [('Total', 'number'), ('number', 'test'), ('test', 'cases'), ('cases', '.')]

>> Trigrams are: 
 [('Total', 'number', 'test'), ('number', 'test', 'cases'), ('test', 'cases', '.')]

>> POS Tags are: 
 [('Total', 'JJ'), ('number', 'NN'), ('test', 'NN'), ('cases', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['Total number test cases']

>> Named Entities are: 
 [('GPE', 'Total')] 

>> Stemming using Porter Stemmer: 
 [('Total', 'total'), ('number', 'number'), ('test', 'test'), ('cases', 'case'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Total', 'total'), ('number', 'number'), ('test', 'test'), ('cases', 'case'), ('.', '.')]

>> Lemmatization: 
 [('Total', 'Total'), ('number', 'number'), ('test', 'test'), ('cases', 'case'), ('.', '.')]



========================================== PARAGRAPH 121 ===========================================

(5)p = TP 

------------------- Sentence 1 -------------------

(5)p = TP

>> Tokens are: 
 ['(', '5', ')', 'p', '=', 'TP']

>> Bigrams are: 
 [('(', '5'), ('5', ')'), (')', 'p'), ('p', '='), ('=', 'TP')]

>> Trigrams are: 
 [('(', '5', ')'), ('5', ')', 'p'), (')', 'p', '='), ('p', '=', 'TP')]

>> POS Tags are: 
 [('(', '('), ('5', 'CD'), (')', ')'), ('p', 'NN'), ('=', 'CD'), ('TP', 'NNP')]

>> Noun Phrases are: 
 ['p', 'TP']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('5', '5'), (')', ')'), ('p', 'p'), ('=', '='), ('TP', 'tp')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('5', '5'), (')', ')'), ('p', 'p'), ('=', '='), ('TP', 'tp')]

>> Lemmatization: 
 [('(', '('), ('5', '5'), (')', ')'), ('p', 'p'), ('=', '='), ('TP', 'TP')]



========================================== PARAGRAPH 122 ===========================================

TP+ FP , 

------------------- Sentence 1 -------------------

TP+ FP ,

>> Tokens are: 
 ['TP+', 'FP', ',']

>> Bigrams are: 
 [('TP+', 'FP'), ('FP', ',')]

>> Trigrams are: 
 [('TP+', 'FP', ',')]

>> POS Tags are: 
 [('TP+', 'NNP'), ('FP', 'NNP'), (',', ',')]

>> Noun Phrases are: 
 ['TP+ FP']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('TP+', 'tp+'), ('FP', 'fp'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('TP+', 'tp+'), ('FP', 'fp'), (',', ',')]

>> Lemmatization: 
 [('TP+', 'TP+'), ('FP', 'FP'), (',', ',')]



========================================== PARAGRAPH 123 ===========================================

(6)r = TP 

------------------- Sentence 1 -------------------

(6)r = TP

>> Tokens are: 
 ['(', '6', ')', 'r', '=', 'TP']

>> Bigrams are: 
 [('(', '6'), ('6', ')'), (')', 'r'), ('r', '='), ('=', 'TP')]

>> Trigrams are: 
 [('(', '6', ')'), ('6', ')', 'r'), (')', 'r', '='), ('r', '=', 'TP')]

>> POS Tags are: 
 [('(', '('), ('6', 'CD'), (')', ')'), ('r', 'NN'), ('=', 'CD'), ('TP', 'NNP')]

>> Noun Phrases are: 
 ['r', 'TP']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('6', '6'), (')', ')'), ('r', 'r'), ('=', '='), ('TP', 'tp')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('6', '6'), (')', ')'), ('r', 'r'), ('=', '='), ('TP', 'tp')]

>> Lemmatization: 
 [('(', '('), ('6', '6'), (')', ')'), ('r', 'r'), ('=', '='), ('TP', 'TP')]



========================================== PARAGRAPH 124 ===========================================

TP+ FN .

------------------- Sentence 1 -------------------

TP+ FN .

>> Tokens are: 
 ['TP+', 'FN', '.']

>> Bigrams are: 
 [('TP+', 'FN'), ('FN', '.')]

>> Trigrams are: 
 [('TP+', 'FN', '.')]

>> POS Tags are: 
 [('TP+', 'NNP'), ('FN', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['TP+ FN']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('TP+', 'tp+'), ('FN', 'fn'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('TP+', 'tp+'), ('FN', 'fn'), ('.', '.')]

>> Lemmatization: 
 [('TP+', 'TP+'), ('FN', 'FN'), ('.', '.')]



========================================== PARAGRAPH 125 ===========================================

Page 7 of 32Tsai et al. Journal of Big Data  (2015) 2:21  

------------------- Sentence 1 -------------------

Page 7 of 32Tsai et al.

>> Tokens are: 
 ['Page', '7', '32Tsai', 'et', 'al', '.']

>> Bigrams are: 
 [('Page', '7'), ('7', '32Tsai'), ('32Tsai', 'et'), ('et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('Page', '7', '32Tsai'), ('7', '32Tsai', 'et'), ('32Tsai', 'et', 'al'), ('et', 'al', '.')]

>> POS Tags are: 
 [('Page', 'NN'), ('7', 'CD'), ('32Tsai', 'CD'), ('et', 'NN'), ('al', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Page', 'et al']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Page', 'page'), ('7', '7'), ('32Tsai', '32tsai'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Page', 'page'), ('7', '7'), ('32Tsai', '32tsai'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('Page', 'Page'), ('7', '7'), ('32Tsai', '32Tsai'), ('et', 'et'), ('al', 'al'), ('.', '.')]


------------------- Sentence 2 -------------------

Journal of Big Data  (2015) 2:21

>> Tokens are: 
 ['Journal', 'Big', 'Data', '(', '2015', ')', '2:21']

>> Bigrams are: 
 [('Journal', 'Big'), ('Big', 'Data'), ('Data', '('), ('(', '2015'), ('2015', ')'), (')', '2:21')]

>> Trigrams are: 
 [('Journal', 'Big', 'Data'), ('Big', 'Data', '('), ('Data', '(', '2015'), ('(', '2015', ')'), ('2015', ')', '2:21')]

>> POS Tags are: 
 [('Journal', 'NNP'), ('Big', 'NNP'), ('Data', 'NNP'), ('(', '('), ('2015', 'CD'), (')', ')'), ('2:21', 'CD')]

>> Noun Phrases are: 
 ['Journal Big Data']

>> Named Entities are: 
 [('PERSON', 'Journal')] 

>> Stemming using Porter Stemmer: 
 [('Journal', 'journal'), ('Big', 'big'), ('Data', 'data'), ('(', '('), ('2015', '2015'), (')', ')'), ('2:21', '2:21')]

>> Stemming using Snowball Stemmer: 
 [('Journal', 'journal'), ('Big', 'big'), ('Data', 'data'), ('(', '('), ('2015', '2015'), (')', ')'), ('2:21', '2:21')]

>> Lemmatization: 
 [('Journal', 'Journal'), ('Big', 'Big'), ('Data', 'Data'), ('(', '('), ('2015', '2015'), (')', ')'), ('2:21', '2:21')]



========================================== PARAGRAPH 126 ===========================================

The F-measure can then be computed as 

------------------- Sentence 1 -------------------

The F-measure can then be computed as

>> Tokens are: 
 ['The', 'F-measure', 'computed']

>> Bigrams are: 
 [('The', 'F-measure'), ('F-measure', 'computed')]

>> Trigrams are: 
 [('The', 'F-measure', 'computed')]

>> POS Tags are: 
 [('The', 'DT'), ('F-measure', 'NN'), ('computed', 'VBD')]

>> Noun Phrases are: 
 ['The F-measure']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('F-measure', 'f-measur'), ('computed', 'comput')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('F-measure', 'f-measur'), ('computed', 'comput')]

>> Lemmatization: 
 [('The', 'The'), ('F-measure', 'F-measure'), ('computed', 'computed')]



========================================== PARAGRAPH 127 ===========================================

In addition to the above-mentioned measurements for evaluating the data mining  results, the computation cost and response time are another two well-known measure- ments. When two different mining algorithms can find the same or similar results, of  course, how fast they can get the final mining results will become the most important  research topic. 

------------------- Sentence 1 -------------------

In addition to the above-mentioned measurements for evaluating the data mining  results, the computation cost and response time are another two well-known measure- ments.

>> Tokens are: 
 ['In', 'addition', 'above-mentioned', 'measurements', 'evaluating', 'data', 'mining', 'results', ',', 'computation', 'cost', 'response', 'time', 'another', 'two', 'well-known', 'measure-', 'ments', '.']

>> Bigrams are: 
 [('In', 'addition'), ('addition', 'above-mentioned'), ('above-mentioned', 'measurements'), ('measurements', 'evaluating'), ('evaluating', 'data'), ('data', 'mining'), ('mining', 'results'), ('results', ','), (',', 'computation'), ('computation', 'cost'), ('cost', 'response'), ('response', 'time'), ('time', 'another'), ('another', 'two'), ('two', 'well-known'), ('well-known', 'measure-'), ('measure-', 'ments'), ('ments', '.')]

>> Trigrams are: 
 [('In', 'addition', 'above-mentioned'), ('addition', 'above-mentioned', 'measurements'), ('above-mentioned', 'measurements', 'evaluating'), ('measurements', 'evaluating', 'data'), ('evaluating', 'data', 'mining'), ('data', 'mining', 'results'), ('mining', 'results', ','), ('results', ',', 'computation'), (',', 'computation', 'cost'), ('computation', 'cost', 'response'), ('cost', 'response', 'time'), ('response', 'time', 'another'), ('time', 'another', 'two'), ('another', 'two', 'well-known'), ('two', 'well-known', 'measure-'), ('well-known', 'measure-', 'ments'), ('measure-', 'ments', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('addition', 'NN'), ('above-mentioned', 'JJ'), ('measurements', 'NNS'), ('evaluating', 'VBG'), ('data', 'NNS'), ('mining', 'NN'), ('results', 'NNS'), (',', ','), ('computation', 'NN'), ('cost', 'NN'), ('response', 'NN'), ('time', 'NN'), ('another', 'DT'), ('two', 'CD'), ('well-known', 'JJ'), ('measure-', 'JJ'), ('ments', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['addition', 'above-mentioned measurements', 'data mining results', 'computation cost response time', 'well-known measure- ments']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('addition', 'addit'), ('above-mentioned', 'above-ment'), ('measurements', 'measur'), ('evaluating', 'evalu'), ('data', 'data'), ('mining', 'mine'), ('results', 'result'), (',', ','), ('computation', 'comput'), ('cost', 'cost'), ('response', 'respons'), ('time', 'time'), ('another', 'anoth'), ('two', 'two'), ('well-known', 'well-known'), ('measure-', 'measure-'), ('ments', 'ment'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('addition', 'addit'), ('above-mentioned', 'above-ment'), ('measurements', 'measur'), ('evaluating', 'evalu'), ('data', 'data'), ('mining', 'mine'), ('results', 'result'), (',', ','), ('computation', 'comput'), ('cost', 'cost'), ('response', 'respons'), ('time', 'time'), ('another', 'anoth'), ('two', 'two'), ('well-known', 'well-known'), ('measure-', 'measure-'), ('ments', 'ment'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('addition', 'addition'), ('above-mentioned', 'above-mentioned'), ('measurements', 'measurement'), ('evaluating', 'evaluating'), ('data', 'data'), ('mining', 'mining'), ('results', 'result'), (',', ','), ('computation', 'computation'), ('cost', 'cost'), ('response', 'response'), ('time', 'time'), ('another', 'another'), ('two', 'two'), ('well-known', 'well-known'), ('measure-', 'measure-'), ('ments', 'ments'), ('.', '.')]


------------------- Sentence 2 -------------------

When two different mining algorithms can find the same or similar results, of  course, how fast they can get the final mining results will become the most important  research topic.

>> Tokens are: 
 ['When', 'two', 'different', 'mining', 'algorithms', 'find', 'similar', 'results', ',', 'course', ',', 'fast', 'get', 'final', 'mining', 'results', 'become', 'important', 'research', 'topic', '.']

>> Bigrams are: 
 [('When', 'two'), ('two', 'different'), ('different', 'mining'), ('mining', 'algorithms'), ('algorithms', 'find'), ('find', 'similar'), ('similar', 'results'), ('results', ','), (',', 'course'), ('course', ','), (',', 'fast'), ('fast', 'get'), ('get', 'final'), ('final', 'mining'), ('mining', 'results'), ('results', 'become'), ('become', 'important'), ('important', 'research'), ('research', 'topic'), ('topic', '.')]

>> Trigrams are: 
 [('When', 'two', 'different'), ('two', 'different', 'mining'), ('different', 'mining', 'algorithms'), ('mining', 'algorithms', 'find'), ('algorithms', 'find', 'similar'), ('find', 'similar', 'results'), ('similar', 'results', ','), ('results', ',', 'course'), (',', 'course', ','), ('course', ',', 'fast'), (',', 'fast', 'get'), ('fast', 'get', 'final'), ('get', 'final', 'mining'), ('final', 'mining', 'results'), ('mining', 'results', 'become'), ('results', 'become', 'important'), ('become', 'important', 'research'), ('important', 'research', 'topic'), ('research', 'topic', '.')]

>> POS Tags are: 
 [('When', 'WRB'), ('two', 'CD'), ('different', 'JJ'), ('mining', 'VBG'), ('algorithms', 'NN'), ('find', 'VBP'), ('similar', 'JJ'), ('results', 'NNS'), (',', ','), ('course', 'NN'), (',', ','), ('fast', 'JJ'), ('get', 'VBP'), ('final', 'JJ'), ('mining', 'NN'), ('results', 'NNS'), ('become', 'VBP'), ('important', 'JJ'), ('research', 'NN'), ('topic', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['algorithms', 'similar results', 'course', 'final mining results', 'important research topic']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('When', 'when'), ('two', 'two'), ('different', 'differ'), ('mining', 'mine'), ('algorithms', 'algorithm'), ('find', 'find'), ('similar', 'similar'), ('results', 'result'), (',', ','), ('course', 'cours'), (',', ','), ('fast', 'fast'), ('get', 'get'), ('final', 'final'), ('mining', 'mine'), ('results', 'result'), ('become', 'becom'), ('important', 'import'), ('research', 'research'), ('topic', 'topic'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('When', 'when'), ('two', 'two'), ('different', 'differ'), ('mining', 'mine'), ('algorithms', 'algorithm'), ('find', 'find'), ('similar', 'similar'), ('results', 'result'), (',', ','), ('course', 'cours'), (',', ','), ('fast', 'fast'), ('get', 'get'), ('final', 'final'), ('mining', 'mine'), ('results', 'result'), ('become', 'becom'), ('important', 'import'), ('research', 'research'), ('topic', 'topic'), ('.', '.')]

>> Lemmatization: 
 [('When', 'When'), ('two', 'two'), ('different', 'different'), ('mining', 'mining'), ('algorithms', 'algorithm'), ('find', 'find'), ('similar', 'similar'), ('results', 'result'), (',', ','), ('course', 'course'), (',', ','), ('fast', 'fast'), ('get', 'get'), ('final', 'final'), ('mining', 'mining'), ('results', 'result'), ('become', 'become'), ('important', 'important'), ('research', 'research'), ('topic', 'topic'), ('.', '.')]



========================================== PARAGRAPH 128 ===========================================

After something (e.g.-, classification rules) is found by data mining methods, the two  essential research topics are: (1) the work to navigate and explore the meaning of the  results from the data analysis to further support the user to do the applicable decision  can be regarded as the interpretation operator [38], which in most cases, gives useful  interface to display the information [39] and (2) a meaningful summarization of the min- ing results [40] can be made to make it easier for the user to understand the information  from the data analysis. The data summarization is generally expected to be one of the  simple ways to provide a concise piece of information to the user because human has  trouble of understanding vast amounts of complicated information. A simple data sum- marization can be found in the clustering search engine, when a query “oasis” is sent to  Carrot2 (http://search.carrot2.org/stable/search), it will return some keywords to rep- resent each group of the clustering results for web links to help us recognize which cat- egory needed by the user, as shown in the left side of Fig. 5. 

------------------- Sentence 1 -------------------

After something (e.g.-, classification rules) is found by data mining methods, the two  essential research topics are: (1) the work to navigate and explore the meaning of the  results from the data analysis to further support the user to do the applicable decision  can be regarded as the interpretation operator [38], which in most cases, gives useful  interface to display the information [39] and (2) a meaningful summarization of the min- ing results [40] can be made to make it easier for the user to understand the information  from the data analysis.

>> Tokens are: 
 ['After', 'something', '(', 'e.g.-', ',', 'classification', 'rules', ')', 'found', 'data', 'mining', 'methods', ',', 'two', 'essential', 'research', 'topics', ':', '(', '1', ')', 'work', 'navigate', 'explore', 'meaning', 'results', 'data', 'analysis', 'support', 'user', 'applicable', 'decision', 'regarded', 'interpretation', 'operator', '[', '38', ']', ',', 'cases', ',', 'gives', 'useful', 'interface', 'display', 'information', '[', '39', ']', '(', '2', ')', 'meaningful', 'summarization', 'min-', 'ing', 'results', '[', '40', ']', 'made', 'make', 'easier', 'user', 'understand', 'information', 'data', 'analysis', '.']

>> Bigrams are: 
 [('After', 'something'), ('something', '('), ('(', 'e.g.-'), ('e.g.-', ','), (',', 'classification'), ('classification', 'rules'), ('rules', ')'), (')', 'found'), ('found', 'data'), ('data', 'mining'), ('mining', 'methods'), ('methods', ','), (',', 'two'), ('two', 'essential'), ('essential', 'research'), ('research', 'topics'), ('topics', ':'), (':', '('), ('(', '1'), ('1', ')'), (')', 'work'), ('work', 'navigate'), ('navigate', 'explore'), ('explore', 'meaning'), ('meaning', 'results'), ('results', 'data'), ('data', 'analysis'), ('analysis', 'support'), ('support', 'user'), ('user', 'applicable'), ('applicable', 'decision'), ('decision', 'regarded'), ('regarded', 'interpretation'), ('interpretation', 'operator'), ('operator', '['), ('[', '38'), ('38', ']'), (']', ','), (',', 'cases'), ('cases', ','), (',', 'gives'), ('gives', 'useful'), ('useful', 'interface'), ('interface', 'display'), ('display', 'information'), ('information', '['), ('[', '39'), ('39', ']'), (']', '('), ('(', '2'), ('2', ')'), (')', 'meaningful'), ('meaningful', 'summarization'), ('summarization', 'min-'), ('min-', 'ing'), ('ing', 'results'), ('results', '['), ('[', '40'), ('40', ']'), (']', 'made'), ('made', 'make'), ('make', 'easier'), ('easier', 'user'), ('user', 'understand'), ('understand', 'information'), ('information', 'data'), ('data', 'analysis'), ('analysis', '.')]

>> Trigrams are: 
 [('After', 'something', '('), ('something', '(', 'e.g.-'), ('(', 'e.g.-', ','), ('e.g.-', ',', 'classification'), (',', 'classification', 'rules'), ('classification', 'rules', ')'), ('rules', ')', 'found'), (')', 'found', 'data'), ('found', 'data', 'mining'), ('data', 'mining', 'methods'), ('mining', 'methods', ','), ('methods', ',', 'two'), (',', 'two', 'essential'), ('two', 'essential', 'research'), ('essential', 'research', 'topics'), ('research', 'topics', ':'), ('topics', ':', '('), (':', '(', '1'), ('(', '1', ')'), ('1', ')', 'work'), (')', 'work', 'navigate'), ('work', 'navigate', 'explore'), ('navigate', 'explore', 'meaning'), ('explore', 'meaning', 'results'), ('meaning', 'results', 'data'), ('results', 'data', 'analysis'), ('data', 'analysis', 'support'), ('analysis', 'support', 'user'), ('support', 'user', 'applicable'), ('user', 'applicable', 'decision'), ('applicable', 'decision', 'regarded'), ('decision', 'regarded', 'interpretation'), ('regarded', 'interpretation', 'operator'), ('interpretation', 'operator', '['), ('operator', '[', '38'), ('[', '38', ']'), ('38', ']', ','), (']', ',', 'cases'), (',', 'cases', ','), ('cases', ',', 'gives'), (',', 'gives', 'useful'), ('gives', 'useful', 'interface'), ('useful', 'interface', 'display'), ('interface', 'display', 'information'), ('display', 'information', '['), ('information', '[', '39'), ('[', '39', ']'), ('39', ']', '('), (']', '(', '2'), ('(', '2', ')'), ('2', ')', 'meaningful'), (')', 'meaningful', 'summarization'), ('meaningful', 'summarization', 'min-'), ('summarization', 'min-', 'ing'), ('min-', 'ing', 'results'), ('ing', 'results', '['), ('results', '[', '40'), ('[', '40', ']'), ('40', ']', 'made'), (']', 'made', 'make'), ('made', 'make', 'easier'), ('make', 'easier', 'user'), ('easier', 'user', 'understand'), ('user', 'understand', 'information'), ('understand', 'information', 'data'), ('information', 'data', 'analysis'), ('data', 'analysis', '.')]

>> POS Tags are: 
 [('After', 'IN'), ('something', 'NN'), ('(', '('), ('e.g.-', 'JJ'), (',', ','), ('classification', 'NN'), ('rules', 'NNS'), (')', ')'), ('found', 'VBD'), ('data', 'NNS'), ('mining', 'NN'), ('methods', 'NNS'), (',', ','), ('two', 'CD'), ('essential', 'JJ'), ('research', 'NN'), ('topics', 'NNS'), (':', ':'), ('(', '('), ('1', 'CD'), (')', ')'), ('work', 'NN'), ('navigate', 'RB'), ('explore', 'RB'), ('meaning', 'JJ'), ('results', 'NNS'), ('data', 'NNS'), ('analysis', 'NN'), ('support', 'NN'), ('user', 'RBR'), ('applicable', 'JJ'), ('decision', 'NN'), ('regarded', 'VBD'), ('interpretation', 'NN'), ('operator', 'NN'), ('[', 'VBD'), ('38', 'CD'), (']', 'NN'), (',', ','), ('cases', 'NNS'), (',', ','), ('gives', 'VBZ'), ('useful', 'JJ'), ('interface', 'NN'), ('display', 'NN'), ('information', 'NN'), ('[', '$'), ('39', 'CD'), (']', 'NNP'), ('(', '('), ('2', 'CD'), (')', ')'), ('meaningful', 'JJ'), ('summarization', 'NN'), ('min-', 'JJ'), ('ing', 'NN'), ('results', 'NNS'), ('[', 'VBD'), ('40', 'CD'), (']', 'NN'), ('made', 'VBD'), ('make', 'VBP'), ('easier', 'JJR'), ('user', 'JJ'), ('understand', 'NN'), ('information', 'NN'), ('data', 'NNS'), ('analysis', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['something', 'classification rules', 'data mining methods', 'essential research topics', 'work', 'meaning results data analysis support', 'applicable decision', 'interpretation operator', ']', 'cases', 'useful interface display information', ']', 'meaningful summarization', 'min- ing results', ']', 'user understand information data analysis']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('After', 'after'), ('something', 'someth'), ('(', '('), ('e.g.-', 'e.g.-'), (',', ','), ('classification', 'classif'), ('rules', 'rule'), (')', ')'), ('found', 'found'), ('data', 'data'), ('mining', 'mine'), ('methods', 'method'), (',', ','), ('two', 'two'), ('essential', 'essenti'), ('research', 'research'), ('topics', 'topic'), (':', ':'), ('(', '('), ('1', '1'), (')', ')'), ('work', 'work'), ('navigate', 'navig'), ('explore', 'explor'), ('meaning', 'mean'), ('results', 'result'), ('data', 'data'), ('analysis', 'analysi'), ('support', 'support'), ('user', 'user'), ('applicable', 'applic'), ('decision', 'decis'), ('regarded', 'regard'), ('interpretation', 'interpret'), ('operator', 'oper'), ('[', '['), ('38', '38'), (']', ']'), (',', ','), ('cases', 'case'), (',', ','), ('gives', 'give'), ('useful', 'use'), ('interface', 'interfac'), ('display', 'display'), ('information', 'inform'), ('[', '['), ('39', '39'), (']', ']'), ('(', '('), ('2', '2'), (')', ')'), ('meaningful', 'meaning'), ('summarization', 'summar'), ('min-', 'min-'), ('ing', 'ing'), ('results', 'result'), ('[', '['), ('40', '40'), (']', ']'), ('made', 'made'), ('make', 'make'), ('easier', 'easier'), ('user', 'user'), ('understand', 'understand'), ('information', 'inform'), ('data', 'data'), ('analysis', 'analysi'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('After', 'after'), ('something', 'someth'), ('(', '('), ('e.g.-', 'e.g.-'), (',', ','), ('classification', 'classif'), ('rules', 'rule'), (')', ')'), ('found', 'found'), ('data', 'data'), ('mining', 'mine'), ('methods', 'method'), (',', ','), ('two', 'two'), ('essential', 'essenti'), ('research', 'research'), ('topics', 'topic'), (':', ':'), ('(', '('), ('1', '1'), (')', ')'), ('work', 'work'), ('navigate', 'navig'), ('explore', 'explor'), ('meaning', 'mean'), ('results', 'result'), ('data', 'data'), ('analysis', 'analysi'), ('support', 'support'), ('user', 'user'), ('applicable', 'applic'), ('decision', 'decis'), ('regarded', 'regard'), ('interpretation', 'interpret'), ('operator', 'oper'), ('[', '['), ('38', '38'), (']', ']'), (',', ','), ('cases', 'case'), (',', ','), ('gives', 'give'), ('useful', 'use'), ('interface', 'interfac'), ('display', 'display'), ('information', 'inform'), ('[', '['), ('39', '39'), (']', ']'), ('(', '('), ('2', '2'), (')', ')'), ('meaningful', 'meaning'), ('summarization', 'summar'), ('min-', 'min-'), ('ing', 'ing'), ('results', 'result'), ('[', '['), ('40', '40'), (']', ']'), ('made', 'made'), ('make', 'make'), ('easier', 'easier'), ('user', 'user'), ('understand', 'understand'), ('information', 'inform'), ('data', 'data'), ('analysis', 'analysi'), ('.', '.')]

>> Lemmatization: 
 [('After', 'After'), ('something', 'something'), ('(', '('), ('e.g.-', 'e.g.-'), (',', ','), ('classification', 'classification'), ('rules', 'rule'), (')', ')'), ('found', 'found'), ('data', 'data'), ('mining', 'mining'), ('methods', 'method'), (',', ','), ('two', 'two'), ('essential', 'essential'), ('research', 'research'), ('topics', 'topic'), (':', ':'), ('(', '('), ('1', '1'), (')', ')'), ('work', 'work'), ('navigate', 'navigate'), ('explore', 'explore'), ('meaning', 'meaning'), ('results', 'result'), ('data', 'data'), ('analysis', 'analysis'), ('support', 'support'), ('user', 'user'), ('applicable', 'applicable'), ('decision', 'decision'), ('regarded', 'regarded'), ('interpretation', 'interpretation'), ('operator', 'operator'), ('[', '['), ('38', '38'), (']', ']'), (',', ','), ('cases', 'case'), (',', ','), ('gives', 'give'), ('useful', 'useful'), ('interface', 'interface'), ('display', 'display'), ('information', 'information'), ('[', '['), ('39', '39'), (']', ']'), ('(', '('), ('2', '2'), (')', ')'), ('meaningful', 'meaningful'), ('summarization', 'summarization'), ('min-', 'min-'), ('ing', 'ing'), ('results', 'result'), ('[', '['), ('40', '40'), (']', ']'), ('made', 'made'), ('make', 'make'), ('easier', 'easier'), ('user', 'user'), ('understand', 'understand'), ('information', 'information'), ('data', 'data'), ('analysis', 'analysis'), ('.', '.')]


------------------- Sentence 2 -------------------

The data summarization is generally expected to be one of the  simple ways to provide a concise piece of information to the user because human has  trouble of understanding vast amounts of complicated information.

>> Tokens are: 
 ['The', 'data', 'summarization', 'generally', 'expected', 'one', 'simple', 'ways', 'provide', 'concise', 'piece', 'information', 'user', 'human', 'trouble', 'understanding', 'vast', 'amounts', 'complicated', 'information', '.']

>> Bigrams are: 
 [('The', 'data'), ('data', 'summarization'), ('summarization', 'generally'), ('generally', 'expected'), ('expected', 'one'), ('one', 'simple'), ('simple', 'ways'), ('ways', 'provide'), ('provide', 'concise'), ('concise', 'piece'), ('piece', 'information'), ('information', 'user'), ('user', 'human'), ('human', 'trouble'), ('trouble', 'understanding'), ('understanding', 'vast'), ('vast', 'amounts'), ('amounts', 'complicated'), ('complicated', 'information'), ('information', '.')]

>> Trigrams are: 
 [('The', 'data', 'summarization'), ('data', 'summarization', 'generally'), ('summarization', 'generally', 'expected'), ('generally', 'expected', 'one'), ('expected', 'one', 'simple'), ('one', 'simple', 'ways'), ('simple', 'ways', 'provide'), ('ways', 'provide', 'concise'), ('provide', 'concise', 'piece'), ('concise', 'piece', 'information'), ('piece', 'information', 'user'), ('information', 'user', 'human'), ('user', 'human', 'trouble'), ('human', 'trouble', 'understanding'), ('trouble', 'understanding', 'vast'), ('understanding', 'vast', 'amounts'), ('vast', 'amounts', 'complicated'), ('amounts', 'complicated', 'information'), ('complicated', 'information', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('data', 'NN'), ('summarization', 'NN'), ('generally', 'RB'), ('expected', 'VBD'), ('one', 'CD'), ('simple', 'NN'), ('ways', 'NNS'), ('provide', 'VBP'), ('concise', 'VB'), ('piece', 'NN'), ('information', 'NN'), ('user', 'IN'), ('human', 'JJ'), ('trouble', 'NN'), ('understanding', 'VBG'), ('vast', 'JJ'), ('amounts', 'NNS'), ('complicated', 'VBN'), ('information', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['The data summarization', 'simple ways', 'piece information', 'human trouble', 'vast amounts', 'information']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('data', 'data'), ('summarization', 'summar'), ('generally', 'gener'), ('expected', 'expect'), ('one', 'one'), ('simple', 'simpl'), ('ways', 'way'), ('provide', 'provid'), ('concise', 'concis'), ('piece', 'piec'), ('information', 'inform'), ('user', 'user'), ('human', 'human'), ('trouble', 'troubl'), ('understanding', 'understand'), ('vast', 'vast'), ('amounts', 'amount'), ('complicated', 'complic'), ('information', 'inform'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('data', 'data'), ('summarization', 'summar'), ('generally', 'general'), ('expected', 'expect'), ('one', 'one'), ('simple', 'simpl'), ('ways', 'way'), ('provide', 'provid'), ('concise', 'concis'), ('piece', 'piec'), ('information', 'inform'), ('user', 'user'), ('human', 'human'), ('trouble', 'troubl'), ('understanding', 'understand'), ('vast', 'vast'), ('amounts', 'amount'), ('complicated', 'complic'), ('information', 'inform'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('data', 'data'), ('summarization', 'summarization'), ('generally', 'generally'), ('expected', 'expected'), ('one', 'one'), ('simple', 'simple'), ('ways', 'way'), ('provide', 'provide'), ('concise', 'concise'), ('piece', 'piece'), ('information', 'information'), ('user', 'user'), ('human', 'human'), ('trouble', 'trouble'), ('understanding', 'understanding'), ('vast', 'vast'), ('amounts', 'amount'), ('complicated', 'complicated'), ('information', 'information'), ('.', '.')]


------------------- Sentence 3 -------------------

A simple data sum- marization can be found in the clustering search engine, when a query “oasis” is sent to  Carrot2 (http://search.carrot2.org/stable/search), it will return some keywords to rep- resent each group of the clustering results for web links to help us recognize which cat- egory needed by the user, as shown in the left side of Fig.

>> Tokens are: 
 ['A', 'simple', 'data', 'sum-', 'marization', 'found', 'clustering', 'search', 'engine', ',', 'query', '“', 'oasis', '”', 'sent', 'Carrot2', '(', 'http', ':', '//search.carrot2.org/stable/search', ')', ',', 'return', 'keywords', 'rep-', 'resent', 'group', 'clustering', 'results', 'web', 'links', 'help', 'us', 'recognize', 'cat-', 'egory', 'needed', 'user', ',', 'shown', 'left', 'side', 'Fig', '.']

>> Bigrams are: 
 [('A', 'simple'), ('simple', 'data'), ('data', 'sum-'), ('sum-', 'marization'), ('marization', 'found'), ('found', 'clustering'), ('clustering', 'search'), ('search', 'engine'), ('engine', ','), (',', 'query'), ('query', '“'), ('“', 'oasis'), ('oasis', '”'), ('”', 'sent'), ('sent', 'Carrot2'), ('Carrot2', '('), ('(', 'http'), ('http', ':'), (':', '//search.carrot2.org/stable/search'), ('//search.carrot2.org/stable/search', ')'), (')', ','), (',', 'return'), ('return', 'keywords'), ('keywords', 'rep-'), ('rep-', 'resent'), ('resent', 'group'), ('group', 'clustering'), ('clustering', 'results'), ('results', 'web'), ('web', 'links'), ('links', 'help'), ('help', 'us'), ('us', 'recognize'), ('recognize', 'cat-'), ('cat-', 'egory'), ('egory', 'needed'), ('needed', 'user'), ('user', ','), (',', 'shown'), ('shown', 'left'), ('left', 'side'), ('side', 'Fig'), ('Fig', '.')]

>> Trigrams are: 
 [('A', 'simple', 'data'), ('simple', 'data', 'sum-'), ('data', 'sum-', 'marization'), ('sum-', 'marization', 'found'), ('marization', 'found', 'clustering'), ('found', 'clustering', 'search'), ('clustering', 'search', 'engine'), ('search', 'engine', ','), ('engine', ',', 'query'), (',', 'query', '“'), ('query', '“', 'oasis'), ('“', 'oasis', '”'), ('oasis', '”', 'sent'), ('”', 'sent', 'Carrot2'), ('sent', 'Carrot2', '('), ('Carrot2', '(', 'http'), ('(', 'http', ':'), ('http', ':', '//search.carrot2.org/stable/search'), (':', '//search.carrot2.org/stable/search', ')'), ('//search.carrot2.org/stable/search', ')', ','), (')', ',', 'return'), (',', 'return', 'keywords'), ('return', 'keywords', 'rep-'), ('keywords', 'rep-', 'resent'), ('rep-', 'resent', 'group'), ('resent', 'group', 'clustering'), ('group', 'clustering', 'results'), ('clustering', 'results', 'web'), ('results', 'web', 'links'), ('web', 'links', 'help'), ('links', 'help', 'us'), ('help', 'us', 'recognize'), ('us', 'recognize', 'cat-'), ('recognize', 'cat-', 'egory'), ('cat-', 'egory', 'needed'), ('egory', 'needed', 'user'), ('needed', 'user', ','), ('user', ',', 'shown'), (',', 'shown', 'left'), ('shown', 'left', 'side'), ('left', 'side', 'Fig'), ('side', 'Fig', '.')]

>> POS Tags are: 
 [('A', 'DT'), ('simple', 'JJ'), ('data', 'NNS'), ('sum-', 'JJ'), ('marization', 'NN'), ('found', 'VBD'), ('clustering', 'VBG'), ('search', 'NN'), ('engine', 'NN'), (',', ','), ('query', 'NN'), ('“', 'JJ'), ('oasis', 'NN'), ('”', 'NNP'), ('sent', 'VBD'), ('Carrot2', 'NNP'), ('(', '('), ('http', 'NN'), (':', ':'), ('//search.carrot2.org/stable/search', 'NN'), (')', ')'), (',', ','), ('return', 'VBP'), ('keywords', 'NNS'), ('rep-', 'JJ'), ('resent', 'NN'), ('group', 'NN'), ('clustering', 'VBG'), ('results', 'NNS'), ('web', 'JJ'), ('links', 'NNS'), ('help', 'VBP'), ('us', 'PRP'), ('recognize', 'VB'), ('cat-', 'JJ'), ('egory', 'NN'), ('needed', 'VBN'), ('user', 'NN'), (',', ','), ('shown', 'VBN'), ('left', 'JJ'), ('side', 'NN'), ('Fig', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['A simple data', 'sum- marization', 'search engine', 'query', '“ oasis ”', 'Carrot2', 'http', '//search.carrot2.org/stable/search', 'keywords', 'rep- resent group', 'results', 'web links', 'cat- egory', 'user', 'left side Fig']

>> Named Entities are: 
 [('GPE', 'Carrot2')] 

>> Stemming using Porter Stemmer: 
 [('A', 'a'), ('simple', 'simpl'), ('data', 'data'), ('sum-', 'sum-'), ('marization', 'mariz'), ('found', 'found'), ('clustering', 'cluster'), ('search', 'search'), ('engine', 'engin'), (',', ','), ('query', 'queri'), ('“', '“'), ('oasis', 'oasi'), ('”', '”'), ('sent', 'sent'), ('Carrot2', 'carrot2'), ('(', '('), ('http', 'http'), (':', ':'), ('//search.carrot2.org/stable/search', '//search.carrot2.org/stable/search'), (')', ')'), (',', ','), ('return', 'return'), ('keywords', 'keyword'), ('rep-', 'rep-'), ('resent', 'resent'), ('group', 'group'), ('clustering', 'cluster'), ('results', 'result'), ('web', 'web'), ('links', 'link'), ('help', 'help'), ('us', 'us'), ('recognize', 'recogn'), ('cat-', 'cat-'), ('egory', 'egori'), ('needed', 'need'), ('user', 'user'), (',', ','), ('shown', 'shown'), ('left', 'left'), ('side', 'side'), ('Fig', 'fig'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('A', 'a'), ('simple', 'simpl'), ('data', 'data'), ('sum-', 'sum-'), ('marization', 'marize'), ('found', 'found'), ('clustering', 'cluster'), ('search', 'search'), ('engine', 'engin'), (',', ','), ('query', 'queri'), ('“', '“'), ('oasis', 'oasi'), ('”', '”'), ('sent', 'sent'), ('Carrot2', 'carrot2'), ('(', '('), ('http', 'http'), (':', ':'), ('//search.carrot2.org/stable/search', '//search.carrot2.org/stable/search'), (')', ')'), (',', ','), ('return', 'return'), ('keywords', 'keyword'), ('rep-', 'rep-'), ('resent', 'resent'), ('group', 'group'), ('clustering', 'cluster'), ('results', 'result'), ('web', 'web'), ('links', 'link'), ('help', 'help'), ('us', 'us'), ('recognize', 'recogn'), ('cat-', 'cat-'), ('egory', 'egori'), ('needed', 'need'), ('user', 'user'), (',', ','), ('shown', 'shown'), ('left', 'left'), ('side', 'side'), ('Fig', 'fig'), ('.', '.')]

>> Lemmatization: 
 [('A', 'A'), ('simple', 'simple'), ('data', 'data'), ('sum-', 'sum-'), ('marization', 'marization'), ('found', 'found'), ('clustering', 'clustering'), ('search', 'search'), ('engine', 'engine'), (',', ','), ('query', 'query'), ('“', '“'), ('oasis', 'oasis'), ('”', '”'), ('sent', 'sent'), ('Carrot2', 'Carrot2'), ('(', '('), ('http', 'http'), (':', ':'), ('//search.carrot2.org/stable/search', '//search.carrot2.org/stable/search'), (')', ')'), (',', ','), ('return', 'return'), ('keywords', 'keywords'), ('rep-', 'rep-'), ('resent', 'resent'), ('group', 'group'), ('clustering', 'clustering'), ('results', 'result'), ('web', 'web'), ('links', 'link'), ('help', 'help'), ('us', 'u'), ('recognize', 'recognize'), ('cat-', 'cat-'), ('egory', 'egory'), ('needed', 'needed'), ('user', 'user'), (',', ','), ('shown', 'shown'), ('left', 'left'), ('side', 'side'), ('Fig', 'Fig'), ('.', '.')]


------------------- Sentence 4 -------------------

5.

>> Tokens are: 
 ['5', '.']

>> Bigrams are: 
 [('5', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('5', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('5', '5'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('5', '5'), ('.', '.')]

>> Lemmatization: 
 [('5', '5'), ('.', '.')]



========================================== PARAGRAPH 129 ===========================================

A useful graphical user interface is another way to provide the meaningful informa- tion to an user. As explained by Shneiderman in [39], we need “overview first, zoom and  filter, then retrieve the details on demand”. The useful graphical user interface [38, 41]  also makes it easier for the user to comprehend the meaning of the results when the  number of dimensions is higher than three. How to display the results of data mining  will affect the user’s perspective to make the decision. For instance, data mining can help  us find “type A influenza” at a particular region, but without the time series and flu virus  infected information of patients, the government could not recognize what situation  (pandemic or controlled) we are facing now so as to make appropriate responses to that.  For this reason, a better solution to merge the information from different sources and  mining algorithm results will be useful to let the user make the right decision. 

------------------- Sentence 1 -------------------

A useful graphical user interface is another way to provide the meaningful informa- tion to an user.

>> Tokens are: 
 ['A', 'useful', 'graphical', 'user', 'interface', 'another', 'way', 'provide', 'meaningful', 'informa-', 'tion', 'user', '.']

>> Bigrams are: 
 [('A', 'useful'), ('useful', 'graphical'), ('graphical', 'user'), ('user', 'interface'), ('interface', 'another'), ('another', 'way'), ('way', 'provide'), ('provide', 'meaningful'), ('meaningful', 'informa-'), ('informa-', 'tion'), ('tion', 'user'), ('user', '.')]

>> Trigrams are: 
 [('A', 'useful', 'graphical'), ('useful', 'graphical', 'user'), ('graphical', 'user', 'interface'), ('user', 'interface', 'another'), ('interface', 'another', 'way'), ('another', 'way', 'provide'), ('way', 'provide', 'meaningful'), ('provide', 'meaningful', 'informa-'), ('meaningful', 'informa-', 'tion'), ('informa-', 'tion', 'user'), ('tion', 'user', '.')]

>> POS Tags are: 
 [('A', 'DT'), ('useful', 'JJ'), ('graphical', 'JJ'), ('user', 'NN'), ('interface', 'NN'), ('another', 'DT'), ('way', 'NN'), ('provide', 'VBP'), ('meaningful', 'JJ'), ('informa-', 'JJ'), ('tion', 'NN'), ('user', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['A useful graphical user interface', 'another way', 'meaningful informa- tion user']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('A', 'a'), ('useful', 'use'), ('graphical', 'graphic'), ('user', 'user'), ('interface', 'interfac'), ('another', 'anoth'), ('way', 'way'), ('provide', 'provid'), ('meaningful', 'meaning'), ('informa-', 'informa-'), ('tion', 'tion'), ('user', 'user'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('A', 'a'), ('useful', 'use'), ('graphical', 'graphic'), ('user', 'user'), ('interface', 'interfac'), ('another', 'anoth'), ('way', 'way'), ('provide', 'provid'), ('meaningful', 'meaning'), ('informa-', 'informa-'), ('tion', 'tion'), ('user', 'user'), ('.', '.')]

>> Lemmatization: 
 [('A', 'A'), ('useful', 'useful'), ('graphical', 'graphical'), ('user', 'user'), ('interface', 'interface'), ('another', 'another'), ('way', 'way'), ('provide', 'provide'), ('meaningful', 'meaningful'), ('informa-', 'informa-'), ('tion', 'tion'), ('user', 'user'), ('.', '.')]


------------------- Sentence 2 -------------------

As explained by Shneiderman in [39], we need “overview first, zoom and  filter, then retrieve the details on demand”.

>> Tokens are: 
 ['As', 'explained', 'Shneiderman', '[', '39', ']', ',', 'need', '“', 'overview', 'first', ',', 'zoom', 'filter', ',', 'retrieve', 'details', 'demand', '”', '.']

>> Bigrams are: 
 [('As', 'explained'), ('explained', 'Shneiderman'), ('Shneiderman', '['), ('[', '39'), ('39', ']'), (']', ','), (',', 'need'), ('need', '“'), ('“', 'overview'), ('overview', 'first'), ('first', ','), (',', 'zoom'), ('zoom', 'filter'), ('filter', ','), (',', 'retrieve'), ('retrieve', 'details'), ('details', 'demand'), ('demand', '”'), ('”', '.')]

>> Trigrams are: 
 [('As', 'explained', 'Shneiderman'), ('explained', 'Shneiderman', '['), ('Shneiderman', '[', '39'), ('[', '39', ']'), ('39', ']', ','), (']', ',', 'need'), (',', 'need', '“'), ('need', '“', 'overview'), ('“', 'overview', 'first'), ('overview', 'first', ','), ('first', ',', 'zoom'), (',', 'zoom', 'filter'), ('zoom', 'filter', ','), ('filter', ',', 'retrieve'), (',', 'retrieve', 'details'), ('retrieve', 'details', 'demand'), ('details', 'demand', '”'), ('demand', '”', '.')]

>> POS Tags are: 
 [('As', 'IN'), ('explained', 'VBN'), ('Shneiderman', 'NNP'), ('[', 'VBZ'), ('39', 'CD'), (']', 'NN'), (',', ','), ('need', 'VBP'), ('“', 'NNP'), ('overview', 'NN'), ('first', 'RB'), (',', ','), ('zoom', 'NN'), ('filter', 'NN'), (',', ','), ('retrieve', 'VBP'), ('details', 'NNS'), ('demand', 'NN'), ('”', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Shneiderman', ']', '“ overview', 'zoom filter', 'details demand ”']

>> Named Entities are: 
 [('PERSON', 'Shneiderman')] 

>> Stemming using Porter Stemmer: 
 [('As', 'as'), ('explained', 'explain'), ('Shneiderman', 'shneiderman'), ('[', '['), ('39', '39'), (']', ']'), (',', ','), ('need', 'need'), ('“', '“'), ('overview', 'overview'), ('first', 'first'), (',', ','), ('zoom', 'zoom'), ('filter', 'filter'), (',', ','), ('retrieve', 'retriev'), ('details', 'detail'), ('demand', 'demand'), ('”', '”'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('As', 'as'), ('explained', 'explain'), ('Shneiderman', 'shneiderman'), ('[', '['), ('39', '39'), (']', ']'), (',', ','), ('need', 'need'), ('“', '“'), ('overview', 'overview'), ('first', 'first'), (',', ','), ('zoom', 'zoom'), ('filter', 'filter'), (',', ','), ('retrieve', 'retriev'), ('details', 'detail'), ('demand', 'demand'), ('”', '”'), ('.', '.')]

>> Lemmatization: 
 [('As', 'As'), ('explained', 'explained'), ('Shneiderman', 'Shneiderman'), ('[', '['), ('39', '39'), (']', ']'), (',', ','), ('need', 'need'), ('“', '“'), ('overview', 'overview'), ('first', 'first'), (',', ','), ('zoom', 'zoom'), ('filter', 'filter'), (',', ','), ('retrieve', 'retrieve'), ('details', 'detail'), ('demand', 'demand'), ('”', '”'), ('.', '.')]


------------------- Sentence 3 -------------------

The useful graphical user interface [38, 41]  also makes it easier for the user to comprehend the meaning of the results when the  number of dimensions is higher than three.

>> Tokens are: 
 ['The', 'useful', 'graphical', 'user', 'interface', '[', '38', ',', '41', ']', 'also', 'makes', 'easier', 'user', 'comprehend', 'meaning', 'results', 'number', 'dimensions', 'higher', 'three', '.']

>> Bigrams are: 
 [('The', 'useful'), ('useful', 'graphical'), ('graphical', 'user'), ('user', 'interface'), ('interface', '['), ('[', '38'), ('38', ','), (',', '41'), ('41', ']'), (']', 'also'), ('also', 'makes'), ('makes', 'easier'), ('easier', 'user'), ('user', 'comprehend'), ('comprehend', 'meaning'), ('meaning', 'results'), ('results', 'number'), ('number', 'dimensions'), ('dimensions', 'higher'), ('higher', 'three'), ('three', '.')]

>> Trigrams are: 
 [('The', 'useful', 'graphical'), ('useful', 'graphical', 'user'), ('graphical', 'user', 'interface'), ('user', 'interface', '['), ('interface', '[', '38'), ('[', '38', ','), ('38', ',', '41'), (',', '41', ']'), ('41', ']', 'also'), (']', 'also', 'makes'), ('also', 'makes', 'easier'), ('makes', 'easier', 'user'), ('easier', 'user', 'comprehend'), ('user', 'comprehend', 'meaning'), ('comprehend', 'meaning', 'results'), ('meaning', 'results', 'number'), ('results', 'number', 'dimensions'), ('number', 'dimensions', 'higher'), ('dimensions', 'higher', 'three'), ('higher', 'three', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('useful', 'JJ'), ('graphical', 'JJ'), ('user', 'NN'), ('interface', 'NN'), ('[', 'NNP'), ('38', 'CD'), (',', ','), ('41', 'CD'), (']', 'NN'), ('also', 'RB'), ('makes', 'VBZ'), ('easier', 'JJR'), ('user', 'JJ'), ('comprehend', 'NN'), ('meaning', 'NN'), ('results', 'NNS'), ('number', 'NN'), ('dimensions', 'NNS'), ('higher', 'RBR'), ('three', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['The useful graphical user interface [', ']', 'user comprehend meaning results number dimensions']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('useful', 'use'), ('graphical', 'graphic'), ('user', 'user'), ('interface', 'interfac'), ('[', '['), ('38', '38'), (',', ','), ('41', '41'), (']', ']'), ('also', 'also'), ('makes', 'make'), ('easier', 'easier'), ('user', 'user'), ('comprehend', 'comprehend'), ('meaning', 'mean'), ('results', 'result'), ('number', 'number'), ('dimensions', 'dimens'), ('higher', 'higher'), ('three', 'three'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('useful', 'use'), ('graphical', 'graphic'), ('user', 'user'), ('interface', 'interfac'), ('[', '['), ('38', '38'), (',', ','), ('41', '41'), (']', ']'), ('also', 'also'), ('makes', 'make'), ('easier', 'easier'), ('user', 'user'), ('comprehend', 'comprehend'), ('meaning', 'mean'), ('results', 'result'), ('number', 'number'), ('dimensions', 'dimens'), ('higher', 'higher'), ('three', 'three'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('useful', 'useful'), ('graphical', 'graphical'), ('user', 'user'), ('interface', 'interface'), ('[', '['), ('38', '38'), (',', ','), ('41', '41'), (']', ']'), ('also', 'also'), ('makes', 'make'), ('easier', 'easier'), ('user', 'user'), ('comprehend', 'comprehend'), ('meaning', 'meaning'), ('results', 'result'), ('number', 'number'), ('dimensions', 'dimension'), ('higher', 'higher'), ('three', 'three'), ('.', '.')]


------------------- Sentence 4 -------------------

How to display the results of data mining  will affect the user’s perspective to make the decision.

>> Tokens are: 
 ['How', 'display', 'results', 'data', 'mining', 'affect', 'user', '’', 'perspective', 'make', 'decision', '.']

>> Bigrams are: 
 [('How', 'display'), ('display', 'results'), ('results', 'data'), ('data', 'mining'), ('mining', 'affect'), ('affect', 'user'), ('user', '’'), ('’', 'perspective'), ('perspective', 'make'), ('make', 'decision'), ('decision', '.')]

>> Trigrams are: 
 [('How', 'display', 'results'), ('display', 'results', 'data'), ('results', 'data', 'mining'), ('data', 'mining', 'affect'), ('mining', 'affect', 'user'), ('affect', 'user', '’'), ('user', '’', 'perspective'), ('’', 'perspective', 'make'), ('perspective', 'make', 'decision'), ('make', 'decision', '.')]

>> POS Tags are: 
 [('How', 'WRB'), ('display', 'JJ'), ('results', 'NNS'), ('data', 'NNS'), ('mining', 'NN'), ('affect', 'VBP'), ('user', 'NN'), ('’', 'VBP'), ('perspective', 'JJ'), ('make', 'NN'), ('decision', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['display results data mining', 'user', 'perspective make decision']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('How', 'how'), ('display', 'display'), ('results', 'result'), ('data', 'data'), ('mining', 'mine'), ('affect', 'affect'), ('user', 'user'), ('’', '’'), ('perspective', 'perspect'), ('make', 'make'), ('decision', 'decis'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('How', 'how'), ('display', 'display'), ('results', 'result'), ('data', 'data'), ('mining', 'mine'), ('affect', 'affect'), ('user', 'user'), ('’', '’'), ('perspective', 'perspect'), ('make', 'make'), ('decision', 'decis'), ('.', '.')]

>> Lemmatization: 
 [('How', 'How'), ('display', 'display'), ('results', 'result'), ('data', 'data'), ('mining', 'mining'), ('affect', 'affect'), ('user', 'user'), ('’', '’'), ('perspective', 'perspective'), ('make', 'make'), ('decision', 'decision'), ('.', '.')]


------------------- Sentence 5 -------------------

For instance, data mining can help  us find “type A influenza” at a particular region, but without the time series and flu virus  infected information of patients, the government could not recognize what situation  (pandemic or controlled) we are facing now so as to make appropriate responses to that.

>> Tokens are: 
 ['For', 'instance', ',', 'data', 'mining', 'help', 'us', 'find', '“', 'type', 'A', 'influenza', '”', 'particular', 'region', ',', 'without', 'time', 'series', 'flu', 'virus', 'infected', 'information', 'patients', ',', 'government', 'could', 'recognize', 'situation', '(', 'pandemic', 'controlled', ')', 'facing', 'make', 'appropriate', 'responses', '.']

>> Bigrams are: 
 [('For', 'instance'), ('instance', ','), (',', 'data'), ('data', 'mining'), ('mining', 'help'), ('help', 'us'), ('us', 'find'), ('find', '“'), ('“', 'type'), ('type', 'A'), ('A', 'influenza'), ('influenza', '”'), ('”', 'particular'), ('particular', 'region'), ('region', ','), (',', 'without'), ('without', 'time'), ('time', 'series'), ('series', 'flu'), ('flu', 'virus'), ('virus', 'infected'), ('infected', 'information'), ('information', 'patients'), ('patients', ','), (',', 'government'), ('government', 'could'), ('could', 'recognize'), ('recognize', 'situation'), ('situation', '('), ('(', 'pandemic'), ('pandemic', 'controlled'), ('controlled', ')'), (')', 'facing'), ('facing', 'make'), ('make', 'appropriate'), ('appropriate', 'responses'), ('responses', '.')]

>> Trigrams are: 
 [('For', 'instance', ','), ('instance', ',', 'data'), (',', 'data', 'mining'), ('data', 'mining', 'help'), ('mining', 'help', 'us'), ('help', 'us', 'find'), ('us', 'find', '“'), ('find', '“', 'type'), ('“', 'type', 'A'), ('type', 'A', 'influenza'), ('A', 'influenza', '”'), ('influenza', '”', 'particular'), ('”', 'particular', 'region'), ('particular', 'region', ','), ('region', ',', 'without'), (',', 'without', 'time'), ('without', 'time', 'series'), ('time', 'series', 'flu'), ('series', 'flu', 'virus'), ('flu', 'virus', 'infected'), ('virus', 'infected', 'information'), ('infected', 'information', 'patients'), ('information', 'patients', ','), ('patients', ',', 'government'), (',', 'government', 'could'), ('government', 'could', 'recognize'), ('could', 'recognize', 'situation'), ('recognize', 'situation', '('), ('situation', '(', 'pandemic'), ('(', 'pandemic', 'controlled'), ('pandemic', 'controlled', ')'), ('controlled', ')', 'facing'), (')', 'facing', 'make'), ('facing', 'make', 'appropriate'), ('make', 'appropriate', 'responses'), ('appropriate', 'responses', '.')]

>> POS Tags are: 
 [('For', 'IN'), ('instance', 'NN'), (',', ','), ('data', 'NNS'), ('mining', 'NN'), ('help', 'VBP'), ('us', 'PRP'), ('find', 'VB'), ('“', 'JJ'), ('type', 'NN'), ('A', 'NNP'), ('influenza', 'NN'), ('”', 'NNP'), ('particular', 'JJ'), ('region', 'NN'), (',', ','), ('without', 'IN'), ('time', 'NN'), ('series', 'NN'), ('flu', 'VBP'), ('virus', 'NN'), ('infected', 'VBN'), ('information', 'NN'), ('patients', 'NNS'), (',', ','), ('government', 'NN'), ('could', 'MD'), ('recognize', 'VB'), ('situation', 'NN'), ('(', '('), ('pandemic', 'JJ'), ('controlled', 'VBN'), (')', ')'), ('facing', 'VBG'), ('make', 'VB'), ('appropriate', 'JJ'), ('responses', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['instance', 'data mining', '“ type A influenza ”', 'particular region', 'time series', 'virus', 'information patients', 'government', 'situation', 'appropriate responses']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('For', 'for'), ('instance', 'instanc'), (',', ','), ('data', 'data'), ('mining', 'mine'), ('help', 'help'), ('us', 'us'), ('find', 'find'), ('“', '“'), ('type', 'type'), ('A', 'a'), ('influenza', 'influenza'), ('”', '”'), ('particular', 'particular'), ('region', 'region'), (',', ','), ('without', 'without'), ('time', 'time'), ('series', 'seri'), ('flu', 'flu'), ('virus', 'viru'), ('infected', 'infect'), ('information', 'inform'), ('patients', 'patient'), (',', ','), ('government', 'govern'), ('could', 'could'), ('recognize', 'recogn'), ('situation', 'situat'), ('(', '('), ('pandemic', 'pandem'), ('controlled', 'control'), (')', ')'), ('facing', 'face'), ('make', 'make'), ('appropriate', 'appropri'), ('responses', 'respons'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('For', 'for'), ('instance', 'instanc'), (',', ','), ('data', 'data'), ('mining', 'mine'), ('help', 'help'), ('us', 'us'), ('find', 'find'), ('“', '“'), ('type', 'type'), ('A', 'a'), ('influenza', 'influenza'), ('”', '”'), ('particular', 'particular'), ('region', 'region'), (',', ','), ('without', 'without'), ('time', 'time'), ('series', 'seri'), ('flu', 'flu'), ('virus', 'virus'), ('infected', 'infect'), ('information', 'inform'), ('patients', 'patient'), (',', ','), ('government', 'govern'), ('could', 'could'), ('recognize', 'recogn'), ('situation', 'situat'), ('(', '('), ('pandemic', 'pandem'), ('controlled', 'control'), (')', ')'), ('facing', 'face'), ('make', 'make'), ('appropriate', 'appropri'), ('responses', 'respons'), ('.', '.')]

>> Lemmatization: 
 [('For', 'For'), ('instance', 'instance'), (',', ','), ('data', 'data'), ('mining', 'mining'), ('help', 'help'), ('us', 'u'), ('find', 'find'), ('“', '“'), ('type', 'type'), ('A', 'A'), ('influenza', 'influenza'), ('”', '”'), ('particular', 'particular'), ('region', 'region'), (',', ','), ('without', 'without'), ('time', 'time'), ('series', 'series'), ('flu', 'flu'), ('virus', 'virus'), ('infected', 'infected'), ('information', 'information'), ('patients', 'patient'), (',', ','), ('government', 'government'), ('could', 'could'), ('recognize', 'recognize'), ('situation', 'situation'), ('(', '('), ('pandemic', 'pandemic'), ('controlled', 'controlled'), (')', ')'), ('facing', 'facing'), ('make', 'make'), ('appropriate', 'appropriate'), ('responses', 'response'), ('.', '.')]


------------------- Sentence 6 -------------------

For this reason, a better solution to merge the information from different sources and  mining algorithm results will be useful to let the user make the right decision.

>> Tokens are: 
 ['For', 'reason', ',', 'better', 'solution', 'merge', 'information', 'different', 'sources', 'mining', 'algorithm', 'results', 'useful', 'let', 'user', 'make', 'right', 'decision', '.']

>> Bigrams are: 
 [('For', 'reason'), ('reason', ','), (',', 'better'), ('better', 'solution'), ('solution', 'merge'), ('merge', 'information'), ('information', 'different'), ('different', 'sources'), ('sources', 'mining'), ('mining', 'algorithm'), ('algorithm', 'results'), ('results', 'useful'), ('useful', 'let'), ('let', 'user'), ('user', 'make'), ('make', 'right'), ('right', 'decision'), ('decision', '.')]

>> Trigrams are: 
 [('For', 'reason', ','), ('reason', ',', 'better'), (',', 'better', 'solution'), ('better', 'solution', 'merge'), ('solution', 'merge', 'information'), ('merge', 'information', 'different'), ('information', 'different', 'sources'), ('different', 'sources', 'mining'), ('sources', 'mining', 'algorithm'), ('mining', 'algorithm', 'results'), ('algorithm', 'results', 'useful'), ('results', 'useful', 'let'), ('useful', 'let', 'user'), ('let', 'user', 'make'), ('user', 'make', 'right'), ('make', 'right', 'decision'), ('right', 'decision', '.')]

>> POS Tags are: 
 [('For', 'IN'), ('reason', 'NN'), (',', ','), ('better', 'JJR'), ('solution', 'NN'), ('merge', 'NN'), ('information', 'NN'), ('different', 'JJ'), ('sources', 'NNS'), ('mining', 'VBG'), ('algorithm', 'JJ'), ('results', 'NNS'), ('useful', 'JJ'), ('let', 'VBP'), ('user', 'JJ'), ('make', 'VB'), ('right', 'JJ'), ('decision', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['reason', 'solution merge information', 'different sources', 'algorithm results', 'right decision']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('For', 'for'), ('reason', 'reason'), (',', ','), ('better', 'better'), ('solution', 'solut'), ('merge', 'merg'), ('information', 'inform'), ('different', 'differ'), ('sources', 'sourc'), ('mining', 'mine'), ('algorithm', 'algorithm'), ('results', 'result'), ('useful', 'use'), ('let', 'let'), ('user', 'user'), ('make', 'make'), ('right', 'right'), ('decision', 'decis'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('For', 'for'), ('reason', 'reason'), (',', ','), ('better', 'better'), ('solution', 'solut'), ('merge', 'merg'), ('information', 'inform'), ('different', 'differ'), ('sources', 'sourc'), ('mining', 'mine'), ('algorithm', 'algorithm'), ('results', 'result'), ('useful', 'use'), ('let', 'let'), ('user', 'user'), ('make', 'make'), ('right', 'right'), ('decision', 'decis'), ('.', '.')]

>> Lemmatization: 
 [('For', 'For'), ('reason', 'reason'), (',', ','), ('better', 'better'), ('solution', 'solution'), ('merge', 'merge'), ('information', 'information'), ('different', 'different'), ('sources', 'source'), ('mining', 'mining'), ('algorithm', 'algorithm'), ('results', 'result'), ('useful', 'useful'), ('let', 'let'), ('user', 'user'), ('make', 'make'), ('right', 'right'), ('decision', 'decision'), ('.', '.')]



========================================== PARAGRAPH 130 ===========================================

Summary 

------------------- Sentence 1 -------------------

Summary

>> Tokens are: 
 ['Summary']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Summary', 'JJ')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Summary', 'summari')]

>> Stemming using Snowball Stemmer: 
 [('Summary', 'summari')]

>> Lemmatization: 
 [('Summary', 'Summary')]



========================================== PARAGRAPH 131 ===========================================

Since the problems of handling and analyzing large-scale and complex input data always  exist in data analytics, several efficient analysis methods were presented to acceler- ate the computation time or to reduce the memory cost for the KDD process, as shown  in Table  2. The study of [42] shows that the basic mathematical concepts (i.e.-, triangle  

------------------- Sentence 1 -------------------

Since the problems of handling and analyzing large-scale and complex input data always  exist in data analytics, several efficient analysis methods were presented to acceler- ate the computation time or to reduce the memory cost for the KDD process, as shown  in Table  2.

>> Tokens are: 
 ['Since', 'problems', 'handling', 'analyzing', 'large-scale', 'complex', 'input', 'data', 'always', 'exist', 'data', 'analytics', ',', 'several', 'efficient', 'analysis', 'methods', 'presented', 'acceler-', 'ate', 'computation', 'time', 'reduce', 'memory', 'cost', 'KDD', 'process', ',', 'shown', 'Table', '2', '.']

>> Bigrams are: 
 [('Since', 'problems'), ('problems', 'handling'), ('handling', 'analyzing'), ('analyzing', 'large-scale'), ('large-scale', 'complex'), ('complex', 'input'), ('input', 'data'), ('data', 'always'), ('always', 'exist'), ('exist', 'data'), ('data', 'analytics'), ('analytics', ','), (',', 'several'), ('several', 'efficient'), ('efficient', 'analysis'), ('analysis', 'methods'), ('methods', 'presented'), ('presented', 'acceler-'), ('acceler-', 'ate'), ('ate', 'computation'), ('computation', 'time'), ('time', 'reduce'), ('reduce', 'memory'), ('memory', 'cost'), ('cost', 'KDD'), ('KDD', 'process'), ('process', ','), (',', 'shown'), ('shown', 'Table'), ('Table', '2'), ('2', '.')]

>> Trigrams are: 
 [('Since', 'problems', 'handling'), ('problems', 'handling', 'analyzing'), ('handling', 'analyzing', 'large-scale'), ('analyzing', 'large-scale', 'complex'), ('large-scale', 'complex', 'input'), ('complex', 'input', 'data'), ('input', 'data', 'always'), ('data', 'always', 'exist'), ('always', 'exist', 'data'), ('exist', 'data', 'analytics'), ('data', 'analytics', ','), ('analytics', ',', 'several'), (',', 'several', 'efficient'), ('several', 'efficient', 'analysis'), ('efficient', 'analysis', 'methods'), ('analysis', 'methods', 'presented'), ('methods', 'presented', 'acceler-'), ('presented', 'acceler-', 'ate'), ('acceler-', 'ate', 'computation'), ('ate', 'computation', 'time'), ('computation', 'time', 'reduce'), ('time', 'reduce', 'memory'), ('reduce', 'memory', 'cost'), ('memory', 'cost', 'KDD'), ('cost', 'KDD', 'process'), ('KDD', 'process', ','), ('process', ',', 'shown'), (',', 'shown', 'Table'), ('shown', 'Table', '2'), ('Table', '2', '.')]

>> POS Tags are: 
 [('Since', 'IN'), ('problems', 'NNS'), ('handling', 'VBG'), ('analyzing', 'VBG'), ('large-scale', 'JJ'), ('complex', 'JJ'), ('input', 'NN'), ('data', 'NNS'), ('always', 'RB'), ('exist', 'VBP'), ('data', 'NNS'), ('analytics', 'NNS'), (',', ','), ('several', 'JJ'), ('efficient', 'JJ'), ('analysis', 'NN'), ('methods', 'NNS'), ('presented', 'VBD'), ('acceler-', 'JJ'), ('ate', 'JJ'), ('computation', 'NN'), ('time', 'NN'), ('reduce', 'VB'), ('memory', 'NN'), ('cost', 'NN'), ('KDD', 'NNP'), ('process', 'NN'), (',', ','), ('shown', 'VBN'), ('Table', 'JJ'), ('2', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['problems', 'large-scale complex input data', 'data analytics', 'several efficient analysis methods', 'acceler- ate computation time', 'memory cost KDD process']

>> Named Entities are: 
 [('ORGANIZATION', 'KDD')] 

>> Stemming using Porter Stemmer: 
 [('Since', 'sinc'), ('problems', 'problem'), ('handling', 'handl'), ('analyzing', 'analyz'), ('large-scale', 'large-scal'), ('complex', 'complex'), ('input', 'input'), ('data', 'data'), ('always', 'alway'), ('exist', 'exist'), ('data', 'data'), ('analytics', 'analyt'), (',', ','), ('several', 'sever'), ('efficient', 'effici'), ('analysis', 'analysi'), ('methods', 'method'), ('presented', 'present'), ('acceler-', 'acceler-'), ('ate', 'ate'), ('computation', 'comput'), ('time', 'time'), ('reduce', 'reduc'), ('memory', 'memori'), ('cost', 'cost'), ('KDD', 'kdd'), ('process', 'process'), (',', ','), ('shown', 'shown'), ('Table', 'tabl'), ('2', '2'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Since', 'sinc'), ('problems', 'problem'), ('handling', 'handl'), ('analyzing', 'analyz'), ('large-scale', 'large-scal'), ('complex', 'complex'), ('input', 'input'), ('data', 'data'), ('always', 'alway'), ('exist', 'exist'), ('data', 'data'), ('analytics', 'analyt'), (',', ','), ('several', 'sever'), ('efficient', 'effici'), ('analysis', 'analysi'), ('methods', 'method'), ('presented', 'present'), ('acceler-', 'acceler-'), ('ate', 'ate'), ('computation', 'comput'), ('time', 'time'), ('reduce', 'reduc'), ('memory', 'memori'), ('cost', 'cost'), ('KDD', 'kdd'), ('process', 'process'), (',', ','), ('shown', 'shown'), ('Table', 'tabl'), ('2', '2'), ('.', '.')]

>> Lemmatization: 
 [('Since', 'Since'), ('problems', 'problem'), ('handling', 'handling'), ('analyzing', 'analyzing'), ('large-scale', 'large-scale'), ('complex', 'complex'), ('input', 'input'), ('data', 'data'), ('always', 'always'), ('exist', 'exist'), ('data', 'data'), ('analytics', 'analytics'), (',', ','), ('several', 'several'), ('efficient', 'efficient'), ('analysis', 'analysis'), ('methods', 'method'), ('presented', 'presented'), ('acceler-', 'acceler-'), ('ate', 'ate'), ('computation', 'computation'), ('time', 'time'), ('reduce', 'reduce'), ('memory', 'memory'), ('cost', 'cost'), ('KDD', 'KDD'), ('process', 'process'), (',', ','), ('shown', 'shown'), ('Table', 'Table'), ('2', '2'), ('.', '.')]


------------------- Sentence 2 -------------------

The study of [42] shows that the basic mathematical concepts (i.e.-, triangle

>> Tokens are: 
 ['The', 'study', '[', '42', ']', 'shows', 'basic', 'mathematical', 'concepts', '(', 'i.e.-', ',', 'triangle']

>> Bigrams are: 
 [('The', 'study'), ('study', '['), ('[', '42'), ('42', ']'), (']', 'shows'), ('shows', 'basic'), ('basic', 'mathematical'), ('mathematical', 'concepts'), ('concepts', '('), ('(', 'i.e.-'), ('i.e.-', ','), (',', 'triangle')]

>> Trigrams are: 
 [('The', 'study', '['), ('study', '[', '42'), ('[', '42', ']'), ('42', ']', 'shows'), (']', 'shows', 'basic'), ('shows', 'basic', 'mathematical'), ('basic', 'mathematical', 'concepts'), ('mathematical', 'concepts', '('), ('concepts', '(', 'i.e.-'), ('(', 'i.e.-', ','), ('i.e.-', ',', 'triangle')]

>> POS Tags are: 
 [('The', 'DT'), ('study', 'NN'), ('[', 'VBD'), ('42', 'CD'), (']', 'NN'), ('shows', 'NNS'), ('basic', 'JJ'), ('mathematical', 'JJ'), ('concepts', 'NNS'), ('(', '('), ('i.e.-', 'JJ'), (',', ','), ('triangle', 'NN')]

>> Noun Phrases are: 
 ['The study', '] shows', 'basic mathematical concepts', 'triangle']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('study', 'studi'), ('[', '['), ('42', '42'), (']', ']'), ('shows', 'show'), ('basic', 'basic'), ('mathematical', 'mathemat'), ('concepts', 'concept'), ('(', '('), ('i.e.-', 'i.e.-'), (',', ','), ('triangle', 'triangl')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('study', 'studi'), ('[', '['), ('42', '42'), (']', ']'), ('shows', 'show'), ('basic', 'basic'), ('mathematical', 'mathemat'), ('concepts', 'concept'), ('(', '('), ('i.e.-', 'i.e.-'), (',', ','), ('triangle', 'triangl')]

>> Lemmatization: 
 [('The', 'The'), ('study', 'study'), ('[', '['), ('42', '42'), (']', ']'), ('shows', 'show'), ('basic', 'basic'), ('mathematical', 'mathematical'), ('concepts', 'concept'), ('(', '('), ('i.e.-', 'i.e.-'), (',', ','), ('triangle', 'triangle')]



========================================== PARAGRAPH 132 ===========================================

(7)F = 2pr 

------------------- Sentence 1 -------------------

(7)F = 2pr

>> Tokens are: 
 ['(', '7', ')', 'F', '=', '2pr']

>> Bigrams are: 
 [('(', '7'), ('7', ')'), (')', 'F'), ('F', '='), ('=', '2pr')]

>> Trigrams are: 
 [('(', '7', ')'), ('7', ')', 'F'), (')', 'F', '='), ('F', '=', '2pr')]

>> POS Tags are: 
 [('(', '('), ('7', 'CD'), (')', ')'), ('F', 'NNP'), ('=', '$'), ('2pr', 'CD')]

>> Noun Phrases are: 
 ['F']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('7', '7'), (')', ')'), ('F', 'f'), ('=', '='), ('2pr', '2pr')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('7', '7'), (')', ')'), ('F', 'f'), ('=', '='), ('2pr', '2pr')]

>> Lemmatization: 
 [('(', '('), ('7', '7'), (')', ')'), ('F', 'F'), ('=', '='), ('2pr', '2pr')]



========================================== PARAGRAPH 133 ===========================================

p+ r . 

------------------- Sentence 1 -------------------

p+ r .

>> Tokens are: 
 ['p+', 'r', '.']

>> Bigrams are: 
 [('p+', 'r'), ('r', '.')]

>> Trigrams are: 
 [('p+', 'r', '.')]

>> POS Tags are: 
 [('p+', 'NN'), ('r', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['p+ r']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('p+', 'p+'), ('r', 'r'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('p+', 'p+'), ('r', 'r'), ('.', '.')]

>> Lemmatization: 
 [('p+', 'p+'), ('r', 'r'), ('.', '.')]



========================================== PARAGRAPH 134 ===========================================

Table 1 Confusion matrix of a classifier [37] 

------------------- Sentence 1 -------------------

Table 1 Confusion matrix of a classifier [37]

>> Tokens are: 
 ['Table', '1', 'Confusion', 'matrix', 'classifier', '[', '37', ']']

>> Bigrams are: 
 [('Table', '1'), ('1', 'Confusion'), ('Confusion', 'matrix'), ('matrix', 'classifier'), ('classifier', '['), ('[', '37'), ('37', ']')]

>> Trigrams are: 
 [('Table', '1', 'Confusion'), ('1', 'Confusion', 'matrix'), ('Confusion', 'matrix', 'classifier'), ('matrix', 'classifier', '['), ('classifier', '[', '37'), ('[', '37', ']')]

>> POS Tags are: 
 [('Table', 'JJ'), ('1', 'CD'), ('Confusion', 'NNP'), ('matrix', 'FW'), ('classifier', 'JJR'), ('[', '$'), ('37', 'CD'), (']', 'NN')]

>> Noun Phrases are: 
 ['Confusion', ']']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Table', 'tabl'), ('1', '1'), ('Confusion', 'confus'), ('matrix', 'matrix'), ('classifier', 'classifi'), ('[', '['), ('37', '37'), (']', ']')]

>> Stemming using Snowball Stemmer: 
 [('Table', 'tabl'), ('1', '1'), ('Confusion', 'confus'), ('matrix', 'matrix'), ('classifier', 'classifi'), ('[', '['), ('37', '37'), (']', ']')]

>> Lemmatization: 
 [('Table', 'Table'), ('1', '1'), ('Confusion', 'Confusion'), ('matrix', 'matrix'), ('classifier', 'classifier'), ('[', '['), ('37', '37'), (']', ']')]



========================================== PARAGRAPH 135 ===========================================

Classified positive Classified negative 

------------------- Sentence 1 -------------------

Classified positive Classified negative

>> Tokens are: 
 ['Classified', 'positive', 'Classified', 'negative']

>> Bigrams are: 
 [('Classified', 'positive'), ('positive', 'Classified'), ('Classified', 'negative')]

>> Trigrams are: 
 [('Classified', 'positive', 'Classified'), ('positive', 'Classified', 'negative')]

>> POS Tags are: 
 [('Classified', 'NNP'), ('positive', 'JJ'), ('Classified', 'NNP'), ('negative', 'NN')]

>> Noun Phrases are: 
 ['Classified', 'positive Classified negative']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Classified', 'classifi'), ('positive', 'posit'), ('Classified', 'classifi'), ('negative', 'neg')]

>> Stemming using Snowball Stemmer: 
 [('Classified', 'classifi'), ('positive', 'posit'), ('Classified', 'classifi'), ('negative', 'negat')]

>> Lemmatization: 
 [('Classified', 'Classified'), ('positive', 'positive'), ('Classified', 'Classified'), ('negative', 'negative')]



========================================== PARAGRAPH 136 ===========================================

Actual positive TP FN 

------------------- Sentence 1 -------------------

Actual positive TP FN

>> Tokens are: 
 ['Actual', 'positive', 'TP', 'FN']

>> Bigrams are: 
 [('Actual', 'positive'), ('positive', 'TP'), ('TP', 'FN')]

>> Trigrams are: 
 [('Actual', 'positive', 'TP'), ('positive', 'TP', 'FN')]

>> POS Tags are: 
 [('Actual', 'JJ'), ('positive', 'JJ'), ('TP', 'NNP'), ('FN', 'NNP')]

>> Noun Phrases are: 
 ['Actual positive TP FN']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Actual', 'actual'), ('positive', 'posit'), ('TP', 'tp'), ('FN', 'fn')]

>> Stemming using Snowball Stemmer: 
 [('Actual', 'actual'), ('positive', 'posit'), ('TP', 'tp'), ('FN', 'fn')]

>> Lemmatization: 
 [('Actual', 'Actual'), ('positive', 'positive'), ('TP', 'TP'), ('FN', 'FN')]



========================================== PARAGRAPH 137 ===========================================

Actual negative FP TN

------------------- Sentence 1 -------------------

Actual negative FP TN

>> Tokens are: 
 ['Actual', 'negative', 'FP', 'TN']

>> Bigrams are: 
 [('Actual', 'negative'), ('negative', 'FP'), ('FP', 'TN')]

>> Trigrams are: 
 [('Actual', 'negative', 'FP'), ('negative', 'FP', 'TN')]

>> POS Tags are: 
 [('Actual', 'JJ'), ('negative', 'JJ'), ('FP', 'NNP'), ('TN', 'NNP')]

>> Noun Phrases are: 
 ['Actual negative FP TN']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Actual', 'actual'), ('negative', 'neg'), ('FP', 'fp'), ('TN', 'tn')]

>> Stemming using Snowball Stemmer: 
 [('Actual', 'actual'), ('negative', 'negat'), ('FP', 'fp'), ('TN', 'tn')]

>> Lemmatization: 
 [('Actual', 'Actual'), ('negative', 'negative'), ('FP', 'FP'), ('TN', 'TN')]



========================================== PARAGRAPH 138 ===========================================

Page 8 of 32Tsai et al. Journal of Big Data  (2015) 2:21  

------------------- Sentence 1 -------------------

Page 8 of 32Tsai et al.

>> Tokens are: 
 ['Page', '8', '32Tsai', 'et', 'al', '.']

>> Bigrams are: 
 [('Page', '8'), ('8', '32Tsai'), ('32Tsai', 'et'), ('et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('Page', '8', '32Tsai'), ('8', '32Tsai', 'et'), ('32Tsai', 'et', 'al'), ('et', 'al', '.')]

>> POS Tags are: 
 [('Page', 'NN'), ('8', 'CD'), ('32Tsai', 'CD'), ('et', 'NN'), ('al', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Page', 'et al']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Page', 'page'), ('8', '8'), ('32Tsai', '32tsai'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Page', 'page'), ('8', '8'), ('32Tsai', '32tsai'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('Page', 'Page'), ('8', '8'), ('32Tsai', '32Tsai'), ('et', 'et'), ('al', 'al'), ('.', '.')]


------------------- Sentence 2 -------------------

Journal of Big Data  (2015) 2:21

>> Tokens are: 
 ['Journal', 'Big', 'Data', '(', '2015', ')', '2:21']

>> Bigrams are: 
 [('Journal', 'Big'), ('Big', 'Data'), ('Data', '('), ('(', '2015'), ('2015', ')'), (')', '2:21')]

>> Trigrams are: 
 [('Journal', 'Big', 'Data'), ('Big', 'Data', '('), ('Data', '(', '2015'), ('(', '2015', ')'), ('2015', ')', '2:21')]

>> POS Tags are: 
 [('Journal', 'NNP'), ('Big', 'NNP'), ('Data', 'NNP'), ('(', '('), ('2015', 'CD'), (')', ')'), ('2:21', 'CD')]

>> Noun Phrases are: 
 ['Journal Big Data']

>> Named Entities are: 
 [('PERSON', 'Journal')] 

>> Stemming using Porter Stemmer: 
 [('Journal', 'journal'), ('Big', 'big'), ('Data', 'data'), ('(', '('), ('2015', '2015'), (')', ')'), ('2:21', '2:21')]

>> Stemming using Snowball Stemmer: 
 [('Journal', 'journal'), ('Big', 'big'), ('Data', 'data'), ('(', '('), ('2015', '2015'), (')', ')'), ('2:21', '2:21')]

>> Lemmatization: 
 [('Journal', 'Journal'), ('Big', 'Big'), ('Data', 'Data'), ('(', '('), ('2015', '2015'), (')', ')'), ('2:21', '2:21')]



========================================== PARAGRAPH 139 ===========================================

inequality) can be used to reduce the computation cost of a clustering algorithm. Another  study [43] shows that the new technologies (i.e.-, distributed computing by GPU) can also  be used to reduce the computation time of data analysis method. In addition to the well- known improved methods for these analysis methods (e.g.-, triangle inequality or distrib- uted computing), a large proportion of studies designed their efficient methods based on  the characteristics of mining algorithms or problem itself, which can be found in [32, 44,  45], and so forth. This kind of improved methods typically was designed for solving the  drawback of the mining algorithms or using different ways to solve the mining problem.  These situations can be found in most association rules and sequential patterns problems  because the original assumption of these problems is for the analysis of large-scale data- set. Since the earlier frequent pattern algorithm (e.g.-, apriori algorithm) needs to scan the  whole dataset many times which is computationally very expensive. How to reduce the  number of times the whole dataset is scanned so as to save the computation cost is one  of the most important things in all the frequent pattern studies. The similar situation also  exists in data clustering and classification studies because the design concept of earlier  algorithms, such as mining the patterns on-the-fly [46], mining partial patterns at differ- ent stages [47], and reducing the number of times the whole dataset is scanned [32], are  therefore presented to enhance the performance of these mining algorithms. Since some  of the data mining problems are NP-hard [48] or the solution space is very large, several  recent studies [23, 49] have attempted to use metaheuristic algorithm as the mining algo- rithm to get the approximate solution within a reasonable time. 

------------------- Sentence 1 -------------------

inequality) can be used to reduce the computation cost of a clustering algorithm.

>> Tokens are: 
 ['inequality', ')', 'used', 'reduce', 'computation', 'cost', 'clustering', 'algorithm', '.']

>> Bigrams are: 
 [('inequality', ')'), (')', 'used'), ('used', 'reduce'), ('reduce', 'computation'), ('computation', 'cost'), ('cost', 'clustering'), ('clustering', 'algorithm'), ('algorithm', '.')]

>> Trigrams are: 
 [('inequality', ')', 'used'), (')', 'used', 'reduce'), ('used', 'reduce', 'computation'), ('reduce', 'computation', 'cost'), ('computation', 'cost', 'clustering'), ('cost', 'clustering', 'algorithm'), ('clustering', 'algorithm', '.')]

>> POS Tags are: 
 [('inequality', 'NN'), (')', ')'), ('used', 'VBD'), ('reduce', 'VB'), ('computation', 'NN'), ('cost', 'NN'), ('clustering', 'VBG'), ('algorithm', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['inequality', 'computation cost', 'algorithm']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('inequality', 'inequ'), (')', ')'), ('used', 'use'), ('reduce', 'reduc'), ('computation', 'comput'), ('cost', 'cost'), ('clustering', 'cluster'), ('algorithm', 'algorithm'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('inequality', 'inequ'), (')', ')'), ('used', 'use'), ('reduce', 'reduc'), ('computation', 'comput'), ('cost', 'cost'), ('clustering', 'cluster'), ('algorithm', 'algorithm'), ('.', '.')]

>> Lemmatization: 
 [('inequality', 'inequality'), (')', ')'), ('used', 'used'), ('reduce', 'reduce'), ('computation', 'computation'), ('cost', 'cost'), ('clustering', 'clustering'), ('algorithm', 'algorithm'), ('.', '.')]


------------------- Sentence 2 -------------------

Another  study [43] shows that the new technologies (i.e.-, distributed computing by GPU) can also  be used to reduce the computation time of data analysis method.

>> Tokens are: 
 ['Another', 'study', '[', '43', ']', 'shows', 'new', 'technologies', '(', 'i.e.-', ',', 'distributed', 'computing', 'GPU', ')', 'also', 'used', 'reduce', 'computation', 'time', 'data', 'analysis', 'method', '.']

>> Bigrams are: 
 [('Another', 'study'), ('study', '['), ('[', '43'), ('43', ']'), (']', 'shows'), ('shows', 'new'), ('new', 'technologies'), ('technologies', '('), ('(', 'i.e.-'), ('i.e.-', ','), (',', 'distributed'), ('distributed', 'computing'), ('computing', 'GPU'), ('GPU', ')'), (')', 'also'), ('also', 'used'), ('used', 'reduce'), ('reduce', 'computation'), ('computation', 'time'), ('time', 'data'), ('data', 'analysis'), ('analysis', 'method'), ('method', '.')]

>> Trigrams are: 
 [('Another', 'study', '['), ('study', '[', '43'), ('[', '43', ']'), ('43', ']', 'shows'), (']', 'shows', 'new'), ('shows', 'new', 'technologies'), ('new', 'technologies', '('), ('technologies', '(', 'i.e.-'), ('(', 'i.e.-', ','), ('i.e.-', ',', 'distributed'), (',', 'distributed', 'computing'), ('distributed', 'computing', 'GPU'), ('computing', 'GPU', ')'), ('GPU', ')', 'also'), (')', 'also', 'used'), ('also', 'used', 'reduce'), ('used', 'reduce', 'computation'), ('reduce', 'computation', 'time'), ('computation', 'time', 'data'), ('time', 'data', 'analysis'), ('data', 'analysis', 'method'), ('analysis', 'method', '.')]

>> POS Tags are: 
 [('Another', 'DT'), ('study', 'NN'), ('[', 'VBD'), ('43', 'CD'), (']', 'NN'), ('shows', 'VBZ'), ('new', 'JJ'), ('technologies', 'NNS'), ('(', '('), ('i.e.-', 'JJ'), (',', ','), ('distributed', 'VBD'), ('computing', 'VBG'), ('GPU', 'NNP'), (')', ')'), ('also', 'RB'), ('used', 'VBD'), ('reduce', 'VB'), ('computation', 'NN'), ('time', 'NN'), ('data', 'NNS'), ('analysis', 'NN'), ('method', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Another study', ']', 'new technologies', 'GPU', 'computation time data analysis method']

>> Named Entities are: 
 [('ORGANIZATION', 'GPU')] 

>> Stemming using Porter Stemmer: 
 [('Another', 'anoth'), ('study', 'studi'), ('[', '['), ('43', '43'), (']', ']'), ('shows', 'show'), ('new', 'new'), ('technologies', 'technolog'), ('(', '('), ('i.e.-', 'i.e.-'), (',', ','), ('distributed', 'distribut'), ('computing', 'comput'), ('GPU', 'gpu'), (')', ')'), ('also', 'also'), ('used', 'use'), ('reduce', 'reduc'), ('computation', 'comput'), ('time', 'time'), ('data', 'data'), ('analysis', 'analysi'), ('method', 'method'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Another', 'anoth'), ('study', 'studi'), ('[', '['), ('43', '43'), (']', ']'), ('shows', 'show'), ('new', 'new'), ('technologies', 'technolog'), ('(', '('), ('i.e.-', 'i.e.-'), (',', ','), ('distributed', 'distribut'), ('computing', 'comput'), ('GPU', 'gpu'), (')', ')'), ('also', 'also'), ('used', 'use'), ('reduce', 'reduc'), ('computation', 'comput'), ('time', 'time'), ('data', 'data'), ('analysis', 'analysi'), ('method', 'method'), ('.', '.')]

>> Lemmatization: 
 [('Another', 'Another'), ('study', 'study'), ('[', '['), ('43', '43'), (']', ']'), ('shows', 'show'), ('new', 'new'), ('technologies', 'technology'), ('(', '('), ('i.e.-', 'i.e.-'), (',', ','), ('distributed', 'distributed'), ('computing', 'computing'), ('GPU', 'GPU'), (')', ')'), ('also', 'also'), ('used', 'used'), ('reduce', 'reduce'), ('computation', 'computation'), ('time', 'time'), ('data', 'data'), ('analysis', 'analysis'), ('method', 'method'), ('.', '.')]


------------------- Sentence 3 -------------------

In addition to the well- known improved methods for these analysis methods (e.g.-, triangle inequality or distrib- uted computing), a large proportion of studies designed their efficient methods based on  the characteristics of mining algorithms or problem itself, which can be found in [32, 44,  45], and so forth.

>> Tokens are: 
 ['In', 'addition', 'well-', 'known', 'improved', 'methods', 'analysis', 'methods', '(', 'e.g.-', ',', 'triangle', 'inequality', 'distrib-', 'uted', 'computing', ')', ',', 'large', 'proportion', 'studies', 'designed', 'efficient', 'methods', 'based', 'characteristics', 'mining', 'algorithms', 'problem', ',', 'found', '[', '32', ',', '44', ',', '45', ']', ',', 'forth', '.']

>> Bigrams are: 
 [('In', 'addition'), ('addition', 'well-'), ('well-', 'known'), ('known', 'improved'), ('improved', 'methods'), ('methods', 'analysis'), ('analysis', 'methods'), ('methods', '('), ('(', 'e.g.-'), ('e.g.-', ','), (',', 'triangle'), ('triangle', 'inequality'), ('inequality', 'distrib-'), ('distrib-', 'uted'), ('uted', 'computing'), ('computing', ')'), (')', ','), (',', 'large'), ('large', 'proportion'), ('proportion', 'studies'), ('studies', 'designed'), ('designed', 'efficient'), ('efficient', 'methods'), ('methods', 'based'), ('based', 'characteristics'), ('characteristics', 'mining'), ('mining', 'algorithms'), ('algorithms', 'problem'), ('problem', ','), (',', 'found'), ('found', '['), ('[', '32'), ('32', ','), (',', '44'), ('44', ','), (',', '45'), ('45', ']'), (']', ','), (',', 'forth'), ('forth', '.')]

>> Trigrams are: 
 [('In', 'addition', 'well-'), ('addition', 'well-', 'known'), ('well-', 'known', 'improved'), ('known', 'improved', 'methods'), ('improved', 'methods', 'analysis'), ('methods', 'analysis', 'methods'), ('analysis', 'methods', '('), ('methods', '(', 'e.g.-'), ('(', 'e.g.-', ','), ('e.g.-', ',', 'triangle'), (',', 'triangle', 'inequality'), ('triangle', 'inequality', 'distrib-'), ('inequality', 'distrib-', 'uted'), ('distrib-', 'uted', 'computing'), ('uted', 'computing', ')'), ('computing', ')', ','), (')', ',', 'large'), (',', 'large', 'proportion'), ('large', 'proportion', 'studies'), ('proportion', 'studies', 'designed'), ('studies', 'designed', 'efficient'), ('designed', 'efficient', 'methods'), ('efficient', 'methods', 'based'), ('methods', 'based', 'characteristics'), ('based', 'characteristics', 'mining'), ('characteristics', 'mining', 'algorithms'), ('mining', 'algorithms', 'problem'), ('algorithms', 'problem', ','), ('problem', ',', 'found'), (',', 'found', '['), ('found', '[', '32'), ('[', '32', ','), ('32', ',', '44'), (',', '44', ','), ('44', ',', '45'), (',', '45', ']'), ('45', ']', ','), (']', ',', 'forth'), (',', 'forth', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('addition', 'NN'), ('well-', 'NN'), ('known', 'VBN'), ('improved', 'JJ'), ('methods', 'NNS'), ('analysis', 'NN'), ('methods', 'NNS'), ('(', '('), ('e.g.-', 'JJ'), (',', ','), ('triangle', 'JJ'), ('inequality', 'NN'), ('distrib-', 'NN'), ('uted', 'JJ'), ('computing', 'NN'), (')', ')'), (',', ','), ('large', 'JJ'), ('proportion', 'NN'), ('studies', 'NNS'), ('designed', 'VBN'), ('efficient', 'JJ'), ('methods', 'NNS'), ('based', 'VBN'), ('characteristics', 'NNS'), ('mining', 'VBG'), ('algorithms', 'NN'), ('problem', 'NN'), (',', ','), ('found', 'VBD'), ('[', 'RB'), ('32', 'CD'), (',', ','), ('44', 'CD'), (',', ','), ('45', 'CD'), (']', 'NN'), (',', ','), ('forth', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['addition well-', 'improved methods analysis methods', 'triangle inequality distrib-', 'uted computing', 'large proportion studies', 'efficient methods', 'characteristics', 'algorithms problem', ']', 'forth']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('addition', 'addit'), ('well-', 'well-'), ('known', 'known'), ('improved', 'improv'), ('methods', 'method'), ('analysis', 'analysi'), ('methods', 'method'), ('(', '('), ('e.g.-', 'e.g.-'), (',', ','), ('triangle', 'triangl'), ('inequality', 'inequ'), ('distrib-', 'distrib-'), ('uted', 'ute'), ('computing', 'comput'), (')', ')'), (',', ','), ('large', 'larg'), ('proportion', 'proport'), ('studies', 'studi'), ('designed', 'design'), ('efficient', 'effici'), ('methods', 'method'), ('based', 'base'), ('characteristics', 'characterist'), ('mining', 'mine'), ('algorithms', 'algorithm'), ('problem', 'problem'), (',', ','), ('found', 'found'), ('[', '['), ('32', '32'), (',', ','), ('44', '44'), (',', ','), ('45', '45'), (']', ']'), (',', ','), ('forth', 'forth'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('addition', 'addit'), ('well-', 'well-'), ('known', 'known'), ('improved', 'improv'), ('methods', 'method'), ('analysis', 'analysi'), ('methods', 'method'), ('(', '('), ('e.g.-', 'e.g.-'), (',', ','), ('triangle', 'triangl'), ('inequality', 'inequ'), ('distrib-', 'distrib-'), ('uted', 'ute'), ('computing', 'comput'), (')', ')'), (',', ','), ('large', 'larg'), ('proportion', 'proport'), ('studies', 'studi'), ('designed', 'design'), ('efficient', 'effici'), ('methods', 'method'), ('based', 'base'), ('characteristics', 'characterist'), ('mining', 'mine'), ('algorithms', 'algorithm'), ('problem', 'problem'), (',', ','), ('found', 'found'), ('[', '['), ('32', '32'), (',', ','), ('44', '44'), (',', ','), ('45', '45'), (']', ']'), (',', ','), ('forth', 'forth'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('addition', 'addition'), ('well-', 'well-'), ('known', 'known'), ('improved', 'improved'), ('methods', 'method'), ('analysis', 'analysis'), ('methods', 'method'), ('(', '('), ('e.g.-', 'e.g.-'), (',', ','), ('triangle', 'triangle'), ('inequality', 'inequality'), ('distrib-', 'distrib-'), ('uted', 'uted'), ('computing', 'computing'), (')', ')'), (',', ','), ('large', 'large'), ('proportion', 'proportion'), ('studies', 'study'), ('designed', 'designed'), ('efficient', 'efficient'), ('methods', 'method'), ('based', 'based'), ('characteristics', 'characteristic'), ('mining', 'mining'), ('algorithms', 'algorithm'), ('problem', 'problem'), (',', ','), ('found', 'found'), ('[', '['), ('32', '32'), (',', ','), ('44', '44'), (',', ','), ('45', '45'), (']', ']'), (',', ','), ('forth', 'forth'), ('.', '.')]


------------------- Sentence 4 -------------------

This kind of improved methods typically was designed for solving the  drawback of the mining algorithms or using different ways to solve the mining problem.

>> Tokens are: 
 ['This', 'kind', 'improved', 'methods', 'typically', 'designed', 'solving', 'drawback', 'mining', 'algorithms', 'using', 'different', 'ways', 'solve', 'mining', 'problem', '.']

>> Bigrams are: 
 [('This', 'kind'), ('kind', 'improved'), ('improved', 'methods'), ('methods', 'typically'), ('typically', 'designed'), ('designed', 'solving'), ('solving', 'drawback'), ('drawback', 'mining'), ('mining', 'algorithms'), ('algorithms', 'using'), ('using', 'different'), ('different', 'ways'), ('ways', 'solve'), ('solve', 'mining'), ('mining', 'problem'), ('problem', '.')]

>> Trigrams are: 
 [('This', 'kind', 'improved'), ('kind', 'improved', 'methods'), ('improved', 'methods', 'typically'), ('methods', 'typically', 'designed'), ('typically', 'designed', 'solving'), ('designed', 'solving', 'drawback'), ('solving', 'drawback', 'mining'), ('drawback', 'mining', 'algorithms'), ('mining', 'algorithms', 'using'), ('algorithms', 'using', 'different'), ('using', 'different', 'ways'), ('different', 'ways', 'solve'), ('ways', 'solve', 'mining'), ('solve', 'mining', 'problem'), ('mining', 'problem', '.')]

>> POS Tags are: 
 [('This', 'DT'), ('kind', 'NN'), ('improved', 'VBD'), ('methods', 'NNS'), ('typically', 'RB'), ('designed', 'VBN'), ('solving', 'VBG'), ('drawback', 'NN'), ('mining', 'NN'), ('algorithms', 'NN'), ('using', 'VBG'), ('different', 'JJ'), ('ways', 'NNS'), ('solve', 'VBP'), ('mining', 'NN'), ('problem', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['This kind', 'methods', 'drawback mining algorithms', 'different ways', 'mining problem']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('This', 'thi'), ('kind', 'kind'), ('improved', 'improv'), ('methods', 'method'), ('typically', 'typic'), ('designed', 'design'), ('solving', 'solv'), ('drawback', 'drawback'), ('mining', 'mine'), ('algorithms', 'algorithm'), ('using', 'use'), ('different', 'differ'), ('ways', 'way'), ('solve', 'solv'), ('mining', 'mine'), ('problem', 'problem'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('This', 'this'), ('kind', 'kind'), ('improved', 'improv'), ('methods', 'method'), ('typically', 'typic'), ('designed', 'design'), ('solving', 'solv'), ('drawback', 'drawback'), ('mining', 'mine'), ('algorithms', 'algorithm'), ('using', 'use'), ('different', 'differ'), ('ways', 'way'), ('solve', 'solv'), ('mining', 'mine'), ('problem', 'problem'), ('.', '.')]

>> Lemmatization: 
 [('This', 'This'), ('kind', 'kind'), ('improved', 'improved'), ('methods', 'method'), ('typically', 'typically'), ('designed', 'designed'), ('solving', 'solving'), ('drawback', 'drawback'), ('mining', 'mining'), ('algorithms', 'algorithm'), ('using', 'using'), ('different', 'different'), ('ways', 'way'), ('solve', 'solve'), ('mining', 'mining'), ('problem', 'problem'), ('.', '.')]


------------------- Sentence 5 -------------------

These situations can be found in most association rules and sequential patterns problems  because the original assumption of these problems is for the analysis of large-scale data- set.

>> Tokens are: 
 ['These', 'situations', 'found', 'association', 'rules', 'sequential', 'patterns', 'problems', 'original', 'assumption', 'problems', 'analysis', 'large-scale', 'data-', 'set', '.']

>> Bigrams are: 
 [('These', 'situations'), ('situations', 'found'), ('found', 'association'), ('association', 'rules'), ('rules', 'sequential'), ('sequential', 'patterns'), ('patterns', 'problems'), ('problems', 'original'), ('original', 'assumption'), ('assumption', 'problems'), ('problems', 'analysis'), ('analysis', 'large-scale'), ('large-scale', 'data-'), ('data-', 'set'), ('set', '.')]

>> Trigrams are: 
 [('These', 'situations', 'found'), ('situations', 'found', 'association'), ('found', 'association', 'rules'), ('association', 'rules', 'sequential'), ('rules', 'sequential', 'patterns'), ('sequential', 'patterns', 'problems'), ('patterns', 'problems', 'original'), ('problems', 'original', 'assumption'), ('original', 'assumption', 'problems'), ('assumption', 'problems', 'analysis'), ('problems', 'analysis', 'large-scale'), ('analysis', 'large-scale', 'data-'), ('large-scale', 'data-', 'set'), ('data-', 'set', '.')]

>> POS Tags are: 
 [('These', 'DT'), ('situations', 'NNS'), ('found', 'VBD'), ('association', 'NN'), ('rules', 'NNS'), ('sequential', 'JJ'), ('patterns', 'NNS'), ('problems', 'NNS'), ('original', 'JJ'), ('assumption', 'NN'), ('problems', 'NNS'), ('analysis', 'IN'), ('large-scale', 'JJ'), ('data-', 'JJ'), ('set', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['These situations', 'association rules', 'sequential patterns problems', 'original assumption problems', 'large-scale data- set']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('These', 'these'), ('situations', 'situat'), ('found', 'found'), ('association', 'associ'), ('rules', 'rule'), ('sequential', 'sequenti'), ('patterns', 'pattern'), ('problems', 'problem'), ('original', 'origin'), ('assumption', 'assumpt'), ('problems', 'problem'), ('analysis', 'analysi'), ('large-scale', 'large-scal'), ('data-', 'data-'), ('set', 'set'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('These', 'these'), ('situations', 'situat'), ('found', 'found'), ('association', 'associ'), ('rules', 'rule'), ('sequential', 'sequenti'), ('patterns', 'pattern'), ('problems', 'problem'), ('original', 'origin'), ('assumption', 'assumpt'), ('problems', 'problem'), ('analysis', 'analysi'), ('large-scale', 'large-scal'), ('data-', 'data-'), ('set', 'set'), ('.', '.')]

>> Lemmatization: 
 [('These', 'These'), ('situations', 'situation'), ('found', 'found'), ('association', 'association'), ('rules', 'rule'), ('sequential', 'sequential'), ('patterns', 'pattern'), ('problems', 'problem'), ('original', 'original'), ('assumption', 'assumption'), ('problems', 'problem'), ('analysis', 'analysis'), ('large-scale', 'large-scale'), ('data-', 'data-'), ('set', 'set'), ('.', '.')]


------------------- Sentence 6 -------------------

Since the earlier frequent pattern algorithm (e.g.-, apriori algorithm) needs to scan the  whole dataset many times which is computationally very expensive.

>> Tokens are: 
 ['Since', 'earlier', 'frequent', 'pattern', 'algorithm', '(', 'e.g.-', ',', 'apriori', 'algorithm', ')', 'needs', 'scan', 'whole', 'dataset', 'many', 'times', 'computationally', 'expensive', '.']

>> Bigrams are: 
 [('Since', 'earlier'), ('earlier', 'frequent'), ('frequent', 'pattern'), ('pattern', 'algorithm'), ('algorithm', '('), ('(', 'e.g.-'), ('e.g.-', ','), (',', 'apriori'), ('apriori', 'algorithm'), ('algorithm', ')'), (')', 'needs'), ('needs', 'scan'), ('scan', 'whole'), ('whole', 'dataset'), ('dataset', 'many'), ('many', 'times'), ('times', 'computationally'), ('computationally', 'expensive'), ('expensive', '.')]

>> Trigrams are: 
 [('Since', 'earlier', 'frequent'), ('earlier', 'frequent', 'pattern'), ('frequent', 'pattern', 'algorithm'), ('pattern', 'algorithm', '('), ('algorithm', '(', 'e.g.-'), ('(', 'e.g.-', ','), ('e.g.-', ',', 'apriori'), (',', 'apriori', 'algorithm'), ('apriori', 'algorithm', ')'), ('algorithm', ')', 'needs'), (')', 'needs', 'scan'), ('needs', 'scan', 'whole'), ('scan', 'whole', 'dataset'), ('whole', 'dataset', 'many'), ('dataset', 'many', 'times'), ('many', 'times', 'computationally'), ('times', 'computationally', 'expensive'), ('computationally', 'expensive', '.')]

>> POS Tags are: 
 [('Since', 'IN'), ('earlier', 'JJR'), ('frequent', 'JJ'), ('pattern', 'NN'), ('algorithm', 'NN'), ('(', '('), ('e.g.-', 'JJ'), (',', ','), ('apriori', 'JJ'), ('algorithm', 'NN'), (')', ')'), ('needs', 'VBZ'), ('scan', 'JJ'), ('whole', 'JJ'), ('dataset', 'NN'), ('many', 'JJ'), ('times', 'NNS'), ('computationally', 'RB'), ('expensive', 'JJ'), ('.', '.')]

>> Noun Phrases are: 
 ['frequent pattern algorithm', 'apriori algorithm', 'scan whole dataset', 'many times']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Since', 'sinc'), ('earlier', 'earlier'), ('frequent', 'frequent'), ('pattern', 'pattern'), ('algorithm', 'algorithm'), ('(', '('), ('e.g.-', 'e.g.-'), (',', ','), ('apriori', 'apriori'), ('algorithm', 'algorithm'), (')', ')'), ('needs', 'need'), ('scan', 'scan'), ('whole', 'whole'), ('dataset', 'dataset'), ('many', 'mani'), ('times', 'time'), ('computationally', 'comput'), ('expensive', 'expens'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Since', 'sinc'), ('earlier', 'earlier'), ('frequent', 'frequent'), ('pattern', 'pattern'), ('algorithm', 'algorithm'), ('(', '('), ('e.g.-', 'e.g.-'), (',', ','), ('apriori', 'apriori'), ('algorithm', 'algorithm'), (')', ')'), ('needs', 'need'), ('scan', 'scan'), ('whole', 'whole'), ('dataset', 'dataset'), ('many', 'mani'), ('times', 'time'), ('computationally', 'comput'), ('expensive', 'expens'), ('.', '.')]

>> Lemmatization: 
 [('Since', 'Since'), ('earlier', 'earlier'), ('frequent', 'frequent'), ('pattern', 'pattern'), ('algorithm', 'algorithm'), ('(', '('), ('e.g.-', 'e.g.-'), (',', ','), ('apriori', 'apriori'), ('algorithm', 'algorithm'), (')', ')'), ('needs', 'need'), ('scan', 'scan'), ('whole', 'whole'), ('dataset', 'dataset'), ('many', 'many'), ('times', 'time'), ('computationally', 'computationally'), ('expensive', 'expensive'), ('.', '.')]


------------------- Sentence 7 -------------------

How to reduce the  number of times the whole dataset is scanned so as to save the computation cost is one  of the most important things in all the frequent pattern studies.

>> Tokens are: 
 ['How', 'reduce', 'number', 'times', 'whole', 'dataset', 'scanned', 'save', 'computation', 'cost', 'one', 'important', 'things', 'frequent', 'pattern', 'studies', '.']

>> Bigrams are: 
 [('How', 'reduce'), ('reduce', 'number'), ('number', 'times'), ('times', 'whole'), ('whole', 'dataset'), ('dataset', 'scanned'), ('scanned', 'save'), ('save', 'computation'), ('computation', 'cost'), ('cost', 'one'), ('one', 'important'), ('important', 'things'), ('things', 'frequent'), ('frequent', 'pattern'), ('pattern', 'studies'), ('studies', '.')]

>> Trigrams are: 
 [('How', 'reduce', 'number'), ('reduce', 'number', 'times'), ('number', 'times', 'whole'), ('times', 'whole', 'dataset'), ('whole', 'dataset', 'scanned'), ('dataset', 'scanned', 'save'), ('scanned', 'save', 'computation'), ('save', 'computation', 'cost'), ('computation', 'cost', 'one'), ('cost', 'one', 'important'), ('one', 'important', 'things'), ('important', 'things', 'frequent'), ('things', 'frequent', 'pattern'), ('frequent', 'pattern', 'studies'), ('pattern', 'studies', '.')]

>> POS Tags are: 
 [('How', 'WRB'), ('reduce', 'VB'), ('number', 'NN'), ('times', 'NNS'), ('whole', 'JJ'), ('dataset', 'NN'), ('scanned', 'VBD'), ('save', 'JJ'), ('computation', 'NN'), ('cost', 'NN'), ('one', 'CD'), ('important', 'JJ'), ('things', 'NNS'), ('frequent', 'JJ'), ('pattern', 'JJ'), ('studies', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['number times', 'whole dataset', 'save computation cost', 'important things', 'frequent pattern studies']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('How', 'how'), ('reduce', 'reduc'), ('number', 'number'), ('times', 'time'), ('whole', 'whole'), ('dataset', 'dataset'), ('scanned', 'scan'), ('save', 'save'), ('computation', 'comput'), ('cost', 'cost'), ('one', 'one'), ('important', 'import'), ('things', 'thing'), ('frequent', 'frequent'), ('pattern', 'pattern'), ('studies', 'studi'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('How', 'how'), ('reduce', 'reduc'), ('number', 'number'), ('times', 'time'), ('whole', 'whole'), ('dataset', 'dataset'), ('scanned', 'scan'), ('save', 'save'), ('computation', 'comput'), ('cost', 'cost'), ('one', 'one'), ('important', 'import'), ('things', 'thing'), ('frequent', 'frequent'), ('pattern', 'pattern'), ('studies', 'studi'), ('.', '.')]

>> Lemmatization: 
 [('How', 'How'), ('reduce', 'reduce'), ('number', 'number'), ('times', 'time'), ('whole', 'whole'), ('dataset', 'dataset'), ('scanned', 'scanned'), ('save', 'save'), ('computation', 'computation'), ('cost', 'cost'), ('one', 'one'), ('important', 'important'), ('things', 'thing'), ('frequent', 'frequent'), ('pattern', 'pattern'), ('studies', 'study'), ('.', '.')]


------------------- Sentence 8 -------------------

The similar situation also  exists in data clustering and classification studies because the design concept of earlier  algorithms, such as mining the patterns on-the-fly [46], mining partial patterns at differ- ent stages [47], and reducing the number of times the whole dataset is scanned [32], are  therefore presented to enhance the performance of these mining algorithms.

>> Tokens are: 
 ['The', 'similar', 'situation', 'also', 'exists', 'data', 'clustering', 'classification', 'studies', 'design', 'concept', 'earlier', 'algorithms', ',', 'mining', 'patterns', 'on-the-fly', '[', '46', ']', ',', 'mining', 'partial', 'patterns', 'differ-', 'ent', 'stages', '[', '47', ']', ',', 'reducing', 'number', 'times', 'whole', 'dataset', 'scanned', '[', '32', ']', ',', 'therefore', 'presented', 'enhance', 'performance', 'mining', 'algorithms', '.']

>> Bigrams are: 
 [('The', 'similar'), ('similar', 'situation'), ('situation', 'also'), ('also', 'exists'), ('exists', 'data'), ('data', 'clustering'), ('clustering', 'classification'), ('classification', 'studies'), ('studies', 'design'), ('design', 'concept'), ('concept', 'earlier'), ('earlier', 'algorithms'), ('algorithms', ','), (',', 'mining'), ('mining', 'patterns'), ('patterns', 'on-the-fly'), ('on-the-fly', '['), ('[', '46'), ('46', ']'), (']', ','), (',', 'mining'), ('mining', 'partial'), ('partial', 'patterns'), ('patterns', 'differ-'), ('differ-', 'ent'), ('ent', 'stages'), ('stages', '['), ('[', '47'), ('47', ']'), (']', ','), (',', 'reducing'), ('reducing', 'number'), ('number', 'times'), ('times', 'whole'), ('whole', 'dataset'), ('dataset', 'scanned'), ('scanned', '['), ('[', '32'), ('32', ']'), (']', ','), (',', 'therefore'), ('therefore', 'presented'), ('presented', 'enhance'), ('enhance', 'performance'), ('performance', 'mining'), ('mining', 'algorithms'), ('algorithms', '.')]

>> Trigrams are: 
 [('The', 'similar', 'situation'), ('similar', 'situation', 'also'), ('situation', 'also', 'exists'), ('also', 'exists', 'data'), ('exists', 'data', 'clustering'), ('data', 'clustering', 'classification'), ('clustering', 'classification', 'studies'), ('classification', 'studies', 'design'), ('studies', 'design', 'concept'), ('design', 'concept', 'earlier'), ('concept', 'earlier', 'algorithms'), ('earlier', 'algorithms', ','), ('algorithms', ',', 'mining'), (',', 'mining', 'patterns'), ('mining', 'patterns', 'on-the-fly'), ('patterns', 'on-the-fly', '['), ('on-the-fly', '[', '46'), ('[', '46', ']'), ('46', ']', ','), (']', ',', 'mining'), (',', 'mining', 'partial'), ('mining', 'partial', 'patterns'), ('partial', 'patterns', 'differ-'), ('patterns', 'differ-', 'ent'), ('differ-', 'ent', 'stages'), ('ent', 'stages', '['), ('stages', '[', '47'), ('[', '47', ']'), ('47', ']', ','), (']', ',', 'reducing'), (',', 'reducing', 'number'), ('reducing', 'number', 'times'), ('number', 'times', 'whole'), ('times', 'whole', 'dataset'), ('whole', 'dataset', 'scanned'), ('dataset', 'scanned', '['), ('scanned', '[', '32'), ('[', '32', ']'), ('32', ']', ','), (']', ',', 'therefore'), (',', 'therefore', 'presented'), ('therefore', 'presented', 'enhance'), ('presented', 'enhance', 'performance'), ('enhance', 'performance', 'mining'), ('performance', 'mining', 'algorithms'), ('mining', 'algorithms', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('similar', 'JJ'), ('situation', 'NN'), ('also', 'RB'), ('exists', 'VBZ'), ('data', 'NNS'), ('clustering', 'VBG'), ('classification', 'NN'), ('studies', 'NNS'), ('design', 'VBP'), ('concept', 'NN'), ('earlier', 'RBR'), ('algorithms', 'NN'), (',', ','), ('mining', 'VBG'), ('patterns', 'NNS'), ('on-the-fly', 'JJ'), ('[', 'JJ'), ('46', 'CD'), (']', 'NN'), (',', ','), ('mining', 'VBG'), ('partial', 'JJ'), ('patterns', 'NNS'), ('differ-', 'JJ'), ('ent', 'JJ'), ('stages', 'NNS'), ('[', 'VBP'), ('47', 'CD'), (']', 'NN'), (',', ','), ('reducing', 'VBG'), ('number', 'NN'), ('times', 'NNS'), ('whole', 'JJ'), ('dataset', 'NN'), ('scanned', 'VBD'), ('[', '$'), ('32', 'CD'), (']', 'NNP'), (',', ','), ('therefore', 'RB'), ('presented', 'VBD'), ('enhance', 'JJ'), ('performance', 'NN'), ('mining', 'NN'), ('algorithms', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['The similar situation', 'data', 'classification studies', 'concept', 'algorithms', 'patterns', ']', 'partial patterns', 'differ- ent stages', ']', 'number times', 'whole dataset', ']', 'enhance performance mining algorithms']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('similar', 'similar'), ('situation', 'situat'), ('also', 'also'), ('exists', 'exist'), ('data', 'data'), ('clustering', 'cluster'), ('classification', 'classif'), ('studies', 'studi'), ('design', 'design'), ('concept', 'concept'), ('earlier', 'earlier'), ('algorithms', 'algorithm'), (',', ','), ('mining', 'mine'), ('patterns', 'pattern'), ('on-the-fly', 'on-the-fli'), ('[', '['), ('46', '46'), (']', ']'), (',', ','), ('mining', 'mine'), ('partial', 'partial'), ('patterns', 'pattern'), ('differ-', 'differ-'), ('ent', 'ent'), ('stages', 'stage'), ('[', '['), ('47', '47'), (']', ']'), (',', ','), ('reducing', 'reduc'), ('number', 'number'), ('times', 'time'), ('whole', 'whole'), ('dataset', 'dataset'), ('scanned', 'scan'), ('[', '['), ('32', '32'), (']', ']'), (',', ','), ('therefore', 'therefor'), ('presented', 'present'), ('enhance', 'enhanc'), ('performance', 'perform'), ('mining', 'mine'), ('algorithms', 'algorithm'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('similar', 'similar'), ('situation', 'situat'), ('also', 'also'), ('exists', 'exist'), ('data', 'data'), ('clustering', 'cluster'), ('classification', 'classif'), ('studies', 'studi'), ('design', 'design'), ('concept', 'concept'), ('earlier', 'earlier'), ('algorithms', 'algorithm'), (',', ','), ('mining', 'mine'), ('patterns', 'pattern'), ('on-the-fly', 'on-the-fli'), ('[', '['), ('46', '46'), (']', ']'), (',', ','), ('mining', 'mine'), ('partial', 'partial'), ('patterns', 'pattern'), ('differ-', 'differ-'), ('ent', 'ent'), ('stages', 'stage'), ('[', '['), ('47', '47'), (']', ']'), (',', ','), ('reducing', 'reduc'), ('number', 'number'), ('times', 'time'), ('whole', 'whole'), ('dataset', 'dataset'), ('scanned', 'scan'), ('[', '['), ('32', '32'), (']', ']'), (',', ','), ('therefore', 'therefor'), ('presented', 'present'), ('enhance', 'enhanc'), ('performance', 'perform'), ('mining', 'mine'), ('algorithms', 'algorithm'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('similar', 'similar'), ('situation', 'situation'), ('also', 'also'), ('exists', 'exists'), ('data', 'data'), ('clustering', 'clustering'), ('classification', 'classification'), ('studies', 'study'), ('design', 'design'), ('concept', 'concept'), ('earlier', 'earlier'), ('algorithms', 'algorithm'), (',', ','), ('mining', 'mining'), ('patterns', 'pattern'), ('on-the-fly', 'on-the-fly'), ('[', '['), ('46', '46'), (']', ']'), (',', ','), ('mining', 'mining'), ('partial', 'partial'), ('patterns', 'pattern'), ('differ-', 'differ-'), ('ent', 'ent'), ('stages', 'stage'), ('[', '['), ('47', '47'), (']', ']'), (',', ','), ('reducing', 'reducing'), ('number', 'number'), ('times', 'time'), ('whole', 'whole'), ('dataset', 'dataset'), ('scanned', 'scanned'), ('[', '['), ('32', '32'), (']', ']'), (',', ','), ('therefore', 'therefore'), ('presented', 'presented'), ('enhance', 'enhance'), ('performance', 'performance'), ('mining', 'mining'), ('algorithms', 'algorithm'), ('.', '.')]


------------------- Sentence 9 -------------------

Since some  of the data mining problems are NP-hard [48] or the solution space is very large, several  recent studies [23, 49] have attempted to use metaheuristic algorithm as the mining algo- rithm to get the approximate solution within a reasonable time.

>> Tokens are: 
 ['Since', 'data', 'mining', 'problems', 'NP-hard', '[', '48', ']', 'solution', 'space', 'large', ',', 'several', 'recent', 'studies', '[', '23', ',', '49', ']', 'attempted', 'use', 'metaheuristic', 'algorithm', 'mining', 'algo-', 'rithm', 'get', 'approximate', 'solution', 'within', 'reasonable', 'time', '.']

>> Bigrams are: 
 [('Since', 'data'), ('data', 'mining'), ('mining', 'problems'), ('problems', 'NP-hard'), ('NP-hard', '['), ('[', '48'), ('48', ']'), (']', 'solution'), ('solution', 'space'), ('space', 'large'), ('large', ','), (',', 'several'), ('several', 'recent'), ('recent', 'studies'), ('studies', '['), ('[', '23'), ('23', ','), (',', '49'), ('49', ']'), (']', 'attempted'), ('attempted', 'use'), ('use', 'metaheuristic'), ('metaheuristic', 'algorithm'), ('algorithm', 'mining'), ('mining', 'algo-'), ('algo-', 'rithm'), ('rithm', 'get'), ('get', 'approximate'), ('approximate', 'solution'), ('solution', 'within'), ('within', 'reasonable'), ('reasonable', 'time'), ('time', '.')]

>> Trigrams are: 
 [('Since', 'data', 'mining'), ('data', 'mining', 'problems'), ('mining', 'problems', 'NP-hard'), ('problems', 'NP-hard', '['), ('NP-hard', '[', '48'), ('[', '48', ']'), ('48', ']', 'solution'), (']', 'solution', 'space'), ('solution', 'space', 'large'), ('space', 'large', ','), ('large', ',', 'several'), (',', 'several', 'recent'), ('several', 'recent', 'studies'), ('recent', 'studies', '['), ('studies', '[', '23'), ('[', '23', ','), ('23', ',', '49'), (',', '49', ']'), ('49', ']', 'attempted'), (']', 'attempted', 'use'), ('attempted', 'use', 'metaheuristic'), ('use', 'metaheuristic', 'algorithm'), ('metaheuristic', 'algorithm', 'mining'), ('algorithm', 'mining', 'algo-'), ('mining', 'algo-', 'rithm'), ('algo-', 'rithm', 'get'), ('rithm', 'get', 'approximate'), ('get', 'approximate', 'solution'), ('approximate', 'solution', 'within'), ('solution', 'within', 'reasonable'), ('within', 'reasonable', 'time'), ('reasonable', 'time', '.')]

>> POS Tags are: 
 [('Since', 'IN'), ('data', 'NNS'), ('mining', 'VBG'), ('problems', 'NNS'), ('NP-hard', 'NNP'), ('[', 'VBD'), ('48', 'CD'), (']', 'NNP'), ('solution', 'NN'), ('space', 'NN'), ('large', 'JJ'), (',', ','), ('several', 'JJ'), ('recent', 'JJ'), ('studies', 'NNS'), ('[', 'VBP'), ('23', 'CD'), (',', ','), ('49', 'CD'), (']', 'NN'), ('attempted', 'VBN'), ('use', 'IN'), ('metaheuristic', 'JJ'), ('algorithm', 'NN'), ('mining', 'VBG'), ('algo-', 'JJ'), ('rithm', 'NN'), ('get', 'VB'), ('approximate', 'JJ'), ('solution', 'NN'), ('within', 'IN'), ('reasonable', 'JJ'), ('time', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['data', 'problems NP-hard', '] solution space', 'several recent studies', ']', 'metaheuristic algorithm', 'algo- rithm', 'approximate solution', 'reasonable time']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Since', 'sinc'), ('data', 'data'), ('mining', 'mine'), ('problems', 'problem'), ('NP-hard', 'np-hard'), ('[', '['), ('48', '48'), (']', ']'), ('solution', 'solut'), ('space', 'space'), ('large', 'larg'), (',', ','), ('several', 'sever'), ('recent', 'recent'), ('studies', 'studi'), ('[', '['), ('23', '23'), (',', ','), ('49', '49'), (']', ']'), ('attempted', 'attempt'), ('use', 'use'), ('metaheuristic', 'metaheurist'), ('algorithm', 'algorithm'), ('mining', 'mine'), ('algo-', 'algo-'), ('rithm', 'rithm'), ('get', 'get'), ('approximate', 'approxim'), ('solution', 'solut'), ('within', 'within'), ('reasonable', 'reason'), ('time', 'time'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Since', 'sinc'), ('data', 'data'), ('mining', 'mine'), ('problems', 'problem'), ('NP-hard', 'np-hard'), ('[', '['), ('48', '48'), (']', ']'), ('solution', 'solut'), ('space', 'space'), ('large', 'larg'), (',', ','), ('several', 'sever'), ('recent', 'recent'), ('studies', 'studi'), ('[', '['), ('23', '23'), (',', ','), ('49', '49'), (']', ']'), ('attempted', 'attempt'), ('use', 'use'), ('metaheuristic', 'metaheurist'), ('algorithm', 'algorithm'), ('mining', 'mine'), ('algo-', 'algo-'), ('rithm', 'rithm'), ('get', 'get'), ('approximate', 'approxim'), ('solution', 'solut'), ('within', 'within'), ('reasonable', 'reason'), ('time', 'time'), ('.', '.')]

>> Lemmatization: 
 [('Since', 'Since'), ('data', 'data'), ('mining', 'mining'), ('problems', 'problem'), ('NP-hard', 'NP-hard'), ('[', '['), ('48', '48'), (']', ']'), ('solution', 'solution'), ('space', 'space'), ('large', 'large'), (',', ','), ('several', 'several'), ('recent', 'recent'), ('studies', 'study'), ('[', '['), ('23', '23'), (',', ','), ('49', '49'), (']', ']'), ('attempted', 'attempted'), ('use', 'use'), ('metaheuristic', 'metaheuristic'), ('algorithm', 'algorithm'), ('mining', 'mining'), ('algo-', 'algo-'), ('rithm', 'rithm'), ('get', 'get'), ('approximate', 'approximate'), ('solution', 'solution'), ('within', 'within'), ('reasonable', 'reasonable'), ('time', 'time'), ('.', '.')]



========================================== PARAGRAPH 140 ===========================================

Abundant research results of data analysis [20, 27, 63] show possible solutions for  dealing with the dilemmas of data mining algorithms. It means that the open issues of  data analysis from the literature [2, 64] usually can help us easily find the possible solu- tions. For instance, the clustering result is extremely sensitive to the initial means, which  can be mitigated by using multiple sets of initial means [65]. According to our observa- tion, most data analysis methods have limitations for big data, that can be described as  follows: 

------------------- Sentence 1 -------------------

Abundant research results of data analysis [20, 27, 63] show possible solutions for  dealing with the dilemmas of data mining algorithms.

>> Tokens are: 
 ['Abundant', 'research', 'results', 'data', 'analysis', '[', '20', ',', '27', ',', '63', ']', 'show', 'possible', 'solutions', 'dealing', 'dilemmas', 'data', 'mining', 'algorithms', '.']

>> Bigrams are: 
 [('Abundant', 'research'), ('research', 'results'), ('results', 'data'), ('data', 'analysis'), ('analysis', '['), ('[', '20'), ('20', ','), (',', '27'), ('27', ','), (',', '63'), ('63', ']'), (']', 'show'), ('show', 'possible'), ('possible', 'solutions'), ('solutions', 'dealing'), ('dealing', 'dilemmas'), ('dilemmas', 'data'), ('data', 'mining'), ('mining', 'algorithms'), ('algorithms', '.')]

>> Trigrams are: 
 [('Abundant', 'research', 'results'), ('research', 'results', 'data'), ('results', 'data', 'analysis'), ('data', 'analysis', '['), ('analysis', '[', '20'), ('[', '20', ','), ('20', ',', '27'), (',', '27', ','), ('27', ',', '63'), (',', '63', ']'), ('63', ']', 'show'), (']', 'show', 'possible'), ('show', 'possible', 'solutions'), ('possible', 'solutions', 'dealing'), ('solutions', 'dealing', 'dilemmas'), ('dealing', 'dilemmas', 'data'), ('dilemmas', 'data', 'mining'), ('data', 'mining', 'algorithms'), ('mining', 'algorithms', '.')]

>> POS Tags are: 
 [('Abundant', 'JJ'), ('research', 'NN'), ('results', 'NNS'), ('data', 'VBD'), ('analysis', 'NN'), ('[', 'NN'), ('20', 'CD'), (',', ','), ('27', 'CD'), (',', ','), ('63', 'CD'), (']', 'NN'), ('show', 'NN'), ('possible', 'JJ'), ('solutions', 'NNS'), ('dealing', 'VBG'), ('dilemmas', 'NN'), ('data', 'NNS'), ('mining', 'NN'), ('algorithms', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Abundant research results', 'analysis [', '] show', 'possible solutions', 'dilemmas data mining algorithms']

>> Named Entities are: 
 [('GPE', 'Abundant')] 

>> Stemming using Porter Stemmer: 
 [('Abundant', 'abund'), ('research', 'research'), ('results', 'result'), ('data', 'data'), ('analysis', 'analysi'), ('[', '['), ('20', '20'), (',', ','), ('27', '27'), (',', ','), ('63', '63'), (']', ']'), ('show', 'show'), ('possible', 'possibl'), ('solutions', 'solut'), ('dealing', 'deal'), ('dilemmas', 'dilemma'), ('data', 'data'), ('mining', 'mine'), ('algorithms', 'algorithm'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Abundant', 'abund'), ('research', 'research'), ('results', 'result'), ('data', 'data'), ('analysis', 'analysi'), ('[', '['), ('20', '20'), (',', ','), ('27', '27'), (',', ','), ('63', '63'), (']', ']'), ('show', 'show'), ('possible', 'possibl'), ('solutions', 'solut'), ('dealing', 'deal'), ('dilemmas', 'dilemma'), ('data', 'data'), ('mining', 'mine'), ('algorithms', 'algorithm'), ('.', '.')]

>> Lemmatization: 
 [('Abundant', 'Abundant'), ('research', 'research'), ('results', 'result'), ('data', 'data'), ('analysis', 'analysis'), ('[', '['), ('20', '20'), (',', ','), ('27', '27'), (',', ','), ('63', '63'), (']', ']'), ('show', 'show'), ('possible', 'possible'), ('solutions', 'solution'), ('dealing', 'dealing'), ('dilemmas', 'dilemma'), ('data', 'data'), ('mining', 'mining'), ('algorithms', 'algorithm'), ('.', '.')]


------------------- Sentence 2 -------------------

It means that the open issues of  data analysis from the literature [2, 64] usually can help us easily find the possible solu- tions.

>> Tokens are: 
 ['It', 'means', 'open', 'issues', 'data', 'analysis', 'literature', '[', '2', ',', '64', ']', 'usually', 'help', 'us', 'easily', 'find', 'possible', 'solu-', 'tions', '.']

>> Bigrams are: 
 [('It', 'means'), ('means', 'open'), ('open', 'issues'), ('issues', 'data'), ('data', 'analysis'), ('analysis', 'literature'), ('literature', '['), ('[', '2'), ('2', ','), (',', '64'), ('64', ']'), (']', 'usually'), ('usually', 'help'), ('help', 'us'), ('us', 'easily'), ('easily', 'find'), ('find', 'possible'), ('possible', 'solu-'), ('solu-', 'tions'), ('tions', '.')]

>> Trigrams are: 
 [('It', 'means', 'open'), ('means', 'open', 'issues'), ('open', 'issues', 'data'), ('issues', 'data', 'analysis'), ('data', 'analysis', 'literature'), ('analysis', 'literature', '['), ('literature', '[', '2'), ('[', '2', ','), ('2', ',', '64'), (',', '64', ']'), ('64', ']', 'usually'), (']', 'usually', 'help'), ('usually', 'help', 'us'), ('help', 'us', 'easily'), ('us', 'easily', 'find'), ('easily', 'find', 'possible'), ('find', 'possible', 'solu-'), ('possible', 'solu-', 'tions'), ('solu-', 'tions', '.')]

>> POS Tags are: 
 [('It', 'PRP'), ('means', 'VBZ'), ('open', 'JJ'), ('issues', 'NNS'), ('data', 'NNS'), ('analysis', 'NN'), ('literature', 'NN'), ('[', 'VBZ'), ('2', 'CD'), (',', ','), ('64', 'CD'), (']', 'NNP'), ('usually', 'RB'), ('help', 'VBP'), ('us', 'PRP'), ('easily', 'RB'), ('find', 'VBP'), ('possible', 'JJ'), ('solu-', 'JJ'), ('tions', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['open issues data analysis literature', ']', 'possible solu- tions']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('It', 'it'), ('means', 'mean'), ('open', 'open'), ('issues', 'issu'), ('data', 'data'), ('analysis', 'analysi'), ('literature', 'literatur'), ('[', '['), ('2', '2'), (',', ','), ('64', '64'), (']', ']'), ('usually', 'usual'), ('help', 'help'), ('us', 'us'), ('easily', 'easili'), ('find', 'find'), ('possible', 'possibl'), ('solu-', 'solu-'), ('tions', 'tion'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('It', 'it'), ('means', 'mean'), ('open', 'open'), ('issues', 'issu'), ('data', 'data'), ('analysis', 'analysi'), ('literature', 'literatur'), ('[', '['), ('2', '2'), (',', ','), ('64', '64'), (']', ']'), ('usually', 'usual'), ('help', 'help'), ('us', 'us'), ('easily', 'easili'), ('find', 'find'), ('possible', 'possibl'), ('solu-', 'solu-'), ('tions', 'tion'), ('.', '.')]

>> Lemmatization: 
 [('It', 'It'), ('means', 'mean'), ('open', 'open'), ('issues', 'issue'), ('data', 'data'), ('analysis', 'analysis'), ('literature', 'literature'), ('[', '['), ('2', '2'), (',', ','), ('64', '64'), (']', ']'), ('usually', 'usually'), ('help', 'help'), ('us', 'u'), ('easily', 'easily'), ('find', 'find'), ('possible', 'possible'), ('solu-', 'solu-'), ('tions', 'tions'), ('.', '.')]


------------------- Sentence 3 -------------------

For instance, the clustering result is extremely sensitive to the initial means, which  can be mitigated by using multiple sets of initial means [65].

>> Tokens are: 
 ['For', 'instance', ',', 'clustering', 'result', 'extremely', 'sensitive', 'initial', 'means', ',', 'mitigated', 'using', 'multiple', 'sets', 'initial', 'means', '[', '65', ']', '.']

>> Bigrams are: 
 [('For', 'instance'), ('instance', ','), (',', 'clustering'), ('clustering', 'result'), ('result', 'extremely'), ('extremely', 'sensitive'), ('sensitive', 'initial'), ('initial', 'means'), ('means', ','), (',', 'mitigated'), ('mitigated', 'using'), ('using', 'multiple'), ('multiple', 'sets'), ('sets', 'initial'), ('initial', 'means'), ('means', '['), ('[', '65'), ('65', ']'), (']', '.')]

>> Trigrams are: 
 [('For', 'instance', ','), ('instance', ',', 'clustering'), (',', 'clustering', 'result'), ('clustering', 'result', 'extremely'), ('result', 'extremely', 'sensitive'), ('extremely', 'sensitive', 'initial'), ('sensitive', 'initial', 'means'), ('initial', 'means', ','), ('means', ',', 'mitigated'), (',', 'mitigated', 'using'), ('mitigated', 'using', 'multiple'), ('using', 'multiple', 'sets'), ('multiple', 'sets', 'initial'), ('sets', 'initial', 'means'), ('initial', 'means', '['), ('means', '[', '65'), ('[', '65', ']'), ('65', ']', '.')]

>> POS Tags are: 
 [('For', 'IN'), ('instance', 'NN'), (',', ','), ('clustering', 'VBG'), ('result', 'NN'), ('extremely', 'RB'), ('sensitive', 'JJ'), ('initial', 'JJ'), ('means', 'NNS'), (',', ','), ('mitigated', 'VBD'), ('using', 'VBG'), ('multiple', 'JJ'), ('sets', 'NNS'), ('initial', 'JJ'), ('means', 'NNS'), ('[', 'VBP'), ('65', 'CD'), (']', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['instance', 'result', 'sensitive initial means', 'multiple sets', 'initial means', ']']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('For', 'for'), ('instance', 'instanc'), (',', ','), ('clustering', 'cluster'), ('result', 'result'), ('extremely', 'extrem'), ('sensitive', 'sensit'), ('initial', 'initi'), ('means', 'mean'), (',', ','), ('mitigated', 'mitig'), ('using', 'use'), ('multiple', 'multipl'), ('sets', 'set'), ('initial', 'initi'), ('means', 'mean'), ('[', '['), ('65', '65'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('For', 'for'), ('instance', 'instanc'), (',', ','), ('clustering', 'cluster'), ('result', 'result'), ('extremely', 'extrem'), ('sensitive', 'sensit'), ('initial', 'initi'), ('means', 'mean'), (',', ','), ('mitigated', 'mitig'), ('using', 'use'), ('multiple', 'multipl'), ('sets', 'set'), ('initial', 'initi'), ('means', 'mean'), ('[', '['), ('65', '65'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('For', 'For'), ('instance', 'instance'), (',', ','), ('clustering', 'clustering'), ('result', 'result'), ('extremely', 'extremely'), ('sensitive', 'sensitive'), ('initial', 'initial'), ('means', 'mean'), (',', ','), ('mitigated', 'mitigated'), ('using', 'using'), ('multiple', 'multiple'), ('sets', 'set'), ('initial', 'initial'), ('means', 'mean'), ('[', '['), ('65', '65'), (']', ']'), ('.', '.')]


------------------- Sentence 4 -------------------

According to our observa- tion, most data analysis methods have limitations for big data, that can be described as  follows:

>> Tokens are: 
 ['According', 'observa-', 'tion', ',', 'data', 'analysis', 'methods', 'limitations', 'big', 'data', ',', 'described', 'follows', ':']

>> Bigrams are: 
 [('According', 'observa-'), ('observa-', 'tion'), ('tion', ','), (',', 'data'), ('data', 'analysis'), ('analysis', 'methods'), ('methods', 'limitations'), ('limitations', 'big'), ('big', 'data'), ('data', ','), (',', 'described'), ('described', 'follows'), ('follows', ':')]

>> Trigrams are: 
 [('According', 'observa-', 'tion'), ('observa-', 'tion', ','), ('tion', ',', 'data'), (',', 'data', 'analysis'), ('data', 'analysis', 'methods'), ('analysis', 'methods', 'limitations'), ('methods', 'limitations', 'big'), ('limitations', 'big', 'data'), ('big', 'data', ','), ('data', ',', 'described'), (',', 'described', 'follows'), ('described', 'follows', ':')]

>> POS Tags are: 
 [('According', 'VBG'), ('observa-', 'JJ'), ('tion', 'NN'), (',', ','), ('data', 'NNS'), ('analysis', 'NN'), ('methods', 'NNS'), ('limitations', 'NNS'), ('big', 'JJ'), ('data', 'NNS'), (',', ','), ('described', 'VBN'), ('follows', 'VBZ'), (':', ':')]

>> Noun Phrases are: 
 ['observa- tion', 'data analysis methods limitations', 'big data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('According', 'accord'), ('observa-', 'observa-'), ('tion', 'tion'), (',', ','), ('data', 'data'), ('analysis', 'analysi'), ('methods', 'method'), ('limitations', 'limit'), ('big', 'big'), ('data', 'data'), (',', ','), ('described', 'describ'), ('follows', 'follow'), (':', ':')]

>> Stemming using Snowball Stemmer: 
 [('According', 'accord'), ('observa-', 'observa-'), ('tion', 'tion'), (',', ','), ('data', 'data'), ('analysis', 'analysi'), ('methods', 'method'), ('limitations', 'limit'), ('big', 'big'), ('data', 'data'), (',', ','), ('described', 'describ'), ('follows', 'follow'), (':', ':')]

>> Lemmatization: 
 [('According', 'According'), ('observa-', 'observa-'), ('tion', 'tion'), (',', ','), ('data', 'data'), ('analysis', 'analysis'), ('methods', 'method'), ('limitations', 'limitation'), ('big', 'big'), ('data', 'data'), (',', ','), ('described', 'described'), ('follows', 'follows'), (':', ':')]



========================================== PARAGRAPH 141 ===========================================

Fig. 5 Screenshot of the results of clustering search engine

------------------- Sentence 1 -------------------

Fig.

>> Tokens are: 
 ['Fig', '.']

>> Bigrams are: 
 [('Fig', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Fig', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Fig']

>> Named Entities are: 
 [('GPE', 'Fig')] 

>> Stemming using Porter Stemmer: 
 [('Fig', 'fig'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Fig', 'fig'), ('.', '.')]

>> Lemmatization: 
 [('Fig', 'Fig'), ('.', '.')]


------------------- Sentence 2 -------------------

5 Screenshot of the results of clustering search engine

>> Tokens are: 
 ['5', 'Screenshot', 'results', 'clustering', 'search', 'engine']

>> Bigrams are: 
 [('5', 'Screenshot'), ('Screenshot', 'results'), ('results', 'clustering'), ('clustering', 'search'), ('search', 'engine')]

>> Trigrams are: 
 [('5', 'Screenshot', 'results'), ('Screenshot', 'results', 'clustering'), ('results', 'clustering', 'search'), ('clustering', 'search', 'engine')]

>> POS Tags are: 
 [('5', 'CD'), ('Screenshot', 'JJ'), ('results', 'NNS'), ('clustering', 'VBG'), ('search', 'NN'), ('engine', 'NN')]

>> Noun Phrases are: 
 ['Screenshot results', 'search engine']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('5', '5'), ('Screenshot', 'screenshot'), ('results', 'result'), ('clustering', 'cluster'), ('search', 'search'), ('engine', 'engin')]

>> Stemming using Snowball Stemmer: 
 [('5', '5'), ('Screenshot', 'screenshot'), ('results', 'result'), ('clustering', 'cluster'), ('search', 'search'), ('engine', 'engin')]

>> Lemmatization: 
 [('5', '5'), ('Screenshot', 'Screenshot'), ('results', 'result'), ('clustering', 'clustering'), ('search', 'search'), ('engine', 'engine')]



========================================== PARAGRAPH 142 ===========================================

Page 9 of 32Tsai et al. Journal of Big Data  (2015) 2:21  

------------------- Sentence 1 -------------------

Page 9 of 32Tsai et al.

>> Tokens are: 
 ['Page', '9', '32Tsai', 'et', 'al', '.']

>> Bigrams are: 
 [('Page', '9'), ('9', '32Tsai'), ('32Tsai', 'et'), ('et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('Page', '9', '32Tsai'), ('9', '32Tsai', 'et'), ('32Tsai', 'et', 'al'), ('et', 'al', '.')]

>> POS Tags are: 
 [('Page', 'NN'), ('9', 'CD'), ('32Tsai', 'CD'), ('et', 'NN'), ('al', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Page', 'et al']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Page', 'page'), ('9', '9'), ('32Tsai', '32tsai'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Page', 'page'), ('9', '9'), ('32Tsai', '32tsai'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('Page', 'Page'), ('9', '9'), ('32Tsai', '32Tsai'), ('et', 'et'), ('al', 'al'), ('.', '.')]


------------------- Sentence 2 -------------------

Journal of Big Data  (2015) 2:21

>> Tokens are: 
 ['Journal', 'Big', 'Data', '(', '2015', ')', '2:21']

>> Bigrams are: 
 [('Journal', 'Big'), ('Big', 'Data'), ('Data', '('), ('(', '2015'), ('2015', ')'), (')', '2:21')]

>> Trigrams are: 
 [('Journal', 'Big', 'Data'), ('Big', 'Data', '('), ('Data', '(', '2015'), ('(', '2015', ')'), ('2015', ')', '2:21')]

>> POS Tags are: 
 [('Journal', 'NNP'), ('Big', 'NNP'), ('Data', 'NNP'), ('(', '('), ('2015', 'CD'), (')', ')'), ('2:21', 'CD')]

>> Noun Phrases are: 
 ['Journal Big Data']

>> Named Entities are: 
 [('PERSON', 'Journal')] 

>> Stemming using Porter Stemmer: 
 [('Journal', 'journal'), ('Big', 'big'), ('Data', 'data'), ('(', '('), ('2015', '2015'), (')', ')'), ('2:21', '2:21')]

>> Stemming using Snowball Stemmer: 
 [('Journal', 'journal'), ('Big', 'big'), ('Data', 'data'), ('(', '('), ('2015', '2015'), (')', ')'), ('2:21', '2:21')]

>> Lemmatization: 
 [('Journal', 'Journal'), ('Big', 'Big'), ('Data', 'Data'), ('(', '('), ('2015', '2015'), (')', ')'), ('2:21', '2:21')]



========================================== PARAGRAPH 143 ===========================================

  – Unscalability and centralization Most data analysis methods are not for large-scale and  complex dataset. The traditional data analysis methods cannot be scaled up because  their design does not take into account large or complex datasets. The design of tra- ditional data analysis methods typically assumed they will be performed in a single  machine, with all the data in memory for the data analysis process. For this reason, the  performance of traditional data analytics will be limited in solving the volume problem  of big data. 

------------------- Sentence 1 -------------------

  – Unscalability and centralization Most data analysis methods are not for large-scale and  complex dataset.

>> Tokens are: 
 ['–', 'Unscalability', 'centralization', 'Most', 'data', 'analysis', 'methods', 'large-scale', 'complex', 'dataset', '.']

>> Bigrams are: 
 [('–', 'Unscalability'), ('Unscalability', 'centralization'), ('centralization', 'Most'), ('Most', 'data'), ('data', 'analysis'), ('analysis', 'methods'), ('methods', 'large-scale'), ('large-scale', 'complex'), ('complex', 'dataset'), ('dataset', '.')]

>> Trigrams are: 
 [('–', 'Unscalability', 'centralization'), ('Unscalability', 'centralization', 'Most'), ('centralization', 'Most', 'data'), ('Most', 'data', 'analysis'), ('data', 'analysis', 'methods'), ('analysis', 'methods', 'large-scale'), ('methods', 'large-scale', 'complex'), ('large-scale', 'complex', 'dataset'), ('complex', 'dataset', '.')]

>> POS Tags are: 
 [('–', 'JJ'), ('Unscalability', 'NNP'), ('centralization', 'NN'), ('Most', 'NNP'), ('data', 'NNS'), ('analysis', 'NN'), ('methods', 'NNS'), ('large-scale', 'JJ'), ('complex', 'JJ'), ('dataset', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['– Unscalability centralization Most data analysis methods', 'large-scale complex dataset']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('–', '–'), ('Unscalability', 'unscal'), ('centralization', 'central'), ('Most', 'most'), ('data', 'data'), ('analysis', 'analysi'), ('methods', 'method'), ('large-scale', 'large-scal'), ('complex', 'complex'), ('dataset', 'dataset'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('–', '–'), ('Unscalability', 'unscal'), ('centralization', 'central'), ('Most', 'most'), ('data', 'data'), ('analysis', 'analysi'), ('methods', 'method'), ('large-scale', 'large-scal'), ('complex', 'complex'), ('dataset', 'dataset'), ('.', '.')]

>> Lemmatization: 
 [('–', '–'), ('Unscalability', 'Unscalability'), ('centralization', 'centralization'), ('Most', 'Most'), ('data', 'data'), ('analysis', 'analysis'), ('methods', 'method'), ('large-scale', 'large-scale'), ('complex', 'complex'), ('dataset', 'dataset'), ('.', '.')]


------------------- Sentence 2 -------------------

The traditional data analysis methods cannot be scaled up because  their design does not take into account large or complex datasets.

>> Tokens are: 
 ['The', 'traditional', 'data', 'analysis', 'methods', 'scaled', 'design', 'take', 'account', 'large', 'complex', 'datasets', '.']

>> Bigrams are: 
 [('The', 'traditional'), ('traditional', 'data'), ('data', 'analysis'), ('analysis', 'methods'), ('methods', 'scaled'), ('scaled', 'design'), ('design', 'take'), ('take', 'account'), ('account', 'large'), ('large', 'complex'), ('complex', 'datasets'), ('datasets', '.')]

>> Trigrams are: 
 [('The', 'traditional', 'data'), ('traditional', 'data', 'analysis'), ('data', 'analysis', 'methods'), ('analysis', 'methods', 'scaled'), ('methods', 'scaled', 'design'), ('scaled', 'design', 'take'), ('design', 'take', 'account'), ('take', 'account', 'large'), ('account', 'large', 'complex'), ('large', 'complex', 'datasets'), ('complex', 'datasets', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('traditional', 'JJ'), ('data', 'NN'), ('analysis', 'NN'), ('methods', 'NNS'), ('scaled', 'VBD'), ('design', 'NN'), ('take', 'NN'), ('account', 'NN'), ('large', 'JJ'), ('complex', 'JJ'), ('datasets', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['The traditional data analysis methods', 'design take account', 'large complex datasets']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('traditional', 'tradit'), ('data', 'data'), ('analysis', 'analysi'), ('methods', 'method'), ('scaled', 'scale'), ('design', 'design'), ('take', 'take'), ('account', 'account'), ('large', 'larg'), ('complex', 'complex'), ('datasets', 'dataset'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('traditional', 'tradit'), ('data', 'data'), ('analysis', 'analysi'), ('methods', 'method'), ('scaled', 'scale'), ('design', 'design'), ('take', 'take'), ('account', 'account'), ('large', 'larg'), ('complex', 'complex'), ('datasets', 'dataset'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('traditional', 'traditional'), ('data', 'data'), ('analysis', 'analysis'), ('methods', 'method'), ('scaled', 'scaled'), ('design', 'design'), ('take', 'take'), ('account', 'account'), ('large', 'large'), ('complex', 'complex'), ('datasets', 'datasets'), ('.', '.')]


------------------- Sentence 3 -------------------

The design of tra- ditional data analysis methods typically assumed they will be performed in a single  machine, with all the data in memory for the data analysis process.

>> Tokens are: 
 ['The', 'design', 'tra-', 'ditional', 'data', 'analysis', 'methods', 'typically', 'assumed', 'performed', 'single', 'machine', ',', 'data', 'memory', 'data', 'analysis', 'process', '.']

>> Bigrams are: 
 [('The', 'design'), ('design', 'tra-'), ('tra-', 'ditional'), ('ditional', 'data'), ('data', 'analysis'), ('analysis', 'methods'), ('methods', 'typically'), ('typically', 'assumed'), ('assumed', 'performed'), ('performed', 'single'), ('single', 'machine'), ('machine', ','), (',', 'data'), ('data', 'memory'), ('memory', 'data'), ('data', 'analysis'), ('analysis', 'process'), ('process', '.')]

>> Trigrams are: 
 [('The', 'design', 'tra-'), ('design', 'tra-', 'ditional'), ('tra-', 'ditional', 'data'), ('ditional', 'data', 'analysis'), ('data', 'analysis', 'methods'), ('analysis', 'methods', 'typically'), ('methods', 'typically', 'assumed'), ('typically', 'assumed', 'performed'), ('assumed', 'performed', 'single'), ('performed', 'single', 'machine'), ('single', 'machine', ','), ('machine', ',', 'data'), (',', 'data', 'memory'), ('data', 'memory', 'data'), ('memory', 'data', 'analysis'), ('data', 'analysis', 'process'), ('analysis', 'process', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('design', 'NN'), ('tra-', 'JJ'), ('ditional', 'JJ'), ('data', 'NNS'), ('analysis', 'NN'), ('methods', 'NNS'), ('typically', 'RB'), ('assumed', 'VBD'), ('performed', 'VBN'), ('single', 'JJ'), ('machine', 'NN'), (',', ','), ('data', 'NNS'), ('memory', 'NN'), ('data', 'NNS'), ('analysis', 'NN'), ('process', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['The design', 'tra- ditional data analysis methods', 'single machine', 'data memory data analysis process']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('design', 'design'), ('tra-', 'tra-'), ('ditional', 'dition'), ('data', 'data'), ('analysis', 'analysi'), ('methods', 'method'), ('typically', 'typic'), ('assumed', 'assum'), ('performed', 'perform'), ('single', 'singl'), ('machine', 'machin'), (',', ','), ('data', 'data'), ('memory', 'memori'), ('data', 'data'), ('analysis', 'analysi'), ('process', 'process'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('design', 'design'), ('tra-', 'tra-'), ('ditional', 'dition'), ('data', 'data'), ('analysis', 'analysi'), ('methods', 'method'), ('typically', 'typic'), ('assumed', 'assum'), ('performed', 'perform'), ('single', 'singl'), ('machine', 'machin'), (',', ','), ('data', 'data'), ('memory', 'memori'), ('data', 'data'), ('analysis', 'analysi'), ('process', 'process'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('design', 'design'), ('tra-', 'tra-'), ('ditional', 'ditional'), ('data', 'data'), ('analysis', 'analysis'), ('methods', 'method'), ('typically', 'typically'), ('assumed', 'assumed'), ('performed', 'performed'), ('single', 'single'), ('machine', 'machine'), (',', ','), ('data', 'data'), ('memory', 'memory'), ('data', 'data'), ('analysis', 'analysis'), ('process', 'process'), ('.', '.')]


------------------- Sentence 4 -------------------

For this reason, the  performance of traditional data analytics will be limited in solving the volume problem  of big data.

>> Tokens are: 
 ['For', 'reason', ',', 'performance', 'traditional', 'data', 'analytics', 'limited', 'solving', 'volume', 'problem', 'big', 'data', '.']

>> Bigrams are: 
 [('For', 'reason'), ('reason', ','), (',', 'performance'), ('performance', 'traditional'), ('traditional', 'data'), ('data', 'analytics'), ('analytics', 'limited'), ('limited', 'solving'), ('solving', 'volume'), ('volume', 'problem'), ('problem', 'big'), ('big', 'data'), ('data', '.')]

>> Trigrams are: 
 [('For', 'reason', ','), ('reason', ',', 'performance'), (',', 'performance', 'traditional'), ('performance', 'traditional', 'data'), ('traditional', 'data', 'analytics'), ('data', 'analytics', 'limited'), ('analytics', 'limited', 'solving'), ('limited', 'solving', 'volume'), ('solving', 'volume', 'problem'), ('volume', 'problem', 'big'), ('problem', 'big', 'data'), ('big', 'data', '.')]

>> POS Tags are: 
 [('For', 'IN'), ('reason', 'NN'), (',', ','), ('performance', 'NN'), ('traditional', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('limited', 'VBD'), ('solving', 'VBG'), ('volume', 'NN'), ('problem', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['reason', 'performance', 'traditional data analytics', 'volume problem', 'big data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('For', 'for'), ('reason', 'reason'), (',', ','), ('performance', 'perform'), ('traditional', 'tradit'), ('data', 'data'), ('analytics', 'analyt'), ('limited', 'limit'), ('solving', 'solv'), ('volume', 'volum'), ('problem', 'problem'), ('big', 'big'), ('data', 'data'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('For', 'for'), ('reason', 'reason'), (',', ','), ('performance', 'perform'), ('traditional', 'tradit'), ('data', 'data'), ('analytics', 'analyt'), ('limited', 'limit'), ('solving', 'solv'), ('volume', 'volum'), ('problem', 'problem'), ('big', 'big'), ('data', 'data'), ('.', '.')]

>> Lemmatization: 
 [('For', 'For'), ('reason', 'reason'), (',', ','), ('performance', 'performance'), ('traditional', 'traditional'), ('data', 'data'), ('analytics', 'analytics'), ('limited', 'limited'), ('solving', 'solving'), ('volume', 'volume'), ('problem', 'problem'), ('big', 'big'), ('data', 'data'), ('.', '.')]



========================================== PARAGRAPH 144 ===========================================

 – Non-dynamic Most traditional data analysis methods cannot be dynamically adjusted  for different situations, meaning that they do not analyze the input data on-the-fly. For  example, the classifiers are usually fixed which cannot be automatically changed. The  incremental learning [66] is a promising research trend because it can dynamically  adjust the the classifiers on the training process with limited resources. As a result, the  performance of traditional data analytics may not be useful to the problem of velocity  problem of big data. 

------------------- Sentence 1 -------------------

 – Non-dynamic Most traditional data analysis methods cannot be dynamically adjusted  for different situations, meaning that they do not analyze the input data on-the-fly.

>> Tokens are: 
 ['–', 'Non-dynamic', 'Most', 'traditional', 'data', 'analysis', 'methods', 'dynamically', 'adjusted', 'different', 'situations', ',', 'meaning', 'analyze', 'input', 'data', 'on-the-fly', '.']

>> Bigrams are: 
 [('–', 'Non-dynamic'), ('Non-dynamic', 'Most'), ('Most', 'traditional'), ('traditional', 'data'), ('data', 'analysis'), ('analysis', 'methods'), ('methods', 'dynamically'), ('dynamically', 'adjusted'), ('adjusted', 'different'), ('different', 'situations'), ('situations', ','), (',', 'meaning'), ('meaning', 'analyze'), ('analyze', 'input'), ('input', 'data'), ('data', 'on-the-fly'), ('on-the-fly', '.')]

>> Trigrams are: 
 [('–', 'Non-dynamic', 'Most'), ('Non-dynamic', 'Most', 'traditional'), ('Most', 'traditional', 'data'), ('traditional', 'data', 'analysis'), ('data', 'analysis', 'methods'), ('analysis', 'methods', 'dynamically'), ('methods', 'dynamically', 'adjusted'), ('dynamically', 'adjusted', 'different'), ('adjusted', 'different', 'situations'), ('different', 'situations', ','), ('situations', ',', 'meaning'), (',', 'meaning', 'analyze'), ('meaning', 'analyze', 'input'), ('analyze', 'input', 'data'), ('input', 'data', 'on-the-fly'), ('data', 'on-the-fly', '.')]

>> POS Tags are: 
 [('–', 'JJ'), ('Non-dynamic', 'NNP'), ('Most', 'NNP'), ('traditional', 'JJ'), ('data', 'NNS'), ('analysis', 'NN'), ('methods', 'NNS'), ('dynamically', 'RB'), ('adjusted', 'VBN'), ('different', 'JJ'), ('situations', 'NNS'), (',', ','), ('meaning', 'VBG'), ('analyze', 'JJ'), ('input', 'NN'), ('data', 'NNS'), ('on-the-fly', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['– Non-dynamic Most', 'traditional data analysis methods', 'different situations', 'analyze input data on-the-fly']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('–', '–'), ('Non-dynamic', 'non-dynam'), ('Most', 'most'), ('traditional', 'tradit'), ('data', 'data'), ('analysis', 'analysi'), ('methods', 'method'), ('dynamically', 'dynam'), ('adjusted', 'adjust'), ('different', 'differ'), ('situations', 'situat'), (',', ','), ('meaning', 'mean'), ('analyze', 'analyz'), ('input', 'input'), ('data', 'data'), ('on-the-fly', 'on-the-fli'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('–', '–'), ('Non-dynamic', 'non-dynam'), ('Most', 'most'), ('traditional', 'tradit'), ('data', 'data'), ('analysis', 'analysi'), ('methods', 'method'), ('dynamically', 'dynam'), ('adjusted', 'adjust'), ('different', 'differ'), ('situations', 'situat'), (',', ','), ('meaning', 'mean'), ('analyze', 'analyz'), ('input', 'input'), ('data', 'data'), ('on-the-fly', 'on-the-fli'), ('.', '.')]

>> Lemmatization: 
 [('–', '–'), ('Non-dynamic', 'Non-dynamic'), ('Most', 'Most'), ('traditional', 'traditional'), ('data', 'data'), ('analysis', 'analysis'), ('methods', 'method'), ('dynamically', 'dynamically'), ('adjusted', 'adjusted'), ('different', 'different'), ('situations', 'situation'), (',', ','), ('meaning', 'meaning'), ('analyze', 'analyze'), ('input', 'input'), ('data', 'data'), ('on-the-fly', 'on-the-fly'), ('.', '.')]


------------------- Sentence 2 -------------------

For  example, the classifiers are usually fixed which cannot be automatically changed.

>> Tokens are: 
 ['For', 'example', ',', 'classifiers', 'usually', 'fixed', 'automatically', 'changed', '.']

>> Bigrams are: 
 [('For', 'example'), ('example', ','), (',', 'classifiers'), ('classifiers', 'usually'), ('usually', 'fixed'), ('fixed', 'automatically'), ('automatically', 'changed'), ('changed', '.')]

>> Trigrams are: 
 [('For', 'example', ','), ('example', ',', 'classifiers'), (',', 'classifiers', 'usually'), ('classifiers', 'usually', 'fixed'), ('usually', 'fixed', 'automatically'), ('fixed', 'automatically', 'changed'), ('automatically', 'changed', '.')]

>> POS Tags are: 
 [('For', 'IN'), ('example', 'NN'), (',', ','), ('classifiers', 'NNS'), ('usually', 'RB'), ('fixed', 'VBN'), ('automatically', 'RB'), ('changed', 'VBN'), ('.', '.')]

>> Noun Phrases are: 
 ['example', 'classifiers']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('For', 'for'), ('example', 'exampl'), (',', ','), ('classifiers', 'classifi'), ('usually', 'usual'), ('fixed', 'fix'), ('automatically', 'automat'), ('changed', 'chang'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('For', 'for'), ('example', 'exampl'), (',', ','), ('classifiers', 'classifi'), ('usually', 'usual'), ('fixed', 'fix'), ('automatically', 'automat'), ('changed', 'chang'), ('.', '.')]

>> Lemmatization: 
 [('For', 'For'), ('example', 'example'), (',', ','), ('classifiers', 'classifier'), ('usually', 'usually'), ('fixed', 'fixed'), ('automatically', 'automatically'), ('changed', 'changed'), ('.', '.')]


------------------- Sentence 3 -------------------

The  incremental learning [66] is a promising research trend because it can dynamically  adjust the the classifiers on the training process with limited resources.

>> Tokens are: 
 ['The', 'incremental', 'learning', '[', '66', ']', 'promising', 'research', 'trend', 'dynamically', 'adjust', 'classifiers', 'training', 'process', 'limited', 'resources', '.']

>> Bigrams are: 
 [('The', 'incremental'), ('incremental', 'learning'), ('learning', '['), ('[', '66'), ('66', ']'), (']', 'promising'), ('promising', 'research'), ('research', 'trend'), ('trend', 'dynamically'), ('dynamically', 'adjust'), ('adjust', 'classifiers'), ('classifiers', 'training'), ('training', 'process'), ('process', 'limited'), ('limited', 'resources'), ('resources', '.')]

>> Trigrams are: 
 [('The', 'incremental', 'learning'), ('incremental', 'learning', '['), ('learning', '[', '66'), ('[', '66', ']'), ('66', ']', 'promising'), (']', 'promising', 'research'), ('promising', 'research', 'trend'), ('research', 'trend', 'dynamically'), ('trend', 'dynamically', 'adjust'), ('dynamically', 'adjust', 'classifiers'), ('adjust', 'classifiers', 'training'), ('classifiers', 'training', 'process'), ('training', 'process', 'limited'), ('process', 'limited', 'resources'), ('limited', 'resources', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('incremental', 'JJ'), ('learning', 'NN'), ('[', '$'), ('66', 'CD'), (']', 'NNP'), ('promising', 'VBG'), ('research', 'NN'), ('trend', 'NN'), ('dynamically', 'RB'), ('adjust', 'JJ'), ('classifiers', 'NNS'), ('training', 'VBG'), ('process', 'NN'), ('limited', 'JJ'), ('resources', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['The incremental learning', ']', 'research trend', 'adjust classifiers', 'process', 'limited resources']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('incremental', 'increment'), ('learning', 'learn'), ('[', '['), ('66', '66'), (']', ']'), ('promising', 'promis'), ('research', 'research'), ('trend', 'trend'), ('dynamically', 'dynam'), ('adjust', 'adjust'), ('classifiers', 'classifi'), ('training', 'train'), ('process', 'process'), ('limited', 'limit'), ('resources', 'resourc'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('incremental', 'increment'), ('learning', 'learn'), ('[', '['), ('66', '66'), (']', ']'), ('promising', 'promis'), ('research', 'research'), ('trend', 'trend'), ('dynamically', 'dynam'), ('adjust', 'adjust'), ('classifiers', 'classifi'), ('training', 'train'), ('process', 'process'), ('limited', 'limit'), ('resources', 'resourc'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('incremental', 'incremental'), ('learning', 'learning'), ('[', '['), ('66', '66'), (']', ']'), ('promising', 'promising'), ('research', 'research'), ('trend', 'trend'), ('dynamically', 'dynamically'), ('adjust', 'adjust'), ('classifiers', 'classifier'), ('training', 'training'), ('process', 'process'), ('limited', 'limited'), ('resources', 'resource'), ('.', '.')]


------------------- Sentence 4 -------------------

As a result, the  performance of traditional data analytics may not be useful to the problem of velocity  problem of big data.

>> Tokens are: 
 ['As', 'result', ',', 'performance', 'traditional', 'data', 'analytics', 'may', 'useful', 'problem', 'velocity', 'problem', 'big', 'data', '.']

>> Bigrams are: 
 [('As', 'result'), ('result', ','), (',', 'performance'), ('performance', 'traditional'), ('traditional', 'data'), ('data', 'analytics'), ('analytics', 'may'), ('may', 'useful'), ('useful', 'problem'), ('problem', 'velocity'), ('velocity', 'problem'), ('problem', 'big'), ('big', 'data'), ('data', '.')]

>> Trigrams are: 
 [('As', 'result', ','), ('result', ',', 'performance'), (',', 'performance', 'traditional'), ('performance', 'traditional', 'data'), ('traditional', 'data', 'analytics'), ('data', 'analytics', 'may'), ('analytics', 'may', 'useful'), ('may', 'useful', 'problem'), ('useful', 'problem', 'velocity'), ('problem', 'velocity', 'problem'), ('velocity', 'problem', 'big'), ('problem', 'big', 'data'), ('big', 'data', '.')]

>> POS Tags are: 
 [('As', 'IN'), ('result', 'NN'), (',', ','), ('performance', 'NN'), ('traditional', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('may', 'MD'), ('useful', 'VB'), ('problem', 'NN'), ('velocity', 'NN'), ('problem', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['result', 'performance', 'traditional data analytics', 'problem velocity problem', 'big data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('As', 'as'), ('result', 'result'), (',', ','), ('performance', 'perform'), ('traditional', 'tradit'), ('data', 'data'), ('analytics', 'analyt'), ('may', 'may'), ('useful', 'use'), ('problem', 'problem'), ('velocity', 'veloc'), ('problem', 'problem'), ('big', 'big'), ('data', 'data'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('As', 'as'), ('result', 'result'), (',', ','), ('performance', 'perform'), ('traditional', 'tradit'), ('data', 'data'), ('analytics', 'analyt'), ('may', 'may'), ('useful', 'use'), ('problem', 'problem'), ('velocity', 'veloc'), ('problem', 'problem'), ('big', 'big'), ('data', 'data'), ('.', '.')]

>> Lemmatization: 
 [('As', 'As'), ('result', 'result'), (',', ','), ('performance', 'performance'), ('traditional', 'traditional'), ('data', 'data'), ('analytics', 'analytics'), ('may', 'may'), ('useful', 'useful'), ('problem', 'problem'), ('velocity', 'velocity'), ('problem', 'problem'), ('big', 'big'), ('data', 'data'), ('.', '.')]



========================================== PARAGRAPH 145 ===========================================

 – Uniform data structure Most of the data mining problems assume that the format of  the input data will be the same. Therefore, the traditional data mining algorithms may  not be able to deal with the problem that the formats of different input data may be  different and some of the data may be incomplete. How to make the input data from  different sources the same format will be a possible solution to the variety problem of  big data. 

------------------- Sentence 1 -------------------

 – Uniform data structure Most of the data mining problems assume that the format of  the input data will be the same.

>> Tokens are: 
 ['–', 'Uniform', 'data', 'structure', 'Most', 'data', 'mining', 'problems', 'assume', 'format', 'input', 'data', '.']

>> Bigrams are: 
 [('–', 'Uniform'), ('Uniform', 'data'), ('data', 'structure'), ('structure', 'Most'), ('Most', 'data'), ('data', 'mining'), ('mining', 'problems'), ('problems', 'assume'), ('assume', 'format'), ('format', 'input'), ('input', 'data'), ('data', '.')]

>> Trigrams are: 
 [('–', 'Uniform', 'data'), ('Uniform', 'data', 'structure'), ('data', 'structure', 'Most'), ('structure', 'Most', 'data'), ('Most', 'data', 'mining'), ('data', 'mining', 'problems'), ('mining', 'problems', 'assume'), ('problems', 'assume', 'format'), ('assume', 'format', 'input'), ('format', 'input', 'data'), ('input', 'data', '.')]

>> POS Tags are: 
 [('–', 'JJ'), ('Uniform', 'NNP'), ('data', 'NN'), ('structure', 'NN'), ('Most', 'NNP'), ('data', 'NNS'), ('mining', 'NN'), ('problems', 'NNS'), ('assume', 'VBP'), ('format', 'JJ'), ('input', 'NN'), ('data', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['– Uniform data structure Most data mining problems', 'format input data']

>> Named Entities are: 
 [('ORGANIZATION', 'Uniform')] 

>> Stemming using Porter Stemmer: 
 [('–', '–'), ('Uniform', 'uniform'), ('data', 'data'), ('structure', 'structur'), ('Most', 'most'), ('data', 'data'), ('mining', 'mine'), ('problems', 'problem'), ('assume', 'assum'), ('format', 'format'), ('input', 'input'), ('data', 'data'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('–', '–'), ('Uniform', 'uniform'), ('data', 'data'), ('structure', 'structur'), ('Most', 'most'), ('data', 'data'), ('mining', 'mine'), ('problems', 'problem'), ('assume', 'assum'), ('format', 'format'), ('input', 'input'), ('data', 'data'), ('.', '.')]

>> Lemmatization: 
 [('–', '–'), ('Uniform', 'Uniform'), ('data', 'data'), ('structure', 'structure'), ('Most', 'Most'), ('data', 'data'), ('mining', 'mining'), ('problems', 'problem'), ('assume', 'assume'), ('format', 'format'), ('input', 'input'), ('data', 'data'), ('.', '.')]


------------------- Sentence 2 -------------------

Therefore, the traditional data mining algorithms may  not be able to deal with the problem that the formats of different input data may be  different and some of the data may be incomplete.

>> Tokens are: 
 ['Therefore', ',', 'traditional', 'data', 'mining', 'algorithms', 'may', 'able', 'deal', 'problem', 'formats', 'different', 'input', 'data', 'may', 'different', 'data', 'may', 'incomplete', '.']

>> Bigrams are: 
 [('Therefore', ','), (',', 'traditional'), ('traditional', 'data'), ('data', 'mining'), ('mining', 'algorithms'), ('algorithms', 'may'), ('may', 'able'), ('able', 'deal'), ('deal', 'problem'), ('problem', 'formats'), ('formats', 'different'), ('different', 'input'), ('input', 'data'), ('data', 'may'), ('may', 'different'), ('different', 'data'), ('data', 'may'), ('may', 'incomplete'), ('incomplete', '.')]

>> Trigrams are: 
 [('Therefore', ',', 'traditional'), (',', 'traditional', 'data'), ('traditional', 'data', 'mining'), ('data', 'mining', 'algorithms'), ('mining', 'algorithms', 'may'), ('algorithms', 'may', 'able'), ('may', 'able', 'deal'), ('able', 'deal', 'problem'), ('deal', 'problem', 'formats'), ('problem', 'formats', 'different'), ('formats', 'different', 'input'), ('different', 'input', 'data'), ('input', 'data', 'may'), ('data', 'may', 'different'), ('may', 'different', 'data'), ('different', 'data', 'may'), ('data', 'may', 'incomplete'), ('may', 'incomplete', '.')]

>> POS Tags are: 
 [('Therefore', 'RB'), (',', ','), ('traditional', 'JJ'), ('data', 'NN'), ('mining', 'NN'), ('algorithms', 'NN'), ('may', 'MD'), ('able', 'JJ'), ('deal', 'NN'), ('problem', 'NN'), ('formats', 'NNS'), ('different', 'JJ'), ('input', 'NN'), ('data', 'NNS'), ('may', 'MD'), ('different', 'JJ'), ('data', 'NNS'), ('may', 'MD'), ('incomplete', 'VB'), ('.', '.')]

>> Noun Phrases are: 
 ['traditional data mining algorithms', 'able deal problem formats', 'different input data', 'different data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Therefore', 'therefor'), (',', ','), ('traditional', 'tradit'), ('data', 'data'), ('mining', 'mine'), ('algorithms', 'algorithm'), ('may', 'may'), ('able', 'abl'), ('deal', 'deal'), ('problem', 'problem'), ('formats', 'format'), ('different', 'differ'), ('input', 'input'), ('data', 'data'), ('may', 'may'), ('different', 'differ'), ('data', 'data'), ('may', 'may'), ('incomplete', 'incomplet'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Therefore', 'therefor'), (',', ','), ('traditional', 'tradit'), ('data', 'data'), ('mining', 'mine'), ('algorithms', 'algorithm'), ('may', 'may'), ('able', 'abl'), ('deal', 'deal'), ('problem', 'problem'), ('formats', 'format'), ('different', 'differ'), ('input', 'input'), ('data', 'data'), ('may', 'may'), ('different', 'differ'), ('data', 'data'), ('may', 'may'), ('incomplete', 'incomplet'), ('.', '.')]

>> Lemmatization: 
 [('Therefore', 'Therefore'), (',', ','), ('traditional', 'traditional'), ('data', 'data'), ('mining', 'mining'), ('algorithms', 'algorithm'), ('may', 'may'), ('able', 'able'), ('deal', 'deal'), ('problem', 'problem'), ('formats', 'format'), ('different', 'different'), ('input', 'input'), ('data', 'data'), ('may', 'may'), ('different', 'different'), ('data', 'data'), ('may', 'may'), ('incomplete', 'incomplete'), ('.', '.')]


------------------- Sentence 3 -------------------

How to make the input data from  different sources the same format will be a possible solution to the variety problem of  big data.

>> Tokens are: 
 ['How', 'make', 'input', 'data', 'different', 'sources', 'format', 'possible', 'solution', 'variety', 'problem', 'big', 'data', '.']

>> Bigrams are: 
 [('How', 'make'), ('make', 'input'), ('input', 'data'), ('data', 'different'), ('different', 'sources'), ('sources', 'format'), ('format', 'possible'), ('possible', 'solution'), ('solution', 'variety'), ('variety', 'problem'), ('problem', 'big'), ('big', 'data'), ('data', '.')]

>> Trigrams are: 
 [('How', 'make', 'input'), ('make', 'input', 'data'), ('input', 'data', 'different'), ('data', 'different', 'sources'), ('different', 'sources', 'format'), ('sources', 'format', 'possible'), ('format', 'possible', 'solution'), ('possible', 'solution', 'variety'), ('solution', 'variety', 'problem'), ('variety', 'problem', 'big'), ('problem', 'big', 'data'), ('big', 'data', '.')]

>> POS Tags are: 
 [('How', 'WRB'), ('make', 'JJ'), ('input', 'NN'), ('data', 'NNS'), ('different', 'JJ'), ('sources', 'NNS'), ('format', 'VBP'), ('possible', 'JJ'), ('solution', 'NN'), ('variety', 'NN'), ('problem', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['make input data', 'different sources', 'possible solution variety problem', 'big data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('How', 'how'), ('make', 'make'), ('input', 'input'), ('data', 'data'), ('different', 'differ'), ('sources', 'sourc'), ('format', 'format'), ('possible', 'possibl'), ('solution', 'solut'), ('variety', 'varieti'), ('problem', 'problem'), ('big', 'big'), ('data', 'data'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('How', 'how'), ('make', 'make'), ('input', 'input'), ('data', 'data'), ('different', 'differ'), ('sources', 'sourc'), ('format', 'format'), ('possible', 'possibl'), ('solution', 'solut'), ('variety', 'varieti'), ('problem', 'problem'), ('big', 'big'), ('data', 'data'), ('.', '.')]

>> Lemmatization: 
 [('How', 'How'), ('make', 'make'), ('input', 'input'), ('data', 'data'), ('different', 'different'), ('sources', 'source'), ('format', 'format'), ('possible', 'possible'), ('solution', 'solution'), ('variety', 'variety'), ('problem', 'problem'), ('big', 'big'), ('data', 'data'), ('.', '.')]



========================================== PARAGRAPH 146 ===========================================

Because the traditional data analysis methods are not designed for large-scale and  complex data, they are almost impossible to be capable of analyzing the big data. Rede- signing and changing the way the data analysis methods are designed are two critical  

------------------- Sentence 1 -------------------

Because the traditional data analysis methods are not designed for large-scale and  complex data, they are almost impossible to be capable of analyzing the big data.

>> Tokens are: 
 ['Because', 'traditional', 'data', 'analysis', 'methods', 'designed', 'large-scale', 'complex', 'data', ',', 'almost', 'impossible', 'capable', 'analyzing', 'big', 'data', '.']

>> Bigrams are: 
 [('Because', 'traditional'), ('traditional', 'data'), ('data', 'analysis'), ('analysis', 'methods'), ('methods', 'designed'), ('designed', 'large-scale'), ('large-scale', 'complex'), ('complex', 'data'), ('data', ','), (',', 'almost'), ('almost', 'impossible'), ('impossible', 'capable'), ('capable', 'analyzing'), ('analyzing', 'big'), ('big', 'data'), ('data', '.')]

>> Trigrams are: 
 [('Because', 'traditional', 'data'), ('traditional', 'data', 'analysis'), ('data', 'analysis', 'methods'), ('analysis', 'methods', 'designed'), ('methods', 'designed', 'large-scale'), ('designed', 'large-scale', 'complex'), ('large-scale', 'complex', 'data'), ('complex', 'data', ','), ('data', ',', 'almost'), (',', 'almost', 'impossible'), ('almost', 'impossible', 'capable'), ('impossible', 'capable', 'analyzing'), ('capable', 'analyzing', 'big'), ('analyzing', 'big', 'data'), ('big', 'data', '.')]

>> POS Tags are: 
 [('Because', 'IN'), ('traditional', 'JJ'), ('data', 'NNS'), ('analysis', 'NN'), ('methods', 'NNS'), ('designed', 'VBN'), ('large-scale', 'JJ'), ('complex', 'JJ'), ('data', 'NN'), (',', ','), ('almost', 'RB'), ('impossible', 'JJ'), ('capable', 'JJ'), ('analyzing', 'VBG'), ('big', 'JJ'), ('data', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['traditional data analysis methods', 'large-scale complex data', 'big data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Because', 'becaus'), ('traditional', 'tradit'), ('data', 'data'), ('analysis', 'analysi'), ('methods', 'method'), ('designed', 'design'), ('large-scale', 'large-scal'), ('complex', 'complex'), ('data', 'data'), (',', ','), ('almost', 'almost'), ('impossible', 'imposs'), ('capable', 'capabl'), ('analyzing', 'analyz'), ('big', 'big'), ('data', 'data'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Because', 'becaus'), ('traditional', 'tradit'), ('data', 'data'), ('analysis', 'analysi'), ('methods', 'method'), ('designed', 'design'), ('large-scale', 'large-scal'), ('complex', 'complex'), ('data', 'data'), (',', ','), ('almost', 'almost'), ('impossible', 'imposs'), ('capable', 'capabl'), ('analyzing', 'analyz'), ('big', 'big'), ('data', 'data'), ('.', '.')]

>> Lemmatization: 
 [('Because', 'Because'), ('traditional', 'traditional'), ('data', 'data'), ('analysis', 'analysis'), ('methods', 'method'), ('designed', 'designed'), ('large-scale', 'large-scale'), ('complex', 'complex'), ('data', 'data'), (',', ','), ('almost', 'almost'), ('impossible', 'impossible'), ('capable', 'capable'), ('analyzing', 'analyzing'), ('big', 'big'), ('data', 'data'), ('.', '.')]


------------------- Sentence 2 -------------------

Rede- signing and changing the way the data analysis methods are designed are two critical

>> Tokens are: 
 ['Rede-', 'signing', 'changing', 'way', 'data', 'analysis', 'methods', 'designed', 'two', 'critical']

>> Bigrams are: 
 [('Rede-', 'signing'), ('signing', 'changing'), ('changing', 'way'), ('way', 'data'), ('data', 'analysis'), ('analysis', 'methods'), ('methods', 'designed'), ('designed', 'two'), ('two', 'critical')]

>> Trigrams are: 
 [('Rede-', 'signing', 'changing'), ('signing', 'changing', 'way'), ('changing', 'way', 'data'), ('way', 'data', 'analysis'), ('data', 'analysis', 'methods'), ('analysis', 'methods', 'designed'), ('methods', 'designed', 'two'), ('designed', 'two', 'critical')]

>> POS Tags are: 
 [('Rede-', 'JJ'), ('signing', 'VBG'), ('changing', 'VBG'), ('way', 'NN'), ('data', 'NNS'), ('analysis', 'NN'), ('methods', 'NNS'), ('designed', 'VBN'), ('two', 'CD'), ('critical', 'JJ')]

>> Noun Phrases are: 
 ['way data analysis methods']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Rede-', 'rede-'), ('signing', 'sign'), ('changing', 'chang'), ('way', 'way'), ('data', 'data'), ('analysis', 'analysi'), ('methods', 'method'), ('designed', 'design'), ('two', 'two'), ('critical', 'critic')]

>> Stemming using Snowball Stemmer: 
 [('Rede-', 'rede-'), ('signing', 'sign'), ('changing', 'chang'), ('way', 'way'), ('data', 'data'), ('analysis', 'analysi'), ('methods', 'method'), ('designed', 'design'), ('two', 'two'), ('critical', 'critic')]

>> Lemmatization: 
 [('Rede-', 'Rede-'), ('signing', 'signing'), ('changing', 'changing'), ('way', 'way'), ('data', 'data'), ('analysis', 'analysis'), ('methods', 'method'), ('designed', 'designed'), ('two', 'two'), ('critical', 'critical')]



========================================== PARAGRAPH 147 ===========================================

Table 2 Efficient data analytics methods for data mining 

------------------- Sentence 1 -------------------

Table 2 Efficient data analytics methods for data mining

>> Tokens are: 
 ['Table', '2', 'Efficient', 'data', 'analytics', 'methods', 'data', 'mining']

>> Bigrams are: 
 [('Table', '2'), ('2', 'Efficient'), ('Efficient', 'data'), ('data', 'analytics'), ('analytics', 'methods'), ('methods', 'data'), ('data', 'mining')]

>> Trigrams are: 
 [('Table', '2', 'Efficient'), ('2', 'Efficient', 'data'), ('Efficient', 'data', 'analytics'), ('data', 'analytics', 'methods'), ('analytics', 'methods', 'data'), ('methods', 'data', 'mining')]

>> POS Tags are: 
 [('Table', 'JJ'), ('2', 'CD'), ('Efficient', 'NNP'), ('data', 'NNS'), ('analytics', 'NNS'), ('methods', 'NNS'), ('data', 'NNS'), ('mining', 'NN')]

>> Noun Phrases are: 
 ['Efficient data analytics methods data mining']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Table', 'tabl'), ('2', '2'), ('Efficient', 'effici'), ('data', 'data'), ('analytics', 'analyt'), ('methods', 'method'), ('data', 'data'), ('mining', 'mine')]

>> Stemming using Snowball Stemmer: 
 [('Table', 'tabl'), ('2', '2'), ('Efficient', 'effici'), ('data', 'data'), ('analytics', 'analyt'), ('methods', 'method'), ('data', 'data'), ('mining', 'mine')]

>> Lemmatization: 
 [('Table', 'Table'), ('2', '2'), ('Efficient', 'Efficient'), ('data', 'data'), ('analytics', 'analytics'), ('methods', 'method'), ('data', 'data'), ('mining', 'mining')]



========================================== PARAGRAPH 148 ===========================================

Problem Method References 

------------------- Sentence 1 -------------------

Problem Method References

>> Tokens are: 
 ['Problem', 'Method', 'References']

>> Bigrams are: 
 [('Problem', 'Method'), ('Method', 'References')]

>> Trigrams are: 
 [('Problem', 'Method', 'References')]

>> POS Tags are: 
 [('Problem', 'NNP'), ('Method', 'NNP'), ('References', 'NNS')]

>> Noun Phrases are: 
 ['Problem Method References']

>> Named Entities are: 
 [('PERSON', 'Problem'), ('ORGANIZATION', 'Method References')] 

>> Stemming using Porter Stemmer: 
 [('Problem', 'problem'), ('Method', 'method'), ('References', 'refer')]

>> Stemming using Snowball Stemmer: 
 [('Problem', 'problem'), ('Method', 'method'), ('References', 'refer')]

>> Lemmatization: 
 [('Problem', 'Problem'), ('Method', 'Method'), ('References', 'References')]



========================================== PARAGRAPH 149 ===========================================

Clustering BIRCH [44] 

------------------- Sentence 1 -------------------

Clustering BIRCH [44]

>> Tokens are: 
 ['Clustering', 'BIRCH', '[', '44', ']']

>> Bigrams are: 
 [('Clustering', 'BIRCH'), ('BIRCH', '['), ('[', '44'), ('44', ']')]

>> Trigrams are: 
 [('Clustering', 'BIRCH', '['), ('BIRCH', '[', '44'), ('[', '44', ']')]

>> POS Tags are: 
 [('Clustering', 'VBG'), ('BIRCH', 'NNP'), ('[', '$'), ('44', 'CD'), (']', 'NN')]

>> Noun Phrases are: 
 ['BIRCH', ']']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Clustering', 'cluster'), ('BIRCH', 'birch'), ('[', '['), ('44', '44'), (']', ']')]

>> Stemming using Snowball Stemmer: 
 [('Clustering', 'cluster'), ('BIRCH', 'birch'), ('[', '['), ('44', '44'), (']', ']')]

>> Lemmatization: 
 [('Clustering', 'Clustering'), ('BIRCH', 'BIRCH'), ('[', '['), ('44', '44'), (']', ']')]



========================================== PARAGRAPH 150 ===========================================

DBSCAN [45] 

------------------- Sentence 1 -------------------

DBSCAN [45]

>> Tokens are: 
 ['DBSCAN', '[', '45', ']']

>> Bigrams are: 
 [('DBSCAN', '['), ('[', '45'), ('45', ']')]

>> Trigrams are: 
 [('DBSCAN', '[', '45'), ('[', '45', ']')]

>> POS Tags are: 
 [('DBSCAN', 'NNP'), ('[', 'NNP'), ('45', 'CD'), (']', 'NN')]

>> Noun Phrases are: 
 ['DBSCAN [', ']']

>> Named Entities are: 
 [('ORGANIZATION', 'DBSCAN')] 

>> Stemming using Porter Stemmer: 
 [('DBSCAN', 'dbscan'), ('[', '['), ('45', '45'), (']', ']')]

>> Stemming using Snowball Stemmer: 
 [('DBSCAN', 'dbscan'), ('[', '['), ('45', '45'), (']', ']')]

>> Lemmatization: 
 [('DBSCAN', 'DBSCAN'), ('[', '['), ('45', '45'), (']', ']')]



========================================== PARAGRAPH 151 ===========================================

Incremental DBSCAN [46] 

------------------- Sentence 1 -------------------

Incremental DBSCAN [46]

>> Tokens are: 
 ['Incremental', 'DBSCAN', '[', '46', ']']

>> Bigrams are: 
 [('Incremental', 'DBSCAN'), ('DBSCAN', '['), ('[', '46'), ('46', ']')]

>> Trigrams are: 
 [('Incremental', 'DBSCAN', '['), ('DBSCAN', '[', '46'), ('[', '46', ']')]

>> POS Tags are: 
 [('Incremental', 'JJ'), ('DBSCAN', 'NNP'), ('[', 'NNP'), ('46', 'CD'), (']', 'NN')]

>> Noun Phrases are: 
 ['Incremental DBSCAN [', ']']

>> Named Entities are: 
 [('ORGANIZATION', 'Incremental'), ('ORGANIZATION', 'DBSCAN')] 

>> Stemming using Porter Stemmer: 
 [('Incremental', 'increment'), ('DBSCAN', 'dbscan'), ('[', '['), ('46', '46'), (']', ']')]

>> Stemming using Snowball Stemmer: 
 [('Incremental', 'increment'), ('DBSCAN', 'dbscan'), ('[', '['), ('46', '46'), (']', ']')]

>> Lemmatization: 
 [('Incremental', 'Incremental'), ('DBSCAN', 'DBSCAN'), ('[', '['), ('46', '46'), (']', ']')]



========================================== PARAGRAPH 152 ===========================================

RKM [47] 

------------------- Sentence 1 -------------------

RKM [47]

>> Tokens are: 
 ['RKM', '[', '47', ']']

>> Bigrams are: 
 [('RKM', '['), ('[', '47'), ('47', ']')]

>> Trigrams are: 
 [('RKM', '[', '47'), ('[', '47', ']')]

>> POS Tags are: 
 [('RKM', 'NNP'), ('[', 'VBD'), ('47', 'CD'), (']', 'NN')]

>> Noun Phrases are: 
 ['RKM', ']']

>> Named Entities are: 
 [('ORGANIZATION', 'RKM')] 

>> Stemming using Porter Stemmer: 
 [('RKM', 'rkm'), ('[', '['), ('47', '47'), (']', ']')]

>> Stemming using Snowball Stemmer: 
 [('RKM', 'rkm'), ('[', '['), ('47', '47'), (']', ']')]

>> Lemmatization: 
 [('RKM', 'RKM'), ('[', '['), ('47', '47'), (']', ']')]



========================================== PARAGRAPH 153 ===========================================

TKM [42] 

------------------- Sentence 1 -------------------

TKM [42]

>> Tokens are: 
 ['TKM', '[', '42', ']']

>> Bigrams are: 
 [('TKM', '['), ('[', '42'), ('42', ']')]

>> Trigrams are: 
 [('TKM', '[', '42'), ('[', '42', ']')]

>> POS Tags are: 
 [('TKM', 'NNP'), ('[', 'VBD'), ('42', 'CD'), (']', 'NN')]

>> Noun Phrases are: 
 ['TKM', ']']

>> Named Entities are: 
 [('ORGANIZATION', 'TKM')] 

>> Stemming using Porter Stemmer: 
 [('TKM', 'tkm'), ('[', '['), ('42', '42'), (']', ']')]

>> Stemming using Snowball Stemmer: 
 [('TKM', 'tkm'), ('[', '['), ('42', '42'), (']', ']')]

>> Lemmatization: 
 [('TKM', 'TKM'), ('[', '['), ('42', '42'), (']', ']')]



========================================== PARAGRAPH 154 ===========================================

Classification SLIQ [50] 

------------------- Sentence 1 -------------------

Classification SLIQ [50]

>> Tokens are: 
 ['Classification', 'SLIQ', '[', '50', ']']

>> Bigrams are: 
 [('Classification', 'SLIQ'), ('SLIQ', '['), ('[', '50'), ('50', ']')]

>> Trigrams are: 
 [('Classification', 'SLIQ', '['), ('SLIQ', '[', '50'), ('[', '50', ']')]

>> POS Tags are: 
 [('Classification', 'NNP'), ('SLIQ', 'NNP'), ('[', 'VBD'), ('50', 'CD'), (']', 'NN')]

>> Noun Phrases are: 
 ['Classification SLIQ', ']']

>> Named Entities are: 
 [('PERSON', 'Classification'), ('ORGANIZATION', 'SLIQ')] 

>> Stemming using Porter Stemmer: 
 [('Classification', 'classif'), ('SLIQ', 'sliq'), ('[', '['), ('50', '50'), (']', ']')]

>> Stemming using Snowball Stemmer: 
 [('Classification', 'classif'), ('SLIQ', 'sliq'), ('[', '['), ('50', '50'), (']', ']')]

>> Lemmatization: 
 [('Classification', 'Classification'), ('SLIQ', 'SLIQ'), ('[', '['), ('50', '50'), (']', ']')]



========================================== PARAGRAPH 155 ===========================================

TLAESA [51] 

------------------- Sentence 1 -------------------

TLAESA [51]

>> Tokens are: 
 ['TLAESA', '[', '51', ']']

>> Bigrams are: 
 [('TLAESA', '['), ('[', '51'), ('51', ']')]

>> Trigrams are: 
 [('TLAESA', '[', '51'), ('[', '51', ']')]

>> POS Tags are: 
 [('TLAESA', 'NNP'), ('[', 'VBZ'), ('51', 'CD'), (']', 'NN')]

>> Noun Phrases are: 
 ['TLAESA', ']']

>> Named Entities are: 
 [('ORGANIZATION', 'TLAESA')] 

>> Stemming using Porter Stemmer: 
 [('TLAESA', 'tlaesa'), ('[', '['), ('51', '51'), (']', ']')]

>> Stemming using Snowball Stemmer: 
 [('TLAESA', 'tlaesa'), ('[', '['), ('51', '51'), (']', ']')]

>> Lemmatization: 
 [('TLAESA', 'TLAESA'), ('[', '['), ('51', '51'), (']', ']')]



========================================== PARAGRAPH 156 ===========================================

FastNN [52] 

------------------- Sentence 1 -------------------

FastNN [52]

>> Tokens are: 
 ['FastNN', '[', '52', ']']

>> Bigrams are: 
 [('FastNN', '['), ('[', '52'), ('52', ']')]

>> Trigrams are: 
 [('FastNN', '[', '52'), ('[', '52', ']')]

>> POS Tags are: 
 [('FastNN', 'NNP'), ('[', 'VBD'), ('52', 'CD'), (']', 'NN')]

>> Noun Phrases are: 
 ['FastNN', ']']

>> Named Entities are: 
 [('ORGANIZATION', 'FastNN')] 

>> Stemming using Porter Stemmer: 
 [('FastNN', 'fastnn'), ('[', '['), ('52', '52'), (']', ']')]

>> Stemming using Snowball Stemmer: 
 [('FastNN', 'fastnn'), ('[', '['), ('52', '52'), (']', ']')]

>> Lemmatization: 
 [('FastNN', 'FastNN'), ('[', '['), ('52', '52'), (']', ']')]



========================================== PARAGRAPH 157 ===========================================

SFFS [53] 

------------------- Sentence 1 -------------------

SFFS [53]

>> Tokens are: 
 ['SFFS', '[', '53', ']']

>> Bigrams are: 
 [('SFFS', '['), ('[', '53'), ('53', ']')]

>> Trigrams are: 
 [('SFFS', '[', '53'), ('[', '53', ']')]

>> POS Tags are: 
 [('SFFS', 'NNP'), ('[', 'VBD'), ('53', 'CD'), (']', 'NN')]

>> Noun Phrases are: 
 ['SFFS', ']']

>> Named Entities are: 
 [('ORGANIZATION', 'SFFS')] 

>> Stemming using Porter Stemmer: 
 [('SFFS', 'sff'), ('[', '['), ('53', '53'), (']', ']')]

>> Stemming using Snowball Stemmer: 
 [('SFFS', 'sffs'), ('[', '['), ('53', '53'), (']', ']')]

>> Lemmatization: 
 [('SFFS', 'SFFS'), ('[', '['), ('53', '53'), (']', ']')]



========================================== PARAGRAPH 158 ===========================================

GPU‑based SVM [43] 

------------------- Sentence 1 -------------------

GPU‑based SVM [43]

>> Tokens are: 
 ['GPU‑based', 'SVM', '[', '43', ']']

>> Bigrams are: 
 [('GPU‑based', 'SVM'), ('SVM', '['), ('[', '43'), ('43', ']')]

>> Trigrams are: 
 [('GPU‑based', 'SVM', '['), ('SVM', '[', '43'), ('[', '43', ']')]

>> POS Tags are: 
 [('GPU‑based', 'VBN'), ('SVM', 'NNP'), ('[', '$'), ('43', 'CD'), (']', 'NN')]

>> Noun Phrases are: 
 ['SVM', ']']

>> Named Entities are: 
 [('ORGANIZATION', 'SVM')] 

>> Stemming using Porter Stemmer: 
 [('GPU‑based', 'gpu‑bas'), ('SVM', 'svm'), ('[', '['), ('43', '43'), (']', ']')]

>> Stemming using Snowball Stemmer: 
 [('GPU‑based', 'gpu‑bas'), ('SVM', 'svm'), ('[', '['), ('43', '43'), (']', ']')]

>> Lemmatization: 
 [('GPU‑based', 'GPU‑based'), ('SVM', 'SVM'), ('[', '['), ('43', '43'), (']', ']')]



========================================== PARAGRAPH 159 ===========================================

Association rules CLOSET [54] 

------------------- Sentence 1 -------------------

Association rules CLOSET [54]

>> Tokens are: 
 ['Association', 'rules', 'CLOSET', '[', '54', ']']

>> Bigrams are: 
 [('Association', 'rules'), ('rules', 'CLOSET'), ('CLOSET', '['), ('[', '54'), ('54', ']')]

>> Trigrams are: 
 [('Association', 'rules', 'CLOSET'), ('rules', 'CLOSET', '['), ('CLOSET', '[', '54'), ('[', '54', ']')]

>> POS Tags are: 
 [('Association', 'NNP'), ('rules', 'NNS'), ('CLOSET', 'NNP'), ('[', 'VBP'), ('54', 'CD'), (']', 'NN')]

>> Noun Phrases are: 
 ['Association rules CLOSET', ']']

>> Named Entities are: 
 [('ORGANIZATION', 'CLOSET')] 

>> Stemming using Porter Stemmer: 
 [('Association', 'associ'), ('rules', 'rule'), ('CLOSET', 'closet'), ('[', '['), ('54', '54'), (']', ']')]

>> Stemming using Snowball Stemmer: 
 [('Association', 'associ'), ('rules', 'rule'), ('CLOSET', 'closet'), ('[', '['), ('54', '54'), (']', ']')]

>> Lemmatization: 
 [('Association', 'Association'), ('rules', 'rule'), ('CLOSET', 'CLOSET'), ('[', '['), ('54', '54'), (']', ']')]



========================================== PARAGRAPH 160 ===========================================

FP‑tree [32] 

------------------- Sentence 1 -------------------

FP‑tree [32]

>> Tokens are: 
 ['FP‑tree', '[', '32', ']']

>> Bigrams are: 
 [('FP‑tree', '['), ('[', '32'), ('32', ']')]

>> Trigrams are: 
 [('FP‑tree', '[', '32'), ('[', '32', ']')]

>> POS Tags are: 
 [('FP‑tree', 'NNP'), ('[', 'VBD'), ('32', 'CD'), (']', 'NN')]

>> Noun Phrases are: 
 ['FP‑tree', ']']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('FP‑tree', 'fp‑tree'), ('[', '['), ('32', '32'), (']', ']')]

>> Stemming using Snowball Stemmer: 
 [('FP‑tree', 'fp‑tree'), ('[', '['), ('32', '32'), (']', ']')]

>> Lemmatization: 
 [('FP‑tree', 'FP‑tree'), ('[', '['), ('32', '32'), (']', ']')]



========================================== PARAGRAPH 161 ===========================================

CHARM [55] 

------------------- Sentence 1 -------------------

CHARM [55]

>> Tokens are: 
 ['CHARM', '[', '55', ']']

>> Bigrams are: 
 [('CHARM', '['), ('[', '55'), ('55', ']')]

>> Trigrams are: 
 [('CHARM', '[', '55'), ('[', '55', ']')]

>> POS Tags are: 
 [('CHARM', 'NNP'), ('[', 'VBD'), ('55', 'CD'), (']', 'NN')]

>> Noun Phrases are: 
 ['CHARM', ']']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('CHARM', 'charm'), ('[', '['), ('55', '55'), (']', ']')]

>> Stemming using Snowball Stemmer: 
 [('CHARM', 'charm'), ('[', '['), ('55', '55'), (']', ']')]

>> Lemmatization: 
 [('CHARM', 'CHARM'), ('[', '['), ('55', '55'), (']', ']')]



========================================== PARAGRAPH 162 ===========================================

MAFIA [56] 

------------------- Sentence 1 -------------------

MAFIA [56]

>> Tokens are: 
 ['MAFIA', '[', '56', ']']

>> Bigrams are: 
 [('MAFIA', '['), ('[', '56'), ('56', ']')]

>> Trigrams are: 
 [('MAFIA', '[', '56'), ('[', '56', ']')]

>> POS Tags are: 
 [('MAFIA', 'NNP'), ('[', 'VBD'), ('56', 'CD'), (']', 'NN')]

>> Noun Phrases are: 
 ['MAFIA', ']']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('MAFIA', 'mafia'), ('[', '['), ('56', '56'), (']', ']')]

>> Stemming using Snowball Stemmer: 
 [('MAFIA', 'mafia'), ('[', '['), ('56', '56'), (']', ']')]

>> Lemmatization: 
 [('MAFIA', 'MAFIA'), ('[', '['), ('56', '56'), (']', ']')]



========================================== PARAGRAPH 163 ===========================================

FAST [57] 

------------------- Sentence 1 -------------------

FAST [57]

>> Tokens are: 
 ['FAST', '[', '57', ']']

>> Bigrams are: 
 [('FAST', '['), ('[', '57'), ('57', ']')]

>> Trigrams are: 
 [('FAST', '[', '57'), ('[', '57', ']')]

>> POS Tags are: 
 [('FAST', 'NNP'), ('[', 'VBD'), ('57', 'CD'), (']', 'NN')]

>> Noun Phrases are: 
 ['FAST', ']']

>> Named Entities are: 
 [('GPE', 'FAST')] 

>> Stemming using Porter Stemmer: 
 [('FAST', 'fast'), ('[', '['), ('57', '57'), (']', ']')]

>> Stemming using Snowball Stemmer: 
 [('FAST', 'fast'), ('[', '['), ('57', '57'), (']', ']')]

>> Lemmatization: 
 [('FAST', 'FAST'), ('[', '['), ('57', '57'), (']', ']')]



========================================== PARAGRAPH 164 ===========================================

Sequential patterns SPADE [58] 

------------------- Sentence 1 -------------------

Sequential patterns SPADE [58]

>> Tokens are: 
 ['Sequential', 'patterns', 'SPADE', '[', '58', ']']

>> Bigrams are: 
 [('Sequential', 'patterns'), ('patterns', 'SPADE'), ('SPADE', '['), ('[', '58'), ('58', ']')]

>> Trigrams are: 
 [('Sequential', 'patterns', 'SPADE'), ('patterns', 'SPADE', '['), ('SPADE', '[', '58'), ('[', '58', ']')]

>> POS Tags are: 
 [('Sequential', 'JJ'), ('patterns', 'NNS'), ('SPADE', 'NNP'), ('[', 'VBD'), ('58', 'CD'), (']', 'NN')]

>> Noun Phrases are: 
 ['Sequential patterns SPADE', ']']

>> Named Entities are: 
 [('ORGANIZATION', 'SPADE')] 

>> Stemming using Porter Stemmer: 
 [('Sequential', 'sequenti'), ('patterns', 'pattern'), ('SPADE', 'spade'), ('[', '['), ('58', '58'), (']', ']')]

>> Stemming using Snowball Stemmer: 
 [('Sequential', 'sequenti'), ('patterns', 'pattern'), ('SPADE', 'spade'), ('[', '['), ('58', '58'), (']', ']')]

>> Lemmatization: 
 [('Sequential', 'Sequential'), ('patterns', 'pattern'), ('SPADE', 'SPADE'), ('[', '['), ('58', '58'), (']', ']')]



========================================== PARAGRAPH 165 ===========================================

CloSpan [59] 

------------------- Sentence 1 -------------------

CloSpan [59]

>> Tokens are: 
 ['CloSpan', '[', '59', ']']

>> Bigrams are: 
 [('CloSpan', '['), ('[', '59'), ('59', ']')]

>> Trigrams are: 
 [('CloSpan', '[', '59'), ('[', '59', ']')]

>> POS Tags are: 
 [('CloSpan', 'NNP'), ('[', 'VBD'), ('59', 'CD'), (']', 'NN')]

>> Noun Phrases are: 
 ['CloSpan', ']']

>> Named Entities are: 
 [('GPE', 'CloSpan')] 

>> Stemming using Porter Stemmer: 
 [('CloSpan', 'clospan'), ('[', '['), ('59', '59'), (']', ']')]

>> Stemming using Snowball Stemmer: 
 [('CloSpan', 'clospan'), ('[', '['), ('59', '59'), (']', ']')]

>> Lemmatization: 
 [('CloSpan', 'CloSpan'), ('[', '['), ('59', '59'), (']', ']')]



========================================== PARAGRAPH 166 ===========================================

PrefixSpan [60] 

------------------- Sentence 1 -------------------

PrefixSpan [60]

>> Tokens are: 
 ['PrefixSpan', '[', '60', ']']

>> Bigrams are: 
 [('PrefixSpan', '['), ('[', '60'), ('60', ']')]

>> Trigrams are: 
 [('PrefixSpan', '[', '60'), ('[', '60', ']')]

>> POS Tags are: 
 [('PrefixSpan', 'NNP'), ('[', 'VBD'), ('60', 'CD'), (']', 'NN')]

>> Noun Phrases are: 
 ['PrefixSpan', ']']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('PrefixSpan', 'prefixspan'), ('[', '['), ('60', '60'), (']', ']')]

>> Stemming using Snowball Stemmer: 
 [('PrefixSpan', 'prefixspan'), ('[', '['), ('60', '60'), (']', ']')]

>> Lemmatization: 
 [('PrefixSpan', 'PrefixSpan'), ('[', '['), ('60', '60'), (']', ']')]



========================================== PARAGRAPH 167 ===========================================

SPAM [61] 

------------------- Sentence 1 -------------------

SPAM [61]

>> Tokens are: 
 ['SPAM', '[', '61', ']']

>> Bigrams are: 
 [('SPAM', '['), ('[', '61'), ('61', ']')]

>> Trigrams are: 
 [('SPAM', '[', '61'), ('[', '61', ']')]

>> POS Tags are: 
 [('SPAM', 'NNP'), ('[', 'VBD'), ('61', 'CD'), (']', 'NN')]

>> Noun Phrases are: 
 ['SPAM', ']']

>> Named Entities are: 
 [('ORGANIZATION', 'SPAM')] 

>> Stemming using Porter Stemmer: 
 [('SPAM', 'spam'), ('[', '['), ('61', '61'), (']', ']')]

>> Stemming using Snowball Stemmer: 
 [('SPAM', 'spam'), ('[', '['), ('61', '61'), (']', ']')]

>> Lemmatization: 
 [('SPAM', 'SPAM'), ('[', '['), ('61', '61'), (']', ']')]



========================================== PARAGRAPH 168 ===========================================

ISE [62]

------------------- Sentence 1 -------------------

ISE [62]

>> Tokens are: 
 ['ISE', '[', '62', ']']

>> Bigrams are: 
 [('ISE', '['), ('[', '62'), ('62', ']')]

>> Trigrams are: 
 [('ISE', '[', '62'), ('[', '62', ']')]

>> POS Tags are: 
 [('ISE', 'NNP'), ('[', 'VBZ'), ('62', 'CD'), (']', 'NN')]

>> Noun Phrases are: 
 ['ISE', ']']

>> Named Entities are: 
 [('ORGANIZATION', 'ISE')] 

>> Stemming using Porter Stemmer: 
 [('ISE', 'ise'), ('[', '['), ('62', '62'), (']', ']')]

>> Stemming using Snowball Stemmer: 
 [('ISE', 'ise'), ('[', '['), ('62', '62'), (']', ']')]

>> Lemmatization: 
 [('ISE', 'ISE'), ('[', '['), ('62', '62'), (']', ']')]



========================================== PARAGRAPH 169 ===========================================

Page 10 of 32Tsai et al. Journal of Big Data  (2015) 2:21  

------------------- Sentence 1 -------------------

Page 10 of 32Tsai et al.

>> Tokens are: 
 ['Page', '10', '32Tsai', 'et', 'al', '.']

>> Bigrams are: 
 [('Page', '10'), ('10', '32Tsai'), ('32Tsai', 'et'), ('et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('Page', '10', '32Tsai'), ('10', '32Tsai', 'et'), ('32Tsai', 'et', 'al'), ('et', 'al', '.')]

>> POS Tags are: 
 [('Page', 'NN'), ('10', 'CD'), ('32Tsai', 'CD'), ('et', 'NN'), ('al', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Page', 'et al']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Page', 'page'), ('10', '10'), ('32Tsai', '32tsai'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Page', 'page'), ('10', '10'), ('32Tsai', '32tsai'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('Page', 'Page'), ('10', '10'), ('32Tsai', '32Tsai'), ('et', 'et'), ('al', 'al'), ('.', '.')]


------------------- Sentence 2 -------------------

Journal of Big Data  (2015) 2:21

>> Tokens are: 
 ['Journal', 'Big', 'Data', '(', '2015', ')', '2:21']

>> Bigrams are: 
 [('Journal', 'Big'), ('Big', 'Data'), ('Data', '('), ('(', '2015'), ('2015', ')'), (')', '2:21')]

>> Trigrams are: 
 [('Journal', 'Big', 'Data'), ('Big', 'Data', '('), ('Data', '(', '2015'), ('(', '2015', ')'), ('2015', ')', '2:21')]

>> POS Tags are: 
 [('Journal', 'NNP'), ('Big', 'NNP'), ('Data', 'NNP'), ('(', '('), ('2015', 'CD'), (')', ')'), ('2:21', 'CD')]

>> Noun Phrases are: 
 ['Journal Big Data']

>> Named Entities are: 
 [('PERSON', 'Journal')] 

>> Stemming using Porter Stemmer: 
 [('Journal', 'journal'), ('Big', 'big'), ('Data', 'data'), ('(', '('), ('2015', '2015'), (')', ')'), ('2:21', '2:21')]

>> Stemming using Snowball Stemmer: 
 [('Journal', 'journal'), ('Big', 'big'), ('Data', 'data'), ('(', '('), ('2015', '2015'), (')', ')'), ('2:21', '2:21')]

>> Lemmatization: 
 [('Journal', 'Journal'), ('Big', 'Big'), ('Data', 'Data'), ('(', '('), ('2015', '2015'), (')', ')'), ('2:21', '2:21')]



========================================== PARAGRAPH 170 ===========================================

trends for big data analysis. Several important concepts in the design of the big data  analysis method will be given in the following sections. 

------------------- Sentence 1 -------------------

trends for big data analysis.

>> Tokens are: 
 ['trends', 'big', 'data', 'analysis', '.']

>> Bigrams are: 
 [('trends', 'big'), ('big', 'data'), ('data', 'analysis'), ('analysis', '.')]

>> Trigrams are: 
 [('trends', 'big', 'data'), ('big', 'data', 'analysis'), ('data', 'analysis', '.')]

>> POS Tags are: 
 [('trends', 'NNS'), ('big', 'JJ'), ('data', 'NNS'), ('analysis', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['trends', 'big data analysis']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('trends', 'trend'), ('big', 'big'), ('data', 'data'), ('analysis', 'analysi'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('trends', 'trend'), ('big', 'big'), ('data', 'data'), ('analysis', 'analysi'), ('.', '.')]

>> Lemmatization: 
 [('trends', 'trend'), ('big', 'big'), ('data', 'data'), ('analysis', 'analysis'), ('.', '.')]


------------------- Sentence 2 -------------------

Several important concepts in the design of the big data  analysis method will be given in the following sections.

>> Tokens are: 
 ['Several', 'important', 'concepts', 'design', 'big', 'data', 'analysis', 'method', 'given', 'following', 'sections', '.']

>> Bigrams are: 
 [('Several', 'important'), ('important', 'concepts'), ('concepts', 'design'), ('design', 'big'), ('big', 'data'), ('data', 'analysis'), ('analysis', 'method'), ('method', 'given'), ('given', 'following'), ('following', 'sections'), ('sections', '.')]

>> Trigrams are: 
 [('Several', 'important', 'concepts'), ('important', 'concepts', 'design'), ('concepts', 'design', 'big'), ('design', 'big', 'data'), ('big', 'data', 'analysis'), ('data', 'analysis', 'method'), ('analysis', 'method', 'given'), ('method', 'given', 'following'), ('given', 'following', 'sections'), ('following', 'sections', '.')]

>> POS Tags are: 
 [('Several', 'JJ'), ('important', 'JJ'), ('concepts', 'NNS'), ('design', 'VBP'), ('big', 'JJ'), ('data', 'NNS'), ('analysis', 'NN'), ('method', 'NN'), ('given', 'VBN'), ('following', 'VBG'), ('sections', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['Several important concepts', 'big data analysis method', 'sections']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Several', 'sever'), ('important', 'import'), ('concepts', 'concept'), ('design', 'design'), ('big', 'big'), ('data', 'data'), ('analysis', 'analysi'), ('method', 'method'), ('given', 'given'), ('following', 'follow'), ('sections', 'section'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Several', 'sever'), ('important', 'import'), ('concepts', 'concept'), ('design', 'design'), ('big', 'big'), ('data', 'data'), ('analysis', 'analysi'), ('method', 'method'), ('given', 'given'), ('following', 'follow'), ('sections', 'section'), ('.', '.')]

>> Lemmatization: 
 [('Several', 'Several'), ('important', 'important'), ('concepts', 'concept'), ('design', 'design'), ('big', 'big'), ('data', 'data'), ('analysis', 'analysis'), ('method', 'method'), ('given', 'given'), ('following', 'following'), ('sections', 'section'), ('.', '.')]



========================================== PARAGRAPH 171 ===========================================

Big data analytics Nowadays, the data that need to be analyzed are not just large, but they are composed  of various data types, and even including streaming data [67]. Since big data has the  unique features of “massive, high dimensional, heterogeneous, complex, unstructured,  incomplete, noisy, and erroneous,” which may change the statistical and data analy- sis approaches [68]. Although it seems that big data makes it possible for us to collect  more data to find more useful information, the truth is that more data do not necessar- ily mean more useful information. It may contain more ambiguous or abnormal data.  For instance, a user may have multiple accounts, or an account may be used by multiple  users, which may degrade the accuracy of the mining results [69]. Therefore, several new  issues for data analytics come up, such as privacy, security, storage, fault tolerance, and  quality of data [70]. 

------------------- Sentence 1 -------------------

Big data analytics Nowadays, the data that need to be analyzed are not just large, but they are composed  of various data types, and even including streaming data [67].

>> Tokens are: 
 ['Big', 'data', 'analytics', 'Nowadays', ',', 'data', 'need', 'analyzed', 'large', ',', 'composed', 'various', 'data', 'types', ',', 'even', 'including', 'streaming', 'data', '[', '67', ']', '.']

>> Bigrams are: 
 [('Big', 'data'), ('data', 'analytics'), ('analytics', 'Nowadays'), ('Nowadays', ','), (',', 'data'), ('data', 'need'), ('need', 'analyzed'), ('analyzed', 'large'), ('large', ','), (',', 'composed'), ('composed', 'various'), ('various', 'data'), ('data', 'types'), ('types', ','), (',', 'even'), ('even', 'including'), ('including', 'streaming'), ('streaming', 'data'), ('data', '['), ('[', '67'), ('67', ']'), (']', '.')]

>> Trigrams are: 
 [('Big', 'data', 'analytics'), ('data', 'analytics', 'Nowadays'), ('analytics', 'Nowadays', ','), ('Nowadays', ',', 'data'), (',', 'data', 'need'), ('data', 'need', 'analyzed'), ('need', 'analyzed', 'large'), ('analyzed', 'large', ','), ('large', ',', 'composed'), (',', 'composed', 'various'), ('composed', 'various', 'data'), ('various', 'data', 'types'), ('data', 'types', ','), ('types', ',', 'even'), (',', 'even', 'including'), ('even', 'including', 'streaming'), ('including', 'streaming', 'data'), ('streaming', 'data', '['), ('data', '[', '67'), ('[', '67', ']'), ('67', ']', '.')]

>> POS Tags are: 
 [('Big', 'NNP'), ('data', 'NNS'), ('analytics', 'NNS'), ('Nowadays', 'NNP'), (',', ','), ('data', 'NNS'), ('need', 'VBP'), ('analyzed', 'VBN'), ('large', 'JJ'), (',', ','), ('composed', 'VBD'), ('various', 'JJ'), ('data', 'NNS'), ('types', 'NNS'), (',', ','), ('even', 'RB'), ('including', 'VBG'), ('streaming', 'VBG'), ('data', 'NNS'), ('[', 'RB'), ('67', 'CD'), (']', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['Big data analytics Nowadays', 'data', 'various data types', 'data', ']']

>> Named Entities are: 
 [('PERSON', 'Nowadays')] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('Nowadays', 'nowaday'), (',', ','), ('data', 'data'), ('need', 'need'), ('analyzed', 'analyz'), ('large', 'larg'), (',', ','), ('composed', 'compos'), ('various', 'variou'), ('data', 'data'), ('types', 'type'), (',', ','), ('even', 'even'), ('including', 'includ'), ('streaming', 'stream'), ('data', 'data'), ('[', '['), ('67', '67'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('Nowadays', 'nowaday'), (',', ','), ('data', 'data'), ('need', 'need'), ('analyzed', 'analyz'), ('large', 'larg'), (',', ','), ('composed', 'compos'), ('various', 'various'), ('data', 'data'), ('types', 'type'), (',', ','), ('even', 'even'), ('including', 'includ'), ('streaming', 'stream'), ('data', 'data'), ('[', '['), ('67', '67'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), ('analytics', 'analytics'), ('Nowadays', 'Nowadays'), (',', ','), ('data', 'data'), ('need', 'need'), ('analyzed', 'analyzed'), ('large', 'large'), (',', ','), ('composed', 'composed'), ('various', 'various'), ('data', 'data'), ('types', 'type'), (',', ','), ('even', 'even'), ('including', 'including'), ('streaming', 'streaming'), ('data', 'data'), ('[', '['), ('67', '67'), (']', ']'), ('.', '.')]


------------------- Sentence 2 -------------------

Since big data has the  unique features of “massive, high dimensional, heterogeneous, complex, unstructured,  incomplete, noisy, and erroneous,” which may change the statistical and data analy- sis approaches [68].

>> Tokens are: 
 ['Since', 'big', 'data', 'unique', 'features', '“', 'massive', ',', 'high', 'dimensional', ',', 'heterogeneous', ',', 'complex', ',', 'unstructured', ',', 'incomplete', ',', 'noisy', ',', 'erroneous', ',', '”', 'may', 'change', 'statistical', 'data', 'analy-', 'sis', 'approaches', '[', '68', ']', '.']

>> Bigrams are: 
 [('Since', 'big'), ('big', 'data'), ('data', 'unique'), ('unique', 'features'), ('features', '“'), ('“', 'massive'), ('massive', ','), (',', 'high'), ('high', 'dimensional'), ('dimensional', ','), (',', 'heterogeneous'), ('heterogeneous', ','), (',', 'complex'), ('complex', ','), (',', 'unstructured'), ('unstructured', ','), (',', 'incomplete'), ('incomplete', ','), (',', 'noisy'), ('noisy', ','), (',', 'erroneous'), ('erroneous', ','), (',', '”'), ('”', 'may'), ('may', 'change'), ('change', 'statistical'), ('statistical', 'data'), ('data', 'analy-'), ('analy-', 'sis'), ('sis', 'approaches'), ('approaches', '['), ('[', '68'), ('68', ']'), (']', '.')]

>> Trigrams are: 
 [('Since', 'big', 'data'), ('big', 'data', 'unique'), ('data', 'unique', 'features'), ('unique', 'features', '“'), ('features', '“', 'massive'), ('“', 'massive', ','), ('massive', ',', 'high'), (',', 'high', 'dimensional'), ('high', 'dimensional', ','), ('dimensional', ',', 'heterogeneous'), (',', 'heterogeneous', ','), ('heterogeneous', ',', 'complex'), (',', 'complex', ','), ('complex', ',', 'unstructured'), (',', 'unstructured', ','), ('unstructured', ',', 'incomplete'), (',', 'incomplete', ','), ('incomplete', ',', 'noisy'), (',', 'noisy', ','), ('noisy', ',', 'erroneous'), (',', 'erroneous', ','), ('erroneous', ',', '”'), (',', '”', 'may'), ('”', 'may', 'change'), ('may', 'change', 'statistical'), ('change', 'statistical', 'data'), ('statistical', 'data', 'analy-'), ('data', 'analy-', 'sis'), ('analy-', 'sis', 'approaches'), ('sis', 'approaches', '['), ('approaches', '[', '68'), ('[', '68', ']'), ('68', ']', '.')]

>> POS Tags are: 
 [('Since', 'IN'), ('big', 'JJ'), ('data', 'NNS'), ('unique', 'NN'), ('features', 'NNS'), ('“', 'VBP'), ('massive', 'JJ'), (',', ','), ('high', 'JJ'), ('dimensional', 'NN'), (',', ','), ('heterogeneous', 'JJ'), (',', ','), ('complex', 'JJ'), (',', ','), ('unstructured', 'JJ'), (',', ','), ('incomplete', 'JJ'), (',', ','), ('noisy', 'JJ'), (',', ','), ('erroneous', 'JJ'), (',', ','), ('”', 'JJ'), ('may', 'MD'), ('change', 'VB'), ('statistical', 'JJ'), ('data', 'NNS'), ('analy-', 'JJ'), ('sis', 'NN'), ('approaches', 'NNS'), ('[', 'VBP'), ('68', 'CD'), (']', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['big data unique features', 'high dimensional', 'statistical data', 'analy- sis approaches', ']']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Since', 'sinc'), ('big', 'big'), ('data', 'data'), ('unique', 'uniqu'), ('features', 'featur'), ('“', '“'), ('massive', 'massiv'), (',', ','), ('high', 'high'), ('dimensional', 'dimension'), (',', ','), ('heterogeneous', 'heterogen'), (',', ','), ('complex', 'complex'), (',', ','), ('unstructured', 'unstructur'), (',', ','), ('incomplete', 'incomplet'), (',', ','), ('noisy', 'noisi'), (',', ','), ('erroneous', 'erron'), (',', ','), ('”', '”'), ('may', 'may'), ('change', 'chang'), ('statistical', 'statist'), ('data', 'data'), ('analy-', 'analy-'), ('sis', 'si'), ('approaches', 'approach'), ('[', '['), ('68', '68'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Since', 'sinc'), ('big', 'big'), ('data', 'data'), ('unique', 'uniqu'), ('features', 'featur'), ('“', '“'), ('massive', 'massiv'), (',', ','), ('high', 'high'), ('dimensional', 'dimension'), (',', ','), ('heterogeneous', 'heterogen'), (',', ','), ('complex', 'complex'), (',', ','), ('unstructured', 'unstructur'), (',', ','), ('incomplete', 'incomplet'), (',', ','), ('noisy', 'noisi'), (',', ','), ('erroneous', 'erron'), (',', ','), ('”', '”'), ('may', 'may'), ('change', 'chang'), ('statistical', 'statist'), ('data', 'data'), ('analy-', 'analy-'), ('sis', 'sis'), ('approaches', 'approach'), ('[', '['), ('68', '68'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('Since', 'Since'), ('big', 'big'), ('data', 'data'), ('unique', 'unique'), ('features', 'feature'), ('“', '“'), ('massive', 'massive'), (',', ','), ('high', 'high'), ('dimensional', 'dimensional'), (',', ','), ('heterogeneous', 'heterogeneous'), (',', ','), ('complex', 'complex'), (',', ','), ('unstructured', 'unstructured'), (',', ','), ('incomplete', 'incomplete'), (',', ','), ('noisy', 'noisy'), (',', ','), ('erroneous', 'erroneous'), (',', ','), ('”', '”'), ('may', 'may'), ('change', 'change'), ('statistical', 'statistical'), ('data', 'data'), ('analy-', 'analy-'), ('sis', 'si'), ('approaches', 'approach'), ('[', '['), ('68', '68'), (']', ']'), ('.', '.')]


------------------- Sentence 3 -------------------

Although it seems that big data makes it possible for us to collect  more data to find more useful information, the truth is that more data do not necessar- ily mean more useful information.

>> Tokens are: 
 ['Although', 'seems', 'big', 'data', 'makes', 'possible', 'us', 'collect', 'data', 'find', 'useful', 'information', ',', 'truth', 'data', 'necessar-', 'ily', 'mean', 'useful', 'information', '.']

>> Bigrams are: 
 [('Although', 'seems'), ('seems', 'big'), ('big', 'data'), ('data', 'makes'), ('makes', 'possible'), ('possible', 'us'), ('us', 'collect'), ('collect', 'data'), ('data', 'find'), ('find', 'useful'), ('useful', 'information'), ('information', ','), (',', 'truth'), ('truth', 'data'), ('data', 'necessar-'), ('necessar-', 'ily'), ('ily', 'mean'), ('mean', 'useful'), ('useful', 'information'), ('information', '.')]

>> Trigrams are: 
 [('Although', 'seems', 'big'), ('seems', 'big', 'data'), ('big', 'data', 'makes'), ('data', 'makes', 'possible'), ('makes', 'possible', 'us'), ('possible', 'us', 'collect'), ('us', 'collect', 'data'), ('collect', 'data', 'find'), ('data', 'find', 'useful'), ('find', 'useful', 'information'), ('useful', 'information', ','), ('information', ',', 'truth'), (',', 'truth', 'data'), ('truth', 'data', 'necessar-'), ('data', 'necessar-', 'ily'), ('necessar-', 'ily', 'mean'), ('ily', 'mean', 'useful'), ('mean', 'useful', 'information'), ('useful', 'information', '.')]

>> POS Tags are: 
 [('Although', 'IN'), ('seems', 'VBZ'), ('big', 'JJ'), ('data', 'NNS'), ('makes', 'VBZ'), ('possible', 'JJ'), ('us', 'PRP'), ('collect', 'VBP'), ('data', 'NNS'), ('find', 'VBP'), ('useful', 'JJ'), ('information', 'NN'), (',', ','), ('truth', 'NN'), ('data', 'NNS'), ('necessar-', 'JJ'), ('ily', 'JJ'), ('mean', 'VB'), ('useful', 'JJ'), ('information', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['big data', 'data', 'useful information', 'truth data', 'useful information']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Although', 'although'), ('seems', 'seem'), ('big', 'big'), ('data', 'data'), ('makes', 'make'), ('possible', 'possibl'), ('us', 'us'), ('collect', 'collect'), ('data', 'data'), ('find', 'find'), ('useful', 'use'), ('information', 'inform'), (',', ','), ('truth', 'truth'), ('data', 'data'), ('necessar-', 'necessar-'), ('ily', 'ili'), ('mean', 'mean'), ('useful', 'use'), ('information', 'inform'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Although', 'although'), ('seems', 'seem'), ('big', 'big'), ('data', 'data'), ('makes', 'make'), ('possible', 'possibl'), ('us', 'us'), ('collect', 'collect'), ('data', 'data'), ('find', 'find'), ('useful', 'use'), ('information', 'inform'), (',', ','), ('truth', 'truth'), ('data', 'data'), ('necessar-', 'necessar-'), ('ily', 'ili'), ('mean', 'mean'), ('useful', 'use'), ('information', 'inform'), ('.', '.')]

>> Lemmatization: 
 [('Although', 'Although'), ('seems', 'seems'), ('big', 'big'), ('data', 'data'), ('makes', 'make'), ('possible', 'possible'), ('us', 'u'), ('collect', 'collect'), ('data', 'data'), ('find', 'find'), ('useful', 'useful'), ('information', 'information'), (',', ','), ('truth', 'truth'), ('data', 'data'), ('necessar-', 'necessar-'), ('ily', 'ily'), ('mean', 'mean'), ('useful', 'useful'), ('information', 'information'), ('.', '.')]


------------------- Sentence 4 -------------------

It may contain more ambiguous or abnormal data.

>> Tokens are: 
 ['It', 'may', 'contain', 'ambiguous', 'abnormal', 'data', '.']

>> Bigrams are: 
 [('It', 'may'), ('may', 'contain'), ('contain', 'ambiguous'), ('ambiguous', 'abnormal'), ('abnormal', 'data'), ('data', '.')]

>> Trigrams are: 
 [('It', 'may', 'contain'), ('may', 'contain', 'ambiguous'), ('contain', 'ambiguous', 'abnormal'), ('ambiguous', 'abnormal', 'data'), ('abnormal', 'data', '.')]

>> POS Tags are: 
 [('It', 'PRP'), ('may', 'MD'), ('contain', 'VB'), ('ambiguous', 'JJ'), ('abnormal', 'JJ'), ('data', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['ambiguous abnormal data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('It', 'it'), ('may', 'may'), ('contain', 'contain'), ('ambiguous', 'ambigu'), ('abnormal', 'abnorm'), ('data', 'data'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('It', 'it'), ('may', 'may'), ('contain', 'contain'), ('ambiguous', 'ambigu'), ('abnormal', 'abnorm'), ('data', 'data'), ('.', '.')]

>> Lemmatization: 
 [('It', 'It'), ('may', 'may'), ('contain', 'contain'), ('ambiguous', 'ambiguous'), ('abnormal', 'abnormal'), ('data', 'data'), ('.', '.')]


------------------- Sentence 5 -------------------

For instance, a user may have multiple accounts, or an account may be used by multiple  users, which may degrade the accuracy of the mining results [69].

>> Tokens are: 
 ['For', 'instance', ',', 'user', 'may', 'multiple', 'accounts', ',', 'account', 'may', 'used', 'multiple', 'users', ',', 'may', 'degrade', 'accuracy', 'mining', 'results', '[', '69', ']', '.']

>> Bigrams are: 
 [('For', 'instance'), ('instance', ','), (',', 'user'), ('user', 'may'), ('may', 'multiple'), ('multiple', 'accounts'), ('accounts', ','), (',', 'account'), ('account', 'may'), ('may', 'used'), ('used', 'multiple'), ('multiple', 'users'), ('users', ','), (',', 'may'), ('may', 'degrade'), ('degrade', 'accuracy'), ('accuracy', 'mining'), ('mining', 'results'), ('results', '['), ('[', '69'), ('69', ']'), (']', '.')]

>> Trigrams are: 
 [('For', 'instance', ','), ('instance', ',', 'user'), (',', 'user', 'may'), ('user', 'may', 'multiple'), ('may', 'multiple', 'accounts'), ('multiple', 'accounts', ','), ('accounts', ',', 'account'), (',', 'account', 'may'), ('account', 'may', 'used'), ('may', 'used', 'multiple'), ('used', 'multiple', 'users'), ('multiple', 'users', ','), ('users', ',', 'may'), (',', 'may', 'degrade'), ('may', 'degrade', 'accuracy'), ('degrade', 'accuracy', 'mining'), ('accuracy', 'mining', 'results'), ('mining', 'results', '['), ('results', '[', '69'), ('[', '69', ']'), ('69', ']', '.')]

>> POS Tags are: 
 [('For', 'IN'), ('instance', 'NN'), (',', ','), ('user', 'NN'), ('may', 'MD'), ('multiple', 'VB'), ('accounts', 'NNS'), (',', ','), ('account', 'NN'), ('may', 'MD'), ('used', 'VBN'), ('multiple', 'NN'), ('users', 'NNS'), (',', ','), ('may', 'MD'), ('degrade', 'VB'), ('accuracy', 'NN'), ('mining', 'NN'), ('results', 'NNS'), ('[', 'VBD'), ('69', 'CD'), (']', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['instance', 'user', 'accounts', 'account', 'multiple users', 'accuracy mining results', ']']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('For', 'for'), ('instance', 'instanc'), (',', ','), ('user', 'user'), ('may', 'may'), ('multiple', 'multipl'), ('accounts', 'account'), (',', ','), ('account', 'account'), ('may', 'may'), ('used', 'use'), ('multiple', 'multipl'), ('users', 'user'), (',', ','), ('may', 'may'), ('degrade', 'degrad'), ('accuracy', 'accuraci'), ('mining', 'mine'), ('results', 'result'), ('[', '['), ('69', '69'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('For', 'for'), ('instance', 'instanc'), (',', ','), ('user', 'user'), ('may', 'may'), ('multiple', 'multipl'), ('accounts', 'account'), (',', ','), ('account', 'account'), ('may', 'may'), ('used', 'use'), ('multiple', 'multipl'), ('users', 'user'), (',', ','), ('may', 'may'), ('degrade', 'degrad'), ('accuracy', 'accuraci'), ('mining', 'mine'), ('results', 'result'), ('[', '['), ('69', '69'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('For', 'For'), ('instance', 'instance'), (',', ','), ('user', 'user'), ('may', 'may'), ('multiple', 'multiple'), ('accounts', 'account'), (',', ','), ('account', 'account'), ('may', 'may'), ('used', 'used'), ('multiple', 'multiple'), ('users', 'user'), (',', ','), ('may', 'may'), ('degrade', 'degrade'), ('accuracy', 'accuracy'), ('mining', 'mining'), ('results', 'result'), ('[', '['), ('69', '69'), (']', ']'), ('.', '.')]


------------------- Sentence 6 -------------------

Therefore, several new  issues for data analytics come up, such as privacy, security, storage, fault tolerance, and  quality of data [70].

>> Tokens are: 
 ['Therefore', ',', 'several', 'new', 'issues', 'data', 'analytics', 'come', ',', 'privacy', ',', 'security', ',', 'storage', ',', 'fault', 'tolerance', ',', 'quality', 'data', '[', '70', ']', '.']

>> Bigrams are: 
 [('Therefore', ','), (',', 'several'), ('several', 'new'), ('new', 'issues'), ('issues', 'data'), ('data', 'analytics'), ('analytics', 'come'), ('come', ','), (',', 'privacy'), ('privacy', ','), (',', 'security'), ('security', ','), (',', 'storage'), ('storage', ','), (',', 'fault'), ('fault', 'tolerance'), ('tolerance', ','), (',', 'quality'), ('quality', 'data'), ('data', '['), ('[', '70'), ('70', ']'), (']', '.')]

>> Trigrams are: 
 [('Therefore', ',', 'several'), (',', 'several', 'new'), ('several', 'new', 'issues'), ('new', 'issues', 'data'), ('issues', 'data', 'analytics'), ('data', 'analytics', 'come'), ('analytics', 'come', ','), ('come', ',', 'privacy'), (',', 'privacy', ','), ('privacy', ',', 'security'), (',', 'security', ','), ('security', ',', 'storage'), (',', 'storage', ','), ('storage', ',', 'fault'), (',', 'fault', 'tolerance'), ('fault', 'tolerance', ','), ('tolerance', ',', 'quality'), (',', 'quality', 'data'), ('quality', 'data', '['), ('data', '[', '70'), ('[', '70', ']'), ('70', ']', '.')]

>> POS Tags are: 
 [('Therefore', 'RB'), (',', ','), ('several', 'JJ'), ('new', 'JJ'), ('issues', 'NNS'), ('data', 'NNS'), ('analytics', 'NNS'), ('come', 'VBP'), (',', ','), ('privacy', 'NN'), (',', ','), ('security', 'NN'), (',', ','), ('storage', 'NN'), (',', ','), ('fault', 'NN'), ('tolerance', 'NN'), (',', ','), ('quality', 'NN'), ('data', 'NNS'), ('[', 'VBP'), ('70', 'CD'), (']', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['several new issues data analytics', 'privacy', 'security', 'storage', 'fault tolerance', 'quality data', ']']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Therefore', 'therefor'), (',', ','), ('several', 'sever'), ('new', 'new'), ('issues', 'issu'), ('data', 'data'), ('analytics', 'analyt'), ('come', 'come'), (',', ','), ('privacy', 'privaci'), (',', ','), ('security', 'secur'), (',', ','), ('storage', 'storag'), (',', ','), ('fault', 'fault'), ('tolerance', 'toler'), (',', ','), ('quality', 'qualiti'), ('data', 'data'), ('[', '['), ('70', '70'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Therefore', 'therefor'), (',', ','), ('several', 'sever'), ('new', 'new'), ('issues', 'issu'), ('data', 'data'), ('analytics', 'analyt'), ('come', 'come'), (',', ','), ('privacy', 'privaci'), (',', ','), ('security', 'secur'), (',', ','), ('storage', 'storag'), (',', ','), ('fault', 'fault'), ('tolerance', 'toler'), (',', ','), ('quality', 'qualiti'), ('data', 'data'), ('[', '['), ('70', '70'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('Therefore', 'Therefore'), (',', ','), ('several', 'several'), ('new', 'new'), ('issues', 'issue'), ('data', 'data'), ('analytics', 'analytics'), ('come', 'come'), (',', ','), ('privacy', 'privacy'), (',', ','), ('security', 'security'), (',', ','), ('storage', 'storage'), (',', ','), ('fault', 'fault'), ('tolerance', 'tolerance'), (',', ','), ('quality', 'quality'), ('data', 'data'), ('[', '['), ('70', '70'), (']', ']'), ('.', '.')]



========================================== PARAGRAPH 172 ===========================================

The big data may be created by handheld device, social network, internet of things,  multimedia, and many other new applications that all have the characteristics of volume,  velocity, and variety. As a result, the whole data analytics has to be re-examined from the  following perspectives: 

------------------- Sentence 1 -------------------

The big data may be created by handheld device, social network, internet of things,  multimedia, and many other new applications that all have the characteristics of volume,  velocity, and variety.

>> Tokens are: 
 ['The', 'big', 'data', 'may', 'created', 'handheld', 'device', ',', 'social', 'network', ',', 'internet', 'things', ',', 'multimedia', ',', 'many', 'new', 'applications', 'characteristics', 'volume', ',', 'velocity', ',', 'variety', '.']

>> Bigrams are: 
 [('The', 'big'), ('big', 'data'), ('data', 'may'), ('may', 'created'), ('created', 'handheld'), ('handheld', 'device'), ('device', ','), (',', 'social'), ('social', 'network'), ('network', ','), (',', 'internet'), ('internet', 'things'), ('things', ','), (',', 'multimedia'), ('multimedia', ','), (',', 'many'), ('many', 'new'), ('new', 'applications'), ('applications', 'characteristics'), ('characteristics', 'volume'), ('volume', ','), (',', 'velocity'), ('velocity', ','), (',', 'variety'), ('variety', '.')]

>> Trigrams are: 
 [('The', 'big', 'data'), ('big', 'data', 'may'), ('data', 'may', 'created'), ('may', 'created', 'handheld'), ('created', 'handheld', 'device'), ('handheld', 'device', ','), ('device', ',', 'social'), (',', 'social', 'network'), ('social', 'network', ','), ('network', ',', 'internet'), (',', 'internet', 'things'), ('internet', 'things', ','), ('things', ',', 'multimedia'), (',', 'multimedia', ','), ('multimedia', ',', 'many'), (',', 'many', 'new'), ('many', 'new', 'applications'), ('new', 'applications', 'characteristics'), ('applications', 'characteristics', 'volume'), ('characteristics', 'volume', ','), ('volume', ',', 'velocity'), (',', 'velocity', ','), ('velocity', ',', 'variety'), (',', 'variety', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('big', 'JJ'), ('data', 'NNS'), ('may', 'MD'), ('created', 'VB'), ('handheld', 'NN'), ('device', 'NN'), (',', ','), ('social', 'JJ'), ('network', 'NN'), (',', ','), ('internet', 'NN'), ('things', 'NNS'), (',', ','), ('multimedia', 'NN'), (',', ','), ('many', 'JJ'), ('new', 'JJ'), ('applications', 'NNS'), ('characteristics', 'NNS'), ('volume', 'NN'), (',', ','), ('velocity', 'NN'), (',', ','), ('variety', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['The big data', 'handheld device', 'social network', 'internet things', 'multimedia', 'many new applications characteristics volume', 'velocity', 'variety']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('big', 'big'), ('data', 'data'), ('may', 'may'), ('created', 'creat'), ('handheld', 'handheld'), ('device', 'devic'), (',', ','), ('social', 'social'), ('network', 'network'), (',', ','), ('internet', 'internet'), ('things', 'thing'), (',', ','), ('multimedia', 'multimedia'), (',', ','), ('many', 'mani'), ('new', 'new'), ('applications', 'applic'), ('characteristics', 'characterist'), ('volume', 'volum'), (',', ','), ('velocity', 'veloc'), (',', ','), ('variety', 'varieti'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('big', 'big'), ('data', 'data'), ('may', 'may'), ('created', 'creat'), ('handheld', 'handheld'), ('device', 'devic'), (',', ','), ('social', 'social'), ('network', 'network'), (',', ','), ('internet', 'internet'), ('things', 'thing'), (',', ','), ('multimedia', 'multimedia'), (',', ','), ('many', 'mani'), ('new', 'new'), ('applications', 'applic'), ('characteristics', 'characterist'), ('volume', 'volum'), (',', ','), ('velocity', 'veloc'), (',', ','), ('variety', 'varieti'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('big', 'big'), ('data', 'data'), ('may', 'may'), ('created', 'created'), ('handheld', 'handheld'), ('device', 'device'), (',', ','), ('social', 'social'), ('network', 'network'), (',', ','), ('internet', 'internet'), ('things', 'thing'), (',', ','), ('multimedia', 'multimedia'), (',', ','), ('many', 'many'), ('new', 'new'), ('applications', 'application'), ('characteristics', 'characteristic'), ('volume', 'volume'), (',', ','), ('velocity', 'velocity'), (',', ','), ('variety', 'variety'), ('.', '.')]


------------------- Sentence 2 -------------------

As a result, the whole data analytics has to be re-examined from the  following perspectives:

>> Tokens are: 
 ['As', 'result', ',', 'whole', 'data', 'analytics', 're-examined', 'following', 'perspectives', ':']

>> Bigrams are: 
 [('As', 'result'), ('result', ','), (',', 'whole'), ('whole', 'data'), ('data', 'analytics'), ('analytics', 're-examined'), ('re-examined', 'following'), ('following', 'perspectives'), ('perspectives', ':')]

>> Trigrams are: 
 [('As', 'result', ','), ('result', ',', 'whole'), (',', 'whole', 'data'), ('whole', 'data', 'analytics'), ('data', 'analytics', 're-examined'), ('analytics', 're-examined', 'following'), ('re-examined', 'following', 'perspectives'), ('following', 'perspectives', ':')]

>> POS Tags are: 
 [('As', 'IN'), ('result', 'NN'), (',', ','), ('whole', 'JJ'), ('data', 'NN'), ('analytics', 'NNS'), ('re-examined', 'JJ'), ('following', 'VBG'), ('perspectives', 'NNS'), (':', ':')]

>> Noun Phrases are: 
 ['result', 'whole data analytics', 'perspectives']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('As', 'as'), ('result', 'result'), (',', ','), ('whole', 'whole'), ('data', 'data'), ('analytics', 'analyt'), ('re-examined', 're-examin'), ('following', 'follow'), ('perspectives', 'perspect'), (':', ':')]

>> Stemming using Snowball Stemmer: 
 [('As', 'as'), ('result', 'result'), (',', ','), ('whole', 'whole'), ('data', 'data'), ('analytics', 'analyt'), ('re-examined', 're-examin'), ('following', 'follow'), ('perspectives', 'perspect'), (':', ':')]

>> Lemmatization: 
 [('As', 'As'), ('result', 'result'), (',', ','), ('whole', 'whole'), ('data', 'data'), ('analytics', 'analytics'), ('re-examined', 're-examined'), ('following', 'following'), ('perspectives', 'perspective'), (':', ':')]



========================================== PARAGRAPH 173 ===========================================

  – From the volume perspective, the deluge of input data is the very first thing that we  need to face because it may paralyze the data analytics. Different from traditional data  analytics, for the wireless sensor network data analysis, Baraniuk [71] pointed out that  the bottleneck of big data analytics will be shifted from sensor to processing, com- munications, storage of sensing data, as shown in Fig. 6. This is because sensors can  gather much more data, but when uploading such large data to upper layer system, it  may create bottlenecks everywhere. 

------------------- Sentence 1 -------------------

  – From the volume perspective, the deluge of input data is the very first thing that we  need to face because it may paralyze the data analytics.

>> Tokens are: 
 ['–', 'From', 'volume', 'perspective', ',', 'deluge', 'input', 'data', 'first', 'thing', 'need', 'face', 'may', 'paralyze', 'data', 'analytics', '.']

>> Bigrams are: 
 [('–', 'From'), ('From', 'volume'), ('volume', 'perspective'), ('perspective', ','), (',', 'deluge'), ('deluge', 'input'), ('input', 'data'), ('data', 'first'), ('first', 'thing'), ('thing', 'need'), ('need', 'face'), ('face', 'may'), ('may', 'paralyze'), ('paralyze', 'data'), ('data', 'analytics'), ('analytics', '.')]

>> Trigrams are: 
 [('–', 'From', 'volume'), ('From', 'volume', 'perspective'), ('volume', 'perspective', ','), ('perspective', ',', 'deluge'), (',', 'deluge', 'input'), ('deluge', 'input', 'data'), ('input', 'data', 'first'), ('data', 'first', 'thing'), ('first', 'thing', 'need'), ('thing', 'need', 'face'), ('need', 'face', 'may'), ('face', 'may', 'paralyze'), ('may', 'paralyze', 'data'), ('paralyze', 'data', 'analytics'), ('data', 'analytics', '.')]

>> POS Tags are: 
 [('–', 'NN'), ('From', 'IN'), ('volume', 'NN'), ('perspective', 'NN'), (',', ','), ('deluge', 'NN'), ('input', 'NN'), ('data', 'NNS'), ('first', 'JJ'), ('thing', 'NN'), ('need', 'NN'), ('face', 'NN'), ('may', 'MD'), ('paralyze', 'VB'), ('data', 'NNS'), ('analytics', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['–', 'volume perspective', 'deluge input data', 'first thing need face', 'data analytics']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('–', '–'), ('From', 'from'), ('volume', 'volum'), ('perspective', 'perspect'), (',', ','), ('deluge', 'delug'), ('input', 'input'), ('data', 'data'), ('first', 'first'), ('thing', 'thing'), ('need', 'need'), ('face', 'face'), ('may', 'may'), ('paralyze', 'paralyz'), ('data', 'data'), ('analytics', 'analyt'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('–', '–'), ('From', 'from'), ('volume', 'volum'), ('perspective', 'perspect'), (',', ','), ('deluge', 'delug'), ('input', 'input'), ('data', 'data'), ('first', 'first'), ('thing', 'thing'), ('need', 'need'), ('face', 'face'), ('may', 'may'), ('paralyze', 'paralyz'), ('data', 'data'), ('analytics', 'analyt'), ('.', '.')]

>> Lemmatization: 
 [('–', '–'), ('From', 'From'), ('volume', 'volume'), ('perspective', 'perspective'), (',', ','), ('deluge', 'deluge'), ('input', 'input'), ('data', 'data'), ('first', 'first'), ('thing', 'thing'), ('need', 'need'), ('face', 'face'), ('may', 'may'), ('paralyze', 'paralyze'), ('data', 'data'), ('analytics', 'analytics'), ('.', '.')]


------------------- Sentence 2 -------------------

Different from traditional data  analytics, for the wireless sensor network data analysis, Baraniuk [71] pointed out that  the bottleneck of big data analytics will be shifted from sensor to processing, com- munications, storage of sensing data, as shown in Fig.

>> Tokens are: 
 ['Different', 'traditional', 'data', 'analytics', ',', 'wireless', 'sensor', 'network', 'data', 'analysis', ',', 'Baraniuk', '[', '71', ']', 'pointed', 'bottleneck', 'big', 'data', 'analytics', 'shifted', 'sensor', 'processing', ',', 'com-', 'munications', ',', 'storage', 'sensing', 'data', ',', 'shown', 'Fig', '.']

>> Bigrams are: 
 [('Different', 'traditional'), ('traditional', 'data'), ('data', 'analytics'), ('analytics', ','), (',', 'wireless'), ('wireless', 'sensor'), ('sensor', 'network'), ('network', 'data'), ('data', 'analysis'), ('analysis', ','), (',', 'Baraniuk'), ('Baraniuk', '['), ('[', '71'), ('71', ']'), (']', 'pointed'), ('pointed', 'bottleneck'), ('bottleneck', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', 'shifted'), ('shifted', 'sensor'), ('sensor', 'processing'), ('processing', ','), (',', 'com-'), ('com-', 'munications'), ('munications', ','), (',', 'storage'), ('storage', 'sensing'), ('sensing', 'data'), ('data', ','), (',', 'shown'), ('shown', 'Fig'), ('Fig', '.')]

>> Trigrams are: 
 [('Different', 'traditional', 'data'), ('traditional', 'data', 'analytics'), ('data', 'analytics', ','), ('analytics', ',', 'wireless'), (',', 'wireless', 'sensor'), ('wireless', 'sensor', 'network'), ('sensor', 'network', 'data'), ('network', 'data', 'analysis'), ('data', 'analysis', ','), ('analysis', ',', 'Baraniuk'), (',', 'Baraniuk', '['), ('Baraniuk', '[', '71'), ('[', '71', ']'), ('71', ']', 'pointed'), (']', 'pointed', 'bottleneck'), ('pointed', 'bottleneck', 'big'), ('bottleneck', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', 'shifted'), ('analytics', 'shifted', 'sensor'), ('shifted', 'sensor', 'processing'), ('sensor', 'processing', ','), ('processing', ',', 'com-'), (',', 'com-', 'munications'), ('com-', 'munications', ','), ('munications', ',', 'storage'), (',', 'storage', 'sensing'), ('storage', 'sensing', 'data'), ('sensing', 'data', ','), ('data', ',', 'shown'), (',', 'shown', 'Fig'), ('shown', 'Fig', '.')]

>> POS Tags are: 
 [('Different', 'JJ'), ('traditional', 'JJ'), ('data', 'NN'), ('analytics', 'NNS'), (',', ','), ('wireless', 'NN'), ('sensor', 'NN'), ('network', 'NN'), ('data', 'NNS'), ('analysis', 'NN'), (',', ','), ('Baraniuk', 'NNP'), ('[', 'VBZ'), ('71', 'CD'), (']', 'NN'), ('pointed', 'VBD'), ('bottleneck', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('shifted', 'VBD'), ('sensor', 'NN'), ('processing', 'NN'), (',', ','), ('com-', 'JJ'), ('munications', 'NNS'), (',', ','), ('storage', 'NN'), ('sensing', 'VBG'), ('data', 'NNS'), (',', ','), ('shown', 'VBN'), ('Fig', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Different traditional data analytics', 'wireless sensor network data analysis', 'Baraniuk', ']', 'bottleneck', 'big data analytics', 'sensor processing', 'com- munications', 'storage', 'data', 'Fig']

>> Named Entities are: 
 [('PERSON', 'Baraniuk'), ('PERSON', 'Fig')] 

>> Stemming using Porter Stemmer: 
 [('Different', 'differ'), ('traditional', 'tradit'), ('data', 'data'), ('analytics', 'analyt'), (',', ','), ('wireless', 'wireless'), ('sensor', 'sensor'), ('network', 'network'), ('data', 'data'), ('analysis', 'analysi'), (',', ','), ('Baraniuk', 'baraniuk'), ('[', '['), ('71', '71'), (']', ']'), ('pointed', 'point'), ('bottleneck', 'bottleneck'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('shifted', 'shift'), ('sensor', 'sensor'), ('processing', 'process'), (',', ','), ('com-', 'com-'), ('munications', 'munic'), (',', ','), ('storage', 'storag'), ('sensing', 'sens'), ('data', 'data'), (',', ','), ('shown', 'shown'), ('Fig', 'fig'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Different', 'differ'), ('traditional', 'tradit'), ('data', 'data'), ('analytics', 'analyt'), (',', ','), ('wireless', 'wireless'), ('sensor', 'sensor'), ('network', 'network'), ('data', 'data'), ('analysis', 'analysi'), (',', ','), ('Baraniuk', 'baraniuk'), ('[', '['), ('71', '71'), (']', ']'), ('pointed', 'point'), ('bottleneck', 'bottleneck'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('shifted', 'shift'), ('sensor', 'sensor'), ('processing', 'process'), (',', ','), ('com-', 'com-'), ('munications', 'munic'), (',', ','), ('storage', 'storag'), ('sensing', 'sens'), ('data', 'data'), (',', ','), ('shown', 'shown'), ('Fig', 'fig'), ('.', '.')]

>> Lemmatization: 
 [('Different', 'Different'), ('traditional', 'traditional'), ('data', 'data'), ('analytics', 'analytics'), (',', ','), ('wireless', 'wireless'), ('sensor', 'sensor'), ('network', 'network'), ('data', 'data'), ('analysis', 'analysis'), (',', ','), ('Baraniuk', 'Baraniuk'), ('[', '['), ('71', '71'), (']', ']'), ('pointed', 'pointed'), ('bottleneck', 'bottleneck'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('shifted', 'shifted'), ('sensor', 'sensor'), ('processing', 'processing'), (',', ','), ('com-', 'com-'), ('munications', 'munications'), (',', ','), ('storage', 'storage'), ('sensing', 'sensing'), ('data', 'data'), (',', ','), ('shown', 'shown'), ('Fig', 'Fig'), ('.', '.')]


------------------- Sentence 3 -------------------

6.

>> Tokens are: 
 ['6', '.']

>> Bigrams are: 
 [('6', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('6', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('6', '6'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('6', '6'), ('.', '.')]

>> Lemmatization: 
 [('6', '6'), ('.', '.')]


------------------- Sentence 4 -------------------

This is because sensors can  gather much more data, but when uploading such large data to upper layer system, it  may create bottlenecks everywhere.

>> Tokens are: 
 ['This', 'sensors', 'gather', 'much', 'data', ',', 'uploading', 'large', 'data', 'upper', 'layer', 'system', ',', 'may', 'create', 'bottlenecks', 'everywhere', '.']

>> Bigrams are: 
 [('This', 'sensors'), ('sensors', 'gather'), ('gather', 'much'), ('much', 'data'), ('data', ','), (',', 'uploading'), ('uploading', 'large'), ('large', 'data'), ('data', 'upper'), ('upper', 'layer'), ('layer', 'system'), ('system', ','), (',', 'may'), ('may', 'create'), ('create', 'bottlenecks'), ('bottlenecks', 'everywhere'), ('everywhere', '.')]

>> Trigrams are: 
 [('This', 'sensors', 'gather'), ('sensors', 'gather', 'much'), ('gather', 'much', 'data'), ('much', 'data', ','), ('data', ',', 'uploading'), (',', 'uploading', 'large'), ('uploading', 'large', 'data'), ('large', 'data', 'upper'), ('data', 'upper', 'layer'), ('upper', 'layer', 'system'), ('layer', 'system', ','), ('system', ',', 'may'), (',', 'may', 'create'), ('may', 'create', 'bottlenecks'), ('create', 'bottlenecks', 'everywhere'), ('bottlenecks', 'everywhere', '.')]

>> POS Tags are: 
 [('This', 'DT'), ('sensors', 'VBZ'), ('gather', 'RB'), ('much', 'JJ'), ('data', 'NNS'), (',', ','), ('uploading', 'VBG'), ('large', 'JJ'), ('data', 'NNS'), ('upper', 'IN'), ('layer', 'NN'), ('system', 'NN'), (',', ','), ('may', 'MD'), ('create', 'VB'), ('bottlenecks', 'NNS'), ('everywhere', 'RB'), ('.', '.')]

>> Noun Phrases are: 
 ['much data', 'large data', 'layer system', 'bottlenecks']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('This', 'thi'), ('sensors', 'sensor'), ('gather', 'gather'), ('much', 'much'), ('data', 'data'), (',', ','), ('uploading', 'upload'), ('large', 'larg'), ('data', 'data'), ('upper', 'upper'), ('layer', 'layer'), ('system', 'system'), (',', ','), ('may', 'may'), ('create', 'creat'), ('bottlenecks', 'bottleneck'), ('everywhere', 'everywher'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('This', 'this'), ('sensors', 'sensor'), ('gather', 'gather'), ('much', 'much'), ('data', 'data'), (',', ','), ('uploading', 'upload'), ('large', 'larg'), ('data', 'data'), ('upper', 'upper'), ('layer', 'layer'), ('system', 'system'), (',', ','), ('may', 'may'), ('create', 'creat'), ('bottlenecks', 'bottleneck'), ('everywhere', 'everywher'), ('.', '.')]

>> Lemmatization: 
 [('This', 'This'), ('sensors', 'sensor'), ('gather', 'gather'), ('much', 'much'), ('data', 'data'), (',', ','), ('uploading', 'uploading'), ('large', 'large'), ('data', 'data'), ('upper', 'upper'), ('layer', 'layer'), ('system', 'system'), (',', ','), ('may', 'may'), ('create', 'create'), ('bottlenecks', 'bottleneck'), ('everywhere', 'everywhere'), ('.', '.')]



========================================== PARAGRAPH 174 ===========================================

 – In addition, from the velocity perspective, real-time or streaming data bring up the  problem of large quantity of data coming into the data analytics within a short dura- tion but the device and system may not be able to handle these input data. This situa- tion is similar to that of the network flow analysis for which we typically cannot mirror  and analyze everything we can gather. 

------------------- Sentence 1 -------------------

 – In addition, from the velocity perspective, real-time or streaming data bring up the  problem of large quantity of data coming into the data analytics within a short dura- tion but the device and system may not be able to handle these input data.

>> Tokens are: 
 ['–', 'In', 'addition', ',', 'velocity', 'perspective', ',', 'real-time', 'streaming', 'data', 'bring', 'problem', 'large', 'quantity', 'data', 'coming', 'data', 'analytics', 'within', 'short', 'dura-', 'tion', 'device', 'system', 'may', 'able', 'handle', 'input', 'data', '.']

>> Bigrams are: 
 [('–', 'In'), ('In', 'addition'), ('addition', ','), (',', 'velocity'), ('velocity', 'perspective'), ('perspective', ','), (',', 'real-time'), ('real-time', 'streaming'), ('streaming', 'data'), ('data', 'bring'), ('bring', 'problem'), ('problem', 'large'), ('large', 'quantity'), ('quantity', 'data'), ('data', 'coming'), ('coming', 'data'), ('data', 'analytics'), ('analytics', 'within'), ('within', 'short'), ('short', 'dura-'), ('dura-', 'tion'), ('tion', 'device'), ('device', 'system'), ('system', 'may'), ('may', 'able'), ('able', 'handle'), ('handle', 'input'), ('input', 'data'), ('data', '.')]

>> Trigrams are: 
 [('–', 'In', 'addition'), ('In', 'addition', ','), ('addition', ',', 'velocity'), (',', 'velocity', 'perspective'), ('velocity', 'perspective', ','), ('perspective', ',', 'real-time'), (',', 'real-time', 'streaming'), ('real-time', 'streaming', 'data'), ('streaming', 'data', 'bring'), ('data', 'bring', 'problem'), ('bring', 'problem', 'large'), ('problem', 'large', 'quantity'), ('large', 'quantity', 'data'), ('quantity', 'data', 'coming'), ('data', 'coming', 'data'), ('coming', 'data', 'analytics'), ('data', 'analytics', 'within'), ('analytics', 'within', 'short'), ('within', 'short', 'dura-'), ('short', 'dura-', 'tion'), ('dura-', 'tion', 'device'), ('tion', 'device', 'system'), ('device', 'system', 'may'), ('system', 'may', 'able'), ('may', 'able', 'handle'), ('able', 'handle', 'input'), ('handle', 'input', 'data'), ('input', 'data', '.')]

>> POS Tags are: 
 [('–', 'NN'), ('In', 'IN'), ('addition', 'NN'), (',', ','), ('velocity', 'NN'), ('perspective', 'NN'), (',', ','), ('real-time', 'JJ'), ('streaming', 'VBG'), ('data', 'NNS'), ('bring', 'NN'), ('problem', 'NN'), ('large', 'JJ'), ('quantity', 'NN'), ('data', 'NNS'), ('coming', 'VBG'), ('data', 'NNS'), ('analytics', 'NNS'), ('within', 'IN'), ('short', 'JJ'), ('dura-', 'JJ'), ('tion', 'NN'), ('device', 'NN'), ('system', 'NN'), ('may', 'MD'), ('able', 'JJ'), ('handle', 'VB'), ('input', 'NN'), ('data', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['–', 'addition', 'velocity perspective', 'data bring problem', 'large quantity data', 'data analytics', 'short dura- tion device system', 'input data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('–', '–'), ('In', 'in'), ('addition', 'addit'), (',', ','), ('velocity', 'veloc'), ('perspective', 'perspect'), (',', ','), ('real-time', 'real-tim'), ('streaming', 'stream'), ('data', 'data'), ('bring', 'bring'), ('problem', 'problem'), ('large', 'larg'), ('quantity', 'quantiti'), ('data', 'data'), ('coming', 'come'), ('data', 'data'), ('analytics', 'analyt'), ('within', 'within'), ('short', 'short'), ('dura-', 'dura-'), ('tion', 'tion'), ('device', 'devic'), ('system', 'system'), ('may', 'may'), ('able', 'abl'), ('handle', 'handl'), ('input', 'input'), ('data', 'data'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('–', '–'), ('In', 'in'), ('addition', 'addit'), (',', ','), ('velocity', 'veloc'), ('perspective', 'perspect'), (',', ','), ('real-time', 'real-tim'), ('streaming', 'stream'), ('data', 'data'), ('bring', 'bring'), ('problem', 'problem'), ('large', 'larg'), ('quantity', 'quantiti'), ('data', 'data'), ('coming', 'come'), ('data', 'data'), ('analytics', 'analyt'), ('within', 'within'), ('short', 'short'), ('dura-', 'dura-'), ('tion', 'tion'), ('device', 'devic'), ('system', 'system'), ('may', 'may'), ('able', 'abl'), ('handle', 'handl'), ('input', 'input'), ('data', 'data'), ('.', '.')]

>> Lemmatization: 
 [('–', '–'), ('In', 'In'), ('addition', 'addition'), (',', ','), ('velocity', 'velocity'), ('perspective', 'perspective'), (',', ','), ('real-time', 'real-time'), ('streaming', 'streaming'), ('data', 'data'), ('bring', 'bring'), ('problem', 'problem'), ('large', 'large'), ('quantity', 'quantity'), ('data', 'data'), ('coming', 'coming'), ('data', 'data'), ('analytics', 'analytics'), ('within', 'within'), ('short', 'short'), ('dura-', 'dura-'), ('tion', 'tion'), ('device', 'device'), ('system', 'system'), ('may', 'may'), ('able', 'able'), ('handle', 'handle'), ('input', 'input'), ('data', 'data'), ('.', '.')]


------------------- Sentence 2 -------------------

This situa- tion is similar to that of the network flow analysis for which we typically cannot mirror  and analyze everything we can gather.

>> Tokens are: 
 ['This', 'situa-', 'tion', 'similar', 'network', 'flow', 'analysis', 'typically', 'mirror', 'analyze', 'everything', 'gather', '.']

>> Bigrams are: 
 [('This', 'situa-'), ('situa-', 'tion'), ('tion', 'similar'), ('similar', 'network'), ('network', 'flow'), ('flow', 'analysis'), ('analysis', 'typically'), ('typically', 'mirror'), ('mirror', 'analyze'), ('analyze', 'everything'), ('everything', 'gather'), ('gather', '.')]

>> Trigrams are: 
 [('This', 'situa-', 'tion'), ('situa-', 'tion', 'similar'), ('tion', 'similar', 'network'), ('similar', 'network', 'flow'), ('network', 'flow', 'analysis'), ('flow', 'analysis', 'typically'), ('analysis', 'typically', 'mirror'), ('typically', 'mirror', 'analyze'), ('mirror', 'analyze', 'everything'), ('analyze', 'everything', 'gather'), ('everything', 'gather', '.')]

>> POS Tags are: 
 [('This', 'DT'), ('situa-', 'JJ'), ('tion', 'NN'), ('similar', 'JJ'), ('network', 'NN'), ('flow', 'NN'), ('analysis', 'NN'), ('typically', 'RB'), ('mirror', 'JJ'), ('analyze', 'IN'), ('everything', 'NN'), ('gather', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['This situa- tion', 'similar network flow analysis', 'everything gather']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('This', 'thi'), ('situa-', 'situa-'), ('tion', 'tion'), ('similar', 'similar'), ('network', 'network'), ('flow', 'flow'), ('analysis', 'analysi'), ('typically', 'typic'), ('mirror', 'mirror'), ('analyze', 'analyz'), ('everything', 'everyth'), ('gather', 'gather'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('This', 'this'), ('situa-', 'situa-'), ('tion', 'tion'), ('similar', 'similar'), ('network', 'network'), ('flow', 'flow'), ('analysis', 'analysi'), ('typically', 'typic'), ('mirror', 'mirror'), ('analyze', 'analyz'), ('everything', 'everyth'), ('gather', 'gather'), ('.', '.')]

>> Lemmatization: 
 [('This', 'This'), ('situa-', 'situa-'), ('tion', 'tion'), ('similar', 'similar'), ('network', 'network'), ('flow', 'flow'), ('analysis', 'analysis'), ('typically', 'typically'), ('mirror', 'mirror'), ('analyze', 'analyze'), ('everything', 'everything'), ('gather', 'gather'), ('.', '.')]



========================================== PARAGRAPH 175 ===========================================

 – From the variety perspective, because the incoming data may use different types or  have incomplete data, how to handle them also bring up another issue for the input  operators of data analytics. 

------------------- Sentence 1 -------------------

 – From the variety perspective, because the incoming data may use different types or  have incomplete data, how to handle them also bring up another issue for the input  operators of data analytics.

>> Tokens are: 
 ['–', 'From', 'variety', 'perspective', ',', 'incoming', 'data', 'may', 'use', 'different', 'types', 'incomplete', 'data', ',', 'handle', 'also', 'bring', 'another', 'issue', 'input', 'operators', 'data', 'analytics', '.']

>> Bigrams are: 
 [('–', 'From'), ('From', 'variety'), ('variety', 'perspective'), ('perspective', ','), (',', 'incoming'), ('incoming', 'data'), ('data', 'may'), ('may', 'use'), ('use', 'different'), ('different', 'types'), ('types', 'incomplete'), ('incomplete', 'data'), ('data', ','), (',', 'handle'), ('handle', 'also'), ('also', 'bring'), ('bring', 'another'), ('another', 'issue'), ('issue', 'input'), ('input', 'operators'), ('operators', 'data'), ('data', 'analytics'), ('analytics', '.')]

>> Trigrams are: 
 [('–', 'From', 'variety'), ('From', 'variety', 'perspective'), ('variety', 'perspective', ','), ('perspective', ',', 'incoming'), (',', 'incoming', 'data'), ('incoming', 'data', 'may'), ('data', 'may', 'use'), ('may', 'use', 'different'), ('use', 'different', 'types'), ('different', 'types', 'incomplete'), ('types', 'incomplete', 'data'), ('incomplete', 'data', ','), ('data', ',', 'handle'), (',', 'handle', 'also'), ('handle', 'also', 'bring'), ('also', 'bring', 'another'), ('bring', 'another', 'issue'), ('another', 'issue', 'input'), ('issue', 'input', 'operators'), ('input', 'operators', 'data'), ('operators', 'data', 'analytics'), ('data', 'analytics', '.')]

>> POS Tags are: 
 [('–', 'NN'), ('From', 'IN'), ('variety', 'NN'), ('perspective', 'NN'), (',', ','), ('incoming', 'VBG'), ('data', 'NNS'), ('may', 'MD'), ('use', 'VB'), ('different', 'JJ'), ('types', 'NNS'), ('incomplete', 'JJ'), ('data', 'NNS'), (',', ','), ('handle', 'NN'), ('also', 'RB'), ('bring', 'VBG'), ('another', 'DT'), ('issue', 'NN'), ('input', 'NN'), ('operators', 'NNS'), ('data', 'VBP'), ('analytics', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['–', 'variety perspective', 'data', 'different types', 'incomplete data', 'handle', 'another issue input operators', 'analytics']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('–', '–'), ('From', 'from'), ('variety', 'varieti'), ('perspective', 'perspect'), (',', ','), ('incoming', 'incom'), ('data', 'data'), ('may', 'may'), ('use', 'use'), ('different', 'differ'), ('types', 'type'), ('incomplete', 'incomplet'), ('data', 'data'), (',', ','), ('handle', 'handl'), ('also', 'also'), ('bring', 'bring'), ('another', 'anoth'), ('issue', 'issu'), ('input', 'input'), ('operators', 'oper'), ('data', 'data'), ('analytics', 'analyt'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('–', '–'), ('From', 'from'), ('variety', 'varieti'), ('perspective', 'perspect'), (',', ','), ('incoming', 'incom'), ('data', 'data'), ('may', 'may'), ('use', 'use'), ('different', 'differ'), ('types', 'type'), ('incomplete', 'incomplet'), ('data', 'data'), (',', ','), ('handle', 'handl'), ('also', 'also'), ('bring', 'bring'), ('another', 'anoth'), ('issue', 'issu'), ('input', 'input'), ('operators', 'oper'), ('data', 'data'), ('analytics', 'analyt'), ('.', '.')]

>> Lemmatization: 
 [('–', '–'), ('From', 'From'), ('variety', 'variety'), ('perspective', 'perspective'), (',', ','), ('incoming', 'incoming'), ('data', 'data'), ('may', 'may'), ('use', 'use'), ('different', 'different'), ('types', 'type'), ('incomplete', 'incomplete'), ('data', 'data'), (',', ','), ('handle', 'handle'), ('also', 'also'), ('bring', 'bring'), ('another', 'another'), ('issue', 'issue'), ('input', 'input'), ('operators', 'operator'), ('data', 'data'), ('analytics', 'analytics'), ('.', '.')]



========================================== PARAGRAPH 176 ===========================================

In this section, we will turn the discussion to the big data analytics process. 

------------------- Sentence 1 -------------------

In this section, we will turn the discussion to the big data analytics process.

>> Tokens are: 
 ['In', 'section', ',', 'turn', 'discussion', 'big', 'data', 'analytics', 'process', '.']

>> Bigrams are: 
 [('In', 'section'), ('section', ','), (',', 'turn'), ('turn', 'discussion'), ('discussion', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', 'process'), ('process', '.')]

>> Trigrams are: 
 [('In', 'section', ','), ('section', ',', 'turn'), (',', 'turn', 'discussion'), ('turn', 'discussion', 'big'), ('discussion', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', 'process'), ('analytics', 'process', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('section', 'NN'), (',', ','), ('turn', 'VBP'), ('discussion', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('process', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['section', 'discussion', 'big data analytics process']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('section', 'section'), (',', ','), ('turn', 'turn'), ('discussion', 'discuss'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('process', 'process'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('section', 'section'), (',', ','), ('turn', 'turn'), ('discussion', 'discuss'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('process', 'process'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('section', 'section'), (',', ','), ('turn', 'turn'), ('discussion', 'discussion'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('process', 'process'), ('.', '.')]



========================================== PARAGRAPH 177 ===========================================

Big data input 

------------------- Sentence 1 -------------------

Big data input

>> Tokens are: 
 ['Big', 'data', 'input']

>> Bigrams are: 
 [('Big', 'data'), ('data', 'input')]

>> Trigrams are: 
 [('Big', 'data', 'input')]

>> POS Tags are: 
 [('Big', 'NNP'), ('data', 'NNS'), ('input', 'NN')]

>> Noun Phrases are: 
 ['Big data input']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('input', 'input')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('input', 'input')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), ('input', 'input')]



========================================== PARAGRAPH 178 ===========================================

The problem of handling a vast quantity of data that the system is unable to process is  not a brand-new research issue; in fact, it appeared in several early approaches [2, 21,  72], e.g.-, marketing analysis, network flow monitor, gene expression analysis, weather  forecast, and even astronomy analysis. This problem still exists in big data analytics  today; thus, preprocessing is an important task to make the computer, platform, and  analysis algorithm be able to handle the input data. The traditional data preprocessing 

------------------- Sentence 1 -------------------

The problem of handling a vast quantity of data that the system is unable to process is  not a brand-new research issue; in fact, it appeared in several early approaches [2, 21,  72], e.g.-, marketing analysis, network flow monitor, gene expression analysis, weather  forecast, and even astronomy analysis.

>> Tokens are: 
 ['The', 'problem', 'handling', 'vast', 'quantity', 'data', 'system', 'unable', 'process', 'brand-new', 'research', 'issue', ';', 'fact', ',', 'appeared', 'several', 'early', 'approaches', '[', '2', ',', '21', ',', '72', ']', ',', 'e.g.-', ',', 'marketing', 'analysis', ',', 'network', 'flow', 'monitor', ',', 'gene', 'expression', 'analysis', ',', 'weather', 'forecast', ',', 'even', 'astronomy', 'analysis', '.']

>> Bigrams are: 
 [('The', 'problem'), ('problem', 'handling'), ('handling', 'vast'), ('vast', 'quantity'), ('quantity', 'data'), ('data', 'system'), ('system', 'unable'), ('unable', 'process'), ('process', 'brand-new'), ('brand-new', 'research'), ('research', 'issue'), ('issue', ';'), (';', 'fact'), ('fact', ','), (',', 'appeared'), ('appeared', 'several'), ('several', 'early'), ('early', 'approaches'), ('approaches', '['), ('[', '2'), ('2', ','), (',', '21'), ('21', ','), (',', '72'), ('72', ']'), (']', ','), (',', 'e.g.-'), ('e.g.-', ','), (',', 'marketing'), ('marketing', 'analysis'), ('analysis', ','), (',', 'network'), ('network', 'flow'), ('flow', 'monitor'), ('monitor', ','), (',', 'gene'), ('gene', 'expression'), ('expression', 'analysis'), ('analysis', ','), (',', 'weather'), ('weather', 'forecast'), ('forecast', ','), (',', 'even'), ('even', 'astronomy'), ('astronomy', 'analysis'), ('analysis', '.')]

>> Trigrams are: 
 [('The', 'problem', 'handling'), ('problem', 'handling', 'vast'), ('handling', 'vast', 'quantity'), ('vast', 'quantity', 'data'), ('quantity', 'data', 'system'), ('data', 'system', 'unable'), ('system', 'unable', 'process'), ('unable', 'process', 'brand-new'), ('process', 'brand-new', 'research'), ('brand-new', 'research', 'issue'), ('research', 'issue', ';'), ('issue', ';', 'fact'), (';', 'fact', ','), ('fact', ',', 'appeared'), (',', 'appeared', 'several'), ('appeared', 'several', 'early'), ('several', 'early', 'approaches'), ('early', 'approaches', '['), ('approaches', '[', '2'), ('[', '2', ','), ('2', ',', '21'), (',', '21', ','), ('21', ',', '72'), (',', '72', ']'), ('72', ']', ','), (']', ',', 'e.g.-'), (',', 'e.g.-', ','), ('e.g.-', ',', 'marketing'), (',', 'marketing', 'analysis'), ('marketing', 'analysis', ','), ('analysis', ',', 'network'), (',', 'network', 'flow'), ('network', 'flow', 'monitor'), ('flow', 'monitor', ','), ('monitor', ',', 'gene'), (',', 'gene', 'expression'), ('gene', 'expression', 'analysis'), ('expression', 'analysis', ','), ('analysis', ',', 'weather'), (',', 'weather', 'forecast'), ('weather', 'forecast', ','), ('forecast', ',', 'even'), (',', 'even', 'astronomy'), ('even', 'astronomy', 'analysis'), ('astronomy', 'analysis', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('problem', 'NN'), ('handling', 'VBG'), ('vast', 'JJ'), ('quantity', 'NN'), ('data', 'NNS'), ('system', 'NN'), ('unable', 'JJ'), ('process', 'NN'), ('brand-new', 'JJ'), ('research', 'NN'), ('issue', 'NN'), (';', ':'), ('fact', 'NN'), (',', ','), ('appeared', 'VBD'), ('several', 'JJ'), ('early', 'JJ'), ('approaches', 'NNS'), ('[', 'VBP'), ('2', 'CD'), (',', ','), ('21', 'CD'), (',', ','), ('72', 'CD'), (']', 'NN'), (',', ','), ('e.g.-', 'JJ'), (',', ','), ('marketing', 'NN'), ('analysis', 'NN'), (',', ','), ('network', 'NN'), ('flow', 'NN'), ('monitor', 'NN'), (',', ','), ('gene', 'NN'), ('expression', 'NN'), ('analysis', 'NN'), (',', ','), ('weather', 'JJR'), ('forecast', 'NN'), (',', ','), ('even', 'RB'), ('astronomy', 'JJ'), ('analysis', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['The problem', 'vast quantity data system', 'unable process', 'brand-new research issue', 'fact', 'several early approaches', ']', 'marketing analysis', 'network flow monitor', 'gene expression analysis', 'forecast', 'astronomy analysis']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('problem', 'problem'), ('handling', 'handl'), ('vast', 'vast'), ('quantity', 'quantiti'), ('data', 'data'), ('system', 'system'), ('unable', 'unabl'), ('process', 'process'), ('brand-new', 'brand-new'), ('research', 'research'), ('issue', 'issu'), (';', ';'), ('fact', 'fact'), (',', ','), ('appeared', 'appear'), ('several', 'sever'), ('early', 'earli'), ('approaches', 'approach'), ('[', '['), ('2', '2'), (',', ','), ('21', '21'), (',', ','), ('72', '72'), (']', ']'), (',', ','), ('e.g.-', 'e.g.-'), (',', ','), ('marketing', 'market'), ('analysis', 'analysi'), (',', ','), ('network', 'network'), ('flow', 'flow'), ('monitor', 'monitor'), (',', ','), ('gene', 'gene'), ('expression', 'express'), ('analysis', 'analysi'), (',', ','), ('weather', 'weather'), ('forecast', 'forecast'), (',', ','), ('even', 'even'), ('astronomy', 'astronomi'), ('analysis', 'analysi'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('problem', 'problem'), ('handling', 'handl'), ('vast', 'vast'), ('quantity', 'quantiti'), ('data', 'data'), ('system', 'system'), ('unable', 'unabl'), ('process', 'process'), ('brand-new', 'brand-new'), ('research', 'research'), ('issue', 'issu'), (';', ';'), ('fact', 'fact'), (',', ','), ('appeared', 'appear'), ('several', 'sever'), ('early', 'earli'), ('approaches', 'approach'), ('[', '['), ('2', '2'), (',', ','), ('21', '21'), (',', ','), ('72', '72'), (']', ']'), (',', ','), ('e.g.-', 'e.g.-'), (',', ','), ('marketing', 'market'), ('analysis', 'analysi'), (',', ','), ('network', 'network'), ('flow', 'flow'), ('monitor', 'monitor'), (',', ','), ('gene', 'gene'), ('expression', 'express'), ('analysis', 'analysi'), (',', ','), ('weather', 'weather'), ('forecast', 'forecast'), (',', ','), ('even', 'even'), ('astronomy', 'astronomi'), ('analysis', 'analysi'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('problem', 'problem'), ('handling', 'handling'), ('vast', 'vast'), ('quantity', 'quantity'), ('data', 'data'), ('system', 'system'), ('unable', 'unable'), ('process', 'process'), ('brand-new', 'brand-new'), ('research', 'research'), ('issue', 'issue'), (';', ';'), ('fact', 'fact'), (',', ','), ('appeared', 'appeared'), ('several', 'several'), ('early', 'early'), ('approaches', 'approach'), ('[', '['), ('2', '2'), (',', ','), ('21', '21'), (',', ','), ('72', '72'), (']', ']'), (',', ','), ('e.g.-', 'e.g.-'), (',', ','), ('marketing', 'marketing'), ('analysis', 'analysis'), (',', ','), ('network', 'network'), ('flow', 'flow'), ('monitor', 'monitor'), (',', ','), ('gene', 'gene'), ('expression', 'expression'), ('analysis', 'analysis'), (',', ','), ('weather', 'weather'), ('forecast', 'forecast'), (',', ','), ('even', 'even'), ('astronomy', 'astronomy'), ('analysis', 'analysis'), ('.', '.')]


------------------- Sentence 2 -------------------

This problem still exists in big data analytics  today; thus, preprocessing is an important task to make the computer, platform, and  analysis algorithm be able to handle the input data.

>> Tokens are: 
 ['This', 'problem', 'still', 'exists', 'big', 'data', 'analytics', 'today', ';', 'thus', ',', 'preprocessing', 'important', 'task', 'make', 'computer', ',', 'platform', ',', 'analysis', 'algorithm', 'able', 'handle', 'input', 'data', '.']

>> Bigrams are: 
 [('This', 'problem'), ('problem', 'still'), ('still', 'exists'), ('exists', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', 'today'), ('today', ';'), (';', 'thus'), ('thus', ','), (',', 'preprocessing'), ('preprocessing', 'important'), ('important', 'task'), ('task', 'make'), ('make', 'computer'), ('computer', ','), (',', 'platform'), ('platform', ','), (',', 'analysis'), ('analysis', 'algorithm'), ('algorithm', 'able'), ('able', 'handle'), ('handle', 'input'), ('input', 'data'), ('data', '.')]

>> Trigrams are: 
 [('This', 'problem', 'still'), ('problem', 'still', 'exists'), ('still', 'exists', 'big'), ('exists', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', 'today'), ('analytics', 'today', ';'), ('today', ';', 'thus'), (';', 'thus', ','), ('thus', ',', 'preprocessing'), (',', 'preprocessing', 'important'), ('preprocessing', 'important', 'task'), ('important', 'task', 'make'), ('task', 'make', 'computer'), ('make', 'computer', ','), ('computer', ',', 'platform'), (',', 'platform', ','), ('platform', ',', 'analysis'), (',', 'analysis', 'algorithm'), ('analysis', 'algorithm', 'able'), ('algorithm', 'able', 'handle'), ('able', 'handle', 'input'), ('handle', 'input', 'data'), ('input', 'data', '.')]

>> POS Tags are: 
 [('This', 'DT'), ('problem', 'NN'), ('still', 'RB'), ('exists', 'VBZ'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('today', 'NN'), (';', ':'), ('thus', 'RB'), (',', ','), ('preprocessing', 'VBG'), ('important', 'JJ'), ('task', 'NNS'), ('make', 'VBP'), ('computer', 'NN'), (',', ','), ('platform', 'NN'), (',', ','), ('analysis', 'NN'), ('algorithm', 'NN'), ('able', 'JJ'), ('handle', 'NN'), ('input', 'NN'), ('data', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['This problem', 'big data analytics today', 'important task', 'computer', 'platform', 'analysis algorithm', 'able handle input data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('This', 'thi'), ('problem', 'problem'), ('still', 'still'), ('exists', 'exist'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('today', 'today'), (';', ';'), ('thus', 'thu'), (',', ','), ('preprocessing', 'preprocess'), ('important', 'import'), ('task', 'task'), ('make', 'make'), ('computer', 'comput'), (',', ','), ('platform', 'platform'), (',', ','), ('analysis', 'analysi'), ('algorithm', 'algorithm'), ('able', 'abl'), ('handle', 'handl'), ('input', 'input'), ('data', 'data'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('This', 'this'), ('problem', 'problem'), ('still', 'still'), ('exists', 'exist'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('today', 'today'), (';', ';'), ('thus', 'thus'), (',', ','), ('preprocessing', 'preprocess'), ('important', 'import'), ('task', 'task'), ('make', 'make'), ('computer', 'comput'), (',', ','), ('platform', 'platform'), (',', ','), ('analysis', 'analysi'), ('algorithm', 'algorithm'), ('able', 'abl'), ('handle', 'handl'), ('input', 'input'), ('data', 'data'), ('.', '.')]

>> Lemmatization: 
 [('This', 'This'), ('problem', 'problem'), ('still', 'still'), ('exists', 'exists'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('today', 'today'), (';', ';'), ('thus', 'thus'), (',', ','), ('preprocessing', 'preprocessing'), ('important', 'important'), ('task', 'task'), ('make', 'make'), ('computer', 'computer'), (',', ','), ('platform', 'platform'), (',', ','), ('analysis', 'analysis'), ('algorithm', 'algorithm'), ('able', 'able'), ('handle', 'handle'), ('input', 'input'), ('data', 'data'), ('.', '.')]


------------------- Sentence 3 -------------------

The traditional data preprocessing

>> Tokens are: 
 ['The', 'traditional', 'data', 'preprocessing']

>> Bigrams are: 
 [('The', 'traditional'), ('traditional', 'data'), ('data', 'preprocessing')]

>> Trigrams are: 
 [('The', 'traditional', 'data'), ('traditional', 'data', 'preprocessing')]

>> POS Tags are: 
 [('The', 'DT'), ('traditional', 'JJ'), ('data', 'NNS'), ('preprocessing', 'NN')]

>> Noun Phrases are: 
 ['The traditional data preprocessing']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('traditional', 'tradit'), ('data', 'data'), ('preprocessing', 'preprocess')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('traditional', 'tradit'), ('data', 'data'), ('preprocessing', 'preprocess')]

>> Lemmatization: 
 [('The', 'The'), ('traditional', 'traditional'), ('data', 'data'), ('preprocessing', 'preprocessing')]



========================================== PARAGRAPH 179 ===========================================

Page 11 of 32Tsai et al. Journal of Big Data  (2015) 2:21  

------------------- Sentence 1 -------------------

Page 11 of 32Tsai et al.

>> Tokens are: 
 ['Page', '11', '32Tsai', 'et', 'al', '.']

>> Bigrams are: 
 [('Page', '11'), ('11', '32Tsai'), ('32Tsai', 'et'), ('et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('Page', '11', '32Tsai'), ('11', '32Tsai', 'et'), ('32Tsai', 'et', 'al'), ('et', 'al', '.')]

>> POS Tags are: 
 [('Page', 'NN'), ('11', 'CD'), ('32Tsai', 'CD'), ('et', 'NN'), ('al', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Page', 'et al']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Page', 'page'), ('11', '11'), ('32Tsai', '32tsai'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Page', 'page'), ('11', '11'), ('32Tsai', '32tsai'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('Page', 'Page'), ('11', '11'), ('32Tsai', '32Tsai'), ('et', 'et'), ('al', 'al'), ('.', '.')]


------------------- Sentence 2 -------------------

Journal of Big Data  (2015) 2:21

>> Tokens are: 
 ['Journal', 'Big', 'Data', '(', '2015', ')', '2:21']

>> Bigrams are: 
 [('Journal', 'Big'), ('Big', 'Data'), ('Data', '('), ('(', '2015'), ('2015', ')'), (')', '2:21')]

>> Trigrams are: 
 [('Journal', 'Big', 'Data'), ('Big', 'Data', '('), ('Data', '(', '2015'), ('(', '2015', ')'), ('2015', ')', '2:21')]

>> POS Tags are: 
 [('Journal', 'NNP'), ('Big', 'NNP'), ('Data', 'NNP'), ('(', '('), ('2015', 'CD'), (')', ')'), ('2:21', 'CD')]

>> Noun Phrases are: 
 ['Journal Big Data']

>> Named Entities are: 
 [('PERSON', 'Journal')] 

>> Stemming using Porter Stemmer: 
 [('Journal', 'journal'), ('Big', 'big'), ('Data', 'data'), ('(', '('), ('2015', '2015'), (')', ')'), ('2:21', '2:21')]

>> Stemming using Snowball Stemmer: 
 [('Journal', 'journal'), ('Big', 'big'), ('Data', 'data'), ('(', '('), ('2015', '2015'), (')', ')'), ('2:21', '2:21')]

>> Lemmatization: 
 [('Journal', 'Journal'), ('Big', 'Big'), ('Data', 'Data'), ('(', '('), ('2015', '2015'), (')', ')'), ('2:21', '2:21')]



========================================== PARAGRAPH 180 ===========================================

methods [73] (e.g.-, compression, sampling, feature selection, and so on) are expected  to be able to operate effectively in the big data age. However, a portion of the studies  still focus on how to reduce the complexity of the input data because even the most  advanced computer technology cannot efficiently process the whole input data by using  a single machine in most cases. By using domain knowledge to design the preprocessing  operator is a possible solution for the big data. In [74], Ham and Lee used the domain  knowledge, B-tree, divide-and-conquer to filter the unrelated log information for the  mobile web log analysis. A later study [75] considered that the computation cost of pre- processing will be quite high for massive logs, sensor, or marketing data analysis. Thus,  Dawelbeit and McCrindle employed the bin packing partitioning method to divide the  input data between the computing processors to handle this high computations of pre- processing on cloud system. The cloud system is employed to preprocess the raw data  and then output the refined data (e.g.-, data with uniform format) to make it easier for the  data analysis method or system to preform the further analysis work. 

------------------- Sentence 1 -------------------

methods [73] (e.g.-, compression, sampling, feature selection, and so on) are expected  to be able to operate effectively in the big data age.

>> Tokens are: 
 ['methods', '[', '73', ']', '(', 'e.g.-', ',', 'compression', ',', 'sampling', ',', 'feature', 'selection', ',', ')', 'expected', 'able', 'operate', 'effectively', 'big', 'data', 'age', '.']

>> Bigrams are: 
 [('methods', '['), ('[', '73'), ('73', ']'), (']', '('), ('(', 'e.g.-'), ('e.g.-', ','), (',', 'compression'), ('compression', ','), (',', 'sampling'), ('sampling', ','), (',', 'feature'), ('feature', 'selection'), ('selection', ','), (',', ')'), (')', 'expected'), ('expected', 'able'), ('able', 'operate'), ('operate', 'effectively'), ('effectively', 'big'), ('big', 'data'), ('data', 'age'), ('age', '.')]

>> Trigrams are: 
 [('methods', '[', '73'), ('[', '73', ']'), ('73', ']', '('), (']', '(', 'e.g.-'), ('(', 'e.g.-', ','), ('e.g.-', ',', 'compression'), (',', 'compression', ','), ('compression', ',', 'sampling'), (',', 'sampling', ','), ('sampling', ',', 'feature'), (',', 'feature', 'selection'), ('feature', 'selection', ','), ('selection', ',', ')'), (',', ')', 'expected'), (')', 'expected', 'able'), ('expected', 'able', 'operate'), ('able', 'operate', 'effectively'), ('operate', 'effectively', 'big'), ('effectively', 'big', 'data'), ('big', 'data', 'age'), ('data', 'age', '.')]

>> POS Tags are: 
 [('methods', 'NNS'), ('[', 'VBP'), ('73', 'CD'), (']', 'NN'), ('(', '('), ('e.g.-', 'JJ'), (',', ','), ('compression', 'NN'), (',', ','), ('sampling', 'VBG'), (',', ','), ('feature', 'NN'), ('selection', 'NN'), (',', ','), (')', ')'), ('expected', 'VBD'), ('able', 'JJ'), ('operate', 'NN'), ('effectively', 'RB'), ('big', 'JJ'), ('data', 'NNS'), ('age', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['methods', ']', 'compression', 'feature selection', 'able operate', 'big data age']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('methods', 'method'), ('[', '['), ('73', '73'), (']', ']'), ('(', '('), ('e.g.-', 'e.g.-'), (',', ','), ('compression', 'compress'), (',', ','), ('sampling', 'sampl'), (',', ','), ('feature', 'featur'), ('selection', 'select'), (',', ','), (')', ')'), ('expected', 'expect'), ('able', 'abl'), ('operate', 'oper'), ('effectively', 'effect'), ('big', 'big'), ('data', 'data'), ('age', 'age'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('methods', 'method'), ('[', '['), ('73', '73'), (']', ']'), ('(', '('), ('e.g.-', 'e.g.-'), (',', ','), ('compression', 'compress'), (',', ','), ('sampling', 'sampl'), (',', ','), ('feature', 'featur'), ('selection', 'select'), (',', ','), (')', ')'), ('expected', 'expect'), ('able', 'abl'), ('operate', 'oper'), ('effectively', 'effect'), ('big', 'big'), ('data', 'data'), ('age', 'age'), ('.', '.')]

>> Lemmatization: 
 [('methods', 'method'), ('[', '['), ('73', '73'), (']', ']'), ('(', '('), ('e.g.-', 'e.g.-'), (',', ','), ('compression', 'compression'), (',', ','), ('sampling', 'sampling'), (',', ','), ('feature', 'feature'), ('selection', 'selection'), (',', ','), (')', ')'), ('expected', 'expected'), ('able', 'able'), ('operate', 'operate'), ('effectively', 'effectively'), ('big', 'big'), ('data', 'data'), ('age', 'age'), ('.', '.')]


------------------- Sentence 2 -------------------

However, a portion of the studies  still focus on how to reduce the complexity of the input data because even the most  advanced computer technology cannot efficiently process the whole input data by using  a single machine in most cases.

>> Tokens are: 
 ['However', ',', 'portion', 'studies', 'still', 'focus', 'reduce', 'complexity', 'input', 'data', 'even', 'advanced', 'computer', 'technology', 'efficiently', 'process', 'whole', 'input', 'data', 'using', 'single', 'machine', 'cases', '.']

>> Bigrams are: 
 [('However', ','), (',', 'portion'), ('portion', 'studies'), ('studies', 'still'), ('still', 'focus'), ('focus', 'reduce'), ('reduce', 'complexity'), ('complexity', 'input'), ('input', 'data'), ('data', 'even'), ('even', 'advanced'), ('advanced', 'computer'), ('computer', 'technology'), ('technology', 'efficiently'), ('efficiently', 'process'), ('process', 'whole'), ('whole', 'input'), ('input', 'data'), ('data', 'using'), ('using', 'single'), ('single', 'machine'), ('machine', 'cases'), ('cases', '.')]

>> Trigrams are: 
 [('However', ',', 'portion'), (',', 'portion', 'studies'), ('portion', 'studies', 'still'), ('studies', 'still', 'focus'), ('still', 'focus', 'reduce'), ('focus', 'reduce', 'complexity'), ('reduce', 'complexity', 'input'), ('complexity', 'input', 'data'), ('input', 'data', 'even'), ('data', 'even', 'advanced'), ('even', 'advanced', 'computer'), ('advanced', 'computer', 'technology'), ('computer', 'technology', 'efficiently'), ('technology', 'efficiently', 'process'), ('efficiently', 'process', 'whole'), ('process', 'whole', 'input'), ('whole', 'input', 'data'), ('input', 'data', 'using'), ('data', 'using', 'single'), ('using', 'single', 'machine'), ('single', 'machine', 'cases'), ('machine', 'cases', '.')]

>> POS Tags are: 
 [('However', 'RB'), (',', ','), ('portion', 'NN'), ('studies', 'NNS'), ('still', 'RB'), ('focus', 'VBP'), ('reduce', 'VB'), ('complexity', 'NN'), ('input', 'NN'), ('data', 'NNS'), ('even', 'RB'), ('advanced', 'VBD'), ('computer', 'NN'), ('technology', 'NN'), ('efficiently', 'RB'), ('process', 'JJ'), ('whole', 'JJ'), ('input', 'NN'), ('data', 'NNS'), ('using', 'VBG'), ('single', 'JJ'), ('machine', 'NN'), ('cases', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['portion studies', 'complexity input data', 'computer technology', 'process whole input data', 'single machine cases']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('However', 'howev'), (',', ','), ('portion', 'portion'), ('studies', 'studi'), ('still', 'still'), ('focus', 'focu'), ('reduce', 'reduc'), ('complexity', 'complex'), ('input', 'input'), ('data', 'data'), ('even', 'even'), ('advanced', 'advanc'), ('computer', 'comput'), ('technology', 'technolog'), ('efficiently', 'effici'), ('process', 'process'), ('whole', 'whole'), ('input', 'input'), ('data', 'data'), ('using', 'use'), ('single', 'singl'), ('machine', 'machin'), ('cases', 'case'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('However', 'howev'), (',', ','), ('portion', 'portion'), ('studies', 'studi'), ('still', 'still'), ('focus', 'focus'), ('reduce', 'reduc'), ('complexity', 'complex'), ('input', 'input'), ('data', 'data'), ('even', 'even'), ('advanced', 'advanc'), ('computer', 'comput'), ('technology', 'technolog'), ('efficiently', 'effici'), ('process', 'process'), ('whole', 'whole'), ('input', 'input'), ('data', 'data'), ('using', 'use'), ('single', 'singl'), ('machine', 'machin'), ('cases', 'case'), ('.', '.')]

>> Lemmatization: 
 [('However', 'However'), (',', ','), ('portion', 'portion'), ('studies', 'study'), ('still', 'still'), ('focus', 'focus'), ('reduce', 'reduce'), ('complexity', 'complexity'), ('input', 'input'), ('data', 'data'), ('even', 'even'), ('advanced', 'advanced'), ('computer', 'computer'), ('technology', 'technology'), ('efficiently', 'efficiently'), ('process', 'process'), ('whole', 'whole'), ('input', 'input'), ('data', 'data'), ('using', 'using'), ('single', 'single'), ('machine', 'machine'), ('cases', 'case'), ('.', '.')]


------------------- Sentence 3 -------------------

By using domain knowledge to design the preprocessing  operator is a possible solution for the big data.

>> Tokens are: 
 ['By', 'using', 'domain', 'knowledge', 'design', 'preprocessing', 'operator', 'possible', 'solution', 'big', 'data', '.']

>> Bigrams are: 
 [('By', 'using'), ('using', 'domain'), ('domain', 'knowledge'), ('knowledge', 'design'), ('design', 'preprocessing'), ('preprocessing', 'operator'), ('operator', 'possible'), ('possible', 'solution'), ('solution', 'big'), ('big', 'data'), ('data', '.')]

>> Trigrams are: 
 [('By', 'using', 'domain'), ('using', 'domain', 'knowledge'), ('domain', 'knowledge', 'design'), ('knowledge', 'design', 'preprocessing'), ('design', 'preprocessing', 'operator'), ('preprocessing', 'operator', 'possible'), ('operator', 'possible', 'solution'), ('possible', 'solution', 'big'), ('solution', 'big', 'data'), ('big', 'data', '.')]

>> POS Tags are: 
 [('By', 'IN'), ('using', 'VBG'), ('domain', 'NN'), ('knowledge', 'NN'), ('design', 'NN'), ('preprocessing', 'VBG'), ('operator', 'NN'), ('possible', 'JJ'), ('solution', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['domain knowledge design', 'operator', 'possible solution', 'big data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('By', 'by'), ('using', 'use'), ('domain', 'domain'), ('knowledge', 'knowledg'), ('design', 'design'), ('preprocessing', 'preprocess'), ('operator', 'oper'), ('possible', 'possibl'), ('solution', 'solut'), ('big', 'big'), ('data', 'data'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('By', 'by'), ('using', 'use'), ('domain', 'domain'), ('knowledge', 'knowledg'), ('design', 'design'), ('preprocessing', 'preprocess'), ('operator', 'oper'), ('possible', 'possibl'), ('solution', 'solut'), ('big', 'big'), ('data', 'data'), ('.', '.')]

>> Lemmatization: 
 [('By', 'By'), ('using', 'using'), ('domain', 'domain'), ('knowledge', 'knowledge'), ('design', 'design'), ('preprocessing', 'preprocessing'), ('operator', 'operator'), ('possible', 'possible'), ('solution', 'solution'), ('big', 'big'), ('data', 'data'), ('.', '.')]


------------------- Sentence 4 -------------------

In [74], Ham and Lee used the domain  knowledge, B-tree, divide-and-conquer to filter the unrelated log information for the  mobile web log analysis.

>> Tokens are: 
 ['In', '[', '74', ']', ',', 'Ham', 'Lee', 'used', 'domain', 'knowledge', ',', 'B-tree', ',', 'divide-and-conquer', 'filter', 'unrelated', 'log', 'information', 'mobile', 'web', 'log', 'analysis', '.']

>> Bigrams are: 
 [('In', '['), ('[', '74'), ('74', ']'), (']', ','), (',', 'Ham'), ('Ham', 'Lee'), ('Lee', 'used'), ('used', 'domain'), ('domain', 'knowledge'), ('knowledge', ','), (',', 'B-tree'), ('B-tree', ','), (',', 'divide-and-conquer'), ('divide-and-conquer', 'filter'), ('filter', 'unrelated'), ('unrelated', 'log'), ('log', 'information'), ('information', 'mobile'), ('mobile', 'web'), ('web', 'log'), ('log', 'analysis'), ('analysis', '.')]

>> Trigrams are: 
 [('In', '[', '74'), ('[', '74', ']'), ('74', ']', ','), (']', ',', 'Ham'), (',', 'Ham', 'Lee'), ('Ham', 'Lee', 'used'), ('Lee', 'used', 'domain'), ('used', 'domain', 'knowledge'), ('domain', 'knowledge', ','), ('knowledge', ',', 'B-tree'), (',', 'B-tree', ','), ('B-tree', ',', 'divide-and-conquer'), (',', 'divide-and-conquer', 'filter'), ('divide-and-conquer', 'filter', 'unrelated'), ('filter', 'unrelated', 'log'), ('unrelated', 'log', 'information'), ('log', 'information', 'mobile'), ('information', 'mobile', 'web'), ('mobile', 'web', 'log'), ('web', 'log', 'analysis'), ('log', 'analysis', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('[', '$'), ('74', 'CD'), (']', 'NNP'), (',', ','), ('Ham', 'NNP'), ('Lee', 'NNP'), ('used', 'VBD'), ('domain', 'NN'), ('knowledge', 'NN'), (',', ','), ('B-tree', 'NNP'), (',', ','), ('divide-and-conquer', 'JJ'), ('filter', 'NN'), ('unrelated', 'JJ'), ('log', 'NN'), ('information', 'NN'), ('mobile', 'NN'), ('web', 'NN'), ('log', 'NN'), ('analysis', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 [']', 'Ham Lee', 'domain knowledge', 'B-tree', 'divide-and-conquer filter', 'unrelated log information mobile web log analysis']

>> Named Entities are: 
 [('PERSON', 'Ham Lee')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('[', '['), ('74', '74'), (']', ']'), (',', ','), ('Ham', 'ham'), ('Lee', 'lee'), ('used', 'use'), ('domain', 'domain'), ('knowledge', 'knowledg'), (',', ','), ('B-tree', 'b-tree'), (',', ','), ('divide-and-conquer', 'divide-and-conqu'), ('filter', 'filter'), ('unrelated', 'unrel'), ('log', 'log'), ('information', 'inform'), ('mobile', 'mobil'), ('web', 'web'), ('log', 'log'), ('analysis', 'analysi'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('[', '['), ('74', '74'), (']', ']'), (',', ','), ('Ham', 'ham'), ('Lee', 'lee'), ('used', 'use'), ('domain', 'domain'), ('knowledge', 'knowledg'), (',', ','), ('B-tree', 'b-tree'), (',', ','), ('divide-and-conquer', 'divide-and-conqu'), ('filter', 'filter'), ('unrelated', 'unrel'), ('log', 'log'), ('information', 'inform'), ('mobile', 'mobil'), ('web', 'web'), ('log', 'log'), ('analysis', 'analysi'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('[', '['), ('74', '74'), (']', ']'), (',', ','), ('Ham', 'Ham'), ('Lee', 'Lee'), ('used', 'used'), ('domain', 'domain'), ('knowledge', 'knowledge'), (',', ','), ('B-tree', 'B-tree'), (',', ','), ('divide-and-conquer', 'divide-and-conquer'), ('filter', 'filter'), ('unrelated', 'unrelated'), ('log', 'log'), ('information', 'information'), ('mobile', 'mobile'), ('web', 'web'), ('log', 'log'), ('analysis', 'analysis'), ('.', '.')]


------------------- Sentence 5 -------------------

A later study [75] considered that the computation cost of pre- processing will be quite high for massive logs, sensor, or marketing data analysis.

>> Tokens are: 
 ['A', 'later', 'study', '[', '75', ']', 'considered', 'computation', 'cost', 'pre-', 'processing', 'quite', 'high', 'massive', 'logs', ',', 'sensor', ',', 'marketing', 'data', 'analysis', '.']

>> Bigrams are: 
 [('A', 'later'), ('later', 'study'), ('study', '['), ('[', '75'), ('75', ']'), (']', 'considered'), ('considered', 'computation'), ('computation', 'cost'), ('cost', 'pre-'), ('pre-', 'processing'), ('processing', 'quite'), ('quite', 'high'), ('high', 'massive'), ('massive', 'logs'), ('logs', ','), (',', 'sensor'), ('sensor', ','), (',', 'marketing'), ('marketing', 'data'), ('data', 'analysis'), ('analysis', '.')]

>> Trigrams are: 
 [('A', 'later', 'study'), ('later', 'study', '['), ('study', '[', '75'), ('[', '75', ']'), ('75', ']', 'considered'), (']', 'considered', 'computation'), ('considered', 'computation', 'cost'), ('computation', 'cost', 'pre-'), ('cost', 'pre-', 'processing'), ('pre-', 'processing', 'quite'), ('processing', 'quite', 'high'), ('quite', 'high', 'massive'), ('high', 'massive', 'logs'), ('massive', 'logs', ','), ('logs', ',', 'sensor'), (',', 'sensor', ','), ('sensor', ',', 'marketing'), (',', 'marketing', 'data'), ('marketing', 'data', 'analysis'), ('data', 'analysis', '.')]

>> POS Tags are: 
 [('A', 'DT'), ('later', 'RBR'), ('study', 'NN'), ('[', 'VBD'), ('75', 'CD'), (']', 'NN'), ('considered', 'VBN'), ('computation', 'NN'), ('cost', 'NN'), ('pre-', 'JJ'), ('processing', 'NN'), ('quite', 'RB'), ('high', 'JJ'), ('massive', 'JJ'), ('logs', 'NNS'), (',', ','), ('sensor', 'NN'), (',', ','), ('marketing', 'NN'), ('data', 'NNS'), ('analysis', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['study', ']', 'computation cost', 'pre- processing', 'high massive logs', 'sensor', 'marketing data analysis']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('A', 'a'), ('later', 'later'), ('study', 'studi'), ('[', '['), ('75', '75'), (']', ']'), ('considered', 'consid'), ('computation', 'comput'), ('cost', 'cost'), ('pre-', 'pre-'), ('processing', 'process'), ('quite', 'quit'), ('high', 'high'), ('massive', 'massiv'), ('logs', 'log'), (',', ','), ('sensor', 'sensor'), (',', ','), ('marketing', 'market'), ('data', 'data'), ('analysis', 'analysi'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('A', 'a'), ('later', 'later'), ('study', 'studi'), ('[', '['), ('75', '75'), (']', ']'), ('considered', 'consid'), ('computation', 'comput'), ('cost', 'cost'), ('pre-', 'pre-'), ('processing', 'process'), ('quite', 'quit'), ('high', 'high'), ('massive', 'massiv'), ('logs', 'log'), (',', ','), ('sensor', 'sensor'), (',', ','), ('marketing', 'market'), ('data', 'data'), ('analysis', 'analysi'), ('.', '.')]

>> Lemmatization: 
 [('A', 'A'), ('later', 'later'), ('study', 'study'), ('[', '['), ('75', '75'), (']', ']'), ('considered', 'considered'), ('computation', 'computation'), ('cost', 'cost'), ('pre-', 'pre-'), ('processing', 'processing'), ('quite', 'quite'), ('high', 'high'), ('massive', 'massive'), ('logs', 'log'), (',', ','), ('sensor', 'sensor'), (',', ','), ('marketing', 'marketing'), ('data', 'data'), ('analysis', 'analysis'), ('.', '.')]


------------------- Sentence 6 -------------------

Thus,  Dawelbeit and McCrindle employed the bin packing partitioning method to divide the  input data between the computing processors to handle this high computations of pre- processing on cloud system.

>> Tokens are: 
 ['Thus', ',', 'Dawelbeit', 'McCrindle', 'employed', 'bin', 'packing', 'partitioning', 'method', 'divide', 'input', 'data', 'computing', 'processors', 'handle', 'high', 'computations', 'pre-', 'processing', 'cloud', 'system', '.']

>> Bigrams are: 
 [('Thus', ','), (',', 'Dawelbeit'), ('Dawelbeit', 'McCrindle'), ('McCrindle', 'employed'), ('employed', 'bin'), ('bin', 'packing'), ('packing', 'partitioning'), ('partitioning', 'method'), ('method', 'divide'), ('divide', 'input'), ('input', 'data'), ('data', 'computing'), ('computing', 'processors'), ('processors', 'handle'), ('handle', 'high'), ('high', 'computations'), ('computations', 'pre-'), ('pre-', 'processing'), ('processing', 'cloud'), ('cloud', 'system'), ('system', '.')]

>> Trigrams are: 
 [('Thus', ',', 'Dawelbeit'), (',', 'Dawelbeit', 'McCrindle'), ('Dawelbeit', 'McCrindle', 'employed'), ('McCrindle', 'employed', 'bin'), ('employed', 'bin', 'packing'), ('bin', 'packing', 'partitioning'), ('packing', 'partitioning', 'method'), ('partitioning', 'method', 'divide'), ('method', 'divide', 'input'), ('divide', 'input', 'data'), ('input', 'data', 'computing'), ('data', 'computing', 'processors'), ('computing', 'processors', 'handle'), ('processors', 'handle', 'high'), ('handle', 'high', 'computations'), ('high', 'computations', 'pre-'), ('computations', 'pre-', 'processing'), ('pre-', 'processing', 'cloud'), ('processing', 'cloud', 'system'), ('cloud', 'system', '.')]

>> POS Tags are: 
 [('Thus', 'RB'), (',', ','), ('Dawelbeit', 'NNP'), ('McCrindle', 'NNP'), ('employed', 'VBD'), ('bin', 'RP'), ('packing', 'VBG'), ('partitioning', 'VBG'), ('method', 'JJ'), ('divide', 'NN'), ('input', 'NN'), ('data', 'NNS'), ('computing', 'VBG'), ('processors', 'NNS'), ('handle', 'VBP'), ('high', 'JJ'), ('computations', 'NNS'), ('pre-', 'JJ'), ('processing', 'VBG'), ('cloud', 'NN'), ('system', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Dawelbeit McCrindle', 'method divide input data', 'processors', 'high computations', 'cloud system']

>> Named Entities are: 
 [('PERSON', 'Dawelbeit McCrindle')] 

>> Stemming using Porter Stemmer: 
 [('Thus', 'thu'), (',', ','), ('Dawelbeit', 'dawelbeit'), ('McCrindle', 'mccrindl'), ('employed', 'employ'), ('bin', 'bin'), ('packing', 'pack'), ('partitioning', 'partit'), ('method', 'method'), ('divide', 'divid'), ('input', 'input'), ('data', 'data'), ('computing', 'comput'), ('processors', 'processor'), ('handle', 'handl'), ('high', 'high'), ('computations', 'comput'), ('pre-', 'pre-'), ('processing', 'process'), ('cloud', 'cloud'), ('system', 'system'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Thus', 'thus'), (',', ','), ('Dawelbeit', 'dawelbeit'), ('McCrindle', 'mccrindl'), ('employed', 'employ'), ('bin', 'bin'), ('packing', 'pack'), ('partitioning', 'partit'), ('method', 'method'), ('divide', 'divid'), ('input', 'input'), ('data', 'data'), ('computing', 'comput'), ('processors', 'processor'), ('handle', 'handl'), ('high', 'high'), ('computations', 'comput'), ('pre-', 'pre-'), ('processing', 'process'), ('cloud', 'cloud'), ('system', 'system'), ('.', '.')]

>> Lemmatization: 
 [('Thus', 'Thus'), (',', ','), ('Dawelbeit', 'Dawelbeit'), ('McCrindle', 'McCrindle'), ('employed', 'employed'), ('bin', 'bin'), ('packing', 'packing'), ('partitioning', 'partitioning'), ('method', 'method'), ('divide', 'divide'), ('input', 'input'), ('data', 'data'), ('computing', 'computing'), ('processors', 'processor'), ('handle', 'handle'), ('high', 'high'), ('computations', 'computation'), ('pre-', 'pre-'), ('processing', 'processing'), ('cloud', 'cloud'), ('system', 'system'), ('.', '.')]


------------------- Sentence 7 -------------------

The cloud system is employed to preprocess the raw data  and then output the refined data (e.g.-, data with uniform format) to make it easier for the  data analysis method or system to preform the further analysis work.

>> Tokens are: 
 ['The', 'cloud', 'system', 'employed', 'preprocess', 'raw', 'data', 'output', 'refined', 'data', '(', 'e.g.-', ',', 'data', 'uniform', 'format', ')', 'make', 'easier', 'data', 'analysis', 'method', 'system', 'preform', 'analysis', 'work', '.']

>> Bigrams are: 
 [('The', 'cloud'), ('cloud', 'system'), ('system', 'employed'), ('employed', 'preprocess'), ('preprocess', 'raw'), ('raw', 'data'), ('data', 'output'), ('output', 'refined'), ('refined', 'data'), ('data', '('), ('(', 'e.g.-'), ('e.g.-', ','), (',', 'data'), ('data', 'uniform'), ('uniform', 'format'), ('format', ')'), (')', 'make'), ('make', 'easier'), ('easier', 'data'), ('data', 'analysis'), ('analysis', 'method'), ('method', 'system'), ('system', 'preform'), ('preform', 'analysis'), ('analysis', 'work'), ('work', '.')]

>> Trigrams are: 
 [('The', 'cloud', 'system'), ('cloud', 'system', 'employed'), ('system', 'employed', 'preprocess'), ('employed', 'preprocess', 'raw'), ('preprocess', 'raw', 'data'), ('raw', 'data', 'output'), ('data', 'output', 'refined'), ('output', 'refined', 'data'), ('refined', 'data', '('), ('data', '(', 'e.g.-'), ('(', 'e.g.-', ','), ('e.g.-', ',', 'data'), (',', 'data', 'uniform'), ('data', 'uniform', 'format'), ('uniform', 'format', ')'), ('format', ')', 'make'), (')', 'make', 'easier'), ('make', 'easier', 'data'), ('easier', 'data', 'analysis'), ('data', 'analysis', 'method'), ('analysis', 'method', 'system'), ('method', 'system', 'preform'), ('system', 'preform', 'analysis'), ('preform', 'analysis', 'work'), ('analysis', 'work', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('cloud', 'NN'), ('system', 'NN'), ('employed', 'VBD'), ('preprocess', 'JJ'), ('raw', 'JJ'), ('data', 'NNS'), ('output', 'NN'), ('refined', 'VBN'), ('data', 'NNS'), ('(', '('), ('e.g.-', 'JJ'), (',', ','), ('data', 'NNS'), ('uniform', 'JJ'), ('format', 'NN'), (')', ')'), ('make', 'VBP'), ('easier', 'JJR'), ('data', 'NNS'), ('analysis', 'NN'), ('method', 'NN'), ('system', 'NN'), ('preform', 'NN'), ('analysis', 'NN'), ('work', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['The cloud system', 'preprocess raw data output', 'data', 'data', 'uniform format', 'data analysis method system preform analysis work']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('cloud', 'cloud'), ('system', 'system'), ('employed', 'employ'), ('preprocess', 'preprocess'), ('raw', 'raw'), ('data', 'data'), ('output', 'output'), ('refined', 'refin'), ('data', 'data'), ('(', '('), ('e.g.-', 'e.g.-'), (',', ','), ('data', 'data'), ('uniform', 'uniform'), ('format', 'format'), (')', ')'), ('make', 'make'), ('easier', 'easier'), ('data', 'data'), ('analysis', 'analysi'), ('method', 'method'), ('system', 'system'), ('preform', 'preform'), ('analysis', 'analysi'), ('work', 'work'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('cloud', 'cloud'), ('system', 'system'), ('employed', 'employ'), ('preprocess', 'preprocess'), ('raw', 'raw'), ('data', 'data'), ('output', 'output'), ('refined', 'refin'), ('data', 'data'), ('(', '('), ('e.g.-', 'e.g.-'), (',', ','), ('data', 'data'), ('uniform', 'uniform'), ('format', 'format'), (')', ')'), ('make', 'make'), ('easier', 'easier'), ('data', 'data'), ('analysis', 'analysi'), ('method', 'method'), ('system', 'system'), ('preform', 'preform'), ('analysis', 'analysi'), ('work', 'work'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('cloud', 'cloud'), ('system', 'system'), ('employed', 'employed'), ('preprocess', 'preprocess'), ('raw', 'raw'), ('data', 'data'), ('output', 'output'), ('refined', 'refined'), ('data', 'data'), ('(', '('), ('e.g.-', 'e.g.-'), (',', ','), ('data', 'data'), ('uniform', 'uniform'), ('format', 'format'), (')', ')'), ('make', 'make'), ('easier', 'easier'), ('data', 'data'), ('analysis', 'analysis'), ('method', 'method'), ('system', 'system'), ('preform', 'preform'), ('analysis', 'analysis'), ('work', 'work'), ('.', '.')]



========================================== PARAGRAPH 181 ===========================================

Sampling and compression are two representative data reduction methods for big  data analytics because reducing the size of data makes the data analytics computation- ally less expensive, thus faster, especially for the data coming to the system rapidly. In  addition to making the sampling data represent the original data effectively [76], how  many instances need to be selected for data mining method is another research issue  [77] because it will affect the performance of the sampling method in most cases. 

------------------- Sentence 1 -------------------

Sampling and compression are two representative data reduction methods for big  data analytics because reducing the size of data makes the data analytics computation- ally less expensive, thus faster, especially for the data coming to the system rapidly.

>> Tokens are: 
 ['Sampling', 'compression', 'two', 'representative', 'data', 'reduction', 'methods', 'big', 'data', 'analytics', 'reducing', 'size', 'data', 'makes', 'data', 'analytics', 'computation-', 'ally', 'less', 'expensive', ',', 'thus', 'faster', ',', 'especially', 'data', 'coming', 'system', 'rapidly', '.']

>> Bigrams are: 
 [('Sampling', 'compression'), ('compression', 'two'), ('two', 'representative'), ('representative', 'data'), ('data', 'reduction'), ('reduction', 'methods'), ('methods', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', 'reducing'), ('reducing', 'size'), ('size', 'data'), ('data', 'makes'), ('makes', 'data'), ('data', 'analytics'), ('analytics', 'computation-'), ('computation-', 'ally'), ('ally', 'less'), ('less', 'expensive'), ('expensive', ','), (',', 'thus'), ('thus', 'faster'), ('faster', ','), (',', 'especially'), ('especially', 'data'), ('data', 'coming'), ('coming', 'system'), ('system', 'rapidly'), ('rapidly', '.')]

>> Trigrams are: 
 [('Sampling', 'compression', 'two'), ('compression', 'two', 'representative'), ('two', 'representative', 'data'), ('representative', 'data', 'reduction'), ('data', 'reduction', 'methods'), ('reduction', 'methods', 'big'), ('methods', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', 'reducing'), ('analytics', 'reducing', 'size'), ('reducing', 'size', 'data'), ('size', 'data', 'makes'), ('data', 'makes', 'data'), ('makes', 'data', 'analytics'), ('data', 'analytics', 'computation-'), ('analytics', 'computation-', 'ally'), ('computation-', 'ally', 'less'), ('ally', 'less', 'expensive'), ('less', 'expensive', ','), ('expensive', ',', 'thus'), (',', 'thus', 'faster'), ('thus', 'faster', ','), ('faster', ',', 'especially'), (',', 'especially', 'data'), ('especially', 'data', 'coming'), ('data', 'coming', 'system'), ('coming', 'system', 'rapidly'), ('system', 'rapidly', '.')]

>> POS Tags are: 
 [('Sampling', 'VBG'), ('compression', 'NN'), ('two', 'CD'), ('representative', 'JJ'), ('data', 'NNS'), ('reduction', 'NN'), ('methods', 'NNS'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('reducing', 'VBG'), ('size', 'NN'), ('data', 'NNS'), ('makes', 'VBZ'), ('data', 'NNS'), ('analytics', 'NNS'), ('computation-', 'JJ'), ('ally', 'RB'), ('less', 'RBR'), ('expensive', 'JJ'), (',', ','), ('thus', 'RB'), ('faster', 'RBR'), (',', ','), ('especially', 'RB'), ('data', 'NNS'), ('coming', 'VBG'), ('system', 'NN'), ('rapidly', 'RB'), ('.', '.')]

>> Noun Phrases are: 
 ['compression', 'representative data reduction methods', 'big data analytics', 'size data', 'data analytics', 'data', 'system']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Sampling', 'sampl'), ('compression', 'compress'), ('two', 'two'), ('representative', 'repres'), ('data', 'data'), ('reduction', 'reduct'), ('methods', 'method'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('reducing', 'reduc'), ('size', 'size'), ('data', 'data'), ('makes', 'make'), ('data', 'data'), ('analytics', 'analyt'), ('computation-', 'computation-'), ('ally', 'alli'), ('less', 'less'), ('expensive', 'expens'), (',', ','), ('thus', 'thu'), ('faster', 'faster'), (',', ','), ('especially', 'especi'), ('data', 'data'), ('coming', 'come'), ('system', 'system'), ('rapidly', 'rapidli'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Sampling', 'sampl'), ('compression', 'compress'), ('two', 'two'), ('representative', 'repres'), ('data', 'data'), ('reduction', 'reduct'), ('methods', 'method'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('reducing', 'reduc'), ('size', 'size'), ('data', 'data'), ('makes', 'make'), ('data', 'data'), ('analytics', 'analyt'), ('computation-', 'computation-'), ('ally', 'alli'), ('less', 'less'), ('expensive', 'expens'), (',', ','), ('thus', 'thus'), ('faster', 'faster'), (',', ','), ('especially', 'especi'), ('data', 'data'), ('coming', 'come'), ('system', 'system'), ('rapidly', 'rapid'), ('.', '.')]

>> Lemmatization: 
 [('Sampling', 'Sampling'), ('compression', 'compression'), ('two', 'two'), ('representative', 'representative'), ('data', 'data'), ('reduction', 'reduction'), ('methods', 'method'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('reducing', 'reducing'), ('size', 'size'), ('data', 'data'), ('makes', 'make'), ('data', 'data'), ('analytics', 'analytics'), ('computation-', 'computation-'), ('ally', 'ally'), ('less', 'le'), ('expensive', 'expensive'), (',', ','), ('thus', 'thus'), ('faster', 'faster'), (',', ','), ('especially', 'especially'), ('data', 'data'), ('coming', 'coming'), ('system', 'system'), ('rapidly', 'rapidly'), ('.', '.')]


------------------- Sentence 2 -------------------

In  addition to making the sampling data represent the original data effectively [76], how  many instances need to be selected for data mining method is another research issue  [77] because it will affect the performance of the sampling method in most cases.

>> Tokens are: 
 ['In', 'addition', 'making', 'sampling', 'data', 'represent', 'original', 'data', 'effectively', '[', '76', ']', ',', 'many', 'instances', 'need', 'selected', 'data', 'mining', 'method', 'another', 'research', 'issue', '[', '77', ']', 'affect', 'performance', 'sampling', 'method', 'cases', '.']

>> Bigrams are: 
 [('In', 'addition'), ('addition', 'making'), ('making', 'sampling'), ('sampling', 'data'), ('data', 'represent'), ('represent', 'original'), ('original', 'data'), ('data', 'effectively'), ('effectively', '['), ('[', '76'), ('76', ']'), (']', ','), (',', 'many'), ('many', 'instances'), ('instances', 'need'), ('need', 'selected'), ('selected', 'data'), ('data', 'mining'), ('mining', 'method'), ('method', 'another'), ('another', 'research'), ('research', 'issue'), ('issue', '['), ('[', '77'), ('77', ']'), (']', 'affect'), ('affect', 'performance'), ('performance', 'sampling'), ('sampling', 'method'), ('method', 'cases'), ('cases', '.')]

>> Trigrams are: 
 [('In', 'addition', 'making'), ('addition', 'making', 'sampling'), ('making', 'sampling', 'data'), ('sampling', 'data', 'represent'), ('data', 'represent', 'original'), ('represent', 'original', 'data'), ('original', 'data', 'effectively'), ('data', 'effectively', '['), ('effectively', '[', '76'), ('[', '76', ']'), ('76', ']', ','), (']', ',', 'many'), (',', 'many', 'instances'), ('many', 'instances', 'need'), ('instances', 'need', 'selected'), ('need', 'selected', 'data'), ('selected', 'data', 'mining'), ('data', 'mining', 'method'), ('mining', 'method', 'another'), ('method', 'another', 'research'), ('another', 'research', 'issue'), ('research', 'issue', '['), ('issue', '[', '77'), ('[', '77', ']'), ('77', ']', 'affect'), (']', 'affect', 'performance'), ('affect', 'performance', 'sampling'), ('performance', 'sampling', 'method'), ('sampling', 'method', 'cases'), ('method', 'cases', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('addition', 'NN'), ('making', 'VBG'), ('sampling', 'VBG'), ('data', 'NNS'), ('represent', 'VBP'), ('original', 'JJ'), ('data', 'NNS'), ('effectively', 'RB'), ('[', 'VBP'), ('76', 'CD'), (']', 'NNP'), (',', ','), ('many', 'JJ'), ('instances', 'NNS'), ('need', 'VBP'), ('selected', 'VBN'), ('data', 'NNS'), ('mining', 'NN'), ('method', 'NN'), ('another', 'DT'), ('research', 'NN'), ('issue', 'NN'), ('[', 'VBD'), ('77', 'CD'), (']', 'NNS'), ('affect', 'JJ'), ('performance', 'NN'), ('sampling', 'VBG'), ('method', 'JJ'), ('cases', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['addition', 'data', 'original data', ']', 'many instances', 'data mining method', 'another research issue', ']', 'affect performance', 'method cases']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('addition', 'addit'), ('making', 'make'), ('sampling', 'sampl'), ('data', 'data'), ('represent', 'repres'), ('original', 'origin'), ('data', 'data'), ('effectively', 'effect'), ('[', '['), ('76', '76'), (']', ']'), (',', ','), ('many', 'mani'), ('instances', 'instanc'), ('need', 'need'), ('selected', 'select'), ('data', 'data'), ('mining', 'mine'), ('method', 'method'), ('another', 'anoth'), ('research', 'research'), ('issue', 'issu'), ('[', '['), ('77', '77'), (']', ']'), ('affect', 'affect'), ('performance', 'perform'), ('sampling', 'sampl'), ('method', 'method'), ('cases', 'case'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('addition', 'addit'), ('making', 'make'), ('sampling', 'sampl'), ('data', 'data'), ('represent', 'repres'), ('original', 'origin'), ('data', 'data'), ('effectively', 'effect'), ('[', '['), ('76', '76'), (']', ']'), (',', ','), ('many', 'mani'), ('instances', 'instanc'), ('need', 'need'), ('selected', 'select'), ('data', 'data'), ('mining', 'mine'), ('method', 'method'), ('another', 'anoth'), ('research', 'research'), ('issue', 'issu'), ('[', '['), ('77', '77'), (']', ']'), ('affect', 'affect'), ('performance', 'perform'), ('sampling', 'sampl'), ('method', 'method'), ('cases', 'case'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('addition', 'addition'), ('making', 'making'), ('sampling', 'sampling'), ('data', 'data'), ('represent', 'represent'), ('original', 'original'), ('data', 'data'), ('effectively', 'effectively'), ('[', '['), ('76', '76'), (']', ']'), (',', ','), ('many', 'many'), ('instances', 'instance'), ('need', 'need'), ('selected', 'selected'), ('data', 'data'), ('mining', 'mining'), ('method', 'method'), ('another', 'another'), ('research', 'research'), ('issue', 'issue'), ('[', '['), ('77', '77'), (']', ']'), ('affect', 'affect'), ('performance', 'performance'), ('sampling', 'sampling'), ('method', 'method'), ('cases', 'case'), ('.', '.')]



========================================== PARAGRAPH 182 ===========================================

To avoid the application-level slow-down caused by the compression process, in [78],  Jun et  al. attempted to use the FPGA to accelerate the compression process. The I/O  performance optimization is another issue for the compression method. For this reason,  Zou et  al. [79] employed the tentative selection and predictive dynamic selection and  switched the appropriate compression method from two different strategies to improve  the performance of the compression process. To make it possible for the compression  method to efficiently compress the data, a promising solution is to apply the clustering  method to the input data to divide them into several different groups and then com- press these input data according to the clustering information. The compression method  

------------------- Sentence 1 -------------------

To avoid the application-level slow-down caused by the compression process, in [78],  Jun et  al.

>> Tokens are: 
 ['To', 'avoid', 'application-level', 'slow-down', 'caused', 'compression', 'process', ',', '[', '78', ']', ',', 'Jun', 'et', 'al', '.']

>> Bigrams are: 
 [('To', 'avoid'), ('avoid', 'application-level'), ('application-level', 'slow-down'), ('slow-down', 'caused'), ('caused', 'compression'), ('compression', 'process'), ('process', ','), (',', '['), ('[', '78'), ('78', ']'), (']', ','), (',', 'Jun'), ('Jun', 'et'), ('et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('To', 'avoid', 'application-level'), ('avoid', 'application-level', 'slow-down'), ('application-level', 'slow-down', 'caused'), ('slow-down', 'caused', 'compression'), ('caused', 'compression', 'process'), ('compression', 'process', ','), ('process', ',', '['), (',', '[', '78'), ('[', '78', ']'), ('78', ']', ','), (']', ',', 'Jun'), (',', 'Jun', 'et'), ('Jun', 'et', 'al'), ('et', 'al', '.')]

>> POS Tags are: 
 [('To', 'TO'), ('avoid', 'VB'), ('application-level', 'JJ'), ('slow-down', 'JJ'), ('caused', 'JJ'), ('compression', 'NN'), ('process', 'NN'), (',', ','), ('[', 'VBZ'), ('78', 'CD'), (']', 'NN'), (',', ','), ('Jun', 'NNP'), ('et', 'CC'), ('al', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['application-level slow-down caused compression process', ']', 'Jun', 'al']

>> Named Entities are: 
 [('PERSON', 'Jun')] 

>> Stemming using Porter Stemmer: 
 [('To', 'to'), ('avoid', 'avoid'), ('application-level', 'application-level'), ('slow-down', 'slow-down'), ('caused', 'caus'), ('compression', 'compress'), ('process', 'process'), (',', ','), ('[', '['), ('78', '78'), (']', ']'), (',', ','), ('Jun', 'jun'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('To', 'to'), ('avoid', 'avoid'), ('application-level', 'application-level'), ('slow-down', 'slow-down'), ('caused', 'caus'), ('compression', 'compress'), ('process', 'process'), (',', ','), ('[', '['), ('78', '78'), (']', ']'), (',', ','), ('Jun', 'jun'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('To', 'To'), ('avoid', 'avoid'), ('application-level', 'application-level'), ('slow-down', 'slow-down'), ('caused', 'caused'), ('compression', 'compression'), ('process', 'process'), (',', ','), ('[', '['), ('78', '78'), (']', ']'), (',', ','), ('Jun', 'Jun'), ('et', 'et'), ('al', 'al'), ('.', '.')]


------------------- Sentence 2 -------------------

attempted to use the FPGA to accelerate the compression process.

>> Tokens are: 
 ['attempted', 'use', 'FPGA', 'accelerate', 'compression', 'process', '.']

>> Bigrams are: 
 [('attempted', 'use'), ('use', 'FPGA'), ('FPGA', 'accelerate'), ('accelerate', 'compression'), ('compression', 'process'), ('process', '.')]

>> Trigrams are: 
 [('attempted', 'use', 'FPGA'), ('use', 'FPGA', 'accelerate'), ('FPGA', 'accelerate', 'compression'), ('accelerate', 'compression', 'process'), ('compression', 'process', '.')]

>> POS Tags are: 
 [('attempted', 'VBN'), ('use', 'NN'), ('FPGA', 'NNP'), ('accelerate', 'NN'), ('compression', 'NN'), ('process', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['use FPGA accelerate compression process']

>> Named Entities are: 
 [('ORGANIZATION', 'FPGA')] 

>> Stemming using Porter Stemmer: 
 [('attempted', 'attempt'), ('use', 'use'), ('FPGA', 'fpga'), ('accelerate', 'acceler'), ('compression', 'compress'), ('process', 'process'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('attempted', 'attempt'), ('use', 'use'), ('FPGA', 'fpga'), ('accelerate', 'acceler'), ('compression', 'compress'), ('process', 'process'), ('.', '.')]

>> Lemmatization: 
 [('attempted', 'attempted'), ('use', 'use'), ('FPGA', 'FPGA'), ('accelerate', 'accelerate'), ('compression', 'compression'), ('process', 'process'), ('.', '.')]


------------------- Sentence 3 -------------------

The I/O  performance optimization is another issue for the compression method.

>> Tokens are: 
 ['The', 'I/O', 'performance', 'optimization', 'another', 'issue', 'compression', 'method', '.']

>> Bigrams are: 
 [('The', 'I/O'), ('I/O', 'performance'), ('performance', 'optimization'), ('optimization', 'another'), ('another', 'issue'), ('issue', 'compression'), ('compression', 'method'), ('method', '.')]

>> Trigrams are: 
 [('The', 'I/O', 'performance'), ('I/O', 'performance', 'optimization'), ('performance', 'optimization', 'another'), ('optimization', 'another', 'issue'), ('another', 'issue', 'compression'), ('issue', 'compression', 'method'), ('compression', 'method', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('I/O', 'NNP'), ('performance', 'NN'), ('optimization', 'NN'), ('another', 'DT'), ('issue', 'NN'), ('compression', 'NN'), ('method', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['The I/O performance optimization', 'another issue compression method']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('I/O', 'i/o'), ('performance', 'perform'), ('optimization', 'optim'), ('another', 'anoth'), ('issue', 'issu'), ('compression', 'compress'), ('method', 'method'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('I/O', 'i/o'), ('performance', 'perform'), ('optimization', 'optim'), ('another', 'anoth'), ('issue', 'issu'), ('compression', 'compress'), ('method', 'method'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('I/O', 'I/O'), ('performance', 'performance'), ('optimization', 'optimization'), ('another', 'another'), ('issue', 'issue'), ('compression', 'compression'), ('method', 'method'), ('.', '.')]


------------------- Sentence 4 -------------------

For this reason,  Zou et  al.

>> Tokens are: 
 ['For', 'reason', ',', 'Zou', 'et', 'al', '.']

>> Bigrams are: 
 [('For', 'reason'), ('reason', ','), (',', 'Zou'), ('Zou', 'et'), ('et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('For', 'reason', ','), ('reason', ',', 'Zou'), (',', 'Zou', 'et'), ('Zou', 'et', 'al'), ('et', 'al', '.')]

>> POS Tags are: 
 [('For', 'IN'), ('reason', 'NN'), (',', ','), ('Zou', 'NNP'), ('et', 'CC'), ('al', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['reason', 'Zou', 'al']

>> Named Entities are: 
 [('PERSON', 'Zou')] 

>> Stemming using Porter Stemmer: 
 [('For', 'for'), ('reason', 'reason'), (',', ','), ('Zou', 'zou'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('For', 'for'), ('reason', 'reason'), (',', ','), ('Zou', 'zou'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('For', 'For'), ('reason', 'reason'), (',', ','), ('Zou', 'Zou'), ('et', 'et'), ('al', 'al'), ('.', '.')]


------------------- Sentence 5 -------------------

[79] employed the tentative selection and predictive dynamic selection and  switched the appropriate compression method from two different strategies to improve  the performance of the compression process.

>> Tokens are: 
 ['[', '79', ']', 'employed', 'tentative', 'selection', 'predictive', 'dynamic', 'selection', 'switched', 'appropriate', 'compression', 'method', 'two', 'different', 'strategies', 'improve', 'performance', 'compression', 'process', '.']

>> Bigrams are: 
 [('[', '79'), ('79', ']'), (']', 'employed'), ('employed', 'tentative'), ('tentative', 'selection'), ('selection', 'predictive'), ('predictive', 'dynamic'), ('dynamic', 'selection'), ('selection', 'switched'), ('switched', 'appropriate'), ('appropriate', 'compression'), ('compression', 'method'), ('method', 'two'), ('two', 'different'), ('different', 'strategies'), ('strategies', 'improve'), ('improve', 'performance'), ('performance', 'compression'), ('compression', 'process'), ('process', '.')]

>> Trigrams are: 
 [('[', '79', ']'), ('79', ']', 'employed'), (']', 'employed', 'tentative'), ('employed', 'tentative', 'selection'), ('tentative', 'selection', 'predictive'), ('selection', 'predictive', 'dynamic'), ('predictive', 'dynamic', 'selection'), ('dynamic', 'selection', 'switched'), ('selection', 'switched', 'appropriate'), ('switched', 'appropriate', 'compression'), ('appropriate', 'compression', 'method'), ('compression', 'method', 'two'), ('method', 'two', 'different'), ('two', 'different', 'strategies'), ('different', 'strategies', 'improve'), ('strategies', 'improve', 'performance'), ('improve', 'performance', 'compression'), ('performance', 'compression', 'process'), ('compression', 'process', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('79', 'CD'), (']', 'JJ'), ('employed', 'VBN'), ('tentative', 'JJ'), ('selection', 'NN'), ('predictive', 'JJ'), ('dynamic', 'JJ'), ('selection', 'NN'), ('switched', 'VBD'), ('appropriate', 'JJ'), ('compression', 'NN'), ('method', 'NN'), ('two', 'CD'), ('different', 'JJ'), ('strategies', 'NNS'), ('improve', 'VBP'), ('performance', 'NN'), ('compression', 'NN'), ('process', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['tentative selection', 'predictive dynamic selection', 'appropriate compression method', 'different strategies', 'performance compression process']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('79', '79'), (']', ']'), ('employed', 'employ'), ('tentative', 'tent'), ('selection', 'select'), ('predictive', 'predict'), ('dynamic', 'dynam'), ('selection', 'select'), ('switched', 'switch'), ('appropriate', 'appropri'), ('compression', 'compress'), ('method', 'method'), ('two', 'two'), ('different', 'differ'), ('strategies', 'strategi'), ('improve', 'improv'), ('performance', 'perform'), ('compression', 'compress'), ('process', 'process'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('79', '79'), (']', ']'), ('employed', 'employ'), ('tentative', 'tentat'), ('selection', 'select'), ('predictive', 'predict'), ('dynamic', 'dynam'), ('selection', 'select'), ('switched', 'switch'), ('appropriate', 'appropri'), ('compression', 'compress'), ('method', 'method'), ('two', 'two'), ('different', 'differ'), ('strategies', 'strategi'), ('improve', 'improv'), ('performance', 'perform'), ('compression', 'compress'), ('process', 'process'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('79', '79'), (']', ']'), ('employed', 'employed'), ('tentative', 'tentative'), ('selection', 'selection'), ('predictive', 'predictive'), ('dynamic', 'dynamic'), ('selection', 'selection'), ('switched', 'switched'), ('appropriate', 'appropriate'), ('compression', 'compression'), ('method', 'method'), ('two', 'two'), ('different', 'different'), ('strategies', 'strategy'), ('improve', 'improve'), ('performance', 'performance'), ('compression', 'compression'), ('process', 'process'), ('.', '.')]


------------------- Sentence 6 -------------------

To make it possible for the compression  method to efficiently compress the data, a promising solution is to apply the clustering  method to the input data to divide them into several different groups and then com- press these input data according to the clustering information.

>> Tokens are: 
 ['To', 'make', 'possible', 'compression', 'method', 'efficiently', 'compress', 'data', ',', 'promising', 'solution', 'apply', 'clustering', 'method', 'input', 'data', 'divide', 'several', 'different', 'groups', 'com-', 'press', 'input', 'data', 'according', 'clustering', 'information', '.']

>> Bigrams are: 
 [('To', 'make'), ('make', 'possible'), ('possible', 'compression'), ('compression', 'method'), ('method', 'efficiently'), ('efficiently', 'compress'), ('compress', 'data'), ('data', ','), (',', 'promising'), ('promising', 'solution'), ('solution', 'apply'), ('apply', 'clustering'), ('clustering', 'method'), ('method', 'input'), ('input', 'data'), ('data', 'divide'), ('divide', 'several'), ('several', 'different'), ('different', 'groups'), ('groups', 'com-'), ('com-', 'press'), ('press', 'input'), ('input', 'data'), ('data', 'according'), ('according', 'clustering'), ('clustering', 'information'), ('information', '.')]

>> Trigrams are: 
 [('To', 'make', 'possible'), ('make', 'possible', 'compression'), ('possible', 'compression', 'method'), ('compression', 'method', 'efficiently'), ('method', 'efficiently', 'compress'), ('efficiently', 'compress', 'data'), ('compress', 'data', ','), ('data', ',', 'promising'), (',', 'promising', 'solution'), ('promising', 'solution', 'apply'), ('solution', 'apply', 'clustering'), ('apply', 'clustering', 'method'), ('clustering', 'method', 'input'), ('method', 'input', 'data'), ('input', 'data', 'divide'), ('data', 'divide', 'several'), ('divide', 'several', 'different'), ('several', 'different', 'groups'), ('different', 'groups', 'com-'), ('groups', 'com-', 'press'), ('com-', 'press', 'input'), ('press', 'input', 'data'), ('input', 'data', 'according'), ('data', 'according', 'clustering'), ('according', 'clustering', 'information'), ('clustering', 'information', '.')]

>> POS Tags are: 
 [('To', 'TO'), ('make', 'VB'), ('possible', 'JJ'), ('compression', 'NN'), ('method', 'NN'), ('efficiently', 'RB'), ('compress', 'JJ'), ('data', 'NNS'), (',', ','), ('promising', 'VBG'), ('solution', 'NN'), ('apply', 'RB'), ('clustering', 'VBG'), ('method', 'NN'), ('input', 'NN'), ('data', 'NNS'), ('divide', 'RB'), ('several', 'JJ'), ('different', 'JJ'), ('groups', 'NNS'), ('com-', 'JJ'), ('press', 'NN'), ('input', 'NN'), ('data', 'NNS'), ('according', 'VBG'), ('clustering', 'VBG'), ('information', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['possible compression method', 'compress data', 'solution', 'method input data', 'several different groups', 'com- press input data', 'information']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('To', 'to'), ('make', 'make'), ('possible', 'possibl'), ('compression', 'compress'), ('method', 'method'), ('efficiently', 'effici'), ('compress', 'compress'), ('data', 'data'), (',', ','), ('promising', 'promis'), ('solution', 'solut'), ('apply', 'appli'), ('clustering', 'cluster'), ('method', 'method'), ('input', 'input'), ('data', 'data'), ('divide', 'divid'), ('several', 'sever'), ('different', 'differ'), ('groups', 'group'), ('com-', 'com-'), ('press', 'press'), ('input', 'input'), ('data', 'data'), ('according', 'accord'), ('clustering', 'cluster'), ('information', 'inform'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('To', 'to'), ('make', 'make'), ('possible', 'possibl'), ('compression', 'compress'), ('method', 'method'), ('efficiently', 'effici'), ('compress', 'compress'), ('data', 'data'), (',', ','), ('promising', 'promis'), ('solution', 'solut'), ('apply', 'appli'), ('clustering', 'cluster'), ('method', 'method'), ('input', 'input'), ('data', 'data'), ('divide', 'divid'), ('several', 'sever'), ('different', 'differ'), ('groups', 'group'), ('com-', 'com-'), ('press', 'press'), ('input', 'input'), ('data', 'data'), ('according', 'accord'), ('clustering', 'cluster'), ('information', 'inform'), ('.', '.')]

>> Lemmatization: 
 [('To', 'To'), ('make', 'make'), ('possible', 'possible'), ('compression', 'compression'), ('method', 'method'), ('efficiently', 'efficiently'), ('compress', 'compress'), ('data', 'data'), (',', ','), ('promising', 'promising'), ('solution', 'solution'), ('apply', 'apply'), ('clustering', 'clustering'), ('method', 'method'), ('input', 'input'), ('data', 'data'), ('divide', 'divide'), ('several', 'several'), ('different', 'different'), ('groups', 'group'), ('com-', 'com-'), ('press', 'press'), ('input', 'input'), ('data', 'data'), ('according', 'according'), ('clustering', 'clustering'), ('information', 'information'), ('.', '.')]


------------------- Sentence 7 -------------------

The compression method

>> Tokens are: 
 ['The', 'compression', 'method']

>> Bigrams are: 
 [('The', 'compression'), ('compression', 'method')]

>> Trigrams are: 
 [('The', 'compression', 'method')]

>> POS Tags are: 
 [('The', 'DT'), ('compression', 'NN'), ('method', 'NN')]

>> Noun Phrases are: 
 ['The compression method']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('compression', 'compress'), ('method', 'method')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('compression', 'compress'), ('method', 'method')]

>> Lemmatization: 
 [('The', 'The'), ('compression', 'compression'), ('method', 'method')]



========================================== PARAGRAPH 183 ===========================================

Sensor Processing Communication Storage 

------------------- Sentence 1 -------------------

Sensor Processing Communication Storage

>> Tokens are: 
 ['Sensor', 'Processing', 'Communication', 'Storage']

>> Bigrams are: 
 [('Sensor', 'Processing'), ('Processing', 'Communication'), ('Communication', 'Storage')]

>> Trigrams are: 
 [('Sensor', 'Processing', 'Communication'), ('Processing', 'Communication', 'Storage')]

>> POS Tags are: 
 [('Sensor', 'NNP'), ('Processing', 'NNP'), ('Communication', 'NNP'), ('Storage', 'NN')]

>> Noun Phrases are: 
 ['Sensor Processing Communication Storage']

>> Named Entities are: 
 [('GPE', 'Sensor')] 

>> Stemming using Porter Stemmer: 
 [('Sensor', 'sensor'), ('Processing', 'process'), ('Communication', 'commun'), ('Storage', 'storag')]

>> Stemming using Snowball Stemmer: 
 [('Sensor', 'sensor'), ('Processing', 'process'), ('Communication', 'communic'), ('Storage', 'storag')]

>> Lemmatization: 
 [('Sensor', 'Sensor'), ('Processing', 'Processing'), ('Communication', 'Communication'), ('Storage', 'Storage')]



========================================== PARAGRAPH 184 ===========================================

In fo 

------------------- Sentence 1 -------------------

In fo

>> Tokens are: 
 ['In', 'fo']

>> Bigrams are: 
 [('In', 'fo')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('In', 'IN'), ('fo', 'NN')]

>> Noun Phrases are: 
 ['fo']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('fo', 'fo')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('fo', 'fo')]

>> Lemmatization: 
 [('In', 'In'), ('fo', 'fo')]



========================================== PARAGRAPH 185 ===========================================

rm at 

------------------- Sentence 1 -------------------

rm at

>> Tokens are: 
 ['rm']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('rm', 'NN')]

>> Noun Phrases are: 
 ['rm']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('rm', 'rm')]

>> Stemming using Snowball Stemmer: 
 [('rm', 'rm')]

>> Lemmatization: 
 [('rm', 'rm')]



========================================== PARAGRAPH 186 ===========================================

io n 

------------------- Sentence 1 -------------------

io n

>> Tokens are: 
 ['io', 'n']

>> Bigrams are: 
 [('io', 'n')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('io', 'NN'), ('n', 'NN')]

>> Noun Phrases are: 
 ['io n']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('io', 'io'), ('n', 'n')]

>> Stemming using Snowball Stemmer: 
 [('io', 'io'), ('n', 'n')]

>> Lemmatization: 
 [('io', 'io'), ('n', 'n')]



========================================== PARAGRAPH 187 ===========================================

R aw 

------------------- Sentence 1 -------------------

R aw

>> Tokens are: 
 ['R', 'aw']

>> Bigrams are: 
 [('R', 'aw')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('R', 'NNP'), ('aw', 'NN')]

>> Noun Phrases are: 
 ['R aw']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('R', 'r'), ('aw', 'aw')]

>> Stemming using Snowball Stemmer: 
 [('R', 'r'), ('aw', 'aw')]

>> Lemmatization: 
 [('R', 'R'), ('aw', 'aw')]



========================================== PARAGRAPH 188 ===========================================

 D at 

------------------- Sentence 1 -------------------

 D at

>> Tokens are: 
 ['D']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('D', 'NN')]

>> Noun Phrases are: 
 ['D']

>> Named Entities are: 
 [('GPE', 'D')] 

>> Stemming using Porter Stemmer: 
 [('D', 'd')]

>> Stemming using Snowball Stemmer: 
 [('D', 'd')]

>> Lemmatization: 
 [('D', 'D')]



========================================== PARAGRAPH 189 ===========================================

a 

------------------- Sentence 1 -------------------

a

>> Tokens are: 
 []

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 []

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 []

>> Stemming using Snowball Stemmer: 
 []

>> Lemmatization: 
 []



========================================== PARAGRAPH 190 ===========================================

Bottleneck 

------------------- Sentence 1 -------------------

Bottleneck

>> Tokens are: 
 ['Bottleneck']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Bottleneck', 'NN')]

>> Noun Phrases are: 
 ['Bottleneck']

>> Named Entities are: 
 [('GPE', 'Bottleneck')] 

>> Stemming using Porter Stemmer: 
 [('Bottleneck', 'bottleneck')]

>> Stemming using Snowball Stemmer: 
 [('Bottleneck', 'bottleneck')]

>> Lemmatization: 
 [('Bottleneck', 'Bottleneck')]



========================================== PARAGRAPH 191 ===========================================

a The conventional sensing system. 

------------------- Sentence 1 -------------------

a The conventional sensing system.

>> Tokens are: 
 ['The', 'conventional', 'sensing', 'system', '.']

>> Bigrams are: 
 [('The', 'conventional'), ('conventional', 'sensing'), ('sensing', 'system'), ('system', '.')]

>> Trigrams are: 
 [('The', 'conventional', 'sensing'), ('conventional', 'sensing', 'system'), ('sensing', 'system', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('conventional', 'JJ'), ('sensing', 'NN'), ('system', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['The conventional sensing system']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('conventional', 'convent'), ('sensing', 'sens'), ('system', 'system'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('conventional', 'convent'), ('sensing', 'sens'), ('system', 'system'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('conventional', 'conventional'), ('sensing', 'sensing'), ('system', 'system'), ('.', '.')]



========================================== PARAGRAPH 192 ===========================================

Processing Communication Storage 

------------------- Sentence 1 -------------------

Processing Communication Storage

>> Tokens are: 
 ['Processing', 'Communication', 'Storage']

>> Bigrams are: 
 [('Processing', 'Communication'), ('Communication', 'Storage')]

>> Trigrams are: 
 [('Processing', 'Communication', 'Storage')]

>> POS Tags are: 
 [('Processing', 'VBG'), ('Communication', 'NNP'), ('Storage', 'NN')]

>> Noun Phrases are: 
 ['Communication Storage']

>> Named Entities are: 
 [('ORGANIZATION', 'Communication')] 

>> Stemming using Porter Stemmer: 
 [('Processing', 'process'), ('Communication', 'commun'), ('Storage', 'storag')]

>> Stemming using Snowball Stemmer: 
 [('Processing', 'process'), ('Communication', 'communic'), ('Storage', 'storag')]

>> Lemmatization: 
 [('Processing', 'Processing'), ('Communication', 'Communication'), ('Storage', 'Storage')]



========================================== PARAGRAPH 193 ===========================================

In fo 

------------------- Sentence 1 -------------------

In fo

>> Tokens are: 
 ['In', 'fo']

>> Bigrams are: 
 [('In', 'fo')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('In', 'IN'), ('fo', 'NN')]

>> Noun Phrases are: 
 ['fo']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('fo', 'fo')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('fo', 'fo')]

>> Lemmatization: 
 [('In', 'In'), ('fo', 'fo')]



========================================== PARAGRAPH 194 ===========================================

rm at 

------------------- Sentence 1 -------------------

rm at

>> Tokens are: 
 ['rm']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('rm', 'NN')]

>> Noun Phrases are: 
 ['rm']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('rm', 'rm')]

>> Stemming using Snowball Stemmer: 
 [('rm', 'rm')]

>> Lemmatization: 
 [('rm', 'rm')]



========================================== PARAGRAPH 195 ===========================================

io n 

------------------- Sentence 1 -------------------

io n

>> Tokens are: 
 ['io', 'n']

>> Bigrams are: 
 [('io', 'n')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('io', 'NN'), ('n', 'NN')]

>> Noun Phrases are: 
 ['io n']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('io', 'io'), ('n', 'n')]

>> Stemming using Snowball Stemmer: 
 [('io', 'io'), ('n', 'n')]

>> Lemmatization: 
 [('io', 'io'), ('n', 'n')]



========================================== PARAGRAPH 196 ===========================================

Sensor 

------------------- Sentence 1 -------------------

Sensor

>> Tokens are: 
 ['Sensor']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Sensor', 'NN')]

>> Noun Phrases are: 
 ['Sensor']

>> Named Entities are: 
 [('GPE', 'Sensor')] 

>> Stemming using Porter Stemmer: 
 [('Sensor', 'sensor')]

>> Stemming using Snowball Stemmer: 
 [('Sensor', 'sensor')]

>> Lemmatization: 
 [('Sensor', 'Sensor')]



========================================== PARAGRAPH 197 ===========================================

Sensor 

------------------- Sentence 1 -------------------

Sensor

>> Tokens are: 
 ['Sensor']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Sensor', 'NN')]

>> Noun Phrases are: 
 ['Sensor']

>> Named Entities are: 
 [('GPE', 'Sensor')] 

>> Stemming using Porter Stemmer: 
 [('Sensor', 'sensor')]

>> Stemming using Snowball Stemmer: 
 [('Sensor', 'sensor')]

>> Lemmatization: 
 [('Sensor', 'Sensor')]



========================================== PARAGRAPH 198 ===========================================

Sensor 

------------------- Sentence 1 -------------------

Sensor

>> Tokens are: 
 ['Sensor']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Sensor', 'NN')]

>> Noun Phrases are: 
 ['Sensor']

>> Named Entities are: 
 [('GPE', 'Sensor')] 

>> Stemming using Porter Stemmer: 
 [('Sensor', 'sensor')]

>> Stemming using Snowball Stemmer: 
 [('Sensor', 'sensor')]

>> Lemmatization: 
 [('Sensor', 'Sensor')]



========================================== PARAGRAPH 199 ===========================================

Sensor 

------------------- Sentence 1 -------------------

Sensor

>> Tokens are: 
 ['Sensor']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Sensor', 'NN')]

>> Noun Phrases are: 
 ['Sensor']

>> Named Entities are: 
 [('GPE', 'Sensor')] 

>> Stemming using Porter Stemmer: 
 [('Sensor', 'sensor')]

>> Stemming using Snowball Stemmer: 
 [('Sensor', 'sensor')]

>> Lemmatization: 
 [('Sensor', 'Sensor')]



========================================== PARAGRAPH 200 ===========================================

Sensor 

------------------- Sentence 1 -------------------

Sensor

>> Tokens are: 
 ['Sensor']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Sensor', 'NN')]

>> Noun Phrases are: 
 ['Sensor']

>> Named Entities are: 
 [('GPE', 'Sensor')] 

>> Stemming using Porter Stemmer: 
 [('Sensor', 'sensor')]

>> Stemming using Snowball Stemmer: 
 [('Sensor', 'sensor')]

>> Lemmatization: 
 [('Sensor', 'Sensor')]



========================================== PARAGRAPH 201 ===========================================

R aw 

------------------- Sentence 1 -------------------

R aw

>> Tokens are: 
 ['R', 'aw']

>> Bigrams are: 
 [('R', 'aw')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('R', 'NNP'), ('aw', 'NN')]

>> Noun Phrases are: 
 ['R aw']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('R', 'r'), ('aw', 'aw')]

>> Stemming using Snowball Stemmer: 
 [('R', 'r'), ('aw', 'aw')]

>> Lemmatization: 
 [('R', 'R'), ('aw', 'aw')]



========================================== PARAGRAPH 202 ===========================================

 D at 

------------------- Sentence 1 -------------------

 D at

>> Tokens are: 
 ['D']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('D', 'NN')]

>> Noun Phrases are: 
 ['D']

>> Named Entities are: 
 [('GPE', 'D')] 

>> Stemming using Porter Stemmer: 
 [('D', 'd')]

>> Stemming using Snowball Stemmer: 
 [('D', 'd')]

>> Lemmatization: 
 [('D', 'D')]



========================================== PARAGRAPH 203 ===========================================

a Bottleneck 

------------------- Sentence 1 -------------------

a Bottleneck

>> Tokens are: 
 ['Bottleneck']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Bottleneck', 'NN')]

>> Noun Phrases are: 
 ['Bottleneck']

>> Named Entities are: 
 [('GPE', 'Bottleneck')] 

>> Stemming using Porter Stemmer: 
 [('Bottleneck', 'bottleneck')]

>> Stemming using Snowball Stemmer: 
 [('Bottleneck', 'bottleneck')]

>> Lemmatization: 
 [('Bottleneck', 'Bottleneck')]



========================================== PARAGRAPH 204 ===========================================

b The sensing system for data deluge. Fig. 6 The comparison between traditional data analysis and big data analysis on wireless sensor network

------------------- Sentence 1 -------------------

b The sensing system for data deluge.

>> Tokens are: 
 ['b', 'The', 'sensing', 'system', 'data', 'deluge', '.']

>> Bigrams are: 
 [('b', 'The'), ('The', 'sensing'), ('sensing', 'system'), ('system', 'data'), ('data', 'deluge'), ('deluge', '.')]

>> Trigrams are: 
 [('b', 'The', 'sensing'), ('The', 'sensing', 'system'), ('sensing', 'system', 'data'), ('system', 'data', 'deluge'), ('data', 'deluge', '.')]

>> POS Tags are: 
 [('b', 'IN'), ('The', 'DT'), ('sensing', 'NN'), ('system', 'NN'), ('data', 'NNS'), ('deluge', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['The sensing system data deluge']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('b', 'b'), ('The', 'the'), ('sensing', 'sens'), ('system', 'system'), ('data', 'data'), ('deluge', 'delug'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('b', 'b'), ('The', 'the'), ('sensing', 'sens'), ('system', 'system'), ('data', 'data'), ('deluge', 'delug'), ('.', '.')]

>> Lemmatization: 
 [('b', 'b'), ('The', 'The'), ('sensing', 'sensing'), ('system', 'system'), ('data', 'data'), ('deluge', 'deluge'), ('.', '.')]


------------------- Sentence 2 -------------------

Fig.

>> Tokens are: 
 ['Fig', '.']

>> Bigrams are: 
 [('Fig', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Fig', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Fig']

>> Named Entities are: 
 [('GPE', 'Fig')] 

>> Stemming using Porter Stemmer: 
 [('Fig', 'fig'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Fig', 'fig'), ('.', '.')]

>> Lemmatization: 
 [('Fig', 'Fig'), ('.', '.')]


------------------- Sentence 3 -------------------

6 The comparison between traditional data analysis and big data analysis on wireless sensor network

>> Tokens are: 
 ['6', 'The', 'comparison', 'traditional', 'data', 'analysis', 'big', 'data', 'analysis', 'wireless', 'sensor', 'network']

>> Bigrams are: 
 [('6', 'The'), ('The', 'comparison'), ('comparison', 'traditional'), ('traditional', 'data'), ('data', 'analysis'), ('analysis', 'big'), ('big', 'data'), ('data', 'analysis'), ('analysis', 'wireless'), ('wireless', 'sensor'), ('sensor', 'network')]

>> Trigrams are: 
 [('6', 'The', 'comparison'), ('The', 'comparison', 'traditional'), ('comparison', 'traditional', 'data'), ('traditional', 'data', 'analysis'), ('data', 'analysis', 'big'), ('analysis', 'big', 'data'), ('big', 'data', 'analysis'), ('data', 'analysis', 'wireless'), ('analysis', 'wireless', 'sensor'), ('wireless', 'sensor', 'network')]

>> POS Tags are: 
 [('6', 'CD'), ('The', 'DT'), ('comparison', 'NN'), ('traditional', 'JJ'), ('data', 'NNS'), ('analysis', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('analysis', 'NN'), ('wireless', 'NN'), ('sensor', 'NN'), ('network', 'NN')]

>> Noun Phrases are: 
 ['The comparison', 'traditional data analysis', 'big data analysis wireless sensor network']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('6', '6'), ('The', 'the'), ('comparison', 'comparison'), ('traditional', 'tradit'), ('data', 'data'), ('analysis', 'analysi'), ('big', 'big'), ('data', 'data'), ('analysis', 'analysi'), ('wireless', 'wireless'), ('sensor', 'sensor'), ('network', 'network')]

>> Stemming using Snowball Stemmer: 
 [('6', '6'), ('The', 'the'), ('comparison', 'comparison'), ('traditional', 'tradit'), ('data', 'data'), ('analysis', 'analysi'), ('big', 'big'), ('data', 'data'), ('analysis', 'analysi'), ('wireless', 'wireless'), ('sensor', 'sensor'), ('network', 'network')]

>> Lemmatization: 
 [('6', '6'), ('The', 'The'), ('comparison', 'comparison'), ('traditional', 'traditional'), ('data', 'data'), ('analysis', 'analysis'), ('big', 'big'), ('data', 'data'), ('analysis', 'analysis'), ('wireless', 'wireless'), ('sensor', 'sensor'), ('network', 'network')]



========================================== PARAGRAPH 205 ===========================================

Page 12 of 32Tsai et al. Journal of Big Data  (2015) 2:21  

------------------- Sentence 1 -------------------

Page 12 of 32Tsai et al.

>> Tokens are: 
 ['Page', '12', '32Tsai', 'et', 'al', '.']

>> Bigrams are: 
 [('Page', '12'), ('12', '32Tsai'), ('32Tsai', 'et'), ('et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('Page', '12', '32Tsai'), ('12', '32Tsai', 'et'), ('32Tsai', 'et', 'al'), ('et', 'al', '.')]

>> POS Tags are: 
 [('Page', 'NN'), ('12', 'CD'), ('32Tsai', 'CD'), ('et', 'NN'), ('al', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Page', 'et al']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Page', 'page'), ('12', '12'), ('32Tsai', '32tsai'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Page', 'page'), ('12', '12'), ('32Tsai', '32tsai'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('Page', 'Page'), ('12', '12'), ('32Tsai', '32Tsai'), ('et', 'et'), ('al', 'al'), ('.', '.')]


------------------- Sentence 2 -------------------

Journal of Big Data  (2015) 2:21

>> Tokens are: 
 ['Journal', 'Big', 'Data', '(', '2015', ')', '2:21']

>> Bigrams are: 
 [('Journal', 'Big'), ('Big', 'Data'), ('Data', '('), ('(', '2015'), ('2015', ')'), (')', '2:21')]

>> Trigrams are: 
 [('Journal', 'Big', 'Data'), ('Big', 'Data', '('), ('Data', '(', '2015'), ('(', '2015', ')'), ('2015', ')', '2:21')]

>> POS Tags are: 
 [('Journal', 'NNP'), ('Big', 'NNP'), ('Data', 'NNP'), ('(', '('), ('2015', 'CD'), (')', ')'), ('2:21', 'CD')]

>> Noun Phrases are: 
 ['Journal Big Data']

>> Named Entities are: 
 [('PERSON', 'Journal')] 

>> Stemming using Porter Stemmer: 
 [('Journal', 'journal'), ('Big', 'big'), ('Data', 'data'), ('(', '('), ('2015', '2015'), (')', ')'), ('2:21', '2:21')]

>> Stemming using Snowball Stemmer: 
 [('Journal', 'journal'), ('Big', 'big'), ('Data', 'data'), ('(', '('), ('2015', '2015'), (')', ')'), ('2:21', '2:21')]

>> Lemmatization: 
 [('Journal', 'Journal'), ('Big', 'Big'), ('Data', 'Data'), ('(', '('), ('2015', '2015'), (')', ')'), ('2:21', '2:21')]



========================================== PARAGRAPH 206 ===========================================

described in [80] is one of this kind of solutions, it first clusters the input data and then  compresses these input data via the clustering results while the study [81] also used clus- tering method to improve the performance of the compression process. 

------------------- Sentence 1 -------------------

described in [80] is one of this kind of solutions, it first clusters the input data and then  compresses these input data via the clustering results while the study [81] also used clus- tering method to improve the performance of the compression process.

>> Tokens are: 
 ['described', '[', '80', ']', 'one', 'kind', 'solutions', ',', 'first', 'clusters', 'input', 'data', 'compresses', 'input', 'data', 'via', 'clustering', 'results', 'study', '[', '81', ']', 'also', 'used', 'clus-', 'tering', 'method', 'improve', 'performance', 'compression', 'process', '.']

>> Bigrams are: 
 [('described', '['), ('[', '80'), ('80', ']'), (']', 'one'), ('one', 'kind'), ('kind', 'solutions'), ('solutions', ','), (',', 'first'), ('first', 'clusters'), ('clusters', 'input'), ('input', 'data'), ('data', 'compresses'), ('compresses', 'input'), ('input', 'data'), ('data', 'via'), ('via', 'clustering'), ('clustering', 'results'), ('results', 'study'), ('study', '['), ('[', '81'), ('81', ']'), (']', 'also'), ('also', 'used'), ('used', 'clus-'), ('clus-', 'tering'), ('tering', 'method'), ('method', 'improve'), ('improve', 'performance'), ('performance', 'compression'), ('compression', 'process'), ('process', '.')]

>> Trigrams are: 
 [('described', '[', '80'), ('[', '80', ']'), ('80', ']', 'one'), (']', 'one', 'kind'), ('one', 'kind', 'solutions'), ('kind', 'solutions', ','), ('solutions', ',', 'first'), (',', 'first', 'clusters'), ('first', 'clusters', 'input'), ('clusters', 'input', 'data'), ('input', 'data', 'compresses'), ('data', 'compresses', 'input'), ('compresses', 'input', 'data'), ('input', 'data', 'via'), ('data', 'via', 'clustering'), ('via', 'clustering', 'results'), ('clustering', 'results', 'study'), ('results', 'study', '['), ('study', '[', '81'), ('[', '81', ']'), ('81', ']', 'also'), (']', 'also', 'used'), ('also', 'used', 'clus-'), ('used', 'clus-', 'tering'), ('clus-', 'tering', 'method'), ('tering', 'method', 'improve'), ('method', 'improve', 'performance'), ('improve', 'performance', 'compression'), ('performance', 'compression', 'process'), ('compression', 'process', '.')]

>> POS Tags are: 
 [('described', 'VBN'), ('[', 'JJ'), ('80', 'CD'), (']', 'JJ'), ('one', 'CD'), ('kind', 'NN'), ('solutions', 'NNS'), (',', ','), ('first', 'JJ'), ('clusters', 'NNS'), ('input', 'VBP'), ('data', 'NNS'), ('compresses', 'NNS'), ('input', 'VBP'), ('data', 'NNS'), ('via', 'IN'), ('clustering', 'VBG'), ('results', 'NNS'), ('study', 'VBD'), ('[', 'JJ'), ('81', 'CD'), (']', 'NN'), ('also', 'RB'), ('used', 'VBD'), ('clus-', 'JJ'), ('tering', 'NN'), ('method', 'NN'), ('improve', 'VB'), ('performance', 'NN'), ('compression', 'NN'), ('process', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['kind solutions', 'first clusters', 'data compresses', 'data', 'results', ']', 'clus- tering method', 'performance compression process']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('described', 'describ'), ('[', '['), ('80', '80'), (']', ']'), ('one', 'one'), ('kind', 'kind'), ('solutions', 'solut'), (',', ','), ('first', 'first'), ('clusters', 'cluster'), ('input', 'input'), ('data', 'data'), ('compresses', 'compress'), ('input', 'input'), ('data', 'data'), ('via', 'via'), ('clustering', 'cluster'), ('results', 'result'), ('study', 'studi'), ('[', '['), ('81', '81'), (']', ']'), ('also', 'also'), ('used', 'use'), ('clus-', 'clus-'), ('tering', 'tere'), ('method', 'method'), ('improve', 'improv'), ('performance', 'perform'), ('compression', 'compress'), ('process', 'process'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('described', 'describ'), ('[', '['), ('80', '80'), (']', ']'), ('one', 'one'), ('kind', 'kind'), ('solutions', 'solut'), (',', ','), ('first', 'first'), ('clusters', 'cluster'), ('input', 'input'), ('data', 'data'), ('compresses', 'compress'), ('input', 'input'), ('data', 'data'), ('via', 'via'), ('clustering', 'cluster'), ('results', 'result'), ('study', 'studi'), ('[', '['), ('81', '81'), (']', ']'), ('also', 'also'), ('used', 'use'), ('clus-', 'clus-'), ('tering', 'tere'), ('method', 'method'), ('improve', 'improv'), ('performance', 'perform'), ('compression', 'compress'), ('process', 'process'), ('.', '.')]

>> Lemmatization: 
 [('described', 'described'), ('[', '['), ('80', '80'), (']', ']'), ('one', 'one'), ('kind', 'kind'), ('solutions', 'solution'), (',', ','), ('first', 'first'), ('clusters', 'cluster'), ('input', 'input'), ('data', 'data'), ('compresses', 'compress'), ('input', 'input'), ('data', 'data'), ('via', 'via'), ('clustering', 'clustering'), ('results', 'result'), ('study', 'study'), ('[', '['), ('81', '81'), (']', ']'), ('also', 'also'), ('used', 'used'), ('clus-', 'clus-'), ('tering', 'tering'), ('method', 'method'), ('improve', 'improve'), ('performance', 'performance'), ('compression', 'compression'), ('process', 'process'), ('.', '.')]



========================================== PARAGRAPH 207 ===========================================

In summary, in addition to handling the large and fast data input, the research issues  of heterogeneous data sources, incomplete data, and noisy data may also affect the per- formance of the data analysis. The input operators will have a stronger impact on the  data analytics at the big data age than it has in the past. As a result, the design of big data  analytics needs to consider how to make these tasks (e.g.-, data clean, data sampling, data  compression) work well. 

------------------- Sentence 1 -------------------

In summary, in addition to handling the large and fast data input, the research issues  of heterogeneous data sources, incomplete data, and noisy data may also affect the per- formance of the data analysis.

>> Tokens are: 
 ['In', 'summary', ',', 'addition', 'handling', 'large', 'fast', 'data', 'input', ',', 'research', 'issues', 'heterogeneous', 'data', 'sources', ',', 'incomplete', 'data', ',', 'noisy', 'data', 'may', 'also', 'affect', 'per-', 'formance', 'data', 'analysis', '.']

>> Bigrams are: 
 [('In', 'summary'), ('summary', ','), (',', 'addition'), ('addition', 'handling'), ('handling', 'large'), ('large', 'fast'), ('fast', 'data'), ('data', 'input'), ('input', ','), (',', 'research'), ('research', 'issues'), ('issues', 'heterogeneous'), ('heterogeneous', 'data'), ('data', 'sources'), ('sources', ','), (',', 'incomplete'), ('incomplete', 'data'), ('data', ','), (',', 'noisy'), ('noisy', 'data'), ('data', 'may'), ('may', 'also'), ('also', 'affect'), ('affect', 'per-'), ('per-', 'formance'), ('formance', 'data'), ('data', 'analysis'), ('analysis', '.')]

>> Trigrams are: 
 [('In', 'summary', ','), ('summary', ',', 'addition'), (',', 'addition', 'handling'), ('addition', 'handling', 'large'), ('handling', 'large', 'fast'), ('large', 'fast', 'data'), ('fast', 'data', 'input'), ('data', 'input', ','), ('input', ',', 'research'), (',', 'research', 'issues'), ('research', 'issues', 'heterogeneous'), ('issues', 'heterogeneous', 'data'), ('heterogeneous', 'data', 'sources'), ('data', 'sources', ','), ('sources', ',', 'incomplete'), (',', 'incomplete', 'data'), ('incomplete', 'data', ','), ('data', ',', 'noisy'), (',', 'noisy', 'data'), ('noisy', 'data', 'may'), ('data', 'may', 'also'), ('may', 'also', 'affect'), ('also', 'affect', 'per-'), ('affect', 'per-', 'formance'), ('per-', 'formance', 'data'), ('formance', 'data', 'analysis'), ('data', 'analysis', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('summary', 'JJ'), (',', ','), ('addition', 'NN'), ('handling', 'VBG'), ('large', 'JJ'), ('fast', 'RB'), ('data', 'NNS'), ('input', 'NN'), (',', ','), ('research', 'NN'), ('issues', 'NNS'), ('heterogeneous', 'JJ'), ('data', 'NNS'), ('sources', 'NNS'), (',', ','), ('incomplete', 'JJ'), ('data', 'NNS'), (',', ','), ('noisy', 'JJ'), ('data', 'NN'), ('may', 'MD'), ('also', 'RB'), ('affect', 'VB'), ('per-', 'JJ'), ('formance', 'NN'), ('data', 'NNS'), ('analysis', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['addition', 'data input', 'research issues', 'heterogeneous data sources', 'incomplete data', 'noisy data', 'per- formance data analysis']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('summary', 'summari'), (',', ','), ('addition', 'addit'), ('handling', 'handl'), ('large', 'larg'), ('fast', 'fast'), ('data', 'data'), ('input', 'input'), (',', ','), ('research', 'research'), ('issues', 'issu'), ('heterogeneous', 'heterogen'), ('data', 'data'), ('sources', 'sourc'), (',', ','), ('incomplete', 'incomplet'), ('data', 'data'), (',', ','), ('noisy', 'noisi'), ('data', 'data'), ('may', 'may'), ('also', 'also'), ('affect', 'affect'), ('per-', 'per-'), ('formance', 'formanc'), ('data', 'data'), ('analysis', 'analysi'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('summary', 'summari'), (',', ','), ('addition', 'addit'), ('handling', 'handl'), ('large', 'larg'), ('fast', 'fast'), ('data', 'data'), ('input', 'input'), (',', ','), ('research', 'research'), ('issues', 'issu'), ('heterogeneous', 'heterogen'), ('data', 'data'), ('sources', 'sourc'), (',', ','), ('incomplete', 'incomplet'), ('data', 'data'), (',', ','), ('noisy', 'noisi'), ('data', 'data'), ('may', 'may'), ('also', 'also'), ('affect', 'affect'), ('per-', 'per-'), ('formance', 'formanc'), ('data', 'data'), ('analysis', 'analysi'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('summary', 'summary'), (',', ','), ('addition', 'addition'), ('handling', 'handling'), ('large', 'large'), ('fast', 'fast'), ('data', 'data'), ('input', 'input'), (',', ','), ('research', 'research'), ('issues', 'issue'), ('heterogeneous', 'heterogeneous'), ('data', 'data'), ('sources', 'source'), (',', ','), ('incomplete', 'incomplete'), ('data', 'data'), (',', ','), ('noisy', 'noisy'), ('data', 'data'), ('may', 'may'), ('also', 'also'), ('affect', 'affect'), ('per-', 'per-'), ('formance', 'formance'), ('data', 'data'), ('analysis', 'analysis'), ('.', '.')]


------------------- Sentence 2 -------------------

The input operators will have a stronger impact on the  data analytics at the big data age than it has in the past.

>> Tokens are: 
 ['The', 'input', 'operators', 'stronger', 'impact', 'data', 'analytics', 'big', 'data', 'age', 'past', '.']

>> Bigrams are: 
 [('The', 'input'), ('input', 'operators'), ('operators', 'stronger'), ('stronger', 'impact'), ('impact', 'data'), ('data', 'analytics'), ('analytics', 'big'), ('big', 'data'), ('data', 'age'), ('age', 'past'), ('past', '.')]

>> Trigrams are: 
 [('The', 'input', 'operators'), ('input', 'operators', 'stronger'), ('operators', 'stronger', 'impact'), ('stronger', 'impact', 'data'), ('impact', 'data', 'analytics'), ('data', 'analytics', 'big'), ('analytics', 'big', 'data'), ('big', 'data', 'age'), ('data', 'age', 'past'), ('age', 'past', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('input', 'NN'), ('operators', 'NNS'), ('stronger', 'JJR'), ('impact', 'NN'), ('data', 'NNS'), ('analytics', 'NNS'), ('big', 'JJ'), ('data', 'NNS'), ('age', 'NN'), ('past', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['The input operators', 'impact data analytics', 'big data age past']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('input', 'input'), ('operators', 'oper'), ('stronger', 'stronger'), ('impact', 'impact'), ('data', 'data'), ('analytics', 'analyt'), ('big', 'big'), ('data', 'data'), ('age', 'age'), ('past', 'past'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('input', 'input'), ('operators', 'oper'), ('stronger', 'stronger'), ('impact', 'impact'), ('data', 'data'), ('analytics', 'analyt'), ('big', 'big'), ('data', 'data'), ('age', 'age'), ('past', 'past'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('input', 'input'), ('operators', 'operator'), ('stronger', 'stronger'), ('impact', 'impact'), ('data', 'data'), ('analytics', 'analytics'), ('big', 'big'), ('data', 'data'), ('age', 'age'), ('past', 'past'), ('.', '.')]


------------------- Sentence 3 -------------------

As a result, the design of big data  analytics needs to consider how to make these tasks (e.g.-, data clean, data sampling, data  compression) work well.

>> Tokens are: 
 ['As', 'result', ',', 'design', 'big', 'data', 'analytics', 'needs', 'consider', 'make', 'tasks', '(', 'e.g.-', ',', 'data', 'clean', ',', 'data', 'sampling', ',', 'data', 'compression', ')', 'work', 'well', '.']

>> Bigrams are: 
 [('As', 'result'), ('result', ','), (',', 'design'), ('design', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', 'needs'), ('needs', 'consider'), ('consider', 'make'), ('make', 'tasks'), ('tasks', '('), ('(', 'e.g.-'), ('e.g.-', ','), (',', 'data'), ('data', 'clean'), ('clean', ','), (',', 'data'), ('data', 'sampling'), ('sampling', ','), (',', 'data'), ('data', 'compression'), ('compression', ')'), (')', 'work'), ('work', 'well'), ('well', '.')]

>> Trigrams are: 
 [('As', 'result', ','), ('result', ',', 'design'), (',', 'design', 'big'), ('design', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', 'needs'), ('analytics', 'needs', 'consider'), ('needs', 'consider', 'make'), ('consider', 'make', 'tasks'), ('make', 'tasks', '('), ('tasks', '(', 'e.g.-'), ('(', 'e.g.-', ','), ('e.g.-', ',', 'data'), (',', 'data', 'clean'), ('data', 'clean', ','), ('clean', ',', 'data'), (',', 'data', 'sampling'), ('data', 'sampling', ','), ('sampling', ',', 'data'), (',', 'data', 'compression'), ('data', 'compression', ')'), ('compression', ')', 'work'), (')', 'work', 'well'), ('work', 'well', '.')]

>> POS Tags are: 
 [('As', 'IN'), ('result', 'NN'), (',', ','), ('design', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('needs', 'NNS'), ('consider', 'VBP'), ('make', 'VB'), ('tasks', 'NNS'), ('(', '('), ('e.g.-', 'JJ'), (',', ','), ('data', 'NNS'), ('clean', 'VBP'), (',', ','), ('data', 'NNS'), ('sampling', 'NN'), (',', ','), ('data', 'NNS'), ('compression', 'NN'), (')', ')'), ('work', 'NN'), ('well', 'RB'), ('.', '.')]

>> Noun Phrases are: 
 ['result', 'design', 'big data analytics needs', 'tasks', 'data', 'data sampling', 'data compression', 'work']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('As', 'as'), ('result', 'result'), (',', ','), ('design', 'design'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('needs', 'need'), ('consider', 'consid'), ('make', 'make'), ('tasks', 'task'), ('(', '('), ('e.g.-', 'e.g.-'), (',', ','), ('data', 'data'), ('clean', 'clean'), (',', ','), ('data', 'data'), ('sampling', 'sampl'), (',', ','), ('data', 'data'), ('compression', 'compress'), (')', ')'), ('work', 'work'), ('well', 'well'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('As', 'as'), ('result', 'result'), (',', ','), ('design', 'design'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('needs', 'need'), ('consider', 'consid'), ('make', 'make'), ('tasks', 'task'), ('(', '('), ('e.g.-', 'e.g.-'), (',', ','), ('data', 'data'), ('clean', 'clean'), (',', ','), ('data', 'data'), ('sampling', 'sampl'), (',', ','), ('data', 'data'), ('compression', 'compress'), (')', ')'), ('work', 'work'), ('well', 'well'), ('.', '.')]

>> Lemmatization: 
 [('As', 'As'), ('result', 'result'), (',', ','), ('design', 'design'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('needs', 'need'), ('consider', 'consider'), ('make', 'make'), ('tasks', 'task'), ('(', '('), ('e.g.-', 'e.g.-'), (',', ','), ('data', 'data'), ('clean', 'clean'), (',', ','), ('data', 'data'), ('sampling', 'sampling'), (',', ','), ('data', 'data'), ('compression', 'compression'), (')', ')'), ('work', 'work'), ('well', 'well'), ('.', '.')]



========================================== PARAGRAPH 208 ===========================================

Big data analysis frameworks and platforms 

------------------- Sentence 1 -------------------

Big data analysis frameworks and platforms

>> Tokens are: 
 ['Big', 'data', 'analysis', 'frameworks', 'platforms']

>> Bigrams are: 
 [('Big', 'data'), ('data', 'analysis'), ('analysis', 'frameworks'), ('frameworks', 'platforms')]

>> Trigrams are: 
 [('Big', 'data', 'analysis'), ('data', 'analysis', 'frameworks'), ('analysis', 'frameworks', 'platforms')]

>> POS Tags are: 
 [('Big', 'NNP'), ('data', 'NNS'), ('analysis', 'NN'), ('frameworks', 'NNS'), ('platforms', 'NNS')]

>> Noun Phrases are: 
 ['Big data analysis frameworks platforms']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('analysis', 'analysi'), ('frameworks', 'framework'), ('platforms', 'platform')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('analysis', 'analysi'), ('frameworks', 'framework'), ('platforms', 'platform')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), ('analysis', 'analysis'), ('frameworks', 'framework'), ('platforms', 'platform')]



========================================== PARAGRAPH 209 ===========================================

Various solutions have been presented for the big data analytics which can be divided  [82] into (1) Processing/Compute: Hadoop [83], Nvidia CUDA [84], or Twitter Storm  [85], (2) Storage: Titan or HDFS, and (3) Analytics: MLPACK [86] or Mahout [87].  Although there exist commercial products for data analysis [83–86], most of the studies  on the traditional data analysis are focused on the design and development of efficient  and/or effective “ways” to find the useful things from the data. But when we enter the  age of big data, most of the current computer systems will not be able to handle the  whole dataset all at once; thus, how to design a good data analytics framework or plat- form3 and how to design analysis methods are both important things for the data analy- sis process. In this section, we will start with a brief introduction to data analysis  frameworks and platforms, followed by a comparison of them. 

------------------- Sentence 1 -------------------

Various solutions have been presented for the big data analytics which can be divided  [82] into (1) Processing/Compute: Hadoop [83], Nvidia CUDA [84], or Twitter Storm  [85], (2) Storage: Titan or HDFS, and (3) Analytics: MLPACK [86] or Mahout [87].

>> Tokens are: 
 ['Various', 'solutions', 'presented', 'big', 'data', 'analytics', 'divided', '[', '82', ']', '(', '1', ')', 'Processing/Compute', ':', 'Hadoop', '[', '83', ']', ',', 'Nvidia', 'CUDA', '[', '84', ']', ',', 'Twitter', 'Storm', '[', '85', ']', ',', '(', '2', ')', 'Storage', ':', 'Titan', 'HDFS', ',', '(', '3', ')', 'Analytics', ':', 'MLPACK', '[', '86', ']', 'Mahout', '[', '87', ']', '.']

>> Bigrams are: 
 [('Various', 'solutions'), ('solutions', 'presented'), ('presented', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', 'divided'), ('divided', '['), ('[', '82'), ('82', ']'), (']', '('), ('(', '1'), ('1', ')'), (')', 'Processing/Compute'), ('Processing/Compute', ':'), (':', 'Hadoop'), ('Hadoop', '['), ('[', '83'), ('83', ']'), (']', ','), (',', 'Nvidia'), ('Nvidia', 'CUDA'), ('CUDA', '['), ('[', '84'), ('84', ']'), (']', ','), (',', 'Twitter'), ('Twitter', 'Storm'), ('Storm', '['), ('[', '85'), ('85', ']'), (']', ','), (',', '('), ('(', '2'), ('2', ')'), (')', 'Storage'), ('Storage', ':'), (':', 'Titan'), ('Titan', 'HDFS'), ('HDFS', ','), (',', '('), ('(', '3'), ('3', ')'), (')', 'Analytics'), ('Analytics', ':'), (':', 'MLPACK'), ('MLPACK', '['), ('[', '86'), ('86', ']'), (']', 'Mahout'), ('Mahout', '['), ('[', '87'), ('87', ']'), (']', '.')]

>> Trigrams are: 
 [('Various', 'solutions', 'presented'), ('solutions', 'presented', 'big'), ('presented', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', 'divided'), ('analytics', 'divided', '['), ('divided', '[', '82'), ('[', '82', ']'), ('82', ']', '('), (']', '(', '1'), ('(', '1', ')'), ('1', ')', 'Processing/Compute'), (')', 'Processing/Compute', ':'), ('Processing/Compute', ':', 'Hadoop'), (':', 'Hadoop', '['), ('Hadoop', '[', '83'), ('[', '83', ']'), ('83', ']', ','), (']', ',', 'Nvidia'), (',', 'Nvidia', 'CUDA'), ('Nvidia', 'CUDA', '['), ('CUDA', '[', '84'), ('[', '84', ']'), ('84', ']', ','), (']', ',', 'Twitter'), (',', 'Twitter', 'Storm'), ('Twitter', 'Storm', '['), ('Storm', '[', '85'), ('[', '85', ']'), ('85', ']', ','), (']', ',', '('), (',', '(', '2'), ('(', '2', ')'), ('2', ')', 'Storage'), (')', 'Storage', ':'), ('Storage', ':', 'Titan'), (':', 'Titan', 'HDFS'), ('Titan', 'HDFS', ','), ('HDFS', ',', '('), (',', '(', '3'), ('(', '3', ')'), ('3', ')', 'Analytics'), (')', 'Analytics', ':'), ('Analytics', ':', 'MLPACK'), (':', 'MLPACK', '['), ('MLPACK', '[', '86'), ('[', '86', ']'), ('86', ']', 'Mahout'), (']', 'Mahout', '['), ('Mahout', '[', '87'), ('[', '87', ']'), ('87', ']', '.')]

>> POS Tags are: 
 [('Various', 'JJ'), ('solutions', 'NNS'), ('presented', 'VBD'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('divided', 'VBD'), ('[', '$'), ('82', 'CD'), (']', 'NNP'), ('(', '('), ('1', 'CD'), (')', ')'), ('Processing/Compute', 'NN'), (':', ':'), ('Hadoop', 'NNP'), ('[', 'VBZ'), ('83', 'CD'), (']', 'NN'), (',', ','), ('Nvidia', 'NNP'), ('CUDA', 'NNP'), ('[', 'VBD'), ('84', 'CD'), (']', 'NN'), (',', ','), ('Twitter', 'NNP'), ('Storm', 'NNP'), ('[', 'VBZ'), ('85', 'CD'), (']', 'NN'), (',', ','), ('(', '('), ('2', 'CD'), (')', ')'), ('Storage', 'NN'), (':', ':'), ('Titan', 'NNP'), ('HDFS', 'NNP'), (',', ','), ('(', '('), ('3', 'CD'), (')', ')'), ('Analytics', 'NNS'), (':', ':'), ('MLPACK', 'NNP'), ('[', 'VBZ'), ('86', 'CD'), (']', 'NN'), ('Mahout', 'NNP'), ('[', 'VBZ'), ('87', 'CD'), (']', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Various solutions', 'big data analytics', ']', 'Processing/Compute', 'Hadoop', ']', 'Nvidia CUDA', ']', 'Twitter Storm', ']', 'Storage', 'Titan HDFS', 'Analytics', 'MLPACK', '] Mahout', ']']

>> Named Entities are: 
 [('GPE', 'Various'), ('PERSON', 'Hadoop'), ('PERSON', 'Nvidia CUDA'), ('PERSON', 'Twitter Storm'), ('PERSON', 'Titan HDFS'), ('ORGANIZATION', 'MLPACK'), ('PERSON', 'Mahout')] 

>> Stemming using Porter Stemmer: 
 [('Various', 'variou'), ('solutions', 'solut'), ('presented', 'present'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('divided', 'divid'), ('[', '['), ('82', '82'), (']', ']'), ('(', '('), ('1', '1'), (')', ')'), ('Processing/Compute', 'processing/comput'), (':', ':'), ('Hadoop', 'hadoop'), ('[', '['), ('83', '83'), (']', ']'), (',', ','), ('Nvidia', 'nvidia'), ('CUDA', 'cuda'), ('[', '['), ('84', '84'), (']', ']'), (',', ','), ('Twitter', 'twitter'), ('Storm', 'storm'), ('[', '['), ('85', '85'), (']', ']'), (',', ','), ('(', '('), ('2', '2'), (')', ')'), ('Storage', 'storag'), (':', ':'), ('Titan', 'titan'), ('HDFS', 'hdf'), (',', ','), ('(', '('), ('3', '3'), (')', ')'), ('Analytics', 'analyt'), (':', ':'), ('MLPACK', 'mlpack'), ('[', '['), ('86', '86'), (']', ']'), ('Mahout', 'mahout'), ('[', '['), ('87', '87'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Various', 'various'), ('solutions', 'solut'), ('presented', 'present'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('divided', 'divid'), ('[', '['), ('82', '82'), (']', ']'), ('(', '('), ('1', '1'), (')', ')'), ('Processing/Compute', 'processing/comput'), (':', ':'), ('Hadoop', 'hadoop'), ('[', '['), ('83', '83'), (']', ']'), (',', ','), ('Nvidia', 'nvidia'), ('CUDA', 'cuda'), ('[', '['), ('84', '84'), (']', ']'), (',', ','), ('Twitter', 'twitter'), ('Storm', 'storm'), ('[', '['), ('85', '85'), (']', ']'), (',', ','), ('(', '('), ('2', '2'), (')', ')'), ('Storage', 'storag'), (':', ':'), ('Titan', 'titan'), ('HDFS', 'hdfs'), (',', ','), ('(', '('), ('3', '3'), (')', ')'), ('Analytics', 'analyt'), (':', ':'), ('MLPACK', 'mlpack'), ('[', '['), ('86', '86'), (']', ']'), ('Mahout', 'mahout'), ('[', '['), ('87', '87'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('Various', 'Various'), ('solutions', 'solution'), ('presented', 'presented'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('divided', 'divided'), ('[', '['), ('82', '82'), (']', ']'), ('(', '('), ('1', '1'), (')', ')'), ('Processing/Compute', 'Processing/Compute'), (':', ':'), ('Hadoop', 'Hadoop'), ('[', '['), ('83', '83'), (']', ']'), (',', ','), ('Nvidia', 'Nvidia'), ('CUDA', 'CUDA'), ('[', '['), ('84', '84'), (']', ']'), (',', ','), ('Twitter', 'Twitter'), ('Storm', 'Storm'), ('[', '['), ('85', '85'), (']', ']'), (',', ','), ('(', '('), ('2', '2'), (')', ')'), ('Storage', 'Storage'), (':', ':'), ('Titan', 'Titan'), ('HDFS', 'HDFS'), (',', ','), ('(', '('), ('3', '3'), (')', ')'), ('Analytics', 'Analytics'), (':', ':'), ('MLPACK', 'MLPACK'), ('[', '['), ('86', '86'), (']', ']'), ('Mahout', 'Mahout'), ('[', '['), ('87', '87'), (']', ']'), ('.', '.')]


------------------- Sentence 2 -------------------

Although there exist commercial products for data analysis [83–86], most of the studies  on the traditional data analysis are focused on the design and development of efficient  and/or effective “ways” to find the useful things from the data.

>> Tokens are: 
 ['Although', 'exist', 'commercial', 'products', 'data', 'analysis', '[', '83–86', ']', ',', 'studies', 'traditional', 'data', 'analysis', 'focused', 'design', 'development', 'efficient', 'and/or', 'effective', '“', 'ways', '”', 'find', 'useful', 'things', 'data', '.']

>> Bigrams are: 
 [('Although', 'exist'), ('exist', 'commercial'), ('commercial', 'products'), ('products', 'data'), ('data', 'analysis'), ('analysis', '['), ('[', '83–86'), ('83–86', ']'), (']', ','), (',', 'studies'), ('studies', 'traditional'), ('traditional', 'data'), ('data', 'analysis'), ('analysis', 'focused'), ('focused', 'design'), ('design', 'development'), ('development', 'efficient'), ('efficient', 'and/or'), ('and/or', 'effective'), ('effective', '“'), ('“', 'ways'), ('ways', '”'), ('”', 'find'), ('find', 'useful'), ('useful', 'things'), ('things', 'data'), ('data', '.')]

>> Trigrams are: 
 [('Although', 'exist', 'commercial'), ('exist', 'commercial', 'products'), ('commercial', 'products', 'data'), ('products', 'data', 'analysis'), ('data', 'analysis', '['), ('analysis', '[', '83–86'), ('[', '83–86', ']'), ('83–86', ']', ','), (']', ',', 'studies'), (',', 'studies', 'traditional'), ('studies', 'traditional', 'data'), ('traditional', 'data', 'analysis'), ('data', 'analysis', 'focused'), ('analysis', 'focused', 'design'), ('focused', 'design', 'development'), ('design', 'development', 'efficient'), ('development', 'efficient', 'and/or'), ('efficient', 'and/or', 'effective'), ('and/or', 'effective', '“'), ('effective', '“', 'ways'), ('“', 'ways', '”'), ('ways', '”', 'find'), ('”', 'find', 'useful'), ('find', 'useful', 'things'), ('useful', 'things', 'data'), ('things', 'data', '.')]

>> POS Tags are: 
 [('Although', 'IN'), ('exist', 'JJ'), ('commercial', 'JJ'), ('products', 'NNS'), ('data', 'NNS'), ('analysis', 'NN'), ('[', 'VBP'), ('83–86', 'CD'), (']', 'NN'), (',', ','), ('studies', 'NNS'), ('traditional', 'JJ'), ('data', 'NNS'), ('analysis', 'NN'), ('focused', 'VBD'), ('design', 'NN'), ('development', 'NN'), ('efficient', 'JJ'), ('and/or', 'RB'), ('effective', 'JJ'), ('“', 'NNP'), ('ways', 'NNS'), ('”', 'VBP'), ('find', 'VBP'), ('useful', 'JJ'), ('things', 'NNS'), ('data', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['exist commercial products data analysis', ']', 'studies', 'traditional data analysis', 'design development', 'effective “ ways', 'useful things data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Although', 'although'), ('exist', 'exist'), ('commercial', 'commerci'), ('products', 'product'), ('data', 'data'), ('analysis', 'analysi'), ('[', '['), ('83–86', '83–86'), (']', ']'), (',', ','), ('studies', 'studi'), ('traditional', 'tradit'), ('data', 'data'), ('analysis', 'analysi'), ('focused', 'focus'), ('design', 'design'), ('development', 'develop'), ('efficient', 'effici'), ('and/or', 'and/or'), ('effective', 'effect'), ('“', '“'), ('ways', 'way'), ('”', '”'), ('find', 'find'), ('useful', 'use'), ('things', 'thing'), ('data', 'data'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Although', 'although'), ('exist', 'exist'), ('commercial', 'commerci'), ('products', 'product'), ('data', 'data'), ('analysis', 'analysi'), ('[', '['), ('83–86', '83–86'), (']', ']'), (',', ','), ('studies', 'studi'), ('traditional', 'tradit'), ('data', 'data'), ('analysis', 'analysi'), ('focused', 'focus'), ('design', 'design'), ('development', 'develop'), ('efficient', 'effici'), ('and/or', 'and/or'), ('effective', 'effect'), ('“', '“'), ('ways', 'way'), ('”', '”'), ('find', 'find'), ('useful', 'use'), ('things', 'thing'), ('data', 'data'), ('.', '.')]

>> Lemmatization: 
 [('Although', 'Although'), ('exist', 'exist'), ('commercial', 'commercial'), ('products', 'product'), ('data', 'data'), ('analysis', 'analysis'), ('[', '['), ('83–86', '83–86'), (']', ']'), (',', ','), ('studies', 'study'), ('traditional', 'traditional'), ('data', 'data'), ('analysis', 'analysis'), ('focused', 'focused'), ('design', 'design'), ('development', 'development'), ('efficient', 'efficient'), ('and/or', 'and/or'), ('effective', 'effective'), ('“', '“'), ('ways', 'way'), ('”', '”'), ('find', 'find'), ('useful', 'useful'), ('things', 'thing'), ('data', 'data'), ('.', '.')]


------------------- Sentence 3 -------------------

But when we enter the  age of big data, most of the current computer systems will not be able to handle the  whole dataset all at once; thus, how to design a good data analytics framework or plat- form3 and how to design analysis methods are both important things for the data analy- sis process.

>> Tokens are: 
 ['But', 'enter', 'age', 'big', 'data', ',', 'current', 'computer', 'systems', 'able', 'handle', 'whole', 'dataset', ';', 'thus', ',', 'design', 'good', 'data', 'analytics', 'framework', 'plat-', 'form3', 'design', 'analysis', 'methods', 'important', 'things', 'data', 'analy-', 'sis', 'process', '.']

>> Bigrams are: 
 [('But', 'enter'), ('enter', 'age'), ('age', 'big'), ('big', 'data'), ('data', ','), (',', 'current'), ('current', 'computer'), ('computer', 'systems'), ('systems', 'able'), ('able', 'handle'), ('handle', 'whole'), ('whole', 'dataset'), ('dataset', ';'), (';', 'thus'), ('thus', ','), (',', 'design'), ('design', 'good'), ('good', 'data'), ('data', 'analytics'), ('analytics', 'framework'), ('framework', 'plat-'), ('plat-', 'form3'), ('form3', 'design'), ('design', 'analysis'), ('analysis', 'methods'), ('methods', 'important'), ('important', 'things'), ('things', 'data'), ('data', 'analy-'), ('analy-', 'sis'), ('sis', 'process'), ('process', '.')]

>> Trigrams are: 
 [('But', 'enter', 'age'), ('enter', 'age', 'big'), ('age', 'big', 'data'), ('big', 'data', ','), ('data', ',', 'current'), (',', 'current', 'computer'), ('current', 'computer', 'systems'), ('computer', 'systems', 'able'), ('systems', 'able', 'handle'), ('able', 'handle', 'whole'), ('handle', 'whole', 'dataset'), ('whole', 'dataset', ';'), ('dataset', ';', 'thus'), (';', 'thus', ','), ('thus', ',', 'design'), (',', 'design', 'good'), ('design', 'good', 'data'), ('good', 'data', 'analytics'), ('data', 'analytics', 'framework'), ('analytics', 'framework', 'plat-'), ('framework', 'plat-', 'form3'), ('plat-', 'form3', 'design'), ('form3', 'design', 'analysis'), ('design', 'analysis', 'methods'), ('analysis', 'methods', 'important'), ('methods', 'important', 'things'), ('important', 'things', 'data'), ('things', 'data', 'analy-'), ('data', 'analy-', 'sis'), ('analy-', 'sis', 'process'), ('sis', 'process', '.')]

>> POS Tags are: 
 [('But', 'CC'), ('enter', 'JJ'), ('age', 'NN'), ('big', 'JJ'), ('data', 'NNS'), (',', ','), ('current', 'JJ'), ('computer', 'NN'), ('systems', 'NNS'), ('able', 'JJ'), ('handle', 'JJ'), ('whole', 'JJ'), ('dataset', 'NN'), (';', ':'), ('thus', 'RB'), (',', ','), ('design', 'NN'), ('good', 'JJ'), ('data', 'NN'), ('analytics', 'NNS'), ('framework', 'VBP'), ('plat-', 'JJ'), ('form3', 'NN'), ('design', 'NN'), ('analysis', 'NN'), ('methods', 'NNS'), ('important', 'JJ'), ('things', 'NNS'), ('data', 'NNS'), ('analy-', 'JJ'), ('sis', 'NN'), ('process', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['enter age', 'big data', 'current computer systems', 'able handle whole dataset', 'design', 'good data analytics', 'plat- form3 design analysis methods', 'important things data', 'analy- sis process']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('But', 'but'), ('enter', 'enter'), ('age', 'age'), ('big', 'big'), ('data', 'data'), (',', ','), ('current', 'current'), ('computer', 'comput'), ('systems', 'system'), ('able', 'abl'), ('handle', 'handl'), ('whole', 'whole'), ('dataset', 'dataset'), (';', ';'), ('thus', 'thu'), (',', ','), ('design', 'design'), ('good', 'good'), ('data', 'data'), ('analytics', 'analyt'), ('framework', 'framework'), ('plat-', 'plat-'), ('form3', 'form3'), ('design', 'design'), ('analysis', 'analysi'), ('methods', 'method'), ('important', 'import'), ('things', 'thing'), ('data', 'data'), ('analy-', 'analy-'), ('sis', 'si'), ('process', 'process'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('But', 'but'), ('enter', 'enter'), ('age', 'age'), ('big', 'big'), ('data', 'data'), (',', ','), ('current', 'current'), ('computer', 'comput'), ('systems', 'system'), ('able', 'abl'), ('handle', 'handl'), ('whole', 'whole'), ('dataset', 'dataset'), (';', ';'), ('thus', 'thus'), (',', ','), ('design', 'design'), ('good', 'good'), ('data', 'data'), ('analytics', 'analyt'), ('framework', 'framework'), ('plat-', 'plat-'), ('form3', 'form3'), ('design', 'design'), ('analysis', 'analysi'), ('methods', 'method'), ('important', 'import'), ('things', 'thing'), ('data', 'data'), ('analy-', 'analy-'), ('sis', 'sis'), ('process', 'process'), ('.', '.')]

>> Lemmatization: 
 [('But', 'But'), ('enter', 'enter'), ('age', 'age'), ('big', 'big'), ('data', 'data'), (',', ','), ('current', 'current'), ('computer', 'computer'), ('systems', 'system'), ('able', 'able'), ('handle', 'handle'), ('whole', 'whole'), ('dataset', 'dataset'), (';', ';'), ('thus', 'thus'), (',', ','), ('design', 'design'), ('good', 'good'), ('data', 'data'), ('analytics', 'analytics'), ('framework', 'framework'), ('plat-', 'plat-'), ('form3', 'form3'), ('design', 'design'), ('analysis', 'analysis'), ('methods', 'method'), ('important', 'important'), ('things', 'thing'), ('data', 'data'), ('analy-', 'analy-'), ('sis', 'si'), ('process', 'process'), ('.', '.')]


------------------- Sentence 4 -------------------

In this section, we will start with a brief introduction to data analysis  frameworks and platforms, followed by a comparison of them.

>> Tokens are: 
 ['In', 'section', ',', 'start', 'brief', 'introduction', 'data', 'analysis', 'frameworks', 'platforms', ',', 'followed', 'comparison', '.']

>> Bigrams are: 
 [('In', 'section'), ('section', ','), (',', 'start'), ('start', 'brief'), ('brief', 'introduction'), ('introduction', 'data'), ('data', 'analysis'), ('analysis', 'frameworks'), ('frameworks', 'platforms'), ('platforms', ','), (',', 'followed'), ('followed', 'comparison'), ('comparison', '.')]

>> Trigrams are: 
 [('In', 'section', ','), ('section', ',', 'start'), (',', 'start', 'brief'), ('start', 'brief', 'introduction'), ('brief', 'introduction', 'data'), ('introduction', 'data', 'analysis'), ('data', 'analysis', 'frameworks'), ('analysis', 'frameworks', 'platforms'), ('frameworks', 'platforms', ','), ('platforms', ',', 'followed'), (',', 'followed', 'comparison'), ('followed', 'comparison', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('section', 'NN'), (',', ','), ('start', 'VBP'), ('brief', 'JJ'), ('introduction', 'NN'), ('data', 'NNS'), ('analysis', 'NN'), ('frameworks', 'NN'), ('platforms', 'NNS'), (',', ','), ('followed', 'VBD'), ('comparison', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['section', 'brief introduction data analysis frameworks platforms', 'comparison']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('section', 'section'), (',', ','), ('start', 'start'), ('brief', 'brief'), ('introduction', 'introduct'), ('data', 'data'), ('analysis', 'analysi'), ('frameworks', 'framework'), ('platforms', 'platform'), (',', ','), ('followed', 'follow'), ('comparison', 'comparison'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('section', 'section'), (',', ','), ('start', 'start'), ('brief', 'brief'), ('introduction', 'introduct'), ('data', 'data'), ('analysis', 'analysi'), ('frameworks', 'framework'), ('platforms', 'platform'), (',', ','), ('followed', 'follow'), ('comparison', 'comparison'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('section', 'section'), (',', ','), ('start', 'start'), ('brief', 'brief'), ('introduction', 'introduction'), ('data', 'data'), ('analysis', 'analysis'), ('frameworks', 'framework'), ('platforms', 'platform'), (',', ','), ('followed', 'followed'), ('comparison', 'comparison'), ('.', '.')]



========================================== PARAGRAPH 210 ===========================================

Researches in frameworks and platforms 

------------------- Sentence 1 -------------------

Researches in frameworks and platforms

>> Tokens are: 
 ['Researches', 'frameworks', 'platforms']

>> Bigrams are: 
 [('Researches', 'frameworks'), ('frameworks', 'platforms')]

>> Trigrams are: 
 [('Researches', 'frameworks', 'platforms')]

>> POS Tags are: 
 [('Researches', 'NNP'), ('frameworks', 'NNS'), ('platforms', 'NNS')]

>> Noun Phrases are: 
 ['Researches frameworks platforms']

>> Named Entities are: 
 [('GPE', 'Researches')] 

>> Stemming using Porter Stemmer: 
 [('Researches', 'research'), ('frameworks', 'framework'), ('platforms', 'platform')]

>> Stemming using Snowball Stemmer: 
 [('Researches', 'research'), ('frameworks', 'framework'), ('platforms', 'platform')]

>> Lemmatization: 
 [('Researches', 'Researches'), ('frameworks', 'framework'), ('platforms', 'platform')]



========================================== PARAGRAPH 211 ===========================================

To date, we can easily find tools and platforms presented by well-known organizations.  The cloud computing technologies are widely used on these platforms and frameworks  to satisfy the large demands of computing power and storage. As shown in Fig. 7, most of  the works on KDD for big data can be moved to cloud system to speed up the response  time or to increase the memory space. With the advance of these works, handling and  analyzing big data within a reasonable time has become not so far away. Since the foun- dation functions to handle and manage the big data were developed gradually; thus, the  data scientists nowadays do not have to take care of everything, from the raw data gath- ering to data analysis, by themselves if they use the existing platforms or technologies  to handle and manage the data. The data scientists nowadays can pay more attention to  finding out the useful information from the data even thought this task is typically like  looking for a needle in a haystack. That is why several recent studies tried to present  efficient and effective framework to analyze the big data, especially on find out the useful  things. 

------------------- Sentence 1 -------------------

To date, we can easily find tools and platforms presented by well-known organizations.

>> Tokens are: 
 ['To', 'date', ',', 'easily', 'find', 'tools', 'platforms', 'presented', 'well-known', 'organizations', '.']

>> Bigrams are: 
 [('To', 'date'), ('date', ','), (',', 'easily'), ('easily', 'find'), ('find', 'tools'), ('tools', 'platforms'), ('platforms', 'presented'), ('presented', 'well-known'), ('well-known', 'organizations'), ('organizations', '.')]

>> Trigrams are: 
 [('To', 'date', ','), ('date', ',', 'easily'), (',', 'easily', 'find'), ('easily', 'find', 'tools'), ('find', 'tools', 'platforms'), ('tools', 'platforms', 'presented'), ('platforms', 'presented', 'well-known'), ('presented', 'well-known', 'organizations'), ('well-known', 'organizations', '.')]

>> POS Tags are: 
 [('To', 'TO'), ('date', 'NN'), (',', ','), ('easily', 'RB'), ('find', 'VB'), ('tools', 'JJ'), ('platforms', 'NNS'), ('presented', 'VBD'), ('well-known', 'JJ'), ('organizations', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['date', 'tools platforms', 'well-known organizations']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('To', 'to'), ('date', 'date'), (',', ','), ('easily', 'easili'), ('find', 'find'), ('tools', 'tool'), ('platforms', 'platform'), ('presented', 'present'), ('well-known', 'well-known'), ('organizations', 'organ'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('To', 'to'), ('date', 'date'), (',', ','), ('easily', 'easili'), ('find', 'find'), ('tools', 'tool'), ('platforms', 'platform'), ('presented', 'present'), ('well-known', 'well-known'), ('organizations', 'organ'), ('.', '.')]

>> Lemmatization: 
 [('To', 'To'), ('date', 'date'), (',', ','), ('easily', 'easily'), ('find', 'find'), ('tools', 'tool'), ('platforms', 'platform'), ('presented', 'presented'), ('well-known', 'well-known'), ('organizations', 'organization'), ('.', '.')]


------------------- Sentence 2 -------------------

The cloud computing technologies are widely used on these platforms and frameworks  to satisfy the large demands of computing power and storage.

>> Tokens are: 
 ['The', 'cloud', 'computing', 'technologies', 'widely', 'used', 'platforms', 'frameworks', 'satisfy', 'large', 'demands', 'computing', 'power', 'storage', '.']

>> Bigrams are: 
 [('The', 'cloud'), ('cloud', 'computing'), ('computing', 'technologies'), ('technologies', 'widely'), ('widely', 'used'), ('used', 'platforms'), ('platforms', 'frameworks'), ('frameworks', 'satisfy'), ('satisfy', 'large'), ('large', 'demands'), ('demands', 'computing'), ('computing', 'power'), ('power', 'storage'), ('storage', '.')]

>> Trigrams are: 
 [('The', 'cloud', 'computing'), ('cloud', 'computing', 'technologies'), ('computing', 'technologies', 'widely'), ('technologies', 'widely', 'used'), ('widely', 'used', 'platforms'), ('used', 'platforms', 'frameworks'), ('platforms', 'frameworks', 'satisfy'), ('frameworks', 'satisfy', 'large'), ('satisfy', 'large', 'demands'), ('large', 'demands', 'computing'), ('demands', 'computing', 'power'), ('computing', 'power', 'storage'), ('power', 'storage', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('cloud', 'NN'), ('computing', 'VBG'), ('technologies', 'NNS'), ('widely', 'RB'), ('used', 'VBD'), ('platforms', 'NNS'), ('frameworks', 'NNS'), ('satisfy', 'RB'), ('large', 'JJ'), ('demands', 'NNS'), ('computing', 'VBG'), ('power', 'NN'), ('storage', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['The cloud', 'technologies', 'platforms frameworks', 'large demands', 'power storage']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('cloud', 'cloud'), ('computing', 'comput'), ('technologies', 'technolog'), ('widely', 'wide'), ('used', 'use'), ('platforms', 'platform'), ('frameworks', 'framework'), ('satisfy', 'satisfi'), ('large', 'larg'), ('demands', 'demand'), ('computing', 'comput'), ('power', 'power'), ('storage', 'storag'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('cloud', 'cloud'), ('computing', 'comput'), ('technologies', 'technolog'), ('widely', 'wide'), ('used', 'use'), ('platforms', 'platform'), ('frameworks', 'framework'), ('satisfy', 'satisfi'), ('large', 'larg'), ('demands', 'demand'), ('computing', 'comput'), ('power', 'power'), ('storage', 'storag'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('cloud', 'cloud'), ('computing', 'computing'), ('technologies', 'technology'), ('widely', 'widely'), ('used', 'used'), ('platforms', 'platform'), ('frameworks', 'framework'), ('satisfy', 'satisfy'), ('large', 'large'), ('demands', 'demand'), ('computing', 'computing'), ('power', 'power'), ('storage', 'storage'), ('.', '.')]


------------------- Sentence 3 -------------------

As shown in Fig.

>> Tokens are: 
 ['As', 'shown', 'Fig', '.']

>> Bigrams are: 
 [('As', 'shown'), ('shown', 'Fig'), ('Fig', '.')]

>> Trigrams are: 
 [('As', 'shown', 'Fig'), ('shown', 'Fig', '.')]

>> POS Tags are: 
 [('As', 'IN'), ('shown', 'VBN'), ('Fig', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Fig']

>> Named Entities are: 
 [('PERSON', 'Fig')] 

>> Stemming using Porter Stemmer: 
 [('As', 'as'), ('shown', 'shown'), ('Fig', 'fig'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('As', 'as'), ('shown', 'shown'), ('Fig', 'fig'), ('.', '.')]

>> Lemmatization: 
 [('As', 'As'), ('shown', 'shown'), ('Fig', 'Fig'), ('.', '.')]


------------------- Sentence 4 -------------------

7, most of  the works on KDD for big data can be moved to cloud system to speed up the response  time or to increase the memory space.

>> Tokens are: 
 ['7', ',', 'works', 'KDD', 'big', 'data', 'moved', 'cloud', 'system', 'speed', 'response', 'time', 'increase', 'memory', 'space', '.']

>> Bigrams are: 
 [('7', ','), (',', 'works'), ('works', 'KDD'), ('KDD', 'big'), ('big', 'data'), ('data', 'moved'), ('moved', 'cloud'), ('cloud', 'system'), ('system', 'speed'), ('speed', 'response'), ('response', 'time'), ('time', 'increase'), ('increase', 'memory'), ('memory', 'space'), ('space', '.')]

>> Trigrams are: 
 [('7', ',', 'works'), (',', 'works', 'KDD'), ('works', 'KDD', 'big'), ('KDD', 'big', 'data'), ('big', 'data', 'moved'), ('data', 'moved', 'cloud'), ('moved', 'cloud', 'system'), ('cloud', 'system', 'speed'), ('system', 'speed', 'response'), ('speed', 'response', 'time'), ('response', 'time', 'increase'), ('time', 'increase', 'memory'), ('increase', 'memory', 'space'), ('memory', 'space', '.')]

>> POS Tags are: 
 [('7', 'CD'), (',', ','), ('works', 'VBZ'), ('KDD', 'NNP'), ('big', 'JJ'), ('data', 'NNS'), ('moved', 'VBD'), ('cloud', 'JJ'), ('system', 'NN'), ('speed', 'NN'), ('response', 'NN'), ('time', 'NN'), ('increase', 'NN'), ('memory', 'NN'), ('space', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['KDD', 'big data', 'cloud system speed response time increase memory space']

>> Named Entities are: 
 [('ORGANIZATION', 'KDD')] 

>> Stemming using Porter Stemmer: 
 [('7', '7'), (',', ','), ('works', 'work'), ('KDD', 'kdd'), ('big', 'big'), ('data', 'data'), ('moved', 'move'), ('cloud', 'cloud'), ('system', 'system'), ('speed', 'speed'), ('response', 'respons'), ('time', 'time'), ('increase', 'increas'), ('memory', 'memori'), ('space', 'space'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('7', '7'), (',', ','), ('works', 'work'), ('KDD', 'kdd'), ('big', 'big'), ('data', 'data'), ('moved', 'move'), ('cloud', 'cloud'), ('system', 'system'), ('speed', 'speed'), ('response', 'respons'), ('time', 'time'), ('increase', 'increas'), ('memory', 'memori'), ('space', 'space'), ('.', '.')]

>> Lemmatization: 
 [('7', '7'), (',', ','), ('works', 'work'), ('KDD', 'KDD'), ('big', 'big'), ('data', 'data'), ('moved', 'moved'), ('cloud', 'cloud'), ('system', 'system'), ('speed', 'speed'), ('response', 'response'), ('time', 'time'), ('increase', 'increase'), ('memory', 'memory'), ('space', 'space'), ('.', '.')]


------------------- Sentence 5 -------------------

With the advance of these works, handling and  analyzing big data within a reasonable time has become not so far away.

>> Tokens are: 
 ['With', 'advance', 'works', ',', 'handling', 'analyzing', 'big', 'data', 'within', 'reasonable', 'time', 'become', 'far', 'away', '.']

>> Bigrams are: 
 [('With', 'advance'), ('advance', 'works'), ('works', ','), (',', 'handling'), ('handling', 'analyzing'), ('analyzing', 'big'), ('big', 'data'), ('data', 'within'), ('within', 'reasonable'), ('reasonable', 'time'), ('time', 'become'), ('become', 'far'), ('far', 'away'), ('away', '.')]

>> Trigrams are: 
 [('With', 'advance', 'works'), ('advance', 'works', ','), ('works', ',', 'handling'), (',', 'handling', 'analyzing'), ('handling', 'analyzing', 'big'), ('analyzing', 'big', 'data'), ('big', 'data', 'within'), ('data', 'within', 'reasonable'), ('within', 'reasonable', 'time'), ('reasonable', 'time', 'become'), ('time', 'become', 'far'), ('become', 'far', 'away'), ('far', 'away', '.')]

>> POS Tags are: 
 [('With', 'IN'), ('advance', 'NN'), ('works', 'NNS'), (',', ','), ('handling', 'VBG'), ('analyzing', 'VBG'), ('big', 'JJ'), ('data', 'NNS'), ('within', 'IN'), ('reasonable', 'JJ'), ('time', 'NN'), ('become', 'VB'), ('far', 'RB'), ('away', 'RB'), ('.', '.')]

>> Noun Phrases are: 
 ['advance works', 'big data', 'reasonable time']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('With', 'with'), ('advance', 'advanc'), ('works', 'work'), (',', ','), ('handling', 'handl'), ('analyzing', 'analyz'), ('big', 'big'), ('data', 'data'), ('within', 'within'), ('reasonable', 'reason'), ('time', 'time'), ('become', 'becom'), ('far', 'far'), ('away', 'away'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('With', 'with'), ('advance', 'advanc'), ('works', 'work'), (',', ','), ('handling', 'handl'), ('analyzing', 'analyz'), ('big', 'big'), ('data', 'data'), ('within', 'within'), ('reasonable', 'reason'), ('time', 'time'), ('become', 'becom'), ('far', 'far'), ('away', 'away'), ('.', '.')]

>> Lemmatization: 
 [('With', 'With'), ('advance', 'advance'), ('works', 'work'), (',', ','), ('handling', 'handling'), ('analyzing', 'analyzing'), ('big', 'big'), ('data', 'data'), ('within', 'within'), ('reasonable', 'reasonable'), ('time', 'time'), ('become', 'become'), ('far', 'far'), ('away', 'away'), ('.', '.')]


------------------- Sentence 6 -------------------

Since the foun- dation functions to handle and manage the big data were developed gradually; thus, the  data scientists nowadays do not have to take care of everything, from the raw data gath- ering to data analysis, by themselves if they use the existing platforms or technologies  to handle and manage the data.

>> Tokens are: 
 ['Since', 'foun-', 'dation', 'functions', 'handle', 'manage', 'big', 'data', 'developed', 'gradually', ';', 'thus', ',', 'data', 'scientists', 'nowadays', 'take', 'care', 'everything', ',', 'raw', 'data', 'gath-', 'ering', 'data', 'analysis', ',', 'use', 'existing', 'platforms', 'technologies', 'handle', 'manage', 'data', '.']

>> Bigrams are: 
 [('Since', 'foun-'), ('foun-', 'dation'), ('dation', 'functions'), ('functions', 'handle'), ('handle', 'manage'), ('manage', 'big'), ('big', 'data'), ('data', 'developed'), ('developed', 'gradually'), ('gradually', ';'), (';', 'thus'), ('thus', ','), (',', 'data'), ('data', 'scientists'), ('scientists', 'nowadays'), ('nowadays', 'take'), ('take', 'care'), ('care', 'everything'), ('everything', ','), (',', 'raw'), ('raw', 'data'), ('data', 'gath-'), ('gath-', 'ering'), ('ering', 'data'), ('data', 'analysis'), ('analysis', ','), (',', 'use'), ('use', 'existing'), ('existing', 'platforms'), ('platforms', 'technologies'), ('technologies', 'handle'), ('handle', 'manage'), ('manage', 'data'), ('data', '.')]

>> Trigrams are: 
 [('Since', 'foun-', 'dation'), ('foun-', 'dation', 'functions'), ('dation', 'functions', 'handle'), ('functions', 'handle', 'manage'), ('handle', 'manage', 'big'), ('manage', 'big', 'data'), ('big', 'data', 'developed'), ('data', 'developed', 'gradually'), ('developed', 'gradually', ';'), ('gradually', ';', 'thus'), (';', 'thus', ','), ('thus', ',', 'data'), (',', 'data', 'scientists'), ('data', 'scientists', 'nowadays'), ('scientists', 'nowadays', 'take'), ('nowadays', 'take', 'care'), ('take', 'care', 'everything'), ('care', 'everything', ','), ('everything', ',', 'raw'), (',', 'raw', 'data'), ('raw', 'data', 'gath-'), ('data', 'gath-', 'ering'), ('gath-', 'ering', 'data'), ('ering', 'data', 'analysis'), ('data', 'analysis', ','), ('analysis', ',', 'use'), (',', 'use', 'existing'), ('use', 'existing', 'platforms'), ('existing', 'platforms', 'technologies'), ('platforms', 'technologies', 'handle'), ('technologies', 'handle', 'manage'), ('handle', 'manage', 'data'), ('manage', 'data', '.')]

>> POS Tags are: 
 [('Since', 'IN'), ('foun-', 'JJ'), ('dation', 'NN'), ('functions', 'NNS'), ('handle', 'VBP'), ('manage', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('developed', 'VBD'), ('gradually', 'RB'), (';', ':'), ('thus', 'RB'), (',', ','), ('data', 'NNS'), ('scientists', 'NNS'), ('nowadays', 'NNS'), ('take', 'VBP'), ('care', 'NN'), ('everything', 'NN'), (',', ','), ('raw', 'JJ'), ('data', 'NNS'), ('gath-', 'NNS'), ('ering', 'VBG'), ('data', 'NNS'), ('analysis', 'NN'), (',', ','), ('use', 'NN'), ('existing', 'VBG'), ('platforms', 'NNS'), ('technologies', 'NNS'), ('handle', 'VBP'), ('manage', 'NN'), ('data', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['foun- dation functions', 'manage', 'big data', 'data scientists nowadays', 'care everything', 'raw data gath-', 'data analysis', 'use', 'platforms technologies', 'manage data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Since', 'sinc'), ('foun-', 'foun-'), ('dation', 'dation'), ('functions', 'function'), ('handle', 'handl'), ('manage', 'manag'), ('big', 'big'), ('data', 'data'), ('developed', 'develop'), ('gradually', 'gradual'), (';', ';'), ('thus', 'thu'), (',', ','), ('data', 'data'), ('scientists', 'scientist'), ('nowadays', 'nowaday'), ('take', 'take'), ('care', 'care'), ('everything', 'everyth'), (',', ','), ('raw', 'raw'), ('data', 'data'), ('gath-', 'gath-'), ('ering', 'ere'), ('data', 'data'), ('analysis', 'analysi'), (',', ','), ('use', 'use'), ('existing', 'exist'), ('platforms', 'platform'), ('technologies', 'technolog'), ('handle', 'handl'), ('manage', 'manag'), ('data', 'data'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Since', 'sinc'), ('foun-', 'foun-'), ('dation', 'dation'), ('functions', 'function'), ('handle', 'handl'), ('manage', 'manag'), ('big', 'big'), ('data', 'data'), ('developed', 'develop'), ('gradually', 'gradual'), (';', ';'), ('thus', 'thus'), (',', ','), ('data', 'data'), ('scientists', 'scientist'), ('nowadays', 'nowaday'), ('take', 'take'), ('care', 'care'), ('everything', 'everyth'), (',', ','), ('raw', 'raw'), ('data', 'data'), ('gath-', 'gath-'), ('ering', 'ere'), ('data', 'data'), ('analysis', 'analysi'), (',', ','), ('use', 'use'), ('existing', 'exist'), ('platforms', 'platform'), ('technologies', 'technolog'), ('handle', 'handl'), ('manage', 'manag'), ('data', 'data'), ('.', '.')]

>> Lemmatization: 
 [('Since', 'Since'), ('foun-', 'foun-'), ('dation', 'dation'), ('functions', 'function'), ('handle', 'handle'), ('manage', 'manage'), ('big', 'big'), ('data', 'data'), ('developed', 'developed'), ('gradually', 'gradually'), (';', ';'), ('thus', 'thus'), (',', ','), ('data', 'data'), ('scientists', 'scientist'), ('nowadays', 'nowadays'), ('take', 'take'), ('care', 'care'), ('everything', 'everything'), (',', ','), ('raw', 'raw'), ('data', 'data'), ('gath-', 'gath-'), ('ering', 'ering'), ('data', 'data'), ('analysis', 'analysis'), (',', ','), ('use', 'use'), ('existing', 'existing'), ('platforms', 'platform'), ('technologies', 'technology'), ('handle', 'handle'), ('manage', 'manage'), ('data', 'data'), ('.', '.')]


------------------- Sentence 7 -------------------

The data scientists nowadays can pay more attention to  finding out the useful information from the data even thought this task is typically like  looking for a needle in a haystack.

>> Tokens are: 
 ['The', 'data', 'scientists', 'nowadays', 'pay', 'attention', 'finding', 'useful', 'information', 'data', 'even', 'thought', 'task', 'typically', 'like', 'looking', 'needle', 'haystack', '.']

>> Bigrams are: 
 [('The', 'data'), ('data', 'scientists'), ('scientists', 'nowadays'), ('nowadays', 'pay'), ('pay', 'attention'), ('attention', 'finding'), ('finding', 'useful'), ('useful', 'information'), ('information', 'data'), ('data', 'even'), ('even', 'thought'), ('thought', 'task'), ('task', 'typically'), ('typically', 'like'), ('like', 'looking'), ('looking', 'needle'), ('needle', 'haystack'), ('haystack', '.')]

>> Trigrams are: 
 [('The', 'data', 'scientists'), ('data', 'scientists', 'nowadays'), ('scientists', 'nowadays', 'pay'), ('nowadays', 'pay', 'attention'), ('pay', 'attention', 'finding'), ('attention', 'finding', 'useful'), ('finding', 'useful', 'information'), ('useful', 'information', 'data'), ('information', 'data', 'even'), ('data', 'even', 'thought'), ('even', 'thought', 'task'), ('thought', 'task', 'typically'), ('task', 'typically', 'like'), ('typically', 'like', 'looking'), ('like', 'looking', 'needle'), ('looking', 'needle', 'haystack'), ('needle', 'haystack', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('data', 'NN'), ('scientists', 'NNS'), ('nowadays', 'VBP'), ('pay', 'VB'), ('attention', 'NN'), ('finding', 'VBG'), ('useful', 'JJ'), ('information', 'NN'), ('data', 'NNS'), ('even', 'RB'), ('thought', 'VBD'), ('task', 'NN'), ('typically', 'RB'), ('like', 'IN'), ('looking', 'VBG'), ('needle', 'JJ'), ('haystack', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['The data scientists', 'attention', 'useful information data', 'task', 'needle haystack']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('data', 'data'), ('scientists', 'scientist'), ('nowadays', 'nowaday'), ('pay', 'pay'), ('attention', 'attent'), ('finding', 'find'), ('useful', 'use'), ('information', 'inform'), ('data', 'data'), ('even', 'even'), ('thought', 'thought'), ('task', 'task'), ('typically', 'typic'), ('like', 'like'), ('looking', 'look'), ('needle', 'needl'), ('haystack', 'haystack'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('data', 'data'), ('scientists', 'scientist'), ('nowadays', 'nowaday'), ('pay', 'pay'), ('attention', 'attent'), ('finding', 'find'), ('useful', 'use'), ('information', 'inform'), ('data', 'data'), ('even', 'even'), ('thought', 'thought'), ('task', 'task'), ('typically', 'typic'), ('like', 'like'), ('looking', 'look'), ('needle', 'needl'), ('haystack', 'haystack'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('data', 'data'), ('scientists', 'scientist'), ('nowadays', 'nowadays'), ('pay', 'pay'), ('attention', 'attention'), ('finding', 'finding'), ('useful', 'useful'), ('information', 'information'), ('data', 'data'), ('even', 'even'), ('thought', 'thought'), ('task', 'task'), ('typically', 'typically'), ('like', 'like'), ('looking', 'looking'), ('needle', 'needle'), ('haystack', 'haystack'), ('.', '.')]


------------------- Sentence 8 -------------------

That is why several recent studies tried to present  efficient and effective framework to analyze the big data, especially on find out the useful  things.

>> Tokens are: 
 ['That', 'several', 'recent', 'studies', 'tried', 'present', 'efficient', 'effective', 'framework', 'analyze', 'big', 'data', ',', 'especially', 'find', 'useful', 'things', '.']

>> Bigrams are: 
 [('That', 'several'), ('several', 'recent'), ('recent', 'studies'), ('studies', 'tried'), ('tried', 'present'), ('present', 'efficient'), ('efficient', 'effective'), ('effective', 'framework'), ('framework', 'analyze'), ('analyze', 'big'), ('big', 'data'), ('data', ','), (',', 'especially'), ('especially', 'find'), ('find', 'useful'), ('useful', 'things'), ('things', '.')]

>> Trigrams are: 
 [('That', 'several', 'recent'), ('several', 'recent', 'studies'), ('recent', 'studies', 'tried'), ('studies', 'tried', 'present'), ('tried', 'present', 'efficient'), ('present', 'efficient', 'effective'), ('efficient', 'effective', 'framework'), ('effective', 'framework', 'analyze'), ('framework', 'analyze', 'big'), ('analyze', 'big', 'data'), ('big', 'data', ','), ('data', ',', 'especially'), (',', 'especially', 'find'), ('especially', 'find', 'useful'), ('find', 'useful', 'things'), ('useful', 'things', '.')]

>> POS Tags are: 
 [('That', 'DT'), ('several', 'JJ'), ('recent', 'JJ'), ('studies', 'NNS'), ('tried', 'VBD'), ('present', 'JJ'), ('efficient', 'JJ'), ('effective', 'JJ'), ('framework', 'NN'), ('analyze', 'RB'), ('big', 'JJ'), ('data', 'NNS'), (',', ','), ('especially', 'RB'), ('find', 'VBP'), ('useful', 'JJ'), ('things', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['That several recent studies', 'present efficient effective framework', 'big data', 'useful things']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('That', 'that'), ('several', 'sever'), ('recent', 'recent'), ('studies', 'studi'), ('tried', 'tri'), ('present', 'present'), ('efficient', 'effici'), ('effective', 'effect'), ('framework', 'framework'), ('analyze', 'analyz'), ('big', 'big'), ('data', 'data'), (',', ','), ('especially', 'especi'), ('find', 'find'), ('useful', 'use'), ('things', 'thing'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('That', 'that'), ('several', 'sever'), ('recent', 'recent'), ('studies', 'studi'), ('tried', 'tri'), ('present', 'present'), ('efficient', 'effici'), ('effective', 'effect'), ('framework', 'framework'), ('analyze', 'analyz'), ('big', 'big'), ('data', 'data'), (',', ','), ('especially', 'especi'), ('find', 'find'), ('useful', 'use'), ('things', 'thing'), ('.', '.')]

>> Lemmatization: 
 [('That', 'That'), ('several', 'several'), ('recent', 'recent'), ('studies', 'study'), ('tried', 'tried'), ('present', 'present'), ('efficient', 'efficient'), ('effective', 'effective'), ('framework', 'framework'), ('analyze', 'analyze'), ('big', 'big'), ('data', 'data'), (',', ','), ('especially', 'especially'), ('find', 'find'), ('useful', 'useful'), ('things', 'thing'), ('.', '.')]



========================================== PARAGRAPH 212 ===========================================

Performance-oriented From the perspective of platform performance, Huai [88]  pointed out that most of the traditional parallel processing models improve the perfor- mance of the system by using a new larger computer system to replace the old computer  system, which is usually referred to as “scale up”, as shown in Fig.  8a. But for the big  data analytics, most researches improve the performance of the system by adding more  

------------------- Sentence 1 -------------------

Performance-oriented From the perspective of platform performance, Huai [88]  pointed out that most of the traditional parallel processing models improve the perfor- mance of the system by using a new larger computer system to replace the old computer  system, which is usually referred to as “scale up”, as shown in Fig.

>> Tokens are: 
 ['Performance-oriented', 'From', 'perspective', 'platform', 'performance', ',', 'Huai', '[', '88', ']', 'pointed', 'traditional', 'parallel', 'processing', 'models', 'improve', 'perfor-', 'mance', 'system', 'using', 'new', 'larger', 'computer', 'system', 'replace', 'old', 'computer', 'system', ',', 'usually', 'referred', '“', 'scale', '”', ',', 'shown', 'Fig', '.']

>> Bigrams are: 
 [('Performance-oriented', 'From'), ('From', 'perspective'), ('perspective', 'platform'), ('platform', 'performance'), ('performance', ','), (',', 'Huai'), ('Huai', '['), ('[', '88'), ('88', ']'), (']', 'pointed'), ('pointed', 'traditional'), ('traditional', 'parallel'), ('parallel', 'processing'), ('processing', 'models'), ('models', 'improve'), ('improve', 'perfor-'), ('perfor-', 'mance'), ('mance', 'system'), ('system', 'using'), ('using', 'new'), ('new', 'larger'), ('larger', 'computer'), ('computer', 'system'), ('system', 'replace'), ('replace', 'old'), ('old', 'computer'), ('computer', 'system'), ('system', ','), (',', 'usually'), ('usually', 'referred'), ('referred', '“'), ('“', 'scale'), ('scale', '”'), ('”', ','), (',', 'shown'), ('shown', 'Fig'), ('Fig', '.')]

>> Trigrams are: 
 [('Performance-oriented', 'From', 'perspective'), ('From', 'perspective', 'platform'), ('perspective', 'platform', 'performance'), ('platform', 'performance', ','), ('performance', ',', 'Huai'), (',', 'Huai', '['), ('Huai', '[', '88'), ('[', '88', ']'), ('88', ']', 'pointed'), (']', 'pointed', 'traditional'), ('pointed', 'traditional', 'parallel'), ('traditional', 'parallel', 'processing'), ('parallel', 'processing', 'models'), ('processing', 'models', 'improve'), ('models', 'improve', 'perfor-'), ('improve', 'perfor-', 'mance'), ('perfor-', 'mance', 'system'), ('mance', 'system', 'using'), ('system', 'using', 'new'), ('using', 'new', 'larger'), ('new', 'larger', 'computer'), ('larger', 'computer', 'system'), ('computer', 'system', 'replace'), ('system', 'replace', 'old'), ('replace', 'old', 'computer'), ('old', 'computer', 'system'), ('computer', 'system', ','), ('system', ',', 'usually'), (',', 'usually', 'referred'), ('usually', 'referred', '“'), ('referred', '“', 'scale'), ('“', 'scale', '”'), ('scale', '”', ','), ('”', ',', 'shown'), (',', 'shown', 'Fig'), ('shown', 'Fig', '.')]

>> POS Tags are: 
 [('Performance-oriented', 'JJ'), ('From', 'NNP'), ('perspective', 'NN'), ('platform', 'NN'), ('performance', 'NN'), (',', ','), ('Huai', 'NNP'), ('[', 'VBZ'), ('88', 'CD'), (']', 'NN'), ('pointed', 'VBD'), ('traditional', 'JJ'), ('parallel', 'NN'), ('processing', 'NN'), ('models', 'NNS'), ('improve', 'VBP'), ('perfor-', 'JJ'), ('mance', 'NN'), ('system', 'NN'), ('using', 'VBG'), ('new', 'JJ'), ('larger', 'JJR'), ('computer', 'NN'), ('system', 'NN'), ('replace', 'VB'), ('old', 'JJ'), ('computer', 'NN'), ('system', 'NN'), (',', ','), ('usually', 'RB'), ('referred', 'VBN'), ('“', 'NNP'), ('scale', 'NN'), ('”', 'NN'), (',', ','), ('shown', 'VBN'), ('Fig', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Performance-oriented From perspective platform performance', 'Huai', ']', 'traditional parallel processing models', 'perfor- mance system', 'computer system', 'old computer system', '“ scale ”', 'Fig']

>> Named Entities are: 
 [('PERSON', 'Huai'), ('PERSON', 'Fig')] 

>> Stemming using Porter Stemmer: 
 [('Performance-oriented', 'performance-ori'), ('From', 'from'), ('perspective', 'perspect'), ('platform', 'platform'), ('performance', 'perform'), (',', ','), ('Huai', 'huai'), ('[', '['), ('88', '88'), (']', ']'), ('pointed', 'point'), ('traditional', 'tradit'), ('parallel', 'parallel'), ('processing', 'process'), ('models', 'model'), ('improve', 'improv'), ('perfor-', 'perfor-'), ('mance', 'manc'), ('system', 'system'), ('using', 'use'), ('new', 'new'), ('larger', 'larger'), ('computer', 'comput'), ('system', 'system'), ('replace', 'replac'), ('old', 'old'), ('computer', 'comput'), ('system', 'system'), (',', ','), ('usually', 'usual'), ('referred', 'refer'), ('“', '“'), ('scale', 'scale'), ('”', '”'), (',', ','), ('shown', 'shown'), ('Fig', 'fig'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Performance-oriented', 'performance-ori'), ('From', 'from'), ('perspective', 'perspect'), ('platform', 'platform'), ('performance', 'perform'), (',', ','), ('Huai', 'huai'), ('[', '['), ('88', '88'), (']', ']'), ('pointed', 'point'), ('traditional', 'tradit'), ('parallel', 'parallel'), ('processing', 'process'), ('models', 'model'), ('improve', 'improv'), ('perfor-', 'perfor-'), ('mance', 'manc'), ('system', 'system'), ('using', 'use'), ('new', 'new'), ('larger', 'larger'), ('computer', 'comput'), ('system', 'system'), ('replace', 'replac'), ('old', 'old'), ('computer', 'comput'), ('system', 'system'), (',', ','), ('usually', 'usual'), ('referred', 'refer'), ('“', '“'), ('scale', 'scale'), ('”', '”'), (',', ','), ('shown', 'shown'), ('Fig', 'fig'), ('.', '.')]

>> Lemmatization: 
 [('Performance-oriented', 'Performance-oriented'), ('From', 'From'), ('perspective', 'perspective'), ('platform', 'platform'), ('performance', 'performance'), (',', ','), ('Huai', 'Huai'), ('[', '['), ('88', '88'), (']', ']'), ('pointed', 'pointed'), ('traditional', 'traditional'), ('parallel', 'parallel'), ('processing', 'processing'), ('models', 'model'), ('improve', 'improve'), ('perfor-', 'perfor-'), ('mance', 'mance'), ('system', 'system'), ('using', 'using'), ('new', 'new'), ('larger', 'larger'), ('computer', 'computer'), ('system', 'system'), ('replace', 'replace'), ('old', 'old'), ('computer', 'computer'), ('system', 'system'), (',', ','), ('usually', 'usually'), ('referred', 'referred'), ('“', '“'), ('scale', 'scale'), ('”', '”'), (',', ','), ('shown', 'shown'), ('Fig', 'Fig'), ('.', '.')]


------------------- Sentence 2 -------------------

8a.

>> Tokens are: 
 ['8a', '.']

>> Bigrams are: 
 [('8a', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('8a', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('8a', '8a'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('8a', '8a'), ('.', '.')]

>> Lemmatization: 
 [('8a', '8a'), ('.', '.')]


------------------- Sentence 3 -------------------

But for the big  data analytics, most researches improve the performance of the system by adding more

>> Tokens are: 
 ['But', 'big', 'data', 'analytics', ',', 'researches', 'improve', 'performance', 'system', 'adding']

>> Bigrams are: 
 [('But', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', ','), (',', 'researches'), ('researches', 'improve'), ('improve', 'performance'), ('performance', 'system'), ('system', 'adding')]

>> Trigrams are: 
 [('But', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', ','), ('analytics', ',', 'researches'), (',', 'researches', 'improve'), ('researches', 'improve', 'performance'), ('improve', 'performance', 'system'), ('performance', 'system', 'adding')]

>> POS Tags are: 
 [('But', 'CC'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), (',', ','), ('researches', 'NNS'), ('improve', 'VBP'), ('performance', 'NN'), ('system', 'NN'), ('adding', 'VBG')]

>> Noun Phrases are: 
 ['big data analytics', 'researches', 'performance system']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('But', 'but'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), (',', ','), ('researches', 'research'), ('improve', 'improv'), ('performance', 'perform'), ('system', 'system'), ('adding', 'ad')]

>> Stemming using Snowball Stemmer: 
 [('But', 'but'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), (',', ','), ('researches', 'research'), ('improve', 'improv'), ('performance', 'perform'), ('system', 'system'), ('adding', 'ad')]

>> Lemmatization: 
 [('But', 'But'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), (',', ','), ('researches', 'research'), ('improve', 'improve'), ('performance', 'performance'), ('system', 'system'), ('adding', 'adding')]



========================================== PARAGRAPH 213 ===========================================

3 In this paper, the analysis framework refers to the whole system, from raw data gathering, data reformat, data analysis,  all the way to knowledge representation.

------------------- Sentence 1 -------------------

3 In this paper, the analysis framework refers to the whole system, from raw data gathering, data reformat, data analysis,  all the way to knowledge representation.

>> Tokens are: 
 ['3', 'In', 'paper', ',', 'analysis', 'framework', 'refers', 'whole', 'system', ',', 'raw', 'data', 'gathering', ',', 'data', 'reformat', ',', 'data', 'analysis', ',', 'way', 'knowledge', 'representation', '.']

>> Bigrams are: 
 [('3', 'In'), ('In', 'paper'), ('paper', ','), (',', 'analysis'), ('analysis', 'framework'), ('framework', 'refers'), ('refers', 'whole'), ('whole', 'system'), ('system', ','), (',', 'raw'), ('raw', 'data'), ('data', 'gathering'), ('gathering', ','), (',', 'data'), ('data', 'reformat'), ('reformat', ','), (',', 'data'), ('data', 'analysis'), ('analysis', ','), (',', 'way'), ('way', 'knowledge'), ('knowledge', 'representation'), ('representation', '.')]

>> Trigrams are: 
 [('3', 'In', 'paper'), ('In', 'paper', ','), ('paper', ',', 'analysis'), (',', 'analysis', 'framework'), ('analysis', 'framework', 'refers'), ('framework', 'refers', 'whole'), ('refers', 'whole', 'system'), ('whole', 'system', ','), ('system', ',', 'raw'), (',', 'raw', 'data'), ('raw', 'data', 'gathering'), ('data', 'gathering', ','), ('gathering', ',', 'data'), (',', 'data', 'reformat'), ('data', 'reformat', ','), ('reformat', ',', 'data'), (',', 'data', 'analysis'), ('data', 'analysis', ','), ('analysis', ',', 'way'), (',', 'way', 'knowledge'), ('way', 'knowledge', 'representation'), ('knowledge', 'representation', '.')]

>> POS Tags are: 
 [('3', 'CD'), ('In', 'IN'), ('paper', 'NN'), (',', ','), ('analysis', 'NN'), ('framework', 'NN'), ('refers', 'NNS'), ('whole', 'JJ'), ('system', 'NN'), (',', ','), ('raw', 'JJ'), ('data', 'NN'), ('gathering', 'NN'), (',', ','), ('data', 'NNS'), ('reformat', 'NN'), (',', ','), ('data', 'NN'), ('analysis', 'NN'), (',', ','), ('way', 'NN'), ('knowledge', 'NN'), ('representation', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['paper', 'analysis framework refers', 'whole system', 'raw data gathering', 'data reformat', 'data analysis', 'way knowledge representation']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('3', '3'), ('In', 'in'), ('paper', 'paper'), (',', ','), ('analysis', 'analysi'), ('framework', 'framework'), ('refers', 'refer'), ('whole', 'whole'), ('system', 'system'), (',', ','), ('raw', 'raw'), ('data', 'data'), ('gathering', 'gather'), (',', ','), ('data', 'data'), ('reformat', 'reformat'), (',', ','), ('data', 'data'), ('analysis', 'analysi'), (',', ','), ('way', 'way'), ('knowledge', 'knowledg'), ('representation', 'represent'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('3', '3'), ('In', 'in'), ('paper', 'paper'), (',', ','), ('analysis', 'analysi'), ('framework', 'framework'), ('refers', 'refer'), ('whole', 'whole'), ('system', 'system'), (',', ','), ('raw', 'raw'), ('data', 'data'), ('gathering', 'gather'), (',', ','), ('data', 'data'), ('reformat', 'reformat'), (',', ','), ('data', 'data'), ('analysis', 'analysi'), (',', ','), ('way', 'way'), ('knowledge', 'knowledg'), ('representation', 'represent'), ('.', '.')]

>> Lemmatization: 
 [('3', '3'), ('In', 'In'), ('paper', 'paper'), (',', ','), ('analysis', 'analysis'), ('framework', 'framework'), ('refers', 'refers'), ('whole', 'whole'), ('system', 'system'), (',', ','), ('raw', 'raw'), ('data', 'data'), ('gathering', 'gathering'), (',', ','), ('data', 'data'), ('reformat', 'reformat'), (',', ','), ('data', 'data'), ('analysis', 'analysis'), (',', ','), ('way', 'way'), ('knowledge', 'knowledge'), ('representation', 'representation'), ('.', '.')]



========================================== PARAGRAPH 214 ===========================================

Page 13 of 32Tsai et al. Journal of Big Data  (2015) 2:21  

------------------- Sentence 1 -------------------

Page 13 of 32Tsai et al.

>> Tokens are: 
 ['Page', '13', '32Tsai', 'et', 'al', '.']

>> Bigrams are: 
 [('Page', '13'), ('13', '32Tsai'), ('32Tsai', 'et'), ('et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('Page', '13', '32Tsai'), ('13', '32Tsai', 'et'), ('32Tsai', 'et', 'al'), ('et', 'al', '.')]

>> POS Tags are: 
 [('Page', 'NN'), ('13', 'CD'), ('32Tsai', 'CD'), ('et', 'NN'), ('al', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Page', 'et al']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Page', 'page'), ('13', '13'), ('32Tsai', '32tsai'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Page', 'page'), ('13', '13'), ('32Tsai', '32tsai'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('Page', 'Page'), ('13', '13'), ('32Tsai', '32Tsai'), ('et', 'et'), ('al', 'al'), ('.', '.')]


------------------- Sentence 2 -------------------

Journal of Big Data  (2015) 2:21

>> Tokens are: 
 ['Journal', 'Big', 'Data', '(', '2015', ')', '2:21']

>> Bigrams are: 
 [('Journal', 'Big'), ('Big', 'Data'), ('Data', '('), ('(', '2015'), ('2015', ')'), (')', '2:21')]

>> Trigrams are: 
 [('Journal', 'Big', 'Data'), ('Big', 'Data', '('), ('Data', '(', '2015'), ('(', '2015', ')'), ('2015', ')', '2:21')]

>> POS Tags are: 
 [('Journal', 'NNP'), ('Big', 'NNP'), ('Data', 'NNP'), ('(', '('), ('2015', 'CD'), (')', ')'), ('2:21', 'CD')]

>> Noun Phrases are: 
 ['Journal Big Data']

>> Named Entities are: 
 [('PERSON', 'Journal')] 

>> Stemming using Porter Stemmer: 
 [('Journal', 'journal'), ('Big', 'big'), ('Data', 'data'), ('(', '('), ('2015', '2015'), (')', ')'), ('2:21', '2:21')]

>> Stemming using Snowball Stemmer: 
 [('Journal', 'journal'), ('Big', 'big'), ('Data', 'data'), ('(', '('), ('2015', '2015'), (')', ')'), ('2:21', '2:21')]

>> Lemmatization: 
 [('Journal', 'Journal'), ('Big', 'Big'), ('Data', 'Data'), ('(', '('), ('2015', '2015'), (')', ')'), ('2:21', '2:21')]



========================================== PARAGRAPH 215 ===========================================

similar computer systems to make it possible for a system to handle all the tasks that  cannot be loaded or computed in a single computer system (called “scale out”), as shown  in Fig. 8b where M1, M2, and M3 represent computer systems that have different com- puting power, respectively. For the scale up based solution, the computing power of the  three systems is in the order of M3 > M2 > M1; but for the scale out based system, all  we have to do is to keep adding more similar computer systems to to a system to increase  its ability. To build a scalable and fault-tolerant manager for big data analysis, Huai et al.  [88] presented a matrix model which consists of three matrices for data set (D), concur- rent data processing operations (O), and data transformations (T), called DOT. The big  data is divided into n subsets each of which is processed by a computer node (worker)  in such a way that all the subsets are processed concurrently, and then the results from  these n computer nodes are collected and transformed to a computer node. By using this  framework, the whole data analysis framework is composed of several DOT blocks. The  system performance can be easily enhanced by adding more DOT blocks to the system. 

------------------- Sentence 1 -------------------

similar computer systems to make it possible for a system to handle all the tasks that  cannot be loaded or computed in a single computer system (called “scale out”), as shown  in Fig.

>> Tokens are: 
 ['similar', 'computer', 'systems', 'make', 'possible', 'system', 'handle', 'tasks', 'loaded', 'computed', 'single', 'computer', 'system', '(', 'called', '“', 'scale', '”', ')', ',', 'shown', 'Fig', '.']

>> Bigrams are: 
 [('similar', 'computer'), ('computer', 'systems'), ('systems', 'make'), ('make', 'possible'), ('possible', 'system'), ('system', 'handle'), ('handle', 'tasks'), ('tasks', 'loaded'), ('loaded', 'computed'), ('computed', 'single'), ('single', 'computer'), ('computer', 'system'), ('system', '('), ('(', 'called'), ('called', '“'), ('“', 'scale'), ('scale', '”'), ('”', ')'), (')', ','), (',', 'shown'), ('shown', 'Fig'), ('Fig', '.')]

>> Trigrams are: 
 [('similar', 'computer', 'systems'), ('computer', 'systems', 'make'), ('systems', 'make', 'possible'), ('make', 'possible', 'system'), ('possible', 'system', 'handle'), ('system', 'handle', 'tasks'), ('handle', 'tasks', 'loaded'), ('tasks', 'loaded', 'computed'), ('loaded', 'computed', 'single'), ('computed', 'single', 'computer'), ('single', 'computer', 'system'), ('computer', 'system', '('), ('system', '(', 'called'), ('(', 'called', '“'), ('called', '“', 'scale'), ('“', 'scale', '”'), ('scale', '”', ')'), ('”', ')', ','), (')', ',', 'shown'), (',', 'shown', 'Fig'), ('shown', 'Fig', '.')]

>> POS Tags are: 
 [('similar', 'JJ'), ('computer', 'NN'), ('systems', 'NNS'), ('make', 'VBP'), ('possible', 'JJ'), ('system', 'NN'), ('handle', 'JJ'), ('tasks', 'NNS'), ('loaded', 'VBN'), ('computed', 'VBN'), ('single', 'JJ'), ('computer', 'NN'), ('system', 'NN'), ('(', '('), ('called', 'VBN'), ('“', 'RB'), ('scale', 'JJ'), ('”', 'NN'), (')', ')'), (',', ','), ('shown', 'VBN'), ('Fig', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['similar computer systems', 'possible system', 'handle tasks', 'single computer system', 'scale ”', 'Fig']

>> Named Entities are: 
 [('PERSON', 'Fig')] 

>> Stemming using Porter Stemmer: 
 [('similar', 'similar'), ('computer', 'comput'), ('systems', 'system'), ('make', 'make'), ('possible', 'possibl'), ('system', 'system'), ('handle', 'handl'), ('tasks', 'task'), ('loaded', 'load'), ('computed', 'comput'), ('single', 'singl'), ('computer', 'comput'), ('system', 'system'), ('(', '('), ('called', 'call'), ('“', '“'), ('scale', 'scale'), ('”', '”'), (')', ')'), (',', ','), ('shown', 'shown'), ('Fig', 'fig'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('similar', 'similar'), ('computer', 'comput'), ('systems', 'system'), ('make', 'make'), ('possible', 'possibl'), ('system', 'system'), ('handle', 'handl'), ('tasks', 'task'), ('loaded', 'load'), ('computed', 'comput'), ('single', 'singl'), ('computer', 'comput'), ('system', 'system'), ('(', '('), ('called', 'call'), ('“', '“'), ('scale', 'scale'), ('”', '”'), (')', ')'), (',', ','), ('shown', 'shown'), ('Fig', 'fig'), ('.', '.')]

>> Lemmatization: 
 [('similar', 'similar'), ('computer', 'computer'), ('systems', 'system'), ('make', 'make'), ('possible', 'possible'), ('system', 'system'), ('handle', 'handle'), ('tasks', 'task'), ('loaded', 'loaded'), ('computed', 'computed'), ('single', 'single'), ('computer', 'computer'), ('system', 'system'), ('(', '('), ('called', 'called'), ('“', '“'), ('scale', 'scale'), ('”', '”'), (')', ')'), (',', ','), ('shown', 'shown'), ('Fig', 'Fig'), ('.', '.')]


------------------- Sentence 2 -------------------

8b where M1, M2, and M3 represent computer systems that have different com- puting power, respectively.

>> Tokens are: 
 ['8b', 'M1', ',', 'M2', ',', 'M3', 'represent', 'computer', 'systems', 'different', 'com-', 'puting', 'power', ',', 'respectively', '.']

>> Bigrams are: 
 [('8b', 'M1'), ('M1', ','), (',', 'M2'), ('M2', ','), (',', 'M3'), ('M3', 'represent'), ('represent', 'computer'), ('computer', 'systems'), ('systems', 'different'), ('different', 'com-'), ('com-', 'puting'), ('puting', 'power'), ('power', ','), (',', 'respectively'), ('respectively', '.')]

>> Trigrams are: 
 [('8b', 'M1', ','), ('M1', ',', 'M2'), (',', 'M2', ','), ('M2', ',', 'M3'), (',', 'M3', 'represent'), ('M3', 'represent', 'computer'), ('represent', 'computer', 'systems'), ('computer', 'systems', 'different'), ('systems', 'different', 'com-'), ('different', 'com-', 'puting'), ('com-', 'puting', 'power'), ('puting', 'power', ','), ('power', ',', 'respectively'), (',', 'respectively', '.')]

>> POS Tags are: 
 [('8b', 'CD'), ('M1', 'NNP'), (',', ','), ('M2', 'NNP'), (',', ','), ('M3', 'NNP'), ('represent', 'VBP'), ('computer', 'NN'), ('systems', 'NNS'), ('different', 'JJ'), ('com-', 'JJ'), ('puting', 'NN'), ('power', 'NN'), (',', ','), ('respectively', 'RB'), ('.', '.')]

>> Noun Phrases are: 
 ['M1', 'M2', 'M3', 'computer systems', 'different com- puting power']

>> Named Entities are: 
 [('GPE', 'M2')] 

>> Stemming using Porter Stemmer: 
 [('8b', '8b'), ('M1', 'm1'), (',', ','), ('M2', 'm2'), (',', ','), ('M3', 'm3'), ('represent', 'repres'), ('computer', 'comput'), ('systems', 'system'), ('different', 'differ'), ('com-', 'com-'), ('puting', 'pute'), ('power', 'power'), (',', ','), ('respectively', 'respect'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('8b', '8b'), ('M1', 'm1'), (',', ','), ('M2', 'm2'), (',', ','), ('M3', 'm3'), ('represent', 'repres'), ('computer', 'comput'), ('systems', 'system'), ('different', 'differ'), ('com-', 'com-'), ('puting', 'pute'), ('power', 'power'), (',', ','), ('respectively', 'respect'), ('.', '.')]

>> Lemmatization: 
 [('8b', '8b'), ('M1', 'M1'), (',', ','), ('M2', 'M2'), (',', ','), ('M3', 'M3'), ('represent', 'represent'), ('computer', 'computer'), ('systems', 'system'), ('different', 'different'), ('com-', 'com-'), ('puting', 'puting'), ('power', 'power'), (',', ','), ('respectively', 'respectively'), ('.', '.')]


------------------- Sentence 3 -------------------

For the scale up based solution, the computing power of the  three systems is in the order of M3 > M2 > M1; but for the scale out based system, all  we have to do is to keep adding more similar computer systems to to a system to increase  its ability.

>> Tokens are: 
 ['For', 'scale', 'based', 'solution', ',', 'computing', 'power', 'three', 'systems', 'order', 'M3', '>', 'M2', '>', 'M1', ';', 'scale', 'based', 'system', ',', 'keep', 'adding', 'similar', 'computer', 'systems', 'system', 'increase', 'ability', '.']

>> Bigrams are: 
 [('For', 'scale'), ('scale', 'based'), ('based', 'solution'), ('solution', ','), (',', 'computing'), ('computing', 'power'), ('power', 'three'), ('three', 'systems'), ('systems', 'order'), ('order', 'M3'), ('M3', '>'), ('>', 'M2'), ('M2', '>'), ('>', 'M1'), ('M1', ';'), (';', 'scale'), ('scale', 'based'), ('based', 'system'), ('system', ','), (',', 'keep'), ('keep', 'adding'), ('adding', 'similar'), ('similar', 'computer'), ('computer', 'systems'), ('systems', 'system'), ('system', 'increase'), ('increase', 'ability'), ('ability', '.')]

>> Trigrams are: 
 [('For', 'scale', 'based'), ('scale', 'based', 'solution'), ('based', 'solution', ','), ('solution', ',', 'computing'), (',', 'computing', 'power'), ('computing', 'power', 'three'), ('power', 'three', 'systems'), ('three', 'systems', 'order'), ('systems', 'order', 'M3'), ('order', 'M3', '>'), ('M3', '>', 'M2'), ('>', 'M2', '>'), ('M2', '>', 'M1'), ('>', 'M1', ';'), ('M1', ';', 'scale'), (';', 'scale', 'based'), ('scale', 'based', 'system'), ('based', 'system', ','), ('system', ',', 'keep'), (',', 'keep', 'adding'), ('keep', 'adding', 'similar'), ('adding', 'similar', 'computer'), ('similar', 'computer', 'systems'), ('computer', 'systems', 'system'), ('systems', 'system', 'increase'), ('system', 'increase', 'ability'), ('increase', 'ability', '.')]

>> POS Tags are: 
 [('For', 'IN'), ('scale', 'NN'), ('based', 'VBN'), ('solution', 'NN'), (',', ','), ('computing', 'VBG'), ('power', 'NN'), ('three', 'CD'), ('systems', 'NNS'), ('order', 'NN'), ('M3', 'NNP'), ('>', 'NNP'), ('M2', 'NNP'), ('>', 'NNP'), ('M1', 'NNP'), (';', ':'), ('scale', 'NN'), ('based', 'VBN'), ('system', 'NN'), (',', ','), ('keep', 'VB'), ('adding', 'VBG'), ('similar', 'JJ'), ('computer', 'NN'), ('systems', 'NNS'), ('system', 'NN'), ('increase', 'JJ'), ('ability', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['scale', 'solution', 'power', 'systems order M3 > M2 > M1', 'scale', 'system', 'similar computer systems system', 'increase ability']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('For', 'for'), ('scale', 'scale'), ('based', 'base'), ('solution', 'solut'), (',', ','), ('computing', 'comput'), ('power', 'power'), ('three', 'three'), ('systems', 'system'), ('order', 'order'), ('M3', 'm3'), ('>', '>'), ('M2', 'm2'), ('>', '>'), ('M1', 'm1'), (';', ';'), ('scale', 'scale'), ('based', 'base'), ('system', 'system'), (',', ','), ('keep', 'keep'), ('adding', 'ad'), ('similar', 'similar'), ('computer', 'comput'), ('systems', 'system'), ('system', 'system'), ('increase', 'increas'), ('ability', 'abil'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('For', 'for'), ('scale', 'scale'), ('based', 'base'), ('solution', 'solut'), (',', ','), ('computing', 'comput'), ('power', 'power'), ('three', 'three'), ('systems', 'system'), ('order', 'order'), ('M3', 'm3'), ('>', '>'), ('M2', 'm2'), ('>', '>'), ('M1', 'm1'), (';', ';'), ('scale', 'scale'), ('based', 'base'), ('system', 'system'), (',', ','), ('keep', 'keep'), ('adding', 'ad'), ('similar', 'similar'), ('computer', 'comput'), ('systems', 'system'), ('system', 'system'), ('increase', 'increas'), ('ability', 'abil'), ('.', '.')]

>> Lemmatization: 
 [('For', 'For'), ('scale', 'scale'), ('based', 'based'), ('solution', 'solution'), (',', ','), ('computing', 'computing'), ('power', 'power'), ('three', 'three'), ('systems', 'system'), ('order', 'order'), ('M3', 'M3'), ('>', '>'), ('M2', 'M2'), ('>', '>'), ('M1', 'M1'), (';', ';'), ('scale', 'scale'), ('based', 'based'), ('system', 'system'), (',', ','), ('keep', 'keep'), ('adding', 'adding'), ('similar', 'similar'), ('computer', 'computer'), ('systems', 'system'), ('system', 'system'), ('increase', 'increase'), ('ability', 'ability'), ('.', '.')]


------------------- Sentence 4 -------------------

To build a scalable and fault-tolerant manager for big data analysis, Huai et al.

>> Tokens are: 
 ['To', 'build', 'scalable', 'fault-tolerant', 'manager', 'big', 'data', 'analysis', ',', 'Huai', 'et', 'al', '.']

>> Bigrams are: 
 [('To', 'build'), ('build', 'scalable'), ('scalable', 'fault-tolerant'), ('fault-tolerant', 'manager'), ('manager', 'big'), ('big', 'data'), ('data', 'analysis'), ('analysis', ','), (',', 'Huai'), ('Huai', 'et'), ('et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('To', 'build', 'scalable'), ('build', 'scalable', 'fault-tolerant'), ('scalable', 'fault-tolerant', 'manager'), ('fault-tolerant', 'manager', 'big'), ('manager', 'big', 'data'), ('big', 'data', 'analysis'), ('data', 'analysis', ','), ('analysis', ',', 'Huai'), (',', 'Huai', 'et'), ('Huai', 'et', 'al'), ('et', 'al', '.')]

>> POS Tags are: 
 [('To', 'TO'), ('build', 'VB'), ('scalable', 'JJ'), ('fault-tolerant', 'JJ'), ('manager', 'NN'), ('big', 'JJ'), ('data', 'NN'), ('analysis', 'NN'), (',', ','), ('Huai', 'NNP'), ('et', 'CC'), ('al', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['scalable fault-tolerant manager', 'big data analysis', 'Huai', 'al']

>> Named Entities are: 
 [('PERSON', 'Huai')] 

>> Stemming using Porter Stemmer: 
 [('To', 'to'), ('build', 'build'), ('scalable', 'scalabl'), ('fault-tolerant', 'fault-toler'), ('manager', 'manag'), ('big', 'big'), ('data', 'data'), ('analysis', 'analysi'), (',', ','), ('Huai', 'huai'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('To', 'to'), ('build', 'build'), ('scalable', 'scalabl'), ('fault-tolerant', 'fault-toler'), ('manager', 'manag'), ('big', 'big'), ('data', 'data'), ('analysis', 'analysi'), (',', ','), ('Huai', 'huai'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('To', 'To'), ('build', 'build'), ('scalable', 'scalable'), ('fault-tolerant', 'fault-tolerant'), ('manager', 'manager'), ('big', 'big'), ('data', 'data'), ('analysis', 'analysis'), (',', ','), ('Huai', 'Huai'), ('et', 'et'), ('al', 'al'), ('.', '.')]


------------------- Sentence 5 -------------------

[88] presented a matrix model which consists of three matrices for data set (D), concur- rent data processing operations (O), and data transformations (T), called DOT.

>> Tokens are: 
 ['[', '88', ']', 'presented', 'matrix', 'model', 'consists', 'three', 'matrices', 'data', 'set', '(', 'D', ')', ',', 'concur-', 'rent', 'data', 'processing', 'operations', '(', 'O', ')', ',', 'data', 'transformations', '(', 'T', ')', ',', 'called', 'DOT', '.']

>> Bigrams are: 
 [('[', '88'), ('88', ']'), (']', 'presented'), ('presented', 'matrix'), ('matrix', 'model'), ('model', 'consists'), ('consists', 'three'), ('three', 'matrices'), ('matrices', 'data'), ('data', 'set'), ('set', '('), ('(', 'D'), ('D', ')'), (')', ','), (',', 'concur-'), ('concur-', 'rent'), ('rent', 'data'), ('data', 'processing'), ('processing', 'operations'), ('operations', '('), ('(', 'O'), ('O', ')'), (')', ','), (',', 'data'), ('data', 'transformations'), ('transformations', '('), ('(', 'T'), ('T', ')'), (')', ','), (',', 'called'), ('called', 'DOT'), ('DOT', '.')]

>> Trigrams are: 
 [('[', '88', ']'), ('88', ']', 'presented'), (']', 'presented', 'matrix'), ('presented', 'matrix', 'model'), ('matrix', 'model', 'consists'), ('model', 'consists', 'three'), ('consists', 'three', 'matrices'), ('three', 'matrices', 'data'), ('matrices', 'data', 'set'), ('data', 'set', '('), ('set', '(', 'D'), ('(', 'D', ')'), ('D', ')', ','), (')', ',', 'concur-'), (',', 'concur-', 'rent'), ('concur-', 'rent', 'data'), ('rent', 'data', 'processing'), ('data', 'processing', 'operations'), ('processing', 'operations', '('), ('operations', '(', 'O'), ('(', 'O', ')'), ('O', ')', ','), (')', ',', 'data'), (',', 'data', 'transformations'), ('data', 'transformations', '('), ('transformations', '(', 'T'), ('(', 'T', ')'), ('T', ')', ','), (')', ',', 'called'), (',', 'called', 'DOT'), ('called', 'DOT', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('88', 'CD'), (']', 'NNS'), ('presented', 'VBN'), ('matrix', 'JJ'), ('model', 'NN'), ('consists', 'VBZ'), ('three', 'CD'), ('matrices', 'NNS'), ('data', 'NNS'), ('set', 'NN'), ('(', '('), ('D', 'NNP'), (')', ')'), (',', ','), ('concur-', 'JJ'), ('rent', 'NN'), ('data', 'NNS'), ('processing', 'NN'), ('operations', 'NNS'), ('(', '('), ('O', 'NNP'), (')', ')'), (',', ','), ('data', 'NNS'), ('transformations', 'NNS'), ('(', '('), ('T', 'NNP'), (')', ')'), (',', ','), ('called', 'VBN'), ('DOT', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 [']', 'matrix model', 'matrices data set', 'D', 'concur- rent data processing operations', 'O', 'data transformations', 'T', 'DOT']

>> Named Entities are: 
 [('ORGANIZATION', 'DOT')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('88', '88'), (']', ']'), ('presented', 'present'), ('matrix', 'matrix'), ('model', 'model'), ('consists', 'consist'), ('three', 'three'), ('matrices', 'matric'), ('data', 'data'), ('set', 'set'), ('(', '('), ('D', 'd'), (')', ')'), (',', ','), ('concur-', 'concur-'), ('rent', 'rent'), ('data', 'data'), ('processing', 'process'), ('operations', 'oper'), ('(', '('), ('O', 'o'), (')', ')'), (',', ','), ('data', 'data'), ('transformations', 'transform'), ('(', '('), ('T', 't'), (')', ')'), (',', ','), ('called', 'call'), ('DOT', 'dot'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('88', '88'), (']', ']'), ('presented', 'present'), ('matrix', 'matrix'), ('model', 'model'), ('consists', 'consist'), ('three', 'three'), ('matrices', 'matric'), ('data', 'data'), ('set', 'set'), ('(', '('), ('D', 'd'), (')', ')'), (',', ','), ('concur-', 'concur-'), ('rent', 'rent'), ('data', 'data'), ('processing', 'process'), ('operations', 'oper'), ('(', '('), ('O', 'o'), (')', ')'), (',', ','), ('data', 'data'), ('transformations', 'transform'), ('(', '('), ('T', 't'), (')', ')'), (',', ','), ('called', 'call'), ('DOT', 'dot'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('88', '88'), (']', ']'), ('presented', 'presented'), ('matrix', 'matrix'), ('model', 'model'), ('consists', 'consists'), ('three', 'three'), ('matrices', 'matrix'), ('data', 'data'), ('set', 'set'), ('(', '('), ('D', 'D'), (')', ')'), (',', ','), ('concur-', 'concur-'), ('rent', 'rent'), ('data', 'data'), ('processing', 'processing'), ('operations', 'operation'), ('(', '('), ('O', 'O'), (')', ')'), (',', ','), ('data', 'data'), ('transformations', 'transformation'), ('(', '('), ('T', 'T'), (')', ')'), (',', ','), ('called', 'called'), ('DOT', 'DOT'), ('.', '.')]


------------------- Sentence 6 -------------------

The big  data is divided into n subsets each of which is processed by a computer node (worker)  in such a way that all the subsets are processed concurrently, and then the results from  these n computer nodes are collected and transformed to a computer node.

>> Tokens are: 
 ['The', 'big', 'data', 'divided', 'n', 'subsets', 'processed', 'computer', 'node', '(', 'worker', ')', 'way', 'subsets', 'processed', 'concurrently', ',', 'results', 'n', 'computer', 'nodes', 'collected', 'transformed', 'computer', 'node', '.']

>> Bigrams are: 
 [('The', 'big'), ('big', 'data'), ('data', 'divided'), ('divided', 'n'), ('n', 'subsets'), ('subsets', 'processed'), ('processed', 'computer'), ('computer', 'node'), ('node', '('), ('(', 'worker'), ('worker', ')'), (')', 'way'), ('way', 'subsets'), ('subsets', 'processed'), ('processed', 'concurrently'), ('concurrently', ','), (',', 'results'), ('results', 'n'), ('n', 'computer'), ('computer', 'nodes'), ('nodes', 'collected'), ('collected', 'transformed'), ('transformed', 'computer'), ('computer', 'node'), ('node', '.')]

>> Trigrams are: 
 [('The', 'big', 'data'), ('big', 'data', 'divided'), ('data', 'divided', 'n'), ('divided', 'n', 'subsets'), ('n', 'subsets', 'processed'), ('subsets', 'processed', 'computer'), ('processed', 'computer', 'node'), ('computer', 'node', '('), ('node', '(', 'worker'), ('(', 'worker', ')'), ('worker', ')', 'way'), (')', 'way', 'subsets'), ('way', 'subsets', 'processed'), ('subsets', 'processed', 'concurrently'), ('processed', 'concurrently', ','), ('concurrently', ',', 'results'), (',', 'results', 'n'), ('results', 'n', 'computer'), ('n', 'computer', 'nodes'), ('computer', 'nodes', 'collected'), ('nodes', 'collected', 'transformed'), ('collected', 'transformed', 'computer'), ('transformed', 'computer', 'node'), ('computer', 'node', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('big', 'JJ'), ('data', 'NNS'), ('divided', 'VBD'), ('n', 'JJ'), ('subsets', 'NNS'), ('processed', 'VBN'), ('computer', 'NN'), ('node', 'NN'), ('(', '('), ('worker', 'NN'), (')', ')'), ('way', 'NN'), ('subsets', 'NNS'), ('processed', 'VBD'), ('concurrently', 'RB'), (',', ','), ('results', 'NNS'), ('n', 'VBP'), ('computer', 'NN'), ('nodes', 'NNS'), ('collected', 'VBD'), ('transformed', 'JJ'), ('computer', 'NN'), ('node', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['The big data', 'n subsets', 'computer node', 'worker', 'way subsets', 'results', 'computer nodes', 'transformed computer node']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('big', 'big'), ('data', 'data'), ('divided', 'divid'), ('n', 'n'), ('subsets', 'subset'), ('processed', 'process'), ('computer', 'comput'), ('node', 'node'), ('(', '('), ('worker', 'worker'), (')', ')'), ('way', 'way'), ('subsets', 'subset'), ('processed', 'process'), ('concurrently', 'concurr'), (',', ','), ('results', 'result'), ('n', 'n'), ('computer', 'comput'), ('nodes', 'node'), ('collected', 'collect'), ('transformed', 'transform'), ('computer', 'comput'), ('node', 'node'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('big', 'big'), ('data', 'data'), ('divided', 'divid'), ('n', 'n'), ('subsets', 'subset'), ('processed', 'process'), ('computer', 'comput'), ('node', 'node'), ('(', '('), ('worker', 'worker'), (')', ')'), ('way', 'way'), ('subsets', 'subset'), ('processed', 'process'), ('concurrently', 'concurr'), (',', ','), ('results', 'result'), ('n', 'n'), ('computer', 'comput'), ('nodes', 'node'), ('collected', 'collect'), ('transformed', 'transform'), ('computer', 'comput'), ('node', 'node'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('big', 'big'), ('data', 'data'), ('divided', 'divided'), ('n', 'n'), ('subsets', 'subset'), ('processed', 'processed'), ('computer', 'computer'), ('node', 'node'), ('(', '('), ('worker', 'worker'), (')', ')'), ('way', 'way'), ('subsets', 'subset'), ('processed', 'processed'), ('concurrently', 'concurrently'), (',', ','), ('results', 'result'), ('n', 'n'), ('computer', 'computer'), ('nodes', 'node'), ('collected', 'collected'), ('transformed', 'transformed'), ('computer', 'computer'), ('node', 'node'), ('.', '.')]


------------------- Sentence 7 -------------------

By using this  framework, the whole data analysis framework is composed of several DOT blocks.

>> Tokens are: 
 ['By', 'using', 'framework', ',', 'whole', 'data', 'analysis', 'framework', 'composed', 'several', 'DOT', 'blocks', '.']

>> Bigrams are: 
 [('By', 'using'), ('using', 'framework'), ('framework', ','), (',', 'whole'), ('whole', 'data'), ('data', 'analysis'), ('analysis', 'framework'), ('framework', 'composed'), ('composed', 'several'), ('several', 'DOT'), ('DOT', 'blocks'), ('blocks', '.')]

>> Trigrams are: 
 [('By', 'using', 'framework'), ('using', 'framework', ','), ('framework', ',', 'whole'), (',', 'whole', 'data'), ('whole', 'data', 'analysis'), ('data', 'analysis', 'framework'), ('analysis', 'framework', 'composed'), ('framework', 'composed', 'several'), ('composed', 'several', 'DOT'), ('several', 'DOT', 'blocks'), ('DOT', 'blocks', '.')]

>> POS Tags are: 
 [('By', 'IN'), ('using', 'VBG'), ('framework', 'NN'), (',', ','), ('whole', 'JJ'), ('data', 'NN'), ('analysis', 'NN'), ('framework', 'NN'), ('composed', 'VBD'), ('several', 'JJ'), ('DOT', 'NNP'), ('blocks', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['framework', 'whole data analysis framework', 'several DOT blocks']

>> Named Entities are: 
 [('ORGANIZATION', 'DOT')] 

>> Stemming using Porter Stemmer: 
 [('By', 'by'), ('using', 'use'), ('framework', 'framework'), (',', ','), ('whole', 'whole'), ('data', 'data'), ('analysis', 'analysi'), ('framework', 'framework'), ('composed', 'compos'), ('several', 'sever'), ('DOT', 'dot'), ('blocks', 'block'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('By', 'by'), ('using', 'use'), ('framework', 'framework'), (',', ','), ('whole', 'whole'), ('data', 'data'), ('analysis', 'analysi'), ('framework', 'framework'), ('composed', 'compos'), ('several', 'sever'), ('DOT', 'dot'), ('blocks', 'block'), ('.', '.')]

>> Lemmatization: 
 [('By', 'By'), ('using', 'using'), ('framework', 'framework'), (',', ','), ('whole', 'whole'), ('data', 'data'), ('analysis', 'analysis'), ('framework', 'framework'), ('composed', 'composed'), ('several', 'several'), ('DOT', 'DOT'), ('blocks', 'block'), ('.', '.')]


------------------- Sentence 8 -------------------

The  system performance can be easily enhanced by adding more DOT blocks to the system.

>> Tokens are: 
 ['The', 'system', 'performance', 'easily', 'enhanced', 'adding', 'DOT', 'blocks', 'system', '.']

>> Bigrams are: 
 [('The', 'system'), ('system', 'performance'), ('performance', 'easily'), ('easily', 'enhanced'), ('enhanced', 'adding'), ('adding', 'DOT'), ('DOT', 'blocks'), ('blocks', 'system'), ('system', '.')]

>> Trigrams are: 
 [('The', 'system', 'performance'), ('system', 'performance', 'easily'), ('performance', 'easily', 'enhanced'), ('easily', 'enhanced', 'adding'), ('enhanced', 'adding', 'DOT'), ('adding', 'DOT', 'blocks'), ('DOT', 'blocks', 'system'), ('blocks', 'system', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('system', 'NN'), ('performance', 'NN'), ('easily', 'RB'), ('enhanced', 'VBD'), ('adding', 'VBG'), ('DOT', 'NNP'), ('blocks', 'NNS'), ('system', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['The system performance', 'DOT blocks system']

>> Named Entities are: 
 [('ORGANIZATION', 'DOT')] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('system', 'system'), ('performance', 'perform'), ('easily', 'easili'), ('enhanced', 'enhanc'), ('adding', 'ad'), ('DOT', 'dot'), ('blocks', 'block'), ('system', 'system'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('system', 'system'), ('performance', 'perform'), ('easily', 'easili'), ('enhanced', 'enhanc'), ('adding', 'ad'), ('DOT', 'dot'), ('blocks', 'block'), ('system', 'system'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('system', 'system'), ('performance', 'performance'), ('easily', 'easily'), ('enhanced', 'enhanced'), ('adding', 'adding'), ('DOT', 'DOT'), ('blocks', 'block'), ('system', 'system'), ('.', '.')]



========================================== PARAGRAPH 216 ===========================================

Another efficient big data analytics was presented in [89], called generalized linear  aggregates distributed engine (GLADE). The GLADE is a multi-level tree-based data  analytics system which consists of two types of computer nodes that are a coordinator  

------------------- Sentence 1 -------------------

Another efficient big data analytics was presented in [89], called generalized linear  aggregates distributed engine (GLADE).

>> Tokens are: 
 ['Another', 'efficient', 'big', 'data', 'analytics', 'presented', '[', '89', ']', ',', 'called', 'generalized', 'linear', 'aggregates', 'distributed', 'engine', '(', 'GLADE', ')', '.']

>> Bigrams are: 
 [('Another', 'efficient'), ('efficient', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', 'presented'), ('presented', '['), ('[', '89'), ('89', ']'), (']', ','), (',', 'called'), ('called', 'generalized'), ('generalized', 'linear'), ('linear', 'aggregates'), ('aggregates', 'distributed'), ('distributed', 'engine'), ('engine', '('), ('(', 'GLADE'), ('GLADE', ')'), (')', '.')]

>> Trigrams are: 
 [('Another', 'efficient', 'big'), ('efficient', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', 'presented'), ('analytics', 'presented', '['), ('presented', '[', '89'), ('[', '89', ']'), ('89', ']', ','), (']', ',', 'called'), (',', 'called', 'generalized'), ('called', 'generalized', 'linear'), ('generalized', 'linear', 'aggregates'), ('linear', 'aggregates', 'distributed'), ('aggregates', 'distributed', 'engine'), ('distributed', 'engine', '('), ('engine', '(', 'GLADE'), ('(', 'GLADE', ')'), ('GLADE', ')', '.')]

>> POS Tags are: 
 [('Another', 'DT'), ('efficient', 'JJ'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('presented', 'VBD'), ('[', 'JJ'), ('89', 'CD'), (']', 'NN'), (',', ','), ('called', 'VBN'), ('generalized', 'VBD'), ('linear', 'JJ'), ('aggregates', 'NNS'), ('distributed', 'VBN'), ('engine', 'NN'), ('(', '('), ('GLADE', 'NNP'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['Another efficient big data analytics', ']', 'linear aggregates', 'engine', 'GLADE']

>> Named Entities are: 
 [('ORGANIZATION', 'GLADE')] 

>> Stemming using Porter Stemmer: 
 [('Another', 'anoth'), ('efficient', 'effici'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('presented', 'present'), ('[', '['), ('89', '89'), (']', ']'), (',', ','), ('called', 'call'), ('generalized', 'gener'), ('linear', 'linear'), ('aggregates', 'aggreg'), ('distributed', 'distribut'), ('engine', 'engin'), ('(', '('), ('GLADE', 'glade'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Another', 'anoth'), ('efficient', 'effici'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('presented', 'present'), ('[', '['), ('89', '89'), (']', ']'), (',', ','), ('called', 'call'), ('generalized', 'general'), ('linear', 'linear'), ('aggregates', 'aggreg'), ('distributed', 'distribut'), ('engine', 'engin'), ('(', '('), ('GLADE', 'glade'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Another', 'Another'), ('efficient', 'efficient'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('presented', 'presented'), ('[', '['), ('89', '89'), (']', ']'), (',', ','), ('called', 'called'), ('generalized', 'generalized'), ('linear', 'linear'), ('aggregates', 'aggregate'), ('distributed', 'distributed'), ('engine', 'engine'), ('(', '('), ('GLADE', 'GLADE'), (')', ')'), ('.', '.')]


------------------- Sentence 2 -------------------

The GLADE is a multi-level tree-based data  analytics system which consists of two types of computer nodes that are a coordinator

>> Tokens are: 
 ['The', 'GLADE', 'multi-level', 'tree-based', 'data', 'analytics', 'system', 'consists', 'two', 'types', 'computer', 'nodes', 'coordinator']

>> Bigrams are: 
 [('The', 'GLADE'), ('GLADE', 'multi-level'), ('multi-level', 'tree-based'), ('tree-based', 'data'), ('data', 'analytics'), ('analytics', 'system'), ('system', 'consists'), ('consists', 'two'), ('two', 'types'), ('types', 'computer'), ('computer', 'nodes'), ('nodes', 'coordinator')]

>> Trigrams are: 
 [('The', 'GLADE', 'multi-level'), ('GLADE', 'multi-level', 'tree-based'), ('multi-level', 'tree-based', 'data'), ('tree-based', 'data', 'analytics'), ('data', 'analytics', 'system'), ('analytics', 'system', 'consists'), ('system', 'consists', 'two'), ('consists', 'two', 'types'), ('two', 'types', 'computer'), ('types', 'computer', 'nodes'), ('computer', 'nodes', 'coordinator')]

>> POS Tags are: 
 [('The', 'DT'), ('GLADE', 'NNP'), ('multi-level', 'JJ'), ('tree-based', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('system', 'NN'), ('consists', 'VBZ'), ('two', 'CD'), ('types', 'NNS'), ('computer', 'NN'), ('nodes', 'NNS'), ('coordinator', 'NN')]

>> Noun Phrases are: 
 ['The GLADE', 'multi-level tree-based data analytics system', 'types computer nodes coordinator']

>> Named Entities are: 
 [('ORGANIZATION', 'GLADE')] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('GLADE', 'glade'), ('multi-level', 'multi-level'), ('tree-based', 'tree-bas'), ('data', 'data'), ('analytics', 'analyt'), ('system', 'system'), ('consists', 'consist'), ('two', 'two'), ('types', 'type'), ('computer', 'comput'), ('nodes', 'node'), ('coordinator', 'coordin')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('GLADE', 'glade'), ('multi-level', 'multi-level'), ('tree-based', 'tree-bas'), ('data', 'data'), ('analytics', 'analyt'), ('system', 'system'), ('consists', 'consist'), ('two', 'two'), ('types', 'type'), ('computer', 'comput'), ('nodes', 'node'), ('coordinator', 'coordin')]

>> Lemmatization: 
 [('The', 'The'), ('GLADE', 'GLADE'), ('multi-level', 'multi-level'), ('tree-based', 'tree-based'), ('data', 'data'), ('analytics', 'analytics'), ('system', 'system'), ('consists', 'consists'), ('two', 'two'), ('types', 'type'), ('computer', 'computer'), ('nodes', 'node'), ('coordinator', 'coordinator')]



========================================== PARAGRAPH 217 ===========================================

S en 

------------------- Sentence 1 -------------------

S en

>> Tokens are: 
 ['S', 'en']

>> Bigrams are: 
 [('S', 'en')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('S', 'NNP'), ('en', 'NN')]

>> Noun Phrases are: 
 ['S en']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('S', 's'), ('en', 'en')]

>> Stemming using Snowball Stemmer: 
 [('S', 's'), ('en', 'en')]

>> Lemmatization: 
 [('S', 'S'), ('en', 'en')]



========================================== PARAGRAPH 218 ===========================================

so r 

------------------- Sentence 1 -------------------

so r

>> Tokens are: 
 ['r']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('r', 'NN')]

>> Noun Phrases are: 
 ['r']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('r', 'r')]

>> Stemming using Snowball Stemmer: 
 [('r', 'r')]

>> Lemmatization: 
 [('r', 'r')]



========================================== PARAGRAPH 219 ===========================================

S en 

------------------- Sentence 1 -------------------

S en

>> Tokens are: 
 ['S', 'en']

>> Bigrams are: 
 [('S', 'en')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('S', 'NNP'), ('en', 'NN')]

>> Noun Phrases are: 
 ['S en']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('S', 's'), ('en', 'en')]

>> Stemming using Snowball Stemmer: 
 [('S', 's'), ('en', 'en')]

>> Lemmatization: 
 [('S', 'S'), ('en', 'en')]



========================================== PARAGRAPH 220 ===========================================

so r 

------------------- Sentence 1 -------------------

so r

>> Tokens are: 
 ['r']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('r', 'NN')]

>> Noun Phrases are: 
 ['r']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('r', 'r')]

>> Stemming using Snowball Stemmer: 
 [('r', 'r')]

>> Lemmatization: 
 [('r', 'r')]



========================================== PARAGRAPH 221 ===========================================

S en 

------------------- Sentence 1 -------------------

S en

>> Tokens are: 
 ['S', 'en']

>> Bigrams are: 
 [('S', 'en')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('S', 'NNP'), ('en', 'NN')]

>> Noun Phrases are: 
 ['S en']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('S', 's'), ('en', 'en')]

>> Stemming using Snowball Stemmer: 
 [('S', 's'), ('en', 'en')]

>> Lemmatization: 
 [('S', 'S'), ('en', 'en')]



========================================== PARAGRAPH 222 ===========================================

so r 

------------------- Sentence 1 -------------------

so r

>> Tokens are: 
 ['r']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('r', 'NN')]

>> Noun Phrases are: 
 ['r']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('r', 'r')]

>> Stemming using Snowball Stemmer: 
 [('r', 'r')]

>> Lemmatization: 
 [('r', 'r')]



========================================== PARAGRAPH 223 ===========================================

S en 

------------------- Sentence 1 -------------------

S en

>> Tokens are: 
 ['S', 'en']

>> Bigrams are: 
 [('S', 'en')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('S', 'NNP'), ('en', 'NN')]

>> Noun Phrases are: 
 ['S en']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('S', 's'), ('en', 'en')]

>> Stemming using Snowball Stemmer: 
 [('S', 's'), ('en', 'en')]

>> Lemmatization: 
 [('S', 'S'), ('en', 'en')]



========================================== PARAGRAPH 224 ===========================================

so r 

------------------- Sentence 1 -------------------

so r

>> Tokens are: 
 ['r']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('r', 'NN')]

>> Noun Phrases are: 
 ['r']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('r', 'r')]

>> Stemming using Snowball Stemmer: 
 [('r', 'r')]

>> Lemmatization: 
 [('r', 'r')]



========================================== PARAGRAPH 225 ===========================================

S en 

------------------- Sentence 1 -------------------

S en

>> Tokens are: 
 ['S', 'en']

>> Bigrams are: 
 [('S', 'en')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('S', 'NNP'), ('en', 'NN')]

>> Noun Phrases are: 
 ['S en']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('S', 's'), ('en', 'en')]

>> Stemming using Snowball Stemmer: 
 [('S', 's'), ('en', 'en')]

>> Lemmatization: 
 [('S', 'S'), ('en', 'en')]



========================================== PARAGRAPH 226 ===========================================

so r 

------------------- Sentence 1 -------------------

so r

>> Tokens are: 
 ['r']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('r', 'NN')]

>> Noun Phrases are: 
 ['r']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('r', 'r')]

>> Stemming using Snowball Stemmer: 
 [('r', 'r')]

>> Lemmatization: 
 [('r', 'r')]



========================================== PARAGRAPH 227 ===========================================

User 

------------------- Sentence 1 -------------------

User

>> Tokens are: 
 ['User']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('User', 'NN')]

>> Noun Phrases are: 
 ['User']

>> Named Entities are: 
 [('GPE', 'User')] 

>> Stemming using Porter Stemmer: 
 [('User', 'user')]

>> Stemming using Snowball Stemmer: 
 [('User', 'user')]

>> Lemmatization: 
 [('User', 'User')]



========================================== PARAGRAPH 228 ===========================================

Raw Data 

------------------- Sentence 1 -------------------

Raw Data

>> Tokens are: 
 ['Raw', 'Data']

>> Bigrams are: 
 [('Raw', 'Data')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Raw', 'NNP'), ('Data', 'NNP')]

>> Noun Phrases are: 
 ['Raw Data']

>> Named Entities are: 
 [('PERSON', 'Raw'), ('ORGANIZATION', 'Data')] 

>> Stemming using Porter Stemmer: 
 [('Raw', 'raw'), ('Data', 'data')]

>> Stemming using Snowball Stemmer: 
 [('Raw', 'raw'), ('Data', 'data')]

>> Lemmatization: 
 [('Raw', 'Raw'), ('Data', 'Data')]



========================================== PARAGRAPH 229 ===========================================

Knowledge 

------------------- Sentence 1 -------------------

Knowledge

>> Tokens are: 
 ['Knowledge']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Knowledge', 'NN')]

>> Noun Phrases are: 
 ['Knowledge']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Knowledge', 'knowledg')]

>> Stemming using Snowball Stemmer: 
 [('Knowledge', 'knowledg')]

>> Lemmatization: 
 [('Knowledge', 'Knowledge')]



========================================== PARAGRAPH 230 ===========================================

Cloud Platform 

------------------- Sentence 1 -------------------

Cloud Platform

>> Tokens are: 
 ['Cloud', 'Platform']

>> Bigrams are: 
 [('Cloud', 'Platform')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Cloud', 'NNP'), ('Platform', 'NNP')]

>> Noun Phrases are: 
 ['Cloud Platform']

>> Named Entities are: 
 [('PERSON', 'Cloud')] 

>> Stemming using Porter Stemmer: 
 [('Cloud', 'cloud'), ('Platform', 'platform')]

>> Stemming using Snowball Stemmer: 
 [('Cloud', 'cloud'), ('Platform', 'platform')]

>> Lemmatization: 
 [('Cloud', 'Cloud'), ('Platform', 'Platform')]



========================================== PARAGRAPH 231 ===========================================

Data Analysis Modules 

------------------- Sentence 1 -------------------

Data Analysis Modules

>> Tokens are: 
 ['Data', 'Analysis', 'Modules']

>> Bigrams are: 
 [('Data', 'Analysis'), ('Analysis', 'Modules')]

>> Trigrams are: 
 [('Data', 'Analysis', 'Modules')]

>> POS Tags are: 
 [('Data', 'NNP'), ('Analysis', 'NNP'), ('Modules', 'NNP')]

>> Noun Phrases are: 
 ['Data Analysis Modules']

>> Named Entities are: 
 [('PERSON', 'Data'), ('PERSON', 'Analysis Modules')] 

>> Stemming using Porter Stemmer: 
 [('Data', 'data'), ('Analysis', 'analysi'), ('Modules', 'modul')]

>> Stemming using Snowball Stemmer: 
 [('Data', 'data'), ('Analysis', 'analysi'), ('Modules', 'modul')]

>> Lemmatization: 
 [('Data', 'Data'), ('Analysis', 'Analysis'), ('Modules', 'Modules')]



========================================== PARAGRAPH 232 ===========================================

Interpretation Applications 

------------------- Sentence 1 -------------------

Interpretation Applications

>> Tokens are: 
 ['Interpretation', 'Applications']

>> Bigrams are: 
 [('Interpretation', 'Applications')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Interpretation', 'NN'), ('Applications', 'NNS')]

>> Noun Phrases are: 
 ['Interpretation Applications']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Interpretation', 'interpret'), ('Applications', 'applic')]

>> Stemming using Snowball Stemmer: 
 [('Interpretation', 'interpret'), ('Applications', 'applic')]

>> Lemmatization: 
 [('Interpretation', 'Interpretation'), ('Applications', 'Applications')]



========================================== PARAGRAPH 233 ===========================================

D at 

------------------- Sentence 1 -------------------

D at

>> Tokens are: 
 ['D']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('D', 'NN')]

>> Noun Phrases are: 
 ['D']

>> Named Entities are: 
 [('GPE', 'D')] 

>> Stemming using Porter Stemmer: 
 [('D', 'd')]

>> Stemming using Snowball Stemmer: 
 [('D', 'd')]

>> Lemmatization: 
 [('D', 'D')]



========================================== PARAGRAPH 234 ===========================================

a  A 

------------------- Sentence 1 -------------------

a  A

>> Tokens are: 
 ['A']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('A', 'DT')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('A', 'a')]

>> Stemming using Snowball Stemmer: 
 [('A', 'a')]

>> Lemmatization: 
 [('A', 'A')]



========================================== PARAGRAPH 235 ===========================================

na ly 

------------------- Sentence 1 -------------------

na ly

>> Tokens are: 
 ['na', 'ly']

>> Bigrams are: 
 [('na', 'ly')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('na', 'NNS'), ('ly', 'VBP')]

>> Noun Phrases are: 
 ['na']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('na', 'na'), ('ly', 'ly')]

>> Stemming using Snowball Stemmer: 
 [('na', 'na'), ('ly', 'ly')]

>> Lemmatization: 
 [('na', 'na'), ('ly', 'ly')]



========================================== PARAGRAPH 236 ===========================================

ti cs 

------------------- Sentence 1 -------------------

ti cs

>> Tokens are: 
 ['ti', 'cs']

>> Bigrams are: 
 [('ti', 'cs')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('ti', 'NN'), ('cs', 'NN')]

>> Noun Phrases are: 
 ['ti cs']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('ti', 'ti'), ('cs', 'cs')]

>> Stemming using Snowball Stemmer: 
 [('ti', 'ti'), ('cs', 'cs')]

>> Lemmatization: 
 [('ti', 'ti'), ('cs', 'c')]



========================================== PARAGRAPH 237 ===========================================

Fig. 7 The basic idea of big data analytics on cloud system 

------------------- Sentence 1 -------------------

Fig.

>> Tokens are: 
 ['Fig', '.']

>> Bigrams are: 
 [('Fig', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Fig', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Fig']

>> Named Entities are: 
 [('GPE', 'Fig')] 

>> Stemming using Porter Stemmer: 
 [('Fig', 'fig'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Fig', 'fig'), ('.', '.')]

>> Lemmatization: 
 [('Fig', 'Fig'), ('.', '.')]


------------------- Sentence 2 -------------------

7 The basic idea of big data analytics on cloud system

>> Tokens are: 
 ['7', 'The', 'basic', 'idea', 'big', 'data', 'analytics', 'cloud', 'system']

>> Bigrams are: 
 [('7', 'The'), ('The', 'basic'), ('basic', 'idea'), ('idea', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', 'cloud'), ('cloud', 'system')]

>> Trigrams are: 
 [('7', 'The', 'basic'), ('The', 'basic', 'idea'), ('basic', 'idea', 'big'), ('idea', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', 'cloud'), ('analytics', 'cloud', 'system')]

>> POS Tags are: 
 [('7', 'CD'), ('The', 'DT'), ('basic', 'JJ'), ('idea', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('cloud', 'VBP'), ('system', 'NN')]

>> Noun Phrases are: 
 ['The basic idea', 'big data analytics', 'system']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('7', '7'), ('The', 'the'), ('basic', 'basic'), ('idea', 'idea'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('cloud', 'cloud'), ('system', 'system')]

>> Stemming using Snowball Stemmer: 
 [('7', '7'), ('The', 'the'), ('basic', 'basic'), ('idea', 'idea'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('cloud', 'cloud'), ('system', 'system')]

>> Lemmatization: 
 [('7', '7'), ('The', 'The'), ('basic', 'basic'), ('idea', 'idea'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('cloud', 'cloud'), ('system', 'system')]



========================================== PARAGRAPH 238 ===========================================

3M2M1M 

------------------- Sentence 1 -------------------

3M2M1M

>> Tokens are: 
 ['3M2M1M']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('3M2M1M', 'CD')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('3M2M1M', '3m2m1m')]

>> Stemming using Snowball Stemmer: 
 [('3M2M1M', '3m2m1m')]

>> Lemmatization: 
 [('3M2M1M', '3M2M1M')]



========================================== PARAGRAPH 239 ===========================================

a Scale up. 

------------------- Sentence 1 -------------------

a Scale up.

>> Tokens are: 
 ['Scale', '.']

>> Bigrams are: 
 [('Scale', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Scale', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Scale']

>> Named Entities are: 
 [('GPE', 'Scale')] 

>> Stemming using Porter Stemmer: 
 [('Scale', 'scale'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Scale', 'scale'), ('.', '.')]

>> Lemmatization: 
 [('Scale', 'Scale'), ('.', '.')]



========================================== PARAGRAPH 240 ===========================================

M1 

------------------- Sentence 1 -------------------

M1

>> Tokens are: 
 ['M1']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('M1', 'NN')]

>> Noun Phrases are: 
 ['M1']

>> Named Entities are: 
 [('GPE', 'M1')] 

>> Stemming using Porter Stemmer: 
 [('M1', 'm1')]

>> Stemming using Snowball Stemmer: 
 [('M1', 'm1')]

>> Lemmatization: 
 [('M1', 'M1')]



========================================== PARAGRAPH 241 ===========================================

6*1M3*1M 

------------------- Sentence 1 -------------------

6*1M3*1M

>> Tokens are: 
 ['6', '*', '1M3', '*', '1M']

>> Bigrams are: 
 [('6', '*'), ('*', '1M3'), ('1M3', '*'), ('*', '1M')]

>> Trigrams are: 
 [('6', '*', '1M3'), ('*', '1M3', '*'), ('1M3', '*', '1M')]

>> POS Tags are: 
 [('6', 'CD'), ('*', 'JJ'), ('1M3', 'CD'), ('*', '$'), ('1M', 'CD')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('6', '6'), ('*', '*'), ('1M3', '1m3'), ('*', '*'), ('1M', '1m')]

>> Stemming using Snowball Stemmer: 
 [('6', '6'), ('*', '*'), ('1M3', '1m3'), ('*', '*'), ('1M', '1m')]

>> Lemmatization: 
 [('6', '6'), ('*', '*'), ('1M3', '1M3'), ('*', '*'), ('1M', '1M')]



========================================== PARAGRAPH 242 ===========================================

b Scale out. 

------------------- Sentence 1 -------------------

b Scale out.

>> Tokens are: 
 ['b', 'Scale', '.']

>> Bigrams are: 
 [('b', 'Scale'), ('Scale', '.')]

>> Trigrams are: 
 [('b', 'Scale', '.')]

>> POS Tags are: 
 [('b', 'NN'), ('Scale', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['b Scale']

>> Named Entities are: 
 [('PERSON', 'Scale')] 

>> Stemming using Porter Stemmer: 
 [('b', 'b'), ('Scale', 'scale'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('b', 'b'), ('Scale', 'scale'), ('.', '.')]

>> Lemmatization: 
 [('b', 'b'), ('Scale', 'Scale'), ('.', '.')]



========================================== PARAGRAPH 243 ===========================================

Fig. 8 The comparisons between scale up and scale out

------------------- Sentence 1 -------------------

Fig.

>> Tokens are: 
 ['Fig', '.']

>> Bigrams are: 
 [('Fig', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Fig', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Fig']

>> Named Entities are: 
 [('GPE', 'Fig')] 

>> Stemming using Porter Stemmer: 
 [('Fig', 'fig'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Fig', 'fig'), ('.', '.')]

>> Lemmatization: 
 [('Fig', 'Fig'), ('.', '.')]


------------------- Sentence 2 -------------------

8 The comparisons between scale up and scale out

>> Tokens are: 
 ['8', 'The', 'comparisons', 'scale', 'scale']

>> Bigrams are: 
 [('8', 'The'), ('The', 'comparisons'), ('comparisons', 'scale'), ('scale', 'scale')]

>> Trigrams are: 
 [('8', 'The', 'comparisons'), ('The', 'comparisons', 'scale'), ('comparisons', 'scale', 'scale')]

>> POS Tags are: 
 [('8', 'CD'), ('The', 'DT'), ('comparisons', 'NNS'), ('scale', 'VBP'), ('scale', 'NN')]

>> Noun Phrases are: 
 ['The comparisons', 'scale']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('8', '8'), ('The', 'the'), ('comparisons', 'comparison'), ('scale', 'scale'), ('scale', 'scale')]

>> Stemming using Snowball Stemmer: 
 [('8', '8'), ('The', 'the'), ('comparisons', 'comparison'), ('scale', 'scale'), ('scale', 'scale')]

>> Lemmatization: 
 [('8', '8'), ('The', 'The'), ('comparisons', 'comparison'), ('scale', 'scale'), ('scale', 'scale')]



========================================== PARAGRAPH 244 ===========================================

Page 14 of 32Tsai et al. Journal of Big Data  (2015) 2:21  

------------------- Sentence 1 -------------------

Page 14 of 32Tsai et al.

>> Tokens are: 
 ['Page', '14', '32Tsai', 'et', 'al', '.']

>> Bigrams are: 
 [('Page', '14'), ('14', '32Tsai'), ('32Tsai', 'et'), ('et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('Page', '14', '32Tsai'), ('14', '32Tsai', 'et'), ('32Tsai', 'et', 'al'), ('et', 'al', '.')]

>> POS Tags are: 
 [('Page', 'NN'), ('14', 'CD'), ('32Tsai', 'CD'), ('et', 'NN'), ('al', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Page', 'et al']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Page', 'page'), ('14', '14'), ('32Tsai', '32tsai'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Page', 'page'), ('14', '14'), ('32Tsai', '32tsai'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('Page', 'Page'), ('14', '14'), ('32Tsai', '32Tsai'), ('et', 'et'), ('al', 'al'), ('.', '.')]


------------------- Sentence 2 -------------------

Journal of Big Data  (2015) 2:21

>> Tokens are: 
 ['Journal', 'Big', 'Data', '(', '2015', ')', '2:21']

>> Bigrams are: 
 [('Journal', 'Big'), ('Big', 'Data'), ('Data', '('), ('(', '2015'), ('2015', ')'), (')', '2:21')]

>> Trigrams are: 
 [('Journal', 'Big', 'Data'), ('Big', 'Data', '('), ('Data', '(', '2015'), ('(', '2015', ')'), ('2015', ')', '2:21')]

>> POS Tags are: 
 [('Journal', 'NNP'), ('Big', 'NNP'), ('Data', 'NNP'), ('(', '('), ('2015', 'CD'), (')', ')'), ('2:21', 'CD')]

>> Noun Phrases are: 
 ['Journal Big Data']

>> Named Entities are: 
 [('PERSON', 'Journal')] 

>> Stemming using Porter Stemmer: 
 [('Journal', 'journal'), ('Big', 'big'), ('Data', 'data'), ('(', '('), ('2015', '2015'), (')', ')'), ('2:21', '2:21')]

>> Stemming using Snowball Stemmer: 
 [('Journal', 'journal'), ('Big', 'big'), ('Data', 'data'), ('(', '('), ('2015', '2015'), (')', ')'), ('2:21', '2:21')]

>> Lemmatization: 
 [('Journal', 'Journal'), ('Big', 'Big'), ('Data', 'Data'), ('(', '('), ('2015', '2015'), (')', ')'), ('2:21', '2:21')]



========================================== PARAGRAPH 245 ===========================================

and workers. The simulation results [90] show that the GLADE can provide a better per- formance than Hadoop in terms of the execution time. Because Hadoop requires large  memory and storage for data replication and it is a single master,4 Essa et al. [91] pre- sented a mobile agent based framework to solve these two problems, called the map  reduce agent mobility (MRAM). The main reason is that each mobile agent can send its  code and data to any other machine; therefore, the whole system will not be down if the  master failed. Compared to Hadoop, the architecture of MRAM was changed from cli- ent/server to a distributed agent. The load time for MRAM is less than Hadoop even  though both of them use the map-reduce solution and Java language. In [92], Herodotou  et al. considered issues of the user needs and system workloads. They presented a self- tuning analytics system built on Hadoop for big data analysis. Since one of the major  goals of their system is to adjust the system based on the user needs and system work- loads to provide good performance automatically, the user usually does not need to  understand and manipulate the Hadoop system. The study [93] was from the perspec- tives of data centric architecture and operational models to presented a big data archi- tecture framework (BDAF) which includes: big data infrastructure, big data analytics,  data structures and models, big data lifecycle management, and big data security.  According to the observations of Demchenko et al. [93], cluster services, Hadoop related  services, data analytics tools, databases, servers, and massively parallel processing data- bases are typically the required applications and services in big data analytics  infrastructure. 

------------------- Sentence 1 -------------------

and workers.

>> Tokens are: 
 ['workers', '.']

>> Bigrams are: 
 [('workers', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('workers', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['workers']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('workers', 'worker'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('workers', 'worker'), ('.', '.')]

>> Lemmatization: 
 [('workers', 'worker'), ('.', '.')]


------------------- Sentence 2 -------------------

The simulation results [90] show that the GLADE can provide a better per- formance than Hadoop in terms of the execution time.

>> Tokens are: 
 ['The', 'simulation', 'results', '[', '90', ']', 'show', 'GLADE', 'provide', 'better', 'per-', 'formance', 'Hadoop', 'terms', 'execution', 'time', '.']

>> Bigrams are: 
 [('The', 'simulation'), ('simulation', 'results'), ('results', '['), ('[', '90'), ('90', ']'), (']', 'show'), ('show', 'GLADE'), ('GLADE', 'provide'), ('provide', 'better'), ('better', 'per-'), ('per-', 'formance'), ('formance', 'Hadoop'), ('Hadoop', 'terms'), ('terms', 'execution'), ('execution', 'time'), ('time', '.')]

>> Trigrams are: 
 [('The', 'simulation', 'results'), ('simulation', 'results', '['), ('results', '[', '90'), ('[', '90', ']'), ('90', ']', 'show'), (']', 'show', 'GLADE'), ('show', 'GLADE', 'provide'), ('GLADE', 'provide', 'better'), ('provide', 'better', 'per-'), ('better', 'per-', 'formance'), ('per-', 'formance', 'Hadoop'), ('formance', 'Hadoop', 'terms'), ('Hadoop', 'terms', 'execution'), ('terms', 'execution', 'time'), ('execution', 'time', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('simulation', 'NN'), ('results', 'NNS'), ('[', 'VBD'), ('90', 'CD'), (']', 'NNP'), ('show', 'NN'), ('GLADE', 'NNP'), ('provide', 'VBP'), ('better', 'JJR'), ('per-', 'JJ'), ('formance', 'NN'), ('Hadoop', 'NNP'), ('terms', 'NNS'), ('execution', 'NN'), ('time', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['The simulation results', '] show GLADE', 'per- formance Hadoop terms execution time']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('simulation', 'simul'), ('results', 'result'), ('[', '['), ('90', '90'), (']', ']'), ('show', 'show'), ('GLADE', 'glade'), ('provide', 'provid'), ('better', 'better'), ('per-', 'per-'), ('formance', 'formanc'), ('Hadoop', 'hadoop'), ('terms', 'term'), ('execution', 'execut'), ('time', 'time'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('simulation', 'simul'), ('results', 'result'), ('[', '['), ('90', '90'), (']', ']'), ('show', 'show'), ('GLADE', 'glade'), ('provide', 'provid'), ('better', 'better'), ('per-', 'per-'), ('formance', 'formanc'), ('Hadoop', 'hadoop'), ('terms', 'term'), ('execution', 'execut'), ('time', 'time'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('simulation', 'simulation'), ('results', 'result'), ('[', '['), ('90', '90'), (']', ']'), ('show', 'show'), ('GLADE', 'GLADE'), ('provide', 'provide'), ('better', 'better'), ('per-', 'per-'), ('formance', 'formance'), ('Hadoop', 'Hadoop'), ('terms', 'term'), ('execution', 'execution'), ('time', 'time'), ('.', '.')]


------------------- Sentence 3 -------------------

Because Hadoop requires large  memory and storage for data replication and it is a single master,4 Essa et al.

>> Tokens are: 
 ['Because', 'Hadoop', 'requires', 'large', 'memory', 'storage', 'data', 'replication', 'single', 'master,4', 'Essa', 'et', 'al', '.']

>> Bigrams are: 
 [('Because', 'Hadoop'), ('Hadoop', 'requires'), ('requires', 'large'), ('large', 'memory'), ('memory', 'storage'), ('storage', 'data'), ('data', 'replication'), ('replication', 'single'), ('single', 'master,4'), ('master,4', 'Essa'), ('Essa', 'et'), ('et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('Because', 'Hadoop', 'requires'), ('Hadoop', 'requires', 'large'), ('requires', 'large', 'memory'), ('large', 'memory', 'storage'), ('memory', 'storage', 'data'), ('storage', 'data', 'replication'), ('data', 'replication', 'single'), ('replication', 'single', 'master,4'), ('single', 'master,4', 'Essa'), ('master,4', 'Essa', 'et'), ('Essa', 'et', 'al'), ('et', 'al', '.')]

>> POS Tags are: 
 [('Because', 'IN'), ('Hadoop', 'NNP'), ('requires', 'VBZ'), ('large', 'JJ'), ('memory', 'NN'), ('storage', 'NN'), ('data', 'NNS'), ('replication', 'NN'), ('single', 'JJ'), ('master,4', 'NN'), ('Essa', 'NNP'), ('et', 'CC'), ('al', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Hadoop', 'large memory storage data replication', 'single master,4 Essa', 'al']

>> Named Entities are: 
 [('PERSON', 'Hadoop')] 

>> Stemming using Porter Stemmer: 
 [('Because', 'becaus'), ('Hadoop', 'hadoop'), ('requires', 'requir'), ('large', 'larg'), ('memory', 'memori'), ('storage', 'storag'), ('data', 'data'), ('replication', 'replic'), ('single', 'singl'), ('master,4', 'master,4'), ('Essa', 'essa'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Because', 'becaus'), ('Hadoop', 'hadoop'), ('requires', 'requir'), ('large', 'larg'), ('memory', 'memori'), ('storage', 'storag'), ('data', 'data'), ('replication', 'replic'), ('single', 'singl'), ('master,4', 'master,4'), ('Essa', 'essa'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('Because', 'Because'), ('Hadoop', 'Hadoop'), ('requires', 'requires'), ('large', 'large'), ('memory', 'memory'), ('storage', 'storage'), ('data', 'data'), ('replication', 'replication'), ('single', 'single'), ('master,4', 'master,4'), ('Essa', 'Essa'), ('et', 'et'), ('al', 'al'), ('.', '.')]


------------------- Sentence 4 -------------------

[91] pre- sented a mobile agent based framework to solve these two problems, called the map  reduce agent mobility (MRAM).

>> Tokens are: 
 ['[', '91', ']', 'pre-', 'sented', 'mobile', 'agent', 'based', 'framework', 'solve', 'two', 'problems', ',', 'called', 'map', 'reduce', 'agent', 'mobility', '(', 'MRAM', ')', '.']

>> Bigrams are: 
 [('[', '91'), ('91', ']'), (']', 'pre-'), ('pre-', 'sented'), ('sented', 'mobile'), ('mobile', 'agent'), ('agent', 'based'), ('based', 'framework'), ('framework', 'solve'), ('solve', 'two'), ('two', 'problems'), ('problems', ','), (',', 'called'), ('called', 'map'), ('map', 'reduce'), ('reduce', 'agent'), ('agent', 'mobility'), ('mobility', '('), ('(', 'MRAM'), ('MRAM', ')'), (')', '.')]

>> Trigrams are: 
 [('[', '91', ']'), ('91', ']', 'pre-'), (']', 'pre-', 'sented'), ('pre-', 'sented', 'mobile'), ('sented', 'mobile', 'agent'), ('mobile', 'agent', 'based'), ('agent', 'based', 'framework'), ('based', 'framework', 'solve'), ('framework', 'solve', 'two'), ('solve', 'two', 'problems'), ('two', 'problems', ','), ('problems', ',', 'called'), (',', 'called', 'map'), ('called', 'map', 'reduce'), ('map', 'reduce', 'agent'), ('reduce', 'agent', 'mobility'), ('agent', 'mobility', '('), ('mobility', '(', 'MRAM'), ('(', 'MRAM', ')'), ('MRAM', ')', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('91', 'CD'), (']', 'JJ'), ('pre-', 'NN'), ('sented', 'VBD'), ('mobile', 'JJ'), ('agent', 'NN'), ('based', 'VBN'), ('framework', 'NN'), ('solve', 'NN'), ('two', 'CD'), ('problems', 'NNS'), (',', ','), ('called', 'VBD'), ('map', 'NN'), ('reduce', 'VB'), ('agent', 'JJ'), ('mobility', 'NN'), ('(', '('), ('MRAM', 'NNP'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['] pre-', 'mobile agent', 'framework solve', 'problems', 'map', 'agent mobility', 'MRAM']

>> Named Entities are: 
 [('ORGANIZATION', 'MRAM')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('91', '91'), (']', ']'), ('pre-', 'pre-'), ('sented', 'sent'), ('mobile', 'mobil'), ('agent', 'agent'), ('based', 'base'), ('framework', 'framework'), ('solve', 'solv'), ('two', 'two'), ('problems', 'problem'), (',', ','), ('called', 'call'), ('map', 'map'), ('reduce', 'reduc'), ('agent', 'agent'), ('mobility', 'mobil'), ('(', '('), ('MRAM', 'mram'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('91', '91'), (']', ']'), ('pre-', 'pre-'), ('sented', 'sent'), ('mobile', 'mobil'), ('agent', 'agent'), ('based', 'base'), ('framework', 'framework'), ('solve', 'solv'), ('two', 'two'), ('problems', 'problem'), (',', ','), ('called', 'call'), ('map', 'map'), ('reduce', 'reduc'), ('agent', 'agent'), ('mobility', 'mobil'), ('(', '('), ('MRAM', 'mram'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('91', '91'), (']', ']'), ('pre-', 'pre-'), ('sented', 'sented'), ('mobile', 'mobile'), ('agent', 'agent'), ('based', 'based'), ('framework', 'framework'), ('solve', 'solve'), ('two', 'two'), ('problems', 'problem'), (',', ','), ('called', 'called'), ('map', 'map'), ('reduce', 'reduce'), ('agent', 'agent'), ('mobility', 'mobility'), ('(', '('), ('MRAM', 'MRAM'), (')', ')'), ('.', '.')]


------------------- Sentence 5 -------------------

The main reason is that each mobile agent can send its  code and data to any other machine; therefore, the whole system will not be down if the  master failed.

>> Tokens are: 
 ['The', 'main', 'reason', 'mobile', 'agent', 'send', 'code', 'data', 'machine', ';', 'therefore', ',', 'whole', 'system', 'master', 'failed', '.']

>> Bigrams are: 
 [('The', 'main'), ('main', 'reason'), ('reason', 'mobile'), ('mobile', 'agent'), ('agent', 'send'), ('send', 'code'), ('code', 'data'), ('data', 'machine'), ('machine', ';'), (';', 'therefore'), ('therefore', ','), (',', 'whole'), ('whole', 'system'), ('system', 'master'), ('master', 'failed'), ('failed', '.')]

>> Trigrams are: 
 [('The', 'main', 'reason'), ('main', 'reason', 'mobile'), ('reason', 'mobile', 'agent'), ('mobile', 'agent', 'send'), ('agent', 'send', 'code'), ('send', 'code', 'data'), ('code', 'data', 'machine'), ('data', 'machine', ';'), ('machine', ';', 'therefore'), (';', 'therefore', ','), ('therefore', ',', 'whole'), (',', 'whole', 'system'), ('whole', 'system', 'master'), ('system', 'master', 'failed'), ('master', 'failed', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('main', 'JJ'), ('reason', 'NN'), ('mobile', 'JJ'), ('agent', 'NN'), ('send', 'VBP'), ('code', 'NN'), ('data', 'NNS'), ('machine', 'NN'), (';', ':'), ('therefore', 'RB'), (',', ','), ('whole', 'JJ'), ('system', 'NN'), ('master', 'NN'), ('failed', 'VBD'), ('.', '.')]

>> Noun Phrases are: 
 ['The main reason', 'mobile agent', 'code data machine', 'whole system master']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('main', 'main'), ('reason', 'reason'), ('mobile', 'mobil'), ('agent', 'agent'), ('send', 'send'), ('code', 'code'), ('data', 'data'), ('machine', 'machin'), (';', ';'), ('therefore', 'therefor'), (',', ','), ('whole', 'whole'), ('system', 'system'), ('master', 'master'), ('failed', 'fail'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('main', 'main'), ('reason', 'reason'), ('mobile', 'mobil'), ('agent', 'agent'), ('send', 'send'), ('code', 'code'), ('data', 'data'), ('machine', 'machin'), (';', ';'), ('therefore', 'therefor'), (',', ','), ('whole', 'whole'), ('system', 'system'), ('master', 'master'), ('failed', 'fail'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('main', 'main'), ('reason', 'reason'), ('mobile', 'mobile'), ('agent', 'agent'), ('send', 'send'), ('code', 'code'), ('data', 'data'), ('machine', 'machine'), (';', ';'), ('therefore', 'therefore'), (',', ','), ('whole', 'whole'), ('system', 'system'), ('master', 'master'), ('failed', 'failed'), ('.', '.')]


------------------- Sentence 6 -------------------

Compared to Hadoop, the architecture of MRAM was changed from cli- ent/server to a distributed agent.

>> Tokens are: 
 ['Compared', 'Hadoop', ',', 'architecture', 'MRAM', 'changed', 'cli-', 'ent/server', 'distributed', 'agent', '.']

>> Bigrams are: 
 [('Compared', 'Hadoop'), ('Hadoop', ','), (',', 'architecture'), ('architecture', 'MRAM'), ('MRAM', 'changed'), ('changed', 'cli-'), ('cli-', 'ent/server'), ('ent/server', 'distributed'), ('distributed', 'agent'), ('agent', '.')]

>> Trigrams are: 
 [('Compared', 'Hadoop', ','), ('Hadoop', ',', 'architecture'), (',', 'architecture', 'MRAM'), ('architecture', 'MRAM', 'changed'), ('MRAM', 'changed', 'cli-'), ('changed', 'cli-', 'ent/server'), ('cli-', 'ent/server', 'distributed'), ('ent/server', 'distributed', 'agent'), ('distributed', 'agent', '.')]

>> POS Tags are: 
 [('Compared', 'NNP'), ('Hadoop', 'NNP'), (',', ','), ('architecture', 'NN'), ('MRAM', 'NNP'), ('changed', 'VBD'), ('cli-', 'JJ'), ('ent/server', 'NN'), ('distributed', 'VBN'), ('agent', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Compared Hadoop', 'architecture MRAM', 'cli- ent/server', 'agent']

>> Named Entities are: 
 [('ORGANIZATION', 'Compared Hadoop'), ('ORGANIZATION', 'MRAM')] 

>> Stemming using Porter Stemmer: 
 [('Compared', 'compar'), ('Hadoop', 'hadoop'), (',', ','), ('architecture', 'architectur'), ('MRAM', 'mram'), ('changed', 'chang'), ('cli-', 'cli-'), ('ent/server', 'ent/serv'), ('distributed', 'distribut'), ('agent', 'agent'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Compared', 'compar'), ('Hadoop', 'hadoop'), (',', ','), ('architecture', 'architectur'), ('MRAM', 'mram'), ('changed', 'chang'), ('cli-', 'cli-'), ('ent/server', 'ent/serv'), ('distributed', 'distribut'), ('agent', 'agent'), ('.', '.')]

>> Lemmatization: 
 [('Compared', 'Compared'), ('Hadoop', 'Hadoop'), (',', ','), ('architecture', 'architecture'), ('MRAM', 'MRAM'), ('changed', 'changed'), ('cli-', 'cli-'), ('ent/server', 'ent/server'), ('distributed', 'distributed'), ('agent', 'agent'), ('.', '.')]


------------------- Sentence 7 -------------------

The load time for MRAM is less than Hadoop even  though both of them use the map-reduce solution and Java language.

>> Tokens are: 
 ['The', 'load', 'time', 'MRAM', 'less', 'Hadoop', 'even', 'though', 'use', 'map-reduce', 'solution', 'Java', 'language', '.']

>> Bigrams are: 
 [('The', 'load'), ('load', 'time'), ('time', 'MRAM'), ('MRAM', 'less'), ('less', 'Hadoop'), ('Hadoop', 'even'), ('even', 'though'), ('though', 'use'), ('use', 'map-reduce'), ('map-reduce', 'solution'), ('solution', 'Java'), ('Java', 'language'), ('language', '.')]

>> Trigrams are: 
 [('The', 'load', 'time'), ('load', 'time', 'MRAM'), ('time', 'MRAM', 'less'), ('MRAM', 'less', 'Hadoop'), ('less', 'Hadoop', 'even'), ('Hadoop', 'even', 'though'), ('even', 'though', 'use'), ('though', 'use', 'map-reduce'), ('use', 'map-reduce', 'solution'), ('map-reduce', 'solution', 'Java'), ('solution', 'Java', 'language'), ('Java', 'language', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('load', 'NN'), ('time', 'NN'), ('MRAM', 'NNP'), ('less', 'CC'), ('Hadoop', 'NNP'), ('even', 'RB'), ('though', 'IN'), ('use', 'JJ'), ('map-reduce', 'JJ'), ('solution', 'NN'), ('Java', 'NNP'), ('language', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['The load time MRAM', 'Hadoop', 'use map-reduce solution Java language']

>> Named Entities are: 
 [('ORGANIZATION', 'MRAM'), ('PERSON', 'Hadoop'), ('PERSON', 'Java')] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('load', 'load'), ('time', 'time'), ('MRAM', 'mram'), ('less', 'less'), ('Hadoop', 'hadoop'), ('even', 'even'), ('though', 'though'), ('use', 'use'), ('map-reduce', 'map-reduc'), ('solution', 'solut'), ('Java', 'java'), ('language', 'languag'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('load', 'load'), ('time', 'time'), ('MRAM', 'mram'), ('less', 'less'), ('Hadoop', 'hadoop'), ('even', 'even'), ('though', 'though'), ('use', 'use'), ('map-reduce', 'map-reduc'), ('solution', 'solut'), ('Java', 'java'), ('language', 'languag'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('load', 'load'), ('time', 'time'), ('MRAM', 'MRAM'), ('less', 'le'), ('Hadoop', 'Hadoop'), ('even', 'even'), ('though', 'though'), ('use', 'use'), ('map-reduce', 'map-reduce'), ('solution', 'solution'), ('Java', 'Java'), ('language', 'language'), ('.', '.')]


------------------- Sentence 8 -------------------

In [92], Herodotou  et al.

>> Tokens are: 
 ['In', '[', '92', ']', ',', 'Herodotou', 'et', 'al', '.']

>> Bigrams are: 
 [('In', '['), ('[', '92'), ('92', ']'), (']', ','), (',', 'Herodotou'), ('Herodotou', 'et'), ('et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('In', '[', '92'), ('[', '92', ']'), ('92', ']', ','), (']', ',', 'Herodotou'), (',', 'Herodotou', 'et'), ('Herodotou', 'et', 'al'), ('et', 'al', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('[', '$'), ('92', 'CD'), (']', 'NNP'), (',', ','), ('Herodotou', 'NNP'), ('et', 'CC'), ('al', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 [']', 'Herodotou', 'al']

>> Named Entities are: 
 [('PERSON', 'Herodotou')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('[', '['), ('92', '92'), (']', ']'), (',', ','), ('Herodotou', 'herodot'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('[', '['), ('92', '92'), (']', ']'), (',', ','), ('Herodotou', 'herodotou'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('[', '['), ('92', '92'), (']', ']'), (',', ','), ('Herodotou', 'Herodotou'), ('et', 'et'), ('al', 'al'), ('.', '.')]


------------------- Sentence 9 -------------------

considered issues of the user needs and system workloads.

>> Tokens are: 
 ['considered', 'issues', 'user', 'needs', 'system', 'workloads', '.']

>> Bigrams are: 
 [('considered', 'issues'), ('issues', 'user'), ('user', 'needs'), ('needs', 'system'), ('system', 'workloads'), ('workloads', '.')]

>> Trigrams are: 
 [('considered', 'issues', 'user'), ('issues', 'user', 'needs'), ('user', 'needs', 'system'), ('needs', 'system', 'workloads'), ('system', 'workloads', '.')]

>> POS Tags are: 
 [('considered', 'VBN'), ('issues', 'NNS'), ('user', 'RBR'), ('needs', 'NNS'), ('system', 'NN'), ('workloads', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['issues', 'needs system workloads']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('considered', 'consid'), ('issues', 'issu'), ('user', 'user'), ('needs', 'need'), ('system', 'system'), ('workloads', 'workload'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('considered', 'consid'), ('issues', 'issu'), ('user', 'user'), ('needs', 'need'), ('system', 'system'), ('workloads', 'workload'), ('.', '.')]

>> Lemmatization: 
 [('considered', 'considered'), ('issues', 'issue'), ('user', 'user'), ('needs', 'need'), ('system', 'system'), ('workloads', 'workload'), ('.', '.')]


------------------- Sentence 10 -------------------

They presented a self- tuning analytics system built on Hadoop for big data analysis.

>> Tokens are: 
 ['They', 'presented', 'self-', 'tuning', 'analytics', 'system', 'built', 'Hadoop', 'big', 'data', 'analysis', '.']

>> Bigrams are: 
 [('They', 'presented'), ('presented', 'self-'), ('self-', 'tuning'), ('tuning', 'analytics'), ('analytics', 'system'), ('system', 'built'), ('built', 'Hadoop'), ('Hadoop', 'big'), ('big', 'data'), ('data', 'analysis'), ('analysis', '.')]

>> Trigrams are: 
 [('They', 'presented', 'self-'), ('presented', 'self-', 'tuning'), ('self-', 'tuning', 'analytics'), ('tuning', 'analytics', 'system'), ('analytics', 'system', 'built'), ('system', 'built', 'Hadoop'), ('built', 'Hadoop', 'big'), ('Hadoop', 'big', 'data'), ('big', 'data', 'analysis'), ('data', 'analysis', '.')]

>> POS Tags are: 
 [('They', 'PRP'), ('presented', 'VBD'), ('self-', 'JJ'), ('tuning', 'NN'), ('analytics', 'NNS'), ('system', 'NN'), ('built', 'VBN'), ('Hadoop', 'NNP'), ('big', 'JJ'), ('data', 'NNS'), ('analysis', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['self- tuning analytics system', 'Hadoop', 'big data analysis']

>> Named Entities are: 
 [('PERSON', 'Hadoop')] 

>> Stemming using Porter Stemmer: 
 [('They', 'they'), ('presented', 'present'), ('self-', 'self-'), ('tuning', 'tune'), ('analytics', 'analyt'), ('system', 'system'), ('built', 'built'), ('Hadoop', 'hadoop'), ('big', 'big'), ('data', 'data'), ('analysis', 'analysi'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('They', 'they'), ('presented', 'present'), ('self-', 'self-'), ('tuning', 'tune'), ('analytics', 'analyt'), ('system', 'system'), ('built', 'built'), ('Hadoop', 'hadoop'), ('big', 'big'), ('data', 'data'), ('analysis', 'analysi'), ('.', '.')]

>> Lemmatization: 
 [('They', 'They'), ('presented', 'presented'), ('self-', 'self-'), ('tuning', 'tuning'), ('analytics', 'analytics'), ('system', 'system'), ('built', 'built'), ('Hadoop', 'Hadoop'), ('big', 'big'), ('data', 'data'), ('analysis', 'analysis'), ('.', '.')]


------------------- Sentence 11 -------------------

Since one of the major  goals of their system is to adjust the system based on the user needs and system work- loads to provide good performance automatically, the user usually does not need to  understand and manipulate the Hadoop system.

>> Tokens are: 
 ['Since', 'one', 'major', 'goals', 'system', 'adjust', 'system', 'based', 'user', 'needs', 'system', 'work-', 'loads', 'provide', 'good', 'performance', 'automatically', ',', 'user', 'usually', 'need', 'understand', 'manipulate', 'Hadoop', 'system', '.']

>> Bigrams are: 
 [('Since', 'one'), ('one', 'major'), ('major', 'goals'), ('goals', 'system'), ('system', 'adjust'), ('adjust', 'system'), ('system', 'based'), ('based', 'user'), ('user', 'needs'), ('needs', 'system'), ('system', 'work-'), ('work-', 'loads'), ('loads', 'provide'), ('provide', 'good'), ('good', 'performance'), ('performance', 'automatically'), ('automatically', ','), (',', 'user'), ('user', 'usually'), ('usually', 'need'), ('need', 'understand'), ('understand', 'manipulate'), ('manipulate', 'Hadoop'), ('Hadoop', 'system'), ('system', '.')]

>> Trigrams are: 
 [('Since', 'one', 'major'), ('one', 'major', 'goals'), ('major', 'goals', 'system'), ('goals', 'system', 'adjust'), ('system', 'adjust', 'system'), ('adjust', 'system', 'based'), ('system', 'based', 'user'), ('based', 'user', 'needs'), ('user', 'needs', 'system'), ('needs', 'system', 'work-'), ('system', 'work-', 'loads'), ('work-', 'loads', 'provide'), ('loads', 'provide', 'good'), ('provide', 'good', 'performance'), ('good', 'performance', 'automatically'), ('performance', 'automatically', ','), ('automatically', ',', 'user'), (',', 'user', 'usually'), ('user', 'usually', 'need'), ('usually', 'need', 'understand'), ('need', 'understand', 'manipulate'), ('understand', 'manipulate', 'Hadoop'), ('manipulate', 'Hadoop', 'system'), ('Hadoop', 'system', '.')]

>> POS Tags are: 
 [('Since', 'IN'), ('one', 'CD'), ('major', 'JJ'), ('goals', 'NNS'), ('system', 'NN'), ('adjust', 'VBP'), ('system', 'NN'), ('based', 'VBN'), ('user', 'RB'), ('needs', 'JJ'), ('system', 'NN'), ('work-', 'JJ'), ('loads', 'NNS'), ('provide', 'RB'), ('good', 'JJ'), ('performance', 'NN'), ('automatically', 'RB'), (',', ','), ('user', 'PRP'), ('usually', 'RB'), ('need', 'VBP'), ('understand', 'JJ'), ('manipulate', 'VB'), ('Hadoop', 'NNP'), ('system', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['major goals system', 'system', 'needs system', 'work- loads', 'good performance', 'Hadoop system']

>> Named Entities are: 
 [('PERSON', 'Hadoop')] 

>> Stemming using Porter Stemmer: 
 [('Since', 'sinc'), ('one', 'one'), ('major', 'major'), ('goals', 'goal'), ('system', 'system'), ('adjust', 'adjust'), ('system', 'system'), ('based', 'base'), ('user', 'user'), ('needs', 'need'), ('system', 'system'), ('work-', 'work-'), ('loads', 'load'), ('provide', 'provid'), ('good', 'good'), ('performance', 'perform'), ('automatically', 'automat'), (',', ','), ('user', 'user'), ('usually', 'usual'), ('need', 'need'), ('understand', 'understand'), ('manipulate', 'manipul'), ('Hadoop', 'hadoop'), ('system', 'system'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Since', 'sinc'), ('one', 'one'), ('major', 'major'), ('goals', 'goal'), ('system', 'system'), ('adjust', 'adjust'), ('system', 'system'), ('based', 'base'), ('user', 'user'), ('needs', 'need'), ('system', 'system'), ('work-', 'work-'), ('loads', 'load'), ('provide', 'provid'), ('good', 'good'), ('performance', 'perform'), ('automatically', 'automat'), (',', ','), ('user', 'user'), ('usually', 'usual'), ('need', 'need'), ('understand', 'understand'), ('manipulate', 'manipul'), ('Hadoop', 'hadoop'), ('system', 'system'), ('.', '.')]

>> Lemmatization: 
 [('Since', 'Since'), ('one', 'one'), ('major', 'major'), ('goals', 'goal'), ('system', 'system'), ('adjust', 'adjust'), ('system', 'system'), ('based', 'based'), ('user', 'user'), ('needs', 'need'), ('system', 'system'), ('work-', 'work-'), ('loads', 'load'), ('provide', 'provide'), ('good', 'good'), ('performance', 'performance'), ('automatically', 'automatically'), (',', ','), ('user', 'user'), ('usually', 'usually'), ('need', 'need'), ('understand', 'understand'), ('manipulate', 'manipulate'), ('Hadoop', 'Hadoop'), ('system', 'system'), ('.', '.')]


------------------- Sentence 12 -------------------

The study [93] was from the perspec- tives of data centric architecture and operational models to presented a big data archi- tecture framework (BDAF) which includes: big data infrastructure, big data analytics,  data structures and models, big data lifecycle management, and big data security.

>> Tokens are: 
 ['The', 'study', '[', '93', ']', 'perspec-', 'tives', 'data', 'centric', 'architecture', 'operational', 'models', 'presented', 'big', 'data', 'archi-', 'tecture', 'framework', '(', 'BDAF', ')', 'includes', ':', 'big', 'data', 'infrastructure', ',', 'big', 'data', 'analytics', ',', 'data', 'structures', 'models', ',', 'big', 'data', 'lifecycle', 'management', ',', 'big', 'data', 'security', '.']

>> Bigrams are: 
 [('The', 'study'), ('study', '['), ('[', '93'), ('93', ']'), (']', 'perspec-'), ('perspec-', 'tives'), ('tives', 'data'), ('data', 'centric'), ('centric', 'architecture'), ('architecture', 'operational'), ('operational', 'models'), ('models', 'presented'), ('presented', 'big'), ('big', 'data'), ('data', 'archi-'), ('archi-', 'tecture'), ('tecture', 'framework'), ('framework', '('), ('(', 'BDAF'), ('BDAF', ')'), (')', 'includes'), ('includes', ':'), (':', 'big'), ('big', 'data'), ('data', 'infrastructure'), ('infrastructure', ','), (',', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', ','), (',', 'data'), ('data', 'structures'), ('structures', 'models'), ('models', ','), (',', 'big'), ('big', 'data'), ('data', 'lifecycle'), ('lifecycle', 'management'), ('management', ','), (',', 'big'), ('big', 'data'), ('data', 'security'), ('security', '.')]

>> Trigrams are: 
 [('The', 'study', '['), ('study', '[', '93'), ('[', '93', ']'), ('93', ']', 'perspec-'), (']', 'perspec-', 'tives'), ('perspec-', 'tives', 'data'), ('tives', 'data', 'centric'), ('data', 'centric', 'architecture'), ('centric', 'architecture', 'operational'), ('architecture', 'operational', 'models'), ('operational', 'models', 'presented'), ('models', 'presented', 'big'), ('presented', 'big', 'data'), ('big', 'data', 'archi-'), ('data', 'archi-', 'tecture'), ('archi-', 'tecture', 'framework'), ('tecture', 'framework', '('), ('framework', '(', 'BDAF'), ('(', 'BDAF', ')'), ('BDAF', ')', 'includes'), (')', 'includes', ':'), ('includes', ':', 'big'), (':', 'big', 'data'), ('big', 'data', 'infrastructure'), ('data', 'infrastructure', ','), ('infrastructure', ',', 'big'), (',', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', ','), ('analytics', ',', 'data'), (',', 'data', 'structures'), ('data', 'structures', 'models'), ('structures', 'models', ','), ('models', ',', 'big'), (',', 'big', 'data'), ('big', 'data', 'lifecycle'), ('data', 'lifecycle', 'management'), ('lifecycle', 'management', ','), ('management', ',', 'big'), (',', 'big', 'data'), ('big', 'data', 'security'), ('data', 'security', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('study', 'NN'), ('[', 'VBD'), ('93', 'CD'), (']', 'JJ'), ('perspec-', 'JJ'), ('tives', 'NNS'), ('data', 'NNS'), ('centric', 'JJ'), ('architecture', 'NN'), ('operational', 'JJ'), ('models', 'NNS'), ('presented', 'VBN'), ('big', 'JJ'), ('data', 'NNS'), ('archi-', 'JJ'), ('tecture', 'NN'), ('framework', 'NN'), ('(', '('), ('BDAF', 'NNP'), (')', ')'), ('includes', 'VBZ'), (':', ':'), ('big', 'JJ'), ('data', 'NNS'), ('infrastructure', 'NN'), (',', ','), ('big', 'JJ'), ('data', 'NN'), ('analytics', 'NNS'), (',', ','), ('data', 'NNS'), ('structures', 'NNS'), ('models', 'NNS'), (',', ','), ('big', 'JJ'), ('data', 'NNS'), ('lifecycle', 'NN'), ('management', 'NN'), (',', ','), ('big', 'JJ'), ('data', 'NNS'), ('security', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['The study', '] perspec- tives data', 'centric architecture', 'operational models', 'big data', 'archi- tecture framework', 'BDAF', 'big data infrastructure', 'big data analytics', 'data structures models', 'big data lifecycle management', 'big data security']

>> Named Entities are: 
 [('ORGANIZATION', 'BDAF')] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('study', 'studi'), ('[', '['), ('93', '93'), (']', ']'), ('perspec-', 'perspec-'), ('tives', 'tive'), ('data', 'data'), ('centric', 'centric'), ('architecture', 'architectur'), ('operational', 'oper'), ('models', 'model'), ('presented', 'present'), ('big', 'big'), ('data', 'data'), ('archi-', 'archi-'), ('tecture', 'tectur'), ('framework', 'framework'), ('(', '('), ('BDAF', 'bdaf'), (')', ')'), ('includes', 'includ'), (':', ':'), ('big', 'big'), ('data', 'data'), ('infrastructure', 'infrastructur'), (',', ','), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), (',', ','), ('data', 'data'), ('structures', 'structur'), ('models', 'model'), (',', ','), ('big', 'big'), ('data', 'data'), ('lifecycle', 'lifecycl'), ('management', 'manag'), (',', ','), ('big', 'big'), ('data', 'data'), ('security', 'secur'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('study', 'studi'), ('[', '['), ('93', '93'), (']', ']'), ('perspec-', 'perspec-'), ('tives', 'tive'), ('data', 'data'), ('centric', 'centric'), ('architecture', 'architectur'), ('operational', 'oper'), ('models', 'model'), ('presented', 'present'), ('big', 'big'), ('data', 'data'), ('archi-', 'archi-'), ('tecture', 'tectur'), ('framework', 'framework'), ('(', '('), ('BDAF', 'bdaf'), (')', ')'), ('includes', 'includ'), (':', ':'), ('big', 'big'), ('data', 'data'), ('infrastructure', 'infrastructur'), (',', ','), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), (',', ','), ('data', 'data'), ('structures', 'structur'), ('models', 'model'), (',', ','), ('big', 'big'), ('data', 'data'), ('lifecycle', 'lifecycl'), ('management', 'manag'), (',', ','), ('big', 'big'), ('data', 'data'), ('security', 'secur'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('study', 'study'), ('[', '['), ('93', '93'), (']', ']'), ('perspec-', 'perspec-'), ('tives', 'tives'), ('data', 'data'), ('centric', 'centric'), ('architecture', 'architecture'), ('operational', 'operational'), ('models', 'model'), ('presented', 'presented'), ('big', 'big'), ('data', 'data'), ('archi-', 'archi-'), ('tecture', 'tecture'), ('framework', 'framework'), ('(', '('), ('BDAF', 'BDAF'), (')', ')'), ('includes', 'includes'), (':', ':'), ('big', 'big'), ('data', 'data'), ('infrastructure', 'infrastructure'), (',', ','), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), (',', ','), ('data', 'data'), ('structures', 'structure'), ('models', 'model'), (',', ','), ('big', 'big'), ('data', 'data'), ('lifecycle', 'lifecycle'), ('management', 'management'), (',', ','), ('big', 'big'), ('data', 'data'), ('security', 'security'), ('.', '.')]


------------------- Sentence 13 -------------------

According to the observations of Demchenko et al.

>> Tokens are: 
 ['According', 'observations', 'Demchenko', 'et', 'al', '.']

>> Bigrams are: 
 [('According', 'observations'), ('observations', 'Demchenko'), ('Demchenko', 'et'), ('et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('According', 'observations', 'Demchenko'), ('observations', 'Demchenko', 'et'), ('Demchenko', 'et', 'al'), ('et', 'al', '.')]

>> POS Tags are: 
 [('According', 'VBG'), ('observations', 'NNS'), ('Demchenko', 'NNP'), ('et', 'CC'), ('al', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['observations Demchenko', 'al']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('According', 'accord'), ('observations', 'observ'), ('Demchenko', 'demchenko'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('According', 'accord'), ('observations', 'observ'), ('Demchenko', 'demchenko'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('According', 'According'), ('observations', 'observation'), ('Demchenko', 'Demchenko'), ('et', 'et'), ('al', 'al'), ('.', '.')]


------------------- Sentence 14 -------------------

[93], cluster services, Hadoop related  services, data analytics tools, databases, servers, and massively parallel processing data- bases are typically the required applications and services in big data analytics  infrastructure.

>> Tokens are: 
 ['[', '93', ']', ',', 'cluster', 'services', ',', 'Hadoop', 'related', 'services', ',', 'data', 'analytics', 'tools', ',', 'databases', ',', 'servers', ',', 'massively', 'parallel', 'processing', 'data-', 'bases', 'typically', 'required', 'applications', 'services', 'big', 'data', 'analytics', 'infrastructure', '.']

>> Bigrams are: 
 [('[', '93'), ('93', ']'), (']', ','), (',', 'cluster'), ('cluster', 'services'), ('services', ','), (',', 'Hadoop'), ('Hadoop', 'related'), ('related', 'services'), ('services', ','), (',', 'data'), ('data', 'analytics'), ('analytics', 'tools'), ('tools', ','), (',', 'databases'), ('databases', ','), (',', 'servers'), ('servers', ','), (',', 'massively'), ('massively', 'parallel'), ('parallel', 'processing'), ('processing', 'data-'), ('data-', 'bases'), ('bases', 'typically'), ('typically', 'required'), ('required', 'applications'), ('applications', 'services'), ('services', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', 'infrastructure'), ('infrastructure', '.')]

>> Trigrams are: 
 [('[', '93', ']'), ('93', ']', ','), (']', ',', 'cluster'), (',', 'cluster', 'services'), ('cluster', 'services', ','), ('services', ',', 'Hadoop'), (',', 'Hadoop', 'related'), ('Hadoop', 'related', 'services'), ('related', 'services', ','), ('services', ',', 'data'), (',', 'data', 'analytics'), ('data', 'analytics', 'tools'), ('analytics', 'tools', ','), ('tools', ',', 'databases'), (',', 'databases', ','), ('databases', ',', 'servers'), (',', 'servers', ','), ('servers', ',', 'massively'), (',', 'massively', 'parallel'), ('massively', 'parallel', 'processing'), ('parallel', 'processing', 'data-'), ('processing', 'data-', 'bases'), ('data-', 'bases', 'typically'), ('bases', 'typically', 'required'), ('typically', 'required', 'applications'), ('required', 'applications', 'services'), ('applications', 'services', 'big'), ('services', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', 'infrastructure'), ('analytics', 'infrastructure', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('93', 'CD'), (']', 'NNS'), (',', ','), ('cluster', 'NN'), ('services', 'NNS'), (',', ','), ('Hadoop', 'NNP'), ('related', 'VBD'), ('services', 'NNS'), (',', ','), ('data', 'NNS'), ('analytics', 'NNS'), ('tools', 'NNS'), (',', ','), ('databases', 'NNS'), (',', ','), ('servers', 'NNS'), (',', ','), ('massively', 'RB'), ('parallel', 'JJ'), ('processing', 'VBG'), ('data-', 'JJ'), ('bases', 'NNS'), ('typically', 'RB'), ('required', 'VBN'), ('applications', 'NNS'), ('services', 'NNS'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('infrastructure', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 [']', 'cluster services', 'Hadoop', 'services', 'data analytics tools', 'databases', 'servers', 'data- bases', 'applications services', 'big data analytics infrastructure']

>> Named Entities are: 
 [('PERSON', 'Hadoop')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('93', '93'), (']', ']'), (',', ','), ('cluster', 'cluster'), ('services', 'servic'), (',', ','), ('Hadoop', 'hadoop'), ('related', 'relat'), ('services', 'servic'), (',', ','), ('data', 'data'), ('analytics', 'analyt'), ('tools', 'tool'), (',', ','), ('databases', 'databas'), (',', ','), ('servers', 'server'), (',', ','), ('massively', 'massiv'), ('parallel', 'parallel'), ('processing', 'process'), ('data-', 'data-'), ('bases', 'base'), ('typically', 'typic'), ('required', 'requir'), ('applications', 'applic'), ('services', 'servic'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('infrastructure', 'infrastructur'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('93', '93'), (']', ']'), (',', ','), ('cluster', 'cluster'), ('services', 'servic'), (',', ','), ('Hadoop', 'hadoop'), ('related', 'relat'), ('services', 'servic'), (',', ','), ('data', 'data'), ('analytics', 'analyt'), ('tools', 'tool'), (',', ','), ('databases', 'databas'), (',', ','), ('servers', 'server'), (',', ','), ('massively', 'massiv'), ('parallel', 'parallel'), ('processing', 'process'), ('data-', 'data-'), ('bases', 'base'), ('typically', 'typic'), ('required', 'requir'), ('applications', 'applic'), ('services', 'servic'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('infrastructure', 'infrastructur'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('93', '93'), (']', ']'), (',', ','), ('cluster', 'cluster'), ('services', 'service'), (',', ','), ('Hadoop', 'Hadoop'), ('related', 'related'), ('services', 'service'), (',', ','), ('data', 'data'), ('analytics', 'analytics'), ('tools', 'tool'), (',', ','), ('databases', 'database'), (',', ','), ('servers', 'server'), (',', ','), ('massively', 'massively'), ('parallel', 'parallel'), ('processing', 'processing'), ('data-', 'data-'), ('bases', 'base'), ('typically', 'typically'), ('required', 'required'), ('applications', 'application'), ('services', 'service'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('infrastructure', 'infrastructure'), ('.', '.')]



========================================== PARAGRAPH 246 ===========================================

Result-oriented Fisher et al. [5] presented a big data pipeline to show the workflow of  big data analytics to extract the valuable knowledge from big data, which consists of the  acquired data, choosing architecture, shaping data into architecture, coding/debugging,  and reflecting works. From the perspectives of statistical computation and data mining,  Ye et  al. [94] presented an architecture of the services platform which integrates R to  provide better data analysis services, called cloud-based big data mining and analyzing  services platform (CBDMASP). The design of this platform is composed of four layers:  the infrastructure services layer, the virtualization layer, the dataset processing layer,  and the services layer. Several large-scale clustering problems (the datasets are of size  from 0.1 G up to 25.6 G) were also used to evaluate the performance of the CBDMASP.  The simulation results show that using map-reduce is much faster than using a single  machine when the input data become too large. Although the size of the test dataset  cannot be regarded as a big dataset, the performance of the big data analytics using map- reduce can be sped up via this kind of testings. In this study, map-reduce is a better solu- tion when the dataset is of size more than 0.2 G, and a single machine is unable to handle  a dataset that is of size more than 1.6 G. 

------------------- Sentence 1 -------------------

Result-oriented Fisher et al.

>> Tokens are: 
 ['Result-oriented', 'Fisher', 'et', 'al', '.']

>> Bigrams are: 
 [('Result-oriented', 'Fisher'), ('Fisher', 'et'), ('et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('Result-oriented', 'Fisher', 'et'), ('Fisher', 'et', 'al'), ('et', 'al', '.')]

>> POS Tags are: 
 [('Result-oriented', 'JJ'), ('Fisher', 'NNP'), ('et', 'NN'), ('al', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Result-oriented Fisher et al']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Result-oriented', 'result-ori'), ('Fisher', 'fisher'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Result-oriented', 'result-ori'), ('Fisher', 'fisher'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('Result-oriented', 'Result-oriented'), ('Fisher', 'Fisher'), ('et', 'et'), ('al', 'al'), ('.', '.')]


------------------- Sentence 2 -------------------

[5] presented a big data pipeline to show the workflow of  big data analytics to extract the valuable knowledge from big data, which consists of the  acquired data, choosing architecture, shaping data into architecture, coding/debugging,  and reflecting works.

>> Tokens are: 
 ['[', '5', ']', 'presented', 'big', 'data', 'pipeline', 'show', 'workflow', 'big', 'data', 'analytics', 'extract', 'valuable', 'knowledge', 'big', 'data', ',', 'consists', 'acquired', 'data', ',', 'choosing', 'architecture', ',', 'shaping', 'data', 'architecture', ',', 'coding/debugging', ',', 'reflecting', 'works', '.']

>> Bigrams are: 
 [('[', '5'), ('5', ']'), (']', 'presented'), ('presented', 'big'), ('big', 'data'), ('data', 'pipeline'), ('pipeline', 'show'), ('show', 'workflow'), ('workflow', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', 'extract'), ('extract', 'valuable'), ('valuable', 'knowledge'), ('knowledge', 'big'), ('big', 'data'), ('data', ','), (',', 'consists'), ('consists', 'acquired'), ('acquired', 'data'), ('data', ','), (',', 'choosing'), ('choosing', 'architecture'), ('architecture', ','), (',', 'shaping'), ('shaping', 'data'), ('data', 'architecture'), ('architecture', ','), (',', 'coding/debugging'), ('coding/debugging', ','), (',', 'reflecting'), ('reflecting', 'works'), ('works', '.')]

>> Trigrams are: 
 [('[', '5', ']'), ('5', ']', 'presented'), (']', 'presented', 'big'), ('presented', 'big', 'data'), ('big', 'data', 'pipeline'), ('data', 'pipeline', 'show'), ('pipeline', 'show', 'workflow'), ('show', 'workflow', 'big'), ('workflow', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', 'extract'), ('analytics', 'extract', 'valuable'), ('extract', 'valuable', 'knowledge'), ('valuable', 'knowledge', 'big'), ('knowledge', 'big', 'data'), ('big', 'data', ','), ('data', ',', 'consists'), (',', 'consists', 'acquired'), ('consists', 'acquired', 'data'), ('acquired', 'data', ','), ('data', ',', 'choosing'), (',', 'choosing', 'architecture'), ('choosing', 'architecture', ','), ('architecture', ',', 'shaping'), (',', 'shaping', 'data'), ('shaping', 'data', 'architecture'), ('data', 'architecture', ','), ('architecture', ',', 'coding/debugging'), (',', 'coding/debugging', ','), ('coding/debugging', ',', 'reflecting'), (',', 'reflecting', 'works'), ('reflecting', 'works', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('5', 'CD'), (']', 'NNS'), ('presented', 'VBN'), ('big', 'JJ'), ('data', 'NNS'), ('pipeline', 'NN'), ('show', 'NN'), ('workflow', 'VBP'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('extract', 'JJ'), ('valuable', 'JJ'), ('knowledge', 'NN'), ('big', 'JJ'), ('data', 'NNS'), (',', ','), ('consists', 'VBZ'), ('acquired', 'VBN'), ('data', 'NNS'), (',', ','), ('choosing', 'VBG'), ('architecture', 'NN'), (',', ','), ('shaping', 'VBG'), ('data', 'NNS'), ('architecture', 'NN'), (',', ','), ('coding/debugging', 'VBG'), (',', ','), ('reflecting', 'VBG'), ('works', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 [']', 'big data pipeline show', 'big data analytics', 'extract valuable knowledge', 'big data', 'data', 'architecture', 'data architecture', 'works']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('5', '5'), (']', ']'), ('presented', 'present'), ('big', 'big'), ('data', 'data'), ('pipeline', 'pipelin'), ('show', 'show'), ('workflow', 'workflow'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('extract', 'extract'), ('valuable', 'valuabl'), ('knowledge', 'knowledg'), ('big', 'big'), ('data', 'data'), (',', ','), ('consists', 'consist'), ('acquired', 'acquir'), ('data', 'data'), (',', ','), ('choosing', 'choos'), ('architecture', 'architectur'), (',', ','), ('shaping', 'shape'), ('data', 'data'), ('architecture', 'architectur'), (',', ','), ('coding/debugging', 'coding/debug'), (',', ','), ('reflecting', 'reflect'), ('works', 'work'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('5', '5'), (']', ']'), ('presented', 'present'), ('big', 'big'), ('data', 'data'), ('pipeline', 'pipelin'), ('show', 'show'), ('workflow', 'workflow'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('extract', 'extract'), ('valuable', 'valuabl'), ('knowledge', 'knowledg'), ('big', 'big'), ('data', 'data'), (',', ','), ('consists', 'consist'), ('acquired', 'acquir'), ('data', 'data'), (',', ','), ('choosing', 'choos'), ('architecture', 'architectur'), (',', ','), ('shaping', 'shape'), ('data', 'data'), ('architecture', 'architectur'), (',', ','), ('coding/debugging', 'coding/debug'), (',', ','), ('reflecting', 'reflect'), ('works', 'work'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('5', '5'), (']', ']'), ('presented', 'presented'), ('big', 'big'), ('data', 'data'), ('pipeline', 'pipeline'), ('show', 'show'), ('workflow', 'workflow'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('extract', 'extract'), ('valuable', 'valuable'), ('knowledge', 'knowledge'), ('big', 'big'), ('data', 'data'), (',', ','), ('consists', 'consists'), ('acquired', 'acquired'), ('data', 'data'), (',', ','), ('choosing', 'choosing'), ('architecture', 'architecture'), (',', ','), ('shaping', 'shaping'), ('data', 'data'), ('architecture', 'architecture'), (',', ','), ('coding/debugging', 'coding/debugging'), (',', ','), ('reflecting', 'reflecting'), ('works', 'work'), ('.', '.')]


------------------- Sentence 3 -------------------

From the perspectives of statistical computation and data mining,  Ye et  al.

>> Tokens are: 
 ['From', 'perspectives', 'statistical', 'computation', 'data', 'mining', ',', 'Ye', 'et', 'al', '.']

>> Bigrams are: 
 [('From', 'perspectives'), ('perspectives', 'statistical'), ('statistical', 'computation'), ('computation', 'data'), ('data', 'mining'), ('mining', ','), (',', 'Ye'), ('Ye', 'et'), ('et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('From', 'perspectives', 'statistical'), ('perspectives', 'statistical', 'computation'), ('statistical', 'computation', 'data'), ('computation', 'data', 'mining'), ('data', 'mining', ','), ('mining', ',', 'Ye'), (',', 'Ye', 'et'), ('Ye', 'et', 'al'), ('et', 'al', '.')]

>> POS Tags are: 
 [('From', 'IN'), ('perspectives', 'NNS'), ('statistical', 'JJ'), ('computation', 'NN'), ('data', 'NNS'), ('mining', 'NN'), (',', ','), ('Ye', 'NNP'), ('et', 'CC'), ('al', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['perspectives', 'statistical computation data mining', 'Ye', 'al']

>> Named Entities are: 
 [('PERSON', 'Ye')] 

>> Stemming using Porter Stemmer: 
 [('From', 'from'), ('perspectives', 'perspect'), ('statistical', 'statist'), ('computation', 'comput'), ('data', 'data'), ('mining', 'mine'), (',', ','), ('Ye', 'ye'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('From', 'from'), ('perspectives', 'perspect'), ('statistical', 'statist'), ('computation', 'comput'), ('data', 'data'), ('mining', 'mine'), (',', ','), ('Ye', 'ye'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('From', 'From'), ('perspectives', 'perspective'), ('statistical', 'statistical'), ('computation', 'computation'), ('data', 'data'), ('mining', 'mining'), (',', ','), ('Ye', 'Ye'), ('et', 'et'), ('al', 'al'), ('.', '.')]


------------------- Sentence 4 -------------------

[94] presented an architecture of the services platform which integrates R to  provide better data analysis services, called cloud-based big data mining and analyzing  services platform (CBDMASP).

>> Tokens are: 
 ['[', '94', ']', 'presented', 'architecture', 'services', 'platform', 'integrates', 'R', 'provide', 'better', 'data', 'analysis', 'services', ',', 'called', 'cloud-based', 'big', 'data', 'mining', 'analyzing', 'services', 'platform', '(', 'CBDMASP', ')', '.']

>> Bigrams are: 
 [('[', '94'), ('94', ']'), (']', 'presented'), ('presented', 'architecture'), ('architecture', 'services'), ('services', 'platform'), ('platform', 'integrates'), ('integrates', 'R'), ('R', 'provide'), ('provide', 'better'), ('better', 'data'), ('data', 'analysis'), ('analysis', 'services'), ('services', ','), (',', 'called'), ('called', 'cloud-based'), ('cloud-based', 'big'), ('big', 'data'), ('data', 'mining'), ('mining', 'analyzing'), ('analyzing', 'services'), ('services', 'platform'), ('platform', '('), ('(', 'CBDMASP'), ('CBDMASP', ')'), (')', '.')]

>> Trigrams are: 
 [('[', '94', ']'), ('94', ']', 'presented'), (']', 'presented', 'architecture'), ('presented', 'architecture', 'services'), ('architecture', 'services', 'platform'), ('services', 'platform', 'integrates'), ('platform', 'integrates', 'R'), ('integrates', 'R', 'provide'), ('R', 'provide', 'better'), ('provide', 'better', 'data'), ('better', 'data', 'analysis'), ('data', 'analysis', 'services'), ('analysis', 'services', ','), ('services', ',', 'called'), (',', 'called', 'cloud-based'), ('called', 'cloud-based', 'big'), ('cloud-based', 'big', 'data'), ('big', 'data', 'mining'), ('data', 'mining', 'analyzing'), ('mining', 'analyzing', 'services'), ('analyzing', 'services', 'platform'), ('services', 'platform', '('), ('platform', '(', 'CBDMASP'), ('(', 'CBDMASP', ')'), ('CBDMASP', ')', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('94', 'CD'), (']', 'NNS'), ('presented', 'VBN'), ('architecture', 'NN'), ('services', 'NNS'), ('platform', 'NN'), ('integrates', 'VBZ'), ('R', 'NNP'), ('provide', 'VBP'), ('better', 'JJR'), ('data', 'NN'), ('analysis', 'NN'), ('services', 'NNS'), (',', ','), ('called', 'VBN'), ('cloud-based', 'JJ'), ('big', 'JJ'), ('data', 'NNS'), ('mining', 'NN'), ('analyzing', 'NN'), ('services', 'NNS'), ('platform', 'NN'), ('(', '('), ('CBDMASP', 'NNP'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 [']', 'architecture services platform', 'R', 'data analysis services', 'cloud-based big data mining analyzing services platform', 'CBDMASP']

>> Named Entities are: 
 [('ORGANIZATION', 'CBDMASP')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('94', '94'), (']', ']'), ('presented', 'present'), ('architecture', 'architectur'), ('services', 'servic'), ('platform', 'platform'), ('integrates', 'integr'), ('R', 'r'), ('provide', 'provid'), ('better', 'better'), ('data', 'data'), ('analysis', 'analysi'), ('services', 'servic'), (',', ','), ('called', 'call'), ('cloud-based', 'cloud-bas'), ('big', 'big'), ('data', 'data'), ('mining', 'mine'), ('analyzing', 'analyz'), ('services', 'servic'), ('platform', 'platform'), ('(', '('), ('CBDMASP', 'cbdmasp'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('94', '94'), (']', ']'), ('presented', 'present'), ('architecture', 'architectur'), ('services', 'servic'), ('platform', 'platform'), ('integrates', 'integr'), ('R', 'r'), ('provide', 'provid'), ('better', 'better'), ('data', 'data'), ('analysis', 'analysi'), ('services', 'servic'), (',', ','), ('called', 'call'), ('cloud-based', 'cloud-bas'), ('big', 'big'), ('data', 'data'), ('mining', 'mine'), ('analyzing', 'analyz'), ('services', 'servic'), ('platform', 'platform'), ('(', '('), ('CBDMASP', 'cbdmasp'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('94', '94'), (']', ']'), ('presented', 'presented'), ('architecture', 'architecture'), ('services', 'service'), ('platform', 'platform'), ('integrates', 'integrates'), ('R', 'R'), ('provide', 'provide'), ('better', 'better'), ('data', 'data'), ('analysis', 'analysis'), ('services', 'service'), (',', ','), ('called', 'called'), ('cloud-based', 'cloud-based'), ('big', 'big'), ('data', 'data'), ('mining', 'mining'), ('analyzing', 'analyzing'), ('services', 'service'), ('platform', 'platform'), ('(', '('), ('CBDMASP', 'CBDMASP'), (')', ')'), ('.', '.')]


------------------- Sentence 5 -------------------

The design of this platform is composed of four layers:  the infrastructure services layer, the virtualization layer, the dataset processing layer,  and the services layer.

>> Tokens are: 
 ['The', 'design', 'platform', 'composed', 'four', 'layers', ':', 'infrastructure', 'services', 'layer', ',', 'virtualization', 'layer', ',', 'dataset', 'processing', 'layer', ',', 'services', 'layer', '.']

>> Bigrams are: 
 [('The', 'design'), ('design', 'platform'), ('platform', 'composed'), ('composed', 'four'), ('four', 'layers'), ('layers', ':'), (':', 'infrastructure'), ('infrastructure', 'services'), ('services', 'layer'), ('layer', ','), (',', 'virtualization'), ('virtualization', 'layer'), ('layer', ','), (',', 'dataset'), ('dataset', 'processing'), ('processing', 'layer'), ('layer', ','), (',', 'services'), ('services', 'layer'), ('layer', '.')]

>> Trigrams are: 
 [('The', 'design', 'platform'), ('design', 'platform', 'composed'), ('platform', 'composed', 'four'), ('composed', 'four', 'layers'), ('four', 'layers', ':'), ('layers', ':', 'infrastructure'), (':', 'infrastructure', 'services'), ('infrastructure', 'services', 'layer'), ('services', 'layer', ','), ('layer', ',', 'virtualization'), (',', 'virtualization', 'layer'), ('virtualization', 'layer', ','), ('layer', ',', 'dataset'), (',', 'dataset', 'processing'), ('dataset', 'processing', 'layer'), ('processing', 'layer', ','), ('layer', ',', 'services'), (',', 'services', 'layer'), ('services', 'layer', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('design', 'NN'), ('platform', 'NN'), ('composed', 'VBD'), ('four', 'CD'), ('layers', 'NNS'), (':', ':'), ('infrastructure', 'NN'), ('services', 'NNS'), ('layer', 'NN'), (',', ','), ('virtualization', 'NN'), ('layer', 'NN'), (',', ','), ('dataset', 'NN'), ('processing', 'NN'), ('layer', 'NN'), (',', ','), ('services', 'NNS'), ('layer', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['The design platform', 'layers', 'infrastructure services layer', 'virtualization layer', 'dataset processing layer', 'services layer']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('design', 'design'), ('platform', 'platform'), ('composed', 'compos'), ('four', 'four'), ('layers', 'layer'), (':', ':'), ('infrastructure', 'infrastructur'), ('services', 'servic'), ('layer', 'layer'), (',', ','), ('virtualization', 'virtual'), ('layer', 'layer'), (',', ','), ('dataset', 'dataset'), ('processing', 'process'), ('layer', 'layer'), (',', ','), ('services', 'servic'), ('layer', 'layer'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('design', 'design'), ('platform', 'platform'), ('composed', 'compos'), ('four', 'four'), ('layers', 'layer'), (':', ':'), ('infrastructure', 'infrastructur'), ('services', 'servic'), ('layer', 'layer'), (',', ','), ('virtualization', 'virtual'), ('layer', 'layer'), (',', ','), ('dataset', 'dataset'), ('processing', 'process'), ('layer', 'layer'), (',', ','), ('services', 'servic'), ('layer', 'layer'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('design', 'design'), ('platform', 'platform'), ('composed', 'composed'), ('four', 'four'), ('layers', 'layer'), (':', ':'), ('infrastructure', 'infrastructure'), ('services', 'service'), ('layer', 'layer'), (',', ','), ('virtualization', 'virtualization'), ('layer', 'layer'), (',', ','), ('dataset', 'dataset'), ('processing', 'processing'), ('layer', 'layer'), (',', ','), ('services', 'service'), ('layer', 'layer'), ('.', '.')]


------------------- Sentence 6 -------------------

Several large-scale clustering problems (the datasets are of size  from 0.1 G up to 25.6 G) were also used to evaluate the performance of the CBDMASP.

>> Tokens are: 
 ['Several', 'large-scale', 'clustering', 'problems', '(', 'datasets', 'size', '0.1', 'G', '25.6', 'G', ')', 'also', 'used', 'evaluate', 'performance', 'CBDMASP', '.']

>> Bigrams are: 
 [('Several', 'large-scale'), ('large-scale', 'clustering'), ('clustering', 'problems'), ('problems', '('), ('(', 'datasets'), ('datasets', 'size'), ('size', '0.1'), ('0.1', 'G'), ('G', '25.6'), ('25.6', 'G'), ('G', ')'), (')', 'also'), ('also', 'used'), ('used', 'evaluate'), ('evaluate', 'performance'), ('performance', 'CBDMASP'), ('CBDMASP', '.')]

>> Trigrams are: 
 [('Several', 'large-scale', 'clustering'), ('large-scale', 'clustering', 'problems'), ('clustering', 'problems', '('), ('problems', '(', 'datasets'), ('(', 'datasets', 'size'), ('datasets', 'size', '0.1'), ('size', '0.1', 'G'), ('0.1', 'G', '25.6'), ('G', '25.6', 'G'), ('25.6', 'G', ')'), ('G', ')', 'also'), (')', 'also', 'used'), ('also', 'used', 'evaluate'), ('used', 'evaluate', 'performance'), ('evaluate', 'performance', 'CBDMASP'), ('performance', 'CBDMASP', '.')]

>> POS Tags are: 
 [('Several', 'JJ'), ('large-scale', 'JJ'), ('clustering', 'NN'), ('problems', 'NNS'), ('(', '('), ('datasets', 'NNS'), ('size', 'NN'), ('0.1', 'CD'), ('G', 'NNP'), ('25.6', 'CD'), ('G', 'NNP'), (')', ')'), ('also', 'RB'), ('used', 'VBN'), ('evaluate', 'JJ'), ('performance', 'NN'), ('CBDMASP', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Several large-scale clustering problems', 'datasets size', 'G', 'G', 'evaluate performance CBDMASP']

>> Named Entities are: 
 [('ORGANIZATION', 'CBDMASP')] 

>> Stemming using Porter Stemmer: 
 [('Several', 'sever'), ('large-scale', 'large-scal'), ('clustering', 'cluster'), ('problems', 'problem'), ('(', '('), ('datasets', 'dataset'), ('size', 'size'), ('0.1', '0.1'), ('G', 'g'), ('25.6', '25.6'), ('G', 'g'), (')', ')'), ('also', 'also'), ('used', 'use'), ('evaluate', 'evalu'), ('performance', 'perform'), ('CBDMASP', 'cbdmasp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Several', 'sever'), ('large-scale', 'large-scal'), ('clustering', 'cluster'), ('problems', 'problem'), ('(', '('), ('datasets', 'dataset'), ('size', 'size'), ('0.1', '0.1'), ('G', 'g'), ('25.6', '25.6'), ('G', 'g'), (')', ')'), ('also', 'also'), ('used', 'use'), ('evaluate', 'evalu'), ('performance', 'perform'), ('CBDMASP', 'cbdmasp'), ('.', '.')]

>> Lemmatization: 
 [('Several', 'Several'), ('large-scale', 'large-scale'), ('clustering', 'clustering'), ('problems', 'problem'), ('(', '('), ('datasets', 'datasets'), ('size', 'size'), ('0.1', '0.1'), ('G', 'G'), ('25.6', '25.6'), ('G', 'G'), (')', ')'), ('also', 'also'), ('used', 'used'), ('evaluate', 'evaluate'), ('performance', 'performance'), ('CBDMASP', 'CBDMASP'), ('.', '.')]


------------------- Sentence 7 -------------------

The simulation results show that using map-reduce is much faster than using a single  machine when the input data become too large.

>> Tokens are: 
 ['The', 'simulation', 'results', 'show', 'using', 'map-reduce', 'much', 'faster', 'using', 'single', 'machine', 'input', 'data', 'become', 'large', '.']

>> Bigrams are: 
 [('The', 'simulation'), ('simulation', 'results'), ('results', 'show'), ('show', 'using'), ('using', 'map-reduce'), ('map-reduce', 'much'), ('much', 'faster'), ('faster', 'using'), ('using', 'single'), ('single', 'machine'), ('machine', 'input'), ('input', 'data'), ('data', 'become'), ('become', 'large'), ('large', '.')]

>> Trigrams are: 
 [('The', 'simulation', 'results'), ('simulation', 'results', 'show'), ('results', 'show', 'using'), ('show', 'using', 'map-reduce'), ('using', 'map-reduce', 'much'), ('map-reduce', 'much', 'faster'), ('much', 'faster', 'using'), ('faster', 'using', 'single'), ('using', 'single', 'machine'), ('single', 'machine', 'input'), ('machine', 'input', 'data'), ('input', 'data', 'become'), ('data', 'become', 'large'), ('become', 'large', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('simulation', 'NN'), ('results', 'NNS'), ('show', 'VBP'), ('using', 'VBG'), ('map-reduce', 'JJ'), ('much', 'JJ'), ('faster', 'RBR'), ('using', 'VBG'), ('single', 'JJ'), ('machine', 'NN'), ('input', 'NN'), ('data', 'NNS'), ('become', 'VB'), ('large', 'JJ'), ('.', '.')]

>> Noun Phrases are: 
 ['The simulation results', 'single machine input data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('simulation', 'simul'), ('results', 'result'), ('show', 'show'), ('using', 'use'), ('map-reduce', 'map-reduc'), ('much', 'much'), ('faster', 'faster'), ('using', 'use'), ('single', 'singl'), ('machine', 'machin'), ('input', 'input'), ('data', 'data'), ('become', 'becom'), ('large', 'larg'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('simulation', 'simul'), ('results', 'result'), ('show', 'show'), ('using', 'use'), ('map-reduce', 'map-reduc'), ('much', 'much'), ('faster', 'faster'), ('using', 'use'), ('single', 'singl'), ('machine', 'machin'), ('input', 'input'), ('data', 'data'), ('become', 'becom'), ('large', 'larg'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('simulation', 'simulation'), ('results', 'result'), ('show', 'show'), ('using', 'using'), ('map-reduce', 'map-reduce'), ('much', 'much'), ('faster', 'faster'), ('using', 'using'), ('single', 'single'), ('machine', 'machine'), ('input', 'input'), ('data', 'data'), ('become', 'become'), ('large', 'large'), ('.', '.')]


------------------- Sentence 8 -------------------

Although the size of the test dataset  cannot be regarded as a big dataset, the performance of the big data analytics using map- reduce can be sped up via this kind of testings.

>> Tokens are: 
 ['Although', 'size', 'test', 'dataset', 'regarded', 'big', 'dataset', ',', 'performance', 'big', 'data', 'analytics', 'using', 'map-', 'reduce', 'sped', 'via', 'kind', 'testings', '.']

>> Bigrams are: 
 [('Although', 'size'), ('size', 'test'), ('test', 'dataset'), ('dataset', 'regarded'), ('regarded', 'big'), ('big', 'dataset'), ('dataset', ','), (',', 'performance'), ('performance', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', 'using'), ('using', 'map-'), ('map-', 'reduce'), ('reduce', 'sped'), ('sped', 'via'), ('via', 'kind'), ('kind', 'testings'), ('testings', '.')]

>> Trigrams are: 
 [('Although', 'size', 'test'), ('size', 'test', 'dataset'), ('test', 'dataset', 'regarded'), ('dataset', 'regarded', 'big'), ('regarded', 'big', 'dataset'), ('big', 'dataset', ','), ('dataset', ',', 'performance'), (',', 'performance', 'big'), ('performance', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', 'using'), ('analytics', 'using', 'map-'), ('using', 'map-', 'reduce'), ('map-', 'reduce', 'sped'), ('reduce', 'sped', 'via'), ('sped', 'via', 'kind'), ('via', 'kind', 'testings'), ('kind', 'testings', '.')]

>> POS Tags are: 
 [('Although', 'IN'), ('size', 'NN'), ('test', 'NN'), ('dataset', 'NN'), ('regarded', 'VBD'), ('big', 'JJ'), ('dataset', 'NN'), (',', ','), ('performance', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('using', 'VBG'), ('map-', 'JJ'), ('reduce', 'VB'), ('sped', 'JJ'), ('via', 'IN'), ('kind', 'NN'), ('testings', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['size test dataset', 'big dataset', 'performance', 'big data analytics', 'kind testings']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Although', 'although'), ('size', 'size'), ('test', 'test'), ('dataset', 'dataset'), ('regarded', 'regard'), ('big', 'big'), ('dataset', 'dataset'), (',', ','), ('performance', 'perform'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('using', 'use'), ('map-', 'map-'), ('reduce', 'reduc'), ('sped', 'sped'), ('via', 'via'), ('kind', 'kind'), ('testings', 'test'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Although', 'although'), ('size', 'size'), ('test', 'test'), ('dataset', 'dataset'), ('regarded', 'regard'), ('big', 'big'), ('dataset', 'dataset'), (',', ','), ('performance', 'perform'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('using', 'use'), ('map-', 'map-'), ('reduce', 'reduc'), ('sped', 'sped'), ('via', 'via'), ('kind', 'kind'), ('testings', 'test'), ('.', '.')]

>> Lemmatization: 
 [('Although', 'Although'), ('size', 'size'), ('test', 'test'), ('dataset', 'dataset'), ('regarded', 'regarded'), ('big', 'big'), ('dataset', 'dataset'), (',', ','), ('performance', 'performance'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('using', 'using'), ('map-', 'map-'), ('reduce', 'reduce'), ('sped', 'sped'), ('via', 'via'), ('kind', 'kind'), ('testings', 'testing'), ('.', '.')]


------------------- Sentence 9 -------------------

In this study, map-reduce is a better solu- tion when the dataset is of size more than 0.2 G, and a single machine is unable to handle  a dataset that is of size more than 1.6 G.

>> Tokens are: 
 ['In', 'study', ',', 'map-reduce', 'better', 'solu-', 'tion', 'dataset', 'size', '0.2', 'G', ',', 'single', 'machine', 'unable', 'handle', 'dataset', 'size', '1.6', 'G', '.']

>> Bigrams are: 
 [('In', 'study'), ('study', ','), (',', 'map-reduce'), ('map-reduce', 'better'), ('better', 'solu-'), ('solu-', 'tion'), ('tion', 'dataset'), ('dataset', 'size'), ('size', '0.2'), ('0.2', 'G'), ('G', ','), (',', 'single'), ('single', 'machine'), ('machine', 'unable'), ('unable', 'handle'), ('handle', 'dataset'), ('dataset', 'size'), ('size', '1.6'), ('1.6', 'G'), ('G', '.')]

>> Trigrams are: 
 [('In', 'study', ','), ('study', ',', 'map-reduce'), (',', 'map-reduce', 'better'), ('map-reduce', 'better', 'solu-'), ('better', 'solu-', 'tion'), ('solu-', 'tion', 'dataset'), ('tion', 'dataset', 'size'), ('dataset', 'size', '0.2'), ('size', '0.2', 'G'), ('0.2', 'G', ','), ('G', ',', 'single'), (',', 'single', 'machine'), ('single', 'machine', 'unable'), ('machine', 'unable', 'handle'), ('unable', 'handle', 'dataset'), ('handle', 'dataset', 'size'), ('dataset', 'size', '1.6'), ('size', '1.6', 'G'), ('1.6', 'G', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('study', 'NN'), (',', ','), ('map-reduce', 'JJ'), ('better', 'RBR'), ('solu-', 'JJ'), ('tion', 'NN'), ('dataset', 'NN'), ('size', 'NN'), ('0.2', 'CD'), ('G', 'NNP'), (',', ','), ('single', 'JJ'), ('machine', 'NN'), ('unable', 'JJ'), ('handle', 'JJ'), ('dataset', 'NN'), ('size', 'NN'), ('1.6', 'CD'), ('G', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['study', 'solu- tion dataset size', 'G', 'single machine', 'unable handle dataset size', 'G']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('study', 'studi'), (',', ','), ('map-reduce', 'map-reduc'), ('better', 'better'), ('solu-', 'solu-'), ('tion', 'tion'), ('dataset', 'dataset'), ('size', 'size'), ('0.2', '0.2'), ('G', 'g'), (',', ','), ('single', 'singl'), ('machine', 'machin'), ('unable', 'unabl'), ('handle', 'handl'), ('dataset', 'dataset'), ('size', 'size'), ('1.6', '1.6'), ('G', 'g'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('study', 'studi'), (',', ','), ('map-reduce', 'map-reduc'), ('better', 'better'), ('solu-', 'solu-'), ('tion', 'tion'), ('dataset', 'dataset'), ('size', 'size'), ('0.2', '0.2'), ('G', 'g'), (',', ','), ('single', 'singl'), ('machine', 'machin'), ('unable', 'unabl'), ('handle', 'handl'), ('dataset', 'dataset'), ('size', 'size'), ('1.6', '1.6'), ('G', 'g'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('study', 'study'), (',', ','), ('map-reduce', 'map-reduce'), ('better', 'better'), ('solu-', 'solu-'), ('tion', 'tion'), ('dataset', 'dataset'), ('size', 'size'), ('0.2', '0.2'), ('G', 'G'), (',', ','), ('single', 'single'), ('machine', 'machine'), ('unable', 'unable'), ('handle', 'handle'), ('dataset', 'dataset'), ('size', 'size'), ('1.6', '1.6'), ('G', 'G'), ('.', '.')]



========================================== PARAGRAPH 247 ===========================================

Another study [95] presented a theorem to explain the big data characteristics, called  HACE: the characteristics of big data usually are large-volume, Heterogeneous, Autono- mous sources with distributed and decentralized control, and we usually try to find out  some useful and interesting things from complex and evolving relationships of data.  Based on these concerns and data mining issues, Wu and his colleagues [95] also pre- sented a big data processing framework which includes data accessing and computing  

------------------- Sentence 1 -------------------

Another study [95] presented a theorem to explain the big data characteristics, called  HACE: the characteristics of big data usually are large-volume, Heterogeneous, Autono- mous sources with distributed and decentralized control, and we usually try to find out  some useful and interesting things from complex and evolving relationships of data.

>> Tokens are: 
 ['Another', 'study', '[', '95', ']', 'presented', 'theorem', 'explain', 'big', 'data', 'characteristics', ',', 'called', 'HACE', ':', 'characteristics', 'big', 'data', 'usually', 'large-volume', ',', 'Heterogeneous', ',', 'Autono-', 'mous', 'sources', 'distributed', 'decentralized', 'control', ',', 'usually', 'try', 'find', 'useful', 'interesting', 'things', 'complex', 'evolving', 'relationships', 'data', '.']

>> Bigrams are: 
 [('Another', 'study'), ('study', '['), ('[', '95'), ('95', ']'), (']', 'presented'), ('presented', 'theorem'), ('theorem', 'explain'), ('explain', 'big'), ('big', 'data'), ('data', 'characteristics'), ('characteristics', ','), (',', 'called'), ('called', 'HACE'), ('HACE', ':'), (':', 'characteristics'), ('characteristics', 'big'), ('big', 'data'), ('data', 'usually'), ('usually', 'large-volume'), ('large-volume', ','), (',', 'Heterogeneous'), ('Heterogeneous', ','), (',', 'Autono-'), ('Autono-', 'mous'), ('mous', 'sources'), ('sources', 'distributed'), ('distributed', 'decentralized'), ('decentralized', 'control'), ('control', ','), (',', 'usually'), ('usually', 'try'), ('try', 'find'), ('find', 'useful'), ('useful', 'interesting'), ('interesting', 'things'), ('things', 'complex'), ('complex', 'evolving'), ('evolving', 'relationships'), ('relationships', 'data'), ('data', '.')]

>> Trigrams are: 
 [('Another', 'study', '['), ('study', '[', '95'), ('[', '95', ']'), ('95', ']', 'presented'), (']', 'presented', 'theorem'), ('presented', 'theorem', 'explain'), ('theorem', 'explain', 'big'), ('explain', 'big', 'data'), ('big', 'data', 'characteristics'), ('data', 'characteristics', ','), ('characteristics', ',', 'called'), (',', 'called', 'HACE'), ('called', 'HACE', ':'), ('HACE', ':', 'characteristics'), (':', 'characteristics', 'big'), ('characteristics', 'big', 'data'), ('big', 'data', 'usually'), ('data', 'usually', 'large-volume'), ('usually', 'large-volume', ','), ('large-volume', ',', 'Heterogeneous'), (',', 'Heterogeneous', ','), ('Heterogeneous', ',', 'Autono-'), (',', 'Autono-', 'mous'), ('Autono-', 'mous', 'sources'), ('mous', 'sources', 'distributed'), ('sources', 'distributed', 'decentralized'), ('distributed', 'decentralized', 'control'), ('decentralized', 'control', ','), ('control', ',', 'usually'), (',', 'usually', 'try'), ('usually', 'try', 'find'), ('try', 'find', 'useful'), ('find', 'useful', 'interesting'), ('useful', 'interesting', 'things'), ('interesting', 'things', 'complex'), ('things', 'complex', 'evolving'), ('complex', 'evolving', 'relationships'), ('evolving', 'relationships', 'data'), ('relationships', 'data', '.')]

>> POS Tags are: 
 [('Another', 'DT'), ('study', 'NN'), ('[', 'VBD'), ('95', 'CD'), (']', 'NN'), ('presented', 'VBN'), ('theorem', 'NN'), ('explain', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('characteristics', 'NNS'), (',', ','), ('called', 'VBD'), ('HACE', 'NNP'), (':', ':'), ('characteristics', 'NNS'), ('big', 'JJ'), ('data', 'NNS'), ('usually', 'RB'), ('large-volume', 'VBP'), (',', ','), ('Heterogeneous', 'NNP'), (',', ','), ('Autono-', 'NNP'), ('mous', 'JJ'), ('sources', 'NNS'), ('distributed', 'VBD'), ('decentralized', 'VBN'), ('control', 'NN'), (',', ','), ('usually', 'RB'), ('try', 'VBP'), ('find', 'VB'), ('useful', 'JJ'), ('interesting', 'JJ'), ('things', 'NNS'), ('complex', 'JJ'), ('evolving', 'VBG'), ('relationships', 'NNS'), ('data', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['Another study', ']', 'theorem explain', 'big data characteristics', 'HACE', 'characteristics', 'big data', 'Heterogeneous', 'Autono-', 'mous sources', 'control', 'useful interesting things', 'relationships data']

>> Named Entities are: 
 [('ORGANIZATION', 'HACE'), ('GPE', 'Heterogeneous')] 

>> Stemming using Porter Stemmer: 
 [('Another', 'anoth'), ('study', 'studi'), ('[', '['), ('95', '95'), (']', ']'), ('presented', 'present'), ('theorem', 'theorem'), ('explain', 'explain'), ('big', 'big'), ('data', 'data'), ('characteristics', 'characterist'), (',', ','), ('called', 'call'), ('HACE', 'hace'), (':', ':'), ('characteristics', 'characterist'), ('big', 'big'), ('data', 'data'), ('usually', 'usual'), ('large-volume', 'large-volum'), (',', ','), ('Heterogeneous', 'heterogen'), (',', ','), ('Autono-', 'autono-'), ('mous', 'mou'), ('sources', 'sourc'), ('distributed', 'distribut'), ('decentralized', 'decentr'), ('control', 'control'), (',', ','), ('usually', 'usual'), ('try', 'tri'), ('find', 'find'), ('useful', 'use'), ('interesting', 'interest'), ('things', 'thing'), ('complex', 'complex'), ('evolving', 'evolv'), ('relationships', 'relationship'), ('data', 'data'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Another', 'anoth'), ('study', 'studi'), ('[', '['), ('95', '95'), (']', ']'), ('presented', 'present'), ('theorem', 'theorem'), ('explain', 'explain'), ('big', 'big'), ('data', 'data'), ('characteristics', 'characterist'), (',', ','), ('called', 'call'), ('HACE', 'hace'), (':', ':'), ('characteristics', 'characterist'), ('big', 'big'), ('data', 'data'), ('usually', 'usual'), ('large-volume', 'large-volum'), (',', ','), ('Heterogeneous', 'heterogen'), (',', ','), ('Autono-', 'autono-'), ('mous', 'mous'), ('sources', 'sourc'), ('distributed', 'distribut'), ('decentralized', 'decentr'), ('control', 'control'), (',', ','), ('usually', 'usual'), ('try', 'tri'), ('find', 'find'), ('useful', 'use'), ('interesting', 'interest'), ('things', 'thing'), ('complex', 'complex'), ('evolving', 'evolv'), ('relationships', 'relationship'), ('data', 'data'), ('.', '.')]

>> Lemmatization: 
 [('Another', 'Another'), ('study', 'study'), ('[', '['), ('95', '95'), (']', ']'), ('presented', 'presented'), ('theorem', 'theorem'), ('explain', 'explain'), ('big', 'big'), ('data', 'data'), ('characteristics', 'characteristic'), (',', ','), ('called', 'called'), ('HACE', 'HACE'), (':', ':'), ('characteristics', 'characteristic'), ('big', 'big'), ('data', 'data'), ('usually', 'usually'), ('large-volume', 'large-volume'), (',', ','), ('Heterogeneous', 'Heterogeneous'), (',', ','), ('Autono-', 'Autono-'), ('mous', 'mous'), ('sources', 'source'), ('distributed', 'distributed'), ('decentralized', 'decentralized'), ('control', 'control'), (',', ','), ('usually', 'usually'), ('try', 'try'), ('find', 'find'), ('useful', 'useful'), ('interesting', 'interesting'), ('things', 'thing'), ('complex', 'complex'), ('evolving', 'evolving'), ('relationships', 'relationship'), ('data', 'data'), ('.', '.')]


------------------- Sentence 2 -------------------

Based on these concerns and data mining issues, Wu and his colleagues [95] also pre- sented a big data processing framework which includes data accessing and computing

>> Tokens are: 
 ['Based', 'concerns', 'data', 'mining', 'issues', ',', 'Wu', 'colleagues', '[', '95', ']', 'also', 'pre-', 'sented', 'big', 'data', 'processing', 'framework', 'includes', 'data', 'accessing', 'computing']

>> Bigrams are: 
 [('Based', 'concerns'), ('concerns', 'data'), ('data', 'mining'), ('mining', 'issues'), ('issues', ','), (',', 'Wu'), ('Wu', 'colleagues'), ('colleagues', '['), ('[', '95'), ('95', ']'), (']', 'also'), ('also', 'pre-'), ('pre-', 'sented'), ('sented', 'big'), ('big', 'data'), ('data', 'processing'), ('processing', 'framework'), ('framework', 'includes'), ('includes', 'data'), ('data', 'accessing'), ('accessing', 'computing')]

>> Trigrams are: 
 [('Based', 'concerns', 'data'), ('concerns', 'data', 'mining'), ('data', 'mining', 'issues'), ('mining', 'issues', ','), ('issues', ',', 'Wu'), (',', 'Wu', 'colleagues'), ('Wu', 'colleagues', '['), ('colleagues', '[', '95'), ('[', '95', ']'), ('95', ']', 'also'), (']', 'also', 'pre-'), ('also', 'pre-', 'sented'), ('pre-', 'sented', 'big'), ('sented', 'big', 'data'), ('big', 'data', 'processing'), ('data', 'processing', 'framework'), ('processing', 'framework', 'includes'), ('framework', 'includes', 'data'), ('includes', 'data', 'accessing'), ('data', 'accessing', 'computing')]

>> POS Tags are: 
 [('Based', 'VBN'), ('concerns', 'NNS'), ('data', 'NNS'), ('mining', 'NN'), ('issues', 'NNS'), (',', ','), ('Wu', 'NNP'), ('colleagues', 'NNS'), ('[', 'VBP'), ('95', 'CD'), (']', 'NNS'), ('also', 'RB'), ('pre-', 'VBP'), ('sented', 'JJ'), ('big', 'JJ'), ('data', 'NNS'), ('processing', 'NN'), ('framework', 'NN'), ('includes', 'VBZ'), ('data', 'NNS'), ('accessing', 'VBG'), ('computing', 'NN')]

>> Noun Phrases are: 
 ['concerns data mining issues', 'Wu colleagues', ']', 'sented big data processing framework', 'data', 'computing']

>> Named Entities are: 
 [('GPE', 'Wu')] 

>> Stemming using Porter Stemmer: 
 [('Based', 'base'), ('concerns', 'concern'), ('data', 'data'), ('mining', 'mine'), ('issues', 'issu'), (',', ','), ('Wu', 'wu'), ('colleagues', 'colleagu'), ('[', '['), ('95', '95'), (']', ']'), ('also', 'also'), ('pre-', 'pre-'), ('sented', 'sent'), ('big', 'big'), ('data', 'data'), ('processing', 'process'), ('framework', 'framework'), ('includes', 'includ'), ('data', 'data'), ('accessing', 'access'), ('computing', 'comput')]

>> Stemming using Snowball Stemmer: 
 [('Based', 'base'), ('concerns', 'concern'), ('data', 'data'), ('mining', 'mine'), ('issues', 'issu'), (',', ','), ('Wu', 'wu'), ('colleagues', 'colleagu'), ('[', '['), ('95', '95'), (']', ']'), ('also', 'also'), ('pre-', 'pre-'), ('sented', 'sent'), ('big', 'big'), ('data', 'data'), ('processing', 'process'), ('framework', 'framework'), ('includes', 'includ'), ('data', 'data'), ('accessing', 'access'), ('computing', 'comput')]

>> Lemmatization: 
 [('Based', 'Based'), ('concerns', 'concern'), ('data', 'data'), ('mining', 'mining'), ('issues', 'issue'), (',', ','), ('Wu', 'Wu'), ('colleagues', 'colleague'), ('[', '['), ('95', '95'), (']', ']'), ('also', 'also'), ('pre-', 'pre-'), ('sented', 'sented'), ('big', 'big'), ('data', 'data'), ('processing', 'processing'), ('framework', 'framework'), ('includes', 'includes'), ('data', 'data'), ('accessing', 'accessing'), ('computing', 'computing')]



========================================== PARAGRAPH 248 ===========================================

4 The whole system may be down when the master machine crashed for a system that has only one master.

------------------- Sentence 1 -------------------

4 The whole system may be down when the master machine crashed for a system that has only one master.

>> Tokens are: 
 ['4', 'The', 'whole', 'system', 'may', 'master', 'machine', 'crashed', 'system', 'one', 'master', '.']

>> Bigrams are: 
 [('4', 'The'), ('The', 'whole'), ('whole', 'system'), ('system', 'may'), ('may', 'master'), ('master', 'machine'), ('machine', 'crashed'), ('crashed', 'system'), ('system', 'one'), ('one', 'master'), ('master', '.')]

>> Trigrams are: 
 [('4', 'The', 'whole'), ('The', 'whole', 'system'), ('whole', 'system', 'may'), ('system', 'may', 'master'), ('may', 'master', 'machine'), ('master', 'machine', 'crashed'), ('machine', 'crashed', 'system'), ('crashed', 'system', 'one'), ('system', 'one', 'master'), ('one', 'master', '.')]

>> POS Tags are: 
 [('4', 'CD'), ('The', 'DT'), ('whole', 'JJ'), ('system', 'NN'), ('may', 'MD'), ('master', 'VB'), ('machine', 'NN'), ('crashed', 'VBN'), ('system', 'NN'), ('one', 'CD'), ('master', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['The whole system', 'machine', 'system', 'master']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('4', '4'), ('The', 'the'), ('whole', 'whole'), ('system', 'system'), ('may', 'may'), ('master', 'master'), ('machine', 'machin'), ('crashed', 'crash'), ('system', 'system'), ('one', 'one'), ('master', 'master'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('4', '4'), ('The', 'the'), ('whole', 'whole'), ('system', 'system'), ('may', 'may'), ('master', 'master'), ('machine', 'machin'), ('crashed', 'crash'), ('system', 'system'), ('one', 'one'), ('master', 'master'), ('.', '.')]

>> Lemmatization: 
 [('4', '4'), ('The', 'The'), ('whole', 'whole'), ('system', 'system'), ('may', 'may'), ('master', 'master'), ('machine', 'machine'), ('crashed', 'crashed'), ('system', 'system'), ('one', 'one'), ('master', 'master'), ('.', '.')]



========================================== PARAGRAPH 249 ===========================================

Page 15 of 32Tsai et al. Journal of Big Data  (2015) 2:21  

------------------- Sentence 1 -------------------

Page 15 of 32Tsai et al.

>> Tokens are: 
 ['Page', '15', '32Tsai', 'et', 'al', '.']

>> Bigrams are: 
 [('Page', '15'), ('15', '32Tsai'), ('32Tsai', 'et'), ('et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('Page', '15', '32Tsai'), ('15', '32Tsai', 'et'), ('32Tsai', 'et', 'al'), ('et', 'al', '.')]

>> POS Tags are: 
 [('Page', 'NN'), ('15', 'CD'), ('32Tsai', 'CD'), ('et', 'NN'), ('al', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Page', 'et al']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Page', 'page'), ('15', '15'), ('32Tsai', '32tsai'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Page', 'page'), ('15', '15'), ('32Tsai', '32tsai'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('Page', 'Page'), ('15', '15'), ('32Tsai', '32Tsai'), ('et', 'et'), ('al', 'al'), ('.', '.')]


------------------- Sentence 2 -------------------

Journal of Big Data  (2015) 2:21

>> Tokens are: 
 ['Journal', 'Big', 'Data', '(', '2015', ')', '2:21']

>> Bigrams are: 
 [('Journal', 'Big'), ('Big', 'Data'), ('Data', '('), ('(', '2015'), ('2015', ')'), (')', '2:21')]

>> Trigrams are: 
 [('Journal', 'Big', 'Data'), ('Big', 'Data', '('), ('Data', '(', '2015'), ('(', '2015', ')'), ('2015', ')', '2:21')]

>> POS Tags are: 
 [('Journal', 'NNP'), ('Big', 'NNP'), ('Data', 'NNP'), ('(', '('), ('2015', 'CD'), (')', ')'), ('2:21', 'CD')]

>> Noun Phrases are: 
 ['Journal Big Data']

>> Named Entities are: 
 [('PERSON', 'Journal')] 

>> Stemming using Porter Stemmer: 
 [('Journal', 'journal'), ('Big', 'big'), ('Data', 'data'), ('(', '('), ('2015', '2015'), (')', ')'), ('2:21', '2:21')]

>> Stemming using Snowball Stemmer: 
 [('Journal', 'journal'), ('Big', 'big'), ('Data', 'data'), ('(', '('), ('2015', '2015'), (')', ')'), ('2:21', '2:21')]

>> Lemmatization: 
 [('Journal', 'Journal'), ('Big', 'Big'), ('Data', 'Data'), ('(', '('), ('2015', '2015'), (')', ')'), ('2:21', '2:21')]



========================================== PARAGRAPH 250 ===========================================

tier, data privacy and domain knowledge tier, and big data mining algorithm tier. This  work explains that the data mining algorithm will become much more important and  much more difficult; thus, challenges will also occur on the design and implementation  of big data analytics platform. In addition to the platform performance and data mining  issues, the privacy issue for big data analytics was a promising research in recent years.  In [96], Laurila et al. explained that the privacy is an essential problem when we try to  find something from the data that are gathered from mobile devices; thus, data security  and data anonymization should also be considered in analyzing this kind of data. Demir- kan and Delen [97] presented a service-oriented decision support system (SODSS) for  big data analytics which includes information source, data management, information  management, and operations management. 

------------------- Sentence 1 -------------------

tier, data privacy and domain knowledge tier, and big data mining algorithm tier.

>> Tokens are: 
 ['tier', ',', 'data', 'privacy', 'domain', 'knowledge', 'tier', ',', 'big', 'data', 'mining', 'algorithm', 'tier', '.']

>> Bigrams are: 
 [('tier', ','), (',', 'data'), ('data', 'privacy'), ('privacy', 'domain'), ('domain', 'knowledge'), ('knowledge', 'tier'), ('tier', ','), (',', 'big'), ('big', 'data'), ('data', 'mining'), ('mining', 'algorithm'), ('algorithm', 'tier'), ('tier', '.')]

>> Trigrams are: 
 [('tier', ',', 'data'), (',', 'data', 'privacy'), ('data', 'privacy', 'domain'), ('privacy', 'domain', 'knowledge'), ('domain', 'knowledge', 'tier'), ('knowledge', 'tier', ','), ('tier', ',', 'big'), (',', 'big', 'data'), ('big', 'data', 'mining'), ('data', 'mining', 'algorithm'), ('mining', 'algorithm', 'tier'), ('algorithm', 'tier', '.')]

>> POS Tags are: 
 [('tier', 'NN'), (',', ','), ('data', 'NNS'), ('privacy', 'NN'), ('domain', 'VBP'), ('knowledge', 'NN'), ('tier', 'NN'), (',', ','), ('big', 'JJ'), ('data', 'NNS'), ('mining', 'NN'), ('algorithm', 'NN'), ('tier', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['tier', 'data privacy', 'knowledge tier', 'big data mining algorithm tier']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('tier', 'tier'), (',', ','), ('data', 'data'), ('privacy', 'privaci'), ('domain', 'domain'), ('knowledge', 'knowledg'), ('tier', 'tier'), (',', ','), ('big', 'big'), ('data', 'data'), ('mining', 'mine'), ('algorithm', 'algorithm'), ('tier', 'tier'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('tier', 'tier'), (',', ','), ('data', 'data'), ('privacy', 'privaci'), ('domain', 'domain'), ('knowledge', 'knowledg'), ('tier', 'tier'), (',', ','), ('big', 'big'), ('data', 'data'), ('mining', 'mine'), ('algorithm', 'algorithm'), ('tier', 'tier'), ('.', '.')]

>> Lemmatization: 
 [('tier', 'tier'), (',', ','), ('data', 'data'), ('privacy', 'privacy'), ('domain', 'domain'), ('knowledge', 'knowledge'), ('tier', 'tier'), (',', ','), ('big', 'big'), ('data', 'data'), ('mining', 'mining'), ('algorithm', 'algorithm'), ('tier', 'tier'), ('.', '.')]


------------------- Sentence 2 -------------------

This  work explains that the data mining algorithm will become much more important and  much more difficult; thus, challenges will also occur on the design and implementation  of big data analytics platform.

>> Tokens are: 
 ['This', 'work', 'explains', 'data', 'mining', 'algorithm', 'become', 'much', 'important', 'much', 'difficult', ';', 'thus', ',', 'challenges', 'also', 'occur', 'design', 'implementation', 'big', 'data', 'analytics', 'platform', '.']

>> Bigrams are: 
 [('This', 'work'), ('work', 'explains'), ('explains', 'data'), ('data', 'mining'), ('mining', 'algorithm'), ('algorithm', 'become'), ('become', 'much'), ('much', 'important'), ('important', 'much'), ('much', 'difficult'), ('difficult', ';'), (';', 'thus'), ('thus', ','), (',', 'challenges'), ('challenges', 'also'), ('also', 'occur'), ('occur', 'design'), ('design', 'implementation'), ('implementation', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', 'platform'), ('platform', '.')]

>> Trigrams are: 
 [('This', 'work', 'explains'), ('work', 'explains', 'data'), ('explains', 'data', 'mining'), ('data', 'mining', 'algorithm'), ('mining', 'algorithm', 'become'), ('algorithm', 'become', 'much'), ('become', 'much', 'important'), ('much', 'important', 'much'), ('important', 'much', 'difficult'), ('much', 'difficult', ';'), ('difficult', ';', 'thus'), (';', 'thus', ','), ('thus', ',', 'challenges'), (',', 'challenges', 'also'), ('challenges', 'also', 'occur'), ('also', 'occur', 'design'), ('occur', 'design', 'implementation'), ('design', 'implementation', 'big'), ('implementation', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', 'platform'), ('analytics', 'platform', '.')]

>> POS Tags are: 
 [('This', 'DT'), ('work', 'NN'), ('explains', 'VBZ'), ('data', 'NNS'), ('mining', 'NN'), ('algorithm', 'VBZ'), ('become', 'VBN'), ('much', 'JJ'), ('important', 'JJ'), ('much', 'JJ'), ('difficult', 'JJ'), (';', ':'), ('thus', 'RB'), (',', ','), ('challenges', 'NNS'), ('also', 'RB'), ('occur', 'VBP'), ('design', 'NN'), ('implementation', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('platform', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['This work', 'data mining', 'challenges', 'design implementation', 'big data analytics platform']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('This', 'thi'), ('work', 'work'), ('explains', 'explain'), ('data', 'data'), ('mining', 'mine'), ('algorithm', 'algorithm'), ('become', 'becom'), ('much', 'much'), ('important', 'import'), ('much', 'much'), ('difficult', 'difficult'), (';', ';'), ('thus', 'thu'), (',', ','), ('challenges', 'challeng'), ('also', 'also'), ('occur', 'occur'), ('design', 'design'), ('implementation', 'implement'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('platform', 'platform'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('This', 'this'), ('work', 'work'), ('explains', 'explain'), ('data', 'data'), ('mining', 'mine'), ('algorithm', 'algorithm'), ('become', 'becom'), ('much', 'much'), ('important', 'import'), ('much', 'much'), ('difficult', 'difficult'), (';', ';'), ('thus', 'thus'), (',', ','), ('challenges', 'challeng'), ('also', 'also'), ('occur', 'occur'), ('design', 'design'), ('implementation', 'implement'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('platform', 'platform'), ('.', '.')]

>> Lemmatization: 
 [('This', 'This'), ('work', 'work'), ('explains', 'explains'), ('data', 'data'), ('mining', 'mining'), ('algorithm', 'algorithm'), ('become', 'become'), ('much', 'much'), ('important', 'important'), ('much', 'much'), ('difficult', 'difficult'), (';', ';'), ('thus', 'thus'), (',', ','), ('challenges', 'challenge'), ('also', 'also'), ('occur', 'occur'), ('design', 'design'), ('implementation', 'implementation'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('platform', 'platform'), ('.', '.')]


------------------- Sentence 3 -------------------

In addition to the platform performance and data mining  issues, the privacy issue for big data analytics was a promising research in recent years.

>> Tokens are: 
 ['In', 'addition', 'platform', 'performance', 'data', 'mining', 'issues', ',', 'privacy', 'issue', 'big', 'data', 'analytics', 'promising', 'research', 'recent', 'years', '.']

>> Bigrams are: 
 [('In', 'addition'), ('addition', 'platform'), ('platform', 'performance'), ('performance', 'data'), ('data', 'mining'), ('mining', 'issues'), ('issues', ','), (',', 'privacy'), ('privacy', 'issue'), ('issue', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', 'promising'), ('promising', 'research'), ('research', 'recent'), ('recent', 'years'), ('years', '.')]

>> Trigrams are: 
 [('In', 'addition', 'platform'), ('addition', 'platform', 'performance'), ('platform', 'performance', 'data'), ('performance', 'data', 'mining'), ('data', 'mining', 'issues'), ('mining', 'issues', ','), ('issues', ',', 'privacy'), (',', 'privacy', 'issue'), ('privacy', 'issue', 'big'), ('issue', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', 'promising'), ('analytics', 'promising', 'research'), ('promising', 'research', 'recent'), ('research', 'recent', 'years'), ('recent', 'years', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('addition', 'NN'), ('platform', 'NN'), ('performance', 'NN'), ('data', 'NNS'), ('mining', 'NN'), ('issues', 'NNS'), (',', ','), ('privacy', 'NN'), ('issue', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('promising', 'VBG'), ('research', 'NN'), ('recent', 'JJ'), ('years', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['addition platform performance data mining issues', 'privacy issue', 'big data analytics', 'research', 'recent years']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('addition', 'addit'), ('platform', 'platform'), ('performance', 'perform'), ('data', 'data'), ('mining', 'mine'), ('issues', 'issu'), (',', ','), ('privacy', 'privaci'), ('issue', 'issu'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('promising', 'promis'), ('research', 'research'), ('recent', 'recent'), ('years', 'year'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('addition', 'addit'), ('platform', 'platform'), ('performance', 'perform'), ('data', 'data'), ('mining', 'mine'), ('issues', 'issu'), (',', ','), ('privacy', 'privaci'), ('issue', 'issu'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('promising', 'promis'), ('research', 'research'), ('recent', 'recent'), ('years', 'year'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('addition', 'addition'), ('platform', 'platform'), ('performance', 'performance'), ('data', 'data'), ('mining', 'mining'), ('issues', 'issue'), (',', ','), ('privacy', 'privacy'), ('issue', 'issue'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('promising', 'promising'), ('research', 'research'), ('recent', 'recent'), ('years', 'year'), ('.', '.')]


------------------- Sentence 4 -------------------

In [96], Laurila et al.

>> Tokens are: 
 ['In', '[', '96', ']', ',', 'Laurila', 'et', 'al', '.']

>> Bigrams are: 
 [('In', '['), ('[', '96'), ('96', ']'), (']', ','), (',', 'Laurila'), ('Laurila', 'et'), ('et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('In', '[', '96'), ('[', '96', ']'), ('96', ']', ','), (']', ',', 'Laurila'), (',', 'Laurila', 'et'), ('Laurila', 'et', 'al'), ('et', 'al', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('[', '$'), ('96', 'CD'), (']', 'NNP'), (',', ','), ('Laurila', 'NNP'), ('et', 'CC'), ('al', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 [']', 'Laurila', 'al']

>> Named Entities are: 
 [('PERSON', 'Laurila')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('[', '['), ('96', '96'), (']', ']'), (',', ','), ('Laurila', 'laurila'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('[', '['), ('96', '96'), (']', ']'), (',', ','), ('Laurila', 'laurila'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('[', '['), ('96', '96'), (']', ']'), (',', ','), ('Laurila', 'Laurila'), ('et', 'et'), ('al', 'al'), ('.', '.')]


------------------- Sentence 5 -------------------

explained that the privacy is an essential problem when we try to  find something from the data that are gathered from mobile devices; thus, data security  and data anonymization should also be considered in analyzing this kind of data.

>> Tokens are: 
 ['explained', 'privacy', 'essential', 'problem', 'try', 'find', 'something', 'data', 'gathered', 'mobile', 'devices', ';', 'thus', ',', 'data', 'security', 'data', 'anonymization', 'also', 'considered', 'analyzing', 'kind', 'data', '.']

>> Bigrams are: 
 [('explained', 'privacy'), ('privacy', 'essential'), ('essential', 'problem'), ('problem', 'try'), ('try', 'find'), ('find', 'something'), ('something', 'data'), ('data', 'gathered'), ('gathered', 'mobile'), ('mobile', 'devices'), ('devices', ';'), (';', 'thus'), ('thus', ','), (',', 'data'), ('data', 'security'), ('security', 'data'), ('data', 'anonymization'), ('anonymization', 'also'), ('also', 'considered'), ('considered', 'analyzing'), ('analyzing', 'kind'), ('kind', 'data'), ('data', '.')]

>> Trigrams are: 
 [('explained', 'privacy', 'essential'), ('privacy', 'essential', 'problem'), ('essential', 'problem', 'try'), ('problem', 'try', 'find'), ('try', 'find', 'something'), ('find', 'something', 'data'), ('something', 'data', 'gathered'), ('data', 'gathered', 'mobile'), ('gathered', 'mobile', 'devices'), ('mobile', 'devices', ';'), ('devices', ';', 'thus'), (';', 'thus', ','), ('thus', ',', 'data'), (',', 'data', 'security'), ('data', 'security', 'data'), ('security', 'data', 'anonymization'), ('data', 'anonymization', 'also'), ('anonymization', 'also', 'considered'), ('also', 'considered', 'analyzing'), ('considered', 'analyzing', 'kind'), ('analyzing', 'kind', 'data'), ('kind', 'data', '.')]

>> POS Tags are: 
 [('explained', 'VBN'), ('privacy', 'NN'), ('essential', 'JJ'), ('problem', 'NN'), ('try', 'NN'), ('find', 'VBP'), ('something', 'NN'), ('data', 'NNS'), ('gathered', 'VBD'), ('mobile', 'JJ'), ('devices', 'NNS'), (';', ':'), ('thus', 'RB'), (',', ','), ('data', 'NNS'), ('security', 'NN'), ('data', 'NNS'), ('anonymization', 'NN'), ('also', 'RB'), ('considered', 'VBD'), ('analyzing', 'VBG'), ('kind', 'NN'), ('data', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['privacy', 'essential problem try', 'something data', 'mobile devices', 'data security data anonymization', 'kind data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('explained', 'explain'), ('privacy', 'privaci'), ('essential', 'essenti'), ('problem', 'problem'), ('try', 'tri'), ('find', 'find'), ('something', 'someth'), ('data', 'data'), ('gathered', 'gather'), ('mobile', 'mobil'), ('devices', 'devic'), (';', ';'), ('thus', 'thu'), (',', ','), ('data', 'data'), ('security', 'secur'), ('data', 'data'), ('anonymization', 'anonym'), ('also', 'also'), ('considered', 'consid'), ('analyzing', 'analyz'), ('kind', 'kind'), ('data', 'data'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('explained', 'explain'), ('privacy', 'privaci'), ('essential', 'essenti'), ('problem', 'problem'), ('try', 'tri'), ('find', 'find'), ('something', 'someth'), ('data', 'data'), ('gathered', 'gather'), ('mobile', 'mobil'), ('devices', 'devic'), (';', ';'), ('thus', 'thus'), (',', ','), ('data', 'data'), ('security', 'secur'), ('data', 'data'), ('anonymization', 'anonym'), ('also', 'also'), ('considered', 'consid'), ('analyzing', 'analyz'), ('kind', 'kind'), ('data', 'data'), ('.', '.')]

>> Lemmatization: 
 [('explained', 'explained'), ('privacy', 'privacy'), ('essential', 'essential'), ('problem', 'problem'), ('try', 'try'), ('find', 'find'), ('something', 'something'), ('data', 'data'), ('gathered', 'gathered'), ('mobile', 'mobile'), ('devices', 'device'), (';', ';'), ('thus', 'thus'), (',', ','), ('data', 'data'), ('security', 'security'), ('data', 'data'), ('anonymization', 'anonymization'), ('also', 'also'), ('considered', 'considered'), ('analyzing', 'analyzing'), ('kind', 'kind'), ('data', 'data'), ('.', '.')]


------------------- Sentence 6 -------------------

Demir- kan and Delen [97] presented a service-oriented decision support system (SODSS) for  big data analytics which includes information source, data management, information  management, and operations management.

>> Tokens are: 
 ['Demir-', 'kan', 'Delen', '[', '97', ']', 'presented', 'service-oriented', 'decision', 'support', 'system', '(', 'SODSS', ')', 'big', 'data', 'analytics', 'includes', 'information', 'source', ',', 'data', 'management', ',', 'information', 'management', ',', 'operations', 'management', '.']

>> Bigrams are: 
 [('Demir-', 'kan'), ('kan', 'Delen'), ('Delen', '['), ('[', '97'), ('97', ']'), (']', 'presented'), ('presented', 'service-oriented'), ('service-oriented', 'decision'), ('decision', 'support'), ('support', 'system'), ('system', '('), ('(', 'SODSS'), ('SODSS', ')'), (')', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', 'includes'), ('includes', 'information'), ('information', 'source'), ('source', ','), (',', 'data'), ('data', 'management'), ('management', ','), (',', 'information'), ('information', 'management'), ('management', ','), (',', 'operations'), ('operations', 'management'), ('management', '.')]

>> Trigrams are: 
 [('Demir-', 'kan', 'Delen'), ('kan', 'Delen', '['), ('Delen', '[', '97'), ('[', '97', ']'), ('97', ']', 'presented'), (']', 'presented', 'service-oriented'), ('presented', 'service-oriented', 'decision'), ('service-oriented', 'decision', 'support'), ('decision', 'support', 'system'), ('support', 'system', '('), ('system', '(', 'SODSS'), ('(', 'SODSS', ')'), ('SODSS', ')', 'big'), (')', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', 'includes'), ('analytics', 'includes', 'information'), ('includes', 'information', 'source'), ('information', 'source', ','), ('source', ',', 'data'), (',', 'data', 'management'), ('data', 'management', ','), ('management', ',', 'information'), (',', 'information', 'management'), ('information', 'management', ','), ('management', ',', 'operations'), (',', 'operations', 'management'), ('operations', 'management', '.')]

>> POS Tags are: 
 [('Demir-', 'NNP'), ('kan', 'NN'), ('Delen', 'NNP'), ('[', 'VBZ'), ('97', 'CD'), (']', 'NN'), ('presented', 'VBD'), ('service-oriented', 'JJ'), ('decision', 'NN'), ('support', 'NN'), ('system', 'NN'), ('(', '('), ('SODSS', 'NNP'), (')', ')'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('includes', 'VBZ'), ('information', 'NN'), ('source', 'NN'), (',', ','), ('data', 'NN'), ('management', 'NN'), (',', ','), ('information', 'NN'), ('management', 'NN'), (',', ','), ('operations', 'NNS'), ('management', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Demir- kan Delen', ']', 'service-oriented decision support system', 'SODSS', 'big data analytics', 'information source', 'data management', 'information management', 'operations management']

>> Named Entities are: 
 [('PERSON', 'Delen'), ('ORGANIZATION', 'SODSS')] 

>> Stemming using Porter Stemmer: 
 [('Demir-', 'demir-'), ('kan', 'kan'), ('Delen', 'delen'), ('[', '['), ('97', '97'), (']', ']'), ('presented', 'present'), ('service-oriented', 'service-ori'), ('decision', 'decis'), ('support', 'support'), ('system', 'system'), ('(', '('), ('SODSS', 'sodss'), (')', ')'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('includes', 'includ'), ('information', 'inform'), ('source', 'sourc'), (',', ','), ('data', 'data'), ('management', 'manag'), (',', ','), ('information', 'inform'), ('management', 'manag'), (',', ','), ('operations', 'oper'), ('management', 'manag'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Demir-', 'demir-'), ('kan', 'kan'), ('Delen', 'delen'), ('[', '['), ('97', '97'), (']', ']'), ('presented', 'present'), ('service-oriented', 'service-ori'), ('decision', 'decis'), ('support', 'support'), ('system', 'system'), ('(', '('), ('SODSS', 'sodss'), (')', ')'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('includes', 'includ'), ('information', 'inform'), ('source', 'sourc'), (',', ','), ('data', 'data'), ('management', 'manag'), (',', ','), ('information', 'inform'), ('management', 'manag'), (',', ','), ('operations', 'oper'), ('management', 'manag'), ('.', '.')]

>> Lemmatization: 
 [('Demir-', 'Demir-'), ('kan', 'kan'), ('Delen', 'Delen'), ('[', '['), ('97', '97'), (']', ']'), ('presented', 'presented'), ('service-oriented', 'service-oriented'), ('decision', 'decision'), ('support', 'support'), ('system', 'system'), ('(', '('), ('SODSS', 'SODSS'), (')', ')'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('includes', 'includes'), ('information', 'information'), ('source', 'source'), (',', ','), ('data', 'data'), ('management', 'management'), (',', ','), ('information', 'information'), ('management', 'management'), (',', ','), ('operations', 'operation'), ('management', 'management'), ('.', '.')]



========================================== PARAGRAPH 251 ===========================================

Comparison between the frameworks/platforms of big data 

------------------- Sentence 1 -------------------

Comparison between the frameworks/platforms of big data

>> Tokens are: 
 ['Comparison', 'frameworks/platforms', 'big', 'data']

>> Bigrams are: 
 [('Comparison', 'frameworks/platforms'), ('frameworks/platforms', 'big'), ('big', 'data')]

>> Trigrams are: 
 [('Comparison', 'frameworks/platforms', 'big'), ('frameworks/platforms', 'big', 'data')]

>> POS Tags are: 
 [('Comparison', 'NNP'), ('frameworks/platforms', 'VBZ'), ('big', 'JJ'), ('data', 'NNS')]

>> Noun Phrases are: 
 ['Comparison', 'big data']

>> Named Entities are: 
 [('ORGANIZATION', 'Comparison')] 

>> Stemming using Porter Stemmer: 
 [('Comparison', 'comparison'), ('frameworks/platforms', 'frameworks/platform'), ('big', 'big'), ('data', 'data')]

>> Stemming using Snowball Stemmer: 
 [('Comparison', 'comparison'), ('frameworks/platforms', 'frameworks/platform'), ('big', 'big'), ('data', 'data')]

>> Lemmatization: 
 [('Comparison', 'Comparison'), ('frameworks/platforms', 'frameworks/platforms'), ('big', 'big'), ('data', 'data')]



========================================== PARAGRAPH 252 ===========================================

In [98], Talia pointed out that cloud-based data analytics services can be divided into  data analytics software as a service, data analytics platform as a service, and data analyt- ics infrastructure as a service. A later study [99] presented a general architecture of big  data analytics which contains multi-source big data collecting, distributed big data stor- ing, and intra/inter big data processing. Since many kinds of data analytics frameworks  and platforms have been presented, some of the studies attempted to compare them to  give a guidance to choose the applicable frameworks or platforms for relevant works. To  give a brief introduction to big data analytics, especially the platforms and frameworks,  in [100], Cuzzocrea et al. first discuss how recent studies responded the “computational  emergency” issue of big data analytics. Some open issues, such as data source heteroge- neity and uncorrelated data filtering, and possible research directions are also given in  the same study. In [101], Zhang and Huang used the 5Ws model to explain what kind  of framework and method we need for different big data approaches. Zhang and Huang  further explained that the 5Ws model represents what kind of data, why we have these  data, where the data come from, when the data occur, who receive the data, and how the  data are transferred. A later study [102] used the features (i.e.-, owner, workload, source  code, low latency, and complexity) to compare the frameworks of Hadoop [83], Storm  [85] and Drill [103]. Thus, it can be easily seen that the framework of Apache Hadoop  has high latency compared with the other two frameworks. To better understand the  strong and weak points of solutions of big data, Chalmers et al. [82] then employed the  volume, variety, variability, velocity, user skill/experience, and infrastructure to evaluate  eight solutions of big data analytics. 

------------------- Sentence 1 -------------------

In [98], Talia pointed out that cloud-based data analytics services can be divided into  data analytics software as a service, data analytics platform as a service, and data analyt- ics infrastructure as a service.

>> Tokens are: 
 ['In', '[', '98', ']', ',', 'Talia', 'pointed', 'cloud-based', 'data', 'analytics', 'services', 'divided', 'data', 'analytics', 'software', 'service', ',', 'data', 'analytics', 'platform', 'service', ',', 'data', 'analyt-', 'ics', 'infrastructure', 'service', '.']

>> Bigrams are: 
 [('In', '['), ('[', '98'), ('98', ']'), (']', ','), (',', 'Talia'), ('Talia', 'pointed'), ('pointed', 'cloud-based'), ('cloud-based', 'data'), ('data', 'analytics'), ('analytics', 'services'), ('services', 'divided'), ('divided', 'data'), ('data', 'analytics'), ('analytics', 'software'), ('software', 'service'), ('service', ','), (',', 'data'), ('data', 'analytics'), ('analytics', 'platform'), ('platform', 'service'), ('service', ','), (',', 'data'), ('data', 'analyt-'), ('analyt-', 'ics'), ('ics', 'infrastructure'), ('infrastructure', 'service'), ('service', '.')]

>> Trigrams are: 
 [('In', '[', '98'), ('[', '98', ']'), ('98', ']', ','), (']', ',', 'Talia'), (',', 'Talia', 'pointed'), ('Talia', 'pointed', 'cloud-based'), ('pointed', 'cloud-based', 'data'), ('cloud-based', 'data', 'analytics'), ('data', 'analytics', 'services'), ('analytics', 'services', 'divided'), ('services', 'divided', 'data'), ('divided', 'data', 'analytics'), ('data', 'analytics', 'software'), ('analytics', 'software', 'service'), ('software', 'service', ','), ('service', ',', 'data'), (',', 'data', 'analytics'), ('data', 'analytics', 'platform'), ('analytics', 'platform', 'service'), ('platform', 'service', ','), ('service', ',', 'data'), (',', 'data', 'analyt-'), ('data', 'analyt-', 'ics'), ('analyt-', 'ics', 'infrastructure'), ('ics', 'infrastructure', 'service'), ('infrastructure', 'service', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('[', '$'), ('98', 'CD'), (']', 'NNP'), (',', ','), ('Talia', 'NNP'), ('pointed', 'VBD'), ('cloud-based', 'JJ'), ('data', 'NN'), ('analytics', 'NNS'), ('services', 'NNS'), ('divided', 'VBD'), ('data', 'NNS'), ('analytics', 'NNS'), ('software', 'NN'), ('service', 'NN'), (',', ','), ('data', 'NNS'), ('analytics', 'NNS'), ('platform', 'NN'), ('service', 'NN'), (',', ','), ('data', 'VBZ'), ('analyt-', 'JJ'), ('ics', 'NNS'), ('infrastructure', 'NN'), ('service', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 [']', 'Talia', 'cloud-based data analytics services', 'data analytics software service', 'data analytics platform service', 'analyt- ics infrastructure service']

>> Named Entities are: 
 [('PERSON', 'Talia')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('[', '['), ('98', '98'), (']', ']'), (',', ','), ('Talia', 'talia'), ('pointed', 'point'), ('cloud-based', 'cloud-bas'), ('data', 'data'), ('analytics', 'analyt'), ('services', 'servic'), ('divided', 'divid'), ('data', 'data'), ('analytics', 'analyt'), ('software', 'softwar'), ('service', 'servic'), (',', ','), ('data', 'data'), ('analytics', 'analyt'), ('platform', 'platform'), ('service', 'servic'), (',', ','), ('data', 'data'), ('analyt-', 'analyt-'), ('ics', 'ic'), ('infrastructure', 'infrastructur'), ('service', 'servic'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('[', '['), ('98', '98'), (']', ']'), (',', ','), ('Talia', 'talia'), ('pointed', 'point'), ('cloud-based', 'cloud-bas'), ('data', 'data'), ('analytics', 'analyt'), ('services', 'servic'), ('divided', 'divid'), ('data', 'data'), ('analytics', 'analyt'), ('software', 'softwar'), ('service', 'servic'), (',', ','), ('data', 'data'), ('analytics', 'analyt'), ('platform', 'platform'), ('service', 'servic'), (',', ','), ('data', 'data'), ('analyt-', 'analyt-'), ('ics', 'ic'), ('infrastructure', 'infrastructur'), ('service', 'servic'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('[', '['), ('98', '98'), (']', ']'), (',', ','), ('Talia', 'Talia'), ('pointed', 'pointed'), ('cloud-based', 'cloud-based'), ('data', 'data'), ('analytics', 'analytics'), ('services', 'service'), ('divided', 'divided'), ('data', 'data'), ('analytics', 'analytics'), ('software', 'software'), ('service', 'service'), (',', ','), ('data', 'data'), ('analytics', 'analytics'), ('platform', 'platform'), ('service', 'service'), (',', ','), ('data', 'data'), ('analyt-', 'analyt-'), ('ics', 'ic'), ('infrastructure', 'infrastructure'), ('service', 'service'), ('.', '.')]


------------------- Sentence 2 -------------------

A later study [99] presented a general architecture of big  data analytics which contains multi-source big data collecting, distributed big data stor- ing, and intra/inter big data processing.

>> Tokens are: 
 ['A', 'later', 'study', '[', '99', ']', 'presented', 'general', 'architecture', 'big', 'data', 'analytics', 'contains', 'multi-source', 'big', 'data', 'collecting', ',', 'distributed', 'big', 'data', 'stor-', 'ing', ',', 'intra/inter', 'big', 'data', 'processing', '.']

>> Bigrams are: 
 [('A', 'later'), ('later', 'study'), ('study', '['), ('[', '99'), ('99', ']'), (']', 'presented'), ('presented', 'general'), ('general', 'architecture'), ('architecture', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', 'contains'), ('contains', 'multi-source'), ('multi-source', 'big'), ('big', 'data'), ('data', 'collecting'), ('collecting', ','), (',', 'distributed'), ('distributed', 'big'), ('big', 'data'), ('data', 'stor-'), ('stor-', 'ing'), ('ing', ','), (',', 'intra/inter'), ('intra/inter', 'big'), ('big', 'data'), ('data', 'processing'), ('processing', '.')]

>> Trigrams are: 
 [('A', 'later', 'study'), ('later', 'study', '['), ('study', '[', '99'), ('[', '99', ']'), ('99', ']', 'presented'), (']', 'presented', 'general'), ('presented', 'general', 'architecture'), ('general', 'architecture', 'big'), ('architecture', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', 'contains'), ('analytics', 'contains', 'multi-source'), ('contains', 'multi-source', 'big'), ('multi-source', 'big', 'data'), ('big', 'data', 'collecting'), ('data', 'collecting', ','), ('collecting', ',', 'distributed'), (',', 'distributed', 'big'), ('distributed', 'big', 'data'), ('big', 'data', 'stor-'), ('data', 'stor-', 'ing'), ('stor-', 'ing', ','), ('ing', ',', 'intra/inter'), (',', 'intra/inter', 'big'), ('intra/inter', 'big', 'data'), ('big', 'data', 'processing'), ('data', 'processing', '.')]

>> POS Tags are: 
 [('A', 'DT'), ('later', 'RBR'), ('study', 'NN'), ('[', 'VBD'), ('99', 'CD'), (']', 'NNP'), ('presented', 'VBD'), ('general', 'JJ'), ('architecture', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('contains', 'NNS'), ('multi-source', 'JJ'), ('big', 'JJ'), ('data', 'NNS'), ('collecting', 'NN'), (',', ','), ('distributed', 'VBD'), ('big', 'JJ'), ('data', 'NNS'), ('stor-', 'JJ'), ('ing', 'NN'), (',', ','), ('intra/inter', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('processing', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['study', ']', 'general architecture', 'big data analytics contains', 'multi-source big data collecting', 'big data', 'stor- ing', 'intra/inter', 'big data processing']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('A', 'a'), ('later', 'later'), ('study', 'studi'), ('[', '['), ('99', '99'), (']', ']'), ('presented', 'present'), ('general', 'gener'), ('architecture', 'architectur'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('contains', 'contain'), ('multi-source', 'multi-sourc'), ('big', 'big'), ('data', 'data'), ('collecting', 'collect'), (',', ','), ('distributed', 'distribut'), ('big', 'big'), ('data', 'data'), ('stor-', 'stor-'), ('ing', 'ing'), (',', ','), ('intra/inter', 'intra/int'), ('big', 'big'), ('data', 'data'), ('processing', 'process'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('A', 'a'), ('later', 'later'), ('study', 'studi'), ('[', '['), ('99', '99'), (']', ']'), ('presented', 'present'), ('general', 'general'), ('architecture', 'architectur'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('contains', 'contain'), ('multi-source', 'multi-sourc'), ('big', 'big'), ('data', 'data'), ('collecting', 'collect'), (',', ','), ('distributed', 'distribut'), ('big', 'big'), ('data', 'data'), ('stor-', 'stor-'), ('ing', 'ing'), (',', ','), ('intra/inter', 'intra/int'), ('big', 'big'), ('data', 'data'), ('processing', 'process'), ('.', '.')]

>> Lemmatization: 
 [('A', 'A'), ('later', 'later'), ('study', 'study'), ('[', '['), ('99', '99'), (']', ']'), ('presented', 'presented'), ('general', 'general'), ('architecture', 'architecture'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('contains', 'contains'), ('multi-source', 'multi-source'), ('big', 'big'), ('data', 'data'), ('collecting', 'collecting'), (',', ','), ('distributed', 'distributed'), ('big', 'big'), ('data', 'data'), ('stor-', 'stor-'), ('ing', 'ing'), (',', ','), ('intra/inter', 'intra/inter'), ('big', 'big'), ('data', 'data'), ('processing', 'processing'), ('.', '.')]


------------------- Sentence 3 -------------------

Since many kinds of data analytics frameworks  and platforms have been presented, some of the studies attempted to compare them to  give a guidance to choose the applicable frameworks or platforms for relevant works.

>> Tokens are: 
 ['Since', 'many', 'kinds', 'data', 'analytics', 'frameworks', 'platforms', 'presented', ',', 'studies', 'attempted', 'compare', 'give', 'guidance', 'choose', 'applicable', 'frameworks', 'platforms', 'relevant', 'works', '.']

>> Bigrams are: 
 [('Since', 'many'), ('many', 'kinds'), ('kinds', 'data'), ('data', 'analytics'), ('analytics', 'frameworks'), ('frameworks', 'platforms'), ('platforms', 'presented'), ('presented', ','), (',', 'studies'), ('studies', 'attempted'), ('attempted', 'compare'), ('compare', 'give'), ('give', 'guidance'), ('guidance', 'choose'), ('choose', 'applicable'), ('applicable', 'frameworks'), ('frameworks', 'platforms'), ('platforms', 'relevant'), ('relevant', 'works'), ('works', '.')]

>> Trigrams are: 
 [('Since', 'many', 'kinds'), ('many', 'kinds', 'data'), ('kinds', 'data', 'analytics'), ('data', 'analytics', 'frameworks'), ('analytics', 'frameworks', 'platforms'), ('frameworks', 'platforms', 'presented'), ('platforms', 'presented', ','), ('presented', ',', 'studies'), (',', 'studies', 'attempted'), ('studies', 'attempted', 'compare'), ('attempted', 'compare', 'give'), ('compare', 'give', 'guidance'), ('give', 'guidance', 'choose'), ('guidance', 'choose', 'applicable'), ('choose', 'applicable', 'frameworks'), ('applicable', 'frameworks', 'platforms'), ('frameworks', 'platforms', 'relevant'), ('platforms', 'relevant', 'works'), ('relevant', 'works', '.')]

>> POS Tags are: 
 [('Since', 'IN'), ('many', 'JJ'), ('kinds', 'NNS'), ('data', 'NNS'), ('analytics', 'NNS'), ('frameworks', 'NNS'), ('platforms', 'NNS'), ('presented', 'VBD'), (',', ','), ('studies', 'NNS'), ('attempted', 'VBD'), ('compare', 'JJ'), ('give', 'JJ'), ('guidance', 'NN'), ('choose', 'NN'), ('applicable', 'JJ'), ('frameworks', 'NNS'), ('platforms', 'NNS'), ('relevant', 'VBP'), ('works', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['many kinds data analytics frameworks platforms', 'studies', 'compare give guidance choose', 'applicable frameworks platforms', 'works']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Since', 'sinc'), ('many', 'mani'), ('kinds', 'kind'), ('data', 'data'), ('analytics', 'analyt'), ('frameworks', 'framework'), ('platforms', 'platform'), ('presented', 'present'), (',', ','), ('studies', 'studi'), ('attempted', 'attempt'), ('compare', 'compar'), ('give', 'give'), ('guidance', 'guidanc'), ('choose', 'choos'), ('applicable', 'applic'), ('frameworks', 'framework'), ('platforms', 'platform'), ('relevant', 'relev'), ('works', 'work'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Since', 'sinc'), ('many', 'mani'), ('kinds', 'kind'), ('data', 'data'), ('analytics', 'analyt'), ('frameworks', 'framework'), ('platforms', 'platform'), ('presented', 'present'), (',', ','), ('studies', 'studi'), ('attempted', 'attempt'), ('compare', 'compar'), ('give', 'give'), ('guidance', 'guidanc'), ('choose', 'choos'), ('applicable', 'applic'), ('frameworks', 'framework'), ('platforms', 'platform'), ('relevant', 'relev'), ('works', 'work'), ('.', '.')]

>> Lemmatization: 
 [('Since', 'Since'), ('many', 'many'), ('kinds', 'kind'), ('data', 'data'), ('analytics', 'analytics'), ('frameworks', 'framework'), ('platforms', 'platform'), ('presented', 'presented'), (',', ','), ('studies', 'study'), ('attempted', 'attempted'), ('compare', 'compare'), ('give', 'give'), ('guidance', 'guidance'), ('choose', 'choose'), ('applicable', 'applicable'), ('frameworks', 'framework'), ('platforms', 'platform'), ('relevant', 'relevant'), ('works', 'work'), ('.', '.')]


------------------- Sentence 4 -------------------

To  give a brief introduction to big data analytics, especially the platforms and frameworks,  in [100], Cuzzocrea et al.

>> Tokens are: 
 ['To', 'give', 'brief', 'introduction', 'big', 'data', 'analytics', ',', 'especially', 'platforms', 'frameworks', ',', '[', '100', ']', ',', 'Cuzzocrea', 'et', 'al', '.']

>> Bigrams are: 
 [('To', 'give'), ('give', 'brief'), ('brief', 'introduction'), ('introduction', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', ','), (',', 'especially'), ('especially', 'platforms'), ('platforms', 'frameworks'), ('frameworks', ','), (',', '['), ('[', '100'), ('100', ']'), (']', ','), (',', 'Cuzzocrea'), ('Cuzzocrea', 'et'), ('et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('To', 'give', 'brief'), ('give', 'brief', 'introduction'), ('brief', 'introduction', 'big'), ('introduction', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', ','), ('analytics', ',', 'especially'), (',', 'especially', 'platforms'), ('especially', 'platforms', 'frameworks'), ('platforms', 'frameworks', ','), ('frameworks', ',', '['), (',', '[', '100'), ('[', '100', ']'), ('100', ']', ','), (']', ',', 'Cuzzocrea'), (',', 'Cuzzocrea', 'et'), ('Cuzzocrea', 'et', 'al'), ('et', 'al', '.')]

>> POS Tags are: 
 [('To', 'TO'), ('give', 'VB'), ('brief', 'JJ'), ('introduction', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), (',', ','), ('especially', 'RB'), ('platforms', 'JJ'), ('frameworks', 'NNS'), (',', ','), ('[', 'VBP'), ('100', 'CD'), (']', 'NN'), (',', ','), ('Cuzzocrea', 'NNP'), ('et', 'CC'), ('al', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['brief introduction', 'big data analytics', 'platforms frameworks', ']', 'Cuzzocrea', 'al']

>> Named Entities are: 
 [('PERSON', 'Cuzzocrea')] 

>> Stemming using Porter Stemmer: 
 [('To', 'to'), ('give', 'give'), ('brief', 'brief'), ('introduction', 'introduct'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), (',', ','), ('especially', 'especi'), ('platforms', 'platform'), ('frameworks', 'framework'), (',', ','), ('[', '['), ('100', '100'), (']', ']'), (',', ','), ('Cuzzocrea', 'cuzzocrea'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('To', 'to'), ('give', 'give'), ('brief', 'brief'), ('introduction', 'introduct'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), (',', ','), ('especially', 'especi'), ('platforms', 'platform'), ('frameworks', 'framework'), (',', ','), ('[', '['), ('100', '100'), (']', ']'), (',', ','), ('Cuzzocrea', 'cuzzocrea'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('To', 'To'), ('give', 'give'), ('brief', 'brief'), ('introduction', 'introduction'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), (',', ','), ('especially', 'especially'), ('platforms', 'platform'), ('frameworks', 'framework'), (',', ','), ('[', '['), ('100', '100'), (']', ']'), (',', ','), ('Cuzzocrea', 'Cuzzocrea'), ('et', 'et'), ('al', 'al'), ('.', '.')]


------------------- Sentence 5 -------------------

first discuss how recent studies responded the “computational  emergency” issue of big data analytics.

>> Tokens are: 
 ['first', 'discuss', 'recent', 'studies', 'responded', '“', 'computational', 'emergency', '”', 'issue', 'big', 'data', 'analytics', '.']

>> Bigrams are: 
 [('first', 'discuss'), ('discuss', 'recent'), ('recent', 'studies'), ('studies', 'responded'), ('responded', '“'), ('“', 'computational'), ('computational', 'emergency'), ('emergency', '”'), ('”', 'issue'), ('issue', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', '.')]

>> Trigrams are: 
 [('first', 'discuss', 'recent'), ('discuss', 'recent', 'studies'), ('recent', 'studies', 'responded'), ('studies', 'responded', '“'), ('responded', '“', 'computational'), ('“', 'computational', 'emergency'), ('computational', 'emergency', '”'), ('emergency', '”', 'issue'), ('”', 'issue', 'big'), ('issue', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', '.')]

>> POS Tags are: 
 [('first', 'RB'), ('discuss', 'JJ'), ('recent', 'JJ'), ('studies', 'NNS'), ('responded', 'VBD'), ('“', 'JJ'), ('computational', 'JJ'), ('emergency', 'NN'), ('”', 'NNP'), ('issue', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['discuss recent studies', '“ computational emergency ” issue', 'big data analytics']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('first', 'first'), ('discuss', 'discuss'), ('recent', 'recent'), ('studies', 'studi'), ('responded', 'respond'), ('“', '“'), ('computational', 'comput'), ('emergency', 'emerg'), ('”', '”'), ('issue', 'issu'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('first', 'first'), ('discuss', 'discuss'), ('recent', 'recent'), ('studies', 'studi'), ('responded', 'respond'), ('“', '“'), ('computational', 'comput'), ('emergency', 'emerg'), ('”', '”'), ('issue', 'issu'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('.', '.')]

>> Lemmatization: 
 [('first', 'first'), ('discuss', 'discus'), ('recent', 'recent'), ('studies', 'study'), ('responded', 'responded'), ('“', '“'), ('computational', 'computational'), ('emergency', 'emergency'), ('”', '”'), ('issue', 'issue'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('.', '.')]


------------------- Sentence 6 -------------------

Some open issues, such as data source heteroge- neity and uncorrelated data filtering, and possible research directions are also given in  the same study.

>> Tokens are: 
 ['Some', 'open', 'issues', ',', 'data', 'source', 'heteroge-', 'neity', 'uncorrelated', 'data', 'filtering', ',', 'possible', 'research', 'directions', 'also', 'given', 'study', '.']

>> Bigrams are: 
 [('Some', 'open'), ('open', 'issues'), ('issues', ','), (',', 'data'), ('data', 'source'), ('source', 'heteroge-'), ('heteroge-', 'neity'), ('neity', 'uncorrelated'), ('uncorrelated', 'data'), ('data', 'filtering'), ('filtering', ','), (',', 'possible'), ('possible', 'research'), ('research', 'directions'), ('directions', 'also'), ('also', 'given'), ('given', 'study'), ('study', '.')]

>> Trigrams are: 
 [('Some', 'open', 'issues'), ('open', 'issues', ','), ('issues', ',', 'data'), (',', 'data', 'source'), ('data', 'source', 'heteroge-'), ('source', 'heteroge-', 'neity'), ('heteroge-', 'neity', 'uncorrelated'), ('neity', 'uncorrelated', 'data'), ('uncorrelated', 'data', 'filtering'), ('data', 'filtering', ','), ('filtering', ',', 'possible'), (',', 'possible', 'research'), ('possible', 'research', 'directions'), ('research', 'directions', 'also'), ('directions', 'also', 'given'), ('also', 'given', 'study'), ('given', 'study', '.')]

>> POS Tags are: 
 [('Some', 'DT'), ('open', 'JJ'), ('issues', 'NNS'), (',', ','), ('data', 'NNS'), ('source', 'NN'), ('heteroge-', 'JJ'), ('neity', 'NN'), ('uncorrelated', 'VBN'), ('data', 'NNS'), ('filtering', 'NN'), (',', ','), ('possible', 'JJ'), ('research', 'NN'), ('directions', 'NNS'), ('also', 'RB'), ('given', 'VBN'), ('study', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Some open issues', 'data source', 'heteroge- neity', 'data filtering', 'possible research directions', 'study']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Some', 'some'), ('open', 'open'), ('issues', 'issu'), (',', ','), ('data', 'data'), ('source', 'sourc'), ('heteroge-', 'heteroge-'), ('neity', 'neiti'), ('uncorrelated', 'uncorrel'), ('data', 'data'), ('filtering', 'filter'), (',', ','), ('possible', 'possibl'), ('research', 'research'), ('directions', 'direct'), ('also', 'also'), ('given', 'given'), ('study', 'studi'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Some', 'some'), ('open', 'open'), ('issues', 'issu'), (',', ','), ('data', 'data'), ('source', 'sourc'), ('heteroge-', 'heteroge-'), ('neity', 'neiti'), ('uncorrelated', 'uncorrel'), ('data', 'data'), ('filtering', 'filter'), (',', ','), ('possible', 'possibl'), ('research', 'research'), ('directions', 'direct'), ('also', 'also'), ('given', 'given'), ('study', 'studi'), ('.', '.')]

>> Lemmatization: 
 [('Some', 'Some'), ('open', 'open'), ('issues', 'issue'), (',', ','), ('data', 'data'), ('source', 'source'), ('heteroge-', 'heteroge-'), ('neity', 'neity'), ('uncorrelated', 'uncorrelated'), ('data', 'data'), ('filtering', 'filtering'), (',', ','), ('possible', 'possible'), ('research', 'research'), ('directions', 'direction'), ('also', 'also'), ('given', 'given'), ('study', 'study'), ('.', '.')]


------------------- Sentence 7 -------------------

In [101], Zhang and Huang used the 5Ws model to explain what kind  of framework and method we need for different big data approaches.

>> Tokens are: 
 ['In', '[', '101', ']', ',', 'Zhang', 'Huang', 'used', '5Ws', 'model', 'explain', 'kind', 'framework', 'method', 'need', 'different', 'big', 'data', 'approaches', '.']

>> Bigrams are: 
 [('In', '['), ('[', '101'), ('101', ']'), (']', ','), (',', 'Zhang'), ('Zhang', 'Huang'), ('Huang', 'used'), ('used', '5Ws'), ('5Ws', 'model'), ('model', 'explain'), ('explain', 'kind'), ('kind', 'framework'), ('framework', 'method'), ('method', 'need'), ('need', 'different'), ('different', 'big'), ('big', 'data'), ('data', 'approaches'), ('approaches', '.')]

>> Trigrams are: 
 [('In', '[', '101'), ('[', '101', ']'), ('101', ']', ','), (']', ',', 'Zhang'), (',', 'Zhang', 'Huang'), ('Zhang', 'Huang', 'used'), ('Huang', 'used', '5Ws'), ('used', '5Ws', 'model'), ('5Ws', 'model', 'explain'), ('model', 'explain', 'kind'), ('explain', 'kind', 'framework'), ('kind', 'framework', 'method'), ('framework', 'method', 'need'), ('method', 'need', 'different'), ('need', 'different', 'big'), ('different', 'big', 'data'), ('big', 'data', 'approaches'), ('data', 'approaches', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('[', '$'), ('101', 'CD'), (']', 'NNP'), (',', ','), ('Zhang', 'NNP'), ('Huang', 'NNP'), ('used', 'VBD'), ('5Ws', 'CD'), ('model', 'NN'), ('explain', 'NN'), ('kind', 'NN'), ('framework', 'NN'), ('method', 'NN'), ('need', 'VBP'), ('different', 'JJ'), ('big', 'JJ'), ('data', 'NN'), ('approaches', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 [']', 'Zhang Huang', 'model explain kind framework method', 'different big data approaches']

>> Named Entities are: 
 [('PERSON', 'Zhang Huang')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('[', '['), ('101', '101'), (']', ']'), (',', ','), ('Zhang', 'zhang'), ('Huang', 'huang'), ('used', 'use'), ('5Ws', '5w'), ('model', 'model'), ('explain', 'explain'), ('kind', 'kind'), ('framework', 'framework'), ('method', 'method'), ('need', 'need'), ('different', 'differ'), ('big', 'big'), ('data', 'data'), ('approaches', 'approach'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('[', '['), ('101', '101'), (']', ']'), (',', ','), ('Zhang', 'zhang'), ('Huang', 'huang'), ('used', 'use'), ('5Ws', '5ws'), ('model', 'model'), ('explain', 'explain'), ('kind', 'kind'), ('framework', 'framework'), ('method', 'method'), ('need', 'need'), ('different', 'differ'), ('big', 'big'), ('data', 'data'), ('approaches', 'approach'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('[', '['), ('101', '101'), (']', ']'), (',', ','), ('Zhang', 'Zhang'), ('Huang', 'Huang'), ('used', 'used'), ('5Ws', '5Ws'), ('model', 'model'), ('explain', 'explain'), ('kind', 'kind'), ('framework', 'framework'), ('method', 'method'), ('need', 'need'), ('different', 'different'), ('big', 'big'), ('data', 'data'), ('approaches', 'approach'), ('.', '.')]


------------------- Sentence 8 -------------------

Zhang and Huang  further explained that the 5Ws model represents what kind of data, why we have these  data, where the data come from, when the data occur, who receive the data, and how the  data are transferred.

>> Tokens are: 
 ['Zhang', 'Huang', 'explained', '5Ws', 'model', 'represents', 'kind', 'data', ',', 'data', ',', 'data', 'come', ',', 'data', 'occur', ',', 'receive', 'data', ',', 'data', 'transferred', '.']

>> Bigrams are: 
 [('Zhang', 'Huang'), ('Huang', 'explained'), ('explained', '5Ws'), ('5Ws', 'model'), ('model', 'represents'), ('represents', 'kind'), ('kind', 'data'), ('data', ','), (',', 'data'), ('data', ','), (',', 'data'), ('data', 'come'), ('come', ','), (',', 'data'), ('data', 'occur'), ('occur', ','), (',', 'receive'), ('receive', 'data'), ('data', ','), (',', 'data'), ('data', 'transferred'), ('transferred', '.')]

>> Trigrams are: 
 [('Zhang', 'Huang', 'explained'), ('Huang', 'explained', '5Ws'), ('explained', '5Ws', 'model'), ('5Ws', 'model', 'represents'), ('model', 'represents', 'kind'), ('represents', 'kind', 'data'), ('kind', 'data', ','), ('data', ',', 'data'), (',', 'data', ','), ('data', ',', 'data'), (',', 'data', 'come'), ('data', 'come', ','), ('come', ',', 'data'), (',', 'data', 'occur'), ('data', 'occur', ','), ('occur', ',', 'receive'), (',', 'receive', 'data'), ('receive', 'data', ','), ('data', ',', 'data'), (',', 'data', 'transferred'), ('data', 'transferred', '.')]

>> POS Tags are: 
 [('Zhang', 'NNP'), ('Huang', 'NNP'), ('explained', 'VBD'), ('5Ws', 'CD'), ('model', 'NN'), ('represents', 'VBZ'), ('kind', 'NN'), ('data', 'NNS'), (',', ','), ('data', 'NNS'), (',', ','), ('data', 'NNS'), ('come', 'VBP'), (',', ','), ('data', 'NNS'), ('occur', 'VBP'), (',', ','), ('receive', 'JJ'), ('data', 'NNS'), (',', ','), ('data', 'NNS'), ('transferred', 'VBD'), ('.', '.')]

>> Noun Phrases are: 
 ['Zhang Huang', 'model', 'kind data', 'data', 'data', 'data', 'receive data', 'data']

>> Named Entities are: 
 [('PERSON', 'Zhang'), ('PERSON', 'Huang')] 

>> Stemming using Porter Stemmer: 
 [('Zhang', 'zhang'), ('Huang', 'huang'), ('explained', 'explain'), ('5Ws', '5w'), ('model', 'model'), ('represents', 'repres'), ('kind', 'kind'), ('data', 'data'), (',', ','), ('data', 'data'), (',', ','), ('data', 'data'), ('come', 'come'), (',', ','), ('data', 'data'), ('occur', 'occur'), (',', ','), ('receive', 'receiv'), ('data', 'data'), (',', ','), ('data', 'data'), ('transferred', 'transfer'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Zhang', 'zhang'), ('Huang', 'huang'), ('explained', 'explain'), ('5Ws', '5ws'), ('model', 'model'), ('represents', 'repres'), ('kind', 'kind'), ('data', 'data'), (',', ','), ('data', 'data'), (',', ','), ('data', 'data'), ('come', 'come'), (',', ','), ('data', 'data'), ('occur', 'occur'), (',', ','), ('receive', 'receiv'), ('data', 'data'), (',', ','), ('data', 'data'), ('transferred', 'transfer'), ('.', '.')]

>> Lemmatization: 
 [('Zhang', 'Zhang'), ('Huang', 'Huang'), ('explained', 'explained'), ('5Ws', '5Ws'), ('model', 'model'), ('represents', 'represents'), ('kind', 'kind'), ('data', 'data'), (',', ','), ('data', 'data'), (',', ','), ('data', 'data'), ('come', 'come'), (',', ','), ('data', 'data'), ('occur', 'occur'), (',', ','), ('receive', 'receive'), ('data', 'data'), (',', ','), ('data', 'data'), ('transferred', 'transferred'), ('.', '.')]


------------------- Sentence 9 -------------------

A later study [102] used the features (i.e.-, owner, workload, source  code, low latency, and complexity) to compare the frameworks of Hadoop [83], Storm  [85] and Drill [103].

>> Tokens are: 
 ['A', 'later', 'study', '[', '102', ']', 'used', 'features', '(', 'i.e.-', ',', 'owner', ',', 'workload', ',', 'source', 'code', ',', 'low', 'latency', ',', 'complexity', ')', 'compare', 'frameworks', 'Hadoop', '[', '83', ']', ',', 'Storm', '[', '85', ']', 'Drill', '[', '103', ']', '.']

>> Bigrams are: 
 [('A', 'later'), ('later', 'study'), ('study', '['), ('[', '102'), ('102', ']'), (']', 'used'), ('used', 'features'), ('features', '('), ('(', 'i.e.-'), ('i.e.-', ','), (',', 'owner'), ('owner', ','), (',', 'workload'), ('workload', ','), (',', 'source'), ('source', 'code'), ('code', ','), (',', 'low'), ('low', 'latency'), ('latency', ','), (',', 'complexity'), ('complexity', ')'), (')', 'compare'), ('compare', 'frameworks'), ('frameworks', 'Hadoop'), ('Hadoop', '['), ('[', '83'), ('83', ']'), (']', ','), (',', 'Storm'), ('Storm', '['), ('[', '85'), ('85', ']'), (']', 'Drill'), ('Drill', '['), ('[', '103'), ('103', ']'), (']', '.')]

>> Trigrams are: 
 [('A', 'later', 'study'), ('later', 'study', '['), ('study', '[', '102'), ('[', '102', ']'), ('102', ']', 'used'), (']', 'used', 'features'), ('used', 'features', '('), ('features', '(', 'i.e.-'), ('(', 'i.e.-', ','), ('i.e.-', ',', 'owner'), (',', 'owner', ','), ('owner', ',', 'workload'), (',', 'workload', ','), ('workload', ',', 'source'), (',', 'source', 'code'), ('source', 'code', ','), ('code', ',', 'low'), (',', 'low', 'latency'), ('low', 'latency', ','), ('latency', ',', 'complexity'), (',', 'complexity', ')'), ('complexity', ')', 'compare'), (')', 'compare', 'frameworks'), ('compare', 'frameworks', 'Hadoop'), ('frameworks', 'Hadoop', '['), ('Hadoop', '[', '83'), ('[', '83', ']'), ('83', ']', ','), (']', ',', 'Storm'), (',', 'Storm', '['), ('Storm', '[', '85'), ('[', '85', ']'), ('85', ']', 'Drill'), (']', 'Drill', '['), ('Drill', '[', '103'), ('[', '103', ']'), ('103', ']', '.')]

>> POS Tags are: 
 [('A', 'DT'), ('later', 'RBR'), ('study', 'NN'), ('[', 'VBD'), ('102', 'CD'), (']', 'NNS'), ('used', 'VBN'), ('features', 'NNS'), ('(', '('), ('i.e.-', 'JJ'), (',', ','), ('owner', 'NN'), (',', ','), ('workload', 'NN'), (',', ','), ('source', 'NN'), ('code', 'NN'), (',', ','), ('low', 'JJ'), ('latency', 'NN'), (',', ','), ('complexity', 'NN'), (')', ')'), ('compare', 'NN'), ('frameworks', 'VBZ'), ('Hadoop', 'NNP'), ('[', 'NNP'), ('83', 'CD'), (']', 'NNP'), (',', ','), ('Storm', 'NNP'), ('[', 'VBZ'), ('85', 'CD'), (']', 'NN'), ('Drill', 'NNP'), ('[', 'VBZ'), ('103', 'CD'), (']', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['study', ']', 'features', 'owner', 'workload', 'source code', 'low latency', 'complexity', 'compare', 'Hadoop [', ']', 'Storm', '] Drill', ']']

>> Named Entities are: 
 [('PERSON', 'Hadoop'), ('PERSON', 'Storm'), ('PERSON', 'Drill')] 

>> Stemming using Porter Stemmer: 
 [('A', 'a'), ('later', 'later'), ('study', 'studi'), ('[', '['), ('102', '102'), (']', ']'), ('used', 'use'), ('features', 'featur'), ('(', '('), ('i.e.-', 'i.e.-'), (',', ','), ('owner', 'owner'), (',', ','), ('workload', 'workload'), (',', ','), ('source', 'sourc'), ('code', 'code'), (',', ','), ('low', 'low'), ('latency', 'latenc'), (',', ','), ('complexity', 'complex'), (')', ')'), ('compare', 'compar'), ('frameworks', 'framework'), ('Hadoop', 'hadoop'), ('[', '['), ('83', '83'), (']', ']'), (',', ','), ('Storm', 'storm'), ('[', '['), ('85', '85'), (']', ']'), ('Drill', 'drill'), ('[', '['), ('103', '103'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('A', 'a'), ('later', 'later'), ('study', 'studi'), ('[', '['), ('102', '102'), (']', ']'), ('used', 'use'), ('features', 'featur'), ('(', '('), ('i.e.-', 'i.e.-'), (',', ','), ('owner', 'owner'), (',', ','), ('workload', 'workload'), (',', ','), ('source', 'sourc'), ('code', 'code'), (',', ','), ('low', 'low'), ('latency', 'latenc'), (',', ','), ('complexity', 'complex'), (')', ')'), ('compare', 'compar'), ('frameworks', 'framework'), ('Hadoop', 'hadoop'), ('[', '['), ('83', '83'), (']', ']'), (',', ','), ('Storm', 'storm'), ('[', '['), ('85', '85'), (']', ']'), ('Drill', 'drill'), ('[', '['), ('103', '103'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('A', 'A'), ('later', 'later'), ('study', 'study'), ('[', '['), ('102', '102'), (']', ']'), ('used', 'used'), ('features', 'feature'), ('(', '('), ('i.e.-', 'i.e.-'), (',', ','), ('owner', 'owner'), (',', ','), ('workload', 'workload'), (',', ','), ('source', 'source'), ('code', 'code'), (',', ','), ('low', 'low'), ('latency', 'latency'), (',', ','), ('complexity', 'complexity'), (')', ')'), ('compare', 'compare'), ('frameworks', 'framework'), ('Hadoop', 'Hadoop'), ('[', '['), ('83', '83'), (']', ']'), (',', ','), ('Storm', 'Storm'), ('[', '['), ('85', '85'), (']', ']'), ('Drill', 'Drill'), ('[', '['), ('103', '103'), (']', ']'), ('.', '.')]


------------------- Sentence 10 -------------------

Thus, it can be easily seen that the framework of Apache Hadoop  has high latency compared with the other two frameworks.

>> Tokens are: 
 ['Thus', ',', 'easily', 'seen', 'framework', 'Apache', 'Hadoop', 'high', 'latency', 'compared', 'two', 'frameworks', '.']

>> Bigrams are: 
 [('Thus', ','), (',', 'easily'), ('easily', 'seen'), ('seen', 'framework'), ('framework', 'Apache'), ('Apache', 'Hadoop'), ('Hadoop', 'high'), ('high', 'latency'), ('latency', 'compared'), ('compared', 'two'), ('two', 'frameworks'), ('frameworks', '.')]

>> Trigrams are: 
 [('Thus', ',', 'easily'), (',', 'easily', 'seen'), ('easily', 'seen', 'framework'), ('seen', 'framework', 'Apache'), ('framework', 'Apache', 'Hadoop'), ('Apache', 'Hadoop', 'high'), ('Hadoop', 'high', 'latency'), ('high', 'latency', 'compared'), ('latency', 'compared', 'two'), ('compared', 'two', 'frameworks'), ('two', 'frameworks', '.')]

>> POS Tags are: 
 [('Thus', 'RB'), (',', ','), ('easily', 'RB'), ('seen', 'VBN'), ('framework', 'NN'), ('Apache', 'NNP'), ('Hadoop', 'NNP'), ('high', 'JJ'), ('latency', 'NN'), ('compared', 'VBN'), ('two', 'CD'), ('frameworks', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['framework Apache Hadoop', 'high latency', 'frameworks']

>> Named Entities are: 
 [('PERSON', 'Apache Hadoop')] 

>> Stemming using Porter Stemmer: 
 [('Thus', 'thu'), (',', ','), ('easily', 'easili'), ('seen', 'seen'), ('framework', 'framework'), ('Apache', 'apach'), ('Hadoop', 'hadoop'), ('high', 'high'), ('latency', 'latenc'), ('compared', 'compar'), ('two', 'two'), ('frameworks', 'framework'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Thus', 'thus'), (',', ','), ('easily', 'easili'), ('seen', 'seen'), ('framework', 'framework'), ('Apache', 'apach'), ('Hadoop', 'hadoop'), ('high', 'high'), ('latency', 'latenc'), ('compared', 'compar'), ('two', 'two'), ('frameworks', 'framework'), ('.', '.')]

>> Lemmatization: 
 [('Thus', 'Thus'), (',', ','), ('easily', 'easily'), ('seen', 'seen'), ('framework', 'framework'), ('Apache', 'Apache'), ('Hadoop', 'Hadoop'), ('high', 'high'), ('latency', 'latency'), ('compared', 'compared'), ('two', 'two'), ('frameworks', 'framework'), ('.', '.')]


------------------- Sentence 11 -------------------

To better understand the  strong and weak points of solutions of big data, Chalmers et al.

>> Tokens are: 
 ['To', 'better', 'understand', 'strong', 'weak', 'points', 'solutions', 'big', 'data', ',', 'Chalmers', 'et', 'al', '.']

>> Bigrams are: 
 [('To', 'better'), ('better', 'understand'), ('understand', 'strong'), ('strong', 'weak'), ('weak', 'points'), ('points', 'solutions'), ('solutions', 'big'), ('big', 'data'), ('data', ','), (',', 'Chalmers'), ('Chalmers', 'et'), ('et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('To', 'better', 'understand'), ('better', 'understand', 'strong'), ('understand', 'strong', 'weak'), ('strong', 'weak', 'points'), ('weak', 'points', 'solutions'), ('points', 'solutions', 'big'), ('solutions', 'big', 'data'), ('big', 'data', ','), ('data', ',', 'Chalmers'), (',', 'Chalmers', 'et'), ('Chalmers', 'et', 'al'), ('et', 'al', '.')]

>> POS Tags are: 
 [('To', 'TO'), ('better', 'JJR'), ('understand', 'VB'), ('strong', 'JJ'), ('weak', 'JJ'), ('points', 'NNS'), ('solutions', 'NNS'), ('big', 'JJ'), ('data', 'NNS'), (',', ','), ('Chalmers', 'NNP'), ('et', 'VBP'), ('al', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['strong weak points solutions', 'big data', 'Chalmers', 'al']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('To', 'to'), ('better', 'better'), ('understand', 'understand'), ('strong', 'strong'), ('weak', 'weak'), ('points', 'point'), ('solutions', 'solut'), ('big', 'big'), ('data', 'data'), (',', ','), ('Chalmers', 'chalmer'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('To', 'to'), ('better', 'better'), ('understand', 'understand'), ('strong', 'strong'), ('weak', 'weak'), ('points', 'point'), ('solutions', 'solut'), ('big', 'big'), ('data', 'data'), (',', ','), ('Chalmers', 'chalmer'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('To', 'To'), ('better', 'better'), ('understand', 'understand'), ('strong', 'strong'), ('weak', 'weak'), ('points', 'point'), ('solutions', 'solution'), ('big', 'big'), ('data', 'data'), (',', ','), ('Chalmers', 'Chalmers'), ('et', 'et'), ('al', 'al'), ('.', '.')]


------------------- Sentence 12 -------------------

[82] then employed the  volume, variety, variability, velocity, user skill/experience, and infrastructure to evaluate  eight solutions of big data analytics.

>> Tokens are: 
 ['[', '82', ']', 'employed', 'volume', ',', 'variety', ',', 'variability', ',', 'velocity', ',', 'user', 'skill/experience', ',', 'infrastructure', 'evaluate', 'eight', 'solutions', 'big', 'data', 'analytics', '.']

>> Bigrams are: 
 [('[', '82'), ('82', ']'), (']', 'employed'), ('employed', 'volume'), ('volume', ','), (',', 'variety'), ('variety', ','), (',', 'variability'), ('variability', ','), (',', 'velocity'), ('velocity', ','), (',', 'user'), ('user', 'skill/experience'), ('skill/experience', ','), (',', 'infrastructure'), ('infrastructure', 'evaluate'), ('evaluate', 'eight'), ('eight', 'solutions'), ('solutions', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', '.')]

>> Trigrams are: 
 [('[', '82', ']'), ('82', ']', 'employed'), (']', 'employed', 'volume'), ('employed', 'volume', ','), ('volume', ',', 'variety'), (',', 'variety', ','), ('variety', ',', 'variability'), (',', 'variability', ','), ('variability', ',', 'velocity'), (',', 'velocity', ','), ('velocity', ',', 'user'), (',', 'user', 'skill/experience'), ('user', 'skill/experience', ','), ('skill/experience', ',', 'infrastructure'), (',', 'infrastructure', 'evaluate'), ('infrastructure', 'evaluate', 'eight'), ('evaluate', 'eight', 'solutions'), ('eight', 'solutions', 'big'), ('solutions', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('82', 'CD'), (']', 'JJ'), ('employed', 'VBN'), ('volume', 'NN'), (',', ','), ('variety', 'NN'), (',', ','), ('variability', 'NN'), (',', ','), ('velocity', 'NN'), (',', ','), ('user', 'JJ'), ('skill/experience', 'NN'), (',', ','), ('infrastructure', 'NN'), ('evaluate', 'JJ'), ('eight', 'CD'), ('solutions', 'NNS'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['volume', 'variety', 'variability', 'velocity', 'user skill/experience', 'infrastructure', 'solutions', 'big data analytics']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('82', '82'), (']', ']'), ('employed', 'employ'), ('volume', 'volum'), (',', ','), ('variety', 'varieti'), (',', ','), ('variability', 'variabl'), (',', ','), ('velocity', 'veloc'), (',', ','), ('user', 'user'), ('skill/experience', 'skill/experi'), (',', ','), ('infrastructure', 'infrastructur'), ('evaluate', 'evalu'), ('eight', 'eight'), ('solutions', 'solut'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('82', '82'), (']', ']'), ('employed', 'employ'), ('volume', 'volum'), (',', ','), ('variety', 'varieti'), (',', ','), ('variability', 'variabl'), (',', ','), ('velocity', 'veloc'), (',', ','), ('user', 'user'), ('skill/experience', 'skill/experi'), (',', ','), ('infrastructure', 'infrastructur'), ('evaluate', 'evalu'), ('eight', 'eight'), ('solutions', 'solut'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('82', '82'), (']', ']'), ('employed', 'employed'), ('volume', 'volume'), (',', ','), ('variety', 'variety'), (',', ','), ('variability', 'variability'), (',', ','), ('velocity', 'velocity'), (',', ','), ('user', 'user'), ('skill/experience', 'skill/experience'), (',', ','), ('infrastructure', 'infrastructure'), ('evaluate', 'evaluate'), ('eight', 'eight'), ('solutions', 'solution'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('.', '.')]



========================================== PARAGRAPH 253 ===========================================

In [104], in addition to defining that a big data system should include data genera- tion, data acquisition, data storage, and data analytics modules, Hu et al. also mentioned  that a big data system can be decomposed into infrastructure, computing, and applica- tion layers. Moreover, a promising research for NoSQL storage systems was also dis- cussed in this study which can be divided into key-value, column, document, and row  databases. Since big data analysis is generally regarded as a high computation cost work,  the high performance computing cluster system (HPCC) is also a possible solution in  early stage of big data analytics. Sagiroglu and Sinanc [105] therefore compare the char- acteristics between HPCC and Hadoop. They then emphasized that HPCC system uses  the multikey and multivariate indexes on distributed file system while Hadoop uses the 

------------------- Sentence 1 -------------------

In [104], in addition to defining that a big data system should include data genera- tion, data acquisition, data storage, and data analytics modules, Hu et al.

>> Tokens are: 
 ['In', '[', '104', ']', ',', 'addition', 'defining', 'big', 'data', 'system', 'include', 'data', 'genera-', 'tion', ',', 'data', 'acquisition', ',', 'data', 'storage', ',', 'data', 'analytics', 'modules', ',', 'Hu', 'et', 'al', '.']

>> Bigrams are: 
 [('In', '['), ('[', '104'), ('104', ']'), (']', ','), (',', 'addition'), ('addition', 'defining'), ('defining', 'big'), ('big', 'data'), ('data', 'system'), ('system', 'include'), ('include', 'data'), ('data', 'genera-'), ('genera-', 'tion'), ('tion', ','), (',', 'data'), ('data', 'acquisition'), ('acquisition', ','), (',', 'data'), ('data', 'storage'), ('storage', ','), (',', 'data'), ('data', 'analytics'), ('analytics', 'modules'), ('modules', ','), (',', 'Hu'), ('Hu', 'et'), ('et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('In', '[', '104'), ('[', '104', ']'), ('104', ']', ','), (']', ',', 'addition'), (',', 'addition', 'defining'), ('addition', 'defining', 'big'), ('defining', 'big', 'data'), ('big', 'data', 'system'), ('data', 'system', 'include'), ('system', 'include', 'data'), ('include', 'data', 'genera-'), ('data', 'genera-', 'tion'), ('genera-', 'tion', ','), ('tion', ',', 'data'), (',', 'data', 'acquisition'), ('data', 'acquisition', ','), ('acquisition', ',', 'data'), (',', 'data', 'storage'), ('data', 'storage', ','), ('storage', ',', 'data'), (',', 'data', 'analytics'), ('data', 'analytics', 'modules'), ('analytics', 'modules', ','), ('modules', ',', 'Hu'), (',', 'Hu', 'et'), ('Hu', 'et', 'al'), ('et', 'al', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('[', '$'), ('104', 'CD'), (']', 'NNP'), (',', ','), ('addition', 'NN'), ('defining', 'VBG'), ('big', 'JJ'), ('data', 'NNS'), ('system', 'NN'), ('include', 'VBP'), ('data', 'NNS'), ('genera-', 'JJ'), ('tion', 'NN'), (',', ','), ('data', 'NNS'), ('acquisition', 'NN'), (',', ','), ('data', 'NNS'), ('storage', 'NN'), (',', ','), ('data', 'NNS'), ('analytics', 'NNS'), ('modules', 'NNS'), (',', ','), ('Hu', 'NNP'), ('et', 'CC'), ('al', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 [']', 'addition', 'big data system', 'data', 'genera- tion', 'data acquisition', 'data storage', 'data analytics modules', 'Hu', 'al']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('[', '['), ('104', '104'), (']', ']'), (',', ','), ('addition', 'addit'), ('defining', 'defin'), ('big', 'big'), ('data', 'data'), ('system', 'system'), ('include', 'includ'), ('data', 'data'), ('genera-', 'genera-'), ('tion', 'tion'), (',', ','), ('data', 'data'), ('acquisition', 'acquisit'), (',', ','), ('data', 'data'), ('storage', 'storag'), (',', ','), ('data', 'data'), ('analytics', 'analyt'), ('modules', 'modul'), (',', ','), ('Hu', 'hu'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('[', '['), ('104', '104'), (']', ']'), (',', ','), ('addition', 'addit'), ('defining', 'defin'), ('big', 'big'), ('data', 'data'), ('system', 'system'), ('include', 'includ'), ('data', 'data'), ('genera-', 'genera-'), ('tion', 'tion'), (',', ','), ('data', 'data'), ('acquisition', 'acquisit'), (',', ','), ('data', 'data'), ('storage', 'storag'), (',', ','), ('data', 'data'), ('analytics', 'analyt'), ('modules', 'modul'), (',', ','), ('Hu', 'hu'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('[', '['), ('104', '104'), (']', ']'), (',', ','), ('addition', 'addition'), ('defining', 'defining'), ('big', 'big'), ('data', 'data'), ('system', 'system'), ('include', 'include'), ('data', 'data'), ('genera-', 'genera-'), ('tion', 'tion'), (',', ','), ('data', 'data'), ('acquisition', 'acquisition'), (',', ','), ('data', 'data'), ('storage', 'storage'), (',', ','), ('data', 'data'), ('analytics', 'analytics'), ('modules', 'module'), (',', ','), ('Hu', 'Hu'), ('et', 'et'), ('al', 'al'), ('.', '.')]


------------------- Sentence 2 -------------------

also mentioned  that a big data system can be decomposed into infrastructure, computing, and applica- tion layers.

>> Tokens are: 
 ['also', 'mentioned', 'big', 'data', 'system', 'decomposed', 'infrastructure', ',', 'computing', ',', 'applica-', 'tion', 'layers', '.']

>> Bigrams are: 
 [('also', 'mentioned'), ('mentioned', 'big'), ('big', 'data'), ('data', 'system'), ('system', 'decomposed'), ('decomposed', 'infrastructure'), ('infrastructure', ','), (',', 'computing'), ('computing', ','), (',', 'applica-'), ('applica-', 'tion'), ('tion', 'layers'), ('layers', '.')]

>> Trigrams are: 
 [('also', 'mentioned', 'big'), ('mentioned', 'big', 'data'), ('big', 'data', 'system'), ('data', 'system', 'decomposed'), ('system', 'decomposed', 'infrastructure'), ('decomposed', 'infrastructure', ','), ('infrastructure', ',', 'computing'), (',', 'computing', ','), ('computing', ',', 'applica-'), (',', 'applica-', 'tion'), ('applica-', 'tion', 'layers'), ('tion', 'layers', '.')]

>> POS Tags are: 
 [('also', 'RB'), ('mentioned', 'VBN'), ('big', 'JJ'), ('data', 'NNS'), ('system', 'NN'), ('decomposed', 'JJ'), ('infrastructure', 'NN'), (',', ','), ('computing', 'VBG'), (',', ','), ('applica-', 'JJ'), ('tion', 'NN'), ('layers', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['big data system', 'decomposed infrastructure', 'applica- tion layers']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('also', 'also'), ('mentioned', 'mention'), ('big', 'big'), ('data', 'data'), ('system', 'system'), ('decomposed', 'decompos'), ('infrastructure', 'infrastructur'), (',', ','), ('computing', 'comput'), (',', ','), ('applica-', 'applica-'), ('tion', 'tion'), ('layers', 'layer'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('also', 'also'), ('mentioned', 'mention'), ('big', 'big'), ('data', 'data'), ('system', 'system'), ('decomposed', 'decompos'), ('infrastructure', 'infrastructur'), (',', ','), ('computing', 'comput'), (',', ','), ('applica-', 'applica-'), ('tion', 'tion'), ('layers', 'layer'), ('.', '.')]

>> Lemmatization: 
 [('also', 'also'), ('mentioned', 'mentioned'), ('big', 'big'), ('data', 'data'), ('system', 'system'), ('decomposed', 'decomposed'), ('infrastructure', 'infrastructure'), (',', ','), ('computing', 'computing'), (',', ','), ('applica-', 'applica-'), ('tion', 'tion'), ('layers', 'layer'), ('.', '.')]


------------------- Sentence 3 -------------------

Moreover, a promising research for NoSQL storage systems was also dis- cussed in this study which can be divided into key-value, column, document, and row  databases.

>> Tokens are: 
 ['Moreover', ',', 'promising', 'research', 'NoSQL', 'storage', 'systems', 'also', 'dis-', 'cussed', 'study', 'divided', 'key-value', ',', 'column', ',', 'document', ',', 'row', 'databases', '.']

>> Bigrams are: 
 [('Moreover', ','), (',', 'promising'), ('promising', 'research'), ('research', 'NoSQL'), ('NoSQL', 'storage'), ('storage', 'systems'), ('systems', 'also'), ('also', 'dis-'), ('dis-', 'cussed'), ('cussed', 'study'), ('study', 'divided'), ('divided', 'key-value'), ('key-value', ','), (',', 'column'), ('column', ','), (',', 'document'), ('document', ','), (',', 'row'), ('row', 'databases'), ('databases', '.')]

>> Trigrams are: 
 [('Moreover', ',', 'promising'), (',', 'promising', 'research'), ('promising', 'research', 'NoSQL'), ('research', 'NoSQL', 'storage'), ('NoSQL', 'storage', 'systems'), ('storage', 'systems', 'also'), ('systems', 'also', 'dis-'), ('also', 'dis-', 'cussed'), ('dis-', 'cussed', 'study'), ('cussed', 'study', 'divided'), ('study', 'divided', 'key-value'), ('divided', 'key-value', ','), ('key-value', ',', 'column'), (',', 'column', ','), ('column', ',', 'document'), (',', 'document', ','), ('document', ',', 'row'), (',', 'row', 'databases'), ('row', 'databases', '.')]

>> POS Tags are: 
 [('Moreover', 'RB'), (',', ','), ('promising', 'VBG'), ('research', 'NN'), ('NoSQL', 'NNP'), ('storage', 'NN'), ('systems', 'NNS'), ('also', 'RB'), ('dis-', 'VBP'), ('cussed', 'JJ'), ('study', 'NN'), ('divided', 'VBD'), ('key-value', 'NN'), (',', ','), ('column', 'NN'), (',', ','), ('document', 'NN'), (',', ','), ('row', 'NN'), ('databases', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['research NoSQL storage systems', 'cussed study', 'key-value', 'column', 'document', 'row databases']

>> Named Entities are: 
 [('ORGANIZATION', 'NoSQL')] 

>> Stemming using Porter Stemmer: 
 [('Moreover', 'moreov'), (',', ','), ('promising', 'promis'), ('research', 'research'), ('NoSQL', 'nosql'), ('storage', 'storag'), ('systems', 'system'), ('also', 'also'), ('dis-', 'dis-'), ('cussed', 'cuss'), ('study', 'studi'), ('divided', 'divid'), ('key-value', 'key-valu'), (',', ','), ('column', 'column'), (',', ','), ('document', 'document'), (',', ','), ('row', 'row'), ('databases', 'databas'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Moreover', 'moreov'), (',', ','), ('promising', 'promis'), ('research', 'research'), ('NoSQL', 'nosql'), ('storage', 'storag'), ('systems', 'system'), ('also', 'also'), ('dis-', 'dis-'), ('cussed', 'cuss'), ('study', 'studi'), ('divided', 'divid'), ('key-value', 'key-valu'), (',', ','), ('column', 'column'), (',', ','), ('document', 'document'), (',', ','), ('row', 'row'), ('databases', 'databas'), ('.', '.')]

>> Lemmatization: 
 [('Moreover', 'Moreover'), (',', ','), ('promising', 'promising'), ('research', 'research'), ('NoSQL', 'NoSQL'), ('storage', 'storage'), ('systems', 'system'), ('also', 'also'), ('dis-', 'dis-'), ('cussed', 'cussed'), ('study', 'study'), ('divided', 'divided'), ('key-value', 'key-value'), (',', ','), ('column', 'column'), (',', ','), ('document', 'document'), (',', ','), ('row', 'row'), ('databases', 'database'), ('.', '.')]


------------------- Sentence 4 -------------------

Since big data analysis is generally regarded as a high computation cost work,  the high performance computing cluster system (HPCC) is also a possible solution in  early stage of big data analytics.

>> Tokens are: 
 ['Since', 'big', 'data', 'analysis', 'generally', 'regarded', 'high', 'computation', 'cost', 'work', ',', 'high', 'performance', 'computing', 'cluster', 'system', '(', 'HPCC', ')', 'also', 'possible', 'solution', 'early', 'stage', 'big', 'data', 'analytics', '.']

>> Bigrams are: 
 [('Since', 'big'), ('big', 'data'), ('data', 'analysis'), ('analysis', 'generally'), ('generally', 'regarded'), ('regarded', 'high'), ('high', 'computation'), ('computation', 'cost'), ('cost', 'work'), ('work', ','), (',', 'high'), ('high', 'performance'), ('performance', 'computing'), ('computing', 'cluster'), ('cluster', 'system'), ('system', '('), ('(', 'HPCC'), ('HPCC', ')'), (')', 'also'), ('also', 'possible'), ('possible', 'solution'), ('solution', 'early'), ('early', 'stage'), ('stage', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', '.')]

>> Trigrams are: 
 [('Since', 'big', 'data'), ('big', 'data', 'analysis'), ('data', 'analysis', 'generally'), ('analysis', 'generally', 'regarded'), ('generally', 'regarded', 'high'), ('regarded', 'high', 'computation'), ('high', 'computation', 'cost'), ('computation', 'cost', 'work'), ('cost', 'work', ','), ('work', ',', 'high'), (',', 'high', 'performance'), ('high', 'performance', 'computing'), ('performance', 'computing', 'cluster'), ('computing', 'cluster', 'system'), ('cluster', 'system', '('), ('system', '(', 'HPCC'), ('(', 'HPCC', ')'), ('HPCC', ')', 'also'), (')', 'also', 'possible'), ('also', 'possible', 'solution'), ('possible', 'solution', 'early'), ('solution', 'early', 'stage'), ('early', 'stage', 'big'), ('stage', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', '.')]

>> POS Tags are: 
 [('Since', 'IN'), ('big', 'JJ'), ('data', 'NNS'), ('analysis', 'NN'), ('generally', 'RB'), ('regarded', 'VBN'), ('high', 'JJ'), ('computation', 'NN'), ('cost', 'NN'), ('work', 'NN'), (',', ','), ('high', 'JJ'), ('performance', 'NN'), ('computing', 'VBG'), ('cluster', 'NN'), ('system', 'NN'), ('(', '('), ('HPCC', 'NNP'), (')', ')'), ('also', 'RB'), ('possible', 'JJ'), ('solution', 'NN'), ('early', 'JJ'), ('stage', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['big data analysis', 'high computation cost work', 'high performance', 'cluster system', 'HPCC', 'possible solution', 'early stage', 'big data analytics']

>> Named Entities are: 
 [('ORGANIZATION', 'HPCC')] 

>> Stemming using Porter Stemmer: 
 [('Since', 'sinc'), ('big', 'big'), ('data', 'data'), ('analysis', 'analysi'), ('generally', 'gener'), ('regarded', 'regard'), ('high', 'high'), ('computation', 'comput'), ('cost', 'cost'), ('work', 'work'), (',', ','), ('high', 'high'), ('performance', 'perform'), ('computing', 'comput'), ('cluster', 'cluster'), ('system', 'system'), ('(', '('), ('HPCC', 'hpcc'), (')', ')'), ('also', 'also'), ('possible', 'possibl'), ('solution', 'solut'), ('early', 'earli'), ('stage', 'stage'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Since', 'sinc'), ('big', 'big'), ('data', 'data'), ('analysis', 'analysi'), ('generally', 'general'), ('regarded', 'regard'), ('high', 'high'), ('computation', 'comput'), ('cost', 'cost'), ('work', 'work'), (',', ','), ('high', 'high'), ('performance', 'perform'), ('computing', 'comput'), ('cluster', 'cluster'), ('system', 'system'), ('(', '('), ('HPCC', 'hpcc'), (')', ')'), ('also', 'also'), ('possible', 'possibl'), ('solution', 'solut'), ('early', 'earli'), ('stage', 'stage'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('.', '.')]

>> Lemmatization: 
 [('Since', 'Since'), ('big', 'big'), ('data', 'data'), ('analysis', 'analysis'), ('generally', 'generally'), ('regarded', 'regarded'), ('high', 'high'), ('computation', 'computation'), ('cost', 'cost'), ('work', 'work'), (',', ','), ('high', 'high'), ('performance', 'performance'), ('computing', 'computing'), ('cluster', 'cluster'), ('system', 'system'), ('(', '('), ('HPCC', 'HPCC'), (')', ')'), ('also', 'also'), ('possible', 'possible'), ('solution', 'solution'), ('early', 'early'), ('stage', 'stage'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('.', '.')]


------------------- Sentence 5 -------------------

Sagiroglu and Sinanc [105] therefore compare the char- acteristics between HPCC and Hadoop.

>> Tokens are: 
 ['Sagiroglu', 'Sinanc', '[', '105', ']', 'therefore', 'compare', 'char-', 'acteristics', 'HPCC', 'Hadoop', '.']

>> Bigrams are: 
 [('Sagiroglu', 'Sinanc'), ('Sinanc', '['), ('[', '105'), ('105', ']'), (']', 'therefore'), ('therefore', 'compare'), ('compare', 'char-'), ('char-', 'acteristics'), ('acteristics', 'HPCC'), ('HPCC', 'Hadoop'), ('Hadoop', '.')]

>> Trigrams are: 
 [('Sagiroglu', 'Sinanc', '['), ('Sinanc', '[', '105'), ('[', '105', ']'), ('105', ']', 'therefore'), (']', 'therefore', 'compare'), ('therefore', 'compare', 'char-'), ('compare', 'char-', 'acteristics'), ('char-', 'acteristics', 'HPCC'), ('acteristics', 'HPCC', 'Hadoop'), ('HPCC', 'Hadoop', '.')]

>> POS Tags are: 
 [('Sagiroglu', 'NNP'), ('Sinanc', 'NNP'), ('[', 'VBZ'), ('105', 'CD'), (']', 'NN'), ('therefore', 'RB'), ('compare', 'JJ'), ('char-', 'JJ'), ('acteristics', 'NNS'), ('HPCC', 'NNP'), ('Hadoop', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Sagiroglu Sinanc', ']', 'compare char- acteristics HPCC Hadoop']

>> Named Entities are: 
 [('PERSON', 'Sagiroglu'), ('ORGANIZATION', 'Sinanc'), ('ORGANIZATION', 'HPCC Hadoop')] 

>> Stemming using Porter Stemmer: 
 [('Sagiroglu', 'sagiroglu'), ('Sinanc', 'sinanc'), ('[', '['), ('105', '105'), (']', ']'), ('therefore', 'therefor'), ('compare', 'compar'), ('char-', 'char-'), ('acteristics', 'acterist'), ('HPCC', 'hpcc'), ('Hadoop', 'hadoop'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Sagiroglu', 'sagiroglu'), ('Sinanc', 'sinanc'), ('[', '['), ('105', '105'), (']', ']'), ('therefore', 'therefor'), ('compare', 'compar'), ('char-', 'char-'), ('acteristics', 'acterist'), ('HPCC', 'hpcc'), ('Hadoop', 'hadoop'), ('.', '.')]

>> Lemmatization: 
 [('Sagiroglu', 'Sagiroglu'), ('Sinanc', 'Sinanc'), ('[', '['), ('105', '105'), (']', ']'), ('therefore', 'therefore'), ('compare', 'compare'), ('char-', 'char-'), ('acteristics', 'acteristics'), ('HPCC', 'HPCC'), ('Hadoop', 'Hadoop'), ('.', '.')]


------------------- Sentence 6 -------------------

They then emphasized that HPCC system uses  the multikey and multivariate indexes on distributed file system while Hadoop uses the

>> Tokens are: 
 ['They', 'emphasized', 'HPCC', 'system', 'uses', 'multikey', 'multivariate', 'indexes', 'distributed', 'file', 'system', 'Hadoop', 'uses']

>> Bigrams are: 
 [('They', 'emphasized'), ('emphasized', 'HPCC'), ('HPCC', 'system'), ('system', 'uses'), ('uses', 'multikey'), ('multikey', 'multivariate'), ('multivariate', 'indexes'), ('indexes', 'distributed'), ('distributed', 'file'), ('file', 'system'), ('system', 'Hadoop'), ('Hadoop', 'uses')]

>> Trigrams are: 
 [('They', 'emphasized', 'HPCC'), ('emphasized', 'HPCC', 'system'), ('HPCC', 'system', 'uses'), ('system', 'uses', 'multikey'), ('uses', 'multikey', 'multivariate'), ('multikey', 'multivariate', 'indexes'), ('multivariate', 'indexes', 'distributed'), ('indexes', 'distributed', 'file'), ('distributed', 'file', 'system'), ('file', 'system', 'Hadoop'), ('system', 'Hadoop', 'uses')]

>> POS Tags are: 
 [('They', 'PRP'), ('emphasized', 'VBD'), ('HPCC', 'NNP'), ('system', 'NN'), ('uses', 'VBZ'), ('multikey', 'JJ'), ('multivariate', 'NN'), ('indexes', 'NNS'), ('distributed', 'VBN'), ('file', 'NN'), ('system', 'NN'), ('Hadoop', 'NNP'), ('uses', 'VBZ')]

>> Noun Phrases are: 
 ['HPCC system', 'multikey multivariate indexes', 'file system Hadoop']

>> Named Entities are: 
 [('ORGANIZATION', 'HPCC'), ('PERSON', 'Hadoop')] 

>> Stemming using Porter Stemmer: 
 [('They', 'they'), ('emphasized', 'emphas'), ('HPCC', 'hpcc'), ('system', 'system'), ('uses', 'use'), ('multikey', 'multikey'), ('multivariate', 'multivari'), ('indexes', 'index'), ('distributed', 'distribut'), ('file', 'file'), ('system', 'system'), ('Hadoop', 'hadoop'), ('uses', 'use')]

>> Stemming using Snowball Stemmer: 
 [('They', 'they'), ('emphasized', 'emphas'), ('HPCC', 'hpcc'), ('system', 'system'), ('uses', 'use'), ('multikey', 'multikey'), ('multivariate', 'multivari'), ('indexes', 'index'), ('distributed', 'distribut'), ('file', 'file'), ('system', 'system'), ('Hadoop', 'hadoop'), ('uses', 'use')]

>> Lemmatization: 
 [('They', 'They'), ('emphasized', 'emphasized'), ('HPCC', 'HPCC'), ('system', 'system'), ('uses', 'us'), ('multikey', 'multikey'), ('multivariate', 'multivariate'), ('indexes', 'index'), ('distributed', 'distributed'), ('file', 'file'), ('system', 'system'), ('Hadoop', 'Hadoop'), ('uses', 'us')]



========================================== PARAGRAPH 254 ===========================================

Page 16 of 32Tsai et al. Journal of Big Data  (2015) 2:21  

------------------- Sentence 1 -------------------

Page 16 of 32Tsai et al.

>> Tokens are: 
 ['Page', '16', '32Tsai', 'et', 'al', '.']

>> Bigrams are: 
 [('Page', '16'), ('16', '32Tsai'), ('32Tsai', 'et'), ('et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('Page', '16', '32Tsai'), ('16', '32Tsai', 'et'), ('32Tsai', 'et', 'al'), ('et', 'al', '.')]

>> POS Tags are: 
 [('Page', 'NN'), ('16', 'CD'), ('32Tsai', 'CD'), ('et', 'NN'), ('al', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Page', 'et al']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Page', 'page'), ('16', '16'), ('32Tsai', '32tsai'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Page', 'page'), ('16', '16'), ('32Tsai', '32tsai'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('Page', 'Page'), ('16', '16'), ('32Tsai', '32Tsai'), ('et', 'et'), ('al', 'al'), ('.', '.')]


------------------- Sentence 2 -------------------

Journal of Big Data  (2015) 2:21

>> Tokens are: 
 ['Journal', 'Big', 'Data', '(', '2015', ')', '2:21']

>> Bigrams are: 
 [('Journal', 'Big'), ('Big', 'Data'), ('Data', '('), ('(', '2015'), ('2015', ')'), (')', '2:21')]

>> Trigrams are: 
 [('Journal', 'Big', 'Data'), ('Big', 'Data', '('), ('Data', '(', '2015'), ('(', '2015', ')'), ('2015', ')', '2:21')]

>> POS Tags are: 
 [('Journal', 'NNP'), ('Big', 'NNP'), ('Data', 'NNP'), ('(', '('), ('2015', 'CD'), (')', ')'), ('2:21', 'CD')]

>> Noun Phrases are: 
 ['Journal Big Data']

>> Named Entities are: 
 [('PERSON', 'Journal')] 

>> Stemming using Porter Stemmer: 
 [('Journal', 'journal'), ('Big', 'big'), ('Data', 'data'), ('(', '('), ('2015', '2015'), (')', ')'), ('2:21', '2:21')]

>> Stemming using Snowball Stemmer: 
 [('Journal', 'journal'), ('Big', 'big'), ('Data', 'data'), ('(', '('), ('2015', '2015'), (')', ')'), ('2:21', '2:21')]

>> Lemmatization: 
 [('Journal', 'Journal'), ('Big', 'Big'), ('Data', 'Data'), ('(', '('), ('2015', '2015'), (')', ')'), ('2:21', '2:21')]



========================================== PARAGRAPH 255 ===========================================

column-oriented database. In [17], Chen et al. give a brief introduction to the big data  analytics of business intelligence (BI) from the perspective of evolution, applications,  and emerging research topics. In their survey, Chen et al. explained that the revolution  of business intelligence and analytics (BI&I) was from BI&I 1.0, BI&I 2.0, to BI&I 3.0  which are DBMS-based and structured content, web-based and unstructured content,  and mobile and sensor based content, respectively. 

------------------- Sentence 1 -------------------

column-oriented database.

>> Tokens are: 
 ['column-oriented', 'database', '.']

>> Bigrams are: 
 [('column-oriented', 'database'), ('database', '.')]

>> Trigrams are: 
 [('column-oriented', 'database', '.')]

>> POS Tags are: 
 [('column-oriented', 'JJ'), ('database', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['column-oriented database']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('column-oriented', 'column-ori'), ('database', 'databas'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('column-oriented', 'column-ori'), ('database', 'databas'), ('.', '.')]

>> Lemmatization: 
 [('column-oriented', 'column-oriented'), ('database', 'database'), ('.', '.')]


------------------- Sentence 2 -------------------

In [17], Chen et al.

>> Tokens are: 
 ['In', '[', '17', ']', ',', 'Chen', 'et', 'al', '.']

>> Bigrams are: 
 [('In', '['), ('[', '17'), ('17', ']'), (']', ','), (',', 'Chen'), ('Chen', 'et'), ('et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('In', '[', '17'), ('[', '17', ']'), ('17', ']', ','), (']', ',', 'Chen'), (',', 'Chen', 'et'), ('Chen', 'et', 'al'), ('et', 'al', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('[', '$'), ('17', 'CD'), (']', 'NNP'), (',', ','), ('Chen', 'NNP'), ('et', 'VBZ'), ('al', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 [']', 'Chen', 'al']

>> Named Entities are: 
 [('PERSON', 'Chen')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('[', '['), ('17', '17'), (']', ']'), (',', ','), ('Chen', 'chen'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('[', '['), ('17', '17'), (']', ']'), (',', ','), ('Chen', 'chen'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('[', '['), ('17', '17'), (']', ']'), (',', ','), ('Chen', 'Chen'), ('et', 'et'), ('al', 'al'), ('.', '.')]


------------------- Sentence 3 -------------------

give a brief introduction to the big data  analytics of business intelligence (BI) from the perspective of evolution, applications,  and emerging research topics.

>> Tokens are: 
 ['give', 'brief', 'introduction', 'big', 'data', 'analytics', 'business', 'intelligence', '(', 'BI', ')', 'perspective', 'evolution', ',', 'applications', ',', 'emerging', 'research', 'topics', '.']

>> Bigrams are: 
 [('give', 'brief'), ('brief', 'introduction'), ('introduction', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', 'business'), ('business', 'intelligence'), ('intelligence', '('), ('(', 'BI'), ('BI', ')'), (')', 'perspective'), ('perspective', 'evolution'), ('evolution', ','), (',', 'applications'), ('applications', ','), (',', 'emerging'), ('emerging', 'research'), ('research', 'topics'), ('topics', '.')]

>> Trigrams are: 
 [('give', 'brief', 'introduction'), ('brief', 'introduction', 'big'), ('introduction', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', 'business'), ('analytics', 'business', 'intelligence'), ('business', 'intelligence', '('), ('intelligence', '(', 'BI'), ('(', 'BI', ')'), ('BI', ')', 'perspective'), (')', 'perspective', 'evolution'), ('perspective', 'evolution', ','), ('evolution', ',', 'applications'), (',', 'applications', ','), ('applications', ',', 'emerging'), (',', 'emerging', 'research'), ('emerging', 'research', 'topics'), ('research', 'topics', '.')]

>> POS Tags are: 
 [('give', 'JJ'), ('brief', 'NN'), ('introduction', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('business', 'NN'), ('intelligence', 'NN'), ('(', '('), ('BI', 'NNP'), (')', ')'), ('perspective', 'NN'), ('evolution', 'NN'), (',', ','), ('applications', 'NNS'), (',', ','), ('emerging', 'VBG'), ('research', 'NN'), ('topics', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['give brief introduction', 'big data analytics business intelligence', 'BI', 'perspective evolution', 'applications', 'research topics']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('give', 'give'), ('brief', 'brief'), ('introduction', 'introduct'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('business', 'busi'), ('intelligence', 'intellig'), ('(', '('), ('BI', 'bi'), (')', ')'), ('perspective', 'perspect'), ('evolution', 'evolut'), (',', ','), ('applications', 'applic'), (',', ','), ('emerging', 'emerg'), ('research', 'research'), ('topics', 'topic'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('give', 'give'), ('brief', 'brief'), ('introduction', 'introduct'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('business', 'busi'), ('intelligence', 'intellig'), ('(', '('), ('BI', 'bi'), (')', ')'), ('perspective', 'perspect'), ('evolution', 'evolut'), (',', ','), ('applications', 'applic'), (',', ','), ('emerging', 'emerg'), ('research', 'research'), ('topics', 'topic'), ('.', '.')]

>> Lemmatization: 
 [('give', 'give'), ('brief', 'brief'), ('introduction', 'introduction'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('business', 'business'), ('intelligence', 'intelligence'), ('(', '('), ('BI', 'BI'), (')', ')'), ('perspective', 'perspective'), ('evolution', 'evolution'), (',', ','), ('applications', 'application'), (',', ','), ('emerging', 'emerging'), ('research', 'research'), ('topics', 'topic'), ('.', '.')]


------------------- Sentence 4 -------------------

In their survey, Chen et al.

>> Tokens are: 
 ['In', 'survey', ',', 'Chen', 'et', 'al', '.']

>> Bigrams are: 
 [('In', 'survey'), ('survey', ','), (',', 'Chen'), ('Chen', 'et'), ('et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('In', 'survey', ','), ('survey', ',', 'Chen'), (',', 'Chen', 'et'), ('Chen', 'et', 'al'), ('et', 'al', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('survey', 'NN'), (',', ','), ('Chen', 'NNP'), ('et', 'VBZ'), ('al', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['survey', 'Chen', 'al']

>> Named Entities are: 
 [('PERSON', 'Chen')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('survey', 'survey'), (',', ','), ('Chen', 'chen'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('survey', 'survey'), (',', ','), ('Chen', 'chen'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('survey', 'survey'), (',', ','), ('Chen', 'Chen'), ('et', 'et'), ('al', 'al'), ('.', '.')]


------------------- Sentence 5 -------------------

explained that the revolution  of business intelligence and analytics (BI&I) was from BI&I 1.0, BI&I 2.0, to BI&I 3.0  which are DBMS-based and structured content, web-based and unstructured content,  and mobile and sensor based content, respectively.

>> Tokens are: 
 ['explained', 'revolution', 'business', 'intelligence', 'analytics', '(', 'BI', '&', 'I', ')', 'BI', '&', 'I', '1.0', ',', 'BI', '&', 'I', '2.0', ',', 'BI', '&', 'I', '3.0', 'DBMS-based', 'structured', 'content', ',', 'web-based', 'unstructured', 'content', ',', 'mobile', 'sensor', 'based', 'content', ',', 'respectively', '.']

>> Bigrams are: 
 [('explained', 'revolution'), ('revolution', 'business'), ('business', 'intelligence'), ('intelligence', 'analytics'), ('analytics', '('), ('(', 'BI'), ('BI', '&'), ('&', 'I'), ('I', ')'), (')', 'BI'), ('BI', '&'), ('&', 'I'), ('I', '1.0'), ('1.0', ','), (',', 'BI'), ('BI', '&'), ('&', 'I'), ('I', '2.0'), ('2.0', ','), (',', 'BI'), ('BI', '&'), ('&', 'I'), ('I', '3.0'), ('3.0', 'DBMS-based'), ('DBMS-based', 'structured'), ('structured', 'content'), ('content', ','), (',', 'web-based'), ('web-based', 'unstructured'), ('unstructured', 'content'), ('content', ','), (',', 'mobile'), ('mobile', 'sensor'), ('sensor', 'based'), ('based', 'content'), ('content', ','), (',', 'respectively'), ('respectively', '.')]

>> Trigrams are: 
 [('explained', 'revolution', 'business'), ('revolution', 'business', 'intelligence'), ('business', 'intelligence', 'analytics'), ('intelligence', 'analytics', '('), ('analytics', '(', 'BI'), ('(', 'BI', '&'), ('BI', '&', 'I'), ('&', 'I', ')'), ('I', ')', 'BI'), (')', 'BI', '&'), ('BI', '&', 'I'), ('&', 'I', '1.0'), ('I', '1.0', ','), ('1.0', ',', 'BI'), (',', 'BI', '&'), ('BI', '&', 'I'), ('&', 'I', '2.0'), ('I', '2.0', ','), ('2.0', ',', 'BI'), (',', 'BI', '&'), ('BI', '&', 'I'), ('&', 'I', '3.0'), ('I', '3.0', 'DBMS-based'), ('3.0', 'DBMS-based', 'structured'), ('DBMS-based', 'structured', 'content'), ('structured', 'content', ','), ('content', ',', 'web-based'), (',', 'web-based', 'unstructured'), ('web-based', 'unstructured', 'content'), ('unstructured', 'content', ','), ('content', ',', 'mobile'), (',', 'mobile', 'sensor'), ('mobile', 'sensor', 'based'), ('sensor', 'based', 'content'), ('based', 'content', ','), ('content', ',', 'respectively'), (',', 'respectively', '.')]

>> POS Tags are: 
 [('explained', 'VBN'), ('revolution', 'NN'), ('business', 'NN'), ('intelligence', 'NN'), ('analytics', 'NNS'), ('(', '('), ('BI', 'NNP'), ('&', 'CC'), ('I', 'PRP'), (')', ')'), ('BI', 'NNP'), ('&', 'CC'), ('I', 'PRP'), ('1.0', 'CD'), (',', ','), ('BI', 'NNP'), ('&', 'CC'), ('I', 'PRP'), ('2.0', 'CD'), (',', ','), ('BI', 'NNP'), ('&', 'CC'), ('I', 'PRP'), ('3.0', 'CD'), ('DBMS-based', 'JJ'), ('structured', 'JJ'), ('content', 'NN'), (',', ','), ('web-based', 'JJ'), ('unstructured', 'JJ'), ('content', 'NN'), (',', ','), ('mobile', 'NN'), ('sensor', 'NN'), ('based', 'VBN'), ('content', 'NN'), (',', ','), ('respectively', 'RB'), ('.', '.')]

>> Noun Phrases are: 
 ['revolution business intelligence analytics', 'BI', 'BI', 'BI', 'BI', 'DBMS-based structured content', 'web-based unstructured content', 'mobile sensor', 'content']

>> Named Entities are: 
 [('ORGANIZATION', 'BI'), ('ORGANIZATION', 'BI'), ('ORGANIZATION', 'BI')] 

>> Stemming using Porter Stemmer: 
 [('explained', 'explain'), ('revolution', 'revolut'), ('business', 'busi'), ('intelligence', 'intellig'), ('analytics', 'analyt'), ('(', '('), ('BI', 'bi'), ('&', '&'), ('I', 'i'), (')', ')'), ('BI', 'bi'), ('&', '&'), ('I', 'i'), ('1.0', '1.0'), (',', ','), ('BI', 'bi'), ('&', '&'), ('I', 'i'), ('2.0', '2.0'), (',', ','), ('BI', 'bi'), ('&', '&'), ('I', 'i'), ('3.0', '3.0'), ('DBMS-based', 'dbms-base'), ('structured', 'structur'), ('content', 'content'), (',', ','), ('web-based', 'web-bas'), ('unstructured', 'unstructur'), ('content', 'content'), (',', ','), ('mobile', 'mobil'), ('sensor', 'sensor'), ('based', 'base'), ('content', 'content'), (',', ','), ('respectively', 'respect'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('explained', 'explain'), ('revolution', 'revolut'), ('business', 'busi'), ('intelligence', 'intellig'), ('analytics', 'analyt'), ('(', '('), ('BI', 'bi'), ('&', '&'), ('I', 'i'), (')', ')'), ('BI', 'bi'), ('&', '&'), ('I', 'i'), ('1.0', '1.0'), (',', ','), ('BI', 'bi'), ('&', '&'), ('I', 'i'), ('2.0', '2.0'), (',', ','), ('BI', 'bi'), ('&', '&'), ('I', 'i'), ('3.0', '3.0'), ('DBMS-based', 'dbms-base'), ('structured', 'structur'), ('content', 'content'), (',', ','), ('web-based', 'web-bas'), ('unstructured', 'unstructur'), ('content', 'content'), (',', ','), ('mobile', 'mobil'), ('sensor', 'sensor'), ('based', 'base'), ('content', 'content'), (',', ','), ('respectively', 'respect'), ('.', '.')]

>> Lemmatization: 
 [('explained', 'explained'), ('revolution', 'revolution'), ('business', 'business'), ('intelligence', 'intelligence'), ('analytics', 'analytics'), ('(', '('), ('BI', 'BI'), ('&', '&'), ('I', 'I'), (')', ')'), ('BI', 'BI'), ('&', '&'), ('I', 'I'), ('1.0', '1.0'), (',', ','), ('BI', 'BI'), ('&', '&'), ('I', 'I'), ('2.0', '2.0'), (',', ','), ('BI', 'BI'), ('&', '&'), ('I', 'I'), ('3.0', '3.0'), ('DBMS-based', 'DBMS-based'), ('structured', 'structured'), ('content', 'content'), (',', ','), ('web-based', 'web-based'), ('unstructured', 'unstructured'), ('content', 'content'), (',', ','), ('mobile', 'mobile'), ('sensor', 'sensor'), ('based', 'based'), ('content', 'content'), (',', ','), ('respectively', 'respectively'), ('.', '.')]



========================================== PARAGRAPH 256 ===========================================

Big data analysis algorithms 

------------------- Sentence 1 -------------------

Big data analysis algorithms

>> Tokens are: 
 ['Big', 'data', 'analysis', 'algorithms']

>> Bigrams are: 
 [('Big', 'data'), ('data', 'analysis'), ('analysis', 'algorithms')]

>> Trigrams are: 
 [('Big', 'data', 'analysis'), ('data', 'analysis', 'algorithms')]

>> POS Tags are: 
 [('Big', 'NNP'), ('data', 'NNS'), ('analysis', 'NN'), ('algorithms', 'NN')]

>> Noun Phrases are: 
 ['Big data analysis algorithms']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('analysis', 'analysi'), ('algorithms', 'algorithm')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('analysis', 'analysi'), ('algorithms', 'algorithm')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), ('analysis', 'analysis'), ('algorithms', 'algorithm')]



========================================== PARAGRAPH 257 ===========================================

Mining algorithms for specific problem 

------------------- Sentence 1 -------------------

Mining algorithms for specific problem

>> Tokens are: 
 ['Mining', 'algorithms', 'specific', 'problem']

>> Bigrams are: 
 [('Mining', 'algorithms'), ('algorithms', 'specific'), ('specific', 'problem')]

>> Trigrams are: 
 [('Mining', 'algorithms', 'specific'), ('algorithms', 'specific', 'problem')]

>> POS Tags are: 
 [('Mining', 'VBG'), ('algorithms', 'NN'), ('specific', 'NN'), ('problem', 'NN')]

>> Noun Phrases are: 
 ['algorithms specific problem']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Mining', 'mine'), ('algorithms', 'algorithm'), ('specific', 'specif'), ('problem', 'problem')]

>> Stemming using Snowball Stemmer: 
 [('Mining', 'mine'), ('algorithms', 'algorithm'), ('specific', 'specif'), ('problem', 'problem')]

>> Lemmatization: 
 [('Mining', 'Mining'), ('algorithms', 'algorithm'), ('specific', 'specific'), ('problem', 'problem')]



========================================== PARAGRAPH 258 ===========================================

Because the big data issues have appeared for nearly ten years, in [106], Fan and Bifet  pointed out that the terms “big data” [107] and “big data mining” [108] were first pre- sented in 1998, respectively. The big data and big data mining almost appearing at the  same time explained that finding something from big data will be one of the major tasks  in this research domain. Data mining algorithms for data analysis also play the vital  role in the big data analysis, in terms of the computation cost, memory requirement,  and accuracy of the end results. In this section, we will give a brief discussion from the  perspective of analysis and search algorithms to explain its importance for big data  analytics. 

------------------- Sentence 1 -------------------

Because the big data issues have appeared for nearly ten years, in [106], Fan and Bifet  pointed out that the terms “big data” [107] and “big data mining” [108] were first pre- sented in 1998, respectively.

>> Tokens are: 
 ['Because', 'big', 'data', 'issues', 'appeared', 'nearly', 'ten', 'years', ',', '[', '106', ']', ',', 'Fan', 'Bifet', 'pointed', 'terms', '“', 'big', 'data', '”', '[', '107', ']', '“', 'big', 'data', 'mining', '”', '[', '108', ']', 'first', 'pre-', 'sented', '1998', ',', 'respectively', '.']

>> Bigrams are: 
 [('Because', 'big'), ('big', 'data'), ('data', 'issues'), ('issues', 'appeared'), ('appeared', 'nearly'), ('nearly', 'ten'), ('ten', 'years'), ('years', ','), (',', '['), ('[', '106'), ('106', ']'), (']', ','), (',', 'Fan'), ('Fan', 'Bifet'), ('Bifet', 'pointed'), ('pointed', 'terms'), ('terms', '“'), ('“', 'big'), ('big', 'data'), ('data', '”'), ('”', '['), ('[', '107'), ('107', ']'), (']', '“'), ('“', 'big'), ('big', 'data'), ('data', 'mining'), ('mining', '”'), ('”', '['), ('[', '108'), ('108', ']'), (']', 'first'), ('first', 'pre-'), ('pre-', 'sented'), ('sented', '1998'), ('1998', ','), (',', 'respectively'), ('respectively', '.')]

>> Trigrams are: 
 [('Because', 'big', 'data'), ('big', 'data', 'issues'), ('data', 'issues', 'appeared'), ('issues', 'appeared', 'nearly'), ('appeared', 'nearly', 'ten'), ('nearly', 'ten', 'years'), ('ten', 'years', ','), ('years', ',', '['), (',', '[', '106'), ('[', '106', ']'), ('106', ']', ','), (']', ',', 'Fan'), (',', 'Fan', 'Bifet'), ('Fan', 'Bifet', 'pointed'), ('Bifet', 'pointed', 'terms'), ('pointed', 'terms', '“'), ('terms', '“', 'big'), ('“', 'big', 'data'), ('big', 'data', '”'), ('data', '”', '['), ('”', '[', '107'), ('[', '107', ']'), ('107', ']', '“'), (']', '“', 'big'), ('“', 'big', 'data'), ('big', 'data', 'mining'), ('data', 'mining', '”'), ('mining', '”', '['), ('”', '[', '108'), ('[', '108', ']'), ('108', ']', 'first'), (']', 'first', 'pre-'), ('first', 'pre-', 'sented'), ('pre-', 'sented', '1998'), ('sented', '1998', ','), ('1998', ',', 'respectively'), (',', 'respectively', '.')]

>> POS Tags are: 
 [('Because', 'IN'), ('big', 'JJ'), ('data', 'NNS'), ('issues', 'NNS'), ('appeared', 'VBD'), ('nearly', 'RB'), ('ten', 'JJ'), ('years', 'NNS'), (',', ','), ('[', 'VBD'), ('106', 'CD'), (']', 'NN'), (',', ','), ('Fan', 'NNP'), ('Bifet', 'NNP'), ('pointed', 'VBD'), ('terms', 'NNS'), ('“', 'VBP'), ('big', 'JJ'), ('data', 'NNS'), ('”', 'VBD'), ('[', 'JJ'), ('107', 'CD'), (']', 'NN'), ('“', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('mining', 'NN'), ('”', 'NNP'), ('[', 'VBZ'), ('108', 'CD'), (']', 'NN'), ('first', 'RB'), ('pre-', 'RB'), ('sented', 'JJ'), ('1998', 'CD'), (',', ','), ('respectively', 'RB'), ('.', '.')]

>> Noun Phrases are: 
 ['big data issues', 'ten years', ']', 'Fan Bifet', 'terms', 'big data', '] “', 'big data mining ”', ']']

>> Named Entities are: 
 [('PERSON', 'Fan Bifet')] 

>> Stemming using Porter Stemmer: 
 [('Because', 'becaus'), ('big', 'big'), ('data', 'data'), ('issues', 'issu'), ('appeared', 'appear'), ('nearly', 'nearli'), ('ten', 'ten'), ('years', 'year'), (',', ','), ('[', '['), ('106', '106'), (']', ']'), (',', ','), ('Fan', 'fan'), ('Bifet', 'bifet'), ('pointed', 'point'), ('terms', 'term'), ('“', '“'), ('big', 'big'), ('data', 'data'), ('”', '”'), ('[', '['), ('107', '107'), (']', ']'), ('“', '“'), ('big', 'big'), ('data', 'data'), ('mining', 'mine'), ('”', '”'), ('[', '['), ('108', '108'), (']', ']'), ('first', 'first'), ('pre-', 'pre-'), ('sented', 'sent'), ('1998', '1998'), (',', ','), ('respectively', 'respect'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Because', 'becaus'), ('big', 'big'), ('data', 'data'), ('issues', 'issu'), ('appeared', 'appear'), ('nearly', 'near'), ('ten', 'ten'), ('years', 'year'), (',', ','), ('[', '['), ('106', '106'), (']', ']'), (',', ','), ('Fan', 'fan'), ('Bifet', 'bifet'), ('pointed', 'point'), ('terms', 'term'), ('“', '“'), ('big', 'big'), ('data', 'data'), ('”', '”'), ('[', '['), ('107', '107'), (']', ']'), ('“', '“'), ('big', 'big'), ('data', 'data'), ('mining', 'mine'), ('”', '”'), ('[', '['), ('108', '108'), (']', ']'), ('first', 'first'), ('pre-', 'pre-'), ('sented', 'sent'), ('1998', '1998'), (',', ','), ('respectively', 'respect'), ('.', '.')]

>> Lemmatization: 
 [('Because', 'Because'), ('big', 'big'), ('data', 'data'), ('issues', 'issue'), ('appeared', 'appeared'), ('nearly', 'nearly'), ('ten', 'ten'), ('years', 'year'), (',', ','), ('[', '['), ('106', '106'), (']', ']'), (',', ','), ('Fan', 'Fan'), ('Bifet', 'Bifet'), ('pointed', 'pointed'), ('terms', 'term'), ('“', '“'), ('big', 'big'), ('data', 'data'), ('”', '”'), ('[', '['), ('107', '107'), (']', ']'), ('“', '“'), ('big', 'big'), ('data', 'data'), ('mining', 'mining'), ('”', '”'), ('[', '['), ('108', '108'), (']', ']'), ('first', 'first'), ('pre-', 'pre-'), ('sented', 'sented'), ('1998', '1998'), (',', ','), ('respectively', 'respectively'), ('.', '.')]


------------------- Sentence 2 -------------------

The big data and big data mining almost appearing at the  same time explained that finding something from big data will be one of the major tasks  in this research domain.

>> Tokens are: 
 ['The', 'big', 'data', 'big', 'data', 'mining', 'almost', 'appearing', 'time', 'explained', 'finding', 'something', 'big', 'data', 'one', 'major', 'tasks', 'research', 'domain', '.']

>> Bigrams are: 
 [('The', 'big'), ('big', 'data'), ('data', 'big'), ('big', 'data'), ('data', 'mining'), ('mining', 'almost'), ('almost', 'appearing'), ('appearing', 'time'), ('time', 'explained'), ('explained', 'finding'), ('finding', 'something'), ('something', 'big'), ('big', 'data'), ('data', 'one'), ('one', 'major'), ('major', 'tasks'), ('tasks', 'research'), ('research', 'domain'), ('domain', '.')]

>> Trigrams are: 
 [('The', 'big', 'data'), ('big', 'data', 'big'), ('data', 'big', 'data'), ('big', 'data', 'mining'), ('data', 'mining', 'almost'), ('mining', 'almost', 'appearing'), ('almost', 'appearing', 'time'), ('appearing', 'time', 'explained'), ('time', 'explained', 'finding'), ('explained', 'finding', 'something'), ('finding', 'something', 'big'), ('something', 'big', 'data'), ('big', 'data', 'one'), ('data', 'one', 'major'), ('one', 'major', 'tasks'), ('major', 'tasks', 'research'), ('tasks', 'research', 'domain'), ('research', 'domain', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('big', 'JJ'), ('data', 'NNS'), ('big', 'JJ'), ('data', 'NNS'), ('mining', 'NN'), ('almost', 'RB'), ('appearing', 'JJ'), ('time', 'NN'), ('explained', 'VBD'), ('finding', 'VBG'), ('something', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('one', 'CD'), ('major', 'JJ'), ('tasks', 'NNS'), ('research', 'NN'), ('domain', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['The big data', 'big data mining', 'appearing time', 'something', 'big data', 'major tasks research domain']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('big', 'big'), ('data', 'data'), ('big', 'big'), ('data', 'data'), ('mining', 'mine'), ('almost', 'almost'), ('appearing', 'appear'), ('time', 'time'), ('explained', 'explain'), ('finding', 'find'), ('something', 'someth'), ('big', 'big'), ('data', 'data'), ('one', 'one'), ('major', 'major'), ('tasks', 'task'), ('research', 'research'), ('domain', 'domain'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('big', 'big'), ('data', 'data'), ('big', 'big'), ('data', 'data'), ('mining', 'mine'), ('almost', 'almost'), ('appearing', 'appear'), ('time', 'time'), ('explained', 'explain'), ('finding', 'find'), ('something', 'someth'), ('big', 'big'), ('data', 'data'), ('one', 'one'), ('major', 'major'), ('tasks', 'task'), ('research', 'research'), ('domain', 'domain'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('big', 'big'), ('data', 'data'), ('big', 'big'), ('data', 'data'), ('mining', 'mining'), ('almost', 'almost'), ('appearing', 'appearing'), ('time', 'time'), ('explained', 'explained'), ('finding', 'finding'), ('something', 'something'), ('big', 'big'), ('data', 'data'), ('one', 'one'), ('major', 'major'), ('tasks', 'task'), ('research', 'research'), ('domain', 'domain'), ('.', '.')]


------------------- Sentence 3 -------------------

Data mining algorithms for data analysis also play the vital  role in the big data analysis, in terms of the computation cost, memory requirement,  and accuracy of the end results.

>> Tokens are: 
 ['Data', 'mining', 'algorithms', 'data', 'analysis', 'also', 'play', 'vital', 'role', 'big', 'data', 'analysis', ',', 'terms', 'computation', 'cost', ',', 'memory', 'requirement', ',', 'accuracy', 'end', 'results', '.']

>> Bigrams are: 
 [('Data', 'mining'), ('mining', 'algorithms'), ('algorithms', 'data'), ('data', 'analysis'), ('analysis', 'also'), ('also', 'play'), ('play', 'vital'), ('vital', 'role'), ('role', 'big'), ('big', 'data'), ('data', 'analysis'), ('analysis', ','), (',', 'terms'), ('terms', 'computation'), ('computation', 'cost'), ('cost', ','), (',', 'memory'), ('memory', 'requirement'), ('requirement', ','), (',', 'accuracy'), ('accuracy', 'end'), ('end', 'results'), ('results', '.')]

>> Trigrams are: 
 [('Data', 'mining', 'algorithms'), ('mining', 'algorithms', 'data'), ('algorithms', 'data', 'analysis'), ('data', 'analysis', 'also'), ('analysis', 'also', 'play'), ('also', 'play', 'vital'), ('play', 'vital', 'role'), ('vital', 'role', 'big'), ('role', 'big', 'data'), ('big', 'data', 'analysis'), ('data', 'analysis', ','), ('analysis', ',', 'terms'), (',', 'terms', 'computation'), ('terms', 'computation', 'cost'), ('computation', 'cost', ','), ('cost', ',', 'memory'), (',', 'memory', 'requirement'), ('memory', 'requirement', ','), ('requirement', ',', 'accuracy'), (',', 'accuracy', 'end'), ('accuracy', 'end', 'results'), ('end', 'results', '.')]

>> POS Tags are: 
 [('Data', 'NNP'), ('mining', 'NN'), ('algorithms', 'NN'), ('data', 'NNS'), ('analysis', 'NN'), ('also', 'RB'), ('play', 'VBP'), ('vital', 'JJ'), ('role', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('analysis', 'NN'), (',', ','), ('terms', 'NNS'), ('computation', 'NN'), ('cost', 'NN'), (',', ','), ('memory', 'NN'), ('requirement', 'NN'), (',', ','), ('accuracy', 'JJ'), ('end', 'NN'), ('results', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['Data mining algorithms data analysis', 'vital role', 'big data analysis', 'terms computation cost', 'memory requirement', 'accuracy end results']

>> Named Entities are: 
 [('GPE', 'Data')] 

>> Stemming using Porter Stemmer: 
 [('Data', 'data'), ('mining', 'mine'), ('algorithms', 'algorithm'), ('data', 'data'), ('analysis', 'analysi'), ('also', 'also'), ('play', 'play'), ('vital', 'vital'), ('role', 'role'), ('big', 'big'), ('data', 'data'), ('analysis', 'analysi'), (',', ','), ('terms', 'term'), ('computation', 'comput'), ('cost', 'cost'), (',', ','), ('memory', 'memori'), ('requirement', 'requir'), (',', ','), ('accuracy', 'accuraci'), ('end', 'end'), ('results', 'result'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Data', 'data'), ('mining', 'mine'), ('algorithms', 'algorithm'), ('data', 'data'), ('analysis', 'analysi'), ('also', 'also'), ('play', 'play'), ('vital', 'vital'), ('role', 'role'), ('big', 'big'), ('data', 'data'), ('analysis', 'analysi'), (',', ','), ('terms', 'term'), ('computation', 'comput'), ('cost', 'cost'), (',', ','), ('memory', 'memori'), ('requirement', 'requir'), (',', ','), ('accuracy', 'accuraci'), ('end', 'end'), ('results', 'result'), ('.', '.')]

>> Lemmatization: 
 [('Data', 'Data'), ('mining', 'mining'), ('algorithms', 'algorithm'), ('data', 'data'), ('analysis', 'analysis'), ('also', 'also'), ('play', 'play'), ('vital', 'vital'), ('role', 'role'), ('big', 'big'), ('data', 'data'), ('analysis', 'analysis'), (',', ','), ('terms', 'term'), ('computation', 'computation'), ('cost', 'cost'), (',', ','), ('memory', 'memory'), ('requirement', 'requirement'), (',', ','), ('accuracy', 'accuracy'), ('end', 'end'), ('results', 'result'), ('.', '.')]


------------------- Sentence 4 -------------------

In this section, we will give a brief discussion from the  perspective of analysis and search algorithms to explain its importance for big data  analytics.

>> Tokens are: 
 ['In', 'section', ',', 'give', 'brief', 'discussion', 'perspective', 'analysis', 'search', 'algorithms', 'explain', 'importance', 'big', 'data', 'analytics', '.']

>> Bigrams are: 
 [('In', 'section'), ('section', ','), (',', 'give'), ('give', 'brief'), ('brief', 'discussion'), ('discussion', 'perspective'), ('perspective', 'analysis'), ('analysis', 'search'), ('search', 'algorithms'), ('algorithms', 'explain'), ('explain', 'importance'), ('importance', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', '.')]

>> Trigrams are: 
 [('In', 'section', ','), ('section', ',', 'give'), (',', 'give', 'brief'), ('give', 'brief', 'discussion'), ('brief', 'discussion', 'perspective'), ('discussion', 'perspective', 'analysis'), ('perspective', 'analysis', 'search'), ('analysis', 'search', 'algorithms'), ('search', 'algorithms', 'explain'), ('algorithms', 'explain', 'importance'), ('explain', 'importance', 'big'), ('importance', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('section', 'NN'), (',', ','), ('give', 'JJ'), ('brief', 'NN'), ('discussion', 'NN'), ('perspective', 'NN'), ('analysis', 'NN'), ('search', 'NN'), ('algorithms', 'NN'), ('explain', 'VBP'), ('importance', 'NN'), ('big', 'JJ'), ('data', 'NN'), ('analytics', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['section', 'give brief discussion perspective analysis search algorithms', 'importance', 'big data analytics']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('section', 'section'), (',', ','), ('give', 'give'), ('brief', 'brief'), ('discussion', 'discuss'), ('perspective', 'perspect'), ('analysis', 'analysi'), ('search', 'search'), ('algorithms', 'algorithm'), ('explain', 'explain'), ('importance', 'import'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('section', 'section'), (',', ','), ('give', 'give'), ('brief', 'brief'), ('discussion', 'discuss'), ('perspective', 'perspect'), ('analysis', 'analysi'), ('search', 'search'), ('algorithms', 'algorithm'), ('explain', 'explain'), ('importance', 'import'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('section', 'section'), (',', ','), ('give', 'give'), ('brief', 'brief'), ('discussion', 'discussion'), ('perspective', 'perspective'), ('analysis', 'analysis'), ('search', 'search'), ('algorithms', 'algorithm'), ('explain', 'explain'), ('importance', 'importance'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('.', '.')]



========================================== PARAGRAPH 259 ===========================================

Clustering algorithms In the big data age, traditional clustering algorithms will become  even more limited than before because they typically require that all the data be in the  same format and be loaded into the same machine so as to find some useful things from  the whole data. Although the problem [64] of analyzing large-scale and high-dimen- sional dataset has attracted many researchers from various disciplines in the last cen- tury, and several solutions [2, 109] have been presented presented in recent years, the  characteristics of big data still brought up several new challenges for the data clustering  issues. Among them, how to reduce the data complexity is one of the important issues  for big data clustering. In [110], Shirkhorshidi et al. divided the big data clustering into  two categories: single-machine clustering (i.e.-, sampling and dimension reduction solu- tions), and multiple-machine clustering (parallel and MapReduce solutions). This means  that traditional reduction solutions can also be used in the big data age because the  complexity and memory space needed for the process of data analysis will be decreased  by using sampling and dimension reduction methods. More precisely, sampling can be  regarded as reducing the “amount of data” entered into a data analyzing process while  dimension reduction can be regarded as “downsizing the whole dataset” because irrel- evant dimensions will be discarded before the data analyzing process is carried out. 

------------------- Sentence 1 -------------------

Clustering algorithms In the big data age, traditional clustering algorithms will become  even more limited than before because they typically require that all the data be in the  same format and be loaded into the same machine so as to find some useful things from  the whole data.

>> Tokens are: 
 ['Clustering', 'algorithms', 'In', 'big', 'data', 'age', ',', 'traditional', 'clustering', 'algorithms', 'become', 'even', 'limited', 'typically', 'require', 'data', 'format', 'loaded', 'machine', 'find', 'useful', 'things', 'whole', 'data', '.']

>> Bigrams are: 
 [('Clustering', 'algorithms'), ('algorithms', 'In'), ('In', 'big'), ('big', 'data'), ('data', 'age'), ('age', ','), (',', 'traditional'), ('traditional', 'clustering'), ('clustering', 'algorithms'), ('algorithms', 'become'), ('become', 'even'), ('even', 'limited'), ('limited', 'typically'), ('typically', 'require'), ('require', 'data'), ('data', 'format'), ('format', 'loaded'), ('loaded', 'machine'), ('machine', 'find'), ('find', 'useful'), ('useful', 'things'), ('things', 'whole'), ('whole', 'data'), ('data', '.')]

>> Trigrams are: 
 [('Clustering', 'algorithms', 'In'), ('algorithms', 'In', 'big'), ('In', 'big', 'data'), ('big', 'data', 'age'), ('data', 'age', ','), ('age', ',', 'traditional'), (',', 'traditional', 'clustering'), ('traditional', 'clustering', 'algorithms'), ('clustering', 'algorithms', 'become'), ('algorithms', 'become', 'even'), ('become', 'even', 'limited'), ('even', 'limited', 'typically'), ('limited', 'typically', 'require'), ('typically', 'require', 'data'), ('require', 'data', 'format'), ('data', 'format', 'loaded'), ('format', 'loaded', 'machine'), ('loaded', 'machine', 'find'), ('machine', 'find', 'useful'), ('find', 'useful', 'things'), ('useful', 'things', 'whole'), ('things', 'whole', 'data'), ('whole', 'data', '.')]

>> POS Tags are: 
 [('Clustering', 'VBG'), ('algorithms', 'NN'), ('In', 'IN'), ('big', 'JJ'), ('data', 'NNS'), ('age', 'NN'), (',', ','), ('traditional', 'JJ'), ('clustering', 'NN'), ('algorithms', 'NN'), ('become', 'VB'), ('even', 'RB'), ('limited', 'JJ'), ('typically', 'RB'), ('require', 'VBP'), ('data', 'NNS'), ('format', 'NNS'), ('loaded', 'VBD'), ('machine', 'NN'), ('find', 'NN'), ('useful', 'JJ'), ('things', 'NNS'), ('whole', 'JJ'), ('data', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['algorithms', 'big data age', 'traditional clustering algorithms', 'data format', 'machine find', 'useful things', 'whole data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Clustering', 'cluster'), ('algorithms', 'algorithm'), ('In', 'in'), ('big', 'big'), ('data', 'data'), ('age', 'age'), (',', ','), ('traditional', 'tradit'), ('clustering', 'cluster'), ('algorithms', 'algorithm'), ('become', 'becom'), ('even', 'even'), ('limited', 'limit'), ('typically', 'typic'), ('require', 'requir'), ('data', 'data'), ('format', 'format'), ('loaded', 'load'), ('machine', 'machin'), ('find', 'find'), ('useful', 'use'), ('things', 'thing'), ('whole', 'whole'), ('data', 'data'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Clustering', 'cluster'), ('algorithms', 'algorithm'), ('In', 'in'), ('big', 'big'), ('data', 'data'), ('age', 'age'), (',', ','), ('traditional', 'tradit'), ('clustering', 'cluster'), ('algorithms', 'algorithm'), ('become', 'becom'), ('even', 'even'), ('limited', 'limit'), ('typically', 'typic'), ('require', 'requir'), ('data', 'data'), ('format', 'format'), ('loaded', 'load'), ('machine', 'machin'), ('find', 'find'), ('useful', 'use'), ('things', 'thing'), ('whole', 'whole'), ('data', 'data'), ('.', '.')]

>> Lemmatization: 
 [('Clustering', 'Clustering'), ('algorithms', 'algorithm'), ('In', 'In'), ('big', 'big'), ('data', 'data'), ('age', 'age'), (',', ','), ('traditional', 'traditional'), ('clustering', 'clustering'), ('algorithms', 'algorithm'), ('become', 'become'), ('even', 'even'), ('limited', 'limited'), ('typically', 'typically'), ('require', 'require'), ('data', 'data'), ('format', 'format'), ('loaded', 'loaded'), ('machine', 'machine'), ('find', 'find'), ('useful', 'useful'), ('things', 'thing'), ('whole', 'whole'), ('data', 'data'), ('.', '.')]


------------------- Sentence 2 -------------------

Although the problem [64] of analyzing large-scale and high-dimen- sional dataset has attracted many researchers from various disciplines in the last cen- tury, and several solutions [2, 109] have been presented presented in recent years, the  characteristics of big data still brought up several new challenges for the data clustering  issues.

>> Tokens are: 
 ['Although', 'problem', '[', '64', ']', 'analyzing', 'large-scale', 'high-dimen-', 'sional', 'dataset', 'attracted', 'many', 'researchers', 'various', 'disciplines', 'last', 'cen-', 'tury', ',', 'several', 'solutions', '[', '2', ',', '109', ']', 'presented', 'presented', 'recent', 'years', ',', 'characteristics', 'big', 'data', 'still', 'brought', 'several', 'new', 'challenges', 'data', 'clustering', 'issues', '.']

>> Bigrams are: 
 [('Although', 'problem'), ('problem', '['), ('[', '64'), ('64', ']'), (']', 'analyzing'), ('analyzing', 'large-scale'), ('large-scale', 'high-dimen-'), ('high-dimen-', 'sional'), ('sional', 'dataset'), ('dataset', 'attracted'), ('attracted', 'many'), ('many', 'researchers'), ('researchers', 'various'), ('various', 'disciplines'), ('disciplines', 'last'), ('last', 'cen-'), ('cen-', 'tury'), ('tury', ','), (',', 'several'), ('several', 'solutions'), ('solutions', '['), ('[', '2'), ('2', ','), (',', '109'), ('109', ']'), (']', 'presented'), ('presented', 'presented'), ('presented', 'recent'), ('recent', 'years'), ('years', ','), (',', 'characteristics'), ('characteristics', 'big'), ('big', 'data'), ('data', 'still'), ('still', 'brought'), ('brought', 'several'), ('several', 'new'), ('new', 'challenges'), ('challenges', 'data'), ('data', 'clustering'), ('clustering', 'issues'), ('issues', '.')]

>> Trigrams are: 
 [('Although', 'problem', '['), ('problem', '[', '64'), ('[', '64', ']'), ('64', ']', 'analyzing'), (']', 'analyzing', 'large-scale'), ('analyzing', 'large-scale', 'high-dimen-'), ('large-scale', 'high-dimen-', 'sional'), ('high-dimen-', 'sional', 'dataset'), ('sional', 'dataset', 'attracted'), ('dataset', 'attracted', 'many'), ('attracted', 'many', 'researchers'), ('many', 'researchers', 'various'), ('researchers', 'various', 'disciplines'), ('various', 'disciplines', 'last'), ('disciplines', 'last', 'cen-'), ('last', 'cen-', 'tury'), ('cen-', 'tury', ','), ('tury', ',', 'several'), (',', 'several', 'solutions'), ('several', 'solutions', '['), ('solutions', '[', '2'), ('[', '2', ','), ('2', ',', '109'), (',', '109', ']'), ('109', ']', 'presented'), (']', 'presented', 'presented'), ('presented', 'presented', 'recent'), ('presented', 'recent', 'years'), ('recent', 'years', ','), ('years', ',', 'characteristics'), (',', 'characteristics', 'big'), ('characteristics', 'big', 'data'), ('big', 'data', 'still'), ('data', 'still', 'brought'), ('still', 'brought', 'several'), ('brought', 'several', 'new'), ('several', 'new', 'challenges'), ('new', 'challenges', 'data'), ('challenges', 'data', 'clustering'), ('data', 'clustering', 'issues'), ('clustering', 'issues', '.')]

>> POS Tags are: 
 [('Although', 'IN'), ('problem', 'NN'), ('[', '$'), ('64', 'CD'), (']', 'JJ'), ('analyzing', 'VBG'), ('large-scale', 'JJ'), ('high-dimen-', 'JJ'), ('sional', 'JJ'), ('dataset', 'NN'), ('attracted', 'VBD'), ('many', 'JJ'), ('researchers', 'NNS'), ('various', 'JJ'), ('disciplines', 'NNS'), ('last', 'JJ'), ('cen-', 'JJ'), ('tury', 'NN'), (',', ','), ('several', 'JJ'), ('solutions', 'NNS'), ('[', 'VBP'), ('2', 'CD'), (',', ','), ('109', 'CD'), (']', 'NN'), ('presented', 'VBN'), ('presented', 'VBN'), ('recent', 'JJ'), ('years', 'NNS'), (',', ','), ('characteristics', 'NNS'), ('big', 'JJ'), ('data', 'NNS'), ('still', 'RB'), ('brought', 'VBD'), ('several', 'JJ'), ('new', 'JJ'), ('challenges', 'NNS'), ('data', 'NNS'), ('clustering', 'VBG'), ('issues', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['problem', 'large-scale high-dimen- sional dataset', 'many researchers', 'various disciplines', 'last cen- tury', 'several solutions', ']', 'recent years', 'characteristics', 'big data', 'several new challenges data', 'issues']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Although', 'although'), ('problem', 'problem'), ('[', '['), ('64', '64'), (']', ']'), ('analyzing', 'analyz'), ('large-scale', 'large-scal'), ('high-dimen-', 'high-dimen-'), ('sional', 'sional'), ('dataset', 'dataset'), ('attracted', 'attract'), ('many', 'mani'), ('researchers', 'research'), ('various', 'variou'), ('disciplines', 'disciplin'), ('last', 'last'), ('cen-', 'cen-'), ('tury', 'turi'), (',', ','), ('several', 'sever'), ('solutions', 'solut'), ('[', '['), ('2', '2'), (',', ','), ('109', '109'), (']', ']'), ('presented', 'present'), ('presented', 'present'), ('recent', 'recent'), ('years', 'year'), (',', ','), ('characteristics', 'characterist'), ('big', 'big'), ('data', 'data'), ('still', 'still'), ('brought', 'brought'), ('several', 'sever'), ('new', 'new'), ('challenges', 'challeng'), ('data', 'data'), ('clustering', 'cluster'), ('issues', 'issu'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Although', 'although'), ('problem', 'problem'), ('[', '['), ('64', '64'), (']', ']'), ('analyzing', 'analyz'), ('large-scale', 'large-scal'), ('high-dimen-', 'high-dimen-'), ('sional', 'sional'), ('dataset', 'dataset'), ('attracted', 'attract'), ('many', 'mani'), ('researchers', 'research'), ('various', 'various'), ('disciplines', 'disciplin'), ('last', 'last'), ('cen-', 'cen-'), ('tury', 'turi'), (',', ','), ('several', 'sever'), ('solutions', 'solut'), ('[', '['), ('2', '2'), (',', ','), ('109', '109'), (']', ']'), ('presented', 'present'), ('presented', 'present'), ('recent', 'recent'), ('years', 'year'), (',', ','), ('characteristics', 'characterist'), ('big', 'big'), ('data', 'data'), ('still', 'still'), ('brought', 'brought'), ('several', 'sever'), ('new', 'new'), ('challenges', 'challeng'), ('data', 'data'), ('clustering', 'cluster'), ('issues', 'issu'), ('.', '.')]

>> Lemmatization: 
 [('Although', 'Although'), ('problem', 'problem'), ('[', '['), ('64', '64'), (']', ']'), ('analyzing', 'analyzing'), ('large-scale', 'large-scale'), ('high-dimen-', 'high-dimen-'), ('sional', 'sional'), ('dataset', 'dataset'), ('attracted', 'attracted'), ('many', 'many'), ('researchers', 'researcher'), ('various', 'various'), ('disciplines', 'discipline'), ('last', 'last'), ('cen-', 'cen-'), ('tury', 'tury'), (',', ','), ('several', 'several'), ('solutions', 'solution'), ('[', '['), ('2', '2'), (',', ','), ('109', '109'), (']', ']'), ('presented', 'presented'), ('presented', 'presented'), ('recent', 'recent'), ('years', 'year'), (',', ','), ('characteristics', 'characteristic'), ('big', 'big'), ('data', 'data'), ('still', 'still'), ('brought', 'brought'), ('several', 'several'), ('new', 'new'), ('challenges', 'challenge'), ('data', 'data'), ('clustering', 'clustering'), ('issues', 'issue'), ('.', '.')]


------------------- Sentence 3 -------------------

Among them, how to reduce the data complexity is one of the important issues  for big data clustering.

>> Tokens are: 
 ['Among', ',', 'reduce', 'data', 'complexity', 'one', 'important', 'issues', 'big', 'data', 'clustering', '.']

>> Bigrams are: 
 [('Among', ','), (',', 'reduce'), ('reduce', 'data'), ('data', 'complexity'), ('complexity', 'one'), ('one', 'important'), ('important', 'issues'), ('issues', 'big'), ('big', 'data'), ('data', 'clustering'), ('clustering', '.')]

>> Trigrams are: 
 [('Among', ',', 'reduce'), (',', 'reduce', 'data'), ('reduce', 'data', 'complexity'), ('data', 'complexity', 'one'), ('complexity', 'one', 'important'), ('one', 'important', 'issues'), ('important', 'issues', 'big'), ('issues', 'big', 'data'), ('big', 'data', 'clustering'), ('data', 'clustering', '.')]

>> POS Tags are: 
 [('Among', 'IN'), (',', ','), ('reduce', 'VB'), ('data', 'NNS'), ('complexity', 'NN'), ('one', 'CD'), ('important', 'JJ'), ('issues', 'NNS'), ('big', 'JJ'), ('data', 'NNS'), ('clustering', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['data complexity', 'important issues', 'big data clustering']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Among', 'among'), (',', ','), ('reduce', 'reduc'), ('data', 'data'), ('complexity', 'complex'), ('one', 'one'), ('important', 'import'), ('issues', 'issu'), ('big', 'big'), ('data', 'data'), ('clustering', 'cluster'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Among', 'among'), (',', ','), ('reduce', 'reduc'), ('data', 'data'), ('complexity', 'complex'), ('one', 'one'), ('important', 'import'), ('issues', 'issu'), ('big', 'big'), ('data', 'data'), ('clustering', 'cluster'), ('.', '.')]

>> Lemmatization: 
 [('Among', 'Among'), (',', ','), ('reduce', 'reduce'), ('data', 'data'), ('complexity', 'complexity'), ('one', 'one'), ('important', 'important'), ('issues', 'issue'), ('big', 'big'), ('data', 'data'), ('clustering', 'clustering'), ('.', '.')]


------------------- Sentence 4 -------------------

In [110], Shirkhorshidi et al.

>> Tokens are: 
 ['In', '[', '110', ']', ',', 'Shirkhorshidi', 'et', 'al', '.']

>> Bigrams are: 
 [('In', '['), ('[', '110'), ('110', ']'), (']', ','), (',', 'Shirkhorshidi'), ('Shirkhorshidi', 'et'), ('et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('In', '[', '110'), ('[', '110', ']'), ('110', ']', ','), (']', ',', 'Shirkhorshidi'), (',', 'Shirkhorshidi', 'et'), ('Shirkhorshidi', 'et', 'al'), ('et', 'al', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('[', '$'), ('110', 'CD'), (']', 'NNP'), (',', ','), ('Shirkhorshidi', 'NNP'), ('et', 'CC'), ('al', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 [']', 'Shirkhorshidi', 'al']

>> Named Entities are: 
 [('GPE', 'Shirkhorshidi')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('[', '['), ('110', '110'), (']', ']'), (',', ','), ('Shirkhorshidi', 'shirkhorshidi'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('[', '['), ('110', '110'), (']', ']'), (',', ','), ('Shirkhorshidi', 'shirkhorshidi'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('[', '['), ('110', '110'), (']', ']'), (',', ','), ('Shirkhorshidi', 'Shirkhorshidi'), ('et', 'et'), ('al', 'al'), ('.', '.')]


------------------- Sentence 5 -------------------

divided the big data clustering into  two categories: single-machine clustering (i.e.-, sampling and dimension reduction solu- tions), and multiple-machine clustering (parallel and MapReduce solutions).

>> Tokens are: 
 ['divided', 'big', 'data', 'clustering', 'two', 'categories', ':', 'single-machine', 'clustering', '(', 'i.e.-', ',', 'sampling', 'dimension', 'reduction', 'solu-', 'tions', ')', ',', 'multiple-machine', 'clustering', '(', 'parallel', 'MapReduce', 'solutions', ')', '.']

>> Bigrams are: 
 [('divided', 'big'), ('big', 'data'), ('data', 'clustering'), ('clustering', 'two'), ('two', 'categories'), ('categories', ':'), (':', 'single-machine'), ('single-machine', 'clustering'), ('clustering', '('), ('(', 'i.e.-'), ('i.e.-', ','), (',', 'sampling'), ('sampling', 'dimension'), ('dimension', 'reduction'), ('reduction', 'solu-'), ('solu-', 'tions'), ('tions', ')'), (')', ','), (',', 'multiple-machine'), ('multiple-machine', 'clustering'), ('clustering', '('), ('(', 'parallel'), ('parallel', 'MapReduce'), ('MapReduce', 'solutions'), ('solutions', ')'), (')', '.')]

>> Trigrams are: 
 [('divided', 'big', 'data'), ('big', 'data', 'clustering'), ('data', 'clustering', 'two'), ('clustering', 'two', 'categories'), ('two', 'categories', ':'), ('categories', ':', 'single-machine'), (':', 'single-machine', 'clustering'), ('single-machine', 'clustering', '('), ('clustering', '(', 'i.e.-'), ('(', 'i.e.-', ','), ('i.e.-', ',', 'sampling'), (',', 'sampling', 'dimension'), ('sampling', 'dimension', 'reduction'), ('dimension', 'reduction', 'solu-'), ('reduction', 'solu-', 'tions'), ('solu-', 'tions', ')'), ('tions', ')', ','), (')', ',', 'multiple-machine'), (',', 'multiple-machine', 'clustering'), ('multiple-machine', 'clustering', '('), ('clustering', '(', 'parallel'), ('(', 'parallel', 'MapReduce'), ('parallel', 'MapReduce', 'solutions'), ('MapReduce', 'solutions', ')'), ('solutions', ')', '.')]

>> POS Tags are: 
 [('divided', 'VBN'), ('big', 'JJ'), ('data', 'NNS'), ('clustering', 'VBG'), ('two', 'CD'), ('categories', 'NNS'), (':', ':'), ('single-machine', 'JJ'), ('clustering', 'NN'), ('(', '('), ('i.e.-', 'JJ'), (',', ','), ('sampling', 'VBG'), ('dimension', 'NN'), ('reduction', 'NN'), ('solu-', 'JJ'), ('tions', 'NNS'), (')', ')'), (',', ','), ('multiple-machine', 'JJ'), ('clustering', 'NN'), ('(', '('), ('parallel', 'JJ'), ('MapReduce', 'NNP'), ('solutions', 'NNS'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['big data', 'categories', 'single-machine clustering', 'dimension reduction', 'solu- tions', 'multiple-machine clustering', 'parallel MapReduce solutions']

>> Named Entities are: 
 [('ORGANIZATION', 'MapReduce')] 

>> Stemming using Porter Stemmer: 
 [('divided', 'divid'), ('big', 'big'), ('data', 'data'), ('clustering', 'cluster'), ('two', 'two'), ('categories', 'categori'), (':', ':'), ('single-machine', 'single-machin'), ('clustering', 'cluster'), ('(', '('), ('i.e.-', 'i.e.-'), (',', ','), ('sampling', 'sampl'), ('dimension', 'dimens'), ('reduction', 'reduct'), ('solu-', 'solu-'), ('tions', 'tion'), (')', ')'), (',', ','), ('multiple-machine', 'multiple-machin'), ('clustering', 'cluster'), ('(', '('), ('parallel', 'parallel'), ('MapReduce', 'mapreduc'), ('solutions', 'solut'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('divided', 'divid'), ('big', 'big'), ('data', 'data'), ('clustering', 'cluster'), ('two', 'two'), ('categories', 'categori'), (':', ':'), ('single-machine', 'single-machin'), ('clustering', 'cluster'), ('(', '('), ('i.e.-', 'i.e.-'), (',', ','), ('sampling', 'sampl'), ('dimension', 'dimens'), ('reduction', 'reduct'), ('solu-', 'solu-'), ('tions', 'tion'), (')', ')'), (',', ','), ('multiple-machine', 'multiple-machin'), ('clustering', 'cluster'), ('(', '('), ('parallel', 'parallel'), ('MapReduce', 'mapreduc'), ('solutions', 'solut'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('divided', 'divided'), ('big', 'big'), ('data', 'data'), ('clustering', 'clustering'), ('two', 'two'), ('categories', 'category'), (':', ':'), ('single-machine', 'single-machine'), ('clustering', 'clustering'), ('(', '('), ('i.e.-', 'i.e.-'), (',', ','), ('sampling', 'sampling'), ('dimension', 'dimension'), ('reduction', 'reduction'), ('solu-', 'solu-'), ('tions', 'tions'), (')', ')'), (',', ','), ('multiple-machine', 'multiple-machine'), ('clustering', 'clustering'), ('(', '('), ('parallel', 'parallel'), ('MapReduce', 'MapReduce'), ('solutions', 'solution'), (')', ')'), ('.', '.')]


------------------- Sentence 6 -------------------

This means  that traditional reduction solutions can also be used in the big data age because the  complexity and memory space needed for the process of data analysis will be decreased  by using sampling and dimension reduction methods.

>> Tokens are: 
 ['This', 'means', 'traditional', 'reduction', 'solutions', 'also', 'used', 'big', 'data', 'age', 'complexity', 'memory', 'space', 'needed', 'process', 'data', 'analysis', 'decreased', 'using', 'sampling', 'dimension', 'reduction', 'methods', '.']

>> Bigrams are: 
 [('This', 'means'), ('means', 'traditional'), ('traditional', 'reduction'), ('reduction', 'solutions'), ('solutions', 'also'), ('also', 'used'), ('used', 'big'), ('big', 'data'), ('data', 'age'), ('age', 'complexity'), ('complexity', 'memory'), ('memory', 'space'), ('space', 'needed'), ('needed', 'process'), ('process', 'data'), ('data', 'analysis'), ('analysis', 'decreased'), ('decreased', 'using'), ('using', 'sampling'), ('sampling', 'dimension'), ('dimension', 'reduction'), ('reduction', 'methods'), ('methods', '.')]

>> Trigrams are: 
 [('This', 'means', 'traditional'), ('means', 'traditional', 'reduction'), ('traditional', 'reduction', 'solutions'), ('reduction', 'solutions', 'also'), ('solutions', 'also', 'used'), ('also', 'used', 'big'), ('used', 'big', 'data'), ('big', 'data', 'age'), ('data', 'age', 'complexity'), ('age', 'complexity', 'memory'), ('complexity', 'memory', 'space'), ('memory', 'space', 'needed'), ('space', 'needed', 'process'), ('needed', 'process', 'data'), ('process', 'data', 'analysis'), ('data', 'analysis', 'decreased'), ('analysis', 'decreased', 'using'), ('decreased', 'using', 'sampling'), ('using', 'sampling', 'dimension'), ('sampling', 'dimension', 'reduction'), ('dimension', 'reduction', 'methods'), ('reduction', 'methods', '.')]

>> POS Tags are: 
 [('This', 'DT'), ('means', 'VBZ'), ('traditional', 'JJ'), ('reduction', 'NN'), ('solutions', 'NNS'), ('also', 'RB'), ('used', 'VBD'), ('big', 'JJ'), ('data', 'NNS'), ('age', 'NN'), ('complexity', 'NN'), ('memory', 'NN'), ('space', 'NN'), ('needed', 'VBD'), ('process', 'NN'), ('data', 'NNS'), ('analysis', 'NN'), ('decreased', 'VBD'), ('using', 'VBG'), ('sampling', 'VBG'), ('dimension', 'NN'), ('reduction', 'NN'), ('methods', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['traditional reduction solutions', 'big data age complexity memory space', 'process data analysis', 'dimension reduction methods']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('This', 'thi'), ('means', 'mean'), ('traditional', 'tradit'), ('reduction', 'reduct'), ('solutions', 'solut'), ('also', 'also'), ('used', 'use'), ('big', 'big'), ('data', 'data'), ('age', 'age'), ('complexity', 'complex'), ('memory', 'memori'), ('space', 'space'), ('needed', 'need'), ('process', 'process'), ('data', 'data'), ('analysis', 'analysi'), ('decreased', 'decreas'), ('using', 'use'), ('sampling', 'sampl'), ('dimension', 'dimens'), ('reduction', 'reduct'), ('methods', 'method'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('This', 'this'), ('means', 'mean'), ('traditional', 'tradit'), ('reduction', 'reduct'), ('solutions', 'solut'), ('also', 'also'), ('used', 'use'), ('big', 'big'), ('data', 'data'), ('age', 'age'), ('complexity', 'complex'), ('memory', 'memori'), ('space', 'space'), ('needed', 'need'), ('process', 'process'), ('data', 'data'), ('analysis', 'analysi'), ('decreased', 'decreas'), ('using', 'use'), ('sampling', 'sampl'), ('dimension', 'dimens'), ('reduction', 'reduct'), ('methods', 'method'), ('.', '.')]

>> Lemmatization: 
 [('This', 'This'), ('means', 'mean'), ('traditional', 'traditional'), ('reduction', 'reduction'), ('solutions', 'solution'), ('also', 'also'), ('used', 'used'), ('big', 'big'), ('data', 'data'), ('age', 'age'), ('complexity', 'complexity'), ('memory', 'memory'), ('space', 'space'), ('needed', 'needed'), ('process', 'process'), ('data', 'data'), ('analysis', 'analysis'), ('decreased', 'decreased'), ('using', 'using'), ('sampling', 'sampling'), ('dimension', 'dimension'), ('reduction', 'reduction'), ('methods', 'method'), ('.', '.')]


------------------- Sentence 7 -------------------

More precisely, sampling can be  regarded as reducing the “amount of data” entered into a data analyzing process while  dimension reduction can be regarded as “downsizing the whole dataset” because irrel- evant dimensions will be discarded before the data analyzing process is carried out.

>> Tokens are: 
 ['More', 'precisely', ',', 'sampling', 'regarded', 'reducing', '“', 'amount', 'data', '”', 'entered', 'data', 'analyzing', 'process', 'dimension', 'reduction', 'regarded', '“', 'downsizing', 'whole', 'dataset', '”', 'irrel-', 'evant', 'dimensions', 'discarded', 'data', 'analyzing', 'process', 'carried', '.']

>> Bigrams are: 
 [('More', 'precisely'), ('precisely', ','), (',', 'sampling'), ('sampling', 'regarded'), ('regarded', 'reducing'), ('reducing', '“'), ('“', 'amount'), ('amount', 'data'), ('data', '”'), ('”', 'entered'), ('entered', 'data'), ('data', 'analyzing'), ('analyzing', 'process'), ('process', 'dimension'), ('dimension', 'reduction'), ('reduction', 'regarded'), ('regarded', '“'), ('“', 'downsizing'), ('downsizing', 'whole'), ('whole', 'dataset'), ('dataset', '”'), ('”', 'irrel-'), ('irrel-', 'evant'), ('evant', 'dimensions'), ('dimensions', 'discarded'), ('discarded', 'data'), ('data', 'analyzing'), ('analyzing', 'process'), ('process', 'carried'), ('carried', '.')]

>> Trigrams are: 
 [('More', 'precisely', ','), ('precisely', ',', 'sampling'), (',', 'sampling', 'regarded'), ('sampling', 'regarded', 'reducing'), ('regarded', 'reducing', '“'), ('reducing', '“', 'amount'), ('“', 'amount', 'data'), ('amount', 'data', '”'), ('data', '”', 'entered'), ('”', 'entered', 'data'), ('entered', 'data', 'analyzing'), ('data', 'analyzing', 'process'), ('analyzing', 'process', 'dimension'), ('process', 'dimension', 'reduction'), ('dimension', 'reduction', 'regarded'), ('reduction', 'regarded', '“'), ('regarded', '“', 'downsizing'), ('“', 'downsizing', 'whole'), ('downsizing', 'whole', 'dataset'), ('whole', 'dataset', '”'), ('dataset', '”', 'irrel-'), ('”', 'irrel-', 'evant'), ('irrel-', 'evant', 'dimensions'), ('evant', 'dimensions', 'discarded'), ('dimensions', 'discarded', 'data'), ('discarded', 'data', 'analyzing'), ('data', 'analyzing', 'process'), ('analyzing', 'process', 'carried'), ('process', 'carried', '.')]

>> POS Tags are: 
 [('More', 'RBR'), ('precisely', 'RB'), (',', ','), ('sampling', 'VBG'), ('regarded', 'VBD'), ('reducing', 'VBG'), ('“', 'JJ'), ('amount', 'NN'), ('data', 'NNS'), ('”', 'RB'), ('entered', 'VBD'), ('data', 'NNS'), ('analyzing', 'VBG'), ('process', 'NN'), ('dimension', 'NN'), ('reduction', 'NN'), ('regarded', 'VBD'), ('“', 'JJ'), ('downsizing', 'VBG'), ('whole', 'JJ'), ('dataset', 'NN'), ('”', 'NNP'), ('irrel-', 'JJ'), ('evant', 'JJ'), ('dimensions', 'NNS'), ('discarded', 'VBD'), ('data', 'NNS'), ('analyzing', 'VBG'), ('process', 'NN'), ('carried', 'VBD'), ('.', '.')]

>> Noun Phrases are: 
 ['“ amount data', 'data', 'process dimension reduction', 'whole dataset ”', 'irrel- evant dimensions', 'data', 'process']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('More', 'more'), ('precisely', 'precis'), (',', ','), ('sampling', 'sampl'), ('regarded', 'regard'), ('reducing', 'reduc'), ('“', '“'), ('amount', 'amount'), ('data', 'data'), ('”', '”'), ('entered', 'enter'), ('data', 'data'), ('analyzing', 'analyz'), ('process', 'process'), ('dimension', 'dimens'), ('reduction', 'reduct'), ('regarded', 'regard'), ('“', '“'), ('downsizing', 'downsiz'), ('whole', 'whole'), ('dataset', 'dataset'), ('”', '”'), ('irrel-', 'irrel-'), ('evant', 'evant'), ('dimensions', 'dimens'), ('discarded', 'discard'), ('data', 'data'), ('analyzing', 'analyz'), ('process', 'process'), ('carried', 'carri'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('More', 'more'), ('precisely', 'precis'), (',', ','), ('sampling', 'sampl'), ('regarded', 'regard'), ('reducing', 'reduc'), ('“', '“'), ('amount', 'amount'), ('data', 'data'), ('”', '”'), ('entered', 'enter'), ('data', 'data'), ('analyzing', 'analyz'), ('process', 'process'), ('dimension', 'dimens'), ('reduction', 'reduct'), ('regarded', 'regard'), ('“', '“'), ('downsizing', 'downsiz'), ('whole', 'whole'), ('dataset', 'dataset'), ('”', '”'), ('irrel-', 'irrel-'), ('evant', 'evant'), ('dimensions', 'dimens'), ('discarded', 'discard'), ('data', 'data'), ('analyzing', 'analyz'), ('process', 'process'), ('carried', 'carri'), ('.', '.')]

>> Lemmatization: 
 [('More', 'More'), ('precisely', 'precisely'), (',', ','), ('sampling', 'sampling'), ('regarded', 'regarded'), ('reducing', 'reducing'), ('“', '“'), ('amount', 'amount'), ('data', 'data'), ('”', '”'), ('entered', 'entered'), ('data', 'data'), ('analyzing', 'analyzing'), ('process', 'process'), ('dimension', 'dimension'), ('reduction', 'reduction'), ('regarded', 'regarded'), ('“', '“'), ('downsizing', 'downsizing'), ('whole', 'whole'), ('dataset', 'dataset'), ('”', '”'), ('irrel-', 'irrel-'), ('evant', 'evant'), ('dimensions', 'dimension'), ('discarded', 'discarded'), ('data', 'data'), ('analyzing', 'analyzing'), ('process', 'process'), ('carried', 'carried'), ('.', '.')]



========================================== PARAGRAPH 260 ===========================================

CloudVista [111] is a representative solution for clustering big data which used cloud  computing to perform the clustering process in parallel. BIRCH [44] and sampling  method were used in CloudVista to show that it is able to handle large-scale data, e.g.-,  25 million census records. Using GPU to enhance the performance of a clustering algo- rithm is another promising solution for big data mining. The multiple species flocking  (MSF) [112] was applied to the CUDA platform from NVIDIA to reduce the computa- tion time of clustering algorithm in [113]. The simulation results show that the speedup  factor can be increased from 30 up to 60 by using GPU for data clustering. Since most  traditional clustering algorithms (e.g, k-means) require a computation that is central- ized, how to make them capable of handling big data clustering problems is the major 

------------------- Sentence 1 -------------------

CloudVista [111] is a representative solution for clustering big data which used cloud  computing to perform the clustering process in parallel.

>> Tokens are: 
 ['CloudVista', '[', '111', ']', 'representative', 'solution', 'clustering', 'big', 'data', 'used', 'cloud', 'computing', 'perform', 'clustering', 'process', 'parallel', '.']

>> Bigrams are: 
 [('CloudVista', '['), ('[', '111'), ('111', ']'), (']', 'representative'), ('representative', 'solution'), ('solution', 'clustering'), ('clustering', 'big'), ('big', 'data'), ('data', 'used'), ('used', 'cloud'), ('cloud', 'computing'), ('computing', 'perform'), ('perform', 'clustering'), ('clustering', 'process'), ('process', 'parallel'), ('parallel', '.')]

>> Trigrams are: 
 [('CloudVista', '[', '111'), ('[', '111', ']'), ('111', ']', 'representative'), (']', 'representative', 'solution'), ('representative', 'solution', 'clustering'), ('solution', 'clustering', 'big'), ('clustering', 'big', 'data'), ('big', 'data', 'used'), ('data', 'used', 'cloud'), ('used', 'cloud', 'computing'), ('cloud', 'computing', 'perform'), ('computing', 'perform', 'clustering'), ('perform', 'clustering', 'process'), ('clustering', 'process', 'parallel'), ('process', 'parallel', '.')]

>> POS Tags are: 
 [('CloudVista', 'NNP'), ('[', 'VBD'), ('111', 'CD'), (']', 'NNP'), ('representative', 'JJ'), ('solution', 'NN'), ('clustering', 'VBG'), ('big', 'JJ'), ('data', 'NNS'), ('used', 'VBD'), ('cloud', 'JJ'), ('computing', 'VBG'), ('perform', 'NN'), ('clustering', 'VBG'), ('process', 'NN'), ('parallel', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['CloudVista', ']', 'representative solution', 'big data', 'perform', 'process parallel']

>> Named Entities are: 
 [('ORGANIZATION', 'CloudVista')] 

>> Stemming using Porter Stemmer: 
 [('CloudVista', 'cloudvista'), ('[', '['), ('111', '111'), (']', ']'), ('representative', 'repres'), ('solution', 'solut'), ('clustering', 'cluster'), ('big', 'big'), ('data', 'data'), ('used', 'use'), ('cloud', 'cloud'), ('computing', 'comput'), ('perform', 'perform'), ('clustering', 'cluster'), ('process', 'process'), ('parallel', 'parallel'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('CloudVista', 'cloudvista'), ('[', '['), ('111', '111'), (']', ']'), ('representative', 'repres'), ('solution', 'solut'), ('clustering', 'cluster'), ('big', 'big'), ('data', 'data'), ('used', 'use'), ('cloud', 'cloud'), ('computing', 'comput'), ('perform', 'perform'), ('clustering', 'cluster'), ('process', 'process'), ('parallel', 'parallel'), ('.', '.')]

>> Lemmatization: 
 [('CloudVista', 'CloudVista'), ('[', '['), ('111', '111'), (']', ']'), ('representative', 'representative'), ('solution', 'solution'), ('clustering', 'clustering'), ('big', 'big'), ('data', 'data'), ('used', 'used'), ('cloud', 'cloud'), ('computing', 'computing'), ('perform', 'perform'), ('clustering', 'clustering'), ('process', 'process'), ('parallel', 'parallel'), ('.', '.')]


------------------- Sentence 2 -------------------

BIRCH [44] and sampling  method were used in CloudVista to show that it is able to handle large-scale data, e.g.-,  25 million census records.

>> Tokens are: 
 ['BIRCH', '[', '44', ']', 'sampling', 'method', 'used', 'CloudVista', 'show', 'able', 'handle', 'large-scale', 'data', ',', 'e.g.-', ',', '25', 'million', 'census', 'records', '.']

>> Bigrams are: 
 [('BIRCH', '['), ('[', '44'), ('44', ']'), (']', 'sampling'), ('sampling', 'method'), ('method', 'used'), ('used', 'CloudVista'), ('CloudVista', 'show'), ('show', 'able'), ('able', 'handle'), ('handle', 'large-scale'), ('large-scale', 'data'), ('data', ','), (',', 'e.g.-'), ('e.g.-', ','), (',', '25'), ('25', 'million'), ('million', 'census'), ('census', 'records'), ('records', '.')]

>> Trigrams are: 
 [('BIRCH', '[', '44'), ('[', '44', ']'), ('44', ']', 'sampling'), (']', 'sampling', 'method'), ('sampling', 'method', 'used'), ('method', 'used', 'CloudVista'), ('used', 'CloudVista', 'show'), ('CloudVista', 'show', 'able'), ('show', 'able', 'handle'), ('able', 'handle', 'large-scale'), ('handle', 'large-scale', 'data'), ('large-scale', 'data', ','), ('data', ',', 'e.g.-'), (',', 'e.g.-', ','), ('e.g.-', ',', '25'), (',', '25', 'million'), ('25', 'million', 'census'), ('million', 'census', 'records'), ('census', 'records', '.')]

>> POS Tags are: 
 [('BIRCH', 'NNP'), ('[', 'VBZ'), ('44', 'CD'), (']', 'NN'), ('sampling', 'VBG'), ('method', 'NN'), ('used', 'VBN'), ('CloudVista', 'NNP'), ('show', 'VBP'), ('able', 'JJ'), ('handle', 'JJ'), ('large-scale', 'JJ'), ('data', 'NNS'), (',', ','), ('e.g.-', 'JJ'), (',', ','), ('25', 'CD'), ('million', 'CD'), ('census', 'NN'), ('records', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['BIRCH', ']', 'method', 'CloudVista', 'able handle large-scale data', 'census records']

>> Named Entities are: 
 [('ORGANIZATION', 'CloudVista')] 

>> Stemming using Porter Stemmer: 
 [('BIRCH', 'birch'), ('[', '['), ('44', '44'), (']', ']'), ('sampling', 'sampl'), ('method', 'method'), ('used', 'use'), ('CloudVista', 'cloudvista'), ('show', 'show'), ('able', 'abl'), ('handle', 'handl'), ('large-scale', 'large-scal'), ('data', 'data'), (',', ','), ('e.g.-', 'e.g.-'), (',', ','), ('25', '25'), ('million', 'million'), ('census', 'censu'), ('records', 'record'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('BIRCH', 'birch'), ('[', '['), ('44', '44'), (']', ']'), ('sampling', 'sampl'), ('method', 'method'), ('used', 'use'), ('CloudVista', 'cloudvista'), ('show', 'show'), ('able', 'abl'), ('handle', 'handl'), ('large-scale', 'large-scal'), ('data', 'data'), (',', ','), ('e.g.-', 'e.g.-'), (',', ','), ('25', '25'), ('million', 'million'), ('census', 'census'), ('records', 'record'), ('.', '.')]

>> Lemmatization: 
 [('BIRCH', 'BIRCH'), ('[', '['), ('44', '44'), (']', ']'), ('sampling', 'sampling'), ('method', 'method'), ('used', 'used'), ('CloudVista', 'CloudVista'), ('show', 'show'), ('able', 'able'), ('handle', 'handle'), ('large-scale', 'large-scale'), ('data', 'data'), (',', ','), ('e.g.-', 'e.g.-'), (',', ','), ('25', '25'), ('million', 'million'), ('census', 'census'), ('records', 'record'), ('.', '.')]


------------------- Sentence 3 -------------------

Using GPU to enhance the performance of a clustering algo- rithm is another promising solution for big data mining.

>> Tokens are: 
 ['Using', 'GPU', 'enhance', 'performance', 'clustering', 'algo-', 'rithm', 'another', 'promising', 'solution', 'big', 'data', 'mining', '.']

>> Bigrams are: 
 [('Using', 'GPU'), ('GPU', 'enhance'), ('enhance', 'performance'), ('performance', 'clustering'), ('clustering', 'algo-'), ('algo-', 'rithm'), ('rithm', 'another'), ('another', 'promising'), ('promising', 'solution'), ('solution', 'big'), ('big', 'data'), ('data', 'mining'), ('mining', '.')]

>> Trigrams are: 
 [('Using', 'GPU', 'enhance'), ('GPU', 'enhance', 'performance'), ('enhance', 'performance', 'clustering'), ('performance', 'clustering', 'algo-'), ('clustering', 'algo-', 'rithm'), ('algo-', 'rithm', 'another'), ('rithm', 'another', 'promising'), ('another', 'promising', 'solution'), ('promising', 'solution', 'big'), ('solution', 'big', 'data'), ('big', 'data', 'mining'), ('data', 'mining', '.')]

>> POS Tags are: 
 [('Using', 'VBG'), ('GPU', 'NNP'), ('enhance', 'NN'), ('performance', 'NN'), ('clustering', 'VBG'), ('algo-', 'JJ'), ('rithm', 'NN'), ('another', 'DT'), ('promising', 'JJ'), ('solution', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('mining', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['GPU enhance performance', 'algo- rithm', 'another promising solution', 'big data mining']

>> Named Entities are: 
 [('ORGANIZATION', 'GPU')] 

>> Stemming using Porter Stemmer: 
 [('Using', 'use'), ('GPU', 'gpu'), ('enhance', 'enhanc'), ('performance', 'perform'), ('clustering', 'cluster'), ('algo-', 'algo-'), ('rithm', 'rithm'), ('another', 'anoth'), ('promising', 'promis'), ('solution', 'solut'), ('big', 'big'), ('data', 'data'), ('mining', 'mine'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Using', 'use'), ('GPU', 'gpu'), ('enhance', 'enhanc'), ('performance', 'perform'), ('clustering', 'cluster'), ('algo-', 'algo-'), ('rithm', 'rithm'), ('another', 'anoth'), ('promising', 'promis'), ('solution', 'solut'), ('big', 'big'), ('data', 'data'), ('mining', 'mine'), ('.', '.')]

>> Lemmatization: 
 [('Using', 'Using'), ('GPU', 'GPU'), ('enhance', 'enhance'), ('performance', 'performance'), ('clustering', 'clustering'), ('algo-', 'algo-'), ('rithm', 'rithm'), ('another', 'another'), ('promising', 'promising'), ('solution', 'solution'), ('big', 'big'), ('data', 'data'), ('mining', 'mining'), ('.', '.')]


------------------- Sentence 4 -------------------

The multiple species flocking  (MSF) [112] was applied to the CUDA platform from NVIDIA to reduce the computa- tion time of clustering algorithm in [113].

>> Tokens are: 
 ['The', 'multiple', 'species', 'flocking', '(', 'MSF', ')', '[', '112', ']', 'applied', 'CUDA', 'platform', 'NVIDIA', 'reduce', 'computa-', 'tion', 'time', 'clustering', 'algorithm', '[', '113', ']', '.']

>> Bigrams are: 
 [('The', 'multiple'), ('multiple', 'species'), ('species', 'flocking'), ('flocking', '('), ('(', 'MSF'), ('MSF', ')'), (')', '['), ('[', '112'), ('112', ']'), (']', 'applied'), ('applied', 'CUDA'), ('CUDA', 'platform'), ('platform', 'NVIDIA'), ('NVIDIA', 'reduce'), ('reduce', 'computa-'), ('computa-', 'tion'), ('tion', 'time'), ('time', 'clustering'), ('clustering', 'algorithm'), ('algorithm', '['), ('[', '113'), ('113', ']'), (']', '.')]

>> Trigrams are: 
 [('The', 'multiple', 'species'), ('multiple', 'species', 'flocking'), ('species', 'flocking', '('), ('flocking', '(', 'MSF'), ('(', 'MSF', ')'), ('MSF', ')', '['), (')', '[', '112'), ('[', '112', ']'), ('112', ']', 'applied'), (']', 'applied', 'CUDA'), ('applied', 'CUDA', 'platform'), ('CUDA', 'platform', 'NVIDIA'), ('platform', 'NVIDIA', 'reduce'), ('NVIDIA', 'reduce', 'computa-'), ('reduce', 'computa-', 'tion'), ('computa-', 'tion', 'time'), ('tion', 'time', 'clustering'), ('time', 'clustering', 'algorithm'), ('clustering', 'algorithm', '['), ('algorithm', '[', '113'), ('[', '113', ']'), ('113', ']', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('multiple', 'JJ'), ('species', 'NNS'), ('flocking', 'VBG'), ('(', '('), ('MSF', 'NNP'), (')', ')'), ('[', 'VBD'), ('112', 'CD'), (']', 'NNP'), ('applied', 'VBD'), ('CUDA', 'NNP'), ('platform', 'NN'), ('NVIDIA', 'NNP'), ('reduce', 'VB'), ('computa-', 'JJ'), ('tion', 'NN'), ('time', 'NN'), ('clustering', 'VBG'), ('algorithm', 'JJ'), ('[', '$'), ('113', 'CD'), (']', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['The multiple species', 'MSF', ']', 'CUDA platform NVIDIA', 'computa- tion time', ']']

>> Named Entities are: 
 [('ORGANIZATION', 'MSF'), ('ORGANIZATION', 'CUDA'), ('ORGANIZATION', 'NVIDIA')] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('multiple', 'multipl'), ('species', 'speci'), ('flocking', 'flock'), ('(', '('), ('MSF', 'msf'), (')', ')'), ('[', '['), ('112', '112'), (']', ']'), ('applied', 'appli'), ('CUDA', 'cuda'), ('platform', 'platform'), ('NVIDIA', 'nvidia'), ('reduce', 'reduc'), ('computa-', 'computa-'), ('tion', 'tion'), ('time', 'time'), ('clustering', 'cluster'), ('algorithm', 'algorithm'), ('[', '['), ('113', '113'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('multiple', 'multipl'), ('species', 'speci'), ('flocking', 'flock'), ('(', '('), ('MSF', 'msf'), (')', ')'), ('[', '['), ('112', '112'), (']', ']'), ('applied', 'appli'), ('CUDA', 'cuda'), ('platform', 'platform'), ('NVIDIA', 'nvidia'), ('reduce', 'reduc'), ('computa-', 'computa-'), ('tion', 'tion'), ('time', 'time'), ('clustering', 'cluster'), ('algorithm', 'algorithm'), ('[', '['), ('113', '113'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('multiple', 'multiple'), ('species', 'specie'), ('flocking', 'flocking'), ('(', '('), ('MSF', 'MSF'), (')', ')'), ('[', '['), ('112', '112'), (']', ']'), ('applied', 'applied'), ('CUDA', 'CUDA'), ('platform', 'platform'), ('NVIDIA', 'NVIDIA'), ('reduce', 'reduce'), ('computa-', 'computa-'), ('tion', 'tion'), ('time', 'time'), ('clustering', 'clustering'), ('algorithm', 'algorithm'), ('[', '['), ('113', '113'), (']', ']'), ('.', '.')]


------------------- Sentence 5 -------------------

The simulation results show that the speedup  factor can be increased from 30 up to 60 by using GPU for data clustering.

>> Tokens are: 
 ['The', 'simulation', 'results', 'show', 'speedup', 'factor', 'increased', '30', '60', 'using', 'GPU', 'data', 'clustering', '.']

>> Bigrams are: 
 [('The', 'simulation'), ('simulation', 'results'), ('results', 'show'), ('show', 'speedup'), ('speedup', 'factor'), ('factor', 'increased'), ('increased', '30'), ('30', '60'), ('60', 'using'), ('using', 'GPU'), ('GPU', 'data'), ('data', 'clustering'), ('clustering', '.')]

>> Trigrams are: 
 [('The', 'simulation', 'results'), ('simulation', 'results', 'show'), ('results', 'show', 'speedup'), ('show', 'speedup', 'factor'), ('speedup', 'factor', 'increased'), ('factor', 'increased', '30'), ('increased', '30', '60'), ('30', '60', 'using'), ('60', 'using', 'GPU'), ('using', 'GPU', 'data'), ('GPU', 'data', 'clustering'), ('data', 'clustering', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('simulation', 'NN'), ('results', 'NNS'), ('show', 'VBP'), ('speedup', 'JJ'), ('factor', 'NN'), ('increased', 'VBD'), ('30', 'CD'), ('60', 'CD'), ('using', 'VBG'), ('GPU', 'NNP'), ('data', 'NNS'), ('clustering', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['The simulation results', 'speedup factor', 'GPU data clustering']

>> Named Entities are: 
 [('ORGANIZATION', 'GPU')] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('simulation', 'simul'), ('results', 'result'), ('show', 'show'), ('speedup', 'speedup'), ('factor', 'factor'), ('increased', 'increas'), ('30', '30'), ('60', '60'), ('using', 'use'), ('GPU', 'gpu'), ('data', 'data'), ('clustering', 'cluster'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('simulation', 'simul'), ('results', 'result'), ('show', 'show'), ('speedup', 'speedup'), ('factor', 'factor'), ('increased', 'increas'), ('30', '30'), ('60', '60'), ('using', 'use'), ('GPU', 'gpu'), ('data', 'data'), ('clustering', 'cluster'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('simulation', 'simulation'), ('results', 'result'), ('show', 'show'), ('speedup', 'speedup'), ('factor', 'factor'), ('increased', 'increased'), ('30', '30'), ('60', '60'), ('using', 'using'), ('GPU', 'GPU'), ('data', 'data'), ('clustering', 'clustering'), ('.', '.')]


------------------- Sentence 6 -------------------

Since most  traditional clustering algorithms (e.g, k-means) require a computation that is central- ized, how to make them capable of handling big data clustering problems is the major

>> Tokens are: 
 ['Since', 'traditional', 'clustering', 'algorithms', '(', 'e.g', ',', 'k-means', ')', 'require', 'computation', 'central-', 'ized', ',', 'make', 'capable', 'handling', 'big', 'data', 'clustering', 'problems', 'major']

>> Bigrams are: 
 [('Since', 'traditional'), ('traditional', 'clustering'), ('clustering', 'algorithms'), ('algorithms', '('), ('(', 'e.g'), ('e.g', ','), (',', 'k-means'), ('k-means', ')'), (')', 'require'), ('require', 'computation'), ('computation', 'central-'), ('central-', 'ized'), ('ized', ','), (',', 'make'), ('make', 'capable'), ('capable', 'handling'), ('handling', 'big'), ('big', 'data'), ('data', 'clustering'), ('clustering', 'problems'), ('problems', 'major')]

>> Trigrams are: 
 [('Since', 'traditional', 'clustering'), ('traditional', 'clustering', 'algorithms'), ('clustering', 'algorithms', '('), ('algorithms', '(', 'e.g'), ('(', 'e.g', ','), ('e.g', ',', 'k-means'), (',', 'k-means', ')'), ('k-means', ')', 'require'), (')', 'require', 'computation'), ('require', 'computation', 'central-'), ('computation', 'central-', 'ized'), ('central-', 'ized', ','), ('ized', ',', 'make'), (',', 'make', 'capable'), ('make', 'capable', 'handling'), ('capable', 'handling', 'big'), ('handling', 'big', 'data'), ('big', 'data', 'clustering'), ('data', 'clustering', 'problems'), ('clustering', 'problems', 'major')]

>> POS Tags are: 
 [('Since', 'IN'), ('traditional', 'JJ'), ('clustering', 'NN'), ('algorithms', 'NN'), ('(', '('), ('e.g', 'JJ'), (',', ','), ('k-means', 'NNS'), (')', ')'), ('require', 'VBP'), ('computation', 'NN'), ('central-', 'JJ'), ('ized', 'JJ'), (',', ','), ('make', 'VBP'), ('capable', 'JJ'), ('handling', 'VBG'), ('big', 'JJ'), ('data', 'NNS'), ('clustering', 'VBG'), ('problems', 'NNS'), ('major', 'JJ')]

>> Noun Phrases are: 
 ['traditional clustering algorithms', 'k-means', 'computation', 'big data', 'problems']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Since', 'sinc'), ('traditional', 'tradit'), ('clustering', 'cluster'), ('algorithms', 'algorithm'), ('(', '('), ('e.g', 'e.g'), (',', ','), ('k-means', 'k-mean'), (')', ')'), ('require', 'requir'), ('computation', 'comput'), ('central-', 'central-'), ('ized', 'ize'), (',', ','), ('make', 'make'), ('capable', 'capabl'), ('handling', 'handl'), ('big', 'big'), ('data', 'data'), ('clustering', 'cluster'), ('problems', 'problem'), ('major', 'major')]

>> Stemming using Snowball Stemmer: 
 [('Since', 'sinc'), ('traditional', 'tradit'), ('clustering', 'cluster'), ('algorithms', 'algorithm'), ('(', '('), ('e.g', 'e.g'), (',', ','), ('k-means', 'k-mean'), (')', ')'), ('require', 'requir'), ('computation', 'comput'), ('central-', 'central-'), ('ized', 'ize'), (',', ','), ('make', 'make'), ('capable', 'capabl'), ('handling', 'handl'), ('big', 'big'), ('data', 'data'), ('clustering', 'cluster'), ('problems', 'problem'), ('major', 'major')]

>> Lemmatization: 
 [('Since', 'Since'), ('traditional', 'traditional'), ('clustering', 'clustering'), ('algorithms', 'algorithm'), ('(', '('), ('e.g', 'e.g'), (',', ','), ('k-means', 'k-means'), (')', ')'), ('require', 'require'), ('computation', 'computation'), ('central-', 'central-'), ('ized', 'ized'), (',', ','), ('make', 'make'), ('capable', 'capable'), ('handling', 'handling'), ('big', 'big'), ('data', 'data'), ('clustering', 'clustering'), ('problems', 'problem'), ('major', 'major')]



========================================== PARAGRAPH 261 ===========================================

Page 17 of 32Tsai et al. Journal of Big Data  (2015) 2:21  

------------------- Sentence 1 -------------------

Page 17 of 32Tsai et al.

>> Tokens are: 
 ['Page', '17', '32Tsai', 'et', 'al', '.']

>> Bigrams are: 
 [('Page', '17'), ('17', '32Tsai'), ('32Tsai', 'et'), ('et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('Page', '17', '32Tsai'), ('17', '32Tsai', 'et'), ('32Tsai', 'et', 'al'), ('et', 'al', '.')]

>> POS Tags are: 
 [('Page', 'NN'), ('17', 'CD'), ('32Tsai', 'CD'), ('et', 'NN'), ('al', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Page', 'et al']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Page', 'page'), ('17', '17'), ('32Tsai', '32tsai'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Page', 'page'), ('17', '17'), ('32Tsai', '32tsai'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('Page', 'Page'), ('17', '17'), ('32Tsai', '32Tsai'), ('et', 'et'), ('al', 'al'), ('.', '.')]


------------------- Sentence 2 -------------------

Journal of Big Data  (2015) 2:21

>> Tokens are: 
 ['Journal', 'Big', 'Data', '(', '2015', ')', '2:21']

>> Bigrams are: 
 [('Journal', 'Big'), ('Big', 'Data'), ('Data', '('), ('(', '2015'), ('2015', ')'), (')', '2:21')]

>> Trigrams are: 
 [('Journal', 'Big', 'Data'), ('Big', 'Data', '('), ('Data', '(', '2015'), ('(', '2015', ')'), ('2015', ')', '2:21')]

>> POS Tags are: 
 [('Journal', 'NNP'), ('Big', 'NNP'), ('Data', 'NNP'), ('(', '('), ('2015', 'CD'), (')', ')'), ('2:21', 'CD')]

>> Noun Phrases are: 
 ['Journal Big Data']

>> Named Entities are: 
 [('PERSON', 'Journal')] 

>> Stemming using Porter Stemmer: 
 [('Journal', 'journal'), ('Big', 'big'), ('Data', 'data'), ('(', '('), ('2015', '2015'), (')', ')'), ('2:21', '2:21')]

>> Stemming using Snowball Stemmer: 
 [('Journal', 'journal'), ('Big', 'big'), ('Data', 'data'), ('(', '('), ('2015', '2015'), (')', ')'), ('2:21', '2:21')]

>> Lemmatization: 
 [('Journal', 'Journal'), ('Big', 'Big'), ('Data', 'Data'), ('(', '('), ('2015', '2015'), (')', ')'), ('2:21', '2:21')]



========================================== PARAGRAPH 262 ===========================================

concern of Feldman et al. [114] who use a tree construction for generating the coresets  in parallel which is called the “merge-and-reduce” approach. Moreover, Feldman et al.  pointed out that by using this solution for clustering, the update time per datum and  memory of the traditional clustering algorithms can be significantly reduced. 

------------------- Sentence 1 -------------------

concern of Feldman et al.

>> Tokens are: 
 ['concern', 'Feldman', 'et', 'al', '.']

>> Bigrams are: 
 [('concern', 'Feldman'), ('Feldman', 'et'), ('et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('concern', 'Feldman', 'et'), ('Feldman', 'et', 'al'), ('et', 'al', '.')]

>> POS Tags are: 
 [('concern', 'NN'), ('Feldman', 'NNP'), ('et', 'VBZ'), ('al', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['concern Feldman', 'al']

>> Named Entities are: 
 [('PERSON', 'Feldman')] 

>> Stemming using Porter Stemmer: 
 [('concern', 'concern'), ('Feldman', 'feldman'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('concern', 'concern'), ('Feldman', 'feldman'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('concern', 'concern'), ('Feldman', 'Feldman'), ('et', 'et'), ('al', 'al'), ('.', '.')]


------------------- Sentence 2 -------------------

[114] who use a tree construction for generating the coresets  in parallel which is called the “merge-and-reduce” approach.

>> Tokens are: 
 ['[', '114', ']', 'use', 'tree', 'construction', 'generating', 'coresets', 'parallel', 'called', '“', 'merge-and-reduce', '”', 'approach', '.']

>> Bigrams are: 
 [('[', '114'), ('114', ']'), (']', 'use'), ('use', 'tree'), ('tree', 'construction'), ('construction', 'generating'), ('generating', 'coresets'), ('coresets', 'parallel'), ('parallel', 'called'), ('called', '“'), ('“', 'merge-and-reduce'), ('merge-and-reduce', '”'), ('”', 'approach'), ('approach', '.')]

>> Trigrams are: 
 [('[', '114', ']'), ('114', ']', 'use'), (']', 'use', 'tree'), ('use', 'tree', 'construction'), ('tree', 'construction', 'generating'), ('construction', 'generating', 'coresets'), ('generating', 'coresets', 'parallel'), ('coresets', 'parallel', 'called'), ('parallel', 'called', '“'), ('called', '“', 'merge-and-reduce'), ('“', 'merge-and-reduce', '”'), ('merge-and-reduce', '”', 'approach'), ('”', 'approach', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('114', 'CD'), (']', 'NNS'), ('use', 'VBP'), ('tree', 'JJ'), ('construction', 'NN'), ('generating', 'VBG'), ('coresets', 'NNS'), ('parallel', 'RB'), ('called', 'VBD'), ('“', 'JJ'), ('merge-and-reduce', 'NN'), ('”', 'NNP'), ('approach', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 [']', 'tree construction', 'coresets', '“ merge-and-reduce ” approach']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('114', '114'), (']', ']'), ('use', 'use'), ('tree', 'tree'), ('construction', 'construct'), ('generating', 'gener'), ('coresets', 'coreset'), ('parallel', 'parallel'), ('called', 'call'), ('“', '“'), ('merge-and-reduce', 'merge-and-reduc'), ('”', '”'), ('approach', 'approach'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('114', '114'), (']', ']'), ('use', 'use'), ('tree', 'tree'), ('construction', 'construct'), ('generating', 'generat'), ('coresets', 'coreset'), ('parallel', 'parallel'), ('called', 'call'), ('“', '“'), ('merge-and-reduce', 'merge-and-reduc'), ('”', '”'), ('approach', 'approach'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('114', '114'), (']', ']'), ('use', 'use'), ('tree', 'tree'), ('construction', 'construction'), ('generating', 'generating'), ('coresets', 'coresets'), ('parallel', 'parallel'), ('called', 'called'), ('“', '“'), ('merge-and-reduce', 'merge-and-reduce'), ('”', '”'), ('approach', 'approach'), ('.', '.')]


------------------- Sentence 3 -------------------

Moreover, Feldman et al.

>> Tokens are: 
 ['Moreover', ',', 'Feldman', 'et', 'al', '.']

>> Bigrams are: 
 [('Moreover', ','), (',', 'Feldman'), ('Feldman', 'et'), ('et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('Moreover', ',', 'Feldman'), (',', 'Feldman', 'et'), ('Feldman', 'et', 'al'), ('et', 'al', '.')]

>> POS Tags are: 
 [('Moreover', 'RB'), (',', ','), ('Feldman', 'NNP'), ('et', 'VBZ'), ('al', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Feldman', 'al']

>> Named Entities are: 
 [('PERSON', 'Feldman')] 

>> Stemming using Porter Stemmer: 
 [('Moreover', 'moreov'), (',', ','), ('Feldman', 'feldman'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Moreover', 'moreov'), (',', ','), ('Feldman', 'feldman'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('Moreover', 'Moreover'), (',', ','), ('Feldman', 'Feldman'), ('et', 'et'), ('al', 'al'), ('.', '.')]


------------------- Sentence 4 -------------------

pointed out that by using this solution for clustering, the update time per datum and  memory of the traditional clustering algorithms can be significantly reduced.

>> Tokens are: 
 ['pointed', 'using', 'solution', 'clustering', ',', 'update', 'time', 'per', 'datum', 'memory', 'traditional', 'clustering', 'algorithms', 'significantly', 'reduced', '.']

>> Bigrams are: 
 [('pointed', 'using'), ('using', 'solution'), ('solution', 'clustering'), ('clustering', ','), (',', 'update'), ('update', 'time'), ('time', 'per'), ('per', 'datum'), ('datum', 'memory'), ('memory', 'traditional'), ('traditional', 'clustering'), ('clustering', 'algorithms'), ('algorithms', 'significantly'), ('significantly', 'reduced'), ('reduced', '.')]

>> Trigrams are: 
 [('pointed', 'using', 'solution'), ('using', 'solution', 'clustering'), ('solution', 'clustering', ','), ('clustering', ',', 'update'), (',', 'update', 'time'), ('update', 'time', 'per'), ('time', 'per', 'datum'), ('per', 'datum', 'memory'), ('datum', 'memory', 'traditional'), ('memory', 'traditional', 'clustering'), ('traditional', 'clustering', 'algorithms'), ('clustering', 'algorithms', 'significantly'), ('algorithms', 'significantly', 'reduced'), ('significantly', 'reduced', '.')]

>> POS Tags are: 
 [('pointed', 'VBN'), ('using', 'VBG'), ('solution', 'NN'), ('clustering', 'NN'), (',', ','), ('update', 'JJ'), ('time', 'NN'), ('per', 'IN'), ('datum', 'NN'), ('memory', 'NN'), ('traditional', 'JJ'), ('clustering', 'NN'), ('algorithms', 'NN'), ('significantly', 'RB'), ('reduced', 'VBN'), ('.', '.')]

>> Noun Phrases are: 
 ['solution clustering', 'update time', 'datum memory', 'traditional clustering algorithms']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('pointed', 'point'), ('using', 'use'), ('solution', 'solut'), ('clustering', 'cluster'), (',', ','), ('update', 'updat'), ('time', 'time'), ('per', 'per'), ('datum', 'datum'), ('memory', 'memori'), ('traditional', 'tradit'), ('clustering', 'cluster'), ('algorithms', 'algorithm'), ('significantly', 'significantli'), ('reduced', 'reduc'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('pointed', 'point'), ('using', 'use'), ('solution', 'solut'), ('clustering', 'cluster'), (',', ','), ('update', 'updat'), ('time', 'time'), ('per', 'per'), ('datum', 'datum'), ('memory', 'memori'), ('traditional', 'tradit'), ('clustering', 'cluster'), ('algorithms', 'algorithm'), ('significantly', 'signific'), ('reduced', 'reduc'), ('.', '.')]

>> Lemmatization: 
 [('pointed', 'pointed'), ('using', 'using'), ('solution', 'solution'), ('clustering', 'clustering'), (',', ','), ('update', 'update'), ('time', 'time'), ('per', 'per'), ('datum', 'datum'), ('memory', 'memory'), ('traditional', 'traditional'), ('clustering', 'clustering'), ('algorithms', 'algorithm'), ('significantly', 'significantly'), ('reduced', 'reduced'), ('.', '.')]



========================================== PARAGRAPH 263 ===========================================

Classification algorithms Similar to the clustering algorithm for big data mining, sev- eral studies also attempted to modify the traditional classification algorithms to make  them work on a parallel computing environment or to develop new classification algo- rithms which work naturally on a parallel computing environment. In [115], the design  of classification algorithm took into account the input data that are gathered by distrib- uted data sources and they will be processed by a heterogeneous set of learners.5 In this  study, Tekin et al. presented a novel classification algorithm called “classify or send for  classification” (CoS). They assumed that each learner can be used to process the input  data in two different ways in a distributed data classification system. One is to perform a  classification function by itself while the other is to forward the input data to another  learner to have them labeled. The information will be exchanged between different  learners. In brief, this kind of solutions can be regarded as a cooperative learning to  improve the accuracy in solving the big data classification problem. An interesting solu- tion uses the quantum computing to reduce the memory space and computing cost of a  classification algorithm. For example, in [116], Rebentrost et al. presented a quantum- based support vector machine for big data classification and argued that the classifica- tion algorithm they proposed can be implemented with a time complexity O(logNM)  where N is the number of dimensions and M is the number of training data. There are  bright prospects for big data mining by using quantum-based search algorithm when the  hardware of quantum computing has become mature. 

------------------- Sentence 1 -------------------

Classification algorithms Similar to the clustering algorithm for big data mining, sev- eral studies also attempted to modify the traditional classification algorithms to make  them work on a parallel computing environment or to develop new classification algo- rithms which work naturally on a parallel computing environment.

>> Tokens are: 
 ['Classification', 'algorithms', 'Similar', 'clustering', 'algorithm', 'big', 'data', 'mining', ',', 'sev-', 'eral', 'studies', 'also', 'attempted', 'modify', 'traditional', 'classification', 'algorithms', 'make', 'work', 'parallel', 'computing', 'environment', 'develop', 'new', 'classification', 'algo-', 'rithms', 'work', 'naturally', 'parallel', 'computing', 'environment', '.']

>> Bigrams are: 
 [('Classification', 'algorithms'), ('algorithms', 'Similar'), ('Similar', 'clustering'), ('clustering', 'algorithm'), ('algorithm', 'big'), ('big', 'data'), ('data', 'mining'), ('mining', ','), (',', 'sev-'), ('sev-', 'eral'), ('eral', 'studies'), ('studies', 'also'), ('also', 'attempted'), ('attempted', 'modify'), ('modify', 'traditional'), ('traditional', 'classification'), ('classification', 'algorithms'), ('algorithms', 'make'), ('make', 'work'), ('work', 'parallel'), ('parallel', 'computing'), ('computing', 'environment'), ('environment', 'develop'), ('develop', 'new'), ('new', 'classification'), ('classification', 'algo-'), ('algo-', 'rithms'), ('rithms', 'work'), ('work', 'naturally'), ('naturally', 'parallel'), ('parallel', 'computing'), ('computing', 'environment'), ('environment', '.')]

>> Trigrams are: 
 [('Classification', 'algorithms', 'Similar'), ('algorithms', 'Similar', 'clustering'), ('Similar', 'clustering', 'algorithm'), ('clustering', 'algorithm', 'big'), ('algorithm', 'big', 'data'), ('big', 'data', 'mining'), ('data', 'mining', ','), ('mining', ',', 'sev-'), (',', 'sev-', 'eral'), ('sev-', 'eral', 'studies'), ('eral', 'studies', 'also'), ('studies', 'also', 'attempted'), ('also', 'attempted', 'modify'), ('attempted', 'modify', 'traditional'), ('modify', 'traditional', 'classification'), ('traditional', 'classification', 'algorithms'), ('classification', 'algorithms', 'make'), ('algorithms', 'make', 'work'), ('make', 'work', 'parallel'), ('work', 'parallel', 'computing'), ('parallel', 'computing', 'environment'), ('computing', 'environment', 'develop'), ('environment', 'develop', 'new'), ('develop', 'new', 'classification'), ('new', 'classification', 'algo-'), ('classification', 'algo-', 'rithms'), ('algo-', 'rithms', 'work'), ('rithms', 'work', 'naturally'), ('work', 'naturally', 'parallel'), ('naturally', 'parallel', 'computing'), ('parallel', 'computing', 'environment'), ('computing', 'environment', '.')]

>> POS Tags are: 
 [('Classification', 'NNP'), ('algorithms', 'VBD'), ('Similar', 'NNP'), ('clustering', 'VBG'), ('algorithm', 'RB'), ('big', 'JJ'), ('data', 'NNS'), ('mining', 'NN'), (',', ','), ('sev-', 'JJ'), ('eral', 'JJ'), ('studies', 'NNS'), ('also', 'RB'), ('attempted', 'VBD'), ('modify', 'JJ'), ('traditional', 'JJ'), ('classification', 'NN'), ('algorithms', 'NNS'), ('make', 'VBP'), ('work', 'NN'), ('parallel', 'RB'), ('computing', 'VBG'), ('environment', 'NN'), ('develop', 'VB'), ('new', 'JJ'), ('classification', 'NN'), ('algo-', 'JJ'), ('rithms', 'NN'), ('work', 'NN'), ('naturally', 'RB'), ('parallel', 'JJ'), ('computing', 'VBG'), ('environment', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Classification', 'Similar', 'big data mining', 'sev- eral studies', 'modify traditional classification algorithms', 'work', 'environment', 'new classification', 'algo- rithms work', 'environment']

>> Named Entities are: 
 [('PERSON', 'Classification'), ('PERSON', 'Similar')] 

>> Stemming using Porter Stemmer: 
 [('Classification', 'classif'), ('algorithms', 'algorithm'), ('Similar', 'similar'), ('clustering', 'cluster'), ('algorithm', 'algorithm'), ('big', 'big'), ('data', 'data'), ('mining', 'mine'), (',', ','), ('sev-', 'sev-'), ('eral', 'eral'), ('studies', 'studi'), ('also', 'also'), ('attempted', 'attempt'), ('modify', 'modifi'), ('traditional', 'tradit'), ('classification', 'classif'), ('algorithms', 'algorithm'), ('make', 'make'), ('work', 'work'), ('parallel', 'parallel'), ('computing', 'comput'), ('environment', 'environ'), ('develop', 'develop'), ('new', 'new'), ('classification', 'classif'), ('algo-', 'algo-'), ('rithms', 'rithm'), ('work', 'work'), ('naturally', 'natur'), ('parallel', 'parallel'), ('computing', 'comput'), ('environment', 'environ'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Classification', 'classif'), ('algorithms', 'algorithm'), ('Similar', 'similar'), ('clustering', 'cluster'), ('algorithm', 'algorithm'), ('big', 'big'), ('data', 'data'), ('mining', 'mine'), (',', ','), ('sev-', 'sev-'), ('eral', 'eral'), ('studies', 'studi'), ('also', 'also'), ('attempted', 'attempt'), ('modify', 'modifi'), ('traditional', 'tradit'), ('classification', 'classif'), ('algorithms', 'algorithm'), ('make', 'make'), ('work', 'work'), ('parallel', 'parallel'), ('computing', 'comput'), ('environment', 'environ'), ('develop', 'develop'), ('new', 'new'), ('classification', 'classif'), ('algo-', 'algo-'), ('rithms', 'rithm'), ('work', 'work'), ('naturally', 'natur'), ('parallel', 'parallel'), ('computing', 'comput'), ('environment', 'environ'), ('.', '.')]

>> Lemmatization: 
 [('Classification', 'Classification'), ('algorithms', 'algorithm'), ('Similar', 'Similar'), ('clustering', 'clustering'), ('algorithm', 'algorithm'), ('big', 'big'), ('data', 'data'), ('mining', 'mining'), (',', ','), ('sev-', 'sev-'), ('eral', 'eral'), ('studies', 'study'), ('also', 'also'), ('attempted', 'attempted'), ('modify', 'modify'), ('traditional', 'traditional'), ('classification', 'classification'), ('algorithms', 'algorithm'), ('make', 'make'), ('work', 'work'), ('parallel', 'parallel'), ('computing', 'computing'), ('environment', 'environment'), ('develop', 'develop'), ('new', 'new'), ('classification', 'classification'), ('algo-', 'algo-'), ('rithms', 'rithms'), ('work', 'work'), ('naturally', 'naturally'), ('parallel', 'parallel'), ('computing', 'computing'), ('environment', 'environment'), ('.', '.')]


------------------- Sentence 2 -------------------

In [115], the design  of classification algorithm took into account the input data that are gathered by distrib- uted data sources and they will be processed by a heterogeneous set of learners.5 In this  study, Tekin et al.

>> Tokens are: 
 ['In', '[', '115', ']', ',', 'design', 'classification', 'algorithm', 'took', 'account', 'input', 'data', 'gathered', 'distrib-', 'uted', 'data', 'sources', 'processed', 'heterogeneous', 'set', 'learners.5', 'In', 'study', ',', 'Tekin', 'et', 'al', '.']

>> Bigrams are: 
 [('In', '['), ('[', '115'), ('115', ']'), (']', ','), (',', 'design'), ('design', 'classification'), ('classification', 'algorithm'), ('algorithm', 'took'), ('took', 'account'), ('account', 'input'), ('input', 'data'), ('data', 'gathered'), ('gathered', 'distrib-'), ('distrib-', 'uted'), ('uted', 'data'), ('data', 'sources'), ('sources', 'processed'), ('processed', 'heterogeneous'), ('heterogeneous', 'set'), ('set', 'learners.5'), ('learners.5', 'In'), ('In', 'study'), ('study', ','), (',', 'Tekin'), ('Tekin', 'et'), ('et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('In', '[', '115'), ('[', '115', ']'), ('115', ']', ','), (']', ',', 'design'), (',', 'design', 'classification'), ('design', 'classification', 'algorithm'), ('classification', 'algorithm', 'took'), ('algorithm', 'took', 'account'), ('took', 'account', 'input'), ('account', 'input', 'data'), ('input', 'data', 'gathered'), ('data', 'gathered', 'distrib-'), ('gathered', 'distrib-', 'uted'), ('distrib-', 'uted', 'data'), ('uted', 'data', 'sources'), ('data', 'sources', 'processed'), ('sources', 'processed', 'heterogeneous'), ('processed', 'heterogeneous', 'set'), ('heterogeneous', 'set', 'learners.5'), ('set', 'learners.5', 'In'), ('learners.5', 'In', 'study'), ('In', 'study', ','), ('study', ',', 'Tekin'), (',', 'Tekin', 'et'), ('Tekin', 'et', 'al'), ('et', 'al', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('[', '$'), ('115', 'CD'), (']', 'NNP'), (',', ','), ('design', 'NN'), ('classification', 'NN'), ('algorithm', 'NN'), ('took', 'VBD'), ('account', 'NN'), ('input', 'NN'), ('data', 'NNS'), ('gathered', 'VBD'), ('distrib-', 'NN'), ('uted', 'JJ'), ('data', 'NNS'), ('sources', 'NNS'), ('processed', 'VBD'), ('heterogeneous', 'JJ'), ('set', 'NN'), ('learners.5', 'NN'), ('In', 'IN'), ('study', 'NN'), (',', ','), ('Tekin', 'NNP'), ('et', 'CC'), ('al', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 [']', 'design classification algorithm', 'account input data', 'distrib-', 'uted data sources', 'heterogeneous set learners.5', 'study', 'Tekin', 'al']

>> Named Entities are: 
 [('PERSON', 'Tekin')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('[', '['), ('115', '115'), (']', ']'), (',', ','), ('design', 'design'), ('classification', 'classif'), ('algorithm', 'algorithm'), ('took', 'took'), ('account', 'account'), ('input', 'input'), ('data', 'data'), ('gathered', 'gather'), ('distrib-', 'distrib-'), ('uted', 'ute'), ('data', 'data'), ('sources', 'sourc'), ('processed', 'process'), ('heterogeneous', 'heterogen'), ('set', 'set'), ('learners.5', 'learners.5'), ('In', 'in'), ('study', 'studi'), (',', ','), ('Tekin', 'tekin'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('[', '['), ('115', '115'), (']', ']'), (',', ','), ('design', 'design'), ('classification', 'classif'), ('algorithm', 'algorithm'), ('took', 'took'), ('account', 'account'), ('input', 'input'), ('data', 'data'), ('gathered', 'gather'), ('distrib-', 'distrib-'), ('uted', 'ute'), ('data', 'data'), ('sources', 'sourc'), ('processed', 'process'), ('heterogeneous', 'heterogen'), ('set', 'set'), ('learners.5', 'learners.5'), ('In', 'in'), ('study', 'studi'), (',', ','), ('Tekin', 'tekin'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('[', '['), ('115', '115'), (']', ']'), (',', ','), ('design', 'design'), ('classification', 'classification'), ('algorithm', 'algorithm'), ('took', 'took'), ('account', 'account'), ('input', 'input'), ('data', 'data'), ('gathered', 'gathered'), ('distrib-', 'distrib-'), ('uted', 'uted'), ('data', 'data'), ('sources', 'source'), ('processed', 'processed'), ('heterogeneous', 'heterogeneous'), ('set', 'set'), ('learners.5', 'learners.5'), ('In', 'In'), ('study', 'study'), (',', ','), ('Tekin', 'Tekin'), ('et', 'et'), ('al', 'al'), ('.', '.')]


------------------- Sentence 3 -------------------

presented a novel classification algorithm called “classify or send for  classification” (CoS).

>> Tokens are: 
 ['presented', 'novel', 'classification', 'algorithm', 'called', '“', 'classify', 'send', 'classification', '”', '(', 'CoS', ')', '.']

>> Bigrams are: 
 [('presented', 'novel'), ('novel', 'classification'), ('classification', 'algorithm'), ('algorithm', 'called'), ('called', '“'), ('“', 'classify'), ('classify', 'send'), ('send', 'classification'), ('classification', '”'), ('”', '('), ('(', 'CoS'), ('CoS', ')'), (')', '.')]

>> Trigrams are: 
 [('presented', 'novel', 'classification'), ('novel', 'classification', 'algorithm'), ('classification', 'algorithm', 'called'), ('algorithm', 'called', '“'), ('called', '“', 'classify'), ('“', 'classify', 'send'), ('classify', 'send', 'classification'), ('send', 'classification', '”'), ('classification', '”', '('), ('”', '(', 'CoS'), ('(', 'CoS', ')'), ('CoS', ')', '.')]

>> POS Tags are: 
 [('presented', 'VBN'), ('novel', 'JJ'), ('classification', 'NN'), ('algorithm', 'NN'), ('called', 'VBN'), ('“', 'NNP'), ('classify', 'VB'), ('send', 'JJ'), ('classification', 'NN'), ('”', 'NNP'), ('(', '('), ('CoS', 'NNP'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['novel classification algorithm', '“', 'send classification ”', 'CoS']

>> Named Entities are: 
 [('ORGANIZATION', 'CoS')] 

>> Stemming using Porter Stemmer: 
 [('presented', 'present'), ('novel', 'novel'), ('classification', 'classif'), ('algorithm', 'algorithm'), ('called', 'call'), ('“', '“'), ('classify', 'classifi'), ('send', 'send'), ('classification', 'classif'), ('”', '”'), ('(', '('), ('CoS', 'co'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('presented', 'present'), ('novel', 'novel'), ('classification', 'classif'), ('algorithm', 'algorithm'), ('called', 'call'), ('“', '“'), ('classify', 'classifi'), ('send', 'send'), ('classification', 'classif'), ('”', '”'), ('(', '('), ('CoS', 'cos'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('presented', 'presented'), ('novel', 'novel'), ('classification', 'classification'), ('algorithm', 'algorithm'), ('called', 'called'), ('“', '“'), ('classify', 'classify'), ('send', 'send'), ('classification', 'classification'), ('”', '”'), ('(', '('), ('CoS', 'CoS'), (')', ')'), ('.', '.')]


------------------- Sentence 4 -------------------

They assumed that each learner can be used to process the input  data in two different ways in a distributed data classification system.

>> Tokens are: 
 ['They', 'assumed', 'learner', 'used', 'process', 'input', 'data', 'two', 'different', 'ways', 'distributed', 'data', 'classification', 'system', '.']

>> Bigrams are: 
 [('They', 'assumed'), ('assumed', 'learner'), ('learner', 'used'), ('used', 'process'), ('process', 'input'), ('input', 'data'), ('data', 'two'), ('two', 'different'), ('different', 'ways'), ('ways', 'distributed'), ('distributed', 'data'), ('data', 'classification'), ('classification', 'system'), ('system', '.')]

>> Trigrams are: 
 [('They', 'assumed', 'learner'), ('assumed', 'learner', 'used'), ('learner', 'used', 'process'), ('used', 'process', 'input'), ('process', 'input', 'data'), ('input', 'data', 'two'), ('data', 'two', 'different'), ('two', 'different', 'ways'), ('different', 'ways', 'distributed'), ('ways', 'distributed', 'data'), ('distributed', 'data', 'classification'), ('data', 'classification', 'system'), ('classification', 'system', '.')]

>> POS Tags are: 
 [('They', 'PRP'), ('assumed', 'VBD'), ('learner', 'NN'), ('used', 'VBN'), ('process', 'NN'), ('input', 'NN'), ('data', 'NNS'), ('two', 'CD'), ('different', 'JJ'), ('ways', 'NNS'), ('distributed', 'VBN'), ('data', 'NNS'), ('classification', 'NN'), ('system', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['learner', 'process input data', 'different ways', 'data classification system']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('They', 'they'), ('assumed', 'assum'), ('learner', 'learner'), ('used', 'use'), ('process', 'process'), ('input', 'input'), ('data', 'data'), ('two', 'two'), ('different', 'differ'), ('ways', 'way'), ('distributed', 'distribut'), ('data', 'data'), ('classification', 'classif'), ('system', 'system'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('They', 'they'), ('assumed', 'assum'), ('learner', 'learner'), ('used', 'use'), ('process', 'process'), ('input', 'input'), ('data', 'data'), ('two', 'two'), ('different', 'differ'), ('ways', 'way'), ('distributed', 'distribut'), ('data', 'data'), ('classification', 'classif'), ('system', 'system'), ('.', '.')]

>> Lemmatization: 
 [('They', 'They'), ('assumed', 'assumed'), ('learner', 'learner'), ('used', 'used'), ('process', 'process'), ('input', 'input'), ('data', 'data'), ('two', 'two'), ('different', 'different'), ('ways', 'way'), ('distributed', 'distributed'), ('data', 'data'), ('classification', 'classification'), ('system', 'system'), ('.', '.')]


------------------- Sentence 5 -------------------

One is to perform a  classification function by itself while the other is to forward the input data to another  learner to have them labeled.

>> Tokens are: 
 ['One', 'perform', 'classification', 'function', 'forward', 'input', 'data', 'another', 'learner', 'labeled', '.']

>> Bigrams are: 
 [('One', 'perform'), ('perform', 'classification'), ('classification', 'function'), ('function', 'forward'), ('forward', 'input'), ('input', 'data'), ('data', 'another'), ('another', 'learner'), ('learner', 'labeled'), ('labeled', '.')]

>> Trigrams are: 
 [('One', 'perform', 'classification'), ('perform', 'classification', 'function'), ('classification', 'function', 'forward'), ('function', 'forward', 'input'), ('forward', 'input', 'data'), ('input', 'data', 'another'), ('data', 'another', 'learner'), ('another', 'learner', 'labeled'), ('learner', 'labeled', '.')]

>> POS Tags are: 
 [('One', 'CD'), ('perform', 'NN'), ('classification', 'NN'), ('function', 'NN'), ('forward', 'RB'), ('input', 'NN'), ('data', 'NNS'), ('another', 'DT'), ('learner', 'NN'), ('labeled', 'VBD'), ('.', '.')]

>> Noun Phrases are: 
 ['perform classification function', 'input data', 'another learner']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('One', 'one'), ('perform', 'perform'), ('classification', 'classif'), ('function', 'function'), ('forward', 'forward'), ('input', 'input'), ('data', 'data'), ('another', 'anoth'), ('learner', 'learner'), ('labeled', 'label'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('One', 'one'), ('perform', 'perform'), ('classification', 'classif'), ('function', 'function'), ('forward', 'forward'), ('input', 'input'), ('data', 'data'), ('another', 'anoth'), ('learner', 'learner'), ('labeled', 'label'), ('.', '.')]

>> Lemmatization: 
 [('One', 'One'), ('perform', 'perform'), ('classification', 'classification'), ('function', 'function'), ('forward', 'forward'), ('input', 'input'), ('data', 'data'), ('another', 'another'), ('learner', 'learner'), ('labeled', 'labeled'), ('.', '.')]


------------------- Sentence 6 -------------------

The information will be exchanged between different  learners.

>> Tokens are: 
 ['The', 'information', 'exchanged', 'different', 'learners', '.']

>> Bigrams are: 
 [('The', 'information'), ('information', 'exchanged'), ('exchanged', 'different'), ('different', 'learners'), ('learners', '.')]

>> Trigrams are: 
 [('The', 'information', 'exchanged'), ('information', 'exchanged', 'different'), ('exchanged', 'different', 'learners'), ('different', 'learners', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('information', 'NN'), ('exchanged', 'VBD'), ('different', 'JJ'), ('learners', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['The information', 'different learners']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('information', 'inform'), ('exchanged', 'exchang'), ('different', 'differ'), ('learners', 'learner'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('information', 'inform'), ('exchanged', 'exchang'), ('different', 'differ'), ('learners', 'learner'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('information', 'information'), ('exchanged', 'exchanged'), ('different', 'different'), ('learners', 'learner'), ('.', '.')]


------------------- Sentence 7 -------------------

In brief, this kind of solutions can be regarded as a cooperative learning to  improve the accuracy in solving the big data classification problem.

>> Tokens are: 
 ['In', 'brief', ',', 'kind', 'solutions', 'regarded', 'cooperative', 'learning', 'improve', 'accuracy', 'solving', 'big', 'data', 'classification', 'problem', '.']

>> Bigrams are: 
 [('In', 'brief'), ('brief', ','), (',', 'kind'), ('kind', 'solutions'), ('solutions', 'regarded'), ('regarded', 'cooperative'), ('cooperative', 'learning'), ('learning', 'improve'), ('improve', 'accuracy'), ('accuracy', 'solving'), ('solving', 'big'), ('big', 'data'), ('data', 'classification'), ('classification', 'problem'), ('problem', '.')]

>> Trigrams are: 
 [('In', 'brief', ','), ('brief', ',', 'kind'), (',', 'kind', 'solutions'), ('kind', 'solutions', 'regarded'), ('solutions', 'regarded', 'cooperative'), ('regarded', 'cooperative', 'learning'), ('cooperative', 'learning', 'improve'), ('learning', 'improve', 'accuracy'), ('improve', 'accuracy', 'solving'), ('accuracy', 'solving', 'big'), ('solving', 'big', 'data'), ('big', 'data', 'classification'), ('data', 'classification', 'problem'), ('classification', 'problem', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('brief', 'NN'), (',', ','), ('kind', 'NN'), ('solutions', 'NNS'), ('regarded', 'VBD'), ('cooperative', 'JJ'), ('learning', 'NN'), ('improve', 'VB'), ('accuracy', 'NN'), ('solving', 'VBG'), ('big', 'JJ'), ('data', 'NNS'), ('classification', 'NN'), ('problem', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['brief', 'kind solutions', 'cooperative learning', 'accuracy', 'big data classification problem']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('brief', 'brief'), (',', ','), ('kind', 'kind'), ('solutions', 'solut'), ('regarded', 'regard'), ('cooperative', 'cooper'), ('learning', 'learn'), ('improve', 'improv'), ('accuracy', 'accuraci'), ('solving', 'solv'), ('big', 'big'), ('data', 'data'), ('classification', 'classif'), ('problem', 'problem'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('brief', 'brief'), (',', ','), ('kind', 'kind'), ('solutions', 'solut'), ('regarded', 'regard'), ('cooperative', 'cooper'), ('learning', 'learn'), ('improve', 'improv'), ('accuracy', 'accuraci'), ('solving', 'solv'), ('big', 'big'), ('data', 'data'), ('classification', 'classif'), ('problem', 'problem'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('brief', 'brief'), (',', ','), ('kind', 'kind'), ('solutions', 'solution'), ('regarded', 'regarded'), ('cooperative', 'cooperative'), ('learning', 'learning'), ('improve', 'improve'), ('accuracy', 'accuracy'), ('solving', 'solving'), ('big', 'big'), ('data', 'data'), ('classification', 'classification'), ('problem', 'problem'), ('.', '.')]


------------------- Sentence 8 -------------------

An interesting solu- tion uses the quantum computing to reduce the memory space and computing cost of a  classification algorithm.

>> Tokens are: 
 ['An', 'interesting', 'solu-', 'tion', 'uses', 'quantum', 'computing', 'reduce', 'memory', 'space', 'computing', 'cost', 'classification', 'algorithm', '.']

>> Bigrams are: 
 [('An', 'interesting'), ('interesting', 'solu-'), ('solu-', 'tion'), ('tion', 'uses'), ('uses', 'quantum'), ('quantum', 'computing'), ('computing', 'reduce'), ('reduce', 'memory'), ('memory', 'space'), ('space', 'computing'), ('computing', 'cost'), ('cost', 'classification'), ('classification', 'algorithm'), ('algorithm', '.')]

>> Trigrams are: 
 [('An', 'interesting', 'solu-'), ('interesting', 'solu-', 'tion'), ('solu-', 'tion', 'uses'), ('tion', 'uses', 'quantum'), ('uses', 'quantum', 'computing'), ('quantum', 'computing', 'reduce'), ('computing', 'reduce', 'memory'), ('reduce', 'memory', 'space'), ('memory', 'space', 'computing'), ('space', 'computing', 'cost'), ('computing', 'cost', 'classification'), ('cost', 'classification', 'algorithm'), ('classification', 'algorithm', '.')]

>> POS Tags are: 
 [('An', 'DT'), ('interesting', 'JJ'), ('solu-', 'JJ'), ('tion', 'NN'), ('uses', 'VBZ'), ('quantum', 'JJ'), ('computing', 'VBG'), ('reduce', 'VB'), ('memory', 'NN'), ('space', 'NN'), ('computing', 'VBG'), ('cost', 'NN'), ('classification', 'NN'), ('algorithm', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['An interesting solu- tion', 'memory space', 'cost classification algorithm']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('An', 'an'), ('interesting', 'interest'), ('solu-', 'solu-'), ('tion', 'tion'), ('uses', 'use'), ('quantum', 'quantum'), ('computing', 'comput'), ('reduce', 'reduc'), ('memory', 'memori'), ('space', 'space'), ('computing', 'comput'), ('cost', 'cost'), ('classification', 'classif'), ('algorithm', 'algorithm'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('An', 'an'), ('interesting', 'interest'), ('solu-', 'solu-'), ('tion', 'tion'), ('uses', 'use'), ('quantum', 'quantum'), ('computing', 'comput'), ('reduce', 'reduc'), ('memory', 'memori'), ('space', 'space'), ('computing', 'comput'), ('cost', 'cost'), ('classification', 'classif'), ('algorithm', 'algorithm'), ('.', '.')]

>> Lemmatization: 
 [('An', 'An'), ('interesting', 'interesting'), ('solu-', 'solu-'), ('tion', 'tion'), ('uses', 'us'), ('quantum', 'quantum'), ('computing', 'computing'), ('reduce', 'reduce'), ('memory', 'memory'), ('space', 'space'), ('computing', 'computing'), ('cost', 'cost'), ('classification', 'classification'), ('algorithm', 'algorithm'), ('.', '.')]


------------------- Sentence 9 -------------------

For example, in [116], Rebentrost et al.

>> Tokens are: 
 ['For', 'example', ',', '[', '116', ']', ',', 'Rebentrost', 'et', 'al', '.']

>> Bigrams are: 
 [('For', 'example'), ('example', ','), (',', '['), ('[', '116'), ('116', ']'), (']', ','), (',', 'Rebentrost'), ('Rebentrost', 'et'), ('et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('For', 'example', ','), ('example', ',', '['), (',', '[', '116'), ('[', '116', ']'), ('116', ']', ','), (']', ',', 'Rebentrost'), (',', 'Rebentrost', 'et'), ('Rebentrost', 'et', 'al'), ('et', 'al', '.')]

>> POS Tags are: 
 [('For', 'IN'), ('example', 'NN'), (',', ','), ('[', 'VBZ'), ('116', 'CD'), (']', 'NN'), (',', ','), ('Rebentrost', 'NNP'), ('et', 'CC'), ('al', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['example', ']', 'Rebentrost', 'al']

>> Named Entities are: 
 [('ORGANIZATION', 'Rebentrost')] 

>> Stemming using Porter Stemmer: 
 [('For', 'for'), ('example', 'exampl'), (',', ','), ('[', '['), ('116', '116'), (']', ']'), (',', ','), ('Rebentrost', 'rebentrost'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('For', 'for'), ('example', 'exampl'), (',', ','), ('[', '['), ('116', '116'), (']', ']'), (',', ','), ('Rebentrost', 'rebentrost'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('For', 'For'), ('example', 'example'), (',', ','), ('[', '['), ('116', '116'), (']', ']'), (',', ','), ('Rebentrost', 'Rebentrost'), ('et', 'et'), ('al', 'al'), ('.', '.')]


------------------- Sentence 10 -------------------

presented a quantum- based support vector machine for big data classification and argued that the classifica- tion algorithm they proposed can be implemented with a time complexity O(logNM)  where N is the number of dimensions and M is the number of training data.

>> Tokens are: 
 ['presented', 'quantum-', 'based', 'support', 'vector', 'machine', 'big', 'data', 'classification', 'argued', 'classifica-', 'tion', 'algorithm', 'proposed', 'implemented', 'time', 'complexity', 'O', '(', 'logNM', ')', 'N', 'number', 'dimensions', 'M', 'number', 'training', 'data', '.']

>> Bigrams are: 
 [('presented', 'quantum-'), ('quantum-', 'based'), ('based', 'support'), ('support', 'vector'), ('vector', 'machine'), ('machine', 'big'), ('big', 'data'), ('data', 'classification'), ('classification', 'argued'), ('argued', 'classifica-'), ('classifica-', 'tion'), ('tion', 'algorithm'), ('algorithm', 'proposed'), ('proposed', 'implemented'), ('implemented', 'time'), ('time', 'complexity'), ('complexity', 'O'), ('O', '('), ('(', 'logNM'), ('logNM', ')'), (')', 'N'), ('N', 'number'), ('number', 'dimensions'), ('dimensions', 'M'), ('M', 'number'), ('number', 'training'), ('training', 'data'), ('data', '.')]

>> Trigrams are: 
 [('presented', 'quantum-', 'based'), ('quantum-', 'based', 'support'), ('based', 'support', 'vector'), ('support', 'vector', 'machine'), ('vector', 'machine', 'big'), ('machine', 'big', 'data'), ('big', 'data', 'classification'), ('data', 'classification', 'argued'), ('classification', 'argued', 'classifica-'), ('argued', 'classifica-', 'tion'), ('classifica-', 'tion', 'algorithm'), ('tion', 'algorithm', 'proposed'), ('algorithm', 'proposed', 'implemented'), ('proposed', 'implemented', 'time'), ('implemented', 'time', 'complexity'), ('time', 'complexity', 'O'), ('complexity', 'O', '('), ('O', '(', 'logNM'), ('(', 'logNM', ')'), ('logNM', ')', 'N'), (')', 'N', 'number'), ('N', 'number', 'dimensions'), ('number', 'dimensions', 'M'), ('dimensions', 'M', 'number'), ('M', 'number', 'training'), ('number', 'training', 'data'), ('training', 'data', '.')]

>> POS Tags are: 
 [('presented', 'VBN'), ('quantum-', 'NN'), ('based', 'VBN'), ('support', 'NN'), ('vector', 'NN'), ('machine', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('classification', 'NN'), ('argued', 'VBD'), ('classifica-', 'JJ'), ('tion', 'NN'), ('algorithm', 'NNS'), ('proposed', 'VBN'), ('implemented', 'JJ'), ('time', 'NN'), ('complexity', 'NN'), ('O', 'NNP'), ('(', '('), ('logNM', 'NN'), (')', ')'), ('N', 'NNP'), ('number', 'NN'), ('dimensions', 'NNS'), ('M', 'NNP'), ('number', 'NN'), ('training', 'NN'), ('data', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['quantum-', 'support vector machine', 'big data classification', 'classifica- tion algorithm', 'implemented time complexity O', 'logNM', 'N number dimensions M number training data']

>> Named Entities are: 
 [('ORGANIZATION', 'logNM')] 

>> Stemming using Porter Stemmer: 
 [('presented', 'present'), ('quantum-', 'quantum-'), ('based', 'base'), ('support', 'support'), ('vector', 'vector'), ('machine', 'machin'), ('big', 'big'), ('data', 'data'), ('classification', 'classif'), ('argued', 'argu'), ('classifica-', 'classifica-'), ('tion', 'tion'), ('algorithm', 'algorithm'), ('proposed', 'propos'), ('implemented', 'implement'), ('time', 'time'), ('complexity', 'complex'), ('O', 'o'), ('(', '('), ('logNM', 'lognm'), (')', ')'), ('N', 'n'), ('number', 'number'), ('dimensions', 'dimens'), ('M', 'm'), ('number', 'number'), ('training', 'train'), ('data', 'data'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('presented', 'present'), ('quantum-', 'quantum-'), ('based', 'base'), ('support', 'support'), ('vector', 'vector'), ('machine', 'machin'), ('big', 'big'), ('data', 'data'), ('classification', 'classif'), ('argued', 'argu'), ('classifica-', 'classifica-'), ('tion', 'tion'), ('algorithm', 'algorithm'), ('proposed', 'propos'), ('implemented', 'implement'), ('time', 'time'), ('complexity', 'complex'), ('O', 'o'), ('(', '('), ('logNM', 'lognm'), (')', ')'), ('N', 'n'), ('number', 'number'), ('dimensions', 'dimens'), ('M', 'm'), ('number', 'number'), ('training', 'train'), ('data', 'data'), ('.', '.')]

>> Lemmatization: 
 [('presented', 'presented'), ('quantum-', 'quantum-'), ('based', 'based'), ('support', 'support'), ('vector', 'vector'), ('machine', 'machine'), ('big', 'big'), ('data', 'data'), ('classification', 'classification'), ('argued', 'argued'), ('classifica-', 'classifica-'), ('tion', 'tion'), ('algorithm', 'algorithm'), ('proposed', 'proposed'), ('implemented', 'implemented'), ('time', 'time'), ('complexity', 'complexity'), ('O', 'O'), ('(', '('), ('logNM', 'logNM'), (')', ')'), ('N', 'N'), ('number', 'number'), ('dimensions', 'dimension'), ('M', 'M'), ('number', 'number'), ('training', 'training'), ('data', 'data'), ('.', '.')]


------------------- Sentence 11 -------------------

There are  bright prospects for big data mining by using quantum-based search algorithm when the  hardware of quantum computing has become mature.

>> Tokens are: 
 ['There', 'bright', 'prospects', 'big', 'data', 'mining', 'using', 'quantum-based', 'search', 'algorithm', 'hardware', 'quantum', 'computing', 'become', 'mature', '.']

>> Bigrams are: 
 [('There', 'bright'), ('bright', 'prospects'), ('prospects', 'big'), ('big', 'data'), ('data', 'mining'), ('mining', 'using'), ('using', 'quantum-based'), ('quantum-based', 'search'), ('search', 'algorithm'), ('algorithm', 'hardware'), ('hardware', 'quantum'), ('quantum', 'computing'), ('computing', 'become'), ('become', 'mature'), ('mature', '.')]

>> Trigrams are: 
 [('There', 'bright', 'prospects'), ('bright', 'prospects', 'big'), ('prospects', 'big', 'data'), ('big', 'data', 'mining'), ('data', 'mining', 'using'), ('mining', 'using', 'quantum-based'), ('using', 'quantum-based', 'search'), ('quantum-based', 'search', 'algorithm'), ('search', 'algorithm', 'hardware'), ('algorithm', 'hardware', 'quantum'), ('hardware', 'quantum', 'computing'), ('quantum', 'computing', 'become'), ('computing', 'become', 'mature'), ('become', 'mature', '.')]

>> POS Tags are: 
 [('There', 'EX'), ('bright', 'JJ'), ('prospects', 'NNS'), ('big', 'JJ'), ('data', 'NNS'), ('mining', 'NN'), ('using', 'VBG'), ('quantum-based', 'JJ'), ('search', 'NN'), ('algorithm', 'NN'), ('hardware', 'NN'), ('quantum', 'NN'), ('computing', 'VBG'), ('become', 'JJ'), ('mature', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['bright prospects', 'big data mining', 'quantum-based search algorithm hardware quantum', 'become mature']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('There', 'there'), ('bright', 'bright'), ('prospects', 'prospect'), ('big', 'big'), ('data', 'data'), ('mining', 'mine'), ('using', 'use'), ('quantum-based', 'quantum-bas'), ('search', 'search'), ('algorithm', 'algorithm'), ('hardware', 'hardwar'), ('quantum', 'quantum'), ('computing', 'comput'), ('become', 'becom'), ('mature', 'matur'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('There', 'there'), ('bright', 'bright'), ('prospects', 'prospect'), ('big', 'big'), ('data', 'data'), ('mining', 'mine'), ('using', 'use'), ('quantum-based', 'quantum-bas'), ('search', 'search'), ('algorithm', 'algorithm'), ('hardware', 'hardwar'), ('quantum', 'quantum'), ('computing', 'comput'), ('become', 'becom'), ('mature', 'matur'), ('.', '.')]

>> Lemmatization: 
 [('There', 'There'), ('bright', 'bright'), ('prospects', 'prospect'), ('big', 'big'), ('data', 'data'), ('mining', 'mining'), ('using', 'using'), ('quantum-based', 'quantum-based'), ('search', 'search'), ('algorithm', 'algorithm'), ('hardware', 'hardware'), ('quantum', 'quantum'), ('computing', 'computing'), ('become', 'become'), ('mature', 'mature'), ('.', '.')]



========================================== PARAGRAPH 264 ===========================================

Frequent pattern mining algorithms Most of the researches on frequent pattern min- ing (i.e.-, association rules and sequential pattern mining) were focused on handling  large-scale dataset at the very beginning because some early approaches of them were  attempted to analyze the data from the transaction data of large shopping mall. Because  the number of transactions usually is more than “tens of thousands”, the issues about  how to handle the large scale data were studied for several years, such as FP-tree [32]  using the tree structure to include the frequent patterns to further reduce the compu- tation time of association rule mining. In addition to the traditional frequent pattern  mining algorithms, of course, parallel computing and cloud computing technologies  have also attracted researchers in this research domain. Among them, the map-reduce  solution was used for the studies [117–119] to enhance the performance of the frequent  pattern mining algorithm. By using the map-reduce model for frequent pattern mining  algorithm, it can be easily expected that its application to “cloud platform” [120, 121] will  definitely become a popular trend in the forthcoming future. The study of [119] no only  used the map-reduce model, it also allowed users to express their specific interest con- straints in the process of frequent pattern mining. The performance of these methods  by using map-reduce model for big data analysis is, no doubt, better than the traditional  frequent pattern mining algorithms running on a single machine. 

------------------- Sentence 1 -------------------

Frequent pattern mining algorithms Most of the researches on frequent pattern min- ing (i.e.-, association rules and sequential pattern mining) were focused on handling  large-scale dataset at the very beginning because some early approaches of them were  attempted to analyze the data from the transaction data of large shopping mall.

>> Tokens are: 
 ['Frequent', 'pattern', 'mining', 'algorithms', 'Most', 'researches', 'frequent', 'pattern', 'min-', 'ing', '(', 'i.e.-', ',', 'association', 'rules', 'sequential', 'pattern', 'mining', ')', 'focused', 'handling', 'large-scale', 'dataset', 'beginning', 'early', 'approaches', 'attempted', 'analyze', 'data', 'transaction', 'data', 'large', 'shopping', 'mall', '.']

>> Bigrams are: 
 [('Frequent', 'pattern'), ('pattern', 'mining'), ('mining', 'algorithms'), ('algorithms', 'Most'), ('Most', 'researches'), ('researches', 'frequent'), ('frequent', 'pattern'), ('pattern', 'min-'), ('min-', 'ing'), ('ing', '('), ('(', 'i.e.-'), ('i.e.-', ','), (',', 'association'), ('association', 'rules'), ('rules', 'sequential'), ('sequential', 'pattern'), ('pattern', 'mining'), ('mining', ')'), (')', 'focused'), ('focused', 'handling'), ('handling', 'large-scale'), ('large-scale', 'dataset'), ('dataset', 'beginning'), ('beginning', 'early'), ('early', 'approaches'), ('approaches', 'attempted'), ('attempted', 'analyze'), ('analyze', 'data'), ('data', 'transaction'), ('transaction', 'data'), ('data', 'large'), ('large', 'shopping'), ('shopping', 'mall'), ('mall', '.')]

>> Trigrams are: 
 [('Frequent', 'pattern', 'mining'), ('pattern', 'mining', 'algorithms'), ('mining', 'algorithms', 'Most'), ('algorithms', 'Most', 'researches'), ('Most', 'researches', 'frequent'), ('researches', 'frequent', 'pattern'), ('frequent', 'pattern', 'min-'), ('pattern', 'min-', 'ing'), ('min-', 'ing', '('), ('ing', '(', 'i.e.-'), ('(', 'i.e.-', ','), ('i.e.-', ',', 'association'), (',', 'association', 'rules'), ('association', 'rules', 'sequential'), ('rules', 'sequential', 'pattern'), ('sequential', 'pattern', 'mining'), ('pattern', 'mining', ')'), ('mining', ')', 'focused'), (')', 'focused', 'handling'), ('focused', 'handling', 'large-scale'), ('handling', 'large-scale', 'dataset'), ('large-scale', 'dataset', 'beginning'), ('dataset', 'beginning', 'early'), ('beginning', 'early', 'approaches'), ('early', 'approaches', 'attempted'), ('approaches', 'attempted', 'analyze'), ('attempted', 'analyze', 'data'), ('analyze', 'data', 'transaction'), ('data', 'transaction', 'data'), ('transaction', 'data', 'large'), ('data', 'large', 'shopping'), ('large', 'shopping', 'mall'), ('shopping', 'mall', '.')]

>> POS Tags are: 
 [('Frequent', 'JJ'), ('pattern', 'NN'), ('mining', 'VBG'), ('algorithms', 'NNS'), ('Most', 'JJS'), ('researches', 'NNS'), ('frequent', 'JJ'), ('pattern', 'JJ'), ('min-', 'JJ'), ('ing', 'NN'), ('(', '('), ('i.e.-', 'JJ'), (',', ','), ('association', 'NN'), ('rules', 'NNS'), ('sequential', 'JJ'), ('pattern', 'NN'), ('mining', 'NN'), (')', ')'), ('focused', 'VBD'), ('handling', 'VBG'), ('large-scale', 'JJ'), ('dataset', 'NN'), ('beginning', 'VBG'), ('early', 'JJ'), ('approaches', 'NNS'), ('attempted', 'VBD'), ('analyze', 'JJ'), ('data', 'NNS'), ('transaction', 'NN'), ('data', 'NNS'), ('large', 'JJ'), ('shopping', 'VBG'), ('mall', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Frequent pattern', 'algorithms', 'researches', 'frequent pattern min- ing', 'association rules', 'sequential pattern mining', 'large-scale dataset', 'early approaches', 'analyze data transaction data', 'mall']

>> Named Entities are: 
 [('GPE', 'Frequent')] 

>> Stemming using Porter Stemmer: 
 [('Frequent', 'frequent'), ('pattern', 'pattern'), ('mining', 'mine'), ('algorithms', 'algorithm'), ('Most', 'most'), ('researches', 'research'), ('frequent', 'frequent'), ('pattern', 'pattern'), ('min-', 'min-'), ('ing', 'ing'), ('(', '('), ('i.e.-', 'i.e.-'), (',', ','), ('association', 'associ'), ('rules', 'rule'), ('sequential', 'sequenti'), ('pattern', 'pattern'), ('mining', 'mine'), (')', ')'), ('focused', 'focus'), ('handling', 'handl'), ('large-scale', 'large-scal'), ('dataset', 'dataset'), ('beginning', 'begin'), ('early', 'earli'), ('approaches', 'approach'), ('attempted', 'attempt'), ('analyze', 'analyz'), ('data', 'data'), ('transaction', 'transact'), ('data', 'data'), ('large', 'larg'), ('shopping', 'shop'), ('mall', 'mall'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Frequent', 'frequent'), ('pattern', 'pattern'), ('mining', 'mine'), ('algorithms', 'algorithm'), ('Most', 'most'), ('researches', 'research'), ('frequent', 'frequent'), ('pattern', 'pattern'), ('min-', 'min-'), ('ing', 'ing'), ('(', '('), ('i.e.-', 'i.e.-'), (',', ','), ('association', 'associ'), ('rules', 'rule'), ('sequential', 'sequenti'), ('pattern', 'pattern'), ('mining', 'mine'), (')', ')'), ('focused', 'focus'), ('handling', 'handl'), ('large-scale', 'large-scal'), ('dataset', 'dataset'), ('beginning', 'begin'), ('early', 'earli'), ('approaches', 'approach'), ('attempted', 'attempt'), ('analyze', 'analyz'), ('data', 'data'), ('transaction', 'transact'), ('data', 'data'), ('large', 'larg'), ('shopping', 'shop'), ('mall', 'mall'), ('.', '.')]

>> Lemmatization: 
 [('Frequent', 'Frequent'), ('pattern', 'pattern'), ('mining', 'mining'), ('algorithms', 'algorithm'), ('Most', 'Most'), ('researches', 'research'), ('frequent', 'frequent'), ('pattern', 'pattern'), ('min-', 'min-'), ('ing', 'ing'), ('(', '('), ('i.e.-', 'i.e.-'), (',', ','), ('association', 'association'), ('rules', 'rule'), ('sequential', 'sequential'), ('pattern', 'pattern'), ('mining', 'mining'), (')', ')'), ('focused', 'focused'), ('handling', 'handling'), ('large-scale', 'large-scale'), ('dataset', 'dataset'), ('beginning', 'beginning'), ('early', 'early'), ('approaches', 'approach'), ('attempted', 'attempted'), ('analyze', 'analyze'), ('data', 'data'), ('transaction', 'transaction'), ('data', 'data'), ('large', 'large'), ('shopping', 'shopping'), ('mall', 'mall'), ('.', '.')]


------------------- Sentence 2 -------------------

Because  the number of transactions usually is more than “tens of thousands”, the issues about  how to handle the large scale data were studied for several years, such as FP-tree [32]  using the tree structure to include the frequent patterns to further reduce the compu- tation time of association rule mining.

>> Tokens are: 
 ['Because', 'number', 'transactions', 'usually', '“', 'tens', 'thousands', '”', ',', 'issues', 'handle', 'large', 'scale', 'data', 'studied', 'several', 'years', ',', 'FP-tree', '[', '32', ']', 'using', 'tree', 'structure', 'include', 'frequent', 'patterns', 'reduce', 'compu-', 'tation', 'time', 'association', 'rule', 'mining', '.']

>> Bigrams are: 
 [('Because', 'number'), ('number', 'transactions'), ('transactions', 'usually'), ('usually', '“'), ('“', 'tens'), ('tens', 'thousands'), ('thousands', '”'), ('”', ','), (',', 'issues'), ('issues', 'handle'), ('handle', 'large'), ('large', 'scale'), ('scale', 'data'), ('data', 'studied'), ('studied', 'several'), ('several', 'years'), ('years', ','), (',', 'FP-tree'), ('FP-tree', '['), ('[', '32'), ('32', ']'), (']', 'using'), ('using', 'tree'), ('tree', 'structure'), ('structure', 'include'), ('include', 'frequent'), ('frequent', 'patterns'), ('patterns', 'reduce'), ('reduce', 'compu-'), ('compu-', 'tation'), ('tation', 'time'), ('time', 'association'), ('association', 'rule'), ('rule', 'mining'), ('mining', '.')]

>> Trigrams are: 
 [('Because', 'number', 'transactions'), ('number', 'transactions', 'usually'), ('transactions', 'usually', '“'), ('usually', '“', 'tens'), ('“', 'tens', 'thousands'), ('tens', 'thousands', '”'), ('thousands', '”', ','), ('”', ',', 'issues'), (',', 'issues', 'handle'), ('issues', 'handle', 'large'), ('handle', 'large', 'scale'), ('large', 'scale', 'data'), ('scale', 'data', 'studied'), ('data', 'studied', 'several'), ('studied', 'several', 'years'), ('several', 'years', ','), ('years', ',', 'FP-tree'), (',', 'FP-tree', '['), ('FP-tree', '[', '32'), ('[', '32', ']'), ('32', ']', 'using'), (']', 'using', 'tree'), ('using', 'tree', 'structure'), ('tree', 'structure', 'include'), ('structure', 'include', 'frequent'), ('include', 'frequent', 'patterns'), ('frequent', 'patterns', 'reduce'), ('patterns', 'reduce', 'compu-'), ('reduce', 'compu-', 'tation'), ('compu-', 'tation', 'time'), ('tation', 'time', 'association'), ('time', 'association', 'rule'), ('association', 'rule', 'mining'), ('rule', 'mining', '.')]

>> POS Tags are: 
 [('Because', 'IN'), ('number', 'NN'), ('transactions', 'NNS'), ('usually', 'RB'), ('“', 'VBP'), ('tens', 'NNS'), ('thousands', 'NNS'), ('”', 'VBP'), (',', ','), ('issues', 'NNS'), ('handle', 'VBP'), ('large', 'JJ'), ('scale', 'NN'), ('data', 'NNS'), ('studied', 'VBD'), ('several', 'JJ'), ('years', 'NNS'), (',', ','), ('FP-tree', 'NNP'), ('[', 'NNP'), ('32', 'CD'), (']', 'NNP'), ('using', 'VBG'), ('tree', 'JJ'), ('structure', 'NN'), ('include', 'VBP'), ('frequent', 'JJ'), ('patterns', 'NNS'), ('reduce', 'VB'), ('compu-', 'JJ'), ('tation', 'NN'), ('time', 'NN'), ('association', 'NN'), ('rule', 'NN'), ('mining', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['number transactions', 'tens thousands', 'issues', 'large scale data', 'several years', 'FP-tree [', ']', 'tree structure', 'frequent patterns', 'compu- tation time association rule mining']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Because', 'becaus'), ('number', 'number'), ('transactions', 'transact'), ('usually', 'usual'), ('“', '“'), ('tens', 'ten'), ('thousands', 'thousand'), ('”', '”'), (',', ','), ('issues', 'issu'), ('handle', 'handl'), ('large', 'larg'), ('scale', 'scale'), ('data', 'data'), ('studied', 'studi'), ('several', 'sever'), ('years', 'year'), (',', ','), ('FP-tree', 'fp-tree'), ('[', '['), ('32', '32'), (']', ']'), ('using', 'use'), ('tree', 'tree'), ('structure', 'structur'), ('include', 'includ'), ('frequent', 'frequent'), ('patterns', 'pattern'), ('reduce', 'reduc'), ('compu-', 'compu-'), ('tation', 'tation'), ('time', 'time'), ('association', 'associ'), ('rule', 'rule'), ('mining', 'mine'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Because', 'becaus'), ('number', 'number'), ('transactions', 'transact'), ('usually', 'usual'), ('“', '“'), ('tens', 'ten'), ('thousands', 'thousand'), ('”', '”'), (',', ','), ('issues', 'issu'), ('handle', 'handl'), ('large', 'larg'), ('scale', 'scale'), ('data', 'data'), ('studied', 'studi'), ('several', 'sever'), ('years', 'year'), (',', ','), ('FP-tree', 'fp-tree'), ('[', '['), ('32', '32'), (']', ']'), ('using', 'use'), ('tree', 'tree'), ('structure', 'structur'), ('include', 'includ'), ('frequent', 'frequent'), ('patterns', 'pattern'), ('reduce', 'reduc'), ('compu-', 'compu-'), ('tation', 'tation'), ('time', 'time'), ('association', 'associ'), ('rule', 'rule'), ('mining', 'mine'), ('.', '.')]

>> Lemmatization: 
 [('Because', 'Because'), ('number', 'number'), ('transactions', 'transaction'), ('usually', 'usually'), ('“', '“'), ('tens', 'ten'), ('thousands', 'thousand'), ('”', '”'), (',', ','), ('issues', 'issue'), ('handle', 'handle'), ('large', 'large'), ('scale', 'scale'), ('data', 'data'), ('studied', 'studied'), ('several', 'several'), ('years', 'year'), (',', ','), ('FP-tree', 'FP-tree'), ('[', '['), ('32', '32'), (']', ']'), ('using', 'using'), ('tree', 'tree'), ('structure', 'structure'), ('include', 'include'), ('frequent', 'frequent'), ('patterns', 'pattern'), ('reduce', 'reduce'), ('compu-', 'compu-'), ('tation', 'tation'), ('time', 'time'), ('association', 'association'), ('rule', 'rule'), ('mining', 'mining'), ('.', '.')]


------------------- Sentence 3 -------------------

In addition to the traditional frequent pattern  mining algorithms, of course, parallel computing and cloud computing technologies  have also attracted researchers in this research domain.

>> Tokens are: 
 ['In', 'addition', 'traditional', 'frequent', 'pattern', 'mining', 'algorithms', ',', 'course', ',', 'parallel', 'computing', 'cloud', 'computing', 'technologies', 'also', 'attracted', 'researchers', 'research', 'domain', '.']

>> Bigrams are: 
 [('In', 'addition'), ('addition', 'traditional'), ('traditional', 'frequent'), ('frequent', 'pattern'), ('pattern', 'mining'), ('mining', 'algorithms'), ('algorithms', ','), (',', 'course'), ('course', ','), (',', 'parallel'), ('parallel', 'computing'), ('computing', 'cloud'), ('cloud', 'computing'), ('computing', 'technologies'), ('technologies', 'also'), ('also', 'attracted'), ('attracted', 'researchers'), ('researchers', 'research'), ('research', 'domain'), ('domain', '.')]

>> Trigrams are: 
 [('In', 'addition', 'traditional'), ('addition', 'traditional', 'frequent'), ('traditional', 'frequent', 'pattern'), ('frequent', 'pattern', 'mining'), ('pattern', 'mining', 'algorithms'), ('mining', 'algorithms', ','), ('algorithms', ',', 'course'), (',', 'course', ','), ('course', ',', 'parallel'), (',', 'parallel', 'computing'), ('parallel', 'computing', 'cloud'), ('computing', 'cloud', 'computing'), ('cloud', 'computing', 'technologies'), ('computing', 'technologies', 'also'), ('technologies', 'also', 'attracted'), ('also', 'attracted', 'researchers'), ('attracted', 'researchers', 'research'), ('researchers', 'research', 'domain'), ('research', 'domain', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('addition', 'NN'), ('traditional', 'JJ'), ('frequent', 'JJ'), ('pattern', 'NN'), ('mining', 'NN'), ('algorithms', 'NN'), (',', ','), ('course', 'NN'), (',', ','), ('parallel', 'JJ'), ('computing', 'VBG'), ('cloud', 'JJ'), ('computing', 'VBG'), ('technologies', 'NNS'), ('also', 'RB'), ('attracted', 'VBD'), ('researchers', 'NNS'), ('research', 'NN'), ('domain', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['addition', 'traditional frequent pattern mining algorithms', 'course', 'technologies', 'researchers research domain']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('addition', 'addit'), ('traditional', 'tradit'), ('frequent', 'frequent'), ('pattern', 'pattern'), ('mining', 'mine'), ('algorithms', 'algorithm'), (',', ','), ('course', 'cours'), (',', ','), ('parallel', 'parallel'), ('computing', 'comput'), ('cloud', 'cloud'), ('computing', 'comput'), ('technologies', 'technolog'), ('also', 'also'), ('attracted', 'attract'), ('researchers', 'research'), ('research', 'research'), ('domain', 'domain'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('addition', 'addit'), ('traditional', 'tradit'), ('frequent', 'frequent'), ('pattern', 'pattern'), ('mining', 'mine'), ('algorithms', 'algorithm'), (',', ','), ('course', 'cours'), (',', ','), ('parallel', 'parallel'), ('computing', 'comput'), ('cloud', 'cloud'), ('computing', 'comput'), ('technologies', 'technolog'), ('also', 'also'), ('attracted', 'attract'), ('researchers', 'research'), ('research', 'research'), ('domain', 'domain'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('addition', 'addition'), ('traditional', 'traditional'), ('frequent', 'frequent'), ('pattern', 'pattern'), ('mining', 'mining'), ('algorithms', 'algorithm'), (',', ','), ('course', 'course'), (',', ','), ('parallel', 'parallel'), ('computing', 'computing'), ('cloud', 'cloud'), ('computing', 'computing'), ('technologies', 'technology'), ('also', 'also'), ('attracted', 'attracted'), ('researchers', 'researcher'), ('research', 'research'), ('domain', 'domain'), ('.', '.')]


------------------- Sentence 4 -------------------

Among them, the map-reduce  solution was used for the studies [117–119] to enhance the performance of the frequent  pattern mining algorithm.

>> Tokens are: 
 ['Among', ',', 'map-reduce', 'solution', 'used', 'studies', '[', '117–119', ']', 'enhance', 'performance', 'frequent', 'pattern', 'mining', 'algorithm', '.']

>> Bigrams are: 
 [('Among', ','), (',', 'map-reduce'), ('map-reduce', 'solution'), ('solution', 'used'), ('used', 'studies'), ('studies', '['), ('[', '117–119'), ('117–119', ']'), (']', 'enhance'), ('enhance', 'performance'), ('performance', 'frequent'), ('frequent', 'pattern'), ('pattern', 'mining'), ('mining', 'algorithm'), ('algorithm', '.')]

>> Trigrams are: 
 [('Among', ',', 'map-reduce'), (',', 'map-reduce', 'solution'), ('map-reduce', 'solution', 'used'), ('solution', 'used', 'studies'), ('used', 'studies', '['), ('studies', '[', '117–119'), ('[', '117–119', ']'), ('117–119', ']', 'enhance'), (']', 'enhance', 'performance'), ('enhance', 'performance', 'frequent'), ('performance', 'frequent', 'pattern'), ('frequent', 'pattern', 'mining'), ('pattern', 'mining', 'algorithm'), ('mining', 'algorithm', '.')]

>> POS Tags are: 
 [('Among', 'IN'), (',', ','), ('map-reduce', 'JJ'), ('solution', 'NN'), ('used', 'VBN'), ('studies', 'NNS'), ('[', 'VBP'), ('117–119', 'CD'), (']', 'JJ'), ('enhance', 'NN'), ('performance', 'NN'), ('frequent', 'JJ'), ('pattern', 'NN'), ('mining', 'NN'), ('algorithm', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['map-reduce solution', 'studies', '] enhance performance', 'frequent pattern mining algorithm']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Among', 'among'), (',', ','), ('map-reduce', 'map-reduc'), ('solution', 'solut'), ('used', 'use'), ('studies', 'studi'), ('[', '['), ('117–119', '117–119'), (']', ']'), ('enhance', 'enhanc'), ('performance', 'perform'), ('frequent', 'frequent'), ('pattern', 'pattern'), ('mining', 'mine'), ('algorithm', 'algorithm'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Among', 'among'), (',', ','), ('map-reduce', 'map-reduc'), ('solution', 'solut'), ('used', 'use'), ('studies', 'studi'), ('[', '['), ('117–119', '117–119'), (']', ']'), ('enhance', 'enhanc'), ('performance', 'perform'), ('frequent', 'frequent'), ('pattern', 'pattern'), ('mining', 'mine'), ('algorithm', 'algorithm'), ('.', '.')]

>> Lemmatization: 
 [('Among', 'Among'), (',', ','), ('map-reduce', 'map-reduce'), ('solution', 'solution'), ('used', 'used'), ('studies', 'study'), ('[', '['), ('117–119', '117–119'), (']', ']'), ('enhance', 'enhance'), ('performance', 'performance'), ('frequent', 'frequent'), ('pattern', 'pattern'), ('mining', 'mining'), ('algorithm', 'algorithm'), ('.', '.')]


------------------- Sentence 5 -------------------

By using the map-reduce model for frequent pattern mining  algorithm, it can be easily expected that its application to “cloud platform” [120, 121] will  definitely become a popular trend in the forthcoming future.

>> Tokens are: 
 ['By', 'using', 'map-reduce', 'model', 'frequent', 'pattern', 'mining', 'algorithm', ',', 'easily', 'expected', 'application', '“', 'cloud', 'platform', '”', '[', '120', ',', '121', ']', 'definitely', 'become', 'popular', 'trend', 'forthcoming', 'future', '.']

>> Bigrams are: 
 [('By', 'using'), ('using', 'map-reduce'), ('map-reduce', 'model'), ('model', 'frequent'), ('frequent', 'pattern'), ('pattern', 'mining'), ('mining', 'algorithm'), ('algorithm', ','), (',', 'easily'), ('easily', 'expected'), ('expected', 'application'), ('application', '“'), ('“', 'cloud'), ('cloud', 'platform'), ('platform', '”'), ('”', '['), ('[', '120'), ('120', ','), (',', '121'), ('121', ']'), (']', 'definitely'), ('definitely', 'become'), ('become', 'popular'), ('popular', 'trend'), ('trend', 'forthcoming'), ('forthcoming', 'future'), ('future', '.')]

>> Trigrams are: 
 [('By', 'using', 'map-reduce'), ('using', 'map-reduce', 'model'), ('map-reduce', 'model', 'frequent'), ('model', 'frequent', 'pattern'), ('frequent', 'pattern', 'mining'), ('pattern', 'mining', 'algorithm'), ('mining', 'algorithm', ','), ('algorithm', ',', 'easily'), (',', 'easily', 'expected'), ('easily', 'expected', 'application'), ('expected', 'application', '“'), ('application', '“', 'cloud'), ('“', 'cloud', 'platform'), ('cloud', 'platform', '”'), ('platform', '”', '['), ('”', '[', '120'), ('[', '120', ','), ('120', ',', '121'), (',', '121', ']'), ('121', ']', 'definitely'), (']', 'definitely', 'become'), ('definitely', 'become', 'popular'), ('become', 'popular', 'trend'), ('popular', 'trend', 'forthcoming'), ('trend', 'forthcoming', 'future'), ('forthcoming', 'future', '.')]

>> POS Tags are: 
 [('By', 'IN'), ('using', 'VBG'), ('map-reduce', 'JJ'), ('model', 'NN'), ('frequent', 'JJ'), ('pattern', 'NN'), ('mining', 'NN'), ('algorithm', 'NN'), (',', ','), ('easily', 'RB'), ('expected', 'VBN'), ('application', 'NN'), ('“', 'NNP'), ('cloud', 'NN'), ('platform', 'NN'), ('”', 'NNP'), ('[', 'NNP'), ('120', 'CD'), (',', ','), ('121', 'CD'), (']', 'NN'), ('definitely', 'RB'), ('become', 'VBN'), ('popular', 'JJ'), ('trend', 'NN'), ('forthcoming', 'JJ'), ('future', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['map-reduce model', 'frequent pattern mining algorithm', 'application “ cloud platform ” [', ']', 'popular trend', 'forthcoming future']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('By', 'by'), ('using', 'use'), ('map-reduce', 'map-reduc'), ('model', 'model'), ('frequent', 'frequent'), ('pattern', 'pattern'), ('mining', 'mine'), ('algorithm', 'algorithm'), (',', ','), ('easily', 'easili'), ('expected', 'expect'), ('application', 'applic'), ('“', '“'), ('cloud', 'cloud'), ('platform', 'platform'), ('”', '”'), ('[', '['), ('120', '120'), (',', ','), ('121', '121'), (']', ']'), ('definitely', 'definit'), ('become', 'becom'), ('popular', 'popular'), ('trend', 'trend'), ('forthcoming', 'forthcom'), ('future', 'futur'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('By', 'by'), ('using', 'use'), ('map-reduce', 'map-reduc'), ('model', 'model'), ('frequent', 'frequent'), ('pattern', 'pattern'), ('mining', 'mine'), ('algorithm', 'algorithm'), (',', ','), ('easily', 'easili'), ('expected', 'expect'), ('application', 'applic'), ('“', '“'), ('cloud', 'cloud'), ('platform', 'platform'), ('”', '”'), ('[', '['), ('120', '120'), (',', ','), ('121', '121'), (']', ']'), ('definitely', 'definit'), ('become', 'becom'), ('popular', 'popular'), ('trend', 'trend'), ('forthcoming', 'forthcom'), ('future', 'futur'), ('.', '.')]

>> Lemmatization: 
 [('By', 'By'), ('using', 'using'), ('map-reduce', 'map-reduce'), ('model', 'model'), ('frequent', 'frequent'), ('pattern', 'pattern'), ('mining', 'mining'), ('algorithm', 'algorithm'), (',', ','), ('easily', 'easily'), ('expected', 'expected'), ('application', 'application'), ('“', '“'), ('cloud', 'cloud'), ('platform', 'platform'), ('”', '”'), ('[', '['), ('120', '120'), (',', ','), ('121', '121'), (']', ']'), ('definitely', 'definitely'), ('become', 'become'), ('popular', 'popular'), ('trend', 'trend'), ('forthcoming', 'forthcoming'), ('future', 'future'), ('.', '.')]


------------------- Sentence 6 -------------------

The study of [119] no only  used the map-reduce model, it also allowed users to express their specific interest con- straints in the process of frequent pattern mining.

>> Tokens are: 
 ['The', 'study', '[', '119', ']', 'used', 'map-reduce', 'model', ',', 'also', 'allowed', 'users', 'express', 'specific', 'interest', 'con-', 'straints', 'process', 'frequent', 'pattern', 'mining', '.']

>> Bigrams are: 
 [('The', 'study'), ('study', '['), ('[', '119'), ('119', ']'), (']', 'used'), ('used', 'map-reduce'), ('map-reduce', 'model'), ('model', ','), (',', 'also'), ('also', 'allowed'), ('allowed', 'users'), ('users', 'express'), ('express', 'specific'), ('specific', 'interest'), ('interest', 'con-'), ('con-', 'straints'), ('straints', 'process'), ('process', 'frequent'), ('frequent', 'pattern'), ('pattern', 'mining'), ('mining', '.')]

>> Trigrams are: 
 [('The', 'study', '['), ('study', '[', '119'), ('[', '119', ']'), ('119', ']', 'used'), (']', 'used', 'map-reduce'), ('used', 'map-reduce', 'model'), ('map-reduce', 'model', ','), ('model', ',', 'also'), (',', 'also', 'allowed'), ('also', 'allowed', 'users'), ('allowed', 'users', 'express'), ('users', 'express', 'specific'), ('express', 'specific', 'interest'), ('specific', 'interest', 'con-'), ('interest', 'con-', 'straints'), ('con-', 'straints', 'process'), ('straints', 'process', 'frequent'), ('process', 'frequent', 'pattern'), ('frequent', 'pattern', 'mining'), ('pattern', 'mining', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('study', 'NN'), ('[', 'VBD'), ('119', 'CD'), (']', 'NNS'), ('used', 'VBN'), ('map-reduce', 'JJ'), ('model', 'NN'), (',', ','), ('also', 'RB'), ('allowed', 'VBN'), ('users', 'NNS'), ('express', 'RBR'), ('specific', 'JJ'), ('interest', 'NN'), ('con-', 'JJ'), ('straints', 'NNS'), ('process', 'JJ'), ('frequent', 'JJ'), ('pattern', 'NN'), ('mining', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['The study', ']', 'map-reduce model', 'users', 'specific interest', 'con- straints', 'process frequent pattern mining']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('study', 'studi'), ('[', '['), ('119', '119'), (']', ']'), ('used', 'use'), ('map-reduce', 'map-reduc'), ('model', 'model'), (',', ','), ('also', 'also'), ('allowed', 'allow'), ('users', 'user'), ('express', 'express'), ('specific', 'specif'), ('interest', 'interest'), ('con-', 'con-'), ('straints', 'straint'), ('process', 'process'), ('frequent', 'frequent'), ('pattern', 'pattern'), ('mining', 'mine'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('study', 'studi'), ('[', '['), ('119', '119'), (']', ']'), ('used', 'use'), ('map-reduce', 'map-reduc'), ('model', 'model'), (',', ','), ('also', 'also'), ('allowed', 'allow'), ('users', 'user'), ('express', 'express'), ('specific', 'specif'), ('interest', 'interest'), ('con-', 'con-'), ('straints', 'straint'), ('process', 'process'), ('frequent', 'frequent'), ('pattern', 'pattern'), ('mining', 'mine'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('study', 'study'), ('[', '['), ('119', '119'), (']', ']'), ('used', 'used'), ('map-reduce', 'map-reduce'), ('model', 'model'), (',', ','), ('also', 'also'), ('allowed', 'allowed'), ('users', 'user'), ('express', 'express'), ('specific', 'specific'), ('interest', 'interest'), ('con-', 'con-'), ('straints', 'straints'), ('process', 'process'), ('frequent', 'frequent'), ('pattern', 'pattern'), ('mining', 'mining'), ('.', '.')]


------------------- Sentence 7 -------------------

The performance of these methods  by using map-reduce model for big data analysis is, no doubt, better than the traditional  frequent pattern mining algorithms running on a single machine.

>> Tokens are: 
 ['The', 'performance', 'methods', 'using', 'map-reduce', 'model', 'big', 'data', 'analysis', ',', 'doubt', ',', 'better', 'traditional', 'frequent', 'pattern', 'mining', 'algorithms', 'running', 'single', 'machine', '.']

>> Bigrams are: 
 [('The', 'performance'), ('performance', 'methods'), ('methods', 'using'), ('using', 'map-reduce'), ('map-reduce', 'model'), ('model', 'big'), ('big', 'data'), ('data', 'analysis'), ('analysis', ','), (',', 'doubt'), ('doubt', ','), (',', 'better'), ('better', 'traditional'), ('traditional', 'frequent'), ('frequent', 'pattern'), ('pattern', 'mining'), ('mining', 'algorithms'), ('algorithms', 'running'), ('running', 'single'), ('single', 'machine'), ('machine', '.')]

>> Trigrams are: 
 [('The', 'performance', 'methods'), ('performance', 'methods', 'using'), ('methods', 'using', 'map-reduce'), ('using', 'map-reduce', 'model'), ('map-reduce', 'model', 'big'), ('model', 'big', 'data'), ('big', 'data', 'analysis'), ('data', 'analysis', ','), ('analysis', ',', 'doubt'), (',', 'doubt', ','), ('doubt', ',', 'better'), (',', 'better', 'traditional'), ('better', 'traditional', 'frequent'), ('traditional', 'frequent', 'pattern'), ('frequent', 'pattern', 'mining'), ('pattern', 'mining', 'algorithms'), ('mining', 'algorithms', 'running'), ('algorithms', 'running', 'single'), ('running', 'single', 'machine'), ('single', 'machine', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('performance', 'NN'), ('methods', 'NNS'), ('using', 'VBG'), ('map-reduce', 'JJ'), ('model', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('analysis', 'NN'), (',', ','), ('doubt', 'NN'), (',', ','), ('better', 'JJR'), ('traditional', 'JJ'), ('frequent', 'JJ'), ('pattern', 'NN'), ('mining', 'NN'), ('algorithms', 'NN'), ('running', 'VBG'), ('single', 'JJ'), ('machine', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['The performance methods', 'map-reduce model', 'big data analysis', 'doubt', 'traditional frequent pattern mining algorithms', 'single machine']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('performance', 'perform'), ('methods', 'method'), ('using', 'use'), ('map-reduce', 'map-reduc'), ('model', 'model'), ('big', 'big'), ('data', 'data'), ('analysis', 'analysi'), (',', ','), ('doubt', 'doubt'), (',', ','), ('better', 'better'), ('traditional', 'tradit'), ('frequent', 'frequent'), ('pattern', 'pattern'), ('mining', 'mine'), ('algorithms', 'algorithm'), ('running', 'run'), ('single', 'singl'), ('machine', 'machin'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('performance', 'perform'), ('methods', 'method'), ('using', 'use'), ('map-reduce', 'map-reduc'), ('model', 'model'), ('big', 'big'), ('data', 'data'), ('analysis', 'analysi'), (',', ','), ('doubt', 'doubt'), (',', ','), ('better', 'better'), ('traditional', 'tradit'), ('frequent', 'frequent'), ('pattern', 'pattern'), ('mining', 'mine'), ('algorithms', 'algorithm'), ('running', 'run'), ('single', 'singl'), ('machine', 'machin'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('performance', 'performance'), ('methods', 'method'), ('using', 'using'), ('map-reduce', 'map-reduce'), ('model', 'model'), ('big', 'big'), ('data', 'data'), ('analysis', 'analysis'), (',', ','), ('doubt', 'doubt'), (',', ','), ('better', 'better'), ('traditional', 'traditional'), ('frequent', 'frequent'), ('pattern', 'pattern'), ('mining', 'mining'), ('algorithms', 'algorithm'), ('running', 'running'), ('single', 'single'), ('machine', 'machine'), ('.', '.')]



========================================== PARAGRAPH 265 ===========================================

5 The learner typically represented the classification function which will create the classifier to help us classify the  unknown input data.

------------------- Sentence 1 -------------------

5 The learner typically represented the classification function which will create the classifier to help us classify the  unknown input data.

>> Tokens are: 
 ['5', 'The', 'learner', 'typically', 'represented', 'classification', 'function', 'create', 'classifier', 'help', 'us', 'classify', 'unknown', 'input', 'data', '.']

>> Bigrams are: 
 [('5', 'The'), ('The', 'learner'), ('learner', 'typically'), ('typically', 'represented'), ('represented', 'classification'), ('classification', 'function'), ('function', 'create'), ('create', 'classifier'), ('classifier', 'help'), ('help', 'us'), ('us', 'classify'), ('classify', 'unknown'), ('unknown', 'input'), ('input', 'data'), ('data', '.')]

>> Trigrams are: 
 [('5', 'The', 'learner'), ('The', 'learner', 'typically'), ('learner', 'typically', 'represented'), ('typically', 'represented', 'classification'), ('represented', 'classification', 'function'), ('classification', 'function', 'create'), ('function', 'create', 'classifier'), ('create', 'classifier', 'help'), ('classifier', 'help', 'us'), ('help', 'us', 'classify'), ('us', 'classify', 'unknown'), ('classify', 'unknown', 'input'), ('unknown', 'input', 'data'), ('input', 'data', '.')]

>> POS Tags are: 
 [('5', 'CD'), ('The', 'DT'), ('learner', 'NN'), ('typically', 'RB'), ('represented', 'VBN'), ('classification', 'NN'), ('function', 'NN'), ('create', 'NN'), ('classifier', 'NN'), ('help', 'VBP'), ('us', 'PRP'), ('classify', 'VB'), ('unknown', 'JJ'), ('input', 'NN'), ('data', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['The learner', 'classification function create classifier', 'unknown input data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('5', '5'), ('The', 'the'), ('learner', 'learner'), ('typically', 'typic'), ('represented', 'repres'), ('classification', 'classif'), ('function', 'function'), ('create', 'creat'), ('classifier', 'classifi'), ('help', 'help'), ('us', 'us'), ('classify', 'classifi'), ('unknown', 'unknown'), ('input', 'input'), ('data', 'data'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('5', '5'), ('The', 'the'), ('learner', 'learner'), ('typically', 'typic'), ('represented', 'repres'), ('classification', 'classif'), ('function', 'function'), ('create', 'creat'), ('classifier', 'classifi'), ('help', 'help'), ('us', 'us'), ('classify', 'classifi'), ('unknown', 'unknown'), ('input', 'input'), ('data', 'data'), ('.', '.')]

>> Lemmatization: 
 [('5', '5'), ('The', 'The'), ('learner', 'learner'), ('typically', 'typically'), ('represented', 'represented'), ('classification', 'classification'), ('function', 'function'), ('create', 'create'), ('classifier', 'classifier'), ('help', 'help'), ('us', 'u'), ('classify', 'classify'), ('unknown', 'unknown'), ('input', 'input'), ('data', 'data'), ('.', '.')]



========================================== PARAGRAPH 266 ===========================================

Page 18 of 32Tsai et al. Journal of Big Data  (2015) 2:21  

------------------- Sentence 1 -------------------

Page 18 of 32Tsai et al.

>> Tokens are: 
 ['Page', '18', '32Tsai', 'et', 'al', '.']

>> Bigrams are: 
 [('Page', '18'), ('18', '32Tsai'), ('32Tsai', 'et'), ('et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('Page', '18', '32Tsai'), ('18', '32Tsai', 'et'), ('32Tsai', 'et', 'al'), ('et', 'al', '.')]

>> POS Tags are: 
 [('Page', 'NN'), ('18', 'CD'), ('32Tsai', 'CD'), ('et', 'NN'), ('al', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Page', 'et al']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Page', 'page'), ('18', '18'), ('32Tsai', '32tsai'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Page', 'page'), ('18', '18'), ('32Tsai', '32tsai'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('Page', 'Page'), ('18', '18'), ('32Tsai', '32Tsai'), ('et', 'et'), ('al', 'al'), ('.', '.')]


------------------- Sentence 2 -------------------

Journal of Big Data  (2015) 2:21

>> Tokens are: 
 ['Journal', 'Big', 'Data', '(', '2015', ')', '2:21']

>> Bigrams are: 
 [('Journal', 'Big'), ('Big', 'Data'), ('Data', '('), ('(', '2015'), ('2015', ')'), (')', '2:21')]

>> Trigrams are: 
 [('Journal', 'Big', 'Data'), ('Big', 'Data', '('), ('Data', '(', '2015'), ('(', '2015', ')'), ('2015', ')', '2:21')]

>> POS Tags are: 
 [('Journal', 'NNP'), ('Big', 'NNP'), ('Data', 'NNP'), ('(', '('), ('2015', 'CD'), (')', ')'), ('2:21', 'CD')]

>> Noun Phrases are: 
 ['Journal Big Data']

>> Named Entities are: 
 [('PERSON', 'Journal')] 

>> Stemming using Porter Stemmer: 
 [('Journal', 'journal'), ('Big', 'big'), ('Data', 'data'), ('(', '('), ('2015', '2015'), (')', ')'), ('2:21', '2:21')]

>> Stemming using Snowball Stemmer: 
 [('Journal', 'journal'), ('Big', 'big'), ('Data', 'data'), ('(', '('), ('2015', '2015'), (')', ')'), ('2:21', '2:21')]

>> Lemmatization: 
 [('Journal', 'Journal'), ('Big', 'Big'), ('Data', 'Data'), ('(', '('), ('2015', '2015'), (')', ')'), ('2:21', '2:21')]



========================================== PARAGRAPH 267 ===========================================

Machine learning for big data mining 

------------------- Sentence 1 -------------------

Machine learning for big data mining

>> Tokens are: 
 ['Machine', 'learning', 'big', 'data', 'mining']

>> Bigrams are: 
 [('Machine', 'learning'), ('learning', 'big'), ('big', 'data'), ('data', 'mining')]

>> Trigrams are: 
 [('Machine', 'learning', 'big'), ('learning', 'big', 'data'), ('big', 'data', 'mining')]

>> POS Tags are: 
 [('Machine', 'NN'), ('learning', 'VBG'), ('big', 'JJ'), ('data', 'NNS'), ('mining', 'NN')]

>> Noun Phrases are: 
 ['Machine', 'big data mining']

>> Named Entities are: 
 [('GPE', 'Machine')] 

>> Stemming using Porter Stemmer: 
 [('Machine', 'machin'), ('learning', 'learn'), ('big', 'big'), ('data', 'data'), ('mining', 'mine')]

>> Stemming using Snowball Stemmer: 
 [('Machine', 'machin'), ('learning', 'learn'), ('big', 'big'), ('data', 'data'), ('mining', 'mine')]

>> Lemmatization: 
 [('Machine', 'Machine'), ('learning', 'learning'), ('big', 'big'), ('data', 'data'), ('mining', 'mining')]



========================================== PARAGRAPH 268 ===========================================

The potential of machine learning for data analytics can be easily found in the early lit- erature [22, 49]. Different from the data mining algorithm design for specific problems,  machine learning algorithms can be used for different mining and analysis problems  because they are typically employed as the “search” algorithm of the required solution.  Since most machine learning algorithms can be used to find an approximate solution  for the optimization problem, they can be employed for most data analysis problems if  the data analysis problems can be formulated as an optimization problem. For exam- ple, genetic algorithm, one of the machine learning algorithms, can not only be used to  solve the clustering problem [25], it can also be used to solve the frequent pattern min- ing problem [33]. The potential of machine learning is not merely for solving different  mining problems in data analysis operator of KDD; it also has the potential of enhanc- ing the performance of the other parts of KDD, such as feature reduction for the input  operators [72]. 

------------------- Sentence 1 -------------------

The potential of machine learning for data analytics can be easily found in the early lit- erature [22, 49].

>> Tokens are: 
 ['The', 'potential', 'machine', 'learning', 'data', 'analytics', 'easily', 'found', 'early', 'lit-', 'erature', '[', '22', ',', '49', ']', '.']

>> Bigrams are: 
 [('The', 'potential'), ('potential', 'machine'), ('machine', 'learning'), ('learning', 'data'), ('data', 'analytics'), ('analytics', 'easily'), ('easily', 'found'), ('found', 'early'), ('early', 'lit-'), ('lit-', 'erature'), ('erature', '['), ('[', '22'), ('22', ','), (',', '49'), ('49', ']'), (']', '.')]

>> Trigrams are: 
 [('The', 'potential', 'machine'), ('potential', 'machine', 'learning'), ('machine', 'learning', 'data'), ('learning', 'data', 'analytics'), ('data', 'analytics', 'easily'), ('analytics', 'easily', 'found'), ('easily', 'found', 'early'), ('found', 'early', 'lit-'), ('early', 'lit-', 'erature'), ('lit-', 'erature', '['), ('erature', '[', '22'), ('[', '22', ','), ('22', ',', '49'), (',', '49', ']'), ('49', ']', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('potential', 'JJ'), ('machine', 'NN'), ('learning', 'VBG'), ('data', 'NNS'), ('analytics', 'NNS'), ('easily', 'RB'), ('found', 'VBD'), ('early', 'JJ'), ('lit-', 'JJ'), ('erature', 'NN'), ('[', 'VBZ'), ('22', 'CD'), (',', ','), ('49', 'CD'), (']', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['The potential machine', 'data analytics', 'early lit- erature', ']']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('potential', 'potenti'), ('machine', 'machin'), ('learning', 'learn'), ('data', 'data'), ('analytics', 'analyt'), ('easily', 'easili'), ('found', 'found'), ('early', 'earli'), ('lit-', 'lit-'), ('erature', 'eratur'), ('[', '['), ('22', '22'), (',', ','), ('49', '49'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('potential', 'potenti'), ('machine', 'machin'), ('learning', 'learn'), ('data', 'data'), ('analytics', 'analyt'), ('easily', 'easili'), ('found', 'found'), ('early', 'earli'), ('lit-', 'lit-'), ('erature', 'eratur'), ('[', '['), ('22', '22'), (',', ','), ('49', '49'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('potential', 'potential'), ('machine', 'machine'), ('learning', 'learning'), ('data', 'data'), ('analytics', 'analytics'), ('easily', 'easily'), ('found', 'found'), ('early', 'early'), ('lit-', 'lit-'), ('erature', 'erature'), ('[', '['), ('22', '22'), (',', ','), ('49', '49'), (']', ']'), ('.', '.')]


------------------- Sentence 2 -------------------

Different from the data mining algorithm design for specific problems,  machine learning algorithms can be used for different mining and analysis problems  because they are typically employed as the “search” algorithm of the required solution.

>> Tokens are: 
 ['Different', 'data', 'mining', 'algorithm', 'design', 'specific', 'problems', ',', 'machine', 'learning', 'algorithms', 'used', 'different', 'mining', 'analysis', 'problems', 'typically', 'employed', '“', 'search', '”', 'algorithm', 'required', 'solution', '.']

>> Bigrams are: 
 [('Different', 'data'), ('data', 'mining'), ('mining', 'algorithm'), ('algorithm', 'design'), ('design', 'specific'), ('specific', 'problems'), ('problems', ','), (',', 'machine'), ('machine', 'learning'), ('learning', 'algorithms'), ('algorithms', 'used'), ('used', 'different'), ('different', 'mining'), ('mining', 'analysis'), ('analysis', 'problems'), ('problems', 'typically'), ('typically', 'employed'), ('employed', '“'), ('“', 'search'), ('search', '”'), ('”', 'algorithm'), ('algorithm', 'required'), ('required', 'solution'), ('solution', '.')]

>> Trigrams are: 
 [('Different', 'data', 'mining'), ('data', 'mining', 'algorithm'), ('mining', 'algorithm', 'design'), ('algorithm', 'design', 'specific'), ('design', 'specific', 'problems'), ('specific', 'problems', ','), ('problems', ',', 'machine'), (',', 'machine', 'learning'), ('machine', 'learning', 'algorithms'), ('learning', 'algorithms', 'used'), ('algorithms', 'used', 'different'), ('used', 'different', 'mining'), ('different', 'mining', 'analysis'), ('mining', 'analysis', 'problems'), ('analysis', 'problems', 'typically'), ('problems', 'typically', 'employed'), ('typically', 'employed', '“'), ('employed', '“', 'search'), ('“', 'search', '”'), ('search', '”', 'algorithm'), ('”', 'algorithm', 'required'), ('algorithm', 'required', 'solution'), ('required', 'solution', '.')]

>> POS Tags are: 
 [('Different', 'NNP'), ('data', 'NNS'), ('mining', 'NN'), ('algorithm', 'NN'), ('design', 'NN'), ('specific', 'JJ'), ('problems', 'NNS'), (',', ','), ('machine', 'NN'), ('learning', 'NN'), ('algorithms', 'VBP'), ('used', 'VBN'), ('different', 'JJ'), ('mining', 'NN'), ('analysis', 'NN'), ('problems', 'NNS'), ('typically', 'RB'), ('employed', 'VBN'), ('“', 'NNP'), ('search', 'NN'), ('”', 'NNP'), ('algorithm', 'NN'), ('required', 'VBN'), ('solution', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Different data mining algorithm design', 'specific problems', 'machine learning', 'different mining analysis problems', '“ search ” algorithm', 'solution']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Different', 'differ'), ('data', 'data'), ('mining', 'mine'), ('algorithm', 'algorithm'), ('design', 'design'), ('specific', 'specif'), ('problems', 'problem'), (',', ','), ('machine', 'machin'), ('learning', 'learn'), ('algorithms', 'algorithm'), ('used', 'use'), ('different', 'differ'), ('mining', 'mine'), ('analysis', 'analysi'), ('problems', 'problem'), ('typically', 'typic'), ('employed', 'employ'), ('“', '“'), ('search', 'search'), ('”', '”'), ('algorithm', 'algorithm'), ('required', 'requir'), ('solution', 'solut'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Different', 'differ'), ('data', 'data'), ('mining', 'mine'), ('algorithm', 'algorithm'), ('design', 'design'), ('specific', 'specif'), ('problems', 'problem'), (',', ','), ('machine', 'machin'), ('learning', 'learn'), ('algorithms', 'algorithm'), ('used', 'use'), ('different', 'differ'), ('mining', 'mine'), ('analysis', 'analysi'), ('problems', 'problem'), ('typically', 'typic'), ('employed', 'employ'), ('“', '“'), ('search', 'search'), ('”', '”'), ('algorithm', 'algorithm'), ('required', 'requir'), ('solution', 'solut'), ('.', '.')]

>> Lemmatization: 
 [('Different', 'Different'), ('data', 'data'), ('mining', 'mining'), ('algorithm', 'algorithm'), ('design', 'design'), ('specific', 'specific'), ('problems', 'problem'), (',', ','), ('machine', 'machine'), ('learning', 'learning'), ('algorithms', 'algorithm'), ('used', 'used'), ('different', 'different'), ('mining', 'mining'), ('analysis', 'analysis'), ('problems', 'problem'), ('typically', 'typically'), ('employed', 'employed'), ('“', '“'), ('search', 'search'), ('”', '”'), ('algorithm', 'algorithm'), ('required', 'required'), ('solution', 'solution'), ('.', '.')]


------------------- Sentence 3 -------------------

Since most machine learning algorithms can be used to find an approximate solution  for the optimization problem, they can be employed for most data analysis problems if  the data analysis problems can be formulated as an optimization problem.

>> Tokens are: 
 ['Since', 'machine', 'learning', 'algorithms', 'used', 'find', 'approximate', 'solution', 'optimization', 'problem', ',', 'employed', 'data', 'analysis', 'problems', 'data', 'analysis', 'problems', 'formulated', 'optimization', 'problem', '.']

>> Bigrams are: 
 [('Since', 'machine'), ('machine', 'learning'), ('learning', 'algorithms'), ('algorithms', 'used'), ('used', 'find'), ('find', 'approximate'), ('approximate', 'solution'), ('solution', 'optimization'), ('optimization', 'problem'), ('problem', ','), (',', 'employed'), ('employed', 'data'), ('data', 'analysis'), ('analysis', 'problems'), ('problems', 'data'), ('data', 'analysis'), ('analysis', 'problems'), ('problems', 'formulated'), ('formulated', 'optimization'), ('optimization', 'problem'), ('problem', '.')]

>> Trigrams are: 
 [('Since', 'machine', 'learning'), ('machine', 'learning', 'algorithms'), ('learning', 'algorithms', 'used'), ('algorithms', 'used', 'find'), ('used', 'find', 'approximate'), ('find', 'approximate', 'solution'), ('approximate', 'solution', 'optimization'), ('solution', 'optimization', 'problem'), ('optimization', 'problem', ','), ('problem', ',', 'employed'), (',', 'employed', 'data'), ('employed', 'data', 'analysis'), ('data', 'analysis', 'problems'), ('analysis', 'problems', 'data'), ('problems', 'data', 'analysis'), ('data', 'analysis', 'problems'), ('analysis', 'problems', 'formulated'), ('problems', 'formulated', 'optimization'), ('formulated', 'optimization', 'problem'), ('optimization', 'problem', '.')]

>> POS Tags are: 
 [('Since', 'IN'), ('machine', 'NN'), ('learning', 'NN'), ('algorithms', 'NN'), ('used', 'VBN'), ('find', 'VB'), ('approximate', 'JJ'), ('solution', 'NN'), ('optimization', 'NN'), ('problem', 'NN'), (',', ','), ('employed', 'VBN'), ('data', 'NNS'), ('analysis', 'NN'), ('problems', 'NNS'), ('data', 'VBP'), ('analysis', 'NN'), ('problems', 'NNS'), ('formulated', 'VBN'), ('optimization', 'NN'), ('problem', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['machine learning algorithms', 'approximate solution optimization problem', 'data analysis problems', 'analysis problems', 'optimization problem']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Since', 'sinc'), ('machine', 'machin'), ('learning', 'learn'), ('algorithms', 'algorithm'), ('used', 'use'), ('find', 'find'), ('approximate', 'approxim'), ('solution', 'solut'), ('optimization', 'optim'), ('problem', 'problem'), (',', ','), ('employed', 'employ'), ('data', 'data'), ('analysis', 'analysi'), ('problems', 'problem'), ('data', 'data'), ('analysis', 'analysi'), ('problems', 'problem'), ('formulated', 'formul'), ('optimization', 'optim'), ('problem', 'problem'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Since', 'sinc'), ('machine', 'machin'), ('learning', 'learn'), ('algorithms', 'algorithm'), ('used', 'use'), ('find', 'find'), ('approximate', 'approxim'), ('solution', 'solut'), ('optimization', 'optim'), ('problem', 'problem'), (',', ','), ('employed', 'employ'), ('data', 'data'), ('analysis', 'analysi'), ('problems', 'problem'), ('data', 'data'), ('analysis', 'analysi'), ('problems', 'problem'), ('formulated', 'formul'), ('optimization', 'optim'), ('problem', 'problem'), ('.', '.')]

>> Lemmatization: 
 [('Since', 'Since'), ('machine', 'machine'), ('learning', 'learning'), ('algorithms', 'algorithm'), ('used', 'used'), ('find', 'find'), ('approximate', 'approximate'), ('solution', 'solution'), ('optimization', 'optimization'), ('problem', 'problem'), (',', ','), ('employed', 'employed'), ('data', 'data'), ('analysis', 'analysis'), ('problems', 'problem'), ('data', 'data'), ('analysis', 'analysis'), ('problems', 'problem'), ('formulated', 'formulated'), ('optimization', 'optimization'), ('problem', 'problem'), ('.', '.')]


------------------- Sentence 4 -------------------

For exam- ple, genetic algorithm, one of the machine learning algorithms, can not only be used to  solve the clustering problem [25], it can also be used to solve the frequent pattern min- ing problem [33].

>> Tokens are: 
 ['For', 'exam-', 'ple', ',', 'genetic', 'algorithm', ',', 'one', 'machine', 'learning', 'algorithms', ',', 'used', 'solve', 'clustering', 'problem', '[', '25', ']', ',', 'also', 'used', 'solve', 'frequent', 'pattern', 'min-', 'ing', 'problem', '[', '33', ']', '.']

>> Bigrams are: 
 [('For', 'exam-'), ('exam-', 'ple'), ('ple', ','), (',', 'genetic'), ('genetic', 'algorithm'), ('algorithm', ','), (',', 'one'), ('one', 'machine'), ('machine', 'learning'), ('learning', 'algorithms'), ('algorithms', ','), (',', 'used'), ('used', 'solve'), ('solve', 'clustering'), ('clustering', 'problem'), ('problem', '['), ('[', '25'), ('25', ']'), (']', ','), (',', 'also'), ('also', 'used'), ('used', 'solve'), ('solve', 'frequent'), ('frequent', 'pattern'), ('pattern', 'min-'), ('min-', 'ing'), ('ing', 'problem'), ('problem', '['), ('[', '33'), ('33', ']'), (']', '.')]

>> Trigrams are: 
 [('For', 'exam-', 'ple'), ('exam-', 'ple', ','), ('ple', ',', 'genetic'), (',', 'genetic', 'algorithm'), ('genetic', 'algorithm', ','), ('algorithm', ',', 'one'), (',', 'one', 'machine'), ('one', 'machine', 'learning'), ('machine', 'learning', 'algorithms'), ('learning', 'algorithms', ','), ('algorithms', ',', 'used'), (',', 'used', 'solve'), ('used', 'solve', 'clustering'), ('solve', 'clustering', 'problem'), ('clustering', 'problem', '['), ('problem', '[', '25'), ('[', '25', ']'), ('25', ']', ','), (']', ',', 'also'), (',', 'also', 'used'), ('also', 'used', 'solve'), ('used', 'solve', 'frequent'), ('solve', 'frequent', 'pattern'), ('frequent', 'pattern', 'min-'), ('pattern', 'min-', 'ing'), ('min-', 'ing', 'problem'), ('ing', 'problem', '['), ('problem', '[', '33'), ('[', '33', ']'), ('33', ']', '.')]

>> POS Tags are: 
 [('For', 'IN'), ('exam-', 'JJ'), ('ple', 'NN'), (',', ','), ('genetic', 'JJ'), ('algorithm', 'NN'), (',', ','), ('one', 'CD'), ('machine', 'NN'), ('learning', 'NN'), ('algorithms', 'NN'), (',', ','), ('used', 'VBD'), ('solve', 'NN'), ('clustering', 'VBG'), ('problem', 'NN'), ('[', '$'), ('25', 'CD'), (']', 'NN'), (',', ','), ('also', 'RB'), ('used', 'VBD'), ('solve', 'VB'), ('frequent', 'JJ'), ('pattern', 'JJ'), ('min-', 'JJ'), ('ing', 'NN'), ('problem', 'NN'), ('[', 'VBZ'), ('33', 'CD'), (']', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['exam- ple', 'genetic algorithm', 'machine learning algorithms', 'solve', 'problem', ']', 'frequent pattern min- ing problem', ']']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('For', 'for'), ('exam-', 'exam-'), ('ple', 'ple'), (',', ','), ('genetic', 'genet'), ('algorithm', 'algorithm'), (',', ','), ('one', 'one'), ('machine', 'machin'), ('learning', 'learn'), ('algorithms', 'algorithm'), (',', ','), ('used', 'use'), ('solve', 'solv'), ('clustering', 'cluster'), ('problem', 'problem'), ('[', '['), ('25', '25'), (']', ']'), (',', ','), ('also', 'also'), ('used', 'use'), ('solve', 'solv'), ('frequent', 'frequent'), ('pattern', 'pattern'), ('min-', 'min-'), ('ing', 'ing'), ('problem', 'problem'), ('[', '['), ('33', '33'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('For', 'for'), ('exam-', 'exam-'), ('ple', 'ple'), (',', ','), ('genetic', 'genet'), ('algorithm', 'algorithm'), (',', ','), ('one', 'one'), ('machine', 'machin'), ('learning', 'learn'), ('algorithms', 'algorithm'), (',', ','), ('used', 'use'), ('solve', 'solv'), ('clustering', 'cluster'), ('problem', 'problem'), ('[', '['), ('25', '25'), (']', ']'), (',', ','), ('also', 'also'), ('used', 'use'), ('solve', 'solv'), ('frequent', 'frequent'), ('pattern', 'pattern'), ('min-', 'min-'), ('ing', 'ing'), ('problem', 'problem'), ('[', '['), ('33', '33'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('For', 'For'), ('exam-', 'exam-'), ('ple', 'ple'), (',', ','), ('genetic', 'genetic'), ('algorithm', 'algorithm'), (',', ','), ('one', 'one'), ('machine', 'machine'), ('learning', 'learning'), ('algorithms', 'algorithm'), (',', ','), ('used', 'used'), ('solve', 'solve'), ('clustering', 'clustering'), ('problem', 'problem'), ('[', '['), ('25', '25'), (']', ']'), (',', ','), ('also', 'also'), ('used', 'used'), ('solve', 'solve'), ('frequent', 'frequent'), ('pattern', 'pattern'), ('min-', 'min-'), ('ing', 'ing'), ('problem', 'problem'), ('[', '['), ('33', '33'), (']', ']'), ('.', '.')]


------------------- Sentence 5 -------------------

The potential of machine learning is not merely for solving different  mining problems in data analysis operator of KDD; it also has the potential of enhanc- ing the performance of the other parts of KDD, such as feature reduction for the input  operators [72].

>> Tokens are: 
 ['The', 'potential', 'machine', 'learning', 'merely', 'solving', 'different', 'mining', 'problems', 'data', 'analysis', 'operator', 'KDD', ';', 'also', 'potential', 'enhanc-', 'ing', 'performance', 'parts', 'KDD', ',', 'feature', 'reduction', 'input', 'operators', '[', '72', ']', '.']

>> Bigrams are: 
 [('The', 'potential'), ('potential', 'machine'), ('machine', 'learning'), ('learning', 'merely'), ('merely', 'solving'), ('solving', 'different'), ('different', 'mining'), ('mining', 'problems'), ('problems', 'data'), ('data', 'analysis'), ('analysis', 'operator'), ('operator', 'KDD'), ('KDD', ';'), (';', 'also'), ('also', 'potential'), ('potential', 'enhanc-'), ('enhanc-', 'ing'), ('ing', 'performance'), ('performance', 'parts'), ('parts', 'KDD'), ('KDD', ','), (',', 'feature'), ('feature', 'reduction'), ('reduction', 'input'), ('input', 'operators'), ('operators', '['), ('[', '72'), ('72', ']'), (']', '.')]

>> Trigrams are: 
 [('The', 'potential', 'machine'), ('potential', 'machine', 'learning'), ('machine', 'learning', 'merely'), ('learning', 'merely', 'solving'), ('merely', 'solving', 'different'), ('solving', 'different', 'mining'), ('different', 'mining', 'problems'), ('mining', 'problems', 'data'), ('problems', 'data', 'analysis'), ('data', 'analysis', 'operator'), ('analysis', 'operator', 'KDD'), ('operator', 'KDD', ';'), ('KDD', ';', 'also'), (';', 'also', 'potential'), ('also', 'potential', 'enhanc-'), ('potential', 'enhanc-', 'ing'), ('enhanc-', 'ing', 'performance'), ('ing', 'performance', 'parts'), ('performance', 'parts', 'KDD'), ('parts', 'KDD', ','), ('KDD', ',', 'feature'), (',', 'feature', 'reduction'), ('feature', 'reduction', 'input'), ('reduction', 'input', 'operators'), ('input', 'operators', '['), ('operators', '[', '72'), ('[', '72', ']'), ('72', ']', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('potential', 'JJ'), ('machine', 'NN'), ('learning', 'VBG'), ('merely', 'RB'), ('solving', 'VBG'), ('different', 'JJ'), ('mining', 'NN'), ('problems', 'NNS'), ('data', 'VBP'), ('analysis', 'NN'), ('operator', 'NN'), ('KDD', 'NNP'), (';', ':'), ('also', 'RB'), ('potential', 'JJ'), ('enhanc-', 'JJ'), ('ing', 'NN'), ('performance', 'NN'), ('parts', 'NNS'), ('KDD', 'NNP'), (',', ','), ('feature', 'NN'), ('reduction', 'NN'), ('input', 'NN'), ('operators', 'NNS'), ('[', 'VBP'), ('72', 'CD'), (']', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['The potential machine', 'different mining problems', 'analysis operator KDD', 'potential enhanc- ing performance parts KDD', 'feature reduction input operators', ']']

>> Named Entities are: 
 [('ORGANIZATION', 'KDD'), ('ORGANIZATION', 'KDD')] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('potential', 'potenti'), ('machine', 'machin'), ('learning', 'learn'), ('merely', 'mere'), ('solving', 'solv'), ('different', 'differ'), ('mining', 'mine'), ('problems', 'problem'), ('data', 'data'), ('analysis', 'analysi'), ('operator', 'oper'), ('KDD', 'kdd'), (';', ';'), ('also', 'also'), ('potential', 'potenti'), ('enhanc-', 'enhanc-'), ('ing', 'ing'), ('performance', 'perform'), ('parts', 'part'), ('KDD', 'kdd'), (',', ','), ('feature', 'featur'), ('reduction', 'reduct'), ('input', 'input'), ('operators', 'oper'), ('[', '['), ('72', '72'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('potential', 'potenti'), ('machine', 'machin'), ('learning', 'learn'), ('merely', 'mere'), ('solving', 'solv'), ('different', 'differ'), ('mining', 'mine'), ('problems', 'problem'), ('data', 'data'), ('analysis', 'analysi'), ('operator', 'oper'), ('KDD', 'kdd'), (';', ';'), ('also', 'also'), ('potential', 'potenti'), ('enhanc-', 'enhanc-'), ('ing', 'ing'), ('performance', 'perform'), ('parts', 'part'), ('KDD', 'kdd'), (',', ','), ('feature', 'featur'), ('reduction', 'reduct'), ('input', 'input'), ('operators', 'oper'), ('[', '['), ('72', '72'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('potential', 'potential'), ('machine', 'machine'), ('learning', 'learning'), ('merely', 'merely'), ('solving', 'solving'), ('different', 'different'), ('mining', 'mining'), ('problems', 'problem'), ('data', 'data'), ('analysis', 'analysis'), ('operator', 'operator'), ('KDD', 'KDD'), (';', ';'), ('also', 'also'), ('potential', 'potential'), ('enhanc-', 'enhanc-'), ('ing', 'ing'), ('performance', 'performance'), ('parts', 'part'), ('KDD', 'KDD'), (',', ','), ('feature', 'feature'), ('reduction', 'reduction'), ('input', 'input'), ('operators', 'operator'), ('[', '['), ('72', '72'), (']', ']'), ('.', '.')]



========================================== PARAGRAPH 269 ===========================================

A recent study [68] shows that some traditional mining algorithms, statistical meth- ods, preprocessing solutions, and even the GUI’s have been applied to several represent- ative tools and platforms for big data analytics. The results show clearly that machine  learning algorithms will be one of the essential parts of big data analytics. One of the  problems in using current machine learning methods for big data analytics is similar to  those of most traditional data mining algorithms which are designed for sequential or  centralized computing. However, one of the most possible solutions is to make them  work for parallel computing. Fortunately, some of the machine learning algorithms (e.g.-,  population-based algorithms) can essentially be used for parallel computing, which have  been demonstrated for several years, such as parallel computing version of genetic algo- rithm [122]. Different from the traditional GA, as shown in Fig. 9a, the population of  island model genetic algorithm, one of the parallel GA’s, can be divided into several sub- populations, as shown in Fig. 9b. This means that the sub-populations can be assigned to  different threads or computer nodes for parallel computing, by a simple modification of  the GA. 

------------------- Sentence 1 -------------------

A recent study [68] shows that some traditional mining algorithms, statistical meth- ods, preprocessing solutions, and even the GUI’s have been applied to several represent- ative tools and platforms for big data analytics.

>> Tokens are: 
 ['A', 'recent', 'study', '[', '68', ']', 'shows', 'traditional', 'mining', 'algorithms', ',', 'statistical', 'meth-', 'ods', ',', 'preprocessing', 'solutions', ',', 'even', 'GUI', '’', 'applied', 'several', 'represent-', 'ative', 'tools', 'platforms', 'big', 'data', 'analytics', '.']

>> Bigrams are: 
 [('A', 'recent'), ('recent', 'study'), ('study', '['), ('[', '68'), ('68', ']'), (']', 'shows'), ('shows', 'traditional'), ('traditional', 'mining'), ('mining', 'algorithms'), ('algorithms', ','), (',', 'statistical'), ('statistical', 'meth-'), ('meth-', 'ods'), ('ods', ','), (',', 'preprocessing'), ('preprocessing', 'solutions'), ('solutions', ','), (',', 'even'), ('even', 'GUI'), ('GUI', '’'), ('’', 'applied'), ('applied', 'several'), ('several', 'represent-'), ('represent-', 'ative'), ('ative', 'tools'), ('tools', 'platforms'), ('platforms', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', '.')]

>> Trigrams are: 
 [('A', 'recent', 'study'), ('recent', 'study', '['), ('study', '[', '68'), ('[', '68', ']'), ('68', ']', 'shows'), (']', 'shows', 'traditional'), ('shows', 'traditional', 'mining'), ('traditional', 'mining', 'algorithms'), ('mining', 'algorithms', ','), ('algorithms', ',', 'statistical'), (',', 'statistical', 'meth-'), ('statistical', 'meth-', 'ods'), ('meth-', 'ods', ','), ('ods', ',', 'preprocessing'), (',', 'preprocessing', 'solutions'), ('preprocessing', 'solutions', ','), ('solutions', ',', 'even'), (',', 'even', 'GUI'), ('even', 'GUI', '’'), ('GUI', '’', 'applied'), ('’', 'applied', 'several'), ('applied', 'several', 'represent-'), ('several', 'represent-', 'ative'), ('represent-', 'ative', 'tools'), ('ative', 'tools', 'platforms'), ('tools', 'platforms', 'big'), ('platforms', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', '.')]

>> POS Tags are: 
 [('A', 'DT'), ('recent', 'JJ'), ('study', 'NN'), ('[', 'VBD'), ('68', 'CD'), (']', 'NN'), ('shows', 'NNS'), ('traditional', 'JJ'), ('mining', 'NN'), ('algorithms', 'NN'), (',', ','), ('statistical', 'JJ'), ('meth-', 'JJ'), ('ods', 'NNS'), (',', ','), ('preprocessing', 'VBG'), ('solutions', 'NNS'), (',', ','), ('even', 'RB'), ('GUI', 'NNP'), ('’', 'NNP'), ('applied', 'VBD'), ('several', 'JJ'), ('represent-', 'JJ'), ('ative', 'JJ'), ('tools', 'NNS'), ('platforms', 'NNS'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['A recent study', '] shows', 'traditional mining algorithms', 'statistical meth- ods', 'solutions', 'GUI ’', 'several represent- ative tools platforms', 'big data analytics']

>> Named Entities are: 
 [('ORGANIZATION', 'GUI')] 

>> Stemming using Porter Stemmer: 
 [('A', 'a'), ('recent', 'recent'), ('study', 'studi'), ('[', '['), ('68', '68'), (']', ']'), ('shows', 'show'), ('traditional', 'tradit'), ('mining', 'mine'), ('algorithms', 'algorithm'), (',', ','), ('statistical', 'statist'), ('meth-', 'meth-'), ('ods', 'od'), (',', ','), ('preprocessing', 'preprocess'), ('solutions', 'solut'), (',', ','), ('even', 'even'), ('GUI', 'gui'), ('’', '’'), ('applied', 'appli'), ('several', 'sever'), ('represent-', 'represent-'), ('ative', 'ativ'), ('tools', 'tool'), ('platforms', 'platform'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('A', 'a'), ('recent', 'recent'), ('study', 'studi'), ('[', '['), ('68', '68'), (']', ']'), ('shows', 'show'), ('traditional', 'tradit'), ('mining', 'mine'), ('algorithms', 'algorithm'), (',', ','), ('statistical', 'statist'), ('meth-', 'meth-'), ('ods', 'od'), (',', ','), ('preprocessing', 'preprocess'), ('solutions', 'solut'), (',', ','), ('even', 'even'), ('GUI', 'gui'), ('’', '’'), ('applied', 'appli'), ('several', 'sever'), ('represent-', 'represent-'), ('ative', 'ativ'), ('tools', 'tool'), ('platforms', 'platform'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('.', '.')]

>> Lemmatization: 
 [('A', 'A'), ('recent', 'recent'), ('study', 'study'), ('[', '['), ('68', '68'), (']', ']'), ('shows', 'show'), ('traditional', 'traditional'), ('mining', 'mining'), ('algorithms', 'algorithm'), (',', ','), ('statistical', 'statistical'), ('meth-', 'meth-'), ('ods', 'od'), (',', ','), ('preprocessing', 'preprocessing'), ('solutions', 'solution'), (',', ','), ('even', 'even'), ('GUI', 'GUI'), ('’', '’'), ('applied', 'applied'), ('several', 'several'), ('represent-', 'represent-'), ('ative', 'ative'), ('tools', 'tool'), ('platforms', 'platform'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('.', '.')]


------------------- Sentence 2 -------------------

The results show clearly that machine  learning algorithms will be one of the essential parts of big data analytics.

>> Tokens are: 
 ['The', 'results', 'show', 'clearly', 'machine', 'learning', 'algorithms', 'one', 'essential', 'parts', 'big', 'data', 'analytics', '.']

>> Bigrams are: 
 [('The', 'results'), ('results', 'show'), ('show', 'clearly'), ('clearly', 'machine'), ('machine', 'learning'), ('learning', 'algorithms'), ('algorithms', 'one'), ('one', 'essential'), ('essential', 'parts'), ('parts', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', '.')]

>> Trigrams are: 
 [('The', 'results', 'show'), ('results', 'show', 'clearly'), ('show', 'clearly', 'machine'), ('clearly', 'machine', 'learning'), ('machine', 'learning', 'algorithms'), ('learning', 'algorithms', 'one'), ('algorithms', 'one', 'essential'), ('one', 'essential', 'parts'), ('essential', 'parts', 'big'), ('parts', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('results', 'NNS'), ('show', 'VBP'), ('clearly', 'RB'), ('machine', 'NN'), ('learning', 'VBG'), ('algorithms', 'JJ'), ('one', 'CD'), ('essential', 'JJ'), ('parts', 'NNS'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['The results', 'machine', 'essential parts', 'big data analytics']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('results', 'result'), ('show', 'show'), ('clearly', 'clearli'), ('machine', 'machin'), ('learning', 'learn'), ('algorithms', 'algorithm'), ('one', 'one'), ('essential', 'essenti'), ('parts', 'part'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('results', 'result'), ('show', 'show'), ('clearly', 'clear'), ('machine', 'machin'), ('learning', 'learn'), ('algorithms', 'algorithm'), ('one', 'one'), ('essential', 'essenti'), ('parts', 'part'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('results', 'result'), ('show', 'show'), ('clearly', 'clearly'), ('machine', 'machine'), ('learning', 'learning'), ('algorithms', 'algorithm'), ('one', 'one'), ('essential', 'essential'), ('parts', 'part'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('.', '.')]


------------------- Sentence 3 -------------------

One of the  problems in using current machine learning methods for big data analytics is similar to  those of most traditional data mining algorithms which are designed for sequential or  centralized computing.

>> Tokens are: 
 ['One', 'problems', 'using', 'current', 'machine', 'learning', 'methods', 'big', 'data', 'analytics', 'similar', 'traditional', 'data', 'mining', 'algorithms', 'designed', 'sequential', 'centralized', 'computing', '.']

>> Bigrams are: 
 [('One', 'problems'), ('problems', 'using'), ('using', 'current'), ('current', 'machine'), ('machine', 'learning'), ('learning', 'methods'), ('methods', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', 'similar'), ('similar', 'traditional'), ('traditional', 'data'), ('data', 'mining'), ('mining', 'algorithms'), ('algorithms', 'designed'), ('designed', 'sequential'), ('sequential', 'centralized'), ('centralized', 'computing'), ('computing', '.')]

>> Trigrams are: 
 [('One', 'problems', 'using'), ('problems', 'using', 'current'), ('using', 'current', 'machine'), ('current', 'machine', 'learning'), ('machine', 'learning', 'methods'), ('learning', 'methods', 'big'), ('methods', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', 'similar'), ('analytics', 'similar', 'traditional'), ('similar', 'traditional', 'data'), ('traditional', 'data', 'mining'), ('data', 'mining', 'algorithms'), ('mining', 'algorithms', 'designed'), ('algorithms', 'designed', 'sequential'), ('designed', 'sequential', 'centralized'), ('sequential', 'centralized', 'computing'), ('centralized', 'computing', '.')]

>> POS Tags are: 
 [('One', 'CD'), ('problems', 'NNS'), ('using', 'VBG'), ('current', 'JJ'), ('machine', 'NN'), ('learning', 'NN'), ('methods', 'NNS'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('similar', 'JJ'), ('traditional', 'JJ'), ('data', 'NN'), ('mining', 'NN'), ('algorithms', 'NN'), ('designed', 'VBN'), ('sequential', 'JJ'), ('centralized', 'VBN'), ('computing', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['problems', 'current machine learning methods', 'big data analytics', 'similar traditional data mining algorithms', 'computing']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('One', 'one'), ('problems', 'problem'), ('using', 'use'), ('current', 'current'), ('machine', 'machin'), ('learning', 'learn'), ('methods', 'method'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('similar', 'similar'), ('traditional', 'tradit'), ('data', 'data'), ('mining', 'mine'), ('algorithms', 'algorithm'), ('designed', 'design'), ('sequential', 'sequenti'), ('centralized', 'central'), ('computing', 'comput'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('One', 'one'), ('problems', 'problem'), ('using', 'use'), ('current', 'current'), ('machine', 'machin'), ('learning', 'learn'), ('methods', 'method'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('similar', 'similar'), ('traditional', 'tradit'), ('data', 'data'), ('mining', 'mine'), ('algorithms', 'algorithm'), ('designed', 'design'), ('sequential', 'sequenti'), ('centralized', 'central'), ('computing', 'comput'), ('.', '.')]

>> Lemmatization: 
 [('One', 'One'), ('problems', 'problem'), ('using', 'using'), ('current', 'current'), ('machine', 'machine'), ('learning', 'learning'), ('methods', 'method'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('similar', 'similar'), ('traditional', 'traditional'), ('data', 'data'), ('mining', 'mining'), ('algorithms', 'algorithm'), ('designed', 'designed'), ('sequential', 'sequential'), ('centralized', 'centralized'), ('computing', 'computing'), ('.', '.')]


------------------- Sentence 4 -------------------

However, one of the most possible solutions is to make them  work for parallel computing.

>> Tokens are: 
 ['However', ',', 'one', 'possible', 'solutions', 'make', 'work', 'parallel', 'computing', '.']

>> Bigrams are: 
 [('However', ','), (',', 'one'), ('one', 'possible'), ('possible', 'solutions'), ('solutions', 'make'), ('make', 'work'), ('work', 'parallel'), ('parallel', 'computing'), ('computing', '.')]

>> Trigrams are: 
 [('However', ',', 'one'), (',', 'one', 'possible'), ('one', 'possible', 'solutions'), ('possible', 'solutions', 'make'), ('solutions', 'make', 'work'), ('make', 'work', 'parallel'), ('work', 'parallel', 'computing'), ('parallel', 'computing', '.')]

>> POS Tags are: 
 [('However', 'RB'), (',', ','), ('one', 'CD'), ('possible', 'JJ'), ('solutions', 'NNS'), ('make', 'VBP'), ('work', 'NN'), ('parallel', 'RB'), ('computing', 'VBG'), ('.', '.')]

>> Noun Phrases are: 
 ['possible solutions', 'work']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('However', 'howev'), (',', ','), ('one', 'one'), ('possible', 'possibl'), ('solutions', 'solut'), ('make', 'make'), ('work', 'work'), ('parallel', 'parallel'), ('computing', 'comput'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('However', 'howev'), (',', ','), ('one', 'one'), ('possible', 'possibl'), ('solutions', 'solut'), ('make', 'make'), ('work', 'work'), ('parallel', 'parallel'), ('computing', 'comput'), ('.', '.')]

>> Lemmatization: 
 [('However', 'However'), (',', ','), ('one', 'one'), ('possible', 'possible'), ('solutions', 'solution'), ('make', 'make'), ('work', 'work'), ('parallel', 'parallel'), ('computing', 'computing'), ('.', '.')]


------------------- Sentence 5 -------------------

Fortunately, some of the machine learning algorithms (e.g.-,  population-based algorithms) can essentially be used for parallel computing, which have  been demonstrated for several years, such as parallel computing version of genetic algo- rithm [122].

>> Tokens are: 
 ['Fortunately', ',', 'machine', 'learning', 'algorithms', '(', 'e.g.-', ',', 'population-based', 'algorithms', ')', 'essentially', 'used', 'parallel', 'computing', ',', 'demonstrated', 'several', 'years', ',', 'parallel', 'computing', 'version', 'genetic', 'algo-', 'rithm', '[', '122', ']', '.']

>> Bigrams are: 
 [('Fortunately', ','), (',', 'machine'), ('machine', 'learning'), ('learning', 'algorithms'), ('algorithms', '('), ('(', 'e.g.-'), ('e.g.-', ','), (',', 'population-based'), ('population-based', 'algorithms'), ('algorithms', ')'), (')', 'essentially'), ('essentially', 'used'), ('used', 'parallel'), ('parallel', 'computing'), ('computing', ','), (',', 'demonstrated'), ('demonstrated', 'several'), ('several', 'years'), ('years', ','), (',', 'parallel'), ('parallel', 'computing'), ('computing', 'version'), ('version', 'genetic'), ('genetic', 'algo-'), ('algo-', 'rithm'), ('rithm', '['), ('[', '122'), ('122', ']'), (']', '.')]

>> Trigrams are: 
 [('Fortunately', ',', 'machine'), (',', 'machine', 'learning'), ('machine', 'learning', 'algorithms'), ('learning', 'algorithms', '('), ('algorithms', '(', 'e.g.-'), ('(', 'e.g.-', ','), ('e.g.-', ',', 'population-based'), (',', 'population-based', 'algorithms'), ('population-based', 'algorithms', ')'), ('algorithms', ')', 'essentially'), (')', 'essentially', 'used'), ('essentially', 'used', 'parallel'), ('used', 'parallel', 'computing'), ('parallel', 'computing', ','), ('computing', ',', 'demonstrated'), (',', 'demonstrated', 'several'), ('demonstrated', 'several', 'years'), ('several', 'years', ','), ('years', ',', 'parallel'), (',', 'parallel', 'computing'), ('parallel', 'computing', 'version'), ('computing', 'version', 'genetic'), ('version', 'genetic', 'algo-'), ('genetic', 'algo-', 'rithm'), ('algo-', 'rithm', '['), ('rithm', '[', '122'), ('[', '122', ']'), ('122', ']', '.')]

>> POS Tags are: 
 [('Fortunately', 'RB'), (',', ','), ('machine', 'NN'), ('learning', 'NN'), ('algorithms', 'NN'), ('(', '('), ('e.g.-', 'JJ'), (',', ','), ('population-based', 'JJ'), ('algorithms', 'NN'), (')', ')'), ('essentially', 'RB'), ('used', 'VBN'), ('parallel', 'NN'), ('computing', 'VBG'), (',', ','), ('demonstrated', 'VBD'), ('several', 'JJ'), ('years', 'NNS'), (',', ','), ('parallel', 'RB'), ('computing', 'VBG'), ('version', 'NN'), ('genetic', 'JJ'), ('algo-', 'JJ'), ('rithm', 'NN'), ('[', '$'), ('122', 'CD'), (']', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['machine learning algorithms', 'population-based algorithms', 'parallel', 'several years', 'version', 'genetic algo- rithm', ']']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Fortunately', 'fortun'), (',', ','), ('machine', 'machin'), ('learning', 'learn'), ('algorithms', 'algorithm'), ('(', '('), ('e.g.-', 'e.g.-'), (',', ','), ('population-based', 'population-bas'), ('algorithms', 'algorithm'), (')', ')'), ('essentially', 'essenti'), ('used', 'use'), ('parallel', 'parallel'), ('computing', 'comput'), (',', ','), ('demonstrated', 'demonstr'), ('several', 'sever'), ('years', 'year'), (',', ','), ('parallel', 'parallel'), ('computing', 'comput'), ('version', 'version'), ('genetic', 'genet'), ('algo-', 'algo-'), ('rithm', 'rithm'), ('[', '['), ('122', '122'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Fortunately', 'fortun'), (',', ','), ('machine', 'machin'), ('learning', 'learn'), ('algorithms', 'algorithm'), ('(', '('), ('e.g.-', 'e.g.-'), (',', ','), ('population-based', 'population-bas'), ('algorithms', 'algorithm'), (')', ')'), ('essentially', 'essenti'), ('used', 'use'), ('parallel', 'parallel'), ('computing', 'comput'), (',', ','), ('demonstrated', 'demonstr'), ('several', 'sever'), ('years', 'year'), (',', ','), ('parallel', 'parallel'), ('computing', 'comput'), ('version', 'version'), ('genetic', 'genet'), ('algo-', 'algo-'), ('rithm', 'rithm'), ('[', '['), ('122', '122'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('Fortunately', 'Fortunately'), (',', ','), ('machine', 'machine'), ('learning', 'learning'), ('algorithms', 'algorithm'), ('(', '('), ('e.g.-', 'e.g.-'), (',', ','), ('population-based', 'population-based'), ('algorithms', 'algorithm'), (')', ')'), ('essentially', 'essentially'), ('used', 'used'), ('parallel', 'parallel'), ('computing', 'computing'), (',', ','), ('demonstrated', 'demonstrated'), ('several', 'several'), ('years', 'year'), (',', ','), ('parallel', 'parallel'), ('computing', 'computing'), ('version', 'version'), ('genetic', 'genetic'), ('algo-', 'algo-'), ('rithm', 'rithm'), ('[', '['), ('122', '122'), (']', ']'), ('.', '.')]


------------------- Sentence 6 -------------------

Different from the traditional GA, as shown in Fig.

>> Tokens are: 
 ['Different', 'traditional', 'GA', ',', 'shown', 'Fig', '.']

>> Bigrams are: 
 [('Different', 'traditional'), ('traditional', 'GA'), ('GA', ','), (',', 'shown'), ('shown', 'Fig'), ('Fig', '.')]

>> Trigrams are: 
 [('Different', 'traditional', 'GA'), ('traditional', 'GA', ','), ('GA', ',', 'shown'), (',', 'shown', 'Fig'), ('shown', 'Fig', '.')]

>> POS Tags are: 
 [('Different', 'NNP'), ('traditional', 'JJ'), ('GA', 'NNP'), (',', ','), ('shown', 'VBN'), ('Fig', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Different', 'traditional GA', 'Fig']

>> Named Entities are: 
 [('PERSON', 'Fig')] 

>> Stemming using Porter Stemmer: 
 [('Different', 'differ'), ('traditional', 'tradit'), ('GA', 'ga'), (',', ','), ('shown', 'shown'), ('Fig', 'fig'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Different', 'differ'), ('traditional', 'tradit'), ('GA', 'ga'), (',', ','), ('shown', 'shown'), ('Fig', 'fig'), ('.', '.')]

>> Lemmatization: 
 [('Different', 'Different'), ('traditional', 'traditional'), ('GA', 'GA'), (',', ','), ('shown', 'shown'), ('Fig', 'Fig'), ('.', '.')]


------------------- Sentence 7 -------------------

9a, the population of  island model genetic algorithm, one of the parallel GA’s, can be divided into several sub- populations, as shown in Fig.

>> Tokens are: 
 ['9a', ',', 'population', 'island', 'model', 'genetic', 'algorithm', ',', 'one', 'parallel', 'GA', '’', ',', 'divided', 'several', 'sub-', 'populations', ',', 'shown', 'Fig', '.']

>> Bigrams are: 
 [('9a', ','), (',', 'population'), ('population', 'island'), ('island', 'model'), ('model', 'genetic'), ('genetic', 'algorithm'), ('algorithm', ','), (',', 'one'), ('one', 'parallel'), ('parallel', 'GA'), ('GA', '’'), ('’', ','), (',', 'divided'), ('divided', 'several'), ('several', 'sub-'), ('sub-', 'populations'), ('populations', ','), (',', 'shown'), ('shown', 'Fig'), ('Fig', '.')]

>> Trigrams are: 
 [('9a', ',', 'population'), (',', 'population', 'island'), ('population', 'island', 'model'), ('island', 'model', 'genetic'), ('model', 'genetic', 'algorithm'), ('genetic', 'algorithm', ','), ('algorithm', ',', 'one'), (',', 'one', 'parallel'), ('one', 'parallel', 'GA'), ('parallel', 'GA', '’'), ('GA', '’', ','), ('’', ',', 'divided'), (',', 'divided', 'several'), ('divided', 'several', 'sub-'), ('several', 'sub-', 'populations'), ('sub-', 'populations', ','), ('populations', ',', 'shown'), (',', 'shown', 'Fig'), ('shown', 'Fig', '.')]

>> POS Tags are: 
 [('9a', 'CD'), (',', ','), ('population', 'NN'), ('island', 'NN'), ('model', 'NN'), ('genetic', 'JJ'), ('algorithm', 'NN'), (',', ','), ('one', 'CD'), ('parallel', 'NN'), ('GA', 'NNP'), ('’', 'NNP'), (',', ','), ('divided', 'VBD'), ('several', 'JJ'), ('sub-', 'JJ'), ('populations', 'NNS'), (',', ','), ('shown', 'VBN'), ('Fig', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['population island model', 'genetic algorithm', 'parallel GA ’', 'several sub- populations', 'Fig']

>> Named Entities are: 
 [('PERSON', 'Fig')] 

>> Stemming using Porter Stemmer: 
 [('9a', '9a'), (',', ','), ('population', 'popul'), ('island', 'island'), ('model', 'model'), ('genetic', 'genet'), ('algorithm', 'algorithm'), (',', ','), ('one', 'one'), ('parallel', 'parallel'), ('GA', 'ga'), ('’', '’'), (',', ','), ('divided', 'divid'), ('several', 'sever'), ('sub-', 'sub-'), ('populations', 'popul'), (',', ','), ('shown', 'shown'), ('Fig', 'fig'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('9a', '9a'), (',', ','), ('population', 'popul'), ('island', 'island'), ('model', 'model'), ('genetic', 'genet'), ('algorithm', 'algorithm'), (',', ','), ('one', 'one'), ('parallel', 'parallel'), ('GA', 'ga'), ('’', '’'), (',', ','), ('divided', 'divid'), ('several', 'sever'), ('sub-', 'sub-'), ('populations', 'popul'), (',', ','), ('shown', 'shown'), ('Fig', 'fig'), ('.', '.')]

>> Lemmatization: 
 [('9a', '9a'), (',', ','), ('population', 'population'), ('island', 'island'), ('model', 'model'), ('genetic', 'genetic'), ('algorithm', 'algorithm'), (',', ','), ('one', 'one'), ('parallel', 'parallel'), ('GA', 'GA'), ('’', '’'), (',', ','), ('divided', 'divided'), ('several', 'several'), ('sub-', 'sub-'), ('populations', 'population'), (',', ','), ('shown', 'shown'), ('Fig', 'Fig'), ('.', '.')]


------------------- Sentence 8 -------------------

9b.

>> Tokens are: 
 ['9b', '.']

>> Bigrams are: 
 [('9b', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('9b', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('9b', '9b'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('9b', '9b'), ('.', '.')]

>> Lemmatization: 
 [('9b', '9b'), ('.', '.')]


------------------- Sentence 9 -------------------

This means that the sub-populations can be assigned to  different threads or computer nodes for parallel computing, by a simple modification of  the GA.

>> Tokens are: 
 ['This', 'means', 'sub-populations', 'assigned', 'different', 'threads', 'computer', 'nodes', 'parallel', 'computing', ',', 'simple', 'modification', 'GA', '.']

>> Bigrams are: 
 [('This', 'means'), ('means', 'sub-populations'), ('sub-populations', 'assigned'), ('assigned', 'different'), ('different', 'threads'), ('threads', 'computer'), ('computer', 'nodes'), ('nodes', 'parallel'), ('parallel', 'computing'), ('computing', ','), (',', 'simple'), ('simple', 'modification'), ('modification', 'GA'), ('GA', '.')]

>> Trigrams are: 
 [('This', 'means', 'sub-populations'), ('means', 'sub-populations', 'assigned'), ('sub-populations', 'assigned', 'different'), ('assigned', 'different', 'threads'), ('different', 'threads', 'computer'), ('threads', 'computer', 'nodes'), ('computer', 'nodes', 'parallel'), ('nodes', 'parallel', 'computing'), ('parallel', 'computing', ','), ('computing', ',', 'simple'), (',', 'simple', 'modification'), ('simple', 'modification', 'GA'), ('modification', 'GA', '.')]

>> POS Tags are: 
 [('This', 'DT'), ('means', 'VBZ'), ('sub-populations', 'NNS'), ('assigned', 'VBN'), ('different', 'JJ'), ('threads', 'NNS'), ('computer', 'NN'), ('nodes', 'NNS'), ('parallel', 'JJ'), ('computing', 'NN'), (',', ','), ('simple', 'JJ'), ('modification', 'NN'), ('GA', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['sub-populations', 'different threads computer nodes', 'parallel computing', 'simple modification GA']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('This', 'thi'), ('means', 'mean'), ('sub-populations', 'sub-popul'), ('assigned', 'assign'), ('different', 'differ'), ('threads', 'thread'), ('computer', 'comput'), ('nodes', 'node'), ('parallel', 'parallel'), ('computing', 'comput'), (',', ','), ('simple', 'simpl'), ('modification', 'modif'), ('GA', 'ga'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('This', 'this'), ('means', 'mean'), ('sub-populations', 'sub-popul'), ('assigned', 'assign'), ('different', 'differ'), ('threads', 'thread'), ('computer', 'comput'), ('nodes', 'node'), ('parallel', 'parallel'), ('computing', 'comput'), (',', ','), ('simple', 'simpl'), ('modification', 'modif'), ('GA', 'ga'), ('.', '.')]

>> Lemmatization: 
 [('This', 'This'), ('means', 'mean'), ('sub-populations', 'sub-populations'), ('assigned', 'assigned'), ('different', 'different'), ('threads', 'thread'), ('computer', 'computer'), ('nodes', 'node'), ('parallel', 'parallel'), ('computing', 'computing'), (',', ','), ('simple', 'simple'), ('modification', 'modification'), ('GA', 'GA'), ('.', '.')]



========================================== PARAGRAPH 270 ===========================================

For this reason, in [123], Kiran and Babu explained that the framework for distributed  data mining algorithm still needs to aggregate the information from different computer  nodes. As shown in Fig. 10, the common design of distributed data mining algorithm is  as follows: each mining algorithm will be performed on a computer node (worker) which  has its locally coherent data, but not the whole data. To construct a globally meaning- ful knowledge after each mining algorithm finds its local model, the local model from  each computer node has to be aggregated and integrated into a final model to represent  the complete knowledge. Kiran and Babu [123] also pointed out that the communication  will be the bottleneck when using this kind of distributed computing framework. 

------------------- Sentence 1 -------------------

For this reason, in [123], Kiran and Babu explained that the framework for distributed  data mining algorithm still needs to aggregate the information from different computer  nodes.

>> Tokens are: 
 ['For', 'reason', ',', '[', '123', ']', ',', 'Kiran', 'Babu', 'explained', 'framework', 'distributed', 'data', 'mining', 'algorithm', 'still', 'needs', 'aggregate', 'information', 'different', 'computer', 'nodes', '.']

>> Bigrams are: 
 [('For', 'reason'), ('reason', ','), (',', '['), ('[', '123'), ('123', ']'), (']', ','), (',', 'Kiran'), ('Kiran', 'Babu'), ('Babu', 'explained'), ('explained', 'framework'), ('framework', 'distributed'), ('distributed', 'data'), ('data', 'mining'), ('mining', 'algorithm'), ('algorithm', 'still'), ('still', 'needs'), ('needs', 'aggregate'), ('aggregate', 'information'), ('information', 'different'), ('different', 'computer'), ('computer', 'nodes'), ('nodes', '.')]

>> Trigrams are: 
 [('For', 'reason', ','), ('reason', ',', '['), (',', '[', '123'), ('[', '123', ']'), ('123', ']', ','), (']', ',', 'Kiran'), (',', 'Kiran', 'Babu'), ('Kiran', 'Babu', 'explained'), ('Babu', 'explained', 'framework'), ('explained', 'framework', 'distributed'), ('framework', 'distributed', 'data'), ('distributed', 'data', 'mining'), ('data', 'mining', 'algorithm'), ('mining', 'algorithm', 'still'), ('algorithm', 'still', 'needs'), ('still', 'needs', 'aggregate'), ('needs', 'aggregate', 'information'), ('aggregate', 'information', 'different'), ('information', 'different', 'computer'), ('different', 'computer', 'nodes'), ('computer', 'nodes', '.')]

>> POS Tags are: 
 [('For', 'IN'), ('reason', 'NN'), (',', ','), ('[', '$'), ('123', 'CD'), (']', 'NNP'), (',', ','), ('Kiran', 'NNP'), ('Babu', 'NNP'), ('explained', 'VBD'), ('framework', 'NN'), ('distributed', 'VBN'), ('data', 'NNS'), ('mining', 'NN'), ('algorithm', 'NN'), ('still', 'RB'), ('needs', 'VBZ'), ('aggregate', 'JJ'), ('information', 'NN'), ('different', 'JJ'), ('computer', 'NN'), ('nodes', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['reason', ']', 'Kiran Babu', 'framework', 'data mining algorithm', 'aggregate information', 'different computer nodes']

>> Named Entities are: 
 [('PERSON', 'Kiran Babu')] 

>> Stemming using Porter Stemmer: 
 [('For', 'for'), ('reason', 'reason'), (',', ','), ('[', '['), ('123', '123'), (']', ']'), (',', ','), ('Kiran', 'kiran'), ('Babu', 'babu'), ('explained', 'explain'), ('framework', 'framework'), ('distributed', 'distribut'), ('data', 'data'), ('mining', 'mine'), ('algorithm', 'algorithm'), ('still', 'still'), ('needs', 'need'), ('aggregate', 'aggreg'), ('information', 'inform'), ('different', 'differ'), ('computer', 'comput'), ('nodes', 'node'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('For', 'for'), ('reason', 'reason'), (',', ','), ('[', '['), ('123', '123'), (']', ']'), (',', ','), ('Kiran', 'kiran'), ('Babu', 'babu'), ('explained', 'explain'), ('framework', 'framework'), ('distributed', 'distribut'), ('data', 'data'), ('mining', 'mine'), ('algorithm', 'algorithm'), ('still', 'still'), ('needs', 'need'), ('aggregate', 'aggreg'), ('information', 'inform'), ('different', 'differ'), ('computer', 'comput'), ('nodes', 'node'), ('.', '.')]

>> Lemmatization: 
 [('For', 'For'), ('reason', 'reason'), (',', ','), ('[', '['), ('123', '123'), (']', ']'), (',', ','), ('Kiran', 'Kiran'), ('Babu', 'Babu'), ('explained', 'explained'), ('framework', 'framework'), ('distributed', 'distributed'), ('data', 'data'), ('mining', 'mining'), ('algorithm', 'algorithm'), ('still', 'still'), ('needs', 'need'), ('aggregate', 'aggregate'), ('information', 'information'), ('different', 'different'), ('computer', 'computer'), ('nodes', 'node'), ('.', '.')]


------------------- Sentence 2 -------------------

As shown in Fig.

>> Tokens are: 
 ['As', 'shown', 'Fig', '.']

>> Bigrams are: 
 [('As', 'shown'), ('shown', 'Fig'), ('Fig', '.')]

>> Trigrams are: 
 [('As', 'shown', 'Fig'), ('shown', 'Fig', '.')]

>> POS Tags are: 
 [('As', 'IN'), ('shown', 'VBN'), ('Fig', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Fig']

>> Named Entities are: 
 [('PERSON', 'Fig')] 

>> Stemming using Porter Stemmer: 
 [('As', 'as'), ('shown', 'shown'), ('Fig', 'fig'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('As', 'as'), ('shown', 'shown'), ('Fig', 'fig'), ('.', '.')]

>> Lemmatization: 
 [('As', 'As'), ('shown', 'shown'), ('Fig', 'Fig'), ('.', '.')]


------------------- Sentence 3 -------------------

10, the common design of distributed data mining algorithm is  as follows: each mining algorithm will be performed on a computer node (worker) which  has its locally coherent data, but not the whole data.

>> Tokens are: 
 ['10', ',', 'common', 'design', 'distributed', 'data', 'mining', 'algorithm', 'follows', ':', 'mining', 'algorithm', 'performed', 'computer', 'node', '(', 'worker', ')', 'locally', 'coherent', 'data', ',', 'whole', 'data', '.']

>> Bigrams are: 
 [('10', ','), (',', 'common'), ('common', 'design'), ('design', 'distributed'), ('distributed', 'data'), ('data', 'mining'), ('mining', 'algorithm'), ('algorithm', 'follows'), ('follows', ':'), (':', 'mining'), ('mining', 'algorithm'), ('algorithm', 'performed'), ('performed', 'computer'), ('computer', 'node'), ('node', '('), ('(', 'worker'), ('worker', ')'), (')', 'locally'), ('locally', 'coherent'), ('coherent', 'data'), ('data', ','), (',', 'whole'), ('whole', 'data'), ('data', '.')]

>> Trigrams are: 
 [('10', ',', 'common'), (',', 'common', 'design'), ('common', 'design', 'distributed'), ('design', 'distributed', 'data'), ('distributed', 'data', 'mining'), ('data', 'mining', 'algorithm'), ('mining', 'algorithm', 'follows'), ('algorithm', 'follows', ':'), ('follows', ':', 'mining'), (':', 'mining', 'algorithm'), ('mining', 'algorithm', 'performed'), ('algorithm', 'performed', 'computer'), ('performed', 'computer', 'node'), ('computer', 'node', '('), ('node', '(', 'worker'), ('(', 'worker', ')'), ('worker', ')', 'locally'), (')', 'locally', 'coherent'), ('locally', 'coherent', 'data'), ('coherent', 'data', ','), ('data', ',', 'whole'), (',', 'whole', 'data'), ('whole', 'data', '.')]

>> POS Tags are: 
 [('10', 'CD'), (',', ','), ('common', 'JJ'), ('design', 'NN'), ('distributed', 'VBN'), ('data', 'NNS'), ('mining', 'NN'), ('algorithm', 'NN'), ('follows', 'VBZ'), (':', ':'), ('mining', 'NN'), ('algorithm', 'NN'), ('performed', 'VBD'), ('computer', 'NN'), ('node', 'NN'), ('(', '('), ('worker', 'NN'), (')', ')'), ('locally', 'RB'), ('coherent', 'JJ'), ('data', 'NNS'), (',', ','), ('whole', 'JJ'), ('data', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['common design', 'data mining algorithm', 'mining algorithm', 'computer node', 'worker', 'coherent data', 'whole data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('10', '10'), (',', ','), ('common', 'common'), ('design', 'design'), ('distributed', 'distribut'), ('data', 'data'), ('mining', 'mine'), ('algorithm', 'algorithm'), ('follows', 'follow'), (':', ':'), ('mining', 'mine'), ('algorithm', 'algorithm'), ('performed', 'perform'), ('computer', 'comput'), ('node', 'node'), ('(', '('), ('worker', 'worker'), (')', ')'), ('locally', 'local'), ('coherent', 'coher'), ('data', 'data'), (',', ','), ('whole', 'whole'), ('data', 'data'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('10', '10'), (',', ','), ('common', 'common'), ('design', 'design'), ('distributed', 'distribut'), ('data', 'data'), ('mining', 'mine'), ('algorithm', 'algorithm'), ('follows', 'follow'), (':', ':'), ('mining', 'mine'), ('algorithm', 'algorithm'), ('performed', 'perform'), ('computer', 'comput'), ('node', 'node'), ('(', '('), ('worker', 'worker'), (')', ')'), ('locally', 'local'), ('coherent', 'coher'), ('data', 'data'), (',', ','), ('whole', 'whole'), ('data', 'data'), ('.', '.')]

>> Lemmatization: 
 [('10', '10'), (',', ','), ('common', 'common'), ('design', 'design'), ('distributed', 'distributed'), ('data', 'data'), ('mining', 'mining'), ('algorithm', 'algorithm'), ('follows', 'follows'), (':', ':'), ('mining', 'mining'), ('algorithm', 'algorithm'), ('performed', 'performed'), ('computer', 'computer'), ('node', 'node'), ('(', '('), ('worker', 'worker'), (')', ')'), ('locally', 'locally'), ('coherent', 'coherent'), ('data', 'data'), (',', ','), ('whole', 'whole'), ('data', 'data'), ('.', '.')]


------------------- Sentence 4 -------------------

To construct a globally meaning- ful knowledge after each mining algorithm finds its local model, the local model from  each computer node has to be aggregated and integrated into a final model to represent  the complete knowledge.

>> Tokens are: 
 ['To', 'construct', 'globally', 'meaning-', 'ful', 'knowledge', 'mining', 'algorithm', 'finds', 'local', 'model', ',', 'local', 'model', 'computer', 'node', 'aggregated', 'integrated', 'final', 'model', 'represent', 'complete', 'knowledge', '.']

>> Bigrams are: 
 [('To', 'construct'), ('construct', 'globally'), ('globally', 'meaning-'), ('meaning-', 'ful'), ('ful', 'knowledge'), ('knowledge', 'mining'), ('mining', 'algorithm'), ('algorithm', 'finds'), ('finds', 'local'), ('local', 'model'), ('model', ','), (',', 'local'), ('local', 'model'), ('model', 'computer'), ('computer', 'node'), ('node', 'aggregated'), ('aggregated', 'integrated'), ('integrated', 'final'), ('final', 'model'), ('model', 'represent'), ('represent', 'complete'), ('complete', 'knowledge'), ('knowledge', '.')]

>> Trigrams are: 
 [('To', 'construct', 'globally'), ('construct', 'globally', 'meaning-'), ('globally', 'meaning-', 'ful'), ('meaning-', 'ful', 'knowledge'), ('ful', 'knowledge', 'mining'), ('knowledge', 'mining', 'algorithm'), ('mining', 'algorithm', 'finds'), ('algorithm', 'finds', 'local'), ('finds', 'local', 'model'), ('local', 'model', ','), ('model', ',', 'local'), (',', 'local', 'model'), ('local', 'model', 'computer'), ('model', 'computer', 'node'), ('computer', 'node', 'aggregated'), ('node', 'aggregated', 'integrated'), ('aggregated', 'integrated', 'final'), ('integrated', 'final', 'model'), ('final', 'model', 'represent'), ('model', 'represent', 'complete'), ('represent', 'complete', 'knowledge'), ('complete', 'knowledge', '.')]

>> POS Tags are: 
 [('To', 'TO'), ('construct', 'VB'), ('globally', 'RB'), ('meaning-', 'JJ'), ('ful', 'JJ'), ('knowledge', 'NN'), ('mining', 'NN'), ('algorithm', 'JJ'), ('finds', 'VBZ'), ('local', 'JJ'), ('model', 'NN'), (',', ','), ('local', 'JJ'), ('model', 'NN'), ('computer', 'NN'), ('node', 'RB'), ('aggregated', 'VBD'), ('integrated', 'JJ'), ('final', 'JJ'), ('model', 'NN'), ('represent', 'JJ'), ('complete', 'JJ'), ('knowledge', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['meaning- ful knowledge mining', 'local model', 'local model computer', 'integrated final model', 'represent complete knowledge']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('To', 'to'), ('construct', 'construct'), ('globally', 'global'), ('meaning-', 'meaning-'), ('ful', 'ful'), ('knowledge', 'knowledg'), ('mining', 'mine'), ('algorithm', 'algorithm'), ('finds', 'find'), ('local', 'local'), ('model', 'model'), (',', ','), ('local', 'local'), ('model', 'model'), ('computer', 'comput'), ('node', 'node'), ('aggregated', 'aggreg'), ('integrated', 'integr'), ('final', 'final'), ('model', 'model'), ('represent', 'repres'), ('complete', 'complet'), ('knowledge', 'knowledg'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('To', 'to'), ('construct', 'construct'), ('globally', 'global'), ('meaning-', 'meaning-'), ('ful', 'ful'), ('knowledge', 'knowledg'), ('mining', 'mine'), ('algorithm', 'algorithm'), ('finds', 'find'), ('local', 'local'), ('model', 'model'), (',', ','), ('local', 'local'), ('model', 'model'), ('computer', 'comput'), ('node', 'node'), ('aggregated', 'aggreg'), ('integrated', 'integr'), ('final', 'final'), ('model', 'model'), ('represent', 'repres'), ('complete', 'complet'), ('knowledge', 'knowledg'), ('.', '.')]

>> Lemmatization: 
 [('To', 'To'), ('construct', 'construct'), ('globally', 'globally'), ('meaning-', 'meaning-'), ('ful', 'ful'), ('knowledge', 'knowledge'), ('mining', 'mining'), ('algorithm', 'algorithm'), ('finds', 'find'), ('local', 'local'), ('model', 'model'), (',', ','), ('local', 'local'), ('model', 'model'), ('computer', 'computer'), ('node', 'node'), ('aggregated', 'aggregated'), ('integrated', 'integrated'), ('final', 'final'), ('model', 'model'), ('represent', 'represent'), ('complete', 'complete'), ('knowledge', 'knowledge'), ('.', '.')]


------------------- Sentence 5 -------------------

Kiran and Babu [123] also pointed out that the communication  will be the bottleneck when using this kind of distributed computing framework.

>> Tokens are: 
 ['Kiran', 'Babu', '[', '123', ']', 'also', 'pointed', 'communication', 'bottleneck', 'using', 'kind', 'distributed', 'computing', 'framework', '.']

>> Bigrams are: 
 [('Kiran', 'Babu'), ('Babu', '['), ('[', '123'), ('123', ']'), (']', 'also'), ('also', 'pointed'), ('pointed', 'communication'), ('communication', 'bottleneck'), ('bottleneck', 'using'), ('using', 'kind'), ('kind', 'distributed'), ('distributed', 'computing'), ('computing', 'framework'), ('framework', '.')]

>> Trigrams are: 
 [('Kiran', 'Babu', '['), ('Babu', '[', '123'), ('[', '123', ']'), ('123', ']', 'also'), (']', 'also', 'pointed'), ('also', 'pointed', 'communication'), ('pointed', 'communication', 'bottleneck'), ('communication', 'bottleneck', 'using'), ('bottleneck', 'using', 'kind'), ('using', 'kind', 'distributed'), ('kind', 'distributed', 'computing'), ('distributed', 'computing', 'framework'), ('computing', 'framework', '.')]

>> POS Tags are: 
 [('Kiran', 'NNP'), ('Babu', 'NNP'), ('[', 'VBD'), ('123', 'CD'), (']', 'NNP'), ('also', 'RB'), ('pointed', 'VBD'), ('communication', 'NN'), ('bottleneck', 'NN'), ('using', 'VBG'), ('kind', 'NN'), ('distributed', 'VBD'), ('computing', 'VBG'), ('framework', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Kiran Babu', ']', 'communication bottleneck', 'kind', 'framework']

>> Named Entities are: 
 [('PERSON', 'Kiran'), ('PERSON', 'Babu')] 

>> Stemming using Porter Stemmer: 
 [('Kiran', 'kiran'), ('Babu', 'babu'), ('[', '['), ('123', '123'), (']', ']'), ('also', 'also'), ('pointed', 'point'), ('communication', 'commun'), ('bottleneck', 'bottleneck'), ('using', 'use'), ('kind', 'kind'), ('distributed', 'distribut'), ('computing', 'comput'), ('framework', 'framework'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Kiran', 'kiran'), ('Babu', 'babu'), ('[', '['), ('123', '123'), (']', ']'), ('also', 'also'), ('pointed', 'point'), ('communication', 'communic'), ('bottleneck', 'bottleneck'), ('using', 'use'), ('kind', 'kind'), ('distributed', 'distribut'), ('computing', 'comput'), ('framework', 'framework'), ('.', '.')]

>> Lemmatization: 
 [('Kiran', 'Kiran'), ('Babu', 'Babu'), ('[', '['), ('123', '123'), (']', ']'), ('also', 'also'), ('pointed', 'pointed'), ('communication', 'communication'), ('bottleneck', 'bottleneck'), ('using', 'using'), ('kind', 'kind'), ('distributed', 'distributed'), ('computing', 'computing'), ('framework', 'framework'), ('.', '.')]



========================================== PARAGRAPH 271 ===========================================

Bu et al. [124] found some research issues when trying to apply machine learning algo- rithms to parallel computing platforms. For instance, the early version of map-reduce  framework does not support “iteration” (i.e.-, recursion). But the good news is that some  recent works [87, 125] have paid close attention to this problem and tried to fix it. Simi- lar to the solutions for enhancing the performance of the traditional data mining algo- rithms, one of the possible solutions to enhancing the performance of a machine  learning algorithm is to use CUDA, i.e.-, a GPU, to reduce the computing time of data 

------------------- Sentence 1 -------------------

Bu et al.

>> Tokens are: 
 ['Bu', 'et', 'al', '.']

>> Bigrams are: 
 [('Bu', 'et'), ('et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('Bu', 'et', 'al'), ('et', 'al', '.')]

>> POS Tags are: 
 [('Bu', 'NNP'), ('et', 'CC'), ('al', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Bu', 'al']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Bu', 'bu'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Bu', 'bu'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('Bu', 'Bu'), ('et', 'et'), ('al', 'al'), ('.', '.')]


------------------- Sentence 2 -------------------

[124] found some research issues when trying to apply machine learning algo- rithms to parallel computing platforms.

>> Tokens are: 
 ['[', '124', ']', 'found', 'research', 'issues', 'trying', 'apply', 'machine', 'learning', 'algo-', 'rithms', 'parallel', 'computing', 'platforms', '.']

>> Bigrams are: 
 [('[', '124'), ('124', ']'), (']', 'found'), ('found', 'research'), ('research', 'issues'), ('issues', 'trying'), ('trying', 'apply'), ('apply', 'machine'), ('machine', 'learning'), ('learning', 'algo-'), ('algo-', 'rithms'), ('rithms', 'parallel'), ('parallel', 'computing'), ('computing', 'platforms'), ('platforms', '.')]

>> Trigrams are: 
 [('[', '124', ']'), ('124', ']', 'found'), (']', 'found', 'research'), ('found', 'research', 'issues'), ('research', 'issues', 'trying'), ('issues', 'trying', 'apply'), ('trying', 'apply', 'machine'), ('apply', 'machine', 'learning'), ('machine', 'learning', 'algo-'), ('learning', 'algo-', 'rithms'), ('algo-', 'rithms', 'parallel'), ('rithms', 'parallel', 'computing'), ('parallel', 'computing', 'platforms'), ('computing', 'platforms', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('124', 'CD'), (']', 'NN'), ('found', 'VBD'), ('research', 'NN'), ('issues', 'NNS'), ('trying', 'VBG'), ('apply', 'RB'), ('machine', 'NN'), ('learning', 'VBG'), ('algo-', 'JJ'), ('rithms', 'NN'), ('parallel', 'NN'), ('computing', 'VBG'), ('platforms', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 [']', 'research issues', 'machine', 'algo- rithms parallel', 'platforms']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('124', '124'), (']', ']'), ('found', 'found'), ('research', 'research'), ('issues', 'issu'), ('trying', 'tri'), ('apply', 'appli'), ('machine', 'machin'), ('learning', 'learn'), ('algo-', 'algo-'), ('rithms', 'rithm'), ('parallel', 'parallel'), ('computing', 'comput'), ('platforms', 'platform'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('124', '124'), (']', ']'), ('found', 'found'), ('research', 'research'), ('issues', 'issu'), ('trying', 'tri'), ('apply', 'appli'), ('machine', 'machin'), ('learning', 'learn'), ('algo-', 'algo-'), ('rithms', 'rithm'), ('parallel', 'parallel'), ('computing', 'comput'), ('platforms', 'platform'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('124', '124'), (']', ']'), ('found', 'found'), ('research', 'research'), ('issues', 'issue'), ('trying', 'trying'), ('apply', 'apply'), ('machine', 'machine'), ('learning', 'learning'), ('algo-', 'algo-'), ('rithms', 'rithms'), ('parallel', 'parallel'), ('computing', 'computing'), ('platforms', 'platform'), ('.', '.')]


------------------- Sentence 3 -------------------

For instance, the early version of map-reduce  framework does not support “iteration” (i.e.-, recursion).

>> Tokens are: 
 ['For', 'instance', ',', 'early', 'version', 'map-reduce', 'framework', 'support', '“', 'iteration', '”', '(', 'i.e.-', ',', 'recursion', ')', '.']

>> Bigrams are: 
 [('For', 'instance'), ('instance', ','), (',', 'early'), ('early', 'version'), ('version', 'map-reduce'), ('map-reduce', 'framework'), ('framework', 'support'), ('support', '“'), ('“', 'iteration'), ('iteration', '”'), ('”', '('), ('(', 'i.e.-'), ('i.e.-', ','), (',', 'recursion'), ('recursion', ')'), (')', '.')]

>> Trigrams are: 
 [('For', 'instance', ','), ('instance', ',', 'early'), (',', 'early', 'version'), ('early', 'version', 'map-reduce'), ('version', 'map-reduce', 'framework'), ('map-reduce', 'framework', 'support'), ('framework', 'support', '“'), ('support', '“', 'iteration'), ('“', 'iteration', '”'), ('iteration', '”', '('), ('”', '(', 'i.e.-'), ('(', 'i.e.-', ','), ('i.e.-', ',', 'recursion'), (',', 'recursion', ')'), ('recursion', ')', '.')]

>> POS Tags are: 
 [('For', 'IN'), ('instance', 'NN'), (',', ','), ('early', 'JJ'), ('version', 'NN'), ('map-reduce', 'NN'), ('framework', 'NN'), ('support', 'NN'), ('“', 'NNP'), ('iteration', 'NN'), ('”', 'NNP'), ('(', '('), ('i.e.-', 'JJ'), (',', ','), ('recursion', 'NN'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['instance', 'early version map-reduce framework support “ iteration ”', 'recursion']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('For', 'for'), ('instance', 'instanc'), (',', ','), ('early', 'earli'), ('version', 'version'), ('map-reduce', 'map-reduc'), ('framework', 'framework'), ('support', 'support'), ('“', '“'), ('iteration', 'iter'), ('”', '”'), ('(', '('), ('i.e.-', 'i.e.-'), (',', ','), ('recursion', 'recurs'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('For', 'for'), ('instance', 'instanc'), (',', ','), ('early', 'earli'), ('version', 'version'), ('map-reduce', 'map-reduc'), ('framework', 'framework'), ('support', 'support'), ('“', '“'), ('iteration', 'iter'), ('”', '”'), ('(', '('), ('i.e.-', 'i.e.-'), (',', ','), ('recursion', 'recurs'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('For', 'For'), ('instance', 'instance'), (',', ','), ('early', 'early'), ('version', 'version'), ('map-reduce', 'map-reduce'), ('framework', 'framework'), ('support', 'support'), ('“', '“'), ('iteration', 'iteration'), ('”', '”'), ('(', '('), ('i.e.-', 'i.e.-'), (',', ','), ('recursion', 'recursion'), (')', ')'), ('.', '.')]


------------------- Sentence 4 -------------------

But the good news is that some  recent works [87, 125] have paid close attention to this problem and tried to fix it.

>> Tokens are: 
 ['But', 'good', 'news', 'recent', 'works', '[', '87', ',', '125', ']', 'paid', 'close', 'attention', 'problem', 'tried', 'fix', '.']

>> Bigrams are: 
 [('But', 'good'), ('good', 'news'), ('news', 'recent'), ('recent', 'works'), ('works', '['), ('[', '87'), ('87', ','), (',', '125'), ('125', ']'), (']', 'paid'), ('paid', 'close'), ('close', 'attention'), ('attention', 'problem'), ('problem', 'tried'), ('tried', 'fix'), ('fix', '.')]

>> Trigrams are: 
 [('But', 'good', 'news'), ('good', 'news', 'recent'), ('news', 'recent', 'works'), ('recent', 'works', '['), ('works', '[', '87'), ('[', '87', ','), ('87', ',', '125'), (',', '125', ']'), ('125', ']', 'paid'), (']', 'paid', 'close'), ('paid', 'close', 'attention'), ('close', 'attention', 'problem'), ('attention', 'problem', 'tried'), ('problem', 'tried', 'fix'), ('tried', 'fix', '.')]

>> POS Tags are: 
 [('But', 'CC'), ('good', 'JJ'), ('news', 'NN'), ('recent', 'JJ'), ('works', 'VBZ'), ('[', 'RB'), ('87', 'CD'), (',', ','), ('125', 'CD'), (']', 'NN'), ('paid', 'VBN'), ('close', 'RB'), ('attention', 'NN'), ('problem', 'NN'), ('tried', 'VBD'), ('fix', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['good news', ']', 'attention problem', 'fix']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('But', 'but'), ('good', 'good'), ('news', 'news'), ('recent', 'recent'), ('works', 'work'), ('[', '['), ('87', '87'), (',', ','), ('125', '125'), (']', ']'), ('paid', 'paid'), ('close', 'close'), ('attention', 'attent'), ('problem', 'problem'), ('tried', 'tri'), ('fix', 'fix'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('But', 'but'), ('good', 'good'), ('news', 'news'), ('recent', 'recent'), ('works', 'work'), ('[', '['), ('87', '87'), (',', ','), ('125', '125'), (']', ']'), ('paid', 'paid'), ('close', 'close'), ('attention', 'attent'), ('problem', 'problem'), ('tried', 'tri'), ('fix', 'fix'), ('.', '.')]

>> Lemmatization: 
 [('But', 'But'), ('good', 'good'), ('news', 'news'), ('recent', 'recent'), ('works', 'work'), ('[', '['), ('87', '87'), (',', ','), ('125', '125'), (']', ']'), ('paid', 'paid'), ('close', 'close'), ('attention', 'attention'), ('problem', 'problem'), ('tried', 'tried'), ('fix', 'fix'), ('.', '.')]


------------------- Sentence 5 -------------------

Simi- lar to the solutions for enhancing the performance of the traditional data mining algo- rithms, one of the possible solutions to enhancing the performance of a machine  learning algorithm is to use CUDA, i.e.-, a GPU, to reduce the computing time of data

>> Tokens are: 
 ['Simi-', 'lar', 'solutions', 'enhancing', 'performance', 'traditional', 'data', 'mining', 'algo-', 'rithms', ',', 'one', 'possible', 'solutions', 'enhancing', 'performance', 'machine', 'learning', 'algorithm', 'use', 'CUDA', ',', 'i.e.-', ',', 'GPU', ',', 'reduce', 'computing', 'time', 'data']

>> Bigrams are: 
 [('Simi-', 'lar'), ('lar', 'solutions'), ('solutions', 'enhancing'), ('enhancing', 'performance'), ('performance', 'traditional'), ('traditional', 'data'), ('data', 'mining'), ('mining', 'algo-'), ('algo-', 'rithms'), ('rithms', ','), (',', 'one'), ('one', 'possible'), ('possible', 'solutions'), ('solutions', 'enhancing'), ('enhancing', 'performance'), ('performance', 'machine'), ('machine', 'learning'), ('learning', 'algorithm'), ('algorithm', 'use'), ('use', 'CUDA'), ('CUDA', ','), (',', 'i.e.-'), ('i.e.-', ','), (',', 'GPU'), ('GPU', ','), (',', 'reduce'), ('reduce', 'computing'), ('computing', 'time'), ('time', 'data')]

>> Trigrams are: 
 [('Simi-', 'lar', 'solutions'), ('lar', 'solutions', 'enhancing'), ('solutions', 'enhancing', 'performance'), ('enhancing', 'performance', 'traditional'), ('performance', 'traditional', 'data'), ('traditional', 'data', 'mining'), ('data', 'mining', 'algo-'), ('mining', 'algo-', 'rithms'), ('algo-', 'rithms', ','), ('rithms', ',', 'one'), (',', 'one', 'possible'), ('one', 'possible', 'solutions'), ('possible', 'solutions', 'enhancing'), ('solutions', 'enhancing', 'performance'), ('enhancing', 'performance', 'machine'), ('performance', 'machine', 'learning'), ('machine', 'learning', 'algorithm'), ('learning', 'algorithm', 'use'), ('algorithm', 'use', 'CUDA'), ('use', 'CUDA', ','), ('CUDA', ',', 'i.e.-'), (',', 'i.e.-', ','), ('i.e.-', ',', 'GPU'), (',', 'GPU', ','), ('GPU', ',', 'reduce'), (',', 'reduce', 'computing'), ('reduce', 'computing', 'time'), ('computing', 'time', 'data')]

>> POS Tags are: 
 [('Simi-', 'JJ'), ('lar', 'JJ'), ('solutions', 'NNS'), ('enhancing', 'VBG'), ('performance', 'NN'), ('traditional', 'JJ'), ('data', 'NNS'), ('mining', 'NN'), ('algo-', 'JJ'), ('rithms', 'NN'), (',', ','), ('one', 'CD'), ('possible', 'JJ'), ('solutions', 'NNS'), ('enhancing', 'VBG'), ('performance', 'NN'), ('machine', 'NN'), ('learning', 'VBG'), ('algorithm', 'JJ'), ('use', 'NN'), ('CUDA', 'NNP'), (',', ','), ('i.e.-', 'JJ'), (',', ','), ('GPU', 'NNP'), (',', ','), ('reduce', 'VB'), ('computing', 'VBG'), ('time', 'NN'), ('data', 'NNS')]

>> Noun Phrases are: 
 ['Simi- lar solutions', 'performance', 'traditional data mining', 'algo- rithms', 'possible solutions', 'performance machine', 'algorithm use CUDA', 'GPU', 'time data']

>> Named Entities are: 
 [('ORGANIZATION', 'CUDA'), ('ORGANIZATION', 'GPU')] 

>> Stemming using Porter Stemmer: 
 [('Simi-', 'simi-'), ('lar', 'lar'), ('solutions', 'solut'), ('enhancing', 'enhanc'), ('performance', 'perform'), ('traditional', 'tradit'), ('data', 'data'), ('mining', 'mine'), ('algo-', 'algo-'), ('rithms', 'rithm'), (',', ','), ('one', 'one'), ('possible', 'possibl'), ('solutions', 'solut'), ('enhancing', 'enhanc'), ('performance', 'perform'), ('machine', 'machin'), ('learning', 'learn'), ('algorithm', 'algorithm'), ('use', 'use'), ('CUDA', 'cuda'), (',', ','), ('i.e.-', 'i.e.-'), (',', ','), ('GPU', 'gpu'), (',', ','), ('reduce', 'reduc'), ('computing', 'comput'), ('time', 'time'), ('data', 'data')]

>> Stemming using Snowball Stemmer: 
 [('Simi-', 'simi-'), ('lar', 'lar'), ('solutions', 'solut'), ('enhancing', 'enhanc'), ('performance', 'perform'), ('traditional', 'tradit'), ('data', 'data'), ('mining', 'mine'), ('algo-', 'algo-'), ('rithms', 'rithm'), (',', ','), ('one', 'one'), ('possible', 'possibl'), ('solutions', 'solut'), ('enhancing', 'enhanc'), ('performance', 'perform'), ('machine', 'machin'), ('learning', 'learn'), ('algorithm', 'algorithm'), ('use', 'use'), ('CUDA', 'cuda'), (',', ','), ('i.e.-', 'i.e.-'), (',', ','), ('GPU', 'gpu'), (',', ','), ('reduce', 'reduc'), ('computing', 'comput'), ('time', 'time'), ('data', 'data')]

>> Lemmatization: 
 [('Simi-', 'Simi-'), ('lar', 'lar'), ('solutions', 'solution'), ('enhancing', 'enhancing'), ('performance', 'performance'), ('traditional', 'traditional'), ('data', 'data'), ('mining', 'mining'), ('algo-', 'algo-'), ('rithms', 'rithms'), (',', ','), ('one', 'one'), ('possible', 'possible'), ('solutions', 'solution'), ('enhancing', 'enhancing'), ('performance', 'performance'), ('machine', 'machine'), ('learning', 'learning'), ('algorithm', 'algorithm'), ('use', 'use'), ('CUDA', 'CUDA'), (',', ','), ('i.e.-', 'i.e.-'), (',', ','), ('GPU', 'GPU'), (',', ','), ('reduce', 'reduce'), ('computing', 'computing'), ('time', 'time'), ('data', 'data')]



========================================== PARAGRAPH 272 ===========================================

Page 19 of 32Tsai et al. Journal of Big Data  (2015) 2:21  

------------------- Sentence 1 -------------------

Page 19 of 32Tsai et al.

>> Tokens are: 
 ['Page', '19', '32Tsai', 'et', 'al', '.']

>> Bigrams are: 
 [('Page', '19'), ('19', '32Tsai'), ('32Tsai', 'et'), ('et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('Page', '19', '32Tsai'), ('19', '32Tsai', 'et'), ('32Tsai', 'et', 'al'), ('et', 'al', '.')]

>> POS Tags are: 
 [('Page', 'NN'), ('19', 'CD'), ('32Tsai', 'CD'), ('et', 'NN'), ('al', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Page', 'et al']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Page', 'page'), ('19', '19'), ('32Tsai', '32tsai'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Page', 'page'), ('19', '19'), ('32Tsai', '32tsai'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('Page', 'Page'), ('19', '19'), ('32Tsai', '32Tsai'), ('et', 'et'), ('al', 'al'), ('.', '.')]


------------------- Sentence 2 -------------------

Journal of Big Data  (2015) 2:21

>> Tokens are: 
 ['Journal', 'Big', 'Data', '(', '2015', ')', '2:21']

>> Bigrams are: 
 [('Journal', 'Big'), ('Big', 'Data'), ('Data', '('), ('(', '2015'), ('2015', ')'), (')', '2:21')]

>> Trigrams are: 
 [('Journal', 'Big', 'Data'), ('Big', 'Data', '('), ('Data', '(', '2015'), ('(', '2015', ')'), ('2015', ')', '2:21')]

>> POS Tags are: 
 [('Journal', 'NNP'), ('Big', 'NNP'), ('Data', 'NNP'), ('(', '('), ('2015', 'CD'), (')', ')'), ('2:21', 'CD')]

>> Noun Phrases are: 
 ['Journal Big Data']

>> Named Entities are: 
 [('PERSON', 'Journal')] 

>> Stemming using Porter Stemmer: 
 [('Journal', 'journal'), ('Big', 'big'), ('Data', 'data'), ('(', '('), ('2015', '2015'), (')', ')'), ('2:21', '2:21')]

>> Stemming using Snowball Stemmer: 
 [('Journal', 'journal'), ('Big', 'big'), ('Data', 'data'), ('(', '('), ('2015', '2015'), (')', ')'), ('2:21', '2:21')]

>> Lemmatization: 
 [('Journal', 'Journal'), ('Big', 'Big'), ('Data', 'Data'), ('(', '('), ('2015', '2015'), (')', ')'), ('2:21', '2:21')]



========================================== PARAGRAPH 273 ===========================================

analysis. Hasan et  al. [126] used CUDA to implement the self-organizing map (SOM)  and multiple back-propagation (MBP) for the classification problem. The simulation  results show that using GPU is faster than using CPU. More precisely, SOM running on  a GPU is three times faster than SOM running on a CPU, and MPB running on a GPU is  twenty-seven times faster than MPB running on a. Another study [127] attempted to  apply the ant-based algorithm to grid computing platform. Since the proposed mining  algorithm is extended by the ant clustering algorithm of Deneubourg et  al. [128],6   

------------------- Sentence 1 -------------------

analysis.

>> Tokens are: 
 ['analysis', '.']

>> Bigrams are: 
 [('analysis', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('analysis', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['analysis']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('analysis', 'analysi'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('analysis', 'analysi'), ('.', '.')]

>> Lemmatization: 
 [('analysis', 'analysis'), ('.', '.')]


------------------- Sentence 2 -------------------

Hasan et  al.

>> Tokens are: 
 ['Hasan', 'et', 'al', '.']

>> Bigrams are: 
 [('Hasan', 'et'), ('et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('Hasan', 'et', 'al'), ('et', 'al', '.')]

>> POS Tags are: 
 [('Hasan', 'NNP'), ('et', 'CC'), ('al', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Hasan', 'al']

>> Named Entities are: 
 [('GPE', 'Hasan')] 

>> Stemming using Porter Stemmer: 
 [('Hasan', 'hasan'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Hasan', 'hasan'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('Hasan', 'Hasan'), ('et', 'et'), ('al', 'al'), ('.', '.')]


------------------- Sentence 3 -------------------

[126] used CUDA to implement the self-organizing map (SOM)  and multiple back-propagation (MBP) for the classification problem.

>> Tokens are: 
 ['[', '126', ']', 'used', 'CUDA', 'implement', 'self-organizing', 'map', '(', 'SOM', ')', 'multiple', 'back-propagation', '(', 'MBP', ')', 'classification', 'problem', '.']

>> Bigrams are: 
 [('[', '126'), ('126', ']'), (']', 'used'), ('used', 'CUDA'), ('CUDA', 'implement'), ('implement', 'self-organizing'), ('self-organizing', 'map'), ('map', '('), ('(', 'SOM'), ('SOM', ')'), (')', 'multiple'), ('multiple', 'back-propagation'), ('back-propagation', '('), ('(', 'MBP'), ('MBP', ')'), (')', 'classification'), ('classification', 'problem'), ('problem', '.')]

>> Trigrams are: 
 [('[', '126', ']'), ('126', ']', 'used'), (']', 'used', 'CUDA'), ('used', 'CUDA', 'implement'), ('CUDA', 'implement', 'self-organizing'), ('implement', 'self-organizing', 'map'), ('self-organizing', 'map', '('), ('map', '(', 'SOM'), ('(', 'SOM', ')'), ('SOM', ')', 'multiple'), (')', 'multiple', 'back-propagation'), ('multiple', 'back-propagation', '('), ('back-propagation', '(', 'MBP'), ('(', 'MBP', ')'), ('MBP', ')', 'classification'), (')', 'classification', 'problem'), ('classification', 'problem', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('126', 'CD'), (']', 'NNS'), ('used', 'VBN'), ('CUDA', 'NNP'), ('implement', 'JJ'), ('self-organizing', 'JJ'), ('map', 'NN'), ('(', '('), ('SOM', 'NNP'), (')', ')'), ('multiple', 'VBD'), ('back-propagation', 'NN'), ('(', '('), ('MBP', 'NNP'), (')', ')'), ('classification', 'NN'), ('problem', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 [']', 'CUDA', 'implement self-organizing map', 'SOM', 'back-propagation', 'MBP', 'classification problem']

>> Named Entities are: 
 [('ORGANIZATION', 'CUDA'), ('ORGANIZATION', 'SOM'), ('ORGANIZATION', 'MBP')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('126', '126'), (']', ']'), ('used', 'use'), ('CUDA', 'cuda'), ('implement', 'implement'), ('self-organizing', 'self-organ'), ('map', 'map'), ('(', '('), ('SOM', 'som'), (')', ')'), ('multiple', 'multipl'), ('back-propagation', 'back-propag'), ('(', '('), ('MBP', 'mbp'), (')', ')'), ('classification', 'classif'), ('problem', 'problem'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('126', '126'), (']', ']'), ('used', 'use'), ('CUDA', 'cuda'), ('implement', 'implement'), ('self-organizing', 'self-organ'), ('map', 'map'), ('(', '('), ('SOM', 'som'), (')', ')'), ('multiple', 'multipl'), ('back-propagation', 'back-propag'), ('(', '('), ('MBP', 'mbp'), (')', ')'), ('classification', 'classif'), ('problem', 'problem'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('126', '126'), (']', ']'), ('used', 'used'), ('CUDA', 'CUDA'), ('implement', 'implement'), ('self-organizing', 'self-organizing'), ('map', 'map'), ('(', '('), ('SOM', 'SOM'), (')', ')'), ('multiple', 'multiple'), ('back-propagation', 'back-propagation'), ('(', '('), ('MBP', 'MBP'), (')', ')'), ('classification', 'classification'), ('problem', 'problem'), ('.', '.')]


------------------- Sentence 4 -------------------

The simulation  results show that using GPU is faster than using CPU.

>> Tokens are: 
 ['The', 'simulation', 'results', 'show', 'using', 'GPU', 'faster', 'using', 'CPU', '.']

>> Bigrams are: 
 [('The', 'simulation'), ('simulation', 'results'), ('results', 'show'), ('show', 'using'), ('using', 'GPU'), ('GPU', 'faster'), ('faster', 'using'), ('using', 'CPU'), ('CPU', '.')]

>> Trigrams are: 
 [('The', 'simulation', 'results'), ('simulation', 'results', 'show'), ('results', 'show', 'using'), ('show', 'using', 'GPU'), ('using', 'GPU', 'faster'), ('GPU', 'faster', 'using'), ('faster', 'using', 'CPU'), ('using', 'CPU', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('simulation', 'NN'), ('results', 'NNS'), ('show', 'VBP'), ('using', 'VBG'), ('GPU', 'NNP'), ('faster', 'RBR'), ('using', 'VBG'), ('CPU', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['The simulation results', 'GPU', 'CPU']

>> Named Entities are: 
 [('ORGANIZATION', 'GPU'), ('ORGANIZATION', 'CPU')] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('simulation', 'simul'), ('results', 'result'), ('show', 'show'), ('using', 'use'), ('GPU', 'gpu'), ('faster', 'faster'), ('using', 'use'), ('CPU', 'cpu'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('simulation', 'simul'), ('results', 'result'), ('show', 'show'), ('using', 'use'), ('GPU', 'gpu'), ('faster', 'faster'), ('using', 'use'), ('CPU', 'cpu'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('simulation', 'simulation'), ('results', 'result'), ('show', 'show'), ('using', 'using'), ('GPU', 'GPU'), ('faster', 'faster'), ('using', 'using'), ('CPU', 'CPU'), ('.', '.')]


------------------- Sentence 5 -------------------

More precisely, SOM running on  a GPU is three times faster than SOM running on a CPU, and MPB running on a GPU is  twenty-seven times faster than MPB running on a.

>> Tokens are: 
 ['More', 'precisely', ',', 'SOM', 'running', 'GPU', 'three', 'times', 'faster', 'SOM', 'running', 'CPU', ',', 'MPB', 'running', 'GPU', 'twenty-seven', 'times', 'faster', 'MPB', 'running', '.']

>> Bigrams are: 
 [('More', 'precisely'), ('precisely', ','), (',', 'SOM'), ('SOM', 'running'), ('running', 'GPU'), ('GPU', 'three'), ('three', 'times'), ('times', 'faster'), ('faster', 'SOM'), ('SOM', 'running'), ('running', 'CPU'), ('CPU', ','), (',', 'MPB'), ('MPB', 'running'), ('running', 'GPU'), ('GPU', 'twenty-seven'), ('twenty-seven', 'times'), ('times', 'faster'), ('faster', 'MPB'), ('MPB', 'running'), ('running', '.')]

>> Trigrams are: 
 [('More', 'precisely', ','), ('precisely', ',', 'SOM'), (',', 'SOM', 'running'), ('SOM', 'running', 'GPU'), ('running', 'GPU', 'three'), ('GPU', 'three', 'times'), ('three', 'times', 'faster'), ('times', 'faster', 'SOM'), ('faster', 'SOM', 'running'), ('SOM', 'running', 'CPU'), ('running', 'CPU', ','), ('CPU', ',', 'MPB'), (',', 'MPB', 'running'), ('MPB', 'running', 'GPU'), ('running', 'GPU', 'twenty-seven'), ('GPU', 'twenty-seven', 'times'), ('twenty-seven', 'times', 'faster'), ('times', 'faster', 'MPB'), ('faster', 'MPB', 'running'), ('MPB', 'running', '.')]

>> POS Tags are: 
 [('More', 'RBR'), ('precisely', 'RB'), (',', ','), ('SOM', 'NNP'), ('running', 'VBG'), ('GPU', 'NNP'), ('three', 'CD'), ('times', 'NNS'), ('faster', 'RBR'), ('SOM', 'NNP'), ('running', 'VBG'), ('CPU', 'NNP'), (',', ','), ('MPB', 'NNP'), ('running', 'VBG'), ('GPU', 'NNP'), ('twenty-seven', 'JJ'), ('times', 'NNS'), ('faster', 'RBR'), ('MPB', 'NNP'), ('running', 'VBG'), ('.', '.')]

>> Noun Phrases are: 
 ['SOM', 'GPU', 'times', 'SOM', 'CPU', 'MPB', 'GPU', 'twenty-seven times', 'MPB']

>> Named Entities are: 
 [('ORGANIZATION', 'SOM'), ('ORGANIZATION', 'GPU'), ('ORGANIZATION', 'CPU'), ('ORGANIZATION', 'MPB'), ('ORGANIZATION', 'GPU')] 

>> Stemming using Porter Stemmer: 
 [('More', 'more'), ('precisely', 'precis'), (',', ','), ('SOM', 'som'), ('running', 'run'), ('GPU', 'gpu'), ('three', 'three'), ('times', 'time'), ('faster', 'faster'), ('SOM', 'som'), ('running', 'run'), ('CPU', 'cpu'), (',', ','), ('MPB', 'mpb'), ('running', 'run'), ('GPU', 'gpu'), ('twenty-seven', 'twenty-seven'), ('times', 'time'), ('faster', 'faster'), ('MPB', 'mpb'), ('running', 'run'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('More', 'more'), ('precisely', 'precis'), (',', ','), ('SOM', 'som'), ('running', 'run'), ('GPU', 'gpu'), ('three', 'three'), ('times', 'time'), ('faster', 'faster'), ('SOM', 'som'), ('running', 'run'), ('CPU', 'cpu'), (',', ','), ('MPB', 'mpb'), ('running', 'run'), ('GPU', 'gpu'), ('twenty-seven', 'twenty-seven'), ('times', 'time'), ('faster', 'faster'), ('MPB', 'mpb'), ('running', 'run'), ('.', '.')]

>> Lemmatization: 
 [('More', 'More'), ('precisely', 'precisely'), (',', ','), ('SOM', 'SOM'), ('running', 'running'), ('GPU', 'GPU'), ('three', 'three'), ('times', 'time'), ('faster', 'faster'), ('SOM', 'SOM'), ('running', 'running'), ('CPU', 'CPU'), (',', ','), ('MPB', 'MPB'), ('running', 'running'), ('GPU', 'GPU'), ('twenty-seven', 'twenty-seven'), ('times', 'time'), ('faster', 'faster'), ('MPB', 'MPB'), ('running', 'running'), ('.', '.')]


------------------- Sentence 6 -------------------

Another study [127] attempted to  apply the ant-based algorithm to grid computing platform.

>> Tokens are: 
 ['Another', 'study', '[', '127', ']', 'attempted', 'apply', 'ant-based', 'algorithm', 'grid', 'computing', 'platform', '.']

>> Bigrams are: 
 [('Another', 'study'), ('study', '['), ('[', '127'), ('127', ']'), (']', 'attempted'), ('attempted', 'apply'), ('apply', 'ant-based'), ('ant-based', 'algorithm'), ('algorithm', 'grid'), ('grid', 'computing'), ('computing', 'platform'), ('platform', '.')]

>> Trigrams are: 
 [('Another', 'study', '['), ('study', '[', '127'), ('[', '127', ']'), ('127', ']', 'attempted'), (']', 'attempted', 'apply'), ('attempted', 'apply', 'ant-based'), ('apply', 'ant-based', 'algorithm'), ('ant-based', 'algorithm', 'grid'), ('algorithm', 'grid', 'computing'), ('grid', 'computing', 'platform'), ('computing', 'platform', '.')]

>> POS Tags are: 
 [('Another', 'DT'), ('study', 'NN'), ('[', 'VBD'), ('127', 'CD'), (']', 'NN'), ('attempted', 'VBD'), ('apply', 'RB'), ('ant-based', 'JJ'), ('algorithm', 'NN'), ('grid', 'NN'), ('computing', 'VBG'), ('platform', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Another study', ']', 'ant-based algorithm grid', 'platform']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Another', 'anoth'), ('study', 'studi'), ('[', '['), ('127', '127'), (']', ']'), ('attempted', 'attempt'), ('apply', 'appli'), ('ant-based', 'ant-bas'), ('algorithm', 'algorithm'), ('grid', 'grid'), ('computing', 'comput'), ('platform', 'platform'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Another', 'anoth'), ('study', 'studi'), ('[', '['), ('127', '127'), (']', ']'), ('attempted', 'attempt'), ('apply', 'appli'), ('ant-based', 'ant-bas'), ('algorithm', 'algorithm'), ('grid', 'grid'), ('computing', 'comput'), ('platform', 'platform'), ('.', '.')]

>> Lemmatization: 
 [('Another', 'Another'), ('study', 'study'), ('[', '['), ('127', '127'), (']', ']'), ('attempted', 'attempted'), ('apply', 'apply'), ('ant-based', 'ant-based'), ('algorithm', 'algorithm'), ('grid', 'grid'), ('computing', 'computing'), ('platform', 'platform'), ('.', '.')]


------------------- Sentence 7 -------------------

Since the proposed mining  algorithm is extended by the ant clustering algorithm of Deneubourg et  al.

>> Tokens are: 
 ['Since', 'proposed', 'mining', 'algorithm', 'extended', 'ant', 'clustering', 'algorithm', 'Deneubourg', 'et', 'al', '.']

>> Bigrams are: 
 [('Since', 'proposed'), ('proposed', 'mining'), ('mining', 'algorithm'), ('algorithm', 'extended'), ('extended', 'ant'), ('ant', 'clustering'), ('clustering', 'algorithm'), ('algorithm', 'Deneubourg'), ('Deneubourg', 'et'), ('et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('Since', 'proposed', 'mining'), ('proposed', 'mining', 'algorithm'), ('mining', 'algorithm', 'extended'), ('algorithm', 'extended', 'ant'), ('extended', 'ant', 'clustering'), ('ant', 'clustering', 'algorithm'), ('clustering', 'algorithm', 'Deneubourg'), ('algorithm', 'Deneubourg', 'et'), ('Deneubourg', 'et', 'al'), ('et', 'al', '.')]

>> POS Tags are: 
 [('Since', 'IN'), ('proposed', 'VBN'), ('mining', 'NN'), ('algorithm', 'NN'), ('extended', 'VBD'), ('ant', 'JJ'), ('clustering', 'VBG'), ('algorithm', 'JJ'), ('Deneubourg', 'NNP'), ('et', 'NN'), ('al', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['mining algorithm', 'algorithm Deneubourg et al']

>> Named Entities are: 
 [('ORGANIZATION', 'Deneubourg')] 

>> Stemming using Porter Stemmer: 
 [('Since', 'sinc'), ('proposed', 'propos'), ('mining', 'mine'), ('algorithm', 'algorithm'), ('extended', 'extend'), ('ant', 'ant'), ('clustering', 'cluster'), ('algorithm', 'algorithm'), ('Deneubourg', 'deneubourg'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Since', 'sinc'), ('proposed', 'propos'), ('mining', 'mine'), ('algorithm', 'algorithm'), ('extended', 'extend'), ('ant', 'ant'), ('clustering', 'cluster'), ('algorithm', 'algorithm'), ('Deneubourg', 'deneubourg'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('Since', 'Since'), ('proposed', 'proposed'), ('mining', 'mining'), ('algorithm', 'algorithm'), ('extended', 'extended'), ('ant', 'ant'), ('clustering', 'clustering'), ('algorithm', 'algorithm'), ('Deneubourg', 'Deneubourg'), ('et', 'et'), ('al', 'al'), ('.', '.')]


------------------- Sentence 8 -------------------

[128],6

>> Tokens are: 
 ['[', '128', ']', ',6']

>> Bigrams are: 
 [('[', '128'), ('128', ']'), (']', ',6')]

>> Trigrams are: 
 [('[', '128', ']'), ('128', ']', ',6')]

>> POS Tags are: 
 [('[', 'RB'), ('128', 'CD'), (']', 'NNS'), (',6', 'VBP')]

>> Noun Phrases are: 
 [']']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('128', '128'), (']', ']'), (',6', ',6')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('128', '128'), (']', ']'), (',6', ',6')]

>> Lemmatization: 
 [('[', '['), ('128', '128'), (']', ']'), (',6', ',6')]



========================================== PARAGRAPH 274 ===========================================

6 The basic idea of [128] is that each ant will pick up and drop data items in terms of the similarity of its local neighbors. 

------------------- Sentence 1 -------------------

6 The basic idea of [128] is that each ant will pick up and drop data items in terms of the similarity of its local neighbors.

>> Tokens are: 
 ['6', 'The', 'basic', 'idea', '[', '128', ']', 'ant', 'pick', 'drop', 'data', 'items', 'terms', 'similarity', 'local', 'neighbors', '.']

>> Bigrams are: 
 [('6', 'The'), ('The', 'basic'), ('basic', 'idea'), ('idea', '['), ('[', '128'), ('128', ']'), (']', 'ant'), ('ant', 'pick'), ('pick', 'drop'), ('drop', 'data'), ('data', 'items'), ('items', 'terms'), ('terms', 'similarity'), ('similarity', 'local'), ('local', 'neighbors'), ('neighbors', '.')]

>> Trigrams are: 
 [('6', 'The', 'basic'), ('The', 'basic', 'idea'), ('basic', 'idea', '['), ('idea', '[', '128'), ('[', '128', ']'), ('128', ']', 'ant'), (']', 'ant', 'pick'), ('ant', 'pick', 'drop'), ('pick', 'drop', 'data'), ('drop', 'data', 'items'), ('data', 'items', 'terms'), ('items', 'terms', 'similarity'), ('terms', 'similarity', 'local'), ('similarity', 'local', 'neighbors'), ('local', 'neighbors', '.')]

>> POS Tags are: 
 [('6', 'CD'), ('The', 'DT'), ('basic', 'JJ'), ('idea', 'NN'), ('[', 'VBD'), ('128', 'CD'), (']', 'NNP'), ('ant', 'JJ'), ('pick', 'NN'), ('drop', 'NN'), ('data', 'NNS'), ('items', 'NNS'), ('terms', 'NNS'), ('similarity', 'VBP'), ('local', 'JJ'), ('neighbors', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['The basic idea', ']', 'ant pick drop data items terms', 'local neighbors']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('6', '6'), ('The', 'the'), ('basic', 'basic'), ('idea', 'idea'), ('[', '['), ('128', '128'), (']', ']'), ('ant', 'ant'), ('pick', 'pick'), ('drop', 'drop'), ('data', 'data'), ('items', 'item'), ('terms', 'term'), ('similarity', 'similar'), ('local', 'local'), ('neighbors', 'neighbor'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('6', '6'), ('The', 'the'), ('basic', 'basic'), ('idea', 'idea'), ('[', '['), ('128', '128'), (']', ']'), ('ant', 'ant'), ('pick', 'pick'), ('drop', 'drop'), ('data', 'data'), ('items', 'item'), ('terms', 'term'), ('similarity', 'similar'), ('local', 'local'), ('neighbors', 'neighbor'), ('.', '.')]

>> Lemmatization: 
 [('6', '6'), ('The', 'The'), ('basic', 'basic'), ('idea', 'idea'), ('[', '['), ('128', '128'), (']', ']'), ('ant', 'ant'), ('pick', 'pick'), ('drop', 'drop'), ('data', 'data'), ('items', 'item'), ('terms', 'term'), ('similarity', 'similarity'), ('local', 'local'), ('neighbors', 'neighbor'), ('.', '.')]



========================================== PARAGRAPH 275 ===========================================

Population 

------------------- Sentence 1 -------------------

Population

>> Tokens are: 
 ['Population']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Population', 'NN')]

>> Noun Phrases are: 
 ['Population']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Population', 'popul')]

>> Stemming using Snowball Stemmer: 
 [('Population', 'popul')]

>> Lemmatization: 
 [('Population', 'Population')]



========================================== PARAGRAPH 276 ===========================================

Crossover Mutation Selectionlt 

------------------- Sentence 1 -------------------

Crossover Mutation Selectionlt

>> Tokens are: 
 ['Crossover', 'Mutation', 'Selectionlt']

>> Bigrams are: 
 [('Crossover', 'Mutation'), ('Mutation', 'Selectionlt')]

>> Trigrams are: 
 [('Crossover', 'Mutation', 'Selectionlt')]

>> POS Tags are: 
 [('Crossover', 'NNP'), ('Mutation', 'NNP'), ('Selectionlt', 'NNP')]

>> Noun Phrases are: 
 ['Crossover Mutation Selectionlt']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Crossover', 'crossov'), ('Mutation', 'mutat'), ('Selectionlt', 'selectionlt')]

>> Stemming using Snowball Stemmer: 
 [('Crossover', 'crossov'), ('Mutation', 'mutat'), ('Selectionlt', 'selectionlt')]

>> Lemmatization: 
 [('Crossover', 'Crossover'), ('Mutation', 'Mutation'), ('Selectionlt', 'Selectionlt')]



========================================== PARAGRAPH 277 ===========================================

er at 

------------------- Sentence 1 -------------------

er at

>> Tokens are: 
 ['er']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('er', 'NN')]

>> Noun Phrases are: 
 ['er']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('er', 'er')]

>> Stemming using Snowball Stemmer: 
 [('er', 'er')]

>> Lemmatization: 
 [('er', 'er')]



========================================== PARAGRAPH 278 ===========================================

io n 

------------------- Sentence 1 -------------------

io n

>> Tokens are: 
 ['io', 'n']

>> Bigrams are: 
 [('io', 'n')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('io', 'NN'), ('n', 'NN')]

>> Noun Phrases are: 
 ['io n']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('io', 'io'), ('n', 'n')]

>> Stemming using Snowball Stemmer: 
 [('io', 'io'), ('n', 'n')]

>> Lemmatization: 
 [('io', 'io'), ('n', 'n')]



========================================== PARAGRAPH 279 ===========================================

Result 

------------------- Sentence 1 -------------------

Result

>> Tokens are: 
 ['Result']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Result', 'NN')]

>> Noun Phrases are: 
 ['Result']

>> Named Entities are: 
 [('GPE', 'Result')] 

>> Stemming using Porter Stemmer: 
 [('Result', 'result')]

>> Stemming using Snowball Stemmer: 
 [('Result', 'result')]

>> Lemmatization: 
 [('Result', 'Result')]



========================================== PARAGRAPH 280 ===========================================

a Traditional GA. 

------------------- Sentence 1 -------------------

a Traditional GA.

>> Tokens are: 
 ['Traditional', 'GA', '.']

>> Bigrams are: 
 [('Traditional', 'GA'), ('GA', '.')]

>> Trigrams are: 
 [('Traditional', 'GA', '.')]

>> POS Tags are: 
 [('Traditional', 'JJ'), ('GA', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Traditional GA']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Traditional', 'tradit'), ('GA', 'ga'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Traditional', 'tradit'), ('GA', 'ga'), ('.', '.')]

>> Lemmatization: 
 [('Traditional', 'Traditional'), ('GA', 'GA'), ('.', '.')]



========================================== PARAGRAPH 281 ===========================================

Crossover Mutation Selectionlt 

------------------- Sentence 1 -------------------

Crossover Mutation Selectionlt

>> Tokens are: 
 ['Crossover', 'Mutation', 'Selectionlt']

>> Bigrams are: 
 [('Crossover', 'Mutation'), ('Mutation', 'Selectionlt')]

>> Trigrams are: 
 [('Crossover', 'Mutation', 'Selectionlt')]

>> POS Tags are: 
 [('Crossover', 'NNP'), ('Mutation', 'NNP'), ('Selectionlt', 'NNP')]

>> Noun Phrases are: 
 ['Crossover Mutation Selectionlt']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Crossover', 'crossov'), ('Mutation', 'mutat'), ('Selectionlt', 'selectionlt')]

>> Stemming using Snowball Stemmer: 
 [('Crossover', 'crossov'), ('Mutation', 'mutat'), ('Selectionlt', 'selectionlt')]

>> Lemmatization: 
 [('Crossover', 'Crossover'), ('Mutation', 'Mutation'), ('Selectionlt', 'Selectionlt')]



========================================== PARAGRAPH 282 ===========================================

er at 

------------------- Sentence 1 -------------------

er at

>> Tokens are: 
 ['er']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('er', 'NN')]

>> Noun Phrases are: 
 ['er']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('er', 'er')]

>> Stemming using Snowball Stemmer: 
 [('er', 'er')]

>> Lemmatization: 
 [('er', 'er')]



========================================== PARAGRAPH 283 ===========================================

io n 

------------------- Sentence 1 -------------------

io n

>> Tokens are: 
 ['io', 'n']

>> Bigrams are: 
 [('io', 'n')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('io', 'NN'), ('n', 'NN')]

>> Noun Phrases are: 
 ['io n']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('io', 'io'), ('n', 'n')]

>> Stemming using Snowball Stemmer: 
 [('io', 'io'), ('n', 'n')]

>> Lemmatization: 
 [('io', 'io'), ('n', 'n')]



========================================== PARAGRAPH 284 ===========================================

sub−population sub−population 

------------------- Sentence 1 -------------------

sub−population sub−population

>> Tokens are: 
 ['sub−population', 'sub−population']

>> Bigrams are: 
 [('sub−population', 'sub−population')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('sub−population', 'NN'), ('sub−population', 'NN')]

>> Noun Phrases are: 
 ['sub−population sub−population']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('sub−population', 'sub−popul'), ('sub−population', 'sub−popul')]

>> Stemming using Snowball Stemmer: 
 [('sub−population', 'sub−popul'), ('sub−population', 'sub−popul')]

>> Lemmatization: 
 [('sub−population', 'sub−population'), ('sub−population', 'sub−population')]



========================================== PARAGRAPH 285 ===========================================

sub−population sub−population 

------------------- Sentence 1 -------------------

sub−population sub−population

>> Tokens are: 
 ['sub−population', 'sub−population']

>> Bigrams are: 
 [('sub−population', 'sub−population')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('sub−population', 'NN'), ('sub−population', 'NN')]

>> Noun Phrases are: 
 ['sub−population sub−population']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('sub−population', 'sub−popul'), ('sub−population', 'sub−popul')]

>> Stemming using Snowball Stemmer: 
 [('sub−population', 'sub−popul'), ('sub−population', 'sub−popul')]

>> Lemmatization: 
 [('sub−population', 'sub−population'), ('sub−population', 'sub−population')]



========================================== PARAGRAPH 286 ===========================================

Crossover Mutation Selection 

------------------- Sentence 1 -------------------

Crossover Mutation Selection

>> Tokens are: 
 ['Crossover', 'Mutation', 'Selection']

>> Bigrams are: 
 [('Crossover', 'Mutation'), ('Mutation', 'Selection')]

>> Trigrams are: 
 [('Crossover', 'Mutation', 'Selection')]

>> POS Tags are: 
 [('Crossover', 'NNP'), ('Mutation', 'NNP'), ('Selection', 'NNP')]

>> Noun Phrases are: 
 ['Crossover Mutation Selection']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Crossover', 'crossov'), ('Mutation', 'mutat'), ('Selection', 'select')]

>> Stemming using Snowball Stemmer: 
 [('Crossover', 'crossov'), ('Mutation', 'mutat'), ('Selection', 'select')]

>> Lemmatization: 
 [('Crossover', 'Crossover'), ('Mutation', 'Mutation'), ('Selection', 'Selection')]



========================================== PARAGRAPH 287 ===========================================

Crossover Mutation Selection 

------------------- Sentence 1 -------------------

Crossover Mutation Selection

>> Tokens are: 
 ['Crossover', 'Mutation', 'Selection']

>> Bigrams are: 
 [('Crossover', 'Mutation'), ('Mutation', 'Selection')]

>> Trigrams are: 
 [('Crossover', 'Mutation', 'Selection')]

>> POS Tags are: 
 [('Crossover', 'NNP'), ('Mutation', 'NNP'), ('Selection', 'NNP')]

>> Noun Phrases are: 
 ['Crossover Mutation Selection']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Crossover', 'crossov'), ('Mutation', 'mutat'), ('Selection', 'select')]

>> Stemming using Snowball Stemmer: 
 [('Crossover', 'crossov'), ('Mutation', 'mutat'), ('Selection', 'select')]

>> Lemmatization: 
 [('Crossover', 'Crossover'), ('Mutation', 'Mutation'), ('Selection', 'Selection')]



========================================== PARAGRAPH 288 ===========================================

Crossover Mutation Selectionlt 

------------------- Sentence 1 -------------------

Crossover Mutation Selectionlt

>> Tokens are: 
 ['Crossover', 'Mutation', 'Selectionlt']

>> Bigrams are: 
 [('Crossover', 'Mutation'), ('Mutation', 'Selectionlt')]

>> Trigrams are: 
 [('Crossover', 'Mutation', 'Selectionlt')]

>> POS Tags are: 
 [('Crossover', 'NNP'), ('Mutation', 'NNP'), ('Selectionlt', 'NNP')]

>> Noun Phrases are: 
 ['Crossover Mutation Selectionlt']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Crossover', 'crossov'), ('Mutation', 'mutat'), ('Selectionlt', 'selectionlt')]

>> Stemming using Snowball Stemmer: 
 [('Crossover', 'crossov'), ('Mutation', 'mutat'), ('Selectionlt', 'selectionlt')]

>> Lemmatization: 
 [('Crossover', 'Crossover'), ('Mutation', 'Mutation'), ('Selectionlt', 'Selectionlt')]



========================================== PARAGRAPH 289 ===========================================

er at 

------------------- Sentence 1 -------------------

er at

>> Tokens are: 
 ['er']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('er', 'NN')]

>> Noun Phrases are: 
 ['er']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('er', 'er')]

>> Stemming using Snowball Stemmer: 
 [('er', 'er')]

>> Lemmatization: 
 [('er', 'er')]



========================================== PARAGRAPH 290 ===========================================

io n lteration 

------------------- Sentence 1 -------------------

io n lteration

>> Tokens are: 
 ['io', 'n', 'lteration']

>> Bigrams are: 
 [('io', 'n'), ('n', 'lteration')]

>> Trigrams are: 
 [('io', 'n', 'lteration')]

>> POS Tags are: 
 [('io', 'NN'), ('n', 'DT'), ('lteration', 'NN')]

>> Noun Phrases are: 
 ['io', 'n lteration']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('io', 'io'), ('n', 'n'), ('lteration', 'lterat')]

>> Stemming using Snowball Stemmer: 
 [('io', 'io'), ('n', 'n'), ('lteration', 'lterat')]

>> Lemmatization: 
 [('io', 'io'), ('n', 'n'), ('lteration', 'lteration')]



========================================== PARAGRAPH 291 ===========================================

lteration 

------------------- Sentence 1 -------------------

lteration

>> Tokens are: 
 ['lteration']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('lteration', 'NN')]

>> Noun Phrases are: 
 ['lteration']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('lteration', 'lterat')]

>> Stemming using Snowball Stemmer: 
 [('lteration', 'lterat')]

>> Lemmatization: 
 [('lteration', 'lteration')]



========================================== PARAGRAPH 292 ===========================================

migration 

------------------- Sentence 1 -------------------

migration

>> Tokens are: 
 ['migration']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('migration', 'NN')]

>> Noun Phrases are: 
 ['migration']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('migration', 'migrat')]

>> Stemming using Snowball Stemmer: 
 [('migration', 'migrat')]

>> Lemmatization: 
 [('migration', 'migration')]



========================================== PARAGRAPH 293 ===========================================

migration 

------------------- Sentence 1 -------------------

migration

>> Tokens are: 
 ['migration']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('migration', 'NN')]

>> Noun Phrases are: 
 ['migration']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('migration', 'migrat')]

>> Stemming using Snowball Stemmer: 
 [('migration', 'migrat')]

>> Lemmatization: 
 [('migration', 'migration')]



========================================== PARAGRAPH 294 ===========================================

m ig 

------------------- Sentence 1 -------------------

m ig

>> Tokens are: 
 ['ig']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('ig', 'NN')]

>> Noun Phrases are: 
 ['ig']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('ig', 'ig')]

>> Stemming using Snowball Stemmer: 
 [('ig', 'ig')]

>> Lemmatization: 
 [('ig', 'ig')]



========================================== PARAGRAPH 295 ===========================================

ra ti 

------------------- Sentence 1 -------------------

ra ti

>> Tokens are: 
 ['ra', 'ti']

>> Bigrams are: 
 [('ra', 'ti')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('ra', 'NN'), ('ti', 'NN')]

>> Noun Phrases are: 
 ['ra ti']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('ra', 'ra'), ('ti', 'ti')]

>> Stemming using Snowball Stemmer: 
 [('ra', 'ra'), ('ti', 'ti')]

>> Lemmatization: 
 [('ra', 'ra'), ('ti', 'ti')]



========================================== PARAGRAPH 296 ===========================================

on m 

------------------- Sentence 1 -------------------

on m

>> Tokens are: 
 []

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 []

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 []

>> Stemming using Snowball Stemmer: 
 []

>> Lemmatization: 
 []



========================================== PARAGRAPH 297 ===========================================

igration 

------------------- Sentence 1 -------------------

igration

>> Tokens are: 
 ['igration']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('igration', 'NN')]

>> Noun Phrases are: 
 ['igration']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('igration', 'igrat')]

>> Stemming using Snowball Stemmer: 
 [('igration', 'igrat')]

>> Lemmatization: 
 [('igration', 'igration')]



========================================== PARAGRAPH 298 ===========================================

Result 

------------------- Sentence 1 -------------------

Result

>> Tokens are: 
 ['Result']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Result', 'NN')]

>> Noun Phrases are: 
 ['Result']

>> Named Entities are: 
 [('GPE', 'Result')] 

>> Stemming using Porter Stemmer: 
 [('Result', 'result')]

>> Stemming using Snowball Stemmer: 
 [('Result', 'result')]

>> Lemmatization: 
 [('Result', 'Result')]



========================================== PARAGRAPH 299 ===========================================

b Island-model GA. Fig. 9 The comparison between basic idea of traditional GA (TGA) and parallel genetic algorithm (PGA) 

------------------- Sentence 1 -------------------

b Island-model GA.

>> Tokens are: 
 ['b', 'Island-model', 'GA', '.']

>> Bigrams are: 
 [('b', 'Island-model'), ('Island-model', 'GA'), ('GA', '.')]

>> Trigrams are: 
 [('b', 'Island-model', 'GA'), ('Island-model', 'GA', '.')]

>> POS Tags are: 
 [('b', 'SYM'), ('Island-model', 'NNP'), ('GA', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Island-model GA']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('b', 'b'), ('Island-model', 'island-model'), ('GA', 'ga'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('b', 'b'), ('Island-model', 'island-model'), ('GA', 'ga'), ('.', '.')]

>> Lemmatization: 
 [('b', 'b'), ('Island-model', 'Island-model'), ('GA', 'GA'), ('.', '.')]


------------------- Sentence 2 -------------------

Fig.

>> Tokens are: 
 ['Fig', '.']

>> Bigrams are: 
 [('Fig', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Fig', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Fig']

>> Named Entities are: 
 [('GPE', 'Fig')] 

>> Stemming using Porter Stemmer: 
 [('Fig', 'fig'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Fig', 'fig'), ('.', '.')]

>> Lemmatization: 
 [('Fig', 'Fig'), ('.', '.')]


------------------- Sentence 3 -------------------

9 The comparison between basic idea of traditional GA (TGA) and parallel genetic algorithm (PGA)

>> Tokens are: 
 ['9', 'The', 'comparison', 'basic', 'idea', 'traditional', 'GA', '(', 'TGA', ')', 'parallel', 'genetic', 'algorithm', '(', 'PGA', ')']

>> Bigrams are: 
 [('9', 'The'), ('The', 'comparison'), ('comparison', 'basic'), ('basic', 'idea'), ('idea', 'traditional'), ('traditional', 'GA'), ('GA', '('), ('(', 'TGA'), ('TGA', ')'), (')', 'parallel'), ('parallel', 'genetic'), ('genetic', 'algorithm'), ('algorithm', '('), ('(', 'PGA'), ('PGA', ')')]

>> Trigrams are: 
 [('9', 'The', 'comparison'), ('The', 'comparison', 'basic'), ('comparison', 'basic', 'idea'), ('basic', 'idea', 'traditional'), ('idea', 'traditional', 'GA'), ('traditional', 'GA', '('), ('GA', '(', 'TGA'), ('(', 'TGA', ')'), ('TGA', ')', 'parallel'), (')', 'parallel', 'genetic'), ('parallel', 'genetic', 'algorithm'), ('genetic', 'algorithm', '('), ('algorithm', '(', 'PGA'), ('(', 'PGA', ')')]

>> POS Tags are: 
 [('9', 'CD'), ('The', 'DT'), ('comparison', 'NN'), ('basic', 'JJ'), ('idea', 'NN'), ('traditional', 'JJ'), ('GA', 'NNP'), ('(', '('), ('TGA', 'NNP'), (')', ')'), ('parallel', 'VBP'), ('genetic', 'JJ'), ('algorithm', 'NN'), ('(', '('), ('PGA', 'NNP'), (')', ')')]

>> Noun Phrases are: 
 ['The comparison', 'basic idea', 'traditional GA', 'TGA', 'genetic algorithm', 'PGA']

>> Named Entities are: 
 [('ORGANIZATION', 'TGA'), ('ORGANIZATION', 'PGA')] 

>> Stemming using Porter Stemmer: 
 [('9', '9'), ('The', 'the'), ('comparison', 'comparison'), ('basic', 'basic'), ('idea', 'idea'), ('traditional', 'tradit'), ('GA', 'ga'), ('(', '('), ('TGA', 'tga'), (')', ')'), ('parallel', 'parallel'), ('genetic', 'genet'), ('algorithm', 'algorithm'), ('(', '('), ('PGA', 'pga'), (')', ')')]

>> Stemming using Snowball Stemmer: 
 [('9', '9'), ('The', 'the'), ('comparison', 'comparison'), ('basic', 'basic'), ('idea', 'idea'), ('traditional', 'tradit'), ('GA', 'ga'), ('(', '('), ('TGA', 'tga'), (')', ')'), ('parallel', 'parallel'), ('genetic', 'genet'), ('algorithm', 'algorithm'), ('(', '('), ('PGA', 'pga'), (')', ')')]

>> Lemmatization: 
 [('9', '9'), ('The', 'The'), ('comparison', 'comparison'), ('basic', 'basic'), ('idea', 'idea'), ('traditional', 'traditional'), ('GA', 'GA'), ('(', '('), ('TGA', 'TGA'), (')', ')'), ('parallel', 'parallel'), ('genetic', 'genetic'), ('algorithm', 'algorithm'), ('(', '('), ('PGA', 'PGA'), (')', ')')]



========================================== PARAGRAPH 300 ===========================================

Data Mining Algorithm Data Mining AlgorithmData Mining Algorithm Data Mining Algorithm 

------------------- Sentence 1 -------------------

Data Mining Algorithm Data Mining AlgorithmData Mining Algorithm Data Mining Algorithm

>> Tokens are: 
 ['Data', 'Mining', 'Algorithm', 'Data', 'Mining', 'AlgorithmData', 'Mining', 'Algorithm', 'Data', 'Mining', 'Algorithm']

>> Bigrams are: 
 [('Data', 'Mining'), ('Mining', 'Algorithm'), ('Algorithm', 'Data'), ('Data', 'Mining'), ('Mining', 'AlgorithmData'), ('AlgorithmData', 'Mining'), ('Mining', 'Algorithm'), ('Algorithm', 'Data'), ('Data', 'Mining'), ('Mining', 'Algorithm')]

>> Trigrams are: 
 [('Data', 'Mining', 'Algorithm'), ('Mining', 'Algorithm', 'Data'), ('Algorithm', 'Data', 'Mining'), ('Data', 'Mining', 'AlgorithmData'), ('Mining', 'AlgorithmData', 'Mining'), ('AlgorithmData', 'Mining', 'Algorithm'), ('Mining', 'Algorithm', 'Data'), ('Algorithm', 'Data', 'Mining'), ('Data', 'Mining', 'Algorithm')]

>> POS Tags are: 
 [('Data', 'NNP'), ('Mining', 'NNP'), ('Algorithm', 'NNP'), ('Data', 'NNP'), ('Mining', 'NNP'), ('AlgorithmData', 'NNP'), ('Mining', 'NNP'), ('Algorithm', 'NNP'), ('Data', 'NNP'), ('Mining', 'NNP'), ('Algorithm', 'NNP')]

>> Noun Phrases are: 
 ['Data Mining Algorithm Data Mining AlgorithmData Mining Algorithm Data Mining Algorithm']

>> Named Entities are: 
 [('PERSON', 'Data')] 

>> Stemming using Porter Stemmer: 
 [('Data', 'data'), ('Mining', 'mine'), ('Algorithm', 'algorithm'), ('Data', 'data'), ('Mining', 'mine'), ('AlgorithmData', 'algorithmdata'), ('Mining', 'mine'), ('Algorithm', 'algorithm'), ('Data', 'data'), ('Mining', 'mine'), ('Algorithm', 'algorithm')]

>> Stemming using Snowball Stemmer: 
 [('Data', 'data'), ('Mining', 'mine'), ('Algorithm', 'algorithm'), ('Data', 'data'), ('Mining', 'mine'), ('AlgorithmData', 'algorithmdata'), ('Mining', 'mine'), ('Algorithm', 'algorithm'), ('Data', 'data'), ('Mining', 'mine'), ('Algorithm', 'algorithm')]

>> Lemmatization: 
 [('Data', 'Data'), ('Mining', 'Mining'), ('Algorithm', 'Algorithm'), ('Data', 'Data'), ('Mining', 'Mining'), ('AlgorithmData', 'AlgorithmData'), ('Mining', 'Mining'), ('Algorithm', 'Algorithm'), ('Data', 'Data'), ('Mining', 'Mining'), ('Algorithm', 'Algorithm')]



========================================== PARAGRAPH 301 ===========================================

Data Source Data Source Data Source Data Source 

------------------- Sentence 1 -------------------

Data Source Data Source Data Source Data Source

>> Tokens are: 
 ['Data', 'Source', 'Data', 'Source', 'Data', 'Source', 'Data', 'Source']

>> Bigrams are: 
 [('Data', 'Source'), ('Source', 'Data'), ('Data', 'Source'), ('Source', 'Data'), ('Data', 'Source'), ('Source', 'Data'), ('Data', 'Source')]

>> Trigrams are: 
 [('Data', 'Source', 'Data'), ('Source', 'Data', 'Source'), ('Data', 'Source', 'Data'), ('Source', 'Data', 'Source'), ('Data', 'Source', 'Data'), ('Source', 'Data', 'Source')]

>> POS Tags are: 
 [('Data', 'NNP'), ('Source', 'NNP'), ('Data', 'NNP'), ('Source', 'NNP'), ('Data', 'NNP'), ('Source', 'NNP'), ('Data', 'NNP'), ('Source', 'NNP')]

>> Noun Phrases are: 
 ['Data Source Data Source Data Source Data Source']

>> Named Entities are: 
 [('PERSON', 'Data'), ('PERSON', 'Source Data Source Data Source Data Source')] 

>> Stemming using Porter Stemmer: 
 [('Data', 'data'), ('Source', 'sourc'), ('Data', 'data'), ('Source', 'sourc'), ('Data', 'data'), ('Source', 'sourc'), ('Data', 'data'), ('Source', 'sourc')]

>> Stemming using Snowball Stemmer: 
 [('Data', 'data'), ('Source', 'sourc'), ('Data', 'data'), ('Source', 'sourc'), ('Data', 'data'), ('Source', 'sourc'), ('Data', 'data'), ('Source', 'sourc')]

>> Lemmatization: 
 [('Data', 'Data'), ('Source', 'Source'), ('Data', 'Data'), ('Source', 'Source'), ('Data', 'Data'), ('Source', 'Source'), ('Data', 'Data'), ('Source', 'Source')]



========================================== PARAGRAPH 302 ===========================================

Local Model Local Model Local Model Local Model 

------------------- Sentence 1 -------------------

Local Model Local Model Local Model Local Model

>> Tokens are: 
 ['Local', 'Model', 'Local', 'Model', 'Local', 'Model', 'Local', 'Model']

>> Bigrams are: 
 [('Local', 'Model'), ('Model', 'Local'), ('Local', 'Model'), ('Model', 'Local'), ('Local', 'Model'), ('Model', 'Local'), ('Local', 'Model')]

>> Trigrams are: 
 [('Local', 'Model', 'Local'), ('Model', 'Local', 'Model'), ('Local', 'Model', 'Local'), ('Model', 'Local', 'Model'), ('Local', 'Model', 'Local'), ('Model', 'Local', 'Model')]

>> POS Tags are: 
 [('Local', 'JJ'), ('Model', 'NNP'), ('Local', 'NNP'), ('Model', 'NNP'), ('Local', 'NNP'), ('Model', 'NNP'), ('Local', 'NNP'), ('Model', 'NNP')]

>> Noun Phrases are: 
 ['Local Model Local Model Local Model Local Model']

>> Named Entities are: 
 [('PERSON', 'Local'), ('PERSON', 'Model Local Model Local Model Local Model')] 

>> Stemming using Porter Stemmer: 
 [('Local', 'local'), ('Model', 'model'), ('Local', 'local'), ('Model', 'model'), ('Local', 'local'), ('Model', 'model'), ('Local', 'local'), ('Model', 'model')]

>> Stemming using Snowball Stemmer: 
 [('Local', 'local'), ('Model', 'model'), ('Local', 'local'), ('Model', 'model'), ('Local', 'local'), ('Model', 'model'), ('Local', 'local'), ('Model', 'model')]

>> Lemmatization: 
 [('Local', 'Local'), ('Model', 'Model'), ('Local', 'Local'), ('Model', 'Model'), ('Local', 'Local'), ('Model', 'Model'), ('Local', 'Local'), ('Model', 'Model')]



========================================== PARAGRAPH 303 ===========================================

... 

------------------- Sentence 1 -------------------

...

>> Tokens are: 
 ['...']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('...', ':')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('...', '...')]

>> Stemming using Snowball Stemmer: 
 [('...', '...')]

>> Lemmatization: 
 [('...', '...')]



========================================== PARAGRAPH 304 ===========================================

Local Model Aggregation Final Model 

------------------- Sentence 1 -------------------

Local Model Aggregation Final Model

>> Tokens are: 
 ['Local', 'Model', 'Aggregation', 'Final', 'Model']

>> Bigrams are: 
 [('Local', 'Model'), ('Model', 'Aggregation'), ('Aggregation', 'Final'), ('Final', 'Model')]

>> Trigrams are: 
 [('Local', 'Model', 'Aggregation'), ('Model', 'Aggregation', 'Final'), ('Aggregation', 'Final', 'Model')]

>> POS Tags are: 
 [('Local', 'JJ'), ('Model', 'NNP'), ('Aggregation', 'NNP'), ('Final', 'NNP'), ('Model', 'NNP')]

>> Noun Phrases are: 
 ['Local Model Aggregation Final Model']

>> Named Entities are: 
 [('PERSON', 'Local'), ('PERSON', 'Model Aggregation Final Model')] 

>> Stemming using Porter Stemmer: 
 [('Local', 'local'), ('Model', 'model'), ('Aggregation', 'aggreg'), ('Final', 'final'), ('Model', 'model')]

>> Stemming using Snowball Stemmer: 
 [('Local', 'local'), ('Model', 'model'), ('Aggregation', 'aggreg'), ('Final', 'final'), ('Model', 'model')]

>> Lemmatization: 
 [('Local', 'Local'), ('Model', 'Model'), ('Aggregation', 'Aggregation'), ('Final', 'Final'), ('Model', 'Model')]



========================================== PARAGRAPH 305 ===========================================

Fig. 10 A simple example of distributed data mining framework [86]

------------------- Sentence 1 -------------------

Fig.

>> Tokens are: 
 ['Fig', '.']

>> Bigrams are: 
 [('Fig', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Fig', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Fig']

>> Named Entities are: 
 [('GPE', 'Fig')] 

>> Stemming using Porter Stemmer: 
 [('Fig', 'fig'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Fig', 'fig'), ('.', '.')]

>> Lemmatization: 
 [('Fig', 'Fig'), ('.', '.')]


------------------- Sentence 2 -------------------

10 A simple example of distributed data mining framework [86]

>> Tokens are: 
 ['10', 'A', 'simple', 'example', 'distributed', 'data', 'mining', 'framework', '[', '86', ']']

>> Bigrams are: 
 [('10', 'A'), ('A', 'simple'), ('simple', 'example'), ('example', 'distributed'), ('distributed', 'data'), ('data', 'mining'), ('mining', 'framework'), ('framework', '['), ('[', '86'), ('86', ']')]

>> Trigrams are: 
 [('10', 'A', 'simple'), ('A', 'simple', 'example'), ('simple', 'example', 'distributed'), ('example', 'distributed', 'data'), ('distributed', 'data', 'mining'), ('data', 'mining', 'framework'), ('mining', 'framework', '['), ('framework', '[', '86'), ('[', '86', ']')]

>> POS Tags are: 
 [('10', 'CD'), ('A', 'NNP'), ('simple', 'JJ'), ('example', 'NN'), ('distributed', 'VBN'), ('data', 'NNS'), ('mining', 'NN'), ('framework', 'NN'), ('[', '$'), ('86', 'CD'), (']', 'NN')]

>> Noun Phrases are: 
 ['A', 'simple example', 'data mining framework', ']']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('10', '10'), ('A', 'a'), ('simple', 'simpl'), ('example', 'exampl'), ('distributed', 'distribut'), ('data', 'data'), ('mining', 'mine'), ('framework', 'framework'), ('[', '['), ('86', '86'), (']', ']')]

>> Stemming using Snowball Stemmer: 
 [('10', '10'), ('A', 'a'), ('simple', 'simpl'), ('example', 'exampl'), ('distributed', 'distribut'), ('data', 'data'), ('mining', 'mine'), ('framework', 'framework'), ('[', '['), ('86', '86'), (']', ']')]

>> Lemmatization: 
 [('10', '10'), ('A', 'A'), ('simple', 'simple'), ('example', 'example'), ('distributed', 'distributed'), ('data', 'data'), ('mining', 'mining'), ('framework', 'framework'), ('[', '['), ('86', '86'), (']', ']')]



========================================== PARAGRAPH 306 ===========================================

Page 20 of 32Tsai et al. Journal of Big Data  (2015) 2:21  

------------------- Sentence 1 -------------------

Page 20 of 32Tsai et al.

>> Tokens are: 
 ['Page', '20', '32Tsai', 'et', 'al', '.']

>> Bigrams are: 
 [('Page', '20'), ('20', '32Tsai'), ('32Tsai', 'et'), ('et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('Page', '20', '32Tsai'), ('20', '32Tsai', 'et'), ('32Tsai', 'et', 'al'), ('et', 'al', '.')]

>> POS Tags are: 
 [('Page', 'NN'), ('20', 'CD'), ('32Tsai', 'CD'), ('et', 'NN'), ('al', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Page', 'et al']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Page', 'page'), ('20', '20'), ('32Tsai', '32tsai'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Page', 'page'), ('20', '20'), ('32Tsai', '32tsai'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('Page', 'Page'), ('20', '20'), ('32Tsai', '32Tsai'), ('et', 'et'), ('al', 'al'), ('.', '.')]


------------------- Sentence 2 -------------------

Journal of Big Data  (2015) 2:21

>> Tokens are: 
 ['Journal', 'Big', 'Data', '(', '2015', ')', '2:21']

>> Bigrams are: 
 [('Journal', 'Big'), ('Big', 'Data'), ('Data', '('), ('(', '2015'), ('2015', ')'), (')', '2:21')]

>> Trigrams are: 
 [('Journal', 'Big', 'Data'), ('Big', 'Data', '('), ('Data', '(', '2015'), ('(', '2015', ')'), ('2015', ')', '2:21')]

>> POS Tags are: 
 [('Journal', 'NNP'), ('Big', 'NNP'), ('Data', 'NNP'), ('(', '('), ('2015', 'CD'), (')', ')'), ('2:21', 'CD')]

>> Noun Phrases are: 
 ['Journal Big Data']

>> Named Entities are: 
 [('PERSON', 'Journal')] 

>> Stemming using Porter Stemmer: 
 [('Journal', 'journal'), ('Big', 'big'), ('Data', 'data'), ('(', '('), ('2015', '2015'), (')', ')'), ('2:21', '2:21')]

>> Stemming using Snowball Stemmer: 
 [('Journal', 'journal'), ('Big', 'big'), ('Data', 'data'), ('(', '('), ('2015', '2015'), (')', ')'), ('2:21', '2:21')]

>> Lemmatization: 
 [('Journal', 'Journal'), ('Big', 'Big'), ('Data', 'Data'), ('(', '('), ('2015', '2015'), (')', ')'), ('2:21', '2:21')]



========================================== PARAGRAPH 307 ===========================================

Ku-Mahamud modified the ant behavior of this ant clustering algorithm for big data  clustering. That is, each ant will be randomly placed on the grid. This means that the ant  clustering algorithm then can be used on a parallel computing environment. 

------------------- Sentence 1 -------------------

Ku-Mahamud modified the ant behavior of this ant clustering algorithm for big data  clustering.

>> Tokens are: 
 ['Ku-Mahamud', 'modified', 'ant', 'behavior', 'ant', 'clustering', 'algorithm', 'big', 'data', 'clustering', '.']

>> Bigrams are: 
 [('Ku-Mahamud', 'modified'), ('modified', 'ant'), ('ant', 'behavior'), ('behavior', 'ant'), ('ant', 'clustering'), ('clustering', 'algorithm'), ('algorithm', 'big'), ('big', 'data'), ('data', 'clustering'), ('clustering', '.')]

>> Trigrams are: 
 [('Ku-Mahamud', 'modified', 'ant'), ('modified', 'ant', 'behavior'), ('ant', 'behavior', 'ant'), ('behavior', 'ant', 'clustering'), ('ant', 'clustering', 'algorithm'), ('clustering', 'algorithm', 'big'), ('algorithm', 'big', 'data'), ('big', 'data', 'clustering'), ('data', 'clustering', '.')]

>> POS Tags are: 
 [('Ku-Mahamud', 'NNP'), ('modified', 'VBD'), ('ant', 'JJ'), ('behavior', 'NN'), ('ant', 'JJ'), ('clustering', 'NN'), ('algorithm', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('clustering', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Ku-Mahamud', 'ant behavior', 'ant clustering algorithm', 'big data clustering']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Ku-Mahamud', 'ku-mahamud'), ('modified', 'modifi'), ('ant', 'ant'), ('behavior', 'behavior'), ('ant', 'ant'), ('clustering', 'cluster'), ('algorithm', 'algorithm'), ('big', 'big'), ('data', 'data'), ('clustering', 'cluster'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Ku-Mahamud', 'ku-mahamud'), ('modified', 'modifi'), ('ant', 'ant'), ('behavior', 'behavior'), ('ant', 'ant'), ('clustering', 'cluster'), ('algorithm', 'algorithm'), ('big', 'big'), ('data', 'data'), ('clustering', 'cluster'), ('.', '.')]

>> Lemmatization: 
 [('Ku-Mahamud', 'Ku-Mahamud'), ('modified', 'modified'), ('ant', 'ant'), ('behavior', 'behavior'), ('ant', 'ant'), ('clustering', 'clustering'), ('algorithm', 'algorithm'), ('big', 'big'), ('data', 'data'), ('clustering', 'clustering'), ('.', '.')]


------------------- Sentence 2 -------------------

That is, each ant will be randomly placed on the grid.

>> Tokens are: 
 ['That', ',', 'ant', 'randomly', 'placed', 'grid', '.']

>> Bigrams are: 
 [('That', ','), (',', 'ant'), ('ant', 'randomly'), ('randomly', 'placed'), ('placed', 'grid'), ('grid', '.')]

>> Trigrams are: 
 [('That', ',', 'ant'), (',', 'ant', 'randomly'), ('ant', 'randomly', 'placed'), ('randomly', 'placed', 'grid'), ('placed', 'grid', '.')]

>> POS Tags are: 
 [('That', 'DT'), (',', ','), ('ant', 'JJ'), ('randomly', 'NN'), ('placed', 'VBD'), ('grid', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['ant randomly', 'grid']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('That', 'that'), (',', ','), ('ant', 'ant'), ('randomly', 'randomli'), ('placed', 'place'), ('grid', 'grid'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('That', 'that'), (',', ','), ('ant', 'ant'), ('randomly', 'random'), ('placed', 'place'), ('grid', 'grid'), ('.', '.')]

>> Lemmatization: 
 [('That', 'That'), (',', ','), ('ant', 'ant'), ('randomly', 'randomly'), ('placed', 'placed'), ('grid', 'grid'), ('.', '.')]


------------------- Sentence 3 -------------------

This means that the ant  clustering algorithm then can be used on a parallel computing environment.

>> Tokens are: 
 ['This', 'means', 'ant', 'clustering', 'algorithm', 'used', 'parallel', 'computing', 'environment', '.']

>> Bigrams are: 
 [('This', 'means'), ('means', 'ant'), ('ant', 'clustering'), ('clustering', 'algorithm'), ('algorithm', 'used'), ('used', 'parallel'), ('parallel', 'computing'), ('computing', 'environment'), ('environment', '.')]

>> Trigrams are: 
 [('This', 'means', 'ant'), ('means', 'ant', 'clustering'), ('ant', 'clustering', 'algorithm'), ('clustering', 'algorithm', 'used'), ('algorithm', 'used', 'parallel'), ('used', 'parallel', 'computing'), ('parallel', 'computing', 'environment'), ('computing', 'environment', '.')]

>> POS Tags are: 
 [('This', 'DT'), ('means', 'VBZ'), ('ant', 'JJ'), ('clustering', 'VBG'), ('algorithm', 'NN'), ('used', 'VBN'), ('parallel', 'RB'), ('computing', 'VBG'), ('environment', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['algorithm', 'environment']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('This', 'thi'), ('means', 'mean'), ('ant', 'ant'), ('clustering', 'cluster'), ('algorithm', 'algorithm'), ('used', 'use'), ('parallel', 'parallel'), ('computing', 'comput'), ('environment', 'environ'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('This', 'this'), ('means', 'mean'), ('ant', 'ant'), ('clustering', 'cluster'), ('algorithm', 'algorithm'), ('used', 'use'), ('parallel', 'parallel'), ('computing', 'comput'), ('environment', 'environ'), ('.', '.')]

>> Lemmatization: 
 [('This', 'This'), ('means', 'mean'), ('ant', 'ant'), ('clustering', 'clustering'), ('algorithm', 'algorithm'), ('used', 'used'), ('parallel', 'parallel'), ('computing', 'computing'), ('environment', 'environment'), ('.', '.')]



========================================== PARAGRAPH 308 ===========================================

The trends of machine learning studies for big data analytics can be divided into two- fold: one attempts to make machine learning algorithms run on parallel platforms, such  as Radoop [129], Mahout [87], and PIMRU [124]; the other is to redesign the machine  learning algorithms to make them suitable for parallel computing or to parallel comput- ing environment, such as neural network algorithms for GPU [126] and ant-based algo- rithm for grid [127]. In summary, both of them make it possible to apply the machine  learning algorithms to big data analytics although still many research issues need to be  solved, such as the communication cost for different computer nodes [86] and the large  computation cost most machine learning algorithms require [126]. 

------------------- Sentence 1 -------------------

The trends of machine learning studies for big data analytics can be divided into two- fold: one attempts to make machine learning algorithms run on parallel platforms, such  as Radoop [129], Mahout [87], and PIMRU [124]; the other is to redesign the machine  learning algorithms to make them suitable for parallel computing or to parallel comput- ing environment, such as neural network algorithms for GPU [126] and ant-based algo- rithm for grid [127].

>> Tokens are: 
 ['The', 'trends', 'machine', 'learning', 'studies', 'big', 'data', 'analytics', 'divided', 'two-', 'fold', ':', 'one', 'attempts', 'make', 'machine', 'learning', 'algorithms', 'run', 'parallel', 'platforms', ',', 'Radoop', '[', '129', ']', ',', 'Mahout', '[', '87', ']', ',', 'PIMRU', '[', '124', ']', ';', 'redesign', 'machine', 'learning', 'algorithms', 'make', 'suitable', 'parallel', 'computing', 'parallel', 'comput-', 'ing', 'environment', ',', 'neural', 'network', 'algorithms', 'GPU', '[', '126', ']', 'ant-based', 'algo-', 'rithm', 'grid', '[', '127', ']', '.']

>> Bigrams are: 
 [('The', 'trends'), ('trends', 'machine'), ('machine', 'learning'), ('learning', 'studies'), ('studies', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', 'divided'), ('divided', 'two-'), ('two-', 'fold'), ('fold', ':'), (':', 'one'), ('one', 'attempts'), ('attempts', 'make'), ('make', 'machine'), ('machine', 'learning'), ('learning', 'algorithms'), ('algorithms', 'run'), ('run', 'parallel'), ('parallel', 'platforms'), ('platforms', ','), (',', 'Radoop'), ('Radoop', '['), ('[', '129'), ('129', ']'), (']', ','), (',', 'Mahout'), ('Mahout', '['), ('[', '87'), ('87', ']'), (']', ','), (',', 'PIMRU'), ('PIMRU', '['), ('[', '124'), ('124', ']'), (']', ';'), (';', 'redesign'), ('redesign', 'machine'), ('machine', 'learning'), ('learning', 'algorithms'), ('algorithms', 'make'), ('make', 'suitable'), ('suitable', 'parallel'), ('parallel', 'computing'), ('computing', 'parallel'), ('parallel', 'comput-'), ('comput-', 'ing'), ('ing', 'environment'), ('environment', ','), (',', 'neural'), ('neural', 'network'), ('network', 'algorithms'), ('algorithms', 'GPU'), ('GPU', '['), ('[', '126'), ('126', ']'), (']', 'ant-based'), ('ant-based', 'algo-'), ('algo-', 'rithm'), ('rithm', 'grid'), ('grid', '['), ('[', '127'), ('127', ']'), (']', '.')]

>> Trigrams are: 
 [('The', 'trends', 'machine'), ('trends', 'machine', 'learning'), ('machine', 'learning', 'studies'), ('learning', 'studies', 'big'), ('studies', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', 'divided'), ('analytics', 'divided', 'two-'), ('divided', 'two-', 'fold'), ('two-', 'fold', ':'), ('fold', ':', 'one'), (':', 'one', 'attempts'), ('one', 'attempts', 'make'), ('attempts', 'make', 'machine'), ('make', 'machine', 'learning'), ('machine', 'learning', 'algorithms'), ('learning', 'algorithms', 'run'), ('algorithms', 'run', 'parallel'), ('run', 'parallel', 'platforms'), ('parallel', 'platforms', ','), ('platforms', ',', 'Radoop'), (',', 'Radoop', '['), ('Radoop', '[', '129'), ('[', '129', ']'), ('129', ']', ','), (']', ',', 'Mahout'), (',', 'Mahout', '['), ('Mahout', '[', '87'), ('[', '87', ']'), ('87', ']', ','), (']', ',', 'PIMRU'), (',', 'PIMRU', '['), ('PIMRU', '[', '124'), ('[', '124', ']'), ('124', ']', ';'), (']', ';', 'redesign'), (';', 'redesign', 'machine'), ('redesign', 'machine', 'learning'), ('machine', 'learning', 'algorithms'), ('learning', 'algorithms', 'make'), ('algorithms', 'make', 'suitable'), ('make', 'suitable', 'parallel'), ('suitable', 'parallel', 'computing'), ('parallel', 'computing', 'parallel'), ('computing', 'parallel', 'comput-'), ('parallel', 'comput-', 'ing'), ('comput-', 'ing', 'environment'), ('ing', 'environment', ','), ('environment', ',', 'neural'), (',', 'neural', 'network'), ('neural', 'network', 'algorithms'), ('network', 'algorithms', 'GPU'), ('algorithms', 'GPU', '['), ('GPU', '[', '126'), ('[', '126', ']'), ('126', ']', 'ant-based'), (']', 'ant-based', 'algo-'), ('ant-based', 'algo-', 'rithm'), ('algo-', 'rithm', 'grid'), ('rithm', 'grid', '['), ('grid', '[', '127'), ('[', '127', ']'), ('127', ']', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('trends', 'NNS'), ('machine', 'NN'), ('learning', 'VBG'), ('studies', 'NNS'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('divided', 'VBD'), ('two-', 'JJ'), ('fold', 'NN'), (':', ':'), ('one', 'CD'), ('attempts', 'NNS'), ('make', 'VBP'), ('machine', 'NN'), ('learning', 'NN'), ('algorithms', 'JJ'), ('run', 'NN'), ('parallel', 'RB'), ('platforms', 'NNS'), (',', ','), ('Radoop', 'NNP'), ('[', 'VBZ'), ('129', 'CD'), (']', 'NN'), (',', ','), ('Mahout', 'NNP'), ('[', 'NNP'), ('87', 'CD'), (']', 'NNP'), (',', ','), ('PIMRU', 'NNP'), ('[', 'VBZ'), ('124', 'CD'), (']', 'NN'), (';', ':'), ('redesign', 'CC'), ('machine', 'NN'), ('learning', 'NN'), ('algorithms', 'NNS'), ('make', 'VBP'), ('suitable', 'JJ'), ('parallel', 'JJ'), ('computing', 'VBG'), ('parallel', 'JJ'), ('comput-', 'JJ'), ('ing', 'NN'), ('environment', 'NN'), (',', ','), ('neural', 'JJ'), ('network', 'NN'), ('algorithms', 'NN'), ('GPU', 'NNP'), ('[', 'VBZ'), ('126', 'CD'), (']', 'JJ'), ('ant-based', 'JJ'), ('algo-', 'JJ'), ('rithm', 'NN'), ('grid', 'NN'), ('[', 'VBD'), ('127', 'CD'), (']', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['The trends machine', 'studies', 'big data analytics', 'two- fold', 'attempts', 'machine learning', 'algorithms run', 'platforms', 'Radoop', ']', 'Mahout [', ']', 'PIMRU', ']', 'machine learning algorithms', 'parallel comput- ing environment', 'neural network algorithms GPU', '] ant-based algo- rithm grid', ']']

>> Named Entities are: 
 [('PERSON', 'Radoop'), ('PERSON', 'Mahout'), ('ORGANIZATION', 'PIMRU'), ('ORGANIZATION', 'GPU')] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('trends', 'trend'), ('machine', 'machin'), ('learning', 'learn'), ('studies', 'studi'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('divided', 'divid'), ('two-', 'two-'), ('fold', 'fold'), (':', ':'), ('one', 'one'), ('attempts', 'attempt'), ('make', 'make'), ('machine', 'machin'), ('learning', 'learn'), ('algorithms', 'algorithm'), ('run', 'run'), ('parallel', 'parallel'), ('platforms', 'platform'), (',', ','), ('Radoop', 'radoop'), ('[', '['), ('129', '129'), (']', ']'), (',', ','), ('Mahout', 'mahout'), ('[', '['), ('87', '87'), (']', ']'), (',', ','), ('PIMRU', 'pimru'), ('[', '['), ('124', '124'), (']', ']'), (';', ';'), ('redesign', 'redesign'), ('machine', 'machin'), ('learning', 'learn'), ('algorithms', 'algorithm'), ('make', 'make'), ('suitable', 'suitabl'), ('parallel', 'parallel'), ('computing', 'comput'), ('parallel', 'parallel'), ('comput-', 'comput-'), ('ing', 'ing'), ('environment', 'environ'), (',', ','), ('neural', 'neural'), ('network', 'network'), ('algorithms', 'algorithm'), ('GPU', 'gpu'), ('[', '['), ('126', '126'), (']', ']'), ('ant-based', 'ant-bas'), ('algo-', 'algo-'), ('rithm', 'rithm'), ('grid', 'grid'), ('[', '['), ('127', '127'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('trends', 'trend'), ('machine', 'machin'), ('learning', 'learn'), ('studies', 'studi'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('divided', 'divid'), ('two-', 'two-'), ('fold', 'fold'), (':', ':'), ('one', 'one'), ('attempts', 'attempt'), ('make', 'make'), ('machine', 'machin'), ('learning', 'learn'), ('algorithms', 'algorithm'), ('run', 'run'), ('parallel', 'parallel'), ('platforms', 'platform'), (',', ','), ('Radoop', 'radoop'), ('[', '['), ('129', '129'), (']', ']'), (',', ','), ('Mahout', 'mahout'), ('[', '['), ('87', '87'), (']', ']'), (',', ','), ('PIMRU', 'pimru'), ('[', '['), ('124', '124'), (']', ']'), (';', ';'), ('redesign', 'redesign'), ('machine', 'machin'), ('learning', 'learn'), ('algorithms', 'algorithm'), ('make', 'make'), ('suitable', 'suitabl'), ('parallel', 'parallel'), ('computing', 'comput'), ('parallel', 'parallel'), ('comput-', 'comput-'), ('ing', 'ing'), ('environment', 'environ'), (',', ','), ('neural', 'neural'), ('network', 'network'), ('algorithms', 'algorithm'), ('GPU', 'gpu'), ('[', '['), ('126', '126'), (']', ']'), ('ant-based', 'ant-bas'), ('algo-', 'algo-'), ('rithm', 'rithm'), ('grid', 'grid'), ('[', '['), ('127', '127'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('trends', 'trend'), ('machine', 'machine'), ('learning', 'learning'), ('studies', 'study'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('divided', 'divided'), ('two-', 'two-'), ('fold', 'fold'), (':', ':'), ('one', 'one'), ('attempts', 'attempt'), ('make', 'make'), ('machine', 'machine'), ('learning', 'learning'), ('algorithms', 'algorithm'), ('run', 'run'), ('parallel', 'parallel'), ('platforms', 'platform'), (',', ','), ('Radoop', 'Radoop'), ('[', '['), ('129', '129'), (']', ']'), (',', ','), ('Mahout', 'Mahout'), ('[', '['), ('87', '87'), (']', ']'), (',', ','), ('PIMRU', 'PIMRU'), ('[', '['), ('124', '124'), (']', ']'), (';', ';'), ('redesign', 'redesign'), ('machine', 'machine'), ('learning', 'learning'), ('algorithms', 'algorithm'), ('make', 'make'), ('suitable', 'suitable'), ('parallel', 'parallel'), ('computing', 'computing'), ('parallel', 'parallel'), ('comput-', 'comput-'), ('ing', 'ing'), ('environment', 'environment'), (',', ','), ('neural', 'neural'), ('network', 'network'), ('algorithms', 'algorithm'), ('GPU', 'GPU'), ('[', '['), ('126', '126'), (']', ']'), ('ant-based', 'ant-based'), ('algo-', 'algo-'), ('rithm', 'rithm'), ('grid', 'grid'), ('[', '['), ('127', '127'), (']', ']'), ('.', '.')]


------------------- Sentence 2 -------------------

In summary, both of them make it possible to apply the machine  learning algorithms to big data analytics although still many research issues need to be  solved, such as the communication cost for different computer nodes [86] and the large  computation cost most machine learning algorithms require [126].

>> Tokens are: 
 ['In', 'summary', ',', 'make', 'possible', 'apply', 'machine', 'learning', 'algorithms', 'big', 'data', 'analytics', 'although', 'still', 'many', 'research', 'issues', 'need', 'solved', ',', 'communication', 'cost', 'different', 'computer', 'nodes', '[', '86', ']', 'large', 'computation', 'cost', 'machine', 'learning', 'algorithms', 'require', '[', '126', ']', '.']

>> Bigrams are: 
 [('In', 'summary'), ('summary', ','), (',', 'make'), ('make', 'possible'), ('possible', 'apply'), ('apply', 'machine'), ('machine', 'learning'), ('learning', 'algorithms'), ('algorithms', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', 'although'), ('although', 'still'), ('still', 'many'), ('many', 'research'), ('research', 'issues'), ('issues', 'need'), ('need', 'solved'), ('solved', ','), (',', 'communication'), ('communication', 'cost'), ('cost', 'different'), ('different', 'computer'), ('computer', 'nodes'), ('nodes', '['), ('[', '86'), ('86', ']'), (']', 'large'), ('large', 'computation'), ('computation', 'cost'), ('cost', 'machine'), ('machine', 'learning'), ('learning', 'algorithms'), ('algorithms', 'require'), ('require', '['), ('[', '126'), ('126', ']'), (']', '.')]

>> Trigrams are: 
 [('In', 'summary', ','), ('summary', ',', 'make'), (',', 'make', 'possible'), ('make', 'possible', 'apply'), ('possible', 'apply', 'machine'), ('apply', 'machine', 'learning'), ('machine', 'learning', 'algorithms'), ('learning', 'algorithms', 'big'), ('algorithms', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', 'although'), ('analytics', 'although', 'still'), ('although', 'still', 'many'), ('still', 'many', 'research'), ('many', 'research', 'issues'), ('research', 'issues', 'need'), ('issues', 'need', 'solved'), ('need', 'solved', ','), ('solved', ',', 'communication'), (',', 'communication', 'cost'), ('communication', 'cost', 'different'), ('cost', 'different', 'computer'), ('different', 'computer', 'nodes'), ('computer', 'nodes', '['), ('nodes', '[', '86'), ('[', '86', ']'), ('86', ']', 'large'), (']', 'large', 'computation'), ('large', 'computation', 'cost'), ('computation', 'cost', 'machine'), ('cost', 'machine', 'learning'), ('machine', 'learning', 'algorithms'), ('learning', 'algorithms', 'require'), ('algorithms', 'require', '['), ('require', '[', '126'), ('[', '126', ']'), ('126', ']', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('summary', 'JJ'), (',', ','), ('make', 'VB'), ('possible', 'JJ'), ('apply', 'NN'), ('machine', 'NN'), ('learning', 'VBG'), ('algorithms', 'JJ'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('although', 'IN'), ('still', 'RB'), ('many', 'JJ'), ('research', 'NN'), ('issues', 'NNS'), ('need', 'VBP'), ('solved', 'VBN'), (',', ','), ('communication', 'NN'), ('cost', 'NN'), ('different', 'JJ'), ('computer', 'NN'), ('nodes', 'NNS'), ('[', 'VBP'), ('86', 'CD'), (']', 'NNP'), ('large', 'JJ'), ('computation', 'NN'), ('cost', 'NN'), ('machine', 'NN'), ('learning', 'VBG'), ('algorithms', 'JJ'), ('require', 'NN'), ('[', 'VBD'), ('126', 'CD'), (']', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['possible apply machine', 'algorithms big data analytics', 'many research issues', 'communication cost', 'different computer nodes', ']', 'large computation cost machine', 'algorithms require', ']']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('summary', 'summari'), (',', ','), ('make', 'make'), ('possible', 'possibl'), ('apply', 'appli'), ('machine', 'machin'), ('learning', 'learn'), ('algorithms', 'algorithm'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('although', 'although'), ('still', 'still'), ('many', 'mani'), ('research', 'research'), ('issues', 'issu'), ('need', 'need'), ('solved', 'solv'), (',', ','), ('communication', 'commun'), ('cost', 'cost'), ('different', 'differ'), ('computer', 'comput'), ('nodes', 'node'), ('[', '['), ('86', '86'), (']', ']'), ('large', 'larg'), ('computation', 'comput'), ('cost', 'cost'), ('machine', 'machin'), ('learning', 'learn'), ('algorithms', 'algorithm'), ('require', 'requir'), ('[', '['), ('126', '126'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('summary', 'summari'), (',', ','), ('make', 'make'), ('possible', 'possibl'), ('apply', 'appli'), ('machine', 'machin'), ('learning', 'learn'), ('algorithms', 'algorithm'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('although', 'although'), ('still', 'still'), ('many', 'mani'), ('research', 'research'), ('issues', 'issu'), ('need', 'need'), ('solved', 'solv'), (',', ','), ('communication', 'communic'), ('cost', 'cost'), ('different', 'differ'), ('computer', 'comput'), ('nodes', 'node'), ('[', '['), ('86', '86'), (']', ']'), ('large', 'larg'), ('computation', 'comput'), ('cost', 'cost'), ('machine', 'machin'), ('learning', 'learn'), ('algorithms', 'algorithm'), ('require', 'requir'), ('[', '['), ('126', '126'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('summary', 'summary'), (',', ','), ('make', 'make'), ('possible', 'possible'), ('apply', 'apply'), ('machine', 'machine'), ('learning', 'learning'), ('algorithms', 'algorithm'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('although', 'although'), ('still', 'still'), ('many', 'many'), ('research', 'research'), ('issues', 'issue'), ('need', 'need'), ('solved', 'solved'), (',', ','), ('communication', 'communication'), ('cost', 'cost'), ('different', 'different'), ('computer', 'computer'), ('nodes', 'node'), ('[', '['), ('86', '86'), (']', ']'), ('large', 'large'), ('computation', 'computation'), ('cost', 'cost'), ('machine', 'machine'), ('learning', 'learning'), ('algorithms', 'algorithm'), ('require', 'require'), ('[', '['), ('126', '126'), (']', ']'), ('.', '.')]



========================================== PARAGRAPH 309 ===========================================

Output the result of big data analysis 

------------------- Sentence 1 -------------------

Output the result of big data analysis

>> Tokens are: 
 ['Output', 'result', 'big', 'data', 'analysis']

>> Bigrams are: 
 [('Output', 'result'), ('result', 'big'), ('big', 'data'), ('data', 'analysis')]

>> Trigrams are: 
 [('Output', 'result', 'big'), ('result', 'big', 'data'), ('big', 'data', 'analysis')]

>> POS Tags are: 
 [('Output', 'NNP'), ('result', 'VBP'), ('big', 'JJ'), ('data', 'NNS'), ('analysis', 'NN')]

>> Noun Phrases are: 
 ['Output', 'big data analysis']

>> Named Entities are: 
 [('GPE', 'Output')] 

>> Stemming using Porter Stemmer: 
 [('Output', 'output'), ('result', 'result'), ('big', 'big'), ('data', 'data'), ('analysis', 'analysi')]

>> Stemming using Snowball Stemmer: 
 [('Output', 'output'), ('result', 'result'), ('big', 'big'), ('data', 'data'), ('analysis', 'analysi')]

>> Lemmatization: 
 [('Output', 'Output'), ('result', 'result'), ('big', 'big'), ('data', 'data'), ('analysis', 'analysis')]



========================================== PARAGRAPH 310 ===========================================

The benchmarks of PigMix [130], GridMix [131], TeraSort and GraySort [132], TPC-C,  TPC-H, TPC-DS [133], and yahoo cloud serving benchmark (YCSB) [134] have been pre- sented for evaluating the performance of the cloud computing and big data analytics sys- tems. Ghazal et al. [135] presented another benchmark (called BigBench) to be used as  an end-to-end big data benchmark which covers the characteristics of 3V of big data and  uses the loading time, time for queries, time for procedural processing queries, and time  for the remaining queries as the metrics. By using these benchmarks, the computation  time is one of the intuitive metrics for evaluating the performance of different big data  analytics platforms or algorithms. That is why Cheptsov [136] compered the high perfor- mance computing (HPC) and cloud system by using the measurement of computation  time to understand their scalability for text file analysis. In addition to the computation  time, the throughput (e.g.-, the number of operations per second) and read/write latency  of operations are the other measurements of big data analytics [137]. In the study of [138],  Zhao et al. believe that the maximum size of data and the maximum number of jobs are  the two important metrics to understand the performance of the big data analytics plat- form. Another study described in [139] presented a systematic evaluation method which  contains the data throughput, concurrency during map and reduce phases, response  times, and the execution time of map and reduce. Moreover, most benchmarks for evalu- ating the performance of big data analytics typically can only provide the response time  or the computation cost; however, the fact is that several factors need to be taken into  account at the same time when building a big data analytics system. The hardware, band- width for data transmission, fault tolerance, cost, power consumption of these systems  are all issues [70, 104] to be taken into account at the same time when building a big data  analytics system. Several solutions available today are to install the big data analytics on a  cloud computing system or a cluster system. Therefore, the measurements of fault toler- ance, task execution, and cost of cloud computing systems can then be used to evaluate  the performance of the corresponding factors of big data analytics. 

------------------- Sentence 1 -------------------

The benchmarks of PigMix [130], GridMix [131], TeraSort and GraySort [132], TPC-C,  TPC-H, TPC-DS [133], and yahoo cloud serving benchmark (YCSB) [134] have been pre- sented for evaluating the performance of the cloud computing and big data analytics sys- tems.

>> Tokens are: 
 ['The', 'benchmarks', 'PigMix', '[', '130', ']', ',', 'GridMix', '[', '131', ']', ',', 'TeraSort', 'GraySort', '[', '132', ']', ',', 'TPC-C', ',', 'TPC-H', ',', 'TPC-DS', '[', '133', ']', ',', 'yahoo', 'cloud', 'serving', 'benchmark', '(', 'YCSB', ')', '[', '134', ']', 'pre-', 'sented', 'evaluating', 'performance', 'cloud', 'computing', 'big', 'data', 'analytics', 'sys-', 'tems', '.']

>> Bigrams are: 
 [('The', 'benchmarks'), ('benchmarks', 'PigMix'), ('PigMix', '['), ('[', '130'), ('130', ']'), (']', ','), (',', 'GridMix'), ('GridMix', '['), ('[', '131'), ('131', ']'), (']', ','), (',', 'TeraSort'), ('TeraSort', 'GraySort'), ('GraySort', '['), ('[', '132'), ('132', ']'), (']', ','), (',', 'TPC-C'), ('TPC-C', ','), (',', 'TPC-H'), ('TPC-H', ','), (',', 'TPC-DS'), ('TPC-DS', '['), ('[', '133'), ('133', ']'), (']', ','), (',', 'yahoo'), ('yahoo', 'cloud'), ('cloud', 'serving'), ('serving', 'benchmark'), ('benchmark', '('), ('(', 'YCSB'), ('YCSB', ')'), (')', '['), ('[', '134'), ('134', ']'), (']', 'pre-'), ('pre-', 'sented'), ('sented', 'evaluating'), ('evaluating', 'performance'), ('performance', 'cloud'), ('cloud', 'computing'), ('computing', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', 'sys-'), ('sys-', 'tems'), ('tems', '.')]

>> Trigrams are: 
 [('The', 'benchmarks', 'PigMix'), ('benchmarks', 'PigMix', '['), ('PigMix', '[', '130'), ('[', '130', ']'), ('130', ']', ','), (']', ',', 'GridMix'), (',', 'GridMix', '['), ('GridMix', '[', '131'), ('[', '131', ']'), ('131', ']', ','), (']', ',', 'TeraSort'), (',', 'TeraSort', 'GraySort'), ('TeraSort', 'GraySort', '['), ('GraySort', '[', '132'), ('[', '132', ']'), ('132', ']', ','), (']', ',', 'TPC-C'), (',', 'TPC-C', ','), ('TPC-C', ',', 'TPC-H'), (',', 'TPC-H', ','), ('TPC-H', ',', 'TPC-DS'), (',', 'TPC-DS', '['), ('TPC-DS', '[', '133'), ('[', '133', ']'), ('133', ']', ','), (']', ',', 'yahoo'), (',', 'yahoo', 'cloud'), ('yahoo', 'cloud', 'serving'), ('cloud', 'serving', 'benchmark'), ('serving', 'benchmark', '('), ('benchmark', '(', 'YCSB'), ('(', 'YCSB', ')'), ('YCSB', ')', '['), (')', '[', '134'), ('[', '134', ']'), ('134', ']', 'pre-'), (']', 'pre-', 'sented'), ('pre-', 'sented', 'evaluating'), ('sented', 'evaluating', 'performance'), ('evaluating', 'performance', 'cloud'), ('performance', 'cloud', 'computing'), ('cloud', 'computing', 'big'), ('computing', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', 'sys-'), ('analytics', 'sys-', 'tems'), ('sys-', 'tems', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('benchmarks', 'NNS'), ('PigMix', 'NNP'), ('[', 'VBD'), ('130', 'CD'), (']', 'NN'), (',', ','), ('GridMix', 'NNP'), ('[', 'NNP'), ('131', 'CD'), (']', 'NNP'), (',', ','), ('TeraSort', 'NNP'), ('GraySort', 'NNP'), ('[', 'VBD'), ('132', 'CD'), (']', 'NN'), (',', ','), ('TPC-C', 'NNP'), (',', ','), ('TPC-H', 'NNP'), (',', ','), ('TPC-DS', 'NNP'), ('[', 'NNP'), ('133', 'CD'), (']', 'NNP'), (',', ','), ('yahoo', 'NNP'), ('cloud', 'VBP'), ('serving', 'VBG'), ('benchmark', 'NN'), ('(', '('), ('YCSB', 'NNP'), (')', ')'), ('[', 'VBD'), ('134', 'CD'), (']', 'JJ'), ('pre-', 'NN'), ('sented', 'VBD'), ('evaluating', 'VBG'), ('performance', 'NN'), ('cloud', 'NN'), ('computing', 'VBG'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('sys-', 'JJ'), ('tems', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['The benchmarks PigMix', ']', 'GridMix [', ']', 'TeraSort GraySort', ']', 'TPC-C', 'TPC-H', 'TPC-DS [', ']', 'yahoo', 'benchmark', 'YCSB', '] pre-', 'performance cloud', 'big data analytics', 'sys- tems']

>> Named Entities are: 
 [('ORGANIZATION', 'PigMix'), ('ORGANIZATION', 'GridMix'), ('ORGANIZATION', 'TeraSort'), ('ORGANIZATION', 'YCSB')] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('benchmarks', 'benchmark'), ('PigMix', 'pigmix'), ('[', '['), ('130', '130'), (']', ']'), (',', ','), ('GridMix', 'gridmix'), ('[', '['), ('131', '131'), (']', ']'), (',', ','), ('TeraSort', 'terasort'), ('GraySort', 'graysort'), ('[', '['), ('132', '132'), (']', ']'), (',', ','), ('TPC-C', 'tpc-c'), (',', ','), ('TPC-H', 'tpc-h'), (',', ','), ('TPC-DS', 'tpc-d'), ('[', '['), ('133', '133'), (']', ']'), (',', ','), ('yahoo', 'yahoo'), ('cloud', 'cloud'), ('serving', 'serv'), ('benchmark', 'benchmark'), ('(', '('), ('YCSB', 'ycsb'), (')', ')'), ('[', '['), ('134', '134'), (']', ']'), ('pre-', 'pre-'), ('sented', 'sent'), ('evaluating', 'evalu'), ('performance', 'perform'), ('cloud', 'cloud'), ('computing', 'comput'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('sys-', 'sys-'), ('tems', 'tem'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('benchmarks', 'benchmark'), ('PigMix', 'pigmix'), ('[', '['), ('130', '130'), (']', ']'), (',', ','), ('GridMix', 'gridmix'), ('[', '['), ('131', '131'), (']', ']'), (',', ','), ('TeraSort', 'terasort'), ('GraySort', 'graysort'), ('[', '['), ('132', '132'), (']', ']'), (',', ','), ('TPC-C', 'tpc-c'), (',', ','), ('TPC-H', 'tpc-h'), (',', ','), ('TPC-DS', 'tpc-ds'), ('[', '['), ('133', '133'), (']', ']'), (',', ','), ('yahoo', 'yahoo'), ('cloud', 'cloud'), ('serving', 'serv'), ('benchmark', 'benchmark'), ('(', '('), ('YCSB', 'ycsb'), (')', ')'), ('[', '['), ('134', '134'), (']', ']'), ('pre-', 'pre-'), ('sented', 'sent'), ('evaluating', 'evalu'), ('performance', 'perform'), ('cloud', 'cloud'), ('computing', 'comput'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('sys-', 'sys-'), ('tems', 'tem'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('benchmarks', 'benchmark'), ('PigMix', 'PigMix'), ('[', '['), ('130', '130'), (']', ']'), (',', ','), ('GridMix', 'GridMix'), ('[', '['), ('131', '131'), (']', ']'), (',', ','), ('TeraSort', 'TeraSort'), ('GraySort', 'GraySort'), ('[', '['), ('132', '132'), (']', ']'), (',', ','), ('TPC-C', 'TPC-C'), (',', ','), ('TPC-H', 'TPC-H'), (',', ','), ('TPC-DS', 'TPC-DS'), ('[', '['), ('133', '133'), (']', ']'), (',', ','), ('yahoo', 'yahoo'), ('cloud', 'cloud'), ('serving', 'serving'), ('benchmark', 'benchmark'), ('(', '('), ('YCSB', 'YCSB'), (')', ')'), ('[', '['), ('134', '134'), (']', ']'), ('pre-', 'pre-'), ('sented', 'sented'), ('evaluating', 'evaluating'), ('performance', 'performance'), ('cloud', 'cloud'), ('computing', 'computing'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('sys-', 'sys-'), ('tems', 'tems'), ('.', '.')]


------------------- Sentence 2 -------------------

Ghazal et al.

>> Tokens are: 
 ['Ghazal', 'et', 'al', '.']

>> Bigrams are: 
 [('Ghazal', 'et'), ('et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('Ghazal', 'et', 'al'), ('et', 'al', '.')]

>> POS Tags are: 
 [('Ghazal', 'NNP'), ('et', 'CC'), ('al', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Ghazal', 'al']

>> Named Entities are: 
 [('GPE', 'Ghazal')] 

>> Stemming using Porter Stemmer: 
 [('Ghazal', 'ghazal'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Ghazal', 'ghazal'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('Ghazal', 'Ghazal'), ('et', 'et'), ('al', 'al'), ('.', '.')]


------------------- Sentence 3 -------------------

[135] presented another benchmark (called BigBench) to be used as  an end-to-end big data benchmark which covers the characteristics of 3V of big data and  uses the loading time, time for queries, time for procedural processing queries, and time  for the remaining queries as the metrics.

>> Tokens are: 
 ['[', '135', ']', 'presented', 'another', 'benchmark', '(', 'called', 'BigBench', ')', 'used', 'end-to-end', 'big', 'data', 'benchmark', 'covers', 'characteristics', '3V', 'big', 'data', 'uses', 'loading', 'time', ',', 'time', 'queries', ',', 'time', 'procedural', 'processing', 'queries', ',', 'time', 'remaining', 'queries', 'metrics', '.']

>> Bigrams are: 
 [('[', '135'), ('135', ']'), (']', 'presented'), ('presented', 'another'), ('another', 'benchmark'), ('benchmark', '('), ('(', 'called'), ('called', 'BigBench'), ('BigBench', ')'), (')', 'used'), ('used', 'end-to-end'), ('end-to-end', 'big'), ('big', 'data'), ('data', 'benchmark'), ('benchmark', 'covers'), ('covers', 'characteristics'), ('characteristics', '3V'), ('3V', 'big'), ('big', 'data'), ('data', 'uses'), ('uses', 'loading'), ('loading', 'time'), ('time', ','), (',', 'time'), ('time', 'queries'), ('queries', ','), (',', 'time'), ('time', 'procedural'), ('procedural', 'processing'), ('processing', 'queries'), ('queries', ','), (',', 'time'), ('time', 'remaining'), ('remaining', 'queries'), ('queries', 'metrics'), ('metrics', '.')]

>> Trigrams are: 
 [('[', '135', ']'), ('135', ']', 'presented'), (']', 'presented', 'another'), ('presented', 'another', 'benchmark'), ('another', 'benchmark', '('), ('benchmark', '(', 'called'), ('(', 'called', 'BigBench'), ('called', 'BigBench', ')'), ('BigBench', ')', 'used'), (')', 'used', 'end-to-end'), ('used', 'end-to-end', 'big'), ('end-to-end', 'big', 'data'), ('big', 'data', 'benchmark'), ('data', 'benchmark', 'covers'), ('benchmark', 'covers', 'characteristics'), ('covers', 'characteristics', '3V'), ('characteristics', '3V', 'big'), ('3V', 'big', 'data'), ('big', 'data', 'uses'), ('data', 'uses', 'loading'), ('uses', 'loading', 'time'), ('loading', 'time', ','), ('time', ',', 'time'), (',', 'time', 'queries'), ('time', 'queries', ','), ('queries', ',', 'time'), (',', 'time', 'procedural'), ('time', 'procedural', 'processing'), ('procedural', 'processing', 'queries'), ('processing', 'queries', ','), ('queries', ',', 'time'), (',', 'time', 'remaining'), ('time', 'remaining', 'queries'), ('remaining', 'queries', 'metrics'), ('queries', 'metrics', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('135', 'CD'), (']', 'NN'), ('presented', 'VBD'), ('another', 'DT'), ('benchmark', 'NN'), ('(', '('), ('called', 'VBN'), ('BigBench', 'NNP'), (')', ')'), ('used', 'VBD'), ('end-to-end', 'JJ'), ('big', 'JJ'), ('data', 'NNS'), ('benchmark', 'NN'), ('covers', 'VBZ'), ('characteristics', 'NNS'), ('3V', 'CD'), ('big', 'JJ'), ('data', 'NNS'), ('uses', 'NNS'), ('loading', 'VBG'), ('time', 'NN'), (',', ','), ('time', 'NN'), ('queries', 'NNS'), (',', ','), ('time', 'NN'), ('procedural', 'JJ'), ('processing', 'NN'), ('queries', 'NNS'), (',', ','), ('time', 'NN'), ('remaining', 'VBG'), ('queries', 'NNS'), ('metrics', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 [']', 'another benchmark', 'BigBench', 'end-to-end big data benchmark', 'characteristics', 'big data uses', 'time', 'time queries', 'time', 'procedural processing queries', 'time', 'queries metrics']

>> Named Entities are: 
 [('ORGANIZATION', 'BigBench')] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('135', '135'), (']', ']'), ('presented', 'present'), ('another', 'anoth'), ('benchmark', 'benchmark'), ('(', '('), ('called', 'call'), ('BigBench', 'bigbench'), (')', ')'), ('used', 'use'), ('end-to-end', 'end-to-end'), ('big', 'big'), ('data', 'data'), ('benchmark', 'benchmark'), ('covers', 'cover'), ('characteristics', 'characterist'), ('3V', '3v'), ('big', 'big'), ('data', 'data'), ('uses', 'use'), ('loading', 'load'), ('time', 'time'), (',', ','), ('time', 'time'), ('queries', 'queri'), (',', ','), ('time', 'time'), ('procedural', 'procedur'), ('processing', 'process'), ('queries', 'queri'), (',', ','), ('time', 'time'), ('remaining', 'remain'), ('queries', 'queri'), ('metrics', 'metric'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('135', '135'), (']', ']'), ('presented', 'present'), ('another', 'anoth'), ('benchmark', 'benchmark'), ('(', '('), ('called', 'call'), ('BigBench', 'bigbench'), (')', ')'), ('used', 'use'), ('end-to-end', 'end-to-end'), ('big', 'big'), ('data', 'data'), ('benchmark', 'benchmark'), ('covers', 'cover'), ('characteristics', 'characterist'), ('3V', '3v'), ('big', 'big'), ('data', 'data'), ('uses', 'use'), ('loading', 'load'), ('time', 'time'), (',', ','), ('time', 'time'), ('queries', 'queri'), (',', ','), ('time', 'time'), ('procedural', 'procedur'), ('processing', 'process'), ('queries', 'queri'), (',', ','), ('time', 'time'), ('remaining', 'remain'), ('queries', 'queri'), ('metrics', 'metric'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('135', '135'), (']', ']'), ('presented', 'presented'), ('another', 'another'), ('benchmark', 'benchmark'), ('(', '('), ('called', 'called'), ('BigBench', 'BigBench'), (')', ')'), ('used', 'used'), ('end-to-end', 'end-to-end'), ('big', 'big'), ('data', 'data'), ('benchmark', 'benchmark'), ('covers', 'cover'), ('characteristics', 'characteristic'), ('3V', '3V'), ('big', 'big'), ('data', 'data'), ('uses', 'us'), ('loading', 'loading'), ('time', 'time'), (',', ','), ('time', 'time'), ('queries', 'query'), (',', ','), ('time', 'time'), ('procedural', 'procedural'), ('processing', 'processing'), ('queries', 'query'), (',', ','), ('time', 'time'), ('remaining', 'remaining'), ('queries', 'query'), ('metrics', 'metric'), ('.', '.')]


------------------- Sentence 4 -------------------

By using these benchmarks, the computation  time is one of the intuitive metrics for evaluating the performance of different big data  analytics platforms or algorithms.

>> Tokens are: 
 ['By', 'using', 'benchmarks', ',', 'computation', 'time', 'one', 'intuitive', 'metrics', 'evaluating', 'performance', 'different', 'big', 'data', 'analytics', 'platforms', 'algorithms', '.']

>> Bigrams are: 
 [('By', 'using'), ('using', 'benchmarks'), ('benchmarks', ','), (',', 'computation'), ('computation', 'time'), ('time', 'one'), ('one', 'intuitive'), ('intuitive', 'metrics'), ('metrics', 'evaluating'), ('evaluating', 'performance'), ('performance', 'different'), ('different', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', 'platforms'), ('platforms', 'algorithms'), ('algorithms', '.')]

>> Trigrams are: 
 [('By', 'using', 'benchmarks'), ('using', 'benchmarks', ','), ('benchmarks', ',', 'computation'), (',', 'computation', 'time'), ('computation', 'time', 'one'), ('time', 'one', 'intuitive'), ('one', 'intuitive', 'metrics'), ('intuitive', 'metrics', 'evaluating'), ('metrics', 'evaluating', 'performance'), ('evaluating', 'performance', 'different'), ('performance', 'different', 'big'), ('different', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', 'platforms'), ('analytics', 'platforms', 'algorithms'), ('platforms', 'algorithms', '.')]

>> POS Tags are: 
 [('By', 'IN'), ('using', 'VBG'), ('benchmarks', 'NNS'), (',', ','), ('computation', 'NN'), ('time', 'NN'), ('one', 'CD'), ('intuitive', 'JJ'), ('metrics', 'NNS'), ('evaluating', 'VBG'), ('performance', 'NN'), ('different', 'JJ'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('platforms', 'NNS'), ('algorithms', 'VBP'), ('.', '.')]

>> Noun Phrases are: 
 ['benchmarks', 'computation time', 'intuitive metrics', 'performance', 'different big data analytics platforms']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('By', 'by'), ('using', 'use'), ('benchmarks', 'benchmark'), (',', ','), ('computation', 'comput'), ('time', 'time'), ('one', 'one'), ('intuitive', 'intuit'), ('metrics', 'metric'), ('evaluating', 'evalu'), ('performance', 'perform'), ('different', 'differ'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('platforms', 'platform'), ('algorithms', 'algorithm'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('By', 'by'), ('using', 'use'), ('benchmarks', 'benchmark'), (',', ','), ('computation', 'comput'), ('time', 'time'), ('one', 'one'), ('intuitive', 'intuit'), ('metrics', 'metric'), ('evaluating', 'evalu'), ('performance', 'perform'), ('different', 'differ'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('platforms', 'platform'), ('algorithms', 'algorithm'), ('.', '.')]

>> Lemmatization: 
 [('By', 'By'), ('using', 'using'), ('benchmarks', 'benchmark'), (',', ','), ('computation', 'computation'), ('time', 'time'), ('one', 'one'), ('intuitive', 'intuitive'), ('metrics', 'metric'), ('evaluating', 'evaluating'), ('performance', 'performance'), ('different', 'different'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('platforms', 'platform'), ('algorithms', 'algorithm'), ('.', '.')]


------------------- Sentence 5 -------------------

That is why Cheptsov [136] compered the high perfor- mance computing (HPC) and cloud system by using the measurement of computation  time to understand their scalability for text file analysis.

>> Tokens are: 
 ['That', 'Cheptsov', '[', '136', ']', 'compered', 'high', 'perfor-', 'mance', 'computing', '(', 'HPC', ')', 'cloud', 'system', 'using', 'measurement', 'computation', 'time', 'understand', 'scalability', 'text', 'file', 'analysis', '.']

>> Bigrams are: 
 [('That', 'Cheptsov'), ('Cheptsov', '['), ('[', '136'), ('136', ']'), (']', 'compered'), ('compered', 'high'), ('high', 'perfor-'), ('perfor-', 'mance'), ('mance', 'computing'), ('computing', '('), ('(', 'HPC'), ('HPC', ')'), (')', 'cloud'), ('cloud', 'system'), ('system', 'using'), ('using', 'measurement'), ('measurement', 'computation'), ('computation', 'time'), ('time', 'understand'), ('understand', 'scalability'), ('scalability', 'text'), ('text', 'file'), ('file', 'analysis'), ('analysis', '.')]

>> Trigrams are: 
 [('That', 'Cheptsov', '['), ('Cheptsov', '[', '136'), ('[', '136', ']'), ('136', ']', 'compered'), (']', 'compered', 'high'), ('compered', 'high', 'perfor-'), ('high', 'perfor-', 'mance'), ('perfor-', 'mance', 'computing'), ('mance', 'computing', '('), ('computing', '(', 'HPC'), ('(', 'HPC', ')'), ('HPC', ')', 'cloud'), (')', 'cloud', 'system'), ('cloud', 'system', 'using'), ('system', 'using', 'measurement'), ('using', 'measurement', 'computation'), ('measurement', 'computation', 'time'), ('computation', 'time', 'understand'), ('time', 'understand', 'scalability'), ('understand', 'scalability', 'text'), ('scalability', 'text', 'file'), ('text', 'file', 'analysis'), ('file', 'analysis', '.')]

>> POS Tags are: 
 [('That', 'DT'), ('Cheptsov', 'NNP'), ('[', 'VBD'), ('136', 'CD'), (']', 'NN'), ('compered', 'VBN'), ('high', 'JJ'), ('perfor-', 'JJ'), ('mance', 'NN'), ('computing', 'NN'), ('(', '('), ('HPC', 'NNP'), (')', ')'), ('cloud', 'NN'), ('system', 'NN'), ('using', 'VBG'), ('measurement', 'JJ'), ('computation', 'NN'), ('time', 'NN'), ('understand', 'JJ'), ('scalability', 'NN'), ('text', 'NN'), ('file', 'NN'), ('analysis', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['That Cheptsov', ']', 'high perfor- mance computing', 'HPC', 'cloud system', 'measurement computation time', 'understand scalability text file analysis']

>> Named Entities are: 
 [('PERSON', 'Cheptsov'), ('ORGANIZATION', 'HPC')] 

>> Stemming using Porter Stemmer: 
 [('That', 'that'), ('Cheptsov', 'cheptsov'), ('[', '['), ('136', '136'), (']', ']'), ('compered', 'comper'), ('high', 'high'), ('perfor-', 'perfor-'), ('mance', 'manc'), ('computing', 'comput'), ('(', '('), ('HPC', 'hpc'), (')', ')'), ('cloud', 'cloud'), ('system', 'system'), ('using', 'use'), ('measurement', 'measur'), ('computation', 'comput'), ('time', 'time'), ('understand', 'understand'), ('scalability', 'scalabl'), ('text', 'text'), ('file', 'file'), ('analysis', 'analysi'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('That', 'that'), ('Cheptsov', 'cheptsov'), ('[', '['), ('136', '136'), (']', ']'), ('compered', 'comper'), ('high', 'high'), ('perfor-', 'perfor-'), ('mance', 'manc'), ('computing', 'comput'), ('(', '('), ('HPC', 'hpc'), (')', ')'), ('cloud', 'cloud'), ('system', 'system'), ('using', 'use'), ('measurement', 'measur'), ('computation', 'comput'), ('time', 'time'), ('understand', 'understand'), ('scalability', 'scalabl'), ('text', 'text'), ('file', 'file'), ('analysis', 'analysi'), ('.', '.')]

>> Lemmatization: 
 [('That', 'That'), ('Cheptsov', 'Cheptsov'), ('[', '['), ('136', '136'), (']', ']'), ('compered', 'compered'), ('high', 'high'), ('perfor-', 'perfor-'), ('mance', 'mance'), ('computing', 'computing'), ('(', '('), ('HPC', 'HPC'), (')', ')'), ('cloud', 'cloud'), ('system', 'system'), ('using', 'using'), ('measurement', 'measurement'), ('computation', 'computation'), ('time', 'time'), ('understand', 'understand'), ('scalability', 'scalability'), ('text', 'text'), ('file', 'file'), ('analysis', 'analysis'), ('.', '.')]


------------------- Sentence 6 -------------------

In addition to the computation  time, the throughput (e.g.-, the number of operations per second) and read/write latency  of operations are the other measurements of big data analytics [137].

>> Tokens are: 
 ['In', 'addition', 'computation', 'time', ',', 'throughput', '(', 'e.g.-', ',', 'number', 'operations', 'per', 'second', ')', 'read/write', 'latency', 'operations', 'measurements', 'big', 'data', 'analytics', '[', '137', ']', '.']

>> Bigrams are: 
 [('In', 'addition'), ('addition', 'computation'), ('computation', 'time'), ('time', ','), (',', 'throughput'), ('throughput', '('), ('(', 'e.g.-'), ('e.g.-', ','), (',', 'number'), ('number', 'operations'), ('operations', 'per'), ('per', 'second'), ('second', ')'), (')', 'read/write'), ('read/write', 'latency'), ('latency', 'operations'), ('operations', 'measurements'), ('measurements', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', '['), ('[', '137'), ('137', ']'), (']', '.')]

>> Trigrams are: 
 [('In', 'addition', 'computation'), ('addition', 'computation', 'time'), ('computation', 'time', ','), ('time', ',', 'throughput'), (',', 'throughput', '('), ('throughput', '(', 'e.g.-'), ('(', 'e.g.-', ','), ('e.g.-', ',', 'number'), (',', 'number', 'operations'), ('number', 'operations', 'per'), ('operations', 'per', 'second'), ('per', 'second', ')'), ('second', ')', 'read/write'), (')', 'read/write', 'latency'), ('read/write', 'latency', 'operations'), ('latency', 'operations', 'measurements'), ('operations', 'measurements', 'big'), ('measurements', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', '['), ('analytics', '[', '137'), ('[', '137', ']'), ('137', ']', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('addition', 'NN'), ('computation', 'NN'), ('time', 'NN'), (',', ','), ('throughput', 'NN'), ('(', '('), ('e.g.-', 'JJ'), (',', ','), ('number', 'NN'), ('operations', 'NNS'), ('per', 'IN'), ('second', 'NN'), (')', ')'), ('read/write', 'NN'), ('latency', 'NN'), ('operations', 'NNS'), ('measurements', 'NNS'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('[', 'VBP'), ('137', 'CD'), (']', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['addition computation time', 'throughput', 'number operations', 'second', 'read/write latency operations measurements', 'big data analytics', ']']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('addition', 'addit'), ('computation', 'comput'), ('time', 'time'), (',', ','), ('throughput', 'throughput'), ('(', '('), ('e.g.-', 'e.g.-'), (',', ','), ('number', 'number'), ('operations', 'oper'), ('per', 'per'), ('second', 'second'), (')', ')'), ('read/write', 'read/writ'), ('latency', 'latenc'), ('operations', 'oper'), ('measurements', 'measur'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('[', '['), ('137', '137'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('addition', 'addit'), ('computation', 'comput'), ('time', 'time'), (',', ','), ('throughput', 'throughput'), ('(', '('), ('e.g.-', 'e.g.-'), (',', ','), ('number', 'number'), ('operations', 'oper'), ('per', 'per'), ('second', 'second'), (')', ')'), ('read/write', 'read/writ'), ('latency', 'latenc'), ('operations', 'oper'), ('measurements', 'measur'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('[', '['), ('137', '137'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('addition', 'addition'), ('computation', 'computation'), ('time', 'time'), (',', ','), ('throughput', 'throughput'), ('(', '('), ('e.g.-', 'e.g.-'), (',', ','), ('number', 'number'), ('operations', 'operation'), ('per', 'per'), ('second', 'second'), (')', ')'), ('read/write', 'read/write'), ('latency', 'latency'), ('operations', 'operation'), ('measurements', 'measurement'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('[', '['), ('137', '137'), (']', ']'), ('.', '.')]


------------------- Sentence 7 -------------------

In the study of [138],  Zhao et al.

>> Tokens are: 
 ['In', 'study', '[', '138', ']', ',', 'Zhao', 'et', 'al', '.']

>> Bigrams are: 
 [('In', 'study'), ('study', '['), ('[', '138'), ('138', ']'), (']', ','), (',', 'Zhao'), ('Zhao', 'et'), ('et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('In', 'study', '['), ('study', '[', '138'), ('[', '138', ']'), ('138', ']', ','), (']', ',', 'Zhao'), (',', 'Zhao', 'et'), ('Zhao', 'et', 'al'), ('et', 'al', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('study', 'NN'), ('[', '$'), ('138', 'CD'), (']', 'NNP'), (',', ','), ('Zhao', 'NNP'), ('et', 'CC'), ('al', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['study', ']', 'Zhao', 'al']

>> Named Entities are: 
 [('PERSON', 'Zhao')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('study', 'studi'), ('[', '['), ('138', '138'), (']', ']'), (',', ','), ('Zhao', 'zhao'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('study', 'studi'), ('[', '['), ('138', '138'), (']', ']'), (',', ','), ('Zhao', 'zhao'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('study', 'study'), ('[', '['), ('138', '138'), (']', ']'), (',', ','), ('Zhao', 'Zhao'), ('et', 'et'), ('al', 'al'), ('.', '.')]


------------------- Sentence 8 -------------------

believe that the maximum size of data and the maximum number of jobs are  the two important metrics to understand the performance of the big data analytics plat- form.

>> Tokens are: 
 ['believe', 'maximum', 'size', 'data', 'maximum', 'number', 'jobs', 'two', 'important', 'metrics', 'understand', 'performance', 'big', 'data', 'analytics', 'plat-', 'form', '.']

>> Bigrams are: 
 [('believe', 'maximum'), ('maximum', 'size'), ('size', 'data'), ('data', 'maximum'), ('maximum', 'number'), ('number', 'jobs'), ('jobs', 'two'), ('two', 'important'), ('important', 'metrics'), ('metrics', 'understand'), ('understand', 'performance'), ('performance', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', 'plat-'), ('plat-', 'form'), ('form', '.')]

>> Trigrams are: 
 [('believe', 'maximum', 'size'), ('maximum', 'size', 'data'), ('size', 'data', 'maximum'), ('data', 'maximum', 'number'), ('maximum', 'number', 'jobs'), ('number', 'jobs', 'two'), ('jobs', 'two', 'important'), ('two', 'important', 'metrics'), ('important', 'metrics', 'understand'), ('metrics', 'understand', 'performance'), ('understand', 'performance', 'big'), ('performance', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', 'plat-'), ('analytics', 'plat-', 'form'), ('plat-', 'form', '.')]

>> POS Tags are: 
 [('believe', 'VB'), ('maximum', 'JJ'), ('size', 'NN'), ('data', 'NNS'), ('maximum', 'JJ'), ('number', 'NN'), ('jobs', 'NNS'), ('two', 'CD'), ('important', 'JJ'), ('metrics', 'NNS'), ('understand', 'VBP'), ('performance', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('plat-', 'JJ'), ('form', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['maximum size data', 'maximum number jobs', 'important metrics', 'performance', 'big data analytics', 'plat- form']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('believe', 'believ'), ('maximum', 'maximum'), ('size', 'size'), ('data', 'data'), ('maximum', 'maximum'), ('number', 'number'), ('jobs', 'job'), ('two', 'two'), ('important', 'import'), ('metrics', 'metric'), ('understand', 'understand'), ('performance', 'perform'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('plat-', 'plat-'), ('form', 'form'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('believe', 'believ'), ('maximum', 'maximum'), ('size', 'size'), ('data', 'data'), ('maximum', 'maximum'), ('number', 'number'), ('jobs', 'job'), ('two', 'two'), ('important', 'import'), ('metrics', 'metric'), ('understand', 'understand'), ('performance', 'perform'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('plat-', 'plat-'), ('form', 'form'), ('.', '.')]

>> Lemmatization: 
 [('believe', 'believe'), ('maximum', 'maximum'), ('size', 'size'), ('data', 'data'), ('maximum', 'maximum'), ('number', 'number'), ('jobs', 'job'), ('two', 'two'), ('important', 'important'), ('metrics', 'metric'), ('understand', 'understand'), ('performance', 'performance'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('plat-', 'plat-'), ('form', 'form'), ('.', '.')]


------------------- Sentence 9 -------------------

Another study described in [139] presented a systematic evaluation method which  contains the data throughput, concurrency during map and reduce phases, response  times, and the execution time of map and reduce.

>> Tokens are: 
 ['Another', 'study', 'described', '[', '139', ']', 'presented', 'systematic', 'evaluation', 'method', 'contains', 'data', 'throughput', ',', 'concurrency', 'map', 'reduce', 'phases', ',', 'response', 'times', ',', 'execution', 'time', 'map', 'reduce', '.']

>> Bigrams are: 
 [('Another', 'study'), ('study', 'described'), ('described', '['), ('[', '139'), ('139', ']'), (']', 'presented'), ('presented', 'systematic'), ('systematic', 'evaluation'), ('evaluation', 'method'), ('method', 'contains'), ('contains', 'data'), ('data', 'throughput'), ('throughput', ','), (',', 'concurrency'), ('concurrency', 'map'), ('map', 'reduce'), ('reduce', 'phases'), ('phases', ','), (',', 'response'), ('response', 'times'), ('times', ','), (',', 'execution'), ('execution', 'time'), ('time', 'map'), ('map', 'reduce'), ('reduce', '.')]

>> Trigrams are: 
 [('Another', 'study', 'described'), ('study', 'described', '['), ('described', '[', '139'), ('[', '139', ']'), ('139', ']', 'presented'), (']', 'presented', 'systematic'), ('presented', 'systematic', 'evaluation'), ('systematic', 'evaluation', 'method'), ('evaluation', 'method', 'contains'), ('method', 'contains', 'data'), ('contains', 'data', 'throughput'), ('data', 'throughput', ','), ('throughput', ',', 'concurrency'), (',', 'concurrency', 'map'), ('concurrency', 'map', 'reduce'), ('map', 'reduce', 'phases'), ('reduce', 'phases', ','), ('phases', ',', 'response'), (',', 'response', 'times'), ('response', 'times', ','), ('times', ',', 'execution'), (',', 'execution', 'time'), ('execution', 'time', 'map'), ('time', 'map', 'reduce'), ('map', 'reduce', '.')]

>> POS Tags are: 
 [('Another', 'DT'), ('study', 'NN'), ('described', 'VBD'), ('[', '$'), ('139', 'CD'), (']', 'NNP'), ('presented', 'VBD'), ('systematic', 'JJ'), ('evaluation', 'NN'), ('method', 'NN'), ('contains', 'VBZ'), ('data', 'NNS'), ('throughput', 'NN'), (',', ','), ('concurrency', 'NN'), ('map', 'NN'), ('reduce', 'VB'), ('phases', 'NNS'), (',', ','), ('response', 'NN'), ('times', 'NNS'), (',', ','), ('execution', 'NN'), ('time', 'NN'), ('map', 'JJ'), ('reduce', 'VB'), ('.', '.')]

>> Noun Phrases are: 
 ['Another study', ']', 'systematic evaluation method', 'data throughput', 'concurrency map', 'phases', 'response times', 'execution time']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Another', 'anoth'), ('study', 'studi'), ('described', 'describ'), ('[', '['), ('139', '139'), (']', ']'), ('presented', 'present'), ('systematic', 'systemat'), ('evaluation', 'evalu'), ('method', 'method'), ('contains', 'contain'), ('data', 'data'), ('throughput', 'throughput'), (',', ','), ('concurrency', 'concurr'), ('map', 'map'), ('reduce', 'reduc'), ('phases', 'phase'), (',', ','), ('response', 'respons'), ('times', 'time'), (',', ','), ('execution', 'execut'), ('time', 'time'), ('map', 'map'), ('reduce', 'reduc'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Another', 'anoth'), ('study', 'studi'), ('described', 'describ'), ('[', '['), ('139', '139'), (']', ']'), ('presented', 'present'), ('systematic', 'systemat'), ('evaluation', 'evalu'), ('method', 'method'), ('contains', 'contain'), ('data', 'data'), ('throughput', 'throughput'), (',', ','), ('concurrency', 'concurr'), ('map', 'map'), ('reduce', 'reduc'), ('phases', 'phase'), (',', ','), ('response', 'respons'), ('times', 'time'), (',', ','), ('execution', 'execut'), ('time', 'time'), ('map', 'map'), ('reduce', 'reduc'), ('.', '.')]

>> Lemmatization: 
 [('Another', 'Another'), ('study', 'study'), ('described', 'described'), ('[', '['), ('139', '139'), (']', ']'), ('presented', 'presented'), ('systematic', 'systematic'), ('evaluation', 'evaluation'), ('method', 'method'), ('contains', 'contains'), ('data', 'data'), ('throughput', 'throughput'), (',', ','), ('concurrency', 'concurrency'), ('map', 'map'), ('reduce', 'reduce'), ('phases', 'phase'), (',', ','), ('response', 'response'), ('times', 'time'), (',', ','), ('execution', 'execution'), ('time', 'time'), ('map', 'map'), ('reduce', 'reduce'), ('.', '.')]


------------------- Sentence 10 -------------------

Moreover, most benchmarks for evalu- ating the performance of big data analytics typically can only provide the response time  or the computation cost; however, the fact is that several factors need to be taken into  account at the same time when building a big data analytics system.

>> Tokens are: 
 ['Moreover', ',', 'benchmarks', 'evalu-', 'ating', 'performance', 'big', 'data', 'analytics', 'typically', 'provide', 'response', 'time', 'computation', 'cost', ';', 'however', ',', 'fact', 'several', 'factors', 'need', 'taken', 'account', 'time', 'building', 'big', 'data', 'analytics', 'system', '.']

>> Bigrams are: 
 [('Moreover', ','), (',', 'benchmarks'), ('benchmarks', 'evalu-'), ('evalu-', 'ating'), ('ating', 'performance'), ('performance', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', 'typically'), ('typically', 'provide'), ('provide', 'response'), ('response', 'time'), ('time', 'computation'), ('computation', 'cost'), ('cost', ';'), (';', 'however'), ('however', ','), (',', 'fact'), ('fact', 'several'), ('several', 'factors'), ('factors', 'need'), ('need', 'taken'), ('taken', 'account'), ('account', 'time'), ('time', 'building'), ('building', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', 'system'), ('system', '.')]

>> Trigrams are: 
 [('Moreover', ',', 'benchmarks'), (',', 'benchmarks', 'evalu-'), ('benchmarks', 'evalu-', 'ating'), ('evalu-', 'ating', 'performance'), ('ating', 'performance', 'big'), ('performance', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', 'typically'), ('analytics', 'typically', 'provide'), ('typically', 'provide', 'response'), ('provide', 'response', 'time'), ('response', 'time', 'computation'), ('time', 'computation', 'cost'), ('computation', 'cost', ';'), ('cost', ';', 'however'), (';', 'however', ','), ('however', ',', 'fact'), (',', 'fact', 'several'), ('fact', 'several', 'factors'), ('several', 'factors', 'need'), ('factors', 'need', 'taken'), ('need', 'taken', 'account'), ('taken', 'account', 'time'), ('account', 'time', 'building'), ('time', 'building', 'big'), ('building', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', 'system'), ('analytics', 'system', '.')]

>> POS Tags are: 
 [('Moreover', 'RB'), (',', ','), ('benchmarks', 'VBZ'), ('evalu-', 'JJ'), ('ating', 'VBG'), ('performance', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('typically', 'RB'), ('provide', 'VBP'), ('response', 'NN'), ('time', 'NN'), ('computation', 'NN'), ('cost', 'NN'), (';', ':'), ('however', 'RB'), (',', ','), ('fact', 'NN'), ('several', 'JJ'), ('factors', 'NNS'), ('need', 'VBP'), ('taken', 'VBN'), ('account', 'NN'), ('time', 'NN'), ('building', 'VBG'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('system', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['performance', 'big data analytics', 'response time computation cost', 'fact', 'several factors', 'account time', 'big data analytics system']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Moreover', 'moreov'), (',', ','), ('benchmarks', 'benchmark'), ('evalu-', 'evalu-'), ('ating', 'ate'), ('performance', 'perform'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('typically', 'typic'), ('provide', 'provid'), ('response', 'respons'), ('time', 'time'), ('computation', 'comput'), ('cost', 'cost'), (';', ';'), ('however', 'howev'), (',', ','), ('fact', 'fact'), ('several', 'sever'), ('factors', 'factor'), ('need', 'need'), ('taken', 'taken'), ('account', 'account'), ('time', 'time'), ('building', 'build'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('system', 'system'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Moreover', 'moreov'), (',', ','), ('benchmarks', 'benchmark'), ('evalu-', 'evalu-'), ('ating', 'ate'), ('performance', 'perform'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('typically', 'typic'), ('provide', 'provid'), ('response', 'respons'), ('time', 'time'), ('computation', 'comput'), ('cost', 'cost'), (';', ';'), ('however', 'howev'), (',', ','), ('fact', 'fact'), ('several', 'sever'), ('factors', 'factor'), ('need', 'need'), ('taken', 'taken'), ('account', 'account'), ('time', 'time'), ('building', 'build'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('system', 'system'), ('.', '.')]

>> Lemmatization: 
 [('Moreover', 'Moreover'), (',', ','), ('benchmarks', 'benchmark'), ('evalu-', 'evalu-'), ('ating', 'ating'), ('performance', 'performance'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('typically', 'typically'), ('provide', 'provide'), ('response', 'response'), ('time', 'time'), ('computation', 'computation'), ('cost', 'cost'), (';', ';'), ('however', 'however'), (',', ','), ('fact', 'fact'), ('several', 'several'), ('factors', 'factor'), ('need', 'need'), ('taken', 'taken'), ('account', 'account'), ('time', 'time'), ('building', 'building'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('system', 'system'), ('.', '.')]


------------------- Sentence 11 -------------------

The hardware, band- width for data transmission, fault tolerance, cost, power consumption of these systems  are all issues [70, 104] to be taken into account at the same time when building a big data  analytics system.

>> Tokens are: 
 ['The', 'hardware', ',', 'band-', 'width', 'data', 'transmission', ',', 'fault', 'tolerance', ',', 'cost', ',', 'power', 'consumption', 'systems', 'issues', '[', '70', ',', '104', ']', 'taken', 'account', 'time', 'building', 'big', 'data', 'analytics', 'system', '.']

>> Bigrams are: 
 [('The', 'hardware'), ('hardware', ','), (',', 'band-'), ('band-', 'width'), ('width', 'data'), ('data', 'transmission'), ('transmission', ','), (',', 'fault'), ('fault', 'tolerance'), ('tolerance', ','), (',', 'cost'), ('cost', ','), (',', 'power'), ('power', 'consumption'), ('consumption', 'systems'), ('systems', 'issues'), ('issues', '['), ('[', '70'), ('70', ','), (',', '104'), ('104', ']'), (']', 'taken'), ('taken', 'account'), ('account', 'time'), ('time', 'building'), ('building', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', 'system'), ('system', '.')]

>> Trigrams are: 
 [('The', 'hardware', ','), ('hardware', ',', 'band-'), (',', 'band-', 'width'), ('band-', 'width', 'data'), ('width', 'data', 'transmission'), ('data', 'transmission', ','), ('transmission', ',', 'fault'), (',', 'fault', 'tolerance'), ('fault', 'tolerance', ','), ('tolerance', ',', 'cost'), (',', 'cost', ','), ('cost', ',', 'power'), (',', 'power', 'consumption'), ('power', 'consumption', 'systems'), ('consumption', 'systems', 'issues'), ('systems', 'issues', '['), ('issues', '[', '70'), ('[', '70', ','), ('70', ',', '104'), (',', '104', ']'), ('104', ']', 'taken'), (']', 'taken', 'account'), ('taken', 'account', 'time'), ('account', 'time', 'building'), ('time', 'building', 'big'), ('building', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', 'system'), ('analytics', 'system', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('hardware', 'NN'), (',', ','), ('band-', 'JJ'), ('width', 'NN'), ('data', 'NNS'), ('transmission', 'NN'), (',', ','), ('fault', 'NN'), ('tolerance', 'NN'), (',', ','), ('cost', 'NN'), (',', ','), ('power', 'NN'), ('consumption', 'NN'), ('systems', 'NNS'), ('issues', 'NNS'), ('[', 'VBP'), ('70', 'CD'), (',', ','), ('104', 'CD'), (']', 'NN'), ('taken', 'VBN'), ('account', 'NN'), ('time', 'NN'), ('building', 'VBG'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('system', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['The hardware', 'band- width data transmission', 'fault tolerance', 'cost', 'power consumption systems issues', ']', 'account time', 'big data analytics system']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('hardware', 'hardwar'), (',', ','), ('band-', 'band-'), ('width', 'width'), ('data', 'data'), ('transmission', 'transmiss'), (',', ','), ('fault', 'fault'), ('tolerance', 'toler'), (',', ','), ('cost', 'cost'), (',', ','), ('power', 'power'), ('consumption', 'consumpt'), ('systems', 'system'), ('issues', 'issu'), ('[', '['), ('70', '70'), (',', ','), ('104', '104'), (']', ']'), ('taken', 'taken'), ('account', 'account'), ('time', 'time'), ('building', 'build'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('system', 'system'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('hardware', 'hardwar'), (',', ','), ('band-', 'band-'), ('width', 'width'), ('data', 'data'), ('transmission', 'transmiss'), (',', ','), ('fault', 'fault'), ('tolerance', 'toler'), (',', ','), ('cost', 'cost'), (',', ','), ('power', 'power'), ('consumption', 'consumpt'), ('systems', 'system'), ('issues', 'issu'), ('[', '['), ('70', '70'), (',', ','), ('104', '104'), (']', ']'), ('taken', 'taken'), ('account', 'account'), ('time', 'time'), ('building', 'build'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('system', 'system'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('hardware', 'hardware'), (',', ','), ('band-', 'band-'), ('width', 'width'), ('data', 'data'), ('transmission', 'transmission'), (',', ','), ('fault', 'fault'), ('tolerance', 'tolerance'), (',', ','), ('cost', 'cost'), (',', ','), ('power', 'power'), ('consumption', 'consumption'), ('systems', 'system'), ('issues', 'issue'), ('[', '['), ('70', '70'), (',', ','), ('104', '104'), (']', ']'), ('taken', 'taken'), ('account', 'account'), ('time', 'time'), ('building', 'building'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('system', 'system'), ('.', '.')]


------------------- Sentence 12 -------------------

Several solutions available today are to install the big data analytics on a  cloud computing system or a cluster system.

>> Tokens are: 
 ['Several', 'solutions', 'available', 'today', 'install', 'big', 'data', 'analytics', 'cloud', 'computing', 'system', 'cluster', 'system', '.']

>> Bigrams are: 
 [('Several', 'solutions'), ('solutions', 'available'), ('available', 'today'), ('today', 'install'), ('install', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', 'cloud'), ('cloud', 'computing'), ('computing', 'system'), ('system', 'cluster'), ('cluster', 'system'), ('system', '.')]

>> Trigrams are: 
 [('Several', 'solutions', 'available'), ('solutions', 'available', 'today'), ('available', 'today', 'install'), ('today', 'install', 'big'), ('install', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', 'cloud'), ('analytics', 'cloud', 'computing'), ('cloud', 'computing', 'system'), ('computing', 'system', 'cluster'), ('system', 'cluster', 'system'), ('cluster', 'system', '.')]

>> POS Tags are: 
 [('Several', 'JJ'), ('solutions', 'NNS'), ('available', 'JJ'), ('today', 'NN'), ('install', 'VBP'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('cloud', 'VBP'), ('computing', 'VBG'), ('system', 'NN'), ('cluster', 'NN'), ('system', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Several solutions', 'available today', 'big data analytics', 'system cluster system']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Several', 'sever'), ('solutions', 'solut'), ('available', 'avail'), ('today', 'today'), ('install', 'instal'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('cloud', 'cloud'), ('computing', 'comput'), ('system', 'system'), ('cluster', 'cluster'), ('system', 'system'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Several', 'sever'), ('solutions', 'solut'), ('available', 'avail'), ('today', 'today'), ('install', 'instal'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('cloud', 'cloud'), ('computing', 'comput'), ('system', 'system'), ('cluster', 'cluster'), ('system', 'system'), ('.', '.')]

>> Lemmatization: 
 [('Several', 'Several'), ('solutions', 'solution'), ('available', 'available'), ('today', 'today'), ('install', 'install'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('cloud', 'cloud'), ('computing', 'computing'), ('system', 'system'), ('cluster', 'cluster'), ('system', 'system'), ('.', '.')]


------------------- Sentence 13 -------------------

Therefore, the measurements of fault toler- ance, task execution, and cost of cloud computing systems can then be used to evaluate  the performance of the corresponding factors of big data analytics.

>> Tokens are: 
 ['Therefore', ',', 'measurements', 'fault', 'toler-', 'ance', ',', 'task', 'execution', ',', 'cost', 'cloud', 'computing', 'systems', 'used', 'evaluate', 'performance', 'corresponding', 'factors', 'big', 'data', 'analytics', '.']

>> Bigrams are: 
 [('Therefore', ','), (',', 'measurements'), ('measurements', 'fault'), ('fault', 'toler-'), ('toler-', 'ance'), ('ance', ','), (',', 'task'), ('task', 'execution'), ('execution', ','), (',', 'cost'), ('cost', 'cloud'), ('cloud', 'computing'), ('computing', 'systems'), ('systems', 'used'), ('used', 'evaluate'), ('evaluate', 'performance'), ('performance', 'corresponding'), ('corresponding', 'factors'), ('factors', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', '.')]

>> Trigrams are: 
 [('Therefore', ',', 'measurements'), (',', 'measurements', 'fault'), ('measurements', 'fault', 'toler-'), ('fault', 'toler-', 'ance'), ('toler-', 'ance', ','), ('ance', ',', 'task'), (',', 'task', 'execution'), ('task', 'execution', ','), ('execution', ',', 'cost'), (',', 'cost', 'cloud'), ('cost', 'cloud', 'computing'), ('cloud', 'computing', 'systems'), ('computing', 'systems', 'used'), ('systems', 'used', 'evaluate'), ('used', 'evaluate', 'performance'), ('evaluate', 'performance', 'corresponding'), ('performance', 'corresponding', 'factors'), ('corresponding', 'factors', 'big'), ('factors', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', '.')]

>> POS Tags are: 
 [('Therefore', 'RB'), (',', ','), ('measurements', 'NNS'), ('fault', 'VBP'), ('toler-', 'JJ'), ('ance', 'NN'), (',', ','), ('task', 'NN'), ('execution', 'NN'), (',', ','), ('cost', 'NN'), ('cloud', 'NN'), ('computing', 'VBG'), ('systems', 'NNS'), ('used', 'VBN'), ('evaluate', 'JJ'), ('performance', 'NN'), ('corresponding', 'VBG'), ('factors', 'NNS'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['measurements', 'toler- ance', 'task execution', 'cost cloud', 'systems', 'evaluate performance', 'factors', 'big data analytics']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Therefore', 'therefor'), (',', ','), ('measurements', 'measur'), ('fault', 'fault'), ('toler-', 'toler-'), ('ance', 'anc'), (',', ','), ('task', 'task'), ('execution', 'execut'), (',', ','), ('cost', 'cost'), ('cloud', 'cloud'), ('computing', 'comput'), ('systems', 'system'), ('used', 'use'), ('evaluate', 'evalu'), ('performance', 'perform'), ('corresponding', 'correspond'), ('factors', 'factor'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Therefore', 'therefor'), (',', ','), ('measurements', 'measur'), ('fault', 'fault'), ('toler-', 'toler-'), ('ance', 'anc'), (',', ','), ('task', 'task'), ('execution', 'execut'), (',', ','), ('cost', 'cost'), ('cloud', 'cloud'), ('computing', 'comput'), ('systems', 'system'), ('used', 'use'), ('evaluate', 'evalu'), ('performance', 'perform'), ('corresponding', 'correspond'), ('factors', 'factor'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('.', '.')]

>> Lemmatization: 
 [('Therefore', 'Therefore'), (',', ','), ('measurements', 'measurement'), ('fault', 'fault'), ('toler-', 'toler-'), ('ance', 'ance'), (',', ','), ('task', 'task'), ('execution', 'execution'), (',', ','), ('cost', 'cost'), ('cloud', 'cloud'), ('computing', 'computing'), ('systems', 'system'), ('used', 'used'), ('evaluate', 'evaluate'), ('performance', 'performance'), ('corresponding', 'corresponding'), ('factors', 'factor'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('.', '.')]



========================================== PARAGRAPH 311 ===========================================

How to present the analysis results to a user is another important work in the output  part of big data analytics because if the user cannot easily understand the meaning of  the results, the results will be entirely useless. Business intelligent and network monitor- ing are the two common approaches because their user interface plays the vital role of 

------------------- Sentence 1 -------------------

How to present the analysis results to a user is another important work in the output  part of big data analytics because if the user cannot easily understand the meaning of  the results, the results will be entirely useless.

>> Tokens are: 
 ['How', 'present', 'analysis', 'results', 'user', 'another', 'important', 'work', 'output', 'part', 'big', 'data', 'analytics', 'user', 'easily', 'understand', 'meaning', 'results', ',', 'results', 'entirely', 'useless', '.']

>> Bigrams are: 
 [('How', 'present'), ('present', 'analysis'), ('analysis', 'results'), ('results', 'user'), ('user', 'another'), ('another', 'important'), ('important', 'work'), ('work', 'output'), ('output', 'part'), ('part', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', 'user'), ('user', 'easily'), ('easily', 'understand'), ('understand', 'meaning'), ('meaning', 'results'), ('results', ','), (',', 'results'), ('results', 'entirely'), ('entirely', 'useless'), ('useless', '.')]

>> Trigrams are: 
 [('How', 'present', 'analysis'), ('present', 'analysis', 'results'), ('analysis', 'results', 'user'), ('results', 'user', 'another'), ('user', 'another', 'important'), ('another', 'important', 'work'), ('important', 'work', 'output'), ('work', 'output', 'part'), ('output', 'part', 'big'), ('part', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', 'user'), ('analytics', 'user', 'easily'), ('user', 'easily', 'understand'), ('easily', 'understand', 'meaning'), ('understand', 'meaning', 'results'), ('meaning', 'results', ','), ('results', ',', 'results'), (',', 'results', 'entirely'), ('results', 'entirely', 'useless'), ('entirely', 'useless', '.')]

>> POS Tags are: 
 [('How', 'WRB'), ('present', 'JJ'), ('analysis', 'NN'), ('results', 'NNS'), ('user', 'VBP'), ('another', 'DT'), ('important', 'JJ'), ('work', 'NN'), ('output', 'NN'), ('part', 'NN'), ('big', 'JJ'), ('data', 'NN'), ('analytics', 'NNS'), ('user', 'VBP'), ('easily', 'RB'), ('understand', 'RB'), ('meaning', 'VBG'), ('results', 'NNS'), (',', ','), ('results', 'NNS'), ('entirely', 'RB'), ('useless', 'JJ'), ('.', '.')]

>> Noun Phrases are: 
 ['present analysis results', 'another important work output part', 'big data analytics', 'results', 'results']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('How', 'how'), ('present', 'present'), ('analysis', 'analysi'), ('results', 'result'), ('user', 'user'), ('another', 'anoth'), ('important', 'import'), ('work', 'work'), ('output', 'output'), ('part', 'part'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('user', 'user'), ('easily', 'easili'), ('understand', 'understand'), ('meaning', 'mean'), ('results', 'result'), (',', ','), ('results', 'result'), ('entirely', 'entir'), ('useless', 'useless'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('How', 'how'), ('present', 'present'), ('analysis', 'analysi'), ('results', 'result'), ('user', 'user'), ('another', 'anoth'), ('important', 'import'), ('work', 'work'), ('output', 'output'), ('part', 'part'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('user', 'user'), ('easily', 'easili'), ('understand', 'understand'), ('meaning', 'mean'), ('results', 'result'), (',', ','), ('results', 'result'), ('entirely', 'entir'), ('useless', 'useless'), ('.', '.')]

>> Lemmatization: 
 [('How', 'How'), ('present', 'present'), ('analysis', 'analysis'), ('results', 'result'), ('user', 'user'), ('another', 'another'), ('important', 'important'), ('work', 'work'), ('output', 'output'), ('part', 'part'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('user', 'user'), ('easily', 'easily'), ('understand', 'understand'), ('meaning', 'meaning'), ('results', 'result'), (',', ','), ('results', 'result'), ('entirely', 'entirely'), ('useless', 'useless'), ('.', '.')]


------------------- Sentence 2 -------------------

Business intelligent and network monitor- ing are the two common approaches because their user interface plays the vital role of

>> Tokens are: 
 ['Business', 'intelligent', 'network', 'monitor-', 'ing', 'two', 'common', 'approaches', 'user', 'interface', 'plays', 'vital', 'role']

>> Bigrams are: 
 [('Business', 'intelligent'), ('intelligent', 'network'), ('network', 'monitor-'), ('monitor-', 'ing'), ('ing', 'two'), ('two', 'common'), ('common', 'approaches'), ('approaches', 'user'), ('user', 'interface'), ('interface', 'plays'), ('plays', 'vital'), ('vital', 'role')]

>> Trigrams are: 
 [('Business', 'intelligent', 'network'), ('intelligent', 'network', 'monitor-'), ('network', 'monitor-', 'ing'), ('monitor-', 'ing', 'two'), ('ing', 'two', 'common'), ('two', 'common', 'approaches'), ('common', 'approaches', 'user'), ('approaches', 'user', 'interface'), ('user', 'interface', 'plays'), ('interface', 'plays', 'vital'), ('plays', 'vital', 'role')]

>> POS Tags are: 
 [('Business', 'NN'), ('intelligent', 'NN'), ('network', 'NN'), ('monitor-', 'JJ'), ('ing', 'NN'), ('two', 'CD'), ('common', 'JJ'), ('approaches', 'NNS'), ('user', 'JJ'), ('interface', 'NN'), ('plays', 'NNS'), ('vital', 'JJ'), ('role', 'NN')]

>> Noun Phrases are: 
 ['Business intelligent network', 'monitor- ing', 'common approaches', 'user interface plays', 'vital role']

>> Named Entities are: 
 [('GPE', 'Business')] 

>> Stemming using Porter Stemmer: 
 [('Business', 'busi'), ('intelligent', 'intellig'), ('network', 'network'), ('monitor-', 'monitor-'), ('ing', 'ing'), ('two', 'two'), ('common', 'common'), ('approaches', 'approach'), ('user', 'user'), ('interface', 'interfac'), ('plays', 'play'), ('vital', 'vital'), ('role', 'role')]

>> Stemming using Snowball Stemmer: 
 [('Business', 'busi'), ('intelligent', 'intellig'), ('network', 'network'), ('monitor-', 'monitor-'), ('ing', 'ing'), ('two', 'two'), ('common', 'common'), ('approaches', 'approach'), ('user', 'user'), ('interface', 'interfac'), ('plays', 'play'), ('vital', 'vital'), ('role', 'role')]

>> Lemmatization: 
 [('Business', 'Business'), ('intelligent', 'intelligent'), ('network', 'network'), ('monitor-', 'monitor-'), ('ing', 'ing'), ('two', 'two'), ('common', 'common'), ('approaches', 'approach'), ('user', 'user'), ('interface', 'interface'), ('plays', 'play'), ('vital', 'vital'), ('role', 'role')]



========================================== PARAGRAPH 312 ===========================================

Page 21 of 32Tsai et al. Journal of Big Data  (2015) 2:21  

------------------- Sentence 1 -------------------

Page 21 of 32Tsai et al.

>> Tokens are: 
 ['Page', '21', '32Tsai', 'et', 'al', '.']

>> Bigrams are: 
 [('Page', '21'), ('21', '32Tsai'), ('32Tsai', 'et'), ('et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('Page', '21', '32Tsai'), ('21', '32Tsai', 'et'), ('32Tsai', 'et', 'al'), ('et', 'al', '.')]

>> POS Tags are: 
 [('Page', 'NN'), ('21', 'CD'), ('32Tsai', 'CD'), ('et', 'NN'), ('al', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Page', 'et al']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Page', 'page'), ('21', '21'), ('32Tsai', '32tsai'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Page', 'page'), ('21', '21'), ('32Tsai', '32tsai'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('Page', 'Page'), ('21', '21'), ('32Tsai', '32Tsai'), ('et', 'et'), ('al', 'al'), ('.', '.')]


------------------- Sentence 2 -------------------

Journal of Big Data  (2015) 2:21

>> Tokens are: 
 ['Journal', 'Big', 'Data', '(', '2015', ')', '2:21']

>> Bigrams are: 
 [('Journal', 'Big'), ('Big', 'Data'), ('Data', '('), ('(', '2015'), ('2015', ')'), (')', '2:21')]

>> Trigrams are: 
 [('Journal', 'Big', 'Data'), ('Big', 'Data', '('), ('Data', '(', '2015'), ('(', '2015', ')'), ('2015', ')', '2:21')]

>> POS Tags are: 
 [('Journal', 'NNP'), ('Big', 'NNP'), ('Data', 'NNP'), ('(', '('), ('2015', 'CD'), (')', ')'), ('2:21', 'CD')]

>> Noun Phrases are: 
 ['Journal Big Data']

>> Named Entities are: 
 [('PERSON', 'Journal')] 

>> Stemming using Porter Stemmer: 
 [('Journal', 'journal'), ('Big', 'big'), ('Data', 'data'), ('(', '('), ('2015', '2015'), (')', ')'), ('2:21', '2:21')]

>> Stemming using Snowball Stemmer: 
 [('Journal', 'journal'), ('Big', 'big'), ('Data', 'data'), ('(', '('), ('2015', '2015'), (')', ')'), ('2:21', '2:21')]

>> Lemmatization: 
 [('Journal', 'Journal'), ('Big', 'Big'), ('Data', 'Data'), ('(', '('), ('2015', '2015'), (')', ')'), ('2:21', '2:21')]



========================================== PARAGRAPH 313 ===========================================

making them workable. Zhang et al. [140] pointed out that the tasks of the visual analyt- ics for commercial systems can be divided into four categories which are exploration,  dashboards, reporting, and alerting. The study [141] showed that the interface for elec- troencephalography (EEG) interpretation is another noticeable research issue in big data  analytics. The user interface for cloud system [142, 143] is the recent trend for big data  analytics. This usually plays vital roles in big data analytics system, one of which is to  simplify the explanation of the needed knowledge to the users while the other is to make  it easier for the users to handle the data analytics system to work with their opinions.  According to our observations, a flexible user interface is needed because although the  big data analytics can help us to find some hidden information, the information found  usually is not knowledge. This situation is just like the example we mentioned in “Output  the result”. The mining or statistical techniques can be employed to know the flu situ- ation of each region, but data scientists sometimes need additional ways to display the  information to find out the knowledge they need or to prove their assumption. Thus,  the user interface can be adjusted by the user to display the knowledge that is needed  urgently for big data analytics. 

------------------- Sentence 1 -------------------

making them workable.

>> Tokens are: 
 ['making', 'workable', '.']

>> Bigrams are: 
 [('making', 'workable'), ('workable', '.')]

>> Trigrams are: 
 [('making', 'workable', '.')]

>> POS Tags are: 
 [('making', 'VBG'), ('workable', 'JJ'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('making', 'make'), ('workable', 'workabl'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('making', 'make'), ('workable', 'workabl'), ('.', '.')]

>> Lemmatization: 
 [('making', 'making'), ('workable', 'workable'), ('.', '.')]


------------------- Sentence 2 -------------------

Zhang et al.

>> Tokens are: 
 ['Zhang', 'et', 'al', '.']

>> Bigrams are: 
 [('Zhang', 'et'), ('et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('Zhang', 'et', 'al'), ('et', 'al', '.')]

>> POS Tags are: 
 [('Zhang', 'NNP'), ('et', 'CC'), ('al', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Zhang', 'al']

>> Named Entities are: 
 [('PERSON', 'Zhang')] 

>> Stemming using Porter Stemmer: 
 [('Zhang', 'zhang'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Zhang', 'zhang'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('Zhang', 'Zhang'), ('et', 'et'), ('al', 'al'), ('.', '.')]


------------------- Sentence 3 -------------------

[140] pointed out that the tasks of the visual analyt- ics for commercial systems can be divided into four categories which are exploration,  dashboards, reporting, and alerting.

>> Tokens are: 
 ['[', '140', ']', 'pointed', 'tasks', 'visual', 'analyt-', 'ics', 'commercial', 'systems', 'divided', 'four', 'categories', 'exploration', ',', 'dashboards', ',', 'reporting', ',', 'alerting', '.']

>> Bigrams are: 
 [('[', '140'), ('140', ']'), (']', 'pointed'), ('pointed', 'tasks'), ('tasks', 'visual'), ('visual', 'analyt-'), ('analyt-', 'ics'), ('ics', 'commercial'), ('commercial', 'systems'), ('systems', 'divided'), ('divided', 'four'), ('four', 'categories'), ('categories', 'exploration'), ('exploration', ','), (',', 'dashboards'), ('dashboards', ','), (',', 'reporting'), ('reporting', ','), (',', 'alerting'), ('alerting', '.')]

>> Trigrams are: 
 [('[', '140', ']'), ('140', ']', 'pointed'), (']', 'pointed', 'tasks'), ('pointed', 'tasks', 'visual'), ('tasks', 'visual', 'analyt-'), ('visual', 'analyt-', 'ics'), ('analyt-', 'ics', 'commercial'), ('ics', 'commercial', 'systems'), ('commercial', 'systems', 'divided'), ('systems', 'divided', 'four'), ('divided', 'four', 'categories'), ('four', 'categories', 'exploration'), ('categories', 'exploration', ','), ('exploration', ',', 'dashboards'), (',', 'dashboards', ','), ('dashboards', ',', 'reporting'), (',', 'reporting', ','), ('reporting', ',', 'alerting'), (',', 'alerting', '.')]

>> POS Tags are: 
 [('[', 'RB'), ('140', 'CD'), (']', 'NNS'), ('pointed', 'VBD'), ('tasks', 'NNS'), ('visual', 'JJ'), ('analyt-', 'JJ'), ('ics', 'NNS'), ('commercial', 'JJ'), ('systems', 'NNS'), ('divided', 'VBD'), ('four', 'CD'), ('categories', 'NNS'), ('exploration', 'NN'), (',', ','), ('dashboards', 'NNS'), (',', ','), ('reporting', 'NN'), (',', ','), ('alerting', 'VBG'), ('.', '.')]

>> Noun Phrases are: 
 [']', 'tasks', 'visual analyt- ics', 'commercial systems', 'categories exploration', 'dashboards', 'reporting']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('140', '140'), (']', ']'), ('pointed', 'point'), ('tasks', 'task'), ('visual', 'visual'), ('analyt-', 'analyt-'), ('ics', 'ic'), ('commercial', 'commerci'), ('systems', 'system'), ('divided', 'divid'), ('four', 'four'), ('categories', 'categori'), ('exploration', 'explor'), (',', ','), ('dashboards', 'dashboard'), (',', ','), ('reporting', 'report'), (',', ','), ('alerting', 'alert'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('140', '140'), (']', ']'), ('pointed', 'point'), ('tasks', 'task'), ('visual', 'visual'), ('analyt-', 'analyt-'), ('ics', 'ic'), ('commercial', 'commerci'), ('systems', 'system'), ('divided', 'divid'), ('four', 'four'), ('categories', 'categori'), ('exploration', 'explor'), (',', ','), ('dashboards', 'dashboard'), (',', ','), ('reporting', 'report'), (',', ','), ('alerting', 'alert'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('140', '140'), (']', ']'), ('pointed', 'pointed'), ('tasks', 'task'), ('visual', 'visual'), ('analyt-', 'analyt-'), ('ics', 'ic'), ('commercial', 'commercial'), ('systems', 'system'), ('divided', 'divided'), ('four', 'four'), ('categories', 'category'), ('exploration', 'exploration'), (',', ','), ('dashboards', 'dashboard'), (',', ','), ('reporting', 'reporting'), (',', ','), ('alerting', 'alerting'), ('.', '.')]


------------------- Sentence 4 -------------------

The study [141] showed that the interface for elec- troencephalography (EEG) interpretation is another noticeable research issue in big data  analytics.

>> Tokens are: 
 ['The', 'study', '[', '141', ']', 'showed', 'interface', 'elec-', 'troencephalography', '(', 'EEG', ')', 'interpretation', 'another', 'noticeable', 'research', 'issue', 'big', 'data', 'analytics', '.']

>> Bigrams are: 
 [('The', 'study'), ('study', '['), ('[', '141'), ('141', ']'), (']', 'showed'), ('showed', 'interface'), ('interface', 'elec-'), ('elec-', 'troencephalography'), ('troencephalography', '('), ('(', 'EEG'), ('EEG', ')'), (')', 'interpretation'), ('interpretation', 'another'), ('another', 'noticeable'), ('noticeable', 'research'), ('research', 'issue'), ('issue', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', '.')]

>> Trigrams are: 
 [('The', 'study', '['), ('study', '[', '141'), ('[', '141', ']'), ('141', ']', 'showed'), (']', 'showed', 'interface'), ('showed', 'interface', 'elec-'), ('interface', 'elec-', 'troencephalography'), ('elec-', 'troencephalography', '('), ('troencephalography', '(', 'EEG'), ('(', 'EEG', ')'), ('EEG', ')', 'interpretation'), (')', 'interpretation', 'another'), ('interpretation', 'another', 'noticeable'), ('another', 'noticeable', 'research'), ('noticeable', 'research', 'issue'), ('research', 'issue', 'big'), ('issue', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('study', 'NN'), ('[', 'VBD'), ('141', 'CD'), (']', 'NN'), ('showed', 'VBD'), ('interface', 'JJ'), ('elec-', 'JJ'), ('troencephalography', 'NN'), ('(', '('), ('EEG', 'NNP'), (')', ')'), ('interpretation', 'NN'), ('another', 'DT'), ('noticeable', 'JJ'), ('research', 'NN'), ('issue', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['The study', ']', 'interface elec- troencephalography', 'EEG', 'interpretation', 'another noticeable research issue', 'big data analytics']

>> Named Entities are: 
 [('ORGANIZATION', 'EEG')] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('study', 'studi'), ('[', '['), ('141', '141'), (']', ']'), ('showed', 'show'), ('interface', 'interfac'), ('elec-', 'elec-'), ('troencephalography', 'troencephalographi'), ('(', '('), ('EEG', 'eeg'), (')', ')'), ('interpretation', 'interpret'), ('another', 'anoth'), ('noticeable', 'notic'), ('research', 'research'), ('issue', 'issu'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('study', 'studi'), ('[', '['), ('141', '141'), (']', ']'), ('showed', 'show'), ('interface', 'interfac'), ('elec-', 'elec-'), ('troencephalography', 'troencephalographi'), ('(', '('), ('EEG', 'eeg'), (')', ')'), ('interpretation', 'interpret'), ('another', 'anoth'), ('noticeable', 'notic'), ('research', 'research'), ('issue', 'issu'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('study', 'study'), ('[', '['), ('141', '141'), (']', ']'), ('showed', 'showed'), ('interface', 'interface'), ('elec-', 'elec-'), ('troencephalography', 'troencephalography'), ('(', '('), ('EEG', 'EEG'), (')', ')'), ('interpretation', 'interpretation'), ('another', 'another'), ('noticeable', 'noticeable'), ('research', 'research'), ('issue', 'issue'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('.', '.')]


------------------- Sentence 5 -------------------

The user interface for cloud system [142, 143] is the recent trend for big data  analytics.

>> Tokens are: 
 ['The', 'user', 'interface', 'cloud', 'system', '[', '142', ',', '143', ']', 'recent', 'trend', 'big', 'data', 'analytics', '.']

>> Bigrams are: 
 [('The', 'user'), ('user', 'interface'), ('interface', 'cloud'), ('cloud', 'system'), ('system', '['), ('[', '142'), ('142', ','), (',', '143'), ('143', ']'), (']', 'recent'), ('recent', 'trend'), ('trend', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', '.')]

>> Trigrams are: 
 [('The', 'user', 'interface'), ('user', 'interface', 'cloud'), ('interface', 'cloud', 'system'), ('cloud', 'system', '['), ('system', '[', '142'), ('[', '142', ','), ('142', ',', '143'), (',', '143', ']'), ('143', ']', 'recent'), (']', 'recent', 'trend'), ('recent', 'trend', 'big'), ('trend', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('user', 'JJ'), ('interface', 'NN'), ('cloud', 'NN'), ('system', 'NN'), ('[', 'VBD'), ('142', 'CD'), (',', ','), ('143', 'CD'), (']', 'JJ'), ('recent', 'JJ'), ('trend', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['The user interface cloud system', '] recent trend', 'big data analytics']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('user', 'user'), ('interface', 'interfac'), ('cloud', 'cloud'), ('system', 'system'), ('[', '['), ('142', '142'), (',', ','), ('143', '143'), (']', ']'), ('recent', 'recent'), ('trend', 'trend'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('user', 'user'), ('interface', 'interfac'), ('cloud', 'cloud'), ('system', 'system'), ('[', '['), ('142', '142'), (',', ','), ('143', '143'), (']', ']'), ('recent', 'recent'), ('trend', 'trend'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('user', 'user'), ('interface', 'interface'), ('cloud', 'cloud'), ('system', 'system'), ('[', '['), ('142', '142'), (',', ','), ('143', '143'), (']', ']'), ('recent', 'recent'), ('trend', 'trend'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('.', '.')]


------------------- Sentence 6 -------------------

This usually plays vital roles in big data analytics system, one of which is to  simplify the explanation of the needed knowledge to the users while the other is to make  it easier for the users to handle the data analytics system to work with their opinions.

>> Tokens are: 
 ['This', 'usually', 'plays', 'vital', 'roles', 'big', 'data', 'analytics', 'system', ',', 'one', 'simplify', 'explanation', 'needed', 'knowledge', 'users', 'make', 'easier', 'users', 'handle', 'data', 'analytics', 'system', 'work', 'opinions', '.']

>> Bigrams are: 
 [('This', 'usually'), ('usually', 'plays'), ('plays', 'vital'), ('vital', 'roles'), ('roles', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', 'system'), ('system', ','), (',', 'one'), ('one', 'simplify'), ('simplify', 'explanation'), ('explanation', 'needed'), ('needed', 'knowledge'), ('knowledge', 'users'), ('users', 'make'), ('make', 'easier'), ('easier', 'users'), ('users', 'handle'), ('handle', 'data'), ('data', 'analytics'), ('analytics', 'system'), ('system', 'work'), ('work', 'opinions'), ('opinions', '.')]

>> Trigrams are: 
 [('This', 'usually', 'plays'), ('usually', 'plays', 'vital'), ('plays', 'vital', 'roles'), ('vital', 'roles', 'big'), ('roles', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', 'system'), ('analytics', 'system', ','), ('system', ',', 'one'), (',', 'one', 'simplify'), ('one', 'simplify', 'explanation'), ('simplify', 'explanation', 'needed'), ('explanation', 'needed', 'knowledge'), ('needed', 'knowledge', 'users'), ('knowledge', 'users', 'make'), ('users', 'make', 'easier'), ('make', 'easier', 'users'), ('easier', 'users', 'handle'), ('users', 'handle', 'data'), ('handle', 'data', 'analytics'), ('data', 'analytics', 'system'), ('analytics', 'system', 'work'), ('system', 'work', 'opinions'), ('work', 'opinions', '.')]

>> POS Tags are: 
 [('This', 'DT'), ('usually', 'RB'), ('plays', 'VBZ'), ('vital', 'JJ'), ('roles', 'NNS'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('system', 'NN'), (',', ','), ('one', 'CD'), ('simplify', 'NN'), ('explanation', 'NN'), ('needed', 'VBD'), ('knowledge', 'NN'), ('users', 'NNS'), ('make', 'VBP'), ('easier', 'JJR'), ('users', 'NNS'), ('handle', 'VBP'), ('data', 'NNS'), ('analytics', 'NNS'), ('system', 'NN'), ('work', 'NN'), ('opinions', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['vital roles', 'big data analytics system', 'simplify explanation', 'knowledge users', 'users', 'data analytics system work opinions']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('This', 'thi'), ('usually', 'usual'), ('plays', 'play'), ('vital', 'vital'), ('roles', 'role'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('system', 'system'), (',', ','), ('one', 'one'), ('simplify', 'simplifi'), ('explanation', 'explan'), ('needed', 'need'), ('knowledge', 'knowledg'), ('users', 'user'), ('make', 'make'), ('easier', 'easier'), ('users', 'user'), ('handle', 'handl'), ('data', 'data'), ('analytics', 'analyt'), ('system', 'system'), ('work', 'work'), ('opinions', 'opinion'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('This', 'this'), ('usually', 'usual'), ('plays', 'play'), ('vital', 'vital'), ('roles', 'role'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('system', 'system'), (',', ','), ('one', 'one'), ('simplify', 'simplifi'), ('explanation', 'explan'), ('needed', 'need'), ('knowledge', 'knowledg'), ('users', 'user'), ('make', 'make'), ('easier', 'easier'), ('users', 'user'), ('handle', 'handl'), ('data', 'data'), ('analytics', 'analyt'), ('system', 'system'), ('work', 'work'), ('opinions', 'opinion'), ('.', '.')]

>> Lemmatization: 
 [('This', 'This'), ('usually', 'usually'), ('plays', 'play'), ('vital', 'vital'), ('roles', 'role'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('system', 'system'), (',', ','), ('one', 'one'), ('simplify', 'simplify'), ('explanation', 'explanation'), ('needed', 'needed'), ('knowledge', 'knowledge'), ('users', 'user'), ('make', 'make'), ('easier', 'easier'), ('users', 'user'), ('handle', 'handle'), ('data', 'data'), ('analytics', 'analytics'), ('system', 'system'), ('work', 'work'), ('opinions', 'opinion'), ('.', '.')]


------------------- Sentence 7 -------------------

According to our observations, a flexible user interface is needed because although the  big data analytics can help us to find some hidden information, the information found  usually is not knowledge.

>> Tokens are: 
 ['According', 'observations', ',', 'flexible', 'user', 'interface', 'needed', 'although', 'big', 'data', 'analytics', 'help', 'us', 'find', 'hidden', 'information', ',', 'information', 'found', 'usually', 'knowledge', '.']

>> Bigrams are: 
 [('According', 'observations'), ('observations', ','), (',', 'flexible'), ('flexible', 'user'), ('user', 'interface'), ('interface', 'needed'), ('needed', 'although'), ('although', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', 'help'), ('help', 'us'), ('us', 'find'), ('find', 'hidden'), ('hidden', 'information'), ('information', ','), (',', 'information'), ('information', 'found'), ('found', 'usually'), ('usually', 'knowledge'), ('knowledge', '.')]

>> Trigrams are: 
 [('According', 'observations', ','), ('observations', ',', 'flexible'), (',', 'flexible', 'user'), ('flexible', 'user', 'interface'), ('user', 'interface', 'needed'), ('interface', 'needed', 'although'), ('needed', 'although', 'big'), ('although', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', 'help'), ('analytics', 'help', 'us'), ('help', 'us', 'find'), ('us', 'find', 'hidden'), ('find', 'hidden', 'information'), ('hidden', 'information', ','), ('information', ',', 'information'), (',', 'information', 'found'), ('information', 'found', 'usually'), ('found', 'usually', 'knowledge'), ('usually', 'knowledge', '.')]

>> POS Tags are: 
 [('According', 'VBG'), ('observations', 'NNS'), (',', ','), ('flexible', 'JJ'), ('user', 'NN'), ('interface', 'NN'), ('needed', 'VBN'), ('although', 'IN'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('help', 'VBP'), ('us', 'PRP'), ('find', 'VB'), ('hidden', 'JJ'), ('information', 'NN'), (',', ','), ('information', 'NN'), ('found', 'VBD'), ('usually', 'RB'), ('knowledge', 'VBN'), ('.', '.')]

>> Noun Phrases are: 
 ['observations', 'flexible user interface', 'big data analytics', 'hidden information', 'information']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('According', 'accord'), ('observations', 'observ'), (',', ','), ('flexible', 'flexibl'), ('user', 'user'), ('interface', 'interfac'), ('needed', 'need'), ('although', 'although'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('help', 'help'), ('us', 'us'), ('find', 'find'), ('hidden', 'hidden'), ('information', 'inform'), (',', ','), ('information', 'inform'), ('found', 'found'), ('usually', 'usual'), ('knowledge', 'knowledg'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('According', 'accord'), ('observations', 'observ'), (',', ','), ('flexible', 'flexibl'), ('user', 'user'), ('interface', 'interfac'), ('needed', 'need'), ('although', 'although'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('help', 'help'), ('us', 'us'), ('find', 'find'), ('hidden', 'hidden'), ('information', 'inform'), (',', ','), ('information', 'inform'), ('found', 'found'), ('usually', 'usual'), ('knowledge', 'knowledg'), ('.', '.')]

>> Lemmatization: 
 [('According', 'According'), ('observations', 'observation'), (',', ','), ('flexible', 'flexible'), ('user', 'user'), ('interface', 'interface'), ('needed', 'needed'), ('although', 'although'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('help', 'help'), ('us', 'u'), ('find', 'find'), ('hidden', 'hidden'), ('information', 'information'), (',', ','), ('information', 'information'), ('found', 'found'), ('usually', 'usually'), ('knowledge', 'knowledge'), ('.', '.')]


------------------- Sentence 8 -------------------

This situation is just like the example we mentioned in “Output  the result”.

>> Tokens are: 
 ['This', 'situation', 'like', 'example', 'mentioned', '“', 'Output', 'result', '”', '.']

>> Bigrams are: 
 [('This', 'situation'), ('situation', 'like'), ('like', 'example'), ('example', 'mentioned'), ('mentioned', '“'), ('“', 'Output'), ('Output', 'result'), ('result', '”'), ('”', '.')]

>> Trigrams are: 
 [('This', 'situation', 'like'), ('situation', 'like', 'example'), ('like', 'example', 'mentioned'), ('example', 'mentioned', '“'), ('mentioned', '“', 'Output'), ('“', 'Output', 'result'), ('Output', 'result', '”'), ('result', '”', '.')]

>> POS Tags are: 
 [('This', 'DT'), ('situation', 'NN'), ('like', 'IN'), ('example', 'NN'), ('mentioned', 'VBD'), ('“', 'NNP'), ('Output', 'NNP'), ('result', 'NN'), ('”', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['This situation', 'example', '“ Output result ”']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('This', 'thi'), ('situation', 'situat'), ('like', 'like'), ('example', 'exampl'), ('mentioned', 'mention'), ('“', '“'), ('Output', 'output'), ('result', 'result'), ('”', '”'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('This', 'this'), ('situation', 'situat'), ('like', 'like'), ('example', 'exampl'), ('mentioned', 'mention'), ('“', '“'), ('Output', 'output'), ('result', 'result'), ('”', '”'), ('.', '.')]

>> Lemmatization: 
 [('This', 'This'), ('situation', 'situation'), ('like', 'like'), ('example', 'example'), ('mentioned', 'mentioned'), ('“', '“'), ('Output', 'Output'), ('result', 'result'), ('”', '”'), ('.', '.')]


------------------- Sentence 9 -------------------

The mining or statistical techniques can be employed to know the flu situ- ation of each region, but data scientists sometimes need additional ways to display the  information to find out the knowledge they need or to prove their assumption.

>> Tokens are: 
 ['The', 'mining', 'statistical', 'techniques', 'employed', 'know', 'flu', 'situ-', 'ation', 'region', ',', 'data', 'scientists', 'sometimes', 'need', 'additional', 'ways', 'display', 'information', 'find', 'knowledge', 'need', 'prove', 'assumption', '.']

>> Bigrams are: 
 [('The', 'mining'), ('mining', 'statistical'), ('statistical', 'techniques'), ('techniques', 'employed'), ('employed', 'know'), ('know', 'flu'), ('flu', 'situ-'), ('situ-', 'ation'), ('ation', 'region'), ('region', ','), (',', 'data'), ('data', 'scientists'), ('scientists', 'sometimes'), ('sometimes', 'need'), ('need', 'additional'), ('additional', 'ways'), ('ways', 'display'), ('display', 'information'), ('information', 'find'), ('find', 'knowledge'), ('knowledge', 'need'), ('need', 'prove'), ('prove', 'assumption'), ('assumption', '.')]

>> Trigrams are: 
 [('The', 'mining', 'statistical'), ('mining', 'statistical', 'techniques'), ('statistical', 'techniques', 'employed'), ('techniques', 'employed', 'know'), ('employed', 'know', 'flu'), ('know', 'flu', 'situ-'), ('flu', 'situ-', 'ation'), ('situ-', 'ation', 'region'), ('ation', 'region', ','), ('region', ',', 'data'), (',', 'data', 'scientists'), ('data', 'scientists', 'sometimes'), ('scientists', 'sometimes', 'need'), ('sometimes', 'need', 'additional'), ('need', 'additional', 'ways'), ('additional', 'ways', 'display'), ('ways', 'display', 'information'), ('display', 'information', 'find'), ('information', 'find', 'knowledge'), ('find', 'knowledge', 'need'), ('knowledge', 'need', 'prove'), ('need', 'prove', 'assumption'), ('prove', 'assumption', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('mining', 'NN'), ('statistical', 'JJ'), ('techniques', 'NNS'), ('employed', 'VBN'), ('know', 'VBP'), ('flu', 'JJ'), ('situ-', 'JJ'), ('ation', 'NN'), ('region', 'NN'), (',', ','), ('data', 'NN'), ('scientists', 'NNS'), ('sometimes', 'RB'), ('need', 'VBP'), ('additional', 'JJ'), ('ways', 'NNS'), ('display', 'VBP'), ('information', 'NN'), ('find', 'VBP'), ('knowledge', 'NN'), ('need', 'VBP'), ('prove', 'VB'), ('assumption', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['The mining', 'statistical techniques', 'flu situ- ation region', 'data scientists', 'additional ways', 'information', 'knowledge', 'assumption']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('mining', 'mine'), ('statistical', 'statist'), ('techniques', 'techniqu'), ('employed', 'employ'), ('know', 'know'), ('flu', 'flu'), ('situ-', 'situ-'), ('ation', 'ation'), ('region', 'region'), (',', ','), ('data', 'data'), ('scientists', 'scientist'), ('sometimes', 'sometim'), ('need', 'need'), ('additional', 'addit'), ('ways', 'way'), ('display', 'display'), ('information', 'inform'), ('find', 'find'), ('knowledge', 'knowledg'), ('need', 'need'), ('prove', 'prove'), ('assumption', 'assumpt'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('mining', 'mine'), ('statistical', 'statist'), ('techniques', 'techniqu'), ('employed', 'employ'), ('know', 'know'), ('flu', 'flu'), ('situ-', 'situ-'), ('ation', 'ation'), ('region', 'region'), (',', ','), ('data', 'data'), ('scientists', 'scientist'), ('sometimes', 'sometim'), ('need', 'need'), ('additional', 'addit'), ('ways', 'way'), ('display', 'display'), ('information', 'inform'), ('find', 'find'), ('knowledge', 'knowledg'), ('need', 'need'), ('prove', 'prove'), ('assumption', 'assumpt'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('mining', 'mining'), ('statistical', 'statistical'), ('techniques', 'technique'), ('employed', 'employed'), ('know', 'know'), ('flu', 'flu'), ('situ-', 'situ-'), ('ation', 'ation'), ('region', 'region'), (',', ','), ('data', 'data'), ('scientists', 'scientist'), ('sometimes', 'sometimes'), ('need', 'need'), ('additional', 'additional'), ('ways', 'way'), ('display', 'display'), ('information', 'information'), ('find', 'find'), ('knowledge', 'knowledge'), ('need', 'need'), ('prove', 'prove'), ('assumption', 'assumption'), ('.', '.')]


------------------- Sentence 10 -------------------

Thus,  the user interface can be adjusted by the user to display the knowledge that is needed  urgently for big data analytics.

>> Tokens are: 
 ['Thus', ',', 'user', 'interface', 'adjusted', 'user', 'display', 'knowledge', 'needed', 'urgently', 'big', 'data', 'analytics', '.']

>> Bigrams are: 
 [('Thus', ','), (',', 'user'), ('user', 'interface'), ('interface', 'adjusted'), ('adjusted', 'user'), ('user', 'display'), ('display', 'knowledge'), ('knowledge', 'needed'), ('needed', 'urgently'), ('urgently', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', '.')]

>> Trigrams are: 
 [('Thus', ',', 'user'), (',', 'user', 'interface'), ('user', 'interface', 'adjusted'), ('interface', 'adjusted', 'user'), ('adjusted', 'user', 'display'), ('user', 'display', 'knowledge'), ('display', 'knowledge', 'needed'), ('knowledge', 'needed', 'urgently'), ('needed', 'urgently', 'big'), ('urgently', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', '.')]

>> POS Tags are: 
 [('Thus', 'RB'), (',', ','), ('user', 'JJ'), ('interface', 'NN'), ('adjusted', 'VBN'), ('user', 'JJ'), ('display', 'NN'), ('knowledge', 'NN'), ('needed', 'VBN'), ('urgently', 'RB'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['user interface', 'user display knowledge', 'big data analytics']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Thus', 'thu'), (',', ','), ('user', 'user'), ('interface', 'interfac'), ('adjusted', 'adjust'), ('user', 'user'), ('display', 'display'), ('knowledge', 'knowledg'), ('needed', 'need'), ('urgently', 'urgent'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Thus', 'thus'), (',', ','), ('user', 'user'), ('interface', 'interfac'), ('adjusted', 'adjust'), ('user', 'user'), ('display', 'display'), ('knowledge', 'knowledg'), ('needed', 'need'), ('urgently', 'urgent'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('.', '.')]

>> Lemmatization: 
 [('Thus', 'Thus'), (',', ','), ('user', 'user'), ('interface', 'interface'), ('adjusted', 'adjusted'), ('user', 'user'), ('display', 'display'), ('knowledge', 'knowledge'), ('needed', 'needed'), ('urgently', 'urgently'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('.', '.')]



========================================== PARAGRAPH 314 ===========================================

Summary of process of big data analytics 

------------------- Sentence 1 -------------------

Summary of process of big data analytics

>> Tokens are: 
 ['Summary', 'process', 'big', 'data', 'analytics']

>> Bigrams are: 
 [('Summary', 'process'), ('process', 'big'), ('big', 'data'), ('data', 'analytics')]

>> Trigrams are: 
 [('Summary', 'process', 'big'), ('process', 'big', 'data'), ('big', 'data', 'analytics')]

>> POS Tags are: 
 [('Summary', 'JJ'), ('process', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS')]

>> Noun Phrases are: 
 ['Summary process', 'big data analytics']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Summary', 'summari'), ('process', 'process'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt')]

>> Stemming using Snowball Stemmer: 
 [('Summary', 'summari'), ('process', 'process'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt')]

>> Lemmatization: 
 [('Summary', 'Summary'), ('process', 'process'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics')]



========================================== PARAGRAPH 315 ===========================================

This discussion of big data analytics in this section was divided into input, analysis, and  output for mapping the data analysis process of KDD. For the input (see also in “Big data  input”) and output (see also “Output the result of big data analysis”) of big data, several  methods and solutions proposed before the big data age (see also “Data input”) can also  be employed for big data analytics in most cases. 

------------------- Sentence 1 -------------------

This discussion of big data analytics in this section was divided into input, analysis, and  output for mapping the data analysis process of KDD.

>> Tokens are: 
 ['This', 'discussion', 'big', 'data', 'analytics', 'section', 'divided', 'input', ',', 'analysis', ',', 'output', 'mapping', 'data', 'analysis', 'process', 'KDD', '.']

>> Bigrams are: 
 [('This', 'discussion'), ('discussion', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', 'section'), ('section', 'divided'), ('divided', 'input'), ('input', ','), (',', 'analysis'), ('analysis', ','), (',', 'output'), ('output', 'mapping'), ('mapping', 'data'), ('data', 'analysis'), ('analysis', 'process'), ('process', 'KDD'), ('KDD', '.')]

>> Trigrams are: 
 [('This', 'discussion', 'big'), ('discussion', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', 'section'), ('analytics', 'section', 'divided'), ('section', 'divided', 'input'), ('divided', 'input', ','), ('input', ',', 'analysis'), (',', 'analysis', ','), ('analysis', ',', 'output'), (',', 'output', 'mapping'), ('output', 'mapping', 'data'), ('mapping', 'data', 'analysis'), ('data', 'analysis', 'process'), ('analysis', 'process', 'KDD'), ('process', 'KDD', '.')]

>> POS Tags are: 
 [('This', 'DT'), ('discussion', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('section', 'NN'), ('divided', 'VBD'), ('input', 'NN'), (',', ','), ('analysis', 'NN'), (',', ','), ('output', 'NN'), ('mapping', 'VBG'), ('data', 'NNS'), ('analysis', 'NN'), ('process', 'NN'), ('KDD', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['This discussion', 'big data analytics section', 'input', 'analysis', 'output', 'data analysis process KDD']

>> Named Entities are: 
 [('ORGANIZATION', 'KDD')] 

>> Stemming using Porter Stemmer: 
 [('This', 'thi'), ('discussion', 'discuss'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('section', 'section'), ('divided', 'divid'), ('input', 'input'), (',', ','), ('analysis', 'analysi'), (',', ','), ('output', 'output'), ('mapping', 'map'), ('data', 'data'), ('analysis', 'analysi'), ('process', 'process'), ('KDD', 'kdd'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('This', 'this'), ('discussion', 'discuss'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('section', 'section'), ('divided', 'divid'), ('input', 'input'), (',', ','), ('analysis', 'analysi'), (',', ','), ('output', 'output'), ('mapping', 'map'), ('data', 'data'), ('analysis', 'analysi'), ('process', 'process'), ('KDD', 'kdd'), ('.', '.')]

>> Lemmatization: 
 [('This', 'This'), ('discussion', 'discussion'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('section', 'section'), ('divided', 'divided'), ('input', 'input'), (',', ','), ('analysis', 'analysis'), (',', ','), ('output', 'output'), ('mapping', 'mapping'), ('data', 'data'), ('analysis', 'analysis'), ('process', 'process'), ('KDD', 'KDD'), ('.', '.')]


------------------- Sentence 2 -------------------

For the input (see also in “Big data  input”) and output (see also “Output the result of big data analysis”) of big data, several  methods and solutions proposed before the big data age (see also “Data input”) can also  be employed for big data analytics in most cases.

>> Tokens are: 
 ['For', 'input', '(', 'see', 'also', '“', 'Big', 'data', 'input', '”', ')', 'output', '(', 'see', 'also', '“', 'Output', 'result', 'big', 'data', 'analysis', '”', ')', 'big', 'data', ',', 'several', 'methods', 'solutions', 'proposed', 'big', 'data', 'age', '(', 'see', 'also', '“', 'Data', 'input', '”', ')', 'also', 'employed', 'big', 'data', 'analytics', 'cases', '.']

>> Bigrams are: 
 [('For', 'input'), ('input', '('), ('(', 'see'), ('see', 'also'), ('also', '“'), ('“', 'Big'), ('Big', 'data'), ('data', 'input'), ('input', '”'), ('”', ')'), (')', 'output'), ('output', '('), ('(', 'see'), ('see', 'also'), ('also', '“'), ('“', 'Output'), ('Output', 'result'), ('result', 'big'), ('big', 'data'), ('data', 'analysis'), ('analysis', '”'), ('”', ')'), (')', 'big'), ('big', 'data'), ('data', ','), (',', 'several'), ('several', 'methods'), ('methods', 'solutions'), ('solutions', 'proposed'), ('proposed', 'big'), ('big', 'data'), ('data', 'age'), ('age', '('), ('(', 'see'), ('see', 'also'), ('also', '“'), ('“', 'Data'), ('Data', 'input'), ('input', '”'), ('”', ')'), (')', 'also'), ('also', 'employed'), ('employed', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', 'cases'), ('cases', '.')]

>> Trigrams are: 
 [('For', 'input', '('), ('input', '(', 'see'), ('(', 'see', 'also'), ('see', 'also', '“'), ('also', '“', 'Big'), ('“', 'Big', 'data'), ('Big', 'data', 'input'), ('data', 'input', '”'), ('input', '”', ')'), ('”', ')', 'output'), (')', 'output', '('), ('output', '(', 'see'), ('(', 'see', 'also'), ('see', 'also', '“'), ('also', '“', 'Output'), ('“', 'Output', 'result'), ('Output', 'result', 'big'), ('result', 'big', 'data'), ('big', 'data', 'analysis'), ('data', 'analysis', '”'), ('analysis', '”', ')'), ('”', ')', 'big'), (')', 'big', 'data'), ('big', 'data', ','), ('data', ',', 'several'), (',', 'several', 'methods'), ('several', 'methods', 'solutions'), ('methods', 'solutions', 'proposed'), ('solutions', 'proposed', 'big'), ('proposed', 'big', 'data'), ('big', 'data', 'age'), ('data', 'age', '('), ('age', '(', 'see'), ('(', 'see', 'also'), ('see', 'also', '“'), ('also', '“', 'Data'), ('“', 'Data', 'input'), ('Data', 'input', '”'), ('input', '”', ')'), ('”', ')', 'also'), (')', 'also', 'employed'), ('also', 'employed', 'big'), ('employed', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', 'cases'), ('analytics', 'cases', '.')]

>> POS Tags are: 
 [('For', 'IN'), ('input', 'NN'), ('(', '('), ('see', 'VB'), ('also', 'RB'), ('“', 'NNP'), ('Big', 'NNP'), ('data', 'NNS'), ('input', 'NN'), ('”', 'NNP'), (')', ')'), ('output', 'NN'), ('(', '('), ('see', 'VB'), ('also', 'RB'), ('“', 'NNP'), ('Output', 'NNP'), ('result', 'VBP'), ('big', 'JJ'), ('data', 'NNS'), ('analysis', 'NN'), ('”', 'NN'), (')', ')'), ('big', 'JJ'), ('data', 'NNS'), (',', ','), ('several', 'JJ'), ('methods', 'NNS'), ('solutions', 'NNS'), ('proposed', 'VBD'), ('big', 'JJ'), ('data', 'NNS'), ('age', 'NN'), ('(', '('), ('see', 'VB'), ('also', 'RB'), ('“', 'NNP'), ('Data', 'NNP'), ('input', 'NN'), ('”', 'NNP'), (')', ')'), ('also', 'RB'), ('employed', 'VBN'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('cases', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['input', '“ Big data input ”', 'output', '“ Output', 'big data analysis ”', 'big data', 'several methods solutions', 'big data age', '“ Data input ”', 'big data analytics cases']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('For', 'for'), ('input', 'input'), ('(', '('), ('see', 'see'), ('also', 'also'), ('“', '“'), ('Big', 'big'), ('data', 'data'), ('input', 'input'), ('”', '”'), (')', ')'), ('output', 'output'), ('(', '('), ('see', 'see'), ('also', 'also'), ('“', '“'), ('Output', 'output'), ('result', 'result'), ('big', 'big'), ('data', 'data'), ('analysis', 'analysi'), ('”', '”'), (')', ')'), ('big', 'big'), ('data', 'data'), (',', ','), ('several', 'sever'), ('methods', 'method'), ('solutions', 'solut'), ('proposed', 'propos'), ('big', 'big'), ('data', 'data'), ('age', 'age'), ('(', '('), ('see', 'see'), ('also', 'also'), ('“', '“'), ('Data', 'data'), ('input', 'input'), ('”', '”'), (')', ')'), ('also', 'also'), ('employed', 'employ'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('cases', 'case'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('For', 'for'), ('input', 'input'), ('(', '('), ('see', 'see'), ('also', 'also'), ('“', '“'), ('Big', 'big'), ('data', 'data'), ('input', 'input'), ('”', '”'), (')', ')'), ('output', 'output'), ('(', '('), ('see', 'see'), ('also', 'also'), ('“', '“'), ('Output', 'output'), ('result', 'result'), ('big', 'big'), ('data', 'data'), ('analysis', 'analysi'), ('”', '”'), (')', ')'), ('big', 'big'), ('data', 'data'), (',', ','), ('several', 'sever'), ('methods', 'method'), ('solutions', 'solut'), ('proposed', 'propos'), ('big', 'big'), ('data', 'data'), ('age', 'age'), ('(', '('), ('see', 'see'), ('also', 'also'), ('“', '“'), ('Data', 'data'), ('input', 'input'), ('”', '”'), (')', ')'), ('also', 'also'), ('employed', 'employ'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('cases', 'case'), ('.', '.')]

>> Lemmatization: 
 [('For', 'For'), ('input', 'input'), ('(', '('), ('see', 'see'), ('also', 'also'), ('“', '“'), ('Big', 'Big'), ('data', 'data'), ('input', 'input'), ('”', '”'), (')', ')'), ('output', 'output'), ('(', '('), ('see', 'see'), ('also', 'also'), ('“', '“'), ('Output', 'Output'), ('result', 'result'), ('big', 'big'), ('data', 'data'), ('analysis', 'analysis'), ('”', '”'), (')', ')'), ('big', 'big'), ('data', 'data'), (',', ','), ('several', 'several'), ('methods', 'method'), ('solutions', 'solution'), ('proposed', 'proposed'), ('big', 'big'), ('data', 'data'), ('age', 'age'), ('(', '('), ('see', 'see'), ('also', 'also'), ('“', '“'), ('Data', 'Data'), ('input', 'input'), ('”', '”'), (')', ')'), ('also', 'also'), ('employed', 'employed'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('cases', 'case'), ('.', '.')]



========================================== PARAGRAPH 316 ===========================================

However, there still exist some new issues of the input and output that the data sci- entists need to confront. A representative example we mentioned in “Big data input” is  that the bottleneck will not only on the sensor or input devices, it may also appear in  other places of data analytics [71]. Although we can employ traditional compression and  sampling technologies to deal with this problem, they can only mitigate the problems  instead of solving the problems completely. Similar situations also exist in the output  part. Although several measurements can be used to evaluate the performance of the  frameworks, platforms, and even data mining algorithms, there still exist several new  issues in the big data age, such as information fusion from different information sources  or information accumulation from different times. 

------------------- Sentence 1 -------------------

However, there still exist some new issues of the input and output that the data sci- entists need to confront.

>> Tokens are: 
 ['However', ',', 'still', 'exist', 'new', 'issues', 'input', 'output', 'data', 'sci-', 'entists', 'need', 'confront', '.']

>> Bigrams are: 
 [('However', ','), (',', 'still'), ('still', 'exist'), ('exist', 'new'), ('new', 'issues'), ('issues', 'input'), ('input', 'output'), ('output', 'data'), ('data', 'sci-'), ('sci-', 'entists'), ('entists', 'need'), ('need', 'confront'), ('confront', '.')]

>> Trigrams are: 
 [('However', ',', 'still'), (',', 'still', 'exist'), ('still', 'exist', 'new'), ('exist', 'new', 'issues'), ('new', 'issues', 'input'), ('issues', 'input', 'output'), ('input', 'output', 'data'), ('output', 'data', 'sci-'), ('data', 'sci-', 'entists'), ('sci-', 'entists', 'need'), ('entists', 'need', 'confront'), ('need', 'confront', '.')]

>> POS Tags are: 
 [('However', 'RB'), (',', ','), ('still', 'RB'), ('exist', 'VBP'), ('new', 'JJ'), ('issues', 'NNS'), ('input', 'VBP'), ('output', 'NN'), ('data', 'NNS'), ('sci-', 'JJ'), ('entists', 'NNS'), ('need', 'VBP'), ('confront', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['new issues', 'output data', 'sci- entists', 'confront']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('However', 'howev'), (',', ','), ('still', 'still'), ('exist', 'exist'), ('new', 'new'), ('issues', 'issu'), ('input', 'input'), ('output', 'output'), ('data', 'data'), ('sci-', 'sci-'), ('entists', 'entist'), ('need', 'need'), ('confront', 'confront'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('However', 'howev'), (',', ','), ('still', 'still'), ('exist', 'exist'), ('new', 'new'), ('issues', 'issu'), ('input', 'input'), ('output', 'output'), ('data', 'data'), ('sci-', 'sci-'), ('entists', 'entist'), ('need', 'need'), ('confront', 'confront'), ('.', '.')]

>> Lemmatization: 
 [('However', 'However'), (',', ','), ('still', 'still'), ('exist', 'exist'), ('new', 'new'), ('issues', 'issue'), ('input', 'input'), ('output', 'output'), ('data', 'data'), ('sci-', 'sci-'), ('entists', 'entists'), ('need', 'need'), ('confront', 'confront'), ('.', '.')]


------------------- Sentence 2 -------------------

A representative example we mentioned in “Big data input” is  that the bottleneck will not only on the sensor or input devices, it may also appear in  other places of data analytics [71].

>> Tokens are: 
 ['A', 'representative', 'example', 'mentioned', '“', 'Big', 'data', 'input', '”', 'bottleneck', 'sensor', 'input', 'devices', ',', 'may', 'also', 'appear', 'places', 'data', 'analytics', '[', '71', ']', '.']

>> Bigrams are: 
 [('A', 'representative'), ('representative', 'example'), ('example', 'mentioned'), ('mentioned', '“'), ('“', 'Big'), ('Big', 'data'), ('data', 'input'), ('input', '”'), ('”', 'bottleneck'), ('bottleneck', 'sensor'), ('sensor', 'input'), ('input', 'devices'), ('devices', ','), (',', 'may'), ('may', 'also'), ('also', 'appear'), ('appear', 'places'), ('places', 'data'), ('data', 'analytics'), ('analytics', '['), ('[', '71'), ('71', ']'), (']', '.')]

>> Trigrams are: 
 [('A', 'representative', 'example'), ('representative', 'example', 'mentioned'), ('example', 'mentioned', '“'), ('mentioned', '“', 'Big'), ('“', 'Big', 'data'), ('Big', 'data', 'input'), ('data', 'input', '”'), ('input', '”', 'bottleneck'), ('”', 'bottleneck', 'sensor'), ('bottleneck', 'sensor', 'input'), ('sensor', 'input', 'devices'), ('input', 'devices', ','), ('devices', ',', 'may'), (',', 'may', 'also'), ('may', 'also', 'appear'), ('also', 'appear', 'places'), ('appear', 'places', 'data'), ('places', 'data', 'analytics'), ('data', 'analytics', '['), ('analytics', '[', '71'), ('[', '71', ']'), ('71', ']', '.')]

>> POS Tags are: 
 [('A', 'DT'), ('representative', 'JJ'), ('example', 'NN'), ('mentioned', 'VBD'), ('“', 'NNP'), ('Big', 'NNP'), ('data', 'NNS'), ('input', 'NN'), ('”', 'NNP'), ('bottleneck', 'NN'), ('sensor', 'NN'), ('input', 'NN'), ('devices', 'NNS'), (',', ','), ('may', 'MD'), ('also', 'RB'), ('appear', 'VB'), ('places', 'NNS'), ('data', 'NNS'), ('analytics', 'NNS'), ('[', 'VBP'), ('71', 'CD'), (']', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['A representative example', '“ Big data input ” bottleneck sensor input devices', 'places data analytics', ']']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('A', 'a'), ('representative', 'repres'), ('example', 'exampl'), ('mentioned', 'mention'), ('“', '“'), ('Big', 'big'), ('data', 'data'), ('input', 'input'), ('”', '”'), ('bottleneck', 'bottleneck'), ('sensor', 'sensor'), ('input', 'input'), ('devices', 'devic'), (',', ','), ('may', 'may'), ('also', 'also'), ('appear', 'appear'), ('places', 'place'), ('data', 'data'), ('analytics', 'analyt'), ('[', '['), ('71', '71'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('A', 'a'), ('representative', 'repres'), ('example', 'exampl'), ('mentioned', 'mention'), ('“', '“'), ('Big', 'big'), ('data', 'data'), ('input', 'input'), ('”', '”'), ('bottleneck', 'bottleneck'), ('sensor', 'sensor'), ('input', 'input'), ('devices', 'devic'), (',', ','), ('may', 'may'), ('also', 'also'), ('appear', 'appear'), ('places', 'place'), ('data', 'data'), ('analytics', 'analyt'), ('[', '['), ('71', '71'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('A', 'A'), ('representative', 'representative'), ('example', 'example'), ('mentioned', 'mentioned'), ('“', '“'), ('Big', 'Big'), ('data', 'data'), ('input', 'input'), ('”', '”'), ('bottleneck', 'bottleneck'), ('sensor', 'sensor'), ('input', 'input'), ('devices', 'device'), (',', ','), ('may', 'may'), ('also', 'also'), ('appear', 'appear'), ('places', 'place'), ('data', 'data'), ('analytics', 'analytics'), ('[', '['), ('71', '71'), (']', ']'), ('.', '.')]


------------------- Sentence 3 -------------------

Although we can employ traditional compression and  sampling technologies to deal with this problem, they can only mitigate the problems  instead of solving the problems completely.

>> Tokens are: 
 ['Although', 'employ', 'traditional', 'compression', 'sampling', 'technologies', 'deal', 'problem', ',', 'mitigate', 'problems', 'instead', 'solving', 'problems', 'completely', '.']

>> Bigrams are: 
 [('Although', 'employ'), ('employ', 'traditional'), ('traditional', 'compression'), ('compression', 'sampling'), ('sampling', 'technologies'), ('technologies', 'deal'), ('deal', 'problem'), ('problem', ','), (',', 'mitigate'), ('mitigate', 'problems'), ('problems', 'instead'), ('instead', 'solving'), ('solving', 'problems'), ('problems', 'completely'), ('completely', '.')]

>> Trigrams are: 
 [('Although', 'employ', 'traditional'), ('employ', 'traditional', 'compression'), ('traditional', 'compression', 'sampling'), ('compression', 'sampling', 'technologies'), ('sampling', 'technologies', 'deal'), ('technologies', 'deal', 'problem'), ('deal', 'problem', ','), ('problem', ',', 'mitigate'), (',', 'mitigate', 'problems'), ('mitigate', 'problems', 'instead'), ('problems', 'instead', 'solving'), ('instead', 'solving', 'problems'), ('solving', 'problems', 'completely'), ('problems', 'completely', '.')]

>> POS Tags are: 
 [('Although', 'IN'), ('employ', 'JJ'), ('traditional', 'JJ'), ('compression', 'NN'), ('sampling', 'VBG'), ('technologies', 'NNS'), ('deal', 'NN'), ('problem', 'NN'), (',', ','), ('mitigate', 'VB'), ('problems', 'NNS'), ('instead', 'RB'), ('solving', 'VBG'), ('problems', 'NNS'), ('completely', 'RB'), ('.', '.')]

>> Noun Phrases are: 
 ['employ traditional compression', 'technologies deal problem', 'problems', 'problems']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Although', 'although'), ('employ', 'employ'), ('traditional', 'tradit'), ('compression', 'compress'), ('sampling', 'sampl'), ('technologies', 'technolog'), ('deal', 'deal'), ('problem', 'problem'), (',', ','), ('mitigate', 'mitig'), ('problems', 'problem'), ('instead', 'instead'), ('solving', 'solv'), ('problems', 'problem'), ('completely', 'complet'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Although', 'although'), ('employ', 'employ'), ('traditional', 'tradit'), ('compression', 'compress'), ('sampling', 'sampl'), ('technologies', 'technolog'), ('deal', 'deal'), ('problem', 'problem'), (',', ','), ('mitigate', 'mitig'), ('problems', 'problem'), ('instead', 'instead'), ('solving', 'solv'), ('problems', 'problem'), ('completely', 'complet'), ('.', '.')]

>> Lemmatization: 
 [('Although', 'Although'), ('employ', 'employ'), ('traditional', 'traditional'), ('compression', 'compression'), ('sampling', 'sampling'), ('technologies', 'technology'), ('deal', 'deal'), ('problem', 'problem'), (',', ','), ('mitigate', 'mitigate'), ('problems', 'problem'), ('instead', 'instead'), ('solving', 'solving'), ('problems', 'problem'), ('completely', 'completely'), ('.', '.')]


------------------- Sentence 4 -------------------

Similar situations also exist in the output  part.

>> Tokens are: 
 ['Similar', 'situations', 'also', 'exist', 'output', 'part', '.']

>> Bigrams are: 
 [('Similar', 'situations'), ('situations', 'also'), ('also', 'exist'), ('exist', 'output'), ('output', 'part'), ('part', '.')]

>> Trigrams are: 
 [('Similar', 'situations', 'also'), ('situations', 'also', 'exist'), ('also', 'exist', 'output'), ('exist', 'output', 'part'), ('output', 'part', '.')]

>> POS Tags are: 
 [('Similar', 'JJ'), ('situations', 'NNS'), ('also', 'RB'), ('exist', 'VBP'), ('output', 'NN'), ('part', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Similar situations', 'output part']

>> Named Entities are: 
 [('GPE', 'Similar')] 

>> Stemming using Porter Stemmer: 
 [('Similar', 'similar'), ('situations', 'situat'), ('also', 'also'), ('exist', 'exist'), ('output', 'output'), ('part', 'part'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Similar', 'similar'), ('situations', 'situat'), ('also', 'also'), ('exist', 'exist'), ('output', 'output'), ('part', 'part'), ('.', '.')]

>> Lemmatization: 
 [('Similar', 'Similar'), ('situations', 'situation'), ('also', 'also'), ('exist', 'exist'), ('output', 'output'), ('part', 'part'), ('.', '.')]


------------------- Sentence 5 -------------------

Although several measurements can be used to evaluate the performance of the  frameworks, platforms, and even data mining algorithms, there still exist several new  issues in the big data age, such as information fusion from different information sources  or information accumulation from different times.

>> Tokens are: 
 ['Although', 'several', 'measurements', 'used', 'evaluate', 'performance', 'frameworks', ',', 'platforms', ',', 'even', 'data', 'mining', 'algorithms', ',', 'still', 'exist', 'several', 'new', 'issues', 'big', 'data', 'age', ',', 'information', 'fusion', 'different', 'information', 'sources', 'information', 'accumulation', 'different', 'times', '.']

>> Bigrams are: 
 [('Although', 'several'), ('several', 'measurements'), ('measurements', 'used'), ('used', 'evaluate'), ('evaluate', 'performance'), ('performance', 'frameworks'), ('frameworks', ','), (',', 'platforms'), ('platforms', ','), (',', 'even'), ('even', 'data'), ('data', 'mining'), ('mining', 'algorithms'), ('algorithms', ','), (',', 'still'), ('still', 'exist'), ('exist', 'several'), ('several', 'new'), ('new', 'issues'), ('issues', 'big'), ('big', 'data'), ('data', 'age'), ('age', ','), (',', 'information'), ('information', 'fusion'), ('fusion', 'different'), ('different', 'information'), ('information', 'sources'), ('sources', 'information'), ('information', 'accumulation'), ('accumulation', 'different'), ('different', 'times'), ('times', '.')]

>> Trigrams are: 
 [('Although', 'several', 'measurements'), ('several', 'measurements', 'used'), ('measurements', 'used', 'evaluate'), ('used', 'evaluate', 'performance'), ('evaluate', 'performance', 'frameworks'), ('performance', 'frameworks', ','), ('frameworks', ',', 'platforms'), (',', 'platforms', ','), ('platforms', ',', 'even'), (',', 'even', 'data'), ('even', 'data', 'mining'), ('data', 'mining', 'algorithms'), ('mining', 'algorithms', ','), ('algorithms', ',', 'still'), (',', 'still', 'exist'), ('still', 'exist', 'several'), ('exist', 'several', 'new'), ('several', 'new', 'issues'), ('new', 'issues', 'big'), ('issues', 'big', 'data'), ('big', 'data', 'age'), ('data', 'age', ','), ('age', ',', 'information'), (',', 'information', 'fusion'), ('information', 'fusion', 'different'), ('fusion', 'different', 'information'), ('different', 'information', 'sources'), ('information', 'sources', 'information'), ('sources', 'information', 'accumulation'), ('information', 'accumulation', 'different'), ('accumulation', 'different', 'times'), ('different', 'times', '.')]

>> POS Tags are: 
 [('Although', 'IN'), ('several', 'JJ'), ('measurements', 'NNS'), ('used', 'VBN'), ('evaluate', 'JJ'), ('performance', 'NN'), ('frameworks', 'NNS'), (',', ','), ('platforms', 'NNS'), (',', ','), ('even', 'RB'), ('data', 'NNS'), ('mining', 'NN'), ('algorithms', 'NN'), (',', ','), ('still', 'RB'), ('exist', 'VB'), ('several', 'JJ'), ('new', 'JJ'), ('issues', 'NNS'), ('big', 'JJ'), ('data', 'NNS'), ('age', 'NN'), (',', ','), ('information', 'NN'), ('fusion', 'NN'), ('different', 'JJ'), ('information', 'NN'), ('sources', 'NNS'), ('information', 'NN'), ('accumulation', 'NN'), ('different', 'JJ'), ('times', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['several measurements', 'evaluate performance frameworks', 'platforms', 'data mining algorithms', 'several new issues', 'big data age', 'information fusion', 'different information sources information accumulation', 'different times']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Although', 'although'), ('several', 'sever'), ('measurements', 'measur'), ('used', 'use'), ('evaluate', 'evalu'), ('performance', 'perform'), ('frameworks', 'framework'), (',', ','), ('platforms', 'platform'), (',', ','), ('even', 'even'), ('data', 'data'), ('mining', 'mine'), ('algorithms', 'algorithm'), (',', ','), ('still', 'still'), ('exist', 'exist'), ('several', 'sever'), ('new', 'new'), ('issues', 'issu'), ('big', 'big'), ('data', 'data'), ('age', 'age'), (',', ','), ('information', 'inform'), ('fusion', 'fusion'), ('different', 'differ'), ('information', 'inform'), ('sources', 'sourc'), ('information', 'inform'), ('accumulation', 'accumul'), ('different', 'differ'), ('times', 'time'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Although', 'although'), ('several', 'sever'), ('measurements', 'measur'), ('used', 'use'), ('evaluate', 'evalu'), ('performance', 'perform'), ('frameworks', 'framework'), (',', ','), ('platforms', 'platform'), (',', ','), ('even', 'even'), ('data', 'data'), ('mining', 'mine'), ('algorithms', 'algorithm'), (',', ','), ('still', 'still'), ('exist', 'exist'), ('several', 'sever'), ('new', 'new'), ('issues', 'issu'), ('big', 'big'), ('data', 'data'), ('age', 'age'), (',', ','), ('information', 'inform'), ('fusion', 'fusion'), ('different', 'differ'), ('information', 'inform'), ('sources', 'sourc'), ('information', 'inform'), ('accumulation', 'accumul'), ('different', 'differ'), ('times', 'time'), ('.', '.')]

>> Lemmatization: 
 [('Although', 'Although'), ('several', 'several'), ('measurements', 'measurement'), ('used', 'used'), ('evaluate', 'evaluate'), ('performance', 'performance'), ('frameworks', 'framework'), (',', ','), ('platforms', 'platform'), (',', ','), ('even', 'even'), ('data', 'data'), ('mining', 'mining'), ('algorithms', 'algorithm'), (',', ','), ('still', 'still'), ('exist', 'exist'), ('several', 'several'), ('new', 'new'), ('issues', 'issue'), ('big', 'big'), ('data', 'data'), ('age', 'age'), (',', ','), ('information', 'information'), ('fusion', 'fusion'), ('different', 'different'), ('information', 'information'), ('sources', 'source'), ('information', 'information'), ('accumulation', 'accumulation'), ('different', 'different'), ('times', 'time'), ('.', '.')]



========================================== PARAGRAPH 317 ===========================================

Several studies attempted to present an efficient or effective solution from the perspec- tive of system (e.g.-, framework and platform) or algorithm level. A simple comparison of  these big data analysis technologies from different perspectives is described in Table 3,  to give a brief introduction to the current studies and trends of data analysis technolo- gies for the big data. The “Perspective” column of this table explains that the study is  focused on the framework or algorithm level; the “Description” column gives the further  goal of the study; and the “Name” column is an abbreviated names of the methods or  platform/framework. From the analysis framework perspective, this table shows that big  data framework, platform, and machine learning are the current research trends in big  data analytics system. For the mining algorithm perspective, the clustering, classification,  and frequent pattern mining issues play the vital role of these researches because several  data analysis problems can be mapped to these essential issues.

------------------- Sentence 1 -------------------

Several studies attempted to present an efficient or effective solution from the perspec- tive of system (e.g.-, framework and platform) or algorithm level.

>> Tokens are: 
 ['Several', 'studies', 'attempted', 'present', 'efficient', 'effective', 'solution', 'perspec-', 'tive', 'system', '(', 'e.g.-', ',', 'framework', 'platform', ')', 'algorithm', 'level', '.']

>> Bigrams are: 
 [('Several', 'studies'), ('studies', 'attempted'), ('attempted', 'present'), ('present', 'efficient'), ('efficient', 'effective'), ('effective', 'solution'), ('solution', 'perspec-'), ('perspec-', 'tive'), ('tive', 'system'), ('system', '('), ('(', 'e.g.-'), ('e.g.-', ','), (',', 'framework'), ('framework', 'platform'), ('platform', ')'), (')', 'algorithm'), ('algorithm', 'level'), ('level', '.')]

>> Trigrams are: 
 [('Several', 'studies', 'attempted'), ('studies', 'attempted', 'present'), ('attempted', 'present', 'efficient'), ('present', 'efficient', 'effective'), ('efficient', 'effective', 'solution'), ('effective', 'solution', 'perspec-'), ('solution', 'perspec-', 'tive'), ('perspec-', 'tive', 'system'), ('tive', 'system', '('), ('system', '(', 'e.g.-'), ('(', 'e.g.-', ','), ('e.g.-', ',', 'framework'), (',', 'framework', 'platform'), ('framework', 'platform', ')'), ('platform', ')', 'algorithm'), (')', 'algorithm', 'level'), ('algorithm', 'level', '.')]

>> POS Tags are: 
 [('Several', 'JJ'), ('studies', 'NNS'), ('attempted', 'VBN'), ('present', 'JJ'), ('efficient', 'JJ'), ('effective', 'JJ'), ('solution', 'NN'), ('perspec-', 'RB'), ('tive', 'JJ'), ('system', 'NN'), ('(', '('), ('e.g.-', 'JJ'), (',', ','), ('framework', 'JJ'), ('platform', 'NN'), (')', ')'), ('algorithm', 'VBZ'), ('level', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Several studies', 'present efficient effective solution', 'tive system', 'framework platform', 'level']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Several', 'sever'), ('studies', 'studi'), ('attempted', 'attempt'), ('present', 'present'), ('efficient', 'effici'), ('effective', 'effect'), ('solution', 'solut'), ('perspec-', 'perspec-'), ('tive', 'tive'), ('system', 'system'), ('(', '('), ('e.g.-', 'e.g.-'), (',', ','), ('framework', 'framework'), ('platform', 'platform'), (')', ')'), ('algorithm', 'algorithm'), ('level', 'level'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Several', 'sever'), ('studies', 'studi'), ('attempted', 'attempt'), ('present', 'present'), ('efficient', 'effici'), ('effective', 'effect'), ('solution', 'solut'), ('perspec-', 'perspec-'), ('tive', 'tive'), ('system', 'system'), ('(', '('), ('e.g.-', 'e.g.-'), (',', ','), ('framework', 'framework'), ('platform', 'platform'), (')', ')'), ('algorithm', 'algorithm'), ('level', 'level'), ('.', '.')]

>> Lemmatization: 
 [('Several', 'Several'), ('studies', 'study'), ('attempted', 'attempted'), ('present', 'present'), ('efficient', 'efficient'), ('effective', 'effective'), ('solution', 'solution'), ('perspec-', 'perspec-'), ('tive', 'tive'), ('system', 'system'), ('(', '('), ('e.g.-', 'e.g.-'), (',', ','), ('framework', 'framework'), ('platform', 'platform'), (')', ')'), ('algorithm', 'algorithm'), ('level', 'level'), ('.', '.')]


------------------- Sentence 2 -------------------

A simple comparison of  these big data analysis technologies from different perspectives is described in Table 3,  to give a brief introduction to the current studies and trends of data analysis technolo- gies for the big data.

>> Tokens are: 
 ['A', 'simple', 'comparison', 'big', 'data', 'analysis', 'technologies', 'different', 'perspectives', 'described', 'Table', '3', ',', 'give', 'brief', 'introduction', 'current', 'studies', 'trends', 'data', 'analysis', 'technolo-', 'gies', 'big', 'data', '.']

>> Bigrams are: 
 [('A', 'simple'), ('simple', 'comparison'), ('comparison', 'big'), ('big', 'data'), ('data', 'analysis'), ('analysis', 'technologies'), ('technologies', 'different'), ('different', 'perspectives'), ('perspectives', 'described'), ('described', 'Table'), ('Table', '3'), ('3', ','), (',', 'give'), ('give', 'brief'), ('brief', 'introduction'), ('introduction', 'current'), ('current', 'studies'), ('studies', 'trends'), ('trends', 'data'), ('data', 'analysis'), ('analysis', 'technolo-'), ('technolo-', 'gies'), ('gies', 'big'), ('big', 'data'), ('data', '.')]

>> Trigrams are: 
 [('A', 'simple', 'comparison'), ('simple', 'comparison', 'big'), ('comparison', 'big', 'data'), ('big', 'data', 'analysis'), ('data', 'analysis', 'technologies'), ('analysis', 'technologies', 'different'), ('technologies', 'different', 'perspectives'), ('different', 'perspectives', 'described'), ('perspectives', 'described', 'Table'), ('described', 'Table', '3'), ('Table', '3', ','), ('3', ',', 'give'), (',', 'give', 'brief'), ('give', 'brief', 'introduction'), ('brief', 'introduction', 'current'), ('introduction', 'current', 'studies'), ('current', 'studies', 'trends'), ('studies', 'trends', 'data'), ('trends', 'data', 'analysis'), ('data', 'analysis', 'technolo-'), ('analysis', 'technolo-', 'gies'), ('technolo-', 'gies', 'big'), ('gies', 'big', 'data'), ('big', 'data', '.')]

>> POS Tags are: 
 [('A', 'DT'), ('simple', 'JJ'), ('comparison', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('analysis', 'NN'), ('technologies', 'NNS'), ('different', 'JJ'), ('perspectives', 'NNS'), ('described', 'VBD'), ('Table', 'JJ'), ('3', 'CD'), (',', ','), ('give', 'VBP'), ('brief', 'JJ'), ('introduction', 'NN'), ('current', 'JJ'), ('studies', 'NNS'), ('trends', 'VBZ'), ('data', 'NNS'), ('analysis', 'NN'), ('technolo-', 'JJ'), ('gies', 'NNS'), ('big', 'JJ'), ('data', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['A simple comparison', 'big data analysis technologies', 'different perspectives', 'brief introduction', 'current studies', 'data analysis', 'technolo- gies', 'big data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('A', 'a'), ('simple', 'simpl'), ('comparison', 'comparison'), ('big', 'big'), ('data', 'data'), ('analysis', 'analysi'), ('technologies', 'technolog'), ('different', 'differ'), ('perspectives', 'perspect'), ('described', 'describ'), ('Table', 'tabl'), ('3', '3'), (',', ','), ('give', 'give'), ('brief', 'brief'), ('introduction', 'introduct'), ('current', 'current'), ('studies', 'studi'), ('trends', 'trend'), ('data', 'data'), ('analysis', 'analysi'), ('technolo-', 'technolo-'), ('gies', 'gie'), ('big', 'big'), ('data', 'data'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('A', 'a'), ('simple', 'simpl'), ('comparison', 'comparison'), ('big', 'big'), ('data', 'data'), ('analysis', 'analysi'), ('technologies', 'technolog'), ('different', 'differ'), ('perspectives', 'perspect'), ('described', 'describ'), ('Table', 'tabl'), ('3', '3'), (',', ','), ('give', 'give'), ('brief', 'brief'), ('introduction', 'introduct'), ('current', 'current'), ('studies', 'studi'), ('trends', 'trend'), ('data', 'data'), ('analysis', 'analysi'), ('technolo-', 'technolo-'), ('gies', 'gie'), ('big', 'big'), ('data', 'data'), ('.', '.')]

>> Lemmatization: 
 [('A', 'A'), ('simple', 'simple'), ('comparison', 'comparison'), ('big', 'big'), ('data', 'data'), ('analysis', 'analysis'), ('technologies', 'technology'), ('different', 'different'), ('perspectives', 'perspective'), ('described', 'described'), ('Table', 'Table'), ('3', '3'), (',', ','), ('give', 'give'), ('brief', 'brief'), ('introduction', 'introduction'), ('current', 'current'), ('studies', 'study'), ('trends', 'trend'), ('data', 'data'), ('analysis', 'analysis'), ('technolo-', 'technolo-'), ('gies', 'gy'), ('big', 'big'), ('data', 'data'), ('.', '.')]


------------------- Sentence 3 -------------------

The “Perspective” column of this table explains that the study is  focused on the framework or algorithm level; the “Description” column gives the further  goal of the study; and the “Name” column is an abbreviated names of the methods or  platform/framework.

>> Tokens are: 
 ['The', '“', 'Perspective', '”', 'column', 'table', 'explains', 'study', 'focused', 'framework', 'algorithm', 'level', ';', '“', 'Description', '”', 'column', 'gives', 'goal', 'study', ';', '“', 'Name', '”', 'column', 'abbreviated', 'names', 'methods', 'platform/framework', '.']

>> Bigrams are: 
 [('The', '“'), ('“', 'Perspective'), ('Perspective', '”'), ('”', 'column'), ('column', 'table'), ('table', 'explains'), ('explains', 'study'), ('study', 'focused'), ('focused', 'framework'), ('framework', 'algorithm'), ('algorithm', 'level'), ('level', ';'), (';', '“'), ('“', 'Description'), ('Description', '”'), ('”', 'column'), ('column', 'gives'), ('gives', 'goal'), ('goal', 'study'), ('study', ';'), (';', '“'), ('“', 'Name'), ('Name', '”'), ('”', 'column'), ('column', 'abbreviated'), ('abbreviated', 'names'), ('names', 'methods'), ('methods', 'platform/framework'), ('platform/framework', '.')]

>> Trigrams are: 
 [('The', '“', 'Perspective'), ('“', 'Perspective', '”'), ('Perspective', '”', 'column'), ('”', 'column', 'table'), ('column', 'table', 'explains'), ('table', 'explains', 'study'), ('explains', 'study', 'focused'), ('study', 'focused', 'framework'), ('focused', 'framework', 'algorithm'), ('framework', 'algorithm', 'level'), ('algorithm', 'level', ';'), ('level', ';', '“'), (';', '“', 'Description'), ('“', 'Description', '”'), ('Description', '”', 'column'), ('”', 'column', 'gives'), ('column', 'gives', 'goal'), ('gives', 'goal', 'study'), ('goal', 'study', ';'), ('study', ';', '“'), (';', '“', 'Name'), ('“', 'Name', '”'), ('Name', '”', 'column'), ('”', 'column', 'abbreviated'), ('column', 'abbreviated', 'names'), ('abbreviated', 'names', 'methods'), ('names', 'methods', 'platform/framework'), ('methods', 'platform/framework', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('“', 'NNP'), ('Perspective', 'NNP'), ('”', 'NNP'), ('column', 'NN'), ('table', 'NN'), ('explains', 'NNS'), ('study', 'VBP'), ('focused', 'JJ'), ('framework', 'NN'), ('algorithm', 'JJ'), ('level', 'NN'), (';', ':'), ('“', 'CC'), ('Description', 'NNP'), ('”', 'NNP'), ('column', 'NN'), ('gives', 'VBZ'), ('goal', 'NN'), ('study', 'NN'), (';', ':'), ('“', 'CC'), ('Name', 'NNP'), ('”', 'NNP'), ('column', 'NN'), ('abbreviated', 'VBD'), ('names', 'RB'), ('methods', 'NNS'), ('platform/framework', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['The “ Perspective ” column table explains', 'focused framework', 'algorithm level', 'Description ” column', 'goal study', 'Name ” column', 'methods platform/framework']

>> Named Entities are: 
 [('PERSON', 'Name')] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('“', '“'), ('Perspective', 'perspect'), ('”', '”'), ('column', 'column'), ('table', 'tabl'), ('explains', 'explain'), ('study', 'studi'), ('focused', 'focus'), ('framework', 'framework'), ('algorithm', 'algorithm'), ('level', 'level'), (';', ';'), ('“', '“'), ('Description', 'descript'), ('”', '”'), ('column', 'column'), ('gives', 'give'), ('goal', 'goal'), ('study', 'studi'), (';', ';'), ('“', '“'), ('Name', 'name'), ('”', '”'), ('column', 'column'), ('abbreviated', 'abbrevi'), ('names', 'name'), ('methods', 'method'), ('platform/framework', 'platform/framework'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('“', '“'), ('Perspective', 'perspect'), ('”', '”'), ('column', 'column'), ('table', 'tabl'), ('explains', 'explain'), ('study', 'studi'), ('focused', 'focus'), ('framework', 'framework'), ('algorithm', 'algorithm'), ('level', 'level'), (';', ';'), ('“', '“'), ('Description', 'descript'), ('”', '”'), ('column', 'column'), ('gives', 'give'), ('goal', 'goal'), ('study', 'studi'), (';', ';'), ('“', '“'), ('Name', 'name'), ('”', '”'), ('column', 'column'), ('abbreviated', 'abbrevi'), ('names', 'name'), ('methods', 'method'), ('platform/framework', 'platform/framework'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('“', '“'), ('Perspective', 'Perspective'), ('”', '”'), ('column', 'column'), ('table', 'table'), ('explains', 'explains'), ('study', 'study'), ('focused', 'focused'), ('framework', 'framework'), ('algorithm', 'algorithm'), ('level', 'level'), (';', ';'), ('“', '“'), ('Description', 'Description'), ('”', '”'), ('column', 'column'), ('gives', 'give'), ('goal', 'goal'), ('study', 'study'), (';', ';'), ('“', '“'), ('Name', 'Name'), ('”', '”'), ('column', 'column'), ('abbreviated', 'abbreviated'), ('names', 'name'), ('methods', 'method'), ('platform/framework', 'platform/framework'), ('.', '.')]


------------------- Sentence 4 -------------------

From the analysis framework perspective, this table shows that big  data framework, platform, and machine learning are the current research trends in big  data analytics system.

>> Tokens are: 
 ['From', 'analysis', 'framework', 'perspective', ',', 'table', 'shows', 'big', 'data', 'framework', ',', 'platform', ',', 'machine', 'learning', 'current', 'research', 'trends', 'big', 'data', 'analytics', 'system', '.']

>> Bigrams are: 
 [('From', 'analysis'), ('analysis', 'framework'), ('framework', 'perspective'), ('perspective', ','), (',', 'table'), ('table', 'shows'), ('shows', 'big'), ('big', 'data'), ('data', 'framework'), ('framework', ','), (',', 'platform'), ('platform', ','), (',', 'machine'), ('machine', 'learning'), ('learning', 'current'), ('current', 'research'), ('research', 'trends'), ('trends', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', 'system'), ('system', '.')]

>> Trigrams are: 
 [('From', 'analysis', 'framework'), ('analysis', 'framework', 'perspective'), ('framework', 'perspective', ','), ('perspective', ',', 'table'), (',', 'table', 'shows'), ('table', 'shows', 'big'), ('shows', 'big', 'data'), ('big', 'data', 'framework'), ('data', 'framework', ','), ('framework', ',', 'platform'), (',', 'platform', ','), ('platform', ',', 'machine'), (',', 'machine', 'learning'), ('machine', 'learning', 'current'), ('learning', 'current', 'research'), ('current', 'research', 'trends'), ('research', 'trends', 'big'), ('trends', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', 'system'), ('analytics', 'system', '.')]

>> POS Tags are: 
 [('From', 'IN'), ('analysis', 'NN'), ('framework', 'NN'), ('perspective', 'NN'), (',', ','), ('table', 'NN'), ('shows', 'NNS'), ('big', 'JJ'), ('data', 'NNS'), ('framework', 'NN'), (',', ','), ('platform', 'NN'), (',', ','), ('machine', 'NN'), ('learning', 'VBG'), ('current', 'JJ'), ('research', 'NN'), ('trends', 'VBZ'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('system', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['analysis framework perspective', 'table shows', 'big data framework', 'platform', 'machine', 'current research', 'big data analytics system']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('From', 'from'), ('analysis', 'analysi'), ('framework', 'framework'), ('perspective', 'perspect'), (',', ','), ('table', 'tabl'), ('shows', 'show'), ('big', 'big'), ('data', 'data'), ('framework', 'framework'), (',', ','), ('platform', 'platform'), (',', ','), ('machine', 'machin'), ('learning', 'learn'), ('current', 'current'), ('research', 'research'), ('trends', 'trend'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('system', 'system'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('From', 'from'), ('analysis', 'analysi'), ('framework', 'framework'), ('perspective', 'perspect'), (',', ','), ('table', 'tabl'), ('shows', 'show'), ('big', 'big'), ('data', 'data'), ('framework', 'framework'), (',', ','), ('platform', 'platform'), (',', ','), ('machine', 'machin'), ('learning', 'learn'), ('current', 'current'), ('research', 'research'), ('trends', 'trend'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('system', 'system'), ('.', '.')]

>> Lemmatization: 
 [('From', 'From'), ('analysis', 'analysis'), ('framework', 'framework'), ('perspective', 'perspective'), (',', ','), ('table', 'table'), ('shows', 'show'), ('big', 'big'), ('data', 'data'), ('framework', 'framework'), (',', ','), ('platform', 'platform'), (',', ','), ('machine', 'machine'), ('learning', 'learning'), ('current', 'current'), ('research', 'research'), ('trends', 'trend'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('system', 'system'), ('.', '.')]


------------------- Sentence 5 -------------------

For the mining algorithm perspective, the clustering, classification,  and frequent pattern mining issues play the vital role of these researches because several  data analysis problems can be mapped to these essential issues.

>> Tokens are: 
 ['For', 'mining', 'algorithm', 'perspective', ',', 'clustering', ',', 'classification', ',', 'frequent', 'pattern', 'mining', 'issues', 'play', 'vital', 'role', 'researches', 'several', 'data', 'analysis', 'problems', 'mapped', 'essential', 'issues', '.']

>> Bigrams are: 
 [('For', 'mining'), ('mining', 'algorithm'), ('algorithm', 'perspective'), ('perspective', ','), (',', 'clustering'), ('clustering', ','), (',', 'classification'), ('classification', ','), (',', 'frequent'), ('frequent', 'pattern'), ('pattern', 'mining'), ('mining', 'issues'), ('issues', 'play'), ('play', 'vital'), ('vital', 'role'), ('role', 'researches'), ('researches', 'several'), ('several', 'data'), ('data', 'analysis'), ('analysis', 'problems'), ('problems', 'mapped'), ('mapped', 'essential'), ('essential', 'issues'), ('issues', '.')]

>> Trigrams are: 
 [('For', 'mining', 'algorithm'), ('mining', 'algorithm', 'perspective'), ('algorithm', 'perspective', ','), ('perspective', ',', 'clustering'), (',', 'clustering', ','), ('clustering', ',', 'classification'), (',', 'classification', ','), ('classification', ',', 'frequent'), (',', 'frequent', 'pattern'), ('frequent', 'pattern', 'mining'), ('pattern', 'mining', 'issues'), ('mining', 'issues', 'play'), ('issues', 'play', 'vital'), ('play', 'vital', 'role'), ('vital', 'role', 'researches'), ('role', 'researches', 'several'), ('researches', 'several', 'data'), ('several', 'data', 'analysis'), ('data', 'analysis', 'problems'), ('analysis', 'problems', 'mapped'), ('problems', 'mapped', 'essential'), ('mapped', 'essential', 'issues'), ('essential', 'issues', '.')]

>> POS Tags are: 
 [('For', 'IN'), ('mining', 'VBG'), ('algorithm', 'JJ'), ('perspective', 'NN'), (',', ','), ('clustering', 'VBG'), (',', ','), ('classification', 'NN'), (',', ','), ('frequent', 'JJ'), ('pattern', 'NN'), ('mining', 'NN'), ('issues', 'NNS'), ('play', 'VBP'), ('vital', 'JJ'), ('role', 'NN'), ('researches', 'NNS'), ('several', 'JJ'), ('data', 'NNS'), ('analysis', 'NN'), ('problems', 'NNS'), ('mapped', 'VBD'), ('essential', 'JJ'), ('issues', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['algorithm perspective', 'classification', 'frequent pattern mining issues', 'vital role researches', 'several data analysis problems', 'essential issues']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('For', 'for'), ('mining', 'mine'), ('algorithm', 'algorithm'), ('perspective', 'perspect'), (',', ','), ('clustering', 'cluster'), (',', ','), ('classification', 'classif'), (',', ','), ('frequent', 'frequent'), ('pattern', 'pattern'), ('mining', 'mine'), ('issues', 'issu'), ('play', 'play'), ('vital', 'vital'), ('role', 'role'), ('researches', 'research'), ('several', 'sever'), ('data', 'data'), ('analysis', 'analysi'), ('problems', 'problem'), ('mapped', 'map'), ('essential', 'essenti'), ('issues', 'issu'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('For', 'for'), ('mining', 'mine'), ('algorithm', 'algorithm'), ('perspective', 'perspect'), (',', ','), ('clustering', 'cluster'), (',', ','), ('classification', 'classif'), (',', ','), ('frequent', 'frequent'), ('pattern', 'pattern'), ('mining', 'mine'), ('issues', 'issu'), ('play', 'play'), ('vital', 'vital'), ('role', 'role'), ('researches', 'research'), ('several', 'sever'), ('data', 'data'), ('analysis', 'analysi'), ('problems', 'problem'), ('mapped', 'map'), ('essential', 'essenti'), ('issues', 'issu'), ('.', '.')]

>> Lemmatization: 
 [('For', 'For'), ('mining', 'mining'), ('algorithm', 'algorithm'), ('perspective', 'perspective'), (',', ','), ('clustering', 'clustering'), (',', ','), ('classification', 'classification'), (',', ','), ('frequent', 'frequent'), ('pattern', 'pattern'), ('mining', 'mining'), ('issues', 'issue'), ('play', 'play'), ('vital', 'vital'), ('role', 'role'), ('researches', 'research'), ('several', 'several'), ('data', 'data'), ('analysis', 'analysis'), ('problems', 'problem'), ('mapped', 'mapped'), ('essential', 'essential'), ('issues', 'issue'), ('.', '.')]



========================================== PARAGRAPH 318 ===========================================

Page 22 of 32Tsai et al. Journal of Big Data  (2015) 2:21  

------------------- Sentence 1 -------------------

Page 22 of 32Tsai et al.

>> Tokens are: 
 ['Page', '22', '32Tsai', 'et', 'al', '.']

>> Bigrams are: 
 [('Page', '22'), ('22', '32Tsai'), ('32Tsai', 'et'), ('et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('Page', '22', '32Tsai'), ('22', '32Tsai', 'et'), ('32Tsai', 'et', 'al'), ('et', 'al', '.')]

>> POS Tags are: 
 [('Page', 'NN'), ('22', 'CD'), ('32Tsai', 'CD'), ('et', 'NN'), ('al', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Page', 'et al']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Page', 'page'), ('22', '22'), ('32Tsai', '32tsai'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Page', 'page'), ('22', '22'), ('32Tsai', '32tsai'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('Page', 'Page'), ('22', '22'), ('32Tsai', '32Tsai'), ('et', 'et'), ('al', 'al'), ('.', '.')]


------------------- Sentence 2 -------------------

Journal of Big Data  (2015) 2:21

>> Tokens are: 
 ['Journal', 'Big', 'Data', '(', '2015', ')', '2:21']

>> Bigrams are: 
 [('Journal', 'Big'), ('Big', 'Data'), ('Data', '('), ('(', '2015'), ('2015', ')'), (')', '2:21')]

>> Trigrams are: 
 [('Journal', 'Big', 'Data'), ('Big', 'Data', '('), ('Data', '(', '2015'), ('(', '2015', ')'), ('2015', ')', '2:21')]

>> POS Tags are: 
 [('Journal', 'NNP'), ('Big', 'NNP'), ('Data', 'NNP'), ('(', '('), ('2015', 'CD'), (')', ')'), ('2:21', 'CD')]

>> Noun Phrases are: 
 ['Journal Big Data']

>> Named Entities are: 
 [('PERSON', 'Journal')] 

>> Stemming using Porter Stemmer: 
 [('Journal', 'journal'), ('Big', 'big'), ('Data', 'data'), ('(', '('), ('2015', '2015'), (')', ')'), ('2:21', '2:21')]

>> Stemming using Snowball Stemmer: 
 [('Journal', 'journal'), ('Big', 'big'), ('Data', 'data'), ('(', '('), ('2015', '2015'), (')', ')'), ('2:21', '2:21')]

>> Lemmatization: 
 [('Journal', 'Journal'), ('Big', 'Big'), ('Data', 'Data'), ('(', '('), ('2015', '2015'), (')', ')'), ('2:21', '2:21')]



========================================== PARAGRAPH 319 ===========================================

A promising trend that can be easily found from these successful examples is to use  machine learning as the search algorithm (i.e.-, mining algorithm) for the data mining  problems of big data analytics system. The machine learning-based methods are able to  

------------------- Sentence 1 -------------------

A promising trend that can be easily found from these successful examples is to use  machine learning as the search algorithm (i.e.-, mining algorithm) for the data mining  problems of big data analytics system.

>> Tokens are: 
 ['A', 'promising', 'trend', 'easily', 'found', 'successful', 'examples', 'use', 'machine', 'learning', 'search', 'algorithm', '(', 'i.e.-', ',', 'mining', 'algorithm', ')', 'data', 'mining', 'problems', 'big', 'data', 'analytics', 'system', '.']

>> Bigrams are: 
 [('A', 'promising'), ('promising', 'trend'), ('trend', 'easily'), ('easily', 'found'), ('found', 'successful'), ('successful', 'examples'), ('examples', 'use'), ('use', 'machine'), ('machine', 'learning'), ('learning', 'search'), ('search', 'algorithm'), ('algorithm', '('), ('(', 'i.e.-'), ('i.e.-', ','), (',', 'mining'), ('mining', 'algorithm'), ('algorithm', ')'), (')', 'data'), ('data', 'mining'), ('mining', 'problems'), ('problems', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', 'system'), ('system', '.')]

>> Trigrams are: 
 [('A', 'promising', 'trend'), ('promising', 'trend', 'easily'), ('trend', 'easily', 'found'), ('easily', 'found', 'successful'), ('found', 'successful', 'examples'), ('successful', 'examples', 'use'), ('examples', 'use', 'machine'), ('use', 'machine', 'learning'), ('machine', 'learning', 'search'), ('learning', 'search', 'algorithm'), ('search', 'algorithm', '('), ('algorithm', '(', 'i.e.-'), ('(', 'i.e.-', ','), ('i.e.-', ',', 'mining'), (',', 'mining', 'algorithm'), ('mining', 'algorithm', ')'), ('algorithm', ')', 'data'), (')', 'data', 'mining'), ('data', 'mining', 'problems'), ('mining', 'problems', 'big'), ('problems', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', 'system'), ('analytics', 'system', '.')]

>> POS Tags are: 
 [('A', 'DT'), ('promising', 'JJ'), ('trend', 'NN'), ('easily', 'RB'), ('found', 'VBN'), ('successful', 'JJ'), ('examples', 'NNS'), ('use', 'VBP'), ('machine', 'NN'), ('learning', 'NN'), ('search', 'NN'), ('algorithm', 'NN'), ('(', '('), ('i.e.-', 'JJ'), (',', ','), ('mining', 'VBG'), ('algorithm', 'NN'), (')', ')'), ('data', 'NN'), ('mining', 'NN'), ('problems', 'NNS'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('system', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['A promising trend', 'successful examples', 'machine learning search algorithm', 'algorithm', 'data mining problems', 'big data analytics system']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('A', 'a'), ('promising', 'promis'), ('trend', 'trend'), ('easily', 'easili'), ('found', 'found'), ('successful', 'success'), ('examples', 'exampl'), ('use', 'use'), ('machine', 'machin'), ('learning', 'learn'), ('search', 'search'), ('algorithm', 'algorithm'), ('(', '('), ('i.e.-', 'i.e.-'), (',', ','), ('mining', 'mine'), ('algorithm', 'algorithm'), (')', ')'), ('data', 'data'), ('mining', 'mine'), ('problems', 'problem'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('system', 'system'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('A', 'a'), ('promising', 'promis'), ('trend', 'trend'), ('easily', 'easili'), ('found', 'found'), ('successful', 'success'), ('examples', 'exampl'), ('use', 'use'), ('machine', 'machin'), ('learning', 'learn'), ('search', 'search'), ('algorithm', 'algorithm'), ('(', '('), ('i.e.-', 'i.e.-'), (',', ','), ('mining', 'mine'), ('algorithm', 'algorithm'), (')', ')'), ('data', 'data'), ('mining', 'mine'), ('problems', 'problem'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('system', 'system'), ('.', '.')]

>> Lemmatization: 
 [('A', 'A'), ('promising', 'promising'), ('trend', 'trend'), ('easily', 'easily'), ('found', 'found'), ('successful', 'successful'), ('examples', 'example'), ('use', 'use'), ('machine', 'machine'), ('learning', 'learning'), ('search', 'search'), ('algorithm', 'algorithm'), ('(', '('), ('i.e.-', 'i.e.-'), (',', ','), ('mining', 'mining'), ('algorithm', 'algorithm'), (')', ')'), ('data', 'data'), ('mining', 'mining'), ('problems', 'problem'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('system', 'system'), ('.', '.')]


------------------- Sentence 2 -------------------

The machine learning-based methods are able to

>> Tokens are: 
 ['The', 'machine', 'learning-based', 'methods', 'able']

>> Bigrams are: 
 [('The', 'machine'), ('machine', 'learning-based'), ('learning-based', 'methods'), ('methods', 'able')]

>> Trigrams are: 
 [('The', 'machine', 'learning-based'), ('machine', 'learning-based', 'methods'), ('learning-based', 'methods', 'able')]

>> POS Tags are: 
 [('The', 'DT'), ('machine', 'NN'), ('learning-based', 'JJ'), ('methods', 'NNS'), ('able', 'JJ')]

>> Noun Phrases are: 
 ['The machine', 'learning-based methods']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('machine', 'machin'), ('learning-based', 'learning-bas'), ('methods', 'method'), ('able', 'abl')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('machine', 'machin'), ('learning-based', 'learning-bas'), ('methods', 'method'), ('able', 'abl')]

>> Lemmatization: 
 [('The', 'The'), ('machine', 'machine'), ('learning-based', 'learning-based'), ('methods', 'method'), ('able', 'able')]



========================================== PARAGRAPH 320 ===========================================

Table 3 The big data analysis frameworks and methods 

------------------- Sentence 1 -------------------

Table 3 The big data analysis frameworks and methods

>> Tokens are: 
 ['Table', '3', 'The', 'big', 'data', 'analysis', 'frameworks', 'methods']

>> Bigrams are: 
 [('Table', '3'), ('3', 'The'), ('The', 'big'), ('big', 'data'), ('data', 'analysis'), ('analysis', 'frameworks'), ('frameworks', 'methods')]

>> Trigrams are: 
 [('Table', '3', 'The'), ('3', 'The', 'big'), ('The', 'big', 'data'), ('big', 'data', 'analysis'), ('data', 'analysis', 'frameworks'), ('analysis', 'frameworks', 'methods')]

>> POS Tags are: 
 [('Table', 'JJ'), ('3', 'CD'), ('The', 'DT'), ('big', 'JJ'), ('data', 'NNS'), ('analysis', 'NN'), ('frameworks', 'NNS'), ('methods', 'NNS')]

>> Noun Phrases are: 
 ['The big data analysis frameworks methods']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Table', 'tabl'), ('3', '3'), ('The', 'the'), ('big', 'big'), ('data', 'data'), ('analysis', 'analysi'), ('frameworks', 'framework'), ('methods', 'method')]

>> Stemming using Snowball Stemmer: 
 [('Table', 'tabl'), ('3', '3'), ('The', 'the'), ('big', 'big'), ('data', 'data'), ('analysis', 'analysi'), ('frameworks', 'framework'), ('methods', 'method')]

>> Lemmatization: 
 [('Table', 'Table'), ('3', '3'), ('The', 'The'), ('big', 'big'), ('data', 'data'), ('analysis', 'analysis'), ('frameworks', 'framework'), ('methods', 'method')]



========================================== PARAGRAPH 321 ===========================================

P perspective, T  taxonomy, ML machine learning, CLU clustering, CLA classification, FP frequent pattern 

------------------- Sentence 1 -------------------

P perspective, T  taxonomy, ML machine learning, CLU clustering, CLA classification, FP frequent pattern

>> Tokens are: 
 ['P', 'perspective', ',', 'T', 'taxonomy', ',', 'ML', 'machine', 'learning', ',', 'CLU', 'clustering', ',', 'CLA', 'classification', ',', 'FP', 'frequent', 'pattern']

>> Bigrams are: 
 [('P', 'perspective'), ('perspective', ','), (',', 'T'), ('T', 'taxonomy'), ('taxonomy', ','), (',', 'ML'), ('ML', 'machine'), ('machine', 'learning'), ('learning', ','), (',', 'CLU'), ('CLU', 'clustering'), ('clustering', ','), (',', 'CLA'), ('CLA', 'classification'), ('classification', ','), (',', 'FP'), ('FP', 'frequent'), ('frequent', 'pattern')]

>> Trigrams are: 
 [('P', 'perspective', ','), ('perspective', ',', 'T'), (',', 'T', 'taxonomy'), ('T', 'taxonomy', ','), ('taxonomy', ',', 'ML'), (',', 'ML', 'machine'), ('ML', 'machine', 'learning'), ('machine', 'learning', ','), ('learning', ',', 'CLU'), (',', 'CLU', 'clustering'), ('CLU', 'clustering', ','), ('clustering', ',', 'CLA'), (',', 'CLA', 'classification'), ('CLA', 'classification', ','), ('classification', ',', 'FP'), (',', 'FP', 'frequent'), ('FP', 'frequent', 'pattern')]

>> POS Tags are: 
 [('P', 'NNP'), ('perspective', 'NN'), (',', ','), ('T', 'NNP'), ('taxonomy', 'NN'), (',', ','), ('ML', 'NNP'), ('machine', 'NN'), ('learning', 'NN'), (',', ','), ('CLU', 'NNP'), ('clustering', 'NN'), (',', ','), ('CLA', 'NNP'), ('classification', 'NN'), (',', ','), ('FP', 'NNP'), ('frequent', 'NN'), ('pattern', 'NN')]

>> Noun Phrases are: 
 ['P perspective', 'T taxonomy', 'ML machine learning', 'CLU clustering', 'CLA classification', 'FP frequent pattern']

>> Named Entities are: 
 [('ORGANIZATION', 'ML'), ('ORGANIZATION', 'CLU'), ('ORGANIZATION', 'CLA'), ('ORGANIZATION', 'FP')] 

>> Stemming using Porter Stemmer: 
 [('P', 'p'), ('perspective', 'perspect'), (',', ','), ('T', 't'), ('taxonomy', 'taxonomi'), (',', ','), ('ML', 'ml'), ('machine', 'machin'), ('learning', 'learn'), (',', ','), ('CLU', 'clu'), ('clustering', 'cluster'), (',', ','), ('CLA', 'cla'), ('classification', 'classif'), (',', ','), ('FP', 'fp'), ('frequent', 'frequent'), ('pattern', 'pattern')]

>> Stemming using Snowball Stemmer: 
 [('P', 'p'), ('perspective', 'perspect'), (',', ','), ('T', 't'), ('taxonomy', 'taxonomi'), (',', ','), ('ML', 'ml'), ('machine', 'machin'), ('learning', 'learn'), (',', ','), ('CLU', 'clu'), ('clustering', 'cluster'), (',', ','), ('CLA', 'cla'), ('classification', 'classif'), (',', ','), ('FP', 'fp'), ('frequent', 'frequent'), ('pattern', 'pattern')]

>> Lemmatization: 
 [('P', 'P'), ('perspective', 'perspective'), (',', ','), ('T', 'T'), ('taxonomy', 'taxonomy'), (',', ','), ('ML', 'ML'), ('machine', 'machine'), ('learning', 'learning'), (',', ','), ('CLU', 'CLU'), ('clustering', 'clustering'), (',', ','), ('CLA', 'CLA'), ('classification', 'classification'), (',', ','), ('FP', 'FP'), ('frequent', 'frequent'), ('pattern', 'pattern')]



========================================== PARAGRAPH 322 ===========================================

P Name References Year Description T 

------------------- Sentence 1 -------------------

P Name References Year Description T

>> Tokens are: 
 ['P', 'Name', 'References', 'Year', 'Description', 'T']

>> Bigrams are: 
 [('P', 'Name'), ('Name', 'References'), ('References', 'Year'), ('Year', 'Description'), ('Description', 'T')]

>> Trigrams are: 
 [('P', 'Name', 'References'), ('Name', 'References', 'Year'), ('References', 'Year', 'Description'), ('Year', 'Description', 'T')]

>> POS Tags are: 
 [('P', 'NNP'), ('Name', 'NNP'), ('References', 'NNPS'), ('Year', 'NNP'), ('Description', 'NNP'), ('T', 'NNP')]

>> Noun Phrases are: 
 ['P Name', 'Year Description T']

>> Named Entities are: 
 [('PERSON', 'P'), ('ORGANIZATION', 'Name References Year')] 

>> Stemming using Porter Stemmer: 
 [('P', 'p'), ('Name', 'name'), ('References', 'refer'), ('Year', 'year'), ('Description', 'descript'), ('T', 't')]

>> Stemming using Snowball Stemmer: 
 [('P', 'p'), ('Name', 'name'), ('References', 'refer'), ('Year', 'year'), ('Description', 'descript'), ('T', 't')]

>> Lemmatization: 
 [('P', 'P'), ('Name', 'Name'), ('References', 'References'), ('Year', 'Year'), ('Description', 'Description'), ('T', 'T')]



========================================== PARAGRAPH 323 ===========================================

Analysis framework DOT [88] 2011 Add more computation resources  via scale out solution 

------------------- Sentence 1 -------------------

Analysis framework DOT [88] 2011 Add more computation resources  via scale out solution

>> Tokens are: 
 ['Analysis', 'framework', 'DOT', '[', '88', ']', '2011', 'Add', 'computation', 'resources', 'via', 'scale', 'solution']

>> Bigrams are: 
 [('Analysis', 'framework'), ('framework', 'DOT'), ('DOT', '['), ('[', '88'), ('88', ']'), (']', '2011'), ('2011', 'Add'), ('Add', 'computation'), ('computation', 'resources'), ('resources', 'via'), ('via', 'scale'), ('scale', 'solution')]

>> Trigrams are: 
 [('Analysis', 'framework', 'DOT'), ('framework', 'DOT', '['), ('DOT', '[', '88'), ('[', '88', ']'), ('88', ']', '2011'), (']', '2011', 'Add'), ('2011', 'Add', 'computation'), ('Add', 'computation', 'resources'), ('computation', 'resources', 'via'), ('resources', 'via', 'scale'), ('via', 'scale', 'solution')]

>> POS Tags are: 
 [('Analysis', 'NN'), ('framework', 'NN'), ('DOT', 'NNP'), ('[', 'VBZ'), ('88', 'CD'), (']', 'NN'), ('2011', 'CD'), ('Add', 'NNP'), ('computation', 'NN'), ('resources', 'NNS'), ('via', 'IN'), ('scale', 'JJ'), ('solution', 'NN')]

>> Noun Phrases are: 
 ['Analysis framework DOT', ']', 'Add computation resources', 'scale solution']

>> Named Entities are: 
 [('GPE', 'Analysis'), ('ORGANIZATION', 'DOT')] 

>> Stemming using Porter Stemmer: 
 [('Analysis', 'analysi'), ('framework', 'framework'), ('DOT', 'dot'), ('[', '['), ('88', '88'), (']', ']'), ('2011', '2011'), ('Add', 'add'), ('computation', 'comput'), ('resources', 'resourc'), ('via', 'via'), ('scale', 'scale'), ('solution', 'solut')]

>> Stemming using Snowball Stemmer: 
 [('Analysis', 'analysi'), ('framework', 'framework'), ('DOT', 'dot'), ('[', '['), ('88', '88'), (']', ']'), ('2011', '2011'), ('Add', 'add'), ('computation', 'comput'), ('resources', 'resourc'), ('via', 'via'), ('scale', 'scale'), ('solution', 'solut')]

>> Lemmatization: 
 [('Analysis', 'Analysis'), ('framework', 'framework'), ('DOT', 'DOT'), ('[', '['), ('88', '88'), (']', ']'), ('2011', '2011'), ('Add', 'Add'), ('computation', 'computation'), ('resources', 'resource'), ('via', 'via'), ('scale', 'scale'), ('solution', 'solution')]



========================================== PARAGRAPH 324 ===========================================

Framework 

------------------- Sentence 1 -------------------

Framework

>> Tokens are: 
 ['Framework']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Framework', 'NN')]

>> Noun Phrases are: 
 ['Framework']

>> Named Entities are: 
 [('GPE', 'Framework')] 

>> Stemming using Porter Stemmer: 
 [('Framework', 'framework')]

>> Stemming using Snowball Stemmer: 
 [('Framework', 'framework')]

>> Lemmatization: 
 [('Framework', 'Framework')]



========================================== PARAGRAPH 325 ===========================================

GLADE [89] 2011 Multi‑level tree‑based system  architecture 

------------------- Sentence 1 -------------------

GLADE [89] 2011 Multi‑level tree‑based system  architecture

>> Tokens are: 
 ['GLADE', '[', '89', ']', '2011', 'Multi‑level', 'tree‑based', 'system', 'architecture']

>> Bigrams are: 
 [('GLADE', '['), ('[', '89'), ('89', ']'), (']', '2011'), ('2011', 'Multi‑level'), ('Multi‑level', 'tree‑based'), ('tree‑based', 'system'), ('system', 'architecture')]

>> Trigrams are: 
 [('GLADE', '[', '89'), ('[', '89', ']'), ('89', ']', '2011'), (']', '2011', 'Multi‑level'), ('2011', 'Multi‑level', 'tree‑based'), ('Multi‑level', 'tree‑based', 'system'), ('tree‑based', 'system', 'architecture')]

>> POS Tags are: 
 [('GLADE', 'NNP'), ('[', 'VBD'), ('89', 'CD'), (']', 'NN'), ('2011', 'CD'), ('Multi‑level', 'NNP'), ('tree‑based', 'VBD'), ('system', 'NN'), ('architecture', 'NN')]

>> Noun Phrases are: 
 ['GLADE', ']', 'Multi‑level', 'system architecture']

>> Named Entities are: 
 [('GPE', 'GLADE')] 

>> Stemming using Porter Stemmer: 
 [('GLADE', 'glade'), ('[', '['), ('89', '89'), (']', ']'), ('2011', '2011'), ('Multi‑level', 'multi‑level'), ('tree‑based', 'tree‑bas'), ('system', 'system'), ('architecture', 'architectur')]

>> Stemming using Snowball Stemmer: 
 [('GLADE', 'glade'), ('[', '['), ('89', '89'), (']', ']'), ('2011', '2011'), ('Multi‑level', 'multi‑level'), ('tree‑based', 'tree‑bas'), ('system', 'system'), ('architecture', 'architectur')]

>> Lemmatization: 
 [('GLADE', 'GLADE'), ('[', '['), ('89', '89'), (']', ']'), ('2011', '2011'), ('Multi‑level', 'Multi‑level'), ('tree‑based', 'tree‑based'), ('system', 'system'), ('architecture', 'architecture')]



========================================== PARAGRAPH 326 ===========================================

Starfish [92] 2012 Self‑tuning analytics system 

------------------- Sentence 1 -------------------

Starfish [92] 2012 Self‑tuning analytics system

>> Tokens are: 
 ['Starfish', '[', '92', ']', '2012', 'Self‑tuning', 'analytics', 'system']

>> Bigrams are: 
 [('Starfish', '['), ('[', '92'), ('92', ']'), (']', '2012'), ('2012', 'Self‑tuning'), ('Self‑tuning', 'analytics'), ('analytics', 'system')]

>> Trigrams are: 
 [('Starfish', '[', '92'), ('[', '92', ']'), ('92', ']', '2012'), (']', '2012', 'Self‑tuning'), ('2012', 'Self‑tuning', 'analytics'), ('Self‑tuning', 'analytics', 'system')]

>> POS Tags are: 
 [('Starfish', 'JJ'), ('[', '$'), ('92', 'CD'), (']', 'JJ'), ('2012', 'CD'), ('Self‑tuning', 'VBG'), ('analytics', 'NNS'), ('system', 'NN')]

>> Noun Phrases are: 
 ['analytics system']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Starfish', 'starfish'), ('[', '['), ('92', '92'), (']', ']'), ('2012', '2012'), ('Self‑tuning', 'self‑tun'), ('analytics', 'analyt'), ('system', 'system')]

>> Stemming using Snowball Stemmer: 
 [('Starfish', 'starfish'), ('[', '['), ('92', '92'), (']', ']'), ('2012', '2012'), ('Self‑tuning', 'self‑tun'), ('analytics', 'analyt'), ('system', 'system')]

>> Lemmatization: 
 [('Starfish', 'Starfish'), ('[', '['), ('92', '92'), (']', ']'), ('2012', '2012'), ('Self‑tuning', 'Self‑tuning'), ('analytics', 'analytics'), ('system', 'system')]



========================================== PARAGRAPH 327 ===========================================

ODT‑MDC [96] 2012 Privacy issues 

------------------- Sentence 1 -------------------

ODT‑MDC [96] 2012 Privacy issues

>> Tokens are: 
 ['ODT‑MDC', '[', '96', ']', '2012', 'Privacy', 'issues']

>> Bigrams are: 
 [('ODT‑MDC', '['), ('[', '96'), ('96', ']'), (']', '2012'), ('2012', 'Privacy'), ('Privacy', 'issues')]

>> Trigrams are: 
 [('ODT‑MDC', '[', '96'), ('[', '96', ']'), ('96', ']', '2012'), (']', '2012', 'Privacy'), ('2012', 'Privacy', 'issues')]

>> POS Tags are: 
 [('ODT‑MDC', 'NNP'), ('[', 'VBD'), ('96', 'CD'), (']', 'NN'), ('2012', 'CD'), ('Privacy', 'NNP'), ('issues', 'NNS')]

>> Noun Phrases are: 
 ['ODT‑MDC', ']', 'Privacy issues']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('ODT‑MDC', 'odt‑mdc'), ('[', '['), ('96', '96'), (']', ']'), ('2012', '2012'), ('Privacy', 'privaci'), ('issues', 'issu')]

>> Stemming using Snowball Stemmer: 
 [('ODT‑MDC', 'odt‑mdc'), ('[', '['), ('96', '96'), (']', ']'), ('2012', '2012'), ('Privacy', 'privaci'), ('issues', 'issu')]

>> Lemmatization: 
 [('ODT‑MDC', 'ODT‑MDC'), ('[', '['), ('96', '96'), (']', ']'), ('2012', '2012'), ('Privacy', 'Privacy'), ('issues', 'issue')]



========================================== PARAGRAPH 328 ===========================================

MRAM [91] 2013 Mobile agent technologies 

------------------- Sentence 1 -------------------

MRAM [91] 2013 Mobile agent technologies

>> Tokens are: 
 ['MRAM', '[', '91', ']', '2013', 'Mobile', 'agent', 'technologies']

>> Bigrams are: 
 [('MRAM', '['), ('[', '91'), ('91', ']'), (']', '2013'), ('2013', 'Mobile'), ('Mobile', 'agent'), ('agent', 'technologies')]

>> Trigrams are: 
 [('MRAM', '[', '91'), ('[', '91', ']'), ('91', ']', '2013'), (']', '2013', 'Mobile'), ('2013', 'Mobile', 'agent'), ('Mobile', 'agent', 'technologies')]

>> POS Tags are: 
 [('MRAM', 'NNP'), ('[', 'VBZ'), ('91', 'CD'), (']', 'NN'), ('2013', 'CD'), ('Mobile', 'NNP'), ('agent', 'NN'), ('technologies', 'NNS')]

>> Noun Phrases are: 
 ['MRAM', ']', 'Mobile agent technologies']

>> Named Entities are: 
 [('ORGANIZATION', 'MRAM')] 

>> Stemming using Porter Stemmer: 
 [('MRAM', 'mram'), ('[', '['), ('91', '91'), (']', ']'), ('2013', '2013'), ('Mobile', 'mobil'), ('agent', 'agent'), ('technologies', 'technolog')]

>> Stemming using Snowball Stemmer: 
 [('MRAM', 'mram'), ('[', '['), ('91', '91'), (']', ']'), ('2013', '2013'), ('Mobile', 'mobil'), ('agent', 'agent'), ('technologies', 'technolog')]

>> Lemmatization: 
 [('MRAM', 'MRAM'), ('[', '['), ('91', '91'), (']', ']'), ('2013', '2013'), ('Mobile', 'Mobile'), ('agent', 'agent'), ('technologies', 'technology')]



========================================== PARAGRAPH 329 ===========================================

CBDMASP [94] 2013 Statistical computation and data  mining approaches 

------------------- Sentence 1 -------------------

CBDMASP [94] 2013 Statistical computation and data  mining approaches

>> Tokens are: 
 ['CBDMASP', '[', '94', ']', '2013', 'Statistical', 'computation', 'data', 'mining', 'approaches']

>> Bigrams are: 
 [('CBDMASP', '['), ('[', '94'), ('94', ']'), (']', '2013'), ('2013', 'Statistical'), ('Statistical', 'computation'), ('computation', 'data'), ('data', 'mining'), ('mining', 'approaches')]

>> Trigrams are: 
 [('CBDMASP', '[', '94'), ('[', '94', ']'), ('94', ']', '2013'), (']', '2013', 'Statistical'), ('2013', 'Statistical', 'computation'), ('Statistical', 'computation', 'data'), ('computation', 'data', 'mining'), ('data', 'mining', 'approaches')]

>> POS Tags are: 
 [('CBDMASP', 'NNP'), ('[', 'VBD'), ('94', 'CD'), (']', 'NN'), ('2013', 'CD'), ('Statistical', 'NNP'), ('computation', 'NN'), ('data', 'NNS'), ('mining', 'NN'), ('approaches', 'NNS')]

>> Noun Phrases are: 
 ['CBDMASP', ']', 'Statistical computation data mining approaches']

>> Named Entities are: 
 [('ORGANIZATION', 'CBDMASP')] 

>> Stemming using Porter Stemmer: 
 [('CBDMASP', 'cbdmasp'), ('[', '['), ('94', '94'), (']', ']'), ('2013', '2013'), ('Statistical', 'statist'), ('computation', 'comput'), ('data', 'data'), ('mining', 'mine'), ('approaches', 'approach')]

>> Stemming using Snowball Stemmer: 
 [('CBDMASP', 'cbdmasp'), ('[', '['), ('94', '94'), (']', ']'), ('2013', '2013'), ('Statistical', 'statist'), ('computation', 'comput'), ('data', 'data'), ('mining', 'mine'), ('approaches', 'approach')]

>> Lemmatization: 
 [('CBDMASP', 'CBDMASP'), ('[', '['), ('94', '94'), (']', ']'), ('2013', '2013'), ('Statistical', 'Statistical'), ('computation', 'computation'), ('data', 'data'), ('mining', 'mining'), ('approaches', 'approach')]



========================================== PARAGRAPH 330 ===========================================

SODSS [97] 2013 Decision support system issues 

------------------- Sentence 1 -------------------

SODSS [97] 2013 Decision support system issues

>> Tokens are: 
 ['SODSS', '[', '97', ']', '2013', 'Decision', 'support', 'system', 'issues']

>> Bigrams are: 
 [('SODSS', '['), ('[', '97'), ('97', ']'), (']', '2013'), ('2013', 'Decision'), ('Decision', 'support'), ('support', 'system'), ('system', 'issues')]

>> Trigrams are: 
 [('SODSS', '[', '97'), ('[', '97', ']'), ('97', ']', '2013'), (']', '2013', 'Decision'), ('2013', 'Decision', 'support'), ('Decision', 'support', 'system'), ('support', 'system', 'issues')]

>> POS Tags are: 
 [('SODSS', 'NNP'), ('[', 'VBD'), ('97', 'CD'), (']', 'NN'), ('2013', 'CD'), ('Decision', 'NNP'), ('support', 'NN'), ('system', 'NN'), ('issues', 'NNS')]

>> Noun Phrases are: 
 ['SODSS', ']', 'Decision support system issues']

>> Named Entities are: 
 [('ORGANIZATION', 'SODSS')] 

>> Stemming using Porter Stemmer: 
 [('SODSS', 'sodss'), ('[', '['), ('97', '97'), (']', ']'), ('2013', '2013'), ('Decision', 'decis'), ('support', 'support'), ('system', 'system'), ('issues', 'issu')]

>> Stemming using Snowball Stemmer: 
 [('SODSS', 'sodss'), ('[', '['), ('97', '97'), (']', ']'), ('2013', '2013'), ('Decision', 'decis'), ('support', 'support'), ('system', 'system'), ('issues', 'issu')]

>> Lemmatization: 
 [('SODSS', 'SODSS'), ('[', '['), ('97', '97'), (']', ']'), ('2013', '2013'), ('Decision', 'Decision'), ('support', 'support'), ('system', 'system'), ('issues', 'issue')]



========================================== PARAGRAPH 331 ===========================================

BDAF [93] 2014 Data centric architecture 

------------------- Sentence 1 -------------------

BDAF [93] 2014 Data centric architecture

>> Tokens are: 
 ['BDAF', '[', '93', ']', '2014', 'Data', 'centric', 'architecture']

>> Bigrams are: 
 [('BDAF', '['), ('[', '93'), ('93', ']'), (']', '2014'), ('2014', 'Data'), ('Data', 'centric'), ('centric', 'architecture')]

>> Trigrams are: 
 [('BDAF', '[', '93'), ('[', '93', ']'), ('93', ']', '2014'), (']', '2014', 'Data'), ('2014', 'Data', 'centric'), ('Data', 'centric', 'architecture')]

>> POS Tags are: 
 [('BDAF', 'NNP'), ('[', 'VBD'), ('93', 'CD'), (']', 'JJ'), ('2014', 'CD'), ('Data', 'NNP'), ('centric', 'NN'), ('architecture', 'NN')]

>> Noun Phrases are: 
 ['BDAF', 'Data centric architecture']

>> Named Entities are: 
 [('ORGANIZATION', 'BDAF')] 

>> Stemming using Porter Stemmer: 
 [('BDAF', 'bdaf'), ('[', '['), ('93', '93'), (']', ']'), ('2014', '2014'), ('Data', 'data'), ('centric', 'centric'), ('architecture', 'architectur')]

>> Stemming using Snowball Stemmer: 
 [('BDAF', 'bdaf'), ('[', '['), ('93', '93'), (']', ']'), ('2014', '2014'), ('Data', 'data'), ('centric', 'centric'), ('architecture', 'architectur')]

>> Lemmatization: 
 [('BDAF', 'BDAF'), ('[', '['), ('93', '93'), (']', ']'), ('2014', '2014'), ('Data', 'Data'), ('centric', 'centric'), ('architecture', 'architecture')]



========================================== PARAGRAPH 332 ===========================================

HACE [95] 2014 Data mining approaches 

------------------- Sentence 1 -------------------

HACE [95] 2014 Data mining approaches

>> Tokens are: 
 ['HACE', '[', '95', ']', '2014', 'Data', 'mining', 'approaches']

>> Bigrams are: 
 [('HACE', '['), ('[', '95'), ('95', ']'), (']', '2014'), ('2014', 'Data'), ('Data', 'mining'), ('mining', 'approaches')]

>> Trigrams are: 
 [('HACE', '[', '95'), ('[', '95', ']'), ('95', ']', '2014'), (']', '2014', 'Data'), ('2014', 'Data', 'mining'), ('Data', 'mining', 'approaches')]

>> POS Tags are: 
 [('HACE', 'NNP'), ('[', 'NNP'), ('95', 'CD'), (']', 'NN'), ('2014', 'CD'), ('Data', 'NNP'), ('mining', 'NN'), ('approaches', 'NNS')]

>> Noun Phrases are: 
 ['HACE [', ']', 'Data mining approaches']

>> Named Entities are: 
 [('ORGANIZATION', 'HACE')] 

>> Stemming using Porter Stemmer: 
 [('HACE', 'hace'), ('[', '['), ('95', '95'), (']', ']'), ('2014', '2014'), ('Data', 'data'), ('mining', 'mine'), ('approaches', 'approach')]

>> Stemming using Snowball Stemmer: 
 [('HACE', 'hace'), ('[', '['), ('95', '95'), (']', ']'), ('2014', '2014'), ('Data', 'data'), ('mining', 'mine'), ('approaches', 'approach')]

>> Lemmatization: 
 [('HACE', 'HACE'), ('[', '['), ('95', '95'), (']', ']'), ('2014', '2014'), ('Data', 'Data'), ('mining', 'mining'), ('approaches', 'approach')]



========================================== PARAGRAPH 333 ===========================================

Hadoop [83] 2011 Parallel computing platform Platform 

------------------- Sentence 1 -------------------

Hadoop [83] 2011 Parallel computing platform Platform

>> Tokens are: 
 ['Hadoop', '[', '83', ']', '2011', 'Parallel', 'computing', 'platform', 'Platform']

>> Bigrams are: 
 [('Hadoop', '['), ('[', '83'), ('83', ']'), (']', '2011'), ('2011', 'Parallel'), ('Parallel', 'computing'), ('computing', 'platform'), ('platform', 'Platform')]

>> Trigrams are: 
 [('Hadoop', '[', '83'), ('[', '83', ']'), ('83', ']', '2011'), (']', '2011', 'Parallel'), ('2011', 'Parallel', 'computing'), ('Parallel', 'computing', 'platform'), ('computing', 'platform', 'Platform')]

>> POS Tags are: 
 [('Hadoop', 'NNP'), ('[', 'VBD'), ('83', 'CD'), (']', 'NN'), ('2011', 'CD'), ('Parallel', 'NNP'), ('computing', 'VBG'), ('platform', 'NN'), ('Platform', 'NN')]

>> Noun Phrases are: 
 ['Hadoop', ']', 'Parallel', 'platform Platform']

>> Named Entities are: 
 [('PERSON', 'Hadoop')] 

>> Stemming using Porter Stemmer: 
 [('Hadoop', 'hadoop'), ('[', '['), ('83', '83'), (']', ']'), ('2011', '2011'), ('Parallel', 'parallel'), ('computing', 'comput'), ('platform', 'platform'), ('Platform', 'platform')]

>> Stemming using Snowball Stemmer: 
 [('Hadoop', 'hadoop'), ('[', '['), ('83', '83'), (']', ']'), ('2011', '2011'), ('Parallel', 'parallel'), ('computing', 'comput'), ('platform', 'platform'), ('Platform', 'platform')]

>> Lemmatization: 
 [('Hadoop', 'Hadoop'), ('[', '['), ('83', '83'), (']', ']'), ('2011', '2011'), ('Parallel', 'Parallel'), ('computing', 'computing'), ('platform', 'platform'), ('Platform', 'Platform')]



========================================== PARAGRAPH 334 ===========================================

CUDA [84] 2007 Parallel computing platform 

------------------- Sentence 1 -------------------

CUDA [84] 2007 Parallel computing platform

>> Tokens are: 
 ['CUDA', '[', '84', ']', '2007', 'Parallel', 'computing', 'platform']

>> Bigrams are: 
 [('CUDA', '['), ('[', '84'), ('84', ']'), (']', '2007'), ('2007', 'Parallel'), ('Parallel', 'computing'), ('computing', 'platform')]

>> Trigrams are: 
 [('CUDA', '[', '84'), ('[', '84', ']'), ('84', ']', '2007'), (']', '2007', 'Parallel'), ('2007', 'Parallel', 'computing'), ('Parallel', 'computing', 'platform')]

>> POS Tags are: 
 [('CUDA', 'NNP'), ('[', 'VBD'), ('84', 'CD'), (']', 'NN'), ('2007', 'CD'), ('Parallel', 'NNP'), ('computing', 'VBG'), ('platform', 'NN')]

>> Noun Phrases are: 
 ['CUDA', ']', 'Parallel', 'platform']

>> Named Entities are: 
 [('ORGANIZATION', 'CUDA')] 

>> Stemming using Porter Stemmer: 
 [('CUDA', 'cuda'), ('[', '['), ('84', '84'), (']', ']'), ('2007', '2007'), ('Parallel', 'parallel'), ('computing', 'comput'), ('platform', 'platform')]

>> Stemming using Snowball Stemmer: 
 [('CUDA', 'cuda'), ('[', '['), ('84', '84'), (']', ']'), ('2007', '2007'), ('Parallel', 'parallel'), ('computing', 'comput'), ('platform', 'platform')]

>> Lemmatization: 
 [('CUDA', 'CUDA'), ('[', '['), ('84', '84'), (']', ']'), ('2007', '2007'), ('Parallel', 'Parallel'), ('computing', 'computing'), ('platform', 'platform')]



========================================== PARAGRAPH 335 ===========================================

Storm [85] 2014 Parallel computing platform 

------------------- Sentence 1 -------------------

Storm [85] 2014 Parallel computing platform

>> Tokens are: 
 ['Storm', '[', '85', ']', '2014', 'Parallel', 'computing', 'platform']

>> Bigrams are: 
 [('Storm', '['), ('[', '85'), ('85', ']'), (']', '2014'), ('2014', 'Parallel'), ('Parallel', 'computing'), ('computing', 'platform')]

>> Trigrams are: 
 [('Storm', '[', '85'), ('[', '85', ']'), ('85', ']', '2014'), (']', '2014', 'Parallel'), ('2014', 'Parallel', 'computing'), ('Parallel', 'computing', 'platform')]

>> POS Tags are: 
 [('Storm', 'NNP'), ('[', 'VBZ'), ('85', 'CD'), (']', 'NN'), ('2014', 'CD'), ('Parallel', 'NNP'), ('computing', 'VBG'), ('platform', 'NN')]

>> Noun Phrases are: 
 ['Storm', ']', 'Parallel', 'platform']

>> Named Entities are: 
 [('GPE', 'Storm')] 

>> Stemming using Porter Stemmer: 
 [('Storm', 'storm'), ('[', '['), ('85', '85'), (']', ']'), ('2014', '2014'), ('Parallel', 'parallel'), ('computing', 'comput'), ('platform', 'platform')]

>> Stemming using Snowball Stemmer: 
 [('Storm', 'storm'), ('[', '['), ('85', '85'), (']', ']'), ('2014', '2014'), ('Parallel', 'parallel'), ('computing', 'comput'), ('platform', 'platform')]

>> Lemmatization: 
 [('Storm', 'Storm'), ('[', '['), ('85', '85'), (']', ']'), ('2014', '2014'), ('Parallel', 'Parallel'), ('computing', 'computing'), ('platform', 'platform')]



========================================== PARAGRAPH 336 ===========================================

Pregel [125] 2010 Large‑scale graph data analysis 

------------------- Sentence 1 -------------------

Pregel [125] 2010 Large‑scale graph data analysis

>> Tokens are: 
 ['Pregel', '[', '125', ']', '2010', 'Large‑scale', 'graph', 'data', 'analysis']

>> Bigrams are: 
 [('Pregel', '['), ('[', '125'), ('125', ']'), (']', '2010'), ('2010', 'Large‑scale'), ('Large‑scale', 'graph'), ('graph', 'data'), ('data', 'analysis')]

>> Trigrams are: 
 [('Pregel', '[', '125'), ('[', '125', ']'), ('125', ']', '2010'), (']', '2010', 'Large‑scale'), ('2010', 'Large‑scale', 'graph'), ('Large‑scale', 'graph', 'data'), ('graph', 'data', 'analysis')]

>> POS Tags are: 
 [('Pregel', 'NNP'), ('[', 'VBD'), ('125', 'CD'), (']', 'NN'), ('2010', 'CD'), ('Large‑scale', 'NNP'), ('graph', 'NN'), ('data', 'NNS'), ('analysis', 'NN')]

>> Noun Phrases are: 
 ['Pregel', ']', 'Large‑scale graph data analysis']

>> Named Entities are: 
 [('PERSON', 'Pregel')] 

>> Stemming using Porter Stemmer: 
 [('Pregel', 'pregel'), ('[', '['), ('125', '125'), (']', ']'), ('2010', '2010'), ('Large‑scale', 'large‑scal'), ('graph', 'graph'), ('data', 'data'), ('analysis', 'analysi')]

>> Stemming using Snowball Stemmer: 
 [('Pregel', 'pregel'), ('[', '['), ('125', '125'), (']', ']'), ('2010', '2010'), ('Large‑scale', 'large‑scal'), ('graph', 'graph'), ('data', 'data'), ('analysis', 'analysi')]

>> Lemmatization: 
 [('Pregel', 'Pregel'), ('[', '['), ('125', '125'), (']', ']'), ('2010', '2010'), ('Large‑scale', 'Large‑scale'), ('graph', 'graph'), ('data', 'data'), ('analysis', 'analysis')]



========================================== PARAGRAPH 337 ===========================================

MLPACK [86] 2013 Scalable machine learning library ML 

------------------- Sentence 1 -------------------

MLPACK [86] 2013 Scalable machine learning library ML

>> Tokens are: 
 ['MLPACK', '[', '86', ']', '2013', 'Scalable', 'machine', 'learning', 'library', 'ML']

>> Bigrams are: 
 [('MLPACK', '['), ('[', '86'), ('86', ']'), (']', '2013'), ('2013', 'Scalable'), ('Scalable', 'machine'), ('machine', 'learning'), ('learning', 'library'), ('library', 'ML')]

>> Trigrams are: 
 [('MLPACK', '[', '86'), ('[', '86', ']'), ('86', ']', '2013'), (']', '2013', 'Scalable'), ('2013', 'Scalable', 'machine'), ('Scalable', 'machine', 'learning'), ('machine', 'learning', 'library'), ('learning', 'library', 'ML')]

>> POS Tags are: 
 [('MLPACK', 'NNP'), ('[', 'VBZ'), ('86', 'CD'), (']', 'NN'), ('2013', 'CD'), ('Scalable', 'JJ'), ('machine', 'NN'), ('learning', 'VBG'), ('library', 'JJ'), ('ML', 'NNP')]

>> Noun Phrases are: 
 ['MLPACK', ']', 'Scalable machine', 'library ML']

>> Named Entities are: 
 [('GPE', 'MLPACK')] 

>> Stemming using Porter Stemmer: 
 [('MLPACK', 'mlpack'), ('[', '['), ('86', '86'), (']', ']'), ('2013', '2013'), ('Scalable', 'scalabl'), ('machine', 'machin'), ('learning', 'learn'), ('library', 'librari'), ('ML', 'ml')]

>> Stemming using Snowball Stemmer: 
 [('MLPACK', 'mlpack'), ('[', '['), ('86', '86'), (']', ']'), ('2013', '2013'), ('Scalable', 'scalabl'), ('machine', 'machin'), ('learning', 'learn'), ('library', 'librari'), ('ML', 'ml')]

>> Lemmatization: 
 [('MLPACK', 'MLPACK'), ('[', '['), ('86', '86'), (']', ']'), ('2013', '2013'), ('Scalable', 'Scalable'), ('machine', 'machine'), ('learning', 'learning'), ('library', 'library'), ('ML', 'ML')]



========================================== PARAGRAPH 338 ===========================================

Mahout [87] 2011 Machine‑learning algorithms 

------------------- Sentence 1 -------------------

Mahout [87] 2011 Machine‑learning algorithms

>> Tokens are: 
 ['Mahout', '[', '87', ']', '2011', 'Machine‑learning', 'algorithms']

>> Bigrams are: 
 [('Mahout', '['), ('[', '87'), ('87', ']'), (']', '2011'), ('2011', 'Machine‑learning'), ('Machine‑learning', 'algorithms')]

>> Trigrams are: 
 [('Mahout', '[', '87'), ('[', '87', ']'), ('87', ']', '2011'), (']', '2011', 'Machine‑learning'), ('2011', 'Machine‑learning', 'algorithms')]

>> POS Tags are: 
 [('Mahout', 'NNP'), ('[', 'VBZ'), ('87', 'CD'), (']', 'NN'), ('2011', 'CD'), ('Machine‑learning', 'NNP'), ('algorithms', 'NN')]

>> Noun Phrases are: 
 ['Mahout', ']', 'Machine‑learning algorithms']

>> Named Entities are: 
 [('GPE', 'Mahout')] 

>> Stemming using Porter Stemmer: 
 [('Mahout', 'mahout'), ('[', '['), ('87', '87'), (']', ']'), ('2011', '2011'), ('Machine‑learning', 'machine‑learn'), ('algorithms', 'algorithm')]

>> Stemming using Snowball Stemmer: 
 [('Mahout', 'mahout'), ('[', '['), ('87', '87'), (']', ']'), ('2011', '2011'), ('Machine‑learning', 'machine‑learn'), ('algorithms', 'algorithm')]

>> Lemmatization: 
 [('Mahout', 'Mahout'), ('[', '['), ('87', '87'), (']', ']'), ('2011', '2011'), ('Machine‑learning', 'Machine‑learning'), ('algorithms', 'algorithm')]



========================================== PARAGRAPH 339 ===========================================

MLAS [124] 2012 Machine‑learning algorithms 

------------------- Sentence 1 -------------------

MLAS [124] 2012 Machine‑learning algorithms

>> Tokens are: 
 ['MLAS', '[', '124', ']', '2012', 'Machine‑learning', 'algorithms']

>> Bigrams are: 
 [('MLAS', '['), ('[', '124'), ('124', ']'), (']', '2012'), ('2012', 'Machine‑learning'), ('Machine‑learning', 'algorithms')]

>> Trigrams are: 
 [('MLAS', '[', '124'), ('[', '124', ']'), ('124', ']', '2012'), (']', '2012', 'Machine‑learning'), ('2012', 'Machine‑learning', 'algorithms')]

>> POS Tags are: 
 [('MLAS', 'NNP'), ('[', 'VBD'), ('124', 'CD'), (']', 'NN'), ('2012', 'CD'), ('Machine‑learning', 'NNP'), ('algorithms', 'NN')]

>> Noun Phrases are: 
 ['MLAS', ']', 'Machine‑learning algorithms']

>> Named Entities are: 
 [('ORGANIZATION', 'MLAS')] 

>> Stemming using Porter Stemmer: 
 [('MLAS', 'mla'), ('[', '['), ('124', '124'), (']', ']'), ('2012', '2012'), ('Machine‑learning', 'machine‑learn'), ('algorithms', 'algorithm')]

>> Stemming using Snowball Stemmer: 
 [('MLAS', 'mlas'), ('[', '['), ('124', '124'), (']', ']'), ('2012', '2012'), ('Machine‑learning', 'machine‑learn'), ('algorithms', 'algorithm')]

>> Lemmatization: 
 [('MLAS', 'MLAS'), ('[', '['), ('124', '124'), (']', ']'), ('2012', '2012'), ('Machine‑learning', 'Machine‑learning'), ('algorithms', 'algorithm')]



========================================== PARAGRAPH 340 ===========================================

PIMRU [124] 2012 Machine Learning algorithms 

------------------- Sentence 1 -------------------

PIMRU [124] 2012 Machine Learning algorithms

>> Tokens are: 
 ['PIMRU', '[', '124', ']', '2012', 'Machine', 'Learning', 'algorithms']

>> Bigrams are: 
 [('PIMRU', '['), ('[', '124'), ('124', ']'), (']', '2012'), ('2012', 'Machine'), ('Machine', 'Learning'), ('Learning', 'algorithms')]

>> Trigrams are: 
 [('PIMRU', '[', '124'), ('[', '124', ']'), ('124', ']', '2012'), (']', '2012', 'Machine'), ('2012', 'Machine', 'Learning'), ('Machine', 'Learning', 'algorithms')]

>> POS Tags are: 
 [('PIMRU', 'NNP'), ('[', 'VBD'), ('124', 'CD'), (']', 'JJ'), ('2012', 'CD'), ('Machine', 'NNP'), ('Learning', 'NNP'), ('algorithms', 'NN')]

>> Noun Phrases are: 
 ['PIMRU', 'Machine Learning algorithms']

>> Named Entities are: 
 [('ORGANIZATION', 'PIMRU'), ('PERSON', 'Machine Learning')] 

>> Stemming using Porter Stemmer: 
 [('PIMRU', 'pimru'), ('[', '['), ('124', '124'), (']', ']'), ('2012', '2012'), ('Machine', 'machin'), ('Learning', 'learn'), ('algorithms', 'algorithm')]

>> Stemming using Snowball Stemmer: 
 [('PIMRU', 'pimru'), ('[', '['), ('124', '124'), (']', ']'), ('2012', '2012'), ('Machine', 'machin'), ('Learning', 'learn'), ('algorithms', 'algorithm')]

>> Lemmatization: 
 [('PIMRU', 'PIMRU'), ('[', '['), ('124', '124'), (']', ']'), ('2012', '2012'), ('Machine', 'Machine'), ('Learning', 'Learning'), ('algorithms', 'algorithm')]



========================================== PARAGRAPH 341 ===========================================

Radoop [129] 2011 Data analytics, machine learning  algorithms, and R statistical tool 

------------------- Sentence 1 -------------------

Radoop [129] 2011 Data analytics, machine learning  algorithms, and R statistical tool

>> Tokens are: 
 ['Radoop', '[', '129', ']', '2011', 'Data', 'analytics', ',', 'machine', 'learning', 'algorithms', ',', 'R', 'statistical', 'tool']

>> Bigrams are: 
 [('Radoop', '['), ('[', '129'), ('129', ']'), (']', '2011'), ('2011', 'Data'), ('Data', 'analytics'), ('analytics', ','), (',', 'machine'), ('machine', 'learning'), ('learning', 'algorithms'), ('algorithms', ','), (',', 'R'), ('R', 'statistical'), ('statistical', 'tool')]

>> Trigrams are: 
 [('Radoop', '[', '129'), ('[', '129', ']'), ('129', ']', '2011'), (']', '2011', 'Data'), ('2011', 'Data', 'analytics'), ('Data', 'analytics', ','), ('analytics', ',', 'machine'), (',', 'machine', 'learning'), ('machine', 'learning', 'algorithms'), ('learning', 'algorithms', ','), ('algorithms', ',', 'R'), (',', 'R', 'statistical'), ('R', 'statistical', 'tool')]

>> POS Tags are: 
 [('Radoop', 'NNP'), ('[', 'VBD'), ('129', 'CD'), (']', 'JJ'), ('2011', 'CD'), ('Data', 'NNP'), ('analytics', 'NNS'), (',', ','), ('machine', 'NN'), ('learning', 'NN'), ('algorithms', 'NN'), (',', ','), ('R', 'NNP'), ('statistical', 'JJ'), ('tool', 'NN')]

>> Noun Phrases are: 
 ['Radoop', 'Data analytics', 'machine learning algorithms', 'R', 'statistical tool']

>> Named Entities are: 
 [('PERSON', 'Radoop')] 

>> Stemming using Porter Stemmer: 
 [('Radoop', 'radoop'), ('[', '['), ('129', '129'), (']', ']'), ('2011', '2011'), ('Data', 'data'), ('analytics', 'analyt'), (',', ','), ('machine', 'machin'), ('learning', 'learn'), ('algorithms', 'algorithm'), (',', ','), ('R', 'r'), ('statistical', 'statist'), ('tool', 'tool')]

>> Stemming using Snowball Stemmer: 
 [('Radoop', 'radoop'), ('[', '['), ('129', '129'), (']', ']'), ('2011', '2011'), ('Data', 'data'), ('analytics', 'analyt'), (',', ','), ('machine', 'machin'), ('learning', 'learn'), ('algorithms', 'algorithm'), (',', ','), ('R', 'r'), ('statistical', 'statist'), ('tool', 'tool')]

>> Lemmatization: 
 [('Radoop', 'Radoop'), ('[', '['), ('129', '129'), (']', ']'), ('2011', '2011'), ('Data', 'Data'), ('analytics', 'analytics'), (',', ','), ('machine', 'machine'), ('learning', 'learning'), ('algorithms', 'algorithm'), (',', ','), ('R', 'R'), ('statistical', 'statistical'), ('tool', 'tool')]



========================================== PARAGRAPH 342 ===========================================

Mining algorithm DBDC [144] 2004 Parallel clustering CLU 

------------------- Sentence 1 -------------------

Mining algorithm DBDC [144] 2004 Parallel clustering CLU

>> Tokens are: 
 ['Mining', 'algorithm', 'DBDC', '[', '144', ']', '2004', 'Parallel', 'clustering', 'CLU']

>> Bigrams are: 
 [('Mining', 'algorithm'), ('algorithm', 'DBDC'), ('DBDC', '['), ('[', '144'), ('144', ']'), (']', '2004'), ('2004', 'Parallel'), ('Parallel', 'clustering'), ('clustering', 'CLU')]

>> Trigrams are: 
 [('Mining', 'algorithm', 'DBDC'), ('algorithm', 'DBDC', '['), ('DBDC', '[', '144'), ('[', '144', ']'), ('144', ']', '2004'), (']', '2004', 'Parallel'), ('2004', 'Parallel', 'clustering'), ('Parallel', 'clustering', 'CLU')]

>> POS Tags are: 
 [('Mining', 'VBG'), ('algorithm', 'JJ'), ('DBDC', 'NNP'), ('[', 'NNP'), ('144', 'CD'), (']', 'NN'), ('2004', 'CD'), ('Parallel', 'NNP'), ('clustering', 'VBG'), ('CLU', 'NNP')]

>> Noun Phrases are: 
 ['algorithm DBDC [', ']', 'Parallel', 'CLU']

>> Named Entities are: 
 [('ORGANIZATION', 'DBDC'), ('ORGANIZATION', 'CLU')] 

>> Stemming using Porter Stemmer: 
 [('Mining', 'mine'), ('algorithm', 'algorithm'), ('DBDC', 'dbdc'), ('[', '['), ('144', '144'), (']', ']'), ('2004', '2004'), ('Parallel', 'parallel'), ('clustering', 'cluster'), ('CLU', 'clu')]

>> Stemming using Snowball Stemmer: 
 [('Mining', 'mine'), ('algorithm', 'algorithm'), ('DBDC', 'dbdc'), ('[', '['), ('144', '144'), (']', ']'), ('2004', '2004'), ('Parallel', 'parallel'), ('clustering', 'cluster'), ('CLU', 'clu')]

>> Lemmatization: 
 [('Mining', 'Mining'), ('algorithm', 'algorithm'), ('DBDC', 'DBDC'), ('[', '['), ('144', '144'), (']', ']'), ('2004', '2004'), ('Parallel', 'Parallel'), ('clustering', 'clustering'), ('CLU', 'CLU')]



========================================== PARAGRAPH 343 ===========================================

PKM [145] 2009 Map‑reduce‑based k‑means cluster‑ ing 

------------------- Sentence 1 -------------------

PKM [145] 2009 Map‑reduce‑based k‑means cluster‑ ing

>> Tokens are: 
 ['PKM', '[', '145', ']', '2009', 'Map‑reduce‑based', 'k‑means', 'cluster‑', 'ing']

>> Bigrams are: 
 [('PKM', '['), ('[', '145'), ('145', ']'), (']', '2009'), ('2009', 'Map‑reduce‑based'), ('Map‑reduce‑based', 'k‑means'), ('k‑means', 'cluster‑'), ('cluster‑', 'ing')]

>> Trigrams are: 
 [('PKM', '[', '145'), ('[', '145', ']'), ('145', ']', '2009'), (']', '2009', 'Map‑reduce‑based'), ('2009', 'Map‑reduce‑based', 'k‑means'), ('Map‑reduce‑based', 'k‑means', 'cluster‑'), ('k‑means', 'cluster‑', 'ing')]

>> POS Tags are: 
 [('PKM', 'NNP'), ('[', 'VBD'), ('145', 'CD'), (']', 'NN'), ('2009', 'CD'), ('Map‑reduce‑based', 'VBD'), ('k‑means', 'NNS'), ('cluster‑', 'VBP'), ('ing', 'VBG')]

>> Noun Phrases are: 
 ['PKM', ']', 'k‑means']

>> Named Entities are: 
 [('ORGANIZATION', 'PKM')] 

>> Stemming using Porter Stemmer: 
 [('PKM', 'pkm'), ('[', '['), ('145', '145'), (']', ']'), ('2009', '2009'), ('Map‑reduce‑based', 'map‑reduce‑bas'), ('k‑means', 'k‑mean'), ('cluster‑', 'cluster‑'), ('ing', 'ing')]

>> Stemming using Snowball Stemmer: 
 [('PKM', 'pkm'), ('[', '['), ('145', '145'), (']', ']'), ('2009', '2009'), ('Map‑reduce‑based', 'map‑reduce‑bas'), ('k‑means', 'k‑mean'), ('cluster‑', 'cluster‑'), ('ing', 'ing')]

>> Lemmatization: 
 [('PKM', 'PKM'), ('[', '['), ('145', '145'), (']', ']'), ('2009', '2009'), ('Map‑reduce‑based', 'Map‑reduce‑based'), ('k‑means', 'k‑means'), ('cluster‑', 'cluster‑'), ('ing', 'ing')]



========================================== PARAGRAPH 344 ===========================================

CloudVista [111] 2012 Cloud computing for clustering 

------------------- Sentence 1 -------------------

CloudVista [111] 2012 Cloud computing for clustering

>> Tokens are: 
 ['CloudVista', '[', '111', ']', '2012', 'Cloud', 'computing', 'clustering']

>> Bigrams are: 
 [('CloudVista', '['), ('[', '111'), ('111', ']'), (']', '2012'), ('2012', 'Cloud'), ('Cloud', 'computing'), ('computing', 'clustering')]

>> Trigrams are: 
 [('CloudVista', '[', '111'), ('[', '111', ']'), ('111', ']', '2012'), (']', '2012', 'Cloud'), ('2012', 'Cloud', 'computing'), ('Cloud', 'computing', 'clustering')]

>> POS Tags are: 
 [('CloudVista', 'NNP'), ('[', 'VBD'), ('111', 'CD'), (']', 'NN'), ('2012', 'CD'), ('Cloud', 'NNP'), ('computing', 'VBG'), ('clustering', 'VBG')]

>> Noun Phrases are: 
 ['CloudVista', ']', 'Cloud']

>> Named Entities are: 
 [('ORGANIZATION', 'CloudVista')] 

>> Stemming using Porter Stemmer: 
 [('CloudVista', 'cloudvista'), ('[', '['), ('111', '111'), (']', ']'), ('2012', '2012'), ('Cloud', 'cloud'), ('computing', 'comput'), ('clustering', 'cluster')]

>> Stemming using Snowball Stemmer: 
 [('CloudVista', 'cloudvista'), ('[', '['), ('111', '111'), (']', ']'), ('2012', '2012'), ('Cloud', 'cloud'), ('computing', 'comput'), ('clustering', 'cluster')]

>> Lemmatization: 
 [('CloudVista', 'CloudVista'), ('[', '['), ('111', '111'), (']', ']'), ('2012', '2012'), ('Cloud', 'Cloud'), ('computing', 'computing'), ('clustering', 'clustering')]



========================================== PARAGRAPH 345 ===========================================

MSFCUDA [113] 2013 GPU for clustering 

------------------- Sentence 1 -------------------

MSFCUDA [113] 2013 GPU for clustering

>> Tokens are: 
 ['MSFCUDA', '[', '113', ']', '2013', 'GPU', 'clustering']

>> Bigrams are: 
 [('MSFCUDA', '['), ('[', '113'), ('113', ']'), (']', '2013'), ('2013', 'GPU'), ('GPU', 'clustering')]

>> Trigrams are: 
 [('MSFCUDA', '[', '113'), ('[', '113', ']'), ('113', ']', '2013'), (']', '2013', 'GPU'), ('2013', 'GPU', 'clustering')]

>> POS Tags are: 
 [('MSFCUDA', 'NNP'), ('[', 'VBD'), ('113', 'CD'), (']', 'NN'), ('2013', 'CD'), ('GPU', 'NNP'), ('clustering', 'VBG')]

>> Noun Phrases are: 
 ['MSFCUDA', ']', 'GPU']

>> Named Entities are: 
 [('ORGANIZATION', 'MSFCUDA')] 

>> Stemming using Porter Stemmer: 
 [('MSFCUDA', 'msfcuda'), ('[', '['), ('113', '113'), (']', ']'), ('2013', '2013'), ('GPU', 'gpu'), ('clustering', 'cluster')]

>> Stemming using Snowball Stemmer: 
 [('MSFCUDA', 'msfcuda'), ('[', '['), ('113', '113'), (']', ']'), ('2013', '2013'), ('GPU', 'gpu'), ('clustering', 'cluster')]

>> Lemmatization: 
 [('MSFCUDA', 'MSFCUDA'), ('[', '['), ('113', '113'), (']', ']'), ('2013', '2013'), ('GPU', 'GPU'), ('clustering', 'clustering')]



========================================== PARAGRAPH 346 ===========================================

BDCAC [127] 2013 Ant on grid computing environment  for clustering 

------------------- Sentence 1 -------------------

BDCAC [127] 2013 Ant on grid computing environment  for clustering

>> Tokens are: 
 ['BDCAC', '[', '127', ']', '2013', 'Ant', 'grid', 'computing', 'environment', 'clustering']

>> Bigrams are: 
 [('BDCAC', '['), ('[', '127'), ('127', ']'), (']', '2013'), ('2013', 'Ant'), ('Ant', 'grid'), ('grid', 'computing'), ('computing', 'environment'), ('environment', 'clustering')]

>> Trigrams are: 
 [('BDCAC', '[', '127'), ('[', '127', ']'), ('127', ']', '2013'), (']', '2013', 'Ant'), ('2013', 'Ant', 'grid'), ('Ant', 'grid', 'computing'), ('grid', 'computing', 'environment'), ('computing', 'environment', 'clustering')]

>> POS Tags are: 
 [('BDCAC', 'NNP'), ('[', 'VBD'), ('127', 'CD'), (']', 'NN'), ('2013', 'CD'), ('Ant', 'NNP'), ('grid', 'JJ'), ('computing', 'VBG'), ('environment', 'NN'), ('clustering', 'NN')]

>> Noun Phrases are: 
 ['BDCAC', ']', 'Ant', 'environment clustering']

>> Named Entities are: 
 [('ORGANIZATION', 'BDCAC')] 

>> Stemming using Porter Stemmer: 
 [('BDCAC', 'bdcac'), ('[', '['), ('127', '127'), (']', ']'), ('2013', '2013'), ('Ant', 'ant'), ('grid', 'grid'), ('computing', 'comput'), ('environment', 'environ'), ('clustering', 'cluster')]

>> Stemming using Snowball Stemmer: 
 [('BDCAC', 'bdcac'), ('[', '['), ('127', '127'), (']', ']'), ('2013', '2013'), ('Ant', 'ant'), ('grid', 'grid'), ('computing', 'comput'), ('environment', 'environ'), ('clustering', 'cluster')]

>> Lemmatization: 
 [('BDCAC', 'BDCAC'), ('[', '['), ('127', '127'), (']', ']'), ('2013', '2013'), ('Ant', 'Ant'), ('grid', 'grid'), ('computing', 'computing'), ('environment', 'environment'), ('clustering', 'clustering')]



========================================== PARAGRAPH 347 ===========================================

Corest [114] 2013 Use a tree construction for generat‑ ing the coresets in parallel for  clustering 

------------------- Sentence 1 -------------------

Corest [114] 2013 Use a tree construction for generat‑ ing the coresets in parallel for  clustering

>> Tokens are: 
 ['Corest', '[', '114', ']', '2013', 'Use', 'tree', 'construction', 'generat‑', 'ing', 'coresets', 'parallel', 'clustering']

>> Bigrams are: 
 [('Corest', '['), ('[', '114'), ('114', ']'), (']', '2013'), ('2013', 'Use'), ('Use', 'tree'), ('tree', 'construction'), ('construction', 'generat‑'), ('generat‑', 'ing'), ('ing', 'coresets'), ('coresets', 'parallel'), ('parallel', 'clustering')]

>> Trigrams are: 
 [('Corest', '[', '114'), ('[', '114', ']'), ('114', ']', '2013'), (']', '2013', 'Use'), ('2013', 'Use', 'tree'), ('Use', 'tree', 'construction'), ('tree', 'construction', 'generat‑'), ('construction', 'generat‑', 'ing'), ('generat‑', 'ing', 'coresets'), ('ing', 'coresets', 'parallel'), ('coresets', 'parallel', 'clustering')]

>> POS Tags are: 
 [('Corest', 'NNP'), ('[', 'VBZ'), ('114', 'CD'), (']', 'NN'), ('2013', 'CD'), ('Use', 'NNP'), ('tree', 'JJ'), ('construction', 'NN'), ('generat‑', 'NN'), ('ing', 'VBG'), ('coresets', 'NNS'), ('parallel', 'JJ'), ('clustering', 'VBG')]

>> Noun Phrases are: 
 ['Corest', ']', 'Use', 'tree construction generat‑', 'coresets']

>> Named Entities are: 
 [('GPE', 'Corest')] 

>> Stemming using Porter Stemmer: 
 [('Corest', 'corest'), ('[', '['), ('114', '114'), (']', ']'), ('2013', '2013'), ('Use', 'use'), ('tree', 'tree'), ('construction', 'construct'), ('generat‑', 'generat‑'), ('ing', 'ing'), ('coresets', 'coreset'), ('parallel', 'parallel'), ('clustering', 'cluster')]

>> Stemming using Snowball Stemmer: 
 [('Corest', 'corest'), ('[', '['), ('114', '114'), (']', ']'), ('2013', '2013'), ('Use', 'use'), ('tree', 'tree'), ('construction', 'construct'), ('generat‑', 'generat‑'), ('ing', 'ing'), ('coresets', 'coreset'), ('parallel', 'parallel'), ('clustering', 'cluster')]

>> Lemmatization: 
 [('Corest', 'Corest'), ('[', '['), ('114', '114'), (']', ']'), ('2013', '2013'), ('Use', 'Use'), ('tree', 'tree'), ('construction', 'construction'), ('generat‑', 'generat‑'), ('ing', 'ing'), ('coresets', 'coresets'), ('parallel', 'parallel'), ('clustering', 'clustering')]



========================================== PARAGRAPH 348 ===========================================

SOM‑MBP [126] 2013 Neural network with CGP for clas‑ sification 

------------------- Sentence 1 -------------------

SOM‑MBP [126] 2013 Neural network with CGP for clas‑ sification

>> Tokens are: 
 ['SOM‑MBP', '[', '126', ']', '2013', 'Neural', 'network', 'CGP', 'clas‑', 'sification']

>> Bigrams are: 
 [('SOM‑MBP', '['), ('[', '126'), ('126', ']'), (']', '2013'), ('2013', 'Neural'), ('Neural', 'network'), ('network', 'CGP'), ('CGP', 'clas‑'), ('clas‑', 'sification')]

>> Trigrams are: 
 [('SOM‑MBP', '[', '126'), ('[', '126', ']'), ('126', ']', '2013'), (']', '2013', 'Neural'), ('2013', 'Neural', 'network'), ('Neural', 'network', 'CGP'), ('network', 'CGP', 'clas‑'), ('CGP', 'clas‑', 'sification')]

>> POS Tags are: 
 [('SOM‑MBP', 'NNP'), ('[', 'VBD'), ('126', 'CD'), (']', 'NN'), ('2013', 'CD'), ('Neural', 'NNP'), ('network', 'NN'), ('CGP', 'NNP'), ('clas‑', 'NN'), ('sification', 'NN')]

>> Noun Phrases are: 
 ['SOM‑MBP', ']', 'Neural network CGP clas‑ sification']

>> Named Entities are: 
 [('ORGANIZATION', 'CGP')] 

>> Stemming using Porter Stemmer: 
 [('SOM‑MBP', 'som‑mbp'), ('[', '['), ('126', '126'), (']', ']'), ('2013', '2013'), ('Neural', 'neural'), ('network', 'network'), ('CGP', 'cgp'), ('clas‑', 'clas‑'), ('sification', 'sific')]

>> Stemming using Snowball Stemmer: 
 [('SOM‑MBP', 'som‑mbp'), ('[', '['), ('126', '126'), (']', ']'), ('2013', '2013'), ('Neural', 'neural'), ('network', 'network'), ('CGP', 'cgp'), ('clas‑', 'clas‑'), ('sification', 'sific')]

>> Lemmatization: 
 [('SOM‑MBP', 'SOM‑MBP'), ('[', '['), ('126', '126'), (']', ']'), ('2013', '2013'), ('Neural', 'Neural'), ('network', 'network'), ('CGP', 'CGP'), ('clas‑', 'clas‑'), ('sification', 'sification')]



========================================== PARAGRAPH 349 ===========================================

CLA 

------------------- Sentence 1 -------------------

CLA

>> Tokens are: 
 ['CLA']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('CLA', 'NN')]

>> Noun Phrases are: 
 ['CLA']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('CLA', 'cla')]

>> Stemming using Snowball Stemmer: 
 [('CLA', 'cla')]

>> Lemmatization: 
 [('CLA', 'CLA')]



========================================== PARAGRAPH 350 ===========================================

CoS [115] 2013 Parallel computing for classification 

------------------- Sentence 1 -------------------

CoS [115] 2013 Parallel computing for classification

>> Tokens are: 
 ['CoS', '[', '115', ']', '2013', 'Parallel', 'computing', 'classification']

>> Bigrams are: 
 [('CoS', '['), ('[', '115'), ('115', ']'), (']', '2013'), ('2013', 'Parallel'), ('Parallel', 'computing'), ('computing', 'classification')]

>> Trigrams are: 
 [('CoS', '[', '115'), ('[', '115', ']'), ('115', ']', '2013'), (']', '2013', 'Parallel'), ('2013', 'Parallel', 'computing'), ('Parallel', 'computing', 'classification')]

>> POS Tags are: 
 [('CoS', 'NNP'), ('[', 'VBZ'), ('115', 'CD'), (']', 'NN'), ('2013', 'CD'), ('Parallel', 'NNP'), ('computing', 'VBG'), ('classification', 'NN')]

>> Noun Phrases are: 
 ['CoS', ']', 'Parallel', 'classification']

>> Named Entities are: 
 [('ORGANIZATION', 'CoS')] 

>> Stemming using Porter Stemmer: 
 [('CoS', 'co'), ('[', '['), ('115', '115'), (']', ']'), ('2013', '2013'), ('Parallel', 'parallel'), ('computing', 'comput'), ('classification', 'classif')]

>> Stemming using Snowball Stemmer: 
 [('CoS', 'cos'), ('[', '['), ('115', '115'), (']', ']'), ('2013', '2013'), ('Parallel', 'parallel'), ('computing', 'comput'), ('classification', 'classif')]

>> Lemmatization: 
 [('CoS', 'CoS'), ('[', '['), ('115', '115'), (']', ']'), ('2013', '2013'), ('Parallel', 'Parallel'), ('computing', 'computing'), ('classification', 'classification')]



========================================== PARAGRAPH 351 ===========================================

SVMGA [72] 2014 Using GA for reduce the number of  dimensions 

------------------- Sentence 1 -------------------

SVMGA [72] 2014 Using GA for reduce the number of  dimensions

>> Tokens are: 
 ['SVMGA', '[', '72', ']', '2014', 'Using', 'GA', 'reduce', 'number', 'dimensions']

>> Bigrams are: 
 [('SVMGA', '['), ('[', '72'), ('72', ']'), (']', '2014'), ('2014', 'Using'), ('Using', 'GA'), ('GA', 'reduce'), ('reduce', 'number'), ('number', 'dimensions')]

>> Trigrams are: 
 [('SVMGA', '[', '72'), ('[', '72', ']'), ('72', ']', '2014'), (']', '2014', 'Using'), ('2014', 'Using', 'GA'), ('Using', 'GA', 'reduce'), ('GA', 'reduce', 'number'), ('reduce', 'number', 'dimensions')]

>> POS Tags are: 
 [('SVMGA', 'NNP'), ('[', 'VBD'), ('72', 'CD'), (']', 'NN'), ('2014', 'CD'), ('Using', 'NNP'), ('GA', 'NNP'), ('reduce', 'VB'), ('number', 'NN'), ('dimensions', 'NNS')]

>> Noun Phrases are: 
 ['SVMGA', ']', 'Using GA', 'number dimensions']

>> Named Entities are: 
 [('ORGANIZATION', 'SVMGA')] 

>> Stemming using Porter Stemmer: 
 [('SVMGA', 'svmga'), ('[', '['), ('72', '72'), (']', ']'), ('2014', '2014'), ('Using', 'use'), ('GA', 'ga'), ('reduce', 'reduc'), ('number', 'number'), ('dimensions', 'dimens')]

>> Stemming using Snowball Stemmer: 
 [('SVMGA', 'svmga'), ('[', '['), ('72', '72'), (']', ']'), ('2014', '2014'), ('Using', 'use'), ('GA', 'ga'), ('reduce', 'reduc'), ('number', 'number'), ('dimensions', 'dimens')]

>> Lemmatization: 
 [('SVMGA', 'SVMGA'), ('[', '['), ('72', '72'), (']', ']'), ('2014', '2014'), ('Using', 'Using'), ('GA', 'GA'), ('reduce', 'reduce'), ('number', 'number'), ('dimensions', 'dimension')]



========================================== PARAGRAPH 352 ===========================================

Quantum SVM [116] 2014 Quantum computing for classifica‑ tion 

------------------- Sentence 1 -------------------

Quantum SVM [116] 2014 Quantum computing for classifica‑ tion

>> Tokens are: 
 ['Quantum', 'SVM', '[', '116', ']', '2014', 'Quantum', 'computing', 'classifica‑', 'tion']

>> Bigrams are: 
 [('Quantum', 'SVM'), ('SVM', '['), ('[', '116'), ('116', ']'), (']', '2014'), ('2014', 'Quantum'), ('Quantum', 'computing'), ('computing', 'classifica‑'), ('classifica‑', 'tion')]

>> Trigrams are: 
 [('Quantum', 'SVM', '['), ('SVM', '[', '116'), ('[', '116', ']'), ('116', ']', '2014'), (']', '2014', 'Quantum'), ('2014', 'Quantum', 'computing'), ('Quantum', 'computing', 'classifica‑'), ('computing', 'classifica‑', 'tion')]

>> POS Tags are: 
 [('Quantum', 'NNP'), ('SVM', 'NNP'), ('[', 'VBD'), ('116', 'CD'), (']', 'NN'), ('2014', 'CD'), ('Quantum', 'NNP'), ('computing', 'VBG'), ('classifica‑', 'NN'), ('tion', 'NN')]

>> Noun Phrases are: 
 ['Quantum SVM', ']', 'Quantum', 'classifica‑ tion']

>> Named Entities are: 
 [('PERSON', 'Quantum'), ('ORGANIZATION', 'SVM')] 

>> Stemming using Porter Stemmer: 
 [('Quantum', 'quantum'), ('SVM', 'svm'), ('[', '['), ('116', '116'), (']', ']'), ('2014', '2014'), ('Quantum', 'quantum'), ('computing', 'comput'), ('classifica‑', 'classifica‑'), ('tion', 'tion')]

>> Stemming using Snowball Stemmer: 
 [('Quantum', 'quantum'), ('SVM', 'svm'), ('[', '['), ('116', '116'), (']', ']'), ('2014', '2014'), ('Quantum', 'quantum'), ('computing', 'comput'), ('classifica‑', 'classifica‑'), ('tion', 'tion')]

>> Lemmatization: 
 [('Quantum', 'Quantum'), ('SVM', 'SVM'), ('[', '['), ('116', '116'), (']', ']'), ('2014', '2014'), ('Quantum', 'Quantum'), ('computing', 'computing'), ('classifica‑', 'classifica‑'), ('tion', 'tion')]



========================================== PARAGRAPH 353 ===========================================

DPSP [121] 2010 Applied frequent pattern algorithm  to cloud platform 

------------------- Sentence 1 -------------------

DPSP [121] 2010 Applied frequent pattern algorithm  to cloud platform

>> Tokens are: 
 ['DPSP', '[', '121', ']', '2010', 'Applied', 'frequent', 'pattern', 'algorithm', 'cloud', 'platform']

>> Bigrams are: 
 [('DPSP', '['), ('[', '121'), ('121', ']'), (']', '2010'), ('2010', 'Applied'), ('Applied', 'frequent'), ('frequent', 'pattern'), ('pattern', 'algorithm'), ('algorithm', 'cloud'), ('cloud', 'platform')]

>> Trigrams are: 
 [('DPSP', '[', '121'), ('[', '121', ']'), ('121', ']', '2010'), (']', '2010', 'Applied'), ('2010', 'Applied', 'frequent'), ('Applied', 'frequent', 'pattern'), ('frequent', 'pattern', 'algorithm'), ('pattern', 'algorithm', 'cloud'), ('algorithm', 'cloud', 'platform')]

>> POS Tags are: 
 [('DPSP', 'NNP'), ('[', 'VBD'), ('121', 'CD'), (']', 'JJ'), ('2010', 'CD'), ('Applied', 'NNP'), ('frequent', 'JJ'), ('pattern', 'NN'), ('algorithm', 'JJ'), ('cloud', 'NN'), ('platform', 'NN')]

>> Noun Phrases are: 
 ['DPSP', 'Applied', 'frequent pattern', 'algorithm cloud platform']

>> Named Entities are: 
 [('ORGANIZATION', 'DPSP')] 

>> Stemming using Porter Stemmer: 
 [('DPSP', 'dpsp'), ('[', '['), ('121', '121'), (']', ']'), ('2010', '2010'), ('Applied', 'appli'), ('frequent', 'frequent'), ('pattern', 'pattern'), ('algorithm', 'algorithm'), ('cloud', 'cloud'), ('platform', 'platform')]

>> Stemming using Snowball Stemmer: 
 [('DPSP', 'dpsp'), ('[', '['), ('121', '121'), (']', ']'), ('2010', '2010'), ('Applied', 'appli'), ('frequent', 'frequent'), ('pattern', 'pattern'), ('algorithm', 'algorithm'), ('cloud', 'cloud'), ('platform', 'platform')]

>> Lemmatization: 
 [('DPSP', 'DPSP'), ('[', '['), ('121', '121'), (']', ']'), ('2010', '2010'), ('Applied', 'Applied'), ('frequent', 'frequent'), ('pattern', 'pattern'), ('algorithm', 'algorithm'), ('cloud', 'cloud'), ('platform', 'platform')]



========================================== PARAGRAPH 354 ===========================================

FP 

------------------- Sentence 1 -------------------

FP

>> Tokens are: 
 ['FP']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('FP', 'NN')]

>> Noun Phrases are: 
 ['FP']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('FP', 'fp')]

>> Stemming using Snowball Stemmer: 
 [('FP', 'fp')]

>> Lemmatization: 
 [('FP', 'FP')]



========================================== PARAGRAPH 355 ===========================================

DHTRIE [120] 2011 Applied frequent pattern algorithm  to cloud platform 

------------------- Sentence 1 -------------------

DHTRIE [120] 2011 Applied frequent pattern algorithm  to cloud platform

>> Tokens are: 
 ['DHTRIE', '[', '120', ']', '2011', 'Applied', 'frequent', 'pattern', 'algorithm', 'cloud', 'platform']

>> Bigrams are: 
 [('DHTRIE', '['), ('[', '120'), ('120', ']'), (']', '2011'), ('2011', 'Applied'), ('Applied', 'frequent'), ('frequent', 'pattern'), ('pattern', 'algorithm'), ('algorithm', 'cloud'), ('cloud', 'platform')]

>> Trigrams are: 
 [('DHTRIE', '[', '120'), ('[', '120', ']'), ('120', ']', '2011'), (']', '2011', 'Applied'), ('2011', 'Applied', 'frequent'), ('Applied', 'frequent', 'pattern'), ('frequent', 'pattern', 'algorithm'), ('pattern', 'algorithm', 'cloud'), ('algorithm', 'cloud', 'platform')]

>> POS Tags are: 
 [('DHTRIE', 'NNP'), ('[', 'VBD'), ('120', 'CD'), (']', 'JJ'), ('2011', 'CD'), ('Applied', 'NNP'), ('frequent', 'JJ'), ('pattern', 'NN'), ('algorithm', 'JJ'), ('cloud', 'NN'), ('platform', 'NN')]

>> Noun Phrases are: 
 ['DHTRIE', 'Applied', 'frequent pattern', 'algorithm cloud platform']

>> Named Entities are: 
 [('ORGANIZATION', 'DHTRIE')] 

>> Stemming using Porter Stemmer: 
 [('DHTRIE', 'dhtrie'), ('[', '['), ('120', '120'), (']', ']'), ('2011', '2011'), ('Applied', 'appli'), ('frequent', 'frequent'), ('pattern', 'pattern'), ('algorithm', 'algorithm'), ('cloud', 'cloud'), ('platform', 'platform')]

>> Stemming using Snowball Stemmer: 
 [('DHTRIE', 'dhtrie'), ('[', '['), ('120', '120'), (']', ']'), ('2011', '2011'), ('Applied', 'appli'), ('frequent', 'frequent'), ('pattern', 'pattern'), ('algorithm', 'algorithm'), ('cloud', 'cloud'), ('platform', 'platform')]

>> Lemmatization: 
 [('DHTRIE', 'DHTRIE'), ('[', '['), ('120', '120'), (']', ']'), ('2011', '2011'), ('Applied', 'Applied'), ('frequent', 'frequent'), ('pattern', 'pattern'), ('algorithm', 'algorithm'), ('cloud', 'cloud'), ('platform', 'platform')]



========================================== PARAGRAPH 356 ===========================================

SPC, FPC, and DPC [117] 2012 Map‑reduce model for frequent pat‑ tern mining 

------------------- Sentence 1 -------------------

SPC, FPC, and DPC [117] 2012 Map‑reduce model for frequent pat‑ tern mining

>> Tokens are: 
 ['SPC', ',', 'FPC', ',', 'DPC', '[', '117', ']', '2012', 'Map‑reduce', 'model', 'frequent', 'pat‑', 'tern', 'mining']

>> Bigrams are: 
 [('SPC', ','), (',', 'FPC'), ('FPC', ','), (',', 'DPC'), ('DPC', '['), ('[', '117'), ('117', ']'), (']', '2012'), ('2012', 'Map‑reduce'), ('Map‑reduce', 'model'), ('model', 'frequent'), ('frequent', 'pat‑'), ('pat‑', 'tern'), ('tern', 'mining')]

>> Trigrams are: 
 [('SPC', ',', 'FPC'), (',', 'FPC', ','), ('FPC', ',', 'DPC'), (',', 'DPC', '['), ('DPC', '[', '117'), ('[', '117', ']'), ('117', ']', '2012'), (']', '2012', 'Map‑reduce'), ('2012', 'Map‑reduce', 'model'), ('Map‑reduce', 'model', 'frequent'), ('model', 'frequent', 'pat‑'), ('frequent', 'pat‑', 'tern'), ('pat‑', 'tern', 'mining')]

>> POS Tags are: 
 [('SPC', 'NNP'), (',', ','), ('FPC', 'NNP'), (',', ','), ('DPC', 'NNP'), ('[', 'NNP'), ('117', 'CD'), (']', 'NN'), ('2012', 'CD'), ('Map‑reduce', 'NNP'), ('model', 'FW'), ('frequent', 'JJ'), ('pat‑', 'NN'), ('tern', 'NN'), ('mining', 'NN')]

>> Noun Phrases are: 
 ['SPC', 'FPC', 'DPC [', ']', 'Map‑reduce', 'frequent pat‑ tern mining']

>> Named Entities are: 
 [('ORGANIZATION', 'FPC'), ('ORGANIZATION', 'DPC')] 

>> Stemming using Porter Stemmer: 
 [('SPC', 'spc'), (',', ','), ('FPC', 'fpc'), (',', ','), ('DPC', 'dpc'), ('[', '['), ('117', '117'), (']', ']'), ('2012', '2012'), ('Map‑reduce', 'map‑reduc'), ('model', 'model'), ('frequent', 'frequent'), ('pat‑', 'pat‑'), ('tern', 'tern'), ('mining', 'mine')]

>> Stemming using Snowball Stemmer: 
 [('SPC', 'spc'), (',', ','), ('FPC', 'fpc'), (',', ','), ('DPC', 'dpc'), ('[', '['), ('117', '117'), (']', ']'), ('2012', '2012'), ('Map‑reduce', 'map‑reduc'), ('model', 'model'), ('frequent', 'frequent'), ('pat‑', 'pat‑'), ('tern', 'tern'), ('mining', 'mine')]

>> Lemmatization: 
 [('SPC', 'SPC'), (',', ','), ('FPC', 'FPC'), (',', ','), ('DPC', 'DPC'), ('[', '['), ('117', '117'), (']', ']'), ('2012', '2012'), ('Map‑reduce', 'Map‑reduce'), ('model', 'model'), ('frequent', 'frequent'), ('pat‑', 'pat‑'), ('tern', 'tern'), ('mining', 'mining')]



========================================== PARAGRAPH 357 ===========================================

MFPSAM [119] 2014 Concerned the specific interest con‑ straints and applied map‑reduce  model

------------------- Sentence 1 -------------------

MFPSAM [119] 2014 Concerned the specific interest con‑ straints and applied map‑reduce  model

>> Tokens are: 
 ['MFPSAM', '[', '119', ']', '2014', 'Concerned', 'specific', 'interest', 'con‑', 'straints', 'applied', 'map‑reduce', 'model']

>> Bigrams are: 
 [('MFPSAM', '['), ('[', '119'), ('119', ']'), (']', '2014'), ('2014', 'Concerned'), ('Concerned', 'specific'), ('specific', 'interest'), ('interest', 'con‑'), ('con‑', 'straints'), ('straints', 'applied'), ('applied', 'map‑reduce'), ('map‑reduce', 'model')]

>> Trigrams are: 
 [('MFPSAM', '[', '119'), ('[', '119', ']'), ('119', ']', '2014'), (']', '2014', 'Concerned'), ('2014', 'Concerned', 'specific'), ('Concerned', 'specific', 'interest'), ('specific', 'interest', 'con‑'), ('interest', 'con‑', 'straints'), ('con‑', 'straints', 'applied'), ('straints', 'applied', 'map‑reduce'), ('applied', 'map‑reduce', 'model')]

>> POS Tags are: 
 [('MFPSAM', 'NNP'), ('[', 'VBD'), ('119', 'CD'), (']', 'JJ'), ('2014', 'CD'), ('Concerned', 'JJ'), ('specific', 'JJ'), ('interest', 'NN'), ('con‑', 'NN'), ('straints', 'NNS'), ('applied', 'VBN'), ('map‑reduce', 'VBP'), ('model', 'NN')]

>> Noun Phrases are: 
 ['MFPSAM', 'Concerned specific interest con‑ straints', 'model']

>> Named Entities are: 
 [('ORGANIZATION', 'MFPSAM')] 

>> Stemming using Porter Stemmer: 
 [('MFPSAM', 'mfpsam'), ('[', '['), ('119', '119'), (']', ']'), ('2014', '2014'), ('Concerned', 'concern'), ('specific', 'specif'), ('interest', 'interest'), ('con‑', 'con‑'), ('straints', 'straint'), ('applied', 'appli'), ('map‑reduce', 'map‑reduc'), ('model', 'model')]

>> Stemming using Snowball Stemmer: 
 [('MFPSAM', 'mfpsam'), ('[', '['), ('119', '119'), (']', ']'), ('2014', '2014'), ('Concerned', 'concern'), ('specific', 'specif'), ('interest', 'interest'), ('con‑', 'con‑'), ('straints', 'straint'), ('applied', 'appli'), ('map‑reduce', 'map‑reduc'), ('model', 'model')]

>> Lemmatization: 
 [('MFPSAM', 'MFPSAM'), ('[', '['), ('119', '119'), (']', ']'), ('2014', '2014'), ('Concerned', 'Concerned'), ('specific', 'specific'), ('interest', 'interest'), ('con‑', 'con‑'), ('straints', 'straints'), ('applied', 'applied'), ('map‑reduce', 'map‑reduce'), ('model', 'model')]



========================================== PARAGRAPH 358 ===========================================

Page 23 of 32Tsai et al. Journal of Big Data  (2015) 2:21  

------------------- Sentence 1 -------------------

Page 23 of 32Tsai et al.

>> Tokens are: 
 ['Page', '23', '32Tsai', 'et', 'al', '.']

>> Bigrams are: 
 [('Page', '23'), ('23', '32Tsai'), ('32Tsai', 'et'), ('et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('Page', '23', '32Tsai'), ('23', '32Tsai', 'et'), ('32Tsai', 'et', 'al'), ('et', 'al', '.')]

>> POS Tags are: 
 [('Page', 'NN'), ('23', 'CD'), ('32Tsai', 'CD'), ('et', 'NN'), ('al', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Page', 'et al']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Page', 'page'), ('23', '23'), ('32Tsai', '32tsai'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Page', 'page'), ('23', '23'), ('32Tsai', '32tsai'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('Page', 'Page'), ('23', '23'), ('32Tsai', '32Tsai'), ('et', 'et'), ('al', 'al'), ('.', '.')]


------------------- Sentence 2 -------------------

Journal of Big Data  (2015) 2:21

>> Tokens are: 
 ['Journal', 'Big', 'Data', '(', '2015', ')', '2:21']

>> Bigrams are: 
 [('Journal', 'Big'), ('Big', 'Data'), ('Data', '('), ('(', '2015'), ('2015', ')'), (')', '2:21')]

>> Trigrams are: 
 [('Journal', 'Big', 'Data'), ('Big', 'Data', '('), ('Data', '(', '2015'), ('(', '2015', ')'), ('2015', ')', '2:21')]

>> POS Tags are: 
 [('Journal', 'NNP'), ('Big', 'NNP'), ('Data', 'NNP'), ('(', '('), ('2015', 'CD'), (')', ')'), ('2:21', 'CD')]

>> Noun Phrases are: 
 ['Journal Big Data']

>> Named Entities are: 
 [('PERSON', 'Journal')] 

>> Stemming using Porter Stemmer: 
 [('Journal', 'journal'), ('Big', 'big'), ('Data', 'data'), ('(', '('), ('2015', '2015'), (')', ')'), ('2:21', '2:21')]

>> Stemming using Snowball Stemmer: 
 [('Journal', 'journal'), ('Big', 'big'), ('Data', 'data'), ('(', '('), ('2015', '2015'), (')', ')'), ('2:21', '2:21')]

>> Lemmatization: 
 [('Journal', 'Journal'), ('Big', 'Big'), ('Data', 'Data'), ('(', '('), ('2015', '2015'), (')', ')'), ('2:21', '2:21')]



========================================== PARAGRAPH 359 ===========================================

make the mining algorithms and relevant platforms smarter or reduce the redundant  computation costs. That parallel computing and cloud computing technologies have a  strong impact on the big data analytics can also be recognized as follows: (1) most of  the big data analytics frameworks and platforms are using Hadoop and Hadoop relevant  technologies to design their solutions; and (2) most of the mining algorithms for big data  analysis have been designed for parallel computing via software or hardware or designed  for Map-Reduce-based platform. 

------------------- Sentence 1 -------------------

make the mining algorithms and relevant platforms smarter or reduce the redundant  computation costs.

>> Tokens are: 
 ['make', 'mining', 'algorithms', 'relevant', 'platforms', 'smarter', 'reduce', 'redundant', 'computation', 'costs', '.']

>> Bigrams are: 
 [('make', 'mining'), ('mining', 'algorithms'), ('algorithms', 'relevant'), ('relevant', 'platforms'), ('platforms', 'smarter'), ('smarter', 'reduce'), ('reduce', 'redundant'), ('redundant', 'computation'), ('computation', 'costs'), ('costs', '.')]

>> Trigrams are: 
 [('make', 'mining', 'algorithms'), ('mining', 'algorithms', 'relevant'), ('algorithms', 'relevant', 'platforms'), ('relevant', 'platforms', 'smarter'), ('platforms', 'smarter', 'reduce'), ('smarter', 'reduce', 'redundant'), ('reduce', 'redundant', 'computation'), ('redundant', 'computation', 'costs'), ('computation', 'costs', '.')]

>> POS Tags are: 
 [('make', 'VB'), ('mining', 'NN'), ('algorithms', 'NN'), ('relevant', 'JJ'), ('platforms', 'NNS'), ('smarter', 'VBP'), ('reduce', 'VB'), ('redundant', 'JJ'), ('computation', 'NN'), ('costs', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['mining algorithms', 'relevant platforms', 'redundant computation costs']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('make', 'make'), ('mining', 'mine'), ('algorithms', 'algorithm'), ('relevant', 'relev'), ('platforms', 'platform'), ('smarter', 'smarter'), ('reduce', 'reduc'), ('redundant', 'redund'), ('computation', 'comput'), ('costs', 'cost'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('make', 'make'), ('mining', 'mine'), ('algorithms', 'algorithm'), ('relevant', 'relev'), ('platforms', 'platform'), ('smarter', 'smarter'), ('reduce', 'reduc'), ('redundant', 'redund'), ('computation', 'comput'), ('costs', 'cost'), ('.', '.')]

>> Lemmatization: 
 [('make', 'make'), ('mining', 'mining'), ('algorithms', 'algorithm'), ('relevant', 'relevant'), ('platforms', 'platform'), ('smarter', 'smarter'), ('reduce', 'reduce'), ('redundant', 'redundant'), ('computation', 'computation'), ('costs', 'cost'), ('.', '.')]


------------------- Sentence 2 -------------------

That parallel computing and cloud computing technologies have a  strong impact on the big data analytics can also be recognized as follows: (1) most of  the big data analytics frameworks and platforms are using Hadoop and Hadoop relevant  technologies to design their solutions; and (2) most of the mining algorithms for big data  analysis have been designed for parallel computing via software or hardware or designed  for Map-Reduce-based platform.

>> Tokens are: 
 ['That', 'parallel', 'computing', 'cloud', 'computing', 'technologies', 'strong', 'impact', 'big', 'data', 'analytics', 'also', 'recognized', 'follows', ':', '(', '1', ')', 'big', 'data', 'analytics', 'frameworks', 'platforms', 'using', 'Hadoop', 'Hadoop', 'relevant', 'technologies', 'design', 'solutions', ';', '(', '2', ')', 'mining', 'algorithms', 'big', 'data', 'analysis', 'designed', 'parallel', 'computing', 'via', 'software', 'hardware', 'designed', 'Map-Reduce-based', 'platform', '.']

>> Bigrams are: 
 [('That', 'parallel'), ('parallel', 'computing'), ('computing', 'cloud'), ('cloud', 'computing'), ('computing', 'technologies'), ('technologies', 'strong'), ('strong', 'impact'), ('impact', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', 'also'), ('also', 'recognized'), ('recognized', 'follows'), ('follows', ':'), (':', '('), ('(', '1'), ('1', ')'), (')', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', 'frameworks'), ('frameworks', 'platforms'), ('platforms', 'using'), ('using', 'Hadoop'), ('Hadoop', 'Hadoop'), ('Hadoop', 'relevant'), ('relevant', 'technologies'), ('technologies', 'design'), ('design', 'solutions'), ('solutions', ';'), (';', '('), ('(', '2'), ('2', ')'), (')', 'mining'), ('mining', 'algorithms'), ('algorithms', 'big'), ('big', 'data'), ('data', 'analysis'), ('analysis', 'designed'), ('designed', 'parallel'), ('parallel', 'computing'), ('computing', 'via'), ('via', 'software'), ('software', 'hardware'), ('hardware', 'designed'), ('designed', 'Map-Reduce-based'), ('Map-Reduce-based', 'platform'), ('platform', '.')]

>> Trigrams are: 
 [('That', 'parallel', 'computing'), ('parallel', 'computing', 'cloud'), ('computing', 'cloud', 'computing'), ('cloud', 'computing', 'technologies'), ('computing', 'technologies', 'strong'), ('technologies', 'strong', 'impact'), ('strong', 'impact', 'big'), ('impact', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', 'also'), ('analytics', 'also', 'recognized'), ('also', 'recognized', 'follows'), ('recognized', 'follows', ':'), ('follows', ':', '('), (':', '(', '1'), ('(', '1', ')'), ('1', ')', 'big'), (')', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', 'frameworks'), ('analytics', 'frameworks', 'platforms'), ('frameworks', 'platforms', 'using'), ('platforms', 'using', 'Hadoop'), ('using', 'Hadoop', 'Hadoop'), ('Hadoop', 'Hadoop', 'relevant'), ('Hadoop', 'relevant', 'technologies'), ('relevant', 'technologies', 'design'), ('technologies', 'design', 'solutions'), ('design', 'solutions', ';'), ('solutions', ';', '('), (';', '(', '2'), ('(', '2', ')'), ('2', ')', 'mining'), (')', 'mining', 'algorithms'), ('mining', 'algorithms', 'big'), ('algorithms', 'big', 'data'), ('big', 'data', 'analysis'), ('data', 'analysis', 'designed'), ('analysis', 'designed', 'parallel'), ('designed', 'parallel', 'computing'), ('parallel', 'computing', 'via'), ('computing', 'via', 'software'), ('via', 'software', 'hardware'), ('software', 'hardware', 'designed'), ('hardware', 'designed', 'Map-Reduce-based'), ('designed', 'Map-Reduce-based', 'platform'), ('Map-Reduce-based', 'platform', '.')]

>> POS Tags are: 
 [('That', 'DT'), ('parallel', 'VBD'), ('computing', 'VBG'), ('cloud', 'JJ'), ('computing', 'VBG'), ('technologies', 'NNS'), ('strong', 'JJ'), ('impact', 'NN'), ('big', 'JJ'), ('data', 'NN'), ('analytics', 'NNS'), ('also', 'RB'), ('recognized', 'VBN'), ('follows', 'VBZ'), (':', ':'), ('(', '('), ('1', 'CD'), (')', ')'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('frameworks', 'NNS'), ('platforms', 'NNS'), ('using', 'VBG'), ('Hadoop', 'NNP'), ('Hadoop', 'NNP'), ('relevant', 'JJ'), ('technologies', 'NNS'), ('design', 'VBP'), ('solutions', 'NNS'), (';', ':'), ('(', '('), ('2', 'CD'), (')', ')'), ('mining', 'NN'), ('algorithms', 'JJ'), ('big', 'JJ'), ('data', 'NNS'), ('analysis', 'NN'), ('designed', 'VBN'), ('parallel', 'JJ'), ('computing', 'VBG'), ('via', 'IN'), ('software', 'NN'), ('hardware', 'NN'), ('designed', 'VBN'), ('Map-Reduce-based', 'JJ'), ('platform', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['technologies', 'strong impact', 'big data analytics', 'big data analytics frameworks platforms', 'Hadoop Hadoop', 'relevant technologies', 'solutions', 'mining', 'algorithms big data analysis', 'software hardware', 'Map-Reduce-based platform']

>> Named Entities are: 
 [('PERSON', 'Hadoop Hadoop')] 

>> Stemming using Porter Stemmer: 
 [('That', 'that'), ('parallel', 'parallel'), ('computing', 'comput'), ('cloud', 'cloud'), ('computing', 'comput'), ('technologies', 'technolog'), ('strong', 'strong'), ('impact', 'impact'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('also', 'also'), ('recognized', 'recogn'), ('follows', 'follow'), (':', ':'), ('(', '('), ('1', '1'), (')', ')'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('frameworks', 'framework'), ('platforms', 'platform'), ('using', 'use'), ('Hadoop', 'hadoop'), ('Hadoop', 'hadoop'), ('relevant', 'relev'), ('technologies', 'technolog'), ('design', 'design'), ('solutions', 'solut'), (';', ';'), ('(', '('), ('2', '2'), (')', ')'), ('mining', 'mine'), ('algorithms', 'algorithm'), ('big', 'big'), ('data', 'data'), ('analysis', 'analysi'), ('designed', 'design'), ('parallel', 'parallel'), ('computing', 'comput'), ('via', 'via'), ('software', 'softwar'), ('hardware', 'hardwar'), ('designed', 'design'), ('Map-Reduce-based', 'map-reduce-bas'), ('platform', 'platform'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('That', 'that'), ('parallel', 'parallel'), ('computing', 'comput'), ('cloud', 'cloud'), ('computing', 'comput'), ('technologies', 'technolog'), ('strong', 'strong'), ('impact', 'impact'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('also', 'also'), ('recognized', 'recogn'), ('follows', 'follow'), (':', ':'), ('(', '('), ('1', '1'), (')', ')'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('frameworks', 'framework'), ('platforms', 'platform'), ('using', 'use'), ('Hadoop', 'hadoop'), ('Hadoop', 'hadoop'), ('relevant', 'relev'), ('technologies', 'technolog'), ('design', 'design'), ('solutions', 'solut'), (';', ';'), ('(', '('), ('2', '2'), (')', ')'), ('mining', 'mine'), ('algorithms', 'algorithm'), ('big', 'big'), ('data', 'data'), ('analysis', 'analysi'), ('designed', 'design'), ('parallel', 'parallel'), ('computing', 'comput'), ('via', 'via'), ('software', 'softwar'), ('hardware', 'hardwar'), ('designed', 'design'), ('Map-Reduce-based', 'map-reduce-bas'), ('platform', 'platform'), ('.', '.')]

>> Lemmatization: 
 [('That', 'That'), ('parallel', 'parallel'), ('computing', 'computing'), ('cloud', 'cloud'), ('computing', 'computing'), ('technologies', 'technology'), ('strong', 'strong'), ('impact', 'impact'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('also', 'also'), ('recognized', 'recognized'), ('follows', 'follows'), (':', ':'), ('(', '('), ('1', '1'), (')', ')'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('frameworks', 'framework'), ('platforms', 'platform'), ('using', 'using'), ('Hadoop', 'Hadoop'), ('Hadoop', 'Hadoop'), ('relevant', 'relevant'), ('technologies', 'technology'), ('design', 'design'), ('solutions', 'solution'), (';', ';'), ('(', '('), ('2', '2'), (')', ')'), ('mining', 'mining'), ('algorithms', 'algorithm'), ('big', 'big'), ('data', 'data'), ('analysis', 'analysis'), ('designed', 'designed'), ('parallel', 'parallel'), ('computing', 'computing'), ('via', 'via'), ('software', 'software'), ('hardware', 'hardware'), ('designed', 'designed'), ('Map-Reduce-based', 'Map-Reduce-based'), ('platform', 'platform'), ('.', '.')]



========================================== PARAGRAPH 360 ===========================================

From the results of recent studies of big data analytics, it is still at the early stage of  Nolan’s stages of growth model [146] which is similar to the situations for the research  topics of cloud computing, internet of things, and smart grid. This is because several  studies just attempted to apply the traditional solutions to the new problems/platforms/ environments. For example, several studies [114, 145] used k-means as an example to  analyze the big data, but not many studies applied the state-of-the-art data mining algo- rithms and machine learning algorithms to the analysis the big data. This explains that  the performance of the big data analytics can be improved by data mining algorithms  and metaheuristic algorithms presented in recent years [147]. The relevant technologies  for compression, sampling, or even the platform presented in recent years may also be  used to enhance the performance of the big data analytics system. As a result, although  these research topics still have several open issues that need to be solved, these situa- tions, on the contrary, also illustrate that everything is possible in these studies. 

------------------- Sentence 1 -------------------

From the results of recent studies of big data analytics, it is still at the early stage of  Nolan’s stages of growth model [146] which is similar to the situations for the research  topics of cloud computing, internet of things, and smart grid.

>> Tokens are: 
 ['From', 'results', 'recent', 'studies', 'big', 'data', 'analytics', ',', 'still', 'early', 'stage', 'Nolan', '’', 'stages', 'growth', 'model', '[', '146', ']', 'similar', 'situations', 'research', 'topics', 'cloud', 'computing', ',', 'internet', 'things', ',', 'smart', 'grid', '.']

>> Bigrams are: 
 [('From', 'results'), ('results', 'recent'), ('recent', 'studies'), ('studies', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', ','), (',', 'still'), ('still', 'early'), ('early', 'stage'), ('stage', 'Nolan'), ('Nolan', '’'), ('’', 'stages'), ('stages', 'growth'), ('growth', 'model'), ('model', '['), ('[', '146'), ('146', ']'), (']', 'similar'), ('similar', 'situations'), ('situations', 'research'), ('research', 'topics'), ('topics', 'cloud'), ('cloud', 'computing'), ('computing', ','), (',', 'internet'), ('internet', 'things'), ('things', ','), (',', 'smart'), ('smart', 'grid'), ('grid', '.')]

>> Trigrams are: 
 [('From', 'results', 'recent'), ('results', 'recent', 'studies'), ('recent', 'studies', 'big'), ('studies', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', ','), ('analytics', ',', 'still'), (',', 'still', 'early'), ('still', 'early', 'stage'), ('early', 'stage', 'Nolan'), ('stage', 'Nolan', '’'), ('Nolan', '’', 'stages'), ('’', 'stages', 'growth'), ('stages', 'growth', 'model'), ('growth', 'model', '['), ('model', '[', '146'), ('[', '146', ']'), ('146', ']', 'similar'), (']', 'similar', 'situations'), ('similar', 'situations', 'research'), ('situations', 'research', 'topics'), ('research', 'topics', 'cloud'), ('topics', 'cloud', 'computing'), ('cloud', 'computing', ','), ('computing', ',', 'internet'), (',', 'internet', 'things'), ('internet', 'things', ','), ('things', ',', 'smart'), (',', 'smart', 'grid'), ('smart', 'grid', '.')]

>> POS Tags are: 
 [('From', 'IN'), ('results', 'NNS'), ('recent', 'JJ'), ('studies', 'NNS'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), (',', ','), ('still', 'RB'), ('early', 'JJ'), ('stage', 'NN'), ('Nolan', 'NNP'), ('’', 'NNP'), ('stages', 'VBZ'), ('growth', 'NN'), ('model', 'NN'), ('[', 'VBZ'), ('146', 'CD'), (']', 'NN'), ('similar', 'JJ'), ('situations', 'NNS'), ('research', 'NN'), ('topics', 'NNS'), ('cloud', 'VBP'), ('computing', 'VBG'), (',', ','), ('internet', 'JJ'), ('things', 'NNS'), (',', ','), ('smart', 'JJ'), ('grid', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['results', 'recent studies', 'big data analytics', 'early stage Nolan ’', 'growth model', ']', 'similar situations research topics', 'internet things', 'smart grid']

>> Named Entities are: 
 [('PERSON', 'Nolan')] 

>> Stemming using Porter Stemmer: 
 [('From', 'from'), ('results', 'result'), ('recent', 'recent'), ('studies', 'studi'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), (',', ','), ('still', 'still'), ('early', 'earli'), ('stage', 'stage'), ('Nolan', 'nolan'), ('’', '’'), ('stages', 'stage'), ('growth', 'growth'), ('model', 'model'), ('[', '['), ('146', '146'), (']', ']'), ('similar', 'similar'), ('situations', 'situat'), ('research', 'research'), ('topics', 'topic'), ('cloud', 'cloud'), ('computing', 'comput'), (',', ','), ('internet', 'internet'), ('things', 'thing'), (',', ','), ('smart', 'smart'), ('grid', 'grid'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('From', 'from'), ('results', 'result'), ('recent', 'recent'), ('studies', 'studi'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), (',', ','), ('still', 'still'), ('early', 'earli'), ('stage', 'stage'), ('Nolan', 'nolan'), ('’', '’'), ('stages', 'stage'), ('growth', 'growth'), ('model', 'model'), ('[', '['), ('146', '146'), (']', ']'), ('similar', 'similar'), ('situations', 'situat'), ('research', 'research'), ('topics', 'topic'), ('cloud', 'cloud'), ('computing', 'comput'), (',', ','), ('internet', 'internet'), ('things', 'thing'), (',', ','), ('smart', 'smart'), ('grid', 'grid'), ('.', '.')]

>> Lemmatization: 
 [('From', 'From'), ('results', 'result'), ('recent', 'recent'), ('studies', 'study'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), (',', ','), ('still', 'still'), ('early', 'early'), ('stage', 'stage'), ('Nolan', 'Nolan'), ('’', '’'), ('stages', 'stage'), ('growth', 'growth'), ('model', 'model'), ('[', '['), ('146', '146'), (']', ']'), ('similar', 'similar'), ('situations', 'situation'), ('research', 'research'), ('topics', 'topic'), ('cloud', 'cloud'), ('computing', 'computing'), (',', ','), ('internet', 'internet'), ('things', 'thing'), (',', ','), ('smart', 'smart'), ('grid', 'grid'), ('.', '.')]


------------------- Sentence 2 -------------------

This is because several  studies just attempted to apply the traditional solutions to the new problems/platforms/ environments.

>> Tokens are: 
 ['This', 'several', 'studies', 'attempted', 'apply', 'traditional', 'solutions', 'new', 'problems/platforms/', 'environments', '.']

>> Bigrams are: 
 [('This', 'several'), ('several', 'studies'), ('studies', 'attempted'), ('attempted', 'apply'), ('apply', 'traditional'), ('traditional', 'solutions'), ('solutions', 'new'), ('new', 'problems/platforms/'), ('problems/platforms/', 'environments'), ('environments', '.')]

>> Trigrams are: 
 [('This', 'several', 'studies'), ('several', 'studies', 'attempted'), ('studies', 'attempted', 'apply'), ('attempted', 'apply', 'traditional'), ('apply', 'traditional', 'solutions'), ('traditional', 'solutions', 'new'), ('solutions', 'new', 'problems/platforms/'), ('new', 'problems/platforms/', 'environments'), ('problems/platforms/', 'environments', '.')]

>> POS Tags are: 
 [('This', 'DT'), ('several', 'JJ'), ('studies', 'NNS'), ('attempted', 'VBD'), ('apply', 'JJ'), ('traditional', 'JJ'), ('solutions', 'NNS'), ('new', 'JJ'), ('problems/platforms/', 'JJ'), ('environments', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['This several studies', 'apply traditional solutions', 'new problems/platforms/ environments']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('This', 'thi'), ('several', 'sever'), ('studies', 'studi'), ('attempted', 'attempt'), ('apply', 'appli'), ('traditional', 'tradit'), ('solutions', 'solut'), ('new', 'new'), ('problems/platforms/', 'problems/platforms/'), ('environments', 'environ'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('This', 'this'), ('several', 'sever'), ('studies', 'studi'), ('attempted', 'attempt'), ('apply', 'appli'), ('traditional', 'tradit'), ('solutions', 'solut'), ('new', 'new'), ('problems/platforms/', 'problems/platforms/'), ('environments', 'environ'), ('.', '.')]

>> Lemmatization: 
 [('This', 'This'), ('several', 'several'), ('studies', 'study'), ('attempted', 'attempted'), ('apply', 'apply'), ('traditional', 'traditional'), ('solutions', 'solution'), ('new', 'new'), ('problems/platforms/', 'problems/platforms/'), ('environments', 'environment'), ('.', '.')]


------------------- Sentence 3 -------------------

For example, several studies [114, 145] used k-means as an example to  analyze the big data, but not many studies applied the state-of-the-art data mining algo- rithms and machine learning algorithms to the analysis the big data.

>> Tokens are: 
 ['For', 'example', ',', 'several', 'studies', '[', '114', ',', '145', ']', 'used', 'k-means', 'example', 'analyze', 'big', 'data', ',', 'many', 'studies', 'applied', 'state-of-the-art', 'data', 'mining', 'algo-', 'rithms', 'machine', 'learning', 'algorithms', 'analysis', 'big', 'data', '.']

>> Bigrams are: 
 [('For', 'example'), ('example', ','), (',', 'several'), ('several', 'studies'), ('studies', '['), ('[', '114'), ('114', ','), (',', '145'), ('145', ']'), (']', 'used'), ('used', 'k-means'), ('k-means', 'example'), ('example', 'analyze'), ('analyze', 'big'), ('big', 'data'), ('data', ','), (',', 'many'), ('many', 'studies'), ('studies', 'applied'), ('applied', 'state-of-the-art'), ('state-of-the-art', 'data'), ('data', 'mining'), ('mining', 'algo-'), ('algo-', 'rithms'), ('rithms', 'machine'), ('machine', 'learning'), ('learning', 'algorithms'), ('algorithms', 'analysis'), ('analysis', 'big'), ('big', 'data'), ('data', '.')]

>> Trigrams are: 
 [('For', 'example', ','), ('example', ',', 'several'), (',', 'several', 'studies'), ('several', 'studies', '['), ('studies', '[', '114'), ('[', '114', ','), ('114', ',', '145'), (',', '145', ']'), ('145', ']', 'used'), (']', 'used', 'k-means'), ('used', 'k-means', 'example'), ('k-means', 'example', 'analyze'), ('example', 'analyze', 'big'), ('analyze', 'big', 'data'), ('big', 'data', ','), ('data', ',', 'many'), (',', 'many', 'studies'), ('many', 'studies', 'applied'), ('studies', 'applied', 'state-of-the-art'), ('applied', 'state-of-the-art', 'data'), ('state-of-the-art', 'data', 'mining'), ('data', 'mining', 'algo-'), ('mining', 'algo-', 'rithms'), ('algo-', 'rithms', 'machine'), ('rithms', 'machine', 'learning'), ('machine', 'learning', 'algorithms'), ('learning', 'algorithms', 'analysis'), ('algorithms', 'analysis', 'big'), ('analysis', 'big', 'data'), ('big', 'data', '.')]

>> POS Tags are: 
 [('For', 'IN'), ('example', 'NN'), (',', ','), ('several', 'JJ'), ('studies', 'NNS'), ('[', 'VBP'), ('114', 'CD'), (',', ','), ('145', 'CD'), (']', 'NNS'), ('used', 'VBN'), ('k-means', 'NNS'), ('example', 'NN'), ('analyze', 'VBP'), ('big', 'JJ'), ('data', 'NNS'), (',', ','), ('many', 'JJ'), ('studies', 'NNS'), ('applied', 'VBD'), ('state-of-the-art', 'JJ'), ('data', 'NNS'), ('mining', 'VBG'), ('algo-', 'JJ'), ('rithms', 'NN'), ('machine', 'NN'), ('learning', 'VBG'), ('algorithms', 'JJ'), ('analysis', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['example', 'several studies', ']', 'k-means example', 'big data', 'many studies', 'state-of-the-art data', 'algo- rithms machine', 'algorithms analysis', 'big data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('For', 'for'), ('example', 'exampl'), (',', ','), ('several', 'sever'), ('studies', 'studi'), ('[', '['), ('114', '114'), (',', ','), ('145', '145'), (']', ']'), ('used', 'use'), ('k-means', 'k-mean'), ('example', 'exampl'), ('analyze', 'analyz'), ('big', 'big'), ('data', 'data'), (',', ','), ('many', 'mani'), ('studies', 'studi'), ('applied', 'appli'), ('state-of-the-art', 'state-of-the-art'), ('data', 'data'), ('mining', 'mine'), ('algo-', 'algo-'), ('rithms', 'rithm'), ('machine', 'machin'), ('learning', 'learn'), ('algorithms', 'algorithm'), ('analysis', 'analysi'), ('big', 'big'), ('data', 'data'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('For', 'for'), ('example', 'exampl'), (',', ','), ('several', 'sever'), ('studies', 'studi'), ('[', '['), ('114', '114'), (',', ','), ('145', '145'), (']', ']'), ('used', 'use'), ('k-means', 'k-mean'), ('example', 'exampl'), ('analyze', 'analyz'), ('big', 'big'), ('data', 'data'), (',', ','), ('many', 'mani'), ('studies', 'studi'), ('applied', 'appli'), ('state-of-the-art', 'state-of-the-art'), ('data', 'data'), ('mining', 'mine'), ('algo-', 'algo-'), ('rithms', 'rithm'), ('machine', 'machin'), ('learning', 'learn'), ('algorithms', 'algorithm'), ('analysis', 'analysi'), ('big', 'big'), ('data', 'data'), ('.', '.')]

>> Lemmatization: 
 [('For', 'For'), ('example', 'example'), (',', ','), ('several', 'several'), ('studies', 'study'), ('[', '['), ('114', '114'), (',', ','), ('145', '145'), (']', ']'), ('used', 'used'), ('k-means', 'k-means'), ('example', 'example'), ('analyze', 'analyze'), ('big', 'big'), ('data', 'data'), (',', ','), ('many', 'many'), ('studies', 'study'), ('applied', 'applied'), ('state-of-the-art', 'state-of-the-art'), ('data', 'data'), ('mining', 'mining'), ('algo-', 'algo-'), ('rithms', 'rithms'), ('machine', 'machine'), ('learning', 'learning'), ('algorithms', 'algorithm'), ('analysis', 'analysis'), ('big', 'big'), ('data', 'data'), ('.', '.')]


------------------- Sentence 4 -------------------

This explains that  the performance of the big data analytics can be improved by data mining algorithms  and metaheuristic algorithms presented in recent years [147].

>> Tokens are: 
 ['This', 'explains', 'performance', 'big', 'data', 'analytics', 'improved', 'data', 'mining', 'algorithms', 'metaheuristic', 'algorithms', 'presented', 'recent', 'years', '[', '147', ']', '.']

>> Bigrams are: 
 [('This', 'explains'), ('explains', 'performance'), ('performance', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', 'improved'), ('improved', 'data'), ('data', 'mining'), ('mining', 'algorithms'), ('algorithms', 'metaheuristic'), ('metaheuristic', 'algorithms'), ('algorithms', 'presented'), ('presented', 'recent'), ('recent', 'years'), ('years', '['), ('[', '147'), ('147', ']'), (']', '.')]

>> Trigrams are: 
 [('This', 'explains', 'performance'), ('explains', 'performance', 'big'), ('performance', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', 'improved'), ('analytics', 'improved', 'data'), ('improved', 'data', 'mining'), ('data', 'mining', 'algorithms'), ('mining', 'algorithms', 'metaheuristic'), ('algorithms', 'metaheuristic', 'algorithms'), ('metaheuristic', 'algorithms', 'presented'), ('algorithms', 'presented', 'recent'), ('presented', 'recent', 'years'), ('recent', 'years', '['), ('years', '[', '147'), ('[', '147', ']'), ('147', ']', '.')]

>> POS Tags are: 
 [('This', 'DT'), ('explains', 'VBZ'), ('performance', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('improved', 'VBN'), ('data', 'NNS'), ('mining', 'NN'), ('algorithms', 'JJ'), ('metaheuristic', 'JJ'), ('algorithms', 'NN'), ('presented', 'VBN'), ('recent', 'JJ'), ('years', 'NNS'), ('[', 'VBP'), ('147', 'CD'), (']', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['performance', 'big data analytics', 'data mining', 'algorithms metaheuristic algorithms', 'recent years', ']']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('This', 'thi'), ('explains', 'explain'), ('performance', 'perform'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('improved', 'improv'), ('data', 'data'), ('mining', 'mine'), ('algorithms', 'algorithm'), ('metaheuristic', 'metaheurist'), ('algorithms', 'algorithm'), ('presented', 'present'), ('recent', 'recent'), ('years', 'year'), ('[', '['), ('147', '147'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('This', 'this'), ('explains', 'explain'), ('performance', 'perform'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('improved', 'improv'), ('data', 'data'), ('mining', 'mine'), ('algorithms', 'algorithm'), ('metaheuristic', 'metaheurist'), ('algorithms', 'algorithm'), ('presented', 'present'), ('recent', 'recent'), ('years', 'year'), ('[', '['), ('147', '147'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('This', 'This'), ('explains', 'explains'), ('performance', 'performance'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('improved', 'improved'), ('data', 'data'), ('mining', 'mining'), ('algorithms', 'algorithm'), ('metaheuristic', 'metaheuristic'), ('algorithms', 'algorithm'), ('presented', 'presented'), ('recent', 'recent'), ('years', 'year'), ('[', '['), ('147', '147'), (']', ']'), ('.', '.')]


------------------- Sentence 5 -------------------

The relevant technologies  for compression, sampling, or even the platform presented in recent years may also be  used to enhance the performance of the big data analytics system.

>> Tokens are: 
 ['The', 'relevant', 'technologies', 'compression', ',', 'sampling', ',', 'even', 'platform', 'presented', 'recent', 'years', 'may', 'also', 'used', 'enhance', 'performance', 'big', 'data', 'analytics', 'system', '.']

>> Bigrams are: 
 [('The', 'relevant'), ('relevant', 'technologies'), ('technologies', 'compression'), ('compression', ','), (',', 'sampling'), ('sampling', ','), (',', 'even'), ('even', 'platform'), ('platform', 'presented'), ('presented', 'recent'), ('recent', 'years'), ('years', 'may'), ('may', 'also'), ('also', 'used'), ('used', 'enhance'), ('enhance', 'performance'), ('performance', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', 'system'), ('system', '.')]

>> Trigrams are: 
 [('The', 'relevant', 'technologies'), ('relevant', 'technologies', 'compression'), ('technologies', 'compression', ','), ('compression', ',', 'sampling'), (',', 'sampling', ','), ('sampling', ',', 'even'), (',', 'even', 'platform'), ('even', 'platform', 'presented'), ('platform', 'presented', 'recent'), ('presented', 'recent', 'years'), ('recent', 'years', 'may'), ('years', 'may', 'also'), ('may', 'also', 'used'), ('also', 'used', 'enhance'), ('used', 'enhance', 'performance'), ('enhance', 'performance', 'big'), ('performance', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', 'system'), ('analytics', 'system', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('relevant', 'JJ'), ('technologies', 'NNS'), ('compression', 'NN'), (',', ','), ('sampling', 'NN'), (',', ','), ('even', 'RB'), ('platform', 'NN'), ('presented', 'VBN'), ('recent', 'JJ'), ('years', 'NNS'), ('may', 'MD'), ('also', 'RB'), ('used', 'VBD'), ('enhance', 'NN'), ('performance', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('system', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['The relevant technologies compression', 'sampling', 'platform', 'recent years', 'enhance performance', 'big data analytics system']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('relevant', 'relev'), ('technologies', 'technolog'), ('compression', 'compress'), (',', ','), ('sampling', 'sampl'), (',', ','), ('even', 'even'), ('platform', 'platform'), ('presented', 'present'), ('recent', 'recent'), ('years', 'year'), ('may', 'may'), ('also', 'also'), ('used', 'use'), ('enhance', 'enhanc'), ('performance', 'perform'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('system', 'system'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('relevant', 'relev'), ('technologies', 'technolog'), ('compression', 'compress'), (',', ','), ('sampling', 'sampl'), (',', ','), ('even', 'even'), ('platform', 'platform'), ('presented', 'present'), ('recent', 'recent'), ('years', 'year'), ('may', 'may'), ('also', 'also'), ('used', 'use'), ('enhance', 'enhanc'), ('performance', 'perform'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('system', 'system'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('relevant', 'relevant'), ('technologies', 'technology'), ('compression', 'compression'), (',', ','), ('sampling', 'sampling'), (',', ','), ('even', 'even'), ('platform', 'platform'), ('presented', 'presented'), ('recent', 'recent'), ('years', 'year'), ('may', 'may'), ('also', 'also'), ('used', 'used'), ('enhance', 'enhance'), ('performance', 'performance'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('system', 'system'), ('.', '.')]


------------------- Sentence 6 -------------------

As a result, although  these research topics still have several open issues that need to be solved, these situa- tions, on the contrary, also illustrate that everything is possible in these studies.

>> Tokens are: 
 ['As', 'result', ',', 'although', 'research', 'topics', 'still', 'several', 'open', 'issues', 'need', 'solved', ',', 'situa-', 'tions', ',', 'contrary', ',', 'also', 'illustrate', 'everything', 'possible', 'studies', '.']

>> Bigrams are: 
 [('As', 'result'), ('result', ','), (',', 'although'), ('although', 'research'), ('research', 'topics'), ('topics', 'still'), ('still', 'several'), ('several', 'open'), ('open', 'issues'), ('issues', 'need'), ('need', 'solved'), ('solved', ','), (',', 'situa-'), ('situa-', 'tions'), ('tions', ','), (',', 'contrary'), ('contrary', ','), (',', 'also'), ('also', 'illustrate'), ('illustrate', 'everything'), ('everything', 'possible'), ('possible', 'studies'), ('studies', '.')]

>> Trigrams are: 
 [('As', 'result', ','), ('result', ',', 'although'), (',', 'although', 'research'), ('although', 'research', 'topics'), ('research', 'topics', 'still'), ('topics', 'still', 'several'), ('still', 'several', 'open'), ('several', 'open', 'issues'), ('open', 'issues', 'need'), ('issues', 'need', 'solved'), ('need', 'solved', ','), ('solved', ',', 'situa-'), (',', 'situa-', 'tions'), ('situa-', 'tions', ','), ('tions', ',', 'contrary'), (',', 'contrary', ','), ('contrary', ',', 'also'), (',', 'also', 'illustrate'), ('also', 'illustrate', 'everything'), ('illustrate', 'everything', 'possible'), ('everything', 'possible', 'studies'), ('possible', 'studies', '.')]

>> POS Tags are: 
 [('As', 'IN'), ('result', 'NN'), (',', ','), ('although', 'IN'), ('research', 'NN'), ('topics', 'NNS'), ('still', 'RB'), ('several', 'JJ'), ('open', 'JJ'), ('issues', 'NNS'), ('need', 'VBP'), ('solved', 'VBN'), (',', ','), ('situa-', 'JJ'), ('tions', 'NNS'), (',', ','), ('contrary', 'JJ'), (',', ','), ('also', 'RB'), ('illustrate', 'VBP'), ('everything', 'NN'), ('possible', 'JJ'), ('studies', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['result', 'research topics', 'several open issues', 'situa- tions', 'everything', 'possible studies']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('As', 'as'), ('result', 'result'), (',', ','), ('although', 'although'), ('research', 'research'), ('topics', 'topic'), ('still', 'still'), ('several', 'sever'), ('open', 'open'), ('issues', 'issu'), ('need', 'need'), ('solved', 'solv'), (',', ','), ('situa-', 'situa-'), ('tions', 'tion'), (',', ','), ('contrary', 'contrari'), (',', ','), ('also', 'also'), ('illustrate', 'illustr'), ('everything', 'everyth'), ('possible', 'possibl'), ('studies', 'studi'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('As', 'as'), ('result', 'result'), (',', ','), ('although', 'although'), ('research', 'research'), ('topics', 'topic'), ('still', 'still'), ('several', 'sever'), ('open', 'open'), ('issues', 'issu'), ('need', 'need'), ('solved', 'solv'), (',', ','), ('situa-', 'situa-'), ('tions', 'tion'), (',', ','), ('contrary', 'contrari'), (',', ','), ('also', 'also'), ('illustrate', 'illustr'), ('everything', 'everyth'), ('possible', 'possibl'), ('studies', 'studi'), ('.', '.')]

>> Lemmatization: 
 [('As', 'As'), ('result', 'result'), (',', ','), ('although', 'although'), ('research', 'research'), ('topics', 'topic'), ('still', 'still'), ('several', 'several'), ('open', 'open'), ('issues', 'issue'), ('need', 'need'), ('solved', 'solved'), (',', ','), ('situa-', 'situa-'), ('tions', 'tions'), (',', ','), ('contrary', 'contrary'), (',', ','), ('also', 'also'), ('illustrate', 'illustrate'), ('everything', 'everything'), ('possible', 'possible'), ('studies', 'study'), ('.', '.')]



========================================== PARAGRAPH 361 ===========================================

The open issues Although the data analytics today may be inefficient for big data caused by the environ- ment, devices, systems, and even problems that are quite different from traditional min- ing problems, because several characteristics of big data also exist in the traditional data  analytics. Several open issues caused by the big data will be addressed as the platform/ framework and data mining perspectives in this section to explain what dilemmas we  may confront because of big data. Here are some of the open issues: 

------------------- Sentence 1 -------------------

The open issues Although the data analytics today may be inefficient for big data caused by the environ- ment, devices, systems, and even problems that are quite different from traditional min- ing problems, because several characteristics of big data also exist in the traditional data  analytics.

>> Tokens are: 
 ['The', 'open', 'issues', 'Although', 'data', 'analytics', 'today', 'may', 'inefficient', 'big', 'data', 'caused', 'environ-', 'ment', ',', 'devices', ',', 'systems', ',', 'even', 'problems', 'quite', 'different', 'traditional', 'min-', 'ing', 'problems', ',', 'several', 'characteristics', 'big', 'data', 'also', 'exist', 'traditional', 'data', 'analytics', '.']

>> Bigrams are: 
 [('The', 'open'), ('open', 'issues'), ('issues', 'Although'), ('Although', 'data'), ('data', 'analytics'), ('analytics', 'today'), ('today', 'may'), ('may', 'inefficient'), ('inefficient', 'big'), ('big', 'data'), ('data', 'caused'), ('caused', 'environ-'), ('environ-', 'ment'), ('ment', ','), (',', 'devices'), ('devices', ','), (',', 'systems'), ('systems', ','), (',', 'even'), ('even', 'problems'), ('problems', 'quite'), ('quite', 'different'), ('different', 'traditional'), ('traditional', 'min-'), ('min-', 'ing'), ('ing', 'problems'), ('problems', ','), (',', 'several'), ('several', 'characteristics'), ('characteristics', 'big'), ('big', 'data'), ('data', 'also'), ('also', 'exist'), ('exist', 'traditional'), ('traditional', 'data'), ('data', 'analytics'), ('analytics', '.')]

>> Trigrams are: 
 [('The', 'open', 'issues'), ('open', 'issues', 'Although'), ('issues', 'Although', 'data'), ('Although', 'data', 'analytics'), ('data', 'analytics', 'today'), ('analytics', 'today', 'may'), ('today', 'may', 'inefficient'), ('may', 'inefficient', 'big'), ('inefficient', 'big', 'data'), ('big', 'data', 'caused'), ('data', 'caused', 'environ-'), ('caused', 'environ-', 'ment'), ('environ-', 'ment', ','), ('ment', ',', 'devices'), (',', 'devices', ','), ('devices', ',', 'systems'), (',', 'systems', ','), ('systems', ',', 'even'), (',', 'even', 'problems'), ('even', 'problems', 'quite'), ('problems', 'quite', 'different'), ('quite', 'different', 'traditional'), ('different', 'traditional', 'min-'), ('traditional', 'min-', 'ing'), ('min-', 'ing', 'problems'), ('ing', 'problems', ','), ('problems', ',', 'several'), (',', 'several', 'characteristics'), ('several', 'characteristics', 'big'), ('characteristics', 'big', 'data'), ('big', 'data', 'also'), ('data', 'also', 'exist'), ('also', 'exist', 'traditional'), ('exist', 'traditional', 'data'), ('traditional', 'data', 'analytics'), ('data', 'analytics', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('open', 'JJ'), ('issues', 'NNS'), ('Although', 'IN'), ('data', 'NN'), ('analytics', 'NNS'), ('today', 'NN'), ('may', 'MD'), ('inefficient', 'VB'), ('big', 'JJ'), ('data', 'NNS'), ('caused', 'VBD'), ('environ-', 'JJ'), ('ment', 'NN'), (',', ','), ('devices', 'NNS'), (',', ','), ('systems', 'NNS'), (',', ','), ('even', 'RB'), ('problems', 'NNS'), ('quite', 'RB'), ('different', 'JJ'), ('traditional', 'JJ'), ('min-', 'NN'), ('ing', 'NN'), ('problems', 'NNS'), (',', ','), ('several', 'JJ'), ('characteristics', 'NNS'), ('big', 'JJ'), ('data', 'NNS'), ('also', 'RB'), ('exist', 'VBP'), ('traditional', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['The open issues', 'data analytics today', 'big data', 'environ- ment', 'devices', 'systems', 'problems', 'different traditional min- ing problems', 'several characteristics', 'big data', 'traditional data analytics']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('open', 'open'), ('issues', 'issu'), ('Although', 'although'), ('data', 'data'), ('analytics', 'analyt'), ('today', 'today'), ('may', 'may'), ('inefficient', 'ineffici'), ('big', 'big'), ('data', 'data'), ('caused', 'caus'), ('environ-', 'environ-'), ('ment', 'ment'), (',', ','), ('devices', 'devic'), (',', ','), ('systems', 'system'), (',', ','), ('even', 'even'), ('problems', 'problem'), ('quite', 'quit'), ('different', 'differ'), ('traditional', 'tradit'), ('min-', 'min-'), ('ing', 'ing'), ('problems', 'problem'), (',', ','), ('several', 'sever'), ('characteristics', 'characterist'), ('big', 'big'), ('data', 'data'), ('also', 'also'), ('exist', 'exist'), ('traditional', 'tradit'), ('data', 'data'), ('analytics', 'analyt'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('open', 'open'), ('issues', 'issu'), ('Although', 'although'), ('data', 'data'), ('analytics', 'analyt'), ('today', 'today'), ('may', 'may'), ('inefficient', 'ineffici'), ('big', 'big'), ('data', 'data'), ('caused', 'caus'), ('environ-', 'environ-'), ('ment', 'ment'), (',', ','), ('devices', 'devic'), (',', ','), ('systems', 'system'), (',', ','), ('even', 'even'), ('problems', 'problem'), ('quite', 'quit'), ('different', 'differ'), ('traditional', 'tradit'), ('min-', 'min-'), ('ing', 'ing'), ('problems', 'problem'), (',', ','), ('several', 'sever'), ('characteristics', 'characterist'), ('big', 'big'), ('data', 'data'), ('also', 'also'), ('exist', 'exist'), ('traditional', 'tradit'), ('data', 'data'), ('analytics', 'analyt'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('open', 'open'), ('issues', 'issue'), ('Although', 'Although'), ('data', 'data'), ('analytics', 'analytics'), ('today', 'today'), ('may', 'may'), ('inefficient', 'inefficient'), ('big', 'big'), ('data', 'data'), ('caused', 'caused'), ('environ-', 'environ-'), ('ment', 'ment'), (',', ','), ('devices', 'device'), (',', ','), ('systems', 'system'), (',', ','), ('even', 'even'), ('problems', 'problem'), ('quite', 'quite'), ('different', 'different'), ('traditional', 'traditional'), ('min-', 'min-'), ('ing', 'ing'), ('problems', 'problem'), (',', ','), ('several', 'several'), ('characteristics', 'characteristic'), ('big', 'big'), ('data', 'data'), ('also', 'also'), ('exist', 'exist'), ('traditional', 'traditional'), ('data', 'data'), ('analytics', 'analytics'), ('.', '.')]


------------------- Sentence 2 -------------------

Several open issues caused by the big data will be addressed as the platform/ framework and data mining perspectives in this section to explain what dilemmas we  may confront because of big data.

>> Tokens are: 
 ['Several', 'open', 'issues', 'caused', 'big', 'data', 'addressed', 'platform/', 'framework', 'data', 'mining', 'perspectives', 'section', 'explain', 'dilemmas', 'may', 'confront', 'big', 'data', '.']

>> Bigrams are: 
 [('Several', 'open'), ('open', 'issues'), ('issues', 'caused'), ('caused', 'big'), ('big', 'data'), ('data', 'addressed'), ('addressed', 'platform/'), ('platform/', 'framework'), ('framework', 'data'), ('data', 'mining'), ('mining', 'perspectives'), ('perspectives', 'section'), ('section', 'explain'), ('explain', 'dilemmas'), ('dilemmas', 'may'), ('may', 'confront'), ('confront', 'big'), ('big', 'data'), ('data', '.')]

>> Trigrams are: 
 [('Several', 'open', 'issues'), ('open', 'issues', 'caused'), ('issues', 'caused', 'big'), ('caused', 'big', 'data'), ('big', 'data', 'addressed'), ('data', 'addressed', 'platform/'), ('addressed', 'platform/', 'framework'), ('platform/', 'framework', 'data'), ('framework', 'data', 'mining'), ('data', 'mining', 'perspectives'), ('mining', 'perspectives', 'section'), ('perspectives', 'section', 'explain'), ('section', 'explain', 'dilemmas'), ('explain', 'dilemmas', 'may'), ('dilemmas', 'may', 'confront'), ('may', 'confront', 'big'), ('confront', 'big', 'data'), ('big', 'data', '.')]

>> POS Tags are: 
 [('Several', 'JJ'), ('open', 'JJ'), ('issues', 'NNS'), ('caused', 'VBD'), ('big', 'JJ'), ('data', 'NNS'), ('addressed', 'VBD'), ('platform/', 'JJ'), ('framework', 'NN'), ('data', 'NNS'), ('mining', 'NN'), ('perspectives', 'NNS'), ('section', 'NN'), ('explain', 'VBP'), ('dilemmas', 'NN'), ('may', 'MD'), ('confront', 'VB'), ('big', 'JJ'), ('data', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['Several open issues', 'big data', 'platform/ framework data mining perspectives section', 'dilemmas', 'big data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Several', 'sever'), ('open', 'open'), ('issues', 'issu'), ('caused', 'caus'), ('big', 'big'), ('data', 'data'), ('addressed', 'address'), ('platform/', 'platform/'), ('framework', 'framework'), ('data', 'data'), ('mining', 'mine'), ('perspectives', 'perspect'), ('section', 'section'), ('explain', 'explain'), ('dilemmas', 'dilemma'), ('may', 'may'), ('confront', 'confront'), ('big', 'big'), ('data', 'data'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Several', 'sever'), ('open', 'open'), ('issues', 'issu'), ('caused', 'caus'), ('big', 'big'), ('data', 'data'), ('addressed', 'address'), ('platform/', 'platform/'), ('framework', 'framework'), ('data', 'data'), ('mining', 'mine'), ('perspectives', 'perspect'), ('section', 'section'), ('explain', 'explain'), ('dilemmas', 'dilemma'), ('may', 'may'), ('confront', 'confront'), ('big', 'big'), ('data', 'data'), ('.', '.')]

>> Lemmatization: 
 [('Several', 'Several'), ('open', 'open'), ('issues', 'issue'), ('caused', 'caused'), ('big', 'big'), ('data', 'data'), ('addressed', 'addressed'), ('platform/', 'platform/'), ('framework', 'framework'), ('data', 'data'), ('mining', 'mining'), ('perspectives', 'perspective'), ('section', 'section'), ('explain', 'explain'), ('dilemmas', 'dilemma'), ('may', 'may'), ('confront', 'confront'), ('big', 'big'), ('data', 'data'), ('.', '.')]


------------------- Sentence 3 -------------------

Here are some of the open issues:

>> Tokens are: 
 ['Here', 'open', 'issues', ':']

>> Bigrams are: 
 [('Here', 'open'), ('open', 'issues'), ('issues', ':')]

>> Trigrams are: 
 [('Here', 'open', 'issues'), ('open', 'issues', ':')]

>> POS Tags are: 
 [('Here', 'RB'), ('open', 'JJ'), ('issues', 'NNS'), (':', ':')]

>> Noun Phrases are: 
 ['open issues']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Here', 'here'), ('open', 'open'), ('issues', 'issu'), (':', ':')]

>> Stemming using Snowball Stemmer: 
 [('Here', 'here'), ('open', 'open'), ('issues', 'issu'), (':', ':')]

>> Lemmatization: 
 [('Here', 'Here'), ('open', 'open'), ('issues', 'issue'), (':', ':')]



========================================== PARAGRAPH 362 ===========================================

Platform and framework perspective 

------------------- Sentence 1 -------------------

Platform and framework perspective

>> Tokens are: 
 ['Platform', 'framework', 'perspective']

>> Bigrams are: 
 [('Platform', 'framework'), ('framework', 'perspective')]

>> Trigrams are: 
 [('Platform', 'framework', 'perspective')]

>> POS Tags are: 
 [('Platform', 'NNP'), ('framework', 'NN'), ('perspective', 'NN')]

>> Noun Phrases are: 
 ['Platform framework perspective']

>> Named Entities are: 
 [('GPE', 'Platform')] 

>> Stemming using Porter Stemmer: 
 [('Platform', 'platform'), ('framework', 'framework'), ('perspective', 'perspect')]

>> Stemming using Snowball Stemmer: 
 [('Platform', 'platform'), ('framework', 'framework'), ('perspective', 'perspect')]

>> Lemmatization: 
 [('Platform', 'Platform'), ('framework', 'framework'), ('perspective', 'perspective')]



========================================== PARAGRAPH 363 ===========================================

Input and output ratio of platform 

------------------- Sentence 1 -------------------

Input and output ratio of platform

>> Tokens are: 
 ['Input', 'output', 'ratio', 'platform']

>> Bigrams are: 
 [('Input', 'output'), ('output', 'ratio'), ('ratio', 'platform')]

>> Trigrams are: 
 [('Input', 'output', 'ratio'), ('output', 'ratio', 'platform')]

>> POS Tags are: 
 [('Input', 'NNP'), ('output', 'NN'), ('ratio', 'NN'), ('platform', 'NN')]

>> Noun Phrases are: 
 ['Input output ratio platform']

>> Named Entities are: 
 [('GPE', 'Input')] 

>> Stemming using Porter Stemmer: 
 [('Input', 'input'), ('output', 'output'), ('ratio', 'ratio'), ('platform', 'platform')]

>> Stemming using Snowball Stemmer: 
 [('Input', 'input'), ('output', 'output'), ('ratio', 'ratio'), ('platform', 'platform')]

>> Lemmatization: 
 [('Input', 'Input'), ('output', 'output'), ('ratio', 'ratio'), ('platform', 'platform')]



========================================== PARAGRAPH 364 ===========================================

A large number of reports and researches mentioned that we will enter the big data age  in the near future. Some of them insinuated to us that these fruitful results of big data  will lead us to a whole new world where “everything” is possible; therefore, the big data  analytics will be an omniscient and omnipotent system. From the pragmatic perspec- tive, the big data analytics is indeed useful and has many possibilities which can help us  more accurately understand the so-called “things.” However, the situation in most stud- ies of big data analytics is that they argued that the results of big data are valuable, but  the business models of most big data analytics are not clear. The fact is that assuming we  have infinite computing resources for big data analytics is a thoroughly impracticable  plan, the input and output ratio (e.g.-, return on investment) will need to be taken into  account before an organization constructs the big data analytics center.

------------------- Sentence 1 -------------------

A large number of reports and researches mentioned that we will enter the big data age  in the near future.

>> Tokens are: 
 ['A', 'large', 'number', 'reports', 'researches', 'mentioned', 'enter', 'big', 'data', 'age', 'near', 'future', '.']

>> Bigrams are: 
 [('A', 'large'), ('large', 'number'), ('number', 'reports'), ('reports', 'researches'), ('researches', 'mentioned'), ('mentioned', 'enter'), ('enter', 'big'), ('big', 'data'), ('data', 'age'), ('age', 'near'), ('near', 'future'), ('future', '.')]

>> Trigrams are: 
 [('A', 'large', 'number'), ('large', 'number', 'reports'), ('number', 'reports', 'researches'), ('reports', 'researches', 'mentioned'), ('researches', 'mentioned', 'enter'), ('mentioned', 'enter', 'big'), ('enter', 'big', 'data'), ('big', 'data', 'age'), ('data', 'age', 'near'), ('age', 'near', 'future'), ('near', 'future', '.')]

>> POS Tags are: 
 [('A', 'DT'), ('large', 'JJ'), ('number', 'NN'), ('reports', 'NNS'), ('researches', 'NNS'), ('mentioned', 'VBD'), ('enter', 'RB'), ('big', 'JJ'), ('data', 'NNS'), ('age', 'NN'), ('near', 'IN'), ('future', 'JJ'), ('.', '.')]

>> Noun Phrases are: 
 ['A large number reports researches', 'big data age']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('A', 'a'), ('large', 'larg'), ('number', 'number'), ('reports', 'report'), ('researches', 'research'), ('mentioned', 'mention'), ('enter', 'enter'), ('big', 'big'), ('data', 'data'), ('age', 'age'), ('near', 'near'), ('future', 'futur'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('A', 'a'), ('large', 'larg'), ('number', 'number'), ('reports', 'report'), ('researches', 'research'), ('mentioned', 'mention'), ('enter', 'enter'), ('big', 'big'), ('data', 'data'), ('age', 'age'), ('near', 'near'), ('future', 'futur'), ('.', '.')]

>> Lemmatization: 
 [('A', 'A'), ('large', 'large'), ('number', 'number'), ('reports', 'report'), ('researches', 'research'), ('mentioned', 'mentioned'), ('enter', 'enter'), ('big', 'big'), ('data', 'data'), ('age', 'age'), ('near', 'near'), ('future', 'future'), ('.', '.')]


------------------- Sentence 2 -------------------

Some of them insinuated to us that these fruitful results of big data  will lead us to a whole new world where “everything” is possible; therefore, the big data  analytics will be an omniscient and omnipotent system.

>> Tokens are: 
 ['Some', 'insinuated', 'us', 'fruitful', 'results', 'big', 'data', 'lead', 'us', 'whole', 'new', 'world', '“', 'everything', '”', 'possible', ';', 'therefore', ',', 'big', 'data', 'analytics', 'omniscient', 'omnipotent', 'system', '.']

>> Bigrams are: 
 [('Some', 'insinuated'), ('insinuated', 'us'), ('us', 'fruitful'), ('fruitful', 'results'), ('results', 'big'), ('big', 'data'), ('data', 'lead'), ('lead', 'us'), ('us', 'whole'), ('whole', 'new'), ('new', 'world'), ('world', '“'), ('“', 'everything'), ('everything', '”'), ('”', 'possible'), ('possible', ';'), (';', 'therefore'), ('therefore', ','), (',', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', 'omniscient'), ('omniscient', 'omnipotent'), ('omnipotent', 'system'), ('system', '.')]

>> Trigrams are: 
 [('Some', 'insinuated', 'us'), ('insinuated', 'us', 'fruitful'), ('us', 'fruitful', 'results'), ('fruitful', 'results', 'big'), ('results', 'big', 'data'), ('big', 'data', 'lead'), ('data', 'lead', 'us'), ('lead', 'us', 'whole'), ('us', 'whole', 'new'), ('whole', 'new', 'world'), ('new', 'world', '“'), ('world', '“', 'everything'), ('“', 'everything', '”'), ('everything', '”', 'possible'), ('”', 'possible', ';'), ('possible', ';', 'therefore'), (';', 'therefore', ','), ('therefore', ',', 'big'), (',', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', 'omniscient'), ('analytics', 'omniscient', 'omnipotent'), ('omniscient', 'omnipotent', 'system'), ('omnipotent', 'system', '.')]

>> POS Tags are: 
 [('Some', 'DT'), ('insinuated', 'VBD'), ('us', 'PRP'), ('fruitful', 'JJ'), ('results', 'NNS'), ('big', 'JJ'), ('data', 'NNS'), ('lead', 'VBP'), ('us', 'PRP'), ('whole', 'JJ'), ('new', 'JJ'), ('world', 'NN'), ('“', 'NN'), ('everything', 'NN'), ('”', 'NNP'), ('possible', 'JJ'), (';', ':'), ('therefore', 'RB'), (',', ','), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('omniscient', 'JJ'), ('omnipotent', 'JJ'), ('system', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['fruitful results', 'big data', 'whole new world “ everything ”', 'big data analytics', 'omniscient omnipotent system']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Some', 'some'), ('insinuated', 'insinu'), ('us', 'us'), ('fruitful', 'fruit'), ('results', 'result'), ('big', 'big'), ('data', 'data'), ('lead', 'lead'), ('us', 'us'), ('whole', 'whole'), ('new', 'new'), ('world', 'world'), ('“', '“'), ('everything', 'everyth'), ('”', '”'), ('possible', 'possibl'), (';', ';'), ('therefore', 'therefor'), (',', ','), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('omniscient', 'omnisci'), ('omnipotent', 'omnipot'), ('system', 'system'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Some', 'some'), ('insinuated', 'insinu'), ('us', 'us'), ('fruitful', 'fruit'), ('results', 'result'), ('big', 'big'), ('data', 'data'), ('lead', 'lead'), ('us', 'us'), ('whole', 'whole'), ('new', 'new'), ('world', 'world'), ('“', '“'), ('everything', 'everyth'), ('”', '”'), ('possible', 'possibl'), (';', ';'), ('therefore', 'therefor'), (',', ','), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('omniscient', 'omnisci'), ('omnipotent', 'omnipot'), ('system', 'system'), ('.', '.')]

>> Lemmatization: 
 [('Some', 'Some'), ('insinuated', 'insinuated'), ('us', 'u'), ('fruitful', 'fruitful'), ('results', 'result'), ('big', 'big'), ('data', 'data'), ('lead', 'lead'), ('us', 'u'), ('whole', 'whole'), ('new', 'new'), ('world', 'world'), ('“', '“'), ('everything', 'everything'), ('”', '”'), ('possible', 'possible'), (';', ';'), ('therefore', 'therefore'), (',', ','), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('omniscient', 'omniscient'), ('omnipotent', 'omnipotent'), ('system', 'system'), ('.', '.')]


------------------- Sentence 3 -------------------

From the pragmatic perspec- tive, the big data analytics is indeed useful and has many possibilities which can help us  more accurately understand the so-called “things.” However, the situation in most stud- ies of big data analytics is that they argued that the results of big data are valuable, but  the business models of most big data analytics are not clear.

>> Tokens are: 
 ['From', 'pragmatic', 'perspec-', 'tive', ',', 'big', 'data', 'analytics', 'indeed', 'useful', 'many', 'possibilities', 'help', 'us', 'accurately', 'understand', 'so-called', '“', 'things.', '”', 'However', ',', 'situation', 'stud-', 'ies', 'big', 'data', 'analytics', 'argued', 'results', 'big', 'data', 'valuable', ',', 'business', 'models', 'big', 'data', 'analytics', 'clear', '.']

>> Bigrams are: 
 [('From', 'pragmatic'), ('pragmatic', 'perspec-'), ('perspec-', 'tive'), ('tive', ','), (',', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', 'indeed'), ('indeed', 'useful'), ('useful', 'many'), ('many', 'possibilities'), ('possibilities', 'help'), ('help', 'us'), ('us', 'accurately'), ('accurately', 'understand'), ('understand', 'so-called'), ('so-called', '“'), ('“', 'things.'), ('things.', '”'), ('”', 'However'), ('However', ','), (',', 'situation'), ('situation', 'stud-'), ('stud-', 'ies'), ('ies', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', 'argued'), ('argued', 'results'), ('results', 'big'), ('big', 'data'), ('data', 'valuable'), ('valuable', ','), (',', 'business'), ('business', 'models'), ('models', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', 'clear'), ('clear', '.')]

>> Trigrams are: 
 [('From', 'pragmatic', 'perspec-'), ('pragmatic', 'perspec-', 'tive'), ('perspec-', 'tive', ','), ('tive', ',', 'big'), (',', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', 'indeed'), ('analytics', 'indeed', 'useful'), ('indeed', 'useful', 'many'), ('useful', 'many', 'possibilities'), ('many', 'possibilities', 'help'), ('possibilities', 'help', 'us'), ('help', 'us', 'accurately'), ('us', 'accurately', 'understand'), ('accurately', 'understand', 'so-called'), ('understand', 'so-called', '“'), ('so-called', '“', 'things.'), ('“', 'things.', '”'), ('things.', '”', 'However'), ('”', 'However', ','), ('However', ',', 'situation'), (',', 'situation', 'stud-'), ('situation', 'stud-', 'ies'), ('stud-', 'ies', 'big'), ('ies', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', 'argued'), ('analytics', 'argued', 'results'), ('argued', 'results', 'big'), ('results', 'big', 'data'), ('big', 'data', 'valuable'), ('data', 'valuable', ','), ('valuable', ',', 'business'), (',', 'business', 'models'), ('business', 'models', 'big'), ('models', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', 'clear'), ('analytics', 'clear', '.')]

>> POS Tags are: 
 [('From', 'IN'), ('pragmatic', 'JJ'), ('perspec-', 'JJ'), ('tive', 'NN'), (',', ','), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('indeed', 'RB'), ('useful', 'JJ'), ('many', 'JJ'), ('possibilities', 'NNS'), ('help', 'VBP'), ('us', 'PRP'), ('accurately', 'RB'), ('understand', 'VBP'), ('so-called', 'JJ'), ('“', 'NNP'), ('things.', 'NN'), ('”', 'NNP'), ('However', 'RB'), (',', ','), ('situation', 'NN'), ('stud-', 'JJ'), ('ies', 'NNS'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('argued', 'VBD'), ('results', 'NNS'), ('big', 'JJ'), ('data', 'NNS'), ('valuable', 'JJ'), (',', ','), ('business', 'NN'), ('models', 'NNS'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('clear', 'JJ'), ('.', '.')]

>> Noun Phrases are: 
 ['pragmatic perspec- tive', 'big data analytics', 'useful many possibilities', 'so-called “ things. ”', 'situation', 'stud- ies', 'big data analytics', 'results', 'big data', 'business models', 'big data analytics']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('From', 'from'), ('pragmatic', 'pragmat'), ('perspec-', 'perspec-'), ('tive', 'tive'), (',', ','), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('indeed', 'inde'), ('useful', 'use'), ('many', 'mani'), ('possibilities', 'possibl'), ('help', 'help'), ('us', 'us'), ('accurately', 'accur'), ('understand', 'understand'), ('so-called', 'so-cal'), ('“', '“'), ('things.', 'things.'), ('”', '”'), ('However', 'howev'), (',', ','), ('situation', 'situat'), ('stud-', 'stud-'), ('ies', 'i'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('argued', 'argu'), ('results', 'result'), ('big', 'big'), ('data', 'data'), ('valuable', 'valuabl'), (',', ','), ('business', 'busi'), ('models', 'model'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('clear', 'clear'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('From', 'from'), ('pragmatic', 'pragmat'), ('perspec-', 'perspec-'), ('tive', 'tive'), (',', ','), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('indeed', 'inde'), ('useful', 'use'), ('many', 'mani'), ('possibilities', 'possibl'), ('help', 'help'), ('us', 'us'), ('accurately', 'accur'), ('understand', 'understand'), ('so-called', 'so-cal'), ('“', '“'), ('things.', 'things.'), ('”', '”'), ('However', 'howev'), (',', ','), ('situation', 'situat'), ('stud-', 'stud-'), ('ies', 'ie'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('argued', 'argu'), ('results', 'result'), ('big', 'big'), ('data', 'data'), ('valuable', 'valuabl'), (',', ','), ('business', 'busi'), ('models', 'model'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('clear', 'clear'), ('.', '.')]

>> Lemmatization: 
 [('From', 'From'), ('pragmatic', 'pragmatic'), ('perspec-', 'perspec-'), ('tive', 'tive'), (',', ','), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('indeed', 'indeed'), ('useful', 'useful'), ('many', 'many'), ('possibilities', 'possibility'), ('help', 'help'), ('us', 'u'), ('accurately', 'accurately'), ('understand', 'understand'), ('so-called', 'so-called'), ('“', '“'), ('things.', 'things.'), ('”', '”'), ('However', 'However'), (',', ','), ('situation', 'situation'), ('stud-', 'stud-'), ('ies', 'y'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('argued', 'argued'), ('results', 'result'), ('big', 'big'), ('data', 'data'), ('valuable', 'valuable'), (',', ','), ('business', 'business'), ('models', 'model'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('clear', 'clear'), ('.', '.')]


------------------- Sentence 4 -------------------

The fact is that assuming we  have infinite computing resources for big data analytics is a thoroughly impracticable  plan, the input and output ratio (e.g.-, return on investment) will need to be taken into  account before an organization constructs the big data analytics center.

>> Tokens are: 
 ['The', 'fact', 'assuming', 'infinite', 'computing', 'resources', 'big', 'data', 'analytics', 'thoroughly', 'impracticable', 'plan', ',', 'input', 'output', 'ratio', '(', 'e.g.-', ',', 'return', 'investment', ')', 'need', 'taken', 'account', 'organization', 'constructs', 'big', 'data', 'analytics', 'center', '.']

>> Bigrams are: 
 [('The', 'fact'), ('fact', 'assuming'), ('assuming', 'infinite'), ('infinite', 'computing'), ('computing', 'resources'), ('resources', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', 'thoroughly'), ('thoroughly', 'impracticable'), ('impracticable', 'plan'), ('plan', ','), (',', 'input'), ('input', 'output'), ('output', 'ratio'), ('ratio', '('), ('(', 'e.g.-'), ('e.g.-', ','), (',', 'return'), ('return', 'investment'), ('investment', ')'), (')', 'need'), ('need', 'taken'), ('taken', 'account'), ('account', 'organization'), ('organization', 'constructs'), ('constructs', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', 'center'), ('center', '.')]

>> Trigrams are: 
 [('The', 'fact', 'assuming'), ('fact', 'assuming', 'infinite'), ('assuming', 'infinite', 'computing'), ('infinite', 'computing', 'resources'), ('computing', 'resources', 'big'), ('resources', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', 'thoroughly'), ('analytics', 'thoroughly', 'impracticable'), ('thoroughly', 'impracticable', 'plan'), ('impracticable', 'plan', ','), ('plan', ',', 'input'), (',', 'input', 'output'), ('input', 'output', 'ratio'), ('output', 'ratio', '('), ('ratio', '(', 'e.g.-'), ('(', 'e.g.-', ','), ('e.g.-', ',', 'return'), (',', 'return', 'investment'), ('return', 'investment', ')'), ('investment', ')', 'need'), (')', 'need', 'taken'), ('need', 'taken', 'account'), ('taken', 'account', 'organization'), ('account', 'organization', 'constructs'), ('organization', 'constructs', 'big'), ('constructs', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', 'center'), ('analytics', 'center', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('fact', 'NN'), ('assuming', 'VBG'), ('infinite', 'JJ'), ('computing', 'VBG'), ('resources', 'NNS'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('thoroughly', 'RB'), ('impracticable', 'JJ'), ('plan', 'NN'), (',', ','), ('input', 'NN'), ('output', 'NN'), ('ratio', 'NN'), ('(', '('), ('e.g.-', 'JJ'), (',', ','), ('return', 'VB'), ('investment', 'NN'), (')', ')'), ('need', 'VBP'), ('taken', 'VBN'), ('account', 'NN'), ('organization', 'NN'), ('constructs', 'VBZ'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('center', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['The fact', 'resources', 'big data analytics', 'impracticable plan', 'input output ratio', 'investment', 'account organization', 'big data analytics center']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('fact', 'fact'), ('assuming', 'assum'), ('infinite', 'infinit'), ('computing', 'comput'), ('resources', 'resourc'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('thoroughly', 'thoroughli'), ('impracticable', 'impractic'), ('plan', 'plan'), (',', ','), ('input', 'input'), ('output', 'output'), ('ratio', 'ratio'), ('(', '('), ('e.g.-', 'e.g.-'), (',', ','), ('return', 'return'), ('investment', 'invest'), (')', ')'), ('need', 'need'), ('taken', 'taken'), ('account', 'account'), ('organization', 'organ'), ('constructs', 'construct'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('center', 'center'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('fact', 'fact'), ('assuming', 'assum'), ('infinite', 'infinit'), ('computing', 'comput'), ('resources', 'resourc'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('thoroughly', 'thorough'), ('impracticable', 'impractic'), ('plan', 'plan'), (',', ','), ('input', 'input'), ('output', 'output'), ('ratio', 'ratio'), ('(', '('), ('e.g.-', 'e.g.-'), (',', ','), ('return', 'return'), ('investment', 'invest'), (')', ')'), ('need', 'need'), ('taken', 'taken'), ('account', 'account'), ('organization', 'organ'), ('constructs', 'construct'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('center', 'center'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('fact', 'fact'), ('assuming', 'assuming'), ('infinite', 'infinite'), ('computing', 'computing'), ('resources', 'resource'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('thoroughly', 'thoroughly'), ('impracticable', 'impracticable'), ('plan', 'plan'), (',', ','), ('input', 'input'), ('output', 'output'), ('ratio', 'ratio'), ('(', '('), ('e.g.-', 'e.g.-'), (',', ','), ('return', 'return'), ('investment', 'investment'), (')', ')'), ('need', 'need'), ('taken', 'taken'), ('account', 'account'), ('organization', 'organization'), ('constructs', 'construct'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('center', 'center'), ('.', '.')]



========================================== PARAGRAPH 365 ===========================================

Page 24 of 32Tsai et al. Journal of Big Data  (2015) 2:21  

------------------- Sentence 1 -------------------

Page 24 of 32Tsai et al.

>> Tokens are: 
 ['Page', '24', '32Tsai', 'et', 'al', '.']

>> Bigrams are: 
 [('Page', '24'), ('24', '32Tsai'), ('32Tsai', 'et'), ('et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('Page', '24', '32Tsai'), ('24', '32Tsai', 'et'), ('32Tsai', 'et', 'al'), ('et', 'al', '.')]

>> POS Tags are: 
 [('Page', 'NN'), ('24', 'CD'), ('32Tsai', 'CD'), ('et', 'NN'), ('al', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Page', 'et al']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Page', 'page'), ('24', '24'), ('32Tsai', '32tsai'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Page', 'page'), ('24', '24'), ('32Tsai', '32tsai'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('Page', 'Page'), ('24', '24'), ('32Tsai', '32Tsai'), ('et', 'et'), ('al', 'al'), ('.', '.')]


------------------- Sentence 2 -------------------

Journal of Big Data  (2015) 2:21

>> Tokens are: 
 ['Journal', 'Big', 'Data', '(', '2015', ')', '2:21']

>> Bigrams are: 
 [('Journal', 'Big'), ('Big', 'Data'), ('Data', '('), ('(', '2015'), ('2015', ')'), (')', '2:21')]

>> Trigrams are: 
 [('Journal', 'Big', 'Data'), ('Big', 'Data', '('), ('Data', '(', '2015'), ('(', '2015', ')'), ('2015', ')', '2:21')]

>> POS Tags are: 
 [('Journal', 'NNP'), ('Big', 'NNP'), ('Data', 'NNP'), ('(', '('), ('2015', 'CD'), (')', ')'), ('2:21', 'CD')]

>> Noun Phrases are: 
 ['Journal Big Data']

>> Named Entities are: 
 [('PERSON', 'Journal')] 

>> Stemming using Porter Stemmer: 
 [('Journal', 'journal'), ('Big', 'big'), ('Data', 'data'), ('(', '('), ('2015', '2015'), (')', ')'), ('2:21', '2:21')]

>> Stemming using Snowball Stemmer: 
 [('Journal', 'journal'), ('Big', 'big'), ('Data', 'data'), ('(', '('), ('2015', '2015'), (')', ')'), ('2:21', '2:21')]

>> Lemmatization: 
 [('Journal', 'Journal'), ('Big', 'Big'), ('Data', 'Data'), ('(', '('), ('2015', '2015'), (')', ')'), ('2:21', '2:21')]



========================================== PARAGRAPH 366 ===========================================

Communication between systems 

------------------- Sentence 1 -------------------

Communication between systems

>> Tokens are: 
 ['Communication', 'systems']

>> Bigrams are: 
 [('Communication', 'systems')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Communication', 'NN'), ('systems', 'NNS')]

>> Noun Phrases are: 
 ['Communication systems']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Communication', 'commun'), ('systems', 'system')]

>> Stemming using Snowball Stemmer: 
 [('Communication', 'communic'), ('systems', 'system')]

>> Lemmatization: 
 [('Communication', 'Communication'), ('systems', 'system')]



========================================== PARAGRAPH 367 ===========================================

Since most big data analytics systems will be designed for parallel computing, and they  typically will work on other systems (e.g.-, cloud platform) or work with other systems  (e.g.-, search engine or knowledge base), the communication between the big data analyt- ics and other systems will strongly impact the performance of the whole process of KDD.  The first research issue for the communication is that the communication cost will incur  between systems of data analytics. How to reduce the communication cost will be the  very first thing that the data scientists need to care. Another research issue for the com- munication is how the big data analytics communicates with other systems. The con- sistency of data between different systems, modules, and operators is also an important  open issue on the communication between systems. Because the communication will  appear more frequently between systems of big data analytics, how to reduce the cost of  communication and how to make the communication between these systems as reliable  as possible will be the two important open issues for big data analytics. 

------------------- Sentence 1 -------------------

Since most big data analytics systems will be designed for parallel computing, and they  typically will work on other systems (e.g.-, cloud platform) or work with other systems  (e.g.-, search engine or knowledge base), the communication between the big data analyt- ics and other systems will strongly impact the performance of the whole process of KDD.

>> Tokens are: 
 ['Since', 'big', 'data', 'analytics', 'systems', 'designed', 'parallel', 'computing', ',', 'typically', 'work', 'systems', '(', 'e.g.-', ',', 'cloud', 'platform', ')', 'work', 'systems', '(', 'e.g.-', ',', 'search', 'engine', 'knowledge', 'base', ')', ',', 'communication', 'big', 'data', 'analyt-', 'ics', 'systems', 'strongly', 'impact', 'performance', 'whole', 'process', 'KDD', '.']

>> Bigrams are: 
 [('Since', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', 'systems'), ('systems', 'designed'), ('designed', 'parallel'), ('parallel', 'computing'), ('computing', ','), (',', 'typically'), ('typically', 'work'), ('work', 'systems'), ('systems', '('), ('(', 'e.g.-'), ('e.g.-', ','), (',', 'cloud'), ('cloud', 'platform'), ('platform', ')'), (')', 'work'), ('work', 'systems'), ('systems', '('), ('(', 'e.g.-'), ('e.g.-', ','), (',', 'search'), ('search', 'engine'), ('engine', 'knowledge'), ('knowledge', 'base'), ('base', ')'), (')', ','), (',', 'communication'), ('communication', 'big'), ('big', 'data'), ('data', 'analyt-'), ('analyt-', 'ics'), ('ics', 'systems'), ('systems', 'strongly'), ('strongly', 'impact'), ('impact', 'performance'), ('performance', 'whole'), ('whole', 'process'), ('process', 'KDD'), ('KDD', '.')]

>> Trigrams are: 
 [('Since', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', 'systems'), ('analytics', 'systems', 'designed'), ('systems', 'designed', 'parallel'), ('designed', 'parallel', 'computing'), ('parallel', 'computing', ','), ('computing', ',', 'typically'), (',', 'typically', 'work'), ('typically', 'work', 'systems'), ('work', 'systems', '('), ('systems', '(', 'e.g.-'), ('(', 'e.g.-', ','), ('e.g.-', ',', 'cloud'), (',', 'cloud', 'platform'), ('cloud', 'platform', ')'), ('platform', ')', 'work'), (')', 'work', 'systems'), ('work', 'systems', '('), ('systems', '(', 'e.g.-'), ('(', 'e.g.-', ','), ('e.g.-', ',', 'search'), (',', 'search', 'engine'), ('search', 'engine', 'knowledge'), ('engine', 'knowledge', 'base'), ('knowledge', 'base', ')'), ('base', ')', ','), (')', ',', 'communication'), (',', 'communication', 'big'), ('communication', 'big', 'data'), ('big', 'data', 'analyt-'), ('data', 'analyt-', 'ics'), ('analyt-', 'ics', 'systems'), ('ics', 'systems', 'strongly'), ('systems', 'strongly', 'impact'), ('strongly', 'impact', 'performance'), ('impact', 'performance', 'whole'), ('performance', 'whole', 'process'), ('whole', 'process', 'KDD'), ('process', 'KDD', '.')]

>> POS Tags are: 
 [('Since', 'IN'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('systems', 'NNS'), ('designed', 'VBN'), ('parallel', 'JJ'), ('computing', 'NN'), (',', ','), ('typically', 'RB'), ('work', 'NN'), ('systems', 'NNS'), ('(', '('), ('e.g.-', 'JJ'), (',', ','), ('cloud', 'JJ'), ('platform', 'NN'), (')', ')'), ('work', 'NN'), ('systems', 'NNS'), ('(', '('), ('e.g.-', 'JJ'), (',', ','), ('search', 'JJ'), ('engine', 'NN'), ('knowledge', 'NN'), ('base', 'NN'), (')', ')'), (',', ','), ('communication', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('analyt-', 'JJ'), ('ics', 'NNS'), ('systems', 'NNS'), ('strongly', 'RB'), ('impact', 'JJ'), ('performance', 'NN'), ('whole', 'JJ'), ('process', 'NN'), ('KDD', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['big data analytics systems', 'parallel computing', 'work systems', 'cloud platform', 'work systems', 'search engine knowledge base', 'communication', 'big data', 'analyt- ics systems', 'impact performance', 'whole process KDD']

>> Named Entities are: 
 [('ORGANIZATION', 'KDD')] 

>> Stemming using Porter Stemmer: 
 [('Since', 'sinc'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('systems', 'system'), ('designed', 'design'), ('parallel', 'parallel'), ('computing', 'comput'), (',', ','), ('typically', 'typic'), ('work', 'work'), ('systems', 'system'), ('(', '('), ('e.g.-', 'e.g.-'), (',', ','), ('cloud', 'cloud'), ('platform', 'platform'), (')', ')'), ('work', 'work'), ('systems', 'system'), ('(', '('), ('e.g.-', 'e.g.-'), (',', ','), ('search', 'search'), ('engine', 'engin'), ('knowledge', 'knowledg'), ('base', 'base'), (')', ')'), (',', ','), ('communication', 'commun'), ('big', 'big'), ('data', 'data'), ('analyt-', 'analyt-'), ('ics', 'ic'), ('systems', 'system'), ('strongly', 'strongli'), ('impact', 'impact'), ('performance', 'perform'), ('whole', 'whole'), ('process', 'process'), ('KDD', 'kdd'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Since', 'sinc'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('systems', 'system'), ('designed', 'design'), ('parallel', 'parallel'), ('computing', 'comput'), (',', ','), ('typically', 'typic'), ('work', 'work'), ('systems', 'system'), ('(', '('), ('e.g.-', 'e.g.-'), (',', ','), ('cloud', 'cloud'), ('platform', 'platform'), (')', ')'), ('work', 'work'), ('systems', 'system'), ('(', '('), ('e.g.-', 'e.g.-'), (',', ','), ('search', 'search'), ('engine', 'engin'), ('knowledge', 'knowledg'), ('base', 'base'), (')', ')'), (',', ','), ('communication', 'communic'), ('big', 'big'), ('data', 'data'), ('analyt-', 'analyt-'), ('ics', 'ic'), ('systems', 'system'), ('strongly', 'strong'), ('impact', 'impact'), ('performance', 'perform'), ('whole', 'whole'), ('process', 'process'), ('KDD', 'kdd'), ('.', '.')]

>> Lemmatization: 
 [('Since', 'Since'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('systems', 'system'), ('designed', 'designed'), ('parallel', 'parallel'), ('computing', 'computing'), (',', ','), ('typically', 'typically'), ('work', 'work'), ('systems', 'system'), ('(', '('), ('e.g.-', 'e.g.-'), (',', ','), ('cloud', 'cloud'), ('platform', 'platform'), (')', ')'), ('work', 'work'), ('systems', 'system'), ('(', '('), ('e.g.-', 'e.g.-'), (',', ','), ('search', 'search'), ('engine', 'engine'), ('knowledge', 'knowledge'), ('base', 'base'), (')', ')'), (',', ','), ('communication', 'communication'), ('big', 'big'), ('data', 'data'), ('analyt-', 'analyt-'), ('ics', 'ic'), ('systems', 'system'), ('strongly', 'strongly'), ('impact', 'impact'), ('performance', 'performance'), ('whole', 'whole'), ('process', 'process'), ('KDD', 'KDD'), ('.', '.')]


------------------- Sentence 2 -------------------

The first research issue for the communication is that the communication cost will incur  between systems of data analytics.

>> Tokens are: 
 ['The', 'first', 'research', 'issue', 'communication', 'communication', 'cost', 'incur', 'systems', 'data', 'analytics', '.']

>> Bigrams are: 
 [('The', 'first'), ('first', 'research'), ('research', 'issue'), ('issue', 'communication'), ('communication', 'communication'), ('communication', 'cost'), ('cost', 'incur'), ('incur', 'systems'), ('systems', 'data'), ('data', 'analytics'), ('analytics', '.')]

>> Trigrams are: 
 [('The', 'first', 'research'), ('first', 'research', 'issue'), ('research', 'issue', 'communication'), ('issue', 'communication', 'communication'), ('communication', 'communication', 'cost'), ('communication', 'cost', 'incur'), ('cost', 'incur', 'systems'), ('incur', 'systems', 'data'), ('systems', 'data', 'analytics'), ('data', 'analytics', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('first', 'JJ'), ('research', 'NN'), ('issue', 'NN'), ('communication', 'NN'), ('communication', 'NN'), ('cost', 'NN'), ('incur', 'JJ'), ('systems', 'NNS'), ('data', 'NNS'), ('analytics', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['The first research issue communication communication cost', 'incur systems data analytics']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('first', 'first'), ('research', 'research'), ('issue', 'issu'), ('communication', 'commun'), ('communication', 'commun'), ('cost', 'cost'), ('incur', 'incur'), ('systems', 'system'), ('data', 'data'), ('analytics', 'analyt'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('first', 'first'), ('research', 'research'), ('issue', 'issu'), ('communication', 'communic'), ('communication', 'communic'), ('cost', 'cost'), ('incur', 'incur'), ('systems', 'system'), ('data', 'data'), ('analytics', 'analyt'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('first', 'first'), ('research', 'research'), ('issue', 'issue'), ('communication', 'communication'), ('communication', 'communication'), ('cost', 'cost'), ('incur', 'incur'), ('systems', 'system'), ('data', 'data'), ('analytics', 'analytics'), ('.', '.')]


------------------- Sentence 3 -------------------

How to reduce the communication cost will be the  very first thing that the data scientists need to care.

>> Tokens are: 
 ['How', 'reduce', 'communication', 'cost', 'first', 'thing', 'data', 'scientists', 'need', 'care', '.']

>> Bigrams are: 
 [('How', 'reduce'), ('reduce', 'communication'), ('communication', 'cost'), ('cost', 'first'), ('first', 'thing'), ('thing', 'data'), ('data', 'scientists'), ('scientists', 'need'), ('need', 'care'), ('care', '.')]

>> Trigrams are: 
 [('How', 'reduce', 'communication'), ('reduce', 'communication', 'cost'), ('communication', 'cost', 'first'), ('cost', 'first', 'thing'), ('first', 'thing', 'data'), ('thing', 'data', 'scientists'), ('data', 'scientists', 'need'), ('scientists', 'need', 'care'), ('need', 'care', '.')]

>> POS Tags are: 
 [('How', 'WRB'), ('reduce', 'VB'), ('communication', 'NN'), ('cost', 'NN'), ('first', 'JJ'), ('thing', 'NN'), ('data', 'NNS'), ('scientists', 'NNS'), ('need', 'VBP'), ('care', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['communication cost', 'first thing data scientists', 'care']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('How', 'how'), ('reduce', 'reduc'), ('communication', 'commun'), ('cost', 'cost'), ('first', 'first'), ('thing', 'thing'), ('data', 'data'), ('scientists', 'scientist'), ('need', 'need'), ('care', 'care'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('How', 'how'), ('reduce', 'reduc'), ('communication', 'communic'), ('cost', 'cost'), ('first', 'first'), ('thing', 'thing'), ('data', 'data'), ('scientists', 'scientist'), ('need', 'need'), ('care', 'care'), ('.', '.')]

>> Lemmatization: 
 [('How', 'How'), ('reduce', 'reduce'), ('communication', 'communication'), ('cost', 'cost'), ('first', 'first'), ('thing', 'thing'), ('data', 'data'), ('scientists', 'scientist'), ('need', 'need'), ('care', 'care'), ('.', '.')]


------------------- Sentence 4 -------------------

Another research issue for the com- munication is how the big data analytics communicates with other systems.

>> Tokens are: 
 ['Another', 'research', 'issue', 'com-', 'munication', 'big', 'data', 'analytics', 'communicates', 'systems', '.']

>> Bigrams are: 
 [('Another', 'research'), ('research', 'issue'), ('issue', 'com-'), ('com-', 'munication'), ('munication', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', 'communicates'), ('communicates', 'systems'), ('systems', '.')]

>> Trigrams are: 
 [('Another', 'research', 'issue'), ('research', 'issue', 'com-'), ('issue', 'com-', 'munication'), ('com-', 'munication', 'big'), ('munication', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', 'communicates'), ('analytics', 'communicates', 'systems'), ('communicates', 'systems', '.')]

>> POS Tags are: 
 [('Another', 'DT'), ('research', 'NN'), ('issue', 'NN'), ('com-', 'JJ'), ('munication', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('communicates', 'NNS'), ('systems', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['Another research issue', 'com- munication', 'big data analytics communicates systems']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Another', 'anoth'), ('research', 'research'), ('issue', 'issu'), ('com-', 'com-'), ('munication', 'munic'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('communicates', 'commun'), ('systems', 'system'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Another', 'anoth'), ('research', 'research'), ('issue', 'issu'), ('com-', 'com-'), ('munication', 'munic'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('communicates', 'communic'), ('systems', 'system'), ('.', '.')]

>> Lemmatization: 
 [('Another', 'Another'), ('research', 'research'), ('issue', 'issue'), ('com-', 'com-'), ('munication', 'munication'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('communicates', 'communicates'), ('systems', 'system'), ('.', '.')]


------------------- Sentence 5 -------------------

The con- sistency of data between different systems, modules, and operators is also an important  open issue on the communication between systems.

>> Tokens are: 
 ['The', 'con-', 'sistency', 'data', 'different', 'systems', ',', 'modules', ',', 'operators', 'also', 'important', 'open', 'issue', 'communication', 'systems', '.']

>> Bigrams are: 
 [('The', 'con-'), ('con-', 'sistency'), ('sistency', 'data'), ('data', 'different'), ('different', 'systems'), ('systems', ','), (',', 'modules'), ('modules', ','), (',', 'operators'), ('operators', 'also'), ('also', 'important'), ('important', 'open'), ('open', 'issue'), ('issue', 'communication'), ('communication', 'systems'), ('systems', '.')]

>> Trigrams are: 
 [('The', 'con-', 'sistency'), ('con-', 'sistency', 'data'), ('sistency', 'data', 'different'), ('data', 'different', 'systems'), ('different', 'systems', ','), ('systems', ',', 'modules'), (',', 'modules', ','), ('modules', ',', 'operators'), (',', 'operators', 'also'), ('operators', 'also', 'important'), ('also', 'important', 'open'), ('important', 'open', 'issue'), ('open', 'issue', 'communication'), ('issue', 'communication', 'systems'), ('communication', 'systems', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('con-', 'JJ'), ('sistency', 'NN'), ('data', 'NNS'), ('different', 'JJ'), ('systems', 'NNS'), (',', ','), ('modules', 'NNS'), (',', ','), ('operators', 'NNS'), ('also', 'RB'), ('important', 'JJ'), ('open', 'JJ'), ('issue', 'NN'), ('communication', 'NN'), ('systems', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['The con- sistency data', 'different systems', 'modules', 'operators', 'important open issue communication systems']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('con-', 'con-'), ('sistency', 'sistenc'), ('data', 'data'), ('different', 'differ'), ('systems', 'system'), (',', ','), ('modules', 'modul'), (',', ','), ('operators', 'oper'), ('also', 'also'), ('important', 'import'), ('open', 'open'), ('issue', 'issu'), ('communication', 'commun'), ('systems', 'system'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('con-', 'con-'), ('sistency', 'sistenc'), ('data', 'data'), ('different', 'differ'), ('systems', 'system'), (',', ','), ('modules', 'modul'), (',', ','), ('operators', 'oper'), ('also', 'also'), ('important', 'import'), ('open', 'open'), ('issue', 'issu'), ('communication', 'communic'), ('systems', 'system'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('con-', 'con-'), ('sistency', 'sistency'), ('data', 'data'), ('different', 'different'), ('systems', 'system'), (',', ','), ('modules', 'module'), (',', ','), ('operators', 'operator'), ('also', 'also'), ('important', 'important'), ('open', 'open'), ('issue', 'issue'), ('communication', 'communication'), ('systems', 'system'), ('.', '.')]


------------------- Sentence 6 -------------------

Because the communication will  appear more frequently between systems of big data analytics, how to reduce the cost of  communication and how to make the communication between these systems as reliable  as possible will be the two important open issues for big data analytics.

>> Tokens are: 
 ['Because', 'communication', 'appear', 'frequently', 'systems', 'big', 'data', 'analytics', ',', 'reduce', 'cost', 'communication', 'make', 'communication', 'systems', 'reliable', 'possible', 'two', 'important', 'open', 'issues', 'big', 'data', 'analytics', '.']

>> Bigrams are: 
 [('Because', 'communication'), ('communication', 'appear'), ('appear', 'frequently'), ('frequently', 'systems'), ('systems', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', ','), (',', 'reduce'), ('reduce', 'cost'), ('cost', 'communication'), ('communication', 'make'), ('make', 'communication'), ('communication', 'systems'), ('systems', 'reliable'), ('reliable', 'possible'), ('possible', 'two'), ('two', 'important'), ('important', 'open'), ('open', 'issues'), ('issues', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', '.')]

>> Trigrams are: 
 [('Because', 'communication', 'appear'), ('communication', 'appear', 'frequently'), ('appear', 'frequently', 'systems'), ('frequently', 'systems', 'big'), ('systems', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', ','), ('analytics', ',', 'reduce'), (',', 'reduce', 'cost'), ('reduce', 'cost', 'communication'), ('cost', 'communication', 'make'), ('communication', 'make', 'communication'), ('make', 'communication', 'systems'), ('communication', 'systems', 'reliable'), ('systems', 'reliable', 'possible'), ('reliable', 'possible', 'two'), ('possible', 'two', 'important'), ('two', 'important', 'open'), ('important', 'open', 'issues'), ('open', 'issues', 'big'), ('issues', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', '.')]

>> POS Tags are: 
 [('Because', 'IN'), ('communication', 'NN'), ('appear', 'VBP'), ('frequently', 'RB'), ('systems', 'NNS'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), (',', ','), ('reduce', 'VB'), ('cost', 'NN'), ('communication', 'NN'), ('make', 'VBP'), ('communication', 'NN'), ('systems', 'NNS'), ('reliable', 'JJ'), ('possible', 'JJ'), ('two', 'CD'), ('important', 'JJ'), ('open', 'JJ'), ('issues', 'NNS'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['communication', 'systems', 'big data analytics', 'cost communication', 'communication systems', 'important open issues', 'big data analytics']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Because', 'becaus'), ('communication', 'commun'), ('appear', 'appear'), ('frequently', 'frequent'), ('systems', 'system'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), (',', ','), ('reduce', 'reduc'), ('cost', 'cost'), ('communication', 'commun'), ('make', 'make'), ('communication', 'commun'), ('systems', 'system'), ('reliable', 'reliabl'), ('possible', 'possibl'), ('two', 'two'), ('important', 'import'), ('open', 'open'), ('issues', 'issu'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Because', 'becaus'), ('communication', 'communic'), ('appear', 'appear'), ('frequently', 'frequent'), ('systems', 'system'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), (',', ','), ('reduce', 'reduc'), ('cost', 'cost'), ('communication', 'communic'), ('make', 'make'), ('communication', 'communic'), ('systems', 'system'), ('reliable', 'reliabl'), ('possible', 'possibl'), ('two', 'two'), ('important', 'import'), ('open', 'open'), ('issues', 'issu'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('.', '.')]

>> Lemmatization: 
 [('Because', 'Because'), ('communication', 'communication'), ('appear', 'appear'), ('frequently', 'frequently'), ('systems', 'system'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), (',', ','), ('reduce', 'reduce'), ('cost', 'cost'), ('communication', 'communication'), ('make', 'make'), ('communication', 'communication'), ('systems', 'system'), ('reliable', 'reliable'), ('possible', 'possible'), ('two', 'two'), ('important', 'important'), ('open', 'open'), ('issues', 'issue'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('.', '.')]



========================================== PARAGRAPH 368 ===========================================

Bottlenecks on data analytics system 

------------------- Sentence 1 -------------------

Bottlenecks on data analytics system

>> Tokens are: 
 ['Bottlenecks', 'data', 'analytics', 'system']

>> Bigrams are: 
 [('Bottlenecks', 'data'), ('data', 'analytics'), ('analytics', 'system')]

>> Trigrams are: 
 [('Bottlenecks', 'data', 'analytics'), ('data', 'analytics', 'system')]

>> POS Tags are: 
 [('Bottlenecks', 'NNP'), ('data', 'NNS'), ('analytics', 'NNS'), ('system', 'NN')]

>> Noun Phrases are: 
 ['Bottlenecks data analytics system']

>> Named Entities are: 
 [('GPE', 'Bottlenecks')] 

>> Stemming using Porter Stemmer: 
 [('Bottlenecks', 'bottleneck'), ('data', 'data'), ('analytics', 'analyt'), ('system', 'system')]

>> Stemming using Snowball Stemmer: 
 [('Bottlenecks', 'bottleneck'), ('data', 'data'), ('analytics', 'analyt'), ('system', 'system')]

>> Lemmatization: 
 [('Bottlenecks', 'Bottlenecks'), ('data', 'data'), ('analytics', 'analytics'), ('system', 'system')]



========================================== PARAGRAPH 369 ===========================================

The bottlenecks will be appeared in different places of the data analytics for big data  because the environments, systems, and input data have changed which are different  from the traditional data analytics. The data deluge of big data will fill up the “input” sys- tem of data analytics, and it will also increase the computation load of the data “analysis”  system. This situation is just like the torrent of water (i.e.-, data deluge) rushed down the  mountain (i.e.-, data analytics), how to split it and how to avoid it flowing into a narrow  place (e.g.-, the operator is not able to handle the input data) will be the most important  things to avoid the bottlenecks in data analytics system. One of the current solutions  to the avoidance of bottlenecks on a data analytics system is to add more computation  resources while the other is to split the analysis works to different computation nodes. A  complete consideration for the whole data analytics to avoid the bottlenecks of that kind  of analytics system is still needed for big data. 

------------------- Sentence 1 -------------------

The bottlenecks will be appeared in different places of the data analytics for big data  because the environments, systems, and input data have changed which are different  from the traditional data analytics.

>> Tokens are: 
 ['The', 'bottlenecks', 'appeared', 'different', 'places', 'data', 'analytics', 'big', 'data', 'environments', ',', 'systems', ',', 'input', 'data', 'changed', 'different', 'traditional', 'data', 'analytics', '.']

>> Bigrams are: 
 [('The', 'bottlenecks'), ('bottlenecks', 'appeared'), ('appeared', 'different'), ('different', 'places'), ('places', 'data'), ('data', 'analytics'), ('analytics', 'big'), ('big', 'data'), ('data', 'environments'), ('environments', ','), (',', 'systems'), ('systems', ','), (',', 'input'), ('input', 'data'), ('data', 'changed'), ('changed', 'different'), ('different', 'traditional'), ('traditional', 'data'), ('data', 'analytics'), ('analytics', '.')]

>> Trigrams are: 
 [('The', 'bottlenecks', 'appeared'), ('bottlenecks', 'appeared', 'different'), ('appeared', 'different', 'places'), ('different', 'places', 'data'), ('places', 'data', 'analytics'), ('data', 'analytics', 'big'), ('analytics', 'big', 'data'), ('big', 'data', 'environments'), ('data', 'environments', ','), ('environments', ',', 'systems'), (',', 'systems', ','), ('systems', ',', 'input'), (',', 'input', 'data'), ('input', 'data', 'changed'), ('data', 'changed', 'different'), ('changed', 'different', 'traditional'), ('different', 'traditional', 'data'), ('traditional', 'data', 'analytics'), ('data', 'analytics', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('bottlenecks', 'NNS'), ('appeared', 'VBD'), ('different', 'JJ'), ('places', 'NNS'), ('data', 'VBP'), ('analytics', 'NNS'), ('big', 'JJ'), ('data', 'NNS'), ('environments', 'NNS'), (',', ','), ('systems', 'NNS'), (',', ','), ('input', 'NN'), ('data', 'NNS'), ('changed', 'VBD'), ('different', 'JJ'), ('traditional', 'JJ'), ('data', 'NN'), ('analytics', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['The bottlenecks', 'different places', 'analytics', 'big data environments', 'systems', 'input data', 'different traditional data analytics']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('bottlenecks', 'bottleneck'), ('appeared', 'appear'), ('different', 'differ'), ('places', 'place'), ('data', 'data'), ('analytics', 'analyt'), ('big', 'big'), ('data', 'data'), ('environments', 'environ'), (',', ','), ('systems', 'system'), (',', ','), ('input', 'input'), ('data', 'data'), ('changed', 'chang'), ('different', 'differ'), ('traditional', 'tradit'), ('data', 'data'), ('analytics', 'analyt'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('bottlenecks', 'bottleneck'), ('appeared', 'appear'), ('different', 'differ'), ('places', 'place'), ('data', 'data'), ('analytics', 'analyt'), ('big', 'big'), ('data', 'data'), ('environments', 'environ'), (',', ','), ('systems', 'system'), (',', ','), ('input', 'input'), ('data', 'data'), ('changed', 'chang'), ('different', 'differ'), ('traditional', 'tradit'), ('data', 'data'), ('analytics', 'analyt'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('bottlenecks', 'bottleneck'), ('appeared', 'appeared'), ('different', 'different'), ('places', 'place'), ('data', 'data'), ('analytics', 'analytics'), ('big', 'big'), ('data', 'data'), ('environments', 'environment'), (',', ','), ('systems', 'system'), (',', ','), ('input', 'input'), ('data', 'data'), ('changed', 'changed'), ('different', 'different'), ('traditional', 'traditional'), ('data', 'data'), ('analytics', 'analytics'), ('.', '.')]


------------------- Sentence 2 -------------------

The data deluge of big data will fill up the “input” sys- tem of data analytics, and it will also increase the computation load of the data “analysis”  system.

>> Tokens are: 
 ['The', 'data', 'deluge', 'big', 'data', 'fill', '“', 'input', '”', 'sys-', 'tem', 'data', 'analytics', ',', 'also', 'increase', 'computation', 'load', 'data', '“', 'analysis', '”', 'system', '.']

>> Bigrams are: 
 [('The', 'data'), ('data', 'deluge'), ('deluge', 'big'), ('big', 'data'), ('data', 'fill'), ('fill', '“'), ('“', 'input'), ('input', '”'), ('”', 'sys-'), ('sys-', 'tem'), ('tem', 'data'), ('data', 'analytics'), ('analytics', ','), (',', 'also'), ('also', 'increase'), ('increase', 'computation'), ('computation', 'load'), ('load', 'data'), ('data', '“'), ('“', 'analysis'), ('analysis', '”'), ('”', 'system'), ('system', '.')]

>> Trigrams are: 
 [('The', 'data', 'deluge'), ('data', 'deluge', 'big'), ('deluge', 'big', 'data'), ('big', 'data', 'fill'), ('data', 'fill', '“'), ('fill', '“', 'input'), ('“', 'input', '”'), ('input', '”', 'sys-'), ('”', 'sys-', 'tem'), ('sys-', 'tem', 'data'), ('tem', 'data', 'analytics'), ('data', 'analytics', ','), ('analytics', ',', 'also'), (',', 'also', 'increase'), ('also', 'increase', 'computation'), ('increase', 'computation', 'load'), ('computation', 'load', 'data'), ('load', 'data', '“'), ('data', '“', 'analysis'), ('“', 'analysis', '”'), ('analysis', '”', 'system'), ('”', 'system', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('data', 'NNS'), ('deluge', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('fill', 'NN'), ('“', 'NNP'), ('input', 'NN'), ('”', 'NNP'), ('sys-', 'JJ'), ('tem', 'NN'), ('data', 'NNS'), ('analytics', 'NNS'), (',', ','), ('also', 'RB'), ('increase', 'VB'), ('computation', 'NN'), ('load', 'NN'), ('data', 'NNS'), ('“', 'NN'), ('analysis', 'NN'), ('”', 'NN'), ('system', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['The data deluge', 'big data fill “ input ”', 'sys- tem data analytics', 'computation load data “ analysis ” system']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('data', 'data'), ('deluge', 'delug'), ('big', 'big'), ('data', 'data'), ('fill', 'fill'), ('“', '“'), ('input', 'input'), ('”', '”'), ('sys-', 'sys-'), ('tem', 'tem'), ('data', 'data'), ('analytics', 'analyt'), (',', ','), ('also', 'also'), ('increase', 'increas'), ('computation', 'comput'), ('load', 'load'), ('data', 'data'), ('“', '“'), ('analysis', 'analysi'), ('”', '”'), ('system', 'system'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('data', 'data'), ('deluge', 'delug'), ('big', 'big'), ('data', 'data'), ('fill', 'fill'), ('“', '“'), ('input', 'input'), ('”', '”'), ('sys-', 'sys-'), ('tem', 'tem'), ('data', 'data'), ('analytics', 'analyt'), (',', ','), ('also', 'also'), ('increase', 'increas'), ('computation', 'comput'), ('load', 'load'), ('data', 'data'), ('“', '“'), ('analysis', 'analysi'), ('”', '”'), ('system', 'system'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('data', 'data'), ('deluge', 'deluge'), ('big', 'big'), ('data', 'data'), ('fill', 'fill'), ('“', '“'), ('input', 'input'), ('”', '”'), ('sys-', 'sys-'), ('tem', 'tem'), ('data', 'data'), ('analytics', 'analytics'), (',', ','), ('also', 'also'), ('increase', 'increase'), ('computation', 'computation'), ('load', 'load'), ('data', 'data'), ('“', '“'), ('analysis', 'analysis'), ('”', '”'), ('system', 'system'), ('.', '.')]


------------------- Sentence 3 -------------------

This situation is just like the torrent of water (i.e.-, data deluge) rushed down the  mountain (i.e.-, data analytics), how to split it and how to avoid it flowing into a narrow  place (e.g.-, the operator is not able to handle the input data) will be the most important  things to avoid the bottlenecks in data analytics system.

>> Tokens are: 
 ['This', 'situation', 'like', 'torrent', 'water', '(', 'i.e.-', ',', 'data', 'deluge', ')', 'rushed', 'mountain', '(', 'i.e.-', ',', 'data', 'analytics', ')', ',', 'split', 'avoid', 'flowing', 'narrow', 'place', '(', 'e.g.-', ',', 'operator', 'able', 'handle', 'input', 'data', ')', 'important', 'things', 'avoid', 'bottlenecks', 'data', 'analytics', 'system', '.']

>> Bigrams are: 
 [('This', 'situation'), ('situation', 'like'), ('like', 'torrent'), ('torrent', 'water'), ('water', '('), ('(', 'i.e.-'), ('i.e.-', ','), (',', 'data'), ('data', 'deluge'), ('deluge', ')'), (')', 'rushed'), ('rushed', 'mountain'), ('mountain', '('), ('(', 'i.e.-'), ('i.e.-', ','), (',', 'data'), ('data', 'analytics'), ('analytics', ')'), (')', ','), (',', 'split'), ('split', 'avoid'), ('avoid', 'flowing'), ('flowing', 'narrow'), ('narrow', 'place'), ('place', '('), ('(', 'e.g.-'), ('e.g.-', ','), (',', 'operator'), ('operator', 'able'), ('able', 'handle'), ('handle', 'input'), ('input', 'data'), ('data', ')'), (')', 'important'), ('important', 'things'), ('things', 'avoid'), ('avoid', 'bottlenecks'), ('bottlenecks', 'data'), ('data', 'analytics'), ('analytics', 'system'), ('system', '.')]

>> Trigrams are: 
 [('This', 'situation', 'like'), ('situation', 'like', 'torrent'), ('like', 'torrent', 'water'), ('torrent', 'water', '('), ('water', '(', 'i.e.-'), ('(', 'i.e.-', ','), ('i.e.-', ',', 'data'), (',', 'data', 'deluge'), ('data', 'deluge', ')'), ('deluge', ')', 'rushed'), (')', 'rushed', 'mountain'), ('rushed', 'mountain', '('), ('mountain', '(', 'i.e.-'), ('(', 'i.e.-', ','), ('i.e.-', ',', 'data'), (',', 'data', 'analytics'), ('data', 'analytics', ')'), ('analytics', ')', ','), (')', ',', 'split'), (',', 'split', 'avoid'), ('split', 'avoid', 'flowing'), ('avoid', 'flowing', 'narrow'), ('flowing', 'narrow', 'place'), ('narrow', 'place', '('), ('place', '(', 'e.g.-'), ('(', 'e.g.-', ','), ('e.g.-', ',', 'operator'), (',', 'operator', 'able'), ('operator', 'able', 'handle'), ('able', 'handle', 'input'), ('handle', 'input', 'data'), ('input', 'data', ')'), ('data', ')', 'important'), (')', 'important', 'things'), ('important', 'things', 'avoid'), ('things', 'avoid', 'bottlenecks'), ('avoid', 'bottlenecks', 'data'), ('bottlenecks', 'data', 'analytics'), ('data', 'analytics', 'system'), ('analytics', 'system', '.')]

>> POS Tags are: 
 [('This', 'DT'), ('situation', 'NN'), ('like', 'IN'), ('torrent', 'JJ'), ('water', 'NN'), ('(', '('), ('i.e.-', 'JJ'), (',', ','), ('data', 'NNS'), ('deluge', 'NN'), (')', ')'), ('rushed', 'VBD'), ('mountain', 'NN'), ('(', '('), ('i.e.-', 'JJ'), (',', ','), ('data', 'NNS'), ('analytics', 'NNS'), (')', ')'), (',', ','), ('split', 'JJ'), ('avoid', 'VBP'), ('flowing', 'VBG'), ('narrow', 'JJ'), ('place', 'NN'), ('(', '('), ('e.g.-', 'JJ'), (',', ','), ('operator', 'NN'), ('able', 'JJ'), ('handle', 'NN'), ('input', 'NN'), ('data', 'NNS'), (')', ')'), ('important', 'JJ'), ('things', 'NNS'), ('avoid', 'VBP'), ('bottlenecks', 'NNS'), ('data', 'VBP'), ('analytics', 'NNS'), ('system', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['This situation', 'torrent water', 'data deluge', 'mountain', 'data analytics', 'narrow place', 'operator', 'able handle input data', 'important things', 'bottlenecks', 'analytics system']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('This', 'thi'), ('situation', 'situat'), ('like', 'like'), ('torrent', 'torrent'), ('water', 'water'), ('(', '('), ('i.e.-', 'i.e.-'), (',', ','), ('data', 'data'), ('deluge', 'delug'), (')', ')'), ('rushed', 'rush'), ('mountain', 'mountain'), ('(', '('), ('i.e.-', 'i.e.-'), (',', ','), ('data', 'data'), ('analytics', 'analyt'), (')', ')'), (',', ','), ('split', 'split'), ('avoid', 'avoid'), ('flowing', 'flow'), ('narrow', 'narrow'), ('place', 'place'), ('(', '('), ('e.g.-', 'e.g.-'), (',', ','), ('operator', 'oper'), ('able', 'abl'), ('handle', 'handl'), ('input', 'input'), ('data', 'data'), (')', ')'), ('important', 'import'), ('things', 'thing'), ('avoid', 'avoid'), ('bottlenecks', 'bottleneck'), ('data', 'data'), ('analytics', 'analyt'), ('system', 'system'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('This', 'this'), ('situation', 'situat'), ('like', 'like'), ('torrent', 'torrent'), ('water', 'water'), ('(', '('), ('i.e.-', 'i.e.-'), (',', ','), ('data', 'data'), ('deluge', 'delug'), (')', ')'), ('rushed', 'rush'), ('mountain', 'mountain'), ('(', '('), ('i.e.-', 'i.e.-'), (',', ','), ('data', 'data'), ('analytics', 'analyt'), (')', ')'), (',', ','), ('split', 'split'), ('avoid', 'avoid'), ('flowing', 'flow'), ('narrow', 'narrow'), ('place', 'place'), ('(', '('), ('e.g.-', 'e.g.-'), (',', ','), ('operator', 'oper'), ('able', 'abl'), ('handle', 'handl'), ('input', 'input'), ('data', 'data'), (')', ')'), ('important', 'import'), ('things', 'thing'), ('avoid', 'avoid'), ('bottlenecks', 'bottleneck'), ('data', 'data'), ('analytics', 'analyt'), ('system', 'system'), ('.', '.')]

>> Lemmatization: 
 [('This', 'This'), ('situation', 'situation'), ('like', 'like'), ('torrent', 'torrent'), ('water', 'water'), ('(', '('), ('i.e.-', 'i.e.-'), (',', ','), ('data', 'data'), ('deluge', 'deluge'), (')', ')'), ('rushed', 'rushed'), ('mountain', 'mountain'), ('(', '('), ('i.e.-', 'i.e.-'), (',', ','), ('data', 'data'), ('analytics', 'analytics'), (')', ')'), (',', ','), ('split', 'split'), ('avoid', 'avoid'), ('flowing', 'flowing'), ('narrow', 'narrow'), ('place', 'place'), ('(', '('), ('e.g.-', 'e.g.-'), (',', ','), ('operator', 'operator'), ('able', 'able'), ('handle', 'handle'), ('input', 'input'), ('data', 'data'), (')', ')'), ('important', 'important'), ('things', 'thing'), ('avoid', 'avoid'), ('bottlenecks', 'bottleneck'), ('data', 'data'), ('analytics', 'analytics'), ('system', 'system'), ('.', '.')]


------------------- Sentence 4 -------------------

One of the current solutions  to the avoidance of bottlenecks on a data analytics system is to add more computation  resources while the other is to split the analysis works to different computation nodes.

>> Tokens are: 
 ['One', 'current', 'solutions', 'avoidance', 'bottlenecks', 'data', 'analytics', 'system', 'add', 'computation', 'resources', 'split', 'analysis', 'works', 'different', 'computation', 'nodes', '.']

>> Bigrams are: 
 [('One', 'current'), ('current', 'solutions'), ('solutions', 'avoidance'), ('avoidance', 'bottlenecks'), ('bottlenecks', 'data'), ('data', 'analytics'), ('analytics', 'system'), ('system', 'add'), ('add', 'computation'), ('computation', 'resources'), ('resources', 'split'), ('split', 'analysis'), ('analysis', 'works'), ('works', 'different'), ('different', 'computation'), ('computation', 'nodes'), ('nodes', '.')]

>> Trigrams are: 
 [('One', 'current', 'solutions'), ('current', 'solutions', 'avoidance'), ('solutions', 'avoidance', 'bottlenecks'), ('avoidance', 'bottlenecks', 'data'), ('bottlenecks', 'data', 'analytics'), ('data', 'analytics', 'system'), ('analytics', 'system', 'add'), ('system', 'add', 'computation'), ('add', 'computation', 'resources'), ('computation', 'resources', 'split'), ('resources', 'split', 'analysis'), ('split', 'analysis', 'works'), ('analysis', 'works', 'different'), ('works', 'different', 'computation'), ('different', 'computation', 'nodes'), ('computation', 'nodes', '.')]

>> POS Tags are: 
 [('One', 'CD'), ('current', 'JJ'), ('solutions', 'NNS'), ('avoidance', 'NN'), ('bottlenecks', 'NNS'), ('data', 'VBP'), ('analytics', 'NNS'), ('system', 'NN'), ('add', 'VBP'), ('computation', 'NN'), ('resources', 'NNS'), ('split', 'VBD'), ('analysis', 'NN'), ('works', 'NNS'), ('different', 'JJ'), ('computation', 'NN'), ('nodes', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['current solutions avoidance bottlenecks', 'analytics system', 'computation resources', 'analysis works', 'different computation nodes']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('One', 'one'), ('current', 'current'), ('solutions', 'solut'), ('avoidance', 'avoid'), ('bottlenecks', 'bottleneck'), ('data', 'data'), ('analytics', 'analyt'), ('system', 'system'), ('add', 'add'), ('computation', 'comput'), ('resources', 'resourc'), ('split', 'split'), ('analysis', 'analysi'), ('works', 'work'), ('different', 'differ'), ('computation', 'comput'), ('nodes', 'node'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('One', 'one'), ('current', 'current'), ('solutions', 'solut'), ('avoidance', 'avoid'), ('bottlenecks', 'bottleneck'), ('data', 'data'), ('analytics', 'analyt'), ('system', 'system'), ('add', 'add'), ('computation', 'comput'), ('resources', 'resourc'), ('split', 'split'), ('analysis', 'analysi'), ('works', 'work'), ('different', 'differ'), ('computation', 'comput'), ('nodes', 'node'), ('.', '.')]

>> Lemmatization: 
 [('One', 'One'), ('current', 'current'), ('solutions', 'solution'), ('avoidance', 'avoidance'), ('bottlenecks', 'bottleneck'), ('data', 'data'), ('analytics', 'analytics'), ('system', 'system'), ('add', 'add'), ('computation', 'computation'), ('resources', 'resource'), ('split', 'split'), ('analysis', 'analysis'), ('works', 'work'), ('different', 'different'), ('computation', 'computation'), ('nodes', 'node'), ('.', '.')]


------------------- Sentence 5 -------------------

A  complete consideration for the whole data analytics to avoid the bottlenecks of that kind  of analytics system is still needed for big data.

>> Tokens are: 
 ['A', 'complete', 'consideration', 'whole', 'data', 'analytics', 'avoid', 'bottlenecks', 'kind', 'analytics', 'system', 'still', 'needed', 'big', 'data', '.']

>> Bigrams are: 
 [('A', 'complete'), ('complete', 'consideration'), ('consideration', 'whole'), ('whole', 'data'), ('data', 'analytics'), ('analytics', 'avoid'), ('avoid', 'bottlenecks'), ('bottlenecks', 'kind'), ('kind', 'analytics'), ('analytics', 'system'), ('system', 'still'), ('still', 'needed'), ('needed', 'big'), ('big', 'data'), ('data', '.')]

>> Trigrams are: 
 [('A', 'complete', 'consideration'), ('complete', 'consideration', 'whole'), ('consideration', 'whole', 'data'), ('whole', 'data', 'analytics'), ('data', 'analytics', 'avoid'), ('analytics', 'avoid', 'bottlenecks'), ('avoid', 'bottlenecks', 'kind'), ('bottlenecks', 'kind', 'analytics'), ('kind', 'analytics', 'system'), ('analytics', 'system', 'still'), ('system', 'still', 'needed'), ('still', 'needed', 'big'), ('needed', 'big', 'data'), ('big', 'data', '.')]

>> POS Tags are: 
 [('A', 'DT'), ('complete', 'JJ'), ('consideration', 'NN'), ('whole', 'JJ'), ('data', 'NN'), ('analytics', 'NNS'), ('avoid', 'VBP'), ('bottlenecks', 'NNS'), ('kind', 'NN'), ('analytics', 'NNS'), ('system', 'NN'), ('still', 'RB'), ('needed', 'VBN'), ('big', 'JJ'), ('data', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['A complete consideration', 'whole data analytics', 'bottlenecks kind analytics system', 'big data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('A', 'a'), ('complete', 'complet'), ('consideration', 'consider'), ('whole', 'whole'), ('data', 'data'), ('analytics', 'analyt'), ('avoid', 'avoid'), ('bottlenecks', 'bottleneck'), ('kind', 'kind'), ('analytics', 'analyt'), ('system', 'system'), ('still', 'still'), ('needed', 'need'), ('big', 'big'), ('data', 'data'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('A', 'a'), ('complete', 'complet'), ('consideration', 'consider'), ('whole', 'whole'), ('data', 'data'), ('analytics', 'analyt'), ('avoid', 'avoid'), ('bottlenecks', 'bottleneck'), ('kind', 'kind'), ('analytics', 'analyt'), ('system', 'system'), ('still', 'still'), ('needed', 'need'), ('big', 'big'), ('data', 'data'), ('.', '.')]

>> Lemmatization: 
 [('A', 'A'), ('complete', 'complete'), ('consideration', 'consideration'), ('whole', 'whole'), ('data', 'data'), ('analytics', 'analytics'), ('avoid', 'avoid'), ('bottlenecks', 'bottleneck'), ('kind', 'kind'), ('analytics', 'analytics'), ('system', 'system'), ('still', 'still'), ('needed', 'needed'), ('big', 'big'), ('data', 'data'), ('.', '.')]



========================================== PARAGRAPH 370 ===========================================

Security issues 

------------------- Sentence 1 -------------------

Security issues

>> Tokens are: 
 ['Security', 'issues']

>> Bigrams are: 
 [('Security', 'issues')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Security', 'NN'), ('issues', 'NNS')]

>> Noun Phrases are: 
 ['Security issues']

>> Named Entities are: 
 [('GPE', 'Security')] 

>> Stemming using Porter Stemmer: 
 [('Security', 'secur'), ('issues', 'issu')]

>> Stemming using Snowball Stemmer: 
 [('Security', 'secur'), ('issues', 'issu')]

>> Lemmatization: 
 [('Security', 'Security'), ('issues', 'issue')]



========================================== PARAGRAPH 371 ===========================================

Since much more environment data and human behavior will be gathered to the big data  analytics, how to protect them will also be an open issue because without a security way  to handle the collected data, the big data analytics cannot be a reliable system. In spite of  the security that we have to tighten for big data analytics before it can gather more data  from everywhere, the fact is that until now, there are still not many studies focusing on  the security issues of the big data analytics. According to our observation, the security  issues of big data analytics can be divided into fourfold: input, data analysis, output, and  communication with other systems. For the input, it can be regarded as the data gather- ing which is relevant to the sensor, the handheld devices, and even the devices of inter- net of things. One of the important security issues on the input part of big data analytics  is to make sure that the sensors will not be compromised by the attacks. For the analysis  and input, it can be regarded as the security problem of such a system. For communi- cation with other system, the security problem is on the communications between big  data analytics and other external systems. Because of these latent problems, security has  become one of the open issues of big data analytics.

------------------- Sentence 1 -------------------

Since much more environment data and human behavior will be gathered to the big data  analytics, how to protect them will also be an open issue because without a security way  to handle the collected data, the big data analytics cannot be a reliable system.

>> Tokens are: 
 ['Since', 'much', 'environment', 'data', 'human', 'behavior', 'gathered', 'big', 'data', 'analytics', ',', 'protect', 'also', 'open', 'issue', 'without', 'security', 'way', 'handle', 'collected', 'data', ',', 'big', 'data', 'analytics', 'reliable', 'system', '.']

>> Bigrams are: 
 [('Since', 'much'), ('much', 'environment'), ('environment', 'data'), ('data', 'human'), ('human', 'behavior'), ('behavior', 'gathered'), ('gathered', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', ','), (',', 'protect'), ('protect', 'also'), ('also', 'open'), ('open', 'issue'), ('issue', 'without'), ('without', 'security'), ('security', 'way'), ('way', 'handle'), ('handle', 'collected'), ('collected', 'data'), ('data', ','), (',', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', 'reliable'), ('reliable', 'system'), ('system', '.')]

>> Trigrams are: 
 [('Since', 'much', 'environment'), ('much', 'environment', 'data'), ('environment', 'data', 'human'), ('data', 'human', 'behavior'), ('human', 'behavior', 'gathered'), ('behavior', 'gathered', 'big'), ('gathered', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', ','), ('analytics', ',', 'protect'), (',', 'protect', 'also'), ('protect', 'also', 'open'), ('also', 'open', 'issue'), ('open', 'issue', 'without'), ('issue', 'without', 'security'), ('without', 'security', 'way'), ('security', 'way', 'handle'), ('way', 'handle', 'collected'), ('handle', 'collected', 'data'), ('collected', 'data', ','), ('data', ',', 'big'), (',', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', 'reliable'), ('analytics', 'reliable', 'system'), ('reliable', 'system', '.')]

>> POS Tags are: 
 [('Since', 'IN'), ('much', 'JJ'), ('environment', 'NN'), ('data', 'NNS'), ('human', 'JJ'), ('behavior', 'NN'), ('gathered', 'VBD'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), (',', ','), ('protect', 'NN'), ('also', 'RB'), ('open', 'JJ'), ('issue', 'NN'), ('without', 'IN'), ('security', 'NN'), ('way', 'NN'), ('handle', 'NN'), ('collected', 'VBN'), ('data', 'NNS'), (',', ','), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('reliable', 'JJ'), ('system', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['much environment data', 'human behavior', 'big data analytics', 'protect', 'open issue', 'security way handle', 'data', 'big data analytics', 'reliable system']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Since', 'sinc'), ('much', 'much'), ('environment', 'environ'), ('data', 'data'), ('human', 'human'), ('behavior', 'behavior'), ('gathered', 'gather'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), (',', ','), ('protect', 'protect'), ('also', 'also'), ('open', 'open'), ('issue', 'issu'), ('without', 'without'), ('security', 'secur'), ('way', 'way'), ('handle', 'handl'), ('collected', 'collect'), ('data', 'data'), (',', ','), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('reliable', 'reliabl'), ('system', 'system'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Since', 'sinc'), ('much', 'much'), ('environment', 'environ'), ('data', 'data'), ('human', 'human'), ('behavior', 'behavior'), ('gathered', 'gather'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), (',', ','), ('protect', 'protect'), ('also', 'also'), ('open', 'open'), ('issue', 'issu'), ('without', 'without'), ('security', 'secur'), ('way', 'way'), ('handle', 'handl'), ('collected', 'collect'), ('data', 'data'), (',', ','), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('reliable', 'reliabl'), ('system', 'system'), ('.', '.')]

>> Lemmatization: 
 [('Since', 'Since'), ('much', 'much'), ('environment', 'environment'), ('data', 'data'), ('human', 'human'), ('behavior', 'behavior'), ('gathered', 'gathered'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), (',', ','), ('protect', 'protect'), ('also', 'also'), ('open', 'open'), ('issue', 'issue'), ('without', 'without'), ('security', 'security'), ('way', 'way'), ('handle', 'handle'), ('collected', 'collected'), ('data', 'data'), (',', ','), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('reliable', 'reliable'), ('system', 'system'), ('.', '.')]


------------------- Sentence 2 -------------------

In spite of  the security that we have to tighten for big data analytics before it can gather more data  from everywhere, the fact is that until now, there are still not many studies focusing on  the security issues of the big data analytics.

>> Tokens are: 
 ['In', 'spite', 'security', 'tighten', 'big', 'data', 'analytics', 'gather', 'data', 'everywhere', ',', 'fact', ',', 'still', 'many', 'studies', 'focusing', 'security', 'issues', 'big', 'data', 'analytics', '.']

>> Bigrams are: 
 [('In', 'spite'), ('spite', 'security'), ('security', 'tighten'), ('tighten', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', 'gather'), ('gather', 'data'), ('data', 'everywhere'), ('everywhere', ','), (',', 'fact'), ('fact', ','), (',', 'still'), ('still', 'many'), ('many', 'studies'), ('studies', 'focusing'), ('focusing', 'security'), ('security', 'issues'), ('issues', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', '.')]

>> Trigrams are: 
 [('In', 'spite', 'security'), ('spite', 'security', 'tighten'), ('security', 'tighten', 'big'), ('tighten', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', 'gather'), ('analytics', 'gather', 'data'), ('gather', 'data', 'everywhere'), ('data', 'everywhere', ','), ('everywhere', ',', 'fact'), (',', 'fact', ','), ('fact', ',', 'still'), (',', 'still', 'many'), ('still', 'many', 'studies'), ('many', 'studies', 'focusing'), ('studies', 'focusing', 'security'), ('focusing', 'security', 'issues'), ('security', 'issues', 'big'), ('issues', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('spite', 'JJ'), ('security', 'NN'), ('tighten', 'VBP'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('gather', 'VBP'), ('data', 'NNS'), ('everywhere', 'RB'), (',', ','), ('fact', 'NN'), (',', ','), ('still', 'RB'), ('many', 'JJ'), ('studies', 'NNS'), ('focusing', 'VBG'), ('security', 'NN'), ('issues', 'NNS'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['spite security', 'big data analytics', 'data', 'fact', 'many studies', 'security issues', 'big data analytics']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('spite', 'spite'), ('security', 'secur'), ('tighten', 'tighten'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('gather', 'gather'), ('data', 'data'), ('everywhere', 'everywher'), (',', ','), ('fact', 'fact'), (',', ','), ('still', 'still'), ('many', 'mani'), ('studies', 'studi'), ('focusing', 'focus'), ('security', 'secur'), ('issues', 'issu'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('spite', 'spite'), ('security', 'secur'), ('tighten', 'tighten'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('gather', 'gather'), ('data', 'data'), ('everywhere', 'everywher'), (',', ','), ('fact', 'fact'), (',', ','), ('still', 'still'), ('many', 'mani'), ('studies', 'studi'), ('focusing', 'focus'), ('security', 'secur'), ('issues', 'issu'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('spite', 'spite'), ('security', 'security'), ('tighten', 'tighten'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('gather', 'gather'), ('data', 'data'), ('everywhere', 'everywhere'), (',', ','), ('fact', 'fact'), (',', ','), ('still', 'still'), ('many', 'many'), ('studies', 'study'), ('focusing', 'focusing'), ('security', 'security'), ('issues', 'issue'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('.', '.')]


------------------- Sentence 3 -------------------

According to our observation, the security  issues of big data analytics can be divided into fourfold: input, data analysis, output, and  communication with other systems.

>> Tokens are: 
 ['According', 'observation', ',', 'security', 'issues', 'big', 'data', 'analytics', 'divided', 'fourfold', ':', 'input', ',', 'data', 'analysis', ',', 'output', ',', 'communication', 'systems', '.']

>> Bigrams are: 
 [('According', 'observation'), ('observation', ','), (',', 'security'), ('security', 'issues'), ('issues', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', 'divided'), ('divided', 'fourfold'), ('fourfold', ':'), (':', 'input'), ('input', ','), (',', 'data'), ('data', 'analysis'), ('analysis', ','), (',', 'output'), ('output', ','), (',', 'communication'), ('communication', 'systems'), ('systems', '.')]

>> Trigrams are: 
 [('According', 'observation', ','), ('observation', ',', 'security'), (',', 'security', 'issues'), ('security', 'issues', 'big'), ('issues', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', 'divided'), ('analytics', 'divided', 'fourfold'), ('divided', 'fourfold', ':'), ('fourfold', ':', 'input'), (':', 'input', ','), ('input', ',', 'data'), (',', 'data', 'analysis'), ('data', 'analysis', ','), ('analysis', ',', 'output'), (',', 'output', ','), ('output', ',', 'communication'), (',', 'communication', 'systems'), ('communication', 'systems', '.')]

>> POS Tags are: 
 [('According', 'VBG'), ('observation', 'NN'), (',', ','), ('security', 'NN'), ('issues', 'NNS'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('divided', 'VBD'), ('fourfold', 'NN'), (':', ':'), ('input', 'NN'), (',', ','), ('data', 'NN'), ('analysis', 'NN'), (',', ','), ('output', 'NN'), (',', ','), ('communication', 'NN'), ('systems', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['observation', 'security issues', 'big data analytics', 'fourfold', 'input', 'data analysis', 'output', 'communication systems']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('According', 'accord'), ('observation', 'observ'), (',', ','), ('security', 'secur'), ('issues', 'issu'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('divided', 'divid'), ('fourfold', 'fourfold'), (':', ':'), ('input', 'input'), (',', ','), ('data', 'data'), ('analysis', 'analysi'), (',', ','), ('output', 'output'), (',', ','), ('communication', 'commun'), ('systems', 'system'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('According', 'accord'), ('observation', 'observ'), (',', ','), ('security', 'secur'), ('issues', 'issu'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('divided', 'divid'), ('fourfold', 'fourfold'), (':', ':'), ('input', 'input'), (',', ','), ('data', 'data'), ('analysis', 'analysi'), (',', ','), ('output', 'output'), (',', ','), ('communication', 'communic'), ('systems', 'system'), ('.', '.')]

>> Lemmatization: 
 [('According', 'According'), ('observation', 'observation'), (',', ','), ('security', 'security'), ('issues', 'issue'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('divided', 'divided'), ('fourfold', 'fourfold'), (':', ':'), ('input', 'input'), (',', ','), ('data', 'data'), ('analysis', 'analysis'), (',', ','), ('output', 'output'), (',', ','), ('communication', 'communication'), ('systems', 'system'), ('.', '.')]


------------------- Sentence 4 -------------------

For the input, it can be regarded as the data gather- ing which is relevant to the sensor, the handheld devices, and even the devices of inter- net of things.

>> Tokens are: 
 ['For', 'input', ',', 'regarded', 'data', 'gather-', 'ing', 'relevant', 'sensor', ',', 'handheld', 'devices', ',', 'even', 'devices', 'inter-', 'net', 'things', '.']

>> Bigrams are: 
 [('For', 'input'), ('input', ','), (',', 'regarded'), ('regarded', 'data'), ('data', 'gather-'), ('gather-', 'ing'), ('ing', 'relevant'), ('relevant', 'sensor'), ('sensor', ','), (',', 'handheld'), ('handheld', 'devices'), ('devices', ','), (',', 'even'), ('even', 'devices'), ('devices', 'inter-'), ('inter-', 'net'), ('net', 'things'), ('things', '.')]

>> Trigrams are: 
 [('For', 'input', ','), ('input', ',', 'regarded'), (',', 'regarded', 'data'), ('regarded', 'data', 'gather-'), ('data', 'gather-', 'ing'), ('gather-', 'ing', 'relevant'), ('ing', 'relevant', 'sensor'), ('relevant', 'sensor', ','), ('sensor', ',', 'handheld'), (',', 'handheld', 'devices'), ('handheld', 'devices', ','), ('devices', ',', 'even'), (',', 'even', 'devices'), ('even', 'devices', 'inter-'), ('devices', 'inter-', 'net'), ('inter-', 'net', 'things'), ('net', 'things', '.')]

>> POS Tags are: 
 [('For', 'IN'), ('input', 'NN'), (',', ','), ('regarded', 'VBD'), ('data', 'NNS'), ('gather-', 'NNS'), ('ing', 'VBG'), ('relevant', 'JJ'), ('sensor', 'NN'), (',', ','), ('handheld', 'JJ'), ('devices', 'NNS'), (',', ','), ('even', 'RB'), ('devices', 'NNS'), ('inter-', 'JJ'), ('net', 'JJ'), ('things', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['input', 'data gather-', 'relevant sensor', 'handheld devices', 'devices', 'inter- net things']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('For', 'for'), ('input', 'input'), (',', ','), ('regarded', 'regard'), ('data', 'data'), ('gather-', 'gather-'), ('ing', 'ing'), ('relevant', 'relev'), ('sensor', 'sensor'), (',', ','), ('handheld', 'handheld'), ('devices', 'devic'), (',', ','), ('even', 'even'), ('devices', 'devic'), ('inter-', 'inter-'), ('net', 'net'), ('things', 'thing'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('For', 'for'), ('input', 'input'), (',', ','), ('regarded', 'regard'), ('data', 'data'), ('gather-', 'gather-'), ('ing', 'ing'), ('relevant', 'relev'), ('sensor', 'sensor'), (',', ','), ('handheld', 'handheld'), ('devices', 'devic'), (',', ','), ('even', 'even'), ('devices', 'devic'), ('inter-', 'inter-'), ('net', 'net'), ('things', 'thing'), ('.', '.')]

>> Lemmatization: 
 [('For', 'For'), ('input', 'input'), (',', ','), ('regarded', 'regarded'), ('data', 'data'), ('gather-', 'gather-'), ('ing', 'ing'), ('relevant', 'relevant'), ('sensor', 'sensor'), (',', ','), ('handheld', 'handheld'), ('devices', 'device'), (',', ','), ('even', 'even'), ('devices', 'device'), ('inter-', 'inter-'), ('net', 'net'), ('things', 'thing'), ('.', '.')]


------------------- Sentence 5 -------------------

One of the important security issues on the input part of big data analytics  is to make sure that the sensors will not be compromised by the attacks.

>> Tokens are: 
 ['One', 'important', 'security', 'issues', 'input', 'part', 'big', 'data', 'analytics', 'make', 'sure', 'sensors', 'compromised', 'attacks', '.']

>> Bigrams are: 
 [('One', 'important'), ('important', 'security'), ('security', 'issues'), ('issues', 'input'), ('input', 'part'), ('part', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', 'make'), ('make', 'sure'), ('sure', 'sensors'), ('sensors', 'compromised'), ('compromised', 'attacks'), ('attacks', '.')]

>> Trigrams are: 
 [('One', 'important', 'security'), ('important', 'security', 'issues'), ('security', 'issues', 'input'), ('issues', 'input', 'part'), ('input', 'part', 'big'), ('part', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', 'make'), ('analytics', 'make', 'sure'), ('make', 'sure', 'sensors'), ('sure', 'sensors', 'compromised'), ('sensors', 'compromised', 'attacks'), ('compromised', 'attacks', '.')]

>> POS Tags are: 
 [('One', 'CD'), ('important', 'JJ'), ('security', 'NN'), ('issues', 'NNS'), ('input', 'VBP'), ('part', 'NN'), ('big', 'JJ'), ('data', 'NN'), ('analytics', 'NNS'), ('make', 'VBP'), ('sure', 'JJ'), ('sensors', 'NNS'), ('compromised', 'VBD'), ('attacks', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['important security issues', 'part', 'big data analytics', 'sure sensors', 'attacks']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('One', 'one'), ('important', 'import'), ('security', 'secur'), ('issues', 'issu'), ('input', 'input'), ('part', 'part'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('make', 'make'), ('sure', 'sure'), ('sensors', 'sensor'), ('compromised', 'compromis'), ('attacks', 'attack'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('One', 'one'), ('important', 'import'), ('security', 'secur'), ('issues', 'issu'), ('input', 'input'), ('part', 'part'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('make', 'make'), ('sure', 'sure'), ('sensors', 'sensor'), ('compromised', 'compromis'), ('attacks', 'attack'), ('.', '.')]

>> Lemmatization: 
 [('One', 'One'), ('important', 'important'), ('security', 'security'), ('issues', 'issue'), ('input', 'input'), ('part', 'part'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('make', 'make'), ('sure', 'sure'), ('sensors', 'sensor'), ('compromised', 'compromised'), ('attacks', 'attack'), ('.', '.')]


------------------- Sentence 6 -------------------

For the analysis  and input, it can be regarded as the security problem of such a system.

>> Tokens are: 
 ['For', 'analysis', 'input', ',', 'regarded', 'security', 'problem', 'system', '.']

>> Bigrams are: 
 [('For', 'analysis'), ('analysis', 'input'), ('input', ','), (',', 'regarded'), ('regarded', 'security'), ('security', 'problem'), ('problem', 'system'), ('system', '.')]

>> Trigrams are: 
 [('For', 'analysis', 'input'), ('analysis', 'input', ','), ('input', ',', 'regarded'), (',', 'regarded', 'security'), ('regarded', 'security', 'problem'), ('security', 'problem', 'system'), ('problem', 'system', '.')]

>> POS Tags are: 
 [('For', 'IN'), ('analysis', 'NN'), ('input', 'NN'), (',', ','), ('regarded', 'VBD'), ('security', 'NN'), ('problem', 'NN'), ('system', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['analysis input', 'security problem system']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('For', 'for'), ('analysis', 'analysi'), ('input', 'input'), (',', ','), ('regarded', 'regard'), ('security', 'secur'), ('problem', 'problem'), ('system', 'system'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('For', 'for'), ('analysis', 'analysi'), ('input', 'input'), (',', ','), ('regarded', 'regard'), ('security', 'secur'), ('problem', 'problem'), ('system', 'system'), ('.', '.')]

>> Lemmatization: 
 [('For', 'For'), ('analysis', 'analysis'), ('input', 'input'), (',', ','), ('regarded', 'regarded'), ('security', 'security'), ('problem', 'problem'), ('system', 'system'), ('.', '.')]


------------------- Sentence 7 -------------------

For communi- cation with other system, the security problem is on the communications between big  data analytics and other external systems.

>> Tokens are: 
 ['For', 'communi-', 'cation', 'system', ',', 'security', 'problem', 'communications', 'big', 'data', 'analytics', 'external', 'systems', '.']

>> Bigrams are: 
 [('For', 'communi-'), ('communi-', 'cation'), ('cation', 'system'), ('system', ','), (',', 'security'), ('security', 'problem'), ('problem', 'communications'), ('communications', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', 'external'), ('external', 'systems'), ('systems', '.')]

>> Trigrams are: 
 [('For', 'communi-', 'cation'), ('communi-', 'cation', 'system'), ('cation', 'system', ','), ('system', ',', 'security'), (',', 'security', 'problem'), ('security', 'problem', 'communications'), ('problem', 'communications', 'big'), ('communications', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', 'external'), ('analytics', 'external', 'systems'), ('external', 'systems', '.')]

>> POS Tags are: 
 [('For', 'IN'), ('communi-', 'JJ'), ('cation', 'NN'), ('system', 'NN'), (',', ','), ('security', 'NN'), ('problem', 'NN'), ('communications', 'NNS'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('external', 'JJ'), ('systems', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['communi- cation system', 'security problem communications', 'big data analytics', 'external systems']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('For', 'for'), ('communi-', 'communi-'), ('cation', 'cation'), ('system', 'system'), (',', ','), ('security', 'secur'), ('problem', 'problem'), ('communications', 'commun'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('external', 'extern'), ('systems', 'system'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('For', 'for'), ('communi-', 'communi-'), ('cation', 'cation'), ('system', 'system'), (',', ','), ('security', 'secur'), ('problem', 'problem'), ('communications', 'communic'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('external', 'extern'), ('systems', 'system'), ('.', '.')]

>> Lemmatization: 
 [('For', 'For'), ('communi-', 'communi-'), ('cation', 'cation'), ('system', 'system'), (',', ','), ('security', 'security'), ('problem', 'problem'), ('communications', 'communication'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('external', 'external'), ('systems', 'system'), ('.', '.')]


------------------- Sentence 8 -------------------

Because of these latent problems, security has  become one of the open issues of big data analytics.

>> Tokens are: 
 ['Because', 'latent', 'problems', ',', 'security', 'become', 'one', 'open', 'issues', 'big', 'data', 'analytics', '.']

>> Bigrams are: 
 [('Because', 'latent'), ('latent', 'problems'), ('problems', ','), (',', 'security'), ('security', 'become'), ('become', 'one'), ('one', 'open'), ('open', 'issues'), ('issues', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', '.')]

>> Trigrams are: 
 [('Because', 'latent', 'problems'), ('latent', 'problems', ','), ('problems', ',', 'security'), (',', 'security', 'become'), ('security', 'become', 'one'), ('become', 'one', 'open'), ('one', 'open', 'issues'), ('open', 'issues', 'big'), ('issues', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', '.')]

>> POS Tags are: 
 [('Because', 'IN'), ('latent', 'NN'), ('problems', 'NNS'), (',', ','), ('security', 'NN'), ('become', 'VBP'), ('one', 'CD'), ('open', 'JJ'), ('issues', 'NNS'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['latent problems', 'security', 'open issues', 'big data analytics']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Because', 'becaus'), ('latent', 'latent'), ('problems', 'problem'), (',', ','), ('security', 'secur'), ('become', 'becom'), ('one', 'one'), ('open', 'open'), ('issues', 'issu'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Because', 'becaus'), ('latent', 'latent'), ('problems', 'problem'), (',', ','), ('security', 'secur'), ('become', 'becom'), ('one', 'one'), ('open', 'open'), ('issues', 'issu'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('.', '.')]

>> Lemmatization: 
 [('Because', 'Because'), ('latent', 'latent'), ('problems', 'problem'), (',', ','), ('security', 'security'), ('become', 'become'), ('one', 'one'), ('open', 'open'), ('issues', 'issue'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('.', '.')]



========================================== PARAGRAPH 372 ===========================================

Page 25 of 32Tsai et al. Journal of Big Data  (2015) 2:21  

------------------- Sentence 1 -------------------

Page 25 of 32Tsai et al.

>> Tokens are: 
 ['Page', '25', '32Tsai', 'et', 'al', '.']

>> Bigrams are: 
 [('Page', '25'), ('25', '32Tsai'), ('32Tsai', 'et'), ('et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('Page', '25', '32Tsai'), ('25', '32Tsai', 'et'), ('32Tsai', 'et', 'al'), ('et', 'al', '.')]

>> POS Tags are: 
 [('Page', 'NN'), ('25', 'CD'), ('32Tsai', 'CD'), ('et', 'NN'), ('al', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Page', 'et al']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Page', 'page'), ('25', '25'), ('32Tsai', '32tsai'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Page', 'page'), ('25', '25'), ('32Tsai', '32tsai'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('Page', 'Page'), ('25', '25'), ('32Tsai', '32Tsai'), ('et', 'et'), ('al', 'al'), ('.', '.')]


------------------- Sentence 2 -------------------

Journal of Big Data  (2015) 2:21

>> Tokens are: 
 ['Journal', 'Big', 'Data', '(', '2015', ')', '2:21']

>> Bigrams are: 
 [('Journal', 'Big'), ('Big', 'Data'), ('Data', '('), ('(', '2015'), ('2015', ')'), (')', '2:21')]

>> Trigrams are: 
 [('Journal', 'Big', 'Data'), ('Big', 'Data', '('), ('Data', '(', '2015'), ('(', '2015', ')'), ('2015', ')', '2:21')]

>> POS Tags are: 
 [('Journal', 'NNP'), ('Big', 'NNP'), ('Data', 'NNP'), ('(', '('), ('2015', 'CD'), (')', ')'), ('2:21', 'CD')]

>> Noun Phrases are: 
 ['Journal Big Data']

>> Named Entities are: 
 [('PERSON', 'Journal')] 

>> Stemming using Porter Stemmer: 
 [('Journal', 'journal'), ('Big', 'big'), ('Data', 'data'), ('(', '('), ('2015', '2015'), (')', ')'), ('2:21', '2:21')]

>> Stemming using Snowball Stemmer: 
 [('Journal', 'journal'), ('Big', 'big'), ('Data', 'data'), ('(', '('), ('2015', '2015'), (')', ')'), ('2:21', '2:21')]

>> Lemmatization: 
 [('Journal', 'Journal'), ('Big', 'Big'), ('Data', 'Data'), ('(', '('), ('2015', '2015'), (')', ')'), ('2:21', '2:21')]



========================================== PARAGRAPH 373 ===========================================

Data mining perspective 

------------------- Sentence 1 -------------------

Data mining perspective

>> Tokens are: 
 ['Data', 'mining', 'perspective']

>> Bigrams are: 
 [('Data', 'mining'), ('mining', 'perspective')]

>> Trigrams are: 
 [('Data', 'mining', 'perspective')]

>> POS Tags are: 
 [('Data', 'NNP'), ('mining', 'NN'), ('perspective', 'NN')]

>> Noun Phrases are: 
 ['Data mining perspective']

>> Named Entities are: 
 [('GPE', 'Data')] 

>> Stemming using Porter Stemmer: 
 [('Data', 'data'), ('mining', 'mine'), ('perspective', 'perspect')]

>> Stemming using Snowball Stemmer: 
 [('Data', 'data'), ('mining', 'mine'), ('perspective', 'perspect')]

>> Lemmatization: 
 [('Data', 'Data'), ('mining', 'mining'), ('perspective', 'perspective')]



========================================== PARAGRAPH 374 ===========================================

Data mining algorithm for map‑reduce solution 

------------------- Sentence 1 -------------------

Data mining algorithm for map‑reduce solution

>> Tokens are: 
 ['Data', 'mining', 'algorithm', 'map‑reduce', 'solution']

>> Bigrams are: 
 [('Data', 'mining'), ('mining', 'algorithm'), ('algorithm', 'map‑reduce'), ('map‑reduce', 'solution')]

>> Trigrams are: 
 [('Data', 'mining', 'algorithm'), ('mining', 'algorithm', 'map‑reduce'), ('algorithm', 'map‑reduce', 'solution')]

>> POS Tags are: 
 [('Data', 'NNP'), ('mining', 'NN'), ('algorithm', 'NN'), ('map‑reduce', 'NN'), ('solution', 'NN')]

>> Noun Phrases are: 
 ['Data mining algorithm map‑reduce solution']

>> Named Entities are: 
 [('GPE', 'Data')] 

>> Stemming using Porter Stemmer: 
 [('Data', 'data'), ('mining', 'mine'), ('algorithm', 'algorithm'), ('map‑reduce', 'map‑reduc'), ('solution', 'solut')]

>> Stemming using Snowball Stemmer: 
 [('Data', 'data'), ('mining', 'mine'), ('algorithm', 'algorithm'), ('map‑reduce', 'map‑reduc'), ('solution', 'solut')]

>> Lemmatization: 
 [('Data', 'Data'), ('mining', 'mining'), ('algorithm', 'algorithm'), ('map‑reduce', 'map‑reduce'), ('solution', 'solution')]



========================================== PARAGRAPH 375 ===========================================

As we mentioned in the previous sections, most of the traditional data mining algo- rithms are not designed for parallel computing; therefore, they are not particularly useful  for the big data mining. Several recent studies have attempted to modify the traditional  data mining algorithms to make them applicable to Hadoop-based platforms. As long  as porting the data mining algorithms to Hadoop is inevitable, making the data min- ing algorithms work on a map-reduce architecture is the first very thing to do to apply  traditional data mining methods to big data analytics. Unfortunately, not many studies  attempted to make the data mining and soft computing algorithms work on Hadoop  because several different backgrounds are needed to develop and design such algorithms.  For instance, the researcher and his or her research group need to have the background  in data mining and Hadoop so as to develop and design such algorithms. Another open  issue is that most data mining algorithms are designed for centralized computing; that  is, they can only work on all the data at the same time. Thus, how to make them work on  a parallel computing system is also a difficult work. The good news is that some studies  [145] have successfully applied the traditional data mining algorithms to the map-reduce  architecture. These results imply that it is possible to do so. According to our observa- tion, although the traditional mining or soft computing algorithms can be used to help  us analyze the data in big data analytics, unfortunately, until now, not many studies are  focused on it. As a consequence, it is an important open issue in big data analytics. 

------------------- Sentence 1 -------------------

As we mentioned in the previous sections, most of the traditional data mining algo- rithms are not designed for parallel computing; therefore, they are not particularly useful  for the big data mining.

>> Tokens are: 
 ['As', 'mentioned', 'previous', 'sections', ',', 'traditional', 'data', 'mining', 'algo-', 'rithms', 'designed', 'parallel', 'computing', ';', 'therefore', ',', 'particularly', 'useful', 'big', 'data', 'mining', '.']

>> Bigrams are: 
 [('As', 'mentioned'), ('mentioned', 'previous'), ('previous', 'sections'), ('sections', ','), (',', 'traditional'), ('traditional', 'data'), ('data', 'mining'), ('mining', 'algo-'), ('algo-', 'rithms'), ('rithms', 'designed'), ('designed', 'parallel'), ('parallel', 'computing'), ('computing', ';'), (';', 'therefore'), ('therefore', ','), (',', 'particularly'), ('particularly', 'useful'), ('useful', 'big'), ('big', 'data'), ('data', 'mining'), ('mining', '.')]

>> Trigrams are: 
 [('As', 'mentioned', 'previous'), ('mentioned', 'previous', 'sections'), ('previous', 'sections', ','), ('sections', ',', 'traditional'), (',', 'traditional', 'data'), ('traditional', 'data', 'mining'), ('data', 'mining', 'algo-'), ('mining', 'algo-', 'rithms'), ('algo-', 'rithms', 'designed'), ('rithms', 'designed', 'parallel'), ('designed', 'parallel', 'computing'), ('parallel', 'computing', ';'), ('computing', ';', 'therefore'), (';', 'therefore', ','), ('therefore', ',', 'particularly'), (',', 'particularly', 'useful'), ('particularly', 'useful', 'big'), ('useful', 'big', 'data'), ('big', 'data', 'mining'), ('data', 'mining', '.')]

>> POS Tags are: 
 [('As', 'IN'), ('mentioned', 'VBN'), ('previous', 'JJ'), ('sections', 'NNS'), (',', ','), ('traditional', 'JJ'), ('data', 'NNS'), ('mining', 'NN'), ('algo-', 'JJ'), ('rithms', 'NN'), ('designed', 'VBN'), ('parallel', 'JJ'), ('computing', 'NN'), (';', ':'), ('therefore', 'RB'), (',', ','), ('particularly', 'RB'), ('useful', 'JJ'), ('big', 'JJ'), ('data', 'NNS'), ('mining', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['previous sections', 'traditional data mining', 'algo- rithms', 'parallel computing', 'useful big data mining']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('As', 'as'), ('mentioned', 'mention'), ('previous', 'previou'), ('sections', 'section'), (',', ','), ('traditional', 'tradit'), ('data', 'data'), ('mining', 'mine'), ('algo-', 'algo-'), ('rithms', 'rithm'), ('designed', 'design'), ('parallel', 'parallel'), ('computing', 'comput'), (';', ';'), ('therefore', 'therefor'), (',', ','), ('particularly', 'particularli'), ('useful', 'use'), ('big', 'big'), ('data', 'data'), ('mining', 'mine'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('As', 'as'), ('mentioned', 'mention'), ('previous', 'previous'), ('sections', 'section'), (',', ','), ('traditional', 'tradit'), ('data', 'data'), ('mining', 'mine'), ('algo-', 'algo-'), ('rithms', 'rithm'), ('designed', 'design'), ('parallel', 'parallel'), ('computing', 'comput'), (';', ';'), ('therefore', 'therefor'), (',', ','), ('particularly', 'particular'), ('useful', 'use'), ('big', 'big'), ('data', 'data'), ('mining', 'mine'), ('.', '.')]

>> Lemmatization: 
 [('As', 'As'), ('mentioned', 'mentioned'), ('previous', 'previous'), ('sections', 'section'), (',', ','), ('traditional', 'traditional'), ('data', 'data'), ('mining', 'mining'), ('algo-', 'algo-'), ('rithms', 'rithms'), ('designed', 'designed'), ('parallel', 'parallel'), ('computing', 'computing'), (';', ';'), ('therefore', 'therefore'), (',', ','), ('particularly', 'particularly'), ('useful', 'useful'), ('big', 'big'), ('data', 'data'), ('mining', 'mining'), ('.', '.')]


------------------- Sentence 2 -------------------

Several recent studies have attempted to modify the traditional  data mining algorithms to make them applicable to Hadoop-based platforms.

>> Tokens are: 
 ['Several', 'recent', 'studies', 'attempted', 'modify', 'traditional', 'data', 'mining', 'algorithms', 'make', 'applicable', 'Hadoop-based', 'platforms', '.']

>> Bigrams are: 
 [('Several', 'recent'), ('recent', 'studies'), ('studies', 'attempted'), ('attempted', 'modify'), ('modify', 'traditional'), ('traditional', 'data'), ('data', 'mining'), ('mining', 'algorithms'), ('algorithms', 'make'), ('make', 'applicable'), ('applicable', 'Hadoop-based'), ('Hadoop-based', 'platforms'), ('platforms', '.')]

>> Trigrams are: 
 [('Several', 'recent', 'studies'), ('recent', 'studies', 'attempted'), ('studies', 'attempted', 'modify'), ('attempted', 'modify', 'traditional'), ('modify', 'traditional', 'data'), ('traditional', 'data', 'mining'), ('data', 'mining', 'algorithms'), ('mining', 'algorithms', 'make'), ('algorithms', 'make', 'applicable'), ('make', 'applicable', 'Hadoop-based'), ('applicable', 'Hadoop-based', 'platforms'), ('Hadoop-based', 'platforms', '.')]

>> POS Tags are: 
 [('Several', 'JJ'), ('recent', 'JJ'), ('studies', 'NNS'), ('attempted', 'VBD'), ('modify', 'JJ'), ('traditional', 'JJ'), ('data', 'NNS'), ('mining', 'NN'), ('algorithms', 'NNS'), ('make', 'VBP'), ('applicable', 'JJ'), ('Hadoop-based', 'JJ'), ('platforms', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['Several recent studies', 'modify traditional data mining algorithms', 'applicable Hadoop-based platforms']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Several', 'sever'), ('recent', 'recent'), ('studies', 'studi'), ('attempted', 'attempt'), ('modify', 'modifi'), ('traditional', 'tradit'), ('data', 'data'), ('mining', 'mine'), ('algorithms', 'algorithm'), ('make', 'make'), ('applicable', 'applic'), ('Hadoop-based', 'hadoop-bas'), ('platforms', 'platform'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Several', 'sever'), ('recent', 'recent'), ('studies', 'studi'), ('attempted', 'attempt'), ('modify', 'modifi'), ('traditional', 'tradit'), ('data', 'data'), ('mining', 'mine'), ('algorithms', 'algorithm'), ('make', 'make'), ('applicable', 'applic'), ('Hadoop-based', 'hadoop-bas'), ('platforms', 'platform'), ('.', '.')]

>> Lemmatization: 
 [('Several', 'Several'), ('recent', 'recent'), ('studies', 'study'), ('attempted', 'attempted'), ('modify', 'modify'), ('traditional', 'traditional'), ('data', 'data'), ('mining', 'mining'), ('algorithms', 'algorithm'), ('make', 'make'), ('applicable', 'applicable'), ('Hadoop-based', 'Hadoop-based'), ('platforms', 'platform'), ('.', '.')]


------------------- Sentence 3 -------------------

As long  as porting the data mining algorithms to Hadoop is inevitable, making the data min- ing algorithms work on a map-reduce architecture is the first very thing to do to apply  traditional data mining methods to big data analytics.

>> Tokens are: 
 ['As', 'long', 'porting', 'data', 'mining', 'algorithms', 'Hadoop', 'inevitable', ',', 'making', 'data', 'min-', 'ing', 'algorithms', 'work', 'map-reduce', 'architecture', 'first', 'thing', 'apply', 'traditional', 'data', 'mining', 'methods', 'big', 'data', 'analytics', '.']

>> Bigrams are: 
 [('As', 'long'), ('long', 'porting'), ('porting', 'data'), ('data', 'mining'), ('mining', 'algorithms'), ('algorithms', 'Hadoop'), ('Hadoop', 'inevitable'), ('inevitable', ','), (',', 'making'), ('making', 'data'), ('data', 'min-'), ('min-', 'ing'), ('ing', 'algorithms'), ('algorithms', 'work'), ('work', 'map-reduce'), ('map-reduce', 'architecture'), ('architecture', 'first'), ('first', 'thing'), ('thing', 'apply'), ('apply', 'traditional'), ('traditional', 'data'), ('data', 'mining'), ('mining', 'methods'), ('methods', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', '.')]

>> Trigrams are: 
 [('As', 'long', 'porting'), ('long', 'porting', 'data'), ('porting', 'data', 'mining'), ('data', 'mining', 'algorithms'), ('mining', 'algorithms', 'Hadoop'), ('algorithms', 'Hadoop', 'inevitable'), ('Hadoop', 'inevitable', ','), ('inevitable', ',', 'making'), (',', 'making', 'data'), ('making', 'data', 'min-'), ('data', 'min-', 'ing'), ('min-', 'ing', 'algorithms'), ('ing', 'algorithms', 'work'), ('algorithms', 'work', 'map-reduce'), ('work', 'map-reduce', 'architecture'), ('map-reduce', 'architecture', 'first'), ('architecture', 'first', 'thing'), ('first', 'thing', 'apply'), ('thing', 'apply', 'traditional'), ('apply', 'traditional', 'data'), ('traditional', 'data', 'mining'), ('data', 'mining', 'methods'), ('mining', 'methods', 'big'), ('methods', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', '.')]

>> POS Tags are: 
 [('As', 'IN'), ('long', 'JJ'), ('porting', 'VBG'), ('data', 'NNS'), ('mining', 'NN'), ('algorithms', 'NN'), ('Hadoop', 'NNP'), ('inevitable', 'JJ'), (',', ','), ('making', 'VBG'), ('data', 'NNS'), ('min-', 'NNS'), ('ing', 'VBG'), ('algorithms', 'JJ'), ('work', 'NN'), ('map-reduce', 'NN'), ('architecture', 'NN'), ('first', 'JJ'), ('thing', 'NN'), ('apply', 'VBP'), ('traditional', 'JJ'), ('data', 'NNS'), ('mining', 'NN'), ('methods', 'NNS'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['data mining algorithms Hadoop', 'data min-', 'algorithms work map-reduce architecture', 'first thing', 'traditional data mining methods', 'big data analytics']

>> Named Entities are: 
 [('PERSON', 'Hadoop')] 

>> Stemming using Porter Stemmer: 
 [('As', 'as'), ('long', 'long'), ('porting', 'port'), ('data', 'data'), ('mining', 'mine'), ('algorithms', 'algorithm'), ('Hadoop', 'hadoop'), ('inevitable', 'inevit'), (',', ','), ('making', 'make'), ('data', 'data'), ('min-', 'min-'), ('ing', 'ing'), ('algorithms', 'algorithm'), ('work', 'work'), ('map-reduce', 'map-reduc'), ('architecture', 'architectur'), ('first', 'first'), ('thing', 'thing'), ('apply', 'appli'), ('traditional', 'tradit'), ('data', 'data'), ('mining', 'mine'), ('methods', 'method'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('As', 'as'), ('long', 'long'), ('porting', 'port'), ('data', 'data'), ('mining', 'mine'), ('algorithms', 'algorithm'), ('Hadoop', 'hadoop'), ('inevitable', 'inevit'), (',', ','), ('making', 'make'), ('data', 'data'), ('min-', 'min-'), ('ing', 'ing'), ('algorithms', 'algorithm'), ('work', 'work'), ('map-reduce', 'map-reduc'), ('architecture', 'architectur'), ('first', 'first'), ('thing', 'thing'), ('apply', 'appli'), ('traditional', 'tradit'), ('data', 'data'), ('mining', 'mine'), ('methods', 'method'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('.', '.')]

>> Lemmatization: 
 [('As', 'As'), ('long', 'long'), ('porting', 'porting'), ('data', 'data'), ('mining', 'mining'), ('algorithms', 'algorithm'), ('Hadoop', 'Hadoop'), ('inevitable', 'inevitable'), (',', ','), ('making', 'making'), ('data', 'data'), ('min-', 'min-'), ('ing', 'ing'), ('algorithms', 'algorithm'), ('work', 'work'), ('map-reduce', 'map-reduce'), ('architecture', 'architecture'), ('first', 'first'), ('thing', 'thing'), ('apply', 'apply'), ('traditional', 'traditional'), ('data', 'data'), ('mining', 'mining'), ('methods', 'method'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('.', '.')]


------------------- Sentence 4 -------------------

Unfortunately, not many studies  attempted to make the data mining and soft computing algorithms work on Hadoop  because several different backgrounds are needed to develop and design such algorithms.

>> Tokens are: 
 ['Unfortunately', ',', 'many', 'studies', 'attempted', 'make', 'data', 'mining', 'soft', 'computing', 'algorithms', 'work', 'Hadoop', 'several', 'different', 'backgrounds', 'needed', 'develop', 'design', 'algorithms', '.']

>> Bigrams are: 
 [('Unfortunately', ','), (',', 'many'), ('many', 'studies'), ('studies', 'attempted'), ('attempted', 'make'), ('make', 'data'), ('data', 'mining'), ('mining', 'soft'), ('soft', 'computing'), ('computing', 'algorithms'), ('algorithms', 'work'), ('work', 'Hadoop'), ('Hadoop', 'several'), ('several', 'different'), ('different', 'backgrounds'), ('backgrounds', 'needed'), ('needed', 'develop'), ('develop', 'design'), ('design', 'algorithms'), ('algorithms', '.')]

>> Trigrams are: 
 [('Unfortunately', ',', 'many'), (',', 'many', 'studies'), ('many', 'studies', 'attempted'), ('studies', 'attempted', 'make'), ('attempted', 'make', 'data'), ('make', 'data', 'mining'), ('data', 'mining', 'soft'), ('mining', 'soft', 'computing'), ('soft', 'computing', 'algorithms'), ('computing', 'algorithms', 'work'), ('algorithms', 'work', 'Hadoop'), ('work', 'Hadoop', 'several'), ('Hadoop', 'several', 'different'), ('several', 'different', 'backgrounds'), ('different', 'backgrounds', 'needed'), ('backgrounds', 'needed', 'develop'), ('needed', 'develop', 'design'), ('develop', 'design', 'algorithms'), ('design', 'algorithms', '.')]

>> POS Tags are: 
 [('Unfortunately', 'RB'), (',', ','), ('many', 'JJ'), ('studies', 'NNS'), ('attempted', 'VBD'), ('make', 'VBP'), ('data', 'NNS'), ('mining', 'NN'), ('soft', 'JJ'), ('computing', 'VBG'), ('algorithms', 'JJ'), ('work', 'NN'), ('Hadoop', 'NNP'), ('several', 'JJ'), ('different', 'JJ'), ('backgrounds', 'NNS'), ('needed', 'VBN'), ('develop', 'VBP'), ('design', 'NN'), ('algorithms', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['many studies', 'data mining', 'algorithms work Hadoop', 'several different backgrounds', 'design algorithms']

>> Named Entities are: 
 [('PERSON', 'Hadoop')] 

>> Stemming using Porter Stemmer: 
 [('Unfortunately', 'unfortun'), (',', ','), ('many', 'mani'), ('studies', 'studi'), ('attempted', 'attempt'), ('make', 'make'), ('data', 'data'), ('mining', 'mine'), ('soft', 'soft'), ('computing', 'comput'), ('algorithms', 'algorithm'), ('work', 'work'), ('Hadoop', 'hadoop'), ('several', 'sever'), ('different', 'differ'), ('backgrounds', 'background'), ('needed', 'need'), ('develop', 'develop'), ('design', 'design'), ('algorithms', 'algorithm'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Unfortunately', 'unfortun'), (',', ','), ('many', 'mani'), ('studies', 'studi'), ('attempted', 'attempt'), ('make', 'make'), ('data', 'data'), ('mining', 'mine'), ('soft', 'soft'), ('computing', 'comput'), ('algorithms', 'algorithm'), ('work', 'work'), ('Hadoop', 'hadoop'), ('several', 'sever'), ('different', 'differ'), ('backgrounds', 'background'), ('needed', 'need'), ('develop', 'develop'), ('design', 'design'), ('algorithms', 'algorithm'), ('.', '.')]

>> Lemmatization: 
 [('Unfortunately', 'Unfortunately'), (',', ','), ('many', 'many'), ('studies', 'study'), ('attempted', 'attempted'), ('make', 'make'), ('data', 'data'), ('mining', 'mining'), ('soft', 'soft'), ('computing', 'computing'), ('algorithms', 'algorithm'), ('work', 'work'), ('Hadoop', 'Hadoop'), ('several', 'several'), ('different', 'different'), ('backgrounds', 'background'), ('needed', 'needed'), ('develop', 'develop'), ('design', 'design'), ('algorithms', 'algorithm'), ('.', '.')]


------------------- Sentence 5 -------------------

For instance, the researcher and his or her research group need to have the background  in data mining and Hadoop so as to develop and design such algorithms.

>> Tokens are: 
 ['For', 'instance', ',', 'researcher', 'research', 'group', 'need', 'background', 'data', 'mining', 'Hadoop', 'develop', 'design', 'algorithms', '.']

>> Bigrams are: 
 [('For', 'instance'), ('instance', ','), (',', 'researcher'), ('researcher', 'research'), ('research', 'group'), ('group', 'need'), ('need', 'background'), ('background', 'data'), ('data', 'mining'), ('mining', 'Hadoop'), ('Hadoop', 'develop'), ('develop', 'design'), ('design', 'algorithms'), ('algorithms', '.')]

>> Trigrams are: 
 [('For', 'instance', ','), ('instance', ',', 'researcher'), (',', 'researcher', 'research'), ('researcher', 'research', 'group'), ('research', 'group', 'need'), ('group', 'need', 'background'), ('need', 'background', 'data'), ('background', 'data', 'mining'), ('data', 'mining', 'Hadoop'), ('mining', 'Hadoop', 'develop'), ('Hadoop', 'develop', 'design'), ('develop', 'design', 'algorithms'), ('design', 'algorithms', '.')]

>> POS Tags are: 
 [('For', 'IN'), ('instance', 'NN'), (',', ','), ('researcher', 'JJR'), ('research', 'NN'), ('group', 'NN'), ('need', 'VBP'), ('background', 'IN'), ('data', 'NNS'), ('mining', 'VBG'), ('Hadoop', 'NNP'), ('develop', 'VB'), ('design', 'NN'), ('algorithms', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['instance', 'research group', 'data', 'Hadoop', 'design algorithms']

>> Named Entities are: 
 [('PERSON', 'Hadoop')] 

>> Stemming using Porter Stemmer: 
 [('For', 'for'), ('instance', 'instanc'), (',', ','), ('researcher', 'research'), ('research', 'research'), ('group', 'group'), ('need', 'need'), ('background', 'background'), ('data', 'data'), ('mining', 'mine'), ('Hadoop', 'hadoop'), ('develop', 'develop'), ('design', 'design'), ('algorithms', 'algorithm'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('For', 'for'), ('instance', 'instanc'), (',', ','), ('researcher', 'research'), ('research', 'research'), ('group', 'group'), ('need', 'need'), ('background', 'background'), ('data', 'data'), ('mining', 'mine'), ('Hadoop', 'hadoop'), ('develop', 'develop'), ('design', 'design'), ('algorithms', 'algorithm'), ('.', '.')]

>> Lemmatization: 
 [('For', 'For'), ('instance', 'instance'), (',', ','), ('researcher', 'researcher'), ('research', 'research'), ('group', 'group'), ('need', 'need'), ('background', 'background'), ('data', 'data'), ('mining', 'mining'), ('Hadoop', 'Hadoop'), ('develop', 'develop'), ('design', 'design'), ('algorithms', 'algorithm'), ('.', '.')]


------------------- Sentence 6 -------------------

Another open  issue is that most data mining algorithms are designed for centralized computing; that  is, they can only work on all the data at the same time.

>> Tokens are: 
 ['Another', 'open', 'issue', 'data', 'mining', 'algorithms', 'designed', 'centralized', 'computing', ';', ',', 'work', 'data', 'time', '.']

>> Bigrams are: 
 [('Another', 'open'), ('open', 'issue'), ('issue', 'data'), ('data', 'mining'), ('mining', 'algorithms'), ('algorithms', 'designed'), ('designed', 'centralized'), ('centralized', 'computing'), ('computing', ';'), (';', ','), (',', 'work'), ('work', 'data'), ('data', 'time'), ('time', '.')]

>> Trigrams are: 
 [('Another', 'open', 'issue'), ('open', 'issue', 'data'), ('issue', 'data', 'mining'), ('data', 'mining', 'algorithms'), ('mining', 'algorithms', 'designed'), ('algorithms', 'designed', 'centralized'), ('designed', 'centralized', 'computing'), ('centralized', 'computing', ';'), ('computing', ';', ','), (';', ',', 'work'), (',', 'work', 'data'), ('work', 'data', 'time'), ('data', 'time', '.')]

>> POS Tags are: 
 [('Another', 'DT'), ('open', 'JJ'), ('issue', 'NN'), ('data', 'NNS'), ('mining', 'NN'), ('algorithms', 'NN'), ('designed', 'VBN'), ('centralized', 'JJ'), ('computing', 'NN'), (';', ':'), (',', ','), ('work', 'VB'), ('data', 'NNS'), ('time', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Another open issue data mining algorithms', 'centralized computing', 'data time']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Another', 'anoth'), ('open', 'open'), ('issue', 'issu'), ('data', 'data'), ('mining', 'mine'), ('algorithms', 'algorithm'), ('designed', 'design'), ('centralized', 'central'), ('computing', 'comput'), (';', ';'), (',', ','), ('work', 'work'), ('data', 'data'), ('time', 'time'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Another', 'anoth'), ('open', 'open'), ('issue', 'issu'), ('data', 'data'), ('mining', 'mine'), ('algorithms', 'algorithm'), ('designed', 'design'), ('centralized', 'central'), ('computing', 'comput'), (';', ';'), (',', ','), ('work', 'work'), ('data', 'data'), ('time', 'time'), ('.', '.')]

>> Lemmatization: 
 [('Another', 'Another'), ('open', 'open'), ('issue', 'issue'), ('data', 'data'), ('mining', 'mining'), ('algorithms', 'algorithm'), ('designed', 'designed'), ('centralized', 'centralized'), ('computing', 'computing'), (';', ';'), (',', ','), ('work', 'work'), ('data', 'data'), ('time', 'time'), ('.', '.')]


------------------- Sentence 7 -------------------

Thus, how to make them work on  a parallel computing system is also a difficult work.

>> Tokens are: 
 ['Thus', ',', 'make', 'work', 'parallel', 'computing', 'system', 'also', 'difficult', 'work', '.']

>> Bigrams are: 
 [('Thus', ','), (',', 'make'), ('make', 'work'), ('work', 'parallel'), ('parallel', 'computing'), ('computing', 'system'), ('system', 'also'), ('also', 'difficult'), ('difficult', 'work'), ('work', '.')]

>> Trigrams are: 
 [('Thus', ',', 'make'), (',', 'make', 'work'), ('make', 'work', 'parallel'), ('work', 'parallel', 'computing'), ('parallel', 'computing', 'system'), ('computing', 'system', 'also'), ('system', 'also', 'difficult'), ('also', 'difficult', 'work'), ('difficult', 'work', '.')]

>> POS Tags are: 
 [('Thus', 'RB'), (',', ','), ('make', 'VBP'), ('work', 'NN'), ('parallel', 'RB'), ('computing', 'VBG'), ('system', 'NN'), ('also', 'RB'), ('difficult', 'JJ'), ('work', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['work', 'system', 'difficult work']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Thus', 'thu'), (',', ','), ('make', 'make'), ('work', 'work'), ('parallel', 'parallel'), ('computing', 'comput'), ('system', 'system'), ('also', 'also'), ('difficult', 'difficult'), ('work', 'work'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Thus', 'thus'), (',', ','), ('make', 'make'), ('work', 'work'), ('parallel', 'parallel'), ('computing', 'comput'), ('system', 'system'), ('also', 'also'), ('difficult', 'difficult'), ('work', 'work'), ('.', '.')]

>> Lemmatization: 
 [('Thus', 'Thus'), (',', ','), ('make', 'make'), ('work', 'work'), ('parallel', 'parallel'), ('computing', 'computing'), ('system', 'system'), ('also', 'also'), ('difficult', 'difficult'), ('work', 'work'), ('.', '.')]


------------------- Sentence 8 -------------------

The good news is that some studies  [145] have successfully applied the traditional data mining algorithms to the map-reduce  architecture.

>> Tokens are: 
 ['The', 'good', 'news', 'studies', '[', '145', ']', 'successfully', 'applied', 'traditional', 'data', 'mining', 'algorithms', 'map-reduce', 'architecture', '.']

>> Bigrams are: 
 [('The', 'good'), ('good', 'news'), ('news', 'studies'), ('studies', '['), ('[', '145'), ('145', ']'), (']', 'successfully'), ('successfully', 'applied'), ('applied', 'traditional'), ('traditional', 'data'), ('data', 'mining'), ('mining', 'algorithms'), ('algorithms', 'map-reduce'), ('map-reduce', 'architecture'), ('architecture', '.')]

>> Trigrams are: 
 [('The', 'good', 'news'), ('good', 'news', 'studies'), ('news', 'studies', '['), ('studies', '[', '145'), ('[', '145', ']'), ('145', ']', 'successfully'), (']', 'successfully', 'applied'), ('successfully', 'applied', 'traditional'), ('applied', 'traditional', 'data'), ('traditional', 'data', 'mining'), ('data', 'mining', 'algorithms'), ('mining', 'algorithms', 'map-reduce'), ('algorithms', 'map-reduce', 'architecture'), ('map-reduce', 'architecture', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('good', 'JJ'), ('news', 'NN'), ('studies', 'NNS'), ('[', 'VBP'), ('145', 'CD'), (']', 'NNP'), ('successfully', 'RB'), ('applied', 'VBD'), ('traditional', 'JJ'), ('data', 'NNS'), ('mining', 'NN'), ('algorithms', 'IN'), ('map-reduce', 'JJ'), ('architecture', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['The good news studies', ']', 'traditional data mining', 'map-reduce architecture']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('good', 'good'), ('news', 'news'), ('studies', 'studi'), ('[', '['), ('145', '145'), (']', ']'), ('successfully', 'success'), ('applied', 'appli'), ('traditional', 'tradit'), ('data', 'data'), ('mining', 'mine'), ('algorithms', 'algorithm'), ('map-reduce', 'map-reduc'), ('architecture', 'architectur'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('good', 'good'), ('news', 'news'), ('studies', 'studi'), ('[', '['), ('145', '145'), (']', ']'), ('successfully', 'success'), ('applied', 'appli'), ('traditional', 'tradit'), ('data', 'data'), ('mining', 'mine'), ('algorithms', 'algorithm'), ('map-reduce', 'map-reduc'), ('architecture', 'architectur'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('good', 'good'), ('news', 'news'), ('studies', 'study'), ('[', '['), ('145', '145'), (']', ']'), ('successfully', 'successfully'), ('applied', 'applied'), ('traditional', 'traditional'), ('data', 'data'), ('mining', 'mining'), ('algorithms', 'algorithm'), ('map-reduce', 'map-reduce'), ('architecture', 'architecture'), ('.', '.')]


------------------- Sentence 9 -------------------

These results imply that it is possible to do so.

>> Tokens are: 
 ['These', 'results', 'imply', 'possible', '.']

>> Bigrams are: 
 [('These', 'results'), ('results', 'imply'), ('imply', 'possible'), ('possible', '.')]

>> Trigrams are: 
 [('These', 'results', 'imply'), ('results', 'imply', 'possible'), ('imply', 'possible', '.')]

>> POS Tags are: 
 [('These', 'DT'), ('results', 'NNS'), ('imply', 'VBP'), ('possible', 'JJ'), ('.', '.')]

>> Noun Phrases are: 
 ['These results']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('These', 'these'), ('results', 'result'), ('imply', 'impli'), ('possible', 'possibl'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('These', 'these'), ('results', 'result'), ('imply', 'impli'), ('possible', 'possibl'), ('.', '.')]

>> Lemmatization: 
 [('These', 'These'), ('results', 'result'), ('imply', 'imply'), ('possible', 'possible'), ('.', '.')]


------------------- Sentence 10 -------------------

According to our observa- tion, although the traditional mining or soft computing algorithms can be used to help  us analyze the data in big data analytics, unfortunately, until now, not many studies are  focused on it.

>> Tokens are: 
 ['According', 'observa-', 'tion', ',', 'although', 'traditional', 'mining', 'soft', 'computing', 'algorithms', 'used', 'help', 'us', 'analyze', 'data', 'big', 'data', 'analytics', ',', 'unfortunately', ',', ',', 'many', 'studies', 'focused', '.']

>> Bigrams are: 
 [('According', 'observa-'), ('observa-', 'tion'), ('tion', ','), (',', 'although'), ('although', 'traditional'), ('traditional', 'mining'), ('mining', 'soft'), ('soft', 'computing'), ('computing', 'algorithms'), ('algorithms', 'used'), ('used', 'help'), ('help', 'us'), ('us', 'analyze'), ('analyze', 'data'), ('data', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', ','), (',', 'unfortunately'), ('unfortunately', ','), (',', ','), (',', 'many'), ('many', 'studies'), ('studies', 'focused'), ('focused', '.')]

>> Trigrams are: 
 [('According', 'observa-', 'tion'), ('observa-', 'tion', ','), ('tion', ',', 'although'), (',', 'although', 'traditional'), ('although', 'traditional', 'mining'), ('traditional', 'mining', 'soft'), ('mining', 'soft', 'computing'), ('soft', 'computing', 'algorithms'), ('computing', 'algorithms', 'used'), ('algorithms', 'used', 'help'), ('used', 'help', 'us'), ('help', 'us', 'analyze'), ('us', 'analyze', 'data'), ('analyze', 'data', 'big'), ('data', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', ','), ('analytics', ',', 'unfortunately'), (',', 'unfortunately', ','), ('unfortunately', ',', ','), (',', ',', 'many'), (',', 'many', 'studies'), ('many', 'studies', 'focused'), ('studies', 'focused', '.')]

>> POS Tags are: 
 [('According', 'VBG'), ('observa-', 'JJ'), ('tion', 'NN'), (',', ','), ('although', 'IN'), ('traditional', 'JJ'), ('mining', 'NN'), ('soft', 'JJ'), ('computing', 'VBG'), ('algorithms', 'NN'), ('used', 'VBN'), ('help', 'VB'), ('us', 'PRP'), ('analyze', 'VB'), ('data', 'NNS'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), (',', ','), ('unfortunately', 'RB'), (',', ','), (',', ','), ('many', 'JJ'), ('studies', 'NNS'), ('focused', 'VBD'), ('.', '.')]

>> Noun Phrases are: 
 ['observa- tion', 'traditional mining', 'algorithms', 'data', 'big data analytics', 'many studies']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('According', 'accord'), ('observa-', 'observa-'), ('tion', 'tion'), (',', ','), ('although', 'although'), ('traditional', 'tradit'), ('mining', 'mine'), ('soft', 'soft'), ('computing', 'comput'), ('algorithms', 'algorithm'), ('used', 'use'), ('help', 'help'), ('us', 'us'), ('analyze', 'analyz'), ('data', 'data'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), (',', ','), ('unfortunately', 'unfortun'), (',', ','), (',', ','), ('many', 'mani'), ('studies', 'studi'), ('focused', 'focus'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('According', 'accord'), ('observa-', 'observa-'), ('tion', 'tion'), (',', ','), ('although', 'although'), ('traditional', 'tradit'), ('mining', 'mine'), ('soft', 'soft'), ('computing', 'comput'), ('algorithms', 'algorithm'), ('used', 'use'), ('help', 'help'), ('us', 'us'), ('analyze', 'analyz'), ('data', 'data'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), (',', ','), ('unfortunately', 'unfortun'), (',', ','), (',', ','), ('many', 'mani'), ('studies', 'studi'), ('focused', 'focus'), ('.', '.')]

>> Lemmatization: 
 [('According', 'According'), ('observa-', 'observa-'), ('tion', 'tion'), (',', ','), ('although', 'although'), ('traditional', 'traditional'), ('mining', 'mining'), ('soft', 'soft'), ('computing', 'computing'), ('algorithms', 'algorithm'), ('used', 'used'), ('help', 'help'), ('us', 'u'), ('analyze', 'analyze'), ('data', 'data'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), (',', ','), ('unfortunately', 'unfortunately'), (',', ','), (',', ','), ('many', 'many'), ('studies', 'study'), ('focused', 'focused'), ('.', '.')]


------------------- Sentence 11 -------------------

As a consequence, it is an important open issue in big data analytics.

>> Tokens are: 
 ['As', 'consequence', ',', 'important', 'open', 'issue', 'big', 'data', 'analytics', '.']

>> Bigrams are: 
 [('As', 'consequence'), ('consequence', ','), (',', 'important'), ('important', 'open'), ('open', 'issue'), ('issue', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', '.')]

>> Trigrams are: 
 [('As', 'consequence', ','), ('consequence', ',', 'important'), (',', 'important', 'open'), ('important', 'open', 'issue'), ('open', 'issue', 'big'), ('issue', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', '.')]

>> POS Tags are: 
 [('As', 'IN'), ('consequence', 'NN'), (',', ','), ('important', 'JJ'), ('open', 'JJ'), ('issue', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['consequence', 'important open issue', 'big data analytics']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('As', 'as'), ('consequence', 'consequ'), (',', ','), ('important', 'import'), ('open', 'open'), ('issue', 'issu'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('As', 'as'), ('consequence', 'consequ'), (',', ','), ('important', 'import'), ('open', 'open'), ('issue', 'issu'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('.', '.')]

>> Lemmatization: 
 [('As', 'As'), ('consequence', 'consequence'), (',', ','), ('important', 'important'), ('open', 'open'), ('issue', 'issue'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('.', '.')]



========================================== PARAGRAPH 376 ===========================================

Noise, outliers, incomplete and inconsistent data 

------------------- Sentence 1 -------------------

Noise, outliers, incomplete and inconsistent data

>> Tokens are: 
 ['Noise', ',', 'outliers', ',', 'incomplete', 'inconsistent', 'data']

>> Bigrams are: 
 [('Noise', ','), (',', 'outliers'), ('outliers', ','), (',', 'incomplete'), ('incomplete', 'inconsistent'), ('inconsistent', 'data')]

>> Trigrams are: 
 [('Noise', ',', 'outliers'), (',', 'outliers', ','), ('outliers', ',', 'incomplete'), (',', 'incomplete', 'inconsistent'), ('incomplete', 'inconsistent', 'data')]

>> POS Tags are: 
 [('Noise', 'NN'), (',', ','), ('outliers', 'NNS'), (',', ','), ('incomplete', 'JJ'), ('inconsistent', 'NN'), ('data', 'NNS')]

>> Noun Phrases are: 
 ['Noise', 'outliers', 'incomplete inconsistent data']

>> Named Entities are: 
 [('GPE', 'Noise')] 

>> Stemming using Porter Stemmer: 
 [('Noise', 'nois'), (',', ','), ('outliers', 'outlier'), (',', ','), ('incomplete', 'incomplet'), ('inconsistent', 'inconsist'), ('data', 'data')]

>> Stemming using Snowball Stemmer: 
 [('Noise', 'nois'), (',', ','), ('outliers', 'outlier'), (',', ','), ('incomplete', 'incomplet'), ('inconsistent', 'inconsist'), ('data', 'data')]

>> Lemmatization: 
 [('Noise', 'Noise'), (',', ','), ('outliers', 'outlier'), (',', ','), ('incomplete', 'incomplete'), ('inconsistent', 'inconsistent'), ('data', 'data')]



========================================== PARAGRAPH 377 ===========================================

Although big data analytics is a new age for data analysis, because several solutions  adopt classical ways to analyze the data on big data analytics, the open issues of tradi- tional data mining algorithms also exist in these new systems. The open issues of noise,  outliers, incomplete, and inconsistent data in traditional data mining algorithms will also  appear in big data mining algorithms. More incomplete and inconsistent data will easily  appear because the data are captured by or generated from different sensors and sys- tems. The impact of noise, outliers, incomplete and inconsistent data will be enlarged for  big data analytics. Therefore, how to mitigate the impact will be the open issues for big  data analytics. 

------------------- Sentence 1 -------------------

Although big data analytics is a new age for data analysis, because several solutions  adopt classical ways to analyze the data on big data analytics, the open issues of tradi- tional data mining algorithms also exist in these new systems.

>> Tokens are: 
 ['Although', 'big', 'data', 'analytics', 'new', 'age', 'data', 'analysis', ',', 'several', 'solutions', 'adopt', 'classical', 'ways', 'analyze', 'data', 'big', 'data', 'analytics', ',', 'open', 'issues', 'tradi-', 'tional', 'data', 'mining', 'algorithms', 'also', 'exist', 'new', 'systems', '.']

>> Bigrams are: 
 [('Although', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', 'new'), ('new', 'age'), ('age', 'data'), ('data', 'analysis'), ('analysis', ','), (',', 'several'), ('several', 'solutions'), ('solutions', 'adopt'), ('adopt', 'classical'), ('classical', 'ways'), ('ways', 'analyze'), ('analyze', 'data'), ('data', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', ','), (',', 'open'), ('open', 'issues'), ('issues', 'tradi-'), ('tradi-', 'tional'), ('tional', 'data'), ('data', 'mining'), ('mining', 'algorithms'), ('algorithms', 'also'), ('also', 'exist'), ('exist', 'new'), ('new', 'systems'), ('systems', '.')]

>> Trigrams are: 
 [('Although', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', 'new'), ('analytics', 'new', 'age'), ('new', 'age', 'data'), ('age', 'data', 'analysis'), ('data', 'analysis', ','), ('analysis', ',', 'several'), (',', 'several', 'solutions'), ('several', 'solutions', 'adopt'), ('solutions', 'adopt', 'classical'), ('adopt', 'classical', 'ways'), ('classical', 'ways', 'analyze'), ('ways', 'analyze', 'data'), ('analyze', 'data', 'big'), ('data', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', ','), ('analytics', ',', 'open'), (',', 'open', 'issues'), ('open', 'issues', 'tradi-'), ('issues', 'tradi-', 'tional'), ('tradi-', 'tional', 'data'), ('tional', 'data', 'mining'), ('data', 'mining', 'algorithms'), ('mining', 'algorithms', 'also'), ('algorithms', 'also', 'exist'), ('also', 'exist', 'new'), ('exist', 'new', 'systems'), ('new', 'systems', '.')]

>> POS Tags are: 
 [('Although', 'IN'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('new', 'JJ'), ('age', 'NN'), ('data', 'NNS'), ('analysis', 'NN'), (',', ','), ('several', 'JJ'), ('solutions', 'NNS'), ('adopt', 'VB'), ('classical', 'JJ'), ('ways', 'NNS'), ('analyze', 'VBP'), ('data', 'NNS'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), (',', ','), ('open', 'JJ'), ('issues', 'NNS'), ('tradi-', 'JJ'), ('tional', 'JJ'), ('data', 'NNS'), ('mining', 'NN'), ('algorithms', 'NN'), ('also', 'RB'), ('exist', 'VBP'), ('new', 'JJ'), ('systems', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['big data analytics', 'new age data analysis', 'several solutions', 'classical ways', 'data', 'big data analytics', 'open issues', 'tradi- tional data mining algorithms', 'new systems']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Although', 'although'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('new', 'new'), ('age', 'age'), ('data', 'data'), ('analysis', 'analysi'), (',', ','), ('several', 'sever'), ('solutions', 'solut'), ('adopt', 'adopt'), ('classical', 'classic'), ('ways', 'way'), ('analyze', 'analyz'), ('data', 'data'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), (',', ','), ('open', 'open'), ('issues', 'issu'), ('tradi-', 'tradi-'), ('tional', 'tional'), ('data', 'data'), ('mining', 'mine'), ('algorithms', 'algorithm'), ('also', 'also'), ('exist', 'exist'), ('new', 'new'), ('systems', 'system'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Although', 'although'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('new', 'new'), ('age', 'age'), ('data', 'data'), ('analysis', 'analysi'), (',', ','), ('several', 'sever'), ('solutions', 'solut'), ('adopt', 'adopt'), ('classical', 'classic'), ('ways', 'way'), ('analyze', 'analyz'), ('data', 'data'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), (',', ','), ('open', 'open'), ('issues', 'issu'), ('tradi-', 'tradi-'), ('tional', 'tional'), ('data', 'data'), ('mining', 'mine'), ('algorithms', 'algorithm'), ('also', 'also'), ('exist', 'exist'), ('new', 'new'), ('systems', 'system'), ('.', '.')]

>> Lemmatization: 
 [('Although', 'Although'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('new', 'new'), ('age', 'age'), ('data', 'data'), ('analysis', 'analysis'), (',', ','), ('several', 'several'), ('solutions', 'solution'), ('adopt', 'adopt'), ('classical', 'classical'), ('ways', 'way'), ('analyze', 'analyze'), ('data', 'data'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), (',', ','), ('open', 'open'), ('issues', 'issue'), ('tradi-', 'tradi-'), ('tional', 'tional'), ('data', 'data'), ('mining', 'mining'), ('algorithms', 'algorithm'), ('also', 'also'), ('exist', 'exist'), ('new', 'new'), ('systems', 'system'), ('.', '.')]


------------------- Sentence 2 -------------------

The open issues of noise,  outliers, incomplete, and inconsistent data in traditional data mining algorithms will also  appear in big data mining algorithms.

>> Tokens are: 
 ['The', 'open', 'issues', 'noise', ',', 'outliers', ',', 'incomplete', ',', 'inconsistent', 'data', 'traditional', 'data', 'mining', 'algorithms', 'also', 'appear', 'big', 'data', 'mining', 'algorithms', '.']

>> Bigrams are: 
 [('The', 'open'), ('open', 'issues'), ('issues', 'noise'), ('noise', ','), (',', 'outliers'), ('outliers', ','), (',', 'incomplete'), ('incomplete', ','), (',', 'inconsistent'), ('inconsistent', 'data'), ('data', 'traditional'), ('traditional', 'data'), ('data', 'mining'), ('mining', 'algorithms'), ('algorithms', 'also'), ('also', 'appear'), ('appear', 'big'), ('big', 'data'), ('data', 'mining'), ('mining', 'algorithms'), ('algorithms', '.')]

>> Trigrams are: 
 [('The', 'open', 'issues'), ('open', 'issues', 'noise'), ('issues', 'noise', ','), ('noise', ',', 'outliers'), (',', 'outliers', ','), ('outliers', ',', 'incomplete'), (',', 'incomplete', ','), ('incomplete', ',', 'inconsistent'), (',', 'inconsistent', 'data'), ('inconsistent', 'data', 'traditional'), ('data', 'traditional', 'data'), ('traditional', 'data', 'mining'), ('data', 'mining', 'algorithms'), ('mining', 'algorithms', 'also'), ('algorithms', 'also', 'appear'), ('also', 'appear', 'big'), ('appear', 'big', 'data'), ('big', 'data', 'mining'), ('data', 'mining', 'algorithms'), ('mining', 'algorithms', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('open', 'JJ'), ('issues', 'NNS'), ('noise', 'NN'), (',', ','), ('outliers', 'NNS'), (',', ','), ('incomplete', 'JJ'), (',', ','), ('inconsistent', 'JJ'), ('data', 'NNS'), ('traditional', 'JJ'), ('data', 'NNS'), ('mining', 'NN'), ('algorithms', 'NN'), ('also', 'RB'), ('appear', 'VBP'), ('big', 'JJ'), ('data', 'NNS'), ('mining', 'NN'), ('algorithms', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['The open issues noise', 'outliers', 'inconsistent data', 'traditional data mining algorithms', 'big data mining algorithms']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('open', 'open'), ('issues', 'issu'), ('noise', 'nois'), (',', ','), ('outliers', 'outlier'), (',', ','), ('incomplete', 'incomplet'), (',', ','), ('inconsistent', 'inconsist'), ('data', 'data'), ('traditional', 'tradit'), ('data', 'data'), ('mining', 'mine'), ('algorithms', 'algorithm'), ('also', 'also'), ('appear', 'appear'), ('big', 'big'), ('data', 'data'), ('mining', 'mine'), ('algorithms', 'algorithm'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('open', 'open'), ('issues', 'issu'), ('noise', 'nois'), (',', ','), ('outliers', 'outlier'), (',', ','), ('incomplete', 'incomplet'), (',', ','), ('inconsistent', 'inconsist'), ('data', 'data'), ('traditional', 'tradit'), ('data', 'data'), ('mining', 'mine'), ('algorithms', 'algorithm'), ('also', 'also'), ('appear', 'appear'), ('big', 'big'), ('data', 'data'), ('mining', 'mine'), ('algorithms', 'algorithm'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('open', 'open'), ('issues', 'issue'), ('noise', 'noise'), (',', ','), ('outliers', 'outlier'), (',', ','), ('incomplete', 'incomplete'), (',', ','), ('inconsistent', 'inconsistent'), ('data', 'data'), ('traditional', 'traditional'), ('data', 'data'), ('mining', 'mining'), ('algorithms', 'algorithm'), ('also', 'also'), ('appear', 'appear'), ('big', 'big'), ('data', 'data'), ('mining', 'mining'), ('algorithms', 'algorithm'), ('.', '.')]


------------------- Sentence 3 -------------------

More incomplete and inconsistent data will easily  appear because the data are captured by or generated from different sensors and sys- tems.

>> Tokens are: 
 ['More', 'incomplete', 'inconsistent', 'data', 'easily', 'appear', 'data', 'captured', 'generated', 'different', 'sensors', 'sys-', 'tems', '.']

>> Bigrams are: 
 [('More', 'incomplete'), ('incomplete', 'inconsistent'), ('inconsistent', 'data'), ('data', 'easily'), ('easily', 'appear'), ('appear', 'data'), ('data', 'captured'), ('captured', 'generated'), ('generated', 'different'), ('different', 'sensors'), ('sensors', 'sys-'), ('sys-', 'tems'), ('tems', '.')]

>> Trigrams are: 
 [('More', 'incomplete', 'inconsistent'), ('incomplete', 'inconsistent', 'data'), ('inconsistent', 'data', 'easily'), ('data', 'easily', 'appear'), ('easily', 'appear', 'data'), ('appear', 'data', 'captured'), ('data', 'captured', 'generated'), ('captured', 'generated', 'different'), ('generated', 'different', 'sensors'), ('different', 'sensors', 'sys-'), ('sensors', 'sys-', 'tems'), ('sys-', 'tems', '.')]

>> POS Tags are: 
 [('More', 'RBR'), ('incomplete', 'JJ'), ('inconsistent', 'NN'), ('data', 'NNS'), ('easily', 'RB'), ('appear', 'VBP'), ('data', 'NNS'), ('captured', 'VBD'), ('generated', 'JJ'), ('different', 'JJ'), ('sensors', 'NNS'), ('sys-', 'JJ'), ('tems', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['incomplete inconsistent data', 'data', 'generated different sensors', 'sys- tems']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('More', 'more'), ('incomplete', 'incomplet'), ('inconsistent', 'inconsist'), ('data', 'data'), ('easily', 'easili'), ('appear', 'appear'), ('data', 'data'), ('captured', 'captur'), ('generated', 'gener'), ('different', 'differ'), ('sensors', 'sensor'), ('sys-', 'sys-'), ('tems', 'tem'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('More', 'more'), ('incomplete', 'incomplet'), ('inconsistent', 'inconsist'), ('data', 'data'), ('easily', 'easili'), ('appear', 'appear'), ('data', 'data'), ('captured', 'captur'), ('generated', 'generat'), ('different', 'differ'), ('sensors', 'sensor'), ('sys-', 'sys-'), ('tems', 'tem'), ('.', '.')]

>> Lemmatization: 
 [('More', 'More'), ('incomplete', 'incomplete'), ('inconsistent', 'inconsistent'), ('data', 'data'), ('easily', 'easily'), ('appear', 'appear'), ('data', 'data'), ('captured', 'captured'), ('generated', 'generated'), ('different', 'different'), ('sensors', 'sensor'), ('sys-', 'sys-'), ('tems', 'tems'), ('.', '.')]


------------------- Sentence 4 -------------------

The impact of noise, outliers, incomplete and inconsistent data will be enlarged for  big data analytics.

>> Tokens are: 
 ['The', 'impact', 'noise', ',', 'outliers', ',', 'incomplete', 'inconsistent', 'data', 'enlarged', 'big', 'data', 'analytics', '.']

>> Bigrams are: 
 [('The', 'impact'), ('impact', 'noise'), ('noise', ','), (',', 'outliers'), ('outliers', ','), (',', 'incomplete'), ('incomplete', 'inconsistent'), ('inconsistent', 'data'), ('data', 'enlarged'), ('enlarged', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', '.')]

>> Trigrams are: 
 [('The', 'impact', 'noise'), ('impact', 'noise', ','), ('noise', ',', 'outliers'), (',', 'outliers', ','), ('outliers', ',', 'incomplete'), (',', 'incomplete', 'inconsistent'), ('incomplete', 'inconsistent', 'data'), ('inconsistent', 'data', 'enlarged'), ('data', 'enlarged', 'big'), ('enlarged', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('impact', 'NN'), ('noise', 'NN'), (',', ','), ('outliers', 'NNS'), (',', ','), ('incomplete', 'JJ'), ('inconsistent', 'NN'), ('data', 'NNS'), ('enlarged', 'VBD'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['The impact noise', 'outliers', 'incomplete inconsistent data', 'big data analytics']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('impact', 'impact'), ('noise', 'nois'), (',', ','), ('outliers', 'outlier'), (',', ','), ('incomplete', 'incomplet'), ('inconsistent', 'inconsist'), ('data', 'data'), ('enlarged', 'enlarg'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('impact', 'impact'), ('noise', 'nois'), (',', ','), ('outliers', 'outlier'), (',', ','), ('incomplete', 'incomplet'), ('inconsistent', 'inconsist'), ('data', 'data'), ('enlarged', 'enlarg'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('impact', 'impact'), ('noise', 'noise'), (',', ','), ('outliers', 'outlier'), (',', ','), ('incomplete', 'incomplete'), ('inconsistent', 'inconsistent'), ('data', 'data'), ('enlarged', 'enlarged'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('.', '.')]


------------------- Sentence 5 -------------------

Therefore, how to mitigate the impact will be the open issues for big  data analytics.

>> Tokens are: 
 ['Therefore', ',', 'mitigate', 'impact', 'open', 'issues', 'big', 'data', 'analytics', '.']

>> Bigrams are: 
 [('Therefore', ','), (',', 'mitigate'), ('mitigate', 'impact'), ('impact', 'open'), ('open', 'issues'), ('issues', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', '.')]

>> Trigrams are: 
 [('Therefore', ',', 'mitigate'), (',', 'mitigate', 'impact'), ('mitigate', 'impact', 'open'), ('impact', 'open', 'issues'), ('open', 'issues', 'big'), ('issues', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', '.')]

>> POS Tags are: 
 [('Therefore', 'RB'), (',', ','), ('mitigate', 'JJ'), ('impact', 'NN'), ('open', 'JJ'), ('issues', 'NNS'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['mitigate impact', 'open issues', 'big data analytics']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Therefore', 'therefor'), (',', ','), ('mitigate', 'mitig'), ('impact', 'impact'), ('open', 'open'), ('issues', 'issu'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Therefore', 'therefor'), (',', ','), ('mitigate', 'mitig'), ('impact', 'impact'), ('open', 'open'), ('issues', 'issu'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('.', '.')]

>> Lemmatization: 
 [('Therefore', 'Therefore'), (',', ','), ('mitigate', 'mitigate'), ('impact', 'impact'), ('open', 'open'), ('issues', 'issue'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('.', '.')]



========================================== PARAGRAPH 378 ===========================================

Bottlenecks on data mining algorithm 

------------------- Sentence 1 -------------------

Bottlenecks on data mining algorithm

>> Tokens are: 
 ['Bottlenecks', 'data', 'mining', 'algorithm']

>> Bigrams are: 
 [('Bottlenecks', 'data'), ('data', 'mining'), ('mining', 'algorithm')]

>> Trigrams are: 
 [('Bottlenecks', 'data', 'mining'), ('data', 'mining', 'algorithm')]

>> POS Tags are: 
 [('Bottlenecks', 'NNP'), ('data', 'NNS'), ('mining', 'NN'), ('algorithm', 'NN')]

>> Noun Phrases are: 
 ['Bottlenecks data mining algorithm']

>> Named Entities are: 
 [('GPE', 'Bottlenecks')] 

>> Stemming using Porter Stemmer: 
 [('Bottlenecks', 'bottleneck'), ('data', 'data'), ('mining', 'mine'), ('algorithm', 'algorithm')]

>> Stemming using Snowball Stemmer: 
 [('Bottlenecks', 'bottleneck'), ('data', 'data'), ('mining', 'mine'), ('algorithm', 'algorithm')]

>> Lemmatization: 
 [('Bottlenecks', 'Bottlenecks'), ('data', 'data'), ('mining', 'mining'), ('algorithm', 'algorithm')]



========================================== PARAGRAPH 379 ===========================================

Most of the data mining algorithms in big data analytics will be designed for parallel  computing. However, once data mining algorithms are designed or modified for paral- lel computing, it is the information exchange between different data mining procedures  that may incur bottlenecks. One of them is the synchronization issue because different  mining procedures will finish their jobs at different times even though they use the same  mining algorithm to work on the same amount of data. Thus, some of the mining pro- cedures will have to wait until the others finished their jobs. This situation may occur  because the loading of different computer nodes may be different during the data mining  process, or it may occur because the convergence speeds are different for the same data  mining algorithm. The bottlenecks of data mining algorithms will become an open issue 

------------------- Sentence 1 -------------------

Most of the data mining algorithms in big data analytics will be designed for parallel  computing.

>> Tokens are: 
 ['Most', 'data', 'mining', 'algorithms', 'big', 'data', 'analytics', 'designed', 'parallel', 'computing', '.']

>> Bigrams are: 
 [('Most', 'data'), ('data', 'mining'), ('mining', 'algorithms'), ('algorithms', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', 'designed'), ('designed', 'parallel'), ('parallel', 'computing'), ('computing', '.')]

>> Trigrams are: 
 [('Most', 'data', 'mining'), ('data', 'mining', 'algorithms'), ('mining', 'algorithms', 'big'), ('algorithms', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', 'designed'), ('analytics', 'designed', 'parallel'), ('designed', 'parallel', 'computing'), ('parallel', 'computing', '.')]

>> POS Tags are: 
 [('Most', 'JJS'), ('data', 'NNS'), ('mining', 'NN'), ('algorithms', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('designed', 'VBN'), ('parallel', 'JJ'), ('computing', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['data mining algorithms', 'big data analytics', 'parallel computing']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Most', 'most'), ('data', 'data'), ('mining', 'mine'), ('algorithms', 'algorithm'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('designed', 'design'), ('parallel', 'parallel'), ('computing', 'comput'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Most', 'most'), ('data', 'data'), ('mining', 'mine'), ('algorithms', 'algorithm'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('designed', 'design'), ('parallel', 'parallel'), ('computing', 'comput'), ('.', '.')]

>> Lemmatization: 
 [('Most', 'Most'), ('data', 'data'), ('mining', 'mining'), ('algorithms', 'algorithm'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('designed', 'designed'), ('parallel', 'parallel'), ('computing', 'computing'), ('.', '.')]


------------------- Sentence 2 -------------------

However, once data mining algorithms are designed or modified for paral- lel computing, it is the information exchange between different data mining procedures  that may incur bottlenecks.

>> Tokens are: 
 ['However', ',', 'data', 'mining', 'algorithms', 'designed', 'modified', 'paral-', 'lel', 'computing', ',', 'information', 'exchange', 'different', 'data', 'mining', 'procedures', 'may', 'incur', 'bottlenecks', '.']

>> Bigrams are: 
 [('However', ','), (',', 'data'), ('data', 'mining'), ('mining', 'algorithms'), ('algorithms', 'designed'), ('designed', 'modified'), ('modified', 'paral-'), ('paral-', 'lel'), ('lel', 'computing'), ('computing', ','), (',', 'information'), ('information', 'exchange'), ('exchange', 'different'), ('different', 'data'), ('data', 'mining'), ('mining', 'procedures'), ('procedures', 'may'), ('may', 'incur'), ('incur', 'bottlenecks'), ('bottlenecks', '.')]

>> Trigrams are: 
 [('However', ',', 'data'), (',', 'data', 'mining'), ('data', 'mining', 'algorithms'), ('mining', 'algorithms', 'designed'), ('algorithms', 'designed', 'modified'), ('designed', 'modified', 'paral-'), ('modified', 'paral-', 'lel'), ('paral-', 'lel', 'computing'), ('lel', 'computing', ','), ('computing', ',', 'information'), (',', 'information', 'exchange'), ('information', 'exchange', 'different'), ('exchange', 'different', 'data'), ('different', 'data', 'mining'), ('data', 'mining', 'procedures'), ('mining', 'procedures', 'may'), ('procedures', 'may', 'incur'), ('may', 'incur', 'bottlenecks'), ('incur', 'bottlenecks', '.')]

>> POS Tags are: 
 [('However', 'RB'), (',', ','), ('data', 'NNS'), ('mining', 'NN'), ('algorithms', 'NN'), ('designed', 'VBN'), ('modified', 'VBD'), ('paral-', 'JJ'), ('lel', 'NN'), ('computing', 'NN'), (',', ','), ('information', 'NN'), ('exchange', 'NN'), ('different', 'JJ'), ('data', 'NNS'), ('mining', 'NN'), ('procedures', 'NNS'), ('may', 'MD'), ('incur', 'VB'), ('bottlenecks', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['data mining algorithms', 'paral- lel computing', 'information exchange', 'different data mining procedures', 'bottlenecks']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('However', 'howev'), (',', ','), ('data', 'data'), ('mining', 'mine'), ('algorithms', 'algorithm'), ('designed', 'design'), ('modified', 'modifi'), ('paral-', 'paral-'), ('lel', 'lel'), ('computing', 'comput'), (',', ','), ('information', 'inform'), ('exchange', 'exchang'), ('different', 'differ'), ('data', 'data'), ('mining', 'mine'), ('procedures', 'procedur'), ('may', 'may'), ('incur', 'incur'), ('bottlenecks', 'bottleneck'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('However', 'howev'), (',', ','), ('data', 'data'), ('mining', 'mine'), ('algorithms', 'algorithm'), ('designed', 'design'), ('modified', 'modifi'), ('paral-', 'paral-'), ('lel', 'lel'), ('computing', 'comput'), (',', ','), ('information', 'inform'), ('exchange', 'exchang'), ('different', 'differ'), ('data', 'data'), ('mining', 'mine'), ('procedures', 'procedur'), ('may', 'may'), ('incur', 'incur'), ('bottlenecks', 'bottleneck'), ('.', '.')]

>> Lemmatization: 
 [('However', 'However'), (',', ','), ('data', 'data'), ('mining', 'mining'), ('algorithms', 'algorithm'), ('designed', 'designed'), ('modified', 'modified'), ('paral-', 'paral-'), ('lel', 'lel'), ('computing', 'computing'), (',', ','), ('information', 'information'), ('exchange', 'exchange'), ('different', 'different'), ('data', 'data'), ('mining', 'mining'), ('procedures', 'procedure'), ('may', 'may'), ('incur', 'incur'), ('bottlenecks', 'bottleneck'), ('.', '.')]


------------------- Sentence 3 -------------------

One of them is the synchronization issue because different  mining procedures will finish their jobs at different times even though they use the same  mining algorithm to work on the same amount of data.

>> Tokens are: 
 ['One', 'synchronization', 'issue', 'different', 'mining', 'procedures', 'finish', 'jobs', 'different', 'times', 'even', 'though', 'use', 'mining', 'algorithm', 'work', 'amount', 'data', '.']

>> Bigrams are: 
 [('One', 'synchronization'), ('synchronization', 'issue'), ('issue', 'different'), ('different', 'mining'), ('mining', 'procedures'), ('procedures', 'finish'), ('finish', 'jobs'), ('jobs', 'different'), ('different', 'times'), ('times', 'even'), ('even', 'though'), ('though', 'use'), ('use', 'mining'), ('mining', 'algorithm'), ('algorithm', 'work'), ('work', 'amount'), ('amount', 'data'), ('data', '.')]

>> Trigrams are: 
 [('One', 'synchronization', 'issue'), ('synchronization', 'issue', 'different'), ('issue', 'different', 'mining'), ('different', 'mining', 'procedures'), ('mining', 'procedures', 'finish'), ('procedures', 'finish', 'jobs'), ('finish', 'jobs', 'different'), ('jobs', 'different', 'times'), ('different', 'times', 'even'), ('times', 'even', 'though'), ('even', 'though', 'use'), ('though', 'use', 'mining'), ('use', 'mining', 'algorithm'), ('mining', 'algorithm', 'work'), ('algorithm', 'work', 'amount'), ('work', 'amount', 'data'), ('amount', 'data', '.')]

>> POS Tags are: 
 [('One', 'CD'), ('synchronization', 'NN'), ('issue', 'NN'), ('different', 'JJ'), ('mining', 'NN'), ('procedures', 'NNS'), ('finish', 'VBP'), ('jobs', 'NNS'), ('different', 'JJ'), ('times', 'NNS'), ('even', 'RB'), ('though', 'IN'), ('use', 'NN'), ('mining', 'NN'), ('algorithm', 'NN'), ('work', 'NN'), ('amount', 'NN'), ('data', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['synchronization issue', 'different mining procedures', 'jobs', 'different times', 'use mining algorithm work amount data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('One', 'one'), ('synchronization', 'synchron'), ('issue', 'issu'), ('different', 'differ'), ('mining', 'mine'), ('procedures', 'procedur'), ('finish', 'finish'), ('jobs', 'job'), ('different', 'differ'), ('times', 'time'), ('even', 'even'), ('though', 'though'), ('use', 'use'), ('mining', 'mine'), ('algorithm', 'algorithm'), ('work', 'work'), ('amount', 'amount'), ('data', 'data'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('One', 'one'), ('synchronization', 'synchron'), ('issue', 'issu'), ('different', 'differ'), ('mining', 'mine'), ('procedures', 'procedur'), ('finish', 'finish'), ('jobs', 'job'), ('different', 'differ'), ('times', 'time'), ('even', 'even'), ('though', 'though'), ('use', 'use'), ('mining', 'mine'), ('algorithm', 'algorithm'), ('work', 'work'), ('amount', 'amount'), ('data', 'data'), ('.', '.')]

>> Lemmatization: 
 [('One', 'One'), ('synchronization', 'synchronization'), ('issue', 'issue'), ('different', 'different'), ('mining', 'mining'), ('procedures', 'procedure'), ('finish', 'finish'), ('jobs', 'job'), ('different', 'different'), ('times', 'time'), ('even', 'even'), ('though', 'though'), ('use', 'use'), ('mining', 'mining'), ('algorithm', 'algorithm'), ('work', 'work'), ('amount', 'amount'), ('data', 'data'), ('.', '.')]


------------------- Sentence 4 -------------------

Thus, some of the mining pro- cedures will have to wait until the others finished their jobs.

>> Tokens are: 
 ['Thus', ',', 'mining', 'pro-', 'cedures', 'wait', 'others', 'finished', 'jobs', '.']

>> Bigrams are: 
 [('Thus', ','), (',', 'mining'), ('mining', 'pro-'), ('pro-', 'cedures'), ('cedures', 'wait'), ('wait', 'others'), ('others', 'finished'), ('finished', 'jobs'), ('jobs', '.')]

>> Trigrams are: 
 [('Thus', ',', 'mining'), (',', 'mining', 'pro-'), ('mining', 'pro-', 'cedures'), ('pro-', 'cedures', 'wait'), ('cedures', 'wait', 'others'), ('wait', 'others', 'finished'), ('others', 'finished', 'jobs'), ('finished', 'jobs', '.')]

>> POS Tags are: 
 [('Thus', 'RB'), (',', ','), ('mining', 'VBG'), ('pro-', 'JJ'), ('cedures', 'NNS'), ('wait', 'VBP'), ('others', 'NNS'), ('finished', 'VBD'), ('jobs', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['pro- cedures', 'others', 'jobs']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Thus', 'thu'), (',', ','), ('mining', 'mine'), ('pro-', 'pro-'), ('cedures', 'cedur'), ('wait', 'wait'), ('others', 'other'), ('finished', 'finish'), ('jobs', 'job'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Thus', 'thus'), (',', ','), ('mining', 'mine'), ('pro-', 'pro-'), ('cedures', 'cedur'), ('wait', 'wait'), ('others', 'other'), ('finished', 'finish'), ('jobs', 'job'), ('.', '.')]

>> Lemmatization: 
 [('Thus', 'Thus'), (',', ','), ('mining', 'mining'), ('pro-', 'pro-'), ('cedures', 'cedures'), ('wait', 'wait'), ('others', 'others'), ('finished', 'finished'), ('jobs', 'job'), ('.', '.')]


------------------- Sentence 5 -------------------

This situation may occur  because the loading of different computer nodes may be different during the data mining  process, or it may occur because the convergence speeds are different for the same data  mining algorithm.

>> Tokens are: 
 ['This', 'situation', 'may', 'occur', 'loading', 'different', 'computer', 'nodes', 'may', 'different', 'data', 'mining', 'process', ',', 'may', 'occur', 'convergence', 'speeds', 'different', 'data', 'mining', 'algorithm', '.']

>> Bigrams are: 
 [('This', 'situation'), ('situation', 'may'), ('may', 'occur'), ('occur', 'loading'), ('loading', 'different'), ('different', 'computer'), ('computer', 'nodes'), ('nodes', 'may'), ('may', 'different'), ('different', 'data'), ('data', 'mining'), ('mining', 'process'), ('process', ','), (',', 'may'), ('may', 'occur'), ('occur', 'convergence'), ('convergence', 'speeds'), ('speeds', 'different'), ('different', 'data'), ('data', 'mining'), ('mining', 'algorithm'), ('algorithm', '.')]

>> Trigrams are: 
 [('This', 'situation', 'may'), ('situation', 'may', 'occur'), ('may', 'occur', 'loading'), ('occur', 'loading', 'different'), ('loading', 'different', 'computer'), ('different', 'computer', 'nodes'), ('computer', 'nodes', 'may'), ('nodes', 'may', 'different'), ('may', 'different', 'data'), ('different', 'data', 'mining'), ('data', 'mining', 'process'), ('mining', 'process', ','), ('process', ',', 'may'), (',', 'may', 'occur'), ('may', 'occur', 'convergence'), ('occur', 'convergence', 'speeds'), ('convergence', 'speeds', 'different'), ('speeds', 'different', 'data'), ('different', 'data', 'mining'), ('data', 'mining', 'algorithm'), ('mining', 'algorithm', '.')]

>> POS Tags are: 
 [('This', 'DT'), ('situation', 'NN'), ('may', 'MD'), ('occur', 'VB'), ('loading', 'VBG'), ('different', 'JJ'), ('computer', 'NN'), ('nodes', 'NNS'), ('may', 'MD'), ('different', 'JJ'), ('data', 'NNS'), ('mining', 'NN'), ('process', 'NN'), (',', ','), ('may', 'MD'), ('occur', 'VB'), ('convergence', 'NN'), ('speeds', 'NNS'), ('different', 'JJ'), ('data', 'NNS'), ('mining', 'NN'), ('algorithm', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['This situation', 'different computer nodes', 'different data mining process', 'convergence speeds', 'different data mining algorithm']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('This', 'thi'), ('situation', 'situat'), ('may', 'may'), ('occur', 'occur'), ('loading', 'load'), ('different', 'differ'), ('computer', 'comput'), ('nodes', 'node'), ('may', 'may'), ('different', 'differ'), ('data', 'data'), ('mining', 'mine'), ('process', 'process'), (',', ','), ('may', 'may'), ('occur', 'occur'), ('convergence', 'converg'), ('speeds', 'speed'), ('different', 'differ'), ('data', 'data'), ('mining', 'mine'), ('algorithm', 'algorithm'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('This', 'this'), ('situation', 'situat'), ('may', 'may'), ('occur', 'occur'), ('loading', 'load'), ('different', 'differ'), ('computer', 'comput'), ('nodes', 'node'), ('may', 'may'), ('different', 'differ'), ('data', 'data'), ('mining', 'mine'), ('process', 'process'), (',', ','), ('may', 'may'), ('occur', 'occur'), ('convergence', 'converg'), ('speeds', 'speed'), ('different', 'differ'), ('data', 'data'), ('mining', 'mine'), ('algorithm', 'algorithm'), ('.', '.')]

>> Lemmatization: 
 [('This', 'This'), ('situation', 'situation'), ('may', 'may'), ('occur', 'occur'), ('loading', 'loading'), ('different', 'different'), ('computer', 'computer'), ('nodes', 'node'), ('may', 'may'), ('different', 'different'), ('data', 'data'), ('mining', 'mining'), ('process', 'process'), (',', ','), ('may', 'may'), ('occur', 'occur'), ('convergence', 'convergence'), ('speeds', 'speed'), ('different', 'different'), ('data', 'data'), ('mining', 'mining'), ('algorithm', 'algorithm'), ('.', '.')]


------------------- Sentence 6 -------------------

The bottlenecks of data mining algorithms will become an open issue

>> Tokens are: 
 ['The', 'bottlenecks', 'data', 'mining', 'algorithms', 'become', 'open', 'issue']

>> Bigrams are: 
 [('The', 'bottlenecks'), ('bottlenecks', 'data'), ('data', 'mining'), ('mining', 'algorithms'), ('algorithms', 'become'), ('become', 'open'), ('open', 'issue')]

>> Trigrams are: 
 [('The', 'bottlenecks', 'data'), ('bottlenecks', 'data', 'mining'), ('data', 'mining', 'algorithms'), ('mining', 'algorithms', 'become'), ('algorithms', 'become', 'open'), ('become', 'open', 'issue')]

>> POS Tags are: 
 [('The', 'DT'), ('bottlenecks', 'NNS'), ('data', 'VBP'), ('mining', 'NN'), ('algorithms', 'NN'), ('become', 'NN'), ('open', 'JJ'), ('issue', 'NN')]

>> Noun Phrases are: 
 ['The bottlenecks', 'mining algorithms become', 'open issue']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('bottlenecks', 'bottleneck'), ('data', 'data'), ('mining', 'mine'), ('algorithms', 'algorithm'), ('become', 'becom'), ('open', 'open'), ('issue', 'issu')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('bottlenecks', 'bottleneck'), ('data', 'data'), ('mining', 'mine'), ('algorithms', 'algorithm'), ('become', 'becom'), ('open', 'open'), ('issue', 'issu')]

>> Lemmatization: 
 [('The', 'The'), ('bottlenecks', 'bottleneck'), ('data', 'data'), ('mining', 'mining'), ('algorithms', 'algorithm'), ('become', 'become'), ('open', 'open'), ('issue', 'issue')]



========================================== PARAGRAPH 380 ===========================================

Page 26 of 32Tsai et al. Journal of Big Data  (2015) 2:21  

------------------- Sentence 1 -------------------

Page 26 of 32Tsai et al.

>> Tokens are: 
 ['Page', '26', '32Tsai', 'et', 'al', '.']

>> Bigrams are: 
 [('Page', '26'), ('26', '32Tsai'), ('32Tsai', 'et'), ('et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('Page', '26', '32Tsai'), ('26', '32Tsai', 'et'), ('32Tsai', 'et', 'al'), ('et', 'al', '.')]

>> POS Tags are: 
 [('Page', 'NN'), ('26', 'CD'), ('32Tsai', 'CD'), ('et', 'NN'), ('al', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Page', 'et al']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Page', 'page'), ('26', '26'), ('32Tsai', '32tsai'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Page', 'page'), ('26', '26'), ('32Tsai', '32tsai'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('Page', 'Page'), ('26', '26'), ('32Tsai', '32Tsai'), ('et', 'et'), ('al', 'al'), ('.', '.')]


------------------- Sentence 2 -------------------

Journal of Big Data  (2015) 2:21

>> Tokens are: 
 ['Journal', 'Big', 'Data', '(', '2015', ')', '2:21']

>> Bigrams are: 
 [('Journal', 'Big'), ('Big', 'Data'), ('Data', '('), ('(', '2015'), ('2015', ')'), (')', '2:21')]

>> Trigrams are: 
 [('Journal', 'Big', 'Data'), ('Big', 'Data', '('), ('Data', '(', '2015'), ('(', '2015', ')'), ('2015', ')', '2:21')]

>> POS Tags are: 
 [('Journal', 'NNP'), ('Big', 'NNP'), ('Data', 'NNP'), ('(', '('), ('2015', 'CD'), (')', ')'), ('2:21', 'CD')]

>> Noun Phrases are: 
 ['Journal Big Data']

>> Named Entities are: 
 [('PERSON', 'Journal')] 

>> Stemming using Porter Stemmer: 
 [('Journal', 'journal'), ('Big', 'big'), ('Data', 'data'), ('(', '('), ('2015', '2015'), (')', ')'), ('2:21', '2:21')]

>> Stemming using Snowball Stemmer: 
 [('Journal', 'journal'), ('Big', 'big'), ('Data', 'data'), ('(', '('), ('2015', '2015'), (')', ')'), ('2:21', '2:21')]

>> Lemmatization: 
 [('Journal', 'Journal'), ('Big', 'Big'), ('Data', 'Data'), ('(', '('), ('2015', '2015'), (')', ')'), ('2:21', '2:21')]



========================================== PARAGRAPH 381 ===========================================

for the big data analytics which explains that we need to take into account this issue  when we develop and design a new data mining algorithm for big data analytics. 

------------------- Sentence 1 -------------------

for the big data analytics which explains that we need to take into account this issue  when we develop and design a new data mining algorithm for big data analytics.

>> Tokens are: 
 ['big', 'data', 'analytics', 'explains', 'need', 'take', 'account', 'issue', 'develop', 'design', 'new', 'data', 'mining', 'algorithm', 'big', 'data', 'analytics', '.']

>> Bigrams are: 
 [('big', 'data'), ('data', 'analytics'), ('analytics', 'explains'), ('explains', 'need'), ('need', 'take'), ('take', 'account'), ('account', 'issue'), ('issue', 'develop'), ('develop', 'design'), ('design', 'new'), ('new', 'data'), ('data', 'mining'), ('mining', 'algorithm'), ('algorithm', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', '.')]

>> Trigrams are: 
 [('big', 'data', 'analytics'), ('data', 'analytics', 'explains'), ('analytics', 'explains', 'need'), ('explains', 'need', 'take'), ('need', 'take', 'account'), ('take', 'account', 'issue'), ('account', 'issue', 'develop'), ('issue', 'develop', 'design'), ('develop', 'design', 'new'), ('design', 'new', 'data'), ('new', 'data', 'mining'), ('data', 'mining', 'algorithm'), ('mining', 'algorithm', 'big'), ('algorithm', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', '.')]

>> POS Tags are: 
 [('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('explains', 'NNS'), ('need', 'VBP'), ('take', 'VBP'), ('account', 'NN'), ('issue', 'NN'), ('develop', 'VB'), ('design', 'JJ'), ('new', 'JJ'), ('data', 'NNS'), ('mining', 'NN'), ('algorithm', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['big data analytics explains', 'account issue', 'design new data mining algorithm', 'big data analytics']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('explains', 'explain'), ('need', 'need'), ('take', 'take'), ('account', 'account'), ('issue', 'issu'), ('develop', 'develop'), ('design', 'design'), ('new', 'new'), ('data', 'data'), ('mining', 'mine'), ('algorithm', 'algorithm'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('explains', 'explain'), ('need', 'need'), ('take', 'take'), ('account', 'account'), ('issue', 'issu'), ('develop', 'develop'), ('design', 'design'), ('new', 'new'), ('data', 'data'), ('mining', 'mine'), ('algorithm', 'algorithm'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('.', '.')]

>> Lemmatization: 
 [('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('explains', 'explains'), ('need', 'need'), ('take', 'take'), ('account', 'account'), ('issue', 'issue'), ('develop', 'develop'), ('design', 'design'), ('new', 'new'), ('data', 'data'), ('mining', 'mining'), ('algorithm', 'algorithm'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('.', '.')]



========================================== PARAGRAPH 382 ===========================================

Privacy issues 

------------------- Sentence 1 -------------------

Privacy issues

>> Tokens are: 
 ['Privacy', 'issues']

>> Bigrams are: 
 [('Privacy', 'issues')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Privacy', 'NN'), ('issues', 'NNS')]

>> Noun Phrases are: 
 ['Privacy issues']

>> Named Entities are: 
 [('GPE', 'Privacy')] 

>> Stemming using Porter Stemmer: 
 [('Privacy', 'privaci'), ('issues', 'issu')]

>> Stemming using Snowball Stemmer: 
 [('Privacy', 'privaci'), ('issues', 'issu')]

>> Lemmatization: 
 [('Privacy', 'Privacy'), ('issues', 'issue')]



========================================== PARAGRAPH 383 ===========================================

The privacy concern typically will make most people uncomfortable, especially if sys- tems cannot guarantee that their personal information will not be accessed by the other  people and organizations. Different from the concern of the security, the privacy issue  is about if it is possible for the system to restore or infer personal information from  the results of big data analytics, even though the input data are anonymous. The pri- vacy issue has become a very important issue because the data mining and other analy- sis technologies will be widely used in big data analytics, the private information may  be exposed to the other people after the analysis process. For example, although all the  gathered data for shop behavior are anonymous (e.g.-, buying a pistol), because the data  can be easily collected by different devices and systems (e.g.-, location of the shop and  age of the buyer), a data mining algorithm can easily infer who bought this pistol. More  precisely, the data analytics is able to reduce the scope of the database because location  of the shop and age of the buyer provide the information to help the system find out pos- sible persons. For this reason, any sensitive information needs to be carefully protected  and used. The anonymous, temporary identification, and encryption are the representa- tive technologies for privacy of data analytics, but the critical factor is how to use, what  to use, and why to use the collected data on big data analytics. 

------------------- Sentence 1 -------------------

The privacy concern typically will make most people uncomfortable, especially if sys- tems cannot guarantee that their personal information will not be accessed by the other  people and organizations.

>> Tokens are: 
 ['The', 'privacy', 'concern', 'typically', 'make', 'people', 'uncomfortable', ',', 'especially', 'sys-', 'tems', 'guarantee', 'personal', 'information', 'accessed', 'people', 'organizations', '.']

>> Bigrams are: 
 [('The', 'privacy'), ('privacy', 'concern'), ('concern', 'typically'), ('typically', 'make'), ('make', 'people'), ('people', 'uncomfortable'), ('uncomfortable', ','), (',', 'especially'), ('especially', 'sys-'), ('sys-', 'tems'), ('tems', 'guarantee'), ('guarantee', 'personal'), ('personal', 'information'), ('information', 'accessed'), ('accessed', 'people'), ('people', 'organizations'), ('organizations', '.')]

>> Trigrams are: 
 [('The', 'privacy', 'concern'), ('privacy', 'concern', 'typically'), ('concern', 'typically', 'make'), ('typically', 'make', 'people'), ('make', 'people', 'uncomfortable'), ('people', 'uncomfortable', ','), ('uncomfortable', ',', 'especially'), (',', 'especially', 'sys-'), ('especially', 'sys-', 'tems'), ('sys-', 'tems', 'guarantee'), ('tems', 'guarantee', 'personal'), ('guarantee', 'personal', 'information'), ('personal', 'information', 'accessed'), ('information', 'accessed', 'people'), ('accessed', 'people', 'organizations'), ('people', 'organizations', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('privacy', 'NN'), ('concern', 'NN'), ('typically', 'RB'), ('make', 'VBP'), ('people', 'NNS'), ('uncomfortable', 'JJ'), (',', ','), ('especially', 'RB'), ('sys-', 'JJ'), ('tems', 'NNS'), ('guarantee', 'VBP'), ('personal', 'JJ'), ('information', 'NN'), ('accessed', 'VBD'), ('people', 'NNS'), ('organizations', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['The privacy concern', 'people', 'sys- tems', 'personal information', 'people organizations']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('privacy', 'privaci'), ('concern', 'concern'), ('typically', 'typic'), ('make', 'make'), ('people', 'peopl'), ('uncomfortable', 'uncomfort'), (',', ','), ('especially', 'especi'), ('sys-', 'sys-'), ('tems', 'tem'), ('guarantee', 'guarante'), ('personal', 'person'), ('information', 'inform'), ('accessed', 'access'), ('people', 'peopl'), ('organizations', 'organ'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('privacy', 'privaci'), ('concern', 'concern'), ('typically', 'typic'), ('make', 'make'), ('people', 'peopl'), ('uncomfortable', 'uncomfort'), (',', ','), ('especially', 'especi'), ('sys-', 'sys-'), ('tems', 'tem'), ('guarantee', 'guarante'), ('personal', 'person'), ('information', 'inform'), ('accessed', 'access'), ('people', 'peopl'), ('organizations', 'organ'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('privacy', 'privacy'), ('concern', 'concern'), ('typically', 'typically'), ('make', 'make'), ('people', 'people'), ('uncomfortable', 'uncomfortable'), (',', ','), ('especially', 'especially'), ('sys-', 'sys-'), ('tems', 'tems'), ('guarantee', 'guarantee'), ('personal', 'personal'), ('information', 'information'), ('accessed', 'accessed'), ('people', 'people'), ('organizations', 'organization'), ('.', '.')]


------------------- Sentence 2 -------------------

Different from the concern of the security, the privacy issue  is about if it is possible for the system to restore or infer personal information from  the results of big data analytics, even though the input data are anonymous.

>> Tokens are: 
 ['Different', 'concern', 'security', ',', 'privacy', 'issue', 'possible', 'system', 'restore', 'infer', 'personal', 'information', 'results', 'big', 'data', 'analytics', ',', 'even', 'though', 'input', 'data', 'anonymous', '.']

>> Bigrams are: 
 [('Different', 'concern'), ('concern', 'security'), ('security', ','), (',', 'privacy'), ('privacy', 'issue'), ('issue', 'possible'), ('possible', 'system'), ('system', 'restore'), ('restore', 'infer'), ('infer', 'personal'), ('personal', 'information'), ('information', 'results'), ('results', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', ','), (',', 'even'), ('even', 'though'), ('though', 'input'), ('input', 'data'), ('data', 'anonymous'), ('anonymous', '.')]

>> Trigrams are: 
 [('Different', 'concern', 'security'), ('concern', 'security', ','), ('security', ',', 'privacy'), (',', 'privacy', 'issue'), ('privacy', 'issue', 'possible'), ('issue', 'possible', 'system'), ('possible', 'system', 'restore'), ('system', 'restore', 'infer'), ('restore', 'infer', 'personal'), ('infer', 'personal', 'information'), ('personal', 'information', 'results'), ('information', 'results', 'big'), ('results', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', ','), ('analytics', ',', 'even'), (',', 'even', 'though'), ('even', 'though', 'input'), ('though', 'input', 'data'), ('input', 'data', 'anonymous'), ('data', 'anonymous', '.')]

>> POS Tags are: 
 [('Different', 'JJ'), ('concern', 'NN'), ('security', 'NN'), (',', ','), ('privacy', 'NN'), ('issue', 'NN'), ('possible', 'JJ'), ('system', 'NN'), ('restore', 'NN'), ('infer', 'VBP'), ('personal', 'JJ'), ('information', 'NN'), ('results', 'NNS'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), (',', ','), ('even', 'RB'), ('though', 'IN'), ('input', 'NN'), ('data', 'NNS'), ('anonymous', 'JJ'), ('.', '.')]

>> Noun Phrases are: 
 ['Different concern security', 'privacy issue', 'possible system restore', 'personal information results', 'big data analytics', 'input data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Different', 'differ'), ('concern', 'concern'), ('security', 'secur'), (',', ','), ('privacy', 'privaci'), ('issue', 'issu'), ('possible', 'possibl'), ('system', 'system'), ('restore', 'restor'), ('infer', 'infer'), ('personal', 'person'), ('information', 'inform'), ('results', 'result'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), (',', ','), ('even', 'even'), ('though', 'though'), ('input', 'input'), ('data', 'data'), ('anonymous', 'anonym'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Different', 'differ'), ('concern', 'concern'), ('security', 'secur'), (',', ','), ('privacy', 'privaci'), ('issue', 'issu'), ('possible', 'possibl'), ('system', 'system'), ('restore', 'restor'), ('infer', 'infer'), ('personal', 'person'), ('information', 'inform'), ('results', 'result'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), (',', ','), ('even', 'even'), ('though', 'though'), ('input', 'input'), ('data', 'data'), ('anonymous', 'anonym'), ('.', '.')]

>> Lemmatization: 
 [('Different', 'Different'), ('concern', 'concern'), ('security', 'security'), (',', ','), ('privacy', 'privacy'), ('issue', 'issue'), ('possible', 'possible'), ('system', 'system'), ('restore', 'restore'), ('infer', 'infer'), ('personal', 'personal'), ('information', 'information'), ('results', 'result'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), (',', ','), ('even', 'even'), ('though', 'though'), ('input', 'input'), ('data', 'data'), ('anonymous', 'anonymous'), ('.', '.')]


------------------- Sentence 3 -------------------

The pri- vacy issue has become a very important issue because the data mining and other analy- sis technologies will be widely used in big data analytics, the private information may  be exposed to the other people after the analysis process.

>> Tokens are: 
 ['The', 'pri-', 'vacy', 'issue', 'become', 'important', 'issue', 'data', 'mining', 'analy-', 'sis', 'technologies', 'widely', 'used', 'big', 'data', 'analytics', ',', 'private', 'information', 'may', 'exposed', 'people', 'analysis', 'process', '.']

>> Bigrams are: 
 [('The', 'pri-'), ('pri-', 'vacy'), ('vacy', 'issue'), ('issue', 'become'), ('become', 'important'), ('important', 'issue'), ('issue', 'data'), ('data', 'mining'), ('mining', 'analy-'), ('analy-', 'sis'), ('sis', 'technologies'), ('technologies', 'widely'), ('widely', 'used'), ('used', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', ','), (',', 'private'), ('private', 'information'), ('information', 'may'), ('may', 'exposed'), ('exposed', 'people'), ('people', 'analysis'), ('analysis', 'process'), ('process', '.')]

>> Trigrams are: 
 [('The', 'pri-', 'vacy'), ('pri-', 'vacy', 'issue'), ('vacy', 'issue', 'become'), ('issue', 'become', 'important'), ('become', 'important', 'issue'), ('important', 'issue', 'data'), ('issue', 'data', 'mining'), ('data', 'mining', 'analy-'), ('mining', 'analy-', 'sis'), ('analy-', 'sis', 'technologies'), ('sis', 'technologies', 'widely'), ('technologies', 'widely', 'used'), ('widely', 'used', 'big'), ('used', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', ','), ('analytics', ',', 'private'), (',', 'private', 'information'), ('private', 'information', 'may'), ('information', 'may', 'exposed'), ('may', 'exposed', 'people'), ('exposed', 'people', 'analysis'), ('people', 'analysis', 'process'), ('analysis', 'process', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('pri-', 'JJ'), ('vacy', 'NN'), ('issue', 'NN'), ('become', 'RBS'), ('important', 'JJ'), ('issue', 'NN'), ('data', 'NNS'), ('mining', 'VBG'), ('analy-', 'JJ'), ('sis', 'NN'), ('technologies', 'NNS'), ('widely', 'RB'), ('used', 'VBD'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), (',', ','), ('private', 'JJ'), ('information', 'NN'), ('may', 'MD'), ('exposed', 'VBN'), ('people', 'NNS'), ('analysis', 'NN'), ('process', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['The pri- vacy issue', 'important issue data', 'analy- sis technologies', 'big data analytics', 'private information', 'people analysis process']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('pri-', 'pri-'), ('vacy', 'vaci'), ('issue', 'issu'), ('become', 'becom'), ('important', 'import'), ('issue', 'issu'), ('data', 'data'), ('mining', 'mine'), ('analy-', 'analy-'), ('sis', 'si'), ('technologies', 'technolog'), ('widely', 'wide'), ('used', 'use'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), (',', ','), ('private', 'privat'), ('information', 'inform'), ('may', 'may'), ('exposed', 'expos'), ('people', 'peopl'), ('analysis', 'analysi'), ('process', 'process'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('pri-', 'pri-'), ('vacy', 'vaci'), ('issue', 'issu'), ('become', 'becom'), ('important', 'import'), ('issue', 'issu'), ('data', 'data'), ('mining', 'mine'), ('analy-', 'analy-'), ('sis', 'sis'), ('technologies', 'technolog'), ('widely', 'wide'), ('used', 'use'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), (',', ','), ('private', 'privat'), ('information', 'inform'), ('may', 'may'), ('exposed', 'expos'), ('people', 'peopl'), ('analysis', 'analysi'), ('process', 'process'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('pri-', 'pri-'), ('vacy', 'vacy'), ('issue', 'issue'), ('become', 'become'), ('important', 'important'), ('issue', 'issue'), ('data', 'data'), ('mining', 'mining'), ('analy-', 'analy-'), ('sis', 'si'), ('technologies', 'technology'), ('widely', 'widely'), ('used', 'used'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), (',', ','), ('private', 'private'), ('information', 'information'), ('may', 'may'), ('exposed', 'exposed'), ('people', 'people'), ('analysis', 'analysis'), ('process', 'process'), ('.', '.')]


------------------- Sentence 4 -------------------

For example, although all the  gathered data for shop behavior are anonymous (e.g.-, buying a pistol), because the data  can be easily collected by different devices and systems (e.g.-, location of the shop and  age of the buyer), a data mining algorithm can easily infer who bought this pistol.

>> Tokens are: 
 ['For', 'example', ',', 'although', 'gathered', 'data', 'shop', 'behavior', 'anonymous', '(', 'e.g.-', ',', 'buying', 'pistol', ')', ',', 'data', 'easily', 'collected', 'different', 'devices', 'systems', '(', 'e.g.-', ',', 'location', 'shop', 'age', 'buyer', ')', ',', 'data', 'mining', 'algorithm', 'easily', 'infer', 'bought', 'pistol', '.']

>> Bigrams are: 
 [('For', 'example'), ('example', ','), (',', 'although'), ('although', 'gathered'), ('gathered', 'data'), ('data', 'shop'), ('shop', 'behavior'), ('behavior', 'anonymous'), ('anonymous', '('), ('(', 'e.g.-'), ('e.g.-', ','), (',', 'buying'), ('buying', 'pistol'), ('pistol', ')'), (')', ','), (',', 'data'), ('data', 'easily'), ('easily', 'collected'), ('collected', 'different'), ('different', 'devices'), ('devices', 'systems'), ('systems', '('), ('(', 'e.g.-'), ('e.g.-', ','), (',', 'location'), ('location', 'shop'), ('shop', 'age'), ('age', 'buyer'), ('buyer', ')'), (')', ','), (',', 'data'), ('data', 'mining'), ('mining', 'algorithm'), ('algorithm', 'easily'), ('easily', 'infer'), ('infer', 'bought'), ('bought', 'pistol'), ('pistol', '.')]

>> Trigrams are: 
 [('For', 'example', ','), ('example', ',', 'although'), (',', 'although', 'gathered'), ('although', 'gathered', 'data'), ('gathered', 'data', 'shop'), ('data', 'shop', 'behavior'), ('shop', 'behavior', 'anonymous'), ('behavior', 'anonymous', '('), ('anonymous', '(', 'e.g.-'), ('(', 'e.g.-', ','), ('e.g.-', ',', 'buying'), (',', 'buying', 'pistol'), ('buying', 'pistol', ')'), ('pistol', ')', ','), (')', ',', 'data'), (',', 'data', 'easily'), ('data', 'easily', 'collected'), ('easily', 'collected', 'different'), ('collected', 'different', 'devices'), ('different', 'devices', 'systems'), ('devices', 'systems', '('), ('systems', '(', 'e.g.-'), ('(', 'e.g.-', ','), ('e.g.-', ',', 'location'), (',', 'location', 'shop'), ('location', 'shop', 'age'), ('shop', 'age', 'buyer'), ('age', 'buyer', ')'), ('buyer', ')', ','), (')', ',', 'data'), (',', 'data', 'mining'), ('data', 'mining', 'algorithm'), ('mining', 'algorithm', 'easily'), ('algorithm', 'easily', 'infer'), ('easily', 'infer', 'bought'), ('infer', 'bought', 'pistol'), ('bought', 'pistol', '.')]

>> POS Tags are: 
 [('For', 'IN'), ('example', 'NN'), (',', ','), ('although', 'IN'), ('gathered', 'VBN'), ('data', 'NNS'), ('shop', 'NN'), ('behavior', 'NN'), ('anonymous', 'JJ'), ('(', '('), ('e.g.-', 'JJ'), (',', ','), ('buying', 'VBG'), ('pistol', 'NN'), (')', ')'), (',', ','), ('data', 'NNS'), ('easily', 'RB'), ('collected', 'VBD'), ('different', 'JJ'), ('devices', 'NNS'), ('systems', 'NNS'), ('(', '('), ('e.g.-', 'JJ'), (',', ','), ('location', 'NN'), ('shop', 'NN'), ('age', 'NN'), ('buyer', 'NN'), (')', ')'), (',', ','), ('data', 'NNS'), ('mining', 'NN'), ('algorithm', 'VBP'), ('easily', 'RB'), ('infer', 'VB'), ('bought', 'JJ'), ('pistol', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['example', 'data shop behavior', 'pistol', 'data', 'different devices systems', 'location shop age buyer', 'data mining', 'bought pistol']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('For', 'for'), ('example', 'exampl'), (',', ','), ('although', 'although'), ('gathered', 'gather'), ('data', 'data'), ('shop', 'shop'), ('behavior', 'behavior'), ('anonymous', 'anonym'), ('(', '('), ('e.g.-', 'e.g.-'), (',', ','), ('buying', 'buy'), ('pistol', 'pistol'), (')', ')'), (',', ','), ('data', 'data'), ('easily', 'easili'), ('collected', 'collect'), ('different', 'differ'), ('devices', 'devic'), ('systems', 'system'), ('(', '('), ('e.g.-', 'e.g.-'), (',', ','), ('location', 'locat'), ('shop', 'shop'), ('age', 'age'), ('buyer', 'buyer'), (')', ')'), (',', ','), ('data', 'data'), ('mining', 'mine'), ('algorithm', 'algorithm'), ('easily', 'easili'), ('infer', 'infer'), ('bought', 'bought'), ('pistol', 'pistol'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('For', 'for'), ('example', 'exampl'), (',', ','), ('although', 'although'), ('gathered', 'gather'), ('data', 'data'), ('shop', 'shop'), ('behavior', 'behavior'), ('anonymous', 'anonym'), ('(', '('), ('e.g.-', 'e.g.-'), (',', ','), ('buying', 'buy'), ('pistol', 'pistol'), (')', ')'), (',', ','), ('data', 'data'), ('easily', 'easili'), ('collected', 'collect'), ('different', 'differ'), ('devices', 'devic'), ('systems', 'system'), ('(', '('), ('e.g.-', 'e.g.-'), (',', ','), ('location', 'locat'), ('shop', 'shop'), ('age', 'age'), ('buyer', 'buyer'), (')', ')'), (',', ','), ('data', 'data'), ('mining', 'mine'), ('algorithm', 'algorithm'), ('easily', 'easili'), ('infer', 'infer'), ('bought', 'bought'), ('pistol', 'pistol'), ('.', '.')]

>> Lemmatization: 
 [('For', 'For'), ('example', 'example'), (',', ','), ('although', 'although'), ('gathered', 'gathered'), ('data', 'data'), ('shop', 'shop'), ('behavior', 'behavior'), ('anonymous', 'anonymous'), ('(', '('), ('e.g.-', 'e.g.-'), (',', ','), ('buying', 'buying'), ('pistol', 'pistol'), (')', ')'), (',', ','), ('data', 'data'), ('easily', 'easily'), ('collected', 'collected'), ('different', 'different'), ('devices', 'device'), ('systems', 'system'), ('(', '('), ('e.g.-', 'e.g.-'), (',', ','), ('location', 'location'), ('shop', 'shop'), ('age', 'age'), ('buyer', 'buyer'), (')', ')'), (',', ','), ('data', 'data'), ('mining', 'mining'), ('algorithm', 'algorithm'), ('easily', 'easily'), ('infer', 'infer'), ('bought', 'bought'), ('pistol', 'pistol'), ('.', '.')]


------------------- Sentence 5 -------------------

More  precisely, the data analytics is able to reduce the scope of the database because location  of the shop and age of the buyer provide the information to help the system find out pos- sible persons.

>> Tokens are: 
 ['More', 'precisely', ',', 'data', 'analytics', 'able', 'reduce', 'scope', 'database', 'location', 'shop', 'age', 'buyer', 'provide', 'information', 'help', 'system', 'find', 'pos-', 'sible', 'persons', '.']

>> Bigrams are: 
 [('More', 'precisely'), ('precisely', ','), (',', 'data'), ('data', 'analytics'), ('analytics', 'able'), ('able', 'reduce'), ('reduce', 'scope'), ('scope', 'database'), ('database', 'location'), ('location', 'shop'), ('shop', 'age'), ('age', 'buyer'), ('buyer', 'provide'), ('provide', 'information'), ('information', 'help'), ('help', 'system'), ('system', 'find'), ('find', 'pos-'), ('pos-', 'sible'), ('sible', 'persons'), ('persons', '.')]

>> Trigrams are: 
 [('More', 'precisely', ','), ('precisely', ',', 'data'), (',', 'data', 'analytics'), ('data', 'analytics', 'able'), ('analytics', 'able', 'reduce'), ('able', 'reduce', 'scope'), ('reduce', 'scope', 'database'), ('scope', 'database', 'location'), ('database', 'location', 'shop'), ('location', 'shop', 'age'), ('shop', 'age', 'buyer'), ('age', 'buyer', 'provide'), ('buyer', 'provide', 'information'), ('provide', 'information', 'help'), ('information', 'help', 'system'), ('help', 'system', 'find'), ('system', 'find', 'pos-'), ('find', 'pos-', 'sible'), ('pos-', 'sible', 'persons'), ('sible', 'persons', '.')]

>> POS Tags are: 
 [('More', 'RBR'), ('precisely', 'RB'), (',', ','), ('data', 'NNS'), ('analytics', 'NNS'), ('able', 'JJ'), ('reduce', 'VB'), ('scope', 'NN'), ('database', 'NN'), ('location', 'NN'), ('shop', 'NN'), ('age', 'NN'), ('buyer', 'NN'), ('provide', 'VBP'), ('information', 'NN'), ('help', 'NN'), ('system', 'NN'), ('find', 'VB'), ('pos-', 'JJ'), ('sible', 'JJ'), ('persons', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['data analytics', 'scope database location shop age buyer', 'information help system', 'pos- sible persons']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('More', 'more'), ('precisely', 'precis'), (',', ','), ('data', 'data'), ('analytics', 'analyt'), ('able', 'abl'), ('reduce', 'reduc'), ('scope', 'scope'), ('database', 'databas'), ('location', 'locat'), ('shop', 'shop'), ('age', 'age'), ('buyer', 'buyer'), ('provide', 'provid'), ('information', 'inform'), ('help', 'help'), ('system', 'system'), ('find', 'find'), ('pos-', 'pos-'), ('sible', 'sibl'), ('persons', 'person'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('More', 'more'), ('precisely', 'precis'), (',', ','), ('data', 'data'), ('analytics', 'analyt'), ('able', 'abl'), ('reduce', 'reduc'), ('scope', 'scope'), ('database', 'databas'), ('location', 'locat'), ('shop', 'shop'), ('age', 'age'), ('buyer', 'buyer'), ('provide', 'provid'), ('information', 'inform'), ('help', 'help'), ('system', 'system'), ('find', 'find'), ('pos-', 'pos-'), ('sible', 'sibl'), ('persons', 'person'), ('.', '.')]

>> Lemmatization: 
 [('More', 'More'), ('precisely', 'precisely'), (',', ','), ('data', 'data'), ('analytics', 'analytics'), ('able', 'able'), ('reduce', 'reduce'), ('scope', 'scope'), ('database', 'database'), ('location', 'location'), ('shop', 'shop'), ('age', 'age'), ('buyer', 'buyer'), ('provide', 'provide'), ('information', 'information'), ('help', 'help'), ('system', 'system'), ('find', 'find'), ('pos-', 'pos-'), ('sible', 'sible'), ('persons', 'person'), ('.', '.')]


------------------- Sentence 6 -------------------

For this reason, any sensitive information needs to be carefully protected  and used.

>> Tokens are: 
 ['For', 'reason', ',', 'sensitive', 'information', 'needs', 'carefully', 'protected', 'used', '.']

>> Bigrams are: 
 [('For', 'reason'), ('reason', ','), (',', 'sensitive'), ('sensitive', 'information'), ('information', 'needs'), ('needs', 'carefully'), ('carefully', 'protected'), ('protected', 'used'), ('used', '.')]

>> Trigrams are: 
 [('For', 'reason', ','), ('reason', ',', 'sensitive'), (',', 'sensitive', 'information'), ('sensitive', 'information', 'needs'), ('information', 'needs', 'carefully'), ('needs', 'carefully', 'protected'), ('carefully', 'protected', 'used'), ('protected', 'used', '.')]

>> POS Tags are: 
 [('For', 'IN'), ('reason', 'NN'), (',', ','), ('sensitive', 'JJ'), ('information', 'NN'), ('needs', 'NNS'), ('carefully', 'RB'), ('protected', 'VBD'), ('used', 'VBN'), ('.', '.')]

>> Noun Phrases are: 
 ['reason', 'sensitive information needs']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('For', 'for'), ('reason', 'reason'), (',', ','), ('sensitive', 'sensit'), ('information', 'inform'), ('needs', 'need'), ('carefully', 'care'), ('protected', 'protect'), ('used', 'use'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('For', 'for'), ('reason', 'reason'), (',', ','), ('sensitive', 'sensit'), ('information', 'inform'), ('needs', 'need'), ('carefully', 'care'), ('protected', 'protect'), ('used', 'use'), ('.', '.')]

>> Lemmatization: 
 [('For', 'For'), ('reason', 'reason'), (',', ','), ('sensitive', 'sensitive'), ('information', 'information'), ('needs', 'need'), ('carefully', 'carefully'), ('protected', 'protected'), ('used', 'used'), ('.', '.')]


------------------- Sentence 7 -------------------

The anonymous, temporary identification, and encryption are the representa- tive technologies for privacy of data analytics, but the critical factor is how to use, what  to use, and why to use the collected data on big data analytics.

>> Tokens are: 
 ['The', 'anonymous', ',', 'temporary', 'identification', ',', 'encryption', 'representa-', 'tive', 'technologies', 'privacy', 'data', 'analytics', ',', 'critical', 'factor', 'use', ',', 'use', ',', 'use', 'collected', 'data', 'big', 'data', 'analytics', '.']

>> Bigrams are: 
 [('The', 'anonymous'), ('anonymous', ','), (',', 'temporary'), ('temporary', 'identification'), ('identification', ','), (',', 'encryption'), ('encryption', 'representa-'), ('representa-', 'tive'), ('tive', 'technologies'), ('technologies', 'privacy'), ('privacy', 'data'), ('data', 'analytics'), ('analytics', ','), (',', 'critical'), ('critical', 'factor'), ('factor', 'use'), ('use', ','), (',', 'use'), ('use', ','), (',', 'use'), ('use', 'collected'), ('collected', 'data'), ('data', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', '.')]

>> Trigrams are: 
 [('The', 'anonymous', ','), ('anonymous', ',', 'temporary'), (',', 'temporary', 'identification'), ('temporary', 'identification', ','), ('identification', ',', 'encryption'), (',', 'encryption', 'representa-'), ('encryption', 'representa-', 'tive'), ('representa-', 'tive', 'technologies'), ('tive', 'technologies', 'privacy'), ('technologies', 'privacy', 'data'), ('privacy', 'data', 'analytics'), ('data', 'analytics', ','), ('analytics', ',', 'critical'), (',', 'critical', 'factor'), ('critical', 'factor', 'use'), ('factor', 'use', ','), ('use', ',', 'use'), (',', 'use', ','), ('use', ',', 'use'), (',', 'use', 'collected'), ('use', 'collected', 'data'), ('collected', 'data', 'big'), ('data', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('anonymous', 'JJ'), (',', ','), ('temporary', 'JJ'), ('identification', 'NN'), (',', ','), ('encryption', 'NN'), ('representa-', 'JJ'), ('tive', 'JJ'), ('technologies', 'NNS'), ('privacy', 'NN'), ('data', 'NNS'), ('analytics', 'NNS'), (',', ','), ('critical', 'JJ'), ('factor', 'NN'), ('use', 'NN'), (',', ','), ('use', 'NN'), (',', ','), ('use', 'NN'), ('collected', 'VBN'), ('data', 'NNS'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['temporary identification', 'encryption', 'representa- tive technologies privacy data analytics', 'critical factor use', 'use', 'use', 'data', 'big data analytics']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('anonymous', 'anonym'), (',', ','), ('temporary', 'temporari'), ('identification', 'identif'), (',', ','), ('encryption', 'encrypt'), ('representa-', 'representa-'), ('tive', 'tive'), ('technologies', 'technolog'), ('privacy', 'privaci'), ('data', 'data'), ('analytics', 'analyt'), (',', ','), ('critical', 'critic'), ('factor', 'factor'), ('use', 'use'), (',', ','), ('use', 'use'), (',', ','), ('use', 'use'), ('collected', 'collect'), ('data', 'data'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('anonymous', 'anonym'), (',', ','), ('temporary', 'temporari'), ('identification', 'identif'), (',', ','), ('encryption', 'encrypt'), ('representa-', 'representa-'), ('tive', 'tive'), ('technologies', 'technolog'), ('privacy', 'privaci'), ('data', 'data'), ('analytics', 'analyt'), (',', ','), ('critical', 'critic'), ('factor', 'factor'), ('use', 'use'), (',', ','), ('use', 'use'), (',', ','), ('use', 'use'), ('collected', 'collect'), ('data', 'data'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('anonymous', 'anonymous'), (',', ','), ('temporary', 'temporary'), ('identification', 'identification'), (',', ','), ('encryption', 'encryption'), ('representa-', 'representa-'), ('tive', 'tive'), ('technologies', 'technology'), ('privacy', 'privacy'), ('data', 'data'), ('analytics', 'analytics'), (',', ','), ('critical', 'critical'), ('factor', 'factor'), ('use', 'use'), (',', ','), ('use', 'use'), (',', ','), ('use', 'use'), ('collected', 'collected'), ('data', 'data'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('.', '.')]



========================================== PARAGRAPH 384 ===========================================

Conclusions In this paper, we reviewed studies on the data analytics from the traditional data analysis  to the recent big data analysis. From the system perspective, the KDD process is used  as the framework for these studies and is summarized into three parts: input, analysis,  and output. From the perspective of big data analytics framework and platform, the dis- cussions are focused on the performance-oriented and results-oriented issues. From the  perspective of data mining problem, this paper gives a brief introduction to the data and  big data mining algorithms which consist of clustering, classification, and frequent pat- terns mining technologies. To better understand the changes brought about by the big  data, this paper is focused on the data analysis of KDD from the platform/framework to  data mining. The open issues on computation, quality of end result, security, and privacy  are then discussed to explain which open issues we may face. Last but not least, to help  the audience of the paper find solutions to welcome the new age of big data, the possible  high impact research trends are given below: 

------------------- Sentence 1 -------------------

Conclusions In this paper, we reviewed studies on the data analytics from the traditional data analysis  to the recent big data analysis.

>> Tokens are: 
 ['Conclusions', 'In', 'paper', ',', 'reviewed', 'studies', 'data', 'analytics', 'traditional', 'data', 'analysis', 'recent', 'big', 'data', 'analysis', '.']

>> Bigrams are: 
 [('Conclusions', 'In'), ('In', 'paper'), ('paper', ','), (',', 'reviewed'), ('reviewed', 'studies'), ('studies', 'data'), ('data', 'analytics'), ('analytics', 'traditional'), ('traditional', 'data'), ('data', 'analysis'), ('analysis', 'recent'), ('recent', 'big'), ('big', 'data'), ('data', 'analysis'), ('analysis', '.')]

>> Trigrams are: 
 [('Conclusions', 'In', 'paper'), ('In', 'paper', ','), ('paper', ',', 'reviewed'), (',', 'reviewed', 'studies'), ('reviewed', 'studies', 'data'), ('studies', 'data', 'analytics'), ('data', 'analytics', 'traditional'), ('analytics', 'traditional', 'data'), ('traditional', 'data', 'analysis'), ('data', 'analysis', 'recent'), ('analysis', 'recent', 'big'), ('recent', 'big', 'data'), ('big', 'data', 'analysis'), ('data', 'analysis', '.')]

>> POS Tags are: 
 [('Conclusions', 'NNS'), ('In', 'IN'), ('paper', 'NN'), (',', ','), ('reviewed', 'VBD'), ('studies', 'NNS'), ('data', 'NNS'), ('analytics', 'NNS'), ('traditional', 'JJ'), ('data', 'NNS'), ('analysis', 'NN'), ('recent', 'JJ'), ('big', 'JJ'), ('data', 'NNS'), ('analysis', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Conclusions', 'paper', 'studies data analytics', 'traditional data analysis', 'recent big data analysis']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Conclusions', 'conclus'), ('In', 'in'), ('paper', 'paper'), (',', ','), ('reviewed', 'review'), ('studies', 'studi'), ('data', 'data'), ('analytics', 'analyt'), ('traditional', 'tradit'), ('data', 'data'), ('analysis', 'analysi'), ('recent', 'recent'), ('big', 'big'), ('data', 'data'), ('analysis', 'analysi'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Conclusions', 'conclus'), ('In', 'in'), ('paper', 'paper'), (',', ','), ('reviewed', 'review'), ('studies', 'studi'), ('data', 'data'), ('analytics', 'analyt'), ('traditional', 'tradit'), ('data', 'data'), ('analysis', 'analysi'), ('recent', 'recent'), ('big', 'big'), ('data', 'data'), ('analysis', 'analysi'), ('.', '.')]

>> Lemmatization: 
 [('Conclusions', 'Conclusions'), ('In', 'In'), ('paper', 'paper'), (',', ','), ('reviewed', 'reviewed'), ('studies', 'study'), ('data', 'data'), ('analytics', 'analytics'), ('traditional', 'traditional'), ('data', 'data'), ('analysis', 'analysis'), ('recent', 'recent'), ('big', 'big'), ('data', 'data'), ('analysis', 'analysis'), ('.', '.')]


------------------- Sentence 2 -------------------

From the system perspective, the KDD process is used  as the framework for these studies and is summarized into three parts: input, analysis,  and output.

>> Tokens are: 
 ['From', 'system', 'perspective', ',', 'KDD', 'process', 'used', 'framework', 'studies', 'summarized', 'three', 'parts', ':', 'input', ',', 'analysis', ',', 'output', '.']

>> Bigrams are: 
 [('From', 'system'), ('system', 'perspective'), ('perspective', ','), (',', 'KDD'), ('KDD', 'process'), ('process', 'used'), ('used', 'framework'), ('framework', 'studies'), ('studies', 'summarized'), ('summarized', 'three'), ('three', 'parts'), ('parts', ':'), (':', 'input'), ('input', ','), (',', 'analysis'), ('analysis', ','), (',', 'output'), ('output', '.')]

>> Trigrams are: 
 [('From', 'system', 'perspective'), ('system', 'perspective', ','), ('perspective', ',', 'KDD'), (',', 'KDD', 'process'), ('KDD', 'process', 'used'), ('process', 'used', 'framework'), ('used', 'framework', 'studies'), ('framework', 'studies', 'summarized'), ('studies', 'summarized', 'three'), ('summarized', 'three', 'parts'), ('three', 'parts', ':'), ('parts', ':', 'input'), (':', 'input', ','), ('input', ',', 'analysis'), (',', 'analysis', ','), ('analysis', ',', 'output'), (',', 'output', '.')]

>> POS Tags are: 
 [('From', 'IN'), ('system', 'NN'), ('perspective', 'NN'), (',', ','), ('KDD', 'NNP'), ('process', 'NN'), ('used', 'VBN'), ('framework', 'NN'), ('studies', 'NNS'), ('summarized', 'VBD'), ('three', 'CD'), ('parts', 'NNS'), (':', ':'), ('input', 'NN'), (',', ','), ('analysis', 'NN'), (',', ','), ('output', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['system perspective', 'KDD process', 'framework studies', 'parts', 'input', 'analysis', 'output']

>> Named Entities are: 
 [('ORGANIZATION', 'KDD')] 

>> Stemming using Porter Stemmer: 
 [('From', 'from'), ('system', 'system'), ('perspective', 'perspect'), (',', ','), ('KDD', 'kdd'), ('process', 'process'), ('used', 'use'), ('framework', 'framework'), ('studies', 'studi'), ('summarized', 'summar'), ('three', 'three'), ('parts', 'part'), (':', ':'), ('input', 'input'), (',', ','), ('analysis', 'analysi'), (',', ','), ('output', 'output'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('From', 'from'), ('system', 'system'), ('perspective', 'perspect'), (',', ','), ('KDD', 'kdd'), ('process', 'process'), ('used', 'use'), ('framework', 'framework'), ('studies', 'studi'), ('summarized', 'summar'), ('three', 'three'), ('parts', 'part'), (':', ':'), ('input', 'input'), (',', ','), ('analysis', 'analysi'), (',', ','), ('output', 'output'), ('.', '.')]

>> Lemmatization: 
 [('From', 'From'), ('system', 'system'), ('perspective', 'perspective'), (',', ','), ('KDD', 'KDD'), ('process', 'process'), ('used', 'used'), ('framework', 'framework'), ('studies', 'study'), ('summarized', 'summarized'), ('three', 'three'), ('parts', 'part'), (':', ':'), ('input', 'input'), (',', ','), ('analysis', 'analysis'), (',', ','), ('output', 'output'), ('.', '.')]


------------------- Sentence 3 -------------------

From the perspective of big data analytics framework and platform, the dis- cussions are focused on the performance-oriented and results-oriented issues.

>> Tokens are: 
 ['From', 'perspective', 'big', 'data', 'analytics', 'framework', 'platform', ',', 'dis-', 'cussions', 'focused', 'performance-oriented', 'results-oriented', 'issues', '.']

>> Bigrams are: 
 [('From', 'perspective'), ('perspective', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', 'framework'), ('framework', 'platform'), ('platform', ','), (',', 'dis-'), ('dis-', 'cussions'), ('cussions', 'focused'), ('focused', 'performance-oriented'), ('performance-oriented', 'results-oriented'), ('results-oriented', 'issues'), ('issues', '.')]

>> Trigrams are: 
 [('From', 'perspective', 'big'), ('perspective', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', 'framework'), ('analytics', 'framework', 'platform'), ('framework', 'platform', ','), ('platform', ',', 'dis-'), (',', 'dis-', 'cussions'), ('dis-', 'cussions', 'focused'), ('cussions', 'focused', 'performance-oriented'), ('focused', 'performance-oriented', 'results-oriented'), ('performance-oriented', 'results-oriented', 'issues'), ('results-oriented', 'issues', '.')]

>> POS Tags are: 
 [('From', 'IN'), ('perspective', 'JJ'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('framework', 'NN'), ('platform', 'NN'), (',', ','), ('dis-', 'JJ'), ('cussions', 'NNS'), ('focused', 'VBD'), ('performance-oriented', 'JJ'), ('results-oriented', 'JJ'), ('issues', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['perspective big data analytics framework platform', 'dis- cussions', 'performance-oriented results-oriented issues']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('From', 'from'), ('perspective', 'perspect'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('framework', 'framework'), ('platform', 'platform'), (',', ','), ('dis-', 'dis-'), ('cussions', 'cussion'), ('focused', 'focus'), ('performance-oriented', 'performance-ori'), ('results-oriented', 'results-ori'), ('issues', 'issu'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('From', 'from'), ('perspective', 'perspect'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('framework', 'framework'), ('platform', 'platform'), (',', ','), ('dis-', 'dis-'), ('cussions', 'cussion'), ('focused', 'focus'), ('performance-oriented', 'performance-ori'), ('results-oriented', 'results-ori'), ('issues', 'issu'), ('.', '.')]

>> Lemmatization: 
 [('From', 'From'), ('perspective', 'perspective'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('framework', 'framework'), ('platform', 'platform'), (',', ','), ('dis-', 'dis-'), ('cussions', 'cussions'), ('focused', 'focused'), ('performance-oriented', 'performance-oriented'), ('results-oriented', 'results-oriented'), ('issues', 'issue'), ('.', '.')]


------------------- Sentence 4 -------------------

From the  perspective of data mining problem, this paper gives a brief introduction to the data and  big data mining algorithms which consist of clustering, classification, and frequent pat- terns mining technologies.

>> Tokens are: 
 ['From', 'perspective', 'data', 'mining', 'problem', ',', 'paper', 'gives', 'brief', 'introduction', 'data', 'big', 'data', 'mining', 'algorithms', 'consist', 'clustering', ',', 'classification', ',', 'frequent', 'pat-', 'terns', 'mining', 'technologies', '.']

>> Bigrams are: 
 [('From', 'perspective'), ('perspective', 'data'), ('data', 'mining'), ('mining', 'problem'), ('problem', ','), (',', 'paper'), ('paper', 'gives'), ('gives', 'brief'), ('brief', 'introduction'), ('introduction', 'data'), ('data', 'big'), ('big', 'data'), ('data', 'mining'), ('mining', 'algorithms'), ('algorithms', 'consist'), ('consist', 'clustering'), ('clustering', ','), (',', 'classification'), ('classification', ','), (',', 'frequent'), ('frequent', 'pat-'), ('pat-', 'terns'), ('terns', 'mining'), ('mining', 'technologies'), ('technologies', '.')]

>> Trigrams are: 
 [('From', 'perspective', 'data'), ('perspective', 'data', 'mining'), ('data', 'mining', 'problem'), ('mining', 'problem', ','), ('problem', ',', 'paper'), (',', 'paper', 'gives'), ('paper', 'gives', 'brief'), ('gives', 'brief', 'introduction'), ('brief', 'introduction', 'data'), ('introduction', 'data', 'big'), ('data', 'big', 'data'), ('big', 'data', 'mining'), ('data', 'mining', 'algorithms'), ('mining', 'algorithms', 'consist'), ('algorithms', 'consist', 'clustering'), ('consist', 'clustering', ','), ('clustering', ',', 'classification'), (',', 'classification', ','), ('classification', ',', 'frequent'), (',', 'frequent', 'pat-'), ('frequent', 'pat-', 'terns'), ('pat-', 'terns', 'mining'), ('terns', 'mining', 'technologies'), ('mining', 'technologies', '.')]

>> POS Tags are: 
 [('From', 'IN'), ('perspective', 'JJ'), ('data', 'NNS'), ('mining', 'NN'), ('problem', 'NN'), (',', ','), ('paper', 'NN'), ('gives', 'VBZ'), ('brief', 'JJ'), ('introduction', 'NN'), ('data', 'NNS'), ('big', 'JJ'), ('data', 'NNS'), ('mining', 'NN'), ('algorithms', 'JJ'), ('consist', 'NN'), ('clustering', 'NN'), (',', ','), ('classification', 'NN'), (',', ','), ('frequent', 'JJ'), ('pat-', 'JJ'), ('terns', 'NNS'), ('mining', 'VBG'), ('technologies', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['perspective data mining problem', 'paper', 'brief introduction data', 'big data mining', 'algorithms consist clustering', 'classification', 'frequent pat- terns', 'technologies']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('From', 'from'), ('perspective', 'perspect'), ('data', 'data'), ('mining', 'mine'), ('problem', 'problem'), (',', ','), ('paper', 'paper'), ('gives', 'give'), ('brief', 'brief'), ('introduction', 'introduct'), ('data', 'data'), ('big', 'big'), ('data', 'data'), ('mining', 'mine'), ('algorithms', 'algorithm'), ('consist', 'consist'), ('clustering', 'cluster'), (',', ','), ('classification', 'classif'), (',', ','), ('frequent', 'frequent'), ('pat-', 'pat-'), ('terns', 'tern'), ('mining', 'mine'), ('technologies', 'technolog'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('From', 'from'), ('perspective', 'perspect'), ('data', 'data'), ('mining', 'mine'), ('problem', 'problem'), (',', ','), ('paper', 'paper'), ('gives', 'give'), ('brief', 'brief'), ('introduction', 'introduct'), ('data', 'data'), ('big', 'big'), ('data', 'data'), ('mining', 'mine'), ('algorithms', 'algorithm'), ('consist', 'consist'), ('clustering', 'cluster'), (',', ','), ('classification', 'classif'), (',', ','), ('frequent', 'frequent'), ('pat-', 'pat-'), ('terns', 'tern'), ('mining', 'mine'), ('technologies', 'technolog'), ('.', '.')]

>> Lemmatization: 
 [('From', 'From'), ('perspective', 'perspective'), ('data', 'data'), ('mining', 'mining'), ('problem', 'problem'), (',', ','), ('paper', 'paper'), ('gives', 'give'), ('brief', 'brief'), ('introduction', 'introduction'), ('data', 'data'), ('big', 'big'), ('data', 'data'), ('mining', 'mining'), ('algorithms', 'algorithm'), ('consist', 'consist'), ('clustering', 'clustering'), (',', ','), ('classification', 'classification'), (',', ','), ('frequent', 'frequent'), ('pat-', 'pat-'), ('terns', 'tern'), ('mining', 'mining'), ('technologies', 'technology'), ('.', '.')]


------------------- Sentence 5 -------------------

To better understand the changes brought about by the big  data, this paper is focused on the data analysis of KDD from the platform/framework to  data mining.

>> Tokens are: 
 ['To', 'better', 'understand', 'changes', 'brought', 'big', 'data', ',', 'paper', 'focused', 'data', 'analysis', 'KDD', 'platform/framework', 'data', 'mining', '.']

>> Bigrams are: 
 [('To', 'better'), ('better', 'understand'), ('understand', 'changes'), ('changes', 'brought'), ('brought', 'big'), ('big', 'data'), ('data', ','), (',', 'paper'), ('paper', 'focused'), ('focused', 'data'), ('data', 'analysis'), ('analysis', 'KDD'), ('KDD', 'platform/framework'), ('platform/framework', 'data'), ('data', 'mining'), ('mining', '.')]

>> Trigrams are: 
 [('To', 'better', 'understand'), ('better', 'understand', 'changes'), ('understand', 'changes', 'brought'), ('changes', 'brought', 'big'), ('brought', 'big', 'data'), ('big', 'data', ','), ('data', ',', 'paper'), (',', 'paper', 'focused'), ('paper', 'focused', 'data'), ('focused', 'data', 'analysis'), ('data', 'analysis', 'KDD'), ('analysis', 'KDD', 'platform/framework'), ('KDD', 'platform/framework', 'data'), ('platform/framework', 'data', 'mining'), ('data', 'mining', '.')]

>> POS Tags are: 
 [('To', 'TO'), ('better', 'JJR'), ('understand', 'NN'), ('changes', 'NNS'), ('brought', 'VBD'), ('big', 'JJ'), ('data', 'NNS'), (',', ','), ('paper', 'NN'), ('focused', 'VBD'), ('data', 'NNS'), ('analysis', 'NN'), ('KDD', 'NNP'), ('platform/framework', 'NN'), ('data', 'NNS'), ('mining', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['understand changes', 'big data', 'paper', 'data analysis KDD platform/framework data mining']

>> Named Entities are: 
 [('ORGANIZATION', 'KDD')] 

>> Stemming using Porter Stemmer: 
 [('To', 'to'), ('better', 'better'), ('understand', 'understand'), ('changes', 'chang'), ('brought', 'brought'), ('big', 'big'), ('data', 'data'), (',', ','), ('paper', 'paper'), ('focused', 'focus'), ('data', 'data'), ('analysis', 'analysi'), ('KDD', 'kdd'), ('platform/framework', 'platform/framework'), ('data', 'data'), ('mining', 'mine'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('To', 'to'), ('better', 'better'), ('understand', 'understand'), ('changes', 'chang'), ('brought', 'brought'), ('big', 'big'), ('data', 'data'), (',', ','), ('paper', 'paper'), ('focused', 'focus'), ('data', 'data'), ('analysis', 'analysi'), ('KDD', 'kdd'), ('platform/framework', 'platform/framework'), ('data', 'data'), ('mining', 'mine'), ('.', '.')]

>> Lemmatization: 
 [('To', 'To'), ('better', 'better'), ('understand', 'understand'), ('changes', 'change'), ('brought', 'brought'), ('big', 'big'), ('data', 'data'), (',', ','), ('paper', 'paper'), ('focused', 'focused'), ('data', 'data'), ('analysis', 'analysis'), ('KDD', 'KDD'), ('platform/framework', 'platform/framework'), ('data', 'data'), ('mining', 'mining'), ('.', '.')]


------------------- Sentence 6 -------------------

The open issues on computation, quality of end result, security, and privacy  are then discussed to explain which open issues we may face.

>> Tokens are: 
 ['The', 'open', 'issues', 'computation', ',', 'quality', 'end', 'result', ',', 'security', ',', 'privacy', 'discussed', 'explain', 'open', 'issues', 'may', 'face', '.']

>> Bigrams are: 
 [('The', 'open'), ('open', 'issues'), ('issues', 'computation'), ('computation', ','), (',', 'quality'), ('quality', 'end'), ('end', 'result'), ('result', ','), (',', 'security'), ('security', ','), (',', 'privacy'), ('privacy', 'discussed'), ('discussed', 'explain'), ('explain', 'open'), ('open', 'issues'), ('issues', 'may'), ('may', 'face'), ('face', '.')]

>> Trigrams are: 
 [('The', 'open', 'issues'), ('open', 'issues', 'computation'), ('issues', 'computation', ','), ('computation', ',', 'quality'), (',', 'quality', 'end'), ('quality', 'end', 'result'), ('end', 'result', ','), ('result', ',', 'security'), (',', 'security', ','), ('security', ',', 'privacy'), (',', 'privacy', 'discussed'), ('privacy', 'discussed', 'explain'), ('discussed', 'explain', 'open'), ('explain', 'open', 'issues'), ('open', 'issues', 'may'), ('issues', 'may', 'face'), ('may', 'face', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('open', 'JJ'), ('issues', 'NNS'), ('computation', 'NN'), (',', ','), ('quality', 'JJ'), ('end', 'NN'), ('result', 'NN'), (',', ','), ('security', 'NN'), (',', ','), ('privacy', 'NN'), ('discussed', 'VBD'), ('explain', 'JJ'), ('open', 'JJ'), ('issues', 'NNS'), ('may', 'MD'), ('face', 'VB'), ('.', '.')]

>> Noun Phrases are: 
 ['The open issues computation', 'quality end result', 'security', 'privacy', 'explain open issues']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('open', 'open'), ('issues', 'issu'), ('computation', 'comput'), (',', ','), ('quality', 'qualiti'), ('end', 'end'), ('result', 'result'), (',', ','), ('security', 'secur'), (',', ','), ('privacy', 'privaci'), ('discussed', 'discuss'), ('explain', 'explain'), ('open', 'open'), ('issues', 'issu'), ('may', 'may'), ('face', 'face'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('open', 'open'), ('issues', 'issu'), ('computation', 'comput'), (',', ','), ('quality', 'qualiti'), ('end', 'end'), ('result', 'result'), (',', ','), ('security', 'secur'), (',', ','), ('privacy', 'privaci'), ('discussed', 'discuss'), ('explain', 'explain'), ('open', 'open'), ('issues', 'issu'), ('may', 'may'), ('face', 'face'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('open', 'open'), ('issues', 'issue'), ('computation', 'computation'), (',', ','), ('quality', 'quality'), ('end', 'end'), ('result', 'result'), (',', ','), ('security', 'security'), (',', ','), ('privacy', 'privacy'), ('discussed', 'discussed'), ('explain', 'explain'), ('open', 'open'), ('issues', 'issue'), ('may', 'may'), ('face', 'face'), ('.', '.')]


------------------- Sentence 7 -------------------

Last but not least, to help  the audience of the paper find solutions to welcome the new age of big data, the possible  high impact research trends are given below:

>> Tokens are: 
 ['Last', 'least', ',', 'help', 'audience', 'paper', 'find', 'solutions', 'welcome', 'new', 'age', 'big', 'data', ',', 'possible', 'high', 'impact', 'research', 'trends', 'given', ':']

>> Bigrams are: 
 [('Last', 'least'), ('least', ','), (',', 'help'), ('help', 'audience'), ('audience', 'paper'), ('paper', 'find'), ('find', 'solutions'), ('solutions', 'welcome'), ('welcome', 'new'), ('new', 'age'), ('age', 'big'), ('big', 'data'), ('data', ','), (',', 'possible'), ('possible', 'high'), ('high', 'impact'), ('impact', 'research'), ('research', 'trends'), ('trends', 'given'), ('given', ':')]

>> Trigrams are: 
 [('Last', 'least', ','), ('least', ',', 'help'), (',', 'help', 'audience'), ('help', 'audience', 'paper'), ('audience', 'paper', 'find'), ('paper', 'find', 'solutions'), ('find', 'solutions', 'welcome'), ('solutions', 'welcome', 'new'), ('welcome', 'new', 'age'), ('new', 'age', 'big'), ('age', 'big', 'data'), ('big', 'data', ','), ('data', ',', 'possible'), (',', 'possible', 'high'), ('possible', 'high', 'impact'), ('high', 'impact', 'research'), ('impact', 'research', 'trends'), ('research', 'trends', 'given'), ('trends', 'given', ':')]

>> POS Tags are: 
 [('Last', 'JJ'), ('least', 'JJS'), (',', ','), ('help', 'NN'), ('audience', 'NN'), ('paper', 'NN'), ('find', 'VBP'), ('solutions', 'NNS'), ('welcome', 'VBP'), ('new', 'JJ'), ('age', 'NN'), ('big', 'JJ'), ('data', 'NNS'), (',', ','), ('possible', 'JJ'), ('high', 'JJ'), ('impact', 'NN'), ('research', 'NN'), ('trends', 'VBZ'), ('given', 'VBN'), (':', ':')]

>> Noun Phrases are: 
 ['help audience paper', 'solutions', 'new age', 'big data', 'possible high impact research']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Last', 'last'), ('least', 'least'), (',', ','), ('help', 'help'), ('audience', 'audienc'), ('paper', 'paper'), ('find', 'find'), ('solutions', 'solut'), ('welcome', 'welcom'), ('new', 'new'), ('age', 'age'), ('big', 'big'), ('data', 'data'), (',', ','), ('possible', 'possibl'), ('high', 'high'), ('impact', 'impact'), ('research', 'research'), ('trends', 'trend'), ('given', 'given'), (':', ':')]

>> Stemming using Snowball Stemmer: 
 [('Last', 'last'), ('least', 'least'), (',', ','), ('help', 'help'), ('audience', 'audienc'), ('paper', 'paper'), ('find', 'find'), ('solutions', 'solut'), ('welcome', 'welcom'), ('new', 'new'), ('age', 'age'), ('big', 'big'), ('data', 'data'), (',', ','), ('possible', 'possibl'), ('high', 'high'), ('impact', 'impact'), ('research', 'research'), ('trends', 'trend'), ('given', 'given'), (':', ':')]

>> Lemmatization: 
 [('Last', 'Last'), ('least', 'least'), (',', ','), ('help', 'help'), ('audience', 'audience'), ('paper', 'paper'), ('find', 'find'), ('solutions', 'solution'), ('welcome', 'welcome'), ('new', 'new'), ('age', 'age'), ('big', 'big'), ('data', 'data'), (',', ','), ('possible', 'possible'), ('high', 'high'), ('impact', 'impact'), ('research', 'research'), ('trends', 'trend'), ('given', 'given'), (':', ':')]



========================================== PARAGRAPH 385 ===========================================

  – For the computation time, there is no doubt at all that parallel computing is one of the  important future trends to make the data analytics work for big data, and consequently  the technologies of cloud computing, Hadoop, and map-reduce will play the impor- tant roles for the big data analytics. To handle the computation resources of the cloud- based platform and to finish the task of data analysis as fast as possible, the scheduling  method is another future trend. 

------------------- Sentence 1 -------------------

  – For the computation time, there is no doubt at all that parallel computing is one of the  important future trends to make the data analytics work for big data, and consequently  the technologies of cloud computing, Hadoop, and map-reduce will play the impor- tant roles for the big data analytics.

>> Tokens are: 
 ['–', 'For', 'computation', 'time', ',', 'doubt', 'parallel', 'computing', 'one', 'important', 'future', 'trends', 'make', 'data', 'analytics', 'work', 'big', 'data', ',', 'consequently', 'technologies', 'cloud', 'computing', ',', 'Hadoop', ',', 'map-reduce', 'play', 'impor-', 'tant', 'roles', 'big', 'data', 'analytics', '.']

>> Bigrams are: 
 [('–', 'For'), ('For', 'computation'), ('computation', 'time'), ('time', ','), (',', 'doubt'), ('doubt', 'parallel'), ('parallel', 'computing'), ('computing', 'one'), ('one', 'important'), ('important', 'future'), ('future', 'trends'), ('trends', 'make'), ('make', 'data'), ('data', 'analytics'), ('analytics', 'work'), ('work', 'big'), ('big', 'data'), ('data', ','), (',', 'consequently'), ('consequently', 'technologies'), ('technologies', 'cloud'), ('cloud', 'computing'), ('computing', ','), (',', 'Hadoop'), ('Hadoop', ','), (',', 'map-reduce'), ('map-reduce', 'play'), ('play', 'impor-'), ('impor-', 'tant'), ('tant', 'roles'), ('roles', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', '.')]

>> Trigrams are: 
 [('–', 'For', 'computation'), ('For', 'computation', 'time'), ('computation', 'time', ','), ('time', ',', 'doubt'), (',', 'doubt', 'parallel'), ('doubt', 'parallel', 'computing'), ('parallel', 'computing', 'one'), ('computing', 'one', 'important'), ('one', 'important', 'future'), ('important', 'future', 'trends'), ('future', 'trends', 'make'), ('trends', 'make', 'data'), ('make', 'data', 'analytics'), ('data', 'analytics', 'work'), ('analytics', 'work', 'big'), ('work', 'big', 'data'), ('big', 'data', ','), ('data', ',', 'consequently'), (',', 'consequently', 'technologies'), ('consequently', 'technologies', 'cloud'), ('technologies', 'cloud', 'computing'), ('cloud', 'computing', ','), ('computing', ',', 'Hadoop'), (',', 'Hadoop', ','), ('Hadoop', ',', 'map-reduce'), (',', 'map-reduce', 'play'), ('map-reduce', 'play', 'impor-'), ('play', 'impor-', 'tant'), ('impor-', 'tant', 'roles'), ('tant', 'roles', 'big'), ('roles', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', '.')]

>> POS Tags are: 
 [('–', 'NN'), ('For', 'IN'), ('computation', 'NN'), ('time', 'NN'), (',', ','), ('doubt', 'NN'), ('parallel', 'VBD'), ('computing', 'VBG'), ('one', 'CD'), ('important', 'JJ'), ('future', 'NN'), ('trends', 'NNS'), ('make', 'VBP'), ('data', 'NNS'), ('analytics', 'NNS'), ('work', 'VBP'), ('big', 'JJ'), ('data', 'NNS'), (',', ','), ('consequently', 'RB'), ('technologies', 'VBZ'), ('cloud', 'NN'), ('computing', 'NN'), (',', ','), ('Hadoop', 'NNP'), (',', ','), ('map-reduce', 'JJ'), ('play', 'NN'), ('impor-', 'JJ'), ('tant', 'NN'), ('roles', 'NNS'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['–', 'computation time', 'doubt', 'important future trends', 'data analytics', 'big data', 'cloud computing', 'Hadoop', 'map-reduce play', 'impor- tant roles', 'big data analytics']

>> Named Entities are: 
 [('GPE', 'Hadoop')] 

>> Stemming using Porter Stemmer: 
 [('–', '–'), ('For', 'for'), ('computation', 'comput'), ('time', 'time'), (',', ','), ('doubt', 'doubt'), ('parallel', 'parallel'), ('computing', 'comput'), ('one', 'one'), ('important', 'import'), ('future', 'futur'), ('trends', 'trend'), ('make', 'make'), ('data', 'data'), ('analytics', 'analyt'), ('work', 'work'), ('big', 'big'), ('data', 'data'), (',', ','), ('consequently', 'consequ'), ('technologies', 'technolog'), ('cloud', 'cloud'), ('computing', 'comput'), (',', ','), ('Hadoop', 'hadoop'), (',', ','), ('map-reduce', 'map-reduc'), ('play', 'play'), ('impor-', 'impor-'), ('tant', 'tant'), ('roles', 'role'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('–', '–'), ('For', 'for'), ('computation', 'comput'), ('time', 'time'), (',', ','), ('doubt', 'doubt'), ('parallel', 'parallel'), ('computing', 'comput'), ('one', 'one'), ('important', 'import'), ('future', 'futur'), ('trends', 'trend'), ('make', 'make'), ('data', 'data'), ('analytics', 'analyt'), ('work', 'work'), ('big', 'big'), ('data', 'data'), (',', ','), ('consequently', 'consequ'), ('technologies', 'technolog'), ('cloud', 'cloud'), ('computing', 'comput'), (',', ','), ('Hadoop', 'hadoop'), (',', ','), ('map-reduce', 'map-reduc'), ('play', 'play'), ('impor-', 'impor-'), ('tant', 'tant'), ('roles', 'role'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('.', '.')]

>> Lemmatization: 
 [('–', '–'), ('For', 'For'), ('computation', 'computation'), ('time', 'time'), (',', ','), ('doubt', 'doubt'), ('parallel', 'parallel'), ('computing', 'computing'), ('one', 'one'), ('important', 'important'), ('future', 'future'), ('trends', 'trend'), ('make', 'make'), ('data', 'data'), ('analytics', 'analytics'), ('work', 'work'), ('big', 'big'), ('data', 'data'), (',', ','), ('consequently', 'consequently'), ('technologies', 'technology'), ('cloud', 'cloud'), ('computing', 'computing'), (',', ','), ('Hadoop', 'Hadoop'), (',', ','), ('map-reduce', 'map-reduce'), ('play', 'play'), ('impor-', 'impor-'), ('tant', 'tant'), ('roles', 'role'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('.', '.')]


------------------- Sentence 2 -------------------

To handle the computation resources of the cloud- based platform and to finish the task of data analysis as fast as possible, the scheduling  method is another future trend.

>> Tokens are: 
 ['To', 'handle', 'computation', 'resources', 'cloud-', 'based', 'platform', 'finish', 'task', 'data', 'analysis', 'fast', 'possible', ',', 'scheduling', 'method', 'another', 'future', 'trend', '.']

>> Bigrams are: 
 [('To', 'handle'), ('handle', 'computation'), ('computation', 'resources'), ('resources', 'cloud-'), ('cloud-', 'based'), ('based', 'platform'), ('platform', 'finish'), ('finish', 'task'), ('task', 'data'), ('data', 'analysis'), ('analysis', 'fast'), ('fast', 'possible'), ('possible', ','), (',', 'scheduling'), ('scheduling', 'method'), ('method', 'another'), ('another', 'future'), ('future', 'trend'), ('trend', '.')]

>> Trigrams are: 
 [('To', 'handle', 'computation'), ('handle', 'computation', 'resources'), ('computation', 'resources', 'cloud-'), ('resources', 'cloud-', 'based'), ('cloud-', 'based', 'platform'), ('based', 'platform', 'finish'), ('platform', 'finish', 'task'), ('finish', 'task', 'data'), ('task', 'data', 'analysis'), ('data', 'analysis', 'fast'), ('analysis', 'fast', 'possible'), ('fast', 'possible', ','), ('possible', ',', 'scheduling'), (',', 'scheduling', 'method'), ('scheduling', 'method', 'another'), ('method', 'another', 'future'), ('another', 'future', 'trend'), ('future', 'trend', '.')]

>> POS Tags are: 
 [('To', 'TO'), ('handle', 'VB'), ('computation', 'NN'), ('resources', 'NNS'), ('cloud-', 'VBP'), ('based', 'VBN'), ('platform', 'NN'), ('finish', 'JJ'), ('task', 'NN'), ('data', 'NNS'), ('analysis', 'NN'), ('fast', 'NN'), ('possible', 'JJ'), (',', ','), ('scheduling', 'VBG'), ('method', 'NN'), ('another', 'DT'), ('future', 'JJ'), ('trend', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['computation resources', 'platform', 'finish task data analysis fast', 'method', 'another future trend']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('To', 'to'), ('handle', 'handl'), ('computation', 'comput'), ('resources', 'resourc'), ('cloud-', 'cloud-'), ('based', 'base'), ('platform', 'platform'), ('finish', 'finish'), ('task', 'task'), ('data', 'data'), ('analysis', 'analysi'), ('fast', 'fast'), ('possible', 'possibl'), (',', ','), ('scheduling', 'schedul'), ('method', 'method'), ('another', 'anoth'), ('future', 'futur'), ('trend', 'trend'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('To', 'to'), ('handle', 'handl'), ('computation', 'comput'), ('resources', 'resourc'), ('cloud-', 'cloud-'), ('based', 'base'), ('platform', 'platform'), ('finish', 'finish'), ('task', 'task'), ('data', 'data'), ('analysis', 'analysi'), ('fast', 'fast'), ('possible', 'possibl'), (',', ','), ('scheduling', 'schedul'), ('method', 'method'), ('another', 'anoth'), ('future', 'futur'), ('trend', 'trend'), ('.', '.')]

>> Lemmatization: 
 [('To', 'To'), ('handle', 'handle'), ('computation', 'computation'), ('resources', 'resource'), ('cloud-', 'cloud-'), ('based', 'based'), ('platform', 'platform'), ('finish', 'finish'), ('task', 'task'), ('data', 'data'), ('analysis', 'analysis'), ('fast', 'fast'), ('possible', 'possible'), (',', ','), ('scheduling', 'scheduling'), ('method', 'method'), ('another', 'another'), ('future', 'future'), ('trend', 'trend'), ('.', '.')]



========================================== PARAGRAPH 386 ===========================================

 – Using efficient methods to reduce the computation time of input, comparison, sam- pling, and a variety of reduction methods will play an important role in big data analyt-

------------------- Sentence 1 -------------------

 – Using efficient methods to reduce the computation time of input, comparison, sam- pling, and a variety of reduction methods will play an important role in big data analyt-

>> Tokens are: 
 ['–', 'Using', 'efficient', 'methods', 'reduce', 'computation', 'time', 'input', ',', 'comparison', ',', 'sam-', 'pling', ',', 'variety', 'reduction', 'methods', 'play', 'important', 'role', 'big', 'data', 'analyt-']

>> Bigrams are: 
 [('–', 'Using'), ('Using', 'efficient'), ('efficient', 'methods'), ('methods', 'reduce'), ('reduce', 'computation'), ('computation', 'time'), ('time', 'input'), ('input', ','), (',', 'comparison'), ('comparison', ','), (',', 'sam-'), ('sam-', 'pling'), ('pling', ','), (',', 'variety'), ('variety', 'reduction'), ('reduction', 'methods'), ('methods', 'play'), ('play', 'important'), ('important', 'role'), ('role', 'big'), ('big', 'data'), ('data', 'analyt-')]

>> Trigrams are: 
 [('–', 'Using', 'efficient'), ('Using', 'efficient', 'methods'), ('efficient', 'methods', 'reduce'), ('methods', 'reduce', 'computation'), ('reduce', 'computation', 'time'), ('computation', 'time', 'input'), ('time', 'input', ','), ('input', ',', 'comparison'), (',', 'comparison', ','), ('comparison', ',', 'sam-'), (',', 'sam-', 'pling'), ('sam-', 'pling', ','), ('pling', ',', 'variety'), (',', 'variety', 'reduction'), ('variety', 'reduction', 'methods'), ('reduction', 'methods', 'play'), ('methods', 'play', 'important'), ('play', 'important', 'role'), ('important', 'role', 'big'), ('role', 'big', 'data'), ('big', 'data', 'analyt-')]

>> POS Tags are: 
 [('–', 'NN'), ('Using', 'NNP'), ('efficient', 'JJ'), ('methods', 'NNS'), ('reduce', 'VB'), ('computation', 'NN'), ('time', 'NN'), ('input', 'NN'), (',', ','), ('comparison', 'NN'), (',', ','), ('sam-', 'JJ'), ('pling', 'NN'), (',', ','), ('variety', 'NN'), ('reduction', 'NN'), ('methods', 'NNS'), ('play', 'VBP'), ('important', 'JJ'), ('role', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('analyt-', 'NNS')]

>> Noun Phrases are: 
 ['– Using', 'efficient methods', 'computation time input', 'comparison', 'sam- pling', 'variety reduction methods', 'important role', 'big data analyt-']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('–', '–'), ('Using', 'use'), ('efficient', 'effici'), ('methods', 'method'), ('reduce', 'reduc'), ('computation', 'comput'), ('time', 'time'), ('input', 'input'), (',', ','), ('comparison', 'comparison'), (',', ','), ('sam-', 'sam-'), ('pling', 'pling'), (',', ','), ('variety', 'varieti'), ('reduction', 'reduct'), ('methods', 'method'), ('play', 'play'), ('important', 'import'), ('role', 'role'), ('big', 'big'), ('data', 'data'), ('analyt-', 'analyt-')]

>> Stemming using Snowball Stemmer: 
 [('–', '–'), ('Using', 'use'), ('efficient', 'effici'), ('methods', 'method'), ('reduce', 'reduc'), ('computation', 'comput'), ('time', 'time'), ('input', 'input'), (',', ','), ('comparison', 'comparison'), (',', ','), ('sam-', 'sam-'), ('pling', 'pling'), (',', ','), ('variety', 'varieti'), ('reduction', 'reduct'), ('methods', 'method'), ('play', 'play'), ('important', 'import'), ('role', 'role'), ('big', 'big'), ('data', 'data'), ('analyt-', 'analyt-')]

>> Lemmatization: 
 [('–', '–'), ('Using', 'Using'), ('efficient', 'efficient'), ('methods', 'method'), ('reduce', 'reduce'), ('computation', 'computation'), ('time', 'time'), ('input', 'input'), (',', ','), ('comparison', 'comparison'), (',', ','), ('sam-', 'sam-'), ('pling', 'pling'), (',', ','), ('variety', 'variety'), ('reduction', 'reduction'), ('methods', 'method'), ('play', 'play'), ('important', 'important'), ('role', 'role'), ('big', 'big'), ('data', 'data'), ('analyt-', 'analyt-')]



========================================== PARAGRAPH 387 ===========================================

Page 27 of 32Tsai et al. Journal of Big Data  (2015) 2:21  

------------------- Sentence 1 -------------------

Page 27 of 32Tsai et al.

>> Tokens are: 
 ['Page', '27', '32Tsai', 'et', 'al', '.']

>> Bigrams are: 
 [('Page', '27'), ('27', '32Tsai'), ('32Tsai', 'et'), ('et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('Page', '27', '32Tsai'), ('27', '32Tsai', 'et'), ('32Tsai', 'et', 'al'), ('et', 'al', '.')]

>> POS Tags are: 
 [('Page', 'NN'), ('27', 'CD'), ('32Tsai', 'CD'), ('et', 'NN'), ('al', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Page', 'et al']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Page', 'page'), ('27', '27'), ('32Tsai', '32tsai'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Page', 'page'), ('27', '27'), ('32Tsai', '32tsai'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('Page', 'Page'), ('27', '27'), ('32Tsai', '32Tsai'), ('et', 'et'), ('al', 'al'), ('.', '.')]


------------------- Sentence 2 -------------------

Journal of Big Data  (2015) 2:21

>> Tokens are: 
 ['Journal', 'Big', 'Data', '(', '2015', ')', '2:21']

>> Bigrams are: 
 [('Journal', 'Big'), ('Big', 'Data'), ('Data', '('), ('(', '2015'), ('2015', ')'), (')', '2:21')]

>> Trigrams are: 
 [('Journal', 'Big', 'Data'), ('Big', 'Data', '('), ('Data', '(', '2015'), ('(', '2015', ')'), ('2015', ')', '2:21')]

>> POS Tags are: 
 [('Journal', 'NNP'), ('Big', 'NNP'), ('Data', 'NNP'), ('(', '('), ('2015', 'CD'), (')', ')'), ('2:21', 'CD')]

>> Noun Phrases are: 
 ['Journal Big Data']

>> Named Entities are: 
 [('PERSON', 'Journal')] 

>> Stemming using Porter Stemmer: 
 [('Journal', 'journal'), ('Big', 'big'), ('Data', 'data'), ('(', '('), ('2015', '2015'), (')', ')'), ('2:21', '2:21')]

>> Stemming using Snowball Stemmer: 
 [('Journal', 'journal'), ('Big', 'big'), ('Data', 'data'), ('(', '('), ('2015', '2015'), (')', ')'), ('2:21', '2:21')]

>> Lemmatization: 
 [('Journal', 'Journal'), ('Big', 'Big'), ('Data', 'Data'), ('(', '('), ('2015', '2015'), (')', ')'), ('2:21', '2:21')]



========================================== PARAGRAPH 388 ===========================================

ics. Because these methods typically do not consider parallel computing environment,  how to make them work on parallel computing environment will be a future research  trend. Similar to the input, the data mining algorithms also face the same situation that  we mentioned in the previous section , how to make them work on parallel comput- ing environment will be a very important research trend because there are abundant  research results on traditional data mining algorithms. 

------------------- Sentence 1 -------------------

ics.

>> Tokens are: 
 ['ics', '.']

>> Bigrams are: 
 [('ics', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('ics', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['ics']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('ics', 'ic'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('ics', 'ic'), ('.', '.')]

>> Lemmatization: 
 [('ics', 'ic'), ('.', '.')]


------------------- Sentence 2 -------------------

Because these methods typically do not consider parallel computing environment,  how to make them work on parallel computing environment will be a future research  trend.

>> Tokens are: 
 ['Because', 'methods', 'typically', 'consider', 'parallel', 'computing', 'environment', ',', 'make', 'work', 'parallel', 'computing', 'environment', 'future', 'research', 'trend', '.']

>> Bigrams are: 
 [('Because', 'methods'), ('methods', 'typically'), ('typically', 'consider'), ('consider', 'parallel'), ('parallel', 'computing'), ('computing', 'environment'), ('environment', ','), (',', 'make'), ('make', 'work'), ('work', 'parallel'), ('parallel', 'computing'), ('computing', 'environment'), ('environment', 'future'), ('future', 'research'), ('research', 'trend'), ('trend', '.')]

>> Trigrams are: 
 [('Because', 'methods', 'typically'), ('methods', 'typically', 'consider'), ('typically', 'consider', 'parallel'), ('consider', 'parallel', 'computing'), ('parallel', 'computing', 'environment'), ('computing', 'environment', ','), ('environment', ',', 'make'), (',', 'make', 'work'), ('make', 'work', 'parallel'), ('work', 'parallel', 'computing'), ('parallel', 'computing', 'environment'), ('computing', 'environment', 'future'), ('environment', 'future', 'research'), ('future', 'research', 'trend'), ('research', 'trend', '.')]

>> POS Tags are: 
 [('Because', 'IN'), ('methods', 'NNS'), ('typically', 'RB'), ('consider', 'VBP'), ('parallel', 'JJ'), ('computing', 'NN'), ('environment', 'NN'), (',', ','), ('make', 'VBP'), ('work', 'NN'), ('parallel', 'RB'), ('computing', 'VBG'), ('environment', 'NN'), ('future', 'JJ'), ('research', 'NN'), ('trend', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['methods', 'parallel computing environment', 'work', 'environment', 'future research trend']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Because', 'becaus'), ('methods', 'method'), ('typically', 'typic'), ('consider', 'consid'), ('parallel', 'parallel'), ('computing', 'comput'), ('environment', 'environ'), (',', ','), ('make', 'make'), ('work', 'work'), ('parallel', 'parallel'), ('computing', 'comput'), ('environment', 'environ'), ('future', 'futur'), ('research', 'research'), ('trend', 'trend'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Because', 'becaus'), ('methods', 'method'), ('typically', 'typic'), ('consider', 'consid'), ('parallel', 'parallel'), ('computing', 'comput'), ('environment', 'environ'), (',', ','), ('make', 'make'), ('work', 'work'), ('parallel', 'parallel'), ('computing', 'comput'), ('environment', 'environ'), ('future', 'futur'), ('research', 'research'), ('trend', 'trend'), ('.', '.')]

>> Lemmatization: 
 [('Because', 'Because'), ('methods', 'method'), ('typically', 'typically'), ('consider', 'consider'), ('parallel', 'parallel'), ('computing', 'computing'), ('environment', 'environment'), (',', ','), ('make', 'make'), ('work', 'work'), ('parallel', 'parallel'), ('computing', 'computing'), ('environment', 'environment'), ('future', 'future'), ('research', 'research'), ('trend', 'trend'), ('.', '.')]


------------------- Sentence 3 -------------------

Similar to the input, the data mining algorithms also face the same situation that  we mentioned in the previous section , how to make them work on parallel comput- ing environment will be a very important research trend because there are abundant  research results on traditional data mining algorithms.

>> Tokens are: 
 ['Similar', 'input', ',', 'data', 'mining', 'algorithms', 'also', 'face', 'situation', 'mentioned', 'previous', 'section', ',', 'make', 'work', 'parallel', 'comput-', 'ing', 'environment', 'important', 'research', 'trend', 'abundant', 'research', 'results', 'traditional', 'data', 'mining', 'algorithms', '.']

>> Bigrams are: 
 [('Similar', 'input'), ('input', ','), (',', 'data'), ('data', 'mining'), ('mining', 'algorithms'), ('algorithms', 'also'), ('also', 'face'), ('face', 'situation'), ('situation', 'mentioned'), ('mentioned', 'previous'), ('previous', 'section'), ('section', ','), (',', 'make'), ('make', 'work'), ('work', 'parallel'), ('parallel', 'comput-'), ('comput-', 'ing'), ('ing', 'environment'), ('environment', 'important'), ('important', 'research'), ('research', 'trend'), ('trend', 'abundant'), ('abundant', 'research'), ('research', 'results'), ('results', 'traditional'), ('traditional', 'data'), ('data', 'mining'), ('mining', 'algorithms'), ('algorithms', '.')]

>> Trigrams are: 
 [('Similar', 'input', ','), ('input', ',', 'data'), (',', 'data', 'mining'), ('data', 'mining', 'algorithms'), ('mining', 'algorithms', 'also'), ('algorithms', 'also', 'face'), ('also', 'face', 'situation'), ('face', 'situation', 'mentioned'), ('situation', 'mentioned', 'previous'), ('mentioned', 'previous', 'section'), ('previous', 'section', ','), ('section', ',', 'make'), (',', 'make', 'work'), ('make', 'work', 'parallel'), ('work', 'parallel', 'comput-'), ('parallel', 'comput-', 'ing'), ('comput-', 'ing', 'environment'), ('ing', 'environment', 'important'), ('environment', 'important', 'research'), ('important', 'research', 'trend'), ('research', 'trend', 'abundant'), ('trend', 'abundant', 'research'), ('abundant', 'research', 'results'), ('research', 'results', 'traditional'), ('results', 'traditional', 'data'), ('traditional', 'data', 'mining'), ('data', 'mining', 'algorithms'), ('mining', 'algorithms', '.')]

>> POS Tags are: 
 [('Similar', 'JJ'), ('input', 'NN'), (',', ','), ('data', 'NNS'), ('mining', 'NN'), ('algorithms', 'NN'), ('also', 'RB'), ('face', 'VBP'), ('situation', 'NN'), ('mentioned', 'VBD'), ('previous', 'JJ'), ('section', 'NN'), (',', ','), ('make', 'VBP'), ('work', 'NN'), ('parallel', 'JJ'), ('comput-', 'JJ'), ('ing', 'NN'), ('environment', 'NN'), ('important', 'JJ'), ('research', 'NN'), ('trend', 'NN'), ('abundant', 'JJ'), ('research', 'NN'), ('results', 'NNS'), ('traditional', 'JJ'), ('data', 'NNS'), ('mining', 'NN'), ('algorithms', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Similar input', 'data mining algorithms', 'situation', 'previous section', 'work', 'parallel comput- ing environment', 'important research trend', 'abundant research results', 'traditional data mining algorithms']

>> Named Entities are: 
 [('GPE', 'Similar')] 

>> Stemming using Porter Stemmer: 
 [('Similar', 'similar'), ('input', 'input'), (',', ','), ('data', 'data'), ('mining', 'mine'), ('algorithms', 'algorithm'), ('also', 'also'), ('face', 'face'), ('situation', 'situat'), ('mentioned', 'mention'), ('previous', 'previou'), ('section', 'section'), (',', ','), ('make', 'make'), ('work', 'work'), ('parallel', 'parallel'), ('comput-', 'comput-'), ('ing', 'ing'), ('environment', 'environ'), ('important', 'import'), ('research', 'research'), ('trend', 'trend'), ('abundant', 'abund'), ('research', 'research'), ('results', 'result'), ('traditional', 'tradit'), ('data', 'data'), ('mining', 'mine'), ('algorithms', 'algorithm'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Similar', 'similar'), ('input', 'input'), (',', ','), ('data', 'data'), ('mining', 'mine'), ('algorithms', 'algorithm'), ('also', 'also'), ('face', 'face'), ('situation', 'situat'), ('mentioned', 'mention'), ('previous', 'previous'), ('section', 'section'), (',', ','), ('make', 'make'), ('work', 'work'), ('parallel', 'parallel'), ('comput-', 'comput-'), ('ing', 'ing'), ('environment', 'environ'), ('important', 'import'), ('research', 'research'), ('trend', 'trend'), ('abundant', 'abund'), ('research', 'research'), ('results', 'result'), ('traditional', 'tradit'), ('data', 'data'), ('mining', 'mine'), ('algorithms', 'algorithm'), ('.', '.')]

>> Lemmatization: 
 [('Similar', 'Similar'), ('input', 'input'), (',', ','), ('data', 'data'), ('mining', 'mining'), ('algorithms', 'algorithm'), ('also', 'also'), ('face', 'face'), ('situation', 'situation'), ('mentioned', 'mentioned'), ('previous', 'previous'), ('section', 'section'), (',', ','), ('make', 'make'), ('work', 'work'), ('parallel', 'parallel'), ('comput-', 'comput-'), ('ing', 'ing'), ('environment', 'environment'), ('important', 'important'), ('research', 'research'), ('trend', 'trend'), ('abundant', 'abundant'), ('research', 'research'), ('results', 'result'), ('traditional', 'traditional'), ('data', 'data'), ('mining', 'mining'), ('algorithms', 'algorithm'), ('.', '.')]



========================================== PARAGRAPH 389 ===========================================

 – How to model the mining problem to find something from big data and how to dis- play the knowledge we got from big data analytics will also be another two vital future  trends because the results of these two researches will decide if the data analytics can  practically work for real world approaches, not just a theoretical stuff. 

------------------- Sentence 1 -------------------

 – How to model the mining problem to find something from big data and how to dis- play the knowledge we got from big data analytics will also be another two vital future  trends because the results of these two researches will decide if the data analytics can  practically work for real world approaches, not just a theoretical stuff.

>> Tokens are: 
 ['–', 'How', 'model', 'mining', 'problem', 'find', 'something', 'big', 'data', 'dis-', 'play', 'knowledge', 'got', 'big', 'data', 'analytics', 'also', 'another', 'two', 'vital', 'future', 'trends', 'results', 'two', 'researches', 'decide', 'data', 'analytics', 'practically', 'work', 'real', 'world', 'approaches', ',', 'theoretical', 'stuff', '.']

>> Bigrams are: 
 [('–', 'How'), ('How', 'model'), ('model', 'mining'), ('mining', 'problem'), ('problem', 'find'), ('find', 'something'), ('something', 'big'), ('big', 'data'), ('data', 'dis-'), ('dis-', 'play'), ('play', 'knowledge'), ('knowledge', 'got'), ('got', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', 'also'), ('also', 'another'), ('another', 'two'), ('two', 'vital'), ('vital', 'future'), ('future', 'trends'), ('trends', 'results'), ('results', 'two'), ('two', 'researches'), ('researches', 'decide'), ('decide', 'data'), ('data', 'analytics'), ('analytics', 'practically'), ('practically', 'work'), ('work', 'real'), ('real', 'world'), ('world', 'approaches'), ('approaches', ','), (',', 'theoretical'), ('theoretical', 'stuff'), ('stuff', '.')]

>> Trigrams are: 
 [('–', 'How', 'model'), ('How', 'model', 'mining'), ('model', 'mining', 'problem'), ('mining', 'problem', 'find'), ('problem', 'find', 'something'), ('find', 'something', 'big'), ('something', 'big', 'data'), ('big', 'data', 'dis-'), ('data', 'dis-', 'play'), ('dis-', 'play', 'knowledge'), ('play', 'knowledge', 'got'), ('knowledge', 'got', 'big'), ('got', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', 'also'), ('analytics', 'also', 'another'), ('also', 'another', 'two'), ('another', 'two', 'vital'), ('two', 'vital', 'future'), ('vital', 'future', 'trends'), ('future', 'trends', 'results'), ('trends', 'results', 'two'), ('results', 'two', 'researches'), ('two', 'researches', 'decide'), ('researches', 'decide', 'data'), ('decide', 'data', 'analytics'), ('data', 'analytics', 'practically'), ('analytics', 'practically', 'work'), ('practically', 'work', 'real'), ('work', 'real', 'world'), ('real', 'world', 'approaches'), ('world', 'approaches', ','), ('approaches', ',', 'theoretical'), (',', 'theoretical', 'stuff'), ('theoretical', 'stuff', '.')]

>> POS Tags are: 
 [('–', 'VB'), ('How', 'WRB'), ('model', 'NN'), ('mining', 'NN'), ('problem', 'NN'), ('find', 'VBP'), ('something', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('dis-', 'JJ'), ('play', 'NN'), ('knowledge', 'NN'), ('got', 'VBD'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('also', 'RB'), ('another', 'DT'), ('two', 'CD'), ('vital', 'JJ'), ('future', 'JJ'), ('trends', 'NNS'), ('results', 'NNS'), ('two', 'CD'), ('researches', 'NNS'), ('decide', 'VBP'), ('data', 'NNS'), ('analytics', 'NNS'), ('practically', 'RB'), ('work', 'VBP'), ('real', 'JJ'), ('world', 'NN'), ('approaches', 'NNS'), (',', ','), ('theoretical', 'JJ'), ('stuff', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['model mining problem', 'something', 'big data', 'dis- play knowledge', 'big data analytics', 'vital future trends results', 'researches', 'data analytics', 'real world approaches', 'theoretical stuff']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('–', '–'), ('How', 'how'), ('model', 'model'), ('mining', 'mine'), ('problem', 'problem'), ('find', 'find'), ('something', 'someth'), ('big', 'big'), ('data', 'data'), ('dis-', 'dis-'), ('play', 'play'), ('knowledge', 'knowledg'), ('got', 'got'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('also', 'also'), ('another', 'anoth'), ('two', 'two'), ('vital', 'vital'), ('future', 'futur'), ('trends', 'trend'), ('results', 'result'), ('two', 'two'), ('researches', 'research'), ('decide', 'decid'), ('data', 'data'), ('analytics', 'analyt'), ('practically', 'practic'), ('work', 'work'), ('real', 'real'), ('world', 'world'), ('approaches', 'approach'), (',', ','), ('theoretical', 'theoret'), ('stuff', 'stuff'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('–', '–'), ('How', 'how'), ('model', 'model'), ('mining', 'mine'), ('problem', 'problem'), ('find', 'find'), ('something', 'someth'), ('big', 'big'), ('data', 'data'), ('dis-', 'dis-'), ('play', 'play'), ('knowledge', 'knowledg'), ('got', 'got'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('also', 'also'), ('another', 'anoth'), ('two', 'two'), ('vital', 'vital'), ('future', 'futur'), ('trends', 'trend'), ('results', 'result'), ('two', 'two'), ('researches', 'research'), ('decide', 'decid'), ('data', 'data'), ('analytics', 'analyt'), ('practically', 'practic'), ('work', 'work'), ('real', 'real'), ('world', 'world'), ('approaches', 'approach'), (',', ','), ('theoretical', 'theoret'), ('stuff', 'stuff'), ('.', '.')]

>> Lemmatization: 
 [('–', '–'), ('How', 'How'), ('model', 'model'), ('mining', 'mining'), ('problem', 'problem'), ('find', 'find'), ('something', 'something'), ('big', 'big'), ('data', 'data'), ('dis-', 'dis-'), ('play', 'play'), ('knowledge', 'knowledge'), ('got', 'got'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('also', 'also'), ('another', 'another'), ('two', 'two'), ('vital', 'vital'), ('future', 'future'), ('trends', 'trend'), ('results', 'result'), ('two', 'two'), ('researches', 'research'), ('decide', 'decide'), ('data', 'data'), ('analytics', 'analytics'), ('practically', 'practically'), ('work', 'work'), ('real', 'real'), ('world', 'world'), ('approaches', 'approach'), (',', ','), ('theoretical', 'theoretical'), ('stuff', 'stuff'), ('.', '.')]



========================================== PARAGRAPH 390 ===========================================

 – The methods of extracting information from external and relative knowledge resources  to further reinforce the big data analytics, until now, are not very popular in big data  analytics. But combining information from different resources to add the value of out- put knowledge is a common solution in the area of information retrieval, such as clus- tering search engine or document summarization. For this reason, information fusion  will also be a future trend for improving the end results of big data analytics. 

------------------- Sentence 1 -------------------

 – The methods of extracting information from external and relative knowledge resources  to further reinforce the big data analytics, until now, are not very popular in big data  analytics.

>> Tokens are: 
 ['–', 'The', 'methods', 'extracting', 'information', 'external', 'relative', 'knowledge', 'resources', 'reinforce', 'big', 'data', 'analytics', ',', ',', 'popular', 'big', 'data', 'analytics', '.']

>> Bigrams are: 
 [('–', 'The'), ('The', 'methods'), ('methods', 'extracting'), ('extracting', 'information'), ('information', 'external'), ('external', 'relative'), ('relative', 'knowledge'), ('knowledge', 'resources'), ('resources', 'reinforce'), ('reinforce', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', ','), (',', ','), (',', 'popular'), ('popular', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', '.')]

>> Trigrams are: 
 [('–', 'The', 'methods'), ('The', 'methods', 'extracting'), ('methods', 'extracting', 'information'), ('extracting', 'information', 'external'), ('information', 'external', 'relative'), ('external', 'relative', 'knowledge'), ('relative', 'knowledge', 'resources'), ('knowledge', 'resources', 'reinforce'), ('resources', 'reinforce', 'big'), ('reinforce', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', ','), ('analytics', ',', ','), (',', ',', 'popular'), (',', 'popular', 'big'), ('popular', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', '.')]

>> POS Tags are: 
 [('–', 'IN'), ('The', 'DT'), ('methods', 'NNS'), ('extracting', 'VBG'), ('information', 'NN'), ('external', 'JJ'), ('relative', 'NN'), ('knowledge', 'NN'), ('resources', 'NNS'), ('reinforce', 'VBP'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), (',', ','), (',', ','), ('popular', 'JJ'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['The methods', 'information', 'external relative knowledge resources', 'big data analytics', 'popular big data analytics']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('–', '–'), ('The', 'the'), ('methods', 'method'), ('extracting', 'extract'), ('information', 'inform'), ('external', 'extern'), ('relative', 'rel'), ('knowledge', 'knowledg'), ('resources', 'resourc'), ('reinforce', 'reinforc'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), (',', ','), (',', ','), ('popular', 'popular'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('–', '–'), ('The', 'the'), ('methods', 'method'), ('extracting', 'extract'), ('information', 'inform'), ('external', 'extern'), ('relative', 'relat'), ('knowledge', 'knowledg'), ('resources', 'resourc'), ('reinforce', 'reinforc'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), (',', ','), (',', ','), ('popular', 'popular'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('.', '.')]

>> Lemmatization: 
 [('–', '–'), ('The', 'The'), ('methods', 'method'), ('extracting', 'extracting'), ('information', 'information'), ('external', 'external'), ('relative', 'relative'), ('knowledge', 'knowledge'), ('resources', 'resource'), ('reinforce', 'reinforce'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), (',', ','), (',', ','), ('popular', 'popular'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('.', '.')]


------------------- Sentence 2 -------------------

But combining information from different resources to add the value of out- put knowledge is a common solution in the area of information retrieval, such as clus- tering search engine or document summarization.

>> Tokens are: 
 ['But', 'combining', 'information', 'different', 'resources', 'add', 'value', 'out-', 'put', 'knowledge', 'common', 'solution', 'area', 'information', 'retrieval', ',', 'clus-', 'tering', 'search', 'engine', 'document', 'summarization', '.']

>> Bigrams are: 
 [('But', 'combining'), ('combining', 'information'), ('information', 'different'), ('different', 'resources'), ('resources', 'add'), ('add', 'value'), ('value', 'out-'), ('out-', 'put'), ('put', 'knowledge'), ('knowledge', 'common'), ('common', 'solution'), ('solution', 'area'), ('area', 'information'), ('information', 'retrieval'), ('retrieval', ','), (',', 'clus-'), ('clus-', 'tering'), ('tering', 'search'), ('search', 'engine'), ('engine', 'document'), ('document', 'summarization'), ('summarization', '.')]

>> Trigrams are: 
 [('But', 'combining', 'information'), ('combining', 'information', 'different'), ('information', 'different', 'resources'), ('different', 'resources', 'add'), ('resources', 'add', 'value'), ('add', 'value', 'out-'), ('value', 'out-', 'put'), ('out-', 'put', 'knowledge'), ('put', 'knowledge', 'common'), ('knowledge', 'common', 'solution'), ('common', 'solution', 'area'), ('solution', 'area', 'information'), ('area', 'information', 'retrieval'), ('information', 'retrieval', ','), ('retrieval', ',', 'clus-'), (',', 'clus-', 'tering'), ('clus-', 'tering', 'search'), ('tering', 'search', 'engine'), ('search', 'engine', 'document'), ('engine', 'document', 'summarization'), ('document', 'summarization', '.')]

>> POS Tags are: 
 [('But', 'CC'), ('combining', 'VBG'), ('information', 'NN'), ('different', 'JJ'), ('resources', 'NNS'), ('add', 'VBP'), ('value', 'NN'), ('out-', 'JJ'), ('put', 'NN'), ('knowledge', 'NN'), ('common', 'JJ'), ('solution', 'NN'), ('area', 'NN'), ('information', 'NN'), ('retrieval', 'NN'), (',', ','), ('clus-', 'JJ'), ('tering', 'VBG'), ('search', 'NN'), ('engine', 'NN'), ('document', 'NN'), ('summarization', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['information', 'different resources', 'value', 'out- put knowledge', 'common solution area information retrieval', 'search engine document summarization']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('But', 'but'), ('combining', 'combin'), ('information', 'inform'), ('different', 'differ'), ('resources', 'resourc'), ('add', 'add'), ('value', 'valu'), ('out-', 'out-'), ('put', 'put'), ('knowledge', 'knowledg'), ('common', 'common'), ('solution', 'solut'), ('area', 'area'), ('information', 'inform'), ('retrieval', 'retriev'), (',', ','), ('clus-', 'clus-'), ('tering', 'tere'), ('search', 'search'), ('engine', 'engin'), ('document', 'document'), ('summarization', 'summar'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('But', 'but'), ('combining', 'combin'), ('information', 'inform'), ('different', 'differ'), ('resources', 'resourc'), ('add', 'add'), ('value', 'valu'), ('out-', 'out-'), ('put', 'put'), ('knowledge', 'knowledg'), ('common', 'common'), ('solution', 'solut'), ('area', 'area'), ('information', 'inform'), ('retrieval', 'retriev'), (',', ','), ('clus-', 'clus-'), ('tering', 'tere'), ('search', 'search'), ('engine', 'engin'), ('document', 'document'), ('summarization', 'summar'), ('.', '.')]

>> Lemmatization: 
 [('But', 'But'), ('combining', 'combining'), ('information', 'information'), ('different', 'different'), ('resources', 'resource'), ('add', 'add'), ('value', 'value'), ('out-', 'out-'), ('put', 'put'), ('knowledge', 'knowledge'), ('common', 'common'), ('solution', 'solution'), ('area', 'area'), ('information', 'information'), ('retrieval', 'retrieval'), (',', ','), ('clus-', 'clus-'), ('tering', 'tering'), ('search', 'search'), ('engine', 'engine'), ('document', 'document'), ('summarization', 'summarization'), ('.', '.')]


------------------- Sentence 3 -------------------

For this reason, information fusion  will also be a future trend for improving the end results of big data analytics.

>> Tokens are: 
 ['For', 'reason', ',', 'information', 'fusion', 'also', 'future', 'trend', 'improving', 'end', 'results', 'big', 'data', 'analytics', '.']

>> Bigrams are: 
 [('For', 'reason'), ('reason', ','), (',', 'information'), ('information', 'fusion'), ('fusion', 'also'), ('also', 'future'), ('future', 'trend'), ('trend', 'improving'), ('improving', 'end'), ('end', 'results'), ('results', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', '.')]

>> Trigrams are: 
 [('For', 'reason', ','), ('reason', ',', 'information'), (',', 'information', 'fusion'), ('information', 'fusion', 'also'), ('fusion', 'also', 'future'), ('also', 'future', 'trend'), ('future', 'trend', 'improving'), ('trend', 'improving', 'end'), ('improving', 'end', 'results'), ('end', 'results', 'big'), ('results', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', '.')]

>> POS Tags are: 
 [('For', 'IN'), ('reason', 'NN'), (',', ','), ('information', 'NN'), ('fusion', 'NN'), ('also', 'RB'), ('future', 'JJ'), ('trend', 'NN'), ('improving', 'VBG'), ('end', 'NN'), ('results', 'NNS'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['reason', 'information fusion', 'future trend', 'end results', 'big data analytics']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('For', 'for'), ('reason', 'reason'), (',', ','), ('information', 'inform'), ('fusion', 'fusion'), ('also', 'also'), ('future', 'futur'), ('trend', 'trend'), ('improving', 'improv'), ('end', 'end'), ('results', 'result'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('For', 'for'), ('reason', 'reason'), (',', ','), ('information', 'inform'), ('fusion', 'fusion'), ('also', 'also'), ('future', 'futur'), ('trend', 'trend'), ('improving', 'improv'), ('end', 'end'), ('results', 'result'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('.', '.')]

>> Lemmatization: 
 [('For', 'For'), ('reason', 'reason'), (',', ','), ('information', 'information'), ('fusion', 'fusion'), ('also', 'also'), ('future', 'future'), ('trend', 'trend'), ('improving', 'improving'), ('end', 'end'), ('results', 'result'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('.', '.')]



========================================== PARAGRAPH 391 ===========================================

 – Because the metaheuristic algorithms are capable of finding an approximate solution  within a reasonable time, they have been widely used in solving the data mining prob- lem in recent years. Until now, many state-of-the-art metaheuristic algorithms still have  not been applied to big data analytics. In addition, compared to some early data mining  algorithms, the performance of metaheuristic is no doubt superior in terms of the com- putation time and the quality of end result. From these observations, the application of  metaheuristic algorithms to big data analytics will also be an important research topic. 

------------------- Sentence 1 -------------------

 – Because the metaheuristic algorithms are capable of finding an approximate solution  within a reasonable time, they have been widely used in solving the data mining prob- lem in recent years.

>> Tokens are: 
 ['–', 'Because', 'metaheuristic', 'algorithms', 'capable', 'finding', 'approximate', 'solution', 'within', 'reasonable', 'time', ',', 'widely', 'used', 'solving', 'data', 'mining', 'prob-', 'lem', 'recent', 'years', '.']

>> Bigrams are: 
 [('–', 'Because'), ('Because', 'metaheuristic'), ('metaheuristic', 'algorithms'), ('algorithms', 'capable'), ('capable', 'finding'), ('finding', 'approximate'), ('approximate', 'solution'), ('solution', 'within'), ('within', 'reasonable'), ('reasonable', 'time'), ('time', ','), (',', 'widely'), ('widely', 'used'), ('used', 'solving'), ('solving', 'data'), ('data', 'mining'), ('mining', 'prob-'), ('prob-', 'lem'), ('lem', 'recent'), ('recent', 'years'), ('years', '.')]

>> Trigrams are: 
 [('–', 'Because', 'metaheuristic'), ('Because', 'metaheuristic', 'algorithms'), ('metaheuristic', 'algorithms', 'capable'), ('algorithms', 'capable', 'finding'), ('capable', 'finding', 'approximate'), ('finding', 'approximate', 'solution'), ('approximate', 'solution', 'within'), ('solution', 'within', 'reasonable'), ('within', 'reasonable', 'time'), ('reasonable', 'time', ','), ('time', ',', 'widely'), (',', 'widely', 'used'), ('widely', 'used', 'solving'), ('used', 'solving', 'data'), ('solving', 'data', 'mining'), ('data', 'mining', 'prob-'), ('mining', 'prob-', 'lem'), ('prob-', 'lem', 'recent'), ('lem', 'recent', 'years'), ('recent', 'years', '.')]

>> POS Tags are: 
 [('–', 'NN'), ('Because', 'IN'), ('metaheuristic', 'JJ'), ('algorithms', 'NN'), ('capable', 'JJ'), ('finding', 'VBG'), ('approximate', 'JJ'), ('solution', 'NN'), ('within', 'IN'), ('reasonable', 'JJ'), ('time', 'NN'), (',', ','), ('widely', 'RB'), ('used', 'VBN'), ('solving', 'VBG'), ('data', 'NNS'), ('mining', 'VBG'), ('prob-', 'NN'), ('lem', 'JJ'), ('recent', 'JJ'), ('years', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['–', 'metaheuristic algorithms', 'approximate solution', 'reasonable time', 'data', 'prob-', 'lem recent years']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('–', '–'), ('Because', 'becaus'), ('metaheuristic', 'metaheurist'), ('algorithms', 'algorithm'), ('capable', 'capabl'), ('finding', 'find'), ('approximate', 'approxim'), ('solution', 'solut'), ('within', 'within'), ('reasonable', 'reason'), ('time', 'time'), (',', ','), ('widely', 'wide'), ('used', 'use'), ('solving', 'solv'), ('data', 'data'), ('mining', 'mine'), ('prob-', 'prob-'), ('lem', 'lem'), ('recent', 'recent'), ('years', 'year'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('–', '–'), ('Because', 'becaus'), ('metaheuristic', 'metaheurist'), ('algorithms', 'algorithm'), ('capable', 'capabl'), ('finding', 'find'), ('approximate', 'approxim'), ('solution', 'solut'), ('within', 'within'), ('reasonable', 'reason'), ('time', 'time'), (',', ','), ('widely', 'wide'), ('used', 'use'), ('solving', 'solv'), ('data', 'data'), ('mining', 'mine'), ('prob-', 'prob-'), ('lem', 'lem'), ('recent', 'recent'), ('years', 'year'), ('.', '.')]

>> Lemmatization: 
 [('–', '–'), ('Because', 'Because'), ('metaheuristic', 'metaheuristic'), ('algorithms', 'algorithm'), ('capable', 'capable'), ('finding', 'finding'), ('approximate', 'approximate'), ('solution', 'solution'), ('within', 'within'), ('reasonable', 'reasonable'), ('time', 'time'), (',', ','), ('widely', 'widely'), ('used', 'used'), ('solving', 'solving'), ('data', 'data'), ('mining', 'mining'), ('prob-', 'prob-'), ('lem', 'lem'), ('recent', 'recent'), ('years', 'year'), ('.', '.')]


------------------- Sentence 2 -------------------

Until now, many state-of-the-art metaheuristic algorithms still have  not been applied to big data analytics.

>> Tokens are: 
 ['Until', ',', 'many', 'state-of-the-art', 'metaheuristic', 'algorithms', 'still', 'applied', 'big', 'data', 'analytics', '.']

>> Bigrams are: 
 [('Until', ','), (',', 'many'), ('many', 'state-of-the-art'), ('state-of-the-art', 'metaheuristic'), ('metaheuristic', 'algorithms'), ('algorithms', 'still'), ('still', 'applied'), ('applied', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', '.')]

>> Trigrams are: 
 [('Until', ',', 'many'), (',', 'many', 'state-of-the-art'), ('many', 'state-of-the-art', 'metaheuristic'), ('state-of-the-art', 'metaheuristic', 'algorithms'), ('metaheuristic', 'algorithms', 'still'), ('algorithms', 'still', 'applied'), ('still', 'applied', 'big'), ('applied', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', '.')]

>> POS Tags are: 
 [('Until', 'IN'), (',', ','), ('many', 'JJ'), ('state-of-the-art', 'JJ'), ('metaheuristic', 'JJ'), ('algorithms', 'NN'), ('still', 'RB'), ('applied', 'VBN'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['many state-of-the-art metaheuristic algorithms', 'big data analytics']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Until', 'until'), (',', ','), ('many', 'mani'), ('state-of-the-art', 'state-of-the-art'), ('metaheuristic', 'metaheurist'), ('algorithms', 'algorithm'), ('still', 'still'), ('applied', 'appli'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Until', 'until'), (',', ','), ('many', 'mani'), ('state-of-the-art', 'state-of-the-art'), ('metaheuristic', 'metaheurist'), ('algorithms', 'algorithm'), ('still', 'still'), ('applied', 'appli'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('.', '.')]

>> Lemmatization: 
 [('Until', 'Until'), (',', ','), ('many', 'many'), ('state-of-the-art', 'state-of-the-art'), ('metaheuristic', 'metaheuristic'), ('algorithms', 'algorithm'), ('still', 'still'), ('applied', 'applied'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('.', '.')]


------------------- Sentence 3 -------------------

In addition, compared to some early data mining  algorithms, the performance of metaheuristic is no doubt superior in terms of the com- putation time and the quality of end result.

>> Tokens are: 
 ['In', 'addition', ',', 'compared', 'early', 'data', 'mining', 'algorithms', ',', 'performance', 'metaheuristic', 'doubt', 'superior', 'terms', 'com-', 'putation', 'time', 'quality', 'end', 'result', '.']

>> Bigrams are: 
 [('In', 'addition'), ('addition', ','), (',', 'compared'), ('compared', 'early'), ('early', 'data'), ('data', 'mining'), ('mining', 'algorithms'), ('algorithms', ','), (',', 'performance'), ('performance', 'metaheuristic'), ('metaheuristic', 'doubt'), ('doubt', 'superior'), ('superior', 'terms'), ('terms', 'com-'), ('com-', 'putation'), ('putation', 'time'), ('time', 'quality'), ('quality', 'end'), ('end', 'result'), ('result', '.')]

>> Trigrams are: 
 [('In', 'addition', ','), ('addition', ',', 'compared'), (',', 'compared', 'early'), ('compared', 'early', 'data'), ('early', 'data', 'mining'), ('data', 'mining', 'algorithms'), ('mining', 'algorithms', ','), ('algorithms', ',', 'performance'), (',', 'performance', 'metaheuristic'), ('performance', 'metaheuristic', 'doubt'), ('metaheuristic', 'doubt', 'superior'), ('doubt', 'superior', 'terms'), ('superior', 'terms', 'com-'), ('terms', 'com-', 'putation'), ('com-', 'putation', 'time'), ('putation', 'time', 'quality'), ('time', 'quality', 'end'), ('quality', 'end', 'result'), ('end', 'result', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('addition', 'NN'), (',', ','), ('compared', 'VBN'), ('early', 'JJ'), ('data', 'NNS'), ('mining', 'NN'), ('algorithms', 'NN'), (',', ','), ('performance', 'NN'), ('metaheuristic', 'JJ'), ('doubt', 'NN'), ('superior', 'JJ'), ('terms', 'NNS'), ('com-', 'JJ'), ('putation', 'NN'), ('time', 'NN'), ('quality', 'JJ'), ('end', 'NN'), ('result', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['addition', 'early data mining algorithms', 'performance', 'metaheuristic doubt', 'superior terms', 'com- putation time', 'quality end result']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('addition', 'addit'), (',', ','), ('compared', 'compar'), ('early', 'earli'), ('data', 'data'), ('mining', 'mine'), ('algorithms', 'algorithm'), (',', ','), ('performance', 'perform'), ('metaheuristic', 'metaheurist'), ('doubt', 'doubt'), ('superior', 'superior'), ('terms', 'term'), ('com-', 'com-'), ('putation', 'putat'), ('time', 'time'), ('quality', 'qualiti'), ('end', 'end'), ('result', 'result'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('addition', 'addit'), (',', ','), ('compared', 'compar'), ('early', 'earli'), ('data', 'data'), ('mining', 'mine'), ('algorithms', 'algorithm'), (',', ','), ('performance', 'perform'), ('metaheuristic', 'metaheurist'), ('doubt', 'doubt'), ('superior', 'superior'), ('terms', 'term'), ('com-', 'com-'), ('putation', 'putat'), ('time', 'time'), ('quality', 'qualiti'), ('end', 'end'), ('result', 'result'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('addition', 'addition'), (',', ','), ('compared', 'compared'), ('early', 'early'), ('data', 'data'), ('mining', 'mining'), ('algorithms', 'algorithm'), (',', ','), ('performance', 'performance'), ('metaheuristic', 'metaheuristic'), ('doubt', 'doubt'), ('superior', 'superior'), ('terms', 'term'), ('com-', 'com-'), ('putation', 'putation'), ('time', 'time'), ('quality', 'quality'), ('end', 'end'), ('result', 'result'), ('.', '.')]


------------------- Sentence 4 -------------------

From these observations, the application of  metaheuristic algorithms to big data analytics will also be an important research topic.

>> Tokens are: 
 ['From', 'observations', ',', 'application', 'metaheuristic', 'algorithms', 'big', 'data', 'analytics', 'also', 'important', 'research', 'topic', '.']

>> Bigrams are: 
 [('From', 'observations'), ('observations', ','), (',', 'application'), ('application', 'metaheuristic'), ('metaheuristic', 'algorithms'), ('algorithms', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', 'also'), ('also', 'important'), ('important', 'research'), ('research', 'topic'), ('topic', '.')]

>> Trigrams are: 
 [('From', 'observations', ','), ('observations', ',', 'application'), (',', 'application', 'metaheuristic'), ('application', 'metaheuristic', 'algorithms'), ('metaheuristic', 'algorithms', 'big'), ('algorithms', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', 'also'), ('analytics', 'also', 'important'), ('also', 'important', 'research'), ('important', 'research', 'topic'), ('research', 'topic', '.')]

>> POS Tags are: 
 [('From', 'IN'), ('observations', 'NNS'), (',', ','), ('application', 'NN'), ('metaheuristic', 'JJ'), ('algorithms', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('also', 'RB'), ('important', 'JJ'), ('research', 'NN'), ('topic', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['observations', 'application', 'metaheuristic algorithms', 'big data analytics', 'important research topic']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('From', 'from'), ('observations', 'observ'), (',', ','), ('application', 'applic'), ('metaheuristic', 'metaheurist'), ('algorithms', 'algorithm'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('also', 'also'), ('important', 'import'), ('research', 'research'), ('topic', 'topic'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('From', 'from'), ('observations', 'observ'), (',', ','), ('application', 'applic'), ('metaheuristic', 'metaheurist'), ('algorithms', 'algorithm'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('also', 'also'), ('important', 'import'), ('research', 'research'), ('topic', 'topic'), ('.', '.')]

>> Lemmatization: 
 [('From', 'From'), ('observations', 'observation'), (',', ','), ('application', 'application'), ('metaheuristic', 'metaheuristic'), ('algorithms', 'algorithm'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('also', 'also'), ('important', 'important'), ('research', 'research'), ('topic', 'topic'), ('.', '.')]



========================================== PARAGRAPH 392 ===========================================

 – Because social network is part of the daily life of most people and because its data  is also a kind of big data, how to analyze the data of a social network has become a  promising research issue. Obviously, it can be used to predict the behavior of a user.  After that, we can make applicable strategies for the user. For instance, a business intel- ligence system can use the analysis results to encourage particular customers to buy  the goods they are interested. 

------------------- Sentence 1 -------------------

 – Because social network is part of the daily life of most people and because its data  is also a kind of big data, how to analyze the data of a social network has become a  promising research issue.

>> Tokens are: 
 ['–', 'Because', 'social', 'network', 'part', 'daily', 'life', 'people', 'data', 'also', 'kind', 'big', 'data', ',', 'analyze', 'data', 'social', 'network', 'become', 'promising', 'research', 'issue', '.']

>> Bigrams are: 
 [('–', 'Because'), ('Because', 'social'), ('social', 'network'), ('network', 'part'), ('part', 'daily'), ('daily', 'life'), ('life', 'people'), ('people', 'data'), ('data', 'also'), ('also', 'kind'), ('kind', 'big'), ('big', 'data'), ('data', ','), (',', 'analyze'), ('analyze', 'data'), ('data', 'social'), ('social', 'network'), ('network', 'become'), ('become', 'promising'), ('promising', 'research'), ('research', 'issue'), ('issue', '.')]

>> Trigrams are: 
 [('–', 'Because', 'social'), ('Because', 'social', 'network'), ('social', 'network', 'part'), ('network', 'part', 'daily'), ('part', 'daily', 'life'), ('daily', 'life', 'people'), ('life', 'people', 'data'), ('people', 'data', 'also'), ('data', 'also', 'kind'), ('also', 'kind', 'big'), ('kind', 'big', 'data'), ('big', 'data', ','), ('data', ',', 'analyze'), (',', 'analyze', 'data'), ('analyze', 'data', 'social'), ('data', 'social', 'network'), ('social', 'network', 'become'), ('network', 'become', 'promising'), ('become', 'promising', 'research'), ('promising', 'research', 'issue'), ('research', 'issue', '.')]

>> POS Tags are: 
 [('–', 'NN'), ('Because', 'IN'), ('social', 'JJ'), ('network', 'NN'), ('part', 'NN'), ('daily', 'JJ'), ('life', 'NN'), ('people', 'NNS'), ('data', 'NNS'), ('also', 'RB'), ('kind', 'NN'), ('big', 'JJ'), ('data', 'NNS'), (',', ','), ('analyze', 'NN'), ('data', 'NNS'), ('social', 'JJ'), ('network', 'NN'), ('become', 'VBP'), ('promising', 'JJ'), ('research', 'NN'), ('issue', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['–', 'social network part', 'daily life people data', 'kind', 'big data', 'analyze data', 'social network', 'promising research issue']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('–', '–'), ('Because', 'becaus'), ('social', 'social'), ('network', 'network'), ('part', 'part'), ('daily', 'daili'), ('life', 'life'), ('people', 'peopl'), ('data', 'data'), ('also', 'also'), ('kind', 'kind'), ('big', 'big'), ('data', 'data'), (',', ','), ('analyze', 'analyz'), ('data', 'data'), ('social', 'social'), ('network', 'network'), ('become', 'becom'), ('promising', 'promis'), ('research', 'research'), ('issue', 'issu'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('–', '–'), ('Because', 'becaus'), ('social', 'social'), ('network', 'network'), ('part', 'part'), ('daily', 'daili'), ('life', 'life'), ('people', 'peopl'), ('data', 'data'), ('also', 'also'), ('kind', 'kind'), ('big', 'big'), ('data', 'data'), (',', ','), ('analyze', 'analyz'), ('data', 'data'), ('social', 'social'), ('network', 'network'), ('become', 'becom'), ('promising', 'promis'), ('research', 'research'), ('issue', 'issu'), ('.', '.')]

>> Lemmatization: 
 [('–', '–'), ('Because', 'Because'), ('social', 'social'), ('network', 'network'), ('part', 'part'), ('daily', 'daily'), ('life', 'life'), ('people', 'people'), ('data', 'data'), ('also', 'also'), ('kind', 'kind'), ('big', 'big'), ('data', 'data'), (',', ','), ('analyze', 'analyze'), ('data', 'data'), ('social', 'social'), ('network', 'network'), ('become', 'become'), ('promising', 'promising'), ('research', 'research'), ('issue', 'issue'), ('.', '.')]


------------------- Sentence 2 -------------------

Obviously, it can be used to predict the behavior of a user.

>> Tokens are: 
 ['Obviously', ',', 'used', 'predict', 'behavior', 'user', '.']

>> Bigrams are: 
 [('Obviously', ','), (',', 'used'), ('used', 'predict'), ('predict', 'behavior'), ('behavior', 'user'), ('user', '.')]

>> Trigrams are: 
 [('Obviously', ',', 'used'), (',', 'used', 'predict'), ('used', 'predict', 'behavior'), ('predict', 'behavior', 'user'), ('behavior', 'user', '.')]

>> POS Tags are: 
 [('Obviously', 'RB'), (',', ','), ('used', 'VBD'), ('predict', 'JJ'), ('behavior', 'JJ'), ('user', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['predict behavior user']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Obviously', 'obvious'), (',', ','), ('used', 'use'), ('predict', 'predict'), ('behavior', 'behavior'), ('user', 'user'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Obviously', 'obvious'), (',', ','), ('used', 'use'), ('predict', 'predict'), ('behavior', 'behavior'), ('user', 'user'), ('.', '.')]

>> Lemmatization: 
 [('Obviously', 'Obviously'), (',', ','), ('used', 'used'), ('predict', 'predict'), ('behavior', 'behavior'), ('user', 'user'), ('.', '.')]


------------------- Sentence 3 -------------------

After that, we can make applicable strategies for the user.

>> Tokens are: 
 ['After', ',', 'make', 'applicable', 'strategies', 'user', '.']

>> Bigrams are: 
 [('After', ','), (',', 'make'), ('make', 'applicable'), ('applicable', 'strategies'), ('strategies', 'user'), ('user', '.')]

>> Trigrams are: 
 [('After', ',', 'make'), (',', 'make', 'applicable'), ('make', 'applicable', 'strategies'), ('applicable', 'strategies', 'user'), ('strategies', 'user', '.')]

>> POS Tags are: 
 [('After', 'IN'), (',', ','), ('make', 'VBP'), ('applicable', 'JJ'), ('strategies', 'NNS'), ('user', 'RBR'), ('.', '.')]

>> Noun Phrases are: 
 ['applicable strategies']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('After', 'after'), (',', ','), ('make', 'make'), ('applicable', 'applic'), ('strategies', 'strategi'), ('user', 'user'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('After', 'after'), (',', ','), ('make', 'make'), ('applicable', 'applic'), ('strategies', 'strategi'), ('user', 'user'), ('.', '.')]

>> Lemmatization: 
 [('After', 'After'), (',', ','), ('make', 'make'), ('applicable', 'applicable'), ('strategies', 'strategy'), ('user', 'user'), ('.', '.')]


------------------- Sentence 4 -------------------

For instance, a business intel- ligence system can use the analysis results to encourage particular customers to buy  the goods they are interested.

>> Tokens are: 
 ['For', 'instance', ',', 'business', 'intel-', 'ligence', 'system', 'use', 'analysis', 'results', 'encourage', 'particular', 'customers', 'buy', 'goods', 'interested', '.']

>> Bigrams are: 
 [('For', 'instance'), ('instance', ','), (',', 'business'), ('business', 'intel-'), ('intel-', 'ligence'), ('ligence', 'system'), ('system', 'use'), ('use', 'analysis'), ('analysis', 'results'), ('results', 'encourage'), ('encourage', 'particular'), ('particular', 'customers'), ('customers', 'buy'), ('buy', 'goods'), ('goods', 'interested'), ('interested', '.')]

>> Trigrams are: 
 [('For', 'instance', ','), ('instance', ',', 'business'), (',', 'business', 'intel-'), ('business', 'intel-', 'ligence'), ('intel-', 'ligence', 'system'), ('ligence', 'system', 'use'), ('system', 'use', 'analysis'), ('use', 'analysis', 'results'), ('analysis', 'results', 'encourage'), ('results', 'encourage', 'particular'), ('encourage', 'particular', 'customers'), ('particular', 'customers', 'buy'), ('customers', 'buy', 'goods'), ('buy', 'goods', 'interested'), ('goods', 'interested', '.')]

>> POS Tags are: 
 [('For', 'IN'), ('instance', 'NN'), (',', ','), ('business', 'NN'), ('intel-', 'JJ'), ('ligence', 'NN'), ('system', 'NN'), ('use', 'NN'), ('analysis', 'NN'), ('results', 'NNS'), ('encourage', 'VBP'), ('particular', 'JJ'), ('customers', 'NNS'), ('buy', 'VBP'), ('goods', 'NNS'), ('interested', 'JJ'), ('.', '.')]

>> Noun Phrases are: 
 ['instance', 'business', 'intel- ligence system use analysis results', 'particular customers', 'goods']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('For', 'for'), ('instance', 'instanc'), (',', ','), ('business', 'busi'), ('intel-', 'intel-'), ('ligence', 'ligenc'), ('system', 'system'), ('use', 'use'), ('analysis', 'analysi'), ('results', 'result'), ('encourage', 'encourag'), ('particular', 'particular'), ('customers', 'custom'), ('buy', 'buy'), ('goods', 'good'), ('interested', 'interest'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('For', 'for'), ('instance', 'instanc'), (',', ','), ('business', 'busi'), ('intel-', 'intel-'), ('ligence', 'ligenc'), ('system', 'system'), ('use', 'use'), ('analysis', 'analysi'), ('results', 'result'), ('encourage', 'encourag'), ('particular', 'particular'), ('customers', 'custom'), ('buy', 'buy'), ('goods', 'good'), ('interested', 'interest'), ('.', '.')]

>> Lemmatization: 
 [('For', 'For'), ('instance', 'instance'), (',', ','), ('business', 'business'), ('intel-', 'intel-'), ('ligence', 'ligence'), ('system', 'system'), ('use', 'use'), ('analysis', 'analysis'), ('results', 'result'), ('encourage', 'encourage'), ('particular', 'particular'), ('customers', 'customer'), ('buy', 'buy'), ('goods', 'good'), ('interested', 'interested'), ('.', '.')]



========================================== PARAGRAPH 393 ===========================================

 – The security and privacy issues that accompany the work of data analysis are intuitive  research topics which contain how to safely store the data, how to make sure the data  communication is protected, and how to prevent someone from finding out the infor- mation about us. Many problems of data security and privacy are essentially the same  as those of the traditional data analysis even if we are entering the big data age. Thus,  how to protect the data will also appear in the research of big data analytics. 

------------------- Sentence 1 -------------------

 – The security and privacy issues that accompany the work of data analysis are intuitive  research topics which contain how to safely store the data, how to make sure the data  communication is protected, and how to prevent someone from finding out the infor- mation about us.

>> Tokens are: 
 ['–', 'The', 'security', 'privacy', 'issues', 'accompany', 'work', 'data', 'analysis', 'intuitive', 'research', 'topics', 'contain', 'safely', 'store', 'data', ',', 'make', 'sure', 'data', 'communication', 'protected', ',', 'prevent', 'someone', 'finding', 'infor-', 'mation', 'us', '.']

>> Bigrams are: 
 [('–', 'The'), ('The', 'security'), ('security', 'privacy'), ('privacy', 'issues'), ('issues', 'accompany'), ('accompany', 'work'), ('work', 'data'), ('data', 'analysis'), ('analysis', 'intuitive'), ('intuitive', 'research'), ('research', 'topics'), ('topics', 'contain'), ('contain', 'safely'), ('safely', 'store'), ('store', 'data'), ('data', ','), (',', 'make'), ('make', 'sure'), ('sure', 'data'), ('data', 'communication'), ('communication', 'protected'), ('protected', ','), (',', 'prevent'), ('prevent', 'someone'), ('someone', 'finding'), ('finding', 'infor-'), ('infor-', 'mation'), ('mation', 'us'), ('us', '.')]

>> Trigrams are: 
 [('–', 'The', 'security'), ('The', 'security', 'privacy'), ('security', 'privacy', 'issues'), ('privacy', 'issues', 'accompany'), ('issues', 'accompany', 'work'), ('accompany', 'work', 'data'), ('work', 'data', 'analysis'), ('data', 'analysis', 'intuitive'), ('analysis', 'intuitive', 'research'), ('intuitive', 'research', 'topics'), ('research', 'topics', 'contain'), ('topics', 'contain', 'safely'), ('contain', 'safely', 'store'), ('safely', 'store', 'data'), ('store', 'data', ','), ('data', ',', 'make'), (',', 'make', 'sure'), ('make', 'sure', 'data'), ('sure', 'data', 'communication'), ('data', 'communication', 'protected'), ('communication', 'protected', ','), ('protected', ',', 'prevent'), (',', 'prevent', 'someone'), ('prevent', 'someone', 'finding'), ('someone', 'finding', 'infor-'), ('finding', 'infor-', 'mation'), ('infor-', 'mation', 'us'), ('mation', 'us', '.')]

>> POS Tags are: 
 [('–', 'IN'), ('The', 'DT'), ('security', 'NN'), ('privacy', 'NN'), ('issues', 'NNS'), ('accompany', 'VBP'), ('work', 'NN'), ('data', 'NNS'), ('analysis', 'NN'), ('intuitive', 'JJ'), ('research', 'NN'), ('topics', 'NNS'), ('contain', 'VBP'), ('safely', 'RB'), ('store', 'NN'), ('data', 'NNS'), (',', ','), ('make', 'VBP'), ('sure', 'JJ'), ('data', 'NNS'), ('communication', 'NN'), ('protected', 'VBN'), (',', ','), ('prevent', 'VB'), ('someone', 'NN'), ('finding', 'VBG'), ('infor-', 'JJ'), ('mation', 'NN'), ('us', 'PRP'), ('.', '.')]

>> Noun Phrases are: 
 ['The security privacy issues', 'work data analysis', 'intuitive research topics', 'store data', 'sure data communication', 'someone', 'infor- mation']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('–', '–'), ('The', 'the'), ('security', 'secur'), ('privacy', 'privaci'), ('issues', 'issu'), ('accompany', 'accompani'), ('work', 'work'), ('data', 'data'), ('analysis', 'analysi'), ('intuitive', 'intuit'), ('research', 'research'), ('topics', 'topic'), ('contain', 'contain'), ('safely', 'safe'), ('store', 'store'), ('data', 'data'), (',', ','), ('make', 'make'), ('sure', 'sure'), ('data', 'data'), ('communication', 'commun'), ('protected', 'protect'), (',', ','), ('prevent', 'prevent'), ('someone', 'someon'), ('finding', 'find'), ('infor-', 'infor-'), ('mation', 'mation'), ('us', 'us'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('–', '–'), ('The', 'the'), ('security', 'secur'), ('privacy', 'privaci'), ('issues', 'issu'), ('accompany', 'accompani'), ('work', 'work'), ('data', 'data'), ('analysis', 'analysi'), ('intuitive', 'intuit'), ('research', 'research'), ('topics', 'topic'), ('contain', 'contain'), ('safely', 'safe'), ('store', 'store'), ('data', 'data'), (',', ','), ('make', 'make'), ('sure', 'sure'), ('data', 'data'), ('communication', 'communic'), ('protected', 'protect'), (',', ','), ('prevent', 'prevent'), ('someone', 'someon'), ('finding', 'find'), ('infor-', 'infor-'), ('mation', 'mation'), ('us', 'us'), ('.', '.')]

>> Lemmatization: 
 [('–', '–'), ('The', 'The'), ('security', 'security'), ('privacy', 'privacy'), ('issues', 'issue'), ('accompany', 'accompany'), ('work', 'work'), ('data', 'data'), ('analysis', 'analysis'), ('intuitive', 'intuitive'), ('research', 'research'), ('topics', 'topic'), ('contain', 'contain'), ('safely', 'safely'), ('store', 'store'), ('data', 'data'), (',', ','), ('make', 'make'), ('sure', 'sure'), ('data', 'data'), ('communication', 'communication'), ('protected', 'protected'), (',', ','), ('prevent', 'prevent'), ('someone', 'someone'), ('finding', 'finding'), ('infor-', 'infor-'), ('mation', 'mation'), ('us', 'u'), ('.', '.')]


------------------- Sentence 2 -------------------

Many problems of data security and privacy are essentially the same  as those of the traditional data analysis even if we are entering the big data age.

>> Tokens are: 
 ['Many', 'problems', 'data', 'security', 'privacy', 'essentially', 'traditional', 'data', 'analysis', 'even', 'entering', 'big', 'data', 'age', '.']

>> Bigrams are: 
 [('Many', 'problems'), ('problems', 'data'), ('data', 'security'), ('security', 'privacy'), ('privacy', 'essentially'), ('essentially', 'traditional'), ('traditional', 'data'), ('data', 'analysis'), ('analysis', 'even'), ('even', 'entering'), ('entering', 'big'), ('big', 'data'), ('data', 'age'), ('age', '.')]

>> Trigrams are: 
 [('Many', 'problems', 'data'), ('problems', 'data', 'security'), ('data', 'security', 'privacy'), ('security', 'privacy', 'essentially'), ('privacy', 'essentially', 'traditional'), ('essentially', 'traditional', 'data'), ('traditional', 'data', 'analysis'), ('data', 'analysis', 'even'), ('analysis', 'even', 'entering'), ('even', 'entering', 'big'), ('entering', 'big', 'data'), ('big', 'data', 'age'), ('data', 'age', '.')]

>> POS Tags are: 
 [('Many', 'JJ'), ('problems', 'NNS'), ('data', 'VBP'), ('security', 'NN'), ('privacy', 'NN'), ('essentially', 'RB'), ('traditional', 'JJ'), ('data', 'NNS'), ('analysis', 'NN'), ('even', 'RB'), ('entering', 'VBG'), ('big', 'JJ'), ('data', 'NNS'), ('age', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Many problems', 'security privacy', 'traditional data analysis', 'big data age']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Many', 'mani'), ('problems', 'problem'), ('data', 'data'), ('security', 'secur'), ('privacy', 'privaci'), ('essentially', 'essenti'), ('traditional', 'tradit'), ('data', 'data'), ('analysis', 'analysi'), ('even', 'even'), ('entering', 'enter'), ('big', 'big'), ('data', 'data'), ('age', 'age'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Many', 'mani'), ('problems', 'problem'), ('data', 'data'), ('security', 'secur'), ('privacy', 'privaci'), ('essentially', 'essenti'), ('traditional', 'tradit'), ('data', 'data'), ('analysis', 'analysi'), ('even', 'even'), ('entering', 'enter'), ('big', 'big'), ('data', 'data'), ('age', 'age'), ('.', '.')]

>> Lemmatization: 
 [('Many', 'Many'), ('problems', 'problem'), ('data', 'data'), ('security', 'security'), ('privacy', 'privacy'), ('essentially', 'essentially'), ('traditional', 'traditional'), ('data', 'data'), ('analysis', 'analysis'), ('even', 'even'), ('entering', 'entering'), ('big', 'big'), ('data', 'data'), ('age', 'age'), ('.', '.')]


------------------- Sentence 3 -------------------

Thus,  how to protect the data will also appear in the research of big data analytics.

>> Tokens are: 
 ['Thus', ',', 'protect', 'data', 'also', 'appear', 'research', 'big', 'data', 'analytics', '.']

>> Bigrams are: 
 [('Thus', ','), (',', 'protect'), ('protect', 'data'), ('data', 'also'), ('also', 'appear'), ('appear', 'research'), ('research', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', '.')]

>> Trigrams are: 
 [('Thus', ',', 'protect'), (',', 'protect', 'data'), ('protect', 'data', 'also'), ('data', 'also', 'appear'), ('also', 'appear', 'research'), ('appear', 'research', 'big'), ('research', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', '.')]

>> POS Tags are: 
 [('Thus', 'RB'), (',', ','), ('protect', 'NN'), ('data', 'NNS'), ('also', 'RB'), ('appear', 'VBP'), ('research', 'NN'), ('big', 'JJ'), ('data', 'NN'), ('analytics', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['protect data', 'research', 'big data analytics']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Thus', 'thu'), (',', ','), ('protect', 'protect'), ('data', 'data'), ('also', 'also'), ('appear', 'appear'), ('research', 'research'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Thus', 'thus'), (',', ','), ('protect', 'protect'), ('data', 'data'), ('also', 'also'), ('appear', 'appear'), ('research', 'research'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('.', '.')]

>> Lemmatization: 
 [('Thus', 'Thus'), (',', ','), ('protect', 'protect'), ('data', 'data'), ('also', 'also'), ('appear', 'appear'), ('research', 'research'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('.', '.')]



========================================== PARAGRAPH 394 ===========================================

Abbreviations PCA: principal components analysis; 3Vs: volume, velocity, and variety; IDC: International Data Corporation; KDD: knowl‑ edge discovery in databases; SVM: support vector machine; SSE: sum of squared errors; GLADE: generalized linear aggre‑ gates distributed engine; BDAF: big data architecture framework; CBDMASP: cloud‑based big data mining & analyzing  services platform; SODSS: service‑oriented decision support system; HPCC: high performance computing cluster system;  BI&I: business intelligence and analytics; DBMS: database management system; MSF: multiple species flocking; GA:  genetic algorithm; SOM: self‑organizing map; MBP: multiple back‑propagation; YCSB: yahoo cloud serving benchmark;  HPC: high performance computing; EEG: electroencephalography. 

------------------- Sentence 1 -------------------

Abbreviations PCA: principal components analysis; 3Vs: volume, velocity, and variety; IDC: International Data Corporation; KDD: knowl‑ edge discovery in databases; SVM: support vector machine; SSE: sum of squared errors; GLADE: generalized linear aggre‑ gates distributed engine; BDAF: big data architecture framework; CBDMASP: cloud‑based big data mining & analyzing  services platform; SODSS: service‑oriented decision support system; HPCC: high performance computing cluster system;  BI&I: business intelligence and analytics; DBMS: database management system; MSF: multiple species flocking; GA:  genetic algorithm; SOM: self‑organizing map; MBP: multiple back‑propagation; YCSB: yahoo cloud serving benchmark;  HPC: high performance computing; EEG: electroencephalography.

>> Tokens are: 
 ['Abbreviations', 'PCA', ':', 'principal', 'components', 'analysis', ';', '3Vs', ':', 'volume', ',', 'velocity', ',', 'variety', ';', 'IDC', ':', 'International', 'Data', 'Corporation', ';', 'KDD', ':', 'knowl‑', 'edge', 'discovery', 'databases', ';', 'SVM', ':', 'support', 'vector', 'machine', ';', 'SSE', ':', 'sum', 'squared', 'errors', ';', 'GLADE', ':', 'generalized', 'linear', 'aggre‑', 'gates', 'distributed', 'engine', ';', 'BDAF', ':', 'big', 'data', 'architecture', 'framework', ';', 'CBDMASP', ':', 'cloud‑based', 'big', 'data', 'mining', '&', 'analyzing', 'services', 'platform', ';', 'SODSS', ':', 'service‑oriented', 'decision', 'support', 'system', ';', 'HPCC', ':', 'high', 'performance', 'computing', 'cluster', 'system', ';', 'BI', '&', 'I', ':', 'business', 'intelligence', 'analytics', ';', 'DBMS', ':', 'database', 'management', 'system', ';', 'MSF', ':', 'multiple', 'species', 'flocking', ';', 'GA', ':', 'genetic', 'algorithm', ';', 'SOM', ':', 'self‑organizing', 'map', ';', 'MBP', ':', 'multiple', 'back‑propagation', ';', 'YCSB', ':', 'yahoo', 'cloud', 'serving', 'benchmark', ';', 'HPC', ':', 'high', 'performance', 'computing', ';', 'EEG', ':', 'electroencephalography', '.']

>> Bigrams are: 
 [('Abbreviations', 'PCA'), ('PCA', ':'), (':', 'principal'), ('principal', 'components'), ('components', 'analysis'), ('analysis', ';'), (';', '3Vs'), ('3Vs', ':'), (':', 'volume'), ('volume', ','), (',', 'velocity'), ('velocity', ','), (',', 'variety'), ('variety', ';'), (';', 'IDC'), ('IDC', ':'), (':', 'International'), ('International', 'Data'), ('Data', 'Corporation'), ('Corporation', ';'), (';', 'KDD'), ('KDD', ':'), (':', 'knowl‑'), ('knowl‑', 'edge'), ('edge', 'discovery'), ('discovery', 'databases'), ('databases', ';'), (';', 'SVM'), ('SVM', ':'), (':', 'support'), ('support', 'vector'), ('vector', 'machine'), ('machine', ';'), (';', 'SSE'), ('SSE', ':'), (':', 'sum'), ('sum', 'squared'), ('squared', 'errors'), ('errors', ';'), (';', 'GLADE'), ('GLADE', ':'), (':', 'generalized'), ('generalized', 'linear'), ('linear', 'aggre‑'), ('aggre‑', 'gates'), ('gates', 'distributed'), ('distributed', 'engine'), ('engine', ';'), (';', 'BDAF'), ('BDAF', ':'), (':', 'big'), ('big', 'data'), ('data', 'architecture'), ('architecture', 'framework'), ('framework', ';'), (';', 'CBDMASP'), ('CBDMASP', ':'), (':', 'cloud‑based'), ('cloud‑based', 'big'), ('big', 'data'), ('data', 'mining'), ('mining', '&'), ('&', 'analyzing'), ('analyzing', 'services'), ('services', 'platform'), ('platform', ';'), (';', 'SODSS'), ('SODSS', ':'), (':', 'service‑oriented'), ('service‑oriented', 'decision'), ('decision', 'support'), ('support', 'system'), ('system', ';'), (';', 'HPCC'), ('HPCC', ':'), (':', 'high'), ('high', 'performance'), ('performance', 'computing'), ('computing', 'cluster'), ('cluster', 'system'), ('system', ';'), (';', 'BI'), ('BI', '&'), ('&', 'I'), ('I', ':'), (':', 'business'), ('business', 'intelligence'), ('intelligence', 'analytics'), ('analytics', ';'), (';', 'DBMS'), ('DBMS', ':'), (':', 'database'), ('database', 'management'), ('management', 'system'), ('system', ';'), (';', 'MSF'), ('MSF', ':'), (':', 'multiple'), ('multiple', 'species'), ('species', 'flocking'), ('flocking', ';'), (';', 'GA'), ('GA', ':'), (':', 'genetic'), ('genetic', 'algorithm'), ('algorithm', ';'), (';', 'SOM'), ('SOM', ':'), (':', 'self‑organizing'), ('self‑organizing', 'map'), ('map', ';'), (';', 'MBP'), ('MBP', ':'), (':', 'multiple'), ('multiple', 'back‑propagation'), ('back‑propagation', ';'), (';', 'YCSB'), ('YCSB', ':'), (':', 'yahoo'), ('yahoo', 'cloud'), ('cloud', 'serving'), ('serving', 'benchmark'), ('benchmark', ';'), (';', 'HPC'), ('HPC', ':'), (':', 'high'), ('high', 'performance'), ('performance', 'computing'), ('computing', ';'), (';', 'EEG'), ('EEG', ':'), (':', 'electroencephalography'), ('electroencephalography', '.')]

>> Trigrams are: 
 [('Abbreviations', 'PCA', ':'), ('PCA', ':', 'principal'), (':', 'principal', 'components'), ('principal', 'components', 'analysis'), ('components', 'analysis', ';'), ('analysis', ';', '3Vs'), (';', '3Vs', ':'), ('3Vs', ':', 'volume'), (':', 'volume', ','), ('volume', ',', 'velocity'), (',', 'velocity', ','), ('velocity', ',', 'variety'), (',', 'variety', ';'), ('variety', ';', 'IDC'), (';', 'IDC', ':'), ('IDC', ':', 'International'), (':', 'International', 'Data'), ('International', 'Data', 'Corporation'), ('Data', 'Corporation', ';'), ('Corporation', ';', 'KDD'), (';', 'KDD', ':'), ('KDD', ':', 'knowl‑'), (':', 'knowl‑', 'edge'), ('knowl‑', 'edge', 'discovery'), ('edge', 'discovery', 'databases'), ('discovery', 'databases', ';'), ('databases', ';', 'SVM'), (';', 'SVM', ':'), ('SVM', ':', 'support'), (':', 'support', 'vector'), ('support', 'vector', 'machine'), ('vector', 'machine', ';'), ('machine', ';', 'SSE'), (';', 'SSE', ':'), ('SSE', ':', 'sum'), (':', 'sum', 'squared'), ('sum', 'squared', 'errors'), ('squared', 'errors', ';'), ('errors', ';', 'GLADE'), (';', 'GLADE', ':'), ('GLADE', ':', 'generalized'), (':', 'generalized', 'linear'), ('generalized', 'linear', 'aggre‑'), ('linear', 'aggre‑', 'gates'), ('aggre‑', 'gates', 'distributed'), ('gates', 'distributed', 'engine'), ('distributed', 'engine', ';'), ('engine', ';', 'BDAF'), (';', 'BDAF', ':'), ('BDAF', ':', 'big'), (':', 'big', 'data'), ('big', 'data', 'architecture'), ('data', 'architecture', 'framework'), ('architecture', 'framework', ';'), ('framework', ';', 'CBDMASP'), (';', 'CBDMASP', ':'), ('CBDMASP', ':', 'cloud‑based'), (':', 'cloud‑based', 'big'), ('cloud‑based', 'big', 'data'), ('big', 'data', 'mining'), ('data', 'mining', '&'), ('mining', '&', 'analyzing'), ('&', 'analyzing', 'services'), ('analyzing', 'services', 'platform'), ('services', 'platform', ';'), ('platform', ';', 'SODSS'), (';', 'SODSS', ':'), ('SODSS', ':', 'service‑oriented'), (':', 'service‑oriented', 'decision'), ('service‑oriented', 'decision', 'support'), ('decision', 'support', 'system'), ('support', 'system', ';'), ('system', ';', 'HPCC'), (';', 'HPCC', ':'), ('HPCC', ':', 'high'), (':', 'high', 'performance'), ('high', 'performance', 'computing'), ('performance', 'computing', 'cluster'), ('computing', 'cluster', 'system'), ('cluster', 'system', ';'), ('system', ';', 'BI'), (';', 'BI', '&'), ('BI', '&', 'I'), ('&', 'I', ':'), ('I', ':', 'business'), (':', 'business', 'intelligence'), ('business', 'intelligence', 'analytics'), ('intelligence', 'analytics', ';'), ('analytics', ';', 'DBMS'), (';', 'DBMS', ':'), ('DBMS', ':', 'database'), (':', 'database', 'management'), ('database', 'management', 'system'), ('management', 'system', ';'), ('system', ';', 'MSF'), (';', 'MSF', ':'), ('MSF', ':', 'multiple'), (':', 'multiple', 'species'), ('multiple', 'species', 'flocking'), ('species', 'flocking', ';'), ('flocking', ';', 'GA'), (';', 'GA', ':'), ('GA', ':', 'genetic'), (':', 'genetic', 'algorithm'), ('genetic', 'algorithm', ';'), ('algorithm', ';', 'SOM'), (';', 'SOM', ':'), ('SOM', ':', 'self‑organizing'), (':', 'self‑organizing', 'map'), ('self‑organizing', 'map', ';'), ('map', ';', 'MBP'), (';', 'MBP', ':'), ('MBP', ':', 'multiple'), (':', 'multiple', 'back‑propagation'), ('multiple', 'back‑propagation', ';'), ('back‑propagation', ';', 'YCSB'), (';', 'YCSB', ':'), ('YCSB', ':', 'yahoo'), (':', 'yahoo', 'cloud'), ('yahoo', 'cloud', 'serving'), ('cloud', 'serving', 'benchmark'), ('serving', 'benchmark', ';'), ('benchmark', ';', 'HPC'), (';', 'HPC', ':'), ('HPC', ':', 'high'), (':', 'high', 'performance'), ('high', 'performance', 'computing'), ('performance', 'computing', ';'), ('computing', ';', 'EEG'), (';', 'EEG', ':'), ('EEG', ':', 'electroencephalography'), (':', 'electroencephalography', '.')]

>> POS Tags are: 
 [('Abbreviations', 'NNS'), ('PCA', 'NNP'), (':', ':'), ('principal', 'JJ'), ('components', 'NNS'), ('analysis', 'NN'), (';', ':'), ('3Vs', 'CD'), (':', ':'), ('volume', 'NN'), (',', ','), ('velocity', 'NN'), (',', ','), ('variety', 'NN'), (';', ':'), ('IDC', 'NNP'), (':', ':'), ('International', 'NNP'), ('Data', 'NNP'), ('Corporation', 'NNP'), (';', ':'), ('KDD', 'NNP'), (':', ':'), ('knowl‑', 'NN'), ('edge', 'NN'), ('discovery', 'NN'), ('databases', 'VBZ'), (';', ':'), ('SVM', 'NNP'), (':', ':'), ('support', 'NN'), ('vector', 'NN'), ('machine', 'NN'), (';', ':'), ('SSE', 'NNP'), (':', ':'), ('sum', 'NN'), ('squared', 'VBD'), ('errors', 'NNS'), (';', ':'), ('GLADE', 'NNP'), (':', ':'), ('generalized', 'VBN'), ('linear', 'JJ'), ('aggre‑', 'NN'), ('gates', 'NNS'), ('distributed', 'VBD'), ('engine', 'NN'), (';', ':'), ('BDAF', 'NNP'), (':', ':'), ('big', 'JJ'), ('data', 'NNS'), ('architecture', 'NN'), ('framework', 'NN'), (';', ':'), ('CBDMASP', 'NNP'), (':', ':'), ('cloud‑based', 'VBD'), ('big', 'JJ'), ('data', 'NNS'), ('mining', 'NN'), ('&', 'CC'), ('analyzing', 'NN'), ('services', 'NNS'), ('platform', 'NN'), (';', ':'), ('SODSS', 'NNP'), (':', ':'), ('service‑oriented', 'VBN'), ('decision', 'NN'), ('support', 'NN'), ('system', 'NN'), (';', ':'), ('HPCC', 'NNP'), (':', ':'), ('high', 'JJ'), ('performance', 'NN'), ('computing', 'VBG'), ('cluster', 'NN'), ('system', 'NN'), (';', ':'), ('BI', 'NNP'), ('&', 'CC'), ('I', 'PRP'), (':', ':'), ('business', 'NN'), ('intelligence', 'NN'), ('analytics', 'NNS'), (';', ':'), ('DBMS', 'NNP'), (':', ':'), ('database', 'NN'), ('management', 'NN'), ('system', 'NN'), (';', ':'), ('MSF', 'NNP'), (':', ':'), ('multiple', 'JJ'), ('species', 'NNS'), ('flocking', 'VBG'), (';', ':'), ('GA', 'NNP'), (':', ':'), ('genetic', 'JJ'), ('algorithm', 'NN'), (';', ':'), ('SOM', 'NNP'), (':', ':'), ('self‑organizing', 'NN'), ('map', 'NN'), (';', ':'), ('MBP', 'NNP'), (':', ':'), ('multiple', 'JJ'), ('back‑propagation', 'NN'), (';', ':'), ('YCSB', 'CC'), (':', ':'), ('yahoo', 'NN'), ('cloud', 'NN'), ('serving', 'VBG'), ('benchmark', 'NN'), (';', ':'), ('HPC', 'NNP'), (':', ':'), ('high', 'JJ'), ('performance', 'NN'), ('computing', 'NN'), (';', ':'), ('EEG', 'NNP'), (':', ':'), ('electroencephalography', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Abbreviations PCA', 'principal components analysis', 'volume', 'velocity', 'variety', 'IDC', 'International Data Corporation', 'KDD', 'knowl‑ edge discovery', 'SVM', 'support vector machine', 'SSE', 'sum', 'errors', 'GLADE', 'linear aggre‑ gates', 'engine', 'BDAF', 'big data architecture framework', 'CBDMASP', 'big data mining', 'analyzing services platform', 'SODSS', 'decision support system', 'HPCC', 'high performance', 'cluster system', 'BI', 'business intelligence analytics', 'DBMS', 'database management system', 'MSF', 'multiple species', 'GA', 'genetic algorithm', 'SOM', 'self‑organizing map', 'MBP', 'multiple back‑propagation', 'yahoo cloud', 'benchmark', 'HPC', 'high performance computing', 'EEG', 'electroencephalography']

>> Named Entities are: 
 [('ORGANIZATION', 'International Data Corporation')] 

>> Stemming using Porter Stemmer: 
 [('Abbreviations', 'abbrevi'), ('PCA', 'pca'), (':', ':'), ('principal', 'princip'), ('components', 'compon'), ('analysis', 'analysi'), (';', ';'), ('3Vs', '3v'), (':', ':'), ('volume', 'volum'), (',', ','), ('velocity', 'veloc'), (',', ','), ('variety', 'varieti'), (';', ';'), ('IDC', 'idc'), (':', ':'), ('International', 'intern'), ('Data', 'data'), ('Corporation', 'corpor'), (';', ';'), ('KDD', 'kdd'), (':', ':'), ('knowl‑', 'knowl‑'), ('edge', 'edg'), ('discovery', 'discoveri'), ('databases', 'databas'), (';', ';'), ('SVM', 'svm'), (':', ':'), ('support', 'support'), ('vector', 'vector'), ('machine', 'machin'), (';', ';'), ('SSE', 'sse'), (':', ':'), ('sum', 'sum'), ('squared', 'squar'), ('errors', 'error'), (';', ';'), ('GLADE', 'glade'), (':', ':'), ('generalized', 'gener'), ('linear', 'linear'), ('aggre‑', 'aggre‑'), ('gates', 'gate'), ('distributed', 'distribut'), ('engine', 'engin'), (';', ';'), ('BDAF', 'bdaf'), (':', ':'), ('big', 'big'), ('data', 'data'), ('architecture', 'architectur'), ('framework', 'framework'), (';', ';'), ('CBDMASP', 'cbdmasp'), (':', ':'), ('cloud‑based', 'cloud‑bas'), ('big', 'big'), ('data', 'data'), ('mining', 'mine'), ('&', '&'), ('analyzing', 'analyz'), ('services', 'servic'), ('platform', 'platform'), (';', ';'), ('SODSS', 'sodss'), (':', ':'), ('service‑oriented', 'service‑ori'), ('decision', 'decis'), ('support', 'support'), ('system', 'system'), (';', ';'), ('HPCC', 'hpcc'), (':', ':'), ('high', 'high'), ('performance', 'perform'), ('computing', 'comput'), ('cluster', 'cluster'), ('system', 'system'), (';', ';'), ('BI', 'bi'), ('&', '&'), ('I', 'i'), (':', ':'), ('business', 'busi'), ('intelligence', 'intellig'), ('analytics', 'analyt'), (';', ';'), ('DBMS', 'dbm'), (':', ':'), ('database', 'databas'), ('management', 'manag'), ('system', 'system'), (';', ';'), ('MSF', 'msf'), (':', ':'), ('multiple', 'multipl'), ('species', 'speci'), ('flocking', 'flock'), (';', ';'), ('GA', 'ga'), (':', ':'), ('genetic', 'genet'), ('algorithm', 'algorithm'), (';', ';'), ('SOM', 'som'), (':', ':'), ('self‑organizing', 'self‑organ'), ('map', 'map'), (';', ';'), ('MBP', 'mbp'), (':', ':'), ('multiple', 'multipl'), ('back‑propagation', 'back‑propag'), (';', ';'), ('YCSB', 'ycsb'), (':', ':'), ('yahoo', 'yahoo'), ('cloud', 'cloud'), ('serving', 'serv'), ('benchmark', 'benchmark'), (';', ';'), ('HPC', 'hpc'), (':', ':'), ('high', 'high'), ('performance', 'perform'), ('computing', 'comput'), (';', ';'), ('EEG', 'eeg'), (':', ':'), ('electroencephalography', 'electroencephalographi'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Abbreviations', 'abbrevi'), ('PCA', 'pca'), (':', ':'), ('principal', 'princip'), ('components', 'compon'), ('analysis', 'analysi'), (';', ';'), ('3Vs', '3vs'), (':', ':'), ('volume', 'volum'), (',', ','), ('velocity', 'veloc'), (',', ','), ('variety', 'varieti'), (';', ';'), ('IDC', 'idc'), (':', ':'), ('International', 'intern'), ('Data', 'data'), ('Corporation', 'corpor'), (';', ';'), ('KDD', 'kdd'), (':', ':'), ('knowl‑', 'knowl‑'), ('edge', 'edg'), ('discovery', 'discoveri'), ('databases', 'databas'), (';', ';'), ('SVM', 'svm'), (':', ':'), ('support', 'support'), ('vector', 'vector'), ('machine', 'machin'), (';', ';'), ('SSE', 'sse'), (':', ':'), ('sum', 'sum'), ('squared', 'squar'), ('errors', 'error'), (';', ';'), ('GLADE', 'glade'), (':', ':'), ('generalized', 'general'), ('linear', 'linear'), ('aggre‑', 'aggre‑'), ('gates', 'gate'), ('distributed', 'distribut'), ('engine', 'engin'), (';', ';'), ('BDAF', 'bdaf'), (':', ':'), ('big', 'big'), ('data', 'data'), ('architecture', 'architectur'), ('framework', 'framework'), (';', ';'), ('CBDMASP', 'cbdmasp'), (':', ':'), ('cloud‑based', 'cloud‑bas'), ('big', 'big'), ('data', 'data'), ('mining', 'mine'), ('&', '&'), ('analyzing', 'analyz'), ('services', 'servic'), ('platform', 'platform'), (';', ';'), ('SODSS', 'sodss'), (':', ':'), ('service‑oriented', 'service‑ori'), ('decision', 'decis'), ('support', 'support'), ('system', 'system'), (';', ';'), ('HPCC', 'hpcc'), (':', ':'), ('high', 'high'), ('performance', 'perform'), ('computing', 'comput'), ('cluster', 'cluster'), ('system', 'system'), (';', ';'), ('BI', 'bi'), ('&', '&'), ('I', 'i'), (':', ':'), ('business', 'busi'), ('intelligence', 'intellig'), ('analytics', 'analyt'), (';', ';'), ('DBMS', 'dbms'), (':', ':'), ('database', 'databas'), ('management', 'manag'), ('system', 'system'), (';', ';'), ('MSF', 'msf'), (':', ':'), ('multiple', 'multipl'), ('species', 'speci'), ('flocking', 'flock'), (';', ';'), ('GA', 'ga'), (':', ':'), ('genetic', 'genet'), ('algorithm', 'algorithm'), (';', ';'), ('SOM', 'som'), (':', ':'), ('self‑organizing', 'self‑organ'), ('map', 'map'), (';', ';'), ('MBP', 'mbp'), (':', ':'), ('multiple', 'multipl'), ('back‑propagation', 'back‑propag'), (';', ';'), ('YCSB', 'ycsb'), (':', ':'), ('yahoo', 'yahoo'), ('cloud', 'cloud'), ('serving', 'serv'), ('benchmark', 'benchmark'), (';', ';'), ('HPC', 'hpc'), (':', ':'), ('high', 'high'), ('performance', 'perform'), ('computing', 'comput'), (';', ';'), ('EEG', 'eeg'), (':', ':'), ('electroencephalography', 'electroencephalographi'), ('.', '.')]

>> Lemmatization: 
 [('Abbreviations', 'Abbreviations'), ('PCA', 'PCA'), (':', ':'), ('principal', 'principal'), ('components', 'component'), ('analysis', 'analysis'), (';', ';'), ('3Vs', '3Vs'), (':', ':'), ('volume', 'volume'), (',', ','), ('velocity', 'velocity'), (',', ','), ('variety', 'variety'), (';', ';'), ('IDC', 'IDC'), (':', ':'), ('International', 'International'), ('Data', 'Data'), ('Corporation', 'Corporation'), (';', ';'), ('KDD', 'KDD'), (':', ':'), ('knowl‑', 'knowl‑'), ('edge', 'edge'), ('discovery', 'discovery'), ('databases', 'database'), (';', ';'), ('SVM', 'SVM'), (':', ':'), ('support', 'support'), ('vector', 'vector'), ('machine', 'machine'), (';', ';'), ('SSE', 'SSE'), (':', ':'), ('sum', 'sum'), ('squared', 'squared'), ('errors', 'error'), (';', ';'), ('GLADE', 'GLADE'), (':', ':'), ('generalized', 'generalized'), ('linear', 'linear'), ('aggre‑', 'aggre‑'), ('gates', 'gate'), ('distributed', 'distributed'), ('engine', 'engine'), (';', ';'), ('BDAF', 'BDAF'), (':', ':'), ('big', 'big'), ('data', 'data'), ('architecture', 'architecture'), ('framework', 'framework'), (';', ';'), ('CBDMASP', 'CBDMASP'), (':', ':'), ('cloud‑based', 'cloud‑based'), ('big', 'big'), ('data', 'data'), ('mining', 'mining'), ('&', '&'), ('analyzing', 'analyzing'), ('services', 'service'), ('platform', 'platform'), (';', ';'), ('SODSS', 'SODSS'), (':', ':'), ('service‑oriented', 'service‑oriented'), ('decision', 'decision'), ('support', 'support'), ('system', 'system'), (';', ';'), ('HPCC', 'HPCC'), (':', ':'), ('high', 'high'), ('performance', 'performance'), ('computing', 'computing'), ('cluster', 'cluster'), ('system', 'system'), (';', ';'), ('BI', 'BI'), ('&', '&'), ('I', 'I'), (':', ':'), ('business', 'business'), ('intelligence', 'intelligence'), ('analytics', 'analytics'), (';', ';'), ('DBMS', 'DBMS'), (':', ':'), ('database', 'database'), ('management', 'management'), ('system', 'system'), (';', ';'), ('MSF', 'MSF'), (':', ':'), ('multiple', 'multiple'), ('species', 'specie'), ('flocking', 'flocking'), (';', ';'), ('GA', 'GA'), (':', ':'), ('genetic', 'genetic'), ('algorithm', 'algorithm'), (';', ';'), ('SOM', 'SOM'), (':', ':'), ('self‑organizing', 'self‑organizing'), ('map', 'map'), (';', ';'), ('MBP', 'MBP'), (':', ':'), ('multiple', 'multiple'), ('back‑propagation', 'back‑propagation'), (';', ';'), ('YCSB', 'YCSB'), (':', ':'), ('yahoo', 'yahoo'), ('cloud', 'cloud'), ('serving', 'serving'), ('benchmark', 'benchmark'), (';', ';'), ('HPC', 'HPC'), (':', ':'), ('high', 'high'), ('performance', 'performance'), ('computing', 'computing'), (';', ';'), ('EEG', 'EEG'), (':', ':'), ('electroencephalography', 'electroencephalography'), ('.', '.')]



========================================== PARAGRAPH 395 ===========================================

Authors’ contributions CWT contributed to the paper review and drafted the first version of the manuscript. CFL contributed to the paper  collection and manuscript organization. HCC and AVV double checked the manuscript and provided several advanced  ideas for this manuscript. All authors read and approved the final manuscript.

------------------- Sentence 1 -------------------

Authors’ contributions CWT contributed to the paper review and drafted the first version of the manuscript.

>> Tokens are: 
 ['Authors', '’', 'contributions', 'CWT', 'contributed', 'paper', 'review', 'drafted', 'first', 'version', 'manuscript', '.']

>> Bigrams are: 
 [('Authors', '’'), ('’', 'contributions'), ('contributions', 'CWT'), ('CWT', 'contributed'), ('contributed', 'paper'), ('paper', 'review'), ('review', 'drafted'), ('drafted', 'first'), ('first', 'version'), ('version', 'manuscript'), ('manuscript', '.')]

>> Trigrams are: 
 [('Authors', '’', 'contributions'), ('’', 'contributions', 'CWT'), ('contributions', 'CWT', 'contributed'), ('CWT', 'contributed', 'paper'), ('contributed', 'paper', 'review'), ('paper', 'review', 'drafted'), ('review', 'drafted', 'first'), ('drafted', 'first', 'version'), ('first', 'version', 'manuscript'), ('version', 'manuscript', '.')]

>> POS Tags are: 
 [('Authors', 'NNS'), ('’', 'VBP'), ('contributions', 'NNS'), ('CWT', 'NNP'), ('contributed', 'VBD'), ('paper', 'NN'), ('review', 'NN'), ('drafted', 'VBD'), ('first', 'JJ'), ('version', 'NN'), ('manuscript', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Authors', 'contributions CWT', 'paper review', 'first version manuscript']

>> Named Entities are: 
 [('ORGANIZATION', 'CWT')] 

>> Stemming using Porter Stemmer: 
 [('Authors', 'author'), ('’', '’'), ('contributions', 'contribut'), ('CWT', 'cwt'), ('contributed', 'contribut'), ('paper', 'paper'), ('review', 'review'), ('drafted', 'draft'), ('first', 'first'), ('version', 'version'), ('manuscript', 'manuscript'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Authors', 'author'), ('’', '’'), ('contributions', 'contribut'), ('CWT', 'cwt'), ('contributed', 'contribut'), ('paper', 'paper'), ('review', 'review'), ('drafted', 'draft'), ('first', 'first'), ('version', 'version'), ('manuscript', 'manuscript'), ('.', '.')]

>> Lemmatization: 
 [('Authors', 'Authors'), ('’', '’'), ('contributions', 'contribution'), ('CWT', 'CWT'), ('contributed', 'contributed'), ('paper', 'paper'), ('review', 'review'), ('drafted', 'drafted'), ('first', 'first'), ('version', 'version'), ('manuscript', 'manuscript'), ('.', '.')]


------------------- Sentence 2 -------------------

CFL contributed to the paper  collection and manuscript organization.

>> Tokens are: 
 ['CFL', 'contributed', 'paper', 'collection', 'manuscript', 'organization', '.']

>> Bigrams are: 
 [('CFL', 'contributed'), ('contributed', 'paper'), ('paper', 'collection'), ('collection', 'manuscript'), ('manuscript', 'organization'), ('organization', '.')]

>> Trigrams are: 
 [('CFL', 'contributed', 'paper'), ('contributed', 'paper', 'collection'), ('paper', 'collection', 'manuscript'), ('collection', 'manuscript', 'organization'), ('manuscript', 'organization', '.')]

>> POS Tags are: 
 [('CFL', 'NNP'), ('contributed', 'VBD'), ('paper', 'NN'), ('collection', 'NN'), ('manuscript', 'NN'), ('organization', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['CFL', 'paper collection manuscript organization']

>> Named Entities are: 
 [('ORGANIZATION', 'CFL')] 

>> Stemming using Porter Stemmer: 
 [('CFL', 'cfl'), ('contributed', 'contribut'), ('paper', 'paper'), ('collection', 'collect'), ('manuscript', 'manuscript'), ('organization', 'organ'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('CFL', 'cfl'), ('contributed', 'contribut'), ('paper', 'paper'), ('collection', 'collect'), ('manuscript', 'manuscript'), ('organization', 'organ'), ('.', '.')]

>> Lemmatization: 
 [('CFL', 'CFL'), ('contributed', 'contributed'), ('paper', 'paper'), ('collection', 'collection'), ('manuscript', 'manuscript'), ('organization', 'organization'), ('.', '.')]


------------------- Sentence 3 -------------------

HCC and AVV double checked the manuscript and provided several advanced  ideas for this manuscript.

>> Tokens are: 
 ['HCC', 'AVV', 'double', 'checked', 'manuscript', 'provided', 'several', 'advanced', 'ideas', 'manuscript', '.']

>> Bigrams are: 
 [('HCC', 'AVV'), ('AVV', 'double'), ('double', 'checked'), ('checked', 'manuscript'), ('manuscript', 'provided'), ('provided', 'several'), ('several', 'advanced'), ('advanced', 'ideas'), ('ideas', 'manuscript'), ('manuscript', '.')]

>> Trigrams are: 
 [('HCC', 'AVV', 'double'), ('AVV', 'double', 'checked'), ('double', 'checked', 'manuscript'), ('checked', 'manuscript', 'provided'), ('manuscript', 'provided', 'several'), ('provided', 'several', 'advanced'), ('several', 'advanced', 'ideas'), ('advanced', 'ideas', 'manuscript'), ('ideas', 'manuscript', '.')]

>> POS Tags are: 
 [('HCC', 'NNP'), ('AVV', 'NNP'), ('double', 'JJ'), ('checked', 'VBD'), ('manuscript', 'NN'), ('provided', 'VBD'), ('several', 'JJ'), ('advanced', 'JJ'), ('ideas', 'NNS'), ('manuscript', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['HCC AVV', 'manuscript', 'several advanced ideas manuscript']

>> Named Entities are: 
 [('ORGANIZATION', 'HCC'), ('ORGANIZATION', 'AVV')] 

>> Stemming using Porter Stemmer: 
 [('HCC', 'hcc'), ('AVV', 'avv'), ('double', 'doubl'), ('checked', 'check'), ('manuscript', 'manuscript'), ('provided', 'provid'), ('several', 'sever'), ('advanced', 'advanc'), ('ideas', 'idea'), ('manuscript', 'manuscript'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('HCC', 'hcc'), ('AVV', 'avv'), ('double', 'doubl'), ('checked', 'check'), ('manuscript', 'manuscript'), ('provided', 'provid'), ('several', 'sever'), ('advanced', 'advanc'), ('ideas', 'idea'), ('manuscript', 'manuscript'), ('.', '.')]

>> Lemmatization: 
 [('HCC', 'HCC'), ('AVV', 'AVV'), ('double', 'double'), ('checked', 'checked'), ('manuscript', 'manuscript'), ('provided', 'provided'), ('several', 'several'), ('advanced', 'advanced'), ('ideas', 'idea'), ('manuscript', 'manuscript'), ('.', '.')]


------------------- Sentence 4 -------------------

All authors read and approved the final manuscript.

>> Tokens are: 
 ['All', 'authors', 'read', 'approved', 'final', 'manuscript', '.']

>> Bigrams are: 
 [('All', 'authors'), ('authors', 'read'), ('read', 'approved'), ('approved', 'final'), ('final', 'manuscript'), ('manuscript', '.')]

>> Trigrams are: 
 [('All', 'authors', 'read'), ('authors', 'read', 'approved'), ('read', 'approved', 'final'), ('approved', 'final', 'manuscript'), ('final', 'manuscript', '.')]

>> POS Tags are: 
 [('All', 'DT'), ('authors', 'NNS'), ('read', 'VBP'), ('approved', 'VBN'), ('final', 'JJ'), ('manuscript', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['All authors', 'final manuscript']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('All', 'all'), ('authors', 'author'), ('read', 'read'), ('approved', 'approv'), ('final', 'final'), ('manuscript', 'manuscript'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('All', 'all'), ('authors', 'author'), ('read', 'read'), ('approved', 'approv'), ('final', 'final'), ('manuscript', 'manuscript'), ('.', '.')]

>> Lemmatization: 
 [('All', 'All'), ('authors', 'author'), ('read', 'read'), ('approved', 'approved'), ('final', 'final'), ('manuscript', 'manuscript'), ('.', '.')]



========================================== PARAGRAPH 396 ===========================================

Page 28 of 32Tsai et al. Journal of Big Data  (2015) 2:21  

------------------- Sentence 1 -------------------

Page 28 of 32Tsai et al.

>> Tokens are: 
 ['Page', '28', '32Tsai', 'et', 'al', '.']

>> Bigrams are: 
 [('Page', '28'), ('28', '32Tsai'), ('32Tsai', 'et'), ('et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('Page', '28', '32Tsai'), ('28', '32Tsai', 'et'), ('32Tsai', 'et', 'al'), ('et', 'al', '.')]

>> POS Tags are: 
 [('Page', 'NN'), ('28', 'CD'), ('32Tsai', 'CD'), ('et', 'NN'), ('al', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Page', 'et al']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Page', 'page'), ('28', '28'), ('32Tsai', '32tsai'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Page', 'page'), ('28', '28'), ('32Tsai', '32tsai'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('Page', 'Page'), ('28', '28'), ('32Tsai', '32Tsai'), ('et', 'et'), ('al', 'al'), ('.', '.')]


------------------- Sentence 2 -------------------

Journal of Big Data  (2015) 2:21

>> Tokens are: 
 ['Journal', 'Big', 'Data', '(', '2015', ')', '2:21']

>> Bigrams are: 
 [('Journal', 'Big'), ('Big', 'Data'), ('Data', '('), ('(', '2015'), ('2015', ')'), (')', '2:21')]

>> Trigrams are: 
 [('Journal', 'Big', 'Data'), ('Big', 'Data', '('), ('Data', '(', '2015'), ('(', '2015', ')'), ('2015', ')', '2:21')]

>> POS Tags are: 
 [('Journal', 'NNP'), ('Big', 'NNP'), ('Data', 'NNP'), ('(', '('), ('2015', 'CD'), (')', ')'), ('2:21', 'CD')]

>> Noun Phrases are: 
 ['Journal Big Data']

>> Named Entities are: 
 [('PERSON', 'Journal')] 

>> Stemming using Porter Stemmer: 
 [('Journal', 'journal'), ('Big', 'big'), ('Data', 'data'), ('(', '('), ('2015', '2015'), (')', ')'), ('2:21', '2:21')]

>> Stemming using Snowball Stemmer: 
 [('Journal', 'journal'), ('Big', 'big'), ('Data', 'data'), ('(', '('), ('2015', '2015'), (')', ')'), ('2:21', '2:21')]

>> Lemmatization: 
 [('Journal', 'Journal'), ('Big', 'Big'), ('Data', 'Data'), ('(', '('), ('2015', '2015'), (')', ')'), ('2:21', '2:21')]



========================================== PARAGRAPH 397 ===========================================

Author details 1 Department of Computer Science and Information Engineering, National Ilan University, Yilan, Taiwan. 2 Institute  of Computer Science and Information Engineering, National Chung Cheng University, Chia‑Yi, Taiwan. 3 Information  Engineering College, Yangzhou University, Yangzhou, Jiangsu, China. 4 School of Information Science and Engineering,  Fujian University of Technology, Fuzhou, Fujian, China. 5 Department of Computer Science, Electrical and Space Engineer‑ ing, Luleå University of Technology, SE‑931 87 Skellefteå, Sweden.  

------------------- Sentence 1 -------------------

Author details 1 Department of Computer Science and Information Engineering, National Ilan University, Yilan, Taiwan.

>> Tokens are: 
 ['Author', 'details', '1', 'Department', 'Computer', 'Science', 'Information', 'Engineering', ',', 'National', 'Ilan', 'University', ',', 'Yilan', ',', 'Taiwan', '.']

>> Bigrams are: 
 [('Author', 'details'), ('details', '1'), ('1', 'Department'), ('Department', 'Computer'), ('Computer', 'Science'), ('Science', 'Information'), ('Information', 'Engineering'), ('Engineering', ','), (',', 'National'), ('National', 'Ilan'), ('Ilan', 'University'), ('University', ','), (',', 'Yilan'), ('Yilan', ','), (',', 'Taiwan'), ('Taiwan', '.')]

>> Trigrams are: 
 [('Author', 'details', '1'), ('details', '1', 'Department'), ('1', 'Department', 'Computer'), ('Department', 'Computer', 'Science'), ('Computer', 'Science', 'Information'), ('Science', 'Information', 'Engineering'), ('Information', 'Engineering', ','), ('Engineering', ',', 'National'), (',', 'National', 'Ilan'), ('National', 'Ilan', 'University'), ('Ilan', 'University', ','), ('University', ',', 'Yilan'), (',', 'Yilan', ','), ('Yilan', ',', 'Taiwan'), (',', 'Taiwan', '.')]

>> POS Tags are: 
 [('Author', 'NN'), ('details', 'NNS'), ('1', 'CD'), ('Department', 'NNP'), ('Computer', 'NNP'), ('Science', 'NNP'), ('Information', 'NNP'), ('Engineering', 'NNP'), (',', ','), ('National', 'NNP'), ('Ilan', 'NNP'), ('University', 'NNP'), (',', ','), ('Yilan', 'NNP'), (',', ','), ('Taiwan', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Author details', 'Department Computer Science Information Engineering', 'National Ilan University', 'Yilan', 'Taiwan']

>> Named Entities are: 
 [('GPE', 'Author'), ('ORGANIZATION', 'National Ilan University'), ('PERSON', 'Yilan'), ('GPE', 'Taiwan')] 

>> Stemming using Porter Stemmer: 
 [('Author', 'author'), ('details', 'detail'), ('1', '1'), ('Department', 'depart'), ('Computer', 'comput'), ('Science', 'scienc'), ('Information', 'inform'), ('Engineering', 'engin'), (',', ','), ('National', 'nation'), ('Ilan', 'ilan'), ('University', 'univers'), (',', ','), ('Yilan', 'yilan'), (',', ','), ('Taiwan', 'taiwan'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Author', 'author'), ('details', 'detail'), ('1', '1'), ('Department', 'depart'), ('Computer', 'comput'), ('Science', 'scienc'), ('Information', 'inform'), ('Engineering', 'engin'), (',', ','), ('National', 'nation'), ('Ilan', 'ilan'), ('University', 'univers'), (',', ','), ('Yilan', 'yilan'), (',', ','), ('Taiwan', 'taiwan'), ('.', '.')]

>> Lemmatization: 
 [('Author', 'Author'), ('details', 'detail'), ('1', '1'), ('Department', 'Department'), ('Computer', 'Computer'), ('Science', 'Science'), ('Information', 'Information'), ('Engineering', 'Engineering'), (',', ','), ('National', 'National'), ('Ilan', 'Ilan'), ('University', 'University'), (',', ','), ('Yilan', 'Yilan'), (',', ','), ('Taiwan', 'Taiwan'), ('.', '.')]


------------------- Sentence 2 -------------------

2 Institute  of Computer Science and Information Engineering, National Chung Cheng University, Chia‑Yi, Taiwan.

>> Tokens are: 
 ['2', 'Institute', 'Computer', 'Science', 'Information', 'Engineering', ',', 'National', 'Chung', 'Cheng', 'University', ',', 'Chia‑Yi', ',', 'Taiwan', '.']

>> Bigrams are: 
 [('2', 'Institute'), ('Institute', 'Computer'), ('Computer', 'Science'), ('Science', 'Information'), ('Information', 'Engineering'), ('Engineering', ','), (',', 'National'), ('National', 'Chung'), ('Chung', 'Cheng'), ('Cheng', 'University'), ('University', ','), (',', 'Chia‑Yi'), ('Chia‑Yi', ','), (',', 'Taiwan'), ('Taiwan', '.')]

>> Trigrams are: 
 [('2', 'Institute', 'Computer'), ('Institute', 'Computer', 'Science'), ('Computer', 'Science', 'Information'), ('Science', 'Information', 'Engineering'), ('Information', 'Engineering', ','), ('Engineering', ',', 'National'), (',', 'National', 'Chung'), ('National', 'Chung', 'Cheng'), ('Chung', 'Cheng', 'University'), ('Cheng', 'University', ','), ('University', ',', 'Chia‑Yi'), (',', 'Chia‑Yi', ','), ('Chia‑Yi', ',', 'Taiwan'), (',', 'Taiwan', '.')]

>> POS Tags are: 
 [('2', 'CD'), ('Institute', 'NNP'), ('Computer', 'NNP'), ('Science', 'NNP'), ('Information', 'NNP'), ('Engineering', 'NNP'), (',', ','), ('National', 'NNP'), ('Chung', 'NNP'), ('Cheng', 'NNP'), ('University', 'NNP'), (',', ','), ('Chia‑Yi', 'NNP'), (',', ','), ('Taiwan', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Institute Computer Science Information Engineering', 'National Chung Cheng University', 'Chia‑Yi', 'Taiwan']

>> Named Entities are: 
 [('ORGANIZATION', 'National Chung Cheng University'), ('GPE', 'Chia‑Yi'), ('GPE', 'Taiwan')] 

>> Stemming using Porter Stemmer: 
 [('2', '2'), ('Institute', 'institut'), ('Computer', 'comput'), ('Science', 'scienc'), ('Information', 'inform'), ('Engineering', 'engin'), (',', ','), ('National', 'nation'), ('Chung', 'chung'), ('Cheng', 'cheng'), ('University', 'univers'), (',', ','), ('Chia‑Yi', 'chia‑yi'), (',', ','), ('Taiwan', 'taiwan'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('2', '2'), ('Institute', 'institut'), ('Computer', 'comput'), ('Science', 'scienc'), ('Information', 'inform'), ('Engineering', 'engin'), (',', ','), ('National', 'nation'), ('Chung', 'chung'), ('Cheng', 'cheng'), ('University', 'univers'), (',', ','), ('Chia‑Yi', 'chia‑yi'), (',', ','), ('Taiwan', 'taiwan'), ('.', '.')]

>> Lemmatization: 
 [('2', '2'), ('Institute', 'Institute'), ('Computer', 'Computer'), ('Science', 'Science'), ('Information', 'Information'), ('Engineering', 'Engineering'), (',', ','), ('National', 'National'), ('Chung', 'Chung'), ('Cheng', 'Cheng'), ('University', 'University'), (',', ','), ('Chia‑Yi', 'Chia‑Yi'), (',', ','), ('Taiwan', 'Taiwan'), ('.', '.')]


------------------- Sentence 3 -------------------

3 Information  Engineering College, Yangzhou University, Yangzhou, Jiangsu, China.

>> Tokens are: 
 ['3', 'Information', 'Engineering', 'College', ',', 'Yangzhou', 'University', ',', 'Yangzhou', ',', 'Jiangsu', ',', 'China', '.']

>> Bigrams are: 
 [('3', 'Information'), ('Information', 'Engineering'), ('Engineering', 'College'), ('College', ','), (',', 'Yangzhou'), ('Yangzhou', 'University'), ('University', ','), (',', 'Yangzhou'), ('Yangzhou', ','), (',', 'Jiangsu'), ('Jiangsu', ','), (',', 'China'), ('China', '.')]

>> Trigrams are: 
 [('3', 'Information', 'Engineering'), ('Information', 'Engineering', 'College'), ('Engineering', 'College', ','), ('College', ',', 'Yangzhou'), (',', 'Yangzhou', 'University'), ('Yangzhou', 'University', ','), ('University', ',', 'Yangzhou'), (',', 'Yangzhou', ','), ('Yangzhou', ',', 'Jiangsu'), (',', 'Jiangsu', ','), ('Jiangsu', ',', 'China'), (',', 'China', '.')]

>> POS Tags are: 
 [('3', 'CD'), ('Information', 'NNP'), ('Engineering', 'NNP'), ('College', 'NNP'), (',', ','), ('Yangzhou', 'NNP'), ('University', 'NNP'), (',', ','), ('Yangzhou', 'NNP'), (',', ','), ('Jiangsu', 'NNP'), (',', ','), ('China', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Information Engineering College', 'Yangzhou University', 'Yangzhou', 'Jiangsu', 'China']

>> Named Entities are: 
 [('ORGANIZATION', 'Yangzhou University'), ('GPE', 'Yangzhou'), ('PERSON', 'Jiangsu'), ('GPE', 'China')] 

>> Stemming using Porter Stemmer: 
 [('3', '3'), ('Information', 'inform'), ('Engineering', 'engin'), ('College', 'colleg'), (',', ','), ('Yangzhou', 'yangzhou'), ('University', 'univers'), (',', ','), ('Yangzhou', 'yangzhou'), (',', ','), ('Jiangsu', 'jiangsu'), (',', ','), ('China', 'china'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('3', '3'), ('Information', 'inform'), ('Engineering', 'engin'), ('College', 'colleg'), (',', ','), ('Yangzhou', 'yangzhou'), ('University', 'univers'), (',', ','), ('Yangzhou', 'yangzhou'), (',', ','), ('Jiangsu', 'jiangsu'), (',', ','), ('China', 'china'), ('.', '.')]

>> Lemmatization: 
 [('3', '3'), ('Information', 'Information'), ('Engineering', 'Engineering'), ('College', 'College'), (',', ','), ('Yangzhou', 'Yangzhou'), ('University', 'University'), (',', ','), ('Yangzhou', 'Yangzhou'), (',', ','), ('Jiangsu', 'Jiangsu'), (',', ','), ('China', 'China'), ('.', '.')]


------------------- Sentence 4 -------------------

4 School of Information Science and Engineering,  Fujian University of Technology, Fuzhou, Fujian, China.

>> Tokens are: 
 ['4', 'School', 'Information', 'Science', 'Engineering', ',', 'Fujian', 'University', 'Technology', ',', 'Fuzhou', ',', 'Fujian', ',', 'China', '.']

>> Bigrams are: 
 [('4', 'School'), ('School', 'Information'), ('Information', 'Science'), ('Science', 'Engineering'), ('Engineering', ','), (',', 'Fujian'), ('Fujian', 'University'), ('University', 'Technology'), ('Technology', ','), (',', 'Fuzhou'), ('Fuzhou', ','), (',', 'Fujian'), ('Fujian', ','), (',', 'China'), ('China', '.')]

>> Trigrams are: 
 [('4', 'School', 'Information'), ('School', 'Information', 'Science'), ('Information', 'Science', 'Engineering'), ('Science', 'Engineering', ','), ('Engineering', ',', 'Fujian'), (',', 'Fujian', 'University'), ('Fujian', 'University', 'Technology'), ('University', 'Technology', ','), ('Technology', ',', 'Fuzhou'), (',', 'Fuzhou', ','), ('Fuzhou', ',', 'Fujian'), (',', 'Fujian', ','), ('Fujian', ',', 'China'), (',', 'China', '.')]

>> POS Tags are: 
 [('4', 'CD'), ('School', 'NNP'), ('Information', 'NNP'), ('Science', 'NNP'), ('Engineering', 'NNP'), (',', ','), ('Fujian', 'NNP'), ('University', 'NNP'), ('Technology', 'NNP'), (',', ','), ('Fuzhou', 'NNP'), (',', ','), ('Fujian', 'NNP'), (',', ','), ('China', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['School Information Science Engineering', 'Fujian University Technology', 'Fuzhou', 'Fujian', 'China']

>> Named Entities are: 
 [('PERSON', 'School Information Science Engineering'), ('PERSON', 'Fujian University Technology'), ('GPE', 'Fuzhou'), ('GPE', 'Fujian'), ('GPE', 'China')] 

>> Stemming using Porter Stemmer: 
 [('4', '4'), ('School', 'school'), ('Information', 'inform'), ('Science', 'scienc'), ('Engineering', 'engin'), (',', ','), ('Fujian', 'fujian'), ('University', 'univers'), ('Technology', 'technolog'), (',', ','), ('Fuzhou', 'fuzhou'), (',', ','), ('Fujian', 'fujian'), (',', ','), ('China', 'china'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('4', '4'), ('School', 'school'), ('Information', 'inform'), ('Science', 'scienc'), ('Engineering', 'engin'), (',', ','), ('Fujian', 'fujian'), ('University', 'univers'), ('Technology', 'technolog'), (',', ','), ('Fuzhou', 'fuzhou'), (',', ','), ('Fujian', 'fujian'), (',', ','), ('China', 'china'), ('.', '.')]

>> Lemmatization: 
 [('4', '4'), ('School', 'School'), ('Information', 'Information'), ('Science', 'Science'), ('Engineering', 'Engineering'), (',', ','), ('Fujian', 'Fujian'), ('University', 'University'), ('Technology', 'Technology'), (',', ','), ('Fuzhou', 'Fuzhou'), (',', ','), ('Fujian', 'Fujian'), (',', ','), ('China', 'China'), ('.', '.')]


------------------- Sentence 5 -------------------

5 Department of Computer Science, Electrical and Space Engineer‑ ing, Luleå University of Technology, SE‑931 87 Skellefteå, Sweden.

>> Tokens are: 
 ['5', 'Department', 'Computer', 'Science', ',', 'Electrical', 'Space', 'Engineer‑', 'ing', ',', 'Luleå', 'University', 'Technology', ',', 'SE‑931', '87', 'Skellefteå', ',', 'Sweden', '.']

>> Bigrams are: 
 [('5', 'Department'), ('Department', 'Computer'), ('Computer', 'Science'), ('Science', ','), (',', 'Electrical'), ('Electrical', 'Space'), ('Space', 'Engineer‑'), ('Engineer‑', 'ing'), ('ing', ','), (',', 'Luleå'), ('Luleå', 'University'), ('University', 'Technology'), ('Technology', ','), (',', 'SE‑931'), ('SE‑931', '87'), ('87', 'Skellefteå'), ('Skellefteå', ','), (',', 'Sweden'), ('Sweden', '.')]

>> Trigrams are: 
 [('5', 'Department', 'Computer'), ('Department', 'Computer', 'Science'), ('Computer', 'Science', ','), ('Science', ',', 'Electrical'), (',', 'Electrical', 'Space'), ('Electrical', 'Space', 'Engineer‑'), ('Space', 'Engineer‑', 'ing'), ('Engineer‑', 'ing', ','), ('ing', ',', 'Luleå'), (',', 'Luleå', 'University'), ('Luleå', 'University', 'Technology'), ('University', 'Technology', ','), ('Technology', ',', 'SE‑931'), (',', 'SE‑931', '87'), ('SE‑931', '87', 'Skellefteå'), ('87', 'Skellefteå', ','), ('Skellefteå', ',', 'Sweden'), (',', 'Sweden', '.')]

>> POS Tags are: 
 [('5', 'CD'), ('Department', 'NNP'), ('Computer', 'NNP'), ('Science', 'NNP'), (',', ','), ('Electrical', 'NNP'), ('Space', 'NNP'), ('Engineer‑', 'NNP'), ('ing', 'NN'), (',', ','), ('Luleå', 'NNP'), ('University', 'NNP'), ('Technology', 'NNP'), (',', ','), ('SE‑931', 'NNP'), ('87', 'CD'), ('Skellefteå', 'NNP'), (',', ','), ('Sweden', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Department Computer Science', 'Electrical Space Engineer‑ ing', 'Luleå University Technology', 'SE‑931', 'Skellefteå', 'Sweden']

>> Named Entities are: 
 [('ORGANIZATION', 'Electrical Space'), ('PERSON', 'Luleå University Technology'), ('GPE', 'Sweden')] 

>> Stemming using Porter Stemmer: 
 [('5', '5'), ('Department', 'depart'), ('Computer', 'comput'), ('Science', 'scienc'), (',', ','), ('Electrical', 'electr'), ('Space', 'space'), ('Engineer‑', 'engineer‑'), ('ing', 'ing'), (',', ','), ('Luleå', 'luleå'), ('University', 'univers'), ('Technology', 'technolog'), (',', ','), ('SE‑931', 'se‑931'), ('87', '87'), ('Skellefteå', 'skellefteå'), (',', ','), ('Sweden', 'sweden'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('5', '5'), ('Department', 'depart'), ('Computer', 'comput'), ('Science', 'scienc'), (',', ','), ('Electrical', 'electr'), ('Space', 'space'), ('Engineer‑', 'engineer‑'), ('ing', 'ing'), (',', ','), ('Luleå', 'luleå'), ('University', 'univers'), ('Technology', 'technolog'), (',', ','), ('SE‑931', 'se‑931'), ('87', '87'), ('Skellefteå', 'skellefteå'), (',', ','), ('Sweden', 'sweden'), ('.', '.')]

>> Lemmatization: 
 [('5', '5'), ('Department', 'Department'), ('Computer', 'Computer'), ('Science', 'Science'), (',', ','), ('Electrical', 'Electrical'), ('Space', 'Space'), ('Engineer‑', 'Engineer‑'), ('ing', 'ing'), (',', ','), ('Luleå', 'Luleå'), ('University', 'University'), ('Technology', 'Technology'), (',', ','), ('SE‑931', 'SE‑931'), ('87', '87'), ('Skellefteå', 'Skellefteå'), (',', ','), ('Sweden', 'Sweden'), ('.', '.')]



========================================== PARAGRAPH 398 ===========================================

Acknowledgements The authors would like to thank the anonymous reviewers for their valuable comments and suggestions on the paper.  This work was supported in part by the Ministry of Science and Technology of Taiwan, R.O.C., under Contracts MOST103‑ 2221‑E‑197‑034, MOST104‑2221‑E‑197‑005, and MOST104‑2221‑E‑197‑014. 

------------------- Sentence 1 -------------------

Acknowledgements The authors would like to thank the anonymous reviewers for their valuable comments and suggestions on the paper.

>> Tokens are: 
 ['Acknowledgements', 'The', 'authors', 'would', 'like', 'thank', 'anonymous', 'reviewers', 'valuable', 'comments', 'suggestions', 'paper', '.']

>> Bigrams are: 
 [('Acknowledgements', 'The'), ('The', 'authors'), ('authors', 'would'), ('would', 'like'), ('like', 'thank'), ('thank', 'anonymous'), ('anonymous', 'reviewers'), ('reviewers', 'valuable'), ('valuable', 'comments'), ('comments', 'suggestions'), ('suggestions', 'paper'), ('paper', '.')]

>> Trigrams are: 
 [('Acknowledgements', 'The', 'authors'), ('The', 'authors', 'would'), ('authors', 'would', 'like'), ('would', 'like', 'thank'), ('like', 'thank', 'anonymous'), ('thank', 'anonymous', 'reviewers'), ('anonymous', 'reviewers', 'valuable'), ('reviewers', 'valuable', 'comments'), ('valuable', 'comments', 'suggestions'), ('comments', 'suggestions', 'paper'), ('suggestions', 'paper', '.')]

>> POS Tags are: 
 [('Acknowledgements', 'NNS'), ('The', 'DT'), ('authors', 'NNS'), ('would', 'MD'), ('like', 'VB'), ('thank', 'NN'), ('anonymous', 'JJ'), ('reviewers', 'NNS'), ('valuable', 'JJ'), ('comments', 'NNS'), ('suggestions', 'NNS'), ('paper', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Acknowledgements', 'The authors', 'thank', 'anonymous reviewers', 'valuable comments suggestions paper']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Acknowledgements', 'acknowledg'), ('The', 'the'), ('authors', 'author'), ('would', 'would'), ('like', 'like'), ('thank', 'thank'), ('anonymous', 'anonym'), ('reviewers', 'review'), ('valuable', 'valuabl'), ('comments', 'comment'), ('suggestions', 'suggest'), ('paper', 'paper'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Acknowledgements', 'acknowledg'), ('The', 'the'), ('authors', 'author'), ('would', 'would'), ('like', 'like'), ('thank', 'thank'), ('anonymous', 'anonym'), ('reviewers', 'review'), ('valuable', 'valuabl'), ('comments', 'comment'), ('suggestions', 'suggest'), ('paper', 'paper'), ('.', '.')]

>> Lemmatization: 
 [('Acknowledgements', 'Acknowledgements'), ('The', 'The'), ('authors', 'author'), ('would', 'would'), ('like', 'like'), ('thank', 'thank'), ('anonymous', 'anonymous'), ('reviewers', 'reviewer'), ('valuable', 'valuable'), ('comments', 'comment'), ('suggestions', 'suggestion'), ('paper', 'paper'), ('.', '.')]


------------------- Sentence 2 -------------------

This work was supported in part by the Ministry of Science and Technology of Taiwan, R.O.C., under Contracts MOST103‑ 2221‑E‑197‑034, MOST104‑2221‑E‑197‑005, and MOST104‑2221‑E‑197‑014.

>> Tokens are: 
 ['This', 'work', 'supported', 'part', 'Ministry', 'Science', 'Technology', 'Taiwan', ',', 'R.O.C.', ',', 'Contracts', 'MOST103‑', '2221‑E‑197‑034', ',', 'MOST104‑2221‑E‑197‑005', ',', 'MOST104‑2221‑E‑197‑014', '.']

>> Bigrams are: 
 [('This', 'work'), ('work', 'supported'), ('supported', 'part'), ('part', 'Ministry'), ('Ministry', 'Science'), ('Science', 'Technology'), ('Technology', 'Taiwan'), ('Taiwan', ','), (',', 'R.O.C.'), ('R.O.C.', ','), (',', 'Contracts'), ('Contracts', 'MOST103‑'), ('MOST103‑', '2221‑E‑197‑034'), ('2221‑E‑197‑034', ','), (',', 'MOST104‑2221‑E‑197‑005'), ('MOST104‑2221‑E‑197‑005', ','), (',', 'MOST104‑2221‑E‑197‑014'), ('MOST104‑2221‑E‑197‑014', '.')]

>> Trigrams are: 
 [('This', 'work', 'supported'), ('work', 'supported', 'part'), ('supported', 'part', 'Ministry'), ('part', 'Ministry', 'Science'), ('Ministry', 'Science', 'Technology'), ('Science', 'Technology', 'Taiwan'), ('Technology', 'Taiwan', ','), ('Taiwan', ',', 'R.O.C.'), (',', 'R.O.C.', ','), ('R.O.C.', ',', 'Contracts'), (',', 'Contracts', 'MOST103‑'), ('Contracts', 'MOST103‑', '2221‑E‑197‑034'), ('MOST103‑', '2221‑E‑197‑034', ','), ('2221‑E‑197‑034', ',', 'MOST104‑2221‑E‑197‑005'), (',', 'MOST104‑2221‑E‑197‑005', ','), ('MOST104‑2221‑E‑197‑005', ',', 'MOST104‑2221‑E‑197‑014'), (',', 'MOST104‑2221‑E‑197‑014', '.')]

>> POS Tags are: 
 [('This', 'DT'), ('work', 'NN'), ('supported', 'VBD'), ('part', 'NN'), ('Ministry', 'NNP'), ('Science', 'NNP'), ('Technology', 'NNP'), ('Taiwan', 'NNP'), (',', ','), ('R.O.C.', 'NNP'), (',', ','), ('Contracts', 'NNP'), ('MOST103‑', 'NNP'), ('2221‑E‑197‑034', 'CD'), (',', ','), ('MOST104‑2221‑E‑197‑005', 'NNP'), (',', ','), ('MOST104‑2221‑E‑197‑014', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['This work', 'part Ministry Science Technology Taiwan', 'R.O.C.', 'Contracts MOST103‑', 'MOST104‑2221‑E‑197‑005', 'MOST104‑2221‑E‑197‑014']

>> Named Entities are: 
 [('ORGANIZATION', 'Ministry Science Technology Taiwan'), ('GPE', 'R.O.C.'), ('ORGANIZATION', 'Contracts')] 

>> Stemming using Porter Stemmer: 
 [('This', 'thi'), ('work', 'work'), ('supported', 'support'), ('part', 'part'), ('Ministry', 'ministri'), ('Science', 'scienc'), ('Technology', 'technolog'), ('Taiwan', 'taiwan'), (',', ','), ('R.O.C.', 'r.o.c.'), (',', ','), ('Contracts', 'contract'), ('MOST103‑', 'most103‑'), ('2221‑E‑197‑034', '2221‑e‑197‑034'), (',', ','), ('MOST104‑2221‑E‑197‑005', 'most104‑2221‑e‑197‑005'), (',', ','), ('MOST104‑2221‑E‑197‑014', 'most104‑2221‑e‑197‑014'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('This', 'this'), ('work', 'work'), ('supported', 'support'), ('part', 'part'), ('Ministry', 'ministri'), ('Science', 'scienc'), ('Technology', 'technolog'), ('Taiwan', 'taiwan'), (',', ','), ('R.O.C.', 'r.o.c.'), (',', ','), ('Contracts', 'contract'), ('MOST103‑', 'most103‑'), ('2221‑E‑197‑034', '2221‑e‑197‑034'), (',', ','), ('MOST104‑2221‑E‑197‑005', 'most104‑2221‑e‑197‑005'), (',', ','), ('MOST104‑2221‑E‑197‑014', 'most104‑2221‑e‑197‑014'), ('.', '.')]

>> Lemmatization: 
 [('This', 'This'), ('work', 'work'), ('supported', 'supported'), ('part', 'part'), ('Ministry', 'Ministry'), ('Science', 'Science'), ('Technology', 'Technology'), ('Taiwan', 'Taiwan'), (',', ','), ('R.O.C.', 'R.O.C.'), (',', ','), ('Contracts', 'Contracts'), ('MOST103‑', 'MOST103‑'), ('2221‑E‑197‑034', '2221‑E‑197‑034'), (',', ','), ('MOST104‑2221‑E‑197‑005', 'MOST104‑2221‑E‑197‑005'), (',', ','), ('MOST104‑2221‑E‑197‑014', 'MOST104‑2221‑E‑197‑014'), ('.', '.')]



========================================== PARAGRAPH 399 ===========================================

Compliance with ethical guidelines 

------------------- Sentence 1 -------------------

Compliance with ethical guidelines

>> Tokens are: 
 ['Compliance', 'ethical', 'guidelines']

>> Bigrams are: 
 [('Compliance', 'ethical'), ('ethical', 'guidelines')]

>> Trigrams are: 
 [('Compliance', 'ethical', 'guidelines')]

>> POS Tags are: 
 [('Compliance', 'NNP'), ('ethical', 'JJ'), ('guidelines', 'NNS')]

>> Noun Phrases are: 
 ['Compliance', 'ethical guidelines']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Compliance', 'complianc'), ('ethical', 'ethic'), ('guidelines', 'guidelin')]

>> Stemming using Snowball Stemmer: 
 [('Compliance', 'complianc'), ('ethical', 'ethic'), ('guidelines', 'guidelin')]

>> Lemmatization: 
 [('Compliance', 'Compliance'), ('ethical', 'ethical'), ('guidelines', 'guideline')]



========================================== PARAGRAPH 400 ===========================================

Competing interests The authors declare that they have no competing interests. 

------------------- Sentence 1 -------------------

Competing interests The authors declare that they have no competing interests.

>> Tokens are: 
 ['Competing', 'interests', 'The', 'authors', 'declare', 'competing', 'interests', '.']

>> Bigrams are: 
 [('Competing', 'interests'), ('interests', 'The'), ('The', 'authors'), ('authors', 'declare'), ('declare', 'competing'), ('competing', 'interests'), ('interests', '.')]

>> Trigrams are: 
 [('Competing', 'interests', 'The'), ('interests', 'The', 'authors'), ('The', 'authors', 'declare'), ('authors', 'declare', 'competing'), ('declare', 'competing', 'interests'), ('competing', 'interests', '.')]

>> POS Tags are: 
 [('Competing', 'VBG'), ('interests', 'NNS'), ('The', 'DT'), ('authors', 'NNS'), ('declare', 'VBP'), ('competing', 'VBG'), ('interests', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['interests', 'The authors', 'interests']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Competing', 'compet'), ('interests', 'interest'), ('The', 'the'), ('authors', 'author'), ('declare', 'declar'), ('competing', 'compet'), ('interests', 'interest'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Competing', 'compet'), ('interests', 'interest'), ('The', 'the'), ('authors', 'author'), ('declare', 'declar'), ('competing', 'compet'), ('interests', 'interest'), ('.', '.')]

>> Lemmatization: 
 [('Competing', 'Competing'), ('interests', 'interest'), ('The', 'The'), ('authors', 'author'), ('declare', 'declare'), ('competing', 'competing'), ('interests', 'interest'), ('.', '.')]



========================================== PARAGRAPH 401 ===========================================

Received: 14 May 2015   Accepted: 2 September 2015 

------------------- Sentence 1 -------------------

Received: 14 May 2015   Accepted: 2 September 2015

>> Tokens are: 
 ['Received', ':', '14', 'May', '2015', 'Accepted', ':', '2', 'September', '2015']

>> Bigrams are: 
 [('Received', ':'), (':', '14'), ('14', 'May'), ('May', '2015'), ('2015', 'Accepted'), ('Accepted', ':'), (':', '2'), ('2', 'September'), ('September', '2015')]

>> Trigrams are: 
 [('Received', ':', '14'), (':', '14', 'May'), ('14', 'May', '2015'), ('May', '2015', 'Accepted'), ('2015', 'Accepted', ':'), ('Accepted', ':', '2'), (':', '2', 'September'), ('2', 'September', '2015')]

>> POS Tags are: 
 [('Received', 'VBN'), (':', ':'), ('14', 'CD'), ('May', 'NNP'), ('2015', 'CD'), ('Accepted', 'VBD'), (':', ':'), ('2', 'CD'), ('September', 'NNP'), ('2015', 'CD')]

>> Noun Phrases are: 
 ['May', 'September']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Received', 'receiv'), (':', ':'), ('14', '14'), ('May', 'may'), ('2015', '2015'), ('Accepted', 'accept'), (':', ':'), ('2', '2'), ('September', 'septemb'), ('2015', '2015')]

>> Stemming using Snowball Stemmer: 
 [('Received', 'receiv'), (':', ':'), ('14', '14'), ('May', 'may'), ('2015', '2015'), ('Accepted', 'accept'), (':', ':'), ('2', '2'), ('September', 'septemb'), ('2015', '2015')]

>> Lemmatization: 
 [('Received', 'Received'), (':', ':'), ('14', '14'), ('May', 'May'), ('2015', '2015'), ('Accepted', 'Accepted'), (':', ':'), ('2', '2'), ('September', 'September'), ('2015', '2015')]



========================================== PARAGRAPH 402 ===========================================

References  1. Lyman P, Varian H. How much information 2003? Tech. Rep, 2004. [Online]. Available: http://www2.sims.berkeley. 

------------------- Sentence 1 -------------------

References  1.

>> Tokens are: 
 ['References', '1', '.']

>> Bigrams are: 
 [('References', '1'), ('1', '.')]

>> Trigrams are: 
 [('References', '1', '.')]

>> POS Tags are: 
 [('References', 'NNS'), ('1', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['References']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('References', 'refer'), ('1', '1'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('References', 'refer'), ('1', '1'), ('.', '.')]

>> Lemmatization: 
 [('References', 'References'), ('1', '1'), ('.', '.')]


------------------- Sentence 2 -------------------

Lyman P, Varian H. How much information 2003?

>> Tokens are: 
 ['Lyman', 'P', ',', 'Varian', 'H.', 'How', 'much', 'information', '2003', '?']

>> Bigrams are: 
 [('Lyman', 'P'), ('P', ','), (',', 'Varian'), ('Varian', 'H.'), ('H.', 'How'), ('How', 'much'), ('much', 'information'), ('information', '2003'), ('2003', '?')]

>> Trigrams are: 
 [('Lyman', 'P', ','), ('P', ',', 'Varian'), (',', 'Varian', 'H.'), ('Varian', 'H.', 'How'), ('H.', 'How', 'much'), ('How', 'much', 'information'), ('much', 'information', '2003'), ('information', '2003', '?')]

>> POS Tags are: 
 [('Lyman', 'NNP'), ('P', 'NNP'), (',', ','), ('Varian', 'NNP'), ('H.', 'NNP'), ('How', 'NNP'), ('much', 'JJ'), ('information', 'NN'), ('2003', 'CD'), ('?', '.')]

>> Noun Phrases are: 
 ['Lyman P', 'Varian H. How', 'much information']

>> Named Entities are: 
 [('PERSON', 'Lyman'), ('ORGANIZATION', 'P'), ('PERSON', 'Varian H. How')] 

>> Stemming using Porter Stemmer: 
 [('Lyman', 'lyman'), ('P', 'p'), (',', ','), ('Varian', 'varian'), ('H.', 'h.'), ('How', 'how'), ('much', 'much'), ('information', 'inform'), ('2003', '2003'), ('?', '?')]

>> Stemming using Snowball Stemmer: 
 [('Lyman', 'lyman'), ('P', 'p'), (',', ','), ('Varian', 'varian'), ('H.', 'h.'), ('How', 'how'), ('much', 'much'), ('information', 'inform'), ('2003', '2003'), ('?', '?')]

>> Lemmatization: 
 [('Lyman', 'Lyman'), ('P', 'P'), (',', ','), ('Varian', 'Varian'), ('H.', 'H.'), ('How', 'How'), ('much', 'much'), ('information', 'information'), ('2003', '2003'), ('?', '?')]


------------------- Sentence 3 -------------------

Tech.

>> Tokens are: 
 ['Tech', '.']

>> Bigrams are: 
 [('Tech', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Tech', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Tech']

>> Named Entities are: 
 [('GPE', 'Tech')] 

>> Stemming using Porter Stemmer: 
 [('Tech', 'tech'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Tech', 'tech'), ('.', '.')]

>> Lemmatization: 
 [('Tech', 'Tech'), ('.', '.')]


------------------- Sentence 4 -------------------

Rep, 2004.

>> Tokens are: 
 ['Rep', ',', '2004', '.']

>> Bigrams are: 
 [('Rep', ','), (',', '2004'), ('2004', '.')]

>> Trigrams are: 
 [('Rep', ',', '2004'), (',', '2004', '.')]

>> POS Tags are: 
 [('Rep', 'NNP'), (',', ','), ('2004', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Rep']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Rep', 'rep'), (',', ','), ('2004', '2004'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Rep', 'rep'), (',', ','), ('2004', '2004'), ('.', '.')]

>> Lemmatization: 
 [('Rep', 'Rep'), (',', ','), ('2004', '2004'), ('.', '.')]


------------------- Sentence 5 -------------------

[Online].

>> Tokens are: 
 ['[', 'Online', ']', '.']

>> Bigrams are: 
 [('[', 'Online'), ('Online', ']'), (']', '.')]

>> Trigrams are: 
 [('[', 'Online', ']'), ('Online', ']', '.')]

>> POS Tags are: 
 [('[', 'JJ'), ('Online', 'NNP'), (']', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['[ Online ]']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('Online', 'onlin'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('Online', 'onlin'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('Online', 'Online'), (']', ']'), ('.', '.')]


------------------- Sentence 6 -------------------

Available: http://www2.sims.berkeley.

>> Tokens are: 
 ['Available', ':', 'http', ':', '//www2.sims.berkeley', '.']

>> Bigrams are: 
 [('Available', ':'), (':', 'http'), ('http', ':'), (':', '//www2.sims.berkeley'), ('//www2.sims.berkeley', '.')]

>> Trigrams are: 
 [('Available', ':', 'http'), (':', 'http', ':'), ('http', ':', '//www2.sims.berkeley'), (':', '//www2.sims.berkeley', '.')]

>> POS Tags are: 
 [('Available', 'JJ'), (':', ':'), ('http', 'NN'), (':', ':'), ('//www2.sims.berkeley', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['http', '//www2.sims.berkeley']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Available', 'avail'), (':', ':'), ('http', 'http'), (':', ':'), ('//www2.sims.berkeley', '//www2.sims.berkeley'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Available', 'avail'), (':', ':'), ('http', 'http'), (':', ':'), ('//www2.sims.berkeley', '//www2.sims.berkeley'), ('.', '.')]

>> Lemmatization: 
 [('Available', 'Available'), (':', ':'), ('http', 'http'), (':', ':'), ('//www2.sims.berkeley', '//www2.sims.berkeley'), ('.', '.')]



========================================== PARAGRAPH 403 ===========================================

edu/research/projects/how‑much‑info‑2003/printable_report.pdf.  2. Xu R, Wunsch D. Clustering. Hoboken: Wiley‑IEEE Press; 2009.  3. Ding C, He X. K‑means clustering via principal component analysis. In: Proceedings of the Twenty‑first Interna‑ 

------------------- Sentence 1 -------------------

edu/research/projects/how‑much‑info‑2003/printable_report.pdf.

>> Tokens are: 
 ['edu/research/projects/how‑much‑info‑2003/printable_report.pdf', '.']

>> Bigrams are: 
 [('edu/research/projects/how‑much‑info‑2003/printable_report.pdf', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('edu/research/projects/how‑much‑info‑2003/printable_report.pdf', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['edu/research/projects/how‑much‑info‑2003/printable_report.pdf']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('edu/research/projects/how‑much‑info‑2003/printable_report.pdf', 'edu/research/projects/how‑much‑info‑2003/printable_report.pdf'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('edu/research/projects/how‑much‑info‑2003/printable_report.pdf', 'edu/research/projects/how‑much‑info‑2003/printable_report.pdf'), ('.', '.')]

>> Lemmatization: 
 [('edu/research/projects/how‑much‑info‑2003/printable_report.pdf', 'edu/research/projects/how‑much‑info‑2003/printable_report.pdf'), ('.', '.')]


------------------- Sentence 2 -------------------

2.

>> Tokens are: 
 ['2', '.']

>> Bigrams are: 
 [('2', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('2', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('2', '2'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('2', '2'), ('.', '.')]

>> Lemmatization: 
 [('2', '2'), ('.', '.')]


------------------- Sentence 3 -------------------

Xu R, Wunsch D. Clustering.

>> Tokens are: 
 ['Xu', 'R', ',', 'Wunsch', 'D.', 'Clustering', '.']

>> Bigrams are: 
 [('Xu', 'R'), ('R', ','), (',', 'Wunsch'), ('Wunsch', 'D.'), ('D.', 'Clustering'), ('Clustering', '.')]

>> Trigrams are: 
 [('Xu', 'R', ','), ('R', ',', 'Wunsch'), (',', 'Wunsch', 'D.'), ('Wunsch', 'D.', 'Clustering'), ('D.', 'Clustering', '.')]

>> POS Tags are: 
 [('Xu', 'NN'), ('R', 'NNP'), (',', ','), ('Wunsch', 'NNP'), ('D.', 'NNP'), ('Clustering', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Xu R', 'Wunsch D. Clustering']

>> Named Entities are: 
 [('PERSON', 'Wunsch D. Clustering')] 

>> Stemming using Porter Stemmer: 
 [('Xu', 'xu'), ('R', 'r'), (',', ','), ('Wunsch', 'wunsch'), ('D.', 'd.'), ('Clustering', 'cluster'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Xu', 'xu'), ('R', 'r'), (',', ','), ('Wunsch', 'wunsch'), ('D.', 'd.'), ('Clustering', 'cluster'), ('.', '.')]

>> Lemmatization: 
 [('Xu', 'Xu'), ('R', 'R'), (',', ','), ('Wunsch', 'Wunsch'), ('D.', 'D.'), ('Clustering', 'Clustering'), ('.', '.')]


------------------- Sentence 4 -------------------

Hoboken: Wiley‑IEEE Press; 2009.

>> Tokens are: 
 ['Hoboken', ':', 'Wiley‑IEEE', 'Press', ';', '2009', '.']

>> Bigrams are: 
 [('Hoboken', ':'), (':', 'Wiley‑IEEE'), ('Wiley‑IEEE', 'Press'), ('Press', ';'), (';', '2009'), ('2009', '.')]

>> Trigrams are: 
 [('Hoboken', ':', 'Wiley‑IEEE'), (':', 'Wiley‑IEEE', 'Press'), ('Wiley‑IEEE', 'Press', ';'), ('Press', ';', '2009'), (';', '2009', '.')]

>> POS Tags are: 
 [('Hoboken', 'VBN'), (':', ':'), ('Wiley‑IEEE', 'JJ'), ('Press', 'NNP'), (';', ':'), ('2009', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Wiley‑IEEE Press']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Hoboken', 'hoboken'), (':', ':'), ('Wiley‑IEEE', 'wiley‑iee'), ('Press', 'press'), (';', ';'), ('2009', '2009'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Hoboken', 'hoboken'), (':', ':'), ('Wiley‑IEEE', 'wiley‑iee'), ('Press', 'press'), (';', ';'), ('2009', '2009'), ('.', '.')]

>> Lemmatization: 
 [('Hoboken', 'Hoboken'), (':', ':'), ('Wiley‑IEEE', 'Wiley‑IEEE'), ('Press', 'Press'), (';', ';'), ('2009', '2009'), ('.', '.')]


------------------- Sentence 5 -------------------

3.

>> Tokens are: 
 ['3', '.']

>> Bigrams are: 
 [('3', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('3', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('3', '3'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('3', '3'), ('.', '.')]

>> Lemmatization: 
 [('3', '3'), ('.', '.')]


------------------- Sentence 6 -------------------

Ding C, He X. K‑means clustering via principal component analysis.

>> Tokens are: 
 ['Ding', 'C', ',', 'He', 'X.', 'K‑means', 'clustering', 'via', 'principal', 'component', 'analysis', '.']

>> Bigrams are: 
 [('Ding', 'C'), ('C', ','), (',', 'He'), ('He', 'X.'), ('X.', 'K‑means'), ('K‑means', 'clustering'), ('clustering', 'via'), ('via', 'principal'), ('principal', 'component'), ('component', 'analysis'), ('analysis', '.')]

>> Trigrams are: 
 [('Ding', 'C', ','), ('C', ',', 'He'), (',', 'He', 'X.'), ('He', 'X.', 'K‑means'), ('X.', 'K‑means', 'clustering'), ('K‑means', 'clustering', 'via'), ('clustering', 'via', 'principal'), ('via', 'principal', 'component'), ('principal', 'component', 'analysis'), ('component', 'analysis', '.')]

>> POS Tags are: 
 [('Ding', 'VBG'), ('C', 'NNP'), (',', ','), ('He', 'PRP'), ('X.', 'VBD'), ('K‑means', 'NNP'), ('clustering', 'VBG'), ('via', 'IN'), ('principal', 'JJ'), ('component', 'JJ'), ('analysis', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['C', 'K‑means', 'principal component analysis']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Ding', 'ding'), ('C', 'c'), (',', ','), ('He', 'he'), ('X.', 'x.'), ('K‑means', 'k‑mean'), ('clustering', 'cluster'), ('via', 'via'), ('principal', 'princip'), ('component', 'compon'), ('analysis', 'analysi'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Ding', 'ding'), ('C', 'c'), (',', ','), ('He', 'he'), ('X.', 'x.'), ('K‑means', 'k‑mean'), ('clustering', 'cluster'), ('via', 'via'), ('principal', 'princip'), ('component', 'compon'), ('analysis', 'analysi'), ('.', '.')]

>> Lemmatization: 
 [('Ding', 'Ding'), ('C', 'C'), (',', ','), ('He', 'He'), ('X.', 'X.'), ('K‑means', 'K‑means'), ('clustering', 'clustering'), ('via', 'via'), ('principal', 'principal'), ('component', 'component'), ('analysis', 'analysis'), ('.', '.')]


------------------- Sentence 7 -------------------

In: Proceedings of the Twenty‑first Interna‑

>> Tokens are: 
 ['In', ':', 'Proceedings', 'Twenty‑first', 'Interna‑']

>> Bigrams are: 
 [('In', ':'), (':', 'Proceedings'), ('Proceedings', 'Twenty‑first'), ('Twenty‑first', 'Interna‑')]

>> Trigrams are: 
 [('In', ':', 'Proceedings'), (':', 'Proceedings', 'Twenty‑first'), ('Proceedings', 'Twenty‑first', 'Interna‑')]

>> POS Tags are: 
 [('In', 'IN'), (':', ':'), ('Proceedings', 'NNS'), ('Twenty‑first', 'NNP'), ('Interna‑', 'NNP')]

>> Noun Phrases are: 
 ['Proceedings Twenty‑first Interna‑']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), (':', ':'), ('Proceedings', 'proceed'), ('Twenty‑first', 'twenty‑first'), ('Interna‑', 'interna‑')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), (':', ':'), ('Proceedings', 'proceed'), ('Twenty‑first', 'twenty‑first'), ('Interna‑', 'interna‑')]

>> Lemmatization: 
 [('In', 'In'), (':', ':'), ('Proceedings', 'Proceedings'), ('Twenty‑first', 'Twenty‑first'), ('Interna‑', 'Interna‑')]



========================================== PARAGRAPH 404 ===========================================

tional Conference on Machine Learning, 2004, pp 1–9.  4. Kollios G, Gunopulos D, Koudas N, Berchtold S. Efficient biased sampling for approximate clustering and outlier  

------------------- Sentence 1 -------------------

tional Conference on Machine Learning, 2004, pp 1–9.

>> Tokens are: 
 ['tional', 'Conference', 'Machine', 'Learning', ',', '2004', ',', 'pp', '1–9', '.']

>> Bigrams are: 
 [('tional', 'Conference'), ('Conference', 'Machine'), ('Machine', 'Learning'), ('Learning', ','), (',', '2004'), ('2004', ','), (',', 'pp'), ('pp', '1–9'), ('1–9', '.')]

>> Trigrams are: 
 [('tional', 'Conference', 'Machine'), ('Conference', 'Machine', 'Learning'), ('Machine', 'Learning', ','), ('Learning', ',', '2004'), (',', '2004', ','), ('2004', ',', 'pp'), (',', 'pp', '1–9'), ('pp', '1–9', '.')]

>> POS Tags are: 
 [('tional', 'JJ'), ('Conference', 'NNP'), ('Machine', 'NNP'), ('Learning', 'NNP'), (',', ','), ('2004', 'CD'), (',', ','), ('pp', 'VBD'), ('1–9', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['tional Conference Machine Learning']

>> Named Entities are: 
 [('ORGANIZATION', 'Conference Machine Learning')] 

>> Stemming using Porter Stemmer: 
 [('tional', 'tional'), ('Conference', 'confer'), ('Machine', 'machin'), ('Learning', 'learn'), (',', ','), ('2004', '2004'), (',', ','), ('pp', 'pp'), ('1–9', '1–9'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('tional', 'tional'), ('Conference', 'confer'), ('Machine', 'machin'), ('Learning', 'learn'), (',', ','), ('2004', '2004'), (',', ','), ('pp', 'pp'), ('1–9', '1–9'), ('.', '.')]

>> Lemmatization: 
 [('tional', 'tional'), ('Conference', 'Conference'), ('Machine', 'Machine'), ('Learning', 'Learning'), (',', ','), ('2004', '2004'), (',', ','), ('pp', 'pp'), ('1–9', '1–9'), ('.', '.')]


------------------- Sentence 2 -------------------

4.

>> Tokens are: 
 ['4', '.']

>> Bigrams are: 
 [('4', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('4', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('4', '4'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('4', '4'), ('.', '.')]

>> Lemmatization: 
 [('4', '4'), ('.', '.')]


------------------- Sentence 3 -------------------

Kollios G, Gunopulos D, Koudas N, Berchtold S. Efficient biased sampling for approximate clustering and outlier

>> Tokens are: 
 ['Kollios', 'G', ',', 'Gunopulos', 'D', ',', 'Koudas', 'N', ',', 'Berchtold', 'S.', 'Efficient', 'biased', 'sampling', 'approximate', 'clustering', 'outlier']

>> Bigrams are: 
 [('Kollios', 'G'), ('G', ','), (',', 'Gunopulos'), ('Gunopulos', 'D'), ('D', ','), (',', 'Koudas'), ('Koudas', 'N'), ('N', ','), (',', 'Berchtold'), ('Berchtold', 'S.'), ('S.', 'Efficient'), ('Efficient', 'biased'), ('biased', 'sampling'), ('sampling', 'approximate'), ('approximate', 'clustering'), ('clustering', 'outlier')]

>> Trigrams are: 
 [('Kollios', 'G', ','), ('G', ',', 'Gunopulos'), (',', 'Gunopulos', 'D'), ('Gunopulos', 'D', ','), ('D', ',', 'Koudas'), (',', 'Koudas', 'N'), ('Koudas', 'N', ','), ('N', ',', 'Berchtold'), (',', 'Berchtold', 'S.'), ('Berchtold', 'S.', 'Efficient'), ('S.', 'Efficient', 'biased'), ('Efficient', 'biased', 'sampling'), ('biased', 'sampling', 'approximate'), ('sampling', 'approximate', 'clustering'), ('approximate', 'clustering', 'outlier')]

>> POS Tags are: 
 [('Kollios', 'NNP'), ('G', 'NNP'), (',', ','), ('Gunopulos', 'NNP'), ('D', 'NNP'), (',', ','), ('Koudas', 'NNP'), ('N', 'NNP'), (',', ','), ('Berchtold', 'NNP'), ('S.', 'NNP'), ('Efficient', 'NNP'), ('biased', 'VBD'), ('sampling', 'VBG'), ('approximate', 'JJ'), ('clustering', 'NN'), ('outlier', 'NN')]

>> Noun Phrases are: 
 ['Kollios G', 'Gunopulos D', 'Koudas N', 'Berchtold S. Efficient', 'approximate clustering outlier']

>> Named Entities are: 
 [('PERSON', 'Kollios'), ('ORGANIZATION', 'G'), ('PERSON', 'Gunopulos D'), ('PERSON', 'Koudas N'), ('PERSON', 'Berchtold S. Efficient')] 

>> Stemming using Porter Stemmer: 
 [('Kollios', 'kollio'), ('G', 'g'), (',', ','), ('Gunopulos', 'gunopulo'), ('D', 'd'), (',', ','), ('Koudas', 'kouda'), ('N', 'n'), (',', ','), ('Berchtold', 'berchtold'), ('S.', 's.'), ('Efficient', 'effici'), ('biased', 'bias'), ('sampling', 'sampl'), ('approximate', 'approxim'), ('clustering', 'cluster'), ('outlier', 'outlier')]

>> Stemming using Snowball Stemmer: 
 [('Kollios', 'kollio'), ('G', 'g'), (',', ','), ('Gunopulos', 'gunopulo'), ('D', 'd'), (',', ','), ('Koudas', 'kouda'), ('N', 'n'), (',', ','), ('Berchtold', 'berchtold'), ('S.', 's.'), ('Efficient', 'effici'), ('biased', 'bias'), ('sampling', 'sampl'), ('approximate', 'approxim'), ('clustering', 'cluster'), ('outlier', 'outlier')]

>> Lemmatization: 
 [('Kollios', 'Kollios'), ('G', 'G'), (',', ','), ('Gunopulos', 'Gunopulos'), ('D', 'D'), (',', ','), ('Koudas', 'Koudas'), ('N', 'N'), (',', ','), ('Berchtold', 'Berchtold'), ('S.', 'S.'), ('Efficient', 'Efficient'), ('biased', 'biased'), ('sampling', 'sampling'), ('approximate', 'approximate'), ('clustering', 'clustering'), ('outlier', 'outlier')]



========================================== PARAGRAPH 405 ===========================================

detection in large data sets. IEEE Trans Knowl Data Eng. 2003;15(5):1170–87.  5. Fisher D, DeLine R, Czerwinski M, Drucker S. Interactions with big data analytics. Interactions. 2012;19(3):50–9.  6. Laney D. 3D data management: controlling data volume, velocity, and variety, META Group, Tech. Rep. 2001.  

------------------- Sentence 1 -------------------

detection in large data sets.

>> Tokens are: 
 ['detection', 'large', 'data', 'sets', '.']

>> Bigrams are: 
 [('detection', 'large'), ('large', 'data'), ('data', 'sets'), ('sets', '.')]

>> Trigrams are: 
 [('detection', 'large', 'data'), ('large', 'data', 'sets'), ('data', 'sets', '.')]

>> POS Tags are: 
 [('detection', 'NN'), ('large', 'JJ'), ('data', 'NNS'), ('sets', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['detection', 'large data sets']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('detection', 'detect'), ('large', 'larg'), ('data', 'data'), ('sets', 'set'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('detection', 'detect'), ('large', 'larg'), ('data', 'data'), ('sets', 'set'), ('.', '.')]

>> Lemmatization: 
 [('detection', 'detection'), ('large', 'large'), ('data', 'data'), ('sets', 'set'), ('.', '.')]


------------------- Sentence 2 -------------------

IEEE Trans Knowl Data Eng.

>> Tokens are: 
 ['IEEE', 'Trans', 'Knowl', 'Data', 'Eng', '.']

>> Bigrams are: 
 [('IEEE', 'Trans'), ('Trans', 'Knowl'), ('Knowl', 'Data'), ('Data', 'Eng'), ('Eng', '.')]

>> Trigrams are: 
 [('IEEE', 'Trans', 'Knowl'), ('Trans', 'Knowl', 'Data'), ('Knowl', 'Data', 'Eng'), ('Data', 'Eng', '.')]

>> POS Tags are: 
 [('IEEE', 'NNP'), ('Trans', 'NNP'), ('Knowl', 'NNP'), ('Data', 'NNP'), ('Eng', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['IEEE Trans Knowl Data Eng']

>> Named Entities are: 
 [('ORGANIZATION', 'IEEE'), ('PERSON', 'Trans Knowl Data Eng')] 

>> Stemming using Porter Stemmer: 
 [('IEEE', 'ieee'), ('Trans', 'tran'), ('Knowl', 'knowl'), ('Data', 'data'), ('Eng', 'eng'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('IEEE', 'ieee'), ('Trans', 'tran'), ('Knowl', 'knowl'), ('Data', 'data'), ('Eng', 'eng'), ('.', '.')]

>> Lemmatization: 
 [('IEEE', 'IEEE'), ('Trans', 'Trans'), ('Knowl', 'Knowl'), ('Data', 'Data'), ('Eng', 'Eng'), ('.', '.')]


------------------- Sentence 3 -------------------

2003;15(5):1170–87.

>> Tokens are: 
 ['2003', ';', '15', '(', '5', ')', ':1170–87', '.']

>> Bigrams are: 
 [('2003', ';'), (';', '15'), ('15', '('), ('(', '5'), ('5', ')'), (')', ':1170–87'), (':1170–87', '.')]

>> Trigrams are: 
 [('2003', ';', '15'), (';', '15', '('), ('15', '(', '5'), ('(', '5', ')'), ('5', ')', ':1170–87'), (')', ':1170–87', '.')]

>> POS Tags are: 
 [('2003', 'CD'), (';', ':'), ('15', 'CD'), ('(', '('), ('5', 'CD'), (')', ')'), (':1170–87', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 [':1170–87']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('2003', '2003'), (';', ';'), ('15', '15'), ('(', '('), ('5', '5'), (')', ')'), (':1170–87', ':1170–87'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('2003', '2003'), (';', ';'), ('15', '15'), ('(', '('), ('5', '5'), (')', ')'), (':1170–87', ':1170–87'), ('.', '.')]

>> Lemmatization: 
 [('2003', '2003'), (';', ';'), ('15', '15'), ('(', '('), ('5', '5'), (')', ')'), (':1170–87', ':1170–87'), ('.', '.')]


------------------- Sentence 4 -------------------

5.

>> Tokens are: 
 ['5', '.']

>> Bigrams are: 
 [('5', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('5', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('5', '5'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('5', '5'), ('.', '.')]

>> Lemmatization: 
 [('5', '5'), ('.', '.')]


------------------- Sentence 5 -------------------

Fisher D, DeLine R, Czerwinski M, Drucker S. Interactions with big data analytics.

>> Tokens are: 
 ['Fisher', 'D', ',', 'DeLine', 'R', ',', 'Czerwinski', 'M', ',', 'Drucker', 'S.', 'Interactions', 'big', 'data', 'analytics', '.']

>> Bigrams are: 
 [('Fisher', 'D'), ('D', ','), (',', 'DeLine'), ('DeLine', 'R'), ('R', ','), (',', 'Czerwinski'), ('Czerwinski', 'M'), ('M', ','), (',', 'Drucker'), ('Drucker', 'S.'), ('S.', 'Interactions'), ('Interactions', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', '.')]

>> Trigrams are: 
 [('Fisher', 'D', ','), ('D', ',', 'DeLine'), (',', 'DeLine', 'R'), ('DeLine', 'R', ','), ('R', ',', 'Czerwinski'), (',', 'Czerwinski', 'M'), ('Czerwinski', 'M', ','), ('M', ',', 'Drucker'), (',', 'Drucker', 'S.'), ('Drucker', 'S.', 'Interactions'), ('S.', 'Interactions', 'big'), ('Interactions', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', '.')]

>> POS Tags are: 
 [('Fisher', 'NNP'), ('D', 'NNP'), (',', ','), ('DeLine', 'NNP'), ('R', 'NNP'), (',', ','), ('Czerwinski', 'NNP'), ('M', 'NNP'), (',', ','), ('Drucker', 'NNP'), ('S.', 'NNP'), ('Interactions', 'NNP'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['Fisher D', 'DeLine R', 'Czerwinski M', 'Drucker S. Interactions', 'big data analytics']

>> Named Entities are: 
 [('PERSON', 'Fisher'), ('ORGANIZATION', 'D'), ('ORGANIZATION', 'DeLine R'), ('PERSON', 'Czerwinski M'), ('PERSON', 'Drucker S. Interactions')] 

>> Stemming using Porter Stemmer: 
 [('Fisher', 'fisher'), ('D', 'd'), (',', ','), ('DeLine', 'delin'), ('R', 'r'), (',', ','), ('Czerwinski', 'czerwinski'), ('M', 'm'), (',', ','), ('Drucker', 'drucker'), ('S.', 's.'), ('Interactions', 'interact'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Fisher', 'fisher'), ('D', 'd'), (',', ','), ('DeLine', 'delin'), ('R', 'r'), (',', ','), ('Czerwinski', 'czerwinski'), ('M', 'm'), (',', ','), ('Drucker', 'drucker'), ('S.', 's.'), ('Interactions', 'interact'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('.', '.')]

>> Lemmatization: 
 [('Fisher', 'Fisher'), ('D', 'D'), (',', ','), ('DeLine', 'DeLine'), ('R', 'R'), (',', ','), ('Czerwinski', 'Czerwinski'), ('M', 'M'), (',', ','), ('Drucker', 'Drucker'), ('S.', 'S.'), ('Interactions', 'Interactions'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('.', '.')]


------------------- Sentence 6 -------------------

Interactions.

>> Tokens are: 
 ['Interactions', '.']

>> Bigrams are: 
 [('Interactions', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Interactions', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['Interactions']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Interactions', 'interact'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Interactions', 'interact'), ('.', '.')]

>> Lemmatization: 
 [('Interactions', 'Interactions'), ('.', '.')]


------------------- Sentence 7 -------------------

2012;19(3):50–9.

>> Tokens are: 
 ['2012', ';', '19', '(', '3', ')', ':50–9', '.']

>> Bigrams are: 
 [('2012', ';'), (';', '19'), ('19', '('), ('(', '3'), ('3', ')'), (')', ':50–9'), (':50–9', '.')]

>> Trigrams are: 
 [('2012', ';', '19'), (';', '19', '('), ('19', '(', '3'), ('(', '3', ')'), ('3', ')', ':50–9'), (')', ':50–9', '.')]

>> POS Tags are: 
 [('2012', 'CD'), (';', ':'), ('19', 'CD'), ('(', '('), ('3', 'CD'), (')', ')'), (':50–9', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 [':50–9']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('2012', '2012'), (';', ';'), ('19', '19'), ('(', '('), ('3', '3'), (')', ')'), (':50–9', ':50–9'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('2012', '2012'), (';', ';'), ('19', '19'), ('(', '('), ('3', '3'), (')', ')'), (':50–9', ':50–9'), ('.', '.')]

>> Lemmatization: 
 [('2012', '2012'), (';', ';'), ('19', '19'), ('(', '('), ('3', '3'), (')', ')'), (':50–9', ':50–9'), ('.', '.')]


------------------- Sentence 8 -------------------

6.

>> Tokens are: 
 ['6', '.']

>> Bigrams are: 
 [('6', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('6', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('6', '6'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('6', '6'), ('.', '.')]

>> Lemmatization: 
 [('6', '6'), ('.', '.')]


------------------- Sentence 9 -------------------

Laney D. 3D data management: controlling data volume, velocity, and variety, META Group, Tech.

>> Tokens are: 
 ['Laney', 'D.', '3D', 'data', 'management', ':', 'controlling', 'data', 'volume', ',', 'velocity', ',', 'variety', ',', 'META', 'Group', ',', 'Tech', '.']

>> Bigrams are: 
 [('Laney', 'D.'), ('D.', '3D'), ('3D', 'data'), ('data', 'management'), ('management', ':'), (':', 'controlling'), ('controlling', 'data'), ('data', 'volume'), ('volume', ','), (',', 'velocity'), ('velocity', ','), (',', 'variety'), ('variety', ','), (',', 'META'), ('META', 'Group'), ('Group', ','), (',', 'Tech'), ('Tech', '.')]

>> Trigrams are: 
 [('Laney', 'D.', '3D'), ('D.', '3D', 'data'), ('3D', 'data', 'management'), ('data', 'management', ':'), ('management', ':', 'controlling'), (':', 'controlling', 'data'), ('controlling', 'data', 'volume'), ('data', 'volume', ','), ('volume', ',', 'velocity'), (',', 'velocity', ','), ('velocity', ',', 'variety'), (',', 'variety', ','), ('variety', ',', 'META'), (',', 'META', 'Group'), ('META', 'Group', ','), ('Group', ',', 'Tech'), (',', 'Tech', '.')]

>> POS Tags are: 
 [('Laney', 'NNP'), ('D.', 'NNP'), ('3D', 'CD'), ('data', 'NNS'), ('management', 'NN'), (':', ':'), ('controlling', 'VBG'), ('data', 'NNS'), ('volume', 'NN'), (',', ','), ('velocity', 'NN'), (',', ','), ('variety', 'NN'), (',', ','), ('META', 'NNP'), ('Group', 'NNP'), (',', ','), ('Tech', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Laney D.', 'data management', 'data volume', 'velocity', 'variety', 'META Group', 'Tech']

>> Named Entities are: 
 [('PERSON', 'Laney'), ('ORGANIZATION', 'META Group'), ('GPE', 'Tech')] 

>> Stemming using Porter Stemmer: 
 [('Laney', 'laney'), ('D.', 'd.'), ('3D', '3d'), ('data', 'data'), ('management', 'manag'), (':', ':'), ('controlling', 'control'), ('data', 'data'), ('volume', 'volum'), (',', ','), ('velocity', 'veloc'), (',', ','), ('variety', 'varieti'), (',', ','), ('META', 'meta'), ('Group', 'group'), (',', ','), ('Tech', 'tech'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Laney', 'laney'), ('D.', 'd.'), ('3D', '3d'), ('data', 'data'), ('management', 'manag'), (':', ':'), ('controlling', 'control'), ('data', 'data'), ('volume', 'volum'), (',', ','), ('velocity', 'veloc'), (',', ','), ('variety', 'varieti'), (',', ','), ('META', 'meta'), ('Group', 'group'), (',', ','), ('Tech', 'tech'), ('.', '.')]

>> Lemmatization: 
 [('Laney', 'Laney'), ('D.', 'D.'), ('3D', '3D'), ('data', 'data'), ('management', 'management'), (':', ':'), ('controlling', 'controlling'), ('data', 'data'), ('volume', 'volume'), (',', ','), ('velocity', 'velocity'), (',', ','), ('variety', 'variety'), (',', ','), ('META', 'META'), ('Group', 'Group'), (',', ','), ('Tech', 'Tech'), ('.', '.')]


------------------- Sentence 10 -------------------

Rep. 2001.

>> Tokens are: 
 ['Rep.', '2001', '.']

>> Bigrams are: 
 [('Rep.', '2001'), ('2001', '.')]

>> Trigrams are: 
 [('Rep.', '2001', '.')]

>> POS Tags are: 
 [('Rep.', 'NNP'), ('2001', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Rep.']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Rep.', 'rep.'), ('2001', '2001'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Rep.', 'rep.'), ('2001', '2001'), ('.', '.')]

>> Lemmatization: 
 [('Rep.', 'Rep.'), ('2001', '2001'), ('.', '.')]



========================================== PARAGRAPH 406 ===========================================

[Online]. Available: http://blogs.gartner.com/doug‑laney/files/2012/01/ad949‑3D‑Data‑Management‑Control‑ ling‑Data‑Volume‑Velocity‑and‑Variety.pdf. 

------------------- Sentence 1 -------------------

[Online].

>> Tokens are: 
 ['[', 'Online', ']', '.']

>> Bigrams are: 
 [('[', 'Online'), ('Online', ']'), (']', '.')]

>> Trigrams are: 
 [('[', 'Online', ']'), ('Online', ']', '.')]

>> POS Tags are: 
 [('[', 'JJ'), ('Online', 'NNP'), (']', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['[ Online ]']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('Online', 'onlin'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('Online', 'onlin'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('Online', 'Online'), (']', ']'), ('.', '.')]


------------------- Sentence 2 -------------------

Available: http://blogs.gartner.com/doug‑laney/files/2012/01/ad949‑3D‑Data‑Management‑Control‑ ling‑Data‑Volume‑Velocity‑and‑Variety.pdf.

>> Tokens are: 
 ['Available', ':', 'http', ':', '//blogs.gartner.com/doug‑laney/files/2012/01/ad949‑3D‑Data‑Management‑Control‑', 'ling‑Data‑Volume‑Velocity‑and‑Variety.pdf', '.']

>> Bigrams are: 
 [('Available', ':'), (':', 'http'), ('http', ':'), (':', '//blogs.gartner.com/doug‑laney/files/2012/01/ad949‑3D‑Data‑Management‑Control‑'), ('//blogs.gartner.com/doug‑laney/files/2012/01/ad949‑3D‑Data‑Management‑Control‑', 'ling‑Data‑Volume‑Velocity‑and‑Variety.pdf'), ('ling‑Data‑Volume‑Velocity‑and‑Variety.pdf', '.')]

>> Trigrams are: 
 [('Available', ':', 'http'), (':', 'http', ':'), ('http', ':', '//blogs.gartner.com/doug‑laney/files/2012/01/ad949‑3D‑Data‑Management‑Control‑'), (':', '//blogs.gartner.com/doug‑laney/files/2012/01/ad949‑3D‑Data‑Management‑Control‑', 'ling‑Data‑Volume‑Velocity‑and‑Variety.pdf'), ('//blogs.gartner.com/doug‑laney/files/2012/01/ad949‑3D‑Data‑Management‑Control‑', 'ling‑Data‑Volume‑Velocity‑and‑Variety.pdf', '.')]

>> POS Tags are: 
 [('Available', 'JJ'), (':', ':'), ('http', 'NN'), (':', ':'), ('//blogs.gartner.com/doug‑laney/files/2012/01/ad949‑3D‑Data‑Management‑Control‑', 'JJ'), ('ling‑Data‑Volume‑Velocity‑and‑Variety.pdf', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['http', '//blogs.gartner.com/doug‑laney/files/2012/01/ad949‑3D‑Data‑Management‑Control‑ ling‑Data‑Volume‑Velocity‑and‑Variety.pdf']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Available', 'avail'), (':', ':'), ('http', 'http'), (':', ':'), ('//blogs.gartner.com/doug‑laney/files/2012/01/ad949‑3D‑Data‑Management‑Control‑', '//blogs.gartner.com/doug‑laney/files/2012/01/ad949‑3d‑data‑management‑control‑'), ('ling‑Data‑Volume‑Velocity‑and‑Variety.pdf', 'ling‑data‑volume‑velocity‑and‑variety.pdf'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Available', 'avail'), (':', ':'), ('http', 'http'), (':', ':'), ('//blogs.gartner.com/doug‑laney/files/2012/01/ad949‑3D‑Data‑Management‑Control‑', '//blogs.gartner.com/doug‑laney/files/2012/01/ad949‑3d‑data‑management‑control‑'), ('ling‑Data‑Volume‑Velocity‑and‑Variety.pdf', 'ling‑data‑volume‑velocity‑and‑variety.pdf'), ('.', '.')]

>> Lemmatization: 
 [('Available', 'Available'), (':', ':'), ('http', 'http'), (':', ':'), ('//blogs.gartner.com/doug‑laney/files/2012/01/ad949‑3D‑Data‑Management‑Control‑', '//blogs.gartner.com/doug‑laney/files/2012/01/ad949‑3D‑Data‑Management‑Control‑'), ('ling‑Data‑Volume‑Velocity‑and‑Variety.pdf', 'ling‑Data‑Volume‑Velocity‑and‑Variety.pdf'), ('.', '.')]



========================================== PARAGRAPH 407 ===========================================

 7. van Rijmenam M. Why the 3v’s are not sufficient to describe big data, BigData Startups, Tech. Rep. 2013. [Online].  Available: http://www.bigdata‑startups.com/3vs‑sufficient‑describe‑big‑data/. 

------------------- Sentence 1 -------------------

 7. van Rijmenam M. Why the 3v’s are not sufficient to describe big data, BigData Startups, Tech.

>> Tokens are: 
 ['7.', 'van', 'Rijmenam', 'M.', 'Why', '3v', '’', 'sufficient', 'describe', 'big', 'data', ',', 'BigData', 'Startups', ',', 'Tech', '.']

>> Bigrams are: 
 [('7.', 'van'), ('van', 'Rijmenam'), ('Rijmenam', 'M.'), ('M.', 'Why'), ('Why', '3v'), ('3v', '’'), ('’', 'sufficient'), ('sufficient', 'describe'), ('describe', 'big'), ('big', 'data'), ('data', ','), (',', 'BigData'), ('BigData', 'Startups'), ('Startups', ','), (',', 'Tech'), ('Tech', '.')]

>> Trigrams are: 
 [('7.', 'van', 'Rijmenam'), ('van', 'Rijmenam', 'M.'), ('Rijmenam', 'M.', 'Why'), ('M.', 'Why', '3v'), ('Why', '3v', '’'), ('3v', '’', 'sufficient'), ('’', 'sufficient', 'describe'), ('sufficient', 'describe', 'big'), ('describe', 'big', 'data'), ('big', 'data', ','), ('data', ',', 'BigData'), (',', 'BigData', 'Startups'), ('BigData', 'Startups', ','), ('Startups', ',', 'Tech'), (',', 'Tech', '.')]

>> POS Tags are: 
 [('7.', 'CD'), ('van', 'NN'), ('Rijmenam', 'NNP'), ('M.', 'NNP'), ('Why', 'WRB'), ('3v', 'CD'), ('’', 'NN'), ('sufficient', 'JJ'), ('describe', 'NN'), ('big', 'JJ'), ('data', 'NNS'), (',', ','), ('BigData', 'NNP'), ('Startups', 'NNP'), (',', ','), ('Tech', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['van Rijmenam M.', '’', 'sufficient describe', 'big data', 'BigData Startups', 'Tech']

>> Named Entities are: 
 [('PERSON', 'Rijmenam M.'), ('ORGANIZATION', 'BigData Startups'), ('GPE', 'Tech')] 

>> Stemming using Porter Stemmer: 
 [('7.', '7.'), ('van', 'van'), ('Rijmenam', 'rijmenam'), ('M.', 'm.'), ('Why', 'whi'), ('3v', '3v'), ('’', '’'), ('sufficient', 'suffici'), ('describe', 'describ'), ('big', 'big'), ('data', 'data'), (',', ','), ('BigData', 'bigdata'), ('Startups', 'startup'), (',', ','), ('Tech', 'tech'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('7.', '7.'), ('van', 'van'), ('Rijmenam', 'rijmenam'), ('M.', 'm.'), ('Why', 'whi'), ('3v', '3v'), ('’', '’'), ('sufficient', 'suffici'), ('describe', 'describ'), ('big', 'big'), ('data', 'data'), (',', ','), ('BigData', 'bigdata'), ('Startups', 'startup'), (',', ','), ('Tech', 'tech'), ('.', '.')]

>> Lemmatization: 
 [('7.', '7.'), ('van', 'van'), ('Rijmenam', 'Rijmenam'), ('M.', 'M.'), ('Why', 'Why'), ('3v', '3v'), ('’', '’'), ('sufficient', 'sufficient'), ('describe', 'describe'), ('big', 'big'), ('data', 'data'), (',', ','), ('BigData', 'BigData'), ('Startups', 'Startups'), (',', ','), ('Tech', 'Tech'), ('.', '.')]


------------------- Sentence 2 -------------------

Rep. 2013.

>> Tokens are: 
 ['Rep.', '2013', '.']

>> Bigrams are: 
 [('Rep.', '2013'), ('2013', '.')]

>> Trigrams are: 
 [('Rep.', '2013', '.')]

>> POS Tags are: 
 [('Rep.', 'NNP'), ('2013', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Rep.']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Rep.', 'rep.'), ('2013', '2013'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Rep.', 'rep.'), ('2013', '2013'), ('.', '.')]

>> Lemmatization: 
 [('Rep.', 'Rep.'), ('2013', '2013'), ('.', '.')]


------------------- Sentence 3 -------------------

[Online].

>> Tokens are: 
 ['[', 'Online', ']', '.']

>> Bigrams are: 
 [('[', 'Online'), ('Online', ']'), (']', '.')]

>> Trigrams are: 
 [('[', 'Online', ']'), ('Online', ']', '.')]

>> POS Tags are: 
 [('[', 'JJ'), ('Online', 'NNP'), (']', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['[ Online ]']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('Online', 'onlin'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('Online', 'onlin'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('Online', 'Online'), (']', ']'), ('.', '.')]


------------------- Sentence 4 -------------------

Available: http://www.bigdata‑startups.com/3vs‑sufficient‑describe‑big‑data/.

>> Tokens are: 
 ['Available', ':', 'http', ':', '//www.bigdata‑startups.com/3vs‑sufficient‑describe‑big‑data/', '.']

>> Bigrams are: 
 [('Available', ':'), (':', 'http'), ('http', ':'), (':', '//www.bigdata‑startups.com/3vs‑sufficient‑describe‑big‑data/'), ('//www.bigdata‑startups.com/3vs‑sufficient‑describe‑big‑data/', '.')]

>> Trigrams are: 
 [('Available', ':', 'http'), (':', 'http', ':'), ('http', ':', '//www.bigdata‑startups.com/3vs‑sufficient‑describe‑big‑data/'), (':', '//www.bigdata‑startups.com/3vs‑sufficient‑describe‑big‑data/', '.')]

>> POS Tags are: 
 [('Available', 'JJ'), (':', ':'), ('http', 'NN'), (':', ':'), ('//www.bigdata‑startups.com/3vs‑sufficient‑describe‑big‑data/', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['http', '//www.bigdata‑startups.com/3vs‑sufficient‑describe‑big‑data/']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Available', 'avail'), (':', ':'), ('http', 'http'), (':', ':'), ('//www.bigdata‑startups.com/3vs‑sufficient‑describe‑big‑data/', '//www.bigdata‑startups.com/3vs‑sufficient‑describe‑big‑data/'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Available', 'avail'), (':', ':'), ('http', 'http'), (':', ':'), ('//www.bigdata‑startups.com/3vs‑sufficient‑describe‑big‑data/', '//www.bigdata‑startups.com/3vs‑sufficient‑describe‑big‑data/'), ('.', '.')]

>> Lemmatization: 
 [('Available', 'Available'), (':', ':'), ('http', 'http'), (':', ':'), ('//www.bigdata‑startups.com/3vs‑sufficient‑describe‑big‑data/', '//www.bigdata‑startups.com/3vs‑sufficient‑describe‑big‑data/'), ('.', '.')]



========================================== PARAGRAPH 408 ===========================================

 8. Borne K. Top 10 big data challenges a serious look at 10 big data v’s, Tech. Rep. 2014. [Online]. Available: https:// www.mapr.com/blog/top‑10‑big‑data‑challenges‑look‑10‑big‑data‑v. 

------------------- Sentence 1 -------------------

 8.

>> Tokens are: 
 ['8', '.']

>> Bigrams are: 
 [('8', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('8', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('8', '8'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('8', '8'), ('.', '.')]

>> Lemmatization: 
 [('8', '8'), ('.', '.')]


------------------- Sentence 2 -------------------

Borne K. Top 10 big data challenges a serious look at 10 big data v’s, Tech.

>> Tokens are: 
 ['Borne', 'K.', 'Top', '10', 'big', 'data', 'challenges', 'serious', 'look', '10', 'big', 'data', 'v', '’', ',', 'Tech', '.']

>> Bigrams are: 
 [('Borne', 'K.'), ('K.', 'Top'), ('Top', '10'), ('10', 'big'), ('big', 'data'), ('data', 'challenges'), ('challenges', 'serious'), ('serious', 'look'), ('look', '10'), ('10', 'big'), ('big', 'data'), ('data', 'v'), ('v', '’'), ('’', ','), (',', 'Tech'), ('Tech', '.')]

>> Trigrams are: 
 [('Borne', 'K.', 'Top'), ('K.', 'Top', '10'), ('Top', '10', 'big'), ('10', 'big', 'data'), ('big', 'data', 'challenges'), ('data', 'challenges', 'serious'), ('challenges', 'serious', 'look'), ('serious', 'look', '10'), ('look', '10', 'big'), ('10', 'big', 'data'), ('big', 'data', 'v'), ('data', 'v', '’'), ('v', '’', ','), ('’', ',', 'Tech'), (',', 'Tech', '.')]

>> POS Tags are: 
 [('Borne', 'NNP'), ('K.', 'NNP'), ('Top', 'NNP'), ('10', 'CD'), ('big', 'JJ'), ('data', 'NNS'), ('challenges', 'NNS'), ('serious', 'JJ'), ('look', 'VBP'), ('10', 'CD'), ('big', 'JJ'), ('data', 'NNS'), ('v', 'NN'), ('’', 'NN'), (',', ','), ('Tech', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Borne K. Top', 'big data challenges', 'big data v ’', 'Tech']

>> Named Entities are: 
 [('PERSON', 'Borne'), ('GPE', 'Tech')] 

>> Stemming using Porter Stemmer: 
 [('Borne', 'born'), ('K.', 'k.'), ('Top', 'top'), ('10', '10'), ('big', 'big'), ('data', 'data'), ('challenges', 'challeng'), ('serious', 'seriou'), ('look', 'look'), ('10', '10'), ('big', 'big'), ('data', 'data'), ('v', 'v'), ('’', '’'), (',', ','), ('Tech', 'tech'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Borne', 'born'), ('K.', 'k.'), ('Top', 'top'), ('10', '10'), ('big', 'big'), ('data', 'data'), ('challenges', 'challeng'), ('serious', 'serious'), ('look', 'look'), ('10', '10'), ('big', 'big'), ('data', 'data'), ('v', 'v'), ('’', '’'), (',', ','), ('Tech', 'tech'), ('.', '.')]

>> Lemmatization: 
 [('Borne', 'Borne'), ('K.', 'K.'), ('Top', 'Top'), ('10', '10'), ('big', 'big'), ('data', 'data'), ('challenges', 'challenge'), ('serious', 'serious'), ('look', 'look'), ('10', '10'), ('big', 'big'), ('data', 'data'), ('v', 'v'), ('’', '’'), (',', ','), ('Tech', 'Tech'), ('.', '.')]


------------------- Sentence 3 -------------------

Rep. 2014.

>> Tokens are: 
 ['Rep.', '2014', '.']

>> Bigrams are: 
 [('Rep.', '2014'), ('2014', '.')]

>> Trigrams are: 
 [('Rep.', '2014', '.')]

>> POS Tags are: 
 [('Rep.', 'NNP'), ('2014', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Rep.']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Rep.', 'rep.'), ('2014', '2014'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Rep.', 'rep.'), ('2014', '2014'), ('.', '.')]

>> Lemmatization: 
 [('Rep.', 'Rep.'), ('2014', '2014'), ('.', '.')]


------------------- Sentence 4 -------------------

[Online].

>> Tokens are: 
 ['[', 'Online', ']', '.']

>> Bigrams are: 
 [('[', 'Online'), ('Online', ']'), (']', '.')]

>> Trigrams are: 
 [('[', 'Online', ']'), ('Online', ']', '.')]

>> POS Tags are: 
 [('[', 'JJ'), ('Online', 'NNP'), (']', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['[ Online ]']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('Online', 'onlin'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('Online', 'onlin'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('Online', 'Online'), (']', ']'), ('.', '.')]


------------------- Sentence 5 -------------------

Available: https:// www.mapr.com/blog/top‑10‑big‑data‑challenges‑look‑10‑big‑data‑v.

>> Tokens are: 
 ['Available', ':', 'https', ':', '//', 'www.mapr.com/blog/top‑10‑big‑data‑challenges‑look‑10‑big‑data‑v', '.']

>> Bigrams are: 
 [('Available', ':'), (':', 'https'), ('https', ':'), (':', '//'), ('//', 'www.mapr.com/blog/top‑10‑big‑data‑challenges‑look‑10‑big‑data‑v'), ('www.mapr.com/blog/top‑10‑big‑data‑challenges‑look‑10‑big‑data‑v', '.')]

>> Trigrams are: 
 [('Available', ':', 'https'), (':', 'https', ':'), ('https', ':', '//'), (':', '//', 'www.mapr.com/blog/top‑10‑big‑data‑challenges‑look‑10‑big‑data‑v'), ('//', 'www.mapr.com/blog/top‑10‑big‑data‑challenges‑look‑10‑big‑data‑v', '.')]

>> POS Tags are: 
 [('Available', 'JJ'), (':', ':'), ('https', 'NN'), (':', ':'), ('//', 'JJ'), ('www.mapr.com/blog/top‑10‑big‑data‑challenges‑look‑10‑big‑data‑v', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['https', '// www.mapr.com/blog/top‑10‑big‑data‑challenges‑look‑10‑big‑data‑v']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Available', 'avail'), (':', ':'), ('https', 'http'), (':', ':'), ('//', '//'), ('www.mapr.com/blog/top‑10‑big‑data‑challenges‑look‑10‑big‑data‑v', 'www.mapr.com/blog/top‑10‑big‑data‑challenges‑look‑10‑big‑data‑v'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Available', 'avail'), (':', ':'), ('https', 'https'), (':', ':'), ('//', '//'), ('www.mapr.com/blog/top‑10‑big‑data‑challenges‑look‑10‑big‑data‑v', 'www.mapr.com/blog/top‑10‑big‑data‑challenges‑look‑10‑big‑data‑v'), ('.', '.')]

>> Lemmatization: 
 [('Available', 'Available'), (':', ':'), ('https', 'http'), (':', ':'), ('//', '//'), ('www.mapr.com/blog/top‑10‑big‑data‑challenges‑look‑10‑big‑data‑v', 'www.mapr.com/blog/top‑10‑big‑data‑challenges‑look‑10‑big‑data‑v'), ('.', '.')]



========================================== PARAGRAPH 409 ===========================================

 9. Press G. $16.1 billion big data market: 2014 predictions from IDC and IIA,  Forbes, Tech. Rep. 2013. [Online]. Available: http://www.forbes.com/sites/ gilpress/2013/12/12/16‑1‑billion‑big‑data‑market‑2014‑predictions‑from‑idc‑and‑iia/. 

------------------- Sentence 1 -------------------

 9.

>> Tokens are: 
 ['9', '.']

>> Bigrams are: 
 [('9', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('9', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('9', '9'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('9', '9'), ('.', '.')]

>> Lemmatization: 
 [('9', '9'), ('.', '.')]


------------------- Sentence 2 -------------------

Press G. $16.1 billion big data market: 2014 predictions from IDC and IIA,  Forbes, Tech.

>> Tokens are: 
 ['Press', 'G.', '$', '16.1', 'billion', 'big', 'data', 'market', ':', '2014', 'predictions', 'IDC', 'IIA', ',', 'Forbes', ',', 'Tech', '.']

>> Bigrams are: 
 [('Press', 'G.'), ('G.', '$'), ('$', '16.1'), ('16.1', 'billion'), ('billion', 'big'), ('big', 'data'), ('data', 'market'), ('market', ':'), (':', '2014'), ('2014', 'predictions'), ('predictions', 'IDC'), ('IDC', 'IIA'), ('IIA', ','), (',', 'Forbes'), ('Forbes', ','), (',', 'Tech'), ('Tech', '.')]

>> Trigrams are: 
 [('Press', 'G.', '$'), ('G.', '$', '16.1'), ('$', '16.1', 'billion'), ('16.1', 'billion', 'big'), ('billion', 'big', 'data'), ('big', 'data', 'market'), ('data', 'market', ':'), ('market', ':', '2014'), (':', '2014', 'predictions'), ('2014', 'predictions', 'IDC'), ('predictions', 'IDC', 'IIA'), ('IDC', 'IIA', ','), ('IIA', ',', 'Forbes'), (',', 'Forbes', ','), ('Forbes', ',', 'Tech'), (',', 'Tech', '.')]

>> POS Tags are: 
 [('Press', 'NNP'), ('G.', 'NNP'), ('$', '$'), ('16.1', 'CD'), ('billion', 'CD'), ('big', 'JJ'), ('data', 'NNS'), ('market', 'NN'), (':', ':'), ('2014', 'CD'), ('predictions', 'NNS'), ('IDC', 'NNP'), ('IIA', 'NNP'), (',', ','), ('Forbes', 'NNP'), (',', ','), ('Tech', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Press G.', 'big data market', 'predictions IDC IIA', 'Forbes', 'Tech']

>> Named Entities are: 
 [('ORGANIZATION', 'IDC'), ('GPE', 'Forbes'), ('GPE', 'Tech')] 

>> Stemming using Porter Stemmer: 
 [('Press', 'press'), ('G.', 'g.'), ('$', '$'), ('16.1', '16.1'), ('billion', 'billion'), ('big', 'big'), ('data', 'data'), ('market', 'market'), (':', ':'), ('2014', '2014'), ('predictions', 'predict'), ('IDC', 'idc'), ('IIA', 'iia'), (',', ','), ('Forbes', 'forb'), (',', ','), ('Tech', 'tech'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Press', 'press'), ('G.', 'g.'), ('$', '$'), ('16.1', '16.1'), ('billion', 'billion'), ('big', 'big'), ('data', 'data'), ('market', 'market'), (':', ':'), ('2014', '2014'), ('predictions', 'predict'), ('IDC', 'idc'), ('IIA', 'iia'), (',', ','), ('Forbes', 'forb'), (',', ','), ('Tech', 'tech'), ('.', '.')]

>> Lemmatization: 
 [('Press', 'Press'), ('G.', 'G.'), ('$', '$'), ('16.1', '16.1'), ('billion', 'billion'), ('big', 'big'), ('data', 'data'), ('market', 'market'), (':', ':'), ('2014', '2014'), ('predictions', 'prediction'), ('IDC', 'IDC'), ('IIA', 'IIA'), (',', ','), ('Forbes', 'Forbes'), (',', ','), ('Tech', 'Tech'), ('.', '.')]


------------------- Sentence 3 -------------------

Rep. 2013.

>> Tokens are: 
 ['Rep.', '2013', '.']

>> Bigrams are: 
 [('Rep.', '2013'), ('2013', '.')]

>> Trigrams are: 
 [('Rep.', '2013', '.')]

>> POS Tags are: 
 [('Rep.', 'NNP'), ('2013', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Rep.']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Rep.', 'rep.'), ('2013', '2013'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Rep.', 'rep.'), ('2013', '2013'), ('.', '.')]

>> Lemmatization: 
 [('Rep.', 'Rep.'), ('2013', '2013'), ('.', '.')]


------------------- Sentence 4 -------------------

[Online].

>> Tokens are: 
 ['[', 'Online', ']', '.']

>> Bigrams are: 
 [('[', 'Online'), ('Online', ']'), (']', '.')]

>> Trigrams are: 
 [('[', 'Online', ']'), ('Online', ']', '.')]

>> POS Tags are: 
 [('[', 'JJ'), ('Online', 'NNP'), (']', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['[ Online ]']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('Online', 'onlin'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('Online', 'onlin'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('Online', 'Online'), (']', ']'), ('.', '.')]


------------------- Sentence 5 -------------------

Available: http://www.forbes.com/sites/ gilpress/2013/12/12/16‑1‑billion‑big‑data‑market‑2014‑predictions‑from‑idc‑and‑iia/.

>> Tokens are: 
 ['Available', ':', 'http', ':', '//www.forbes.com/sites/', 'gilpress/2013/12/12/16‑1‑billion‑big‑data‑market‑2014‑predictions‑from‑idc‑and‑iia/', '.']

>> Bigrams are: 
 [('Available', ':'), (':', 'http'), ('http', ':'), (':', '//www.forbes.com/sites/'), ('//www.forbes.com/sites/', 'gilpress/2013/12/12/16‑1‑billion‑big‑data‑market‑2014‑predictions‑from‑idc‑and‑iia/'), ('gilpress/2013/12/12/16‑1‑billion‑big‑data‑market‑2014‑predictions‑from‑idc‑and‑iia/', '.')]

>> Trigrams are: 
 [('Available', ':', 'http'), (':', 'http', ':'), ('http', ':', '//www.forbes.com/sites/'), (':', '//www.forbes.com/sites/', 'gilpress/2013/12/12/16‑1‑billion‑big‑data‑market‑2014‑predictions‑from‑idc‑and‑iia/'), ('//www.forbes.com/sites/', 'gilpress/2013/12/12/16‑1‑billion‑big‑data‑market‑2014‑predictions‑from‑idc‑and‑iia/', '.')]

>> POS Tags are: 
 [('Available', 'JJ'), (':', ':'), ('http', 'NN'), (':', ':'), ('//www.forbes.com/sites/', 'JJ'), ('gilpress/2013/12/12/16‑1‑billion‑big‑data‑market‑2014‑predictions‑from‑idc‑and‑iia/', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['http', '//www.forbes.com/sites/ gilpress/2013/12/12/16‑1‑billion‑big‑data‑market‑2014‑predictions‑from‑idc‑and‑iia/']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Available', 'avail'), (':', ':'), ('http', 'http'), (':', ':'), ('//www.forbes.com/sites/', '//www.forbes.com/sites/'), ('gilpress/2013/12/12/16‑1‑billion‑big‑data‑market‑2014‑predictions‑from‑idc‑and‑iia/', 'gilpress/2013/12/12/16‑1‑billion‑big‑data‑market‑2014‑predictions‑from‑idc‑and‑iia/'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Available', 'avail'), (':', ':'), ('http', 'http'), (':', ':'), ('//www.forbes.com/sites/', '//www.forbes.com/sites/'), ('gilpress/2013/12/12/16‑1‑billion‑big‑data‑market‑2014‑predictions‑from‑idc‑and‑iia/', 'gilpress/2013/12/12/16‑1‑billion‑big‑data‑market‑2014‑predictions‑from‑idc‑and‑iia/'), ('.', '.')]

>> Lemmatization: 
 [('Available', 'Available'), (':', ':'), ('http', 'http'), (':', ':'), ('//www.forbes.com/sites/', '//www.forbes.com/sites/'), ('gilpress/2013/12/12/16‑1‑billion‑big‑data‑market‑2014‑predictions‑from‑idc‑and‑iia/', 'gilpress/2013/12/12/16‑1‑billion‑big‑data‑market‑2014‑predictions‑from‑idc‑and‑iia/'), ('.', '.')]



========================================== PARAGRAPH 410 ===========================================

 10. Big data and analytics—an IDC four pillar research area, IDC, Tech. Rep. 2013. [Online]. Available: http://www.idc. com/prodserv/FourPillars/bigData/index.jsp. 

------------------- Sentence 1 -------------------

 10.

>> Tokens are: 
 ['10', '.']

>> Bigrams are: 
 [('10', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('10', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('10', '10'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('10', '10'), ('.', '.')]

>> Lemmatization: 
 [('10', '10'), ('.', '.')]


------------------- Sentence 2 -------------------

Big data and analytics—an IDC four pillar research area, IDC, Tech.

>> Tokens are: 
 ['Big', 'data', 'analytics—an', 'IDC', 'four', 'pillar', 'research', 'area', ',', 'IDC', ',', 'Tech', '.']

>> Bigrams are: 
 [('Big', 'data'), ('data', 'analytics—an'), ('analytics—an', 'IDC'), ('IDC', 'four'), ('four', 'pillar'), ('pillar', 'research'), ('research', 'area'), ('area', ','), (',', 'IDC'), ('IDC', ','), (',', 'Tech'), ('Tech', '.')]

>> Trigrams are: 
 [('Big', 'data', 'analytics—an'), ('data', 'analytics—an', 'IDC'), ('analytics—an', 'IDC', 'four'), ('IDC', 'four', 'pillar'), ('four', 'pillar', 'research'), ('pillar', 'research', 'area'), ('research', 'area', ','), ('area', ',', 'IDC'), (',', 'IDC', ','), ('IDC', ',', 'Tech'), (',', 'Tech', '.')]

>> POS Tags are: 
 [('Big', 'NNP'), ('data', 'NNS'), ('analytics—an', 'VBD'), ('IDC', 'NNP'), ('four', 'CD'), ('pillar', 'NN'), ('research', 'NN'), ('area', 'NN'), (',', ','), ('IDC', 'NNP'), (',', ','), ('Tech', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Big data', 'IDC', 'pillar research area', 'IDC', 'Tech']

>> Named Entities are: 
 [('ORGANIZATION', 'IDC'), ('ORGANIZATION', 'IDC'), ('GPE', 'Tech')] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('analytics—an', 'analytics—an'), ('IDC', 'idc'), ('four', 'four'), ('pillar', 'pillar'), ('research', 'research'), ('area', 'area'), (',', ','), ('IDC', 'idc'), (',', ','), ('Tech', 'tech'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('analytics—an', 'analytics—an'), ('IDC', 'idc'), ('four', 'four'), ('pillar', 'pillar'), ('research', 'research'), ('area', 'area'), (',', ','), ('IDC', 'idc'), (',', ','), ('Tech', 'tech'), ('.', '.')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), ('analytics—an', 'analytics—an'), ('IDC', 'IDC'), ('four', 'four'), ('pillar', 'pillar'), ('research', 'research'), ('area', 'area'), (',', ','), ('IDC', 'IDC'), (',', ','), ('Tech', 'Tech'), ('.', '.')]


------------------- Sentence 3 -------------------

Rep. 2013.

>> Tokens are: 
 ['Rep.', '2013', '.']

>> Bigrams are: 
 [('Rep.', '2013'), ('2013', '.')]

>> Trigrams are: 
 [('Rep.', '2013', '.')]

>> POS Tags are: 
 [('Rep.', 'NNP'), ('2013', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Rep.']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Rep.', 'rep.'), ('2013', '2013'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Rep.', 'rep.'), ('2013', '2013'), ('.', '.')]

>> Lemmatization: 
 [('Rep.', 'Rep.'), ('2013', '2013'), ('.', '.')]


------------------- Sentence 4 -------------------

[Online].

>> Tokens are: 
 ['[', 'Online', ']', '.']

>> Bigrams are: 
 [('[', 'Online'), ('Online', ']'), (']', '.')]

>> Trigrams are: 
 [('[', 'Online', ']'), ('Online', ']', '.')]

>> POS Tags are: 
 [('[', 'JJ'), ('Online', 'NNP'), (']', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['[ Online ]']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('Online', 'onlin'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('Online', 'onlin'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('Online', 'Online'), (']', ']'), ('.', '.')]


------------------- Sentence 5 -------------------

Available: http://www.idc.

>> Tokens are: 
 ['Available', ':', 'http', ':', '//www.idc', '.']

>> Bigrams are: 
 [('Available', ':'), (':', 'http'), ('http', ':'), (':', '//www.idc'), ('//www.idc', '.')]

>> Trigrams are: 
 [('Available', ':', 'http'), (':', 'http', ':'), ('http', ':', '//www.idc'), (':', '//www.idc', '.')]

>> POS Tags are: 
 [('Available', 'JJ'), (':', ':'), ('http', 'NN'), (':', ':'), ('//www.idc', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['http', '//www.idc']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Available', 'avail'), (':', ':'), ('http', 'http'), (':', ':'), ('//www.idc', '//www.idc'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Available', 'avail'), (':', ':'), ('http', 'http'), (':', ':'), ('//www.idc', '//www.idc'), ('.', '.')]

>> Lemmatization: 
 [('Available', 'Available'), (':', ':'), ('http', 'http'), (':', ':'), ('//www.idc', '//www.idc'), ('.', '.')]


------------------- Sentence 6 -------------------

com/prodserv/FourPillars/bigData/index.jsp.

>> Tokens are: 
 ['com/prodserv/FourPillars/bigData/index.jsp', '.']

>> Bigrams are: 
 [('com/prodserv/FourPillars/bigData/index.jsp', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('com/prodserv/FourPillars/bigData/index.jsp', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['com/prodserv/FourPillars/bigData/index.jsp']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('com/prodserv/FourPillars/bigData/index.jsp', 'com/prodserv/fourpillars/bigdata/index.jsp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('com/prodserv/FourPillars/bigData/index.jsp', 'com/prodserv/fourpillars/bigdata/index.jsp'), ('.', '.')]

>> Lemmatization: 
 [('com/prodserv/FourPillars/bigData/index.jsp', 'com/prodserv/FourPillars/bigData/index.jsp'), ('.', '.')]



========================================== PARAGRAPH 411 ===========================================

 11. Taft DK. Big data market to reach $46.34 billion by 2018, EWEEK, Tech. Rep. 2013. [Online]. Available: http://www. eweek.com/database/big‑data‑market‑to‑reach‑46.34‑billion‑by‑2018.html. 

------------------- Sentence 1 -------------------

 11.

>> Tokens are: 
 ['11', '.']

>> Bigrams are: 
 [('11', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('11', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('11', '11'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('11', '11'), ('.', '.')]

>> Lemmatization: 
 [('11', '11'), ('.', '.')]


------------------- Sentence 2 -------------------

Taft DK.

>> Tokens are: 
 ['Taft', 'DK', '.']

>> Bigrams are: 
 [('Taft', 'DK'), ('DK', '.')]

>> Trigrams are: 
 [('Taft', 'DK', '.')]

>> POS Tags are: 
 [('Taft', 'NNP'), ('DK', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Taft DK']

>> Named Entities are: 
 [('PERSON', 'Taft')] 

>> Stemming using Porter Stemmer: 
 [('Taft', 'taft'), ('DK', 'dk'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Taft', 'taft'), ('DK', 'dk'), ('.', '.')]

>> Lemmatization: 
 [('Taft', 'Taft'), ('DK', 'DK'), ('.', '.')]


------------------- Sentence 3 -------------------

Big data market to reach $46.34 billion by 2018, EWEEK, Tech.

>> Tokens are: 
 ['Big', 'data', 'market', 'reach', '$', '46.34', 'billion', '2018', ',', 'EWEEK', ',', 'Tech', '.']

>> Bigrams are: 
 [('Big', 'data'), ('data', 'market'), ('market', 'reach'), ('reach', '$'), ('$', '46.34'), ('46.34', 'billion'), ('billion', '2018'), ('2018', ','), (',', 'EWEEK'), ('EWEEK', ','), (',', 'Tech'), ('Tech', '.')]

>> Trigrams are: 
 [('Big', 'data', 'market'), ('data', 'market', 'reach'), ('market', 'reach', '$'), ('reach', '$', '46.34'), ('$', '46.34', 'billion'), ('46.34', 'billion', '2018'), ('billion', '2018', ','), ('2018', ',', 'EWEEK'), (',', 'EWEEK', ','), ('EWEEK', ',', 'Tech'), (',', 'Tech', '.')]

>> POS Tags are: 
 [('Big', 'JJ'), ('data', 'NNS'), ('market', 'NN'), ('reach', 'VBP'), ('$', '$'), ('46.34', 'CD'), ('billion', 'CD'), ('2018', 'CD'), (',', ','), ('EWEEK', 'NNP'), (',', ','), ('Tech', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Big data market', 'EWEEK', 'Tech']

>> Named Entities are: 
 [('ORGANIZATION', 'EWEEK'), ('GPE', 'Tech')] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('market', 'market'), ('reach', 'reach'), ('$', '$'), ('46.34', '46.34'), ('billion', 'billion'), ('2018', '2018'), (',', ','), ('EWEEK', 'eweek'), (',', ','), ('Tech', 'tech'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('market', 'market'), ('reach', 'reach'), ('$', '$'), ('46.34', '46.34'), ('billion', 'billion'), ('2018', '2018'), (',', ','), ('EWEEK', 'eweek'), (',', ','), ('Tech', 'tech'), ('.', '.')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), ('market', 'market'), ('reach', 'reach'), ('$', '$'), ('46.34', '46.34'), ('billion', 'billion'), ('2018', '2018'), (',', ','), ('EWEEK', 'EWEEK'), (',', ','), ('Tech', 'Tech'), ('.', '.')]


------------------- Sentence 4 -------------------

Rep. 2013.

>> Tokens are: 
 ['Rep.', '2013', '.']

>> Bigrams are: 
 [('Rep.', '2013'), ('2013', '.')]

>> Trigrams are: 
 [('Rep.', '2013', '.')]

>> POS Tags are: 
 [('Rep.', 'NNP'), ('2013', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Rep.']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Rep.', 'rep.'), ('2013', '2013'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Rep.', 'rep.'), ('2013', '2013'), ('.', '.')]

>> Lemmatization: 
 [('Rep.', 'Rep.'), ('2013', '2013'), ('.', '.')]


------------------- Sentence 5 -------------------

[Online].

>> Tokens are: 
 ['[', 'Online', ']', '.']

>> Bigrams are: 
 [('[', 'Online'), ('Online', ']'), (']', '.')]

>> Trigrams are: 
 [('[', 'Online', ']'), ('Online', ']', '.')]

>> POS Tags are: 
 [('[', 'JJ'), ('Online', 'NNP'), (']', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['[ Online ]']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('Online', 'onlin'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('Online', 'onlin'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('Online', 'Online'), (']', ']'), ('.', '.')]


------------------- Sentence 6 -------------------

Available: http://www.

>> Tokens are: 
 ['Available', ':', 'http', ':', '//www', '.']

>> Bigrams are: 
 [('Available', ':'), (':', 'http'), ('http', ':'), (':', '//www'), ('//www', '.')]

>> Trigrams are: 
 [('Available', ':', 'http'), (':', 'http', ':'), ('http', ':', '//www'), (':', '//www', '.')]

>> POS Tags are: 
 [('Available', 'JJ'), (':', ':'), ('http', 'NN'), (':', ':'), ('//www', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['http', '//www']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Available', 'avail'), (':', ':'), ('http', 'http'), (':', ':'), ('//www', '//www'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Available', 'avail'), (':', ':'), ('http', 'http'), (':', ':'), ('//www', '//www'), ('.', '.')]

>> Lemmatization: 
 [('Available', 'Available'), (':', ':'), ('http', 'http'), (':', ':'), ('//www', '//www'), ('.', '.')]


------------------- Sentence 7 -------------------

eweek.com/database/big‑data‑market‑to‑reach‑46.34‑billion‑by‑2018.html.

>> Tokens are: 
 ['eweek.com/database/big‑data‑market‑to‑reach‑46.34‑billion‑by‑2018.html', '.']

>> Bigrams are: 
 [('eweek.com/database/big‑data‑market‑to‑reach‑46.34‑billion‑by‑2018.html', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('eweek.com/database/big‑data‑market‑to‑reach‑46.34‑billion‑by‑2018.html', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['eweek.com/database/big‑data‑market‑to‑reach‑46.34‑billion‑by‑2018.html']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('eweek.com/database/big‑data‑market‑to‑reach‑46.34‑billion‑by‑2018.html', 'eweek.com/database/big‑data‑market‑to‑reach‑46.34‑billion‑by‑2018.html'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('eweek.com/database/big‑data‑market‑to‑reach‑46.34‑billion‑by‑2018.html', 'eweek.com/database/big‑data‑market‑to‑reach‑46.34‑billion‑by‑2018.html'), ('.', '.')]

>> Lemmatization: 
 [('eweek.com/database/big‑data‑market‑to‑reach‑46.34‑billion‑by‑2018.html', 'eweek.com/database/big‑data‑market‑to‑reach‑46.34‑billion‑by‑2018.html'), ('.', '.')]



========================================== PARAGRAPH 412 ===========================================

 12. Research A. Big data spending to reach $114 billion in 2018; look for machine learning to drive ana‑ lytics, ABI Research, Tech. Rep. 2013. [Online]. Available: https://www.abiresearch.com/press/ big‑data‑spending‑to‑reach‑114‑billion‑in‑2018‑loo. 

------------------- Sentence 1 -------------------

 12.

>> Tokens are: 
 ['12', '.']

>> Bigrams are: 
 [('12', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('12', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('12', '12'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('12', '12'), ('.', '.')]

>> Lemmatization: 
 [('12', '12'), ('.', '.')]


------------------- Sentence 2 -------------------

Research A.

>> Tokens are: 
 ['Research', 'A', '.']

>> Bigrams are: 
 [('Research', 'A'), ('A', '.')]

>> Trigrams are: 
 [('Research', 'A', '.')]

>> POS Tags are: 
 [('Research', 'NN'), ('A', 'DT'), ('.', '.')]

>> Noun Phrases are: 
 ['Research']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Research', 'research'), ('A', 'a'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Research', 'research'), ('A', 'a'), ('.', '.')]

>> Lemmatization: 
 [('Research', 'Research'), ('A', 'A'), ('.', '.')]


------------------- Sentence 3 -------------------

Big data spending to reach $114 billion in 2018; look for machine learning to drive ana‑ lytics, ABI Research, Tech.

>> Tokens are: 
 ['Big', 'data', 'spending', 'reach', '$', '114', 'billion', '2018', ';', 'look', 'machine', 'learning', 'drive', 'ana‑', 'lytics', ',', 'ABI', 'Research', ',', 'Tech', '.']

>> Bigrams are: 
 [('Big', 'data'), ('data', 'spending'), ('spending', 'reach'), ('reach', '$'), ('$', '114'), ('114', 'billion'), ('billion', '2018'), ('2018', ';'), (';', 'look'), ('look', 'machine'), ('machine', 'learning'), ('learning', 'drive'), ('drive', 'ana‑'), ('ana‑', 'lytics'), ('lytics', ','), (',', 'ABI'), ('ABI', 'Research'), ('Research', ','), (',', 'Tech'), ('Tech', '.')]

>> Trigrams are: 
 [('Big', 'data', 'spending'), ('data', 'spending', 'reach'), ('spending', 'reach', '$'), ('reach', '$', '114'), ('$', '114', 'billion'), ('114', 'billion', '2018'), ('billion', '2018', ';'), ('2018', ';', 'look'), (';', 'look', 'machine'), ('look', 'machine', 'learning'), ('machine', 'learning', 'drive'), ('learning', 'drive', 'ana‑'), ('drive', 'ana‑', 'lytics'), ('ana‑', 'lytics', ','), ('lytics', ',', 'ABI'), (',', 'ABI', 'Research'), ('ABI', 'Research', ','), ('Research', ',', 'Tech'), (',', 'Tech', '.')]

>> POS Tags are: 
 [('Big', 'NNP'), ('data', 'NNS'), ('spending', 'NN'), ('reach', 'VBP'), ('$', '$'), ('114', 'CD'), ('billion', 'CD'), ('2018', 'CD'), (';', ':'), ('look', 'CC'), ('machine', 'NN'), ('learning', 'NN'), ('drive', 'NN'), ('ana‑', 'NN'), ('lytics', 'NNS'), (',', ','), ('ABI', 'NNP'), ('Research', 'NNP'), (',', ','), ('Tech', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Big data spending', 'machine learning drive ana‑ lytics', 'ABI Research', 'Tech']

>> Named Entities are: 
 [('ORGANIZATION', 'ABI Research'), ('GPE', 'Tech')] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('spending', 'spend'), ('reach', 'reach'), ('$', '$'), ('114', '114'), ('billion', 'billion'), ('2018', '2018'), (';', ';'), ('look', 'look'), ('machine', 'machin'), ('learning', 'learn'), ('drive', 'drive'), ('ana‑', 'ana‑'), ('lytics', 'lytic'), (',', ','), ('ABI', 'abi'), ('Research', 'research'), (',', ','), ('Tech', 'tech'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('spending', 'spend'), ('reach', 'reach'), ('$', '$'), ('114', '114'), ('billion', 'billion'), ('2018', '2018'), (';', ';'), ('look', 'look'), ('machine', 'machin'), ('learning', 'learn'), ('drive', 'drive'), ('ana‑', 'ana‑'), ('lytics', 'lytic'), (',', ','), ('ABI', 'abi'), ('Research', 'research'), (',', ','), ('Tech', 'tech'), ('.', '.')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), ('spending', 'spending'), ('reach', 'reach'), ('$', '$'), ('114', '114'), ('billion', 'billion'), ('2018', '2018'), (';', ';'), ('look', 'look'), ('machine', 'machine'), ('learning', 'learning'), ('drive', 'drive'), ('ana‑', 'ana‑'), ('lytics', 'lytics'), (',', ','), ('ABI', 'ABI'), ('Research', 'Research'), (',', ','), ('Tech', 'Tech'), ('.', '.')]


------------------- Sentence 4 -------------------

Rep. 2013.

>> Tokens are: 
 ['Rep.', '2013', '.']

>> Bigrams are: 
 [('Rep.', '2013'), ('2013', '.')]

>> Trigrams are: 
 [('Rep.', '2013', '.')]

>> POS Tags are: 
 [('Rep.', 'NNP'), ('2013', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Rep.']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Rep.', 'rep.'), ('2013', '2013'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Rep.', 'rep.'), ('2013', '2013'), ('.', '.')]

>> Lemmatization: 
 [('Rep.', 'Rep.'), ('2013', '2013'), ('.', '.')]


------------------- Sentence 5 -------------------

[Online].

>> Tokens are: 
 ['[', 'Online', ']', '.']

>> Bigrams are: 
 [('[', 'Online'), ('Online', ']'), (']', '.')]

>> Trigrams are: 
 [('[', 'Online', ']'), ('Online', ']', '.')]

>> POS Tags are: 
 [('[', 'JJ'), ('Online', 'NNP'), (']', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['[ Online ]']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('Online', 'onlin'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('Online', 'onlin'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('Online', 'Online'), (']', ']'), ('.', '.')]


------------------- Sentence 6 -------------------

Available: https://www.abiresearch.com/press/ big‑data‑spending‑to‑reach‑114‑billion‑in‑2018‑loo.

>> Tokens are: 
 ['Available', ':', 'https', ':', '//www.abiresearch.com/press/', 'big‑data‑spending‑to‑reach‑114‑billion‑in‑2018‑loo', '.']

>> Bigrams are: 
 [('Available', ':'), (':', 'https'), ('https', ':'), (':', '//www.abiresearch.com/press/'), ('//www.abiresearch.com/press/', 'big‑data‑spending‑to‑reach‑114‑billion‑in‑2018‑loo'), ('big‑data‑spending‑to‑reach‑114‑billion‑in‑2018‑loo', '.')]

>> Trigrams are: 
 [('Available', ':', 'https'), (':', 'https', ':'), ('https', ':', '//www.abiresearch.com/press/'), (':', '//www.abiresearch.com/press/', 'big‑data‑spending‑to‑reach‑114‑billion‑in‑2018‑loo'), ('//www.abiresearch.com/press/', 'big‑data‑spending‑to‑reach‑114‑billion‑in‑2018‑loo', '.')]

>> POS Tags are: 
 [('Available', 'JJ'), (':', ':'), ('https', 'NN'), (':', ':'), ('//www.abiresearch.com/press/', 'JJ'), ('big‑data‑spending‑to‑reach‑114‑billion‑in‑2018‑loo', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['https', '//www.abiresearch.com/press/ big‑data‑spending‑to‑reach‑114‑billion‑in‑2018‑loo']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Available', 'avail'), (':', ':'), ('https', 'http'), (':', ':'), ('//www.abiresearch.com/press/', '//www.abiresearch.com/press/'), ('big‑data‑spending‑to‑reach‑114‑billion‑in‑2018‑loo', 'big‑data‑spending‑to‑reach‑114‑billion‑in‑2018‑loo'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Available', 'avail'), (':', ':'), ('https', 'https'), (':', ':'), ('//www.abiresearch.com/press/', '//www.abiresearch.com/press/'), ('big‑data‑spending‑to‑reach‑114‑billion‑in‑2018‑loo', 'big‑data‑spending‑to‑reach‑114‑billion‑in‑2018‑loo'), ('.', '.')]

>> Lemmatization: 
 [('Available', 'Available'), (':', ':'), ('https', 'http'), (':', ':'), ('//www.abiresearch.com/press/', '//www.abiresearch.com/press/'), ('big‑data‑spending‑to‑reach‑114‑billion‑in‑2018‑loo', 'big‑data‑spending‑to‑reach‑114‑billion‑in‑2018‑loo'), ('.', '.')]



========================================== PARAGRAPH 413 ===========================================

 13. Furrier J. Big data market $50 billion by 2017—HP vertica comes out #1—according to wikibon  research, SiliconANGLE, Tech. Rep. 2012. [Online]. Available: http://siliconangle.com/blog/2012/02/15/ big‑data‑market‑15‑billion‑by‑2017‑hp‑vertica‑comes‑out‑1‑according‑to‑wikibon‑research/. 

------------------- Sentence 1 -------------------

 13.

>> Tokens are: 
 ['13', '.']

>> Bigrams are: 
 [('13', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('13', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('13', '13'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('13', '13'), ('.', '.')]

>> Lemmatization: 
 [('13', '13'), ('.', '.')]


------------------- Sentence 2 -------------------

Furrier J.

>> Tokens are: 
 ['Furrier', 'J', '.']

>> Bigrams are: 
 [('Furrier', 'J'), ('J', '.')]

>> Trigrams are: 
 [('Furrier', 'J', '.')]

>> POS Tags are: 
 [('Furrier', 'NNP'), ('J', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Furrier J']

>> Named Entities are: 
 [('PERSON', 'Furrier')] 

>> Stemming using Porter Stemmer: 
 [('Furrier', 'furrier'), ('J', 'j'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Furrier', 'furrier'), ('J', 'j'), ('.', '.')]

>> Lemmatization: 
 [('Furrier', 'Furrier'), ('J', 'J'), ('.', '.')]


------------------- Sentence 3 -------------------

Big data market $50 billion by 2017—HP vertica comes out #1—according to wikibon  research, SiliconANGLE, Tech.

>> Tokens are: 
 ['Big', 'data', 'market', '$', '50', 'billion', '2017—HP', 'vertica', 'comes', '#', '1—according', 'wikibon', 'research', ',', 'SiliconANGLE', ',', 'Tech', '.']

>> Bigrams are: 
 [('Big', 'data'), ('data', 'market'), ('market', '$'), ('$', '50'), ('50', 'billion'), ('billion', '2017—HP'), ('2017—HP', 'vertica'), ('vertica', 'comes'), ('comes', '#'), ('#', '1—according'), ('1—according', 'wikibon'), ('wikibon', 'research'), ('research', ','), (',', 'SiliconANGLE'), ('SiliconANGLE', ','), (',', 'Tech'), ('Tech', '.')]

>> Trigrams are: 
 [('Big', 'data', 'market'), ('data', 'market', '$'), ('market', '$', '50'), ('$', '50', 'billion'), ('50', 'billion', '2017—HP'), ('billion', '2017—HP', 'vertica'), ('2017—HP', 'vertica', 'comes'), ('vertica', 'comes', '#'), ('comes', '#', '1—according'), ('#', '1—according', 'wikibon'), ('1—according', 'wikibon', 'research'), ('wikibon', 'research', ','), ('research', ',', 'SiliconANGLE'), (',', 'SiliconANGLE', ','), ('SiliconANGLE', ',', 'Tech'), (',', 'Tech', '.')]

>> POS Tags are: 
 [('Big', 'JJ'), ('data', 'NN'), ('market', 'NN'), ('$', '$'), ('50', 'CD'), ('billion', 'CD'), ('2017—HP', 'CD'), ('vertica', 'NN'), ('comes', 'VBZ'), ('#', '#'), ('1—according', 'VBG'), ('wikibon', 'NN'), ('research', 'NN'), (',', ','), ('SiliconANGLE', 'NNP'), (',', ','), ('Tech', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Big data market', 'vertica', 'wikibon research', 'SiliconANGLE', 'Tech']

>> Named Entities are: 
 [('ORGANIZATION', 'SiliconANGLE'), ('GPE', 'Tech')] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('market', 'market'), ('$', '$'), ('50', '50'), ('billion', 'billion'), ('2017—HP', '2017—hp'), ('vertica', 'vertica'), ('comes', 'come'), ('#', '#'), ('1—according', '1—accord'), ('wikibon', 'wikibon'), ('research', 'research'), (',', ','), ('SiliconANGLE', 'siliconangl'), (',', ','), ('Tech', 'tech'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('market', 'market'), ('$', '$'), ('50', '50'), ('billion', 'billion'), ('2017—HP', '2017—hp'), ('vertica', 'vertica'), ('comes', 'come'), ('#', '#'), ('1—according', '1—accord'), ('wikibon', 'wikibon'), ('research', 'research'), (',', ','), ('SiliconANGLE', 'siliconangl'), (',', ','), ('Tech', 'tech'), ('.', '.')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), ('market', 'market'), ('$', '$'), ('50', '50'), ('billion', 'billion'), ('2017—HP', '2017—HP'), ('vertica', 'vertica'), ('comes', 'come'), ('#', '#'), ('1—according', '1—according'), ('wikibon', 'wikibon'), ('research', 'research'), (',', ','), ('SiliconANGLE', 'SiliconANGLE'), (',', ','), ('Tech', 'Tech'), ('.', '.')]


------------------- Sentence 4 -------------------

Rep. 2012.

>> Tokens are: 
 ['Rep.', '2012', '.']

>> Bigrams are: 
 [('Rep.', '2012'), ('2012', '.')]

>> Trigrams are: 
 [('Rep.', '2012', '.')]

>> POS Tags are: 
 [('Rep.', 'NNP'), ('2012', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Rep.']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Rep.', 'rep.'), ('2012', '2012'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Rep.', 'rep.'), ('2012', '2012'), ('.', '.')]

>> Lemmatization: 
 [('Rep.', 'Rep.'), ('2012', '2012'), ('.', '.')]


------------------- Sentence 5 -------------------

[Online].

>> Tokens are: 
 ['[', 'Online', ']', '.']

>> Bigrams are: 
 [('[', 'Online'), ('Online', ']'), (']', '.')]

>> Trigrams are: 
 [('[', 'Online', ']'), ('Online', ']', '.')]

>> POS Tags are: 
 [('[', 'JJ'), ('Online', 'NNP'), (']', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['[ Online ]']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('Online', 'onlin'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('Online', 'onlin'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('Online', 'Online'), (']', ']'), ('.', '.')]


------------------- Sentence 6 -------------------

Available: http://siliconangle.com/blog/2012/02/15/ big‑data‑market‑15‑billion‑by‑2017‑hp‑vertica‑comes‑out‑1‑according‑to‑wikibon‑research/.

>> Tokens are: 
 ['Available', ':', 'http', ':', '//siliconangle.com/blog/2012/02/15/', 'big‑data‑market‑15‑billion‑by‑2017‑hp‑vertica‑comes‑out‑1‑according‑to‑wikibon‑research/', '.']

>> Bigrams are: 
 [('Available', ':'), (':', 'http'), ('http', ':'), (':', '//siliconangle.com/blog/2012/02/15/'), ('//siliconangle.com/blog/2012/02/15/', 'big‑data‑market‑15‑billion‑by‑2017‑hp‑vertica‑comes‑out‑1‑according‑to‑wikibon‑research/'), ('big‑data‑market‑15‑billion‑by‑2017‑hp‑vertica‑comes‑out‑1‑according‑to‑wikibon‑research/', '.')]

>> Trigrams are: 
 [('Available', ':', 'http'), (':', 'http', ':'), ('http', ':', '//siliconangle.com/blog/2012/02/15/'), (':', '//siliconangle.com/blog/2012/02/15/', 'big‑data‑market‑15‑billion‑by‑2017‑hp‑vertica‑comes‑out‑1‑according‑to‑wikibon‑research/'), ('//siliconangle.com/blog/2012/02/15/', 'big‑data‑market‑15‑billion‑by‑2017‑hp‑vertica‑comes‑out‑1‑according‑to‑wikibon‑research/', '.')]

>> POS Tags are: 
 [('Available', 'JJ'), (':', ':'), ('http', 'NN'), (':', ':'), ('//siliconangle.com/blog/2012/02/15/', 'JJ'), ('big‑data‑market‑15‑billion‑by‑2017‑hp‑vertica‑comes‑out‑1‑according‑to‑wikibon‑research/', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['http', '//siliconangle.com/blog/2012/02/15/ big‑data‑market‑15‑billion‑by‑2017‑hp‑vertica‑comes‑out‑1‑according‑to‑wikibon‑research/']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Available', 'avail'), (':', ':'), ('http', 'http'), (':', ':'), ('//siliconangle.com/blog/2012/02/15/', '//siliconangle.com/blog/2012/02/15/'), ('big‑data‑market‑15‑billion‑by‑2017‑hp‑vertica‑comes‑out‑1‑according‑to‑wikibon‑research/', 'big‑data‑market‑15‑billion‑by‑2017‑hp‑vertica‑comes‑out‑1‑according‑to‑wikibon‑research/'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Available', 'avail'), (':', ':'), ('http', 'http'), (':', ':'), ('//siliconangle.com/blog/2012/02/15/', '//siliconangle.com/blog/2012/02/15/'), ('big‑data‑market‑15‑billion‑by‑2017‑hp‑vertica‑comes‑out‑1‑according‑to‑wikibon‑research/', 'big‑data‑market‑15‑billion‑by‑2017‑hp‑vertica‑comes‑out‑1‑according‑to‑wikibon‑research/'), ('.', '.')]

>> Lemmatization: 
 [('Available', 'Available'), (':', ':'), ('http', 'http'), (':', ':'), ('//siliconangle.com/blog/2012/02/15/', '//siliconangle.com/blog/2012/02/15/'), ('big‑data‑market‑15‑billion‑by‑2017‑hp‑vertica‑comes‑out‑1‑according‑to‑wikibon‑research/', 'big‑data‑market‑15‑billion‑by‑2017‑hp‑vertica‑comes‑out‑1‑according‑to‑wikibon‑research/'), ('.', '.')]



========================================== PARAGRAPH 414 ===========================================

 14. Kelly J, Vellante D, Floyer D. Big data market size and vendor revenues, Wikibon, Tech. Rep. 2014. [Online]. Available:  http://wikibon.org/wiki/v/Big_Data_Market_Size_and_Vendor_Revenues. 

------------------- Sentence 1 -------------------

 14.

>> Tokens are: 
 ['14', '.']

>> Bigrams are: 
 [('14', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('14', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('14', '14'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('14', '14'), ('.', '.')]

>> Lemmatization: 
 [('14', '14'), ('.', '.')]


------------------- Sentence 2 -------------------

Kelly J, Vellante D, Floyer D. Big data market size and vendor revenues, Wikibon, Tech.

>> Tokens are: 
 ['Kelly', 'J', ',', 'Vellante', 'D', ',', 'Floyer', 'D.', 'Big', 'data', 'market', 'size', 'vendor', 'revenues', ',', 'Wikibon', ',', 'Tech', '.']

>> Bigrams are: 
 [('Kelly', 'J'), ('J', ','), (',', 'Vellante'), ('Vellante', 'D'), ('D', ','), (',', 'Floyer'), ('Floyer', 'D.'), ('D.', 'Big'), ('Big', 'data'), ('data', 'market'), ('market', 'size'), ('size', 'vendor'), ('vendor', 'revenues'), ('revenues', ','), (',', 'Wikibon'), ('Wikibon', ','), (',', 'Tech'), ('Tech', '.')]

>> Trigrams are: 
 [('Kelly', 'J', ','), ('J', ',', 'Vellante'), (',', 'Vellante', 'D'), ('Vellante', 'D', ','), ('D', ',', 'Floyer'), (',', 'Floyer', 'D.'), ('Floyer', 'D.', 'Big'), ('D.', 'Big', 'data'), ('Big', 'data', 'market'), ('data', 'market', 'size'), ('market', 'size', 'vendor'), ('size', 'vendor', 'revenues'), ('vendor', 'revenues', ','), ('revenues', ',', 'Wikibon'), (',', 'Wikibon', ','), ('Wikibon', ',', 'Tech'), (',', 'Tech', '.')]

>> POS Tags are: 
 [('Kelly', 'NNP'), ('J', 'NNP'), (',', ','), ('Vellante', 'NNP'), ('D', 'NNP'), (',', ','), ('Floyer', 'NNP'), ('D.', 'NNP'), ('Big', 'NNP'), ('data', 'NN'), ('market', 'NN'), ('size', 'NN'), ('vendor', 'NN'), ('revenues', 'NNS'), (',', ','), ('Wikibon', 'NNP'), (',', ','), ('Tech', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Kelly J', 'Vellante D', 'Floyer D. Big data market size vendor revenues', 'Wikibon', 'Tech']

>> Named Entities are: 
 [('PERSON', 'Kelly'), ('ORGANIZATION', 'J'), ('PERSON', 'Vellante D'), ('PERSON', 'Floyer D.'), ('GPE', 'Wikibon'), ('GPE', 'Tech')] 

>> Stemming using Porter Stemmer: 
 [('Kelly', 'kelli'), ('J', 'j'), (',', ','), ('Vellante', 'vellant'), ('D', 'd'), (',', ','), ('Floyer', 'floyer'), ('D.', 'd.'), ('Big', 'big'), ('data', 'data'), ('market', 'market'), ('size', 'size'), ('vendor', 'vendor'), ('revenues', 'revenu'), (',', ','), ('Wikibon', 'wikibon'), (',', ','), ('Tech', 'tech'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Kelly', 'kelli'), ('J', 'j'), (',', ','), ('Vellante', 'vellant'), ('D', 'd'), (',', ','), ('Floyer', 'floyer'), ('D.', 'd.'), ('Big', 'big'), ('data', 'data'), ('market', 'market'), ('size', 'size'), ('vendor', 'vendor'), ('revenues', 'revenu'), (',', ','), ('Wikibon', 'wikibon'), (',', ','), ('Tech', 'tech'), ('.', '.')]

>> Lemmatization: 
 [('Kelly', 'Kelly'), ('J', 'J'), (',', ','), ('Vellante', 'Vellante'), ('D', 'D'), (',', ','), ('Floyer', 'Floyer'), ('D.', 'D.'), ('Big', 'Big'), ('data', 'data'), ('market', 'market'), ('size', 'size'), ('vendor', 'vendor'), ('revenues', 'revenue'), (',', ','), ('Wikibon', 'Wikibon'), (',', ','), ('Tech', 'Tech'), ('.', '.')]


------------------- Sentence 3 -------------------

Rep. 2014.

>> Tokens are: 
 ['Rep.', '2014', '.']

>> Bigrams are: 
 [('Rep.', '2014'), ('2014', '.')]

>> Trigrams are: 
 [('Rep.', '2014', '.')]

>> POS Tags are: 
 [('Rep.', 'NNP'), ('2014', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Rep.']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Rep.', 'rep.'), ('2014', '2014'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Rep.', 'rep.'), ('2014', '2014'), ('.', '.')]

>> Lemmatization: 
 [('Rep.', 'Rep.'), ('2014', '2014'), ('.', '.')]


------------------- Sentence 4 -------------------

[Online].

>> Tokens are: 
 ['[', 'Online', ']', '.']

>> Bigrams are: 
 [('[', 'Online'), ('Online', ']'), (']', '.')]

>> Trigrams are: 
 [('[', 'Online', ']'), ('Online', ']', '.')]

>> POS Tags are: 
 [('[', 'JJ'), ('Online', 'NNP'), (']', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['[ Online ]']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('Online', 'onlin'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('Online', 'onlin'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('Online', 'Online'), (']', ']'), ('.', '.')]


------------------- Sentence 5 -------------------

Available:  http://wikibon.org/wiki/v/Big_Data_Market_Size_and_Vendor_Revenues.

>> Tokens are: 
 ['Available', ':', 'http', ':', '//wikibon.org/wiki/v/Big_Data_Market_Size_and_Vendor_Revenues', '.']

>> Bigrams are: 
 [('Available', ':'), (':', 'http'), ('http', ':'), (':', '//wikibon.org/wiki/v/Big_Data_Market_Size_and_Vendor_Revenues'), ('//wikibon.org/wiki/v/Big_Data_Market_Size_and_Vendor_Revenues', '.')]

>> Trigrams are: 
 [('Available', ':', 'http'), (':', 'http', ':'), ('http', ':', '//wikibon.org/wiki/v/Big_Data_Market_Size_and_Vendor_Revenues'), (':', '//wikibon.org/wiki/v/Big_Data_Market_Size_and_Vendor_Revenues', '.')]

>> POS Tags are: 
 [('Available', 'JJ'), (':', ':'), ('http', 'NN'), (':', ':'), ('//wikibon.org/wiki/v/Big_Data_Market_Size_and_Vendor_Revenues', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['http', '//wikibon.org/wiki/v/Big_Data_Market_Size_and_Vendor_Revenues']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Available', 'avail'), (':', ':'), ('http', 'http'), (':', ':'), ('//wikibon.org/wiki/v/Big_Data_Market_Size_and_Vendor_Revenues', '//wikibon.org/wiki/v/big_data_market_size_and_vendor_revenu'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Available', 'avail'), (':', ':'), ('http', 'http'), (':', ':'), ('//wikibon.org/wiki/v/Big_Data_Market_Size_and_Vendor_Revenues', '//wikibon.org/wiki/v/big_data_market_size_and_vendor_revenu'), ('.', '.')]

>> Lemmatization: 
 [('Available', 'Available'), (':', ':'), ('http', 'http'), (':', ':'), ('//wikibon.org/wiki/v/Big_Data_Market_Size_and_Vendor_Revenues', '//wikibon.org/wiki/v/Big_Data_Market_Size_and_Vendor_Revenues'), ('.', '.')]



========================================== PARAGRAPH 415 ===========================================

 15. Kelly J, Floyer D, Vellante D, Miniman S. Big data vendor revenue and market fore‑ cast 2012‑2017, Wikibon, Tech. Rep. 2014. [Online]. Available: http://wikibon.org/wiki/v/ Big_Data_Vendor_Revenue_and_Market_Forecast_2012‑2017. 

------------------- Sentence 1 -------------------

 15.

>> Tokens are: 
 ['15', '.']

>> Bigrams are: 
 [('15', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('15', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('15', '15'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('15', '15'), ('.', '.')]

>> Lemmatization: 
 [('15', '15'), ('.', '.')]


------------------- Sentence 2 -------------------

Kelly J, Floyer D, Vellante D, Miniman S. Big data vendor revenue and market fore‑ cast 2012‑2017, Wikibon, Tech.

>> Tokens are: 
 ['Kelly', 'J', ',', 'Floyer', 'D', ',', 'Vellante', 'D', ',', 'Miniman', 'S.', 'Big', 'data', 'vendor', 'revenue', 'market', 'fore‑', 'cast', '2012‑2017', ',', 'Wikibon', ',', 'Tech', '.']

>> Bigrams are: 
 [('Kelly', 'J'), ('J', ','), (',', 'Floyer'), ('Floyer', 'D'), ('D', ','), (',', 'Vellante'), ('Vellante', 'D'), ('D', ','), (',', 'Miniman'), ('Miniman', 'S.'), ('S.', 'Big'), ('Big', 'data'), ('data', 'vendor'), ('vendor', 'revenue'), ('revenue', 'market'), ('market', 'fore‑'), ('fore‑', 'cast'), ('cast', '2012‑2017'), ('2012‑2017', ','), (',', 'Wikibon'), ('Wikibon', ','), (',', 'Tech'), ('Tech', '.')]

>> Trigrams are: 
 [('Kelly', 'J', ','), ('J', ',', 'Floyer'), (',', 'Floyer', 'D'), ('Floyer', 'D', ','), ('D', ',', 'Vellante'), (',', 'Vellante', 'D'), ('Vellante', 'D', ','), ('D', ',', 'Miniman'), (',', 'Miniman', 'S.'), ('Miniman', 'S.', 'Big'), ('S.', 'Big', 'data'), ('Big', 'data', 'vendor'), ('data', 'vendor', 'revenue'), ('vendor', 'revenue', 'market'), ('revenue', 'market', 'fore‑'), ('market', 'fore‑', 'cast'), ('fore‑', 'cast', '2012‑2017'), ('cast', '2012‑2017', ','), ('2012‑2017', ',', 'Wikibon'), (',', 'Wikibon', ','), ('Wikibon', ',', 'Tech'), (',', 'Tech', '.')]

>> POS Tags are: 
 [('Kelly', 'NNP'), ('J', 'NNP'), (',', ','), ('Floyer', 'NNP'), ('D', 'NNP'), (',', ','), ('Vellante', 'NNP'), ('D', 'NNP'), (',', ','), ('Miniman', 'NNP'), ('S.', 'NNP'), ('Big', 'NNP'), ('data', 'NNS'), ('vendor', 'NN'), ('revenue', 'NN'), ('market', 'NN'), ('fore‑', 'VBD'), ('cast', 'RB'), ('2012‑2017', 'CD'), (',', ','), ('Wikibon', 'NNP'), (',', ','), ('Tech', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Kelly J', 'Floyer D', 'Vellante D', 'Miniman S. Big data vendor revenue market', 'Wikibon', 'Tech']

>> Named Entities are: 
 [('PERSON', 'Kelly'), ('ORGANIZATION', 'J'), ('PERSON', 'Floyer D'), ('PERSON', 'Vellante D'), ('PERSON', 'Miniman S.'), ('GPE', 'Wikibon'), ('GPE', 'Tech')] 

>> Stemming using Porter Stemmer: 
 [('Kelly', 'kelli'), ('J', 'j'), (',', ','), ('Floyer', 'floyer'), ('D', 'd'), (',', ','), ('Vellante', 'vellant'), ('D', 'd'), (',', ','), ('Miniman', 'miniman'), ('S.', 's.'), ('Big', 'big'), ('data', 'data'), ('vendor', 'vendor'), ('revenue', 'revenu'), ('market', 'market'), ('fore‑', 'fore‑'), ('cast', 'cast'), ('2012‑2017', '2012‑2017'), (',', ','), ('Wikibon', 'wikibon'), (',', ','), ('Tech', 'tech'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Kelly', 'kelli'), ('J', 'j'), (',', ','), ('Floyer', 'floyer'), ('D', 'd'), (',', ','), ('Vellante', 'vellant'), ('D', 'd'), (',', ','), ('Miniman', 'miniman'), ('S.', 's.'), ('Big', 'big'), ('data', 'data'), ('vendor', 'vendor'), ('revenue', 'revenu'), ('market', 'market'), ('fore‑', 'fore‑'), ('cast', 'cast'), ('2012‑2017', '2012‑2017'), (',', ','), ('Wikibon', 'wikibon'), (',', ','), ('Tech', 'tech'), ('.', '.')]

>> Lemmatization: 
 [('Kelly', 'Kelly'), ('J', 'J'), (',', ','), ('Floyer', 'Floyer'), ('D', 'D'), (',', ','), ('Vellante', 'Vellante'), ('D', 'D'), (',', ','), ('Miniman', 'Miniman'), ('S.', 'S.'), ('Big', 'Big'), ('data', 'data'), ('vendor', 'vendor'), ('revenue', 'revenue'), ('market', 'market'), ('fore‑', 'fore‑'), ('cast', 'cast'), ('2012‑2017', '2012‑2017'), (',', ','), ('Wikibon', 'Wikibon'), (',', ','), ('Tech', 'Tech'), ('.', '.')]


------------------- Sentence 3 -------------------

Rep. 2014.

>> Tokens are: 
 ['Rep.', '2014', '.']

>> Bigrams are: 
 [('Rep.', '2014'), ('2014', '.')]

>> Trigrams are: 
 [('Rep.', '2014', '.')]

>> POS Tags are: 
 [('Rep.', 'NNP'), ('2014', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Rep.']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Rep.', 'rep.'), ('2014', '2014'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Rep.', 'rep.'), ('2014', '2014'), ('.', '.')]

>> Lemmatization: 
 [('Rep.', 'Rep.'), ('2014', '2014'), ('.', '.')]


------------------- Sentence 4 -------------------

[Online].

>> Tokens are: 
 ['[', 'Online', ']', '.']

>> Bigrams are: 
 [('[', 'Online'), ('Online', ']'), (']', '.')]

>> Trigrams are: 
 [('[', 'Online', ']'), ('Online', ']', '.')]

>> POS Tags are: 
 [('[', 'JJ'), ('Online', 'NNP'), (']', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['[ Online ]']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('Online', 'onlin'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('Online', 'onlin'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('Online', 'Online'), (']', ']'), ('.', '.')]


------------------- Sentence 5 -------------------

Available: http://wikibon.org/wiki/v/ Big_Data_Vendor_Revenue_and_Market_Forecast_2012‑2017.

>> Tokens are: 
 ['Available', ':', 'http', ':', '//wikibon.org/wiki/v/', 'Big_Data_Vendor_Revenue_and_Market_Forecast_2012‑2017', '.']

>> Bigrams are: 
 [('Available', ':'), (':', 'http'), ('http', ':'), (':', '//wikibon.org/wiki/v/'), ('//wikibon.org/wiki/v/', 'Big_Data_Vendor_Revenue_and_Market_Forecast_2012‑2017'), ('Big_Data_Vendor_Revenue_and_Market_Forecast_2012‑2017', '.')]

>> Trigrams are: 
 [('Available', ':', 'http'), (':', 'http', ':'), ('http', ':', '//wikibon.org/wiki/v/'), (':', '//wikibon.org/wiki/v/', 'Big_Data_Vendor_Revenue_and_Market_Forecast_2012‑2017'), ('//wikibon.org/wiki/v/', 'Big_Data_Vendor_Revenue_and_Market_Forecast_2012‑2017', '.')]

>> POS Tags are: 
 [('Available', 'JJ'), (':', ':'), ('http', 'NN'), (':', ':'), ('//wikibon.org/wiki/v/', 'JJ'), ('Big_Data_Vendor_Revenue_and_Market_Forecast_2012‑2017', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['http', '//wikibon.org/wiki/v/ Big_Data_Vendor_Revenue_and_Market_Forecast_2012‑2017']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Available', 'avail'), (':', ':'), ('http', 'http'), (':', ':'), ('//wikibon.org/wiki/v/', '//wikibon.org/wiki/v/'), ('Big_Data_Vendor_Revenue_and_Market_Forecast_2012‑2017', 'big_data_vendor_revenue_and_market_forecast_2012‑2017'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Available', 'avail'), (':', ':'), ('http', 'http'), (':', ':'), ('//wikibon.org/wiki/v/', '//wikibon.org/wiki/v/'), ('Big_Data_Vendor_Revenue_and_Market_Forecast_2012‑2017', 'big_data_vendor_revenue_and_market_forecast_2012‑2017'), ('.', '.')]

>> Lemmatization: 
 [('Available', 'Available'), (':', ':'), ('http', 'http'), (':', ':'), ('//wikibon.org/wiki/v/', '//wikibon.org/wiki/v/'), ('Big_Data_Vendor_Revenue_and_Market_Forecast_2012‑2017', 'Big_Data_Vendor_Revenue_and_Market_Forecast_2012‑2017'), ('.', '.')]



========================================== PARAGRAPH 416 ===========================================

 16. Mayer‑Schonberger V, Cukier K. Big data: a revolution that will transform how we live, work, and think. Boston:  Houghton Mifflin Harcourt; 2013. 

------------------- Sentence 1 -------------------

 16.

>> Tokens are: 
 ['16', '.']

>> Bigrams are: 
 [('16', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('16', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('16', '16'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('16', '16'), ('.', '.')]

>> Lemmatization: 
 [('16', '16'), ('.', '.')]


------------------- Sentence 2 -------------------

Mayer‑Schonberger V, Cukier K. Big data: a revolution that will transform how we live, work, and think.

>> Tokens are: 
 ['Mayer‑Schonberger', 'V', ',', 'Cukier', 'K.', 'Big', 'data', ':', 'revolution', 'transform', 'live', ',', 'work', ',', 'think', '.']

>> Bigrams are: 
 [('Mayer‑Schonberger', 'V'), ('V', ','), (',', 'Cukier'), ('Cukier', 'K.'), ('K.', 'Big'), ('Big', 'data'), ('data', ':'), (':', 'revolution'), ('revolution', 'transform'), ('transform', 'live'), ('live', ','), (',', 'work'), ('work', ','), (',', 'think'), ('think', '.')]

>> Trigrams are: 
 [('Mayer‑Schonberger', 'V', ','), ('V', ',', 'Cukier'), (',', 'Cukier', 'K.'), ('Cukier', 'K.', 'Big'), ('K.', 'Big', 'data'), ('Big', 'data', ':'), ('data', ':', 'revolution'), (':', 'revolution', 'transform'), ('revolution', 'transform', 'live'), ('transform', 'live', ','), ('live', ',', 'work'), (',', 'work', ','), ('work', ',', 'think'), (',', 'think', '.')]

>> POS Tags are: 
 [('Mayer‑Schonberger', 'NNP'), ('V', 'NNP'), (',', ','), ('Cukier', 'NNP'), ('K.', 'NNP'), ('Big', 'NNP'), ('data', 'NNS'), (':', ':'), ('revolution', 'NN'), ('transform', 'NN'), ('live', 'JJ'), (',', ','), ('work', 'NN'), (',', ','), ('think', 'VBP'), ('.', '.')]

>> Noun Phrases are: 
 ['Mayer‑Schonberger V', 'Cukier K. Big data', 'revolution transform', 'work']

>> Named Entities are: 
 [('PERSON', 'Cukier K.')] 

>> Stemming using Porter Stemmer: 
 [('Mayer‑Schonberger', 'mayer‑schonberg'), ('V', 'v'), (',', ','), ('Cukier', 'cukier'), ('K.', 'k.'), ('Big', 'big'), ('data', 'data'), (':', ':'), ('revolution', 'revolut'), ('transform', 'transform'), ('live', 'live'), (',', ','), ('work', 'work'), (',', ','), ('think', 'think'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Mayer‑Schonberger', 'mayer‑schonberg'), ('V', 'v'), (',', ','), ('Cukier', 'cukier'), ('K.', 'k.'), ('Big', 'big'), ('data', 'data'), (':', ':'), ('revolution', 'revolut'), ('transform', 'transform'), ('live', 'live'), (',', ','), ('work', 'work'), (',', ','), ('think', 'think'), ('.', '.')]

>> Lemmatization: 
 [('Mayer‑Schonberger', 'Mayer‑Schonberger'), ('V', 'V'), (',', ','), ('Cukier', 'Cukier'), ('K.', 'K.'), ('Big', 'Big'), ('data', 'data'), (':', ':'), ('revolution', 'revolution'), ('transform', 'transform'), ('live', 'live'), (',', ','), ('work', 'work'), (',', ','), ('think', 'think'), ('.', '.')]


------------------- Sentence 3 -------------------

Boston:  Houghton Mifflin Harcourt; 2013.

>> Tokens are: 
 ['Boston', ':', 'Houghton', 'Mifflin', 'Harcourt', ';', '2013', '.']

>> Bigrams are: 
 [('Boston', ':'), (':', 'Houghton'), ('Houghton', 'Mifflin'), ('Mifflin', 'Harcourt'), ('Harcourt', ';'), (';', '2013'), ('2013', '.')]

>> Trigrams are: 
 [('Boston', ':', 'Houghton'), (':', 'Houghton', 'Mifflin'), ('Houghton', 'Mifflin', 'Harcourt'), ('Mifflin', 'Harcourt', ';'), ('Harcourt', ';', '2013'), (';', '2013', '.')]

>> POS Tags are: 
 [('Boston', 'NNP'), (':', ':'), ('Houghton', 'NNP'), ('Mifflin', 'NNP'), ('Harcourt', 'NNP'), (';', ':'), ('2013', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Boston', 'Houghton Mifflin Harcourt']

>> Named Entities are: 
 [('GPE', 'Boston'), ('PERSON', 'Houghton Mifflin Harcourt')] 

>> Stemming using Porter Stemmer: 
 [('Boston', 'boston'), (':', ':'), ('Houghton', 'houghton'), ('Mifflin', 'mifflin'), ('Harcourt', 'harcourt'), (';', ';'), ('2013', '2013'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Boston', 'boston'), (':', ':'), ('Houghton', 'houghton'), ('Mifflin', 'mifflin'), ('Harcourt', 'harcourt'), (';', ';'), ('2013', '2013'), ('.', '.')]

>> Lemmatization: 
 [('Boston', 'Boston'), (':', ':'), ('Houghton', 'Houghton'), ('Mifflin', 'Mifflin'), ('Harcourt', 'Harcourt'), (';', ';'), ('2013', '2013'), ('.', '.')]



========================================== PARAGRAPH 417 ===========================================

 17. Chen H, Chiang RHL, Storey VC. Business intelligence and analytics: from big data to big impact. MIS Quart.  2012;36(4):1165–88. 

------------------- Sentence 1 -------------------

 17.

>> Tokens are: 
 ['17', '.']

>> Bigrams are: 
 [('17', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('17', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('17', '17'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('17', '17'), ('.', '.')]

>> Lemmatization: 
 [('17', '17'), ('.', '.')]


------------------- Sentence 2 -------------------

Chen H, Chiang RHL, Storey VC.

>> Tokens are: 
 ['Chen', 'H', ',', 'Chiang', 'RHL', ',', 'Storey', 'VC', '.']

>> Bigrams are: 
 [('Chen', 'H'), ('H', ','), (',', 'Chiang'), ('Chiang', 'RHL'), ('RHL', ','), (',', 'Storey'), ('Storey', 'VC'), ('VC', '.')]

>> Trigrams are: 
 [('Chen', 'H', ','), ('H', ',', 'Chiang'), (',', 'Chiang', 'RHL'), ('Chiang', 'RHL', ','), ('RHL', ',', 'Storey'), (',', 'Storey', 'VC'), ('Storey', 'VC', '.')]

>> POS Tags are: 
 [('Chen', 'NNP'), ('H', 'NNP'), (',', ','), ('Chiang', 'NNP'), ('RHL', 'NNP'), (',', ','), ('Storey', 'NNP'), ('VC', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Chen H', 'Chiang RHL', 'Storey VC']

>> Named Entities are: 
 [('PERSON', 'Chen'), ('ORGANIZATION', 'H'), ('PERSON', 'Chiang RHL'), ('PERSON', 'Storey VC')] 

>> Stemming using Porter Stemmer: 
 [('Chen', 'chen'), ('H', 'h'), (',', ','), ('Chiang', 'chiang'), ('RHL', 'rhl'), (',', ','), ('Storey', 'storey'), ('VC', 'vc'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Chen', 'chen'), ('H', 'h'), (',', ','), ('Chiang', 'chiang'), ('RHL', 'rhl'), (',', ','), ('Storey', 'storey'), ('VC', 'vc'), ('.', '.')]

>> Lemmatization: 
 [('Chen', 'Chen'), ('H', 'H'), (',', ','), ('Chiang', 'Chiang'), ('RHL', 'RHL'), (',', ','), ('Storey', 'Storey'), ('VC', 'VC'), ('.', '.')]


------------------- Sentence 3 -------------------

Business intelligence and analytics: from big data to big impact.

>> Tokens are: 
 ['Business', 'intelligence', 'analytics', ':', 'big', 'data', 'big', 'impact', '.']

>> Bigrams are: 
 [('Business', 'intelligence'), ('intelligence', 'analytics'), ('analytics', ':'), (':', 'big'), ('big', 'data'), ('data', 'big'), ('big', 'impact'), ('impact', '.')]

>> Trigrams are: 
 [('Business', 'intelligence', 'analytics'), ('intelligence', 'analytics', ':'), ('analytics', ':', 'big'), (':', 'big', 'data'), ('big', 'data', 'big'), ('data', 'big', 'impact'), ('big', 'impact', '.')]

>> POS Tags are: 
 [('Business', 'NN'), ('intelligence', 'NN'), ('analytics', 'NNS'), (':', ':'), ('big', 'JJ'), ('data', 'NNS'), ('big', 'JJ'), ('impact', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Business intelligence analytics', 'big data', 'big impact']

>> Named Entities are: 
 [('GPE', 'Business')] 

>> Stemming using Porter Stemmer: 
 [('Business', 'busi'), ('intelligence', 'intellig'), ('analytics', 'analyt'), (':', ':'), ('big', 'big'), ('data', 'data'), ('big', 'big'), ('impact', 'impact'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Business', 'busi'), ('intelligence', 'intellig'), ('analytics', 'analyt'), (':', ':'), ('big', 'big'), ('data', 'data'), ('big', 'big'), ('impact', 'impact'), ('.', '.')]

>> Lemmatization: 
 [('Business', 'Business'), ('intelligence', 'intelligence'), ('analytics', 'analytics'), (':', ':'), ('big', 'big'), ('data', 'data'), ('big', 'big'), ('impact', 'impact'), ('.', '.')]


------------------- Sentence 4 -------------------

MIS Quart.

>> Tokens are: 
 ['MIS', 'Quart', '.']

>> Bigrams are: 
 [('MIS', 'Quart'), ('Quart', '.')]

>> Trigrams are: 
 [('MIS', 'Quart', '.')]

>> POS Tags are: 
 [('MIS', 'NNP'), ('Quart', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['MIS Quart']

>> Named Entities are: 
 [('ORGANIZATION', 'MIS Quart')] 

>> Stemming using Porter Stemmer: 
 [('MIS', 'mi'), ('Quart', 'quart'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('MIS', 'mis'), ('Quart', 'quart'), ('.', '.')]

>> Lemmatization: 
 [('MIS', 'MIS'), ('Quart', 'Quart'), ('.', '.')]


------------------- Sentence 5 -------------------

2012;36(4):1165–88.

>> Tokens are: 
 ['2012', ';', '36', '(', '4', ')', ':1165–88', '.']

>> Bigrams are: 
 [('2012', ';'), (';', '36'), ('36', '('), ('(', '4'), ('4', ')'), (')', ':1165–88'), (':1165–88', '.')]

>> Trigrams are: 
 [('2012', ';', '36'), (';', '36', '('), ('36', '(', '4'), ('(', '4', ')'), ('4', ')', ':1165–88'), (')', ':1165–88', '.')]

>> POS Tags are: 
 [('2012', 'CD'), (';', ':'), ('36', 'CD'), ('(', '('), ('4', 'CD'), (')', ')'), (':1165–88', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 [':1165–88']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('2012', '2012'), (';', ';'), ('36', '36'), ('(', '('), ('4', '4'), (')', ')'), (':1165–88', ':1165–88'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('2012', '2012'), (';', ';'), ('36', '36'), ('(', '('), ('4', '4'), (')', ')'), (':1165–88', ':1165–88'), ('.', '.')]

>> Lemmatization: 
 [('2012', '2012'), (';', ';'), ('36', '36'), ('(', '('), ('4', '4'), (')', ')'), (':1165–88', ':1165–88'), ('.', '.')]



========================================== PARAGRAPH 418 ===========================================

 18. Kitchin R. The real‑time city? big data and smart urbanism. Geo J. 2014;79(1):1–14.  19. Fayyad UM, Piatetsky‑Shapiro G, Smyth P. From data mining to knowledge discovery in databases. AI Mag.  

------------------- Sentence 1 -------------------

 18.

>> Tokens are: 
 ['18', '.']

>> Bigrams are: 
 [('18', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('18', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('18', '18'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('18', '18'), ('.', '.')]

>> Lemmatization: 
 [('18', '18'), ('.', '.')]


------------------- Sentence 2 -------------------

Kitchin R. The real‑time city?

>> Tokens are: 
 ['Kitchin', 'R.', 'The', 'real‑time', 'city', '?']

>> Bigrams are: 
 [('Kitchin', 'R.'), ('R.', 'The'), ('The', 'real‑time'), ('real‑time', 'city'), ('city', '?')]

>> Trigrams are: 
 [('Kitchin', 'R.', 'The'), ('R.', 'The', 'real‑time'), ('The', 'real‑time', 'city'), ('real‑time', 'city', '?')]

>> POS Tags are: 
 [('Kitchin', 'NNP'), ('R.', 'NNP'), ('The', 'DT'), ('real‑time', 'NN'), ('city', 'NN'), ('?', '.')]

>> Noun Phrases are: 
 ['Kitchin R.', 'The real‑time city']

>> Named Entities are: 
 [('PERSON', 'Kitchin')] 

>> Stemming using Porter Stemmer: 
 [('Kitchin', 'kitchin'), ('R.', 'r.'), ('The', 'the'), ('real‑time', 'real‑tim'), ('city', 'citi'), ('?', '?')]

>> Stemming using Snowball Stemmer: 
 [('Kitchin', 'kitchin'), ('R.', 'r.'), ('The', 'the'), ('real‑time', 'real‑tim'), ('city', 'citi'), ('?', '?')]

>> Lemmatization: 
 [('Kitchin', 'Kitchin'), ('R.', 'R.'), ('The', 'The'), ('real‑time', 'real‑time'), ('city', 'city'), ('?', '?')]


------------------- Sentence 3 -------------------

big data and smart urbanism.

>> Tokens are: 
 ['big', 'data', 'smart', 'urbanism', '.']

>> Bigrams are: 
 [('big', 'data'), ('data', 'smart'), ('smart', 'urbanism'), ('urbanism', '.')]

>> Trigrams are: 
 [('big', 'data', 'smart'), ('data', 'smart', 'urbanism'), ('smart', 'urbanism', '.')]

>> POS Tags are: 
 [('big', 'JJ'), ('data', 'NNS'), ('smart', 'JJ'), ('urbanism', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['big data', 'smart urbanism']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('big', 'big'), ('data', 'data'), ('smart', 'smart'), ('urbanism', 'urban'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('big', 'big'), ('data', 'data'), ('smart', 'smart'), ('urbanism', 'urban'), ('.', '.')]

>> Lemmatization: 
 [('big', 'big'), ('data', 'data'), ('smart', 'smart'), ('urbanism', 'urbanism'), ('.', '.')]


------------------- Sentence 4 -------------------

Geo J.

>> Tokens are: 
 ['Geo', 'J', '.']

>> Bigrams are: 
 [('Geo', 'J'), ('J', '.')]

>> Trigrams are: 
 [('Geo', 'J', '.')]

>> POS Tags are: 
 [('Geo', 'NNP'), ('J', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Geo J']

>> Named Entities are: 
 [('PERSON', 'Geo')] 

>> Stemming using Porter Stemmer: 
 [('Geo', 'geo'), ('J', 'j'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Geo', 'geo'), ('J', 'j'), ('.', '.')]

>> Lemmatization: 
 [('Geo', 'Geo'), ('J', 'J'), ('.', '.')]


------------------- Sentence 5 -------------------

2014;79(1):1–14.

>> Tokens are: 
 ['2014', ';', '79', '(', '1', ')', ':1–14', '.']

>> Bigrams are: 
 [('2014', ';'), (';', '79'), ('79', '('), ('(', '1'), ('1', ')'), (')', ':1–14'), (':1–14', '.')]

>> Trigrams are: 
 [('2014', ';', '79'), (';', '79', '('), ('79', '(', '1'), ('(', '1', ')'), ('1', ')', ':1–14'), (')', ':1–14', '.')]

>> POS Tags are: 
 [('2014', 'CD'), (';', ':'), ('79', 'CD'), ('(', '('), ('1', 'CD'), (')', ')'), (':1–14', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 [':1–14']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('2014', '2014'), (';', ';'), ('79', '79'), ('(', '('), ('1', '1'), (')', ')'), (':1–14', ':1–14'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('2014', '2014'), (';', ';'), ('79', '79'), ('(', '('), ('1', '1'), (')', ')'), (':1–14', ':1–14'), ('.', '.')]

>> Lemmatization: 
 [('2014', '2014'), (';', ';'), ('79', '79'), ('(', '('), ('1', '1'), (')', ')'), (':1–14', ':1–14'), ('.', '.')]


------------------- Sentence 6 -------------------

19.

>> Tokens are: 
 ['19', '.']

>> Bigrams are: 
 [('19', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('19', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('19', '19'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('19', '19'), ('.', '.')]

>> Lemmatization: 
 [('19', '19'), ('.', '.')]


------------------- Sentence 7 -------------------

Fayyad UM, Piatetsky‑Shapiro G, Smyth P. From data mining to knowledge discovery in databases.

>> Tokens are: 
 ['Fayyad', 'UM', ',', 'Piatetsky‑Shapiro', 'G', ',', 'Smyth', 'P.', 'From', 'data', 'mining', 'knowledge', 'discovery', 'databases', '.']

>> Bigrams are: 
 [('Fayyad', 'UM'), ('UM', ','), (',', 'Piatetsky‑Shapiro'), ('Piatetsky‑Shapiro', 'G'), ('G', ','), (',', 'Smyth'), ('Smyth', 'P.'), ('P.', 'From'), ('From', 'data'), ('data', 'mining'), ('mining', 'knowledge'), ('knowledge', 'discovery'), ('discovery', 'databases'), ('databases', '.')]

>> Trigrams are: 
 [('Fayyad', 'UM', ','), ('UM', ',', 'Piatetsky‑Shapiro'), (',', 'Piatetsky‑Shapiro', 'G'), ('Piatetsky‑Shapiro', 'G', ','), ('G', ',', 'Smyth'), (',', 'Smyth', 'P.'), ('Smyth', 'P.', 'From'), ('P.', 'From', 'data'), ('From', 'data', 'mining'), ('data', 'mining', 'knowledge'), ('mining', 'knowledge', 'discovery'), ('knowledge', 'discovery', 'databases'), ('discovery', 'databases', '.')]

>> POS Tags are: 
 [('Fayyad', 'NNP'), ('UM', 'NNP'), (',', ','), ('Piatetsky‑Shapiro', 'NNP'), ('G', 'NNP'), (',', ','), ('Smyth', 'NNP'), ('P.', 'NNP'), ('From', 'NNP'), ('data', 'NN'), ('mining', 'NN'), ('knowledge', 'NN'), ('discovery', 'NN'), ('databases', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['Fayyad UM', 'Piatetsky‑Shapiro G', 'Smyth P. From data mining knowledge discovery databases']

>> Named Entities are: 
 [('PERSON', 'Fayyad'), ('GPE', 'UM'), ('PERSON', 'Smyth')] 

>> Stemming using Porter Stemmer: 
 [('Fayyad', 'fayyad'), ('UM', 'um'), (',', ','), ('Piatetsky‑Shapiro', 'piatetsky‑shapiro'), ('G', 'g'), (',', ','), ('Smyth', 'smyth'), ('P.', 'p.'), ('From', 'from'), ('data', 'data'), ('mining', 'mine'), ('knowledge', 'knowledg'), ('discovery', 'discoveri'), ('databases', 'databas'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Fayyad', 'fayyad'), ('UM', 'um'), (',', ','), ('Piatetsky‑Shapiro', 'piatetsky‑shapiro'), ('G', 'g'), (',', ','), ('Smyth', 'smyth'), ('P.', 'p.'), ('From', 'from'), ('data', 'data'), ('mining', 'mine'), ('knowledge', 'knowledg'), ('discovery', 'discoveri'), ('databases', 'databas'), ('.', '.')]

>> Lemmatization: 
 [('Fayyad', 'Fayyad'), ('UM', 'UM'), (',', ','), ('Piatetsky‑Shapiro', 'Piatetsky‑Shapiro'), ('G', 'G'), (',', ','), ('Smyth', 'Smyth'), ('P.', 'P.'), ('From', 'From'), ('data', 'data'), ('mining', 'mining'), ('knowledge', 'knowledge'), ('discovery', 'discovery'), ('databases', 'database'), ('.', '.')]


------------------- Sentence 8 -------------------

AI Mag.

>> Tokens are: 
 ['AI', 'Mag', '.']

>> Bigrams are: 
 [('AI', 'Mag'), ('Mag', '.')]

>> Trigrams are: 
 [('AI', 'Mag', '.')]

>> POS Tags are: 
 [('AI', 'NNP'), ('Mag', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['AI Mag']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('AI', 'ai'), ('Mag', 'mag'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('AI', 'ai'), ('Mag', 'mag'), ('.', '.')]

>> Lemmatization: 
 [('AI', 'AI'), ('Mag', 'Mag'), ('.', '.')]



========================================== PARAGRAPH 419 ===========================================

1996;17(3):37–54.  20. Han J. Data mining: concepts and techniques. San Francisco: Morgan Kaufmann Publishers Inc.; 2005.  21. Agrawal R, Imieliński T, Swami A. Mining association rules between sets of items in large databases. Proc ACM  

------------------- Sentence 1 -------------------

1996;17(3):37–54.

>> Tokens are: 
 ['1996', ';', '17', '(', '3', ')', ':37–54', '.']

>> Bigrams are: 
 [('1996', ';'), (';', '17'), ('17', '('), ('(', '3'), ('3', ')'), (')', ':37–54'), (':37–54', '.')]

>> Trigrams are: 
 [('1996', ';', '17'), (';', '17', '('), ('17', '(', '3'), ('(', '3', ')'), ('3', ')', ':37–54'), (')', ':37–54', '.')]

>> POS Tags are: 
 [('1996', 'CD'), (';', ':'), ('17', 'CD'), ('(', '('), ('3', 'CD'), (')', ')'), (':37–54', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 [':37–54']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('1996', '1996'), (';', ';'), ('17', '17'), ('(', '('), ('3', '3'), (')', ')'), (':37–54', ':37–54'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('1996', '1996'), (';', ';'), ('17', '17'), ('(', '('), ('3', '3'), (')', ')'), (':37–54', ':37–54'), ('.', '.')]

>> Lemmatization: 
 [('1996', '1996'), (';', ';'), ('17', '17'), ('(', '('), ('3', '3'), (')', ')'), (':37–54', ':37–54'), ('.', '.')]


------------------- Sentence 2 -------------------

20.

>> Tokens are: 
 ['20', '.']

>> Bigrams are: 
 [('20', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('20', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('20', '20'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('20', '20'), ('.', '.')]

>> Lemmatization: 
 [('20', '20'), ('.', '.')]


------------------- Sentence 3 -------------------

Han J.

>> Tokens are: 
 ['Han', 'J', '.']

>> Bigrams are: 
 [('Han', 'J'), ('J', '.')]

>> Trigrams are: 
 [('Han', 'J', '.')]

>> POS Tags are: 
 [('Han', 'NNP'), ('J', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Han J']

>> Named Entities are: 
 [('PERSON', 'Han')] 

>> Stemming using Porter Stemmer: 
 [('Han', 'han'), ('J', 'j'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Han', 'han'), ('J', 'j'), ('.', '.')]

>> Lemmatization: 
 [('Han', 'Han'), ('J', 'J'), ('.', '.')]


------------------- Sentence 4 -------------------

Data mining: concepts and techniques.

>> Tokens are: 
 ['Data', 'mining', ':', 'concepts', 'techniques', '.']

>> Bigrams are: 
 [('Data', 'mining'), ('mining', ':'), (':', 'concepts'), ('concepts', 'techniques'), ('techniques', '.')]

>> Trigrams are: 
 [('Data', 'mining', ':'), ('mining', ':', 'concepts'), (':', 'concepts', 'techniques'), ('concepts', 'techniques', '.')]

>> POS Tags are: 
 [('Data', 'NNP'), ('mining', 'NN'), (':', ':'), ('concepts', 'NNS'), ('techniques', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['Data mining', 'concepts techniques']

>> Named Entities are: 
 [('GPE', 'Data')] 

>> Stemming using Porter Stemmer: 
 [('Data', 'data'), ('mining', 'mine'), (':', ':'), ('concepts', 'concept'), ('techniques', 'techniqu'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Data', 'data'), ('mining', 'mine'), (':', ':'), ('concepts', 'concept'), ('techniques', 'techniqu'), ('.', '.')]

>> Lemmatization: 
 [('Data', 'Data'), ('mining', 'mining'), (':', ':'), ('concepts', 'concept'), ('techniques', 'technique'), ('.', '.')]


------------------- Sentence 5 -------------------

San Francisco: Morgan Kaufmann Publishers Inc.; 2005.

>> Tokens are: 
 ['San', 'Francisco', ':', 'Morgan', 'Kaufmann', 'Publishers', 'Inc.', ';', '2005', '.']

>> Bigrams are: 
 [('San', 'Francisco'), ('Francisco', ':'), (':', 'Morgan'), ('Morgan', 'Kaufmann'), ('Kaufmann', 'Publishers'), ('Publishers', 'Inc.'), ('Inc.', ';'), (';', '2005'), ('2005', '.')]

>> Trigrams are: 
 [('San', 'Francisco', ':'), ('Francisco', ':', 'Morgan'), (':', 'Morgan', 'Kaufmann'), ('Morgan', 'Kaufmann', 'Publishers'), ('Kaufmann', 'Publishers', 'Inc.'), ('Publishers', 'Inc.', ';'), ('Inc.', ';', '2005'), (';', '2005', '.')]

>> POS Tags are: 
 [('San', 'NNP'), ('Francisco', 'NNP'), (':', ':'), ('Morgan', 'NNP'), ('Kaufmann', 'NNP'), ('Publishers', 'NNP'), ('Inc.', 'NNP'), (';', ':'), ('2005', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['San Francisco', 'Morgan Kaufmann Publishers Inc.']

>> Named Entities are: 
 [('GPE', 'San'), ('PERSON', 'Francisco'), ('PERSON', 'Morgan Kaufmann Publishers')] 

>> Stemming using Porter Stemmer: 
 [('San', 'san'), ('Francisco', 'francisco'), (':', ':'), ('Morgan', 'morgan'), ('Kaufmann', 'kaufmann'), ('Publishers', 'publish'), ('Inc.', 'inc.'), (';', ';'), ('2005', '2005'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('San', 'san'), ('Francisco', 'francisco'), (':', ':'), ('Morgan', 'morgan'), ('Kaufmann', 'kaufmann'), ('Publishers', 'publish'), ('Inc.', 'inc.'), (';', ';'), ('2005', '2005'), ('.', '.')]

>> Lemmatization: 
 [('San', 'San'), ('Francisco', 'Francisco'), (':', ':'), ('Morgan', 'Morgan'), ('Kaufmann', 'Kaufmann'), ('Publishers', 'Publishers'), ('Inc.', 'Inc.'), (';', ';'), ('2005', '2005'), ('.', '.')]


------------------- Sentence 6 -------------------

21.

>> Tokens are: 
 ['21', '.']

>> Bigrams are: 
 [('21', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('21', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('21', '21'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('21', '21'), ('.', '.')]

>> Lemmatization: 
 [('21', '21'), ('.', '.')]


------------------- Sentence 7 -------------------

Agrawal R, Imieliński T, Swami A.

>> Tokens are: 
 ['Agrawal', 'R', ',', 'Imieliński', 'T', ',', 'Swami', 'A', '.']

>> Bigrams are: 
 [('Agrawal', 'R'), ('R', ','), (',', 'Imieliński'), ('Imieliński', 'T'), ('T', ','), (',', 'Swami'), ('Swami', 'A'), ('A', '.')]

>> Trigrams are: 
 [('Agrawal', 'R', ','), ('R', ',', 'Imieliński'), (',', 'Imieliński', 'T'), ('Imieliński', 'T', ','), ('T', ',', 'Swami'), (',', 'Swami', 'A'), ('Swami', 'A', '.')]

>> POS Tags are: 
 [('Agrawal', 'NNP'), ('R', 'NNP'), (',', ','), ('Imieliński', 'NNP'), ('T', 'NNP'), (',', ','), ('Swami', 'NNP'), ('A', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Agrawal R', 'Imieliński T', 'Swami A']

>> Named Entities are: 
 [('PERSON', 'Agrawal'), ('ORGANIZATION', 'R'), ('PERSON', 'Imieliński T'), ('PERSON', 'Swami A')] 

>> Stemming using Porter Stemmer: 
 [('Agrawal', 'agraw'), ('R', 'r'), (',', ','), ('Imieliński', 'imieliński'), ('T', 't'), (',', ','), ('Swami', 'swami'), ('A', 'a'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Agrawal', 'agraw'), ('R', 'r'), (',', ','), ('Imieliński', 'imieliński'), ('T', 't'), (',', ','), ('Swami', 'swami'), ('A', 'a'), ('.', '.')]

>> Lemmatization: 
 [('Agrawal', 'Agrawal'), ('R', 'R'), (',', ','), ('Imieliński', 'Imieliński'), ('T', 'T'), (',', ','), ('Swami', 'Swami'), ('A', 'A'), ('.', '.')]


------------------- Sentence 8 -------------------

Mining association rules between sets of items in large databases.

>> Tokens are: 
 ['Mining', 'association', 'rules', 'sets', 'items', 'large', 'databases', '.']

>> Bigrams are: 
 [('Mining', 'association'), ('association', 'rules'), ('rules', 'sets'), ('sets', 'items'), ('items', 'large'), ('large', 'databases'), ('databases', '.')]

>> Trigrams are: 
 [('Mining', 'association', 'rules'), ('association', 'rules', 'sets'), ('rules', 'sets', 'items'), ('sets', 'items', 'large'), ('items', 'large', 'databases'), ('large', 'databases', '.')]

>> POS Tags are: 
 [('Mining', 'VBG'), ('association', 'NN'), ('rules', 'NNS'), ('sets', 'VBZ'), ('items', 'NNS'), ('large', 'JJ'), ('databases', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['association rules', 'items', 'large databases']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Mining', 'mine'), ('association', 'associ'), ('rules', 'rule'), ('sets', 'set'), ('items', 'item'), ('large', 'larg'), ('databases', 'databas'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Mining', 'mine'), ('association', 'associ'), ('rules', 'rule'), ('sets', 'set'), ('items', 'item'), ('large', 'larg'), ('databases', 'databas'), ('.', '.')]

>> Lemmatization: 
 [('Mining', 'Mining'), ('association', 'association'), ('rules', 'rule'), ('sets', 'set'), ('items', 'item'), ('large', 'large'), ('databases', 'database'), ('.', '.')]


------------------- Sentence 9 -------------------

Proc ACM

>> Tokens are: 
 ['Proc', 'ACM']

>> Bigrams are: 
 [('Proc', 'ACM')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Proc', 'NNP'), ('ACM', 'NNP')]

>> Noun Phrases are: 
 ['Proc ACM']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Proc', 'proc'), ('ACM', 'acm')]

>> Stemming using Snowball Stemmer: 
 [('Proc', 'proc'), ('ACM', 'acm')]

>> Lemmatization: 
 [('Proc', 'Proc'), ('ACM', 'ACM')]



========================================== PARAGRAPH 420 ===========================================

SIGMOD Int Conf Manag Data. 1993;22(2):207–16.  22. Witten IH, Frank E. Data mining: practical machine learning tools and techniques. San Francisco: Morgan Kauf‑ 

------------------- Sentence 1 -------------------

SIGMOD Int Conf Manag Data.

>> Tokens are: 
 ['SIGMOD', 'Int', 'Conf', 'Manag', 'Data', '.']

>> Bigrams are: 
 [('SIGMOD', 'Int'), ('Int', 'Conf'), ('Conf', 'Manag'), ('Manag', 'Data'), ('Data', '.')]

>> Trigrams are: 
 [('SIGMOD', 'Int', 'Conf'), ('Int', 'Conf', 'Manag'), ('Conf', 'Manag', 'Data'), ('Manag', 'Data', '.')]

>> POS Tags are: 
 [('SIGMOD', 'NNP'), ('Int', 'NNP'), ('Conf', 'NNP'), ('Manag', 'NNP'), ('Data', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['SIGMOD Int Conf Manag Data']

>> Named Entities are: 
 [('ORGANIZATION', 'SIGMOD'), ('ORGANIZATION', 'Int Conf Manag Data')] 

>> Stemming using Porter Stemmer: 
 [('SIGMOD', 'sigmod'), ('Int', 'int'), ('Conf', 'conf'), ('Manag', 'manag'), ('Data', 'data'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('SIGMOD', 'sigmod'), ('Int', 'int'), ('Conf', 'conf'), ('Manag', 'manag'), ('Data', 'data'), ('.', '.')]

>> Lemmatization: 
 [('SIGMOD', 'SIGMOD'), ('Int', 'Int'), ('Conf', 'Conf'), ('Manag', 'Manag'), ('Data', 'Data'), ('.', '.')]


------------------- Sentence 2 -------------------

1993;22(2):207–16.

>> Tokens are: 
 ['1993', ';', '22', '(', '2', ')', ':207–16', '.']

>> Bigrams are: 
 [('1993', ';'), (';', '22'), ('22', '('), ('(', '2'), ('2', ')'), (')', ':207–16'), (':207–16', '.')]

>> Trigrams are: 
 [('1993', ';', '22'), (';', '22', '('), ('22', '(', '2'), ('(', '2', ')'), ('2', ')', ':207–16'), (')', ':207–16', '.')]

>> POS Tags are: 
 [('1993', 'CD'), (';', ':'), ('22', 'CD'), ('(', '('), ('2', 'CD'), (')', ')'), (':207–16', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 [':207–16']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('1993', '1993'), (';', ';'), ('22', '22'), ('(', '('), ('2', '2'), (')', ')'), (':207–16', ':207–16'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('1993', '1993'), (';', ';'), ('22', '22'), ('(', '('), ('2', '2'), (')', ')'), (':207–16', ':207–16'), ('.', '.')]

>> Lemmatization: 
 [('1993', '1993'), (';', ';'), ('22', '22'), ('(', '('), ('2', '2'), (')', ')'), (':207–16', ':207–16'), ('.', '.')]


------------------- Sentence 3 -------------------

22.

>> Tokens are: 
 ['22', '.']

>> Bigrams are: 
 [('22', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('22', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('22', '22'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('22', '22'), ('.', '.')]

>> Lemmatization: 
 [('22', '22'), ('.', '.')]


------------------- Sentence 4 -------------------

Witten IH, Frank E. Data mining: practical machine learning tools and techniques.

>> Tokens are: 
 ['Witten', 'IH', ',', 'Frank', 'E.', 'Data', 'mining', ':', 'practical', 'machine', 'learning', 'tools', 'techniques', '.']

>> Bigrams are: 
 [('Witten', 'IH'), ('IH', ','), (',', 'Frank'), ('Frank', 'E.'), ('E.', 'Data'), ('Data', 'mining'), ('mining', ':'), (':', 'practical'), ('practical', 'machine'), ('machine', 'learning'), ('learning', 'tools'), ('tools', 'techniques'), ('techniques', '.')]

>> Trigrams are: 
 [('Witten', 'IH', ','), ('IH', ',', 'Frank'), (',', 'Frank', 'E.'), ('Frank', 'E.', 'Data'), ('E.', 'Data', 'mining'), ('Data', 'mining', ':'), ('mining', ':', 'practical'), (':', 'practical', 'machine'), ('practical', 'machine', 'learning'), ('machine', 'learning', 'tools'), ('learning', 'tools', 'techniques'), ('tools', 'techniques', '.')]

>> POS Tags are: 
 [('Witten', 'NNP'), ('IH', 'NNP'), (',', ','), ('Frank', 'NNP'), ('E.', 'NNP'), ('Data', 'NNP'), ('mining', 'NN'), (':', ':'), ('practical', 'JJ'), ('machine', 'NN'), ('learning', 'NN'), ('tools', 'NNS'), ('techniques', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['Witten IH', 'Frank E. Data mining', 'practical machine learning tools techniques']

>> Named Entities are: 
 [('PERSON', 'Witten'), ('GPE', 'IH'), ('PERSON', 'Frank E. Data')] 

>> Stemming using Porter Stemmer: 
 [('Witten', 'witten'), ('IH', 'ih'), (',', ','), ('Frank', 'frank'), ('E.', 'e.'), ('Data', 'data'), ('mining', 'mine'), (':', ':'), ('practical', 'practic'), ('machine', 'machin'), ('learning', 'learn'), ('tools', 'tool'), ('techniques', 'techniqu'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Witten', 'witten'), ('IH', 'ih'), (',', ','), ('Frank', 'frank'), ('E.', 'e.'), ('Data', 'data'), ('mining', 'mine'), (':', ':'), ('practical', 'practic'), ('machine', 'machin'), ('learning', 'learn'), ('tools', 'tool'), ('techniques', 'techniqu'), ('.', '.')]

>> Lemmatization: 
 [('Witten', 'Witten'), ('IH', 'IH'), (',', ','), ('Frank', 'Frank'), ('E.', 'E.'), ('Data', 'Data'), ('mining', 'mining'), (':', ':'), ('practical', 'practical'), ('machine', 'machine'), ('learning', 'learning'), ('tools', 'tool'), ('techniques', 'technique'), ('.', '.')]


------------------- Sentence 5 -------------------

San Francisco: Morgan Kauf‑

>> Tokens are: 
 ['San', 'Francisco', ':', 'Morgan', 'Kauf‑']

>> Bigrams are: 
 [('San', 'Francisco'), ('Francisco', ':'), (':', 'Morgan'), ('Morgan', 'Kauf‑')]

>> Trigrams are: 
 [('San', 'Francisco', ':'), ('Francisco', ':', 'Morgan'), (':', 'Morgan', 'Kauf‑')]

>> POS Tags are: 
 [('San', 'NNP'), ('Francisco', 'NNP'), (':', ':'), ('Morgan', 'NNP'), ('Kauf‑', 'NNP')]

>> Noun Phrases are: 
 ['San Francisco', 'Morgan Kauf‑']

>> Named Entities are: 
 [('GPE', 'San'), ('PERSON', 'Francisco'), ('PERSON', 'Morgan')] 

>> Stemming using Porter Stemmer: 
 [('San', 'san'), ('Francisco', 'francisco'), (':', ':'), ('Morgan', 'morgan'), ('Kauf‑', 'kauf‑')]

>> Stemming using Snowball Stemmer: 
 [('San', 'san'), ('Francisco', 'francisco'), (':', ':'), ('Morgan', 'morgan'), ('Kauf‑', 'kauf‑')]

>> Lemmatization: 
 [('San', 'San'), ('Francisco', 'Francisco'), (':', ':'), ('Morgan', 'Morgan'), ('Kauf‑', 'Kauf‑')]



========================================== PARAGRAPH 421 ===========================================

mann Publishers Inc.; 2005.  23. Abbass H, Newton C, Sarker R. Data mining: a heuristic approach. Hershey: IGI Global; 2002.  24. Cannataro M, Congiusta A, Pugliese A, Talia D, Trunfio P. Distributed data mining on grids: services, tools, and  

------------------- Sentence 1 -------------------

mann Publishers Inc.; 2005.

>> Tokens are: 
 ['mann', 'Publishers', 'Inc.', ';', '2005', '.']

>> Bigrams are: 
 [('mann', 'Publishers'), ('Publishers', 'Inc.'), ('Inc.', ';'), (';', '2005'), ('2005', '.')]

>> Trigrams are: 
 [('mann', 'Publishers', 'Inc.'), ('Publishers', 'Inc.', ';'), ('Inc.', ';', '2005'), (';', '2005', '.')]

>> POS Tags are: 
 [('mann', 'NN'), ('Publishers', 'NNPS'), ('Inc.', 'NNP'), (';', ':'), ('2005', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['mann', 'Inc.']

>> Named Entities are: 
 [('ORGANIZATION', 'Publishers Inc.')] 

>> Stemming using Porter Stemmer: 
 [('mann', 'mann'), ('Publishers', 'publish'), ('Inc.', 'inc.'), (';', ';'), ('2005', '2005'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('mann', 'mann'), ('Publishers', 'publish'), ('Inc.', 'inc.'), (';', ';'), ('2005', '2005'), ('.', '.')]

>> Lemmatization: 
 [('mann', 'mann'), ('Publishers', 'Publishers'), ('Inc.', 'Inc.'), (';', ';'), ('2005', '2005'), ('.', '.')]


------------------- Sentence 2 -------------------

23.

>> Tokens are: 
 ['23', '.']

>> Bigrams are: 
 [('23', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('23', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('23', '23'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('23', '23'), ('.', '.')]

>> Lemmatization: 
 [('23', '23'), ('.', '.')]


------------------- Sentence 3 -------------------

Abbass H, Newton C, Sarker R. Data mining: a heuristic approach.

>> Tokens are: 
 ['Abbass', 'H', ',', 'Newton', 'C', ',', 'Sarker', 'R.', 'Data', 'mining', ':', 'heuristic', 'approach', '.']

>> Bigrams are: 
 [('Abbass', 'H'), ('H', ','), (',', 'Newton'), ('Newton', 'C'), ('C', ','), (',', 'Sarker'), ('Sarker', 'R.'), ('R.', 'Data'), ('Data', 'mining'), ('mining', ':'), (':', 'heuristic'), ('heuristic', 'approach'), ('approach', '.')]

>> Trigrams are: 
 [('Abbass', 'H', ','), ('H', ',', 'Newton'), (',', 'Newton', 'C'), ('Newton', 'C', ','), ('C', ',', 'Sarker'), (',', 'Sarker', 'R.'), ('Sarker', 'R.', 'Data'), ('R.', 'Data', 'mining'), ('Data', 'mining', ':'), ('mining', ':', 'heuristic'), (':', 'heuristic', 'approach'), ('heuristic', 'approach', '.')]

>> POS Tags are: 
 [('Abbass', 'NNP'), ('H', 'NNP'), (',', ','), ('Newton', 'NNP'), ('C', 'NNP'), (',', ','), ('Sarker', 'NNP'), ('R.', 'NNP'), ('Data', 'NNP'), ('mining', 'NN'), (':', ':'), ('heuristic', 'JJ'), ('approach', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Abbass H', 'Newton C', 'Sarker R. Data mining', 'heuristic approach']

>> Named Entities are: 
 [('PERSON', 'Abbass'), ('ORGANIZATION', 'H'), ('GPE', 'Newton'), ('PERSON', 'Sarker R. Data')] 

>> Stemming using Porter Stemmer: 
 [('Abbass', 'abbass'), ('H', 'h'), (',', ','), ('Newton', 'newton'), ('C', 'c'), (',', ','), ('Sarker', 'sarker'), ('R.', 'r.'), ('Data', 'data'), ('mining', 'mine'), (':', ':'), ('heuristic', 'heurist'), ('approach', 'approach'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Abbass', 'abbass'), ('H', 'h'), (',', ','), ('Newton', 'newton'), ('C', 'c'), (',', ','), ('Sarker', 'sarker'), ('R.', 'r.'), ('Data', 'data'), ('mining', 'mine'), (':', ':'), ('heuristic', 'heurist'), ('approach', 'approach'), ('.', '.')]

>> Lemmatization: 
 [('Abbass', 'Abbass'), ('H', 'H'), (',', ','), ('Newton', 'Newton'), ('C', 'C'), (',', ','), ('Sarker', 'Sarker'), ('R.', 'R.'), ('Data', 'Data'), ('mining', 'mining'), (':', ':'), ('heuristic', 'heuristic'), ('approach', 'approach'), ('.', '.')]


------------------- Sentence 4 -------------------

Hershey: IGI Global; 2002.

>> Tokens are: 
 ['Hershey', ':', 'IGI', 'Global', ';', '2002', '.']

>> Bigrams are: 
 [('Hershey', ':'), (':', 'IGI'), ('IGI', 'Global'), ('Global', ';'), (';', '2002'), ('2002', '.')]

>> Trigrams are: 
 [('Hershey', ':', 'IGI'), (':', 'IGI', 'Global'), ('IGI', 'Global', ';'), ('Global', ';', '2002'), (';', '2002', '.')]

>> POS Tags are: 
 [('Hershey', 'NN'), (':', ':'), ('IGI', 'NNP'), ('Global', 'NNP'), (';', ':'), ('2002', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Hershey', 'IGI Global']

>> Named Entities are: 
 [('GPE', 'Hershey'), ('ORGANIZATION', 'IGI Global')] 

>> Stemming using Porter Stemmer: 
 [('Hershey', 'hershey'), (':', ':'), ('IGI', 'igi'), ('Global', 'global'), (';', ';'), ('2002', '2002'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Hershey', 'hershey'), (':', ':'), ('IGI', 'igi'), ('Global', 'global'), (';', ';'), ('2002', '2002'), ('.', '.')]

>> Lemmatization: 
 [('Hershey', 'Hershey'), (':', ':'), ('IGI', 'IGI'), ('Global', 'Global'), (';', ';'), ('2002', '2002'), ('.', '.')]


------------------- Sentence 5 -------------------

24.

>> Tokens are: 
 ['24', '.']

>> Bigrams are: 
 [('24', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('24', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('24', '24'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('24', '24'), ('.', '.')]

>> Lemmatization: 
 [('24', '24'), ('.', '.')]


------------------- Sentence 6 -------------------

Cannataro M, Congiusta A, Pugliese A, Talia D, Trunfio P. Distributed data mining on grids: services, tools, and

>> Tokens are: 
 ['Cannataro', 'M', ',', 'Congiusta', 'A', ',', 'Pugliese', 'A', ',', 'Talia', 'D', ',', 'Trunfio', 'P.', 'Distributed', 'data', 'mining', 'grids', ':', 'services', ',', 'tools', ',']

>> Bigrams are: 
 [('Cannataro', 'M'), ('M', ','), (',', 'Congiusta'), ('Congiusta', 'A'), ('A', ','), (',', 'Pugliese'), ('Pugliese', 'A'), ('A', ','), (',', 'Talia'), ('Talia', 'D'), ('D', ','), (',', 'Trunfio'), ('Trunfio', 'P.'), ('P.', 'Distributed'), ('Distributed', 'data'), ('data', 'mining'), ('mining', 'grids'), ('grids', ':'), (':', 'services'), ('services', ','), (',', 'tools'), ('tools', ',')]

>> Trigrams are: 
 [('Cannataro', 'M', ','), ('M', ',', 'Congiusta'), (',', 'Congiusta', 'A'), ('Congiusta', 'A', ','), ('A', ',', 'Pugliese'), (',', 'Pugliese', 'A'), ('Pugliese', 'A', ','), ('A', ',', 'Talia'), (',', 'Talia', 'D'), ('Talia', 'D', ','), ('D', ',', 'Trunfio'), (',', 'Trunfio', 'P.'), ('Trunfio', 'P.', 'Distributed'), ('P.', 'Distributed', 'data'), ('Distributed', 'data', 'mining'), ('data', 'mining', 'grids'), ('mining', 'grids', ':'), ('grids', ':', 'services'), (':', 'services', ','), ('services', ',', 'tools'), (',', 'tools', ',')]

>> POS Tags are: 
 [('Cannataro', 'NNP'), ('M', 'NNP'), (',', ','), ('Congiusta', 'NNP'), ('A', 'NNP'), (',', ','), ('Pugliese', 'NNP'), ('A', 'NNP'), (',', ','), ('Talia', 'NNP'), ('D', 'NNP'), (',', ','), ('Trunfio', 'NNP'), ('P.', 'NNP'), ('Distributed', 'NNP'), ('data', 'NN'), ('mining', 'NN'), ('grids', 'NNS'), (':', ':'), ('services', 'NNS'), (',', ','), ('tools', 'NNS'), (',', ',')]

>> Noun Phrases are: 
 ['Cannataro M', 'Congiusta A', 'Pugliese A', 'Talia D', 'Trunfio P. Distributed data mining grids', 'services', 'tools']

>> Named Entities are: 
 [('PERSON', 'Cannataro'), ('PERSON', 'Congiusta A'), ('PERSON', 'Pugliese A'), ('PERSON', 'Talia D'), ('PERSON', 'Trunfio P. Distributed')] 

>> Stemming using Porter Stemmer: 
 [('Cannataro', 'cannataro'), ('M', 'm'), (',', ','), ('Congiusta', 'congiusta'), ('A', 'a'), (',', ','), ('Pugliese', 'puglies'), ('A', 'a'), (',', ','), ('Talia', 'talia'), ('D', 'd'), (',', ','), ('Trunfio', 'trunfio'), ('P.', 'p.'), ('Distributed', 'distribut'), ('data', 'data'), ('mining', 'mine'), ('grids', 'grid'), (':', ':'), ('services', 'servic'), (',', ','), ('tools', 'tool'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('Cannataro', 'cannataro'), ('M', 'm'), (',', ','), ('Congiusta', 'congiusta'), ('A', 'a'), (',', ','), ('Pugliese', 'puglies'), ('A', 'a'), (',', ','), ('Talia', 'talia'), ('D', 'd'), (',', ','), ('Trunfio', 'trunfio'), ('P.', 'p.'), ('Distributed', 'distribut'), ('data', 'data'), ('mining', 'mine'), ('grids', 'grid'), (':', ':'), ('services', 'servic'), (',', ','), ('tools', 'tool'), (',', ',')]

>> Lemmatization: 
 [('Cannataro', 'Cannataro'), ('M', 'M'), (',', ','), ('Congiusta', 'Congiusta'), ('A', 'A'), (',', ','), ('Pugliese', 'Pugliese'), ('A', 'A'), (',', ','), ('Talia', 'Talia'), ('D', 'D'), (',', ','), ('Trunfio', 'Trunfio'), ('P.', 'P.'), ('Distributed', 'Distributed'), ('data', 'data'), ('mining', 'mining'), ('grids', 'grid'), (':', ':'), ('services', 'service'), (',', ','), ('tools', 'tool'), (',', ',')]



========================================== PARAGRAPH 422 ===========================================

applications. IEEE Trans Syst Man Cyber Part B Cyber. 2004;34(6):2451–65.

------------------- Sentence 1 -------------------

applications.

>> Tokens are: 
 ['applications', '.']

>> Bigrams are: 
 [('applications', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('applications', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['applications']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('applications', 'applic'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('applications', 'applic'), ('.', '.')]

>> Lemmatization: 
 [('applications', 'application'), ('.', '.')]


------------------- Sentence 2 -------------------

IEEE Trans Syst Man Cyber Part B Cyber.

>> Tokens are: 
 ['IEEE', 'Trans', 'Syst', 'Man', 'Cyber', 'Part', 'B', 'Cyber', '.']

>> Bigrams are: 
 [('IEEE', 'Trans'), ('Trans', 'Syst'), ('Syst', 'Man'), ('Man', 'Cyber'), ('Cyber', 'Part'), ('Part', 'B'), ('B', 'Cyber'), ('Cyber', '.')]

>> Trigrams are: 
 [('IEEE', 'Trans', 'Syst'), ('Trans', 'Syst', 'Man'), ('Syst', 'Man', 'Cyber'), ('Man', 'Cyber', 'Part'), ('Cyber', 'Part', 'B'), ('Part', 'B', 'Cyber'), ('B', 'Cyber', '.')]

>> POS Tags are: 
 [('IEEE', 'NNP'), ('Trans', 'NNP'), ('Syst', 'NNP'), ('Man', 'NNP'), ('Cyber', 'NNP'), ('Part', 'NNP'), ('B', 'NNP'), ('Cyber', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['IEEE Trans Syst Man Cyber Part B Cyber']

>> Named Entities are: 
 [('ORGANIZATION', 'IEEE'), ('PERSON', 'Trans Syst Man')] 

>> Stemming using Porter Stemmer: 
 [('IEEE', 'ieee'), ('Trans', 'tran'), ('Syst', 'syst'), ('Man', 'man'), ('Cyber', 'cyber'), ('Part', 'part'), ('B', 'b'), ('Cyber', 'cyber'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('IEEE', 'ieee'), ('Trans', 'tran'), ('Syst', 'syst'), ('Man', 'man'), ('Cyber', 'cyber'), ('Part', 'part'), ('B', 'b'), ('Cyber', 'cyber'), ('.', '.')]

>> Lemmatization: 
 [('IEEE', 'IEEE'), ('Trans', 'Trans'), ('Syst', 'Syst'), ('Man', 'Man'), ('Cyber', 'Cyber'), ('Part', 'Part'), ('B', 'B'), ('Cyber', 'Cyber'), ('.', '.')]


------------------- Sentence 3 -------------------

2004;34(6):2451–65.

>> Tokens are: 
 ['2004', ';', '34', '(', '6', ')', ':2451–65', '.']

>> Bigrams are: 
 [('2004', ';'), (';', '34'), ('34', '('), ('(', '6'), ('6', ')'), (')', ':2451–65'), (':2451–65', '.')]

>> Trigrams are: 
 [('2004', ';', '34'), (';', '34', '('), ('34', '(', '6'), ('(', '6', ')'), ('6', ')', ':2451–65'), (')', ':2451–65', '.')]

>> POS Tags are: 
 [('2004', 'CD'), (';', ':'), ('34', 'CD'), ('(', '('), ('6', 'CD'), (')', ')'), (':2451–65', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 [':2451–65']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('2004', '2004'), (';', ';'), ('34', '34'), ('(', '('), ('6', '6'), (')', ')'), (':2451–65', ':2451–65'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('2004', '2004'), (';', ';'), ('34', '34'), ('(', '('), ('6', '6'), (')', ')'), (':2451–65', ':2451–65'), ('.', '.')]

>> Lemmatization: 
 [('2004', '2004'), (';', ';'), ('34', '34'), ('(', '('), ('6', '6'), (')', ')'), (':2451–65', ':2451–65'), ('.', '.')]



========================================== PARAGRAPH 423 ===========================================

Page 29 of 32Tsai et al. Journal of Big Data  (2015) 2:21  

------------------- Sentence 1 -------------------

Page 29 of 32Tsai et al.

>> Tokens are: 
 ['Page', '29', '32Tsai', 'et', 'al', '.']

>> Bigrams are: 
 [('Page', '29'), ('29', '32Tsai'), ('32Tsai', 'et'), ('et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('Page', '29', '32Tsai'), ('29', '32Tsai', 'et'), ('32Tsai', 'et', 'al'), ('et', 'al', '.')]

>> POS Tags are: 
 [('Page', 'NN'), ('29', 'CD'), ('32Tsai', 'CD'), ('et', 'NN'), ('al', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Page', 'et al']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Page', 'page'), ('29', '29'), ('32Tsai', '32tsai'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Page', 'page'), ('29', '29'), ('32Tsai', '32tsai'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('Page', 'Page'), ('29', '29'), ('32Tsai', '32Tsai'), ('et', 'et'), ('al', 'al'), ('.', '.')]


------------------- Sentence 2 -------------------

Journal of Big Data  (2015) 2:21

>> Tokens are: 
 ['Journal', 'Big', 'Data', '(', '2015', ')', '2:21']

>> Bigrams are: 
 [('Journal', 'Big'), ('Big', 'Data'), ('Data', '('), ('(', '2015'), ('2015', ')'), (')', '2:21')]

>> Trigrams are: 
 [('Journal', 'Big', 'Data'), ('Big', 'Data', '('), ('Data', '(', '2015'), ('(', '2015', ')'), ('2015', ')', '2:21')]

>> POS Tags are: 
 [('Journal', 'NNP'), ('Big', 'NNP'), ('Data', 'NNP'), ('(', '('), ('2015', 'CD'), (')', ')'), ('2:21', 'CD')]

>> Noun Phrases are: 
 ['Journal Big Data']

>> Named Entities are: 
 [('PERSON', 'Journal')] 

>> Stemming using Porter Stemmer: 
 [('Journal', 'journal'), ('Big', 'big'), ('Data', 'data'), ('(', '('), ('2015', '2015'), (')', ')'), ('2:21', '2:21')]

>> Stemming using Snowball Stemmer: 
 [('Journal', 'journal'), ('Big', 'big'), ('Data', 'data'), ('(', '('), ('2015', '2015'), (')', ')'), ('2:21', '2:21')]

>> Lemmatization: 
 [('Journal', 'Journal'), ('Big', 'Big'), ('Data', 'Data'), ('(', '('), ('2015', '2015'), (')', ')'), ('2:21', '2:21')]



========================================== PARAGRAPH 424 ===========================================

 25. Krishna K, Murty MN. Genetic k‑means algorithm. IEEE Trans Syst Man Cyber Part B Cyber. 1999;29(3):433–9.  26. Tsai C‑W, Lai C‑F, Chiang M‑C, Yang L. Data mining for internet of things: a survey. IEEE Commun Surveys Tutor.  

------------------- Sentence 1 -------------------

 25.

>> Tokens are: 
 ['25', '.']

>> Bigrams are: 
 [('25', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('25', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('25', '25'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('25', '25'), ('.', '.')]

>> Lemmatization: 
 [('25', '25'), ('.', '.')]


------------------- Sentence 2 -------------------

Krishna K, Murty MN.

>> Tokens are: 
 ['Krishna', 'K', ',', 'Murty', 'MN', '.']

>> Bigrams are: 
 [('Krishna', 'K'), ('K', ','), (',', 'Murty'), ('Murty', 'MN'), ('MN', '.')]

>> Trigrams are: 
 [('Krishna', 'K', ','), ('K', ',', 'Murty'), (',', 'Murty', 'MN'), ('Murty', 'MN', '.')]

>> POS Tags are: 
 [('Krishna', 'NNP'), ('K', 'NNP'), (',', ','), ('Murty', 'NNP'), ('MN', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Krishna K', 'Murty MN']

>> Named Entities are: 
 [('PERSON', 'Krishna'), ('ORGANIZATION', 'K'), ('PERSON', 'Murty MN')] 

>> Stemming using Porter Stemmer: 
 [('Krishna', 'krishna'), ('K', 'k'), (',', ','), ('Murty', 'murti'), ('MN', 'mn'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Krishna', 'krishna'), ('K', 'k'), (',', ','), ('Murty', 'murti'), ('MN', 'mn'), ('.', '.')]

>> Lemmatization: 
 [('Krishna', 'Krishna'), ('K', 'K'), (',', ','), ('Murty', 'Murty'), ('MN', 'MN'), ('.', '.')]


------------------- Sentence 3 -------------------

Genetic k‑means algorithm.

>> Tokens are: 
 ['Genetic', 'k‑means', 'algorithm', '.']

>> Bigrams are: 
 [('Genetic', 'k‑means'), ('k‑means', 'algorithm'), ('algorithm', '.')]

>> Trigrams are: 
 [('Genetic', 'k‑means', 'algorithm'), ('k‑means', 'algorithm', '.')]

>> POS Tags are: 
 [('Genetic', 'JJ'), ('k‑means', 'NNS'), ('algorithm', 'VBP'), ('.', '.')]

>> Noun Phrases are: 
 ['Genetic k‑means']

>> Named Entities are: 
 [('GPE', 'Genetic')] 

>> Stemming using Porter Stemmer: 
 [('Genetic', 'genet'), ('k‑means', 'k‑mean'), ('algorithm', 'algorithm'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Genetic', 'genet'), ('k‑means', 'k‑mean'), ('algorithm', 'algorithm'), ('.', '.')]

>> Lemmatization: 
 [('Genetic', 'Genetic'), ('k‑means', 'k‑means'), ('algorithm', 'algorithm'), ('.', '.')]


------------------- Sentence 4 -------------------

IEEE Trans Syst Man Cyber Part B Cyber.

>> Tokens are: 
 ['IEEE', 'Trans', 'Syst', 'Man', 'Cyber', 'Part', 'B', 'Cyber', '.']

>> Bigrams are: 
 [('IEEE', 'Trans'), ('Trans', 'Syst'), ('Syst', 'Man'), ('Man', 'Cyber'), ('Cyber', 'Part'), ('Part', 'B'), ('B', 'Cyber'), ('Cyber', '.')]

>> Trigrams are: 
 [('IEEE', 'Trans', 'Syst'), ('Trans', 'Syst', 'Man'), ('Syst', 'Man', 'Cyber'), ('Man', 'Cyber', 'Part'), ('Cyber', 'Part', 'B'), ('Part', 'B', 'Cyber'), ('B', 'Cyber', '.')]

>> POS Tags are: 
 [('IEEE', 'NNP'), ('Trans', 'NNP'), ('Syst', 'NNP'), ('Man', 'NNP'), ('Cyber', 'NNP'), ('Part', 'NNP'), ('B', 'NNP'), ('Cyber', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['IEEE Trans Syst Man Cyber Part B Cyber']

>> Named Entities are: 
 [('ORGANIZATION', 'IEEE'), ('PERSON', 'Trans Syst Man')] 

>> Stemming using Porter Stemmer: 
 [('IEEE', 'ieee'), ('Trans', 'tran'), ('Syst', 'syst'), ('Man', 'man'), ('Cyber', 'cyber'), ('Part', 'part'), ('B', 'b'), ('Cyber', 'cyber'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('IEEE', 'ieee'), ('Trans', 'tran'), ('Syst', 'syst'), ('Man', 'man'), ('Cyber', 'cyber'), ('Part', 'part'), ('B', 'b'), ('Cyber', 'cyber'), ('.', '.')]

>> Lemmatization: 
 [('IEEE', 'IEEE'), ('Trans', 'Trans'), ('Syst', 'Syst'), ('Man', 'Man'), ('Cyber', 'Cyber'), ('Part', 'Part'), ('B', 'B'), ('Cyber', 'Cyber'), ('.', '.')]


------------------- Sentence 5 -------------------

1999;29(3):433–9.

>> Tokens are: 
 ['1999', ';', '29', '(', '3', ')', ':433–9', '.']

>> Bigrams are: 
 [('1999', ';'), (';', '29'), ('29', '('), ('(', '3'), ('3', ')'), (')', ':433–9'), (':433–9', '.')]

>> Trigrams are: 
 [('1999', ';', '29'), (';', '29', '('), ('29', '(', '3'), ('(', '3', ')'), ('3', ')', ':433–9'), (')', ':433–9', '.')]

>> POS Tags are: 
 [('1999', 'CD'), (';', ':'), ('29', 'CD'), ('(', '('), ('3', 'CD'), (')', ')'), (':433–9', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 [':433–9']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('1999', '1999'), (';', ';'), ('29', '29'), ('(', '('), ('3', '3'), (')', ')'), (':433–9', ':433–9'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('1999', '1999'), (';', ';'), ('29', '29'), ('(', '('), ('3', '3'), (')', ')'), (':433–9', ':433–9'), ('.', '.')]

>> Lemmatization: 
 [('1999', '1999'), (';', ';'), ('29', '29'), ('(', '('), ('3', '3'), (')', ')'), (':433–9', ':433–9'), ('.', '.')]


------------------- Sentence 6 -------------------

26.

>> Tokens are: 
 ['26', '.']

>> Bigrams are: 
 [('26', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('26', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('26', '26'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('26', '26'), ('.', '.')]

>> Lemmatization: 
 [('26', '26'), ('.', '.')]


------------------- Sentence 7 -------------------

Tsai C‑W, Lai C‑F, Chiang M‑C, Yang L. Data mining for internet of things: a survey.

>> Tokens are: 
 ['Tsai', 'C‑W', ',', 'Lai', 'C‑F', ',', 'Chiang', 'M‑C', ',', 'Yang', 'L.', 'Data', 'mining', 'internet', 'things', ':', 'survey', '.']

>> Bigrams are: 
 [('Tsai', 'C‑W'), ('C‑W', ','), (',', 'Lai'), ('Lai', 'C‑F'), ('C‑F', ','), (',', 'Chiang'), ('Chiang', 'M‑C'), ('M‑C', ','), (',', 'Yang'), ('Yang', 'L.'), ('L.', 'Data'), ('Data', 'mining'), ('mining', 'internet'), ('internet', 'things'), ('things', ':'), (':', 'survey'), ('survey', '.')]

>> Trigrams are: 
 [('Tsai', 'C‑W', ','), ('C‑W', ',', 'Lai'), (',', 'Lai', 'C‑F'), ('Lai', 'C‑F', ','), ('C‑F', ',', 'Chiang'), (',', 'Chiang', 'M‑C'), ('Chiang', 'M‑C', ','), ('M‑C', ',', 'Yang'), (',', 'Yang', 'L.'), ('Yang', 'L.', 'Data'), ('L.', 'Data', 'mining'), ('Data', 'mining', 'internet'), ('mining', 'internet', 'things'), ('internet', 'things', ':'), ('things', ':', 'survey'), (':', 'survey', '.')]

>> POS Tags are: 
 [('Tsai', 'NNP'), ('C‑W', 'NNP'), (',', ','), ('Lai', 'NNP'), ('C‑F', 'NNP'), (',', ','), ('Chiang', 'NNP'), ('M‑C', 'NNP'), (',', ','), ('Yang', 'NNP'), ('L.', 'NNP'), ('Data', 'NNP'), ('mining', 'NN'), ('internet', 'NN'), ('things', 'NNS'), (':', ':'), ('survey', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Tsai C‑W', 'Lai C‑F', 'Chiang M‑C', 'Yang L. Data mining internet things', 'survey']

>> Named Entities are: 
 [('PERSON', 'Tsai'), ('PERSON', 'Lai C‑F'), ('PERSON', 'Chiang M‑C'), ('PERSON', 'Yang L. Data')] 

>> Stemming using Porter Stemmer: 
 [('Tsai', 'tsai'), ('C‑W', 'c‑w'), (',', ','), ('Lai', 'lai'), ('C‑F', 'c‑f'), (',', ','), ('Chiang', 'chiang'), ('M‑C', 'm‑c'), (',', ','), ('Yang', 'yang'), ('L.', 'l.'), ('Data', 'data'), ('mining', 'mine'), ('internet', 'internet'), ('things', 'thing'), (':', ':'), ('survey', 'survey'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Tsai', 'tsai'), ('C‑W', 'c‑w'), (',', ','), ('Lai', 'lai'), ('C‑F', 'c‑f'), (',', ','), ('Chiang', 'chiang'), ('M‑C', 'm‑c'), (',', ','), ('Yang', 'yang'), ('L.', 'l.'), ('Data', 'data'), ('mining', 'mine'), ('internet', 'internet'), ('things', 'thing'), (':', ':'), ('survey', 'survey'), ('.', '.')]

>> Lemmatization: 
 [('Tsai', 'Tsai'), ('C‑W', 'C‑W'), (',', ','), ('Lai', 'Lai'), ('C‑F', 'C‑F'), (',', ','), ('Chiang', 'Chiang'), ('M‑C', 'M‑C'), (',', ','), ('Yang', 'Yang'), ('L.', 'L.'), ('Data', 'Data'), ('mining', 'mining'), ('internet', 'internet'), ('things', 'thing'), (':', ':'), ('survey', 'survey'), ('.', '.')]


------------------- Sentence 8 -------------------

IEEE Commun Surveys Tutor.

>> Tokens are: 
 ['IEEE', 'Commun', 'Surveys', 'Tutor', '.']

>> Bigrams are: 
 [('IEEE', 'Commun'), ('Commun', 'Surveys'), ('Surveys', 'Tutor'), ('Tutor', '.')]

>> Trigrams are: 
 [('IEEE', 'Commun', 'Surveys'), ('Commun', 'Surveys', 'Tutor'), ('Surveys', 'Tutor', '.')]

>> POS Tags are: 
 [('IEEE', 'NNP'), ('Commun', 'NNP'), ('Surveys', 'NNP'), ('Tutor', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['IEEE Commun Surveys Tutor']

>> Named Entities are: 
 [('ORGANIZATION', 'IEEE'), ('ORGANIZATION', 'Commun Surveys Tutor')] 

>> Stemming using Porter Stemmer: 
 [('IEEE', 'ieee'), ('Commun', 'commun'), ('Surveys', 'survey'), ('Tutor', 'tutor'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('IEEE', 'ieee'), ('Commun', 'commun'), ('Surveys', 'survey'), ('Tutor', 'tutor'), ('.', '.')]

>> Lemmatization: 
 [('IEEE', 'IEEE'), ('Commun', 'Commun'), ('Surveys', 'Surveys'), ('Tutor', 'Tutor'), ('.', '.')]



========================================== PARAGRAPH 425 ===========================================

2014;16(1):77–97.  27. Jain AK, Murty MN, Flynn PJ. Data clustering: a review. ACM Comp Surveys. 1999;31(3):264–323.  28. McQueen JB. Some methods of classification and analysis of multivariate observations. In: Proceedings of the  

------------------- Sentence 1 -------------------

2014;16(1):77–97.

>> Tokens are: 
 ['2014', ';', '16', '(', '1', ')', ':77–97', '.']

>> Bigrams are: 
 [('2014', ';'), (';', '16'), ('16', '('), ('(', '1'), ('1', ')'), (')', ':77–97'), (':77–97', '.')]

>> Trigrams are: 
 [('2014', ';', '16'), (';', '16', '('), ('16', '(', '1'), ('(', '1', ')'), ('1', ')', ':77–97'), (')', ':77–97', '.')]

>> POS Tags are: 
 [('2014', 'CD'), (';', ':'), ('16', 'CD'), ('(', '('), ('1', 'CD'), (')', ')'), (':77–97', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 [':77–97']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('2014', '2014'), (';', ';'), ('16', '16'), ('(', '('), ('1', '1'), (')', ')'), (':77–97', ':77–97'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('2014', '2014'), (';', ';'), ('16', '16'), ('(', '('), ('1', '1'), (')', ')'), (':77–97', ':77–97'), ('.', '.')]

>> Lemmatization: 
 [('2014', '2014'), (';', ';'), ('16', '16'), ('(', '('), ('1', '1'), (')', ')'), (':77–97', ':77–97'), ('.', '.')]


------------------- Sentence 2 -------------------

27.

>> Tokens are: 
 ['27', '.']

>> Bigrams are: 
 [('27', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('27', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('27', '27'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('27', '27'), ('.', '.')]

>> Lemmatization: 
 [('27', '27'), ('.', '.')]


------------------- Sentence 3 -------------------

Jain AK, Murty MN, Flynn PJ.

>> Tokens are: 
 ['Jain', 'AK', ',', 'Murty', 'MN', ',', 'Flynn', 'PJ', '.']

>> Bigrams are: 
 [('Jain', 'AK'), ('AK', ','), (',', 'Murty'), ('Murty', 'MN'), ('MN', ','), (',', 'Flynn'), ('Flynn', 'PJ'), ('PJ', '.')]

>> Trigrams are: 
 [('Jain', 'AK', ','), ('AK', ',', 'Murty'), (',', 'Murty', 'MN'), ('Murty', 'MN', ','), ('MN', ',', 'Flynn'), (',', 'Flynn', 'PJ'), ('Flynn', 'PJ', '.')]

>> POS Tags are: 
 [('Jain', 'NNP'), ('AK', 'NNP'), (',', ','), ('Murty', 'NNP'), ('MN', 'NNP'), (',', ','), ('Flynn', 'NNP'), ('PJ', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Jain AK', 'Murty MN', 'Flynn PJ']

>> Named Entities are: 
 [('GPE', 'Jain AK'), ('PERSON', 'Murty MN'), ('PERSON', 'Flynn PJ')] 

>> Stemming using Porter Stemmer: 
 [('Jain', 'jain'), ('AK', 'ak'), (',', ','), ('Murty', 'murti'), ('MN', 'mn'), (',', ','), ('Flynn', 'flynn'), ('PJ', 'pj'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Jain', 'jain'), ('AK', 'ak'), (',', ','), ('Murty', 'murti'), ('MN', 'mn'), (',', ','), ('Flynn', 'flynn'), ('PJ', 'pj'), ('.', '.')]

>> Lemmatization: 
 [('Jain', 'Jain'), ('AK', 'AK'), (',', ','), ('Murty', 'Murty'), ('MN', 'MN'), (',', ','), ('Flynn', 'Flynn'), ('PJ', 'PJ'), ('.', '.')]


------------------- Sentence 4 -------------------

Data clustering: a review.

>> Tokens are: 
 ['Data', 'clustering', ':', 'review', '.']

>> Bigrams are: 
 [('Data', 'clustering'), ('clustering', ':'), (':', 'review'), ('review', '.')]

>> Trigrams are: 
 [('Data', 'clustering', ':'), ('clustering', ':', 'review'), (':', 'review', '.')]

>> POS Tags are: 
 [('Data', 'NNS'), ('clustering', 'NN'), (':', ':'), ('review', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Data clustering', 'review']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Data', 'data'), ('clustering', 'cluster'), (':', ':'), ('review', 'review'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Data', 'data'), ('clustering', 'cluster'), (':', ':'), ('review', 'review'), ('.', '.')]

>> Lemmatization: 
 [('Data', 'Data'), ('clustering', 'clustering'), (':', ':'), ('review', 'review'), ('.', '.')]


------------------- Sentence 5 -------------------

ACM Comp Surveys.

>> Tokens are: 
 ['ACM', 'Comp', 'Surveys', '.']

>> Bigrams are: 
 [('ACM', 'Comp'), ('Comp', 'Surveys'), ('Surveys', '.')]

>> Trigrams are: 
 [('ACM', 'Comp', 'Surveys'), ('Comp', 'Surveys', '.')]

>> POS Tags are: 
 [('ACM', 'NNP'), ('Comp', 'NNP'), ('Surveys', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['ACM Comp Surveys']

>> Named Entities are: 
 [('ORGANIZATION', 'ACM'), ('ORGANIZATION', 'Comp Surveys')] 

>> Stemming using Porter Stemmer: 
 [('ACM', 'acm'), ('Comp', 'comp'), ('Surveys', 'survey'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('ACM', 'acm'), ('Comp', 'comp'), ('Surveys', 'survey'), ('.', '.')]

>> Lemmatization: 
 [('ACM', 'ACM'), ('Comp', 'Comp'), ('Surveys', 'Surveys'), ('.', '.')]


------------------- Sentence 6 -------------------

1999;31(3):264–323.

>> Tokens are: 
 ['1999', ';', '31', '(', '3', ')', ':264–323', '.']

>> Bigrams are: 
 [('1999', ';'), (';', '31'), ('31', '('), ('(', '3'), ('3', ')'), (')', ':264–323'), (':264–323', '.')]

>> Trigrams are: 
 [('1999', ';', '31'), (';', '31', '('), ('31', '(', '3'), ('(', '3', ')'), ('3', ')', ':264–323'), (')', ':264–323', '.')]

>> POS Tags are: 
 [('1999', 'CD'), (';', ':'), ('31', 'CD'), ('(', '('), ('3', 'CD'), (')', ')'), (':264–323', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 [':264–323']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('1999', '1999'), (';', ';'), ('31', '31'), ('(', '('), ('3', '3'), (')', ')'), (':264–323', ':264–323'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('1999', '1999'), (';', ';'), ('31', '31'), ('(', '('), ('3', '3'), (')', ')'), (':264–323', ':264–323'), ('.', '.')]

>> Lemmatization: 
 [('1999', '1999'), (';', ';'), ('31', '31'), ('(', '('), ('3', '3'), (')', ')'), (':264–323', ':264–323'), ('.', '.')]


------------------- Sentence 7 -------------------

28.

>> Tokens are: 
 ['28', '.']

>> Bigrams are: 
 [('28', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('28', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('28', '28'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('28', '28'), ('.', '.')]

>> Lemmatization: 
 [('28', '28'), ('.', '.')]


------------------- Sentence 8 -------------------

McQueen JB.

>> Tokens are: 
 ['McQueen', 'JB', '.']

>> Bigrams are: 
 [('McQueen', 'JB'), ('JB', '.')]

>> Trigrams are: 
 [('McQueen', 'JB', '.')]

>> POS Tags are: 
 [('McQueen', 'NNP'), ('JB', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['McQueen JB']

>> Named Entities are: 
 [('ORGANIZATION', 'McQueen')] 

>> Stemming using Porter Stemmer: 
 [('McQueen', 'mcqueen'), ('JB', 'jb'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('McQueen', 'mcqueen'), ('JB', 'jb'), ('.', '.')]

>> Lemmatization: 
 [('McQueen', 'McQueen'), ('JB', 'JB'), ('.', '.')]


------------------- Sentence 9 -------------------

Some methods of classification and analysis of multivariate observations.

>> Tokens are: 
 ['Some', 'methods', 'classification', 'analysis', 'multivariate', 'observations', '.']

>> Bigrams are: 
 [('Some', 'methods'), ('methods', 'classification'), ('classification', 'analysis'), ('analysis', 'multivariate'), ('multivariate', 'observations'), ('observations', '.')]

>> Trigrams are: 
 [('Some', 'methods', 'classification'), ('methods', 'classification', 'analysis'), ('classification', 'analysis', 'multivariate'), ('analysis', 'multivariate', 'observations'), ('multivariate', 'observations', '.')]

>> POS Tags are: 
 [('Some', 'DT'), ('methods', 'NNS'), ('classification', 'NN'), ('analysis', 'NN'), ('multivariate', 'NN'), ('observations', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['Some methods classification analysis multivariate observations']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Some', 'some'), ('methods', 'method'), ('classification', 'classif'), ('analysis', 'analysi'), ('multivariate', 'multivari'), ('observations', 'observ'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Some', 'some'), ('methods', 'method'), ('classification', 'classif'), ('analysis', 'analysi'), ('multivariate', 'multivari'), ('observations', 'observ'), ('.', '.')]

>> Lemmatization: 
 [('Some', 'Some'), ('methods', 'method'), ('classification', 'classification'), ('analysis', 'analysis'), ('multivariate', 'multivariate'), ('observations', 'observation'), ('.', '.')]


------------------- Sentence 10 -------------------

In: Proceedings of the

>> Tokens are: 
 ['In', ':', 'Proceedings']

>> Bigrams are: 
 [('In', ':'), (':', 'Proceedings')]

>> Trigrams are: 
 [('In', ':', 'Proceedings')]

>> POS Tags are: 
 [('In', 'IN'), (':', ':'), ('Proceedings', 'NNS')]

>> Noun Phrases are: 
 ['Proceedings']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), (':', ':'), ('Proceedings', 'proceed')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), (':', ':'), ('Proceedings', 'proceed')]

>> Lemmatization: 
 [('In', 'In'), (':', ':'), ('Proceedings', 'Proceedings')]



========================================== PARAGRAPH 426 ===========================================

Berkeley Symposium on Mathematical Statistics and Probability, 1967. pp 281–297.  29. Safavian S, Landgrebe D. A survey of decision tree classifier methodology. IEEE Trans Syst Man Cyber.  

------------------- Sentence 1 -------------------

Berkeley Symposium on Mathematical Statistics and Probability, 1967. pp 281–297.

>> Tokens are: 
 ['Berkeley', 'Symposium', 'Mathematical', 'Statistics', 'Probability', ',', '1967.', 'pp', '281–297', '.']

>> Bigrams are: 
 [('Berkeley', 'Symposium'), ('Symposium', 'Mathematical'), ('Mathematical', 'Statistics'), ('Statistics', 'Probability'), ('Probability', ','), (',', '1967.'), ('1967.', 'pp'), ('pp', '281–297'), ('281–297', '.')]

>> Trigrams are: 
 [('Berkeley', 'Symposium', 'Mathematical'), ('Symposium', 'Mathematical', 'Statistics'), ('Mathematical', 'Statistics', 'Probability'), ('Statistics', 'Probability', ','), ('Probability', ',', '1967.'), (',', '1967.', 'pp'), ('1967.', 'pp', '281–297'), ('pp', '281–297', '.')]

>> POS Tags are: 
 [('Berkeley', 'NNP'), ('Symposium', 'NNP'), ('Mathematical', 'NNP'), ('Statistics', 'NNPS'), ('Probability', 'NNP'), (',', ','), ('1967.', 'CD'), ('pp', 'NN'), ('281–297', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Berkeley Symposium Mathematical', 'Probability', 'pp']

>> Named Entities are: 
 [('PERSON', 'Berkeley'), ('PERSON', 'Symposium Mathematical')] 

>> Stemming using Porter Stemmer: 
 [('Berkeley', 'berkeley'), ('Symposium', 'symposium'), ('Mathematical', 'mathemat'), ('Statistics', 'statist'), ('Probability', 'probabl'), (',', ','), ('1967.', '1967.'), ('pp', 'pp'), ('281–297', '281–297'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Berkeley', 'berkeley'), ('Symposium', 'symposium'), ('Mathematical', 'mathemat'), ('Statistics', 'statist'), ('Probability', 'probabl'), (',', ','), ('1967.', '1967.'), ('pp', 'pp'), ('281–297', '281–297'), ('.', '.')]

>> Lemmatization: 
 [('Berkeley', 'Berkeley'), ('Symposium', 'Symposium'), ('Mathematical', 'Mathematical'), ('Statistics', 'Statistics'), ('Probability', 'Probability'), (',', ','), ('1967.', '1967.'), ('pp', 'pp'), ('281–297', '281–297'), ('.', '.')]


------------------- Sentence 2 -------------------

29.

>> Tokens are: 
 ['29', '.']

>> Bigrams are: 
 [('29', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('29', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('29', '29'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('29', '29'), ('.', '.')]

>> Lemmatization: 
 [('29', '29'), ('.', '.')]


------------------- Sentence 3 -------------------

Safavian S, Landgrebe D. A survey of decision tree classifier methodology.

>> Tokens are: 
 ['Safavian', 'S', ',', 'Landgrebe', 'D.', 'A', 'survey', 'decision', 'tree', 'classifier', 'methodology', '.']

>> Bigrams are: 
 [('Safavian', 'S'), ('S', ','), (',', 'Landgrebe'), ('Landgrebe', 'D.'), ('D.', 'A'), ('A', 'survey'), ('survey', 'decision'), ('decision', 'tree'), ('tree', 'classifier'), ('classifier', 'methodology'), ('methodology', '.')]

>> Trigrams are: 
 [('Safavian', 'S', ','), ('S', ',', 'Landgrebe'), (',', 'Landgrebe', 'D.'), ('Landgrebe', 'D.', 'A'), ('D.', 'A', 'survey'), ('A', 'survey', 'decision'), ('survey', 'decision', 'tree'), ('decision', 'tree', 'classifier'), ('tree', 'classifier', 'methodology'), ('classifier', 'methodology', '.')]

>> POS Tags are: 
 [('Safavian', 'JJ'), ('S', 'NNP'), (',', ','), ('Landgrebe', 'NNP'), ('D.', 'NNP'), ('A', 'NNP'), ('survey', 'NN'), ('decision', 'NN'), ('tree', 'NN'), ('classifier', 'JJR'), ('methodology', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Safavian S', 'Landgrebe D. A survey decision tree', 'methodology']

>> Named Entities are: 
 [('GPE', 'Safavian'), ('ORGANIZATION', 'S'), ('PERSON', 'Landgrebe')] 

>> Stemming using Porter Stemmer: 
 [('Safavian', 'safavian'), ('S', 's'), (',', ','), ('Landgrebe', 'landgreb'), ('D.', 'd.'), ('A', 'a'), ('survey', 'survey'), ('decision', 'decis'), ('tree', 'tree'), ('classifier', 'classifi'), ('methodology', 'methodolog'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Safavian', 'safavian'), ('S', 's'), (',', ','), ('Landgrebe', 'landgreb'), ('D.', 'd.'), ('A', 'a'), ('survey', 'survey'), ('decision', 'decis'), ('tree', 'tree'), ('classifier', 'classifi'), ('methodology', 'methodolog'), ('.', '.')]

>> Lemmatization: 
 [('Safavian', 'Safavian'), ('S', 'S'), (',', ','), ('Landgrebe', 'Landgrebe'), ('D.', 'D.'), ('A', 'A'), ('survey', 'survey'), ('decision', 'decision'), ('tree', 'tree'), ('classifier', 'classifier'), ('methodology', 'methodology'), ('.', '.')]


------------------- Sentence 4 -------------------

IEEE Trans Syst Man Cyber.

>> Tokens are: 
 ['IEEE', 'Trans', 'Syst', 'Man', 'Cyber', '.']

>> Bigrams are: 
 [('IEEE', 'Trans'), ('Trans', 'Syst'), ('Syst', 'Man'), ('Man', 'Cyber'), ('Cyber', '.')]

>> Trigrams are: 
 [('IEEE', 'Trans', 'Syst'), ('Trans', 'Syst', 'Man'), ('Syst', 'Man', 'Cyber'), ('Man', 'Cyber', '.')]

>> POS Tags are: 
 [('IEEE', 'NNP'), ('Trans', 'NNP'), ('Syst', 'NNP'), ('Man', 'NNP'), ('Cyber', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['IEEE Trans Syst Man Cyber']

>> Named Entities are: 
 [('ORGANIZATION', 'IEEE'), ('PERSON', 'Trans Syst Man')] 

>> Stemming using Porter Stemmer: 
 [('IEEE', 'ieee'), ('Trans', 'tran'), ('Syst', 'syst'), ('Man', 'man'), ('Cyber', 'cyber'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('IEEE', 'ieee'), ('Trans', 'tran'), ('Syst', 'syst'), ('Man', 'man'), ('Cyber', 'cyber'), ('.', '.')]

>> Lemmatization: 
 [('IEEE', 'IEEE'), ('Trans', 'Trans'), ('Syst', 'Syst'), ('Man', 'Man'), ('Cyber', 'Cyber'), ('.', '.')]



========================================== PARAGRAPH 427 ===========================================

1991;21(3):660–74.  30. McCallum A, Nigam K. A comparison of event models for naive bayes text classification. In: Proceedings of the  

------------------- Sentence 1 -------------------

1991;21(3):660–74.

>> Tokens are: 
 ['1991', ';', '21', '(', '3', ')', ':660–74', '.']

>> Bigrams are: 
 [('1991', ';'), (';', '21'), ('21', '('), ('(', '3'), ('3', ')'), (')', ':660–74'), (':660–74', '.')]

>> Trigrams are: 
 [('1991', ';', '21'), (';', '21', '('), ('21', '(', '3'), ('(', '3', ')'), ('3', ')', ':660–74'), (')', ':660–74', '.')]

>> POS Tags are: 
 [('1991', 'CD'), (';', ':'), ('21', 'CD'), ('(', '('), ('3', 'CD'), (')', ')'), (':660–74', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 [':660–74']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('1991', '1991'), (';', ';'), ('21', '21'), ('(', '('), ('3', '3'), (')', ')'), (':660–74', ':660–74'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('1991', '1991'), (';', ';'), ('21', '21'), ('(', '('), ('3', '3'), (')', ')'), (':660–74', ':660–74'), ('.', '.')]

>> Lemmatization: 
 [('1991', '1991'), (';', ';'), ('21', '21'), ('(', '('), ('3', '3'), (')', ')'), (':660–74', ':660–74'), ('.', '.')]


------------------- Sentence 2 -------------------

30.

>> Tokens are: 
 ['30', '.']

>> Bigrams are: 
 [('30', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('30', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('30', '30'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('30', '30'), ('.', '.')]

>> Lemmatization: 
 [('30', '30'), ('.', '.')]


------------------- Sentence 3 -------------------

McCallum A, Nigam K. A comparison of event models for naive bayes text classification.

>> Tokens are: 
 ['McCallum', 'A', ',', 'Nigam', 'K.', 'A', 'comparison', 'event', 'models', 'naive', 'bayes', 'text', 'classification', '.']

>> Bigrams are: 
 [('McCallum', 'A'), ('A', ','), (',', 'Nigam'), ('Nigam', 'K.'), ('K.', 'A'), ('A', 'comparison'), ('comparison', 'event'), ('event', 'models'), ('models', 'naive'), ('naive', 'bayes'), ('bayes', 'text'), ('text', 'classification'), ('classification', '.')]

>> Trigrams are: 
 [('McCallum', 'A', ','), ('A', ',', 'Nigam'), (',', 'Nigam', 'K.'), ('Nigam', 'K.', 'A'), ('K.', 'A', 'comparison'), ('A', 'comparison', 'event'), ('comparison', 'event', 'models'), ('event', 'models', 'naive'), ('models', 'naive', 'bayes'), ('naive', 'bayes', 'text'), ('bayes', 'text', 'classification'), ('text', 'classification', '.')]

>> POS Tags are: 
 [('McCallum', 'NNP'), ('A', 'NNP'), (',', ','), ('Nigam', 'NNP'), ('K.', 'NNP'), ('A', 'NNP'), ('comparison', 'NN'), ('event', 'NN'), ('models', 'NNS'), ('naive', 'JJ'), ('bayes', 'NNS'), ('text', 'JJ'), ('classification', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['McCallum A', 'Nigam K. A comparison event models', 'naive bayes', 'text classification']

>> Named Entities are: 
 [('PERSON', 'Nigam')] 

>> Stemming using Porter Stemmer: 
 [('McCallum', 'mccallum'), ('A', 'a'), (',', ','), ('Nigam', 'nigam'), ('K.', 'k.'), ('A', 'a'), ('comparison', 'comparison'), ('event', 'event'), ('models', 'model'), ('naive', 'naiv'), ('bayes', 'bay'), ('text', 'text'), ('classification', 'classif'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('McCallum', 'mccallum'), ('A', 'a'), (',', ','), ('Nigam', 'nigam'), ('K.', 'k.'), ('A', 'a'), ('comparison', 'comparison'), ('event', 'event'), ('models', 'model'), ('naive', 'naiv'), ('bayes', 'bay'), ('text', 'text'), ('classification', 'classif'), ('.', '.')]

>> Lemmatization: 
 [('McCallum', 'McCallum'), ('A', 'A'), (',', ','), ('Nigam', 'Nigam'), ('K.', 'K.'), ('A', 'A'), ('comparison', 'comparison'), ('event', 'event'), ('models', 'model'), ('naive', 'naive'), ('bayes', 'bayes'), ('text', 'text'), ('classification', 'classification'), ('.', '.')]


------------------- Sentence 4 -------------------

In: Proceedings of the

>> Tokens are: 
 ['In', ':', 'Proceedings']

>> Bigrams are: 
 [('In', ':'), (':', 'Proceedings')]

>> Trigrams are: 
 [('In', ':', 'Proceedings')]

>> POS Tags are: 
 [('In', 'IN'), (':', ':'), ('Proceedings', 'NNS')]

>> Noun Phrases are: 
 ['Proceedings']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), (':', ':'), ('Proceedings', 'proceed')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), (':', ':'), ('Proceedings', 'proceed')]

>> Lemmatization: 
 [('In', 'In'), (':', ':'), ('Proceedings', 'Proceedings')]



========================================== PARAGRAPH 428 ===========================================

National Conference on Artificial Intelligence, 1998. pp. 41–48.  31. Boser BE, Guyon IM, Vapnik VN. A training algorithm for optimal margin classifiers. In: Proceedings of the annual  

------------------- Sentence 1 -------------------

National Conference on Artificial Intelligence, 1998. pp.

>> Tokens are: 
 ['National', 'Conference', 'Artificial', 'Intelligence', ',', '1998.', 'pp', '.']

>> Bigrams are: 
 [('National', 'Conference'), ('Conference', 'Artificial'), ('Artificial', 'Intelligence'), ('Intelligence', ','), (',', '1998.'), ('1998.', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('National', 'Conference', 'Artificial'), ('Conference', 'Artificial', 'Intelligence'), ('Artificial', 'Intelligence', ','), ('Intelligence', ',', '1998.'), (',', '1998.', 'pp'), ('1998.', 'pp', '.')]

>> POS Tags are: 
 [('National', 'NNP'), ('Conference', 'NNP'), ('Artificial', 'NNP'), ('Intelligence', 'NNP'), (',', ','), ('1998.', 'CD'), ('pp', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['National Conference Artificial Intelligence', 'pp']

>> Named Entities are: 
 [('ORGANIZATION', 'National Conference Artificial Intelligence')] 

>> Stemming using Porter Stemmer: 
 [('National', 'nation'), ('Conference', 'confer'), ('Artificial', 'artifici'), ('Intelligence', 'intellig'), (',', ','), ('1998.', '1998.'), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('National', 'nation'), ('Conference', 'confer'), ('Artificial', 'artifici'), ('Intelligence', 'intellig'), (',', ','), ('1998.', '1998.'), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('National', 'National'), ('Conference', 'Conference'), ('Artificial', 'Artificial'), ('Intelligence', 'Intelligence'), (',', ','), ('1998.', '1998.'), ('pp', 'pp'), ('.', '.')]


------------------- Sentence 2 -------------------

41–48.

>> Tokens are: 
 ['41–48', '.']

>> Bigrams are: 
 [('41–48', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('41–48', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('41–48', '41–48'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('41–48', '41–48'), ('.', '.')]

>> Lemmatization: 
 [('41–48', '41–48'), ('.', '.')]


------------------- Sentence 3 -------------------

31.

>> Tokens are: 
 ['31', '.']

>> Bigrams are: 
 [('31', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('31', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('31', '31'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('31', '31'), ('.', '.')]

>> Lemmatization: 
 [('31', '31'), ('.', '.')]


------------------- Sentence 4 -------------------

Boser BE, Guyon IM, Vapnik VN.

>> Tokens are: 
 ['Boser', 'BE', ',', 'Guyon', 'IM', ',', 'Vapnik', 'VN', '.']

>> Bigrams are: 
 [('Boser', 'BE'), ('BE', ','), (',', 'Guyon'), ('Guyon', 'IM'), ('IM', ','), (',', 'Vapnik'), ('Vapnik', 'VN'), ('VN', '.')]

>> Trigrams are: 
 [('Boser', 'BE', ','), ('BE', ',', 'Guyon'), (',', 'Guyon', 'IM'), ('Guyon', 'IM', ','), ('IM', ',', 'Vapnik'), (',', 'Vapnik', 'VN'), ('Vapnik', 'VN', '.')]

>> POS Tags are: 
 [('Boser', 'NNP'), ('BE', 'NNP'), (',', ','), ('Guyon', 'NNP'), ('IM', 'NNP'), (',', ','), ('Vapnik', 'NNP'), ('VN', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Boser BE', 'Guyon IM', 'Vapnik VN']

>> Named Entities are: 
 [('GPE', 'Boser BE'), ('PERSON', 'Guyon IM'), ('PERSON', 'Vapnik VN')] 

>> Stemming using Porter Stemmer: 
 [('Boser', 'boser'), ('BE', 'be'), (',', ','), ('Guyon', 'guyon'), ('IM', 'im'), (',', ','), ('Vapnik', 'vapnik'), ('VN', 'vn'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Boser', 'boser'), ('BE', 'be'), (',', ','), ('Guyon', 'guyon'), ('IM', 'im'), (',', ','), ('Vapnik', 'vapnik'), ('VN', 'vn'), ('.', '.')]

>> Lemmatization: 
 [('Boser', 'Boser'), ('BE', 'BE'), (',', ','), ('Guyon', 'Guyon'), ('IM', 'IM'), (',', ','), ('Vapnik', 'Vapnik'), ('VN', 'VN'), ('.', '.')]


------------------- Sentence 5 -------------------

A training algorithm for optimal margin classifiers.

>> Tokens are: 
 ['A', 'training', 'algorithm', 'optimal', 'margin', 'classifiers', '.']

>> Bigrams are: 
 [('A', 'training'), ('training', 'algorithm'), ('algorithm', 'optimal'), ('optimal', 'margin'), ('margin', 'classifiers'), ('classifiers', '.')]

>> Trigrams are: 
 [('A', 'training', 'algorithm'), ('training', 'algorithm', 'optimal'), ('algorithm', 'optimal', 'margin'), ('optimal', 'margin', 'classifiers'), ('margin', 'classifiers', '.')]

>> POS Tags are: 
 [('A', 'DT'), ('training', 'NN'), ('algorithm', 'NN'), ('optimal', 'JJ'), ('margin', 'NN'), ('classifiers', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['A training algorithm', 'optimal margin classifiers']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('A', 'a'), ('training', 'train'), ('algorithm', 'algorithm'), ('optimal', 'optim'), ('margin', 'margin'), ('classifiers', 'classifi'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('A', 'a'), ('training', 'train'), ('algorithm', 'algorithm'), ('optimal', 'optim'), ('margin', 'margin'), ('classifiers', 'classifi'), ('.', '.')]

>> Lemmatization: 
 [('A', 'A'), ('training', 'training'), ('algorithm', 'algorithm'), ('optimal', 'optimal'), ('margin', 'margin'), ('classifiers', 'classifier'), ('.', '.')]


------------------- Sentence 6 -------------------

In: Proceedings of the annual

>> Tokens are: 
 ['In', ':', 'Proceedings', 'annual']

>> Bigrams are: 
 [('In', ':'), (':', 'Proceedings'), ('Proceedings', 'annual')]

>> Trigrams are: 
 [('In', ':', 'Proceedings'), (':', 'Proceedings', 'annual')]

>> POS Tags are: 
 [('In', 'IN'), (':', ':'), ('Proceedings', 'NNS'), ('annual', 'JJ')]

>> Noun Phrases are: 
 ['Proceedings']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), (':', ':'), ('Proceedings', 'proceed'), ('annual', 'annual')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), (':', ':'), ('Proceedings', 'proceed'), ('annual', 'annual')]

>> Lemmatization: 
 [('In', 'In'), (':', ':'), ('Proceedings', 'Proceedings'), ('annual', 'annual')]



========================================== PARAGRAPH 429 ===========================================

workshop on Computational learning theory, 1992. pp. 144–152.  32. Han J, Pei J, Yin Y. Mining frequent patterns without candidate generation. In : Proceedings of the ACM SIGMOD  

------------------- Sentence 1 -------------------

workshop on Computational learning theory, 1992. pp.

>> Tokens are: 
 ['workshop', 'Computational', 'learning', 'theory', ',', '1992.', 'pp', '.']

>> Bigrams are: 
 [('workshop', 'Computational'), ('Computational', 'learning'), ('learning', 'theory'), ('theory', ','), (',', '1992.'), ('1992.', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('workshop', 'Computational', 'learning'), ('Computational', 'learning', 'theory'), ('learning', 'theory', ','), ('theory', ',', '1992.'), (',', '1992.', 'pp'), ('1992.', 'pp', '.')]

>> POS Tags are: 
 [('workshop', 'NN'), ('Computational', 'NNP'), ('learning', 'NN'), ('theory', 'NN'), (',', ','), ('1992.', 'CD'), ('pp', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['workshop Computational learning theory', 'pp']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('workshop', 'workshop'), ('Computational', 'comput'), ('learning', 'learn'), ('theory', 'theori'), (',', ','), ('1992.', '1992.'), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('workshop', 'workshop'), ('Computational', 'comput'), ('learning', 'learn'), ('theory', 'theori'), (',', ','), ('1992.', '1992.'), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('workshop', 'workshop'), ('Computational', 'Computational'), ('learning', 'learning'), ('theory', 'theory'), (',', ','), ('1992.', '1992.'), ('pp', 'pp'), ('.', '.')]


------------------- Sentence 2 -------------------

144–152.

>> Tokens are: 
 ['144–152', '.']

>> Bigrams are: 
 [('144–152', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('144–152', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('144–152', '144–152'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('144–152', '144–152'), ('.', '.')]

>> Lemmatization: 
 [('144–152', '144–152'), ('.', '.')]


------------------- Sentence 3 -------------------

32.

>> Tokens are: 
 ['32', '.']

>> Bigrams are: 
 [('32', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('32', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('32', '32'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('32', '32'), ('.', '.')]

>> Lemmatization: 
 [('32', '32'), ('.', '.')]


------------------- Sentence 4 -------------------

Han J, Pei J, Yin Y.

>> Tokens are: 
 ['Han', 'J', ',', 'Pei', 'J', ',', 'Yin', 'Y', '.']

>> Bigrams are: 
 [('Han', 'J'), ('J', ','), (',', 'Pei'), ('Pei', 'J'), ('J', ','), (',', 'Yin'), ('Yin', 'Y'), ('Y', '.')]

>> Trigrams are: 
 [('Han', 'J', ','), ('J', ',', 'Pei'), (',', 'Pei', 'J'), ('Pei', 'J', ','), ('J', ',', 'Yin'), (',', 'Yin', 'Y'), ('Yin', 'Y', '.')]

>> POS Tags are: 
 [('Han', 'NNP'), ('J', 'NNP'), (',', ','), ('Pei', 'NNP'), ('J', 'NNP'), (',', ','), ('Yin', 'NNP'), ('Y', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Han J', 'Pei J', 'Yin Y']

>> Named Entities are: 
 [('PERSON', 'Han'), ('ORGANIZATION', 'J'), ('PERSON', 'Pei J'), ('PERSON', 'Yin Y')] 

>> Stemming using Porter Stemmer: 
 [('Han', 'han'), ('J', 'j'), (',', ','), ('Pei', 'pei'), ('J', 'j'), (',', ','), ('Yin', 'yin'), ('Y', 'y'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Han', 'han'), ('J', 'j'), (',', ','), ('Pei', 'pei'), ('J', 'j'), (',', ','), ('Yin', 'yin'), ('Y', 'y'), ('.', '.')]

>> Lemmatization: 
 [('Han', 'Han'), ('J', 'J'), (',', ','), ('Pei', 'Pei'), ('J', 'J'), (',', ','), ('Yin', 'Yin'), ('Y', 'Y'), ('.', '.')]


------------------- Sentence 5 -------------------

Mining frequent patterns without candidate generation.

>> Tokens are: 
 ['Mining', 'frequent', 'patterns', 'without', 'candidate', 'generation', '.']

>> Bigrams are: 
 [('Mining', 'frequent'), ('frequent', 'patterns'), ('patterns', 'without'), ('without', 'candidate'), ('candidate', 'generation'), ('generation', '.')]

>> Trigrams are: 
 [('Mining', 'frequent', 'patterns'), ('frequent', 'patterns', 'without'), ('patterns', 'without', 'candidate'), ('without', 'candidate', 'generation'), ('candidate', 'generation', '.')]

>> POS Tags are: 
 [('Mining', 'VBG'), ('frequent', 'JJ'), ('patterns', 'NNS'), ('without', 'IN'), ('candidate', 'NN'), ('generation', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['frequent patterns', 'candidate generation']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Mining', 'mine'), ('frequent', 'frequent'), ('patterns', 'pattern'), ('without', 'without'), ('candidate', 'candid'), ('generation', 'gener'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Mining', 'mine'), ('frequent', 'frequent'), ('patterns', 'pattern'), ('without', 'without'), ('candidate', 'candid'), ('generation', 'generat'), ('.', '.')]

>> Lemmatization: 
 [('Mining', 'Mining'), ('frequent', 'frequent'), ('patterns', 'pattern'), ('without', 'without'), ('candidate', 'candidate'), ('generation', 'generation'), ('.', '.')]


------------------- Sentence 6 -------------------

In : Proceedings of the ACM SIGMOD

>> Tokens are: 
 ['In', ':', 'Proceedings', 'ACM', 'SIGMOD']

>> Bigrams are: 
 [('In', ':'), (':', 'Proceedings'), ('Proceedings', 'ACM'), ('ACM', 'SIGMOD')]

>> Trigrams are: 
 [('In', ':', 'Proceedings'), (':', 'Proceedings', 'ACM'), ('Proceedings', 'ACM', 'SIGMOD')]

>> POS Tags are: 
 [('In', 'IN'), (':', ':'), ('Proceedings', 'NNS'), ('ACM', 'NNP'), ('SIGMOD', 'NNP')]

>> Noun Phrases are: 
 ['Proceedings ACM SIGMOD']

>> Named Entities are: 
 [('ORGANIZATION', 'ACM')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), (':', ':'), ('Proceedings', 'proceed'), ('ACM', 'acm'), ('SIGMOD', 'sigmod')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), (':', ':'), ('Proceedings', 'proceed'), ('ACM', 'acm'), ('SIGMOD', 'sigmod')]

>> Lemmatization: 
 [('In', 'In'), (':', ':'), ('Proceedings', 'Proceedings'), ('ACM', 'ACM'), ('SIGMOD', 'SIGMOD')]



========================================== PARAGRAPH 430 ===========================================

International Conference on Management of Data, 2000. pp. 1–12.  33. Kaya M, Alhajj R. Genetic algorithm based framework for mining fuzzy association rules. Fuzzy Sets Syst.  

------------------- Sentence 1 -------------------

International Conference on Management of Data, 2000. pp.

>> Tokens are: 
 ['International', 'Conference', 'Management', 'Data', ',', '2000.', 'pp', '.']

>> Bigrams are: 
 [('International', 'Conference'), ('Conference', 'Management'), ('Management', 'Data'), ('Data', ','), (',', '2000.'), ('2000.', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('International', 'Conference', 'Management'), ('Conference', 'Management', 'Data'), ('Management', 'Data', ','), ('Data', ',', '2000.'), (',', '2000.', 'pp'), ('2000.', 'pp', '.')]

>> POS Tags are: 
 [('International', 'NNP'), ('Conference', 'NNP'), ('Management', 'NNP'), ('Data', 'NNP'), (',', ','), ('2000.', 'CD'), ('pp', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['International Conference Management Data', 'pp']

>> Named Entities are: 
 [('ORGANIZATION', 'International Conference Management Data')] 

>> Stemming using Porter Stemmer: 
 [('International', 'intern'), ('Conference', 'confer'), ('Management', 'manag'), ('Data', 'data'), (',', ','), ('2000.', '2000.'), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('International', 'intern'), ('Conference', 'confer'), ('Management', 'manag'), ('Data', 'data'), (',', ','), ('2000.', '2000.'), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('International', 'International'), ('Conference', 'Conference'), ('Management', 'Management'), ('Data', 'Data'), (',', ','), ('2000.', '2000.'), ('pp', 'pp'), ('.', '.')]


------------------- Sentence 2 -------------------

1–12.

>> Tokens are: 
 ['1–12', '.']

>> Bigrams are: 
 [('1–12', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('1–12', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('1–12', '1–12'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('1–12', '1–12'), ('.', '.')]

>> Lemmatization: 
 [('1–12', '1–12'), ('.', '.')]


------------------- Sentence 3 -------------------

33.

>> Tokens are: 
 ['33', '.']

>> Bigrams are: 
 [('33', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('33', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('33', '33'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('33', '33'), ('.', '.')]

>> Lemmatization: 
 [('33', '33'), ('.', '.')]


------------------- Sentence 4 -------------------

Kaya M, Alhajj R. Genetic algorithm based framework for mining fuzzy association rules.

>> Tokens are: 
 ['Kaya', 'M', ',', 'Alhajj', 'R.', 'Genetic', 'algorithm', 'based', 'framework', 'mining', 'fuzzy', 'association', 'rules', '.']

>> Bigrams are: 
 [('Kaya', 'M'), ('M', ','), (',', 'Alhajj'), ('Alhajj', 'R.'), ('R.', 'Genetic'), ('Genetic', 'algorithm'), ('algorithm', 'based'), ('based', 'framework'), ('framework', 'mining'), ('mining', 'fuzzy'), ('fuzzy', 'association'), ('association', 'rules'), ('rules', '.')]

>> Trigrams are: 
 [('Kaya', 'M', ','), ('M', ',', 'Alhajj'), (',', 'Alhajj', 'R.'), ('Alhajj', 'R.', 'Genetic'), ('R.', 'Genetic', 'algorithm'), ('Genetic', 'algorithm', 'based'), ('algorithm', 'based', 'framework'), ('based', 'framework', 'mining'), ('framework', 'mining', 'fuzzy'), ('mining', 'fuzzy', 'association'), ('fuzzy', 'association', 'rules'), ('association', 'rules', '.')]

>> POS Tags are: 
 [('Kaya', 'NNP'), ('M', 'NNP'), (',', ','), ('Alhajj', 'NNP'), ('R.', 'NNP'), ('Genetic', 'NNP'), ('algorithm', 'NN'), ('based', 'VBN'), ('framework', 'NN'), ('mining', 'VBG'), ('fuzzy', 'JJ'), ('association', 'NN'), ('rules', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['Kaya M', 'Alhajj R. Genetic algorithm', 'framework', 'fuzzy association rules']

>> Named Entities are: 
 [('PERSON', 'Kaya'), ('PERSON', 'Alhajj R. Genetic')] 

>> Stemming using Porter Stemmer: 
 [('Kaya', 'kaya'), ('M', 'm'), (',', ','), ('Alhajj', 'alhajj'), ('R.', 'r.'), ('Genetic', 'genet'), ('algorithm', 'algorithm'), ('based', 'base'), ('framework', 'framework'), ('mining', 'mine'), ('fuzzy', 'fuzzi'), ('association', 'associ'), ('rules', 'rule'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Kaya', 'kaya'), ('M', 'm'), (',', ','), ('Alhajj', 'alhajj'), ('R.', 'r.'), ('Genetic', 'genet'), ('algorithm', 'algorithm'), ('based', 'base'), ('framework', 'framework'), ('mining', 'mine'), ('fuzzy', 'fuzzi'), ('association', 'associ'), ('rules', 'rule'), ('.', '.')]

>> Lemmatization: 
 [('Kaya', 'Kaya'), ('M', 'M'), (',', ','), ('Alhajj', 'Alhajj'), ('R.', 'R.'), ('Genetic', 'Genetic'), ('algorithm', 'algorithm'), ('based', 'based'), ('framework', 'framework'), ('mining', 'mining'), ('fuzzy', 'fuzzy'), ('association', 'association'), ('rules', 'rule'), ('.', '.')]


------------------- Sentence 5 -------------------

Fuzzy Sets Syst.

>> Tokens are: 
 ['Fuzzy', 'Sets', 'Syst', '.']

>> Bigrams are: 
 [('Fuzzy', 'Sets'), ('Sets', 'Syst'), ('Syst', '.')]

>> Trigrams are: 
 [('Fuzzy', 'Sets', 'Syst'), ('Sets', 'Syst', '.')]

>> POS Tags are: 
 [('Fuzzy', 'NNP'), ('Sets', 'NNP'), ('Syst', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Fuzzy Sets Syst']

>> Named Entities are: 
 [('PERSON', 'Fuzzy'), ('ORGANIZATION', 'Sets Syst')] 

>> Stemming using Porter Stemmer: 
 [('Fuzzy', 'fuzzi'), ('Sets', 'set'), ('Syst', 'syst'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Fuzzy', 'fuzzi'), ('Sets', 'set'), ('Syst', 'syst'), ('.', '.')]

>> Lemmatization: 
 [('Fuzzy', 'Fuzzy'), ('Sets', 'Sets'), ('Syst', 'Syst'), ('.', '.')]



========================================== PARAGRAPH 431 ===========================================

2005;152(3):587–601.  34. Srikant R, Agrawal R. Mining sequential patterns: generalizations and performance improvements. In: Proceedings  

------------------- Sentence 1 -------------------

2005;152(3):587–601.

>> Tokens are: 
 ['2005', ';', '152', '(', '3', ')', ':587–601', '.']

>> Bigrams are: 
 [('2005', ';'), (';', '152'), ('152', '('), ('(', '3'), ('3', ')'), (')', ':587–601'), (':587–601', '.')]

>> Trigrams are: 
 [('2005', ';', '152'), (';', '152', '('), ('152', '(', '3'), ('(', '3', ')'), ('3', ')', ':587–601'), (')', ':587–601', '.')]

>> POS Tags are: 
 [('2005', 'CD'), (';', ':'), ('152', 'CD'), ('(', '('), ('3', 'CD'), (')', ')'), (':587–601', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 [':587–601']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('2005', '2005'), (';', ';'), ('152', '152'), ('(', '('), ('3', '3'), (')', ')'), (':587–601', ':587–601'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('2005', '2005'), (';', ';'), ('152', '152'), ('(', '('), ('3', '3'), (')', ')'), (':587–601', ':587–601'), ('.', '.')]

>> Lemmatization: 
 [('2005', '2005'), (';', ';'), ('152', '152'), ('(', '('), ('3', '3'), (')', ')'), (':587–601', ':587–601'), ('.', '.')]


------------------- Sentence 2 -------------------

34.

>> Tokens are: 
 ['34', '.']

>> Bigrams are: 
 [('34', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('34', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('34', '34'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('34', '34'), ('.', '.')]

>> Lemmatization: 
 [('34', '34'), ('.', '.')]


------------------- Sentence 3 -------------------

Srikant R, Agrawal R. Mining sequential patterns: generalizations and performance improvements.

>> Tokens are: 
 ['Srikant', 'R', ',', 'Agrawal', 'R.', 'Mining', 'sequential', 'patterns', ':', 'generalizations', 'performance', 'improvements', '.']

>> Bigrams are: 
 [('Srikant', 'R'), ('R', ','), (',', 'Agrawal'), ('Agrawal', 'R.'), ('R.', 'Mining'), ('Mining', 'sequential'), ('sequential', 'patterns'), ('patterns', ':'), (':', 'generalizations'), ('generalizations', 'performance'), ('performance', 'improvements'), ('improvements', '.')]

>> Trigrams are: 
 [('Srikant', 'R', ','), ('R', ',', 'Agrawal'), (',', 'Agrawal', 'R.'), ('Agrawal', 'R.', 'Mining'), ('R.', 'Mining', 'sequential'), ('Mining', 'sequential', 'patterns'), ('sequential', 'patterns', ':'), ('patterns', ':', 'generalizations'), (':', 'generalizations', 'performance'), ('generalizations', 'performance', 'improvements'), ('performance', 'improvements', '.')]

>> POS Tags are: 
 [('Srikant', 'NNP'), ('R', 'NNP'), (',', ','), ('Agrawal', 'NNP'), ('R.', 'NNP'), ('Mining', 'NNP'), ('sequential', 'JJ'), ('patterns', 'NNS'), (':', ':'), ('generalizations', 'NNS'), ('performance', 'NN'), ('improvements', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['Srikant R', 'Agrawal R. Mining', 'sequential patterns', 'generalizations performance improvements']

>> Named Entities are: 
 [('PERSON', 'Srikant'), ('ORGANIZATION', 'R'), ('PERSON', 'Agrawal R.')] 

>> Stemming using Porter Stemmer: 
 [('Srikant', 'srikant'), ('R', 'r'), (',', ','), ('Agrawal', 'agraw'), ('R.', 'r.'), ('Mining', 'mine'), ('sequential', 'sequenti'), ('patterns', 'pattern'), (':', ':'), ('generalizations', 'gener'), ('performance', 'perform'), ('improvements', 'improv'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Srikant', 'srikant'), ('R', 'r'), (',', ','), ('Agrawal', 'agraw'), ('R.', 'r.'), ('Mining', 'mine'), ('sequential', 'sequenti'), ('patterns', 'pattern'), (':', ':'), ('generalizations', 'general'), ('performance', 'perform'), ('improvements', 'improv'), ('.', '.')]

>> Lemmatization: 
 [('Srikant', 'Srikant'), ('R', 'R'), (',', ','), ('Agrawal', 'Agrawal'), ('R.', 'R.'), ('Mining', 'Mining'), ('sequential', 'sequential'), ('patterns', 'pattern'), (':', ':'), ('generalizations', 'generalization'), ('performance', 'performance'), ('improvements', 'improvement'), ('.', '.')]


------------------- Sentence 4 -------------------

In: Proceedings

>> Tokens are: 
 ['In', ':', 'Proceedings']

>> Bigrams are: 
 [('In', ':'), (':', 'Proceedings')]

>> Trigrams are: 
 [('In', ':', 'Proceedings')]

>> POS Tags are: 
 [('In', 'IN'), (':', ':'), ('Proceedings', 'NNS')]

>> Noun Phrases are: 
 ['Proceedings']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), (':', ':'), ('Proceedings', 'proceed')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), (':', ':'), ('Proceedings', 'proceed')]

>> Lemmatization: 
 [('In', 'In'), (':', ':'), ('Proceedings', 'Proceedings')]



========================================== PARAGRAPH 432 ===========================================

of the International Conference on Extending Database Technology: Advances in Database Technology, 1996. pp  3–17. 

------------------- Sentence 1 -------------------

of the International Conference on Extending Database Technology: Advances in Database Technology, 1996. pp  3–17.

>> Tokens are: 
 ['International', 'Conference', 'Extending', 'Database', 'Technology', ':', 'Advances', 'Database', 'Technology', ',', '1996.', 'pp', '3–17', '.']

>> Bigrams are: 
 [('International', 'Conference'), ('Conference', 'Extending'), ('Extending', 'Database'), ('Database', 'Technology'), ('Technology', ':'), (':', 'Advances'), ('Advances', 'Database'), ('Database', 'Technology'), ('Technology', ','), (',', '1996.'), ('1996.', 'pp'), ('pp', '3–17'), ('3–17', '.')]

>> Trigrams are: 
 [('International', 'Conference', 'Extending'), ('Conference', 'Extending', 'Database'), ('Extending', 'Database', 'Technology'), ('Database', 'Technology', ':'), ('Technology', ':', 'Advances'), (':', 'Advances', 'Database'), ('Advances', 'Database', 'Technology'), ('Database', 'Technology', ','), ('Technology', ',', '1996.'), (',', '1996.', 'pp'), ('1996.', 'pp', '3–17'), ('pp', '3–17', '.')]

>> POS Tags are: 
 [('International', 'NNP'), ('Conference', 'NNP'), ('Extending', 'NNP'), ('Database', 'NNP'), ('Technology', 'NNP'), (':', ':'), ('Advances', 'NNS'), ('Database', 'NNP'), ('Technology', 'NNP'), (',', ','), ('1996.', 'CD'), ('pp', 'NN'), ('3–17', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['International Conference Extending Database Technology', 'Advances Database Technology', 'pp']

>> Named Entities are: 
 [('ORGANIZATION', 'International Conference'), ('PERSON', 'Database Technology')] 

>> Stemming using Porter Stemmer: 
 [('International', 'intern'), ('Conference', 'confer'), ('Extending', 'extend'), ('Database', 'databas'), ('Technology', 'technolog'), (':', ':'), ('Advances', 'advanc'), ('Database', 'databas'), ('Technology', 'technolog'), (',', ','), ('1996.', '1996.'), ('pp', 'pp'), ('3–17', '3–17'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('International', 'intern'), ('Conference', 'confer'), ('Extending', 'extend'), ('Database', 'databas'), ('Technology', 'technolog'), (':', ':'), ('Advances', 'advanc'), ('Database', 'databas'), ('Technology', 'technolog'), (',', ','), ('1996.', '1996.'), ('pp', 'pp'), ('3–17', '3–17'), ('.', '.')]

>> Lemmatization: 
 [('International', 'International'), ('Conference', 'Conference'), ('Extending', 'Extending'), ('Database', 'Database'), ('Technology', 'Technology'), (':', ':'), ('Advances', 'Advances'), ('Database', 'Database'), ('Technology', 'Technology'), (',', ','), ('1996.', '1996.'), ('pp', 'pp'), ('3–17', '3–17'), ('.', '.')]



========================================== PARAGRAPH 433 ===========================================

 35. Zaki MJ. Spade: an efficient algorithm for mining frequent sequences. Mach Learn. 2001;42(1–2):31–60.  36. Baeza‑Yates RA, Ribeiro‑Neto B. Modern Information Retrieval. Boston: Addison‑Wesley Longman Publishing Co.,  

------------------- Sentence 1 -------------------

 35.

>> Tokens are: 
 ['35', '.']

>> Bigrams are: 
 [('35', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('35', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('35', '35'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('35', '35'), ('.', '.')]

>> Lemmatization: 
 [('35', '35'), ('.', '.')]


------------------- Sentence 2 -------------------

Zaki MJ.

>> Tokens are: 
 ['Zaki', 'MJ', '.']

>> Bigrams are: 
 [('Zaki', 'MJ'), ('MJ', '.')]

>> Trigrams are: 
 [('Zaki', 'MJ', '.')]

>> POS Tags are: 
 [('Zaki', 'NNP'), ('MJ', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Zaki MJ']

>> Named Entities are: 
 [('PERSON', 'Zaki')] 

>> Stemming using Porter Stemmer: 
 [('Zaki', 'zaki'), ('MJ', 'mj'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Zaki', 'zaki'), ('MJ', 'mj'), ('.', '.')]

>> Lemmatization: 
 [('Zaki', 'Zaki'), ('MJ', 'MJ'), ('.', '.')]


------------------- Sentence 3 -------------------

Spade: an efficient algorithm for mining frequent sequences.

>> Tokens are: 
 ['Spade', ':', 'efficient', 'algorithm', 'mining', 'frequent', 'sequences', '.']

>> Bigrams are: 
 [('Spade', ':'), (':', 'efficient'), ('efficient', 'algorithm'), ('algorithm', 'mining'), ('mining', 'frequent'), ('frequent', 'sequences'), ('sequences', '.')]

>> Trigrams are: 
 [('Spade', ':', 'efficient'), (':', 'efficient', 'algorithm'), ('efficient', 'algorithm', 'mining'), ('algorithm', 'mining', 'frequent'), ('mining', 'frequent', 'sequences'), ('frequent', 'sequences', '.')]

>> POS Tags are: 
 [('Spade', 'NN'), (':', ':'), ('efficient', 'JJ'), ('algorithm', 'NN'), ('mining', 'NN'), ('frequent', 'JJ'), ('sequences', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['Spade', 'efficient algorithm mining', 'frequent sequences']

>> Named Entities are: 
 [('GPE', 'Spade')] 

>> Stemming using Porter Stemmer: 
 [('Spade', 'spade'), (':', ':'), ('efficient', 'effici'), ('algorithm', 'algorithm'), ('mining', 'mine'), ('frequent', 'frequent'), ('sequences', 'sequenc'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Spade', 'spade'), (':', ':'), ('efficient', 'effici'), ('algorithm', 'algorithm'), ('mining', 'mine'), ('frequent', 'frequent'), ('sequences', 'sequenc'), ('.', '.')]

>> Lemmatization: 
 [('Spade', 'Spade'), (':', ':'), ('efficient', 'efficient'), ('algorithm', 'algorithm'), ('mining', 'mining'), ('frequent', 'frequent'), ('sequences', 'sequence'), ('.', '.')]


------------------- Sentence 4 -------------------

Mach Learn.

>> Tokens are: 
 ['Mach', 'Learn', '.']

>> Bigrams are: 
 [('Mach', 'Learn'), ('Learn', '.')]

>> Trigrams are: 
 [('Mach', 'Learn', '.')]

>> POS Tags are: 
 [('Mach', 'NNP'), ('Learn', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Mach Learn']

>> Named Entities are: 
 [('PERSON', 'Mach'), ('ORGANIZATION', 'Learn')] 

>> Stemming using Porter Stemmer: 
 [('Mach', 'mach'), ('Learn', 'learn'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Mach', 'mach'), ('Learn', 'learn'), ('.', '.')]

>> Lemmatization: 
 [('Mach', 'Mach'), ('Learn', 'Learn'), ('.', '.')]


------------------- Sentence 5 -------------------

2001;42(1–2):31–60.

>> Tokens are: 
 ['2001', ';', '42', '(', '1–2', ')', ':31–60', '.']

>> Bigrams are: 
 [('2001', ';'), (';', '42'), ('42', '('), ('(', '1–2'), ('1–2', ')'), (')', ':31–60'), (':31–60', '.')]

>> Trigrams are: 
 [('2001', ';', '42'), (';', '42', '('), ('42', '(', '1–2'), ('(', '1–2', ')'), ('1–2', ')', ':31–60'), (')', ':31–60', '.')]

>> POS Tags are: 
 [('2001', 'CD'), (';', ':'), ('42', 'CD'), ('(', '('), ('1–2', 'CD'), (')', ')'), (':31–60', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 [':31–60']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('2001', '2001'), (';', ';'), ('42', '42'), ('(', '('), ('1–2', '1–2'), (')', ')'), (':31–60', ':31–60'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('2001', '2001'), (';', ';'), ('42', '42'), ('(', '('), ('1–2', '1–2'), (')', ')'), (':31–60', ':31–60'), ('.', '.')]

>> Lemmatization: 
 [('2001', '2001'), (';', ';'), ('42', '42'), ('(', '('), ('1–2', '1–2'), (')', ')'), (':31–60', ':31–60'), ('.', '.')]


------------------- Sentence 6 -------------------

36.

>> Tokens are: 
 ['36', '.']

>> Bigrams are: 
 [('36', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('36', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('36', '36'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('36', '36'), ('.', '.')]

>> Lemmatization: 
 [('36', '36'), ('.', '.')]


------------------- Sentence 7 -------------------

Baeza‑Yates RA, Ribeiro‑Neto B.

>> Tokens are: 
 ['Baeza‑Yates', 'RA', ',', 'Ribeiro‑Neto', 'B', '.']

>> Bigrams are: 
 [('Baeza‑Yates', 'RA'), ('RA', ','), (',', 'Ribeiro‑Neto'), ('Ribeiro‑Neto', 'B'), ('B', '.')]

>> Trigrams are: 
 [('Baeza‑Yates', 'RA', ','), ('RA', ',', 'Ribeiro‑Neto'), (',', 'Ribeiro‑Neto', 'B'), ('Ribeiro‑Neto', 'B', '.')]

>> POS Tags are: 
 [('Baeza‑Yates', 'NNS'), ('RA', 'NNP'), (',', ','), ('Ribeiro‑Neto', 'NNP'), ('B', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Baeza‑Yates RA', 'Ribeiro‑Neto B']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Baeza‑Yates', 'baeza‑y'), ('RA', 'ra'), (',', ','), ('Ribeiro‑Neto', 'ribeiro‑neto'), ('B', 'b'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Baeza‑Yates', 'baeza‑y'), ('RA', 'ra'), (',', ','), ('Ribeiro‑Neto', 'ribeiro‑neto'), ('B', 'b'), ('.', '.')]

>> Lemmatization: 
 [('Baeza‑Yates', 'Baeza‑Yates'), ('RA', 'RA'), (',', ','), ('Ribeiro‑Neto', 'Ribeiro‑Neto'), ('B', 'B'), ('.', '.')]


------------------- Sentence 8 -------------------

Modern Information Retrieval.

>> Tokens are: 
 ['Modern', 'Information', 'Retrieval', '.']

>> Bigrams are: 
 [('Modern', 'Information'), ('Information', 'Retrieval'), ('Retrieval', '.')]

>> Trigrams are: 
 [('Modern', 'Information', 'Retrieval'), ('Information', 'Retrieval', '.')]

>> POS Tags are: 
 [('Modern', 'JJ'), ('Information', 'NNP'), ('Retrieval', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Modern Information Retrieval']

>> Named Entities are: 
 [('GPE', 'Modern'), ('ORGANIZATION', 'Information Retrieval')] 

>> Stemming using Porter Stemmer: 
 [('Modern', 'modern'), ('Information', 'inform'), ('Retrieval', 'retriev'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Modern', 'modern'), ('Information', 'inform'), ('Retrieval', 'retriev'), ('.', '.')]

>> Lemmatization: 
 [('Modern', 'Modern'), ('Information', 'Information'), ('Retrieval', 'Retrieval'), ('.', '.')]


------------------- Sentence 9 -------------------

Boston: Addison‑Wesley Longman Publishing Co.,

>> Tokens are: 
 ['Boston', ':', 'Addison‑Wesley', 'Longman', 'Publishing', 'Co.', ',']

>> Bigrams are: 
 [('Boston', ':'), (':', 'Addison‑Wesley'), ('Addison‑Wesley', 'Longman'), ('Longman', 'Publishing'), ('Publishing', 'Co.'), ('Co.', ',')]

>> Trigrams are: 
 [('Boston', ':', 'Addison‑Wesley'), (':', 'Addison‑Wesley', 'Longman'), ('Addison‑Wesley', 'Longman', 'Publishing'), ('Longman', 'Publishing', 'Co.'), ('Publishing', 'Co.', ',')]

>> POS Tags are: 
 [('Boston', 'NNP'), (':', ':'), ('Addison‑Wesley', 'NNP'), ('Longman', 'NNP'), ('Publishing', 'NNP'), ('Co.', 'NNP'), (',', ',')]

>> Noun Phrases are: 
 ['Boston', 'Addison‑Wesley Longman Publishing Co.']

>> Named Entities are: 
 [('GPE', 'Boston')] 

>> Stemming using Porter Stemmer: 
 [('Boston', 'boston'), (':', ':'), ('Addison‑Wesley', 'addison‑wesley'), ('Longman', 'longman'), ('Publishing', 'publish'), ('Co.', 'co.'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('Boston', 'boston'), (':', ':'), ('Addison‑Wesley', 'addison‑wesley'), ('Longman', 'longman'), ('Publishing', 'publish'), ('Co.', 'co.'), (',', ',')]

>> Lemmatization: 
 [('Boston', 'Boston'), (':', ':'), ('Addison‑Wesley', 'Addison‑Wesley'), ('Longman', 'Longman'), ('Publishing', 'Publishing'), ('Co.', 'Co.'), (',', ',')]



========================================== PARAGRAPH 434 ===========================================

Inc; 1999.  37. Liu B. Web data mining: exploring hyperlinks, contents, and usage data. Berlin, Heidelberg: Springer‑Verlag; 2007.  38. d’Aquin M, Jay N. Interpreting data mining results with linked data for learning analytics: motivation, case study  

------------------- Sentence 1 -------------------

Inc; 1999.

>> Tokens are: 
 ['Inc', ';', '1999', '.']

>> Bigrams are: 
 [('Inc', ';'), (';', '1999'), ('1999', '.')]

>> Trigrams are: 
 [('Inc', ';', '1999'), (';', '1999', '.')]

>> POS Tags are: 
 [('Inc', 'NNP'), (';', ':'), ('1999', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Inc']

>> Named Entities are: 
 [('GPE', 'Inc')] 

>> Stemming using Porter Stemmer: 
 [('Inc', 'inc'), (';', ';'), ('1999', '1999'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Inc', 'inc'), (';', ';'), ('1999', '1999'), ('.', '.')]

>> Lemmatization: 
 [('Inc', 'Inc'), (';', ';'), ('1999', '1999'), ('.', '.')]


------------------- Sentence 2 -------------------

37.

>> Tokens are: 
 ['37', '.']

>> Bigrams are: 
 [('37', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('37', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('37', '37'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('37', '37'), ('.', '.')]

>> Lemmatization: 
 [('37', '37'), ('.', '.')]


------------------- Sentence 3 -------------------

Liu B.

>> Tokens are: 
 ['Liu', 'B', '.']

>> Bigrams are: 
 [('Liu', 'B'), ('B', '.')]

>> Trigrams are: 
 [('Liu', 'B', '.')]

>> POS Tags are: 
 [('Liu', 'NNP'), ('B', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Liu B']

>> Named Entities are: 
 [('PERSON', 'Liu')] 

>> Stemming using Porter Stemmer: 
 [('Liu', 'liu'), ('B', 'b'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Liu', 'liu'), ('B', 'b'), ('.', '.')]

>> Lemmatization: 
 [('Liu', 'Liu'), ('B', 'B'), ('.', '.')]


------------------- Sentence 4 -------------------

Web data mining: exploring hyperlinks, contents, and usage data.

>> Tokens are: 
 ['Web', 'data', 'mining', ':', 'exploring', 'hyperlinks', ',', 'contents', ',', 'usage', 'data', '.']

>> Bigrams are: 
 [('Web', 'data'), ('data', 'mining'), ('mining', ':'), (':', 'exploring'), ('exploring', 'hyperlinks'), ('hyperlinks', ','), (',', 'contents'), ('contents', ','), (',', 'usage'), ('usage', 'data'), ('data', '.')]

>> Trigrams are: 
 [('Web', 'data', 'mining'), ('data', 'mining', ':'), ('mining', ':', 'exploring'), (':', 'exploring', 'hyperlinks'), ('exploring', 'hyperlinks', ','), ('hyperlinks', ',', 'contents'), (',', 'contents', ','), ('contents', ',', 'usage'), (',', 'usage', 'data'), ('usage', 'data', '.')]

>> POS Tags are: 
 [('Web', 'NNP'), ('data', 'NNS'), ('mining', 'NN'), (':', ':'), ('exploring', 'JJ'), ('hyperlinks', 'NNS'), (',', ','), ('contents', 'NNS'), (',', ','), ('usage', 'JJ'), ('data', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['Web data mining', 'exploring hyperlinks', 'contents', 'usage data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Web', 'web'), ('data', 'data'), ('mining', 'mine'), (':', ':'), ('exploring', 'explor'), ('hyperlinks', 'hyperlink'), (',', ','), ('contents', 'content'), (',', ','), ('usage', 'usag'), ('data', 'data'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Web', 'web'), ('data', 'data'), ('mining', 'mine'), (':', ':'), ('exploring', 'explor'), ('hyperlinks', 'hyperlink'), (',', ','), ('contents', 'content'), (',', ','), ('usage', 'usag'), ('data', 'data'), ('.', '.')]

>> Lemmatization: 
 [('Web', 'Web'), ('data', 'data'), ('mining', 'mining'), (':', ':'), ('exploring', 'exploring'), ('hyperlinks', 'hyperlink'), (',', ','), ('contents', 'content'), (',', ','), ('usage', 'usage'), ('data', 'data'), ('.', '.')]


------------------- Sentence 5 -------------------

Berlin, Heidelberg: Springer‑Verlag; 2007.

>> Tokens are: 
 ['Berlin', ',', 'Heidelberg', ':', 'Springer‑Verlag', ';', '2007', '.']

>> Bigrams are: 
 [('Berlin', ','), (',', 'Heidelberg'), ('Heidelberg', ':'), (':', 'Springer‑Verlag'), ('Springer‑Verlag', ';'), (';', '2007'), ('2007', '.')]

>> Trigrams are: 
 [('Berlin', ',', 'Heidelberg'), (',', 'Heidelberg', ':'), ('Heidelberg', ':', 'Springer‑Verlag'), (':', 'Springer‑Verlag', ';'), ('Springer‑Verlag', ';', '2007'), (';', '2007', '.')]

>> POS Tags are: 
 [('Berlin', 'NNP'), (',', ','), ('Heidelberg', 'NNP'), (':', ':'), ('Springer‑Verlag', 'NN'), (';', ':'), ('2007', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Berlin', 'Heidelberg', 'Springer‑Verlag']

>> Named Entities are: 
 [('GPE', 'Berlin'), ('PERSON', 'Heidelberg')] 

>> Stemming using Porter Stemmer: 
 [('Berlin', 'berlin'), (',', ','), ('Heidelberg', 'heidelberg'), (':', ':'), ('Springer‑Verlag', 'springer‑verlag'), (';', ';'), ('2007', '2007'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Berlin', 'berlin'), (',', ','), ('Heidelberg', 'heidelberg'), (':', ':'), ('Springer‑Verlag', 'springer‑verlag'), (';', ';'), ('2007', '2007'), ('.', '.')]

>> Lemmatization: 
 [('Berlin', 'Berlin'), (',', ','), ('Heidelberg', 'Heidelberg'), (':', ':'), ('Springer‑Verlag', 'Springer‑Verlag'), (';', ';'), ('2007', '2007'), ('.', '.')]


------------------- Sentence 6 -------------------

38. d’Aquin M, Jay N. Interpreting data mining results with linked data for learning analytics: motivation, case study

>> Tokens are: 
 ['38.', '’', 'Aquin', 'M', ',', 'Jay', 'N.', 'Interpreting', 'data', 'mining', 'results', 'linked', 'data', 'learning', 'analytics', ':', 'motivation', ',', 'case', 'study']

>> Bigrams are: 
 [('38.', '’'), ('’', 'Aquin'), ('Aquin', 'M'), ('M', ','), (',', 'Jay'), ('Jay', 'N.'), ('N.', 'Interpreting'), ('Interpreting', 'data'), ('data', 'mining'), ('mining', 'results'), ('results', 'linked'), ('linked', 'data'), ('data', 'learning'), ('learning', 'analytics'), ('analytics', ':'), (':', 'motivation'), ('motivation', ','), (',', 'case'), ('case', 'study')]

>> Trigrams are: 
 [('38.', '’', 'Aquin'), ('’', 'Aquin', 'M'), ('Aquin', 'M', ','), ('M', ',', 'Jay'), (',', 'Jay', 'N.'), ('Jay', 'N.', 'Interpreting'), ('N.', 'Interpreting', 'data'), ('Interpreting', 'data', 'mining'), ('data', 'mining', 'results'), ('mining', 'results', 'linked'), ('results', 'linked', 'data'), ('linked', 'data', 'learning'), ('data', 'learning', 'analytics'), ('learning', 'analytics', ':'), ('analytics', ':', 'motivation'), (':', 'motivation', ','), ('motivation', ',', 'case'), (',', 'case', 'study')]

>> POS Tags are: 
 [('38.', 'CD'), ('’', 'JJ'), ('Aquin', 'NNP'), ('M', 'NNP'), (',', ','), ('Jay', 'NNP'), ('N.', 'NNP'), ('Interpreting', 'NNP'), ('data', 'NNS'), ('mining', 'NN'), ('results', 'NNS'), ('linked', 'VBN'), ('data', 'NNS'), ('learning', 'VBG'), ('analytics', 'NNS'), (':', ':'), ('motivation', 'NN'), (',', ','), ('case', 'NN'), ('study', 'NN')]

>> Noun Phrases are: 
 ['’ Aquin M', 'Jay N. Interpreting data mining results', 'data', 'analytics', 'motivation', 'case study']

>> Named Entities are: 
 [('PERSON', 'Aquin M'), ('PERSON', 'Jay N.')] 

>> Stemming using Porter Stemmer: 
 [('38.', '38.'), ('’', '’'), ('Aquin', 'aquin'), ('M', 'm'), (',', ','), ('Jay', 'jay'), ('N.', 'n.'), ('Interpreting', 'interpret'), ('data', 'data'), ('mining', 'mine'), ('results', 'result'), ('linked', 'link'), ('data', 'data'), ('learning', 'learn'), ('analytics', 'analyt'), (':', ':'), ('motivation', 'motiv'), (',', ','), ('case', 'case'), ('study', 'studi')]

>> Stemming using Snowball Stemmer: 
 [('38.', '38.'), ('’', '’'), ('Aquin', 'aquin'), ('M', 'm'), (',', ','), ('Jay', 'jay'), ('N.', 'n.'), ('Interpreting', 'interpret'), ('data', 'data'), ('mining', 'mine'), ('results', 'result'), ('linked', 'link'), ('data', 'data'), ('learning', 'learn'), ('analytics', 'analyt'), (':', ':'), ('motivation', 'motiv'), (',', ','), ('case', 'case'), ('study', 'studi')]

>> Lemmatization: 
 [('38.', '38.'), ('’', '’'), ('Aquin', 'Aquin'), ('M', 'M'), (',', ','), ('Jay', 'Jay'), ('N.', 'N.'), ('Interpreting', 'Interpreting'), ('data', 'data'), ('mining', 'mining'), ('results', 'result'), ('linked', 'linked'), ('data', 'data'), ('learning', 'learning'), ('analytics', 'analytics'), (':', ':'), ('motivation', 'motivation'), (',', ','), ('case', 'case'), ('study', 'study')]



========================================== PARAGRAPH 435 ===========================================

and directions. In: Proceedings of the International Conference on Learning Analytics and Knowledge, pp  155–164. 

------------------- Sentence 1 -------------------

and directions.

>> Tokens are: 
 ['directions', '.']

>> Bigrams are: 
 [('directions', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('directions', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['directions']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('directions', 'direct'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('directions', 'direct'), ('.', '.')]

>> Lemmatization: 
 [('directions', 'direction'), ('.', '.')]


------------------- Sentence 2 -------------------

In: Proceedings of the International Conference on Learning Analytics and Knowledge, pp  155–164.

>> Tokens are: 
 ['In', ':', 'Proceedings', 'International', 'Conference', 'Learning', 'Analytics', 'Knowledge', ',', 'pp', '155–164', '.']

>> Bigrams are: 
 [('In', ':'), (':', 'Proceedings'), ('Proceedings', 'International'), ('International', 'Conference'), ('Conference', 'Learning'), ('Learning', 'Analytics'), ('Analytics', 'Knowledge'), ('Knowledge', ','), (',', 'pp'), ('pp', '155–164'), ('155–164', '.')]

>> Trigrams are: 
 [('In', ':', 'Proceedings'), (':', 'Proceedings', 'International'), ('Proceedings', 'International', 'Conference'), ('International', 'Conference', 'Learning'), ('Conference', 'Learning', 'Analytics'), ('Learning', 'Analytics', 'Knowledge'), ('Analytics', 'Knowledge', ','), ('Knowledge', ',', 'pp'), (',', 'pp', '155–164'), ('pp', '155–164', '.')]

>> POS Tags are: 
 [('In', 'IN'), (':', ':'), ('Proceedings', 'NNS'), ('International', 'NNP'), ('Conference', 'NNP'), ('Learning', 'NNP'), ('Analytics', 'NNP'), ('Knowledge', 'NNP'), (',', ','), ('pp', 'VBD'), ('155–164', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Proceedings International Conference Learning Analytics Knowledge']

>> Named Entities are: 
 [('ORGANIZATION', 'International Conference')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), (':', ':'), ('Proceedings', 'proceed'), ('International', 'intern'), ('Conference', 'confer'), ('Learning', 'learn'), ('Analytics', 'analyt'), ('Knowledge', 'knowledg'), (',', ','), ('pp', 'pp'), ('155–164', '155–164'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), (':', ':'), ('Proceedings', 'proceed'), ('International', 'intern'), ('Conference', 'confer'), ('Learning', 'learn'), ('Analytics', 'analyt'), ('Knowledge', 'knowledg'), (',', ','), ('pp', 'pp'), ('155–164', '155–164'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), (':', ':'), ('Proceedings', 'Proceedings'), ('International', 'International'), ('Conference', 'Conference'), ('Learning', 'Learning'), ('Analytics', 'Analytics'), ('Knowledge', 'Knowledge'), (',', ','), ('pp', 'pp'), ('155–164', '155–164'), ('.', '.')]



========================================== PARAGRAPH 436 ===========================================

 39. Shneiderman B. The eyes have it: a task by data type taxonomy for information visualizations. In: Proceedings of  the IEEE Symposium on Visual Languages, 1996, pp 336–343. 

------------------- Sentence 1 -------------------

 39.

>> Tokens are: 
 ['39', '.']

>> Bigrams are: 
 [('39', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('39', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('39', '39'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('39', '39'), ('.', '.')]

>> Lemmatization: 
 [('39', '39'), ('.', '.')]


------------------- Sentence 2 -------------------

Shneiderman B.

>> Tokens are: 
 ['Shneiderman', 'B', '.']

>> Bigrams are: 
 [('Shneiderman', 'B'), ('B', '.')]

>> Trigrams are: 
 [('Shneiderman', 'B', '.')]

>> POS Tags are: 
 [('Shneiderman', 'NNP'), ('B', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Shneiderman B']

>> Named Entities are: 
 [('PERSON', 'Shneiderman')] 

>> Stemming using Porter Stemmer: 
 [('Shneiderman', 'shneiderman'), ('B', 'b'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Shneiderman', 'shneiderman'), ('B', 'b'), ('.', '.')]

>> Lemmatization: 
 [('Shneiderman', 'Shneiderman'), ('B', 'B'), ('.', '.')]


------------------- Sentence 3 -------------------

The eyes have it: a task by data type taxonomy for information visualizations.

>> Tokens are: 
 ['The', 'eyes', ':', 'task', 'data', 'type', 'taxonomy', 'information', 'visualizations', '.']

>> Bigrams are: 
 [('The', 'eyes'), ('eyes', ':'), (':', 'task'), ('task', 'data'), ('data', 'type'), ('type', 'taxonomy'), ('taxonomy', 'information'), ('information', 'visualizations'), ('visualizations', '.')]

>> Trigrams are: 
 [('The', 'eyes', ':'), ('eyes', ':', 'task'), (':', 'task', 'data'), ('task', 'data', 'type'), ('data', 'type', 'taxonomy'), ('type', 'taxonomy', 'information'), ('taxonomy', 'information', 'visualizations'), ('information', 'visualizations', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('eyes', 'NNS'), (':', ':'), ('task', 'NN'), ('data', 'NNS'), ('type', 'NN'), ('taxonomy', 'NN'), ('information', 'NN'), ('visualizations', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['The eyes', 'task data type taxonomy information visualizations']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('eyes', 'eye'), (':', ':'), ('task', 'task'), ('data', 'data'), ('type', 'type'), ('taxonomy', 'taxonomi'), ('information', 'inform'), ('visualizations', 'visual'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('eyes', 'eye'), (':', ':'), ('task', 'task'), ('data', 'data'), ('type', 'type'), ('taxonomy', 'taxonomi'), ('information', 'inform'), ('visualizations', 'visual'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('eyes', 'eye'), (':', ':'), ('task', 'task'), ('data', 'data'), ('type', 'type'), ('taxonomy', 'taxonomy'), ('information', 'information'), ('visualizations', 'visualization'), ('.', '.')]


------------------- Sentence 4 -------------------

In: Proceedings of  the IEEE Symposium on Visual Languages, 1996, pp 336–343.

>> Tokens are: 
 ['In', ':', 'Proceedings', 'IEEE', 'Symposium', 'Visual', 'Languages', ',', '1996', ',', 'pp', '336–343', '.']

>> Bigrams are: 
 [('In', ':'), (':', 'Proceedings'), ('Proceedings', 'IEEE'), ('IEEE', 'Symposium'), ('Symposium', 'Visual'), ('Visual', 'Languages'), ('Languages', ','), (',', '1996'), ('1996', ','), (',', 'pp'), ('pp', '336–343'), ('336–343', '.')]

>> Trigrams are: 
 [('In', ':', 'Proceedings'), (':', 'Proceedings', 'IEEE'), ('Proceedings', 'IEEE', 'Symposium'), ('IEEE', 'Symposium', 'Visual'), ('Symposium', 'Visual', 'Languages'), ('Visual', 'Languages', ','), ('Languages', ',', '1996'), (',', '1996', ','), ('1996', ',', 'pp'), (',', 'pp', '336–343'), ('pp', '336–343', '.')]

>> POS Tags are: 
 [('In', 'IN'), (':', ':'), ('Proceedings', 'NNS'), ('IEEE', 'NNP'), ('Symposium', 'NNP'), ('Visual', 'NNP'), ('Languages', 'NNP'), (',', ','), ('1996', 'CD'), (',', ','), ('pp', 'VBD'), ('336–343', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Proceedings IEEE Symposium Visual Languages']

>> Named Entities are: 
 [('ORGANIZATION', 'IEEE Symposium Visual Languages')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), (':', ':'), ('Proceedings', 'proceed'), ('IEEE', 'ieee'), ('Symposium', 'symposium'), ('Visual', 'visual'), ('Languages', 'languag'), (',', ','), ('1996', '1996'), (',', ','), ('pp', 'pp'), ('336–343', '336–343'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), (':', ':'), ('Proceedings', 'proceed'), ('IEEE', 'ieee'), ('Symposium', 'symposium'), ('Visual', 'visual'), ('Languages', 'languag'), (',', ','), ('1996', '1996'), (',', ','), ('pp', 'pp'), ('336–343', '336–343'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), (':', ':'), ('Proceedings', 'Proceedings'), ('IEEE', 'IEEE'), ('Symposium', 'Symposium'), ('Visual', 'Visual'), ('Languages', 'Languages'), (',', ','), ('1996', '1996'), (',', ','), ('pp', 'pp'), ('336–343', '336–343'), ('.', '.')]



========================================== PARAGRAPH 437 ===========================================

 40. Mani I, Bloedorn E. Multi‑document summarization by graph search and matching. In: Proceedings of the National  Conference on Artificial Intelligence and Ninth Conference on Innovative Applications of Artificial Intelligence,  1997, pp 622–628. 

------------------- Sentence 1 -------------------

 40.

>> Tokens are: 
 ['40', '.']

>> Bigrams are: 
 [('40', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('40', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('40', '40'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('40', '40'), ('.', '.')]

>> Lemmatization: 
 [('40', '40'), ('.', '.')]


------------------- Sentence 2 -------------------

Mani I, Bloedorn E. Multi‑document summarization by graph search and matching.

>> Tokens are: 
 ['Mani', 'I', ',', 'Bloedorn', 'E.', 'Multi‑document', 'summarization', 'graph', 'search', 'matching', '.']

>> Bigrams are: 
 [('Mani', 'I'), ('I', ','), (',', 'Bloedorn'), ('Bloedorn', 'E.'), ('E.', 'Multi‑document'), ('Multi‑document', 'summarization'), ('summarization', 'graph'), ('graph', 'search'), ('search', 'matching'), ('matching', '.')]

>> Trigrams are: 
 [('Mani', 'I', ','), ('I', ',', 'Bloedorn'), (',', 'Bloedorn', 'E.'), ('Bloedorn', 'E.', 'Multi‑document'), ('E.', 'Multi‑document', 'summarization'), ('Multi‑document', 'summarization', 'graph'), ('summarization', 'graph', 'search'), ('graph', 'search', 'matching'), ('search', 'matching', '.')]

>> POS Tags are: 
 [('Mani', 'NNP'), ('I', 'PRP'), (',', ','), ('Bloedorn', 'NNP'), ('E.', 'NNP'), ('Multi‑document', 'NNP'), ('summarization', 'NN'), ('graph', 'NN'), ('search', 'NN'), ('matching', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Mani', 'Bloedorn E. Multi‑document summarization graph search matching']

>> Named Entities are: 
 [('PERSON', 'Bloedorn E.')] 

>> Stemming using Porter Stemmer: 
 [('Mani', 'mani'), ('I', 'i'), (',', ','), ('Bloedorn', 'bloedorn'), ('E.', 'e.'), ('Multi‑document', 'multi‑docu'), ('summarization', 'summar'), ('graph', 'graph'), ('search', 'search'), ('matching', 'match'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Mani', 'mani'), ('I', 'i'), (',', ','), ('Bloedorn', 'bloedorn'), ('E.', 'e.'), ('Multi‑document', 'multi‑docu'), ('summarization', 'summar'), ('graph', 'graph'), ('search', 'search'), ('matching', 'match'), ('.', '.')]

>> Lemmatization: 
 [('Mani', 'Mani'), ('I', 'I'), (',', ','), ('Bloedorn', 'Bloedorn'), ('E.', 'E.'), ('Multi‑document', 'Multi‑document'), ('summarization', 'summarization'), ('graph', 'graph'), ('search', 'search'), ('matching', 'matching'), ('.', '.')]


------------------- Sentence 3 -------------------

In: Proceedings of the National  Conference on Artificial Intelligence and Ninth Conference on Innovative Applications of Artificial Intelligence,  1997, pp 622–628.

>> Tokens are: 
 ['In', ':', 'Proceedings', 'National', 'Conference', 'Artificial', 'Intelligence', 'Ninth', 'Conference', 'Innovative', 'Applications', 'Artificial', 'Intelligence', ',', '1997', ',', 'pp', '622–628', '.']

>> Bigrams are: 
 [('In', ':'), (':', 'Proceedings'), ('Proceedings', 'National'), ('National', 'Conference'), ('Conference', 'Artificial'), ('Artificial', 'Intelligence'), ('Intelligence', 'Ninth'), ('Ninth', 'Conference'), ('Conference', 'Innovative'), ('Innovative', 'Applications'), ('Applications', 'Artificial'), ('Artificial', 'Intelligence'), ('Intelligence', ','), (',', '1997'), ('1997', ','), (',', 'pp'), ('pp', '622–628'), ('622–628', '.')]

>> Trigrams are: 
 [('In', ':', 'Proceedings'), (':', 'Proceedings', 'National'), ('Proceedings', 'National', 'Conference'), ('National', 'Conference', 'Artificial'), ('Conference', 'Artificial', 'Intelligence'), ('Artificial', 'Intelligence', 'Ninth'), ('Intelligence', 'Ninth', 'Conference'), ('Ninth', 'Conference', 'Innovative'), ('Conference', 'Innovative', 'Applications'), ('Innovative', 'Applications', 'Artificial'), ('Applications', 'Artificial', 'Intelligence'), ('Artificial', 'Intelligence', ','), ('Intelligence', ',', '1997'), (',', '1997', ','), ('1997', ',', 'pp'), (',', 'pp', '622–628'), ('pp', '622–628', '.')]

>> POS Tags are: 
 [('In', 'IN'), (':', ':'), ('Proceedings', 'NNS'), ('National', 'NNP'), ('Conference', 'NNP'), ('Artificial', 'NNP'), ('Intelligence', 'NNP'), ('Ninth', 'NNP'), ('Conference', 'NNP'), ('Innovative', 'NNP'), ('Applications', 'NNP'), ('Artificial', 'NNP'), ('Intelligence', 'NNP'), (',', ','), ('1997', 'CD'), (',', ','), ('pp', 'VBD'), ('622–628', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Proceedings National Conference Artificial Intelligence Ninth Conference Innovative Applications Artificial Intelligence']

>> Named Entities are: 
 [('ORGANIZATION', 'National Conference Artificial Intelligence Ninth Conference Innovative Applications Artificial Intelligence')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), (':', ':'), ('Proceedings', 'proceed'), ('National', 'nation'), ('Conference', 'confer'), ('Artificial', 'artifici'), ('Intelligence', 'intellig'), ('Ninth', 'ninth'), ('Conference', 'confer'), ('Innovative', 'innov'), ('Applications', 'applic'), ('Artificial', 'artifici'), ('Intelligence', 'intellig'), (',', ','), ('1997', '1997'), (',', ','), ('pp', 'pp'), ('622–628', '622–628'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), (':', ':'), ('Proceedings', 'proceed'), ('National', 'nation'), ('Conference', 'confer'), ('Artificial', 'artifici'), ('Intelligence', 'intellig'), ('Ninth', 'ninth'), ('Conference', 'confer'), ('Innovative', 'innov'), ('Applications', 'applic'), ('Artificial', 'artifici'), ('Intelligence', 'intellig'), (',', ','), ('1997', '1997'), (',', ','), ('pp', 'pp'), ('622–628', '622–628'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), (':', ':'), ('Proceedings', 'Proceedings'), ('National', 'National'), ('Conference', 'Conference'), ('Artificial', 'Artificial'), ('Intelligence', 'Intelligence'), ('Ninth', 'Ninth'), ('Conference', 'Conference'), ('Innovative', 'Innovative'), ('Applications', 'Applications'), ('Artificial', 'Artificial'), ('Intelligence', 'Intelligence'), (',', ','), ('1997', '1997'), (',', ','), ('pp', 'pp'), ('622–628', '622–628'), ('.', '.')]



========================================== PARAGRAPH 438 ===========================================

 41. Kopanakis I, Pelekis N, Karanikas H, Mavroudkis T. Visual techniques for the interpretation of data mining out‑ comes. In: Proceedings of the Panhellenic Conference on Advances in Informatics, 2005. pp 25–35. 

------------------- Sentence 1 -------------------

 41.

>> Tokens are: 
 ['41', '.']

>> Bigrams are: 
 [('41', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('41', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('41', '41'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('41', '41'), ('.', '.')]

>> Lemmatization: 
 [('41', '41'), ('.', '.')]


------------------- Sentence 2 -------------------

Kopanakis I, Pelekis N, Karanikas H, Mavroudkis T. Visual techniques for the interpretation of data mining out‑ comes.

>> Tokens are: 
 ['Kopanakis', 'I', ',', 'Pelekis', 'N', ',', 'Karanikas', 'H', ',', 'Mavroudkis', 'T.', 'Visual', 'techniques', 'interpretation', 'data', 'mining', 'out‑', 'comes', '.']

>> Bigrams are: 
 [('Kopanakis', 'I'), ('I', ','), (',', 'Pelekis'), ('Pelekis', 'N'), ('N', ','), (',', 'Karanikas'), ('Karanikas', 'H'), ('H', ','), (',', 'Mavroudkis'), ('Mavroudkis', 'T.'), ('T.', 'Visual'), ('Visual', 'techniques'), ('techniques', 'interpretation'), ('interpretation', 'data'), ('data', 'mining'), ('mining', 'out‑'), ('out‑', 'comes'), ('comes', '.')]

>> Trigrams are: 
 [('Kopanakis', 'I', ','), ('I', ',', 'Pelekis'), (',', 'Pelekis', 'N'), ('Pelekis', 'N', ','), ('N', ',', 'Karanikas'), (',', 'Karanikas', 'H'), ('Karanikas', 'H', ','), ('H', ',', 'Mavroudkis'), (',', 'Mavroudkis', 'T.'), ('Mavroudkis', 'T.', 'Visual'), ('T.', 'Visual', 'techniques'), ('Visual', 'techniques', 'interpretation'), ('techniques', 'interpretation', 'data'), ('interpretation', 'data', 'mining'), ('data', 'mining', 'out‑'), ('mining', 'out‑', 'comes'), ('out‑', 'comes', '.')]

>> POS Tags are: 
 [('Kopanakis', 'NNP'), ('I', 'PRP'), (',', ','), ('Pelekis', 'NNP'), ('N', 'NNP'), (',', ','), ('Karanikas', 'NNP'), ('H', 'NNP'), (',', ','), ('Mavroudkis', 'NNP'), ('T.', 'NNP'), ('Visual', 'NNP'), ('techniques', 'VBZ'), ('interpretation', 'NN'), ('data', 'NNS'), ('mining', 'NN'), ('out‑', 'NN'), ('comes', 'VBZ'), ('.', '.')]

>> Noun Phrases are: 
 ['Kopanakis', 'Pelekis N', 'Karanikas H', 'Mavroudkis T. Visual', 'interpretation data mining out‑']

>> Named Entities are: 
 [('PERSON', 'Pelekis N'), ('PERSON', 'Karanikas H'), ('PERSON', 'Mavroudkis T. Visual')] 

>> Stemming using Porter Stemmer: 
 [('Kopanakis', 'kopanaki'), ('I', 'i'), (',', ','), ('Pelekis', 'peleki'), ('N', 'n'), (',', ','), ('Karanikas', 'karanika'), ('H', 'h'), (',', ','), ('Mavroudkis', 'mavroudki'), ('T.', 't.'), ('Visual', 'visual'), ('techniques', 'techniqu'), ('interpretation', 'interpret'), ('data', 'data'), ('mining', 'mine'), ('out‑', 'out‑'), ('comes', 'come'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Kopanakis', 'kopanaki'), ('I', 'i'), (',', ','), ('Pelekis', 'peleki'), ('N', 'n'), (',', ','), ('Karanikas', 'karanika'), ('H', 'h'), (',', ','), ('Mavroudkis', 'mavroudki'), ('T.', 't.'), ('Visual', 'visual'), ('techniques', 'techniqu'), ('interpretation', 'interpret'), ('data', 'data'), ('mining', 'mine'), ('out‑', 'out‑'), ('comes', 'come'), ('.', '.')]

>> Lemmatization: 
 [('Kopanakis', 'Kopanakis'), ('I', 'I'), (',', ','), ('Pelekis', 'Pelekis'), ('N', 'N'), (',', ','), ('Karanikas', 'Karanikas'), ('H', 'H'), (',', ','), ('Mavroudkis', 'Mavroudkis'), ('T.', 'T.'), ('Visual', 'Visual'), ('techniques', 'technique'), ('interpretation', 'interpretation'), ('data', 'data'), ('mining', 'mining'), ('out‑', 'out‑'), ('comes', 'come'), ('.', '.')]


------------------- Sentence 3 -------------------

In: Proceedings of the Panhellenic Conference on Advances in Informatics, 2005. pp 25–35.

>> Tokens are: 
 ['In', ':', 'Proceedings', 'Panhellenic', 'Conference', 'Advances', 'Informatics', ',', '2005.', 'pp', '25–35', '.']

>> Bigrams are: 
 [('In', ':'), (':', 'Proceedings'), ('Proceedings', 'Panhellenic'), ('Panhellenic', 'Conference'), ('Conference', 'Advances'), ('Advances', 'Informatics'), ('Informatics', ','), (',', '2005.'), ('2005.', 'pp'), ('pp', '25–35'), ('25–35', '.')]

>> Trigrams are: 
 [('In', ':', 'Proceedings'), (':', 'Proceedings', 'Panhellenic'), ('Proceedings', 'Panhellenic', 'Conference'), ('Panhellenic', 'Conference', 'Advances'), ('Conference', 'Advances', 'Informatics'), ('Advances', 'Informatics', ','), ('Informatics', ',', '2005.'), (',', '2005.', 'pp'), ('2005.', 'pp', '25–35'), ('pp', '25–35', '.')]

>> POS Tags are: 
 [('In', 'IN'), (':', ':'), ('Proceedings', 'NNS'), ('Panhellenic', 'NNP'), ('Conference', 'NNP'), ('Advances', 'NNPS'), ('Informatics', 'NNP'), (',', ','), ('2005.', 'CD'), ('pp', 'NN'), ('25–35', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Proceedings Panhellenic Conference', 'Informatics', 'pp']

>> Named Entities are: 
 [('PERSON', 'Panhellenic Conference')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), (':', ':'), ('Proceedings', 'proceed'), ('Panhellenic', 'panhellen'), ('Conference', 'confer'), ('Advances', 'advanc'), ('Informatics', 'informat'), (',', ','), ('2005.', '2005.'), ('pp', 'pp'), ('25–35', '25–35'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), (':', ':'), ('Proceedings', 'proceed'), ('Panhellenic', 'panhellen'), ('Conference', 'confer'), ('Advances', 'advanc'), ('Informatics', 'informat'), (',', ','), ('2005.', '2005.'), ('pp', 'pp'), ('25–35', '25–35'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), (':', ':'), ('Proceedings', 'Proceedings'), ('Panhellenic', 'Panhellenic'), ('Conference', 'Conference'), ('Advances', 'Advances'), ('Informatics', 'Informatics'), (',', ','), ('2005.', '2005.'), ('pp', 'pp'), ('25–35', '25–35'), ('.', '.')]



========================================== PARAGRAPH 439 ===========================================

 42. Elkan C. Using the triangle inequality to accelerate k‑means. In: Proceedings of the International Conference on  Machine Learning, 2003, pp 147–153. 

------------------- Sentence 1 -------------------

 42.

>> Tokens are: 
 ['42', '.']

>> Bigrams are: 
 [('42', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('42', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('42', '42'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('42', '42'), ('.', '.')]

>> Lemmatization: 
 [('42', '42'), ('.', '.')]


------------------- Sentence 2 -------------------

Elkan C. Using the triangle inequality to accelerate k‑means.

>> Tokens are: 
 ['Elkan', 'C.', 'Using', 'triangle', 'inequality', 'accelerate', 'k‑means', '.']

>> Bigrams are: 
 [('Elkan', 'C.'), ('C.', 'Using'), ('Using', 'triangle'), ('triangle', 'inequality'), ('inequality', 'accelerate'), ('accelerate', 'k‑means'), ('k‑means', '.')]

>> Trigrams are: 
 [('Elkan', 'C.', 'Using'), ('C.', 'Using', 'triangle'), ('Using', 'triangle', 'inequality'), ('triangle', 'inequality', 'accelerate'), ('inequality', 'accelerate', 'k‑means'), ('accelerate', 'k‑means', '.')]

>> POS Tags are: 
 [('Elkan', 'NNP'), ('C.', 'NNP'), ('Using', 'NNP'), ('triangle', 'JJ'), ('inequality', 'NN'), ('accelerate', 'NN'), ('k‑means', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['Elkan C. Using', 'triangle inequality accelerate k‑means']

>> Named Entities are: 
 [('PERSON', 'Elkan')] 

>> Stemming using Porter Stemmer: 
 [('Elkan', 'elkan'), ('C.', 'c.'), ('Using', 'use'), ('triangle', 'triangl'), ('inequality', 'inequ'), ('accelerate', 'acceler'), ('k‑means', 'k‑mean'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Elkan', 'elkan'), ('C.', 'c.'), ('Using', 'use'), ('triangle', 'triangl'), ('inequality', 'inequ'), ('accelerate', 'acceler'), ('k‑means', 'k‑mean'), ('.', '.')]

>> Lemmatization: 
 [('Elkan', 'Elkan'), ('C.', 'C.'), ('Using', 'Using'), ('triangle', 'triangle'), ('inequality', 'inequality'), ('accelerate', 'accelerate'), ('k‑means', 'k‑means'), ('.', '.')]


------------------- Sentence 3 -------------------

In: Proceedings of the International Conference on  Machine Learning, 2003, pp 147–153.

>> Tokens are: 
 ['In', ':', 'Proceedings', 'International', 'Conference', 'Machine', 'Learning', ',', '2003', ',', 'pp', '147–153', '.']

>> Bigrams are: 
 [('In', ':'), (':', 'Proceedings'), ('Proceedings', 'International'), ('International', 'Conference'), ('Conference', 'Machine'), ('Machine', 'Learning'), ('Learning', ','), (',', '2003'), ('2003', ','), (',', 'pp'), ('pp', '147–153'), ('147–153', '.')]

>> Trigrams are: 
 [('In', ':', 'Proceedings'), (':', 'Proceedings', 'International'), ('Proceedings', 'International', 'Conference'), ('International', 'Conference', 'Machine'), ('Conference', 'Machine', 'Learning'), ('Machine', 'Learning', ','), ('Learning', ',', '2003'), (',', '2003', ','), ('2003', ',', 'pp'), (',', 'pp', '147–153'), ('pp', '147–153', '.')]

>> POS Tags are: 
 [('In', 'IN'), (':', ':'), ('Proceedings', 'NNS'), ('International', 'NNP'), ('Conference', 'NNP'), ('Machine', 'NNP'), ('Learning', 'NNP'), (',', ','), ('2003', 'CD'), (',', ','), ('pp', 'VBD'), ('147–153', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Proceedings International Conference Machine Learning']

>> Named Entities are: 
 [('ORGANIZATION', 'International Conference Machine Learning')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), (':', ':'), ('Proceedings', 'proceed'), ('International', 'intern'), ('Conference', 'confer'), ('Machine', 'machin'), ('Learning', 'learn'), (',', ','), ('2003', '2003'), (',', ','), ('pp', 'pp'), ('147–153', '147–153'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), (':', ':'), ('Proceedings', 'proceed'), ('International', 'intern'), ('Conference', 'confer'), ('Machine', 'machin'), ('Learning', 'learn'), (',', ','), ('2003', '2003'), (',', ','), ('pp', 'pp'), ('147–153', '147–153'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), (':', ':'), ('Proceedings', 'Proceedings'), ('International', 'International'), ('Conference', 'Conference'), ('Machine', 'Machine'), ('Learning', 'Learning'), (',', ','), ('2003', '2003'), (',', ','), ('pp', 'pp'), ('147–153', '147–153'), ('.', '.')]



========================================== PARAGRAPH 440 ===========================================

 43. Catanzaro B, Sundaram N, Keutzer K. Fast support vector machine training and classification on graphics proces‑ sors. In: Proceedings of the International Conference on Machine Learning, 2008. pp 104–111. 

------------------- Sentence 1 -------------------

 43.

>> Tokens are: 
 ['43', '.']

>> Bigrams are: 
 [('43', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('43', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('43', '43'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('43', '43'), ('.', '.')]

>> Lemmatization: 
 [('43', '43'), ('.', '.')]


------------------- Sentence 2 -------------------

Catanzaro B, Sundaram N, Keutzer K. Fast support vector machine training and classification on graphics proces‑ sors.

>> Tokens are: 
 ['Catanzaro', 'B', ',', 'Sundaram', 'N', ',', 'Keutzer', 'K.', 'Fast', 'support', 'vector', 'machine', 'training', 'classification', 'graphics', 'proces‑', 'sors', '.']

>> Bigrams are: 
 [('Catanzaro', 'B'), ('B', ','), (',', 'Sundaram'), ('Sundaram', 'N'), ('N', ','), (',', 'Keutzer'), ('Keutzer', 'K.'), ('K.', 'Fast'), ('Fast', 'support'), ('support', 'vector'), ('vector', 'machine'), ('machine', 'training'), ('training', 'classification'), ('classification', 'graphics'), ('graphics', 'proces‑'), ('proces‑', 'sors'), ('sors', '.')]

>> Trigrams are: 
 [('Catanzaro', 'B', ','), ('B', ',', 'Sundaram'), (',', 'Sundaram', 'N'), ('Sundaram', 'N', ','), ('N', ',', 'Keutzer'), (',', 'Keutzer', 'K.'), ('Keutzer', 'K.', 'Fast'), ('K.', 'Fast', 'support'), ('Fast', 'support', 'vector'), ('support', 'vector', 'machine'), ('vector', 'machine', 'training'), ('machine', 'training', 'classification'), ('training', 'classification', 'graphics'), ('classification', 'graphics', 'proces‑'), ('graphics', 'proces‑', 'sors'), ('proces‑', 'sors', '.')]

>> POS Tags are: 
 [('Catanzaro', 'NNP'), ('B', 'NNP'), (',', ','), ('Sundaram', 'NNP'), ('N', 'NNP'), (',', ','), ('Keutzer', 'NNP'), ('K.', 'NNP'), ('Fast', 'NNP'), ('support', 'NN'), ('vector', 'NN'), ('machine', 'NN'), ('training', 'NN'), ('classification', 'NN'), ('graphics', 'NNS'), ('proces‑', 'JJ'), ('sors', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['Catanzaro B', 'Sundaram N', 'Keutzer K. Fast support vector machine training classification graphics', 'proces‑ sors']

>> Named Entities are: 
 [('PERSON', 'Catanzaro'), ('ORGANIZATION', 'Sundaram N'), ('PERSON', 'Keutzer K. Fast')] 

>> Stemming using Porter Stemmer: 
 [('Catanzaro', 'catanzaro'), ('B', 'b'), (',', ','), ('Sundaram', 'sundaram'), ('N', 'n'), (',', ','), ('Keutzer', 'keutzer'), ('K.', 'k.'), ('Fast', 'fast'), ('support', 'support'), ('vector', 'vector'), ('machine', 'machin'), ('training', 'train'), ('classification', 'classif'), ('graphics', 'graphic'), ('proces‑', 'proces‑'), ('sors', 'sor'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Catanzaro', 'catanzaro'), ('B', 'b'), (',', ','), ('Sundaram', 'sundaram'), ('N', 'n'), (',', ','), ('Keutzer', 'keutzer'), ('K.', 'k.'), ('Fast', 'fast'), ('support', 'support'), ('vector', 'vector'), ('machine', 'machin'), ('training', 'train'), ('classification', 'classif'), ('graphics', 'graphic'), ('proces‑', 'proces‑'), ('sors', 'sor'), ('.', '.')]

>> Lemmatization: 
 [('Catanzaro', 'Catanzaro'), ('B', 'B'), (',', ','), ('Sundaram', 'Sundaram'), ('N', 'N'), (',', ','), ('Keutzer', 'Keutzer'), ('K.', 'K.'), ('Fast', 'Fast'), ('support', 'support'), ('vector', 'vector'), ('machine', 'machine'), ('training', 'training'), ('classification', 'classification'), ('graphics', 'graphic'), ('proces‑', 'proces‑'), ('sors', 'sors'), ('.', '.')]


------------------- Sentence 3 -------------------

In: Proceedings of the International Conference on Machine Learning, 2008. pp 104–111.

>> Tokens are: 
 ['In', ':', 'Proceedings', 'International', 'Conference', 'Machine', 'Learning', ',', '2008.', 'pp', '104–111', '.']

>> Bigrams are: 
 [('In', ':'), (':', 'Proceedings'), ('Proceedings', 'International'), ('International', 'Conference'), ('Conference', 'Machine'), ('Machine', 'Learning'), ('Learning', ','), (',', '2008.'), ('2008.', 'pp'), ('pp', '104–111'), ('104–111', '.')]

>> Trigrams are: 
 [('In', ':', 'Proceedings'), (':', 'Proceedings', 'International'), ('Proceedings', 'International', 'Conference'), ('International', 'Conference', 'Machine'), ('Conference', 'Machine', 'Learning'), ('Machine', 'Learning', ','), ('Learning', ',', '2008.'), (',', '2008.', 'pp'), ('2008.', 'pp', '104–111'), ('pp', '104–111', '.')]

>> POS Tags are: 
 [('In', 'IN'), (':', ':'), ('Proceedings', 'NNS'), ('International', 'NNP'), ('Conference', 'NNP'), ('Machine', 'NNP'), ('Learning', 'NNP'), (',', ','), ('2008.', 'CD'), ('pp', 'NN'), ('104–111', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Proceedings International Conference Machine Learning', 'pp']

>> Named Entities are: 
 [('ORGANIZATION', 'International Conference Machine Learning')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), (':', ':'), ('Proceedings', 'proceed'), ('International', 'intern'), ('Conference', 'confer'), ('Machine', 'machin'), ('Learning', 'learn'), (',', ','), ('2008.', '2008.'), ('pp', 'pp'), ('104–111', '104–111'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), (':', ':'), ('Proceedings', 'proceed'), ('International', 'intern'), ('Conference', 'confer'), ('Machine', 'machin'), ('Learning', 'learn'), (',', ','), ('2008.', '2008.'), ('pp', 'pp'), ('104–111', '104–111'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), (':', ':'), ('Proceedings', 'Proceedings'), ('International', 'International'), ('Conference', 'Conference'), ('Machine', 'Machine'), ('Learning', 'Learning'), (',', ','), ('2008.', '2008.'), ('pp', 'pp'), ('104–111', '104–111'), ('.', '.')]



========================================== PARAGRAPH 441 ===========================================

 44. Zhang T, Ramakrishnan R, Livny M. BIRCH: an efficient data clustering method for very large databases. In: Pro‑ ceedings of the ACM SIGMOD International Conference on Management of Data, 1996. pp 103–114. 

------------------- Sentence 1 -------------------

 44.

>> Tokens are: 
 ['44', '.']

>> Bigrams are: 
 [('44', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('44', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('44', '44'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('44', '44'), ('.', '.')]

>> Lemmatization: 
 [('44', '44'), ('.', '.')]


------------------- Sentence 2 -------------------

Zhang T, Ramakrishnan R, Livny M. BIRCH: an efficient data clustering method for very large databases.

>> Tokens are: 
 ['Zhang', 'T', ',', 'Ramakrishnan', 'R', ',', 'Livny', 'M.', 'BIRCH', ':', 'efficient', 'data', 'clustering', 'method', 'large', 'databases', '.']

>> Bigrams are: 
 [('Zhang', 'T'), ('T', ','), (',', 'Ramakrishnan'), ('Ramakrishnan', 'R'), ('R', ','), (',', 'Livny'), ('Livny', 'M.'), ('M.', 'BIRCH'), ('BIRCH', ':'), (':', 'efficient'), ('efficient', 'data'), ('data', 'clustering'), ('clustering', 'method'), ('method', 'large'), ('large', 'databases'), ('databases', '.')]

>> Trigrams are: 
 [('Zhang', 'T', ','), ('T', ',', 'Ramakrishnan'), (',', 'Ramakrishnan', 'R'), ('Ramakrishnan', 'R', ','), ('R', ',', 'Livny'), (',', 'Livny', 'M.'), ('Livny', 'M.', 'BIRCH'), ('M.', 'BIRCH', ':'), ('BIRCH', ':', 'efficient'), (':', 'efficient', 'data'), ('efficient', 'data', 'clustering'), ('data', 'clustering', 'method'), ('clustering', 'method', 'large'), ('method', 'large', 'databases'), ('large', 'databases', '.')]

>> POS Tags are: 
 [('Zhang', 'NNP'), ('T', 'NNP'), (',', ','), ('Ramakrishnan', 'NNP'), ('R', 'NNP'), (',', ','), ('Livny', 'NNP'), ('M.', 'NNP'), ('BIRCH', 'NNP'), (':', ':'), ('efficient', 'JJ'), ('data', 'NNS'), ('clustering', 'VBG'), ('method', 'NN'), ('large', 'JJ'), ('databases', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['Zhang T', 'Ramakrishnan R', 'Livny M. BIRCH', 'efficient data', 'method', 'large databases']

>> Named Entities are: 
 [('PERSON', 'Zhang'), ('ORGANIZATION', 'T'), ('PERSON', 'Ramakrishnan R'), ('PERSON', 'Livny M.')] 

>> Stemming using Porter Stemmer: 
 [('Zhang', 'zhang'), ('T', 't'), (',', ','), ('Ramakrishnan', 'ramakrishnan'), ('R', 'r'), (',', ','), ('Livny', 'livni'), ('M.', 'm.'), ('BIRCH', 'birch'), (':', ':'), ('efficient', 'effici'), ('data', 'data'), ('clustering', 'cluster'), ('method', 'method'), ('large', 'larg'), ('databases', 'databas'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Zhang', 'zhang'), ('T', 't'), (',', ','), ('Ramakrishnan', 'ramakrishnan'), ('R', 'r'), (',', ','), ('Livny', 'livni'), ('M.', 'm.'), ('BIRCH', 'birch'), (':', ':'), ('efficient', 'effici'), ('data', 'data'), ('clustering', 'cluster'), ('method', 'method'), ('large', 'larg'), ('databases', 'databas'), ('.', '.')]

>> Lemmatization: 
 [('Zhang', 'Zhang'), ('T', 'T'), (',', ','), ('Ramakrishnan', 'Ramakrishnan'), ('R', 'R'), (',', ','), ('Livny', 'Livny'), ('M.', 'M.'), ('BIRCH', 'BIRCH'), (':', ':'), ('efficient', 'efficient'), ('data', 'data'), ('clustering', 'clustering'), ('method', 'method'), ('large', 'large'), ('databases', 'database'), ('.', '.')]


------------------- Sentence 3 -------------------

In: Pro‑ ceedings of the ACM SIGMOD International Conference on Management of Data, 1996. pp 103–114.

>> Tokens are: 
 ['In', ':', 'Pro‑', 'ceedings', 'ACM', 'SIGMOD', 'International', 'Conference', 'Management', 'Data', ',', '1996.', 'pp', '103–114', '.']

>> Bigrams are: 
 [('In', ':'), (':', 'Pro‑'), ('Pro‑', 'ceedings'), ('ceedings', 'ACM'), ('ACM', 'SIGMOD'), ('SIGMOD', 'International'), ('International', 'Conference'), ('Conference', 'Management'), ('Management', 'Data'), ('Data', ','), (',', '1996.'), ('1996.', 'pp'), ('pp', '103–114'), ('103–114', '.')]

>> Trigrams are: 
 [('In', ':', 'Pro‑'), (':', 'Pro‑', 'ceedings'), ('Pro‑', 'ceedings', 'ACM'), ('ceedings', 'ACM', 'SIGMOD'), ('ACM', 'SIGMOD', 'International'), ('SIGMOD', 'International', 'Conference'), ('International', 'Conference', 'Management'), ('Conference', 'Management', 'Data'), ('Management', 'Data', ','), ('Data', ',', '1996.'), (',', '1996.', 'pp'), ('1996.', 'pp', '103–114'), ('pp', '103–114', '.')]

>> POS Tags are: 
 [('In', 'IN'), (':', ':'), ('Pro‑', 'NNP'), ('ceedings', 'NNS'), ('ACM', 'NNP'), ('SIGMOD', 'NNP'), ('International', 'NNP'), ('Conference', 'NNP'), ('Management', 'NNP'), ('Data', 'NNP'), (',', ','), ('1996.', 'CD'), ('pp', 'NN'), ('103–114', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Pro‑ ceedings ACM SIGMOD International Conference Management Data', 'pp']

>> Named Entities are: 
 [('ORGANIZATION', 'ACM'), ('ORGANIZATION', 'SIGMOD International Conference Management Data')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), (':', ':'), ('Pro‑', 'pro‑'), ('ceedings', 'ceed'), ('ACM', 'acm'), ('SIGMOD', 'sigmod'), ('International', 'intern'), ('Conference', 'confer'), ('Management', 'manag'), ('Data', 'data'), (',', ','), ('1996.', '1996.'), ('pp', 'pp'), ('103–114', '103–114'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), (':', ':'), ('Pro‑', 'pro‑'), ('ceedings', 'ceed'), ('ACM', 'acm'), ('SIGMOD', 'sigmod'), ('International', 'intern'), ('Conference', 'confer'), ('Management', 'manag'), ('Data', 'data'), (',', ','), ('1996.', '1996.'), ('pp', 'pp'), ('103–114', '103–114'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), (':', ':'), ('Pro‑', 'Pro‑'), ('ceedings', 'ceedings'), ('ACM', 'ACM'), ('SIGMOD', 'SIGMOD'), ('International', 'International'), ('Conference', 'Conference'), ('Management', 'Management'), ('Data', 'Data'), (',', ','), ('1996.', '1996.'), ('pp', 'pp'), ('103–114', '103–114'), ('.', '.')]



========================================== PARAGRAPH 442 ===========================================

 45. Ester M, Kriegel HP, Sander J, Xu X. A density‑based algorithm for discovering clusters in large spatial databases  with noise. In: Proceedings of the Second International Conference on Knowledge Discovery and Data Mining,  1996. pp 226–231. 

------------------- Sentence 1 -------------------

 45.

>> Tokens are: 
 ['45', '.']

>> Bigrams are: 
 [('45', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('45', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('45', '45'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('45', '45'), ('.', '.')]

>> Lemmatization: 
 [('45', '45'), ('.', '.')]


------------------- Sentence 2 -------------------

Ester M, Kriegel HP, Sander J, Xu X.

>> Tokens are: 
 ['Ester', 'M', ',', 'Kriegel', 'HP', ',', 'Sander', 'J', ',', 'Xu', 'X', '.']

>> Bigrams are: 
 [('Ester', 'M'), ('M', ','), (',', 'Kriegel'), ('Kriegel', 'HP'), ('HP', ','), (',', 'Sander'), ('Sander', 'J'), ('J', ','), (',', 'Xu'), ('Xu', 'X'), ('X', '.')]

>> Trigrams are: 
 [('Ester', 'M', ','), ('M', ',', 'Kriegel'), (',', 'Kriegel', 'HP'), ('Kriegel', 'HP', ','), ('HP', ',', 'Sander'), (',', 'Sander', 'J'), ('Sander', 'J', ','), ('J', ',', 'Xu'), (',', 'Xu', 'X'), ('Xu', 'X', '.')]

>> POS Tags are: 
 [('Ester', 'NNP'), ('M', 'NNP'), (',', ','), ('Kriegel', 'NNP'), ('HP', 'NNP'), (',', ','), ('Sander', 'NNP'), ('J', 'NNP'), (',', ','), ('Xu', 'NNP'), ('X', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Ester M', 'Kriegel HP', 'Sander J', 'Xu X']

>> Named Entities are: 
 [('PERSON', 'Ester'), ('PERSON', 'Kriegel HP'), ('PERSON', 'Sander J'), ('PERSON', 'Xu X')] 

>> Stemming using Porter Stemmer: 
 [('Ester', 'ester'), ('M', 'm'), (',', ','), ('Kriegel', 'kriegel'), ('HP', 'hp'), (',', ','), ('Sander', 'sander'), ('J', 'j'), (',', ','), ('Xu', 'xu'), ('X', 'x'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Ester', 'ester'), ('M', 'm'), (',', ','), ('Kriegel', 'kriegel'), ('HP', 'hp'), (',', ','), ('Sander', 'sander'), ('J', 'j'), (',', ','), ('Xu', 'xu'), ('X', 'x'), ('.', '.')]

>> Lemmatization: 
 [('Ester', 'Ester'), ('M', 'M'), (',', ','), ('Kriegel', 'Kriegel'), ('HP', 'HP'), (',', ','), ('Sander', 'Sander'), ('J', 'J'), (',', ','), ('Xu', 'Xu'), ('X', 'X'), ('.', '.')]


------------------- Sentence 3 -------------------

A density‑based algorithm for discovering clusters in large spatial databases  with noise.

>> Tokens are: 
 ['A', 'density‑based', 'algorithm', 'discovering', 'clusters', 'large', 'spatial', 'databases', 'noise', '.']

>> Bigrams are: 
 [('A', 'density‑based'), ('density‑based', 'algorithm'), ('algorithm', 'discovering'), ('discovering', 'clusters'), ('clusters', 'large'), ('large', 'spatial'), ('spatial', 'databases'), ('databases', 'noise'), ('noise', '.')]

>> Trigrams are: 
 [('A', 'density‑based', 'algorithm'), ('density‑based', 'algorithm', 'discovering'), ('algorithm', 'discovering', 'clusters'), ('discovering', 'clusters', 'large'), ('clusters', 'large', 'spatial'), ('large', 'spatial', 'databases'), ('spatial', 'databases', 'noise'), ('databases', 'noise', '.')]

>> POS Tags are: 
 [('A', 'DT'), ('density‑based', 'JJ'), ('algorithm', 'NN'), ('discovering', 'VBG'), ('clusters', 'NNS'), ('large', 'JJ'), ('spatial', 'JJ'), ('databases', 'NNS'), ('noise', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['A density‑based algorithm', 'clusters', 'large spatial databases noise']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('A', 'a'), ('density‑based', 'density‑bas'), ('algorithm', 'algorithm'), ('discovering', 'discov'), ('clusters', 'cluster'), ('large', 'larg'), ('spatial', 'spatial'), ('databases', 'databas'), ('noise', 'nois'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('A', 'a'), ('density‑based', 'density‑bas'), ('algorithm', 'algorithm'), ('discovering', 'discov'), ('clusters', 'cluster'), ('large', 'larg'), ('spatial', 'spatial'), ('databases', 'databas'), ('noise', 'nois'), ('.', '.')]

>> Lemmatization: 
 [('A', 'A'), ('density‑based', 'density‑based'), ('algorithm', 'algorithm'), ('discovering', 'discovering'), ('clusters', 'cluster'), ('large', 'large'), ('spatial', 'spatial'), ('databases', 'database'), ('noise', 'noise'), ('.', '.')]


------------------- Sentence 4 -------------------

In: Proceedings of the Second International Conference on Knowledge Discovery and Data Mining,  1996. pp 226–231.

>> Tokens are: 
 ['In', ':', 'Proceedings', 'Second', 'International', 'Conference', 'Knowledge', 'Discovery', 'Data', 'Mining', ',', '1996.', 'pp', '226–231', '.']

>> Bigrams are: 
 [('In', ':'), (':', 'Proceedings'), ('Proceedings', 'Second'), ('Second', 'International'), ('International', 'Conference'), ('Conference', 'Knowledge'), ('Knowledge', 'Discovery'), ('Discovery', 'Data'), ('Data', 'Mining'), ('Mining', ','), (',', '1996.'), ('1996.', 'pp'), ('pp', '226–231'), ('226–231', '.')]

>> Trigrams are: 
 [('In', ':', 'Proceedings'), (':', 'Proceedings', 'Second'), ('Proceedings', 'Second', 'International'), ('Second', 'International', 'Conference'), ('International', 'Conference', 'Knowledge'), ('Conference', 'Knowledge', 'Discovery'), ('Knowledge', 'Discovery', 'Data'), ('Discovery', 'Data', 'Mining'), ('Data', 'Mining', ','), ('Mining', ',', '1996.'), (',', '1996.', 'pp'), ('1996.', 'pp', '226–231'), ('pp', '226–231', '.')]

>> POS Tags are: 
 [('In', 'IN'), (':', ':'), ('Proceedings', 'NNS'), ('Second', 'NNP'), ('International', 'NNP'), ('Conference', 'NNP'), ('Knowledge', 'NNP'), ('Discovery', 'NNP'), ('Data', 'NNP'), ('Mining', 'NNP'), (',', ','), ('1996.', 'CD'), ('pp', 'NN'), ('226–231', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Proceedings Second International Conference Knowledge Discovery Data Mining', 'pp']

>> Named Entities are: 
 [('ORGANIZATION', 'Second International Conference')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), (':', ':'), ('Proceedings', 'proceed'), ('Second', 'second'), ('International', 'intern'), ('Conference', 'confer'), ('Knowledge', 'knowledg'), ('Discovery', 'discoveri'), ('Data', 'data'), ('Mining', 'mine'), (',', ','), ('1996.', '1996.'), ('pp', 'pp'), ('226–231', '226–231'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), (':', ':'), ('Proceedings', 'proceed'), ('Second', 'second'), ('International', 'intern'), ('Conference', 'confer'), ('Knowledge', 'knowledg'), ('Discovery', 'discoveri'), ('Data', 'data'), ('Mining', 'mine'), (',', ','), ('1996.', '1996.'), ('pp', 'pp'), ('226–231', '226–231'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), (':', ':'), ('Proceedings', 'Proceedings'), ('Second', 'Second'), ('International', 'International'), ('Conference', 'Conference'), ('Knowledge', 'Knowledge'), ('Discovery', 'Discovery'), ('Data', 'Data'), ('Mining', 'Mining'), (',', ','), ('1996.', '1996.'), ('pp', 'pp'), ('226–231', '226–231'), ('.', '.')]



========================================== PARAGRAPH 443 ===========================================

 46. Ester M, Kriegel HP, Sander J, Wimmer M, Xu X. Incremental clustering for mining in a data warehousing environ‑ ment. In: Proceedings of the International Conference on Very Large Data Bases, 1998. pp 323–333. 

------------------- Sentence 1 -------------------

 46.

>> Tokens are: 
 ['46', '.']

>> Bigrams are: 
 [('46', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('46', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('46', '46'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('46', '46'), ('.', '.')]

>> Lemmatization: 
 [('46', '46'), ('.', '.')]


------------------- Sentence 2 -------------------

Ester M, Kriegel HP, Sander J, Wimmer M, Xu X.

>> Tokens are: 
 ['Ester', 'M', ',', 'Kriegel', 'HP', ',', 'Sander', 'J', ',', 'Wimmer', 'M', ',', 'Xu', 'X', '.']

>> Bigrams are: 
 [('Ester', 'M'), ('M', ','), (',', 'Kriegel'), ('Kriegel', 'HP'), ('HP', ','), (',', 'Sander'), ('Sander', 'J'), ('J', ','), (',', 'Wimmer'), ('Wimmer', 'M'), ('M', ','), (',', 'Xu'), ('Xu', 'X'), ('X', '.')]

>> Trigrams are: 
 [('Ester', 'M', ','), ('M', ',', 'Kriegel'), (',', 'Kriegel', 'HP'), ('Kriegel', 'HP', ','), ('HP', ',', 'Sander'), (',', 'Sander', 'J'), ('Sander', 'J', ','), ('J', ',', 'Wimmer'), (',', 'Wimmer', 'M'), ('Wimmer', 'M', ','), ('M', ',', 'Xu'), (',', 'Xu', 'X'), ('Xu', 'X', '.')]

>> POS Tags are: 
 [('Ester', 'NNP'), ('M', 'NNP'), (',', ','), ('Kriegel', 'NNP'), ('HP', 'NNP'), (',', ','), ('Sander', 'NNP'), ('J', 'NNP'), (',', ','), ('Wimmer', 'NNP'), ('M', 'NNP'), (',', ','), ('Xu', 'NNP'), ('X', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Ester M', 'Kriegel HP', 'Sander J', 'Wimmer M', 'Xu X']

>> Named Entities are: 
 [('PERSON', 'Ester'), ('PERSON', 'Kriegel HP'), ('PERSON', 'Sander J'), ('PERSON', 'Wimmer M'), ('PERSON', 'Xu X')] 

>> Stemming using Porter Stemmer: 
 [('Ester', 'ester'), ('M', 'm'), (',', ','), ('Kriegel', 'kriegel'), ('HP', 'hp'), (',', ','), ('Sander', 'sander'), ('J', 'j'), (',', ','), ('Wimmer', 'wimmer'), ('M', 'm'), (',', ','), ('Xu', 'xu'), ('X', 'x'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Ester', 'ester'), ('M', 'm'), (',', ','), ('Kriegel', 'kriegel'), ('HP', 'hp'), (',', ','), ('Sander', 'sander'), ('J', 'j'), (',', ','), ('Wimmer', 'wimmer'), ('M', 'm'), (',', ','), ('Xu', 'xu'), ('X', 'x'), ('.', '.')]

>> Lemmatization: 
 [('Ester', 'Ester'), ('M', 'M'), (',', ','), ('Kriegel', 'Kriegel'), ('HP', 'HP'), (',', ','), ('Sander', 'Sander'), ('J', 'J'), (',', ','), ('Wimmer', 'Wimmer'), ('M', 'M'), (',', ','), ('Xu', 'Xu'), ('X', 'X'), ('.', '.')]


------------------- Sentence 3 -------------------

Incremental clustering for mining in a data warehousing environ‑ ment.

>> Tokens are: 
 ['Incremental', 'clustering', 'mining', 'data', 'warehousing', 'environ‑', 'ment', '.']

>> Bigrams are: 
 [('Incremental', 'clustering'), ('clustering', 'mining'), ('mining', 'data'), ('data', 'warehousing'), ('warehousing', 'environ‑'), ('environ‑', 'ment'), ('ment', '.')]

>> Trigrams are: 
 [('Incremental', 'clustering', 'mining'), ('clustering', 'mining', 'data'), ('mining', 'data', 'warehousing'), ('data', 'warehousing', 'environ‑'), ('warehousing', 'environ‑', 'ment'), ('environ‑', 'ment', '.')]

>> POS Tags are: 
 [('Incremental', 'JJ'), ('clustering', 'VBG'), ('mining', 'NN'), ('data', 'NNS'), ('warehousing', 'VBG'), ('environ‑', 'JJ'), ('ment', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['mining data', 'environ‑ ment']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Incremental', 'increment'), ('clustering', 'cluster'), ('mining', 'mine'), ('data', 'data'), ('warehousing', 'wareh'), ('environ‑', 'environ‑'), ('ment', 'ment'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Incremental', 'increment'), ('clustering', 'cluster'), ('mining', 'mine'), ('data', 'data'), ('warehousing', 'wareh'), ('environ‑', 'environ‑'), ('ment', 'ment'), ('.', '.')]

>> Lemmatization: 
 [('Incremental', 'Incremental'), ('clustering', 'clustering'), ('mining', 'mining'), ('data', 'data'), ('warehousing', 'warehousing'), ('environ‑', 'environ‑'), ('ment', 'ment'), ('.', '.')]


------------------- Sentence 4 -------------------

In: Proceedings of the International Conference on Very Large Data Bases, 1998. pp 323–333.

>> Tokens are: 
 ['In', ':', 'Proceedings', 'International', 'Conference', 'Very', 'Large', 'Data', 'Bases', ',', '1998.', 'pp', '323–333', '.']

>> Bigrams are: 
 [('In', ':'), (':', 'Proceedings'), ('Proceedings', 'International'), ('International', 'Conference'), ('Conference', 'Very'), ('Very', 'Large'), ('Large', 'Data'), ('Data', 'Bases'), ('Bases', ','), (',', '1998.'), ('1998.', 'pp'), ('pp', '323–333'), ('323–333', '.')]

>> Trigrams are: 
 [('In', ':', 'Proceedings'), (':', 'Proceedings', 'International'), ('Proceedings', 'International', 'Conference'), ('International', 'Conference', 'Very'), ('Conference', 'Very', 'Large'), ('Very', 'Large', 'Data'), ('Large', 'Data', 'Bases'), ('Data', 'Bases', ','), ('Bases', ',', '1998.'), (',', '1998.', 'pp'), ('1998.', 'pp', '323–333'), ('pp', '323–333', '.')]

>> POS Tags are: 
 [('In', 'IN'), (':', ':'), ('Proceedings', 'NNS'), ('International', 'NNP'), ('Conference', 'NNP'), ('Very', 'NNP'), ('Large', 'NNP'), ('Data', 'NNP'), ('Bases', 'NNP'), (',', ','), ('1998.', 'CD'), ('pp', 'NN'), ('323–333', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Proceedings International Conference Very Large Data Bases', 'pp']

>> Named Entities are: 
 [('ORGANIZATION', 'International Conference Very Large Data Bases')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), (':', ':'), ('Proceedings', 'proceed'), ('International', 'intern'), ('Conference', 'confer'), ('Very', 'veri'), ('Large', 'larg'), ('Data', 'data'), ('Bases', 'base'), (',', ','), ('1998.', '1998.'), ('pp', 'pp'), ('323–333', '323–333'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), (':', ':'), ('Proceedings', 'proceed'), ('International', 'intern'), ('Conference', 'confer'), ('Very', 'veri'), ('Large', 'larg'), ('Data', 'data'), ('Bases', 'base'), (',', ','), ('1998.', '1998.'), ('pp', 'pp'), ('323–333', '323–333'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), (':', ':'), ('Proceedings', 'Proceedings'), ('International', 'International'), ('Conference', 'Conference'), ('Very', 'Very'), ('Large', 'Large'), ('Data', 'Data'), ('Bases', 'Bases'), (',', ','), ('1998.', '1998.'), ('pp', 'pp'), ('323–333', '323–333'), ('.', '.')]



========================================== PARAGRAPH 444 ===========================================

 47. Ordonez C, Omiecinski E. Efficient disk‑based k‑means clustering for relational databases. IEEE Trans Knowl Data  Eng. 2004;16(8):909–21. 

------------------- Sentence 1 -------------------

 47.

>> Tokens are: 
 ['47', '.']

>> Bigrams are: 
 [('47', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('47', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('47', '47'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('47', '47'), ('.', '.')]

>> Lemmatization: 
 [('47', '47'), ('.', '.')]


------------------- Sentence 2 -------------------

Ordonez C, Omiecinski E. Efficient disk‑based k‑means clustering for relational databases.

>> Tokens are: 
 ['Ordonez', 'C', ',', 'Omiecinski', 'E.', 'Efficient', 'disk‑based', 'k‑means', 'clustering', 'relational', 'databases', '.']

>> Bigrams are: 
 [('Ordonez', 'C'), ('C', ','), (',', 'Omiecinski'), ('Omiecinski', 'E.'), ('E.', 'Efficient'), ('Efficient', 'disk‑based'), ('disk‑based', 'k‑means'), ('k‑means', 'clustering'), ('clustering', 'relational'), ('relational', 'databases'), ('databases', '.')]

>> Trigrams are: 
 [('Ordonez', 'C', ','), ('C', ',', 'Omiecinski'), (',', 'Omiecinski', 'E.'), ('Omiecinski', 'E.', 'Efficient'), ('E.', 'Efficient', 'disk‑based'), ('Efficient', 'disk‑based', 'k‑means'), ('disk‑based', 'k‑means', 'clustering'), ('k‑means', 'clustering', 'relational'), ('clustering', 'relational', 'databases'), ('relational', 'databases', '.')]

>> POS Tags are: 
 [('Ordonez', 'NNP'), ('C', 'NNP'), (',', ','), ('Omiecinski', 'NNP'), ('E.', 'NNP'), ('Efficient', 'NNP'), ('disk‑based', 'VBD'), ('k‑means', 'NNS'), ('clustering', 'VBG'), ('relational', 'JJ'), ('databases', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['Ordonez C', 'Omiecinski E. Efficient', 'k‑means', 'relational databases']

>> Named Entities are: 
 [('PERSON', 'Ordonez'), ('PERSON', 'Omiecinski E. Efficient')] 

>> Stemming using Porter Stemmer: 
 [('Ordonez', 'ordonez'), ('C', 'c'), (',', ','), ('Omiecinski', 'omiecinski'), ('E.', 'e.'), ('Efficient', 'effici'), ('disk‑based', 'disk‑bas'), ('k‑means', 'k‑mean'), ('clustering', 'cluster'), ('relational', 'relat'), ('databases', 'databas'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Ordonez', 'ordonez'), ('C', 'c'), (',', ','), ('Omiecinski', 'omiecinski'), ('E.', 'e.'), ('Efficient', 'effici'), ('disk‑based', 'disk‑bas'), ('k‑means', 'k‑mean'), ('clustering', 'cluster'), ('relational', 'relat'), ('databases', 'databas'), ('.', '.')]

>> Lemmatization: 
 [('Ordonez', 'Ordonez'), ('C', 'C'), (',', ','), ('Omiecinski', 'Omiecinski'), ('E.', 'E.'), ('Efficient', 'Efficient'), ('disk‑based', 'disk‑based'), ('k‑means', 'k‑means'), ('clustering', 'clustering'), ('relational', 'relational'), ('databases', 'database'), ('.', '.')]


------------------- Sentence 3 -------------------

IEEE Trans Knowl Data  Eng.

>> Tokens are: 
 ['IEEE', 'Trans', 'Knowl', 'Data', 'Eng', '.']

>> Bigrams are: 
 [('IEEE', 'Trans'), ('Trans', 'Knowl'), ('Knowl', 'Data'), ('Data', 'Eng'), ('Eng', '.')]

>> Trigrams are: 
 [('IEEE', 'Trans', 'Knowl'), ('Trans', 'Knowl', 'Data'), ('Knowl', 'Data', 'Eng'), ('Data', 'Eng', '.')]

>> POS Tags are: 
 [('IEEE', 'NNP'), ('Trans', 'NNP'), ('Knowl', 'NNP'), ('Data', 'NNP'), ('Eng', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['IEEE Trans Knowl Data Eng']

>> Named Entities are: 
 [('ORGANIZATION', 'IEEE'), ('PERSON', 'Trans Knowl Data Eng')] 

>> Stemming using Porter Stemmer: 
 [('IEEE', 'ieee'), ('Trans', 'tran'), ('Knowl', 'knowl'), ('Data', 'data'), ('Eng', 'eng'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('IEEE', 'ieee'), ('Trans', 'tran'), ('Knowl', 'knowl'), ('Data', 'data'), ('Eng', 'eng'), ('.', '.')]

>> Lemmatization: 
 [('IEEE', 'IEEE'), ('Trans', 'Trans'), ('Knowl', 'Knowl'), ('Data', 'Data'), ('Eng', 'Eng'), ('.', '.')]


------------------- Sentence 4 -------------------

2004;16(8):909–21.

>> Tokens are: 
 ['2004', ';', '16', '(', '8', ')', ':909–21', '.']

>> Bigrams are: 
 [('2004', ';'), (';', '16'), ('16', '('), ('(', '8'), ('8', ')'), (')', ':909–21'), (':909–21', '.')]

>> Trigrams are: 
 [('2004', ';', '16'), (';', '16', '('), ('16', '(', '8'), ('(', '8', ')'), ('8', ')', ':909–21'), (')', ':909–21', '.')]

>> POS Tags are: 
 [('2004', 'CD'), (';', ':'), ('16', 'CD'), ('(', '('), ('8', 'CD'), (')', ')'), (':909–21', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 [':909–21']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('2004', '2004'), (';', ';'), ('16', '16'), ('(', '('), ('8', '8'), (')', ')'), (':909–21', ':909–21'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('2004', '2004'), (';', ';'), ('16', '16'), ('(', '('), ('8', '8'), (')', ')'), (':909–21', ':909–21'), ('.', '.')]

>> Lemmatization: 
 [('2004', '2004'), (';', ';'), ('16', '16'), ('(', '('), ('8', '8'), (')', ')'), (':909–21', ':909–21'), ('.', '.')]



========================================== PARAGRAPH 445 ===========================================

 48. Kogan J. Introduction to clustering large and high‑dimensional data. Cambridge: Cambridge Univ Press; 2007.  49. Mitra S, Pal S, Mitra P. Data mining in soft computing framework: a survey. IEEE Trans Neural Netw. 2002;13(1):3–14.  50. Mehta M, Agrawal R, Rissanen J. SLIQ: a fast scalable classifier for data mining. In: Proceedings of the 5th Interna‑ 

------------------- Sentence 1 -------------------

 48.

>> Tokens are: 
 ['48', '.']

>> Bigrams are: 
 [('48', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('48', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('48', '48'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('48', '48'), ('.', '.')]

>> Lemmatization: 
 [('48', '48'), ('.', '.')]


------------------- Sentence 2 -------------------

Kogan J.

>> Tokens are: 
 ['Kogan', 'J', '.']

>> Bigrams are: 
 [('Kogan', 'J'), ('J', '.')]

>> Trigrams are: 
 [('Kogan', 'J', '.')]

>> POS Tags are: 
 [('Kogan', 'NNP'), ('J', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Kogan J']

>> Named Entities are: 
 [('PERSON', 'Kogan')] 

>> Stemming using Porter Stemmer: 
 [('Kogan', 'kogan'), ('J', 'j'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Kogan', 'kogan'), ('J', 'j'), ('.', '.')]

>> Lemmatization: 
 [('Kogan', 'Kogan'), ('J', 'J'), ('.', '.')]


------------------- Sentence 3 -------------------

Introduction to clustering large and high‑dimensional data.

>> Tokens are: 
 ['Introduction', 'clustering', 'large', 'high‑dimensional', 'data', '.']

>> Bigrams are: 
 [('Introduction', 'clustering'), ('clustering', 'large'), ('large', 'high‑dimensional'), ('high‑dimensional', 'data'), ('data', '.')]

>> Trigrams are: 
 [('Introduction', 'clustering', 'large'), ('clustering', 'large', 'high‑dimensional'), ('large', 'high‑dimensional', 'data'), ('high‑dimensional', 'data', '.')]

>> POS Tags are: 
 [('Introduction', 'NN'), ('clustering', 'VBG'), ('large', 'JJ'), ('high‑dimensional', 'JJ'), ('data', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['Introduction', 'large high‑dimensional data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Introduction', 'introduct'), ('clustering', 'cluster'), ('large', 'larg'), ('high‑dimensional', 'high‑dimension'), ('data', 'data'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Introduction', 'introduct'), ('clustering', 'cluster'), ('large', 'larg'), ('high‑dimensional', 'high‑dimension'), ('data', 'data'), ('.', '.')]

>> Lemmatization: 
 [('Introduction', 'Introduction'), ('clustering', 'clustering'), ('large', 'large'), ('high‑dimensional', 'high‑dimensional'), ('data', 'data'), ('.', '.')]


------------------- Sentence 4 -------------------

Cambridge: Cambridge Univ Press; 2007.

>> Tokens are: 
 ['Cambridge', ':', 'Cambridge', 'Univ', 'Press', ';', '2007', '.']

>> Bigrams are: 
 [('Cambridge', ':'), (':', 'Cambridge'), ('Cambridge', 'Univ'), ('Univ', 'Press'), ('Press', ';'), (';', '2007'), ('2007', '.')]

>> Trigrams are: 
 [('Cambridge', ':', 'Cambridge'), (':', 'Cambridge', 'Univ'), ('Cambridge', 'Univ', 'Press'), ('Univ', 'Press', ';'), ('Press', ';', '2007'), (';', '2007', '.')]

>> POS Tags are: 
 [('Cambridge', 'NN'), (':', ':'), ('Cambridge', 'NNP'), ('Univ', 'NNP'), ('Press', 'NNP'), (';', ':'), ('2007', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Cambridge', 'Cambridge Univ Press']

>> Named Entities are: 
 [('GPE', 'Cambridge'), ('PERSON', 'Cambridge Univ Press')] 

>> Stemming using Porter Stemmer: 
 [('Cambridge', 'cambridg'), (':', ':'), ('Cambridge', 'cambridg'), ('Univ', 'univ'), ('Press', 'press'), (';', ';'), ('2007', '2007'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Cambridge', 'cambridg'), (':', ':'), ('Cambridge', 'cambridg'), ('Univ', 'univ'), ('Press', 'press'), (';', ';'), ('2007', '2007'), ('.', '.')]

>> Lemmatization: 
 [('Cambridge', 'Cambridge'), (':', ':'), ('Cambridge', 'Cambridge'), ('Univ', 'Univ'), ('Press', 'Press'), (';', ';'), ('2007', '2007'), ('.', '.')]


------------------- Sentence 5 -------------------

49.

>> Tokens are: 
 ['49', '.']

>> Bigrams are: 
 [('49', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('49', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('49', '49'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('49', '49'), ('.', '.')]

>> Lemmatization: 
 [('49', '49'), ('.', '.')]


------------------- Sentence 6 -------------------

Mitra S, Pal S, Mitra P. Data mining in soft computing framework: a survey.

>> Tokens are: 
 ['Mitra', 'S', ',', 'Pal', 'S', ',', 'Mitra', 'P.', 'Data', 'mining', 'soft', 'computing', 'framework', ':', 'survey', '.']

>> Bigrams are: 
 [('Mitra', 'S'), ('S', ','), (',', 'Pal'), ('Pal', 'S'), ('S', ','), (',', 'Mitra'), ('Mitra', 'P.'), ('P.', 'Data'), ('Data', 'mining'), ('mining', 'soft'), ('soft', 'computing'), ('computing', 'framework'), ('framework', ':'), (':', 'survey'), ('survey', '.')]

>> Trigrams are: 
 [('Mitra', 'S', ','), ('S', ',', 'Pal'), (',', 'Pal', 'S'), ('Pal', 'S', ','), ('S', ',', 'Mitra'), (',', 'Mitra', 'P.'), ('Mitra', 'P.', 'Data'), ('P.', 'Data', 'mining'), ('Data', 'mining', 'soft'), ('mining', 'soft', 'computing'), ('soft', 'computing', 'framework'), ('computing', 'framework', ':'), ('framework', ':', 'survey'), (':', 'survey', '.')]

>> POS Tags are: 
 [('Mitra', 'NNP'), ('S', 'NNP'), (',', ','), ('Pal', 'NNP'), ('S', 'NNP'), (',', ','), ('Mitra', 'NNP'), ('P.', 'NNP'), ('Data', 'NNP'), ('mining', 'NN'), ('soft', 'JJ'), ('computing', 'VBG'), ('framework', 'NN'), (':', ':'), ('survey', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Mitra S', 'Pal S', 'Mitra P. Data mining', 'framework', 'survey']

>> Named Entities are: 
 [('PERSON', 'Mitra'), ('ORGANIZATION', 'S'), ('PERSON', 'Pal S'), ('PERSON', 'Mitra P. Data')] 

>> Stemming using Porter Stemmer: 
 [('Mitra', 'mitra'), ('S', 's'), (',', ','), ('Pal', 'pal'), ('S', 's'), (',', ','), ('Mitra', 'mitra'), ('P.', 'p.'), ('Data', 'data'), ('mining', 'mine'), ('soft', 'soft'), ('computing', 'comput'), ('framework', 'framework'), (':', ':'), ('survey', 'survey'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Mitra', 'mitra'), ('S', 's'), (',', ','), ('Pal', 'pal'), ('S', 's'), (',', ','), ('Mitra', 'mitra'), ('P.', 'p.'), ('Data', 'data'), ('mining', 'mine'), ('soft', 'soft'), ('computing', 'comput'), ('framework', 'framework'), (':', ':'), ('survey', 'survey'), ('.', '.')]

>> Lemmatization: 
 [('Mitra', 'Mitra'), ('S', 'S'), (',', ','), ('Pal', 'Pal'), ('S', 'S'), (',', ','), ('Mitra', 'Mitra'), ('P.', 'P.'), ('Data', 'Data'), ('mining', 'mining'), ('soft', 'soft'), ('computing', 'computing'), ('framework', 'framework'), (':', ':'), ('survey', 'survey'), ('.', '.')]


------------------- Sentence 7 -------------------

IEEE Trans Neural Netw.

>> Tokens are: 
 ['IEEE', 'Trans', 'Neural', 'Netw', '.']

>> Bigrams are: 
 [('IEEE', 'Trans'), ('Trans', 'Neural'), ('Neural', 'Netw'), ('Netw', '.')]

>> Trigrams are: 
 [('IEEE', 'Trans', 'Neural'), ('Trans', 'Neural', 'Netw'), ('Neural', 'Netw', '.')]

>> POS Tags are: 
 [('IEEE', 'NNP'), ('Trans', 'NNP'), ('Neural', 'NNP'), ('Netw', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['IEEE Trans Neural Netw']

>> Named Entities are: 
 [('ORGANIZATION', 'IEEE'), ('PERSON', 'Trans Neural Netw')] 

>> Stemming using Porter Stemmer: 
 [('IEEE', 'ieee'), ('Trans', 'tran'), ('Neural', 'neural'), ('Netw', 'netw'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('IEEE', 'ieee'), ('Trans', 'tran'), ('Neural', 'neural'), ('Netw', 'netw'), ('.', '.')]

>> Lemmatization: 
 [('IEEE', 'IEEE'), ('Trans', 'Trans'), ('Neural', 'Neural'), ('Netw', 'Netw'), ('.', '.')]


------------------- Sentence 8 -------------------

2002;13(1):3–14.

>> Tokens are: 
 ['2002', ';', '13', '(', '1', ')', ':3–14', '.']

>> Bigrams are: 
 [('2002', ';'), (';', '13'), ('13', '('), ('(', '1'), ('1', ')'), (')', ':3–14'), (':3–14', '.')]

>> Trigrams are: 
 [('2002', ';', '13'), (';', '13', '('), ('13', '(', '1'), ('(', '1', ')'), ('1', ')', ':3–14'), (')', ':3–14', '.')]

>> POS Tags are: 
 [('2002', 'CD'), (';', ':'), ('13', 'CD'), ('(', '('), ('1', 'CD'), (')', ')'), (':3–14', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 [':3–14']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('2002', '2002'), (';', ';'), ('13', '13'), ('(', '('), ('1', '1'), (')', ')'), (':3–14', ':3–14'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('2002', '2002'), (';', ';'), ('13', '13'), ('(', '('), ('1', '1'), (')', ')'), (':3–14', ':3–14'), ('.', '.')]

>> Lemmatization: 
 [('2002', '2002'), (';', ';'), ('13', '13'), ('(', '('), ('1', '1'), (')', ')'), (':3–14', ':3–14'), ('.', '.')]


------------------- Sentence 9 -------------------

50.

>> Tokens are: 
 ['50', '.']

>> Bigrams are: 
 [('50', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('50', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('50', '50'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('50', '50'), ('.', '.')]

>> Lemmatization: 
 [('50', '50'), ('.', '.')]


------------------- Sentence 10 -------------------

Mehta M, Agrawal R, Rissanen J. SLIQ: a fast scalable classifier for data mining.

>> Tokens are: 
 ['Mehta', 'M', ',', 'Agrawal', 'R', ',', 'Rissanen', 'J.', 'SLIQ', ':', 'fast', 'scalable', 'classifier', 'data', 'mining', '.']

>> Bigrams are: 
 [('Mehta', 'M'), ('M', ','), (',', 'Agrawal'), ('Agrawal', 'R'), ('R', ','), (',', 'Rissanen'), ('Rissanen', 'J.'), ('J.', 'SLIQ'), ('SLIQ', ':'), (':', 'fast'), ('fast', 'scalable'), ('scalable', 'classifier'), ('classifier', 'data'), ('data', 'mining'), ('mining', '.')]

>> Trigrams are: 
 [('Mehta', 'M', ','), ('M', ',', 'Agrawal'), (',', 'Agrawal', 'R'), ('Agrawal', 'R', ','), ('R', ',', 'Rissanen'), (',', 'Rissanen', 'J.'), ('Rissanen', 'J.', 'SLIQ'), ('J.', 'SLIQ', ':'), ('SLIQ', ':', 'fast'), (':', 'fast', 'scalable'), ('fast', 'scalable', 'classifier'), ('scalable', 'classifier', 'data'), ('classifier', 'data', 'mining'), ('data', 'mining', '.')]

>> POS Tags are: 
 [('Mehta', 'NNP'), ('M', 'NNP'), (',', ','), ('Agrawal', 'NNP'), ('R', 'NNP'), (',', ','), ('Rissanen', 'NNP'), ('J.', 'NNP'), ('SLIQ', 'NNP'), (':', ':'), ('fast', 'RB'), ('scalable', 'JJ'), ('classifier', 'JJR'), ('data', 'NNS'), ('mining', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Mehta M', 'Agrawal R', 'Rissanen J. SLIQ', 'data mining']

>> Named Entities are: 
 [('PERSON', 'Mehta'), ('PERSON', 'Agrawal R'), ('PERSON', 'Rissanen J.')] 

>> Stemming using Porter Stemmer: 
 [('Mehta', 'mehta'), ('M', 'm'), (',', ','), ('Agrawal', 'agraw'), ('R', 'r'), (',', ','), ('Rissanen', 'rissanen'), ('J.', 'j.'), ('SLIQ', 'sliq'), (':', ':'), ('fast', 'fast'), ('scalable', 'scalabl'), ('classifier', 'classifi'), ('data', 'data'), ('mining', 'mine'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Mehta', 'mehta'), ('M', 'm'), (',', ','), ('Agrawal', 'agraw'), ('R', 'r'), (',', ','), ('Rissanen', 'rissanen'), ('J.', 'j.'), ('SLIQ', 'sliq'), (':', ':'), ('fast', 'fast'), ('scalable', 'scalabl'), ('classifier', 'classifi'), ('data', 'data'), ('mining', 'mine'), ('.', '.')]

>> Lemmatization: 
 [('Mehta', 'Mehta'), ('M', 'M'), (',', ','), ('Agrawal', 'Agrawal'), ('R', 'R'), (',', ','), ('Rissanen', 'Rissanen'), ('J.', 'J.'), ('SLIQ', 'SLIQ'), (':', ':'), ('fast', 'fast'), ('scalable', 'scalable'), ('classifier', 'classifier'), ('data', 'data'), ('mining', 'mining'), ('.', '.')]


------------------- Sentence 11 -------------------

In: Proceedings of the 5th Interna‑

>> Tokens are: 
 ['In', ':', 'Proceedings', '5th', 'Interna‑']

>> Bigrams are: 
 [('In', ':'), (':', 'Proceedings'), ('Proceedings', '5th'), ('5th', 'Interna‑')]

>> Trigrams are: 
 [('In', ':', 'Proceedings'), (':', 'Proceedings', '5th'), ('Proceedings', '5th', 'Interna‑')]

>> POS Tags are: 
 [('In', 'IN'), (':', ':'), ('Proceedings', 'NNS'), ('5th', 'CD'), ('Interna‑', 'NNP')]

>> Noun Phrases are: 
 ['Proceedings', 'Interna‑']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), (':', ':'), ('Proceedings', 'proceed'), ('5th', '5th'), ('Interna‑', 'interna‑')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), (':', ':'), ('Proceedings', 'proceed'), ('5th', '5th'), ('Interna‑', 'interna‑')]

>> Lemmatization: 
 [('In', 'In'), (':', ':'), ('Proceedings', 'Proceedings'), ('5th', '5th'), ('Interna‑', 'Interna‑')]



========================================== PARAGRAPH 446 ===========================================

tional Conference on Extending Database Technology: Advances in Database Technology. 1996. pp 18–32.  51. Micó L, Oncina J, Carrasco RC. A fast branch and bound nearest neighbour classifier in metric spaces. Pattern  

------------------- Sentence 1 -------------------

tional Conference on Extending Database Technology: Advances in Database Technology.

>> Tokens are: 
 ['tional', 'Conference', 'Extending', 'Database', 'Technology', ':', 'Advances', 'Database', 'Technology', '.']

>> Bigrams are: 
 [('tional', 'Conference'), ('Conference', 'Extending'), ('Extending', 'Database'), ('Database', 'Technology'), ('Technology', ':'), (':', 'Advances'), ('Advances', 'Database'), ('Database', 'Technology'), ('Technology', '.')]

>> Trigrams are: 
 [('tional', 'Conference', 'Extending'), ('Conference', 'Extending', 'Database'), ('Extending', 'Database', 'Technology'), ('Database', 'Technology', ':'), ('Technology', ':', 'Advances'), (':', 'Advances', 'Database'), ('Advances', 'Database', 'Technology'), ('Database', 'Technology', '.')]

>> POS Tags are: 
 [('tional', 'JJ'), ('Conference', 'NNP'), ('Extending', 'NNP'), ('Database', 'NNP'), ('Technology', 'NNP'), (':', ':'), ('Advances', 'NNS'), ('Database', 'NNP'), ('Technology', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['tional Conference Extending Database Technology', 'Advances Database Technology']

>> Named Entities are: 
 [('ORGANIZATION', 'Conference'), ('PERSON', 'Database Technology')] 

>> Stemming using Porter Stemmer: 
 [('tional', 'tional'), ('Conference', 'confer'), ('Extending', 'extend'), ('Database', 'databas'), ('Technology', 'technolog'), (':', ':'), ('Advances', 'advanc'), ('Database', 'databas'), ('Technology', 'technolog'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('tional', 'tional'), ('Conference', 'confer'), ('Extending', 'extend'), ('Database', 'databas'), ('Technology', 'technolog'), (':', ':'), ('Advances', 'advanc'), ('Database', 'databas'), ('Technology', 'technolog'), ('.', '.')]

>> Lemmatization: 
 [('tional', 'tional'), ('Conference', 'Conference'), ('Extending', 'Extending'), ('Database', 'Database'), ('Technology', 'Technology'), (':', ':'), ('Advances', 'Advances'), ('Database', 'Database'), ('Technology', 'Technology'), ('.', '.')]


------------------- Sentence 2 -------------------

1996. pp 18–32.

>> Tokens are: 
 ['1996.', 'pp', '18–32', '.']

>> Bigrams are: 
 [('1996.', 'pp'), ('pp', '18–32'), ('18–32', '.')]

>> Trigrams are: 
 [('1996.', 'pp', '18–32'), ('pp', '18–32', '.')]

>> POS Tags are: 
 [('1996.', 'CD'), ('pp', 'JJ'), ('18–32', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('1996.', '1996.'), ('pp', 'pp'), ('18–32', '18–32'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('1996.', '1996.'), ('pp', 'pp'), ('18–32', '18–32'), ('.', '.')]

>> Lemmatization: 
 [('1996.', '1996.'), ('pp', 'pp'), ('18–32', '18–32'), ('.', '.')]


------------------- Sentence 3 -------------------

51.

>> Tokens are: 
 ['51', '.']

>> Bigrams are: 
 [('51', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('51', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('51', '51'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('51', '51'), ('.', '.')]

>> Lemmatization: 
 [('51', '51'), ('.', '.')]


------------------- Sentence 4 -------------------

Micó L, Oncina J, Carrasco RC.

>> Tokens are: 
 ['Micó', 'L', ',', 'Oncina', 'J', ',', 'Carrasco', 'RC', '.']

>> Bigrams are: 
 [('Micó', 'L'), ('L', ','), (',', 'Oncina'), ('Oncina', 'J'), ('J', ','), (',', 'Carrasco'), ('Carrasco', 'RC'), ('RC', '.')]

>> Trigrams are: 
 [('Micó', 'L', ','), ('L', ',', 'Oncina'), (',', 'Oncina', 'J'), ('Oncina', 'J', ','), ('J', ',', 'Carrasco'), (',', 'Carrasco', 'RC'), ('Carrasco', 'RC', '.')]

>> POS Tags are: 
 [('Micó', 'NNP'), ('L', 'NNP'), (',', ','), ('Oncina', 'NNP'), ('J', 'NNP'), (',', ','), ('Carrasco', 'NNP'), ('RC', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Micó L', 'Oncina J', 'Carrasco RC']

>> Named Entities are: 
 [('PERSON', 'Micó'), ('ORGANIZATION', 'L'), ('PERSON', 'Oncina J'), ('PERSON', 'Carrasco RC')] 

>> Stemming using Porter Stemmer: 
 [('Micó', 'micó'), ('L', 'l'), (',', ','), ('Oncina', 'oncina'), ('J', 'j'), (',', ','), ('Carrasco', 'carrasco'), ('RC', 'rc'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Micó', 'micó'), ('L', 'l'), (',', ','), ('Oncina', 'oncina'), ('J', 'j'), (',', ','), ('Carrasco', 'carrasco'), ('RC', 'rc'), ('.', '.')]

>> Lemmatization: 
 [('Micó', 'Micó'), ('L', 'L'), (',', ','), ('Oncina', 'Oncina'), ('J', 'J'), (',', ','), ('Carrasco', 'Carrasco'), ('RC', 'RC'), ('.', '.')]


------------------- Sentence 5 -------------------

A fast branch and bound nearest neighbour classifier in metric spaces.

>> Tokens are: 
 ['A', 'fast', 'branch', 'bound', 'nearest', 'neighbour', 'classifier', 'metric', 'spaces', '.']

>> Bigrams are: 
 [('A', 'fast'), ('fast', 'branch'), ('branch', 'bound'), ('bound', 'nearest'), ('nearest', 'neighbour'), ('neighbour', 'classifier'), ('classifier', 'metric'), ('metric', 'spaces'), ('spaces', '.')]

>> Trigrams are: 
 [('A', 'fast', 'branch'), ('fast', 'branch', 'bound'), ('branch', 'bound', 'nearest'), ('bound', 'nearest', 'neighbour'), ('nearest', 'neighbour', 'classifier'), ('neighbour', 'classifier', 'metric'), ('classifier', 'metric', 'spaces'), ('metric', 'spaces', '.')]

>> POS Tags are: 
 [('A', 'DT'), ('fast', 'JJ'), ('branch', 'NN'), ('bound', 'NN'), ('nearest', 'JJS'), ('neighbour', 'NN'), ('classifier', 'NN'), ('metric', 'JJ'), ('spaces', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['A fast branch bound', 'neighbour classifier', 'metric spaces']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('A', 'a'), ('fast', 'fast'), ('branch', 'branch'), ('bound', 'bound'), ('nearest', 'nearest'), ('neighbour', 'neighbour'), ('classifier', 'classifi'), ('metric', 'metric'), ('spaces', 'space'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('A', 'a'), ('fast', 'fast'), ('branch', 'branch'), ('bound', 'bound'), ('nearest', 'nearest'), ('neighbour', 'neighbour'), ('classifier', 'classifi'), ('metric', 'metric'), ('spaces', 'space'), ('.', '.')]

>> Lemmatization: 
 [('A', 'A'), ('fast', 'fast'), ('branch', 'branch'), ('bound', 'bound'), ('nearest', 'nearest'), ('neighbour', 'neighbour'), ('classifier', 'classifier'), ('metric', 'metric'), ('spaces', 'space'), ('.', '.')]


------------------- Sentence 6 -------------------

Pattern

>> Tokens are: 
 ['Pattern']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Pattern', 'NN')]

>> Noun Phrases are: 
 ['Pattern']

>> Named Entities are: 
 [('GPE', 'Pattern')] 

>> Stemming using Porter Stemmer: 
 [('Pattern', 'pattern')]

>> Stemming using Snowball Stemmer: 
 [('Pattern', 'pattern')]

>> Lemmatization: 
 [('Pattern', 'Pattern')]



========================================== PARAGRAPH 447 ===========================================

Recogn Lett. 1996;17(7):731–9.  52. Djouadi A, Bouktache E. A fast algorithm for the nearest‑neighbor classifier. IEEE Trans Pattern Anal Mach Intel.  

------------------- Sentence 1 -------------------

Recogn Lett.

>> Tokens are: 
 ['Recogn', 'Lett', '.']

>> Bigrams are: 
 [('Recogn', 'Lett'), ('Lett', '.')]

>> Trigrams are: 
 [('Recogn', 'Lett', '.')]

>> POS Tags are: 
 [('Recogn', 'NNP'), ('Lett', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Recogn Lett']

>> Named Entities are: 
 [('PERSON', 'Recogn'), ('ORGANIZATION', 'Lett')] 

>> Stemming using Porter Stemmer: 
 [('Recogn', 'recogn'), ('Lett', 'lett'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Recogn', 'recogn'), ('Lett', 'lett'), ('.', '.')]

>> Lemmatization: 
 [('Recogn', 'Recogn'), ('Lett', 'Lett'), ('.', '.')]


------------------- Sentence 2 -------------------

1996;17(7):731–9.

>> Tokens are: 
 ['1996', ';', '17', '(', '7', ')', ':731–9', '.']

>> Bigrams are: 
 [('1996', ';'), (';', '17'), ('17', '('), ('(', '7'), ('7', ')'), (')', ':731–9'), (':731–9', '.')]

>> Trigrams are: 
 [('1996', ';', '17'), (';', '17', '('), ('17', '(', '7'), ('(', '7', ')'), ('7', ')', ':731–9'), (')', ':731–9', '.')]

>> POS Tags are: 
 [('1996', 'CD'), (';', ':'), ('17', 'CD'), ('(', '('), ('7', 'CD'), (')', ')'), (':731–9', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 [':731–9']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('1996', '1996'), (';', ';'), ('17', '17'), ('(', '('), ('7', '7'), (')', ')'), (':731–9', ':731–9'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('1996', '1996'), (';', ';'), ('17', '17'), ('(', '('), ('7', '7'), (')', ')'), (':731–9', ':731–9'), ('.', '.')]

>> Lemmatization: 
 [('1996', '1996'), (';', ';'), ('17', '17'), ('(', '('), ('7', '7'), (')', ')'), (':731–9', ':731–9'), ('.', '.')]


------------------- Sentence 3 -------------------

52.

>> Tokens are: 
 ['52', '.']

>> Bigrams are: 
 [('52', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('52', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('52', '52'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('52', '52'), ('.', '.')]

>> Lemmatization: 
 [('52', '52'), ('.', '.')]


------------------- Sentence 4 -------------------

Djouadi A, Bouktache E. A fast algorithm for the nearest‑neighbor classifier.

>> Tokens are: 
 ['Djouadi', 'A', ',', 'Bouktache', 'E.', 'A', 'fast', 'algorithm', 'nearest‑neighbor', 'classifier', '.']

>> Bigrams are: 
 [('Djouadi', 'A'), ('A', ','), (',', 'Bouktache'), ('Bouktache', 'E.'), ('E.', 'A'), ('A', 'fast'), ('fast', 'algorithm'), ('algorithm', 'nearest‑neighbor'), ('nearest‑neighbor', 'classifier'), ('classifier', '.')]

>> Trigrams are: 
 [('Djouadi', 'A', ','), ('A', ',', 'Bouktache'), (',', 'Bouktache', 'E.'), ('Bouktache', 'E.', 'A'), ('E.', 'A', 'fast'), ('A', 'fast', 'algorithm'), ('fast', 'algorithm', 'nearest‑neighbor'), ('algorithm', 'nearest‑neighbor', 'classifier'), ('nearest‑neighbor', 'classifier', '.')]

>> POS Tags are: 
 [('Djouadi', 'NNP'), ('A', 'NNP'), (',', ','), ('Bouktache', 'NNP'), ('E.', 'NNP'), ('A', 'NNP'), ('fast', 'RB'), ('algorithm', 'JJ'), ('nearest‑neighbor', 'NN'), ('classifier', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Djouadi A', 'Bouktache E. A', 'algorithm nearest‑neighbor classifier']

>> Named Entities are: 
 [('PERSON', 'Djouadi'), ('PERSON', 'Bouktache')] 

>> Stemming using Porter Stemmer: 
 [('Djouadi', 'djouadi'), ('A', 'a'), (',', ','), ('Bouktache', 'bouktach'), ('E.', 'e.'), ('A', 'a'), ('fast', 'fast'), ('algorithm', 'algorithm'), ('nearest‑neighbor', 'nearest‑neighbor'), ('classifier', 'classifi'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Djouadi', 'djouadi'), ('A', 'a'), (',', ','), ('Bouktache', 'bouktach'), ('E.', 'e.'), ('A', 'a'), ('fast', 'fast'), ('algorithm', 'algorithm'), ('nearest‑neighbor', 'nearest‑neighbor'), ('classifier', 'classifi'), ('.', '.')]

>> Lemmatization: 
 [('Djouadi', 'Djouadi'), ('A', 'A'), (',', ','), ('Bouktache', 'Bouktache'), ('E.', 'E.'), ('A', 'A'), ('fast', 'fast'), ('algorithm', 'algorithm'), ('nearest‑neighbor', 'nearest‑neighbor'), ('classifier', 'classifier'), ('.', '.')]


------------------- Sentence 5 -------------------

IEEE Trans Pattern Anal Mach Intel.

>> Tokens are: 
 ['IEEE', 'Trans', 'Pattern', 'Anal', 'Mach', 'Intel', '.']

>> Bigrams are: 
 [('IEEE', 'Trans'), ('Trans', 'Pattern'), ('Pattern', 'Anal'), ('Anal', 'Mach'), ('Mach', 'Intel'), ('Intel', '.')]

>> Trigrams are: 
 [('IEEE', 'Trans', 'Pattern'), ('Trans', 'Pattern', 'Anal'), ('Pattern', 'Anal', 'Mach'), ('Anal', 'Mach', 'Intel'), ('Mach', 'Intel', '.')]

>> POS Tags are: 
 [('IEEE', 'NNP'), ('Trans', 'NNP'), ('Pattern', 'NNP'), ('Anal', 'NNP'), ('Mach', 'NNP'), ('Intel', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['IEEE Trans Pattern Anal Mach Intel']

>> Named Entities are: 
 [('ORGANIZATION', 'IEEE'), ('PERSON', 'Trans Pattern Anal Mach Intel')] 

>> Stemming using Porter Stemmer: 
 [('IEEE', 'ieee'), ('Trans', 'tran'), ('Pattern', 'pattern'), ('Anal', 'anal'), ('Mach', 'mach'), ('Intel', 'intel'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('IEEE', 'ieee'), ('Trans', 'tran'), ('Pattern', 'pattern'), ('Anal', 'anal'), ('Mach', 'mach'), ('Intel', 'intel'), ('.', '.')]

>> Lemmatization: 
 [('IEEE', 'IEEE'), ('Trans', 'Trans'), ('Pattern', 'Pattern'), ('Anal', 'Anal'), ('Mach', 'Mach'), ('Intel', 'Intel'), ('.', '.')]



========================================== PARAGRAPH 448 ===========================================

1997;19(3):277–82.  53. Ververidis D, Kotropoulos C. Fast and accurate sequential floating forward feature selection with the bayes classi‑ 

------------------- Sentence 1 -------------------

1997;19(3):277–82.

>> Tokens are: 
 ['1997', ';', '19', '(', '3', ')', ':277–82', '.']

>> Bigrams are: 
 [('1997', ';'), (';', '19'), ('19', '('), ('(', '3'), ('3', ')'), (')', ':277–82'), (':277–82', '.')]

>> Trigrams are: 
 [('1997', ';', '19'), (';', '19', '('), ('19', '(', '3'), ('(', '3', ')'), ('3', ')', ':277–82'), (')', ':277–82', '.')]

>> POS Tags are: 
 [('1997', 'CD'), (';', ':'), ('19', 'CD'), ('(', '('), ('3', 'CD'), (')', ')'), (':277–82', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 [':277–82']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('1997', '1997'), (';', ';'), ('19', '19'), ('(', '('), ('3', '3'), (')', ')'), (':277–82', ':277–82'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('1997', '1997'), (';', ';'), ('19', '19'), ('(', '('), ('3', '3'), (')', ')'), (':277–82', ':277–82'), ('.', '.')]

>> Lemmatization: 
 [('1997', '1997'), (';', ';'), ('19', '19'), ('(', '('), ('3', '3'), (')', ')'), (':277–82', ':277–82'), ('.', '.')]


------------------- Sentence 2 -------------------

53.

>> Tokens are: 
 ['53', '.']

>> Bigrams are: 
 [('53', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('53', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('53', '53'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('53', '53'), ('.', '.')]

>> Lemmatization: 
 [('53', '53'), ('.', '.')]


------------------- Sentence 3 -------------------

Ververidis D, Kotropoulos C. Fast and accurate sequential floating forward feature selection with the bayes classi‑

>> Tokens are: 
 ['Ververidis', 'D', ',', 'Kotropoulos', 'C.', 'Fast', 'accurate', 'sequential', 'floating', 'forward', 'feature', 'selection', 'bayes', 'classi‑']

>> Bigrams are: 
 [('Ververidis', 'D'), ('D', ','), (',', 'Kotropoulos'), ('Kotropoulos', 'C.'), ('C.', 'Fast'), ('Fast', 'accurate'), ('accurate', 'sequential'), ('sequential', 'floating'), ('floating', 'forward'), ('forward', 'feature'), ('feature', 'selection'), ('selection', 'bayes'), ('bayes', 'classi‑')]

>> Trigrams are: 
 [('Ververidis', 'D', ','), ('D', ',', 'Kotropoulos'), (',', 'Kotropoulos', 'C.'), ('Kotropoulos', 'C.', 'Fast'), ('C.', 'Fast', 'accurate'), ('Fast', 'accurate', 'sequential'), ('accurate', 'sequential', 'floating'), ('sequential', 'floating', 'forward'), ('floating', 'forward', 'feature'), ('forward', 'feature', 'selection'), ('feature', 'selection', 'bayes'), ('selection', 'bayes', 'classi‑')]

>> POS Tags are: 
 [('Ververidis', 'NNP'), ('D', 'NNP'), (',', ','), ('Kotropoulos', 'NNP'), ('C.', 'NNP'), ('Fast', 'NNP'), ('accurate', 'JJ'), ('sequential', 'JJ'), ('floating', 'VBG'), ('forward', 'RB'), ('feature', 'NN'), ('selection', 'NN'), ('bayes', 'NNS'), ('classi‑', 'VBP')]

>> Noun Phrases are: 
 ['Ververidis D', 'Kotropoulos C. Fast', 'feature selection bayes']

>> Named Entities are: 
 [('PERSON', 'Ververidis'), ('ORGANIZATION', 'D'), ('PERSON', 'Kotropoulos C. Fast')] 

>> Stemming using Porter Stemmer: 
 [('Ververidis', 'ververidi'), ('D', 'd'), (',', ','), ('Kotropoulos', 'kotropoulo'), ('C.', 'c.'), ('Fast', 'fast'), ('accurate', 'accur'), ('sequential', 'sequenti'), ('floating', 'float'), ('forward', 'forward'), ('feature', 'featur'), ('selection', 'select'), ('bayes', 'bay'), ('classi‑', 'classi‑')]

>> Stemming using Snowball Stemmer: 
 [('Ververidis', 'ververidi'), ('D', 'd'), (',', ','), ('Kotropoulos', 'kotropoulo'), ('C.', 'c.'), ('Fast', 'fast'), ('accurate', 'accur'), ('sequential', 'sequenti'), ('floating', 'float'), ('forward', 'forward'), ('feature', 'featur'), ('selection', 'select'), ('bayes', 'bay'), ('classi‑', 'classi‑')]

>> Lemmatization: 
 [('Ververidis', 'Ververidis'), ('D', 'D'), (',', ','), ('Kotropoulos', 'Kotropoulos'), ('C.', 'C.'), ('Fast', 'Fast'), ('accurate', 'accurate'), ('sequential', 'sequential'), ('floating', 'floating'), ('forward', 'forward'), ('feature', 'feature'), ('selection', 'selection'), ('bayes', 'bayes'), ('classi‑', 'classi‑')]



========================================== PARAGRAPH 449 ===========================================

fier applied to speech emotion recognition. Signal Process. 2008;88(12):2956–70.  54. Pei J, Han J, Mao R. CLOSET: an efficient algorithm for mining frequent closed itemsets. In: Proceedings of the ACM  

------------------- Sentence 1 -------------------

fier applied to speech emotion recognition.

>> Tokens are: 
 ['fier', 'applied', 'speech', 'emotion', 'recognition', '.']

>> Bigrams are: 
 [('fier', 'applied'), ('applied', 'speech'), ('speech', 'emotion'), ('emotion', 'recognition'), ('recognition', '.')]

>> Trigrams are: 
 [('fier', 'applied', 'speech'), ('applied', 'speech', 'emotion'), ('speech', 'emotion', 'recognition'), ('emotion', 'recognition', '.')]

>> POS Tags are: 
 [('fier', 'RB'), ('applied', 'VBN'), ('speech', 'JJ'), ('emotion', 'NN'), ('recognition', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['speech emotion recognition']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('fier', 'fier'), ('applied', 'appli'), ('speech', 'speech'), ('emotion', 'emot'), ('recognition', 'recognit'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('fier', 'fier'), ('applied', 'appli'), ('speech', 'speech'), ('emotion', 'emot'), ('recognition', 'recognit'), ('.', '.')]

>> Lemmatization: 
 [('fier', 'fier'), ('applied', 'applied'), ('speech', 'speech'), ('emotion', 'emotion'), ('recognition', 'recognition'), ('.', '.')]


------------------- Sentence 2 -------------------

Signal Process.

>> Tokens are: 
 ['Signal', 'Process', '.']

>> Bigrams are: 
 [('Signal', 'Process'), ('Process', '.')]

>> Trigrams are: 
 [('Signal', 'Process', '.')]

>> POS Tags are: 
 [('Signal', 'NNP'), ('Process', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Signal Process']

>> Named Entities are: 
 [('PERSON', 'Signal'), ('ORGANIZATION', 'Process')] 

>> Stemming using Porter Stemmer: 
 [('Signal', 'signal'), ('Process', 'process'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Signal', 'signal'), ('Process', 'process'), ('.', '.')]

>> Lemmatization: 
 [('Signal', 'Signal'), ('Process', 'Process'), ('.', '.')]


------------------- Sentence 3 -------------------

2008;88(12):2956–70.

>> Tokens are: 
 ['2008', ';', '88', '(', '12', ')', ':2956–70', '.']

>> Bigrams are: 
 [('2008', ';'), (';', '88'), ('88', '('), ('(', '12'), ('12', ')'), (')', ':2956–70'), (':2956–70', '.')]

>> Trigrams are: 
 [('2008', ';', '88'), (';', '88', '('), ('88', '(', '12'), ('(', '12', ')'), ('12', ')', ':2956–70'), (')', ':2956–70', '.')]

>> POS Tags are: 
 [('2008', 'CD'), (';', ':'), ('88', 'CD'), ('(', '('), ('12', 'CD'), (')', ')'), (':2956–70', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 [':2956–70']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('2008', '2008'), (';', ';'), ('88', '88'), ('(', '('), ('12', '12'), (')', ')'), (':2956–70', ':2956–70'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('2008', '2008'), (';', ';'), ('88', '88'), ('(', '('), ('12', '12'), (')', ')'), (':2956–70', ':2956–70'), ('.', '.')]

>> Lemmatization: 
 [('2008', '2008'), (';', ';'), ('88', '88'), ('(', '('), ('12', '12'), (')', ')'), (':2956–70', ':2956–70'), ('.', '.')]


------------------- Sentence 4 -------------------

54.

>> Tokens are: 
 ['54', '.']

>> Bigrams are: 
 [('54', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('54', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('54', '54'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('54', '54'), ('.', '.')]

>> Lemmatization: 
 [('54', '54'), ('.', '.')]


------------------- Sentence 5 -------------------

Pei J, Han J, Mao R. CLOSET: an efficient algorithm for mining frequent closed itemsets.

>> Tokens are: 
 ['Pei', 'J', ',', 'Han', 'J', ',', 'Mao', 'R.', 'CLOSET', ':', 'efficient', 'algorithm', 'mining', 'frequent', 'closed', 'itemsets', '.']

>> Bigrams are: 
 [('Pei', 'J'), ('J', ','), (',', 'Han'), ('Han', 'J'), ('J', ','), (',', 'Mao'), ('Mao', 'R.'), ('R.', 'CLOSET'), ('CLOSET', ':'), (':', 'efficient'), ('efficient', 'algorithm'), ('algorithm', 'mining'), ('mining', 'frequent'), ('frequent', 'closed'), ('closed', 'itemsets'), ('itemsets', '.')]

>> Trigrams are: 
 [('Pei', 'J', ','), ('J', ',', 'Han'), (',', 'Han', 'J'), ('Han', 'J', ','), ('J', ',', 'Mao'), (',', 'Mao', 'R.'), ('Mao', 'R.', 'CLOSET'), ('R.', 'CLOSET', ':'), ('CLOSET', ':', 'efficient'), (':', 'efficient', 'algorithm'), ('efficient', 'algorithm', 'mining'), ('algorithm', 'mining', 'frequent'), ('mining', 'frequent', 'closed'), ('frequent', 'closed', 'itemsets'), ('closed', 'itemsets', '.')]

>> POS Tags are: 
 [('Pei', 'NNP'), ('J', 'NNP'), (',', ','), ('Han', 'NNP'), ('J', 'NNP'), (',', ','), ('Mao', 'NNP'), ('R.', 'NNP'), ('CLOSET', 'NNP'), (':', ':'), ('efficient', 'JJ'), ('algorithm', 'NN'), ('mining', 'NN'), ('frequent', 'NN'), ('closed', 'VBD'), ('itemsets', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['Pei J', 'Han J', 'Mao R. CLOSET', 'efficient algorithm mining frequent', 'itemsets']

>> Named Entities are: 
 [('PERSON', 'Pei'), ('ORGANIZATION', 'J'), ('PERSON', 'Han J'), ('PERSON', 'Mao R.')] 

>> Stemming using Porter Stemmer: 
 [('Pei', 'pei'), ('J', 'j'), (',', ','), ('Han', 'han'), ('J', 'j'), (',', ','), ('Mao', 'mao'), ('R.', 'r.'), ('CLOSET', 'closet'), (':', ':'), ('efficient', 'effici'), ('algorithm', 'algorithm'), ('mining', 'mine'), ('frequent', 'frequent'), ('closed', 'close'), ('itemsets', 'itemset'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Pei', 'pei'), ('J', 'j'), (',', ','), ('Han', 'han'), ('J', 'j'), (',', ','), ('Mao', 'mao'), ('R.', 'r.'), ('CLOSET', 'closet'), (':', ':'), ('efficient', 'effici'), ('algorithm', 'algorithm'), ('mining', 'mine'), ('frequent', 'frequent'), ('closed', 'close'), ('itemsets', 'itemset'), ('.', '.')]

>> Lemmatization: 
 [('Pei', 'Pei'), ('J', 'J'), (',', ','), ('Han', 'Han'), ('J', 'J'), (',', ','), ('Mao', 'Mao'), ('R.', 'R.'), ('CLOSET', 'CLOSET'), (':', ':'), ('efficient', 'efficient'), ('algorithm', 'algorithm'), ('mining', 'mining'), ('frequent', 'frequent'), ('closed', 'closed'), ('itemsets', 'itemsets'), ('.', '.')]


------------------- Sentence 6 -------------------

In: Proceedings of the ACM

>> Tokens are: 
 ['In', ':', 'Proceedings', 'ACM']

>> Bigrams are: 
 [('In', ':'), (':', 'Proceedings'), ('Proceedings', 'ACM')]

>> Trigrams are: 
 [('In', ':', 'Proceedings'), (':', 'Proceedings', 'ACM')]

>> POS Tags are: 
 [('In', 'IN'), (':', ':'), ('Proceedings', 'NNS'), ('ACM', 'VBP')]

>> Noun Phrases are: 
 ['Proceedings']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), (':', ':'), ('Proceedings', 'proceed'), ('ACM', 'acm')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), (':', ':'), ('Proceedings', 'proceed'), ('ACM', 'acm')]

>> Lemmatization: 
 [('In', 'In'), (':', ':'), ('Proceedings', 'Proceedings'), ('ACM', 'ACM')]



========================================== PARAGRAPH 450 ===========================================

SIGMOD Workshop on Research Issues in Data Mining and Knowledge Discovery, 2000. pp 21–30.  55. Zaki MJ, Hsiao C‑J. Efficient algorithms for mining closed itemsets and their lattice structure. IEEE Trans Knowl Data  

------------------- Sentence 1 -------------------

SIGMOD Workshop on Research Issues in Data Mining and Knowledge Discovery, 2000. pp 21–30.

>> Tokens are: 
 ['SIGMOD', 'Workshop', 'Research', 'Issues', 'Data', 'Mining', 'Knowledge', 'Discovery', ',', '2000.', 'pp', '21–30', '.']

>> Bigrams are: 
 [('SIGMOD', 'Workshop'), ('Workshop', 'Research'), ('Research', 'Issues'), ('Issues', 'Data'), ('Data', 'Mining'), ('Mining', 'Knowledge'), ('Knowledge', 'Discovery'), ('Discovery', ','), (',', '2000.'), ('2000.', 'pp'), ('pp', '21–30'), ('21–30', '.')]

>> Trigrams are: 
 [('SIGMOD', 'Workshop', 'Research'), ('Workshop', 'Research', 'Issues'), ('Research', 'Issues', 'Data'), ('Issues', 'Data', 'Mining'), ('Data', 'Mining', 'Knowledge'), ('Mining', 'Knowledge', 'Discovery'), ('Knowledge', 'Discovery', ','), ('Discovery', ',', '2000.'), (',', '2000.', 'pp'), ('2000.', 'pp', '21–30'), ('pp', '21–30', '.')]

>> POS Tags are: 
 [('SIGMOD', 'NNP'), ('Workshop', 'NNP'), ('Research', 'NNP'), ('Issues', 'NNP'), ('Data', 'NNP'), ('Mining', 'NNP'), ('Knowledge', 'NNP'), ('Discovery', 'NNP'), (',', ','), ('2000.', 'CD'), ('pp', 'NN'), ('21–30', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['SIGMOD Workshop Research Issues Data Mining Knowledge Discovery', 'pp']

>> Named Entities are: 
 [('ORGANIZATION', 'SIGMOD Workshop'), ('PERSON', 'Issues Data')] 

>> Stemming using Porter Stemmer: 
 [('SIGMOD', 'sigmod'), ('Workshop', 'workshop'), ('Research', 'research'), ('Issues', 'issu'), ('Data', 'data'), ('Mining', 'mine'), ('Knowledge', 'knowledg'), ('Discovery', 'discoveri'), (',', ','), ('2000.', '2000.'), ('pp', 'pp'), ('21–30', '21–30'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('SIGMOD', 'sigmod'), ('Workshop', 'workshop'), ('Research', 'research'), ('Issues', 'issu'), ('Data', 'data'), ('Mining', 'mine'), ('Knowledge', 'knowledg'), ('Discovery', 'discoveri'), (',', ','), ('2000.', '2000.'), ('pp', 'pp'), ('21–30', '21–30'), ('.', '.')]

>> Lemmatization: 
 [('SIGMOD', 'SIGMOD'), ('Workshop', 'Workshop'), ('Research', 'Research'), ('Issues', 'Issues'), ('Data', 'Data'), ('Mining', 'Mining'), ('Knowledge', 'Knowledge'), ('Discovery', 'Discovery'), (',', ','), ('2000.', '2000.'), ('pp', 'pp'), ('21–30', '21–30'), ('.', '.')]


------------------- Sentence 2 -------------------

55.

>> Tokens are: 
 ['55', '.']

>> Bigrams are: 
 [('55', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('55', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('55', '55'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('55', '55'), ('.', '.')]

>> Lemmatization: 
 [('55', '55'), ('.', '.')]


------------------- Sentence 3 -------------------

Zaki MJ, Hsiao C‑J.

>> Tokens are: 
 ['Zaki', 'MJ', ',', 'Hsiao', 'C‑J', '.']

>> Bigrams are: 
 [('Zaki', 'MJ'), ('MJ', ','), (',', 'Hsiao'), ('Hsiao', 'C‑J'), ('C‑J', '.')]

>> Trigrams are: 
 [('Zaki', 'MJ', ','), ('MJ', ',', 'Hsiao'), (',', 'Hsiao', 'C‑J'), ('Hsiao', 'C‑J', '.')]

>> POS Tags are: 
 [('Zaki', 'NNP'), ('MJ', 'NNP'), (',', ','), ('Hsiao', 'NNP'), ('C‑J', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Zaki MJ', 'Hsiao C‑J']

>> Named Entities are: 
 [('PERSON', 'Zaki'), ('GPE', 'MJ'), ('PERSON', 'Hsiao')] 

>> Stemming using Porter Stemmer: 
 [('Zaki', 'zaki'), ('MJ', 'mj'), (',', ','), ('Hsiao', 'hsiao'), ('C‑J', 'c‑j'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Zaki', 'zaki'), ('MJ', 'mj'), (',', ','), ('Hsiao', 'hsiao'), ('C‑J', 'c‑j'), ('.', '.')]

>> Lemmatization: 
 [('Zaki', 'Zaki'), ('MJ', 'MJ'), (',', ','), ('Hsiao', 'Hsiao'), ('C‑J', 'C‑J'), ('.', '.')]


------------------- Sentence 4 -------------------

Efficient algorithms for mining closed itemsets and their lattice structure.

>> Tokens are: 
 ['Efficient', 'algorithms', 'mining', 'closed', 'itemsets', 'lattice', 'structure', '.']

>> Bigrams are: 
 [('Efficient', 'algorithms'), ('algorithms', 'mining'), ('mining', 'closed'), ('closed', 'itemsets'), ('itemsets', 'lattice'), ('lattice', 'structure'), ('structure', '.')]

>> Trigrams are: 
 [('Efficient', 'algorithms', 'mining'), ('algorithms', 'mining', 'closed'), ('mining', 'closed', 'itemsets'), ('closed', 'itemsets', 'lattice'), ('itemsets', 'lattice', 'structure'), ('lattice', 'structure', '.')]

>> POS Tags are: 
 [('Efficient', 'JJ'), ('algorithms', 'NN'), ('mining', 'NN'), ('closed', 'VBD'), ('itemsets', 'NNS'), ('lattice', 'JJ'), ('structure', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Efficient algorithms mining', 'itemsets', 'lattice structure']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Efficient', 'effici'), ('algorithms', 'algorithm'), ('mining', 'mine'), ('closed', 'close'), ('itemsets', 'itemset'), ('lattice', 'lattic'), ('structure', 'structur'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Efficient', 'effici'), ('algorithms', 'algorithm'), ('mining', 'mine'), ('closed', 'close'), ('itemsets', 'itemset'), ('lattice', 'lattic'), ('structure', 'structur'), ('.', '.')]

>> Lemmatization: 
 [('Efficient', 'Efficient'), ('algorithms', 'algorithm'), ('mining', 'mining'), ('closed', 'closed'), ('itemsets', 'itemsets'), ('lattice', 'lattice'), ('structure', 'structure'), ('.', '.')]


------------------- Sentence 5 -------------------

IEEE Trans Knowl Data

>> Tokens are: 
 ['IEEE', 'Trans', 'Knowl', 'Data']

>> Bigrams are: 
 [('IEEE', 'Trans'), ('Trans', 'Knowl'), ('Knowl', 'Data')]

>> Trigrams are: 
 [('IEEE', 'Trans', 'Knowl'), ('Trans', 'Knowl', 'Data')]

>> POS Tags are: 
 [('IEEE', 'NNP'), ('Trans', 'NNP'), ('Knowl', 'NNP'), ('Data', 'NNP')]

>> Noun Phrases are: 
 ['IEEE Trans Knowl Data']

>> Named Entities are: 
 [('ORGANIZATION', 'IEEE'), ('PERSON', 'Trans Knowl Data')] 

>> Stemming using Porter Stemmer: 
 [('IEEE', 'ieee'), ('Trans', 'tran'), ('Knowl', 'knowl'), ('Data', 'data')]

>> Stemming using Snowball Stemmer: 
 [('IEEE', 'ieee'), ('Trans', 'tran'), ('Knowl', 'knowl'), ('Data', 'data')]

>> Lemmatization: 
 [('IEEE', 'IEEE'), ('Trans', 'Trans'), ('Knowl', 'Knowl'), ('Data', 'Data')]



========================================== PARAGRAPH 451 ===========================================

Eng. 2005;17(4):462–78.  56. Burdick D, Calimlim M, Gehrke J. MAFIA: a maximal frequent itemset algorithm for transactional databases. In:  

------------------- Sentence 1 -------------------

Eng.

>> Tokens are: 
 ['Eng', '.']

>> Bigrams are: 
 [('Eng', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Eng', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Eng']

>> Named Entities are: 
 [('GPE', 'Eng')] 

>> Stemming using Porter Stemmer: 
 [('Eng', 'eng'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Eng', 'eng'), ('.', '.')]

>> Lemmatization: 
 [('Eng', 'Eng'), ('.', '.')]


------------------- Sentence 2 -------------------

2005;17(4):462–78.

>> Tokens are: 
 ['2005', ';', '17', '(', '4', ')', ':462–78', '.']

>> Bigrams are: 
 [('2005', ';'), (';', '17'), ('17', '('), ('(', '4'), ('4', ')'), (')', ':462–78'), (':462–78', '.')]

>> Trigrams are: 
 [('2005', ';', '17'), (';', '17', '('), ('17', '(', '4'), ('(', '4', ')'), ('4', ')', ':462–78'), (')', ':462–78', '.')]

>> POS Tags are: 
 [('2005', 'CD'), (';', ':'), ('17', 'CD'), ('(', '('), ('4', 'CD'), (')', ')'), (':462–78', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 [':462–78']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('2005', '2005'), (';', ';'), ('17', '17'), ('(', '('), ('4', '4'), (')', ')'), (':462–78', ':462–78'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('2005', '2005'), (';', ';'), ('17', '17'), ('(', '('), ('4', '4'), (')', ')'), (':462–78', ':462–78'), ('.', '.')]

>> Lemmatization: 
 [('2005', '2005'), (';', ';'), ('17', '17'), ('(', '('), ('4', '4'), (')', ')'), (':462–78', ':462–78'), ('.', '.')]


------------------- Sentence 3 -------------------

56.

>> Tokens are: 
 ['56', '.']

>> Bigrams are: 
 [('56', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('56', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('56', '56'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('56', '56'), ('.', '.')]

>> Lemmatization: 
 [('56', '56'), ('.', '.')]


------------------- Sentence 4 -------------------

Burdick D, Calimlim M, Gehrke J. MAFIA: a maximal frequent itemset algorithm for transactional databases.

>> Tokens are: 
 ['Burdick', 'D', ',', 'Calimlim', 'M', ',', 'Gehrke', 'J.', 'MAFIA', ':', 'maximal', 'frequent', 'itemset', 'algorithm', 'transactional', 'databases', '.']

>> Bigrams are: 
 [('Burdick', 'D'), ('D', ','), (',', 'Calimlim'), ('Calimlim', 'M'), ('M', ','), (',', 'Gehrke'), ('Gehrke', 'J.'), ('J.', 'MAFIA'), ('MAFIA', ':'), (':', 'maximal'), ('maximal', 'frequent'), ('frequent', 'itemset'), ('itemset', 'algorithm'), ('algorithm', 'transactional'), ('transactional', 'databases'), ('databases', '.')]

>> Trigrams are: 
 [('Burdick', 'D', ','), ('D', ',', 'Calimlim'), (',', 'Calimlim', 'M'), ('Calimlim', 'M', ','), ('M', ',', 'Gehrke'), (',', 'Gehrke', 'J.'), ('Gehrke', 'J.', 'MAFIA'), ('J.', 'MAFIA', ':'), ('MAFIA', ':', 'maximal'), (':', 'maximal', 'frequent'), ('maximal', 'frequent', 'itemset'), ('frequent', 'itemset', 'algorithm'), ('itemset', 'algorithm', 'transactional'), ('algorithm', 'transactional', 'databases'), ('transactional', 'databases', '.')]

>> POS Tags are: 
 [('Burdick', 'NNP'), ('D', 'NNP'), (',', ','), ('Calimlim', 'NNP'), ('M', 'NNP'), (',', ','), ('Gehrke', 'NNP'), ('J.', 'NNP'), ('MAFIA', 'NNP'), (':', ':'), ('maximal', 'JJ'), ('frequent', 'JJ'), ('itemset', 'NN'), ('algorithm', 'JJ'), ('transactional', 'JJ'), ('databases', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['Burdick D', 'Calimlim M', 'Gehrke J. MAFIA', 'maximal frequent itemset', 'algorithm transactional databases']

>> Named Entities are: 
 [('PERSON', 'Burdick'), ('ORGANIZATION', 'D'), ('PERSON', 'Calimlim M'), ('PERSON', 'Gehrke J.')] 

>> Stemming using Porter Stemmer: 
 [('Burdick', 'burdick'), ('D', 'd'), (',', ','), ('Calimlim', 'calimlim'), ('M', 'm'), (',', ','), ('Gehrke', 'gehrk'), ('J.', 'j.'), ('MAFIA', 'mafia'), (':', ':'), ('maximal', 'maxim'), ('frequent', 'frequent'), ('itemset', 'itemset'), ('algorithm', 'algorithm'), ('transactional', 'transact'), ('databases', 'databas'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Burdick', 'burdick'), ('D', 'd'), (',', ','), ('Calimlim', 'calimlim'), ('M', 'm'), (',', ','), ('Gehrke', 'gehrk'), ('J.', 'j.'), ('MAFIA', 'mafia'), (':', ':'), ('maximal', 'maxim'), ('frequent', 'frequent'), ('itemset', 'itemset'), ('algorithm', 'algorithm'), ('transactional', 'transact'), ('databases', 'databas'), ('.', '.')]

>> Lemmatization: 
 [('Burdick', 'Burdick'), ('D', 'D'), (',', ','), ('Calimlim', 'Calimlim'), ('M', 'M'), (',', ','), ('Gehrke', 'Gehrke'), ('J.', 'J.'), ('MAFIA', 'MAFIA'), (':', ':'), ('maximal', 'maximal'), ('frequent', 'frequent'), ('itemset', 'itemset'), ('algorithm', 'algorithm'), ('transactional', 'transactional'), ('databases', 'database'), ('.', '.')]


------------------- Sentence 5 -------------------

In:

>> Tokens are: 
 ['In', ':']

>> Bigrams are: 
 [('In', ':')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('In', 'IN'), (':', ':')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), (':', ':')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), (':', ':')]

>> Lemmatization: 
 [('In', 'In'), (':', ':')]



========================================== PARAGRAPH 452 ===========================================

Proceedings of the International Conference on Data Engineering, 2001. pp 443–452.  57. Chen B, Haas P, Scheuermann P. A new two‑phase sampling based algorithm for discovering association rules. In:  

------------------- Sentence 1 -------------------

Proceedings of the International Conference on Data Engineering, 2001. pp 443–452.

>> Tokens are: 
 ['Proceedings', 'International', 'Conference', 'Data', 'Engineering', ',', '2001.', 'pp', '443–452', '.']

>> Bigrams are: 
 [('Proceedings', 'International'), ('International', 'Conference'), ('Conference', 'Data'), ('Data', 'Engineering'), ('Engineering', ','), (',', '2001.'), ('2001.', 'pp'), ('pp', '443–452'), ('443–452', '.')]

>> Trigrams are: 
 [('Proceedings', 'International', 'Conference'), ('International', 'Conference', 'Data'), ('Conference', 'Data', 'Engineering'), ('Data', 'Engineering', ','), ('Engineering', ',', '2001.'), (',', '2001.', 'pp'), ('2001.', 'pp', '443–452'), ('pp', '443–452', '.')]

>> POS Tags are: 
 [('Proceedings', 'NNS'), ('International', 'NNP'), ('Conference', 'NNP'), ('Data', 'NNP'), ('Engineering', 'NNP'), (',', ','), ('2001.', 'CD'), ('pp', 'NN'), ('443–452', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Proceedings International Conference Data Engineering', 'pp']

>> Named Entities are: 
 [('ORGANIZATION', 'International Conference Data Engineering')] 

>> Stemming using Porter Stemmer: 
 [('Proceedings', 'proceed'), ('International', 'intern'), ('Conference', 'confer'), ('Data', 'data'), ('Engineering', 'engin'), (',', ','), ('2001.', '2001.'), ('pp', 'pp'), ('443–452', '443–452'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Proceedings', 'proceed'), ('International', 'intern'), ('Conference', 'confer'), ('Data', 'data'), ('Engineering', 'engin'), (',', ','), ('2001.', '2001.'), ('pp', 'pp'), ('443–452', '443–452'), ('.', '.')]

>> Lemmatization: 
 [('Proceedings', 'Proceedings'), ('International', 'International'), ('Conference', 'Conference'), ('Data', 'Data'), ('Engineering', 'Engineering'), (',', ','), ('2001.', '2001.'), ('pp', 'pp'), ('443–452', '443–452'), ('.', '.')]


------------------- Sentence 2 -------------------

57.

>> Tokens are: 
 ['57', '.']

>> Bigrams are: 
 [('57', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('57', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('57', '57'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('57', '57'), ('.', '.')]

>> Lemmatization: 
 [('57', '57'), ('.', '.')]


------------------- Sentence 3 -------------------

Chen B, Haas P, Scheuermann P. A new two‑phase sampling based algorithm for discovering association rules.

>> Tokens are: 
 ['Chen', 'B', ',', 'Haas', 'P', ',', 'Scheuermann', 'P.', 'A', 'new', 'two‑phase', 'sampling', 'based', 'algorithm', 'discovering', 'association', 'rules', '.']

>> Bigrams are: 
 [('Chen', 'B'), ('B', ','), (',', 'Haas'), ('Haas', 'P'), ('P', ','), (',', 'Scheuermann'), ('Scheuermann', 'P.'), ('P.', 'A'), ('A', 'new'), ('new', 'two‑phase'), ('two‑phase', 'sampling'), ('sampling', 'based'), ('based', 'algorithm'), ('algorithm', 'discovering'), ('discovering', 'association'), ('association', 'rules'), ('rules', '.')]

>> Trigrams are: 
 [('Chen', 'B', ','), ('B', ',', 'Haas'), (',', 'Haas', 'P'), ('Haas', 'P', ','), ('P', ',', 'Scheuermann'), (',', 'Scheuermann', 'P.'), ('Scheuermann', 'P.', 'A'), ('P.', 'A', 'new'), ('A', 'new', 'two‑phase'), ('new', 'two‑phase', 'sampling'), ('two‑phase', 'sampling', 'based'), ('sampling', 'based', 'algorithm'), ('based', 'algorithm', 'discovering'), ('algorithm', 'discovering', 'association'), ('discovering', 'association', 'rules'), ('association', 'rules', '.')]

>> POS Tags are: 
 [('Chen', 'NNP'), ('B', 'NNP'), (',', ','), ('Haas', 'NNP'), ('P', 'NNP'), (',', ','), ('Scheuermann', 'NNP'), ('P.', 'NNP'), ('A', 'NNP'), ('new', 'JJ'), ('two‑phase', 'NN'), ('sampling', 'VBG'), ('based', 'VBN'), ('algorithm', 'IN'), ('discovering', 'VBG'), ('association', 'NN'), ('rules', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['Chen B', 'Haas P', 'Scheuermann P. A', 'new two‑phase', 'association rules']

>> Named Entities are: 
 [('PERSON', 'Chen'), ('PERSON', 'Haas P'), ('PERSON', 'Scheuermann')] 

>> Stemming using Porter Stemmer: 
 [('Chen', 'chen'), ('B', 'b'), (',', ','), ('Haas', 'haa'), ('P', 'p'), (',', ','), ('Scheuermann', 'scheuermann'), ('P.', 'p.'), ('A', 'a'), ('new', 'new'), ('two‑phase', 'two‑phas'), ('sampling', 'sampl'), ('based', 'base'), ('algorithm', 'algorithm'), ('discovering', 'discov'), ('association', 'associ'), ('rules', 'rule'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Chen', 'chen'), ('B', 'b'), (',', ','), ('Haas', 'haa'), ('P', 'p'), (',', ','), ('Scheuermann', 'scheuermann'), ('P.', 'p.'), ('A', 'a'), ('new', 'new'), ('two‑phase', 'two‑phas'), ('sampling', 'sampl'), ('based', 'base'), ('algorithm', 'algorithm'), ('discovering', 'discov'), ('association', 'associ'), ('rules', 'rule'), ('.', '.')]

>> Lemmatization: 
 [('Chen', 'Chen'), ('B', 'B'), (',', ','), ('Haas', 'Haas'), ('P', 'P'), (',', ','), ('Scheuermann', 'Scheuermann'), ('P.', 'P.'), ('A', 'A'), ('new', 'new'), ('two‑phase', 'two‑phase'), ('sampling', 'sampling'), ('based', 'based'), ('algorithm', 'algorithm'), ('discovering', 'discovering'), ('association', 'association'), ('rules', 'rule'), ('.', '.')]


------------------- Sentence 4 -------------------

In:

>> Tokens are: 
 ['In', ':']

>> Bigrams are: 
 [('In', ':')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('In', 'IN'), (':', ':')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), (':', ':')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), (':', ':')]

>> Lemmatization: 
 [('In', 'In'), (':', ':')]



========================================== PARAGRAPH 453 ===========================================

Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, 2002. pp  462–468. 

------------------- Sentence 1 -------------------

Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, 2002. pp  462–468.

>> Tokens are: 
 ['Proceedings', 'ACM', 'SIGKDD', 'International', 'Conference', 'Knowledge', 'Discovery', 'Data', 'Mining', ',', '2002.', 'pp', '462–468', '.']

>> Bigrams are: 
 [('Proceedings', 'ACM'), ('ACM', 'SIGKDD'), ('SIGKDD', 'International'), ('International', 'Conference'), ('Conference', 'Knowledge'), ('Knowledge', 'Discovery'), ('Discovery', 'Data'), ('Data', 'Mining'), ('Mining', ','), (',', '2002.'), ('2002.', 'pp'), ('pp', '462–468'), ('462–468', '.')]

>> Trigrams are: 
 [('Proceedings', 'ACM', 'SIGKDD'), ('ACM', 'SIGKDD', 'International'), ('SIGKDD', 'International', 'Conference'), ('International', 'Conference', 'Knowledge'), ('Conference', 'Knowledge', 'Discovery'), ('Knowledge', 'Discovery', 'Data'), ('Discovery', 'Data', 'Mining'), ('Data', 'Mining', ','), ('Mining', ',', '2002.'), (',', '2002.', 'pp'), ('2002.', 'pp', '462–468'), ('pp', '462–468', '.')]

>> POS Tags are: 
 [('Proceedings', 'NNS'), ('ACM', 'NNP'), ('SIGKDD', 'NNP'), ('International', 'NNP'), ('Conference', 'NNP'), ('Knowledge', 'NNP'), ('Discovery', 'NNP'), ('Data', 'NNP'), ('Mining', 'NNP'), (',', ','), ('2002.', 'CD'), ('pp', 'NN'), ('462–468', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Proceedings ACM SIGKDD International Conference Knowledge Discovery Data Mining', 'pp']

>> Named Entities are: 
 [('ORGANIZATION', 'ACM'), ('ORGANIZATION', 'SIGKDD International Conference')] 

>> Stemming using Porter Stemmer: 
 [('Proceedings', 'proceed'), ('ACM', 'acm'), ('SIGKDD', 'sigkdd'), ('International', 'intern'), ('Conference', 'confer'), ('Knowledge', 'knowledg'), ('Discovery', 'discoveri'), ('Data', 'data'), ('Mining', 'mine'), (',', ','), ('2002.', '2002.'), ('pp', 'pp'), ('462–468', '462–468'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Proceedings', 'proceed'), ('ACM', 'acm'), ('SIGKDD', 'sigkdd'), ('International', 'intern'), ('Conference', 'confer'), ('Knowledge', 'knowledg'), ('Discovery', 'discoveri'), ('Data', 'data'), ('Mining', 'mine'), (',', ','), ('2002.', '2002.'), ('pp', 'pp'), ('462–468', '462–468'), ('.', '.')]

>> Lemmatization: 
 [('Proceedings', 'Proceedings'), ('ACM', 'ACM'), ('SIGKDD', 'SIGKDD'), ('International', 'International'), ('Conference', 'Conference'), ('Knowledge', 'Knowledge'), ('Discovery', 'Discovery'), ('Data', 'Data'), ('Mining', 'Mining'), (',', ','), ('2002.', '2002.'), ('pp', 'pp'), ('462–468', '462–468'), ('.', '.')]



========================================== PARAGRAPH 454 ===========================================

 58. Zaki MJ. SPADE: an efficient algorithm for mining frequent sequences. Mach Learn. 2001;42(1–2):31–60.  59. Yan X, Han J, Afshar R. CloSpan: mining closed sequential patterns in large datasets. In: Proceedings of the SIAM  

------------------- Sentence 1 -------------------

 58.

>> Tokens are: 
 ['58', '.']

>> Bigrams are: 
 [('58', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('58', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('58', '58'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('58', '58'), ('.', '.')]

>> Lemmatization: 
 [('58', '58'), ('.', '.')]


------------------- Sentence 2 -------------------

Zaki MJ.

>> Tokens are: 
 ['Zaki', 'MJ', '.']

>> Bigrams are: 
 [('Zaki', 'MJ'), ('MJ', '.')]

>> Trigrams are: 
 [('Zaki', 'MJ', '.')]

>> POS Tags are: 
 [('Zaki', 'NNP'), ('MJ', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Zaki MJ']

>> Named Entities are: 
 [('PERSON', 'Zaki')] 

>> Stemming using Porter Stemmer: 
 [('Zaki', 'zaki'), ('MJ', 'mj'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Zaki', 'zaki'), ('MJ', 'mj'), ('.', '.')]

>> Lemmatization: 
 [('Zaki', 'Zaki'), ('MJ', 'MJ'), ('.', '.')]


------------------- Sentence 3 -------------------

SPADE: an efficient algorithm for mining frequent sequences.

>> Tokens are: 
 ['SPADE', ':', 'efficient', 'algorithm', 'mining', 'frequent', 'sequences', '.']

>> Bigrams are: 
 [('SPADE', ':'), (':', 'efficient'), ('efficient', 'algorithm'), ('algorithm', 'mining'), ('mining', 'frequent'), ('frequent', 'sequences'), ('sequences', '.')]

>> Trigrams are: 
 [('SPADE', ':', 'efficient'), (':', 'efficient', 'algorithm'), ('efficient', 'algorithm', 'mining'), ('algorithm', 'mining', 'frequent'), ('mining', 'frequent', 'sequences'), ('frequent', 'sequences', '.')]

>> POS Tags are: 
 [('SPADE', 'NN'), (':', ':'), ('efficient', 'JJ'), ('algorithm', 'NN'), ('mining', 'NN'), ('frequent', 'JJ'), ('sequences', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['SPADE', 'efficient algorithm mining', 'frequent sequences']

>> Named Entities are: 
 [('GPE', 'SPADE')] 

>> Stemming using Porter Stemmer: 
 [('SPADE', 'spade'), (':', ':'), ('efficient', 'effici'), ('algorithm', 'algorithm'), ('mining', 'mine'), ('frequent', 'frequent'), ('sequences', 'sequenc'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('SPADE', 'spade'), (':', ':'), ('efficient', 'effici'), ('algorithm', 'algorithm'), ('mining', 'mine'), ('frequent', 'frequent'), ('sequences', 'sequenc'), ('.', '.')]

>> Lemmatization: 
 [('SPADE', 'SPADE'), (':', ':'), ('efficient', 'efficient'), ('algorithm', 'algorithm'), ('mining', 'mining'), ('frequent', 'frequent'), ('sequences', 'sequence'), ('.', '.')]


------------------- Sentence 4 -------------------

Mach Learn.

>> Tokens are: 
 ['Mach', 'Learn', '.']

>> Bigrams are: 
 [('Mach', 'Learn'), ('Learn', '.')]

>> Trigrams are: 
 [('Mach', 'Learn', '.')]

>> POS Tags are: 
 [('Mach', 'NNP'), ('Learn', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Mach Learn']

>> Named Entities are: 
 [('PERSON', 'Mach'), ('ORGANIZATION', 'Learn')] 

>> Stemming using Porter Stemmer: 
 [('Mach', 'mach'), ('Learn', 'learn'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Mach', 'mach'), ('Learn', 'learn'), ('.', '.')]

>> Lemmatization: 
 [('Mach', 'Mach'), ('Learn', 'Learn'), ('.', '.')]


------------------- Sentence 5 -------------------

2001;42(1–2):31–60.

>> Tokens are: 
 ['2001', ';', '42', '(', '1–2', ')', ':31–60', '.']

>> Bigrams are: 
 [('2001', ';'), (';', '42'), ('42', '('), ('(', '1–2'), ('1–2', ')'), (')', ':31–60'), (':31–60', '.')]

>> Trigrams are: 
 [('2001', ';', '42'), (';', '42', '('), ('42', '(', '1–2'), ('(', '1–2', ')'), ('1–2', ')', ':31–60'), (')', ':31–60', '.')]

>> POS Tags are: 
 [('2001', 'CD'), (';', ':'), ('42', 'CD'), ('(', '('), ('1–2', 'CD'), (')', ')'), (':31–60', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 [':31–60']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('2001', '2001'), (';', ';'), ('42', '42'), ('(', '('), ('1–2', '1–2'), (')', ')'), (':31–60', ':31–60'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('2001', '2001'), (';', ';'), ('42', '42'), ('(', '('), ('1–2', '1–2'), (')', ')'), (':31–60', ':31–60'), ('.', '.')]

>> Lemmatization: 
 [('2001', '2001'), (';', ';'), ('42', '42'), ('(', '('), ('1–2', '1–2'), (')', ')'), (':31–60', ':31–60'), ('.', '.')]


------------------- Sentence 6 -------------------

59.

>> Tokens are: 
 ['59', '.']

>> Bigrams are: 
 [('59', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('59', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('59', '59'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('59', '59'), ('.', '.')]

>> Lemmatization: 
 [('59', '59'), ('.', '.')]


------------------- Sentence 7 -------------------

Yan X, Han J, Afshar R. CloSpan: mining closed sequential patterns in large datasets.

>> Tokens are: 
 ['Yan', 'X', ',', 'Han', 'J', ',', 'Afshar', 'R.', 'CloSpan', ':', 'mining', 'closed', 'sequential', 'patterns', 'large', 'datasets', '.']

>> Bigrams are: 
 [('Yan', 'X'), ('X', ','), (',', 'Han'), ('Han', 'J'), ('J', ','), (',', 'Afshar'), ('Afshar', 'R.'), ('R.', 'CloSpan'), ('CloSpan', ':'), (':', 'mining'), ('mining', 'closed'), ('closed', 'sequential'), ('sequential', 'patterns'), ('patterns', 'large'), ('large', 'datasets'), ('datasets', '.')]

>> Trigrams are: 
 [('Yan', 'X', ','), ('X', ',', 'Han'), (',', 'Han', 'J'), ('Han', 'J', ','), ('J', ',', 'Afshar'), (',', 'Afshar', 'R.'), ('Afshar', 'R.', 'CloSpan'), ('R.', 'CloSpan', ':'), ('CloSpan', ':', 'mining'), (':', 'mining', 'closed'), ('mining', 'closed', 'sequential'), ('closed', 'sequential', 'patterns'), ('sequential', 'patterns', 'large'), ('patterns', 'large', 'datasets'), ('large', 'datasets', '.')]

>> POS Tags are: 
 [('Yan', 'NNP'), ('X', 'NNP'), (',', ','), ('Han', 'NNP'), ('J', 'NNP'), (',', ','), ('Afshar', 'NNP'), ('R.', 'NNP'), ('CloSpan', 'NNP'), (':', ':'), ('mining', 'NN'), ('closed', 'VBD'), ('sequential', 'JJ'), ('patterns', 'NNS'), ('large', 'JJ'), ('datasets', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['Yan X', 'Han J', 'Afshar R. CloSpan', 'mining', 'sequential patterns', 'large datasets']

>> Named Entities are: 
 [('PERSON', 'Yan'), ('ORGANIZATION', 'X'), ('PERSON', 'Han J'), ('PERSON', 'Afshar R.')] 

>> Stemming using Porter Stemmer: 
 [('Yan', 'yan'), ('X', 'x'), (',', ','), ('Han', 'han'), ('J', 'j'), (',', ','), ('Afshar', 'afshar'), ('R.', 'r.'), ('CloSpan', 'clospan'), (':', ':'), ('mining', 'mine'), ('closed', 'close'), ('sequential', 'sequenti'), ('patterns', 'pattern'), ('large', 'larg'), ('datasets', 'dataset'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Yan', 'yan'), ('X', 'x'), (',', ','), ('Han', 'han'), ('J', 'j'), (',', ','), ('Afshar', 'afshar'), ('R.', 'r.'), ('CloSpan', 'clospan'), (':', ':'), ('mining', 'mine'), ('closed', 'close'), ('sequential', 'sequenti'), ('patterns', 'pattern'), ('large', 'larg'), ('datasets', 'dataset'), ('.', '.')]

>> Lemmatization: 
 [('Yan', 'Yan'), ('X', 'X'), (',', ','), ('Han', 'Han'), ('J', 'J'), (',', ','), ('Afshar', 'Afshar'), ('R.', 'R.'), ('CloSpan', 'CloSpan'), (':', ':'), ('mining', 'mining'), ('closed', 'closed'), ('sequential', 'sequential'), ('patterns', 'pattern'), ('large', 'large'), ('datasets', 'datasets'), ('.', '.')]


------------------- Sentence 8 -------------------

In: Proceedings of the SIAM

>> Tokens are: 
 ['In', ':', 'Proceedings', 'SIAM']

>> Bigrams are: 
 [('In', ':'), (':', 'Proceedings'), ('Proceedings', 'SIAM')]

>> Trigrams are: 
 [('In', ':', 'Proceedings'), (':', 'Proceedings', 'SIAM')]

>> POS Tags are: 
 [('In', 'IN'), (':', ':'), ('Proceedings', 'NNS'), ('SIAM', 'NNP')]

>> Noun Phrases are: 
 ['Proceedings SIAM']

>> Named Entities are: 
 [('ORGANIZATION', 'SIAM')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), (':', ':'), ('Proceedings', 'proceed'), ('SIAM', 'siam')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), (':', ':'), ('Proceedings', 'proceed'), ('SIAM', 'siam')]

>> Lemmatization: 
 [('In', 'In'), (':', ':'), ('Proceedings', 'Proceedings'), ('SIAM', 'SIAM')]



========================================== PARAGRAPH 455 ===========================================

International Conference on Data Mining, 2003. pp 166–177.  60. Pei J, Han J, Asl MB, Pinto H, Chen Q, Dayal U, Hsu MC. PrefixSpan mining sequential patterns efficiently by  

------------------- Sentence 1 -------------------

International Conference on Data Mining, 2003. pp 166–177.

>> Tokens are: 
 ['International', 'Conference', 'Data', 'Mining', ',', '2003.', 'pp', '166–177', '.']

>> Bigrams are: 
 [('International', 'Conference'), ('Conference', 'Data'), ('Data', 'Mining'), ('Mining', ','), (',', '2003.'), ('2003.', 'pp'), ('pp', '166–177'), ('166–177', '.')]

>> Trigrams are: 
 [('International', 'Conference', 'Data'), ('Conference', 'Data', 'Mining'), ('Data', 'Mining', ','), ('Mining', ',', '2003.'), (',', '2003.', 'pp'), ('2003.', 'pp', '166–177'), ('pp', '166–177', '.')]

>> POS Tags are: 
 [('International', 'NNP'), ('Conference', 'NNP'), ('Data', 'NNP'), ('Mining', 'NNP'), (',', ','), ('2003.', 'CD'), ('pp', 'NN'), ('166–177', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['International Conference Data Mining', 'pp']

>> Named Entities are: 
 [('ORGANIZATION', 'International Conference Data Mining')] 

>> Stemming using Porter Stemmer: 
 [('International', 'intern'), ('Conference', 'confer'), ('Data', 'data'), ('Mining', 'mine'), (',', ','), ('2003.', '2003.'), ('pp', 'pp'), ('166–177', '166–177'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('International', 'intern'), ('Conference', 'confer'), ('Data', 'data'), ('Mining', 'mine'), (',', ','), ('2003.', '2003.'), ('pp', 'pp'), ('166–177', '166–177'), ('.', '.')]

>> Lemmatization: 
 [('International', 'International'), ('Conference', 'Conference'), ('Data', 'Data'), ('Mining', 'Mining'), (',', ','), ('2003.', '2003.'), ('pp', 'pp'), ('166–177', '166–177'), ('.', '.')]


------------------- Sentence 2 -------------------

60.

>> Tokens are: 
 ['60', '.']

>> Bigrams are: 
 [('60', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('60', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('60', '60'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('60', '60'), ('.', '.')]

>> Lemmatization: 
 [('60', '60'), ('.', '.')]


------------------- Sentence 3 -------------------

Pei J, Han J, Asl MB, Pinto H, Chen Q, Dayal U, Hsu MC.

>> Tokens are: 
 ['Pei', 'J', ',', 'Han', 'J', ',', 'Asl', 'MB', ',', 'Pinto', 'H', ',', 'Chen', 'Q', ',', 'Dayal', 'U', ',', 'Hsu', 'MC', '.']

>> Bigrams are: 
 [('Pei', 'J'), ('J', ','), (',', 'Han'), ('Han', 'J'), ('J', ','), (',', 'Asl'), ('Asl', 'MB'), ('MB', ','), (',', 'Pinto'), ('Pinto', 'H'), ('H', ','), (',', 'Chen'), ('Chen', 'Q'), ('Q', ','), (',', 'Dayal'), ('Dayal', 'U'), ('U', ','), (',', 'Hsu'), ('Hsu', 'MC'), ('MC', '.')]

>> Trigrams are: 
 [('Pei', 'J', ','), ('J', ',', 'Han'), (',', 'Han', 'J'), ('Han', 'J', ','), ('J', ',', 'Asl'), (',', 'Asl', 'MB'), ('Asl', 'MB', ','), ('MB', ',', 'Pinto'), (',', 'Pinto', 'H'), ('Pinto', 'H', ','), ('H', ',', 'Chen'), (',', 'Chen', 'Q'), ('Chen', 'Q', ','), ('Q', ',', 'Dayal'), (',', 'Dayal', 'U'), ('Dayal', 'U', ','), ('U', ',', 'Hsu'), (',', 'Hsu', 'MC'), ('Hsu', 'MC', '.')]

>> POS Tags are: 
 [('Pei', 'NNP'), ('J', 'NNP'), (',', ','), ('Han', 'NNP'), ('J', 'NNP'), (',', ','), ('Asl', 'NNP'), ('MB', 'NNP'), (',', ','), ('Pinto', 'NNP'), ('H', 'NNP'), (',', ','), ('Chen', 'NNP'), ('Q', 'NNP'), (',', ','), ('Dayal', 'NNP'), ('U', 'NNP'), (',', ','), ('Hsu', 'NNP'), ('MC', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Pei J', 'Han J', 'Asl MB', 'Pinto H', 'Chen Q', 'Dayal U', 'Hsu MC']

>> Named Entities are: 
 [('PERSON', 'Pei'), ('ORGANIZATION', 'J'), ('PERSON', 'Han J'), ('PERSON', 'Asl MB'), ('PERSON', 'Pinto H'), ('PERSON', 'Chen Q'), ('PERSON', 'Dayal U'), ('PERSON', 'Hsu MC')] 

>> Stemming using Porter Stemmer: 
 [('Pei', 'pei'), ('J', 'j'), (',', ','), ('Han', 'han'), ('J', 'j'), (',', ','), ('Asl', 'asl'), ('MB', 'mb'), (',', ','), ('Pinto', 'pinto'), ('H', 'h'), (',', ','), ('Chen', 'chen'), ('Q', 'q'), (',', ','), ('Dayal', 'dayal'), ('U', 'u'), (',', ','), ('Hsu', 'hsu'), ('MC', 'mc'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Pei', 'pei'), ('J', 'j'), (',', ','), ('Han', 'han'), ('J', 'j'), (',', ','), ('Asl', 'asl'), ('MB', 'mb'), (',', ','), ('Pinto', 'pinto'), ('H', 'h'), (',', ','), ('Chen', 'chen'), ('Q', 'q'), (',', ','), ('Dayal', 'dayal'), ('U', 'u'), (',', ','), ('Hsu', 'hsu'), ('MC', 'mc'), ('.', '.')]

>> Lemmatization: 
 [('Pei', 'Pei'), ('J', 'J'), (',', ','), ('Han', 'Han'), ('J', 'J'), (',', ','), ('Asl', 'Asl'), ('MB', 'MB'), (',', ','), ('Pinto', 'Pinto'), ('H', 'H'), (',', ','), ('Chen', 'Chen'), ('Q', 'Q'), (',', ','), ('Dayal', 'Dayal'), ('U', 'U'), (',', ','), ('Hsu', 'Hsu'), ('MC', 'MC'), ('.', '.')]


------------------- Sentence 4 -------------------

PrefixSpan mining sequential patterns efficiently by

>> Tokens are: 
 ['PrefixSpan', 'mining', 'sequential', 'patterns', 'efficiently']

>> Bigrams are: 
 [('PrefixSpan', 'mining'), ('mining', 'sequential'), ('sequential', 'patterns'), ('patterns', 'efficiently')]

>> Trigrams are: 
 [('PrefixSpan', 'mining', 'sequential'), ('mining', 'sequential', 'patterns'), ('sequential', 'patterns', 'efficiently')]

>> POS Tags are: 
 [('PrefixSpan', 'NNP'), ('mining', 'VBG'), ('sequential', 'JJ'), ('patterns', 'NNS'), ('efficiently', 'RB')]

>> Noun Phrases are: 
 ['PrefixSpan', 'sequential patterns']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('PrefixSpan', 'prefixspan'), ('mining', 'mine'), ('sequential', 'sequenti'), ('patterns', 'pattern'), ('efficiently', 'effici')]

>> Stemming using Snowball Stemmer: 
 [('PrefixSpan', 'prefixspan'), ('mining', 'mine'), ('sequential', 'sequenti'), ('patterns', 'pattern'), ('efficiently', 'effici')]

>> Lemmatization: 
 [('PrefixSpan', 'PrefixSpan'), ('mining', 'mining'), ('sequential', 'sequential'), ('patterns', 'pattern'), ('efficiently', 'efficiently')]



========================================== PARAGRAPH 456 ===========================================

prefix projected pattern growth. In: Proceedings of the International Conference on Data Engineering, 2001. pp  215–226.

------------------- Sentence 1 -------------------

prefix projected pattern growth.

>> Tokens are: 
 ['prefix', 'projected', 'pattern', 'growth', '.']

>> Bigrams are: 
 [('prefix', 'projected'), ('projected', 'pattern'), ('pattern', 'growth'), ('growth', '.')]

>> Trigrams are: 
 [('prefix', 'projected', 'pattern'), ('projected', 'pattern', 'growth'), ('pattern', 'growth', '.')]

>> POS Tags are: 
 [('prefix', 'NN'), ('projected', 'VBD'), ('pattern', 'JJ'), ('growth', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['prefix', 'pattern growth']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('prefix', 'prefix'), ('projected', 'project'), ('pattern', 'pattern'), ('growth', 'growth'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('prefix', 'prefix'), ('projected', 'project'), ('pattern', 'pattern'), ('growth', 'growth'), ('.', '.')]

>> Lemmatization: 
 [('prefix', 'prefix'), ('projected', 'projected'), ('pattern', 'pattern'), ('growth', 'growth'), ('.', '.')]


------------------- Sentence 2 -------------------

In: Proceedings of the International Conference on Data Engineering, 2001. pp  215–226.

>> Tokens are: 
 ['In', ':', 'Proceedings', 'International', 'Conference', 'Data', 'Engineering', ',', '2001.', 'pp', '215–226', '.']

>> Bigrams are: 
 [('In', ':'), (':', 'Proceedings'), ('Proceedings', 'International'), ('International', 'Conference'), ('Conference', 'Data'), ('Data', 'Engineering'), ('Engineering', ','), (',', '2001.'), ('2001.', 'pp'), ('pp', '215–226'), ('215–226', '.')]

>> Trigrams are: 
 [('In', ':', 'Proceedings'), (':', 'Proceedings', 'International'), ('Proceedings', 'International', 'Conference'), ('International', 'Conference', 'Data'), ('Conference', 'Data', 'Engineering'), ('Data', 'Engineering', ','), ('Engineering', ',', '2001.'), (',', '2001.', 'pp'), ('2001.', 'pp', '215–226'), ('pp', '215–226', '.')]

>> POS Tags are: 
 [('In', 'IN'), (':', ':'), ('Proceedings', 'NNS'), ('International', 'NNP'), ('Conference', 'NNP'), ('Data', 'NNP'), ('Engineering', 'NNP'), (',', ','), ('2001.', 'CD'), ('pp', 'NN'), ('215–226', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Proceedings International Conference Data Engineering', 'pp']

>> Named Entities are: 
 [('ORGANIZATION', 'International Conference Data Engineering')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), (':', ':'), ('Proceedings', 'proceed'), ('International', 'intern'), ('Conference', 'confer'), ('Data', 'data'), ('Engineering', 'engin'), (',', ','), ('2001.', '2001.'), ('pp', 'pp'), ('215–226', '215–226'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), (':', ':'), ('Proceedings', 'proceed'), ('International', 'intern'), ('Conference', 'confer'), ('Data', 'data'), ('Engineering', 'engin'), (',', ','), ('2001.', '2001.'), ('pp', 'pp'), ('215–226', '215–226'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), (':', ':'), ('Proceedings', 'Proceedings'), ('International', 'International'), ('Conference', 'Conference'), ('Data', 'Data'), ('Engineering', 'Engineering'), (',', ','), ('2001.', '2001.'), ('pp', 'pp'), ('215–226', '215–226'), ('.', '.')]



========================================== PARAGRAPH 457 ===========================================

Page 30 of 32Tsai et al. Journal of Big Data  (2015) 2:21  

------------------- Sentence 1 -------------------

Page 30 of 32Tsai et al.

>> Tokens are: 
 ['Page', '30', '32Tsai', 'et', 'al', '.']

>> Bigrams are: 
 [('Page', '30'), ('30', '32Tsai'), ('32Tsai', 'et'), ('et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('Page', '30', '32Tsai'), ('30', '32Tsai', 'et'), ('32Tsai', 'et', 'al'), ('et', 'al', '.')]

>> POS Tags are: 
 [('Page', 'NN'), ('30', 'CD'), ('32Tsai', 'CD'), ('et', 'NN'), ('al', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Page', 'et al']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Page', 'page'), ('30', '30'), ('32Tsai', '32tsai'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Page', 'page'), ('30', '30'), ('32Tsai', '32tsai'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('Page', 'Page'), ('30', '30'), ('32Tsai', '32Tsai'), ('et', 'et'), ('al', 'al'), ('.', '.')]


------------------- Sentence 2 -------------------

Journal of Big Data  (2015) 2:21

>> Tokens are: 
 ['Journal', 'Big', 'Data', '(', '2015', ')', '2:21']

>> Bigrams are: 
 [('Journal', 'Big'), ('Big', 'Data'), ('Data', '('), ('(', '2015'), ('2015', ')'), (')', '2:21')]

>> Trigrams are: 
 [('Journal', 'Big', 'Data'), ('Big', 'Data', '('), ('Data', '(', '2015'), ('(', '2015', ')'), ('2015', ')', '2:21')]

>> POS Tags are: 
 [('Journal', 'NNP'), ('Big', 'NNP'), ('Data', 'NNP'), ('(', '('), ('2015', 'CD'), (')', ')'), ('2:21', 'CD')]

>> Noun Phrases are: 
 ['Journal Big Data']

>> Named Entities are: 
 [('PERSON', 'Journal')] 

>> Stemming using Porter Stemmer: 
 [('Journal', 'journal'), ('Big', 'big'), ('Data', 'data'), ('(', '('), ('2015', '2015'), (')', ')'), ('2:21', '2:21')]

>> Stemming using Snowball Stemmer: 
 [('Journal', 'journal'), ('Big', 'big'), ('Data', 'data'), ('(', '('), ('2015', '2015'), (')', ')'), ('2:21', '2:21')]

>> Lemmatization: 
 [('Journal', 'Journal'), ('Big', 'Big'), ('Data', 'Data'), ('(', '('), ('2015', '2015'), (')', ')'), ('2:21', '2:21')]



========================================== PARAGRAPH 458 ===========================================

 61. Ayres J, Flannick J, Gehrke J, Yiu T. Sequential PAttern Mining using a bitmap representation. In: Proceedings of the  ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, 2002. pp 429–435. 

------------------- Sentence 1 -------------------

 61.

>> Tokens are: 
 ['61', '.']

>> Bigrams are: 
 [('61', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('61', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('61', '61'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('61', '61'), ('.', '.')]

>> Lemmatization: 
 [('61', '61'), ('.', '.')]


------------------- Sentence 2 -------------------

Ayres J, Flannick J, Gehrke J, Yiu T. Sequential PAttern Mining using a bitmap representation.

>> Tokens are: 
 ['Ayres', 'J', ',', 'Flannick', 'J', ',', 'Gehrke', 'J', ',', 'Yiu', 'T.', 'Sequential', 'PAttern', 'Mining', 'using', 'bitmap', 'representation', '.']

>> Bigrams are: 
 [('Ayres', 'J'), ('J', ','), (',', 'Flannick'), ('Flannick', 'J'), ('J', ','), (',', 'Gehrke'), ('Gehrke', 'J'), ('J', ','), (',', 'Yiu'), ('Yiu', 'T.'), ('T.', 'Sequential'), ('Sequential', 'PAttern'), ('PAttern', 'Mining'), ('Mining', 'using'), ('using', 'bitmap'), ('bitmap', 'representation'), ('representation', '.')]

>> Trigrams are: 
 [('Ayres', 'J', ','), ('J', ',', 'Flannick'), (',', 'Flannick', 'J'), ('Flannick', 'J', ','), ('J', ',', 'Gehrke'), (',', 'Gehrke', 'J'), ('Gehrke', 'J', ','), ('J', ',', 'Yiu'), (',', 'Yiu', 'T.'), ('Yiu', 'T.', 'Sequential'), ('T.', 'Sequential', 'PAttern'), ('Sequential', 'PAttern', 'Mining'), ('PAttern', 'Mining', 'using'), ('Mining', 'using', 'bitmap'), ('using', 'bitmap', 'representation'), ('bitmap', 'representation', '.')]

>> POS Tags are: 
 [('Ayres', 'NNS'), ('J', 'NNP'), (',', ','), ('Flannick', 'NNP'), ('J', 'NNP'), (',', ','), ('Gehrke', 'NNP'), ('J', 'NNP'), (',', ','), ('Yiu', 'NNP'), ('T.', 'NNP'), ('Sequential', 'NNP'), ('PAttern', 'NNP'), ('Mining', 'NNP'), ('using', 'VBG'), ('bitmap', 'JJ'), ('representation', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Ayres J', 'Flannick J', 'Gehrke J', 'Yiu T. Sequential PAttern Mining', 'bitmap representation']

>> Named Entities are: 
 [('PERSON', 'Ayres'), ('ORGANIZATION', 'J'), ('PERSON', 'Flannick J'), ('PERSON', 'Gehrke J'), ('PERSON', 'Yiu T. Sequential PAttern')] 

>> Stemming using Porter Stemmer: 
 [('Ayres', 'ayr'), ('J', 'j'), (',', ','), ('Flannick', 'flannick'), ('J', 'j'), (',', ','), ('Gehrke', 'gehrk'), ('J', 'j'), (',', ','), ('Yiu', 'yiu'), ('T.', 't.'), ('Sequential', 'sequenti'), ('PAttern', 'pattern'), ('Mining', 'mine'), ('using', 'use'), ('bitmap', 'bitmap'), ('representation', 'represent'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Ayres', 'ayr'), ('J', 'j'), (',', ','), ('Flannick', 'flannick'), ('J', 'j'), (',', ','), ('Gehrke', 'gehrk'), ('J', 'j'), (',', ','), ('Yiu', 'yiu'), ('T.', 't.'), ('Sequential', 'sequenti'), ('PAttern', 'pattern'), ('Mining', 'mine'), ('using', 'use'), ('bitmap', 'bitmap'), ('representation', 'represent'), ('.', '.')]

>> Lemmatization: 
 [('Ayres', 'Ayres'), ('J', 'J'), (',', ','), ('Flannick', 'Flannick'), ('J', 'J'), (',', ','), ('Gehrke', 'Gehrke'), ('J', 'J'), (',', ','), ('Yiu', 'Yiu'), ('T.', 'T.'), ('Sequential', 'Sequential'), ('PAttern', 'PAttern'), ('Mining', 'Mining'), ('using', 'using'), ('bitmap', 'bitmap'), ('representation', 'representation'), ('.', '.')]


------------------- Sentence 3 -------------------

In: Proceedings of the  ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, 2002. pp 429–435.

>> Tokens are: 
 ['In', ':', 'Proceedings', 'ACM', 'SIGKDD', 'International', 'Conference', 'Knowledge', 'Discovery', 'Data', 'Mining', ',', '2002.', 'pp', '429–435', '.']

>> Bigrams are: 
 [('In', ':'), (':', 'Proceedings'), ('Proceedings', 'ACM'), ('ACM', 'SIGKDD'), ('SIGKDD', 'International'), ('International', 'Conference'), ('Conference', 'Knowledge'), ('Knowledge', 'Discovery'), ('Discovery', 'Data'), ('Data', 'Mining'), ('Mining', ','), (',', '2002.'), ('2002.', 'pp'), ('pp', '429–435'), ('429–435', '.')]

>> Trigrams are: 
 [('In', ':', 'Proceedings'), (':', 'Proceedings', 'ACM'), ('Proceedings', 'ACM', 'SIGKDD'), ('ACM', 'SIGKDD', 'International'), ('SIGKDD', 'International', 'Conference'), ('International', 'Conference', 'Knowledge'), ('Conference', 'Knowledge', 'Discovery'), ('Knowledge', 'Discovery', 'Data'), ('Discovery', 'Data', 'Mining'), ('Data', 'Mining', ','), ('Mining', ',', '2002.'), (',', '2002.', 'pp'), ('2002.', 'pp', '429–435'), ('pp', '429–435', '.')]

>> POS Tags are: 
 [('In', 'IN'), (':', ':'), ('Proceedings', 'NNS'), ('ACM', 'NNP'), ('SIGKDD', 'NNP'), ('International', 'NNP'), ('Conference', 'NNP'), ('Knowledge', 'NNP'), ('Discovery', 'NNP'), ('Data', 'NNP'), ('Mining', 'NNP'), (',', ','), ('2002.', 'CD'), ('pp', 'NN'), ('429–435', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Proceedings ACM SIGKDD International Conference Knowledge Discovery Data Mining', 'pp']

>> Named Entities are: 
 [('ORGANIZATION', 'ACM'), ('ORGANIZATION', 'SIGKDD International Conference')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), (':', ':'), ('Proceedings', 'proceed'), ('ACM', 'acm'), ('SIGKDD', 'sigkdd'), ('International', 'intern'), ('Conference', 'confer'), ('Knowledge', 'knowledg'), ('Discovery', 'discoveri'), ('Data', 'data'), ('Mining', 'mine'), (',', ','), ('2002.', '2002.'), ('pp', 'pp'), ('429–435', '429–435'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), (':', ':'), ('Proceedings', 'proceed'), ('ACM', 'acm'), ('SIGKDD', 'sigkdd'), ('International', 'intern'), ('Conference', 'confer'), ('Knowledge', 'knowledg'), ('Discovery', 'discoveri'), ('Data', 'data'), ('Mining', 'mine'), (',', ','), ('2002.', '2002.'), ('pp', 'pp'), ('429–435', '429–435'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), (':', ':'), ('Proceedings', 'Proceedings'), ('ACM', 'ACM'), ('SIGKDD', 'SIGKDD'), ('International', 'International'), ('Conference', 'Conference'), ('Knowledge', 'Knowledge'), ('Discovery', 'Discovery'), ('Data', 'Data'), ('Mining', 'Mining'), (',', ','), ('2002.', '2002.'), ('pp', 'pp'), ('429–435', '429–435'), ('.', '.')]



========================================== PARAGRAPH 459 ===========================================

 62. Masseglia F, Poncelet P, Teisseire M. Incremental mining of sequential patterns in large databases. Data Knowl Eng.  2003;46(1):97–121. 

------------------- Sentence 1 -------------------

 62.

>> Tokens are: 
 ['62', '.']

>> Bigrams are: 
 [('62', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('62', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('62', '62'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('62', '62'), ('.', '.')]

>> Lemmatization: 
 [('62', '62'), ('.', '.')]


------------------- Sentence 2 -------------------

Masseglia F, Poncelet P, Teisseire M. Incremental mining of sequential patterns in large databases.

>> Tokens are: 
 ['Masseglia', 'F', ',', 'Poncelet', 'P', ',', 'Teisseire', 'M.', 'Incremental', 'mining', 'sequential', 'patterns', 'large', 'databases', '.']

>> Bigrams are: 
 [('Masseglia', 'F'), ('F', ','), (',', 'Poncelet'), ('Poncelet', 'P'), ('P', ','), (',', 'Teisseire'), ('Teisseire', 'M.'), ('M.', 'Incremental'), ('Incremental', 'mining'), ('mining', 'sequential'), ('sequential', 'patterns'), ('patterns', 'large'), ('large', 'databases'), ('databases', '.')]

>> Trigrams are: 
 [('Masseglia', 'F', ','), ('F', ',', 'Poncelet'), (',', 'Poncelet', 'P'), ('Poncelet', 'P', ','), ('P', ',', 'Teisseire'), (',', 'Teisseire', 'M.'), ('Teisseire', 'M.', 'Incremental'), ('M.', 'Incremental', 'mining'), ('Incremental', 'mining', 'sequential'), ('mining', 'sequential', 'patterns'), ('sequential', 'patterns', 'large'), ('patterns', 'large', 'databases'), ('large', 'databases', '.')]

>> POS Tags are: 
 [('Masseglia', 'NNP'), ('F', 'NNP'), (',', ','), ('Poncelet', 'NNP'), ('P', 'NNP'), (',', ','), ('Teisseire', 'NNP'), ('M.', 'NNP'), ('Incremental', 'NNP'), ('mining', 'NN'), ('sequential', 'NN'), ('patterns', 'NNS'), ('large', 'JJ'), ('databases', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['Masseglia F', 'Poncelet P', 'Teisseire M. Incremental mining sequential patterns', 'large databases']

>> Named Entities are: 
 [('PERSON', 'Masseglia'), ('ORGANIZATION', 'F'), ('PERSON', 'Poncelet P'), ('PERSON', 'Teisseire M. Incremental')] 

>> Stemming using Porter Stemmer: 
 [('Masseglia', 'masseglia'), ('F', 'f'), (',', ','), ('Poncelet', 'poncelet'), ('P', 'p'), (',', ','), ('Teisseire', 'teisseir'), ('M.', 'm.'), ('Incremental', 'increment'), ('mining', 'mine'), ('sequential', 'sequenti'), ('patterns', 'pattern'), ('large', 'larg'), ('databases', 'databas'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Masseglia', 'masseglia'), ('F', 'f'), (',', ','), ('Poncelet', 'poncelet'), ('P', 'p'), (',', ','), ('Teisseire', 'teisseir'), ('M.', 'm.'), ('Incremental', 'increment'), ('mining', 'mine'), ('sequential', 'sequenti'), ('patterns', 'pattern'), ('large', 'larg'), ('databases', 'databas'), ('.', '.')]

>> Lemmatization: 
 [('Masseglia', 'Masseglia'), ('F', 'F'), (',', ','), ('Poncelet', 'Poncelet'), ('P', 'P'), (',', ','), ('Teisseire', 'Teisseire'), ('M.', 'M.'), ('Incremental', 'Incremental'), ('mining', 'mining'), ('sequential', 'sequential'), ('patterns', 'pattern'), ('large', 'large'), ('databases', 'database'), ('.', '.')]


------------------- Sentence 3 -------------------

Data Knowl Eng.

>> Tokens are: 
 ['Data', 'Knowl', 'Eng', '.']

>> Bigrams are: 
 [('Data', 'Knowl'), ('Knowl', 'Eng'), ('Eng', '.')]

>> Trigrams are: 
 [('Data', 'Knowl', 'Eng'), ('Knowl', 'Eng', '.')]

>> POS Tags are: 
 [('Data', 'NNP'), ('Knowl', 'NNP'), ('Eng', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Data Knowl Eng']

>> Named Entities are: 
 [('PERSON', 'Data'), ('PERSON', 'Knowl Eng')] 

>> Stemming using Porter Stemmer: 
 [('Data', 'data'), ('Knowl', 'knowl'), ('Eng', 'eng'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Data', 'data'), ('Knowl', 'knowl'), ('Eng', 'eng'), ('.', '.')]

>> Lemmatization: 
 [('Data', 'Data'), ('Knowl', 'Knowl'), ('Eng', 'Eng'), ('.', '.')]


------------------- Sentence 4 -------------------

2003;46(1):97–121.

>> Tokens are: 
 ['2003', ';', '46', '(', '1', ')', ':97–121', '.']

>> Bigrams are: 
 [('2003', ';'), (';', '46'), ('46', '('), ('(', '1'), ('1', ')'), (')', ':97–121'), (':97–121', '.')]

>> Trigrams are: 
 [('2003', ';', '46'), (';', '46', '('), ('46', '(', '1'), ('(', '1', ')'), ('1', ')', ':97–121'), (')', ':97–121', '.')]

>> POS Tags are: 
 [('2003', 'CD'), (';', ':'), ('46', 'CD'), ('(', '('), ('1', 'CD'), (')', ')'), (':97–121', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 [':97–121']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('2003', '2003'), (';', ';'), ('46', '46'), ('(', '('), ('1', '1'), (')', ')'), (':97–121', ':97–121'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('2003', '2003'), (';', ';'), ('46', '46'), ('(', '('), ('1', '1'), (')', ')'), (':97–121', ':97–121'), ('.', '.')]

>> Lemmatization: 
 [('2003', '2003'), (';', ';'), ('46', '46'), ('(', '('), ('1', '1'), (')', ')'), (':97–121', ':97–121'), ('.', '.')]



========================================== PARAGRAPH 460 ===========================================

 63. Xu R, Wunsch‑II DC. Survey of clustering algorithms. IEEE Trans Neural Netw. 2005;16(3):645–78.  64. Chiang M‑C, Tsai C‑W, Yang C‑S. A time‑efficient pattern reduction algorithm for k‑means clustering. Inform Sci.  

------------------- Sentence 1 -------------------

 63.

>> Tokens are: 
 ['63', '.']

>> Bigrams are: 
 [('63', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('63', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('63', '63'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('63', '63'), ('.', '.')]

>> Lemmatization: 
 [('63', '63'), ('.', '.')]


------------------- Sentence 2 -------------------

Xu R, Wunsch‑II DC.

>> Tokens are: 
 ['Xu', 'R', ',', 'Wunsch‑II', 'DC', '.']

>> Bigrams are: 
 [('Xu', 'R'), ('R', ','), (',', 'Wunsch‑II'), ('Wunsch‑II', 'DC'), ('DC', '.')]

>> Trigrams are: 
 [('Xu', 'R', ','), ('R', ',', 'Wunsch‑II'), (',', 'Wunsch‑II', 'DC'), ('Wunsch‑II', 'DC', '.')]

>> POS Tags are: 
 [('Xu', 'NN'), ('R', 'NNP'), (',', ','), ('Wunsch‑II', 'NNP'), ('DC', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Xu R', 'Wunsch‑II DC']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Xu', 'xu'), ('R', 'r'), (',', ','), ('Wunsch‑II', 'wunsch‑ii'), ('DC', 'dc'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Xu', 'xu'), ('R', 'r'), (',', ','), ('Wunsch‑II', 'wunsch‑ii'), ('DC', 'dc'), ('.', '.')]

>> Lemmatization: 
 [('Xu', 'Xu'), ('R', 'R'), (',', ','), ('Wunsch‑II', 'Wunsch‑II'), ('DC', 'DC'), ('.', '.')]


------------------- Sentence 3 -------------------

Survey of clustering algorithms.

>> Tokens are: 
 ['Survey', 'clustering', 'algorithms', '.']

>> Bigrams are: 
 [('Survey', 'clustering'), ('clustering', 'algorithms'), ('algorithms', '.')]

>> Trigrams are: 
 [('Survey', 'clustering', 'algorithms'), ('clustering', 'algorithms', '.')]

>> POS Tags are: 
 [('Survey', 'NNP'), ('clustering', 'VBG'), ('algorithms', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Survey', 'algorithms']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Survey', 'survey'), ('clustering', 'cluster'), ('algorithms', 'algorithm'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Survey', 'survey'), ('clustering', 'cluster'), ('algorithms', 'algorithm'), ('.', '.')]

>> Lemmatization: 
 [('Survey', 'Survey'), ('clustering', 'clustering'), ('algorithms', 'algorithm'), ('.', '.')]


------------------- Sentence 4 -------------------

IEEE Trans Neural Netw.

>> Tokens are: 
 ['IEEE', 'Trans', 'Neural', 'Netw', '.']

>> Bigrams are: 
 [('IEEE', 'Trans'), ('Trans', 'Neural'), ('Neural', 'Netw'), ('Netw', '.')]

>> Trigrams are: 
 [('IEEE', 'Trans', 'Neural'), ('Trans', 'Neural', 'Netw'), ('Neural', 'Netw', '.')]

>> POS Tags are: 
 [('IEEE', 'NNP'), ('Trans', 'NNP'), ('Neural', 'NNP'), ('Netw', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['IEEE Trans Neural Netw']

>> Named Entities are: 
 [('ORGANIZATION', 'IEEE'), ('PERSON', 'Trans Neural Netw')] 

>> Stemming using Porter Stemmer: 
 [('IEEE', 'ieee'), ('Trans', 'tran'), ('Neural', 'neural'), ('Netw', 'netw'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('IEEE', 'ieee'), ('Trans', 'tran'), ('Neural', 'neural'), ('Netw', 'netw'), ('.', '.')]

>> Lemmatization: 
 [('IEEE', 'IEEE'), ('Trans', 'Trans'), ('Neural', 'Neural'), ('Netw', 'Netw'), ('.', '.')]


------------------- Sentence 5 -------------------

2005;16(3):645–78.

>> Tokens are: 
 ['2005', ';', '16', '(', '3', ')', ':645–78', '.']

>> Bigrams are: 
 [('2005', ';'), (';', '16'), ('16', '('), ('(', '3'), ('3', ')'), (')', ':645–78'), (':645–78', '.')]

>> Trigrams are: 
 [('2005', ';', '16'), (';', '16', '('), ('16', '(', '3'), ('(', '3', ')'), ('3', ')', ':645–78'), (')', ':645–78', '.')]

>> POS Tags are: 
 [('2005', 'CD'), (';', ':'), ('16', 'CD'), ('(', '('), ('3', 'CD'), (')', ')'), (':645–78', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 [':645–78']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('2005', '2005'), (';', ';'), ('16', '16'), ('(', '('), ('3', '3'), (')', ')'), (':645–78', ':645–78'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('2005', '2005'), (';', ';'), ('16', '16'), ('(', '('), ('3', '3'), (')', ')'), (':645–78', ':645–78'), ('.', '.')]

>> Lemmatization: 
 [('2005', '2005'), (';', ';'), ('16', '16'), ('(', '('), ('3', '3'), (')', ')'), (':645–78', ':645–78'), ('.', '.')]


------------------- Sentence 6 -------------------

64.

>> Tokens are: 
 ['64', '.']

>> Bigrams are: 
 [('64', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('64', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('64', '64'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('64', '64'), ('.', '.')]

>> Lemmatization: 
 [('64', '64'), ('.', '.')]


------------------- Sentence 7 -------------------

Chiang M‑C, Tsai C‑W, Yang C‑S.

>> Tokens are: 
 ['Chiang', 'M‑C', ',', 'Tsai', 'C‑W', ',', 'Yang', 'C‑S', '.']

>> Bigrams are: 
 [('Chiang', 'M‑C'), ('M‑C', ','), (',', 'Tsai'), ('Tsai', 'C‑W'), ('C‑W', ','), (',', 'Yang'), ('Yang', 'C‑S'), ('C‑S', '.')]

>> Trigrams are: 
 [('Chiang', 'M‑C', ','), ('M‑C', ',', 'Tsai'), (',', 'Tsai', 'C‑W'), ('Tsai', 'C‑W', ','), ('C‑W', ',', 'Yang'), (',', 'Yang', 'C‑S'), ('Yang', 'C‑S', '.')]

>> POS Tags are: 
 [('Chiang', 'NNP'), ('M‑C', 'NNP'), (',', ','), ('Tsai', 'NNP'), ('C‑W', 'NNP'), (',', ','), ('Yang', 'NNP'), ('C‑S', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Chiang M‑C', 'Tsai C‑W', 'Yang C‑S']

>> Named Entities are: 
 [('GPE', 'Chiang'), ('PERSON', 'Tsai C‑W'), ('PERSON', 'Yang')] 

>> Stemming using Porter Stemmer: 
 [('Chiang', 'chiang'), ('M‑C', 'm‑c'), (',', ','), ('Tsai', 'tsai'), ('C‑W', 'c‑w'), (',', ','), ('Yang', 'yang'), ('C‑S', 'c‑'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Chiang', 'chiang'), ('M‑C', 'm‑c'), (',', ','), ('Tsai', 'tsai'), ('C‑W', 'c‑w'), (',', ','), ('Yang', 'yang'), ('C‑S', 'c‑s'), ('.', '.')]

>> Lemmatization: 
 [('Chiang', 'Chiang'), ('M‑C', 'M‑C'), (',', ','), ('Tsai', 'Tsai'), ('C‑W', 'C‑W'), (',', ','), ('Yang', 'Yang'), ('C‑S', 'C‑S'), ('.', '.')]


------------------- Sentence 8 -------------------

A time‑efficient pattern reduction algorithm for k‑means clustering.

>> Tokens are: 
 ['A', 'time‑efficient', 'pattern', 'reduction', 'algorithm', 'k‑means', 'clustering', '.']

>> Bigrams are: 
 [('A', 'time‑efficient'), ('time‑efficient', 'pattern'), ('pattern', 'reduction'), ('reduction', 'algorithm'), ('algorithm', 'k‑means'), ('k‑means', 'clustering'), ('clustering', '.')]

>> Trigrams are: 
 [('A', 'time‑efficient', 'pattern'), ('time‑efficient', 'pattern', 'reduction'), ('pattern', 'reduction', 'algorithm'), ('reduction', 'algorithm', 'k‑means'), ('algorithm', 'k‑means', 'clustering'), ('k‑means', 'clustering', '.')]

>> POS Tags are: 
 [('A', 'DT'), ('time‑efficient', 'NN'), ('pattern', 'NN'), ('reduction', 'NN'), ('algorithm', 'NN'), ('k‑means', 'NNS'), ('clustering', 'VBG'), ('.', '.')]

>> Noun Phrases are: 
 ['A time‑efficient pattern reduction algorithm k‑means']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('A', 'a'), ('time‑efficient', 'time‑effici'), ('pattern', 'pattern'), ('reduction', 'reduct'), ('algorithm', 'algorithm'), ('k‑means', 'k‑mean'), ('clustering', 'cluster'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('A', 'a'), ('time‑efficient', 'time‑effici'), ('pattern', 'pattern'), ('reduction', 'reduct'), ('algorithm', 'algorithm'), ('k‑means', 'k‑mean'), ('clustering', 'cluster'), ('.', '.')]

>> Lemmatization: 
 [('A', 'A'), ('time‑efficient', 'time‑efficient'), ('pattern', 'pattern'), ('reduction', 'reduction'), ('algorithm', 'algorithm'), ('k‑means', 'k‑means'), ('clustering', 'clustering'), ('.', '.')]


------------------- Sentence 9 -------------------

Inform Sci.

>> Tokens are: 
 ['Inform', 'Sci', '.']

>> Bigrams are: 
 [('Inform', 'Sci'), ('Sci', '.')]

>> Trigrams are: 
 [('Inform', 'Sci', '.')]

>> POS Tags are: 
 [('Inform', 'NNP'), ('Sci', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Inform Sci']

>> Named Entities are: 
 [('PERSON', 'Inform'), ('ORGANIZATION', 'Sci')] 

>> Stemming using Porter Stemmer: 
 [('Inform', 'inform'), ('Sci', 'sci'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Inform', 'inform'), ('Sci', 'sci'), ('.', '.')]

>> Lemmatization: 
 [('Inform', 'Inform'), ('Sci', 'Sci'), ('.', '.')]



========================================== PARAGRAPH 461 ===========================================

2011;181(4):716–31.  65. Bradley PS, Fayyad UM. Refining initial points for k‑means clustering. In: Proceedings of the International Confer‑ 

------------------- Sentence 1 -------------------

2011;181(4):716–31.

>> Tokens are: 
 ['2011', ';', '181', '(', '4', ')', ':716–31', '.']

>> Bigrams are: 
 [('2011', ';'), (';', '181'), ('181', '('), ('(', '4'), ('4', ')'), (')', ':716–31'), (':716–31', '.')]

>> Trigrams are: 
 [('2011', ';', '181'), (';', '181', '('), ('181', '(', '4'), ('(', '4', ')'), ('4', ')', ':716–31'), (')', ':716–31', '.')]

>> POS Tags are: 
 [('2011', 'CD'), (';', ':'), ('181', 'CD'), ('(', '('), ('4', 'CD'), (')', ')'), (':716–31', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 [':716–31']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('2011', '2011'), (';', ';'), ('181', '181'), ('(', '('), ('4', '4'), (')', ')'), (':716–31', ':716–31'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('2011', '2011'), (';', ';'), ('181', '181'), ('(', '('), ('4', '4'), (')', ')'), (':716–31', ':716–31'), ('.', '.')]

>> Lemmatization: 
 [('2011', '2011'), (';', ';'), ('181', '181'), ('(', '('), ('4', '4'), (')', ')'), (':716–31', ':716–31'), ('.', '.')]


------------------- Sentence 2 -------------------

65.

>> Tokens are: 
 ['65', '.']

>> Bigrams are: 
 [('65', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('65', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('65', '65'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('65', '65'), ('.', '.')]

>> Lemmatization: 
 [('65', '65'), ('.', '.')]


------------------- Sentence 3 -------------------

Bradley PS, Fayyad UM.

>> Tokens are: 
 ['Bradley', 'PS', ',', 'Fayyad', 'UM', '.']

>> Bigrams are: 
 [('Bradley', 'PS'), ('PS', ','), (',', 'Fayyad'), ('Fayyad', 'UM'), ('UM', '.')]

>> Trigrams are: 
 [('Bradley', 'PS', ','), ('PS', ',', 'Fayyad'), (',', 'Fayyad', 'UM'), ('Fayyad', 'UM', '.')]

>> POS Tags are: 
 [('Bradley', 'NNP'), ('PS', 'NNP'), (',', ','), ('Fayyad', 'NNP'), ('UM', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Bradley PS', 'Fayyad UM']

>> Named Entities are: 
 [('PERSON', 'Bradley'), ('GPE', 'PS'), ('PERSON', 'Fayyad UM')] 

>> Stemming using Porter Stemmer: 
 [('Bradley', 'bradley'), ('PS', 'ps'), (',', ','), ('Fayyad', 'fayyad'), ('UM', 'um'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Bradley', 'bradley'), ('PS', 'ps'), (',', ','), ('Fayyad', 'fayyad'), ('UM', 'um'), ('.', '.')]

>> Lemmatization: 
 [('Bradley', 'Bradley'), ('PS', 'PS'), (',', ','), ('Fayyad', 'Fayyad'), ('UM', 'UM'), ('.', '.')]


------------------- Sentence 4 -------------------

Refining initial points for k‑means clustering.

>> Tokens are: 
 ['Refining', 'initial', 'points', 'k‑means', 'clustering', '.']

>> Bigrams are: 
 [('Refining', 'initial'), ('initial', 'points'), ('points', 'k‑means'), ('k‑means', 'clustering'), ('clustering', '.')]

>> Trigrams are: 
 [('Refining', 'initial', 'points'), ('initial', 'points', 'k‑means'), ('points', 'k‑means', 'clustering'), ('k‑means', 'clustering', '.')]

>> POS Tags are: 
 [('Refining', 'VBG'), ('initial', 'JJ'), ('points', 'NNS'), ('k‑means', 'VBZ'), ('clustering', 'VBG'), ('.', '.')]

>> Noun Phrases are: 
 ['initial points']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Refining', 'refin'), ('initial', 'initi'), ('points', 'point'), ('k‑means', 'k‑mean'), ('clustering', 'cluster'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Refining', 'refin'), ('initial', 'initi'), ('points', 'point'), ('k‑means', 'k‑mean'), ('clustering', 'cluster'), ('.', '.')]

>> Lemmatization: 
 [('Refining', 'Refining'), ('initial', 'initial'), ('points', 'point'), ('k‑means', 'k‑means'), ('clustering', 'clustering'), ('.', '.')]


------------------- Sentence 5 -------------------

In: Proceedings of the International Confer‑

>> Tokens are: 
 ['In', ':', 'Proceedings', 'International', 'Confer‑']

>> Bigrams are: 
 [('In', ':'), (':', 'Proceedings'), ('Proceedings', 'International'), ('International', 'Confer‑')]

>> Trigrams are: 
 [('In', ':', 'Proceedings'), (':', 'Proceedings', 'International'), ('Proceedings', 'International', 'Confer‑')]

>> POS Tags are: 
 [('In', 'IN'), (':', ':'), ('Proceedings', 'NNS'), ('International', 'NNP'), ('Confer‑', 'NNP')]

>> Noun Phrases are: 
 ['Proceedings International Confer‑']

>> Named Entities are: 
 [('ORGANIZATION', 'International')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), (':', ':'), ('Proceedings', 'proceed'), ('International', 'intern'), ('Confer‑', 'confer‑')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), (':', ':'), ('Proceedings', 'proceed'), ('International', 'intern'), ('Confer‑', 'confer‑')]

>> Lemmatization: 
 [('In', 'In'), (':', ':'), ('Proceedings', 'Proceedings'), ('International', 'International'), ('Confer‑', 'Confer‑')]



========================================== PARAGRAPH 462 ===========================================

ence on Machine Learning, 1998. pp 91–99.  66. Laskov P, Gehl C, Krüger S, Müller K‑R. Incremental support vector learning: analysis, implementation and applica‑ 

------------------- Sentence 1 -------------------

ence on Machine Learning, 1998. pp 91–99.

>> Tokens are: 
 ['ence', 'Machine', 'Learning', ',', '1998.', 'pp', '91–99', '.']

>> Bigrams are: 
 [('ence', 'Machine'), ('Machine', 'Learning'), ('Learning', ','), (',', '1998.'), ('1998.', 'pp'), ('pp', '91–99'), ('91–99', '.')]

>> Trigrams are: 
 [('ence', 'Machine', 'Learning'), ('Machine', 'Learning', ','), ('Learning', ',', '1998.'), (',', '1998.', 'pp'), ('1998.', 'pp', '91–99'), ('pp', '91–99', '.')]

>> POS Tags are: 
 [('ence', 'NN'), ('Machine', 'NNP'), ('Learning', 'NNP'), (',', ','), ('1998.', 'CD'), ('pp', 'NN'), ('91–99', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['ence Machine Learning', 'pp']

>> Named Entities are: 
 [('PERSON', 'Machine Learning')] 

>> Stemming using Porter Stemmer: 
 [('ence', 'enc'), ('Machine', 'machin'), ('Learning', 'learn'), (',', ','), ('1998.', '1998.'), ('pp', 'pp'), ('91–99', '91–99'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('ence', 'enc'), ('Machine', 'machin'), ('Learning', 'learn'), (',', ','), ('1998.', '1998.'), ('pp', 'pp'), ('91–99', '91–99'), ('.', '.')]

>> Lemmatization: 
 [('ence', 'ence'), ('Machine', 'Machine'), ('Learning', 'Learning'), (',', ','), ('1998.', '1998.'), ('pp', 'pp'), ('91–99', '91–99'), ('.', '.')]


------------------- Sentence 2 -------------------

66.

>> Tokens are: 
 ['66', '.']

>> Bigrams are: 
 [('66', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('66', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('66', '66'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('66', '66'), ('.', '.')]

>> Lemmatization: 
 [('66', '66'), ('.', '.')]


------------------- Sentence 3 -------------------

Laskov P, Gehl C, Krüger S, Müller K‑R.

>> Tokens are: 
 ['Laskov', 'P', ',', 'Gehl', 'C', ',', 'Krüger', 'S', ',', 'Müller', 'K‑R', '.']

>> Bigrams are: 
 [('Laskov', 'P'), ('P', ','), (',', 'Gehl'), ('Gehl', 'C'), ('C', ','), (',', 'Krüger'), ('Krüger', 'S'), ('S', ','), (',', 'Müller'), ('Müller', 'K‑R'), ('K‑R', '.')]

>> Trigrams are: 
 [('Laskov', 'P', ','), ('P', ',', 'Gehl'), (',', 'Gehl', 'C'), ('Gehl', 'C', ','), ('C', ',', 'Krüger'), (',', 'Krüger', 'S'), ('Krüger', 'S', ','), ('S', ',', 'Müller'), (',', 'Müller', 'K‑R'), ('Müller', 'K‑R', '.')]

>> POS Tags are: 
 [('Laskov', 'NNP'), ('P', 'NNP'), (',', ','), ('Gehl', 'NNP'), ('C', 'NNP'), (',', ','), ('Krüger', 'NNP'), ('S', 'NNP'), (',', ','), ('Müller', 'NNP'), ('K‑R', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Laskov P', 'Gehl C', 'Krüger S', 'Müller K‑R']

>> Named Entities are: 
 [('PERSON', 'Laskov'), ('ORGANIZATION', 'P'), ('PERSON', 'Gehl C'), ('PERSON', 'Krüger S'), ('PERSON', 'Müller')] 

>> Stemming using Porter Stemmer: 
 [('Laskov', 'laskov'), ('P', 'p'), (',', ','), ('Gehl', 'gehl'), ('C', 'c'), (',', ','), ('Krüger', 'krüger'), ('S', 's'), (',', ','), ('Müller', 'müller'), ('K‑R', 'k‑r'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Laskov', 'laskov'), ('P', 'p'), (',', ','), ('Gehl', 'gehl'), ('C', 'c'), (',', ','), ('Krüger', 'krüger'), ('S', 's'), (',', ','), ('Müller', 'müller'), ('K‑R', 'k‑r'), ('.', '.')]

>> Lemmatization: 
 [('Laskov', 'Laskov'), ('P', 'P'), (',', ','), ('Gehl', 'Gehl'), ('C', 'C'), (',', ','), ('Krüger', 'Krüger'), ('S', 'S'), (',', ','), ('Müller', 'Müller'), ('K‑R', 'K‑R'), ('.', '.')]


------------------- Sentence 4 -------------------

Incremental support vector learning: analysis, implementation and applica‑

>> Tokens are: 
 ['Incremental', 'support', 'vector', 'learning', ':', 'analysis', ',', 'implementation', 'applica‑']

>> Bigrams are: 
 [('Incremental', 'support'), ('support', 'vector'), ('vector', 'learning'), ('learning', ':'), (':', 'analysis'), ('analysis', ','), (',', 'implementation'), ('implementation', 'applica‑')]

>> Trigrams are: 
 [('Incremental', 'support', 'vector'), ('support', 'vector', 'learning'), ('vector', 'learning', ':'), ('learning', ':', 'analysis'), (':', 'analysis', ','), ('analysis', ',', 'implementation'), (',', 'implementation', 'applica‑')]

>> POS Tags are: 
 [('Incremental', 'JJ'), ('support', 'NN'), ('vector', 'NN'), ('learning', 'NN'), (':', ':'), ('analysis', 'NN'), (',', ','), ('implementation', 'NN'), ('applica‑', 'NN')]

>> Noun Phrases are: 
 ['Incremental support vector learning', 'analysis', 'implementation applica‑']

>> Named Entities are: 
 [('GPE', 'Incremental')] 

>> Stemming using Porter Stemmer: 
 [('Incremental', 'increment'), ('support', 'support'), ('vector', 'vector'), ('learning', 'learn'), (':', ':'), ('analysis', 'analysi'), (',', ','), ('implementation', 'implement'), ('applica‑', 'applica‑')]

>> Stemming using Snowball Stemmer: 
 [('Incremental', 'increment'), ('support', 'support'), ('vector', 'vector'), ('learning', 'learn'), (':', ':'), ('analysis', 'analysi'), (',', ','), ('implementation', 'implement'), ('applica‑', 'applica‑')]

>> Lemmatization: 
 [('Incremental', 'Incremental'), ('support', 'support'), ('vector', 'vector'), ('learning', 'learning'), (':', ':'), ('analysis', 'analysis'), (',', ','), ('implementation', 'implementation'), ('applica‑', 'applica‑')]



========================================== PARAGRAPH 463 ===========================================

tions. J Mach Learn Res. 2006;7:1909–36.  67. Russom P. Big data analytics. TDWI: Tech. Rep ; 2011.  68. Ma C, Zhang HH, Wang X. Machine learning for big data analytics in plants. Trends Plant Sci. 2014;19(12):798–808.  69. Boyd D, Crawford K. Critical questions for big data. Inform Commun Soc. 2012;15(5):662–79.  70. Katal A, Wazid M, Goudar R. Big data: issues, challenges, tools and good practices. In: Proceedings of the Interna‑ 

------------------- Sentence 1 -------------------

tions.

>> Tokens are: 
 ['tions', '.']

>> Bigrams are: 
 [('tions', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('tions', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['tions']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('tions', 'tion'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('tions', 'tion'), ('.', '.')]

>> Lemmatization: 
 [('tions', 'tions'), ('.', '.')]


------------------- Sentence 2 -------------------

J Mach Learn Res.

>> Tokens are: 
 ['J', 'Mach', 'Learn', 'Res', '.']

>> Bigrams are: 
 [('J', 'Mach'), ('Mach', 'Learn'), ('Learn', 'Res'), ('Res', '.')]

>> Trigrams are: 
 [('J', 'Mach', 'Learn'), ('Mach', 'Learn', 'Res'), ('Learn', 'Res', '.')]

>> POS Tags are: 
 [('J', 'NNP'), ('Mach', 'NNP'), ('Learn', 'NNP'), ('Res', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['J Mach Learn Res']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('J', 'j'), ('Mach', 'mach'), ('Learn', 'learn'), ('Res', 're'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('J', 'j'), ('Mach', 'mach'), ('Learn', 'learn'), ('Res', 'res'), ('.', '.')]

>> Lemmatization: 
 [('J', 'J'), ('Mach', 'Mach'), ('Learn', 'Learn'), ('Res', 'Res'), ('.', '.')]


------------------- Sentence 3 -------------------

2006;7:1909–36.

>> Tokens are: 
 ['2006', ';', '7:1909–36', '.']

>> Bigrams are: 
 [('2006', ';'), (';', '7:1909–36'), ('7:1909–36', '.')]

>> Trigrams are: 
 [('2006', ';', '7:1909–36'), (';', '7:1909–36', '.')]

>> POS Tags are: 
 [('2006', 'CD'), (';', ':'), ('7:1909–36', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('2006', '2006'), (';', ';'), ('7:1909–36', '7:1909–36'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('2006', '2006'), (';', ';'), ('7:1909–36', '7:1909–36'), ('.', '.')]

>> Lemmatization: 
 [('2006', '2006'), (';', ';'), ('7:1909–36', '7:1909–36'), ('.', '.')]


------------------- Sentence 4 -------------------

67.

>> Tokens are: 
 ['67', '.']

>> Bigrams are: 
 [('67', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('67', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('67', '67'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('67', '67'), ('.', '.')]

>> Lemmatization: 
 [('67', '67'), ('.', '.')]


------------------- Sentence 5 -------------------

Russom P. Big data analytics.

>> Tokens are: 
 ['Russom', 'P.', 'Big', 'data', 'analytics', '.']

>> Bigrams are: 
 [('Russom', 'P.'), ('P.', 'Big'), ('Big', 'data'), ('data', 'analytics'), ('analytics', '.')]

>> Trigrams are: 
 [('Russom', 'P.', 'Big'), ('P.', 'Big', 'data'), ('Big', 'data', 'analytics'), ('data', 'analytics', '.')]

>> POS Tags are: 
 [('Russom', 'NNP'), ('P.', 'NNP'), ('Big', 'NNP'), ('data', 'NN'), ('analytics', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['Russom P. Big data analytics']

>> Named Entities are: 
 [('GPE', 'Russom')] 

>> Stemming using Porter Stemmer: 
 [('Russom', 'russom'), ('P.', 'p.'), ('Big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Russom', 'russom'), ('P.', 'p.'), ('Big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('.', '.')]

>> Lemmatization: 
 [('Russom', 'Russom'), ('P.', 'P.'), ('Big', 'Big'), ('data', 'data'), ('analytics', 'analytics'), ('.', '.')]


------------------- Sentence 6 -------------------

TDWI: Tech.

>> Tokens are: 
 ['TDWI', ':', 'Tech', '.']

>> Bigrams are: 
 [('TDWI', ':'), (':', 'Tech'), ('Tech', '.')]

>> Trigrams are: 
 [('TDWI', ':', 'Tech'), (':', 'Tech', '.')]

>> POS Tags are: 
 [('TDWI', 'NN'), (':', ':'), ('Tech', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['TDWI', 'Tech']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('TDWI', 'tdwi'), (':', ':'), ('Tech', 'tech'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('TDWI', 'tdwi'), (':', ':'), ('Tech', 'tech'), ('.', '.')]

>> Lemmatization: 
 [('TDWI', 'TDWI'), (':', ':'), ('Tech', 'Tech'), ('.', '.')]


------------------- Sentence 7 -------------------

Rep ; 2011.

>> Tokens are: 
 ['Rep', ';', '2011', '.']

>> Bigrams are: 
 [('Rep', ';'), (';', '2011'), ('2011', '.')]

>> Trigrams are: 
 [('Rep', ';', '2011'), (';', '2011', '.')]

>> POS Tags are: 
 [('Rep', 'NNP'), (';', ':'), ('2011', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Rep']

>> Named Entities are: 
 [('GPE', 'Rep')] 

>> Stemming using Porter Stemmer: 
 [('Rep', 'rep'), (';', ';'), ('2011', '2011'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Rep', 'rep'), (';', ';'), ('2011', '2011'), ('.', '.')]

>> Lemmatization: 
 [('Rep', 'Rep'), (';', ';'), ('2011', '2011'), ('.', '.')]


------------------- Sentence 8 -------------------

68.

>> Tokens are: 
 ['68', '.']

>> Bigrams are: 
 [('68', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('68', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('68', '68'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('68', '68'), ('.', '.')]

>> Lemmatization: 
 [('68', '68'), ('.', '.')]


------------------- Sentence 9 -------------------

Ma C, Zhang HH, Wang X.

>> Tokens are: 
 ['Ma', 'C', ',', 'Zhang', 'HH', ',', 'Wang', 'X', '.']

>> Bigrams are: 
 [('Ma', 'C'), ('C', ','), (',', 'Zhang'), ('Zhang', 'HH'), ('HH', ','), (',', 'Wang'), ('Wang', 'X'), ('X', '.')]

>> Trigrams are: 
 [('Ma', 'C', ','), ('C', ',', 'Zhang'), (',', 'Zhang', 'HH'), ('Zhang', 'HH', ','), ('HH', ',', 'Wang'), (',', 'Wang', 'X'), ('Wang', 'X', '.')]

>> POS Tags are: 
 [('Ma', 'NNP'), ('C', 'NNP'), (',', ','), ('Zhang', 'NNP'), ('HH', 'NNP'), (',', ','), ('Wang', 'NNP'), ('X', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Ma C', 'Zhang HH', 'Wang X']

>> Named Entities are: 
 [('PERSON', 'Zhang HH'), ('PERSON', 'Wang X')] 

>> Stemming using Porter Stemmer: 
 [('Ma', 'ma'), ('C', 'c'), (',', ','), ('Zhang', 'zhang'), ('HH', 'hh'), (',', ','), ('Wang', 'wang'), ('X', 'x'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Ma', 'ma'), ('C', 'c'), (',', ','), ('Zhang', 'zhang'), ('HH', 'hh'), (',', ','), ('Wang', 'wang'), ('X', 'x'), ('.', '.')]

>> Lemmatization: 
 [('Ma', 'Ma'), ('C', 'C'), (',', ','), ('Zhang', 'Zhang'), ('HH', 'HH'), (',', ','), ('Wang', 'Wang'), ('X', 'X'), ('.', '.')]


------------------- Sentence 10 -------------------

Machine learning for big data analytics in plants.

>> Tokens are: 
 ['Machine', 'learning', 'big', 'data', 'analytics', 'plants', '.']

>> Bigrams are: 
 [('Machine', 'learning'), ('learning', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', 'plants'), ('plants', '.')]

>> Trigrams are: 
 [('Machine', 'learning', 'big'), ('learning', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', 'plants'), ('analytics', 'plants', '.')]

>> POS Tags are: 
 [('Machine', 'NN'), ('learning', 'VBG'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('plants', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['Machine', 'big data analytics plants']

>> Named Entities are: 
 [('GPE', 'Machine')] 

>> Stemming using Porter Stemmer: 
 [('Machine', 'machin'), ('learning', 'learn'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('plants', 'plant'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Machine', 'machin'), ('learning', 'learn'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('plants', 'plant'), ('.', '.')]

>> Lemmatization: 
 [('Machine', 'Machine'), ('learning', 'learning'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('plants', 'plant'), ('.', '.')]


------------------- Sentence 11 -------------------

Trends Plant Sci.

>> Tokens are: 
 ['Trends', 'Plant', 'Sci', '.']

>> Bigrams are: 
 [('Trends', 'Plant'), ('Plant', 'Sci'), ('Sci', '.')]

>> Trigrams are: 
 [('Trends', 'Plant', 'Sci'), ('Plant', 'Sci', '.')]

>> POS Tags are: 
 [('Trends', 'NNS'), ('Plant', 'NNP'), ('Sci', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Trends Plant Sci']

>> Named Entities are: 
 [('PERSON', 'Plant Sci')] 

>> Stemming using Porter Stemmer: 
 [('Trends', 'trend'), ('Plant', 'plant'), ('Sci', 'sci'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Trends', 'trend'), ('Plant', 'plant'), ('Sci', 'sci'), ('.', '.')]

>> Lemmatization: 
 [('Trends', 'Trends'), ('Plant', 'Plant'), ('Sci', 'Sci'), ('.', '.')]


------------------- Sentence 12 -------------------

2014;19(12):798–808.

>> Tokens are: 
 ['2014', ';', '19', '(', '12', ')', ':798–808', '.']

>> Bigrams are: 
 [('2014', ';'), (';', '19'), ('19', '('), ('(', '12'), ('12', ')'), (')', ':798–808'), (':798–808', '.')]

>> Trigrams are: 
 [('2014', ';', '19'), (';', '19', '('), ('19', '(', '12'), ('(', '12', ')'), ('12', ')', ':798–808'), (')', ':798–808', '.')]

>> POS Tags are: 
 [('2014', 'CD'), (';', ':'), ('19', 'CD'), ('(', '('), ('12', 'CD'), (')', ')'), (':798–808', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 [':798–808']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('2014', '2014'), (';', ';'), ('19', '19'), ('(', '('), ('12', '12'), (')', ')'), (':798–808', ':798–808'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('2014', '2014'), (';', ';'), ('19', '19'), ('(', '('), ('12', '12'), (')', ')'), (':798–808', ':798–808'), ('.', '.')]

>> Lemmatization: 
 [('2014', '2014'), (';', ';'), ('19', '19'), ('(', '('), ('12', '12'), (')', ')'), (':798–808', ':798–808'), ('.', '.')]


------------------- Sentence 13 -------------------

69.

>> Tokens are: 
 ['69', '.']

>> Bigrams are: 
 [('69', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('69', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('69', '69'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('69', '69'), ('.', '.')]

>> Lemmatization: 
 [('69', '69'), ('.', '.')]


------------------- Sentence 14 -------------------

Boyd D, Crawford K. Critical questions for big data.

>> Tokens are: 
 ['Boyd', 'D', ',', 'Crawford', 'K.', 'Critical', 'questions', 'big', 'data', '.']

>> Bigrams are: 
 [('Boyd', 'D'), ('D', ','), (',', 'Crawford'), ('Crawford', 'K.'), ('K.', 'Critical'), ('Critical', 'questions'), ('questions', 'big'), ('big', 'data'), ('data', '.')]

>> Trigrams are: 
 [('Boyd', 'D', ','), ('D', ',', 'Crawford'), (',', 'Crawford', 'K.'), ('Crawford', 'K.', 'Critical'), ('K.', 'Critical', 'questions'), ('Critical', 'questions', 'big'), ('questions', 'big', 'data'), ('big', 'data', '.')]

>> POS Tags are: 
 [('Boyd', 'NNP'), ('D', 'NNP'), (',', ','), ('Crawford', 'NNP'), ('K.', 'NNP'), ('Critical', 'NNP'), ('questions', 'NNS'), ('big', 'JJ'), ('data', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['Boyd D', 'Crawford K. Critical questions', 'big data']

>> Named Entities are: 
 [('PERSON', 'Boyd'), ('ORGANIZATION', 'D'), ('PERSON', 'Crawford K. Critical')] 

>> Stemming using Porter Stemmer: 
 [('Boyd', 'boyd'), ('D', 'd'), (',', ','), ('Crawford', 'crawford'), ('K.', 'k.'), ('Critical', 'critic'), ('questions', 'question'), ('big', 'big'), ('data', 'data'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Boyd', 'boyd'), ('D', 'd'), (',', ','), ('Crawford', 'crawford'), ('K.', 'k.'), ('Critical', 'critic'), ('questions', 'question'), ('big', 'big'), ('data', 'data'), ('.', '.')]

>> Lemmatization: 
 [('Boyd', 'Boyd'), ('D', 'D'), (',', ','), ('Crawford', 'Crawford'), ('K.', 'K.'), ('Critical', 'Critical'), ('questions', 'question'), ('big', 'big'), ('data', 'data'), ('.', '.')]


------------------- Sentence 15 -------------------

Inform Commun Soc.

>> Tokens are: 
 ['Inform', 'Commun', 'Soc', '.']

>> Bigrams are: 
 [('Inform', 'Commun'), ('Commun', 'Soc'), ('Soc', '.')]

>> Trigrams are: 
 [('Inform', 'Commun', 'Soc'), ('Commun', 'Soc', '.')]

>> POS Tags are: 
 [('Inform', 'NNP'), ('Commun', 'NNP'), ('Soc', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Inform Commun Soc']

>> Named Entities are: 
 [('PERSON', 'Inform'), ('ORGANIZATION', 'Commun Soc')] 

>> Stemming using Porter Stemmer: 
 [('Inform', 'inform'), ('Commun', 'commun'), ('Soc', 'soc'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Inform', 'inform'), ('Commun', 'commun'), ('Soc', 'soc'), ('.', '.')]

>> Lemmatization: 
 [('Inform', 'Inform'), ('Commun', 'Commun'), ('Soc', 'Soc'), ('.', '.')]


------------------- Sentence 16 -------------------

2012;15(5):662–79.

>> Tokens are: 
 ['2012', ';', '15', '(', '5', ')', ':662–79', '.']

>> Bigrams are: 
 [('2012', ';'), (';', '15'), ('15', '('), ('(', '5'), ('5', ')'), (')', ':662–79'), (':662–79', '.')]

>> Trigrams are: 
 [('2012', ';', '15'), (';', '15', '('), ('15', '(', '5'), ('(', '5', ')'), ('5', ')', ':662–79'), (')', ':662–79', '.')]

>> POS Tags are: 
 [('2012', 'CD'), (';', ':'), ('15', 'CD'), ('(', '('), ('5', 'CD'), (')', ')'), (':662–79', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 [':662–79']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('2012', '2012'), (';', ';'), ('15', '15'), ('(', '('), ('5', '5'), (')', ')'), (':662–79', ':662–79'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('2012', '2012'), (';', ';'), ('15', '15'), ('(', '('), ('5', '5'), (')', ')'), (':662–79', ':662–79'), ('.', '.')]

>> Lemmatization: 
 [('2012', '2012'), (';', ';'), ('15', '15'), ('(', '('), ('5', '5'), (')', ')'), (':662–79', ':662–79'), ('.', '.')]


------------------- Sentence 17 -------------------

70.

>> Tokens are: 
 ['70', '.']

>> Bigrams are: 
 [('70', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('70', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('70', '70'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('70', '70'), ('.', '.')]

>> Lemmatization: 
 [('70', '70'), ('.', '.')]


------------------- Sentence 18 -------------------

Katal A, Wazid M, Goudar R. Big data: issues, challenges, tools and good practices.

>> Tokens are: 
 ['Katal', 'A', ',', 'Wazid', 'M', ',', 'Goudar', 'R.', 'Big', 'data', ':', 'issues', ',', 'challenges', ',', 'tools', 'good', 'practices', '.']

>> Bigrams are: 
 [('Katal', 'A'), ('A', ','), (',', 'Wazid'), ('Wazid', 'M'), ('M', ','), (',', 'Goudar'), ('Goudar', 'R.'), ('R.', 'Big'), ('Big', 'data'), ('data', ':'), (':', 'issues'), ('issues', ','), (',', 'challenges'), ('challenges', ','), (',', 'tools'), ('tools', 'good'), ('good', 'practices'), ('practices', '.')]

>> Trigrams are: 
 [('Katal', 'A', ','), ('A', ',', 'Wazid'), (',', 'Wazid', 'M'), ('Wazid', 'M', ','), ('M', ',', 'Goudar'), (',', 'Goudar', 'R.'), ('Goudar', 'R.', 'Big'), ('R.', 'Big', 'data'), ('Big', 'data', ':'), ('data', ':', 'issues'), (':', 'issues', ','), ('issues', ',', 'challenges'), (',', 'challenges', ','), ('challenges', ',', 'tools'), (',', 'tools', 'good'), ('tools', 'good', 'practices'), ('good', 'practices', '.')]

>> POS Tags are: 
 [('Katal', 'NNP'), ('A', 'NNP'), (',', ','), ('Wazid', 'NNP'), ('M', 'NNP'), (',', ','), ('Goudar', 'NNP'), ('R.', 'NNP'), ('Big', 'NNP'), ('data', 'NNS'), (':', ':'), ('issues', 'NNS'), (',', ','), ('challenges', 'NNS'), (',', ','), ('tools', 'NNS'), ('good', 'JJ'), ('practices', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['Katal A', 'Wazid M', 'Goudar R. Big data', 'issues', 'challenges', 'tools', 'good practices']

>> Named Entities are: 
 [('PERSON', 'Katal'), ('PERSON', 'Wazid M'), ('PERSON', 'Goudar R.')] 

>> Stemming using Porter Stemmer: 
 [('Katal', 'katal'), ('A', 'a'), (',', ','), ('Wazid', 'wazid'), ('M', 'm'), (',', ','), ('Goudar', 'goudar'), ('R.', 'r.'), ('Big', 'big'), ('data', 'data'), (':', ':'), ('issues', 'issu'), (',', ','), ('challenges', 'challeng'), (',', ','), ('tools', 'tool'), ('good', 'good'), ('practices', 'practic'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Katal', 'katal'), ('A', 'a'), (',', ','), ('Wazid', 'wazid'), ('M', 'm'), (',', ','), ('Goudar', 'goudar'), ('R.', 'r.'), ('Big', 'big'), ('data', 'data'), (':', ':'), ('issues', 'issu'), (',', ','), ('challenges', 'challeng'), (',', ','), ('tools', 'tool'), ('good', 'good'), ('practices', 'practic'), ('.', '.')]

>> Lemmatization: 
 [('Katal', 'Katal'), ('A', 'A'), (',', ','), ('Wazid', 'Wazid'), ('M', 'M'), (',', ','), ('Goudar', 'Goudar'), ('R.', 'R.'), ('Big', 'Big'), ('data', 'data'), (':', ':'), ('issues', 'issue'), (',', ','), ('challenges', 'challenge'), (',', ','), ('tools', 'tool'), ('good', 'good'), ('practices', 'practice'), ('.', '.')]


------------------- Sentence 19 -------------------

In: Proceedings of the Interna‑

>> Tokens are: 
 ['In', ':', 'Proceedings', 'Interna‑']

>> Bigrams are: 
 [('In', ':'), (':', 'Proceedings'), ('Proceedings', 'Interna‑')]

>> Trigrams are: 
 [('In', ':', 'Proceedings'), (':', 'Proceedings', 'Interna‑')]

>> POS Tags are: 
 [('In', 'IN'), (':', ':'), ('Proceedings', 'NNS'), ('Interna‑', 'NNP')]

>> Noun Phrases are: 
 ['Proceedings Interna‑']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), (':', ':'), ('Proceedings', 'proceed'), ('Interna‑', 'interna‑')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), (':', ':'), ('Proceedings', 'proceed'), ('Interna‑', 'interna‑')]

>> Lemmatization: 
 [('In', 'In'), (':', ':'), ('Proceedings', 'Proceedings'), ('Interna‑', 'Interna‑')]



========================================== PARAGRAPH 464 ===========================================

tional Conference on Contemporary Computing, 2013. pp 404–409.  71. Baraniuk RG. More is less: signal processing and the data deluge. Science. 2011;331(6018):717–9.  72. Lee J, Hong S, Lee JH. An efficient prediction for heavy rain from big weather data using genetic algorithm. In:  

------------------- Sentence 1 -------------------

tional Conference on Contemporary Computing, 2013. pp 404–409.

>> Tokens are: 
 ['tional', 'Conference', 'Contemporary', 'Computing', ',', '2013.', 'pp', '404–409', '.']

>> Bigrams are: 
 [('tional', 'Conference'), ('Conference', 'Contemporary'), ('Contemporary', 'Computing'), ('Computing', ','), (',', '2013.'), ('2013.', 'pp'), ('pp', '404–409'), ('404–409', '.')]

>> Trigrams are: 
 [('tional', 'Conference', 'Contemporary'), ('Conference', 'Contemporary', 'Computing'), ('Contemporary', 'Computing', ','), ('Computing', ',', '2013.'), (',', '2013.', 'pp'), ('2013.', 'pp', '404–409'), ('pp', '404–409', '.')]

>> POS Tags are: 
 [('tional', 'JJ'), ('Conference', 'NNP'), ('Contemporary', 'NNP'), ('Computing', 'NNP'), (',', ','), ('2013.', 'CD'), ('pp', 'NN'), ('404–409', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['tional Conference Contemporary Computing', 'pp']

>> Named Entities are: 
 [('ORGANIZATION', 'Conference')] 

>> Stemming using Porter Stemmer: 
 [('tional', 'tional'), ('Conference', 'confer'), ('Contemporary', 'contemporari'), ('Computing', 'comput'), (',', ','), ('2013.', '2013.'), ('pp', 'pp'), ('404–409', '404–409'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('tional', 'tional'), ('Conference', 'confer'), ('Contemporary', 'contemporari'), ('Computing', 'comput'), (',', ','), ('2013.', '2013.'), ('pp', 'pp'), ('404–409', '404–409'), ('.', '.')]

>> Lemmatization: 
 [('tional', 'tional'), ('Conference', 'Conference'), ('Contemporary', 'Contemporary'), ('Computing', 'Computing'), (',', ','), ('2013.', '2013.'), ('pp', 'pp'), ('404–409', '404–409'), ('.', '.')]


------------------- Sentence 2 -------------------

71.

>> Tokens are: 
 ['71', '.']

>> Bigrams are: 
 [('71', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('71', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('71', '71'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('71', '71'), ('.', '.')]

>> Lemmatization: 
 [('71', '71'), ('.', '.')]


------------------- Sentence 3 -------------------

Baraniuk RG.

>> Tokens are: 
 ['Baraniuk', 'RG', '.']

>> Bigrams are: 
 [('Baraniuk', 'RG'), ('RG', '.')]

>> Trigrams are: 
 [('Baraniuk', 'RG', '.')]

>> POS Tags are: 
 [('Baraniuk', 'NNP'), ('RG', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Baraniuk RG']

>> Named Entities are: 
 [('PERSON', 'Baraniuk')] 

>> Stemming using Porter Stemmer: 
 [('Baraniuk', 'baraniuk'), ('RG', 'rg'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Baraniuk', 'baraniuk'), ('RG', 'rg'), ('.', '.')]

>> Lemmatization: 
 [('Baraniuk', 'Baraniuk'), ('RG', 'RG'), ('.', '.')]


------------------- Sentence 4 -------------------

More is less: signal processing and the data deluge.

>> Tokens are: 
 ['More', 'less', ':', 'signal', 'processing', 'data', 'deluge', '.']

>> Bigrams are: 
 [('More', 'less'), ('less', ':'), (':', 'signal'), ('signal', 'processing'), ('processing', 'data'), ('data', 'deluge'), ('deluge', '.')]

>> Trigrams are: 
 [('More', 'less', ':'), ('less', ':', 'signal'), (':', 'signal', 'processing'), ('signal', 'processing', 'data'), ('processing', 'data', 'deluge'), ('data', 'deluge', '.')]

>> POS Tags are: 
 [('More', 'JJR'), ('less', 'NN'), (':', ':'), ('signal', 'JJ'), ('processing', 'NN'), ('data', 'NNS'), ('deluge', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['less', 'signal processing data deluge']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('More', 'more'), ('less', 'less'), (':', ':'), ('signal', 'signal'), ('processing', 'process'), ('data', 'data'), ('deluge', 'delug'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('More', 'more'), ('less', 'less'), (':', ':'), ('signal', 'signal'), ('processing', 'process'), ('data', 'data'), ('deluge', 'delug'), ('.', '.')]

>> Lemmatization: 
 [('More', 'More'), ('less', 'le'), (':', ':'), ('signal', 'signal'), ('processing', 'processing'), ('data', 'data'), ('deluge', 'deluge'), ('.', '.')]


------------------- Sentence 5 -------------------

Science.

>> Tokens are: 
 ['Science', '.']

>> Bigrams are: 
 [('Science', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Science', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Science']

>> Named Entities are: 
 [('GPE', 'Science')] 

>> Stemming using Porter Stemmer: 
 [('Science', 'scienc'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Science', 'scienc'), ('.', '.')]

>> Lemmatization: 
 [('Science', 'Science'), ('.', '.')]


------------------- Sentence 6 -------------------

2011;331(6018):717–9.

>> Tokens are: 
 ['2011', ';', '331', '(', '6018', ')', ':717–9', '.']

>> Bigrams are: 
 [('2011', ';'), (';', '331'), ('331', '('), ('(', '6018'), ('6018', ')'), (')', ':717–9'), (':717–9', '.')]

>> Trigrams are: 
 [('2011', ';', '331'), (';', '331', '('), ('331', '(', '6018'), ('(', '6018', ')'), ('6018', ')', ':717–9'), (')', ':717–9', '.')]

>> POS Tags are: 
 [('2011', 'CD'), (';', ':'), ('331', 'CD'), ('(', '('), ('6018', 'CD'), (')', ')'), (':717–9', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 [':717–9']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('2011', '2011'), (';', ';'), ('331', '331'), ('(', '('), ('6018', '6018'), (')', ')'), (':717–9', ':717–9'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('2011', '2011'), (';', ';'), ('331', '331'), ('(', '('), ('6018', '6018'), (')', ')'), (':717–9', ':717–9'), ('.', '.')]

>> Lemmatization: 
 [('2011', '2011'), (';', ';'), ('331', '331'), ('(', '('), ('6018', '6018'), (')', ')'), (':717–9', ':717–9'), ('.', '.')]


------------------- Sentence 7 -------------------

72.

>> Tokens are: 
 ['72', '.']

>> Bigrams are: 
 [('72', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('72', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('72', '72'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('72', '72'), ('.', '.')]

>> Lemmatization: 
 [('72', '72'), ('.', '.')]


------------------- Sentence 8 -------------------

Lee J, Hong S, Lee JH.

>> Tokens are: 
 ['Lee', 'J', ',', 'Hong', 'S', ',', 'Lee', 'JH', '.']

>> Bigrams are: 
 [('Lee', 'J'), ('J', ','), (',', 'Hong'), ('Hong', 'S'), ('S', ','), (',', 'Lee'), ('Lee', 'JH'), ('JH', '.')]

>> Trigrams are: 
 [('Lee', 'J', ','), ('J', ',', 'Hong'), (',', 'Hong', 'S'), ('Hong', 'S', ','), ('S', ',', 'Lee'), (',', 'Lee', 'JH'), ('Lee', 'JH', '.')]

>> POS Tags are: 
 [('Lee', 'NNP'), ('J', 'NNP'), (',', ','), ('Hong', 'NNP'), ('S', 'NNP'), (',', ','), ('Lee', 'NNP'), ('JH', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Lee J', 'Hong S', 'Lee JH']

>> Named Entities are: 
 [('PERSON', 'Lee'), ('ORGANIZATION', 'J'), ('GPE', 'Hong'), ('PERSON', 'Lee JH')] 

>> Stemming using Porter Stemmer: 
 [('Lee', 'lee'), ('J', 'j'), (',', ','), ('Hong', 'hong'), ('S', 's'), (',', ','), ('Lee', 'lee'), ('JH', 'jh'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Lee', 'lee'), ('J', 'j'), (',', ','), ('Hong', 'hong'), ('S', 's'), (',', ','), ('Lee', 'lee'), ('JH', 'jh'), ('.', '.')]

>> Lemmatization: 
 [('Lee', 'Lee'), ('J', 'J'), (',', ','), ('Hong', 'Hong'), ('S', 'S'), (',', ','), ('Lee', 'Lee'), ('JH', 'JH'), ('.', '.')]


------------------- Sentence 9 -------------------

An efficient prediction for heavy rain from big weather data using genetic algorithm.

>> Tokens are: 
 ['An', 'efficient', 'prediction', 'heavy', 'rain', 'big', 'weather', 'data', 'using', 'genetic', 'algorithm', '.']

>> Bigrams are: 
 [('An', 'efficient'), ('efficient', 'prediction'), ('prediction', 'heavy'), ('heavy', 'rain'), ('rain', 'big'), ('big', 'weather'), ('weather', 'data'), ('data', 'using'), ('using', 'genetic'), ('genetic', 'algorithm'), ('algorithm', '.')]

>> Trigrams are: 
 [('An', 'efficient', 'prediction'), ('efficient', 'prediction', 'heavy'), ('prediction', 'heavy', 'rain'), ('heavy', 'rain', 'big'), ('rain', 'big', 'weather'), ('big', 'weather', 'data'), ('weather', 'data', 'using'), ('data', 'using', 'genetic'), ('using', 'genetic', 'algorithm'), ('genetic', 'algorithm', '.')]

>> POS Tags are: 
 [('An', 'DT'), ('efficient', 'JJ'), ('prediction', 'NN'), ('heavy', 'JJ'), ('rain', 'NN'), ('big', 'JJ'), ('weather', 'NN'), ('data', 'NNS'), ('using', 'VBG'), ('genetic', 'JJ'), ('algorithm', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['An efficient prediction', 'heavy rain', 'big weather data', 'genetic algorithm']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('An', 'an'), ('efficient', 'effici'), ('prediction', 'predict'), ('heavy', 'heavi'), ('rain', 'rain'), ('big', 'big'), ('weather', 'weather'), ('data', 'data'), ('using', 'use'), ('genetic', 'genet'), ('algorithm', 'algorithm'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('An', 'an'), ('efficient', 'effici'), ('prediction', 'predict'), ('heavy', 'heavi'), ('rain', 'rain'), ('big', 'big'), ('weather', 'weather'), ('data', 'data'), ('using', 'use'), ('genetic', 'genet'), ('algorithm', 'algorithm'), ('.', '.')]

>> Lemmatization: 
 [('An', 'An'), ('efficient', 'efficient'), ('prediction', 'prediction'), ('heavy', 'heavy'), ('rain', 'rain'), ('big', 'big'), ('weather', 'weather'), ('data', 'data'), ('using', 'using'), ('genetic', 'genetic'), ('algorithm', 'algorithm'), ('.', '.')]


------------------- Sentence 10 -------------------

In:

>> Tokens are: 
 ['In', ':']

>> Bigrams are: 
 [('In', ':')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('In', 'IN'), (':', ':')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), (':', ':')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), (':', ':')]

>> Lemmatization: 
 [('In', 'In'), (':', ':')]



========================================== PARAGRAPH 465 ===========================================

Proceedings of the International Conference on Ubiquitous Information Management and Communication, 2014.  pp 25:1–25:7. 

------------------- Sentence 1 -------------------

Proceedings of the International Conference on Ubiquitous Information Management and Communication, 2014.  pp 25:1–25:7.

>> Tokens are: 
 ['Proceedings', 'International', 'Conference', 'Ubiquitous', 'Information', 'Management', 'Communication', ',', '2014.', 'pp', '25:1–25:7', '.']

>> Bigrams are: 
 [('Proceedings', 'International'), ('International', 'Conference'), ('Conference', 'Ubiquitous'), ('Ubiquitous', 'Information'), ('Information', 'Management'), ('Management', 'Communication'), ('Communication', ','), (',', '2014.'), ('2014.', 'pp'), ('pp', '25:1–25:7'), ('25:1–25:7', '.')]

>> Trigrams are: 
 [('Proceedings', 'International', 'Conference'), ('International', 'Conference', 'Ubiquitous'), ('Conference', 'Ubiquitous', 'Information'), ('Ubiquitous', 'Information', 'Management'), ('Information', 'Management', 'Communication'), ('Management', 'Communication', ','), ('Communication', ',', '2014.'), (',', '2014.', 'pp'), ('2014.', 'pp', '25:1–25:7'), ('pp', '25:1–25:7', '.')]

>> POS Tags are: 
 [('Proceedings', 'NNS'), ('International', 'NNP'), ('Conference', 'NNP'), ('Ubiquitous', 'NNP'), ('Information', 'NNP'), ('Management', 'NNP'), ('Communication', 'NNP'), (',', ','), ('2014.', 'CD'), ('pp', 'NN'), ('25:1–25:7', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Proceedings International Conference Ubiquitous Information Management Communication', 'pp']

>> Named Entities are: 
 [('ORGANIZATION', 'International Conference Ubiquitous Information')] 

>> Stemming using Porter Stemmer: 
 [('Proceedings', 'proceed'), ('International', 'intern'), ('Conference', 'confer'), ('Ubiquitous', 'ubiquit'), ('Information', 'inform'), ('Management', 'manag'), ('Communication', 'commun'), (',', ','), ('2014.', '2014.'), ('pp', 'pp'), ('25:1–25:7', '25:1–25:7'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Proceedings', 'proceed'), ('International', 'intern'), ('Conference', 'confer'), ('Ubiquitous', 'ubiquit'), ('Information', 'inform'), ('Management', 'manag'), ('Communication', 'communic'), (',', ','), ('2014.', '2014.'), ('pp', 'pp'), ('25:1–25:7', '25:1–25:7'), ('.', '.')]

>> Lemmatization: 
 [('Proceedings', 'Proceedings'), ('International', 'International'), ('Conference', 'Conference'), ('Ubiquitous', 'Ubiquitous'), ('Information', 'Information'), ('Management', 'Management'), ('Communication', 'Communication'), (',', ','), ('2014.', '2014.'), ('pp', 'pp'), ('25:1–25:7', '25:1–25:7'), ('.', '.')]



========================================== PARAGRAPH 466 ===========================================

 73. Famili A, Shen W‑M, Weber R, Simoudis E. Data preprocessing and intelligent data analysis. Intel Data Anal.  1997;1(1–4):3–23. 

------------------- Sentence 1 -------------------

 73.

>> Tokens are: 
 ['73', '.']

>> Bigrams are: 
 [('73', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('73', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('73', '73'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('73', '73'), ('.', '.')]

>> Lemmatization: 
 [('73', '73'), ('.', '.')]


------------------- Sentence 2 -------------------

Famili A, Shen W‑M, Weber R, Simoudis E. Data preprocessing and intelligent data analysis.

>> Tokens are: 
 ['Famili', 'A', ',', 'Shen', 'W‑M', ',', 'Weber', 'R', ',', 'Simoudis', 'E.', 'Data', 'preprocessing', 'intelligent', 'data', 'analysis', '.']

>> Bigrams are: 
 [('Famili', 'A'), ('A', ','), (',', 'Shen'), ('Shen', 'W‑M'), ('W‑M', ','), (',', 'Weber'), ('Weber', 'R'), ('R', ','), (',', 'Simoudis'), ('Simoudis', 'E.'), ('E.', 'Data'), ('Data', 'preprocessing'), ('preprocessing', 'intelligent'), ('intelligent', 'data'), ('data', 'analysis'), ('analysis', '.')]

>> Trigrams are: 
 [('Famili', 'A', ','), ('A', ',', 'Shen'), (',', 'Shen', 'W‑M'), ('Shen', 'W‑M', ','), ('W‑M', ',', 'Weber'), (',', 'Weber', 'R'), ('Weber', 'R', ','), ('R', ',', 'Simoudis'), (',', 'Simoudis', 'E.'), ('Simoudis', 'E.', 'Data'), ('E.', 'Data', 'preprocessing'), ('Data', 'preprocessing', 'intelligent'), ('preprocessing', 'intelligent', 'data'), ('intelligent', 'data', 'analysis'), ('data', 'analysis', '.')]

>> POS Tags are: 
 [('Famili', 'NNP'), ('A', 'NNP'), (',', ','), ('Shen', 'NNP'), ('W‑M', 'NNP'), (',', ','), ('Weber', 'NNP'), ('R', 'NNP'), (',', ','), ('Simoudis', 'NNP'), ('E.', 'NNP'), ('Data', 'NNP'), ('preprocessing', 'NN'), ('intelligent', 'NN'), ('data', 'NNS'), ('analysis', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Famili A', 'Shen W‑M', 'Weber R', 'Simoudis E. Data preprocessing intelligent data analysis']

>> Named Entities are: 
 [('PERSON', 'Famili'), ('PERSON', 'Shen W‑M'), ('PERSON', 'Weber R'), ('PERSON', 'Simoudis E. Data')] 

>> Stemming using Porter Stemmer: 
 [('Famili', 'famili'), ('A', 'a'), (',', ','), ('Shen', 'shen'), ('W‑M', 'w‑m'), (',', ','), ('Weber', 'weber'), ('R', 'r'), (',', ','), ('Simoudis', 'simoudi'), ('E.', 'e.'), ('Data', 'data'), ('preprocessing', 'preprocess'), ('intelligent', 'intellig'), ('data', 'data'), ('analysis', 'analysi'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Famili', 'famili'), ('A', 'a'), (',', ','), ('Shen', 'shen'), ('W‑M', 'w‑m'), (',', ','), ('Weber', 'weber'), ('R', 'r'), (',', ','), ('Simoudis', 'simoudi'), ('E.', 'e.'), ('Data', 'data'), ('preprocessing', 'preprocess'), ('intelligent', 'intellig'), ('data', 'data'), ('analysis', 'analysi'), ('.', '.')]

>> Lemmatization: 
 [('Famili', 'Famili'), ('A', 'A'), (',', ','), ('Shen', 'Shen'), ('W‑M', 'W‑M'), (',', ','), ('Weber', 'Weber'), ('R', 'R'), (',', ','), ('Simoudis', 'Simoudis'), ('E.', 'E.'), ('Data', 'Data'), ('preprocessing', 'preprocessing'), ('intelligent', 'intelligent'), ('data', 'data'), ('analysis', 'analysis'), ('.', '.')]


------------------- Sentence 3 -------------------

Intel Data Anal.

>> Tokens are: 
 ['Intel', 'Data', 'Anal', '.']

>> Bigrams are: 
 [('Intel', 'Data'), ('Data', 'Anal'), ('Anal', '.')]

>> Trigrams are: 
 [('Intel', 'Data', 'Anal'), ('Data', 'Anal', '.')]

>> POS Tags are: 
 [('Intel', 'NNP'), ('Data', 'NNP'), ('Anal', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Intel Data Anal']

>> Named Entities are: 
 [('ORGANIZATION', 'Intel'), ('PERSON', 'Data Anal')] 

>> Stemming using Porter Stemmer: 
 [('Intel', 'intel'), ('Data', 'data'), ('Anal', 'anal'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Intel', 'intel'), ('Data', 'data'), ('Anal', 'anal'), ('.', '.')]

>> Lemmatization: 
 [('Intel', 'Intel'), ('Data', 'Data'), ('Anal', 'Anal'), ('.', '.')]


------------------- Sentence 4 -------------------

1997;1(1–4):3–23.

>> Tokens are: 
 ['1997', ';', '1', '(', '1–4', ')', ':3–23', '.']

>> Bigrams are: 
 [('1997', ';'), (';', '1'), ('1', '('), ('(', '1–4'), ('1–4', ')'), (')', ':3–23'), (':3–23', '.')]

>> Trigrams are: 
 [('1997', ';', '1'), (';', '1', '('), ('1', '(', '1–4'), ('(', '1–4', ')'), ('1–4', ')', ':3–23'), (')', ':3–23', '.')]

>> POS Tags are: 
 [('1997', 'CD'), (';', ':'), ('1', 'CD'), ('(', '('), ('1–4', 'CD'), (')', ')'), (':3–23', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 [':3–23']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('1997', '1997'), (';', ';'), ('1', '1'), ('(', '('), ('1–4', '1–4'), (')', ')'), (':3–23', ':3–23'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('1997', '1997'), (';', ';'), ('1', '1'), ('(', '('), ('1–4', '1–4'), (')', ')'), (':3–23', ':3–23'), ('.', '.')]

>> Lemmatization: 
 [('1997', '1997'), (';', ';'), ('1', '1'), ('(', '('), ('1–4', '1–4'), (')', ')'), (':3–23', ':3–23'), ('.', '.')]



========================================== PARAGRAPH 467 ===========================================

 74. Zhang H. A novel data preprocessing solution for large scale digital forensics investigation on big data, Master’s  thesis, Norway, 2013. 

------------------- Sentence 1 -------------------

 74.

>> Tokens are: 
 ['74', '.']

>> Bigrams are: 
 [('74', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('74', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('74', '74'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('74', '74'), ('.', '.')]

>> Lemmatization: 
 [('74', '74'), ('.', '.')]


------------------- Sentence 2 -------------------

Zhang H. A novel data preprocessing solution for large scale digital forensics investigation on big data, Master’s  thesis, Norway, 2013.

>> Tokens are: 
 ['Zhang', 'H.', 'A', 'novel', 'data', 'preprocessing', 'solution', 'large', 'scale', 'digital', 'forensics', 'investigation', 'big', 'data', ',', 'Master', '’', 'thesis', ',', 'Norway', ',', '2013', '.']

>> Bigrams are: 
 [('Zhang', 'H.'), ('H.', 'A'), ('A', 'novel'), ('novel', 'data'), ('data', 'preprocessing'), ('preprocessing', 'solution'), ('solution', 'large'), ('large', 'scale'), ('scale', 'digital'), ('digital', 'forensics'), ('forensics', 'investigation'), ('investigation', 'big'), ('big', 'data'), ('data', ','), (',', 'Master'), ('Master', '’'), ('’', 'thesis'), ('thesis', ','), (',', 'Norway'), ('Norway', ','), (',', '2013'), ('2013', '.')]

>> Trigrams are: 
 [('Zhang', 'H.', 'A'), ('H.', 'A', 'novel'), ('A', 'novel', 'data'), ('novel', 'data', 'preprocessing'), ('data', 'preprocessing', 'solution'), ('preprocessing', 'solution', 'large'), ('solution', 'large', 'scale'), ('large', 'scale', 'digital'), ('scale', 'digital', 'forensics'), ('digital', 'forensics', 'investigation'), ('forensics', 'investigation', 'big'), ('investigation', 'big', 'data'), ('big', 'data', ','), ('data', ',', 'Master'), (',', 'Master', '’'), ('Master', '’', 'thesis'), ('’', 'thesis', ','), ('thesis', ',', 'Norway'), (',', 'Norway', ','), ('Norway', ',', '2013'), (',', '2013', '.')]

>> POS Tags are: 
 [('Zhang', 'NNP'), ('H.', 'NNP'), ('A', 'NNP'), ('novel', 'NN'), ('data', 'NNS'), ('preprocessing', 'VBG'), ('solution', 'NN'), ('large', 'JJ'), ('scale', 'JJ'), ('digital', 'JJ'), ('forensics', 'NNS'), ('investigation', 'NN'), ('big', 'JJ'), ('data', 'NNS'), (',', ','), ('Master', 'NNP'), ('’', 'NNP'), ('thesis', 'NN'), (',', ','), ('Norway', 'NNP'), (',', ','), ('2013', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Zhang H. A novel data', 'solution', 'large scale digital forensics investigation', 'big data', 'Master ’ thesis', 'Norway']

>> Named Entities are: 
 [('PERSON', 'Zhang'), ('PERSON', 'Master'), ('GPE', 'Norway')] 

>> Stemming using Porter Stemmer: 
 [('Zhang', 'zhang'), ('H.', 'h.'), ('A', 'a'), ('novel', 'novel'), ('data', 'data'), ('preprocessing', 'preprocess'), ('solution', 'solut'), ('large', 'larg'), ('scale', 'scale'), ('digital', 'digit'), ('forensics', 'forens'), ('investigation', 'investig'), ('big', 'big'), ('data', 'data'), (',', ','), ('Master', 'master'), ('’', '’'), ('thesis', 'thesi'), (',', ','), ('Norway', 'norway'), (',', ','), ('2013', '2013'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Zhang', 'zhang'), ('H.', 'h.'), ('A', 'a'), ('novel', 'novel'), ('data', 'data'), ('preprocessing', 'preprocess'), ('solution', 'solut'), ('large', 'larg'), ('scale', 'scale'), ('digital', 'digit'), ('forensics', 'forens'), ('investigation', 'investig'), ('big', 'big'), ('data', 'data'), (',', ','), ('Master', 'master'), ('’', '’'), ('thesis', 'thesi'), (',', ','), ('Norway', 'norway'), (',', ','), ('2013', '2013'), ('.', '.')]

>> Lemmatization: 
 [('Zhang', 'Zhang'), ('H.', 'H.'), ('A', 'A'), ('novel', 'novel'), ('data', 'data'), ('preprocessing', 'preprocessing'), ('solution', 'solution'), ('large', 'large'), ('scale', 'scale'), ('digital', 'digital'), ('forensics', 'forensics'), ('investigation', 'investigation'), ('big', 'big'), ('data', 'data'), (',', ','), ('Master', 'Master'), ('’', '’'), ('thesis', 'thesis'), (',', ','), ('Norway', 'Norway'), (',', ','), ('2013', '2013'), ('.', '.')]



========================================== PARAGRAPH 468 ===========================================

 75. Ham YJ, Lee H‑W. International journal of advances in soft computing and its applications. Calc Paralleles Reseaux  et Syst Repar. 2014;6(1):1–18. 

------------------- Sentence 1 -------------------

 75.

>> Tokens are: 
 ['75', '.']

>> Bigrams are: 
 [('75', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('75', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('75', '75'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('75', '75'), ('.', '.')]

>> Lemmatization: 
 [('75', '75'), ('.', '.')]


------------------- Sentence 2 -------------------

Ham YJ, Lee H‑W.

>> Tokens are: 
 ['Ham', 'YJ', ',', 'Lee', 'H‑W', '.']

>> Bigrams are: 
 [('Ham', 'YJ'), ('YJ', ','), (',', 'Lee'), ('Lee', 'H‑W'), ('H‑W', '.')]

>> Trigrams are: 
 [('Ham', 'YJ', ','), ('YJ', ',', 'Lee'), (',', 'Lee', 'H‑W'), ('Lee', 'H‑W', '.')]

>> POS Tags are: 
 [('Ham', 'NNP'), ('YJ', 'NNP'), (',', ','), ('Lee', 'NNP'), ('H‑W', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Ham YJ', 'Lee H‑W']

>> Named Entities are: 
 [('PERSON', 'Ham'), ('GPE', 'YJ'), ('PERSON', 'Lee')] 

>> Stemming using Porter Stemmer: 
 [('Ham', 'ham'), ('YJ', 'yj'), (',', ','), ('Lee', 'lee'), ('H‑W', 'h‑w'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Ham', 'ham'), ('YJ', 'yj'), (',', ','), ('Lee', 'lee'), ('H‑W', 'h‑w'), ('.', '.')]

>> Lemmatization: 
 [('Ham', 'Ham'), ('YJ', 'YJ'), (',', ','), ('Lee', 'Lee'), ('H‑W', 'H‑W'), ('.', '.')]


------------------- Sentence 3 -------------------

International journal of advances in soft computing and its applications.

>> Tokens are: 
 ['International', 'journal', 'advances', 'soft', 'computing', 'applications', '.']

>> Bigrams are: 
 [('International', 'journal'), ('journal', 'advances'), ('advances', 'soft'), ('soft', 'computing'), ('computing', 'applications'), ('applications', '.')]

>> Trigrams are: 
 [('International', 'journal', 'advances'), ('journal', 'advances', 'soft'), ('advances', 'soft', 'computing'), ('soft', 'computing', 'applications'), ('computing', 'applications', '.')]

>> POS Tags are: 
 [('International', 'NNP'), ('journal', 'NN'), ('advances', 'NNS'), ('soft', 'JJ'), ('computing', 'VBG'), ('applications', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['International journal advances', 'applications']

>> Named Entities are: 
 [('GPE', 'International')] 

>> Stemming using Porter Stemmer: 
 [('International', 'intern'), ('journal', 'journal'), ('advances', 'advanc'), ('soft', 'soft'), ('computing', 'comput'), ('applications', 'applic'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('International', 'intern'), ('journal', 'journal'), ('advances', 'advanc'), ('soft', 'soft'), ('computing', 'comput'), ('applications', 'applic'), ('.', '.')]

>> Lemmatization: 
 [('International', 'International'), ('journal', 'journal'), ('advances', 'advance'), ('soft', 'soft'), ('computing', 'computing'), ('applications', 'application'), ('.', '.')]


------------------- Sentence 4 -------------------

Calc Paralleles Reseaux  et Syst Repar.

>> Tokens are: 
 ['Calc', 'Paralleles', 'Reseaux', 'et', 'Syst', 'Repar', '.']

>> Bigrams are: 
 [('Calc', 'Paralleles'), ('Paralleles', 'Reseaux'), ('Reseaux', 'et'), ('et', 'Syst'), ('Syst', 'Repar'), ('Repar', '.')]

>> Trigrams are: 
 [('Calc', 'Paralleles', 'Reseaux'), ('Paralleles', 'Reseaux', 'et'), ('Reseaux', 'et', 'Syst'), ('et', 'Syst', 'Repar'), ('Syst', 'Repar', '.')]

>> POS Tags are: 
 [('Calc', 'NNP'), ('Paralleles', 'NNP'), ('Reseaux', 'NNP'), ('et', 'FW'), ('Syst', 'NNP'), ('Repar', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Calc Paralleles Reseaux', 'Syst Repar']

>> Named Entities are: 
 [('PERSON', 'Calc'), ('ORGANIZATION', 'Paralleles Reseaux'), ('PERSON', 'Syst Repar')] 

>> Stemming using Porter Stemmer: 
 [('Calc', 'calc'), ('Paralleles', 'parallel'), ('Reseaux', 'reseaux'), ('et', 'et'), ('Syst', 'syst'), ('Repar', 'repar'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Calc', 'calc'), ('Paralleles', 'parallel'), ('Reseaux', 'reseaux'), ('et', 'et'), ('Syst', 'syst'), ('Repar', 'repar'), ('.', '.')]

>> Lemmatization: 
 [('Calc', 'Calc'), ('Paralleles', 'Paralleles'), ('Reseaux', 'Reseaux'), ('et', 'et'), ('Syst', 'Syst'), ('Repar', 'Repar'), ('.', '.')]


------------------- Sentence 5 -------------------

2014;6(1):1–18.

>> Tokens are: 
 ['2014', ';', '6', '(', '1', ')', ':1–18', '.']

>> Bigrams are: 
 [('2014', ';'), (';', '6'), ('6', '('), ('(', '1'), ('1', ')'), (')', ':1–18'), (':1–18', '.')]

>> Trigrams are: 
 [('2014', ';', '6'), (';', '6', '('), ('6', '(', '1'), ('(', '1', ')'), ('1', ')', ':1–18'), (')', ':1–18', '.')]

>> POS Tags are: 
 [('2014', 'CD'), (';', ':'), ('6', 'CD'), ('(', '('), ('1', 'CD'), (')', ')'), (':1–18', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 [':1–18']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('2014', '2014'), (';', ';'), ('6', '6'), ('(', '('), ('1', '1'), (')', ')'), (':1–18', ':1–18'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('2014', '2014'), (';', ';'), ('6', '6'), ('(', '('), ('1', '1'), (')', ')'), (':1–18', ':1–18'), ('.', '.')]

>> Lemmatization: 
 [('2014', '2014'), (';', ';'), ('6', '6'), ('(', '('), ('1', '1'), (')', ')'), (':1–18', ':1–18'), ('.', '.')]



========================================== PARAGRAPH 469 ===========================================

 76. Cormode G, Duffield N. Sampling for big data: a tutorial. In: Proceedings of the ACM SIGKDD International Confer‑ ence on Knowledge Discovery and Data Mining, 2014. pp 1975–1975. 

------------------- Sentence 1 -------------------

 76.

>> Tokens are: 
 ['76', '.']

>> Bigrams are: 
 [('76', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('76', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('76', '76'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('76', '76'), ('.', '.')]

>> Lemmatization: 
 [('76', '76'), ('.', '.')]


------------------- Sentence 2 -------------------

Cormode G, Duffield N. Sampling for big data: a tutorial.

>> Tokens are: 
 ['Cormode', 'G', ',', 'Duffield', 'N.', 'Sampling', 'big', 'data', ':', 'tutorial', '.']

>> Bigrams are: 
 [('Cormode', 'G'), ('G', ','), (',', 'Duffield'), ('Duffield', 'N.'), ('N.', 'Sampling'), ('Sampling', 'big'), ('big', 'data'), ('data', ':'), (':', 'tutorial'), ('tutorial', '.')]

>> Trigrams are: 
 [('Cormode', 'G', ','), ('G', ',', 'Duffield'), (',', 'Duffield', 'N.'), ('Duffield', 'N.', 'Sampling'), ('N.', 'Sampling', 'big'), ('Sampling', 'big', 'data'), ('big', 'data', ':'), ('data', ':', 'tutorial'), (':', 'tutorial', '.')]

>> POS Tags are: 
 [('Cormode', 'NNP'), ('G', 'NNP'), (',', ','), ('Duffield', 'NNP'), ('N.', 'NNP'), ('Sampling', 'NNP'), ('big', 'JJ'), ('data', 'NNS'), (':', ':'), ('tutorial', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Cormode G', 'Duffield N. Sampling', 'big data', 'tutorial']

>> Named Entities are: 
 [('PERSON', 'Cormode'), ('ORGANIZATION', 'G'), ('PERSON', 'Duffield N. Sampling')] 

>> Stemming using Porter Stemmer: 
 [('Cormode', 'cormod'), ('G', 'g'), (',', ','), ('Duffield', 'duffield'), ('N.', 'n.'), ('Sampling', 'sampl'), ('big', 'big'), ('data', 'data'), (':', ':'), ('tutorial', 'tutori'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Cormode', 'cormod'), ('G', 'g'), (',', ','), ('Duffield', 'duffield'), ('N.', 'n.'), ('Sampling', 'sampl'), ('big', 'big'), ('data', 'data'), (':', ':'), ('tutorial', 'tutori'), ('.', '.')]

>> Lemmatization: 
 [('Cormode', 'Cormode'), ('G', 'G'), (',', ','), ('Duffield', 'Duffield'), ('N.', 'N.'), ('Sampling', 'Sampling'), ('big', 'big'), ('data', 'data'), (':', ':'), ('tutorial', 'tutorial'), ('.', '.')]


------------------- Sentence 3 -------------------

In: Proceedings of the ACM SIGKDD International Confer‑ ence on Knowledge Discovery and Data Mining, 2014. pp 1975–1975.

>> Tokens are: 
 ['In', ':', 'Proceedings', 'ACM', 'SIGKDD', 'International', 'Confer‑', 'ence', 'Knowledge', 'Discovery', 'Data', 'Mining', ',', '2014.', 'pp', '1975–1975', '.']

>> Bigrams are: 
 [('In', ':'), (':', 'Proceedings'), ('Proceedings', 'ACM'), ('ACM', 'SIGKDD'), ('SIGKDD', 'International'), ('International', 'Confer‑'), ('Confer‑', 'ence'), ('ence', 'Knowledge'), ('Knowledge', 'Discovery'), ('Discovery', 'Data'), ('Data', 'Mining'), ('Mining', ','), (',', '2014.'), ('2014.', 'pp'), ('pp', '1975–1975'), ('1975–1975', '.')]

>> Trigrams are: 
 [('In', ':', 'Proceedings'), (':', 'Proceedings', 'ACM'), ('Proceedings', 'ACM', 'SIGKDD'), ('ACM', 'SIGKDD', 'International'), ('SIGKDD', 'International', 'Confer‑'), ('International', 'Confer‑', 'ence'), ('Confer‑', 'ence', 'Knowledge'), ('ence', 'Knowledge', 'Discovery'), ('Knowledge', 'Discovery', 'Data'), ('Discovery', 'Data', 'Mining'), ('Data', 'Mining', ','), ('Mining', ',', '2014.'), (',', '2014.', 'pp'), ('2014.', 'pp', '1975–1975'), ('pp', '1975–1975', '.')]

>> POS Tags are: 
 [('In', 'IN'), (':', ':'), ('Proceedings', 'NNS'), ('ACM', 'NNP'), ('SIGKDD', 'NNP'), ('International', 'NNP'), ('Confer‑', 'NNP'), ('ence', 'NN'), ('Knowledge', 'NNP'), ('Discovery', 'NNP'), ('Data', 'NNP'), ('Mining', 'NNP'), (',', ','), ('2014.', 'CD'), ('pp', 'NN'), ('1975–1975', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Proceedings ACM SIGKDD International Confer‑ ence Knowledge Discovery Data Mining', 'pp']

>> Named Entities are: 
 [('ORGANIZATION', 'ACM'), ('ORGANIZATION', 'SIGKDD International'), ('PERSON', 'Knowledge Discovery Data Mining')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), (':', ':'), ('Proceedings', 'proceed'), ('ACM', 'acm'), ('SIGKDD', 'sigkdd'), ('International', 'intern'), ('Confer‑', 'confer‑'), ('ence', 'enc'), ('Knowledge', 'knowledg'), ('Discovery', 'discoveri'), ('Data', 'data'), ('Mining', 'mine'), (',', ','), ('2014.', '2014.'), ('pp', 'pp'), ('1975–1975', '1975–1975'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), (':', ':'), ('Proceedings', 'proceed'), ('ACM', 'acm'), ('SIGKDD', 'sigkdd'), ('International', 'intern'), ('Confer‑', 'confer‑'), ('ence', 'enc'), ('Knowledge', 'knowledg'), ('Discovery', 'discoveri'), ('Data', 'data'), ('Mining', 'mine'), (',', ','), ('2014.', '2014.'), ('pp', 'pp'), ('1975–1975', '1975–1975'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), (':', ':'), ('Proceedings', 'Proceedings'), ('ACM', 'ACM'), ('SIGKDD', 'SIGKDD'), ('International', 'International'), ('Confer‑', 'Confer‑'), ('ence', 'ence'), ('Knowledge', 'Knowledge'), ('Discovery', 'Discovery'), ('Data', 'Data'), ('Mining', 'Mining'), (',', ','), ('2014.', '2014.'), ('pp', 'pp'), ('1975–1975', '1975–1975'), ('.', '.')]



========================================== PARAGRAPH 470 ===========================================

 77. Satyanarayana A. Intelligent sampling for big data using bootstrap sampling and chebyshev inequality. In: Pro‑ ceedings of the IEEE Canadian Conference on Electrical and Computer Engineering, 2014. pp 1–6. 

------------------- Sentence 1 -------------------

 77.

>> Tokens are: 
 ['77', '.']

>> Bigrams are: 
 [('77', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('77', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('77', '77'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('77', '77'), ('.', '.')]

>> Lemmatization: 
 [('77', '77'), ('.', '.')]


------------------- Sentence 2 -------------------

Satyanarayana A.

>> Tokens are: 
 ['Satyanarayana', 'A', '.']

>> Bigrams are: 
 [('Satyanarayana', 'A'), ('A', '.')]

>> Trigrams are: 
 [('Satyanarayana', 'A', '.')]

>> POS Tags are: 
 [('Satyanarayana', 'NNP'), ('A', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Satyanarayana A']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Satyanarayana', 'satyanarayana'), ('A', 'a'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Satyanarayana', 'satyanarayana'), ('A', 'a'), ('.', '.')]

>> Lemmatization: 
 [('Satyanarayana', 'Satyanarayana'), ('A', 'A'), ('.', '.')]


------------------- Sentence 3 -------------------

Intelligent sampling for big data using bootstrap sampling and chebyshev inequality.

>> Tokens are: 
 ['Intelligent', 'sampling', 'big', 'data', 'using', 'bootstrap', 'sampling', 'chebyshev', 'inequality', '.']

>> Bigrams are: 
 [('Intelligent', 'sampling'), ('sampling', 'big'), ('big', 'data'), ('data', 'using'), ('using', 'bootstrap'), ('bootstrap', 'sampling'), ('sampling', 'chebyshev'), ('chebyshev', 'inequality'), ('inequality', '.')]

>> Trigrams are: 
 [('Intelligent', 'sampling', 'big'), ('sampling', 'big', 'data'), ('big', 'data', 'using'), ('data', 'using', 'bootstrap'), ('using', 'bootstrap', 'sampling'), ('bootstrap', 'sampling', 'chebyshev'), ('sampling', 'chebyshev', 'inequality'), ('chebyshev', 'inequality', '.')]

>> POS Tags are: 
 [('Intelligent', 'NNP'), ('sampling', 'VBG'), ('big', 'JJ'), ('data', 'NNS'), ('using', 'VBG'), ('bootstrap', 'NN'), ('sampling', 'VBG'), ('chebyshev', 'JJ'), ('inequality', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Intelligent', 'big data', 'bootstrap', 'chebyshev inequality']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Intelligent', 'intellig'), ('sampling', 'sampl'), ('big', 'big'), ('data', 'data'), ('using', 'use'), ('bootstrap', 'bootstrap'), ('sampling', 'sampl'), ('chebyshev', 'chebyshev'), ('inequality', 'inequ'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Intelligent', 'intellig'), ('sampling', 'sampl'), ('big', 'big'), ('data', 'data'), ('using', 'use'), ('bootstrap', 'bootstrap'), ('sampling', 'sampl'), ('chebyshev', 'chebyshev'), ('inequality', 'inequ'), ('.', '.')]

>> Lemmatization: 
 [('Intelligent', 'Intelligent'), ('sampling', 'sampling'), ('big', 'big'), ('data', 'data'), ('using', 'using'), ('bootstrap', 'bootstrap'), ('sampling', 'sampling'), ('chebyshev', 'chebyshev'), ('inequality', 'inequality'), ('.', '.')]


------------------- Sentence 4 -------------------

In: Pro‑ ceedings of the IEEE Canadian Conference on Electrical and Computer Engineering, 2014. pp 1–6.

>> Tokens are: 
 ['In', ':', 'Pro‑', 'ceedings', 'IEEE', 'Canadian', 'Conference', 'Electrical', 'Computer', 'Engineering', ',', '2014.', 'pp', '1–6', '.']

>> Bigrams are: 
 [('In', ':'), (':', 'Pro‑'), ('Pro‑', 'ceedings'), ('ceedings', 'IEEE'), ('IEEE', 'Canadian'), ('Canadian', 'Conference'), ('Conference', 'Electrical'), ('Electrical', 'Computer'), ('Computer', 'Engineering'), ('Engineering', ','), (',', '2014.'), ('2014.', 'pp'), ('pp', '1–6'), ('1–6', '.')]

>> Trigrams are: 
 [('In', ':', 'Pro‑'), (':', 'Pro‑', 'ceedings'), ('Pro‑', 'ceedings', 'IEEE'), ('ceedings', 'IEEE', 'Canadian'), ('IEEE', 'Canadian', 'Conference'), ('Canadian', 'Conference', 'Electrical'), ('Conference', 'Electrical', 'Computer'), ('Electrical', 'Computer', 'Engineering'), ('Computer', 'Engineering', ','), ('Engineering', ',', '2014.'), (',', '2014.', 'pp'), ('2014.', 'pp', '1–6'), ('pp', '1–6', '.')]

>> POS Tags are: 
 [('In', 'IN'), (':', ':'), ('Pro‑', 'NNP'), ('ceedings', 'NNS'), ('IEEE', 'NNP'), ('Canadian', 'NNP'), ('Conference', 'NNP'), ('Electrical', 'NNP'), ('Computer', 'NNP'), ('Engineering', 'NNP'), (',', ','), ('2014.', 'CD'), ('pp', 'NN'), ('1–6', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Pro‑ ceedings IEEE Canadian Conference Electrical Computer Engineering', 'pp']

>> Named Entities are: 
 [('ORGANIZATION', 'IEEE Canadian Conference Electrical Computer Engineering')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), (':', ':'), ('Pro‑', 'pro‑'), ('ceedings', 'ceed'), ('IEEE', 'ieee'), ('Canadian', 'canadian'), ('Conference', 'confer'), ('Electrical', 'electr'), ('Computer', 'comput'), ('Engineering', 'engin'), (',', ','), ('2014.', '2014.'), ('pp', 'pp'), ('1–6', '1–6'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), (':', ':'), ('Pro‑', 'pro‑'), ('ceedings', 'ceed'), ('IEEE', 'ieee'), ('Canadian', 'canadian'), ('Conference', 'confer'), ('Electrical', 'electr'), ('Computer', 'comput'), ('Engineering', 'engin'), (',', ','), ('2014.', '2014.'), ('pp', 'pp'), ('1–6', '1–6'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), (':', ':'), ('Pro‑', 'Pro‑'), ('ceedings', 'ceedings'), ('IEEE', 'IEEE'), ('Canadian', 'Canadian'), ('Conference', 'Conference'), ('Electrical', 'Electrical'), ('Computer', 'Computer'), ('Engineering', 'Engineering'), (',', ','), ('2014.', '2014.'), ('pp', 'pp'), ('1–6', '1–6'), ('.', '.')]



========================================== PARAGRAPH 471 ===========================================

 78. Jun SW, Fleming K, Adler M, Emer JS. Zip‑io: architecture for application‑specific compression of big data. In:  Proceedings of the International Conference on Field‑Programmable Technology, 2012, pp 343–351. 

------------------- Sentence 1 -------------------

 78.

>> Tokens are: 
 ['78', '.']

>> Bigrams are: 
 [('78', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('78', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('78', '78'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('78', '78'), ('.', '.')]

>> Lemmatization: 
 [('78', '78'), ('.', '.')]


------------------- Sentence 2 -------------------

Jun SW, Fleming K, Adler M, Emer JS.

>> Tokens are: 
 ['Jun', 'SW', ',', 'Fleming', 'K', ',', 'Adler', 'M', ',', 'Emer', 'JS', '.']

>> Bigrams are: 
 [('Jun', 'SW'), ('SW', ','), (',', 'Fleming'), ('Fleming', 'K'), ('K', ','), (',', 'Adler'), ('Adler', 'M'), ('M', ','), (',', 'Emer'), ('Emer', 'JS'), ('JS', '.')]

>> Trigrams are: 
 [('Jun', 'SW', ','), ('SW', ',', 'Fleming'), (',', 'Fleming', 'K'), ('Fleming', 'K', ','), ('K', ',', 'Adler'), (',', 'Adler', 'M'), ('Adler', 'M', ','), ('M', ',', 'Emer'), (',', 'Emer', 'JS'), ('Emer', 'JS', '.')]

>> POS Tags are: 
 [('Jun', 'NNP'), ('SW', 'NNP'), (',', ','), ('Fleming', 'NNP'), ('K', 'NNP'), (',', ','), ('Adler', 'NNP'), ('M', 'NNP'), (',', ','), ('Emer', 'NNP'), ('JS', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Jun SW', 'Fleming K', 'Adler M', 'Emer JS']

>> Named Entities are: 
 [('PERSON', 'Jun'), ('GPE', 'SW'), ('PERSON', 'Fleming K'), ('PERSON', 'Adler M'), ('PERSON', 'Emer JS')] 

>> Stemming using Porter Stemmer: 
 [('Jun', 'jun'), ('SW', 'sw'), (',', ','), ('Fleming', 'fleme'), ('K', 'k'), (',', ','), ('Adler', 'adler'), ('M', 'm'), (',', ','), ('Emer', 'emer'), ('JS', 'js'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Jun', 'jun'), ('SW', 'sw'), (',', ','), ('Fleming', 'fleme'), ('K', 'k'), (',', ','), ('Adler', 'adler'), ('M', 'm'), (',', ','), ('Emer', 'emer'), ('JS', 'js'), ('.', '.')]

>> Lemmatization: 
 [('Jun', 'Jun'), ('SW', 'SW'), (',', ','), ('Fleming', 'Fleming'), ('K', 'K'), (',', ','), ('Adler', 'Adler'), ('M', 'M'), (',', ','), ('Emer', 'Emer'), ('JS', 'JS'), ('.', '.')]


------------------- Sentence 3 -------------------

Zip‑io: architecture for application‑specific compression of big data.

>> Tokens are: 
 ['Zip‑io', ':', 'architecture', 'application‑specific', 'compression', 'big', 'data', '.']

>> Bigrams are: 
 [('Zip‑io', ':'), (':', 'architecture'), ('architecture', 'application‑specific'), ('application‑specific', 'compression'), ('compression', 'big'), ('big', 'data'), ('data', '.')]

>> Trigrams are: 
 [('Zip‑io', ':', 'architecture'), (':', 'architecture', 'application‑specific'), ('architecture', 'application‑specific', 'compression'), ('application‑specific', 'compression', 'big'), ('compression', 'big', 'data'), ('big', 'data', '.')]

>> POS Tags are: 
 [('Zip‑io', 'NN'), (':', ':'), ('architecture', 'NN'), ('application‑specific', 'JJ'), ('compression', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['Zip‑io', 'architecture', 'application‑specific compression', 'big data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Zip‑io', 'zip‑io'), (':', ':'), ('architecture', 'architectur'), ('application‑specific', 'application‑specif'), ('compression', 'compress'), ('big', 'big'), ('data', 'data'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Zip‑io', 'zip‑io'), (':', ':'), ('architecture', 'architectur'), ('application‑specific', 'application‑specif'), ('compression', 'compress'), ('big', 'big'), ('data', 'data'), ('.', '.')]

>> Lemmatization: 
 [('Zip‑io', 'Zip‑io'), (':', ':'), ('architecture', 'architecture'), ('application‑specific', 'application‑specific'), ('compression', 'compression'), ('big', 'big'), ('data', 'data'), ('.', '.')]


------------------- Sentence 4 -------------------

In:  Proceedings of the International Conference on Field‑Programmable Technology, 2012, pp 343–351.

>> Tokens are: 
 ['In', ':', 'Proceedings', 'International', 'Conference', 'Field‑Programmable', 'Technology', ',', '2012', ',', 'pp', '343–351', '.']

>> Bigrams are: 
 [('In', ':'), (':', 'Proceedings'), ('Proceedings', 'International'), ('International', 'Conference'), ('Conference', 'Field‑Programmable'), ('Field‑Programmable', 'Technology'), ('Technology', ','), (',', '2012'), ('2012', ','), (',', 'pp'), ('pp', '343–351'), ('343–351', '.')]

>> Trigrams are: 
 [('In', ':', 'Proceedings'), (':', 'Proceedings', 'International'), ('Proceedings', 'International', 'Conference'), ('International', 'Conference', 'Field‑Programmable'), ('Conference', 'Field‑Programmable', 'Technology'), ('Field‑Programmable', 'Technology', ','), ('Technology', ',', '2012'), (',', '2012', ','), ('2012', ',', 'pp'), (',', 'pp', '343–351'), ('pp', '343–351', '.')]

>> POS Tags are: 
 [('In', 'IN'), (':', ':'), ('Proceedings', 'NNS'), ('International', 'NNP'), ('Conference', 'NNP'), ('Field‑Programmable', 'NNP'), ('Technology', 'NNP'), (',', ','), ('2012', 'CD'), (',', ','), ('pp', 'VBD'), ('343–351', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Proceedings International Conference Field‑Programmable Technology']

>> Named Entities are: 
 [('ORGANIZATION', 'International Conference')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), (':', ':'), ('Proceedings', 'proceed'), ('International', 'intern'), ('Conference', 'confer'), ('Field‑Programmable', 'field‑programm'), ('Technology', 'technolog'), (',', ','), ('2012', '2012'), (',', ','), ('pp', 'pp'), ('343–351', '343–351'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), (':', ':'), ('Proceedings', 'proceed'), ('International', 'intern'), ('Conference', 'confer'), ('Field‑Programmable', 'field‑programm'), ('Technology', 'technolog'), (',', ','), ('2012', '2012'), (',', ','), ('pp', 'pp'), ('343–351', '343–351'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), (':', ':'), ('Proceedings', 'Proceedings'), ('International', 'International'), ('Conference', 'Conference'), ('Field‑Programmable', 'Field‑Programmable'), ('Technology', 'Technology'), (',', ','), ('2012', '2012'), (',', ','), ('pp', 'pp'), ('343–351', '343–351'), ('.', '.')]



========================================== PARAGRAPH 472 ===========================================

 79. Zou H, Yu Y, Tang W, Chen HM. Improving I/O performance with adaptive data compression for big data applica‑ tions. In: Proceedings of the International Parallel and Distributed Processing Symposium Workshops, 2014. pp  1228–1237. 

------------------- Sentence 1 -------------------

 79.

>> Tokens are: 
 ['79', '.']

>> Bigrams are: 
 [('79', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('79', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('79', '79'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('79', '79'), ('.', '.')]

>> Lemmatization: 
 [('79', '79'), ('.', '.')]


------------------- Sentence 2 -------------------

Zou H, Yu Y, Tang W, Chen HM.

>> Tokens are: 
 ['Zou', 'H', ',', 'Yu', 'Y', ',', 'Tang', 'W', ',', 'Chen', 'HM', '.']

>> Bigrams are: 
 [('Zou', 'H'), ('H', ','), (',', 'Yu'), ('Yu', 'Y'), ('Y', ','), (',', 'Tang'), ('Tang', 'W'), ('W', ','), (',', 'Chen'), ('Chen', 'HM'), ('HM', '.')]

>> Trigrams are: 
 [('Zou', 'H', ','), ('H', ',', 'Yu'), (',', 'Yu', 'Y'), ('Yu', 'Y', ','), ('Y', ',', 'Tang'), (',', 'Tang', 'W'), ('Tang', 'W', ','), ('W', ',', 'Chen'), (',', 'Chen', 'HM'), ('Chen', 'HM', '.')]

>> POS Tags are: 
 [('Zou', 'NNP'), ('H', 'NNP'), (',', ','), ('Yu', 'NNP'), ('Y', 'NNP'), (',', ','), ('Tang', 'NNP'), ('W', 'NNP'), (',', ','), ('Chen', 'NNP'), ('HM', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Zou H', 'Yu Y', 'Tang W', 'Chen HM']

>> Named Entities are: 
 [('PERSON', 'Zou'), ('ORGANIZATION', 'H'), ('PERSON', 'Yu Y'), ('PERSON', 'Tang W'), ('PERSON', 'Chen HM')] 

>> Stemming using Porter Stemmer: 
 [('Zou', 'zou'), ('H', 'h'), (',', ','), ('Yu', 'yu'), ('Y', 'y'), (',', ','), ('Tang', 'tang'), ('W', 'w'), (',', ','), ('Chen', 'chen'), ('HM', 'hm'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Zou', 'zou'), ('H', 'h'), (',', ','), ('Yu', 'yu'), ('Y', 'y'), (',', ','), ('Tang', 'tang'), ('W', 'w'), (',', ','), ('Chen', 'chen'), ('HM', 'hm'), ('.', '.')]

>> Lemmatization: 
 [('Zou', 'Zou'), ('H', 'H'), (',', ','), ('Yu', 'Yu'), ('Y', 'Y'), (',', ','), ('Tang', 'Tang'), ('W', 'W'), (',', ','), ('Chen', 'Chen'), ('HM', 'HM'), ('.', '.')]


------------------- Sentence 3 -------------------

Improving I/O performance with adaptive data compression for big data applica‑ tions.

>> Tokens are: 
 ['Improving', 'I/O', 'performance', 'adaptive', 'data', 'compression', 'big', 'data', 'applica‑', 'tions', '.']

>> Bigrams are: 
 [('Improving', 'I/O'), ('I/O', 'performance'), ('performance', 'adaptive'), ('adaptive', 'data'), ('data', 'compression'), ('compression', 'big'), ('big', 'data'), ('data', 'applica‑'), ('applica‑', 'tions'), ('tions', '.')]

>> Trigrams are: 
 [('Improving', 'I/O', 'performance'), ('I/O', 'performance', 'adaptive'), ('performance', 'adaptive', 'data'), ('adaptive', 'data', 'compression'), ('data', 'compression', 'big'), ('compression', 'big', 'data'), ('big', 'data', 'applica‑'), ('data', 'applica‑', 'tions'), ('applica‑', 'tions', '.')]

>> POS Tags are: 
 [('Improving', 'VBG'), ('I/O', 'NNP'), ('performance', 'NN'), ('adaptive', 'JJ'), ('data', 'NNS'), ('compression', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('applica‑', 'NN'), ('tions', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['I/O performance', 'adaptive data compression', 'big data applica‑ tions']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Improving', 'improv'), ('I/O', 'i/o'), ('performance', 'perform'), ('adaptive', 'adapt'), ('data', 'data'), ('compression', 'compress'), ('big', 'big'), ('data', 'data'), ('applica‑', 'applica‑'), ('tions', 'tion'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Improving', 'improv'), ('I/O', 'i/o'), ('performance', 'perform'), ('adaptive', 'adapt'), ('data', 'data'), ('compression', 'compress'), ('big', 'big'), ('data', 'data'), ('applica‑', 'applica‑'), ('tions', 'tion'), ('.', '.')]

>> Lemmatization: 
 [('Improving', 'Improving'), ('I/O', 'I/O'), ('performance', 'performance'), ('adaptive', 'adaptive'), ('data', 'data'), ('compression', 'compression'), ('big', 'big'), ('data', 'data'), ('applica‑', 'applica‑'), ('tions', 'tions'), ('.', '.')]


------------------- Sentence 4 -------------------

In: Proceedings of the International Parallel and Distributed Processing Symposium Workshops, 2014. pp  1228–1237.

>> Tokens are: 
 ['In', ':', 'Proceedings', 'International', 'Parallel', 'Distributed', 'Processing', 'Symposium', 'Workshops', ',', '2014.', 'pp', '1228–1237', '.']

>> Bigrams are: 
 [('In', ':'), (':', 'Proceedings'), ('Proceedings', 'International'), ('International', 'Parallel'), ('Parallel', 'Distributed'), ('Distributed', 'Processing'), ('Processing', 'Symposium'), ('Symposium', 'Workshops'), ('Workshops', ','), (',', '2014.'), ('2014.', 'pp'), ('pp', '1228–1237'), ('1228–1237', '.')]

>> Trigrams are: 
 [('In', ':', 'Proceedings'), (':', 'Proceedings', 'International'), ('Proceedings', 'International', 'Parallel'), ('International', 'Parallel', 'Distributed'), ('Parallel', 'Distributed', 'Processing'), ('Distributed', 'Processing', 'Symposium'), ('Processing', 'Symposium', 'Workshops'), ('Symposium', 'Workshops', ','), ('Workshops', ',', '2014.'), (',', '2014.', 'pp'), ('2014.', 'pp', '1228–1237'), ('pp', '1228–1237', '.')]

>> POS Tags are: 
 [('In', 'IN'), (':', ':'), ('Proceedings', 'NNS'), ('International', 'NNP'), ('Parallel', 'NNP'), ('Distributed', 'NNP'), ('Processing', 'NNP'), ('Symposium', 'NNP'), ('Workshops', 'NNP'), (',', ','), ('2014.', 'CD'), ('pp', 'NN'), ('1228–1237', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Proceedings International Parallel Distributed Processing Symposium Workshops', 'pp']

>> Named Entities are: 
 [('ORGANIZATION', 'International Parallel Distributed')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), (':', ':'), ('Proceedings', 'proceed'), ('International', 'intern'), ('Parallel', 'parallel'), ('Distributed', 'distribut'), ('Processing', 'process'), ('Symposium', 'symposium'), ('Workshops', 'workshop'), (',', ','), ('2014.', '2014.'), ('pp', 'pp'), ('1228–1237', '1228–1237'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), (':', ':'), ('Proceedings', 'proceed'), ('International', 'intern'), ('Parallel', 'parallel'), ('Distributed', 'distribut'), ('Processing', 'process'), ('Symposium', 'symposium'), ('Workshops', 'workshop'), (',', ','), ('2014.', '2014.'), ('pp', 'pp'), ('1228–1237', '1228–1237'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), (':', ':'), ('Proceedings', 'Proceedings'), ('International', 'International'), ('Parallel', 'Parallel'), ('Distributed', 'Distributed'), ('Processing', 'Processing'), ('Symposium', 'Symposium'), ('Workshops', 'Workshops'), (',', ','), ('2014.', '2014.'), ('pp', 'pp'), ('1228–1237', '1228–1237'), ('.', '.')]



========================================== PARAGRAPH 473 ===========================================

 80. Yang C, Zhang X, Zhong C, Liu C, Pei J, Ramamohanarao K, Chen J. A spatiotemporal compression based approach  for efficient big data processing on cloud. J Comp Syst Sci. 2014;80(8):1563–83. 

------------------- Sentence 1 -------------------

 80.

>> Tokens are: 
 ['80', '.']

>> Bigrams are: 
 [('80', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('80', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('80', '80'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('80', '80'), ('.', '.')]

>> Lemmatization: 
 [('80', '80'), ('.', '.')]


------------------- Sentence 2 -------------------

Yang C, Zhang X, Zhong C, Liu C, Pei J, Ramamohanarao K, Chen J.

>> Tokens are: 
 ['Yang', 'C', ',', 'Zhang', 'X', ',', 'Zhong', 'C', ',', 'Liu', 'C', ',', 'Pei', 'J', ',', 'Ramamohanarao', 'K', ',', 'Chen', 'J', '.']

>> Bigrams are: 
 [('Yang', 'C'), ('C', ','), (',', 'Zhang'), ('Zhang', 'X'), ('X', ','), (',', 'Zhong'), ('Zhong', 'C'), ('C', ','), (',', 'Liu'), ('Liu', 'C'), ('C', ','), (',', 'Pei'), ('Pei', 'J'), ('J', ','), (',', 'Ramamohanarao'), ('Ramamohanarao', 'K'), ('K', ','), (',', 'Chen'), ('Chen', 'J'), ('J', '.')]

>> Trigrams are: 
 [('Yang', 'C', ','), ('C', ',', 'Zhang'), (',', 'Zhang', 'X'), ('Zhang', 'X', ','), ('X', ',', 'Zhong'), (',', 'Zhong', 'C'), ('Zhong', 'C', ','), ('C', ',', 'Liu'), (',', 'Liu', 'C'), ('Liu', 'C', ','), ('C', ',', 'Pei'), (',', 'Pei', 'J'), ('Pei', 'J', ','), ('J', ',', 'Ramamohanarao'), (',', 'Ramamohanarao', 'K'), ('Ramamohanarao', 'K', ','), ('K', ',', 'Chen'), (',', 'Chen', 'J'), ('Chen', 'J', '.')]

>> POS Tags are: 
 [('Yang', 'NNP'), ('C', 'NNP'), (',', ','), ('Zhang', 'NNP'), ('X', 'NNP'), (',', ','), ('Zhong', 'NNP'), ('C', 'NNP'), (',', ','), ('Liu', 'NNP'), ('C', 'NNP'), (',', ','), ('Pei', 'NNP'), ('J', 'NNP'), (',', ','), ('Ramamohanarao', 'NNP'), ('K', 'NNP'), (',', ','), ('Chen', 'NNP'), ('J', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Yang C', 'Zhang X', 'Zhong C', 'Liu C', 'Pei J', 'Ramamohanarao K', 'Chen J']

>> Named Entities are: 
 [('PERSON', 'Yang'), ('PERSON', 'Zhang X'), ('PERSON', 'Zhong C'), ('PERSON', 'Liu C'), ('PERSON', 'Pei J'), ('PERSON', 'Ramamohanarao K'), ('PERSON', 'Chen J')] 

>> Stemming using Porter Stemmer: 
 [('Yang', 'yang'), ('C', 'c'), (',', ','), ('Zhang', 'zhang'), ('X', 'x'), (',', ','), ('Zhong', 'zhong'), ('C', 'c'), (',', ','), ('Liu', 'liu'), ('C', 'c'), (',', ','), ('Pei', 'pei'), ('J', 'j'), (',', ','), ('Ramamohanarao', 'ramamohanarao'), ('K', 'k'), (',', ','), ('Chen', 'chen'), ('J', 'j'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Yang', 'yang'), ('C', 'c'), (',', ','), ('Zhang', 'zhang'), ('X', 'x'), (',', ','), ('Zhong', 'zhong'), ('C', 'c'), (',', ','), ('Liu', 'liu'), ('C', 'c'), (',', ','), ('Pei', 'pei'), ('J', 'j'), (',', ','), ('Ramamohanarao', 'ramamohanarao'), ('K', 'k'), (',', ','), ('Chen', 'chen'), ('J', 'j'), ('.', '.')]

>> Lemmatization: 
 [('Yang', 'Yang'), ('C', 'C'), (',', ','), ('Zhang', 'Zhang'), ('X', 'X'), (',', ','), ('Zhong', 'Zhong'), ('C', 'C'), (',', ','), ('Liu', 'Liu'), ('C', 'C'), (',', ','), ('Pei', 'Pei'), ('J', 'J'), (',', ','), ('Ramamohanarao', 'Ramamohanarao'), ('K', 'K'), (',', ','), ('Chen', 'Chen'), ('J', 'J'), ('.', '.')]


------------------- Sentence 3 -------------------

A spatiotemporal compression based approach  for efficient big data processing on cloud.

>> Tokens are: 
 ['A', 'spatiotemporal', 'compression', 'based', 'approach', 'efficient', 'big', 'data', 'processing', 'cloud', '.']

>> Bigrams are: 
 [('A', 'spatiotemporal'), ('spatiotemporal', 'compression'), ('compression', 'based'), ('based', 'approach'), ('approach', 'efficient'), ('efficient', 'big'), ('big', 'data'), ('data', 'processing'), ('processing', 'cloud'), ('cloud', '.')]

>> Trigrams are: 
 [('A', 'spatiotemporal', 'compression'), ('spatiotemporal', 'compression', 'based'), ('compression', 'based', 'approach'), ('based', 'approach', 'efficient'), ('approach', 'efficient', 'big'), ('efficient', 'big', 'data'), ('big', 'data', 'processing'), ('data', 'processing', 'cloud'), ('processing', 'cloud', '.')]

>> POS Tags are: 
 [('A', 'DT'), ('spatiotemporal', 'JJ'), ('compression', 'NN'), ('based', 'VBN'), ('approach', 'NN'), ('efficient', 'JJ'), ('big', 'JJ'), ('data', 'NNS'), ('processing', 'NN'), ('cloud', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['A spatiotemporal compression', 'approach', 'efficient big data processing cloud']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('A', 'a'), ('spatiotemporal', 'spatiotempor'), ('compression', 'compress'), ('based', 'base'), ('approach', 'approach'), ('efficient', 'effici'), ('big', 'big'), ('data', 'data'), ('processing', 'process'), ('cloud', 'cloud'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('A', 'a'), ('spatiotemporal', 'spatiotempor'), ('compression', 'compress'), ('based', 'base'), ('approach', 'approach'), ('efficient', 'effici'), ('big', 'big'), ('data', 'data'), ('processing', 'process'), ('cloud', 'cloud'), ('.', '.')]

>> Lemmatization: 
 [('A', 'A'), ('spatiotemporal', 'spatiotemporal'), ('compression', 'compression'), ('based', 'based'), ('approach', 'approach'), ('efficient', 'efficient'), ('big', 'big'), ('data', 'data'), ('processing', 'processing'), ('cloud', 'cloud'), ('.', '.')]


------------------- Sentence 4 -------------------

J Comp Syst Sci.

>> Tokens are: 
 ['J', 'Comp', 'Syst', 'Sci', '.']

>> Bigrams are: 
 [('J', 'Comp'), ('Comp', 'Syst'), ('Syst', 'Sci'), ('Sci', '.')]

>> Trigrams are: 
 [('J', 'Comp', 'Syst'), ('Comp', 'Syst', 'Sci'), ('Syst', 'Sci', '.')]

>> POS Tags are: 
 [('J', 'NNP'), ('Comp', 'NNP'), ('Syst', 'NNP'), ('Sci', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['J Comp Syst Sci']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('J', 'j'), ('Comp', 'comp'), ('Syst', 'syst'), ('Sci', 'sci'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('J', 'j'), ('Comp', 'comp'), ('Syst', 'syst'), ('Sci', 'sci'), ('.', '.')]

>> Lemmatization: 
 [('J', 'J'), ('Comp', 'Comp'), ('Syst', 'Syst'), ('Sci', 'Sci'), ('.', '.')]


------------------- Sentence 5 -------------------

2014;80(8):1563–83.

>> Tokens are: 
 ['2014', ';', '80', '(', '8', ')', ':1563–83', '.']

>> Bigrams are: 
 [('2014', ';'), (';', '80'), ('80', '('), ('(', '8'), ('8', ')'), (')', ':1563–83'), (':1563–83', '.')]

>> Trigrams are: 
 [('2014', ';', '80'), (';', '80', '('), ('80', '(', '8'), ('(', '8', ')'), ('8', ')', ':1563–83'), (')', ':1563–83', '.')]

>> POS Tags are: 
 [('2014', 'CD'), (';', ':'), ('80', 'CD'), ('(', '('), ('8', 'CD'), (')', ')'), (':1563–83', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 [':1563–83']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('2014', '2014'), (';', ';'), ('80', '80'), ('(', '('), ('8', '8'), (')', ')'), (':1563–83', ':1563–83'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('2014', '2014'), (';', ';'), ('80', '80'), ('(', '('), ('8', '8'), (')', ')'), (':1563–83', ':1563–83'), ('.', '.')]

>> Lemmatization: 
 [('2014', '2014'), (';', ';'), ('80', '80'), ('(', '('), ('8', '8'), (')', ')'), (':1563–83', ':1563–83'), ('.', '.')]



========================================== PARAGRAPH 474 ===========================================

 81. Xue Z, Shen G, Li J, Xu Q, Zhang Y, Shao J. Compression‑aware I/O performance analysis for big data clustering. In:  Proceedings of the International Workshop on Big Data, Streams and Heterogeneous Source Mining: Algorithms,  Systems, Programming Models and Applications, 2012. pp 45–52. 

------------------- Sentence 1 -------------------

 81.

>> Tokens are: 
 ['81', '.']

>> Bigrams are: 
 [('81', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('81', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('81', '81'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('81', '81'), ('.', '.')]

>> Lemmatization: 
 [('81', '81'), ('.', '.')]


------------------- Sentence 2 -------------------

Xue Z, Shen G, Li J, Xu Q, Zhang Y, Shao J. Compression‑aware I/O performance analysis for big data clustering.

>> Tokens are: 
 ['Xue', 'Z', ',', 'Shen', 'G', ',', 'Li', 'J', ',', 'Xu', 'Q', ',', 'Zhang', 'Y', ',', 'Shao', 'J.', 'Compression‑aware', 'I/O', 'performance', 'analysis', 'big', 'data', 'clustering', '.']

>> Bigrams are: 
 [('Xue', 'Z'), ('Z', ','), (',', 'Shen'), ('Shen', 'G'), ('G', ','), (',', 'Li'), ('Li', 'J'), ('J', ','), (',', 'Xu'), ('Xu', 'Q'), ('Q', ','), (',', 'Zhang'), ('Zhang', 'Y'), ('Y', ','), (',', 'Shao'), ('Shao', 'J.'), ('J.', 'Compression‑aware'), ('Compression‑aware', 'I/O'), ('I/O', 'performance'), ('performance', 'analysis'), ('analysis', 'big'), ('big', 'data'), ('data', 'clustering'), ('clustering', '.')]

>> Trigrams are: 
 [('Xue', 'Z', ','), ('Z', ',', 'Shen'), (',', 'Shen', 'G'), ('Shen', 'G', ','), ('G', ',', 'Li'), (',', 'Li', 'J'), ('Li', 'J', ','), ('J', ',', 'Xu'), (',', 'Xu', 'Q'), ('Xu', 'Q', ','), ('Q', ',', 'Zhang'), (',', 'Zhang', 'Y'), ('Zhang', 'Y', ','), ('Y', ',', 'Shao'), (',', 'Shao', 'J.'), ('Shao', 'J.', 'Compression‑aware'), ('J.', 'Compression‑aware', 'I/O'), ('Compression‑aware', 'I/O', 'performance'), ('I/O', 'performance', 'analysis'), ('performance', 'analysis', 'big'), ('analysis', 'big', 'data'), ('big', 'data', 'clustering'), ('data', 'clustering', '.')]

>> POS Tags are: 
 [('Xue', 'NNP'), ('Z', 'NNP'), (',', ','), ('Shen', 'NNP'), ('G', 'NNP'), (',', ','), ('Li', 'NNP'), ('J', 'NNP'), (',', ','), ('Xu', 'NNP'), ('Q', 'NNP'), (',', ','), ('Zhang', 'NNP'), ('Y', 'NNP'), (',', ','), ('Shao', 'NNP'), ('J.', 'NNP'), ('Compression‑aware', 'NNP'), ('I/O', 'NNP'), ('performance', 'NN'), ('analysis', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('clustering', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Xue Z', 'Shen G', 'Li J', 'Xu Q', 'Zhang Y', 'Shao J. Compression‑aware I/O performance analysis', 'big data clustering']

>> Named Entities are: 
 [('PERSON', 'Xue'), ('ORGANIZATION', 'Z'), ('PERSON', 'Shen G'), ('PERSON', 'Li J'), ('PERSON', 'Xu Q'), ('PERSON', 'Zhang Y'), ('PERSON', 'Shao J.')] 

>> Stemming using Porter Stemmer: 
 [('Xue', 'xue'), ('Z', 'z'), (',', ','), ('Shen', 'shen'), ('G', 'g'), (',', ','), ('Li', 'li'), ('J', 'j'), (',', ','), ('Xu', 'xu'), ('Q', 'q'), (',', ','), ('Zhang', 'zhang'), ('Y', 'y'), (',', ','), ('Shao', 'shao'), ('J.', 'j.'), ('Compression‑aware', 'compression‑awar'), ('I/O', 'i/o'), ('performance', 'perform'), ('analysis', 'analysi'), ('big', 'big'), ('data', 'data'), ('clustering', 'cluster'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Xue', 'xue'), ('Z', 'z'), (',', ','), ('Shen', 'shen'), ('G', 'g'), (',', ','), ('Li', 'li'), ('J', 'j'), (',', ','), ('Xu', 'xu'), ('Q', 'q'), (',', ','), ('Zhang', 'zhang'), ('Y', 'y'), (',', ','), ('Shao', 'shao'), ('J.', 'j.'), ('Compression‑aware', 'compression‑awar'), ('I/O', 'i/o'), ('performance', 'perform'), ('analysis', 'analysi'), ('big', 'big'), ('data', 'data'), ('clustering', 'cluster'), ('.', '.')]

>> Lemmatization: 
 [('Xue', 'Xue'), ('Z', 'Z'), (',', ','), ('Shen', 'Shen'), ('G', 'G'), (',', ','), ('Li', 'Li'), ('J', 'J'), (',', ','), ('Xu', 'Xu'), ('Q', 'Q'), (',', ','), ('Zhang', 'Zhang'), ('Y', 'Y'), (',', ','), ('Shao', 'Shao'), ('J.', 'J.'), ('Compression‑aware', 'Compression‑aware'), ('I/O', 'I/O'), ('performance', 'performance'), ('analysis', 'analysis'), ('big', 'big'), ('data', 'data'), ('clustering', 'clustering'), ('.', '.')]


------------------- Sentence 3 -------------------

In:  Proceedings of the International Workshop on Big Data, Streams and Heterogeneous Source Mining: Algorithms,  Systems, Programming Models and Applications, 2012. pp 45–52.

>> Tokens are: 
 ['In', ':', 'Proceedings', 'International', 'Workshop', 'Big', 'Data', ',', 'Streams', 'Heterogeneous', 'Source', 'Mining', ':', 'Algorithms', ',', 'Systems', ',', 'Programming', 'Models', 'Applications', ',', '2012.', 'pp', '45–52', '.']

>> Bigrams are: 
 [('In', ':'), (':', 'Proceedings'), ('Proceedings', 'International'), ('International', 'Workshop'), ('Workshop', 'Big'), ('Big', 'Data'), ('Data', ','), (',', 'Streams'), ('Streams', 'Heterogeneous'), ('Heterogeneous', 'Source'), ('Source', 'Mining'), ('Mining', ':'), (':', 'Algorithms'), ('Algorithms', ','), (',', 'Systems'), ('Systems', ','), (',', 'Programming'), ('Programming', 'Models'), ('Models', 'Applications'), ('Applications', ','), (',', '2012.'), ('2012.', 'pp'), ('pp', '45–52'), ('45–52', '.')]

>> Trigrams are: 
 [('In', ':', 'Proceedings'), (':', 'Proceedings', 'International'), ('Proceedings', 'International', 'Workshop'), ('International', 'Workshop', 'Big'), ('Workshop', 'Big', 'Data'), ('Big', 'Data', ','), ('Data', ',', 'Streams'), (',', 'Streams', 'Heterogeneous'), ('Streams', 'Heterogeneous', 'Source'), ('Heterogeneous', 'Source', 'Mining'), ('Source', 'Mining', ':'), ('Mining', ':', 'Algorithms'), (':', 'Algorithms', ','), ('Algorithms', ',', 'Systems'), (',', 'Systems', ','), ('Systems', ',', 'Programming'), (',', 'Programming', 'Models'), ('Programming', 'Models', 'Applications'), ('Models', 'Applications', ','), ('Applications', ',', '2012.'), (',', '2012.', 'pp'), ('2012.', 'pp', '45–52'), ('pp', '45–52', '.')]

>> POS Tags are: 
 [('In', 'IN'), (':', ':'), ('Proceedings', 'NNS'), ('International', 'NNP'), ('Workshop', 'NNP'), ('Big', 'NNP'), ('Data', 'NNP'), (',', ','), ('Streams', 'NNP'), ('Heterogeneous', 'NNP'), ('Source', 'NNP'), ('Mining', 'NNP'), (':', ':'), ('Algorithms', 'NNP'), (',', ','), ('Systems', 'NNP'), (',', ','), ('Programming', 'NNP'), ('Models', 'NNP'), ('Applications', 'NNP'), (',', ','), ('2012.', 'CD'), ('pp', 'NN'), ('45–52', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Proceedings International Workshop Big Data', 'Streams Heterogeneous Source Mining', 'Algorithms', 'Systems', 'Programming Models Applications', 'pp']

>> Named Entities are: 
 [('ORGANIZATION', 'International Workshop'), ('PERSON', 'Streams Heterogeneous Source'), ('PERSON', 'Systems')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), (':', ':'), ('Proceedings', 'proceed'), ('International', 'intern'), ('Workshop', 'workshop'), ('Big', 'big'), ('Data', 'data'), (',', ','), ('Streams', 'stream'), ('Heterogeneous', 'heterogen'), ('Source', 'sourc'), ('Mining', 'mine'), (':', ':'), ('Algorithms', 'algorithm'), (',', ','), ('Systems', 'system'), (',', ','), ('Programming', 'program'), ('Models', 'model'), ('Applications', 'applic'), (',', ','), ('2012.', '2012.'), ('pp', 'pp'), ('45–52', '45–52'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), (':', ':'), ('Proceedings', 'proceed'), ('International', 'intern'), ('Workshop', 'workshop'), ('Big', 'big'), ('Data', 'data'), (',', ','), ('Streams', 'stream'), ('Heterogeneous', 'heterogen'), ('Source', 'sourc'), ('Mining', 'mine'), (':', ':'), ('Algorithms', 'algorithm'), (',', ','), ('Systems', 'system'), (',', ','), ('Programming', 'program'), ('Models', 'model'), ('Applications', 'applic'), (',', ','), ('2012.', '2012.'), ('pp', 'pp'), ('45–52', '45–52'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), (':', ':'), ('Proceedings', 'Proceedings'), ('International', 'International'), ('Workshop', 'Workshop'), ('Big', 'Big'), ('Data', 'Data'), (',', ','), ('Streams', 'Streams'), ('Heterogeneous', 'Heterogeneous'), ('Source', 'Source'), ('Mining', 'Mining'), (':', ':'), ('Algorithms', 'Algorithms'), (',', ','), ('Systems', 'Systems'), (',', ','), ('Programming', 'Programming'), ('Models', 'Models'), ('Applications', 'Applications'), (',', ','), ('2012.', '2012.'), ('pp', 'pp'), ('45–52', '45–52'), ('.', '.')]



========================================== PARAGRAPH 475 ===========================================

 82. Pospiech M, Felden C. Big data—a state‑of‑the‑art. In: Proceedings of the Americas Conference on Information  Systems, 2012, pp 1–23. [Online]. Available: http://aisel.aisnet.org/amcis2012/proceedings/DecisionSupport/22. 

------------------- Sentence 1 -------------------

 82.

>> Tokens are: 
 ['82', '.']

>> Bigrams are: 
 [('82', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('82', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('82', '82'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('82', '82'), ('.', '.')]

>> Lemmatization: 
 [('82', '82'), ('.', '.')]


------------------- Sentence 2 -------------------

Pospiech M, Felden C. Big data—a state‑of‑the‑art.

>> Tokens are: 
 ['Pospiech', 'M', ',', 'Felden', 'C.', 'Big', 'data—a', 'state‑of‑the‑art', '.']

>> Bigrams are: 
 [('Pospiech', 'M'), ('M', ','), (',', 'Felden'), ('Felden', 'C.'), ('C.', 'Big'), ('Big', 'data—a'), ('data—a', 'state‑of‑the‑art'), ('state‑of‑the‑art', '.')]

>> Trigrams are: 
 [('Pospiech', 'M', ','), ('M', ',', 'Felden'), (',', 'Felden', 'C.'), ('Felden', 'C.', 'Big'), ('C.', 'Big', 'data—a'), ('Big', 'data—a', 'state‑of‑the‑art'), ('data—a', 'state‑of‑the‑art', '.')]

>> POS Tags are: 
 [('Pospiech', 'NNP'), ('M', 'NNP'), (',', ','), ('Felden', 'NNP'), ('C.', 'NNP'), ('Big', 'NNP'), ('data—a', 'NN'), ('state‑of‑the‑art', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Pospiech M', 'Felden C. Big data—a state‑of‑the‑art']

>> Named Entities are: 
 [('PERSON', 'Pospiech'), ('PERSON', 'Felden C.')] 

>> Stemming using Porter Stemmer: 
 [('Pospiech', 'pospiech'), ('M', 'm'), (',', ','), ('Felden', 'felden'), ('C.', 'c.'), ('Big', 'big'), ('data—a', 'data—a'), ('state‑of‑the‑art', 'state‑of‑the‑art'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Pospiech', 'pospiech'), ('M', 'm'), (',', ','), ('Felden', 'felden'), ('C.', 'c.'), ('Big', 'big'), ('data—a', 'data—a'), ('state‑of‑the‑art', 'state‑of‑the‑art'), ('.', '.')]

>> Lemmatization: 
 [('Pospiech', 'Pospiech'), ('M', 'M'), (',', ','), ('Felden', 'Felden'), ('C.', 'C.'), ('Big', 'Big'), ('data—a', 'data—a'), ('state‑of‑the‑art', 'state‑of‑the‑art'), ('.', '.')]


------------------- Sentence 3 -------------------

In: Proceedings of the Americas Conference on Information  Systems, 2012, pp 1–23.

>> Tokens are: 
 ['In', ':', 'Proceedings', 'Americas', 'Conference', 'Information', 'Systems', ',', '2012', ',', 'pp', '1–23', '.']

>> Bigrams are: 
 [('In', ':'), (':', 'Proceedings'), ('Proceedings', 'Americas'), ('Americas', 'Conference'), ('Conference', 'Information'), ('Information', 'Systems'), ('Systems', ','), (',', '2012'), ('2012', ','), (',', 'pp'), ('pp', '1–23'), ('1–23', '.')]

>> Trigrams are: 
 [('In', ':', 'Proceedings'), (':', 'Proceedings', 'Americas'), ('Proceedings', 'Americas', 'Conference'), ('Americas', 'Conference', 'Information'), ('Conference', 'Information', 'Systems'), ('Information', 'Systems', ','), ('Systems', ',', '2012'), (',', '2012', ','), ('2012', ',', 'pp'), (',', 'pp', '1–23'), ('pp', '1–23', '.')]

>> POS Tags are: 
 [('In', 'IN'), (':', ':'), ('Proceedings', 'NNS'), ('Americas', 'NNP'), ('Conference', 'NNP'), ('Information', 'NNP'), ('Systems', 'NNP'), (',', ','), ('2012', 'CD'), (',', ','), ('pp', 'VBD'), ('1–23', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Proceedings Americas Conference Information Systems']

>> Named Entities are: 
 [('PERSON', 'Americas Conference')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), (':', ':'), ('Proceedings', 'proceed'), ('Americas', 'america'), ('Conference', 'confer'), ('Information', 'inform'), ('Systems', 'system'), (',', ','), ('2012', '2012'), (',', ','), ('pp', 'pp'), ('1–23', '1–23'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), (':', ':'), ('Proceedings', 'proceed'), ('Americas', 'america'), ('Conference', 'confer'), ('Information', 'inform'), ('Systems', 'system'), (',', ','), ('2012', '2012'), (',', ','), ('pp', 'pp'), ('1–23', '1–23'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), (':', ':'), ('Proceedings', 'Proceedings'), ('Americas', 'Americas'), ('Conference', 'Conference'), ('Information', 'Information'), ('Systems', 'Systems'), (',', ','), ('2012', '2012'), (',', ','), ('pp', 'pp'), ('1–23', '1–23'), ('.', '.')]


------------------- Sentence 4 -------------------

[Online].

>> Tokens are: 
 ['[', 'Online', ']', '.']

>> Bigrams are: 
 [('[', 'Online'), ('Online', ']'), (']', '.')]

>> Trigrams are: 
 [('[', 'Online', ']'), ('Online', ']', '.')]

>> POS Tags are: 
 [('[', 'JJ'), ('Online', 'NNP'), (']', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['[ Online ]']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('Online', 'onlin'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('Online', 'onlin'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('Online', 'Online'), (']', ']'), ('.', '.')]


------------------- Sentence 5 -------------------

Available: http://aisel.aisnet.org/amcis2012/proceedings/DecisionSupport/22.

>> Tokens are: 
 ['Available', ':', 'http', ':', '//aisel.aisnet.org/amcis2012/proceedings/DecisionSupport/22', '.']

>> Bigrams are: 
 [('Available', ':'), (':', 'http'), ('http', ':'), (':', '//aisel.aisnet.org/amcis2012/proceedings/DecisionSupport/22'), ('//aisel.aisnet.org/amcis2012/proceedings/DecisionSupport/22', '.')]

>> Trigrams are: 
 [('Available', ':', 'http'), (':', 'http', ':'), ('http', ':', '//aisel.aisnet.org/amcis2012/proceedings/DecisionSupport/22'), (':', '//aisel.aisnet.org/amcis2012/proceedings/DecisionSupport/22', '.')]

>> POS Tags are: 
 [('Available', 'JJ'), (':', ':'), ('http', 'NN'), (':', ':'), ('//aisel.aisnet.org/amcis2012/proceedings/DecisionSupport/22', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['http', '//aisel.aisnet.org/amcis2012/proceedings/DecisionSupport/22']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Available', 'avail'), (':', ':'), ('http', 'http'), (':', ':'), ('//aisel.aisnet.org/amcis2012/proceedings/DecisionSupport/22', '//aisel.aisnet.org/amcis2012/proceedings/decisionsupport/22'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Available', 'avail'), (':', ':'), ('http', 'http'), (':', ':'), ('//aisel.aisnet.org/amcis2012/proceedings/DecisionSupport/22', '//aisel.aisnet.org/amcis2012/proceedings/decisionsupport/22'), ('.', '.')]

>> Lemmatization: 
 [('Available', 'Available'), (':', ':'), ('http', 'http'), (':', ':'), ('//aisel.aisnet.org/amcis2012/proceedings/DecisionSupport/22', '//aisel.aisnet.org/amcis2012/proceedings/DecisionSupport/22'), ('.', '.')]



========================================== PARAGRAPH 476 ===========================================

 83. Apache Hadoop, February 2, 2015. [Online]. Available: http://hadoop.apache.org.  84. Cuda, February 2, 2015. [Online]. Available: URL: http://www.nvidia.com/object/cuda_home_new.html.  85. Apache Storm, February 2, 2015. [Online]. Available: URL: http://storm.apache.org/.  86. Curtin RR, Cline JR, Slagle NP, March WB, Ram P, Mehta NA, Gray AG. MLPACK: a scalable C++ machine learning  

------------------- Sentence 1 -------------------

 83.

>> Tokens are: 
 ['83', '.']

>> Bigrams are: 
 [('83', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('83', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('83', '83'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('83', '83'), ('.', '.')]

>> Lemmatization: 
 [('83', '83'), ('.', '.')]


------------------- Sentence 2 -------------------

Apache Hadoop, February 2, 2015.

>> Tokens are: 
 ['Apache', 'Hadoop', ',', 'February', '2', ',', '2015', '.']

>> Bigrams are: 
 [('Apache', 'Hadoop'), ('Hadoop', ','), (',', 'February'), ('February', '2'), ('2', ','), (',', '2015'), ('2015', '.')]

>> Trigrams are: 
 [('Apache', 'Hadoop', ','), ('Hadoop', ',', 'February'), (',', 'February', '2'), ('February', '2', ','), ('2', ',', '2015'), (',', '2015', '.')]

>> POS Tags are: 
 [('Apache', 'NNP'), ('Hadoop', 'NNP'), (',', ','), ('February', 'NNP'), ('2', 'CD'), (',', ','), ('2015', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Apache Hadoop', 'February']

>> Named Entities are: 
 [('PERSON', 'Apache'), ('ORGANIZATION', 'Hadoop')] 

>> Stemming using Porter Stemmer: 
 [('Apache', 'apach'), ('Hadoop', 'hadoop'), (',', ','), ('February', 'februari'), ('2', '2'), (',', ','), ('2015', '2015'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Apache', 'apach'), ('Hadoop', 'hadoop'), (',', ','), ('February', 'februari'), ('2', '2'), (',', ','), ('2015', '2015'), ('.', '.')]

>> Lemmatization: 
 [('Apache', 'Apache'), ('Hadoop', 'Hadoop'), (',', ','), ('February', 'February'), ('2', '2'), (',', ','), ('2015', '2015'), ('.', '.')]


------------------- Sentence 3 -------------------

[Online].

>> Tokens are: 
 ['[', 'Online', ']', '.']

>> Bigrams are: 
 [('[', 'Online'), ('Online', ']'), (']', '.')]

>> Trigrams are: 
 [('[', 'Online', ']'), ('Online', ']', '.')]

>> POS Tags are: 
 [('[', 'JJ'), ('Online', 'NNP'), (']', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['[ Online ]']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('Online', 'onlin'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('Online', 'onlin'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('Online', 'Online'), (']', ']'), ('.', '.')]


------------------- Sentence 4 -------------------

Available: http://hadoop.apache.org.

>> Tokens are: 
 ['Available', ':', 'http', ':', '//hadoop.apache.org', '.']

>> Bigrams are: 
 [('Available', ':'), (':', 'http'), ('http', ':'), (':', '//hadoop.apache.org'), ('//hadoop.apache.org', '.')]

>> Trigrams are: 
 [('Available', ':', 'http'), (':', 'http', ':'), ('http', ':', '//hadoop.apache.org'), (':', '//hadoop.apache.org', '.')]

>> POS Tags are: 
 [('Available', 'JJ'), (':', ':'), ('http', 'NN'), (':', ':'), ('//hadoop.apache.org', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['http', '//hadoop.apache.org']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Available', 'avail'), (':', ':'), ('http', 'http'), (':', ':'), ('//hadoop.apache.org', '//hadoop.apache.org'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Available', 'avail'), (':', ':'), ('http', 'http'), (':', ':'), ('//hadoop.apache.org', '//hadoop.apache.org'), ('.', '.')]

>> Lemmatization: 
 [('Available', 'Available'), (':', ':'), ('http', 'http'), (':', ':'), ('//hadoop.apache.org', '//hadoop.apache.org'), ('.', '.')]


------------------- Sentence 5 -------------------

84.

>> Tokens are: 
 ['84', '.']

>> Bigrams are: 
 [('84', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('84', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('84', '84'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('84', '84'), ('.', '.')]

>> Lemmatization: 
 [('84', '84'), ('.', '.')]


------------------- Sentence 6 -------------------

Cuda, February 2, 2015.

>> Tokens are: 
 ['Cuda', ',', 'February', '2', ',', '2015', '.']

>> Bigrams are: 
 [('Cuda', ','), (',', 'February'), ('February', '2'), ('2', ','), (',', '2015'), ('2015', '.')]

>> Trigrams are: 
 [('Cuda', ',', 'February'), (',', 'February', '2'), ('February', '2', ','), ('2', ',', '2015'), (',', '2015', '.')]

>> POS Tags are: 
 [('Cuda', 'NNP'), (',', ','), ('February', 'NNP'), ('2', 'CD'), (',', ','), ('2015', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Cuda', 'February']

>> Named Entities are: 
 [('GPE', 'Cuda')] 

>> Stemming using Porter Stemmer: 
 [('Cuda', 'cuda'), (',', ','), ('February', 'februari'), ('2', '2'), (',', ','), ('2015', '2015'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Cuda', 'cuda'), (',', ','), ('February', 'februari'), ('2', '2'), (',', ','), ('2015', '2015'), ('.', '.')]

>> Lemmatization: 
 [('Cuda', 'Cuda'), (',', ','), ('February', 'February'), ('2', '2'), (',', ','), ('2015', '2015'), ('.', '.')]


------------------- Sentence 7 -------------------

[Online].

>> Tokens are: 
 ['[', 'Online', ']', '.']

>> Bigrams are: 
 [('[', 'Online'), ('Online', ']'), (']', '.')]

>> Trigrams are: 
 [('[', 'Online', ']'), ('Online', ']', '.')]

>> POS Tags are: 
 [('[', 'JJ'), ('Online', 'NNP'), (']', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['[ Online ]']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('Online', 'onlin'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('Online', 'onlin'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('Online', 'Online'), (']', ']'), ('.', '.')]


------------------- Sentence 8 -------------------

Available: URL: http://www.nvidia.com/object/cuda_home_new.html.

>> Tokens are: 
 ['Available', ':', 'URL', ':', 'http', ':', '//www.nvidia.com/object/cuda_home_new.html', '.']

>> Bigrams are: 
 [('Available', ':'), (':', 'URL'), ('URL', ':'), (':', 'http'), ('http', ':'), (':', '//www.nvidia.com/object/cuda_home_new.html'), ('//www.nvidia.com/object/cuda_home_new.html', '.')]

>> Trigrams are: 
 [('Available', ':', 'URL'), (':', 'URL', ':'), ('URL', ':', 'http'), (':', 'http', ':'), ('http', ':', '//www.nvidia.com/object/cuda_home_new.html'), (':', '//www.nvidia.com/object/cuda_home_new.html', '.')]

>> POS Tags are: 
 [('Available', 'JJ'), (':', ':'), ('URL', 'NN'), (':', ':'), ('http', 'NN'), (':', ':'), ('//www.nvidia.com/object/cuda_home_new.html', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['URL', 'http', '//www.nvidia.com/object/cuda_home_new.html']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Available', 'avail'), (':', ':'), ('URL', 'url'), (':', ':'), ('http', 'http'), (':', ':'), ('//www.nvidia.com/object/cuda_home_new.html', '//www.nvidia.com/object/cuda_home_new.html'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Available', 'avail'), (':', ':'), ('URL', 'url'), (':', ':'), ('http', 'http'), (':', ':'), ('//www.nvidia.com/object/cuda_home_new.html', '//www.nvidia.com/object/cuda_home_new.html'), ('.', '.')]

>> Lemmatization: 
 [('Available', 'Available'), (':', ':'), ('URL', 'URL'), (':', ':'), ('http', 'http'), (':', ':'), ('//www.nvidia.com/object/cuda_home_new.html', '//www.nvidia.com/object/cuda_home_new.html'), ('.', '.')]


------------------- Sentence 9 -------------------

85.

>> Tokens are: 
 ['85', '.']

>> Bigrams are: 
 [('85', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('85', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('85', '85'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('85', '85'), ('.', '.')]

>> Lemmatization: 
 [('85', '85'), ('.', '.')]


------------------- Sentence 10 -------------------

Apache Storm, February 2, 2015.

>> Tokens are: 
 ['Apache', 'Storm', ',', 'February', '2', ',', '2015', '.']

>> Bigrams are: 
 [('Apache', 'Storm'), ('Storm', ','), (',', 'February'), ('February', '2'), ('2', ','), (',', '2015'), ('2015', '.')]

>> Trigrams are: 
 [('Apache', 'Storm', ','), ('Storm', ',', 'February'), (',', 'February', '2'), ('February', '2', ','), ('2', ',', '2015'), (',', '2015', '.')]

>> POS Tags are: 
 [('Apache', 'NNP'), ('Storm', 'NNP'), (',', ','), ('February', 'NNP'), ('2', 'CD'), (',', ','), ('2015', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Apache Storm', 'February']

>> Named Entities are: 
 [('PERSON', 'Apache'), ('GPE', 'Storm')] 

>> Stemming using Porter Stemmer: 
 [('Apache', 'apach'), ('Storm', 'storm'), (',', ','), ('February', 'februari'), ('2', '2'), (',', ','), ('2015', '2015'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Apache', 'apach'), ('Storm', 'storm'), (',', ','), ('February', 'februari'), ('2', '2'), (',', ','), ('2015', '2015'), ('.', '.')]

>> Lemmatization: 
 [('Apache', 'Apache'), ('Storm', 'Storm'), (',', ','), ('February', 'February'), ('2', '2'), (',', ','), ('2015', '2015'), ('.', '.')]


------------------- Sentence 11 -------------------

[Online].

>> Tokens are: 
 ['[', 'Online', ']', '.']

>> Bigrams are: 
 [('[', 'Online'), ('Online', ']'), (']', '.')]

>> Trigrams are: 
 [('[', 'Online', ']'), ('Online', ']', '.')]

>> POS Tags are: 
 [('[', 'JJ'), ('Online', 'NNP'), (']', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['[ Online ]']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('Online', 'onlin'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('Online', 'onlin'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('Online', 'Online'), (']', ']'), ('.', '.')]


------------------- Sentence 12 -------------------

Available: URL: http://storm.apache.org/.

>> Tokens are: 
 ['Available', ':', 'URL', ':', 'http', ':', '//storm.apache.org/', '.']

>> Bigrams are: 
 [('Available', ':'), (':', 'URL'), ('URL', ':'), (':', 'http'), ('http', ':'), (':', '//storm.apache.org/'), ('//storm.apache.org/', '.')]

>> Trigrams are: 
 [('Available', ':', 'URL'), (':', 'URL', ':'), ('URL', ':', 'http'), (':', 'http', ':'), ('http', ':', '//storm.apache.org/'), (':', '//storm.apache.org/', '.')]

>> POS Tags are: 
 [('Available', 'JJ'), (':', ':'), ('URL', 'NN'), (':', ':'), ('http', 'NN'), (':', ':'), ('//storm.apache.org/', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['URL', 'http', '//storm.apache.org/']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Available', 'avail'), (':', ':'), ('URL', 'url'), (':', ':'), ('http', 'http'), (':', ':'), ('//storm.apache.org/', '//storm.apache.org/'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Available', 'avail'), (':', ':'), ('URL', 'url'), (':', ':'), ('http', 'http'), (':', ':'), ('//storm.apache.org/', '//storm.apache.org/'), ('.', '.')]

>> Lemmatization: 
 [('Available', 'Available'), (':', ':'), ('URL', 'URL'), (':', ':'), ('http', 'http'), (':', ':'), ('//storm.apache.org/', '//storm.apache.org/'), ('.', '.')]


------------------- Sentence 13 -------------------

86.

>> Tokens are: 
 ['86', '.']

>> Bigrams are: 
 [('86', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('86', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('86', '86'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('86', '86'), ('.', '.')]

>> Lemmatization: 
 [('86', '86'), ('.', '.')]


------------------- Sentence 14 -------------------

Curtin RR, Cline JR, Slagle NP, March WB, Ram P, Mehta NA, Gray AG.

>> Tokens are: 
 ['Curtin', 'RR', ',', 'Cline', 'JR', ',', 'Slagle', 'NP', ',', 'March', 'WB', ',', 'Ram', 'P', ',', 'Mehta', 'NA', ',', 'Gray', 'AG', '.']

>> Bigrams are: 
 [('Curtin', 'RR'), ('RR', ','), (',', 'Cline'), ('Cline', 'JR'), ('JR', ','), (',', 'Slagle'), ('Slagle', 'NP'), ('NP', ','), (',', 'March'), ('March', 'WB'), ('WB', ','), (',', 'Ram'), ('Ram', 'P'), ('P', ','), (',', 'Mehta'), ('Mehta', 'NA'), ('NA', ','), (',', 'Gray'), ('Gray', 'AG'), ('AG', '.')]

>> Trigrams are: 
 [('Curtin', 'RR', ','), ('RR', ',', 'Cline'), (',', 'Cline', 'JR'), ('Cline', 'JR', ','), ('JR', ',', 'Slagle'), (',', 'Slagle', 'NP'), ('Slagle', 'NP', ','), ('NP', ',', 'March'), (',', 'March', 'WB'), ('March', 'WB', ','), ('WB', ',', 'Ram'), (',', 'Ram', 'P'), ('Ram', 'P', ','), ('P', ',', 'Mehta'), (',', 'Mehta', 'NA'), ('Mehta', 'NA', ','), ('NA', ',', 'Gray'), (',', 'Gray', 'AG'), ('Gray', 'AG', '.')]

>> POS Tags are: 
 [('Curtin', 'NNP'), ('RR', 'NNP'), (',', ','), ('Cline', 'NNP'), ('JR', 'NNP'), (',', ','), ('Slagle', 'NNP'), ('NP', 'NNP'), (',', ','), ('March', 'NNP'), ('WB', 'NNP'), (',', ','), ('Ram', 'NNP'), ('P', 'NNP'), (',', ','), ('Mehta', 'NNP'), ('NA', 'NNP'), (',', ','), ('Gray', 'NNP'), ('AG', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Curtin RR', 'Cline JR', 'Slagle NP', 'March WB', 'Ram P', 'Mehta NA', 'Gray AG']

>> Named Entities are: 
 [('PERSON', 'Curtin'), ('GPE', 'RR'), ('PERSON', 'Cline JR'), ('PERSON', 'Slagle NP'), ('PERSON', 'March WB'), ('PERSON', 'Ram P'), ('PERSON', 'Mehta NA'), ('PERSON', 'Gray AG')] 

>> Stemming using Porter Stemmer: 
 [('Curtin', 'curtin'), ('RR', 'rr'), (',', ','), ('Cline', 'cline'), ('JR', 'jr'), (',', ','), ('Slagle', 'slagl'), ('NP', 'np'), (',', ','), ('March', 'march'), ('WB', 'wb'), (',', ','), ('Ram', 'ram'), ('P', 'p'), (',', ','), ('Mehta', 'mehta'), ('NA', 'na'), (',', ','), ('Gray', 'gray'), ('AG', 'ag'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Curtin', 'curtin'), ('RR', 'rr'), (',', ','), ('Cline', 'cline'), ('JR', 'jr'), (',', ','), ('Slagle', 'slagl'), ('NP', 'np'), (',', ','), ('March', 'march'), ('WB', 'wb'), (',', ','), ('Ram', 'ram'), ('P', 'p'), (',', ','), ('Mehta', 'mehta'), ('NA', 'na'), (',', ','), ('Gray', 'gray'), ('AG', 'ag'), ('.', '.')]

>> Lemmatization: 
 [('Curtin', 'Curtin'), ('RR', 'RR'), (',', ','), ('Cline', 'Cline'), ('JR', 'JR'), (',', ','), ('Slagle', 'Slagle'), ('NP', 'NP'), (',', ','), ('March', 'March'), ('WB', 'WB'), (',', ','), ('Ram', 'Ram'), ('P', 'P'), (',', ','), ('Mehta', 'Mehta'), ('NA', 'NA'), (',', ','), ('Gray', 'Gray'), ('AG', 'AG'), ('.', '.')]


------------------- Sentence 15 -------------------

MLPACK: a scalable C++ machine learning

>> Tokens are: 
 ['MLPACK', ':', 'scalable', 'C++', 'machine', 'learning']

>> Bigrams are: 
 [('MLPACK', ':'), (':', 'scalable'), ('scalable', 'C++'), ('C++', 'machine'), ('machine', 'learning')]

>> Trigrams are: 
 [('MLPACK', ':', 'scalable'), (':', 'scalable', 'C++'), ('scalable', 'C++', 'machine'), ('C++', 'machine', 'learning')]

>> POS Tags are: 
 [('MLPACK', 'NN'), (':', ':'), ('scalable', 'JJ'), ('C++', 'NNP'), ('machine', 'NN'), ('learning', 'NN')]

>> Noun Phrases are: 
 ['MLPACK', 'scalable C++ machine learning']

>> Named Entities are: 
 [('GPE', 'MLPACK')] 

>> Stemming using Porter Stemmer: 
 [('MLPACK', 'mlpack'), (':', ':'), ('scalable', 'scalabl'), ('C++', 'c++'), ('machine', 'machin'), ('learning', 'learn')]

>> Stemming using Snowball Stemmer: 
 [('MLPACK', 'mlpack'), (':', ':'), ('scalable', 'scalabl'), ('C++', 'c++'), ('machine', 'machin'), ('learning', 'learn')]

>> Lemmatization: 
 [('MLPACK', 'MLPACK'), (':', ':'), ('scalable', 'scalable'), ('C++', 'C++'), ('machine', 'machine'), ('learning', 'learning')]



========================================== PARAGRAPH 477 ===========================================

library. J Mach Learn Res. 2013;14:801–5.  87. Apache Mahout, February 2, 2015. [Online]. Available: http://mahout.apache.org/.  88. Huai Y, Lee R, Zhang S, Xia CH, Zhang X. DOT: a matrix model for analyzing, optimizing and deploying software for  

------------------- Sentence 1 -------------------

library.

>> Tokens are: 
 ['library', '.']

>> Bigrams are: 
 [('library', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('library', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['library']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('library', 'librari'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('library', 'librari'), ('.', '.')]

>> Lemmatization: 
 [('library', 'library'), ('.', '.')]


------------------- Sentence 2 -------------------

J Mach Learn Res.

>> Tokens are: 
 ['J', 'Mach', 'Learn', 'Res', '.']

>> Bigrams are: 
 [('J', 'Mach'), ('Mach', 'Learn'), ('Learn', 'Res'), ('Res', '.')]

>> Trigrams are: 
 [('J', 'Mach', 'Learn'), ('Mach', 'Learn', 'Res'), ('Learn', 'Res', '.')]

>> POS Tags are: 
 [('J', 'NNP'), ('Mach', 'NNP'), ('Learn', 'NNP'), ('Res', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['J Mach Learn Res']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('J', 'j'), ('Mach', 'mach'), ('Learn', 'learn'), ('Res', 're'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('J', 'j'), ('Mach', 'mach'), ('Learn', 'learn'), ('Res', 'res'), ('.', '.')]

>> Lemmatization: 
 [('J', 'J'), ('Mach', 'Mach'), ('Learn', 'Learn'), ('Res', 'Res'), ('.', '.')]


------------------- Sentence 3 -------------------

2013;14:801–5.

>> Tokens are: 
 ['2013', ';', '14:801–5', '.']

>> Bigrams are: 
 [('2013', ';'), (';', '14:801–5'), ('14:801–5', '.')]

>> Trigrams are: 
 [('2013', ';', '14:801–5'), (';', '14:801–5', '.')]

>> POS Tags are: 
 [('2013', 'CD'), (';', ':'), ('14:801–5', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('2013', '2013'), (';', ';'), ('14:801–5', '14:801–5'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('2013', '2013'), (';', ';'), ('14:801–5', '14:801–5'), ('.', '.')]

>> Lemmatization: 
 [('2013', '2013'), (';', ';'), ('14:801–5', '14:801–5'), ('.', '.')]


------------------- Sentence 4 -------------------

87.

>> Tokens are: 
 ['87', '.']

>> Bigrams are: 
 [('87', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('87', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('87', '87'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('87', '87'), ('.', '.')]

>> Lemmatization: 
 [('87', '87'), ('.', '.')]


------------------- Sentence 5 -------------------

Apache Mahout, February 2, 2015.

>> Tokens are: 
 ['Apache', 'Mahout', ',', 'February', '2', ',', '2015', '.']

>> Bigrams are: 
 [('Apache', 'Mahout'), ('Mahout', ','), (',', 'February'), ('February', '2'), ('2', ','), (',', '2015'), ('2015', '.')]

>> Trigrams are: 
 [('Apache', 'Mahout', ','), ('Mahout', ',', 'February'), (',', 'February', '2'), ('February', '2', ','), ('2', ',', '2015'), (',', '2015', '.')]

>> POS Tags are: 
 [('Apache', 'NNP'), ('Mahout', 'NNP'), (',', ','), ('February', 'NNP'), ('2', 'CD'), (',', ','), ('2015', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Apache Mahout', 'February']

>> Named Entities are: 
 [('PERSON', 'Apache'), ('ORGANIZATION', 'Mahout')] 

>> Stemming using Porter Stemmer: 
 [('Apache', 'apach'), ('Mahout', 'mahout'), (',', ','), ('February', 'februari'), ('2', '2'), (',', ','), ('2015', '2015'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Apache', 'apach'), ('Mahout', 'mahout'), (',', ','), ('February', 'februari'), ('2', '2'), (',', ','), ('2015', '2015'), ('.', '.')]

>> Lemmatization: 
 [('Apache', 'Apache'), ('Mahout', 'Mahout'), (',', ','), ('February', 'February'), ('2', '2'), (',', ','), ('2015', '2015'), ('.', '.')]


------------------- Sentence 6 -------------------

[Online].

>> Tokens are: 
 ['[', 'Online', ']', '.']

>> Bigrams are: 
 [('[', 'Online'), ('Online', ']'), (']', '.')]

>> Trigrams are: 
 [('[', 'Online', ']'), ('Online', ']', '.')]

>> POS Tags are: 
 [('[', 'JJ'), ('Online', 'NNP'), (']', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['[ Online ]']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('Online', 'onlin'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('Online', 'onlin'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('Online', 'Online'), (']', ']'), ('.', '.')]


------------------- Sentence 7 -------------------

Available: http://mahout.apache.org/.

>> Tokens are: 
 ['Available', ':', 'http', ':', '//mahout.apache.org/', '.']

>> Bigrams are: 
 [('Available', ':'), (':', 'http'), ('http', ':'), (':', '//mahout.apache.org/'), ('//mahout.apache.org/', '.')]

>> Trigrams are: 
 [('Available', ':', 'http'), (':', 'http', ':'), ('http', ':', '//mahout.apache.org/'), (':', '//mahout.apache.org/', '.')]

>> POS Tags are: 
 [('Available', 'JJ'), (':', ':'), ('http', 'NN'), (':', ':'), ('//mahout.apache.org/', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['http', '//mahout.apache.org/']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Available', 'avail'), (':', ':'), ('http', 'http'), (':', ':'), ('//mahout.apache.org/', '//mahout.apache.org/'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Available', 'avail'), (':', ':'), ('http', 'http'), (':', ':'), ('//mahout.apache.org/', '//mahout.apache.org/'), ('.', '.')]

>> Lemmatization: 
 [('Available', 'Available'), (':', ':'), ('http', 'http'), (':', ':'), ('//mahout.apache.org/', '//mahout.apache.org/'), ('.', '.')]


------------------- Sentence 8 -------------------

88.

>> Tokens are: 
 ['88', '.']

>> Bigrams are: 
 [('88', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('88', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('88', '88'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('88', '88'), ('.', '.')]

>> Lemmatization: 
 [('88', '88'), ('.', '.')]


------------------- Sentence 9 -------------------

Huai Y, Lee R, Zhang S, Xia CH, Zhang X.

>> Tokens are: 
 ['Huai', 'Y', ',', 'Lee', 'R', ',', 'Zhang', 'S', ',', 'Xia', 'CH', ',', 'Zhang', 'X', '.']

>> Bigrams are: 
 [('Huai', 'Y'), ('Y', ','), (',', 'Lee'), ('Lee', 'R'), ('R', ','), (',', 'Zhang'), ('Zhang', 'S'), ('S', ','), (',', 'Xia'), ('Xia', 'CH'), ('CH', ','), (',', 'Zhang'), ('Zhang', 'X'), ('X', '.')]

>> Trigrams are: 
 [('Huai', 'Y', ','), ('Y', ',', 'Lee'), (',', 'Lee', 'R'), ('Lee', 'R', ','), ('R', ',', 'Zhang'), (',', 'Zhang', 'S'), ('Zhang', 'S', ','), ('S', ',', 'Xia'), (',', 'Xia', 'CH'), ('Xia', 'CH', ','), ('CH', ',', 'Zhang'), (',', 'Zhang', 'X'), ('Zhang', 'X', '.')]

>> POS Tags are: 
 [('Huai', 'NNP'), ('Y', 'NNP'), (',', ','), ('Lee', 'NNP'), ('R', 'NNP'), (',', ','), ('Zhang', 'NNP'), ('S', 'NNP'), (',', ','), ('Xia', 'NNP'), ('CH', 'NNP'), (',', ','), ('Zhang', 'NNP'), ('X', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Huai Y', 'Lee R', 'Zhang S', 'Xia CH', 'Zhang X']

>> Named Entities are: 
 [('PERSON', 'Huai'), ('ORGANIZATION', 'Y'), ('PERSON', 'Lee R'), ('PERSON', 'Zhang S'), ('PERSON', 'Xia CH'), ('PERSON', 'Zhang X')] 

>> Stemming using Porter Stemmer: 
 [('Huai', 'huai'), ('Y', 'y'), (',', ','), ('Lee', 'lee'), ('R', 'r'), (',', ','), ('Zhang', 'zhang'), ('S', 's'), (',', ','), ('Xia', 'xia'), ('CH', 'ch'), (',', ','), ('Zhang', 'zhang'), ('X', 'x'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Huai', 'huai'), ('Y', 'y'), (',', ','), ('Lee', 'lee'), ('R', 'r'), (',', ','), ('Zhang', 'zhang'), ('S', 's'), (',', ','), ('Xia', 'xia'), ('CH', 'ch'), (',', ','), ('Zhang', 'zhang'), ('X', 'x'), ('.', '.')]

>> Lemmatization: 
 [('Huai', 'Huai'), ('Y', 'Y'), (',', ','), ('Lee', 'Lee'), ('R', 'R'), (',', ','), ('Zhang', 'Zhang'), ('S', 'S'), (',', ','), ('Xia', 'Xia'), ('CH', 'CH'), (',', ','), ('Zhang', 'Zhang'), ('X', 'X'), ('.', '.')]


------------------- Sentence 10 -------------------

DOT: a matrix model for analyzing, optimizing and deploying software for

>> Tokens are: 
 ['DOT', ':', 'matrix', 'model', 'analyzing', ',', 'optimizing', 'deploying', 'software']

>> Bigrams are: 
 [('DOT', ':'), (':', 'matrix'), ('matrix', 'model'), ('model', 'analyzing'), ('analyzing', ','), (',', 'optimizing'), ('optimizing', 'deploying'), ('deploying', 'software')]

>> Trigrams are: 
 [('DOT', ':', 'matrix'), (':', 'matrix', 'model'), ('matrix', 'model', 'analyzing'), ('model', 'analyzing', ','), ('analyzing', ',', 'optimizing'), (',', 'optimizing', 'deploying'), ('optimizing', 'deploying', 'software')]

>> POS Tags are: 
 [('DOT', 'NN'), (':', ':'), ('matrix', 'NN'), ('model', 'NN'), ('analyzing', 'VBG'), (',', ','), ('optimizing', 'VBG'), ('deploying', 'VBG'), ('software', 'NN')]

>> Noun Phrases are: 
 ['DOT', 'matrix model', 'software']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('DOT', 'dot'), (':', ':'), ('matrix', 'matrix'), ('model', 'model'), ('analyzing', 'analyz'), (',', ','), ('optimizing', 'optim'), ('deploying', 'deploy'), ('software', 'softwar')]

>> Stemming using Snowball Stemmer: 
 [('DOT', 'dot'), (':', ':'), ('matrix', 'matrix'), ('model', 'model'), ('analyzing', 'analyz'), (',', ','), ('optimizing', 'optim'), ('deploying', 'deploy'), ('software', 'softwar')]

>> Lemmatization: 
 [('DOT', 'DOT'), (':', ':'), ('matrix', 'matrix'), ('model', 'model'), ('analyzing', 'analyzing'), (',', ','), ('optimizing', 'optimizing'), ('deploying', 'deploying'), ('software', 'software')]



========================================== PARAGRAPH 478 ===========================================

big data analytics in distributed systems. In: Proceedings of the ACM Symposium on Cloud Computing, 2011. pp  4:1–4:14. 

------------------- Sentence 1 -------------------

big data analytics in distributed systems.

>> Tokens are: 
 ['big', 'data', 'analytics', 'distributed', 'systems', '.']

>> Bigrams are: 
 [('big', 'data'), ('data', 'analytics'), ('analytics', 'distributed'), ('distributed', 'systems'), ('systems', '.')]

>> Trigrams are: 
 [('big', 'data', 'analytics'), ('data', 'analytics', 'distributed'), ('analytics', 'distributed', 'systems'), ('distributed', 'systems', '.')]

>> POS Tags are: 
 [('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('distributed', 'VBD'), ('systems', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['big data analytics', 'systems']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('distributed', 'distribut'), ('systems', 'system'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('distributed', 'distribut'), ('systems', 'system'), ('.', '.')]

>> Lemmatization: 
 [('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('distributed', 'distributed'), ('systems', 'system'), ('.', '.')]


------------------- Sentence 2 -------------------

In: Proceedings of the ACM Symposium on Cloud Computing, 2011. pp  4:1–4:14.

>> Tokens are: 
 ['In', ':', 'Proceedings', 'ACM', 'Symposium', 'Cloud', 'Computing', ',', '2011.', 'pp', '4:1–4:14', '.']

>> Bigrams are: 
 [('In', ':'), (':', 'Proceedings'), ('Proceedings', 'ACM'), ('ACM', 'Symposium'), ('Symposium', 'Cloud'), ('Cloud', 'Computing'), ('Computing', ','), (',', '2011.'), ('2011.', 'pp'), ('pp', '4:1–4:14'), ('4:1–4:14', '.')]

>> Trigrams are: 
 [('In', ':', 'Proceedings'), (':', 'Proceedings', 'ACM'), ('Proceedings', 'ACM', 'Symposium'), ('ACM', 'Symposium', 'Cloud'), ('Symposium', 'Cloud', 'Computing'), ('Cloud', 'Computing', ','), ('Computing', ',', '2011.'), (',', '2011.', 'pp'), ('2011.', 'pp', '4:1–4:14'), ('pp', '4:1–4:14', '.')]

>> POS Tags are: 
 [('In', 'IN'), (':', ':'), ('Proceedings', 'NNS'), ('ACM', 'NNP'), ('Symposium', 'NNP'), ('Cloud', 'NNP'), ('Computing', 'NNP'), (',', ','), ('2011.', 'CD'), ('pp', 'NN'), ('4:1–4:14', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Proceedings ACM Symposium Cloud Computing', 'pp']

>> Named Entities are: 
 [('ORGANIZATION', 'ACM Symposium Cloud')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), (':', ':'), ('Proceedings', 'proceed'), ('ACM', 'acm'), ('Symposium', 'symposium'), ('Cloud', 'cloud'), ('Computing', 'comput'), (',', ','), ('2011.', '2011.'), ('pp', 'pp'), ('4:1–4:14', '4:1–4:14'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), (':', ':'), ('Proceedings', 'proceed'), ('ACM', 'acm'), ('Symposium', 'symposium'), ('Cloud', 'cloud'), ('Computing', 'comput'), (',', ','), ('2011.', '2011.'), ('pp', 'pp'), ('4:1–4:14', '4:1–4:14'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), (':', ':'), ('Proceedings', 'Proceedings'), ('ACM', 'ACM'), ('Symposium', 'Symposium'), ('Cloud', 'Cloud'), ('Computing', 'Computing'), (',', ','), ('2011.', '2011.'), ('pp', 'pp'), ('4:1–4:14', '4:1–4:14'), ('.', '.')]



========================================== PARAGRAPH 479 ===========================================

 89. Rusu F, Dobra A. GLADE: a scalable framework for efficient analytics. In: Proceedings of LADIS Workshop held in  conjunction with VLDB, 2012. pp 1–6. 

------------------- Sentence 1 -------------------

 89.

>> Tokens are: 
 ['89', '.']

>> Bigrams are: 
 [('89', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('89', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('89', '89'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('89', '89'), ('.', '.')]

>> Lemmatization: 
 [('89', '89'), ('.', '.')]


------------------- Sentence 2 -------------------

Rusu F, Dobra A. GLADE: a scalable framework for efficient analytics.

>> Tokens are: 
 ['Rusu', 'F', ',', 'Dobra', 'A.', 'GLADE', ':', 'scalable', 'framework', 'efficient', 'analytics', '.']

>> Bigrams are: 
 [('Rusu', 'F'), ('F', ','), (',', 'Dobra'), ('Dobra', 'A.'), ('A.', 'GLADE'), ('GLADE', ':'), (':', 'scalable'), ('scalable', 'framework'), ('framework', 'efficient'), ('efficient', 'analytics'), ('analytics', '.')]

>> Trigrams are: 
 [('Rusu', 'F', ','), ('F', ',', 'Dobra'), (',', 'Dobra', 'A.'), ('Dobra', 'A.', 'GLADE'), ('A.', 'GLADE', ':'), ('GLADE', ':', 'scalable'), (':', 'scalable', 'framework'), ('scalable', 'framework', 'efficient'), ('framework', 'efficient', 'analytics'), ('efficient', 'analytics', '.')]

>> POS Tags are: 
 [('Rusu', 'NNP'), ('F', 'NNP'), (',', ','), ('Dobra', 'NNP'), ('A.', 'NN'), ('GLADE', 'NNP'), (':', ':'), ('scalable', 'JJ'), ('framework', 'NN'), ('efficient', 'JJ'), ('analytics', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['Rusu F', 'Dobra A. GLADE', 'scalable framework', 'efficient analytics']

>> Named Entities are: 
 [('GPE', 'Rusu'), ('ORGANIZATION', 'F'), ('PERSON', 'Dobra')] 

>> Stemming using Porter Stemmer: 
 [('Rusu', 'rusu'), ('F', 'f'), (',', ','), ('Dobra', 'dobra'), ('A.', 'a.'), ('GLADE', 'glade'), (':', ':'), ('scalable', 'scalabl'), ('framework', 'framework'), ('efficient', 'effici'), ('analytics', 'analyt'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Rusu', 'rusu'), ('F', 'f'), (',', ','), ('Dobra', 'dobra'), ('A.', 'a.'), ('GLADE', 'glade'), (':', ':'), ('scalable', 'scalabl'), ('framework', 'framework'), ('efficient', 'effici'), ('analytics', 'analyt'), ('.', '.')]

>> Lemmatization: 
 [('Rusu', 'Rusu'), ('F', 'F'), (',', ','), ('Dobra', 'Dobra'), ('A.', 'A.'), ('GLADE', 'GLADE'), (':', ':'), ('scalable', 'scalable'), ('framework', 'framework'), ('efficient', 'efficient'), ('analytics', 'analytics'), ('.', '.')]


------------------- Sentence 3 -------------------

In: Proceedings of LADIS Workshop held in  conjunction with VLDB, 2012. pp 1–6.

>> Tokens are: 
 ['In', ':', 'Proceedings', 'LADIS', 'Workshop', 'held', 'conjunction', 'VLDB', ',', '2012.', 'pp', '1–6', '.']

>> Bigrams are: 
 [('In', ':'), (':', 'Proceedings'), ('Proceedings', 'LADIS'), ('LADIS', 'Workshop'), ('Workshop', 'held'), ('held', 'conjunction'), ('conjunction', 'VLDB'), ('VLDB', ','), (',', '2012.'), ('2012.', 'pp'), ('pp', '1–6'), ('1–6', '.')]

>> Trigrams are: 
 [('In', ':', 'Proceedings'), (':', 'Proceedings', 'LADIS'), ('Proceedings', 'LADIS', 'Workshop'), ('LADIS', 'Workshop', 'held'), ('Workshop', 'held', 'conjunction'), ('held', 'conjunction', 'VLDB'), ('conjunction', 'VLDB', ','), ('VLDB', ',', '2012.'), (',', '2012.', 'pp'), ('2012.', 'pp', '1–6'), ('pp', '1–6', '.')]

>> POS Tags are: 
 [('In', 'IN'), (':', ':'), ('Proceedings', 'NNS'), ('LADIS', 'NNP'), ('Workshop', 'NNP'), ('held', 'VBD'), ('conjunction', 'NN'), ('VLDB', 'NNP'), (',', ','), ('2012.', 'CD'), ('pp', 'NN'), ('1–6', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Proceedings LADIS Workshop', 'conjunction VLDB', 'pp']

>> Named Entities are: 
 [('ORGANIZATION', 'LADIS Workshop'), ('ORGANIZATION', 'VLDB')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), (':', ':'), ('Proceedings', 'proceed'), ('LADIS', 'ladi'), ('Workshop', 'workshop'), ('held', 'held'), ('conjunction', 'conjunct'), ('VLDB', 'vldb'), (',', ','), ('2012.', '2012.'), ('pp', 'pp'), ('1–6', '1–6'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), (':', ':'), ('Proceedings', 'proceed'), ('LADIS', 'ladi'), ('Workshop', 'workshop'), ('held', 'held'), ('conjunction', 'conjunct'), ('VLDB', 'vldb'), (',', ','), ('2012.', '2012.'), ('pp', 'pp'), ('1–6', '1–6'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), (':', ':'), ('Proceedings', 'Proceedings'), ('LADIS', 'LADIS'), ('Workshop', 'Workshop'), ('held', 'held'), ('conjunction', 'conjunction'), ('VLDB', 'VLDB'), (',', ','), ('2012.', '2012.'), ('pp', 'pp'), ('1–6', '1–6'), ('.', '.')]



========================================== PARAGRAPH 480 ===========================================

 90. Cheng Y, Qin C, Rusu F. GLADE: big data analytics made easy. In: Proceedings of the ACM SIGMOD International  Conference on Management of Data, 2012. pp 697–700. 

------------------- Sentence 1 -------------------

 90.

>> Tokens are: 
 ['90', '.']

>> Bigrams are: 
 [('90', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('90', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('90', '90'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('90', '90'), ('.', '.')]

>> Lemmatization: 
 [('90', '90'), ('.', '.')]


------------------- Sentence 2 -------------------

Cheng Y, Qin C, Rusu F. GLADE: big data analytics made easy.

>> Tokens are: 
 ['Cheng', 'Y', ',', 'Qin', 'C', ',', 'Rusu', 'F.', 'GLADE', ':', 'big', 'data', 'analytics', 'made', 'easy', '.']

>> Bigrams are: 
 [('Cheng', 'Y'), ('Y', ','), (',', 'Qin'), ('Qin', 'C'), ('C', ','), (',', 'Rusu'), ('Rusu', 'F.'), ('F.', 'GLADE'), ('GLADE', ':'), (':', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', 'made'), ('made', 'easy'), ('easy', '.')]

>> Trigrams are: 
 [('Cheng', 'Y', ','), ('Y', ',', 'Qin'), (',', 'Qin', 'C'), ('Qin', 'C', ','), ('C', ',', 'Rusu'), (',', 'Rusu', 'F.'), ('Rusu', 'F.', 'GLADE'), ('F.', 'GLADE', ':'), ('GLADE', ':', 'big'), (':', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', 'made'), ('analytics', 'made', 'easy'), ('made', 'easy', '.')]

>> POS Tags are: 
 [('Cheng', 'NNP'), ('Y', 'NNP'), (',', ','), ('Qin', 'NNP'), ('C', 'NNP'), (',', ','), ('Rusu', 'NNP'), ('F.', 'NNP'), ('GLADE', 'NNP'), (':', ':'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('made', 'VBD'), ('easy', 'JJ'), ('.', '.')]

>> Noun Phrases are: 
 ['Cheng Y', 'Qin C', 'Rusu F. GLADE', 'big data analytics']

>> Named Entities are: 
 [('PERSON', 'Cheng'), ('ORGANIZATION', 'Y'), ('PERSON', 'Qin C'), ('PERSON', 'Rusu F.')] 

>> Stemming using Porter Stemmer: 
 [('Cheng', 'cheng'), ('Y', 'y'), (',', ','), ('Qin', 'qin'), ('C', 'c'), (',', ','), ('Rusu', 'rusu'), ('F.', 'f.'), ('GLADE', 'glade'), (':', ':'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('made', 'made'), ('easy', 'easi'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Cheng', 'cheng'), ('Y', 'y'), (',', ','), ('Qin', 'qin'), ('C', 'c'), (',', ','), ('Rusu', 'rusu'), ('F.', 'f.'), ('GLADE', 'glade'), (':', ':'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('made', 'made'), ('easy', 'easi'), ('.', '.')]

>> Lemmatization: 
 [('Cheng', 'Cheng'), ('Y', 'Y'), (',', ','), ('Qin', 'Qin'), ('C', 'C'), (',', ','), ('Rusu', 'Rusu'), ('F.', 'F.'), ('GLADE', 'GLADE'), (':', ':'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('made', 'made'), ('easy', 'easy'), ('.', '.')]


------------------- Sentence 3 -------------------

In: Proceedings of the ACM SIGMOD International  Conference on Management of Data, 2012. pp 697–700.

>> Tokens are: 
 ['In', ':', 'Proceedings', 'ACM', 'SIGMOD', 'International', 'Conference', 'Management', 'Data', ',', '2012.', 'pp', '697–700', '.']

>> Bigrams are: 
 [('In', ':'), (':', 'Proceedings'), ('Proceedings', 'ACM'), ('ACM', 'SIGMOD'), ('SIGMOD', 'International'), ('International', 'Conference'), ('Conference', 'Management'), ('Management', 'Data'), ('Data', ','), (',', '2012.'), ('2012.', 'pp'), ('pp', '697–700'), ('697–700', '.')]

>> Trigrams are: 
 [('In', ':', 'Proceedings'), (':', 'Proceedings', 'ACM'), ('Proceedings', 'ACM', 'SIGMOD'), ('ACM', 'SIGMOD', 'International'), ('SIGMOD', 'International', 'Conference'), ('International', 'Conference', 'Management'), ('Conference', 'Management', 'Data'), ('Management', 'Data', ','), ('Data', ',', '2012.'), (',', '2012.', 'pp'), ('2012.', 'pp', '697–700'), ('pp', '697–700', '.')]

>> POS Tags are: 
 [('In', 'IN'), (':', ':'), ('Proceedings', 'NNS'), ('ACM', 'NNP'), ('SIGMOD', 'NNP'), ('International', 'NNP'), ('Conference', 'NNP'), ('Management', 'NNP'), ('Data', 'NNP'), (',', ','), ('2012.', 'CD'), ('pp', 'NN'), ('697–700', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Proceedings ACM SIGMOD International Conference Management Data', 'pp']

>> Named Entities are: 
 [('ORGANIZATION', 'ACM'), ('ORGANIZATION', 'SIGMOD International Conference Management Data')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), (':', ':'), ('Proceedings', 'proceed'), ('ACM', 'acm'), ('SIGMOD', 'sigmod'), ('International', 'intern'), ('Conference', 'confer'), ('Management', 'manag'), ('Data', 'data'), (',', ','), ('2012.', '2012.'), ('pp', 'pp'), ('697–700', '697–700'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), (':', ':'), ('Proceedings', 'proceed'), ('ACM', 'acm'), ('SIGMOD', 'sigmod'), ('International', 'intern'), ('Conference', 'confer'), ('Management', 'manag'), ('Data', 'data'), (',', ','), ('2012.', '2012.'), ('pp', 'pp'), ('697–700', '697–700'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), (':', ':'), ('Proceedings', 'Proceedings'), ('ACM', 'ACM'), ('SIGMOD', 'SIGMOD'), ('International', 'International'), ('Conference', 'Conference'), ('Management', 'Management'), ('Data', 'Data'), (',', ','), ('2012.', '2012.'), ('pp', 'pp'), ('697–700', '697–700'), ('.', '.')]



========================================== PARAGRAPH 481 ===========================================

 91. Essa YM, Attiya G, El‑Sayed A. Mobile agent based new framework for improving big data analysis. In: Proceedings  of the International Conference on Cloud Computing and Big Data. 2013, pp 381–386. 

------------------- Sentence 1 -------------------

 91.

>> Tokens are: 
 ['91', '.']

>> Bigrams are: 
 [('91', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('91', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('91', '91'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('91', '91'), ('.', '.')]

>> Lemmatization: 
 [('91', '91'), ('.', '.')]


------------------- Sentence 2 -------------------

Essa YM, Attiya G, El‑Sayed A.

>> Tokens are: 
 ['Essa', 'YM', ',', 'Attiya', 'G', ',', 'El‑Sayed', 'A', '.']

>> Bigrams are: 
 [('Essa', 'YM'), ('YM', ','), (',', 'Attiya'), ('Attiya', 'G'), ('G', ','), (',', 'El‑Sayed'), ('El‑Sayed', 'A'), ('A', '.')]

>> Trigrams are: 
 [('Essa', 'YM', ','), ('YM', ',', 'Attiya'), (',', 'Attiya', 'G'), ('Attiya', 'G', ','), ('G', ',', 'El‑Sayed'), (',', 'El‑Sayed', 'A'), ('El‑Sayed', 'A', '.')]

>> POS Tags are: 
 [('Essa', 'NNP'), ('YM', 'NNP'), (',', ','), ('Attiya', 'NNP'), ('G', 'NNP'), (',', ','), ('El‑Sayed', 'VBD'), ('A', 'DT'), ('.', '.')]

>> Noun Phrases are: 
 ['Essa YM', 'Attiya G']

>> Named Entities are: 
 [('PERSON', 'Essa'), ('GPE', 'YM'), ('PERSON', 'Attiya G')] 

>> Stemming using Porter Stemmer: 
 [('Essa', 'essa'), ('YM', 'ym'), (',', ','), ('Attiya', 'attiya'), ('G', 'g'), (',', ','), ('El‑Sayed', 'el‑say'), ('A', 'a'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Essa', 'essa'), ('YM', 'ym'), (',', ','), ('Attiya', 'attiya'), ('G', 'g'), (',', ','), ('El‑Sayed', 'el‑say'), ('A', 'a'), ('.', '.')]

>> Lemmatization: 
 [('Essa', 'Essa'), ('YM', 'YM'), (',', ','), ('Attiya', 'Attiya'), ('G', 'G'), (',', ','), ('El‑Sayed', 'El‑Sayed'), ('A', 'A'), ('.', '.')]


------------------- Sentence 3 -------------------

Mobile agent based new framework for improving big data analysis.

>> Tokens are: 
 ['Mobile', 'agent', 'based', 'new', 'framework', 'improving', 'big', 'data', 'analysis', '.']

>> Bigrams are: 
 [('Mobile', 'agent'), ('agent', 'based'), ('based', 'new'), ('new', 'framework'), ('framework', 'improving'), ('improving', 'big'), ('big', 'data'), ('data', 'analysis'), ('analysis', '.')]

>> Trigrams are: 
 [('Mobile', 'agent', 'based'), ('agent', 'based', 'new'), ('based', 'new', 'framework'), ('new', 'framework', 'improving'), ('framework', 'improving', 'big'), ('improving', 'big', 'data'), ('big', 'data', 'analysis'), ('data', 'analysis', '.')]

>> POS Tags are: 
 [('Mobile', 'NNP'), ('agent', 'NN'), ('based', 'VBN'), ('new', 'JJ'), ('framework', 'NN'), ('improving', 'VBG'), ('big', 'JJ'), ('data', 'NNS'), ('analysis', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Mobile agent', 'new framework', 'big data analysis']

>> Named Entities are: 
 [('GPE', 'Mobile')] 

>> Stemming using Porter Stemmer: 
 [('Mobile', 'mobil'), ('agent', 'agent'), ('based', 'base'), ('new', 'new'), ('framework', 'framework'), ('improving', 'improv'), ('big', 'big'), ('data', 'data'), ('analysis', 'analysi'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Mobile', 'mobil'), ('agent', 'agent'), ('based', 'base'), ('new', 'new'), ('framework', 'framework'), ('improving', 'improv'), ('big', 'big'), ('data', 'data'), ('analysis', 'analysi'), ('.', '.')]

>> Lemmatization: 
 [('Mobile', 'Mobile'), ('agent', 'agent'), ('based', 'based'), ('new', 'new'), ('framework', 'framework'), ('improving', 'improving'), ('big', 'big'), ('data', 'data'), ('analysis', 'analysis'), ('.', '.')]


------------------- Sentence 4 -------------------

In: Proceedings  of the International Conference on Cloud Computing and Big Data.

>> Tokens are: 
 ['In', ':', 'Proceedings', 'International', 'Conference', 'Cloud', 'Computing', 'Big', 'Data', '.']

>> Bigrams are: 
 [('In', ':'), (':', 'Proceedings'), ('Proceedings', 'International'), ('International', 'Conference'), ('Conference', 'Cloud'), ('Cloud', 'Computing'), ('Computing', 'Big'), ('Big', 'Data'), ('Data', '.')]

>> Trigrams are: 
 [('In', ':', 'Proceedings'), (':', 'Proceedings', 'International'), ('Proceedings', 'International', 'Conference'), ('International', 'Conference', 'Cloud'), ('Conference', 'Cloud', 'Computing'), ('Cloud', 'Computing', 'Big'), ('Computing', 'Big', 'Data'), ('Big', 'Data', '.')]

>> POS Tags are: 
 [('In', 'IN'), (':', ':'), ('Proceedings', 'NNS'), ('International', 'NNP'), ('Conference', 'NNP'), ('Cloud', 'NNP'), ('Computing', 'NNP'), ('Big', 'NNP'), ('Data', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Proceedings International Conference Cloud Computing Big Data']

>> Named Entities are: 
 [('ORGANIZATION', 'International Conference Cloud')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), (':', ':'), ('Proceedings', 'proceed'), ('International', 'intern'), ('Conference', 'confer'), ('Cloud', 'cloud'), ('Computing', 'comput'), ('Big', 'big'), ('Data', 'data'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), (':', ':'), ('Proceedings', 'proceed'), ('International', 'intern'), ('Conference', 'confer'), ('Cloud', 'cloud'), ('Computing', 'comput'), ('Big', 'big'), ('Data', 'data'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), (':', ':'), ('Proceedings', 'Proceedings'), ('International', 'International'), ('Conference', 'Conference'), ('Cloud', 'Cloud'), ('Computing', 'Computing'), ('Big', 'Big'), ('Data', 'Data'), ('.', '.')]


------------------- Sentence 5 -------------------

2013, pp 381–386.

>> Tokens are: 
 ['2013', ',', 'pp', '381–386', '.']

>> Bigrams are: 
 [('2013', ','), (',', 'pp'), ('pp', '381–386'), ('381–386', '.')]

>> Trigrams are: 
 [('2013', ',', 'pp'), (',', 'pp', '381–386'), ('pp', '381–386', '.')]

>> POS Tags are: 
 [('2013', 'CD'), (',', ','), ('pp', 'VBD'), ('381–386', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('2013', '2013'), (',', ','), ('pp', 'pp'), ('381–386', '381–386'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('2013', '2013'), (',', ','), ('pp', 'pp'), ('381–386', '381–386'), ('.', '.')]

>> Lemmatization: 
 [('2013', '2013'), (',', ','), ('pp', 'pp'), ('381–386', '381–386'), ('.', '.')]



========================================== PARAGRAPH 482 ===========================================

 92. Wonner J, Grosjean J, Capobianco A, Bechmann D Starfish: a selection technique for dense virtual environments.  In: Proceedings of the ACM Symposium on Virtual Reality Software and Technology, 2012. pp 101–104. 

------------------- Sentence 1 -------------------

 92.

>> Tokens are: 
 ['92', '.']

>> Bigrams are: 
 [('92', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('92', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('92', '92'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('92', '92'), ('.', '.')]

>> Lemmatization: 
 [('92', '92'), ('.', '.')]


------------------- Sentence 2 -------------------

Wonner J, Grosjean J, Capobianco A, Bechmann D Starfish: a selection technique for dense virtual environments.

>> Tokens are: 
 ['Wonner', 'J', ',', 'Grosjean', 'J', ',', 'Capobianco', 'A', ',', 'Bechmann', 'D', 'Starfish', ':', 'selection', 'technique', 'dense', 'virtual', 'environments', '.']

>> Bigrams are: 
 [('Wonner', 'J'), ('J', ','), (',', 'Grosjean'), ('Grosjean', 'J'), ('J', ','), (',', 'Capobianco'), ('Capobianco', 'A'), ('A', ','), (',', 'Bechmann'), ('Bechmann', 'D'), ('D', 'Starfish'), ('Starfish', ':'), (':', 'selection'), ('selection', 'technique'), ('technique', 'dense'), ('dense', 'virtual'), ('virtual', 'environments'), ('environments', '.')]

>> Trigrams are: 
 [('Wonner', 'J', ','), ('J', ',', 'Grosjean'), (',', 'Grosjean', 'J'), ('Grosjean', 'J', ','), ('J', ',', 'Capobianco'), (',', 'Capobianco', 'A'), ('Capobianco', 'A', ','), ('A', ',', 'Bechmann'), (',', 'Bechmann', 'D'), ('Bechmann', 'D', 'Starfish'), ('D', 'Starfish', ':'), ('Starfish', ':', 'selection'), (':', 'selection', 'technique'), ('selection', 'technique', 'dense'), ('technique', 'dense', 'virtual'), ('dense', 'virtual', 'environments'), ('virtual', 'environments', '.')]

>> POS Tags are: 
 [('Wonner', 'NNP'), ('J', 'NNP'), (',', ','), ('Grosjean', 'NNP'), ('J', 'NNP'), (',', ','), ('Capobianco', 'NNP'), ('A', 'NNP'), (',', ','), ('Bechmann', 'NNP'), ('D', 'NNP'), ('Starfish', 'NNP'), (':', ':'), ('selection', 'NN'), ('technique', 'NN'), ('dense', 'VBP'), ('virtual', 'JJ'), ('environments', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['Wonner J', 'Grosjean J', 'Capobianco A', 'Bechmann D Starfish', 'selection technique', 'virtual environments']

>> Named Entities are: 
 [('PERSON', 'Wonner'), ('ORGANIZATION', 'J'), ('PERSON', 'Grosjean J'), ('PERSON', 'Capobianco A'), ('PERSON', 'Bechmann D Starfish')] 

>> Stemming using Porter Stemmer: 
 [('Wonner', 'wonner'), ('J', 'j'), (',', ','), ('Grosjean', 'grosjean'), ('J', 'j'), (',', ','), ('Capobianco', 'capobianco'), ('A', 'a'), (',', ','), ('Bechmann', 'bechmann'), ('D', 'd'), ('Starfish', 'starfish'), (':', ':'), ('selection', 'select'), ('technique', 'techniqu'), ('dense', 'dens'), ('virtual', 'virtual'), ('environments', 'environ'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Wonner', 'wonner'), ('J', 'j'), (',', ','), ('Grosjean', 'grosjean'), ('J', 'j'), (',', ','), ('Capobianco', 'capobianco'), ('A', 'a'), (',', ','), ('Bechmann', 'bechmann'), ('D', 'd'), ('Starfish', 'starfish'), (':', ':'), ('selection', 'select'), ('technique', 'techniqu'), ('dense', 'dens'), ('virtual', 'virtual'), ('environments', 'environ'), ('.', '.')]

>> Lemmatization: 
 [('Wonner', 'Wonner'), ('J', 'J'), (',', ','), ('Grosjean', 'Grosjean'), ('J', 'J'), (',', ','), ('Capobianco', 'Capobianco'), ('A', 'A'), (',', ','), ('Bechmann', 'Bechmann'), ('D', 'D'), ('Starfish', 'Starfish'), (':', ':'), ('selection', 'selection'), ('technique', 'technique'), ('dense', 'dense'), ('virtual', 'virtual'), ('environments', 'environment'), ('.', '.')]


------------------- Sentence 3 -------------------

In: Proceedings of the ACM Symposium on Virtual Reality Software and Technology, 2012. pp 101–104.

>> Tokens are: 
 ['In', ':', 'Proceedings', 'ACM', 'Symposium', 'Virtual', 'Reality', 'Software', 'Technology', ',', '2012.', 'pp', '101–104', '.']

>> Bigrams are: 
 [('In', ':'), (':', 'Proceedings'), ('Proceedings', 'ACM'), ('ACM', 'Symposium'), ('Symposium', 'Virtual'), ('Virtual', 'Reality'), ('Reality', 'Software'), ('Software', 'Technology'), ('Technology', ','), (',', '2012.'), ('2012.', 'pp'), ('pp', '101–104'), ('101–104', '.')]

>> Trigrams are: 
 [('In', ':', 'Proceedings'), (':', 'Proceedings', 'ACM'), ('Proceedings', 'ACM', 'Symposium'), ('ACM', 'Symposium', 'Virtual'), ('Symposium', 'Virtual', 'Reality'), ('Virtual', 'Reality', 'Software'), ('Reality', 'Software', 'Technology'), ('Software', 'Technology', ','), ('Technology', ',', '2012.'), (',', '2012.', 'pp'), ('2012.', 'pp', '101–104'), ('pp', '101–104', '.')]

>> POS Tags are: 
 [('In', 'IN'), (':', ':'), ('Proceedings', 'NNS'), ('ACM', 'NNP'), ('Symposium', 'NNP'), ('Virtual', 'NNP'), ('Reality', 'NNP'), ('Software', 'NNP'), ('Technology', 'NNP'), (',', ','), ('2012.', 'CD'), ('pp', 'NN'), ('101–104', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Proceedings ACM Symposium Virtual Reality Software Technology', 'pp']

>> Named Entities are: 
 [('ORGANIZATION', 'ACM Symposium Virtual Reality Software Technology')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), (':', ':'), ('Proceedings', 'proceed'), ('ACM', 'acm'), ('Symposium', 'symposium'), ('Virtual', 'virtual'), ('Reality', 'realiti'), ('Software', 'softwar'), ('Technology', 'technolog'), (',', ','), ('2012.', '2012.'), ('pp', 'pp'), ('101–104', '101–104'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), (':', ':'), ('Proceedings', 'proceed'), ('ACM', 'acm'), ('Symposium', 'symposium'), ('Virtual', 'virtual'), ('Reality', 'realiti'), ('Software', 'softwar'), ('Technology', 'technolog'), (',', ','), ('2012.', '2012.'), ('pp', 'pp'), ('101–104', '101–104'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), (':', ':'), ('Proceedings', 'Proceedings'), ('ACM', 'ACM'), ('Symposium', 'Symposium'), ('Virtual', 'Virtual'), ('Reality', 'Reality'), ('Software', 'Software'), ('Technology', 'Technology'), (',', ','), ('2012.', '2012.'), ('pp', 'pp'), ('101–104', '101–104'), ('.', '.')]



========================================== PARAGRAPH 483 ===========================================

 93. Demchenko Y, de Laat C, Membrey P. Defining architecture components of the big data ecosystem. In: Proceed‑ ings of the International Conference on Collaboration Technologies and Systems, 2014. pp 104–112. 

------------------- Sentence 1 -------------------

 93.

>> Tokens are: 
 ['93', '.']

>> Bigrams are: 
 [('93', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('93', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('93', '93'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('93', '93'), ('.', '.')]

>> Lemmatization: 
 [('93', '93'), ('.', '.')]


------------------- Sentence 2 -------------------

Demchenko Y, de Laat C, Membrey P. Defining architecture components of the big data ecosystem.

>> Tokens are: 
 ['Demchenko', 'Y', ',', 'de', 'Laat', 'C', ',', 'Membrey', 'P.', 'Defining', 'architecture', 'components', 'big', 'data', 'ecosystem', '.']

>> Bigrams are: 
 [('Demchenko', 'Y'), ('Y', ','), (',', 'de'), ('de', 'Laat'), ('Laat', 'C'), ('C', ','), (',', 'Membrey'), ('Membrey', 'P.'), ('P.', 'Defining'), ('Defining', 'architecture'), ('architecture', 'components'), ('components', 'big'), ('big', 'data'), ('data', 'ecosystem'), ('ecosystem', '.')]

>> Trigrams are: 
 [('Demchenko', 'Y', ','), ('Y', ',', 'de'), (',', 'de', 'Laat'), ('de', 'Laat', 'C'), ('Laat', 'C', ','), ('C', ',', 'Membrey'), (',', 'Membrey', 'P.'), ('Membrey', 'P.', 'Defining'), ('P.', 'Defining', 'architecture'), ('Defining', 'architecture', 'components'), ('architecture', 'components', 'big'), ('components', 'big', 'data'), ('big', 'data', 'ecosystem'), ('data', 'ecosystem', '.')]

>> POS Tags are: 
 [('Demchenko', 'NNP'), ('Y', 'NNP'), (',', ','), ('de', 'FW'), ('Laat', 'NNP'), ('C', 'NNP'), (',', ','), ('Membrey', 'NNP'), ('P.', 'NNP'), ('Defining', 'NNP'), ('architecture', 'NN'), ('components', 'NNS'), ('big', 'JJ'), ('data', 'NNS'), ('ecosystem', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Demchenko Y', 'Laat C', 'Membrey P. Defining architecture components', 'big data ecosystem']

>> Named Entities are: 
 [('PERSON', 'Demchenko'), ('ORGANIZATION', 'Y'), ('PERSON', 'Laat C'), ('PERSON', 'Membrey P. Defining')] 

>> Stemming using Porter Stemmer: 
 [('Demchenko', 'demchenko'), ('Y', 'y'), (',', ','), ('de', 'de'), ('Laat', 'laat'), ('C', 'c'), (',', ','), ('Membrey', 'membrey'), ('P.', 'p.'), ('Defining', 'defin'), ('architecture', 'architectur'), ('components', 'compon'), ('big', 'big'), ('data', 'data'), ('ecosystem', 'ecosystem'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Demchenko', 'demchenko'), ('Y', 'y'), (',', ','), ('de', 'de'), ('Laat', 'laat'), ('C', 'c'), (',', ','), ('Membrey', 'membrey'), ('P.', 'p.'), ('Defining', 'defin'), ('architecture', 'architectur'), ('components', 'compon'), ('big', 'big'), ('data', 'data'), ('ecosystem', 'ecosystem'), ('.', '.')]

>> Lemmatization: 
 [('Demchenko', 'Demchenko'), ('Y', 'Y'), (',', ','), ('de', 'de'), ('Laat', 'Laat'), ('C', 'C'), (',', ','), ('Membrey', 'Membrey'), ('P.', 'P.'), ('Defining', 'Defining'), ('architecture', 'architecture'), ('components', 'component'), ('big', 'big'), ('data', 'data'), ('ecosystem', 'ecosystem'), ('.', '.')]


------------------- Sentence 3 -------------------

In: Proceed‑ ings of the International Conference on Collaboration Technologies and Systems, 2014. pp 104–112.

>> Tokens are: 
 ['In', ':', 'Proceed‑', 'ings', 'International', 'Conference', 'Collaboration', 'Technologies', 'Systems', ',', '2014.', 'pp', '104–112', '.']

>> Bigrams are: 
 [('In', ':'), (':', 'Proceed‑'), ('Proceed‑', 'ings'), ('ings', 'International'), ('International', 'Conference'), ('Conference', 'Collaboration'), ('Collaboration', 'Technologies'), ('Technologies', 'Systems'), ('Systems', ','), (',', '2014.'), ('2014.', 'pp'), ('pp', '104–112'), ('104–112', '.')]

>> Trigrams are: 
 [('In', ':', 'Proceed‑'), (':', 'Proceed‑', 'ings'), ('Proceed‑', 'ings', 'International'), ('ings', 'International', 'Conference'), ('International', 'Conference', 'Collaboration'), ('Conference', 'Collaboration', 'Technologies'), ('Collaboration', 'Technologies', 'Systems'), ('Technologies', 'Systems', ','), ('Systems', ',', '2014.'), (',', '2014.', 'pp'), ('2014.', 'pp', '104–112'), ('pp', '104–112', '.')]

>> POS Tags are: 
 [('In', 'IN'), (':', ':'), ('Proceed‑', 'NNP'), ('ings', 'VBZ'), ('International', 'NNP'), ('Conference', 'NNP'), ('Collaboration', 'NNP'), ('Technologies', 'NNPS'), ('Systems', 'NNP'), (',', ','), ('2014.', 'CD'), ('pp', 'NN'), ('104–112', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Proceed‑', 'International Conference Collaboration', 'Systems', 'pp']

>> Named Entities are: 
 [('ORGANIZATION', 'International Conference Collaboration Technologies Systems')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), (':', ':'), ('Proceed‑', 'proceed‑'), ('ings', 'ing'), ('International', 'intern'), ('Conference', 'confer'), ('Collaboration', 'collabor'), ('Technologies', 'technolog'), ('Systems', 'system'), (',', ','), ('2014.', '2014.'), ('pp', 'pp'), ('104–112', '104–112'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), (':', ':'), ('Proceed‑', 'proceed‑'), ('ings', 'ing'), ('International', 'intern'), ('Conference', 'confer'), ('Collaboration', 'collabor'), ('Technologies', 'technolog'), ('Systems', 'system'), (',', ','), ('2014.', '2014.'), ('pp', 'pp'), ('104–112', '104–112'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), (':', ':'), ('Proceed‑', 'Proceed‑'), ('ings', 'ings'), ('International', 'International'), ('Conference', 'Conference'), ('Collaboration', 'Collaboration'), ('Technologies', 'Technologies'), ('Systems', 'Systems'), (',', ','), ('2014.', '2014.'), ('pp', 'pp'), ('104–112', '104–112'), ('.', '.')]



========================================== PARAGRAPH 484 ===========================================

 94. Ye F, Wang ZJ, Zhou FC, Wang YP, Zhou YC. Cloud‑based big data mining and analyzing services platform integrat‑ ing r. In: Proceedings of the International Conference on Advanced Cloud and Big Data, 2013. pp 147–151. 

------------------- Sentence 1 -------------------

 94.

>> Tokens are: 
 ['94', '.']

>> Bigrams are: 
 [('94', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('94', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('94', '94'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('94', '94'), ('.', '.')]

>> Lemmatization: 
 [('94', '94'), ('.', '.')]


------------------- Sentence 2 -------------------

Ye F, Wang ZJ, Zhou FC, Wang YP, Zhou YC.

>> Tokens are: 
 ['Ye', 'F', ',', 'Wang', 'ZJ', ',', 'Zhou', 'FC', ',', 'Wang', 'YP', ',', 'Zhou', 'YC', '.']

>> Bigrams are: 
 [('Ye', 'F'), ('F', ','), (',', 'Wang'), ('Wang', 'ZJ'), ('ZJ', ','), (',', 'Zhou'), ('Zhou', 'FC'), ('FC', ','), (',', 'Wang'), ('Wang', 'YP'), ('YP', ','), (',', 'Zhou'), ('Zhou', 'YC'), ('YC', '.')]

>> Trigrams are: 
 [('Ye', 'F', ','), ('F', ',', 'Wang'), (',', 'Wang', 'ZJ'), ('Wang', 'ZJ', ','), ('ZJ', ',', 'Zhou'), (',', 'Zhou', 'FC'), ('Zhou', 'FC', ','), ('FC', ',', 'Wang'), (',', 'Wang', 'YP'), ('Wang', 'YP', ','), ('YP', ',', 'Zhou'), (',', 'Zhou', 'YC'), ('Zhou', 'YC', '.')]

>> POS Tags are: 
 [('Ye', 'NNP'), ('F', 'NNP'), (',', ','), ('Wang', 'NNP'), ('ZJ', 'NNP'), (',', ','), ('Zhou', 'NNP'), ('FC', 'NNP'), (',', ','), ('Wang', 'NNP'), ('YP', 'NNP'), (',', ','), ('Zhou', 'NNP'), ('YC', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Ye F', 'Wang ZJ', 'Zhou FC', 'Wang YP', 'Zhou YC']

>> Named Entities are: 
 [('PERSON', 'Ye'), ('ORGANIZATION', 'F'), ('PERSON', 'Wang ZJ'), ('PERSON', 'Zhou FC'), ('PERSON', 'Wang YP'), ('PERSON', 'Zhou YC')] 

>> Stemming using Porter Stemmer: 
 [('Ye', 'ye'), ('F', 'f'), (',', ','), ('Wang', 'wang'), ('ZJ', 'zj'), (',', ','), ('Zhou', 'zhou'), ('FC', 'fc'), (',', ','), ('Wang', 'wang'), ('YP', 'yp'), (',', ','), ('Zhou', 'zhou'), ('YC', 'yc'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Ye', 'ye'), ('F', 'f'), (',', ','), ('Wang', 'wang'), ('ZJ', 'zj'), (',', ','), ('Zhou', 'zhou'), ('FC', 'fc'), (',', ','), ('Wang', 'wang'), ('YP', 'yp'), (',', ','), ('Zhou', 'zhou'), ('YC', 'yc'), ('.', '.')]

>> Lemmatization: 
 [('Ye', 'Ye'), ('F', 'F'), (',', ','), ('Wang', 'Wang'), ('ZJ', 'ZJ'), (',', ','), ('Zhou', 'Zhou'), ('FC', 'FC'), (',', ','), ('Wang', 'Wang'), ('YP', 'YP'), (',', ','), ('Zhou', 'Zhou'), ('YC', 'YC'), ('.', '.')]


------------------- Sentence 3 -------------------

Cloud‑based big data mining and analyzing services platform integrat‑ ing r. In: Proceedings of the International Conference on Advanced Cloud and Big Data, 2013. pp 147–151.

>> Tokens are: 
 ['Cloud‑based', 'big', 'data', 'mining', 'analyzing', 'services', 'platform', 'integrat‑', 'ing', 'r.', 'In', ':', 'Proceedings', 'International', 'Conference', 'Advanced', 'Cloud', 'Big', 'Data', ',', '2013.', 'pp', '147–151', '.']

>> Bigrams are: 
 [('Cloud‑based', 'big'), ('big', 'data'), ('data', 'mining'), ('mining', 'analyzing'), ('analyzing', 'services'), ('services', 'platform'), ('platform', 'integrat‑'), ('integrat‑', 'ing'), ('ing', 'r.'), ('r.', 'In'), ('In', ':'), (':', 'Proceedings'), ('Proceedings', 'International'), ('International', 'Conference'), ('Conference', 'Advanced'), ('Advanced', 'Cloud'), ('Cloud', 'Big'), ('Big', 'Data'), ('Data', ','), (',', '2013.'), ('2013.', 'pp'), ('pp', '147–151'), ('147–151', '.')]

>> Trigrams are: 
 [('Cloud‑based', 'big', 'data'), ('big', 'data', 'mining'), ('data', 'mining', 'analyzing'), ('mining', 'analyzing', 'services'), ('analyzing', 'services', 'platform'), ('services', 'platform', 'integrat‑'), ('platform', 'integrat‑', 'ing'), ('integrat‑', 'ing', 'r.'), ('ing', 'r.', 'In'), ('r.', 'In', ':'), ('In', ':', 'Proceedings'), (':', 'Proceedings', 'International'), ('Proceedings', 'International', 'Conference'), ('International', 'Conference', 'Advanced'), ('Conference', 'Advanced', 'Cloud'), ('Advanced', 'Cloud', 'Big'), ('Cloud', 'Big', 'Data'), ('Big', 'Data', ','), ('Data', ',', '2013.'), (',', '2013.', 'pp'), ('2013.', 'pp', '147–151'), ('pp', '147–151', '.')]

>> POS Tags are: 
 [('Cloud‑based', 'VBN'), ('big', 'JJ'), ('data', 'NNS'), ('mining', 'NN'), ('analyzing', 'NN'), ('services', 'NNS'), ('platform', 'NN'), ('integrat‑', 'VBP'), ('ing', 'VBG'), ('r.', 'NN'), ('In', 'IN'), (':', ':'), ('Proceedings', 'NNS'), ('International', 'NNP'), ('Conference', 'NNP'), ('Advanced', 'NNP'), ('Cloud', 'NNP'), ('Big', 'NNP'), ('Data', 'NNP'), (',', ','), ('2013.', 'CD'), ('pp', 'NN'), ('147–151', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['big data mining analyzing services platform', 'r.', 'Proceedings International Conference Advanced Cloud Big Data', 'pp']

>> Named Entities are: 
 [('ORGANIZATION', 'International Conference Advanced Cloud')] 

>> Stemming using Porter Stemmer: 
 [('Cloud‑based', 'cloud‑bas'), ('big', 'big'), ('data', 'data'), ('mining', 'mine'), ('analyzing', 'analyz'), ('services', 'servic'), ('platform', 'platform'), ('integrat‑', 'integrat‑'), ('ing', 'ing'), ('r.', 'r.'), ('In', 'in'), (':', ':'), ('Proceedings', 'proceed'), ('International', 'intern'), ('Conference', 'confer'), ('Advanced', 'advanc'), ('Cloud', 'cloud'), ('Big', 'big'), ('Data', 'data'), (',', ','), ('2013.', '2013.'), ('pp', 'pp'), ('147–151', '147–151'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Cloud‑based', 'cloud‑bas'), ('big', 'big'), ('data', 'data'), ('mining', 'mine'), ('analyzing', 'analyz'), ('services', 'servic'), ('platform', 'platform'), ('integrat‑', 'integrat‑'), ('ing', 'ing'), ('r.', 'r.'), ('In', 'in'), (':', ':'), ('Proceedings', 'proceed'), ('International', 'intern'), ('Conference', 'confer'), ('Advanced', 'advanc'), ('Cloud', 'cloud'), ('Big', 'big'), ('Data', 'data'), (',', ','), ('2013.', '2013.'), ('pp', 'pp'), ('147–151', '147–151'), ('.', '.')]

>> Lemmatization: 
 [('Cloud‑based', 'Cloud‑based'), ('big', 'big'), ('data', 'data'), ('mining', 'mining'), ('analyzing', 'analyzing'), ('services', 'service'), ('platform', 'platform'), ('integrat‑', 'integrat‑'), ('ing', 'ing'), ('r.', 'r.'), ('In', 'In'), (':', ':'), ('Proceedings', 'Proceedings'), ('International', 'International'), ('Conference', 'Conference'), ('Advanced', 'Advanced'), ('Cloud', 'Cloud'), ('Big', 'Big'), ('Data', 'Data'), (',', ','), ('2013.', '2013.'), ('pp', 'pp'), ('147–151', '147–151'), ('.', '.')]



========================================== PARAGRAPH 485 ===========================================

 95. Wu X, Zhu X, Wu G‑Q, Ding W. Data mining with big data. IEEE Trans Knowl Data Eng. 2014;26(1):97–107.  96. Laurila JK, Gatica‑Perez D, Aad I, Blom J, Bornet O, Do T, Dousse O, Eberle J, Miettinen M. The mobile data chal‑ 

------------------- Sentence 1 -------------------

 95.

>> Tokens are: 
 ['95', '.']

>> Bigrams are: 
 [('95', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('95', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('95', '95'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('95', '95'), ('.', '.')]

>> Lemmatization: 
 [('95', '95'), ('.', '.')]


------------------- Sentence 2 -------------------

Wu X, Zhu X, Wu G‑Q, Ding W. Data mining with big data.

>> Tokens are: 
 ['Wu', 'X', ',', 'Zhu', 'X', ',', 'Wu', 'G‑Q', ',', 'Ding', 'W.', 'Data', 'mining', 'big', 'data', '.']

>> Bigrams are: 
 [('Wu', 'X'), ('X', ','), (',', 'Zhu'), ('Zhu', 'X'), ('X', ','), (',', 'Wu'), ('Wu', 'G‑Q'), ('G‑Q', ','), (',', 'Ding'), ('Ding', 'W.'), ('W.', 'Data'), ('Data', 'mining'), ('mining', 'big'), ('big', 'data'), ('data', '.')]

>> Trigrams are: 
 [('Wu', 'X', ','), ('X', ',', 'Zhu'), (',', 'Zhu', 'X'), ('Zhu', 'X', ','), ('X', ',', 'Wu'), (',', 'Wu', 'G‑Q'), ('Wu', 'G‑Q', ','), ('G‑Q', ',', 'Ding'), (',', 'Ding', 'W.'), ('Ding', 'W.', 'Data'), ('W.', 'Data', 'mining'), ('Data', 'mining', 'big'), ('mining', 'big', 'data'), ('big', 'data', '.')]

>> POS Tags are: 
 [('Wu', 'NNP'), ('X', 'NNP'), (',', ','), ('Zhu', 'NNP'), ('X', 'NNP'), (',', ','), ('Wu', 'NNP'), ('G‑Q', 'NNP'), (',', ','), ('Ding', 'NNP'), ('W.', 'NNP'), ('Data', 'NNP'), ('mining', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['Wu X', 'Zhu X', 'Wu G‑Q', 'Ding W. Data mining', 'big data']

>> Named Entities are: 
 [('PERSON', 'Zhu X'), ('PERSON', 'Wu G‑Q'), ('PERSON', 'Ding W. Data')] 

>> Stemming using Porter Stemmer: 
 [('Wu', 'wu'), ('X', 'x'), (',', ','), ('Zhu', 'zhu'), ('X', 'x'), (',', ','), ('Wu', 'wu'), ('G‑Q', 'g‑q'), (',', ','), ('Ding', 'ding'), ('W.', 'w.'), ('Data', 'data'), ('mining', 'mine'), ('big', 'big'), ('data', 'data'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Wu', 'wu'), ('X', 'x'), (',', ','), ('Zhu', 'zhu'), ('X', 'x'), (',', ','), ('Wu', 'wu'), ('G‑Q', 'g‑q'), (',', ','), ('Ding', 'ding'), ('W.', 'w.'), ('Data', 'data'), ('mining', 'mine'), ('big', 'big'), ('data', 'data'), ('.', '.')]

>> Lemmatization: 
 [('Wu', 'Wu'), ('X', 'X'), (',', ','), ('Zhu', 'Zhu'), ('X', 'X'), (',', ','), ('Wu', 'Wu'), ('G‑Q', 'G‑Q'), (',', ','), ('Ding', 'Ding'), ('W.', 'W.'), ('Data', 'Data'), ('mining', 'mining'), ('big', 'big'), ('data', 'data'), ('.', '.')]


------------------- Sentence 3 -------------------

IEEE Trans Knowl Data Eng.

>> Tokens are: 
 ['IEEE', 'Trans', 'Knowl', 'Data', 'Eng', '.']

>> Bigrams are: 
 [('IEEE', 'Trans'), ('Trans', 'Knowl'), ('Knowl', 'Data'), ('Data', 'Eng'), ('Eng', '.')]

>> Trigrams are: 
 [('IEEE', 'Trans', 'Knowl'), ('Trans', 'Knowl', 'Data'), ('Knowl', 'Data', 'Eng'), ('Data', 'Eng', '.')]

>> POS Tags are: 
 [('IEEE', 'NNP'), ('Trans', 'NNP'), ('Knowl', 'NNP'), ('Data', 'NNP'), ('Eng', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['IEEE Trans Knowl Data Eng']

>> Named Entities are: 
 [('ORGANIZATION', 'IEEE'), ('PERSON', 'Trans Knowl Data Eng')] 

>> Stemming using Porter Stemmer: 
 [('IEEE', 'ieee'), ('Trans', 'tran'), ('Knowl', 'knowl'), ('Data', 'data'), ('Eng', 'eng'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('IEEE', 'ieee'), ('Trans', 'tran'), ('Knowl', 'knowl'), ('Data', 'data'), ('Eng', 'eng'), ('.', '.')]

>> Lemmatization: 
 [('IEEE', 'IEEE'), ('Trans', 'Trans'), ('Knowl', 'Knowl'), ('Data', 'Data'), ('Eng', 'Eng'), ('.', '.')]


------------------- Sentence 4 -------------------

2014;26(1):97–107.

>> Tokens are: 
 ['2014', ';', '26', '(', '1', ')', ':97–107', '.']

>> Bigrams are: 
 [('2014', ';'), (';', '26'), ('26', '('), ('(', '1'), ('1', ')'), (')', ':97–107'), (':97–107', '.')]

>> Trigrams are: 
 [('2014', ';', '26'), (';', '26', '('), ('26', '(', '1'), ('(', '1', ')'), ('1', ')', ':97–107'), (')', ':97–107', '.')]

>> POS Tags are: 
 [('2014', 'CD'), (';', ':'), ('26', 'CD'), ('(', '('), ('1', 'CD'), (')', ')'), (':97–107', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 [':97–107']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('2014', '2014'), (';', ';'), ('26', '26'), ('(', '('), ('1', '1'), (')', ')'), (':97–107', ':97–107'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('2014', '2014'), (';', ';'), ('26', '26'), ('(', '('), ('1', '1'), (')', ')'), (':97–107', ':97–107'), ('.', '.')]

>> Lemmatization: 
 [('2014', '2014'), (';', ';'), ('26', '26'), ('(', '('), ('1', '1'), (')', ')'), (':97–107', ':97–107'), ('.', '.')]


------------------- Sentence 5 -------------------

96.

>> Tokens are: 
 ['96', '.']

>> Bigrams are: 
 [('96', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('96', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('96', '96'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('96', '96'), ('.', '.')]

>> Lemmatization: 
 [('96', '96'), ('.', '.')]


------------------- Sentence 6 -------------------

Laurila JK, Gatica‑Perez D, Aad I, Blom J, Bornet O, Do T, Dousse O, Eberle J, Miettinen M. The mobile data chal‑

>> Tokens are: 
 ['Laurila', 'JK', ',', 'Gatica‑Perez', 'D', ',', 'Aad', 'I', ',', 'Blom', 'J', ',', 'Bornet', 'O', ',', 'Do', 'T', ',', 'Dousse', 'O', ',', 'Eberle', 'J', ',', 'Miettinen', 'M.', 'The', 'mobile', 'data', 'chal‑']

>> Bigrams are: 
 [('Laurila', 'JK'), ('JK', ','), (',', 'Gatica‑Perez'), ('Gatica‑Perez', 'D'), ('D', ','), (',', 'Aad'), ('Aad', 'I'), ('I', ','), (',', 'Blom'), ('Blom', 'J'), ('J', ','), (',', 'Bornet'), ('Bornet', 'O'), ('O', ','), (',', 'Do'), ('Do', 'T'), ('T', ','), (',', 'Dousse'), ('Dousse', 'O'), ('O', ','), (',', 'Eberle'), ('Eberle', 'J'), ('J', ','), (',', 'Miettinen'), ('Miettinen', 'M.'), ('M.', 'The'), ('The', 'mobile'), ('mobile', 'data'), ('data', 'chal‑')]

>> Trigrams are: 
 [('Laurila', 'JK', ','), ('JK', ',', 'Gatica‑Perez'), (',', 'Gatica‑Perez', 'D'), ('Gatica‑Perez', 'D', ','), ('D', ',', 'Aad'), (',', 'Aad', 'I'), ('Aad', 'I', ','), ('I', ',', 'Blom'), (',', 'Blom', 'J'), ('Blom', 'J', ','), ('J', ',', 'Bornet'), (',', 'Bornet', 'O'), ('Bornet', 'O', ','), ('O', ',', 'Do'), (',', 'Do', 'T'), ('Do', 'T', ','), ('T', ',', 'Dousse'), (',', 'Dousse', 'O'), ('Dousse', 'O', ','), ('O', ',', 'Eberle'), (',', 'Eberle', 'J'), ('Eberle', 'J', ','), ('J', ',', 'Miettinen'), (',', 'Miettinen', 'M.'), ('Miettinen', 'M.', 'The'), ('M.', 'The', 'mobile'), ('The', 'mobile', 'data'), ('mobile', 'data', 'chal‑')]

>> POS Tags are: 
 [('Laurila', 'NNP'), ('JK', 'NNP'), (',', ','), ('Gatica‑Perez', 'NNP'), ('D', 'NNP'), (',', ','), ('Aad', 'NNP'), ('I', 'PRP'), (',', ','), ('Blom', 'NNP'), ('J', 'NNP'), (',', ','), ('Bornet', 'NNP'), ('O', 'NNP'), (',', ','), ('Do', 'NNP'), ('T', 'NNP'), (',', ','), ('Dousse', 'NNP'), ('O', 'NNP'), (',', ','), ('Eberle', 'NNP'), ('J', 'NNP'), (',', ','), ('Miettinen', 'NNP'), ('M.', 'NNP'), ('The', 'DT'), ('mobile', 'JJ'), ('data', 'NNS'), ('chal‑', 'NN')]

>> Noun Phrases are: 
 ['Laurila JK', 'Gatica‑Perez D', 'Aad', 'Blom J', 'Bornet O', 'Do T', 'Dousse O', 'Eberle J', 'Miettinen M.', 'The mobile data chal‑']

>> Named Entities are: 
 [('PERSON', 'Laurila'), ('GPE', 'JK'), ('PERSON', 'Blom J'), ('PERSON', 'Bornet O'), ('PERSON', 'Do T'), ('PERSON', 'Dousse O'), ('PERSON', 'Eberle J'), ('PERSON', 'Miettinen')] 

>> Stemming using Porter Stemmer: 
 [('Laurila', 'laurila'), ('JK', 'jk'), (',', ','), ('Gatica‑Perez', 'gatica‑perez'), ('D', 'd'), (',', ','), ('Aad', 'aad'), ('I', 'i'), (',', ','), ('Blom', 'blom'), ('J', 'j'), (',', ','), ('Bornet', 'bornet'), ('O', 'o'), (',', ','), ('Do', 'do'), ('T', 't'), (',', ','), ('Dousse', 'douss'), ('O', 'o'), (',', ','), ('Eberle', 'eberl'), ('J', 'j'), (',', ','), ('Miettinen', 'miettinen'), ('M.', 'm.'), ('The', 'the'), ('mobile', 'mobil'), ('data', 'data'), ('chal‑', 'chal‑')]

>> Stemming using Snowball Stemmer: 
 [('Laurila', 'laurila'), ('JK', 'jk'), (',', ','), ('Gatica‑Perez', 'gatica‑perez'), ('D', 'd'), (',', ','), ('Aad', 'aad'), ('I', 'i'), (',', ','), ('Blom', 'blom'), ('J', 'j'), (',', ','), ('Bornet', 'bornet'), ('O', 'o'), (',', ','), ('Do', 'do'), ('T', 't'), (',', ','), ('Dousse', 'douss'), ('O', 'o'), (',', ','), ('Eberle', 'eberl'), ('J', 'j'), (',', ','), ('Miettinen', 'miettinen'), ('M.', 'm.'), ('The', 'the'), ('mobile', 'mobil'), ('data', 'data'), ('chal‑', 'chal‑')]

>> Lemmatization: 
 [('Laurila', 'Laurila'), ('JK', 'JK'), (',', ','), ('Gatica‑Perez', 'Gatica‑Perez'), ('D', 'D'), (',', ','), ('Aad', 'Aad'), ('I', 'I'), (',', ','), ('Blom', 'Blom'), ('J', 'J'), (',', ','), ('Bornet', 'Bornet'), ('O', 'O'), (',', ','), ('Do', 'Do'), ('T', 'T'), (',', ','), ('Dousse', 'Dousse'), ('O', 'O'), (',', ','), ('Eberle', 'Eberle'), ('J', 'J'), (',', ','), ('Miettinen', 'Miettinen'), ('M.', 'M.'), ('The', 'The'), ('mobile', 'mobile'), ('data', 'data'), ('chal‑', 'chal‑')]



========================================== PARAGRAPH 486 ===========================================

lenge: big data for mobile computing research. In: Proceedings of the Mobile Data Challenge by Nokia Workshop,  2012. pp 1–8. 

------------------- Sentence 1 -------------------

lenge: big data for mobile computing research.

>> Tokens are: 
 ['lenge', ':', 'big', 'data', 'mobile', 'computing', 'research', '.']

>> Bigrams are: 
 [('lenge', ':'), (':', 'big'), ('big', 'data'), ('data', 'mobile'), ('mobile', 'computing'), ('computing', 'research'), ('research', '.')]

>> Trigrams are: 
 [('lenge', ':', 'big'), (':', 'big', 'data'), ('big', 'data', 'mobile'), ('data', 'mobile', 'computing'), ('mobile', 'computing', 'research'), ('computing', 'research', '.')]

>> POS Tags are: 
 [('lenge', 'NN'), (':', ':'), ('big', 'JJ'), ('data', 'NNS'), ('mobile', 'NN'), ('computing', 'VBG'), ('research', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['lenge', 'big data mobile', 'research']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('lenge', 'leng'), (':', ':'), ('big', 'big'), ('data', 'data'), ('mobile', 'mobil'), ('computing', 'comput'), ('research', 'research'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('lenge', 'leng'), (':', ':'), ('big', 'big'), ('data', 'data'), ('mobile', 'mobil'), ('computing', 'comput'), ('research', 'research'), ('.', '.')]

>> Lemmatization: 
 [('lenge', 'lenge'), (':', ':'), ('big', 'big'), ('data', 'data'), ('mobile', 'mobile'), ('computing', 'computing'), ('research', 'research'), ('.', '.')]


------------------- Sentence 2 -------------------

In: Proceedings of the Mobile Data Challenge by Nokia Workshop,  2012. pp 1–8.

>> Tokens are: 
 ['In', ':', 'Proceedings', 'Mobile', 'Data', 'Challenge', 'Nokia', 'Workshop', ',', '2012.', 'pp', '1–8', '.']

>> Bigrams are: 
 [('In', ':'), (':', 'Proceedings'), ('Proceedings', 'Mobile'), ('Mobile', 'Data'), ('Data', 'Challenge'), ('Challenge', 'Nokia'), ('Nokia', 'Workshop'), ('Workshop', ','), (',', '2012.'), ('2012.', 'pp'), ('pp', '1–8'), ('1–8', '.')]

>> Trigrams are: 
 [('In', ':', 'Proceedings'), (':', 'Proceedings', 'Mobile'), ('Proceedings', 'Mobile', 'Data'), ('Mobile', 'Data', 'Challenge'), ('Data', 'Challenge', 'Nokia'), ('Challenge', 'Nokia', 'Workshop'), ('Nokia', 'Workshop', ','), ('Workshop', ',', '2012.'), (',', '2012.', 'pp'), ('2012.', 'pp', '1–8'), ('pp', '1–8', '.')]

>> POS Tags are: 
 [('In', 'IN'), (':', ':'), ('Proceedings', 'NNS'), ('Mobile', 'NNP'), ('Data', 'NNP'), ('Challenge', 'NNP'), ('Nokia', 'NNP'), ('Workshop', 'NNP'), (',', ','), ('2012.', 'CD'), ('pp', 'NN'), ('1–8', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Proceedings Mobile Data Challenge Nokia Workshop', 'pp']

>> Named Entities are: 
 [('PERSON', 'Mobile Data Challenge Nokia Workshop')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), (':', ':'), ('Proceedings', 'proceed'), ('Mobile', 'mobil'), ('Data', 'data'), ('Challenge', 'challeng'), ('Nokia', 'nokia'), ('Workshop', 'workshop'), (',', ','), ('2012.', '2012.'), ('pp', 'pp'), ('1–8', '1–8'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), (':', ':'), ('Proceedings', 'proceed'), ('Mobile', 'mobil'), ('Data', 'data'), ('Challenge', 'challeng'), ('Nokia', 'nokia'), ('Workshop', 'workshop'), (',', ','), ('2012.', '2012.'), ('pp', 'pp'), ('1–8', '1–8'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), (':', ':'), ('Proceedings', 'Proceedings'), ('Mobile', 'Mobile'), ('Data', 'Data'), ('Challenge', 'Challenge'), ('Nokia', 'Nokia'), ('Workshop', 'Workshop'), (',', ','), ('2012.', '2012.'), ('pp', 'pp'), ('1–8', '1–8'), ('.', '.')]



========================================== PARAGRAPH 487 ===========================================

 97. Demirkan H, Delen D. Leveraging the capabilities of service‑oriented decision support systems: putting analytics  and big data in cloud. Decision Support Syst. 2013;55(1):412–21. 

------------------- Sentence 1 -------------------

 97.

>> Tokens are: 
 ['97', '.']

>> Bigrams are: 
 [('97', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('97', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('97', '97'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('97', '97'), ('.', '.')]

>> Lemmatization: 
 [('97', '97'), ('.', '.')]


------------------- Sentence 2 -------------------

Demirkan H, Delen D. Leveraging the capabilities of service‑oriented decision support systems: putting analytics  and big data in cloud.

>> Tokens are: 
 ['Demirkan', 'H', ',', 'Delen', 'D.', 'Leveraging', 'capabilities', 'service‑oriented', 'decision', 'support', 'systems', ':', 'putting', 'analytics', 'big', 'data', 'cloud', '.']

>> Bigrams are: 
 [('Demirkan', 'H'), ('H', ','), (',', 'Delen'), ('Delen', 'D.'), ('D.', 'Leveraging'), ('Leveraging', 'capabilities'), ('capabilities', 'service‑oriented'), ('service‑oriented', 'decision'), ('decision', 'support'), ('support', 'systems'), ('systems', ':'), (':', 'putting'), ('putting', 'analytics'), ('analytics', 'big'), ('big', 'data'), ('data', 'cloud'), ('cloud', '.')]

>> Trigrams are: 
 [('Demirkan', 'H', ','), ('H', ',', 'Delen'), (',', 'Delen', 'D.'), ('Delen', 'D.', 'Leveraging'), ('D.', 'Leveraging', 'capabilities'), ('Leveraging', 'capabilities', 'service‑oriented'), ('capabilities', 'service‑oriented', 'decision'), ('service‑oriented', 'decision', 'support'), ('decision', 'support', 'systems'), ('support', 'systems', ':'), ('systems', ':', 'putting'), (':', 'putting', 'analytics'), ('putting', 'analytics', 'big'), ('analytics', 'big', 'data'), ('big', 'data', 'cloud'), ('data', 'cloud', '.')]

>> POS Tags are: 
 [('Demirkan', 'NNP'), ('H', 'NNP'), (',', ','), ('Delen', 'NNP'), ('D.', 'NNP'), ('Leveraging', 'NNP'), ('capabilities', 'NNS'), ('service‑oriented', 'VBD'), ('decision', 'NN'), ('support', 'NN'), ('systems', 'NNS'), (':', ':'), ('putting', 'VBG'), ('analytics', 'NNS'), ('big', 'JJ'), ('data', 'NNS'), ('cloud', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Demirkan H', 'Delen D. Leveraging capabilities', 'decision support systems', 'analytics', 'big data cloud']

>> Named Entities are: 
 [('PERSON', 'Demirkan'), ('ORGANIZATION', 'H'), ('PERSON', 'Delen D.')] 

>> Stemming using Porter Stemmer: 
 [('Demirkan', 'demirkan'), ('H', 'h'), (',', ','), ('Delen', 'delen'), ('D.', 'd.'), ('Leveraging', 'leverag'), ('capabilities', 'capabl'), ('service‑oriented', 'service‑ori'), ('decision', 'decis'), ('support', 'support'), ('systems', 'system'), (':', ':'), ('putting', 'put'), ('analytics', 'analyt'), ('big', 'big'), ('data', 'data'), ('cloud', 'cloud'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Demirkan', 'demirkan'), ('H', 'h'), (',', ','), ('Delen', 'delen'), ('D.', 'd.'), ('Leveraging', 'leverag'), ('capabilities', 'capabl'), ('service‑oriented', 'service‑ori'), ('decision', 'decis'), ('support', 'support'), ('systems', 'system'), (':', ':'), ('putting', 'put'), ('analytics', 'analyt'), ('big', 'big'), ('data', 'data'), ('cloud', 'cloud'), ('.', '.')]

>> Lemmatization: 
 [('Demirkan', 'Demirkan'), ('H', 'H'), (',', ','), ('Delen', 'Delen'), ('D.', 'D.'), ('Leveraging', 'Leveraging'), ('capabilities', 'capability'), ('service‑oriented', 'service‑oriented'), ('decision', 'decision'), ('support', 'support'), ('systems', 'system'), (':', ':'), ('putting', 'putting'), ('analytics', 'analytics'), ('big', 'big'), ('data', 'data'), ('cloud', 'cloud'), ('.', '.')]


------------------- Sentence 3 -------------------

Decision Support Syst.

>> Tokens are: 
 ['Decision', 'Support', 'Syst', '.']

>> Bigrams are: 
 [('Decision', 'Support'), ('Support', 'Syst'), ('Syst', '.')]

>> Trigrams are: 
 [('Decision', 'Support', 'Syst'), ('Support', 'Syst', '.')]

>> POS Tags are: 
 [('Decision', 'NNP'), ('Support', 'NNP'), ('Syst', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Decision Support Syst']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Decision', 'decis'), ('Support', 'support'), ('Syst', 'syst'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Decision', 'decis'), ('Support', 'support'), ('Syst', 'syst'), ('.', '.')]

>> Lemmatization: 
 [('Decision', 'Decision'), ('Support', 'Support'), ('Syst', 'Syst'), ('.', '.')]


------------------- Sentence 4 -------------------

2013;55(1):412–21.

>> Tokens are: 
 ['2013', ';', '55', '(', '1', ')', ':412–21', '.']

>> Bigrams are: 
 [('2013', ';'), (';', '55'), ('55', '('), ('(', '1'), ('1', ')'), (')', ':412–21'), (':412–21', '.')]

>> Trigrams are: 
 [('2013', ';', '55'), (';', '55', '('), ('55', '(', '1'), ('(', '1', ')'), ('1', ')', ':412–21'), (')', ':412–21', '.')]

>> POS Tags are: 
 [('2013', 'CD'), (';', ':'), ('55', 'CD'), ('(', '('), ('1', 'CD'), (')', ')'), (':412–21', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 [':412–21']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('2013', '2013'), (';', ';'), ('55', '55'), ('(', '('), ('1', '1'), (')', ')'), (':412–21', ':412–21'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('2013', '2013'), (';', ';'), ('55', '55'), ('(', '('), ('1', '1'), (')', ')'), (':412–21', ':412–21'), ('.', '.')]

>> Lemmatization: 
 [('2013', '2013'), (';', ';'), ('55', '55'), ('(', '('), ('1', '1'), (')', ')'), (':412–21', ':412–21'), ('.', '.')]



========================================== PARAGRAPH 488 ===========================================

 98. Talia D. Clouds for scalable big data analytics. Computer. 2013;46(5):98–101.

------------------- Sentence 1 -------------------

 98.

>> Tokens are: 
 ['98', '.']

>> Bigrams are: 
 [('98', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('98', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('98', '98'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('98', '98'), ('.', '.')]

>> Lemmatization: 
 [('98', '98'), ('.', '.')]


------------------- Sentence 2 -------------------

Talia D. Clouds for scalable big data analytics.

>> Tokens are: 
 ['Talia', 'D.', 'Clouds', 'scalable', 'big', 'data', 'analytics', '.']

>> Bigrams are: 
 [('Talia', 'D.'), ('D.', 'Clouds'), ('Clouds', 'scalable'), ('scalable', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', '.')]

>> Trigrams are: 
 [('Talia', 'D.', 'Clouds'), ('D.', 'Clouds', 'scalable'), ('Clouds', 'scalable', 'big'), ('scalable', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', '.')]

>> POS Tags are: 
 [('Talia', 'NNP'), ('D.', 'NNP'), ('Clouds', 'NNP'), ('scalable', 'JJ'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['Talia D. Clouds', 'scalable big data analytics']

>> Named Entities are: 
 [('PERSON', 'Talia')] 

>> Stemming using Porter Stemmer: 
 [('Talia', 'talia'), ('D.', 'd.'), ('Clouds', 'cloud'), ('scalable', 'scalabl'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Talia', 'talia'), ('D.', 'd.'), ('Clouds', 'cloud'), ('scalable', 'scalabl'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('.', '.')]

>> Lemmatization: 
 [('Talia', 'Talia'), ('D.', 'D.'), ('Clouds', 'Clouds'), ('scalable', 'scalable'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('.', '.')]


------------------- Sentence 3 -------------------

Computer.

>> Tokens are: 
 ['Computer', '.']

>> Bigrams are: 
 [('Computer', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Computer', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Computer']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Computer', 'comput'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Computer', 'comput'), ('.', '.')]

>> Lemmatization: 
 [('Computer', 'Computer'), ('.', '.')]


------------------- Sentence 4 -------------------

2013;46(5):98–101.

>> Tokens are: 
 ['2013', ';', '46', '(', '5', ')', ':98–101', '.']

>> Bigrams are: 
 [('2013', ';'), (';', '46'), ('46', '('), ('(', '5'), ('5', ')'), (')', ':98–101'), (':98–101', '.')]

>> Trigrams are: 
 [('2013', ';', '46'), (';', '46', '('), ('46', '(', '5'), ('(', '5', ')'), ('5', ')', ':98–101'), (')', ':98–101', '.')]

>> POS Tags are: 
 [('2013', 'CD'), (';', ':'), ('46', 'CD'), ('(', '('), ('5', 'CD'), (')', ')'), (':98–101', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 [':98–101']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('2013', '2013'), (';', ';'), ('46', '46'), ('(', '('), ('5', '5'), (')', ')'), (':98–101', ':98–101'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('2013', '2013'), (';', ';'), ('46', '46'), ('(', '('), ('5', '5'), (')', ')'), (':98–101', ':98–101'), ('.', '.')]

>> Lemmatization: 
 [('2013', '2013'), (';', ';'), ('46', '46'), ('(', '('), ('5', '5'), (')', ')'), (':98–101', ':98–101'), ('.', '.')]



========================================== PARAGRAPH 489 ===========================================

Page 31 of 32Tsai et al. Journal of Big Data  (2015) 2:21  

------------------- Sentence 1 -------------------

Page 31 of 32Tsai et al.

>> Tokens are: 
 ['Page', '31', '32Tsai', 'et', 'al', '.']

>> Bigrams are: 
 [('Page', '31'), ('31', '32Tsai'), ('32Tsai', 'et'), ('et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('Page', '31', '32Tsai'), ('31', '32Tsai', 'et'), ('32Tsai', 'et', 'al'), ('et', 'al', '.')]

>> POS Tags are: 
 [('Page', 'NN'), ('31', 'CD'), ('32Tsai', 'CD'), ('et', 'NN'), ('al', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Page', 'et al']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Page', 'page'), ('31', '31'), ('32Tsai', '32tsai'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Page', 'page'), ('31', '31'), ('32Tsai', '32tsai'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('Page', 'Page'), ('31', '31'), ('32Tsai', '32Tsai'), ('et', 'et'), ('al', 'al'), ('.', '.')]


------------------- Sentence 2 -------------------

Journal of Big Data  (2015) 2:21

>> Tokens are: 
 ['Journal', 'Big', 'Data', '(', '2015', ')', '2:21']

>> Bigrams are: 
 [('Journal', 'Big'), ('Big', 'Data'), ('Data', '('), ('(', '2015'), ('2015', ')'), (')', '2:21')]

>> Trigrams are: 
 [('Journal', 'Big', 'Data'), ('Big', 'Data', '('), ('Data', '(', '2015'), ('(', '2015', ')'), ('2015', ')', '2:21')]

>> POS Tags are: 
 [('Journal', 'NNP'), ('Big', 'NNP'), ('Data', 'NNP'), ('(', '('), ('2015', 'CD'), (')', ')'), ('2:21', 'CD')]

>> Noun Phrases are: 
 ['Journal Big Data']

>> Named Entities are: 
 [('PERSON', 'Journal')] 

>> Stemming using Porter Stemmer: 
 [('Journal', 'journal'), ('Big', 'big'), ('Data', 'data'), ('(', '('), ('2015', '2015'), (')', ')'), ('2:21', '2:21')]

>> Stemming using Snowball Stemmer: 
 [('Journal', 'journal'), ('Big', 'big'), ('Data', 'data'), ('(', '('), ('2015', '2015'), (')', ')'), ('2:21', '2:21')]

>> Lemmatization: 
 [('Journal', 'Journal'), ('Big', 'Big'), ('Data', 'Data'), ('(', '('), ('2015', '2015'), (')', ')'), ('2:21', '2:21')]



========================================== PARAGRAPH 490 ===========================================

 99. Lu R, Zhu H, Liu X, Liu JK, Shao J. Toward efficient and privacy‑preserving computing in big data era. IEEE Netw.  2014;28(4):46–50. 

------------------- Sentence 1 -------------------

 99.

>> Tokens are: 
 ['99', '.']

>> Bigrams are: 
 [('99', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('99', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('99', '99'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('99', '99'), ('.', '.')]

>> Lemmatization: 
 [('99', '99'), ('.', '.')]


------------------- Sentence 2 -------------------

Lu R, Zhu H, Liu X, Liu JK, Shao J.

>> Tokens are: 
 ['Lu', 'R', ',', 'Zhu', 'H', ',', 'Liu', 'X', ',', 'Liu', 'JK', ',', 'Shao', 'J', '.']

>> Bigrams are: 
 [('Lu', 'R'), ('R', ','), (',', 'Zhu'), ('Zhu', 'H'), ('H', ','), (',', 'Liu'), ('Liu', 'X'), ('X', ','), (',', 'Liu'), ('Liu', 'JK'), ('JK', ','), (',', 'Shao'), ('Shao', 'J'), ('J', '.')]

>> Trigrams are: 
 [('Lu', 'R', ','), ('R', ',', 'Zhu'), (',', 'Zhu', 'H'), ('Zhu', 'H', ','), ('H', ',', 'Liu'), (',', 'Liu', 'X'), ('Liu', 'X', ','), ('X', ',', 'Liu'), (',', 'Liu', 'JK'), ('Liu', 'JK', ','), ('JK', ',', 'Shao'), (',', 'Shao', 'J'), ('Shao', 'J', '.')]

>> POS Tags are: 
 [('Lu', 'NNP'), ('R', 'NNP'), (',', ','), ('Zhu', 'NNP'), ('H', 'NNP'), (',', ','), ('Liu', 'NNP'), ('X', 'NNP'), (',', ','), ('Liu', 'NNP'), ('JK', 'NNP'), (',', ','), ('Shao', 'NNP'), ('J', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Lu R', 'Zhu H', 'Liu X', 'Liu JK', 'Shao J']

>> Named Entities are: 
 [('PERSON', 'Zhu H'), ('PERSON', 'Liu X'), ('PERSON', 'Liu JK'), ('PERSON', 'Shao J')] 

>> Stemming using Porter Stemmer: 
 [('Lu', 'lu'), ('R', 'r'), (',', ','), ('Zhu', 'zhu'), ('H', 'h'), (',', ','), ('Liu', 'liu'), ('X', 'x'), (',', ','), ('Liu', 'liu'), ('JK', 'jk'), (',', ','), ('Shao', 'shao'), ('J', 'j'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Lu', 'lu'), ('R', 'r'), (',', ','), ('Zhu', 'zhu'), ('H', 'h'), (',', ','), ('Liu', 'liu'), ('X', 'x'), (',', ','), ('Liu', 'liu'), ('JK', 'jk'), (',', ','), ('Shao', 'shao'), ('J', 'j'), ('.', '.')]

>> Lemmatization: 
 [('Lu', 'Lu'), ('R', 'R'), (',', ','), ('Zhu', 'Zhu'), ('H', 'H'), (',', ','), ('Liu', 'Liu'), ('X', 'X'), (',', ','), ('Liu', 'Liu'), ('JK', 'JK'), (',', ','), ('Shao', 'Shao'), ('J', 'J'), ('.', '.')]


------------------- Sentence 3 -------------------

Toward efficient and privacy‑preserving computing in big data era.

>> Tokens are: 
 ['Toward', 'efficient', 'privacy‑preserving', 'computing', 'big', 'data', 'era', '.']

>> Bigrams are: 
 [('Toward', 'efficient'), ('efficient', 'privacy‑preserving'), ('privacy‑preserving', 'computing'), ('computing', 'big'), ('big', 'data'), ('data', 'era'), ('era', '.')]

>> Trigrams are: 
 [('Toward', 'efficient', 'privacy‑preserving'), ('efficient', 'privacy‑preserving', 'computing'), ('privacy‑preserving', 'computing', 'big'), ('computing', 'big', 'data'), ('big', 'data', 'era'), ('data', 'era', '.')]

>> POS Tags are: 
 [('Toward', 'NNP'), ('efficient', 'JJ'), ('privacy‑preserving', 'VBG'), ('computing', 'VBG'), ('big', 'JJ'), ('data', 'NNS'), ('era', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Toward', 'big data era']

>> Named Entities are: 
 [('PERSON', 'Toward')] 

>> Stemming using Porter Stemmer: 
 [('Toward', 'toward'), ('efficient', 'effici'), ('privacy‑preserving', 'privacy‑preserv'), ('computing', 'comput'), ('big', 'big'), ('data', 'data'), ('era', 'era'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Toward', 'toward'), ('efficient', 'effici'), ('privacy‑preserving', 'privacy‑preserv'), ('computing', 'comput'), ('big', 'big'), ('data', 'data'), ('era', 'era'), ('.', '.')]

>> Lemmatization: 
 [('Toward', 'Toward'), ('efficient', 'efficient'), ('privacy‑preserving', 'privacy‑preserving'), ('computing', 'computing'), ('big', 'big'), ('data', 'data'), ('era', 'era'), ('.', '.')]


------------------- Sentence 4 -------------------

IEEE Netw.

>> Tokens are: 
 ['IEEE', 'Netw', '.']

>> Bigrams are: 
 [('IEEE', 'Netw'), ('Netw', '.')]

>> Trigrams are: 
 [('IEEE', 'Netw', '.')]

>> POS Tags are: 
 [('IEEE', 'NNP'), ('Netw', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['IEEE Netw']

>> Named Entities are: 
 [('ORGANIZATION', 'IEEE Netw')] 

>> Stemming using Porter Stemmer: 
 [('IEEE', 'ieee'), ('Netw', 'netw'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('IEEE', 'ieee'), ('Netw', 'netw'), ('.', '.')]

>> Lemmatization: 
 [('IEEE', 'IEEE'), ('Netw', 'Netw'), ('.', '.')]


------------------- Sentence 5 -------------------

2014;28(4):46–50.

>> Tokens are: 
 ['2014', ';', '28', '(', '4', ')', ':46–50', '.']

>> Bigrams are: 
 [('2014', ';'), (';', '28'), ('28', '('), ('(', '4'), ('4', ')'), (')', ':46–50'), (':46–50', '.')]

>> Trigrams are: 
 [('2014', ';', '28'), (';', '28', '('), ('28', '(', '4'), ('(', '4', ')'), ('4', ')', ':46–50'), (')', ':46–50', '.')]

>> POS Tags are: 
 [('2014', 'CD'), (';', ':'), ('28', 'CD'), ('(', '('), ('4', 'CD'), (')', ')'), (':46–50', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 [':46–50']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('2014', '2014'), (';', ';'), ('28', '28'), ('(', '('), ('4', '4'), (')', ')'), (':46–50', ':46–50'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('2014', '2014'), (';', ';'), ('28', '28'), ('(', '('), ('4', '4'), (')', ')'), (':46–50', ':46–50'), ('.', '.')]

>> Lemmatization: 
 [('2014', '2014'), (';', ';'), ('28', '28'), ('(', '('), ('4', '4'), (')', ')'), (':46–50', ':46–50'), ('.', '.')]



========================================== PARAGRAPH 491 ===========================================

 100. Cuzzocrea A, Song IY, Davis KC. Analytics over large‑scale multidimensional data: The big data revolution!. In:  Proceedings of the ACM International Workshop on Data Warehousing and OLAP, 2011. pp 101–104. 

------------------- Sentence 1 -------------------

 100.

>> Tokens are: 
 ['100', '.']

>> Bigrams are: 
 [('100', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('100', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('100', '100'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('100', '100'), ('.', '.')]

>> Lemmatization: 
 [('100', '100'), ('.', '.')]


------------------- Sentence 2 -------------------

Cuzzocrea A, Song IY, Davis KC.

>> Tokens are: 
 ['Cuzzocrea', 'A', ',', 'Song', 'IY', ',', 'Davis', 'KC', '.']

>> Bigrams are: 
 [('Cuzzocrea', 'A'), ('A', ','), (',', 'Song'), ('Song', 'IY'), ('IY', ','), (',', 'Davis'), ('Davis', 'KC'), ('KC', '.')]

>> Trigrams are: 
 [('Cuzzocrea', 'A', ','), ('A', ',', 'Song'), (',', 'Song', 'IY'), ('Song', 'IY', ','), ('IY', ',', 'Davis'), (',', 'Davis', 'KC'), ('Davis', 'KC', '.')]

>> POS Tags are: 
 [('Cuzzocrea', 'NNP'), ('A', 'NNP'), (',', ','), ('Song', 'NNP'), ('IY', 'NNP'), (',', ','), ('Davis', 'NNP'), ('KC', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Cuzzocrea A', 'Song IY', 'Davis KC']

>> Named Entities are: 
 [('PERSON', 'Cuzzocrea'), ('PERSON', 'Song IY'), ('PERSON', 'Davis KC')] 

>> Stemming using Porter Stemmer: 
 [('Cuzzocrea', 'cuzzocrea'), ('A', 'a'), (',', ','), ('Song', 'song'), ('IY', 'iy'), (',', ','), ('Davis', 'davi'), ('KC', 'kc'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Cuzzocrea', 'cuzzocrea'), ('A', 'a'), (',', ','), ('Song', 'song'), ('IY', 'iy'), (',', ','), ('Davis', 'davi'), ('KC', 'kc'), ('.', '.')]

>> Lemmatization: 
 [('Cuzzocrea', 'Cuzzocrea'), ('A', 'A'), (',', ','), ('Song', 'Song'), ('IY', 'IY'), (',', ','), ('Davis', 'Davis'), ('KC', 'KC'), ('.', '.')]


------------------- Sentence 3 -------------------

Analytics over large‑scale multidimensional data: The big data revolution!.

>> Tokens are: 
 ['Analytics', 'large‑scale', 'multidimensional', 'data', ':', 'The', 'big', 'data', 'revolution', '!', '.']

>> Bigrams are: 
 [('Analytics', 'large‑scale'), ('large‑scale', 'multidimensional'), ('multidimensional', 'data'), ('data', ':'), (':', 'The'), ('The', 'big'), ('big', 'data'), ('data', 'revolution'), ('revolution', '!'), ('!', '.')]

>> Trigrams are: 
 [('Analytics', 'large‑scale', 'multidimensional'), ('large‑scale', 'multidimensional', 'data'), ('multidimensional', 'data', ':'), ('data', ':', 'The'), (':', 'The', 'big'), ('The', 'big', 'data'), ('big', 'data', 'revolution'), ('data', 'revolution', '!'), ('revolution', '!', '.')]

>> POS Tags are: 
 [('Analytics', 'NNS'), ('large‑scale', 'JJ'), ('multidimensional', 'JJ'), ('data', 'NNS'), (':', ':'), ('The', 'DT'), ('big', 'JJ'), ('data', 'NNS'), ('revolution', 'NN'), ('!', '.'), ('.', '.')]

>> Noun Phrases are: 
 ['Analytics', 'large‑scale multidimensional data', 'The big data revolution']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Analytics', 'analyt'), ('large‑scale', 'large‑scal'), ('multidimensional', 'multidimension'), ('data', 'data'), (':', ':'), ('The', 'the'), ('big', 'big'), ('data', 'data'), ('revolution', 'revolut'), ('!', '!'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Analytics', 'analyt'), ('large‑scale', 'large‑scal'), ('multidimensional', 'multidimension'), ('data', 'data'), (':', ':'), ('The', 'the'), ('big', 'big'), ('data', 'data'), ('revolution', 'revolut'), ('!', '!'), ('.', '.')]

>> Lemmatization: 
 [('Analytics', 'Analytics'), ('large‑scale', 'large‑scale'), ('multidimensional', 'multidimensional'), ('data', 'data'), (':', ':'), ('The', 'The'), ('big', 'big'), ('data', 'data'), ('revolution', 'revolution'), ('!', '!'), ('.', '.')]


------------------- Sentence 4 -------------------

In:  Proceedings of the ACM International Workshop on Data Warehousing and OLAP, 2011. pp 101–104.

>> Tokens are: 
 ['In', ':', 'Proceedings', 'ACM', 'International', 'Workshop', 'Data', 'Warehousing', 'OLAP', ',', '2011.', 'pp', '101–104', '.']

>> Bigrams are: 
 [('In', ':'), (':', 'Proceedings'), ('Proceedings', 'ACM'), ('ACM', 'International'), ('International', 'Workshop'), ('Workshop', 'Data'), ('Data', 'Warehousing'), ('Warehousing', 'OLAP'), ('OLAP', ','), (',', '2011.'), ('2011.', 'pp'), ('pp', '101–104'), ('101–104', '.')]

>> Trigrams are: 
 [('In', ':', 'Proceedings'), (':', 'Proceedings', 'ACM'), ('Proceedings', 'ACM', 'International'), ('ACM', 'International', 'Workshop'), ('International', 'Workshop', 'Data'), ('Workshop', 'Data', 'Warehousing'), ('Data', 'Warehousing', 'OLAP'), ('Warehousing', 'OLAP', ','), ('OLAP', ',', '2011.'), (',', '2011.', 'pp'), ('2011.', 'pp', '101–104'), ('pp', '101–104', '.')]

>> POS Tags are: 
 [('In', 'IN'), (':', ':'), ('Proceedings', 'NNS'), ('ACM', 'NNP'), ('International', 'NNP'), ('Workshop', 'NNP'), ('Data', 'NNP'), ('Warehousing', 'NNP'), ('OLAP', 'NNP'), (',', ','), ('2011.', 'CD'), ('pp', 'NN'), ('101–104', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Proceedings ACM International Workshop Data Warehousing OLAP', 'pp']

>> Named Entities are: 
 [('ORGANIZATION', 'ACM International Workshop Data')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), (':', ':'), ('Proceedings', 'proceed'), ('ACM', 'acm'), ('International', 'intern'), ('Workshop', 'workshop'), ('Data', 'data'), ('Warehousing', 'wareh'), ('OLAP', 'olap'), (',', ','), ('2011.', '2011.'), ('pp', 'pp'), ('101–104', '101–104'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), (':', ':'), ('Proceedings', 'proceed'), ('ACM', 'acm'), ('International', 'intern'), ('Workshop', 'workshop'), ('Data', 'data'), ('Warehousing', 'wareh'), ('OLAP', 'olap'), (',', ','), ('2011.', '2011.'), ('pp', 'pp'), ('101–104', '101–104'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), (':', ':'), ('Proceedings', 'Proceedings'), ('ACM', 'ACM'), ('International', 'International'), ('Workshop', 'Workshop'), ('Data', 'Data'), ('Warehousing', 'Warehousing'), ('OLAP', 'OLAP'), (',', ','), ('2011.', '2011.'), ('pp', 'pp'), ('101–104', '101–104'), ('.', '.')]



========================================== PARAGRAPH 492 ===========================================

 101. Zhang J, Huang ML. 5Ws model for big data analysis and visualization. In: Proceedings of the International Confer‑ ence on Computational Science and Engineering, 2013. pp 1021–1028. 

------------------- Sentence 1 -------------------

 101.

>> Tokens are: 
 ['101', '.']

>> Bigrams are: 
 [('101', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('101', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('101', '101'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('101', '101'), ('.', '.')]

>> Lemmatization: 
 [('101', '101'), ('.', '.')]


------------------- Sentence 2 -------------------

Zhang J, Huang ML.

>> Tokens are: 
 ['Zhang', 'J', ',', 'Huang', 'ML', '.']

>> Bigrams are: 
 [('Zhang', 'J'), ('J', ','), (',', 'Huang'), ('Huang', 'ML'), ('ML', '.')]

>> Trigrams are: 
 [('Zhang', 'J', ','), ('J', ',', 'Huang'), (',', 'Huang', 'ML'), ('Huang', 'ML', '.')]

>> POS Tags are: 
 [('Zhang', 'NNP'), ('J', 'NNP'), (',', ','), ('Huang', 'NNP'), ('ML', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Zhang J', 'Huang ML']

>> Named Entities are: 
 [('PERSON', 'Zhang'), ('ORGANIZATION', 'J'), ('PERSON', 'Huang ML')] 

>> Stemming using Porter Stemmer: 
 [('Zhang', 'zhang'), ('J', 'j'), (',', ','), ('Huang', 'huang'), ('ML', 'ml'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Zhang', 'zhang'), ('J', 'j'), (',', ','), ('Huang', 'huang'), ('ML', 'ml'), ('.', '.')]

>> Lemmatization: 
 [('Zhang', 'Zhang'), ('J', 'J'), (',', ','), ('Huang', 'Huang'), ('ML', 'ML'), ('.', '.')]


------------------- Sentence 3 -------------------

5Ws model for big data analysis and visualization.

>> Tokens are: 
 ['5Ws', 'model', 'big', 'data', 'analysis', 'visualization', '.']

>> Bigrams are: 
 [('5Ws', 'model'), ('model', 'big'), ('big', 'data'), ('data', 'analysis'), ('analysis', 'visualization'), ('visualization', '.')]

>> Trigrams are: 
 [('5Ws', 'model', 'big'), ('model', 'big', 'data'), ('big', 'data', 'analysis'), ('data', 'analysis', 'visualization'), ('analysis', 'visualization', '.')]

>> POS Tags are: 
 [('5Ws', 'CD'), ('model', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('analysis', 'NN'), ('visualization', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['model', 'big data analysis visualization']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('5Ws', '5w'), ('model', 'model'), ('big', 'big'), ('data', 'data'), ('analysis', 'analysi'), ('visualization', 'visual'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('5Ws', '5ws'), ('model', 'model'), ('big', 'big'), ('data', 'data'), ('analysis', 'analysi'), ('visualization', 'visual'), ('.', '.')]

>> Lemmatization: 
 [('5Ws', '5Ws'), ('model', 'model'), ('big', 'big'), ('data', 'data'), ('analysis', 'analysis'), ('visualization', 'visualization'), ('.', '.')]


------------------- Sentence 4 -------------------

In: Proceedings of the International Confer‑ ence on Computational Science and Engineering, 2013. pp 1021–1028.

>> Tokens are: 
 ['In', ':', 'Proceedings', 'International', 'Confer‑', 'ence', 'Computational', 'Science', 'Engineering', ',', '2013.', 'pp', '1021–1028', '.']

>> Bigrams are: 
 [('In', ':'), (':', 'Proceedings'), ('Proceedings', 'International'), ('International', 'Confer‑'), ('Confer‑', 'ence'), ('ence', 'Computational'), ('Computational', 'Science'), ('Science', 'Engineering'), ('Engineering', ','), (',', '2013.'), ('2013.', 'pp'), ('pp', '1021–1028'), ('1021–1028', '.')]

>> Trigrams are: 
 [('In', ':', 'Proceedings'), (':', 'Proceedings', 'International'), ('Proceedings', 'International', 'Confer‑'), ('International', 'Confer‑', 'ence'), ('Confer‑', 'ence', 'Computational'), ('ence', 'Computational', 'Science'), ('Computational', 'Science', 'Engineering'), ('Science', 'Engineering', ','), ('Engineering', ',', '2013.'), (',', '2013.', 'pp'), ('2013.', 'pp', '1021–1028'), ('pp', '1021–1028', '.')]

>> POS Tags are: 
 [('In', 'IN'), (':', ':'), ('Proceedings', 'NNS'), ('International', 'NNP'), ('Confer‑', 'NNP'), ('ence', 'NN'), ('Computational', 'NNP'), ('Science', 'NNP'), ('Engineering', 'NNP'), (',', ','), ('2013.', 'CD'), ('pp', 'NN'), ('1021–1028', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Proceedings International Confer‑ ence Computational Science Engineering', 'pp']

>> Named Entities are: 
 [('ORGANIZATION', 'International'), ('ORGANIZATION', 'Computational Science Engineering')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), (':', ':'), ('Proceedings', 'proceed'), ('International', 'intern'), ('Confer‑', 'confer‑'), ('ence', 'enc'), ('Computational', 'comput'), ('Science', 'scienc'), ('Engineering', 'engin'), (',', ','), ('2013.', '2013.'), ('pp', 'pp'), ('1021–1028', '1021–1028'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), (':', ':'), ('Proceedings', 'proceed'), ('International', 'intern'), ('Confer‑', 'confer‑'), ('ence', 'enc'), ('Computational', 'comput'), ('Science', 'scienc'), ('Engineering', 'engin'), (',', ','), ('2013.', '2013.'), ('pp', 'pp'), ('1021–1028', '1021–1028'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), (':', ':'), ('Proceedings', 'Proceedings'), ('International', 'International'), ('Confer‑', 'Confer‑'), ('ence', 'ence'), ('Computational', 'Computational'), ('Science', 'Science'), ('Engineering', 'Engineering'), (',', ','), ('2013.', '2013.'), ('pp', 'pp'), ('1021–1028', '1021–1028'), ('.', '.')]



========================================== PARAGRAPH 493 ===========================================

 102. Chandarana  P, Vijayalakshmi M. Big data analytics frameworks. In: Proceedings of the International Conference on  Circuits, Systems, Communication and Information Technology Applications, 2014. pp 430–434. 

------------------- Sentence 1 -------------------

 102.

>> Tokens are: 
 ['102', '.']

>> Bigrams are: 
 [('102', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('102', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('102', '102'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('102', '102'), ('.', '.')]

>> Lemmatization: 
 [('102', '102'), ('.', '.')]


------------------- Sentence 2 -------------------

Chandarana  P, Vijayalakshmi M. Big data analytics frameworks.

>> Tokens are: 
 ['Chandarana', 'P', ',', 'Vijayalakshmi', 'M.', 'Big', 'data', 'analytics', 'frameworks', '.']

>> Bigrams are: 
 [('Chandarana', 'P'), ('P', ','), (',', 'Vijayalakshmi'), ('Vijayalakshmi', 'M.'), ('M.', 'Big'), ('Big', 'data'), ('data', 'analytics'), ('analytics', 'frameworks'), ('frameworks', '.')]

>> Trigrams are: 
 [('Chandarana', 'P', ','), ('P', ',', 'Vijayalakshmi'), (',', 'Vijayalakshmi', 'M.'), ('Vijayalakshmi', 'M.', 'Big'), ('M.', 'Big', 'data'), ('Big', 'data', 'analytics'), ('data', 'analytics', 'frameworks'), ('analytics', 'frameworks', '.')]

>> POS Tags are: 
 [('Chandarana', 'NNP'), ('P', 'NNP'), (',', ','), ('Vijayalakshmi', 'NNP'), ('M.', 'NNP'), ('Big', 'NNP'), ('data', 'NNS'), ('analytics', 'NNS'), ('frameworks', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['Chandarana P', 'Vijayalakshmi M. Big data analytics frameworks']

>> Named Entities are: 
 [('PERSON', 'Chandarana'), ('ORGANIZATION', 'P'), ('PERSON', 'Vijayalakshmi M.')] 

>> Stemming using Porter Stemmer: 
 [('Chandarana', 'chandarana'), ('P', 'p'), (',', ','), ('Vijayalakshmi', 'vijayalakshmi'), ('M.', 'm.'), ('Big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('frameworks', 'framework'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Chandarana', 'chandarana'), ('P', 'p'), (',', ','), ('Vijayalakshmi', 'vijayalakshmi'), ('M.', 'm.'), ('Big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('frameworks', 'framework'), ('.', '.')]

>> Lemmatization: 
 [('Chandarana', 'Chandarana'), ('P', 'P'), (',', ','), ('Vijayalakshmi', 'Vijayalakshmi'), ('M.', 'M.'), ('Big', 'Big'), ('data', 'data'), ('analytics', 'analytics'), ('frameworks', 'framework'), ('.', '.')]


------------------- Sentence 3 -------------------

In: Proceedings of the International Conference on  Circuits, Systems, Communication and Information Technology Applications, 2014. pp 430–434.

>> Tokens are: 
 ['In', ':', 'Proceedings', 'International', 'Conference', 'Circuits', ',', 'Systems', ',', 'Communication', 'Information', 'Technology', 'Applications', ',', '2014.', 'pp', '430–434', '.']

>> Bigrams are: 
 [('In', ':'), (':', 'Proceedings'), ('Proceedings', 'International'), ('International', 'Conference'), ('Conference', 'Circuits'), ('Circuits', ','), (',', 'Systems'), ('Systems', ','), (',', 'Communication'), ('Communication', 'Information'), ('Information', 'Technology'), ('Technology', 'Applications'), ('Applications', ','), (',', '2014.'), ('2014.', 'pp'), ('pp', '430–434'), ('430–434', '.')]

>> Trigrams are: 
 [('In', ':', 'Proceedings'), (':', 'Proceedings', 'International'), ('Proceedings', 'International', 'Conference'), ('International', 'Conference', 'Circuits'), ('Conference', 'Circuits', ','), ('Circuits', ',', 'Systems'), (',', 'Systems', ','), ('Systems', ',', 'Communication'), (',', 'Communication', 'Information'), ('Communication', 'Information', 'Technology'), ('Information', 'Technology', 'Applications'), ('Technology', 'Applications', ','), ('Applications', ',', '2014.'), (',', '2014.', 'pp'), ('2014.', 'pp', '430–434'), ('pp', '430–434', '.')]

>> POS Tags are: 
 [('In', 'IN'), (':', ':'), ('Proceedings', 'NNS'), ('International', 'NNP'), ('Conference', 'NNP'), ('Circuits', 'NNP'), (',', ','), ('Systems', 'NNP'), (',', ','), ('Communication', 'NNP'), ('Information', 'NNP'), ('Technology', 'NNP'), ('Applications', 'NNP'), (',', ','), ('2014.', 'CD'), ('pp', 'NN'), ('430–434', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Proceedings International Conference Circuits', 'Systems', 'Communication Information Technology Applications', 'pp']

>> Named Entities are: 
 [('ORGANIZATION', 'International Conference Circuits'), ('PERSON', 'Systems'), ('ORGANIZATION', 'Communication Information Technology Applications')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), (':', ':'), ('Proceedings', 'proceed'), ('International', 'intern'), ('Conference', 'confer'), ('Circuits', 'circuit'), (',', ','), ('Systems', 'system'), (',', ','), ('Communication', 'commun'), ('Information', 'inform'), ('Technology', 'technolog'), ('Applications', 'applic'), (',', ','), ('2014.', '2014.'), ('pp', 'pp'), ('430–434', '430–434'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), (':', ':'), ('Proceedings', 'proceed'), ('International', 'intern'), ('Conference', 'confer'), ('Circuits', 'circuit'), (',', ','), ('Systems', 'system'), (',', ','), ('Communication', 'communic'), ('Information', 'inform'), ('Technology', 'technolog'), ('Applications', 'applic'), (',', ','), ('2014.', '2014.'), ('pp', 'pp'), ('430–434', '430–434'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), (':', ':'), ('Proceedings', 'Proceedings'), ('International', 'International'), ('Conference', 'Conference'), ('Circuits', 'Circuits'), (',', ','), ('Systems', 'Systems'), (',', ','), ('Communication', 'Communication'), ('Information', 'Information'), ('Technology', 'Technology'), ('Applications', 'Applications'), (',', ','), ('2014.', '2014.'), ('pp', 'pp'), ('430–434', '430–434'), ('.', '.')]



========================================== PARAGRAPH 494 ===========================================

 103. Apache Drill February 2, 2015. [Online]. Available: URL: http://drill.apache.org/.  104. Hu H, Wen Y, Chua T‑S, Li X. Toward scalable systems for big data analytics: a technology tutorial. IEEE Access.  

------------------- Sentence 1 -------------------

 103.

>> Tokens are: 
 ['103', '.']

>> Bigrams are: 
 [('103', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('103', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('103', '103'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('103', '103'), ('.', '.')]

>> Lemmatization: 
 [('103', '103'), ('.', '.')]


------------------- Sentence 2 -------------------

Apache Drill February 2, 2015.

>> Tokens are: 
 ['Apache', 'Drill', 'February', '2', ',', '2015', '.']

>> Bigrams are: 
 [('Apache', 'Drill'), ('Drill', 'February'), ('February', '2'), ('2', ','), (',', '2015'), ('2015', '.')]

>> Trigrams are: 
 [('Apache', 'Drill', 'February'), ('Drill', 'February', '2'), ('February', '2', ','), ('2', ',', '2015'), (',', '2015', '.')]

>> POS Tags are: 
 [('Apache', 'NNP'), ('Drill', 'NNP'), ('February', 'NNP'), ('2', 'CD'), (',', ','), ('2015', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Apache Drill February']

>> Named Entities are: 
 [('PERSON', 'Apache'), ('PERSON', 'Drill')] 

>> Stemming using Porter Stemmer: 
 [('Apache', 'apach'), ('Drill', 'drill'), ('February', 'februari'), ('2', '2'), (',', ','), ('2015', '2015'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Apache', 'apach'), ('Drill', 'drill'), ('February', 'februari'), ('2', '2'), (',', ','), ('2015', '2015'), ('.', '.')]

>> Lemmatization: 
 [('Apache', 'Apache'), ('Drill', 'Drill'), ('February', 'February'), ('2', '2'), (',', ','), ('2015', '2015'), ('.', '.')]


------------------- Sentence 3 -------------------

[Online].

>> Tokens are: 
 ['[', 'Online', ']', '.']

>> Bigrams are: 
 [('[', 'Online'), ('Online', ']'), (']', '.')]

>> Trigrams are: 
 [('[', 'Online', ']'), ('Online', ']', '.')]

>> POS Tags are: 
 [('[', 'JJ'), ('Online', 'NNP'), (']', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['[ Online ]']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('Online', 'onlin'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('Online', 'onlin'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('Online', 'Online'), (']', ']'), ('.', '.')]


------------------- Sentence 4 -------------------

Available: URL: http://drill.apache.org/.

>> Tokens are: 
 ['Available', ':', 'URL', ':', 'http', ':', '//drill.apache.org/', '.']

>> Bigrams are: 
 [('Available', ':'), (':', 'URL'), ('URL', ':'), (':', 'http'), ('http', ':'), (':', '//drill.apache.org/'), ('//drill.apache.org/', '.')]

>> Trigrams are: 
 [('Available', ':', 'URL'), (':', 'URL', ':'), ('URL', ':', 'http'), (':', 'http', ':'), ('http', ':', '//drill.apache.org/'), (':', '//drill.apache.org/', '.')]

>> POS Tags are: 
 [('Available', 'JJ'), (':', ':'), ('URL', 'NN'), (':', ':'), ('http', 'NN'), (':', ':'), ('//drill.apache.org/', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['URL', 'http', '//drill.apache.org/']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Available', 'avail'), (':', ':'), ('URL', 'url'), (':', ':'), ('http', 'http'), (':', ':'), ('//drill.apache.org/', '//drill.apache.org/'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Available', 'avail'), (':', ':'), ('URL', 'url'), (':', ':'), ('http', 'http'), (':', ':'), ('//drill.apache.org/', '//drill.apache.org/'), ('.', '.')]

>> Lemmatization: 
 [('Available', 'Available'), (':', ':'), ('URL', 'URL'), (':', ':'), ('http', 'http'), (':', ':'), ('//drill.apache.org/', '//drill.apache.org/'), ('.', '.')]


------------------- Sentence 5 -------------------

104.

>> Tokens are: 
 ['104', '.']

>> Bigrams are: 
 [('104', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('104', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('104', '104'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('104', '104'), ('.', '.')]

>> Lemmatization: 
 [('104', '104'), ('.', '.')]


------------------- Sentence 6 -------------------

Hu H, Wen Y, Chua T‑S, Li X.

>> Tokens are: 
 ['Hu', 'H', ',', 'Wen', 'Y', ',', 'Chua', 'T‑S', ',', 'Li', 'X', '.']

>> Bigrams are: 
 [('Hu', 'H'), ('H', ','), (',', 'Wen'), ('Wen', 'Y'), ('Y', ','), (',', 'Chua'), ('Chua', 'T‑S'), ('T‑S', ','), (',', 'Li'), ('Li', 'X'), ('X', '.')]

>> Trigrams are: 
 [('Hu', 'H', ','), ('H', ',', 'Wen'), (',', 'Wen', 'Y'), ('Wen', 'Y', ','), ('Y', ',', 'Chua'), (',', 'Chua', 'T‑S'), ('Chua', 'T‑S', ','), ('T‑S', ',', 'Li'), (',', 'Li', 'X'), ('Li', 'X', '.')]

>> POS Tags are: 
 [('Hu', 'NNP'), ('H', 'NNP'), (',', ','), ('Wen', 'NNP'), ('Y', 'NNP'), (',', ','), ('Chua', 'NNP'), ('T‑S', 'NNP'), (',', ','), ('Li', 'NNP'), ('X', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Hu H', 'Wen Y', 'Chua T‑S', 'Li X']

>> Named Entities are: 
 [('PERSON', 'Wen Y'), ('PERSON', 'Chua T‑S'), ('PERSON', 'Li X')] 

>> Stemming using Porter Stemmer: 
 [('Hu', 'hu'), ('H', 'h'), (',', ','), ('Wen', 'wen'), ('Y', 'y'), (',', ','), ('Chua', 'chua'), ('T‑S', 't‑'), (',', ','), ('Li', 'li'), ('X', 'x'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Hu', 'hu'), ('H', 'h'), (',', ','), ('Wen', 'wen'), ('Y', 'y'), (',', ','), ('Chua', 'chua'), ('T‑S', 't‑s'), (',', ','), ('Li', 'li'), ('X', 'x'), ('.', '.')]

>> Lemmatization: 
 [('Hu', 'Hu'), ('H', 'H'), (',', ','), ('Wen', 'Wen'), ('Y', 'Y'), (',', ','), ('Chua', 'Chua'), ('T‑S', 'T‑S'), (',', ','), ('Li', 'Li'), ('X', 'X'), ('.', '.')]


------------------- Sentence 7 -------------------

Toward scalable systems for big data analytics: a technology tutorial.

>> Tokens are: 
 ['Toward', 'scalable', 'systems', 'big', 'data', 'analytics', ':', 'technology', 'tutorial', '.']

>> Bigrams are: 
 [('Toward', 'scalable'), ('scalable', 'systems'), ('systems', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', ':'), (':', 'technology'), ('technology', 'tutorial'), ('tutorial', '.')]

>> Trigrams are: 
 [('Toward', 'scalable', 'systems'), ('scalable', 'systems', 'big'), ('systems', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', ':'), ('analytics', ':', 'technology'), (':', 'technology', 'tutorial'), ('technology', 'tutorial', '.')]

>> POS Tags are: 
 [('Toward', 'NNP'), ('scalable', 'JJ'), ('systems', 'NNS'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), (':', ':'), ('technology', 'NN'), ('tutorial', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Toward', 'scalable systems', 'big data analytics', 'technology tutorial']

>> Named Entities are: 
 [('PERSON', 'Toward')] 

>> Stemming using Porter Stemmer: 
 [('Toward', 'toward'), ('scalable', 'scalabl'), ('systems', 'system'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), (':', ':'), ('technology', 'technolog'), ('tutorial', 'tutori'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Toward', 'toward'), ('scalable', 'scalabl'), ('systems', 'system'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), (':', ':'), ('technology', 'technolog'), ('tutorial', 'tutori'), ('.', '.')]

>> Lemmatization: 
 [('Toward', 'Toward'), ('scalable', 'scalable'), ('systems', 'system'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), (':', ':'), ('technology', 'technology'), ('tutorial', 'tutorial'), ('.', '.')]


------------------- Sentence 8 -------------------

IEEE Access.

>> Tokens are: 
 ['IEEE', 'Access', '.']

>> Bigrams are: 
 [('IEEE', 'Access'), ('Access', '.')]

>> Trigrams are: 
 [('IEEE', 'Access', '.')]

>> POS Tags are: 
 [('IEEE', 'NNP'), ('Access', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['IEEE Access']

>> Named Entities are: 
 [('ORGANIZATION', 'IEEE Access')] 

>> Stemming using Porter Stemmer: 
 [('IEEE', 'ieee'), ('Access', 'access'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('IEEE', 'ieee'), ('Access', 'access'), ('.', '.')]

>> Lemmatization: 
 [('IEEE', 'IEEE'), ('Access', 'Access'), ('.', '.')]



========================================== PARAGRAPH 495 ===========================================

2014;2:652–87.  105. Sagiroglu S, Sinanc D, Big data: a review. In: Proceedings of the International Conference on Collaboration Tech‑ 

------------------- Sentence 1 -------------------

2014;2:652–87.

>> Tokens are: 
 ['2014', ';', '2:652–87', '.']

>> Bigrams are: 
 [('2014', ';'), (';', '2:652–87'), ('2:652–87', '.')]

>> Trigrams are: 
 [('2014', ';', '2:652–87'), (';', '2:652–87', '.')]

>> POS Tags are: 
 [('2014', 'CD'), (';', ':'), ('2:652–87', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('2014', '2014'), (';', ';'), ('2:652–87', '2:652–87'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('2014', '2014'), (';', ';'), ('2:652–87', '2:652–87'), ('.', '.')]

>> Lemmatization: 
 [('2014', '2014'), (';', ';'), ('2:652–87', '2:652–87'), ('.', '.')]


------------------- Sentence 2 -------------------

105.

>> Tokens are: 
 ['105', '.']

>> Bigrams are: 
 [('105', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('105', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('105', '105'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('105', '105'), ('.', '.')]

>> Lemmatization: 
 [('105', '105'), ('.', '.')]


------------------- Sentence 3 -------------------

Sagiroglu S, Sinanc D, Big data: a review.

>> Tokens are: 
 ['Sagiroglu', 'S', ',', 'Sinanc', 'D', ',', 'Big', 'data', ':', 'review', '.']

>> Bigrams are: 
 [('Sagiroglu', 'S'), ('S', ','), (',', 'Sinanc'), ('Sinanc', 'D'), ('D', ','), (',', 'Big'), ('Big', 'data'), ('data', ':'), (':', 'review'), ('review', '.')]

>> Trigrams are: 
 [('Sagiroglu', 'S', ','), ('S', ',', 'Sinanc'), (',', 'Sinanc', 'D'), ('Sinanc', 'D', ','), ('D', ',', 'Big'), (',', 'Big', 'data'), ('Big', 'data', ':'), ('data', ':', 'review'), (':', 'review', '.')]

>> POS Tags are: 
 [('Sagiroglu', 'NNP'), ('S', 'NNP'), (',', ','), ('Sinanc', 'NNP'), ('D', 'NNP'), (',', ','), ('Big', 'NNP'), ('data', 'NNS'), (':', ':'), ('review', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Sagiroglu S', 'Sinanc D', 'Big data', 'review']

>> Named Entities are: 
 [('PERSON', 'Sagiroglu'), ('ORGANIZATION', 'S'), ('PERSON', 'Sinanc D')] 

>> Stemming using Porter Stemmer: 
 [('Sagiroglu', 'sagiroglu'), ('S', 's'), (',', ','), ('Sinanc', 'sinanc'), ('D', 'd'), (',', ','), ('Big', 'big'), ('data', 'data'), (':', ':'), ('review', 'review'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Sagiroglu', 'sagiroglu'), ('S', 's'), (',', ','), ('Sinanc', 'sinanc'), ('D', 'd'), (',', ','), ('Big', 'big'), ('data', 'data'), (':', ':'), ('review', 'review'), ('.', '.')]

>> Lemmatization: 
 [('Sagiroglu', 'Sagiroglu'), ('S', 'S'), (',', ','), ('Sinanc', 'Sinanc'), ('D', 'D'), (',', ','), ('Big', 'Big'), ('data', 'data'), (':', ':'), ('review', 'review'), ('.', '.')]


------------------- Sentence 4 -------------------

In: Proceedings of the International Conference on Collaboration Tech‑

>> Tokens are: 
 ['In', ':', 'Proceedings', 'International', 'Conference', 'Collaboration', 'Tech‑']

>> Bigrams are: 
 [('In', ':'), (':', 'Proceedings'), ('Proceedings', 'International'), ('International', 'Conference'), ('Conference', 'Collaboration'), ('Collaboration', 'Tech‑')]

>> Trigrams are: 
 [('In', ':', 'Proceedings'), (':', 'Proceedings', 'International'), ('Proceedings', 'International', 'Conference'), ('International', 'Conference', 'Collaboration'), ('Conference', 'Collaboration', 'Tech‑')]

>> POS Tags are: 
 [('In', 'IN'), (':', ':'), ('Proceedings', 'NNS'), ('International', 'NNP'), ('Conference', 'NNP'), ('Collaboration', 'NNP'), ('Tech‑', 'NNP')]

>> Noun Phrases are: 
 ['Proceedings International Conference Collaboration Tech‑']

>> Named Entities are: 
 [('ORGANIZATION', 'International Conference Collaboration')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), (':', ':'), ('Proceedings', 'proceed'), ('International', 'intern'), ('Conference', 'confer'), ('Collaboration', 'collabor'), ('Tech‑', 'tech‑')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), (':', ':'), ('Proceedings', 'proceed'), ('International', 'intern'), ('Conference', 'confer'), ('Collaboration', 'collabor'), ('Tech‑', 'tech‑')]

>> Lemmatization: 
 [('In', 'In'), (':', ':'), ('Proceedings', 'Proceedings'), ('International', 'International'), ('Conference', 'Conference'), ('Collaboration', 'Collaboration'), ('Tech‑', 'Tech‑')]



========================================== PARAGRAPH 496 ===========================================

nologies and Systems, 2013. pp 42–47.  106. Fan W, Bifet A. Mining big data: current status, and forecast to the future. ACM SIGKDD Explor Newslett.  

------------------- Sentence 1 -------------------

nologies and Systems, 2013. pp 42–47.

>> Tokens are: 
 ['nologies', 'Systems', ',', '2013.', 'pp', '42–47', '.']

>> Bigrams are: 
 [('nologies', 'Systems'), ('Systems', ','), (',', '2013.'), ('2013.', 'pp'), ('pp', '42–47'), ('42–47', '.')]

>> Trigrams are: 
 [('nologies', 'Systems', ','), ('Systems', ',', '2013.'), (',', '2013.', 'pp'), ('2013.', 'pp', '42–47'), ('pp', '42–47', '.')]

>> POS Tags are: 
 [('nologies', 'NNS'), ('Systems', 'NNPS'), (',', ','), ('2013.', 'CD'), ('pp', 'NN'), ('42–47', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['nologies', 'pp']

>> Named Entities are: 
 [('PERSON', 'Systems')] 

>> Stemming using Porter Stemmer: 
 [('nologies', 'nolog'), ('Systems', 'system'), (',', ','), ('2013.', '2013.'), ('pp', 'pp'), ('42–47', '42–47'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('nologies', 'nolog'), ('Systems', 'system'), (',', ','), ('2013.', '2013.'), ('pp', 'pp'), ('42–47', '42–47'), ('.', '.')]

>> Lemmatization: 
 [('nologies', 'nologies'), ('Systems', 'Systems'), (',', ','), ('2013.', '2013.'), ('pp', 'pp'), ('42–47', '42–47'), ('.', '.')]


------------------- Sentence 2 -------------------

106.

>> Tokens are: 
 ['106', '.']

>> Bigrams are: 
 [('106', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('106', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('106', '106'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('106', '106'), ('.', '.')]

>> Lemmatization: 
 [('106', '106'), ('.', '.')]


------------------- Sentence 3 -------------------

Fan W, Bifet A.

>> Tokens are: 
 ['Fan', 'W', ',', 'Bifet', 'A', '.']

>> Bigrams are: 
 [('Fan', 'W'), ('W', ','), (',', 'Bifet'), ('Bifet', 'A'), ('A', '.')]

>> Trigrams are: 
 [('Fan', 'W', ','), ('W', ',', 'Bifet'), (',', 'Bifet', 'A'), ('Bifet', 'A', '.')]

>> POS Tags are: 
 [('Fan', 'NNP'), ('W', 'NNP'), (',', ','), ('Bifet', 'NNP'), ('A', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Fan W', 'Bifet A']

>> Named Entities are: 
 [('PERSON', 'Fan'), ('ORGANIZATION', 'W'), ('PERSON', 'Bifet A')] 

>> Stemming using Porter Stemmer: 
 [('Fan', 'fan'), ('W', 'w'), (',', ','), ('Bifet', 'bifet'), ('A', 'a'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Fan', 'fan'), ('W', 'w'), (',', ','), ('Bifet', 'bifet'), ('A', 'a'), ('.', '.')]

>> Lemmatization: 
 [('Fan', 'Fan'), ('W', 'W'), (',', ','), ('Bifet', 'Bifet'), ('A', 'A'), ('.', '.')]


------------------- Sentence 4 -------------------

Mining big data: current status, and forecast to the future.

>> Tokens are: 
 ['Mining', 'big', 'data', ':', 'current', 'status', ',', 'forecast', 'future', '.']

>> Bigrams are: 
 [('Mining', 'big'), ('big', 'data'), ('data', ':'), (':', 'current'), ('current', 'status'), ('status', ','), (',', 'forecast'), ('forecast', 'future'), ('future', '.')]

>> Trigrams are: 
 [('Mining', 'big', 'data'), ('big', 'data', ':'), ('data', ':', 'current'), (':', 'current', 'status'), ('current', 'status', ','), ('status', ',', 'forecast'), (',', 'forecast', 'future'), ('forecast', 'future', '.')]

>> POS Tags are: 
 [('Mining', 'VBG'), ('big', 'JJ'), ('data', 'NNS'), (':', ':'), ('current', 'JJ'), ('status', 'NN'), (',', ','), ('forecast', 'VBN'), ('future', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['big data', 'current status', 'future']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Mining', 'mine'), ('big', 'big'), ('data', 'data'), (':', ':'), ('current', 'current'), ('status', 'statu'), (',', ','), ('forecast', 'forecast'), ('future', 'futur'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Mining', 'mine'), ('big', 'big'), ('data', 'data'), (':', ':'), ('current', 'current'), ('status', 'status'), (',', ','), ('forecast', 'forecast'), ('future', 'futur'), ('.', '.')]

>> Lemmatization: 
 [('Mining', 'Mining'), ('big', 'big'), ('data', 'data'), (':', ':'), ('current', 'current'), ('status', 'status'), (',', ','), ('forecast', 'forecast'), ('future', 'future'), ('.', '.')]


------------------- Sentence 5 -------------------

ACM SIGKDD Explor Newslett.

>> Tokens are: 
 ['ACM', 'SIGKDD', 'Explor', 'Newslett', '.']

>> Bigrams are: 
 [('ACM', 'SIGKDD'), ('SIGKDD', 'Explor'), ('Explor', 'Newslett'), ('Newslett', '.')]

>> Trigrams are: 
 [('ACM', 'SIGKDD', 'Explor'), ('SIGKDD', 'Explor', 'Newslett'), ('Explor', 'Newslett', '.')]

>> POS Tags are: 
 [('ACM', 'NNP'), ('SIGKDD', 'NNP'), ('Explor', 'NNP'), ('Newslett', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['ACM SIGKDD Explor Newslett']

>> Named Entities are: 
 [('ORGANIZATION', 'ACM'), ('ORGANIZATION', 'SIGKDD Explor Newslett')] 

>> Stemming using Porter Stemmer: 
 [('ACM', 'acm'), ('SIGKDD', 'sigkdd'), ('Explor', 'explor'), ('Newslett', 'newslett'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('ACM', 'acm'), ('SIGKDD', 'sigkdd'), ('Explor', 'explor'), ('Newslett', 'newslett'), ('.', '.')]

>> Lemmatization: 
 [('ACM', 'ACM'), ('SIGKDD', 'SIGKDD'), ('Explor', 'Explor'), ('Newslett', 'Newslett'), ('.', '.')]



========================================== PARAGRAPH 497 ===========================================

2013;14(2):1–5.  107. Diebold FX. On the origin(s) and development of the term “big data”, Penn Institute for Economic Research,  

------------------- Sentence 1 -------------------

2013;14(2):1–5.

>> Tokens are: 
 ['2013', ';', '14', '(', '2', ')', ':1–5', '.']

>> Bigrams are: 
 [('2013', ';'), (';', '14'), ('14', '('), ('(', '2'), ('2', ')'), (')', ':1–5'), (':1–5', '.')]

>> Trigrams are: 
 [('2013', ';', '14'), (';', '14', '('), ('14', '(', '2'), ('(', '2', ')'), ('2', ')', ':1–5'), (')', ':1–5', '.')]

>> POS Tags are: 
 [('2013', 'CD'), (';', ':'), ('14', 'CD'), ('(', '('), ('2', 'CD'), (')', ')'), (':1–5', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 [':1–5']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('2013', '2013'), (';', ';'), ('14', '14'), ('(', '('), ('2', '2'), (')', ')'), (':1–5', ':1–5'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('2013', '2013'), (';', ';'), ('14', '14'), ('(', '('), ('2', '2'), (')', ')'), (':1–5', ':1–5'), ('.', '.')]

>> Lemmatization: 
 [('2013', '2013'), (';', ';'), ('14', '14'), ('(', '('), ('2', '2'), (')', ')'), (':1–5', ':1–5'), ('.', '.')]


------------------- Sentence 2 -------------------

107.

>> Tokens are: 
 ['107', '.']

>> Bigrams are: 
 [('107', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('107', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('107', '107'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('107', '107'), ('.', '.')]

>> Lemmatization: 
 [('107', '107'), ('.', '.')]


------------------- Sentence 3 -------------------

Diebold FX.

>> Tokens are: 
 ['Diebold', 'FX', '.']

>> Bigrams are: 
 [('Diebold', 'FX'), ('FX', '.')]

>> Trigrams are: 
 [('Diebold', 'FX', '.')]

>> POS Tags are: 
 [('Diebold', 'NNP'), ('FX', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Diebold FX']

>> Named Entities are: 
 [('PERSON', 'Diebold')] 

>> Stemming using Porter Stemmer: 
 [('Diebold', 'diebold'), ('FX', 'fx'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Diebold', 'diebold'), ('FX', 'fx'), ('.', '.')]

>> Lemmatization: 
 [('Diebold', 'Diebold'), ('FX', 'FX'), ('.', '.')]


------------------- Sentence 4 -------------------

On the origin(s) and development of the term “big data”, Penn Institute for Economic Research,

>> Tokens are: 
 ['On', 'origin', '(', ')', 'development', 'term', '“', 'big', 'data', '”', ',', 'Penn', 'Institute', 'Economic', 'Research', ',']

>> Bigrams are: 
 [('On', 'origin'), ('origin', '('), ('(', ')'), (')', 'development'), ('development', 'term'), ('term', '“'), ('“', 'big'), ('big', 'data'), ('data', '”'), ('”', ','), (',', 'Penn'), ('Penn', 'Institute'), ('Institute', 'Economic'), ('Economic', 'Research'), ('Research', ',')]

>> Trigrams are: 
 [('On', 'origin', '('), ('origin', '(', ')'), ('(', ')', 'development'), (')', 'development', 'term'), ('development', 'term', '“'), ('term', '“', 'big'), ('“', 'big', 'data'), ('big', 'data', '”'), ('data', '”', ','), ('”', ',', 'Penn'), (',', 'Penn', 'Institute'), ('Penn', 'Institute', 'Economic'), ('Institute', 'Economic', 'Research'), ('Economic', 'Research', ',')]

>> POS Tags are: 
 [('On', 'IN'), ('origin', 'NN'), ('(', '('), (')', ')'), ('development', 'NN'), ('term', 'NN'), ('“', 'NNP'), ('big', 'JJ'), ('data', 'NNS'), ('”', 'NN'), (',', ','), ('Penn', 'NNP'), ('Institute', 'NNP'), ('Economic', 'NNP'), ('Research', 'NNP'), (',', ',')]

>> Noun Phrases are: 
 ['origin', 'development term “', 'big data ”', 'Penn Institute Economic Research']

>> Named Entities are: 
 [('PERSON', 'Penn Institute Economic Research')] 

>> Stemming using Porter Stemmer: 
 [('On', 'on'), ('origin', 'origin'), ('(', '('), (')', ')'), ('development', 'develop'), ('term', 'term'), ('“', '“'), ('big', 'big'), ('data', 'data'), ('”', '”'), (',', ','), ('Penn', 'penn'), ('Institute', 'institut'), ('Economic', 'econom'), ('Research', 'research'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('On', 'on'), ('origin', 'origin'), ('(', '('), (')', ')'), ('development', 'develop'), ('term', 'term'), ('“', '“'), ('big', 'big'), ('data', 'data'), ('”', '”'), (',', ','), ('Penn', 'penn'), ('Institute', 'institut'), ('Economic', 'econom'), ('Research', 'research'), (',', ',')]

>> Lemmatization: 
 [('On', 'On'), ('origin', 'origin'), ('(', '('), (')', ')'), ('development', 'development'), ('term', 'term'), ('“', '“'), ('big', 'big'), ('data', 'data'), ('”', '”'), (',', ','), ('Penn', 'Penn'), ('Institute', 'Institute'), ('Economic', 'Economic'), ('Research', 'Research'), (',', ',')]



========================================== PARAGRAPH 498 ===========================================

Department of Economics, University of Pennsylvania, Tech. Rep. 2012. [Online]. Available: http://economics.sas. upenn.edu/sites/economics.sas.upenn.edu/files/12‑037.pdf. 

------------------- Sentence 1 -------------------

Department of Economics, University of Pennsylvania, Tech.

>> Tokens are: 
 ['Department', 'Economics', ',', 'University', 'Pennsylvania', ',', 'Tech', '.']

>> Bigrams are: 
 [('Department', 'Economics'), ('Economics', ','), (',', 'University'), ('University', 'Pennsylvania'), ('Pennsylvania', ','), (',', 'Tech'), ('Tech', '.')]

>> Trigrams are: 
 [('Department', 'Economics', ','), ('Economics', ',', 'University'), (',', 'University', 'Pennsylvania'), ('University', 'Pennsylvania', ','), ('Pennsylvania', ',', 'Tech'), (',', 'Tech', '.')]

>> POS Tags are: 
 [('Department', 'NNP'), ('Economics', 'NNP'), (',', ','), ('University', 'NNP'), ('Pennsylvania', 'NNP'), (',', ','), ('Tech', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Department Economics', 'University Pennsylvania', 'Tech']

>> Named Entities are: 
 [('ORGANIZATION', 'University Pennsylvania'), ('GPE', 'Tech')] 

>> Stemming using Porter Stemmer: 
 [('Department', 'depart'), ('Economics', 'econom'), (',', ','), ('University', 'univers'), ('Pennsylvania', 'pennsylvania'), (',', ','), ('Tech', 'tech'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Department', 'depart'), ('Economics', 'econom'), (',', ','), ('University', 'univers'), ('Pennsylvania', 'pennsylvania'), (',', ','), ('Tech', 'tech'), ('.', '.')]

>> Lemmatization: 
 [('Department', 'Department'), ('Economics', 'Economics'), (',', ','), ('University', 'University'), ('Pennsylvania', 'Pennsylvania'), (',', ','), ('Tech', 'Tech'), ('.', '.')]


------------------- Sentence 2 -------------------

Rep. 2012.

>> Tokens are: 
 ['Rep.', '2012', '.']

>> Bigrams are: 
 [('Rep.', '2012'), ('2012', '.')]

>> Trigrams are: 
 [('Rep.', '2012', '.')]

>> POS Tags are: 
 [('Rep.', 'NNP'), ('2012', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Rep.']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Rep.', 'rep.'), ('2012', '2012'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Rep.', 'rep.'), ('2012', '2012'), ('.', '.')]

>> Lemmatization: 
 [('Rep.', 'Rep.'), ('2012', '2012'), ('.', '.')]


------------------- Sentence 3 -------------------

[Online].

>> Tokens are: 
 ['[', 'Online', ']', '.']

>> Bigrams are: 
 [('[', 'Online'), ('Online', ']'), (']', '.')]

>> Trigrams are: 
 [('[', 'Online', ']'), ('Online', ']', '.')]

>> POS Tags are: 
 [('[', 'JJ'), ('Online', 'NNP'), (']', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['[ Online ]']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('Online', 'onlin'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('Online', 'onlin'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('Online', 'Online'), (']', ']'), ('.', '.')]


------------------- Sentence 4 -------------------

Available: http://economics.sas.

>> Tokens are: 
 ['Available', ':', 'http', ':', '//economics.sas', '.']

>> Bigrams are: 
 [('Available', ':'), (':', 'http'), ('http', ':'), (':', '//economics.sas'), ('//economics.sas', '.')]

>> Trigrams are: 
 [('Available', ':', 'http'), (':', 'http', ':'), ('http', ':', '//economics.sas'), (':', '//economics.sas', '.')]

>> POS Tags are: 
 [('Available', 'JJ'), (':', ':'), ('http', 'NN'), (':', ':'), ('//economics.sas', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['http', '//economics.sas']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Available', 'avail'), (':', ':'), ('http', 'http'), (':', ':'), ('//economics.sas', '//economics.sa'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Available', 'avail'), (':', ':'), ('http', 'http'), (':', ':'), ('//economics.sas', '//economics.sa'), ('.', '.')]

>> Lemmatization: 
 [('Available', 'Available'), (':', ':'), ('http', 'http'), (':', ':'), ('//economics.sas', '//economics.sas'), ('.', '.')]


------------------- Sentence 5 -------------------

upenn.edu/sites/economics.sas.upenn.edu/files/12‑037.pdf.

>> Tokens are: 
 ['upenn.edu/sites/economics.sas.upenn.edu/files/12‑037.pdf', '.']

>> Bigrams are: 
 [('upenn.edu/sites/economics.sas.upenn.edu/files/12‑037.pdf', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('upenn.edu/sites/economics.sas.upenn.edu/files/12‑037.pdf', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['upenn.edu/sites/economics.sas.upenn.edu/files/12‑037.pdf']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('upenn.edu/sites/economics.sas.upenn.edu/files/12‑037.pdf', 'upenn.edu/sites/economics.sas.upenn.edu/files/12‑037.pdf'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('upenn.edu/sites/economics.sas.upenn.edu/files/12‑037.pdf', 'upenn.edu/sites/economics.sas.upenn.edu/files/12‑037.pdf'), ('.', '.')]

>> Lemmatization: 
 [('upenn.edu/sites/economics.sas.upenn.edu/files/12‑037.pdf', 'upenn.edu/sites/economics.sas.upenn.edu/files/12‑037.pdf'), ('.', '.')]



========================================== PARAGRAPH 499 ===========================================

 108. Weiss SM, Indurkhya N. Predictive data mining: a practical guide. San Francisco: Morgan Kaufmann Publishers Inc.;  1998. 

------------------- Sentence 1 -------------------

 108.

>> Tokens are: 
 ['108', '.']

>> Bigrams are: 
 [('108', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('108', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('108', '108'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('108', '108'), ('.', '.')]

>> Lemmatization: 
 [('108', '108'), ('.', '.')]


------------------- Sentence 2 -------------------

Weiss SM, Indurkhya N. Predictive data mining: a practical guide.

>> Tokens are: 
 ['Weiss', 'SM', ',', 'Indurkhya', 'N.', 'Predictive', 'data', 'mining', ':', 'practical', 'guide', '.']

>> Bigrams are: 
 [('Weiss', 'SM'), ('SM', ','), (',', 'Indurkhya'), ('Indurkhya', 'N.'), ('N.', 'Predictive'), ('Predictive', 'data'), ('data', 'mining'), ('mining', ':'), (':', 'practical'), ('practical', 'guide'), ('guide', '.')]

>> Trigrams are: 
 [('Weiss', 'SM', ','), ('SM', ',', 'Indurkhya'), (',', 'Indurkhya', 'N.'), ('Indurkhya', 'N.', 'Predictive'), ('N.', 'Predictive', 'data'), ('Predictive', 'data', 'mining'), ('data', 'mining', ':'), ('mining', ':', 'practical'), (':', 'practical', 'guide'), ('practical', 'guide', '.')]

>> POS Tags are: 
 [('Weiss', 'JJ'), ('SM', 'NNP'), (',', ','), ('Indurkhya', 'NNP'), ('N.', 'NNP'), ('Predictive', 'NNP'), ('data', 'NN'), ('mining', 'NN'), (':', ':'), ('practical', 'JJ'), ('guide', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Weiss SM', 'Indurkhya N. Predictive data mining', 'practical guide']

>> Named Entities are: 
 [('PERSON', 'Weiss SM'), ('PERSON', 'Indurkhya N.')] 

>> Stemming using Porter Stemmer: 
 [('Weiss', 'weiss'), ('SM', 'sm'), (',', ','), ('Indurkhya', 'indurkhya'), ('N.', 'n.'), ('Predictive', 'predict'), ('data', 'data'), ('mining', 'mine'), (':', ':'), ('practical', 'practic'), ('guide', 'guid'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Weiss', 'weiss'), ('SM', 'sm'), (',', ','), ('Indurkhya', 'indurkhya'), ('N.', 'n.'), ('Predictive', 'predict'), ('data', 'data'), ('mining', 'mine'), (':', ':'), ('practical', 'practic'), ('guide', 'guid'), ('.', '.')]

>> Lemmatization: 
 [('Weiss', 'Weiss'), ('SM', 'SM'), (',', ','), ('Indurkhya', 'Indurkhya'), ('N.', 'N.'), ('Predictive', 'Predictive'), ('data', 'data'), ('mining', 'mining'), (':', ':'), ('practical', 'practical'), ('guide', 'guide'), ('.', '.')]


------------------- Sentence 3 -------------------

San Francisco: Morgan Kaufmann Publishers Inc.;  1998.

>> Tokens are: 
 ['San', 'Francisco', ':', 'Morgan', 'Kaufmann', 'Publishers', 'Inc.', ';', '1998', '.']

>> Bigrams are: 
 [('San', 'Francisco'), ('Francisco', ':'), (':', 'Morgan'), ('Morgan', 'Kaufmann'), ('Kaufmann', 'Publishers'), ('Publishers', 'Inc.'), ('Inc.', ';'), (';', '1998'), ('1998', '.')]

>> Trigrams are: 
 [('San', 'Francisco', ':'), ('Francisco', ':', 'Morgan'), (':', 'Morgan', 'Kaufmann'), ('Morgan', 'Kaufmann', 'Publishers'), ('Kaufmann', 'Publishers', 'Inc.'), ('Publishers', 'Inc.', ';'), ('Inc.', ';', '1998'), (';', '1998', '.')]

>> POS Tags are: 
 [('San', 'NNP'), ('Francisco', 'NNP'), (':', ':'), ('Morgan', 'NNP'), ('Kaufmann', 'NNP'), ('Publishers', 'NNP'), ('Inc.', 'NNP'), (';', ':'), ('1998', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['San Francisco', 'Morgan Kaufmann Publishers Inc.']

>> Named Entities are: 
 [('GPE', 'San'), ('PERSON', 'Francisco'), ('PERSON', 'Morgan Kaufmann Publishers')] 

>> Stemming using Porter Stemmer: 
 [('San', 'san'), ('Francisco', 'francisco'), (':', ':'), ('Morgan', 'morgan'), ('Kaufmann', 'kaufmann'), ('Publishers', 'publish'), ('Inc.', 'inc.'), (';', ';'), ('1998', '1998'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('San', 'san'), ('Francisco', 'francisco'), (':', ':'), ('Morgan', 'morgan'), ('Kaufmann', 'kaufmann'), ('Publishers', 'publish'), ('Inc.', 'inc.'), (';', ';'), ('1998', '1998'), ('.', '.')]

>> Lemmatization: 
 [('San', 'San'), ('Francisco', 'Francisco'), (':', ':'), ('Morgan', 'Morgan'), ('Kaufmann', 'Kaufmann'), ('Publishers', 'Publishers'), ('Inc.', 'Inc.'), (';', ';'), ('1998', '1998'), ('.', '.')]



========================================== PARAGRAPH 500 ===========================================

 109. Fahad A, Alshatri N, Tari Z, Alamri A, Khalil I, Zomaya A, Foufou S, Bouras A. A survey of clustering algorithms for big  data: taxonomy and empirical analysis. IEEE Trans Emerg Topics Comp. 2014;2(3):267–79. 

------------------- Sentence 1 -------------------

 109.

>> Tokens are: 
 ['109', '.']

>> Bigrams are: 
 [('109', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('109', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('109', '109'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('109', '109'), ('.', '.')]

>> Lemmatization: 
 [('109', '109'), ('.', '.')]


------------------- Sentence 2 -------------------

Fahad A, Alshatri N, Tari Z, Alamri A, Khalil I, Zomaya A, Foufou S, Bouras A.

>> Tokens are: 
 ['Fahad', 'A', ',', 'Alshatri', 'N', ',', 'Tari', 'Z', ',', 'Alamri', 'A', ',', 'Khalil', 'I', ',', 'Zomaya', 'A', ',', 'Foufou', 'S', ',', 'Bouras', 'A', '.']

>> Bigrams are: 
 [('Fahad', 'A'), ('A', ','), (',', 'Alshatri'), ('Alshatri', 'N'), ('N', ','), (',', 'Tari'), ('Tari', 'Z'), ('Z', ','), (',', 'Alamri'), ('Alamri', 'A'), ('A', ','), (',', 'Khalil'), ('Khalil', 'I'), ('I', ','), (',', 'Zomaya'), ('Zomaya', 'A'), ('A', ','), (',', 'Foufou'), ('Foufou', 'S'), ('S', ','), (',', 'Bouras'), ('Bouras', 'A'), ('A', '.')]

>> Trigrams are: 
 [('Fahad', 'A', ','), ('A', ',', 'Alshatri'), (',', 'Alshatri', 'N'), ('Alshatri', 'N', ','), ('N', ',', 'Tari'), (',', 'Tari', 'Z'), ('Tari', 'Z', ','), ('Z', ',', 'Alamri'), (',', 'Alamri', 'A'), ('Alamri', 'A', ','), ('A', ',', 'Khalil'), (',', 'Khalil', 'I'), ('Khalil', 'I', ','), ('I', ',', 'Zomaya'), (',', 'Zomaya', 'A'), ('Zomaya', 'A', ','), ('A', ',', 'Foufou'), (',', 'Foufou', 'S'), ('Foufou', 'S', ','), ('S', ',', 'Bouras'), (',', 'Bouras', 'A'), ('Bouras', 'A', '.')]

>> POS Tags are: 
 [('Fahad', 'NNP'), ('A', 'NNP'), (',', ','), ('Alshatri', 'NNP'), ('N', 'NNP'), (',', ','), ('Tari', 'NNP'), ('Z', 'NNP'), (',', ','), ('Alamri', 'NNP'), ('A', 'NNP'), (',', ','), ('Khalil', 'NNP'), ('I', 'PRP'), (',', ','), ('Zomaya', 'NNP'), ('A', 'NNP'), (',', ','), ('Foufou', 'NNP'), ('S', 'NNP'), (',', ','), ('Bouras', 'NNP'), ('A', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Fahad A', 'Alshatri N', 'Tari Z', 'Alamri A', 'Khalil', 'Zomaya A', 'Foufou S', 'Bouras A']

>> Named Entities are: 
 [('PERSON', 'Fahad'), ('PERSON', 'Alshatri N'), ('PERSON', 'Tari Z'), ('PERSON', 'Alamri A'), ('PERSON', 'Khalil'), ('PERSON', 'Zomaya A'), ('PERSON', 'Foufou S'), ('PERSON', 'Bouras A')] 

>> Stemming using Porter Stemmer: 
 [('Fahad', 'fahad'), ('A', 'a'), (',', ','), ('Alshatri', 'alshatri'), ('N', 'n'), (',', ','), ('Tari', 'tari'), ('Z', 'z'), (',', ','), ('Alamri', 'alamri'), ('A', 'a'), (',', ','), ('Khalil', 'khalil'), ('I', 'i'), (',', ','), ('Zomaya', 'zomaya'), ('A', 'a'), (',', ','), ('Foufou', 'foufou'), ('S', 's'), (',', ','), ('Bouras', 'boura'), ('A', 'a'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Fahad', 'fahad'), ('A', 'a'), (',', ','), ('Alshatri', 'alshatri'), ('N', 'n'), (',', ','), ('Tari', 'tari'), ('Z', 'z'), (',', ','), ('Alamri', 'alamri'), ('A', 'a'), (',', ','), ('Khalil', 'khalil'), ('I', 'i'), (',', ','), ('Zomaya', 'zomaya'), ('A', 'a'), (',', ','), ('Foufou', 'foufou'), ('S', 's'), (',', ','), ('Bouras', 'boura'), ('A', 'a'), ('.', '.')]

>> Lemmatization: 
 [('Fahad', 'Fahad'), ('A', 'A'), (',', ','), ('Alshatri', 'Alshatri'), ('N', 'N'), (',', ','), ('Tari', 'Tari'), ('Z', 'Z'), (',', ','), ('Alamri', 'Alamri'), ('A', 'A'), (',', ','), ('Khalil', 'Khalil'), ('I', 'I'), (',', ','), ('Zomaya', 'Zomaya'), ('A', 'A'), (',', ','), ('Foufou', 'Foufou'), ('S', 'S'), (',', ','), ('Bouras', 'Bouras'), ('A', 'A'), ('.', '.')]


------------------- Sentence 3 -------------------

A survey of clustering algorithms for big  data: taxonomy and empirical analysis.

>> Tokens are: 
 ['A', 'survey', 'clustering', 'algorithms', 'big', 'data', ':', 'taxonomy', 'empirical', 'analysis', '.']

>> Bigrams are: 
 [('A', 'survey'), ('survey', 'clustering'), ('clustering', 'algorithms'), ('algorithms', 'big'), ('big', 'data'), ('data', ':'), (':', 'taxonomy'), ('taxonomy', 'empirical'), ('empirical', 'analysis'), ('analysis', '.')]

>> Trigrams are: 
 [('A', 'survey', 'clustering'), ('survey', 'clustering', 'algorithms'), ('clustering', 'algorithms', 'big'), ('algorithms', 'big', 'data'), ('big', 'data', ':'), ('data', ':', 'taxonomy'), (':', 'taxonomy', 'empirical'), ('taxonomy', 'empirical', 'analysis'), ('empirical', 'analysis', '.')]

>> POS Tags are: 
 [('A', 'DT'), ('survey', 'NN'), ('clustering', 'VBG'), ('algorithms', 'JJ'), ('big', 'JJ'), ('data', 'NNS'), (':', ':'), ('taxonomy', 'JJ'), ('empirical', 'JJ'), ('analysis', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['A survey', 'algorithms big data', 'taxonomy empirical analysis']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('A', 'a'), ('survey', 'survey'), ('clustering', 'cluster'), ('algorithms', 'algorithm'), ('big', 'big'), ('data', 'data'), (':', ':'), ('taxonomy', 'taxonomi'), ('empirical', 'empir'), ('analysis', 'analysi'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('A', 'a'), ('survey', 'survey'), ('clustering', 'cluster'), ('algorithms', 'algorithm'), ('big', 'big'), ('data', 'data'), (':', ':'), ('taxonomy', 'taxonomi'), ('empirical', 'empir'), ('analysis', 'analysi'), ('.', '.')]

>> Lemmatization: 
 [('A', 'A'), ('survey', 'survey'), ('clustering', 'clustering'), ('algorithms', 'algorithm'), ('big', 'big'), ('data', 'data'), (':', ':'), ('taxonomy', 'taxonomy'), ('empirical', 'empirical'), ('analysis', 'analysis'), ('.', '.')]


------------------- Sentence 4 -------------------

IEEE Trans Emerg Topics Comp.

>> Tokens are: 
 ['IEEE', 'Trans', 'Emerg', 'Topics', 'Comp', '.']

>> Bigrams are: 
 [('IEEE', 'Trans'), ('Trans', 'Emerg'), ('Emerg', 'Topics'), ('Topics', 'Comp'), ('Comp', '.')]

>> Trigrams are: 
 [('IEEE', 'Trans', 'Emerg'), ('Trans', 'Emerg', 'Topics'), ('Emerg', 'Topics', 'Comp'), ('Topics', 'Comp', '.')]

>> POS Tags are: 
 [('IEEE', 'NNP'), ('Trans', 'NNP'), ('Emerg', 'NNP'), ('Topics', 'NNP'), ('Comp', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['IEEE Trans Emerg Topics Comp']

>> Named Entities are: 
 [('ORGANIZATION', 'IEEE'), ('PERSON', 'Trans Emerg Topics Comp')] 

>> Stemming using Porter Stemmer: 
 [('IEEE', 'ieee'), ('Trans', 'tran'), ('Emerg', 'emerg'), ('Topics', 'topic'), ('Comp', 'comp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('IEEE', 'ieee'), ('Trans', 'tran'), ('Emerg', 'emerg'), ('Topics', 'topic'), ('Comp', 'comp'), ('.', '.')]

>> Lemmatization: 
 [('IEEE', 'IEEE'), ('Trans', 'Trans'), ('Emerg', 'Emerg'), ('Topics', 'Topics'), ('Comp', 'Comp'), ('.', '.')]


------------------- Sentence 5 -------------------

2014;2(3):267–79.

>> Tokens are: 
 ['2014', ';', '2', '(', '3', ')', ':267–79', '.']

>> Bigrams are: 
 [('2014', ';'), (';', '2'), ('2', '('), ('(', '3'), ('3', ')'), (')', ':267–79'), (':267–79', '.')]

>> Trigrams are: 
 [('2014', ';', '2'), (';', '2', '('), ('2', '(', '3'), ('(', '3', ')'), ('3', ')', ':267–79'), (')', ':267–79', '.')]

>> POS Tags are: 
 [('2014', 'CD'), (';', ':'), ('2', 'CD'), ('(', '('), ('3', 'CD'), (')', ')'), (':267–79', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 [':267–79']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('2014', '2014'), (';', ';'), ('2', '2'), ('(', '('), ('3', '3'), (')', ')'), (':267–79', ':267–79'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('2014', '2014'), (';', ';'), ('2', '2'), ('(', '('), ('3', '3'), (')', ')'), (':267–79', ':267–79'), ('.', '.')]

>> Lemmatization: 
 [('2014', '2014'), (';', ';'), ('2', '2'), ('(', '('), ('3', '3'), (')', ')'), (':267–79', ':267–79'), ('.', '.')]



========================================== PARAGRAPH 501 ===========================================

 110. Shirkhorshidi AS, Aghabozorgi SR, Teh YW, Herawan T. Big data clustering: a review. In: Proceedings of the Interna‑ tional Conference on Computational Science and Its Applications, 2014. pp 707–720. 

------------------- Sentence 1 -------------------

 110.

>> Tokens are: 
 ['110', '.']

>> Bigrams are: 
 [('110', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('110', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('110', '110'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('110', '110'), ('.', '.')]

>> Lemmatization: 
 [('110', '110'), ('.', '.')]


------------------- Sentence 2 -------------------

Shirkhorshidi AS, Aghabozorgi SR, Teh YW, Herawan T. Big data clustering: a review.

>> Tokens are: 
 ['Shirkhorshidi', 'AS', ',', 'Aghabozorgi', 'SR', ',', 'Teh', 'YW', ',', 'Herawan', 'T.', 'Big', 'data', 'clustering', ':', 'review', '.']

>> Bigrams are: 
 [('Shirkhorshidi', 'AS'), ('AS', ','), (',', 'Aghabozorgi'), ('Aghabozorgi', 'SR'), ('SR', ','), (',', 'Teh'), ('Teh', 'YW'), ('YW', ','), (',', 'Herawan'), ('Herawan', 'T.'), ('T.', 'Big'), ('Big', 'data'), ('data', 'clustering'), ('clustering', ':'), (':', 'review'), ('review', '.')]

>> Trigrams are: 
 [('Shirkhorshidi', 'AS', ','), ('AS', ',', 'Aghabozorgi'), (',', 'Aghabozorgi', 'SR'), ('Aghabozorgi', 'SR', ','), ('SR', ',', 'Teh'), (',', 'Teh', 'YW'), ('Teh', 'YW', ','), ('YW', ',', 'Herawan'), (',', 'Herawan', 'T.'), ('Herawan', 'T.', 'Big'), ('T.', 'Big', 'data'), ('Big', 'data', 'clustering'), ('data', 'clustering', ':'), ('clustering', ':', 'review'), (':', 'review', '.')]

>> POS Tags are: 
 [('Shirkhorshidi', 'NNP'), ('AS', 'NNP'), (',', ','), ('Aghabozorgi', 'NNP'), ('SR', 'NNP'), (',', ','), ('Teh', 'NNP'), ('YW', 'NNP'), (',', ','), ('Herawan', 'NNP'), ('T.', 'NNP'), ('Big', 'NNP'), ('data', 'NNS'), ('clustering', 'NN'), (':', ':'), ('review', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Shirkhorshidi AS', 'Aghabozorgi SR', 'Teh YW', 'Herawan T. Big data clustering', 'review']

>> Named Entities are: 
 [('GPE', 'Shirkhorshidi'), ('PERSON', 'Aghabozorgi SR'), ('PERSON', 'Teh YW'), ('PERSON', 'Herawan T.')] 

>> Stemming using Porter Stemmer: 
 [('Shirkhorshidi', 'shirkhorshidi'), ('AS', 'as'), (',', ','), ('Aghabozorgi', 'aghabozorgi'), ('SR', 'sr'), (',', ','), ('Teh', 'teh'), ('YW', 'yw'), (',', ','), ('Herawan', 'herawan'), ('T.', 't.'), ('Big', 'big'), ('data', 'data'), ('clustering', 'cluster'), (':', ':'), ('review', 'review'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Shirkhorshidi', 'shirkhorshidi'), ('AS', 'as'), (',', ','), ('Aghabozorgi', 'aghabozorgi'), ('SR', 'sr'), (',', ','), ('Teh', 'teh'), ('YW', 'yw'), (',', ','), ('Herawan', 'herawan'), ('T.', 't.'), ('Big', 'big'), ('data', 'data'), ('clustering', 'cluster'), (':', ':'), ('review', 'review'), ('.', '.')]

>> Lemmatization: 
 [('Shirkhorshidi', 'Shirkhorshidi'), ('AS', 'AS'), (',', ','), ('Aghabozorgi', 'Aghabozorgi'), ('SR', 'SR'), (',', ','), ('Teh', 'Teh'), ('YW', 'YW'), (',', ','), ('Herawan', 'Herawan'), ('T.', 'T.'), ('Big', 'Big'), ('data', 'data'), ('clustering', 'clustering'), (':', ':'), ('review', 'review'), ('.', '.')]


------------------- Sentence 3 -------------------

In: Proceedings of the Interna‑ tional Conference on Computational Science and Its Applications, 2014. pp 707–720.

>> Tokens are: 
 ['In', ':', 'Proceedings', 'Interna‑', 'tional', 'Conference', 'Computational', 'Science', 'Its', 'Applications', ',', '2014.', 'pp', '707–720', '.']

>> Bigrams are: 
 [('In', ':'), (':', 'Proceedings'), ('Proceedings', 'Interna‑'), ('Interna‑', 'tional'), ('tional', 'Conference'), ('Conference', 'Computational'), ('Computational', 'Science'), ('Science', 'Its'), ('Its', 'Applications'), ('Applications', ','), (',', '2014.'), ('2014.', 'pp'), ('pp', '707–720'), ('707–720', '.')]

>> Trigrams are: 
 [('In', ':', 'Proceedings'), (':', 'Proceedings', 'Interna‑'), ('Proceedings', 'Interna‑', 'tional'), ('Interna‑', 'tional', 'Conference'), ('tional', 'Conference', 'Computational'), ('Conference', 'Computational', 'Science'), ('Computational', 'Science', 'Its'), ('Science', 'Its', 'Applications'), ('Its', 'Applications', ','), ('Applications', ',', '2014.'), (',', '2014.', 'pp'), ('2014.', 'pp', '707–720'), ('pp', '707–720', '.')]

>> POS Tags are: 
 [('In', 'IN'), (':', ':'), ('Proceedings', 'NNS'), ('Interna‑', 'NNP'), ('tional', 'JJ'), ('Conference', 'NNP'), ('Computational', 'NNP'), ('Science', 'NNP'), ('Its', 'PRP$'), ('Applications', 'NNP'), (',', ','), ('2014.', 'CD'), ('pp', 'NN'), ('707–720', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Proceedings Interna‑', 'tional Conference Computational Science', 'Applications', 'pp']

>> Named Entities are: 
 [('ORGANIZATION', 'Conference Computational')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), (':', ':'), ('Proceedings', 'proceed'), ('Interna‑', 'interna‑'), ('tional', 'tional'), ('Conference', 'confer'), ('Computational', 'comput'), ('Science', 'scienc'), ('Its', 'it'), ('Applications', 'applic'), (',', ','), ('2014.', '2014.'), ('pp', 'pp'), ('707–720', '707–720'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), (':', ':'), ('Proceedings', 'proceed'), ('Interna‑', 'interna‑'), ('tional', 'tional'), ('Conference', 'confer'), ('Computational', 'comput'), ('Science', 'scienc'), ('Its', 'it'), ('Applications', 'applic'), (',', ','), ('2014.', '2014.'), ('pp', 'pp'), ('707–720', '707–720'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), (':', ':'), ('Proceedings', 'Proceedings'), ('Interna‑', 'Interna‑'), ('tional', 'tional'), ('Conference', 'Conference'), ('Computational', 'Computational'), ('Science', 'Science'), ('Its', 'Its'), ('Applications', 'Applications'), (',', ','), ('2014.', '2014.'), ('pp', 'pp'), ('707–720', '707–720'), ('.', '.')]



========================================== PARAGRAPH 502 ===========================================

 111. Xu H, Li Z, Guo S, Chen K. Cloudvista: interactive and economical visual cluster analysis for big data in the cloud.  Proc VLDB Endowment. 2012;5(12):1886–9. 

------------------- Sentence 1 -------------------

 111.

>> Tokens are: 
 ['111', '.']

>> Bigrams are: 
 [('111', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('111', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('111', '111'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('111', '111'), ('.', '.')]

>> Lemmatization: 
 [('111', '111'), ('.', '.')]


------------------- Sentence 2 -------------------

Xu H, Li Z, Guo S, Chen K. Cloudvista: interactive and economical visual cluster analysis for big data in the cloud.

>> Tokens are: 
 ['Xu', 'H', ',', 'Li', 'Z', ',', 'Guo', 'S', ',', 'Chen', 'K.', 'Cloudvista', ':', 'interactive', 'economical', 'visual', 'cluster', 'analysis', 'big', 'data', 'cloud', '.']

>> Bigrams are: 
 [('Xu', 'H'), ('H', ','), (',', 'Li'), ('Li', 'Z'), ('Z', ','), (',', 'Guo'), ('Guo', 'S'), ('S', ','), (',', 'Chen'), ('Chen', 'K.'), ('K.', 'Cloudvista'), ('Cloudvista', ':'), (':', 'interactive'), ('interactive', 'economical'), ('economical', 'visual'), ('visual', 'cluster'), ('cluster', 'analysis'), ('analysis', 'big'), ('big', 'data'), ('data', 'cloud'), ('cloud', '.')]

>> Trigrams are: 
 [('Xu', 'H', ','), ('H', ',', 'Li'), (',', 'Li', 'Z'), ('Li', 'Z', ','), ('Z', ',', 'Guo'), (',', 'Guo', 'S'), ('Guo', 'S', ','), ('S', ',', 'Chen'), (',', 'Chen', 'K.'), ('Chen', 'K.', 'Cloudvista'), ('K.', 'Cloudvista', ':'), ('Cloudvista', ':', 'interactive'), (':', 'interactive', 'economical'), ('interactive', 'economical', 'visual'), ('economical', 'visual', 'cluster'), ('visual', 'cluster', 'analysis'), ('cluster', 'analysis', 'big'), ('analysis', 'big', 'data'), ('big', 'data', 'cloud'), ('data', 'cloud', '.')]

>> POS Tags are: 
 [('Xu', 'NN'), ('H', 'NNP'), (',', ','), ('Li', 'NNP'), ('Z', 'NNP'), (',', ','), ('Guo', 'NNP'), ('S', 'NNP'), (',', ','), ('Chen', 'NNP'), ('K.', 'NNP'), ('Cloudvista', 'NNP'), (':', ':'), ('interactive', 'JJ'), ('economical', 'JJ'), ('visual', 'JJ'), ('cluster', 'NN'), ('analysis', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('cloud', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Xu H', 'Li Z', 'Guo S', 'Chen K. Cloudvista', 'interactive economical visual cluster analysis', 'big data cloud']

>> Named Entities are: 
 [('PERSON', 'Li Z'), ('PERSON', 'Guo S'), ('PERSON', 'Chen K. Cloudvista')] 

>> Stemming using Porter Stemmer: 
 [('Xu', 'xu'), ('H', 'h'), (',', ','), ('Li', 'li'), ('Z', 'z'), (',', ','), ('Guo', 'guo'), ('S', 's'), (',', ','), ('Chen', 'chen'), ('K.', 'k.'), ('Cloudvista', 'cloudvista'), (':', ':'), ('interactive', 'interact'), ('economical', 'econom'), ('visual', 'visual'), ('cluster', 'cluster'), ('analysis', 'analysi'), ('big', 'big'), ('data', 'data'), ('cloud', 'cloud'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Xu', 'xu'), ('H', 'h'), (',', ','), ('Li', 'li'), ('Z', 'z'), (',', ','), ('Guo', 'guo'), ('S', 's'), (',', ','), ('Chen', 'chen'), ('K.', 'k.'), ('Cloudvista', 'cloudvista'), (':', ':'), ('interactive', 'interact'), ('economical', 'econom'), ('visual', 'visual'), ('cluster', 'cluster'), ('analysis', 'analysi'), ('big', 'big'), ('data', 'data'), ('cloud', 'cloud'), ('.', '.')]

>> Lemmatization: 
 [('Xu', 'Xu'), ('H', 'H'), (',', ','), ('Li', 'Li'), ('Z', 'Z'), (',', ','), ('Guo', 'Guo'), ('S', 'S'), (',', ','), ('Chen', 'Chen'), ('K.', 'K.'), ('Cloudvista', 'Cloudvista'), (':', ':'), ('interactive', 'interactive'), ('economical', 'economical'), ('visual', 'visual'), ('cluster', 'cluster'), ('analysis', 'analysis'), ('big', 'big'), ('data', 'data'), ('cloud', 'cloud'), ('.', '.')]


------------------- Sentence 3 -------------------

Proc VLDB Endowment.

>> Tokens are: 
 ['Proc', 'VLDB', 'Endowment', '.']

>> Bigrams are: 
 [('Proc', 'VLDB'), ('VLDB', 'Endowment'), ('Endowment', '.')]

>> Trigrams are: 
 [('Proc', 'VLDB', 'Endowment'), ('VLDB', 'Endowment', '.')]

>> POS Tags are: 
 [('Proc', 'NNP'), ('VLDB', 'NNP'), ('Endowment', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Proc VLDB Endowment']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Proc', 'proc'), ('VLDB', 'vldb'), ('Endowment', 'endow'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Proc', 'proc'), ('VLDB', 'vldb'), ('Endowment', 'endow'), ('.', '.')]

>> Lemmatization: 
 [('Proc', 'Proc'), ('VLDB', 'VLDB'), ('Endowment', 'Endowment'), ('.', '.')]


------------------- Sentence 4 -------------------

2012;5(12):1886–9.

>> Tokens are: 
 ['2012', ';', '5', '(', '12', ')', ':1886–9', '.']

>> Bigrams are: 
 [('2012', ';'), (';', '5'), ('5', '('), ('(', '12'), ('12', ')'), (')', ':1886–9'), (':1886–9', '.')]

>> Trigrams are: 
 [('2012', ';', '5'), (';', '5', '('), ('5', '(', '12'), ('(', '12', ')'), ('12', ')', ':1886–9'), (')', ':1886–9', '.')]

>> POS Tags are: 
 [('2012', 'CD'), (';', ':'), ('5', 'CD'), ('(', '('), ('12', 'CD'), (')', ')'), (':1886–9', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 [':1886–9']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('2012', '2012'), (';', ';'), ('5', '5'), ('(', '('), ('12', '12'), (')', ')'), (':1886–9', ':1886–9'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('2012', '2012'), (';', ';'), ('5', '5'), ('(', '('), ('12', '12'), (')', ')'), (':1886–9', ':1886–9'), ('.', '.')]

>> Lemmatization: 
 [('2012', '2012'), (';', ';'), ('5', '5'), ('(', '('), ('12', '12'), (')', ')'), (':1886–9', ':1886–9'), ('.', '.')]



========================================== PARAGRAPH 503 ===========================================

 112. Cui X, Gao J, Potok TE. A flocking based algorithm for document clustering analysis. J Syst Archit.  2006;52(89):505–15. 

------------------- Sentence 1 -------------------

 112.

>> Tokens are: 
 ['112', '.']

>> Bigrams are: 
 [('112', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('112', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('112', '112'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('112', '112'), ('.', '.')]

>> Lemmatization: 
 [('112', '112'), ('.', '.')]


------------------- Sentence 2 -------------------

Cui X, Gao J, Potok TE.

>> Tokens are: 
 ['Cui', 'X', ',', 'Gao', 'J', ',', 'Potok', 'TE', '.']

>> Bigrams are: 
 [('Cui', 'X'), ('X', ','), (',', 'Gao'), ('Gao', 'J'), ('J', ','), (',', 'Potok'), ('Potok', 'TE'), ('TE', '.')]

>> Trigrams are: 
 [('Cui', 'X', ','), ('X', ',', 'Gao'), (',', 'Gao', 'J'), ('Gao', 'J', ','), ('J', ',', 'Potok'), (',', 'Potok', 'TE'), ('Potok', 'TE', '.')]

>> POS Tags are: 
 [('Cui', 'NNP'), ('X', 'NNP'), (',', ','), ('Gao', 'NNP'), ('J', 'NNP'), (',', ','), ('Potok', 'NNP'), ('TE', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Cui X', 'Gao J', 'Potok TE']

>> Named Entities are: 
 [('PERSON', 'Cui'), ('ORGANIZATION', 'X'), ('PERSON', 'Gao J'), ('PERSON', 'Potok TE')] 

>> Stemming using Porter Stemmer: 
 [('Cui', 'cui'), ('X', 'x'), (',', ','), ('Gao', 'gao'), ('J', 'j'), (',', ','), ('Potok', 'potok'), ('TE', 'te'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Cui', 'cui'), ('X', 'x'), (',', ','), ('Gao', 'gao'), ('J', 'j'), (',', ','), ('Potok', 'potok'), ('TE', 'te'), ('.', '.')]

>> Lemmatization: 
 [('Cui', 'Cui'), ('X', 'X'), (',', ','), ('Gao', 'Gao'), ('J', 'J'), (',', ','), ('Potok', 'Potok'), ('TE', 'TE'), ('.', '.')]


------------------- Sentence 3 -------------------

A flocking based algorithm for document clustering analysis.

>> Tokens are: 
 ['A', 'flocking', 'based', 'algorithm', 'document', 'clustering', 'analysis', '.']

>> Bigrams are: 
 [('A', 'flocking'), ('flocking', 'based'), ('based', 'algorithm'), ('algorithm', 'document'), ('document', 'clustering'), ('clustering', 'analysis'), ('analysis', '.')]

>> Trigrams are: 
 [('A', 'flocking', 'based'), ('flocking', 'based', 'algorithm'), ('based', 'algorithm', 'document'), ('algorithm', 'document', 'clustering'), ('document', 'clustering', 'analysis'), ('clustering', 'analysis', '.')]

>> POS Tags are: 
 [('A', 'DT'), ('flocking', 'NN'), ('based', 'VBN'), ('algorithm', 'JJ'), ('document', 'NN'), ('clustering', 'VBG'), ('analysis', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['A flocking', 'algorithm document', 'analysis']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('A', 'a'), ('flocking', 'flock'), ('based', 'base'), ('algorithm', 'algorithm'), ('document', 'document'), ('clustering', 'cluster'), ('analysis', 'analysi'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('A', 'a'), ('flocking', 'flock'), ('based', 'base'), ('algorithm', 'algorithm'), ('document', 'document'), ('clustering', 'cluster'), ('analysis', 'analysi'), ('.', '.')]

>> Lemmatization: 
 [('A', 'A'), ('flocking', 'flocking'), ('based', 'based'), ('algorithm', 'algorithm'), ('document', 'document'), ('clustering', 'clustering'), ('analysis', 'analysis'), ('.', '.')]


------------------- Sentence 4 -------------------

J Syst Archit.

>> Tokens are: 
 ['J', 'Syst', 'Archit', '.']

>> Bigrams are: 
 [('J', 'Syst'), ('Syst', 'Archit'), ('Archit', '.')]

>> Trigrams are: 
 [('J', 'Syst', 'Archit'), ('Syst', 'Archit', '.')]

>> POS Tags are: 
 [('J', 'NNP'), ('Syst', 'NNP'), ('Archit', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['J Syst Archit']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('J', 'j'), ('Syst', 'syst'), ('Archit', 'archit'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('J', 'j'), ('Syst', 'syst'), ('Archit', 'archit'), ('.', '.')]

>> Lemmatization: 
 [('J', 'J'), ('Syst', 'Syst'), ('Archit', 'Archit'), ('.', '.')]


------------------- Sentence 5 -------------------

2006;52(89):505–15.

>> Tokens are: 
 ['2006', ';', '52', '(', '89', ')', ':505–15', '.']

>> Bigrams are: 
 [('2006', ';'), (';', '52'), ('52', '('), ('(', '89'), ('89', ')'), (')', ':505–15'), (':505–15', '.')]

>> Trigrams are: 
 [('2006', ';', '52'), (';', '52', '('), ('52', '(', '89'), ('(', '89', ')'), ('89', ')', ':505–15'), (')', ':505–15', '.')]

>> POS Tags are: 
 [('2006', 'CD'), (';', ':'), ('52', 'CD'), ('(', '('), ('89', 'CD'), (')', ')'), (':505–15', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 [':505–15']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('2006', '2006'), (';', ';'), ('52', '52'), ('(', '('), ('89', '89'), (')', ')'), (':505–15', ':505–15'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('2006', '2006'), (';', ';'), ('52', '52'), ('(', '('), ('89', '89'), (')', ')'), (':505–15', ':505–15'), ('.', '.')]

>> Lemmatization: 
 [('2006', '2006'), (';', ';'), ('52', '52'), ('(', '('), ('89', '89'), (')', ')'), (':505–15', ':505–15'), ('.', '.')]



========================================== PARAGRAPH 504 ===========================================

 113. Cui X, Charles JS, Potok T. GPU enhanced parallel computing for large scale data clustering. Future Gener Comp  Syst. 2013;29(7):1736–41. 

------------------- Sentence 1 -------------------

 113.

>> Tokens are: 
 ['113', '.']

>> Bigrams are: 
 [('113', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('113', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('113', '113'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('113', '113'), ('.', '.')]

>> Lemmatization: 
 [('113', '113'), ('.', '.')]


------------------- Sentence 2 -------------------

Cui X, Charles JS, Potok T. GPU enhanced parallel computing for large scale data clustering.

>> Tokens are: 
 ['Cui', 'X', ',', 'Charles', 'JS', ',', 'Potok', 'T.', 'GPU', 'enhanced', 'parallel', 'computing', 'large', 'scale', 'data', 'clustering', '.']

>> Bigrams are: 
 [('Cui', 'X'), ('X', ','), (',', 'Charles'), ('Charles', 'JS'), ('JS', ','), (',', 'Potok'), ('Potok', 'T.'), ('T.', 'GPU'), ('GPU', 'enhanced'), ('enhanced', 'parallel'), ('parallel', 'computing'), ('computing', 'large'), ('large', 'scale'), ('scale', 'data'), ('data', 'clustering'), ('clustering', '.')]

>> Trigrams are: 
 [('Cui', 'X', ','), ('X', ',', 'Charles'), (',', 'Charles', 'JS'), ('Charles', 'JS', ','), ('JS', ',', 'Potok'), (',', 'Potok', 'T.'), ('Potok', 'T.', 'GPU'), ('T.', 'GPU', 'enhanced'), ('GPU', 'enhanced', 'parallel'), ('enhanced', 'parallel', 'computing'), ('parallel', 'computing', 'large'), ('computing', 'large', 'scale'), ('large', 'scale', 'data'), ('scale', 'data', 'clustering'), ('data', 'clustering', '.')]

>> POS Tags are: 
 [('Cui', 'NNP'), ('X', 'NNP'), (',', ','), ('Charles', 'NNP'), ('JS', 'NNP'), (',', ','), ('Potok', 'NNP'), ('T.', 'NNP'), ('GPU', 'NNP'), ('enhanced', 'VBD'), ('parallel', 'JJ'), ('computing', 'VBG'), ('large', 'JJ'), ('scale', 'NN'), ('data', 'NNS'), ('clustering', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Cui X', 'Charles JS', 'Potok T. GPU', 'large scale data clustering']

>> Named Entities are: 
 [('PERSON', 'Cui'), ('ORGANIZATION', 'X'), ('PERSON', 'Charles JS'), ('PERSON', 'Potok T. GPU')] 

>> Stemming using Porter Stemmer: 
 [('Cui', 'cui'), ('X', 'x'), (',', ','), ('Charles', 'charl'), ('JS', 'js'), (',', ','), ('Potok', 'potok'), ('T.', 't.'), ('GPU', 'gpu'), ('enhanced', 'enhanc'), ('parallel', 'parallel'), ('computing', 'comput'), ('large', 'larg'), ('scale', 'scale'), ('data', 'data'), ('clustering', 'cluster'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Cui', 'cui'), ('X', 'x'), (',', ','), ('Charles', 'charl'), ('JS', 'js'), (',', ','), ('Potok', 'potok'), ('T.', 't.'), ('GPU', 'gpu'), ('enhanced', 'enhanc'), ('parallel', 'parallel'), ('computing', 'comput'), ('large', 'larg'), ('scale', 'scale'), ('data', 'data'), ('clustering', 'cluster'), ('.', '.')]

>> Lemmatization: 
 [('Cui', 'Cui'), ('X', 'X'), (',', ','), ('Charles', 'Charles'), ('JS', 'JS'), (',', ','), ('Potok', 'Potok'), ('T.', 'T.'), ('GPU', 'GPU'), ('enhanced', 'enhanced'), ('parallel', 'parallel'), ('computing', 'computing'), ('large', 'large'), ('scale', 'scale'), ('data', 'data'), ('clustering', 'clustering'), ('.', '.')]


------------------- Sentence 3 -------------------

Future Gener Comp  Syst.

>> Tokens are: 
 ['Future', 'Gener', 'Comp', 'Syst', '.']

>> Bigrams are: 
 [('Future', 'Gener'), ('Gener', 'Comp'), ('Comp', 'Syst'), ('Syst', '.')]

>> Trigrams are: 
 [('Future', 'Gener', 'Comp'), ('Gener', 'Comp', 'Syst'), ('Comp', 'Syst', '.')]

>> POS Tags are: 
 [('Future', 'JJ'), ('Gener', 'NNP'), ('Comp', 'NNP'), ('Syst', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Future Gener Comp Syst']

>> Named Entities are: 
 [('PERSON', 'Future'), ('ORGANIZATION', 'Gener Comp Syst')] 

>> Stemming using Porter Stemmer: 
 [('Future', 'futur'), ('Gener', 'gener'), ('Comp', 'comp'), ('Syst', 'syst'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Future', 'futur'), ('Gener', 'gener'), ('Comp', 'comp'), ('Syst', 'syst'), ('.', '.')]

>> Lemmatization: 
 [('Future', 'Future'), ('Gener', 'Gener'), ('Comp', 'Comp'), ('Syst', 'Syst'), ('.', '.')]


------------------- Sentence 4 -------------------

2013;29(7):1736–41.

>> Tokens are: 
 ['2013', ';', '29', '(', '7', ')', ':1736–41', '.']

>> Bigrams are: 
 [('2013', ';'), (';', '29'), ('29', '('), ('(', '7'), ('7', ')'), (')', ':1736–41'), (':1736–41', '.')]

>> Trigrams are: 
 [('2013', ';', '29'), (';', '29', '('), ('29', '(', '7'), ('(', '7', ')'), ('7', ')', ':1736–41'), (')', ':1736–41', '.')]

>> POS Tags are: 
 [('2013', 'CD'), (';', ':'), ('29', 'CD'), ('(', '('), ('7', 'CD'), (')', ')'), (':1736–41', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 [':1736–41']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('2013', '2013'), (';', ';'), ('29', '29'), ('(', '('), ('7', '7'), (')', ')'), (':1736–41', ':1736–41'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('2013', '2013'), (';', ';'), ('29', '29'), ('(', '('), ('7', '7'), (')', ')'), (':1736–41', ':1736–41'), ('.', '.')]

>> Lemmatization: 
 [('2013', '2013'), (';', ';'), ('29', '29'), ('(', '('), ('7', '7'), (')', ')'), (':1736–41', ':1736–41'), ('.', '.')]



========================================== PARAGRAPH 505 ===========================================

 114. Feldman D, Schmidt M, Sohler C. Turning big data into tiny data: Constant‑size coresets for k‑means, pca and  projective clustering. In: Proceedings of the ACM‑SIAM Symposium on Discrete Algorithms, 2013. pp 1434–1453. 

------------------- Sentence 1 -------------------

 114.

>> Tokens are: 
 ['114', '.']

>> Bigrams are: 
 [('114', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('114', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('114', '114'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('114', '114'), ('.', '.')]

>> Lemmatization: 
 [('114', '114'), ('.', '.')]


------------------- Sentence 2 -------------------

Feldman D, Schmidt M, Sohler C. Turning big data into tiny data: Constant‑size coresets for k‑means, pca and  projective clustering.

>> Tokens are: 
 ['Feldman', 'D', ',', 'Schmidt', 'M', ',', 'Sohler', 'C.', 'Turning', 'big', 'data', 'tiny', 'data', ':', 'Constant‑size', 'coresets', 'k‑means', ',', 'pca', 'projective', 'clustering', '.']

>> Bigrams are: 
 [('Feldman', 'D'), ('D', ','), (',', 'Schmidt'), ('Schmidt', 'M'), ('M', ','), (',', 'Sohler'), ('Sohler', 'C.'), ('C.', 'Turning'), ('Turning', 'big'), ('big', 'data'), ('data', 'tiny'), ('tiny', 'data'), ('data', ':'), (':', 'Constant‑size'), ('Constant‑size', 'coresets'), ('coresets', 'k‑means'), ('k‑means', ','), (',', 'pca'), ('pca', 'projective'), ('projective', 'clustering'), ('clustering', '.')]

>> Trigrams are: 
 [('Feldman', 'D', ','), ('D', ',', 'Schmidt'), (',', 'Schmidt', 'M'), ('Schmidt', 'M', ','), ('M', ',', 'Sohler'), (',', 'Sohler', 'C.'), ('Sohler', 'C.', 'Turning'), ('C.', 'Turning', 'big'), ('Turning', 'big', 'data'), ('big', 'data', 'tiny'), ('data', 'tiny', 'data'), ('tiny', 'data', ':'), ('data', ':', 'Constant‑size'), (':', 'Constant‑size', 'coresets'), ('Constant‑size', 'coresets', 'k‑means'), ('coresets', 'k‑means', ','), ('k‑means', ',', 'pca'), (',', 'pca', 'projective'), ('pca', 'projective', 'clustering'), ('projective', 'clustering', '.')]

>> POS Tags are: 
 [('Feldman', 'NNP'), ('D', 'NNP'), (',', ','), ('Schmidt', 'NNP'), ('M', 'NNP'), (',', ','), ('Sohler', 'NNP'), ('C.', 'NNP'), ('Turning', 'NNP'), ('big', 'JJ'), ('data', 'NNS'), ('tiny', 'JJ'), ('data', 'NNS'), (':', ':'), ('Constant‑size', 'NNP'), ('coresets', 'NNS'), ('k‑means', 'NNS'), (',', ','), ('pca', 'VBP'), ('projective', 'JJ'), ('clustering', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Feldman D', 'Schmidt M', 'Sohler C. Turning', 'big data', 'tiny data', 'Constant‑size coresets k‑means', 'projective clustering']

>> Named Entities are: 
 [('PERSON', 'Feldman'), ('ORGANIZATION', 'D'), ('PERSON', 'Schmidt M'), ('PERSON', 'Sohler C. Turning')] 

>> Stemming using Porter Stemmer: 
 [('Feldman', 'feldman'), ('D', 'd'), (',', ','), ('Schmidt', 'schmidt'), ('M', 'm'), (',', ','), ('Sohler', 'sohler'), ('C.', 'c.'), ('Turning', 'turn'), ('big', 'big'), ('data', 'data'), ('tiny', 'tini'), ('data', 'data'), (':', ':'), ('Constant‑size', 'constant‑s'), ('coresets', 'coreset'), ('k‑means', 'k‑mean'), (',', ','), ('pca', 'pca'), ('projective', 'project'), ('clustering', 'cluster'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Feldman', 'feldman'), ('D', 'd'), (',', ','), ('Schmidt', 'schmidt'), ('M', 'm'), (',', ','), ('Sohler', 'sohler'), ('C.', 'c.'), ('Turning', 'turn'), ('big', 'big'), ('data', 'data'), ('tiny', 'tini'), ('data', 'data'), (':', ':'), ('Constant‑size', 'constant‑s'), ('coresets', 'coreset'), ('k‑means', 'k‑mean'), (',', ','), ('pca', 'pca'), ('projective', 'project'), ('clustering', 'cluster'), ('.', '.')]

>> Lemmatization: 
 [('Feldman', 'Feldman'), ('D', 'D'), (',', ','), ('Schmidt', 'Schmidt'), ('M', 'M'), (',', ','), ('Sohler', 'Sohler'), ('C.', 'C.'), ('Turning', 'Turning'), ('big', 'big'), ('data', 'data'), ('tiny', 'tiny'), ('data', 'data'), (':', ':'), ('Constant‑size', 'Constant‑size'), ('coresets', 'coresets'), ('k‑means', 'k‑means'), (',', ','), ('pca', 'pca'), ('projective', 'projective'), ('clustering', 'clustering'), ('.', '.')]


------------------- Sentence 3 -------------------

In: Proceedings of the ACM‑SIAM Symposium on Discrete Algorithms, 2013. pp 1434–1453.

>> Tokens are: 
 ['In', ':', 'Proceedings', 'ACM‑SIAM', 'Symposium', 'Discrete', 'Algorithms', ',', '2013.', 'pp', '1434–1453', '.']

>> Bigrams are: 
 [('In', ':'), (':', 'Proceedings'), ('Proceedings', 'ACM‑SIAM'), ('ACM‑SIAM', 'Symposium'), ('Symposium', 'Discrete'), ('Discrete', 'Algorithms'), ('Algorithms', ','), (',', '2013.'), ('2013.', 'pp'), ('pp', '1434–1453'), ('1434–1453', '.')]

>> Trigrams are: 
 [('In', ':', 'Proceedings'), (':', 'Proceedings', 'ACM‑SIAM'), ('Proceedings', 'ACM‑SIAM', 'Symposium'), ('ACM‑SIAM', 'Symposium', 'Discrete'), ('Symposium', 'Discrete', 'Algorithms'), ('Discrete', 'Algorithms', ','), ('Algorithms', ',', '2013.'), (',', '2013.', 'pp'), ('2013.', 'pp', '1434–1453'), ('pp', '1434–1453', '.')]

>> POS Tags are: 
 [('In', 'IN'), (':', ':'), ('Proceedings', 'NNS'), ('ACM‑SIAM', 'NNP'), ('Symposium', 'NNP'), ('Discrete', 'NNP'), ('Algorithms', 'NNP'), (',', ','), ('2013.', 'CD'), ('pp', 'NN'), ('1434–1453', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Proceedings ACM‑SIAM Symposium Discrete Algorithms', 'pp']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), (':', ':'), ('Proceedings', 'proceed'), ('ACM‑SIAM', 'acm‑siam'), ('Symposium', 'symposium'), ('Discrete', 'discret'), ('Algorithms', 'algorithm'), (',', ','), ('2013.', '2013.'), ('pp', 'pp'), ('1434–1453', '1434–1453'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), (':', ':'), ('Proceedings', 'proceed'), ('ACM‑SIAM', 'acm‑siam'), ('Symposium', 'symposium'), ('Discrete', 'discret'), ('Algorithms', 'algorithm'), (',', ','), ('2013.', '2013.'), ('pp', 'pp'), ('1434–1453', '1434–1453'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), (':', ':'), ('Proceedings', 'Proceedings'), ('ACM‑SIAM', 'ACM‑SIAM'), ('Symposium', 'Symposium'), ('Discrete', 'Discrete'), ('Algorithms', 'Algorithms'), (',', ','), ('2013.', '2013.'), ('pp', 'pp'), ('1434–1453', '1434–1453'), ('.', '.')]



========================================== PARAGRAPH 506 ===========================================

 115. Tekin  C, van der Schaar M. Distributed online big data classification using context information. In: Proceedings of  the Allerton Conference on Communication, Control, and Computing, 2013. pp 1435–1442. 

------------------- Sentence 1 -------------------

 115.

>> Tokens are: 
 ['115', '.']

>> Bigrams are: 
 [('115', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('115', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('115', '115'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('115', '115'), ('.', '.')]

>> Lemmatization: 
 [('115', '115'), ('.', '.')]


------------------- Sentence 2 -------------------

Tekin  C, van der Schaar M. Distributed online big data classification using context information.

>> Tokens are: 
 ['Tekin', 'C', ',', 'van', 'der', 'Schaar', 'M.', 'Distributed', 'online', 'big', 'data', 'classification', 'using', 'context', 'information', '.']

>> Bigrams are: 
 [('Tekin', 'C'), ('C', ','), (',', 'van'), ('van', 'der'), ('der', 'Schaar'), ('Schaar', 'M.'), ('M.', 'Distributed'), ('Distributed', 'online'), ('online', 'big'), ('big', 'data'), ('data', 'classification'), ('classification', 'using'), ('using', 'context'), ('context', 'information'), ('information', '.')]

>> Trigrams are: 
 [('Tekin', 'C', ','), ('C', ',', 'van'), (',', 'van', 'der'), ('van', 'der', 'Schaar'), ('der', 'Schaar', 'M.'), ('Schaar', 'M.', 'Distributed'), ('M.', 'Distributed', 'online'), ('Distributed', 'online', 'big'), ('online', 'big', 'data'), ('big', 'data', 'classification'), ('data', 'classification', 'using'), ('classification', 'using', 'context'), ('using', 'context', 'information'), ('context', 'information', '.')]

>> POS Tags are: 
 [('Tekin', 'NNP'), ('C', 'NNP'), (',', ','), ('van', 'NN'), ('der', 'NN'), ('Schaar', 'NNP'), ('M.', 'NNP'), ('Distributed', 'NNP'), ('online', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('classification', 'NN'), ('using', 'VBG'), ('context', 'JJ'), ('information', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Tekin C', 'van der Schaar M. Distributed online', 'big data classification', 'context information']

>> Named Entities are: 
 [('PERSON', 'Tekin'), ('PERSON', 'Schaar M. Distributed')] 

>> Stemming using Porter Stemmer: 
 [('Tekin', 'tekin'), ('C', 'c'), (',', ','), ('van', 'van'), ('der', 'der'), ('Schaar', 'schaar'), ('M.', 'm.'), ('Distributed', 'distribut'), ('online', 'onlin'), ('big', 'big'), ('data', 'data'), ('classification', 'classif'), ('using', 'use'), ('context', 'context'), ('information', 'inform'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Tekin', 'tekin'), ('C', 'c'), (',', ','), ('van', 'van'), ('der', 'der'), ('Schaar', 'schaar'), ('M.', 'm.'), ('Distributed', 'distribut'), ('online', 'onlin'), ('big', 'big'), ('data', 'data'), ('classification', 'classif'), ('using', 'use'), ('context', 'context'), ('information', 'inform'), ('.', '.')]

>> Lemmatization: 
 [('Tekin', 'Tekin'), ('C', 'C'), (',', ','), ('van', 'van'), ('der', 'der'), ('Schaar', 'Schaar'), ('M.', 'M.'), ('Distributed', 'Distributed'), ('online', 'online'), ('big', 'big'), ('data', 'data'), ('classification', 'classification'), ('using', 'using'), ('context', 'context'), ('information', 'information'), ('.', '.')]


------------------- Sentence 3 -------------------

In: Proceedings of  the Allerton Conference on Communication, Control, and Computing, 2013. pp 1435–1442.

>> Tokens are: 
 ['In', ':', 'Proceedings', 'Allerton', 'Conference', 'Communication', ',', 'Control', ',', 'Computing', ',', '2013.', 'pp', '1435–1442', '.']

>> Bigrams are: 
 [('In', ':'), (':', 'Proceedings'), ('Proceedings', 'Allerton'), ('Allerton', 'Conference'), ('Conference', 'Communication'), ('Communication', ','), (',', 'Control'), ('Control', ','), (',', 'Computing'), ('Computing', ','), (',', '2013.'), ('2013.', 'pp'), ('pp', '1435–1442'), ('1435–1442', '.')]

>> Trigrams are: 
 [('In', ':', 'Proceedings'), (':', 'Proceedings', 'Allerton'), ('Proceedings', 'Allerton', 'Conference'), ('Allerton', 'Conference', 'Communication'), ('Conference', 'Communication', ','), ('Communication', ',', 'Control'), (',', 'Control', ','), ('Control', ',', 'Computing'), (',', 'Computing', ','), ('Computing', ',', '2013.'), (',', '2013.', 'pp'), ('2013.', 'pp', '1435–1442'), ('pp', '1435–1442', '.')]

>> POS Tags are: 
 [('In', 'IN'), (':', ':'), ('Proceedings', 'NNS'), ('Allerton', 'NNP'), ('Conference', 'NNP'), ('Communication', 'NNP'), (',', ','), ('Control', 'NNP'), (',', ','), ('Computing', 'NNP'), (',', ','), ('2013.', 'CD'), ('pp', 'NN'), ('1435–1442', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Proceedings Allerton Conference Communication', 'Control', 'Computing', 'pp']

>> Named Entities are: 
 [('PERSON', 'Allerton Conference Communication'), ('ORGANIZATION', 'Control'), ('ORGANIZATION', 'Computing')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), (':', ':'), ('Proceedings', 'proceed'), ('Allerton', 'allerton'), ('Conference', 'confer'), ('Communication', 'commun'), (',', ','), ('Control', 'control'), (',', ','), ('Computing', 'comput'), (',', ','), ('2013.', '2013.'), ('pp', 'pp'), ('1435–1442', '1435–1442'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), (':', ':'), ('Proceedings', 'proceed'), ('Allerton', 'allerton'), ('Conference', 'confer'), ('Communication', 'communic'), (',', ','), ('Control', 'control'), (',', ','), ('Computing', 'comput'), (',', ','), ('2013.', '2013.'), ('pp', 'pp'), ('1435–1442', '1435–1442'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), (':', ':'), ('Proceedings', 'Proceedings'), ('Allerton', 'Allerton'), ('Conference', 'Conference'), ('Communication', 'Communication'), (',', ','), ('Control', 'Control'), (',', ','), ('Computing', 'Computing'), (',', ','), ('2013.', '2013.'), ('pp', 'pp'), ('1435–1442', '1435–1442'), ('.', '.')]



========================================== PARAGRAPH 507 ===========================================

 116. Rebentrost P, Mohseni M, Lloyd S. Quantum support vector machine for big feature and big data classifica‑ tion. CoRR, vol. abs/1307.0471, 2014. [Online]. Available: http://dblp.uni‑trier.de/db/journals/corr/corr1307. html#RebentrostML13. 

------------------- Sentence 1 -------------------

 116.

>> Tokens are: 
 ['116', '.']

>> Bigrams are: 
 [('116', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('116', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('116', '116'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('116', '116'), ('.', '.')]

>> Lemmatization: 
 [('116', '116'), ('.', '.')]


------------------- Sentence 2 -------------------

Rebentrost P, Mohseni M, Lloyd S. Quantum support vector machine for big feature and big data classifica‑ tion.

>> Tokens are: 
 ['Rebentrost', 'P', ',', 'Mohseni', 'M', ',', 'Lloyd', 'S.', 'Quantum', 'support', 'vector', 'machine', 'big', 'feature', 'big', 'data', 'classifica‑', 'tion', '.']

>> Bigrams are: 
 [('Rebentrost', 'P'), ('P', ','), (',', 'Mohseni'), ('Mohseni', 'M'), ('M', ','), (',', 'Lloyd'), ('Lloyd', 'S.'), ('S.', 'Quantum'), ('Quantum', 'support'), ('support', 'vector'), ('vector', 'machine'), ('machine', 'big'), ('big', 'feature'), ('feature', 'big'), ('big', 'data'), ('data', 'classifica‑'), ('classifica‑', 'tion'), ('tion', '.')]

>> Trigrams are: 
 [('Rebentrost', 'P', ','), ('P', ',', 'Mohseni'), (',', 'Mohseni', 'M'), ('Mohseni', 'M', ','), ('M', ',', 'Lloyd'), (',', 'Lloyd', 'S.'), ('Lloyd', 'S.', 'Quantum'), ('S.', 'Quantum', 'support'), ('Quantum', 'support', 'vector'), ('support', 'vector', 'machine'), ('vector', 'machine', 'big'), ('machine', 'big', 'feature'), ('big', 'feature', 'big'), ('feature', 'big', 'data'), ('big', 'data', 'classifica‑'), ('data', 'classifica‑', 'tion'), ('classifica‑', 'tion', '.')]

>> POS Tags are: 
 [('Rebentrost', 'NNP'), ('P', 'NNP'), (',', ','), ('Mohseni', 'NNP'), ('M', 'NNP'), (',', ','), ('Lloyd', 'NNP'), ('S.', 'NNP'), ('Quantum', 'NNP'), ('support', 'NN'), ('vector', 'NN'), ('machine', 'NN'), ('big', 'JJ'), ('feature', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('classifica‑', 'NN'), ('tion', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Rebentrost P', 'Mohseni M', 'Lloyd S. Quantum support vector machine', 'big feature', 'big data classifica‑ tion']

>> Named Entities are: 
 [('PERSON', 'Rebentrost'), ('ORGANIZATION', 'P'), ('PERSON', 'Mohseni M'), ('PERSON', 'Lloyd S. Quantum')] 

>> Stemming using Porter Stemmer: 
 [('Rebentrost', 'rebentrost'), ('P', 'p'), (',', ','), ('Mohseni', 'mohseni'), ('M', 'm'), (',', ','), ('Lloyd', 'lloyd'), ('S.', 's.'), ('Quantum', 'quantum'), ('support', 'support'), ('vector', 'vector'), ('machine', 'machin'), ('big', 'big'), ('feature', 'featur'), ('big', 'big'), ('data', 'data'), ('classifica‑', 'classifica‑'), ('tion', 'tion'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Rebentrost', 'rebentrost'), ('P', 'p'), (',', ','), ('Mohseni', 'mohseni'), ('M', 'm'), (',', ','), ('Lloyd', 'lloyd'), ('S.', 's.'), ('Quantum', 'quantum'), ('support', 'support'), ('vector', 'vector'), ('machine', 'machin'), ('big', 'big'), ('feature', 'featur'), ('big', 'big'), ('data', 'data'), ('classifica‑', 'classifica‑'), ('tion', 'tion'), ('.', '.')]

>> Lemmatization: 
 [('Rebentrost', 'Rebentrost'), ('P', 'P'), (',', ','), ('Mohseni', 'Mohseni'), ('M', 'M'), (',', ','), ('Lloyd', 'Lloyd'), ('S.', 'S.'), ('Quantum', 'Quantum'), ('support', 'support'), ('vector', 'vector'), ('machine', 'machine'), ('big', 'big'), ('feature', 'feature'), ('big', 'big'), ('data', 'data'), ('classifica‑', 'classifica‑'), ('tion', 'tion'), ('.', '.')]


------------------- Sentence 3 -------------------

CoRR, vol.

>> Tokens are: 
 ['CoRR', ',', 'vol', '.']

>> Bigrams are: 
 [('CoRR', ','), (',', 'vol'), ('vol', '.')]

>> Trigrams are: 
 [('CoRR', ',', 'vol'), (',', 'vol', '.')]

>> POS Tags are: 
 [('CoRR', 'NNP'), (',', ','), ('vol', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['CoRR', 'vol']

>> Named Entities are: 
 [('GPE', 'CoRR')] 

>> Stemming using Porter Stemmer: 
 [('CoRR', 'corr'), (',', ','), ('vol', 'vol'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('CoRR', 'corr'), (',', ','), ('vol', 'vol'), ('.', '.')]

>> Lemmatization: 
 [('CoRR', 'CoRR'), (',', ','), ('vol', 'vol'), ('.', '.')]


------------------- Sentence 4 -------------------

abs/1307.0471, 2014.

>> Tokens are: 
 ['abs/1307.0471', ',', '2014', '.']

>> Bigrams are: 
 [('abs/1307.0471', ','), (',', '2014'), ('2014', '.')]

>> Trigrams are: 
 [('abs/1307.0471', ',', '2014'), (',', '2014', '.')]

>> POS Tags are: 
 [('abs/1307.0471', 'NN'), (',', ','), ('2014', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['abs/1307.0471']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('abs/1307.0471', 'abs/1307.0471'), (',', ','), ('2014', '2014'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('abs/1307.0471', 'abs/1307.0471'), (',', ','), ('2014', '2014'), ('.', '.')]

>> Lemmatization: 
 [('abs/1307.0471', 'abs/1307.0471'), (',', ','), ('2014', '2014'), ('.', '.')]


------------------- Sentence 5 -------------------

[Online].

>> Tokens are: 
 ['[', 'Online', ']', '.']

>> Bigrams are: 
 [('[', 'Online'), ('Online', ']'), (']', '.')]

>> Trigrams are: 
 [('[', 'Online', ']'), ('Online', ']', '.')]

>> POS Tags are: 
 [('[', 'JJ'), ('Online', 'NNP'), (']', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['[ Online ]']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('Online', 'onlin'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('Online', 'onlin'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('Online', 'Online'), (']', ']'), ('.', '.')]


------------------- Sentence 6 -------------------

Available: http://dblp.uni‑trier.de/db/journals/corr/corr1307.

>> Tokens are: 
 ['Available', ':', 'http', ':', '//dblp.uni‑trier.de/db/journals/corr/corr1307', '.']

>> Bigrams are: 
 [('Available', ':'), (':', 'http'), ('http', ':'), (':', '//dblp.uni‑trier.de/db/journals/corr/corr1307'), ('//dblp.uni‑trier.de/db/journals/corr/corr1307', '.')]

>> Trigrams are: 
 [('Available', ':', 'http'), (':', 'http', ':'), ('http', ':', '//dblp.uni‑trier.de/db/journals/corr/corr1307'), (':', '//dblp.uni‑trier.de/db/journals/corr/corr1307', '.')]

>> POS Tags are: 
 [('Available', 'JJ'), (':', ':'), ('http', 'NN'), (':', ':'), ('//dblp.uni‑trier.de/db/journals/corr/corr1307', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['http', '//dblp.uni‑trier.de/db/journals/corr/corr1307']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Available', 'avail'), (':', ':'), ('http', 'http'), (':', ':'), ('//dblp.uni‑trier.de/db/journals/corr/corr1307', '//dblp.uni‑trier.de/db/journals/corr/corr1307'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Available', 'avail'), (':', ':'), ('http', 'http'), (':', ':'), ('//dblp.uni‑trier.de/db/journals/corr/corr1307', '//dblp.uni‑trier.de/db/journals/corr/corr1307'), ('.', '.')]

>> Lemmatization: 
 [('Available', 'Available'), (':', ':'), ('http', 'http'), (':', ':'), ('//dblp.uni‑trier.de/db/journals/corr/corr1307', '//dblp.uni‑trier.de/db/journals/corr/corr1307'), ('.', '.')]


------------------- Sentence 7 -------------------

html#RebentrostML13.

>> Tokens are: 
 ['html', '#', 'RebentrostML13', '.']

>> Bigrams are: 
 [('html', '#'), ('#', 'RebentrostML13'), ('RebentrostML13', '.')]

>> Trigrams are: 
 [('html', '#', 'RebentrostML13'), ('#', 'RebentrostML13', '.')]

>> POS Tags are: 
 [('html', 'NN'), ('#', '#'), ('RebentrostML13', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['html', 'RebentrostML13']

>> Named Entities are: 
 [('ORGANIZATION', 'RebentrostML13')] 

>> Stemming using Porter Stemmer: 
 [('html', 'html'), ('#', '#'), ('RebentrostML13', 'rebentrostml13'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('html', 'html'), ('#', '#'), ('RebentrostML13', 'rebentrostml13'), ('.', '.')]

>> Lemmatization: 
 [('html', 'html'), ('#', '#'), ('RebentrostML13', 'RebentrostML13'), ('.', '.')]



========================================== PARAGRAPH 508 ===========================================

 117. Lin MY, Lee PY, Hsueh SC. Apriori‑based frequent itemset mining algorithms on mapreduce. In: Proceedings of the  International Conference on Ubiquitous Information Management and Communication, 2012. pp 76:1–76:8. 

------------------- Sentence 1 -------------------

 117.

>> Tokens are: 
 ['117', '.']

>> Bigrams are: 
 [('117', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('117', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('117', '117'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('117', '117'), ('.', '.')]

>> Lemmatization: 
 [('117', '117'), ('.', '.')]


------------------- Sentence 2 -------------------

Lin MY, Lee PY, Hsueh SC.

>> Tokens are: 
 ['Lin', 'MY', ',', 'Lee', 'PY', ',', 'Hsueh', 'SC', '.']

>> Bigrams are: 
 [('Lin', 'MY'), ('MY', ','), (',', 'Lee'), ('Lee', 'PY'), ('PY', ','), (',', 'Hsueh'), ('Hsueh', 'SC'), ('SC', '.')]

>> Trigrams are: 
 [('Lin', 'MY', ','), ('MY', ',', 'Lee'), (',', 'Lee', 'PY'), ('Lee', 'PY', ','), ('PY', ',', 'Hsueh'), (',', 'Hsueh', 'SC'), ('Hsueh', 'SC', '.')]

>> POS Tags are: 
 [('Lin', 'NNP'), ('MY', 'NNP'), (',', ','), ('Lee', 'NNP'), ('PY', 'NNP'), (',', ','), ('Hsueh', 'NNP'), ('SC', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Lin MY', 'Lee PY', 'Hsueh SC']

>> Named Entities are: 
 [('PERSON', 'Lin'), ('GPE', 'MY'), ('PERSON', 'Lee PY'), ('PERSON', 'Hsueh SC')] 

>> Stemming using Porter Stemmer: 
 [('Lin', 'lin'), ('MY', 'my'), (',', ','), ('Lee', 'lee'), ('PY', 'py'), (',', ','), ('Hsueh', 'hsueh'), ('SC', 'sc'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Lin', 'lin'), ('MY', 'my'), (',', ','), ('Lee', 'lee'), ('PY', 'py'), (',', ','), ('Hsueh', 'hsueh'), ('SC', 'sc'), ('.', '.')]

>> Lemmatization: 
 [('Lin', 'Lin'), ('MY', 'MY'), (',', ','), ('Lee', 'Lee'), ('PY', 'PY'), (',', ','), ('Hsueh', 'Hsueh'), ('SC', 'SC'), ('.', '.')]


------------------- Sentence 3 -------------------

Apriori‑based frequent itemset mining algorithms on mapreduce.

>> Tokens are: 
 ['Apriori‑based', 'frequent', 'itemset', 'mining', 'algorithms', 'mapreduce', '.']

>> Bigrams are: 
 [('Apriori‑based', 'frequent'), ('frequent', 'itemset'), ('itemset', 'mining'), ('mining', 'algorithms'), ('algorithms', 'mapreduce'), ('mapreduce', '.')]

>> Trigrams are: 
 [('Apriori‑based', 'frequent', 'itemset'), ('frequent', 'itemset', 'mining'), ('itemset', 'mining', 'algorithms'), ('mining', 'algorithms', 'mapreduce'), ('algorithms', 'mapreduce', '.')]

>> POS Tags are: 
 [('Apriori‑based', 'JJ'), ('frequent', 'JJ'), ('itemset', 'NN'), ('mining', 'NN'), ('algorithms', 'NN'), ('mapreduce', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Apriori‑based frequent itemset mining algorithms mapreduce']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Apriori‑based', 'apriori‑bas'), ('frequent', 'frequent'), ('itemset', 'itemset'), ('mining', 'mine'), ('algorithms', 'algorithm'), ('mapreduce', 'mapreduc'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Apriori‑based', 'apriori‑bas'), ('frequent', 'frequent'), ('itemset', 'itemset'), ('mining', 'mine'), ('algorithms', 'algorithm'), ('mapreduce', 'mapreduc'), ('.', '.')]

>> Lemmatization: 
 [('Apriori‑based', 'Apriori‑based'), ('frequent', 'frequent'), ('itemset', 'itemset'), ('mining', 'mining'), ('algorithms', 'algorithm'), ('mapreduce', 'mapreduce'), ('.', '.')]


------------------- Sentence 4 -------------------

In: Proceedings of the  International Conference on Ubiquitous Information Management and Communication, 2012. pp 76:1–76:8.

>> Tokens are: 
 ['In', ':', 'Proceedings', 'International', 'Conference', 'Ubiquitous', 'Information', 'Management', 'Communication', ',', '2012.', 'pp', '76:1–76:8', '.']

>> Bigrams are: 
 [('In', ':'), (':', 'Proceedings'), ('Proceedings', 'International'), ('International', 'Conference'), ('Conference', 'Ubiquitous'), ('Ubiquitous', 'Information'), ('Information', 'Management'), ('Management', 'Communication'), ('Communication', ','), (',', '2012.'), ('2012.', 'pp'), ('pp', '76:1–76:8'), ('76:1–76:8', '.')]

>> Trigrams are: 
 [('In', ':', 'Proceedings'), (':', 'Proceedings', 'International'), ('Proceedings', 'International', 'Conference'), ('International', 'Conference', 'Ubiquitous'), ('Conference', 'Ubiquitous', 'Information'), ('Ubiquitous', 'Information', 'Management'), ('Information', 'Management', 'Communication'), ('Management', 'Communication', ','), ('Communication', ',', '2012.'), (',', '2012.', 'pp'), ('2012.', 'pp', '76:1–76:8'), ('pp', '76:1–76:8', '.')]

>> POS Tags are: 
 [('In', 'IN'), (':', ':'), ('Proceedings', 'NNS'), ('International', 'NNP'), ('Conference', 'NNP'), ('Ubiquitous', 'NNP'), ('Information', 'NNP'), ('Management', 'NNP'), ('Communication', 'NNP'), (',', ','), ('2012.', 'CD'), ('pp', 'NN'), ('76:1–76:8', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Proceedings International Conference Ubiquitous Information Management Communication', 'pp']

>> Named Entities are: 
 [('ORGANIZATION', 'International Conference Ubiquitous Information')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), (':', ':'), ('Proceedings', 'proceed'), ('International', 'intern'), ('Conference', 'confer'), ('Ubiquitous', 'ubiquit'), ('Information', 'inform'), ('Management', 'manag'), ('Communication', 'commun'), (',', ','), ('2012.', '2012.'), ('pp', 'pp'), ('76:1–76:8', '76:1–76:8'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), (':', ':'), ('Proceedings', 'proceed'), ('International', 'intern'), ('Conference', 'confer'), ('Ubiquitous', 'ubiquit'), ('Information', 'inform'), ('Management', 'manag'), ('Communication', 'communic'), (',', ','), ('2012.', '2012.'), ('pp', 'pp'), ('76:1–76:8', '76:1–76:8'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), (':', ':'), ('Proceedings', 'Proceedings'), ('International', 'International'), ('Conference', 'Conference'), ('Ubiquitous', 'Ubiquitous'), ('Information', 'Information'), ('Management', 'Management'), ('Communication', 'Communication'), (',', ','), ('2012.', '2012.'), ('pp', 'pp'), ('76:1–76:8', '76:1–76:8'), ('.', '.')]



========================================== PARAGRAPH 509 ===========================================

 118. Riondato M, DeBrabant JA, Fonseca R, Upfal E. PARMA: a parallel randomized algorithm for approximate associa‑ tion rules mining in mapreduce. In: Proceedings of the ACM International Conference on Information and Knowl‑ edge Management, 2012. pp 85–94. 

------------------- Sentence 1 -------------------

 118.

>> Tokens are: 
 ['118', '.']

>> Bigrams are: 
 [('118', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('118', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('118', '118'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('118', '118'), ('.', '.')]

>> Lemmatization: 
 [('118', '118'), ('.', '.')]


------------------- Sentence 2 -------------------

Riondato M, DeBrabant JA, Fonseca R, Upfal E. PARMA: a parallel randomized algorithm for approximate associa‑ tion rules mining in mapreduce.

>> Tokens are: 
 ['Riondato', 'M', ',', 'DeBrabant', 'JA', ',', 'Fonseca', 'R', ',', 'Upfal', 'E.', 'PARMA', ':', 'parallel', 'randomized', 'algorithm', 'approximate', 'associa‑', 'tion', 'rules', 'mining', 'mapreduce', '.']

>> Bigrams are: 
 [('Riondato', 'M'), ('M', ','), (',', 'DeBrabant'), ('DeBrabant', 'JA'), ('JA', ','), (',', 'Fonseca'), ('Fonseca', 'R'), ('R', ','), (',', 'Upfal'), ('Upfal', 'E.'), ('E.', 'PARMA'), ('PARMA', ':'), (':', 'parallel'), ('parallel', 'randomized'), ('randomized', 'algorithm'), ('algorithm', 'approximate'), ('approximate', 'associa‑'), ('associa‑', 'tion'), ('tion', 'rules'), ('rules', 'mining'), ('mining', 'mapreduce'), ('mapreduce', '.')]

>> Trigrams are: 
 [('Riondato', 'M', ','), ('M', ',', 'DeBrabant'), (',', 'DeBrabant', 'JA'), ('DeBrabant', 'JA', ','), ('JA', ',', 'Fonseca'), (',', 'Fonseca', 'R'), ('Fonseca', 'R', ','), ('R', ',', 'Upfal'), (',', 'Upfal', 'E.'), ('Upfal', 'E.', 'PARMA'), ('E.', 'PARMA', ':'), ('PARMA', ':', 'parallel'), (':', 'parallel', 'randomized'), ('parallel', 'randomized', 'algorithm'), ('randomized', 'algorithm', 'approximate'), ('algorithm', 'approximate', 'associa‑'), ('approximate', 'associa‑', 'tion'), ('associa‑', 'tion', 'rules'), ('tion', 'rules', 'mining'), ('rules', 'mining', 'mapreduce'), ('mining', 'mapreduce', '.')]

>> POS Tags are: 
 [('Riondato', 'NNP'), ('M', 'NNP'), (',', ','), ('DeBrabant', 'NNP'), ('JA', 'NNP'), (',', ','), ('Fonseca', 'NNP'), ('R', 'NNP'), (',', ','), ('Upfal', 'NNP'), ('E.', 'NNP'), ('PARMA', 'NNP'), (':', ':'), ('parallel', 'JJ'), ('randomized', 'VBN'), ('algorithm', 'JJ'), ('approximate', 'JJ'), ('associa‑', 'NN'), ('tion', 'NN'), ('rules', 'NNS'), ('mining', 'VBG'), ('mapreduce', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Riondato M', 'DeBrabant JA', 'Fonseca R', 'Upfal E. PARMA', 'algorithm approximate associa‑ tion rules', 'mapreduce']

>> Named Entities are: 
 [('PERSON', 'Riondato'), ('ORGANIZATION', 'DeBrabant'), ('PERSON', 'Fonseca R'), ('PERSON', 'Upfal E.')] 

>> Stemming using Porter Stemmer: 
 [('Riondato', 'riondato'), ('M', 'm'), (',', ','), ('DeBrabant', 'debrab'), ('JA', 'ja'), (',', ','), ('Fonseca', 'fonseca'), ('R', 'r'), (',', ','), ('Upfal', 'upfal'), ('E.', 'e.'), ('PARMA', 'parma'), (':', ':'), ('parallel', 'parallel'), ('randomized', 'random'), ('algorithm', 'algorithm'), ('approximate', 'approxim'), ('associa‑', 'associa‑'), ('tion', 'tion'), ('rules', 'rule'), ('mining', 'mine'), ('mapreduce', 'mapreduc'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Riondato', 'riondato'), ('M', 'm'), (',', ','), ('DeBrabant', 'debrab'), ('JA', 'ja'), (',', ','), ('Fonseca', 'fonseca'), ('R', 'r'), (',', ','), ('Upfal', 'upfal'), ('E.', 'e.'), ('PARMA', 'parma'), (':', ':'), ('parallel', 'parallel'), ('randomized', 'random'), ('algorithm', 'algorithm'), ('approximate', 'approxim'), ('associa‑', 'associa‑'), ('tion', 'tion'), ('rules', 'rule'), ('mining', 'mine'), ('mapreduce', 'mapreduc'), ('.', '.')]

>> Lemmatization: 
 [('Riondato', 'Riondato'), ('M', 'M'), (',', ','), ('DeBrabant', 'DeBrabant'), ('JA', 'JA'), (',', ','), ('Fonseca', 'Fonseca'), ('R', 'R'), (',', ','), ('Upfal', 'Upfal'), ('E.', 'E.'), ('PARMA', 'PARMA'), (':', ':'), ('parallel', 'parallel'), ('randomized', 'randomized'), ('algorithm', 'algorithm'), ('approximate', 'approximate'), ('associa‑', 'associa‑'), ('tion', 'tion'), ('rules', 'rule'), ('mining', 'mining'), ('mapreduce', 'mapreduce'), ('.', '.')]


------------------- Sentence 3 -------------------

In: Proceedings of the ACM International Conference on Information and Knowl‑ edge Management, 2012. pp 85–94.

>> Tokens are: 
 ['In', ':', 'Proceedings', 'ACM', 'International', 'Conference', 'Information', 'Knowl‑', 'edge', 'Management', ',', '2012.', 'pp', '85–94', '.']

>> Bigrams are: 
 [('In', ':'), (':', 'Proceedings'), ('Proceedings', 'ACM'), ('ACM', 'International'), ('International', 'Conference'), ('Conference', 'Information'), ('Information', 'Knowl‑'), ('Knowl‑', 'edge'), ('edge', 'Management'), ('Management', ','), (',', '2012.'), ('2012.', 'pp'), ('pp', '85–94'), ('85–94', '.')]

>> Trigrams are: 
 [('In', ':', 'Proceedings'), (':', 'Proceedings', 'ACM'), ('Proceedings', 'ACM', 'International'), ('ACM', 'International', 'Conference'), ('International', 'Conference', 'Information'), ('Conference', 'Information', 'Knowl‑'), ('Information', 'Knowl‑', 'edge'), ('Knowl‑', 'edge', 'Management'), ('edge', 'Management', ','), ('Management', ',', '2012.'), (',', '2012.', 'pp'), ('2012.', 'pp', '85–94'), ('pp', '85–94', '.')]

>> POS Tags are: 
 [('In', 'IN'), (':', ':'), ('Proceedings', 'NNS'), ('ACM', 'NNP'), ('International', 'NNP'), ('Conference', 'NNP'), ('Information', 'NNP'), ('Knowl‑', 'NNP'), ('edge', 'NN'), ('Management', 'NNP'), (',', ','), ('2012.', 'CD'), ('pp', 'NN'), ('85–94', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Proceedings ACM International Conference Information Knowl‑ edge Management', 'pp']

>> Named Entities are: 
 [('ORGANIZATION', 'ACM International Conference Information')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), (':', ':'), ('Proceedings', 'proceed'), ('ACM', 'acm'), ('International', 'intern'), ('Conference', 'confer'), ('Information', 'inform'), ('Knowl‑', 'knowl‑'), ('edge', 'edg'), ('Management', 'manag'), (',', ','), ('2012.', '2012.'), ('pp', 'pp'), ('85–94', '85–94'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), (':', ':'), ('Proceedings', 'proceed'), ('ACM', 'acm'), ('International', 'intern'), ('Conference', 'confer'), ('Information', 'inform'), ('Knowl‑', 'knowl‑'), ('edge', 'edg'), ('Management', 'manag'), (',', ','), ('2012.', '2012.'), ('pp', 'pp'), ('85–94', '85–94'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), (':', ':'), ('Proceedings', 'Proceedings'), ('ACM', 'ACM'), ('International', 'International'), ('Conference', 'Conference'), ('Information', 'Information'), ('Knowl‑', 'Knowl‑'), ('edge', 'edge'), ('Management', 'Management'), (',', ','), ('2012.', '2012.'), ('pp', 'pp'), ('85–94', '85–94'), ('.', '.')]



========================================== PARAGRAPH 510 ===========================================

 119. Leung CS, MacKinnon R, Jiang F. Reducing the search space for big data mining for interesting patterns from  uncertain data. In: Proceedings of the International Congress on Big Data, 2014. pp 315–322. 

------------------- Sentence 1 -------------------

 119.

>> Tokens are: 
 ['119', '.']

>> Bigrams are: 
 [('119', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('119', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('119', '119'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('119', '119'), ('.', '.')]

>> Lemmatization: 
 [('119', '119'), ('.', '.')]


------------------- Sentence 2 -------------------

Leung CS, MacKinnon R, Jiang F. Reducing the search space for big data mining for interesting patterns from  uncertain data.

>> Tokens are: 
 ['Leung', 'CS', ',', 'MacKinnon', 'R', ',', 'Jiang', 'F.', 'Reducing', 'search', 'space', 'big', 'data', 'mining', 'interesting', 'patterns', 'uncertain', 'data', '.']

>> Bigrams are: 
 [('Leung', 'CS'), ('CS', ','), (',', 'MacKinnon'), ('MacKinnon', 'R'), ('R', ','), (',', 'Jiang'), ('Jiang', 'F.'), ('F.', 'Reducing'), ('Reducing', 'search'), ('search', 'space'), ('space', 'big'), ('big', 'data'), ('data', 'mining'), ('mining', 'interesting'), ('interesting', 'patterns'), ('patterns', 'uncertain'), ('uncertain', 'data'), ('data', '.')]

>> Trigrams are: 
 [('Leung', 'CS', ','), ('CS', ',', 'MacKinnon'), (',', 'MacKinnon', 'R'), ('MacKinnon', 'R', ','), ('R', ',', 'Jiang'), (',', 'Jiang', 'F.'), ('Jiang', 'F.', 'Reducing'), ('F.', 'Reducing', 'search'), ('Reducing', 'search', 'space'), ('search', 'space', 'big'), ('space', 'big', 'data'), ('big', 'data', 'mining'), ('data', 'mining', 'interesting'), ('mining', 'interesting', 'patterns'), ('interesting', 'patterns', 'uncertain'), ('patterns', 'uncertain', 'data'), ('uncertain', 'data', '.')]

>> POS Tags are: 
 [('Leung', 'NNP'), ('CS', 'NNP'), (',', ','), ('MacKinnon', 'NNP'), ('R', 'NNP'), (',', ','), ('Jiang', 'NNP'), ('F.', 'NNP'), ('Reducing', 'NNP'), ('search', 'NN'), ('space', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('mining', 'NN'), ('interesting', 'NN'), ('patterns', 'NNS'), ('uncertain', 'JJ'), ('data', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['Leung CS', 'MacKinnon R', 'Jiang F. Reducing search space', 'big data mining interesting patterns', 'uncertain data']

>> Named Entities are: 
 [('PERSON', 'Leung'), ('GPE', 'CS'), ('ORGANIZATION', 'MacKinnon R'), ('PERSON', 'Jiang F. Reducing')] 

>> Stemming using Porter Stemmer: 
 [('Leung', 'leung'), ('CS', 'cs'), (',', ','), ('MacKinnon', 'mackinnon'), ('R', 'r'), (',', ','), ('Jiang', 'jiang'), ('F.', 'f.'), ('Reducing', 'reduc'), ('search', 'search'), ('space', 'space'), ('big', 'big'), ('data', 'data'), ('mining', 'mine'), ('interesting', 'interest'), ('patterns', 'pattern'), ('uncertain', 'uncertain'), ('data', 'data'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Leung', 'leung'), ('CS', 'cs'), (',', ','), ('MacKinnon', 'mackinnon'), ('R', 'r'), (',', ','), ('Jiang', 'jiang'), ('F.', 'f.'), ('Reducing', 'reduc'), ('search', 'search'), ('space', 'space'), ('big', 'big'), ('data', 'data'), ('mining', 'mine'), ('interesting', 'interest'), ('patterns', 'pattern'), ('uncertain', 'uncertain'), ('data', 'data'), ('.', '.')]

>> Lemmatization: 
 [('Leung', 'Leung'), ('CS', 'CS'), (',', ','), ('MacKinnon', 'MacKinnon'), ('R', 'R'), (',', ','), ('Jiang', 'Jiang'), ('F.', 'F.'), ('Reducing', 'Reducing'), ('search', 'search'), ('space', 'space'), ('big', 'big'), ('data', 'data'), ('mining', 'mining'), ('interesting', 'interesting'), ('patterns', 'pattern'), ('uncertain', 'uncertain'), ('data', 'data'), ('.', '.')]


------------------- Sentence 3 -------------------

In: Proceedings of the International Congress on Big Data, 2014. pp 315–322.

>> Tokens are: 
 ['In', ':', 'Proceedings', 'International', 'Congress', 'Big', 'Data', ',', '2014.', 'pp', '315–322', '.']

>> Bigrams are: 
 [('In', ':'), (':', 'Proceedings'), ('Proceedings', 'International'), ('International', 'Congress'), ('Congress', 'Big'), ('Big', 'Data'), ('Data', ','), (',', '2014.'), ('2014.', 'pp'), ('pp', '315–322'), ('315–322', '.')]

>> Trigrams are: 
 [('In', ':', 'Proceedings'), (':', 'Proceedings', 'International'), ('Proceedings', 'International', 'Congress'), ('International', 'Congress', 'Big'), ('Congress', 'Big', 'Data'), ('Big', 'Data', ','), ('Data', ',', '2014.'), (',', '2014.', 'pp'), ('2014.', 'pp', '315–322'), ('pp', '315–322', '.')]

>> POS Tags are: 
 [('In', 'IN'), (':', ':'), ('Proceedings', 'NNS'), ('International', 'NNP'), ('Congress', 'NNP'), ('Big', 'NNP'), ('Data', 'NNP'), (',', ','), ('2014.', 'CD'), ('pp', 'NN'), ('315–322', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Proceedings International Congress Big Data', 'pp']

>> Named Entities are: 
 [('ORGANIZATION', 'International Congress')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), (':', ':'), ('Proceedings', 'proceed'), ('International', 'intern'), ('Congress', 'congress'), ('Big', 'big'), ('Data', 'data'), (',', ','), ('2014.', '2014.'), ('pp', 'pp'), ('315–322', '315–322'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), (':', ':'), ('Proceedings', 'proceed'), ('International', 'intern'), ('Congress', 'congress'), ('Big', 'big'), ('Data', 'data'), (',', ','), ('2014.', '2014.'), ('pp', 'pp'), ('315–322', '315–322'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), (':', ':'), ('Proceedings', 'Proceedings'), ('International', 'International'), ('Congress', 'Congress'), ('Big', 'Big'), ('Data', 'Data'), (',', ','), ('2014.', '2014.'), ('pp', 'pp'), ('315–322', '315–322'), ('.', '.')]



========================================== PARAGRAPH 511 ===========================================

 120. Yang L, Shi Z, Xu L, Liang F, Kirsh I. DH‑TRIE frequent pattern mining on hadoop using JPA. In: Proceedings of the  International Conference on Granular Computing, 2011. pp 875–878. 

------------------- Sentence 1 -------------------

 120.

>> Tokens are: 
 ['120', '.']

>> Bigrams are: 
 [('120', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('120', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('120', '120'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('120', '120'), ('.', '.')]

>> Lemmatization: 
 [('120', '120'), ('.', '.')]


------------------- Sentence 2 -------------------

Yang L, Shi Z, Xu L, Liang F, Kirsh I. DH‑TRIE frequent pattern mining on hadoop using JPA.

>> Tokens are: 
 ['Yang', 'L', ',', 'Shi', 'Z', ',', 'Xu', 'L', ',', 'Liang', 'F', ',', 'Kirsh', 'I.', 'DH‑TRIE', 'frequent', 'pattern', 'mining', 'hadoop', 'using', 'JPA', '.']

>> Bigrams are: 
 [('Yang', 'L'), ('L', ','), (',', 'Shi'), ('Shi', 'Z'), ('Z', ','), (',', 'Xu'), ('Xu', 'L'), ('L', ','), (',', 'Liang'), ('Liang', 'F'), ('F', ','), (',', 'Kirsh'), ('Kirsh', 'I.'), ('I.', 'DH‑TRIE'), ('DH‑TRIE', 'frequent'), ('frequent', 'pattern'), ('pattern', 'mining'), ('mining', 'hadoop'), ('hadoop', 'using'), ('using', 'JPA'), ('JPA', '.')]

>> Trigrams are: 
 [('Yang', 'L', ','), ('L', ',', 'Shi'), (',', 'Shi', 'Z'), ('Shi', 'Z', ','), ('Z', ',', 'Xu'), (',', 'Xu', 'L'), ('Xu', 'L', ','), ('L', ',', 'Liang'), (',', 'Liang', 'F'), ('Liang', 'F', ','), ('F', ',', 'Kirsh'), (',', 'Kirsh', 'I.'), ('Kirsh', 'I.', 'DH‑TRIE'), ('I.', 'DH‑TRIE', 'frequent'), ('DH‑TRIE', 'frequent', 'pattern'), ('frequent', 'pattern', 'mining'), ('pattern', 'mining', 'hadoop'), ('mining', 'hadoop', 'using'), ('hadoop', 'using', 'JPA'), ('using', 'JPA', '.')]

>> POS Tags are: 
 [('Yang', 'NNP'), ('L', 'NNP'), (',', ','), ('Shi', 'NNP'), ('Z', 'NNP'), (',', ','), ('Xu', 'NNP'), ('L', 'NNP'), (',', ','), ('Liang', 'NNP'), ('F', 'NNP'), (',', ','), ('Kirsh', 'NNP'), ('I.', 'NNP'), ('DH‑TRIE', 'NNP'), ('frequent', 'JJ'), ('pattern', 'NN'), ('mining', 'NN'), ('hadoop', 'NN'), ('using', 'VBG'), ('JPA', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Yang L', 'Shi Z', 'Xu L', 'Liang F', 'Kirsh I. DH‑TRIE', 'frequent pattern mining hadoop', 'JPA']

>> Named Entities are: 
 [('PERSON', 'Yang'), ('ORGANIZATION', 'L'), ('PERSON', 'Shi Z'), ('PERSON', 'Xu L'), ('PERSON', 'Liang F'), ('PERSON', 'Kirsh I.'), ('ORGANIZATION', 'JPA')] 

>> Stemming using Porter Stemmer: 
 [('Yang', 'yang'), ('L', 'l'), (',', ','), ('Shi', 'shi'), ('Z', 'z'), (',', ','), ('Xu', 'xu'), ('L', 'l'), (',', ','), ('Liang', 'liang'), ('F', 'f'), (',', ','), ('Kirsh', 'kirsh'), ('I.', 'i.'), ('DH‑TRIE', 'dh‑trie'), ('frequent', 'frequent'), ('pattern', 'pattern'), ('mining', 'mine'), ('hadoop', 'hadoop'), ('using', 'use'), ('JPA', 'jpa'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Yang', 'yang'), ('L', 'l'), (',', ','), ('Shi', 'shi'), ('Z', 'z'), (',', ','), ('Xu', 'xu'), ('L', 'l'), (',', ','), ('Liang', 'liang'), ('F', 'f'), (',', ','), ('Kirsh', 'kirsh'), ('I.', 'i.'), ('DH‑TRIE', 'dh‑trie'), ('frequent', 'frequent'), ('pattern', 'pattern'), ('mining', 'mine'), ('hadoop', 'hadoop'), ('using', 'use'), ('JPA', 'jpa'), ('.', '.')]

>> Lemmatization: 
 [('Yang', 'Yang'), ('L', 'L'), (',', ','), ('Shi', 'Shi'), ('Z', 'Z'), (',', ','), ('Xu', 'Xu'), ('L', 'L'), (',', ','), ('Liang', 'Liang'), ('F', 'F'), (',', ','), ('Kirsh', 'Kirsh'), ('I.', 'I.'), ('DH‑TRIE', 'DH‑TRIE'), ('frequent', 'frequent'), ('pattern', 'pattern'), ('mining', 'mining'), ('hadoop', 'hadoop'), ('using', 'using'), ('JPA', 'JPA'), ('.', '.')]


------------------- Sentence 3 -------------------

In: Proceedings of the  International Conference on Granular Computing, 2011. pp 875–878.

>> Tokens are: 
 ['In', ':', 'Proceedings', 'International', 'Conference', 'Granular', 'Computing', ',', '2011.', 'pp', '875–878', '.']

>> Bigrams are: 
 [('In', ':'), (':', 'Proceedings'), ('Proceedings', 'International'), ('International', 'Conference'), ('Conference', 'Granular'), ('Granular', 'Computing'), ('Computing', ','), (',', '2011.'), ('2011.', 'pp'), ('pp', '875–878'), ('875–878', '.')]

>> Trigrams are: 
 [('In', ':', 'Proceedings'), (':', 'Proceedings', 'International'), ('Proceedings', 'International', 'Conference'), ('International', 'Conference', 'Granular'), ('Conference', 'Granular', 'Computing'), ('Granular', 'Computing', ','), ('Computing', ',', '2011.'), (',', '2011.', 'pp'), ('2011.', 'pp', '875–878'), ('pp', '875–878', '.')]

>> POS Tags are: 
 [('In', 'IN'), (':', ':'), ('Proceedings', 'NNS'), ('International', 'NNP'), ('Conference', 'NNP'), ('Granular', 'NNP'), ('Computing', 'NNP'), (',', ','), ('2011.', 'CD'), ('pp', 'NN'), ('875–878', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Proceedings International Conference Granular Computing', 'pp']

>> Named Entities are: 
 [('ORGANIZATION', 'International Conference Granular')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), (':', ':'), ('Proceedings', 'proceed'), ('International', 'intern'), ('Conference', 'confer'), ('Granular', 'granular'), ('Computing', 'comput'), (',', ','), ('2011.', '2011.'), ('pp', 'pp'), ('875–878', '875–878'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), (':', ':'), ('Proceedings', 'proceed'), ('International', 'intern'), ('Conference', 'confer'), ('Granular', 'granular'), ('Computing', 'comput'), (',', ','), ('2011.', '2011.'), ('pp', 'pp'), ('875–878', '875–878'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), (':', ':'), ('Proceedings', 'Proceedings'), ('International', 'International'), ('Conference', 'Conference'), ('Granular', 'Granular'), ('Computing', 'Computing'), (',', ','), ('2011.', '2011.'), ('pp', 'pp'), ('875–878', '875–878'), ('.', '.')]



========================================== PARAGRAPH 512 ===========================================

 121. Huang JW, Lin SC, Chen MS. DPSP: Distributed progressive sequential pattern mining on the cloud. In: Proceed‑ ings of the Advances in Knowledge Discovery and Data Mining, vol. 6119, 2010, pp 27–34. 

------------------- Sentence 1 -------------------

 121.

>> Tokens are: 
 ['121', '.']

>> Bigrams are: 
 [('121', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('121', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('121', '121'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('121', '121'), ('.', '.')]

>> Lemmatization: 
 [('121', '121'), ('.', '.')]


------------------- Sentence 2 -------------------

Huang JW, Lin SC, Chen MS. DPSP: Distributed progressive sequential pattern mining on the cloud.

>> Tokens are: 
 ['Huang', 'JW', ',', 'Lin', 'SC', ',', 'Chen', 'MS.', 'DPSP', ':', 'Distributed', 'progressive', 'sequential', 'pattern', 'mining', 'cloud', '.']

>> Bigrams are: 
 [('Huang', 'JW'), ('JW', ','), (',', 'Lin'), ('Lin', 'SC'), ('SC', ','), (',', 'Chen'), ('Chen', 'MS.'), ('MS.', 'DPSP'), ('DPSP', ':'), (':', 'Distributed'), ('Distributed', 'progressive'), ('progressive', 'sequential'), ('sequential', 'pattern'), ('pattern', 'mining'), ('mining', 'cloud'), ('cloud', '.')]

>> Trigrams are: 
 [('Huang', 'JW', ','), ('JW', ',', 'Lin'), (',', 'Lin', 'SC'), ('Lin', 'SC', ','), ('SC', ',', 'Chen'), (',', 'Chen', 'MS.'), ('Chen', 'MS.', 'DPSP'), ('MS.', 'DPSP', ':'), ('DPSP', ':', 'Distributed'), (':', 'Distributed', 'progressive'), ('Distributed', 'progressive', 'sequential'), ('progressive', 'sequential', 'pattern'), ('sequential', 'pattern', 'mining'), ('pattern', 'mining', 'cloud'), ('mining', 'cloud', '.')]

>> POS Tags are: 
 [('Huang', 'NNP'), ('JW', 'NNP'), (',', ','), ('Lin', 'NNP'), ('SC', 'NNP'), (',', ','), ('Chen', 'NNP'), ('MS.', 'NNP'), ('DPSP', 'NNP'), (':', ':'), ('Distributed', 'VBN'), ('progressive', 'JJ'), ('sequential', 'JJ'), ('pattern', 'NN'), ('mining', 'NN'), ('cloud', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Huang JW', 'Lin SC', 'Chen MS. DPSP', 'progressive sequential pattern mining cloud']

>> Named Entities are: 
 [('PERSON', 'Huang'), ('GPE', 'JW'), ('PERSON', 'Lin SC'), ('PERSON', 'Chen')] 

>> Stemming using Porter Stemmer: 
 [('Huang', 'huang'), ('JW', 'jw'), (',', ','), ('Lin', 'lin'), ('SC', 'sc'), (',', ','), ('Chen', 'chen'), ('MS.', 'ms.'), ('DPSP', 'dpsp'), (':', ':'), ('Distributed', 'distribut'), ('progressive', 'progress'), ('sequential', 'sequenti'), ('pattern', 'pattern'), ('mining', 'mine'), ('cloud', 'cloud'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Huang', 'huang'), ('JW', 'jw'), (',', ','), ('Lin', 'lin'), ('SC', 'sc'), (',', ','), ('Chen', 'chen'), ('MS.', 'ms.'), ('DPSP', 'dpsp'), (':', ':'), ('Distributed', 'distribut'), ('progressive', 'progress'), ('sequential', 'sequenti'), ('pattern', 'pattern'), ('mining', 'mine'), ('cloud', 'cloud'), ('.', '.')]

>> Lemmatization: 
 [('Huang', 'Huang'), ('JW', 'JW'), (',', ','), ('Lin', 'Lin'), ('SC', 'SC'), (',', ','), ('Chen', 'Chen'), ('MS.', 'MS.'), ('DPSP', 'DPSP'), (':', ':'), ('Distributed', 'Distributed'), ('progressive', 'progressive'), ('sequential', 'sequential'), ('pattern', 'pattern'), ('mining', 'mining'), ('cloud', 'cloud'), ('.', '.')]


------------------- Sentence 3 -------------------

In: Proceed‑ ings of the Advances in Knowledge Discovery and Data Mining, vol.

>> Tokens are: 
 ['In', ':', 'Proceed‑', 'ings', 'Advances', 'Knowledge', 'Discovery', 'Data', 'Mining', ',', 'vol', '.']

>> Bigrams are: 
 [('In', ':'), (':', 'Proceed‑'), ('Proceed‑', 'ings'), ('ings', 'Advances'), ('Advances', 'Knowledge'), ('Knowledge', 'Discovery'), ('Discovery', 'Data'), ('Data', 'Mining'), ('Mining', ','), (',', 'vol'), ('vol', '.')]

>> Trigrams are: 
 [('In', ':', 'Proceed‑'), (':', 'Proceed‑', 'ings'), ('Proceed‑', 'ings', 'Advances'), ('ings', 'Advances', 'Knowledge'), ('Advances', 'Knowledge', 'Discovery'), ('Knowledge', 'Discovery', 'Data'), ('Discovery', 'Data', 'Mining'), ('Data', 'Mining', ','), ('Mining', ',', 'vol'), (',', 'vol', '.')]

>> POS Tags are: 
 [('In', 'IN'), (':', ':'), ('Proceed‑', 'NNP'), ('ings', 'NNS'), ('Advances', 'NNP'), ('Knowledge', 'NNP'), ('Discovery', 'NNP'), ('Data', 'NNP'), ('Mining', 'NNP'), (',', ','), ('vol', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Proceed‑ ings Advances Knowledge Discovery Data Mining', 'vol']

>> Named Entities are: 
 [('PERSON', 'Advances Knowledge Discovery Data Mining')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), (':', ':'), ('Proceed‑', 'proceed‑'), ('ings', 'ing'), ('Advances', 'advanc'), ('Knowledge', 'knowledg'), ('Discovery', 'discoveri'), ('Data', 'data'), ('Mining', 'mine'), (',', ','), ('vol', 'vol'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), (':', ':'), ('Proceed‑', 'proceed‑'), ('ings', 'ing'), ('Advances', 'advanc'), ('Knowledge', 'knowledg'), ('Discovery', 'discoveri'), ('Data', 'data'), ('Mining', 'mine'), (',', ','), ('vol', 'vol'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), (':', ':'), ('Proceed‑', 'Proceed‑'), ('ings', 'ings'), ('Advances', 'Advances'), ('Knowledge', 'Knowledge'), ('Discovery', 'Discovery'), ('Data', 'Data'), ('Mining', 'Mining'), (',', ','), ('vol', 'vol'), ('.', '.')]


------------------- Sentence 4 -------------------

6119, 2010, pp 27–34.

>> Tokens are: 
 ['6119', ',', '2010', ',', 'pp', '27–34', '.']

>> Bigrams are: 
 [('6119', ','), (',', '2010'), ('2010', ','), (',', 'pp'), ('pp', '27–34'), ('27–34', '.')]

>> Trigrams are: 
 [('6119', ',', '2010'), (',', '2010', ','), ('2010', ',', 'pp'), (',', 'pp', '27–34'), ('pp', '27–34', '.')]

>> POS Tags are: 
 [('6119', 'CD'), (',', ','), ('2010', 'CD'), (',', ','), ('pp', 'VBD'), ('27–34', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('6119', '6119'), (',', ','), ('2010', '2010'), (',', ','), ('pp', 'pp'), ('27–34', '27–34'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('6119', '6119'), (',', ','), ('2010', '2010'), (',', ','), ('pp', 'pp'), ('27–34', '27–34'), ('.', '.')]

>> Lemmatization: 
 [('6119', '6119'), (',', ','), ('2010', '2010'), (',', ','), ('pp', 'pp'), ('27–34', '27–34'), ('.', '.')]



========================================== PARAGRAPH 513 ===========================================

 122. Paz CE. A survey of parallel genetic algorithms. Calc Paralleles Reseaux et Syst Repar. 1998;10(2):141–71.  123. kranthi Kiran B, Babu AV. A comparative study of issues in big data clustering algorithm with constraint based  

------------------- Sentence 1 -------------------

 122.

>> Tokens are: 
 ['122', '.']

>> Bigrams are: 
 [('122', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('122', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('122', '122'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('122', '122'), ('.', '.')]

>> Lemmatization: 
 [('122', '122'), ('.', '.')]


------------------- Sentence 2 -------------------

Paz CE.

>> Tokens are: 
 ['Paz', 'CE', '.']

>> Bigrams are: 
 [('Paz', 'CE'), ('CE', '.')]

>> Trigrams are: 
 [('Paz', 'CE', '.')]

>> POS Tags are: 
 [('Paz', 'NNP'), ('CE', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Paz CE']

>> Named Entities are: 
 [('PERSON', 'Paz')] 

>> Stemming using Porter Stemmer: 
 [('Paz', 'paz'), ('CE', 'ce'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Paz', 'paz'), ('CE', 'ce'), ('.', '.')]

>> Lemmatization: 
 [('Paz', 'Paz'), ('CE', 'CE'), ('.', '.')]


------------------- Sentence 3 -------------------

A survey of parallel genetic algorithms.

>> Tokens are: 
 ['A', 'survey', 'parallel', 'genetic', 'algorithms', '.']

>> Bigrams are: 
 [('A', 'survey'), ('survey', 'parallel'), ('parallel', 'genetic'), ('genetic', 'algorithms'), ('algorithms', '.')]

>> Trigrams are: 
 [('A', 'survey', 'parallel'), ('survey', 'parallel', 'genetic'), ('parallel', 'genetic', 'algorithms'), ('genetic', 'algorithms', '.')]

>> POS Tags are: 
 [('A', 'DT'), ('survey', 'NN'), ('parallel', 'JJ'), ('genetic', 'JJ'), ('algorithms', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['A survey', 'parallel genetic algorithms']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('A', 'a'), ('survey', 'survey'), ('parallel', 'parallel'), ('genetic', 'genet'), ('algorithms', 'algorithm'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('A', 'a'), ('survey', 'survey'), ('parallel', 'parallel'), ('genetic', 'genet'), ('algorithms', 'algorithm'), ('.', '.')]

>> Lemmatization: 
 [('A', 'A'), ('survey', 'survey'), ('parallel', 'parallel'), ('genetic', 'genetic'), ('algorithms', 'algorithm'), ('.', '.')]


------------------- Sentence 4 -------------------

Calc Paralleles Reseaux et Syst Repar.

>> Tokens are: 
 ['Calc', 'Paralleles', 'Reseaux', 'et', 'Syst', 'Repar', '.']

>> Bigrams are: 
 [('Calc', 'Paralleles'), ('Paralleles', 'Reseaux'), ('Reseaux', 'et'), ('et', 'Syst'), ('Syst', 'Repar'), ('Repar', '.')]

>> Trigrams are: 
 [('Calc', 'Paralleles', 'Reseaux'), ('Paralleles', 'Reseaux', 'et'), ('Reseaux', 'et', 'Syst'), ('et', 'Syst', 'Repar'), ('Syst', 'Repar', '.')]

>> POS Tags are: 
 [('Calc', 'NNP'), ('Paralleles', 'NNP'), ('Reseaux', 'NNP'), ('et', 'FW'), ('Syst', 'NNP'), ('Repar', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Calc Paralleles Reseaux', 'Syst Repar']

>> Named Entities are: 
 [('PERSON', 'Calc'), ('ORGANIZATION', 'Paralleles Reseaux'), ('PERSON', 'Syst Repar')] 

>> Stemming using Porter Stemmer: 
 [('Calc', 'calc'), ('Paralleles', 'parallel'), ('Reseaux', 'reseaux'), ('et', 'et'), ('Syst', 'syst'), ('Repar', 'repar'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Calc', 'calc'), ('Paralleles', 'parallel'), ('Reseaux', 'reseaux'), ('et', 'et'), ('Syst', 'syst'), ('Repar', 'repar'), ('.', '.')]

>> Lemmatization: 
 [('Calc', 'Calc'), ('Paralleles', 'Paralleles'), ('Reseaux', 'Reseaux'), ('et', 'et'), ('Syst', 'Syst'), ('Repar', 'Repar'), ('.', '.')]


------------------- Sentence 5 -------------------

1998;10(2):141–71.

>> Tokens are: 
 ['1998', ';', '10', '(', '2', ')', ':141–71', '.']

>> Bigrams are: 
 [('1998', ';'), (';', '10'), ('10', '('), ('(', '2'), ('2', ')'), (')', ':141–71'), (':141–71', '.')]

>> Trigrams are: 
 [('1998', ';', '10'), (';', '10', '('), ('10', '(', '2'), ('(', '2', ')'), ('2', ')', ':141–71'), (')', ':141–71', '.')]

>> POS Tags are: 
 [('1998', 'CD'), (';', ':'), ('10', 'CD'), ('(', '('), ('2', 'CD'), (')', ')'), (':141–71', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 [':141–71']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('1998', '1998'), (';', ';'), ('10', '10'), ('(', '('), ('2', '2'), (')', ')'), (':141–71', ':141–71'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('1998', '1998'), (';', ';'), ('10', '10'), ('(', '('), ('2', '2'), (')', ')'), (':141–71', ':141–71'), ('.', '.')]

>> Lemmatization: 
 [('1998', '1998'), (';', ';'), ('10', '10'), ('(', '('), ('2', '2'), (')', ')'), (':141–71', ':141–71'), ('.', '.')]


------------------- Sentence 6 -------------------

123. kranthi Kiran B, Babu AV.

>> Tokens are: 
 ['123.', 'kranthi', 'Kiran', 'B', ',', 'Babu', 'AV', '.']

>> Bigrams are: 
 [('123.', 'kranthi'), ('kranthi', 'Kiran'), ('Kiran', 'B'), ('B', ','), (',', 'Babu'), ('Babu', 'AV'), ('AV', '.')]

>> Trigrams are: 
 [('123.', 'kranthi', 'Kiran'), ('kranthi', 'Kiran', 'B'), ('Kiran', 'B', ','), ('B', ',', 'Babu'), (',', 'Babu', 'AV'), ('Babu', 'AV', '.')]

>> POS Tags are: 
 [('123.', 'CD'), ('kranthi', 'NN'), ('Kiran', 'NNP'), ('B', 'NNP'), (',', ','), ('Babu', 'NNP'), ('AV', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['kranthi Kiran B', 'Babu AV']

>> Named Entities are: 
 [('PERSON', 'Kiran B'), ('PERSON', 'Babu AV')] 

>> Stemming using Porter Stemmer: 
 [('123.', '123.'), ('kranthi', 'kranthi'), ('Kiran', 'kiran'), ('B', 'b'), (',', ','), ('Babu', 'babu'), ('AV', 'av'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('123.', '123.'), ('kranthi', 'kranthi'), ('Kiran', 'kiran'), ('B', 'b'), (',', ','), ('Babu', 'babu'), ('AV', 'av'), ('.', '.')]

>> Lemmatization: 
 [('123.', '123.'), ('kranthi', 'kranthi'), ('Kiran', 'Kiran'), ('B', 'B'), (',', ','), ('Babu', 'Babu'), ('AV', 'AV'), ('.', '.')]


------------------- Sentence 7 -------------------

A comparative study of issues in big data clustering algorithm with constraint based

>> Tokens are: 
 ['A', 'comparative', 'study', 'issues', 'big', 'data', 'clustering', 'algorithm', 'constraint', 'based']

>> Bigrams are: 
 [('A', 'comparative'), ('comparative', 'study'), ('study', 'issues'), ('issues', 'big'), ('big', 'data'), ('data', 'clustering'), ('clustering', 'algorithm'), ('algorithm', 'constraint'), ('constraint', 'based')]

>> Trigrams are: 
 [('A', 'comparative', 'study'), ('comparative', 'study', 'issues'), ('study', 'issues', 'big'), ('issues', 'big', 'data'), ('big', 'data', 'clustering'), ('data', 'clustering', 'algorithm'), ('clustering', 'algorithm', 'constraint'), ('algorithm', 'constraint', 'based')]

>> POS Tags are: 
 [('A', 'DT'), ('comparative', 'JJ'), ('study', 'NN'), ('issues', 'NNS'), ('big', 'JJ'), ('data', 'NNS'), ('clustering', 'VBG'), ('algorithm', 'NN'), ('constraint', 'NN'), ('based', 'VBN')]

>> Noun Phrases are: 
 ['A comparative study issues', 'big data', 'algorithm constraint']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('A', 'a'), ('comparative', 'compar'), ('study', 'studi'), ('issues', 'issu'), ('big', 'big'), ('data', 'data'), ('clustering', 'cluster'), ('algorithm', 'algorithm'), ('constraint', 'constraint'), ('based', 'base')]

>> Stemming using Snowball Stemmer: 
 [('A', 'a'), ('comparative', 'compar'), ('study', 'studi'), ('issues', 'issu'), ('big', 'big'), ('data', 'data'), ('clustering', 'cluster'), ('algorithm', 'algorithm'), ('constraint', 'constraint'), ('based', 'base')]

>> Lemmatization: 
 [('A', 'A'), ('comparative', 'comparative'), ('study', 'study'), ('issues', 'issue'), ('big', 'big'), ('data', 'data'), ('clustering', 'clustering'), ('algorithm', 'algorithm'), ('constraint', 'constraint'), ('based', 'based')]



========================================== PARAGRAPH 514 ===========================================

genetic algorithm for associative clustering. Int J Innov Res Comp Commun Eng 2014; 2(8): 5423–5432.  124. Bu Y, Borkar VR, Carey MJ, Rosen J, Polyzotis N, Condie T, Weimer M, Ramakrishnan R. Scaling datalog for machine  

------------------- Sentence 1 -------------------

genetic algorithm for associative clustering.

>> Tokens are: 
 ['genetic', 'algorithm', 'associative', 'clustering', '.']

>> Bigrams are: 
 [('genetic', 'algorithm'), ('algorithm', 'associative'), ('associative', 'clustering'), ('clustering', '.')]

>> Trigrams are: 
 [('genetic', 'algorithm', 'associative'), ('algorithm', 'associative', 'clustering'), ('associative', 'clustering', '.')]

>> POS Tags are: 
 [('genetic', 'JJ'), ('algorithm', 'NNS'), ('associative', 'JJ'), ('clustering', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['genetic algorithm', 'associative clustering']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('genetic', 'genet'), ('algorithm', 'algorithm'), ('associative', 'associ'), ('clustering', 'cluster'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('genetic', 'genet'), ('algorithm', 'algorithm'), ('associative', 'associ'), ('clustering', 'cluster'), ('.', '.')]

>> Lemmatization: 
 [('genetic', 'genetic'), ('algorithm', 'algorithm'), ('associative', 'associative'), ('clustering', 'clustering'), ('.', '.')]


------------------- Sentence 2 -------------------

Int J Innov Res Comp Commun Eng 2014; 2(8): 5423–5432.

>> Tokens are: 
 ['Int', 'J', 'Innov', 'Res', 'Comp', 'Commun', 'Eng', '2014', ';', '2', '(', '8', ')', ':', '5423–5432', '.']

>> Bigrams are: 
 [('Int', 'J'), ('J', 'Innov'), ('Innov', 'Res'), ('Res', 'Comp'), ('Comp', 'Commun'), ('Commun', 'Eng'), ('Eng', '2014'), ('2014', ';'), (';', '2'), ('2', '('), ('(', '8'), ('8', ')'), (')', ':'), (':', '5423–5432'), ('5423–5432', '.')]

>> Trigrams are: 
 [('Int', 'J', 'Innov'), ('J', 'Innov', 'Res'), ('Innov', 'Res', 'Comp'), ('Res', 'Comp', 'Commun'), ('Comp', 'Commun', 'Eng'), ('Commun', 'Eng', '2014'), ('Eng', '2014', ';'), ('2014', ';', '2'), (';', '2', '('), ('2', '(', '8'), ('(', '8', ')'), ('8', ')', ':'), (')', ':', '5423–5432'), (':', '5423–5432', '.')]

>> POS Tags are: 
 [('Int', 'NNP'), ('J', 'NNP'), ('Innov', 'NNP'), ('Res', 'NNP'), ('Comp', 'NNP'), ('Commun', 'NNP'), ('Eng', 'NNP'), ('2014', 'CD'), (';', ':'), ('2', 'CD'), ('(', '('), ('8', 'CD'), (')', ')'), (':', ':'), ('5423–5432', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Int J Innov Res Comp Commun Eng']

>> Named Entities are: 
 [('ORGANIZATION', 'Int'), ('PERSON', 'Innov Res Comp Commun')] 

>> Stemming using Porter Stemmer: 
 [('Int', 'int'), ('J', 'j'), ('Innov', 'innov'), ('Res', 're'), ('Comp', 'comp'), ('Commun', 'commun'), ('Eng', 'eng'), ('2014', '2014'), (';', ';'), ('2', '2'), ('(', '('), ('8', '8'), (')', ')'), (':', ':'), ('5423–5432', '5423–5432'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Int', 'int'), ('J', 'j'), ('Innov', 'innov'), ('Res', 'res'), ('Comp', 'comp'), ('Commun', 'commun'), ('Eng', 'eng'), ('2014', '2014'), (';', ';'), ('2', '2'), ('(', '('), ('8', '8'), (')', ')'), (':', ':'), ('5423–5432', '5423–5432'), ('.', '.')]

>> Lemmatization: 
 [('Int', 'Int'), ('J', 'J'), ('Innov', 'Innov'), ('Res', 'Res'), ('Comp', 'Comp'), ('Commun', 'Commun'), ('Eng', 'Eng'), ('2014', '2014'), (';', ';'), ('2', '2'), ('(', '('), ('8', '8'), (')', ')'), (':', ':'), ('5423–5432', '5423–5432'), ('.', '.')]


------------------- Sentence 3 -------------------

124.

>> Tokens are: 
 ['124', '.']

>> Bigrams are: 
 [('124', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('124', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('124', '124'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('124', '124'), ('.', '.')]

>> Lemmatization: 
 [('124', '124'), ('.', '.')]


------------------- Sentence 4 -------------------

Bu Y, Borkar VR, Carey MJ, Rosen J, Polyzotis N, Condie T, Weimer M, Ramakrishnan R. Scaling datalog for machine

>> Tokens are: 
 ['Bu', 'Y', ',', 'Borkar', 'VR', ',', 'Carey', 'MJ', ',', 'Rosen', 'J', ',', 'Polyzotis', 'N', ',', 'Condie', 'T', ',', 'Weimer', 'M', ',', 'Ramakrishnan', 'R.', 'Scaling', 'datalog', 'machine']

>> Bigrams are: 
 [('Bu', 'Y'), ('Y', ','), (',', 'Borkar'), ('Borkar', 'VR'), ('VR', ','), (',', 'Carey'), ('Carey', 'MJ'), ('MJ', ','), (',', 'Rosen'), ('Rosen', 'J'), ('J', ','), (',', 'Polyzotis'), ('Polyzotis', 'N'), ('N', ','), (',', 'Condie'), ('Condie', 'T'), ('T', ','), (',', 'Weimer'), ('Weimer', 'M'), ('M', ','), (',', 'Ramakrishnan'), ('Ramakrishnan', 'R.'), ('R.', 'Scaling'), ('Scaling', 'datalog'), ('datalog', 'machine')]

>> Trigrams are: 
 [('Bu', 'Y', ','), ('Y', ',', 'Borkar'), (',', 'Borkar', 'VR'), ('Borkar', 'VR', ','), ('VR', ',', 'Carey'), (',', 'Carey', 'MJ'), ('Carey', 'MJ', ','), ('MJ', ',', 'Rosen'), (',', 'Rosen', 'J'), ('Rosen', 'J', ','), ('J', ',', 'Polyzotis'), (',', 'Polyzotis', 'N'), ('Polyzotis', 'N', ','), ('N', ',', 'Condie'), (',', 'Condie', 'T'), ('Condie', 'T', ','), ('T', ',', 'Weimer'), (',', 'Weimer', 'M'), ('Weimer', 'M', ','), ('M', ',', 'Ramakrishnan'), (',', 'Ramakrishnan', 'R.'), ('Ramakrishnan', 'R.', 'Scaling'), ('R.', 'Scaling', 'datalog'), ('Scaling', 'datalog', 'machine')]

>> POS Tags are: 
 [('Bu', 'NNP'), ('Y', 'NNP'), (',', ','), ('Borkar', 'NNP'), ('VR', 'NNP'), (',', ','), ('Carey', 'NNP'), ('MJ', 'NNP'), (',', ','), ('Rosen', 'NNP'), ('J', 'NNP'), (',', ','), ('Polyzotis', 'NNP'), ('N', 'NNP'), (',', ','), ('Condie', 'NNP'), ('T', 'NNP'), (',', ','), ('Weimer', 'NNP'), ('M', 'NNP'), (',', ','), ('Ramakrishnan', 'NNP'), ('R.', 'NNP'), ('Scaling', 'NNP'), ('datalog', 'NN'), ('machine', 'NN')]

>> Noun Phrases are: 
 ['Bu Y', 'Borkar VR', 'Carey MJ', 'Rosen J', 'Polyzotis N', 'Condie T', 'Weimer M', 'Ramakrishnan R. Scaling datalog machine']

>> Named Entities are: 
 [('PERSON', 'Borkar VR'), ('PERSON', 'Carey MJ'), ('PERSON', 'Rosen J'), ('PERSON', 'Polyzotis N'), ('PERSON', 'Condie T'), ('PERSON', 'Weimer M'), ('PERSON', 'Ramakrishnan R. Scaling')] 

>> Stemming using Porter Stemmer: 
 [('Bu', 'bu'), ('Y', 'y'), (',', ','), ('Borkar', 'borkar'), ('VR', 'vr'), (',', ','), ('Carey', 'carey'), ('MJ', 'mj'), (',', ','), ('Rosen', 'rosen'), ('J', 'j'), (',', ','), ('Polyzotis', 'polyzoti'), ('N', 'n'), (',', ','), ('Condie', 'condi'), ('T', 't'), (',', ','), ('Weimer', 'weimer'), ('M', 'm'), (',', ','), ('Ramakrishnan', 'ramakrishnan'), ('R.', 'r.'), ('Scaling', 'scale'), ('datalog', 'datalog'), ('machine', 'machin')]

>> Stemming using Snowball Stemmer: 
 [('Bu', 'bu'), ('Y', 'y'), (',', ','), ('Borkar', 'borkar'), ('VR', 'vr'), (',', ','), ('Carey', 'carey'), ('MJ', 'mj'), (',', ','), ('Rosen', 'rosen'), ('J', 'j'), (',', ','), ('Polyzotis', 'polyzoti'), ('N', 'n'), (',', ','), ('Condie', 'condi'), ('T', 't'), (',', ','), ('Weimer', 'weimer'), ('M', 'm'), (',', ','), ('Ramakrishnan', 'ramakrishnan'), ('R.', 'r.'), ('Scaling', 'scale'), ('datalog', 'datalog'), ('machine', 'machin')]

>> Lemmatization: 
 [('Bu', 'Bu'), ('Y', 'Y'), (',', ','), ('Borkar', 'Borkar'), ('VR', 'VR'), (',', ','), ('Carey', 'Carey'), ('MJ', 'MJ'), (',', ','), ('Rosen', 'Rosen'), ('J', 'J'), (',', ','), ('Polyzotis', 'Polyzotis'), ('N', 'N'), (',', ','), ('Condie', 'Condie'), ('T', 'T'), (',', ','), ('Weimer', 'Weimer'), ('M', 'M'), (',', ','), ('Ramakrishnan', 'Ramakrishnan'), ('R.', 'R.'), ('Scaling', 'Scaling'), ('datalog', 'datalog'), ('machine', 'machine')]



========================================== PARAGRAPH 515 ===========================================

learning on big data, CoRR, vol. abs/1203.0160, 2012. [Online]. Available: http://dblp.uni‑trier.de/db/journals/corr/ corr1203.html#abs‑1203‑0160. 

------------------- Sentence 1 -------------------

learning on big data, CoRR, vol.

>> Tokens are: 
 ['learning', 'big', 'data', ',', 'CoRR', ',', 'vol', '.']

>> Bigrams are: 
 [('learning', 'big'), ('big', 'data'), ('data', ','), (',', 'CoRR'), ('CoRR', ','), (',', 'vol'), ('vol', '.')]

>> Trigrams are: 
 [('learning', 'big', 'data'), ('big', 'data', ','), ('data', ',', 'CoRR'), (',', 'CoRR', ','), ('CoRR', ',', 'vol'), (',', 'vol', '.')]

>> POS Tags are: 
 [('learning', 'VBG'), ('big', 'JJ'), ('data', 'NNS'), (',', ','), ('CoRR', 'NNP'), (',', ','), ('vol', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['big data', 'CoRR', 'vol']

>> Named Entities are: 
 [('ORGANIZATION', 'CoRR')] 

>> Stemming using Porter Stemmer: 
 [('learning', 'learn'), ('big', 'big'), ('data', 'data'), (',', ','), ('CoRR', 'corr'), (',', ','), ('vol', 'vol'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('learning', 'learn'), ('big', 'big'), ('data', 'data'), (',', ','), ('CoRR', 'corr'), (',', ','), ('vol', 'vol'), ('.', '.')]

>> Lemmatization: 
 [('learning', 'learning'), ('big', 'big'), ('data', 'data'), (',', ','), ('CoRR', 'CoRR'), (',', ','), ('vol', 'vol'), ('.', '.')]


------------------- Sentence 2 -------------------

abs/1203.0160, 2012.

>> Tokens are: 
 ['abs/1203.0160', ',', '2012', '.']

>> Bigrams are: 
 [('abs/1203.0160', ','), (',', '2012'), ('2012', '.')]

>> Trigrams are: 
 [('abs/1203.0160', ',', '2012'), (',', '2012', '.')]

>> POS Tags are: 
 [('abs/1203.0160', 'NN'), (',', ','), ('2012', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['abs/1203.0160']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('abs/1203.0160', 'abs/1203.0160'), (',', ','), ('2012', '2012'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('abs/1203.0160', 'abs/1203.0160'), (',', ','), ('2012', '2012'), ('.', '.')]

>> Lemmatization: 
 [('abs/1203.0160', 'abs/1203.0160'), (',', ','), ('2012', '2012'), ('.', '.')]


------------------- Sentence 3 -------------------

[Online].

>> Tokens are: 
 ['[', 'Online', ']', '.']

>> Bigrams are: 
 [('[', 'Online'), ('Online', ']'), (']', '.')]

>> Trigrams are: 
 [('[', 'Online', ']'), ('Online', ']', '.')]

>> POS Tags are: 
 [('[', 'JJ'), ('Online', 'NNP'), (']', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['[ Online ]']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('Online', 'onlin'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('Online', 'onlin'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('Online', 'Online'), (']', ']'), ('.', '.')]


------------------- Sentence 4 -------------------

Available: http://dblp.uni‑trier.de/db/journals/corr/ corr1203.html#abs‑1203‑0160.

>> Tokens are: 
 ['Available', ':', 'http', ':', '//dblp.uni‑trier.de/db/journals/corr/', 'corr1203.html', '#', 'abs‑1203‑0160', '.']

>> Bigrams are: 
 [('Available', ':'), (':', 'http'), ('http', ':'), (':', '//dblp.uni‑trier.de/db/journals/corr/'), ('//dblp.uni‑trier.de/db/journals/corr/', 'corr1203.html'), ('corr1203.html', '#'), ('#', 'abs‑1203‑0160'), ('abs‑1203‑0160', '.')]

>> Trigrams are: 
 [('Available', ':', 'http'), (':', 'http', ':'), ('http', ':', '//dblp.uni‑trier.de/db/journals/corr/'), (':', '//dblp.uni‑trier.de/db/journals/corr/', 'corr1203.html'), ('//dblp.uni‑trier.de/db/journals/corr/', 'corr1203.html', '#'), ('corr1203.html', '#', 'abs‑1203‑0160'), ('#', 'abs‑1203‑0160', '.')]

>> POS Tags are: 
 [('Available', 'JJ'), (':', ':'), ('http', 'NN'), (':', ':'), ('//dblp.uni‑trier.de/db/journals/corr/', 'JJ'), ('corr1203.html', 'NN'), ('#', '#'), ('abs‑1203‑0160', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['http', '//dblp.uni‑trier.de/db/journals/corr/ corr1203.html', 'abs‑1203‑0160']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Available', 'avail'), (':', ':'), ('http', 'http'), (':', ':'), ('//dblp.uni‑trier.de/db/journals/corr/', '//dblp.uni‑trier.de/db/journals/corr/'), ('corr1203.html', 'corr1203.html'), ('#', '#'), ('abs‑1203‑0160', 'abs‑1203‑0160'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Available', 'avail'), (':', ':'), ('http', 'http'), (':', ':'), ('//dblp.uni‑trier.de/db/journals/corr/', '//dblp.uni‑trier.de/db/journals/corr/'), ('corr1203.html', 'corr1203.html'), ('#', '#'), ('abs‑1203‑0160', 'abs‑1203‑0160'), ('.', '.')]

>> Lemmatization: 
 [('Available', 'Available'), (':', ':'), ('http', 'http'), (':', ':'), ('//dblp.uni‑trier.de/db/journals/corr/', '//dblp.uni‑trier.de/db/journals/corr/'), ('corr1203.html', 'corr1203.html'), ('#', '#'), ('abs‑1203‑0160', 'abs‑1203‑0160'), ('.', '.')]



========================================== PARAGRAPH 516 ===========================================

 125. Malewicz G, Austern MH, Bik AJ, Dehnert JC, Horn I, Leiser N, Czajkowski G. Pregel: A system for large‑scale graph  processing. In: Proceedings of the ACM SIGMOD International Conference on Management of Data, 2010. pp  135–146. 

------------------- Sentence 1 -------------------

 125.

>> Tokens are: 
 ['125', '.']

>> Bigrams are: 
 [('125', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('125', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('125', '125'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('125', '125'), ('.', '.')]

>> Lemmatization: 
 [('125', '125'), ('.', '.')]


------------------- Sentence 2 -------------------

Malewicz G, Austern MH, Bik AJ, Dehnert JC, Horn I, Leiser N, Czajkowski G. Pregel: A system for large‑scale graph  processing.

>> Tokens are: 
 ['Malewicz', 'G', ',', 'Austern', 'MH', ',', 'Bik', 'AJ', ',', 'Dehnert', 'JC', ',', 'Horn', 'I', ',', 'Leiser', 'N', ',', 'Czajkowski', 'G.', 'Pregel', ':', 'A', 'system', 'large‑scale', 'graph', 'processing', '.']

>> Bigrams are: 
 [('Malewicz', 'G'), ('G', ','), (',', 'Austern'), ('Austern', 'MH'), ('MH', ','), (',', 'Bik'), ('Bik', 'AJ'), ('AJ', ','), (',', 'Dehnert'), ('Dehnert', 'JC'), ('JC', ','), (',', 'Horn'), ('Horn', 'I'), ('I', ','), (',', 'Leiser'), ('Leiser', 'N'), ('N', ','), (',', 'Czajkowski'), ('Czajkowski', 'G.'), ('G.', 'Pregel'), ('Pregel', ':'), (':', 'A'), ('A', 'system'), ('system', 'large‑scale'), ('large‑scale', 'graph'), ('graph', 'processing'), ('processing', '.')]

>> Trigrams are: 
 [('Malewicz', 'G', ','), ('G', ',', 'Austern'), (',', 'Austern', 'MH'), ('Austern', 'MH', ','), ('MH', ',', 'Bik'), (',', 'Bik', 'AJ'), ('Bik', 'AJ', ','), ('AJ', ',', 'Dehnert'), (',', 'Dehnert', 'JC'), ('Dehnert', 'JC', ','), ('JC', ',', 'Horn'), (',', 'Horn', 'I'), ('Horn', 'I', ','), ('I', ',', 'Leiser'), (',', 'Leiser', 'N'), ('Leiser', 'N', ','), ('N', ',', 'Czajkowski'), (',', 'Czajkowski', 'G.'), ('Czajkowski', 'G.', 'Pregel'), ('G.', 'Pregel', ':'), ('Pregel', ':', 'A'), (':', 'A', 'system'), ('A', 'system', 'large‑scale'), ('system', 'large‑scale', 'graph'), ('large‑scale', 'graph', 'processing'), ('graph', 'processing', '.')]

>> POS Tags are: 
 [('Malewicz', 'NNP'), ('G', 'NNP'), (',', ','), ('Austern', 'NNP'), ('MH', 'NNP'), (',', ','), ('Bik', 'NNP'), ('AJ', 'NNP'), (',', ','), ('Dehnert', 'NNP'), ('JC', 'NNP'), (',', ','), ('Horn', 'NNP'), ('I', 'PRP'), (',', ','), ('Leiser', 'NNP'), ('N', 'NNP'), (',', ','), ('Czajkowski', 'NNP'), ('G.', 'NNP'), ('Pregel', 'NNP'), (':', ':'), ('A', 'DT'), ('system', 'NN'), ('large‑scale', 'JJ'), ('graph', 'NN'), ('processing', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Malewicz G', 'Austern MH', 'Bik AJ', 'Dehnert JC', 'Horn', 'Leiser N', 'Czajkowski G. Pregel', 'A system', 'large‑scale graph processing']

>> Named Entities are: 
 [('PERSON', 'Malewicz'), ('ORGANIZATION', 'G'), ('PERSON', 'Austern MH'), ('PERSON', 'Bik AJ'), ('PERSON', 'Dehnert JC'), ('PERSON', 'Leiser N'), ('PERSON', 'Czajkowski G.')] 

>> Stemming using Porter Stemmer: 
 [('Malewicz', 'malewicz'), ('G', 'g'), (',', ','), ('Austern', 'austern'), ('MH', 'mh'), (',', ','), ('Bik', 'bik'), ('AJ', 'aj'), (',', ','), ('Dehnert', 'dehnert'), ('JC', 'jc'), (',', ','), ('Horn', 'horn'), ('I', 'i'), (',', ','), ('Leiser', 'leiser'), ('N', 'n'), (',', ','), ('Czajkowski', 'czajkowski'), ('G.', 'g.'), ('Pregel', 'pregel'), (':', ':'), ('A', 'a'), ('system', 'system'), ('large‑scale', 'large‑scal'), ('graph', 'graph'), ('processing', 'process'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Malewicz', 'malewicz'), ('G', 'g'), (',', ','), ('Austern', 'austern'), ('MH', 'mh'), (',', ','), ('Bik', 'bik'), ('AJ', 'aj'), (',', ','), ('Dehnert', 'dehnert'), ('JC', 'jc'), (',', ','), ('Horn', 'horn'), ('I', 'i'), (',', ','), ('Leiser', 'leiser'), ('N', 'n'), (',', ','), ('Czajkowski', 'czajkowski'), ('G.', 'g.'), ('Pregel', 'pregel'), (':', ':'), ('A', 'a'), ('system', 'system'), ('large‑scale', 'large‑scal'), ('graph', 'graph'), ('processing', 'process'), ('.', '.')]

>> Lemmatization: 
 [('Malewicz', 'Malewicz'), ('G', 'G'), (',', ','), ('Austern', 'Austern'), ('MH', 'MH'), (',', ','), ('Bik', 'Bik'), ('AJ', 'AJ'), (',', ','), ('Dehnert', 'Dehnert'), ('JC', 'JC'), (',', ','), ('Horn', 'Horn'), ('I', 'I'), (',', ','), ('Leiser', 'Leiser'), ('N', 'N'), (',', ','), ('Czajkowski', 'Czajkowski'), ('G.', 'G.'), ('Pregel', 'Pregel'), (':', ':'), ('A', 'A'), ('system', 'system'), ('large‑scale', 'large‑scale'), ('graph', 'graph'), ('processing', 'processing'), ('.', '.')]


------------------- Sentence 3 -------------------

In: Proceedings of the ACM SIGMOD International Conference on Management of Data, 2010. pp  135–146.

>> Tokens are: 
 ['In', ':', 'Proceedings', 'ACM', 'SIGMOD', 'International', 'Conference', 'Management', 'Data', ',', '2010.', 'pp', '135–146', '.']

>> Bigrams are: 
 [('In', ':'), (':', 'Proceedings'), ('Proceedings', 'ACM'), ('ACM', 'SIGMOD'), ('SIGMOD', 'International'), ('International', 'Conference'), ('Conference', 'Management'), ('Management', 'Data'), ('Data', ','), (',', '2010.'), ('2010.', 'pp'), ('pp', '135–146'), ('135–146', '.')]

>> Trigrams are: 
 [('In', ':', 'Proceedings'), (':', 'Proceedings', 'ACM'), ('Proceedings', 'ACM', 'SIGMOD'), ('ACM', 'SIGMOD', 'International'), ('SIGMOD', 'International', 'Conference'), ('International', 'Conference', 'Management'), ('Conference', 'Management', 'Data'), ('Management', 'Data', ','), ('Data', ',', '2010.'), (',', '2010.', 'pp'), ('2010.', 'pp', '135–146'), ('pp', '135–146', '.')]

>> POS Tags are: 
 [('In', 'IN'), (':', ':'), ('Proceedings', 'NNS'), ('ACM', 'NNP'), ('SIGMOD', 'NNP'), ('International', 'NNP'), ('Conference', 'NNP'), ('Management', 'NNP'), ('Data', 'NNP'), (',', ','), ('2010.', 'CD'), ('pp', 'NN'), ('135–146', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Proceedings ACM SIGMOD International Conference Management Data', 'pp']

>> Named Entities are: 
 [('ORGANIZATION', 'ACM'), ('ORGANIZATION', 'SIGMOD International Conference Management Data')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), (':', ':'), ('Proceedings', 'proceed'), ('ACM', 'acm'), ('SIGMOD', 'sigmod'), ('International', 'intern'), ('Conference', 'confer'), ('Management', 'manag'), ('Data', 'data'), (',', ','), ('2010.', '2010.'), ('pp', 'pp'), ('135–146', '135–146'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), (':', ':'), ('Proceedings', 'proceed'), ('ACM', 'acm'), ('SIGMOD', 'sigmod'), ('International', 'intern'), ('Conference', 'confer'), ('Management', 'manag'), ('Data', 'data'), (',', ','), ('2010.', '2010.'), ('pp', 'pp'), ('135–146', '135–146'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), (':', ':'), ('Proceedings', 'Proceedings'), ('ACM', 'ACM'), ('SIGMOD', 'SIGMOD'), ('International', 'International'), ('Conference', 'Conference'), ('Management', 'Management'), ('Data', 'Data'), (',', ','), ('2010.', '2010.'), ('pp', 'pp'), ('135–146', '135–146'), ('.', '.')]



========================================== PARAGRAPH 517 ===========================================

 126. Hasan S, Shamsuddin S,  Lopes N. Soft computing methods for big data problems. In: Proceedings of the Sympo‑ sium on GPU Computing and Applications, 2013. pp 235–247. 

------------------- Sentence 1 -------------------

 126.

>> Tokens are: 
 ['126', '.']

>> Bigrams are: 
 [('126', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('126', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('126', '126'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('126', '126'), ('.', '.')]

>> Lemmatization: 
 [('126', '126'), ('.', '.')]


------------------- Sentence 2 -------------------

Hasan S, Shamsuddin S,  Lopes N. Soft computing methods for big data problems.

>> Tokens are: 
 ['Hasan', 'S', ',', 'Shamsuddin', 'S', ',', 'Lopes', 'N.', 'Soft', 'computing', 'methods', 'big', 'data', 'problems', '.']

>> Bigrams are: 
 [('Hasan', 'S'), ('S', ','), (',', 'Shamsuddin'), ('Shamsuddin', 'S'), ('S', ','), (',', 'Lopes'), ('Lopes', 'N.'), ('N.', 'Soft'), ('Soft', 'computing'), ('computing', 'methods'), ('methods', 'big'), ('big', 'data'), ('data', 'problems'), ('problems', '.')]

>> Trigrams are: 
 [('Hasan', 'S', ','), ('S', ',', 'Shamsuddin'), (',', 'Shamsuddin', 'S'), ('Shamsuddin', 'S', ','), ('S', ',', 'Lopes'), (',', 'Lopes', 'N.'), ('Lopes', 'N.', 'Soft'), ('N.', 'Soft', 'computing'), ('Soft', 'computing', 'methods'), ('computing', 'methods', 'big'), ('methods', 'big', 'data'), ('big', 'data', 'problems'), ('data', 'problems', '.')]

>> POS Tags are: 
 [('Hasan', 'NNP'), ('S', 'NNP'), (',', ','), ('Shamsuddin', 'NNP'), ('S', 'NNP'), (',', ','), ('Lopes', 'NNP'), ('N.', 'NNP'), ('Soft', 'NNP'), ('computing', 'VBG'), ('methods', 'NNS'), ('big', 'JJ'), ('data', 'NNS'), ('problems', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['Hasan S', 'Shamsuddin S', 'Lopes N. Soft', 'methods', 'big data problems']

>> Named Entities are: 
 [('PERSON', 'Hasan'), ('ORGANIZATION', 'S'), ('PERSON', 'Shamsuddin S'), ('PERSON', 'Lopes N. Soft')] 

>> Stemming using Porter Stemmer: 
 [('Hasan', 'hasan'), ('S', 's'), (',', ','), ('Shamsuddin', 'shamsuddin'), ('S', 's'), (',', ','), ('Lopes', 'lope'), ('N.', 'n.'), ('Soft', 'soft'), ('computing', 'comput'), ('methods', 'method'), ('big', 'big'), ('data', 'data'), ('problems', 'problem'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Hasan', 'hasan'), ('S', 's'), (',', ','), ('Shamsuddin', 'shamsuddin'), ('S', 's'), (',', ','), ('Lopes', 'lope'), ('N.', 'n.'), ('Soft', 'soft'), ('computing', 'comput'), ('methods', 'method'), ('big', 'big'), ('data', 'data'), ('problems', 'problem'), ('.', '.')]

>> Lemmatization: 
 [('Hasan', 'Hasan'), ('S', 'S'), (',', ','), ('Shamsuddin', 'Shamsuddin'), ('S', 'S'), (',', ','), ('Lopes', 'Lopes'), ('N.', 'N.'), ('Soft', 'Soft'), ('computing', 'computing'), ('methods', 'method'), ('big', 'big'), ('data', 'data'), ('problems', 'problem'), ('.', '.')]


------------------- Sentence 3 -------------------

In: Proceedings of the Sympo‑ sium on GPU Computing and Applications, 2013. pp 235–247.

>> Tokens are: 
 ['In', ':', 'Proceedings', 'Sympo‑', 'sium', 'GPU', 'Computing', 'Applications', ',', '2013.', 'pp', '235–247', '.']

>> Bigrams are: 
 [('In', ':'), (':', 'Proceedings'), ('Proceedings', 'Sympo‑'), ('Sympo‑', 'sium'), ('sium', 'GPU'), ('GPU', 'Computing'), ('Computing', 'Applications'), ('Applications', ','), (',', '2013.'), ('2013.', 'pp'), ('pp', '235–247'), ('235–247', '.')]

>> Trigrams are: 
 [('In', ':', 'Proceedings'), (':', 'Proceedings', 'Sympo‑'), ('Proceedings', 'Sympo‑', 'sium'), ('Sympo‑', 'sium', 'GPU'), ('sium', 'GPU', 'Computing'), ('GPU', 'Computing', 'Applications'), ('Computing', 'Applications', ','), ('Applications', ',', '2013.'), (',', '2013.', 'pp'), ('2013.', 'pp', '235–247'), ('pp', '235–247', '.')]

>> POS Tags are: 
 [('In', 'IN'), (':', ':'), ('Proceedings', 'NNS'), ('Sympo‑', 'NNP'), ('sium', 'NN'), ('GPU', 'NNP'), ('Computing', 'NNP'), ('Applications', 'NNP'), (',', ','), ('2013.', 'CD'), ('pp', 'NN'), ('235–247', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Proceedings Sympo‑ sium GPU Computing Applications', 'pp']

>> Named Entities are: 
 [('ORGANIZATION', 'GPU')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), (':', ':'), ('Proceedings', 'proceed'), ('Sympo‑', 'sympo‑'), ('sium', 'sium'), ('GPU', 'gpu'), ('Computing', 'comput'), ('Applications', 'applic'), (',', ','), ('2013.', '2013.'), ('pp', 'pp'), ('235–247', '235–247'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), (':', ':'), ('Proceedings', 'proceed'), ('Sympo‑', 'sympo‑'), ('sium', 'sium'), ('GPU', 'gpu'), ('Computing', 'comput'), ('Applications', 'applic'), (',', ','), ('2013.', '2013.'), ('pp', 'pp'), ('235–247', '235–247'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), (':', ':'), ('Proceedings', 'Proceedings'), ('Sympo‑', 'Sympo‑'), ('sium', 'sium'), ('GPU', 'GPU'), ('Computing', 'Computing'), ('Applications', 'Applications'), (',', ','), ('2013.', '2013.'), ('pp', 'pp'), ('235–247', '235–247'), ('.', '.')]



========================================== PARAGRAPH 518 ===========================================

 127. Ku‑Mahamud KR. Big data clustering using grid computing and ant‑based algorithm. In: Proceedings of the Inter‑ national Conference on Computing and Informatics, 2013. pp 6–14. 

------------------- Sentence 1 -------------------

 127.

>> Tokens are: 
 ['127', '.']

>> Bigrams are: 
 [('127', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('127', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('127', '127'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('127', '127'), ('.', '.')]

>> Lemmatization: 
 [('127', '127'), ('.', '.')]


------------------- Sentence 2 -------------------

Ku‑Mahamud KR.

>> Tokens are: 
 ['Ku‑Mahamud', 'KR', '.']

>> Bigrams are: 
 [('Ku‑Mahamud', 'KR'), ('KR', '.')]

>> Trigrams are: 
 [('Ku‑Mahamud', 'KR', '.')]

>> POS Tags are: 
 [('Ku‑Mahamud', 'NNP'), ('KR', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Ku‑Mahamud KR']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Ku‑Mahamud', 'ku‑mahamud'), ('KR', 'kr'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Ku‑Mahamud', 'ku‑mahamud'), ('KR', 'kr'), ('.', '.')]

>> Lemmatization: 
 [('Ku‑Mahamud', 'Ku‑Mahamud'), ('KR', 'KR'), ('.', '.')]


------------------- Sentence 3 -------------------

Big data clustering using grid computing and ant‑based algorithm.

>> Tokens are: 
 ['Big', 'data', 'clustering', 'using', 'grid', 'computing', 'ant‑based', 'algorithm', '.']

>> Bigrams are: 
 [('Big', 'data'), ('data', 'clustering'), ('clustering', 'using'), ('using', 'grid'), ('grid', 'computing'), ('computing', 'ant‑based'), ('ant‑based', 'algorithm'), ('algorithm', '.')]

>> Trigrams are: 
 [('Big', 'data', 'clustering'), ('data', 'clustering', 'using'), ('clustering', 'using', 'grid'), ('using', 'grid', 'computing'), ('grid', 'computing', 'ant‑based'), ('computing', 'ant‑based', 'algorithm'), ('ant‑based', 'algorithm', '.')]

>> POS Tags are: 
 [('Big', 'NNP'), ('data', 'NNS'), ('clustering', 'VBG'), ('using', 'VBG'), ('grid', 'JJ'), ('computing', 'VBG'), ('ant‑based', 'JJ'), ('algorithm', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Big data', 'ant‑based algorithm']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('clustering', 'cluster'), ('using', 'use'), ('grid', 'grid'), ('computing', 'comput'), ('ant‑based', 'ant‑bas'), ('algorithm', 'algorithm'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('clustering', 'cluster'), ('using', 'use'), ('grid', 'grid'), ('computing', 'comput'), ('ant‑based', 'ant‑bas'), ('algorithm', 'algorithm'), ('.', '.')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), ('clustering', 'clustering'), ('using', 'using'), ('grid', 'grid'), ('computing', 'computing'), ('ant‑based', 'ant‑based'), ('algorithm', 'algorithm'), ('.', '.')]


------------------- Sentence 4 -------------------

In: Proceedings of the Inter‑ national Conference on Computing and Informatics, 2013. pp 6–14.

>> Tokens are: 
 ['In', ':', 'Proceedings', 'Inter‑', 'national', 'Conference', 'Computing', 'Informatics', ',', '2013.', 'pp', '6–14', '.']

>> Bigrams are: 
 [('In', ':'), (':', 'Proceedings'), ('Proceedings', 'Inter‑'), ('Inter‑', 'national'), ('national', 'Conference'), ('Conference', 'Computing'), ('Computing', 'Informatics'), ('Informatics', ','), (',', '2013.'), ('2013.', 'pp'), ('pp', '6–14'), ('6–14', '.')]

>> Trigrams are: 
 [('In', ':', 'Proceedings'), (':', 'Proceedings', 'Inter‑'), ('Proceedings', 'Inter‑', 'national'), ('Inter‑', 'national', 'Conference'), ('national', 'Conference', 'Computing'), ('Conference', 'Computing', 'Informatics'), ('Computing', 'Informatics', ','), ('Informatics', ',', '2013.'), (',', '2013.', 'pp'), ('2013.', 'pp', '6–14'), ('pp', '6–14', '.')]

>> POS Tags are: 
 [('In', 'IN'), (':', ':'), ('Proceedings', 'NNS'), ('Inter‑', 'NNP'), ('national', 'JJ'), ('Conference', 'NNP'), ('Computing', 'NNP'), ('Informatics', 'NNP'), (',', ','), ('2013.', 'CD'), ('pp', 'NN'), ('6–14', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Proceedings Inter‑', 'national Conference Computing Informatics', 'pp']

>> Named Entities are: 
 [('ORGANIZATION', 'Conference')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), (':', ':'), ('Proceedings', 'proceed'), ('Inter‑', 'inter‑'), ('national', 'nation'), ('Conference', 'confer'), ('Computing', 'comput'), ('Informatics', 'informat'), (',', ','), ('2013.', '2013.'), ('pp', 'pp'), ('6–14', '6–14'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), (':', ':'), ('Proceedings', 'proceed'), ('Inter‑', 'inter‑'), ('national', 'nation'), ('Conference', 'confer'), ('Computing', 'comput'), ('Informatics', 'informat'), (',', ','), ('2013.', '2013.'), ('pp', 'pp'), ('6–14', '6–14'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), (':', ':'), ('Proceedings', 'Proceedings'), ('Inter‑', 'Inter‑'), ('national', 'national'), ('Conference', 'Conference'), ('Computing', 'Computing'), ('Informatics', 'Informatics'), (',', ','), ('2013.', '2013.'), ('pp', 'pp'), ('6–14', '6–14'), ('.', '.')]



========================================== PARAGRAPH 519 ===========================================

 128. Deneubourg JL, Goss S, Franks N, Sendova‑Franks A, Detrain C, Chrétien L. The dynamics of collective sorting  robot‑like ants and ant‑like robots. In: Proceedings of the International Conference on Simulation of Adaptive  Behavior on From Animals to Animats, 1990. pp 356–363. 

------------------- Sentence 1 -------------------

 128.

>> Tokens are: 
 ['128', '.']

>> Bigrams are: 
 [('128', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('128', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('128', '128'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('128', '128'), ('.', '.')]

>> Lemmatization: 
 [('128', '128'), ('.', '.')]


------------------- Sentence 2 -------------------

Deneubourg JL, Goss S, Franks N, Sendova‑Franks A, Detrain C, Chrétien L. The dynamics of collective sorting  robot‑like ants and ant‑like robots.

>> Tokens are: 
 ['Deneubourg', 'JL', ',', 'Goss', 'S', ',', 'Franks', 'N', ',', 'Sendova‑Franks', 'A', ',', 'Detrain', 'C', ',', 'Chrétien', 'L.', 'The', 'dynamics', 'collective', 'sorting', 'robot‑like', 'ants', 'ant‑like', 'robots', '.']

>> Bigrams are: 
 [('Deneubourg', 'JL'), ('JL', ','), (',', 'Goss'), ('Goss', 'S'), ('S', ','), (',', 'Franks'), ('Franks', 'N'), ('N', ','), (',', 'Sendova‑Franks'), ('Sendova‑Franks', 'A'), ('A', ','), (',', 'Detrain'), ('Detrain', 'C'), ('C', ','), (',', 'Chrétien'), ('Chrétien', 'L.'), ('L.', 'The'), ('The', 'dynamics'), ('dynamics', 'collective'), ('collective', 'sorting'), ('sorting', 'robot‑like'), ('robot‑like', 'ants'), ('ants', 'ant‑like'), ('ant‑like', 'robots'), ('robots', '.')]

>> Trigrams are: 
 [('Deneubourg', 'JL', ','), ('JL', ',', 'Goss'), (',', 'Goss', 'S'), ('Goss', 'S', ','), ('S', ',', 'Franks'), (',', 'Franks', 'N'), ('Franks', 'N', ','), ('N', ',', 'Sendova‑Franks'), (',', 'Sendova‑Franks', 'A'), ('Sendova‑Franks', 'A', ','), ('A', ',', 'Detrain'), (',', 'Detrain', 'C'), ('Detrain', 'C', ','), ('C', ',', 'Chrétien'), (',', 'Chrétien', 'L.'), ('Chrétien', 'L.', 'The'), ('L.', 'The', 'dynamics'), ('The', 'dynamics', 'collective'), ('dynamics', 'collective', 'sorting'), ('collective', 'sorting', 'robot‑like'), ('sorting', 'robot‑like', 'ants'), ('robot‑like', 'ants', 'ant‑like'), ('ants', 'ant‑like', 'robots'), ('ant‑like', 'robots', '.')]

>> POS Tags are: 
 [('Deneubourg', 'NNP'), ('JL', 'NNP'), (',', ','), ('Goss', 'NNP'), ('S', 'NNP'), (',', ','), ('Franks', 'NNP'), ('N', 'NNP'), (',', ','), ('Sendova‑Franks', 'NNP'), ('A', 'NNP'), (',', ','), ('Detrain', 'NNP'), ('C', 'NNP'), (',', ','), ('Chrétien', 'NNP'), ('L.', 'NNP'), ('The', 'DT'), ('dynamics', 'NNS'), ('collective', 'JJ'), ('sorting', 'VBG'), ('robot‑like', 'NN'), ('ants', 'NNS'), ('ant‑like', 'IN'), ('robots', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['Deneubourg JL', 'Goss S', 'Franks N', 'Sendova‑Franks A', 'Detrain C', 'Chrétien L.', 'The dynamics', 'robot‑like ants', 'robots']

>> Named Entities are: 
 [('PERSON', 'Deneubourg'), ('GPE', 'JL'), ('PERSON', 'Goss S'), ('PERSON', 'Franks N'), ('PERSON', 'Detrain C'), ('PERSON', 'Chrétien')] 

>> Stemming using Porter Stemmer: 
 [('Deneubourg', 'deneubourg'), ('JL', 'jl'), (',', ','), ('Goss', 'goss'), ('S', 's'), (',', ','), ('Franks', 'frank'), ('N', 'n'), (',', ','), ('Sendova‑Franks', 'sendova‑frank'), ('A', 'a'), (',', ','), ('Detrain', 'detrain'), ('C', 'c'), (',', ','), ('Chrétien', 'chrétien'), ('L.', 'l.'), ('The', 'the'), ('dynamics', 'dynam'), ('collective', 'collect'), ('sorting', 'sort'), ('robot‑like', 'robot‑lik'), ('ants', 'ant'), ('ant‑like', 'ant‑lik'), ('robots', 'robot'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Deneubourg', 'deneubourg'), ('JL', 'jl'), (',', ','), ('Goss', 'goss'), ('S', 's'), (',', ','), ('Franks', 'frank'), ('N', 'n'), (',', ','), ('Sendova‑Franks', 'sendova‑frank'), ('A', 'a'), (',', ','), ('Detrain', 'detrain'), ('C', 'c'), (',', ','), ('Chrétien', 'chrétien'), ('L.', 'l.'), ('The', 'the'), ('dynamics', 'dynam'), ('collective', 'collect'), ('sorting', 'sort'), ('robot‑like', 'robot‑lik'), ('ants', 'ant'), ('ant‑like', 'ant‑lik'), ('robots', 'robot'), ('.', '.')]

>> Lemmatization: 
 [('Deneubourg', 'Deneubourg'), ('JL', 'JL'), (',', ','), ('Goss', 'Goss'), ('S', 'S'), (',', ','), ('Franks', 'Franks'), ('N', 'N'), (',', ','), ('Sendova‑Franks', 'Sendova‑Franks'), ('A', 'A'), (',', ','), ('Detrain', 'Detrain'), ('C', 'C'), (',', ','), ('Chrétien', 'Chrétien'), ('L.', 'L.'), ('The', 'The'), ('dynamics', 'dynamic'), ('collective', 'collective'), ('sorting', 'sorting'), ('robot‑like', 'robot‑like'), ('ants', 'ant'), ('ant‑like', 'ant‑like'), ('robots', 'robot'), ('.', '.')]


------------------- Sentence 3 -------------------

In: Proceedings of the International Conference on Simulation of Adaptive  Behavior on From Animals to Animats, 1990. pp 356–363.

>> Tokens are: 
 ['In', ':', 'Proceedings', 'International', 'Conference', 'Simulation', 'Adaptive', 'Behavior', 'From', 'Animals', 'Animats', ',', '1990.', 'pp', '356–363', '.']

>> Bigrams are: 
 [('In', ':'), (':', 'Proceedings'), ('Proceedings', 'International'), ('International', 'Conference'), ('Conference', 'Simulation'), ('Simulation', 'Adaptive'), ('Adaptive', 'Behavior'), ('Behavior', 'From'), ('From', 'Animals'), ('Animals', 'Animats'), ('Animats', ','), (',', '1990.'), ('1990.', 'pp'), ('pp', '356–363'), ('356–363', '.')]

>> Trigrams are: 
 [('In', ':', 'Proceedings'), (':', 'Proceedings', 'International'), ('Proceedings', 'International', 'Conference'), ('International', 'Conference', 'Simulation'), ('Conference', 'Simulation', 'Adaptive'), ('Simulation', 'Adaptive', 'Behavior'), ('Adaptive', 'Behavior', 'From'), ('Behavior', 'From', 'Animals'), ('From', 'Animals', 'Animats'), ('Animals', 'Animats', ','), ('Animats', ',', '1990.'), (',', '1990.', 'pp'), ('1990.', 'pp', '356–363'), ('pp', '356–363', '.')]

>> POS Tags are: 
 [('In', 'IN'), (':', ':'), ('Proceedings', 'NNS'), ('International', 'NNP'), ('Conference', 'NNP'), ('Simulation', 'NNP'), ('Adaptive', 'NNP'), ('Behavior', 'NNP'), ('From', 'NNP'), ('Animals', 'NNP'), ('Animats', 'NNP'), (',', ','), ('1990.', 'CD'), ('pp', 'NN'), ('356–363', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Proceedings International Conference Simulation Adaptive Behavior From Animals Animats', 'pp']

>> Named Entities are: 
 [('ORGANIZATION', 'International Conference Simulation Adaptive Behavior'), ('PERSON', 'Animals Animats')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), (':', ':'), ('Proceedings', 'proceed'), ('International', 'intern'), ('Conference', 'confer'), ('Simulation', 'simul'), ('Adaptive', 'adapt'), ('Behavior', 'behavior'), ('From', 'from'), ('Animals', 'anim'), ('Animats', 'animat'), (',', ','), ('1990.', '1990.'), ('pp', 'pp'), ('356–363', '356–363'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), (':', ':'), ('Proceedings', 'proceed'), ('International', 'intern'), ('Conference', 'confer'), ('Simulation', 'simul'), ('Adaptive', 'adapt'), ('Behavior', 'behavior'), ('From', 'from'), ('Animals', 'anim'), ('Animats', 'animat'), (',', ','), ('1990.', '1990.'), ('pp', 'pp'), ('356–363', '356–363'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), (':', ':'), ('Proceedings', 'Proceedings'), ('International', 'International'), ('Conference', 'Conference'), ('Simulation', 'Simulation'), ('Adaptive', 'Adaptive'), ('Behavior', 'Behavior'), ('From', 'From'), ('Animals', 'Animals'), ('Animats', 'Animats'), (',', ','), ('1990.', '1990.'), ('pp', 'pp'), ('356–363', '356–363'), ('.', '.')]



========================================== PARAGRAPH 520 ===========================================

 129. Radoop [Online]. https://rapidminer.com/products/radoop/. Accessed 2 Feb 2015.  130. PigMix [Online]. https://cwiki.apache.org/confluence/display/PIG/PigMix. Accessed 2 Feb 2015.  131. GridMix [Online]. http://hadoop.apache.org/docs/r1.2.1/gridmix.html. Accessed 2 Feb 2015.  132. TeraSoft [Online]. http://sortbenchmark.org/. Accessed 2 Feb 2015.  133. TPC, transaction processing performance council [Online]. http://www.tpc.org/. Accessed 2 Feb 2015.  134. Cooper BF, Silberstein A, Tam E, Ramakrishnan R, Sears R. Benchmarking cloud serving systems with ycsb. In:  

------------------- Sentence 1 -------------------

 129.

>> Tokens are: 
 ['129', '.']

>> Bigrams are: 
 [('129', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('129', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('129', '129'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('129', '129'), ('.', '.')]

>> Lemmatization: 
 [('129', '129'), ('.', '.')]


------------------- Sentence 2 -------------------

Radoop [Online].

>> Tokens are: 
 ['Radoop', '[', 'Online', ']', '.']

>> Bigrams are: 
 [('Radoop', '['), ('[', 'Online'), ('Online', ']'), (']', '.')]

>> Trigrams are: 
 [('Radoop', '[', 'Online'), ('[', 'Online', ']'), ('Online', ']', '.')]

>> POS Tags are: 
 [('Radoop', 'NNP'), ('[', 'NNP'), ('Online', 'NNP'), (']', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Radoop [ Online ]']

>> Named Entities are: 
 [('PERSON', 'Radoop'), ('PERSON', 'Online')] 

>> Stemming using Porter Stemmer: 
 [('Radoop', 'radoop'), ('[', '['), ('Online', 'onlin'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Radoop', 'radoop'), ('[', '['), ('Online', 'onlin'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('Radoop', 'Radoop'), ('[', '['), ('Online', 'Online'), (']', ']'), ('.', '.')]


------------------- Sentence 3 -------------------

https://rapidminer.com/products/radoop/.

>> Tokens are: 
 ['https', ':', '//rapidminer.com/products/radoop/', '.']

>> Bigrams are: 
 [('https', ':'), (':', '//rapidminer.com/products/radoop/'), ('//rapidminer.com/products/radoop/', '.')]

>> Trigrams are: 
 [('https', ':', '//rapidminer.com/products/radoop/'), (':', '//rapidminer.com/products/radoop/', '.')]

>> POS Tags are: 
 [('https', 'NN'), (':', ':'), ('//rapidminer.com/products/radoop/', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['https', '//rapidminer.com/products/radoop/']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('https', 'http'), (':', ':'), ('//rapidminer.com/products/radoop/', '//rapidminer.com/products/radoop/'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('https', 'https'), (':', ':'), ('//rapidminer.com/products/radoop/', '//rapidminer.com/products/radoop/'), ('.', '.')]

>> Lemmatization: 
 [('https', 'http'), (':', ':'), ('//rapidminer.com/products/radoop/', '//rapidminer.com/products/radoop/'), ('.', '.')]


------------------- Sentence 4 -------------------

Accessed 2 Feb 2015.

>> Tokens are: 
 ['Accessed', '2', 'Feb', '2015', '.']

>> Bigrams are: 
 [('Accessed', '2'), ('2', 'Feb'), ('Feb', '2015'), ('2015', '.')]

>> Trigrams are: 
 [('Accessed', '2', 'Feb'), ('2', 'Feb', '2015'), ('Feb', '2015', '.')]

>> POS Tags are: 
 [('Accessed', 'JJ'), ('2', 'CD'), ('Feb', 'NNP'), ('2015', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Feb']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Accessed', 'access'), ('2', '2'), ('Feb', 'feb'), ('2015', '2015'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Accessed', 'access'), ('2', '2'), ('Feb', 'feb'), ('2015', '2015'), ('.', '.')]

>> Lemmatization: 
 [('Accessed', 'Accessed'), ('2', '2'), ('Feb', 'Feb'), ('2015', '2015'), ('.', '.')]


------------------- Sentence 5 -------------------

130.

>> Tokens are: 
 ['130', '.']

>> Bigrams are: 
 [('130', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('130', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('130', '130'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('130', '130'), ('.', '.')]

>> Lemmatization: 
 [('130', '130'), ('.', '.')]


------------------- Sentence 6 -------------------

PigMix [Online].

>> Tokens are: 
 ['PigMix', '[', 'Online', ']', '.']

>> Bigrams are: 
 [('PigMix', '['), ('[', 'Online'), ('Online', ']'), (']', '.')]

>> Trigrams are: 
 [('PigMix', '[', 'Online'), ('[', 'Online', ']'), ('Online', ']', '.')]

>> POS Tags are: 
 [('PigMix', 'NNP'), ('[', 'NNP'), ('Online', 'NNP'), (']', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['PigMix [ Online ]']

>> Named Entities are: 
 [('ORGANIZATION', 'PigMix'), ('PERSON', 'Online')] 

>> Stemming using Porter Stemmer: 
 [('PigMix', 'pigmix'), ('[', '['), ('Online', 'onlin'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('PigMix', 'pigmix'), ('[', '['), ('Online', 'onlin'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('PigMix', 'PigMix'), ('[', '['), ('Online', 'Online'), (']', ']'), ('.', '.')]


------------------- Sentence 7 -------------------

https://cwiki.apache.org/confluence/display/PIG/PigMix.

>> Tokens are: 
 ['https', ':', '//cwiki.apache.org/confluence/display/PIG/PigMix', '.']

>> Bigrams are: 
 [('https', ':'), (':', '//cwiki.apache.org/confluence/display/PIG/PigMix'), ('//cwiki.apache.org/confluence/display/PIG/PigMix', '.')]

>> Trigrams are: 
 [('https', ':', '//cwiki.apache.org/confluence/display/PIG/PigMix'), (':', '//cwiki.apache.org/confluence/display/PIG/PigMix', '.')]

>> POS Tags are: 
 [('https', 'NN'), (':', ':'), ('//cwiki.apache.org/confluence/display/PIG/PigMix', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['https', '//cwiki.apache.org/confluence/display/PIG/PigMix']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('https', 'http'), (':', ':'), ('//cwiki.apache.org/confluence/display/PIG/PigMix', '//cwiki.apache.org/confluence/display/pig/pigmix'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('https', 'https'), (':', ':'), ('//cwiki.apache.org/confluence/display/PIG/PigMix', '//cwiki.apache.org/confluence/display/pig/pigmix'), ('.', '.')]

>> Lemmatization: 
 [('https', 'http'), (':', ':'), ('//cwiki.apache.org/confluence/display/PIG/PigMix', '//cwiki.apache.org/confluence/display/PIG/PigMix'), ('.', '.')]


------------------- Sentence 8 -------------------

Accessed 2 Feb 2015.

>> Tokens are: 
 ['Accessed', '2', 'Feb', '2015', '.']

>> Bigrams are: 
 [('Accessed', '2'), ('2', 'Feb'), ('Feb', '2015'), ('2015', '.')]

>> Trigrams are: 
 [('Accessed', '2', 'Feb'), ('2', 'Feb', '2015'), ('Feb', '2015', '.')]

>> POS Tags are: 
 [('Accessed', 'JJ'), ('2', 'CD'), ('Feb', 'NNP'), ('2015', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Feb']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Accessed', 'access'), ('2', '2'), ('Feb', 'feb'), ('2015', '2015'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Accessed', 'access'), ('2', '2'), ('Feb', 'feb'), ('2015', '2015'), ('.', '.')]

>> Lemmatization: 
 [('Accessed', 'Accessed'), ('2', '2'), ('Feb', 'Feb'), ('2015', '2015'), ('.', '.')]


------------------- Sentence 9 -------------------

131.

>> Tokens are: 
 ['131', '.']

>> Bigrams are: 
 [('131', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('131', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('131', '131'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('131', '131'), ('.', '.')]

>> Lemmatization: 
 [('131', '131'), ('.', '.')]


------------------- Sentence 10 -------------------

GridMix [Online].

>> Tokens are: 
 ['GridMix', '[', 'Online', ']', '.']

>> Bigrams are: 
 [('GridMix', '['), ('[', 'Online'), ('Online', ']'), (']', '.')]

>> Trigrams are: 
 [('GridMix', '[', 'Online'), ('[', 'Online', ']'), ('Online', ']', '.')]

>> POS Tags are: 
 [('GridMix', 'NNP'), ('[', 'NNP'), ('Online', 'NNP'), (']', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['GridMix [ Online ]']

>> Named Entities are: 
 [('ORGANIZATION', 'GridMix'), ('PERSON', 'Online')] 

>> Stemming using Porter Stemmer: 
 [('GridMix', 'gridmix'), ('[', '['), ('Online', 'onlin'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('GridMix', 'gridmix'), ('[', '['), ('Online', 'onlin'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('GridMix', 'GridMix'), ('[', '['), ('Online', 'Online'), (']', ']'), ('.', '.')]


------------------- Sentence 11 -------------------

http://hadoop.apache.org/docs/r1.2.1/gridmix.html.

>> Tokens are: 
 ['http', ':', '//hadoop.apache.org/docs/r1.2.1/gridmix.html', '.']

>> Bigrams are: 
 [('http', ':'), (':', '//hadoop.apache.org/docs/r1.2.1/gridmix.html'), ('//hadoop.apache.org/docs/r1.2.1/gridmix.html', '.')]

>> Trigrams are: 
 [('http', ':', '//hadoop.apache.org/docs/r1.2.1/gridmix.html'), (':', '//hadoop.apache.org/docs/r1.2.1/gridmix.html', '.')]

>> POS Tags are: 
 [('http', 'NN'), (':', ':'), ('//hadoop.apache.org/docs/r1.2.1/gridmix.html', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['http', '//hadoop.apache.org/docs/r1.2.1/gridmix.html']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('http', 'http'), (':', ':'), ('//hadoop.apache.org/docs/r1.2.1/gridmix.html', '//hadoop.apache.org/docs/r1.2.1/gridmix.html'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('http', 'http'), (':', ':'), ('//hadoop.apache.org/docs/r1.2.1/gridmix.html', '//hadoop.apache.org/docs/r1.2.1/gridmix.html'), ('.', '.')]

>> Lemmatization: 
 [('http', 'http'), (':', ':'), ('//hadoop.apache.org/docs/r1.2.1/gridmix.html', '//hadoop.apache.org/docs/r1.2.1/gridmix.html'), ('.', '.')]


------------------- Sentence 12 -------------------

Accessed 2 Feb 2015.

>> Tokens are: 
 ['Accessed', '2', 'Feb', '2015', '.']

>> Bigrams are: 
 [('Accessed', '2'), ('2', 'Feb'), ('Feb', '2015'), ('2015', '.')]

>> Trigrams are: 
 [('Accessed', '2', 'Feb'), ('2', 'Feb', '2015'), ('Feb', '2015', '.')]

>> POS Tags are: 
 [('Accessed', 'JJ'), ('2', 'CD'), ('Feb', 'NNP'), ('2015', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Feb']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Accessed', 'access'), ('2', '2'), ('Feb', 'feb'), ('2015', '2015'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Accessed', 'access'), ('2', '2'), ('Feb', 'feb'), ('2015', '2015'), ('.', '.')]

>> Lemmatization: 
 [('Accessed', 'Accessed'), ('2', '2'), ('Feb', 'Feb'), ('2015', '2015'), ('.', '.')]


------------------- Sentence 13 -------------------

132.

>> Tokens are: 
 ['132', '.']

>> Bigrams are: 
 [('132', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('132', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('132', '132'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('132', '132'), ('.', '.')]

>> Lemmatization: 
 [('132', '132'), ('.', '.')]


------------------- Sentence 14 -------------------

TeraSoft [Online].

>> Tokens are: 
 ['TeraSoft', '[', 'Online', ']', '.']

>> Bigrams are: 
 [('TeraSoft', '['), ('[', 'Online'), ('Online', ']'), (']', '.')]

>> Trigrams are: 
 [('TeraSoft', '[', 'Online'), ('[', 'Online', ']'), ('Online', ']', '.')]

>> POS Tags are: 
 [('TeraSoft', 'NNP'), ('[', 'NNP'), ('Online', 'NNP'), (']', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['TeraSoft [ Online ]']

>> Named Entities are: 
 [('ORGANIZATION', 'TeraSoft'), ('PERSON', 'Online')] 

>> Stemming using Porter Stemmer: 
 [('TeraSoft', 'terasoft'), ('[', '['), ('Online', 'onlin'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('TeraSoft', 'terasoft'), ('[', '['), ('Online', 'onlin'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('TeraSoft', 'TeraSoft'), ('[', '['), ('Online', 'Online'), (']', ']'), ('.', '.')]


------------------- Sentence 15 -------------------

http://sortbenchmark.org/.

>> Tokens are: 
 ['http', ':', '//sortbenchmark.org/', '.']

>> Bigrams are: 
 [('http', ':'), (':', '//sortbenchmark.org/'), ('//sortbenchmark.org/', '.')]

>> Trigrams are: 
 [('http', ':', '//sortbenchmark.org/'), (':', '//sortbenchmark.org/', '.')]

>> POS Tags are: 
 [('http', 'NN'), (':', ':'), ('//sortbenchmark.org/', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['http', '//sortbenchmark.org/']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('http', 'http'), (':', ':'), ('//sortbenchmark.org/', '//sortbenchmark.org/'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('http', 'http'), (':', ':'), ('//sortbenchmark.org/', '//sortbenchmark.org/'), ('.', '.')]

>> Lemmatization: 
 [('http', 'http'), (':', ':'), ('//sortbenchmark.org/', '//sortbenchmark.org/'), ('.', '.')]


------------------- Sentence 16 -------------------

Accessed 2 Feb 2015.

>> Tokens are: 
 ['Accessed', '2', 'Feb', '2015', '.']

>> Bigrams are: 
 [('Accessed', '2'), ('2', 'Feb'), ('Feb', '2015'), ('2015', '.')]

>> Trigrams are: 
 [('Accessed', '2', 'Feb'), ('2', 'Feb', '2015'), ('Feb', '2015', '.')]

>> POS Tags are: 
 [('Accessed', 'JJ'), ('2', 'CD'), ('Feb', 'NNP'), ('2015', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Feb']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Accessed', 'access'), ('2', '2'), ('Feb', 'feb'), ('2015', '2015'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Accessed', 'access'), ('2', '2'), ('Feb', 'feb'), ('2015', '2015'), ('.', '.')]

>> Lemmatization: 
 [('Accessed', 'Accessed'), ('2', '2'), ('Feb', 'Feb'), ('2015', '2015'), ('.', '.')]


------------------- Sentence 17 -------------------

133.

>> Tokens are: 
 ['133', '.']

>> Bigrams are: 
 [('133', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('133', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('133', '133'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('133', '133'), ('.', '.')]

>> Lemmatization: 
 [('133', '133'), ('.', '.')]


------------------- Sentence 18 -------------------

TPC, transaction processing performance council [Online].

>> Tokens are: 
 ['TPC', ',', 'transaction', 'processing', 'performance', 'council', '[', 'Online', ']', '.']

>> Bigrams are: 
 [('TPC', ','), (',', 'transaction'), ('transaction', 'processing'), ('processing', 'performance'), ('performance', 'council'), ('council', '['), ('[', 'Online'), ('Online', ']'), (']', '.')]

>> Trigrams are: 
 [('TPC', ',', 'transaction'), (',', 'transaction', 'processing'), ('transaction', 'processing', 'performance'), ('processing', 'performance', 'council'), ('performance', 'council', '['), ('council', '[', 'Online'), ('[', 'Online', ']'), ('Online', ']', '.')]

>> POS Tags are: 
 [('TPC', 'NNP'), (',', ','), ('transaction', 'NN'), ('processing', 'NN'), ('performance', 'NN'), ('council', 'NN'), ('[', 'NNP'), ('Online', 'NNP'), (']', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['TPC', 'transaction processing performance council [ Online ]']

>> Named Entities are: 
 [('PERSON', 'Online')] 

>> Stemming using Porter Stemmer: 
 [('TPC', 'tpc'), (',', ','), ('transaction', 'transact'), ('processing', 'process'), ('performance', 'perform'), ('council', 'council'), ('[', '['), ('Online', 'onlin'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('TPC', 'tpc'), (',', ','), ('transaction', 'transact'), ('processing', 'process'), ('performance', 'perform'), ('council', 'council'), ('[', '['), ('Online', 'onlin'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('TPC', 'TPC'), (',', ','), ('transaction', 'transaction'), ('processing', 'processing'), ('performance', 'performance'), ('council', 'council'), ('[', '['), ('Online', 'Online'), (']', ']'), ('.', '.')]


------------------- Sentence 19 -------------------

http://www.tpc.org/.

>> Tokens are: 
 ['http', ':', '//www.tpc.org/', '.']

>> Bigrams are: 
 [('http', ':'), (':', '//www.tpc.org/'), ('//www.tpc.org/', '.')]

>> Trigrams are: 
 [('http', ':', '//www.tpc.org/'), (':', '//www.tpc.org/', '.')]

>> POS Tags are: 
 [('http', 'NN'), (':', ':'), ('//www.tpc.org/', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['http', '//www.tpc.org/']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('http', 'http'), (':', ':'), ('//www.tpc.org/', '//www.tpc.org/'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('http', 'http'), (':', ':'), ('//www.tpc.org/', '//www.tpc.org/'), ('.', '.')]

>> Lemmatization: 
 [('http', 'http'), (':', ':'), ('//www.tpc.org/', '//www.tpc.org/'), ('.', '.')]


------------------- Sentence 20 -------------------

Accessed 2 Feb 2015.

>> Tokens are: 
 ['Accessed', '2', 'Feb', '2015', '.']

>> Bigrams are: 
 [('Accessed', '2'), ('2', 'Feb'), ('Feb', '2015'), ('2015', '.')]

>> Trigrams are: 
 [('Accessed', '2', 'Feb'), ('2', 'Feb', '2015'), ('Feb', '2015', '.')]

>> POS Tags are: 
 [('Accessed', 'JJ'), ('2', 'CD'), ('Feb', 'NNP'), ('2015', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Feb']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Accessed', 'access'), ('2', '2'), ('Feb', 'feb'), ('2015', '2015'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Accessed', 'access'), ('2', '2'), ('Feb', 'feb'), ('2015', '2015'), ('.', '.')]

>> Lemmatization: 
 [('Accessed', 'Accessed'), ('2', '2'), ('Feb', 'Feb'), ('2015', '2015'), ('.', '.')]


------------------- Sentence 21 -------------------

134. Cooper BF, Silberstein A, Tam E, Ramakrishnan R, Sears R. Benchmarking cloud serving systems with ycsb.

>> Tokens are: 
 ['134.', 'Cooper', 'BF', ',', 'Silberstein', 'A', ',', 'Tam', 'E', ',', 'Ramakrishnan', 'R', ',', 'Sears', 'R.', 'Benchmarking', 'cloud', 'serving', 'systems', 'ycsb', '.']

>> Bigrams are: 
 [('134.', 'Cooper'), ('Cooper', 'BF'), ('BF', ','), (',', 'Silberstein'), ('Silberstein', 'A'), ('A', ','), (',', 'Tam'), ('Tam', 'E'), ('E', ','), (',', 'Ramakrishnan'), ('Ramakrishnan', 'R'), ('R', ','), (',', 'Sears'), ('Sears', 'R.'), ('R.', 'Benchmarking'), ('Benchmarking', 'cloud'), ('cloud', 'serving'), ('serving', 'systems'), ('systems', 'ycsb'), ('ycsb', '.')]

>> Trigrams are: 
 [('134.', 'Cooper', 'BF'), ('Cooper', 'BF', ','), ('BF', ',', 'Silberstein'), (',', 'Silberstein', 'A'), ('Silberstein', 'A', ','), ('A', ',', 'Tam'), (',', 'Tam', 'E'), ('Tam', 'E', ','), ('E', ',', 'Ramakrishnan'), (',', 'Ramakrishnan', 'R'), ('Ramakrishnan', 'R', ','), ('R', ',', 'Sears'), (',', 'Sears', 'R.'), ('Sears', 'R.', 'Benchmarking'), ('R.', 'Benchmarking', 'cloud'), ('Benchmarking', 'cloud', 'serving'), ('cloud', 'serving', 'systems'), ('serving', 'systems', 'ycsb'), ('systems', 'ycsb', '.')]

>> POS Tags are: 
 [('134.', 'CD'), ('Cooper', 'NNP'), ('BF', 'NNP'), (',', ','), ('Silberstein', 'NNP'), ('A', 'NNP'), (',', ','), ('Tam', 'NNP'), ('E', 'NNP'), (',', ','), ('Ramakrishnan', 'NNP'), ('R', 'NNP'), (',', ','), ('Sears', 'NNP'), ('R.', 'NNP'), ('Benchmarking', 'NNP'), ('cloud', 'NN'), ('serving', 'VBG'), ('systems', 'NNS'), ('ycsb', 'RB'), ('.', '.')]

>> Noun Phrases are: 
 ['Cooper BF', 'Silberstein A', 'Tam E', 'Ramakrishnan R', 'Sears R. Benchmarking cloud', 'systems']

>> Named Entities are: 
 [('PERSON', 'Cooper BF'), ('PERSON', 'Silberstein A'), ('PERSON', 'Tam E'), ('PERSON', 'Ramakrishnan R'), ('PERSON', 'Sears R. Benchmarking')] 

>> Stemming using Porter Stemmer: 
 [('134.', '134.'), ('Cooper', 'cooper'), ('BF', 'bf'), (',', ','), ('Silberstein', 'silberstein'), ('A', 'a'), (',', ','), ('Tam', 'tam'), ('E', 'e'), (',', ','), ('Ramakrishnan', 'ramakrishnan'), ('R', 'r'), (',', ','), ('Sears', 'sear'), ('R.', 'r.'), ('Benchmarking', 'benchmark'), ('cloud', 'cloud'), ('serving', 'serv'), ('systems', 'system'), ('ycsb', 'ycsb'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('134.', '134.'), ('Cooper', 'cooper'), ('BF', 'bf'), (',', ','), ('Silberstein', 'silberstein'), ('A', 'a'), (',', ','), ('Tam', 'tam'), ('E', 'e'), (',', ','), ('Ramakrishnan', 'ramakrishnan'), ('R', 'r'), (',', ','), ('Sears', 'sear'), ('R.', 'r.'), ('Benchmarking', 'benchmark'), ('cloud', 'cloud'), ('serving', 'serv'), ('systems', 'system'), ('ycsb', 'ycsb'), ('.', '.')]

>> Lemmatization: 
 [('134.', '134.'), ('Cooper', 'Cooper'), ('BF', 'BF'), (',', ','), ('Silberstein', 'Silberstein'), ('A', 'A'), (',', ','), ('Tam', 'Tam'), ('E', 'E'), (',', ','), ('Ramakrishnan', 'Ramakrishnan'), ('R', 'R'), (',', ','), ('Sears', 'Sears'), ('R.', 'R.'), ('Benchmarking', 'Benchmarking'), ('cloud', 'cloud'), ('serving', 'serving'), ('systems', 'system'), ('ycsb', 'ycsb'), ('.', '.')]


------------------- Sentence 22 -------------------

In:

>> Tokens are: 
 ['In', ':']

>> Bigrams are: 
 [('In', ':')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('In', 'IN'), (':', ':')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), (':', ':')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), (':', ':')]

>> Lemmatization: 
 [('In', 'In'), (':', ':')]



========================================== PARAGRAPH 521 ===========================================

Proceedings of the ACM Symposium on Cloud Computing, 2010. pp 143–154.

------------------- Sentence 1 -------------------

Proceedings of the ACM Symposium on Cloud Computing, 2010. pp 143–154.

>> Tokens are: 
 ['Proceedings', 'ACM', 'Symposium', 'Cloud', 'Computing', ',', '2010.', 'pp', '143–154', '.']

>> Bigrams are: 
 [('Proceedings', 'ACM'), ('ACM', 'Symposium'), ('Symposium', 'Cloud'), ('Cloud', 'Computing'), ('Computing', ','), (',', '2010.'), ('2010.', 'pp'), ('pp', '143–154'), ('143–154', '.')]

>> Trigrams are: 
 [('Proceedings', 'ACM', 'Symposium'), ('ACM', 'Symposium', 'Cloud'), ('Symposium', 'Cloud', 'Computing'), ('Cloud', 'Computing', ','), ('Computing', ',', '2010.'), (',', '2010.', 'pp'), ('2010.', 'pp', '143–154'), ('pp', '143–154', '.')]

>> POS Tags are: 
 [('Proceedings', 'NNS'), ('ACM', 'NNP'), ('Symposium', 'NNP'), ('Cloud', 'NNP'), ('Computing', 'NNP'), (',', ','), ('2010.', 'CD'), ('pp', 'NN'), ('143–154', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Proceedings ACM Symposium Cloud Computing', 'pp']

>> Named Entities are: 
 [('ORGANIZATION', 'ACM Symposium Cloud')] 

>> Stemming using Porter Stemmer: 
 [('Proceedings', 'proceed'), ('ACM', 'acm'), ('Symposium', 'symposium'), ('Cloud', 'cloud'), ('Computing', 'comput'), (',', ','), ('2010.', '2010.'), ('pp', 'pp'), ('143–154', '143–154'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Proceedings', 'proceed'), ('ACM', 'acm'), ('Symposium', 'symposium'), ('Cloud', 'cloud'), ('Computing', 'comput'), (',', ','), ('2010.', '2010.'), ('pp', 'pp'), ('143–154', '143–154'), ('.', '.')]

>> Lemmatization: 
 [('Proceedings', 'Proceedings'), ('ACM', 'ACM'), ('Symposium', 'Symposium'), ('Cloud', 'Cloud'), ('Computing', 'Computing'), (',', ','), ('2010.', '2010.'), ('pp', 'pp'), ('143–154', '143–154'), ('.', '.')]



========================================== PARAGRAPH 522 ===========================================

Page 32 of 32Tsai et al. Journal of Big Data  (2015) 2:21  

------------------- Sentence 1 -------------------

Page 32 of 32Tsai et al.

>> Tokens are: 
 ['Page', '32', '32Tsai', 'et', 'al', '.']

>> Bigrams are: 
 [('Page', '32'), ('32', '32Tsai'), ('32Tsai', 'et'), ('et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('Page', '32', '32Tsai'), ('32', '32Tsai', 'et'), ('32Tsai', 'et', 'al'), ('et', 'al', '.')]

>> POS Tags are: 
 [('Page', 'NN'), ('32', 'CD'), ('32Tsai', 'CD'), ('et', 'NN'), ('al', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Page', 'et al']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Page', 'page'), ('32', '32'), ('32Tsai', '32tsai'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Page', 'page'), ('32', '32'), ('32Tsai', '32tsai'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('Page', 'Page'), ('32', '32'), ('32Tsai', '32Tsai'), ('et', 'et'), ('al', 'al'), ('.', '.')]


------------------- Sentence 2 -------------------

Journal of Big Data  (2015) 2:21

>> Tokens are: 
 ['Journal', 'Big', 'Data', '(', '2015', ')', '2:21']

>> Bigrams are: 
 [('Journal', 'Big'), ('Big', 'Data'), ('Data', '('), ('(', '2015'), ('2015', ')'), (')', '2:21')]

>> Trigrams are: 
 [('Journal', 'Big', 'Data'), ('Big', 'Data', '('), ('Data', '(', '2015'), ('(', '2015', ')'), ('2015', ')', '2:21')]

>> POS Tags are: 
 [('Journal', 'NNP'), ('Big', 'NNP'), ('Data', 'NNP'), ('(', '('), ('2015', 'CD'), (')', ')'), ('2:21', 'CD')]

>> Noun Phrases are: 
 ['Journal Big Data']

>> Named Entities are: 
 [('PERSON', 'Journal')] 

>> Stemming using Porter Stemmer: 
 [('Journal', 'journal'), ('Big', 'big'), ('Data', 'data'), ('(', '('), ('2015', '2015'), (')', ')'), ('2:21', '2:21')]

>> Stemming using Snowball Stemmer: 
 [('Journal', 'journal'), ('Big', 'big'), ('Data', 'data'), ('(', '('), ('2015', '2015'), (')', ')'), ('2:21', '2:21')]

>> Lemmatization: 
 [('Journal', 'Journal'), ('Big', 'Big'), ('Data', 'Data'), ('(', '('), ('2015', '2015'), (')', ')'), ('2:21', '2:21')]



========================================== PARAGRAPH 523 ===========================================

 135. Ghazal A, Rabl T, Hu M, Raab F, Poess M, Crolotte A, Jacobsen HA. BigBench: Towards an industry standard bench‑ mark for big data analytics. In: Proceedings of the ACM SIGMOD International Conference on Management of  Data, 2013. pp 1197–1208. 

------------------- Sentence 1 -------------------

 135.

>> Tokens are: 
 ['135', '.']

>> Bigrams are: 
 [('135', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('135', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('135', '135'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('135', '135'), ('.', '.')]

>> Lemmatization: 
 [('135', '135'), ('.', '.')]


------------------- Sentence 2 -------------------

Ghazal A, Rabl T, Hu M, Raab F, Poess M, Crolotte A, Jacobsen HA.

>> Tokens are: 
 ['Ghazal', 'A', ',', 'Rabl', 'T', ',', 'Hu', 'M', ',', 'Raab', 'F', ',', 'Poess', 'M', ',', 'Crolotte', 'A', ',', 'Jacobsen', 'HA', '.']

>> Bigrams are: 
 [('Ghazal', 'A'), ('A', ','), (',', 'Rabl'), ('Rabl', 'T'), ('T', ','), (',', 'Hu'), ('Hu', 'M'), ('M', ','), (',', 'Raab'), ('Raab', 'F'), ('F', ','), (',', 'Poess'), ('Poess', 'M'), ('M', ','), (',', 'Crolotte'), ('Crolotte', 'A'), ('A', ','), (',', 'Jacobsen'), ('Jacobsen', 'HA'), ('HA', '.')]

>> Trigrams are: 
 [('Ghazal', 'A', ','), ('A', ',', 'Rabl'), (',', 'Rabl', 'T'), ('Rabl', 'T', ','), ('T', ',', 'Hu'), (',', 'Hu', 'M'), ('Hu', 'M', ','), ('M', ',', 'Raab'), (',', 'Raab', 'F'), ('Raab', 'F', ','), ('F', ',', 'Poess'), (',', 'Poess', 'M'), ('Poess', 'M', ','), ('M', ',', 'Crolotte'), (',', 'Crolotte', 'A'), ('Crolotte', 'A', ','), ('A', ',', 'Jacobsen'), (',', 'Jacobsen', 'HA'), ('Jacobsen', 'HA', '.')]

>> POS Tags are: 
 [('Ghazal', 'NNP'), ('A', 'NNP'), (',', ','), ('Rabl', 'NNP'), ('T', 'NNP'), (',', ','), ('Hu', 'NNP'), ('M', 'NNP'), (',', ','), ('Raab', 'NNP'), ('F', 'NNP'), (',', ','), ('Poess', 'NNP'), ('M', 'NNP'), (',', ','), ('Crolotte', 'NNP'), ('A', 'NNP'), (',', ','), ('Jacobsen', 'NNP'), ('HA', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Ghazal A', 'Rabl T', 'Hu M', 'Raab F', 'Poess M', 'Crolotte A', 'Jacobsen HA']

>> Named Entities are: 
 [('PERSON', 'Ghazal'), ('PERSON', 'Rabl T'), ('PERSON', 'Hu M'), ('PERSON', 'Raab F'), ('PERSON', 'Poess M'), ('PERSON', 'Crolotte A'), ('PERSON', 'Jacobsen HA')] 

>> Stemming using Porter Stemmer: 
 [('Ghazal', 'ghazal'), ('A', 'a'), (',', ','), ('Rabl', 'rabl'), ('T', 't'), (',', ','), ('Hu', 'hu'), ('M', 'm'), (',', ','), ('Raab', 'raab'), ('F', 'f'), (',', ','), ('Poess', 'poess'), ('M', 'm'), (',', ','), ('Crolotte', 'crolott'), ('A', 'a'), (',', ','), ('Jacobsen', 'jacobsen'), ('HA', 'ha'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Ghazal', 'ghazal'), ('A', 'a'), (',', ','), ('Rabl', 'rabl'), ('T', 't'), (',', ','), ('Hu', 'hu'), ('M', 'm'), (',', ','), ('Raab', 'raab'), ('F', 'f'), (',', ','), ('Poess', 'poess'), ('M', 'm'), (',', ','), ('Crolotte', 'crolott'), ('A', 'a'), (',', ','), ('Jacobsen', 'jacobsen'), ('HA', 'ha'), ('.', '.')]

>> Lemmatization: 
 [('Ghazal', 'Ghazal'), ('A', 'A'), (',', ','), ('Rabl', 'Rabl'), ('T', 'T'), (',', ','), ('Hu', 'Hu'), ('M', 'M'), (',', ','), ('Raab', 'Raab'), ('F', 'F'), (',', ','), ('Poess', 'Poess'), ('M', 'M'), (',', ','), ('Crolotte', 'Crolotte'), ('A', 'A'), (',', ','), ('Jacobsen', 'Jacobsen'), ('HA', 'HA'), ('.', '.')]


------------------- Sentence 3 -------------------

BigBench: Towards an industry standard bench‑ mark for big data analytics.

>> Tokens are: 
 ['BigBench', ':', 'Towards', 'industry', 'standard', 'bench‑', 'mark', 'big', 'data', 'analytics', '.']

>> Bigrams are: 
 [('BigBench', ':'), (':', 'Towards'), ('Towards', 'industry'), ('industry', 'standard'), ('standard', 'bench‑'), ('bench‑', 'mark'), ('mark', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', '.')]

>> Trigrams are: 
 [('BigBench', ':', 'Towards'), (':', 'Towards', 'industry'), ('Towards', 'industry', 'standard'), ('industry', 'standard', 'bench‑'), ('standard', 'bench‑', 'mark'), ('bench‑', 'mark', 'big'), ('mark', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', '.')]

>> POS Tags are: 
 [('BigBench', 'NN'), (':', ':'), ('Towards', 'NNS'), ('industry', 'NN'), ('standard', 'NN'), ('bench‑', 'NN'), ('mark', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['BigBench', 'Towards industry standard bench‑ mark', 'big data analytics']

>> Named Entities are: 
 [('GPE', 'BigBench')] 

>> Stemming using Porter Stemmer: 
 [('BigBench', 'bigbench'), (':', ':'), ('Towards', 'toward'), ('industry', 'industri'), ('standard', 'standard'), ('bench‑', 'bench‑'), ('mark', 'mark'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('BigBench', 'bigbench'), (':', ':'), ('Towards', 'toward'), ('industry', 'industri'), ('standard', 'standard'), ('bench‑', 'bench‑'), ('mark', 'mark'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('.', '.')]

>> Lemmatization: 
 [('BigBench', 'BigBench'), (':', ':'), ('Towards', 'Towards'), ('industry', 'industry'), ('standard', 'standard'), ('bench‑', 'bench‑'), ('mark', 'mark'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('.', '.')]


------------------- Sentence 4 -------------------

In: Proceedings of the ACM SIGMOD International Conference on Management of  Data, 2013. pp 1197–1208.

>> Tokens are: 
 ['In', ':', 'Proceedings', 'ACM', 'SIGMOD', 'International', 'Conference', 'Management', 'Data', ',', '2013.', 'pp', '1197–1208', '.']

>> Bigrams are: 
 [('In', ':'), (':', 'Proceedings'), ('Proceedings', 'ACM'), ('ACM', 'SIGMOD'), ('SIGMOD', 'International'), ('International', 'Conference'), ('Conference', 'Management'), ('Management', 'Data'), ('Data', ','), (',', '2013.'), ('2013.', 'pp'), ('pp', '1197–1208'), ('1197–1208', '.')]

>> Trigrams are: 
 [('In', ':', 'Proceedings'), (':', 'Proceedings', 'ACM'), ('Proceedings', 'ACM', 'SIGMOD'), ('ACM', 'SIGMOD', 'International'), ('SIGMOD', 'International', 'Conference'), ('International', 'Conference', 'Management'), ('Conference', 'Management', 'Data'), ('Management', 'Data', ','), ('Data', ',', '2013.'), (',', '2013.', 'pp'), ('2013.', 'pp', '1197–1208'), ('pp', '1197–1208', '.')]

>> POS Tags are: 
 [('In', 'IN'), (':', ':'), ('Proceedings', 'NNS'), ('ACM', 'NNP'), ('SIGMOD', 'NNP'), ('International', 'NNP'), ('Conference', 'NNP'), ('Management', 'NNP'), ('Data', 'NNP'), (',', ','), ('2013.', 'CD'), ('pp', 'NN'), ('1197–1208', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Proceedings ACM SIGMOD International Conference Management Data', 'pp']

>> Named Entities are: 
 [('ORGANIZATION', 'ACM'), ('ORGANIZATION', 'SIGMOD International Conference Management Data')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), (':', ':'), ('Proceedings', 'proceed'), ('ACM', 'acm'), ('SIGMOD', 'sigmod'), ('International', 'intern'), ('Conference', 'confer'), ('Management', 'manag'), ('Data', 'data'), (',', ','), ('2013.', '2013.'), ('pp', 'pp'), ('1197–1208', '1197–1208'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), (':', ':'), ('Proceedings', 'proceed'), ('ACM', 'acm'), ('SIGMOD', 'sigmod'), ('International', 'intern'), ('Conference', 'confer'), ('Management', 'manag'), ('Data', 'data'), (',', ','), ('2013.', '2013.'), ('pp', 'pp'), ('1197–1208', '1197–1208'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), (':', ':'), ('Proceedings', 'Proceedings'), ('ACM', 'ACM'), ('SIGMOD', 'SIGMOD'), ('International', 'International'), ('Conference', 'Conference'), ('Management', 'Management'), ('Data', 'Data'), (',', ','), ('2013.', '2013.'), ('pp', 'pp'), ('1197–1208', '1197–1208'), ('.', '.')]



========================================== PARAGRAPH 524 ===========================================

 136. Cheptsov A. Hpc in big data age: An evaluation report for java‑based data‑intensive applications implemented  with hadoop and openmpi. In: Proceedings of the European MPI Users’ Group Meeting, 2014. pp 175:175–175:180. 

------------------- Sentence 1 -------------------

 136.

>> Tokens are: 
 ['136', '.']

>> Bigrams are: 
 [('136', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('136', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('136', '136'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('136', '136'), ('.', '.')]

>> Lemmatization: 
 [('136', '136'), ('.', '.')]


------------------- Sentence 2 -------------------

Cheptsov A. Hpc in big data age: An evaluation report for java‑based data‑intensive applications implemented  with hadoop and openmpi.

>> Tokens are: 
 ['Cheptsov', 'A.', 'Hpc', 'big', 'data', 'age', ':', 'An', 'evaluation', 'report', 'java‑based', 'data‑intensive', 'applications', 'implemented', 'hadoop', 'openmpi', '.']

>> Bigrams are: 
 [('Cheptsov', 'A.'), ('A.', 'Hpc'), ('Hpc', 'big'), ('big', 'data'), ('data', 'age'), ('age', ':'), (':', 'An'), ('An', 'evaluation'), ('evaluation', 'report'), ('report', 'java‑based'), ('java‑based', 'data‑intensive'), ('data‑intensive', 'applications'), ('applications', 'implemented'), ('implemented', 'hadoop'), ('hadoop', 'openmpi'), ('openmpi', '.')]

>> Trigrams are: 
 [('Cheptsov', 'A.', 'Hpc'), ('A.', 'Hpc', 'big'), ('Hpc', 'big', 'data'), ('big', 'data', 'age'), ('data', 'age', ':'), ('age', ':', 'An'), (':', 'An', 'evaluation'), ('An', 'evaluation', 'report'), ('evaluation', 'report', 'java‑based'), ('report', 'java‑based', 'data‑intensive'), ('java‑based', 'data‑intensive', 'applications'), ('data‑intensive', 'applications', 'implemented'), ('applications', 'implemented', 'hadoop'), ('implemented', 'hadoop', 'openmpi'), ('hadoop', 'openmpi', '.')]

>> POS Tags are: 
 [('Cheptsov', 'NNP'), ('A.', 'NN'), ('Hpc', 'NNP'), ('big', 'JJ'), ('data', 'NNS'), ('age', 'NN'), (':', ':'), ('An', 'DT'), ('evaluation', 'NN'), ('report', 'NN'), ('java‑based', 'VBD'), ('data‑intensive', 'JJ'), ('applications', 'NNS'), ('implemented', 'VBD'), ('hadoop', 'NN'), ('openmpi', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Cheptsov A. Hpc', 'big data age', 'An evaluation report', 'data‑intensive applications', 'hadoop openmpi']

>> Named Entities are: 
 [('GPE', 'Cheptsov')] 

>> Stemming using Porter Stemmer: 
 [('Cheptsov', 'cheptsov'), ('A.', 'a.'), ('Hpc', 'hpc'), ('big', 'big'), ('data', 'data'), ('age', 'age'), (':', ':'), ('An', 'an'), ('evaluation', 'evalu'), ('report', 'report'), ('java‑based', 'java‑bas'), ('data‑intensive', 'data‑intens'), ('applications', 'applic'), ('implemented', 'implement'), ('hadoop', 'hadoop'), ('openmpi', 'openmpi'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Cheptsov', 'cheptsov'), ('A.', 'a.'), ('Hpc', 'hpc'), ('big', 'big'), ('data', 'data'), ('age', 'age'), (':', ':'), ('An', 'an'), ('evaluation', 'evalu'), ('report', 'report'), ('java‑based', 'java‑bas'), ('data‑intensive', 'data‑intens'), ('applications', 'applic'), ('implemented', 'implement'), ('hadoop', 'hadoop'), ('openmpi', 'openmpi'), ('.', '.')]

>> Lemmatization: 
 [('Cheptsov', 'Cheptsov'), ('A.', 'A.'), ('Hpc', 'Hpc'), ('big', 'big'), ('data', 'data'), ('age', 'age'), (':', ':'), ('An', 'An'), ('evaluation', 'evaluation'), ('report', 'report'), ('java‑based', 'java‑based'), ('data‑intensive', 'data‑intensive'), ('applications', 'application'), ('implemented', 'implemented'), ('hadoop', 'hadoop'), ('openmpi', 'openmpi'), ('.', '.')]


------------------- Sentence 3 -------------------

In: Proceedings of the European MPI Users’ Group Meeting, 2014. pp 175:175–175:180.

>> Tokens are: 
 ['In', ':', 'Proceedings', 'European', 'MPI', 'Users', '’', 'Group', 'Meeting', ',', '2014.', 'pp', '175:175–175:180', '.']

>> Bigrams are: 
 [('In', ':'), (':', 'Proceedings'), ('Proceedings', 'European'), ('European', 'MPI'), ('MPI', 'Users'), ('Users', '’'), ('’', 'Group'), ('Group', 'Meeting'), ('Meeting', ','), (',', '2014.'), ('2014.', 'pp'), ('pp', '175:175–175:180'), ('175:175–175:180', '.')]

>> Trigrams are: 
 [('In', ':', 'Proceedings'), (':', 'Proceedings', 'European'), ('Proceedings', 'European', 'MPI'), ('European', 'MPI', 'Users'), ('MPI', 'Users', '’'), ('Users', '’', 'Group'), ('’', 'Group', 'Meeting'), ('Group', 'Meeting', ','), ('Meeting', ',', '2014.'), (',', '2014.', 'pp'), ('2014.', 'pp', '175:175–175:180'), ('pp', '175:175–175:180', '.')]

>> POS Tags are: 
 [('In', 'IN'), (':', ':'), ('Proceedings', 'NNS'), ('European', 'JJ'), ('MPI', 'NNP'), ('Users', 'NNP'), ('’', 'NNP'), ('Group', 'NNP'), ('Meeting', 'NNP'), (',', ','), ('2014.', 'CD'), ('pp', 'NN'), ('175:175–175:180', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Proceedings', 'European MPI Users ’ Group Meeting', 'pp']

>> Named Entities are: 
 [('ORGANIZATION', 'European'), ('ORGANIZATION', 'MPI Users')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), (':', ':'), ('Proceedings', 'proceed'), ('European', 'european'), ('MPI', 'mpi'), ('Users', 'user'), ('’', '’'), ('Group', 'group'), ('Meeting', 'meet'), (',', ','), ('2014.', '2014.'), ('pp', 'pp'), ('175:175–175:180', '175:175–175:180'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), (':', ':'), ('Proceedings', 'proceed'), ('European', 'european'), ('MPI', 'mpi'), ('Users', 'user'), ('’', '’'), ('Group', 'group'), ('Meeting', 'meet'), (',', ','), ('2014.', '2014.'), ('pp', 'pp'), ('175:175–175:180', '175:175–175:180'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), (':', ':'), ('Proceedings', 'Proceedings'), ('European', 'European'), ('MPI', 'MPI'), ('Users', 'Users'), ('’', '’'), ('Group', 'Group'), ('Meeting', 'Meeting'), (',', ','), ('2014.', '2014.'), ('pp', 'pp'), ('175:175–175:180', '175:175–175:180'), ('.', '.')]



========================================== PARAGRAPH 525 ===========================================

 137. Yuan LY, Wu L, You JH, Chi Y. Rubato db: A highly scalable staged grid database system for oltp and big data  applications. In: Proceedings of the ACM International Conference on Conference on Information and Knowledge  Management, 2014. pp 1–10. 

------------------- Sentence 1 -------------------

 137.

>> Tokens are: 
 ['137', '.']

>> Bigrams are: 
 [('137', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('137', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('137', '137'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('137', '137'), ('.', '.')]

>> Lemmatization: 
 [('137', '137'), ('.', '.')]


------------------- Sentence 2 -------------------

Yuan LY, Wu L, You JH, Chi Y. Rubato db: A highly scalable staged grid database system for oltp and big data  applications.

>> Tokens are: 
 ['Yuan', 'LY', ',', 'Wu', 'L', ',', 'You', 'JH', ',', 'Chi', 'Y.', 'Rubato', 'db', ':', 'A', 'highly', 'scalable', 'staged', 'grid', 'database', 'system', 'oltp', 'big', 'data', 'applications', '.']

>> Bigrams are: 
 [('Yuan', 'LY'), ('LY', ','), (',', 'Wu'), ('Wu', 'L'), ('L', ','), (',', 'You'), ('You', 'JH'), ('JH', ','), (',', 'Chi'), ('Chi', 'Y.'), ('Y.', 'Rubato'), ('Rubato', 'db'), ('db', ':'), (':', 'A'), ('A', 'highly'), ('highly', 'scalable'), ('scalable', 'staged'), ('staged', 'grid'), ('grid', 'database'), ('database', 'system'), ('system', 'oltp'), ('oltp', 'big'), ('big', 'data'), ('data', 'applications'), ('applications', '.')]

>> Trigrams are: 
 [('Yuan', 'LY', ','), ('LY', ',', 'Wu'), (',', 'Wu', 'L'), ('Wu', 'L', ','), ('L', ',', 'You'), (',', 'You', 'JH'), ('You', 'JH', ','), ('JH', ',', 'Chi'), (',', 'Chi', 'Y.'), ('Chi', 'Y.', 'Rubato'), ('Y.', 'Rubato', 'db'), ('Rubato', 'db', ':'), ('db', ':', 'A'), (':', 'A', 'highly'), ('A', 'highly', 'scalable'), ('highly', 'scalable', 'staged'), ('scalable', 'staged', 'grid'), ('staged', 'grid', 'database'), ('grid', 'database', 'system'), ('database', 'system', 'oltp'), ('system', 'oltp', 'big'), ('oltp', 'big', 'data'), ('big', 'data', 'applications'), ('data', 'applications', '.')]

>> POS Tags are: 
 [('Yuan', 'JJ'), ('LY', 'NNP'), (',', ','), ('Wu', 'NNP'), ('L', 'NNP'), (',', ','), ('You', 'PRP'), ('JH', 'VBP'), (',', ','), ('Chi', 'NNP'), ('Y.', 'NNP'), ('Rubato', 'NNP'), ('db', 'NN'), (':', ':'), ('A', 'DT'), ('highly', 'RB'), ('scalable', 'JJ'), ('staged', 'VBD'), ('grid', 'JJ'), ('database', 'NN'), ('system', 'NN'), ('oltp', 'VBP'), ('big', 'JJ'), ('data', 'NNS'), ('applications', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['Yuan LY', 'Wu L', 'Chi Y. Rubato db', 'grid database system', 'big data applications']

>> Named Entities are: 
 [('PERSON', 'Yuan LY'), ('PERSON', 'Wu L'), ('PERSON', 'Chi Y. Rubato')] 

>> Stemming using Porter Stemmer: 
 [('Yuan', 'yuan'), ('LY', 'ly'), (',', ','), ('Wu', 'wu'), ('L', 'l'), (',', ','), ('You', 'you'), ('JH', 'jh'), (',', ','), ('Chi', 'chi'), ('Y.', 'y.'), ('Rubato', 'rubato'), ('db', 'db'), (':', ':'), ('A', 'a'), ('highly', 'highli'), ('scalable', 'scalabl'), ('staged', 'stage'), ('grid', 'grid'), ('database', 'databas'), ('system', 'system'), ('oltp', 'oltp'), ('big', 'big'), ('data', 'data'), ('applications', 'applic'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Yuan', 'yuan'), ('LY', 'ly'), (',', ','), ('Wu', 'wu'), ('L', 'l'), (',', ','), ('You', 'you'), ('JH', 'jh'), (',', ','), ('Chi', 'chi'), ('Y.', 'y.'), ('Rubato', 'rubato'), ('db', 'db'), (':', ':'), ('A', 'a'), ('highly', 'high'), ('scalable', 'scalabl'), ('staged', 'stage'), ('grid', 'grid'), ('database', 'databas'), ('system', 'system'), ('oltp', 'oltp'), ('big', 'big'), ('data', 'data'), ('applications', 'applic'), ('.', '.')]

>> Lemmatization: 
 [('Yuan', 'Yuan'), ('LY', 'LY'), (',', ','), ('Wu', 'Wu'), ('L', 'L'), (',', ','), ('You', 'You'), ('JH', 'JH'), (',', ','), ('Chi', 'Chi'), ('Y.', 'Y.'), ('Rubato', 'Rubato'), ('db', 'db'), (':', ':'), ('A', 'A'), ('highly', 'highly'), ('scalable', 'scalable'), ('staged', 'staged'), ('grid', 'grid'), ('database', 'database'), ('system', 'system'), ('oltp', 'oltp'), ('big', 'big'), ('data', 'data'), ('applications', 'application'), ('.', '.')]


------------------- Sentence 3 -------------------

In: Proceedings of the ACM International Conference on Conference on Information and Knowledge  Management, 2014. pp 1–10.

>> Tokens are: 
 ['In', ':', 'Proceedings', 'ACM', 'International', 'Conference', 'Conference', 'Information', 'Knowledge', 'Management', ',', '2014.', 'pp', '1–10', '.']

>> Bigrams are: 
 [('In', ':'), (':', 'Proceedings'), ('Proceedings', 'ACM'), ('ACM', 'International'), ('International', 'Conference'), ('Conference', 'Conference'), ('Conference', 'Information'), ('Information', 'Knowledge'), ('Knowledge', 'Management'), ('Management', ','), (',', '2014.'), ('2014.', 'pp'), ('pp', '1–10'), ('1–10', '.')]

>> Trigrams are: 
 [('In', ':', 'Proceedings'), (':', 'Proceedings', 'ACM'), ('Proceedings', 'ACM', 'International'), ('ACM', 'International', 'Conference'), ('International', 'Conference', 'Conference'), ('Conference', 'Conference', 'Information'), ('Conference', 'Information', 'Knowledge'), ('Information', 'Knowledge', 'Management'), ('Knowledge', 'Management', ','), ('Management', ',', '2014.'), (',', '2014.', 'pp'), ('2014.', 'pp', '1–10'), ('pp', '1–10', '.')]

>> POS Tags are: 
 [('In', 'IN'), (':', ':'), ('Proceedings', 'NNS'), ('ACM', 'NNP'), ('International', 'NNP'), ('Conference', 'NNP'), ('Conference', 'NNP'), ('Information', 'NNP'), ('Knowledge', 'NNP'), ('Management', 'NNP'), (',', ','), ('2014.', 'CD'), ('pp', 'NN'), ('1–10', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Proceedings ACM International Conference Conference Information Knowledge Management', 'pp']

>> Named Entities are: 
 [('ORGANIZATION', 'ACM International Conference Conference Information')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), (':', ':'), ('Proceedings', 'proceed'), ('ACM', 'acm'), ('International', 'intern'), ('Conference', 'confer'), ('Conference', 'confer'), ('Information', 'inform'), ('Knowledge', 'knowledg'), ('Management', 'manag'), (',', ','), ('2014.', '2014.'), ('pp', 'pp'), ('1–10', '1–10'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), (':', ':'), ('Proceedings', 'proceed'), ('ACM', 'acm'), ('International', 'intern'), ('Conference', 'confer'), ('Conference', 'confer'), ('Information', 'inform'), ('Knowledge', 'knowledg'), ('Management', 'manag'), (',', ','), ('2014.', '2014.'), ('pp', 'pp'), ('1–10', '1–10'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), (':', ':'), ('Proceedings', 'Proceedings'), ('ACM', 'ACM'), ('International', 'International'), ('Conference', 'Conference'), ('Conference', 'Conference'), ('Information', 'Information'), ('Knowledge', 'Knowledge'), ('Management', 'Management'), (',', ','), ('2014.', '2014.'), ('pp', 'pp'), ('1–10', '1–10'), ('.', '.')]



========================================== PARAGRAPH 526 ===========================================

 138. Zhao JM, Wang WS, Liu X, Chen YF. Big data benchmark ‑ big DS. In: Proceedings of the Advancing Big Data  Benchmarks, 2014, pp. 49–57. 

------------------- Sentence 1 -------------------

 138.

>> Tokens are: 
 ['138', '.']

>> Bigrams are: 
 [('138', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('138', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('138', '138'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('138', '138'), ('.', '.')]

>> Lemmatization: 
 [('138', '138'), ('.', '.')]


------------------- Sentence 2 -------------------

Zhao JM, Wang WS, Liu X, Chen YF.

>> Tokens are: 
 ['Zhao', 'JM', ',', 'Wang', 'WS', ',', 'Liu', 'X', ',', 'Chen', 'YF', '.']

>> Bigrams are: 
 [('Zhao', 'JM'), ('JM', ','), (',', 'Wang'), ('Wang', 'WS'), ('WS', ','), (',', 'Liu'), ('Liu', 'X'), ('X', ','), (',', 'Chen'), ('Chen', 'YF'), ('YF', '.')]

>> Trigrams are: 
 [('Zhao', 'JM', ','), ('JM', ',', 'Wang'), (',', 'Wang', 'WS'), ('Wang', 'WS', ','), ('WS', ',', 'Liu'), (',', 'Liu', 'X'), ('Liu', 'X', ','), ('X', ',', 'Chen'), (',', 'Chen', 'YF'), ('Chen', 'YF', '.')]

>> POS Tags are: 
 [('Zhao', 'NNP'), ('JM', 'NNP'), (',', ','), ('Wang', 'NNP'), ('WS', 'NNP'), (',', ','), ('Liu', 'NNP'), ('X', 'NNP'), (',', ','), ('Chen', 'NNP'), ('YF', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Zhao JM', 'Wang WS', 'Liu X', 'Chen YF']

>> Named Entities are: 
 [('PERSON', 'Zhao'), ('GPE', 'JM'), ('PERSON', 'Wang WS'), ('PERSON', 'Liu X'), ('PERSON', 'Chen YF')] 

>> Stemming using Porter Stemmer: 
 [('Zhao', 'zhao'), ('JM', 'jm'), (',', ','), ('Wang', 'wang'), ('WS', 'ws'), (',', ','), ('Liu', 'liu'), ('X', 'x'), (',', ','), ('Chen', 'chen'), ('YF', 'yf'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Zhao', 'zhao'), ('JM', 'jm'), (',', ','), ('Wang', 'wang'), ('WS', 'ws'), (',', ','), ('Liu', 'liu'), ('X', 'x'), (',', ','), ('Chen', 'chen'), ('YF', 'yf'), ('.', '.')]

>> Lemmatization: 
 [('Zhao', 'Zhao'), ('JM', 'JM'), (',', ','), ('Wang', 'Wang'), ('WS', 'WS'), (',', ','), ('Liu', 'Liu'), ('X', 'X'), (',', ','), ('Chen', 'Chen'), ('YF', 'YF'), ('.', '.')]


------------------- Sentence 3 -------------------

Big data benchmark ‑ big DS.

>> Tokens are: 
 ['Big', 'data', 'benchmark', '‑', 'big', 'DS', '.']

>> Bigrams are: 
 [('Big', 'data'), ('data', 'benchmark'), ('benchmark', '‑'), ('‑', 'big'), ('big', 'DS'), ('DS', '.')]

>> Trigrams are: 
 [('Big', 'data', 'benchmark'), ('data', 'benchmark', '‑'), ('benchmark', '‑', 'big'), ('‑', 'big', 'DS'), ('big', 'DS', '.')]

>> POS Tags are: 
 [('Big', 'NNP'), ('data', 'NNS'), ('benchmark', 'NN'), ('‑', 'NNP'), ('big', 'JJ'), ('DS', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Big data benchmark ‑', 'big DS']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('benchmark', 'benchmark'), ('‑', '‑'), ('big', 'big'), ('DS', 'ds'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('benchmark', 'benchmark'), ('‑', '‑'), ('big', 'big'), ('DS', 'ds'), ('.', '.')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), ('benchmark', 'benchmark'), ('‑', '‑'), ('big', 'big'), ('DS', 'DS'), ('.', '.')]


------------------- Sentence 4 -------------------

In: Proceedings of the Advancing Big Data  Benchmarks, 2014, pp.

>> Tokens are: 
 ['In', ':', 'Proceedings', 'Advancing', 'Big', 'Data', 'Benchmarks', ',', '2014', ',', 'pp', '.']

>> Bigrams are: 
 [('In', ':'), (':', 'Proceedings'), ('Proceedings', 'Advancing'), ('Advancing', 'Big'), ('Big', 'Data'), ('Data', 'Benchmarks'), ('Benchmarks', ','), (',', '2014'), ('2014', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('In', ':', 'Proceedings'), (':', 'Proceedings', 'Advancing'), ('Proceedings', 'Advancing', 'Big'), ('Advancing', 'Big', 'Data'), ('Big', 'Data', 'Benchmarks'), ('Data', 'Benchmarks', ','), ('Benchmarks', ',', '2014'), (',', '2014', ','), ('2014', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('In', 'IN'), (':', ':'), ('Proceedings', 'NNS'), ('Advancing', 'VBG'), ('Big', 'NNP'), ('Data', 'NNP'), ('Benchmarks', 'NNP'), (',', ','), ('2014', 'CD'), (',', ','), ('pp', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Proceedings', 'Big Data Benchmarks', 'pp']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), (':', ':'), ('Proceedings', 'proceed'), ('Advancing', 'advanc'), ('Big', 'big'), ('Data', 'data'), ('Benchmarks', 'benchmark'), (',', ','), ('2014', '2014'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), (':', ':'), ('Proceedings', 'proceed'), ('Advancing', 'advanc'), ('Big', 'big'), ('Data', 'data'), ('Benchmarks', 'benchmark'), (',', ','), ('2014', '2014'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), (':', ':'), ('Proceedings', 'Proceedings'), ('Advancing', 'Advancing'), ('Big', 'Big'), ('Data', 'Data'), ('Benchmarks', 'Benchmarks'), (',', ','), ('2014', '2014'), (',', ','), ('pp', 'pp'), ('.', '.')]


------------------- Sentence 5 -------------------

49–57.

>> Tokens are: 
 ['49–57', '.']

>> Bigrams are: 
 [('49–57', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('49–57', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('49–57', '49–57'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('49–57', '49–57'), ('.', '.')]

>> Lemmatization: 
 [('49–57', '49–57'), ('.', '.')]



========================================== PARAGRAPH 527 ===========================================

 139.  Saletore V, Krishnan K, Viswanathan V, Tolentino M. HcBench: Methodology, development, and full‑system charac‑ terization of a customer usage representative big data/hadoop benchmark. In: Advancing Big Data Benchmarks,  2014. pp 73–93. 

------------------- Sentence 1 -------------------

 139.

>> Tokens are: 
 ['139', '.']

>> Bigrams are: 
 [('139', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('139', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('139', '139'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('139', '139'), ('.', '.')]

>> Lemmatization: 
 [('139', '139'), ('.', '.')]


------------------- Sentence 2 -------------------

Saletore V, Krishnan K, Viswanathan V, Tolentino M. HcBench: Methodology, development, and full‑system charac‑ terization of a customer usage representative big data/hadoop benchmark.

>> Tokens are: 
 ['Saletore', 'V', ',', 'Krishnan', 'K', ',', 'Viswanathan', 'V', ',', 'Tolentino', 'M.', 'HcBench', ':', 'Methodology', ',', 'development', ',', 'full‑system', 'charac‑', 'terization', 'customer', 'usage', 'representative', 'big', 'data/hadoop', 'benchmark', '.']

>> Bigrams are: 
 [('Saletore', 'V'), ('V', ','), (',', 'Krishnan'), ('Krishnan', 'K'), ('K', ','), (',', 'Viswanathan'), ('Viswanathan', 'V'), ('V', ','), (',', 'Tolentino'), ('Tolentino', 'M.'), ('M.', 'HcBench'), ('HcBench', ':'), (':', 'Methodology'), ('Methodology', ','), (',', 'development'), ('development', ','), (',', 'full‑system'), ('full‑system', 'charac‑'), ('charac‑', 'terization'), ('terization', 'customer'), ('customer', 'usage'), ('usage', 'representative'), ('representative', 'big'), ('big', 'data/hadoop'), ('data/hadoop', 'benchmark'), ('benchmark', '.')]

>> Trigrams are: 
 [('Saletore', 'V', ','), ('V', ',', 'Krishnan'), (',', 'Krishnan', 'K'), ('Krishnan', 'K', ','), ('K', ',', 'Viswanathan'), (',', 'Viswanathan', 'V'), ('Viswanathan', 'V', ','), ('V', ',', 'Tolentino'), (',', 'Tolentino', 'M.'), ('Tolentino', 'M.', 'HcBench'), ('M.', 'HcBench', ':'), ('HcBench', ':', 'Methodology'), (':', 'Methodology', ','), ('Methodology', ',', 'development'), (',', 'development', ','), ('development', ',', 'full‑system'), (',', 'full‑system', 'charac‑'), ('full‑system', 'charac‑', 'terization'), ('charac‑', 'terization', 'customer'), ('terization', 'customer', 'usage'), ('customer', 'usage', 'representative'), ('usage', 'representative', 'big'), ('representative', 'big', 'data/hadoop'), ('big', 'data/hadoop', 'benchmark'), ('data/hadoop', 'benchmark', '.')]

>> POS Tags are: 
 [('Saletore', 'NNP'), ('V', 'NNP'), (',', ','), ('Krishnan', 'NNP'), ('K', 'NNP'), (',', ','), ('Viswanathan', 'NNP'), ('V', 'NNP'), (',', ','), ('Tolentino', 'NNP'), ('M.', 'NNP'), ('HcBench', 'NNP'), (':', ':'), ('Methodology', 'NN'), (',', ','), ('development', 'NN'), (',', ','), ('full‑system', 'NN'), ('charac‑', 'NN'), ('terization', 'NN'), ('customer', 'NN'), ('usage', 'NN'), ('representative', 'JJ'), ('big', 'JJ'), ('data/hadoop', 'NN'), ('benchmark', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Saletore V', 'Krishnan K', 'Viswanathan V', 'Tolentino M. HcBench', 'Methodology', 'development', 'full‑system charac‑ terization customer usage', 'representative big data/hadoop benchmark']

>> Named Entities are: 
 [('PERSON', 'Saletore V'), ('PERSON', 'Krishnan K'), ('PERSON', 'Viswanathan V'), ('PERSON', 'Tolentino M.'), ('ORGANIZATION', 'Methodology')] 

>> Stemming using Porter Stemmer: 
 [('Saletore', 'saletor'), ('V', 'v'), (',', ','), ('Krishnan', 'krishnan'), ('K', 'k'), (',', ','), ('Viswanathan', 'viswanathan'), ('V', 'v'), (',', ','), ('Tolentino', 'tolentino'), ('M.', 'm.'), ('HcBench', 'hcbench'), (':', ':'), ('Methodology', 'methodolog'), (',', ','), ('development', 'develop'), (',', ','), ('full‑system', 'full‑system'), ('charac‑', 'charac‑'), ('terization', 'teriz'), ('customer', 'custom'), ('usage', 'usag'), ('representative', 'repres'), ('big', 'big'), ('data/hadoop', 'data/hadoop'), ('benchmark', 'benchmark'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Saletore', 'saletor'), ('V', 'v'), (',', ','), ('Krishnan', 'krishnan'), ('K', 'k'), (',', ','), ('Viswanathan', 'viswanathan'), ('V', 'v'), (',', ','), ('Tolentino', 'tolentino'), ('M.', 'm.'), ('HcBench', 'hcbench'), (':', ':'), ('Methodology', 'methodolog'), (',', ','), ('development', 'develop'), (',', ','), ('full‑system', 'full‑system'), ('charac‑', 'charac‑'), ('terization', 'terize'), ('customer', 'custom'), ('usage', 'usag'), ('representative', 'repres'), ('big', 'big'), ('data/hadoop', 'data/hadoop'), ('benchmark', 'benchmark'), ('.', '.')]

>> Lemmatization: 
 [('Saletore', 'Saletore'), ('V', 'V'), (',', ','), ('Krishnan', 'Krishnan'), ('K', 'K'), (',', ','), ('Viswanathan', 'Viswanathan'), ('V', 'V'), (',', ','), ('Tolentino', 'Tolentino'), ('M.', 'M.'), ('HcBench', 'HcBench'), (':', ':'), ('Methodology', 'Methodology'), (',', ','), ('development', 'development'), (',', ','), ('full‑system', 'full‑system'), ('charac‑', 'charac‑'), ('terization', 'terization'), ('customer', 'customer'), ('usage', 'usage'), ('representative', 'representative'), ('big', 'big'), ('data/hadoop', 'data/hadoop'), ('benchmark', 'benchmark'), ('.', '.')]


------------------- Sentence 3 -------------------

In: Advancing Big Data Benchmarks,  2014. pp 73–93.

>> Tokens are: 
 ['In', ':', 'Advancing', 'Big', 'Data', 'Benchmarks', ',', '2014.', 'pp', '73–93', '.']

>> Bigrams are: 
 [('In', ':'), (':', 'Advancing'), ('Advancing', 'Big'), ('Big', 'Data'), ('Data', 'Benchmarks'), ('Benchmarks', ','), (',', '2014.'), ('2014.', 'pp'), ('pp', '73–93'), ('73–93', '.')]

>> Trigrams are: 
 [('In', ':', 'Advancing'), (':', 'Advancing', 'Big'), ('Advancing', 'Big', 'Data'), ('Big', 'Data', 'Benchmarks'), ('Data', 'Benchmarks', ','), ('Benchmarks', ',', '2014.'), (',', '2014.', 'pp'), ('2014.', 'pp', '73–93'), ('pp', '73–93', '.')]

>> POS Tags are: 
 [('In', 'IN'), (':', ':'), ('Advancing', 'VBG'), ('Big', 'NNP'), ('Data', 'NNP'), ('Benchmarks', 'NNP'), (',', ','), ('2014.', 'CD'), ('pp', 'NN'), ('73–93', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Big Data Benchmarks', 'pp']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), (':', ':'), ('Advancing', 'advanc'), ('Big', 'big'), ('Data', 'data'), ('Benchmarks', 'benchmark'), (',', ','), ('2014.', '2014.'), ('pp', 'pp'), ('73–93', '73–93'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), (':', ':'), ('Advancing', 'advanc'), ('Big', 'big'), ('Data', 'data'), ('Benchmarks', 'benchmark'), (',', ','), ('2014.', '2014.'), ('pp', 'pp'), ('73–93', '73–93'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), (':', ':'), ('Advancing', 'Advancing'), ('Big', 'Big'), ('Data', 'Data'), ('Benchmarks', 'Benchmarks'), (',', ','), ('2014.', '2014.'), ('pp', 'pp'), ('73–93', '73–93'), ('.', '.')]



========================================== PARAGRAPH 528 ===========================================

 140. Zhang L, Stoffel A, Behrisch M,  Mittelstadt S, Schreck T, Pompl R, Weber S, Last H, Keim D. Visual analytics for the  big data era—a comparative review of state‑of‑the‑art commercial systems. In: Proceedings of the IEEE Confer‑ ence on Visual Analytics Science and Technology, 2012. pp 173–182. 

------------------- Sentence 1 -------------------

 140.

>> Tokens are: 
 ['140', '.']

>> Bigrams are: 
 [('140', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('140', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('140', '140'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('140', '140'), ('.', '.')]

>> Lemmatization: 
 [('140', '140'), ('.', '.')]


------------------- Sentence 2 -------------------

Zhang L, Stoffel A, Behrisch M,  Mittelstadt S, Schreck T, Pompl R, Weber S, Last H, Keim D. Visual analytics for the  big data era—a comparative review of state‑of‑the‑art commercial systems.

>> Tokens are: 
 ['Zhang', 'L', ',', 'Stoffel', 'A', ',', 'Behrisch', 'M', ',', 'Mittelstadt', 'S', ',', 'Schreck', 'T', ',', 'Pompl', 'R', ',', 'Weber', 'S', ',', 'Last', 'H', ',', 'Keim', 'D.', 'Visual', 'analytics', 'big', 'data', 'era—a', 'comparative', 'review', 'state‑of‑the‑art', 'commercial', 'systems', '.']

>> Bigrams are: 
 [('Zhang', 'L'), ('L', ','), (',', 'Stoffel'), ('Stoffel', 'A'), ('A', ','), (',', 'Behrisch'), ('Behrisch', 'M'), ('M', ','), (',', 'Mittelstadt'), ('Mittelstadt', 'S'), ('S', ','), (',', 'Schreck'), ('Schreck', 'T'), ('T', ','), (',', 'Pompl'), ('Pompl', 'R'), ('R', ','), (',', 'Weber'), ('Weber', 'S'), ('S', ','), (',', 'Last'), ('Last', 'H'), ('H', ','), (',', 'Keim'), ('Keim', 'D.'), ('D.', 'Visual'), ('Visual', 'analytics'), ('analytics', 'big'), ('big', 'data'), ('data', 'era—a'), ('era—a', 'comparative'), ('comparative', 'review'), ('review', 'state‑of‑the‑art'), ('state‑of‑the‑art', 'commercial'), ('commercial', 'systems'), ('systems', '.')]

>> Trigrams are: 
 [('Zhang', 'L', ','), ('L', ',', 'Stoffel'), (',', 'Stoffel', 'A'), ('Stoffel', 'A', ','), ('A', ',', 'Behrisch'), (',', 'Behrisch', 'M'), ('Behrisch', 'M', ','), ('M', ',', 'Mittelstadt'), (',', 'Mittelstadt', 'S'), ('Mittelstadt', 'S', ','), ('S', ',', 'Schreck'), (',', 'Schreck', 'T'), ('Schreck', 'T', ','), ('T', ',', 'Pompl'), (',', 'Pompl', 'R'), ('Pompl', 'R', ','), ('R', ',', 'Weber'), (',', 'Weber', 'S'), ('Weber', 'S', ','), ('S', ',', 'Last'), (',', 'Last', 'H'), ('Last', 'H', ','), ('H', ',', 'Keim'), (',', 'Keim', 'D.'), ('Keim', 'D.', 'Visual'), ('D.', 'Visual', 'analytics'), ('Visual', 'analytics', 'big'), ('analytics', 'big', 'data'), ('big', 'data', 'era—a'), ('data', 'era—a', 'comparative'), ('era—a', 'comparative', 'review'), ('comparative', 'review', 'state‑of‑the‑art'), ('review', 'state‑of‑the‑art', 'commercial'), ('state‑of‑the‑art', 'commercial', 'systems'), ('commercial', 'systems', '.')]

>> POS Tags are: 
 [('Zhang', 'NNP'), ('L', 'NNP'), (',', ','), ('Stoffel', 'NNP'), ('A', 'NNP'), (',', ','), ('Behrisch', 'NNP'), ('M', 'NNP'), (',', ','), ('Mittelstadt', 'NNP'), ('S', 'NNP'), (',', ','), ('Schreck', 'NNP'), ('T', 'NNP'), (',', ','), ('Pompl', 'NNP'), ('R', 'NNP'), (',', ','), ('Weber', 'NNP'), ('S', 'NNP'), (',', ','), ('Last', 'JJ'), ('H', 'NNP'), (',', ','), ('Keim', 'NNP'), ('D.', 'NNP'), ('Visual', 'NNP'), ('analytics', 'NNS'), ('big', 'JJ'), ('data', 'NNS'), ('era—a', 'RB'), ('comparative', 'JJ'), ('review', 'NN'), ('state‑of‑the‑art', 'JJ'), ('commercial', 'JJ'), ('systems', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['Zhang L', 'Stoffel A', 'Behrisch M', 'Mittelstadt S', 'Schreck T', 'Pompl R', 'Weber S', 'Last H', 'Keim D. Visual analytics', 'big data', 'comparative review', 'state‑of‑the‑art commercial systems']

>> Named Entities are: 
 [('PERSON', 'Zhang'), ('ORGANIZATION', 'L'), ('PERSON', 'Stoffel A'), ('PERSON', 'Behrisch M'), ('PERSON', 'Mittelstadt S'), ('PERSON', 'Schreck T'), ('PERSON', 'Pompl R'), ('PERSON', 'Weber S'), ('PERSON', 'Last H'), ('PERSON', 'Keim D. Visual')] 

>> Stemming using Porter Stemmer: 
 [('Zhang', 'zhang'), ('L', 'l'), (',', ','), ('Stoffel', 'stoffel'), ('A', 'a'), (',', ','), ('Behrisch', 'behrisch'), ('M', 'm'), (',', ','), ('Mittelstadt', 'mittelstadt'), ('S', 's'), (',', ','), ('Schreck', 'schreck'), ('T', 't'), (',', ','), ('Pompl', 'pompl'), ('R', 'r'), (',', ','), ('Weber', 'weber'), ('S', 's'), (',', ','), ('Last', 'last'), ('H', 'h'), (',', ','), ('Keim', 'keim'), ('D.', 'd.'), ('Visual', 'visual'), ('analytics', 'analyt'), ('big', 'big'), ('data', 'data'), ('era—a', 'era—a'), ('comparative', 'compar'), ('review', 'review'), ('state‑of‑the‑art', 'state‑of‑the‑art'), ('commercial', 'commerci'), ('systems', 'system'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Zhang', 'zhang'), ('L', 'l'), (',', ','), ('Stoffel', 'stoffel'), ('A', 'a'), (',', ','), ('Behrisch', 'behrisch'), ('M', 'm'), (',', ','), ('Mittelstadt', 'mittelstadt'), ('S', 's'), (',', ','), ('Schreck', 'schreck'), ('T', 't'), (',', ','), ('Pompl', 'pompl'), ('R', 'r'), (',', ','), ('Weber', 'weber'), ('S', 's'), (',', ','), ('Last', 'last'), ('H', 'h'), (',', ','), ('Keim', 'keim'), ('D.', 'd.'), ('Visual', 'visual'), ('analytics', 'analyt'), ('big', 'big'), ('data', 'data'), ('era—a', 'era—a'), ('comparative', 'compar'), ('review', 'review'), ('state‑of‑the‑art', 'state‑of‑the‑art'), ('commercial', 'commerci'), ('systems', 'system'), ('.', '.')]

>> Lemmatization: 
 [('Zhang', 'Zhang'), ('L', 'L'), (',', ','), ('Stoffel', 'Stoffel'), ('A', 'A'), (',', ','), ('Behrisch', 'Behrisch'), ('M', 'M'), (',', ','), ('Mittelstadt', 'Mittelstadt'), ('S', 'S'), (',', ','), ('Schreck', 'Schreck'), ('T', 'T'), (',', ','), ('Pompl', 'Pompl'), ('R', 'R'), (',', ','), ('Weber', 'Weber'), ('S', 'S'), (',', ','), ('Last', 'Last'), ('H', 'H'), (',', ','), ('Keim', 'Keim'), ('D.', 'D.'), ('Visual', 'Visual'), ('analytics', 'analytics'), ('big', 'big'), ('data', 'data'), ('era—a', 'era—a'), ('comparative', 'comparative'), ('review', 'review'), ('state‑of‑the‑art', 'state‑of‑the‑art'), ('commercial', 'commercial'), ('systems', 'system'), ('.', '.')]


------------------- Sentence 3 -------------------

In: Proceedings of the IEEE Confer‑ ence on Visual Analytics Science and Technology, 2012. pp 173–182.

>> Tokens are: 
 ['In', ':', 'Proceedings', 'IEEE', 'Confer‑', 'ence', 'Visual', 'Analytics', 'Science', 'Technology', ',', '2012.', 'pp', '173–182', '.']

>> Bigrams are: 
 [('In', ':'), (':', 'Proceedings'), ('Proceedings', 'IEEE'), ('IEEE', 'Confer‑'), ('Confer‑', 'ence'), ('ence', 'Visual'), ('Visual', 'Analytics'), ('Analytics', 'Science'), ('Science', 'Technology'), ('Technology', ','), (',', '2012.'), ('2012.', 'pp'), ('pp', '173–182'), ('173–182', '.')]

>> Trigrams are: 
 [('In', ':', 'Proceedings'), (':', 'Proceedings', 'IEEE'), ('Proceedings', 'IEEE', 'Confer‑'), ('IEEE', 'Confer‑', 'ence'), ('Confer‑', 'ence', 'Visual'), ('ence', 'Visual', 'Analytics'), ('Visual', 'Analytics', 'Science'), ('Analytics', 'Science', 'Technology'), ('Science', 'Technology', ','), ('Technology', ',', '2012.'), (',', '2012.', 'pp'), ('2012.', 'pp', '173–182'), ('pp', '173–182', '.')]

>> POS Tags are: 
 [('In', 'IN'), (':', ':'), ('Proceedings', 'NNS'), ('IEEE', 'NNP'), ('Confer‑', 'NNP'), ('ence', 'NN'), ('Visual', 'NNP'), ('Analytics', 'NNP'), ('Science', 'NNP'), ('Technology', 'NNP'), (',', ','), ('2012.', 'CD'), ('pp', 'NN'), ('173–182', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Proceedings IEEE Confer‑ ence Visual Analytics Science Technology', 'pp']

>> Named Entities are: 
 [('ORGANIZATION', 'IEEE'), ('PERSON', 'Visual Analytics Science Technology')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), (':', ':'), ('Proceedings', 'proceed'), ('IEEE', 'ieee'), ('Confer‑', 'confer‑'), ('ence', 'enc'), ('Visual', 'visual'), ('Analytics', 'analyt'), ('Science', 'scienc'), ('Technology', 'technolog'), (',', ','), ('2012.', '2012.'), ('pp', 'pp'), ('173–182', '173–182'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), (':', ':'), ('Proceedings', 'proceed'), ('IEEE', 'ieee'), ('Confer‑', 'confer‑'), ('ence', 'enc'), ('Visual', 'visual'), ('Analytics', 'analyt'), ('Science', 'scienc'), ('Technology', 'technolog'), (',', ','), ('2012.', '2012.'), ('pp', 'pp'), ('173–182', '173–182'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), (':', ':'), ('Proceedings', 'Proceedings'), ('IEEE', 'IEEE'), ('Confer‑', 'Confer‑'), ('ence', 'ence'), ('Visual', 'Visual'), ('Analytics', 'Analytics'), ('Science', 'Science'), ('Technology', 'Technology'), (',', ','), ('2012.', '2012.'), ('pp', 'pp'), ('173–182', '173–182'), ('.', '.')]



========================================== PARAGRAPH 529 ===========================================

 141. Harati A, Lopez S, Obeid I, Picone J, Jacobson M, Tobochnik S. The TUH EEG CORPUS: A big data resource for auto‑ mated eeg interpretation. In: Proceeding of the IEEE Signal Processing in Medicine and Biology Symposium, 2014.  pp 1–5. 

------------------- Sentence 1 -------------------

 141.

>> Tokens are: 
 ['141', '.']

>> Bigrams are: 
 [('141', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('141', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('141', '141'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('141', '141'), ('.', '.')]

>> Lemmatization: 
 [('141', '141'), ('.', '.')]


------------------- Sentence 2 -------------------

Harati A, Lopez S, Obeid I, Picone J, Jacobson M, Tobochnik S. The TUH EEG CORPUS: A big data resource for auto‑ mated eeg interpretation.

>> Tokens are: 
 ['Harati', 'A', ',', 'Lopez', 'S', ',', 'Obeid', 'I', ',', 'Picone', 'J', ',', 'Jacobson', 'M', ',', 'Tobochnik', 'S.', 'The', 'TUH', 'EEG', 'CORPUS', ':', 'A', 'big', 'data', 'resource', 'auto‑', 'mated', 'eeg', 'interpretation', '.']

>> Bigrams are: 
 [('Harati', 'A'), ('A', ','), (',', 'Lopez'), ('Lopez', 'S'), ('S', ','), (',', 'Obeid'), ('Obeid', 'I'), ('I', ','), (',', 'Picone'), ('Picone', 'J'), ('J', ','), (',', 'Jacobson'), ('Jacobson', 'M'), ('M', ','), (',', 'Tobochnik'), ('Tobochnik', 'S.'), ('S.', 'The'), ('The', 'TUH'), ('TUH', 'EEG'), ('EEG', 'CORPUS'), ('CORPUS', ':'), (':', 'A'), ('A', 'big'), ('big', 'data'), ('data', 'resource'), ('resource', 'auto‑'), ('auto‑', 'mated'), ('mated', 'eeg'), ('eeg', 'interpretation'), ('interpretation', '.')]

>> Trigrams are: 
 [('Harati', 'A', ','), ('A', ',', 'Lopez'), (',', 'Lopez', 'S'), ('Lopez', 'S', ','), ('S', ',', 'Obeid'), (',', 'Obeid', 'I'), ('Obeid', 'I', ','), ('I', ',', 'Picone'), (',', 'Picone', 'J'), ('Picone', 'J', ','), ('J', ',', 'Jacobson'), (',', 'Jacobson', 'M'), ('Jacobson', 'M', ','), ('M', ',', 'Tobochnik'), (',', 'Tobochnik', 'S.'), ('Tobochnik', 'S.', 'The'), ('S.', 'The', 'TUH'), ('The', 'TUH', 'EEG'), ('TUH', 'EEG', 'CORPUS'), ('EEG', 'CORPUS', ':'), ('CORPUS', ':', 'A'), (':', 'A', 'big'), ('A', 'big', 'data'), ('big', 'data', 'resource'), ('data', 'resource', 'auto‑'), ('resource', 'auto‑', 'mated'), ('auto‑', 'mated', 'eeg'), ('mated', 'eeg', 'interpretation'), ('eeg', 'interpretation', '.')]

>> POS Tags are: 
 [('Harati', 'NNP'), ('A', 'NNP'), (',', ','), ('Lopez', 'NNP'), ('S', 'NNP'), (',', ','), ('Obeid', 'NNP'), ('I', 'PRP'), (',', ','), ('Picone', 'NNP'), ('J', 'NNP'), (',', ','), ('Jacobson', 'NNP'), ('M', 'NNP'), (',', ','), ('Tobochnik', 'NNP'), ('S.', 'NNP'), ('The', 'DT'), ('TUH', 'NNP'), ('EEG', 'NNP'), ('CORPUS', 'NNP'), (':', ':'), ('A', 'DT'), ('big', 'JJ'), ('data', 'NNS'), ('resource', 'NN'), ('auto‑', 'NN'), ('mated', 'VBD'), ('eeg', 'JJ'), ('interpretation', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Harati A', 'Lopez S', 'Obeid', 'Picone J', 'Jacobson M', 'Tobochnik S.', 'The TUH EEG CORPUS', 'A big data resource auto‑', 'eeg interpretation']

>> Named Entities are: 
 [('PERSON', 'Harati'), ('PERSON', 'Lopez S'), ('PERSON', 'Obeid'), ('PERSON', 'Picone J'), ('PERSON', 'Jacobson M'), ('PERSON', 'Tobochnik'), ('ORGANIZATION', 'TUH')] 

>> Stemming using Porter Stemmer: 
 [('Harati', 'harati'), ('A', 'a'), (',', ','), ('Lopez', 'lopez'), ('S', 's'), (',', ','), ('Obeid', 'obeid'), ('I', 'i'), (',', ','), ('Picone', 'picon'), ('J', 'j'), (',', ','), ('Jacobson', 'jacobson'), ('M', 'm'), (',', ','), ('Tobochnik', 'tobochnik'), ('S.', 's.'), ('The', 'the'), ('TUH', 'tuh'), ('EEG', 'eeg'), ('CORPUS', 'corpu'), (':', ':'), ('A', 'a'), ('big', 'big'), ('data', 'data'), ('resource', 'resourc'), ('auto‑', 'auto‑'), ('mated', 'mate'), ('eeg', 'eeg'), ('interpretation', 'interpret'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Harati', 'harati'), ('A', 'a'), (',', ','), ('Lopez', 'lopez'), ('S', 's'), (',', ','), ('Obeid', 'obeid'), ('I', 'i'), (',', ','), ('Picone', 'picon'), ('J', 'j'), (',', ','), ('Jacobson', 'jacobson'), ('M', 'm'), (',', ','), ('Tobochnik', 'tobochnik'), ('S.', 's.'), ('The', 'the'), ('TUH', 'tuh'), ('EEG', 'eeg'), ('CORPUS', 'corpus'), (':', ':'), ('A', 'a'), ('big', 'big'), ('data', 'data'), ('resource', 'resourc'), ('auto‑', 'auto‑'), ('mated', 'mate'), ('eeg', 'eeg'), ('interpretation', 'interpret'), ('.', '.')]

>> Lemmatization: 
 [('Harati', 'Harati'), ('A', 'A'), (',', ','), ('Lopez', 'Lopez'), ('S', 'S'), (',', ','), ('Obeid', 'Obeid'), ('I', 'I'), (',', ','), ('Picone', 'Picone'), ('J', 'J'), (',', ','), ('Jacobson', 'Jacobson'), ('M', 'M'), (',', ','), ('Tobochnik', 'Tobochnik'), ('S.', 'S.'), ('The', 'The'), ('TUH', 'TUH'), ('EEG', 'EEG'), ('CORPUS', 'CORPUS'), (':', ':'), ('A', 'A'), ('big', 'big'), ('data', 'data'), ('resource', 'resource'), ('auto‑', 'auto‑'), ('mated', 'mated'), ('eeg', 'eeg'), ('interpretation', 'interpretation'), ('.', '.')]


------------------- Sentence 3 -------------------

In: Proceeding of the IEEE Signal Processing in Medicine and Biology Symposium, 2014.  pp 1–5.

>> Tokens are: 
 ['In', ':', 'Proceeding', 'IEEE', 'Signal', 'Processing', 'Medicine', 'Biology', 'Symposium', ',', '2014.', 'pp', '1–5', '.']

>> Bigrams are: 
 [('In', ':'), (':', 'Proceeding'), ('Proceeding', 'IEEE'), ('IEEE', 'Signal'), ('Signal', 'Processing'), ('Processing', 'Medicine'), ('Medicine', 'Biology'), ('Biology', 'Symposium'), ('Symposium', ','), (',', '2014.'), ('2014.', 'pp'), ('pp', '1–5'), ('1–5', '.')]

>> Trigrams are: 
 [('In', ':', 'Proceeding'), (':', 'Proceeding', 'IEEE'), ('Proceeding', 'IEEE', 'Signal'), ('IEEE', 'Signal', 'Processing'), ('Signal', 'Processing', 'Medicine'), ('Processing', 'Medicine', 'Biology'), ('Medicine', 'Biology', 'Symposium'), ('Biology', 'Symposium', ','), ('Symposium', ',', '2014.'), (',', '2014.', 'pp'), ('2014.', 'pp', '1–5'), ('pp', '1–5', '.')]

>> POS Tags are: 
 [('In', 'IN'), (':', ':'), ('Proceeding', 'VBG'), ('IEEE', 'NNP'), ('Signal', 'NNP'), ('Processing', 'NNP'), ('Medicine', 'NNP'), ('Biology', 'NNP'), ('Symposium', 'NNP'), (',', ','), ('2014.', 'CD'), ('pp', 'NN'), ('1–5', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['IEEE Signal Processing Medicine Biology Symposium', 'pp']

>> Named Entities are: 
 [('ORGANIZATION', 'IEEE Signal'), ('PERSON', 'Medicine Biology Symposium')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), (':', ':'), ('Proceeding', 'proceed'), ('IEEE', 'ieee'), ('Signal', 'signal'), ('Processing', 'process'), ('Medicine', 'medicin'), ('Biology', 'biolog'), ('Symposium', 'symposium'), (',', ','), ('2014.', '2014.'), ('pp', 'pp'), ('1–5', '1–5'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), (':', ':'), ('Proceeding', 'proceed'), ('IEEE', 'ieee'), ('Signal', 'signal'), ('Processing', 'process'), ('Medicine', 'medicin'), ('Biology', 'biolog'), ('Symposium', 'symposium'), (',', ','), ('2014.', '2014.'), ('pp', 'pp'), ('1–5', '1–5'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), (':', ':'), ('Proceeding', 'Proceeding'), ('IEEE', 'IEEE'), ('Signal', 'Signal'), ('Processing', 'Processing'), ('Medicine', 'Medicine'), ('Biology', 'Biology'), ('Symposium', 'Symposium'), (',', ','), ('2014.', '2014.'), ('pp', 'pp'), ('1–5', '1–5'), ('.', '.')]



========================================== PARAGRAPH 530 ===========================================

 142. Thusoo A, Sarma JS, Jain N, Shao Z, Chakka P, Anthony S, Liu H, Wyckoff P, Murthy R. Hive: a warehousing solution  over a map‑reduce framework. Proc VLDB Endowment. 2009;2(2):1626–9. 

------------------- Sentence 1 -------------------

 142.

>> Tokens are: 
 ['142', '.']

>> Bigrams are: 
 [('142', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('142', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('142', '142'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('142', '142'), ('.', '.')]

>> Lemmatization: 
 [('142', '142'), ('.', '.')]


------------------- Sentence 2 -------------------

Thusoo A, Sarma JS, Jain N, Shao Z, Chakka P, Anthony S, Liu H, Wyckoff P, Murthy R. Hive: a warehousing solution  over a map‑reduce framework.

>> Tokens are: 
 ['Thusoo', 'A', ',', 'Sarma', 'JS', ',', 'Jain', 'N', ',', 'Shao', 'Z', ',', 'Chakka', 'P', ',', 'Anthony', 'S', ',', 'Liu', 'H', ',', 'Wyckoff', 'P', ',', 'Murthy', 'R.', 'Hive', ':', 'warehousing', 'solution', 'map‑reduce', 'framework', '.']

>> Bigrams are: 
 [('Thusoo', 'A'), ('A', ','), (',', 'Sarma'), ('Sarma', 'JS'), ('JS', ','), (',', 'Jain'), ('Jain', 'N'), ('N', ','), (',', 'Shao'), ('Shao', 'Z'), ('Z', ','), (',', 'Chakka'), ('Chakka', 'P'), ('P', ','), (',', 'Anthony'), ('Anthony', 'S'), ('S', ','), (',', 'Liu'), ('Liu', 'H'), ('H', ','), (',', 'Wyckoff'), ('Wyckoff', 'P'), ('P', ','), (',', 'Murthy'), ('Murthy', 'R.'), ('R.', 'Hive'), ('Hive', ':'), (':', 'warehousing'), ('warehousing', 'solution'), ('solution', 'map‑reduce'), ('map‑reduce', 'framework'), ('framework', '.')]

>> Trigrams are: 
 [('Thusoo', 'A', ','), ('A', ',', 'Sarma'), (',', 'Sarma', 'JS'), ('Sarma', 'JS', ','), ('JS', ',', 'Jain'), (',', 'Jain', 'N'), ('Jain', 'N', ','), ('N', ',', 'Shao'), (',', 'Shao', 'Z'), ('Shao', 'Z', ','), ('Z', ',', 'Chakka'), (',', 'Chakka', 'P'), ('Chakka', 'P', ','), ('P', ',', 'Anthony'), (',', 'Anthony', 'S'), ('Anthony', 'S', ','), ('S', ',', 'Liu'), (',', 'Liu', 'H'), ('Liu', 'H', ','), ('H', ',', 'Wyckoff'), (',', 'Wyckoff', 'P'), ('Wyckoff', 'P', ','), ('P', ',', 'Murthy'), (',', 'Murthy', 'R.'), ('Murthy', 'R.', 'Hive'), ('R.', 'Hive', ':'), ('Hive', ':', 'warehousing'), (':', 'warehousing', 'solution'), ('warehousing', 'solution', 'map‑reduce'), ('solution', 'map‑reduce', 'framework'), ('map‑reduce', 'framework', '.')]

>> POS Tags are: 
 [('Thusoo', 'NNP'), ('A', 'NNP'), (',', ','), ('Sarma', 'NNP'), ('JS', 'NNP'), (',', ','), ('Jain', 'NNP'), ('N', 'NNP'), (',', ','), ('Shao', 'NNP'), ('Z', 'NNP'), (',', ','), ('Chakka', 'NNP'), ('P', 'NNP'), (',', ','), ('Anthony', 'NNP'), ('S', 'NNP'), (',', ','), ('Liu', 'NNP'), ('H', 'NNP'), (',', ','), ('Wyckoff', 'NNP'), ('P', 'NNP'), (',', ','), ('Murthy', 'NNP'), ('R.', 'NNP'), ('Hive', 'NNP'), (':', ':'), ('warehousing', 'JJ'), ('solution', 'NN'), ('map‑reduce', 'NN'), ('framework', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Thusoo A', 'Sarma JS', 'Jain N', 'Shao Z', 'Chakka P', 'Anthony S', 'Liu H', 'Wyckoff P', 'Murthy R. Hive', 'warehousing solution map‑reduce framework']

>> Named Entities are: 
 [('PERSON', 'Sarma JS'), ('PERSON', 'Jain N'), ('PERSON', 'Shao Z'), ('PERSON', 'Chakka P'), ('PERSON', 'Anthony S'), ('PERSON', 'Liu H'), ('PERSON', 'Wyckoff P'), ('PERSON', 'Murthy R.')] 

>> Stemming using Porter Stemmer: 
 [('Thusoo', 'thusoo'), ('A', 'a'), (',', ','), ('Sarma', 'sarma'), ('JS', 'js'), (',', ','), ('Jain', 'jain'), ('N', 'n'), (',', ','), ('Shao', 'shao'), ('Z', 'z'), (',', ','), ('Chakka', 'chakka'), ('P', 'p'), (',', ','), ('Anthony', 'anthoni'), ('S', 's'), (',', ','), ('Liu', 'liu'), ('H', 'h'), (',', ','), ('Wyckoff', 'wyckoff'), ('P', 'p'), (',', ','), ('Murthy', 'murthi'), ('R.', 'r.'), ('Hive', 'hive'), (':', ':'), ('warehousing', 'wareh'), ('solution', 'solut'), ('map‑reduce', 'map‑reduc'), ('framework', 'framework'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Thusoo', 'thusoo'), ('A', 'a'), (',', ','), ('Sarma', 'sarma'), ('JS', 'js'), (',', ','), ('Jain', 'jain'), ('N', 'n'), (',', ','), ('Shao', 'shao'), ('Z', 'z'), (',', ','), ('Chakka', 'chakka'), ('P', 'p'), (',', ','), ('Anthony', 'anthoni'), ('S', 's'), (',', ','), ('Liu', 'liu'), ('H', 'h'), (',', ','), ('Wyckoff', 'wyckoff'), ('P', 'p'), (',', ','), ('Murthy', 'murthi'), ('R.', 'r.'), ('Hive', 'hive'), (':', ':'), ('warehousing', 'wareh'), ('solution', 'solut'), ('map‑reduce', 'map‑reduc'), ('framework', 'framework'), ('.', '.')]

>> Lemmatization: 
 [('Thusoo', 'Thusoo'), ('A', 'A'), (',', ','), ('Sarma', 'Sarma'), ('JS', 'JS'), (',', ','), ('Jain', 'Jain'), ('N', 'N'), (',', ','), ('Shao', 'Shao'), ('Z', 'Z'), (',', ','), ('Chakka', 'Chakka'), ('P', 'P'), (',', ','), ('Anthony', 'Anthony'), ('S', 'S'), (',', ','), ('Liu', 'Liu'), ('H', 'H'), (',', ','), ('Wyckoff', 'Wyckoff'), ('P', 'P'), (',', ','), ('Murthy', 'Murthy'), ('R.', 'R.'), ('Hive', 'Hive'), (':', ':'), ('warehousing', 'warehousing'), ('solution', 'solution'), ('map‑reduce', 'map‑reduce'), ('framework', 'framework'), ('.', '.')]


------------------- Sentence 3 -------------------

Proc VLDB Endowment.

>> Tokens are: 
 ['Proc', 'VLDB', 'Endowment', '.']

>> Bigrams are: 
 [('Proc', 'VLDB'), ('VLDB', 'Endowment'), ('Endowment', '.')]

>> Trigrams are: 
 [('Proc', 'VLDB', 'Endowment'), ('VLDB', 'Endowment', '.')]

>> POS Tags are: 
 [('Proc', 'NNP'), ('VLDB', 'NNP'), ('Endowment', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Proc VLDB Endowment']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Proc', 'proc'), ('VLDB', 'vldb'), ('Endowment', 'endow'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Proc', 'proc'), ('VLDB', 'vldb'), ('Endowment', 'endow'), ('.', '.')]

>> Lemmatization: 
 [('Proc', 'Proc'), ('VLDB', 'VLDB'), ('Endowment', 'Endowment'), ('.', '.')]


------------------- Sentence 4 -------------------

2009;2(2):1626–9.

>> Tokens are: 
 ['2009', ';', '2', '(', '2', ')', ':1626–9', '.']

>> Bigrams are: 
 [('2009', ';'), (';', '2'), ('2', '('), ('(', '2'), ('2', ')'), (')', ':1626–9'), (':1626–9', '.')]

>> Trigrams are: 
 [('2009', ';', '2'), (';', '2', '('), ('2', '(', '2'), ('(', '2', ')'), ('2', ')', ':1626–9'), (')', ':1626–9', '.')]

>> POS Tags are: 
 [('2009', 'CD'), (';', ':'), ('2', 'CD'), ('(', '('), ('2', 'CD'), (')', ')'), (':1626–9', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 [':1626–9']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('2009', '2009'), (';', ';'), ('2', '2'), ('(', '('), ('2', '2'), (')', ')'), (':1626–9', ':1626–9'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('2009', '2009'), (';', ';'), ('2', '2'), ('(', '('), ('2', '2'), (')', ')'), (':1626–9', ':1626–9'), ('.', '.')]

>> Lemmatization: 
 [('2009', '2009'), (';', ';'), ('2', '2'), ('(', '('), ('2', '2'), (')', ')'), (':1626–9', ':1626–9'), ('.', '.')]



========================================== PARAGRAPH 531 ===========================================

 143. Beckmann M, Ebecken NFF, de Lima BSLP,Costa MA. A user interface for big data with rapidminer.  RapidMiner World, Boston, MA, Tech. Rep., 2014. [Online]. Available: http://www.slideshare.net/ RapidMiner/a‑user‑interface‑for‑big‑data‑with‑rapidminer‑marcelo‑beckmann. 

------------------- Sentence 1 -------------------

 143.

>> Tokens are: 
 ['143', '.']

>> Bigrams are: 
 [('143', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('143', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('143', '143'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('143', '143'), ('.', '.')]

>> Lemmatization: 
 [('143', '143'), ('.', '.')]


------------------- Sentence 2 -------------------

Beckmann M, Ebecken NFF, de Lima BSLP,Costa MA.

>> Tokens are: 
 ['Beckmann', 'M', ',', 'Ebecken', 'NFF', ',', 'de', 'Lima', 'BSLP', ',', 'Costa', 'MA', '.']

>> Bigrams are: 
 [('Beckmann', 'M'), ('M', ','), (',', 'Ebecken'), ('Ebecken', 'NFF'), ('NFF', ','), (',', 'de'), ('de', 'Lima'), ('Lima', 'BSLP'), ('BSLP', ','), (',', 'Costa'), ('Costa', 'MA'), ('MA', '.')]

>> Trigrams are: 
 [('Beckmann', 'M', ','), ('M', ',', 'Ebecken'), (',', 'Ebecken', 'NFF'), ('Ebecken', 'NFF', ','), ('NFF', ',', 'de'), (',', 'de', 'Lima'), ('de', 'Lima', 'BSLP'), ('Lima', 'BSLP', ','), ('BSLP', ',', 'Costa'), (',', 'Costa', 'MA'), ('Costa', 'MA', '.')]

>> POS Tags are: 
 [('Beckmann', 'NNP'), ('M', 'NNP'), (',', ','), ('Ebecken', 'NNP'), ('NFF', 'NNP'), (',', ','), ('de', 'FW'), ('Lima', 'NNP'), ('BSLP', 'NNP'), (',', ','), ('Costa', 'NNP'), ('MA', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Beckmann M', 'Ebecken NFF', 'Lima BSLP', 'Costa MA']

>> Named Entities are: 
 [('PERSON', 'Beckmann'), ('PERSON', 'Ebecken NFF'), ('PERSON', 'Lima BSLP'), ('PERSON', 'Costa MA')] 

>> Stemming using Porter Stemmer: 
 [('Beckmann', 'beckmann'), ('M', 'm'), (',', ','), ('Ebecken', 'ebecken'), ('NFF', 'nff'), (',', ','), ('de', 'de'), ('Lima', 'lima'), ('BSLP', 'bslp'), (',', ','), ('Costa', 'costa'), ('MA', 'ma'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Beckmann', 'beckmann'), ('M', 'm'), (',', ','), ('Ebecken', 'ebecken'), ('NFF', 'nff'), (',', ','), ('de', 'de'), ('Lima', 'lima'), ('BSLP', 'bslp'), (',', ','), ('Costa', 'costa'), ('MA', 'ma'), ('.', '.')]

>> Lemmatization: 
 [('Beckmann', 'Beckmann'), ('M', 'M'), (',', ','), ('Ebecken', 'Ebecken'), ('NFF', 'NFF'), (',', ','), ('de', 'de'), ('Lima', 'Lima'), ('BSLP', 'BSLP'), (',', ','), ('Costa', 'Costa'), ('MA', 'MA'), ('.', '.')]


------------------- Sentence 3 -------------------

A user interface for big data with rapidminer.

>> Tokens are: 
 ['A', 'user', 'interface', 'big', 'data', 'rapidminer', '.']

>> Bigrams are: 
 [('A', 'user'), ('user', 'interface'), ('interface', 'big'), ('big', 'data'), ('data', 'rapidminer'), ('rapidminer', '.')]

>> Trigrams are: 
 [('A', 'user', 'interface'), ('user', 'interface', 'big'), ('interface', 'big', 'data'), ('big', 'data', 'rapidminer'), ('data', 'rapidminer', '.')]

>> POS Tags are: 
 [('A', 'DT'), ('user', 'JJ'), ('interface', 'NN'), ('big', 'JJ'), ('data', 'NN'), ('rapidminer', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['A user interface', 'big data rapidminer']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('A', 'a'), ('user', 'user'), ('interface', 'interfac'), ('big', 'big'), ('data', 'data'), ('rapidminer', 'rapidmin'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('A', 'a'), ('user', 'user'), ('interface', 'interfac'), ('big', 'big'), ('data', 'data'), ('rapidminer', 'rapidmin'), ('.', '.')]

>> Lemmatization: 
 [('A', 'A'), ('user', 'user'), ('interface', 'interface'), ('big', 'big'), ('data', 'data'), ('rapidminer', 'rapidminer'), ('.', '.')]


------------------- Sentence 4 -------------------

RapidMiner World, Boston, MA, Tech.

>> Tokens are: 
 ['RapidMiner', 'World', ',', 'Boston', ',', 'MA', ',', 'Tech', '.']

>> Bigrams are: 
 [('RapidMiner', 'World'), ('World', ','), (',', 'Boston'), ('Boston', ','), (',', 'MA'), ('MA', ','), (',', 'Tech'), ('Tech', '.')]

>> Trigrams are: 
 [('RapidMiner', 'World', ','), ('World', ',', 'Boston'), (',', 'Boston', ','), ('Boston', ',', 'MA'), (',', 'MA', ','), ('MA', ',', 'Tech'), (',', 'Tech', '.')]

>> POS Tags are: 
 [('RapidMiner', 'NNP'), ('World', 'NNP'), (',', ','), ('Boston', 'NNP'), (',', ','), ('MA', 'NNP'), (',', ','), ('Tech', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['RapidMiner World', 'Boston', 'MA', 'Tech']

>> Named Entities are: 
 [('ORGANIZATION', 'RapidMiner'), ('GPE', 'World'), ('GPE', 'Boston'), ('ORGANIZATION', 'MA'), ('GPE', 'Tech')] 

>> Stemming using Porter Stemmer: 
 [('RapidMiner', 'rapidmin'), ('World', 'world'), (',', ','), ('Boston', 'boston'), (',', ','), ('MA', 'ma'), (',', ','), ('Tech', 'tech'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('RapidMiner', 'rapidmin'), ('World', 'world'), (',', ','), ('Boston', 'boston'), (',', ','), ('MA', 'ma'), (',', ','), ('Tech', 'tech'), ('.', '.')]

>> Lemmatization: 
 [('RapidMiner', 'RapidMiner'), ('World', 'World'), (',', ','), ('Boston', 'Boston'), (',', ','), ('MA', 'MA'), (',', ','), ('Tech', 'Tech'), ('.', '.')]


------------------- Sentence 5 -------------------

Rep., 2014.

>> Tokens are: 
 ['Rep.', ',', '2014', '.']

>> Bigrams are: 
 [('Rep.', ','), (',', '2014'), ('2014', '.')]

>> Trigrams are: 
 [('Rep.', ',', '2014'), (',', '2014', '.')]

>> POS Tags are: 
 [('Rep.', 'NNP'), (',', ','), ('2014', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Rep.']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Rep.', 'rep.'), (',', ','), ('2014', '2014'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Rep.', 'rep.'), (',', ','), ('2014', '2014'), ('.', '.')]

>> Lemmatization: 
 [('Rep.', 'Rep.'), (',', ','), ('2014', '2014'), ('.', '.')]


------------------- Sentence 6 -------------------

[Online].

>> Tokens are: 
 ['[', 'Online', ']', '.']

>> Bigrams are: 
 [('[', 'Online'), ('Online', ']'), (']', '.')]

>> Trigrams are: 
 [('[', 'Online', ']'), ('Online', ']', '.')]

>> POS Tags are: 
 [('[', 'JJ'), ('Online', 'NNP'), (']', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['[ Online ]']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('[', '['), ('Online', 'onlin'), (']', ']'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('[', '['), ('Online', 'onlin'), (']', ']'), ('.', '.')]

>> Lemmatization: 
 [('[', '['), ('Online', 'Online'), (']', ']'), ('.', '.')]


------------------- Sentence 7 -------------------

Available: http://www.slideshare.net/ RapidMiner/a‑user‑interface‑for‑big‑data‑with‑rapidminer‑marcelo‑beckmann.

>> Tokens are: 
 ['Available', ':', 'http', ':', '//www.slideshare.net/', 'RapidMiner/a‑user‑interface‑for‑big‑data‑with‑rapidminer‑marcelo‑beckmann', '.']

>> Bigrams are: 
 [('Available', ':'), (':', 'http'), ('http', ':'), (':', '//www.slideshare.net/'), ('//www.slideshare.net/', 'RapidMiner/a‑user‑interface‑for‑big‑data‑with‑rapidminer‑marcelo‑beckmann'), ('RapidMiner/a‑user‑interface‑for‑big‑data‑with‑rapidminer‑marcelo‑beckmann', '.')]

>> Trigrams are: 
 [('Available', ':', 'http'), (':', 'http', ':'), ('http', ':', '//www.slideshare.net/'), (':', '//www.slideshare.net/', 'RapidMiner/a‑user‑interface‑for‑big‑data‑with‑rapidminer‑marcelo‑beckmann'), ('//www.slideshare.net/', 'RapidMiner/a‑user‑interface‑for‑big‑data‑with‑rapidminer‑marcelo‑beckmann', '.')]

>> POS Tags are: 
 [('Available', 'JJ'), (':', ':'), ('http', 'NN'), (':', ':'), ('//www.slideshare.net/', 'JJ'), ('RapidMiner/a‑user‑interface‑for‑big‑data‑with‑rapidminer‑marcelo‑beckmann', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['http', '//www.slideshare.net/ RapidMiner/a‑user‑interface‑for‑big‑data‑with‑rapidminer‑marcelo‑beckmann']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Available', 'avail'), (':', ':'), ('http', 'http'), (':', ':'), ('//www.slideshare.net/', '//www.slideshare.net/'), ('RapidMiner/a‑user‑interface‑for‑big‑data‑with‑rapidminer‑marcelo‑beckmann', 'rapidminer/a‑user‑interface‑for‑big‑data‑with‑rapidminer‑marcelo‑beckmann'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Available', 'avail'), (':', ':'), ('http', 'http'), (':', ':'), ('//www.slideshare.net/', '//www.slideshare.net/'), ('RapidMiner/a‑user‑interface‑for‑big‑data‑with‑rapidminer‑marcelo‑beckmann', 'rapidminer/a‑user‑interface‑for‑big‑data‑with‑rapidminer‑marcelo‑beckmann'), ('.', '.')]

>> Lemmatization: 
 [('Available', 'Available'), (':', ':'), ('http', 'http'), (':', ':'), ('//www.slideshare.net/', '//www.slideshare.net/'), ('RapidMiner/a‑user‑interface‑for‑big‑data‑with‑rapidminer‑marcelo‑beckmann', 'RapidMiner/a‑user‑interface‑for‑big‑data‑with‑rapidminer‑marcelo‑beckmann'), ('.', '.')]



========================================== PARAGRAPH 532 ===========================================

 144. Januzaj E, Kriegel HP, Pfeifle M. DBDC: Density based distributed clustering. In: Proceedings of the Advances in  Database Technology, 2004; vol. 2992, 2004, pp 88–105. 

------------------- Sentence 1 -------------------

 144.

>> Tokens are: 
 ['144', '.']

>> Bigrams are: 
 [('144', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('144', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('144', '144'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('144', '144'), ('.', '.')]

>> Lemmatization: 
 [('144', '144'), ('.', '.')]


------------------- Sentence 2 -------------------

Januzaj E, Kriegel HP, Pfeifle M. DBDC: Density based distributed clustering.

>> Tokens are: 
 ['Januzaj', 'E', ',', 'Kriegel', 'HP', ',', 'Pfeifle', 'M.', 'DBDC', ':', 'Density', 'based', 'distributed', 'clustering', '.']

>> Bigrams are: 
 [('Januzaj', 'E'), ('E', ','), (',', 'Kriegel'), ('Kriegel', 'HP'), ('HP', ','), (',', 'Pfeifle'), ('Pfeifle', 'M.'), ('M.', 'DBDC'), ('DBDC', ':'), (':', 'Density'), ('Density', 'based'), ('based', 'distributed'), ('distributed', 'clustering'), ('clustering', '.')]

>> Trigrams are: 
 [('Januzaj', 'E', ','), ('E', ',', 'Kriegel'), (',', 'Kriegel', 'HP'), ('Kriegel', 'HP', ','), ('HP', ',', 'Pfeifle'), (',', 'Pfeifle', 'M.'), ('Pfeifle', 'M.', 'DBDC'), ('M.', 'DBDC', ':'), ('DBDC', ':', 'Density'), (':', 'Density', 'based'), ('Density', 'based', 'distributed'), ('based', 'distributed', 'clustering'), ('distributed', 'clustering', '.')]

>> POS Tags are: 
 [('Januzaj', 'NNP'), ('E', 'NNP'), (',', ','), ('Kriegel', 'NNP'), ('HP', 'NNP'), (',', ','), ('Pfeifle', 'NNP'), ('M.', 'NNP'), ('DBDC', 'NNP'), (':', ':'), ('Density', 'NN'), ('based', 'VBN'), ('distributed', 'VBN'), ('clustering', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Januzaj E', 'Kriegel HP', 'Pfeifle M. DBDC', 'Density', 'clustering']

>> Named Entities are: 
 [('PERSON', 'Januzaj'), ('ORGANIZATION', 'E'), ('PERSON', 'Kriegel HP'), ('PERSON', 'Pfeifle M.')] 

>> Stemming using Porter Stemmer: 
 [('Januzaj', 'januzaj'), ('E', 'e'), (',', ','), ('Kriegel', 'kriegel'), ('HP', 'hp'), (',', ','), ('Pfeifle', 'pfeifl'), ('M.', 'm.'), ('DBDC', 'dbdc'), (':', ':'), ('Density', 'densiti'), ('based', 'base'), ('distributed', 'distribut'), ('clustering', 'cluster'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Januzaj', 'januzaj'), ('E', 'e'), (',', ','), ('Kriegel', 'kriegel'), ('HP', 'hp'), (',', ','), ('Pfeifle', 'pfeifl'), ('M.', 'm.'), ('DBDC', 'dbdc'), (':', ':'), ('Density', 'densiti'), ('based', 'base'), ('distributed', 'distribut'), ('clustering', 'cluster'), ('.', '.')]

>> Lemmatization: 
 [('Januzaj', 'Januzaj'), ('E', 'E'), (',', ','), ('Kriegel', 'Kriegel'), ('HP', 'HP'), (',', ','), ('Pfeifle', 'Pfeifle'), ('M.', 'M.'), ('DBDC', 'DBDC'), (':', ':'), ('Density', 'Density'), ('based', 'based'), ('distributed', 'distributed'), ('clustering', 'clustering'), ('.', '.')]


------------------- Sentence 3 -------------------

In: Proceedings of the Advances in  Database Technology, 2004; vol.

>> Tokens are: 
 ['In', ':', 'Proceedings', 'Advances', 'Database', 'Technology', ',', '2004', ';', 'vol', '.']

>> Bigrams are: 
 [('In', ':'), (':', 'Proceedings'), ('Proceedings', 'Advances'), ('Advances', 'Database'), ('Database', 'Technology'), ('Technology', ','), (',', '2004'), ('2004', ';'), (';', 'vol'), ('vol', '.')]

>> Trigrams are: 
 [('In', ':', 'Proceedings'), (':', 'Proceedings', 'Advances'), ('Proceedings', 'Advances', 'Database'), ('Advances', 'Database', 'Technology'), ('Database', 'Technology', ','), ('Technology', ',', '2004'), (',', '2004', ';'), ('2004', ';', 'vol'), (';', 'vol', '.')]

>> POS Tags are: 
 [('In', 'IN'), (':', ':'), ('Proceedings', 'NNS'), ('Advances', 'NNS'), ('Database', 'NNP'), ('Technology', 'NNP'), (',', ','), ('2004', 'CD'), (';', ':'), ('vol', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Proceedings Advances Database Technology', 'vol']

>> Named Entities are: 
 [('PERSON', 'Database Technology')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), (':', ':'), ('Proceedings', 'proceed'), ('Advances', 'advanc'), ('Database', 'databas'), ('Technology', 'technolog'), (',', ','), ('2004', '2004'), (';', ';'), ('vol', 'vol'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), (':', ':'), ('Proceedings', 'proceed'), ('Advances', 'advanc'), ('Database', 'databas'), ('Technology', 'technolog'), (',', ','), ('2004', '2004'), (';', ';'), ('vol', 'vol'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), (':', ':'), ('Proceedings', 'Proceedings'), ('Advances', 'Advances'), ('Database', 'Database'), ('Technology', 'Technology'), (',', ','), ('2004', '2004'), (';', ';'), ('vol', 'vol'), ('.', '.')]


------------------- Sentence 4 -------------------

2992, 2004, pp 88–105.

>> Tokens are: 
 ['2992', ',', '2004', ',', 'pp', '88–105', '.']

>> Bigrams are: 
 [('2992', ','), (',', '2004'), ('2004', ','), (',', 'pp'), ('pp', '88–105'), ('88–105', '.')]

>> Trigrams are: 
 [('2992', ',', '2004'), (',', '2004', ','), ('2004', ',', 'pp'), (',', 'pp', '88–105'), ('pp', '88–105', '.')]

>> POS Tags are: 
 [('2992', 'CD'), (',', ','), ('2004', 'CD'), (',', ','), ('pp', 'VBD'), ('88–105', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('2992', '2992'), (',', ','), ('2004', '2004'), (',', ','), ('pp', 'pp'), ('88–105', '88–105'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('2992', '2992'), (',', ','), ('2004', '2004'), (',', ','), ('pp', 'pp'), ('88–105', '88–105'), ('.', '.')]

>> Lemmatization: 
 [('2992', '2992'), (',', ','), ('2004', '2004'), (',', ','), ('pp', 'pp'), ('88–105', '88–105'), ('.', '.')]



========================================== PARAGRAPH 533 ===========================================

 145. Zhao W, Ma H, He Q. Parallel k‑means clustering based on mapreduce. Proceedings Cloud Comp.  2009;5931:674–9. 

------------------- Sentence 1 -------------------

 145.

>> Tokens are: 
 ['145', '.']

>> Bigrams are: 
 [('145', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('145', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('145', '145'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('145', '145'), ('.', '.')]

>> Lemmatization: 
 [('145', '145'), ('.', '.')]


------------------- Sentence 2 -------------------

Zhao W, Ma H, He Q.

>> Tokens are: 
 ['Zhao', 'W', ',', 'Ma', 'H', ',', 'He', 'Q', '.']

>> Bigrams are: 
 [('Zhao', 'W'), ('W', ','), (',', 'Ma'), ('Ma', 'H'), ('H', ','), (',', 'He'), ('He', 'Q'), ('Q', '.')]

>> Trigrams are: 
 [('Zhao', 'W', ','), ('W', ',', 'Ma'), (',', 'Ma', 'H'), ('Ma', 'H', ','), ('H', ',', 'He'), (',', 'He', 'Q'), ('He', 'Q', '.')]

>> POS Tags are: 
 [('Zhao', 'NNP'), ('W', 'NNP'), (',', ','), ('Ma', 'NNP'), ('H', 'NNP'), (',', ','), ('He', 'PRP'), ('Q', 'VBZ'), ('.', '.')]

>> Noun Phrases are: 
 ['Zhao W', 'Ma H']

>> Named Entities are: 
 [('PERSON', 'Zhao'), ('ORGANIZATION', 'W'), ('PERSON', 'Ma H')] 

>> Stemming using Porter Stemmer: 
 [('Zhao', 'zhao'), ('W', 'w'), (',', ','), ('Ma', 'ma'), ('H', 'h'), (',', ','), ('He', 'he'), ('Q', 'q'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Zhao', 'zhao'), ('W', 'w'), (',', ','), ('Ma', 'ma'), ('H', 'h'), (',', ','), ('He', 'he'), ('Q', 'q'), ('.', '.')]

>> Lemmatization: 
 [('Zhao', 'Zhao'), ('W', 'W'), (',', ','), ('Ma', 'Ma'), ('H', 'H'), (',', ','), ('He', 'He'), ('Q', 'Q'), ('.', '.')]


------------------- Sentence 3 -------------------

Parallel k‑means clustering based on mapreduce.

>> Tokens are: 
 ['Parallel', 'k‑means', 'clustering', 'based', 'mapreduce', '.']

>> Bigrams are: 
 [('Parallel', 'k‑means'), ('k‑means', 'clustering'), ('clustering', 'based'), ('based', 'mapreduce'), ('mapreduce', '.')]

>> Trigrams are: 
 [('Parallel', 'k‑means', 'clustering'), ('k‑means', 'clustering', 'based'), ('clustering', 'based', 'mapreduce'), ('based', 'mapreduce', '.')]

>> POS Tags are: 
 [('Parallel', 'NNP'), ('k‑means', 'VBZ'), ('clustering', 'VBG'), ('based', 'VBN'), ('mapreduce', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Parallel', 'mapreduce']

>> Named Entities are: 
 [('GPE', 'Parallel')] 

>> Stemming using Porter Stemmer: 
 [('Parallel', 'parallel'), ('k‑means', 'k‑mean'), ('clustering', 'cluster'), ('based', 'base'), ('mapreduce', 'mapreduc'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Parallel', 'parallel'), ('k‑means', 'k‑mean'), ('clustering', 'cluster'), ('based', 'base'), ('mapreduce', 'mapreduc'), ('.', '.')]

>> Lemmatization: 
 [('Parallel', 'Parallel'), ('k‑means', 'k‑means'), ('clustering', 'clustering'), ('based', 'based'), ('mapreduce', 'mapreduce'), ('.', '.')]


------------------- Sentence 4 -------------------

Proceedings Cloud Comp.

>> Tokens are: 
 ['Proceedings', 'Cloud', 'Comp', '.']

>> Bigrams are: 
 [('Proceedings', 'Cloud'), ('Cloud', 'Comp'), ('Comp', '.')]

>> Trigrams are: 
 [('Proceedings', 'Cloud', 'Comp'), ('Cloud', 'Comp', '.')]

>> POS Tags are: 
 [('Proceedings', 'NNS'), ('Cloud', 'NNP'), ('Comp', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Proceedings Cloud Comp']

>> Named Entities are: 
 [('PERSON', 'Cloud Comp')] 

>> Stemming using Porter Stemmer: 
 [('Proceedings', 'proceed'), ('Cloud', 'cloud'), ('Comp', 'comp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Proceedings', 'proceed'), ('Cloud', 'cloud'), ('Comp', 'comp'), ('.', '.')]

>> Lemmatization: 
 [('Proceedings', 'Proceedings'), ('Cloud', 'Cloud'), ('Comp', 'Comp'), ('.', '.')]


------------------- Sentence 5 -------------------

2009;5931:674–9.

>> Tokens are: 
 ['2009', ';', '5931:674–9', '.']

>> Bigrams are: 
 [('2009', ';'), (';', '5931:674–9'), ('5931:674–9', '.')]

>> Trigrams are: 
 [('2009', ';', '5931:674–9'), (';', '5931:674–9', '.')]

>> POS Tags are: 
 [('2009', 'CD'), (';', ':'), ('5931:674–9', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('2009', '2009'), (';', ';'), ('5931:674–9', '5931:674–9'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('2009', '2009'), (';', ';'), ('5931:674–9', '5931:674–9'), ('.', '.')]

>> Lemmatization: 
 [('2009', '2009'), (';', ';'), ('5931:674–9', '5931:674–9'), ('.', '.')]



========================================== PARAGRAPH 534 ===========================================

 146. Nolan RL. Managing the crises in data processing. Harvard Bus Rev. 1979;57(1):115–26.  147. Tsai CW, Huang WC, Chiang MC. Recent development of metaheuristics for clustering. In: Proceedings of the  

------------------- Sentence 1 -------------------

 146.

>> Tokens are: 
 ['146', '.']

>> Bigrams are: 
 [('146', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('146', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('146', '146'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('146', '146'), ('.', '.')]

>> Lemmatization: 
 [('146', '146'), ('.', '.')]


------------------- Sentence 2 -------------------

Nolan RL.

>> Tokens are: 
 ['Nolan', 'RL', '.']

>> Bigrams are: 
 [('Nolan', 'RL'), ('RL', '.')]

>> Trigrams are: 
 [('Nolan', 'RL', '.')]

>> POS Tags are: 
 [('Nolan', 'NNP'), ('RL', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Nolan RL']

>> Named Entities are: 
 [('PERSON', 'Nolan')] 

>> Stemming using Porter Stemmer: 
 [('Nolan', 'nolan'), ('RL', 'rl'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Nolan', 'nolan'), ('RL', 'rl'), ('.', '.')]

>> Lemmatization: 
 [('Nolan', 'Nolan'), ('RL', 'RL'), ('.', '.')]


------------------- Sentence 3 -------------------

Managing the crises in data processing.

>> Tokens are: 
 ['Managing', 'crises', 'data', 'processing', '.']

>> Bigrams are: 
 [('Managing', 'crises'), ('crises', 'data'), ('data', 'processing'), ('processing', '.')]

>> Trigrams are: 
 [('Managing', 'crises', 'data'), ('crises', 'data', 'processing'), ('data', 'processing', '.')]

>> POS Tags are: 
 [('Managing', 'VBG'), ('crises', 'NNS'), ('data', 'NNS'), ('processing', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['crises data processing']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Managing', 'manag'), ('crises', 'crise'), ('data', 'data'), ('processing', 'process'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Managing', 'manag'), ('crises', 'crise'), ('data', 'data'), ('processing', 'process'), ('.', '.')]

>> Lemmatization: 
 [('Managing', 'Managing'), ('crises', 'crisis'), ('data', 'data'), ('processing', 'processing'), ('.', '.')]


------------------- Sentence 4 -------------------

Harvard Bus Rev.

>> Tokens are: 
 ['Harvard', 'Bus', 'Rev', '.']

>> Bigrams are: 
 [('Harvard', 'Bus'), ('Bus', 'Rev'), ('Rev', '.')]

>> Trigrams are: 
 [('Harvard', 'Bus', 'Rev'), ('Bus', 'Rev', '.')]

>> POS Tags are: 
 [('Harvard', 'NNP'), ('Bus', 'NNP'), ('Rev', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Harvard Bus Rev']

>> Named Entities are: 
 [('PERSON', 'Harvard'), ('PERSON', 'Bus Rev')] 

>> Stemming using Porter Stemmer: 
 [('Harvard', 'harvard'), ('Bus', 'bu'), ('Rev', 'rev'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Harvard', 'harvard'), ('Bus', 'bus'), ('Rev', 'rev'), ('.', '.')]

>> Lemmatization: 
 [('Harvard', 'Harvard'), ('Bus', 'Bus'), ('Rev', 'Rev'), ('.', '.')]


------------------- Sentence 5 -------------------

1979;57(1):115–26.

>> Tokens are: 
 ['1979', ';', '57', '(', '1', ')', ':115–26', '.']

>> Bigrams are: 
 [('1979', ';'), (';', '57'), ('57', '('), ('(', '1'), ('1', ')'), (')', ':115–26'), (':115–26', '.')]

>> Trigrams are: 
 [('1979', ';', '57'), (';', '57', '('), ('57', '(', '1'), ('(', '1', ')'), ('1', ')', ':115–26'), (')', ':115–26', '.')]

>> POS Tags are: 
 [('1979', 'CD'), (';', ':'), ('57', 'CD'), ('(', '('), ('1', 'CD'), (')', ')'), (':115–26', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 [':115–26']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('1979', '1979'), (';', ';'), ('57', '57'), ('(', '('), ('1', '1'), (')', ')'), (':115–26', ':115–26'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('1979', '1979'), (';', ';'), ('57', '57'), ('(', '('), ('1', '1'), (')', ')'), (':115–26', ':115–26'), ('.', '.')]

>> Lemmatization: 
 [('1979', '1979'), (';', ';'), ('57', '57'), ('(', '('), ('1', '1'), (')', ')'), (':115–26', ':115–26'), ('.', '.')]


------------------- Sentence 6 -------------------

147.

>> Tokens are: 
 ['147', '.']

>> Bigrams are: 
 [('147', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('147', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('147', '147'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('147', '147'), ('.', '.')]

>> Lemmatization: 
 [('147', '147'), ('.', '.')]


------------------- Sentence 7 -------------------

Tsai CW, Huang WC, Chiang MC.

>> Tokens are: 
 ['Tsai', 'CW', ',', 'Huang', 'WC', ',', 'Chiang', 'MC', '.']

>> Bigrams are: 
 [('Tsai', 'CW'), ('CW', ','), (',', 'Huang'), ('Huang', 'WC'), ('WC', ','), (',', 'Chiang'), ('Chiang', 'MC'), ('MC', '.')]

>> Trigrams are: 
 [('Tsai', 'CW', ','), ('CW', ',', 'Huang'), (',', 'Huang', 'WC'), ('Huang', 'WC', ','), ('WC', ',', 'Chiang'), (',', 'Chiang', 'MC'), ('Chiang', 'MC', '.')]

>> POS Tags are: 
 [('Tsai', 'NNP'), ('CW', 'NNP'), (',', ','), ('Huang', 'NNP'), ('WC', 'NNP'), (',', ','), ('Chiang', 'NNP'), ('MC', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Tsai CW', 'Huang WC', 'Chiang MC']

>> Named Entities are: 
 [('PERSON', 'Tsai'), ('GPE', 'CW'), ('PERSON', 'Huang WC'), ('PERSON', 'Chiang MC')] 

>> Stemming using Porter Stemmer: 
 [('Tsai', 'tsai'), ('CW', 'cw'), (',', ','), ('Huang', 'huang'), ('WC', 'wc'), (',', ','), ('Chiang', 'chiang'), ('MC', 'mc'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Tsai', 'tsai'), ('CW', 'cw'), (',', ','), ('Huang', 'huang'), ('WC', 'wc'), (',', ','), ('Chiang', 'chiang'), ('MC', 'mc'), ('.', '.')]

>> Lemmatization: 
 [('Tsai', 'Tsai'), ('CW', 'CW'), (',', ','), ('Huang', 'Huang'), ('WC', 'WC'), (',', ','), ('Chiang', 'Chiang'), ('MC', 'MC'), ('.', '.')]


------------------- Sentence 8 -------------------

Recent development of metaheuristics for clustering.

>> Tokens are: 
 ['Recent', 'development', 'metaheuristics', 'clustering', '.']

>> Bigrams are: 
 [('Recent', 'development'), ('development', 'metaheuristics'), ('metaheuristics', 'clustering'), ('clustering', '.')]

>> Trigrams are: 
 [('Recent', 'development', 'metaheuristics'), ('development', 'metaheuristics', 'clustering'), ('metaheuristics', 'clustering', '.')]

>> POS Tags are: 
 [('Recent', 'JJ'), ('development', 'NN'), ('metaheuristics', 'NNS'), ('clustering', 'VBG'), ('.', '.')]

>> Noun Phrases are: 
 ['Recent development metaheuristics']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Recent', 'recent'), ('development', 'develop'), ('metaheuristics', 'metaheurist'), ('clustering', 'cluster'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Recent', 'recent'), ('development', 'develop'), ('metaheuristics', 'metaheurist'), ('clustering', 'cluster'), ('.', '.')]

>> Lemmatization: 
 [('Recent', 'Recent'), ('development', 'development'), ('metaheuristics', 'metaheuristics'), ('clustering', 'clustering'), ('.', '.')]


------------------- Sentence 9 -------------------

In: Proceedings of the

>> Tokens are: 
 ['In', ':', 'Proceedings']

>> Bigrams are: 
 [('In', ':'), (':', 'Proceedings')]

>> Trigrams are: 
 [('In', ':', 'Proceedings')]

>> POS Tags are: 
 [('In', 'IN'), (':', ':'), ('Proceedings', 'NNS')]

>> Noun Phrases are: 
 ['Proceedings']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), (':', ':'), ('Proceedings', 'proceed')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), (':', ':'), ('Proceedings', 'proceed')]

>> Lemmatization: 
 [('In', 'In'), (':', ':'), ('Proceedings', 'Proceedings')]



========================================== PARAGRAPH 535 ===========================================

Mobile, Ubiquitous, and Intelligent Computing, 2014; vol. 274, pp. 629–636.

------------------- Sentence 1 -------------------

Mobile, Ubiquitous, and Intelligent Computing, 2014; vol.

>> Tokens are: 
 ['Mobile', ',', 'Ubiquitous', ',', 'Intelligent', 'Computing', ',', '2014', ';', 'vol', '.']

>> Bigrams are: 
 [('Mobile', ','), (',', 'Ubiquitous'), ('Ubiquitous', ','), (',', 'Intelligent'), ('Intelligent', 'Computing'), ('Computing', ','), (',', '2014'), ('2014', ';'), (';', 'vol'), ('vol', '.')]

>> Trigrams are: 
 [('Mobile', ',', 'Ubiquitous'), (',', 'Ubiquitous', ','), ('Ubiquitous', ',', 'Intelligent'), (',', 'Intelligent', 'Computing'), ('Intelligent', 'Computing', ','), ('Computing', ',', '2014'), (',', '2014', ';'), ('2014', ';', 'vol'), (';', 'vol', '.')]

>> POS Tags are: 
 [('Mobile', 'NNP'), (',', ','), ('Ubiquitous', 'NNP'), (',', ','), ('Intelligent', 'NNP'), ('Computing', 'NNP'), (',', ','), ('2014', 'CD'), (';', ':'), ('vol', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Mobile', 'Ubiquitous', 'Intelligent Computing', 'vol']

>> Named Entities are: 
 [('GPE', 'Mobile'), ('GPE', 'Ubiquitous'), ('ORGANIZATION', 'Intelligent')] 

>> Stemming using Porter Stemmer: 
 [('Mobile', 'mobil'), (',', ','), ('Ubiquitous', 'ubiquit'), (',', ','), ('Intelligent', 'intellig'), ('Computing', 'comput'), (',', ','), ('2014', '2014'), (';', ';'), ('vol', 'vol'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Mobile', 'mobil'), (',', ','), ('Ubiquitous', 'ubiquit'), (',', ','), ('Intelligent', 'intellig'), ('Computing', 'comput'), (',', ','), ('2014', '2014'), (';', ';'), ('vol', 'vol'), ('.', '.')]

>> Lemmatization: 
 [('Mobile', 'Mobile'), (',', ','), ('Ubiquitous', 'Ubiquitous'), (',', ','), ('Intelligent', 'Intelligent'), ('Computing', 'Computing'), (',', ','), ('2014', '2014'), (';', ';'), ('vol', 'vol'), ('.', '.')]


------------------- Sentence 2 -------------------

274, pp.

>> Tokens are: 
 ['274', ',', 'pp', '.']

>> Bigrams are: 
 [('274', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('274', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('274', 'CD'), (',', ','), ('pp', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['pp']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('274', '274'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('274', '274'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('274', '274'), (',', ','), ('pp', 'pp'), ('.', '.')]


------------------- Sentence 3 -------------------

629–636.

>> Tokens are: 
 ['629–636', '.']

>> Bigrams are: 
 [('629–636', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('629–636', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('629–636', '629–636'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('629–636', '629–636'), ('.', '.')]

>> Lemmatization: 
 [('629–636', '629–636'), ('.', '.')]

