				 *** Text Processing using NLTK *** 


========================================== PARAGRAPH 1 ===========================================

1Facebook AI Research, 770 Broadway, New York, New York 10003 USA. 2New York University, 715 Broadway, New York, New York 10003, USA. 3Department of Computer Science and Operations  Research Université de Montréal, Pavillon André-Aisenstadt, PO Box 6128  Centre-Ville STN Montréal, Quebec H3C 3J7, Canada. 4Google, 1600 Amphitheatre Parkway, Mountain View, California  94043, USA. 5Department of Computer Science, University of Toronto, 6 King’s College Road, Toronto, Ontario M5S 3G4, Canada. 

------------------- Sentence 1 -------------------

1Facebook AI Research, 770 Broadway, New York, New York 10003 USA.

>> Tokens are: 
 ['1Facebook', 'AI', 'Research', ',', '770', 'Broadway', ',', 'New', 'York', ',', 'New', 'York', '10003', 'USA', '.']

>> Bigrams are: 
 [('1Facebook', 'AI'), ('AI', 'Research'), ('Research', ','), (',', '770'), ('770', 'Broadway'), ('Broadway', ','), (',', 'New'), ('New', 'York'), ('York', ','), (',', 'New'), ('New', 'York'), ('York', '10003'), ('10003', 'USA'), ('USA', '.')]

>> Trigrams are: 
 [('1Facebook', 'AI', 'Research'), ('AI', 'Research', ','), ('Research', ',', '770'), (',', '770', 'Broadway'), ('770', 'Broadway', ','), ('Broadway', ',', 'New'), (',', 'New', 'York'), ('New', 'York', ','), ('York', ',', 'New'), (',', 'New', 'York'), ('New', 'York', '10003'), ('York', '10003', 'USA'), ('10003', 'USA', '.')]

>> POS Tags are: 
 [('1Facebook', 'CD'), ('AI', 'NNP'), ('Research', 'NNP'), (',', ','), ('770', 'CD'), ('Broadway', 'NNP'), (',', ','), ('New', 'NNP'), ('York', 'NNP'), (',', ','), ('New', 'NNP'), ('York', 'NNP'), ('10003', 'CD'), ('USA', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['AI Research', 'Broadway', 'New York', 'New York', 'USA']

>> Named Entities are: 
 [('GPE', 'Broadway'), ('GPE', 'New York'), ('GPE', 'New York')] 

>> Stemming using Porter Stemmer: 
 [('1Facebook', '1facebook'), ('AI', 'ai'), ('Research', 'research'), (',', ','), ('770', '770'), ('Broadway', 'broadway'), (',', ','), ('New', 'new'), ('York', 'york'), (',', ','), ('New', 'new'), ('York', 'york'), ('10003', '10003'), ('USA', 'usa'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('1Facebook', '1facebook'), ('AI', 'ai'), ('Research', 'research'), (',', ','), ('770', '770'), ('Broadway', 'broadway'), (',', ','), ('New', 'new'), ('York', 'york'), (',', ','), ('New', 'new'), ('York', 'york'), ('10003', '10003'), ('USA', 'usa'), ('.', '.')]

>> Lemmatization: 
 [('1Facebook', '1Facebook'), ('AI', 'AI'), ('Research', 'Research'), (',', ','), ('770', '770'), ('Broadway', 'Broadway'), (',', ','), ('New', 'New'), ('York', 'York'), (',', ','), ('New', 'New'), ('York', 'York'), ('10003', '10003'), ('USA', 'USA'), ('.', '.')]


------------------- Sentence 2 -------------------

2New York University, 715 Broadway, New York, New York 10003, USA.

>> Tokens are: 
 ['2New', 'York', 'University', ',', '715', 'Broadway', ',', 'New', 'York', ',', 'New', 'York', '10003', ',', 'USA', '.']

>> Bigrams are: 
 [('2New', 'York'), ('York', 'University'), ('University', ','), (',', '715'), ('715', 'Broadway'), ('Broadway', ','), (',', 'New'), ('New', 'York'), ('York', ','), (',', 'New'), ('New', 'York'), ('York', '10003'), ('10003', ','), (',', 'USA'), ('USA', '.')]

>> Trigrams are: 
 [('2New', 'York', 'University'), ('York', 'University', ','), ('University', ',', '715'), (',', '715', 'Broadway'), ('715', 'Broadway', ','), ('Broadway', ',', 'New'), (',', 'New', 'York'), ('New', 'York', ','), ('York', ',', 'New'), (',', 'New', 'York'), ('New', 'York', '10003'), ('York', '10003', ','), ('10003', ',', 'USA'), (',', 'USA', '.')]

>> POS Tags are: 
 [('2New', 'CD'), ('York', 'NNP'), ('University', 'NNP'), (',', ','), ('715', 'CD'), ('Broadway', 'NNP'), (',', ','), ('New', 'NNP'), ('York', 'NNP'), (',', ','), ('New', 'NNP'), ('York', 'NNP'), ('10003', 'CD'), (',', ','), ('USA', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['York University', 'Broadway', 'New York', 'New York', 'USA']

>> Named Entities are: 
 [('ORGANIZATION', 'York University'), ('GPE', 'Broadway'), ('GPE', 'New York'), ('GPE', 'New York'), ('ORGANIZATION', 'USA')] 

>> Stemming using Porter Stemmer: 
 [('2New', '2new'), ('York', 'york'), ('University', 'univers'), (',', ','), ('715', '715'), ('Broadway', 'broadway'), (',', ','), ('New', 'new'), ('York', 'york'), (',', ','), ('New', 'new'), ('York', 'york'), ('10003', '10003'), (',', ','), ('USA', 'usa'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('2New', '2new'), ('York', 'york'), ('University', 'univers'), (',', ','), ('715', '715'), ('Broadway', 'broadway'), (',', ','), ('New', 'new'), ('York', 'york'), (',', ','), ('New', 'new'), ('York', 'york'), ('10003', '10003'), (',', ','), ('USA', 'usa'), ('.', '.')]

>> Lemmatization: 
 [('2New', '2New'), ('York', 'York'), ('University', 'University'), (',', ','), ('715', '715'), ('Broadway', 'Broadway'), (',', ','), ('New', 'New'), ('York', 'York'), (',', ','), ('New', 'New'), ('York', 'York'), ('10003', '10003'), (',', ','), ('USA', 'USA'), ('.', '.')]


------------------- Sentence 3 -------------------

3Department of Computer Science and Operations  Research Université de Montréal, Pavillon André-Aisenstadt, PO Box 6128  Centre-Ville STN Montréal, Quebec H3C 3J7, Canada.

>> Tokens are: 
 ['3Department', 'Computer', 'Science', 'Operations', 'Research', 'Université', 'de', 'Montréal', ',', 'Pavillon', 'André-Aisenstadt', ',', 'PO', 'Box', '6128', 'Centre-Ville', 'STN', 'Montréal', ',', 'Quebec', 'H3C', '3J7', ',', 'Canada', '.']

>> Bigrams are: 
 [('3Department', 'Computer'), ('Computer', 'Science'), ('Science', 'Operations'), ('Operations', 'Research'), ('Research', 'Université'), ('Université', 'de'), ('de', 'Montréal'), ('Montréal', ','), (',', 'Pavillon'), ('Pavillon', 'André-Aisenstadt'), ('André-Aisenstadt', ','), (',', 'PO'), ('PO', 'Box'), ('Box', '6128'), ('6128', 'Centre-Ville'), ('Centre-Ville', 'STN'), ('STN', 'Montréal'), ('Montréal', ','), (',', 'Quebec'), ('Quebec', 'H3C'), ('H3C', '3J7'), ('3J7', ','), (',', 'Canada'), ('Canada', '.')]

>> Trigrams are: 
 [('3Department', 'Computer', 'Science'), ('Computer', 'Science', 'Operations'), ('Science', 'Operations', 'Research'), ('Operations', 'Research', 'Université'), ('Research', 'Université', 'de'), ('Université', 'de', 'Montréal'), ('de', 'Montréal', ','), ('Montréal', ',', 'Pavillon'), (',', 'Pavillon', 'André-Aisenstadt'), ('Pavillon', 'André-Aisenstadt', ','), ('André-Aisenstadt', ',', 'PO'), (',', 'PO', 'Box'), ('PO', 'Box', '6128'), ('Box', '6128', 'Centre-Ville'), ('6128', 'Centre-Ville', 'STN'), ('Centre-Ville', 'STN', 'Montréal'), ('STN', 'Montréal', ','), ('Montréal', ',', 'Quebec'), (',', 'Quebec', 'H3C'), ('Quebec', 'H3C', '3J7'), ('H3C', '3J7', ','), ('3J7', ',', 'Canada'), (',', 'Canada', '.')]

>> POS Tags are: 
 [('3Department', 'CD'), ('Computer', 'NNP'), ('Science', 'NNP'), ('Operations', 'NNP'), ('Research', 'NNP'), ('Université', 'NNP'), ('de', 'FW'), ('Montréal', 'NNP'), (',', ','), ('Pavillon', 'NNP'), ('André-Aisenstadt', 'NNP'), (',', ','), ('PO', 'NNP'), ('Box', 'NNP'), ('6128', 'CD'), ('Centre-Ville', 'NNP'), ('STN', 'NNP'), ('Montréal', 'NNP'), (',', ','), ('Quebec', 'NNP'), ('H3C', 'NNP'), ('3J7', 'CD'), (',', ','), ('Canada', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Computer Science Operations Research Université', 'Montréal', 'Pavillon André-Aisenstadt', 'PO Box', 'Centre-Ville STN Montréal', 'Quebec H3C', 'Canada']

>> Named Entities are: 
 [('ORGANIZATION', 'Computer Science Operations'), ('PERSON', 'Montréal'), ('PERSON', 'Pavillon'), ('ORGANIZATION', 'PO'), ('PERSON', 'Quebec H3C'), ('GPE', 'Canada')] 

>> Stemming using Porter Stemmer: 
 [('3Department', '3depart'), ('Computer', 'comput'), ('Science', 'scienc'), ('Operations', 'oper'), ('Research', 'research'), ('Université', 'université'), ('de', 'de'), ('Montréal', 'montréal'), (',', ','), ('Pavillon', 'pavillon'), ('André-Aisenstadt', 'andré-aisenstadt'), (',', ','), ('PO', 'po'), ('Box', 'box'), ('6128', '6128'), ('Centre-Ville', 'centre-vil'), ('STN', 'stn'), ('Montréal', 'montréal'), (',', ','), ('Quebec', 'quebec'), ('H3C', 'h3c'), ('3J7', '3j7'), (',', ','), ('Canada', 'canada'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('3Department', '3depart'), ('Computer', 'comput'), ('Science', 'scienc'), ('Operations', 'oper'), ('Research', 'research'), ('Université', 'université'), ('de', 'de'), ('Montréal', 'montréal'), (',', ','), ('Pavillon', 'pavillon'), ('André-Aisenstadt', 'andré-aisenstadt'), (',', ','), ('PO', 'po'), ('Box', 'box'), ('6128', '6128'), ('Centre-Ville', 'centre-vill'), ('STN', 'stn'), ('Montréal', 'montréal'), (',', ','), ('Quebec', 'quebec'), ('H3C', 'h3c'), ('3J7', '3j7'), (',', ','), ('Canada', 'canada'), ('.', '.')]

>> Lemmatization: 
 [('3Department', '3Department'), ('Computer', 'Computer'), ('Science', 'Science'), ('Operations', 'Operations'), ('Research', 'Research'), ('Université', 'Université'), ('de', 'de'), ('Montréal', 'Montréal'), (',', ','), ('Pavillon', 'Pavillon'), ('André-Aisenstadt', 'André-Aisenstadt'), (',', ','), ('PO', 'PO'), ('Box', 'Box'), ('6128', '6128'), ('Centre-Ville', 'Centre-Ville'), ('STN', 'STN'), ('Montréal', 'Montréal'), (',', ','), ('Quebec', 'Quebec'), ('H3C', 'H3C'), ('3J7', '3J7'), (',', ','), ('Canada', 'Canada'), ('.', '.')]


------------------- Sentence 4 -------------------

4Google, 1600 Amphitheatre Parkway, Mountain View, California  94043, USA.

>> Tokens are: 
 ['4Google', ',', '1600', 'Amphitheatre', 'Parkway', ',', 'Mountain', 'View', ',', 'California', '94043', ',', 'USA', '.']

>> Bigrams are: 
 [('4Google', ','), (',', '1600'), ('1600', 'Amphitheatre'), ('Amphitheatre', 'Parkway'), ('Parkway', ','), (',', 'Mountain'), ('Mountain', 'View'), ('View', ','), (',', 'California'), ('California', '94043'), ('94043', ','), (',', 'USA'), ('USA', '.')]

>> Trigrams are: 
 [('4Google', ',', '1600'), (',', '1600', 'Amphitheatre'), ('1600', 'Amphitheatre', 'Parkway'), ('Amphitheatre', 'Parkway', ','), ('Parkway', ',', 'Mountain'), (',', 'Mountain', 'View'), ('Mountain', 'View', ','), ('View', ',', 'California'), (',', 'California', '94043'), ('California', '94043', ','), ('94043', ',', 'USA'), (',', 'USA', '.')]

>> POS Tags are: 
 [('4Google', 'CD'), (',', ','), ('1600', 'CD'), ('Amphitheatre', 'NNP'), ('Parkway', 'NNP'), (',', ','), ('Mountain', 'NNP'), ('View', 'NNP'), (',', ','), ('California', 'NNP'), ('94043', 'CD'), (',', ','), ('USA', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Amphitheatre Parkway', 'Mountain View', 'California', 'USA']

>> Named Entities are: 
 [('PERSON', 'Mountain View'), ('GPE', 'California'), ('ORGANIZATION', 'USA')] 

>> Stemming using Porter Stemmer: 
 [('4Google', '4googl'), (',', ','), ('1600', '1600'), ('Amphitheatre', 'amphitheatr'), ('Parkway', 'parkway'), (',', ','), ('Mountain', 'mountain'), ('View', 'view'), (',', ','), ('California', 'california'), ('94043', '94043'), (',', ','), ('USA', 'usa'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('4Google', '4googl'), (',', ','), ('1600', '1600'), ('Amphitheatre', 'amphitheatr'), ('Parkway', 'parkway'), (',', ','), ('Mountain', 'mountain'), ('View', 'view'), (',', ','), ('California', 'california'), ('94043', '94043'), (',', ','), ('USA', 'usa'), ('.', '.')]

>> Lemmatization: 
 [('4Google', '4Google'), (',', ','), ('1600', '1600'), ('Amphitheatre', 'Amphitheatre'), ('Parkway', 'Parkway'), (',', ','), ('Mountain', 'Mountain'), ('View', 'View'), (',', ','), ('California', 'California'), ('94043', '94043'), (',', ','), ('USA', 'USA'), ('.', '.')]


------------------- Sentence 5 -------------------

5Department of Computer Science, University of Toronto, 6 King’s College Road, Toronto, Ontario M5S 3G4, Canada.

>> Tokens are: 
 ['5Department', 'Computer', 'Science', ',', 'University', 'Toronto', ',', '6', 'King', '’', 'College', 'Road', ',', 'Toronto', ',', 'Ontario', 'M5S', '3G4', ',', 'Canada', '.']

>> Bigrams are: 
 [('5Department', 'Computer'), ('Computer', 'Science'), ('Science', ','), (',', 'University'), ('University', 'Toronto'), ('Toronto', ','), (',', '6'), ('6', 'King'), ('King', '’'), ('’', 'College'), ('College', 'Road'), ('Road', ','), (',', 'Toronto'), ('Toronto', ','), (',', 'Ontario'), ('Ontario', 'M5S'), ('M5S', '3G4'), ('3G4', ','), (',', 'Canada'), ('Canada', '.')]

>> Trigrams are: 
 [('5Department', 'Computer', 'Science'), ('Computer', 'Science', ','), ('Science', ',', 'University'), (',', 'University', 'Toronto'), ('University', 'Toronto', ','), ('Toronto', ',', '6'), (',', '6', 'King'), ('6', 'King', '’'), ('King', '’', 'College'), ('’', 'College', 'Road'), ('College', 'Road', ','), ('Road', ',', 'Toronto'), (',', 'Toronto', ','), ('Toronto', ',', 'Ontario'), (',', 'Ontario', 'M5S'), ('Ontario', 'M5S', '3G4'), ('M5S', '3G4', ','), ('3G4', ',', 'Canada'), (',', 'Canada', '.')]

>> POS Tags are: 
 [('5Department', 'CD'), ('Computer', 'NNP'), ('Science', 'NNP'), (',', ','), ('University', 'NNP'), ('Toronto', 'NNP'), (',', ','), ('6', 'CD'), ('King', 'NNP'), ('’', 'NNP'), ('College', 'NNP'), ('Road', 'NNP'), (',', ','), ('Toronto', 'NNP'), (',', ','), ('Ontario', 'NNP'), ('M5S', 'NNP'), ('3G4', 'CD'), (',', ','), ('Canada', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Computer Science', 'University Toronto', 'King ’ College Road', 'Toronto', 'Ontario M5S', 'Canada']

>> Named Entities are: 
 [('ORGANIZATION', 'Computer Science'), ('ORGANIZATION', 'University Toronto'), ('GPE', 'Toronto'), ('PERSON', 'Ontario M5S'), ('GPE', 'Canada')] 

>> Stemming using Porter Stemmer: 
 [('5Department', '5depart'), ('Computer', 'comput'), ('Science', 'scienc'), (',', ','), ('University', 'univers'), ('Toronto', 'toronto'), (',', ','), ('6', '6'), ('King', 'king'), ('’', '’'), ('College', 'colleg'), ('Road', 'road'), (',', ','), ('Toronto', 'toronto'), (',', ','), ('Ontario', 'ontario'), ('M5S', 'm5'), ('3G4', '3g4'), (',', ','), ('Canada', 'canada'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('5Department', '5depart'), ('Computer', 'comput'), ('Science', 'scienc'), (',', ','), ('University', 'univers'), ('Toronto', 'toronto'), (',', ','), ('6', '6'), ('King', 'king'), ('’', '’'), ('College', 'colleg'), ('Road', 'road'), (',', ','), ('Toronto', 'toronto'), (',', ','), ('Ontario', 'ontario'), ('M5S', 'm5s'), ('3G4', '3g4'), (',', ','), ('Canada', 'canada'), ('.', '.')]

>> Lemmatization: 
 [('5Department', '5Department'), ('Computer', 'Computer'), ('Science', 'Science'), (',', ','), ('University', 'University'), ('Toronto', 'Toronto'), (',', ','), ('6', '6'), ('King', 'King'), ('’', '’'), ('College', 'College'), ('Road', 'Road'), (',', ','), ('Toronto', 'Toronto'), (',', ','), ('Ontario', 'Ontario'), ('M5S', 'M5S'), ('3G4', '3G4'), (',', ','), ('Canada', 'Canada'), ('.', '.')]



========================================== PARAGRAPH 2 ===========================================

Machine-learning technology powers many aspects of modern society: from web searches to content filtering on social net-works to recommendations on e-commerce websites, and  it is increasingly present in consumer products such as cameras and  smartphones. Machine-learning systems are used to identify objects  in images, transcribe speech into text, match news items, posts or  products with users’ interests, and select relevant results of search.  Increasingly, these applications make use of a class of techniques called  deep learning.  

------------------- Sentence 1 -------------------

Machine-learning technology powers many aspects of modern society: from web searches to content filtering on social net-works to recommendations on e-commerce websites, and  it is increasingly present in consumer products such as cameras and  smartphones.

>> Tokens are: 
 ['Machine-learning', 'technology', 'powers', 'many', 'aspects', 'modern', 'society', ':', 'web', 'searches', 'content', 'filtering', 'social', 'net-works', 'recommendations', 'e-commerce', 'websites', ',', 'increasingly', 'present', 'consumer', 'products', 'cameras', 'smartphones', '.']

>> Bigrams are: 
 [('Machine-learning', 'technology'), ('technology', 'powers'), ('powers', 'many'), ('many', 'aspects'), ('aspects', 'modern'), ('modern', 'society'), ('society', ':'), (':', 'web'), ('web', 'searches'), ('searches', 'content'), ('content', 'filtering'), ('filtering', 'social'), ('social', 'net-works'), ('net-works', 'recommendations'), ('recommendations', 'e-commerce'), ('e-commerce', 'websites'), ('websites', ','), (',', 'increasingly'), ('increasingly', 'present'), ('present', 'consumer'), ('consumer', 'products'), ('products', 'cameras'), ('cameras', 'smartphones'), ('smartphones', '.')]

>> Trigrams are: 
 [('Machine-learning', 'technology', 'powers'), ('technology', 'powers', 'many'), ('powers', 'many', 'aspects'), ('many', 'aspects', 'modern'), ('aspects', 'modern', 'society'), ('modern', 'society', ':'), ('society', ':', 'web'), (':', 'web', 'searches'), ('web', 'searches', 'content'), ('searches', 'content', 'filtering'), ('content', 'filtering', 'social'), ('filtering', 'social', 'net-works'), ('social', 'net-works', 'recommendations'), ('net-works', 'recommendations', 'e-commerce'), ('recommendations', 'e-commerce', 'websites'), ('e-commerce', 'websites', ','), ('websites', ',', 'increasingly'), (',', 'increasingly', 'present'), ('increasingly', 'present', 'consumer'), ('present', 'consumer', 'products'), ('consumer', 'products', 'cameras'), ('products', 'cameras', 'smartphones'), ('cameras', 'smartphones', '.')]

>> POS Tags are: 
 [('Machine-learning', 'NNP'), ('technology', 'NN'), ('powers', 'NNS'), ('many', 'JJ'), ('aspects', 'NNS'), ('modern', 'JJ'), ('society', 'NN'), (':', ':'), ('web', 'JJ'), ('searches', 'NNS'), ('content', 'JJ'), ('filtering', 'VBG'), ('social', 'JJ'), ('net-works', 'JJ'), ('recommendations', 'NNS'), ('e-commerce', 'JJ'), ('websites', 'NNS'), (',', ','), ('increasingly', 'RB'), ('present', 'JJ'), ('consumer', 'NN'), ('products', 'NNS'), ('cameras', 'JJ'), ('smartphones', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['Machine-learning technology powers', 'many aspects', 'modern society', 'web searches', 'social net-works recommendations', 'e-commerce websites', 'present consumer products', 'cameras smartphones']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Machine-learning', 'machine-learn'), ('technology', 'technolog'), ('powers', 'power'), ('many', 'mani'), ('aspects', 'aspect'), ('modern', 'modern'), ('society', 'societi'), (':', ':'), ('web', 'web'), ('searches', 'search'), ('content', 'content'), ('filtering', 'filter'), ('social', 'social'), ('net-works', 'net-work'), ('recommendations', 'recommend'), ('e-commerce', 'e-commerc'), ('websites', 'websit'), (',', ','), ('increasingly', 'increasingli'), ('present', 'present'), ('consumer', 'consum'), ('products', 'product'), ('cameras', 'camera'), ('smartphones', 'smartphon'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Machine-learning', 'machine-learn'), ('technology', 'technolog'), ('powers', 'power'), ('many', 'mani'), ('aspects', 'aspect'), ('modern', 'modern'), ('society', 'societi'), (':', ':'), ('web', 'web'), ('searches', 'search'), ('content', 'content'), ('filtering', 'filter'), ('social', 'social'), ('net-works', 'net-work'), ('recommendations', 'recommend'), ('e-commerce', 'e-commerc'), ('websites', 'websit'), (',', ','), ('increasingly', 'increas'), ('present', 'present'), ('consumer', 'consum'), ('products', 'product'), ('cameras', 'camera'), ('smartphones', 'smartphon'), ('.', '.')]

>> Lemmatization: 
 [('Machine-learning', 'Machine-learning'), ('technology', 'technology'), ('powers', 'power'), ('many', 'many'), ('aspects', 'aspect'), ('modern', 'modern'), ('society', 'society'), (':', ':'), ('web', 'web'), ('searches', 'search'), ('content', 'content'), ('filtering', 'filtering'), ('social', 'social'), ('net-works', 'net-works'), ('recommendations', 'recommendation'), ('e-commerce', 'e-commerce'), ('websites', 'website'), (',', ','), ('increasingly', 'increasingly'), ('present', 'present'), ('consumer', 'consumer'), ('products', 'product'), ('cameras', 'camera'), ('smartphones', 'smartphones'), ('.', '.')]


------------------- Sentence 2 -------------------

Machine-learning systems are used to identify objects  in images, transcribe speech into text, match news items, posts or  products with users’ interests, and select relevant results of search.

>> Tokens are: 
 ['Machine-learning', 'systems', 'used', 'identify', 'objects', 'images', ',', 'transcribe', 'speech', 'text', ',', 'match', 'news', 'items', ',', 'posts', 'products', 'users', '’', 'interests', ',', 'select', 'relevant', 'results', 'search', '.']

>> Bigrams are: 
 [('Machine-learning', 'systems'), ('systems', 'used'), ('used', 'identify'), ('identify', 'objects'), ('objects', 'images'), ('images', ','), (',', 'transcribe'), ('transcribe', 'speech'), ('speech', 'text'), ('text', ','), (',', 'match'), ('match', 'news'), ('news', 'items'), ('items', ','), (',', 'posts'), ('posts', 'products'), ('products', 'users'), ('users', '’'), ('’', 'interests'), ('interests', ','), (',', 'select'), ('select', 'relevant'), ('relevant', 'results'), ('results', 'search'), ('search', '.')]

>> Trigrams are: 
 [('Machine-learning', 'systems', 'used'), ('systems', 'used', 'identify'), ('used', 'identify', 'objects'), ('identify', 'objects', 'images'), ('objects', 'images', ','), ('images', ',', 'transcribe'), (',', 'transcribe', 'speech'), ('transcribe', 'speech', 'text'), ('speech', 'text', ','), ('text', ',', 'match'), (',', 'match', 'news'), ('match', 'news', 'items'), ('news', 'items', ','), ('items', ',', 'posts'), (',', 'posts', 'products'), ('posts', 'products', 'users'), ('products', 'users', '’'), ('users', '’', 'interests'), ('’', 'interests', ','), ('interests', ',', 'select'), (',', 'select', 'relevant'), ('select', 'relevant', 'results'), ('relevant', 'results', 'search'), ('results', 'search', '.')]

>> POS Tags are: 
 [('Machine-learning', 'JJ'), ('systems', 'NNS'), ('used', 'VBN'), ('identify', 'JJ'), ('objects', 'NNS'), ('images', 'NNS'), (',', ','), ('transcribe', 'EX'), ('speech', 'NN'), ('text', 'NN'), (',', ','), ('match', 'VB'), ('news', 'NN'), ('items', 'NNS'), (',', ','), ('posts', 'NNS'), ('products', 'NNS'), ('users', 'NNS'), ('’', 'VBP'), ('interests', 'NNS'), (',', ','), ('select', 'VBP'), ('relevant', 'JJ'), ('results', 'NNS'), ('search', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Machine-learning systems', 'identify objects images', 'speech text', 'news items', 'posts products users', 'interests', 'relevant results search']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Machine-learning', 'machine-learn'), ('systems', 'system'), ('used', 'use'), ('identify', 'identifi'), ('objects', 'object'), ('images', 'imag'), (',', ','), ('transcribe', 'transcrib'), ('speech', 'speech'), ('text', 'text'), (',', ','), ('match', 'match'), ('news', 'news'), ('items', 'item'), (',', ','), ('posts', 'post'), ('products', 'product'), ('users', 'user'), ('’', '’'), ('interests', 'interest'), (',', ','), ('select', 'select'), ('relevant', 'relev'), ('results', 'result'), ('search', 'search'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Machine-learning', 'machine-learn'), ('systems', 'system'), ('used', 'use'), ('identify', 'identifi'), ('objects', 'object'), ('images', 'imag'), (',', ','), ('transcribe', 'transcrib'), ('speech', 'speech'), ('text', 'text'), (',', ','), ('match', 'match'), ('news', 'news'), ('items', 'item'), (',', ','), ('posts', 'post'), ('products', 'product'), ('users', 'user'), ('’', '’'), ('interests', 'interest'), (',', ','), ('select', 'select'), ('relevant', 'relev'), ('results', 'result'), ('search', 'search'), ('.', '.')]

>> Lemmatization: 
 [('Machine-learning', 'Machine-learning'), ('systems', 'system'), ('used', 'used'), ('identify', 'identify'), ('objects', 'object'), ('images', 'image'), (',', ','), ('transcribe', 'transcribe'), ('speech', 'speech'), ('text', 'text'), (',', ','), ('match', 'match'), ('news', 'news'), ('items', 'item'), (',', ','), ('posts', 'post'), ('products', 'product'), ('users', 'user'), ('’', '’'), ('interests', 'interest'), (',', ','), ('select', 'select'), ('relevant', 'relevant'), ('results', 'result'), ('search', 'search'), ('.', '.')]


------------------- Sentence 3 -------------------

Increasingly, these applications make use of a class of techniques called  deep learning.

>> Tokens are: 
 ['Increasingly', ',', 'applications', 'make', 'use', 'class', 'techniques', 'called', 'deep', 'learning', '.']

>> Bigrams are: 
 [('Increasingly', ','), (',', 'applications'), ('applications', 'make'), ('make', 'use'), ('use', 'class'), ('class', 'techniques'), ('techniques', 'called'), ('called', 'deep'), ('deep', 'learning'), ('learning', '.')]

>> Trigrams are: 
 [('Increasingly', ',', 'applications'), (',', 'applications', 'make'), ('applications', 'make', 'use'), ('make', 'use', 'class'), ('use', 'class', 'techniques'), ('class', 'techniques', 'called'), ('techniques', 'called', 'deep'), ('called', 'deep', 'learning'), ('deep', 'learning', '.')]

>> POS Tags are: 
 [('Increasingly', 'RB'), (',', ','), ('applications', 'NNS'), ('make', 'VBP'), ('use', 'JJ'), ('class', 'NN'), ('techniques', 'NNS'), ('called', 'VBN'), ('deep', 'RB'), ('learning', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['applications', 'use class techniques', 'learning']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Increasingly', 'increasingli'), (',', ','), ('applications', 'applic'), ('make', 'make'), ('use', 'use'), ('class', 'class'), ('techniques', 'techniqu'), ('called', 'call'), ('deep', 'deep'), ('learning', 'learn'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Increasingly', 'increas'), (',', ','), ('applications', 'applic'), ('make', 'make'), ('use', 'use'), ('class', 'class'), ('techniques', 'techniqu'), ('called', 'call'), ('deep', 'deep'), ('learning', 'learn'), ('.', '.')]

>> Lemmatization: 
 [('Increasingly', 'Increasingly'), (',', ','), ('applications', 'application'), ('make', 'make'), ('use', 'use'), ('class', 'class'), ('techniques', 'technique'), ('called', 'called'), ('deep', 'deep'), ('learning', 'learning'), ('.', '.')]



========================================== PARAGRAPH 3 ===========================================

Conventional machine-learning techniques were limited in their  ability to process natural data in their raw form. For decades, con- structing a pattern-recognition or machine-learning system required  careful engineering and considerable domain expertise to design a fea- ture extractor that transformed the raw data (such as the pixel values  of an image) into a suitable internal representation or feature vector  from which the learning subsystem, often a classifier, could detect or  classify patterns in the input.  

------------------- Sentence 1 -------------------

Conventional machine-learning techniques were limited in their  ability to process natural data in their raw form.

>> Tokens are: 
 ['Conventional', 'machine-learning', 'techniques', 'limited', 'ability', 'process', 'natural', 'data', 'raw', 'form', '.']

>> Bigrams are: 
 [('Conventional', 'machine-learning'), ('machine-learning', 'techniques'), ('techniques', 'limited'), ('limited', 'ability'), ('ability', 'process'), ('process', 'natural'), ('natural', 'data'), ('data', 'raw'), ('raw', 'form'), ('form', '.')]

>> Trigrams are: 
 [('Conventional', 'machine-learning', 'techniques'), ('machine-learning', 'techniques', 'limited'), ('techniques', 'limited', 'ability'), ('limited', 'ability', 'process'), ('ability', 'process', 'natural'), ('process', 'natural', 'data'), ('natural', 'data', 'raw'), ('data', 'raw', 'form'), ('raw', 'form', '.')]

>> POS Tags are: 
 [('Conventional', 'JJ'), ('machine-learning', 'NN'), ('techniques', 'NNS'), ('limited', 'JJ'), ('ability', 'NN'), ('process', 'NN'), ('natural', 'JJ'), ('data', 'NNS'), ('raw', 'JJ'), ('form', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Conventional machine-learning techniques', 'limited ability process', 'natural data', 'raw form']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Conventional', 'convent'), ('machine-learning', 'machine-learn'), ('techniques', 'techniqu'), ('limited', 'limit'), ('ability', 'abil'), ('process', 'process'), ('natural', 'natur'), ('data', 'data'), ('raw', 'raw'), ('form', 'form'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Conventional', 'convent'), ('machine-learning', 'machine-learn'), ('techniques', 'techniqu'), ('limited', 'limit'), ('ability', 'abil'), ('process', 'process'), ('natural', 'natur'), ('data', 'data'), ('raw', 'raw'), ('form', 'form'), ('.', '.')]

>> Lemmatization: 
 [('Conventional', 'Conventional'), ('machine-learning', 'machine-learning'), ('techniques', 'technique'), ('limited', 'limited'), ('ability', 'ability'), ('process', 'process'), ('natural', 'natural'), ('data', 'data'), ('raw', 'raw'), ('form', 'form'), ('.', '.')]


------------------- Sentence 2 -------------------

For decades, con- structing a pattern-recognition or machine-learning system required  careful engineering and considerable domain expertise to design a fea- ture extractor that transformed the raw data (such as the pixel values  of an image) into a suitable internal representation or feature vector  from which the learning subsystem, often a classifier, could detect or  classify patterns in the input.

>> Tokens are: 
 ['For', 'decades', ',', 'con-', 'structing', 'pattern-recognition', 'machine-learning', 'system', 'required', 'careful', 'engineering', 'considerable', 'domain', 'expertise', 'design', 'fea-', 'ture', 'extractor', 'transformed', 'raw', 'data', '(', 'pixel', 'values', 'image', ')', 'suitable', 'internal', 'representation', 'feature', 'vector', 'learning', 'subsystem', ',', 'often', 'classifier', ',', 'could', 'detect', 'classify', 'patterns', 'input', '.']

>> Bigrams are: 
 [('For', 'decades'), ('decades', ','), (',', 'con-'), ('con-', 'structing'), ('structing', 'pattern-recognition'), ('pattern-recognition', 'machine-learning'), ('machine-learning', 'system'), ('system', 'required'), ('required', 'careful'), ('careful', 'engineering'), ('engineering', 'considerable'), ('considerable', 'domain'), ('domain', 'expertise'), ('expertise', 'design'), ('design', 'fea-'), ('fea-', 'ture'), ('ture', 'extractor'), ('extractor', 'transformed'), ('transformed', 'raw'), ('raw', 'data'), ('data', '('), ('(', 'pixel'), ('pixel', 'values'), ('values', 'image'), ('image', ')'), (')', 'suitable'), ('suitable', 'internal'), ('internal', 'representation'), ('representation', 'feature'), ('feature', 'vector'), ('vector', 'learning'), ('learning', 'subsystem'), ('subsystem', ','), (',', 'often'), ('often', 'classifier'), ('classifier', ','), (',', 'could'), ('could', 'detect'), ('detect', 'classify'), ('classify', 'patterns'), ('patterns', 'input'), ('input', '.')]

>> Trigrams are: 
 [('For', 'decades', ','), ('decades', ',', 'con-'), (',', 'con-', 'structing'), ('con-', 'structing', 'pattern-recognition'), ('structing', 'pattern-recognition', 'machine-learning'), ('pattern-recognition', 'machine-learning', 'system'), ('machine-learning', 'system', 'required'), ('system', 'required', 'careful'), ('required', 'careful', 'engineering'), ('careful', 'engineering', 'considerable'), ('engineering', 'considerable', 'domain'), ('considerable', 'domain', 'expertise'), ('domain', 'expertise', 'design'), ('expertise', 'design', 'fea-'), ('design', 'fea-', 'ture'), ('fea-', 'ture', 'extractor'), ('ture', 'extractor', 'transformed'), ('extractor', 'transformed', 'raw'), ('transformed', 'raw', 'data'), ('raw', 'data', '('), ('data', '(', 'pixel'), ('(', 'pixel', 'values'), ('pixel', 'values', 'image'), ('values', 'image', ')'), ('image', ')', 'suitable'), (')', 'suitable', 'internal'), ('suitable', 'internal', 'representation'), ('internal', 'representation', 'feature'), ('representation', 'feature', 'vector'), ('feature', 'vector', 'learning'), ('vector', 'learning', 'subsystem'), ('learning', 'subsystem', ','), ('subsystem', ',', 'often'), (',', 'often', 'classifier'), ('often', 'classifier', ','), ('classifier', ',', 'could'), (',', 'could', 'detect'), ('could', 'detect', 'classify'), ('detect', 'classify', 'patterns'), ('classify', 'patterns', 'input'), ('patterns', 'input', '.')]

>> POS Tags are: 
 [('For', 'IN'), ('decades', 'NNS'), (',', ','), ('con-', 'JJ'), ('structing', 'VBG'), ('pattern-recognition', 'NN'), ('machine-learning', 'JJ'), ('system', 'NN'), ('required', 'VBN'), ('careful', 'JJ'), ('engineering', 'NN'), ('considerable', 'JJ'), ('domain', 'NN'), ('expertise', 'NN'), ('design', 'NN'), ('fea-', 'JJ'), ('ture', 'NN'), ('extractor', 'NN'), ('transformed', 'VBD'), ('raw', 'JJ'), ('data', 'NNS'), ('(', '('), ('pixel', 'NN'), ('values', 'NNS'), ('image', 'NN'), (')', ')'), ('suitable', 'JJ'), ('internal', 'JJ'), ('representation', 'NN'), ('feature', 'NN'), ('vector', 'NN'), ('learning', 'VBG'), ('subsystem', 'NN'), (',', ','), ('often', 'RB'), ('classifier', 'JJR'), (',', ','), ('could', 'MD'), ('detect', 'VB'), ('classify', 'VB'), ('patterns', 'NNS'), ('input', 'VB'), ('.', '.')]

>> Noun Phrases are: 
 ['decades', 'pattern-recognition', 'machine-learning system', 'careful engineering', 'considerable domain expertise design', 'fea- ture extractor', 'raw data', 'pixel values image', 'suitable internal representation feature vector', 'subsystem', 'patterns']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('For', 'for'), ('decades', 'decad'), (',', ','), ('con-', 'con-'), ('structing', 'struct'), ('pattern-recognition', 'pattern-recognit'), ('machine-learning', 'machine-learn'), ('system', 'system'), ('required', 'requir'), ('careful', 'care'), ('engineering', 'engin'), ('considerable', 'consider'), ('domain', 'domain'), ('expertise', 'expertis'), ('design', 'design'), ('fea-', 'fea-'), ('ture', 'ture'), ('extractor', 'extractor'), ('transformed', 'transform'), ('raw', 'raw'), ('data', 'data'), ('(', '('), ('pixel', 'pixel'), ('values', 'valu'), ('image', 'imag'), (')', ')'), ('suitable', 'suitabl'), ('internal', 'intern'), ('representation', 'represent'), ('feature', 'featur'), ('vector', 'vector'), ('learning', 'learn'), ('subsystem', 'subsystem'), (',', ','), ('often', 'often'), ('classifier', 'classifi'), (',', ','), ('could', 'could'), ('detect', 'detect'), ('classify', 'classifi'), ('patterns', 'pattern'), ('input', 'input'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('For', 'for'), ('decades', 'decad'), (',', ','), ('con-', 'con-'), ('structing', 'struct'), ('pattern-recognition', 'pattern-recognit'), ('machine-learning', 'machine-learn'), ('system', 'system'), ('required', 'requir'), ('careful', 'care'), ('engineering', 'engin'), ('considerable', 'consider'), ('domain', 'domain'), ('expertise', 'expertis'), ('design', 'design'), ('fea-', 'fea-'), ('ture', 'ture'), ('extractor', 'extractor'), ('transformed', 'transform'), ('raw', 'raw'), ('data', 'data'), ('(', '('), ('pixel', 'pixel'), ('values', 'valu'), ('image', 'imag'), (')', ')'), ('suitable', 'suitabl'), ('internal', 'intern'), ('representation', 'represent'), ('feature', 'featur'), ('vector', 'vector'), ('learning', 'learn'), ('subsystem', 'subsystem'), (',', ','), ('often', 'often'), ('classifier', 'classifi'), (',', ','), ('could', 'could'), ('detect', 'detect'), ('classify', 'classifi'), ('patterns', 'pattern'), ('input', 'input'), ('.', '.')]

>> Lemmatization: 
 [('For', 'For'), ('decades', 'decade'), (',', ','), ('con-', 'con-'), ('structing', 'structing'), ('pattern-recognition', 'pattern-recognition'), ('machine-learning', 'machine-learning'), ('system', 'system'), ('required', 'required'), ('careful', 'careful'), ('engineering', 'engineering'), ('considerable', 'considerable'), ('domain', 'domain'), ('expertise', 'expertise'), ('design', 'design'), ('fea-', 'fea-'), ('ture', 'ture'), ('extractor', 'extractor'), ('transformed', 'transformed'), ('raw', 'raw'), ('data', 'data'), ('(', '('), ('pixel', 'pixel'), ('values', 'value'), ('image', 'image'), (')', ')'), ('suitable', 'suitable'), ('internal', 'internal'), ('representation', 'representation'), ('feature', 'feature'), ('vector', 'vector'), ('learning', 'learning'), ('subsystem', 'subsystem'), (',', ','), ('often', 'often'), ('classifier', 'classifier'), (',', ','), ('could', 'could'), ('detect', 'detect'), ('classify', 'classify'), ('patterns', 'pattern'), ('input', 'input'), ('.', '.')]



========================================== PARAGRAPH 4 ===========================================

Representation learning is a set of methods that allows a machine to  be fed with raw data and to automatically discover the representations  needed for detection or classification. Deep-learning methods are  representation-learning methods with multiple levels of representa- tion, obtained by composing simple but non-linear modules that each  transform the representation at one level (starting with the raw input)  into a representation at a higher, slightly more abstract level. With the  composition of enough such transformations, very complex functions  can be learned. For classification tasks, higher layers of representation  amplify aspects of the input that are important for discrimination and  suppress irrelevant variations. An image, for example, comes in the  form of an array of pixel values, and the learned features in the first  layer of representation typically represent the presence or absence of  edges at particular orientations and locations in the image. The second  layer typically detects motifs by spotting particular arrangements of  edges, regardless of small variations in the edge positions. The third  layer may assemble motifs into larger combinations that correspond  to parts of familiar objects, and subsequent layers would detect objects  as combinations of these parts. The key aspect of deep learning is that  these layers of features are not designed by human engineers: they  are learned from data using a general-purpose learning procedure.  

------------------- Sentence 1 -------------------

Representation learning is a set of methods that allows a machine to  be fed with raw data and to automatically discover the representations  needed for detection or classification.

>> Tokens are: 
 ['Representation', 'learning', 'set', 'methods', 'allows', 'machine', 'fed', 'raw', 'data', 'automatically', 'discover', 'representations', 'needed', 'detection', 'classification', '.']

>> Bigrams are: 
 [('Representation', 'learning'), ('learning', 'set'), ('set', 'methods'), ('methods', 'allows'), ('allows', 'machine'), ('machine', 'fed'), ('fed', 'raw'), ('raw', 'data'), ('data', 'automatically'), ('automatically', 'discover'), ('discover', 'representations'), ('representations', 'needed'), ('needed', 'detection'), ('detection', 'classification'), ('classification', '.')]

>> Trigrams are: 
 [('Representation', 'learning', 'set'), ('learning', 'set', 'methods'), ('set', 'methods', 'allows'), ('methods', 'allows', 'machine'), ('allows', 'machine', 'fed'), ('machine', 'fed', 'raw'), ('fed', 'raw', 'data'), ('raw', 'data', 'automatically'), ('data', 'automatically', 'discover'), ('automatically', 'discover', 'representations'), ('discover', 'representations', 'needed'), ('representations', 'needed', 'detection'), ('needed', 'detection', 'classification'), ('detection', 'classification', '.')]

>> POS Tags are: 
 [('Representation', 'NN'), ('learning', 'VBG'), ('set', 'VBN'), ('methods', 'NNS'), ('allows', 'VBZ'), ('machine', 'NN'), ('fed', 'VBN'), ('raw', 'JJ'), ('data', 'NNS'), ('automatically', 'RB'), ('discover', 'VBP'), ('representations', 'NNS'), ('needed', 'VBN'), ('detection', 'NN'), ('classification', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Representation', 'methods', 'machine', 'raw data', 'representations', 'detection classification']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Representation', 'represent'), ('learning', 'learn'), ('set', 'set'), ('methods', 'method'), ('allows', 'allow'), ('machine', 'machin'), ('fed', 'fed'), ('raw', 'raw'), ('data', 'data'), ('automatically', 'automat'), ('discover', 'discov'), ('representations', 'represent'), ('needed', 'need'), ('detection', 'detect'), ('classification', 'classif'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Representation', 'represent'), ('learning', 'learn'), ('set', 'set'), ('methods', 'method'), ('allows', 'allow'), ('machine', 'machin'), ('fed', 'fed'), ('raw', 'raw'), ('data', 'data'), ('automatically', 'automat'), ('discover', 'discov'), ('representations', 'represent'), ('needed', 'need'), ('detection', 'detect'), ('classification', 'classif'), ('.', '.')]

>> Lemmatization: 
 [('Representation', 'Representation'), ('learning', 'learning'), ('set', 'set'), ('methods', 'method'), ('allows', 'allows'), ('machine', 'machine'), ('fed', 'fed'), ('raw', 'raw'), ('data', 'data'), ('automatically', 'automatically'), ('discover', 'discover'), ('representations', 'representation'), ('needed', 'needed'), ('detection', 'detection'), ('classification', 'classification'), ('.', '.')]


------------------- Sentence 2 -------------------

Deep-learning methods are  representation-learning methods with multiple levels of representa- tion, obtained by composing simple but non-linear modules that each  transform the representation at one level (starting with the raw input)  into a representation at a higher, slightly more abstract level.

>> Tokens are: 
 ['Deep-learning', 'methods', 'representation-learning', 'methods', 'multiple', 'levels', 'representa-', 'tion', ',', 'obtained', 'composing', 'simple', 'non-linear', 'modules', 'transform', 'representation', 'one', 'level', '(', 'starting', 'raw', 'input', ')', 'representation', 'higher', ',', 'slightly', 'abstract', 'level', '.']

>> Bigrams are: 
 [('Deep-learning', 'methods'), ('methods', 'representation-learning'), ('representation-learning', 'methods'), ('methods', 'multiple'), ('multiple', 'levels'), ('levels', 'representa-'), ('representa-', 'tion'), ('tion', ','), (',', 'obtained'), ('obtained', 'composing'), ('composing', 'simple'), ('simple', 'non-linear'), ('non-linear', 'modules'), ('modules', 'transform'), ('transform', 'representation'), ('representation', 'one'), ('one', 'level'), ('level', '('), ('(', 'starting'), ('starting', 'raw'), ('raw', 'input'), ('input', ')'), (')', 'representation'), ('representation', 'higher'), ('higher', ','), (',', 'slightly'), ('slightly', 'abstract'), ('abstract', 'level'), ('level', '.')]

>> Trigrams are: 
 [('Deep-learning', 'methods', 'representation-learning'), ('methods', 'representation-learning', 'methods'), ('representation-learning', 'methods', 'multiple'), ('methods', 'multiple', 'levels'), ('multiple', 'levels', 'representa-'), ('levels', 'representa-', 'tion'), ('representa-', 'tion', ','), ('tion', ',', 'obtained'), (',', 'obtained', 'composing'), ('obtained', 'composing', 'simple'), ('composing', 'simple', 'non-linear'), ('simple', 'non-linear', 'modules'), ('non-linear', 'modules', 'transform'), ('modules', 'transform', 'representation'), ('transform', 'representation', 'one'), ('representation', 'one', 'level'), ('one', 'level', '('), ('level', '(', 'starting'), ('(', 'starting', 'raw'), ('starting', 'raw', 'input'), ('raw', 'input', ')'), ('input', ')', 'representation'), (')', 'representation', 'higher'), ('representation', 'higher', ','), ('higher', ',', 'slightly'), (',', 'slightly', 'abstract'), ('slightly', 'abstract', 'level'), ('abstract', 'level', '.')]

>> POS Tags are: 
 [('Deep-learning', 'JJ'), ('methods', 'NNS'), ('representation-learning', 'JJ'), ('methods', 'NNS'), ('multiple', 'JJ'), ('levels', 'NNS'), ('representa-', 'JJ'), ('tion', 'NN'), (',', ','), ('obtained', 'VBD'), ('composing', 'VBG'), ('simple', 'JJ'), ('non-linear', 'JJ'), ('modules', 'NNS'), ('transform', 'VB'), ('representation', 'NN'), ('one', 'CD'), ('level', 'NN'), ('(', '('), ('starting', 'VBG'), ('raw', 'JJ'), ('input', 'NN'), (')', ')'), ('representation', 'NN'), ('higher', 'JJR'), (',', ','), ('slightly', 'RB'), ('abstract', 'JJ'), ('level', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Deep-learning methods', 'representation-learning methods', 'multiple levels', 'representa- tion', 'simple non-linear modules', 'representation', 'level', 'raw input', 'representation', 'abstract level']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Deep-learning', 'deep-learn'), ('methods', 'method'), ('representation-learning', 'representation-learn'), ('methods', 'method'), ('multiple', 'multipl'), ('levels', 'level'), ('representa-', 'representa-'), ('tion', 'tion'), (',', ','), ('obtained', 'obtain'), ('composing', 'compos'), ('simple', 'simpl'), ('non-linear', 'non-linear'), ('modules', 'modul'), ('transform', 'transform'), ('representation', 'represent'), ('one', 'one'), ('level', 'level'), ('(', '('), ('starting', 'start'), ('raw', 'raw'), ('input', 'input'), (')', ')'), ('representation', 'represent'), ('higher', 'higher'), (',', ','), ('slightly', 'slightli'), ('abstract', 'abstract'), ('level', 'level'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Deep-learning', 'deep-learn'), ('methods', 'method'), ('representation-learning', 'representation-learn'), ('methods', 'method'), ('multiple', 'multipl'), ('levels', 'level'), ('representa-', 'representa-'), ('tion', 'tion'), (',', ','), ('obtained', 'obtain'), ('composing', 'compos'), ('simple', 'simpl'), ('non-linear', 'non-linear'), ('modules', 'modul'), ('transform', 'transform'), ('representation', 'represent'), ('one', 'one'), ('level', 'level'), ('(', '('), ('starting', 'start'), ('raw', 'raw'), ('input', 'input'), (')', ')'), ('representation', 'represent'), ('higher', 'higher'), (',', ','), ('slightly', 'slight'), ('abstract', 'abstract'), ('level', 'level'), ('.', '.')]

>> Lemmatization: 
 [('Deep-learning', 'Deep-learning'), ('methods', 'method'), ('representation-learning', 'representation-learning'), ('methods', 'method'), ('multiple', 'multiple'), ('levels', 'level'), ('representa-', 'representa-'), ('tion', 'tion'), (',', ','), ('obtained', 'obtained'), ('composing', 'composing'), ('simple', 'simple'), ('non-linear', 'non-linear'), ('modules', 'module'), ('transform', 'transform'), ('representation', 'representation'), ('one', 'one'), ('level', 'level'), ('(', '('), ('starting', 'starting'), ('raw', 'raw'), ('input', 'input'), (')', ')'), ('representation', 'representation'), ('higher', 'higher'), (',', ','), ('slightly', 'slightly'), ('abstract', 'abstract'), ('level', 'level'), ('.', '.')]


------------------- Sentence 3 -------------------

With the  composition of enough such transformations, very complex functions  can be learned.

>> Tokens are: 
 ['With', 'composition', 'enough', 'transformations', ',', 'complex', 'functions', 'learned', '.']

>> Bigrams are: 
 [('With', 'composition'), ('composition', 'enough'), ('enough', 'transformations'), ('transformations', ','), (',', 'complex'), ('complex', 'functions'), ('functions', 'learned'), ('learned', '.')]

>> Trigrams are: 
 [('With', 'composition', 'enough'), ('composition', 'enough', 'transformations'), ('enough', 'transformations', ','), ('transformations', ',', 'complex'), (',', 'complex', 'functions'), ('complex', 'functions', 'learned'), ('functions', 'learned', '.')]

>> POS Tags are: 
 [('With', 'IN'), ('composition', 'NN'), ('enough', 'JJ'), ('transformations', 'NNS'), (',', ','), ('complex', 'JJ'), ('functions', 'NNS'), ('learned', 'VBD'), ('.', '.')]

>> Noun Phrases are: 
 ['composition', 'enough transformations', 'complex functions']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('With', 'with'), ('composition', 'composit'), ('enough', 'enough'), ('transformations', 'transform'), (',', ','), ('complex', 'complex'), ('functions', 'function'), ('learned', 'learn'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('With', 'with'), ('composition', 'composit'), ('enough', 'enough'), ('transformations', 'transform'), (',', ','), ('complex', 'complex'), ('functions', 'function'), ('learned', 'learn'), ('.', '.')]

>> Lemmatization: 
 [('With', 'With'), ('composition', 'composition'), ('enough', 'enough'), ('transformations', 'transformation'), (',', ','), ('complex', 'complex'), ('functions', 'function'), ('learned', 'learned'), ('.', '.')]


------------------- Sentence 4 -------------------

For classification tasks, higher layers of representation  amplify aspects of the input that are important for discrimination and  suppress irrelevant variations.

>> Tokens are: 
 ['For', 'classification', 'tasks', ',', 'higher', 'layers', 'representation', 'amplify', 'aspects', 'input', 'important', 'discrimination', 'suppress', 'irrelevant', 'variations', '.']

>> Bigrams are: 
 [('For', 'classification'), ('classification', 'tasks'), ('tasks', ','), (',', 'higher'), ('higher', 'layers'), ('layers', 'representation'), ('representation', 'amplify'), ('amplify', 'aspects'), ('aspects', 'input'), ('input', 'important'), ('important', 'discrimination'), ('discrimination', 'suppress'), ('suppress', 'irrelevant'), ('irrelevant', 'variations'), ('variations', '.')]

>> Trigrams are: 
 [('For', 'classification', 'tasks'), ('classification', 'tasks', ','), ('tasks', ',', 'higher'), (',', 'higher', 'layers'), ('higher', 'layers', 'representation'), ('layers', 'representation', 'amplify'), ('representation', 'amplify', 'aspects'), ('amplify', 'aspects', 'input'), ('aspects', 'input', 'important'), ('input', 'important', 'discrimination'), ('important', 'discrimination', 'suppress'), ('discrimination', 'suppress', 'irrelevant'), ('suppress', 'irrelevant', 'variations'), ('irrelevant', 'variations', '.')]

>> POS Tags are: 
 [('For', 'IN'), ('classification', 'NN'), ('tasks', 'NNS'), (',', ','), ('higher', 'JJR'), ('layers', 'NNS'), ('representation', 'VBP'), ('amplify', 'JJ'), ('aspects', 'NNS'), ('input', 'VBP'), ('important', 'JJ'), ('discrimination', 'NN'), ('suppress', 'NN'), ('irrelevant', 'JJ'), ('variations', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['classification tasks', 'layers', 'amplify aspects', 'important discrimination suppress', 'irrelevant variations']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('For', 'for'), ('classification', 'classif'), ('tasks', 'task'), (',', ','), ('higher', 'higher'), ('layers', 'layer'), ('representation', 'represent'), ('amplify', 'amplifi'), ('aspects', 'aspect'), ('input', 'input'), ('important', 'import'), ('discrimination', 'discrimin'), ('suppress', 'suppress'), ('irrelevant', 'irrelev'), ('variations', 'variat'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('For', 'for'), ('classification', 'classif'), ('tasks', 'task'), (',', ','), ('higher', 'higher'), ('layers', 'layer'), ('representation', 'represent'), ('amplify', 'amplifi'), ('aspects', 'aspect'), ('input', 'input'), ('important', 'import'), ('discrimination', 'discrimin'), ('suppress', 'suppress'), ('irrelevant', 'irrelev'), ('variations', 'variat'), ('.', '.')]

>> Lemmatization: 
 [('For', 'For'), ('classification', 'classification'), ('tasks', 'task'), (',', ','), ('higher', 'higher'), ('layers', 'layer'), ('representation', 'representation'), ('amplify', 'amplify'), ('aspects', 'aspect'), ('input', 'input'), ('important', 'important'), ('discrimination', 'discrimination'), ('suppress', 'suppress'), ('irrelevant', 'irrelevant'), ('variations', 'variation'), ('.', '.')]


------------------- Sentence 5 -------------------

An image, for example, comes in the  form of an array of pixel values, and the learned features in the first  layer of representation typically represent the presence or absence of  edges at particular orientations and locations in the image.

>> Tokens are: 
 ['An', 'image', ',', 'example', ',', 'comes', 'form', 'array', 'pixel', 'values', ',', 'learned', 'features', 'first', 'layer', 'representation', 'typically', 'represent', 'presence', 'absence', 'edges', 'particular', 'orientations', 'locations', 'image', '.']

>> Bigrams are: 
 [('An', 'image'), ('image', ','), (',', 'example'), ('example', ','), (',', 'comes'), ('comes', 'form'), ('form', 'array'), ('array', 'pixel'), ('pixel', 'values'), ('values', ','), (',', 'learned'), ('learned', 'features'), ('features', 'first'), ('first', 'layer'), ('layer', 'representation'), ('representation', 'typically'), ('typically', 'represent'), ('represent', 'presence'), ('presence', 'absence'), ('absence', 'edges'), ('edges', 'particular'), ('particular', 'orientations'), ('orientations', 'locations'), ('locations', 'image'), ('image', '.')]

>> Trigrams are: 
 [('An', 'image', ','), ('image', ',', 'example'), (',', 'example', ','), ('example', ',', 'comes'), (',', 'comes', 'form'), ('comes', 'form', 'array'), ('form', 'array', 'pixel'), ('array', 'pixel', 'values'), ('pixel', 'values', ','), ('values', ',', 'learned'), (',', 'learned', 'features'), ('learned', 'features', 'first'), ('features', 'first', 'layer'), ('first', 'layer', 'representation'), ('layer', 'representation', 'typically'), ('representation', 'typically', 'represent'), ('typically', 'represent', 'presence'), ('represent', 'presence', 'absence'), ('presence', 'absence', 'edges'), ('absence', 'edges', 'particular'), ('edges', 'particular', 'orientations'), ('particular', 'orientations', 'locations'), ('orientations', 'locations', 'image'), ('locations', 'image', '.')]

>> POS Tags are: 
 [('An', 'DT'), ('image', 'NN'), (',', ','), ('example', 'NN'), (',', ','), ('comes', 'VBZ'), ('form', 'JJ'), ('array', 'NN'), ('pixel', 'NN'), ('values', 'NNS'), (',', ','), ('learned', 'VBD'), ('features', 'NNS'), ('first', 'JJ'), ('layer', 'JJ'), ('representation', 'NN'), ('typically', 'RB'), ('represent', 'JJ'), ('presence', 'NN'), ('absence', 'NN'), ('edges', 'VBZ'), ('particular', 'JJ'), ('orientations', 'NNS'), ('locations', 'NNS'), ('image', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['An image', 'example', 'form array pixel values', 'features', 'first layer representation', 'represent presence absence', 'particular orientations locations image']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('An', 'an'), ('image', 'imag'), (',', ','), ('example', 'exampl'), (',', ','), ('comes', 'come'), ('form', 'form'), ('array', 'array'), ('pixel', 'pixel'), ('values', 'valu'), (',', ','), ('learned', 'learn'), ('features', 'featur'), ('first', 'first'), ('layer', 'layer'), ('representation', 'represent'), ('typically', 'typic'), ('represent', 'repres'), ('presence', 'presenc'), ('absence', 'absenc'), ('edges', 'edg'), ('particular', 'particular'), ('orientations', 'orient'), ('locations', 'locat'), ('image', 'imag'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('An', 'an'), ('image', 'imag'), (',', ','), ('example', 'exampl'), (',', ','), ('comes', 'come'), ('form', 'form'), ('array', 'array'), ('pixel', 'pixel'), ('values', 'valu'), (',', ','), ('learned', 'learn'), ('features', 'featur'), ('first', 'first'), ('layer', 'layer'), ('representation', 'represent'), ('typically', 'typic'), ('represent', 'repres'), ('presence', 'presenc'), ('absence', 'absenc'), ('edges', 'edg'), ('particular', 'particular'), ('orientations', 'orient'), ('locations', 'locat'), ('image', 'imag'), ('.', '.')]

>> Lemmatization: 
 [('An', 'An'), ('image', 'image'), (',', ','), ('example', 'example'), (',', ','), ('comes', 'come'), ('form', 'form'), ('array', 'array'), ('pixel', 'pixel'), ('values', 'value'), (',', ','), ('learned', 'learned'), ('features', 'feature'), ('first', 'first'), ('layer', 'layer'), ('representation', 'representation'), ('typically', 'typically'), ('represent', 'represent'), ('presence', 'presence'), ('absence', 'absence'), ('edges', 'edge'), ('particular', 'particular'), ('orientations', 'orientation'), ('locations', 'location'), ('image', 'image'), ('.', '.')]


------------------- Sentence 6 -------------------

The second  layer typically detects motifs by spotting particular arrangements of  edges, regardless of small variations in the edge positions.

>> Tokens are: 
 ['The', 'second', 'layer', 'typically', 'detects', 'motifs', 'spotting', 'particular', 'arrangements', 'edges', ',', 'regardless', 'small', 'variations', 'edge', 'positions', '.']

>> Bigrams are: 
 [('The', 'second'), ('second', 'layer'), ('layer', 'typically'), ('typically', 'detects'), ('detects', 'motifs'), ('motifs', 'spotting'), ('spotting', 'particular'), ('particular', 'arrangements'), ('arrangements', 'edges'), ('edges', ','), (',', 'regardless'), ('regardless', 'small'), ('small', 'variations'), ('variations', 'edge'), ('edge', 'positions'), ('positions', '.')]

>> Trigrams are: 
 [('The', 'second', 'layer'), ('second', 'layer', 'typically'), ('layer', 'typically', 'detects'), ('typically', 'detects', 'motifs'), ('detects', 'motifs', 'spotting'), ('motifs', 'spotting', 'particular'), ('spotting', 'particular', 'arrangements'), ('particular', 'arrangements', 'edges'), ('arrangements', 'edges', ','), ('edges', ',', 'regardless'), (',', 'regardless', 'small'), ('regardless', 'small', 'variations'), ('small', 'variations', 'edge'), ('variations', 'edge', 'positions'), ('edge', 'positions', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('second', 'JJ'), ('layer', 'NN'), ('typically', 'RB'), ('detects', 'VBZ'), ('motifs', 'NNS'), ('spotting', 'VBG'), ('particular', 'JJ'), ('arrangements', 'NNS'), ('edges', 'NNS'), (',', ','), ('regardless', 'RB'), ('small', 'JJ'), ('variations', 'NNS'), ('edge', 'VBP'), ('positions', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['The second layer', 'motifs', 'particular arrangements edges', 'small variations', 'positions']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('second', 'second'), ('layer', 'layer'), ('typically', 'typic'), ('detects', 'detect'), ('motifs', 'motif'), ('spotting', 'spot'), ('particular', 'particular'), ('arrangements', 'arrang'), ('edges', 'edg'), (',', ','), ('regardless', 'regardless'), ('small', 'small'), ('variations', 'variat'), ('edge', 'edg'), ('positions', 'posit'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('second', 'second'), ('layer', 'layer'), ('typically', 'typic'), ('detects', 'detect'), ('motifs', 'motif'), ('spotting', 'spot'), ('particular', 'particular'), ('arrangements', 'arrang'), ('edges', 'edg'), (',', ','), ('regardless', 'regardless'), ('small', 'small'), ('variations', 'variat'), ('edge', 'edg'), ('positions', 'posit'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('second', 'second'), ('layer', 'layer'), ('typically', 'typically'), ('detects', 'detects'), ('motifs', 'motif'), ('spotting', 'spotting'), ('particular', 'particular'), ('arrangements', 'arrangement'), ('edges', 'edge'), (',', ','), ('regardless', 'regardless'), ('small', 'small'), ('variations', 'variation'), ('edge', 'edge'), ('positions', 'position'), ('.', '.')]


------------------- Sentence 7 -------------------

The third  layer may assemble motifs into larger combinations that correspond  to parts of familiar objects, and subsequent layers would detect objects  as combinations of these parts.

>> Tokens are: 
 ['The', 'third', 'layer', 'may', 'assemble', 'motifs', 'larger', 'combinations', 'correspond', 'parts', 'familiar', 'objects', ',', 'subsequent', 'layers', 'would', 'detect', 'objects', 'combinations', 'parts', '.']

>> Bigrams are: 
 [('The', 'third'), ('third', 'layer'), ('layer', 'may'), ('may', 'assemble'), ('assemble', 'motifs'), ('motifs', 'larger'), ('larger', 'combinations'), ('combinations', 'correspond'), ('correspond', 'parts'), ('parts', 'familiar'), ('familiar', 'objects'), ('objects', ','), (',', 'subsequent'), ('subsequent', 'layers'), ('layers', 'would'), ('would', 'detect'), ('detect', 'objects'), ('objects', 'combinations'), ('combinations', 'parts'), ('parts', '.')]

>> Trigrams are: 
 [('The', 'third', 'layer'), ('third', 'layer', 'may'), ('layer', 'may', 'assemble'), ('may', 'assemble', 'motifs'), ('assemble', 'motifs', 'larger'), ('motifs', 'larger', 'combinations'), ('larger', 'combinations', 'correspond'), ('combinations', 'correspond', 'parts'), ('correspond', 'parts', 'familiar'), ('parts', 'familiar', 'objects'), ('familiar', 'objects', ','), ('objects', ',', 'subsequent'), (',', 'subsequent', 'layers'), ('subsequent', 'layers', 'would'), ('layers', 'would', 'detect'), ('would', 'detect', 'objects'), ('detect', 'objects', 'combinations'), ('objects', 'combinations', 'parts'), ('combinations', 'parts', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('third', 'JJ'), ('layer', 'NN'), ('may', 'MD'), ('assemble', 'VB'), ('motifs', 'NNS'), ('larger', 'JJR'), ('combinations', 'NNS'), ('correspond', 'NN'), ('parts', 'NNS'), ('familiar', 'JJ'), ('objects', 'NNS'), (',', ','), ('subsequent', 'JJ'), ('layers', 'NNS'), ('would', 'MD'), ('detect', 'VB'), ('objects', 'NNS'), ('combinations', 'NNS'), ('parts', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['The third layer', 'motifs', 'combinations correspond parts', 'familiar objects', 'subsequent layers', 'objects combinations parts']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('third', 'third'), ('layer', 'layer'), ('may', 'may'), ('assemble', 'assembl'), ('motifs', 'motif'), ('larger', 'larger'), ('combinations', 'combin'), ('correspond', 'correspond'), ('parts', 'part'), ('familiar', 'familiar'), ('objects', 'object'), (',', ','), ('subsequent', 'subsequ'), ('layers', 'layer'), ('would', 'would'), ('detect', 'detect'), ('objects', 'object'), ('combinations', 'combin'), ('parts', 'part'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('third', 'third'), ('layer', 'layer'), ('may', 'may'), ('assemble', 'assembl'), ('motifs', 'motif'), ('larger', 'larger'), ('combinations', 'combin'), ('correspond', 'correspond'), ('parts', 'part'), ('familiar', 'familiar'), ('objects', 'object'), (',', ','), ('subsequent', 'subsequ'), ('layers', 'layer'), ('would', 'would'), ('detect', 'detect'), ('objects', 'object'), ('combinations', 'combin'), ('parts', 'part'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('third', 'third'), ('layer', 'layer'), ('may', 'may'), ('assemble', 'assemble'), ('motifs', 'motif'), ('larger', 'larger'), ('combinations', 'combination'), ('correspond', 'correspond'), ('parts', 'part'), ('familiar', 'familiar'), ('objects', 'object'), (',', ','), ('subsequent', 'subsequent'), ('layers', 'layer'), ('would', 'would'), ('detect', 'detect'), ('objects', 'object'), ('combinations', 'combination'), ('parts', 'part'), ('.', '.')]


------------------- Sentence 8 -------------------

The key aspect of deep learning is that  these layers of features are not designed by human engineers: they  are learned from data using a general-purpose learning procedure.

>> Tokens are: 
 ['The', 'key', 'aspect', 'deep', 'learning', 'layers', 'features', 'designed', 'human', 'engineers', ':', 'learned', 'data', 'using', 'general-purpose', 'learning', 'procedure', '.']

>> Bigrams are: 
 [('The', 'key'), ('key', 'aspect'), ('aspect', 'deep'), ('deep', 'learning'), ('learning', 'layers'), ('layers', 'features'), ('features', 'designed'), ('designed', 'human'), ('human', 'engineers'), ('engineers', ':'), (':', 'learned'), ('learned', 'data'), ('data', 'using'), ('using', 'general-purpose'), ('general-purpose', 'learning'), ('learning', 'procedure'), ('procedure', '.')]

>> Trigrams are: 
 [('The', 'key', 'aspect'), ('key', 'aspect', 'deep'), ('aspect', 'deep', 'learning'), ('deep', 'learning', 'layers'), ('learning', 'layers', 'features'), ('layers', 'features', 'designed'), ('features', 'designed', 'human'), ('designed', 'human', 'engineers'), ('human', 'engineers', ':'), ('engineers', ':', 'learned'), (':', 'learned', 'data'), ('learned', 'data', 'using'), ('data', 'using', 'general-purpose'), ('using', 'general-purpose', 'learning'), ('general-purpose', 'learning', 'procedure'), ('learning', 'procedure', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('key', 'JJ'), ('aspect', 'JJ'), ('deep', 'JJ'), ('learning', 'NN'), ('layers', 'NNS'), ('features', 'NNS'), ('designed', 'VBN'), ('human', 'JJ'), ('engineers', 'NNS'), (':', ':'), ('learned', 'VBN'), ('data', 'NNS'), ('using', 'VBG'), ('general-purpose', 'JJ'), ('learning', 'JJ'), ('procedure', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['The key aspect deep learning layers features', 'human engineers', 'data', 'general-purpose learning procedure']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('key', 'key'), ('aspect', 'aspect'), ('deep', 'deep'), ('learning', 'learn'), ('layers', 'layer'), ('features', 'featur'), ('designed', 'design'), ('human', 'human'), ('engineers', 'engin'), (':', ':'), ('learned', 'learn'), ('data', 'data'), ('using', 'use'), ('general-purpose', 'general-purpos'), ('learning', 'learn'), ('procedure', 'procedur'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('key', 'key'), ('aspect', 'aspect'), ('deep', 'deep'), ('learning', 'learn'), ('layers', 'layer'), ('features', 'featur'), ('designed', 'design'), ('human', 'human'), ('engineers', 'engin'), (':', ':'), ('learned', 'learn'), ('data', 'data'), ('using', 'use'), ('general-purpose', 'general-purpos'), ('learning', 'learn'), ('procedure', 'procedur'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('key', 'key'), ('aspect', 'aspect'), ('deep', 'deep'), ('learning', 'learning'), ('layers', 'layer'), ('features', 'feature'), ('designed', 'designed'), ('human', 'human'), ('engineers', 'engineer'), (':', ':'), ('learned', 'learned'), ('data', 'data'), ('using', 'using'), ('general-purpose', 'general-purpose'), ('learning', 'learning'), ('procedure', 'procedure'), ('.', '.')]



========================================== PARAGRAPH 5 ===========================================

Deep learning is making major advances in solving problems that  have resisted the best attempts of the artificial intelligence commu- nity for many years. It has turned out to be very good at discovering  

------------------- Sentence 1 -------------------

Deep learning is making major advances in solving problems that  have resisted the best attempts of the artificial intelligence commu- nity for many years.

>> Tokens are: 
 ['Deep', 'learning', 'making', 'major', 'advances', 'solving', 'problems', 'resisted', 'best', 'attempts', 'artificial', 'intelligence', 'commu-', 'nity', 'many', 'years', '.']

>> Bigrams are: 
 [('Deep', 'learning'), ('learning', 'making'), ('making', 'major'), ('major', 'advances'), ('advances', 'solving'), ('solving', 'problems'), ('problems', 'resisted'), ('resisted', 'best'), ('best', 'attempts'), ('attempts', 'artificial'), ('artificial', 'intelligence'), ('intelligence', 'commu-'), ('commu-', 'nity'), ('nity', 'many'), ('many', 'years'), ('years', '.')]

>> Trigrams are: 
 [('Deep', 'learning', 'making'), ('learning', 'making', 'major'), ('making', 'major', 'advances'), ('major', 'advances', 'solving'), ('advances', 'solving', 'problems'), ('solving', 'problems', 'resisted'), ('problems', 'resisted', 'best'), ('resisted', 'best', 'attempts'), ('best', 'attempts', 'artificial'), ('attempts', 'artificial', 'intelligence'), ('artificial', 'intelligence', 'commu-'), ('intelligence', 'commu-', 'nity'), ('commu-', 'nity', 'many'), ('nity', 'many', 'years'), ('many', 'years', '.')]

>> POS Tags are: 
 [('Deep', 'JJ'), ('learning', 'NN'), ('making', 'VBG'), ('major', 'JJ'), ('advances', 'NNS'), ('solving', 'VBG'), ('problems', 'NNS'), ('resisted', 'VBD'), ('best', 'JJS'), ('attempts', 'NNS'), ('artificial', 'JJ'), ('intelligence', 'NN'), ('commu-', 'JJ'), ('nity', 'NN'), ('many', 'JJ'), ('years', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['Deep learning', 'major advances', 'problems', 'attempts', 'artificial intelligence', 'commu- nity', 'many years']

>> Named Entities are: 
 [('GPE', 'Deep')] 

>> Stemming using Porter Stemmer: 
 [('Deep', 'deep'), ('learning', 'learn'), ('making', 'make'), ('major', 'major'), ('advances', 'advanc'), ('solving', 'solv'), ('problems', 'problem'), ('resisted', 'resist'), ('best', 'best'), ('attempts', 'attempt'), ('artificial', 'artifici'), ('intelligence', 'intellig'), ('commu-', 'commu-'), ('nity', 'niti'), ('many', 'mani'), ('years', 'year'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Deep', 'deep'), ('learning', 'learn'), ('making', 'make'), ('major', 'major'), ('advances', 'advanc'), ('solving', 'solv'), ('problems', 'problem'), ('resisted', 'resist'), ('best', 'best'), ('attempts', 'attempt'), ('artificial', 'artifici'), ('intelligence', 'intellig'), ('commu-', 'commu-'), ('nity', 'niti'), ('many', 'mani'), ('years', 'year'), ('.', '.')]

>> Lemmatization: 
 [('Deep', 'Deep'), ('learning', 'learning'), ('making', 'making'), ('major', 'major'), ('advances', 'advance'), ('solving', 'solving'), ('problems', 'problem'), ('resisted', 'resisted'), ('best', 'best'), ('attempts', 'attempt'), ('artificial', 'artificial'), ('intelligence', 'intelligence'), ('commu-', 'commu-'), ('nity', 'nity'), ('many', 'many'), ('years', 'year'), ('.', '.')]


------------------- Sentence 2 -------------------

It has turned out to be very good at discovering

>> Tokens are: 
 ['It', 'turned', 'good', 'discovering']

>> Bigrams are: 
 [('It', 'turned'), ('turned', 'good'), ('good', 'discovering')]

>> Trigrams are: 
 [('It', 'turned', 'good'), ('turned', 'good', 'discovering')]

>> POS Tags are: 
 [('It', 'PRP'), ('turned', 'VBD'), ('good', 'JJ'), ('discovering', 'NN')]

>> Noun Phrases are: 
 ['good discovering']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('It', 'it'), ('turned', 'turn'), ('good', 'good'), ('discovering', 'discov')]

>> Stemming using Snowball Stemmer: 
 [('It', 'it'), ('turned', 'turn'), ('good', 'good'), ('discovering', 'discov')]

>> Lemmatization: 
 [('It', 'It'), ('turned', 'turned'), ('good', 'good'), ('discovering', 'discovering')]



========================================== PARAGRAPH 6 ===========================================

intricate structures in high-dimensional data and is therefore applica- ble to many domains of science, business and government. In addition  to beating records in image recognition1–4 and speech recognition5–7, it  has beaten other machine-learning techniques at predicting the activ- ity of potential drug molecules8, analysing particle accelerator data9,10,  reconstructing brain circuits11, and predicting the effects of mutations  in non-coding DNA on gene expression and disease12,13. Perhaps more  surprisingly, deep learning has produced extremely promising results  for various tasks in natural language understanding14, particularly  topic classification, sentiment analysis, question answering15 and lan- guage translation16,17.  

------------------- Sentence 1 -------------------

intricate structures in high-dimensional data and is therefore applica- ble to many domains of science, business and government.

>> Tokens are: 
 ['intricate', 'structures', 'high-dimensional', 'data', 'therefore', 'applica-', 'ble', 'many', 'domains', 'science', ',', 'business', 'government', '.']

>> Bigrams are: 
 [('intricate', 'structures'), ('structures', 'high-dimensional'), ('high-dimensional', 'data'), ('data', 'therefore'), ('therefore', 'applica-'), ('applica-', 'ble'), ('ble', 'many'), ('many', 'domains'), ('domains', 'science'), ('science', ','), (',', 'business'), ('business', 'government'), ('government', '.')]

>> Trigrams are: 
 [('intricate', 'structures', 'high-dimensional'), ('structures', 'high-dimensional', 'data'), ('high-dimensional', 'data', 'therefore'), ('data', 'therefore', 'applica-'), ('therefore', 'applica-', 'ble'), ('applica-', 'ble', 'many'), ('ble', 'many', 'domains'), ('many', 'domains', 'science'), ('domains', 'science', ','), ('science', ',', 'business'), (',', 'business', 'government'), ('business', 'government', '.')]

>> POS Tags are: 
 [('intricate', 'JJ'), ('structures', 'NNS'), ('high-dimensional', 'JJ'), ('data', 'NNS'), ('therefore', 'RB'), ('applica-', 'JJ'), ('ble', 'JJ'), ('many', 'JJ'), ('domains', 'NNS'), ('science', 'NN'), (',', ','), ('business', 'NN'), ('government', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['intricate structures', 'high-dimensional data', 'applica- ble many domains science', 'business government']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('intricate', 'intric'), ('structures', 'structur'), ('high-dimensional', 'high-dimension'), ('data', 'data'), ('therefore', 'therefor'), ('applica-', 'applica-'), ('ble', 'ble'), ('many', 'mani'), ('domains', 'domain'), ('science', 'scienc'), (',', ','), ('business', 'busi'), ('government', 'govern'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('intricate', 'intric'), ('structures', 'structur'), ('high-dimensional', 'high-dimension'), ('data', 'data'), ('therefore', 'therefor'), ('applica-', 'applica-'), ('ble', 'ble'), ('many', 'mani'), ('domains', 'domain'), ('science', 'scienc'), (',', ','), ('business', 'busi'), ('government', 'govern'), ('.', '.')]

>> Lemmatization: 
 [('intricate', 'intricate'), ('structures', 'structure'), ('high-dimensional', 'high-dimensional'), ('data', 'data'), ('therefore', 'therefore'), ('applica-', 'applica-'), ('ble', 'ble'), ('many', 'many'), ('domains', 'domain'), ('science', 'science'), (',', ','), ('business', 'business'), ('government', 'government'), ('.', '.')]


------------------- Sentence 2 -------------------

In addition  to beating records in image recognition1–4 and speech recognition5–7, it  has beaten other machine-learning techniques at predicting the activ- ity of potential drug molecules8, analysing particle accelerator data9,10,  reconstructing brain circuits11, and predicting the effects of mutations  in non-coding DNA on gene expression and disease12,13.

>> Tokens are: 
 ['In', 'addition', 'beating', 'records', 'image', 'recognition1–4', 'speech', 'recognition5–7', ',', 'beaten', 'machine-learning', 'techniques', 'predicting', 'activ-', 'ity', 'potential', 'drug', 'molecules8', ',', 'analysing', 'particle', 'accelerator', 'data9,10', ',', 'reconstructing', 'brain', 'circuits11', ',', 'predicting', 'effects', 'mutations', 'non-coding', 'DNA', 'gene', 'expression', 'disease12,13', '.']

>> Bigrams are: 
 [('In', 'addition'), ('addition', 'beating'), ('beating', 'records'), ('records', 'image'), ('image', 'recognition1–4'), ('recognition1–4', 'speech'), ('speech', 'recognition5–7'), ('recognition5–7', ','), (',', 'beaten'), ('beaten', 'machine-learning'), ('machine-learning', 'techniques'), ('techniques', 'predicting'), ('predicting', 'activ-'), ('activ-', 'ity'), ('ity', 'potential'), ('potential', 'drug'), ('drug', 'molecules8'), ('molecules8', ','), (',', 'analysing'), ('analysing', 'particle'), ('particle', 'accelerator'), ('accelerator', 'data9,10'), ('data9,10', ','), (',', 'reconstructing'), ('reconstructing', 'brain'), ('brain', 'circuits11'), ('circuits11', ','), (',', 'predicting'), ('predicting', 'effects'), ('effects', 'mutations'), ('mutations', 'non-coding'), ('non-coding', 'DNA'), ('DNA', 'gene'), ('gene', 'expression'), ('expression', 'disease12,13'), ('disease12,13', '.')]

>> Trigrams are: 
 [('In', 'addition', 'beating'), ('addition', 'beating', 'records'), ('beating', 'records', 'image'), ('records', 'image', 'recognition1–4'), ('image', 'recognition1–4', 'speech'), ('recognition1–4', 'speech', 'recognition5–7'), ('speech', 'recognition5–7', ','), ('recognition5–7', ',', 'beaten'), (',', 'beaten', 'machine-learning'), ('beaten', 'machine-learning', 'techniques'), ('machine-learning', 'techniques', 'predicting'), ('techniques', 'predicting', 'activ-'), ('predicting', 'activ-', 'ity'), ('activ-', 'ity', 'potential'), ('ity', 'potential', 'drug'), ('potential', 'drug', 'molecules8'), ('drug', 'molecules8', ','), ('molecules8', ',', 'analysing'), (',', 'analysing', 'particle'), ('analysing', 'particle', 'accelerator'), ('particle', 'accelerator', 'data9,10'), ('accelerator', 'data9,10', ','), ('data9,10', ',', 'reconstructing'), (',', 'reconstructing', 'brain'), ('reconstructing', 'brain', 'circuits11'), ('brain', 'circuits11', ','), ('circuits11', ',', 'predicting'), (',', 'predicting', 'effects'), ('predicting', 'effects', 'mutations'), ('effects', 'mutations', 'non-coding'), ('mutations', 'non-coding', 'DNA'), ('non-coding', 'DNA', 'gene'), ('DNA', 'gene', 'expression'), ('gene', 'expression', 'disease12,13'), ('expression', 'disease12,13', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('addition', 'NN'), ('beating', 'NN'), ('records', 'NNS'), ('image', 'NN'), ('recognition1–4', 'NN'), ('speech', 'NN'), ('recognition5–7', 'NN'), (',', ','), ('beaten', 'JJ'), ('machine-learning', 'JJ'), ('techniques', 'NNS'), ('predicting', 'VBG'), ('activ-', 'JJ'), ('ity', 'NN'), ('potential', 'JJ'), ('drug', 'NN'), ('molecules8', 'NN'), (',', ','), ('analysing', 'VBG'), ('particle', 'NN'), ('accelerator', 'NN'), ('data9,10', 'NN'), (',', ','), ('reconstructing', 'VBG'), ('brain', 'NN'), ('circuits11', 'NN'), (',', ','), ('predicting', 'VBG'), ('effects', 'NNS'), ('mutations', 'NNS'), ('non-coding', 'JJ'), ('DNA', 'NNP'), ('gene', 'NN'), ('expression', 'NN'), ('disease12,13', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['addition beating records image recognition1–4 speech recognition5–7', 'beaten machine-learning techniques', 'activ- ity', 'potential drug molecules8', 'particle accelerator data9,10', 'brain circuits11', 'effects mutations', 'non-coding DNA gene expression disease12,13']

>> Named Entities are: 
 [('ORGANIZATION', 'DNA')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('addition', 'addit'), ('beating', 'beat'), ('records', 'record'), ('image', 'imag'), ('recognition1–4', 'recognition1–4'), ('speech', 'speech'), ('recognition5–7', 'recognition5–7'), (',', ','), ('beaten', 'beaten'), ('machine-learning', 'machine-learn'), ('techniques', 'techniqu'), ('predicting', 'predict'), ('activ-', 'activ-'), ('ity', 'iti'), ('potential', 'potenti'), ('drug', 'drug'), ('molecules8', 'molecules8'), (',', ','), ('analysing', 'analys'), ('particle', 'particl'), ('accelerator', 'acceler'), ('data9,10', 'data9,10'), (',', ','), ('reconstructing', 'reconstruct'), ('brain', 'brain'), ('circuits11', 'circuits11'), (',', ','), ('predicting', 'predict'), ('effects', 'effect'), ('mutations', 'mutat'), ('non-coding', 'non-cod'), ('DNA', 'dna'), ('gene', 'gene'), ('expression', 'express'), ('disease12,13', 'disease12,13'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('addition', 'addit'), ('beating', 'beat'), ('records', 'record'), ('image', 'imag'), ('recognition1–4', 'recognition1–4'), ('speech', 'speech'), ('recognition5–7', 'recognition5–7'), (',', ','), ('beaten', 'beaten'), ('machine-learning', 'machine-learn'), ('techniques', 'techniqu'), ('predicting', 'predict'), ('activ-', 'activ-'), ('ity', 'iti'), ('potential', 'potenti'), ('drug', 'drug'), ('molecules8', 'molecules8'), (',', ','), ('analysing', 'analys'), ('particle', 'particl'), ('accelerator', 'acceler'), ('data9,10', 'data9,10'), (',', ','), ('reconstructing', 'reconstruct'), ('brain', 'brain'), ('circuits11', 'circuits11'), (',', ','), ('predicting', 'predict'), ('effects', 'effect'), ('mutations', 'mutat'), ('non-coding', 'non-cod'), ('DNA', 'dna'), ('gene', 'gene'), ('expression', 'express'), ('disease12,13', 'disease12,13'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('addition', 'addition'), ('beating', 'beating'), ('records', 'record'), ('image', 'image'), ('recognition1–4', 'recognition1–4'), ('speech', 'speech'), ('recognition5–7', 'recognition5–7'), (',', ','), ('beaten', 'beaten'), ('machine-learning', 'machine-learning'), ('techniques', 'technique'), ('predicting', 'predicting'), ('activ-', 'activ-'), ('ity', 'ity'), ('potential', 'potential'), ('drug', 'drug'), ('molecules8', 'molecules8'), (',', ','), ('analysing', 'analysing'), ('particle', 'particle'), ('accelerator', 'accelerator'), ('data9,10', 'data9,10'), (',', ','), ('reconstructing', 'reconstructing'), ('brain', 'brain'), ('circuits11', 'circuits11'), (',', ','), ('predicting', 'predicting'), ('effects', 'effect'), ('mutations', 'mutation'), ('non-coding', 'non-coding'), ('DNA', 'DNA'), ('gene', 'gene'), ('expression', 'expression'), ('disease12,13', 'disease12,13'), ('.', '.')]


------------------- Sentence 3 -------------------

Perhaps more  surprisingly, deep learning has produced extremely promising results  for various tasks in natural language understanding14, particularly  topic classification, sentiment analysis, question answering15 and lan- guage translation16,17.

>> Tokens are: 
 ['Perhaps', 'surprisingly', ',', 'deep', 'learning', 'produced', 'extremely', 'promising', 'results', 'various', 'tasks', 'natural', 'language', 'understanding14', ',', 'particularly', 'topic', 'classification', ',', 'sentiment', 'analysis', ',', 'question', 'answering15', 'lan-', 'guage', 'translation16,17', '.']

>> Bigrams are: 
 [('Perhaps', 'surprisingly'), ('surprisingly', ','), (',', 'deep'), ('deep', 'learning'), ('learning', 'produced'), ('produced', 'extremely'), ('extremely', 'promising'), ('promising', 'results'), ('results', 'various'), ('various', 'tasks'), ('tasks', 'natural'), ('natural', 'language'), ('language', 'understanding14'), ('understanding14', ','), (',', 'particularly'), ('particularly', 'topic'), ('topic', 'classification'), ('classification', ','), (',', 'sentiment'), ('sentiment', 'analysis'), ('analysis', ','), (',', 'question'), ('question', 'answering15'), ('answering15', 'lan-'), ('lan-', 'guage'), ('guage', 'translation16,17'), ('translation16,17', '.')]

>> Trigrams are: 
 [('Perhaps', 'surprisingly', ','), ('surprisingly', ',', 'deep'), (',', 'deep', 'learning'), ('deep', 'learning', 'produced'), ('learning', 'produced', 'extremely'), ('produced', 'extremely', 'promising'), ('extremely', 'promising', 'results'), ('promising', 'results', 'various'), ('results', 'various', 'tasks'), ('various', 'tasks', 'natural'), ('tasks', 'natural', 'language'), ('natural', 'language', 'understanding14'), ('language', 'understanding14', ','), ('understanding14', ',', 'particularly'), (',', 'particularly', 'topic'), ('particularly', 'topic', 'classification'), ('topic', 'classification', ','), ('classification', ',', 'sentiment'), (',', 'sentiment', 'analysis'), ('sentiment', 'analysis', ','), ('analysis', ',', 'question'), (',', 'question', 'answering15'), ('question', 'answering15', 'lan-'), ('answering15', 'lan-', 'guage'), ('lan-', 'guage', 'translation16,17'), ('guage', 'translation16,17', '.')]

>> POS Tags are: 
 [('Perhaps', 'RB'), ('surprisingly', 'RB'), (',', ','), ('deep', 'JJ'), ('learning', 'NN'), ('produced', 'VBD'), ('extremely', 'RB'), ('promising', 'JJ'), ('results', 'NNS'), ('various', 'JJ'), ('tasks', 'NNS'), ('natural', 'JJ'), ('language', 'NN'), ('understanding14', 'JJ'), (',', ','), ('particularly', 'RB'), ('topic', 'JJ'), ('classification', 'NN'), (',', ','), ('sentiment', 'NN'), ('analysis', 'NN'), (',', ','), ('question', 'NN'), ('answering15', 'IN'), ('lan-', 'JJ'), ('guage', 'NN'), ('translation16,17', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['deep learning', 'promising results', 'various tasks', 'natural language', 'topic classification', 'sentiment analysis', 'question', 'lan- guage translation16,17']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Perhaps', 'perhap'), ('surprisingly', 'surprisingli'), (',', ','), ('deep', 'deep'), ('learning', 'learn'), ('produced', 'produc'), ('extremely', 'extrem'), ('promising', 'promis'), ('results', 'result'), ('various', 'variou'), ('tasks', 'task'), ('natural', 'natur'), ('language', 'languag'), ('understanding14', 'understanding14'), (',', ','), ('particularly', 'particularli'), ('topic', 'topic'), ('classification', 'classif'), (',', ','), ('sentiment', 'sentiment'), ('analysis', 'analysi'), (',', ','), ('question', 'question'), ('answering15', 'answering15'), ('lan-', 'lan-'), ('guage', 'guag'), ('translation16,17', 'translation16,17'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Perhaps', 'perhap'), ('surprisingly', 'surpris'), (',', ','), ('deep', 'deep'), ('learning', 'learn'), ('produced', 'produc'), ('extremely', 'extrem'), ('promising', 'promis'), ('results', 'result'), ('various', 'various'), ('tasks', 'task'), ('natural', 'natur'), ('language', 'languag'), ('understanding14', 'understanding14'), (',', ','), ('particularly', 'particular'), ('topic', 'topic'), ('classification', 'classif'), (',', ','), ('sentiment', 'sentiment'), ('analysis', 'analysi'), (',', ','), ('question', 'question'), ('answering15', 'answering15'), ('lan-', 'lan-'), ('guage', 'guag'), ('translation16,17', 'translation16,17'), ('.', '.')]

>> Lemmatization: 
 [('Perhaps', 'Perhaps'), ('surprisingly', 'surprisingly'), (',', ','), ('deep', 'deep'), ('learning', 'learning'), ('produced', 'produced'), ('extremely', 'extremely'), ('promising', 'promising'), ('results', 'result'), ('various', 'various'), ('tasks', 'task'), ('natural', 'natural'), ('language', 'language'), ('understanding14', 'understanding14'), (',', ','), ('particularly', 'particularly'), ('topic', 'topic'), ('classification', 'classification'), (',', ','), ('sentiment', 'sentiment'), ('analysis', 'analysis'), (',', ','), ('question', 'question'), ('answering15', 'answering15'), ('lan-', 'lan-'), ('guage', 'guage'), ('translation16,17', 'translation16,17'), ('.', '.')]



========================================== PARAGRAPH 7 ===========================================

We think that deep learning will have many more successes in the  near future because it requires very little engineering by hand, so it  can easily take advantage of increases in the amount of available com- putation and data. New learning algorithms and architectures that are  currently being developed for deep neural networks will only acceler- ate this progress.  

------------------- Sentence 1 -------------------

We think that deep learning will have many more successes in the  near future because it requires very little engineering by hand, so it  can easily take advantage of increases in the amount of available com- putation and data.

>> Tokens are: 
 ['We', 'think', 'deep', 'learning', 'many', 'successes', 'near', 'future', 'requires', 'little', 'engineering', 'hand', ',', 'easily', 'take', 'advantage', 'increases', 'amount', 'available', 'com-', 'putation', 'data', '.']

>> Bigrams are: 
 [('We', 'think'), ('think', 'deep'), ('deep', 'learning'), ('learning', 'many'), ('many', 'successes'), ('successes', 'near'), ('near', 'future'), ('future', 'requires'), ('requires', 'little'), ('little', 'engineering'), ('engineering', 'hand'), ('hand', ','), (',', 'easily'), ('easily', 'take'), ('take', 'advantage'), ('advantage', 'increases'), ('increases', 'amount'), ('amount', 'available'), ('available', 'com-'), ('com-', 'putation'), ('putation', 'data'), ('data', '.')]

>> Trigrams are: 
 [('We', 'think', 'deep'), ('think', 'deep', 'learning'), ('deep', 'learning', 'many'), ('learning', 'many', 'successes'), ('many', 'successes', 'near'), ('successes', 'near', 'future'), ('near', 'future', 'requires'), ('future', 'requires', 'little'), ('requires', 'little', 'engineering'), ('little', 'engineering', 'hand'), ('engineering', 'hand', ','), ('hand', ',', 'easily'), (',', 'easily', 'take'), ('easily', 'take', 'advantage'), ('take', 'advantage', 'increases'), ('advantage', 'increases', 'amount'), ('increases', 'amount', 'available'), ('amount', 'available', 'com-'), ('available', 'com-', 'putation'), ('com-', 'putation', 'data'), ('putation', 'data', '.')]

>> POS Tags are: 
 [('We', 'PRP'), ('think', 'VBP'), ('deep', 'JJ'), ('learning', 'VBG'), ('many', 'JJ'), ('successes', 'NNS'), ('near', 'IN'), ('future', 'JJ'), ('requires', 'VBZ'), ('little', 'JJ'), ('engineering', 'NN'), ('hand', 'NN'), (',', ','), ('easily', 'RB'), ('take', 'VB'), ('advantage', 'NN'), ('increases', 'NNS'), ('amount', 'VBP'), ('available', 'JJ'), ('com-', 'JJ'), ('putation', 'NN'), ('data', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['many successes', 'little engineering hand', 'advantage increases', 'available com- putation data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('We', 'we'), ('think', 'think'), ('deep', 'deep'), ('learning', 'learn'), ('many', 'mani'), ('successes', 'success'), ('near', 'near'), ('future', 'futur'), ('requires', 'requir'), ('little', 'littl'), ('engineering', 'engin'), ('hand', 'hand'), (',', ','), ('easily', 'easili'), ('take', 'take'), ('advantage', 'advantag'), ('increases', 'increas'), ('amount', 'amount'), ('available', 'avail'), ('com-', 'com-'), ('putation', 'putat'), ('data', 'data'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('We', 'we'), ('think', 'think'), ('deep', 'deep'), ('learning', 'learn'), ('many', 'mani'), ('successes', 'success'), ('near', 'near'), ('future', 'futur'), ('requires', 'requir'), ('little', 'littl'), ('engineering', 'engin'), ('hand', 'hand'), (',', ','), ('easily', 'easili'), ('take', 'take'), ('advantage', 'advantag'), ('increases', 'increas'), ('amount', 'amount'), ('available', 'avail'), ('com-', 'com-'), ('putation', 'putat'), ('data', 'data'), ('.', '.')]

>> Lemmatization: 
 [('We', 'We'), ('think', 'think'), ('deep', 'deep'), ('learning', 'learning'), ('many', 'many'), ('successes', 'success'), ('near', 'near'), ('future', 'future'), ('requires', 'requires'), ('little', 'little'), ('engineering', 'engineering'), ('hand', 'hand'), (',', ','), ('easily', 'easily'), ('take', 'take'), ('advantage', 'advantage'), ('increases', 'increase'), ('amount', 'amount'), ('available', 'available'), ('com-', 'com-'), ('putation', 'putation'), ('data', 'data'), ('.', '.')]


------------------- Sentence 2 -------------------

New learning algorithms and architectures that are  currently being developed for deep neural networks will only acceler- ate this progress.

>> Tokens are: 
 ['New', 'learning', 'algorithms', 'architectures', 'currently', 'developed', 'deep', 'neural', 'networks', 'acceler-', 'ate', 'progress', '.']

>> Bigrams are: 
 [('New', 'learning'), ('learning', 'algorithms'), ('algorithms', 'architectures'), ('architectures', 'currently'), ('currently', 'developed'), ('developed', 'deep'), ('deep', 'neural'), ('neural', 'networks'), ('networks', 'acceler-'), ('acceler-', 'ate'), ('ate', 'progress'), ('progress', '.')]

>> Trigrams are: 
 [('New', 'learning', 'algorithms'), ('learning', 'algorithms', 'architectures'), ('algorithms', 'architectures', 'currently'), ('architectures', 'currently', 'developed'), ('currently', 'developed', 'deep'), ('developed', 'deep', 'neural'), ('deep', 'neural', 'networks'), ('neural', 'networks', 'acceler-'), ('networks', 'acceler-', 'ate'), ('acceler-', 'ate', 'progress'), ('ate', 'progress', '.')]

>> POS Tags are: 
 [('New', 'NNP'), ('learning', 'VBG'), ('algorithms', 'JJ'), ('architectures', 'NNS'), ('currently', 'RB'), ('developed', 'VBD'), ('deep', 'JJ'), ('neural', 'JJ'), ('networks', 'NNS'), ('acceler-', 'JJ'), ('ate', 'JJ'), ('progress', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['New', 'algorithms architectures', 'deep neural networks', 'acceler- ate progress']

>> Named Entities are: 
 [('GPE', 'New')] 

>> Stemming using Porter Stemmer: 
 [('New', 'new'), ('learning', 'learn'), ('algorithms', 'algorithm'), ('architectures', 'architectur'), ('currently', 'current'), ('developed', 'develop'), ('deep', 'deep'), ('neural', 'neural'), ('networks', 'network'), ('acceler-', 'acceler-'), ('ate', 'ate'), ('progress', 'progress'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('New', 'new'), ('learning', 'learn'), ('algorithms', 'algorithm'), ('architectures', 'architectur'), ('currently', 'current'), ('developed', 'develop'), ('deep', 'deep'), ('neural', 'neural'), ('networks', 'network'), ('acceler-', 'acceler-'), ('ate', 'ate'), ('progress', 'progress'), ('.', '.')]

>> Lemmatization: 
 [('New', 'New'), ('learning', 'learning'), ('algorithms', 'algorithm'), ('architectures', 'architecture'), ('currently', 'currently'), ('developed', 'developed'), ('deep', 'deep'), ('neural', 'neural'), ('networks', 'network'), ('acceler-', 'acceler-'), ('ate', 'ate'), ('progress', 'progress'), ('.', '.')]



========================================== PARAGRAPH 8 ===========================================

Supervised learning  The most common form of machine learning, deep or not, is super- vised learning. Imagine that we want to build a system that can classify  images as containing, say, a house, a car, a person or a pet. We first  collect a large data set of images of houses, cars, people and pets, each  labelled with its category. During training, the machine is shown an  image and produces an output in the form of a vector of scores, one  for each category. We want the desired category to have the highest  score of all categories, but this is unlikely to happen before training.  We compute an objective function that measures the error (or dis- tance) between the output scores and the desired pattern of scores. The  machine then modifies its internal adjustable parameters to reduce  this error. These adjustable parameters, often called weights, are real  numbers that can be seen as ‘knobs’ that define the input–output func- tion of the machine. In a typical deep-learning system, there may be  hundreds of millions of these adjustable weights, and hundreds of  millions of labelled examples with which to train the machine.  

------------------- Sentence 1 -------------------

Supervised learning  The most common form of machine learning, deep or not, is super- vised learning.

>> Tokens are: 
 ['Supervised', 'learning', 'The', 'common', 'form', 'machine', 'learning', ',', 'deep', ',', 'super-', 'vised', 'learning', '.']

>> Bigrams are: 
 [('Supervised', 'learning'), ('learning', 'The'), ('The', 'common'), ('common', 'form'), ('form', 'machine'), ('machine', 'learning'), ('learning', ','), (',', 'deep'), ('deep', ','), (',', 'super-'), ('super-', 'vised'), ('vised', 'learning'), ('learning', '.')]

>> Trigrams are: 
 [('Supervised', 'learning', 'The'), ('learning', 'The', 'common'), ('The', 'common', 'form'), ('common', 'form', 'machine'), ('form', 'machine', 'learning'), ('machine', 'learning', ','), ('learning', ',', 'deep'), (',', 'deep', ','), ('deep', ',', 'super-'), (',', 'super-', 'vised'), ('super-', 'vised', 'learning'), ('vised', 'learning', '.')]

>> POS Tags are: 
 [('Supervised', 'VBN'), ('learning', 'VBG'), ('The', 'DT'), ('common', 'JJ'), ('form', 'NN'), ('machine', 'NN'), ('learning', 'NN'), (',', ','), ('deep', 'JJ'), (',', ','), ('super-', 'JJ'), ('vised', 'VBD'), ('learning', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['The common form machine learning', 'learning']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Supervised', 'supervis'), ('learning', 'learn'), ('The', 'the'), ('common', 'common'), ('form', 'form'), ('machine', 'machin'), ('learning', 'learn'), (',', ','), ('deep', 'deep'), (',', ','), ('super-', 'super-'), ('vised', 'vise'), ('learning', 'learn'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Supervised', 'supervis'), ('learning', 'learn'), ('The', 'the'), ('common', 'common'), ('form', 'form'), ('machine', 'machin'), ('learning', 'learn'), (',', ','), ('deep', 'deep'), (',', ','), ('super-', 'super-'), ('vised', 'vise'), ('learning', 'learn'), ('.', '.')]

>> Lemmatization: 
 [('Supervised', 'Supervised'), ('learning', 'learning'), ('The', 'The'), ('common', 'common'), ('form', 'form'), ('machine', 'machine'), ('learning', 'learning'), (',', ','), ('deep', 'deep'), (',', ','), ('super-', 'super-'), ('vised', 'vised'), ('learning', 'learning'), ('.', '.')]


------------------- Sentence 2 -------------------

Imagine that we want to build a system that can classify  images as containing, say, a house, a car, a person or a pet.

>> Tokens are: 
 ['Imagine', 'want', 'build', 'system', 'classify', 'images', 'containing', ',', 'say', ',', 'house', ',', 'car', ',', 'person', 'pet', '.']

>> Bigrams are: 
 [('Imagine', 'want'), ('want', 'build'), ('build', 'system'), ('system', 'classify'), ('classify', 'images'), ('images', 'containing'), ('containing', ','), (',', 'say'), ('say', ','), (',', 'house'), ('house', ','), (',', 'car'), ('car', ','), (',', 'person'), ('person', 'pet'), ('pet', '.')]

>> Trigrams are: 
 [('Imagine', 'want', 'build'), ('want', 'build', 'system'), ('build', 'system', 'classify'), ('system', 'classify', 'images'), ('classify', 'images', 'containing'), ('images', 'containing', ','), ('containing', ',', 'say'), (',', 'say', ','), ('say', ',', 'house'), (',', 'house', ','), ('house', ',', 'car'), (',', 'car', ','), ('car', ',', 'person'), (',', 'person', 'pet'), ('person', 'pet', '.')]

>> POS Tags are: 
 [('Imagine', 'NNP'), ('want', 'VBP'), ('build', 'NN'), ('system', 'NN'), ('classify', 'JJ'), ('images', 'NNS'), ('containing', 'VBG'), (',', ','), ('say', 'VBP'), (',', ','), ('house', 'NN'), (',', ','), ('car', 'NN'), (',', ','), ('person', 'NN'), ('pet', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Imagine', 'build system', 'classify images', 'house', 'car', 'person pet']

>> Named Entities are: 
 [('GPE', 'Imagine')] 

>> Stemming using Porter Stemmer: 
 [('Imagine', 'imagin'), ('want', 'want'), ('build', 'build'), ('system', 'system'), ('classify', 'classifi'), ('images', 'imag'), ('containing', 'contain'), (',', ','), ('say', 'say'), (',', ','), ('house', 'hous'), (',', ','), ('car', 'car'), (',', ','), ('person', 'person'), ('pet', 'pet'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Imagine', 'imagin'), ('want', 'want'), ('build', 'build'), ('system', 'system'), ('classify', 'classifi'), ('images', 'imag'), ('containing', 'contain'), (',', ','), ('say', 'say'), (',', ','), ('house', 'hous'), (',', ','), ('car', 'car'), (',', ','), ('person', 'person'), ('pet', 'pet'), ('.', '.')]

>> Lemmatization: 
 [('Imagine', 'Imagine'), ('want', 'want'), ('build', 'build'), ('system', 'system'), ('classify', 'classify'), ('images', 'image'), ('containing', 'containing'), (',', ','), ('say', 'say'), (',', ','), ('house', 'house'), (',', ','), ('car', 'car'), (',', ','), ('person', 'person'), ('pet', 'pet'), ('.', '.')]


------------------- Sentence 3 -------------------

We first  collect a large data set of images of houses, cars, people and pets, each  labelled with its category.

>> Tokens are: 
 ['We', 'first', 'collect', 'large', 'data', 'set', 'images', 'houses', ',', 'cars', ',', 'people', 'pets', ',', 'labelled', 'category', '.']

>> Bigrams are: 
 [('We', 'first'), ('first', 'collect'), ('collect', 'large'), ('large', 'data'), ('data', 'set'), ('set', 'images'), ('images', 'houses'), ('houses', ','), (',', 'cars'), ('cars', ','), (',', 'people'), ('people', 'pets'), ('pets', ','), (',', 'labelled'), ('labelled', 'category'), ('category', '.')]

>> Trigrams are: 
 [('We', 'first', 'collect'), ('first', 'collect', 'large'), ('collect', 'large', 'data'), ('large', 'data', 'set'), ('data', 'set', 'images'), ('set', 'images', 'houses'), ('images', 'houses', ','), ('houses', ',', 'cars'), (',', 'cars', ','), ('cars', ',', 'people'), (',', 'people', 'pets'), ('people', 'pets', ','), ('pets', ',', 'labelled'), (',', 'labelled', 'category'), ('labelled', 'category', '.')]

>> POS Tags are: 
 [('We', 'PRP'), ('first', 'RB'), ('collect', 'VBP'), ('large', 'JJ'), ('data', 'NNS'), ('set', 'VBD'), ('images', 'NNS'), ('houses', 'NNS'), (',', ','), ('cars', 'NNS'), (',', ','), ('people', 'NNS'), ('pets', 'NNS'), (',', ','), ('labelled', 'VBD'), ('category', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['large data', 'images houses', 'cars', 'people pets', 'category']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('We', 'we'), ('first', 'first'), ('collect', 'collect'), ('large', 'larg'), ('data', 'data'), ('set', 'set'), ('images', 'imag'), ('houses', 'hous'), (',', ','), ('cars', 'car'), (',', ','), ('people', 'peopl'), ('pets', 'pet'), (',', ','), ('labelled', 'label'), ('category', 'categori'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('We', 'we'), ('first', 'first'), ('collect', 'collect'), ('large', 'larg'), ('data', 'data'), ('set', 'set'), ('images', 'imag'), ('houses', 'hous'), (',', ','), ('cars', 'car'), (',', ','), ('people', 'peopl'), ('pets', 'pet'), (',', ','), ('labelled', 'label'), ('category', 'categori'), ('.', '.')]

>> Lemmatization: 
 [('We', 'We'), ('first', 'first'), ('collect', 'collect'), ('large', 'large'), ('data', 'data'), ('set', 'set'), ('images', 'image'), ('houses', 'house'), (',', ','), ('cars', 'car'), (',', ','), ('people', 'people'), ('pets', 'pet'), (',', ','), ('labelled', 'labelled'), ('category', 'category'), ('.', '.')]


------------------- Sentence 4 -------------------

During training, the machine is shown an  image and produces an output in the form of a vector of scores, one  for each category.

>> Tokens are: 
 ['During', 'training', ',', 'machine', 'shown', 'image', 'produces', 'output', 'form', 'vector', 'scores', ',', 'one', 'category', '.']

>> Bigrams are: 
 [('During', 'training'), ('training', ','), (',', 'machine'), ('machine', 'shown'), ('shown', 'image'), ('image', 'produces'), ('produces', 'output'), ('output', 'form'), ('form', 'vector'), ('vector', 'scores'), ('scores', ','), (',', 'one'), ('one', 'category'), ('category', '.')]

>> Trigrams are: 
 [('During', 'training', ','), ('training', ',', 'machine'), (',', 'machine', 'shown'), ('machine', 'shown', 'image'), ('shown', 'image', 'produces'), ('image', 'produces', 'output'), ('produces', 'output', 'form'), ('output', 'form', 'vector'), ('form', 'vector', 'scores'), ('vector', 'scores', ','), ('scores', ',', 'one'), (',', 'one', 'category'), ('one', 'category', '.')]

>> POS Tags are: 
 [('During', 'IN'), ('training', 'NN'), (',', ','), ('machine', 'NN'), ('shown', 'VBN'), ('image', 'NN'), ('produces', 'VBZ'), ('output', 'NN'), ('form', 'NN'), ('vector', 'NN'), ('scores', 'NNS'), (',', ','), ('one', 'CD'), ('category', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['training', 'machine', 'image', 'output form vector scores', 'category']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('During', 'dure'), ('training', 'train'), (',', ','), ('machine', 'machin'), ('shown', 'shown'), ('image', 'imag'), ('produces', 'produc'), ('output', 'output'), ('form', 'form'), ('vector', 'vector'), ('scores', 'score'), (',', ','), ('one', 'one'), ('category', 'categori'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('During', 'dure'), ('training', 'train'), (',', ','), ('machine', 'machin'), ('shown', 'shown'), ('image', 'imag'), ('produces', 'produc'), ('output', 'output'), ('form', 'form'), ('vector', 'vector'), ('scores', 'score'), (',', ','), ('one', 'one'), ('category', 'categori'), ('.', '.')]

>> Lemmatization: 
 [('During', 'During'), ('training', 'training'), (',', ','), ('machine', 'machine'), ('shown', 'shown'), ('image', 'image'), ('produces', 'produce'), ('output', 'output'), ('form', 'form'), ('vector', 'vector'), ('scores', 'score'), (',', ','), ('one', 'one'), ('category', 'category'), ('.', '.')]


------------------- Sentence 5 -------------------

We want the desired category to have the highest  score of all categories, but this is unlikely to happen before training.

>> Tokens are: 
 ['We', 'want', 'desired', 'category', 'highest', 'score', 'categories', ',', 'unlikely', 'happen', 'training', '.']

>> Bigrams are: 
 [('We', 'want'), ('want', 'desired'), ('desired', 'category'), ('category', 'highest'), ('highest', 'score'), ('score', 'categories'), ('categories', ','), (',', 'unlikely'), ('unlikely', 'happen'), ('happen', 'training'), ('training', '.')]

>> Trigrams are: 
 [('We', 'want', 'desired'), ('want', 'desired', 'category'), ('desired', 'category', 'highest'), ('category', 'highest', 'score'), ('highest', 'score', 'categories'), ('score', 'categories', ','), ('categories', ',', 'unlikely'), (',', 'unlikely', 'happen'), ('unlikely', 'happen', 'training'), ('happen', 'training', '.')]

>> POS Tags are: 
 [('We', 'PRP'), ('want', 'VBP'), ('desired', 'JJ'), ('category', 'NN'), ('highest', 'JJS'), ('score', 'NN'), ('categories', 'NNS'), (',', ','), ('unlikely', 'JJ'), ('happen', 'JJ'), ('training', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['desired category', 'score categories', 'unlikely happen training']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('We', 'we'), ('want', 'want'), ('desired', 'desir'), ('category', 'categori'), ('highest', 'highest'), ('score', 'score'), ('categories', 'categori'), (',', ','), ('unlikely', 'unlik'), ('happen', 'happen'), ('training', 'train'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('We', 'we'), ('want', 'want'), ('desired', 'desir'), ('category', 'categori'), ('highest', 'highest'), ('score', 'score'), ('categories', 'categori'), (',', ','), ('unlikely', 'unlik'), ('happen', 'happen'), ('training', 'train'), ('.', '.')]

>> Lemmatization: 
 [('We', 'We'), ('want', 'want'), ('desired', 'desired'), ('category', 'category'), ('highest', 'highest'), ('score', 'score'), ('categories', 'category'), (',', ','), ('unlikely', 'unlikely'), ('happen', 'happen'), ('training', 'training'), ('.', '.')]


------------------- Sentence 6 -------------------

We compute an objective function that measures the error (or dis- tance) between the output scores and the desired pattern of scores.

>> Tokens are: 
 ['We', 'compute', 'objective', 'function', 'measures', 'error', '(', 'dis-', 'tance', ')', 'output', 'scores', 'desired', 'pattern', 'scores', '.']

>> Bigrams are: 
 [('We', 'compute'), ('compute', 'objective'), ('objective', 'function'), ('function', 'measures'), ('measures', 'error'), ('error', '('), ('(', 'dis-'), ('dis-', 'tance'), ('tance', ')'), (')', 'output'), ('output', 'scores'), ('scores', 'desired'), ('desired', 'pattern'), ('pattern', 'scores'), ('scores', '.')]

>> Trigrams are: 
 [('We', 'compute', 'objective'), ('compute', 'objective', 'function'), ('objective', 'function', 'measures'), ('function', 'measures', 'error'), ('measures', 'error', '('), ('error', '(', 'dis-'), ('(', 'dis-', 'tance'), ('dis-', 'tance', ')'), ('tance', ')', 'output'), (')', 'output', 'scores'), ('output', 'scores', 'desired'), ('scores', 'desired', 'pattern'), ('desired', 'pattern', 'scores'), ('pattern', 'scores', '.')]

>> POS Tags are: 
 [('We', 'PRP'), ('compute', 'VBP'), ('objective', 'JJ'), ('function', 'NN'), ('measures', 'NNS'), ('error', 'VBP'), ('(', '('), ('dis-', 'JJ'), ('tance', 'NN'), (')', ')'), ('output', 'NN'), ('scores', 'NNS'), ('desired', 'VBD'), ('pattern', 'JJ'), ('scores', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['objective function measures', 'dis- tance', 'output scores', 'pattern scores']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('We', 'we'), ('compute', 'comput'), ('objective', 'object'), ('function', 'function'), ('measures', 'measur'), ('error', 'error'), ('(', '('), ('dis-', 'dis-'), ('tance', 'tanc'), (')', ')'), ('output', 'output'), ('scores', 'score'), ('desired', 'desir'), ('pattern', 'pattern'), ('scores', 'score'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('We', 'we'), ('compute', 'comput'), ('objective', 'object'), ('function', 'function'), ('measures', 'measur'), ('error', 'error'), ('(', '('), ('dis-', 'dis-'), ('tance', 'tanc'), (')', ')'), ('output', 'output'), ('scores', 'score'), ('desired', 'desir'), ('pattern', 'pattern'), ('scores', 'score'), ('.', '.')]

>> Lemmatization: 
 [('We', 'We'), ('compute', 'compute'), ('objective', 'objective'), ('function', 'function'), ('measures', 'measure'), ('error', 'error'), ('(', '('), ('dis-', 'dis-'), ('tance', 'tance'), (')', ')'), ('output', 'output'), ('scores', 'score'), ('desired', 'desired'), ('pattern', 'pattern'), ('scores', 'score'), ('.', '.')]


------------------- Sentence 7 -------------------

The  machine then modifies its internal adjustable parameters to reduce  this error.

>> Tokens are: 
 ['The', 'machine', 'modifies', 'internal', 'adjustable', 'parameters', 'reduce', 'error', '.']

>> Bigrams are: 
 [('The', 'machine'), ('machine', 'modifies'), ('modifies', 'internal'), ('internal', 'adjustable'), ('adjustable', 'parameters'), ('parameters', 'reduce'), ('reduce', 'error'), ('error', '.')]

>> Trigrams are: 
 [('The', 'machine', 'modifies'), ('machine', 'modifies', 'internal'), ('modifies', 'internal', 'adjustable'), ('internal', 'adjustable', 'parameters'), ('adjustable', 'parameters', 'reduce'), ('parameters', 'reduce', 'error'), ('reduce', 'error', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('machine', 'NN'), ('modifies', 'VBZ'), ('internal', 'JJ'), ('adjustable', 'JJ'), ('parameters', 'NNS'), ('reduce', 'VB'), ('error', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['The machine', 'internal adjustable parameters', 'error']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('machine', 'machin'), ('modifies', 'modifi'), ('internal', 'intern'), ('adjustable', 'adjust'), ('parameters', 'paramet'), ('reduce', 'reduc'), ('error', 'error'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('machine', 'machin'), ('modifies', 'modifi'), ('internal', 'intern'), ('adjustable', 'adjust'), ('parameters', 'paramet'), ('reduce', 'reduc'), ('error', 'error'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('machine', 'machine'), ('modifies', 'modifies'), ('internal', 'internal'), ('adjustable', 'adjustable'), ('parameters', 'parameter'), ('reduce', 'reduce'), ('error', 'error'), ('.', '.')]


------------------- Sentence 8 -------------------

These adjustable parameters, often called weights, are real  numbers that can be seen as ‘knobs’ that define the input–output func- tion of the machine.

>> Tokens are: 
 ['These', 'adjustable', 'parameters', ',', 'often', 'called', 'weights', ',', 'real', 'numbers', 'seen', '‘', 'knobs', '’', 'define', 'input–output', 'func-', 'tion', 'machine', '.']

>> Bigrams are: 
 [('These', 'adjustable'), ('adjustable', 'parameters'), ('parameters', ','), (',', 'often'), ('often', 'called'), ('called', 'weights'), ('weights', ','), (',', 'real'), ('real', 'numbers'), ('numbers', 'seen'), ('seen', '‘'), ('‘', 'knobs'), ('knobs', '’'), ('’', 'define'), ('define', 'input–output'), ('input–output', 'func-'), ('func-', 'tion'), ('tion', 'machine'), ('machine', '.')]

>> Trigrams are: 
 [('These', 'adjustable', 'parameters'), ('adjustable', 'parameters', ','), ('parameters', ',', 'often'), (',', 'often', 'called'), ('often', 'called', 'weights'), ('called', 'weights', ','), ('weights', ',', 'real'), (',', 'real', 'numbers'), ('real', 'numbers', 'seen'), ('numbers', 'seen', '‘'), ('seen', '‘', 'knobs'), ('‘', 'knobs', '’'), ('knobs', '’', 'define'), ('’', 'define', 'input–output'), ('define', 'input–output', 'func-'), ('input–output', 'func-', 'tion'), ('func-', 'tion', 'machine'), ('tion', 'machine', '.')]

>> POS Tags are: 
 [('These', 'DT'), ('adjustable', 'JJ'), ('parameters', 'NNS'), (',', ','), ('often', 'RB'), ('called', 'VBD'), ('weights', 'NNS'), (',', ','), ('real', 'JJ'), ('numbers', 'NNS'), ('seen', 'VBN'), ('‘', 'NNP'), ('knobs', 'NNP'), ('’', 'NNP'), ('define', 'NN'), ('input–output', 'NN'), ('func-', 'JJ'), ('tion', 'NN'), ('machine', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['These adjustable parameters', 'weights', 'real numbers', '‘ knobs ’ define input–output', 'func- tion machine']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('These', 'these'), ('adjustable', 'adjust'), ('parameters', 'paramet'), (',', ','), ('often', 'often'), ('called', 'call'), ('weights', 'weight'), (',', ','), ('real', 'real'), ('numbers', 'number'), ('seen', 'seen'), ('‘', '‘'), ('knobs', 'knob'), ('’', '’'), ('define', 'defin'), ('input–output', 'input–output'), ('func-', 'func-'), ('tion', 'tion'), ('machine', 'machin'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('These', 'these'), ('adjustable', 'adjust'), ('parameters', 'paramet'), (',', ','), ('often', 'often'), ('called', 'call'), ('weights', 'weight'), (',', ','), ('real', 'real'), ('numbers', 'number'), ('seen', 'seen'), ('‘', '‘'), ('knobs', 'knob'), ('’', '’'), ('define', 'defin'), ('input–output', 'input–output'), ('func-', 'func-'), ('tion', 'tion'), ('machine', 'machin'), ('.', '.')]

>> Lemmatization: 
 [('These', 'These'), ('adjustable', 'adjustable'), ('parameters', 'parameter'), (',', ','), ('often', 'often'), ('called', 'called'), ('weights', 'weight'), (',', ','), ('real', 'real'), ('numbers', 'number'), ('seen', 'seen'), ('‘', '‘'), ('knobs', 'knob'), ('’', '’'), ('define', 'define'), ('input–output', 'input–output'), ('func-', 'func-'), ('tion', 'tion'), ('machine', 'machine'), ('.', '.')]


------------------- Sentence 9 -------------------

In a typical deep-learning system, there may be  hundreds of millions of these adjustable weights, and hundreds of  millions of labelled examples with which to train the machine.

>> Tokens are: 
 ['In', 'typical', 'deep-learning', 'system', ',', 'may', 'hundreds', 'millions', 'adjustable', 'weights', ',', 'hundreds', 'millions', 'labelled', 'examples', 'train', 'machine', '.']

>> Bigrams are: 
 [('In', 'typical'), ('typical', 'deep-learning'), ('deep-learning', 'system'), ('system', ','), (',', 'may'), ('may', 'hundreds'), ('hundreds', 'millions'), ('millions', 'adjustable'), ('adjustable', 'weights'), ('weights', ','), (',', 'hundreds'), ('hundreds', 'millions'), ('millions', 'labelled'), ('labelled', 'examples'), ('examples', 'train'), ('train', 'machine'), ('machine', '.')]

>> Trigrams are: 
 [('In', 'typical', 'deep-learning'), ('typical', 'deep-learning', 'system'), ('deep-learning', 'system', ','), ('system', ',', 'may'), (',', 'may', 'hundreds'), ('may', 'hundreds', 'millions'), ('hundreds', 'millions', 'adjustable'), ('millions', 'adjustable', 'weights'), ('adjustable', 'weights', ','), ('weights', ',', 'hundreds'), (',', 'hundreds', 'millions'), ('hundreds', 'millions', 'labelled'), ('millions', 'labelled', 'examples'), ('labelled', 'examples', 'train'), ('examples', 'train', 'machine'), ('train', 'machine', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('typical', 'JJ'), ('deep-learning', 'NN'), ('system', 'NN'), (',', ','), ('may', 'MD'), ('hundreds', 'VB'), ('millions', 'NNS'), ('adjustable', 'JJ'), ('weights', 'NNS'), (',', ','), ('hundreds', 'NNS'), ('millions', 'NNS'), ('labelled', 'VBD'), ('examples', 'NNS'), ('train', 'VBP'), ('machine', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['typical deep-learning system', 'millions', 'adjustable weights', 'hundreds millions', 'examples', 'machine']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('typical', 'typic'), ('deep-learning', 'deep-learn'), ('system', 'system'), (',', ','), ('may', 'may'), ('hundreds', 'hundr'), ('millions', 'million'), ('adjustable', 'adjust'), ('weights', 'weight'), (',', ','), ('hundreds', 'hundr'), ('millions', 'million'), ('labelled', 'label'), ('examples', 'exampl'), ('train', 'train'), ('machine', 'machin'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('typical', 'typic'), ('deep-learning', 'deep-learn'), ('system', 'system'), (',', ','), ('may', 'may'), ('hundreds', 'hundr'), ('millions', 'million'), ('adjustable', 'adjust'), ('weights', 'weight'), (',', ','), ('hundreds', 'hundr'), ('millions', 'million'), ('labelled', 'label'), ('examples', 'exampl'), ('train', 'train'), ('machine', 'machin'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('typical', 'typical'), ('deep-learning', 'deep-learning'), ('system', 'system'), (',', ','), ('may', 'may'), ('hundreds', 'hundred'), ('millions', 'million'), ('adjustable', 'adjustable'), ('weights', 'weight'), (',', ','), ('hundreds', 'hundred'), ('millions', 'million'), ('labelled', 'labelled'), ('examples', 'example'), ('train', 'train'), ('machine', 'machine'), ('.', '.')]



========================================== PARAGRAPH 9 ===========================================

To properly adjust the weight vector, the learning algorithm com- putes a gradient vector that, for each weight, indicates by what amount  the error would increase or decrease if the weight were increased by a  tiny amount. The weight vector is then adjusted in the opposite direc- tion to the gradient vector.  

------------------- Sentence 1 -------------------

To properly adjust the weight vector, the learning algorithm com- putes a gradient vector that, for each weight, indicates by what amount  the error would increase or decrease if the weight were increased by a  tiny amount.

>> Tokens are: 
 ['To', 'properly', 'adjust', 'weight', 'vector', ',', 'learning', 'algorithm', 'com-', 'putes', 'gradient', 'vector', ',', 'weight', ',', 'indicates', 'amount', 'error', 'would', 'increase', 'decrease', 'weight', 'increased', 'tiny', 'amount', '.']

>> Bigrams are: 
 [('To', 'properly'), ('properly', 'adjust'), ('adjust', 'weight'), ('weight', 'vector'), ('vector', ','), (',', 'learning'), ('learning', 'algorithm'), ('algorithm', 'com-'), ('com-', 'putes'), ('putes', 'gradient'), ('gradient', 'vector'), ('vector', ','), (',', 'weight'), ('weight', ','), (',', 'indicates'), ('indicates', 'amount'), ('amount', 'error'), ('error', 'would'), ('would', 'increase'), ('increase', 'decrease'), ('decrease', 'weight'), ('weight', 'increased'), ('increased', 'tiny'), ('tiny', 'amount'), ('amount', '.')]

>> Trigrams are: 
 [('To', 'properly', 'adjust'), ('properly', 'adjust', 'weight'), ('adjust', 'weight', 'vector'), ('weight', 'vector', ','), ('vector', ',', 'learning'), (',', 'learning', 'algorithm'), ('learning', 'algorithm', 'com-'), ('algorithm', 'com-', 'putes'), ('com-', 'putes', 'gradient'), ('putes', 'gradient', 'vector'), ('gradient', 'vector', ','), ('vector', ',', 'weight'), (',', 'weight', ','), ('weight', ',', 'indicates'), (',', 'indicates', 'amount'), ('indicates', 'amount', 'error'), ('amount', 'error', 'would'), ('error', 'would', 'increase'), ('would', 'increase', 'decrease'), ('increase', 'decrease', 'weight'), ('decrease', 'weight', 'increased'), ('weight', 'increased', 'tiny'), ('increased', 'tiny', 'amount'), ('tiny', 'amount', '.')]

>> POS Tags are: 
 [('To', 'TO'), ('properly', 'RB'), ('adjust', 'VB'), ('weight', 'NN'), ('vector', 'NN'), (',', ','), ('learning', 'VBG'), ('algorithm', 'JJ'), ('com-', 'JJ'), ('putes', 'NNS'), ('gradient', 'JJ'), ('vector', 'NN'), (',', ','), ('weight', 'NN'), (',', ','), ('indicates', 'VBZ'), ('amount', 'NN'), ('error', 'NN'), ('would', 'MD'), ('increase', 'VB'), ('decrease', 'NN'), ('weight', 'NN'), ('increased', 'VBD'), ('tiny', 'JJ'), ('amount', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['weight vector', 'algorithm com- putes', 'gradient vector', 'weight', 'amount error', 'decrease weight', 'tiny amount']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('To', 'to'), ('properly', 'properli'), ('adjust', 'adjust'), ('weight', 'weight'), ('vector', 'vector'), (',', ','), ('learning', 'learn'), ('algorithm', 'algorithm'), ('com-', 'com-'), ('putes', 'pute'), ('gradient', 'gradient'), ('vector', 'vector'), (',', ','), ('weight', 'weight'), (',', ','), ('indicates', 'indic'), ('amount', 'amount'), ('error', 'error'), ('would', 'would'), ('increase', 'increas'), ('decrease', 'decreas'), ('weight', 'weight'), ('increased', 'increas'), ('tiny', 'tini'), ('amount', 'amount'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('To', 'to'), ('properly', 'proper'), ('adjust', 'adjust'), ('weight', 'weight'), ('vector', 'vector'), (',', ','), ('learning', 'learn'), ('algorithm', 'algorithm'), ('com-', 'com-'), ('putes', 'pute'), ('gradient', 'gradient'), ('vector', 'vector'), (',', ','), ('weight', 'weight'), (',', ','), ('indicates', 'indic'), ('amount', 'amount'), ('error', 'error'), ('would', 'would'), ('increase', 'increas'), ('decrease', 'decreas'), ('weight', 'weight'), ('increased', 'increas'), ('tiny', 'tini'), ('amount', 'amount'), ('.', '.')]

>> Lemmatization: 
 [('To', 'To'), ('properly', 'properly'), ('adjust', 'adjust'), ('weight', 'weight'), ('vector', 'vector'), (',', ','), ('learning', 'learning'), ('algorithm', 'algorithm'), ('com-', 'com-'), ('putes', 'putes'), ('gradient', 'gradient'), ('vector', 'vector'), (',', ','), ('weight', 'weight'), (',', ','), ('indicates', 'indicates'), ('amount', 'amount'), ('error', 'error'), ('would', 'would'), ('increase', 'increase'), ('decrease', 'decrease'), ('weight', 'weight'), ('increased', 'increased'), ('tiny', 'tiny'), ('amount', 'amount'), ('.', '.')]


------------------- Sentence 2 -------------------

The weight vector is then adjusted in the opposite direc- tion to the gradient vector.

>> Tokens are: 
 ['The', 'weight', 'vector', 'adjusted', 'opposite', 'direc-', 'tion', 'gradient', 'vector', '.']

>> Bigrams are: 
 [('The', 'weight'), ('weight', 'vector'), ('vector', 'adjusted'), ('adjusted', 'opposite'), ('opposite', 'direc-'), ('direc-', 'tion'), ('tion', 'gradient'), ('gradient', 'vector'), ('vector', '.')]

>> Trigrams are: 
 [('The', 'weight', 'vector'), ('weight', 'vector', 'adjusted'), ('vector', 'adjusted', 'opposite'), ('adjusted', 'opposite', 'direc-'), ('opposite', 'direc-', 'tion'), ('direc-', 'tion', 'gradient'), ('tion', 'gradient', 'vector'), ('gradient', 'vector', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('weight', 'NN'), ('vector', 'NN'), ('adjusted', 'VBD'), ('opposite', 'JJ'), ('direc-', 'JJ'), ('tion', 'NN'), ('gradient', 'NN'), ('vector', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['The weight vector', 'opposite direc- tion gradient vector']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('weight', 'weight'), ('vector', 'vector'), ('adjusted', 'adjust'), ('opposite', 'opposit'), ('direc-', 'direc-'), ('tion', 'tion'), ('gradient', 'gradient'), ('vector', 'vector'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('weight', 'weight'), ('vector', 'vector'), ('adjusted', 'adjust'), ('opposite', 'opposit'), ('direc-', 'direc-'), ('tion', 'tion'), ('gradient', 'gradient'), ('vector', 'vector'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('weight', 'weight'), ('vector', 'vector'), ('adjusted', 'adjusted'), ('opposite', 'opposite'), ('direc-', 'direc-'), ('tion', 'tion'), ('gradient', 'gradient'), ('vector', 'vector'), ('.', '.')]



========================================== PARAGRAPH 10 ===========================================

The objective function, averaged over all the training examples, can  

------------------- Sentence 1 -------------------

The objective function, averaged over all the training examples, can

>> Tokens are: 
 ['The', 'objective', 'function', ',', 'averaged', 'training', 'examples', ',']

>> Bigrams are: 
 [('The', 'objective'), ('objective', 'function'), ('function', ','), (',', 'averaged'), ('averaged', 'training'), ('training', 'examples'), ('examples', ',')]

>> Trigrams are: 
 [('The', 'objective', 'function'), ('objective', 'function', ','), ('function', ',', 'averaged'), (',', 'averaged', 'training'), ('averaged', 'training', 'examples'), ('training', 'examples', ',')]

>> POS Tags are: 
 [('The', 'DT'), ('objective', 'JJ'), ('function', 'NN'), (',', ','), ('averaged', 'VBD'), ('training', 'NN'), ('examples', 'NNS'), (',', ',')]

>> Noun Phrases are: 
 ['The objective function', 'training examples']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('objective', 'object'), ('function', 'function'), (',', ','), ('averaged', 'averag'), ('training', 'train'), ('examples', 'exampl'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('objective', 'object'), ('function', 'function'), (',', ','), ('averaged', 'averag'), ('training', 'train'), ('examples', 'exampl'), (',', ',')]

>> Lemmatization: 
 [('The', 'The'), ('objective', 'objective'), ('function', 'function'), (',', ','), ('averaged', 'averaged'), ('training', 'training'), ('examples', 'example'), (',', ',')]



========================================== PARAGRAPH 11 ===========================================

Deep learning allows computational models that are composed of multiple processing layers to learn representations of  data with multiple levels of abstraction. These methods have dramatically improved the state-of-the-art in speech rec- ognition, visual object recognition, object detection and many other domains such as drug discovery and genomics. Deep  learning discovers intricate structure in large data sets by using the backpropagation algorithm to indicate how a machine  should change its internal parameters that are used to compute the representation in each layer from the representation in  the previous layer. Deep convolutional nets have brought about breakthroughs in processing images, video, speech and  audio, whereas recurrent nets have shone light on sequential data such as text and speech.  

------------------- Sentence 1 -------------------

Deep learning allows computational models that are composed of multiple processing layers to learn representations of  data with multiple levels of abstraction.

>> Tokens are: 
 ['Deep', 'learning', 'allows', 'computational', 'models', 'composed', 'multiple', 'processing', 'layers', 'learn', 'representations', 'data', 'multiple', 'levels', 'abstraction', '.']

>> Bigrams are: 
 [('Deep', 'learning'), ('learning', 'allows'), ('allows', 'computational'), ('computational', 'models'), ('models', 'composed'), ('composed', 'multiple'), ('multiple', 'processing'), ('processing', 'layers'), ('layers', 'learn'), ('learn', 'representations'), ('representations', 'data'), ('data', 'multiple'), ('multiple', 'levels'), ('levels', 'abstraction'), ('abstraction', '.')]

>> Trigrams are: 
 [('Deep', 'learning', 'allows'), ('learning', 'allows', 'computational'), ('allows', 'computational', 'models'), ('computational', 'models', 'composed'), ('models', 'composed', 'multiple'), ('composed', 'multiple', 'processing'), ('multiple', 'processing', 'layers'), ('processing', 'layers', 'learn'), ('layers', 'learn', 'representations'), ('learn', 'representations', 'data'), ('representations', 'data', 'multiple'), ('data', 'multiple', 'levels'), ('multiple', 'levels', 'abstraction'), ('levels', 'abstraction', '.')]

>> POS Tags are: 
 [('Deep', 'NNP'), ('learning', 'NN'), ('allows', 'VBZ'), ('computational', 'JJ'), ('models', 'NNS'), ('composed', 'VBN'), ('multiple', 'JJ'), ('processing', 'NN'), ('layers', 'NNS'), ('learn', 'VBP'), ('representations', 'NNS'), ('data', 'NNS'), ('multiple', 'NN'), ('levels', 'NNS'), ('abstraction', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Deep learning', 'computational models', 'multiple processing layers', 'representations data multiple levels abstraction']

>> Named Entities are: 
 [('GPE', 'Deep')] 

>> Stemming using Porter Stemmer: 
 [('Deep', 'deep'), ('learning', 'learn'), ('allows', 'allow'), ('computational', 'comput'), ('models', 'model'), ('composed', 'compos'), ('multiple', 'multipl'), ('processing', 'process'), ('layers', 'layer'), ('learn', 'learn'), ('representations', 'represent'), ('data', 'data'), ('multiple', 'multipl'), ('levels', 'level'), ('abstraction', 'abstract'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Deep', 'deep'), ('learning', 'learn'), ('allows', 'allow'), ('computational', 'comput'), ('models', 'model'), ('composed', 'compos'), ('multiple', 'multipl'), ('processing', 'process'), ('layers', 'layer'), ('learn', 'learn'), ('representations', 'represent'), ('data', 'data'), ('multiple', 'multipl'), ('levels', 'level'), ('abstraction', 'abstract'), ('.', '.')]

>> Lemmatization: 
 [('Deep', 'Deep'), ('learning', 'learning'), ('allows', 'allows'), ('computational', 'computational'), ('models', 'model'), ('composed', 'composed'), ('multiple', 'multiple'), ('processing', 'processing'), ('layers', 'layer'), ('learn', 'learn'), ('representations', 'representation'), ('data', 'data'), ('multiple', 'multiple'), ('levels', 'level'), ('abstraction', 'abstraction'), ('.', '.')]


------------------- Sentence 2 -------------------

These methods have dramatically improved the state-of-the-art in speech rec- ognition, visual object recognition, object detection and many other domains such as drug discovery and genomics.

>> Tokens are: 
 ['These', 'methods', 'dramatically', 'improved', 'state-of-the-art', 'speech', 'rec-', 'ognition', ',', 'visual', 'object', 'recognition', ',', 'object', 'detection', 'many', 'domains', 'drug', 'discovery', 'genomics', '.']

>> Bigrams are: 
 [('These', 'methods'), ('methods', 'dramatically'), ('dramatically', 'improved'), ('improved', 'state-of-the-art'), ('state-of-the-art', 'speech'), ('speech', 'rec-'), ('rec-', 'ognition'), ('ognition', ','), (',', 'visual'), ('visual', 'object'), ('object', 'recognition'), ('recognition', ','), (',', 'object'), ('object', 'detection'), ('detection', 'many'), ('many', 'domains'), ('domains', 'drug'), ('drug', 'discovery'), ('discovery', 'genomics'), ('genomics', '.')]

>> Trigrams are: 
 [('These', 'methods', 'dramatically'), ('methods', 'dramatically', 'improved'), ('dramatically', 'improved', 'state-of-the-art'), ('improved', 'state-of-the-art', 'speech'), ('state-of-the-art', 'speech', 'rec-'), ('speech', 'rec-', 'ognition'), ('rec-', 'ognition', ','), ('ognition', ',', 'visual'), (',', 'visual', 'object'), ('visual', 'object', 'recognition'), ('object', 'recognition', ','), ('recognition', ',', 'object'), (',', 'object', 'detection'), ('object', 'detection', 'many'), ('detection', 'many', 'domains'), ('many', 'domains', 'drug'), ('domains', 'drug', 'discovery'), ('drug', 'discovery', 'genomics'), ('discovery', 'genomics', '.')]

>> POS Tags are: 
 [('These', 'DT'), ('methods', 'NNS'), ('dramatically', 'RB'), ('improved', 'VBN'), ('state-of-the-art', 'JJ'), ('speech', 'NN'), ('rec-', 'JJ'), ('ognition', 'NN'), (',', ','), ('visual', 'JJ'), ('object', 'NN'), ('recognition', 'NN'), (',', ','), ('object', 'JJ'), ('detection', 'NN'), ('many', 'JJ'), ('domains', 'NNS'), ('drug', 'NN'), ('discovery', 'NN'), ('genomics', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['These methods', 'state-of-the-art speech', 'rec- ognition', 'visual object recognition', 'object detection', 'many domains drug discovery genomics']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('These', 'these'), ('methods', 'method'), ('dramatically', 'dramat'), ('improved', 'improv'), ('state-of-the-art', 'state-of-the-art'), ('speech', 'speech'), ('rec-', 'rec-'), ('ognition', 'ognit'), (',', ','), ('visual', 'visual'), ('object', 'object'), ('recognition', 'recognit'), (',', ','), ('object', 'object'), ('detection', 'detect'), ('many', 'mani'), ('domains', 'domain'), ('drug', 'drug'), ('discovery', 'discoveri'), ('genomics', 'genom'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('These', 'these'), ('methods', 'method'), ('dramatically', 'dramat'), ('improved', 'improv'), ('state-of-the-art', 'state-of-the-art'), ('speech', 'speech'), ('rec-', 'rec-'), ('ognition', 'ognit'), (',', ','), ('visual', 'visual'), ('object', 'object'), ('recognition', 'recognit'), (',', ','), ('object', 'object'), ('detection', 'detect'), ('many', 'mani'), ('domains', 'domain'), ('drug', 'drug'), ('discovery', 'discoveri'), ('genomics', 'genom'), ('.', '.')]

>> Lemmatization: 
 [('These', 'These'), ('methods', 'method'), ('dramatically', 'dramatically'), ('improved', 'improved'), ('state-of-the-art', 'state-of-the-art'), ('speech', 'speech'), ('rec-', 'rec-'), ('ognition', 'ognition'), (',', ','), ('visual', 'visual'), ('object', 'object'), ('recognition', 'recognition'), (',', ','), ('object', 'object'), ('detection', 'detection'), ('many', 'many'), ('domains', 'domain'), ('drug', 'drug'), ('discovery', 'discovery'), ('genomics', 'genomics'), ('.', '.')]


------------------- Sentence 3 -------------------

Deep  learning discovers intricate structure in large data sets by using the backpropagation algorithm to indicate how a machine  should change its internal parameters that are used to compute the representation in each layer from the representation in  the previous layer.

>> Tokens are: 
 ['Deep', 'learning', 'discovers', 'intricate', 'structure', 'large', 'data', 'sets', 'using', 'backpropagation', 'algorithm', 'indicate', 'machine', 'change', 'internal', 'parameters', 'used', 'compute', 'representation', 'layer', 'representation', 'previous', 'layer', '.']

>> Bigrams are: 
 [('Deep', 'learning'), ('learning', 'discovers'), ('discovers', 'intricate'), ('intricate', 'structure'), ('structure', 'large'), ('large', 'data'), ('data', 'sets'), ('sets', 'using'), ('using', 'backpropagation'), ('backpropagation', 'algorithm'), ('algorithm', 'indicate'), ('indicate', 'machine'), ('machine', 'change'), ('change', 'internal'), ('internal', 'parameters'), ('parameters', 'used'), ('used', 'compute'), ('compute', 'representation'), ('representation', 'layer'), ('layer', 'representation'), ('representation', 'previous'), ('previous', 'layer'), ('layer', '.')]

>> Trigrams are: 
 [('Deep', 'learning', 'discovers'), ('learning', 'discovers', 'intricate'), ('discovers', 'intricate', 'structure'), ('intricate', 'structure', 'large'), ('structure', 'large', 'data'), ('large', 'data', 'sets'), ('data', 'sets', 'using'), ('sets', 'using', 'backpropagation'), ('using', 'backpropagation', 'algorithm'), ('backpropagation', 'algorithm', 'indicate'), ('algorithm', 'indicate', 'machine'), ('indicate', 'machine', 'change'), ('machine', 'change', 'internal'), ('change', 'internal', 'parameters'), ('internal', 'parameters', 'used'), ('parameters', 'used', 'compute'), ('used', 'compute', 'representation'), ('compute', 'representation', 'layer'), ('representation', 'layer', 'representation'), ('layer', 'representation', 'previous'), ('representation', 'previous', 'layer'), ('previous', 'layer', '.')]

>> POS Tags are: 
 [('Deep', 'NNP'), ('learning', 'NN'), ('discovers', 'NNS'), ('intricate', 'VBP'), ('structure', 'NN'), ('large', 'JJ'), ('data', 'NNS'), ('sets', 'NNS'), ('using', 'VBG'), ('backpropagation', 'NN'), ('algorithm', 'NN'), ('indicate', 'VBP'), ('machine', 'NN'), ('change', 'NN'), ('internal', 'JJ'), ('parameters', 'NNS'), ('used', 'VBD'), ('compute', 'JJ'), ('representation', 'NN'), ('layer', 'NN'), ('representation', 'NN'), ('previous', 'JJ'), ('layer', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Deep learning discovers', 'structure', 'large data sets', 'backpropagation algorithm', 'machine change', 'internal parameters', 'compute representation layer representation', 'previous layer']

>> Named Entities are: 
 [('GPE', 'Deep')] 

>> Stemming using Porter Stemmer: 
 [('Deep', 'deep'), ('learning', 'learn'), ('discovers', 'discov'), ('intricate', 'intric'), ('structure', 'structur'), ('large', 'larg'), ('data', 'data'), ('sets', 'set'), ('using', 'use'), ('backpropagation', 'backpropag'), ('algorithm', 'algorithm'), ('indicate', 'indic'), ('machine', 'machin'), ('change', 'chang'), ('internal', 'intern'), ('parameters', 'paramet'), ('used', 'use'), ('compute', 'comput'), ('representation', 'represent'), ('layer', 'layer'), ('representation', 'represent'), ('previous', 'previou'), ('layer', 'layer'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Deep', 'deep'), ('learning', 'learn'), ('discovers', 'discov'), ('intricate', 'intric'), ('structure', 'structur'), ('large', 'larg'), ('data', 'data'), ('sets', 'set'), ('using', 'use'), ('backpropagation', 'backpropag'), ('algorithm', 'algorithm'), ('indicate', 'indic'), ('machine', 'machin'), ('change', 'chang'), ('internal', 'intern'), ('parameters', 'paramet'), ('used', 'use'), ('compute', 'comput'), ('representation', 'represent'), ('layer', 'layer'), ('representation', 'represent'), ('previous', 'previous'), ('layer', 'layer'), ('.', '.')]

>> Lemmatization: 
 [('Deep', 'Deep'), ('learning', 'learning'), ('discovers', 'discovers'), ('intricate', 'intricate'), ('structure', 'structure'), ('large', 'large'), ('data', 'data'), ('sets', 'set'), ('using', 'using'), ('backpropagation', 'backpropagation'), ('algorithm', 'algorithm'), ('indicate', 'indicate'), ('machine', 'machine'), ('change', 'change'), ('internal', 'internal'), ('parameters', 'parameter'), ('used', 'used'), ('compute', 'compute'), ('representation', 'representation'), ('layer', 'layer'), ('representation', 'representation'), ('previous', 'previous'), ('layer', 'layer'), ('.', '.')]


------------------- Sentence 4 -------------------

Deep convolutional nets have brought about breakthroughs in processing images, video, speech and  audio, whereas recurrent nets have shone light on sequential data such as text and speech.

>> Tokens are: 
 ['Deep', 'convolutional', 'nets', 'brought', 'breakthroughs', 'processing', 'images', ',', 'video', ',', 'speech', 'audio', ',', 'whereas', 'recurrent', 'nets', 'shone', 'light', 'sequential', 'data', 'text', 'speech', '.']

>> Bigrams are: 
 [('Deep', 'convolutional'), ('convolutional', 'nets'), ('nets', 'brought'), ('brought', 'breakthroughs'), ('breakthroughs', 'processing'), ('processing', 'images'), ('images', ','), (',', 'video'), ('video', ','), (',', 'speech'), ('speech', 'audio'), ('audio', ','), (',', 'whereas'), ('whereas', 'recurrent'), ('recurrent', 'nets'), ('nets', 'shone'), ('shone', 'light'), ('light', 'sequential'), ('sequential', 'data'), ('data', 'text'), ('text', 'speech'), ('speech', '.')]

>> Trigrams are: 
 [('Deep', 'convolutional', 'nets'), ('convolutional', 'nets', 'brought'), ('nets', 'brought', 'breakthroughs'), ('brought', 'breakthroughs', 'processing'), ('breakthroughs', 'processing', 'images'), ('processing', 'images', ','), ('images', ',', 'video'), (',', 'video', ','), ('video', ',', 'speech'), (',', 'speech', 'audio'), ('speech', 'audio', ','), ('audio', ',', 'whereas'), (',', 'whereas', 'recurrent'), ('whereas', 'recurrent', 'nets'), ('recurrent', 'nets', 'shone'), ('nets', 'shone', 'light'), ('shone', 'light', 'sequential'), ('light', 'sequential', 'data'), ('sequential', 'data', 'text'), ('data', 'text', 'speech'), ('text', 'speech', '.')]

>> POS Tags are: 
 [('Deep', 'JJ'), ('convolutional', 'JJ'), ('nets', 'NNS'), ('brought', 'VBD'), ('breakthroughs', 'RP'), ('processing', 'NN'), ('images', 'NNS'), (',', ','), ('video', 'NN'), (',', ','), ('speech', 'NN'), ('audio', 'NN'), (',', ','), ('whereas', 'JJ'), ('recurrent', 'NN'), ('nets', 'NNS'), ('shone', 'VBP'), ('light', 'JJ'), ('sequential', 'JJ'), ('data', 'NNS'), ('text', 'NN'), ('speech', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Deep convolutional nets', 'processing images', 'video', 'speech audio', 'whereas recurrent nets', 'light sequential data text speech']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Deep', 'deep'), ('convolutional', 'convolut'), ('nets', 'net'), ('brought', 'brought'), ('breakthroughs', 'breakthrough'), ('processing', 'process'), ('images', 'imag'), (',', ','), ('video', 'video'), (',', ','), ('speech', 'speech'), ('audio', 'audio'), (',', ','), ('whereas', 'wherea'), ('recurrent', 'recurr'), ('nets', 'net'), ('shone', 'shone'), ('light', 'light'), ('sequential', 'sequenti'), ('data', 'data'), ('text', 'text'), ('speech', 'speech'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Deep', 'deep'), ('convolutional', 'convolut'), ('nets', 'net'), ('brought', 'brought'), ('breakthroughs', 'breakthrough'), ('processing', 'process'), ('images', 'imag'), (',', ','), ('video', 'video'), (',', ','), ('speech', 'speech'), ('audio', 'audio'), (',', ','), ('whereas', 'wherea'), ('recurrent', 'recurr'), ('nets', 'net'), ('shone', 'shone'), ('light', 'light'), ('sequential', 'sequenti'), ('data', 'data'), ('text', 'text'), ('speech', 'speech'), ('.', '.')]

>> Lemmatization: 
 [('Deep', 'Deep'), ('convolutional', 'convolutional'), ('nets', 'net'), ('brought', 'brought'), ('breakthroughs', 'breakthrough'), ('processing', 'processing'), ('images', 'image'), (',', ','), ('video', 'video'), (',', ','), ('speech', 'speech'), ('audio', 'audio'), (',', ','), ('whereas', 'whereas'), ('recurrent', 'recurrent'), ('nets', 'net'), ('shone', 'shone'), ('light', 'light'), ('sequential', 'sequential'), ('data', 'data'), ('text', 'text'), ('speech', 'speech'), ('.', '.')]



========================================== PARAGRAPH 12 ===========================================

Deep learning Yann LeCun1,2, Yoshua Bengio3 & Geoffrey Hinton4,5 

------------------- Sentence 1 -------------------

Deep learning Yann LeCun1,2, Yoshua Bengio3 & Geoffrey Hinton4,5

>> Tokens are: 
 ['Deep', 'learning', 'Yann', 'LeCun1,2', ',', 'Yoshua', 'Bengio3', '&', 'Geoffrey', 'Hinton4,5']

>> Bigrams are: 
 [('Deep', 'learning'), ('learning', 'Yann'), ('Yann', 'LeCun1,2'), ('LeCun1,2', ','), (',', 'Yoshua'), ('Yoshua', 'Bengio3'), ('Bengio3', '&'), ('&', 'Geoffrey'), ('Geoffrey', 'Hinton4,5')]

>> Trigrams are: 
 [('Deep', 'learning', 'Yann'), ('learning', 'Yann', 'LeCun1,2'), ('Yann', 'LeCun1,2', ','), ('LeCun1,2', ',', 'Yoshua'), (',', 'Yoshua', 'Bengio3'), ('Yoshua', 'Bengio3', '&'), ('Bengio3', '&', 'Geoffrey'), ('&', 'Geoffrey', 'Hinton4,5')]

>> POS Tags are: 
 [('Deep', 'NNP'), ('learning', 'NN'), ('Yann', 'NNP'), ('LeCun1,2', 'NNP'), (',', ','), ('Yoshua', 'NNP'), ('Bengio3', 'NNP'), ('&', 'CC'), ('Geoffrey', 'NNP'), ('Hinton4,5', 'NNP')]

>> Noun Phrases are: 
 ['Deep learning Yann LeCun1,2', 'Yoshua Bengio3', 'Geoffrey Hinton4,5']

>> Named Entities are: 
 [('GPE', 'Deep'), ('PERSON', 'Yann LeCun1,2'), ('PERSON', 'Yoshua Bengio3'), ('PERSON', 'Geoffrey')] 

>> Stemming using Porter Stemmer: 
 [('Deep', 'deep'), ('learning', 'learn'), ('Yann', 'yann'), ('LeCun1,2', 'lecun1,2'), (',', ','), ('Yoshua', 'yoshua'), ('Bengio3', 'bengio3'), ('&', '&'), ('Geoffrey', 'geoffrey'), ('Hinton4,5', 'hinton4,5')]

>> Stemming using Snowball Stemmer: 
 [('Deep', 'deep'), ('learning', 'learn'), ('Yann', 'yann'), ('LeCun1,2', 'lecun1,2'), (',', ','), ('Yoshua', 'yoshua'), ('Bengio3', 'bengio3'), ('&', '&'), ('Geoffrey', 'geoffrey'), ('Hinton4,5', 'hinton4,5')]

>> Lemmatization: 
 [('Deep', 'Deep'), ('learning', 'learning'), ('Yann', 'Yann'), ('LeCun1,2', 'LeCun1,2'), (',', ','), ('Yoshua', 'Yoshua'), ('Bengio3', 'Bengio3'), ('&', '&'), ('Geoffrey', 'Geoffrey'), ('Hinton4,5', 'Hinton4,5')]



========================================== PARAGRAPH 13 ===========================================

4 3 6  |  N A T U R E  |  V O L  5 2 1  |  2 8  M A Y  2 0 1 5 

------------------- Sentence 1 -------------------

4 3 6  |  N A T U R E  |  V O L  5 2 1  |  2 8  M A Y  2 0 1 5

>> Tokens are: 
 ['4', '3', '6', '|', 'N', 'A', 'T', 'U', 'R', 'E', '|', 'V', 'O', 'L', '5', '2', '1', '|', '2', '8', 'M', 'A', 'Y', '2', '0', '1', '5']

>> Bigrams are: 
 [('4', '3'), ('3', '6'), ('6', '|'), ('|', 'N'), ('N', 'A'), ('A', 'T'), ('T', 'U'), ('U', 'R'), ('R', 'E'), ('E', '|'), ('|', 'V'), ('V', 'O'), ('O', 'L'), ('L', '5'), ('5', '2'), ('2', '1'), ('1', '|'), ('|', '2'), ('2', '8'), ('8', 'M'), ('M', 'A'), ('A', 'Y'), ('Y', '2'), ('2', '0'), ('0', '1'), ('1', '5')]

>> Trigrams are: 
 [('4', '3', '6'), ('3', '6', '|'), ('6', '|', 'N'), ('|', 'N', 'A'), ('N', 'A', 'T'), ('A', 'T', 'U'), ('T', 'U', 'R'), ('U', 'R', 'E'), ('R', 'E', '|'), ('E', '|', 'V'), ('|', 'V', 'O'), ('V', 'O', 'L'), ('O', 'L', '5'), ('L', '5', '2'), ('5', '2', '1'), ('2', '1', '|'), ('1', '|', '2'), ('|', '2', '8'), ('2', '8', 'M'), ('8', 'M', 'A'), ('M', 'A', 'Y'), ('A', 'Y', '2'), ('Y', '2', '0'), ('2', '0', '1'), ('0', '1', '5')]

>> POS Tags are: 
 [('4', 'CD'), ('3', 'CD'), ('6', 'CD'), ('|', 'NN'), ('N', 'NNP'), ('A', 'NNP'), ('T', 'NNP'), ('U', 'NNP'), ('R', 'NNP'), ('E', 'NNP'), ('|', 'NNP'), ('V', 'NNP'), ('O', 'NNP'), ('L', 'NNP'), ('5', 'CD'), ('2', 'CD'), ('1', 'CD'), ('|', 'NN'), ('2', 'CD'), ('8', 'CD'), ('M', 'NNP'), ('A', 'NNP'), ('Y', 'NNP'), ('2', 'CD'), ('0', 'CD'), ('1', 'CD'), ('5', 'CD')]

>> Noun Phrases are: 
 ['| N A T U R E | V O L', '|', 'M A Y']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('4', '4'), ('3', '3'), ('6', '6'), ('|', '|'), ('N', 'n'), ('A', 'a'), ('T', 't'), ('U', 'u'), ('R', 'r'), ('E', 'e'), ('|', '|'), ('V', 'v'), ('O', 'o'), ('L', 'l'), ('5', '5'), ('2', '2'), ('1', '1'), ('|', '|'), ('2', '2'), ('8', '8'), ('M', 'm'), ('A', 'a'), ('Y', 'y'), ('2', '2'), ('0', '0'), ('1', '1'), ('5', '5')]

>> Stemming using Snowball Stemmer: 
 [('4', '4'), ('3', '3'), ('6', '6'), ('|', '|'), ('N', 'n'), ('A', 'a'), ('T', 't'), ('U', 'u'), ('R', 'r'), ('E', 'e'), ('|', '|'), ('V', 'v'), ('O', 'o'), ('L', 'l'), ('5', '5'), ('2', '2'), ('1', '1'), ('|', '|'), ('2', '2'), ('8', '8'), ('M', 'm'), ('A', 'a'), ('Y', 'y'), ('2', '2'), ('0', '0'), ('1', '1'), ('5', '5')]

>> Lemmatization: 
 [('4', '4'), ('3', '3'), ('6', '6'), ('|', '|'), ('N', 'N'), ('A', 'A'), ('T', 'T'), ('U', 'U'), ('R', 'R'), ('E', 'E'), ('|', '|'), ('V', 'V'), ('O', 'O'), ('L', 'L'), ('5', '5'), ('2', '2'), ('1', '1'), ('|', '|'), ('2', '2'), ('8', '8'), ('M', 'M'), ('A', 'A'), ('Y', 'Y'), ('2', '2'), ('0', '0'), ('1', '1'), ('5', '5')]



========================================== PARAGRAPH 14 ===========================================

REVIEW doi:10.1038/nature14539 

------------------- Sentence 1 -------------------

REVIEW doi:10.1038/nature14539

>> Tokens are: 
 ['REVIEW', 'doi:10.1038/nature14539']

>> Bigrams are: 
 [('REVIEW', 'doi:10.1038/nature14539')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('REVIEW', 'NNP'), ('doi:10.1038/nature14539', 'NN')]

>> Noun Phrases are: 
 ['REVIEW doi:10.1038/nature14539']

>> Named Entities are: 
 [('GPE', 'REVIEW')] 

>> Stemming using Porter Stemmer: 
 [('REVIEW', 'review'), ('doi:10.1038/nature14539', 'doi:10.1038/nature14539')]

>> Stemming using Snowball Stemmer: 
 [('REVIEW', 'review'), ('doi:10.1038/nature14539', 'doi:10.1038/nature14539')]

>> Lemmatization: 
 [('REVIEW', 'REVIEW'), ('doi:10.1038/nature14539', 'doi:10.1038/nature14539')]



========================================== PARAGRAPH 15 ===========================================

© 2015 Macmillan Publishers Limited. All rights reserved

------------------- Sentence 1 -------------------

© 2015 Macmillan Publishers Limited.

>> Tokens are: 
 ['©', '2015', 'Macmillan', 'Publishers', 'Limited', '.']

>> Bigrams are: 
 [('©', '2015'), ('2015', 'Macmillan'), ('Macmillan', 'Publishers'), ('Publishers', 'Limited'), ('Limited', '.')]

>> Trigrams are: 
 [('©', '2015', 'Macmillan'), ('2015', 'Macmillan', 'Publishers'), ('Macmillan', 'Publishers', 'Limited'), ('Publishers', 'Limited', '.')]

>> POS Tags are: 
 [('©', 'NN'), ('2015', 'CD'), ('Macmillan', 'NNP'), ('Publishers', 'NNP'), ('Limited', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['©', 'Macmillan Publishers Limited']

>> Named Entities are: 
 [('PERSON', 'Macmillan Publishers Limited')] 

>> Stemming using Porter Stemmer: 
 [('©', '©'), ('2015', '2015'), ('Macmillan', 'macmillan'), ('Publishers', 'publish'), ('Limited', 'limit'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('©', '©'), ('2015', '2015'), ('Macmillan', 'macmillan'), ('Publishers', 'publish'), ('Limited', 'limit'), ('.', '.')]

>> Lemmatization: 
 [('©', '©'), ('2015', '2015'), ('Macmillan', 'Macmillan'), ('Publishers', 'Publishers'), ('Limited', 'Limited'), ('.', '.')]


------------------- Sentence 2 -------------------

All rights reserved

>> Tokens are: 
 ['All', 'rights', 'reserved']

>> Bigrams are: 
 [('All', 'rights'), ('rights', 'reserved')]

>> Trigrams are: 
 [('All', 'rights', 'reserved')]

>> POS Tags are: 
 [('All', 'DT'), ('rights', 'NNS'), ('reserved', 'VBN')]

>> Noun Phrases are: 
 ['All rights']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('All', 'all'), ('rights', 'right'), ('reserved', 'reserv')]

>> Stemming using Snowball Stemmer: 
 [('All', 'all'), ('rights', 'right'), ('reserved', 'reserv')]

>> Lemmatization: 
 [('All', 'All'), ('rights', 'right'), ('reserved', 'reserved')]



========================================== PARAGRAPH 16 ===========================================

be seen as a kind of hilly landscape in the high-dimensional space of  weight values. The negative gradient vector indicates the direction  of steepest descent in this landscape, taking it closer to a minimum,  where the output error is low on average.  

------------------- Sentence 1 -------------------

be seen as a kind of hilly landscape in the high-dimensional space of  weight values.

>> Tokens are: 
 ['seen', 'kind', 'hilly', 'landscape', 'high-dimensional', 'space', 'weight', 'values', '.']

>> Bigrams are: 
 [('seen', 'kind'), ('kind', 'hilly'), ('hilly', 'landscape'), ('landscape', 'high-dimensional'), ('high-dimensional', 'space'), ('space', 'weight'), ('weight', 'values'), ('values', '.')]

>> Trigrams are: 
 [('seen', 'kind', 'hilly'), ('kind', 'hilly', 'landscape'), ('hilly', 'landscape', 'high-dimensional'), ('landscape', 'high-dimensional', 'space'), ('high-dimensional', 'space', 'weight'), ('space', 'weight', 'values'), ('weight', 'values', '.')]

>> POS Tags are: 
 [('seen', 'VBN'), ('kind', 'NN'), ('hilly', 'RB'), ('landscape', 'VBZ'), ('high-dimensional', 'JJ'), ('space', 'NN'), ('weight', 'NN'), ('values', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['kind', 'high-dimensional space weight values']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('seen', 'seen'), ('kind', 'kind'), ('hilly', 'hilli'), ('landscape', 'landscap'), ('high-dimensional', 'high-dimension'), ('space', 'space'), ('weight', 'weight'), ('values', 'valu'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('seen', 'seen'), ('kind', 'kind'), ('hilly', 'hilli'), ('landscape', 'landscap'), ('high-dimensional', 'high-dimension'), ('space', 'space'), ('weight', 'weight'), ('values', 'valu'), ('.', '.')]

>> Lemmatization: 
 [('seen', 'seen'), ('kind', 'kind'), ('hilly', 'hilly'), ('landscape', 'landscape'), ('high-dimensional', 'high-dimensional'), ('space', 'space'), ('weight', 'weight'), ('values', 'value'), ('.', '.')]


------------------- Sentence 2 -------------------

The negative gradient vector indicates the direction  of steepest descent in this landscape, taking it closer to a minimum,  where the output error is low on average.

>> Tokens are: 
 ['The', 'negative', 'gradient', 'vector', 'indicates', 'direction', 'steepest', 'descent', 'landscape', ',', 'taking', 'closer', 'minimum', ',', 'output', 'error', 'low', 'average', '.']

>> Bigrams are: 
 [('The', 'negative'), ('negative', 'gradient'), ('gradient', 'vector'), ('vector', 'indicates'), ('indicates', 'direction'), ('direction', 'steepest'), ('steepest', 'descent'), ('descent', 'landscape'), ('landscape', ','), (',', 'taking'), ('taking', 'closer'), ('closer', 'minimum'), ('minimum', ','), (',', 'output'), ('output', 'error'), ('error', 'low'), ('low', 'average'), ('average', '.')]

>> Trigrams are: 
 [('The', 'negative', 'gradient'), ('negative', 'gradient', 'vector'), ('gradient', 'vector', 'indicates'), ('vector', 'indicates', 'direction'), ('indicates', 'direction', 'steepest'), ('direction', 'steepest', 'descent'), ('steepest', 'descent', 'landscape'), ('descent', 'landscape', ','), ('landscape', ',', 'taking'), (',', 'taking', 'closer'), ('taking', 'closer', 'minimum'), ('closer', 'minimum', ','), ('minimum', ',', 'output'), (',', 'output', 'error'), ('output', 'error', 'low'), ('error', 'low', 'average'), ('low', 'average', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('negative', 'JJ'), ('gradient', 'NN'), ('vector', 'NN'), ('indicates', 'VBZ'), ('direction', 'NN'), ('steepest', 'FW'), ('descent', 'NN'), ('landscape', 'NN'), (',', ','), ('taking', 'VBG'), ('closer', 'RBR'), ('minimum', 'JJ'), (',', ','), ('output', 'NN'), ('error', 'RB'), ('low', 'JJ'), ('average', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['The negative gradient vector', 'direction', 'descent landscape', 'output', 'low average']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('negative', 'neg'), ('gradient', 'gradient'), ('vector', 'vector'), ('indicates', 'indic'), ('direction', 'direct'), ('steepest', 'steepest'), ('descent', 'descent'), ('landscape', 'landscap'), (',', ','), ('taking', 'take'), ('closer', 'closer'), ('minimum', 'minimum'), (',', ','), ('output', 'output'), ('error', 'error'), ('low', 'low'), ('average', 'averag'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('negative', 'negat'), ('gradient', 'gradient'), ('vector', 'vector'), ('indicates', 'indic'), ('direction', 'direct'), ('steepest', 'steepest'), ('descent', 'descent'), ('landscape', 'landscap'), (',', ','), ('taking', 'take'), ('closer', 'closer'), ('minimum', 'minimum'), (',', ','), ('output', 'output'), ('error', 'error'), ('low', 'low'), ('average', 'averag'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('negative', 'negative'), ('gradient', 'gradient'), ('vector', 'vector'), ('indicates', 'indicates'), ('direction', 'direction'), ('steepest', 'steepest'), ('descent', 'descent'), ('landscape', 'landscape'), (',', ','), ('taking', 'taking'), ('closer', 'closer'), ('minimum', 'minimum'), (',', ','), ('output', 'output'), ('error', 'error'), ('low', 'low'), ('average', 'average'), ('.', '.')]



========================================== PARAGRAPH 17 ===========================================

In practice, most practitioners use a procedure called stochastic  gradient descent (SGD). This consists of showing the input vector  for a few examples, computing the outputs and the errors, computing  the average gradient for those examples, and adjusting the weights  accordingly. The process is repeated for many small sets of examples  from the training set until the average of the objective function stops  decreasing. It is called stochastic because each small set of examples  gives a noisy estimate of the average gradient over all examples. This  simple procedure usually finds a good set of weights surprisingly  quickly when compared with far more elaborate optimization tech- niques18. After training, the performance of the system is measured  on a different set of examples called a test set. This serves to test the  generalization ability of the machine — its ability to produce sensible  answers on new inputs that it has never seen during training.  

------------------- Sentence 1 -------------------

In practice, most practitioners use a procedure called stochastic  gradient descent (SGD).

>> Tokens are: 
 ['In', 'practice', ',', 'practitioners', 'use', 'procedure', 'called', 'stochastic', 'gradient', 'descent', '(', 'SGD', ')', '.']

>> Bigrams are: 
 [('In', 'practice'), ('practice', ','), (',', 'practitioners'), ('practitioners', 'use'), ('use', 'procedure'), ('procedure', 'called'), ('called', 'stochastic'), ('stochastic', 'gradient'), ('gradient', 'descent'), ('descent', '('), ('(', 'SGD'), ('SGD', ')'), (')', '.')]

>> Trigrams are: 
 [('In', 'practice', ','), ('practice', ',', 'practitioners'), (',', 'practitioners', 'use'), ('practitioners', 'use', 'procedure'), ('use', 'procedure', 'called'), ('procedure', 'called', 'stochastic'), ('called', 'stochastic', 'gradient'), ('stochastic', 'gradient', 'descent'), ('gradient', 'descent', '('), ('descent', '(', 'SGD'), ('(', 'SGD', ')'), ('SGD', ')', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('practice', 'NN'), (',', ','), ('practitioners', 'NNS'), ('use', 'VBP'), ('procedure', 'NN'), ('called', 'VBN'), ('stochastic', 'JJ'), ('gradient', 'NN'), ('descent', 'NN'), ('(', '('), ('SGD', 'NNP'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['practice', 'practitioners', 'procedure', 'stochastic gradient descent', 'SGD']

>> Named Entities are: 
 [('ORGANIZATION', 'SGD')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('practice', 'practic'), (',', ','), ('practitioners', 'practition'), ('use', 'use'), ('procedure', 'procedur'), ('called', 'call'), ('stochastic', 'stochast'), ('gradient', 'gradient'), ('descent', 'descent'), ('(', '('), ('SGD', 'sgd'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('practice', 'practic'), (',', ','), ('practitioners', 'practition'), ('use', 'use'), ('procedure', 'procedur'), ('called', 'call'), ('stochastic', 'stochast'), ('gradient', 'gradient'), ('descent', 'descent'), ('(', '('), ('SGD', 'sgd'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('practice', 'practice'), (',', ','), ('practitioners', 'practitioner'), ('use', 'use'), ('procedure', 'procedure'), ('called', 'called'), ('stochastic', 'stochastic'), ('gradient', 'gradient'), ('descent', 'descent'), ('(', '('), ('SGD', 'SGD'), (')', ')'), ('.', '.')]


------------------- Sentence 2 -------------------

This consists of showing the input vector  for a few examples, computing the outputs and the errors, computing  the average gradient for those examples, and adjusting the weights  accordingly.

>> Tokens are: 
 ['This', 'consists', 'showing', 'input', 'vector', 'examples', ',', 'computing', 'outputs', 'errors', ',', 'computing', 'average', 'gradient', 'examples', ',', 'adjusting', 'weights', 'accordingly', '.']

>> Bigrams are: 
 [('This', 'consists'), ('consists', 'showing'), ('showing', 'input'), ('input', 'vector'), ('vector', 'examples'), ('examples', ','), (',', 'computing'), ('computing', 'outputs'), ('outputs', 'errors'), ('errors', ','), (',', 'computing'), ('computing', 'average'), ('average', 'gradient'), ('gradient', 'examples'), ('examples', ','), (',', 'adjusting'), ('adjusting', 'weights'), ('weights', 'accordingly'), ('accordingly', '.')]

>> Trigrams are: 
 [('This', 'consists', 'showing'), ('consists', 'showing', 'input'), ('showing', 'input', 'vector'), ('input', 'vector', 'examples'), ('vector', 'examples', ','), ('examples', ',', 'computing'), (',', 'computing', 'outputs'), ('computing', 'outputs', 'errors'), ('outputs', 'errors', ','), ('errors', ',', 'computing'), (',', 'computing', 'average'), ('computing', 'average', 'gradient'), ('average', 'gradient', 'examples'), ('gradient', 'examples', ','), ('examples', ',', 'adjusting'), (',', 'adjusting', 'weights'), ('adjusting', 'weights', 'accordingly'), ('weights', 'accordingly', '.')]

>> POS Tags are: 
 [('This', 'DT'), ('consists', 'VBZ'), ('showing', 'VBG'), ('input', 'JJ'), ('vector', 'NN'), ('examples', 'NNS'), (',', ','), ('computing', 'VBG'), ('outputs', 'JJ'), ('errors', 'NNS'), (',', ','), ('computing', 'VBG'), ('average', 'JJ'), ('gradient', 'JJ'), ('examples', 'NNS'), (',', ','), ('adjusting', 'VBG'), ('weights', 'NNS'), ('accordingly', 'RB'), ('.', '.')]

>> Noun Phrases are: 
 ['input vector examples', 'outputs errors', 'average gradient examples', 'weights']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('This', 'thi'), ('consists', 'consist'), ('showing', 'show'), ('input', 'input'), ('vector', 'vector'), ('examples', 'exampl'), (',', ','), ('computing', 'comput'), ('outputs', 'output'), ('errors', 'error'), (',', ','), ('computing', 'comput'), ('average', 'averag'), ('gradient', 'gradient'), ('examples', 'exampl'), (',', ','), ('adjusting', 'adjust'), ('weights', 'weight'), ('accordingly', 'accordingli'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('This', 'this'), ('consists', 'consist'), ('showing', 'show'), ('input', 'input'), ('vector', 'vector'), ('examples', 'exampl'), (',', ','), ('computing', 'comput'), ('outputs', 'output'), ('errors', 'error'), (',', ','), ('computing', 'comput'), ('average', 'averag'), ('gradient', 'gradient'), ('examples', 'exampl'), (',', ','), ('adjusting', 'adjust'), ('weights', 'weight'), ('accordingly', 'accord'), ('.', '.')]

>> Lemmatization: 
 [('This', 'This'), ('consists', 'consists'), ('showing', 'showing'), ('input', 'input'), ('vector', 'vector'), ('examples', 'example'), (',', ','), ('computing', 'computing'), ('outputs', 'output'), ('errors', 'error'), (',', ','), ('computing', 'computing'), ('average', 'average'), ('gradient', 'gradient'), ('examples', 'example'), (',', ','), ('adjusting', 'adjusting'), ('weights', 'weight'), ('accordingly', 'accordingly'), ('.', '.')]


------------------- Sentence 3 -------------------

The process is repeated for many small sets of examples  from the training set until the average of the objective function stops  decreasing.

>> Tokens are: 
 ['The', 'process', 'repeated', 'many', 'small', 'sets', 'examples', 'training', 'set', 'average', 'objective', 'function', 'stops', 'decreasing', '.']

>> Bigrams are: 
 [('The', 'process'), ('process', 'repeated'), ('repeated', 'many'), ('many', 'small'), ('small', 'sets'), ('sets', 'examples'), ('examples', 'training'), ('training', 'set'), ('set', 'average'), ('average', 'objective'), ('objective', 'function'), ('function', 'stops'), ('stops', 'decreasing'), ('decreasing', '.')]

>> Trigrams are: 
 [('The', 'process', 'repeated'), ('process', 'repeated', 'many'), ('repeated', 'many', 'small'), ('many', 'small', 'sets'), ('small', 'sets', 'examples'), ('sets', 'examples', 'training'), ('examples', 'training', 'set'), ('training', 'set', 'average'), ('set', 'average', 'objective'), ('average', 'objective', 'function'), ('objective', 'function', 'stops'), ('function', 'stops', 'decreasing'), ('stops', 'decreasing', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('process', 'NN'), ('repeated', 'VBD'), ('many', 'JJ'), ('small', 'JJ'), ('sets', 'NNS'), ('examples', 'VBZ'), ('training', 'VBG'), ('set', 'VBN'), ('average', 'JJ'), ('objective', 'JJ'), ('function', 'NN'), ('stops', 'VBZ'), ('decreasing', 'VBG'), ('.', '.')]

>> Noun Phrases are: 
 ['The process', 'many small sets', 'average objective function']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('process', 'process'), ('repeated', 'repeat'), ('many', 'mani'), ('small', 'small'), ('sets', 'set'), ('examples', 'exampl'), ('training', 'train'), ('set', 'set'), ('average', 'averag'), ('objective', 'object'), ('function', 'function'), ('stops', 'stop'), ('decreasing', 'decreas'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('process', 'process'), ('repeated', 'repeat'), ('many', 'mani'), ('small', 'small'), ('sets', 'set'), ('examples', 'exampl'), ('training', 'train'), ('set', 'set'), ('average', 'averag'), ('objective', 'object'), ('function', 'function'), ('stops', 'stop'), ('decreasing', 'decreas'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('process', 'process'), ('repeated', 'repeated'), ('many', 'many'), ('small', 'small'), ('sets', 'set'), ('examples', 'example'), ('training', 'training'), ('set', 'set'), ('average', 'average'), ('objective', 'objective'), ('function', 'function'), ('stops', 'stop'), ('decreasing', 'decreasing'), ('.', '.')]


------------------- Sentence 4 -------------------

It is called stochastic because each small set of examples  gives a noisy estimate of the average gradient over all examples.

>> Tokens are: 
 ['It', 'called', 'stochastic', 'small', 'set', 'examples', 'gives', 'noisy', 'estimate', 'average', 'gradient', 'examples', '.']

>> Bigrams are: 
 [('It', 'called'), ('called', 'stochastic'), ('stochastic', 'small'), ('small', 'set'), ('set', 'examples'), ('examples', 'gives'), ('gives', 'noisy'), ('noisy', 'estimate'), ('estimate', 'average'), ('average', 'gradient'), ('gradient', 'examples'), ('examples', '.')]

>> Trigrams are: 
 [('It', 'called', 'stochastic'), ('called', 'stochastic', 'small'), ('stochastic', 'small', 'set'), ('small', 'set', 'examples'), ('set', 'examples', 'gives'), ('examples', 'gives', 'noisy'), ('gives', 'noisy', 'estimate'), ('noisy', 'estimate', 'average'), ('estimate', 'average', 'gradient'), ('average', 'gradient', 'examples'), ('gradient', 'examples', '.')]

>> POS Tags are: 
 [('It', 'PRP'), ('called', 'VBD'), ('stochastic', 'JJ'), ('small', 'JJ'), ('set', 'NN'), ('examples', 'NNS'), ('gives', 'VBZ'), ('noisy', 'JJ'), ('estimate', 'NN'), ('average', 'JJ'), ('gradient', 'JJ'), ('examples', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['stochastic small set examples', 'noisy estimate', 'average gradient examples']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('It', 'it'), ('called', 'call'), ('stochastic', 'stochast'), ('small', 'small'), ('set', 'set'), ('examples', 'exampl'), ('gives', 'give'), ('noisy', 'noisi'), ('estimate', 'estim'), ('average', 'averag'), ('gradient', 'gradient'), ('examples', 'exampl'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('It', 'it'), ('called', 'call'), ('stochastic', 'stochast'), ('small', 'small'), ('set', 'set'), ('examples', 'exampl'), ('gives', 'give'), ('noisy', 'noisi'), ('estimate', 'estim'), ('average', 'averag'), ('gradient', 'gradient'), ('examples', 'exampl'), ('.', '.')]

>> Lemmatization: 
 [('It', 'It'), ('called', 'called'), ('stochastic', 'stochastic'), ('small', 'small'), ('set', 'set'), ('examples', 'example'), ('gives', 'give'), ('noisy', 'noisy'), ('estimate', 'estimate'), ('average', 'average'), ('gradient', 'gradient'), ('examples', 'example'), ('.', '.')]


------------------- Sentence 5 -------------------

This  simple procedure usually finds a good set of weights surprisingly  quickly when compared with far more elaborate optimization tech- niques18.

>> Tokens are: 
 ['This', 'simple', 'procedure', 'usually', 'finds', 'good', 'set', 'weights', 'surprisingly', 'quickly', 'compared', 'far', 'elaborate', 'optimization', 'tech-', 'niques18', '.']

>> Bigrams are: 
 [('This', 'simple'), ('simple', 'procedure'), ('procedure', 'usually'), ('usually', 'finds'), ('finds', 'good'), ('good', 'set'), ('set', 'weights'), ('weights', 'surprisingly'), ('surprisingly', 'quickly'), ('quickly', 'compared'), ('compared', 'far'), ('far', 'elaborate'), ('elaborate', 'optimization'), ('optimization', 'tech-'), ('tech-', 'niques18'), ('niques18', '.')]

>> Trigrams are: 
 [('This', 'simple', 'procedure'), ('simple', 'procedure', 'usually'), ('procedure', 'usually', 'finds'), ('usually', 'finds', 'good'), ('finds', 'good', 'set'), ('good', 'set', 'weights'), ('set', 'weights', 'surprisingly'), ('weights', 'surprisingly', 'quickly'), ('surprisingly', 'quickly', 'compared'), ('quickly', 'compared', 'far'), ('compared', 'far', 'elaborate'), ('far', 'elaborate', 'optimization'), ('elaborate', 'optimization', 'tech-'), ('optimization', 'tech-', 'niques18'), ('tech-', 'niques18', '.')]

>> POS Tags are: 
 [('This', 'DT'), ('simple', 'JJ'), ('procedure', 'NN'), ('usually', 'RB'), ('finds', 'VBZ'), ('good', 'JJ'), ('set', 'NN'), ('weights', 'NNS'), ('surprisingly', 'RB'), ('quickly', 'RB'), ('compared', 'VBN'), ('far', 'RB'), ('elaborate', 'JJ'), ('optimization', 'NN'), ('tech-', 'JJ'), ('niques18', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['This simple procedure', 'good set weights', 'elaborate optimization', 'tech- niques18']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('This', 'thi'), ('simple', 'simpl'), ('procedure', 'procedur'), ('usually', 'usual'), ('finds', 'find'), ('good', 'good'), ('set', 'set'), ('weights', 'weight'), ('surprisingly', 'surprisingli'), ('quickly', 'quickli'), ('compared', 'compar'), ('far', 'far'), ('elaborate', 'elabor'), ('optimization', 'optim'), ('tech-', 'tech-'), ('niques18', 'niques18'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('This', 'this'), ('simple', 'simpl'), ('procedure', 'procedur'), ('usually', 'usual'), ('finds', 'find'), ('good', 'good'), ('set', 'set'), ('weights', 'weight'), ('surprisingly', 'surpris'), ('quickly', 'quick'), ('compared', 'compar'), ('far', 'far'), ('elaborate', 'elabor'), ('optimization', 'optim'), ('tech-', 'tech-'), ('niques18', 'niques18'), ('.', '.')]

>> Lemmatization: 
 [('This', 'This'), ('simple', 'simple'), ('procedure', 'procedure'), ('usually', 'usually'), ('finds', 'find'), ('good', 'good'), ('set', 'set'), ('weights', 'weight'), ('surprisingly', 'surprisingly'), ('quickly', 'quickly'), ('compared', 'compared'), ('far', 'far'), ('elaborate', 'elaborate'), ('optimization', 'optimization'), ('tech-', 'tech-'), ('niques18', 'niques18'), ('.', '.')]


------------------- Sentence 6 -------------------

After training, the performance of the system is measured  on a different set of examples called a test set.

>> Tokens are: 
 ['After', 'training', ',', 'performance', 'system', 'measured', 'different', 'set', 'examples', 'called', 'test', 'set', '.']

>> Bigrams are: 
 [('After', 'training'), ('training', ','), (',', 'performance'), ('performance', 'system'), ('system', 'measured'), ('measured', 'different'), ('different', 'set'), ('set', 'examples'), ('examples', 'called'), ('called', 'test'), ('test', 'set'), ('set', '.')]

>> Trigrams are: 
 [('After', 'training', ','), ('training', ',', 'performance'), (',', 'performance', 'system'), ('performance', 'system', 'measured'), ('system', 'measured', 'different'), ('measured', 'different', 'set'), ('different', 'set', 'examples'), ('set', 'examples', 'called'), ('examples', 'called', 'test'), ('called', 'test', 'set'), ('test', 'set', '.')]

>> POS Tags are: 
 [('After', 'IN'), ('training', 'NN'), (',', ','), ('performance', 'NN'), ('system', 'NN'), ('measured', 'VBD'), ('different', 'JJ'), ('set', 'NN'), ('examples', 'NNS'), ('called', 'VBD'), ('test', 'NN'), ('set', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['training', 'performance system', 'different set examples', 'test set']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('After', 'after'), ('training', 'train'), (',', ','), ('performance', 'perform'), ('system', 'system'), ('measured', 'measur'), ('different', 'differ'), ('set', 'set'), ('examples', 'exampl'), ('called', 'call'), ('test', 'test'), ('set', 'set'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('After', 'after'), ('training', 'train'), (',', ','), ('performance', 'perform'), ('system', 'system'), ('measured', 'measur'), ('different', 'differ'), ('set', 'set'), ('examples', 'exampl'), ('called', 'call'), ('test', 'test'), ('set', 'set'), ('.', '.')]

>> Lemmatization: 
 [('After', 'After'), ('training', 'training'), (',', ','), ('performance', 'performance'), ('system', 'system'), ('measured', 'measured'), ('different', 'different'), ('set', 'set'), ('examples', 'example'), ('called', 'called'), ('test', 'test'), ('set', 'set'), ('.', '.')]


------------------- Sentence 7 -------------------

This serves to test the  generalization ability of the machine — its ability to produce sensible  answers on new inputs that it has never seen during training.

>> Tokens are: 
 ['This', 'serves', 'test', 'generalization', 'ability', 'machine', '—', 'ability', 'produce', 'sensible', 'answers', 'new', 'inputs', 'never', 'seen', 'training', '.']

>> Bigrams are: 
 [('This', 'serves'), ('serves', 'test'), ('test', 'generalization'), ('generalization', 'ability'), ('ability', 'machine'), ('machine', '—'), ('—', 'ability'), ('ability', 'produce'), ('produce', 'sensible'), ('sensible', 'answers'), ('answers', 'new'), ('new', 'inputs'), ('inputs', 'never'), ('never', 'seen'), ('seen', 'training'), ('training', '.')]

>> Trigrams are: 
 [('This', 'serves', 'test'), ('serves', 'test', 'generalization'), ('test', 'generalization', 'ability'), ('generalization', 'ability', 'machine'), ('ability', 'machine', '—'), ('machine', '—', 'ability'), ('—', 'ability', 'produce'), ('ability', 'produce', 'sensible'), ('produce', 'sensible', 'answers'), ('sensible', 'answers', 'new'), ('answers', 'new', 'inputs'), ('new', 'inputs', 'never'), ('inputs', 'never', 'seen'), ('never', 'seen', 'training'), ('seen', 'training', '.')]

>> POS Tags are: 
 [('This', 'DT'), ('serves', 'VBZ'), ('test', 'JJ'), ('generalization', 'NN'), ('ability', 'NN'), ('machine', 'NN'), ('—', 'NNP'), ('ability', 'NN'), ('produce', 'VBP'), ('sensible', 'JJ'), ('answers', 'NNS'), ('new', 'JJ'), ('inputs', 'NNS'), ('never', 'RB'), ('seen', 'VBN'), ('training', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['test generalization ability machine — ability', 'sensible answers', 'new inputs', 'training']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('This', 'thi'), ('serves', 'serv'), ('test', 'test'), ('generalization', 'gener'), ('ability', 'abil'), ('machine', 'machin'), ('—', '—'), ('ability', 'abil'), ('produce', 'produc'), ('sensible', 'sensibl'), ('answers', 'answer'), ('new', 'new'), ('inputs', 'input'), ('never', 'never'), ('seen', 'seen'), ('training', 'train'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('This', 'this'), ('serves', 'serv'), ('test', 'test'), ('generalization', 'general'), ('ability', 'abil'), ('machine', 'machin'), ('—', '—'), ('ability', 'abil'), ('produce', 'produc'), ('sensible', 'sensibl'), ('answers', 'answer'), ('new', 'new'), ('inputs', 'input'), ('never', 'never'), ('seen', 'seen'), ('training', 'train'), ('.', '.')]

>> Lemmatization: 
 [('This', 'This'), ('serves', 'serf'), ('test', 'test'), ('generalization', 'generalization'), ('ability', 'ability'), ('machine', 'machine'), ('—', '—'), ('ability', 'ability'), ('produce', 'produce'), ('sensible', 'sensible'), ('answers', 'answer'), ('new', 'new'), ('inputs', 'input'), ('never', 'never'), ('seen', 'seen'), ('training', 'training'), ('.', '.')]



========================================== PARAGRAPH 18 ===========================================

Many of the current practical applications of machine learning use  linear classifiers on top of hand-engineered features. A two-class linear  classifier computes a weighted sum of the feature vector components.  If the weighted sum is above a threshold, the input is classified as  belonging to a particular category.  

------------------- Sentence 1 -------------------

Many of the current practical applications of machine learning use  linear classifiers on top of hand-engineered features.

>> Tokens are: 
 ['Many', 'current', 'practical', 'applications', 'machine', 'learning', 'use', 'linear', 'classifiers', 'top', 'hand-engineered', 'features', '.']

>> Bigrams are: 
 [('Many', 'current'), ('current', 'practical'), ('practical', 'applications'), ('applications', 'machine'), ('machine', 'learning'), ('learning', 'use'), ('use', 'linear'), ('linear', 'classifiers'), ('classifiers', 'top'), ('top', 'hand-engineered'), ('hand-engineered', 'features'), ('features', '.')]

>> Trigrams are: 
 [('Many', 'current', 'practical'), ('current', 'practical', 'applications'), ('practical', 'applications', 'machine'), ('applications', 'machine', 'learning'), ('machine', 'learning', 'use'), ('learning', 'use', 'linear'), ('use', 'linear', 'classifiers'), ('linear', 'classifiers', 'top'), ('classifiers', 'top', 'hand-engineered'), ('top', 'hand-engineered', 'features'), ('hand-engineered', 'features', '.')]

>> POS Tags are: 
 [('Many', 'JJ'), ('current', 'JJ'), ('practical', 'JJ'), ('applications', 'NNS'), ('machine', 'NN'), ('learning', 'NN'), ('use', 'NN'), ('linear', 'JJ'), ('classifiers', 'NNS'), ('top', 'JJ'), ('hand-engineered', 'JJ'), ('features', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['Many current practical applications machine learning use', 'linear classifiers', 'top hand-engineered features']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Many', 'mani'), ('current', 'current'), ('practical', 'practic'), ('applications', 'applic'), ('machine', 'machin'), ('learning', 'learn'), ('use', 'use'), ('linear', 'linear'), ('classifiers', 'classifi'), ('top', 'top'), ('hand-engineered', 'hand-engin'), ('features', 'featur'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Many', 'mani'), ('current', 'current'), ('practical', 'practic'), ('applications', 'applic'), ('machine', 'machin'), ('learning', 'learn'), ('use', 'use'), ('linear', 'linear'), ('classifiers', 'classifi'), ('top', 'top'), ('hand-engineered', 'hand-engin'), ('features', 'featur'), ('.', '.')]

>> Lemmatization: 
 [('Many', 'Many'), ('current', 'current'), ('practical', 'practical'), ('applications', 'application'), ('machine', 'machine'), ('learning', 'learning'), ('use', 'use'), ('linear', 'linear'), ('classifiers', 'classifier'), ('top', 'top'), ('hand-engineered', 'hand-engineered'), ('features', 'feature'), ('.', '.')]


------------------- Sentence 2 -------------------

A two-class linear  classifier computes a weighted sum of the feature vector components.

>> Tokens are: 
 ['A', 'two-class', 'linear', 'classifier', 'computes', 'weighted', 'sum', 'feature', 'vector', 'components', '.']

>> Bigrams are: 
 [('A', 'two-class'), ('two-class', 'linear'), ('linear', 'classifier'), ('classifier', 'computes'), ('computes', 'weighted'), ('weighted', 'sum'), ('sum', 'feature'), ('feature', 'vector'), ('vector', 'components'), ('components', '.')]

>> Trigrams are: 
 [('A', 'two-class', 'linear'), ('two-class', 'linear', 'classifier'), ('linear', 'classifier', 'computes'), ('classifier', 'computes', 'weighted'), ('computes', 'weighted', 'sum'), ('weighted', 'sum', 'feature'), ('sum', 'feature', 'vector'), ('feature', 'vector', 'components'), ('vector', 'components', '.')]

>> POS Tags are: 
 [('A', 'DT'), ('two-class', 'JJ'), ('linear', 'JJ'), ('classifier', 'NN'), ('computes', 'NNS'), ('weighted', 'VBD'), ('sum', 'JJ'), ('feature', 'NN'), ('vector', 'NN'), ('components', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['A two-class linear classifier computes', 'sum feature vector components']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('A', 'a'), ('two-class', 'two-class'), ('linear', 'linear'), ('classifier', 'classifi'), ('computes', 'comput'), ('weighted', 'weight'), ('sum', 'sum'), ('feature', 'featur'), ('vector', 'vector'), ('components', 'compon'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('A', 'a'), ('two-class', 'two-class'), ('linear', 'linear'), ('classifier', 'classifi'), ('computes', 'comput'), ('weighted', 'weight'), ('sum', 'sum'), ('feature', 'featur'), ('vector', 'vector'), ('components', 'compon'), ('.', '.')]

>> Lemmatization: 
 [('A', 'A'), ('two-class', 'two-class'), ('linear', 'linear'), ('classifier', 'classifier'), ('computes', 'computes'), ('weighted', 'weighted'), ('sum', 'sum'), ('feature', 'feature'), ('vector', 'vector'), ('components', 'component'), ('.', '.')]


------------------- Sentence 3 -------------------

If the weighted sum is above a threshold, the input is classified as  belonging to a particular category.

>> Tokens are: 
 ['If', 'weighted', 'sum', 'threshold', ',', 'input', 'classified', 'belonging', 'particular', 'category', '.']

>> Bigrams are: 
 [('If', 'weighted'), ('weighted', 'sum'), ('sum', 'threshold'), ('threshold', ','), (',', 'input'), ('input', 'classified'), ('classified', 'belonging'), ('belonging', 'particular'), ('particular', 'category'), ('category', '.')]

>> Trigrams are: 
 [('If', 'weighted', 'sum'), ('weighted', 'sum', 'threshold'), ('sum', 'threshold', ','), ('threshold', ',', 'input'), (',', 'input', 'classified'), ('input', 'classified', 'belonging'), ('classified', 'belonging', 'particular'), ('belonging', 'particular', 'category'), ('particular', 'category', '.')]

>> POS Tags are: 
 [('If', 'IN'), ('weighted', 'VBN'), ('sum', 'NN'), ('threshold', 'NN'), (',', ','), ('input', 'NN'), ('classified', 'VBD'), ('belonging', 'VBG'), ('particular', 'JJ'), ('category', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['sum threshold', 'input', 'particular category']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('If', 'if'), ('weighted', 'weight'), ('sum', 'sum'), ('threshold', 'threshold'), (',', ','), ('input', 'input'), ('classified', 'classifi'), ('belonging', 'belong'), ('particular', 'particular'), ('category', 'categori'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('If', 'if'), ('weighted', 'weight'), ('sum', 'sum'), ('threshold', 'threshold'), (',', ','), ('input', 'input'), ('classified', 'classifi'), ('belonging', 'belong'), ('particular', 'particular'), ('category', 'categori'), ('.', '.')]

>> Lemmatization: 
 [('If', 'If'), ('weighted', 'weighted'), ('sum', 'sum'), ('threshold', 'threshold'), (',', ','), ('input', 'input'), ('classified', 'classified'), ('belonging', 'belonging'), ('particular', 'particular'), ('category', 'category'), ('.', '.')]



========================================== PARAGRAPH 19 ===========================================

Since the 1960s we have known that linear classifiers can only carve  their input space into very simple regions, namely half-spaces sepa- rated by a hyperplane19. But problems such as image and speech recog- nition require the input–output function to be insensitive to irrelevant  variations of the input, such as variations in position, orientation or  illumination of an object, or variations in the pitch or accent of speech,  while being very sensitive to particular minute variations (for example,  the difference between a white wolf and a breed of wolf-like white  dog called a Samoyed). At the pixel level, images of two Samoyeds in  different poses and in different environments may be very different  from each other, whereas two images of a Samoyed and a wolf in the  same position and on similar backgrounds may be very similar to each  other. A linear classifier, or any other ‘shallow’ classifier operating on  

------------------- Sentence 1 -------------------

Since the 1960s we have known that linear classifiers can only carve  their input space into very simple regions, namely half-spaces sepa- rated by a hyperplane19.

>> Tokens are: 
 ['Since', '1960s', 'known', 'linear', 'classifiers', 'carve', 'input', 'space', 'simple', 'regions', ',', 'namely', 'half-spaces', 'sepa-', 'rated', 'hyperplane19', '.']

>> Bigrams are: 
 [('Since', '1960s'), ('1960s', 'known'), ('known', 'linear'), ('linear', 'classifiers'), ('classifiers', 'carve'), ('carve', 'input'), ('input', 'space'), ('space', 'simple'), ('simple', 'regions'), ('regions', ','), (',', 'namely'), ('namely', 'half-spaces'), ('half-spaces', 'sepa-'), ('sepa-', 'rated'), ('rated', 'hyperplane19'), ('hyperplane19', '.')]

>> Trigrams are: 
 [('Since', '1960s', 'known'), ('1960s', 'known', 'linear'), ('known', 'linear', 'classifiers'), ('linear', 'classifiers', 'carve'), ('classifiers', 'carve', 'input'), ('carve', 'input', 'space'), ('input', 'space', 'simple'), ('space', 'simple', 'regions'), ('simple', 'regions', ','), ('regions', ',', 'namely'), (',', 'namely', 'half-spaces'), ('namely', 'half-spaces', 'sepa-'), ('half-spaces', 'sepa-', 'rated'), ('sepa-', 'rated', 'hyperplane19'), ('rated', 'hyperplane19', '.')]

>> POS Tags are: 
 [('Since', 'IN'), ('1960s', 'CD'), ('known', 'JJ'), ('linear', 'JJ'), ('classifiers', 'NNS'), ('carve', 'VBP'), ('input', 'JJ'), ('space', 'NN'), ('simple', 'NN'), ('regions', 'NNS'), (',', ','), ('namely', 'RB'), ('half-spaces', 'JJ'), ('sepa-', 'JJ'), ('rated', 'VBN'), ('hyperplane19', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['known linear classifiers', 'input space simple regions', 'hyperplane19']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Since', 'sinc'), ('1960s', '1960'), ('known', 'known'), ('linear', 'linear'), ('classifiers', 'classifi'), ('carve', 'carv'), ('input', 'input'), ('space', 'space'), ('simple', 'simpl'), ('regions', 'region'), (',', ','), ('namely', 'name'), ('half-spaces', 'half-spac'), ('sepa-', 'sepa-'), ('rated', 'rate'), ('hyperplane19', 'hyperplane19'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Since', 'sinc'), ('1960s', '1960s'), ('known', 'known'), ('linear', 'linear'), ('classifiers', 'classifi'), ('carve', 'carv'), ('input', 'input'), ('space', 'space'), ('simple', 'simpl'), ('regions', 'region'), (',', ','), ('namely', 'name'), ('half-spaces', 'half-spac'), ('sepa-', 'sepa-'), ('rated', 'rate'), ('hyperplane19', 'hyperplane19'), ('.', '.')]

>> Lemmatization: 
 [('Since', 'Since'), ('1960s', '1960s'), ('known', 'known'), ('linear', 'linear'), ('classifiers', 'classifier'), ('carve', 'carve'), ('input', 'input'), ('space', 'space'), ('simple', 'simple'), ('regions', 'region'), (',', ','), ('namely', 'namely'), ('half-spaces', 'half-spaces'), ('sepa-', 'sepa-'), ('rated', 'rated'), ('hyperplane19', 'hyperplane19'), ('.', '.')]


------------------- Sentence 2 -------------------

But problems such as image and speech recog- nition require the input–output function to be insensitive to irrelevant  variations of the input, such as variations in position, orientation or  illumination of an object, or variations in the pitch or accent of speech,  while being very sensitive to particular minute variations (for example,  the difference between a white wolf and a breed of wolf-like white  dog called a Samoyed).

>> Tokens are: 
 ['But', 'problems', 'image', 'speech', 'recog-', 'nition', 'require', 'input–output', 'function', 'insensitive', 'irrelevant', 'variations', 'input', ',', 'variations', 'position', ',', 'orientation', 'illumination', 'object', ',', 'variations', 'pitch', 'accent', 'speech', ',', 'sensitive', 'particular', 'minute', 'variations', '(', 'example', ',', 'difference', 'white', 'wolf', 'breed', 'wolf-like', 'white', 'dog', 'called', 'Samoyed', ')', '.']

>> Bigrams are: 
 [('But', 'problems'), ('problems', 'image'), ('image', 'speech'), ('speech', 'recog-'), ('recog-', 'nition'), ('nition', 'require'), ('require', 'input–output'), ('input–output', 'function'), ('function', 'insensitive'), ('insensitive', 'irrelevant'), ('irrelevant', 'variations'), ('variations', 'input'), ('input', ','), (',', 'variations'), ('variations', 'position'), ('position', ','), (',', 'orientation'), ('orientation', 'illumination'), ('illumination', 'object'), ('object', ','), (',', 'variations'), ('variations', 'pitch'), ('pitch', 'accent'), ('accent', 'speech'), ('speech', ','), (',', 'sensitive'), ('sensitive', 'particular'), ('particular', 'minute'), ('minute', 'variations'), ('variations', '('), ('(', 'example'), ('example', ','), (',', 'difference'), ('difference', 'white'), ('white', 'wolf'), ('wolf', 'breed'), ('breed', 'wolf-like'), ('wolf-like', 'white'), ('white', 'dog'), ('dog', 'called'), ('called', 'Samoyed'), ('Samoyed', ')'), (')', '.')]

>> Trigrams are: 
 [('But', 'problems', 'image'), ('problems', 'image', 'speech'), ('image', 'speech', 'recog-'), ('speech', 'recog-', 'nition'), ('recog-', 'nition', 'require'), ('nition', 'require', 'input–output'), ('require', 'input–output', 'function'), ('input–output', 'function', 'insensitive'), ('function', 'insensitive', 'irrelevant'), ('insensitive', 'irrelevant', 'variations'), ('irrelevant', 'variations', 'input'), ('variations', 'input', ','), ('input', ',', 'variations'), (',', 'variations', 'position'), ('variations', 'position', ','), ('position', ',', 'orientation'), (',', 'orientation', 'illumination'), ('orientation', 'illumination', 'object'), ('illumination', 'object', ','), ('object', ',', 'variations'), (',', 'variations', 'pitch'), ('variations', 'pitch', 'accent'), ('pitch', 'accent', 'speech'), ('accent', 'speech', ','), ('speech', ',', 'sensitive'), (',', 'sensitive', 'particular'), ('sensitive', 'particular', 'minute'), ('particular', 'minute', 'variations'), ('minute', 'variations', '('), ('variations', '(', 'example'), ('(', 'example', ','), ('example', ',', 'difference'), (',', 'difference', 'white'), ('difference', 'white', 'wolf'), ('white', 'wolf', 'breed'), ('wolf', 'breed', 'wolf-like'), ('breed', 'wolf-like', 'white'), ('wolf-like', 'white', 'dog'), ('white', 'dog', 'called'), ('dog', 'called', 'Samoyed'), ('called', 'Samoyed', ')'), ('Samoyed', ')', '.')]

>> POS Tags are: 
 [('But', 'CC'), ('problems', 'NNS'), ('image', 'NN'), ('speech', 'VBD'), ('recog-', 'JJ'), ('nition', 'NN'), ('require', 'NN'), ('input–output', 'NN'), ('function', 'NN'), ('insensitive', 'JJ'), ('irrelevant', 'JJ'), ('variations', 'NNS'), ('input', 'NN'), (',', ','), ('variations', 'NNS'), ('position', 'NN'), (',', ','), ('orientation', 'NN'), ('illumination', 'NN'), ('object', 'NN'), (',', ','), ('variations', 'NNS'), ('pitch', 'VBP'), ('accent', 'NN'), ('speech', 'NN'), (',', ','), ('sensitive', 'JJ'), ('particular', 'JJ'), ('minute', 'NN'), ('variations', 'NNS'), ('(', '('), ('example', 'NN'), (',', ','), ('difference', 'NN'), ('white', 'JJ'), ('wolf', 'NN'), ('breed', 'VBD'), ('wolf-like', 'JJ'), ('white', 'JJ'), ('dog', 'NN'), ('called', 'VBN'), ('Samoyed', 'NNP'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['problems image', 'recog- nition require input–output function', 'insensitive irrelevant variations input', 'variations position', 'orientation illumination object', 'variations', 'accent speech', 'sensitive particular minute variations', 'example', 'difference', 'white wolf', 'wolf-like white dog', 'Samoyed']

>> Named Entities are: 
 [('PERSON', 'Samoyed')] 

>> Stemming using Porter Stemmer: 
 [('But', 'but'), ('problems', 'problem'), ('image', 'imag'), ('speech', 'speech'), ('recog-', 'recog-'), ('nition', 'nition'), ('require', 'requir'), ('input–output', 'input–output'), ('function', 'function'), ('insensitive', 'insensit'), ('irrelevant', 'irrelev'), ('variations', 'variat'), ('input', 'input'), (',', ','), ('variations', 'variat'), ('position', 'posit'), (',', ','), ('orientation', 'orient'), ('illumination', 'illumin'), ('object', 'object'), (',', ','), ('variations', 'variat'), ('pitch', 'pitch'), ('accent', 'accent'), ('speech', 'speech'), (',', ','), ('sensitive', 'sensit'), ('particular', 'particular'), ('minute', 'minut'), ('variations', 'variat'), ('(', '('), ('example', 'exampl'), (',', ','), ('difference', 'differ'), ('white', 'white'), ('wolf', 'wolf'), ('breed', 'breed'), ('wolf-like', 'wolf-lik'), ('white', 'white'), ('dog', 'dog'), ('called', 'call'), ('Samoyed', 'samoy'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('But', 'but'), ('problems', 'problem'), ('image', 'imag'), ('speech', 'speech'), ('recog-', 'recog-'), ('nition', 'nition'), ('require', 'requir'), ('input–output', 'input–output'), ('function', 'function'), ('insensitive', 'insensit'), ('irrelevant', 'irrelev'), ('variations', 'variat'), ('input', 'input'), (',', ','), ('variations', 'variat'), ('position', 'posit'), (',', ','), ('orientation', 'orient'), ('illumination', 'illumin'), ('object', 'object'), (',', ','), ('variations', 'variat'), ('pitch', 'pitch'), ('accent', 'accent'), ('speech', 'speech'), (',', ','), ('sensitive', 'sensit'), ('particular', 'particular'), ('minute', 'minut'), ('variations', 'variat'), ('(', '('), ('example', 'exampl'), (',', ','), ('difference', 'differ'), ('white', 'white'), ('wolf', 'wolf'), ('breed', 'breed'), ('wolf-like', 'wolf-lik'), ('white', 'white'), ('dog', 'dog'), ('called', 'call'), ('Samoyed', 'samoy'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('But', 'But'), ('problems', 'problem'), ('image', 'image'), ('speech', 'speech'), ('recog-', 'recog-'), ('nition', 'nition'), ('require', 'require'), ('input–output', 'input–output'), ('function', 'function'), ('insensitive', 'insensitive'), ('irrelevant', 'irrelevant'), ('variations', 'variation'), ('input', 'input'), (',', ','), ('variations', 'variation'), ('position', 'position'), (',', ','), ('orientation', 'orientation'), ('illumination', 'illumination'), ('object', 'object'), (',', ','), ('variations', 'variation'), ('pitch', 'pitch'), ('accent', 'accent'), ('speech', 'speech'), (',', ','), ('sensitive', 'sensitive'), ('particular', 'particular'), ('minute', 'minute'), ('variations', 'variation'), ('(', '('), ('example', 'example'), (',', ','), ('difference', 'difference'), ('white', 'white'), ('wolf', 'wolf'), ('breed', 'breed'), ('wolf-like', 'wolf-like'), ('white', 'white'), ('dog', 'dog'), ('called', 'called'), ('Samoyed', 'Samoyed'), (')', ')'), ('.', '.')]


------------------- Sentence 3 -------------------

At the pixel level, images of two Samoyeds in  different poses and in different environments may be very different  from each other, whereas two images of a Samoyed and a wolf in the  same position and on similar backgrounds may be very similar to each  other.

>> Tokens are: 
 ['At', 'pixel', 'level', ',', 'images', 'two', 'Samoyeds', 'different', 'poses', 'different', 'environments', 'may', 'different', ',', 'whereas', 'two', 'images', 'Samoyed', 'wolf', 'position', 'similar', 'backgrounds', 'may', 'similar', '.']

>> Bigrams are: 
 [('At', 'pixel'), ('pixel', 'level'), ('level', ','), (',', 'images'), ('images', 'two'), ('two', 'Samoyeds'), ('Samoyeds', 'different'), ('different', 'poses'), ('poses', 'different'), ('different', 'environments'), ('environments', 'may'), ('may', 'different'), ('different', ','), (',', 'whereas'), ('whereas', 'two'), ('two', 'images'), ('images', 'Samoyed'), ('Samoyed', 'wolf'), ('wolf', 'position'), ('position', 'similar'), ('similar', 'backgrounds'), ('backgrounds', 'may'), ('may', 'similar'), ('similar', '.')]

>> Trigrams are: 
 [('At', 'pixel', 'level'), ('pixel', 'level', ','), ('level', ',', 'images'), (',', 'images', 'two'), ('images', 'two', 'Samoyeds'), ('two', 'Samoyeds', 'different'), ('Samoyeds', 'different', 'poses'), ('different', 'poses', 'different'), ('poses', 'different', 'environments'), ('different', 'environments', 'may'), ('environments', 'may', 'different'), ('may', 'different', ','), ('different', ',', 'whereas'), (',', 'whereas', 'two'), ('whereas', 'two', 'images'), ('two', 'images', 'Samoyed'), ('images', 'Samoyed', 'wolf'), ('Samoyed', 'wolf', 'position'), ('wolf', 'position', 'similar'), ('position', 'similar', 'backgrounds'), ('similar', 'backgrounds', 'may'), ('backgrounds', 'may', 'similar'), ('may', 'similar', '.')]

>> POS Tags are: 
 [('At', 'IN'), ('pixel', 'JJ'), ('level', 'NN'), (',', ','), ('images', 'VBZ'), ('two', 'CD'), ('Samoyeds', 'NNP'), ('different', 'JJ'), ('poses', 'NNS'), ('different', 'JJ'), ('environments', 'NNS'), ('may', 'MD'), ('different', 'JJ'), (',', ','), ('whereas', 'JJ'), ('two', 'CD'), ('images', 'NNS'), ('Samoyed', 'NNP'), ('wolf', 'NN'), ('position', 'NN'), ('similar', 'JJ'), ('backgrounds', 'NNS'), ('may', 'MD'), ('similar', 'JJ'), ('.', '.')]

>> Noun Phrases are: 
 ['pixel level', 'Samoyeds', 'different poses', 'different environments', 'images Samoyed wolf position', 'similar backgrounds']

>> Named Entities are: 
 [('PERSON', 'Samoyed')] 

>> Stemming using Porter Stemmer: 
 [('At', 'at'), ('pixel', 'pixel'), ('level', 'level'), (',', ','), ('images', 'imag'), ('two', 'two'), ('Samoyeds', 'samoy'), ('different', 'differ'), ('poses', 'pose'), ('different', 'differ'), ('environments', 'environ'), ('may', 'may'), ('different', 'differ'), (',', ','), ('whereas', 'wherea'), ('two', 'two'), ('images', 'imag'), ('Samoyed', 'samoy'), ('wolf', 'wolf'), ('position', 'posit'), ('similar', 'similar'), ('backgrounds', 'background'), ('may', 'may'), ('similar', 'similar'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('At', 'at'), ('pixel', 'pixel'), ('level', 'level'), (',', ','), ('images', 'imag'), ('two', 'two'), ('Samoyeds', 'samoy'), ('different', 'differ'), ('poses', 'pose'), ('different', 'differ'), ('environments', 'environ'), ('may', 'may'), ('different', 'differ'), (',', ','), ('whereas', 'wherea'), ('two', 'two'), ('images', 'imag'), ('Samoyed', 'samoy'), ('wolf', 'wolf'), ('position', 'posit'), ('similar', 'similar'), ('backgrounds', 'background'), ('may', 'may'), ('similar', 'similar'), ('.', '.')]

>> Lemmatization: 
 [('At', 'At'), ('pixel', 'pixel'), ('level', 'level'), (',', ','), ('images', 'image'), ('two', 'two'), ('Samoyeds', 'Samoyeds'), ('different', 'different'), ('poses', 'pose'), ('different', 'different'), ('environments', 'environment'), ('may', 'may'), ('different', 'different'), (',', ','), ('whereas', 'whereas'), ('two', 'two'), ('images', 'image'), ('Samoyed', 'Samoyed'), ('wolf', 'wolf'), ('position', 'position'), ('similar', 'similar'), ('backgrounds', 'background'), ('may', 'may'), ('similar', 'similar'), ('.', '.')]


------------------- Sentence 4 -------------------

A linear classifier, or any other ‘shallow’ classifier operating on

>> Tokens are: 
 ['A', 'linear', 'classifier', ',', '‘', 'shallow', '’', 'classifier', 'operating']

>> Bigrams are: 
 [('A', 'linear'), ('linear', 'classifier'), ('classifier', ','), (',', '‘'), ('‘', 'shallow'), ('shallow', '’'), ('’', 'classifier'), ('classifier', 'operating')]

>> Trigrams are: 
 [('A', 'linear', 'classifier'), ('linear', 'classifier', ','), ('classifier', ',', '‘'), (',', '‘', 'shallow'), ('‘', 'shallow', '’'), ('shallow', '’', 'classifier'), ('’', 'classifier', 'operating')]

>> POS Tags are: 
 [('A', 'DT'), ('linear', 'JJ'), ('classifier', 'NN'), (',', ','), ('‘', 'NNP'), ('shallow', 'VBP'), ('’', 'NNP'), ('classifier', 'NN'), ('operating', 'VBG')]

>> Noun Phrases are: 
 ['A linear classifier', '‘', '’ classifier']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('A', 'a'), ('linear', 'linear'), ('classifier', 'classifi'), (',', ','), ('‘', '‘'), ('shallow', 'shallow'), ('’', '’'), ('classifier', 'classifi'), ('operating', 'oper')]

>> Stemming using Snowball Stemmer: 
 [('A', 'a'), ('linear', 'linear'), ('classifier', 'classifi'), (',', ','), ('‘', '‘'), ('shallow', 'shallow'), ('’', '’'), ('classifier', 'classifi'), ('operating', 'oper')]

>> Lemmatization: 
 [('A', 'A'), ('linear', 'linear'), ('classifier', 'classifier'), (',', ','), ('‘', '‘'), ('shallow', 'shallow'), ('’', '’'), ('classifier', 'classifier'), ('operating', 'operating')]



========================================== PARAGRAPH 20 ===========================================

Figure 1 | Multilayer neural networks and backpropagation. a, A multi- layer neural network (shown by the connected dots) can distort the input  space to make the classes of data (examples of which are on the red and  blue lines) linearly separable. Note how a regular grid (shown on the left)  in input space is also transformed (shown in the middle panel) by hidden  units. This is an illustrative example with only two input units, two hidden  units and one output unit, but the networks used for object recognition  or natural language processing contain tens or hundreds of thousands of  units. Reproduced with permission from C. Olah (http://colah.github.io/).  b, The chain rule of derivatives tells us how two small effects (that of a small  change of x on y, and that of y on z) are composed. A small change Δx in  x gets transformed first into a small change Δy in y by getting multiplied  by ∂y/∂x (that is, the definition of partial derivative). Similarly, the change  Δy creates a change Δz in z. Substituting one equation into the other  gives the chain rule of derivatives — how Δx gets turned into Δz through  multiplication by the product of ∂y/∂x and ∂z/∂x. It also works when x,  y and z are vectors (and the derivatives are Jacobian matrices). c, The  equations used for computing the forward pass in a neural net with two  hidden layers and one output layer, each constituting a module through  

------------------- Sentence 1 -------------------

Figure 1 | Multilayer neural networks and backpropagation.

>> Tokens are: 
 ['Figure', '1', '|', 'Multilayer', 'neural', 'networks', 'backpropagation', '.']

>> Bigrams are: 
 [('Figure', '1'), ('1', '|'), ('|', 'Multilayer'), ('Multilayer', 'neural'), ('neural', 'networks'), ('networks', 'backpropagation'), ('backpropagation', '.')]

>> Trigrams are: 
 [('Figure', '1', '|'), ('1', '|', 'Multilayer'), ('|', 'Multilayer', 'neural'), ('Multilayer', 'neural', 'networks'), ('neural', 'networks', 'backpropagation'), ('networks', 'backpropagation', '.')]

>> POS Tags are: 
 [('Figure', 'NN'), ('1', 'CD'), ('|', 'NN'), ('Multilayer', 'NNP'), ('neural', 'JJ'), ('networks', 'NNS'), ('backpropagation', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Figure', '| Multilayer', 'neural networks backpropagation']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Figure', 'figur'), ('1', '1'), ('|', '|'), ('Multilayer', 'multilay'), ('neural', 'neural'), ('networks', 'network'), ('backpropagation', 'backpropag'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Figure', 'figur'), ('1', '1'), ('|', '|'), ('Multilayer', 'multilay'), ('neural', 'neural'), ('networks', 'network'), ('backpropagation', 'backpropag'), ('.', '.')]

>> Lemmatization: 
 [('Figure', 'Figure'), ('1', '1'), ('|', '|'), ('Multilayer', 'Multilayer'), ('neural', 'neural'), ('networks', 'network'), ('backpropagation', 'backpropagation'), ('.', '.')]


------------------- Sentence 2 -------------------

a, A multi- layer neural network (shown by the connected dots) can distort the input  space to make the classes of data (examples of which are on the red and  blue lines) linearly separable.

>> Tokens are: 
 [',', 'A', 'multi-', 'layer', 'neural', 'network', '(', 'shown', 'connected', 'dots', ')', 'distort', 'input', 'space', 'make', 'classes', 'data', '(', 'examples', 'red', 'blue', 'lines', ')', 'linearly', 'separable', '.']

>> Bigrams are: 
 [(',', 'A'), ('A', 'multi-'), ('multi-', 'layer'), ('layer', 'neural'), ('neural', 'network'), ('network', '('), ('(', 'shown'), ('shown', 'connected'), ('connected', 'dots'), ('dots', ')'), (')', 'distort'), ('distort', 'input'), ('input', 'space'), ('space', 'make'), ('make', 'classes'), ('classes', 'data'), ('data', '('), ('(', 'examples'), ('examples', 'red'), ('red', 'blue'), ('blue', 'lines'), ('lines', ')'), (')', 'linearly'), ('linearly', 'separable'), ('separable', '.')]

>> Trigrams are: 
 [(',', 'A', 'multi-'), ('A', 'multi-', 'layer'), ('multi-', 'layer', 'neural'), ('layer', 'neural', 'network'), ('neural', 'network', '('), ('network', '(', 'shown'), ('(', 'shown', 'connected'), ('shown', 'connected', 'dots'), ('connected', 'dots', ')'), ('dots', ')', 'distort'), (')', 'distort', 'input'), ('distort', 'input', 'space'), ('input', 'space', 'make'), ('space', 'make', 'classes'), ('make', 'classes', 'data'), ('classes', 'data', '('), ('data', '(', 'examples'), ('(', 'examples', 'red'), ('examples', 'red', 'blue'), ('red', 'blue', 'lines'), ('blue', 'lines', ')'), ('lines', ')', 'linearly'), (')', 'linearly', 'separable'), ('linearly', 'separable', '.')]

>> POS Tags are: 
 [(',', ','), ('A', 'DT'), ('multi-', 'JJ'), ('layer', 'NN'), ('neural', 'JJ'), ('network', 'NN'), ('(', '('), ('shown', 'VBN'), ('connected', 'VBN'), ('dots', 'NNS'), (')', ')'), ('distort', 'NN'), ('input', 'VBD'), ('space', 'NN'), ('make', 'NN'), ('classes', 'NNS'), ('data', 'NNS'), ('(', '('), ('examples', 'NNS'), ('red', 'VBN'), ('blue', 'JJ'), ('lines', 'NNS'), (')', ')'), ('linearly', 'RB'), ('separable', 'JJ'), ('.', '.')]

>> Noun Phrases are: 
 ['A multi- layer', 'neural network', 'dots', 'distort', 'space make classes data', 'examples', 'blue lines']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [(',', ','), ('A', 'a'), ('multi-', 'multi-'), ('layer', 'layer'), ('neural', 'neural'), ('network', 'network'), ('(', '('), ('shown', 'shown'), ('connected', 'connect'), ('dots', 'dot'), (')', ')'), ('distort', 'distort'), ('input', 'input'), ('space', 'space'), ('make', 'make'), ('classes', 'class'), ('data', 'data'), ('(', '('), ('examples', 'exampl'), ('red', 'red'), ('blue', 'blue'), ('lines', 'line'), (')', ')'), ('linearly', 'linearli'), ('separable', 'separ'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [(',', ','), ('A', 'a'), ('multi-', 'multi-'), ('layer', 'layer'), ('neural', 'neural'), ('network', 'network'), ('(', '('), ('shown', 'shown'), ('connected', 'connect'), ('dots', 'dot'), (')', ')'), ('distort', 'distort'), ('input', 'input'), ('space', 'space'), ('make', 'make'), ('classes', 'class'), ('data', 'data'), ('(', '('), ('examples', 'exampl'), ('red', 'red'), ('blue', 'blue'), ('lines', 'line'), (')', ')'), ('linearly', 'linear'), ('separable', 'separ'), ('.', '.')]

>> Lemmatization: 
 [(',', ','), ('A', 'A'), ('multi-', 'multi-'), ('layer', 'layer'), ('neural', 'neural'), ('network', 'network'), ('(', '('), ('shown', 'shown'), ('connected', 'connected'), ('dots', 'dot'), (')', ')'), ('distort', 'distort'), ('input', 'input'), ('space', 'space'), ('make', 'make'), ('classes', 'class'), ('data', 'data'), ('(', '('), ('examples', 'example'), ('red', 'red'), ('blue', 'blue'), ('lines', 'line'), (')', ')'), ('linearly', 'linearly'), ('separable', 'separable'), ('.', '.')]


------------------- Sentence 3 -------------------

Note how a regular grid (shown on the left)  in input space is also transformed (shown in the middle panel) by hidden  units.

>> Tokens are: 
 ['Note', 'regular', 'grid', '(', 'shown', 'left', ')', 'input', 'space', 'also', 'transformed', '(', 'shown', 'middle', 'panel', ')', 'hidden', 'units', '.']

>> Bigrams are: 
 [('Note', 'regular'), ('regular', 'grid'), ('grid', '('), ('(', 'shown'), ('shown', 'left'), ('left', ')'), (')', 'input'), ('input', 'space'), ('space', 'also'), ('also', 'transformed'), ('transformed', '('), ('(', 'shown'), ('shown', 'middle'), ('middle', 'panel'), ('panel', ')'), (')', 'hidden'), ('hidden', 'units'), ('units', '.')]

>> Trigrams are: 
 [('Note', 'regular', 'grid'), ('regular', 'grid', '('), ('grid', '(', 'shown'), ('(', 'shown', 'left'), ('shown', 'left', ')'), ('left', ')', 'input'), (')', 'input', 'space'), ('input', 'space', 'also'), ('space', 'also', 'transformed'), ('also', 'transformed', '('), ('transformed', '(', 'shown'), ('(', 'shown', 'middle'), ('shown', 'middle', 'panel'), ('middle', 'panel', ')'), ('panel', ')', 'hidden'), (')', 'hidden', 'units'), ('hidden', 'units', '.')]

>> POS Tags are: 
 [('Note', 'NNP'), ('regular', 'JJ'), ('grid', 'NN'), ('(', '('), ('shown', 'VBN'), ('left', 'VBN'), (')', ')'), ('input', 'NN'), ('space', 'NN'), ('also', 'RB'), ('transformed', 'VBD'), ('(', '('), ('shown', 'VBN'), ('middle', 'RB'), ('panel', 'NN'), (')', ')'), ('hidden', 'VBZ'), ('units', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['Note', 'regular grid', 'input space', 'panel', 'units']

>> Named Entities are: 
 [('GPE', 'Note')] 

>> Stemming using Porter Stemmer: 
 [('Note', 'note'), ('regular', 'regular'), ('grid', 'grid'), ('(', '('), ('shown', 'shown'), ('left', 'left'), (')', ')'), ('input', 'input'), ('space', 'space'), ('also', 'also'), ('transformed', 'transform'), ('(', '('), ('shown', 'shown'), ('middle', 'middl'), ('panel', 'panel'), (')', ')'), ('hidden', 'hidden'), ('units', 'unit'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Note', 'note'), ('regular', 'regular'), ('grid', 'grid'), ('(', '('), ('shown', 'shown'), ('left', 'left'), (')', ')'), ('input', 'input'), ('space', 'space'), ('also', 'also'), ('transformed', 'transform'), ('(', '('), ('shown', 'shown'), ('middle', 'middl'), ('panel', 'panel'), (')', ')'), ('hidden', 'hidden'), ('units', 'unit'), ('.', '.')]

>> Lemmatization: 
 [('Note', 'Note'), ('regular', 'regular'), ('grid', 'grid'), ('(', '('), ('shown', 'shown'), ('left', 'left'), (')', ')'), ('input', 'input'), ('space', 'space'), ('also', 'also'), ('transformed', 'transformed'), ('(', '('), ('shown', 'shown'), ('middle', 'middle'), ('panel', 'panel'), (')', ')'), ('hidden', 'hidden'), ('units', 'unit'), ('.', '.')]


------------------- Sentence 4 -------------------

This is an illustrative example with only two input units, two hidden  units and one output unit, but the networks used for object recognition  or natural language processing contain tens or hundreds of thousands of  units.

>> Tokens are: 
 ['This', 'illustrative', 'example', 'two', 'input', 'units', ',', 'two', 'hidden', 'units', 'one', 'output', 'unit', ',', 'networks', 'used', 'object', 'recognition', 'natural', 'language', 'processing', 'contain', 'tens', 'hundreds', 'thousands', 'units', '.']

>> Bigrams are: 
 [('This', 'illustrative'), ('illustrative', 'example'), ('example', 'two'), ('two', 'input'), ('input', 'units'), ('units', ','), (',', 'two'), ('two', 'hidden'), ('hidden', 'units'), ('units', 'one'), ('one', 'output'), ('output', 'unit'), ('unit', ','), (',', 'networks'), ('networks', 'used'), ('used', 'object'), ('object', 'recognition'), ('recognition', 'natural'), ('natural', 'language'), ('language', 'processing'), ('processing', 'contain'), ('contain', 'tens'), ('tens', 'hundreds'), ('hundreds', 'thousands'), ('thousands', 'units'), ('units', '.')]

>> Trigrams are: 
 [('This', 'illustrative', 'example'), ('illustrative', 'example', 'two'), ('example', 'two', 'input'), ('two', 'input', 'units'), ('input', 'units', ','), ('units', ',', 'two'), (',', 'two', 'hidden'), ('two', 'hidden', 'units'), ('hidden', 'units', 'one'), ('units', 'one', 'output'), ('one', 'output', 'unit'), ('output', 'unit', ','), ('unit', ',', 'networks'), (',', 'networks', 'used'), ('networks', 'used', 'object'), ('used', 'object', 'recognition'), ('object', 'recognition', 'natural'), ('recognition', 'natural', 'language'), ('natural', 'language', 'processing'), ('language', 'processing', 'contain'), ('processing', 'contain', 'tens'), ('contain', 'tens', 'hundreds'), ('tens', 'hundreds', 'thousands'), ('hundreds', 'thousands', 'units'), ('thousands', 'units', '.')]

>> POS Tags are: 
 [('This', 'DT'), ('illustrative', 'JJ'), ('example', 'NN'), ('two', 'CD'), ('input', 'NN'), ('units', 'NNS'), (',', ','), ('two', 'CD'), ('hidden', 'JJ'), ('units', 'NNS'), ('one', 'CD'), ('output', 'NN'), ('unit', 'NN'), (',', ','), ('networks', 'NNS'), ('used', 'VBD'), ('object', 'JJ'), ('recognition', 'NN'), ('natural', 'JJ'), ('language', 'NN'), ('processing', 'NN'), ('contain', 'NN'), ('tens', 'NNS'), ('hundreds', 'NNS'), ('thousands', 'NNS'), ('units', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['This illustrative example', 'input units', 'hidden units', 'output unit', 'networks', 'object recognition', 'natural language processing contain tens hundreds thousands units']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('This', 'thi'), ('illustrative', 'illustr'), ('example', 'exampl'), ('two', 'two'), ('input', 'input'), ('units', 'unit'), (',', ','), ('two', 'two'), ('hidden', 'hidden'), ('units', 'unit'), ('one', 'one'), ('output', 'output'), ('unit', 'unit'), (',', ','), ('networks', 'network'), ('used', 'use'), ('object', 'object'), ('recognition', 'recognit'), ('natural', 'natur'), ('language', 'languag'), ('processing', 'process'), ('contain', 'contain'), ('tens', 'ten'), ('hundreds', 'hundr'), ('thousands', 'thousand'), ('units', 'unit'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('This', 'this'), ('illustrative', 'illustr'), ('example', 'exampl'), ('two', 'two'), ('input', 'input'), ('units', 'unit'), (',', ','), ('two', 'two'), ('hidden', 'hidden'), ('units', 'unit'), ('one', 'one'), ('output', 'output'), ('unit', 'unit'), (',', ','), ('networks', 'network'), ('used', 'use'), ('object', 'object'), ('recognition', 'recognit'), ('natural', 'natur'), ('language', 'languag'), ('processing', 'process'), ('contain', 'contain'), ('tens', 'ten'), ('hundreds', 'hundr'), ('thousands', 'thousand'), ('units', 'unit'), ('.', '.')]

>> Lemmatization: 
 [('This', 'This'), ('illustrative', 'illustrative'), ('example', 'example'), ('two', 'two'), ('input', 'input'), ('units', 'unit'), (',', ','), ('two', 'two'), ('hidden', 'hidden'), ('units', 'unit'), ('one', 'one'), ('output', 'output'), ('unit', 'unit'), (',', ','), ('networks', 'network'), ('used', 'used'), ('object', 'object'), ('recognition', 'recognition'), ('natural', 'natural'), ('language', 'language'), ('processing', 'processing'), ('contain', 'contain'), ('tens', 'ten'), ('hundreds', 'hundred'), ('thousands', 'thousand'), ('units', 'unit'), ('.', '.')]


------------------- Sentence 5 -------------------

Reproduced with permission from C. Olah (http://colah.github.io/).

>> Tokens are: 
 ['Reproduced', 'permission', 'C.', 'Olah', '(', 'http', ':', '//colah.github.io/', ')', '.']

>> Bigrams are: 
 [('Reproduced', 'permission'), ('permission', 'C.'), ('C.', 'Olah'), ('Olah', '('), ('(', 'http'), ('http', ':'), (':', '//colah.github.io/'), ('//colah.github.io/', ')'), (')', '.')]

>> Trigrams are: 
 [('Reproduced', 'permission', 'C.'), ('permission', 'C.', 'Olah'), ('C.', 'Olah', '('), ('Olah', '(', 'http'), ('(', 'http', ':'), ('http', ':', '//colah.github.io/'), (':', '//colah.github.io/', ')'), ('//colah.github.io/', ')', '.')]

>> POS Tags are: 
 [('Reproduced', 'VBN'), ('permission', 'NN'), ('C.', 'NNP'), ('Olah', 'NNP'), ('(', '('), ('http', 'NN'), (':', ':'), ('//colah.github.io/', 'NN'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['permission C. Olah', 'http', '//colah.github.io/']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Reproduced', 'reproduc'), ('permission', 'permiss'), ('C.', 'c.'), ('Olah', 'olah'), ('(', '('), ('http', 'http'), (':', ':'), ('//colah.github.io/', '//colah.github.io/'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Reproduced', 'reproduc'), ('permission', 'permiss'), ('C.', 'c.'), ('Olah', 'olah'), ('(', '('), ('http', 'http'), (':', ':'), ('//colah.github.io/', '//colah.github.io/'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Reproduced', 'Reproduced'), ('permission', 'permission'), ('C.', 'C.'), ('Olah', 'Olah'), ('(', '('), ('http', 'http'), (':', ':'), ('//colah.github.io/', '//colah.github.io/'), (')', ')'), ('.', '.')]


------------------- Sentence 6 -------------------

b, The chain rule of derivatives tells us how two small effects (that of a small  change of x on y, and that of y on z) are composed.

>> Tokens are: 
 ['b', ',', 'The', 'chain', 'rule', 'derivatives', 'tells', 'us', 'two', 'small', 'effects', '(', 'small', 'change', 'x', ',', 'z', ')', 'composed', '.']

>> Bigrams are: 
 [('b', ','), (',', 'The'), ('The', 'chain'), ('chain', 'rule'), ('rule', 'derivatives'), ('derivatives', 'tells'), ('tells', 'us'), ('us', 'two'), ('two', 'small'), ('small', 'effects'), ('effects', '('), ('(', 'small'), ('small', 'change'), ('change', 'x'), ('x', ','), (',', 'z'), ('z', ')'), (')', 'composed'), ('composed', '.')]

>> Trigrams are: 
 [('b', ',', 'The'), (',', 'The', 'chain'), ('The', 'chain', 'rule'), ('chain', 'rule', 'derivatives'), ('rule', 'derivatives', 'tells'), ('derivatives', 'tells', 'us'), ('tells', 'us', 'two'), ('us', 'two', 'small'), ('two', 'small', 'effects'), ('small', 'effects', '('), ('effects', '(', 'small'), ('(', 'small', 'change'), ('small', 'change', 'x'), ('change', 'x', ','), ('x', ',', 'z'), (',', 'z', ')'), ('z', ')', 'composed'), (')', 'composed', '.')]

>> POS Tags are: 
 [('b', 'NN'), (',', ','), ('The', 'DT'), ('chain', 'NN'), ('rule', 'NN'), ('derivatives', 'NNS'), ('tells', 'VBP'), ('us', 'PRP'), ('two', 'CD'), ('small', 'JJ'), ('effects', 'NNS'), ('(', '('), ('small', 'JJ'), ('change', 'NN'), ('x', 'NNP'), (',', ','), ('z', 'NN'), (')', ')'), ('composed', 'VBD'), ('.', '.')]

>> Noun Phrases are: 
 ['b', 'The chain rule derivatives', 'small effects', 'small change x', 'z']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('b', 'b'), (',', ','), ('The', 'the'), ('chain', 'chain'), ('rule', 'rule'), ('derivatives', 'deriv'), ('tells', 'tell'), ('us', 'us'), ('two', 'two'), ('small', 'small'), ('effects', 'effect'), ('(', '('), ('small', 'small'), ('change', 'chang'), ('x', 'x'), (',', ','), ('z', 'z'), (')', ')'), ('composed', 'compos'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('b', 'b'), (',', ','), ('The', 'the'), ('chain', 'chain'), ('rule', 'rule'), ('derivatives', 'deriv'), ('tells', 'tell'), ('us', 'us'), ('two', 'two'), ('small', 'small'), ('effects', 'effect'), ('(', '('), ('small', 'small'), ('change', 'chang'), ('x', 'x'), (',', ','), ('z', 'z'), (')', ')'), ('composed', 'compos'), ('.', '.')]

>> Lemmatization: 
 [('b', 'b'), (',', ','), ('The', 'The'), ('chain', 'chain'), ('rule', 'rule'), ('derivatives', 'derivative'), ('tells', 'tell'), ('us', 'u'), ('two', 'two'), ('small', 'small'), ('effects', 'effect'), ('(', '('), ('small', 'small'), ('change', 'change'), ('x', 'x'), (',', ','), ('z', 'z'), (')', ')'), ('composed', 'composed'), ('.', '.')]


------------------- Sentence 7 -------------------

A small change Δx in  x gets transformed first into a small change Δy in y by getting multiplied  by ∂y/∂x (that is, the definition of partial derivative).

>> Tokens are: 
 ['A', 'small', 'change', 'Δx', 'x', 'gets', 'transformed', 'first', 'small', 'change', 'Δy', 'getting', 'multiplied', '∂y/∂x', '(', ',', 'definition', 'partial', 'derivative', ')', '.']

>> Bigrams are: 
 [('A', 'small'), ('small', 'change'), ('change', 'Δx'), ('Δx', 'x'), ('x', 'gets'), ('gets', 'transformed'), ('transformed', 'first'), ('first', 'small'), ('small', 'change'), ('change', 'Δy'), ('Δy', 'getting'), ('getting', 'multiplied'), ('multiplied', '∂y/∂x'), ('∂y/∂x', '('), ('(', ','), (',', 'definition'), ('definition', 'partial'), ('partial', 'derivative'), ('derivative', ')'), (')', '.')]

>> Trigrams are: 
 [('A', 'small', 'change'), ('small', 'change', 'Δx'), ('change', 'Δx', 'x'), ('Δx', 'x', 'gets'), ('x', 'gets', 'transformed'), ('gets', 'transformed', 'first'), ('transformed', 'first', 'small'), ('first', 'small', 'change'), ('small', 'change', 'Δy'), ('change', 'Δy', 'getting'), ('Δy', 'getting', 'multiplied'), ('getting', 'multiplied', '∂y/∂x'), ('multiplied', '∂y/∂x', '('), ('∂y/∂x', '(', ','), ('(', ',', 'definition'), (',', 'definition', 'partial'), ('definition', 'partial', 'derivative'), ('partial', 'derivative', ')'), ('derivative', ')', '.')]

>> POS Tags are: 
 [('A', 'DT'), ('small', 'JJ'), ('change', 'NN'), ('Δx', 'NNP'), ('x', 'NNP'), ('gets', 'VBZ'), ('transformed', 'VBN'), ('first', 'RB'), ('small', 'JJ'), ('change', 'NN'), ('Δy', 'NNP'), ('getting', 'VBG'), ('multiplied', 'VBN'), ('∂y/∂x', 'NNP'), ('(', '('), (',', ','), ('definition', 'NN'), ('partial', 'JJ'), ('derivative', 'NN'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['A small change Δx x', 'small change Δy', '∂y/∂x', 'definition', 'partial derivative']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('A', 'a'), ('small', 'small'), ('change', 'chang'), ('Δx', 'δx'), ('x', 'x'), ('gets', 'get'), ('transformed', 'transform'), ('first', 'first'), ('small', 'small'), ('change', 'chang'), ('Δy', 'δy'), ('getting', 'get'), ('multiplied', 'multipli'), ('∂y/∂x', '∂y/∂x'), ('(', '('), (',', ','), ('definition', 'definit'), ('partial', 'partial'), ('derivative', 'deriv'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('A', 'a'), ('small', 'small'), ('change', 'chang'), ('Δx', 'δx'), ('x', 'x'), ('gets', 'get'), ('transformed', 'transform'), ('first', 'first'), ('small', 'small'), ('change', 'chang'), ('Δy', 'δy'), ('getting', 'get'), ('multiplied', 'multipli'), ('∂y/∂x', '∂y/∂x'), ('(', '('), (',', ','), ('definition', 'definit'), ('partial', 'partial'), ('derivative', 'deriv'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('A', 'A'), ('small', 'small'), ('change', 'change'), ('Δx', 'Δx'), ('x', 'x'), ('gets', 'get'), ('transformed', 'transformed'), ('first', 'first'), ('small', 'small'), ('change', 'change'), ('Δy', 'Δy'), ('getting', 'getting'), ('multiplied', 'multiplied'), ('∂y/∂x', '∂y/∂x'), ('(', '('), (',', ','), ('definition', 'definition'), ('partial', 'partial'), ('derivative', 'derivative'), (')', ')'), ('.', '.')]


------------------- Sentence 8 -------------------

Similarly, the change  Δy creates a change Δz in z.

>> Tokens are: 
 ['Similarly', ',', 'change', 'Δy', 'creates', 'change', 'Δz', 'z', '.']

>> Bigrams are: 
 [('Similarly', ','), (',', 'change'), ('change', 'Δy'), ('Δy', 'creates'), ('creates', 'change'), ('change', 'Δz'), ('Δz', 'z'), ('z', '.')]

>> Trigrams are: 
 [('Similarly', ',', 'change'), (',', 'change', 'Δy'), ('change', 'Δy', 'creates'), ('Δy', 'creates', 'change'), ('creates', 'change', 'Δz'), ('change', 'Δz', 'z'), ('Δz', 'z', '.')]

>> POS Tags are: 
 [('Similarly', 'RB'), (',', ','), ('change', 'NN'), ('Δy', 'NNP'), ('creates', 'VBZ'), ('change', 'NN'), ('Δz', 'NNP'), ('z', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['change Δy', 'change Δz z']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Similarly', 'similarli'), (',', ','), ('change', 'chang'), ('Δy', 'δy'), ('creates', 'creat'), ('change', 'chang'), ('Δz', 'δz'), ('z', 'z'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Similarly', 'similar'), (',', ','), ('change', 'chang'), ('Δy', 'δy'), ('creates', 'creat'), ('change', 'chang'), ('Δz', 'δz'), ('z', 'z'), ('.', '.')]

>> Lemmatization: 
 [('Similarly', 'Similarly'), (',', ','), ('change', 'change'), ('Δy', 'Δy'), ('creates', 'creates'), ('change', 'change'), ('Δz', 'Δz'), ('z', 'z'), ('.', '.')]


------------------- Sentence 9 -------------------

Substituting one equation into the other  gives the chain rule of derivatives — how Δx gets turned into Δz through  multiplication by the product of ∂y/∂x and ∂z/∂x.

>> Tokens are: 
 ['Substituting', 'one', 'equation', 'gives', 'chain', 'rule', 'derivatives', '—', 'Δx', 'gets', 'turned', 'Δz', 'multiplication', 'product', '∂y/∂x', '∂z/∂x', '.']

>> Bigrams are: 
 [('Substituting', 'one'), ('one', 'equation'), ('equation', 'gives'), ('gives', 'chain'), ('chain', 'rule'), ('rule', 'derivatives'), ('derivatives', '—'), ('—', 'Δx'), ('Δx', 'gets'), ('gets', 'turned'), ('turned', 'Δz'), ('Δz', 'multiplication'), ('multiplication', 'product'), ('product', '∂y/∂x'), ('∂y/∂x', '∂z/∂x'), ('∂z/∂x', '.')]

>> Trigrams are: 
 [('Substituting', 'one', 'equation'), ('one', 'equation', 'gives'), ('equation', 'gives', 'chain'), ('gives', 'chain', 'rule'), ('chain', 'rule', 'derivatives'), ('rule', 'derivatives', '—'), ('derivatives', '—', 'Δx'), ('—', 'Δx', 'gets'), ('Δx', 'gets', 'turned'), ('gets', 'turned', 'Δz'), ('turned', 'Δz', 'multiplication'), ('Δz', 'multiplication', 'product'), ('multiplication', 'product', '∂y/∂x'), ('product', '∂y/∂x', '∂z/∂x'), ('∂y/∂x', '∂z/∂x', '.')]

>> POS Tags are: 
 [('Substituting', 'VBG'), ('one', 'CD'), ('equation', 'NN'), ('gives', 'VBZ'), ('chain', 'NN'), ('rule', 'NN'), ('derivatives', 'NNS'), ('—', 'VBP'), ('Δx', 'JJ'), ('gets', 'VBZ'), ('turned', 'JJ'), ('Δz', 'JJ'), ('multiplication', 'NN'), ('product', 'NN'), ('∂y/∂x', 'NNP'), ('∂z/∂x', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['equation', 'chain rule derivatives', 'turned Δz multiplication product ∂y/∂x ∂z/∂x']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Substituting', 'substitut'), ('one', 'one'), ('equation', 'equat'), ('gives', 'give'), ('chain', 'chain'), ('rule', 'rule'), ('derivatives', 'deriv'), ('—', '—'), ('Δx', 'δx'), ('gets', 'get'), ('turned', 'turn'), ('Δz', 'δz'), ('multiplication', 'multipl'), ('product', 'product'), ('∂y/∂x', '∂y/∂x'), ('∂z/∂x', '∂z/∂x'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Substituting', 'substitut'), ('one', 'one'), ('equation', 'equat'), ('gives', 'give'), ('chain', 'chain'), ('rule', 'rule'), ('derivatives', 'deriv'), ('—', '—'), ('Δx', 'δx'), ('gets', 'get'), ('turned', 'turn'), ('Δz', 'δz'), ('multiplication', 'multipl'), ('product', 'product'), ('∂y/∂x', '∂y/∂x'), ('∂z/∂x', '∂z/∂x'), ('.', '.')]

>> Lemmatization: 
 [('Substituting', 'Substituting'), ('one', 'one'), ('equation', 'equation'), ('gives', 'give'), ('chain', 'chain'), ('rule', 'rule'), ('derivatives', 'derivative'), ('—', '—'), ('Δx', 'Δx'), ('gets', 'get'), ('turned', 'turned'), ('Δz', 'Δz'), ('multiplication', 'multiplication'), ('product', 'product'), ('∂y/∂x', '∂y/∂x'), ('∂z/∂x', '∂z/∂x'), ('.', '.')]


------------------- Sentence 10 -------------------

It also works when x,  y and z are vectors (and the derivatives are Jacobian matrices).

>> Tokens are: 
 ['It', 'also', 'works', 'x', ',', 'z', 'vectors', '(', 'derivatives', 'Jacobian', 'matrices', ')', '.']

>> Bigrams are: 
 [('It', 'also'), ('also', 'works'), ('works', 'x'), ('x', ','), (',', 'z'), ('z', 'vectors'), ('vectors', '('), ('(', 'derivatives'), ('derivatives', 'Jacobian'), ('Jacobian', 'matrices'), ('matrices', ')'), (')', '.')]

>> Trigrams are: 
 [('It', 'also', 'works'), ('also', 'works', 'x'), ('works', 'x', ','), ('x', ',', 'z'), (',', 'z', 'vectors'), ('z', 'vectors', '('), ('vectors', '(', 'derivatives'), ('(', 'derivatives', 'Jacobian'), ('derivatives', 'Jacobian', 'matrices'), ('Jacobian', 'matrices', ')'), ('matrices', ')', '.')]

>> POS Tags are: 
 [('It', 'PRP'), ('also', 'RB'), ('works', 'VBZ'), ('x', 'NNP'), (',', ','), ('z', 'NN'), ('vectors', 'NNS'), ('(', '('), ('derivatives', 'NNS'), ('Jacobian', 'NNP'), ('matrices', 'NNS'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['x', 'z vectors', 'derivatives Jacobian matrices']

>> Named Entities are: 
 [('GPE', 'Jacobian')] 

>> Stemming using Porter Stemmer: 
 [('It', 'it'), ('also', 'also'), ('works', 'work'), ('x', 'x'), (',', ','), ('z', 'z'), ('vectors', 'vector'), ('(', '('), ('derivatives', 'deriv'), ('Jacobian', 'jacobian'), ('matrices', 'matric'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('It', 'it'), ('also', 'also'), ('works', 'work'), ('x', 'x'), (',', ','), ('z', 'z'), ('vectors', 'vector'), ('(', '('), ('derivatives', 'deriv'), ('Jacobian', 'jacobian'), ('matrices', 'matric'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('It', 'It'), ('also', 'also'), ('works', 'work'), ('x', 'x'), (',', ','), ('z', 'z'), ('vectors', 'vector'), ('(', '('), ('derivatives', 'derivative'), ('Jacobian', 'Jacobian'), ('matrices', 'matrix'), (')', ')'), ('.', '.')]


------------------- Sentence 11 -------------------

c, The  equations used for computing the forward pass in a neural net with two  hidden layers and one output layer, each constituting a module through

>> Tokens are: 
 ['c', ',', 'The', 'equations', 'used', 'computing', 'forward', 'pass', 'neural', 'net', 'two', 'hidden', 'layers', 'one', 'output', 'layer', ',', 'constituting', 'module']

>> Bigrams are: 
 [('c', ','), (',', 'The'), ('The', 'equations'), ('equations', 'used'), ('used', 'computing'), ('computing', 'forward'), ('forward', 'pass'), ('pass', 'neural'), ('neural', 'net'), ('net', 'two'), ('two', 'hidden'), ('hidden', 'layers'), ('layers', 'one'), ('one', 'output'), ('output', 'layer'), ('layer', ','), (',', 'constituting'), ('constituting', 'module')]

>> Trigrams are: 
 [('c', ',', 'The'), (',', 'The', 'equations'), ('The', 'equations', 'used'), ('equations', 'used', 'computing'), ('used', 'computing', 'forward'), ('computing', 'forward', 'pass'), ('forward', 'pass', 'neural'), ('pass', 'neural', 'net'), ('neural', 'net', 'two'), ('net', 'two', 'hidden'), ('two', 'hidden', 'layers'), ('hidden', 'layers', 'one'), ('layers', 'one', 'output'), ('one', 'output', 'layer'), ('output', 'layer', ','), ('layer', ',', 'constituting'), (',', 'constituting', 'module')]

>> POS Tags are: 
 [('c', 'NN'), (',', ','), ('The', 'DT'), ('equations', 'NNS'), ('used', 'VBD'), ('computing', 'VBG'), ('forward', 'RB'), ('pass', 'JJ'), ('neural', 'JJ'), ('net', 'NN'), ('two', 'CD'), ('hidden', 'NN'), ('layers', 'NNS'), ('one', 'CD'), ('output', 'NN'), ('layer', 'NN'), (',', ','), ('constituting', 'VBG'), ('module', 'NN')]

>> Noun Phrases are: 
 ['c', 'The equations', 'pass neural net', 'hidden layers', 'output layer', 'module']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('c', 'c'), (',', ','), ('The', 'the'), ('equations', 'equat'), ('used', 'use'), ('computing', 'comput'), ('forward', 'forward'), ('pass', 'pass'), ('neural', 'neural'), ('net', 'net'), ('two', 'two'), ('hidden', 'hidden'), ('layers', 'layer'), ('one', 'one'), ('output', 'output'), ('layer', 'layer'), (',', ','), ('constituting', 'constitut'), ('module', 'modul')]

>> Stemming using Snowball Stemmer: 
 [('c', 'c'), (',', ','), ('The', 'the'), ('equations', 'equat'), ('used', 'use'), ('computing', 'comput'), ('forward', 'forward'), ('pass', 'pass'), ('neural', 'neural'), ('net', 'net'), ('two', 'two'), ('hidden', 'hidden'), ('layers', 'layer'), ('one', 'one'), ('output', 'output'), ('layer', 'layer'), (',', ','), ('constituting', 'constitut'), ('module', 'modul')]

>> Lemmatization: 
 [('c', 'c'), (',', ','), ('The', 'The'), ('equations', 'equation'), ('used', 'used'), ('computing', 'computing'), ('forward', 'forward'), ('pass', 'pas'), ('neural', 'neural'), ('net', 'net'), ('two', 'two'), ('hidden', 'hidden'), ('layers', 'layer'), ('one', 'one'), ('output', 'output'), ('layer', 'layer'), (',', ','), ('constituting', 'constituting'), ('module', 'module')]



========================================== PARAGRAPH 21 ===========================================

which one can backpropagate gradients. At each layer, we first compute  the total input z to each unit, which is a weighted sum of the outputs of  the units in the layer below. Then a non-linear function f(.) is applied to  z to get the output of the unit. For simplicity, we have omitted bias terms.  The non-linear functions used in neural networks include the rectified  linear unit (ReLU) f(z) = max(0,z), commonly used in recent years, as  well as the more conventional sigmoids, such as the hyberbolic tangent,  f(z) = (exp(z) − exp(−z))/(exp(z) + exp(−z)) and logistic function logistic,  f(z) = 1/(1 + exp(−z)). d, The equations used for computing the backward  pass. At each hidden layer we compute the error derivative with respect to  the output of each unit, which is a weighted sum of the error derivatives  with respect to the total inputs to the units in the layer above. We then  convert the error derivative with respect to the output into the error  derivative with respect to the input by multiplying it by the gradient of f(z).  At the output layer, the error derivative with respect to the output of a unit  is computed by differentiating the cost function. This gives yl − tl if the cost  function for unit l is 0.5(yl − tl) 

------------------- Sentence 1 -------------------

which one can backpropagate gradients.

>> Tokens are: 
 ['one', 'backpropagate', 'gradients', '.']

>> Bigrams are: 
 [('one', 'backpropagate'), ('backpropagate', 'gradients'), ('gradients', '.')]

>> Trigrams are: 
 [('one', 'backpropagate', 'gradients'), ('backpropagate', 'gradients', '.')]

>> POS Tags are: 
 [('one', 'CD'), ('backpropagate', 'NN'), ('gradients', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['backpropagate gradients']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('one', 'one'), ('backpropagate', 'backpropag'), ('gradients', 'gradient'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('one', 'one'), ('backpropagate', 'backpropag'), ('gradients', 'gradient'), ('.', '.')]

>> Lemmatization: 
 [('one', 'one'), ('backpropagate', 'backpropagate'), ('gradients', 'gradient'), ('.', '.')]


------------------- Sentence 2 -------------------

At each layer, we first compute  the total input z to each unit, which is a weighted sum of the outputs of  the units in the layer below.

>> Tokens are: 
 ['At', 'layer', ',', 'first', 'compute', 'total', 'input', 'z', 'unit', ',', 'weighted', 'sum', 'outputs', 'units', 'layer', '.']

>> Bigrams are: 
 [('At', 'layer'), ('layer', ','), (',', 'first'), ('first', 'compute'), ('compute', 'total'), ('total', 'input'), ('input', 'z'), ('z', 'unit'), ('unit', ','), (',', 'weighted'), ('weighted', 'sum'), ('sum', 'outputs'), ('outputs', 'units'), ('units', 'layer'), ('layer', '.')]

>> Trigrams are: 
 [('At', 'layer', ','), ('layer', ',', 'first'), (',', 'first', 'compute'), ('first', 'compute', 'total'), ('compute', 'total', 'input'), ('total', 'input', 'z'), ('input', 'z', 'unit'), ('z', 'unit', ','), ('unit', ',', 'weighted'), (',', 'weighted', 'sum'), ('weighted', 'sum', 'outputs'), ('sum', 'outputs', 'units'), ('outputs', 'units', 'layer'), ('units', 'layer', '.')]

>> POS Tags are: 
 [('At', 'IN'), ('layer', 'NN'), (',', ','), ('first', 'RB'), ('compute', 'JJ'), ('total', 'NN'), ('input', 'NN'), ('z', 'NNP'), ('unit', 'NN'), (',', ','), ('weighted', 'VBD'), ('sum', 'NN'), ('outputs', 'NNS'), ('units', 'NNS'), ('layer', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['layer', 'compute total input z unit', 'sum outputs units layer']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('At', 'at'), ('layer', 'layer'), (',', ','), ('first', 'first'), ('compute', 'comput'), ('total', 'total'), ('input', 'input'), ('z', 'z'), ('unit', 'unit'), (',', ','), ('weighted', 'weight'), ('sum', 'sum'), ('outputs', 'output'), ('units', 'unit'), ('layer', 'layer'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('At', 'at'), ('layer', 'layer'), (',', ','), ('first', 'first'), ('compute', 'comput'), ('total', 'total'), ('input', 'input'), ('z', 'z'), ('unit', 'unit'), (',', ','), ('weighted', 'weight'), ('sum', 'sum'), ('outputs', 'output'), ('units', 'unit'), ('layer', 'layer'), ('.', '.')]

>> Lemmatization: 
 [('At', 'At'), ('layer', 'layer'), (',', ','), ('first', 'first'), ('compute', 'compute'), ('total', 'total'), ('input', 'input'), ('z', 'z'), ('unit', 'unit'), (',', ','), ('weighted', 'weighted'), ('sum', 'sum'), ('outputs', 'output'), ('units', 'unit'), ('layer', 'layer'), ('.', '.')]


------------------- Sentence 3 -------------------

Then a non-linear function f(.)

>> Tokens are: 
 ['Then', 'non-linear', 'function', 'f', '(', '.', ')']

>> Bigrams are: 
 [('Then', 'non-linear'), ('non-linear', 'function'), ('function', 'f'), ('f', '('), ('(', '.'), ('.', ')')]

>> Trigrams are: 
 [('Then', 'non-linear', 'function'), ('non-linear', 'function', 'f'), ('function', 'f', '('), ('f', '(', '.'), ('(', '.', ')')]

>> POS Tags are: 
 [('Then', 'RB'), ('non-linear', 'JJ'), ('function', 'NN'), ('f', 'NN'), ('(', '('), ('.', '.'), (')', ')')]

>> Noun Phrases are: 
 ['non-linear function f']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Then', 'then'), ('non-linear', 'non-linear'), ('function', 'function'), ('f', 'f'), ('(', '('), ('.', '.'), (')', ')')]

>> Stemming using Snowball Stemmer: 
 [('Then', 'then'), ('non-linear', 'non-linear'), ('function', 'function'), ('f', 'f'), ('(', '('), ('.', '.'), (')', ')')]

>> Lemmatization: 
 [('Then', 'Then'), ('non-linear', 'non-linear'), ('function', 'function'), ('f', 'f'), ('(', '('), ('.', '.'), (')', ')')]


------------------- Sentence 4 -------------------

is applied to  z to get the output of the unit.

>> Tokens are: 
 ['applied', 'z', 'get', 'output', 'unit', '.']

>> Bigrams are: 
 [('applied', 'z'), ('z', 'get'), ('get', 'output'), ('output', 'unit'), ('unit', '.')]

>> Trigrams are: 
 [('applied', 'z', 'get'), ('z', 'get', 'output'), ('get', 'output', 'unit'), ('output', 'unit', '.')]

>> POS Tags are: 
 [('applied', 'VBN'), ('z', 'NN'), ('get', 'NN'), ('output', 'NN'), ('unit', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['z get output unit']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('applied', 'appli'), ('z', 'z'), ('get', 'get'), ('output', 'output'), ('unit', 'unit'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('applied', 'appli'), ('z', 'z'), ('get', 'get'), ('output', 'output'), ('unit', 'unit'), ('.', '.')]

>> Lemmatization: 
 [('applied', 'applied'), ('z', 'z'), ('get', 'get'), ('output', 'output'), ('unit', 'unit'), ('.', '.')]


------------------- Sentence 5 -------------------

For simplicity, we have omitted bias terms.

>> Tokens are: 
 ['For', 'simplicity', ',', 'omitted', 'bias', 'terms', '.']

>> Bigrams are: 
 [('For', 'simplicity'), ('simplicity', ','), (',', 'omitted'), ('omitted', 'bias'), ('bias', 'terms'), ('terms', '.')]

>> Trigrams are: 
 [('For', 'simplicity', ','), ('simplicity', ',', 'omitted'), (',', 'omitted', 'bias'), ('omitted', 'bias', 'terms'), ('bias', 'terms', '.')]

>> POS Tags are: 
 [('For', 'IN'), ('simplicity', 'NN'), (',', ','), ('omitted', 'VBN'), ('bias', 'NN'), ('terms', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['simplicity', 'bias terms']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('For', 'for'), ('simplicity', 'simplic'), (',', ','), ('omitted', 'omit'), ('bias', 'bia'), ('terms', 'term'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('For', 'for'), ('simplicity', 'simplic'), (',', ','), ('omitted', 'omit'), ('bias', 'bias'), ('terms', 'term'), ('.', '.')]

>> Lemmatization: 
 [('For', 'For'), ('simplicity', 'simplicity'), (',', ','), ('omitted', 'omitted'), ('bias', 'bias'), ('terms', 'term'), ('.', '.')]


------------------- Sentence 6 -------------------

The non-linear functions used in neural networks include the rectified  linear unit (ReLU) f(z) = max(0,z), commonly used in recent years, as  well as the more conventional sigmoids, such as the hyberbolic tangent,  f(z) = (exp(z) − exp(−z))/(exp(z) + exp(−z)) and logistic function logistic,  f(z) = 1/(1 + exp(−z)).

>> Tokens are: 
 ['The', 'non-linear', 'functions', 'used', 'neural', 'networks', 'include', 'rectified', 'linear', 'unit', '(', 'ReLU', ')', 'f', '(', 'z', ')', '=', 'max', '(', '0', ',', 'z', ')', ',', 'commonly', 'used', 'recent', 'years', ',', 'well', 'conventional', 'sigmoids', ',', 'hyberbolic', 'tangent', ',', 'f', '(', 'z', ')', '=', '(', 'exp', '(', 'z', ')', '−', 'exp', '(', '−z', ')', ')', '/', '(', 'exp', '(', 'z', ')', '+', 'exp', '(', '−z', ')', ')', 'logistic', 'function', 'logistic', ',', 'f', '(', 'z', ')', '=', '1/', '(', '1', '+', 'exp', '(', '−z', ')', ')', '.']

>> Bigrams are: 
 [('The', 'non-linear'), ('non-linear', 'functions'), ('functions', 'used'), ('used', 'neural'), ('neural', 'networks'), ('networks', 'include'), ('include', 'rectified'), ('rectified', 'linear'), ('linear', 'unit'), ('unit', '('), ('(', 'ReLU'), ('ReLU', ')'), (')', 'f'), ('f', '('), ('(', 'z'), ('z', ')'), (')', '='), ('=', 'max'), ('max', '('), ('(', '0'), ('0', ','), (',', 'z'), ('z', ')'), (')', ','), (',', 'commonly'), ('commonly', 'used'), ('used', 'recent'), ('recent', 'years'), ('years', ','), (',', 'well'), ('well', 'conventional'), ('conventional', 'sigmoids'), ('sigmoids', ','), (',', 'hyberbolic'), ('hyberbolic', 'tangent'), ('tangent', ','), (',', 'f'), ('f', '('), ('(', 'z'), ('z', ')'), (')', '='), ('=', '('), ('(', 'exp'), ('exp', '('), ('(', 'z'), ('z', ')'), (')', '−'), ('−', 'exp'), ('exp', '('), ('(', '−z'), ('−z', ')'), (')', ')'), (')', '/'), ('/', '('), ('(', 'exp'), ('exp', '('), ('(', 'z'), ('z', ')'), (')', '+'), ('+', 'exp'), ('exp', '('), ('(', '−z'), ('−z', ')'), (')', ')'), (')', 'logistic'), ('logistic', 'function'), ('function', 'logistic'), ('logistic', ','), (',', 'f'), ('f', '('), ('(', 'z'), ('z', ')'), (')', '='), ('=', '1/'), ('1/', '('), ('(', '1'), ('1', '+'), ('+', 'exp'), ('exp', '('), ('(', '−z'), ('−z', ')'), (')', ')'), (')', '.')]

>> Trigrams are: 
 [('The', 'non-linear', 'functions'), ('non-linear', 'functions', 'used'), ('functions', 'used', 'neural'), ('used', 'neural', 'networks'), ('neural', 'networks', 'include'), ('networks', 'include', 'rectified'), ('include', 'rectified', 'linear'), ('rectified', 'linear', 'unit'), ('linear', 'unit', '('), ('unit', '(', 'ReLU'), ('(', 'ReLU', ')'), ('ReLU', ')', 'f'), (')', 'f', '('), ('f', '(', 'z'), ('(', 'z', ')'), ('z', ')', '='), (')', '=', 'max'), ('=', 'max', '('), ('max', '(', '0'), ('(', '0', ','), ('0', ',', 'z'), (',', 'z', ')'), ('z', ')', ','), (')', ',', 'commonly'), (',', 'commonly', 'used'), ('commonly', 'used', 'recent'), ('used', 'recent', 'years'), ('recent', 'years', ','), ('years', ',', 'well'), (',', 'well', 'conventional'), ('well', 'conventional', 'sigmoids'), ('conventional', 'sigmoids', ','), ('sigmoids', ',', 'hyberbolic'), (',', 'hyberbolic', 'tangent'), ('hyberbolic', 'tangent', ','), ('tangent', ',', 'f'), (',', 'f', '('), ('f', '(', 'z'), ('(', 'z', ')'), ('z', ')', '='), (')', '=', '('), ('=', '(', 'exp'), ('(', 'exp', '('), ('exp', '(', 'z'), ('(', 'z', ')'), ('z', ')', '−'), (')', '−', 'exp'), ('−', 'exp', '('), ('exp', '(', '−z'), ('(', '−z', ')'), ('−z', ')', ')'), (')', ')', '/'), (')', '/', '('), ('/', '(', 'exp'), ('(', 'exp', '('), ('exp', '(', 'z'), ('(', 'z', ')'), ('z', ')', '+'), (')', '+', 'exp'), ('+', 'exp', '('), ('exp', '(', '−z'), ('(', '−z', ')'), ('−z', ')', ')'), (')', ')', 'logistic'), (')', 'logistic', 'function'), ('logistic', 'function', 'logistic'), ('function', 'logistic', ','), ('logistic', ',', 'f'), (',', 'f', '('), ('f', '(', 'z'), ('(', 'z', ')'), ('z', ')', '='), (')', '=', '1/'), ('=', '1/', '('), ('1/', '(', '1'), ('(', '1', '+'), ('1', '+', 'exp'), ('+', 'exp', '('), ('exp', '(', '−z'), ('(', '−z', ')'), ('−z', ')', ')'), (')', ')', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('non-linear', 'JJ'), ('functions', 'NNS'), ('used', 'VBN'), ('neural', 'JJ'), ('networks', 'NNS'), ('include', 'VBP'), ('rectified', 'JJ'), ('linear', 'JJ'), ('unit', 'NN'), ('(', '('), ('ReLU', 'NNP'), (')', ')'), ('f', 'NN'), ('(', '('), ('z', 'NN'), (')', ')'), ('=', 'NN'), ('max', 'NN'), ('(', '('), ('0', 'CD'), (',', ','), ('z', 'NN'), (')', ')'), (',', ','), ('commonly', 'RB'), ('used', 'VBN'), ('recent', 'JJ'), ('years', 'NNS'), (',', ','), ('well', 'RB'), ('conventional', 'JJ'), ('sigmoids', 'NNS'), (',', ','), ('hyberbolic', 'JJ'), ('tangent', 'NN'), (',', ','), ('f', 'NN'), ('(', '('), ('z', 'NN'), (')', ')'), ('=', 'NN'), ('(', '('), ('exp', 'NN'), ('(', '('), ('z', 'NN'), (')', ')'), ('−', 'NN'), ('exp', 'NN'), ('(', '('), ('−z', 'NNP'), (')', ')'), (')', ')'), ('/', 'FW'), ('(', '('), ('exp', 'FW'), ('(', '('), ('z', 'NN'), (')', ')'), ('+', 'NN'), ('exp', 'NN'), ('(', '('), ('−z', 'NNP'), (')', ')'), (')', ')'), ('logistic', 'JJ'), ('function', 'NN'), ('logistic', 'JJ'), (',', ','), ('f', 'NN'), ('(', '('), ('z', 'NN'), (')', ')'), ('=', 'VBZ'), ('1/', 'CD'), ('(', '('), ('1', 'CD'), ('+', 'NN'), ('exp', 'NN'), ('(', '('), ('−z', 'NNP'), (')', ')'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['The non-linear functions', 'neural networks', 'rectified linear unit', 'ReLU', 'f', 'z', '= max', 'z', 'recent years', 'conventional sigmoids', 'hyberbolic tangent', 'f', 'z', '=', 'exp', 'z', '− exp', '−z', 'z', '+ exp', '−z', 'logistic function', 'f', 'z', '+ exp', '−z']

>> Named Entities are: 
 [('ORGANIZATION', 'ReLU')] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('non-linear', 'non-linear'), ('functions', 'function'), ('used', 'use'), ('neural', 'neural'), ('networks', 'network'), ('include', 'includ'), ('rectified', 'rectifi'), ('linear', 'linear'), ('unit', 'unit'), ('(', '('), ('ReLU', 'relu'), (')', ')'), ('f', 'f'), ('(', '('), ('z', 'z'), (')', ')'), ('=', '='), ('max', 'max'), ('(', '('), ('0', '0'), (',', ','), ('z', 'z'), (')', ')'), (',', ','), ('commonly', 'commonli'), ('used', 'use'), ('recent', 'recent'), ('years', 'year'), (',', ','), ('well', 'well'), ('conventional', 'convent'), ('sigmoids', 'sigmoid'), (',', ','), ('hyberbolic', 'hyberbol'), ('tangent', 'tangent'), (',', ','), ('f', 'f'), ('(', '('), ('z', 'z'), (')', ')'), ('=', '='), ('(', '('), ('exp', 'exp'), ('(', '('), ('z', 'z'), (')', ')'), ('−', '−'), ('exp', 'exp'), ('(', '('), ('−z', '−z'), (')', ')'), (')', ')'), ('/', '/'), ('(', '('), ('exp', 'exp'), ('(', '('), ('z', 'z'), (')', ')'), ('+', '+'), ('exp', 'exp'), ('(', '('), ('−z', '−z'), (')', ')'), (')', ')'), ('logistic', 'logist'), ('function', 'function'), ('logistic', 'logist'), (',', ','), ('f', 'f'), ('(', '('), ('z', 'z'), (')', ')'), ('=', '='), ('1/', '1/'), ('(', '('), ('1', '1'), ('+', '+'), ('exp', 'exp'), ('(', '('), ('−z', '−z'), (')', ')'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('non-linear', 'non-linear'), ('functions', 'function'), ('used', 'use'), ('neural', 'neural'), ('networks', 'network'), ('include', 'includ'), ('rectified', 'rectifi'), ('linear', 'linear'), ('unit', 'unit'), ('(', '('), ('ReLU', 'relu'), (')', ')'), ('f', 'f'), ('(', '('), ('z', 'z'), (')', ')'), ('=', '='), ('max', 'max'), ('(', '('), ('0', '0'), (',', ','), ('z', 'z'), (')', ')'), (',', ','), ('commonly', 'common'), ('used', 'use'), ('recent', 'recent'), ('years', 'year'), (',', ','), ('well', 'well'), ('conventional', 'convent'), ('sigmoids', 'sigmoid'), (',', ','), ('hyberbolic', 'hyberbol'), ('tangent', 'tangent'), (',', ','), ('f', 'f'), ('(', '('), ('z', 'z'), (')', ')'), ('=', '='), ('(', '('), ('exp', 'exp'), ('(', '('), ('z', 'z'), (')', ')'), ('−', '−'), ('exp', 'exp'), ('(', '('), ('−z', '−z'), (')', ')'), (')', ')'), ('/', '/'), ('(', '('), ('exp', 'exp'), ('(', '('), ('z', 'z'), (')', ')'), ('+', '+'), ('exp', 'exp'), ('(', '('), ('−z', '−z'), (')', ')'), (')', ')'), ('logistic', 'logist'), ('function', 'function'), ('logistic', 'logist'), (',', ','), ('f', 'f'), ('(', '('), ('z', 'z'), (')', ')'), ('=', '='), ('1/', '1/'), ('(', '('), ('1', '1'), ('+', '+'), ('exp', 'exp'), ('(', '('), ('−z', '−z'), (')', ')'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('non-linear', 'non-linear'), ('functions', 'function'), ('used', 'used'), ('neural', 'neural'), ('networks', 'network'), ('include', 'include'), ('rectified', 'rectified'), ('linear', 'linear'), ('unit', 'unit'), ('(', '('), ('ReLU', 'ReLU'), (')', ')'), ('f', 'f'), ('(', '('), ('z', 'z'), (')', ')'), ('=', '='), ('max', 'max'), ('(', '('), ('0', '0'), (',', ','), ('z', 'z'), (')', ')'), (',', ','), ('commonly', 'commonly'), ('used', 'used'), ('recent', 'recent'), ('years', 'year'), (',', ','), ('well', 'well'), ('conventional', 'conventional'), ('sigmoids', 'sigmoids'), (',', ','), ('hyberbolic', 'hyberbolic'), ('tangent', 'tangent'), (',', ','), ('f', 'f'), ('(', '('), ('z', 'z'), (')', ')'), ('=', '='), ('(', '('), ('exp', 'exp'), ('(', '('), ('z', 'z'), (')', ')'), ('−', '−'), ('exp', 'exp'), ('(', '('), ('−z', '−z'), (')', ')'), (')', ')'), ('/', '/'), ('(', '('), ('exp', 'exp'), ('(', '('), ('z', 'z'), (')', ')'), ('+', '+'), ('exp', 'exp'), ('(', '('), ('−z', '−z'), (')', ')'), (')', ')'), ('logistic', 'logistic'), ('function', 'function'), ('logistic', 'logistic'), (',', ','), ('f', 'f'), ('(', '('), ('z', 'z'), (')', ')'), ('=', '='), ('1/', '1/'), ('(', '('), ('1', '1'), ('+', '+'), ('exp', 'exp'), ('(', '('), ('−z', '−z'), (')', ')'), (')', ')'), ('.', '.')]


------------------- Sentence 7 -------------------

d, The equations used for computing the backward  pass.

>> Tokens are: 
 [',', 'The', 'equations', 'used', 'computing', 'backward', 'pass', '.']

>> Bigrams are: 
 [(',', 'The'), ('The', 'equations'), ('equations', 'used'), ('used', 'computing'), ('computing', 'backward'), ('backward', 'pass'), ('pass', '.')]

>> Trigrams are: 
 [(',', 'The', 'equations'), ('The', 'equations', 'used'), ('equations', 'used', 'computing'), ('used', 'computing', 'backward'), ('computing', 'backward', 'pass'), ('backward', 'pass', '.')]

>> POS Tags are: 
 [(',', ','), ('The', 'DT'), ('equations', 'NNS'), ('used', 'VBD'), ('computing', 'VBG'), ('backward', 'RB'), ('pass', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['The equations', 'pass']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [(',', ','), ('The', 'the'), ('equations', 'equat'), ('used', 'use'), ('computing', 'comput'), ('backward', 'backward'), ('pass', 'pass'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [(',', ','), ('The', 'the'), ('equations', 'equat'), ('used', 'use'), ('computing', 'comput'), ('backward', 'backward'), ('pass', 'pass'), ('.', '.')]

>> Lemmatization: 
 [(',', ','), ('The', 'The'), ('equations', 'equation'), ('used', 'used'), ('computing', 'computing'), ('backward', 'backward'), ('pass', 'pas'), ('.', '.')]


------------------- Sentence 8 -------------------

At each hidden layer we compute the error derivative with respect to  the output of each unit, which is a weighted sum of the error derivatives  with respect to the total inputs to the units in the layer above.

>> Tokens are: 
 ['At', 'hidden', 'layer', 'compute', 'error', 'derivative', 'respect', 'output', 'unit', ',', 'weighted', 'sum', 'error', 'derivatives', 'respect', 'total', 'inputs', 'units', 'layer', '.']

>> Bigrams are: 
 [('At', 'hidden'), ('hidden', 'layer'), ('layer', 'compute'), ('compute', 'error'), ('error', 'derivative'), ('derivative', 'respect'), ('respect', 'output'), ('output', 'unit'), ('unit', ','), (',', 'weighted'), ('weighted', 'sum'), ('sum', 'error'), ('error', 'derivatives'), ('derivatives', 'respect'), ('respect', 'total'), ('total', 'inputs'), ('inputs', 'units'), ('units', 'layer'), ('layer', '.')]

>> Trigrams are: 
 [('At', 'hidden', 'layer'), ('hidden', 'layer', 'compute'), ('layer', 'compute', 'error'), ('compute', 'error', 'derivative'), ('error', 'derivative', 'respect'), ('derivative', 'respect', 'output'), ('respect', 'output', 'unit'), ('output', 'unit', ','), ('unit', ',', 'weighted'), (',', 'weighted', 'sum'), ('weighted', 'sum', 'error'), ('sum', 'error', 'derivatives'), ('error', 'derivatives', 'respect'), ('derivatives', 'respect', 'total'), ('respect', 'total', 'inputs'), ('total', 'inputs', 'units'), ('inputs', 'units', 'layer'), ('units', 'layer', '.')]

>> POS Tags are: 
 [('At', 'IN'), ('hidden', 'JJ'), ('layer', 'NN'), ('compute', 'NN'), ('error', 'NN'), ('derivative', 'JJ'), ('respect', 'NN'), ('output', 'NN'), ('unit', 'NN'), (',', ','), ('weighted', 'VBD'), ('sum', 'JJ'), ('error', 'NN'), ('derivatives', 'NNS'), ('respect', 'VBP'), ('total', 'JJ'), ('inputs', 'NNS'), ('units', 'NNS'), ('layer', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['hidden layer compute error', 'derivative respect output unit', 'sum error derivatives', 'total inputs units layer']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('At', 'at'), ('hidden', 'hidden'), ('layer', 'layer'), ('compute', 'comput'), ('error', 'error'), ('derivative', 'deriv'), ('respect', 'respect'), ('output', 'output'), ('unit', 'unit'), (',', ','), ('weighted', 'weight'), ('sum', 'sum'), ('error', 'error'), ('derivatives', 'deriv'), ('respect', 'respect'), ('total', 'total'), ('inputs', 'input'), ('units', 'unit'), ('layer', 'layer'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('At', 'at'), ('hidden', 'hidden'), ('layer', 'layer'), ('compute', 'comput'), ('error', 'error'), ('derivative', 'deriv'), ('respect', 'respect'), ('output', 'output'), ('unit', 'unit'), (',', ','), ('weighted', 'weight'), ('sum', 'sum'), ('error', 'error'), ('derivatives', 'deriv'), ('respect', 'respect'), ('total', 'total'), ('inputs', 'input'), ('units', 'unit'), ('layer', 'layer'), ('.', '.')]

>> Lemmatization: 
 [('At', 'At'), ('hidden', 'hidden'), ('layer', 'layer'), ('compute', 'compute'), ('error', 'error'), ('derivative', 'derivative'), ('respect', 'respect'), ('output', 'output'), ('unit', 'unit'), (',', ','), ('weighted', 'weighted'), ('sum', 'sum'), ('error', 'error'), ('derivatives', 'derivative'), ('respect', 'respect'), ('total', 'total'), ('inputs', 'input'), ('units', 'unit'), ('layer', 'layer'), ('.', '.')]


------------------- Sentence 9 -------------------

We then  convert the error derivative with respect to the output into the error  derivative with respect to the input by multiplying it by the gradient of f(z).

>> Tokens are: 
 ['We', 'convert', 'error', 'derivative', 'respect', 'output', 'error', 'derivative', 'respect', 'input', 'multiplying', 'gradient', 'f', '(', 'z', ')', '.']

>> Bigrams are: 
 [('We', 'convert'), ('convert', 'error'), ('error', 'derivative'), ('derivative', 'respect'), ('respect', 'output'), ('output', 'error'), ('error', 'derivative'), ('derivative', 'respect'), ('respect', 'input'), ('input', 'multiplying'), ('multiplying', 'gradient'), ('gradient', 'f'), ('f', '('), ('(', 'z'), ('z', ')'), (')', '.')]

>> Trigrams are: 
 [('We', 'convert', 'error'), ('convert', 'error', 'derivative'), ('error', 'derivative', 'respect'), ('derivative', 'respect', 'output'), ('respect', 'output', 'error'), ('output', 'error', 'derivative'), ('error', 'derivative', 'respect'), ('derivative', 'respect', 'input'), ('respect', 'input', 'multiplying'), ('input', 'multiplying', 'gradient'), ('multiplying', 'gradient', 'f'), ('gradient', 'f', '('), ('f', '(', 'z'), ('(', 'z', ')'), ('z', ')', '.')]

>> POS Tags are: 
 [('We', 'PRP'), ('convert', 'VBP'), ('error', 'JJ'), ('derivative', 'JJ'), ('respect', 'NN'), ('output', 'NN'), ('error', 'RB'), ('derivative', 'JJ'), ('respect', 'NN'), ('input', 'NN'), ('multiplying', 'VBG'), ('gradient', 'JJ'), ('f', 'NN'), ('(', '('), ('z', 'NN'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['error derivative respect output', 'derivative respect input', 'gradient f', 'z']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('We', 'we'), ('convert', 'convert'), ('error', 'error'), ('derivative', 'deriv'), ('respect', 'respect'), ('output', 'output'), ('error', 'error'), ('derivative', 'deriv'), ('respect', 'respect'), ('input', 'input'), ('multiplying', 'multipli'), ('gradient', 'gradient'), ('f', 'f'), ('(', '('), ('z', 'z'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('We', 'we'), ('convert', 'convert'), ('error', 'error'), ('derivative', 'deriv'), ('respect', 'respect'), ('output', 'output'), ('error', 'error'), ('derivative', 'deriv'), ('respect', 'respect'), ('input', 'input'), ('multiplying', 'multipli'), ('gradient', 'gradient'), ('f', 'f'), ('(', '('), ('z', 'z'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('We', 'We'), ('convert', 'convert'), ('error', 'error'), ('derivative', 'derivative'), ('respect', 'respect'), ('output', 'output'), ('error', 'error'), ('derivative', 'derivative'), ('respect', 'respect'), ('input', 'input'), ('multiplying', 'multiplying'), ('gradient', 'gradient'), ('f', 'f'), ('(', '('), ('z', 'z'), (')', ')'), ('.', '.')]


------------------- Sentence 10 -------------------

At the output layer, the error derivative with respect to the output of a unit  is computed by differentiating the cost function.

>> Tokens are: 
 ['At', 'output', 'layer', ',', 'error', 'derivative', 'respect', 'output', 'unit', 'computed', 'differentiating', 'cost', 'function', '.']

>> Bigrams are: 
 [('At', 'output'), ('output', 'layer'), ('layer', ','), (',', 'error'), ('error', 'derivative'), ('derivative', 'respect'), ('respect', 'output'), ('output', 'unit'), ('unit', 'computed'), ('computed', 'differentiating'), ('differentiating', 'cost'), ('cost', 'function'), ('function', '.')]

>> Trigrams are: 
 [('At', 'output', 'layer'), ('output', 'layer', ','), ('layer', ',', 'error'), (',', 'error', 'derivative'), ('error', 'derivative', 'respect'), ('derivative', 'respect', 'output'), ('respect', 'output', 'unit'), ('output', 'unit', 'computed'), ('unit', 'computed', 'differentiating'), ('computed', 'differentiating', 'cost'), ('differentiating', 'cost', 'function'), ('cost', 'function', '.')]

>> POS Tags are: 
 [('At', 'IN'), ('output', 'NN'), ('layer', 'NN'), (',', ','), ('error', 'NN'), ('derivative', 'JJ'), ('respect', 'NN'), ('output', 'NN'), ('unit', 'NN'), ('computed', 'VBD'), ('differentiating', 'VBG'), ('cost', 'NN'), ('function', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['output layer', 'error', 'derivative respect output unit', 'cost function']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('At', 'at'), ('output', 'output'), ('layer', 'layer'), (',', ','), ('error', 'error'), ('derivative', 'deriv'), ('respect', 'respect'), ('output', 'output'), ('unit', 'unit'), ('computed', 'comput'), ('differentiating', 'differenti'), ('cost', 'cost'), ('function', 'function'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('At', 'at'), ('output', 'output'), ('layer', 'layer'), (',', ','), ('error', 'error'), ('derivative', 'deriv'), ('respect', 'respect'), ('output', 'output'), ('unit', 'unit'), ('computed', 'comput'), ('differentiating', 'differenti'), ('cost', 'cost'), ('function', 'function'), ('.', '.')]

>> Lemmatization: 
 [('At', 'At'), ('output', 'output'), ('layer', 'layer'), (',', ','), ('error', 'error'), ('derivative', 'derivative'), ('respect', 'respect'), ('output', 'output'), ('unit', 'unit'), ('computed', 'computed'), ('differentiating', 'differentiating'), ('cost', 'cost'), ('function', 'function'), ('.', '.')]


------------------- Sentence 11 -------------------

This gives yl − tl if the cost  function for unit l is 0.5(yl − tl)

>> Tokens are: 
 ['This', 'gives', 'yl', '−', 'tl', 'cost', 'function', 'unit', 'l', '0.5', '(', 'yl', '−', 'tl', ')']

>> Bigrams are: 
 [('This', 'gives'), ('gives', 'yl'), ('yl', '−'), ('−', 'tl'), ('tl', 'cost'), ('cost', 'function'), ('function', 'unit'), ('unit', 'l'), ('l', '0.5'), ('0.5', '('), ('(', 'yl'), ('yl', '−'), ('−', 'tl'), ('tl', ')')]

>> Trigrams are: 
 [('This', 'gives', 'yl'), ('gives', 'yl', '−'), ('yl', '−', 'tl'), ('−', 'tl', 'cost'), ('tl', 'cost', 'function'), ('cost', 'function', 'unit'), ('function', 'unit', 'l'), ('unit', 'l', '0.5'), ('l', '0.5', '('), ('0.5', '(', 'yl'), ('(', 'yl', '−'), ('yl', '−', 'tl'), ('−', 'tl', ')')]

>> POS Tags are: 
 [('This', 'DT'), ('gives', 'VBZ'), ('yl', 'JJR'), ('−', 'JJ'), ('tl', 'NN'), ('cost', 'NN'), ('function', 'NN'), ('unit', 'NN'), ('l', 'VBZ'), ('0.5', 'CD'), ('(', '('), ('yl', 'JJ'), ('−', 'NNP'), ('tl', 'NN'), (')', ')')]

>> Noun Phrases are: 
 ['− tl cost function unit', 'yl − tl']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('This', 'thi'), ('gives', 'give'), ('yl', 'yl'), ('−', '−'), ('tl', 'tl'), ('cost', 'cost'), ('function', 'function'), ('unit', 'unit'), ('l', 'l'), ('0.5', '0.5'), ('(', '('), ('yl', 'yl'), ('−', '−'), ('tl', 'tl'), (')', ')')]

>> Stemming using Snowball Stemmer: 
 [('This', 'this'), ('gives', 'give'), ('yl', 'yl'), ('−', '−'), ('tl', 'tl'), ('cost', 'cost'), ('function', 'function'), ('unit', 'unit'), ('l', 'l'), ('0.5', '0.5'), ('(', '('), ('yl', 'yl'), ('−', '−'), ('tl', 'tl'), (')', ')')]

>> Lemmatization: 
 [('This', 'This'), ('gives', 'give'), ('yl', 'yl'), ('−', '−'), ('tl', 'tl'), ('cost', 'cost'), ('function', 'function'), ('unit', 'unit'), ('l', 'l'), ('0.5', '0.5'), ('(', '('), ('yl', 'yl'), ('−', '−'), ('tl', 'tl'), (')', ')')]



========================================== PARAGRAPH 22 ===========================================

2, where tl is the target value. Once the ∂E/∂zk  is known, the error-derivative for the weight wjk on the connection from  unit j in the layer below is just yj ∂E/∂zk. 

------------------- Sentence 1 -------------------

2, where tl is the target value.

>> Tokens are: 
 ['2', ',', 'tl', 'target', 'value', '.']

>> Bigrams are: 
 [('2', ','), (',', 'tl'), ('tl', 'target'), ('target', 'value'), ('value', '.')]

>> Trigrams are: 
 [('2', ',', 'tl'), (',', 'tl', 'target'), ('tl', 'target', 'value'), ('target', 'value', '.')]

>> POS Tags are: 
 [('2', 'CD'), (',', ','), ('tl', 'NN'), ('target', 'NN'), ('value', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['tl target value']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('2', '2'), (',', ','), ('tl', 'tl'), ('target', 'target'), ('value', 'valu'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('2', '2'), (',', ','), ('tl', 'tl'), ('target', 'target'), ('value', 'valu'), ('.', '.')]

>> Lemmatization: 
 [('2', '2'), (',', ','), ('tl', 'tl'), ('target', 'target'), ('value', 'value'), ('.', '.')]


------------------- Sentence 2 -------------------

Once the ∂E/∂zk  is known, the error-derivative for the weight wjk on the connection from  unit j in the layer below is just yj ∂E/∂zk.

>> Tokens are: 
 ['Once', '∂E/∂zk', 'known', ',', 'error-derivative', 'weight', 'wjk', 'connection', 'unit', 'j', 'layer', 'yj', '∂E/∂zk', '.']

>> Bigrams are: 
 [('Once', '∂E/∂zk'), ('∂E/∂zk', 'known'), ('known', ','), (',', 'error-derivative'), ('error-derivative', 'weight'), ('weight', 'wjk'), ('wjk', 'connection'), ('connection', 'unit'), ('unit', 'j'), ('j', 'layer'), ('layer', 'yj'), ('yj', '∂E/∂zk'), ('∂E/∂zk', '.')]

>> Trigrams are: 
 [('Once', '∂E/∂zk', 'known'), ('∂E/∂zk', 'known', ','), ('known', ',', 'error-derivative'), (',', 'error-derivative', 'weight'), ('error-derivative', 'weight', 'wjk'), ('weight', 'wjk', 'connection'), ('wjk', 'connection', 'unit'), ('connection', 'unit', 'j'), ('unit', 'j', 'layer'), ('j', 'layer', 'yj'), ('layer', 'yj', '∂E/∂zk'), ('yj', '∂E/∂zk', '.')]

>> POS Tags are: 
 [('Once', 'RB'), ('∂E/∂zk', 'JJ'), ('known', 'VBN'), (',', ','), ('error-derivative', 'JJ'), ('weight', 'NN'), ('wjk', 'WP'), ('connection', 'NN'), ('unit', 'NN'), ('j', 'NN'), ('layer', 'NN'), ('yj', 'NN'), ('∂E/∂zk', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['error-derivative weight', 'connection unit j layer yj ∂E/∂zk']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Once', 'onc'), ('∂E/∂zk', '∂e/∂zk'), ('known', 'known'), (',', ','), ('error-derivative', 'error-deriv'), ('weight', 'weight'), ('wjk', 'wjk'), ('connection', 'connect'), ('unit', 'unit'), ('j', 'j'), ('layer', 'layer'), ('yj', 'yj'), ('∂E/∂zk', '∂e/∂zk'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Once', 'onc'), ('∂E/∂zk', '∂e/∂zk'), ('known', 'known'), (',', ','), ('error-derivative', 'error-deriv'), ('weight', 'weight'), ('wjk', 'wjk'), ('connection', 'connect'), ('unit', 'unit'), ('j', 'j'), ('layer', 'layer'), ('yj', 'yj'), ('∂E/∂zk', '∂e/∂zk'), ('.', '.')]

>> Lemmatization: 
 [('Once', 'Once'), ('∂E/∂zk', '∂E/∂zk'), ('known', 'known'), (',', ','), ('error-derivative', 'error-derivative'), ('weight', 'weight'), ('wjk', 'wjk'), ('connection', 'connection'), ('unit', 'unit'), ('j', 'j'), ('layer', 'layer'), ('yj', 'yj'), ('∂E/∂zk', '∂E/∂zk'), ('.', '.')]



========================================== PARAGRAPH 23 ===========================================

Input (2) 

------------------- Sentence 1 -------------------

Input (2)

>> Tokens are: 
 ['Input', '(', '2', ')']

>> Bigrams are: 
 [('Input', '('), ('(', '2'), ('2', ')')]

>> Trigrams are: 
 [('Input', '(', '2'), ('(', '2', ')')]

>> POS Tags are: 
 [('Input', 'NNP'), ('(', '('), ('2', 'CD'), (')', ')')]

>> Noun Phrases are: 
 ['Input']

>> Named Entities are: 
 [('GPE', 'Input')] 

>> Stemming using Porter Stemmer: 
 [('Input', 'input'), ('(', '('), ('2', '2'), (')', ')')]

>> Stemming using Snowball Stemmer: 
 [('Input', 'input'), ('(', '('), ('2', '2'), (')', ')')]

>> Lemmatization: 
 [('Input', 'Input'), ('(', '('), ('2', '2'), (')', ')')]



========================================== PARAGRAPH 24 ===========================================

Output (1 sigmoid) 

------------------- Sentence 1 -------------------

Output (1 sigmoid)

>> Tokens are: 
 ['Output', '(', '1', 'sigmoid', ')']

>> Bigrams are: 
 [('Output', '('), ('(', '1'), ('1', 'sigmoid'), ('sigmoid', ')')]

>> Trigrams are: 
 [('Output', '(', '1'), ('(', '1', 'sigmoid'), ('1', 'sigmoid', ')')]

>> POS Tags are: 
 [('Output', 'NNP'), ('(', '('), ('1', 'CD'), ('sigmoid', 'NN'), (')', ')')]

>> Noun Phrases are: 
 ['Output', 'sigmoid']

>> Named Entities are: 
 [('GPE', 'Output')] 

>> Stemming using Porter Stemmer: 
 [('Output', 'output'), ('(', '('), ('1', '1'), ('sigmoid', 'sigmoid'), (')', ')')]

>> Stemming using Snowball Stemmer: 
 [('Output', 'output'), ('(', '('), ('1', '1'), ('sigmoid', 'sigmoid'), (')', ')')]

>> Lemmatization: 
 [('Output', 'Output'), ('(', '('), ('1', '1'), ('sigmoid', 'sigmoid'), (')', ')')]



========================================== PARAGRAPH 25 ===========================================

Hidden (2 sigmoid) 

------------------- Sentence 1 -------------------

Hidden (2 sigmoid)

>> Tokens are: 
 ['Hidden', '(', '2', 'sigmoid', ')']

>> Bigrams are: 
 [('Hidden', '('), ('(', '2'), ('2', 'sigmoid'), ('sigmoid', ')')]

>> Trigrams are: 
 [('Hidden', '(', '2'), ('(', '2', 'sigmoid'), ('2', 'sigmoid', ')')]

>> POS Tags are: 
 [('Hidden', 'NNP'), ('(', '('), ('2', 'CD'), ('sigmoid', 'NN'), (')', ')')]

>> Noun Phrases are: 
 ['Hidden', 'sigmoid']

>> Named Entities are: 
 [('GPE', 'Hidden')] 

>> Stemming using Porter Stemmer: 
 [('Hidden', 'hidden'), ('(', '('), ('2', '2'), ('sigmoid', 'sigmoid'), (')', ')')]

>> Stemming using Snowball Stemmer: 
 [('Hidden', 'hidden'), ('(', '('), ('2', '2'), ('sigmoid', 'sigmoid'), (')', ')')]

>> Lemmatization: 
 [('Hidden', 'Hidden'), ('(', '('), ('2', '2'), ('sigmoid', 'sigmoid'), (')', ')')]



========================================== PARAGRAPH 26 ===========================================

a b 

------------------- Sentence 1 -------------------

a b

>> Tokens are: 
 ['b']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('b', 'NN')]

>> Noun Phrases are: 
 ['b']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('b', 'b')]

>> Stemming using Snowball Stemmer: 
 [('b', 'b')]

>> Lemmatization: 
 [('b', 'b')]



========================================== PARAGRAPH 27 ===========================================

dc 

------------------- Sentence 1 -------------------

dc

>> Tokens are: 
 ['dc']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('dc', 'NN')]

>> Noun Phrases are: 
 ['dc']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('dc', 'dc')]

>> Stemming using Snowball Stemmer: 
 [('dc', 'dc')]

>> Lemmatization: 
 [('dc', 'dc')]



========================================== PARAGRAPH 28 ===========================================

y y 

------------------- Sentence 1 -------------------

y y

>> Tokens are: 
 []

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 []

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 []

>> Stemming using Snowball Stemmer: 
 []

>> Lemmatization: 
 []



========================================== PARAGRAPH 29 ===========================================

x y x 

------------------- Sentence 1 -------------------

x y x

>> Tokens are: 
 ['x', 'x\uf0b6']

>> Bigrams are: 
 [('x', 'x\uf0b6')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('x', 'NN'), ('x\uf0b6', 'NN')]

>> Noun Phrases are: 
 ['x x\uf0b6']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('x', 'x'), ('x\uf0b6', 'x\uf0b6')]

>> Stemming using Snowball Stemmer: 
 [('x', 'x'), ('x\uf0b6', 'x\uf0b6')]

>> Lemmatization: 
 [('x', 'x'), ('x\uf0b6', 'x\uf0b6')]



========================================== PARAGRAPH 30 ===========================================

=y z 

------------------- Sentence 1 -------------------

=y z

>> Tokens are: 
 ['\uf0b6=y', 'z']

>> Bigrams are: 
 [('\uf0b6=y', 'z')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('\uf0b6=y', 'NNS'), ('z', 'NN')]

>> Noun Phrases are: 
 ['\uf0b6=y z']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('\uf0b6=y', '\uf0b6=i'), ('z', 'z')]

>> Stemming using Snowball Stemmer: 
 [('\uf0b6=y', '\uf0b6=i'), ('z', 'z')]

>> Lemmatization: 
 [('\uf0b6=y', '\uf0b6=y'), ('z', 'z')]



========================================== PARAGRAPH 31 ===========================================

  

------------------- Sentence 1 -------------------

 

>> Tokens are: 
 ['\uf0b6', '\uf0b6']

>> Bigrams are: 
 [('\uf0b6', '\uf0b6')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('\uf0b6', 'NN'), ('\uf0b6', 'NN')]

>> Noun Phrases are: 
 ['\uf0b6 \uf0b6']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('\uf0b6', '\uf0b6'), ('\uf0b6', '\uf0b6')]

>> Stemming using Snowball Stemmer: 
 [('\uf0b6', '\uf0b6'), ('\uf0b6', '\uf0b6')]

>> Lemmatization: 
 [('\uf0b6', '\uf0b6'), ('\uf0b6', '\uf0b6')]



========================================== PARAGRAPH 32 ===========================================

x y 

------------------- Sentence 1 -------------------

x y

>> Tokens are: 
 ['x']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('x', 'NN')]

>> Noun Phrases are: 
 ['x']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('x', 'x')]

>> Stemming using Snowball Stemmer: 
 [('x', 'x')]

>> Lemmatization: 
 [('x', 'x')]



========================================== PARAGRAPH 33 ===========================================

  

------------------- Sentence 1 -------------------

 

>> Tokens are: 
 ['\uf0b6', '\uf0b6']

>> Bigrams are: 
 [('\uf0b6', '\uf0b6')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('\uf0b6', 'NN'), ('\uf0b6', 'NN')]

>> Noun Phrases are: 
 ['\uf0b6 \uf0b6']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('\uf0b6', '\uf0b6'), ('\uf0b6', '\uf0b6')]

>> Stemming using Snowball Stemmer: 
 [('\uf0b6', '\uf0b6'), ('\uf0b6', '\uf0b6')]

>> Lemmatization: 
 [('\uf0b6', '\uf0b6'), ('\uf0b6', '\uf0b6')]



========================================== PARAGRAPH 34 ===========================================

z y zz y 

------------------- Sentence 1 -------------------

z y zz y

>> Tokens are: 
 ['z', 'zz', 'y\uf0b6']

>> Bigrams are: 
 [('z', 'zz'), ('zz', 'y\uf0b6')]

>> Trigrams are: 
 [('z', 'zz', 'y\uf0b6')]

>> POS Tags are: 
 [('z', 'NN'), ('zz', 'CD'), ('y\uf0b6', 'NN')]

>> Noun Phrases are: 
 ['z', 'y\uf0b6']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('z', 'z'), ('zz', 'zz'), ('y\uf0b6', 'y\uf0b6')]

>> Stemming using Snowball Stemmer: 
 [('z', 'z'), ('zz', 'zz'), ('y\uf0b6', 'y\uf0b6')]

>> Lemmatization: 
 [('z', 'z'), ('zz', 'zz'), ('y\uf0b6', 'y\uf0b6')]



========================================== PARAGRAPH 35 ===========================================

=Δ Δ 

------------------- Sentence 1 -------------------

=Δ Δ

>> Tokens are: 
 ['\uf0b6=Δ', 'Δ']

>> Bigrams are: 
 [('\uf0b6=Δ', 'Δ')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('\uf0b6=Δ', 'NN'), ('Δ', 'NN')]

>> Noun Phrases are: 
 ['\uf0b6=Δ Δ']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('\uf0b6=Δ', '\uf0b6=δ'), ('Δ', 'δ')]

>> Stemming using Snowball Stemmer: 
 [('\uf0b6=Δ', '\uf0b6=δ'), ('Δ', 'δ')]

>> Lemmatization: 
 [('\uf0b6=Δ', '\uf0b6=Δ'), ('Δ', 'Δ')]



========================================== PARAGRAPH 36 ===========================================

Δ Δ 

------------------- Sentence 1 -------------------

Δ Δ

>> Tokens are: 
 ['Δ', 'Δ']

>> Bigrams are: 
 [('Δ', 'Δ')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Δ', 'NN'), ('Δ', 'NN')]

>> Noun Phrases are: 
 ['Δ Δ']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Δ', 'δ'), ('Δ', 'δ')]

>> Stemming using Snowball Stemmer: 
 [('Δ', 'δ'), ('Δ', 'δ')]

>> Lemmatization: 
 [('Δ', 'Δ'), ('Δ', 'Δ')]



========================================== PARAGRAPH 37 ===========================================

Δ Δz y z 

------------------- Sentence 1 -------------------

Δ Δz y z

>> Tokens are: 
 ['Δ', 'Δz', 'z']

>> Bigrams are: 
 [('Δ', 'Δz'), ('Δz', 'z')]

>> Trigrams are: 
 [('Δ', 'Δz', 'z')]

>> POS Tags are: 
 [('Δ', 'NN'), ('Δz', 'NNP'), ('z', 'NN')]

>> Noun Phrases are: 
 ['Δ Δz z']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Δ', 'δ'), ('Δz', 'δz'), ('z', 'z')]

>> Stemming using Snowball Stemmer: 
 [('Δ', 'δ'), ('Δz', 'δz'), ('z', 'z')]

>> Lemmatization: 
 [('Δ', 'Δ'), ('Δz', 'Δz'), ('z', 'z')]



========================================== PARAGRAPH 38 ===========================================

x y x 

------------------- Sentence 1 -------------------

x y x

>> Tokens are: 
 ['x', 'x\uf0b6']

>> Bigrams are: 
 [('x', 'x\uf0b6')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('x', 'NN'), ('x\uf0b6', 'NN')]

>> Noun Phrases are: 
 ['x x\uf0b6']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('x', 'x'), ('x\uf0b6', 'x\uf0b6')]

>> Stemming using Snowball Stemmer: 
 [('x', 'x'), ('x\uf0b6', 'x\uf0b6')]

>> Lemmatization: 
 [('x', 'x'), ('x\uf0b6', 'x\uf0b6')]



========================================== PARAGRAPH 39 ===========================================

  = 

------------------- Sentence 1 -------------------

  =

>> Tokens are: 
 ['\uf0b6', '\uf0b6', '\uf0b6=']

>> Bigrams are: 
 [('\uf0b6', '\uf0b6'), ('\uf0b6', '\uf0b6=')]

>> Trigrams are: 
 [('\uf0b6', '\uf0b6', '\uf0b6=')]

>> POS Tags are: 
 [('\uf0b6', 'JJ'), ('\uf0b6', 'NNP'), ('\uf0b6=', 'NN')]

>> Noun Phrases are: 
 ['\uf0b6 \uf0b6 \uf0b6=']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('\uf0b6', '\uf0b6'), ('\uf0b6', '\uf0b6'), ('\uf0b6=', '\uf0b6=')]

>> Stemming using Snowball Stemmer: 
 [('\uf0b6', '\uf0b6'), ('\uf0b6', '\uf0b6'), ('\uf0b6=', '\uf0b6=')]

>> Lemmatization: 
 [('\uf0b6', '\uf0b6'), ('\uf0b6', '\uf0b6'), ('\uf0b6=', '\uf0b6=')]



========================================== PARAGRAPH 40 ===========================================

x z 

------------------- Sentence 1 -------------------

x z

>> Tokens are: 
 ['x', 'z']

>> Bigrams are: 
 [('x', 'z')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('x', 'NNS'), ('z', 'NN')]

>> Noun Phrases are: 
 ['x z']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('x', 'x'), ('z', 'z')]

>> Stemming using Snowball Stemmer: 
 [('x', 'x'), ('z', 'z')]

>> Lemmatization: 
 [('x', 'x'), ('z', 'z')]



========================================== PARAGRAPH 41 ===========================================

y z 

------------------- Sentence 1 -------------------

y z

>> Tokens are: 
 ['z']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('z', 'NN')]

>> Noun Phrases are: 
 ['z']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('z', 'z')]

>> Stemming using Snowball Stemmer: 
 [('z', 'z')]

>> Lemmatization: 
 [('z', 'z')]



========================================== PARAGRAPH 42 ===========================================

xx y 

------------------- Sentence 1 -------------------

xx y

>> Tokens are: 
 ['xx']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('xx', 'NN')]

>> Noun Phrases are: 
 ['xx']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('xx', 'xx')]

>> Stemming using Snowball Stemmer: 
 [('xx', 'xx')]

>> Lemmatization: 
 [('xx', 'xx')]



========================================== PARAGRAPH 43 ===========================================

  

------------------- Sentence 1 -------------------

 

>> Tokens are: 
 ['\uf0b6', '\uf0b6']

>> Bigrams are: 
 [('\uf0b6', '\uf0b6')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('\uf0b6', 'NN'), ('\uf0b6', 'NN')]

>> Noun Phrases are: 
 ['\uf0b6 \uf0b6']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('\uf0b6', '\uf0b6'), ('\uf0b6', '\uf0b6')]

>> Stemming using Snowball Stemmer: 
 [('\uf0b6', '\uf0b6'), ('\uf0b6', '\uf0b6')]

>> Lemmatization: 
 [('\uf0b6', '\uf0b6'), ('\uf0b6', '\uf0b6')]



========================================== PARAGRAPH 44 ===========================================

  

------------------- Sentence 1 -------------------

 

>> Tokens are: 
 ['\uf0b6', '\uf0b6']

>> Bigrams are: 
 [('\uf0b6', '\uf0b6')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('\uf0b6', 'NN'), ('\uf0b6', 'NN')]

>> Noun Phrases are: 
 ['\uf0b6 \uf0b6']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('\uf0b6', '\uf0b6'), ('\uf0b6', '\uf0b6')]

>> Stemming using Snowball Stemmer: 
 [('\uf0b6', '\uf0b6'), ('\uf0b6', '\uf0b6')]

>> Lemmatization: 
 [('\uf0b6', '\uf0b6'), ('\uf0b6', '\uf0b6')]



========================================== PARAGRAPH 45 ===========================================

 = 

------------------- Sentence 1 -------------------

 =

>> Tokens are: 
 ['\uf0b6', '\uf0b6=']

>> Bigrams are: 
 [('\uf0b6', '\uf0b6=')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('\uf0b6', 'NN'), ('\uf0b6=', 'NN')]

>> Noun Phrases are: 
 ['\uf0b6 \uf0b6=']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('\uf0b6', '\uf0b6'), ('\uf0b6=', '\uf0b6=')]

>> Stemming using Snowball Stemmer: 
 [('\uf0b6', '\uf0b6'), ('\uf0b6=', '\uf0b6=')]

>> Lemmatization: 
 [('\uf0b6', '\uf0b6'), ('\uf0b6=', '\uf0b6=')]



========================================== PARAGRAPH 46 ===========================================

Compare outputs with correct  answer to get error derivatives 

------------------- Sentence 1 -------------------

Compare outputs with correct  answer to get error derivatives

>> Tokens are: 
 ['Compare', 'outputs', 'correct', 'answer', 'get', 'error', 'derivatives']

>> Bigrams are: 
 [('Compare', 'outputs'), ('outputs', 'correct'), ('correct', 'answer'), ('answer', 'get'), ('get', 'error'), ('error', 'derivatives')]

>> Trigrams are: 
 [('Compare', 'outputs', 'correct'), ('outputs', 'correct', 'answer'), ('correct', 'answer', 'get'), ('answer', 'get', 'error'), ('get', 'error', 'derivatives')]

>> POS Tags are: 
 [('Compare', 'NNP'), ('outputs', 'VBZ'), ('correct', 'JJ'), ('answer', 'NN'), ('get', 'VB'), ('error', 'NN'), ('derivatives', 'NNS')]

>> Noun Phrases are: 
 ['Compare', 'correct answer', 'error derivatives']

>> Named Entities are: 
 [('ORGANIZATION', 'Compare')] 

>> Stemming using Porter Stemmer: 
 [('Compare', 'compar'), ('outputs', 'output'), ('correct', 'correct'), ('answer', 'answer'), ('get', 'get'), ('error', 'error'), ('derivatives', 'deriv')]

>> Stemming using Snowball Stemmer: 
 [('Compare', 'compar'), ('outputs', 'output'), ('correct', 'correct'), ('answer', 'answer'), ('get', 'get'), ('error', 'error'), ('derivatives', 'deriv')]

>> Lemmatization: 
 [('Compare', 'Compare'), ('outputs', 'output'), ('correct', 'correct'), ('answer', 'answer'), ('get', 'get'), ('error', 'error'), ('derivatives', 'derivative')]



========================================== PARAGRAPH 47 ===========================================

j 

------------------- Sentence 1 -------------------

j

>> Tokens are: 
 ['j']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('j', 'NN')]

>> Noun Phrases are: 
 ['j']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('j', 'j')]

>> Stemming using Snowball Stemmer: 
 [('j', 'j')]

>> Lemmatization: 
 [('j', 'j')]



========================================== PARAGRAPH 48 ===========================================

k 

------------------- Sentence 1 -------------------

k

>> Tokens are: 
 ['k']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('k', 'NN')]

>> Noun Phrases are: 
 ['k']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('k', 'k')]

>> Stemming using Snowball Stemmer: 
 [('k', 'k')]

>> Lemmatization: 
 [('k', 'k')]



========================================== PARAGRAPH 49 ===========================================

E yl 

------------------- Sentence 1 -------------------

E yl

>> Tokens are: 
 ['E', 'yl']

>> Bigrams are: 
 [('E', 'yl')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('E', 'NN'), ('yl', 'NN')]

>> Noun Phrases are: 
 ['E yl']

>> Named Entities are: 
 [('GPE', 'E')] 

>> Stemming using Porter Stemmer: 
 [('E', 'e'), ('yl', 'yl')]

>> Stemming using Snowball Stemmer: 
 [('E', 'e'), ('yl', 'yl')]

>> Lemmatization: 
 [('E', 'E'), ('yl', 'yl')]



========================================== PARAGRAPH 50 ===========================================

=yl tl 

------------------- Sentence 1 -------------------

=yl tl

>> Tokens are: 
 ['=yl', 'tl']

>> Bigrams are: 
 [('=yl', 'tl')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('=yl', 'NN'), ('tl', 'NN')]

>> Noun Phrases are: 
 ['=yl tl']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('=yl', '=yl'), ('tl', 'tl')]

>> Stemming using Snowball Stemmer: 
 [('=yl', '=yl'), ('tl', 'tl')]

>> Lemmatization: 
 [('=yl', '=yl'), ('tl', 'tl')]



========================================== PARAGRAPH 51 ===========================================

E zl 

------------------- Sentence 1 -------------------

E zl

>> Tokens are: 
 ['E', 'zl']

>> Bigrams are: 
 [('E', 'zl')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('E', 'NN'), ('zl', 'NN')]

>> Noun Phrases are: 
 ['E zl']

>> Named Entities are: 
 [('GPE', 'E')] 

>> Stemming using Porter Stemmer: 
 [('E', 'e'), ('zl', 'zl')]

>> Stemming using Snowball Stemmer: 
 [('E', 'e'), ('zl', 'zl')]

>> Lemmatization: 
 [('E', 'E'), ('zl', 'zl')]



========================================== PARAGRAPH 52 ===========================================

= E yl 

------------------- Sentence 1 -------------------

= E yl

>> Tokens are: 
 ['=', 'E', 'yl']

>> Bigrams are: 
 [('=', 'E'), ('E', 'yl')]

>> Trigrams are: 
 [('=', 'E', 'yl')]

>> POS Tags are: 
 [('=', 'JJ'), ('E', 'NNP'), ('yl', 'NN')]

>> Noun Phrases are: 
 ['= E yl']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('=', '='), ('E', 'e'), ('yl', 'yl')]

>> Stemming using Snowball Stemmer: 
 [('=', '='), ('E', 'e'), ('yl', 'yl')]

>> Lemmatization: 
 [('=', '='), ('E', 'E'), ('yl', 'yl')]



========================================== PARAGRAPH 53 ===========================================

yl zl 

------------------- Sentence 1 -------------------

yl zl

>> Tokens are: 
 ['yl', 'zl']

>> Bigrams are: 
 [('yl', 'zl')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('yl', 'NN'), ('zl', 'NN')]

>> Noun Phrases are: 
 ['yl zl']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('yl', 'yl'), ('zl', 'zl')]

>> Stemming using Snowball Stemmer: 
 [('yl', 'yl'), ('zl', 'zl')]

>> Lemmatization: 
 [('yl', 'yl'), ('zl', 'zl')]



========================================== PARAGRAPH 54 ===========================================

l 

------------------- Sentence 1 -------------------

l

>> Tokens are: 
 ['l']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('l', 'NN')]

>> Noun Phrases are: 
 ['l']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('l', 'l')]

>> Stemming using Snowball Stemmer: 
 [('l', 'l')]

>> Lemmatization: 
 [('l', 'l')]



========================================== PARAGRAPH 55 ===========================================

E yj 

------------------- Sentence 1 -------------------

E yj

>> Tokens are: 
 ['E', 'yj']

>> Bigrams are: 
 [('E', 'yj')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('E', 'NN'), ('yj', 'NN')]

>> Noun Phrases are: 
 ['E yj']

>> Named Entities are: 
 [('GPE', 'E')] 

>> Stemming using Porter Stemmer: 
 [('E', 'e'), ('yj', 'yj')]

>> Stemming using Snowball Stemmer: 
 [('E', 'e'), ('yj', 'yj')]

>> Lemmatization: 
 [('E', 'E'), ('yj', 'yj')]



========================================== PARAGRAPH 56 ===========================================

= wjk E zk 

------------------- Sentence 1 -------------------

= wjk E zk

>> Tokens are: 
 ['=', 'wjk', 'E', 'zk']

>> Bigrams are: 
 [('=', 'wjk'), ('wjk', 'E'), ('E', 'zk')]

>> Trigrams are: 
 [('=', 'wjk', 'E'), ('wjk', 'E', 'zk')]

>> POS Tags are: 
 [('=', 'JJ'), ('wjk', 'NN'), ('E', 'NNP'), ('zk', 'NN')]

>> Noun Phrases are: 
 ['= wjk E zk']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('=', '='), ('wjk', 'wjk'), ('E', 'e'), ('zk', 'zk')]

>> Stemming using Snowball Stemmer: 
 [('=', '='), ('wjk', 'wjk'), ('E', 'e'), ('zk', 'zk')]

>> Lemmatization: 
 [('=', '='), ('wjk', 'wjk'), ('E', 'E'), ('zk', 'zk')]



========================================== PARAGRAPH 57 ===========================================

E zj 

------------------- Sentence 1 -------------------

E zj

>> Tokens are: 
 ['E', 'zj']

>> Bigrams are: 
 [('E', 'zj')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('E', 'NN'), ('zj', 'NN')]

>> Noun Phrases are: 
 ['E zj']

>> Named Entities are: 
 [('GPE', 'E')] 

>> Stemming using Porter Stemmer: 
 [('E', 'e'), ('zj', 'zj')]

>> Stemming using Snowball Stemmer: 
 [('E', 'e'), ('zj', 'zj')]

>> Lemmatization: 
 [('E', 'E'), ('zj', 'zj')]



========================================== PARAGRAPH 58 ===========================================

= E yj 

------------------- Sentence 1 -------------------

= E yj

>> Tokens are: 
 ['=', 'E', 'yj']

>> Bigrams are: 
 [('=', 'E'), ('E', 'yj')]

>> Trigrams are: 
 [('=', 'E', 'yj')]

>> POS Tags are: 
 [('=', 'JJ'), ('E', 'NNP'), ('yj', 'NN')]

>> Noun Phrases are: 
 ['= E yj']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('=', '='), ('E', 'e'), ('yj', 'yj')]

>> Stemming using Snowball Stemmer: 
 [('=', '='), ('E', 'e'), ('yj', 'yj')]

>> Lemmatization: 
 [('=', '='), ('E', 'E'), ('yj', 'yj')]



========================================== PARAGRAPH 59 ===========================================

yj zj 

------------------- Sentence 1 -------------------

yj zj

>> Tokens are: 
 ['yj', 'zj']

>> Bigrams are: 
 [('yj', 'zj')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('yj', 'NN'), ('zj', 'NN')]

>> Noun Phrases are: 
 ['yj zj']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('yj', 'yj'), ('zj', 'zj')]

>> Stemming using Snowball Stemmer: 
 [('yj', 'yj'), ('zj', 'zj')]

>> Lemmatization: 
 [('yj', 'yj'), ('zj', 'zj')]



========================================== PARAGRAPH 60 ===========================================

E yk 

------------------- Sentence 1 -------------------

E yk

>> Tokens are: 
 ['E', 'yk']

>> Bigrams are: 
 [('E', 'yk')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('E', 'NN'), ('yk', 'NN')]

>> Noun Phrases are: 
 ['E yk']

>> Named Entities are: 
 [('GPE', 'E')] 

>> Stemming using Porter Stemmer: 
 [('E', 'e'), ('yk', 'yk')]

>> Stemming using Snowball Stemmer: 
 [('E', 'e'), ('yk', 'yk')]

>> Lemmatization: 
 [('E', 'E'), ('yk', 'yk')]



========================================== PARAGRAPH 61 ===========================================

= wkl E zl 

------------------- Sentence 1 -------------------

= wkl E zl

>> Tokens are: 
 ['=', 'wkl', 'E', 'zl']

>> Bigrams are: 
 [('=', 'wkl'), ('wkl', 'E'), ('E', 'zl')]

>> Trigrams are: 
 [('=', 'wkl', 'E'), ('wkl', 'E', 'zl')]

>> POS Tags are: 
 [('=', 'JJ'), ('wkl', 'NN'), ('E', 'NNP'), ('zl', 'NN')]

>> Noun Phrases are: 
 ['= wkl E zl']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('=', '='), ('wkl', 'wkl'), ('E', 'e'), ('zl', 'zl')]

>> Stemming using Snowball Stemmer: 
 [('=', '='), ('wkl', 'wkl'), ('E', 'e'), ('zl', 'zl')]

>> Lemmatization: 
 [('=', '='), ('wkl', 'wkl'), ('E', 'E'), ('zl', 'zl')]



========================================== PARAGRAPH 62 ===========================================

E zk 

------------------- Sentence 1 -------------------

E zk

>> Tokens are: 
 ['E', 'zk']

>> Bigrams are: 
 [('E', 'zk')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('E', 'NN'), ('zk', 'NN')]

>> Noun Phrases are: 
 ['E zk']

>> Named Entities are: 
 [('GPE', 'E')] 

>> Stemming using Porter Stemmer: 
 [('E', 'e'), ('zk', 'zk')]

>> Stemming using Snowball Stemmer: 
 [('E', 'e'), ('zk', 'zk')]

>> Lemmatization: 
 [('E', 'E'), ('zk', 'zk')]



========================================== PARAGRAPH 63 ===========================================

= E yk 

------------------- Sentence 1 -------------------

= E yk

>> Tokens are: 
 ['=', 'E', 'yk']

>> Bigrams are: 
 [('=', 'E'), ('E', 'yk')]

>> Trigrams are: 
 [('=', 'E', 'yk')]

>> POS Tags are: 
 [('=', 'JJ'), ('E', 'NNP'), ('yk', 'NN')]

>> Noun Phrases are: 
 ['= E yk']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('=', '='), ('E', 'e'), ('yk', 'yk')]

>> Stemming using Snowball Stemmer: 
 [('=', '='), ('E', 'e'), ('yk', 'yk')]

>> Lemmatization: 
 [('=', '='), ('E', 'E'), ('yk', 'yk')]



========================================== PARAGRAPH 64 ===========================================

yk zk 

------------------- Sentence 1 -------------------

yk zk

>> Tokens are: 
 ['yk', 'zk']

>> Bigrams are: 
 [('yk', 'zk')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('yk', 'NN'), ('zk', 'NN')]

>> Noun Phrases are: 
 ['yk zk']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('yk', 'yk'), ('zk', 'zk')]

>> Stemming using Snowball Stemmer: 
 [('yk', 'yk'), ('zk', 'zk')]

>> Lemmatization: 
 [('yk', 'yk'), ('zk', 'zk')]



========================================== PARAGRAPH 65 ===========================================

wkl 

------------------- Sentence 1 -------------------

wkl

>> Tokens are: 
 ['wkl']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('wkl', 'NN')]

>> Noun Phrases are: 
 ['wkl']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('wkl', 'wkl')]

>> Stemming using Snowball Stemmer: 
 [('wkl', 'wkl')]

>> Lemmatization: 
 [('wkl', 'wkl')]



========================================== PARAGRAPH 66 ===========================================

wjk 

------------------- Sentence 1 -------------------

wjk

>> Tokens are: 
 ['wjk']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('wjk', 'NN')]

>> Noun Phrases are: 
 ['wjk']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('wjk', 'wjk')]

>> Stemming using Snowball Stemmer: 
 [('wjk', 'wjk')]

>> Lemmatization: 
 [('wjk', 'wjk')]



========================================== PARAGRAPH 67 ===========================================

wij 

------------------- Sentence 1 -------------------

wij

>> Tokens are: 
 ['wij']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('wij', 'NN')]

>> Noun Phrases are: 
 ['wij']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('wij', 'wij')]

>> Stemming using Snowball Stemmer: 
 [('wij', 'wij')]

>> Lemmatization: 
 [('wij', 'wij')]



========================================== PARAGRAPH 68 ===========================================

i 

------------------- Sentence 1 -------------------

i

>> Tokens are: 
 []

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 []

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 []

>> Stemming using Snowball Stemmer: 
 []

>> Lemmatization: 
 []



========================================== PARAGRAPH 69 ===========================================

j 

------------------- Sentence 1 -------------------

j

>> Tokens are: 
 ['j']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('j', 'NN')]

>> Noun Phrases are: 
 ['j']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('j', 'j')]

>> Stemming using Snowball Stemmer: 
 [('j', 'j')]

>> Lemmatization: 
 [('j', 'j')]



========================================== PARAGRAPH 70 ===========================================

k 

------------------- Sentence 1 -------------------

k

>> Tokens are: 
 ['k']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('k', 'NN')]

>> Noun Phrases are: 
 ['k']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('k', 'k')]

>> Stemming using Snowball Stemmer: 
 [('k', 'k')]

>> Lemmatization: 
 [('k', 'k')]



========================================== PARAGRAPH 71 ===========================================

yl = f (zl ) 

------------------- Sentence 1 -------------------

yl = f (zl )

>> Tokens are: 
 ['yl', '=', 'f', '(', 'zl', ')']

>> Bigrams are: 
 [('yl', '='), ('=', 'f'), ('f', '('), ('(', 'zl'), ('zl', ')')]

>> Trigrams are: 
 [('yl', '=', 'f'), ('=', 'f', '('), ('f', '(', 'zl'), ('(', 'zl', ')')]

>> POS Tags are: 
 [('yl', 'NN'), ('=', 'NN'), ('f', 'NN'), ('(', '('), ('zl', 'NN'), (')', ')')]

>> Noun Phrases are: 
 ['yl = f', 'zl']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('yl', 'yl'), ('=', '='), ('f', 'f'), ('(', '('), ('zl', 'zl'), (')', ')')]

>> Stemming using Snowball Stemmer: 
 [('yl', 'yl'), ('=', '='), ('f', 'f'), ('(', '('), ('zl', 'zl'), (')', ')')]

>> Lemmatization: 
 [('yl', 'yl'), ('=', '='), ('f', 'f'), ('(', '('), ('zl', 'zl'), (')', ')')]



========================================== PARAGRAPH 72 ===========================================

zl = wkl yk l 

------------------- Sentence 1 -------------------

zl = wkl yk l

>> Tokens are: 
 ['zl', '=', 'wkl', 'yk', 'l']

>> Bigrams are: 
 [('zl', '='), ('=', 'wkl'), ('wkl', 'yk'), ('yk', 'l')]

>> Trigrams are: 
 [('zl', '=', 'wkl'), ('=', 'wkl', 'yk'), ('wkl', 'yk', 'l')]

>> POS Tags are: 
 [('zl', 'NN'), ('=', 'NNP'), ('wkl', 'NN'), ('yk', 'NN'), ('l', 'NN')]

>> Noun Phrases are: 
 ['zl = wkl yk l']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('zl', 'zl'), ('=', '='), ('wkl', 'wkl'), ('yk', 'yk'), ('l', 'l')]

>> Stemming using Snowball Stemmer: 
 [('zl', 'zl'), ('=', '='), ('wkl', 'wkl'), ('yk', 'yk'), ('l', 'l')]

>> Lemmatization: 
 [('zl', 'zl'), ('=', '='), ('wkl', 'wkl'), ('yk', 'yk'), ('l', 'l')]



========================================== PARAGRAPH 73 ===========================================

yj = f (zj ) 

------------------- Sentence 1 -------------------

yj = f (zj )

>> Tokens are: 
 ['yj', '=', 'f', '(', 'zj', ')']

>> Bigrams are: 
 [('yj', '='), ('=', 'f'), ('f', '('), ('(', 'zj'), ('zj', ')')]

>> Trigrams are: 
 [('yj', '=', 'f'), ('=', 'f', '('), ('f', '(', 'zj'), ('(', 'zj', ')')]

>> POS Tags are: 
 [('yj', 'NN'), ('=', 'NN'), ('f', 'NN'), ('(', '('), ('zj', 'NN'), (')', ')')]

>> Noun Phrases are: 
 ['yj = f', 'zj']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('yj', 'yj'), ('=', '='), ('f', 'f'), ('(', '('), ('zj', 'zj'), (')', ')')]

>> Stemming using Snowball Stemmer: 
 [('yj', 'yj'), ('=', '='), ('f', 'f'), ('(', '('), ('zj', 'zj'), (')', ')')]

>> Lemmatization: 
 [('yj', 'yj'), ('=', '='), ('f', 'f'), ('(', '('), ('zj', 'zj'), (')', ')')]



========================================== PARAGRAPH 74 ===========================================

zj = wij xi 

------------------- Sentence 1 -------------------

zj = wij xi

>> Tokens are: 
 ['zj', '=', 'wij', 'xi']

>> Bigrams are: 
 [('zj', '='), ('=', 'wij'), ('wij', 'xi')]

>> Trigrams are: 
 [('zj', '=', 'wij'), ('=', 'wij', 'xi')]

>> POS Tags are: 
 [('zj', 'NN'), ('=', 'NNP'), ('wij', 'NN'), ('xi', 'NN')]

>> Noun Phrases are: 
 ['zj = wij xi']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('zj', 'zj'), ('=', '='), ('wij', 'wij'), ('xi', 'xi')]

>> Stemming using Snowball Stemmer: 
 [('zj', 'zj'), ('=', '='), ('wij', 'wij'), ('xi', 'xi')]

>> Lemmatization: 
 [('zj', 'zj'), ('=', '='), ('wij', 'wij'), ('xi', 'xi')]



========================================== PARAGRAPH 75 ===========================================

yk = f (zk ) 

------------------- Sentence 1 -------------------

yk = f (zk )

>> Tokens are: 
 ['yk', '=', 'f', '(', 'zk', ')']

>> Bigrams are: 
 [('yk', '='), ('=', 'f'), ('f', '('), ('(', 'zk'), ('zk', ')')]

>> Trigrams are: 
 [('yk', '=', 'f'), ('=', 'f', '('), ('f', '(', 'zk'), ('(', 'zk', ')')]

>> POS Tags are: 
 [('yk', 'NN'), ('=', 'NN'), ('f', 'NN'), ('(', '('), ('zk', 'NN'), (')', ')')]

>> Noun Phrases are: 
 ['yk = f', 'zk']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('yk', 'yk'), ('=', '='), ('f', 'f'), ('(', '('), ('zk', 'zk'), (')', ')')]

>> Stemming using Snowball Stemmer: 
 [('yk', 'yk'), ('=', '='), ('f', 'f'), ('(', '('), ('zk', 'zk'), (')', ')')]

>> Lemmatization: 
 [('yk', 'yk'), ('=', '='), ('f', 'f'), ('(', '('), ('zk', 'zk'), (')', ')')]



========================================== PARAGRAPH 76 ===========================================

zk = wjk yj 

------------------- Sentence 1 -------------------

zk = wjk yj

>> Tokens are: 
 ['zk', '=', 'wjk', 'yj']

>> Bigrams are: 
 [('zk', '='), ('=', 'wjk'), ('wjk', 'yj')]

>> Trigrams are: 
 [('zk', '=', 'wjk'), ('=', 'wjk', 'yj')]

>> POS Tags are: 
 [('zk', 'NN'), ('=', 'NNP'), ('wjk', 'NN'), ('yj', 'NN')]

>> Noun Phrases are: 
 ['zk = wjk yj']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('zk', 'zk'), ('=', '='), ('wjk', 'wjk'), ('yj', 'yj')]

>> Stemming using Snowball Stemmer: 
 [('zk', 'zk'), ('=', '='), ('wjk', 'wjk'), ('yj', 'yj')]

>> Lemmatization: 
 [('zk', 'zk'), ('=', '='), ('wjk', 'wjk'), ('yj', 'yj')]



========================================== PARAGRAPH 77 ===========================================

Output units  

------------------- Sentence 1 -------------------

Output units

>> Tokens are: 
 ['Output', 'units']

>> Bigrams are: 
 [('Output', 'units')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Output', 'NNP'), ('units', 'NNS')]

>> Noun Phrases are: 
 ['Output units']

>> Named Entities are: 
 [('GPE', 'Output')] 

>> Stemming using Porter Stemmer: 
 [('Output', 'output'), ('units', 'unit')]

>> Stemming using Snowball Stemmer: 
 [('Output', 'output'), ('units', 'unit')]

>> Lemmatization: 
 [('Output', 'Output'), ('units', 'unit')]



========================================== PARAGRAPH 78 ===========================================

Input units  

------------------- Sentence 1 -------------------

Input units

>> Tokens are: 
 ['Input', 'units']

>> Bigrams are: 
 [('Input', 'units')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Input', 'NNP'), ('units', 'NNS')]

>> Noun Phrases are: 
 ['Input units']

>> Named Entities are: 
 [('GPE', 'Input')] 

>> Stemming using Porter Stemmer: 
 [('Input', 'input'), ('units', 'unit')]

>> Stemming using Snowball Stemmer: 
 [('Input', 'input'), ('units', 'unit')]

>> Lemmatization: 
 [('Input', 'Input'), ('units', 'unit')]



========================================== PARAGRAPH 79 ===========================================

Hidden units H2  

------------------- Sentence 1 -------------------

Hidden units H2

>> Tokens are: 
 ['Hidden', 'units', 'H2']

>> Bigrams are: 
 [('Hidden', 'units'), ('units', 'H2')]

>> Trigrams are: 
 [('Hidden', 'units', 'H2')]

>> POS Tags are: 
 [('Hidden', 'NNP'), ('units', 'NNS'), ('H2', 'NNP')]

>> Noun Phrases are: 
 ['Hidden units H2']

>> Named Entities are: 
 [('GPE', 'Hidden')] 

>> Stemming using Porter Stemmer: 
 [('Hidden', 'hidden'), ('units', 'unit'), ('H2', 'h2')]

>> Stemming using Snowball Stemmer: 
 [('Hidden', 'hidden'), ('units', 'unit'), ('H2', 'h2')]

>> Lemmatization: 
 [('Hidden', 'Hidden'), ('units', 'unit'), ('H2', 'H2')]



========================================== PARAGRAPH 80 ===========================================

Hidden units H1  

------------------- Sentence 1 -------------------

Hidden units H1

>> Tokens are: 
 ['Hidden', 'units', 'H1']

>> Bigrams are: 
 [('Hidden', 'units'), ('units', 'H1')]

>> Trigrams are: 
 [('Hidden', 'units', 'H1')]

>> POS Tags are: 
 [('Hidden', 'NNP'), ('units', 'NNS'), ('H1', 'NNP')]

>> Noun Phrases are: 
 ['Hidden units H1']

>> Named Entities are: 
 [('GPE', 'Hidden')] 

>> Stemming using Porter Stemmer: 
 [('Hidden', 'hidden'), ('units', 'unit'), ('H1', 'h1')]

>> Stemming using Snowball Stemmer: 
 [('Hidden', 'hidden'), ('units', 'unit'), ('H1', 'h1')]

>> Lemmatization: 
 [('Hidden', 'Hidden'), ('units', 'unit'), ('H1', 'H1')]



========================================== PARAGRAPH 81 ===========================================

wkl 

------------------- Sentence 1 -------------------

wkl

>> Tokens are: 
 ['wkl']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('wkl', 'NN')]

>> Noun Phrases are: 
 ['wkl']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('wkl', 'wkl')]

>> Stemming using Snowball Stemmer: 
 [('wkl', 'wkl')]

>> Lemmatization: 
 [('wkl', 'wkl')]



========================================== PARAGRAPH 82 ===========================================

wjk 

------------------- Sentence 1 -------------------

wjk

>> Tokens are: 
 ['wjk']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('wjk', 'NN')]

>> Noun Phrases are: 
 ['wjk']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('wjk', 'wjk')]

>> Stemming using Snowball Stemmer: 
 [('wjk', 'wjk')]

>> Lemmatization: 
 [('wjk', 'wjk')]



========================================== PARAGRAPH 83 ===========================================

wij 

------------------- Sentence 1 -------------------

wij

>> Tokens are: 
 ['wij']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('wij', 'NN')]

>> Noun Phrases are: 
 ['wij']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('wij', 'wij')]

>> Stemming using Snowball Stemmer: 
 [('wij', 'wij')]

>> Lemmatization: 
 [('wij', 'wij')]



========================================== PARAGRAPH 84 ===========================================

k  H2 

------------------- Sentence 1 -------------------

k  H2

>> Tokens are: 
 ['k', '\uf065', 'H2']

>> Bigrams are: 
 [('k', '\uf065'), ('\uf065', 'H2')]

>> Trigrams are: 
 [('k', '\uf065', 'H2')]

>> POS Tags are: 
 [('k', 'NN'), ('\uf065', 'NNP'), ('H2', 'NNP')]

>> Noun Phrases are: 
 ['k \uf065 H2']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('k', 'k'), ('\uf065', '\uf065'), ('H2', 'h2')]

>> Stemming using Snowball Stemmer: 
 [('k', 'k'), ('\uf065', '\uf065'), ('H2', 'h2')]

>> Lemmatization: 
 [('k', 'k'), ('\uf065', '\uf065'), ('H2', 'H2')]



========================================== PARAGRAPH 85 ===========================================

k  H2 

------------------- Sentence 1 -------------------

k  H2

>> Tokens are: 
 ['k', '\uf065', 'H2']

>> Bigrams are: 
 [('k', '\uf065'), ('\uf065', 'H2')]

>> Trigrams are: 
 [('k', '\uf065', 'H2')]

>> POS Tags are: 
 [('k', 'NN'), ('\uf065', 'NNP'), ('H2', 'NNP')]

>> Noun Phrases are: 
 ['k \uf065 H2']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('k', 'k'), ('\uf065', '\uf065'), ('H2', 'h2')]

>> Stemming using Snowball Stemmer: 
 [('k', 'k'), ('\uf065', '\uf065'), ('H2', 'h2')]

>> Lemmatization: 
 [('k', 'k'), ('\uf065', '\uf065'), ('H2', 'H2')]



========================================== PARAGRAPH 86 ===========================================

I  out 

------------------- Sentence 1 -------------------

I  out

>> Tokens are: 
 ['I', '\uf065']

>> Bigrams are: 
 [('I', '\uf065')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('I', 'PRP'), ('\uf065', 'VBP')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('I', 'i'), ('\uf065', '\uf065')]

>> Stemming using Snowball Stemmer: 
 [('I', 'i'), ('\uf065', '\uf065')]

>> Lemmatization: 
 [('I', 'I'), ('\uf065', '\uf065')]



========================================== PARAGRAPH 87 ===========================================

j  H1 

------------------- Sentence 1 -------------------

j  H1

>> Tokens are: 
 ['j', '\uf065', 'H1']

>> Bigrams are: 
 [('j', '\uf065'), ('\uf065', 'H1')]

>> Trigrams are: 
 [('j', '\uf065', 'H1')]

>> POS Tags are: 
 [('j', 'NN'), ('\uf065', 'CD'), ('H1', 'NNP')]

>> Noun Phrases are: 
 ['j', 'H1']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('j', 'j'), ('\uf065', '\uf065'), ('H1', 'h1')]

>> Stemming using Snowball Stemmer: 
 [('j', 'j'), ('\uf065', '\uf065'), ('H1', 'h1')]

>> Lemmatization: 
 [('j', 'j'), ('\uf065', '\uf065'), ('H1', 'H1')]



========================================== PARAGRAPH 88 ===========================================

i  Input 

------------------- Sentence 1 -------------------

i  Input

>> Tokens are: 
 ['\uf065', 'Input']

>> Bigrams are: 
 [('\uf065', 'Input')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('\uf065', 'NN'), ('Input', 'NNP')]

>> Noun Phrases are: 
 ['\uf065 Input']

>> Named Entities are: 
 [('PERSON', 'Input')] 

>> Stemming using Porter Stemmer: 
 [('\uf065', '\uf065'), ('Input', 'input')]

>> Stemming using Snowball Stemmer: 
 [('\uf065', '\uf065'), ('Input', 'input')]

>> Lemmatization: 
 [('\uf065', '\uf065'), ('Input', 'Input')]



========================================== PARAGRAPH 89 ===========================================

i 

------------------- Sentence 1 -------------------

i

>> Tokens are: 
 []

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 []

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 []

>> Stemming using Snowball Stemmer: 
 []

>> Lemmatization: 
 []



========================================== PARAGRAPH 90 ===========================================

2 8  M A Y  2 0 1 5  |  V O L  5 2 1  |  N A T U R E  |  4 3 7 

------------------- Sentence 1 -------------------

2 8  M A Y  2 0 1 5  |  V O L  5 2 1  |  N A T U R E  |  4 3 7

>> Tokens are: 
 ['2', '8', 'M', 'A', 'Y', '2', '0', '1', '5', '|', 'V', 'O', 'L', '5', '2', '1', '|', 'N', 'A', 'T', 'U', 'R', 'E', '|', '4', '3', '7']

>> Bigrams are: 
 [('2', '8'), ('8', 'M'), ('M', 'A'), ('A', 'Y'), ('Y', '2'), ('2', '0'), ('0', '1'), ('1', '5'), ('5', '|'), ('|', 'V'), ('V', 'O'), ('O', 'L'), ('L', '5'), ('5', '2'), ('2', '1'), ('1', '|'), ('|', 'N'), ('N', 'A'), ('A', 'T'), ('T', 'U'), ('U', 'R'), ('R', 'E'), ('E', '|'), ('|', '4'), ('4', '3'), ('3', '7')]

>> Trigrams are: 
 [('2', '8', 'M'), ('8', 'M', 'A'), ('M', 'A', 'Y'), ('A', 'Y', '2'), ('Y', '2', '0'), ('2', '0', '1'), ('0', '1', '5'), ('1', '5', '|'), ('5', '|', 'V'), ('|', 'V', 'O'), ('V', 'O', 'L'), ('O', 'L', '5'), ('L', '5', '2'), ('5', '2', '1'), ('2', '1', '|'), ('1', '|', 'N'), ('|', 'N', 'A'), ('N', 'A', 'T'), ('A', 'T', 'U'), ('T', 'U', 'R'), ('U', 'R', 'E'), ('R', 'E', '|'), ('E', '|', '4'), ('|', '4', '3'), ('4', '3', '7')]

>> POS Tags are: 
 [('2', 'CD'), ('8', 'CD'), ('M', 'NNP'), ('A', 'NNP'), ('Y', 'NNP'), ('2', 'CD'), ('0', 'CD'), ('1', 'CD'), ('5', 'CD'), ('|', 'NN'), ('V', 'NNP'), ('O', 'NNP'), ('L', 'NNP'), ('5', 'CD'), ('2', 'CD'), ('1', 'CD'), ('|', 'NN'), ('N', 'NNP'), ('A', 'NNP'), ('T', 'NNP'), ('U', 'NNP'), ('R', 'NNP'), ('E', 'NNP'), ('|', 'VBD'), ('4', 'CD'), ('3', 'CD'), ('7', 'CD')]

>> Noun Phrases are: 
 ['M A Y', '| V O L', '| N A T U R E']

>> Named Entities are: 
 [('PERSON', 'V O')] 

>> Stemming using Porter Stemmer: 
 [('2', '2'), ('8', '8'), ('M', 'm'), ('A', 'a'), ('Y', 'y'), ('2', '2'), ('0', '0'), ('1', '1'), ('5', '5'), ('|', '|'), ('V', 'v'), ('O', 'o'), ('L', 'l'), ('5', '5'), ('2', '2'), ('1', '1'), ('|', '|'), ('N', 'n'), ('A', 'a'), ('T', 't'), ('U', 'u'), ('R', 'r'), ('E', 'e'), ('|', '|'), ('4', '4'), ('3', '3'), ('7', '7')]

>> Stemming using Snowball Stemmer: 
 [('2', '2'), ('8', '8'), ('M', 'm'), ('A', 'a'), ('Y', 'y'), ('2', '2'), ('0', '0'), ('1', '1'), ('5', '5'), ('|', '|'), ('V', 'v'), ('O', 'o'), ('L', 'l'), ('5', '5'), ('2', '2'), ('1', '1'), ('|', '|'), ('N', 'n'), ('A', 'a'), ('T', 't'), ('U', 'u'), ('R', 'r'), ('E', 'e'), ('|', '|'), ('4', '4'), ('3', '3'), ('7', '7')]

>> Lemmatization: 
 [('2', '2'), ('8', '8'), ('M', 'M'), ('A', 'A'), ('Y', 'Y'), ('2', '2'), ('0', '0'), ('1', '1'), ('5', '5'), ('|', '|'), ('V', 'V'), ('O', 'O'), ('L', 'L'), ('5', '5'), ('2', '2'), ('1', '1'), ('|', '|'), ('N', 'N'), ('A', 'A'), ('T', 'T'), ('U', 'U'), ('R', 'R'), ('E', 'E'), ('|', '|'), ('4', '4'), ('3', '3'), ('7', '7')]



========================================== PARAGRAPH 91 ===========================================

REVIEW INSIGHT 

------------------- Sentence 1 -------------------

REVIEW INSIGHT

>> Tokens are: 
 ['REVIEW', 'INSIGHT']

>> Bigrams are: 
 [('REVIEW', 'INSIGHT')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('REVIEW', 'NNP'), ('INSIGHT', 'NNP')]

>> Noun Phrases are: 
 ['REVIEW INSIGHT']

>> Named Entities are: 
 [('ORGANIZATION', 'REVIEW')] 

>> Stemming using Porter Stemmer: 
 [('REVIEW', 'review'), ('INSIGHT', 'insight')]

>> Stemming using Snowball Stemmer: 
 [('REVIEW', 'review'), ('INSIGHT', 'insight')]

>> Lemmatization: 
 [('REVIEW', 'REVIEW'), ('INSIGHT', 'INSIGHT')]



========================================== PARAGRAPH 92 ===========================================

© 2015 Macmillan Publishers Limited. All rights reserved

------------------- Sentence 1 -------------------

© 2015 Macmillan Publishers Limited.

>> Tokens are: 
 ['©', '2015', 'Macmillan', 'Publishers', 'Limited', '.']

>> Bigrams are: 
 [('©', '2015'), ('2015', 'Macmillan'), ('Macmillan', 'Publishers'), ('Publishers', 'Limited'), ('Limited', '.')]

>> Trigrams are: 
 [('©', '2015', 'Macmillan'), ('2015', 'Macmillan', 'Publishers'), ('Macmillan', 'Publishers', 'Limited'), ('Publishers', 'Limited', '.')]

>> POS Tags are: 
 [('©', 'NN'), ('2015', 'CD'), ('Macmillan', 'NNP'), ('Publishers', 'NNP'), ('Limited', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['©', 'Macmillan Publishers Limited']

>> Named Entities are: 
 [('PERSON', 'Macmillan Publishers Limited')] 

>> Stemming using Porter Stemmer: 
 [('©', '©'), ('2015', '2015'), ('Macmillan', 'macmillan'), ('Publishers', 'publish'), ('Limited', 'limit'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('©', '©'), ('2015', '2015'), ('Macmillan', 'macmillan'), ('Publishers', 'publish'), ('Limited', 'limit'), ('.', '.')]

>> Lemmatization: 
 [('©', '©'), ('2015', '2015'), ('Macmillan', 'Macmillan'), ('Publishers', 'Publishers'), ('Limited', 'Limited'), ('.', '.')]


------------------- Sentence 2 -------------------

All rights reserved

>> Tokens are: 
 ['All', 'rights', 'reserved']

>> Bigrams are: 
 [('All', 'rights'), ('rights', 'reserved')]

>> Trigrams are: 
 [('All', 'rights', 'reserved')]

>> POS Tags are: 
 [('All', 'DT'), ('rights', 'NNS'), ('reserved', 'VBN')]

>> Noun Phrases are: 
 ['All rights']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('All', 'all'), ('rights', 'right'), ('reserved', 'reserv')]

>> Stemming using Snowball Stemmer: 
 [('All', 'all'), ('rights', 'right'), ('reserved', 'reserv')]

>> Lemmatization: 
 [('All', 'All'), ('rights', 'right'), ('reserved', 'reserved')]



========================================== PARAGRAPH 93 ===========================================

raw pixels could not possibly distinguish the latter two, while putting  the former two in the same category. This is why shallow classifiers  require a good feature extractor that solves the selectivity–invariance  dilemma — one that produces representations that are selective to  the aspects of the image that are important for discrimination, but  that are invariant to irrelevant aspects such as the pose of the animal.  To make classifiers more powerful, one can use generic non-linear  features, as with kernel methods20, but generic features such as those  arising with the Gaussian kernel do not allow the learner to general- ize well far from the training examples21. The conventional option is  to hand design good feature extractors, which requires a consider- able amount of engineering skill and domain expertise. But this can  all be avoided if good features can be learned automatically using a  general-purpose learning procedure. This is the key advantage of  deep learning.  

------------------- Sentence 1 -------------------

raw pixels could not possibly distinguish the latter two, while putting  the former two in the same category.

>> Tokens are: 
 ['raw', 'pixels', 'could', 'possibly', 'distinguish', 'latter', 'two', ',', 'putting', 'former', 'two', 'category', '.']

>> Bigrams are: 
 [('raw', 'pixels'), ('pixels', 'could'), ('could', 'possibly'), ('possibly', 'distinguish'), ('distinguish', 'latter'), ('latter', 'two'), ('two', ','), (',', 'putting'), ('putting', 'former'), ('former', 'two'), ('two', 'category'), ('category', '.')]

>> Trigrams are: 
 [('raw', 'pixels', 'could'), ('pixels', 'could', 'possibly'), ('could', 'possibly', 'distinguish'), ('possibly', 'distinguish', 'latter'), ('distinguish', 'latter', 'two'), ('latter', 'two', ','), ('two', ',', 'putting'), (',', 'putting', 'former'), ('putting', 'former', 'two'), ('former', 'two', 'category'), ('two', 'category', '.')]

>> POS Tags are: 
 [('raw', 'JJ'), ('pixels', 'NNS'), ('could', 'MD'), ('possibly', 'RB'), ('distinguish', 'VB'), ('latter', 'JJR'), ('two', 'CD'), (',', ','), ('putting', 'VBG'), ('former', 'JJ'), ('two', 'CD'), ('category', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['raw pixels', 'category']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('raw', 'raw'), ('pixels', 'pixel'), ('could', 'could'), ('possibly', 'possibl'), ('distinguish', 'distinguish'), ('latter', 'latter'), ('two', 'two'), (',', ','), ('putting', 'put'), ('former', 'former'), ('two', 'two'), ('category', 'categori'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('raw', 'raw'), ('pixels', 'pixel'), ('could', 'could'), ('possibly', 'possibl'), ('distinguish', 'distinguish'), ('latter', 'latter'), ('two', 'two'), (',', ','), ('putting', 'put'), ('former', 'former'), ('two', 'two'), ('category', 'categori'), ('.', '.')]

>> Lemmatization: 
 [('raw', 'raw'), ('pixels', 'pixel'), ('could', 'could'), ('possibly', 'possibly'), ('distinguish', 'distinguish'), ('latter', 'latter'), ('two', 'two'), (',', ','), ('putting', 'putting'), ('former', 'former'), ('two', 'two'), ('category', 'category'), ('.', '.')]


------------------- Sentence 2 -------------------

This is why shallow classifiers  require a good feature extractor that solves the selectivity–invariance  dilemma — one that produces representations that are selective to  the aspects of the image that are important for discrimination, but  that are invariant to irrelevant aspects such as the pose of the animal.

>> Tokens are: 
 ['This', 'shallow', 'classifiers', 'require', 'good', 'feature', 'extractor', 'solves', 'selectivity–invariance', 'dilemma', '—', 'one', 'produces', 'representations', 'selective', 'aspects', 'image', 'important', 'discrimination', ',', 'invariant', 'irrelevant', 'aspects', 'pose', 'animal', '.']

>> Bigrams are: 
 [('This', 'shallow'), ('shallow', 'classifiers'), ('classifiers', 'require'), ('require', 'good'), ('good', 'feature'), ('feature', 'extractor'), ('extractor', 'solves'), ('solves', 'selectivity–invariance'), ('selectivity–invariance', 'dilemma'), ('dilemma', '—'), ('—', 'one'), ('one', 'produces'), ('produces', 'representations'), ('representations', 'selective'), ('selective', 'aspects'), ('aspects', 'image'), ('image', 'important'), ('important', 'discrimination'), ('discrimination', ','), (',', 'invariant'), ('invariant', 'irrelevant'), ('irrelevant', 'aspects'), ('aspects', 'pose'), ('pose', 'animal'), ('animal', '.')]

>> Trigrams are: 
 [('This', 'shallow', 'classifiers'), ('shallow', 'classifiers', 'require'), ('classifiers', 'require', 'good'), ('require', 'good', 'feature'), ('good', 'feature', 'extractor'), ('feature', 'extractor', 'solves'), ('extractor', 'solves', 'selectivity–invariance'), ('solves', 'selectivity–invariance', 'dilemma'), ('selectivity–invariance', 'dilemma', '—'), ('dilemma', '—', 'one'), ('—', 'one', 'produces'), ('one', 'produces', 'representations'), ('produces', 'representations', 'selective'), ('representations', 'selective', 'aspects'), ('selective', 'aspects', 'image'), ('aspects', 'image', 'important'), ('image', 'important', 'discrimination'), ('important', 'discrimination', ','), ('discrimination', ',', 'invariant'), (',', 'invariant', 'irrelevant'), ('invariant', 'irrelevant', 'aspects'), ('irrelevant', 'aspects', 'pose'), ('aspects', 'pose', 'animal'), ('pose', 'animal', '.')]

>> POS Tags are: 
 [('This', 'DT'), ('shallow', 'JJ'), ('classifiers', 'NNS'), ('require', 'VBP'), ('good', 'JJ'), ('feature', 'NN'), ('extractor', 'NN'), ('solves', 'VBZ'), ('selectivity–invariance', 'RB'), ('dilemma', 'JJ'), ('—', 'NNP'), ('one', 'CD'), ('produces', 'VBZ'), ('representations', 'NNS'), ('selective', 'JJ'), ('aspects', 'NNS'), ('image', 'NN'), ('important', 'JJ'), ('discrimination', 'NN'), (',', ','), ('invariant', 'JJ'), ('irrelevant', 'JJ'), ('aspects', 'NNS'), ('pose', 'VBP'), ('animal', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['This shallow classifiers', 'good feature extractor', 'dilemma —', 'representations', 'selective aspects image', 'important discrimination', 'invariant irrelevant aspects', 'animal']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('This', 'thi'), ('shallow', 'shallow'), ('classifiers', 'classifi'), ('require', 'requir'), ('good', 'good'), ('feature', 'featur'), ('extractor', 'extractor'), ('solves', 'solv'), ('selectivity–invariance', 'selectivity–invari'), ('dilemma', 'dilemma'), ('—', '—'), ('one', 'one'), ('produces', 'produc'), ('representations', 'represent'), ('selective', 'select'), ('aspects', 'aspect'), ('image', 'imag'), ('important', 'import'), ('discrimination', 'discrimin'), (',', ','), ('invariant', 'invari'), ('irrelevant', 'irrelev'), ('aspects', 'aspect'), ('pose', 'pose'), ('animal', 'anim'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('This', 'this'), ('shallow', 'shallow'), ('classifiers', 'classifi'), ('require', 'requir'), ('good', 'good'), ('feature', 'featur'), ('extractor', 'extractor'), ('solves', 'solv'), ('selectivity–invariance', 'selectivity–invari'), ('dilemma', 'dilemma'), ('—', '—'), ('one', 'one'), ('produces', 'produc'), ('representations', 'represent'), ('selective', 'select'), ('aspects', 'aspect'), ('image', 'imag'), ('important', 'import'), ('discrimination', 'discrimin'), (',', ','), ('invariant', 'invari'), ('irrelevant', 'irrelev'), ('aspects', 'aspect'), ('pose', 'pose'), ('animal', 'anim'), ('.', '.')]

>> Lemmatization: 
 [('This', 'This'), ('shallow', 'shallow'), ('classifiers', 'classifier'), ('require', 'require'), ('good', 'good'), ('feature', 'feature'), ('extractor', 'extractor'), ('solves', 'solves'), ('selectivity–invariance', 'selectivity–invariance'), ('dilemma', 'dilemma'), ('—', '—'), ('one', 'one'), ('produces', 'produce'), ('representations', 'representation'), ('selective', 'selective'), ('aspects', 'aspect'), ('image', 'image'), ('important', 'important'), ('discrimination', 'discrimination'), (',', ','), ('invariant', 'invariant'), ('irrelevant', 'irrelevant'), ('aspects', 'aspect'), ('pose', 'pose'), ('animal', 'animal'), ('.', '.')]


------------------- Sentence 3 -------------------

To make classifiers more powerful, one can use generic non-linear  features, as with kernel methods20, but generic features such as those  arising with the Gaussian kernel do not allow the learner to general- ize well far from the training examples21.

>> Tokens are: 
 ['To', 'make', 'classifiers', 'powerful', ',', 'one', 'use', 'generic', 'non-linear', 'features', ',', 'kernel', 'methods20', ',', 'generic', 'features', 'arising', 'Gaussian', 'kernel', 'allow', 'learner', 'general-', 'ize', 'well', 'far', 'training', 'examples21', '.']

>> Bigrams are: 
 [('To', 'make'), ('make', 'classifiers'), ('classifiers', 'powerful'), ('powerful', ','), (',', 'one'), ('one', 'use'), ('use', 'generic'), ('generic', 'non-linear'), ('non-linear', 'features'), ('features', ','), (',', 'kernel'), ('kernel', 'methods20'), ('methods20', ','), (',', 'generic'), ('generic', 'features'), ('features', 'arising'), ('arising', 'Gaussian'), ('Gaussian', 'kernel'), ('kernel', 'allow'), ('allow', 'learner'), ('learner', 'general-'), ('general-', 'ize'), ('ize', 'well'), ('well', 'far'), ('far', 'training'), ('training', 'examples21'), ('examples21', '.')]

>> Trigrams are: 
 [('To', 'make', 'classifiers'), ('make', 'classifiers', 'powerful'), ('classifiers', 'powerful', ','), ('powerful', ',', 'one'), (',', 'one', 'use'), ('one', 'use', 'generic'), ('use', 'generic', 'non-linear'), ('generic', 'non-linear', 'features'), ('non-linear', 'features', ','), ('features', ',', 'kernel'), (',', 'kernel', 'methods20'), ('kernel', 'methods20', ','), ('methods20', ',', 'generic'), (',', 'generic', 'features'), ('generic', 'features', 'arising'), ('features', 'arising', 'Gaussian'), ('arising', 'Gaussian', 'kernel'), ('Gaussian', 'kernel', 'allow'), ('kernel', 'allow', 'learner'), ('allow', 'learner', 'general-'), ('learner', 'general-', 'ize'), ('general-', 'ize', 'well'), ('ize', 'well', 'far'), ('well', 'far', 'training'), ('far', 'training', 'examples21'), ('training', 'examples21', '.')]

>> POS Tags are: 
 [('To', 'TO'), ('make', 'VB'), ('classifiers', 'NNS'), ('powerful', 'JJ'), (',', ','), ('one', 'CD'), ('use', 'NN'), ('generic', 'JJ'), ('non-linear', 'JJ'), ('features', 'NNS'), (',', ','), ('kernel', 'NNS'), ('methods20', 'VBP'), (',', ','), ('generic', 'JJ'), ('features', 'NNS'), ('arising', 'VBG'), ('Gaussian', 'JJ'), ('kernel', 'NNS'), ('allow', 'VBP'), ('learner', 'JJR'), ('general-', 'JJ'), ('ize', 'NN'), ('well', 'RB'), ('far', 'RB'), ('training', 'VBG'), ('examples21', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['classifiers', 'use', 'generic non-linear features', 'kernel', 'generic features', 'Gaussian kernel', 'general- ize', 'examples21']

>> Named Entities are: 
 [('GPE', 'Gaussian')] 

>> Stemming using Porter Stemmer: 
 [('To', 'to'), ('make', 'make'), ('classifiers', 'classifi'), ('powerful', 'power'), (',', ','), ('one', 'one'), ('use', 'use'), ('generic', 'gener'), ('non-linear', 'non-linear'), ('features', 'featur'), (',', ','), ('kernel', 'kernel'), ('methods20', 'methods20'), (',', ','), ('generic', 'gener'), ('features', 'featur'), ('arising', 'aris'), ('Gaussian', 'gaussian'), ('kernel', 'kernel'), ('allow', 'allow'), ('learner', 'learner'), ('general-', 'general-'), ('ize', 'ize'), ('well', 'well'), ('far', 'far'), ('training', 'train'), ('examples21', 'examples21'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('To', 'to'), ('make', 'make'), ('classifiers', 'classifi'), ('powerful', 'power'), (',', ','), ('one', 'one'), ('use', 'use'), ('generic', 'generic'), ('non-linear', 'non-linear'), ('features', 'featur'), (',', ','), ('kernel', 'kernel'), ('methods20', 'methods20'), (',', ','), ('generic', 'generic'), ('features', 'featur'), ('arising', 'aris'), ('Gaussian', 'gaussian'), ('kernel', 'kernel'), ('allow', 'allow'), ('learner', 'learner'), ('general-', 'general-'), ('ize', 'ize'), ('well', 'well'), ('far', 'far'), ('training', 'train'), ('examples21', 'examples21'), ('.', '.')]

>> Lemmatization: 
 [('To', 'To'), ('make', 'make'), ('classifiers', 'classifier'), ('powerful', 'powerful'), (',', ','), ('one', 'one'), ('use', 'use'), ('generic', 'generic'), ('non-linear', 'non-linear'), ('features', 'feature'), (',', ','), ('kernel', 'kernel'), ('methods20', 'methods20'), (',', ','), ('generic', 'generic'), ('features', 'feature'), ('arising', 'arising'), ('Gaussian', 'Gaussian'), ('kernel', 'kernel'), ('allow', 'allow'), ('learner', 'learner'), ('general-', 'general-'), ('ize', 'ize'), ('well', 'well'), ('far', 'far'), ('training', 'training'), ('examples21', 'examples21'), ('.', '.')]


------------------- Sentence 4 -------------------

The conventional option is  to hand design good feature extractors, which requires a consider- able amount of engineering skill and domain expertise.

>> Tokens are: 
 ['The', 'conventional', 'option', 'hand', 'design', 'good', 'feature', 'extractors', ',', 'requires', 'consider-', 'able', 'amount', 'engineering', 'skill', 'domain', 'expertise', '.']

>> Bigrams are: 
 [('The', 'conventional'), ('conventional', 'option'), ('option', 'hand'), ('hand', 'design'), ('design', 'good'), ('good', 'feature'), ('feature', 'extractors'), ('extractors', ','), (',', 'requires'), ('requires', 'consider-'), ('consider-', 'able'), ('able', 'amount'), ('amount', 'engineering'), ('engineering', 'skill'), ('skill', 'domain'), ('domain', 'expertise'), ('expertise', '.')]

>> Trigrams are: 
 [('The', 'conventional', 'option'), ('conventional', 'option', 'hand'), ('option', 'hand', 'design'), ('hand', 'design', 'good'), ('design', 'good', 'feature'), ('good', 'feature', 'extractors'), ('feature', 'extractors', ','), ('extractors', ',', 'requires'), (',', 'requires', 'consider-'), ('requires', 'consider-', 'able'), ('consider-', 'able', 'amount'), ('able', 'amount', 'engineering'), ('amount', 'engineering', 'skill'), ('engineering', 'skill', 'domain'), ('skill', 'domain', 'expertise'), ('domain', 'expertise', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('conventional', 'JJ'), ('option', 'NN'), ('hand', 'NN'), ('design', 'NN'), ('good', 'JJ'), ('feature', 'NN'), ('extractors', 'NNS'), (',', ','), ('requires', 'VBZ'), ('consider-', 'JJ'), ('able', 'JJ'), ('amount', 'NN'), ('engineering', 'NN'), ('skill', 'NN'), ('domain', 'VBP'), ('expertise', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['The conventional option hand design', 'good feature extractors', 'consider- able amount engineering skill', 'expertise']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('conventional', 'convent'), ('option', 'option'), ('hand', 'hand'), ('design', 'design'), ('good', 'good'), ('feature', 'featur'), ('extractors', 'extractor'), (',', ','), ('requires', 'requir'), ('consider-', 'consider-'), ('able', 'abl'), ('amount', 'amount'), ('engineering', 'engin'), ('skill', 'skill'), ('domain', 'domain'), ('expertise', 'expertis'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('conventional', 'convent'), ('option', 'option'), ('hand', 'hand'), ('design', 'design'), ('good', 'good'), ('feature', 'featur'), ('extractors', 'extractor'), (',', ','), ('requires', 'requir'), ('consider-', 'consider-'), ('able', 'abl'), ('amount', 'amount'), ('engineering', 'engin'), ('skill', 'skill'), ('domain', 'domain'), ('expertise', 'expertis'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('conventional', 'conventional'), ('option', 'option'), ('hand', 'hand'), ('design', 'design'), ('good', 'good'), ('feature', 'feature'), ('extractors', 'extractor'), (',', ','), ('requires', 'requires'), ('consider-', 'consider-'), ('able', 'able'), ('amount', 'amount'), ('engineering', 'engineering'), ('skill', 'skill'), ('domain', 'domain'), ('expertise', 'expertise'), ('.', '.')]


------------------- Sentence 5 -------------------

But this can  all be avoided if good features can be learned automatically using a  general-purpose learning procedure.

>> Tokens are: 
 ['But', 'avoided', 'good', 'features', 'learned', 'automatically', 'using', 'general-purpose', 'learning', 'procedure', '.']

>> Bigrams are: 
 [('But', 'avoided'), ('avoided', 'good'), ('good', 'features'), ('features', 'learned'), ('learned', 'automatically'), ('automatically', 'using'), ('using', 'general-purpose'), ('general-purpose', 'learning'), ('learning', 'procedure'), ('procedure', '.')]

>> Trigrams are: 
 [('But', 'avoided', 'good'), ('avoided', 'good', 'features'), ('good', 'features', 'learned'), ('features', 'learned', 'automatically'), ('learned', 'automatically', 'using'), ('automatically', 'using', 'general-purpose'), ('using', 'general-purpose', 'learning'), ('general-purpose', 'learning', 'procedure'), ('learning', 'procedure', '.')]

>> POS Tags are: 
 [('But', 'CC'), ('avoided', 'VBD'), ('good', 'JJ'), ('features', 'NNS'), ('learned', 'VBD'), ('automatically', 'RB'), ('using', 'VBG'), ('general-purpose', 'JJ'), ('learning', 'JJ'), ('procedure', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['good features', 'general-purpose learning procedure']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('But', 'but'), ('avoided', 'avoid'), ('good', 'good'), ('features', 'featur'), ('learned', 'learn'), ('automatically', 'automat'), ('using', 'use'), ('general-purpose', 'general-purpos'), ('learning', 'learn'), ('procedure', 'procedur'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('But', 'but'), ('avoided', 'avoid'), ('good', 'good'), ('features', 'featur'), ('learned', 'learn'), ('automatically', 'automat'), ('using', 'use'), ('general-purpose', 'general-purpos'), ('learning', 'learn'), ('procedure', 'procedur'), ('.', '.')]

>> Lemmatization: 
 [('But', 'But'), ('avoided', 'avoided'), ('good', 'good'), ('features', 'feature'), ('learned', 'learned'), ('automatically', 'automatically'), ('using', 'using'), ('general-purpose', 'general-purpose'), ('learning', 'learning'), ('procedure', 'procedure'), ('.', '.')]


------------------- Sentence 6 -------------------

This is the key advantage of  deep learning.

>> Tokens are: 
 ['This', 'key', 'advantage', 'deep', 'learning', '.']

>> Bigrams are: 
 [('This', 'key'), ('key', 'advantage'), ('advantage', 'deep'), ('deep', 'learning'), ('learning', '.')]

>> Trigrams are: 
 [('This', 'key', 'advantage'), ('key', 'advantage', 'deep'), ('advantage', 'deep', 'learning'), ('deep', 'learning', '.')]

>> POS Tags are: 
 [('This', 'DT'), ('key', 'JJ'), ('advantage', 'NN'), ('deep', 'JJ'), ('learning', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['This key advantage', 'deep learning']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('This', 'thi'), ('key', 'key'), ('advantage', 'advantag'), ('deep', 'deep'), ('learning', 'learn'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('This', 'this'), ('key', 'key'), ('advantage', 'advantag'), ('deep', 'deep'), ('learning', 'learn'), ('.', '.')]

>> Lemmatization: 
 [('This', 'This'), ('key', 'key'), ('advantage', 'advantage'), ('deep', 'deep'), ('learning', 'learning'), ('.', '.')]



========================================== PARAGRAPH 94 ===========================================

A deep-learning architecture is a multilayer stack of simple mod- ules, all (or most) of which are subject to learning, and many of which  compute non-linear input–output mappings. Each module in the  stack transforms its input to increase both the selectivity and the  invariance of the representation. With multiple non-linear layers, say  a depth of 5 to 20, a system can implement extremely intricate func- tions of its inputs that are simultaneously sensitive to minute details  — distinguishing Samoyeds from white wolves — and insensitive to  large irrelevant variations such as the background, pose, lighting and  surrounding objects.  

------------------- Sentence 1 -------------------

A deep-learning architecture is a multilayer stack of simple mod- ules, all (or most) of which are subject to learning, and many of which  compute non-linear input–output mappings.

>> Tokens are: 
 ['A', 'deep-learning', 'architecture', 'multilayer', 'stack', 'simple', 'mod-', 'ules', ',', '(', ')', 'subject', 'learning', ',', 'many', 'compute', 'non-linear', 'input–output', 'mappings', '.']

>> Bigrams are: 
 [('A', 'deep-learning'), ('deep-learning', 'architecture'), ('architecture', 'multilayer'), ('multilayer', 'stack'), ('stack', 'simple'), ('simple', 'mod-'), ('mod-', 'ules'), ('ules', ','), (',', '('), ('(', ')'), (')', 'subject'), ('subject', 'learning'), ('learning', ','), (',', 'many'), ('many', 'compute'), ('compute', 'non-linear'), ('non-linear', 'input–output'), ('input–output', 'mappings'), ('mappings', '.')]

>> Trigrams are: 
 [('A', 'deep-learning', 'architecture'), ('deep-learning', 'architecture', 'multilayer'), ('architecture', 'multilayer', 'stack'), ('multilayer', 'stack', 'simple'), ('stack', 'simple', 'mod-'), ('simple', 'mod-', 'ules'), ('mod-', 'ules', ','), ('ules', ',', '('), (',', '(', ')'), ('(', ')', 'subject'), (')', 'subject', 'learning'), ('subject', 'learning', ','), ('learning', ',', 'many'), (',', 'many', 'compute'), ('many', 'compute', 'non-linear'), ('compute', 'non-linear', 'input–output'), ('non-linear', 'input–output', 'mappings'), ('input–output', 'mappings', '.')]

>> POS Tags are: 
 [('A', 'DT'), ('deep-learning', 'JJ'), ('architecture', 'NN'), ('multilayer', 'NN'), ('stack', 'NN'), ('simple', 'JJ'), ('mod-', 'JJ'), ('ules', 'NNS'), (',', ','), ('(', '('), (')', ')'), ('subject', 'NN'), ('learning', 'VBG'), (',', ','), ('many', 'JJ'), ('compute', 'VBP'), ('non-linear', 'JJ'), ('input–output', 'NN'), ('mappings', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['A deep-learning architecture multilayer stack', 'simple mod- ules', 'subject', 'non-linear input–output mappings']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('A', 'a'), ('deep-learning', 'deep-learn'), ('architecture', 'architectur'), ('multilayer', 'multilay'), ('stack', 'stack'), ('simple', 'simpl'), ('mod-', 'mod-'), ('ules', 'ule'), (',', ','), ('(', '('), (')', ')'), ('subject', 'subject'), ('learning', 'learn'), (',', ','), ('many', 'mani'), ('compute', 'comput'), ('non-linear', 'non-linear'), ('input–output', 'input–output'), ('mappings', 'map'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('A', 'a'), ('deep-learning', 'deep-learn'), ('architecture', 'architectur'), ('multilayer', 'multilay'), ('stack', 'stack'), ('simple', 'simpl'), ('mod-', 'mod-'), ('ules', 'ule'), (',', ','), ('(', '('), (')', ')'), ('subject', 'subject'), ('learning', 'learn'), (',', ','), ('many', 'mani'), ('compute', 'comput'), ('non-linear', 'non-linear'), ('input–output', 'input–output'), ('mappings', 'map'), ('.', '.')]

>> Lemmatization: 
 [('A', 'A'), ('deep-learning', 'deep-learning'), ('architecture', 'architecture'), ('multilayer', 'multilayer'), ('stack', 'stack'), ('simple', 'simple'), ('mod-', 'mod-'), ('ules', 'ules'), (',', ','), ('(', '('), (')', ')'), ('subject', 'subject'), ('learning', 'learning'), (',', ','), ('many', 'many'), ('compute', 'compute'), ('non-linear', 'non-linear'), ('input–output', 'input–output'), ('mappings', 'mapping'), ('.', '.')]


------------------- Sentence 2 -------------------

Each module in the  stack transforms its input to increase both the selectivity and the  invariance of the representation.

>> Tokens are: 
 ['Each', 'module', 'stack', 'transforms', 'input', 'increase', 'selectivity', 'invariance', 'representation', '.']

>> Bigrams are: 
 [('Each', 'module'), ('module', 'stack'), ('stack', 'transforms'), ('transforms', 'input'), ('input', 'increase'), ('increase', 'selectivity'), ('selectivity', 'invariance'), ('invariance', 'representation'), ('representation', '.')]

>> Trigrams are: 
 [('Each', 'module', 'stack'), ('module', 'stack', 'transforms'), ('stack', 'transforms', 'input'), ('transforms', 'input', 'increase'), ('input', 'increase', 'selectivity'), ('increase', 'selectivity', 'invariance'), ('selectivity', 'invariance', 'representation'), ('invariance', 'representation', '.')]

>> POS Tags are: 
 [('Each', 'DT'), ('module', 'NN'), ('stack', 'NN'), ('transforms', 'NNS'), ('input', 'VBP'), ('increase', 'VB'), ('selectivity', 'NN'), ('invariance', 'NN'), ('representation', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Each module stack transforms', 'selectivity invariance representation']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Each', 'each'), ('module', 'modul'), ('stack', 'stack'), ('transforms', 'transform'), ('input', 'input'), ('increase', 'increas'), ('selectivity', 'select'), ('invariance', 'invari'), ('representation', 'represent'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Each', 'each'), ('module', 'modul'), ('stack', 'stack'), ('transforms', 'transform'), ('input', 'input'), ('increase', 'increas'), ('selectivity', 'select'), ('invariance', 'invari'), ('representation', 'represent'), ('.', '.')]

>> Lemmatization: 
 [('Each', 'Each'), ('module', 'module'), ('stack', 'stack'), ('transforms', 'transforms'), ('input', 'input'), ('increase', 'increase'), ('selectivity', 'selectivity'), ('invariance', 'invariance'), ('representation', 'representation'), ('.', '.')]


------------------- Sentence 3 -------------------

With multiple non-linear layers, say  a depth of 5 to 20, a system can implement extremely intricate func- tions of its inputs that are simultaneously sensitive to minute details  — distinguishing Samoyeds from white wolves — and insensitive to  large irrelevant variations such as the background, pose, lighting and  surrounding objects.

>> Tokens are: 
 ['With', 'multiple', 'non-linear', 'layers', ',', 'say', 'depth', '5', '20', ',', 'system', 'implement', 'extremely', 'intricate', 'func-', 'tions', 'inputs', 'simultaneously', 'sensitive', 'minute', 'details', '—', 'distinguishing', 'Samoyeds', 'white', 'wolves', '—', 'insensitive', 'large', 'irrelevant', 'variations', 'background', ',', 'pose', ',', 'lighting', 'surrounding', 'objects', '.']

>> Bigrams are: 
 [('With', 'multiple'), ('multiple', 'non-linear'), ('non-linear', 'layers'), ('layers', ','), (',', 'say'), ('say', 'depth'), ('depth', '5'), ('5', '20'), ('20', ','), (',', 'system'), ('system', 'implement'), ('implement', 'extremely'), ('extremely', 'intricate'), ('intricate', 'func-'), ('func-', 'tions'), ('tions', 'inputs'), ('inputs', 'simultaneously'), ('simultaneously', 'sensitive'), ('sensitive', 'minute'), ('minute', 'details'), ('details', '—'), ('—', 'distinguishing'), ('distinguishing', 'Samoyeds'), ('Samoyeds', 'white'), ('white', 'wolves'), ('wolves', '—'), ('—', 'insensitive'), ('insensitive', 'large'), ('large', 'irrelevant'), ('irrelevant', 'variations'), ('variations', 'background'), ('background', ','), (',', 'pose'), ('pose', ','), (',', 'lighting'), ('lighting', 'surrounding'), ('surrounding', 'objects'), ('objects', '.')]

>> Trigrams are: 
 [('With', 'multiple', 'non-linear'), ('multiple', 'non-linear', 'layers'), ('non-linear', 'layers', ','), ('layers', ',', 'say'), (',', 'say', 'depth'), ('say', 'depth', '5'), ('depth', '5', '20'), ('5', '20', ','), ('20', ',', 'system'), (',', 'system', 'implement'), ('system', 'implement', 'extremely'), ('implement', 'extremely', 'intricate'), ('extremely', 'intricate', 'func-'), ('intricate', 'func-', 'tions'), ('func-', 'tions', 'inputs'), ('tions', 'inputs', 'simultaneously'), ('inputs', 'simultaneously', 'sensitive'), ('simultaneously', 'sensitive', 'minute'), ('sensitive', 'minute', 'details'), ('minute', 'details', '—'), ('details', '—', 'distinguishing'), ('—', 'distinguishing', 'Samoyeds'), ('distinguishing', 'Samoyeds', 'white'), ('Samoyeds', 'white', 'wolves'), ('white', 'wolves', '—'), ('wolves', '—', 'insensitive'), ('—', 'insensitive', 'large'), ('insensitive', 'large', 'irrelevant'), ('large', 'irrelevant', 'variations'), ('irrelevant', 'variations', 'background'), ('variations', 'background', ','), ('background', ',', 'pose'), (',', 'pose', ','), ('pose', ',', 'lighting'), (',', 'lighting', 'surrounding'), ('lighting', 'surrounding', 'objects'), ('surrounding', 'objects', '.')]

>> POS Tags are: 
 [('With', 'IN'), ('multiple', 'JJ'), ('non-linear', 'JJ'), ('layers', 'NNS'), (',', ','), ('say', 'VBP'), ('depth', 'JJ'), ('5', 'CD'), ('20', 'CD'), (',', ','), ('system', 'NN'), ('implement', 'NN'), ('extremely', 'RB'), ('intricate', 'JJ'), ('func-', 'JJ'), ('tions', 'NNS'), ('inputs', 'VBZ'), ('simultaneously', 'RB'), ('sensitive', 'JJ'), ('minute', 'NN'), ('details', 'NNS'), ('—', 'VBP'), ('distinguishing', 'VBG'), ('Samoyeds', 'NNP'), ('white', 'JJ'), ('wolves', 'NNS'), ('—', 'VBP'), ('insensitive', 'JJ'), ('large', 'JJ'), ('irrelevant', 'JJ'), ('variations', 'NNS'), ('background', 'NN'), (',', ','), ('pose', 'NN'), (',', ','), ('lighting', 'VBG'), ('surrounding', 'VBG'), ('objects', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['multiple non-linear layers', 'system implement', 'intricate func- tions', 'sensitive minute details', 'Samoyeds', 'white wolves', 'insensitive large irrelevant variations background', 'pose', 'objects']

>> Named Entities are: 
 [('PERSON', 'Samoyeds')] 

>> Stemming using Porter Stemmer: 
 [('With', 'with'), ('multiple', 'multipl'), ('non-linear', 'non-linear'), ('layers', 'layer'), (',', ','), ('say', 'say'), ('depth', 'depth'), ('5', '5'), ('20', '20'), (',', ','), ('system', 'system'), ('implement', 'implement'), ('extremely', 'extrem'), ('intricate', 'intric'), ('func-', 'func-'), ('tions', 'tion'), ('inputs', 'input'), ('simultaneously', 'simultan'), ('sensitive', 'sensit'), ('minute', 'minut'), ('details', 'detail'), ('—', '—'), ('distinguishing', 'distinguish'), ('Samoyeds', 'samoy'), ('white', 'white'), ('wolves', 'wolv'), ('—', '—'), ('insensitive', 'insensit'), ('large', 'larg'), ('irrelevant', 'irrelev'), ('variations', 'variat'), ('background', 'background'), (',', ','), ('pose', 'pose'), (',', ','), ('lighting', 'light'), ('surrounding', 'surround'), ('objects', 'object'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('With', 'with'), ('multiple', 'multipl'), ('non-linear', 'non-linear'), ('layers', 'layer'), (',', ','), ('say', 'say'), ('depth', 'depth'), ('5', '5'), ('20', '20'), (',', ','), ('system', 'system'), ('implement', 'implement'), ('extremely', 'extrem'), ('intricate', 'intric'), ('func-', 'func-'), ('tions', 'tion'), ('inputs', 'input'), ('simultaneously', 'simultan'), ('sensitive', 'sensit'), ('minute', 'minut'), ('details', 'detail'), ('—', '—'), ('distinguishing', 'distinguish'), ('Samoyeds', 'samoy'), ('white', 'white'), ('wolves', 'wolv'), ('—', '—'), ('insensitive', 'insensit'), ('large', 'larg'), ('irrelevant', 'irrelev'), ('variations', 'variat'), ('background', 'background'), (',', ','), ('pose', 'pose'), (',', ','), ('lighting', 'light'), ('surrounding', 'surround'), ('objects', 'object'), ('.', '.')]

>> Lemmatization: 
 [('With', 'With'), ('multiple', 'multiple'), ('non-linear', 'non-linear'), ('layers', 'layer'), (',', ','), ('say', 'say'), ('depth', 'depth'), ('5', '5'), ('20', '20'), (',', ','), ('system', 'system'), ('implement', 'implement'), ('extremely', 'extremely'), ('intricate', 'intricate'), ('func-', 'func-'), ('tions', 'tions'), ('inputs', 'input'), ('simultaneously', 'simultaneously'), ('sensitive', 'sensitive'), ('minute', 'minute'), ('details', 'detail'), ('—', '—'), ('distinguishing', 'distinguishing'), ('Samoyeds', 'Samoyeds'), ('white', 'white'), ('wolves', 'wolf'), ('—', '—'), ('insensitive', 'insensitive'), ('large', 'large'), ('irrelevant', 'irrelevant'), ('variations', 'variation'), ('background', 'background'), (',', ','), ('pose', 'pose'), (',', ','), ('lighting', 'lighting'), ('surrounding', 'surrounding'), ('objects', 'object'), ('.', '.')]



========================================== PARAGRAPH 95 ===========================================

Backpropagation to train multilayer architectures  From the earliest days of pattern recognition22,23, the aim of research- ers has been to replace hand-engineered features with trainable  multilayer networks, but despite its simplicity, the solution was not  widely understood until the mid 1980s. As it turns out, multilayer  architectures can be trained by simple stochastic gradient descent.  As long as the modules are relatively smooth functions of their inputs  and of their internal weights, one can compute gradients using the  backpropagation procedure. The idea that this could be done, and  that it worked, was discovered independently by several different  groups during the 1970s and 1980s24–27.   

------------------- Sentence 1 -------------------

Backpropagation to train multilayer architectures  From the earliest days of pattern recognition22,23, the aim of research- ers has been to replace hand-engineered features with trainable  multilayer networks, but despite its simplicity, the solution was not  widely understood until the mid 1980s.

>> Tokens are: 
 ['Backpropagation', 'train', 'multilayer', 'architectures', 'From', 'earliest', 'days', 'pattern', 'recognition22,23', ',', 'aim', 'research-', 'ers', 'replace', 'hand-engineered', 'features', 'trainable', 'multilayer', 'networks', ',', 'despite', 'simplicity', ',', 'solution', 'widely', 'understood', 'mid', '1980s', '.']

>> Bigrams are: 
 [('Backpropagation', 'train'), ('train', 'multilayer'), ('multilayer', 'architectures'), ('architectures', 'From'), ('From', 'earliest'), ('earliest', 'days'), ('days', 'pattern'), ('pattern', 'recognition22,23'), ('recognition22,23', ','), (',', 'aim'), ('aim', 'research-'), ('research-', 'ers'), ('ers', 'replace'), ('replace', 'hand-engineered'), ('hand-engineered', 'features'), ('features', 'trainable'), ('trainable', 'multilayer'), ('multilayer', 'networks'), ('networks', ','), (',', 'despite'), ('despite', 'simplicity'), ('simplicity', ','), (',', 'solution'), ('solution', 'widely'), ('widely', 'understood'), ('understood', 'mid'), ('mid', '1980s'), ('1980s', '.')]

>> Trigrams are: 
 [('Backpropagation', 'train', 'multilayer'), ('train', 'multilayer', 'architectures'), ('multilayer', 'architectures', 'From'), ('architectures', 'From', 'earliest'), ('From', 'earliest', 'days'), ('earliest', 'days', 'pattern'), ('days', 'pattern', 'recognition22,23'), ('pattern', 'recognition22,23', ','), ('recognition22,23', ',', 'aim'), (',', 'aim', 'research-'), ('aim', 'research-', 'ers'), ('research-', 'ers', 'replace'), ('ers', 'replace', 'hand-engineered'), ('replace', 'hand-engineered', 'features'), ('hand-engineered', 'features', 'trainable'), ('features', 'trainable', 'multilayer'), ('trainable', 'multilayer', 'networks'), ('multilayer', 'networks', ','), ('networks', ',', 'despite'), (',', 'despite', 'simplicity'), ('despite', 'simplicity', ','), ('simplicity', ',', 'solution'), (',', 'solution', 'widely'), ('solution', 'widely', 'understood'), ('widely', 'understood', 'mid'), ('understood', 'mid', '1980s'), ('mid', '1980s', '.')]

>> POS Tags are: 
 [('Backpropagation', 'NNP'), ('train', 'NN'), ('multilayer', 'NN'), ('architectures', 'NNS'), ('From', 'IN'), ('earliest', 'JJS'), ('days', 'NNS'), ('pattern', 'JJ'), ('recognition22,23', 'NN'), (',', ','), ('aim', 'JJ'), ('research-', 'JJ'), ('ers', 'NNS'), ('replace', 'VB'), ('hand-engineered', 'JJ'), ('features', 'NNS'), ('trainable', 'JJ'), ('multilayer', 'NN'), ('networks', 'NNS'), (',', ','), ('despite', 'IN'), ('simplicity', 'NN'), (',', ','), ('solution', 'NN'), ('widely', 'RB'), ('understood', 'VBD'), ('mid', 'JJ'), ('1980s', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Backpropagation train multilayer architectures', 'days', 'pattern recognition22,23', 'aim research- ers', 'hand-engineered features', 'trainable multilayer networks', 'simplicity', 'solution']

>> Named Entities are: 
 [('GPE', 'Backpropagation')] 

>> Stemming using Porter Stemmer: 
 [('Backpropagation', 'backpropag'), ('train', 'train'), ('multilayer', 'multilay'), ('architectures', 'architectur'), ('From', 'from'), ('earliest', 'earliest'), ('days', 'day'), ('pattern', 'pattern'), ('recognition22,23', 'recognition22,23'), (',', ','), ('aim', 'aim'), ('research-', 'research-'), ('ers', 'er'), ('replace', 'replac'), ('hand-engineered', 'hand-engin'), ('features', 'featur'), ('trainable', 'trainabl'), ('multilayer', 'multilay'), ('networks', 'network'), (',', ','), ('despite', 'despit'), ('simplicity', 'simplic'), (',', ','), ('solution', 'solut'), ('widely', 'wide'), ('understood', 'understood'), ('mid', 'mid'), ('1980s', '1980'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Backpropagation', 'backpropag'), ('train', 'train'), ('multilayer', 'multilay'), ('architectures', 'architectur'), ('From', 'from'), ('earliest', 'earliest'), ('days', 'day'), ('pattern', 'pattern'), ('recognition22,23', 'recognition22,23'), (',', ','), ('aim', 'aim'), ('research-', 'research-'), ('ers', 'er'), ('replace', 'replac'), ('hand-engineered', 'hand-engin'), ('features', 'featur'), ('trainable', 'trainabl'), ('multilayer', 'multilay'), ('networks', 'network'), (',', ','), ('despite', 'despit'), ('simplicity', 'simplic'), (',', ','), ('solution', 'solut'), ('widely', 'wide'), ('understood', 'understood'), ('mid', 'mid'), ('1980s', '1980s'), ('.', '.')]

>> Lemmatization: 
 [('Backpropagation', 'Backpropagation'), ('train', 'train'), ('multilayer', 'multilayer'), ('architectures', 'architecture'), ('From', 'From'), ('earliest', 'earliest'), ('days', 'day'), ('pattern', 'pattern'), ('recognition22,23', 'recognition22,23'), (',', ','), ('aim', 'aim'), ('research-', 'research-'), ('ers', 'er'), ('replace', 'replace'), ('hand-engineered', 'hand-engineered'), ('features', 'feature'), ('trainable', 'trainable'), ('multilayer', 'multilayer'), ('networks', 'network'), (',', ','), ('despite', 'despite'), ('simplicity', 'simplicity'), (',', ','), ('solution', 'solution'), ('widely', 'widely'), ('understood', 'understood'), ('mid', 'mid'), ('1980s', '1980s'), ('.', '.')]


------------------- Sentence 2 -------------------

As it turns out, multilayer  architectures can be trained by simple stochastic gradient descent.

>> Tokens are: 
 ['As', 'turns', ',', 'multilayer', 'architectures', 'trained', 'simple', 'stochastic', 'gradient', 'descent', '.']

>> Bigrams are: 
 [('As', 'turns'), ('turns', ','), (',', 'multilayer'), ('multilayer', 'architectures'), ('architectures', 'trained'), ('trained', 'simple'), ('simple', 'stochastic'), ('stochastic', 'gradient'), ('gradient', 'descent'), ('descent', '.')]

>> Trigrams are: 
 [('As', 'turns', ','), ('turns', ',', 'multilayer'), (',', 'multilayer', 'architectures'), ('multilayer', 'architectures', 'trained'), ('architectures', 'trained', 'simple'), ('trained', 'simple', 'stochastic'), ('simple', 'stochastic', 'gradient'), ('stochastic', 'gradient', 'descent'), ('gradient', 'descent', '.')]

>> POS Tags are: 
 [('As', 'IN'), ('turns', 'NNS'), (',', ','), ('multilayer', 'NN'), ('architectures', 'NNS'), ('trained', 'VBD'), ('simple', 'JJ'), ('stochastic', 'JJ'), ('gradient', 'NN'), ('descent', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['turns', 'multilayer architectures', 'simple stochastic gradient descent']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('As', 'as'), ('turns', 'turn'), (',', ','), ('multilayer', 'multilay'), ('architectures', 'architectur'), ('trained', 'train'), ('simple', 'simpl'), ('stochastic', 'stochast'), ('gradient', 'gradient'), ('descent', 'descent'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('As', 'as'), ('turns', 'turn'), (',', ','), ('multilayer', 'multilay'), ('architectures', 'architectur'), ('trained', 'train'), ('simple', 'simpl'), ('stochastic', 'stochast'), ('gradient', 'gradient'), ('descent', 'descent'), ('.', '.')]

>> Lemmatization: 
 [('As', 'As'), ('turns', 'turn'), (',', ','), ('multilayer', 'multilayer'), ('architectures', 'architecture'), ('trained', 'trained'), ('simple', 'simple'), ('stochastic', 'stochastic'), ('gradient', 'gradient'), ('descent', 'descent'), ('.', '.')]


------------------- Sentence 3 -------------------

As long as the modules are relatively smooth functions of their inputs  and of their internal weights, one can compute gradients using the  backpropagation procedure.

>> Tokens are: 
 ['As', 'long', 'modules', 'relatively', 'smooth', 'functions', 'inputs', 'internal', 'weights', ',', 'one', 'compute', 'gradients', 'using', 'backpropagation', 'procedure', '.']

>> Bigrams are: 
 [('As', 'long'), ('long', 'modules'), ('modules', 'relatively'), ('relatively', 'smooth'), ('smooth', 'functions'), ('functions', 'inputs'), ('inputs', 'internal'), ('internal', 'weights'), ('weights', ','), (',', 'one'), ('one', 'compute'), ('compute', 'gradients'), ('gradients', 'using'), ('using', 'backpropagation'), ('backpropagation', 'procedure'), ('procedure', '.')]

>> Trigrams are: 
 [('As', 'long', 'modules'), ('long', 'modules', 'relatively'), ('modules', 'relatively', 'smooth'), ('relatively', 'smooth', 'functions'), ('smooth', 'functions', 'inputs'), ('functions', 'inputs', 'internal'), ('inputs', 'internal', 'weights'), ('internal', 'weights', ','), ('weights', ',', 'one'), (',', 'one', 'compute'), ('one', 'compute', 'gradients'), ('compute', 'gradients', 'using'), ('gradients', 'using', 'backpropagation'), ('using', 'backpropagation', 'procedure'), ('backpropagation', 'procedure', '.')]

>> POS Tags are: 
 [('As', 'IN'), ('long', 'JJ'), ('modules', 'NNS'), ('relatively', 'RB'), ('smooth', 'JJ'), ('functions', 'NNS'), ('inputs', 'VBP'), ('internal', 'JJ'), ('weights', 'NNS'), (',', ','), ('one', 'CD'), ('compute', 'NN'), ('gradients', 'NNS'), ('using', 'VBG'), ('backpropagation', 'NN'), ('procedure', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['long modules', 'smooth functions', 'internal weights', 'compute gradients', 'backpropagation procedure']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('As', 'as'), ('long', 'long'), ('modules', 'modul'), ('relatively', 'rel'), ('smooth', 'smooth'), ('functions', 'function'), ('inputs', 'input'), ('internal', 'intern'), ('weights', 'weight'), (',', ','), ('one', 'one'), ('compute', 'comput'), ('gradients', 'gradient'), ('using', 'use'), ('backpropagation', 'backpropag'), ('procedure', 'procedur'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('As', 'as'), ('long', 'long'), ('modules', 'modul'), ('relatively', 'relat'), ('smooth', 'smooth'), ('functions', 'function'), ('inputs', 'input'), ('internal', 'intern'), ('weights', 'weight'), (',', ','), ('one', 'one'), ('compute', 'comput'), ('gradients', 'gradient'), ('using', 'use'), ('backpropagation', 'backpropag'), ('procedure', 'procedur'), ('.', '.')]

>> Lemmatization: 
 [('As', 'As'), ('long', 'long'), ('modules', 'module'), ('relatively', 'relatively'), ('smooth', 'smooth'), ('functions', 'function'), ('inputs', 'input'), ('internal', 'internal'), ('weights', 'weight'), (',', ','), ('one', 'one'), ('compute', 'compute'), ('gradients', 'gradient'), ('using', 'using'), ('backpropagation', 'backpropagation'), ('procedure', 'procedure'), ('.', '.')]


------------------- Sentence 4 -------------------

The idea that this could be done, and  that it worked, was discovered independently by several different  groups during the 1970s and 1980s24–27.

>> Tokens are: 
 ['The', 'idea', 'could', 'done', ',', 'worked', ',', 'discovered', 'independently', 'several', 'different', 'groups', '1970s', '1980s24–27', '.']

>> Bigrams are: 
 [('The', 'idea'), ('idea', 'could'), ('could', 'done'), ('done', ','), (',', 'worked'), ('worked', ','), (',', 'discovered'), ('discovered', 'independently'), ('independently', 'several'), ('several', 'different'), ('different', 'groups'), ('groups', '1970s'), ('1970s', '1980s24–27'), ('1980s24–27', '.')]

>> Trigrams are: 
 [('The', 'idea', 'could'), ('idea', 'could', 'done'), ('could', 'done', ','), ('done', ',', 'worked'), (',', 'worked', ','), ('worked', ',', 'discovered'), (',', 'discovered', 'independently'), ('discovered', 'independently', 'several'), ('independently', 'several', 'different'), ('several', 'different', 'groups'), ('different', 'groups', '1970s'), ('groups', '1970s', '1980s24–27'), ('1970s', '1980s24–27', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('idea', 'NN'), ('could', 'MD'), ('done', 'VBN'), (',', ','), ('worked', 'VBD'), (',', ','), ('discovered', 'VBN'), ('independently', 'RB'), ('several', 'JJ'), ('different', 'JJ'), ('groups', 'NNS'), ('1970s', 'CD'), ('1980s24–27', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['The idea', 'several different groups']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('idea', 'idea'), ('could', 'could'), ('done', 'done'), (',', ','), ('worked', 'work'), (',', ','), ('discovered', 'discov'), ('independently', 'independ'), ('several', 'sever'), ('different', 'differ'), ('groups', 'group'), ('1970s', '1970'), ('1980s24–27', '1980s24–27'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('idea', 'idea'), ('could', 'could'), ('done', 'done'), (',', ','), ('worked', 'work'), (',', ','), ('discovered', 'discov'), ('independently', 'independ'), ('several', 'sever'), ('different', 'differ'), ('groups', 'group'), ('1970s', '1970s'), ('1980s24–27', '1980s24–27'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('idea', 'idea'), ('could', 'could'), ('done', 'done'), (',', ','), ('worked', 'worked'), (',', ','), ('discovered', 'discovered'), ('independently', 'independently'), ('several', 'several'), ('different', 'different'), ('groups', 'group'), ('1970s', '1970s'), ('1980s24–27', '1980s24–27'), ('.', '.')]



========================================== PARAGRAPH 96 ===========================================

The backpropagation procedure to compute the gradient of an  objective function with respect to the weights of a multilayer stack  of modules is nothing more than a practical application of the chain  

------------------- Sentence 1 -------------------

The backpropagation procedure to compute the gradient of an  objective function with respect to the weights of a multilayer stack  of modules is nothing more than a practical application of the chain

>> Tokens are: 
 ['The', 'backpropagation', 'procedure', 'compute', 'gradient', 'objective', 'function', 'respect', 'weights', 'multilayer', 'stack', 'modules', 'nothing', 'practical', 'application', 'chain']

>> Bigrams are: 
 [('The', 'backpropagation'), ('backpropagation', 'procedure'), ('procedure', 'compute'), ('compute', 'gradient'), ('gradient', 'objective'), ('objective', 'function'), ('function', 'respect'), ('respect', 'weights'), ('weights', 'multilayer'), ('multilayer', 'stack'), ('stack', 'modules'), ('modules', 'nothing'), ('nothing', 'practical'), ('practical', 'application'), ('application', 'chain')]

>> Trigrams are: 
 [('The', 'backpropagation', 'procedure'), ('backpropagation', 'procedure', 'compute'), ('procedure', 'compute', 'gradient'), ('compute', 'gradient', 'objective'), ('gradient', 'objective', 'function'), ('objective', 'function', 'respect'), ('function', 'respect', 'weights'), ('respect', 'weights', 'multilayer'), ('weights', 'multilayer', 'stack'), ('multilayer', 'stack', 'modules'), ('stack', 'modules', 'nothing'), ('modules', 'nothing', 'practical'), ('nothing', 'practical', 'application'), ('practical', 'application', 'chain')]

>> POS Tags are: 
 [('The', 'DT'), ('backpropagation', 'NN'), ('procedure', 'NN'), ('compute', 'NN'), ('gradient', 'NN'), ('objective', 'JJ'), ('function', 'NN'), ('respect', 'NN'), ('weights', 'NNS'), ('multilayer', 'VBP'), ('stack', 'NN'), ('modules', 'NNS'), ('nothing', 'NN'), ('practical', 'JJ'), ('application', 'NN'), ('chain', 'NN')]

>> Noun Phrases are: 
 ['The backpropagation procedure compute gradient', 'objective function respect weights', 'stack modules nothing', 'practical application chain']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('backpropagation', 'backpropag'), ('procedure', 'procedur'), ('compute', 'comput'), ('gradient', 'gradient'), ('objective', 'object'), ('function', 'function'), ('respect', 'respect'), ('weights', 'weight'), ('multilayer', 'multilay'), ('stack', 'stack'), ('modules', 'modul'), ('nothing', 'noth'), ('practical', 'practic'), ('application', 'applic'), ('chain', 'chain')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('backpropagation', 'backpropag'), ('procedure', 'procedur'), ('compute', 'comput'), ('gradient', 'gradient'), ('objective', 'object'), ('function', 'function'), ('respect', 'respect'), ('weights', 'weight'), ('multilayer', 'multilay'), ('stack', 'stack'), ('modules', 'modul'), ('nothing', 'noth'), ('practical', 'practic'), ('application', 'applic'), ('chain', 'chain')]

>> Lemmatization: 
 [('The', 'The'), ('backpropagation', 'backpropagation'), ('procedure', 'procedure'), ('compute', 'compute'), ('gradient', 'gradient'), ('objective', 'objective'), ('function', 'function'), ('respect', 'respect'), ('weights', 'weight'), ('multilayer', 'multilayer'), ('stack', 'stack'), ('modules', 'module'), ('nothing', 'nothing'), ('practical', 'practical'), ('application', 'application'), ('chain', 'chain')]



========================================== PARAGRAPH 97 ===========================================

rule for derivatives. The key insight is that the derivative (or gradi- ent) of the objective with respect to the input of a module can be  computed by working backwards from the gradient with respect to  the output of that module (or the input of the subsequent module)  (Fig. 1). The backpropagation equation can be applied repeatedly to  propagate gradients through all modules, starting from the output  at the top (where the network produces its prediction) all the way to  the bottom (where the external input is fed). Once these gradients  have been computed, it is straightforward to compute the gradients  with respect to the weights of each module.  

------------------- Sentence 1 -------------------

rule for derivatives.

>> Tokens are: 
 ['rule', 'derivatives', '.']

>> Bigrams are: 
 [('rule', 'derivatives'), ('derivatives', '.')]

>> Trigrams are: 
 [('rule', 'derivatives', '.')]

>> POS Tags are: 
 [('rule', 'NN'), ('derivatives', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['rule derivatives']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('rule', 'rule'), ('derivatives', 'deriv'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('rule', 'rule'), ('derivatives', 'deriv'), ('.', '.')]

>> Lemmatization: 
 [('rule', 'rule'), ('derivatives', 'derivative'), ('.', '.')]


------------------- Sentence 2 -------------------

The key insight is that the derivative (or gradi- ent) of the objective with respect to the input of a module can be  computed by working backwards from the gradient with respect to  the output of that module (or the input of the subsequent module)  (Fig.

>> Tokens are: 
 ['The', 'key', 'insight', 'derivative', '(', 'gradi-', 'ent', ')', 'objective', 'respect', 'input', 'module', 'computed', 'working', 'backwards', 'gradient', 'respect', 'output', 'module', '(', 'input', 'subsequent', 'module', ')', '(', 'Fig', '.']

>> Bigrams are: 
 [('The', 'key'), ('key', 'insight'), ('insight', 'derivative'), ('derivative', '('), ('(', 'gradi-'), ('gradi-', 'ent'), ('ent', ')'), (')', 'objective'), ('objective', 'respect'), ('respect', 'input'), ('input', 'module'), ('module', 'computed'), ('computed', 'working'), ('working', 'backwards'), ('backwards', 'gradient'), ('gradient', 'respect'), ('respect', 'output'), ('output', 'module'), ('module', '('), ('(', 'input'), ('input', 'subsequent'), ('subsequent', 'module'), ('module', ')'), (')', '('), ('(', 'Fig'), ('Fig', '.')]

>> Trigrams are: 
 [('The', 'key', 'insight'), ('key', 'insight', 'derivative'), ('insight', 'derivative', '('), ('derivative', '(', 'gradi-'), ('(', 'gradi-', 'ent'), ('gradi-', 'ent', ')'), ('ent', ')', 'objective'), (')', 'objective', 'respect'), ('objective', 'respect', 'input'), ('respect', 'input', 'module'), ('input', 'module', 'computed'), ('module', 'computed', 'working'), ('computed', 'working', 'backwards'), ('working', 'backwards', 'gradient'), ('backwards', 'gradient', 'respect'), ('gradient', 'respect', 'output'), ('respect', 'output', 'module'), ('output', 'module', '('), ('module', '(', 'input'), ('(', 'input', 'subsequent'), ('input', 'subsequent', 'module'), ('subsequent', 'module', ')'), ('module', ')', '('), (')', '(', 'Fig'), ('(', 'Fig', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('key', 'JJ'), ('insight', 'JJ'), ('derivative', 'NN'), ('(', '('), ('gradi-', 'JJ'), ('ent', 'NN'), (')', ')'), ('objective', 'NN'), ('respect', 'NN'), ('input', 'NN'), ('module', 'NN'), ('computed', 'VBD'), ('working', 'VBG'), ('backwards', 'NNS'), ('gradient', 'JJ'), ('respect', 'NN'), ('output', 'NN'), ('module', 'NN'), ('(', '('), ('input', 'JJ'), ('subsequent', 'JJ'), ('module', 'NN'), (')', ')'), ('(', '('), ('Fig', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['The key insight derivative', 'gradi- ent', 'objective respect input module', 'backwards', 'gradient respect output module', 'input subsequent module', 'Fig']

>> Named Entities are: 
 [('ORGANIZATION', 'Fig')] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('key', 'key'), ('insight', 'insight'), ('derivative', 'deriv'), ('(', '('), ('gradi-', 'gradi-'), ('ent', 'ent'), (')', ')'), ('objective', 'object'), ('respect', 'respect'), ('input', 'input'), ('module', 'modul'), ('computed', 'comput'), ('working', 'work'), ('backwards', 'backward'), ('gradient', 'gradient'), ('respect', 'respect'), ('output', 'output'), ('module', 'modul'), ('(', '('), ('input', 'input'), ('subsequent', 'subsequ'), ('module', 'modul'), (')', ')'), ('(', '('), ('Fig', 'fig'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('key', 'key'), ('insight', 'insight'), ('derivative', 'deriv'), ('(', '('), ('gradi-', 'gradi-'), ('ent', 'ent'), (')', ')'), ('objective', 'object'), ('respect', 'respect'), ('input', 'input'), ('module', 'modul'), ('computed', 'comput'), ('working', 'work'), ('backwards', 'backward'), ('gradient', 'gradient'), ('respect', 'respect'), ('output', 'output'), ('module', 'modul'), ('(', '('), ('input', 'input'), ('subsequent', 'subsequ'), ('module', 'modul'), (')', ')'), ('(', '('), ('Fig', 'fig'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('key', 'key'), ('insight', 'insight'), ('derivative', 'derivative'), ('(', '('), ('gradi-', 'gradi-'), ('ent', 'ent'), (')', ')'), ('objective', 'objective'), ('respect', 'respect'), ('input', 'input'), ('module', 'module'), ('computed', 'computed'), ('working', 'working'), ('backwards', 'backwards'), ('gradient', 'gradient'), ('respect', 'respect'), ('output', 'output'), ('module', 'module'), ('(', '('), ('input', 'input'), ('subsequent', 'subsequent'), ('module', 'module'), (')', ')'), ('(', '('), ('Fig', 'Fig'), ('.', '.')]


------------------- Sentence 3 -------------------

1).

>> Tokens are: 
 ['1', ')', '.']

>> Bigrams are: 
 [('1', ')'), (')', '.')]

>> Trigrams are: 
 [('1', ')', '.')]

>> POS Tags are: 
 [('1', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('1', '1'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('1', '1'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('1', '1'), (')', ')'), ('.', '.')]


------------------- Sentence 4 -------------------

The backpropagation equation can be applied repeatedly to  propagate gradients through all modules, starting from the output  at the top (where the network produces its prediction) all the way to  the bottom (where the external input is fed).

>> Tokens are: 
 ['The', 'backpropagation', 'equation', 'applied', 'repeatedly', 'propagate', 'gradients', 'modules', ',', 'starting', 'output', 'top', '(', 'network', 'produces', 'prediction', ')', 'way', 'bottom', '(', 'external', 'input', 'fed', ')', '.']

>> Bigrams are: 
 [('The', 'backpropagation'), ('backpropagation', 'equation'), ('equation', 'applied'), ('applied', 'repeatedly'), ('repeatedly', 'propagate'), ('propagate', 'gradients'), ('gradients', 'modules'), ('modules', ','), (',', 'starting'), ('starting', 'output'), ('output', 'top'), ('top', '('), ('(', 'network'), ('network', 'produces'), ('produces', 'prediction'), ('prediction', ')'), (')', 'way'), ('way', 'bottom'), ('bottom', '('), ('(', 'external'), ('external', 'input'), ('input', 'fed'), ('fed', ')'), (')', '.')]

>> Trigrams are: 
 [('The', 'backpropagation', 'equation'), ('backpropagation', 'equation', 'applied'), ('equation', 'applied', 'repeatedly'), ('applied', 'repeatedly', 'propagate'), ('repeatedly', 'propagate', 'gradients'), ('propagate', 'gradients', 'modules'), ('gradients', 'modules', ','), ('modules', ',', 'starting'), (',', 'starting', 'output'), ('starting', 'output', 'top'), ('output', 'top', '('), ('top', '(', 'network'), ('(', 'network', 'produces'), ('network', 'produces', 'prediction'), ('produces', 'prediction', ')'), ('prediction', ')', 'way'), (')', 'way', 'bottom'), ('way', 'bottom', '('), ('bottom', '(', 'external'), ('(', 'external', 'input'), ('external', 'input', 'fed'), ('input', 'fed', ')'), ('fed', ')', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('backpropagation', 'NN'), ('equation', 'NN'), ('applied', 'VBD'), ('repeatedly', 'RB'), ('propagate', 'JJ'), ('gradients', 'NNS'), ('modules', 'NNS'), (',', ','), ('starting', 'VBG'), ('output', 'NN'), ('top', 'NN'), ('(', '('), ('network', 'NN'), ('produces', 'VBZ'), ('prediction', 'NN'), (')', ')'), ('way', 'NN'), ('bottom', 'NN'), ('(', '('), ('external', 'JJ'), ('input', 'NN'), ('fed', 'VBN'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['The backpropagation equation', 'propagate gradients modules', 'output top', 'network', 'prediction', 'way bottom', 'external input']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('backpropagation', 'backpropag'), ('equation', 'equat'), ('applied', 'appli'), ('repeatedly', 'repeatedli'), ('propagate', 'propag'), ('gradients', 'gradient'), ('modules', 'modul'), (',', ','), ('starting', 'start'), ('output', 'output'), ('top', 'top'), ('(', '('), ('network', 'network'), ('produces', 'produc'), ('prediction', 'predict'), (')', ')'), ('way', 'way'), ('bottom', 'bottom'), ('(', '('), ('external', 'extern'), ('input', 'input'), ('fed', 'fed'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('backpropagation', 'backpropag'), ('equation', 'equat'), ('applied', 'appli'), ('repeatedly', 'repeat'), ('propagate', 'propag'), ('gradients', 'gradient'), ('modules', 'modul'), (',', ','), ('starting', 'start'), ('output', 'output'), ('top', 'top'), ('(', '('), ('network', 'network'), ('produces', 'produc'), ('prediction', 'predict'), (')', ')'), ('way', 'way'), ('bottom', 'bottom'), ('(', '('), ('external', 'extern'), ('input', 'input'), ('fed', 'fed'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('backpropagation', 'backpropagation'), ('equation', 'equation'), ('applied', 'applied'), ('repeatedly', 'repeatedly'), ('propagate', 'propagate'), ('gradients', 'gradient'), ('modules', 'module'), (',', ','), ('starting', 'starting'), ('output', 'output'), ('top', 'top'), ('(', '('), ('network', 'network'), ('produces', 'produce'), ('prediction', 'prediction'), (')', ')'), ('way', 'way'), ('bottom', 'bottom'), ('(', '('), ('external', 'external'), ('input', 'input'), ('fed', 'fed'), (')', ')'), ('.', '.')]


------------------- Sentence 5 -------------------

Once these gradients  have been computed, it is straightforward to compute the gradients  with respect to the weights of each module.

>> Tokens are: 
 ['Once', 'gradients', 'computed', ',', 'straightforward', 'compute', 'gradients', 'respect', 'weights', 'module', '.']

>> Bigrams are: 
 [('Once', 'gradients'), ('gradients', 'computed'), ('computed', ','), (',', 'straightforward'), ('straightforward', 'compute'), ('compute', 'gradients'), ('gradients', 'respect'), ('respect', 'weights'), ('weights', 'module'), ('module', '.')]

>> Trigrams are: 
 [('Once', 'gradients', 'computed'), ('gradients', 'computed', ','), ('computed', ',', 'straightforward'), (',', 'straightforward', 'compute'), ('straightforward', 'compute', 'gradients'), ('compute', 'gradients', 'respect'), ('gradients', 'respect', 'weights'), ('respect', 'weights', 'module'), ('weights', 'module', '.')]

>> POS Tags are: 
 [('Once', 'RB'), ('gradients', 'NNS'), ('computed', 'VBD'), (',', ','), ('straightforward', 'JJ'), ('compute', 'NN'), ('gradients', 'NNS'), ('respect', 'VBP'), ('weights', 'NNS'), ('module', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['gradients', 'straightforward compute gradients', 'weights module']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Once', 'onc'), ('gradients', 'gradient'), ('computed', 'comput'), (',', ','), ('straightforward', 'straightforward'), ('compute', 'comput'), ('gradients', 'gradient'), ('respect', 'respect'), ('weights', 'weight'), ('module', 'modul'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Once', 'onc'), ('gradients', 'gradient'), ('computed', 'comput'), (',', ','), ('straightforward', 'straightforward'), ('compute', 'comput'), ('gradients', 'gradient'), ('respect', 'respect'), ('weights', 'weight'), ('module', 'modul'), ('.', '.')]

>> Lemmatization: 
 [('Once', 'Once'), ('gradients', 'gradient'), ('computed', 'computed'), (',', ','), ('straightforward', 'straightforward'), ('compute', 'compute'), ('gradients', 'gradient'), ('respect', 'respect'), ('weights', 'weight'), ('module', 'module'), ('.', '.')]



========================================== PARAGRAPH 98 ===========================================

Many applications of deep learning use feedforward neural net- work architectures (Fig. 1), which learn to map a fixed-size input  (for example, an image) to a fixed-size output (for example, a prob- ability for each of several categories). To go from one layer to the  next, a set of units compute a weighted sum of their inputs from the  previous layer and pass the result through a non-linear function. At  present, the most popular non-linear function is the rectified linear  unit (ReLU), which is simply the half-wave rectifier f(z) = max(z, 0).  In past decades, neural nets used smoother non-linearities, such as  tanh(z) or 1/(1 + exp(−z)), but the ReLU typically learns much faster  in networks with many layers, allowing training of a deep supervised  network without unsupervised pre-training28. Units that are not in  the input or output layer are conventionally called hidden units. The  hidden layers can be seen as distorting the input in a non-linear way  so that categories become linearly separable by the last layer (Fig. 1).  

------------------- Sentence 1 -------------------

Many applications of deep learning use feedforward neural net- work architectures (Fig.

>> Tokens are: 
 ['Many', 'applications', 'deep', 'learning', 'use', 'feedforward', 'neural', 'net-', 'work', 'architectures', '(', 'Fig', '.']

>> Bigrams are: 
 [('Many', 'applications'), ('applications', 'deep'), ('deep', 'learning'), ('learning', 'use'), ('use', 'feedforward'), ('feedforward', 'neural'), ('neural', 'net-'), ('net-', 'work'), ('work', 'architectures'), ('architectures', '('), ('(', 'Fig'), ('Fig', '.')]

>> Trigrams are: 
 [('Many', 'applications', 'deep'), ('applications', 'deep', 'learning'), ('deep', 'learning', 'use'), ('learning', 'use', 'feedforward'), ('use', 'feedforward', 'neural'), ('feedforward', 'neural', 'net-'), ('neural', 'net-', 'work'), ('net-', 'work', 'architectures'), ('work', 'architectures', '('), ('architectures', '(', 'Fig'), ('(', 'Fig', '.')]

>> POS Tags are: 
 [('Many', 'JJ'), ('applications', 'NNS'), ('deep', 'VBP'), ('learning', 'VBG'), ('use', 'NN'), ('feedforward', 'JJ'), ('neural', 'JJ'), ('net-', 'JJ'), ('work', 'NN'), ('architectures', 'NNS'), ('(', '('), ('Fig', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Many applications', 'use', 'feedforward neural net- work architectures', 'Fig']

>> Named Entities are: 
 [('ORGANIZATION', 'Fig')] 

>> Stemming using Porter Stemmer: 
 [('Many', 'mani'), ('applications', 'applic'), ('deep', 'deep'), ('learning', 'learn'), ('use', 'use'), ('feedforward', 'feedforward'), ('neural', 'neural'), ('net-', 'net-'), ('work', 'work'), ('architectures', 'architectur'), ('(', '('), ('Fig', 'fig'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Many', 'mani'), ('applications', 'applic'), ('deep', 'deep'), ('learning', 'learn'), ('use', 'use'), ('feedforward', 'feedforward'), ('neural', 'neural'), ('net-', 'net-'), ('work', 'work'), ('architectures', 'architectur'), ('(', '('), ('Fig', 'fig'), ('.', '.')]

>> Lemmatization: 
 [('Many', 'Many'), ('applications', 'application'), ('deep', 'deep'), ('learning', 'learning'), ('use', 'use'), ('feedforward', 'feedforward'), ('neural', 'neural'), ('net-', 'net-'), ('work', 'work'), ('architectures', 'architecture'), ('(', '('), ('Fig', 'Fig'), ('.', '.')]


------------------- Sentence 2 -------------------

1), which learn to map a fixed-size input  (for example, an image) to a fixed-size output (for example, a prob- ability for each of several categories).

>> Tokens are: 
 ['1', ')', ',', 'learn', 'map', 'fixed-size', 'input', '(', 'example', ',', 'image', ')', 'fixed-size', 'output', '(', 'example', ',', 'prob-', 'ability', 'several', 'categories', ')', '.']

>> Bigrams are: 
 [('1', ')'), (')', ','), (',', 'learn'), ('learn', 'map'), ('map', 'fixed-size'), ('fixed-size', 'input'), ('input', '('), ('(', 'example'), ('example', ','), (',', 'image'), ('image', ')'), (')', 'fixed-size'), ('fixed-size', 'output'), ('output', '('), ('(', 'example'), ('example', ','), (',', 'prob-'), ('prob-', 'ability'), ('ability', 'several'), ('several', 'categories'), ('categories', ')'), (')', '.')]

>> Trigrams are: 
 [('1', ')', ','), (')', ',', 'learn'), (',', 'learn', 'map'), ('learn', 'map', 'fixed-size'), ('map', 'fixed-size', 'input'), ('fixed-size', 'input', '('), ('input', '(', 'example'), ('(', 'example', ','), ('example', ',', 'image'), (',', 'image', ')'), ('image', ')', 'fixed-size'), (')', 'fixed-size', 'output'), ('fixed-size', 'output', '('), ('output', '(', 'example'), ('(', 'example', ','), ('example', ',', 'prob-'), (',', 'prob-', 'ability'), ('prob-', 'ability', 'several'), ('ability', 'several', 'categories'), ('several', 'categories', ')'), ('categories', ')', '.')]

>> POS Tags are: 
 [('1', 'CD'), (')', ')'), (',', ','), ('learn', 'JJ'), ('map', 'NN'), ('fixed-size', 'JJ'), ('input', 'NN'), ('(', '('), ('example', 'NN'), (',', ','), ('image', 'NN'), (')', ')'), ('fixed-size', 'NN'), ('output', 'NN'), ('(', '('), ('example', 'NN'), (',', ','), ('prob-', 'JJ'), ('ability', 'NN'), ('several', 'JJ'), ('categories', 'NNS'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['learn map', 'fixed-size input', 'example', 'image', 'fixed-size output', 'example', 'prob- ability', 'several categories']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('1', '1'), (')', ')'), (',', ','), ('learn', 'learn'), ('map', 'map'), ('fixed-size', 'fixed-s'), ('input', 'input'), ('(', '('), ('example', 'exampl'), (',', ','), ('image', 'imag'), (')', ')'), ('fixed-size', 'fixed-s'), ('output', 'output'), ('(', '('), ('example', 'exampl'), (',', ','), ('prob-', 'prob-'), ('ability', 'abil'), ('several', 'sever'), ('categories', 'categori'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('1', '1'), (')', ')'), (',', ','), ('learn', 'learn'), ('map', 'map'), ('fixed-size', 'fixed-s'), ('input', 'input'), ('(', '('), ('example', 'exampl'), (',', ','), ('image', 'imag'), (')', ')'), ('fixed-size', 'fixed-s'), ('output', 'output'), ('(', '('), ('example', 'exampl'), (',', ','), ('prob-', 'prob-'), ('ability', 'abil'), ('several', 'sever'), ('categories', 'categori'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('1', '1'), (')', ')'), (',', ','), ('learn', 'learn'), ('map', 'map'), ('fixed-size', 'fixed-size'), ('input', 'input'), ('(', '('), ('example', 'example'), (',', ','), ('image', 'image'), (')', ')'), ('fixed-size', 'fixed-size'), ('output', 'output'), ('(', '('), ('example', 'example'), (',', ','), ('prob-', 'prob-'), ('ability', 'ability'), ('several', 'several'), ('categories', 'category'), (')', ')'), ('.', '.')]


------------------- Sentence 3 -------------------

To go from one layer to the  next, a set of units compute a weighted sum of their inputs from the  previous layer and pass the result through a non-linear function.

>> Tokens are: 
 ['To', 'go', 'one', 'layer', 'next', ',', 'set', 'units', 'compute', 'weighted', 'sum', 'inputs', 'previous', 'layer', 'pass', 'result', 'non-linear', 'function', '.']

>> Bigrams are: 
 [('To', 'go'), ('go', 'one'), ('one', 'layer'), ('layer', 'next'), ('next', ','), (',', 'set'), ('set', 'units'), ('units', 'compute'), ('compute', 'weighted'), ('weighted', 'sum'), ('sum', 'inputs'), ('inputs', 'previous'), ('previous', 'layer'), ('layer', 'pass'), ('pass', 'result'), ('result', 'non-linear'), ('non-linear', 'function'), ('function', '.')]

>> Trigrams are: 
 [('To', 'go', 'one'), ('go', 'one', 'layer'), ('one', 'layer', 'next'), ('layer', 'next', ','), ('next', ',', 'set'), (',', 'set', 'units'), ('set', 'units', 'compute'), ('units', 'compute', 'weighted'), ('compute', 'weighted', 'sum'), ('weighted', 'sum', 'inputs'), ('sum', 'inputs', 'previous'), ('inputs', 'previous', 'layer'), ('previous', 'layer', 'pass'), ('layer', 'pass', 'result'), ('pass', 'result', 'non-linear'), ('result', 'non-linear', 'function'), ('non-linear', 'function', '.')]

>> POS Tags are: 
 [('To', 'TO'), ('go', 'VB'), ('one', 'CD'), ('layer', 'NN'), ('next', 'JJ'), (',', ','), ('set', 'VBN'), ('units', 'NNS'), ('compute', 'VBP'), ('weighted', 'JJ'), ('sum', 'NN'), ('inputs', 'NNS'), ('previous', 'JJ'), ('layer', 'NN'), ('pass', 'NN'), ('result', 'NN'), ('non-linear', 'JJ'), ('function', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['layer', 'units', 'weighted sum inputs', 'previous layer pass result', 'non-linear function']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('To', 'to'), ('go', 'go'), ('one', 'one'), ('layer', 'layer'), ('next', 'next'), (',', ','), ('set', 'set'), ('units', 'unit'), ('compute', 'comput'), ('weighted', 'weight'), ('sum', 'sum'), ('inputs', 'input'), ('previous', 'previou'), ('layer', 'layer'), ('pass', 'pass'), ('result', 'result'), ('non-linear', 'non-linear'), ('function', 'function'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('To', 'to'), ('go', 'go'), ('one', 'one'), ('layer', 'layer'), ('next', 'next'), (',', ','), ('set', 'set'), ('units', 'unit'), ('compute', 'comput'), ('weighted', 'weight'), ('sum', 'sum'), ('inputs', 'input'), ('previous', 'previous'), ('layer', 'layer'), ('pass', 'pass'), ('result', 'result'), ('non-linear', 'non-linear'), ('function', 'function'), ('.', '.')]

>> Lemmatization: 
 [('To', 'To'), ('go', 'go'), ('one', 'one'), ('layer', 'layer'), ('next', 'next'), (',', ','), ('set', 'set'), ('units', 'unit'), ('compute', 'compute'), ('weighted', 'weighted'), ('sum', 'sum'), ('inputs', 'input'), ('previous', 'previous'), ('layer', 'layer'), ('pass', 'pas'), ('result', 'result'), ('non-linear', 'non-linear'), ('function', 'function'), ('.', '.')]


------------------- Sentence 4 -------------------

At  present, the most popular non-linear function is the rectified linear  unit (ReLU), which is simply the half-wave rectifier f(z) = max(z, 0).

>> Tokens are: 
 ['At', 'present', ',', 'popular', 'non-linear', 'function', 'rectified', 'linear', 'unit', '(', 'ReLU', ')', ',', 'simply', 'half-wave', 'rectifier', 'f', '(', 'z', ')', '=', 'max', '(', 'z', ',', '0', ')', '.']

>> Bigrams are: 
 [('At', 'present'), ('present', ','), (',', 'popular'), ('popular', 'non-linear'), ('non-linear', 'function'), ('function', 'rectified'), ('rectified', 'linear'), ('linear', 'unit'), ('unit', '('), ('(', 'ReLU'), ('ReLU', ')'), (')', ','), (',', 'simply'), ('simply', 'half-wave'), ('half-wave', 'rectifier'), ('rectifier', 'f'), ('f', '('), ('(', 'z'), ('z', ')'), (')', '='), ('=', 'max'), ('max', '('), ('(', 'z'), ('z', ','), (',', '0'), ('0', ')'), (')', '.')]

>> Trigrams are: 
 [('At', 'present', ','), ('present', ',', 'popular'), (',', 'popular', 'non-linear'), ('popular', 'non-linear', 'function'), ('non-linear', 'function', 'rectified'), ('function', 'rectified', 'linear'), ('rectified', 'linear', 'unit'), ('linear', 'unit', '('), ('unit', '(', 'ReLU'), ('(', 'ReLU', ')'), ('ReLU', ')', ','), (')', ',', 'simply'), (',', 'simply', 'half-wave'), ('simply', 'half-wave', 'rectifier'), ('half-wave', 'rectifier', 'f'), ('rectifier', 'f', '('), ('f', '(', 'z'), ('(', 'z', ')'), ('z', ')', '='), (')', '=', 'max'), ('=', 'max', '('), ('max', '(', 'z'), ('(', 'z', ','), ('z', ',', '0'), (',', '0', ')'), ('0', ')', '.')]

>> POS Tags are: 
 [('At', 'IN'), ('present', 'JJ'), (',', ','), ('popular', 'JJ'), ('non-linear', 'JJ'), ('function', 'NN'), ('rectified', 'VBD'), ('linear', 'JJ'), ('unit', 'NN'), ('(', '('), ('ReLU', 'NNP'), (')', ')'), (',', ','), ('simply', 'RB'), ('half-wave', 'JJ'), ('rectifier', 'NN'), ('f', 'NN'), ('(', '('), ('z', 'NN'), (')', ')'), ('=', 'NN'), ('max', 'NN'), ('(', '('), ('z', 'NN'), (',', ','), ('0', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['popular non-linear function', 'linear unit', 'ReLU', 'half-wave rectifier f', 'z', '= max', 'z']

>> Named Entities are: 
 [('ORGANIZATION', 'ReLU')] 

>> Stemming using Porter Stemmer: 
 [('At', 'at'), ('present', 'present'), (',', ','), ('popular', 'popular'), ('non-linear', 'non-linear'), ('function', 'function'), ('rectified', 'rectifi'), ('linear', 'linear'), ('unit', 'unit'), ('(', '('), ('ReLU', 'relu'), (')', ')'), (',', ','), ('simply', 'simpli'), ('half-wave', 'half-wav'), ('rectifier', 'rectifi'), ('f', 'f'), ('(', '('), ('z', 'z'), (')', ')'), ('=', '='), ('max', 'max'), ('(', '('), ('z', 'z'), (',', ','), ('0', '0'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('At', 'at'), ('present', 'present'), (',', ','), ('popular', 'popular'), ('non-linear', 'non-linear'), ('function', 'function'), ('rectified', 'rectifi'), ('linear', 'linear'), ('unit', 'unit'), ('(', '('), ('ReLU', 'relu'), (')', ')'), (',', ','), ('simply', 'simpli'), ('half-wave', 'half-wav'), ('rectifier', 'rectifi'), ('f', 'f'), ('(', '('), ('z', 'z'), (')', ')'), ('=', '='), ('max', 'max'), ('(', '('), ('z', 'z'), (',', ','), ('0', '0'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('At', 'At'), ('present', 'present'), (',', ','), ('popular', 'popular'), ('non-linear', 'non-linear'), ('function', 'function'), ('rectified', 'rectified'), ('linear', 'linear'), ('unit', 'unit'), ('(', '('), ('ReLU', 'ReLU'), (')', ')'), (',', ','), ('simply', 'simply'), ('half-wave', 'half-wave'), ('rectifier', 'rectifier'), ('f', 'f'), ('(', '('), ('z', 'z'), (')', ')'), ('=', '='), ('max', 'max'), ('(', '('), ('z', 'z'), (',', ','), ('0', '0'), (')', ')'), ('.', '.')]


------------------- Sentence 5 -------------------

In past decades, neural nets used smoother non-linearities, such as  tanh(z) or 1/(1 + exp(−z)), but the ReLU typically learns much faster  in networks with many layers, allowing training of a deep supervised  network without unsupervised pre-training28.

>> Tokens are: 
 ['In', 'past', 'decades', ',', 'neural', 'nets', 'used', 'smoother', 'non-linearities', ',', 'tanh', '(', 'z', ')', '1/', '(', '1', '+', 'exp', '(', '−z', ')', ')', ',', 'ReLU', 'typically', 'learns', 'much', 'faster', 'networks', 'many', 'layers', ',', 'allowing', 'training', 'deep', 'supervised', 'network', 'without', 'unsupervised', 'pre-training28', '.']

>> Bigrams are: 
 [('In', 'past'), ('past', 'decades'), ('decades', ','), (',', 'neural'), ('neural', 'nets'), ('nets', 'used'), ('used', 'smoother'), ('smoother', 'non-linearities'), ('non-linearities', ','), (',', 'tanh'), ('tanh', '('), ('(', 'z'), ('z', ')'), (')', '1/'), ('1/', '('), ('(', '1'), ('1', '+'), ('+', 'exp'), ('exp', '('), ('(', '−z'), ('−z', ')'), (')', ')'), (')', ','), (',', 'ReLU'), ('ReLU', 'typically'), ('typically', 'learns'), ('learns', 'much'), ('much', 'faster'), ('faster', 'networks'), ('networks', 'many'), ('many', 'layers'), ('layers', ','), (',', 'allowing'), ('allowing', 'training'), ('training', 'deep'), ('deep', 'supervised'), ('supervised', 'network'), ('network', 'without'), ('without', 'unsupervised'), ('unsupervised', 'pre-training28'), ('pre-training28', '.')]

>> Trigrams are: 
 [('In', 'past', 'decades'), ('past', 'decades', ','), ('decades', ',', 'neural'), (',', 'neural', 'nets'), ('neural', 'nets', 'used'), ('nets', 'used', 'smoother'), ('used', 'smoother', 'non-linearities'), ('smoother', 'non-linearities', ','), ('non-linearities', ',', 'tanh'), (',', 'tanh', '('), ('tanh', '(', 'z'), ('(', 'z', ')'), ('z', ')', '1/'), (')', '1/', '('), ('1/', '(', '1'), ('(', '1', '+'), ('1', '+', 'exp'), ('+', 'exp', '('), ('exp', '(', '−z'), ('(', '−z', ')'), ('−z', ')', ')'), (')', ')', ','), (')', ',', 'ReLU'), (',', 'ReLU', 'typically'), ('ReLU', 'typically', 'learns'), ('typically', 'learns', 'much'), ('learns', 'much', 'faster'), ('much', 'faster', 'networks'), ('faster', 'networks', 'many'), ('networks', 'many', 'layers'), ('many', 'layers', ','), ('layers', ',', 'allowing'), (',', 'allowing', 'training'), ('allowing', 'training', 'deep'), ('training', 'deep', 'supervised'), ('deep', 'supervised', 'network'), ('supervised', 'network', 'without'), ('network', 'without', 'unsupervised'), ('without', 'unsupervised', 'pre-training28'), ('unsupervised', 'pre-training28', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('past', 'JJ'), ('decades', 'NNS'), (',', ','), ('neural', 'JJ'), ('nets', 'NNS'), ('used', 'VBD'), ('smoother', 'JJR'), ('non-linearities', 'NNS'), (',', ','), ('tanh', 'NN'), ('(', '('), ('z', 'NN'), (')', ')'), ('1/', 'CD'), ('(', '('), ('1', 'CD'), ('+', 'NN'), ('exp', 'NN'), ('(', '('), ('−z', 'NNP'), (')', ')'), (')', ')'), (',', ','), ('ReLU', 'NNP'), ('typically', 'RB'), ('learns', 'VBZ'), ('much', 'JJ'), ('faster', 'JJR'), ('networks', 'NNS'), ('many', 'JJ'), ('layers', 'NNS'), (',', ','), ('allowing', 'VBG'), ('training', 'VBG'), ('deep', 'JJ'), ('supervised', 'VBN'), ('network', 'NN'), ('without', 'IN'), ('unsupervised', 'JJ'), ('pre-training28', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['past decades', 'neural nets', 'non-linearities', 'tanh', 'z', '+ exp', '−z', 'ReLU', 'networks', 'many layers', 'network', 'unsupervised pre-training28']

>> Named Entities are: 
 [('ORGANIZATION', 'ReLU')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('past', 'past'), ('decades', 'decad'), (',', ','), ('neural', 'neural'), ('nets', 'net'), ('used', 'use'), ('smoother', 'smoother'), ('non-linearities', 'non-linear'), (',', ','), ('tanh', 'tanh'), ('(', '('), ('z', 'z'), (')', ')'), ('1/', '1/'), ('(', '('), ('1', '1'), ('+', '+'), ('exp', 'exp'), ('(', '('), ('−z', '−z'), (')', ')'), (')', ')'), (',', ','), ('ReLU', 'relu'), ('typically', 'typic'), ('learns', 'learn'), ('much', 'much'), ('faster', 'faster'), ('networks', 'network'), ('many', 'mani'), ('layers', 'layer'), (',', ','), ('allowing', 'allow'), ('training', 'train'), ('deep', 'deep'), ('supervised', 'supervis'), ('network', 'network'), ('without', 'without'), ('unsupervised', 'unsupervis'), ('pre-training28', 'pre-training28'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('past', 'past'), ('decades', 'decad'), (',', ','), ('neural', 'neural'), ('nets', 'net'), ('used', 'use'), ('smoother', 'smoother'), ('non-linearities', 'non-linear'), (',', ','), ('tanh', 'tanh'), ('(', '('), ('z', 'z'), (')', ')'), ('1/', '1/'), ('(', '('), ('1', '1'), ('+', '+'), ('exp', 'exp'), ('(', '('), ('−z', '−z'), (')', ')'), (')', ')'), (',', ','), ('ReLU', 'relu'), ('typically', 'typic'), ('learns', 'learn'), ('much', 'much'), ('faster', 'faster'), ('networks', 'network'), ('many', 'mani'), ('layers', 'layer'), (',', ','), ('allowing', 'allow'), ('training', 'train'), ('deep', 'deep'), ('supervised', 'supervis'), ('network', 'network'), ('without', 'without'), ('unsupervised', 'unsupervis'), ('pre-training28', 'pre-training28'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('past', 'past'), ('decades', 'decade'), (',', ','), ('neural', 'neural'), ('nets', 'net'), ('used', 'used'), ('smoother', 'smoother'), ('non-linearities', 'non-linearities'), (',', ','), ('tanh', 'tanh'), ('(', '('), ('z', 'z'), (')', ')'), ('1/', '1/'), ('(', '('), ('1', '1'), ('+', '+'), ('exp', 'exp'), ('(', '('), ('−z', '−z'), (')', ')'), (')', ')'), (',', ','), ('ReLU', 'ReLU'), ('typically', 'typically'), ('learns', 'learns'), ('much', 'much'), ('faster', 'faster'), ('networks', 'network'), ('many', 'many'), ('layers', 'layer'), (',', ','), ('allowing', 'allowing'), ('training', 'training'), ('deep', 'deep'), ('supervised', 'supervised'), ('network', 'network'), ('without', 'without'), ('unsupervised', 'unsupervised'), ('pre-training28', 'pre-training28'), ('.', '.')]


------------------- Sentence 6 -------------------

Units that are not in  the input or output layer are conventionally called hidden units.

>> Tokens are: 
 ['Units', 'input', 'output', 'layer', 'conventionally', 'called', 'hidden', 'units', '.']

>> Bigrams are: 
 [('Units', 'input'), ('input', 'output'), ('output', 'layer'), ('layer', 'conventionally'), ('conventionally', 'called'), ('called', 'hidden'), ('hidden', 'units'), ('units', '.')]

>> Trigrams are: 
 [('Units', 'input', 'output'), ('input', 'output', 'layer'), ('output', 'layer', 'conventionally'), ('layer', 'conventionally', 'called'), ('conventionally', 'called', 'hidden'), ('called', 'hidden', 'units'), ('hidden', 'units', '.')]

>> POS Tags are: 
 [('Units', 'NNS'), ('input', 'VBP'), ('output', 'NN'), ('layer', 'NN'), ('conventionally', 'RB'), ('called', 'VBD'), ('hidden', 'JJ'), ('units', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['Units', 'output layer', 'hidden units']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Units', 'unit'), ('input', 'input'), ('output', 'output'), ('layer', 'layer'), ('conventionally', 'convent'), ('called', 'call'), ('hidden', 'hidden'), ('units', 'unit'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Units', 'unit'), ('input', 'input'), ('output', 'output'), ('layer', 'layer'), ('conventionally', 'convent'), ('called', 'call'), ('hidden', 'hidden'), ('units', 'unit'), ('.', '.')]

>> Lemmatization: 
 [('Units', 'Units'), ('input', 'input'), ('output', 'output'), ('layer', 'layer'), ('conventionally', 'conventionally'), ('called', 'called'), ('hidden', 'hidden'), ('units', 'unit'), ('.', '.')]


------------------- Sentence 7 -------------------

The  hidden layers can be seen as distorting the input in a non-linear way  so that categories become linearly separable by the last layer (Fig.

>> Tokens are: 
 ['The', 'hidden', 'layers', 'seen', 'distorting', 'input', 'non-linear', 'way', 'categories', 'become', 'linearly', 'separable', 'last', 'layer', '(', 'Fig', '.']

>> Bigrams are: 
 [('The', 'hidden'), ('hidden', 'layers'), ('layers', 'seen'), ('seen', 'distorting'), ('distorting', 'input'), ('input', 'non-linear'), ('non-linear', 'way'), ('way', 'categories'), ('categories', 'become'), ('become', 'linearly'), ('linearly', 'separable'), ('separable', 'last'), ('last', 'layer'), ('layer', '('), ('(', 'Fig'), ('Fig', '.')]

>> Trigrams are: 
 [('The', 'hidden', 'layers'), ('hidden', 'layers', 'seen'), ('layers', 'seen', 'distorting'), ('seen', 'distorting', 'input'), ('distorting', 'input', 'non-linear'), ('input', 'non-linear', 'way'), ('non-linear', 'way', 'categories'), ('way', 'categories', 'become'), ('categories', 'become', 'linearly'), ('become', 'linearly', 'separable'), ('linearly', 'separable', 'last'), ('separable', 'last', 'layer'), ('last', 'layer', '('), ('layer', '(', 'Fig'), ('(', 'Fig', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('hidden', 'JJ'), ('layers', 'NNS'), ('seen', 'VBN'), ('distorting', 'VBG'), ('input', 'JJ'), ('non-linear', 'JJ'), ('way', 'NN'), ('categories', 'NNS'), ('become', 'VBP'), ('linearly', 'RB'), ('separable', 'JJ'), ('last', 'JJ'), ('layer', 'NN'), ('(', '('), ('Fig', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['The hidden layers', 'input non-linear way categories', 'separable last layer', 'Fig']

>> Named Entities are: 
 [('ORGANIZATION', 'Fig')] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('hidden', 'hidden'), ('layers', 'layer'), ('seen', 'seen'), ('distorting', 'distort'), ('input', 'input'), ('non-linear', 'non-linear'), ('way', 'way'), ('categories', 'categori'), ('become', 'becom'), ('linearly', 'linearli'), ('separable', 'separ'), ('last', 'last'), ('layer', 'layer'), ('(', '('), ('Fig', 'fig'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('hidden', 'hidden'), ('layers', 'layer'), ('seen', 'seen'), ('distorting', 'distort'), ('input', 'input'), ('non-linear', 'non-linear'), ('way', 'way'), ('categories', 'categori'), ('become', 'becom'), ('linearly', 'linear'), ('separable', 'separ'), ('last', 'last'), ('layer', 'layer'), ('(', '('), ('Fig', 'fig'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('hidden', 'hidden'), ('layers', 'layer'), ('seen', 'seen'), ('distorting', 'distorting'), ('input', 'input'), ('non-linear', 'non-linear'), ('way', 'way'), ('categories', 'category'), ('become', 'become'), ('linearly', 'linearly'), ('separable', 'separable'), ('last', 'last'), ('layer', 'layer'), ('(', '('), ('Fig', 'Fig'), ('.', '.')]


------------------- Sentence 8 -------------------

1).

>> Tokens are: 
 ['1', ')', '.']

>> Bigrams are: 
 [('1', ')'), (')', '.')]

>> Trigrams are: 
 [('1', ')', '.')]

>> POS Tags are: 
 [('1', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('1', '1'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('1', '1'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('1', '1'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 99 ===========================================

In the late 1990s, neural nets and backpropagation were largely  forsaken by the machine-learning community and ignored by the  computer-vision and speech-recognition communities. It was widely  thought that learning useful, multistage, feature extractors with lit- tle prior knowledge was infeasible. In particular, it was commonly  thought that simple gradient descent would get trapped in poor local  minima — weight configurations for which no small change would  reduce the average error.  

------------------- Sentence 1 -------------------

In the late 1990s, neural nets and backpropagation were largely  forsaken by the machine-learning community and ignored by the  computer-vision and speech-recognition communities.

>> Tokens are: 
 ['In', 'late', '1990s', ',', 'neural', 'nets', 'backpropagation', 'largely', 'forsaken', 'machine-learning', 'community', 'ignored', 'computer-vision', 'speech-recognition', 'communities', '.']

>> Bigrams are: 
 [('In', 'late'), ('late', '1990s'), ('1990s', ','), (',', 'neural'), ('neural', 'nets'), ('nets', 'backpropagation'), ('backpropagation', 'largely'), ('largely', 'forsaken'), ('forsaken', 'machine-learning'), ('machine-learning', 'community'), ('community', 'ignored'), ('ignored', 'computer-vision'), ('computer-vision', 'speech-recognition'), ('speech-recognition', 'communities'), ('communities', '.')]

>> Trigrams are: 
 [('In', 'late', '1990s'), ('late', '1990s', ','), ('1990s', ',', 'neural'), (',', 'neural', 'nets'), ('neural', 'nets', 'backpropagation'), ('nets', 'backpropagation', 'largely'), ('backpropagation', 'largely', 'forsaken'), ('largely', 'forsaken', 'machine-learning'), ('forsaken', 'machine-learning', 'community'), ('machine-learning', 'community', 'ignored'), ('community', 'ignored', 'computer-vision'), ('ignored', 'computer-vision', 'speech-recognition'), ('computer-vision', 'speech-recognition', 'communities'), ('speech-recognition', 'communities', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('late', 'JJ'), ('1990s', 'CD'), (',', ','), ('neural', 'JJ'), ('nets', 'NNS'), ('backpropagation', 'VBP'), ('largely', 'RB'), ('forsaken', 'JJ'), ('machine-learning', 'JJ'), ('community', 'NN'), ('ignored', 'VBN'), ('computer-vision', 'JJ'), ('speech-recognition', 'NN'), ('communities', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['neural nets', 'forsaken machine-learning community', 'computer-vision speech-recognition communities']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('late', 'late'), ('1990s', '1990'), (',', ','), ('neural', 'neural'), ('nets', 'net'), ('backpropagation', 'backpropag'), ('largely', 'larg'), ('forsaken', 'forsaken'), ('machine-learning', 'machine-learn'), ('community', 'commun'), ('ignored', 'ignor'), ('computer-vision', 'computer-vis'), ('speech-recognition', 'speech-recognit'), ('communities', 'commun'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('late', 'late'), ('1990s', '1990s'), (',', ','), ('neural', 'neural'), ('nets', 'net'), ('backpropagation', 'backpropag'), ('largely', 'larg'), ('forsaken', 'forsaken'), ('machine-learning', 'machine-learn'), ('community', 'communiti'), ('ignored', 'ignor'), ('computer-vision', 'computer-vis'), ('speech-recognition', 'speech-recognit'), ('communities', 'communiti'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('late', 'late'), ('1990s', '1990s'), (',', ','), ('neural', 'neural'), ('nets', 'net'), ('backpropagation', 'backpropagation'), ('largely', 'largely'), ('forsaken', 'forsaken'), ('machine-learning', 'machine-learning'), ('community', 'community'), ('ignored', 'ignored'), ('computer-vision', 'computer-vision'), ('speech-recognition', 'speech-recognition'), ('communities', 'community'), ('.', '.')]


------------------- Sentence 2 -------------------

It was widely  thought that learning useful, multistage, feature extractors with lit- tle prior knowledge was infeasible.

>> Tokens are: 
 ['It', 'widely', 'thought', 'learning', 'useful', ',', 'multistage', ',', 'feature', 'extractors', 'lit-', 'tle', 'prior', 'knowledge', 'infeasible', '.']

>> Bigrams are: 
 [('It', 'widely'), ('widely', 'thought'), ('thought', 'learning'), ('learning', 'useful'), ('useful', ','), (',', 'multistage'), ('multistage', ','), (',', 'feature'), ('feature', 'extractors'), ('extractors', 'lit-'), ('lit-', 'tle'), ('tle', 'prior'), ('prior', 'knowledge'), ('knowledge', 'infeasible'), ('infeasible', '.')]

>> Trigrams are: 
 [('It', 'widely', 'thought'), ('widely', 'thought', 'learning'), ('thought', 'learning', 'useful'), ('learning', 'useful', ','), ('useful', ',', 'multistage'), (',', 'multistage', ','), ('multistage', ',', 'feature'), (',', 'feature', 'extractors'), ('feature', 'extractors', 'lit-'), ('extractors', 'lit-', 'tle'), ('lit-', 'tle', 'prior'), ('tle', 'prior', 'knowledge'), ('prior', 'knowledge', 'infeasible'), ('knowledge', 'infeasible', '.')]

>> POS Tags are: 
 [('It', 'PRP'), ('widely', 'RB'), ('thought', 'VBD'), ('learning', 'VBG'), ('useful', 'JJ'), (',', ','), ('multistage', 'NN'), (',', ','), ('feature', 'JJ'), ('extractors', 'NNS'), ('lit-', 'JJ'), ('tle', 'JJ'), ('prior', 'JJ'), ('knowledge', 'NN'), ('infeasible', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['multistage', 'feature extractors', 'lit- tle prior knowledge infeasible']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('It', 'it'), ('widely', 'wide'), ('thought', 'thought'), ('learning', 'learn'), ('useful', 'use'), (',', ','), ('multistage', 'multistag'), (',', ','), ('feature', 'featur'), ('extractors', 'extractor'), ('lit-', 'lit-'), ('tle', 'tle'), ('prior', 'prior'), ('knowledge', 'knowledg'), ('infeasible', 'infeas'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('It', 'it'), ('widely', 'wide'), ('thought', 'thought'), ('learning', 'learn'), ('useful', 'use'), (',', ','), ('multistage', 'multistag'), (',', ','), ('feature', 'featur'), ('extractors', 'extractor'), ('lit-', 'lit-'), ('tle', 'tle'), ('prior', 'prior'), ('knowledge', 'knowledg'), ('infeasible', 'infeas'), ('.', '.')]

>> Lemmatization: 
 [('It', 'It'), ('widely', 'widely'), ('thought', 'thought'), ('learning', 'learning'), ('useful', 'useful'), (',', ','), ('multistage', 'multistage'), (',', ','), ('feature', 'feature'), ('extractors', 'extractor'), ('lit-', 'lit-'), ('tle', 'tle'), ('prior', 'prior'), ('knowledge', 'knowledge'), ('infeasible', 'infeasible'), ('.', '.')]


------------------- Sentence 3 -------------------

In particular, it was commonly  thought that simple gradient descent would get trapped in poor local  minima — weight configurations for which no small change would  reduce the average error.

>> Tokens are: 
 ['In', 'particular', ',', 'commonly', 'thought', 'simple', 'gradient', 'descent', 'would', 'get', 'trapped', 'poor', 'local', 'minima', '—', 'weight', 'configurations', 'small', 'change', 'would', 'reduce', 'average', 'error', '.']

>> Bigrams are: 
 [('In', 'particular'), ('particular', ','), (',', 'commonly'), ('commonly', 'thought'), ('thought', 'simple'), ('simple', 'gradient'), ('gradient', 'descent'), ('descent', 'would'), ('would', 'get'), ('get', 'trapped'), ('trapped', 'poor'), ('poor', 'local'), ('local', 'minima'), ('minima', '—'), ('—', 'weight'), ('weight', 'configurations'), ('configurations', 'small'), ('small', 'change'), ('change', 'would'), ('would', 'reduce'), ('reduce', 'average'), ('average', 'error'), ('error', '.')]

>> Trigrams are: 
 [('In', 'particular', ','), ('particular', ',', 'commonly'), (',', 'commonly', 'thought'), ('commonly', 'thought', 'simple'), ('thought', 'simple', 'gradient'), ('simple', 'gradient', 'descent'), ('gradient', 'descent', 'would'), ('descent', 'would', 'get'), ('would', 'get', 'trapped'), ('get', 'trapped', 'poor'), ('trapped', 'poor', 'local'), ('poor', 'local', 'minima'), ('local', 'minima', '—'), ('minima', '—', 'weight'), ('—', 'weight', 'configurations'), ('weight', 'configurations', 'small'), ('configurations', 'small', 'change'), ('small', 'change', 'would'), ('change', 'would', 'reduce'), ('would', 'reduce', 'average'), ('reduce', 'average', 'error'), ('average', 'error', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('particular', 'JJ'), (',', ','), ('commonly', 'RB'), ('thought', 'VBD'), ('simple', 'JJ'), ('gradient', 'JJ'), ('descent', 'NN'), ('would', 'MD'), ('get', 'VB'), ('trapped', 'VBN'), ('poor', 'JJ'), ('local', 'JJ'), ('minima', 'NN'), ('—', 'NNP'), ('weight', 'VBD'), ('configurations', 'NNS'), ('small', 'JJ'), ('change', 'NN'), ('would', 'MD'), ('reduce', 'VB'), ('average', 'JJ'), ('error', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['simple gradient descent', 'poor local minima —', 'configurations', 'small change', 'average error']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('particular', 'particular'), (',', ','), ('commonly', 'commonli'), ('thought', 'thought'), ('simple', 'simpl'), ('gradient', 'gradient'), ('descent', 'descent'), ('would', 'would'), ('get', 'get'), ('trapped', 'trap'), ('poor', 'poor'), ('local', 'local'), ('minima', 'minima'), ('—', '—'), ('weight', 'weight'), ('configurations', 'configur'), ('small', 'small'), ('change', 'chang'), ('would', 'would'), ('reduce', 'reduc'), ('average', 'averag'), ('error', 'error'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('particular', 'particular'), (',', ','), ('commonly', 'common'), ('thought', 'thought'), ('simple', 'simpl'), ('gradient', 'gradient'), ('descent', 'descent'), ('would', 'would'), ('get', 'get'), ('trapped', 'trap'), ('poor', 'poor'), ('local', 'local'), ('minima', 'minima'), ('—', '—'), ('weight', 'weight'), ('configurations', 'configur'), ('small', 'small'), ('change', 'chang'), ('would', 'would'), ('reduce', 'reduc'), ('average', 'averag'), ('error', 'error'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('particular', 'particular'), (',', ','), ('commonly', 'commonly'), ('thought', 'thought'), ('simple', 'simple'), ('gradient', 'gradient'), ('descent', 'descent'), ('would', 'would'), ('get', 'get'), ('trapped', 'trapped'), ('poor', 'poor'), ('local', 'local'), ('minima', 'minimum'), ('—', '—'), ('weight', 'weight'), ('configurations', 'configuration'), ('small', 'small'), ('change', 'change'), ('would', 'would'), ('reduce', 'reduce'), ('average', 'average'), ('error', 'error'), ('.', '.')]



========================================== PARAGRAPH 100 ===========================================

In practice, poor local minima are rarely a problem with large net- works. Regardless of the initial conditions, the system nearly always  reaches solutions of very similar quality. Recent theoretical and  empirical results strongly suggest that local minima are not a serious  issue in general. Instead, the landscape is packed with a combinato- rially large number of saddle points where the gradient is zero, and  the surface curves up in most dimensions and curves down in the  

------------------- Sentence 1 -------------------

In practice, poor local minima are rarely a problem with large net- works.

>> Tokens are: 
 ['In', 'practice', ',', 'poor', 'local', 'minima', 'rarely', 'problem', 'large', 'net-', 'works', '.']

>> Bigrams are: 
 [('In', 'practice'), ('practice', ','), (',', 'poor'), ('poor', 'local'), ('local', 'minima'), ('minima', 'rarely'), ('rarely', 'problem'), ('problem', 'large'), ('large', 'net-'), ('net-', 'works'), ('works', '.')]

>> Trigrams are: 
 [('In', 'practice', ','), ('practice', ',', 'poor'), (',', 'poor', 'local'), ('poor', 'local', 'minima'), ('local', 'minima', 'rarely'), ('minima', 'rarely', 'problem'), ('rarely', 'problem', 'large'), ('problem', 'large', 'net-'), ('large', 'net-', 'works'), ('net-', 'works', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('practice', 'NN'), (',', ','), ('poor', 'JJ'), ('local', 'JJ'), ('minima', 'NN'), ('rarely', 'RB'), ('problem', 'NN'), ('large', 'JJ'), ('net-', 'JJ'), ('works', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['practice', 'poor local minima', 'problem', 'large net- works']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('practice', 'practic'), (',', ','), ('poor', 'poor'), ('local', 'local'), ('minima', 'minima'), ('rarely', 'rare'), ('problem', 'problem'), ('large', 'larg'), ('net-', 'net-'), ('works', 'work'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('practice', 'practic'), (',', ','), ('poor', 'poor'), ('local', 'local'), ('minima', 'minima'), ('rarely', 'rare'), ('problem', 'problem'), ('large', 'larg'), ('net-', 'net-'), ('works', 'work'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('practice', 'practice'), (',', ','), ('poor', 'poor'), ('local', 'local'), ('minima', 'minimum'), ('rarely', 'rarely'), ('problem', 'problem'), ('large', 'large'), ('net-', 'net-'), ('works', 'work'), ('.', '.')]


------------------- Sentence 2 -------------------

Regardless of the initial conditions, the system nearly always  reaches solutions of very similar quality.

>> Tokens are: 
 ['Regardless', 'initial', 'conditions', ',', 'system', 'nearly', 'always', 'reaches', 'solutions', 'similar', 'quality', '.']

>> Bigrams are: 
 [('Regardless', 'initial'), ('initial', 'conditions'), ('conditions', ','), (',', 'system'), ('system', 'nearly'), ('nearly', 'always'), ('always', 'reaches'), ('reaches', 'solutions'), ('solutions', 'similar'), ('similar', 'quality'), ('quality', '.')]

>> Trigrams are: 
 [('Regardless', 'initial', 'conditions'), ('initial', 'conditions', ','), ('conditions', ',', 'system'), (',', 'system', 'nearly'), ('system', 'nearly', 'always'), ('nearly', 'always', 'reaches'), ('always', 'reaches', 'solutions'), ('reaches', 'solutions', 'similar'), ('solutions', 'similar', 'quality'), ('similar', 'quality', '.')]

>> POS Tags are: 
 [('Regardless', 'RB'), ('initial', 'JJ'), ('conditions', 'NNS'), (',', ','), ('system', 'NN'), ('nearly', 'RB'), ('always', 'RB'), ('reaches', 'VBZ'), ('solutions', 'NNS'), ('similar', 'JJ'), ('quality', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['initial conditions', 'system', 'solutions', 'similar quality']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Regardless', 'regardless'), ('initial', 'initi'), ('conditions', 'condit'), (',', ','), ('system', 'system'), ('nearly', 'nearli'), ('always', 'alway'), ('reaches', 'reach'), ('solutions', 'solut'), ('similar', 'similar'), ('quality', 'qualiti'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Regardless', 'regardless'), ('initial', 'initi'), ('conditions', 'condit'), (',', ','), ('system', 'system'), ('nearly', 'near'), ('always', 'alway'), ('reaches', 'reach'), ('solutions', 'solut'), ('similar', 'similar'), ('quality', 'qualiti'), ('.', '.')]

>> Lemmatization: 
 [('Regardless', 'Regardless'), ('initial', 'initial'), ('conditions', 'condition'), (',', ','), ('system', 'system'), ('nearly', 'nearly'), ('always', 'always'), ('reaches', 'reach'), ('solutions', 'solution'), ('similar', 'similar'), ('quality', 'quality'), ('.', '.')]


------------------- Sentence 3 -------------------

Recent theoretical and  empirical results strongly suggest that local minima are not a serious  issue in general.

>> Tokens are: 
 ['Recent', 'theoretical', 'empirical', 'results', 'strongly', 'suggest', 'local', 'minima', 'serious', 'issue', 'general', '.']

>> Bigrams are: 
 [('Recent', 'theoretical'), ('theoretical', 'empirical'), ('empirical', 'results'), ('results', 'strongly'), ('strongly', 'suggest'), ('suggest', 'local'), ('local', 'minima'), ('minima', 'serious'), ('serious', 'issue'), ('issue', 'general'), ('general', '.')]

>> Trigrams are: 
 [('Recent', 'theoretical', 'empirical'), ('theoretical', 'empirical', 'results'), ('empirical', 'results', 'strongly'), ('results', 'strongly', 'suggest'), ('strongly', 'suggest', 'local'), ('suggest', 'local', 'minima'), ('local', 'minima', 'serious'), ('minima', 'serious', 'issue'), ('serious', 'issue', 'general'), ('issue', 'general', '.')]

>> POS Tags are: 
 [('Recent', 'JJ'), ('theoretical', 'JJ'), ('empirical', 'JJ'), ('results', 'NNS'), ('strongly', 'RB'), ('suggest', 'VBP'), ('local', 'JJ'), ('minima', 'NN'), ('serious', 'JJ'), ('issue', 'NN'), ('general', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Recent theoretical empirical results', 'local minima', 'serious issue general']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Recent', 'recent'), ('theoretical', 'theoret'), ('empirical', 'empir'), ('results', 'result'), ('strongly', 'strongli'), ('suggest', 'suggest'), ('local', 'local'), ('minima', 'minima'), ('serious', 'seriou'), ('issue', 'issu'), ('general', 'gener'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Recent', 'recent'), ('theoretical', 'theoret'), ('empirical', 'empir'), ('results', 'result'), ('strongly', 'strong'), ('suggest', 'suggest'), ('local', 'local'), ('minima', 'minima'), ('serious', 'serious'), ('issue', 'issu'), ('general', 'general'), ('.', '.')]

>> Lemmatization: 
 [('Recent', 'Recent'), ('theoretical', 'theoretical'), ('empirical', 'empirical'), ('results', 'result'), ('strongly', 'strongly'), ('suggest', 'suggest'), ('local', 'local'), ('minima', 'minimum'), ('serious', 'serious'), ('issue', 'issue'), ('general', 'general'), ('.', '.')]


------------------- Sentence 4 -------------------

Instead, the landscape is packed with a combinato- rially large number of saddle points where the gradient is zero, and  the surface curves up in most dimensions and curves down in the

>> Tokens are: 
 ['Instead', ',', 'landscape', 'packed', 'combinato-', 'rially', 'large', 'number', 'saddle', 'points', 'gradient', 'zero', ',', 'surface', 'curves', 'dimensions', 'curves']

>> Bigrams are: 
 [('Instead', ','), (',', 'landscape'), ('landscape', 'packed'), ('packed', 'combinato-'), ('combinato-', 'rially'), ('rially', 'large'), ('large', 'number'), ('number', 'saddle'), ('saddle', 'points'), ('points', 'gradient'), ('gradient', 'zero'), ('zero', ','), (',', 'surface'), ('surface', 'curves'), ('curves', 'dimensions'), ('dimensions', 'curves')]

>> Trigrams are: 
 [('Instead', ',', 'landscape'), (',', 'landscape', 'packed'), ('landscape', 'packed', 'combinato-'), ('packed', 'combinato-', 'rially'), ('combinato-', 'rially', 'large'), ('rially', 'large', 'number'), ('large', 'number', 'saddle'), ('number', 'saddle', 'points'), ('saddle', 'points', 'gradient'), ('points', 'gradient', 'zero'), ('gradient', 'zero', ','), ('zero', ',', 'surface'), (',', 'surface', 'curves'), ('surface', 'curves', 'dimensions'), ('curves', 'dimensions', 'curves')]

>> POS Tags are: 
 [('Instead', 'RB'), (',', ','), ('landscape', 'NN'), ('packed', 'VBD'), ('combinato-', 'JJ'), ('rially', 'RB'), ('large', 'JJ'), ('number', 'NN'), ('saddle', 'JJ'), ('points', 'NNS'), ('gradient', 'NN'), ('zero', 'CD'), (',', ','), ('surface', 'NN'), ('curves', 'NNS'), ('dimensions', 'NNS'), ('curves', 'NNS')]

>> Noun Phrases are: 
 ['landscape', 'large number', 'saddle points gradient', 'surface curves dimensions curves']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Instead', 'instead'), (',', ','), ('landscape', 'landscap'), ('packed', 'pack'), ('combinato-', 'combinato-'), ('rially', 'rialli'), ('large', 'larg'), ('number', 'number'), ('saddle', 'saddl'), ('points', 'point'), ('gradient', 'gradient'), ('zero', 'zero'), (',', ','), ('surface', 'surfac'), ('curves', 'curv'), ('dimensions', 'dimens'), ('curves', 'curv')]

>> Stemming using Snowball Stemmer: 
 [('Instead', 'instead'), (',', ','), ('landscape', 'landscap'), ('packed', 'pack'), ('combinato-', 'combinato-'), ('rially', 'rialli'), ('large', 'larg'), ('number', 'number'), ('saddle', 'saddl'), ('points', 'point'), ('gradient', 'gradient'), ('zero', 'zero'), (',', ','), ('surface', 'surfac'), ('curves', 'curv'), ('dimensions', 'dimens'), ('curves', 'curv')]

>> Lemmatization: 
 [('Instead', 'Instead'), (',', ','), ('landscape', 'landscape'), ('packed', 'packed'), ('combinato-', 'combinato-'), ('rially', 'rially'), ('large', 'large'), ('number', 'number'), ('saddle', 'saddle'), ('points', 'point'), ('gradient', 'gradient'), ('zero', 'zero'), (',', ','), ('surface', 'surface'), ('curves', 'curve'), ('dimensions', 'dimension'), ('curves', 'curve')]



========================================== PARAGRAPH 101 ===========================================

Figure 2 | Inside a convolutional network. The outputs (not the filters)  of each layer (horizontally) of a typical convolutional network architecture  applied to the image of a Samoyed dog (bottom left; and RGB (red, green,  blue) inputs, bottom right). Each rectangular image is a feature map  

------------------- Sentence 1 -------------------

Figure 2 | Inside a convolutional network.

>> Tokens are: 
 ['Figure', '2', '|', 'Inside', 'convolutional', 'network', '.']

>> Bigrams are: 
 [('Figure', '2'), ('2', '|'), ('|', 'Inside'), ('Inside', 'convolutional'), ('convolutional', 'network'), ('network', '.')]

>> Trigrams are: 
 [('Figure', '2', '|'), ('2', '|', 'Inside'), ('|', 'Inside', 'convolutional'), ('Inside', 'convolutional', 'network'), ('convolutional', 'network', '.')]

>> POS Tags are: 
 [('Figure', 'NN'), ('2', 'CD'), ('|', 'NN'), ('Inside', 'NNP'), ('convolutional', 'JJ'), ('network', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Figure', '| Inside', 'convolutional network']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Figure', 'figur'), ('2', '2'), ('|', '|'), ('Inside', 'insid'), ('convolutional', 'convolut'), ('network', 'network'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Figure', 'figur'), ('2', '2'), ('|', '|'), ('Inside', 'insid'), ('convolutional', 'convolut'), ('network', 'network'), ('.', '.')]

>> Lemmatization: 
 [('Figure', 'Figure'), ('2', '2'), ('|', '|'), ('Inside', 'Inside'), ('convolutional', 'convolutional'), ('network', 'network'), ('.', '.')]


------------------- Sentence 2 -------------------

The outputs (not the filters)  of each layer (horizontally) of a typical convolutional network architecture  applied to the image of a Samoyed dog (bottom left; and RGB (red, green,  blue) inputs, bottom right).

>> Tokens are: 
 ['The', 'outputs', '(', 'filters', ')', 'layer', '(', 'horizontally', ')', 'typical', 'convolutional', 'network', 'architecture', 'applied', 'image', 'Samoyed', 'dog', '(', 'bottom', 'left', ';', 'RGB', '(', 'red', ',', 'green', ',', 'blue', ')', 'inputs', ',', 'bottom', 'right', ')', '.']

>> Bigrams are: 
 [('The', 'outputs'), ('outputs', '('), ('(', 'filters'), ('filters', ')'), (')', 'layer'), ('layer', '('), ('(', 'horizontally'), ('horizontally', ')'), (')', 'typical'), ('typical', 'convolutional'), ('convolutional', 'network'), ('network', 'architecture'), ('architecture', 'applied'), ('applied', 'image'), ('image', 'Samoyed'), ('Samoyed', 'dog'), ('dog', '('), ('(', 'bottom'), ('bottom', 'left'), ('left', ';'), (';', 'RGB'), ('RGB', '('), ('(', 'red'), ('red', ','), (',', 'green'), ('green', ','), (',', 'blue'), ('blue', ')'), (')', 'inputs'), ('inputs', ','), (',', 'bottom'), ('bottom', 'right'), ('right', ')'), (')', '.')]

>> Trigrams are: 
 [('The', 'outputs', '('), ('outputs', '(', 'filters'), ('(', 'filters', ')'), ('filters', ')', 'layer'), (')', 'layer', '('), ('layer', '(', 'horizontally'), ('(', 'horizontally', ')'), ('horizontally', ')', 'typical'), (')', 'typical', 'convolutional'), ('typical', 'convolutional', 'network'), ('convolutional', 'network', 'architecture'), ('network', 'architecture', 'applied'), ('architecture', 'applied', 'image'), ('applied', 'image', 'Samoyed'), ('image', 'Samoyed', 'dog'), ('Samoyed', 'dog', '('), ('dog', '(', 'bottom'), ('(', 'bottom', 'left'), ('bottom', 'left', ';'), ('left', ';', 'RGB'), (';', 'RGB', '('), ('RGB', '(', 'red'), ('(', 'red', ','), ('red', ',', 'green'), (',', 'green', ','), ('green', ',', 'blue'), (',', 'blue', ')'), ('blue', ')', 'inputs'), (')', 'inputs', ','), ('inputs', ',', 'bottom'), (',', 'bottom', 'right'), ('bottom', 'right', ')'), ('right', ')', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('outputs', 'NNS'), ('(', '('), ('filters', 'NNS'), (')', ')'), ('layer', 'NN'), ('(', '('), ('horizontally', 'RB'), (')', ')'), ('typical', 'JJ'), ('convolutional', 'JJ'), ('network', 'NN'), ('architecture', 'NN'), ('applied', 'VBN'), ('image', 'NN'), ('Samoyed', 'NNP'), ('dog', 'NN'), ('(', '('), ('bottom', 'JJ'), ('left', 'VBN'), (';', ':'), ('RGB', 'NNP'), ('(', '('), ('red', 'JJ'), (',', ','), ('green', 'JJ'), (',', ','), ('blue', 'JJ'), (')', ')'), ('inputs', 'NNS'), (',', ','), ('bottom', 'RB'), ('right', 'RB'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['The outputs', 'filters', 'layer', 'typical convolutional network architecture', 'image Samoyed dog', 'RGB', 'inputs']

>> Named Entities are: 
 [('PERSON', 'Samoyed'), ('ORGANIZATION', 'RGB')] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('outputs', 'output'), ('(', '('), ('filters', 'filter'), (')', ')'), ('layer', 'layer'), ('(', '('), ('horizontally', 'horizont'), (')', ')'), ('typical', 'typic'), ('convolutional', 'convolut'), ('network', 'network'), ('architecture', 'architectur'), ('applied', 'appli'), ('image', 'imag'), ('Samoyed', 'samoy'), ('dog', 'dog'), ('(', '('), ('bottom', 'bottom'), ('left', 'left'), (';', ';'), ('RGB', 'rgb'), ('(', '('), ('red', 'red'), (',', ','), ('green', 'green'), (',', ','), ('blue', 'blue'), (')', ')'), ('inputs', 'input'), (',', ','), ('bottom', 'bottom'), ('right', 'right'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('outputs', 'output'), ('(', '('), ('filters', 'filter'), (')', ')'), ('layer', 'layer'), ('(', '('), ('horizontally', 'horizont'), (')', ')'), ('typical', 'typic'), ('convolutional', 'convolut'), ('network', 'network'), ('architecture', 'architectur'), ('applied', 'appli'), ('image', 'imag'), ('Samoyed', 'samoy'), ('dog', 'dog'), ('(', '('), ('bottom', 'bottom'), ('left', 'left'), (';', ';'), ('RGB', 'rgb'), ('(', '('), ('red', 'red'), (',', ','), ('green', 'green'), (',', ','), ('blue', 'blue'), (')', ')'), ('inputs', 'input'), (',', ','), ('bottom', 'bottom'), ('right', 'right'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('outputs', 'output'), ('(', '('), ('filters', 'filter'), (')', ')'), ('layer', 'layer'), ('(', '('), ('horizontally', 'horizontally'), (')', ')'), ('typical', 'typical'), ('convolutional', 'convolutional'), ('network', 'network'), ('architecture', 'architecture'), ('applied', 'applied'), ('image', 'image'), ('Samoyed', 'Samoyed'), ('dog', 'dog'), ('(', '('), ('bottom', 'bottom'), ('left', 'left'), (';', ';'), ('RGB', 'RGB'), ('(', '('), ('red', 'red'), (',', ','), ('green', 'green'), (',', ','), ('blue', 'blue'), (')', ')'), ('inputs', 'input'), (',', ','), ('bottom', 'bottom'), ('right', 'right'), (')', ')'), ('.', '.')]


------------------- Sentence 3 -------------------

Each rectangular image is a feature map

>> Tokens are: 
 ['Each', 'rectangular', 'image', 'feature', 'map']

>> Bigrams are: 
 [('Each', 'rectangular'), ('rectangular', 'image'), ('image', 'feature'), ('feature', 'map')]

>> Trigrams are: 
 [('Each', 'rectangular', 'image'), ('rectangular', 'image', 'feature'), ('image', 'feature', 'map')]

>> POS Tags are: 
 [('Each', 'DT'), ('rectangular', 'JJ'), ('image', 'NN'), ('feature', 'NN'), ('map', 'NN')]

>> Noun Phrases are: 
 ['Each rectangular image feature map']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Each', 'each'), ('rectangular', 'rectangular'), ('image', 'imag'), ('feature', 'featur'), ('map', 'map')]

>> Stemming using Snowball Stemmer: 
 [('Each', 'each'), ('rectangular', 'rectangular'), ('image', 'imag'), ('feature', 'featur'), ('map', 'map')]

>> Lemmatization: 
 [('Each', 'Each'), ('rectangular', 'rectangular'), ('image', 'image'), ('feature', 'feature'), ('map', 'map')]



========================================== PARAGRAPH 102 ===========================================

corresponding to the output for one of the learned features, detected at each  of the image positions. Information flows bottom up, with lower-level features  acting as oriented edge detectors, and a score is computed for each image class  in output. ReLU, rectified linear unit. 

------------------- Sentence 1 -------------------

corresponding to the output for one of the learned features, detected at each  of the image positions.

>> Tokens are: 
 ['corresponding', 'output', 'one', 'learned', 'features', ',', 'detected', 'image', 'positions', '.']

>> Bigrams are: 
 [('corresponding', 'output'), ('output', 'one'), ('one', 'learned'), ('learned', 'features'), ('features', ','), (',', 'detected'), ('detected', 'image'), ('image', 'positions'), ('positions', '.')]

>> Trigrams are: 
 [('corresponding', 'output', 'one'), ('output', 'one', 'learned'), ('one', 'learned', 'features'), ('learned', 'features', ','), ('features', ',', 'detected'), (',', 'detected', 'image'), ('detected', 'image', 'positions'), ('image', 'positions', '.')]

>> POS Tags are: 
 [('corresponding', 'VBG'), ('output', 'NN'), ('one', 'CD'), ('learned', 'VBD'), ('features', 'NNS'), (',', ','), ('detected', 'VBN'), ('image', 'NN'), ('positions', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['output', 'features', 'image positions']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('corresponding', 'correspond'), ('output', 'output'), ('one', 'one'), ('learned', 'learn'), ('features', 'featur'), (',', ','), ('detected', 'detect'), ('image', 'imag'), ('positions', 'posit'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('corresponding', 'correspond'), ('output', 'output'), ('one', 'one'), ('learned', 'learn'), ('features', 'featur'), (',', ','), ('detected', 'detect'), ('image', 'imag'), ('positions', 'posit'), ('.', '.')]

>> Lemmatization: 
 [('corresponding', 'corresponding'), ('output', 'output'), ('one', 'one'), ('learned', 'learned'), ('features', 'feature'), (',', ','), ('detected', 'detected'), ('image', 'image'), ('positions', 'position'), ('.', '.')]


------------------- Sentence 2 -------------------

Information flows bottom up, with lower-level features  acting as oriented edge detectors, and a score is computed for each image class  in output.

>> Tokens are: 
 ['Information', 'flows', 'bottom', ',', 'lower-level', 'features', 'acting', 'oriented', 'edge', 'detectors', ',', 'score', 'computed', 'image', 'class', 'output', '.']

>> Bigrams are: 
 [('Information', 'flows'), ('flows', 'bottom'), ('bottom', ','), (',', 'lower-level'), ('lower-level', 'features'), ('features', 'acting'), ('acting', 'oriented'), ('oriented', 'edge'), ('edge', 'detectors'), ('detectors', ','), (',', 'score'), ('score', 'computed'), ('computed', 'image'), ('image', 'class'), ('class', 'output'), ('output', '.')]

>> Trigrams are: 
 [('Information', 'flows', 'bottom'), ('flows', 'bottom', ','), ('bottom', ',', 'lower-level'), (',', 'lower-level', 'features'), ('lower-level', 'features', 'acting'), ('features', 'acting', 'oriented'), ('acting', 'oriented', 'edge'), ('oriented', 'edge', 'detectors'), ('edge', 'detectors', ','), ('detectors', ',', 'score'), (',', 'score', 'computed'), ('score', 'computed', 'image'), ('computed', 'image', 'class'), ('image', 'class', 'output'), ('class', 'output', '.')]

>> POS Tags are: 
 [('Information', 'NN'), ('flows', 'VBZ'), ('bottom', 'NN'), (',', ','), ('lower-level', 'JJ'), ('features', 'NNS'), ('acting', 'VBG'), ('oriented', 'VBN'), ('edge', 'NN'), ('detectors', 'NNS'), (',', ','), ('score', 'RB'), ('computed', 'JJ'), ('image', 'NN'), ('class', 'NN'), ('output', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Information', 'bottom', 'lower-level features', 'edge detectors', 'computed image class output']

>> Named Entities are: 
 [('GPE', 'Information')] 

>> Stemming using Porter Stemmer: 
 [('Information', 'inform'), ('flows', 'flow'), ('bottom', 'bottom'), (',', ','), ('lower-level', 'lower-level'), ('features', 'featur'), ('acting', 'act'), ('oriented', 'orient'), ('edge', 'edg'), ('detectors', 'detector'), (',', ','), ('score', 'score'), ('computed', 'comput'), ('image', 'imag'), ('class', 'class'), ('output', 'output'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Information', 'inform'), ('flows', 'flow'), ('bottom', 'bottom'), (',', ','), ('lower-level', 'lower-level'), ('features', 'featur'), ('acting', 'act'), ('oriented', 'orient'), ('edge', 'edg'), ('detectors', 'detector'), (',', ','), ('score', 'score'), ('computed', 'comput'), ('image', 'imag'), ('class', 'class'), ('output', 'output'), ('.', '.')]

>> Lemmatization: 
 [('Information', 'Information'), ('flows', 'flow'), ('bottom', 'bottom'), (',', ','), ('lower-level', 'lower-level'), ('features', 'feature'), ('acting', 'acting'), ('oriented', 'oriented'), ('edge', 'edge'), ('detectors', 'detector'), (',', ','), ('score', 'score'), ('computed', 'computed'), ('image', 'image'), ('class', 'class'), ('output', 'output'), ('.', '.')]


------------------- Sentence 3 -------------------

ReLU, rectified linear unit.

>> Tokens are: 
 ['ReLU', ',', 'rectified', 'linear', 'unit', '.']

>> Bigrams are: 
 [('ReLU', ','), (',', 'rectified'), ('rectified', 'linear'), ('linear', 'unit'), ('unit', '.')]

>> Trigrams are: 
 [('ReLU', ',', 'rectified'), (',', 'rectified', 'linear'), ('rectified', 'linear', 'unit'), ('linear', 'unit', '.')]

>> POS Tags are: 
 [('ReLU', 'NNP'), (',', ','), ('rectified', 'VBD'), ('linear', 'JJ'), ('unit', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['ReLU', 'linear unit']

>> Named Entities are: 
 [('GPE', 'ReLU')] 

>> Stemming using Porter Stemmer: 
 [('ReLU', 'relu'), (',', ','), ('rectified', 'rectifi'), ('linear', 'linear'), ('unit', 'unit'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('ReLU', 'relu'), (',', ','), ('rectified', 'rectifi'), ('linear', 'linear'), ('unit', 'unit'), ('.', '.')]

>> Lemmatization: 
 [('ReLU', 'ReLU'), (',', ','), ('rectified', 'rectified'), ('linear', 'linear'), ('unit', 'unit'), ('.', '.')]



========================================== PARAGRAPH 103 ===========================================

Red Green Blue 

------------------- Sentence 1 -------------------

Red Green Blue

>> Tokens are: 
 ['Red', 'Green', 'Blue']

>> Bigrams are: 
 [('Red', 'Green'), ('Green', 'Blue')]

>> Trigrams are: 
 [('Red', 'Green', 'Blue')]

>> POS Tags are: 
 [('Red', 'JJ'), ('Green', 'NNP'), ('Blue', 'NNP')]

>> Noun Phrases are: 
 ['Red Green Blue']

>> Named Entities are: 
 [('ORGANIZATION', 'Green Blue')] 

>> Stemming using Porter Stemmer: 
 [('Red', 'red'), ('Green', 'green'), ('Blue', 'blue')]

>> Stemming using Snowball Stemmer: 
 [('Red', 'red'), ('Green', 'green'), ('Blue', 'blue')]

>> Lemmatization: 
 [('Red', 'Red'), ('Green', 'Green'), ('Blue', 'Blue')]



========================================== PARAGRAPH 104 ===========================================

Samoyed (16); Papillon (5.7); Pomeranian (2.7); Arctic fox (1.0); Eskimo dog (0.6); white wolf (0.4); Siberian husky (0.4) 

------------------- Sentence 1 -------------------

Samoyed (16); Papillon (5.7); Pomeranian (2.7); Arctic fox (1.0); Eskimo dog (0.6); white wolf (0.4); Siberian husky (0.4)

>> Tokens are: 
 ['Samoyed', '(', '16', ')', ';', 'Papillon', '(', '5.7', ')', ';', 'Pomeranian', '(', '2.7', ')', ';', 'Arctic', 'fox', '(', '1.0', ')', ';', 'Eskimo', 'dog', '(', '0.6', ')', ';', 'white', 'wolf', '(', '0.4', ')', ';', 'Siberian', 'husky', '(', '0.4', ')']

>> Bigrams are: 
 [('Samoyed', '('), ('(', '16'), ('16', ')'), (')', ';'), (';', 'Papillon'), ('Papillon', '('), ('(', '5.7'), ('5.7', ')'), (')', ';'), (';', 'Pomeranian'), ('Pomeranian', '('), ('(', '2.7'), ('2.7', ')'), (')', ';'), (';', 'Arctic'), ('Arctic', 'fox'), ('fox', '('), ('(', '1.0'), ('1.0', ')'), (')', ';'), (';', 'Eskimo'), ('Eskimo', 'dog'), ('dog', '('), ('(', '0.6'), ('0.6', ')'), (')', ';'), (';', 'white'), ('white', 'wolf'), ('wolf', '('), ('(', '0.4'), ('0.4', ')'), (')', ';'), (';', 'Siberian'), ('Siberian', 'husky'), ('husky', '('), ('(', '0.4'), ('0.4', ')')]

>> Trigrams are: 
 [('Samoyed', '(', '16'), ('(', '16', ')'), ('16', ')', ';'), (')', ';', 'Papillon'), (';', 'Papillon', '('), ('Papillon', '(', '5.7'), ('(', '5.7', ')'), ('5.7', ')', ';'), (')', ';', 'Pomeranian'), (';', 'Pomeranian', '('), ('Pomeranian', '(', '2.7'), ('(', '2.7', ')'), ('2.7', ')', ';'), (')', ';', 'Arctic'), (';', 'Arctic', 'fox'), ('Arctic', 'fox', '('), ('fox', '(', '1.0'), ('(', '1.0', ')'), ('1.0', ')', ';'), (')', ';', 'Eskimo'), (';', 'Eskimo', 'dog'), ('Eskimo', 'dog', '('), ('dog', '(', '0.6'), ('(', '0.6', ')'), ('0.6', ')', ';'), (')', ';', 'white'), (';', 'white', 'wolf'), ('white', 'wolf', '('), ('wolf', '(', '0.4'), ('(', '0.4', ')'), ('0.4', ')', ';'), (')', ';', 'Siberian'), (';', 'Siberian', 'husky'), ('Siberian', 'husky', '('), ('husky', '(', '0.4'), ('(', '0.4', ')')]

>> POS Tags are: 
 [('Samoyed', 'NNP'), ('(', '('), ('16', 'CD'), (')', ')'), (';', ':'), ('Papillon', 'NNP'), ('(', '('), ('5.7', 'CD'), (')', ')'), (';', ':'), ('Pomeranian', 'NNP'), ('(', '('), ('2.7', 'CD'), (')', ')'), (';', ':'), ('Arctic', 'NNP'), ('fox', 'NN'), ('(', '('), ('1.0', 'CD'), (')', ')'), (';', ':'), ('Eskimo', 'NNP'), ('dog', 'NN'), ('(', '('), ('0.6', 'CD'), (')', ')'), (';', ':'), ('white', 'JJ'), ('wolf', 'NN'), ('(', '('), ('0.4', 'CD'), (')', ')'), (';', ':'), ('Siberian', 'JJ'), ('husky', 'NN'), ('(', '('), ('0.4', 'CD'), (')', ')')]

>> Noun Phrases are: 
 ['Samoyed', 'Papillon', 'Pomeranian', 'Arctic fox', 'Eskimo dog', 'white wolf', 'Siberian husky']

>> Named Entities are: 
 [('GPE', 'Samoyed'), ('GPE', 'Papillon'), ('GPE', 'Pomeranian'), ('GPE', 'Arctic'), ('GPE', 'Eskimo'), ('GPE', 'Siberian')] 

>> Stemming using Porter Stemmer: 
 [('Samoyed', 'samoy'), ('(', '('), ('16', '16'), (')', ')'), (';', ';'), ('Papillon', 'papillon'), ('(', '('), ('5.7', '5.7'), (')', ')'), (';', ';'), ('Pomeranian', 'pomeranian'), ('(', '('), ('2.7', '2.7'), (')', ')'), (';', ';'), ('Arctic', 'arctic'), ('fox', 'fox'), ('(', '('), ('1.0', '1.0'), (')', ')'), (';', ';'), ('Eskimo', 'eskimo'), ('dog', 'dog'), ('(', '('), ('0.6', '0.6'), (')', ')'), (';', ';'), ('white', 'white'), ('wolf', 'wolf'), ('(', '('), ('0.4', '0.4'), (')', ')'), (';', ';'), ('Siberian', 'siberian'), ('husky', 'huski'), ('(', '('), ('0.4', '0.4'), (')', ')')]

>> Stemming using Snowball Stemmer: 
 [('Samoyed', 'samoy'), ('(', '('), ('16', '16'), (')', ')'), (';', ';'), ('Papillon', 'papillon'), ('(', '('), ('5.7', '5.7'), (')', ')'), (';', ';'), ('Pomeranian', 'pomeranian'), ('(', '('), ('2.7', '2.7'), (')', ')'), (';', ';'), ('Arctic', 'arctic'), ('fox', 'fox'), ('(', '('), ('1.0', '1.0'), (')', ')'), (';', ';'), ('Eskimo', 'eskimo'), ('dog', 'dog'), ('(', '('), ('0.6', '0.6'), (')', ')'), (';', ';'), ('white', 'white'), ('wolf', 'wolf'), ('(', '('), ('0.4', '0.4'), (')', ')'), (';', ';'), ('Siberian', 'siberian'), ('husky', 'huski'), ('(', '('), ('0.4', '0.4'), (')', ')')]

>> Lemmatization: 
 [('Samoyed', 'Samoyed'), ('(', '('), ('16', '16'), (')', ')'), (';', ';'), ('Papillon', 'Papillon'), ('(', '('), ('5.7', '5.7'), (')', ')'), (';', ';'), ('Pomeranian', 'Pomeranian'), ('(', '('), ('2.7', '2.7'), (')', ')'), (';', ';'), ('Arctic', 'Arctic'), ('fox', 'fox'), ('(', '('), ('1.0', '1.0'), (')', ')'), (';', ';'), ('Eskimo', 'Eskimo'), ('dog', 'dog'), ('(', '('), ('0.6', '0.6'), (')', ')'), (';', ';'), ('white', 'white'), ('wolf', 'wolf'), ('(', '('), ('0.4', '0.4'), (')', ')'), (';', ';'), ('Siberian', 'Siberian'), ('husky', 'husky'), ('(', '('), ('0.4', '0.4'), (')', ')')]



========================================== PARAGRAPH 105 ===========================================

Convolutions and ReLU 

------------------- Sentence 1 -------------------

Convolutions and ReLU

>> Tokens are: 
 ['Convolutions', 'ReLU']

>> Bigrams are: 
 [('Convolutions', 'ReLU')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Convolutions', 'NNS'), ('ReLU', 'NNP')]

>> Noun Phrases are: 
 ['Convolutions ReLU']

>> Named Entities are: 
 [('ORGANIZATION', 'ReLU')] 

>> Stemming using Porter Stemmer: 
 [('Convolutions', 'convolut'), ('ReLU', 'relu')]

>> Stemming using Snowball Stemmer: 
 [('Convolutions', 'convolut'), ('ReLU', 'relu')]

>> Lemmatization: 
 [('Convolutions', 'Convolutions'), ('ReLU', 'ReLU')]



========================================== PARAGRAPH 106 ===========================================

Max pooling 

------------------- Sentence 1 -------------------

Max pooling

>> Tokens are: 
 ['Max', 'pooling']

>> Bigrams are: 
 [('Max', 'pooling')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Max', 'NNP'), ('pooling', 'NN')]

>> Noun Phrases are: 
 ['Max pooling']

>> Named Entities are: 
 [('GPE', 'Max')] 

>> Stemming using Porter Stemmer: 
 [('Max', 'max'), ('pooling', 'pool')]

>> Stemming using Snowball Stemmer: 
 [('Max', 'max'), ('pooling', 'pool')]

>> Lemmatization: 
 [('Max', 'Max'), ('pooling', 'pooling')]



========================================== PARAGRAPH 107 ===========================================

Max pooling 

------------------- Sentence 1 -------------------

Max pooling

>> Tokens are: 
 ['Max', 'pooling']

>> Bigrams are: 
 [('Max', 'pooling')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Max', 'NNP'), ('pooling', 'NN')]

>> Noun Phrases are: 
 ['Max pooling']

>> Named Entities are: 
 [('GPE', 'Max')] 

>> Stemming using Porter Stemmer: 
 [('Max', 'max'), ('pooling', 'pool')]

>> Stemming using Snowball Stemmer: 
 [('Max', 'max'), ('pooling', 'pool')]

>> Lemmatization: 
 [('Max', 'Max'), ('pooling', 'pooling')]



========================================== PARAGRAPH 108 ===========================================

Convolutions and ReLU 

------------------- Sentence 1 -------------------

Convolutions and ReLU

>> Tokens are: 
 ['Convolutions', 'ReLU']

>> Bigrams are: 
 [('Convolutions', 'ReLU')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Convolutions', 'NNS'), ('ReLU', 'NNP')]

>> Noun Phrases are: 
 ['Convolutions ReLU']

>> Named Entities are: 
 [('ORGANIZATION', 'ReLU')] 

>> Stemming using Porter Stemmer: 
 [('Convolutions', 'convolut'), ('ReLU', 'relu')]

>> Stemming using Snowball Stemmer: 
 [('Convolutions', 'convolut'), ('ReLU', 'relu')]

>> Lemmatization: 
 [('Convolutions', 'Convolutions'), ('ReLU', 'ReLU')]



========================================== PARAGRAPH 109 ===========================================

Convolutions and ReLU 

------------------- Sentence 1 -------------------

Convolutions and ReLU

>> Tokens are: 
 ['Convolutions', 'ReLU']

>> Bigrams are: 
 [('Convolutions', 'ReLU')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Convolutions', 'NNS'), ('ReLU', 'NNP')]

>> Noun Phrases are: 
 ['Convolutions ReLU']

>> Named Entities are: 
 [('ORGANIZATION', 'ReLU')] 

>> Stemming using Porter Stemmer: 
 [('Convolutions', 'convolut'), ('ReLU', 'relu')]

>> Stemming using Snowball Stemmer: 
 [('Convolutions', 'convolut'), ('ReLU', 'relu')]

>> Lemmatization: 
 [('Convolutions', 'Convolutions'), ('ReLU', 'ReLU')]



========================================== PARAGRAPH 110 ===========================================

4 3 8  |  N A T U R E  |  V O L  5 2 1  |  2 8  M A Y  2 0 1 5 

------------------- Sentence 1 -------------------

4 3 8  |  N A T U R E  |  V O L  5 2 1  |  2 8  M A Y  2 0 1 5

>> Tokens are: 
 ['4', '3', '8', '|', 'N', 'A', 'T', 'U', 'R', 'E', '|', 'V', 'O', 'L', '5', '2', '1', '|', '2', '8', 'M', 'A', 'Y', '2', '0', '1', '5']

>> Bigrams are: 
 [('4', '3'), ('3', '8'), ('8', '|'), ('|', 'N'), ('N', 'A'), ('A', 'T'), ('T', 'U'), ('U', 'R'), ('R', 'E'), ('E', '|'), ('|', 'V'), ('V', 'O'), ('O', 'L'), ('L', '5'), ('5', '2'), ('2', '1'), ('1', '|'), ('|', '2'), ('2', '8'), ('8', 'M'), ('M', 'A'), ('A', 'Y'), ('Y', '2'), ('2', '0'), ('0', '1'), ('1', '5')]

>> Trigrams are: 
 [('4', '3', '8'), ('3', '8', '|'), ('8', '|', 'N'), ('|', 'N', 'A'), ('N', 'A', 'T'), ('A', 'T', 'U'), ('T', 'U', 'R'), ('U', 'R', 'E'), ('R', 'E', '|'), ('E', '|', 'V'), ('|', 'V', 'O'), ('V', 'O', 'L'), ('O', 'L', '5'), ('L', '5', '2'), ('5', '2', '1'), ('2', '1', '|'), ('1', '|', '2'), ('|', '2', '8'), ('2', '8', 'M'), ('8', 'M', 'A'), ('M', 'A', 'Y'), ('A', 'Y', '2'), ('Y', '2', '0'), ('2', '0', '1'), ('0', '1', '5')]

>> POS Tags are: 
 [('4', 'CD'), ('3', 'CD'), ('8', 'CD'), ('|', 'NN'), ('N', 'NNP'), ('A', 'NNP'), ('T', 'NNP'), ('U', 'NNP'), ('R', 'NNP'), ('E', 'NNP'), ('|', 'NNP'), ('V', 'NNP'), ('O', 'NNP'), ('L', 'NNP'), ('5', 'CD'), ('2', 'CD'), ('1', 'CD'), ('|', 'NN'), ('2', 'CD'), ('8', 'CD'), ('M', 'NNP'), ('A', 'NNP'), ('Y', 'NNP'), ('2', 'CD'), ('0', 'CD'), ('1', 'CD'), ('5', 'CD')]

>> Noun Phrases are: 
 ['| N A T U R E | V O L', '|', 'M A Y']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('4', '4'), ('3', '3'), ('8', '8'), ('|', '|'), ('N', 'n'), ('A', 'a'), ('T', 't'), ('U', 'u'), ('R', 'r'), ('E', 'e'), ('|', '|'), ('V', 'v'), ('O', 'o'), ('L', 'l'), ('5', '5'), ('2', '2'), ('1', '1'), ('|', '|'), ('2', '2'), ('8', '8'), ('M', 'm'), ('A', 'a'), ('Y', 'y'), ('2', '2'), ('0', '0'), ('1', '1'), ('5', '5')]

>> Stemming using Snowball Stemmer: 
 [('4', '4'), ('3', '3'), ('8', '8'), ('|', '|'), ('N', 'n'), ('A', 'a'), ('T', 't'), ('U', 'u'), ('R', 'r'), ('E', 'e'), ('|', '|'), ('V', 'v'), ('O', 'o'), ('L', 'l'), ('5', '5'), ('2', '2'), ('1', '1'), ('|', '|'), ('2', '2'), ('8', '8'), ('M', 'm'), ('A', 'a'), ('Y', 'y'), ('2', '2'), ('0', '0'), ('1', '1'), ('5', '5')]

>> Lemmatization: 
 [('4', '4'), ('3', '3'), ('8', '8'), ('|', '|'), ('N', 'N'), ('A', 'A'), ('T', 'T'), ('U', 'U'), ('R', 'R'), ('E', 'E'), ('|', '|'), ('V', 'V'), ('O', 'O'), ('L', 'L'), ('5', '5'), ('2', '2'), ('1', '1'), ('|', '|'), ('2', '2'), ('8', '8'), ('M', 'M'), ('A', 'A'), ('Y', 'Y'), ('2', '2'), ('0', '0'), ('1', '1'), ('5', '5')]



========================================== PARAGRAPH 111 ===========================================

REVIEWINSIGHT 

------------------- Sentence 1 -------------------

REVIEWINSIGHT

>> Tokens are: 
 ['REVIEWINSIGHT']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('REVIEWINSIGHT', 'NN')]

>> Noun Phrases are: 
 ['REVIEWINSIGHT']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('REVIEWINSIGHT', 'reviewinsight')]

>> Stemming using Snowball Stemmer: 
 [('REVIEWINSIGHT', 'reviewinsight')]

>> Lemmatization: 
 [('REVIEWINSIGHT', 'REVIEWINSIGHT')]



========================================== PARAGRAPH 112 ===========================================

© 2015 Macmillan Publishers Limited. All rights reserved

------------------- Sentence 1 -------------------

© 2015 Macmillan Publishers Limited.

>> Tokens are: 
 ['©', '2015', 'Macmillan', 'Publishers', 'Limited', '.']

>> Bigrams are: 
 [('©', '2015'), ('2015', 'Macmillan'), ('Macmillan', 'Publishers'), ('Publishers', 'Limited'), ('Limited', '.')]

>> Trigrams are: 
 [('©', '2015', 'Macmillan'), ('2015', 'Macmillan', 'Publishers'), ('Macmillan', 'Publishers', 'Limited'), ('Publishers', 'Limited', '.')]

>> POS Tags are: 
 [('©', 'NN'), ('2015', 'CD'), ('Macmillan', 'NNP'), ('Publishers', 'NNP'), ('Limited', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['©', 'Macmillan Publishers Limited']

>> Named Entities are: 
 [('PERSON', 'Macmillan Publishers Limited')] 

>> Stemming using Porter Stemmer: 
 [('©', '©'), ('2015', '2015'), ('Macmillan', 'macmillan'), ('Publishers', 'publish'), ('Limited', 'limit'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('©', '©'), ('2015', '2015'), ('Macmillan', 'macmillan'), ('Publishers', 'publish'), ('Limited', 'limit'), ('.', '.')]

>> Lemmatization: 
 [('©', '©'), ('2015', '2015'), ('Macmillan', 'Macmillan'), ('Publishers', 'Publishers'), ('Limited', 'Limited'), ('.', '.')]


------------------- Sentence 2 -------------------

All rights reserved

>> Tokens are: 
 ['All', 'rights', 'reserved']

>> Bigrams are: 
 [('All', 'rights'), ('rights', 'reserved')]

>> Trigrams are: 
 [('All', 'rights', 'reserved')]

>> POS Tags are: 
 [('All', 'DT'), ('rights', 'NNS'), ('reserved', 'VBN')]

>> Noun Phrases are: 
 ['All rights']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('All', 'all'), ('rights', 'right'), ('reserved', 'reserv')]

>> Stemming using Snowball Stemmer: 
 [('All', 'all'), ('rights', 'right'), ('reserved', 'reserv')]

>> Lemmatization: 
 [('All', 'All'), ('rights', 'right'), ('reserved', 'reserved')]



========================================== PARAGRAPH 113 ===========================================

remainder29,30. The analysis seems to show that saddle points with  only a few downward curving directions are present in very large  numbers, but almost all of them have very similar values of the objec- tive function. Hence, it does not much matter which of these saddle  points the algorithm gets stuck at.  

------------------- Sentence 1 -------------------

remainder29,30.

>> Tokens are: 
 ['remainder29,30', '.']

>> Bigrams are: 
 [('remainder29,30', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('remainder29,30', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['remainder29,30']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('remainder29,30', 'remainder29,30'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('remainder29,30', 'remainder29,30'), ('.', '.')]

>> Lemmatization: 
 [('remainder29,30', 'remainder29,30'), ('.', '.')]


------------------- Sentence 2 -------------------

The analysis seems to show that saddle points with  only a few downward curving directions are present in very large  numbers, but almost all of them have very similar values of the objec- tive function.

>> Tokens are: 
 ['The', 'analysis', 'seems', 'show', 'saddle', 'points', 'downward', 'curving', 'directions', 'present', 'large', 'numbers', ',', 'almost', 'similar', 'values', 'objec-', 'tive', 'function', '.']

>> Bigrams are: 
 [('The', 'analysis'), ('analysis', 'seems'), ('seems', 'show'), ('show', 'saddle'), ('saddle', 'points'), ('points', 'downward'), ('downward', 'curving'), ('curving', 'directions'), ('directions', 'present'), ('present', 'large'), ('large', 'numbers'), ('numbers', ','), (',', 'almost'), ('almost', 'similar'), ('similar', 'values'), ('values', 'objec-'), ('objec-', 'tive'), ('tive', 'function'), ('function', '.')]

>> Trigrams are: 
 [('The', 'analysis', 'seems'), ('analysis', 'seems', 'show'), ('seems', 'show', 'saddle'), ('show', 'saddle', 'points'), ('saddle', 'points', 'downward'), ('points', 'downward', 'curving'), ('downward', 'curving', 'directions'), ('curving', 'directions', 'present'), ('directions', 'present', 'large'), ('present', 'large', 'numbers'), ('large', 'numbers', ','), ('numbers', ',', 'almost'), (',', 'almost', 'similar'), ('almost', 'similar', 'values'), ('similar', 'values', 'objec-'), ('values', 'objec-', 'tive'), ('objec-', 'tive', 'function'), ('tive', 'function', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('analysis', 'NN'), ('seems', 'VBZ'), ('show', 'VBP'), ('saddle', 'JJ'), ('points', 'NNS'), ('downward', 'RB'), ('curving', 'VBG'), ('directions', 'NNS'), ('present', 'JJ'), ('large', 'JJ'), ('numbers', 'NNS'), (',', ','), ('almost', 'RB'), ('similar', 'JJ'), ('values', 'NNS'), ('objec-', 'JJ'), ('tive', 'JJ'), ('function', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['The analysis', 'saddle points', 'directions', 'present large numbers', 'similar values', 'objec- tive function']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('analysis', 'analysi'), ('seems', 'seem'), ('show', 'show'), ('saddle', 'saddl'), ('points', 'point'), ('downward', 'downward'), ('curving', 'curv'), ('directions', 'direct'), ('present', 'present'), ('large', 'larg'), ('numbers', 'number'), (',', ','), ('almost', 'almost'), ('similar', 'similar'), ('values', 'valu'), ('objec-', 'objec-'), ('tive', 'tive'), ('function', 'function'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('analysis', 'analysi'), ('seems', 'seem'), ('show', 'show'), ('saddle', 'saddl'), ('points', 'point'), ('downward', 'downward'), ('curving', 'curv'), ('directions', 'direct'), ('present', 'present'), ('large', 'larg'), ('numbers', 'number'), (',', ','), ('almost', 'almost'), ('similar', 'similar'), ('values', 'valu'), ('objec-', 'objec-'), ('tive', 'tive'), ('function', 'function'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('analysis', 'analysis'), ('seems', 'seems'), ('show', 'show'), ('saddle', 'saddle'), ('points', 'point'), ('downward', 'downward'), ('curving', 'curving'), ('directions', 'direction'), ('present', 'present'), ('large', 'large'), ('numbers', 'number'), (',', ','), ('almost', 'almost'), ('similar', 'similar'), ('values', 'value'), ('objec-', 'objec-'), ('tive', 'tive'), ('function', 'function'), ('.', '.')]


------------------- Sentence 3 -------------------

Hence, it does not much matter which of these saddle  points the algorithm gets stuck at.

>> Tokens are: 
 ['Hence', ',', 'much', 'matter', 'saddle', 'points', 'algorithm', 'gets', 'stuck', '.']

>> Bigrams are: 
 [('Hence', ','), (',', 'much'), ('much', 'matter'), ('matter', 'saddle'), ('saddle', 'points'), ('points', 'algorithm'), ('algorithm', 'gets'), ('gets', 'stuck'), ('stuck', '.')]

>> Trigrams are: 
 [('Hence', ',', 'much'), (',', 'much', 'matter'), ('much', 'matter', 'saddle'), ('matter', 'saddle', 'points'), ('saddle', 'points', 'algorithm'), ('points', 'algorithm', 'gets'), ('algorithm', 'gets', 'stuck'), ('gets', 'stuck', '.')]

>> POS Tags are: 
 [('Hence', 'NNP'), (',', ','), ('much', 'JJ'), ('matter', 'NN'), ('saddle', 'JJ'), ('points', 'NNS'), ('algorithm', 'JJ'), ('gets', 'VBZ'), ('stuck', 'VBN'), ('.', '.')]

>> Noun Phrases are: 
 ['Hence', 'much matter', 'saddle points']

>> Named Entities are: 
 [('GPE', 'Hence')] 

>> Stemming using Porter Stemmer: 
 [('Hence', 'henc'), (',', ','), ('much', 'much'), ('matter', 'matter'), ('saddle', 'saddl'), ('points', 'point'), ('algorithm', 'algorithm'), ('gets', 'get'), ('stuck', 'stuck'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Hence', 'henc'), (',', ','), ('much', 'much'), ('matter', 'matter'), ('saddle', 'saddl'), ('points', 'point'), ('algorithm', 'algorithm'), ('gets', 'get'), ('stuck', 'stuck'), ('.', '.')]

>> Lemmatization: 
 [('Hence', 'Hence'), (',', ','), ('much', 'much'), ('matter', 'matter'), ('saddle', 'saddle'), ('points', 'point'), ('algorithm', 'algorithm'), ('gets', 'get'), ('stuck', 'stuck'), ('.', '.')]



========================================== PARAGRAPH 114 ===========================================

Interest in deep feedforward networks was revived around 2006  (refs 31–34) by a group of researchers brought together by the Cana- dian Institute for Advanced Research (CIFAR). The researchers intro- duced unsupervised learning procedures that could create layers of  feature detectors without requiring labelled data. The objective in  learning each layer of feature detectors was to be able to reconstruct  or model the activities of feature detectors (or raw inputs) in the layer  below. By ‘pre-training’ several layers of progressively more complex  feature detectors using this reconstruction objective, the weights of a  deep network could be initialized to sensible values. A final layer of  output units could then be added to the top of the network and the  whole deep system could be fine-tuned using standard backpropaga- tion33–35. This worked remarkably well for recognizing handwritten  digits or for detecting pedestrians, especially when the amount of  labelled data was very limited36.  

------------------- Sentence 1 -------------------

Interest in deep feedforward networks was revived around 2006  (refs 31–34) by a group of researchers brought together by the Cana- dian Institute for Advanced Research (CIFAR).

>> Tokens are: 
 ['Interest', 'deep', 'feedforward', 'networks', 'revived', 'around', '2006', '(', 'refs', '31–34', ')', 'group', 'researchers', 'brought', 'together', 'Cana-', 'dian', 'Institute', 'Advanced', 'Research', '(', 'CIFAR', ')', '.']

>> Bigrams are: 
 [('Interest', 'deep'), ('deep', 'feedforward'), ('feedforward', 'networks'), ('networks', 'revived'), ('revived', 'around'), ('around', '2006'), ('2006', '('), ('(', 'refs'), ('refs', '31–34'), ('31–34', ')'), (')', 'group'), ('group', 'researchers'), ('researchers', 'brought'), ('brought', 'together'), ('together', 'Cana-'), ('Cana-', 'dian'), ('dian', 'Institute'), ('Institute', 'Advanced'), ('Advanced', 'Research'), ('Research', '('), ('(', 'CIFAR'), ('CIFAR', ')'), (')', '.')]

>> Trigrams are: 
 [('Interest', 'deep', 'feedforward'), ('deep', 'feedforward', 'networks'), ('feedforward', 'networks', 'revived'), ('networks', 'revived', 'around'), ('revived', 'around', '2006'), ('around', '2006', '('), ('2006', '(', 'refs'), ('(', 'refs', '31–34'), ('refs', '31–34', ')'), ('31–34', ')', 'group'), (')', 'group', 'researchers'), ('group', 'researchers', 'brought'), ('researchers', 'brought', 'together'), ('brought', 'together', 'Cana-'), ('together', 'Cana-', 'dian'), ('Cana-', 'dian', 'Institute'), ('dian', 'Institute', 'Advanced'), ('Institute', 'Advanced', 'Research'), ('Advanced', 'Research', '('), ('Research', '(', 'CIFAR'), ('(', 'CIFAR', ')'), ('CIFAR', ')', '.')]

>> POS Tags are: 
 [('Interest', 'NN'), ('deep', 'RB'), ('feedforward', 'RB'), ('networks', 'VBZ'), ('revived', 'VBN'), ('around', 'IN'), ('2006', 'CD'), ('(', '('), ('refs', 'VB'), ('31–34', 'CD'), (')', ')'), ('group', 'NN'), ('researchers', 'NNS'), ('brought', 'VBD'), ('together', 'RB'), ('Cana-', 'NNP'), ('dian', 'JJ'), ('Institute', 'NNP'), ('Advanced', 'NNP'), ('Research', 'NNP'), ('(', '('), ('CIFAR', 'NNP'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['Interest', 'group researchers', 'Cana-', 'dian Institute Advanced Research', 'CIFAR']

>> Named Entities are: 
 [('GPE', 'Interest'), ('ORGANIZATION', 'Institute Advanced'), ('ORGANIZATION', 'CIFAR')] 

>> Stemming using Porter Stemmer: 
 [('Interest', 'interest'), ('deep', 'deep'), ('feedforward', 'feedforward'), ('networks', 'network'), ('revived', 'reviv'), ('around', 'around'), ('2006', '2006'), ('(', '('), ('refs', 'ref'), ('31–34', '31–34'), (')', ')'), ('group', 'group'), ('researchers', 'research'), ('brought', 'brought'), ('together', 'togeth'), ('Cana-', 'cana-'), ('dian', 'dian'), ('Institute', 'institut'), ('Advanced', 'advanc'), ('Research', 'research'), ('(', '('), ('CIFAR', 'cifar'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Interest', 'interest'), ('deep', 'deep'), ('feedforward', 'feedforward'), ('networks', 'network'), ('revived', 'reviv'), ('around', 'around'), ('2006', '2006'), ('(', '('), ('refs', 'ref'), ('31–34', '31–34'), (')', ')'), ('group', 'group'), ('researchers', 'research'), ('brought', 'brought'), ('together', 'togeth'), ('Cana-', 'cana-'), ('dian', 'dian'), ('Institute', 'institut'), ('Advanced', 'advanc'), ('Research', 'research'), ('(', '('), ('CIFAR', 'cifar'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Interest', 'Interest'), ('deep', 'deep'), ('feedforward', 'feedforward'), ('networks', 'network'), ('revived', 'revived'), ('around', 'around'), ('2006', '2006'), ('(', '('), ('refs', 'ref'), ('31–34', '31–34'), (')', ')'), ('group', 'group'), ('researchers', 'researcher'), ('brought', 'brought'), ('together', 'together'), ('Cana-', 'Cana-'), ('dian', 'dian'), ('Institute', 'Institute'), ('Advanced', 'Advanced'), ('Research', 'Research'), ('(', '('), ('CIFAR', 'CIFAR'), (')', ')'), ('.', '.')]


------------------- Sentence 2 -------------------

The researchers intro- duced unsupervised learning procedures that could create layers of  feature detectors without requiring labelled data.

>> Tokens are: 
 ['The', 'researchers', 'intro-', 'duced', 'unsupervised', 'learning', 'procedures', 'could', 'create', 'layers', 'feature', 'detectors', 'without', 'requiring', 'labelled', 'data', '.']

>> Bigrams are: 
 [('The', 'researchers'), ('researchers', 'intro-'), ('intro-', 'duced'), ('duced', 'unsupervised'), ('unsupervised', 'learning'), ('learning', 'procedures'), ('procedures', 'could'), ('could', 'create'), ('create', 'layers'), ('layers', 'feature'), ('feature', 'detectors'), ('detectors', 'without'), ('without', 'requiring'), ('requiring', 'labelled'), ('labelled', 'data'), ('data', '.')]

>> Trigrams are: 
 [('The', 'researchers', 'intro-'), ('researchers', 'intro-', 'duced'), ('intro-', 'duced', 'unsupervised'), ('duced', 'unsupervised', 'learning'), ('unsupervised', 'learning', 'procedures'), ('learning', 'procedures', 'could'), ('procedures', 'could', 'create'), ('could', 'create', 'layers'), ('create', 'layers', 'feature'), ('layers', 'feature', 'detectors'), ('feature', 'detectors', 'without'), ('detectors', 'without', 'requiring'), ('without', 'requiring', 'labelled'), ('requiring', 'labelled', 'data'), ('labelled', 'data', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('researchers', 'NNS'), ('intro-', 'JJ'), ('duced', 'VBD'), ('unsupervised', 'JJ'), ('learning', 'NN'), ('procedures', 'NNS'), ('could', 'MD'), ('create', 'VB'), ('layers', 'NNS'), ('feature', 'JJ'), ('detectors', 'NNS'), ('without', 'IN'), ('requiring', 'VBG'), ('labelled', 'VBN'), ('data', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['The researchers', 'unsupervised learning procedures', 'layers', 'feature detectors', 'data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('researchers', 'research'), ('intro-', 'intro-'), ('duced', 'duce'), ('unsupervised', 'unsupervis'), ('learning', 'learn'), ('procedures', 'procedur'), ('could', 'could'), ('create', 'creat'), ('layers', 'layer'), ('feature', 'featur'), ('detectors', 'detector'), ('without', 'without'), ('requiring', 'requir'), ('labelled', 'label'), ('data', 'data'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('researchers', 'research'), ('intro-', 'intro-'), ('duced', 'duce'), ('unsupervised', 'unsupervis'), ('learning', 'learn'), ('procedures', 'procedur'), ('could', 'could'), ('create', 'creat'), ('layers', 'layer'), ('feature', 'featur'), ('detectors', 'detector'), ('without', 'without'), ('requiring', 'requir'), ('labelled', 'label'), ('data', 'data'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('researchers', 'researcher'), ('intro-', 'intro-'), ('duced', 'duced'), ('unsupervised', 'unsupervised'), ('learning', 'learning'), ('procedures', 'procedure'), ('could', 'could'), ('create', 'create'), ('layers', 'layer'), ('feature', 'feature'), ('detectors', 'detector'), ('without', 'without'), ('requiring', 'requiring'), ('labelled', 'labelled'), ('data', 'data'), ('.', '.')]


------------------- Sentence 3 -------------------

The objective in  learning each layer of feature detectors was to be able to reconstruct  or model the activities of feature detectors (or raw inputs) in the layer  below.

>> Tokens are: 
 ['The', 'objective', 'learning', 'layer', 'feature', 'detectors', 'able', 'reconstruct', 'model', 'activities', 'feature', 'detectors', '(', 'raw', 'inputs', ')', 'layer', '.']

>> Bigrams are: 
 [('The', 'objective'), ('objective', 'learning'), ('learning', 'layer'), ('layer', 'feature'), ('feature', 'detectors'), ('detectors', 'able'), ('able', 'reconstruct'), ('reconstruct', 'model'), ('model', 'activities'), ('activities', 'feature'), ('feature', 'detectors'), ('detectors', '('), ('(', 'raw'), ('raw', 'inputs'), ('inputs', ')'), (')', 'layer'), ('layer', '.')]

>> Trigrams are: 
 [('The', 'objective', 'learning'), ('objective', 'learning', 'layer'), ('learning', 'layer', 'feature'), ('layer', 'feature', 'detectors'), ('feature', 'detectors', 'able'), ('detectors', 'able', 'reconstruct'), ('able', 'reconstruct', 'model'), ('reconstruct', 'model', 'activities'), ('model', 'activities', 'feature'), ('activities', 'feature', 'detectors'), ('feature', 'detectors', '('), ('detectors', '(', 'raw'), ('(', 'raw', 'inputs'), ('raw', 'inputs', ')'), ('inputs', ')', 'layer'), (')', 'layer', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('objective', 'JJ'), ('learning', 'NN'), ('layer', 'NN'), ('feature', 'NN'), ('detectors', 'NNS'), ('able', 'JJ'), ('reconstruct', 'NN'), ('model', 'NN'), ('activities', 'NNS'), ('feature', 'VBP'), ('detectors', 'NNS'), ('(', '('), ('raw', 'JJ'), ('inputs', 'NNS'), (')', ')'), ('layer', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['The objective learning layer feature detectors', 'able reconstruct model activities', 'detectors', 'raw inputs', 'layer']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('objective', 'object'), ('learning', 'learn'), ('layer', 'layer'), ('feature', 'featur'), ('detectors', 'detector'), ('able', 'abl'), ('reconstruct', 'reconstruct'), ('model', 'model'), ('activities', 'activ'), ('feature', 'featur'), ('detectors', 'detector'), ('(', '('), ('raw', 'raw'), ('inputs', 'input'), (')', ')'), ('layer', 'layer'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('objective', 'object'), ('learning', 'learn'), ('layer', 'layer'), ('feature', 'featur'), ('detectors', 'detector'), ('able', 'abl'), ('reconstruct', 'reconstruct'), ('model', 'model'), ('activities', 'activ'), ('feature', 'featur'), ('detectors', 'detector'), ('(', '('), ('raw', 'raw'), ('inputs', 'input'), (')', ')'), ('layer', 'layer'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('objective', 'objective'), ('learning', 'learning'), ('layer', 'layer'), ('feature', 'feature'), ('detectors', 'detector'), ('able', 'able'), ('reconstruct', 'reconstruct'), ('model', 'model'), ('activities', 'activity'), ('feature', 'feature'), ('detectors', 'detector'), ('(', '('), ('raw', 'raw'), ('inputs', 'input'), (')', ')'), ('layer', 'layer'), ('.', '.')]


------------------- Sentence 4 -------------------

By ‘pre-training’ several layers of progressively more complex  feature detectors using this reconstruction objective, the weights of a  deep network could be initialized to sensible values.

>> Tokens are: 
 ['By', '‘', 'pre-training', '’', 'several', 'layers', 'progressively', 'complex', 'feature', 'detectors', 'using', 'reconstruction', 'objective', ',', 'weights', 'deep', 'network', 'could', 'initialized', 'sensible', 'values', '.']

>> Bigrams are: 
 [('By', '‘'), ('‘', 'pre-training'), ('pre-training', '’'), ('’', 'several'), ('several', 'layers'), ('layers', 'progressively'), ('progressively', 'complex'), ('complex', 'feature'), ('feature', 'detectors'), ('detectors', 'using'), ('using', 'reconstruction'), ('reconstruction', 'objective'), ('objective', ','), (',', 'weights'), ('weights', 'deep'), ('deep', 'network'), ('network', 'could'), ('could', 'initialized'), ('initialized', 'sensible'), ('sensible', 'values'), ('values', '.')]

>> Trigrams are: 
 [('By', '‘', 'pre-training'), ('‘', 'pre-training', '’'), ('pre-training', '’', 'several'), ('’', 'several', 'layers'), ('several', 'layers', 'progressively'), ('layers', 'progressively', 'complex'), ('progressively', 'complex', 'feature'), ('complex', 'feature', 'detectors'), ('feature', 'detectors', 'using'), ('detectors', 'using', 'reconstruction'), ('using', 'reconstruction', 'objective'), ('reconstruction', 'objective', ','), ('objective', ',', 'weights'), (',', 'weights', 'deep'), ('weights', 'deep', 'network'), ('deep', 'network', 'could'), ('network', 'could', 'initialized'), ('could', 'initialized', 'sensible'), ('initialized', 'sensible', 'values'), ('sensible', 'values', '.')]

>> POS Tags are: 
 [('By', 'IN'), ('‘', 'JJ'), ('pre-training', 'JJ'), ('’', 'NNP'), ('several', 'JJ'), ('layers', 'NNS'), ('progressively', 'RB'), ('complex', 'JJ'), ('feature', 'NN'), ('detectors', 'NNS'), ('using', 'VBG'), ('reconstruction', 'NN'), ('objective', 'NN'), (',', ','), ('weights', 'NNS'), ('deep', 'VBP'), ('network', 'NN'), ('could', 'MD'), ('initialized', 'VB'), ('sensible', 'JJ'), ('values', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['‘ pre-training ’', 'several layers', 'complex feature detectors', 'reconstruction objective', 'weights', 'network', 'sensible values']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('By', 'by'), ('‘', '‘'), ('pre-training', 'pre-train'), ('’', '’'), ('several', 'sever'), ('layers', 'layer'), ('progressively', 'progress'), ('complex', 'complex'), ('feature', 'featur'), ('detectors', 'detector'), ('using', 'use'), ('reconstruction', 'reconstruct'), ('objective', 'object'), (',', ','), ('weights', 'weight'), ('deep', 'deep'), ('network', 'network'), ('could', 'could'), ('initialized', 'initi'), ('sensible', 'sensibl'), ('values', 'valu'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('By', 'by'), ('‘', '‘'), ('pre-training', 'pre-train'), ('’', '’'), ('several', 'sever'), ('layers', 'layer'), ('progressively', 'progress'), ('complex', 'complex'), ('feature', 'featur'), ('detectors', 'detector'), ('using', 'use'), ('reconstruction', 'reconstruct'), ('objective', 'object'), (',', ','), ('weights', 'weight'), ('deep', 'deep'), ('network', 'network'), ('could', 'could'), ('initialized', 'initi'), ('sensible', 'sensibl'), ('values', 'valu'), ('.', '.')]

>> Lemmatization: 
 [('By', 'By'), ('‘', '‘'), ('pre-training', 'pre-training'), ('’', '’'), ('several', 'several'), ('layers', 'layer'), ('progressively', 'progressively'), ('complex', 'complex'), ('feature', 'feature'), ('detectors', 'detector'), ('using', 'using'), ('reconstruction', 'reconstruction'), ('objective', 'objective'), (',', ','), ('weights', 'weight'), ('deep', 'deep'), ('network', 'network'), ('could', 'could'), ('initialized', 'initialized'), ('sensible', 'sensible'), ('values', 'value'), ('.', '.')]


------------------- Sentence 5 -------------------

A final layer of  output units could then be added to the top of the network and the  whole deep system could be fine-tuned using standard backpropaga- tion33–35.

>> Tokens are: 
 ['A', 'final', 'layer', 'output', 'units', 'could', 'added', 'top', 'network', 'whole', 'deep', 'system', 'could', 'fine-tuned', 'using', 'standard', 'backpropaga-', 'tion33–35', '.']

>> Bigrams are: 
 [('A', 'final'), ('final', 'layer'), ('layer', 'output'), ('output', 'units'), ('units', 'could'), ('could', 'added'), ('added', 'top'), ('top', 'network'), ('network', 'whole'), ('whole', 'deep'), ('deep', 'system'), ('system', 'could'), ('could', 'fine-tuned'), ('fine-tuned', 'using'), ('using', 'standard'), ('standard', 'backpropaga-'), ('backpropaga-', 'tion33–35'), ('tion33–35', '.')]

>> Trigrams are: 
 [('A', 'final', 'layer'), ('final', 'layer', 'output'), ('layer', 'output', 'units'), ('output', 'units', 'could'), ('units', 'could', 'added'), ('could', 'added', 'top'), ('added', 'top', 'network'), ('top', 'network', 'whole'), ('network', 'whole', 'deep'), ('whole', 'deep', 'system'), ('deep', 'system', 'could'), ('system', 'could', 'fine-tuned'), ('could', 'fine-tuned', 'using'), ('fine-tuned', 'using', 'standard'), ('using', 'standard', 'backpropaga-'), ('standard', 'backpropaga-', 'tion33–35'), ('backpropaga-', 'tion33–35', '.')]

>> POS Tags are: 
 [('A', 'DT'), ('final', 'JJ'), ('layer', 'NN'), ('output', 'NN'), ('units', 'NNS'), ('could', 'MD'), ('added', 'VB'), ('top', 'JJ'), ('network', 'NN'), ('whole', 'JJ'), ('deep', 'NN'), ('system', 'NN'), ('could', 'MD'), ('fine-tuned', 'VB'), ('using', 'VBG'), ('standard', 'JJ'), ('backpropaga-', 'JJ'), ('tion33–35', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['A final layer output units', 'top network', 'whole deep system', 'standard backpropaga- tion33–35']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('A', 'a'), ('final', 'final'), ('layer', 'layer'), ('output', 'output'), ('units', 'unit'), ('could', 'could'), ('added', 'ad'), ('top', 'top'), ('network', 'network'), ('whole', 'whole'), ('deep', 'deep'), ('system', 'system'), ('could', 'could'), ('fine-tuned', 'fine-tun'), ('using', 'use'), ('standard', 'standard'), ('backpropaga-', 'backpropaga-'), ('tion33–35', 'tion33–35'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('A', 'a'), ('final', 'final'), ('layer', 'layer'), ('output', 'output'), ('units', 'unit'), ('could', 'could'), ('added', 'ad'), ('top', 'top'), ('network', 'network'), ('whole', 'whole'), ('deep', 'deep'), ('system', 'system'), ('could', 'could'), ('fine-tuned', 'fine-tun'), ('using', 'use'), ('standard', 'standard'), ('backpropaga-', 'backpropaga-'), ('tion33–35', 'tion33–35'), ('.', '.')]

>> Lemmatization: 
 [('A', 'A'), ('final', 'final'), ('layer', 'layer'), ('output', 'output'), ('units', 'unit'), ('could', 'could'), ('added', 'added'), ('top', 'top'), ('network', 'network'), ('whole', 'whole'), ('deep', 'deep'), ('system', 'system'), ('could', 'could'), ('fine-tuned', 'fine-tuned'), ('using', 'using'), ('standard', 'standard'), ('backpropaga-', 'backpropaga-'), ('tion33–35', 'tion33–35'), ('.', '.')]


------------------- Sentence 6 -------------------

This worked remarkably well for recognizing handwritten  digits or for detecting pedestrians, especially when the amount of  labelled data was very limited36.

>> Tokens are: 
 ['This', 'worked', 'remarkably', 'well', 'recognizing', 'handwritten', 'digits', 'detecting', 'pedestrians', ',', 'especially', 'amount', 'labelled', 'data', 'limited36', '.']

>> Bigrams are: 
 [('This', 'worked'), ('worked', 'remarkably'), ('remarkably', 'well'), ('well', 'recognizing'), ('recognizing', 'handwritten'), ('handwritten', 'digits'), ('digits', 'detecting'), ('detecting', 'pedestrians'), ('pedestrians', ','), (',', 'especially'), ('especially', 'amount'), ('amount', 'labelled'), ('labelled', 'data'), ('data', 'limited36'), ('limited36', '.')]

>> Trigrams are: 
 [('This', 'worked', 'remarkably'), ('worked', 'remarkably', 'well'), ('remarkably', 'well', 'recognizing'), ('well', 'recognizing', 'handwritten'), ('recognizing', 'handwritten', 'digits'), ('handwritten', 'digits', 'detecting'), ('digits', 'detecting', 'pedestrians'), ('detecting', 'pedestrians', ','), ('pedestrians', ',', 'especially'), (',', 'especially', 'amount'), ('especially', 'amount', 'labelled'), ('amount', 'labelled', 'data'), ('labelled', 'data', 'limited36'), ('data', 'limited36', '.')]

>> POS Tags are: 
 [('This', 'DT'), ('worked', 'VBD'), ('remarkably', 'RB'), ('well', 'RB'), ('recognizing', 'VBG'), ('handwritten', 'VBN'), ('digits', 'NNS'), ('detecting', 'VBG'), ('pedestrians', 'NNS'), (',', ','), ('especially', 'RB'), ('amount', 'VB'), ('labelled', 'JJ'), ('data', 'NNS'), ('limited36', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['digits', 'pedestrians', 'labelled data limited36']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('This', 'thi'), ('worked', 'work'), ('remarkably', 'remark'), ('well', 'well'), ('recognizing', 'recogn'), ('handwritten', 'handwritten'), ('digits', 'digit'), ('detecting', 'detect'), ('pedestrians', 'pedestrian'), (',', ','), ('especially', 'especi'), ('amount', 'amount'), ('labelled', 'label'), ('data', 'data'), ('limited36', 'limited36'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('This', 'this'), ('worked', 'work'), ('remarkably', 'remark'), ('well', 'well'), ('recognizing', 'recogn'), ('handwritten', 'handwritten'), ('digits', 'digit'), ('detecting', 'detect'), ('pedestrians', 'pedestrian'), (',', ','), ('especially', 'especi'), ('amount', 'amount'), ('labelled', 'label'), ('data', 'data'), ('limited36', 'limited36'), ('.', '.')]

>> Lemmatization: 
 [('This', 'This'), ('worked', 'worked'), ('remarkably', 'remarkably'), ('well', 'well'), ('recognizing', 'recognizing'), ('handwritten', 'handwritten'), ('digits', 'digit'), ('detecting', 'detecting'), ('pedestrians', 'pedestrian'), (',', ','), ('especially', 'especially'), ('amount', 'amount'), ('labelled', 'labelled'), ('data', 'data'), ('limited36', 'limited36'), ('.', '.')]



========================================== PARAGRAPH 115 ===========================================

The first major application of this pre-training approach was in  speech recognition, and it was made possible by the advent of fast  graphics processing units (GPUs) that were convenient to program37  and allowed researchers to train networks 10 or 20 times faster. In  2009, the approach was used to map short temporal windows of coef- ficients extracted from a sound wave to a set of probabilities for the  various fragments of speech that might be represented by the frame  in the centre of the window. It achieved record-breaking results on a  standard speech recognition benchmark that used a small vocabu- lary38 and was quickly developed to give record-breaking results on  a large vocabulary task39. By 2012, versions of the deep net from 2009  were being developed by many of the major speech groups6 and were  already being deployed in Android phones. For smaller data sets,  unsupervised pre-training helps to prevent overfitting40, leading to  significantly better generalization when the number of labelled exam- ples is small, or in a transfer setting where we have lots of examples  for some ‘source’ tasks but very few for some ‘target’ tasks. Once deep  learning had been rehabilitated, it turned out that the pre-training  stage was only needed for small data sets.  

------------------- Sentence 1 -------------------

The first major application of this pre-training approach was in  speech recognition, and it was made possible by the advent of fast  graphics processing units (GPUs) that were convenient to program37  and allowed researchers to train networks 10 or 20 times faster.

>> Tokens are: 
 ['The', 'first', 'major', 'application', 'pre-training', 'approach', 'speech', 'recognition', ',', 'made', 'possible', 'advent', 'fast', 'graphics', 'processing', 'units', '(', 'GPUs', ')', 'convenient', 'program37', 'allowed', 'researchers', 'train', 'networks', '10', '20', 'times', 'faster', '.']

>> Bigrams are: 
 [('The', 'first'), ('first', 'major'), ('major', 'application'), ('application', 'pre-training'), ('pre-training', 'approach'), ('approach', 'speech'), ('speech', 'recognition'), ('recognition', ','), (',', 'made'), ('made', 'possible'), ('possible', 'advent'), ('advent', 'fast'), ('fast', 'graphics'), ('graphics', 'processing'), ('processing', 'units'), ('units', '('), ('(', 'GPUs'), ('GPUs', ')'), (')', 'convenient'), ('convenient', 'program37'), ('program37', 'allowed'), ('allowed', 'researchers'), ('researchers', 'train'), ('train', 'networks'), ('networks', '10'), ('10', '20'), ('20', 'times'), ('times', 'faster'), ('faster', '.')]

>> Trigrams are: 
 [('The', 'first', 'major'), ('first', 'major', 'application'), ('major', 'application', 'pre-training'), ('application', 'pre-training', 'approach'), ('pre-training', 'approach', 'speech'), ('approach', 'speech', 'recognition'), ('speech', 'recognition', ','), ('recognition', ',', 'made'), (',', 'made', 'possible'), ('made', 'possible', 'advent'), ('possible', 'advent', 'fast'), ('advent', 'fast', 'graphics'), ('fast', 'graphics', 'processing'), ('graphics', 'processing', 'units'), ('processing', 'units', '('), ('units', '(', 'GPUs'), ('(', 'GPUs', ')'), ('GPUs', ')', 'convenient'), (')', 'convenient', 'program37'), ('convenient', 'program37', 'allowed'), ('program37', 'allowed', 'researchers'), ('allowed', 'researchers', 'train'), ('researchers', 'train', 'networks'), ('train', 'networks', '10'), ('networks', '10', '20'), ('10', '20', 'times'), ('20', 'times', 'faster'), ('times', 'faster', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('first', 'JJ'), ('major', 'JJ'), ('application', 'NN'), ('pre-training', 'JJ'), ('approach', 'NN'), ('speech', 'NN'), ('recognition', 'NN'), (',', ','), ('made', 'VBD'), ('possible', 'JJ'), ('advent', 'JJ'), ('fast', 'NN'), ('graphics', 'NNS'), ('processing', 'VBG'), ('units', 'NNS'), ('(', '('), ('GPUs', 'NNP'), (')', ')'), ('convenient', 'NN'), ('program37', 'NN'), ('allowed', 'VBD'), ('researchers', 'NNS'), ('train', 'VBP'), ('networks', 'NNS'), ('10', 'CD'), ('20', 'CD'), ('times', 'NNS'), ('faster', 'RBR'), ('.', '.')]

>> Noun Phrases are: 
 ['The first major application', 'pre-training approach speech recognition', 'possible advent fast graphics', 'units', 'GPUs', 'convenient program37', 'researchers', 'networks', 'times']

>> Named Entities are: 
 [('ORGANIZATION', 'GPUs')] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('first', 'first'), ('major', 'major'), ('application', 'applic'), ('pre-training', 'pre-train'), ('approach', 'approach'), ('speech', 'speech'), ('recognition', 'recognit'), (',', ','), ('made', 'made'), ('possible', 'possibl'), ('advent', 'advent'), ('fast', 'fast'), ('graphics', 'graphic'), ('processing', 'process'), ('units', 'unit'), ('(', '('), ('GPUs', 'gpu'), (')', ')'), ('convenient', 'conveni'), ('program37', 'program37'), ('allowed', 'allow'), ('researchers', 'research'), ('train', 'train'), ('networks', 'network'), ('10', '10'), ('20', '20'), ('times', 'time'), ('faster', 'faster'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('first', 'first'), ('major', 'major'), ('application', 'applic'), ('pre-training', 'pre-train'), ('approach', 'approach'), ('speech', 'speech'), ('recognition', 'recognit'), (',', ','), ('made', 'made'), ('possible', 'possibl'), ('advent', 'advent'), ('fast', 'fast'), ('graphics', 'graphic'), ('processing', 'process'), ('units', 'unit'), ('(', '('), ('GPUs', 'gpus'), (')', ')'), ('convenient', 'conveni'), ('program37', 'program37'), ('allowed', 'allow'), ('researchers', 'research'), ('train', 'train'), ('networks', 'network'), ('10', '10'), ('20', '20'), ('times', 'time'), ('faster', 'faster'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('first', 'first'), ('major', 'major'), ('application', 'application'), ('pre-training', 'pre-training'), ('approach', 'approach'), ('speech', 'speech'), ('recognition', 'recognition'), (',', ','), ('made', 'made'), ('possible', 'possible'), ('advent', 'advent'), ('fast', 'fast'), ('graphics', 'graphic'), ('processing', 'processing'), ('units', 'unit'), ('(', '('), ('GPUs', 'GPUs'), (')', ')'), ('convenient', 'convenient'), ('program37', 'program37'), ('allowed', 'allowed'), ('researchers', 'researcher'), ('train', 'train'), ('networks', 'network'), ('10', '10'), ('20', '20'), ('times', 'time'), ('faster', 'faster'), ('.', '.')]


------------------- Sentence 2 -------------------

In  2009, the approach was used to map short temporal windows of coef- ficients extracted from a sound wave to a set of probabilities for the  various fragments of speech that might be represented by the frame  in the centre of the window.

>> Tokens are: 
 ['In', '2009', ',', 'approach', 'used', 'map', 'short', 'temporal', 'windows', 'coef-', 'ficients', 'extracted', 'sound', 'wave', 'set', 'probabilities', 'various', 'fragments', 'speech', 'might', 'represented', 'frame', 'centre', 'window', '.']

>> Bigrams are: 
 [('In', '2009'), ('2009', ','), (',', 'approach'), ('approach', 'used'), ('used', 'map'), ('map', 'short'), ('short', 'temporal'), ('temporal', 'windows'), ('windows', 'coef-'), ('coef-', 'ficients'), ('ficients', 'extracted'), ('extracted', 'sound'), ('sound', 'wave'), ('wave', 'set'), ('set', 'probabilities'), ('probabilities', 'various'), ('various', 'fragments'), ('fragments', 'speech'), ('speech', 'might'), ('might', 'represented'), ('represented', 'frame'), ('frame', 'centre'), ('centre', 'window'), ('window', '.')]

>> Trigrams are: 
 [('In', '2009', ','), ('2009', ',', 'approach'), (',', 'approach', 'used'), ('approach', 'used', 'map'), ('used', 'map', 'short'), ('map', 'short', 'temporal'), ('short', 'temporal', 'windows'), ('temporal', 'windows', 'coef-'), ('windows', 'coef-', 'ficients'), ('coef-', 'ficients', 'extracted'), ('ficients', 'extracted', 'sound'), ('extracted', 'sound', 'wave'), ('sound', 'wave', 'set'), ('wave', 'set', 'probabilities'), ('set', 'probabilities', 'various'), ('probabilities', 'various', 'fragments'), ('various', 'fragments', 'speech'), ('fragments', 'speech', 'might'), ('speech', 'might', 'represented'), ('might', 'represented', 'frame'), ('represented', 'frame', 'centre'), ('frame', 'centre', 'window'), ('centre', 'window', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('2009', 'CD'), (',', ','), ('approach', 'NN'), ('used', 'VBN'), ('map', 'JJ'), ('short', 'JJ'), ('temporal', 'JJ'), ('windows', 'NNS'), ('coef-', 'JJ'), ('ficients', 'NNS'), ('extracted', 'VBN'), ('sound', 'JJ'), ('wave', 'NN'), ('set', 'VBN'), ('probabilities', 'NNS'), ('various', 'JJ'), ('fragments', 'NNS'), ('speech', 'NN'), ('might', 'MD'), ('represented', 'VB'), ('frame', 'NN'), ('centre', 'NN'), ('window', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['approach', 'map short temporal windows', 'coef- ficients', 'sound wave', 'probabilities', 'various fragments speech', 'frame centre window']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('2009', '2009'), (',', ','), ('approach', 'approach'), ('used', 'use'), ('map', 'map'), ('short', 'short'), ('temporal', 'tempor'), ('windows', 'window'), ('coef-', 'coef-'), ('ficients', 'ficient'), ('extracted', 'extract'), ('sound', 'sound'), ('wave', 'wave'), ('set', 'set'), ('probabilities', 'probabl'), ('various', 'variou'), ('fragments', 'fragment'), ('speech', 'speech'), ('might', 'might'), ('represented', 'repres'), ('frame', 'frame'), ('centre', 'centr'), ('window', 'window'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('2009', '2009'), (',', ','), ('approach', 'approach'), ('used', 'use'), ('map', 'map'), ('short', 'short'), ('temporal', 'tempor'), ('windows', 'window'), ('coef-', 'coef-'), ('ficients', 'ficient'), ('extracted', 'extract'), ('sound', 'sound'), ('wave', 'wave'), ('set', 'set'), ('probabilities', 'probabl'), ('various', 'various'), ('fragments', 'fragment'), ('speech', 'speech'), ('might', 'might'), ('represented', 'repres'), ('frame', 'frame'), ('centre', 'centr'), ('window', 'window'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('2009', '2009'), (',', ','), ('approach', 'approach'), ('used', 'used'), ('map', 'map'), ('short', 'short'), ('temporal', 'temporal'), ('windows', 'window'), ('coef-', 'coef-'), ('ficients', 'ficients'), ('extracted', 'extracted'), ('sound', 'sound'), ('wave', 'wave'), ('set', 'set'), ('probabilities', 'probability'), ('various', 'various'), ('fragments', 'fragment'), ('speech', 'speech'), ('might', 'might'), ('represented', 'represented'), ('frame', 'frame'), ('centre', 'centre'), ('window', 'window'), ('.', '.')]


------------------- Sentence 3 -------------------

It achieved record-breaking results on a  standard speech recognition benchmark that used a small vocabu- lary38 and was quickly developed to give record-breaking results on  a large vocabulary task39.

>> Tokens are: 
 ['It', 'achieved', 'record-breaking', 'results', 'standard', 'speech', 'recognition', 'benchmark', 'used', 'small', 'vocabu-', 'lary38', 'quickly', 'developed', 'give', 'record-breaking', 'results', 'large', 'vocabulary', 'task39', '.']

>> Bigrams are: 
 [('It', 'achieved'), ('achieved', 'record-breaking'), ('record-breaking', 'results'), ('results', 'standard'), ('standard', 'speech'), ('speech', 'recognition'), ('recognition', 'benchmark'), ('benchmark', 'used'), ('used', 'small'), ('small', 'vocabu-'), ('vocabu-', 'lary38'), ('lary38', 'quickly'), ('quickly', 'developed'), ('developed', 'give'), ('give', 'record-breaking'), ('record-breaking', 'results'), ('results', 'large'), ('large', 'vocabulary'), ('vocabulary', 'task39'), ('task39', '.')]

>> Trigrams are: 
 [('It', 'achieved', 'record-breaking'), ('achieved', 'record-breaking', 'results'), ('record-breaking', 'results', 'standard'), ('results', 'standard', 'speech'), ('standard', 'speech', 'recognition'), ('speech', 'recognition', 'benchmark'), ('recognition', 'benchmark', 'used'), ('benchmark', 'used', 'small'), ('used', 'small', 'vocabu-'), ('small', 'vocabu-', 'lary38'), ('vocabu-', 'lary38', 'quickly'), ('lary38', 'quickly', 'developed'), ('quickly', 'developed', 'give'), ('developed', 'give', 'record-breaking'), ('give', 'record-breaking', 'results'), ('record-breaking', 'results', 'large'), ('results', 'large', 'vocabulary'), ('large', 'vocabulary', 'task39'), ('vocabulary', 'task39', '.')]

>> POS Tags are: 
 [('It', 'PRP'), ('achieved', 'VBD'), ('record-breaking', 'JJ'), ('results', 'NNS'), ('standard', 'JJ'), ('speech', 'JJ'), ('recognition', 'NN'), ('benchmark', 'NN'), ('used', 'VBN'), ('small', 'JJ'), ('vocabu-', 'JJ'), ('lary38', 'NN'), ('quickly', 'RB'), ('developed', 'VBD'), ('give', 'VB'), ('record-breaking', 'JJ'), ('results', 'NNS'), ('large', 'JJ'), ('vocabulary', 'JJ'), ('task39', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['record-breaking results', 'standard speech recognition benchmark', 'small vocabu- lary38', 'record-breaking results', 'large vocabulary task39']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('It', 'it'), ('achieved', 'achiev'), ('record-breaking', 'record-break'), ('results', 'result'), ('standard', 'standard'), ('speech', 'speech'), ('recognition', 'recognit'), ('benchmark', 'benchmark'), ('used', 'use'), ('small', 'small'), ('vocabu-', 'vocabu-'), ('lary38', 'lary38'), ('quickly', 'quickli'), ('developed', 'develop'), ('give', 'give'), ('record-breaking', 'record-break'), ('results', 'result'), ('large', 'larg'), ('vocabulary', 'vocabulari'), ('task39', 'task39'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('It', 'it'), ('achieved', 'achiev'), ('record-breaking', 'record-break'), ('results', 'result'), ('standard', 'standard'), ('speech', 'speech'), ('recognition', 'recognit'), ('benchmark', 'benchmark'), ('used', 'use'), ('small', 'small'), ('vocabu-', 'vocabu-'), ('lary38', 'lary38'), ('quickly', 'quick'), ('developed', 'develop'), ('give', 'give'), ('record-breaking', 'record-break'), ('results', 'result'), ('large', 'larg'), ('vocabulary', 'vocabulari'), ('task39', 'task39'), ('.', '.')]

>> Lemmatization: 
 [('It', 'It'), ('achieved', 'achieved'), ('record-breaking', 'record-breaking'), ('results', 'result'), ('standard', 'standard'), ('speech', 'speech'), ('recognition', 'recognition'), ('benchmark', 'benchmark'), ('used', 'used'), ('small', 'small'), ('vocabu-', 'vocabu-'), ('lary38', 'lary38'), ('quickly', 'quickly'), ('developed', 'developed'), ('give', 'give'), ('record-breaking', 'record-breaking'), ('results', 'result'), ('large', 'large'), ('vocabulary', 'vocabulary'), ('task39', 'task39'), ('.', '.')]


------------------- Sentence 4 -------------------

By 2012, versions of the deep net from 2009  were being developed by many of the major speech groups6 and were  already being deployed in Android phones.

>> Tokens are: 
 ['By', '2012', ',', 'versions', 'deep', 'net', '2009', 'developed', 'many', 'major', 'speech', 'groups6', 'already', 'deployed', 'Android', 'phones', '.']

>> Bigrams are: 
 [('By', '2012'), ('2012', ','), (',', 'versions'), ('versions', 'deep'), ('deep', 'net'), ('net', '2009'), ('2009', 'developed'), ('developed', 'many'), ('many', 'major'), ('major', 'speech'), ('speech', 'groups6'), ('groups6', 'already'), ('already', 'deployed'), ('deployed', 'Android'), ('Android', 'phones'), ('phones', '.')]

>> Trigrams are: 
 [('By', '2012', ','), ('2012', ',', 'versions'), (',', 'versions', 'deep'), ('versions', 'deep', 'net'), ('deep', 'net', '2009'), ('net', '2009', 'developed'), ('2009', 'developed', 'many'), ('developed', 'many', 'major'), ('many', 'major', 'speech'), ('major', 'speech', 'groups6'), ('speech', 'groups6', 'already'), ('groups6', 'already', 'deployed'), ('already', 'deployed', 'Android'), ('deployed', 'Android', 'phones'), ('Android', 'phones', '.')]

>> POS Tags are: 
 [('By', 'IN'), ('2012', 'CD'), (',', ','), ('versions', 'NNS'), ('deep', 'VBP'), ('net', 'JJ'), ('2009', 'CD'), ('developed', 'VBD'), ('many', 'JJ'), ('major', 'JJ'), ('speech', 'NN'), ('groups6', 'NN'), ('already', 'RB'), ('deployed', 'VBN'), ('Android', 'NNP'), ('phones', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['versions', 'many major speech groups6', 'Android phones']

>> Named Entities are: 
 [('PERSON', 'Android')] 

>> Stemming using Porter Stemmer: 
 [('By', 'by'), ('2012', '2012'), (',', ','), ('versions', 'version'), ('deep', 'deep'), ('net', 'net'), ('2009', '2009'), ('developed', 'develop'), ('many', 'mani'), ('major', 'major'), ('speech', 'speech'), ('groups6', 'groups6'), ('already', 'alreadi'), ('deployed', 'deploy'), ('Android', 'android'), ('phones', 'phone'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('By', 'by'), ('2012', '2012'), (',', ','), ('versions', 'version'), ('deep', 'deep'), ('net', 'net'), ('2009', '2009'), ('developed', 'develop'), ('many', 'mani'), ('major', 'major'), ('speech', 'speech'), ('groups6', 'groups6'), ('already', 'alreadi'), ('deployed', 'deploy'), ('Android', 'android'), ('phones', 'phone'), ('.', '.')]

>> Lemmatization: 
 [('By', 'By'), ('2012', '2012'), (',', ','), ('versions', 'version'), ('deep', 'deep'), ('net', 'net'), ('2009', '2009'), ('developed', 'developed'), ('many', 'many'), ('major', 'major'), ('speech', 'speech'), ('groups6', 'groups6'), ('already', 'already'), ('deployed', 'deployed'), ('Android', 'Android'), ('phones', 'phone'), ('.', '.')]


------------------- Sentence 5 -------------------

For smaller data sets,  unsupervised pre-training helps to prevent overfitting40, leading to  significantly better generalization when the number of labelled exam- ples is small, or in a transfer setting where we have lots of examples  for some ‘source’ tasks but very few for some ‘target’ tasks.

>> Tokens are: 
 ['For', 'smaller', 'data', 'sets', ',', 'unsupervised', 'pre-training', 'helps', 'prevent', 'overfitting40', ',', 'leading', 'significantly', 'better', 'generalization', 'number', 'labelled', 'exam-', 'ples', 'small', ',', 'transfer', 'setting', 'lots', 'examples', '‘', 'source', '’', 'tasks', '‘', 'target', '’', 'tasks', '.']

>> Bigrams are: 
 [('For', 'smaller'), ('smaller', 'data'), ('data', 'sets'), ('sets', ','), (',', 'unsupervised'), ('unsupervised', 'pre-training'), ('pre-training', 'helps'), ('helps', 'prevent'), ('prevent', 'overfitting40'), ('overfitting40', ','), (',', 'leading'), ('leading', 'significantly'), ('significantly', 'better'), ('better', 'generalization'), ('generalization', 'number'), ('number', 'labelled'), ('labelled', 'exam-'), ('exam-', 'ples'), ('ples', 'small'), ('small', ','), (',', 'transfer'), ('transfer', 'setting'), ('setting', 'lots'), ('lots', 'examples'), ('examples', '‘'), ('‘', 'source'), ('source', '’'), ('’', 'tasks'), ('tasks', '‘'), ('‘', 'target'), ('target', '’'), ('’', 'tasks'), ('tasks', '.')]

>> Trigrams are: 
 [('For', 'smaller', 'data'), ('smaller', 'data', 'sets'), ('data', 'sets', ','), ('sets', ',', 'unsupervised'), (',', 'unsupervised', 'pre-training'), ('unsupervised', 'pre-training', 'helps'), ('pre-training', 'helps', 'prevent'), ('helps', 'prevent', 'overfitting40'), ('prevent', 'overfitting40', ','), ('overfitting40', ',', 'leading'), (',', 'leading', 'significantly'), ('leading', 'significantly', 'better'), ('significantly', 'better', 'generalization'), ('better', 'generalization', 'number'), ('generalization', 'number', 'labelled'), ('number', 'labelled', 'exam-'), ('labelled', 'exam-', 'ples'), ('exam-', 'ples', 'small'), ('ples', 'small', ','), ('small', ',', 'transfer'), (',', 'transfer', 'setting'), ('transfer', 'setting', 'lots'), ('setting', 'lots', 'examples'), ('lots', 'examples', '‘'), ('examples', '‘', 'source'), ('‘', 'source', '’'), ('source', '’', 'tasks'), ('’', 'tasks', '‘'), ('tasks', '‘', 'target'), ('‘', 'target', '’'), ('target', '’', 'tasks'), ('’', 'tasks', '.')]

>> POS Tags are: 
 [('For', 'IN'), ('smaller', 'JJR'), ('data', 'NN'), ('sets', 'NNS'), (',', ','), ('unsupervised', 'JJ'), ('pre-training', 'NN'), ('helps', 'VBZ'), ('prevent', 'VB'), ('overfitting40', 'NN'), (',', ','), ('leading', 'VBG'), ('significantly', 'RB'), ('better', 'JJR'), ('generalization', 'NN'), ('number', 'NN'), ('labelled', 'VBD'), ('exam-', 'JJ'), ('ples', 'NNS'), ('small', 'JJ'), (',', ','), ('transfer', 'VB'), ('setting', 'VBG'), ('lots', 'NNS'), ('examples', 'NNS'), ('‘', 'VBP'), ('source', 'NN'), ('’', 'NN'), ('tasks', 'NNS'), ('‘', 'VBP'), ('target', 'NN'), ('’', 'JJ'), ('tasks', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['data sets', 'unsupervised pre-training', 'overfitting40', 'generalization number', 'exam- ples', 'lots examples', 'source ’ tasks', 'target', '’ tasks']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('For', 'for'), ('smaller', 'smaller'), ('data', 'data'), ('sets', 'set'), (',', ','), ('unsupervised', 'unsupervis'), ('pre-training', 'pre-train'), ('helps', 'help'), ('prevent', 'prevent'), ('overfitting40', 'overfitting40'), (',', ','), ('leading', 'lead'), ('significantly', 'significantli'), ('better', 'better'), ('generalization', 'gener'), ('number', 'number'), ('labelled', 'label'), ('exam-', 'exam-'), ('ples', 'ple'), ('small', 'small'), (',', ','), ('transfer', 'transfer'), ('setting', 'set'), ('lots', 'lot'), ('examples', 'exampl'), ('‘', '‘'), ('source', 'sourc'), ('’', '’'), ('tasks', 'task'), ('‘', '‘'), ('target', 'target'), ('’', '’'), ('tasks', 'task'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('For', 'for'), ('smaller', 'smaller'), ('data', 'data'), ('sets', 'set'), (',', ','), ('unsupervised', 'unsupervis'), ('pre-training', 'pre-train'), ('helps', 'help'), ('prevent', 'prevent'), ('overfitting40', 'overfitting40'), (',', ','), ('leading', 'lead'), ('significantly', 'signific'), ('better', 'better'), ('generalization', 'general'), ('number', 'number'), ('labelled', 'label'), ('exam-', 'exam-'), ('ples', 'ples'), ('small', 'small'), (',', ','), ('transfer', 'transfer'), ('setting', 'set'), ('lots', 'lot'), ('examples', 'exampl'), ('‘', '‘'), ('source', 'sourc'), ('’', '’'), ('tasks', 'task'), ('‘', '‘'), ('target', 'target'), ('’', '’'), ('tasks', 'task'), ('.', '.')]

>> Lemmatization: 
 [('For', 'For'), ('smaller', 'smaller'), ('data', 'data'), ('sets', 'set'), (',', ','), ('unsupervised', 'unsupervised'), ('pre-training', 'pre-training'), ('helps', 'help'), ('prevent', 'prevent'), ('overfitting40', 'overfitting40'), (',', ','), ('leading', 'leading'), ('significantly', 'significantly'), ('better', 'better'), ('generalization', 'generalization'), ('number', 'number'), ('labelled', 'labelled'), ('exam-', 'exam-'), ('ples', 'ples'), ('small', 'small'), (',', ','), ('transfer', 'transfer'), ('setting', 'setting'), ('lots', 'lot'), ('examples', 'example'), ('‘', '‘'), ('source', 'source'), ('’', '’'), ('tasks', 'task'), ('‘', '‘'), ('target', 'target'), ('’', '’'), ('tasks', 'task'), ('.', '.')]


------------------- Sentence 6 -------------------

Once deep  learning had been rehabilitated, it turned out that the pre-training  stage was only needed for small data sets.

>> Tokens are: 
 ['Once', 'deep', 'learning', 'rehabilitated', ',', 'turned', 'pre-training', 'stage', 'needed', 'small', 'data', 'sets', '.']

>> Bigrams are: 
 [('Once', 'deep'), ('deep', 'learning'), ('learning', 'rehabilitated'), ('rehabilitated', ','), (',', 'turned'), ('turned', 'pre-training'), ('pre-training', 'stage'), ('stage', 'needed'), ('needed', 'small'), ('small', 'data'), ('data', 'sets'), ('sets', '.')]

>> Trigrams are: 
 [('Once', 'deep', 'learning'), ('deep', 'learning', 'rehabilitated'), ('learning', 'rehabilitated', ','), ('rehabilitated', ',', 'turned'), (',', 'turned', 'pre-training'), ('turned', 'pre-training', 'stage'), ('pre-training', 'stage', 'needed'), ('stage', 'needed', 'small'), ('needed', 'small', 'data'), ('small', 'data', 'sets'), ('data', 'sets', '.')]

>> POS Tags are: 
 [('Once', 'RB'), ('deep', 'JJ'), ('learning', 'NN'), ('rehabilitated', 'VBN'), (',', ','), ('turned', 'VBD'), ('pre-training', 'JJ'), ('stage', 'NN'), ('needed', 'VBD'), ('small', 'JJ'), ('data', 'NNS'), ('sets', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['deep learning', 'pre-training stage', 'small data sets']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Once', 'onc'), ('deep', 'deep'), ('learning', 'learn'), ('rehabilitated', 'rehabilit'), (',', ','), ('turned', 'turn'), ('pre-training', 'pre-train'), ('stage', 'stage'), ('needed', 'need'), ('small', 'small'), ('data', 'data'), ('sets', 'set'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Once', 'onc'), ('deep', 'deep'), ('learning', 'learn'), ('rehabilitated', 'rehabilit'), (',', ','), ('turned', 'turn'), ('pre-training', 'pre-train'), ('stage', 'stage'), ('needed', 'need'), ('small', 'small'), ('data', 'data'), ('sets', 'set'), ('.', '.')]

>> Lemmatization: 
 [('Once', 'Once'), ('deep', 'deep'), ('learning', 'learning'), ('rehabilitated', 'rehabilitated'), (',', ','), ('turned', 'turned'), ('pre-training', 'pre-training'), ('stage', 'stage'), ('needed', 'needed'), ('small', 'small'), ('data', 'data'), ('sets', 'set'), ('.', '.')]



========================================== PARAGRAPH 116 ===========================================

There was, however, one particular type of deep, feedforward net- work that was much easier to train and generalized much better than  networks with full connectivity between adjacent layers. This was  the convolutional neural network (ConvNet)41,42. It achieved many  practical successes during the period when neural networks were out  of favour and it has recently been widely adopted by the computer- vision community.  

------------------- Sentence 1 -------------------

There was, however, one particular type of deep, feedforward net- work that was much easier to train and generalized much better than  networks with full connectivity between adjacent layers.

>> Tokens are: 
 ['There', ',', 'however', ',', 'one', 'particular', 'type', 'deep', ',', 'feedforward', 'net-', 'work', 'much', 'easier', 'train', 'generalized', 'much', 'better', 'networks', 'full', 'connectivity', 'adjacent', 'layers', '.']

>> Bigrams are: 
 [('There', ','), (',', 'however'), ('however', ','), (',', 'one'), ('one', 'particular'), ('particular', 'type'), ('type', 'deep'), ('deep', ','), (',', 'feedforward'), ('feedforward', 'net-'), ('net-', 'work'), ('work', 'much'), ('much', 'easier'), ('easier', 'train'), ('train', 'generalized'), ('generalized', 'much'), ('much', 'better'), ('better', 'networks'), ('networks', 'full'), ('full', 'connectivity'), ('connectivity', 'adjacent'), ('adjacent', 'layers'), ('layers', '.')]

>> Trigrams are: 
 [('There', ',', 'however'), (',', 'however', ','), ('however', ',', 'one'), (',', 'one', 'particular'), ('one', 'particular', 'type'), ('particular', 'type', 'deep'), ('type', 'deep', ','), ('deep', ',', 'feedforward'), (',', 'feedforward', 'net-'), ('feedforward', 'net-', 'work'), ('net-', 'work', 'much'), ('work', 'much', 'easier'), ('much', 'easier', 'train'), ('easier', 'train', 'generalized'), ('train', 'generalized', 'much'), ('generalized', 'much', 'better'), ('much', 'better', 'networks'), ('better', 'networks', 'full'), ('networks', 'full', 'connectivity'), ('full', 'connectivity', 'adjacent'), ('connectivity', 'adjacent', 'layers'), ('adjacent', 'layers', '.')]

>> POS Tags are: 
 [('There', 'EX'), (',', ','), ('however', 'RB'), (',', ','), ('one', 'CD'), ('particular', 'JJ'), ('type', 'NN'), ('deep', 'NN'), (',', ','), ('feedforward', 'JJ'), ('net-', 'JJ'), ('work', 'NN'), ('much', 'RB'), ('easier', 'JJR'), ('train', 'VB'), ('generalized', 'JJ'), ('much', 'RB'), ('better', 'JJR'), ('networks', 'NNS'), ('full', 'JJ'), ('connectivity', 'NN'), ('adjacent', 'JJ'), ('layers', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['particular type deep', 'feedforward net- work', 'networks', 'full connectivity', 'adjacent layers']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('There', 'there'), (',', ','), ('however', 'howev'), (',', ','), ('one', 'one'), ('particular', 'particular'), ('type', 'type'), ('deep', 'deep'), (',', ','), ('feedforward', 'feedforward'), ('net-', 'net-'), ('work', 'work'), ('much', 'much'), ('easier', 'easier'), ('train', 'train'), ('generalized', 'gener'), ('much', 'much'), ('better', 'better'), ('networks', 'network'), ('full', 'full'), ('connectivity', 'connect'), ('adjacent', 'adjac'), ('layers', 'layer'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('There', 'there'), (',', ','), ('however', 'howev'), (',', ','), ('one', 'one'), ('particular', 'particular'), ('type', 'type'), ('deep', 'deep'), (',', ','), ('feedforward', 'feedforward'), ('net-', 'net-'), ('work', 'work'), ('much', 'much'), ('easier', 'easier'), ('train', 'train'), ('generalized', 'general'), ('much', 'much'), ('better', 'better'), ('networks', 'network'), ('full', 'full'), ('connectivity', 'connect'), ('adjacent', 'adjac'), ('layers', 'layer'), ('.', '.')]

>> Lemmatization: 
 [('There', 'There'), (',', ','), ('however', 'however'), (',', ','), ('one', 'one'), ('particular', 'particular'), ('type', 'type'), ('deep', 'deep'), (',', ','), ('feedforward', 'feedforward'), ('net-', 'net-'), ('work', 'work'), ('much', 'much'), ('easier', 'easier'), ('train', 'train'), ('generalized', 'generalized'), ('much', 'much'), ('better', 'better'), ('networks', 'network'), ('full', 'full'), ('connectivity', 'connectivity'), ('adjacent', 'adjacent'), ('layers', 'layer'), ('.', '.')]


------------------- Sentence 2 -------------------

This was  the convolutional neural network (ConvNet)41,42.

>> Tokens are: 
 ['This', 'convolutional', 'neural', 'network', '(', 'ConvNet', ')', '41,42', '.']

>> Bigrams are: 
 [('This', 'convolutional'), ('convolutional', 'neural'), ('neural', 'network'), ('network', '('), ('(', 'ConvNet'), ('ConvNet', ')'), (')', '41,42'), ('41,42', '.')]

>> Trigrams are: 
 [('This', 'convolutional', 'neural'), ('convolutional', 'neural', 'network'), ('neural', 'network', '('), ('network', '(', 'ConvNet'), ('(', 'ConvNet', ')'), ('ConvNet', ')', '41,42'), (')', '41,42', '.')]

>> POS Tags are: 
 [('This', 'DT'), ('convolutional', 'JJ'), ('neural', 'JJ'), ('network', 'NN'), ('(', '('), ('ConvNet', 'NNP'), (')', ')'), ('41,42', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['This convolutional neural network', 'ConvNet']

>> Named Entities are: 
 [('ORGANIZATION', 'ConvNet')] 

>> Stemming using Porter Stemmer: 
 [('This', 'thi'), ('convolutional', 'convolut'), ('neural', 'neural'), ('network', 'network'), ('(', '('), ('ConvNet', 'convnet'), (')', ')'), ('41,42', '41,42'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('This', 'this'), ('convolutional', 'convolut'), ('neural', 'neural'), ('network', 'network'), ('(', '('), ('ConvNet', 'convnet'), (')', ')'), ('41,42', '41,42'), ('.', '.')]

>> Lemmatization: 
 [('This', 'This'), ('convolutional', 'convolutional'), ('neural', 'neural'), ('network', 'network'), ('(', '('), ('ConvNet', 'ConvNet'), (')', ')'), ('41,42', '41,42'), ('.', '.')]


------------------- Sentence 3 -------------------

It achieved many  practical successes during the period when neural networks were out  of favour and it has recently been widely adopted by the computer- vision community.

>> Tokens are: 
 ['It', 'achieved', 'many', 'practical', 'successes', 'period', 'neural', 'networks', 'favour', 'recently', 'widely', 'adopted', 'computer-', 'vision', 'community', '.']

>> Bigrams are: 
 [('It', 'achieved'), ('achieved', 'many'), ('many', 'practical'), ('practical', 'successes'), ('successes', 'period'), ('period', 'neural'), ('neural', 'networks'), ('networks', 'favour'), ('favour', 'recently'), ('recently', 'widely'), ('widely', 'adopted'), ('adopted', 'computer-'), ('computer-', 'vision'), ('vision', 'community'), ('community', '.')]

>> Trigrams are: 
 [('It', 'achieved', 'many'), ('achieved', 'many', 'practical'), ('many', 'practical', 'successes'), ('practical', 'successes', 'period'), ('successes', 'period', 'neural'), ('period', 'neural', 'networks'), ('neural', 'networks', 'favour'), ('networks', 'favour', 'recently'), ('favour', 'recently', 'widely'), ('recently', 'widely', 'adopted'), ('widely', 'adopted', 'computer-'), ('adopted', 'computer-', 'vision'), ('computer-', 'vision', 'community'), ('vision', 'community', '.')]

>> POS Tags are: 
 [('It', 'PRP'), ('achieved', 'VBD'), ('many', 'JJ'), ('practical', 'JJ'), ('successes', 'NNS'), ('period', 'NN'), ('neural', 'JJ'), ('networks', 'NNS'), ('favour', 'VBP'), ('recently', 'RB'), ('widely', 'RB'), ('adopted', 'VBN'), ('computer-', 'JJ'), ('vision', 'NN'), ('community', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['many practical successes period', 'neural networks', 'computer- vision community']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('It', 'it'), ('achieved', 'achiev'), ('many', 'mani'), ('practical', 'practic'), ('successes', 'success'), ('period', 'period'), ('neural', 'neural'), ('networks', 'network'), ('favour', 'favour'), ('recently', 'recent'), ('widely', 'wide'), ('adopted', 'adopt'), ('computer-', 'computer-'), ('vision', 'vision'), ('community', 'commun'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('It', 'it'), ('achieved', 'achiev'), ('many', 'mani'), ('practical', 'practic'), ('successes', 'success'), ('period', 'period'), ('neural', 'neural'), ('networks', 'network'), ('favour', 'favour'), ('recently', 'recent'), ('widely', 'wide'), ('adopted', 'adopt'), ('computer-', 'computer-'), ('vision', 'vision'), ('community', 'communiti'), ('.', '.')]

>> Lemmatization: 
 [('It', 'It'), ('achieved', 'achieved'), ('many', 'many'), ('practical', 'practical'), ('successes', 'success'), ('period', 'period'), ('neural', 'neural'), ('networks', 'network'), ('favour', 'favour'), ('recently', 'recently'), ('widely', 'widely'), ('adopted', 'adopted'), ('computer-', 'computer-'), ('vision', 'vision'), ('community', 'community'), ('.', '.')]



========================================== PARAGRAPH 117 ===========================================

Convolutional neural networks  ConvNets are designed to process data that come in the form of  multiple arrays, for example a colour image composed of three 2D  arrays containing pixel intensities in the three colour channels. Many  data modalities are in the form of multiple arrays: 1D for signals and  sequences, including language; 2D for images or audio spectrograms;  and 3D for video or volumetric images. There are four key ideas  behind ConvNets that take advantage of the properties of natural  signals: local connections, shared weights, pooling and the use of  many layers.  

------------------- Sentence 1 -------------------

Convolutional neural networks  ConvNets are designed to process data that come in the form of  multiple arrays, for example a colour image composed of three 2D  arrays containing pixel intensities in the three colour channels.

>> Tokens are: 
 ['Convolutional', 'neural', 'networks', 'ConvNets', 'designed', 'process', 'data', 'come', 'form', 'multiple', 'arrays', ',', 'example', 'colour', 'image', 'composed', 'three', '2D', 'arrays', 'containing', 'pixel', 'intensities', 'three', 'colour', 'channels', '.']

>> Bigrams are: 
 [('Convolutional', 'neural'), ('neural', 'networks'), ('networks', 'ConvNets'), ('ConvNets', 'designed'), ('designed', 'process'), ('process', 'data'), ('data', 'come'), ('come', 'form'), ('form', 'multiple'), ('multiple', 'arrays'), ('arrays', ','), (',', 'example'), ('example', 'colour'), ('colour', 'image'), ('image', 'composed'), ('composed', 'three'), ('three', '2D'), ('2D', 'arrays'), ('arrays', 'containing'), ('containing', 'pixel'), ('pixel', 'intensities'), ('intensities', 'three'), ('three', 'colour'), ('colour', 'channels'), ('channels', '.')]

>> Trigrams are: 
 [('Convolutional', 'neural', 'networks'), ('neural', 'networks', 'ConvNets'), ('networks', 'ConvNets', 'designed'), ('ConvNets', 'designed', 'process'), ('designed', 'process', 'data'), ('process', 'data', 'come'), ('data', 'come', 'form'), ('come', 'form', 'multiple'), ('form', 'multiple', 'arrays'), ('multiple', 'arrays', ','), ('arrays', ',', 'example'), (',', 'example', 'colour'), ('example', 'colour', 'image'), ('colour', 'image', 'composed'), ('image', 'composed', 'three'), ('composed', 'three', '2D'), ('three', '2D', 'arrays'), ('2D', 'arrays', 'containing'), ('arrays', 'containing', 'pixel'), ('containing', 'pixel', 'intensities'), ('pixel', 'intensities', 'three'), ('intensities', 'three', 'colour'), ('three', 'colour', 'channels'), ('colour', 'channels', '.')]

>> POS Tags are: 
 [('Convolutional', 'JJ'), ('neural', 'JJ'), ('networks', 'NNS'), ('ConvNets', 'NNS'), ('designed', 'VBN'), ('process', 'NN'), ('data', 'NNS'), ('come', 'VBP'), ('form', 'NN'), ('multiple', 'NN'), ('arrays', 'NNS'), (',', ','), ('example', 'NN'), ('colour', 'NN'), ('image', 'NN'), ('composed', 'VBD'), ('three', 'CD'), ('2D', 'CD'), ('arrays', 'NNS'), ('containing', 'VBG'), ('pixel', 'NN'), ('intensities', 'NNS'), ('three', 'CD'), ('colour', 'NN'), ('channels', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['Convolutional neural networks ConvNets', 'process data', 'form multiple arrays', 'example colour image', 'arrays', 'pixel intensities', 'colour channels']

>> Named Entities are: 
 [('ORGANIZATION', 'ConvNets')] 

>> Stemming using Porter Stemmer: 
 [('Convolutional', 'convolut'), ('neural', 'neural'), ('networks', 'network'), ('ConvNets', 'convnet'), ('designed', 'design'), ('process', 'process'), ('data', 'data'), ('come', 'come'), ('form', 'form'), ('multiple', 'multipl'), ('arrays', 'array'), (',', ','), ('example', 'exampl'), ('colour', 'colour'), ('image', 'imag'), ('composed', 'compos'), ('three', 'three'), ('2D', '2d'), ('arrays', 'array'), ('containing', 'contain'), ('pixel', 'pixel'), ('intensities', 'intens'), ('three', 'three'), ('colour', 'colour'), ('channels', 'channel'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Convolutional', 'convolut'), ('neural', 'neural'), ('networks', 'network'), ('ConvNets', 'convnet'), ('designed', 'design'), ('process', 'process'), ('data', 'data'), ('come', 'come'), ('form', 'form'), ('multiple', 'multipl'), ('arrays', 'array'), (',', ','), ('example', 'exampl'), ('colour', 'colour'), ('image', 'imag'), ('composed', 'compos'), ('three', 'three'), ('2D', '2d'), ('arrays', 'array'), ('containing', 'contain'), ('pixel', 'pixel'), ('intensities', 'intens'), ('three', 'three'), ('colour', 'colour'), ('channels', 'channel'), ('.', '.')]

>> Lemmatization: 
 [('Convolutional', 'Convolutional'), ('neural', 'neural'), ('networks', 'network'), ('ConvNets', 'ConvNets'), ('designed', 'designed'), ('process', 'process'), ('data', 'data'), ('come', 'come'), ('form', 'form'), ('multiple', 'multiple'), ('arrays', 'array'), (',', ','), ('example', 'example'), ('colour', 'colour'), ('image', 'image'), ('composed', 'composed'), ('three', 'three'), ('2D', '2D'), ('arrays', 'array'), ('containing', 'containing'), ('pixel', 'pixel'), ('intensities', 'intensity'), ('three', 'three'), ('colour', 'colour'), ('channels', 'channel'), ('.', '.')]


------------------- Sentence 2 -------------------

Many  data modalities are in the form of multiple arrays: 1D for signals and  sequences, including language; 2D for images or audio spectrograms;  and 3D for video or volumetric images.

>> Tokens are: 
 ['Many', 'data', 'modalities', 'form', 'multiple', 'arrays', ':', '1D', 'signals', 'sequences', ',', 'including', 'language', ';', '2D', 'images', 'audio', 'spectrograms', ';', '3D', 'video', 'volumetric', 'images', '.']

>> Bigrams are: 
 [('Many', 'data'), ('data', 'modalities'), ('modalities', 'form'), ('form', 'multiple'), ('multiple', 'arrays'), ('arrays', ':'), (':', '1D'), ('1D', 'signals'), ('signals', 'sequences'), ('sequences', ','), (',', 'including'), ('including', 'language'), ('language', ';'), (';', '2D'), ('2D', 'images'), ('images', 'audio'), ('audio', 'spectrograms'), ('spectrograms', ';'), (';', '3D'), ('3D', 'video'), ('video', 'volumetric'), ('volumetric', 'images'), ('images', '.')]

>> Trigrams are: 
 [('Many', 'data', 'modalities'), ('data', 'modalities', 'form'), ('modalities', 'form', 'multiple'), ('form', 'multiple', 'arrays'), ('multiple', 'arrays', ':'), ('arrays', ':', '1D'), (':', '1D', 'signals'), ('1D', 'signals', 'sequences'), ('signals', 'sequences', ','), ('sequences', ',', 'including'), (',', 'including', 'language'), ('including', 'language', ';'), ('language', ';', '2D'), (';', '2D', 'images'), ('2D', 'images', 'audio'), ('images', 'audio', 'spectrograms'), ('audio', 'spectrograms', ';'), ('spectrograms', ';', '3D'), (';', '3D', 'video'), ('3D', 'video', 'volumetric'), ('video', 'volumetric', 'images'), ('volumetric', 'images', '.')]

>> POS Tags are: 
 [('Many', 'JJ'), ('data', 'NNS'), ('modalities', 'NNS'), ('form', 'VBP'), ('multiple', 'JJ'), ('arrays', 'NNS'), (':', ':'), ('1D', 'CD'), ('signals', 'NNS'), ('sequences', 'NNS'), (',', ','), ('including', 'VBG'), ('language', 'NN'), (';', ':'), ('2D', 'CD'), ('images', 'NNS'), ('audio', 'JJ'), ('spectrograms', 'NNS'), (';', ':'), ('3D', 'CD'), ('video', 'NN'), ('volumetric', 'JJ'), ('images', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['Many data modalities', 'multiple arrays', 'signals sequences', 'language', 'images', 'audio spectrograms', 'video', 'volumetric images']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Many', 'mani'), ('data', 'data'), ('modalities', 'modal'), ('form', 'form'), ('multiple', 'multipl'), ('arrays', 'array'), (':', ':'), ('1D', '1d'), ('signals', 'signal'), ('sequences', 'sequenc'), (',', ','), ('including', 'includ'), ('language', 'languag'), (';', ';'), ('2D', '2d'), ('images', 'imag'), ('audio', 'audio'), ('spectrograms', 'spectrogram'), (';', ';'), ('3D', '3d'), ('video', 'video'), ('volumetric', 'volumetr'), ('images', 'imag'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Many', 'mani'), ('data', 'data'), ('modalities', 'modal'), ('form', 'form'), ('multiple', 'multipl'), ('arrays', 'array'), (':', ':'), ('1D', '1d'), ('signals', 'signal'), ('sequences', 'sequenc'), (',', ','), ('including', 'includ'), ('language', 'languag'), (';', ';'), ('2D', '2d'), ('images', 'imag'), ('audio', 'audio'), ('spectrograms', 'spectrogram'), (';', ';'), ('3D', '3d'), ('video', 'video'), ('volumetric', 'volumetr'), ('images', 'imag'), ('.', '.')]

>> Lemmatization: 
 [('Many', 'Many'), ('data', 'data'), ('modalities', 'modality'), ('form', 'form'), ('multiple', 'multiple'), ('arrays', 'array'), (':', ':'), ('1D', '1D'), ('signals', 'signal'), ('sequences', 'sequence'), (',', ','), ('including', 'including'), ('language', 'language'), (';', ';'), ('2D', '2D'), ('images', 'image'), ('audio', 'audio'), ('spectrograms', 'spectrogram'), (';', ';'), ('3D', '3D'), ('video', 'video'), ('volumetric', 'volumetric'), ('images', 'image'), ('.', '.')]


------------------- Sentence 3 -------------------

There are four key ideas  behind ConvNets that take advantage of the properties of natural  signals: local connections, shared weights, pooling and the use of  many layers.

>> Tokens are: 
 ['There', 'four', 'key', 'ideas', 'behind', 'ConvNets', 'take', 'advantage', 'properties', 'natural', 'signals', ':', 'local', 'connections', ',', 'shared', 'weights', ',', 'pooling', 'use', 'many', 'layers', '.']

>> Bigrams are: 
 [('There', 'four'), ('four', 'key'), ('key', 'ideas'), ('ideas', 'behind'), ('behind', 'ConvNets'), ('ConvNets', 'take'), ('take', 'advantage'), ('advantage', 'properties'), ('properties', 'natural'), ('natural', 'signals'), ('signals', ':'), (':', 'local'), ('local', 'connections'), ('connections', ','), (',', 'shared'), ('shared', 'weights'), ('weights', ','), (',', 'pooling'), ('pooling', 'use'), ('use', 'many'), ('many', 'layers'), ('layers', '.')]

>> Trigrams are: 
 [('There', 'four', 'key'), ('four', 'key', 'ideas'), ('key', 'ideas', 'behind'), ('ideas', 'behind', 'ConvNets'), ('behind', 'ConvNets', 'take'), ('ConvNets', 'take', 'advantage'), ('take', 'advantage', 'properties'), ('advantage', 'properties', 'natural'), ('properties', 'natural', 'signals'), ('natural', 'signals', ':'), ('signals', ':', 'local'), (':', 'local', 'connections'), ('local', 'connections', ','), ('connections', ',', 'shared'), (',', 'shared', 'weights'), ('shared', 'weights', ','), ('weights', ',', 'pooling'), (',', 'pooling', 'use'), ('pooling', 'use', 'many'), ('use', 'many', 'layers'), ('many', 'layers', '.')]

>> POS Tags are: 
 [('There', 'EX'), ('four', 'CD'), ('key', 'NN'), ('ideas', 'NNS'), ('behind', 'IN'), ('ConvNets', 'NNS'), ('take', 'VBP'), ('advantage', 'NN'), ('properties', 'NNS'), ('natural', 'JJ'), ('signals', 'NNS'), (':', ':'), ('local', 'JJ'), ('connections', 'NNS'), (',', ','), ('shared', 'VBN'), ('weights', 'NNS'), (',', ','), ('pooling', 'VBG'), ('use', 'RB'), ('many', 'JJ'), ('layers', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['key ideas', 'ConvNets', 'advantage properties', 'natural signals', 'local connections', 'weights', 'many layers']

>> Named Entities are: 
 [('ORGANIZATION', 'ConvNets')] 

>> Stemming using Porter Stemmer: 
 [('There', 'there'), ('four', 'four'), ('key', 'key'), ('ideas', 'idea'), ('behind', 'behind'), ('ConvNets', 'convnet'), ('take', 'take'), ('advantage', 'advantag'), ('properties', 'properti'), ('natural', 'natur'), ('signals', 'signal'), (':', ':'), ('local', 'local'), ('connections', 'connect'), (',', ','), ('shared', 'share'), ('weights', 'weight'), (',', ','), ('pooling', 'pool'), ('use', 'use'), ('many', 'mani'), ('layers', 'layer'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('There', 'there'), ('four', 'four'), ('key', 'key'), ('ideas', 'idea'), ('behind', 'behind'), ('ConvNets', 'convnet'), ('take', 'take'), ('advantage', 'advantag'), ('properties', 'properti'), ('natural', 'natur'), ('signals', 'signal'), (':', ':'), ('local', 'local'), ('connections', 'connect'), (',', ','), ('shared', 'share'), ('weights', 'weight'), (',', ','), ('pooling', 'pool'), ('use', 'use'), ('many', 'mani'), ('layers', 'layer'), ('.', '.')]

>> Lemmatization: 
 [('There', 'There'), ('four', 'four'), ('key', 'key'), ('ideas', 'idea'), ('behind', 'behind'), ('ConvNets', 'ConvNets'), ('take', 'take'), ('advantage', 'advantage'), ('properties', 'property'), ('natural', 'natural'), ('signals', 'signal'), (':', ':'), ('local', 'local'), ('connections', 'connection'), (',', ','), ('shared', 'shared'), ('weights', 'weight'), (',', ','), ('pooling', 'pooling'), ('use', 'use'), ('many', 'many'), ('layers', 'layer'), ('.', '.')]



========================================== PARAGRAPH 118 ===========================================

The architecture of a typical ConvNet (Fig. 2) is structured as a  series of stages. The first few stages are composed of two types of  layers: convolutional layers and pooling layers. Units in a convolu- tional layer are organized in feature maps, within which each unit  is connected to local patches in the feature maps of the previous  layer through a set of weights called a filter bank. The result of this  local weighted sum is then passed through a non-linearity such as a  ReLU. All units in a feature map share the same filter bank. Differ- ent feature maps in a layer use different filter banks. The reason for  

------------------- Sentence 1 -------------------

The architecture of a typical ConvNet (Fig.

>> Tokens are: 
 ['The', 'architecture', 'typical', 'ConvNet', '(', 'Fig', '.']

>> Bigrams are: 
 [('The', 'architecture'), ('architecture', 'typical'), ('typical', 'ConvNet'), ('ConvNet', '('), ('(', 'Fig'), ('Fig', '.')]

>> Trigrams are: 
 [('The', 'architecture', 'typical'), ('architecture', 'typical', 'ConvNet'), ('typical', 'ConvNet', '('), ('ConvNet', '(', 'Fig'), ('(', 'Fig', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('architecture', 'NN'), ('typical', 'JJ'), ('ConvNet', 'NNP'), ('(', '('), ('Fig', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['The architecture', 'typical ConvNet', 'Fig']

>> Named Entities are: 
 [('ORGANIZATION', 'ConvNet'), ('ORGANIZATION', 'Fig')] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('architecture', 'architectur'), ('typical', 'typic'), ('ConvNet', 'convnet'), ('(', '('), ('Fig', 'fig'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('architecture', 'architectur'), ('typical', 'typic'), ('ConvNet', 'convnet'), ('(', '('), ('Fig', 'fig'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('architecture', 'architecture'), ('typical', 'typical'), ('ConvNet', 'ConvNet'), ('(', '('), ('Fig', 'Fig'), ('.', '.')]


------------------- Sentence 2 -------------------

2) is structured as a  series of stages.

>> Tokens are: 
 ['2', ')', 'structured', 'series', 'stages', '.']

>> Bigrams are: 
 [('2', ')'), (')', 'structured'), ('structured', 'series'), ('series', 'stages'), ('stages', '.')]

>> Trigrams are: 
 [('2', ')', 'structured'), (')', 'structured', 'series'), ('structured', 'series', 'stages'), ('series', 'stages', '.')]

>> POS Tags are: 
 [('2', 'CD'), (')', ')'), ('structured', 'VBN'), ('series', 'NN'), ('stages', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['series stages']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('2', '2'), (')', ')'), ('structured', 'structur'), ('series', 'seri'), ('stages', 'stage'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('2', '2'), (')', ')'), ('structured', 'structur'), ('series', 'seri'), ('stages', 'stage'), ('.', '.')]

>> Lemmatization: 
 [('2', '2'), (')', ')'), ('structured', 'structured'), ('series', 'series'), ('stages', 'stage'), ('.', '.')]


------------------- Sentence 3 -------------------

The first few stages are composed of two types of  layers: convolutional layers and pooling layers.

>> Tokens are: 
 ['The', 'first', 'stages', 'composed', 'two', 'types', 'layers', ':', 'convolutional', 'layers', 'pooling', 'layers', '.']

>> Bigrams are: 
 [('The', 'first'), ('first', 'stages'), ('stages', 'composed'), ('composed', 'two'), ('two', 'types'), ('types', 'layers'), ('layers', ':'), (':', 'convolutional'), ('convolutional', 'layers'), ('layers', 'pooling'), ('pooling', 'layers'), ('layers', '.')]

>> Trigrams are: 
 [('The', 'first', 'stages'), ('first', 'stages', 'composed'), ('stages', 'composed', 'two'), ('composed', 'two', 'types'), ('two', 'types', 'layers'), ('types', 'layers', ':'), ('layers', ':', 'convolutional'), (':', 'convolutional', 'layers'), ('convolutional', 'layers', 'pooling'), ('layers', 'pooling', 'layers'), ('pooling', 'layers', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('first', 'JJ'), ('stages', 'NNS'), ('composed', 'VBN'), ('two', 'CD'), ('types', 'NNS'), ('layers', 'NNS'), (':', ':'), ('convolutional', 'JJ'), ('layers', 'NNS'), ('pooling', 'VBG'), ('layers', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['The first stages', 'types layers', 'convolutional layers', 'layers']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('first', 'first'), ('stages', 'stage'), ('composed', 'compos'), ('two', 'two'), ('types', 'type'), ('layers', 'layer'), (':', ':'), ('convolutional', 'convolut'), ('layers', 'layer'), ('pooling', 'pool'), ('layers', 'layer'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('first', 'first'), ('stages', 'stage'), ('composed', 'compos'), ('two', 'two'), ('types', 'type'), ('layers', 'layer'), (':', ':'), ('convolutional', 'convolut'), ('layers', 'layer'), ('pooling', 'pool'), ('layers', 'layer'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('first', 'first'), ('stages', 'stage'), ('composed', 'composed'), ('two', 'two'), ('types', 'type'), ('layers', 'layer'), (':', ':'), ('convolutional', 'convolutional'), ('layers', 'layer'), ('pooling', 'pooling'), ('layers', 'layer'), ('.', '.')]


------------------- Sentence 4 -------------------

Units in a convolu- tional layer are organized in feature maps, within which each unit  is connected to local patches in the feature maps of the previous  layer through a set of weights called a filter bank.

>> Tokens are: 
 ['Units', 'convolu-', 'tional', 'layer', 'organized', 'feature', 'maps', ',', 'within', 'unit', 'connected', 'local', 'patches', 'feature', 'maps', 'previous', 'layer', 'set', 'weights', 'called', 'filter', 'bank', '.']

>> Bigrams are: 
 [('Units', 'convolu-'), ('convolu-', 'tional'), ('tional', 'layer'), ('layer', 'organized'), ('organized', 'feature'), ('feature', 'maps'), ('maps', ','), (',', 'within'), ('within', 'unit'), ('unit', 'connected'), ('connected', 'local'), ('local', 'patches'), ('patches', 'feature'), ('feature', 'maps'), ('maps', 'previous'), ('previous', 'layer'), ('layer', 'set'), ('set', 'weights'), ('weights', 'called'), ('called', 'filter'), ('filter', 'bank'), ('bank', '.')]

>> Trigrams are: 
 [('Units', 'convolu-', 'tional'), ('convolu-', 'tional', 'layer'), ('tional', 'layer', 'organized'), ('layer', 'organized', 'feature'), ('organized', 'feature', 'maps'), ('feature', 'maps', ','), ('maps', ',', 'within'), (',', 'within', 'unit'), ('within', 'unit', 'connected'), ('unit', 'connected', 'local'), ('connected', 'local', 'patches'), ('local', 'patches', 'feature'), ('patches', 'feature', 'maps'), ('feature', 'maps', 'previous'), ('maps', 'previous', 'layer'), ('previous', 'layer', 'set'), ('layer', 'set', 'weights'), ('set', 'weights', 'called'), ('weights', 'called', 'filter'), ('called', 'filter', 'bank'), ('filter', 'bank', '.')]

>> POS Tags are: 
 [('Units', 'NNS'), ('convolu-', 'JJ'), ('tional', 'JJ'), ('layer', 'NN'), ('organized', 'VBN'), ('feature', 'NN'), ('maps', 'NNS'), (',', ','), ('within', 'IN'), ('unit', 'NN'), ('connected', 'VBD'), ('local', 'JJ'), ('patches', 'NNS'), ('feature', 'VBP'), ('maps', 'NNS'), ('previous', 'JJ'), ('layer', 'NN'), ('set', 'VBN'), ('weights', 'NNS'), ('called', 'VBD'), ('filter', 'RB'), ('bank', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Units', 'convolu- tional layer', 'feature maps', 'unit', 'local patches', 'maps', 'previous layer', 'weights', 'bank']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Units', 'unit'), ('convolu-', 'convolu-'), ('tional', 'tional'), ('layer', 'layer'), ('organized', 'organ'), ('feature', 'featur'), ('maps', 'map'), (',', ','), ('within', 'within'), ('unit', 'unit'), ('connected', 'connect'), ('local', 'local'), ('patches', 'patch'), ('feature', 'featur'), ('maps', 'map'), ('previous', 'previou'), ('layer', 'layer'), ('set', 'set'), ('weights', 'weight'), ('called', 'call'), ('filter', 'filter'), ('bank', 'bank'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Units', 'unit'), ('convolu-', 'convolu-'), ('tional', 'tional'), ('layer', 'layer'), ('organized', 'organ'), ('feature', 'featur'), ('maps', 'map'), (',', ','), ('within', 'within'), ('unit', 'unit'), ('connected', 'connect'), ('local', 'local'), ('patches', 'patch'), ('feature', 'featur'), ('maps', 'map'), ('previous', 'previous'), ('layer', 'layer'), ('set', 'set'), ('weights', 'weight'), ('called', 'call'), ('filter', 'filter'), ('bank', 'bank'), ('.', '.')]

>> Lemmatization: 
 [('Units', 'Units'), ('convolu-', 'convolu-'), ('tional', 'tional'), ('layer', 'layer'), ('organized', 'organized'), ('feature', 'feature'), ('maps', 'map'), (',', ','), ('within', 'within'), ('unit', 'unit'), ('connected', 'connected'), ('local', 'local'), ('patches', 'patch'), ('feature', 'feature'), ('maps', 'map'), ('previous', 'previous'), ('layer', 'layer'), ('set', 'set'), ('weights', 'weight'), ('called', 'called'), ('filter', 'filter'), ('bank', 'bank'), ('.', '.')]


------------------- Sentence 5 -------------------

The result of this  local weighted sum is then passed through a non-linearity such as a  ReLU.

>> Tokens are: 
 ['The', 'result', 'local', 'weighted', 'sum', 'passed', 'non-linearity', 'ReLU', '.']

>> Bigrams are: 
 [('The', 'result'), ('result', 'local'), ('local', 'weighted'), ('weighted', 'sum'), ('sum', 'passed'), ('passed', 'non-linearity'), ('non-linearity', 'ReLU'), ('ReLU', '.')]

>> Trigrams are: 
 [('The', 'result', 'local'), ('result', 'local', 'weighted'), ('local', 'weighted', 'sum'), ('weighted', 'sum', 'passed'), ('sum', 'passed', 'non-linearity'), ('passed', 'non-linearity', 'ReLU'), ('non-linearity', 'ReLU', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('result', 'NN'), ('local', 'JJ'), ('weighted', 'VBD'), ('sum', 'NN'), ('passed', 'VBD'), ('non-linearity', 'JJ'), ('ReLU', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['The result', 'sum', 'non-linearity ReLU']

>> Named Entities are: 
 [('ORGANIZATION', 'ReLU')] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('result', 'result'), ('local', 'local'), ('weighted', 'weight'), ('sum', 'sum'), ('passed', 'pass'), ('non-linearity', 'non-linear'), ('ReLU', 'relu'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('result', 'result'), ('local', 'local'), ('weighted', 'weight'), ('sum', 'sum'), ('passed', 'pass'), ('non-linearity', 'non-linear'), ('ReLU', 'relu'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('result', 'result'), ('local', 'local'), ('weighted', 'weighted'), ('sum', 'sum'), ('passed', 'passed'), ('non-linearity', 'non-linearity'), ('ReLU', 'ReLU'), ('.', '.')]


------------------- Sentence 6 -------------------

All units in a feature map share the same filter bank.

>> Tokens are: 
 ['All', 'units', 'feature', 'map', 'share', 'filter', 'bank', '.']

>> Bigrams are: 
 [('All', 'units'), ('units', 'feature'), ('feature', 'map'), ('map', 'share'), ('share', 'filter'), ('filter', 'bank'), ('bank', '.')]

>> Trigrams are: 
 [('All', 'units', 'feature'), ('units', 'feature', 'map'), ('feature', 'map', 'share'), ('map', 'share', 'filter'), ('share', 'filter', 'bank'), ('filter', 'bank', '.')]

>> POS Tags are: 
 [('All', 'DT'), ('units', 'NNS'), ('feature', 'VBP'), ('map', 'JJ'), ('share', 'NN'), ('filter', 'RBR'), ('bank', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['All units', 'map share', 'bank']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('All', 'all'), ('units', 'unit'), ('feature', 'featur'), ('map', 'map'), ('share', 'share'), ('filter', 'filter'), ('bank', 'bank'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('All', 'all'), ('units', 'unit'), ('feature', 'featur'), ('map', 'map'), ('share', 'share'), ('filter', 'filter'), ('bank', 'bank'), ('.', '.')]

>> Lemmatization: 
 [('All', 'All'), ('units', 'unit'), ('feature', 'feature'), ('map', 'map'), ('share', 'share'), ('filter', 'filter'), ('bank', 'bank'), ('.', '.')]


------------------- Sentence 7 -------------------

Differ- ent feature maps in a layer use different filter banks.

>> Tokens are: 
 ['Differ-', 'ent', 'feature', 'maps', 'layer', 'use', 'different', 'filter', 'banks', '.']

>> Bigrams are: 
 [('Differ-', 'ent'), ('ent', 'feature'), ('feature', 'maps'), ('maps', 'layer'), ('layer', 'use'), ('use', 'different'), ('different', 'filter'), ('filter', 'banks'), ('banks', '.')]

>> Trigrams are: 
 [('Differ-', 'ent', 'feature'), ('ent', 'feature', 'maps'), ('feature', 'maps', 'layer'), ('maps', 'layer', 'use'), ('layer', 'use', 'different'), ('use', 'different', 'filter'), ('different', 'filter', 'banks'), ('filter', 'banks', '.')]

>> POS Tags are: 
 [('Differ-', 'JJ'), ('ent', 'JJ'), ('feature', 'NN'), ('maps', 'NNS'), ('layer', 'VBP'), ('use', 'RB'), ('different', 'JJ'), ('filter', 'NN'), ('banks', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['Differ- ent feature maps', 'different filter banks']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Differ-', 'differ-'), ('ent', 'ent'), ('feature', 'featur'), ('maps', 'map'), ('layer', 'layer'), ('use', 'use'), ('different', 'differ'), ('filter', 'filter'), ('banks', 'bank'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Differ-', 'differ-'), ('ent', 'ent'), ('feature', 'featur'), ('maps', 'map'), ('layer', 'layer'), ('use', 'use'), ('different', 'differ'), ('filter', 'filter'), ('banks', 'bank'), ('.', '.')]

>> Lemmatization: 
 [('Differ-', 'Differ-'), ('ent', 'ent'), ('feature', 'feature'), ('maps', 'map'), ('layer', 'layer'), ('use', 'use'), ('different', 'different'), ('filter', 'filter'), ('banks', 'bank'), ('.', '.')]


------------------- Sentence 8 -------------------

The reason for

>> Tokens are: 
 ['The', 'reason']

>> Bigrams are: 
 [('The', 'reason')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('The', 'DT'), ('reason', 'NN')]

>> Noun Phrases are: 
 ['The reason']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('reason', 'reason')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('reason', 'reason')]

>> Lemmatization: 
 [('The', 'The'), ('reason', 'reason')]



========================================== PARAGRAPH 119 ===========================================

this architecture is twofold. First, in array data such as images, local  groups of values are often highly correlated, forming distinctive local  motifs that are easily detected. Second, the local statistics of images  and other signals are invariant to location. In other words, if a motif  can appear in one part of the image, it could appear anywhere, hence  the idea of units at different locations sharing the same weights and  detecting the same pattern in different parts of the array. Mathemati- cally, the filtering operation performed by a feature map is a discrete  convolution, hence the name.  

------------------- Sentence 1 -------------------

this architecture is twofold.

>> Tokens are: 
 ['architecture', 'twofold', '.']

>> Bigrams are: 
 [('architecture', 'twofold'), ('twofold', '.')]

>> Trigrams are: 
 [('architecture', 'twofold', '.')]

>> POS Tags are: 
 [('architecture', 'NN'), ('twofold', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['architecture twofold']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('architecture', 'architectur'), ('twofold', 'twofold'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('architecture', 'architectur'), ('twofold', 'twofold'), ('.', '.')]

>> Lemmatization: 
 [('architecture', 'architecture'), ('twofold', 'twofold'), ('.', '.')]


------------------- Sentence 2 -------------------

First, in array data such as images, local  groups of values are often highly correlated, forming distinctive local  motifs that are easily detected.

>> Tokens are: 
 ['First', ',', 'array', 'data', 'images', ',', 'local', 'groups', 'values', 'often', 'highly', 'correlated', ',', 'forming', 'distinctive', 'local', 'motifs', 'easily', 'detected', '.']

>> Bigrams are: 
 [('First', ','), (',', 'array'), ('array', 'data'), ('data', 'images'), ('images', ','), (',', 'local'), ('local', 'groups'), ('groups', 'values'), ('values', 'often'), ('often', 'highly'), ('highly', 'correlated'), ('correlated', ','), (',', 'forming'), ('forming', 'distinctive'), ('distinctive', 'local'), ('local', 'motifs'), ('motifs', 'easily'), ('easily', 'detected'), ('detected', '.')]

>> Trigrams are: 
 [('First', ',', 'array'), (',', 'array', 'data'), ('array', 'data', 'images'), ('data', 'images', ','), ('images', ',', 'local'), (',', 'local', 'groups'), ('local', 'groups', 'values'), ('groups', 'values', 'often'), ('values', 'often', 'highly'), ('often', 'highly', 'correlated'), ('highly', 'correlated', ','), ('correlated', ',', 'forming'), (',', 'forming', 'distinctive'), ('forming', 'distinctive', 'local'), ('distinctive', 'local', 'motifs'), ('local', 'motifs', 'easily'), ('motifs', 'easily', 'detected'), ('easily', 'detected', '.')]

>> POS Tags are: 
 [('First', 'RB'), (',', ','), ('array', 'NN'), ('data', 'NNS'), ('images', 'NNS'), (',', ','), ('local', 'JJ'), ('groups', 'NNS'), ('values', 'NNS'), ('often', 'RB'), ('highly', 'RB'), ('correlated', 'VBN'), (',', ','), ('forming', 'VBG'), ('distinctive', 'JJ'), ('local', 'JJ'), ('motifs', 'NNS'), ('easily', 'RB'), ('detected', 'VBN'), ('.', '.')]

>> Noun Phrases are: 
 ['array data images', 'local groups values', 'distinctive local motifs']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('First', 'first'), (',', ','), ('array', 'array'), ('data', 'data'), ('images', 'imag'), (',', ','), ('local', 'local'), ('groups', 'group'), ('values', 'valu'), ('often', 'often'), ('highly', 'highli'), ('correlated', 'correl'), (',', ','), ('forming', 'form'), ('distinctive', 'distinct'), ('local', 'local'), ('motifs', 'motif'), ('easily', 'easili'), ('detected', 'detect'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('First', 'first'), (',', ','), ('array', 'array'), ('data', 'data'), ('images', 'imag'), (',', ','), ('local', 'local'), ('groups', 'group'), ('values', 'valu'), ('often', 'often'), ('highly', 'high'), ('correlated', 'correl'), (',', ','), ('forming', 'form'), ('distinctive', 'distinct'), ('local', 'local'), ('motifs', 'motif'), ('easily', 'easili'), ('detected', 'detect'), ('.', '.')]

>> Lemmatization: 
 [('First', 'First'), (',', ','), ('array', 'array'), ('data', 'data'), ('images', 'image'), (',', ','), ('local', 'local'), ('groups', 'group'), ('values', 'value'), ('often', 'often'), ('highly', 'highly'), ('correlated', 'correlated'), (',', ','), ('forming', 'forming'), ('distinctive', 'distinctive'), ('local', 'local'), ('motifs', 'motif'), ('easily', 'easily'), ('detected', 'detected'), ('.', '.')]


------------------- Sentence 3 -------------------

Second, the local statistics of images  and other signals are invariant to location.

>> Tokens are: 
 ['Second', ',', 'local', 'statistics', 'images', 'signals', 'invariant', 'location', '.']

>> Bigrams are: 
 [('Second', ','), (',', 'local'), ('local', 'statistics'), ('statistics', 'images'), ('images', 'signals'), ('signals', 'invariant'), ('invariant', 'location'), ('location', '.')]

>> Trigrams are: 
 [('Second', ',', 'local'), (',', 'local', 'statistics'), ('local', 'statistics', 'images'), ('statistics', 'images', 'signals'), ('images', 'signals', 'invariant'), ('signals', 'invariant', 'location'), ('invariant', 'location', '.')]

>> POS Tags are: 
 [('Second', 'NNP'), (',', ','), ('local', 'JJ'), ('statistics', 'NNS'), ('images', 'NNS'), ('signals', 'NNS'), ('invariant', 'JJ'), ('location', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Second', 'local statistics images signals', 'invariant location']

>> Named Entities are: 
 [('GPE', 'Second')] 

>> Stemming using Porter Stemmer: 
 [('Second', 'second'), (',', ','), ('local', 'local'), ('statistics', 'statist'), ('images', 'imag'), ('signals', 'signal'), ('invariant', 'invari'), ('location', 'locat'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Second', 'second'), (',', ','), ('local', 'local'), ('statistics', 'statist'), ('images', 'imag'), ('signals', 'signal'), ('invariant', 'invari'), ('location', 'locat'), ('.', '.')]

>> Lemmatization: 
 [('Second', 'Second'), (',', ','), ('local', 'local'), ('statistics', 'statistic'), ('images', 'image'), ('signals', 'signal'), ('invariant', 'invariant'), ('location', 'location'), ('.', '.')]


------------------- Sentence 4 -------------------

In other words, if a motif  can appear in one part of the image, it could appear anywhere, hence  the idea of units at different locations sharing the same weights and  detecting the same pattern in different parts of the array.

>> Tokens are: 
 ['In', 'words', ',', 'motif', 'appear', 'one', 'part', 'image', ',', 'could', 'appear', 'anywhere', ',', 'hence', 'idea', 'units', 'different', 'locations', 'sharing', 'weights', 'detecting', 'pattern', 'different', 'parts', 'array', '.']

>> Bigrams are: 
 [('In', 'words'), ('words', ','), (',', 'motif'), ('motif', 'appear'), ('appear', 'one'), ('one', 'part'), ('part', 'image'), ('image', ','), (',', 'could'), ('could', 'appear'), ('appear', 'anywhere'), ('anywhere', ','), (',', 'hence'), ('hence', 'idea'), ('idea', 'units'), ('units', 'different'), ('different', 'locations'), ('locations', 'sharing'), ('sharing', 'weights'), ('weights', 'detecting'), ('detecting', 'pattern'), ('pattern', 'different'), ('different', 'parts'), ('parts', 'array'), ('array', '.')]

>> Trigrams are: 
 [('In', 'words', ','), ('words', ',', 'motif'), (',', 'motif', 'appear'), ('motif', 'appear', 'one'), ('appear', 'one', 'part'), ('one', 'part', 'image'), ('part', 'image', ','), ('image', ',', 'could'), (',', 'could', 'appear'), ('could', 'appear', 'anywhere'), ('appear', 'anywhere', ','), ('anywhere', ',', 'hence'), (',', 'hence', 'idea'), ('hence', 'idea', 'units'), ('idea', 'units', 'different'), ('units', 'different', 'locations'), ('different', 'locations', 'sharing'), ('locations', 'sharing', 'weights'), ('sharing', 'weights', 'detecting'), ('weights', 'detecting', 'pattern'), ('detecting', 'pattern', 'different'), ('pattern', 'different', 'parts'), ('different', 'parts', 'array'), ('parts', 'array', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('words', 'NNS'), (',', ','), ('motif', 'FW'), ('appear', 'VBP'), ('one', 'CD'), ('part', 'NN'), ('image', 'NN'), (',', ','), ('could', 'MD'), ('appear', 'VB'), ('anywhere', 'RB'), (',', ','), ('hence', 'RB'), ('idea', 'NN'), ('units', 'NNS'), ('different', 'JJ'), ('locations', 'NNS'), ('sharing', 'VBG'), ('weights', 'NNS'), ('detecting', 'VBG'), ('pattern', 'JJ'), ('different', 'JJ'), ('parts', 'NNS'), ('array', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['words', 'part image', 'idea units', 'different locations', 'weights', 'pattern different parts array']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('words', 'word'), (',', ','), ('motif', 'motif'), ('appear', 'appear'), ('one', 'one'), ('part', 'part'), ('image', 'imag'), (',', ','), ('could', 'could'), ('appear', 'appear'), ('anywhere', 'anywher'), (',', ','), ('hence', 'henc'), ('idea', 'idea'), ('units', 'unit'), ('different', 'differ'), ('locations', 'locat'), ('sharing', 'share'), ('weights', 'weight'), ('detecting', 'detect'), ('pattern', 'pattern'), ('different', 'differ'), ('parts', 'part'), ('array', 'array'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('words', 'word'), (',', ','), ('motif', 'motif'), ('appear', 'appear'), ('one', 'one'), ('part', 'part'), ('image', 'imag'), (',', ','), ('could', 'could'), ('appear', 'appear'), ('anywhere', 'anywher'), (',', ','), ('hence', 'henc'), ('idea', 'idea'), ('units', 'unit'), ('different', 'differ'), ('locations', 'locat'), ('sharing', 'share'), ('weights', 'weight'), ('detecting', 'detect'), ('pattern', 'pattern'), ('different', 'differ'), ('parts', 'part'), ('array', 'array'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('words', 'word'), (',', ','), ('motif', 'motif'), ('appear', 'appear'), ('one', 'one'), ('part', 'part'), ('image', 'image'), (',', ','), ('could', 'could'), ('appear', 'appear'), ('anywhere', 'anywhere'), (',', ','), ('hence', 'hence'), ('idea', 'idea'), ('units', 'unit'), ('different', 'different'), ('locations', 'location'), ('sharing', 'sharing'), ('weights', 'weight'), ('detecting', 'detecting'), ('pattern', 'pattern'), ('different', 'different'), ('parts', 'part'), ('array', 'array'), ('.', '.')]


------------------- Sentence 5 -------------------

Mathemati- cally, the filtering operation performed by a feature map is a discrete  convolution, hence the name.

>> Tokens are: 
 ['Mathemati-', 'cally', ',', 'filtering', 'operation', 'performed', 'feature', 'map', 'discrete', 'convolution', ',', 'hence', 'name', '.']

>> Bigrams are: 
 [('Mathemati-', 'cally'), ('cally', ','), (',', 'filtering'), ('filtering', 'operation'), ('operation', 'performed'), ('performed', 'feature'), ('feature', 'map'), ('map', 'discrete'), ('discrete', 'convolution'), ('convolution', ','), (',', 'hence'), ('hence', 'name'), ('name', '.')]

>> Trigrams are: 
 [('Mathemati-', 'cally', ','), ('cally', ',', 'filtering'), (',', 'filtering', 'operation'), ('filtering', 'operation', 'performed'), ('operation', 'performed', 'feature'), ('performed', 'feature', 'map'), ('feature', 'map', 'discrete'), ('map', 'discrete', 'convolution'), ('discrete', 'convolution', ','), ('convolution', ',', 'hence'), (',', 'hence', 'name'), ('hence', 'name', '.')]

>> POS Tags are: 
 [('Mathemati-', 'NNP'), ('cally', 'RB'), (',', ','), ('filtering', 'VBG'), ('operation', 'NN'), ('performed', 'VBD'), ('feature', 'JJ'), ('map', 'NN'), ('discrete', 'JJ'), ('convolution', 'NN'), (',', ','), ('hence', 'NN'), ('name', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Mathemati-', 'operation', 'feature map', 'discrete convolution', 'hence name']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Mathemati-', 'mathemati-'), ('cally', 'calli'), (',', ','), ('filtering', 'filter'), ('operation', 'oper'), ('performed', 'perform'), ('feature', 'featur'), ('map', 'map'), ('discrete', 'discret'), ('convolution', 'convolut'), (',', ','), ('hence', 'henc'), ('name', 'name'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Mathemati-', 'mathemati-'), ('cally', 'calli'), (',', ','), ('filtering', 'filter'), ('operation', 'oper'), ('performed', 'perform'), ('feature', 'featur'), ('map', 'map'), ('discrete', 'discret'), ('convolution', 'convolut'), (',', ','), ('hence', 'henc'), ('name', 'name'), ('.', '.')]

>> Lemmatization: 
 [('Mathemati-', 'Mathemati-'), ('cally', 'cally'), (',', ','), ('filtering', 'filtering'), ('operation', 'operation'), ('performed', 'performed'), ('feature', 'feature'), ('map', 'map'), ('discrete', 'discrete'), ('convolution', 'convolution'), (',', ','), ('hence', 'hence'), ('name', 'name'), ('.', '.')]



========================================== PARAGRAPH 120 ===========================================

Although the role of the convolutional layer is to detect local con- junctions of features from the previous layer, the role of the pooling  layer is to merge semantically similar features into one. Because the  relative positions of the features forming a motif can vary somewhat,  reliably detecting the motif can be done by coarse-graining the posi- tion of each feature. A typical pooling unit computes the maximum  of a local patch of units in one feature map (or in a few feature maps).  Neighbouring pooling units take input from patches that are shifted  by more than one row or column, thereby reducing the dimension of  the representation and creating an invariance to small shifts and dis- tortions. Two or three stages of convolution, non-linearity and pool- ing are stacked, followed by more convolutional and fully-connected  layers. Backpropagating gradients through a ConvNet is as simple as  through a regular deep network, allowing all the weights in all the  filter banks to be trained.  

------------------- Sentence 1 -------------------

Although the role of the convolutional layer is to detect local con- junctions of features from the previous layer, the role of the pooling  layer is to merge semantically similar features into one.

>> Tokens are: 
 ['Although', 'role', 'convolutional', 'layer', 'detect', 'local', 'con-', 'junctions', 'features', 'previous', 'layer', ',', 'role', 'pooling', 'layer', 'merge', 'semantically', 'similar', 'features', 'one', '.']

>> Bigrams are: 
 [('Although', 'role'), ('role', 'convolutional'), ('convolutional', 'layer'), ('layer', 'detect'), ('detect', 'local'), ('local', 'con-'), ('con-', 'junctions'), ('junctions', 'features'), ('features', 'previous'), ('previous', 'layer'), ('layer', ','), (',', 'role'), ('role', 'pooling'), ('pooling', 'layer'), ('layer', 'merge'), ('merge', 'semantically'), ('semantically', 'similar'), ('similar', 'features'), ('features', 'one'), ('one', '.')]

>> Trigrams are: 
 [('Although', 'role', 'convolutional'), ('role', 'convolutional', 'layer'), ('convolutional', 'layer', 'detect'), ('layer', 'detect', 'local'), ('detect', 'local', 'con-'), ('local', 'con-', 'junctions'), ('con-', 'junctions', 'features'), ('junctions', 'features', 'previous'), ('features', 'previous', 'layer'), ('previous', 'layer', ','), ('layer', ',', 'role'), (',', 'role', 'pooling'), ('role', 'pooling', 'layer'), ('pooling', 'layer', 'merge'), ('layer', 'merge', 'semantically'), ('merge', 'semantically', 'similar'), ('semantically', 'similar', 'features'), ('similar', 'features', 'one'), ('features', 'one', '.')]

>> POS Tags are: 
 [('Although', 'IN'), ('role', 'NN'), ('convolutional', 'JJ'), ('layer', 'NN'), ('detect', 'JJ'), ('local', 'JJ'), ('con-', 'NN'), ('junctions', 'NNS'), ('features', 'VBZ'), ('previous', 'JJ'), ('layer', 'NN'), (',', ','), ('role', 'NN'), ('pooling', 'VBG'), ('layer', 'JJ'), ('merge', 'NN'), ('semantically', 'RB'), ('similar', 'JJ'), ('features', 'NNS'), ('one', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['role', 'convolutional layer', 'detect local con- junctions', 'previous layer', 'role', 'layer merge', 'similar features']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Although', 'although'), ('role', 'role'), ('convolutional', 'convolut'), ('layer', 'layer'), ('detect', 'detect'), ('local', 'local'), ('con-', 'con-'), ('junctions', 'junction'), ('features', 'featur'), ('previous', 'previou'), ('layer', 'layer'), (',', ','), ('role', 'role'), ('pooling', 'pool'), ('layer', 'layer'), ('merge', 'merg'), ('semantically', 'semant'), ('similar', 'similar'), ('features', 'featur'), ('one', 'one'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Although', 'although'), ('role', 'role'), ('convolutional', 'convolut'), ('layer', 'layer'), ('detect', 'detect'), ('local', 'local'), ('con-', 'con-'), ('junctions', 'junction'), ('features', 'featur'), ('previous', 'previous'), ('layer', 'layer'), (',', ','), ('role', 'role'), ('pooling', 'pool'), ('layer', 'layer'), ('merge', 'merg'), ('semantically', 'semant'), ('similar', 'similar'), ('features', 'featur'), ('one', 'one'), ('.', '.')]

>> Lemmatization: 
 [('Although', 'Although'), ('role', 'role'), ('convolutional', 'convolutional'), ('layer', 'layer'), ('detect', 'detect'), ('local', 'local'), ('con-', 'con-'), ('junctions', 'junction'), ('features', 'feature'), ('previous', 'previous'), ('layer', 'layer'), (',', ','), ('role', 'role'), ('pooling', 'pooling'), ('layer', 'layer'), ('merge', 'merge'), ('semantically', 'semantically'), ('similar', 'similar'), ('features', 'feature'), ('one', 'one'), ('.', '.')]


------------------- Sentence 2 -------------------

Because the  relative positions of the features forming a motif can vary somewhat,  reliably detecting the motif can be done by coarse-graining the posi- tion of each feature.

>> Tokens are: 
 ['Because', 'relative', 'positions', 'features', 'forming', 'motif', 'vary', 'somewhat', ',', 'reliably', 'detecting', 'motif', 'done', 'coarse-graining', 'posi-', 'tion', 'feature', '.']

>> Bigrams are: 
 [('Because', 'relative'), ('relative', 'positions'), ('positions', 'features'), ('features', 'forming'), ('forming', 'motif'), ('motif', 'vary'), ('vary', 'somewhat'), ('somewhat', ','), (',', 'reliably'), ('reliably', 'detecting'), ('detecting', 'motif'), ('motif', 'done'), ('done', 'coarse-graining'), ('coarse-graining', 'posi-'), ('posi-', 'tion'), ('tion', 'feature'), ('feature', '.')]

>> Trigrams are: 
 [('Because', 'relative', 'positions'), ('relative', 'positions', 'features'), ('positions', 'features', 'forming'), ('features', 'forming', 'motif'), ('forming', 'motif', 'vary'), ('motif', 'vary', 'somewhat'), ('vary', 'somewhat', ','), ('somewhat', ',', 'reliably'), (',', 'reliably', 'detecting'), ('reliably', 'detecting', 'motif'), ('detecting', 'motif', 'done'), ('motif', 'done', 'coarse-graining'), ('done', 'coarse-graining', 'posi-'), ('coarse-graining', 'posi-', 'tion'), ('posi-', 'tion', 'feature'), ('tion', 'feature', '.')]

>> POS Tags are: 
 [('Because', 'IN'), ('relative', 'JJ'), ('positions', 'NNS'), ('features', 'NNS'), ('forming', 'VBG'), ('motif', 'JJ'), ('vary', 'JJ'), ('somewhat', 'RB'), (',', ','), ('reliably', 'RB'), ('detecting', 'VBG'), ('motif', 'PRP'), ('done', 'VBN'), ('coarse-graining', 'JJ'), ('posi-', 'JJ'), ('tion', 'NN'), ('feature', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['relative positions features', 'coarse-graining posi- tion feature']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Because', 'becaus'), ('relative', 'rel'), ('positions', 'posit'), ('features', 'featur'), ('forming', 'form'), ('motif', 'motif'), ('vary', 'vari'), ('somewhat', 'somewhat'), (',', ','), ('reliably', 'reliabl'), ('detecting', 'detect'), ('motif', 'motif'), ('done', 'done'), ('coarse-graining', 'coarse-grain'), ('posi-', 'posi-'), ('tion', 'tion'), ('feature', 'featur'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Because', 'becaus'), ('relative', 'relat'), ('positions', 'posit'), ('features', 'featur'), ('forming', 'form'), ('motif', 'motif'), ('vary', 'vari'), ('somewhat', 'somewhat'), (',', ','), ('reliably', 'reliabl'), ('detecting', 'detect'), ('motif', 'motif'), ('done', 'done'), ('coarse-graining', 'coarse-grain'), ('posi-', 'posi-'), ('tion', 'tion'), ('feature', 'featur'), ('.', '.')]

>> Lemmatization: 
 [('Because', 'Because'), ('relative', 'relative'), ('positions', 'position'), ('features', 'feature'), ('forming', 'forming'), ('motif', 'motif'), ('vary', 'vary'), ('somewhat', 'somewhat'), (',', ','), ('reliably', 'reliably'), ('detecting', 'detecting'), ('motif', 'motif'), ('done', 'done'), ('coarse-graining', 'coarse-graining'), ('posi-', 'posi-'), ('tion', 'tion'), ('feature', 'feature'), ('.', '.')]


------------------- Sentence 3 -------------------

A typical pooling unit computes the maximum  of a local patch of units in one feature map (or in a few feature maps).

>> Tokens are: 
 ['A', 'typical', 'pooling', 'unit', 'computes', 'maximum', 'local', 'patch', 'units', 'one', 'feature', 'map', '(', 'feature', 'maps', ')', '.']

>> Bigrams are: 
 [('A', 'typical'), ('typical', 'pooling'), ('pooling', 'unit'), ('unit', 'computes'), ('computes', 'maximum'), ('maximum', 'local'), ('local', 'patch'), ('patch', 'units'), ('units', 'one'), ('one', 'feature'), ('feature', 'map'), ('map', '('), ('(', 'feature'), ('feature', 'maps'), ('maps', ')'), (')', '.')]

>> Trigrams are: 
 [('A', 'typical', 'pooling'), ('typical', 'pooling', 'unit'), ('pooling', 'unit', 'computes'), ('unit', 'computes', 'maximum'), ('computes', 'maximum', 'local'), ('maximum', 'local', 'patch'), ('local', 'patch', 'units'), ('patch', 'units', 'one'), ('units', 'one', 'feature'), ('one', 'feature', 'map'), ('feature', 'map', '('), ('map', '(', 'feature'), ('(', 'feature', 'maps'), ('feature', 'maps', ')'), ('maps', ')', '.')]

>> POS Tags are: 
 [('A', 'DT'), ('typical', 'JJ'), ('pooling', 'NN'), ('unit', 'NN'), ('computes', 'VBZ'), ('maximum', 'JJ'), ('local', 'JJ'), ('patch', 'NN'), ('units', 'NNS'), ('one', 'CD'), ('feature', 'NN'), ('map', 'NN'), ('(', '('), ('feature', 'JJ'), ('maps', 'NNS'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['A typical pooling unit', 'maximum local patch units', 'feature map', 'feature maps']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('A', 'a'), ('typical', 'typic'), ('pooling', 'pool'), ('unit', 'unit'), ('computes', 'comput'), ('maximum', 'maximum'), ('local', 'local'), ('patch', 'patch'), ('units', 'unit'), ('one', 'one'), ('feature', 'featur'), ('map', 'map'), ('(', '('), ('feature', 'featur'), ('maps', 'map'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('A', 'a'), ('typical', 'typic'), ('pooling', 'pool'), ('unit', 'unit'), ('computes', 'comput'), ('maximum', 'maximum'), ('local', 'local'), ('patch', 'patch'), ('units', 'unit'), ('one', 'one'), ('feature', 'featur'), ('map', 'map'), ('(', '('), ('feature', 'featur'), ('maps', 'map'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('A', 'A'), ('typical', 'typical'), ('pooling', 'pooling'), ('unit', 'unit'), ('computes', 'computes'), ('maximum', 'maximum'), ('local', 'local'), ('patch', 'patch'), ('units', 'unit'), ('one', 'one'), ('feature', 'feature'), ('map', 'map'), ('(', '('), ('feature', 'feature'), ('maps', 'map'), (')', ')'), ('.', '.')]


------------------- Sentence 4 -------------------

Neighbouring pooling units take input from patches that are shifted  by more than one row or column, thereby reducing the dimension of  the representation and creating an invariance to small shifts and dis- tortions.

>> Tokens are: 
 ['Neighbouring', 'pooling', 'units', 'take', 'input', 'patches', 'shifted', 'one', 'row', 'column', ',', 'thereby', 'reducing', 'dimension', 'representation', 'creating', 'invariance', 'small', 'shifts', 'dis-', 'tortions', '.']

>> Bigrams are: 
 [('Neighbouring', 'pooling'), ('pooling', 'units'), ('units', 'take'), ('take', 'input'), ('input', 'patches'), ('patches', 'shifted'), ('shifted', 'one'), ('one', 'row'), ('row', 'column'), ('column', ','), (',', 'thereby'), ('thereby', 'reducing'), ('reducing', 'dimension'), ('dimension', 'representation'), ('representation', 'creating'), ('creating', 'invariance'), ('invariance', 'small'), ('small', 'shifts'), ('shifts', 'dis-'), ('dis-', 'tortions'), ('tortions', '.')]

>> Trigrams are: 
 [('Neighbouring', 'pooling', 'units'), ('pooling', 'units', 'take'), ('units', 'take', 'input'), ('take', 'input', 'patches'), ('input', 'patches', 'shifted'), ('patches', 'shifted', 'one'), ('shifted', 'one', 'row'), ('one', 'row', 'column'), ('row', 'column', ','), ('column', ',', 'thereby'), (',', 'thereby', 'reducing'), ('thereby', 'reducing', 'dimension'), ('reducing', 'dimension', 'representation'), ('dimension', 'representation', 'creating'), ('representation', 'creating', 'invariance'), ('creating', 'invariance', 'small'), ('invariance', 'small', 'shifts'), ('small', 'shifts', 'dis-'), ('shifts', 'dis-', 'tortions'), ('dis-', 'tortions', '.')]

>> POS Tags are: 
 [('Neighbouring', 'VBG'), ('pooling', 'VBG'), ('units', 'NNS'), ('take', 'VBP'), ('input', 'NN'), ('patches', 'NNS'), ('shifted', 'VBD'), ('one', 'CD'), ('row', 'NN'), ('column', 'NN'), (',', ','), ('thereby', 'RB'), ('reducing', 'VBG'), ('dimension', 'NN'), ('representation', 'NN'), ('creating', 'VBG'), ('invariance', 'NN'), ('small', 'JJ'), ('shifts', 'NNS'), ('dis-', 'JJ'), ('tortions', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['units', 'input patches', 'row column', 'dimension representation', 'invariance', 'small shifts', 'dis- tortions']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Neighbouring', 'neighbour'), ('pooling', 'pool'), ('units', 'unit'), ('take', 'take'), ('input', 'input'), ('patches', 'patch'), ('shifted', 'shift'), ('one', 'one'), ('row', 'row'), ('column', 'column'), (',', ','), ('thereby', 'therebi'), ('reducing', 'reduc'), ('dimension', 'dimens'), ('representation', 'represent'), ('creating', 'creat'), ('invariance', 'invari'), ('small', 'small'), ('shifts', 'shift'), ('dis-', 'dis-'), ('tortions', 'tortion'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Neighbouring', 'neighbour'), ('pooling', 'pool'), ('units', 'unit'), ('take', 'take'), ('input', 'input'), ('patches', 'patch'), ('shifted', 'shift'), ('one', 'one'), ('row', 'row'), ('column', 'column'), (',', ','), ('thereby', 'therebi'), ('reducing', 'reduc'), ('dimension', 'dimens'), ('representation', 'represent'), ('creating', 'creat'), ('invariance', 'invari'), ('small', 'small'), ('shifts', 'shift'), ('dis-', 'dis-'), ('tortions', 'tortion'), ('.', '.')]

>> Lemmatization: 
 [('Neighbouring', 'Neighbouring'), ('pooling', 'pooling'), ('units', 'unit'), ('take', 'take'), ('input', 'input'), ('patches', 'patch'), ('shifted', 'shifted'), ('one', 'one'), ('row', 'row'), ('column', 'column'), (',', ','), ('thereby', 'thereby'), ('reducing', 'reducing'), ('dimension', 'dimension'), ('representation', 'representation'), ('creating', 'creating'), ('invariance', 'invariance'), ('small', 'small'), ('shifts', 'shift'), ('dis-', 'dis-'), ('tortions', 'tortions'), ('.', '.')]


------------------- Sentence 5 -------------------

Two or three stages of convolution, non-linearity and pool- ing are stacked, followed by more convolutional and fully-connected  layers.

>> Tokens are: 
 ['Two', 'three', 'stages', 'convolution', ',', 'non-linearity', 'pool-', 'ing', 'stacked', ',', 'followed', 'convolutional', 'fully-connected', 'layers', '.']

>> Bigrams are: 
 [('Two', 'three'), ('three', 'stages'), ('stages', 'convolution'), ('convolution', ','), (',', 'non-linearity'), ('non-linearity', 'pool-'), ('pool-', 'ing'), ('ing', 'stacked'), ('stacked', ','), (',', 'followed'), ('followed', 'convolutional'), ('convolutional', 'fully-connected'), ('fully-connected', 'layers'), ('layers', '.')]

>> Trigrams are: 
 [('Two', 'three', 'stages'), ('three', 'stages', 'convolution'), ('stages', 'convolution', ','), ('convolution', ',', 'non-linearity'), (',', 'non-linearity', 'pool-'), ('non-linearity', 'pool-', 'ing'), ('pool-', 'ing', 'stacked'), ('ing', 'stacked', ','), ('stacked', ',', 'followed'), (',', 'followed', 'convolutional'), ('followed', 'convolutional', 'fully-connected'), ('convolutional', 'fully-connected', 'layers'), ('fully-connected', 'layers', '.')]

>> POS Tags are: 
 [('Two', 'CD'), ('three', 'CD'), ('stages', 'NNS'), ('convolution', 'NN'), (',', ','), ('non-linearity', 'JJ'), ('pool-', 'JJ'), ('ing', 'NN'), ('stacked', 'VBD'), (',', ','), ('followed', 'VBD'), ('convolutional', 'JJ'), ('fully-connected', 'JJ'), ('layers', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['stages convolution', 'non-linearity pool- ing', 'convolutional fully-connected layers']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Two', 'two'), ('three', 'three'), ('stages', 'stage'), ('convolution', 'convolut'), (',', ','), ('non-linearity', 'non-linear'), ('pool-', 'pool-'), ('ing', 'ing'), ('stacked', 'stack'), (',', ','), ('followed', 'follow'), ('convolutional', 'convolut'), ('fully-connected', 'fully-connect'), ('layers', 'layer'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Two', 'two'), ('three', 'three'), ('stages', 'stage'), ('convolution', 'convolut'), (',', ','), ('non-linearity', 'non-linear'), ('pool-', 'pool-'), ('ing', 'ing'), ('stacked', 'stack'), (',', ','), ('followed', 'follow'), ('convolutional', 'convolut'), ('fully-connected', 'fully-connect'), ('layers', 'layer'), ('.', '.')]

>> Lemmatization: 
 [('Two', 'Two'), ('three', 'three'), ('stages', 'stage'), ('convolution', 'convolution'), (',', ','), ('non-linearity', 'non-linearity'), ('pool-', 'pool-'), ('ing', 'ing'), ('stacked', 'stacked'), (',', ','), ('followed', 'followed'), ('convolutional', 'convolutional'), ('fully-connected', 'fully-connected'), ('layers', 'layer'), ('.', '.')]


------------------- Sentence 6 -------------------

Backpropagating gradients through a ConvNet is as simple as  through a regular deep network, allowing all the weights in all the  filter banks to be trained.

>> Tokens are: 
 ['Backpropagating', 'gradients', 'ConvNet', 'simple', 'regular', 'deep', 'network', ',', 'allowing', 'weights', 'filter', 'banks', 'trained', '.']

>> Bigrams are: 
 [('Backpropagating', 'gradients'), ('gradients', 'ConvNet'), ('ConvNet', 'simple'), ('simple', 'regular'), ('regular', 'deep'), ('deep', 'network'), ('network', ','), (',', 'allowing'), ('allowing', 'weights'), ('weights', 'filter'), ('filter', 'banks'), ('banks', 'trained'), ('trained', '.')]

>> Trigrams are: 
 [('Backpropagating', 'gradients', 'ConvNet'), ('gradients', 'ConvNet', 'simple'), ('ConvNet', 'simple', 'regular'), ('simple', 'regular', 'deep'), ('regular', 'deep', 'network'), ('deep', 'network', ','), ('network', ',', 'allowing'), (',', 'allowing', 'weights'), ('allowing', 'weights', 'filter'), ('weights', 'filter', 'banks'), ('filter', 'banks', 'trained'), ('banks', 'trained', '.')]

>> POS Tags are: 
 [('Backpropagating', 'VBG'), ('gradients', 'NNS'), ('ConvNet', 'NNP'), ('simple', 'NN'), ('regular', 'JJ'), ('deep', 'JJ'), ('network', 'NN'), (',', ','), ('allowing', 'VBG'), ('weights', 'NNS'), ('filter', 'JJ'), ('banks', 'NNS'), ('trained', 'VBD'), ('.', '.')]

>> Noun Phrases are: 
 ['gradients ConvNet simple', 'regular deep network', 'weights', 'filter banks']

>> Named Entities are: 
 [('ORGANIZATION', 'ConvNet')] 

>> Stemming using Porter Stemmer: 
 [('Backpropagating', 'backpropag'), ('gradients', 'gradient'), ('ConvNet', 'convnet'), ('simple', 'simpl'), ('regular', 'regular'), ('deep', 'deep'), ('network', 'network'), (',', ','), ('allowing', 'allow'), ('weights', 'weight'), ('filter', 'filter'), ('banks', 'bank'), ('trained', 'train'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Backpropagating', 'backpropag'), ('gradients', 'gradient'), ('ConvNet', 'convnet'), ('simple', 'simpl'), ('regular', 'regular'), ('deep', 'deep'), ('network', 'network'), (',', ','), ('allowing', 'allow'), ('weights', 'weight'), ('filter', 'filter'), ('banks', 'bank'), ('trained', 'train'), ('.', '.')]

>> Lemmatization: 
 [('Backpropagating', 'Backpropagating'), ('gradients', 'gradient'), ('ConvNet', 'ConvNet'), ('simple', 'simple'), ('regular', 'regular'), ('deep', 'deep'), ('network', 'network'), (',', ','), ('allowing', 'allowing'), ('weights', 'weight'), ('filter', 'filter'), ('banks', 'bank'), ('trained', 'trained'), ('.', '.')]



========================================== PARAGRAPH 121 ===========================================

Deep neural networks exploit the property that many natural sig- nals are compositional hierarchies, in which higher-level features  are obtained by composing lower-level ones. In images, local combi- nations of edges form motifs, motifs assemble into parts, and parts  form objects. Similar hierarchies exist in speech and text from sounds  to phones, phonemes, syllables, words and sentences. The pooling  allows representations to vary very little when elements in the previ- ous layer vary in position and appearance.  

------------------- Sentence 1 -------------------

Deep neural networks exploit the property that many natural sig- nals are compositional hierarchies, in which higher-level features  are obtained by composing lower-level ones.

>> Tokens are: 
 ['Deep', 'neural', 'networks', 'exploit', 'property', 'many', 'natural', 'sig-', 'nals', 'compositional', 'hierarchies', ',', 'higher-level', 'features', 'obtained', 'composing', 'lower-level', 'ones', '.']

>> Bigrams are: 
 [('Deep', 'neural'), ('neural', 'networks'), ('networks', 'exploit'), ('exploit', 'property'), ('property', 'many'), ('many', 'natural'), ('natural', 'sig-'), ('sig-', 'nals'), ('nals', 'compositional'), ('compositional', 'hierarchies'), ('hierarchies', ','), (',', 'higher-level'), ('higher-level', 'features'), ('features', 'obtained'), ('obtained', 'composing'), ('composing', 'lower-level'), ('lower-level', 'ones'), ('ones', '.')]

>> Trigrams are: 
 [('Deep', 'neural', 'networks'), ('neural', 'networks', 'exploit'), ('networks', 'exploit', 'property'), ('exploit', 'property', 'many'), ('property', 'many', 'natural'), ('many', 'natural', 'sig-'), ('natural', 'sig-', 'nals'), ('sig-', 'nals', 'compositional'), ('nals', 'compositional', 'hierarchies'), ('compositional', 'hierarchies', ','), ('hierarchies', ',', 'higher-level'), (',', 'higher-level', 'features'), ('higher-level', 'features', 'obtained'), ('features', 'obtained', 'composing'), ('obtained', 'composing', 'lower-level'), ('composing', 'lower-level', 'ones'), ('lower-level', 'ones', '.')]

>> POS Tags are: 
 [('Deep', 'JJ'), ('neural', 'JJ'), ('networks', 'NNS'), ('exploit', 'VBP'), ('property', 'NN'), ('many', 'JJ'), ('natural', 'JJ'), ('sig-', 'JJ'), ('nals', 'NNS'), ('compositional', 'JJ'), ('hierarchies', 'NNS'), (',', ','), ('higher-level', 'JJ'), ('features', 'NNS'), ('obtained', 'VBN'), ('composing', 'VBG'), ('lower-level', 'JJ'), ('ones', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['Deep neural networks', 'property', 'many natural sig- nals', 'compositional hierarchies', 'higher-level features', 'lower-level ones']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Deep', 'deep'), ('neural', 'neural'), ('networks', 'network'), ('exploit', 'exploit'), ('property', 'properti'), ('many', 'mani'), ('natural', 'natur'), ('sig-', 'sig-'), ('nals', 'nal'), ('compositional', 'composit'), ('hierarchies', 'hierarchi'), (',', ','), ('higher-level', 'higher-level'), ('features', 'featur'), ('obtained', 'obtain'), ('composing', 'compos'), ('lower-level', 'lower-level'), ('ones', 'one'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Deep', 'deep'), ('neural', 'neural'), ('networks', 'network'), ('exploit', 'exploit'), ('property', 'properti'), ('many', 'mani'), ('natural', 'natur'), ('sig-', 'sig-'), ('nals', 'nal'), ('compositional', 'composit'), ('hierarchies', 'hierarchi'), (',', ','), ('higher-level', 'higher-level'), ('features', 'featur'), ('obtained', 'obtain'), ('composing', 'compos'), ('lower-level', 'lower-level'), ('ones', 'one'), ('.', '.')]

>> Lemmatization: 
 [('Deep', 'Deep'), ('neural', 'neural'), ('networks', 'network'), ('exploit', 'exploit'), ('property', 'property'), ('many', 'many'), ('natural', 'natural'), ('sig-', 'sig-'), ('nals', 'nals'), ('compositional', 'compositional'), ('hierarchies', 'hierarchy'), (',', ','), ('higher-level', 'higher-level'), ('features', 'feature'), ('obtained', 'obtained'), ('composing', 'composing'), ('lower-level', 'lower-level'), ('ones', 'one'), ('.', '.')]


------------------- Sentence 2 -------------------

In images, local combi- nations of edges form motifs, motifs assemble into parts, and parts  form objects.

>> Tokens are: 
 ['In', 'images', ',', 'local', 'combi-', 'nations', 'edges', 'form', 'motifs', ',', 'motifs', 'assemble', 'parts', ',', 'parts', 'form', 'objects', '.']

>> Bigrams are: 
 [('In', 'images'), ('images', ','), (',', 'local'), ('local', 'combi-'), ('combi-', 'nations'), ('nations', 'edges'), ('edges', 'form'), ('form', 'motifs'), ('motifs', ','), (',', 'motifs'), ('motifs', 'assemble'), ('assemble', 'parts'), ('parts', ','), (',', 'parts'), ('parts', 'form'), ('form', 'objects'), ('objects', '.')]

>> Trigrams are: 
 [('In', 'images', ','), ('images', ',', 'local'), (',', 'local', 'combi-'), ('local', 'combi-', 'nations'), ('combi-', 'nations', 'edges'), ('nations', 'edges', 'form'), ('edges', 'form', 'motifs'), ('form', 'motifs', ','), ('motifs', ',', 'motifs'), (',', 'motifs', 'assemble'), ('motifs', 'assemble', 'parts'), ('assemble', 'parts', ','), ('parts', ',', 'parts'), (',', 'parts', 'form'), ('parts', 'form', 'objects'), ('form', 'objects', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('images', 'NNS'), (',', ','), ('local', 'JJ'), ('combi-', 'JJ'), ('nations', 'NNS'), ('edges', 'VBZ'), ('form', 'NN'), ('motifs', 'NNS'), (',', ','), ('motifs', 'NNS'), ('assemble', 'JJ'), ('parts', 'NNS'), (',', ','), ('parts', 'NNS'), ('form', 'VBP'), ('objects', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['images', 'local combi- nations', 'form motifs', 'motifs', 'assemble parts', 'parts', 'objects']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('images', 'imag'), (',', ','), ('local', 'local'), ('combi-', 'combi-'), ('nations', 'nation'), ('edges', 'edg'), ('form', 'form'), ('motifs', 'motif'), (',', ','), ('motifs', 'motif'), ('assemble', 'assembl'), ('parts', 'part'), (',', ','), ('parts', 'part'), ('form', 'form'), ('objects', 'object'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('images', 'imag'), (',', ','), ('local', 'local'), ('combi-', 'combi-'), ('nations', 'nation'), ('edges', 'edg'), ('form', 'form'), ('motifs', 'motif'), (',', ','), ('motifs', 'motif'), ('assemble', 'assembl'), ('parts', 'part'), (',', ','), ('parts', 'part'), ('form', 'form'), ('objects', 'object'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('images', 'image'), (',', ','), ('local', 'local'), ('combi-', 'combi-'), ('nations', 'nation'), ('edges', 'edge'), ('form', 'form'), ('motifs', 'motif'), (',', ','), ('motifs', 'motif'), ('assemble', 'assemble'), ('parts', 'part'), (',', ','), ('parts', 'part'), ('form', 'form'), ('objects', 'object'), ('.', '.')]


------------------- Sentence 3 -------------------

Similar hierarchies exist in speech and text from sounds  to phones, phonemes, syllables, words and sentences.

>> Tokens are: 
 ['Similar', 'hierarchies', 'exist', 'speech', 'text', 'sounds', 'phones', ',', 'phonemes', ',', 'syllables', ',', 'words', 'sentences', '.']

>> Bigrams are: 
 [('Similar', 'hierarchies'), ('hierarchies', 'exist'), ('exist', 'speech'), ('speech', 'text'), ('text', 'sounds'), ('sounds', 'phones'), ('phones', ','), (',', 'phonemes'), ('phonemes', ','), (',', 'syllables'), ('syllables', ','), (',', 'words'), ('words', 'sentences'), ('sentences', '.')]

>> Trigrams are: 
 [('Similar', 'hierarchies', 'exist'), ('hierarchies', 'exist', 'speech'), ('exist', 'speech', 'text'), ('speech', 'text', 'sounds'), ('text', 'sounds', 'phones'), ('sounds', 'phones', ','), ('phones', ',', 'phonemes'), (',', 'phonemes', ','), ('phonemes', ',', 'syllables'), (',', 'syllables', ','), ('syllables', ',', 'words'), (',', 'words', 'sentences'), ('words', 'sentences', '.')]

>> POS Tags are: 
 [('Similar', 'JJ'), ('hierarchies', 'NNS'), ('exist', 'VBP'), ('speech', 'JJ'), ('text', 'NN'), ('sounds', 'VBZ'), ('phones', 'NNS'), (',', ','), ('phonemes', 'NNS'), (',', ','), ('syllables', 'NNS'), (',', ','), ('words', 'NNS'), ('sentences', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['Similar hierarchies', 'speech text', 'phones', 'phonemes', 'syllables', 'words sentences']

>> Named Entities are: 
 [('GPE', 'Similar')] 

>> Stemming using Porter Stemmer: 
 [('Similar', 'similar'), ('hierarchies', 'hierarchi'), ('exist', 'exist'), ('speech', 'speech'), ('text', 'text'), ('sounds', 'sound'), ('phones', 'phone'), (',', ','), ('phonemes', 'phonem'), (',', ','), ('syllables', 'syllabl'), (',', ','), ('words', 'word'), ('sentences', 'sentenc'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Similar', 'similar'), ('hierarchies', 'hierarchi'), ('exist', 'exist'), ('speech', 'speech'), ('text', 'text'), ('sounds', 'sound'), ('phones', 'phone'), (',', ','), ('phonemes', 'phonem'), (',', ','), ('syllables', 'syllabl'), (',', ','), ('words', 'word'), ('sentences', 'sentenc'), ('.', '.')]

>> Lemmatization: 
 [('Similar', 'Similar'), ('hierarchies', 'hierarchy'), ('exist', 'exist'), ('speech', 'speech'), ('text', 'text'), ('sounds', 'sound'), ('phones', 'phone'), (',', ','), ('phonemes', 'phoneme'), (',', ','), ('syllables', 'syllable'), (',', ','), ('words', 'word'), ('sentences', 'sentence'), ('.', '.')]


------------------- Sentence 4 -------------------

The pooling  allows representations to vary very little when elements in the previ- ous layer vary in position and appearance.

>> Tokens are: 
 ['The', 'pooling', 'allows', 'representations', 'vary', 'little', 'elements', 'previ-', 'ous', 'layer', 'vary', 'position', 'appearance', '.']

>> Bigrams are: 
 [('The', 'pooling'), ('pooling', 'allows'), ('allows', 'representations'), ('representations', 'vary'), ('vary', 'little'), ('little', 'elements'), ('elements', 'previ-'), ('previ-', 'ous'), ('ous', 'layer'), ('layer', 'vary'), ('vary', 'position'), ('position', 'appearance'), ('appearance', '.')]

>> Trigrams are: 
 [('The', 'pooling', 'allows'), ('pooling', 'allows', 'representations'), ('allows', 'representations', 'vary'), ('representations', 'vary', 'little'), ('vary', 'little', 'elements'), ('little', 'elements', 'previ-'), ('elements', 'previ-', 'ous'), ('previ-', 'ous', 'layer'), ('ous', 'layer', 'vary'), ('layer', 'vary', 'position'), ('vary', 'position', 'appearance'), ('position', 'appearance', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('pooling', 'NN'), ('allows', 'VBZ'), ('representations', 'NNS'), ('vary', 'JJ'), ('little', 'JJ'), ('elements', 'NNS'), ('previ-', 'JJ'), ('ous', 'JJ'), ('layer', 'NN'), ('vary', 'JJ'), ('position', 'NN'), ('appearance', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['The pooling', 'representations', 'vary little elements', 'previ- ous layer', 'vary position appearance']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('pooling', 'pool'), ('allows', 'allow'), ('representations', 'represent'), ('vary', 'vari'), ('little', 'littl'), ('elements', 'element'), ('previ-', 'previ-'), ('ous', 'ou'), ('layer', 'layer'), ('vary', 'vari'), ('position', 'posit'), ('appearance', 'appear'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('pooling', 'pool'), ('allows', 'allow'), ('representations', 'represent'), ('vary', 'vari'), ('little', 'littl'), ('elements', 'element'), ('previ-', 'previ-'), ('ous', 'ous'), ('layer', 'layer'), ('vary', 'vari'), ('position', 'posit'), ('appearance', 'appear'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('pooling', 'pooling'), ('allows', 'allows'), ('representations', 'representation'), ('vary', 'vary'), ('little', 'little'), ('elements', 'element'), ('previ-', 'previ-'), ('ous', 'ous'), ('layer', 'layer'), ('vary', 'vary'), ('position', 'position'), ('appearance', 'appearance'), ('.', '.')]



========================================== PARAGRAPH 122 ===========================================

The convolutional and pooling layers in ConvNets are directly  inspired by the classic notions of simple cells and complex cells in  visual neuroscience43, and the overall architecture is reminiscent of  the LGN–V1–V2–V4–IT hierarchy in the visual cortex ventral path- way44. When ConvNet models and monkeys are shown the same pic- ture, the activations of high-level units in the ConvNet explains half  of the variance of random sets of 160 neurons in the monkey’s infer- otemporal cortex45. ConvNets have their roots in the neocognitron46,  the architecture of which was somewhat similar, but did not have an  end-to-end supervised-learning algorithm such as backpropagation.  A primitive 1D ConvNet called a time-delay neural net was used for  the recognition of phonemes and simple words47,48.  

------------------- Sentence 1 -------------------

The convolutional and pooling layers in ConvNets are directly  inspired by the classic notions of simple cells and complex cells in  visual neuroscience43, and the overall architecture is reminiscent of  the LGN–V1–V2–V4–IT hierarchy in the visual cortex ventral path- way44.

>> Tokens are: 
 ['The', 'convolutional', 'pooling', 'layers', 'ConvNets', 'directly', 'inspired', 'classic', 'notions', 'simple', 'cells', 'complex', 'cells', 'visual', 'neuroscience43', ',', 'overall', 'architecture', 'reminiscent', 'LGN–V1–V2–V4–IT', 'hierarchy', 'visual', 'cortex', 'ventral', 'path-', 'way44', '.']

>> Bigrams are: 
 [('The', 'convolutional'), ('convolutional', 'pooling'), ('pooling', 'layers'), ('layers', 'ConvNets'), ('ConvNets', 'directly'), ('directly', 'inspired'), ('inspired', 'classic'), ('classic', 'notions'), ('notions', 'simple'), ('simple', 'cells'), ('cells', 'complex'), ('complex', 'cells'), ('cells', 'visual'), ('visual', 'neuroscience43'), ('neuroscience43', ','), (',', 'overall'), ('overall', 'architecture'), ('architecture', 'reminiscent'), ('reminiscent', 'LGN–V1–V2–V4–IT'), ('LGN–V1–V2–V4–IT', 'hierarchy'), ('hierarchy', 'visual'), ('visual', 'cortex'), ('cortex', 'ventral'), ('ventral', 'path-'), ('path-', 'way44'), ('way44', '.')]

>> Trigrams are: 
 [('The', 'convolutional', 'pooling'), ('convolutional', 'pooling', 'layers'), ('pooling', 'layers', 'ConvNets'), ('layers', 'ConvNets', 'directly'), ('ConvNets', 'directly', 'inspired'), ('directly', 'inspired', 'classic'), ('inspired', 'classic', 'notions'), ('classic', 'notions', 'simple'), ('notions', 'simple', 'cells'), ('simple', 'cells', 'complex'), ('cells', 'complex', 'cells'), ('complex', 'cells', 'visual'), ('cells', 'visual', 'neuroscience43'), ('visual', 'neuroscience43', ','), ('neuroscience43', ',', 'overall'), (',', 'overall', 'architecture'), ('overall', 'architecture', 'reminiscent'), ('architecture', 'reminiscent', 'LGN–V1–V2–V4–IT'), ('reminiscent', 'LGN–V1–V2–V4–IT', 'hierarchy'), ('LGN–V1–V2–V4–IT', 'hierarchy', 'visual'), ('hierarchy', 'visual', 'cortex'), ('visual', 'cortex', 'ventral'), ('cortex', 'ventral', 'path-'), ('ventral', 'path-', 'way44'), ('path-', 'way44', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('convolutional', 'JJ'), ('pooling', 'NN'), ('layers', 'NNS'), ('ConvNets', 'NNP'), ('directly', 'RB'), ('inspired', 'VBD'), ('classic', 'JJ'), ('notions', 'NNS'), ('simple', 'JJ'), ('cells', 'NNS'), ('complex', 'JJ'), ('cells', 'NNS'), ('visual', 'JJ'), ('neuroscience43', 'RB'), (',', ','), ('overall', 'JJ'), ('architecture', 'NN'), ('reminiscent', 'NN'), ('LGN–V1–V2–V4–IT', 'NNP'), ('hierarchy', 'NN'), ('visual', 'JJ'), ('cortex', 'JJ'), ('ventral', 'JJ'), ('path-', 'JJ'), ('way44', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['The convolutional pooling layers ConvNets', 'classic notions', 'simple cells', 'complex cells', 'overall architecture reminiscent LGN–V1–V2–V4–IT hierarchy', 'visual cortex ventral path- way44']

>> Named Entities are: 
 [('ORGANIZATION', 'ConvNets')] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('convolutional', 'convolut'), ('pooling', 'pool'), ('layers', 'layer'), ('ConvNets', 'convnet'), ('directly', 'directli'), ('inspired', 'inspir'), ('classic', 'classic'), ('notions', 'notion'), ('simple', 'simpl'), ('cells', 'cell'), ('complex', 'complex'), ('cells', 'cell'), ('visual', 'visual'), ('neuroscience43', 'neuroscience43'), (',', ','), ('overall', 'overal'), ('architecture', 'architectur'), ('reminiscent', 'reminisc'), ('LGN–V1–V2–V4–IT', 'lgn–v1–v2–v4–it'), ('hierarchy', 'hierarchi'), ('visual', 'visual'), ('cortex', 'cortex'), ('ventral', 'ventral'), ('path-', 'path-'), ('way44', 'way44'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('convolutional', 'convolut'), ('pooling', 'pool'), ('layers', 'layer'), ('ConvNets', 'convnet'), ('directly', 'direct'), ('inspired', 'inspir'), ('classic', 'classic'), ('notions', 'notion'), ('simple', 'simpl'), ('cells', 'cell'), ('complex', 'complex'), ('cells', 'cell'), ('visual', 'visual'), ('neuroscience43', 'neuroscience43'), (',', ','), ('overall', 'overal'), ('architecture', 'architectur'), ('reminiscent', 'reminisc'), ('LGN–V1–V2–V4–IT', 'lgn–v1–v2–v4–it'), ('hierarchy', 'hierarchi'), ('visual', 'visual'), ('cortex', 'cortex'), ('ventral', 'ventral'), ('path-', 'path-'), ('way44', 'way44'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('convolutional', 'convolutional'), ('pooling', 'pooling'), ('layers', 'layer'), ('ConvNets', 'ConvNets'), ('directly', 'directly'), ('inspired', 'inspired'), ('classic', 'classic'), ('notions', 'notion'), ('simple', 'simple'), ('cells', 'cell'), ('complex', 'complex'), ('cells', 'cell'), ('visual', 'visual'), ('neuroscience43', 'neuroscience43'), (',', ','), ('overall', 'overall'), ('architecture', 'architecture'), ('reminiscent', 'reminiscent'), ('LGN–V1–V2–V4–IT', 'LGN–V1–V2–V4–IT'), ('hierarchy', 'hierarchy'), ('visual', 'visual'), ('cortex', 'cortex'), ('ventral', 'ventral'), ('path-', 'path-'), ('way44', 'way44'), ('.', '.')]


------------------- Sentence 2 -------------------

When ConvNet models and monkeys are shown the same pic- ture, the activations of high-level units in the ConvNet explains half  of the variance of random sets of 160 neurons in the monkey’s infer- otemporal cortex45.

>> Tokens are: 
 ['When', 'ConvNet', 'models', 'monkeys', 'shown', 'pic-', 'ture', ',', 'activations', 'high-level', 'units', 'ConvNet', 'explains', 'half', 'variance', 'random', 'sets', '160', 'neurons', 'monkey', '’', 'infer-', 'otemporal', 'cortex45', '.']

>> Bigrams are: 
 [('When', 'ConvNet'), ('ConvNet', 'models'), ('models', 'monkeys'), ('monkeys', 'shown'), ('shown', 'pic-'), ('pic-', 'ture'), ('ture', ','), (',', 'activations'), ('activations', 'high-level'), ('high-level', 'units'), ('units', 'ConvNet'), ('ConvNet', 'explains'), ('explains', 'half'), ('half', 'variance'), ('variance', 'random'), ('random', 'sets'), ('sets', '160'), ('160', 'neurons'), ('neurons', 'monkey'), ('monkey', '’'), ('’', 'infer-'), ('infer-', 'otemporal'), ('otemporal', 'cortex45'), ('cortex45', '.')]

>> Trigrams are: 
 [('When', 'ConvNet', 'models'), ('ConvNet', 'models', 'monkeys'), ('models', 'monkeys', 'shown'), ('monkeys', 'shown', 'pic-'), ('shown', 'pic-', 'ture'), ('pic-', 'ture', ','), ('ture', ',', 'activations'), (',', 'activations', 'high-level'), ('activations', 'high-level', 'units'), ('high-level', 'units', 'ConvNet'), ('units', 'ConvNet', 'explains'), ('ConvNet', 'explains', 'half'), ('explains', 'half', 'variance'), ('half', 'variance', 'random'), ('variance', 'random', 'sets'), ('random', 'sets', '160'), ('sets', '160', 'neurons'), ('160', 'neurons', 'monkey'), ('neurons', 'monkey', '’'), ('monkey', '’', 'infer-'), ('’', 'infer-', 'otemporal'), ('infer-', 'otemporal', 'cortex45'), ('otemporal', 'cortex45', '.')]

>> POS Tags are: 
 [('When', 'WRB'), ('ConvNet', 'NNP'), ('models', 'NNS'), ('monkeys', 'VBP'), ('shown', 'VBN'), ('pic-', 'JJ'), ('ture', 'NN'), (',', ','), ('activations', 'NNS'), ('high-level', 'VBP'), ('units', 'NNS'), ('ConvNet', 'NNP'), ('explains', 'VBZ'), ('half', 'JJ'), ('variance', 'NN'), ('random', 'JJ'), ('sets', 'NNS'), ('160', 'CD'), ('neurons', 'NNS'), ('monkey', 'JJ'), ('’', 'NNP'), ('infer-', 'JJ'), ('otemporal', 'JJ'), ('cortex45', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['ConvNet models', 'pic- ture', 'activations', 'units ConvNet', 'half variance', 'random sets', 'neurons', 'monkey ’', 'infer- otemporal cortex45']

>> Named Entities are: 
 [('ORGANIZATION', 'ConvNet'), ('ORGANIZATION', 'ConvNet')] 

>> Stemming using Porter Stemmer: 
 [('When', 'when'), ('ConvNet', 'convnet'), ('models', 'model'), ('monkeys', 'monkey'), ('shown', 'shown'), ('pic-', 'pic-'), ('ture', 'ture'), (',', ','), ('activations', 'activ'), ('high-level', 'high-level'), ('units', 'unit'), ('ConvNet', 'convnet'), ('explains', 'explain'), ('half', 'half'), ('variance', 'varianc'), ('random', 'random'), ('sets', 'set'), ('160', '160'), ('neurons', 'neuron'), ('monkey', 'monkey'), ('’', '’'), ('infer-', 'infer-'), ('otemporal', 'otempor'), ('cortex45', 'cortex45'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('When', 'when'), ('ConvNet', 'convnet'), ('models', 'model'), ('monkeys', 'monkey'), ('shown', 'shown'), ('pic-', 'pic-'), ('ture', 'ture'), (',', ','), ('activations', 'activ'), ('high-level', 'high-level'), ('units', 'unit'), ('ConvNet', 'convnet'), ('explains', 'explain'), ('half', 'half'), ('variance', 'varianc'), ('random', 'random'), ('sets', 'set'), ('160', '160'), ('neurons', 'neuron'), ('monkey', 'monkey'), ('’', '’'), ('infer-', 'infer-'), ('otemporal', 'otempor'), ('cortex45', 'cortex45'), ('.', '.')]

>> Lemmatization: 
 [('When', 'When'), ('ConvNet', 'ConvNet'), ('models', 'model'), ('monkeys', 'monkey'), ('shown', 'shown'), ('pic-', 'pic-'), ('ture', 'ture'), (',', ','), ('activations', 'activation'), ('high-level', 'high-level'), ('units', 'unit'), ('ConvNet', 'ConvNet'), ('explains', 'explains'), ('half', 'half'), ('variance', 'variance'), ('random', 'random'), ('sets', 'set'), ('160', '160'), ('neurons', 'neuron'), ('monkey', 'monkey'), ('’', '’'), ('infer-', 'infer-'), ('otemporal', 'otemporal'), ('cortex45', 'cortex45'), ('.', '.')]


------------------- Sentence 3 -------------------

ConvNets have their roots in the neocognitron46,  the architecture of which was somewhat similar, but did not have an  end-to-end supervised-learning algorithm such as backpropagation.

>> Tokens are: 
 ['ConvNets', 'roots', 'neocognitron46', ',', 'architecture', 'somewhat', 'similar', ',', 'end-to-end', 'supervised-learning', 'algorithm', 'backpropagation', '.']

>> Bigrams are: 
 [('ConvNets', 'roots'), ('roots', 'neocognitron46'), ('neocognitron46', ','), (',', 'architecture'), ('architecture', 'somewhat'), ('somewhat', 'similar'), ('similar', ','), (',', 'end-to-end'), ('end-to-end', 'supervised-learning'), ('supervised-learning', 'algorithm'), ('algorithm', 'backpropagation'), ('backpropagation', '.')]

>> Trigrams are: 
 [('ConvNets', 'roots', 'neocognitron46'), ('roots', 'neocognitron46', ','), ('neocognitron46', ',', 'architecture'), (',', 'architecture', 'somewhat'), ('architecture', 'somewhat', 'similar'), ('somewhat', 'similar', ','), ('similar', ',', 'end-to-end'), (',', 'end-to-end', 'supervised-learning'), ('end-to-end', 'supervised-learning', 'algorithm'), ('supervised-learning', 'algorithm', 'backpropagation'), ('algorithm', 'backpropagation', '.')]

>> POS Tags are: 
 [('ConvNets', 'NNS'), ('roots', 'VBP'), ('neocognitron46', 'RB'), (',', ','), ('architecture', 'NN'), ('somewhat', 'RB'), ('similar', 'JJ'), (',', ','), ('end-to-end', 'JJ'), ('supervised-learning', 'JJ'), ('algorithm', 'NN'), ('backpropagation', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['ConvNets', 'architecture', 'end-to-end supervised-learning algorithm backpropagation']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('ConvNets', 'convnet'), ('roots', 'root'), ('neocognitron46', 'neocognitron46'), (',', ','), ('architecture', 'architectur'), ('somewhat', 'somewhat'), ('similar', 'similar'), (',', ','), ('end-to-end', 'end-to-end'), ('supervised-learning', 'supervised-learn'), ('algorithm', 'algorithm'), ('backpropagation', 'backpropag'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('ConvNets', 'convnet'), ('roots', 'root'), ('neocognitron46', 'neocognitron46'), (',', ','), ('architecture', 'architectur'), ('somewhat', 'somewhat'), ('similar', 'similar'), (',', ','), ('end-to-end', 'end-to-end'), ('supervised-learning', 'supervised-learn'), ('algorithm', 'algorithm'), ('backpropagation', 'backpropag'), ('.', '.')]

>> Lemmatization: 
 [('ConvNets', 'ConvNets'), ('roots', 'root'), ('neocognitron46', 'neocognitron46'), (',', ','), ('architecture', 'architecture'), ('somewhat', 'somewhat'), ('similar', 'similar'), (',', ','), ('end-to-end', 'end-to-end'), ('supervised-learning', 'supervised-learning'), ('algorithm', 'algorithm'), ('backpropagation', 'backpropagation'), ('.', '.')]


------------------- Sentence 4 -------------------

A primitive 1D ConvNet called a time-delay neural net was used for  the recognition of phonemes and simple words47,48.

>> Tokens are: 
 ['A', 'primitive', '1D', 'ConvNet', 'called', 'time-delay', 'neural', 'net', 'used', 'recognition', 'phonemes', 'simple', 'words47,48', '.']

>> Bigrams are: 
 [('A', 'primitive'), ('primitive', '1D'), ('1D', 'ConvNet'), ('ConvNet', 'called'), ('called', 'time-delay'), ('time-delay', 'neural'), ('neural', 'net'), ('net', 'used'), ('used', 'recognition'), ('recognition', 'phonemes'), ('phonemes', 'simple'), ('simple', 'words47,48'), ('words47,48', '.')]

>> Trigrams are: 
 [('A', 'primitive', '1D'), ('primitive', '1D', 'ConvNet'), ('1D', 'ConvNet', 'called'), ('ConvNet', 'called', 'time-delay'), ('called', 'time-delay', 'neural'), ('time-delay', 'neural', 'net'), ('neural', 'net', 'used'), ('net', 'used', 'recognition'), ('used', 'recognition', 'phonemes'), ('recognition', 'phonemes', 'simple'), ('phonemes', 'simple', 'words47,48'), ('simple', 'words47,48', '.')]

>> POS Tags are: 
 [('A', 'DT'), ('primitive', 'JJ'), ('1D', 'CD'), ('ConvNet', 'NNP'), ('called', 'VBD'), ('time-delay', 'JJ'), ('neural', 'JJ'), ('net', 'NN'), ('used', 'VBN'), ('recognition', 'NN'), ('phonemes', 'RB'), ('simple', 'JJ'), ('words47,48', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['ConvNet', 'time-delay neural net', 'recognition', 'simple words47,48']

>> Named Entities are: 
 [('ORGANIZATION', 'ConvNet')] 

>> Stemming using Porter Stemmer: 
 [('A', 'a'), ('primitive', 'primit'), ('1D', '1d'), ('ConvNet', 'convnet'), ('called', 'call'), ('time-delay', 'time-delay'), ('neural', 'neural'), ('net', 'net'), ('used', 'use'), ('recognition', 'recognit'), ('phonemes', 'phonem'), ('simple', 'simpl'), ('words47,48', 'words47,48'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('A', 'a'), ('primitive', 'primit'), ('1D', '1d'), ('ConvNet', 'convnet'), ('called', 'call'), ('time-delay', 'time-delay'), ('neural', 'neural'), ('net', 'net'), ('used', 'use'), ('recognition', 'recognit'), ('phonemes', 'phonem'), ('simple', 'simpl'), ('words47,48', 'words47,48'), ('.', '.')]

>> Lemmatization: 
 [('A', 'A'), ('primitive', 'primitive'), ('1D', '1D'), ('ConvNet', 'ConvNet'), ('called', 'called'), ('time-delay', 'time-delay'), ('neural', 'neural'), ('net', 'net'), ('used', 'used'), ('recognition', 'recognition'), ('phonemes', 'phoneme'), ('simple', 'simple'), ('words47,48', 'words47,48'), ('.', '.')]



========================================== PARAGRAPH 123 ===========================================

There have been numerous applications of convolutional net- works going back to the early 1990s, starting with time-delay neu- ral networks for speech recognition47 and document reading42. The  document reading system used a ConvNet trained jointly with a  probabilistic model that implemented language constraints. By the  late 1990s this system was reading over 10% of all the cheques in the  United States. A number of ConvNet-based optical character recog- nition and handwriting recognition systems were later deployed by  Microsoft49. ConvNets were also experimented with in the early 1990s  for object detection in natural images, including faces and hands50,51,  and for face recognition52.  

------------------- Sentence 1 -------------------

There have been numerous applications of convolutional net- works going back to the early 1990s, starting with time-delay neu- ral networks for speech recognition47 and document reading42.

>> Tokens are: 
 ['There', 'numerous', 'applications', 'convolutional', 'net-', 'works', 'going', 'back', 'early', '1990s', ',', 'starting', 'time-delay', 'neu-', 'ral', 'networks', 'speech', 'recognition47', 'document', 'reading42', '.']

>> Bigrams are: 
 [('There', 'numerous'), ('numerous', 'applications'), ('applications', 'convolutional'), ('convolutional', 'net-'), ('net-', 'works'), ('works', 'going'), ('going', 'back'), ('back', 'early'), ('early', '1990s'), ('1990s', ','), (',', 'starting'), ('starting', 'time-delay'), ('time-delay', 'neu-'), ('neu-', 'ral'), ('ral', 'networks'), ('networks', 'speech'), ('speech', 'recognition47'), ('recognition47', 'document'), ('document', 'reading42'), ('reading42', '.')]

>> Trigrams are: 
 [('There', 'numerous', 'applications'), ('numerous', 'applications', 'convolutional'), ('applications', 'convolutional', 'net-'), ('convolutional', 'net-', 'works'), ('net-', 'works', 'going'), ('works', 'going', 'back'), ('going', 'back', 'early'), ('back', 'early', '1990s'), ('early', '1990s', ','), ('1990s', ',', 'starting'), (',', 'starting', 'time-delay'), ('starting', 'time-delay', 'neu-'), ('time-delay', 'neu-', 'ral'), ('neu-', 'ral', 'networks'), ('ral', 'networks', 'speech'), ('networks', 'speech', 'recognition47'), ('speech', 'recognition47', 'document'), ('recognition47', 'document', 'reading42'), ('document', 'reading42', '.')]

>> POS Tags are: 
 [('There', 'EX'), ('numerous', 'JJ'), ('applications', 'NNS'), ('convolutional', 'JJ'), ('net-', 'JJ'), ('works', 'NNS'), ('going', 'VBG'), ('back', 'RB'), ('early', 'RB'), ('1990s', 'CD'), (',', ','), ('starting', 'VBG'), ('time-delay', 'JJ'), ('neu-', 'JJ'), ('ral', 'JJ'), ('networks', 'NNS'), ('speech', 'VBP'), ('recognition47', 'JJ'), ('document', 'NN'), ('reading42', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['numerous applications', 'convolutional net- works', 'time-delay neu- ral networks', 'recognition47 document reading42']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('There', 'there'), ('numerous', 'numer'), ('applications', 'applic'), ('convolutional', 'convolut'), ('net-', 'net-'), ('works', 'work'), ('going', 'go'), ('back', 'back'), ('early', 'earli'), ('1990s', '1990'), (',', ','), ('starting', 'start'), ('time-delay', 'time-delay'), ('neu-', 'neu-'), ('ral', 'ral'), ('networks', 'network'), ('speech', 'speech'), ('recognition47', 'recognition47'), ('document', 'document'), ('reading42', 'reading42'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('There', 'there'), ('numerous', 'numer'), ('applications', 'applic'), ('convolutional', 'convolut'), ('net-', 'net-'), ('works', 'work'), ('going', 'go'), ('back', 'back'), ('early', 'earli'), ('1990s', '1990s'), (',', ','), ('starting', 'start'), ('time-delay', 'time-delay'), ('neu-', 'neu-'), ('ral', 'ral'), ('networks', 'network'), ('speech', 'speech'), ('recognition47', 'recognition47'), ('document', 'document'), ('reading42', 'reading42'), ('.', '.')]

>> Lemmatization: 
 [('There', 'There'), ('numerous', 'numerous'), ('applications', 'application'), ('convolutional', 'convolutional'), ('net-', 'net-'), ('works', 'work'), ('going', 'going'), ('back', 'back'), ('early', 'early'), ('1990s', '1990s'), (',', ','), ('starting', 'starting'), ('time-delay', 'time-delay'), ('neu-', 'neu-'), ('ral', 'ral'), ('networks', 'network'), ('speech', 'speech'), ('recognition47', 'recognition47'), ('document', 'document'), ('reading42', 'reading42'), ('.', '.')]


------------------- Sentence 2 -------------------

The  document reading system used a ConvNet trained jointly with a  probabilistic model that implemented language constraints.

>> Tokens are: 
 ['The', 'document', 'reading', 'system', 'used', 'ConvNet', 'trained', 'jointly', 'probabilistic', 'model', 'implemented', 'language', 'constraints', '.']

>> Bigrams are: 
 [('The', 'document'), ('document', 'reading'), ('reading', 'system'), ('system', 'used'), ('used', 'ConvNet'), ('ConvNet', 'trained'), ('trained', 'jointly'), ('jointly', 'probabilistic'), ('probabilistic', 'model'), ('model', 'implemented'), ('implemented', 'language'), ('language', 'constraints'), ('constraints', '.')]

>> Trigrams are: 
 [('The', 'document', 'reading'), ('document', 'reading', 'system'), ('reading', 'system', 'used'), ('system', 'used', 'ConvNet'), ('used', 'ConvNet', 'trained'), ('ConvNet', 'trained', 'jointly'), ('trained', 'jointly', 'probabilistic'), ('jointly', 'probabilistic', 'model'), ('probabilistic', 'model', 'implemented'), ('model', 'implemented', 'language'), ('implemented', 'language', 'constraints'), ('language', 'constraints', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('document', 'NN'), ('reading', 'NN'), ('system', 'NN'), ('used', 'VBN'), ('ConvNet', 'NNP'), ('trained', 'VBD'), ('jointly', 'RB'), ('probabilistic', 'JJ'), ('model', 'NN'), ('implemented', 'VBN'), ('language', 'NN'), ('constraints', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['The document reading system', 'ConvNet', 'probabilistic model', 'language constraints']

>> Named Entities are: 
 [('ORGANIZATION', 'ConvNet')] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('document', 'document'), ('reading', 'read'), ('system', 'system'), ('used', 'use'), ('ConvNet', 'convnet'), ('trained', 'train'), ('jointly', 'jointli'), ('probabilistic', 'probabilist'), ('model', 'model'), ('implemented', 'implement'), ('language', 'languag'), ('constraints', 'constraint'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('document', 'document'), ('reading', 'read'), ('system', 'system'), ('used', 'use'), ('ConvNet', 'convnet'), ('trained', 'train'), ('jointly', 'joint'), ('probabilistic', 'probabilist'), ('model', 'model'), ('implemented', 'implement'), ('language', 'languag'), ('constraints', 'constraint'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('document', 'document'), ('reading', 'reading'), ('system', 'system'), ('used', 'used'), ('ConvNet', 'ConvNet'), ('trained', 'trained'), ('jointly', 'jointly'), ('probabilistic', 'probabilistic'), ('model', 'model'), ('implemented', 'implemented'), ('language', 'language'), ('constraints', 'constraint'), ('.', '.')]


------------------- Sentence 3 -------------------

By the  late 1990s this system was reading over 10% of all the cheques in the  United States.

>> Tokens are: 
 ['By', 'late', '1990s', 'system', 'reading', '10', '%', 'cheques', 'United', 'States', '.']

>> Bigrams are: 
 [('By', 'late'), ('late', '1990s'), ('1990s', 'system'), ('system', 'reading'), ('reading', '10'), ('10', '%'), ('%', 'cheques'), ('cheques', 'United'), ('United', 'States'), ('States', '.')]

>> Trigrams are: 
 [('By', 'late', '1990s'), ('late', '1990s', 'system'), ('1990s', 'system', 'reading'), ('system', 'reading', '10'), ('reading', '10', '%'), ('10', '%', 'cheques'), ('%', 'cheques', 'United'), ('cheques', 'United', 'States'), ('United', 'States', '.')]

>> POS Tags are: 
 [('By', 'IN'), ('late', 'JJ'), ('1990s', 'CD'), ('system', 'NN'), ('reading', 'VBG'), ('10', 'CD'), ('%', 'NN'), ('cheques', 'NNS'), ('United', 'NNP'), ('States', 'NNPS'), ('.', '.')]

>> Noun Phrases are: 
 ['system', '% cheques United']

>> Named Entities are: 
 [('GPE', 'United States')] 

>> Stemming using Porter Stemmer: 
 [('By', 'by'), ('late', 'late'), ('1990s', '1990'), ('system', 'system'), ('reading', 'read'), ('10', '10'), ('%', '%'), ('cheques', 'chequ'), ('United', 'unit'), ('States', 'state'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('By', 'by'), ('late', 'late'), ('1990s', '1990s'), ('system', 'system'), ('reading', 'read'), ('10', '10'), ('%', '%'), ('cheques', 'chequ'), ('United', 'unit'), ('States', 'state'), ('.', '.')]

>> Lemmatization: 
 [('By', 'By'), ('late', 'late'), ('1990s', '1990s'), ('system', 'system'), ('reading', 'reading'), ('10', '10'), ('%', '%'), ('cheques', 'cheque'), ('United', 'United'), ('States', 'States'), ('.', '.')]


------------------- Sentence 4 -------------------

A number of ConvNet-based optical character recog- nition and handwriting recognition systems were later deployed by  Microsoft49.

>> Tokens are: 
 ['A', 'number', 'ConvNet-based', 'optical', 'character', 'recog-', 'nition', 'handwriting', 'recognition', 'systems', 'later', 'deployed', 'Microsoft49', '.']

>> Bigrams are: 
 [('A', 'number'), ('number', 'ConvNet-based'), ('ConvNet-based', 'optical'), ('optical', 'character'), ('character', 'recog-'), ('recog-', 'nition'), ('nition', 'handwriting'), ('handwriting', 'recognition'), ('recognition', 'systems'), ('systems', 'later'), ('later', 'deployed'), ('deployed', 'Microsoft49'), ('Microsoft49', '.')]

>> Trigrams are: 
 [('A', 'number', 'ConvNet-based'), ('number', 'ConvNet-based', 'optical'), ('ConvNet-based', 'optical', 'character'), ('optical', 'character', 'recog-'), ('character', 'recog-', 'nition'), ('recog-', 'nition', 'handwriting'), ('nition', 'handwriting', 'recognition'), ('handwriting', 'recognition', 'systems'), ('recognition', 'systems', 'later'), ('systems', 'later', 'deployed'), ('later', 'deployed', 'Microsoft49'), ('deployed', 'Microsoft49', '.')]

>> POS Tags are: 
 [('A', 'DT'), ('number', 'NN'), ('ConvNet-based', 'JJ'), ('optical', 'JJ'), ('character', 'NN'), ('recog-', 'JJ'), ('nition', 'NN'), ('handwriting', 'VBG'), ('recognition', 'NN'), ('systems', 'NNS'), ('later', 'RB'), ('deployed', 'VBN'), ('Microsoft49', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['A number', 'ConvNet-based optical character', 'recog- nition', 'recognition systems', 'Microsoft49']

>> Named Entities are: 
 [('PERSON', 'Microsoft49')] 

>> Stemming using Porter Stemmer: 
 [('A', 'a'), ('number', 'number'), ('ConvNet-based', 'convnet-bas'), ('optical', 'optic'), ('character', 'charact'), ('recog-', 'recog-'), ('nition', 'nition'), ('handwriting', 'handwrit'), ('recognition', 'recognit'), ('systems', 'system'), ('later', 'later'), ('deployed', 'deploy'), ('Microsoft49', 'microsoft49'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('A', 'a'), ('number', 'number'), ('ConvNet-based', 'convnet-bas'), ('optical', 'optic'), ('character', 'charact'), ('recog-', 'recog-'), ('nition', 'nition'), ('handwriting', 'handwrit'), ('recognition', 'recognit'), ('systems', 'system'), ('later', 'later'), ('deployed', 'deploy'), ('Microsoft49', 'microsoft49'), ('.', '.')]

>> Lemmatization: 
 [('A', 'A'), ('number', 'number'), ('ConvNet-based', 'ConvNet-based'), ('optical', 'optical'), ('character', 'character'), ('recog-', 'recog-'), ('nition', 'nition'), ('handwriting', 'handwriting'), ('recognition', 'recognition'), ('systems', 'system'), ('later', 'later'), ('deployed', 'deployed'), ('Microsoft49', 'Microsoft49'), ('.', '.')]


------------------- Sentence 5 -------------------

ConvNets were also experimented with in the early 1990s  for object detection in natural images, including faces and hands50,51,  and for face recognition52.

>> Tokens are: 
 ['ConvNets', 'also', 'experimented', 'early', '1990s', 'object', 'detection', 'natural', 'images', ',', 'including', 'faces', 'hands50,51', ',', 'face', 'recognition52', '.']

>> Bigrams are: 
 [('ConvNets', 'also'), ('also', 'experimented'), ('experimented', 'early'), ('early', '1990s'), ('1990s', 'object'), ('object', 'detection'), ('detection', 'natural'), ('natural', 'images'), ('images', ','), (',', 'including'), ('including', 'faces'), ('faces', 'hands50,51'), ('hands50,51', ','), (',', 'face'), ('face', 'recognition52'), ('recognition52', '.')]

>> Trigrams are: 
 [('ConvNets', 'also', 'experimented'), ('also', 'experimented', 'early'), ('experimented', 'early', '1990s'), ('early', '1990s', 'object'), ('1990s', 'object', 'detection'), ('object', 'detection', 'natural'), ('detection', 'natural', 'images'), ('natural', 'images', ','), ('images', ',', 'including'), (',', 'including', 'faces'), ('including', 'faces', 'hands50,51'), ('faces', 'hands50,51', ','), ('hands50,51', ',', 'face'), (',', 'face', 'recognition52'), ('face', 'recognition52', '.')]

>> POS Tags are: 
 [('ConvNets', 'NNS'), ('also', 'RB'), ('experimented', 'VBD'), ('early', 'JJ'), ('1990s', 'CD'), ('object', 'JJ'), ('detection', 'NN'), ('natural', 'JJ'), ('images', 'NNS'), (',', ','), ('including', 'VBG'), ('faces', 'VBZ'), ('hands50,51', 'NN'), (',', ','), ('face', 'NN'), ('recognition52', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['ConvNets', 'object detection', 'natural images', 'hands50,51', 'face recognition52']

>> Named Entities are: 
 [('ORGANIZATION', 'ConvNets')] 

>> Stemming using Porter Stemmer: 
 [('ConvNets', 'convnet'), ('also', 'also'), ('experimented', 'experi'), ('early', 'earli'), ('1990s', '1990'), ('object', 'object'), ('detection', 'detect'), ('natural', 'natur'), ('images', 'imag'), (',', ','), ('including', 'includ'), ('faces', 'face'), ('hands50,51', 'hands50,51'), (',', ','), ('face', 'face'), ('recognition52', 'recognition52'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('ConvNets', 'convnet'), ('also', 'also'), ('experimented', 'experi'), ('early', 'earli'), ('1990s', '1990s'), ('object', 'object'), ('detection', 'detect'), ('natural', 'natur'), ('images', 'imag'), (',', ','), ('including', 'includ'), ('faces', 'face'), ('hands50,51', 'hands50,51'), (',', ','), ('face', 'face'), ('recognition52', 'recognition52'), ('.', '.')]

>> Lemmatization: 
 [('ConvNets', 'ConvNets'), ('also', 'also'), ('experimented', 'experimented'), ('early', 'early'), ('1990s', '1990s'), ('object', 'object'), ('detection', 'detection'), ('natural', 'natural'), ('images', 'image'), (',', ','), ('including', 'including'), ('faces', 'face'), ('hands50,51', 'hands50,51'), (',', ','), ('face', 'face'), ('recognition52', 'recognition52'), ('.', '.')]



========================================== PARAGRAPH 124 ===========================================

Image understanding with deep convolutional networks  Since the early 2000s, ConvNets have been applied with great success to  the detection, segmentation and recognition of objects and regions in  images. These were all tasks in which labelled data was relatively abun- dant, such as traffic sign recognition53, the segmentation of biological  images54 particularly for connectomics55, and the detection of faces,  text, pedestrians and human bodies in natural images36,50,51,56–58. A major  recent practical success of ConvNets is face recognition59.  

------------------- Sentence 1 -------------------

Image understanding with deep convolutional networks  Since the early 2000s, ConvNets have been applied with great success to  the detection, segmentation and recognition of objects and regions in  images.

>> Tokens are: 
 ['Image', 'understanding', 'deep', 'convolutional', 'networks', 'Since', 'early', '2000s', ',', 'ConvNets', 'applied', 'great', 'success', 'detection', ',', 'segmentation', 'recognition', 'objects', 'regions', 'images', '.']

>> Bigrams are: 
 [('Image', 'understanding'), ('understanding', 'deep'), ('deep', 'convolutional'), ('convolutional', 'networks'), ('networks', 'Since'), ('Since', 'early'), ('early', '2000s'), ('2000s', ','), (',', 'ConvNets'), ('ConvNets', 'applied'), ('applied', 'great'), ('great', 'success'), ('success', 'detection'), ('detection', ','), (',', 'segmentation'), ('segmentation', 'recognition'), ('recognition', 'objects'), ('objects', 'regions'), ('regions', 'images'), ('images', '.')]

>> Trigrams are: 
 [('Image', 'understanding', 'deep'), ('understanding', 'deep', 'convolutional'), ('deep', 'convolutional', 'networks'), ('convolutional', 'networks', 'Since'), ('networks', 'Since', 'early'), ('Since', 'early', '2000s'), ('early', '2000s', ','), ('2000s', ',', 'ConvNets'), (',', 'ConvNets', 'applied'), ('ConvNets', 'applied', 'great'), ('applied', 'great', 'success'), ('great', 'success', 'detection'), ('success', 'detection', ','), ('detection', ',', 'segmentation'), (',', 'segmentation', 'recognition'), ('segmentation', 'recognition', 'objects'), ('recognition', 'objects', 'regions'), ('objects', 'regions', 'images'), ('regions', 'images', '.')]

>> POS Tags are: 
 [('Image', 'NN'), ('understanding', 'JJ'), ('deep', 'JJ'), ('convolutional', 'NN'), ('networks', 'NNS'), ('Since', 'IN'), ('early', 'RB'), ('2000s', 'CD'), (',', ','), ('ConvNets', 'NNP'), ('applied', 'VBD'), ('great', 'JJ'), ('success', 'NN'), ('detection', 'NN'), (',', ','), ('segmentation', 'NN'), ('recognition', 'NN'), ('objects', 'VBZ'), ('regions', 'NNS'), ('images', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['Image', 'understanding deep convolutional networks', 'ConvNets', 'great success detection', 'segmentation recognition', 'regions images']

>> Named Entities are: 
 [('GPE', 'Image'), ('ORGANIZATION', 'ConvNets')] 

>> Stemming using Porter Stemmer: 
 [('Image', 'imag'), ('understanding', 'understand'), ('deep', 'deep'), ('convolutional', 'convolut'), ('networks', 'network'), ('Since', 'sinc'), ('early', 'earli'), ('2000s', '2000'), (',', ','), ('ConvNets', 'convnet'), ('applied', 'appli'), ('great', 'great'), ('success', 'success'), ('detection', 'detect'), (',', ','), ('segmentation', 'segment'), ('recognition', 'recognit'), ('objects', 'object'), ('regions', 'region'), ('images', 'imag'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Image', 'imag'), ('understanding', 'understand'), ('deep', 'deep'), ('convolutional', 'convolut'), ('networks', 'network'), ('Since', 'sinc'), ('early', 'earli'), ('2000s', '2000s'), (',', ','), ('ConvNets', 'convnet'), ('applied', 'appli'), ('great', 'great'), ('success', 'success'), ('detection', 'detect'), (',', ','), ('segmentation', 'segment'), ('recognition', 'recognit'), ('objects', 'object'), ('regions', 'region'), ('images', 'imag'), ('.', '.')]

>> Lemmatization: 
 [('Image', 'Image'), ('understanding', 'understanding'), ('deep', 'deep'), ('convolutional', 'convolutional'), ('networks', 'network'), ('Since', 'Since'), ('early', 'early'), ('2000s', '2000s'), (',', ','), ('ConvNets', 'ConvNets'), ('applied', 'applied'), ('great', 'great'), ('success', 'success'), ('detection', 'detection'), (',', ','), ('segmentation', 'segmentation'), ('recognition', 'recognition'), ('objects', 'object'), ('regions', 'region'), ('images', 'image'), ('.', '.')]


------------------- Sentence 2 -------------------

These were all tasks in which labelled data was relatively abun- dant, such as traffic sign recognition53, the segmentation of biological  images54 particularly for connectomics55, and the detection of faces,  text, pedestrians and human bodies in natural images36,50,51,56–58.

>> Tokens are: 
 ['These', 'tasks', 'labelled', 'data', 'relatively', 'abun-', 'dant', ',', 'traffic', 'sign', 'recognition53', ',', 'segmentation', 'biological', 'images54', 'particularly', 'connectomics55', ',', 'detection', 'faces', ',', 'text', ',', 'pedestrians', 'human', 'bodies', 'natural', 'images36,50,51,56–58', '.']

>> Bigrams are: 
 [('These', 'tasks'), ('tasks', 'labelled'), ('labelled', 'data'), ('data', 'relatively'), ('relatively', 'abun-'), ('abun-', 'dant'), ('dant', ','), (',', 'traffic'), ('traffic', 'sign'), ('sign', 'recognition53'), ('recognition53', ','), (',', 'segmentation'), ('segmentation', 'biological'), ('biological', 'images54'), ('images54', 'particularly'), ('particularly', 'connectomics55'), ('connectomics55', ','), (',', 'detection'), ('detection', 'faces'), ('faces', ','), (',', 'text'), ('text', ','), (',', 'pedestrians'), ('pedestrians', 'human'), ('human', 'bodies'), ('bodies', 'natural'), ('natural', 'images36,50,51,56–58'), ('images36,50,51,56–58', '.')]

>> Trigrams are: 
 [('These', 'tasks', 'labelled'), ('tasks', 'labelled', 'data'), ('labelled', 'data', 'relatively'), ('data', 'relatively', 'abun-'), ('relatively', 'abun-', 'dant'), ('abun-', 'dant', ','), ('dant', ',', 'traffic'), (',', 'traffic', 'sign'), ('traffic', 'sign', 'recognition53'), ('sign', 'recognition53', ','), ('recognition53', ',', 'segmentation'), (',', 'segmentation', 'biological'), ('segmentation', 'biological', 'images54'), ('biological', 'images54', 'particularly'), ('images54', 'particularly', 'connectomics55'), ('particularly', 'connectomics55', ','), ('connectomics55', ',', 'detection'), (',', 'detection', 'faces'), ('detection', 'faces', ','), ('faces', ',', 'text'), (',', 'text', ','), ('text', ',', 'pedestrians'), (',', 'pedestrians', 'human'), ('pedestrians', 'human', 'bodies'), ('human', 'bodies', 'natural'), ('bodies', 'natural', 'images36,50,51,56–58'), ('natural', 'images36,50,51,56–58', '.')]

>> POS Tags are: 
 [('These', 'DT'), ('tasks', 'NNS'), ('labelled', 'VBD'), ('data', 'NNS'), ('relatively', 'RB'), ('abun-', 'JJ'), ('dant', 'NN'), (',', ','), ('traffic', 'NN'), ('sign', 'NN'), ('recognition53', 'NN'), (',', ','), ('segmentation', 'NN'), ('biological', 'JJ'), ('images54', 'NN'), ('particularly', 'RB'), ('connectomics55', 'NN'), (',', ','), ('detection', 'NN'), ('faces', 'VBZ'), (',', ','), ('text', 'NN'), (',', ','), ('pedestrians', 'VBZ'), ('human', 'JJ'), ('bodies', 'NNS'), ('natural', 'JJ'), ('images36,50,51,56–58', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['These tasks', 'data', 'abun- dant', 'traffic sign recognition53', 'segmentation', 'biological images54', 'connectomics55', 'detection', 'text', 'human bodies', 'natural images36,50,51,56–58']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('These', 'these'), ('tasks', 'task'), ('labelled', 'label'), ('data', 'data'), ('relatively', 'rel'), ('abun-', 'abun-'), ('dant', 'dant'), (',', ','), ('traffic', 'traffic'), ('sign', 'sign'), ('recognition53', 'recognition53'), (',', ','), ('segmentation', 'segment'), ('biological', 'biolog'), ('images54', 'images54'), ('particularly', 'particularli'), ('connectomics55', 'connectomics55'), (',', ','), ('detection', 'detect'), ('faces', 'face'), (',', ','), ('text', 'text'), (',', ','), ('pedestrians', 'pedestrian'), ('human', 'human'), ('bodies', 'bodi'), ('natural', 'natur'), ('images36,50,51,56–58', 'images36,50,51,56–58'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('These', 'these'), ('tasks', 'task'), ('labelled', 'label'), ('data', 'data'), ('relatively', 'relat'), ('abun-', 'abun-'), ('dant', 'dant'), (',', ','), ('traffic', 'traffic'), ('sign', 'sign'), ('recognition53', 'recognition53'), (',', ','), ('segmentation', 'segment'), ('biological', 'biolog'), ('images54', 'images54'), ('particularly', 'particular'), ('connectomics55', 'connectomics55'), (',', ','), ('detection', 'detect'), ('faces', 'face'), (',', ','), ('text', 'text'), (',', ','), ('pedestrians', 'pedestrian'), ('human', 'human'), ('bodies', 'bodi'), ('natural', 'natur'), ('images36,50,51,56–58', 'images36,50,51,56–58'), ('.', '.')]

>> Lemmatization: 
 [('These', 'These'), ('tasks', 'task'), ('labelled', 'labelled'), ('data', 'data'), ('relatively', 'relatively'), ('abun-', 'abun-'), ('dant', 'dant'), (',', ','), ('traffic', 'traffic'), ('sign', 'sign'), ('recognition53', 'recognition53'), (',', ','), ('segmentation', 'segmentation'), ('biological', 'biological'), ('images54', 'images54'), ('particularly', 'particularly'), ('connectomics55', 'connectomics55'), (',', ','), ('detection', 'detection'), ('faces', 'face'), (',', ','), ('text', 'text'), (',', ','), ('pedestrians', 'pedestrian'), ('human', 'human'), ('bodies', 'body'), ('natural', 'natural'), ('images36,50,51,56–58', 'images36,50,51,56–58'), ('.', '.')]


------------------- Sentence 3 -------------------

A major  recent practical success of ConvNets is face recognition59.

>> Tokens are: 
 ['A', 'major', 'recent', 'practical', 'success', 'ConvNets', 'face', 'recognition59', '.']

>> Bigrams are: 
 [('A', 'major'), ('major', 'recent'), ('recent', 'practical'), ('practical', 'success'), ('success', 'ConvNets'), ('ConvNets', 'face'), ('face', 'recognition59'), ('recognition59', '.')]

>> Trigrams are: 
 [('A', 'major', 'recent'), ('major', 'recent', 'practical'), ('recent', 'practical', 'success'), ('practical', 'success', 'ConvNets'), ('success', 'ConvNets', 'face'), ('ConvNets', 'face', 'recognition59'), ('face', 'recognition59', '.')]

>> POS Tags are: 
 [('A', 'DT'), ('major', 'JJ'), ('recent', 'JJ'), ('practical', 'JJ'), ('success', 'NN'), ('ConvNets', 'NNP'), ('face', 'NN'), ('recognition59', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['A major recent practical success ConvNets face recognition59']

>> Named Entities are: 
 [('ORGANIZATION', 'ConvNets')] 

>> Stemming using Porter Stemmer: 
 [('A', 'a'), ('major', 'major'), ('recent', 'recent'), ('practical', 'practic'), ('success', 'success'), ('ConvNets', 'convnet'), ('face', 'face'), ('recognition59', 'recognition59'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('A', 'a'), ('major', 'major'), ('recent', 'recent'), ('practical', 'practic'), ('success', 'success'), ('ConvNets', 'convnet'), ('face', 'face'), ('recognition59', 'recognition59'), ('.', '.')]

>> Lemmatization: 
 [('A', 'A'), ('major', 'major'), ('recent', 'recent'), ('practical', 'practical'), ('success', 'success'), ('ConvNets', 'ConvNets'), ('face', 'face'), ('recognition59', 'recognition59'), ('.', '.')]



========================================== PARAGRAPH 125 ===========================================

Importantly, images can be labelled at the pixel level, which will have  applications in technology, including autonomous mobile robots and  

------------------- Sentence 1 -------------------

Importantly, images can be labelled at the pixel level, which will have  applications in technology, including autonomous mobile robots and

>> Tokens are: 
 ['Importantly', ',', 'images', 'labelled', 'pixel', 'level', ',', 'applications', 'technology', ',', 'including', 'autonomous', 'mobile', 'robots']

>> Bigrams are: 
 [('Importantly', ','), (',', 'images'), ('images', 'labelled'), ('labelled', 'pixel'), ('pixel', 'level'), ('level', ','), (',', 'applications'), ('applications', 'technology'), ('technology', ','), (',', 'including'), ('including', 'autonomous'), ('autonomous', 'mobile'), ('mobile', 'robots')]

>> Trigrams are: 
 [('Importantly', ',', 'images'), (',', 'images', 'labelled'), ('images', 'labelled', 'pixel'), ('labelled', 'pixel', 'level'), ('pixel', 'level', ','), ('level', ',', 'applications'), (',', 'applications', 'technology'), ('applications', 'technology', ','), ('technology', ',', 'including'), (',', 'including', 'autonomous'), ('including', 'autonomous', 'mobile'), ('autonomous', 'mobile', 'robots')]

>> POS Tags are: 
 [('Importantly', 'RB'), (',', ','), ('images', 'NNS'), ('labelled', 'VBD'), ('pixel', 'JJ'), ('level', 'NN'), (',', ','), ('applications', 'NNS'), ('technology', 'NN'), (',', ','), ('including', 'VBG'), ('autonomous', 'JJ'), ('mobile', 'JJ'), ('robots', 'NNS')]

>> Noun Phrases are: 
 ['images', 'pixel level', 'applications technology', 'autonomous mobile robots']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Importantly', 'importantli'), (',', ','), ('images', 'imag'), ('labelled', 'label'), ('pixel', 'pixel'), ('level', 'level'), (',', ','), ('applications', 'applic'), ('technology', 'technolog'), (',', ','), ('including', 'includ'), ('autonomous', 'autonom'), ('mobile', 'mobil'), ('robots', 'robot')]

>> Stemming using Snowball Stemmer: 
 [('Importantly', 'import'), (',', ','), ('images', 'imag'), ('labelled', 'label'), ('pixel', 'pixel'), ('level', 'level'), (',', ','), ('applications', 'applic'), ('technology', 'technolog'), (',', ','), ('including', 'includ'), ('autonomous', 'autonom'), ('mobile', 'mobil'), ('robots', 'robot')]

>> Lemmatization: 
 [('Importantly', 'Importantly'), (',', ','), ('images', 'image'), ('labelled', 'labelled'), ('pixel', 'pixel'), ('level', 'level'), (',', ','), ('applications', 'application'), ('technology', 'technology'), (',', ','), ('including', 'including'), ('autonomous', 'autonomous'), ('mobile', 'mobile'), ('robots', 'robot')]



========================================== PARAGRAPH 126 ===========================================

2 8  M A Y  2 0 1 5  |  V O L  5 2 1  |  N A T U R E  |  4 3 9 

------------------- Sentence 1 -------------------

2 8  M A Y  2 0 1 5  |  V O L  5 2 1  |  N A T U R E  |  4 3 9

>> Tokens are: 
 ['2', '8', 'M', 'A', 'Y', '2', '0', '1', '5', '|', 'V', 'O', 'L', '5', '2', '1', '|', 'N', 'A', 'T', 'U', 'R', 'E', '|', '4', '3', '9']

>> Bigrams are: 
 [('2', '8'), ('8', 'M'), ('M', 'A'), ('A', 'Y'), ('Y', '2'), ('2', '0'), ('0', '1'), ('1', '5'), ('5', '|'), ('|', 'V'), ('V', 'O'), ('O', 'L'), ('L', '5'), ('5', '2'), ('2', '1'), ('1', '|'), ('|', 'N'), ('N', 'A'), ('A', 'T'), ('T', 'U'), ('U', 'R'), ('R', 'E'), ('E', '|'), ('|', '4'), ('4', '3'), ('3', '9')]

>> Trigrams are: 
 [('2', '8', 'M'), ('8', 'M', 'A'), ('M', 'A', 'Y'), ('A', 'Y', '2'), ('Y', '2', '0'), ('2', '0', '1'), ('0', '1', '5'), ('1', '5', '|'), ('5', '|', 'V'), ('|', 'V', 'O'), ('V', 'O', 'L'), ('O', 'L', '5'), ('L', '5', '2'), ('5', '2', '1'), ('2', '1', '|'), ('1', '|', 'N'), ('|', 'N', 'A'), ('N', 'A', 'T'), ('A', 'T', 'U'), ('T', 'U', 'R'), ('U', 'R', 'E'), ('R', 'E', '|'), ('E', '|', '4'), ('|', '4', '3'), ('4', '3', '9')]

>> POS Tags are: 
 [('2', 'CD'), ('8', 'CD'), ('M', 'NNP'), ('A', 'NNP'), ('Y', 'NNP'), ('2', 'CD'), ('0', 'CD'), ('1', 'CD'), ('5', 'CD'), ('|', 'NN'), ('V', 'NNP'), ('O', 'NNP'), ('L', 'NNP'), ('5', 'CD'), ('2', 'CD'), ('1', 'CD'), ('|', 'NN'), ('N', 'NNP'), ('A', 'NNP'), ('T', 'NNP'), ('U', 'NNP'), ('R', 'NNP'), ('E', 'NNP'), ('|', 'VBD'), ('4', 'CD'), ('3', 'CD'), ('9', 'CD')]

>> Noun Phrases are: 
 ['M A Y', '| V O L', '| N A T U R E']

>> Named Entities are: 
 [('PERSON', 'V O')] 

>> Stemming using Porter Stemmer: 
 [('2', '2'), ('8', '8'), ('M', 'm'), ('A', 'a'), ('Y', 'y'), ('2', '2'), ('0', '0'), ('1', '1'), ('5', '5'), ('|', '|'), ('V', 'v'), ('O', 'o'), ('L', 'l'), ('5', '5'), ('2', '2'), ('1', '1'), ('|', '|'), ('N', 'n'), ('A', 'a'), ('T', 't'), ('U', 'u'), ('R', 'r'), ('E', 'e'), ('|', '|'), ('4', '4'), ('3', '3'), ('9', '9')]

>> Stemming using Snowball Stemmer: 
 [('2', '2'), ('8', '8'), ('M', 'm'), ('A', 'a'), ('Y', 'y'), ('2', '2'), ('0', '0'), ('1', '1'), ('5', '5'), ('|', '|'), ('V', 'v'), ('O', 'o'), ('L', 'l'), ('5', '5'), ('2', '2'), ('1', '1'), ('|', '|'), ('N', 'n'), ('A', 'a'), ('T', 't'), ('U', 'u'), ('R', 'r'), ('E', 'e'), ('|', '|'), ('4', '4'), ('3', '3'), ('9', '9')]

>> Lemmatization: 
 [('2', '2'), ('8', '8'), ('M', 'M'), ('A', 'A'), ('Y', 'Y'), ('2', '2'), ('0', '0'), ('1', '1'), ('5', '5'), ('|', '|'), ('V', 'V'), ('O', 'O'), ('L', 'L'), ('5', '5'), ('2', '2'), ('1', '1'), ('|', '|'), ('N', 'N'), ('A', 'A'), ('T', 'T'), ('U', 'U'), ('R', 'R'), ('E', 'E'), ('|', '|'), ('4', '4'), ('3', '3'), ('9', '9')]



========================================== PARAGRAPH 127 ===========================================

REVIEW INSIGHT 

------------------- Sentence 1 -------------------

REVIEW INSIGHT

>> Tokens are: 
 ['REVIEW', 'INSIGHT']

>> Bigrams are: 
 [('REVIEW', 'INSIGHT')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('REVIEW', 'NNP'), ('INSIGHT', 'NNP')]

>> Noun Phrases are: 
 ['REVIEW INSIGHT']

>> Named Entities are: 
 [('ORGANIZATION', 'REVIEW')] 

>> Stemming using Porter Stemmer: 
 [('REVIEW', 'review'), ('INSIGHT', 'insight')]

>> Stemming using Snowball Stemmer: 
 [('REVIEW', 'review'), ('INSIGHT', 'insight')]

>> Lemmatization: 
 [('REVIEW', 'REVIEW'), ('INSIGHT', 'INSIGHT')]



========================================== PARAGRAPH 128 ===========================================

© 2015 Macmillan Publishers Limited. All rights reserved

------------------- Sentence 1 -------------------

© 2015 Macmillan Publishers Limited.

>> Tokens are: 
 ['©', '2015', 'Macmillan', 'Publishers', 'Limited', '.']

>> Bigrams are: 
 [('©', '2015'), ('2015', 'Macmillan'), ('Macmillan', 'Publishers'), ('Publishers', 'Limited'), ('Limited', '.')]

>> Trigrams are: 
 [('©', '2015', 'Macmillan'), ('2015', 'Macmillan', 'Publishers'), ('Macmillan', 'Publishers', 'Limited'), ('Publishers', 'Limited', '.')]

>> POS Tags are: 
 [('©', 'NN'), ('2015', 'CD'), ('Macmillan', 'NNP'), ('Publishers', 'NNP'), ('Limited', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['©', 'Macmillan Publishers Limited']

>> Named Entities are: 
 [('PERSON', 'Macmillan Publishers Limited')] 

>> Stemming using Porter Stemmer: 
 [('©', '©'), ('2015', '2015'), ('Macmillan', 'macmillan'), ('Publishers', 'publish'), ('Limited', 'limit'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('©', '©'), ('2015', '2015'), ('Macmillan', 'macmillan'), ('Publishers', 'publish'), ('Limited', 'limit'), ('.', '.')]

>> Lemmatization: 
 [('©', '©'), ('2015', '2015'), ('Macmillan', 'Macmillan'), ('Publishers', 'Publishers'), ('Limited', 'Limited'), ('.', '.')]


------------------- Sentence 2 -------------------

All rights reserved

>> Tokens are: 
 ['All', 'rights', 'reserved']

>> Bigrams are: 
 [('All', 'rights'), ('rights', 'reserved')]

>> Trigrams are: 
 [('All', 'rights', 'reserved')]

>> POS Tags are: 
 [('All', 'DT'), ('rights', 'NNS'), ('reserved', 'VBN')]

>> Noun Phrases are: 
 ['All rights']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('All', 'all'), ('rights', 'right'), ('reserved', 'reserv')]

>> Stemming using Snowball Stemmer: 
 [('All', 'all'), ('rights', 'right'), ('reserved', 'reserv')]

>> Lemmatization: 
 [('All', 'All'), ('rights', 'right'), ('reserved', 'reserved')]



========================================== PARAGRAPH 129 ===========================================

self-driving cars60,61. Companies such as Mobileye and NVIDIA are  using such ConvNet-based methods in their upcoming vision sys- tems for cars. Other applications gaining importance involve natural  language understanding14 and speech recognition7.  

------------------- Sentence 1 -------------------

self-driving cars60,61.

>> Tokens are: 
 ['self-driving', 'cars60,61', '.']

>> Bigrams are: 
 [('self-driving', 'cars60,61'), ('cars60,61', '.')]

>> Trigrams are: 
 [('self-driving', 'cars60,61', '.')]

>> POS Tags are: 
 [('self-driving', 'JJ'), ('cars60,61', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['self-driving cars60,61']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('self-driving', 'self-driv'), ('cars60,61', 'cars60,61'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('self-driving', 'self-driv'), ('cars60,61', 'cars60,61'), ('.', '.')]

>> Lemmatization: 
 [('self-driving', 'self-driving'), ('cars60,61', 'cars60,61'), ('.', '.')]


------------------- Sentence 2 -------------------

Companies such as Mobileye and NVIDIA are  using such ConvNet-based methods in their upcoming vision sys- tems for cars.

>> Tokens are: 
 ['Companies', 'Mobileye', 'NVIDIA', 'using', 'ConvNet-based', 'methods', 'upcoming', 'vision', 'sys-', 'tems', 'cars', '.']

>> Bigrams are: 
 [('Companies', 'Mobileye'), ('Mobileye', 'NVIDIA'), ('NVIDIA', 'using'), ('using', 'ConvNet-based'), ('ConvNet-based', 'methods'), ('methods', 'upcoming'), ('upcoming', 'vision'), ('vision', 'sys-'), ('sys-', 'tems'), ('tems', 'cars'), ('cars', '.')]

>> Trigrams are: 
 [('Companies', 'Mobileye', 'NVIDIA'), ('Mobileye', 'NVIDIA', 'using'), ('NVIDIA', 'using', 'ConvNet-based'), ('using', 'ConvNet-based', 'methods'), ('ConvNet-based', 'methods', 'upcoming'), ('methods', 'upcoming', 'vision'), ('upcoming', 'vision', 'sys-'), ('vision', 'sys-', 'tems'), ('sys-', 'tems', 'cars'), ('tems', 'cars', '.')]

>> POS Tags are: 
 [('Companies', 'NNS'), ('Mobileye', 'NNP'), ('NVIDIA', 'NNP'), ('using', 'VBG'), ('ConvNet-based', 'JJ'), ('methods', 'NNS'), ('upcoming', 'VBG'), ('vision', 'NN'), ('sys-', 'JJ'), ('tems', 'NN'), ('cars', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['Companies Mobileye NVIDIA', 'ConvNet-based methods', 'vision', 'sys- tems cars']

>> Named Entities are: 
 [('PERSON', 'Mobileye NVIDIA')] 

>> Stemming using Porter Stemmer: 
 [('Companies', 'compani'), ('Mobileye', 'mobiley'), ('NVIDIA', 'nvidia'), ('using', 'use'), ('ConvNet-based', 'convnet-bas'), ('methods', 'method'), ('upcoming', 'upcom'), ('vision', 'vision'), ('sys-', 'sys-'), ('tems', 'tem'), ('cars', 'car'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Companies', 'compani'), ('Mobileye', 'mobiley'), ('NVIDIA', 'nvidia'), ('using', 'use'), ('ConvNet-based', 'convnet-bas'), ('methods', 'method'), ('upcoming', 'upcom'), ('vision', 'vision'), ('sys-', 'sys-'), ('tems', 'tem'), ('cars', 'car'), ('.', '.')]

>> Lemmatization: 
 [('Companies', 'Companies'), ('Mobileye', 'Mobileye'), ('NVIDIA', 'NVIDIA'), ('using', 'using'), ('ConvNet-based', 'ConvNet-based'), ('methods', 'method'), ('upcoming', 'upcoming'), ('vision', 'vision'), ('sys-', 'sys-'), ('tems', 'tems'), ('cars', 'car'), ('.', '.')]


------------------- Sentence 3 -------------------

Other applications gaining importance involve natural  language understanding14 and speech recognition7.

>> Tokens are: 
 ['Other', 'applications', 'gaining', 'importance', 'involve', 'natural', 'language', 'understanding14', 'speech', 'recognition7', '.']

>> Bigrams are: 
 [('Other', 'applications'), ('applications', 'gaining'), ('gaining', 'importance'), ('importance', 'involve'), ('involve', 'natural'), ('natural', 'language'), ('language', 'understanding14'), ('understanding14', 'speech'), ('speech', 'recognition7'), ('recognition7', '.')]

>> Trigrams are: 
 [('Other', 'applications', 'gaining'), ('applications', 'gaining', 'importance'), ('gaining', 'importance', 'involve'), ('importance', 'involve', 'natural'), ('involve', 'natural', 'language'), ('natural', 'language', 'understanding14'), ('language', 'understanding14', 'speech'), ('understanding14', 'speech', 'recognition7'), ('speech', 'recognition7', '.')]

>> POS Tags are: 
 [('Other', 'JJ'), ('applications', 'NNS'), ('gaining', 'VBG'), ('importance', 'NN'), ('involve', 'VB'), ('natural', 'JJ'), ('language', 'NN'), ('understanding14', 'JJ'), ('speech', 'NN'), ('recognition7', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Other applications', 'importance', 'natural language', 'understanding14 speech recognition7']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Other', 'other'), ('applications', 'applic'), ('gaining', 'gain'), ('importance', 'import'), ('involve', 'involv'), ('natural', 'natur'), ('language', 'languag'), ('understanding14', 'understanding14'), ('speech', 'speech'), ('recognition7', 'recognition7'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Other', 'other'), ('applications', 'applic'), ('gaining', 'gain'), ('importance', 'import'), ('involve', 'involv'), ('natural', 'natur'), ('language', 'languag'), ('understanding14', 'understanding14'), ('speech', 'speech'), ('recognition7', 'recognition7'), ('.', '.')]

>> Lemmatization: 
 [('Other', 'Other'), ('applications', 'application'), ('gaining', 'gaining'), ('importance', 'importance'), ('involve', 'involve'), ('natural', 'natural'), ('language', 'language'), ('understanding14', 'understanding14'), ('speech', 'speech'), ('recognition7', 'recognition7'), ('.', '.')]



========================================== PARAGRAPH 130 ===========================================

Despite these successes, ConvNets were largely forsaken by the  mainstream computer-vision and machine-learning communities  until the ImageNet competition in 2012. When deep convolutional  networks were applied to a data set of about a million images from  the web that contained 1,000 different classes, they achieved spec- tacular results, almost halving the error rates of the best compet- ing approaches1. This success came from the efficient use of GPUs,  ReLUs, a new regularization technique called dropout62, and tech- niques to generate more training examples by deforming the existing  ones. This success has brought about a revolution in computer vision;  ConvNets are now the dominant approach for almost all recognition  and detection tasks4,58,59,63–65 and approach human performance on  some tasks. A recent stunning demonstration combines ConvNets  and recurrent net modules for the generation of image captions  (Fig. 3).  

------------------- Sentence 1 -------------------

Despite these successes, ConvNets were largely forsaken by the  mainstream computer-vision and machine-learning communities  until the ImageNet competition in 2012.

>> Tokens are: 
 ['Despite', 'successes', ',', 'ConvNets', 'largely', 'forsaken', 'mainstream', 'computer-vision', 'machine-learning', 'communities', 'ImageNet', 'competition', '2012', '.']

>> Bigrams are: 
 [('Despite', 'successes'), ('successes', ','), (',', 'ConvNets'), ('ConvNets', 'largely'), ('largely', 'forsaken'), ('forsaken', 'mainstream'), ('mainstream', 'computer-vision'), ('computer-vision', 'machine-learning'), ('machine-learning', 'communities'), ('communities', 'ImageNet'), ('ImageNet', 'competition'), ('competition', '2012'), ('2012', '.')]

>> Trigrams are: 
 [('Despite', 'successes', ','), ('successes', ',', 'ConvNets'), (',', 'ConvNets', 'largely'), ('ConvNets', 'largely', 'forsaken'), ('largely', 'forsaken', 'mainstream'), ('forsaken', 'mainstream', 'computer-vision'), ('mainstream', 'computer-vision', 'machine-learning'), ('computer-vision', 'machine-learning', 'communities'), ('machine-learning', 'communities', 'ImageNet'), ('communities', 'ImageNet', 'competition'), ('ImageNet', 'competition', '2012'), ('competition', '2012', '.')]

>> POS Tags are: 
 [('Despite', 'IN'), ('successes', 'NNS'), (',', ','), ('ConvNets', 'NNP'), ('largely', 'RB'), ('forsaken', 'JJ'), ('mainstream', 'JJ'), ('computer-vision', 'NN'), ('machine-learning', 'JJ'), ('communities', 'NNS'), ('ImageNet', 'NNP'), ('competition', 'NN'), ('2012', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['successes', 'ConvNets', 'forsaken mainstream computer-vision', 'machine-learning communities ImageNet competition']

>> Named Entities are: 
 [('ORGANIZATION', 'ConvNets'), ('ORGANIZATION', 'ImageNet')] 

>> Stemming using Porter Stemmer: 
 [('Despite', 'despit'), ('successes', 'success'), (',', ','), ('ConvNets', 'convnet'), ('largely', 'larg'), ('forsaken', 'forsaken'), ('mainstream', 'mainstream'), ('computer-vision', 'computer-vis'), ('machine-learning', 'machine-learn'), ('communities', 'commun'), ('ImageNet', 'imagenet'), ('competition', 'competit'), ('2012', '2012'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Despite', 'despit'), ('successes', 'success'), (',', ','), ('ConvNets', 'convnet'), ('largely', 'larg'), ('forsaken', 'forsaken'), ('mainstream', 'mainstream'), ('computer-vision', 'computer-vis'), ('machine-learning', 'machine-learn'), ('communities', 'communiti'), ('ImageNet', 'imagenet'), ('competition', 'competit'), ('2012', '2012'), ('.', '.')]

>> Lemmatization: 
 [('Despite', 'Despite'), ('successes', 'success'), (',', ','), ('ConvNets', 'ConvNets'), ('largely', 'largely'), ('forsaken', 'forsaken'), ('mainstream', 'mainstream'), ('computer-vision', 'computer-vision'), ('machine-learning', 'machine-learning'), ('communities', 'community'), ('ImageNet', 'ImageNet'), ('competition', 'competition'), ('2012', '2012'), ('.', '.')]


------------------- Sentence 2 -------------------

When deep convolutional  networks were applied to a data set of about a million images from  the web that contained 1,000 different classes, they achieved spec- tacular results, almost halving the error rates of the best compet- ing approaches1.

>> Tokens are: 
 ['When', 'deep', 'convolutional', 'networks', 'applied', 'data', 'set', 'million', 'images', 'web', 'contained', '1,000', 'different', 'classes', ',', 'achieved', 'spec-', 'tacular', 'results', ',', 'almost', 'halving', 'error', 'rates', 'best', 'compet-', 'ing', 'approaches1', '.']

>> Bigrams are: 
 [('When', 'deep'), ('deep', 'convolutional'), ('convolutional', 'networks'), ('networks', 'applied'), ('applied', 'data'), ('data', 'set'), ('set', 'million'), ('million', 'images'), ('images', 'web'), ('web', 'contained'), ('contained', '1,000'), ('1,000', 'different'), ('different', 'classes'), ('classes', ','), (',', 'achieved'), ('achieved', 'spec-'), ('spec-', 'tacular'), ('tacular', 'results'), ('results', ','), (',', 'almost'), ('almost', 'halving'), ('halving', 'error'), ('error', 'rates'), ('rates', 'best'), ('best', 'compet-'), ('compet-', 'ing'), ('ing', 'approaches1'), ('approaches1', '.')]

>> Trigrams are: 
 [('When', 'deep', 'convolutional'), ('deep', 'convolutional', 'networks'), ('convolutional', 'networks', 'applied'), ('networks', 'applied', 'data'), ('applied', 'data', 'set'), ('data', 'set', 'million'), ('set', 'million', 'images'), ('million', 'images', 'web'), ('images', 'web', 'contained'), ('web', 'contained', '1,000'), ('contained', '1,000', 'different'), ('1,000', 'different', 'classes'), ('different', 'classes', ','), ('classes', ',', 'achieved'), (',', 'achieved', 'spec-'), ('achieved', 'spec-', 'tacular'), ('spec-', 'tacular', 'results'), ('tacular', 'results', ','), ('results', ',', 'almost'), (',', 'almost', 'halving'), ('almost', 'halving', 'error'), ('halving', 'error', 'rates'), ('error', 'rates', 'best'), ('rates', 'best', 'compet-'), ('best', 'compet-', 'ing'), ('compet-', 'ing', 'approaches1'), ('ing', 'approaches1', '.')]

>> POS Tags are: 
 [('When', 'WRB'), ('deep', 'JJ'), ('convolutional', 'JJ'), ('networks', 'NNS'), ('applied', 'VBN'), ('data', 'NNS'), ('set', 'VBN'), ('million', 'CD'), ('images', 'NNS'), ('web', 'VBP'), ('contained', 'VBN'), ('1,000', 'CD'), ('different', 'JJ'), ('classes', 'NNS'), (',', ','), ('achieved', 'VBD'), ('spec-', 'JJ'), ('tacular', 'JJ'), ('results', 'NNS'), (',', ','), ('almost', 'RB'), ('halving', 'VBG'), ('error', 'NN'), ('rates', 'NNS'), ('best', 'RB'), ('compet-', 'JJ'), ('ing', 'NN'), ('approaches1', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['deep convolutional networks', 'data', 'images', 'different classes', 'spec- tacular results', 'error rates', 'compet- ing approaches1']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('When', 'when'), ('deep', 'deep'), ('convolutional', 'convolut'), ('networks', 'network'), ('applied', 'appli'), ('data', 'data'), ('set', 'set'), ('million', 'million'), ('images', 'imag'), ('web', 'web'), ('contained', 'contain'), ('1,000', '1,000'), ('different', 'differ'), ('classes', 'class'), (',', ','), ('achieved', 'achiev'), ('spec-', 'spec-'), ('tacular', 'tacular'), ('results', 'result'), (',', ','), ('almost', 'almost'), ('halving', 'halv'), ('error', 'error'), ('rates', 'rate'), ('best', 'best'), ('compet-', 'compet-'), ('ing', 'ing'), ('approaches1', 'approaches1'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('When', 'when'), ('deep', 'deep'), ('convolutional', 'convolut'), ('networks', 'network'), ('applied', 'appli'), ('data', 'data'), ('set', 'set'), ('million', 'million'), ('images', 'imag'), ('web', 'web'), ('contained', 'contain'), ('1,000', '1,000'), ('different', 'differ'), ('classes', 'class'), (',', ','), ('achieved', 'achiev'), ('spec-', 'spec-'), ('tacular', 'tacular'), ('results', 'result'), (',', ','), ('almost', 'almost'), ('halving', 'halv'), ('error', 'error'), ('rates', 'rate'), ('best', 'best'), ('compet-', 'compet-'), ('ing', 'ing'), ('approaches1', 'approaches1'), ('.', '.')]

>> Lemmatization: 
 [('When', 'When'), ('deep', 'deep'), ('convolutional', 'convolutional'), ('networks', 'network'), ('applied', 'applied'), ('data', 'data'), ('set', 'set'), ('million', 'million'), ('images', 'image'), ('web', 'web'), ('contained', 'contained'), ('1,000', '1,000'), ('different', 'different'), ('classes', 'class'), (',', ','), ('achieved', 'achieved'), ('spec-', 'spec-'), ('tacular', 'tacular'), ('results', 'result'), (',', ','), ('almost', 'almost'), ('halving', 'halving'), ('error', 'error'), ('rates', 'rate'), ('best', 'best'), ('compet-', 'compet-'), ('ing', 'ing'), ('approaches1', 'approaches1'), ('.', '.')]


------------------- Sentence 3 -------------------

This success came from the efficient use of GPUs,  ReLUs, a new regularization technique called dropout62, and tech- niques to generate more training examples by deforming the existing  ones.

>> Tokens are: 
 ['This', 'success', 'came', 'efficient', 'use', 'GPUs', ',', 'ReLUs', ',', 'new', 'regularization', 'technique', 'called', 'dropout62', ',', 'tech-', 'niques', 'generate', 'training', 'examples', 'deforming', 'existing', 'ones', '.']

>> Bigrams are: 
 [('This', 'success'), ('success', 'came'), ('came', 'efficient'), ('efficient', 'use'), ('use', 'GPUs'), ('GPUs', ','), (',', 'ReLUs'), ('ReLUs', ','), (',', 'new'), ('new', 'regularization'), ('regularization', 'technique'), ('technique', 'called'), ('called', 'dropout62'), ('dropout62', ','), (',', 'tech-'), ('tech-', 'niques'), ('niques', 'generate'), ('generate', 'training'), ('training', 'examples'), ('examples', 'deforming'), ('deforming', 'existing'), ('existing', 'ones'), ('ones', '.')]

>> Trigrams are: 
 [('This', 'success', 'came'), ('success', 'came', 'efficient'), ('came', 'efficient', 'use'), ('efficient', 'use', 'GPUs'), ('use', 'GPUs', ','), ('GPUs', ',', 'ReLUs'), (',', 'ReLUs', ','), ('ReLUs', ',', 'new'), (',', 'new', 'regularization'), ('new', 'regularization', 'technique'), ('regularization', 'technique', 'called'), ('technique', 'called', 'dropout62'), ('called', 'dropout62', ','), ('dropout62', ',', 'tech-'), (',', 'tech-', 'niques'), ('tech-', 'niques', 'generate'), ('niques', 'generate', 'training'), ('generate', 'training', 'examples'), ('training', 'examples', 'deforming'), ('examples', 'deforming', 'existing'), ('deforming', 'existing', 'ones'), ('existing', 'ones', '.')]

>> POS Tags are: 
 [('This', 'DT'), ('success', 'NN'), ('came', 'VBD'), ('efficient', 'JJ'), ('use', 'NN'), ('GPUs', 'NNP'), (',', ','), ('ReLUs', 'NNP'), (',', ','), ('new', 'JJ'), ('regularization', 'NN'), ('technique', 'NN'), ('called', 'VBN'), ('dropout62', 'NN'), (',', ','), ('tech-', 'JJ'), ('niques', 'NNS'), ('generate', 'VBP'), ('training', 'NN'), ('examples', 'NNS'), ('deforming', 'VBG'), ('existing', 'VBG'), ('ones', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['This success', 'efficient use GPUs', 'ReLUs', 'new regularization technique', 'dropout62', 'tech- niques', 'training examples', 'ones']

>> Named Entities are: 
 [('ORGANIZATION', 'GPUs'), ('ORGANIZATION', 'ReLUs')] 

>> Stemming using Porter Stemmer: 
 [('This', 'thi'), ('success', 'success'), ('came', 'came'), ('efficient', 'effici'), ('use', 'use'), ('GPUs', 'gpu'), (',', ','), ('ReLUs', 'relu'), (',', ','), ('new', 'new'), ('regularization', 'regular'), ('technique', 'techniqu'), ('called', 'call'), ('dropout62', 'dropout62'), (',', ','), ('tech-', 'tech-'), ('niques', 'niqu'), ('generate', 'gener'), ('training', 'train'), ('examples', 'exampl'), ('deforming', 'deform'), ('existing', 'exist'), ('ones', 'one'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('This', 'this'), ('success', 'success'), ('came', 'came'), ('efficient', 'effici'), ('use', 'use'), ('GPUs', 'gpus'), (',', ','), ('ReLUs', 'relus'), (',', ','), ('new', 'new'), ('regularization', 'regular'), ('technique', 'techniqu'), ('called', 'call'), ('dropout62', 'dropout62'), (',', ','), ('tech-', 'tech-'), ('niques', 'niqu'), ('generate', 'generat'), ('training', 'train'), ('examples', 'exampl'), ('deforming', 'deform'), ('existing', 'exist'), ('ones', 'one'), ('.', '.')]

>> Lemmatization: 
 [('This', 'This'), ('success', 'success'), ('came', 'came'), ('efficient', 'efficient'), ('use', 'use'), ('GPUs', 'GPUs'), (',', ','), ('ReLUs', 'ReLUs'), (',', ','), ('new', 'new'), ('regularization', 'regularization'), ('technique', 'technique'), ('called', 'called'), ('dropout62', 'dropout62'), (',', ','), ('tech-', 'tech-'), ('niques', 'niques'), ('generate', 'generate'), ('training', 'training'), ('examples', 'example'), ('deforming', 'deforming'), ('existing', 'existing'), ('ones', 'one'), ('.', '.')]


------------------- Sentence 4 -------------------

This success has brought about a revolution in computer vision;  ConvNets are now the dominant approach for almost all recognition  and detection tasks4,58,59,63–65 and approach human performance on  some tasks.

>> Tokens are: 
 ['This', 'success', 'brought', 'revolution', 'computer', 'vision', ';', 'ConvNets', 'dominant', 'approach', 'almost', 'recognition', 'detection', 'tasks4,58,59,63–65', 'approach', 'human', 'performance', 'tasks', '.']

>> Bigrams are: 
 [('This', 'success'), ('success', 'brought'), ('brought', 'revolution'), ('revolution', 'computer'), ('computer', 'vision'), ('vision', ';'), (';', 'ConvNets'), ('ConvNets', 'dominant'), ('dominant', 'approach'), ('approach', 'almost'), ('almost', 'recognition'), ('recognition', 'detection'), ('detection', 'tasks4,58,59,63–65'), ('tasks4,58,59,63–65', 'approach'), ('approach', 'human'), ('human', 'performance'), ('performance', 'tasks'), ('tasks', '.')]

>> Trigrams are: 
 [('This', 'success', 'brought'), ('success', 'brought', 'revolution'), ('brought', 'revolution', 'computer'), ('revolution', 'computer', 'vision'), ('computer', 'vision', ';'), ('vision', ';', 'ConvNets'), (';', 'ConvNets', 'dominant'), ('ConvNets', 'dominant', 'approach'), ('dominant', 'approach', 'almost'), ('approach', 'almost', 'recognition'), ('almost', 'recognition', 'detection'), ('recognition', 'detection', 'tasks4,58,59,63–65'), ('detection', 'tasks4,58,59,63–65', 'approach'), ('tasks4,58,59,63–65', 'approach', 'human'), ('approach', 'human', 'performance'), ('human', 'performance', 'tasks'), ('performance', 'tasks', '.')]

>> POS Tags are: 
 [('This', 'DT'), ('success', 'NN'), ('brought', 'VBD'), ('revolution', 'NN'), ('computer', 'NN'), ('vision', 'NN'), (';', ':'), ('ConvNets', 'NNP'), ('dominant', 'VBP'), ('approach', 'NN'), ('almost', 'RB'), ('recognition', 'NN'), ('detection', 'NN'), ('tasks4,58,59,63–65', 'IN'), ('approach', 'NN'), ('human', 'JJ'), ('performance', 'NN'), ('tasks', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['This success', 'revolution computer vision', 'ConvNets', 'approach', 'recognition detection', 'approach', 'human performance tasks']

>> Named Entities are: 
 [('ORGANIZATION', 'ConvNets')] 

>> Stemming using Porter Stemmer: 
 [('This', 'thi'), ('success', 'success'), ('brought', 'brought'), ('revolution', 'revolut'), ('computer', 'comput'), ('vision', 'vision'), (';', ';'), ('ConvNets', 'convnet'), ('dominant', 'domin'), ('approach', 'approach'), ('almost', 'almost'), ('recognition', 'recognit'), ('detection', 'detect'), ('tasks4,58,59,63–65', 'tasks4,58,59,63–65'), ('approach', 'approach'), ('human', 'human'), ('performance', 'perform'), ('tasks', 'task'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('This', 'this'), ('success', 'success'), ('brought', 'brought'), ('revolution', 'revolut'), ('computer', 'comput'), ('vision', 'vision'), (';', ';'), ('ConvNets', 'convnet'), ('dominant', 'domin'), ('approach', 'approach'), ('almost', 'almost'), ('recognition', 'recognit'), ('detection', 'detect'), ('tasks4,58,59,63–65', 'tasks4,58,59,63–65'), ('approach', 'approach'), ('human', 'human'), ('performance', 'perform'), ('tasks', 'task'), ('.', '.')]

>> Lemmatization: 
 [('This', 'This'), ('success', 'success'), ('brought', 'brought'), ('revolution', 'revolution'), ('computer', 'computer'), ('vision', 'vision'), (';', ';'), ('ConvNets', 'ConvNets'), ('dominant', 'dominant'), ('approach', 'approach'), ('almost', 'almost'), ('recognition', 'recognition'), ('detection', 'detection'), ('tasks4,58,59,63–65', 'tasks4,58,59,63–65'), ('approach', 'approach'), ('human', 'human'), ('performance', 'performance'), ('tasks', 'task'), ('.', '.')]


------------------- Sentence 5 -------------------

A recent stunning demonstration combines ConvNets  and recurrent net modules for the generation of image captions  (Fig.

>> Tokens are: 
 ['A', 'recent', 'stunning', 'demonstration', 'combines', 'ConvNets', 'recurrent', 'net', 'modules', 'generation', 'image', 'captions', '(', 'Fig', '.']

>> Bigrams are: 
 [('A', 'recent'), ('recent', 'stunning'), ('stunning', 'demonstration'), ('demonstration', 'combines'), ('combines', 'ConvNets'), ('ConvNets', 'recurrent'), ('recurrent', 'net'), ('net', 'modules'), ('modules', 'generation'), ('generation', 'image'), ('image', 'captions'), ('captions', '('), ('(', 'Fig'), ('Fig', '.')]

>> Trigrams are: 
 [('A', 'recent', 'stunning'), ('recent', 'stunning', 'demonstration'), ('stunning', 'demonstration', 'combines'), ('demonstration', 'combines', 'ConvNets'), ('combines', 'ConvNets', 'recurrent'), ('ConvNets', 'recurrent', 'net'), ('recurrent', 'net', 'modules'), ('net', 'modules', 'generation'), ('modules', 'generation', 'image'), ('generation', 'image', 'captions'), ('image', 'captions', '('), ('captions', '(', 'Fig'), ('(', 'Fig', '.')]

>> POS Tags are: 
 [('A', 'DT'), ('recent', 'JJ'), ('stunning', 'JJ'), ('demonstration', 'NN'), ('combines', 'NNS'), ('ConvNets', 'NNP'), ('recurrent', 'JJ'), ('net', 'JJ'), ('modules', 'NNS'), ('generation', 'NN'), ('image', 'NN'), ('captions', 'NNS'), ('(', '('), ('Fig', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['A recent stunning demonstration combines ConvNets', 'recurrent net modules generation image captions', 'Fig']

>> Named Entities are: 
 [('ORGANIZATION', 'ConvNets'), ('ORGANIZATION', 'Fig')] 

>> Stemming using Porter Stemmer: 
 [('A', 'a'), ('recent', 'recent'), ('stunning', 'stun'), ('demonstration', 'demonstr'), ('combines', 'combin'), ('ConvNets', 'convnet'), ('recurrent', 'recurr'), ('net', 'net'), ('modules', 'modul'), ('generation', 'gener'), ('image', 'imag'), ('captions', 'caption'), ('(', '('), ('Fig', 'fig'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('A', 'a'), ('recent', 'recent'), ('stunning', 'stun'), ('demonstration', 'demonstr'), ('combines', 'combin'), ('ConvNets', 'convnet'), ('recurrent', 'recurr'), ('net', 'net'), ('modules', 'modul'), ('generation', 'generat'), ('image', 'imag'), ('captions', 'caption'), ('(', '('), ('Fig', 'fig'), ('.', '.')]

>> Lemmatization: 
 [('A', 'A'), ('recent', 'recent'), ('stunning', 'stunning'), ('demonstration', 'demonstration'), ('combines', 'combine'), ('ConvNets', 'ConvNets'), ('recurrent', 'recurrent'), ('net', 'net'), ('modules', 'module'), ('generation', 'generation'), ('image', 'image'), ('captions', 'caption'), ('(', '('), ('Fig', 'Fig'), ('.', '.')]


------------------- Sentence 6 -------------------

3).

>> Tokens are: 
 ['3', ')', '.']

>> Bigrams are: 
 [('3', ')'), (')', '.')]

>> Trigrams are: 
 [('3', ')', '.')]

>> POS Tags are: 
 [('3', 'LS'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('3', '3'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('3', '3'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('3', '3'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 131 ===========================================

Recent ConvNet architectures have 10 to 20 layers of ReLUs, hun- dreds of millions of weights, and billions of connections between  units. Whereas training such large networks could have taken weeks  only two years ago, progress in hardware, software and algorithm  parallelization have reduced training times to a few hours.  

------------------- Sentence 1 -------------------

Recent ConvNet architectures have 10 to 20 layers of ReLUs, hun- dreds of millions of weights, and billions of connections between  units.

>> Tokens are: 
 ['Recent', 'ConvNet', 'architectures', '10', '20', 'layers', 'ReLUs', ',', 'hun-', 'dreds', 'millions', 'weights', ',', 'billions', 'connections', 'units', '.']

>> Bigrams are: 
 [('Recent', 'ConvNet'), ('ConvNet', 'architectures'), ('architectures', '10'), ('10', '20'), ('20', 'layers'), ('layers', 'ReLUs'), ('ReLUs', ','), (',', 'hun-'), ('hun-', 'dreds'), ('dreds', 'millions'), ('millions', 'weights'), ('weights', ','), (',', 'billions'), ('billions', 'connections'), ('connections', 'units'), ('units', '.')]

>> Trigrams are: 
 [('Recent', 'ConvNet', 'architectures'), ('ConvNet', 'architectures', '10'), ('architectures', '10', '20'), ('10', '20', 'layers'), ('20', 'layers', 'ReLUs'), ('layers', 'ReLUs', ','), ('ReLUs', ',', 'hun-'), (',', 'hun-', 'dreds'), ('hun-', 'dreds', 'millions'), ('dreds', 'millions', 'weights'), ('millions', 'weights', ','), ('weights', ',', 'billions'), (',', 'billions', 'connections'), ('billions', 'connections', 'units'), ('connections', 'units', '.')]

>> POS Tags are: 
 [('Recent', 'JJ'), ('ConvNet', 'NNP'), ('architectures', 'VBZ'), ('10', 'CD'), ('20', 'CD'), ('layers', 'NNS'), ('ReLUs', 'NNP'), (',', ','), ('hun-', 'JJ'), ('dreds', 'NNS'), ('millions', 'NNS'), ('weights', 'NNS'), (',', ','), ('billions', 'NNS'), ('connections', 'NNS'), ('units', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['Recent ConvNet', 'layers ReLUs', 'hun- dreds millions weights', 'billions connections units']

>> Named Entities are: 
 [('ORGANIZATION', 'ConvNet'), ('ORGANIZATION', 'ReLUs')] 

>> Stemming using Porter Stemmer: 
 [('Recent', 'recent'), ('ConvNet', 'convnet'), ('architectures', 'architectur'), ('10', '10'), ('20', '20'), ('layers', 'layer'), ('ReLUs', 'relu'), (',', ','), ('hun-', 'hun-'), ('dreds', 'dred'), ('millions', 'million'), ('weights', 'weight'), (',', ','), ('billions', 'billion'), ('connections', 'connect'), ('units', 'unit'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Recent', 'recent'), ('ConvNet', 'convnet'), ('architectures', 'architectur'), ('10', '10'), ('20', '20'), ('layers', 'layer'), ('ReLUs', 'relus'), (',', ','), ('hun-', 'hun-'), ('dreds', 'dred'), ('millions', 'million'), ('weights', 'weight'), (',', ','), ('billions', 'billion'), ('connections', 'connect'), ('units', 'unit'), ('.', '.')]

>> Lemmatization: 
 [('Recent', 'Recent'), ('ConvNet', 'ConvNet'), ('architectures', 'architecture'), ('10', '10'), ('20', '20'), ('layers', 'layer'), ('ReLUs', 'ReLUs'), (',', ','), ('hun-', 'hun-'), ('dreds', 'dreds'), ('millions', 'million'), ('weights', 'weight'), (',', ','), ('billions', 'billion'), ('connections', 'connection'), ('units', 'unit'), ('.', '.')]


------------------- Sentence 2 -------------------

Whereas training such large networks could have taken weeks  only two years ago, progress in hardware, software and algorithm  parallelization have reduced training times to a few hours.

>> Tokens are: 
 ['Whereas', 'training', 'large', 'networks', 'could', 'taken', 'weeks', 'two', 'years', 'ago', ',', 'progress', 'hardware', ',', 'software', 'algorithm', 'parallelization', 'reduced', 'training', 'times', 'hours', '.']

>> Bigrams are: 
 [('Whereas', 'training'), ('training', 'large'), ('large', 'networks'), ('networks', 'could'), ('could', 'taken'), ('taken', 'weeks'), ('weeks', 'two'), ('two', 'years'), ('years', 'ago'), ('ago', ','), (',', 'progress'), ('progress', 'hardware'), ('hardware', ','), (',', 'software'), ('software', 'algorithm'), ('algorithm', 'parallelization'), ('parallelization', 'reduced'), ('reduced', 'training'), ('training', 'times'), ('times', 'hours'), ('hours', '.')]

>> Trigrams are: 
 [('Whereas', 'training', 'large'), ('training', 'large', 'networks'), ('large', 'networks', 'could'), ('networks', 'could', 'taken'), ('could', 'taken', 'weeks'), ('taken', 'weeks', 'two'), ('weeks', 'two', 'years'), ('two', 'years', 'ago'), ('years', 'ago', ','), ('ago', ',', 'progress'), (',', 'progress', 'hardware'), ('progress', 'hardware', ','), ('hardware', ',', 'software'), (',', 'software', 'algorithm'), ('software', 'algorithm', 'parallelization'), ('algorithm', 'parallelization', 'reduced'), ('parallelization', 'reduced', 'training'), ('reduced', 'training', 'times'), ('training', 'times', 'hours'), ('times', 'hours', '.')]

>> POS Tags are: 
 [('Whereas', 'IN'), ('training', 'VBG'), ('large', 'JJ'), ('networks', 'NNS'), ('could', 'MD'), ('taken', 'VBN'), ('weeks', 'NNS'), ('two', 'CD'), ('years', 'NNS'), ('ago', 'RB'), (',', ','), ('progress', 'NN'), ('hardware', 'NN'), (',', ','), ('software', 'NN'), ('algorithm', 'JJ'), ('parallelization', 'NN'), ('reduced', 'VBD'), ('training', 'NN'), ('times', 'NNS'), ('hours', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['large networks', 'weeks', 'years', 'progress hardware', 'software', 'algorithm parallelization', 'training times hours']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Whereas', 'wherea'), ('training', 'train'), ('large', 'larg'), ('networks', 'network'), ('could', 'could'), ('taken', 'taken'), ('weeks', 'week'), ('two', 'two'), ('years', 'year'), ('ago', 'ago'), (',', ','), ('progress', 'progress'), ('hardware', 'hardwar'), (',', ','), ('software', 'softwar'), ('algorithm', 'algorithm'), ('parallelization', 'parallel'), ('reduced', 'reduc'), ('training', 'train'), ('times', 'time'), ('hours', 'hour'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Whereas', 'wherea'), ('training', 'train'), ('large', 'larg'), ('networks', 'network'), ('could', 'could'), ('taken', 'taken'), ('weeks', 'week'), ('two', 'two'), ('years', 'year'), ('ago', 'ago'), (',', ','), ('progress', 'progress'), ('hardware', 'hardwar'), (',', ','), ('software', 'softwar'), ('algorithm', 'algorithm'), ('parallelization', 'parallel'), ('reduced', 'reduc'), ('training', 'train'), ('times', 'time'), ('hours', 'hour'), ('.', '.')]

>> Lemmatization: 
 [('Whereas', 'Whereas'), ('training', 'training'), ('large', 'large'), ('networks', 'network'), ('could', 'could'), ('taken', 'taken'), ('weeks', 'week'), ('two', 'two'), ('years', 'year'), ('ago', 'ago'), (',', ','), ('progress', 'progress'), ('hardware', 'hardware'), (',', ','), ('software', 'software'), ('algorithm', 'algorithm'), ('parallelization', 'parallelization'), ('reduced', 'reduced'), ('training', 'training'), ('times', 'time'), ('hours', 'hour'), ('.', '.')]



========================================== PARAGRAPH 132 ===========================================

The performance of ConvNet-based vision systems has caused  most major technology companies, including Google, Facebook,  

------------------- Sentence 1 -------------------

The performance of ConvNet-based vision systems has caused  most major technology companies, including Google, Facebook,

>> Tokens are: 
 ['The', 'performance', 'ConvNet-based', 'vision', 'systems', 'caused', 'major', 'technology', 'companies', ',', 'including', 'Google', ',', 'Facebook', ',']

>> Bigrams are: 
 [('The', 'performance'), ('performance', 'ConvNet-based'), ('ConvNet-based', 'vision'), ('vision', 'systems'), ('systems', 'caused'), ('caused', 'major'), ('major', 'technology'), ('technology', 'companies'), ('companies', ','), (',', 'including'), ('including', 'Google'), ('Google', ','), (',', 'Facebook'), ('Facebook', ',')]

>> Trigrams are: 
 [('The', 'performance', 'ConvNet-based'), ('performance', 'ConvNet-based', 'vision'), ('ConvNet-based', 'vision', 'systems'), ('vision', 'systems', 'caused'), ('systems', 'caused', 'major'), ('caused', 'major', 'technology'), ('major', 'technology', 'companies'), ('technology', 'companies', ','), ('companies', ',', 'including'), (',', 'including', 'Google'), ('including', 'Google', ','), ('Google', ',', 'Facebook'), (',', 'Facebook', ',')]

>> POS Tags are: 
 [('The', 'DT'), ('performance', 'NN'), ('ConvNet-based', 'JJ'), ('vision', 'NN'), ('systems', 'NNS'), ('caused', 'VBD'), ('major', 'JJ'), ('technology', 'NN'), ('companies', 'NNS'), (',', ','), ('including', 'VBG'), ('Google', 'NNP'), (',', ','), ('Facebook', 'NNP'), (',', ',')]

>> Noun Phrases are: 
 ['The performance', 'ConvNet-based vision systems', 'major technology companies', 'Google', 'Facebook']

>> Named Entities are: 
 [('PERSON', 'Google'), ('GPE', 'Facebook')] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('performance', 'perform'), ('ConvNet-based', 'convnet-bas'), ('vision', 'vision'), ('systems', 'system'), ('caused', 'caus'), ('major', 'major'), ('technology', 'technolog'), ('companies', 'compani'), (',', ','), ('including', 'includ'), ('Google', 'googl'), (',', ','), ('Facebook', 'facebook'), (',', ',')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('performance', 'perform'), ('ConvNet-based', 'convnet-bas'), ('vision', 'vision'), ('systems', 'system'), ('caused', 'caus'), ('major', 'major'), ('technology', 'technolog'), ('companies', 'compani'), (',', ','), ('including', 'includ'), ('Google', 'googl'), (',', ','), ('Facebook', 'facebook'), (',', ',')]

>> Lemmatization: 
 [('The', 'The'), ('performance', 'performance'), ('ConvNet-based', 'ConvNet-based'), ('vision', 'vision'), ('systems', 'system'), ('caused', 'caused'), ('major', 'major'), ('technology', 'technology'), ('companies', 'company'), (',', ','), ('including', 'including'), ('Google', 'Google'), (',', ','), ('Facebook', 'Facebook'), (',', ',')]



========================================== PARAGRAPH 133 ===========================================

Microsoft, IBM, Yahoo!, Twitter and Adobe, as well as a quickly  growing number of start-ups to initiate research and development  projects and to deploy ConvNet-based image understanding products  and services.  

------------------- Sentence 1 -------------------

Microsoft, IBM, Yahoo!, Twitter and Adobe, as well as a quickly  growing number of start-ups to initiate research and development  projects and to deploy ConvNet-based image understanding products  and services.

>> Tokens are: 
 ['Microsoft', ',', 'IBM', ',', 'Yahoo', '!', ',', 'Twitter', 'Adobe', ',', 'well', 'quickly', 'growing', 'number', 'start-ups', 'initiate', 'research', 'development', 'projects', 'deploy', 'ConvNet-based', 'image', 'understanding', 'products', 'services', '.']

>> Bigrams are: 
 [('Microsoft', ','), (',', 'IBM'), ('IBM', ','), (',', 'Yahoo'), ('Yahoo', '!'), ('!', ','), (',', 'Twitter'), ('Twitter', 'Adobe'), ('Adobe', ','), (',', 'well'), ('well', 'quickly'), ('quickly', 'growing'), ('growing', 'number'), ('number', 'start-ups'), ('start-ups', 'initiate'), ('initiate', 'research'), ('research', 'development'), ('development', 'projects'), ('projects', 'deploy'), ('deploy', 'ConvNet-based'), ('ConvNet-based', 'image'), ('image', 'understanding'), ('understanding', 'products'), ('products', 'services'), ('services', '.')]

>> Trigrams are: 
 [('Microsoft', ',', 'IBM'), (',', 'IBM', ','), ('IBM', ',', 'Yahoo'), (',', 'Yahoo', '!'), ('Yahoo', '!', ','), ('!', ',', 'Twitter'), (',', 'Twitter', 'Adobe'), ('Twitter', 'Adobe', ','), ('Adobe', ',', 'well'), (',', 'well', 'quickly'), ('well', 'quickly', 'growing'), ('quickly', 'growing', 'number'), ('growing', 'number', 'start-ups'), ('number', 'start-ups', 'initiate'), ('start-ups', 'initiate', 'research'), ('initiate', 'research', 'development'), ('research', 'development', 'projects'), ('development', 'projects', 'deploy'), ('projects', 'deploy', 'ConvNet-based'), ('deploy', 'ConvNet-based', 'image'), ('ConvNet-based', 'image', 'understanding'), ('image', 'understanding', 'products'), ('understanding', 'products', 'services'), ('products', 'services', '.')]

>> POS Tags are: 
 [('Microsoft', 'NNP'), (',', ','), ('IBM', 'NNP'), (',', ','), ('Yahoo', 'NNP'), ('!', '.'), (',', ','), ('Twitter', 'NNP'), ('Adobe', 'NNP'), (',', ','), ('well', 'RB'), ('quickly', 'RB'), ('growing', 'VBG'), ('number', 'NN'), ('start-ups', 'JJ'), ('initiate', 'JJ'), ('research', 'NN'), ('development', 'NN'), ('projects', 'NNS'), ('deploy', 'VBP'), ('ConvNet-based', 'JJ'), ('image', 'NN'), ('understanding', 'NN'), ('products', 'NNS'), ('services', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['Microsoft', 'IBM', 'Yahoo', 'Twitter Adobe', 'number', 'start-ups initiate research development projects', 'ConvNet-based image understanding products services']

>> Named Entities are: 
 [('GPE', 'Microsoft'), ('ORGANIZATION', 'IBM'), ('PERSON', 'Yahoo'), ('PERSON', 'Twitter Adobe')] 

>> Stemming using Porter Stemmer: 
 [('Microsoft', 'microsoft'), (',', ','), ('IBM', 'ibm'), (',', ','), ('Yahoo', 'yahoo'), ('!', '!'), (',', ','), ('Twitter', 'twitter'), ('Adobe', 'adob'), (',', ','), ('well', 'well'), ('quickly', 'quickli'), ('growing', 'grow'), ('number', 'number'), ('start-ups', 'start-up'), ('initiate', 'initi'), ('research', 'research'), ('development', 'develop'), ('projects', 'project'), ('deploy', 'deploy'), ('ConvNet-based', 'convnet-bas'), ('image', 'imag'), ('understanding', 'understand'), ('products', 'product'), ('services', 'servic'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Microsoft', 'microsoft'), (',', ','), ('IBM', 'ibm'), (',', ','), ('Yahoo', 'yahoo'), ('!', '!'), (',', ','), ('Twitter', 'twitter'), ('Adobe', 'adob'), (',', ','), ('well', 'well'), ('quickly', 'quick'), ('growing', 'grow'), ('number', 'number'), ('start-ups', 'start-up'), ('initiate', 'initi'), ('research', 'research'), ('development', 'develop'), ('projects', 'project'), ('deploy', 'deploy'), ('ConvNet-based', 'convnet-bas'), ('image', 'imag'), ('understanding', 'understand'), ('products', 'product'), ('services', 'servic'), ('.', '.')]

>> Lemmatization: 
 [('Microsoft', 'Microsoft'), (',', ','), ('IBM', 'IBM'), (',', ','), ('Yahoo', 'Yahoo'), ('!', '!'), (',', ','), ('Twitter', 'Twitter'), ('Adobe', 'Adobe'), (',', ','), ('well', 'well'), ('quickly', 'quickly'), ('growing', 'growing'), ('number', 'number'), ('start-ups', 'start-ups'), ('initiate', 'initiate'), ('research', 'research'), ('development', 'development'), ('projects', 'project'), ('deploy', 'deploy'), ('ConvNet-based', 'ConvNet-based'), ('image', 'image'), ('understanding', 'understanding'), ('products', 'product'), ('services', 'service'), ('.', '.')]



========================================== PARAGRAPH 134 ===========================================

ConvNets are easily amenable to efficient hardware implemen- tations in chips or field-programmable gate arrays66,67. A number  of companies such as NVIDIA, Mobileye, Intel, Qualcomm and  Samsung are developing ConvNet chips to enable real-time vision  applications in smartphones, cameras, robots and self-driving cars.  

------------------- Sentence 1 -------------------

ConvNets are easily amenable to efficient hardware implemen- tations in chips or field-programmable gate arrays66,67.

>> Tokens are: 
 ['ConvNets', 'easily', 'amenable', 'efficient', 'hardware', 'implemen-', 'tations', 'chips', 'field-programmable', 'gate', 'arrays66,67', '.']

>> Bigrams are: 
 [('ConvNets', 'easily'), ('easily', 'amenable'), ('amenable', 'efficient'), ('efficient', 'hardware'), ('hardware', 'implemen-'), ('implemen-', 'tations'), ('tations', 'chips'), ('chips', 'field-programmable'), ('field-programmable', 'gate'), ('gate', 'arrays66,67'), ('arrays66,67', '.')]

>> Trigrams are: 
 [('ConvNets', 'easily', 'amenable'), ('easily', 'amenable', 'efficient'), ('amenable', 'efficient', 'hardware'), ('efficient', 'hardware', 'implemen-'), ('hardware', 'implemen-', 'tations'), ('implemen-', 'tations', 'chips'), ('tations', 'chips', 'field-programmable'), ('chips', 'field-programmable', 'gate'), ('field-programmable', 'gate', 'arrays66,67'), ('gate', 'arrays66,67', '.')]

>> POS Tags are: 
 [('ConvNets', 'NNS'), ('easily', 'RB'), ('amenable', 'JJ'), ('efficient', 'JJ'), ('hardware', 'NN'), ('implemen-', 'JJ'), ('tations', 'NNS'), ('chips', 'NNS'), ('field-programmable', 'JJ'), ('gate', 'NN'), ('arrays66,67', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['ConvNets', 'amenable efficient hardware', 'implemen- tations chips', 'field-programmable gate arrays66,67']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('ConvNets', 'convnet'), ('easily', 'easili'), ('amenable', 'amen'), ('efficient', 'effici'), ('hardware', 'hardwar'), ('implemen-', 'implemen-'), ('tations', 'tation'), ('chips', 'chip'), ('field-programmable', 'field-programm'), ('gate', 'gate'), ('arrays66,67', 'arrays66,67'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('ConvNets', 'convnet'), ('easily', 'easili'), ('amenable', 'amen'), ('efficient', 'effici'), ('hardware', 'hardwar'), ('implemen-', 'implemen-'), ('tations', 'tation'), ('chips', 'chip'), ('field-programmable', 'field-programm'), ('gate', 'gate'), ('arrays66,67', 'arrays66,67'), ('.', '.')]

>> Lemmatization: 
 [('ConvNets', 'ConvNets'), ('easily', 'easily'), ('amenable', 'amenable'), ('efficient', 'efficient'), ('hardware', 'hardware'), ('implemen-', 'implemen-'), ('tations', 'tations'), ('chips', 'chip'), ('field-programmable', 'field-programmable'), ('gate', 'gate'), ('arrays66,67', 'arrays66,67'), ('.', '.')]


------------------- Sentence 2 -------------------

A number  of companies such as NVIDIA, Mobileye, Intel, Qualcomm and  Samsung are developing ConvNet chips to enable real-time vision  applications in smartphones, cameras, robots and self-driving cars.

>> Tokens are: 
 ['A', 'number', 'companies', 'NVIDIA', ',', 'Mobileye', ',', 'Intel', ',', 'Qualcomm', 'Samsung', 'developing', 'ConvNet', 'chips', 'enable', 'real-time', 'vision', 'applications', 'smartphones', ',', 'cameras', ',', 'robots', 'self-driving', 'cars', '.']

>> Bigrams are: 
 [('A', 'number'), ('number', 'companies'), ('companies', 'NVIDIA'), ('NVIDIA', ','), (',', 'Mobileye'), ('Mobileye', ','), (',', 'Intel'), ('Intel', ','), (',', 'Qualcomm'), ('Qualcomm', 'Samsung'), ('Samsung', 'developing'), ('developing', 'ConvNet'), ('ConvNet', 'chips'), ('chips', 'enable'), ('enable', 'real-time'), ('real-time', 'vision'), ('vision', 'applications'), ('applications', 'smartphones'), ('smartphones', ','), (',', 'cameras'), ('cameras', ','), (',', 'robots'), ('robots', 'self-driving'), ('self-driving', 'cars'), ('cars', '.')]

>> Trigrams are: 
 [('A', 'number', 'companies'), ('number', 'companies', 'NVIDIA'), ('companies', 'NVIDIA', ','), ('NVIDIA', ',', 'Mobileye'), (',', 'Mobileye', ','), ('Mobileye', ',', 'Intel'), (',', 'Intel', ','), ('Intel', ',', 'Qualcomm'), (',', 'Qualcomm', 'Samsung'), ('Qualcomm', 'Samsung', 'developing'), ('Samsung', 'developing', 'ConvNet'), ('developing', 'ConvNet', 'chips'), ('ConvNet', 'chips', 'enable'), ('chips', 'enable', 'real-time'), ('enable', 'real-time', 'vision'), ('real-time', 'vision', 'applications'), ('vision', 'applications', 'smartphones'), ('applications', 'smartphones', ','), ('smartphones', ',', 'cameras'), (',', 'cameras', ','), ('cameras', ',', 'robots'), (',', 'robots', 'self-driving'), ('robots', 'self-driving', 'cars'), ('self-driving', 'cars', '.')]

>> POS Tags are: 
 [('A', 'DT'), ('number', 'NN'), ('companies', 'NNS'), ('NVIDIA', 'NNP'), (',', ','), ('Mobileye', 'NNP'), (',', ','), ('Intel', 'NNP'), (',', ','), ('Qualcomm', 'NNP'), ('Samsung', 'NNP'), ('developing', 'VBG'), ('ConvNet', 'NNP'), ('chips', 'NNS'), ('enable', 'JJ'), ('real-time', 'JJ'), ('vision', 'NN'), ('applications', 'NNS'), ('smartphones', 'NNS'), (',', ','), ('cameras', 'NNS'), (',', ','), ('robots', 'NNS'), ('self-driving', 'JJ'), ('cars', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['A number companies NVIDIA', 'Mobileye', 'Intel', 'Qualcomm Samsung', 'ConvNet chips', 'enable real-time vision applications smartphones', 'cameras', 'robots', 'self-driving cars']

>> Named Entities are: 
 [('ORGANIZATION', 'NVIDIA'), ('GPE', 'Mobileye'), ('ORGANIZATION', 'Intel'), ('PERSON', 'Qualcomm Samsung'), ('ORGANIZATION', 'ConvNet')] 

>> Stemming using Porter Stemmer: 
 [('A', 'a'), ('number', 'number'), ('companies', 'compani'), ('NVIDIA', 'nvidia'), (',', ','), ('Mobileye', 'mobiley'), (',', ','), ('Intel', 'intel'), (',', ','), ('Qualcomm', 'qualcomm'), ('Samsung', 'samsung'), ('developing', 'develop'), ('ConvNet', 'convnet'), ('chips', 'chip'), ('enable', 'enabl'), ('real-time', 'real-tim'), ('vision', 'vision'), ('applications', 'applic'), ('smartphones', 'smartphon'), (',', ','), ('cameras', 'camera'), (',', ','), ('robots', 'robot'), ('self-driving', 'self-driv'), ('cars', 'car'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('A', 'a'), ('number', 'number'), ('companies', 'compani'), ('NVIDIA', 'nvidia'), (',', ','), ('Mobileye', 'mobiley'), (',', ','), ('Intel', 'intel'), (',', ','), ('Qualcomm', 'qualcomm'), ('Samsung', 'samsung'), ('developing', 'develop'), ('ConvNet', 'convnet'), ('chips', 'chip'), ('enable', 'enabl'), ('real-time', 'real-tim'), ('vision', 'vision'), ('applications', 'applic'), ('smartphones', 'smartphon'), (',', ','), ('cameras', 'camera'), (',', ','), ('robots', 'robot'), ('self-driving', 'self-driv'), ('cars', 'car'), ('.', '.')]

>> Lemmatization: 
 [('A', 'A'), ('number', 'number'), ('companies', 'company'), ('NVIDIA', 'NVIDIA'), (',', ','), ('Mobileye', 'Mobileye'), (',', ','), ('Intel', 'Intel'), (',', ','), ('Qualcomm', 'Qualcomm'), ('Samsung', 'Samsung'), ('developing', 'developing'), ('ConvNet', 'ConvNet'), ('chips', 'chip'), ('enable', 'enable'), ('real-time', 'real-time'), ('vision', 'vision'), ('applications', 'application'), ('smartphones', 'smartphones'), (',', ','), ('cameras', 'camera'), (',', ','), ('robots', 'robot'), ('self-driving', 'self-driving'), ('cars', 'car'), ('.', '.')]



========================================== PARAGRAPH 135 ===========================================

Distributed representations and language processing  Deep-learning theory shows that deep nets have two different expo- nential advantages over classic learning algorithms that do not use  distributed representations21. Both of these advantages arise from the  power of composition and depend on the underlying data-generating  distribution having an appropriate componential structure40. First,  learning distributed representations enable generalization to new  combinations of the values of learned features beyond those seen  during training (for example, 2n combinations are possible with n  binary features)68,69. Second, composing layers of representation in  a deep net brings the potential for another exponential advantage70  (exponential in the depth).  

------------------- Sentence 1 -------------------

Distributed representations and language processing  Deep-learning theory shows that deep nets have two different expo- nential advantages over classic learning algorithms that do not use  distributed representations21.

>> Tokens are: 
 ['Distributed', 'representations', 'language', 'processing', 'Deep-learning', 'theory', 'shows', 'deep', 'nets', 'two', 'different', 'expo-', 'nential', 'advantages', 'classic', 'learning', 'algorithms', 'use', 'distributed', 'representations21', '.']

>> Bigrams are: 
 [('Distributed', 'representations'), ('representations', 'language'), ('language', 'processing'), ('processing', 'Deep-learning'), ('Deep-learning', 'theory'), ('theory', 'shows'), ('shows', 'deep'), ('deep', 'nets'), ('nets', 'two'), ('two', 'different'), ('different', 'expo-'), ('expo-', 'nential'), ('nential', 'advantages'), ('advantages', 'classic'), ('classic', 'learning'), ('learning', 'algorithms'), ('algorithms', 'use'), ('use', 'distributed'), ('distributed', 'representations21'), ('representations21', '.')]

>> Trigrams are: 
 [('Distributed', 'representations', 'language'), ('representations', 'language', 'processing'), ('language', 'processing', 'Deep-learning'), ('processing', 'Deep-learning', 'theory'), ('Deep-learning', 'theory', 'shows'), ('theory', 'shows', 'deep'), ('shows', 'deep', 'nets'), ('deep', 'nets', 'two'), ('nets', 'two', 'different'), ('two', 'different', 'expo-'), ('different', 'expo-', 'nential'), ('expo-', 'nential', 'advantages'), ('nential', 'advantages', 'classic'), ('advantages', 'classic', 'learning'), ('classic', 'learning', 'algorithms'), ('learning', 'algorithms', 'use'), ('algorithms', 'use', 'distributed'), ('use', 'distributed', 'representations21'), ('distributed', 'representations21', '.')]

>> POS Tags are: 
 [('Distributed', 'VBN'), ('representations', 'NNS'), ('language', 'NN'), ('processing', 'VBG'), ('Deep-learning', 'NNP'), ('theory', 'NN'), ('shows', 'NNS'), ('deep', 'VBP'), ('nets', 'NNS'), ('two', 'CD'), ('different', 'JJ'), ('expo-', 'JJ'), ('nential', 'JJ'), ('advantages', 'NNS'), ('classic', 'VBP'), ('learning', 'VBG'), ('algorithms', 'NN'), ('use', 'NN'), ('distributed', 'VBD'), ('representations21', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['representations language', 'Deep-learning theory shows', 'nets', 'different expo- nential advantages', 'algorithms use', 'representations21']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Distributed', 'distribut'), ('representations', 'represent'), ('language', 'languag'), ('processing', 'process'), ('Deep-learning', 'deep-learn'), ('theory', 'theori'), ('shows', 'show'), ('deep', 'deep'), ('nets', 'net'), ('two', 'two'), ('different', 'differ'), ('expo-', 'expo-'), ('nential', 'nential'), ('advantages', 'advantag'), ('classic', 'classic'), ('learning', 'learn'), ('algorithms', 'algorithm'), ('use', 'use'), ('distributed', 'distribut'), ('representations21', 'representations21'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Distributed', 'distribut'), ('representations', 'represent'), ('language', 'languag'), ('processing', 'process'), ('Deep-learning', 'deep-learn'), ('theory', 'theori'), ('shows', 'show'), ('deep', 'deep'), ('nets', 'net'), ('two', 'two'), ('different', 'differ'), ('expo-', 'expo-'), ('nential', 'nential'), ('advantages', 'advantag'), ('classic', 'classic'), ('learning', 'learn'), ('algorithms', 'algorithm'), ('use', 'use'), ('distributed', 'distribut'), ('representations21', 'representations21'), ('.', '.')]

>> Lemmatization: 
 [('Distributed', 'Distributed'), ('representations', 'representation'), ('language', 'language'), ('processing', 'processing'), ('Deep-learning', 'Deep-learning'), ('theory', 'theory'), ('shows', 'show'), ('deep', 'deep'), ('nets', 'net'), ('two', 'two'), ('different', 'different'), ('expo-', 'expo-'), ('nential', 'nential'), ('advantages', 'advantage'), ('classic', 'classic'), ('learning', 'learning'), ('algorithms', 'algorithm'), ('use', 'use'), ('distributed', 'distributed'), ('representations21', 'representations21'), ('.', '.')]


------------------- Sentence 2 -------------------

Both of these advantages arise from the  power of composition and depend on the underlying data-generating  distribution having an appropriate componential structure40.

>> Tokens are: 
 ['Both', 'advantages', 'arise', 'power', 'composition', 'depend', 'underlying', 'data-generating', 'distribution', 'appropriate', 'componential', 'structure40', '.']

>> Bigrams are: 
 [('Both', 'advantages'), ('advantages', 'arise'), ('arise', 'power'), ('power', 'composition'), ('composition', 'depend'), ('depend', 'underlying'), ('underlying', 'data-generating'), ('data-generating', 'distribution'), ('distribution', 'appropriate'), ('appropriate', 'componential'), ('componential', 'structure40'), ('structure40', '.')]

>> Trigrams are: 
 [('Both', 'advantages', 'arise'), ('advantages', 'arise', 'power'), ('arise', 'power', 'composition'), ('power', 'composition', 'depend'), ('composition', 'depend', 'underlying'), ('depend', 'underlying', 'data-generating'), ('underlying', 'data-generating', 'distribution'), ('data-generating', 'distribution', 'appropriate'), ('distribution', 'appropriate', 'componential'), ('appropriate', 'componential', 'structure40'), ('componential', 'structure40', '.')]

>> POS Tags are: 
 [('Both', 'DT'), ('advantages', 'NNS'), ('arise', 'VBP'), ('power', 'NN'), ('composition', 'NN'), ('depend', 'VBP'), ('underlying', 'VBG'), ('data-generating', 'JJ'), ('distribution', 'NN'), ('appropriate', 'JJ'), ('componential', 'JJ'), ('structure40', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Both advantages', 'power composition', 'data-generating distribution', 'appropriate componential structure40']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Both', 'both'), ('advantages', 'advantag'), ('arise', 'aris'), ('power', 'power'), ('composition', 'composit'), ('depend', 'depend'), ('underlying', 'underli'), ('data-generating', 'data-gener'), ('distribution', 'distribut'), ('appropriate', 'appropri'), ('componential', 'componenti'), ('structure40', 'structure40'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Both', 'both'), ('advantages', 'advantag'), ('arise', 'aris'), ('power', 'power'), ('composition', 'composit'), ('depend', 'depend'), ('underlying', 'under'), ('data-generating', 'data-gener'), ('distribution', 'distribut'), ('appropriate', 'appropri'), ('componential', 'componenti'), ('structure40', 'structure40'), ('.', '.')]

>> Lemmatization: 
 [('Both', 'Both'), ('advantages', 'advantage'), ('arise', 'arise'), ('power', 'power'), ('composition', 'composition'), ('depend', 'depend'), ('underlying', 'underlying'), ('data-generating', 'data-generating'), ('distribution', 'distribution'), ('appropriate', 'appropriate'), ('componential', 'componential'), ('structure40', 'structure40'), ('.', '.')]


------------------- Sentence 3 -------------------

First,  learning distributed representations enable generalization to new  combinations of the values of learned features beyond those seen  during training (for example, 2n combinations are possible with n  binary features)68,69.

>> Tokens are: 
 ['First', ',', 'learning', 'distributed', 'representations', 'enable', 'generalization', 'new', 'combinations', 'values', 'learned', 'features', 'beyond', 'seen', 'training', '(', 'example', ',', '2n', 'combinations', 'possible', 'n', 'binary', 'features', ')', '68,69', '.']

>> Bigrams are: 
 [('First', ','), (',', 'learning'), ('learning', 'distributed'), ('distributed', 'representations'), ('representations', 'enable'), ('enable', 'generalization'), ('generalization', 'new'), ('new', 'combinations'), ('combinations', 'values'), ('values', 'learned'), ('learned', 'features'), ('features', 'beyond'), ('beyond', 'seen'), ('seen', 'training'), ('training', '('), ('(', 'example'), ('example', ','), (',', '2n'), ('2n', 'combinations'), ('combinations', 'possible'), ('possible', 'n'), ('n', 'binary'), ('binary', 'features'), ('features', ')'), (')', '68,69'), ('68,69', '.')]

>> Trigrams are: 
 [('First', ',', 'learning'), (',', 'learning', 'distributed'), ('learning', 'distributed', 'representations'), ('distributed', 'representations', 'enable'), ('representations', 'enable', 'generalization'), ('enable', 'generalization', 'new'), ('generalization', 'new', 'combinations'), ('new', 'combinations', 'values'), ('combinations', 'values', 'learned'), ('values', 'learned', 'features'), ('learned', 'features', 'beyond'), ('features', 'beyond', 'seen'), ('beyond', 'seen', 'training'), ('seen', 'training', '('), ('training', '(', 'example'), ('(', 'example', ','), ('example', ',', '2n'), (',', '2n', 'combinations'), ('2n', 'combinations', 'possible'), ('combinations', 'possible', 'n'), ('possible', 'n', 'binary'), ('n', 'binary', 'features'), ('binary', 'features', ')'), ('features', ')', '68,69'), (')', '68,69', '.')]

>> POS Tags are: 
 [('First', 'RB'), (',', ','), ('learning', 'VBG'), ('distributed', 'VBN'), ('representations', 'NNS'), ('enable', 'JJ'), ('generalization', 'NN'), ('new', 'JJ'), ('combinations', 'NNS'), ('values', 'NNS'), ('learned', 'VBD'), ('features', 'NNS'), ('beyond', 'IN'), ('seen', 'VBN'), ('training', 'NN'), ('(', '('), ('example', 'NN'), (',', ','), ('2n', 'CD'), ('combinations', 'NNS'), ('possible', 'JJ'), ('n', 'JJ'), ('binary', 'JJ'), ('features', 'NNS'), (')', ')'), ('68,69', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['representations', 'enable generalization', 'new combinations values', 'features', 'training', 'example', 'combinations', 'possible n binary features']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('First', 'first'), (',', ','), ('learning', 'learn'), ('distributed', 'distribut'), ('representations', 'represent'), ('enable', 'enabl'), ('generalization', 'gener'), ('new', 'new'), ('combinations', 'combin'), ('values', 'valu'), ('learned', 'learn'), ('features', 'featur'), ('beyond', 'beyond'), ('seen', 'seen'), ('training', 'train'), ('(', '('), ('example', 'exampl'), (',', ','), ('2n', '2n'), ('combinations', 'combin'), ('possible', 'possibl'), ('n', 'n'), ('binary', 'binari'), ('features', 'featur'), (')', ')'), ('68,69', '68,69'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('First', 'first'), (',', ','), ('learning', 'learn'), ('distributed', 'distribut'), ('representations', 'represent'), ('enable', 'enabl'), ('generalization', 'general'), ('new', 'new'), ('combinations', 'combin'), ('values', 'valu'), ('learned', 'learn'), ('features', 'featur'), ('beyond', 'beyond'), ('seen', 'seen'), ('training', 'train'), ('(', '('), ('example', 'exampl'), (',', ','), ('2n', '2n'), ('combinations', 'combin'), ('possible', 'possibl'), ('n', 'n'), ('binary', 'binari'), ('features', 'featur'), (')', ')'), ('68,69', '68,69'), ('.', '.')]

>> Lemmatization: 
 [('First', 'First'), (',', ','), ('learning', 'learning'), ('distributed', 'distributed'), ('representations', 'representation'), ('enable', 'enable'), ('generalization', 'generalization'), ('new', 'new'), ('combinations', 'combination'), ('values', 'value'), ('learned', 'learned'), ('features', 'feature'), ('beyond', 'beyond'), ('seen', 'seen'), ('training', 'training'), ('(', '('), ('example', 'example'), (',', ','), ('2n', '2n'), ('combinations', 'combination'), ('possible', 'possible'), ('n', 'n'), ('binary', 'binary'), ('features', 'feature'), (')', ')'), ('68,69', '68,69'), ('.', '.')]


------------------- Sentence 4 -------------------

Second, composing layers of representation in  a deep net brings the potential for another exponential advantage70  (exponential in the depth).

>> Tokens are: 
 ['Second', ',', 'composing', 'layers', 'representation', 'deep', 'net', 'brings', 'potential', 'another', 'exponential', 'advantage70', '(', 'exponential', 'depth', ')', '.']

>> Bigrams are: 
 [('Second', ','), (',', 'composing'), ('composing', 'layers'), ('layers', 'representation'), ('representation', 'deep'), ('deep', 'net'), ('net', 'brings'), ('brings', 'potential'), ('potential', 'another'), ('another', 'exponential'), ('exponential', 'advantage70'), ('advantage70', '('), ('(', 'exponential'), ('exponential', 'depth'), ('depth', ')'), (')', '.')]

>> Trigrams are: 
 [('Second', ',', 'composing'), (',', 'composing', 'layers'), ('composing', 'layers', 'representation'), ('layers', 'representation', 'deep'), ('representation', 'deep', 'net'), ('deep', 'net', 'brings'), ('net', 'brings', 'potential'), ('brings', 'potential', 'another'), ('potential', 'another', 'exponential'), ('another', 'exponential', 'advantage70'), ('exponential', 'advantage70', '('), ('advantage70', '(', 'exponential'), ('(', 'exponential', 'depth'), ('exponential', 'depth', ')'), ('depth', ')', '.')]

>> POS Tags are: 
 [('Second', 'JJ'), (',', ','), ('composing', 'VBG'), ('layers', 'NNS'), ('representation', 'VBP'), ('deep', 'JJ'), ('net', 'JJ'), ('brings', 'NNS'), ('potential', 'JJ'), ('another', 'DT'), ('exponential', 'JJ'), ('advantage70', 'NN'), ('(', '('), ('exponential', 'JJ'), ('depth', 'NN'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['layers', 'deep net brings', 'another exponential advantage70', 'exponential depth']

>> Named Entities are: 
 [('GPE', 'Second')] 

>> Stemming using Porter Stemmer: 
 [('Second', 'second'), (',', ','), ('composing', 'compos'), ('layers', 'layer'), ('representation', 'represent'), ('deep', 'deep'), ('net', 'net'), ('brings', 'bring'), ('potential', 'potenti'), ('another', 'anoth'), ('exponential', 'exponenti'), ('advantage70', 'advantage70'), ('(', '('), ('exponential', 'exponenti'), ('depth', 'depth'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Second', 'second'), (',', ','), ('composing', 'compos'), ('layers', 'layer'), ('representation', 'represent'), ('deep', 'deep'), ('net', 'net'), ('brings', 'bring'), ('potential', 'potenti'), ('another', 'anoth'), ('exponential', 'exponenti'), ('advantage70', 'advantage70'), ('(', '('), ('exponential', 'exponenti'), ('depth', 'depth'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Second', 'Second'), (',', ','), ('composing', 'composing'), ('layers', 'layer'), ('representation', 'representation'), ('deep', 'deep'), ('net', 'net'), ('brings', 'brings'), ('potential', 'potential'), ('another', 'another'), ('exponential', 'exponential'), ('advantage70', 'advantage70'), ('(', '('), ('exponential', 'exponential'), ('depth', 'depth'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 136 ===========================================

The hidden layers of a multilayer neural network learn to repre- sent the network’s inputs in a way that makes it easy to predict the  target outputs. This is nicely demonstrated by training a multilayer  neural network to predict the next word in a sequence from a local  

------------------- Sentence 1 -------------------

The hidden layers of a multilayer neural network learn to repre- sent the network’s inputs in a way that makes it easy to predict the  target outputs.

>> Tokens are: 
 ['The', 'hidden', 'layers', 'multilayer', 'neural', 'network', 'learn', 'repre-', 'sent', 'network', '’', 'inputs', 'way', 'makes', 'easy', 'predict', 'target', 'outputs', '.']

>> Bigrams are: 
 [('The', 'hidden'), ('hidden', 'layers'), ('layers', 'multilayer'), ('multilayer', 'neural'), ('neural', 'network'), ('network', 'learn'), ('learn', 'repre-'), ('repre-', 'sent'), ('sent', 'network'), ('network', '’'), ('’', 'inputs'), ('inputs', 'way'), ('way', 'makes'), ('makes', 'easy'), ('easy', 'predict'), ('predict', 'target'), ('target', 'outputs'), ('outputs', '.')]

>> Trigrams are: 
 [('The', 'hidden', 'layers'), ('hidden', 'layers', 'multilayer'), ('layers', 'multilayer', 'neural'), ('multilayer', 'neural', 'network'), ('neural', 'network', 'learn'), ('network', 'learn', 'repre-'), ('learn', 'repre-', 'sent'), ('repre-', 'sent', 'network'), ('sent', 'network', '’'), ('network', '’', 'inputs'), ('’', 'inputs', 'way'), ('inputs', 'way', 'makes'), ('way', 'makes', 'easy'), ('makes', 'easy', 'predict'), ('easy', 'predict', 'target'), ('predict', 'target', 'outputs'), ('target', 'outputs', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('hidden', 'JJ'), ('layers', 'NNS'), ('multilayer', 'VBP'), ('neural', 'JJ'), ('network', 'NN'), ('learn', 'JJ'), ('repre-', 'NN'), ('sent', 'NN'), ('network', 'NN'), ('’', 'NNP'), ('inputs', 'VBZ'), ('way', 'NN'), ('makes', 'VBZ'), ('easy', 'JJ'), ('predict', 'JJ'), ('target', 'NN'), ('outputs', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['The hidden layers', 'neural network', 'learn repre- sent network ’', 'way', 'easy predict target outputs']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('hidden', 'hidden'), ('layers', 'layer'), ('multilayer', 'multilay'), ('neural', 'neural'), ('network', 'network'), ('learn', 'learn'), ('repre-', 'repre-'), ('sent', 'sent'), ('network', 'network'), ('’', '’'), ('inputs', 'input'), ('way', 'way'), ('makes', 'make'), ('easy', 'easi'), ('predict', 'predict'), ('target', 'target'), ('outputs', 'output'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('hidden', 'hidden'), ('layers', 'layer'), ('multilayer', 'multilay'), ('neural', 'neural'), ('network', 'network'), ('learn', 'learn'), ('repre-', 'repre-'), ('sent', 'sent'), ('network', 'network'), ('’', '’'), ('inputs', 'input'), ('way', 'way'), ('makes', 'make'), ('easy', 'easi'), ('predict', 'predict'), ('target', 'target'), ('outputs', 'output'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('hidden', 'hidden'), ('layers', 'layer'), ('multilayer', 'multilayer'), ('neural', 'neural'), ('network', 'network'), ('learn', 'learn'), ('repre-', 'repre-'), ('sent', 'sent'), ('network', 'network'), ('’', '’'), ('inputs', 'input'), ('way', 'way'), ('makes', 'make'), ('easy', 'easy'), ('predict', 'predict'), ('target', 'target'), ('outputs', 'output'), ('.', '.')]


------------------- Sentence 2 -------------------

This is nicely demonstrated by training a multilayer  neural network to predict the next word in a sequence from a local

>> Tokens are: 
 ['This', 'nicely', 'demonstrated', 'training', 'multilayer', 'neural', 'network', 'predict', 'next', 'word', 'sequence', 'local']

>> Bigrams are: 
 [('This', 'nicely'), ('nicely', 'demonstrated'), ('demonstrated', 'training'), ('training', 'multilayer'), ('multilayer', 'neural'), ('neural', 'network'), ('network', 'predict'), ('predict', 'next'), ('next', 'word'), ('word', 'sequence'), ('sequence', 'local')]

>> Trigrams are: 
 [('This', 'nicely', 'demonstrated'), ('nicely', 'demonstrated', 'training'), ('demonstrated', 'training', 'multilayer'), ('training', 'multilayer', 'neural'), ('multilayer', 'neural', 'network'), ('neural', 'network', 'predict'), ('network', 'predict', 'next'), ('predict', 'next', 'word'), ('next', 'word', 'sequence'), ('word', 'sequence', 'local')]

>> POS Tags are: 
 [('This', 'DT'), ('nicely', 'RB'), ('demonstrated', 'JJ'), ('training', 'NN'), ('multilayer', 'NN'), ('neural', 'JJ'), ('network', 'NN'), ('predict', 'VBP'), ('next', 'JJ'), ('word', 'NN'), ('sequence', 'NN'), ('local', 'JJ')]

>> Noun Phrases are: 
 ['demonstrated training multilayer', 'neural network', 'next word sequence']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('This', 'thi'), ('nicely', 'nice'), ('demonstrated', 'demonstr'), ('training', 'train'), ('multilayer', 'multilay'), ('neural', 'neural'), ('network', 'network'), ('predict', 'predict'), ('next', 'next'), ('word', 'word'), ('sequence', 'sequenc'), ('local', 'local')]

>> Stemming using Snowball Stemmer: 
 [('This', 'this'), ('nicely', 'nice'), ('demonstrated', 'demonstr'), ('training', 'train'), ('multilayer', 'multilay'), ('neural', 'neural'), ('network', 'network'), ('predict', 'predict'), ('next', 'next'), ('word', 'word'), ('sequence', 'sequenc'), ('local', 'local')]

>> Lemmatization: 
 [('This', 'This'), ('nicely', 'nicely'), ('demonstrated', 'demonstrated'), ('training', 'training'), ('multilayer', 'multilayer'), ('neural', 'neural'), ('network', 'network'), ('predict', 'predict'), ('next', 'next'), ('word', 'word'), ('sequence', 'sequence'), ('local', 'local')]



========================================== PARAGRAPH 137 ===========================================

Figure 3 | From image to text. Captions generated by a recurrent neural  network (RNN) taking, as extra input, the representation extracted by a deep  convolution neural network (CNN) from a test image, with the RNN trained to  ‘translate’ high-level representations of images into captions (top). Reproduced  

------------------- Sentence 1 -------------------

Figure 3 | From image to text.

>> Tokens are: 
 ['Figure', '3', '|', 'From', 'image', 'text', '.']

>> Bigrams are: 
 [('Figure', '3'), ('3', '|'), ('|', 'From'), ('From', 'image'), ('image', 'text'), ('text', '.')]

>> Trigrams are: 
 [('Figure', '3', '|'), ('3', '|', 'From'), ('|', 'From', 'image'), ('From', 'image', 'text'), ('image', 'text', '.')]

>> POS Tags are: 
 [('Figure', 'NN'), ('3', 'CD'), ('|', 'NN'), ('From', 'NNP'), ('image', 'NN'), ('text', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Figure', '| From image text']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Figure', 'figur'), ('3', '3'), ('|', '|'), ('From', 'from'), ('image', 'imag'), ('text', 'text'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Figure', 'figur'), ('3', '3'), ('|', '|'), ('From', 'from'), ('image', 'imag'), ('text', 'text'), ('.', '.')]

>> Lemmatization: 
 [('Figure', 'Figure'), ('3', '3'), ('|', '|'), ('From', 'From'), ('image', 'image'), ('text', 'text'), ('.', '.')]


------------------- Sentence 2 -------------------

Captions generated by a recurrent neural  network (RNN) taking, as extra input, the representation extracted by a deep  convolution neural network (CNN) from a test image, with the RNN trained to  ‘translate’ high-level representations of images into captions (top).

>> Tokens are: 
 ['Captions', 'generated', 'recurrent', 'neural', 'network', '(', 'RNN', ')', 'taking', ',', 'extra', 'input', ',', 'representation', 'extracted', 'deep', 'convolution', 'neural', 'network', '(', 'CNN', ')', 'test', 'image', ',', 'RNN', 'trained', '‘', 'translate', '’', 'high-level', 'representations', 'images', 'captions', '(', 'top', ')', '.']

>> Bigrams are: 
 [('Captions', 'generated'), ('generated', 'recurrent'), ('recurrent', 'neural'), ('neural', 'network'), ('network', '('), ('(', 'RNN'), ('RNN', ')'), (')', 'taking'), ('taking', ','), (',', 'extra'), ('extra', 'input'), ('input', ','), (',', 'representation'), ('representation', 'extracted'), ('extracted', 'deep'), ('deep', 'convolution'), ('convolution', 'neural'), ('neural', 'network'), ('network', '('), ('(', 'CNN'), ('CNN', ')'), (')', 'test'), ('test', 'image'), ('image', ','), (',', 'RNN'), ('RNN', 'trained'), ('trained', '‘'), ('‘', 'translate'), ('translate', '’'), ('’', 'high-level'), ('high-level', 'representations'), ('representations', 'images'), ('images', 'captions'), ('captions', '('), ('(', 'top'), ('top', ')'), (')', '.')]

>> Trigrams are: 
 [('Captions', 'generated', 'recurrent'), ('generated', 'recurrent', 'neural'), ('recurrent', 'neural', 'network'), ('neural', 'network', '('), ('network', '(', 'RNN'), ('(', 'RNN', ')'), ('RNN', ')', 'taking'), (')', 'taking', ','), ('taking', ',', 'extra'), (',', 'extra', 'input'), ('extra', 'input', ','), ('input', ',', 'representation'), (',', 'representation', 'extracted'), ('representation', 'extracted', 'deep'), ('extracted', 'deep', 'convolution'), ('deep', 'convolution', 'neural'), ('convolution', 'neural', 'network'), ('neural', 'network', '('), ('network', '(', 'CNN'), ('(', 'CNN', ')'), ('CNN', ')', 'test'), (')', 'test', 'image'), ('test', 'image', ','), ('image', ',', 'RNN'), (',', 'RNN', 'trained'), ('RNN', 'trained', '‘'), ('trained', '‘', 'translate'), ('‘', 'translate', '’'), ('translate', '’', 'high-level'), ('’', 'high-level', 'representations'), ('high-level', 'representations', 'images'), ('representations', 'images', 'captions'), ('images', 'captions', '('), ('captions', '(', 'top'), ('(', 'top', ')'), ('top', ')', '.')]

>> POS Tags are: 
 [('Captions', 'NNS'), ('generated', 'VBD'), ('recurrent', 'JJ'), ('neural', 'JJ'), ('network', 'NN'), ('(', '('), ('RNN', 'NNP'), (')', ')'), ('taking', 'NN'), (',', ','), ('extra', 'JJ'), ('input', 'NN'), (',', ','), ('representation', 'NN'), ('extracted', 'VBD'), ('deep', 'JJ'), ('convolution', 'NN'), ('neural', 'JJ'), ('network', 'NN'), ('(', '('), ('CNN', 'NNP'), (')', ')'), ('test', 'NN'), ('image', 'NN'), (',', ','), ('RNN', 'NNP'), ('trained', 'VBD'), ('‘', 'NNP'), ('translate', 'NN'), ('’', 'NNP'), ('high-level', 'JJ'), ('representations', 'NNS'), ('images', 'NNS'), ('captions', 'NNS'), ('(', '('), ('top', 'JJ'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['Captions', 'recurrent neural network', 'RNN', 'taking', 'extra input', 'representation', 'deep convolution', 'neural network', 'CNN', 'test image', 'RNN', '‘ translate ’', 'high-level representations images captions']

>> Named Entities are: 
 [('ORGANIZATION', 'RNN'), ('ORGANIZATION', 'CNN'), ('ORGANIZATION', 'RNN')] 

>> Stemming using Porter Stemmer: 
 [('Captions', 'caption'), ('generated', 'gener'), ('recurrent', 'recurr'), ('neural', 'neural'), ('network', 'network'), ('(', '('), ('RNN', 'rnn'), (')', ')'), ('taking', 'take'), (',', ','), ('extra', 'extra'), ('input', 'input'), (',', ','), ('representation', 'represent'), ('extracted', 'extract'), ('deep', 'deep'), ('convolution', 'convolut'), ('neural', 'neural'), ('network', 'network'), ('(', '('), ('CNN', 'cnn'), (')', ')'), ('test', 'test'), ('image', 'imag'), (',', ','), ('RNN', 'rnn'), ('trained', 'train'), ('‘', '‘'), ('translate', 'translat'), ('’', '’'), ('high-level', 'high-level'), ('representations', 'represent'), ('images', 'imag'), ('captions', 'caption'), ('(', '('), ('top', 'top'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Captions', 'caption'), ('generated', 'generat'), ('recurrent', 'recurr'), ('neural', 'neural'), ('network', 'network'), ('(', '('), ('RNN', 'rnn'), (')', ')'), ('taking', 'take'), (',', ','), ('extra', 'extra'), ('input', 'input'), (',', ','), ('representation', 'represent'), ('extracted', 'extract'), ('deep', 'deep'), ('convolution', 'convolut'), ('neural', 'neural'), ('network', 'network'), ('(', '('), ('CNN', 'cnn'), (')', ')'), ('test', 'test'), ('image', 'imag'), (',', ','), ('RNN', 'rnn'), ('trained', 'train'), ('‘', '‘'), ('translate', 'translat'), ('’', '’'), ('high-level', 'high-level'), ('representations', 'represent'), ('images', 'imag'), ('captions', 'caption'), ('(', '('), ('top', 'top'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Captions', 'Captions'), ('generated', 'generated'), ('recurrent', 'recurrent'), ('neural', 'neural'), ('network', 'network'), ('(', '('), ('RNN', 'RNN'), (')', ')'), ('taking', 'taking'), (',', ','), ('extra', 'extra'), ('input', 'input'), (',', ','), ('representation', 'representation'), ('extracted', 'extracted'), ('deep', 'deep'), ('convolution', 'convolution'), ('neural', 'neural'), ('network', 'network'), ('(', '('), ('CNN', 'CNN'), (')', ')'), ('test', 'test'), ('image', 'image'), (',', ','), ('RNN', 'RNN'), ('trained', 'trained'), ('‘', '‘'), ('translate', 'translate'), ('’', '’'), ('high-level', 'high-level'), ('representations', 'representation'), ('images', 'image'), ('captions', 'caption'), ('(', '('), ('top', 'top'), (')', ')'), ('.', '.')]


------------------- Sentence 3 -------------------

Reproduced

>> Tokens are: 
 ['Reproduced']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Reproduced', 'VBN')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Reproduced', 'reproduc')]

>> Stemming using Snowball Stemmer: 
 [('Reproduced', 'reproduc')]

>> Lemmatization: 
 [('Reproduced', 'Reproduced')]



========================================== PARAGRAPH 138 ===========================================

with permission from ref. 102. When the RNN is given the ability to focus its  attention on a different location in the input image (middle and bottom; the  lighter patches were given more attention) as it generates each word (bold), we  found86 that it exploits this to achieve better ‘translation’ of images into captions. 

------------------- Sentence 1 -------------------

with permission from ref.

>> Tokens are: 
 ['permission', 'ref', '.']

>> Bigrams are: 
 [('permission', 'ref'), ('ref', '.')]

>> Trigrams are: 
 [('permission', 'ref', '.')]

>> POS Tags are: 
 [('permission', 'NN'), ('ref', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['permission ref']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('permission', 'permiss'), ('ref', 'ref'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('permission', 'permiss'), ('ref', 'ref'), ('.', '.')]

>> Lemmatization: 
 [('permission', 'permission'), ('ref', 'ref'), ('.', '.')]


------------------- Sentence 2 -------------------

102.

>> Tokens are: 
 ['102', '.']

>> Bigrams are: 
 [('102', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('102', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('102', '102'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('102', '102'), ('.', '.')]

>> Lemmatization: 
 [('102', '102'), ('.', '.')]


------------------- Sentence 3 -------------------

When the RNN is given the ability to focus its  attention on a different location in the input image (middle and bottom; the  lighter patches were given more attention) as it generates each word (bold), we  found86 that it exploits this to achieve better ‘translation’ of images into captions.

>> Tokens are: 
 ['When', 'RNN', 'given', 'ability', 'focus', 'attention', 'different', 'location', 'input', 'image', '(', 'middle', 'bottom', ';', 'lighter', 'patches', 'given', 'attention', ')', 'generates', 'word', '(', 'bold', ')', ',', 'found86', 'exploits', 'achieve', 'better', '‘', 'translation', '’', 'images', 'captions', '.']

>> Bigrams are: 
 [('When', 'RNN'), ('RNN', 'given'), ('given', 'ability'), ('ability', 'focus'), ('focus', 'attention'), ('attention', 'different'), ('different', 'location'), ('location', 'input'), ('input', 'image'), ('image', '('), ('(', 'middle'), ('middle', 'bottom'), ('bottom', ';'), (';', 'lighter'), ('lighter', 'patches'), ('patches', 'given'), ('given', 'attention'), ('attention', ')'), (')', 'generates'), ('generates', 'word'), ('word', '('), ('(', 'bold'), ('bold', ')'), (')', ','), (',', 'found86'), ('found86', 'exploits'), ('exploits', 'achieve'), ('achieve', 'better'), ('better', '‘'), ('‘', 'translation'), ('translation', '’'), ('’', 'images'), ('images', 'captions'), ('captions', '.')]

>> Trigrams are: 
 [('When', 'RNN', 'given'), ('RNN', 'given', 'ability'), ('given', 'ability', 'focus'), ('ability', 'focus', 'attention'), ('focus', 'attention', 'different'), ('attention', 'different', 'location'), ('different', 'location', 'input'), ('location', 'input', 'image'), ('input', 'image', '('), ('image', '(', 'middle'), ('(', 'middle', 'bottom'), ('middle', 'bottom', ';'), ('bottom', ';', 'lighter'), (';', 'lighter', 'patches'), ('lighter', 'patches', 'given'), ('patches', 'given', 'attention'), ('given', 'attention', ')'), ('attention', ')', 'generates'), (')', 'generates', 'word'), ('generates', 'word', '('), ('word', '(', 'bold'), ('(', 'bold', ')'), ('bold', ')', ','), (')', ',', 'found86'), (',', 'found86', 'exploits'), ('found86', 'exploits', 'achieve'), ('exploits', 'achieve', 'better'), ('achieve', 'better', '‘'), ('better', '‘', 'translation'), ('‘', 'translation', '’'), ('translation', '’', 'images'), ('’', 'images', 'captions'), ('images', 'captions', '.')]

>> POS Tags are: 
 [('When', 'WRB'), ('RNN', 'NNP'), ('given', 'VBN'), ('ability', 'NN'), ('focus', 'NN'), ('attention', 'NN'), ('different', 'JJ'), ('location', 'NN'), ('input', 'NN'), ('image', 'NN'), ('(', '('), ('middle', 'JJ'), ('bottom', 'NN'), (';', ':'), ('lighter', 'JJR'), ('patches', 'NNS'), ('given', 'VBN'), ('attention', 'NN'), (')', ')'), ('generates', 'VBZ'), ('word', 'NN'), ('(', '('), ('bold', 'JJ'), (')', ')'), (',', ','), ('found86', 'JJ'), ('exploits', 'NNS'), ('achieve', 'VBP'), ('better', 'JJR'), ('‘', 'JJ'), ('translation', 'NN'), ('’', 'NN'), ('images', 'NNS'), ('captions', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['RNN', 'ability focus attention', 'different location input image', 'middle bottom', 'patches', 'attention', 'word', 'found86 exploits', '‘ translation ’ images captions']

>> Named Entities are: 
 [('ORGANIZATION', 'RNN')] 

>> Stemming using Porter Stemmer: 
 [('When', 'when'), ('RNN', 'rnn'), ('given', 'given'), ('ability', 'abil'), ('focus', 'focu'), ('attention', 'attent'), ('different', 'differ'), ('location', 'locat'), ('input', 'input'), ('image', 'imag'), ('(', '('), ('middle', 'middl'), ('bottom', 'bottom'), (';', ';'), ('lighter', 'lighter'), ('patches', 'patch'), ('given', 'given'), ('attention', 'attent'), (')', ')'), ('generates', 'gener'), ('word', 'word'), ('(', '('), ('bold', 'bold'), (')', ')'), (',', ','), ('found86', 'found86'), ('exploits', 'exploit'), ('achieve', 'achiev'), ('better', 'better'), ('‘', '‘'), ('translation', 'translat'), ('’', '’'), ('images', 'imag'), ('captions', 'caption'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('When', 'when'), ('RNN', 'rnn'), ('given', 'given'), ('ability', 'abil'), ('focus', 'focus'), ('attention', 'attent'), ('different', 'differ'), ('location', 'locat'), ('input', 'input'), ('image', 'imag'), ('(', '('), ('middle', 'middl'), ('bottom', 'bottom'), (';', ';'), ('lighter', 'lighter'), ('patches', 'patch'), ('given', 'given'), ('attention', 'attent'), (')', ')'), ('generates', 'generat'), ('word', 'word'), ('(', '('), ('bold', 'bold'), (')', ')'), (',', ','), ('found86', 'found86'), ('exploits', 'exploit'), ('achieve', 'achiev'), ('better', 'better'), ('‘', '‘'), ('translation', 'translat'), ('’', '’'), ('images', 'imag'), ('captions', 'caption'), ('.', '.')]

>> Lemmatization: 
 [('When', 'When'), ('RNN', 'RNN'), ('given', 'given'), ('ability', 'ability'), ('focus', 'focus'), ('attention', 'attention'), ('different', 'different'), ('location', 'location'), ('input', 'input'), ('image', 'image'), ('(', '('), ('middle', 'middle'), ('bottom', 'bottom'), (';', ';'), ('lighter', 'lighter'), ('patches', 'patch'), ('given', 'given'), ('attention', 'attention'), (')', ')'), ('generates', 'generates'), ('word', 'word'), ('(', '('), ('bold', 'bold'), (')', ')'), (',', ','), ('found86', 'found86'), ('exploits', 'exploit'), ('achieve', 'achieve'), ('better', 'better'), ('‘', '‘'), ('translation', 'translation'), ('’', '’'), ('images', 'image'), ('captions', 'caption'), ('.', '.')]



========================================== PARAGRAPH 139 ===========================================

Vision Deep CNN 

------------------- Sentence 1 -------------------

Vision Deep CNN

>> Tokens are: 
 ['Vision', 'Deep', 'CNN']

>> Bigrams are: 
 [('Vision', 'Deep'), ('Deep', 'CNN')]

>> Trigrams are: 
 [('Vision', 'Deep', 'CNN')]

>> POS Tags are: 
 [('Vision', 'NNP'), ('Deep', 'NNP'), ('CNN', 'NNP')]

>> Noun Phrases are: 
 ['Vision Deep CNN']

>> Named Entities are: 
 [('PERSON', 'Vision'), ('ORGANIZATION', 'Deep')] 

>> Stemming using Porter Stemmer: 
 [('Vision', 'vision'), ('Deep', 'deep'), ('CNN', 'cnn')]

>> Stemming using Snowball Stemmer: 
 [('Vision', 'vision'), ('Deep', 'deep'), ('CNN', 'cnn')]

>> Lemmatization: 
 [('Vision', 'Vision'), ('Deep', 'Deep'), ('CNN', 'CNN')]



========================================== PARAGRAPH 140 ===========================================

Language Generating RNN 

------------------- Sentence 1 -------------------

Language Generating RNN

>> Tokens are: 
 ['Language', 'Generating', 'RNN']

>> Bigrams are: 
 [('Language', 'Generating'), ('Generating', 'RNN')]

>> Trigrams are: 
 [('Language', 'Generating', 'RNN')]

>> POS Tags are: 
 [('Language', 'NN'), ('Generating', 'VBG'), ('RNN', 'NNP')]

>> Noun Phrases are: 
 ['Language', 'RNN']

>> Named Entities are: 
 [('ORGANIZATION', 'RNN')] 

>> Stemming using Porter Stemmer: 
 [('Language', 'languag'), ('Generating', 'gener'), ('RNN', 'rnn')]

>> Stemming using Snowball Stemmer: 
 [('Language', 'languag'), ('Generating', 'generat'), ('RNN', 'rnn')]

>> Lemmatization: 
 [('Language', 'Language'), ('Generating', 'Generating'), ('RNN', 'RNN')]



========================================== PARAGRAPH 141 ===========================================

A group of people  shopping at an outdoor  

------------------- Sentence 1 -------------------

A group of people  shopping at an outdoor

>> Tokens are: 
 ['A', 'group', 'people', 'shopping', 'outdoor']

>> Bigrams are: 
 [('A', 'group'), ('group', 'people'), ('people', 'shopping'), ('shopping', 'outdoor')]

>> Trigrams are: 
 [('A', 'group', 'people'), ('group', 'people', 'shopping'), ('people', 'shopping', 'outdoor')]

>> POS Tags are: 
 [('A', 'DT'), ('group', 'NN'), ('people', 'NNS'), ('shopping', 'VBG'), ('outdoor', 'NN')]

>> Noun Phrases are: 
 ['A group people', 'outdoor']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('A', 'a'), ('group', 'group'), ('people', 'peopl'), ('shopping', 'shop'), ('outdoor', 'outdoor')]

>> Stemming using Snowball Stemmer: 
 [('A', 'a'), ('group', 'group'), ('people', 'peopl'), ('shopping', 'shop'), ('outdoor', 'outdoor')]

>> Lemmatization: 
 [('A', 'A'), ('group', 'group'), ('people', 'people'), ('shopping', 'shopping'), ('outdoor', 'outdoor')]



========================================== PARAGRAPH 142 ===========================================

market. 

------------------- Sentence 1 -------------------

market.

>> Tokens are: 
 ['market', '.']

>> Bigrams are: 
 [('market', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('market', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['market']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('market', 'market'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('market', 'market'), ('.', '.')]

>> Lemmatization: 
 [('market', 'market'), ('.', '.')]



========================================== PARAGRAPH 143 ===========================================

There are many  vegetables at the  

------------------- Sentence 1 -------------------

There are many  vegetables at the

>> Tokens are: 
 ['There', 'many', 'vegetables']

>> Bigrams are: 
 [('There', 'many'), ('many', 'vegetables')]

>> Trigrams are: 
 [('There', 'many', 'vegetables')]

>> POS Tags are: 
 [('There', 'EX'), ('many', 'JJ'), ('vegetables', 'NNS')]

>> Noun Phrases are: 
 ['many vegetables']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('There', 'there'), ('many', 'mani'), ('vegetables', 'veget')]

>> Stemming using Snowball Stemmer: 
 [('There', 'there'), ('many', 'mani'), ('vegetables', 'veget')]

>> Lemmatization: 
 [('There', 'There'), ('many', 'many'), ('vegetables', 'vegetable')]



========================================== PARAGRAPH 144 ===========================================

fruit stand. 

------------------- Sentence 1 -------------------

fruit stand.

>> Tokens are: 
 ['fruit', 'stand', '.']

>> Bigrams are: 
 [('fruit', 'stand'), ('stand', '.')]

>> Trigrams are: 
 [('fruit', 'stand', '.')]

>> POS Tags are: 
 [('fruit', 'NN'), ('stand', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['fruit stand']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('fruit', 'fruit'), ('stand', 'stand'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('fruit', 'fruit'), ('stand', 'stand'), ('.', '.')]

>> Lemmatization: 
 [('fruit', 'fruit'), ('stand', 'stand'), ('.', '.')]



========================================== PARAGRAPH 145 ===========================================

A woman is throwing a frisbee in a park. 

------------------- Sentence 1 -------------------

A woman is throwing a frisbee in a park.

>> Tokens are: 
 ['A', 'woman', 'throwing', 'frisbee', 'park', '.']

>> Bigrams are: 
 [('A', 'woman'), ('woman', 'throwing'), ('throwing', 'frisbee'), ('frisbee', 'park'), ('park', '.')]

>> Trigrams are: 
 [('A', 'woman', 'throwing'), ('woman', 'throwing', 'frisbee'), ('throwing', 'frisbee', 'park'), ('frisbee', 'park', '.')]

>> POS Tags are: 
 [('A', 'DT'), ('woman', 'NN'), ('throwing', 'VBG'), ('frisbee', 'NN'), ('park', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['A woman', 'frisbee park']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('A', 'a'), ('woman', 'woman'), ('throwing', 'throw'), ('frisbee', 'frisbe'), ('park', 'park'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('A', 'a'), ('woman', 'woman'), ('throwing', 'throw'), ('frisbee', 'frisbe'), ('park', 'park'), ('.', '.')]

>> Lemmatization: 
 [('A', 'A'), ('woman', 'woman'), ('throwing', 'throwing'), ('frisbee', 'frisbee'), ('park', 'park'), ('.', '.')]



========================================== PARAGRAPH 146 ===========================================

A little girl sitting on a bed with a teddy bear. A group of people sitting on a boat in the water. A gira�e standing in a forest with trees in the background. 

------------------- Sentence 1 -------------------

A little girl sitting on a bed with a teddy bear.

>> Tokens are: 
 ['A', 'little', 'girl', 'sitting', 'bed', 'teddy', 'bear', '.']

>> Bigrams are: 
 [('A', 'little'), ('little', 'girl'), ('girl', 'sitting'), ('sitting', 'bed'), ('bed', 'teddy'), ('teddy', 'bear'), ('bear', '.')]

>> Trigrams are: 
 [('A', 'little', 'girl'), ('little', 'girl', 'sitting'), ('girl', 'sitting', 'bed'), ('sitting', 'bed', 'teddy'), ('bed', 'teddy', 'bear'), ('teddy', 'bear', '.')]

>> POS Tags are: 
 [('A', 'DT'), ('little', 'JJ'), ('girl', 'NN'), ('sitting', 'VBG'), ('bed', 'VBD'), ('teddy', 'JJ'), ('bear', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['A little girl', 'teddy bear']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('A', 'a'), ('little', 'littl'), ('girl', 'girl'), ('sitting', 'sit'), ('bed', 'bed'), ('teddy', 'teddi'), ('bear', 'bear'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('A', 'a'), ('little', 'littl'), ('girl', 'girl'), ('sitting', 'sit'), ('bed', 'bed'), ('teddy', 'teddi'), ('bear', 'bear'), ('.', '.')]

>> Lemmatization: 
 [('A', 'A'), ('little', 'little'), ('girl', 'girl'), ('sitting', 'sitting'), ('bed', 'bed'), ('teddy', 'teddy'), ('bear', 'bear'), ('.', '.')]


------------------- Sentence 2 -------------------

A group of people sitting on a boat in the water.

>> Tokens are: 
 ['A', 'group', 'people', 'sitting', 'boat', 'water', '.']

>> Bigrams are: 
 [('A', 'group'), ('group', 'people'), ('people', 'sitting'), ('sitting', 'boat'), ('boat', 'water'), ('water', '.')]

>> Trigrams are: 
 [('A', 'group', 'people'), ('group', 'people', 'sitting'), ('people', 'sitting', 'boat'), ('sitting', 'boat', 'water'), ('boat', 'water', '.')]

>> POS Tags are: 
 [('A', 'DT'), ('group', 'NN'), ('people', 'NNS'), ('sitting', 'VBG'), ('boat', 'NN'), ('water', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['A group people', 'boat water']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('A', 'a'), ('group', 'group'), ('people', 'peopl'), ('sitting', 'sit'), ('boat', 'boat'), ('water', 'water'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('A', 'a'), ('group', 'group'), ('people', 'peopl'), ('sitting', 'sit'), ('boat', 'boat'), ('water', 'water'), ('.', '.')]

>> Lemmatization: 
 [('A', 'A'), ('group', 'group'), ('people', 'people'), ('sitting', 'sitting'), ('boat', 'boat'), ('water', 'water'), ('.', '.')]


------------------- Sentence 3 -------------------

A gira�e standing in a forest with trees in the background.

>> Tokens are: 
 ['A', 'gira�e', 'standing', 'forest', 'trees', 'background', '.']

>> Bigrams are: 
 [('A', 'gira�e'), ('gira�e', 'standing'), ('standing', 'forest'), ('forest', 'trees'), ('trees', 'background'), ('background', '.')]

>> Trigrams are: 
 [('A', 'gira�e', 'standing'), ('gira�e', 'standing', 'forest'), ('standing', 'forest', 'trees'), ('forest', 'trees', 'background'), ('trees', 'background', '.')]

>> POS Tags are: 
 [('A', 'DT'), ('gira�e', 'NN'), ('standing', 'VBG'), ('forest', 'JJS'), ('trees', 'NNS'), ('background', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['A gira�e', 'trees background']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('A', 'a'), ('gira�e', 'gira�'), ('standing', 'stand'), ('forest', 'forest'), ('trees', 'tree'), ('background', 'background'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('A', 'a'), ('gira�e', 'gira�'), ('standing', 'stand'), ('forest', 'forest'), ('trees', 'tree'), ('background', 'background'), ('.', '.')]

>> Lemmatization: 
 [('A', 'A'), ('gira�e', 'gira�e'), ('standing', 'standing'), ('forest', 'forest'), ('trees', 'tree'), ('background', 'background'), ('.', '.')]



========================================== PARAGRAPH 147 ===========================================

A dog is standing on a hardwood �oor. A stop sign is on a road with a mountain in the background 

------------------- Sentence 1 -------------------

A dog is standing on a hardwood �oor.

>> Tokens are: 
 ['A', 'dog', 'standing', 'hardwood', '�oor', '.']

>> Bigrams are: 
 [('A', 'dog'), ('dog', 'standing'), ('standing', 'hardwood'), ('hardwood', '�oor'), ('�oor', '.')]

>> Trigrams are: 
 [('A', 'dog', 'standing'), ('dog', 'standing', 'hardwood'), ('standing', 'hardwood', '�oor'), ('hardwood', '�oor', '.')]

>> POS Tags are: 
 [('A', 'DT'), ('dog', 'NN'), ('standing', 'VBG'), ('hardwood', 'NN'), ('�oor', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['A dog', 'hardwood �oor']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('A', 'a'), ('dog', 'dog'), ('standing', 'stand'), ('hardwood', 'hardwood'), ('�oor', '�oor'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('A', 'a'), ('dog', 'dog'), ('standing', 'stand'), ('hardwood', 'hardwood'), ('�oor', '�oor'), ('.', '.')]

>> Lemmatization: 
 [('A', 'A'), ('dog', 'dog'), ('standing', 'standing'), ('hardwood', 'hardwood'), ('�oor', '�oor'), ('.', '.')]


------------------- Sentence 2 -------------------

A stop sign is on a road with a mountain in the background

>> Tokens are: 
 ['A', 'stop', 'sign', 'road', 'mountain', 'background']

>> Bigrams are: 
 [('A', 'stop'), ('stop', 'sign'), ('sign', 'road'), ('road', 'mountain'), ('mountain', 'background')]

>> Trigrams are: 
 [('A', 'stop', 'sign'), ('stop', 'sign', 'road'), ('sign', 'road', 'mountain'), ('road', 'mountain', 'background')]

>> POS Tags are: 
 [('A', 'DT'), ('stop', 'JJ'), ('sign', 'NN'), ('road', 'NN'), ('mountain', 'NN'), ('background', 'NN')]

>> Noun Phrases are: 
 ['A stop sign road mountain background']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('A', 'a'), ('stop', 'stop'), ('sign', 'sign'), ('road', 'road'), ('mountain', 'mountain'), ('background', 'background')]

>> Stemming using Snowball Stemmer: 
 [('A', 'a'), ('stop', 'stop'), ('sign', 'sign'), ('road', 'road'), ('mountain', 'mountain'), ('background', 'background')]

>> Lemmatization: 
 [('A', 'A'), ('stop', 'stop'), ('sign', 'sign'), ('road', 'road'), ('mountain', 'mountain'), ('background', 'background')]



========================================== PARAGRAPH 148 ===========================================

4 4 0  |  N A T U R E  |  V O L  5 2 1  |  2 8  M A Y  2 0 1 5 

------------------- Sentence 1 -------------------

4 4 0  |  N A T U R E  |  V O L  5 2 1  |  2 8  M A Y  2 0 1 5

>> Tokens are: 
 ['4', '4', '0', '|', 'N', 'A', 'T', 'U', 'R', 'E', '|', 'V', 'O', 'L', '5', '2', '1', '|', '2', '8', 'M', 'A', 'Y', '2', '0', '1', '5']

>> Bigrams are: 
 [('4', '4'), ('4', '0'), ('0', '|'), ('|', 'N'), ('N', 'A'), ('A', 'T'), ('T', 'U'), ('U', 'R'), ('R', 'E'), ('E', '|'), ('|', 'V'), ('V', 'O'), ('O', 'L'), ('L', '5'), ('5', '2'), ('2', '1'), ('1', '|'), ('|', '2'), ('2', '8'), ('8', 'M'), ('M', 'A'), ('A', 'Y'), ('Y', '2'), ('2', '0'), ('0', '1'), ('1', '5')]

>> Trigrams are: 
 [('4', '4', '0'), ('4', '0', '|'), ('0', '|', 'N'), ('|', 'N', 'A'), ('N', 'A', 'T'), ('A', 'T', 'U'), ('T', 'U', 'R'), ('U', 'R', 'E'), ('R', 'E', '|'), ('E', '|', 'V'), ('|', 'V', 'O'), ('V', 'O', 'L'), ('O', 'L', '5'), ('L', '5', '2'), ('5', '2', '1'), ('2', '1', '|'), ('1', '|', '2'), ('|', '2', '8'), ('2', '8', 'M'), ('8', 'M', 'A'), ('M', 'A', 'Y'), ('A', 'Y', '2'), ('Y', '2', '0'), ('2', '0', '1'), ('0', '1', '5')]

>> POS Tags are: 
 [('4', 'CD'), ('4', 'CD'), ('0', 'CD'), ('|', 'NN'), ('N', 'NNP'), ('A', 'NNP'), ('T', 'NNP'), ('U', 'NNP'), ('R', 'NNP'), ('E', 'NNP'), ('|', 'NNP'), ('V', 'NNP'), ('O', 'NNP'), ('L', 'NNP'), ('5', 'CD'), ('2', 'CD'), ('1', 'CD'), ('|', 'NN'), ('2', 'CD'), ('8', 'CD'), ('M', 'NNP'), ('A', 'NNP'), ('Y', 'NNP'), ('2', 'CD'), ('0', 'CD'), ('1', 'CD'), ('5', 'CD')]

>> Noun Phrases are: 
 ['| N A T U R E | V O L', '|', 'M A Y']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('4', '4'), ('4', '4'), ('0', '0'), ('|', '|'), ('N', 'n'), ('A', 'a'), ('T', 't'), ('U', 'u'), ('R', 'r'), ('E', 'e'), ('|', '|'), ('V', 'v'), ('O', 'o'), ('L', 'l'), ('5', '5'), ('2', '2'), ('1', '1'), ('|', '|'), ('2', '2'), ('8', '8'), ('M', 'm'), ('A', 'a'), ('Y', 'y'), ('2', '2'), ('0', '0'), ('1', '1'), ('5', '5')]

>> Stemming using Snowball Stemmer: 
 [('4', '4'), ('4', '4'), ('0', '0'), ('|', '|'), ('N', 'n'), ('A', 'a'), ('T', 't'), ('U', 'u'), ('R', 'r'), ('E', 'e'), ('|', '|'), ('V', 'v'), ('O', 'o'), ('L', 'l'), ('5', '5'), ('2', '2'), ('1', '1'), ('|', '|'), ('2', '2'), ('8', '8'), ('M', 'm'), ('A', 'a'), ('Y', 'y'), ('2', '2'), ('0', '0'), ('1', '1'), ('5', '5')]

>> Lemmatization: 
 [('4', '4'), ('4', '4'), ('0', '0'), ('|', '|'), ('N', 'N'), ('A', 'A'), ('T', 'T'), ('U', 'U'), ('R', 'R'), ('E', 'E'), ('|', '|'), ('V', 'V'), ('O', 'O'), ('L', 'L'), ('5', '5'), ('2', '2'), ('1', '1'), ('|', '|'), ('2', '2'), ('8', '8'), ('M', 'M'), ('A', 'A'), ('Y', 'Y'), ('2', '2'), ('0', '0'), ('1', '1'), ('5', '5')]



========================================== PARAGRAPH 149 ===========================================

REVIEWINSIGHT 

------------------- Sentence 1 -------------------

REVIEWINSIGHT

>> Tokens are: 
 ['REVIEWINSIGHT']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('REVIEWINSIGHT', 'NN')]

>> Noun Phrases are: 
 ['REVIEWINSIGHT']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('REVIEWINSIGHT', 'reviewinsight')]

>> Stemming using Snowball Stemmer: 
 [('REVIEWINSIGHT', 'reviewinsight')]

>> Lemmatization: 
 [('REVIEWINSIGHT', 'REVIEWINSIGHT')]



========================================== PARAGRAPH 150 ===========================================

© 2015 Macmillan Publishers Limited. All rights reserved

------------------- Sentence 1 -------------------

© 2015 Macmillan Publishers Limited.

>> Tokens are: 
 ['©', '2015', 'Macmillan', 'Publishers', 'Limited', '.']

>> Bigrams are: 
 [('©', '2015'), ('2015', 'Macmillan'), ('Macmillan', 'Publishers'), ('Publishers', 'Limited'), ('Limited', '.')]

>> Trigrams are: 
 [('©', '2015', 'Macmillan'), ('2015', 'Macmillan', 'Publishers'), ('Macmillan', 'Publishers', 'Limited'), ('Publishers', 'Limited', '.')]

>> POS Tags are: 
 [('©', 'NN'), ('2015', 'CD'), ('Macmillan', 'NNP'), ('Publishers', 'NNP'), ('Limited', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['©', 'Macmillan Publishers Limited']

>> Named Entities are: 
 [('PERSON', 'Macmillan Publishers Limited')] 

>> Stemming using Porter Stemmer: 
 [('©', '©'), ('2015', '2015'), ('Macmillan', 'macmillan'), ('Publishers', 'publish'), ('Limited', 'limit'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('©', '©'), ('2015', '2015'), ('Macmillan', 'macmillan'), ('Publishers', 'publish'), ('Limited', 'limit'), ('.', '.')]

>> Lemmatization: 
 [('©', '©'), ('2015', '2015'), ('Macmillan', 'Macmillan'), ('Publishers', 'Publishers'), ('Limited', 'Limited'), ('.', '.')]


------------------- Sentence 2 -------------------

All rights reserved

>> Tokens are: 
 ['All', 'rights', 'reserved']

>> Bigrams are: 
 [('All', 'rights'), ('rights', 'reserved')]

>> Trigrams are: 
 [('All', 'rights', 'reserved')]

>> POS Tags are: 
 [('All', 'DT'), ('rights', 'NNS'), ('reserved', 'VBN')]

>> Noun Phrases are: 
 ['All rights']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('All', 'all'), ('rights', 'right'), ('reserved', 'reserv')]

>> Stemming using Snowball Stemmer: 
 [('All', 'all'), ('rights', 'right'), ('reserved', 'reserv')]

>> Lemmatization: 
 [('All', 'All'), ('rights', 'right'), ('reserved', 'reserved')]



========================================== PARAGRAPH 151 ===========================================

context of earlier words71. Each word in the context is presented to  the network as a one-of-N vector, that is, one component has a value  of 1 and the rest are 0. In the first layer, each word creates a different  pattern of activations, or word vectors (Fig. 4). In a language model,  the other layers of the network learn to convert the input word vec- tors into an output word vector for the predicted next word, which  can be used to predict the probability for any word in the vocabulary  to appear as the next word. The network learns word vectors that  contain many active components each of which can be interpreted  as a separate feature of the word, as was first demonstrated27 in the  context of learning distributed representations for symbols. These  semantic features were not explicitly present in the input. They were  discovered by the learning procedure as a good way of factorizing  the structured relationships between the input and output symbols  into multiple ‘micro-rules’. Learning word vectors turned out to also  work very well when the word sequences come from a large corpus  of real text and the individual micro-rules are unreliable71. When  trained to predict the next word in a news story, for example, the  learned word vectors for Tuesday and Wednesday are very similar, as  are the word vectors for Sweden and Norway. Such representations  are called distributed representations because their elements (the  features) are not mutually exclusive and their many configurations  correspond to the variations seen in the observed data. These word  vectors are composed of learned features that were not determined  ahead of time by experts, but automatically discovered by the neural  network. Vector representations of words learned from text are now  very widely used in natural language applications14,17,72–76.  

------------------- Sentence 1 -------------------

context of earlier words71.

>> Tokens are: 
 ['context', 'earlier', 'words71', '.']

>> Bigrams are: 
 [('context', 'earlier'), ('earlier', 'words71'), ('words71', '.')]

>> Trigrams are: 
 [('context', 'earlier', 'words71'), ('earlier', 'words71', '.')]

>> POS Tags are: 
 [('context', 'NN'), ('earlier', 'RBR'), ('words71', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['context', 'words71']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('context', 'context'), ('earlier', 'earlier'), ('words71', 'words71'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('context', 'context'), ('earlier', 'earlier'), ('words71', 'words71'), ('.', '.')]

>> Lemmatization: 
 [('context', 'context'), ('earlier', 'earlier'), ('words71', 'words71'), ('.', '.')]


------------------- Sentence 2 -------------------

Each word in the context is presented to  the network as a one-of-N vector, that is, one component has a value  of 1 and the rest are 0.

>> Tokens are: 
 ['Each', 'word', 'context', 'presented', 'network', 'one-of-N', 'vector', ',', ',', 'one', 'component', 'value', '1', 'rest', '0', '.']

>> Bigrams are: 
 [('Each', 'word'), ('word', 'context'), ('context', 'presented'), ('presented', 'network'), ('network', 'one-of-N'), ('one-of-N', 'vector'), ('vector', ','), (',', ','), (',', 'one'), ('one', 'component'), ('component', 'value'), ('value', '1'), ('1', 'rest'), ('rest', '0'), ('0', '.')]

>> Trigrams are: 
 [('Each', 'word', 'context'), ('word', 'context', 'presented'), ('context', 'presented', 'network'), ('presented', 'network', 'one-of-N'), ('network', 'one-of-N', 'vector'), ('one-of-N', 'vector', ','), ('vector', ',', ','), (',', ',', 'one'), (',', 'one', 'component'), ('one', 'component', 'value'), ('component', 'value', '1'), ('value', '1', 'rest'), ('1', 'rest', '0'), ('rest', '0', '.')]

>> POS Tags are: 
 [('Each', 'DT'), ('word', 'NN'), ('context', 'NN'), ('presented', 'VBN'), ('network', 'NN'), ('one-of-N', 'JJ'), ('vector', 'NN'), (',', ','), (',', ','), ('one', 'CD'), ('component', 'NN'), ('value', 'NN'), ('1', 'CD'), ('rest', 'NN'), ('0', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['Each word context', 'network', 'one-of-N vector', 'component value', 'rest']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Each', 'each'), ('word', 'word'), ('context', 'context'), ('presented', 'present'), ('network', 'network'), ('one-of-N', 'one-of-n'), ('vector', 'vector'), (',', ','), (',', ','), ('one', 'one'), ('component', 'compon'), ('value', 'valu'), ('1', '1'), ('rest', 'rest'), ('0', '0'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Each', 'each'), ('word', 'word'), ('context', 'context'), ('presented', 'present'), ('network', 'network'), ('one-of-N', 'one-of-n'), ('vector', 'vector'), (',', ','), (',', ','), ('one', 'one'), ('component', 'compon'), ('value', 'valu'), ('1', '1'), ('rest', 'rest'), ('0', '0'), ('.', '.')]

>> Lemmatization: 
 [('Each', 'Each'), ('word', 'word'), ('context', 'context'), ('presented', 'presented'), ('network', 'network'), ('one-of-N', 'one-of-N'), ('vector', 'vector'), (',', ','), (',', ','), ('one', 'one'), ('component', 'component'), ('value', 'value'), ('1', '1'), ('rest', 'rest'), ('0', '0'), ('.', '.')]


------------------- Sentence 3 -------------------

In the first layer, each word creates a different  pattern of activations, or word vectors (Fig.

>> Tokens are: 
 ['In', 'first', 'layer', ',', 'word', 'creates', 'different', 'pattern', 'activations', ',', 'word', 'vectors', '(', 'Fig', '.']

>> Bigrams are: 
 [('In', 'first'), ('first', 'layer'), ('layer', ','), (',', 'word'), ('word', 'creates'), ('creates', 'different'), ('different', 'pattern'), ('pattern', 'activations'), ('activations', ','), (',', 'word'), ('word', 'vectors'), ('vectors', '('), ('(', 'Fig'), ('Fig', '.')]

>> Trigrams are: 
 [('In', 'first', 'layer'), ('first', 'layer', ','), ('layer', ',', 'word'), (',', 'word', 'creates'), ('word', 'creates', 'different'), ('creates', 'different', 'pattern'), ('different', 'pattern', 'activations'), ('pattern', 'activations', ','), ('activations', ',', 'word'), (',', 'word', 'vectors'), ('word', 'vectors', '('), ('vectors', '(', 'Fig'), ('(', 'Fig', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('first', 'JJ'), ('layer', 'NN'), (',', ','), ('word', 'NN'), ('creates', 'VBZ'), ('different', 'JJ'), ('pattern', 'JJ'), ('activations', 'NNS'), (',', ','), ('word', 'NN'), ('vectors', 'NNS'), ('(', '('), ('Fig', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['first layer', 'word', 'different pattern activations', 'word vectors', 'Fig']

>> Named Entities are: 
 [('ORGANIZATION', 'Fig')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('first', 'first'), ('layer', 'layer'), (',', ','), ('word', 'word'), ('creates', 'creat'), ('different', 'differ'), ('pattern', 'pattern'), ('activations', 'activ'), (',', ','), ('word', 'word'), ('vectors', 'vector'), ('(', '('), ('Fig', 'fig'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('first', 'first'), ('layer', 'layer'), (',', ','), ('word', 'word'), ('creates', 'creat'), ('different', 'differ'), ('pattern', 'pattern'), ('activations', 'activ'), (',', ','), ('word', 'word'), ('vectors', 'vector'), ('(', '('), ('Fig', 'fig'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('first', 'first'), ('layer', 'layer'), (',', ','), ('word', 'word'), ('creates', 'creates'), ('different', 'different'), ('pattern', 'pattern'), ('activations', 'activation'), (',', ','), ('word', 'word'), ('vectors', 'vector'), ('(', '('), ('Fig', 'Fig'), ('.', '.')]


------------------- Sentence 4 -------------------

4).

>> Tokens are: 
 ['4', ')', '.']

>> Bigrams are: 
 [('4', ')'), (')', '.')]

>> Trigrams are: 
 [('4', ')', '.')]

>> POS Tags are: 
 [('4', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('4', '4'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('4', '4'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('4', '4'), (')', ')'), ('.', '.')]


------------------- Sentence 5 -------------------

In a language model,  the other layers of the network learn to convert the input word vec- tors into an output word vector for the predicted next word, which  can be used to predict the probability for any word in the vocabulary  to appear as the next word.

>> Tokens are: 
 ['In', 'language', 'model', ',', 'layers', 'network', 'learn', 'convert', 'input', 'word', 'vec-', 'tors', 'output', 'word', 'vector', 'predicted', 'next', 'word', ',', 'used', 'predict', 'probability', 'word', 'vocabulary', 'appear', 'next', 'word', '.']

>> Bigrams are: 
 [('In', 'language'), ('language', 'model'), ('model', ','), (',', 'layers'), ('layers', 'network'), ('network', 'learn'), ('learn', 'convert'), ('convert', 'input'), ('input', 'word'), ('word', 'vec-'), ('vec-', 'tors'), ('tors', 'output'), ('output', 'word'), ('word', 'vector'), ('vector', 'predicted'), ('predicted', 'next'), ('next', 'word'), ('word', ','), (',', 'used'), ('used', 'predict'), ('predict', 'probability'), ('probability', 'word'), ('word', 'vocabulary'), ('vocabulary', 'appear'), ('appear', 'next'), ('next', 'word'), ('word', '.')]

>> Trigrams are: 
 [('In', 'language', 'model'), ('language', 'model', ','), ('model', ',', 'layers'), (',', 'layers', 'network'), ('layers', 'network', 'learn'), ('network', 'learn', 'convert'), ('learn', 'convert', 'input'), ('convert', 'input', 'word'), ('input', 'word', 'vec-'), ('word', 'vec-', 'tors'), ('vec-', 'tors', 'output'), ('tors', 'output', 'word'), ('output', 'word', 'vector'), ('word', 'vector', 'predicted'), ('vector', 'predicted', 'next'), ('predicted', 'next', 'word'), ('next', 'word', ','), ('word', ',', 'used'), (',', 'used', 'predict'), ('used', 'predict', 'probability'), ('predict', 'probability', 'word'), ('probability', 'word', 'vocabulary'), ('word', 'vocabulary', 'appear'), ('vocabulary', 'appear', 'next'), ('appear', 'next', 'word'), ('next', 'word', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('language', 'NN'), ('model', 'NN'), (',', ','), ('layers', 'NNS'), ('network', 'NN'), ('learn', 'VBP'), ('convert', 'NN'), ('input', 'NN'), ('word', 'NN'), ('vec-', 'JJ'), ('tors', 'NNS'), ('output', 'NN'), ('word', 'NN'), ('vector', 'NN'), ('predicted', 'VBD'), ('next', 'JJ'), ('word', 'NN'), (',', ','), ('used', 'VBD'), ('predict', 'JJ'), ('probability', 'NN'), ('word', 'NN'), ('vocabulary', 'JJ'), ('appear', 'VBP'), ('next', 'JJ'), ('word', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['language model', 'layers network', 'convert input word', 'vec- tors output word vector', 'next word', 'predict probability word', 'next word']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('language', 'languag'), ('model', 'model'), (',', ','), ('layers', 'layer'), ('network', 'network'), ('learn', 'learn'), ('convert', 'convert'), ('input', 'input'), ('word', 'word'), ('vec-', 'vec-'), ('tors', 'tor'), ('output', 'output'), ('word', 'word'), ('vector', 'vector'), ('predicted', 'predict'), ('next', 'next'), ('word', 'word'), (',', ','), ('used', 'use'), ('predict', 'predict'), ('probability', 'probabl'), ('word', 'word'), ('vocabulary', 'vocabulari'), ('appear', 'appear'), ('next', 'next'), ('word', 'word'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('language', 'languag'), ('model', 'model'), (',', ','), ('layers', 'layer'), ('network', 'network'), ('learn', 'learn'), ('convert', 'convert'), ('input', 'input'), ('word', 'word'), ('vec-', 'vec-'), ('tors', 'tor'), ('output', 'output'), ('word', 'word'), ('vector', 'vector'), ('predicted', 'predict'), ('next', 'next'), ('word', 'word'), (',', ','), ('used', 'use'), ('predict', 'predict'), ('probability', 'probabl'), ('word', 'word'), ('vocabulary', 'vocabulari'), ('appear', 'appear'), ('next', 'next'), ('word', 'word'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('language', 'language'), ('model', 'model'), (',', ','), ('layers', 'layer'), ('network', 'network'), ('learn', 'learn'), ('convert', 'convert'), ('input', 'input'), ('word', 'word'), ('vec-', 'vec-'), ('tors', 'tor'), ('output', 'output'), ('word', 'word'), ('vector', 'vector'), ('predicted', 'predicted'), ('next', 'next'), ('word', 'word'), (',', ','), ('used', 'used'), ('predict', 'predict'), ('probability', 'probability'), ('word', 'word'), ('vocabulary', 'vocabulary'), ('appear', 'appear'), ('next', 'next'), ('word', 'word'), ('.', '.')]


------------------- Sentence 6 -------------------

The network learns word vectors that  contain many active components each of which can be interpreted  as a separate feature of the word, as was first demonstrated27 in the  context of learning distributed representations for symbols.

>> Tokens are: 
 ['The', 'network', 'learns', 'word', 'vectors', 'contain', 'many', 'active', 'components', 'interpreted', 'separate', 'feature', 'word', ',', 'first', 'demonstrated27', 'context', 'learning', 'distributed', 'representations', 'symbols', '.']

>> Bigrams are: 
 [('The', 'network'), ('network', 'learns'), ('learns', 'word'), ('word', 'vectors'), ('vectors', 'contain'), ('contain', 'many'), ('many', 'active'), ('active', 'components'), ('components', 'interpreted'), ('interpreted', 'separate'), ('separate', 'feature'), ('feature', 'word'), ('word', ','), (',', 'first'), ('first', 'demonstrated27'), ('demonstrated27', 'context'), ('context', 'learning'), ('learning', 'distributed'), ('distributed', 'representations'), ('representations', 'symbols'), ('symbols', '.')]

>> Trigrams are: 
 [('The', 'network', 'learns'), ('network', 'learns', 'word'), ('learns', 'word', 'vectors'), ('word', 'vectors', 'contain'), ('vectors', 'contain', 'many'), ('contain', 'many', 'active'), ('many', 'active', 'components'), ('active', 'components', 'interpreted'), ('components', 'interpreted', 'separate'), ('interpreted', 'separate', 'feature'), ('separate', 'feature', 'word'), ('feature', 'word', ','), ('word', ',', 'first'), (',', 'first', 'demonstrated27'), ('first', 'demonstrated27', 'context'), ('demonstrated27', 'context', 'learning'), ('context', 'learning', 'distributed'), ('learning', 'distributed', 'representations'), ('distributed', 'representations', 'symbols'), ('representations', 'symbols', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('network', 'NN'), ('learns', 'VBZ'), ('word', 'NN'), ('vectors', 'NNS'), ('contain', 'VBP'), ('many', 'JJ'), ('active', 'JJ'), ('components', 'NNS'), ('interpreted', 'VBN'), ('separate', 'JJ'), ('feature', 'NN'), ('word', 'NN'), (',', ','), ('first', 'JJ'), ('demonstrated27', 'NN'), ('context', 'NN'), ('learning', 'NN'), ('distributed', 'VBD'), ('representations', 'NNS'), ('symbols', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['The network', 'word vectors', 'many active components', 'separate feature word', 'first demonstrated27 context learning', 'representations symbols']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('network', 'network'), ('learns', 'learn'), ('word', 'word'), ('vectors', 'vector'), ('contain', 'contain'), ('many', 'mani'), ('active', 'activ'), ('components', 'compon'), ('interpreted', 'interpret'), ('separate', 'separ'), ('feature', 'featur'), ('word', 'word'), (',', ','), ('first', 'first'), ('demonstrated27', 'demonstrated27'), ('context', 'context'), ('learning', 'learn'), ('distributed', 'distribut'), ('representations', 'represent'), ('symbols', 'symbol'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('network', 'network'), ('learns', 'learn'), ('word', 'word'), ('vectors', 'vector'), ('contain', 'contain'), ('many', 'mani'), ('active', 'activ'), ('components', 'compon'), ('interpreted', 'interpret'), ('separate', 'separ'), ('feature', 'featur'), ('word', 'word'), (',', ','), ('first', 'first'), ('demonstrated27', 'demonstrated27'), ('context', 'context'), ('learning', 'learn'), ('distributed', 'distribut'), ('representations', 'represent'), ('symbols', 'symbol'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('network', 'network'), ('learns', 'learns'), ('word', 'word'), ('vectors', 'vector'), ('contain', 'contain'), ('many', 'many'), ('active', 'active'), ('components', 'component'), ('interpreted', 'interpreted'), ('separate', 'separate'), ('feature', 'feature'), ('word', 'word'), (',', ','), ('first', 'first'), ('demonstrated27', 'demonstrated27'), ('context', 'context'), ('learning', 'learning'), ('distributed', 'distributed'), ('representations', 'representation'), ('symbols', 'symbol'), ('.', '.')]


------------------- Sentence 7 -------------------

These  semantic features were not explicitly present in the input.

>> Tokens are: 
 ['These', 'semantic', 'features', 'explicitly', 'present', 'input', '.']

>> Bigrams are: 
 [('These', 'semantic'), ('semantic', 'features'), ('features', 'explicitly'), ('explicitly', 'present'), ('present', 'input'), ('input', '.')]

>> Trigrams are: 
 [('These', 'semantic', 'features'), ('semantic', 'features', 'explicitly'), ('features', 'explicitly', 'present'), ('explicitly', 'present', 'input'), ('present', 'input', '.')]

>> POS Tags are: 
 [('These', 'DT'), ('semantic', 'JJ'), ('features', 'NNS'), ('explicitly', 'RB'), ('present', 'JJ'), ('input', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['These semantic features', 'present input']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('These', 'these'), ('semantic', 'semant'), ('features', 'featur'), ('explicitly', 'explicitli'), ('present', 'present'), ('input', 'input'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('These', 'these'), ('semantic', 'semant'), ('features', 'featur'), ('explicitly', 'explicit'), ('present', 'present'), ('input', 'input'), ('.', '.')]

>> Lemmatization: 
 [('These', 'These'), ('semantic', 'semantic'), ('features', 'feature'), ('explicitly', 'explicitly'), ('present', 'present'), ('input', 'input'), ('.', '.')]


------------------- Sentence 8 -------------------

They were  discovered by the learning procedure as a good way of factorizing  the structured relationships between the input and output symbols  into multiple ‘micro-rules’.

>> Tokens are: 
 ['They', 'discovered', 'learning', 'procedure', 'good', 'way', 'factorizing', 'structured', 'relationships', 'input', 'output', 'symbols', 'multiple', '‘', 'micro-rules', '’', '.']

>> Bigrams are: 
 [('They', 'discovered'), ('discovered', 'learning'), ('learning', 'procedure'), ('procedure', 'good'), ('good', 'way'), ('way', 'factorizing'), ('factorizing', 'structured'), ('structured', 'relationships'), ('relationships', 'input'), ('input', 'output'), ('output', 'symbols'), ('symbols', 'multiple'), ('multiple', '‘'), ('‘', 'micro-rules'), ('micro-rules', '’'), ('’', '.')]

>> Trigrams are: 
 [('They', 'discovered', 'learning'), ('discovered', 'learning', 'procedure'), ('learning', 'procedure', 'good'), ('procedure', 'good', 'way'), ('good', 'way', 'factorizing'), ('way', 'factorizing', 'structured'), ('factorizing', 'structured', 'relationships'), ('structured', 'relationships', 'input'), ('relationships', 'input', 'output'), ('input', 'output', 'symbols'), ('output', 'symbols', 'multiple'), ('symbols', 'multiple', '‘'), ('multiple', '‘', 'micro-rules'), ('‘', 'micro-rules', '’'), ('micro-rules', '’', '.')]

>> POS Tags are: 
 [('They', 'PRP'), ('discovered', 'VBD'), ('learning', 'JJ'), ('procedure', 'NN'), ('good', 'JJ'), ('way', 'NN'), ('factorizing', 'VBG'), ('structured', 'VBN'), ('relationships', 'NNS'), ('input', 'VBP'), ('output', 'NN'), ('symbols', 'NNS'), ('multiple', 'JJ'), ('‘', 'NNP'), ('micro-rules', 'NNS'), ('’', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['learning procedure', 'good way', 'relationships', 'output symbols', 'multiple ‘ micro-rules ’']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('They', 'they'), ('discovered', 'discov'), ('learning', 'learn'), ('procedure', 'procedur'), ('good', 'good'), ('way', 'way'), ('factorizing', 'factor'), ('structured', 'structur'), ('relationships', 'relationship'), ('input', 'input'), ('output', 'output'), ('symbols', 'symbol'), ('multiple', 'multipl'), ('‘', '‘'), ('micro-rules', 'micro-rul'), ('’', '’'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('They', 'they'), ('discovered', 'discov'), ('learning', 'learn'), ('procedure', 'procedur'), ('good', 'good'), ('way', 'way'), ('factorizing', 'factor'), ('structured', 'structur'), ('relationships', 'relationship'), ('input', 'input'), ('output', 'output'), ('symbols', 'symbol'), ('multiple', 'multipl'), ('‘', '‘'), ('micro-rules', 'micro-rul'), ('’', '’'), ('.', '.')]

>> Lemmatization: 
 [('They', 'They'), ('discovered', 'discovered'), ('learning', 'learning'), ('procedure', 'procedure'), ('good', 'good'), ('way', 'way'), ('factorizing', 'factorizing'), ('structured', 'structured'), ('relationships', 'relationship'), ('input', 'input'), ('output', 'output'), ('symbols', 'symbol'), ('multiple', 'multiple'), ('‘', '‘'), ('micro-rules', 'micro-rules'), ('’', '’'), ('.', '.')]


------------------- Sentence 9 -------------------

Learning word vectors turned out to also  work very well when the word sequences come from a large corpus  of real text and the individual micro-rules are unreliable71.

>> Tokens are: 
 ['Learning', 'word', 'vectors', 'turned', 'also', 'work', 'well', 'word', 'sequences', 'come', 'large', 'corpus', 'real', 'text', 'individual', 'micro-rules', 'unreliable71', '.']

>> Bigrams are: 
 [('Learning', 'word'), ('word', 'vectors'), ('vectors', 'turned'), ('turned', 'also'), ('also', 'work'), ('work', 'well'), ('well', 'word'), ('word', 'sequences'), ('sequences', 'come'), ('come', 'large'), ('large', 'corpus'), ('corpus', 'real'), ('real', 'text'), ('text', 'individual'), ('individual', 'micro-rules'), ('micro-rules', 'unreliable71'), ('unreliable71', '.')]

>> Trigrams are: 
 [('Learning', 'word', 'vectors'), ('word', 'vectors', 'turned'), ('vectors', 'turned', 'also'), ('turned', 'also', 'work'), ('also', 'work', 'well'), ('work', 'well', 'word'), ('well', 'word', 'sequences'), ('word', 'sequences', 'come'), ('sequences', 'come', 'large'), ('come', 'large', 'corpus'), ('large', 'corpus', 'real'), ('corpus', 'real', 'text'), ('real', 'text', 'individual'), ('text', 'individual', 'micro-rules'), ('individual', 'micro-rules', 'unreliable71'), ('micro-rules', 'unreliable71', '.')]

>> POS Tags are: 
 [('Learning', 'VBG'), ('word', 'NN'), ('vectors', 'NNS'), ('turned', 'VBD'), ('also', 'RB'), ('work', 'NN'), ('well', 'RB'), ('word', 'NN'), ('sequences', 'VBZ'), ('come', 'VBN'), ('large', 'JJ'), ('corpus', 'NN'), ('real', 'JJ'), ('text', 'JJ'), ('individual', 'JJ'), ('micro-rules', 'NNS'), ('unreliable71', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['word vectors', 'work', 'word', 'large corpus', 'real text individual micro-rules unreliable71']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Learning', 'learn'), ('word', 'word'), ('vectors', 'vector'), ('turned', 'turn'), ('also', 'also'), ('work', 'work'), ('well', 'well'), ('word', 'word'), ('sequences', 'sequenc'), ('come', 'come'), ('large', 'larg'), ('corpus', 'corpu'), ('real', 'real'), ('text', 'text'), ('individual', 'individu'), ('micro-rules', 'micro-rul'), ('unreliable71', 'unreliable71'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Learning', 'learn'), ('word', 'word'), ('vectors', 'vector'), ('turned', 'turn'), ('also', 'also'), ('work', 'work'), ('well', 'well'), ('word', 'word'), ('sequences', 'sequenc'), ('come', 'come'), ('large', 'larg'), ('corpus', 'corpus'), ('real', 'real'), ('text', 'text'), ('individual', 'individu'), ('micro-rules', 'micro-rul'), ('unreliable71', 'unreliable71'), ('.', '.')]

>> Lemmatization: 
 [('Learning', 'Learning'), ('word', 'word'), ('vectors', 'vector'), ('turned', 'turned'), ('also', 'also'), ('work', 'work'), ('well', 'well'), ('word', 'word'), ('sequences', 'sequence'), ('come', 'come'), ('large', 'large'), ('corpus', 'corpus'), ('real', 'real'), ('text', 'text'), ('individual', 'individual'), ('micro-rules', 'micro-rules'), ('unreliable71', 'unreliable71'), ('.', '.')]


------------------- Sentence 10 -------------------

When  trained to predict the next word in a news story, for example, the  learned word vectors for Tuesday and Wednesday are very similar, as  are the word vectors for Sweden and Norway.

>> Tokens are: 
 ['When', 'trained', 'predict', 'next', 'word', 'news', 'story', ',', 'example', ',', 'learned', 'word', 'vectors', 'Tuesday', 'Wednesday', 'similar', ',', 'word', 'vectors', 'Sweden', 'Norway', '.']

>> Bigrams are: 
 [('When', 'trained'), ('trained', 'predict'), ('predict', 'next'), ('next', 'word'), ('word', 'news'), ('news', 'story'), ('story', ','), (',', 'example'), ('example', ','), (',', 'learned'), ('learned', 'word'), ('word', 'vectors'), ('vectors', 'Tuesday'), ('Tuesday', 'Wednesday'), ('Wednesday', 'similar'), ('similar', ','), (',', 'word'), ('word', 'vectors'), ('vectors', 'Sweden'), ('Sweden', 'Norway'), ('Norway', '.')]

>> Trigrams are: 
 [('When', 'trained', 'predict'), ('trained', 'predict', 'next'), ('predict', 'next', 'word'), ('next', 'word', 'news'), ('word', 'news', 'story'), ('news', 'story', ','), ('story', ',', 'example'), (',', 'example', ','), ('example', ',', 'learned'), (',', 'learned', 'word'), ('learned', 'word', 'vectors'), ('word', 'vectors', 'Tuesday'), ('vectors', 'Tuesday', 'Wednesday'), ('Tuesday', 'Wednesday', 'similar'), ('Wednesday', 'similar', ','), ('similar', ',', 'word'), (',', 'word', 'vectors'), ('word', 'vectors', 'Sweden'), ('vectors', 'Sweden', 'Norway'), ('Sweden', 'Norway', '.')]

>> POS Tags are: 
 [('When', 'WRB'), ('trained', 'VBN'), ('predict', 'VBP'), ('next', 'JJ'), ('word', 'NN'), ('news', 'NN'), ('story', 'NN'), (',', ','), ('example', 'NN'), (',', ','), ('learned', 'VBD'), ('word', 'NN'), ('vectors', 'NNS'), ('Tuesday', 'NNP'), ('Wednesday', 'NNP'), ('similar', 'JJ'), (',', ','), ('word', 'NN'), ('vectors', 'NNS'), ('Sweden', 'NNP'), ('Norway', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['next word news story', 'example', 'word vectors Tuesday Wednesday', 'word vectors Sweden Norway']

>> Named Entities are: 
 [('PERSON', 'Sweden Norway')] 

>> Stemming using Porter Stemmer: 
 [('When', 'when'), ('trained', 'train'), ('predict', 'predict'), ('next', 'next'), ('word', 'word'), ('news', 'news'), ('story', 'stori'), (',', ','), ('example', 'exampl'), (',', ','), ('learned', 'learn'), ('word', 'word'), ('vectors', 'vector'), ('Tuesday', 'tuesday'), ('Wednesday', 'wednesday'), ('similar', 'similar'), (',', ','), ('word', 'word'), ('vectors', 'vector'), ('Sweden', 'sweden'), ('Norway', 'norway'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('When', 'when'), ('trained', 'train'), ('predict', 'predict'), ('next', 'next'), ('word', 'word'), ('news', 'news'), ('story', 'stori'), (',', ','), ('example', 'exampl'), (',', ','), ('learned', 'learn'), ('word', 'word'), ('vectors', 'vector'), ('Tuesday', 'tuesday'), ('Wednesday', 'wednesday'), ('similar', 'similar'), (',', ','), ('word', 'word'), ('vectors', 'vector'), ('Sweden', 'sweden'), ('Norway', 'norway'), ('.', '.')]

>> Lemmatization: 
 [('When', 'When'), ('trained', 'trained'), ('predict', 'predict'), ('next', 'next'), ('word', 'word'), ('news', 'news'), ('story', 'story'), (',', ','), ('example', 'example'), (',', ','), ('learned', 'learned'), ('word', 'word'), ('vectors', 'vector'), ('Tuesday', 'Tuesday'), ('Wednesday', 'Wednesday'), ('similar', 'similar'), (',', ','), ('word', 'word'), ('vectors', 'vector'), ('Sweden', 'Sweden'), ('Norway', 'Norway'), ('.', '.')]


------------------- Sentence 11 -------------------

Such representations  are called distributed representations because their elements (the  features) are not mutually exclusive and their many configurations  correspond to the variations seen in the observed data.

>> Tokens are: 
 ['Such', 'representations', 'called', 'distributed', 'representations', 'elements', '(', 'features', ')', 'mutually', 'exclusive', 'many', 'configurations', 'correspond', 'variations', 'seen', 'observed', 'data', '.']

>> Bigrams are: 
 [('Such', 'representations'), ('representations', 'called'), ('called', 'distributed'), ('distributed', 'representations'), ('representations', 'elements'), ('elements', '('), ('(', 'features'), ('features', ')'), (')', 'mutually'), ('mutually', 'exclusive'), ('exclusive', 'many'), ('many', 'configurations'), ('configurations', 'correspond'), ('correspond', 'variations'), ('variations', 'seen'), ('seen', 'observed'), ('observed', 'data'), ('data', '.')]

>> Trigrams are: 
 [('Such', 'representations', 'called'), ('representations', 'called', 'distributed'), ('called', 'distributed', 'representations'), ('distributed', 'representations', 'elements'), ('representations', 'elements', '('), ('elements', '(', 'features'), ('(', 'features', ')'), ('features', ')', 'mutually'), (')', 'mutually', 'exclusive'), ('mutually', 'exclusive', 'many'), ('exclusive', 'many', 'configurations'), ('many', 'configurations', 'correspond'), ('configurations', 'correspond', 'variations'), ('correspond', 'variations', 'seen'), ('variations', 'seen', 'observed'), ('seen', 'observed', 'data'), ('observed', 'data', '.')]

>> POS Tags are: 
 [('Such', 'JJ'), ('representations', 'NNS'), ('called', 'VBN'), ('distributed', 'JJ'), ('representations', 'NNS'), ('elements', 'NNS'), ('(', '('), ('features', 'NNS'), (')', ')'), ('mutually', 'RB'), ('exclusive', 'JJ'), ('many', 'JJ'), ('configurations', 'NNS'), ('correspond', 'VBP'), ('variations', 'NNS'), ('seen', 'VBN'), ('observed', 'VBN'), ('data', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['Such representations', 'distributed representations elements', 'features', 'exclusive many configurations', 'variations', 'data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Such', 'such'), ('representations', 'represent'), ('called', 'call'), ('distributed', 'distribut'), ('representations', 'represent'), ('elements', 'element'), ('(', '('), ('features', 'featur'), (')', ')'), ('mutually', 'mutual'), ('exclusive', 'exclus'), ('many', 'mani'), ('configurations', 'configur'), ('correspond', 'correspond'), ('variations', 'variat'), ('seen', 'seen'), ('observed', 'observ'), ('data', 'data'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Such', 'such'), ('representations', 'represent'), ('called', 'call'), ('distributed', 'distribut'), ('representations', 'represent'), ('elements', 'element'), ('(', '('), ('features', 'featur'), (')', ')'), ('mutually', 'mutual'), ('exclusive', 'exclus'), ('many', 'mani'), ('configurations', 'configur'), ('correspond', 'correspond'), ('variations', 'variat'), ('seen', 'seen'), ('observed', 'observ'), ('data', 'data'), ('.', '.')]

>> Lemmatization: 
 [('Such', 'Such'), ('representations', 'representation'), ('called', 'called'), ('distributed', 'distributed'), ('representations', 'representation'), ('elements', 'element'), ('(', '('), ('features', 'feature'), (')', ')'), ('mutually', 'mutually'), ('exclusive', 'exclusive'), ('many', 'many'), ('configurations', 'configuration'), ('correspond', 'correspond'), ('variations', 'variation'), ('seen', 'seen'), ('observed', 'observed'), ('data', 'data'), ('.', '.')]


------------------- Sentence 12 -------------------

These word  vectors are composed of learned features that were not determined  ahead of time by experts, but automatically discovered by the neural  network.

>> Tokens are: 
 ['These', 'word', 'vectors', 'composed', 'learned', 'features', 'determined', 'ahead', 'time', 'experts', ',', 'automatically', 'discovered', 'neural', 'network', '.']

>> Bigrams are: 
 [('These', 'word'), ('word', 'vectors'), ('vectors', 'composed'), ('composed', 'learned'), ('learned', 'features'), ('features', 'determined'), ('determined', 'ahead'), ('ahead', 'time'), ('time', 'experts'), ('experts', ','), (',', 'automatically'), ('automatically', 'discovered'), ('discovered', 'neural'), ('neural', 'network'), ('network', '.')]

>> Trigrams are: 
 [('These', 'word', 'vectors'), ('word', 'vectors', 'composed'), ('vectors', 'composed', 'learned'), ('composed', 'learned', 'features'), ('learned', 'features', 'determined'), ('features', 'determined', 'ahead'), ('determined', 'ahead', 'time'), ('ahead', 'time', 'experts'), ('time', 'experts', ','), ('experts', ',', 'automatically'), (',', 'automatically', 'discovered'), ('automatically', 'discovered', 'neural'), ('discovered', 'neural', 'network'), ('neural', 'network', '.')]

>> POS Tags are: 
 [('These', 'DT'), ('word', 'NN'), ('vectors', 'NNS'), ('composed', 'VBD'), ('learned', 'JJ'), ('features', 'NNS'), ('determined', 'VBN'), ('ahead', 'RB'), ('time', 'NN'), ('experts', 'NNS'), (',', ','), ('automatically', 'RB'), ('discovered', 'VBN'), ('neural', 'JJ'), ('network', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['These word vectors', 'learned features', 'time experts', 'neural network']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('These', 'these'), ('word', 'word'), ('vectors', 'vector'), ('composed', 'compos'), ('learned', 'learn'), ('features', 'featur'), ('determined', 'determin'), ('ahead', 'ahead'), ('time', 'time'), ('experts', 'expert'), (',', ','), ('automatically', 'automat'), ('discovered', 'discov'), ('neural', 'neural'), ('network', 'network'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('These', 'these'), ('word', 'word'), ('vectors', 'vector'), ('composed', 'compos'), ('learned', 'learn'), ('features', 'featur'), ('determined', 'determin'), ('ahead', 'ahead'), ('time', 'time'), ('experts', 'expert'), (',', ','), ('automatically', 'automat'), ('discovered', 'discov'), ('neural', 'neural'), ('network', 'network'), ('.', '.')]

>> Lemmatization: 
 [('These', 'These'), ('word', 'word'), ('vectors', 'vector'), ('composed', 'composed'), ('learned', 'learned'), ('features', 'feature'), ('determined', 'determined'), ('ahead', 'ahead'), ('time', 'time'), ('experts', 'expert'), (',', ','), ('automatically', 'automatically'), ('discovered', 'discovered'), ('neural', 'neural'), ('network', 'network'), ('.', '.')]


------------------- Sentence 13 -------------------

Vector representations of words learned from text are now  very widely used in natural language applications14,17,72–76.

>> Tokens are: 
 ['Vector', 'representations', 'words', 'learned', 'text', 'widely', 'used', 'natural', 'language', 'applications14,17,72–76', '.']

>> Bigrams are: 
 [('Vector', 'representations'), ('representations', 'words'), ('words', 'learned'), ('learned', 'text'), ('text', 'widely'), ('widely', 'used'), ('used', 'natural'), ('natural', 'language'), ('language', 'applications14,17,72–76'), ('applications14,17,72–76', '.')]

>> Trigrams are: 
 [('Vector', 'representations', 'words'), ('representations', 'words', 'learned'), ('words', 'learned', 'text'), ('learned', 'text', 'widely'), ('text', 'widely', 'used'), ('widely', 'used', 'natural'), ('used', 'natural', 'language'), ('natural', 'language', 'applications14,17,72–76'), ('language', 'applications14,17,72–76', '.')]

>> POS Tags are: 
 [('Vector', 'NNP'), ('representations', 'NNS'), ('words', 'NNS'), ('learned', 'VBD'), ('text', 'NN'), ('widely', 'RB'), ('used', 'VBD'), ('natural', 'JJ'), ('language', 'NN'), ('applications14,17,72–76', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Vector representations words', 'text', 'natural language applications14,17,72–76']

>> Named Entities are: 
 [('GPE', 'Vector')] 

>> Stemming using Porter Stemmer: 
 [('Vector', 'vector'), ('representations', 'represent'), ('words', 'word'), ('learned', 'learn'), ('text', 'text'), ('widely', 'wide'), ('used', 'use'), ('natural', 'natur'), ('language', 'languag'), ('applications14,17,72–76', 'applications14,17,72–76'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Vector', 'vector'), ('representations', 'represent'), ('words', 'word'), ('learned', 'learn'), ('text', 'text'), ('widely', 'wide'), ('used', 'use'), ('natural', 'natur'), ('language', 'languag'), ('applications14,17,72–76', 'applications14,17,72–76'), ('.', '.')]

>> Lemmatization: 
 [('Vector', 'Vector'), ('representations', 'representation'), ('words', 'word'), ('learned', 'learned'), ('text', 'text'), ('widely', 'widely'), ('used', 'used'), ('natural', 'natural'), ('language', 'language'), ('applications14,17,72–76', 'applications14,17,72–76'), ('.', '.')]



========================================== PARAGRAPH 152 ===========================================

The issue of representation lies at the heart of the debate between  the logic-inspired and the neural-network-inspired paradigms for  cognition. In the logic-inspired paradigm, an instance of a symbol is  something for which the only property is that it is either identical or  non-identical to other symbol instances. It has no internal structure  that is relevant to its use; and to reason with symbols, they must be  bound to the variables in judiciously chosen rules of inference. By  contrast, neural networks just use big activity vectors, big weight  matrices and scalar non-linearities to perform the type of fast ‘intui- tive’ inference that underpins effortless commonsense reasoning.  

------------------- Sentence 1 -------------------

The issue of representation lies at the heart of the debate between  the logic-inspired and the neural-network-inspired paradigms for  cognition.

>> Tokens are: 
 ['The', 'issue', 'representation', 'lies', 'heart', 'debate', 'logic-inspired', 'neural-network-inspired', 'paradigms', 'cognition', '.']

>> Bigrams are: 
 [('The', 'issue'), ('issue', 'representation'), ('representation', 'lies'), ('lies', 'heart'), ('heart', 'debate'), ('debate', 'logic-inspired'), ('logic-inspired', 'neural-network-inspired'), ('neural-network-inspired', 'paradigms'), ('paradigms', 'cognition'), ('cognition', '.')]

>> Trigrams are: 
 [('The', 'issue', 'representation'), ('issue', 'representation', 'lies'), ('representation', 'lies', 'heart'), ('lies', 'heart', 'debate'), ('heart', 'debate', 'logic-inspired'), ('debate', 'logic-inspired', 'neural-network-inspired'), ('logic-inspired', 'neural-network-inspired', 'paradigms'), ('neural-network-inspired', 'paradigms', 'cognition'), ('paradigms', 'cognition', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('issue', 'NN'), ('representation', 'NN'), ('lies', 'VBZ'), ('heart', 'NN'), ('debate', 'NN'), ('logic-inspired', 'JJ'), ('neural-network-inspired', 'JJ'), ('paradigms', 'NN'), ('cognition', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['The issue representation', 'heart debate', 'logic-inspired neural-network-inspired paradigms cognition']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('issue', 'issu'), ('representation', 'represent'), ('lies', 'lie'), ('heart', 'heart'), ('debate', 'debat'), ('logic-inspired', 'logic-inspir'), ('neural-network-inspired', 'neural-network-inspir'), ('paradigms', 'paradigm'), ('cognition', 'cognit'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('issue', 'issu'), ('representation', 'represent'), ('lies', 'lie'), ('heart', 'heart'), ('debate', 'debat'), ('logic-inspired', 'logic-inspir'), ('neural-network-inspired', 'neural-network-inspir'), ('paradigms', 'paradigm'), ('cognition', 'cognit'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('issue', 'issue'), ('representation', 'representation'), ('lies', 'lie'), ('heart', 'heart'), ('debate', 'debate'), ('logic-inspired', 'logic-inspired'), ('neural-network-inspired', 'neural-network-inspired'), ('paradigms', 'paradigm'), ('cognition', 'cognition'), ('.', '.')]


------------------- Sentence 2 -------------------

In the logic-inspired paradigm, an instance of a symbol is  something for which the only property is that it is either identical or  non-identical to other symbol instances.

>> Tokens are: 
 ['In', 'logic-inspired', 'paradigm', ',', 'instance', 'symbol', 'something', 'property', 'either', 'identical', 'non-identical', 'symbol', 'instances', '.']

>> Bigrams are: 
 [('In', 'logic-inspired'), ('logic-inspired', 'paradigm'), ('paradigm', ','), (',', 'instance'), ('instance', 'symbol'), ('symbol', 'something'), ('something', 'property'), ('property', 'either'), ('either', 'identical'), ('identical', 'non-identical'), ('non-identical', 'symbol'), ('symbol', 'instances'), ('instances', '.')]

>> Trigrams are: 
 [('In', 'logic-inspired', 'paradigm'), ('logic-inspired', 'paradigm', ','), ('paradigm', ',', 'instance'), (',', 'instance', 'symbol'), ('instance', 'symbol', 'something'), ('symbol', 'something', 'property'), ('something', 'property', 'either'), ('property', 'either', 'identical'), ('either', 'identical', 'non-identical'), ('identical', 'non-identical', 'symbol'), ('non-identical', 'symbol', 'instances'), ('symbol', 'instances', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('logic-inspired', 'JJ'), ('paradigm', 'NN'), (',', ','), ('instance', 'NN'), ('symbol', 'NN'), ('something', 'NN'), ('property', 'NN'), ('either', 'DT'), ('identical', 'JJ'), ('non-identical', 'JJ'), ('symbol', 'NN'), ('instances', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['logic-inspired paradigm', 'instance symbol something property', 'either identical non-identical symbol instances']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('logic-inspired', 'logic-inspir'), ('paradigm', 'paradigm'), (',', ','), ('instance', 'instanc'), ('symbol', 'symbol'), ('something', 'someth'), ('property', 'properti'), ('either', 'either'), ('identical', 'ident'), ('non-identical', 'non-ident'), ('symbol', 'symbol'), ('instances', 'instanc'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('logic-inspired', 'logic-inspir'), ('paradigm', 'paradigm'), (',', ','), ('instance', 'instanc'), ('symbol', 'symbol'), ('something', 'someth'), ('property', 'properti'), ('either', 'either'), ('identical', 'ident'), ('non-identical', 'non-ident'), ('symbol', 'symbol'), ('instances', 'instanc'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('logic-inspired', 'logic-inspired'), ('paradigm', 'paradigm'), (',', ','), ('instance', 'instance'), ('symbol', 'symbol'), ('something', 'something'), ('property', 'property'), ('either', 'either'), ('identical', 'identical'), ('non-identical', 'non-identical'), ('symbol', 'symbol'), ('instances', 'instance'), ('.', '.')]


------------------- Sentence 3 -------------------

It has no internal structure  that is relevant to its use; and to reason with symbols, they must be  bound to the variables in judiciously chosen rules of inference.

>> Tokens are: 
 ['It', 'internal', 'structure', 'relevant', 'use', ';', 'reason', 'symbols', ',', 'must', 'bound', 'variables', 'judiciously', 'chosen', 'rules', 'inference', '.']

>> Bigrams are: 
 [('It', 'internal'), ('internal', 'structure'), ('structure', 'relevant'), ('relevant', 'use'), ('use', ';'), (';', 'reason'), ('reason', 'symbols'), ('symbols', ','), (',', 'must'), ('must', 'bound'), ('bound', 'variables'), ('variables', 'judiciously'), ('judiciously', 'chosen'), ('chosen', 'rules'), ('rules', 'inference'), ('inference', '.')]

>> Trigrams are: 
 [('It', 'internal', 'structure'), ('internal', 'structure', 'relevant'), ('structure', 'relevant', 'use'), ('relevant', 'use', ';'), ('use', ';', 'reason'), (';', 'reason', 'symbols'), ('reason', 'symbols', ','), ('symbols', ',', 'must'), (',', 'must', 'bound'), ('must', 'bound', 'variables'), ('bound', 'variables', 'judiciously'), ('variables', 'judiciously', 'chosen'), ('judiciously', 'chosen', 'rules'), ('chosen', 'rules', 'inference'), ('rules', 'inference', '.')]

>> POS Tags are: 
 [('It', 'PRP'), ('internal', 'JJ'), ('structure', 'NN'), ('relevant', 'JJ'), ('use', 'NN'), (';', ':'), ('reason', 'NN'), ('symbols', 'NNS'), (',', ','), ('must', 'MD'), ('bound', 'VB'), ('variables', 'NNS'), ('judiciously', 'RB'), ('chosen', 'VBN'), ('rules', 'NNS'), ('inference', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['internal structure', 'relevant use', 'reason symbols', 'variables', 'rules inference']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('It', 'it'), ('internal', 'intern'), ('structure', 'structur'), ('relevant', 'relev'), ('use', 'use'), (';', ';'), ('reason', 'reason'), ('symbols', 'symbol'), (',', ','), ('must', 'must'), ('bound', 'bound'), ('variables', 'variabl'), ('judiciously', 'judici'), ('chosen', 'chosen'), ('rules', 'rule'), ('inference', 'infer'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('It', 'it'), ('internal', 'intern'), ('structure', 'structur'), ('relevant', 'relev'), ('use', 'use'), (';', ';'), ('reason', 'reason'), ('symbols', 'symbol'), (',', ','), ('must', 'must'), ('bound', 'bound'), ('variables', 'variabl'), ('judiciously', 'judici'), ('chosen', 'chosen'), ('rules', 'rule'), ('inference', 'infer'), ('.', '.')]

>> Lemmatization: 
 [('It', 'It'), ('internal', 'internal'), ('structure', 'structure'), ('relevant', 'relevant'), ('use', 'use'), (';', ';'), ('reason', 'reason'), ('symbols', 'symbol'), (',', ','), ('must', 'must'), ('bound', 'bound'), ('variables', 'variable'), ('judiciously', 'judiciously'), ('chosen', 'chosen'), ('rules', 'rule'), ('inference', 'inference'), ('.', '.')]


------------------- Sentence 4 -------------------

By  contrast, neural networks just use big activity vectors, big weight  matrices and scalar non-linearities to perform the type of fast ‘intui- tive’ inference that underpins effortless commonsense reasoning.

>> Tokens are: 
 ['By', 'contrast', ',', 'neural', 'networks', 'use', 'big', 'activity', 'vectors', ',', 'big', 'weight', 'matrices', 'scalar', 'non-linearities', 'perform', 'type', 'fast', '‘', 'intui-', 'tive', '’', 'inference', 'underpins', 'effortless', 'commonsense', 'reasoning', '.']

>> Bigrams are: 
 [('By', 'contrast'), ('contrast', ','), (',', 'neural'), ('neural', 'networks'), ('networks', 'use'), ('use', 'big'), ('big', 'activity'), ('activity', 'vectors'), ('vectors', ','), (',', 'big'), ('big', 'weight'), ('weight', 'matrices'), ('matrices', 'scalar'), ('scalar', 'non-linearities'), ('non-linearities', 'perform'), ('perform', 'type'), ('type', 'fast'), ('fast', '‘'), ('‘', 'intui-'), ('intui-', 'tive'), ('tive', '’'), ('’', 'inference'), ('inference', 'underpins'), ('underpins', 'effortless'), ('effortless', 'commonsense'), ('commonsense', 'reasoning'), ('reasoning', '.')]

>> Trigrams are: 
 [('By', 'contrast', ','), ('contrast', ',', 'neural'), (',', 'neural', 'networks'), ('neural', 'networks', 'use'), ('networks', 'use', 'big'), ('use', 'big', 'activity'), ('big', 'activity', 'vectors'), ('activity', 'vectors', ','), ('vectors', ',', 'big'), (',', 'big', 'weight'), ('big', 'weight', 'matrices'), ('weight', 'matrices', 'scalar'), ('matrices', 'scalar', 'non-linearities'), ('scalar', 'non-linearities', 'perform'), ('non-linearities', 'perform', 'type'), ('perform', 'type', 'fast'), ('type', 'fast', '‘'), ('fast', '‘', 'intui-'), ('‘', 'intui-', 'tive'), ('intui-', 'tive', '’'), ('tive', '’', 'inference'), ('’', 'inference', 'underpins'), ('inference', 'underpins', 'effortless'), ('underpins', 'effortless', 'commonsense'), ('effortless', 'commonsense', 'reasoning'), ('commonsense', 'reasoning', '.')]

>> POS Tags are: 
 [('By', 'IN'), ('contrast', 'NN'), (',', ','), ('neural', 'JJ'), ('networks', 'NNS'), ('use', 'VBP'), ('big', 'JJ'), ('activity', 'NN'), ('vectors', 'NNS'), (',', ','), ('big', 'JJ'), ('weight', 'NN'), ('matrices', 'NNS'), ('scalar', 'JJ'), ('non-linearities', 'NNS'), ('perform', 'NN'), ('type', 'NN'), ('fast', 'RB'), ('‘', 'JJ'), ('intui-', 'JJ'), ('tive', 'JJ'), ('’', 'NN'), ('inference', 'NN'), ('underpins', 'VBZ'), ('effortless', 'JJ'), ('commonsense', 'NN'), ('reasoning', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['contrast', 'neural networks', 'big activity vectors', 'big weight matrices', 'scalar non-linearities perform type', '‘ intui- tive ’ inference', 'effortless commonsense reasoning']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('By', 'by'), ('contrast', 'contrast'), (',', ','), ('neural', 'neural'), ('networks', 'network'), ('use', 'use'), ('big', 'big'), ('activity', 'activ'), ('vectors', 'vector'), (',', ','), ('big', 'big'), ('weight', 'weight'), ('matrices', 'matric'), ('scalar', 'scalar'), ('non-linearities', 'non-linear'), ('perform', 'perform'), ('type', 'type'), ('fast', 'fast'), ('‘', '‘'), ('intui-', 'intui-'), ('tive', 'tive'), ('’', '’'), ('inference', 'infer'), ('underpins', 'underpin'), ('effortless', 'effortless'), ('commonsense', 'commonsens'), ('reasoning', 'reason'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('By', 'by'), ('contrast', 'contrast'), (',', ','), ('neural', 'neural'), ('networks', 'network'), ('use', 'use'), ('big', 'big'), ('activity', 'activ'), ('vectors', 'vector'), (',', ','), ('big', 'big'), ('weight', 'weight'), ('matrices', 'matric'), ('scalar', 'scalar'), ('non-linearities', 'non-linear'), ('perform', 'perform'), ('type', 'type'), ('fast', 'fast'), ('‘', '‘'), ('intui-', 'intui-'), ('tive', 'tive'), ('’', '’'), ('inference', 'infer'), ('underpins', 'underpin'), ('effortless', 'effortless'), ('commonsense', 'commonsens'), ('reasoning', 'reason'), ('.', '.')]

>> Lemmatization: 
 [('By', 'By'), ('contrast', 'contrast'), (',', ','), ('neural', 'neural'), ('networks', 'network'), ('use', 'use'), ('big', 'big'), ('activity', 'activity'), ('vectors', 'vector'), (',', ','), ('big', 'big'), ('weight', 'weight'), ('matrices', 'matrix'), ('scalar', 'scalar'), ('non-linearities', 'non-linearities'), ('perform', 'perform'), ('type', 'type'), ('fast', 'fast'), ('‘', '‘'), ('intui-', 'intui-'), ('tive', 'tive'), ('’', '’'), ('inference', 'inference'), ('underpins', 'underpins'), ('effortless', 'effortless'), ('commonsense', 'commonsense'), ('reasoning', 'reasoning'), ('.', '.')]



========================================== PARAGRAPH 153 ===========================================

Before the introduction of neural language models71, the standard  approach to statistical modelling of language did not exploit distrib- uted representations: it was based on counting frequencies of occur- rences of short symbol sequences of length up to N (called N-grams).  The number of possible N-grams is on the order of VN, where V is  the vocabulary size, so taking into account a context of more than a  

------------------- Sentence 1 -------------------

Before the introduction of neural language models71, the standard  approach to statistical modelling of language did not exploit distrib- uted representations: it was based on counting frequencies of occur- rences of short symbol sequences of length up to N (called N-grams).

>> Tokens are: 
 ['Before', 'introduction', 'neural', 'language', 'models71', ',', 'standard', 'approach', 'statistical', 'modelling', 'language', 'exploit', 'distrib-', 'uted', 'representations', ':', 'based', 'counting', 'frequencies', 'occur-', 'rences', 'short', 'symbol', 'sequences', 'length', 'N', '(', 'called', 'N-grams', ')', '.']

>> Bigrams are: 
 [('Before', 'introduction'), ('introduction', 'neural'), ('neural', 'language'), ('language', 'models71'), ('models71', ','), (',', 'standard'), ('standard', 'approach'), ('approach', 'statistical'), ('statistical', 'modelling'), ('modelling', 'language'), ('language', 'exploit'), ('exploit', 'distrib-'), ('distrib-', 'uted'), ('uted', 'representations'), ('representations', ':'), (':', 'based'), ('based', 'counting'), ('counting', 'frequencies'), ('frequencies', 'occur-'), ('occur-', 'rences'), ('rences', 'short'), ('short', 'symbol'), ('symbol', 'sequences'), ('sequences', 'length'), ('length', 'N'), ('N', '('), ('(', 'called'), ('called', 'N-grams'), ('N-grams', ')'), (')', '.')]

>> Trigrams are: 
 [('Before', 'introduction', 'neural'), ('introduction', 'neural', 'language'), ('neural', 'language', 'models71'), ('language', 'models71', ','), ('models71', ',', 'standard'), (',', 'standard', 'approach'), ('standard', 'approach', 'statistical'), ('approach', 'statistical', 'modelling'), ('statistical', 'modelling', 'language'), ('modelling', 'language', 'exploit'), ('language', 'exploit', 'distrib-'), ('exploit', 'distrib-', 'uted'), ('distrib-', 'uted', 'representations'), ('uted', 'representations', ':'), ('representations', ':', 'based'), (':', 'based', 'counting'), ('based', 'counting', 'frequencies'), ('counting', 'frequencies', 'occur-'), ('frequencies', 'occur-', 'rences'), ('occur-', 'rences', 'short'), ('rences', 'short', 'symbol'), ('short', 'symbol', 'sequences'), ('symbol', 'sequences', 'length'), ('sequences', 'length', 'N'), ('length', 'N', '('), ('N', '(', 'called'), ('(', 'called', 'N-grams'), ('called', 'N-grams', ')'), ('N-grams', ')', '.')]

>> POS Tags are: 
 [('Before', 'IN'), ('introduction', 'JJ'), ('neural', 'JJ'), ('language', 'NN'), ('models71', 'NN'), (',', ','), ('standard', 'JJ'), ('approach', 'NN'), ('statistical', 'JJ'), ('modelling', 'NN'), ('language', 'NN'), ('exploit', 'VBD'), ('distrib-', 'RB'), ('uted', 'JJ'), ('representations', 'NNS'), (':', ':'), ('based', 'VBN'), ('counting', 'VBG'), ('frequencies', 'NNS'), ('occur-', 'JJ'), ('rences', 'NNS'), ('short', 'JJ'), ('symbol', 'NN'), ('sequences', 'NNS'), ('length', 'VBP'), ('N', 'NNP'), ('(', '('), ('called', 'VBN'), ('N-grams', 'NNP'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['introduction neural language models71', 'standard approach', 'statistical modelling language', 'uted representations', 'frequencies', 'occur- rences', 'short symbol sequences', 'N', 'N-grams']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Before', 'befor'), ('introduction', 'introduct'), ('neural', 'neural'), ('language', 'languag'), ('models71', 'models71'), (',', ','), ('standard', 'standard'), ('approach', 'approach'), ('statistical', 'statist'), ('modelling', 'model'), ('language', 'languag'), ('exploit', 'exploit'), ('distrib-', 'distrib-'), ('uted', 'ute'), ('representations', 'represent'), (':', ':'), ('based', 'base'), ('counting', 'count'), ('frequencies', 'frequenc'), ('occur-', 'occur-'), ('rences', 'renc'), ('short', 'short'), ('symbol', 'symbol'), ('sequences', 'sequenc'), ('length', 'length'), ('N', 'n'), ('(', '('), ('called', 'call'), ('N-grams', 'n-gram'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Before', 'befor'), ('introduction', 'introduct'), ('neural', 'neural'), ('language', 'languag'), ('models71', 'models71'), (',', ','), ('standard', 'standard'), ('approach', 'approach'), ('statistical', 'statist'), ('modelling', 'model'), ('language', 'languag'), ('exploit', 'exploit'), ('distrib-', 'distrib-'), ('uted', 'ute'), ('representations', 'represent'), (':', ':'), ('based', 'base'), ('counting', 'count'), ('frequencies', 'frequenc'), ('occur-', 'occur-'), ('rences', 'renc'), ('short', 'short'), ('symbol', 'symbol'), ('sequences', 'sequenc'), ('length', 'length'), ('N', 'n'), ('(', '('), ('called', 'call'), ('N-grams', 'n-gram'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Before', 'Before'), ('introduction', 'introduction'), ('neural', 'neural'), ('language', 'language'), ('models71', 'models71'), (',', ','), ('standard', 'standard'), ('approach', 'approach'), ('statistical', 'statistical'), ('modelling', 'modelling'), ('language', 'language'), ('exploit', 'exploit'), ('distrib-', 'distrib-'), ('uted', 'uted'), ('representations', 'representation'), (':', ':'), ('based', 'based'), ('counting', 'counting'), ('frequencies', 'frequency'), ('occur-', 'occur-'), ('rences', 'rences'), ('short', 'short'), ('symbol', 'symbol'), ('sequences', 'sequence'), ('length', 'length'), ('N', 'N'), ('(', '('), ('called', 'called'), ('N-grams', 'N-grams'), (')', ')'), ('.', '.')]


------------------- Sentence 2 -------------------

The number of possible N-grams is on the order of VN, where V is  the vocabulary size, so taking into account a context of more than a

>> Tokens are: 
 ['The', 'number', 'possible', 'N-grams', 'order', 'VN', ',', 'V', 'vocabulary', 'size', ',', 'taking', 'account', 'context']

>> Bigrams are: 
 [('The', 'number'), ('number', 'possible'), ('possible', 'N-grams'), ('N-grams', 'order'), ('order', 'VN'), ('VN', ','), (',', 'V'), ('V', 'vocabulary'), ('vocabulary', 'size'), ('size', ','), (',', 'taking'), ('taking', 'account'), ('account', 'context')]

>> Trigrams are: 
 [('The', 'number', 'possible'), ('number', 'possible', 'N-grams'), ('possible', 'N-grams', 'order'), ('N-grams', 'order', 'VN'), ('order', 'VN', ','), ('VN', ',', 'V'), (',', 'V', 'vocabulary'), ('V', 'vocabulary', 'size'), ('vocabulary', 'size', ','), ('size', ',', 'taking'), (',', 'taking', 'account'), ('taking', 'account', 'context')]

>> POS Tags are: 
 [('The', 'DT'), ('number', 'NN'), ('possible', 'JJ'), ('N-grams', 'JJ'), ('order', 'NN'), ('VN', 'NNP'), (',', ','), ('V', 'NNP'), ('vocabulary', 'JJ'), ('size', 'NN'), (',', ','), ('taking', 'VBG'), ('account', 'NN'), ('context', 'NN')]

>> Noun Phrases are: 
 ['The number', 'possible N-grams order VN', 'V', 'vocabulary size', 'account context']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('number', 'number'), ('possible', 'possibl'), ('N-grams', 'n-gram'), ('order', 'order'), ('VN', 'vn'), (',', ','), ('V', 'v'), ('vocabulary', 'vocabulari'), ('size', 'size'), (',', ','), ('taking', 'take'), ('account', 'account'), ('context', 'context')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('number', 'number'), ('possible', 'possibl'), ('N-grams', 'n-gram'), ('order', 'order'), ('VN', 'vn'), (',', ','), ('V', 'v'), ('vocabulary', 'vocabulari'), ('size', 'size'), (',', ','), ('taking', 'take'), ('account', 'account'), ('context', 'context')]

>> Lemmatization: 
 [('The', 'The'), ('number', 'number'), ('possible', 'possible'), ('N-grams', 'N-grams'), ('order', 'order'), ('VN', 'VN'), (',', ','), ('V', 'V'), ('vocabulary', 'vocabulary'), ('size', 'size'), (',', ','), ('taking', 'taking'), ('account', 'account'), ('context', 'context')]



========================================== PARAGRAPH 154 ===========================================

handful of words would require very large training corpora. N-grams  treat each word as an atomic unit, so they cannot generalize across  semantically related sequences of words, whereas neural language  models can because they associate each word with a vector of real  valued features, and semantically related words end up close to each  other in that vector space (Fig. 4).  

------------------- Sentence 1 -------------------

handful of words would require very large training corpora.

>> Tokens are: 
 ['handful', 'words', 'would', 'require', 'large', 'training', 'corpora', '.']

>> Bigrams are: 
 [('handful', 'words'), ('words', 'would'), ('would', 'require'), ('require', 'large'), ('large', 'training'), ('training', 'corpora'), ('corpora', '.')]

>> Trigrams are: 
 [('handful', 'words', 'would'), ('words', 'would', 'require'), ('would', 'require', 'large'), ('require', 'large', 'training'), ('large', 'training', 'corpora'), ('training', 'corpora', '.')]

>> POS Tags are: 
 [('handful', 'NN'), ('words', 'NNS'), ('would', 'MD'), ('require', 'VB'), ('large', 'JJ'), ('training', 'NN'), ('corpora', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['handful words', 'large training corpora']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('handful', 'hand'), ('words', 'word'), ('would', 'would'), ('require', 'requir'), ('large', 'larg'), ('training', 'train'), ('corpora', 'corpora'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('handful', 'hand'), ('words', 'word'), ('would', 'would'), ('require', 'requir'), ('large', 'larg'), ('training', 'train'), ('corpora', 'corpora'), ('.', '.')]

>> Lemmatization: 
 [('handful', 'handful'), ('words', 'word'), ('would', 'would'), ('require', 'require'), ('large', 'large'), ('training', 'training'), ('corpora', 'corpus'), ('.', '.')]


------------------- Sentence 2 -------------------

N-grams  treat each word as an atomic unit, so they cannot generalize across  semantically related sequences of words, whereas neural language  models can because they associate each word with a vector of real  valued features, and semantically related words end up close to each  other in that vector space (Fig.

>> Tokens are: 
 ['N-grams', 'treat', 'word', 'atomic', 'unit', ',', 'generalize', 'across', 'semantically', 'related', 'sequences', 'words', ',', 'whereas', 'neural', 'language', 'models', 'associate', 'word', 'vector', 'real', 'valued', 'features', ',', 'semantically', 'related', 'words', 'end', 'close', 'vector', 'space', '(', 'Fig', '.']

>> Bigrams are: 
 [('N-grams', 'treat'), ('treat', 'word'), ('word', 'atomic'), ('atomic', 'unit'), ('unit', ','), (',', 'generalize'), ('generalize', 'across'), ('across', 'semantically'), ('semantically', 'related'), ('related', 'sequences'), ('sequences', 'words'), ('words', ','), (',', 'whereas'), ('whereas', 'neural'), ('neural', 'language'), ('language', 'models'), ('models', 'associate'), ('associate', 'word'), ('word', 'vector'), ('vector', 'real'), ('real', 'valued'), ('valued', 'features'), ('features', ','), (',', 'semantically'), ('semantically', 'related'), ('related', 'words'), ('words', 'end'), ('end', 'close'), ('close', 'vector'), ('vector', 'space'), ('space', '('), ('(', 'Fig'), ('Fig', '.')]

>> Trigrams are: 
 [('N-grams', 'treat', 'word'), ('treat', 'word', 'atomic'), ('word', 'atomic', 'unit'), ('atomic', 'unit', ','), ('unit', ',', 'generalize'), (',', 'generalize', 'across'), ('generalize', 'across', 'semantically'), ('across', 'semantically', 'related'), ('semantically', 'related', 'sequences'), ('related', 'sequences', 'words'), ('sequences', 'words', ','), ('words', ',', 'whereas'), (',', 'whereas', 'neural'), ('whereas', 'neural', 'language'), ('neural', 'language', 'models'), ('language', 'models', 'associate'), ('models', 'associate', 'word'), ('associate', 'word', 'vector'), ('word', 'vector', 'real'), ('vector', 'real', 'valued'), ('real', 'valued', 'features'), ('valued', 'features', ','), ('features', ',', 'semantically'), (',', 'semantically', 'related'), ('semantically', 'related', 'words'), ('related', 'words', 'end'), ('words', 'end', 'close'), ('end', 'close', 'vector'), ('close', 'vector', 'space'), ('vector', 'space', '('), ('space', '(', 'Fig'), ('(', 'Fig', '.')]

>> POS Tags are: 
 [('N-grams', 'JJ'), ('treat', 'NN'), ('word', 'NN'), ('atomic', 'JJ'), ('unit', 'NN'), (',', ','), ('generalize', 'VB'), ('across', 'IN'), ('semantically', 'RB'), ('related', 'VBN'), ('sequences', 'NNS'), ('words', 'NNS'), (',', ','), ('whereas', 'JJ'), ('neural', 'JJ'), ('language', 'NN'), ('models', 'NNS'), ('associate', 'VBP'), ('word', 'NN'), ('vector', 'NN'), ('real', 'JJ'), ('valued', 'VBN'), ('features', 'NNS'), (',', ','), ('semantically', 'RB'), ('related', 'JJ'), ('words', 'NNS'), ('end', 'VBP'), ('close', 'JJ'), ('vector', 'NN'), ('space', 'NN'), ('(', '('), ('Fig', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['N-grams treat word', 'atomic unit', 'sequences words', 'whereas neural language models', 'word vector', 'features', 'related words', 'close vector space', 'Fig']

>> Named Entities are: 
 [('ORGANIZATION', 'Fig')] 

>> Stemming using Porter Stemmer: 
 [('N-grams', 'n-gram'), ('treat', 'treat'), ('word', 'word'), ('atomic', 'atom'), ('unit', 'unit'), (',', ','), ('generalize', 'gener'), ('across', 'across'), ('semantically', 'semant'), ('related', 'relat'), ('sequences', 'sequenc'), ('words', 'word'), (',', ','), ('whereas', 'wherea'), ('neural', 'neural'), ('language', 'languag'), ('models', 'model'), ('associate', 'associ'), ('word', 'word'), ('vector', 'vector'), ('real', 'real'), ('valued', 'valu'), ('features', 'featur'), (',', ','), ('semantically', 'semant'), ('related', 'relat'), ('words', 'word'), ('end', 'end'), ('close', 'close'), ('vector', 'vector'), ('space', 'space'), ('(', '('), ('Fig', 'fig'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('N-grams', 'n-gram'), ('treat', 'treat'), ('word', 'word'), ('atomic', 'atom'), ('unit', 'unit'), (',', ','), ('generalize', 'general'), ('across', 'across'), ('semantically', 'semant'), ('related', 'relat'), ('sequences', 'sequenc'), ('words', 'word'), (',', ','), ('whereas', 'wherea'), ('neural', 'neural'), ('language', 'languag'), ('models', 'model'), ('associate', 'associ'), ('word', 'word'), ('vector', 'vector'), ('real', 'real'), ('valued', 'valu'), ('features', 'featur'), (',', ','), ('semantically', 'semant'), ('related', 'relat'), ('words', 'word'), ('end', 'end'), ('close', 'close'), ('vector', 'vector'), ('space', 'space'), ('(', '('), ('Fig', 'fig'), ('.', '.')]

>> Lemmatization: 
 [('N-grams', 'N-grams'), ('treat', 'treat'), ('word', 'word'), ('atomic', 'atomic'), ('unit', 'unit'), (',', ','), ('generalize', 'generalize'), ('across', 'across'), ('semantically', 'semantically'), ('related', 'related'), ('sequences', 'sequence'), ('words', 'word'), (',', ','), ('whereas', 'whereas'), ('neural', 'neural'), ('language', 'language'), ('models', 'model'), ('associate', 'associate'), ('word', 'word'), ('vector', 'vector'), ('real', 'real'), ('valued', 'valued'), ('features', 'feature'), (',', ','), ('semantically', 'semantically'), ('related', 'related'), ('words', 'word'), ('end', 'end'), ('close', 'close'), ('vector', 'vector'), ('space', 'space'), ('(', '('), ('Fig', 'Fig'), ('.', '.')]


------------------- Sentence 3 -------------------

4).

>> Tokens are: 
 ['4', ')', '.']

>> Bigrams are: 
 [('4', ')'), (')', '.')]

>> Trigrams are: 
 [('4', ')', '.')]

>> POS Tags are: 
 [('4', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('4', '4'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('4', '4'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('4', '4'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 155 ===========================================

Recurrent neural networks  When backpropagation was first introduced, its most exciting use was  for training recurrent neural networks (RNNs). For tasks that involve  sequential inputs, such as speech and language, it is often better to  use RNNs (Fig. 5). RNNs process an input sequence one element at a  time, maintaining in their hidden units a ‘state vector’ that implicitly  contains information about the history of all the past elements of  the sequence. When we consider the outputs of the hidden units at  different discrete time steps as if they were the outputs of different  neurons in a deep multilayer network (Fig. 5, right), it becomes clear  how we can apply backpropagation to train RNNs.  

------------------- Sentence 1 -------------------

Recurrent neural networks  When backpropagation was first introduced, its most exciting use was  for training recurrent neural networks (RNNs).

>> Tokens are: 
 ['Recurrent', 'neural', 'networks', 'When', 'backpropagation', 'first', 'introduced', ',', 'exciting', 'use', 'training', 'recurrent', 'neural', 'networks', '(', 'RNNs', ')', '.']

>> Bigrams are: 
 [('Recurrent', 'neural'), ('neural', 'networks'), ('networks', 'When'), ('When', 'backpropagation'), ('backpropagation', 'first'), ('first', 'introduced'), ('introduced', ','), (',', 'exciting'), ('exciting', 'use'), ('use', 'training'), ('training', 'recurrent'), ('recurrent', 'neural'), ('neural', 'networks'), ('networks', '('), ('(', 'RNNs'), ('RNNs', ')'), (')', '.')]

>> Trigrams are: 
 [('Recurrent', 'neural', 'networks'), ('neural', 'networks', 'When'), ('networks', 'When', 'backpropagation'), ('When', 'backpropagation', 'first'), ('backpropagation', 'first', 'introduced'), ('first', 'introduced', ','), ('introduced', ',', 'exciting'), (',', 'exciting', 'use'), ('exciting', 'use', 'training'), ('use', 'training', 'recurrent'), ('training', 'recurrent', 'neural'), ('recurrent', 'neural', 'networks'), ('neural', 'networks', '('), ('networks', '(', 'RNNs'), ('(', 'RNNs', ')'), ('RNNs', ')', '.')]

>> POS Tags are: 
 [('Recurrent', 'JJ'), ('neural', 'JJ'), ('networks', 'NNS'), ('When', 'WRB'), ('backpropagation', 'NN'), ('first', 'RB'), ('introduced', 'VBD'), (',', ','), ('exciting', 'VBG'), ('use', 'NN'), ('training', 'NN'), ('recurrent', 'JJ'), ('neural', 'JJ'), ('networks', 'NNS'), ('(', '('), ('RNNs', 'NNP'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['Recurrent neural networks', 'backpropagation', 'use training', 'recurrent neural networks', 'RNNs']

>> Named Entities are: 
 [('ORGANIZATION', 'RNNs')] 

>> Stemming using Porter Stemmer: 
 [('Recurrent', 'recurr'), ('neural', 'neural'), ('networks', 'network'), ('When', 'when'), ('backpropagation', 'backpropag'), ('first', 'first'), ('introduced', 'introduc'), (',', ','), ('exciting', 'excit'), ('use', 'use'), ('training', 'train'), ('recurrent', 'recurr'), ('neural', 'neural'), ('networks', 'network'), ('(', '('), ('RNNs', 'rnn'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Recurrent', 'recurr'), ('neural', 'neural'), ('networks', 'network'), ('When', 'when'), ('backpropagation', 'backpropag'), ('first', 'first'), ('introduced', 'introduc'), (',', ','), ('exciting', 'excit'), ('use', 'use'), ('training', 'train'), ('recurrent', 'recurr'), ('neural', 'neural'), ('networks', 'network'), ('(', '('), ('RNNs', 'rnns'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Recurrent', 'Recurrent'), ('neural', 'neural'), ('networks', 'network'), ('When', 'When'), ('backpropagation', 'backpropagation'), ('first', 'first'), ('introduced', 'introduced'), (',', ','), ('exciting', 'exciting'), ('use', 'use'), ('training', 'training'), ('recurrent', 'recurrent'), ('neural', 'neural'), ('networks', 'network'), ('(', '('), ('RNNs', 'RNNs'), (')', ')'), ('.', '.')]


------------------- Sentence 2 -------------------

For tasks that involve  sequential inputs, such as speech and language, it is often better to  use RNNs (Fig.

>> Tokens are: 
 ['For', 'tasks', 'involve', 'sequential', 'inputs', ',', 'speech', 'language', ',', 'often', 'better', 'use', 'RNNs', '(', 'Fig', '.']

>> Bigrams are: 
 [('For', 'tasks'), ('tasks', 'involve'), ('involve', 'sequential'), ('sequential', 'inputs'), ('inputs', ','), (',', 'speech'), ('speech', 'language'), ('language', ','), (',', 'often'), ('often', 'better'), ('better', 'use'), ('use', 'RNNs'), ('RNNs', '('), ('(', 'Fig'), ('Fig', '.')]

>> Trigrams are: 
 [('For', 'tasks', 'involve'), ('tasks', 'involve', 'sequential'), ('involve', 'sequential', 'inputs'), ('sequential', 'inputs', ','), ('inputs', ',', 'speech'), (',', 'speech', 'language'), ('speech', 'language', ','), ('language', ',', 'often'), (',', 'often', 'better'), ('often', 'better', 'use'), ('better', 'use', 'RNNs'), ('use', 'RNNs', '('), ('RNNs', '(', 'Fig'), ('(', 'Fig', '.')]

>> POS Tags are: 
 [('For', 'IN'), ('tasks', 'NNS'), ('involve', 'VBP'), ('sequential', 'JJ'), ('inputs', 'NNS'), (',', ','), ('speech', 'NN'), ('language', 'NN'), (',', ','), ('often', 'RB'), ('better', 'RBR'), ('use', 'NN'), ('RNNs', 'NNP'), ('(', '('), ('Fig', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['tasks', 'sequential inputs', 'speech language', 'use RNNs', 'Fig']

>> Named Entities are: 
 [('ORGANIZATION', 'RNNs'), ('ORGANIZATION', 'Fig')] 

>> Stemming using Porter Stemmer: 
 [('For', 'for'), ('tasks', 'task'), ('involve', 'involv'), ('sequential', 'sequenti'), ('inputs', 'input'), (',', ','), ('speech', 'speech'), ('language', 'languag'), (',', ','), ('often', 'often'), ('better', 'better'), ('use', 'use'), ('RNNs', 'rnn'), ('(', '('), ('Fig', 'fig'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('For', 'for'), ('tasks', 'task'), ('involve', 'involv'), ('sequential', 'sequenti'), ('inputs', 'input'), (',', ','), ('speech', 'speech'), ('language', 'languag'), (',', ','), ('often', 'often'), ('better', 'better'), ('use', 'use'), ('RNNs', 'rnns'), ('(', '('), ('Fig', 'fig'), ('.', '.')]

>> Lemmatization: 
 [('For', 'For'), ('tasks', 'task'), ('involve', 'involve'), ('sequential', 'sequential'), ('inputs', 'input'), (',', ','), ('speech', 'speech'), ('language', 'language'), (',', ','), ('often', 'often'), ('better', 'better'), ('use', 'use'), ('RNNs', 'RNNs'), ('(', '('), ('Fig', 'Fig'), ('.', '.')]


------------------- Sentence 3 -------------------

5).

>> Tokens are: 
 ['5', ')', '.']

>> Bigrams are: 
 [('5', ')'), (')', '.')]

>> Trigrams are: 
 [('5', ')', '.')]

>> POS Tags are: 
 [('5', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('5', '5'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('5', '5'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('5', '5'), (')', ')'), ('.', '.')]


------------------- Sentence 4 -------------------

RNNs process an input sequence one element at a  time, maintaining in their hidden units a ‘state vector’ that implicitly  contains information about the history of all the past elements of  the sequence.

>> Tokens are: 
 ['RNNs', 'process', 'input', 'sequence', 'one', 'element', 'time', ',', 'maintaining', 'hidden', 'units', '‘', 'state', 'vector', '’', 'implicitly', 'contains', 'information', 'history', 'past', 'elements', 'sequence', '.']

>> Bigrams are: 
 [('RNNs', 'process'), ('process', 'input'), ('input', 'sequence'), ('sequence', 'one'), ('one', 'element'), ('element', 'time'), ('time', ','), (',', 'maintaining'), ('maintaining', 'hidden'), ('hidden', 'units'), ('units', '‘'), ('‘', 'state'), ('state', 'vector'), ('vector', '’'), ('’', 'implicitly'), ('implicitly', 'contains'), ('contains', 'information'), ('information', 'history'), ('history', 'past'), ('past', 'elements'), ('elements', 'sequence'), ('sequence', '.')]

>> Trigrams are: 
 [('RNNs', 'process', 'input'), ('process', 'input', 'sequence'), ('input', 'sequence', 'one'), ('sequence', 'one', 'element'), ('one', 'element', 'time'), ('element', 'time', ','), ('time', ',', 'maintaining'), (',', 'maintaining', 'hidden'), ('maintaining', 'hidden', 'units'), ('hidden', 'units', '‘'), ('units', '‘', 'state'), ('‘', 'state', 'vector'), ('state', 'vector', '’'), ('vector', '’', 'implicitly'), ('’', 'implicitly', 'contains'), ('implicitly', 'contains', 'information'), ('contains', 'information', 'history'), ('information', 'history', 'past'), ('history', 'past', 'elements'), ('past', 'elements', 'sequence'), ('elements', 'sequence', '.')]

>> POS Tags are: 
 [('RNNs', 'NNP'), ('process', 'NN'), ('input', 'NN'), ('sequence', 'NN'), ('one', 'CD'), ('element', 'NN'), ('time', 'NN'), (',', ','), ('maintaining', 'VBG'), ('hidden', 'JJ'), ('units', 'NNS'), ('‘', 'VBP'), ('state', 'NN'), ('vector', 'NN'), ('’', 'NNP'), ('implicitly', 'RB'), ('contains', 'VBZ'), ('information', 'NN'), ('history', 'NN'), ('past', 'IN'), ('elements', 'NNS'), ('sequence', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['RNNs process input sequence', 'element time', 'hidden units', 'state vector ’', 'information history', 'elements sequence']

>> Named Entities are: 
 [('GPE', 'RNNs')] 

>> Stemming using Porter Stemmer: 
 [('RNNs', 'rnn'), ('process', 'process'), ('input', 'input'), ('sequence', 'sequenc'), ('one', 'one'), ('element', 'element'), ('time', 'time'), (',', ','), ('maintaining', 'maintain'), ('hidden', 'hidden'), ('units', 'unit'), ('‘', '‘'), ('state', 'state'), ('vector', 'vector'), ('’', '’'), ('implicitly', 'implicitli'), ('contains', 'contain'), ('information', 'inform'), ('history', 'histori'), ('past', 'past'), ('elements', 'element'), ('sequence', 'sequenc'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('RNNs', 'rnns'), ('process', 'process'), ('input', 'input'), ('sequence', 'sequenc'), ('one', 'one'), ('element', 'element'), ('time', 'time'), (',', ','), ('maintaining', 'maintain'), ('hidden', 'hidden'), ('units', 'unit'), ('‘', '‘'), ('state', 'state'), ('vector', 'vector'), ('’', '’'), ('implicitly', 'implicit'), ('contains', 'contain'), ('information', 'inform'), ('history', 'histori'), ('past', 'past'), ('elements', 'element'), ('sequence', 'sequenc'), ('.', '.')]

>> Lemmatization: 
 [('RNNs', 'RNNs'), ('process', 'process'), ('input', 'input'), ('sequence', 'sequence'), ('one', 'one'), ('element', 'element'), ('time', 'time'), (',', ','), ('maintaining', 'maintaining'), ('hidden', 'hidden'), ('units', 'unit'), ('‘', '‘'), ('state', 'state'), ('vector', 'vector'), ('’', '’'), ('implicitly', 'implicitly'), ('contains', 'contains'), ('information', 'information'), ('history', 'history'), ('past', 'past'), ('elements', 'element'), ('sequence', 'sequence'), ('.', '.')]


------------------- Sentence 5 -------------------

When we consider the outputs of the hidden units at  different discrete time steps as if they were the outputs of different  neurons in a deep multilayer network (Fig.

>> Tokens are: 
 ['When', 'consider', 'outputs', 'hidden', 'units', 'different', 'discrete', 'time', 'steps', 'outputs', 'different', 'neurons', 'deep', 'multilayer', 'network', '(', 'Fig', '.']

>> Bigrams are: 
 [('When', 'consider'), ('consider', 'outputs'), ('outputs', 'hidden'), ('hidden', 'units'), ('units', 'different'), ('different', 'discrete'), ('discrete', 'time'), ('time', 'steps'), ('steps', 'outputs'), ('outputs', 'different'), ('different', 'neurons'), ('neurons', 'deep'), ('deep', 'multilayer'), ('multilayer', 'network'), ('network', '('), ('(', 'Fig'), ('Fig', '.')]

>> Trigrams are: 
 [('When', 'consider', 'outputs'), ('consider', 'outputs', 'hidden'), ('outputs', 'hidden', 'units'), ('hidden', 'units', 'different'), ('units', 'different', 'discrete'), ('different', 'discrete', 'time'), ('discrete', 'time', 'steps'), ('time', 'steps', 'outputs'), ('steps', 'outputs', 'different'), ('outputs', 'different', 'neurons'), ('different', 'neurons', 'deep'), ('neurons', 'deep', 'multilayer'), ('deep', 'multilayer', 'network'), ('multilayer', 'network', '('), ('network', '(', 'Fig'), ('(', 'Fig', '.')]

>> POS Tags are: 
 [('When', 'WRB'), ('consider', 'NN'), ('outputs', 'VBZ'), ('hidden', 'JJ'), ('units', 'NNS'), ('different', 'JJ'), ('discrete', 'JJ'), ('time', 'NN'), ('steps', 'NNS'), ('outputs', 'RB'), ('different', 'JJ'), ('neurons', 'NNS'), ('deep', 'VBP'), ('multilayer', 'NN'), ('network', 'NN'), ('(', '('), ('Fig', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['consider', 'hidden units', 'different discrete time steps', 'different neurons', 'multilayer network', 'Fig']

>> Named Entities are: 
 [('ORGANIZATION', 'Fig')] 

>> Stemming using Porter Stemmer: 
 [('When', 'when'), ('consider', 'consid'), ('outputs', 'output'), ('hidden', 'hidden'), ('units', 'unit'), ('different', 'differ'), ('discrete', 'discret'), ('time', 'time'), ('steps', 'step'), ('outputs', 'output'), ('different', 'differ'), ('neurons', 'neuron'), ('deep', 'deep'), ('multilayer', 'multilay'), ('network', 'network'), ('(', '('), ('Fig', 'fig'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('When', 'when'), ('consider', 'consid'), ('outputs', 'output'), ('hidden', 'hidden'), ('units', 'unit'), ('different', 'differ'), ('discrete', 'discret'), ('time', 'time'), ('steps', 'step'), ('outputs', 'output'), ('different', 'differ'), ('neurons', 'neuron'), ('deep', 'deep'), ('multilayer', 'multilay'), ('network', 'network'), ('(', '('), ('Fig', 'fig'), ('.', '.')]

>> Lemmatization: 
 [('When', 'When'), ('consider', 'consider'), ('outputs', 'output'), ('hidden', 'hidden'), ('units', 'unit'), ('different', 'different'), ('discrete', 'discrete'), ('time', 'time'), ('steps', 'step'), ('outputs', 'output'), ('different', 'different'), ('neurons', 'neuron'), ('deep', 'deep'), ('multilayer', 'multilayer'), ('network', 'network'), ('(', '('), ('Fig', 'Fig'), ('.', '.')]


------------------- Sentence 6 -------------------

5, right), it becomes clear  how we can apply backpropagation to train RNNs.

>> Tokens are: 
 ['5', ',', 'right', ')', ',', 'becomes', 'clear', 'apply', 'backpropagation', 'train', 'RNNs', '.']

>> Bigrams are: 
 [('5', ','), (',', 'right'), ('right', ')'), (')', ','), (',', 'becomes'), ('becomes', 'clear'), ('clear', 'apply'), ('apply', 'backpropagation'), ('backpropagation', 'train'), ('train', 'RNNs'), ('RNNs', '.')]

>> Trigrams are: 
 [('5', ',', 'right'), (',', 'right', ')'), ('right', ')', ','), (')', ',', 'becomes'), (',', 'becomes', 'clear'), ('becomes', 'clear', 'apply'), ('clear', 'apply', 'backpropagation'), ('apply', 'backpropagation', 'train'), ('backpropagation', 'train', 'RNNs'), ('train', 'RNNs', '.')]

>> POS Tags are: 
 [('5', 'CD'), (',', ','), ('right', 'RB'), (')', ')'), (',', ','), ('becomes', 'VBZ'), ('clear', 'JJ'), ('apply', 'IN'), ('backpropagation', 'NN'), ('train', 'NN'), ('RNNs', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['backpropagation train RNNs']

>> Named Entities are: 
 [('ORGANIZATION', 'RNNs')] 

>> Stemming using Porter Stemmer: 
 [('5', '5'), (',', ','), ('right', 'right'), (')', ')'), (',', ','), ('becomes', 'becom'), ('clear', 'clear'), ('apply', 'appli'), ('backpropagation', 'backpropag'), ('train', 'train'), ('RNNs', 'rnn'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('5', '5'), (',', ','), ('right', 'right'), (')', ')'), (',', ','), ('becomes', 'becom'), ('clear', 'clear'), ('apply', 'appli'), ('backpropagation', 'backpropag'), ('train', 'train'), ('RNNs', 'rnns'), ('.', '.')]

>> Lemmatization: 
 [('5', '5'), (',', ','), ('right', 'right'), (')', ')'), (',', ','), ('becomes', 'becomes'), ('clear', 'clear'), ('apply', 'apply'), ('backpropagation', 'backpropagation'), ('train', 'train'), ('RNNs', 'RNNs'), ('.', '.')]



========================================== PARAGRAPH 156 ===========================================

RNNs are very powerful dynamic systems, but training them has  proved to be problematic because the backpropagated gradients  either grow or shrink at each time step, so over many time steps they  typically explode or vanish77,78.  

------------------- Sentence 1 -------------------

RNNs are very powerful dynamic systems, but training them has  proved to be problematic because the backpropagated gradients  either grow or shrink at each time step, so over many time steps they  typically explode or vanish77,78.

>> Tokens are: 
 ['RNNs', 'powerful', 'dynamic', 'systems', ',', 'training', 'proved', 'problematic', 'backpropagated', 'gradients', 'either', 'grow', 'shrink', 'time', 'step', ',', 'many', 'time', 'steps', 'typically', 'explode', 'vanish77,78', '.']

>> Bigrams are: 
 [('RNNs', 'powerful'), ('powerful', 'dynamic'), ('dynamic', 'systems'), ('systems', ','), (',', 'training'), ('training', 'proved'), ('proved', 'problematic'), ('problematic', 'backpropagated'), ('backpropagated', 'gradients'), ('gradients', 'either'), ('either', 'grow'), ('grow', 'shrink'), ('shrink', 'time'), ('time', 'step'), ('step', ','), (',', 'many'), ('many', 'time'), ('time', 'steps'), ('steps', 'typically'), ('typically', 'explode'), ('explode', 'vanish77,78'), ('vanish77,78', '.')]

>> Trigrams are: 
 [('RNNs', 'powerful', 'dynamic'), ('powerful', 'dynamic', 'systems'), ('dynamic', 'systems', ','), ('systems', ',', 'training'), (',', 'training', 'proved'), ('training', 'proved', 'problematic'), ('proved', 'problematic', 'backpropagated'), ('problematic', 'backpropagated', 'gradients'), ('backpropagated', 'gradients', 'either'), ('gradients', 'either', 'grow'), ('either', 'grow', 'shrink'), ('grow', 'shrink', 'time'), ('shrink', 'time', 'step'), ('time', 'step', ','), ('step', ',', 'many'), (',', 'many', 'time'), ('many', 'time', 'steps'), ('time', 'steps', 'typically'), ('steps', 'typically', 'explode'), ('typically', 'explode', 'vanish77,78'), ('explode', 'vanish77,78', '.')]

>> POS Tags are: 
 [('RNNs', 'NNP'), ('powerful', 'JJ'), ('dynamic', 'JJ'), ('systems', 'NNS'), (',', ','), ('training', 'VBG'), ('proved', 'VBN'), ('problematic', 'JJ'), ('backpropagated', 'VBD'), ('gradients', 'NNS'), ('either', 'CC'), ('grow', 'VB'), ('shrink', 'NN'), ('time', 'NN'), ('step', 'NN'), (',', ','), ('many', 'JJ'), ('time', 'NN'), ('steps', 'NNS'), ('typically', 'RB'), ('explode', 'VBP'), ('vanish77,78', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['RNNs', 'powerful dynamic systems', 'gradients', 'shrink time step', 'many time steps', 'vanish77,78']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('RNNs', 'rnn'), ('powerful', 'power'), ('dynamic', 'dynam'), ('systems', 'system'), (',', ','), ('training', 'train'), ('proved', 'prove'), ('problematic', 'problemat'), ('backpropagated', 'backpropag'), ('gradients', 'gradient'), ('either', 'either'), ('grow', 'grow'), ('shrink', 'shrink'), ('time', 'time'), ('step', 'step'), (',', ','), ('many', 'mani'), ('time', 'time'), ('steps', 'step'), ('typically', 'typic'), ('explode', 'explod'), ('vanish77,78', 'vanish77,78'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('RNNs', 'rnns'), ('powerful', 'power'), ('dynamic', 'dynam'), ('systems', 'system'), (',', ','), ('training', 'train'), ('proved', 'prove'), ('problematic', 'problemat'), ('backpropagated', 'backpropag'), ('gradients', 'gradient'), ('either', 'either'), ('grow', 'grow'), ('shrink', 'shrink'), ('time', 'time'), ('step', 'step'), (',', ','), ('many', 'mani'), ('time', 'time'), ('steps', 'step'), ('typically', 'typic'), ('explode', 'explod'), ('vanish77,78', 'vanish77,78'), ('.', '.')]

>> Lemmatization: 
 [('RNNs', 'RNNs'), ('powerful', 'powerful'), ('dynamic', 'dynamic'), ('systems', 'system'), (',', ','), ('training', 'training'), ('proved', 'proved'), ('problematic', 'problematic'), ('backpropagated', 'backpropagated'), ('gradients', 'gradient'), ('either', 'either'), ('grow', 'grow'), ('shrink', 'shrink'), ('time', 'time'), ('step', 'step'), (',', ','), ('many', 'many'), ('time', 'time'), ('steps', 'step'), ('typically', 'typically'), ('explode', 'explode'), ('vanish77,78', 'vanish77,78'), ('.', '.')]



========================================== PARAGRAPH 157 ===========================================

Thanks to advances in their architecture79,80 and ways of training  them81,82, RNNs have been found to be very good at predicting the  next character in the text83 or the next word in a sequence75, but they  can also be used for more complex tasks. For example, after reading  an English sentence one word at a time, an English ‘encoder’ network  can be trained so that the final state vector of its hidden units is a good  representation of the thought expressed by the sentence. This thought  vector can then be used as the initial hidden state of (or as extra input  to) a jointly trained French ‘decoder’ network, which outputs a prob- ability distribution for the first word of the French translation. If a  particular first word is chosen from this distribution and provided  as input to the decoder network it will then output a probability dis- tribution for the second word of the translation and so on until a  full stop is chosen17,72,76. Overall, this process generates sequences of  French words according to a probability distribution that depends on  the English sentence. This rather naive way of performing machine  translation has quickly become competitive with the state-of-the-art,  and this raises serious doubts about whether understanding a sen- tence requires anything like the internal symbolic expressions that are  manipulated by using inference rules. It is more compatible with the  view that everyday reasoning involves many simultaneous analogies  

------------------- Sentence 1 -------------------

Thanks to advances in their architecture79,80 and ways of training  them81,82, RNNs have been found to be very good at predicting the  next character in the text83 or the next word in a sequence75, but they  can also be used for more complex tasks.

>> Tokens are: 
 ['Thanks', 'advances', 'architecture79,80', 'ways', 'training', 'them81,82', ',', 'RNNs', 'found', 'good', 'predicting', 'next', 'character', 'text83', 'next', 'word', 'sequence75', ',', 'also', 'used', 'complex', 'tasks', '.']

>> Bigrams are: 
 [('Thanks', 'advances'), ('advances', 'architecture79,80'), ('architecture79,80', 'ways'), ('ways', 'training'), ('training', 'them81,82'), ('them81,82', ','), (',', 'RNNs'), ('RNNs', 'found'), ('found', 'good'), ('good', 'predicting'), ('predicting', 'next'), ('next', 'character'), ('character', 'text83'), ('text83', 'next'), ('next', 'word'), ('word', 'sequence75'), ('sequence75', ','), (',', 'also'), ('also', 'used'), ('used', 'complex'), ('complex', 'tasks'), ('tasks', '.')]

>> Trigrams are: 
 [('Thanks', 'advances', 'architecture79,80'), ('advances', 'architecture79,80', 'ways'), ('architecture79,80', 'ways', 'training'), ('ways', 'training', 'them81,82'), ('training', 'them81,82', ','), ('them81,82', ',', 'RNNs'), (',', 'RNNs', 'found'), ('RNNs', 'found', 'good'), ('found', 'good', 'predicting'), ('good', 'predicting', 'next'), ('predicting', 'next', 'character'), ('next', 'character', 'text83'), ('character', 'text83', 'next'), ('text83', 'next', 'word'), ('next', 'word', 'sequence75'), ('word', 'sequence75', ','), ('sequence75', ',', 'also'), (',', 'also', 'used'), ('also', 'used', 'complex'), ('used', 'complex', 'tasks'), ('complex', 'tasks', '.')]

>> POS Tags are: 
 [('Thanks', 'NNS'), ('advances', 'NNS'), ('architecture79,80', 'VBP'), ('ways', 'NNS'), ('training', 'VBG'), ('them81,82', 'NN'), (',', ','), ('RNNs', 'NNP'), ('found', 'VBD'), ('good', 'JJ'), ('predicting', 'VBG'), ('next', 'JJ'), ('character', 'NN'), ('text83', 'NN'), ('next', 'JJ'), ('word', 'NN'), ('sequence75', 'NN'), (',', ','), ('also', 'RB'), ('used', 'VBD'), ('complex', 'JJ'), ('tasks', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['Thanks advances', 'ways', 'them81,82', 'RNNs', 'next character text83', 'next word sequence75', 'complex tasks']

>> Named Entities are: 
 [('GPE', 'Thanks'), ('ORGANIZATION', 'RNNs')] 

>> Stemming using Porter Stemmer: 
 [('Thanks', 'thank'), ('advances', 'advanc'), ('architecture79,80', 'architecture79,80'), ('ways', 'way'), ('training', 'train'), ('them81,82', 'them81,82'), (',', ','), ('RNNs', 'rnn'), ('found', 'found'), ('good', 'good'), ('predicting', 'predict'), ('next', 'next'), ('character', 'charact'), ('text83', 'text83'), ('next', 'next'), ('word', 'word'), ('sequence75', 'sequence75'), (',', ','), ('also', 'also'), ('used', 'use'), ('complex', 'complex'), ('tasks', 'task'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Thanks', 'thank'), ('advances', 'advanc'), ('architecture79,80', 'architecture79,80'), ('ways', 'way'), ('training', 'train'), ('them81,82', 'them81,82'), (',', ','), ('RNNs', 'rnns'), ('found', 'found'), ('good', 'good'), ('predicting', 'predict'), ('next', 'next'), ('character', 'charact'), ('text83', 'text83'), ('next', 'next'), ('word', 'word'), ('sequence75', 'sequence75'), (',', ','), ('also', 'also'), ('used', 'use'), ('complex', 'complex'), ('tasks', 'task'), ('.', '.')]

>> Lemmatization: 
 [('Thanks', 'Thanks'), ('advances', 'advance'), ('architecture79,80', 'architecture79,80'), ('ways', 'way'), ('training', 'training'), ('them81,82', 'them81,82'), (',', ','), ('RNNs', 'RNNs'), ('found', 'found'), ('good', 'good'), ('predicting', 'predicting'), ('next', 'next'), ('character', 'character'), ('text83', 'text83'), ('next', 'next'), ('word', 'word'), ('sequence75', 'sequence75'), (',', ','), ('also', 'also'), ('used', 'used'), ('complex', 'complex'), ('tasks', 'task'), ('.', '.')]


------------------- Sentence 2 -------------------

For example, after reading  an English sentence one word at a time, an English ‘encoder’ network  can be trained so that the final state vector of its hidden units is a good  representation of the thought expressed by the sentence.

>> Tokens are: 
 ['For', 'example', ',', 'reading', 'English', 'sentence', 'one', 'word', 'time', ',', 'English', '‘', 'encoder', '’', 'network', 'trained', 'final', 'state', 'vector', 'hidden', 'units', 'good', 'representation', 'thought', 'expressed', 'sentence', '.']

>> Bigrams are: 
 [('For', 'example'), ('example', ','), (',', 'reading'), ('reading', 'English'), ('English', 'sentence'), ('sentence', 'one'), ('one', 'word'), ('word', 'time'), ('time', ','), (',', 'English'), ('English', '‘'), ('‘', 'encoder'), ('encoder', '’'), ('’', 'network'), ('network', 'trained'), ('trained', 'final'), ('final', 'state'), ('state', 'vector'), ('vector', 'hidden'), ('hidden', 'units'), ('units', 'good'), ('good', 'representation'), ('representation', 'thought'), ('thought', 'expressed'), ('expressed', 'sentence'), ('sentence', '.')]

>> Trigrams are: 
 [('For', 'example', ','), ('example', ',', 'reading'), (',', 'reading', 'English'), ('reading', 'English', 'sentence'), ('English', 'sentence', 'one'), ('sentence', 'one', 'word'), ('one', 'word', 'time'), ('word', 'time', ','), ('time', ',', 'English'), (',', 'English', '‘'), ('English', '‘', 'encoder'), ('‘', 'encoder', '’'), ('encoder', '’', 'network'), ('’', 'network', 'trained'), ('network', 'trained', 'final'), ('trained', 'final', 'state'), ('final', 'state', 'vector'), ('state', 'vector', 'hidden'), ('vector', 'hidden', 'units'), ('hidden', 'units', 'good'), ('units', 'good', 'representation'), ('good', 'representation', 'thought'), ('representation', 'thought', 'expressed'), ('thought', 'expressed', 'sentence'), ('expressed', 'sentence', '.')]

>> POS Tags are: 
 [('For', 'IN'), ('example', 'NN'), (',', ','), ('reading', 'VBG'), ('English', 'JJ'), ('sentence', 'NN'), ('one', 'CD'), ('word', 'NN'), ('time', 'NN'), (',', ','), ('English', 'NNP'), ('‘', 'NNP'), ('encoder', 'NN'), ('’', 'NNP'), ('network', 'NN'), ('trained', 'VBD'), ('final', 'JJ'), ('state', 'NN'), ('vector', 'NN'), ('hidden', 'JJ'), ('units', 'NNS'), ('good', 'JJ'), ('representation', 'NN'), ('thought', 'VBD'), ('expressed', 'VBN'), ('sentence', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['example', 'English sentence', 'word time', 'English ‘ encoder ’ network', 'final state vector', 'hidden units', 'good representation', 'sentence']

>> Named Entities are: 
 [('GPE', 'English'), ('PERSON', 'English')] 

>> Stemming using Porter Stemmer: 
 [('For', 'for'), ('example', 'exampl'), (',', ','), ('reading', 'read'), ('English', 'english'), ('sentence', 'sentenc'), ('one', 'one'), ('word', 'word'), ('time', 'time'), (',', ','), ('English', 'english'), ('‘', '‘'), ('encoder', 'encod'), ('’', '’'), ('network', 'network'), ('trained', 'train'), ('final', 'final'), ('state', 'state'), ('vector', 'vector'), ('hidden', 'hidden'), ('units', 'unit'), ('good', 'good'), ('representation', 'represent'), ('thought', 'thought'), ('expressed', 'express'), ('sentence', 'sentenc'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('For', 'for'), ('example', 'exampl'), (',', ','), ('reading', 'read'), ('English', 'english'), ('sentence', 'sentenc'), ('one', 'one'), ('word', 'word'), ('time', 'time'), (',', ','), ('English', 'english'), ('‘', '‘'), ('encoder', 'encod'), ('’', '’'), ('network', 'network'), ('trained', 'train'), ('final', 'final'), ('state', 'state'), ('vector', 'vector'), ('hidden', 'hidden'), ('units', 'unit'), ('good', 'good'), ('representation', 'represent'), ('thought', 'thought'), ('expressed', 'express'), ('sentence', 'sentenc'), ('.', '.')]

>> Lemmatization: 
 [('For', 'For'), ('example', 'example'), (',', ','), ('reading', 'reading'), ('English', 'English'), ('sentence', 'sentence'), ('one', 'one'), ('word', 'word'), ('time', 'time'), (',', ','), ('English', 'English'), ('‘', '‘'), ('encoder', 'encoder'), ('’', '’'), ('network', 'network'), ('trained', 'trained'), ('final', 'final'), ('state', 'state'), ('vector', 'vector'), ('hidden', 'hidden'), ('units', 'unit'), ('good', 'good'), ('representation', 'representation'), ('thought', 'thought'), ('expressed', 'expressed'), ('sentence', 'sentence'), ('.', '.')]


------------------- Sentence 3 -------------------

This thought  vector can then be used as the initial hidden state of (or as extra input  to) a jointly trained French ‘decoder’ network, which outputs a prob- ability distribution for the first word of the French translation.

>> Tokens are: 
 ['This', 'thought', 'vector', 'used', 'initial', 'hidden', 'state', '(', 'extra', 'input', ')', 'jointly', 'trained', 'French', '‘', 'decoder', '’', 'network', ',', 'outputs', 'prob-', 'ability', 'distribution', 'first', 'word', 'French', 'translation', '.']

>> Bigrams are: 
 [('This', 'thought'), ('thought', 'vector'), ('vector', 'used'), ('used', 'initial'), ('initial', 'hidden'), ('hidden', 'state'), ('state', '('), ('(', 'extra'), ('extra', 'input'), ('input', ')'), (')', 'jointly'), ('jointly', 'trained'), ('trained', 'French'), ('French', '‘'), ('‘', 'decoder'), ('decoder', '’'), ('’', 'network'), ('network', ','), (',', 'outputs'), ('outputs', 'prob-'), ('prob-', 'ability'), ('ability', 'distribution'), ('distribution', 'first'), ('first', 'word'), ('word', 'French'), ('French', 'translation'), ('translation', '.')]

>> Trigrams are: 
 [('This', 'thought', 'vector'), ('thought', 'vector', 'used'), ('vector', 'used', 'initial'), ('used', 'initial', 'hidden'), ('initial', 'hidden', 'state'), ('hidden', 'state', '('), ('state', '(', 'extra'), ('(', 'extra', 'input'), ('extra', 'input', ')'), ('input', ')', 'jointly'), (')', 'jointly', 'trained'), ('jointly', 'trained', 'French'), ('trained', 'French', '‘'), ('French', '‘', 'decoder'), ('‘', 'decoder', '’'), ('decoder', '’', 'network'), ('’', 'network', ','), ('network', ',', 'outputs'), (',', 'outputs', 'prob-'), ('outputs', 'prob-', 'ability'), ('prob-', 'ability', 'distribution'), ('ability', 'distribution', 'first'), ('distribution', 'first', 'word'), ('first', 'word', 'French'), ('word', 'French', 'translation'), ('French', 'translation', '.')]

>> POS Tags are: 
 [('This', 'DT'), ('thought', 'VBD'), ('vector', 'NN'), ('used', 'VBN'), ('initial', 'JJ'), ('hidden', 'JJ'), ('state', 'NN'), ('(', '('), ('extra', 'JJ'), ('input', 'NN'), (')', ')'), ('jointly', 'RB'), ('trained', 'VBN'), ('French', 'JJ'), ('‘', 'NNP'), ('decoder', 'NN'), ('’', 'NNP'), ('network', 'NN'), (',', ','), ('outputs', 'VBZ'), ('prob-', 'JJ'), ('ability', 'NN'), ('distribution', 'NN'), ('first', 'RB'), ('word', 'NN'), ('French', 'JJ'), ('translation', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['vector', 'initial hidden state', 'extra input', 'French ‘ decoder ’ network', 'prob- ability distribution', 'word', 'French translation']

>> Named Entities are: 
 [('GPE', 'French'), ('GPE', 'French')] 

>> Stemming using Porter Stemmer: 
 [('This', 'thi'), ('thought', 'thought'), ('vector', 'vector'), ('used', 'use'), ('initial', 'initi'), ('hidden', 'hidden'), ('state', 'state'), ('(', '('), ('extra', 'extra'), ('input', 'input'), (')', ')'), ('jointly', 'jointli'), ('trained', 'train'), ('French', 'french'), ('‘', '‘'), ('decoder', 'decod'), ('’', '’'), ('network', 'network'), (',', ','), ('outputs', 'output'), ('prob-', 'prob-'), ('ability', 'abil'), ('distribution', 'distribut'), ('first', 'first'), ('word', 'word'), ('French', 'french'), ('translation', 'translat'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('This', 'this'), ('thought', 'thought'), ('vector', 'vector'), ('used', 'use'), ('initial', 'initi'), ('hidden', 'hidden'), ('state', 'state'), ('(', '('), ('extra', 'extra'), ('input', 'input'), (')', ')'), ('jointly', 'joint'), ('trained', 'train'), ('French', 'french'), ('‘', '‘'), ('decoder', 'decod'), ('’', '’'), ('network', 'network'), (',', ','), ('outputs', 'output'), ('prob-', 'prob-'), ('ability', 'abil'), ('distribution', 'distribut'), ('first', 'first'), ('word', 'word'), ('French', 'french'), ('translation', 'translat'), ('.', '.')]

>> Lemmatization: 
 [('This', 'This'), ('thought', 'thought'), ('vector', 'vector'), ('used', 'used'), ('initial', 'initial'), ('hidden', 'hidden'), ('state', 'state'), ('(', '('), ('extra', 'extra'), ('input', 'input'), (')', ')'), ('jointly', 'jointly'), ('trained', 'trained'), ('French', 'French'), ('‘', '‘'), ('decoder', 'decoder'), ('’', '’'), ('network', 'network'), (',', ','), ('outputs', 'output'), ('prob-', 'prob-'), ('ability', 'ability'), ('distribution', 'distribution'), ('first', 'first'), ('word', 'word'), ('French', 'French'), ('translation', 'translation'), ('.', '.')]


------------------- Sentence 4 -------------------

If a  particular first word is chosen from this distribution and provided  as input to the decoder network it will then output a probability dis- tribution for the second word of the translation and so on until a  full stop is chosen17,72,76.

>> Tokens are: 
 ['If', 'particular', 'first', 'word', 'chosen', 'distribution', 'provided', 'input', 'decoder', 'network', 'output', 'probability', 'dis-', 'tribution', 'second', 'word', 'translation', 'full', 'stop', 'chosen17,72,76', '.']

>> Bigrams are: 
 [('If', 'particular'), ('particular', 'first'), ('first', 'word'), ('word', 'chosen'), ('chosen', 'distribution'), ('distribution', 'provided'), ('provided', 'input'), ('input', 'decoder'), ('decoder', 'network'), ('network', 'output'), ('output', 'probability'), ('probability', 'dis-'), ('dis-', 'tribution'), ('tribution', 'second'), ('second', 'word'), ('word', 'translation'), ('translation', 'full'), ('full', 'stop'), ('stop', 'chosen17,72,76'), ('chosen17,72,76', '.')]

>> Trigrams are: 
 [('If', 'particular', 'first'), ('particular', 'first', 'word'), ('first', 'word', 'chosen'), ('word', 'chosen', 'distribution'), ('chosen', 'distribution', 'provided'), ('distribution', 'provided', 'input'), ('provided', 'input', 'decoder'), ('input', 'decoder', 'network'), ('decoder', 'network', 'output'), ('network', 'output', 'probability'), ('output', 'probability', 'dis-'), ('probability', 'dis-', 'tribution'), ('dis-', 'tribution', 'second'), ('tribution', 'second', 'word'), ('second', 'word', 'translation'), ('word', 'translation', 'full'), ('translation', 'full', 'stop'), ('full', 'stop', 'chosen17,72,76'), ('stop', 'chosen17,72,76', '.')]

>> POS Tags are: 
 [('If', 'IN'), ('particular', 'JJ'), ('first', 'JJ'), ('word', 'NN'), ('chosen', 'VBN'), ('distribution', 'NN'), ('provided', 'VBD'), ('input', 'NN'), ('decoder', 'NN'), ('network', 'NN'), ('output', 'NN'), ('probability', 'NN'), ('dis-', 'JJ'), ('tribution', 'NN'), ('second', 'JJ'), ('word', 'NN'), ('translation', 'NN'), ('full', 'JJ'), ('stop', 'NN'), ('chosen17,72,76', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['particular first word', 'distribution', 'input decoder network output probability', 'dis- tribution', 'second word translation', 'full stop chosen17,72,76']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('If', 'if'), ('particular', 'particular'), ('first', 'first'), ('word', 'word'), ('chosen', 'chosen'), ('distribution', 'distribut'), ('provided', 'provid'), ('input', 'input'), ('decoder', 'decod'), ('network', 'network'), ('output', 'output'), ('probability', 'probabl'), ('dis-', 'dis-'), ('tribution', 'tribut'), ('second', 'second'), ('word', 'word'), ('translation', 'translat'), ('full', 'full'), ('stop', 'stop'), ('chosen17,72,76', 'chosen17,72,76'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('If', 'if'), ('particular', 'particular'), ('first', 'first'), ('word', 'word'), ('chosen', 'chosen'), ('distribution', 'distribut'), ('provided', 'provid'), ('input', 'input'), ('decoder', 'decod'), ('network', 'network'), ('output', 'output'), ('probability', 'probabl'), ('dis-', 'dis-'), ('tribution', 'tribut'), ('second', 'second'), ('word', 'word'), ('translation', 'translat'), ('full', 'full'), ('stop', 'stop'), ('chosen17,72,76', 'chosen17,72,76'), ('.', '.')]

>> Lemmatization: 
 [('If', 'If'), ('particular', 'particular'), ('first', 'first'), ('word', 'word'), ('chosen', 'chosen'), ('distribution', 'distribution'), ('provided', 'provided'), ('input', 'input'), ('decoder', 'decoder'), ('network', 'network'), ('output', 'output'), ('probability', 'probability'), ('dis-', 'dis-'), ('tribution', 'tribution'), ('second', 'second'), ('word', 'word'), ('translation', 'translation'), ('full', 'full'), ('stop', 'stop'), ('chosen17,72,76', 'chosen17,72,76'), ('.', '.')]


------------------- Sentence 5 -------------------

Overall, this process generates sequences of  French words according to a probability distribution that depends on  the English sentence.

>> Tokens are: 
 ['Overall', ',', 'process', 'generates', 'sequences', 'French', 'words', 'according', 'probability', 'distribution', 'depends', 'English', 'sentence', '.']

>> Bigrams are: 
 [('Overall', ','), (',', 'process'), ('process', 'generates'), ('generates', 'sequences'), ('sequences', 'French'), ('French', 'words'), ('words', 'according'), ('according', 'probability'), ('probability', 'distribution'), ('distribution', 'depends'), ('depends', 'English'), ('English', 'sentence'), ('sentence', '.')]

>> Trigrams are: 
 [('Overall', ',', 'process'), (',', 'process', 'generates'), ('process', 'generates', 'sequences'), ('generates', 'sequences', 'French'), ('sequences', 'French', 'words'), ('French', 'words', 'according'), ('words', 'according', 'probability'), ('according', 'probability', 'distribution'), ('probability', 'distribution', 'depends'), ('distribution', 'depends', 'English'), ('depends', 'English', 'sentence'), ('English', 'sentence', '.')]

>> POS Tags are: 
 [('Overall', 'JJ'), (',', ','), ('process', 'NN'), ('generates', 'NNS'), ('sequences', 'NNS'), ('French', 'JJ'), ('words', 'NNS'), ('according', 'VBG'), ('probability', 'NN'), ('distribution', 'NN'), ('depends', 'VBZ'), ('English', 'JJ'), ('sentence', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['process generates sequences', 'French words', 'probability distribution', 'English sentence']

>> Named Entities are: 
 [('GPE', 'Overall'), ('GPE', 'French'), ('GPE', 'English')] 

>> Stemming using Porter Stemmer: 
 [('Overall', 'overal'), (',', ','), ('process', 'process'), ('generates', 'gener'), ('sequences', 'sequenc'), ('French', 'french'), ('words', 'word'), ('according', 'accord'), ('probability', 'probabl'), ('distribution', 'distribut'), ('depends', 'depend'), ('English', 'english'), ('sentence', 'sentenc'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Overall', 'overal'), (',', ','), ('process', 'process'), ('generates', 'generat'), ('sequences', 'sequenc'), ('French', 'french'), ('words', 'word'), ('according', 'accord'), ('probability', 'probabl'), ('distribution', 'distribut'), ('depends', 'depend'), ('English', 'english'), ('sentence', 'sentenc'), ('.', '.')]

>> Lemmatization: 
 [('Overall', 'Overall'), (',', ','), ('process', 'process'), ('generates', 'generates'), ('sequences', 'sequence'), ('French', 'French'), ('words', 'word'), ('according', 'according'), ('probability', 'probability'), ('distribution', 'distribution'), ('depends', 'depends'), ('English', 'English'), ('sentence', 'sentence'), ('.', '.')]


------------------- Sentence 6 -------------------

This rather naive way of performing machine  translation has quickly become competitive with the state-of-the-art,  and this raises serious doubts about whether understanding a sen- tence requires anything like the internal symbolic expressions that are  manipulated by using inference rules.

>> Tokens are: 
 ['This', 'rather', 'naive', 'way', 'performing', 'machine', 'translation', 'quickly', 'become', 'competitive', 'state-of-the-art', ',', 'raises', 'serious', 'doubts', 'whether', 'understanding', 'sen-', 'tence', 'requires', 'anything', 'like', 'internal', 'symbolic', 'expressions', 'manipulated', 'using', 'inference', 'rules', '.']

>> Bigrams are: 
 [('This', 'rather'), ('rather', 'naive'), ('naive', 'way'), ('way', 'performing'), ('performing', 'machine'), ('machine', 'translation'), ('translation', 'quickly'), ('quickly', 'become'), ('become', 'competitive'), ('competitive', 'state-of-the-art'), ('state-of-the-art', ','), (',', 'raises'), ('raises', 'serious'), ('serious', 'doubts'), ('doubts', 'whether'), ('whether', 'understanding'), ('understanding', 'sen-'), ('sen-', 'tence'), ('tence', 'requires'), ('requires', 'anything'), ('anything', 'like'), ('like', 'internal'), ('internal', 'symbolic'), ('symbolic', 'expressions'), ('expressions', 'manipulated'), ('manipulated', 'using'), ('using', 'inference'), ('inference', 'rules'), ('rules', '.')]

>> Trigrams are: 
 [('This', 'rather', 'naive'), ('rather', 'naive', 'way'), ('naive', 'way', 'performing'), ('way', 'performing', 'machine'), ('performing', 'machine', 'translation'), ('machine', 'translation', 'quickly'), ('translation', 'quickly', 'become'), ('quickly', 'become', 'competitive'), ('become', 'competitive', 'state-of-the-art'), ('competitive', 'state-of-the-art', ','), ('state-of-the-art', ',', 'raises'), (',', 'raises', 'serious'), ('raises', 'serious', 'doubts'), ('serious', 'doubts', 'whether'), ('doubts', 'whether', 'understanding'), ('whether', 'understanding', 'sen-'), ('understanding', 'sen-', 'tence'), ('sen-', 'tence', 'requires'), ('tence', 'requires', 'anything'), ('requires', 'anything', 'like'), ('anything', 'like', 'internal'), ('like', 'internal', 'symbolic'), ('internal', 'symbolic', 'expressions'), ('symbolic', 'expressions', 'manipulated'), ('expressions', 'manipulated', 'using'), ('manipulated', 'using', 'inference'), ('using', 'inference', 'rules'), ('inference', 'rules', '.')]

>> POS Tags are: 
 [('This', 'DT'), ('rather', 'RB'), ('naive', 'JJ'), ('way', 'NN'), ('performing', 'VBG'), ('machine', 'NN'), ('translation', 'NN'), ('quickly', 'RB'), ('become', 'VB'), ('competitive', 'JJ'), ('state-of-the-art', 'JJ'), (',', ','), ('raises', 'VBZ'), ('serious', 'JJ'), ('doubts', 'NNS'), ('whether', 'IN'), ('understanding', 'VBG'), ('sen-', 'JJ'), ('tence', 'NN'), ('requires', 'VBZ'), ('anything', 'NN'), ('like', 'IN'), ('internal', 'JJ'), ('symbolic', 'JJ'), ('expressions', 'NNS'), ('manipulated', 'VBD'), ('using', 'VBG'), ('inference', 'NN'), ('rules', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['naive way', 'machine translation', 'serious doubts', 'sen- tence', 'anything', 'internal symbolic expressions', 'inference rules']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('This', 'thi'), ('rather', 'rather'), ('naive', 'naiv'), ('way', 'way'), ('performing', 'perform'), ('machine', 'machin'), ('translation', 'translat'), ('quickly', 'quickli'), ('become', 'becom'), ('competitive', 'competit'), ('state-of-the-art', 'state-of-the-art'), (',', ','), ('raises', 'rais'), ('serious', 'seriou'), ('doubts', 'doubt'), ('whether', 'whether'), ('understanding', 'understand'), ('sen-', 'sen-'), ('tence', 'tenc'), ('requires', 'requir'), ('anything', 'anyth'), ('like', 'like'), ('internal', 'intern'), ('symbolic', 'symbol'), ('expressions', 'express'), ('manipulated', 'manipul'), ('using', 'use'), ('inference', 'infer'), ('rules', 'rule'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('This', 'this'), ('rather', 'rather'), ('naive', 'naiv'), ('way', 'way'), ('performing', 'perform'), ('machine', 'machin'), ('translation', 'translat'), ('quickly', 'quick'), ('become', 'becom'), ('competitive', 'competit'), ('state-of-the-art', 'state-of-the-art'), (',', ','), ('raises', 'rais'), ('serious', 'serious'), ('doubts', 'doubt'), ('whether', 'whether'), ('understanding', 'understand'), ('sen-', 'sen-'), ('tence', 'tenc'), ('requires', 'requir'), ('anything', 'anyth'), ('like', 'like'), ('internal', 'intern'), ('symbolic', 'symbol'), ('expressions', 'express'), ('manipulated', 'manipul'), ('using', 'use'), ('inference', 'infer'), ('rules', 'rule'), ('.', '.')]

>> Lemmatization: 
 [('This', 'This'), ('rather', 'rather'), ('naive', 'naive'), ('way', 'way'), ('performing', 'performing'), ('machine', 'machine'), ('translation', 'translation'), ('quickly', 'quickly'), ('become', 'become'), ('competitive', 'competitive'), ('state-of-the-art', 'state-of-the-art'), (',', ','), ('raises', 'raise'), ('serious', 'serious'), ('doubts', 'doubt'), ('whether', 'whether'), ('understanding', 'understanding'), ('sen-', 'sen-'), ('tence', 'tence'), ('requires', 'requires'), ('anything', 'anything'), ('like', 'like'), ('internal', 'internal'), ('symbolic', 'symbolic'), ('expressions', 'expression'), ('manipulated', 'manipulated'), ('using', 'using'), ('inference', 'inference'), ('rules', 'rule'), ('.', '.')]


------------------- Sentence 7 -------------------

It is more compatible with the  view that everyday reasoning involves many simultaneous analogies

>> Tokens are: 
 ['It', 'compatible', 'view', 'everyday', 'reasoning', 'involves', 'many', 'simultaneous', 'analogies']

>> Bigrams are: 
 [('It', 'compatible'), ('compatible', 'view'), ('view', 'everyday'), ('everyday', 'reasoning'), ('reasoning', 'involves'), ('involves', 'many'), ('many', 'simultaneous'), ('simultaneous', 'analogies')]

>> Trigrams are: 
 [('It', 'compatible', 'view'), ('compatible', 'view', 'everyday'), ('view', 'everyday', 'reasoning'), ('everyday', 'reasoning', 'involves'), ('reasoning', 'involves', 'many'), ('involves', 'many', 'simultaneous'), ('many', 'simultaneous', 'analogies')]

>> POS Tags are: 
 [('It', 'PRP'), ('compatible', 'JJ'), ('view', 'NN'), ('everyday', 'JJ'), ('reasoning', 'VBG'), ('involves', 'VBZ'), ('many', 'JJ'), ('simultaneous', 'JJ'), ('analogies', 'NNS')]

>> Noun Phrases are: 
 ['compatible view', 'many simultaneous analogies']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('It', 'it'), ('compatible', 'compat'), ('view', 'view'), ('everyday', 'everyday'), ('reasoning', 'reason'), ('involves', 'involv'), ('many', 'mani'), ('simultaneous', 'simultan'), ('analogies', 'analog')]

>> Stemming using Snowball Stemmer: 
 [('It', 'it'), ('compatible', 'compat'), ('view', 'view'), ('everyday', 'everyday'), ('reasoning', 'reason'), ('involves', 'involv'), ('many', 'mani'), ('simultaneous', 'simultan'), ('analogies', 'analog')]

>> Lemmatization: 
 [('It', 'It'), ('compatible', 'compatible'), ('view', 'view'), ('everyday', 'everyday'), ('reasoning', 'reasoning'), ('involves', 'involves'), ('many', 'many'), ('simultaneous', 'simultaneous'), ('analogies', 'analogy')]



========================================== PARAGRAPH 158 ===========================================

Figure 4 | Visualizing the learned word vectors. On the left is an illustration  of word representations learned for modelling language, non-linearly projected  to 2D for visualization using the t-SNE algorithm103. On the right is a 2D  representation of phrases learned by an English-to-French encoder–decoder  recurrent neural network75. One can observe that semantically similar words  

------------------- Sentence 1 -------------------

Figure 4 | Visualizing the learned word vectors.

>> Tokens are: 
 ['Figure', '4', '|', 'Visualizing', 'learned', 'word', 'vectors', '.']

>> Bigrams are: 
 [('Figure', '4'), ('4', '|'), ('|', 'Visualizing'), ('Visualizing', 'learned'), ('learned', 'word'), ('word', 'vectors'), ('vectors', '.')]

>> Trigrams are: 
 [('Figure', '4', '|'), ('4', '|', 'Visualizing'), ('|', 'Visualizing', 'learned'), ('Visualizing', 'learned', 'word'), ('learned', 'word', 'vectors'), ('word', 'vectors', '.')]

>> POS Tags are: 
 [('Figure', 'NN'), ('4', 'CD'), ('|', 'NN'), ('Visualizing', 'NNP'), ('learned', 'VBD'), ('word', 'NN'), ('vectors', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['Figure', '| Visualizing', 'word vectors']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Figure', 'figur'), ('4', '4'), ('|', '|'), ('Visualizing', 'visual'), ('learned', 'learn'), ('word', 'word'), ('vectors', 'vector'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Figure', 'figur'), ('4', '4'), ('|', '|'), ('Visualizing', 'visual'), ('learned', 'learn'), ('word', 'word'), ('vectors', 'vector'), ('.', '.')]

>> Lemmatization: 
 [('Figure', 'Figure'), ('4', '4'), ('|', '|'), ('Visualizing', 'Visualizing'), ('learned', 'learned'), ('word', 'word'), ('vectors', 'vector'), ('.', '.')]


------------------- Sentence 2 -------------------

On the left is an illustration  of word representations learned for modelling language, non-linearly projected  to 2D for visualization using the t-SNE algorithm103.

>> Tokens are: 
 ['On', 'left', 'illustration', 'word', 'representations', 'learned', 'modelling', 'language', ',', 'non-linearly', 'projected', '2D', 'visualization', 'using', 't-SNE', 'algorithm103', '.']

>> Bigrams are: 
 [('On', 'left'), ('left', 'illustration'), ('illustration', 'word'), ('word', 'representations'), ('representations', 'learned'), ('learned', 'modelling'), ('modelling', 'language'), ('language', ','), (',', 'non-linearly'), ('non-linearly', 'projected'), ('projected', '2D'), ('2D', 'visualization'), ('visualization', 'using'), ('using', 't-SNE'), ('t-SNE', 'algorithm103'), ('algorithm103', '.')]

>> Trigrams are: 
 [('On', 'left', 'illustration'), ('left', 'illustration', 'word'), ('illustration', 'word', 'representations'), ('word', 'representations', 'learned'), ('representations', 'learned', 'modelling'), ('learned', 'modelling', 'language'), ('modelling', 'language', ','), ('language', ',', 'non-linearly'), (',', 'non-linearly', 'projected'), ('non-linearly', 'projected', '2D'), ('projected', '2D', 'visualization'), ('2D', 'visualization', 'using'), ('visualization', 'using', 't-SNE'), ('using', 't-SNE', 'algorithm103'), ('t-SNE', 'algorithm103', '.')]

>> POS Tags are: 
 [('On', 'IN'), ('left', 'JJ'), ('illustration', 'NN'), ('word', 'NN'), ('representations', 'NNS'), ('learned', 'VBD'), ('modelling', 'VBG'), ('language', 'NN'), (',', ','), ('non-linearly', 'RB'), ('projected', 'VBD'), ('2D', 'CD'), ('visualization', 'NN'), ('using', 'VBG'), ('t-SNE', 'JJ'), ('algorithm103', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['left illustration word representations', 'language', 'visualization', 't-SNE algorithm103']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('On', 'on'), ('left', 'left'), ('illustration', 'illustr'), ('word', 'word'), ('representations', 'represent'), ('learned', 'learn'), ('modelling', 'model'), ('language', 'languag'), (',', ','), ('non-linearly', 'non-linearli'), ('projected', 'project'), ('2D', '2d'), ('visualization', 'visual'), ('using', 'use'), ('t-SNE', 't-sne'), ('algorithm103', 'algorithm103'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('On', 'on'), ('left', 'left'), ('illustration', 'illustr'), ('word', 'word'), ('representations', 'represent'), ('learned', 'learn'), ('modelling', 'model'), ('language', 'languag'), (',', ','), ('non-linearly', 'non-linear'), ('projected', 'project'), ('2D', '2d'), ('visualization', 'visual'), ('using', 'use'), ('t-SNE', 't-sne'), ('algorithm103', 'algorithm103'), ('.', '.')]

>> Lemmatization: 
 [('On', 'On'), ('left', 'left'), ('illustration', 'illustration'), ('word', 'word'), ('representations', 'representation'), ('learned', 'learned'), ('modelling', 'modelling'), ('language', 'language'), (',', ','), ('non-linearly', 'non-linearly'), ('projected', 'projected'), ('2D', '2D'), ('visualization', 'visualization'), ('using', 'using'), ('t-SNE', 't-SNE'), ('algorithm103', 'algorithm103'), ('.', '.')]


------------------- Sentence 3 -------------------

On the right is a 2D  representation of phrases learned by an English-to-French encoder–decoder  recurrent neural network75.

>> Tokens are: 
 ['On', 'right', '2D', 'representation', 'phrases', 'learned', 'English-to-French', 'encoder–decoder', 'recurrent', 'neural', 'network75', '.']

>> Bigrams are: 
 [('On', 'right'), ('right', '2D'), ('2D', 'representation'), ('representation', 'phrases'), ('phrases', 'learned'), ('learned', 'English-to-French'), ('English-to-French', 'encoder–decoder'), ('encoder–decoder', 'recurrent'), ('recurrent', 'neural'), ('neural', 'network75'), ('network75', '.')]

>> Trigrams are: 
 [('On', 'right', '2D'), ('right', '2D', 'representation'), ('2D', 'representation', 'phrases'), ('representation', 'phrases', 'learned'), ('phrases', 'learned', 'English-to-French'), ('learned', 'English-to-French', 'encoder–decoder'), ('English-to-French', 'encoder–decoder', 'recurrent'), ('encoder–decoder', 'recurrent', 'neural'), ('recurrent', 'neural', 'network75'), ('neural', 'network75', '.')]

>> POS Tags are: 
 [('On', 'IN'), ('right', 'JJ'), ('2D', 'CD'), ('representation', 'NN'), ('phrases', 'NNS'), ('learned', 'VBD'), ('English-to-French', 'JJ'), ('encoder–decoder', 'NN'), ('recurrent', 'NN'), ('neural', 'JJ'), ('network75', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['representation phrases', 'English-to-French encoder–decoder recurrent', 'neural network75']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('On', 'on'), ('right', 'right'), ('2D', '2d'), ('representation', 'represent'), ('phrases', 'phrase'), ('learned', 'learn'), ('English-to-French', 'english-to-french'), ('encoder–decoder', 'encoder–decod'), ('recurrent', 'recurr'), ('neural', 'neural'), ('network75', 'network75'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('On', 'on'), ('right', 'right'), ('2D', '2d'), ('representation', 'represent'), ('phrases', 'phrase'), ('learned', 'learn'), ('English-to-French', 'english-to-french'), ('encoder–decoder', 'encoder–decod'), ('recurrent', 'recurr'), ('neural', 'neural'), ('network75', 'network75'), ('.', '.')]

>> Lemmatization: 
 [('On', 'On'), ('right', 'right'), ('2D', '2D'), ('representation', 'representation'), ('phrases', 'phrase'), ('learned', 'learned'), ('English-to-French', 'English-to-French'), ('encoder–decoder', 'encoder–decoder'), ('recurrent', 'recurrent'), ('neural', 'neural'), ('network75', 'network75'), ('.', '.')]


------------------- Sentence 4 -------------------

One can observe that semantically similar words

>> Tokens are: 
 ['One', 'observe', 'semantically', 'similar', 'words']

>> Bigrams are: 
 [('One', 'observe'), ('observe', 'semantically'), ('semantically', 'similar'), ('similar', 'words')]

>> Trigrams are: 
 [('One', 'observe', 'semantically'), ('observe', 'semantically', 'similar'), ('semantically', 'similar', 'words')]

>> POS Tags are: 
 [('One', 'CD'), ('observe', 'NN'), ('semantically', 'RB'), ('similar', 'JJ'), ('words', 'NNS')]

>> Noun Phrases are: 
 ['observe', 'similar words']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('One', 'one'), ('observe', 'observ'), ('semantically', 'semant'), ('similar', 'similar'), ('words', 'word')]

>> Stemming using Snowball Stemmer: 
 [('One', 'one'), ('observe', 'observ'), ('semantically', 'semant'), ('similar', 'similar'), ('words', 'word')]

>> Lemmatization: 
 [('One', 'One'), ('observe', 'observe'), ('semantically', 'semantically'), ('similar', 'similar'), ('words', 'word')]



========================================== PARAGRAPH 159 ===========================================

or sequences of words are mapped to nearby representations. The distributed  representations of words are obtained by using backpropagation to jointly learn  a representation for each word and a function that predicts a target quantity  such as the next word in a sequence (for language modelling) or a whole  sequence of translated words (for machine translation)18,75. 

------------------- Sentence 1 -------------------

or sequences of words are mapped to nearby representations.

>> Tokens are: 
 ['sequences', 'words', 'mapped', 'nearby', 'representations', '.']

>> Bigrams are: 
 [('sequences', 'words'), ('words', 'mapped'), ('mapped', 'nearby'), ('nearby', 'representations'), ('representations', '.')]

>> Trigrams are: 
 [('sequences', 'words', 'mapped'), ('words', 'mapped', 'nearby'), ('mapped', 'nearby', 'representations'), ('nearby', 'representations', '.')]

>> POS Tags are: 
 [('sequences', 'NNS'), ('words', 'NNS'), ('mapped', 'VBD'), ('nearby', 'JJ'), ('representations', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['sequences words', 'nearby representations']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('sequences', 'sequenc'), ('words', 'word'), ('mapped', 'map'), ('nearby', 'nearbi'), ('representations', 'represent'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('sequences', 'sequenc'), ('words', 'word'), ('mapped', 'map'), ('nearby', 'nearbi'), ('representations', 'represent'), ('.', '.')]

>> Lemmatization: 
 [('sequences', 'sequence'), ('words', 'word'), ('mapped', 'mapped'), ('nearby', 'nearby'), ('representations', 'representation'), ('.', '.')]


------------------- Sentence 2 -------------------

The distributed  representations of words are obtained by using backpropagation to jointly learn  a representation for each word and a function that predicts a target quantity  such as the next word in a sequence (for language modelling) or a whole  sequence of translated words (for machine translation)18,75.

>> Tokens are: 
 ['The', 'distributed', 'representations', 'words', 'obtained', 'using', 'backpropagation', 'jointly', 'learn', 'representation', 'word', 'function', 'predicts', 'target', 'quantity', 'next', 'word', 'sequence', '(', 'language', 'modelling', ')', 'whole', 'sequence', 'translated', 'words', '(', 'machine', 'translation', ')', '18,75', '.']

>> Bigrams are: 
 [('The', 'distributed'), ('distributed', 'representations'), ('representations', 'words'), ('words', 'obtained'), ('obtained', 'using'), ('using', 'backpropagation'), ('backpropagation', 'jointly'), ('jointly', 'learn'), ('learn', 'representation'), ('representation', 'word'), ('word', 'function'), ('function', 'predicts'), ('predicts', 'target'), ('target', 'quantity'), ('quantity', 'next'), ('next', 'word'), ('word', 'sequence'), ('sequence', '('), ('(', 'language'), ('language', 'modelling'), ('modelling', ')'), (')', 'whole'), ('whole', 'sequence'), ('sequence', 'translated'), ('translated', 'words'), ('words', '('), ('(', 'machine'), ('machine', 'translation'), ('translation', ')'), (')', '18,75'), ('18,75', '.')]

>> Trigrams are: 
 [('The', 'distributed', 'representations'), ('distributed', 'representations', 'words'), ('representations', 'words', 'obtained'), ('words', 'obtained', 'using'), ('obtained', 'using', 'backpropagation'), ('using', 'backpropagation', 'jointly'), ('backpropagation', 'jointly', 'learn'), ('jointly', 'learn', 'representation'), ('learn', 'representation', 'word'), ('representation', 'word', 'function'), ('word', 'function', 'predicts'), ('function', 'predicts', 'target'), ('predicts', 'target', 'quantity'), ('target', 'quantity', 'next'), ('quantity', 'next', 'word'), ('next', 'word', 'sequence'), ('word', 'sequence', '('), ('sequence', '(', 'language'), ('(', 'language', 'modelling'), ('language', 'modelling', ')'), ('modelling', ')', 'whole'), (')', 'whole', 'sequence'), ('whole', 'sequence', 'translated'), ('sequence', 'translated', 'words'), ('translated', 'words', '('), ('words', '(', 'machine'), ('(', 'machine', 'translation'), ('machine', 'translation', ')'), ('translation', ')', '18,75'), (')', '18,75', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('distributed', 'JJ'), ('representations', 'NNS'), ('words', 'NNS'), ('obtained', 'VBN'), ('using', 'VBG'), ('backpropagation', 'NN'), ('jointly', 'RB'), ('learn', 'JJ'), ('representation', 'NN'), ('word', 'NN'), ('function', 'NN'), ('predicts', 'VBZ'), ('target', 'VBP'), ('quantity', 'NN'), ('next', 'JJ'), ('word', 'NN'), ('sequence', 'NN'), ('(', '('), ('language', 'NN'), ('modelling', 'VBG'), (')', ')'), ('whole', 'JJ'), ('sequence', 'NN'), ('translated', 'VBN'), ('words', 'NNS'), ('(', '('), ('machine', 'NN'), ('translation', 'NN'), (')', ')'), ('18,75', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['The distributed representations words', 'backpropagation', 'learn representation word function', 'quantity', 'next word sequence', 'language', 'whole sequence', 'words', 'machine translation']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('distributed', 'distribut'), ('representations', 'represent'), ('words', 'word'), ('obtained', 'obtain'), ('using', 'use'), ('backpropagation', 'backpropag'), ('jointly', 'jointli'), ('learn', 'learn'), ('representation', 'represent'), ('word', 'word'), ('function', 'function'), ('predicts', 'predict'), ('target', 'target'), ('quantity', 'quantiti'), ('next', 'next'), ('word', 'word'), ('sequence', 'sequenc'), ('(', '('), ('language', 'languag'), ('modelling', 'model'), (')', ')'), ('whole', 'whole'), ('sequence', 'sequenc'), ('translated', 'translat'), ('words', 'word'), ('(', '('), ('machine', 'machin'), ('translation', 'translat'), (')', ')'), ('18,75', '18,75'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('distributed', 'distribut'), ('representations', 'represent'), ('words', 'word'), ('obtained', 'obtain'), ('using', 'use'), ('backpropagation', 'backpropag'), ('jointly', 'joint'), ('learn', 'learn'), ('representation', 'represent'), ('word', 'word'), ('function', 'function'), ('predicts', 'predict'), ('target', 'target'), ('quantity', 'quantiti'), ('next', 'next'), ('word', 'word'), ('sequence', 'sequenc'), ('(', '('), ('language', 'languag'), ('modelling', 'model'), (')', ')'), ('whole', 'whole'), ('sequence', 'sequenc'), ('translated', 'translat'), ('words', 'word'), ('(', '('), ('machine', 'machin'), ('translation', 'translat'), (')', ')'), ('18,75', '18,75'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('distributed', 'distributed'), ('representations', 'representation'), ('words', 'word'), ('obtained', 'obtained'), ('using', 'using'), ('backpropagation', 'backpropagation'), ('jointly', 'jointly'), ('learn', 'learn'), ('representation', 'representation'), ('word', 'word'), ('function', 'function'), ('predicts', 'predicts'), ('target', 'target'), ('quantity', 'quantity'), ('next', 'next'), ('word', 'word'), ('sequence', 'sequence'), ('(', '('), ('language', 'language'), ('modelling', 'modelling'), (')', ')'), ('whole', 'whole'), ('sequence', 'sequence'), ('translated', 'translated'), ('words', 'word'), ('(', '('), ('machine', 'machine'), ('translation', 'translation'), (')', ')'), ('18,75', '18,75'), ('.', '.')]



========================================== PARAGRAPH 160 ===========================================

−37 −36 −35 −34 −33 −32 −31 −30 −29 

------------------- Sentence 1 -------------------

−37 −36 −35 −34 −33 −32 −31 −30 −29

>> Tokens are: 
 ['−37', '−36', '−35', '−34', '−33', '−32', '−31', '−30', '−29']

>> Bigrams are: 
 [('−37', '−36'), ('−36', '−35'), ('−35', '−34'), ('−34', '−33'), ('−33', '−32'), ('−32', '−31'), ('−31', '−30'), ('−30', '−29')]

>> Trigrams are: 
 [('−37', '−36', '−35'), ('−36', '−35', '−34'), ('−35', '−34', '−33'), ('−34', '−33', '−32'), ('−33', '−32', '−31'), ('−32', '−31', '−30'), ('−31', '−30', '−29')]

>> POS Tags are: 
 [('−37', 'JJ'), ('−36', 'NNP'), ('−35', 'NNP'), ('−34', 'NNP'), ('−33', 'NNP'), ('−32', 'NNP'), ('−31', 'NNP'), ('−30', 'NNP'), ('−29', 'NN')]

>> Noun Phrases are: 
 ['−37 −36 −35 −34 −33 −32 −31 −30 −29']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('−37', '−37'), ('−36', '−36'), ('−35', '−35'), ('−34', '−34'), ('−33', '−33'), ('−32', '−32'), ('−31', '−31'), ('−30', '−30'), ('−29', '−29')]

>> Stemming using Snowball Stemmer: 
 [('−37', '−37'), ('−36', '−36'), ('−35', '−35'), ('−34', '−34'), ('−33', '−33'), ('−32', '−32'), ('−31', '−31'), ('−30', '−30'), ('−29', '−29')]

>> Lemmatization: 
 [('−37', '−37'), ('−36', '−36'), ('−35', '−35'), ('−34', '−34'), ('−33', '−33'), ('−32', '−32'), ('−31', '−31'), ('−30', '−30'), ('−29', '−29')]



========================================== PARAGRAPH 161 ===========================================

9 

------------------- Sentence 1 -------------------

9

>> Tokens are: 
 ['9']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('9', 'CD')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('9', '9')]

>> Stemming using Snowball Stemmer: 
 [('9', '9')]

>> Lemmatization: 
 [('9', '9')]



========================================== PARAGRAPH 162 ===========================================

10 

------------------- Sentence 1 -------------------

10

>> Tokens are: 
 ['10']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('10', 'CD')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('10', '10')]

>> Stemming using Snowball Stemmer: 
 [('10', '10')]

>> Lemmatization: 
 [('10', '10')]



========================================== PARAGRAPH 163 ===========================================

10.5 

------------------- Sentence 1 -------------------

10.5

>> Tokens are: 
 ['10.5']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('10.5', 'CD')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('10.5', '10.5')]

>> Stemming using Snowball Stemmer: 
 [('10.5', '10.5')]

>> Lemmatization: 
 [('10.5', '10.5')]



========================================== PARAGRAPH 164 ===========================================

11 

------------------- Sentence 1 -------------------

11

>> Tokens are: 
 ['11']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('11', 'CD')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('11', '11')]

>> Stemming using Snowball Stemmer: 
 [('11', '11')]

>> Lemmatization: 
 [('11', '11')]



========================================== PARAGRAPH 165 ===========================================

11.5 

------------------- Sentence 1 -------------------

11.5

>> Tokens are: 
 ['11.5']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('11.5', 'CD')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('11.5', '11.5')]

>> Stemming using Snowball Stemmer: 
 [('11.5', '11.5')]

>> Lemmatization: 
 [('11.5', '11.5')]



========================================== PARAGRAPH 166 ===========================================

12 

------------------- Sentence 1 -------------------

12

>> Tokens are: 
 ['12']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('12', 'CD')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('12', '12')]

>> Stemming using Snowball Stemmer: 
 [('12', '12')]

>> Lemmatization: 
 [('12', '12')]



========================================== PARAGRAPH 167 ===========================================

12.5 

------------------- Sentence 1 -------------------

12.5

>> Tokens are: 
 ['12.5']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('12.5', 'CD')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('12.5', '12.5')]

>> Stemming using Snowball Stemmer: 
 [('12.5', '12.5')]

>> Lemmatization: 
 [('12.5', '12.5')]



========================================== PARAGRAPH 168 ===========================================

13 

------------------- Sentence 1 -------------------

13

>> Tokens are: 
 ['13']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('13', 'CD')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('13', '13')]

>> Stemming using Snowball Stemmer: 
 [('13', '13')]

>> Lemmatization: 
 [('13', '13')]



========================================== PARAGRAPH 169 ===========================================

13.5 

------------------- Sentence 1 -------------------

13.5

>> Tokens are: 
 ['13.5']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('13.5', 'CD')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('13.5', '13.5')]

>> Stemming using Snowball Stemmer: 
 [('13.5', '13.5')]

>> Lemmatization: 
 [('13.5', '13.5')]



========================================== PARAGRAPH 170 ===========================================

14 

------------------- Sentence 1 -------------------

14

>> Tokens are: 
 ['14']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('14', 'CD')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('14', '14')]

>> Stemming using Snowball Stemmer: 
 [('14', '14')]

>> Lemmatization: 
 [('14', '14')]



========================================== PARAGRAPH 171 ===========================================

 community 

------------------- Sentence 1 -------------------

 community

>> Tokens are: 
 ['community']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('community', 'NN')]

>> Noun Phrases are: 
 ['community']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('community', 'commun')]

>> Stemming using Snowball Stemmer: 
 [('community', 'communiti')]

>> Lemmatization: 
 [('community', 'community')]



========================================== PARAGRAPH 172 ===========================================

 organizations  institutions 

------------------- Sentence 1 -------------------

 organizations  institutions

>> Tokens are: 
 ['organizations', 'institutions']

>> Bigrams are: 
 [('organizations', 'institutions')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('organizations', 'NNS'), ('institutions', 'NNS')]

>> Noun Phrases are: 
 ['organizations institutions']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('organizations', 'organ'), ('institutions', 'institut')]

>> Stemming using Snowball Stemmer: 
 [('organizations', 'organ'), ('institutions', 'institut')]

>> Lemmatization: 
 [('organizations', 'organization'), ('institutions', 'institution')]



========================================== PARAGRAPH 173 ===========================================

 society  industry 

------------------- Sentence 1 -------------------

 society  industry

>> Tokens are: 
 ['society', 'industry']

>> Bigrams are: 
 [('society', 'industry')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('society', 'NN'), ('industry', 'NN')]

>> Noun Phrases are: 
 ['society industry']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('society', 'societi'), ('industry', 'industri')]

>> Stemming using Snowball Stemmer: 
 [('society', 'societi'), ('industry', 'industri')]

>> Lemmatization: 
 [('society', 'society'), ('industry', 'industry')]



========================================== PARAGRAPH 174 ===========================================

 company 

------------------- Sentence 1 -------------------

 company

>> Tokens are: 
 ['company']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('company', 'NN')]

>> Noun Phrases are: 
 ['company']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('company', 'compani')]

>> Stemming using Snowball Stemmer: 
 [('company', 'compani')]

>> Lemmatization: 
 [('company', 'company')]



========================================== PARAGRAPH 175 ===========================================

 organization 

------------------- Sentence 1 -------------------

 organization

>> Tokens are: 
 ['organization']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('organization', 'NN')]

>> Noun Phrases are: 
 ['organization']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('organization', 'organ')]

>> Stemming using Snowball Stemmer: 
 [('organization', 'organ')]

>> Lemmatization: 
 [('organization', 'organization')]



========================================== PARAGRAPH 176 ===========================================

 school 

------------------- Sentence 1 -------------------

 school

>> Tokens are: 
 ['school']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('school', 'NN')]

>> Noun Phrases are: 
 ['school']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('school', 'school')]

>> Stemming using Snowball Stemmer: 
 [('school', 'school')]

>> Lemmatization: 
 [('school', 'school')]



========================================== PARAGRAPH 177 ===========================================

 companies 

------------------- Sentence 1 -------------------

 companies

>> Tokens are: 
 ['companies']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('companies', 'NNS')]

>> Noun Phrases are: 
 ['companies']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('companies', 'compani')]

>> Stemming using Snowball Stemmer: 
 [('companies', 'compani')]

>> Lemmatization: 
 [('companies', 'company')]



========================================== PARAGRAPH 178 ===========================================

 Community 

------------------- Sentence 1 -------------------

 Community

>> Tokens are: 
 ['Community']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Community', 'NNP')]

>> Noun Phrases are: 
 ['Community']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Community', 'commun')]

>> Stemming using Snowball Stemmer: 
 [('Community', 'communiti')]

>> Lemmatization: 
 [('Community', 'Community')]



========================================== PARAGRAPH 179 ===========================================

 o�ce 

------------------- Sentence 1 -------------------

 o�ce

>> Tokens are: 
 ['o�ce']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('o�ce', 'NN')]

>> Noun Phrases are: 
 ['o�ce']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('o�ce', 'o�c')]

>> Stemming using Snowball Stemmer: 
 [('o�ce', 'o�c')]

>> Lemmatization: 
 [('o�ce', 'o�ce')]



========================================== PARAGRAPH 180 ===========================================

 Agency 

------------------- Sentence 1 -------------------

 Agency

>> Tokens are: 
 ['Agency']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Agency', 'NN')]

>> Noun Phrases are: 
 ['Agency']

>> Named Entities are: 
 [('GPE', 'Agency')] 

>> Stemming using Porter Stemmer: 
 [('Agency', 'agenc')]

>> Stemming using Snowball Stemmer: 
 [('Agency', 'agenc')]

>> Lemmatization: 
 [('Agency', 'Agency')]



========================================== PARAGRAPH 181 ===========================================

 communities 

------------------- Sentence 1 -------------------

 communities

>> Tokens are: 
 ['communities']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('communities', 'NNS')]

>> Noun Phrases are: 
 ['communities']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('communities', 'commun')]

>> Stemming using Snowball Stemmer: 
 [('communities', 'communiti')]

>> Lemmatization: 
 [('communities', 'community')]



========================================== PARAGRAPH 182 ===========================================

 Association 

------------------- Sentence 1 -------------------

 Association

>> Tokens are: 
 ['Association']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Association', 'NNP')]

>> Noun Phrases are: 
 ['Association']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Association', 'associ')]

>> Stemming using Snowball Stemmer: 
 [('Association', 'associ')]

>> Lemmatization: 
 [('Association', 'Association')]



========================================== PARAGRAPH 183 ===========================================

 body 

------------------- Sentence 1 -------------------

 body

>> Tokens are: 
 ['body']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('body', 'NN')]

>> Noun Phrases are: 
 ['body']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('body', 'bodi')]

>> Stemming using Snowball Stemmer: 
 [('body', 'bodi')]

>> Lemmatization: 
 [('body', 'body')]



========================================== PARAGRAPH 184 ===========================================

 schools 

------------------- Sentence 1 -------------------

 schools

>> Tokens are: 
 ['schools']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('schools', 'NNS')]

>> Noun Phrases are: 
 ['schools']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('schools', 'school')]

>> Stemming using Snowball Stemmer: 
 [('schools', 'school')]

>> Lemmatization: 
 [('schools', 'school')]



========================================== PARAGRAPH 185 ===========================================

 agencies 

------------------- Sentence 1 -------------------

 agencies

>> Tokens are: 
 ['agencies']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('agencies', 'NNS')]

>> Noun Phrases are: 
 ['agencies']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('agencies', 'agenc')]

>> Stemming using Snowball Stemmer: 
 [('agencies', 'agenc')]

>> Lemmatization: 
 [('agencies', 'agency')]



========================================== PARAGRAPH 186 ===========================================

−5.5 −5 −4.5 −4 −3.5 −3 −2.5 −2 −4.2 

------------------- Sentence 1 -------------------

−5.5 −5 −4.5 −4 −3.5 −3 −2.5 −2 −4.2

>> Tokens are: 
 ['−5.5', '−5', '−4.5', '−4', '−3.5', '−3', '−2.5', '−2', '−4.2']

>> Bigrams are: 
 [('−5.5', '−5'), ('−5', '−4.5'), ('−4.5', '−4'), ('−4', '−3.5'), ('−3.5', '−3'), ('−3', '−2.5'), ('−2.5', '−2'), ('−2', '−4.2')]

>> Trigrams are: 
 [('−5.5', '−5', '−4.5'), ('−5', '−4.5', '−4'), ('−4.5', '−4', '−3.5'), ('−4', '−3.5', '−3'), ('−3.5', '−3', '−2.5'), ('−3', '−2.5', '−2'), ('−2.5', '−2', '−4.2')]

>> POS Tags are: 
 [('−5.5', 'JJ'), ('−5', 'NNP'), ('−4.5', 'NNP'), ('−4', 'NNP'), ('−3.5', 'NNP'), ('−3', 'NNP'), ('−2.5', 'NNP'), ('−2', 'NNP'), ('−4.2', 'NN')]

>> Noun Phrases are: 
 ['−5.5 −5 −4.5 −4 −3.5 −3 −2.5 −2 −4.2']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('−5.5', '−5.5'), ('−5', '−5'), ('−4.5', '−4.5'), ('−4', '−4'), ('−3.5', '−3.5'), ('−3', '−3'), ('−2.5', '−2.5'), ('−2', '−2'), ('−4.2', '−4.2')]

>> Stemming using Snowball Stemmer: 
 [('−5.5', '−5.5'), ('−5', '−5'), ('−4.5', '−4.5'), ('−4', '−4'), ('−3.5', '−3.5'), ('−3', '−3'), ('−2.5', '−2.5'), ('−2', '−2'), ('−4.2', '−4.2')]

>> Lemmatization: 
 [('−5.5', '−5.5'), ('−5', '−5'), ('−4.5', '−4.5'), ('−4', '−4'), ('−3.5', '−3.5'), ('−3', '−3'), ('−2.5', '−2.5'), ('−2', '−2'), ('−4.2', '−4.2')]



========================================== PARAGRAPH 187 ===========================================

−4 

------------------- Sentence 1 -------------------

−4

>> Tokens are: 
 ['−4']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('−4', 'NN')]

>> Noun Phrases are: 
 ['−4']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('−4', '−4')]

>> Stemming using Snowball Stemmer: 
 [('−4', '−4')]

>> Lemmatization: 
 [('−4', '−4')]



========================================== PARAGRAPH 188 ===========================================

−3.8 

------------------- Sentence 1 -------------------

−3.8

>> Tokens are: 
 ['−3.8']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('−3.8', 'NN')]

>> Noun Phrases are: 
 ['−3.8']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('−3.8', '−3.8')]

>> Stemming using Snowball Stemmer: 
 [('−3.8', '−3.8')]

>> Lemmatization: 
 [('−3.8', '−3.8')]



========================================== PARAGRAPH 189 ===========================================

−3.6 

------------------- Sentence 1 -------------------

−3.6

>> Tokens are: 
 ['−3.6']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('−3.6', 'NN')]

>> Noun Phrases are: 
 ['−3.6']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('−3.6', '−3.6')]

>> Stemming using Snowball Stemmer: 
 [('−3.6', '−3.6')]

>> Lemmatization: 
 [('−3.6', '−3.6')]



========================================== PARAGRAPH 190 ===========================================

−3.4 

------------------- Sentence 1 -------------------

−3.4

>> Tokens are: 
 ['−3.4']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('−3.4', 'NN')]

>> Noun Phrases are: 
 ['−3.4']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('−3.4', '−3.4')]

>> Stemming using Snowball Stemmer: 
 [('−3.4', '−3.4')]

>> Lemmatization: 
 [('−3.4', '−3.4')]



========================================== PARAGRAPH 191 ===========================================

−3.2 

------------------- Sentence 1 -------------------

−3.2

>> Tokens are: 
 ['−3.2']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('−3.2', 'NN')]

>> Noun Phrases are: 
 ['−3.2']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('−3.2', '−3.2')]

>> Stemming using Snowball Stemmer: 
 [('−3.2', '−3.2')]

>> Lemmatization: 
 [('−3.2', '−3.2')]



========================================== PARAGRAPH 192 ===========================================

−3 

------------------- Sentence 1 -------------------

−3

>> Tokens are: 
 ['−3']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('−3', 'NN')]

>> Noun Phrases are: 
 ['−3']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('−3', '−3')]

>> Stemming using Snowball Stemmer: 
 [('−3', '−3')]

>> Lemmatization: 
 [('−3', '−3')]



========================================== PARAGRAPH 193 ===========================================

−2.8 

------------------- Sentence 1 -------------------

−2.8

>> Tokens are: 
 ['−2.8']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('−2.8', 'NN')]

>> Noun Phrases are: 
 ['−2.8']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('−2.8', '−2.8')]

>> Stemming using Snowball Stemmer: 
 [('−2.8', '−2.8')]

>> Lemmatization: 
 [('−2.8', '−2.8')]



========================================== PARAGRAPH 194 ===========================================

−2.6 

------------------- Sentence 1 -------------------

−2.6

>> Tokens are: 
 ['−2.6']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('−2.6', 'NN')]

>> Noun Phrases are: 
 ['−2.6']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('−2.6', '−2.6')]

>> Stemming using Snowball Stemmer: 
 [('−2.6', '−2.6')]

>> Lemmatization: 
 [('−2.6', '−2.6')]



========================================== PARAGRAPH 195 ===========================================

−2.4 

------------------- Sentence 1 -------------------

−2.4

>> Tokens are: 
 ['−2.4']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('−2.4', 'NN')]

>> Noun Phrases are: 
 ['−2.4']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('−2.4', '−2.4')]

>> Stemming using Snowball Stemmer: 
 [('−2.4', '−2.4')]

>> Lemmatization: 
 [('−2.4', '−2.4')]



========================================== PARAGRAPH 196 ===========================================

−2.2 

------------------- Sentence 1 -------------------

−2.2

>> Tokens are: 
 ['−2.2']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('−2.2', 'NN')]

>> Noun Phrases are: 
 ['−2.2']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('−2.2', '−2.2')]

>> Stemming using Snowball Stemmer: 
 [('−2.2', '−2.2')]

>> Lemmatization: 
 [('−2.2', '−2.2')]



========================================== PARAGRAPH 197 ===========================================

over the past few months 

------------------- Sentence 1 -------------------

over the past few months

>> Tokens are: 
 ['past', 'months']

>> Bigrams are: 
 [('past', 'months')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('past', 'JJ'), ('months', 'NNS')]

>> Noun Phrases are: 
 ['past months']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('past', 'past'), ('months', 'month')]

>> Stemming using Snowball Stemmer: 
 [('past', 'past'), ('months', 'month')]

>> Lemmatization: 
 [('past', 'past'), ('months', 'month')]



========================================== PARAGRAPH 198 ===========================================

that a few days 

------------------- Sentence 1 -------------------

that a few days

>> Tokens are: 
 ['days']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('days', 'NNS')]

>> Noun Phrases are: 
 ['days']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('days', 'day')]

>> Stemming using Snowball Stemmer: 
 [('days', 'day')]

>> Lemmatization: 
 [('days', 'day')]



========================================== PARAGRAPH 199 ===========================================

In the last few daysthe past few days 

------------------- Sentence 1 -------------------

In the last few daysthe past few days

>> Tokens are: 
 ['In', 'last', 'daysthe', 'past', 'days']

>> Bigrams are: 
 [('In', 'last'), ('last', 'daysthe'), ('daysthe', 'past'), ('past', 'days')]

>> Trigrams are: 
 [('In', 'last', 'daysthe'), ('last', 'daysthe', 'past'), ('daysthe', 'past', 'days')]

>> POS Tags are: 
 [('In', 'IN'), ('last', 'JJ'), ('daysthe', 'JJ'), ('past', 'NN'), ('days', 'NNS')]

>> Noun Phrases are: 
 ['last daysthe past days']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('last', 'last'), ('daysthe', 'daysth'), ('past', 'past'), ('days', 'day')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('last', 'last'), ('daysthe', 'daysth'), ('past', 'past'), ('days', 'day')]

>> Lemmatization: 
 [('In', 'In'), ('last', 'last'), ('daysthe', 'daysthe'), ('past', 'past'), ('days', 'day')]



========================================== PARAGRAPH 200 ===========================================

In a few months 

------------------- Sentence 1 -------------------

In a few months

>> Tokens are: 
 ['In', 'months']

>> Bigrams are: 
 [('In', 'months')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('In', 'IN'), ('months', 'NNS')]

>> Noun Phrases are: 
 ['months']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('months', 'month')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('months', 'month')]

>> Lemmatization: 
 [('In', 'In'), ('months', 'month')]



========================================== PARAGRAPH 201 ===========================================

in the coming months 

------------------- Sentence 1 -------------------

in the coming months

>> Tokens are: 
 ['coming', 'months']

>> Bigrams are: 
 [('coming', 'months')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('coming', 'VBG'), ('months', 'NNS')]

>> Noun Phrases are: 
 ['months']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('coming', 'come'), ('months', 'month')]

>> Stemming using Snowball Stemmer: 
 [('coming', 'come'), ('months', 'month')]

>> Lemmatization: 
 [('coming', 'coming'), ('months', 'month')]



========================================== PARAGRAPH 202 ===========================================

a few months ago 

------------------- Sentence 1 -------------------

a few months ago

>> Tokens are: 
 ['months', 'ago']

>> Bigrams are: 
 [('months', 'ago')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('months', 'NNS'), ('ago', 'RB')]

>> Noun Phrases are: 
 ['months']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('months', 'month'), ('ago', 'ago')]

>> Stemming using Snowball Stemmer: 
 [('months', 'month'), ('ago', 'ago')]

>> Lemmatization: 
 [('months', 'month'), ('ago', 'ago')]



========================================== PARAGRAPH 203 ===========================================

&quot; the two groups 

------------------- Sentence 1 -------------------

&quot; the two groups

>> Tokens are: 
 ['&', 'quot', ';', 'two', 'groups']

>> Bigrams are: 
 [('&', 'quot'), ('quot', ';'), (';', 'two'), ('two', 'groups')]

>> Trigrams are: 
 [('&', 'quot', ';'), ('quot', ';', 'two'), (';', 'two', 'groups')]

>> POS Tags are: 
 [('&', 'CC'), ('quot', 'NN'), (';', ':'), ('two', 'CD'), ('groups', 'NNS')]

>> Noun Phrases are: 
 ['quot', 'groups']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('&', '&'), ('quot', 'quot'), (';', ';'), ('two', 'two'), ('groups', 'group')]

>> Stemming using Snowball Stemmer: 
 [('&', '&'), ('quot', 'quot'), (';', ';'), ('two', 'two'), ('groups', 'group')]

>> Lemmatization: 
 [('&', '&'), ('quot', 'quot'), (';', ';'), ('two', 'two'), ('groups', 'group')]



========================================== PARAGRAPH 204 ===========================================

of the two groups 

------------------- Sentence 1 -------------------

of the two groups

>> Tokens are: 
 ['two', 'groups']

>> Bigrams are: 
 [('two', 'groups')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('two', 'CD'), ('groups', 'NNS')]

>> Noun Phrases are: 
 ['groups']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('two', 'two'), ('groups', 'group')]

>> Stemming using Snowball Stemmer: 
 [('two', 'two'), ('groups', 'group')]

>> Lemmatization: 
 [('two', 'two'), ('groups', 'group')]



========================================== PARAGRAPH 205 ===========================================

over the last few months 

------------------- Sentence 1 -------------------

over the last few months

>> Tokens are: 
 ['last', 'months']

>> Bigrams are: 
 [('last', 'months')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('last', 'JJ'), ('months', 'NNS')]

>> Noun Phrases are: 
 ['last months']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('last', 'last'), ('months', 'month')]

>> Stemming using Snowball Stemmer: 
 [('last', 'last'), ('months', 'month')]

>> Lemmatization: 
 [('last', 'last'), ('months', 'month')]



========================================== PARAGRAPH 206 ===========================================

dispute between the two 

------------------- Sentence 1 -------------------

dispute between the two

>> Tokens are: 
 ['dispute', 'two']

>> Bigrams are: 
 [('dispute', 'two')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('dispute', 'NN'), ('two', 'CD')]

>> Noun Phrases are: 
 ['dispute']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('dispute', 'disput'), ('two', 'two')]

>> Stemming using Snowball Stemmer: 
 [('dispute', 'disput'), ('two', 'two')]

>> Lemmatization: 
 [('dispute', 'dispute'), ('two', 'two')]



========================================== PARAGRAPH 207 ===========================================

the last two decades 

------------------- Sentence 1 -------------------

the last two decades

>> Tokens are: 
 ['last', 'two', 'decades']

>> Bigrams are: 
 [('last', 'two'), ('two', 'decades')]

>> Trigrams are: 
 [('last', 'two', 'decades')]

>> POS Tags are: 
 [('last', 'JJ'), ('two', 'CD'), ('decades', 'NNS')]

>> Noun Phrases are: 
 ['decades']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('last', 'last'), ('two', 'two'), ('decades', 'decad')]

>> Stemming using Snowball Stemmer: 
 [('last', 'last'), ('two', 'two'), ('decades', 'decad')]

>> Lemmatization: 
 [('last', 'last'), ('two', 'two'), ('decades', 'decade')]



========================================== PARAGRAPH 208 ===========================================

the next six months 

------------------- Sentence 1 -------------------

the next six months

>> Tokens are: 
 ['next', 'six', 'months']

>> Bigrams are: 
 [('next', 'six'), ('six', 'months')]

>> Trigrams are: 
 [('next', 'six', 'months')]

>> POS Tags are: 
 [('next', 'JJ'), ('six', 'CD'), ('months', 'NNS')]

>> Noun Phrases are: 
 ['months']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('next', 'next'), ('six', 'six'), ('months', 'month')]

>> Stemming using Snowball Stemmer: 
 [('next', 'next'), ('six', 'six'), ('months', 'month')]

>> Lemmatization: 
 [('next', 'next'), ('six', 'six'), ('months', 'month')]



========================================== PARAGRAPH 209 ===========================================

two months before being for nearly two months 

------------------- Sentence 1 -------------------

two months before being for nearly two months

>> Tokens are: 
 ['two', 'months', 'nearly', 'two', 'months']

>> Bigrams are: 
 [('two', 'months'), ('months', 'nearly'), ('nearly', 'two'), ('two', 'months')]

>> Trigrams are: 
 [('two', 'months', 'nearly'), ('months', 'nearly', 'two'), ('nearly', 'two', 'months')]

>> POS Tags are: 
 [('two', 'CD'), ('months', 'NNS'), ('nearly', 'RB'), ('two', 'CD'), ('months', 'NNS')]

>> Noun Phrases are: 
 ['months', 'months']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('two', 'two'), ('months', 'month'), ('nearly', 'nearli'), ('two', 'two'), ('months', 'month')]

>> Stemming using Snowball Stemmer: 
 [('two', 'two'), ('months', 'month'), ('nearly', 'near'), ('two', 'two'), ('months', 'month')]

>> Lemmatization: 
 [('two', 'two'), ('months', 'month'), ('nearly', 'nearly'), ('two', 'two'), ('months', 'month')]



========================================== PARAGRAPH 210 ===========================================

over the last two decades 

------------------- Sentence 1 -------------------

over the last two decades

>> Tokens are: 
 ['last', 'two', 'decades']

>> Bigrams are: 
 [('last', 'two'), ('two', 'decades')]

>> Trigrams are: 
 [('last', 'two', 'decades')]

>> POS Tags are: 
 [('last', 'JJ'), ('two', 'CD'), ('decades', 'NNS')]

>> Noun Phrases are: 
 ['decades']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('last', 'last'), ('two', 'two'), ('decades', 'decad')]

>> Stemming using Snowball Stemmer: 
 [('last', 'last'), ('two', 'two'), ('decades', 'decad')]

>> Lemmatization: 
 [('last', 'last'), ('two', 'two'), ('decades', 'decade')]



========================================== PARAGRAPH 211 ===========================================

within a few months 

------------------- Sentence 1 -------------------

within a few months

>> Tokens are: 
 ['within', 'months']

>> Bigrams are: 
 [('within', 'months')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('within', 'IN'), ('months', 'NNS')]

>> Noun Phrases are: 
 ['months']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('within', 'within'), ('months', 'month')]

>> Stemming using Snowball Stemmer: 
 [('within', 'within'), ('months', 'month')]

>> Lemmatization: 
 [('within', 'within'), ('months', 'month')]



========================================== PARAGRAPH 212 ===========================================

2 8  M A Y  2 0 1 5  |  V O L  5 2 1  |  N A T U R E  |  4 4 1 

------------------- Sentence 1 -------------------

2 8  M A Y  2 0 1 5  |  V O L  5 2 1  |  N A T U R E  |  4 4 1

>> Tokens are: 
 ['2', '8', 'M', 'A', 'Y', '2', '0', '1', '5', '|', 'V', 'O', 'L', '5', '2', '1', '|', 'N', 'A', 'T', 'U', 'R', 'E', '|', '4', '4', '1']

>> Bigrams are: 
 [('2', '8'), ('8', 'M'), ('M', 'A'), ('A', 'Y'), ('Y', '2'), ('2', '0'), ('0', '1'), ('1', '5'), ('5', '|'), ('|', 'V'), ('V', 'O'), ('O', 'L'), ('L', '5'), ('5', '2'), ('2', '1'), ('1', '|'), ('|', 'N'), ('N', 'A'), ('A', 'T'), ('T', 'U'), ('U', 'R'), ('R', 'E'), ('E', '|'), ('|', '4'), ('4', '4'), ('4', '1')]

>> Trigrams are: 
 [('2', '8', 'M'), ('8', 'M', 'A'), ('M', 'A', 'Y'), ('A', 'Y', '2'), ('Y', '2', '0'), ('2', '0', '1'), ('0', '1', '5'), ('1', '5', '|'), ('5', '|', 'V'), ('|', 'V', 'O'), ('V', 'O', 'L'), ('O', 'L', '5'), ('L', '5', '2'), ('5', '2', '1'), ('2', '1', '|'), ('1', '|', 'N'), ('|', 'N', 'A'), ('N', 'A', 'T'), ('A', 'T', 'U'), ('T', 'U', 'R'), ('U', 'R', 'E'), ('R', 'E', '|'), ('E', '|', '4'), ('|', '4', '4'), ('4', '4', '1')]

>> POS Tags are: 
 [('2', 'CD'), ('8', 'CD'), ('M', 'NNP'), ('A', 'NNP'), ('Y', 'NNP'), ('2', 'CD'), ('0', 'CD'), ('1', 'CD'), ('5', 'CD'), ('|', 'NN'), ('V', 'NNP'), ('O', 'NNP'), ('L', 'NNP'), ('5', 'CD'), ('2', 'CD'), ('1', 'CD'), ('|', 'NN'), ('N', 'NNP'), ('A', 'NNP'), ('T', 'NNP'), ('U', 'NNP'), ('R', 'NNP'), ('E', 'NNP'), ('|', 'VBD'), ('4', 'CD'), ('4', 'CD'), ('1', 'CD')]

>> Noun Phrases are: 
 ['M A Y', '| V O L', '| N A T U R E']

>> Named Entities are: 
 [('PERSON', 'V O')] 

>> Stemming using Porter Stemmer: 
 [('2', '2'), ('8', '8'), ('M', 'm'), ('A', 'a'), ('Y', 'y'), ('2', '2'), ('0', '0'), ('1', '1'), ('5', '5'), ('|', '|'), ('V', 'v'), ('O', 'o'), ('L', 'l'), ('5', '5'), ('2', '2'), ('1', '1'), ('|', '|'), ('N', 'n'), ('A', 'a'), ('T', 't'), ('U', 'u'), ('R', 'r'), ('E', 'e'), ('|', '|'), ('4', '4'), ('4', '4'), ('1', '1')]

>> Stemming using Snowball Stemmer: 
 [('2', '2'), ('8', '8'), ('M', 'm'), ('A', 'a'), ('Y', 'y'), ('2', '2'), ('0', '0'), ('1', '1'), ('5', '5'), ('|', '|'), ('V', 'v'), ('O', 'o'), ('L', 'l'), ('5', '5'), ('2', '2'), ('1', '1'), ('|', '|'), ('N', 'n'), ('A', 'a'), ('T', 't'), ('U', 'u'), ('R', 'r'), ('E', 'e'), ('|', '|'), ('4', '4'), ('4', '4'), ('1', '1')]

>> Lemmatization: 
 [('2', '2'), ('8', '8'), ('M', 'M'), ('A', 'A'), ('Y', 'Y'), ('2', '2'), ('0', '0'), ('1', '1'), ('5', '5'), ('|', '|'), ('V', 'V'), ('O', 'O'), ('L', 'L'), ('5', '5'), ('2', '2'), ('1', '1'), ('|', '|'), ('N', 'N'), ('A', 'A'), ('T', 'T'), ('U', 'U'), ('R', 'R'), ('E', 'E'), ('|', '|'), ('4', '4'), ('4', '4'), ('1', '1')]



========================================== PARAGRAPH 213 ===========================================

REVIEW INSIGHT 

------------------- Sentence 1 -------------------

REVIEW INSIGHT

>> Tokens are: 
 ['REVIEW', 'INSIGHT']

>> Bigrams are: 
 [('REVIEW', 'INSIGHT')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('REVIEW', 'NNP'), ('INSIGHT', 'NNP')]

>> Noun Phrases are: 
 ['REVIEW INSIGHT']

>> Named Entities are: 
 [('ORGANIZATION', 'REVIEW')] 

>> Stemming using Porter Stemmer: 
 [('REVIEW', 'review'), ('INSIGHT', 'insight')]

>> Stemming using Snowball Stemmer: 
 [('REVIEW', 'review'), ('INSIGHT', 'insight')]

>> Lemmatization: 
 [('REVIEW', 'REVIEW'), ('INSIGHT', 'INSIGHT')]



========================================== PARAGRAPH 214 ===========================================

© 2015 Macmillan Publishers Limited. All rights reserved

------------------- Sentence 1 -------------------

© 2015 Macmillan Publishers Limited.

>> Tokens are: 
 ['©', '2015', 'Macmillan', 'Publishers', 'Limited', '.']

>> Bigrams are: 
 [('©', '2015'), ('2015', 'Macmillan'), ('Macmillan', 'Publishers'), ('Publishers', 'Limited'), ('Limited', '.')]

>> Trigrams are: 
 [('©', '2015', 'Macmillan'), ('2015', 'Macmillan', 'Publishers'), ('Macmillan', 'Publishers', 'Limited'), ('Publishers', 'Limited', '.')]

>> POS Tags are: 
 [('©', 'NN'), ('2015', 'CD'), ('Macmillan', 'NNP'), ('Publishers', 'NNP'), ('Limited', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['©', 'Macmillan Publishers Limited']

>> Named Entities are: 
 [('PERSON', 'Macmillan Publishers Limited')] 

>> Stemming using Porter Stemmer: 
 [('©', '©'), ('2015', '2015'), ('Macmillan', 'macmillan'), ('Publishers', 'publish'), ('Limited', 'limit'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('©', '©'), ('2015', '2015'), ('Macmillan', 'macmillan'), ('Publishers', 'publish'), ('Limited', 'limit'), ('.', '.')]

>> Lemmatization: 
 [('©', '©'), ('2015', '2015'), ('Macmillan', 'Macmillan'), ('Publishers', 'Publishers'), ('Limited', 'Limited'), ('.', '.')]


------------------- Sentence 2 -------------------

All rights reserved

>> Tokens are: 
 ['All', 'rights', 'reserved']

>> Bigrams are: 
 [('All', 'rights'), ('rights', 'reserved')]

>> Trigrams are: 
 [('All', 'rights', 'reserved')]

>> POS Tags are: 
 [('All', 'DT'), ('rights', 'NNS'), ('reserved', 'VBN')]

>> Noun Phrases are: 
 ['All rights']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('All', 'all'), ('rights', 'right'), ('reserved', 'reserv')]

>> Stemming using Snowball Stemmer: 
 [('All', 'all'), ('rights', 'right'), ('reserved', 'reserv')]

>> Lemmatization: 
 [('All', 'All'), ('rights', 'right'), ('reserved', 'reserved')]



========================================== PARAGRAPH 215 ===========================================

that each contribute plausibility to a conclusion84,85.  Instead of translating the meaning of a French sentence into an  

------------------- Sentence 1 -------------------

that each contribute plausibility to a conclusion84,85.

>> Tokens are: 
 ['contribute', 'plausibility', 'conclusion84,85', '.']

>> Bigrams are: 
 [('contribute', 'plausibility'), ('plausibility', 'conclusion84,85'), ('conclusion84,85', '.')]

>> Trigrams are: 
 [('contribute', 'plausibility', 'conclusion84,85'), ('plausibility', 'conclusion84,85', '.')]

>> POS Tags are: 
 [('contribute', 'JJ'), ('plausibility', 'NN'), ('conclusion84,85', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['contribute plausibility conclusion84,85']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('contribute', 'contribut'), ('plausibility', 'plausibl'), ('conclusion84,85', 'conclusion84,85'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('contribute', 'contribut'), ('plausibility', 'plausibl'), ('conclusion84,85', 'conclusion84,85'), ('.', '.')]

>> Lemmatization: 
 [('contribute', 'contribute'), ('plausibility', 'plausibility'), ('conclusion84,85', 'conclusion84,85'), ('.', '.')]


------------------- Sentence 2 -------------------

Instead of translating the meaning of a French sentence into an

>> Tokens are: 
 ['Instead', 'translating', 'meaning', 'French', 'sentence']

>> Bigrams are: 
 [('Instead', 'translating'), ('translating', 'meaning'), ('meaning', 'French'), ('French', 'sentence')]

>> Trigrams are: 
 [('Instead', 'translating', 'meaning'), ('translating', 'meaning', 'French'), ('meaning', 'French', 'sentence')]

>> POS Tags are: 
 [('Instead', 'RB'), ('translating', 'VBG'), ('meaning', 'VBG'), ('French', 'JJ'), ('sentence', 'NN')]

>> Noun Phrases are: 
 ['French sentence']

>> Named Entities are: 
 [('GPE', 'French')] 

>> Stemming using Porter Stemmer: 
 [('Instead', 'instead'), ('translating', 'translat'), ('meaning', 'mean'), ('French', 'french'), ('sentence', 'sentenc')]

>> Stemming using Snowball Stemmer: 
 [('Instead', 'instead'), ('translating', 'translat'), ('meaning', 'mean'), ('French', 'french'), ('sentence', 'sentenc')]

>> Lemmatization: 
 [('Instead', 'Instead'), ('translating', 'translating'), ('meaning', 'meaning'), ('French', 'French'), ('sentence', 'sentence')]



========================================== PARAGRAPH 216 ===========================================

English sentence, one can learn to ‘translate’ the meaning of an image  into an English sentence (Fig. 3). The encoder here is a deep Con- vNet that converts the pixels into an activity vector in its last hidden  layer. The decoder is an RNN similar to the ones used for machine  translation and neural language modelling. There has been a surge of  interest in such systems recently (see examples mentioned in ref. 86).  

------------------- Sentence 1 -------------------

English sentence, one can learn to ‘translate’ the meaning of an image  into an English sentence (Fig.

>> Tokens are: 
 ['English', 'sentence', ',', 'one', 'learn', '‘', 'translate', '’', 'meaning', 'image', 'English', 'sentence', '(', 'Fig', '.']

>> Bigrams are: 
 [('English', 'sentence'), ('sentence', ','), (',', 'one'), ('one', 'learn'), ('learn', '‘'), ('‘', 'translate'), ('translate', '’'), ('’', 'meaning'), ('meaning', 'image'), ('image', 'English'), ('English', 'sentence'), ('sentence', '('), ('(', 'Fig'), ('Fig', '.')]

>> Trigrams are: 
 [('English', 'sentence', ','), ('sentence', ',', 'one'), (',', 'one', 'learn'), ('one', 'learn', '‘'), ('learn', '‘', 'translate'), ('‘', 'translate', '’'), ('translate', '’', 'meaning'), ('’', 'meaning', 'image'), ('meaning', 'image', 'English'), ('image', 'English', 'sentence'), ('English', 'sentence', '('), ('sentence', '(', 'Fig'), ('(', 'Fig', '.')]

>> POS Tags are: 
 [('English', 'JJ'), ('sentence', 'NN'), (',', ','), ('one', 'CD'), ('learn', 'NN'), ('‘', 'NN'), ('translate', 'NN'), ('’', 'NN'), ('meaning', 'VBG'), ('image', 'NN'), ('English', 'JJ'), ('sentence', 'NN'), ('(', '('), ('Fig', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['English sentence', 'learn ‘ translate ’', 'image', 'English sentence', 'Fig']

>> Named Entities are: 
 [('GPE', 'English'), ('GPE', 'English'), ('ORGANIZATION', 'Fig')] 

>> Stemming using Porter Stemmer: 
 [('English', 'english'), ('sentence', 'sentenc'), (',', ','), ('one', 'one'), ('learn', 'learn'), ('‘', '‘'), ('translate', 'translat'), ('’', '’'), ('meaning', 'mean'), ('image', 'imag'), ('English', 'english'), ('sentence', 'sentenc'), ('(', '('), ('Fig', 'fig'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('English', 'english'), ('sentence', 'sentenc'), (',', ','), ('one', 'one'), ('learn', 'learn'), ('‘', '‘'), ('translate', 'translat'), ('’', '’'), ('meaning', 'mean'), ('image', 'imag'), ('English', 'english'), ('sentence', 'sentenc'), ('(', '('), ('Fig', 'fig'), ('.', '.')]

>> Lemmatization: 
 [('English', 'English'), ('sentence', 'sentence'), (',', ','), ('one', 'one'), ('learn', 'learn'), ('‘', '‘'), ('translate', 'translate'), ('’', '’'), ('meaning', 'meaning'), ('image', 'image'), ('English', 'English'), ('sentence', 'sentence'), ('(', '('), ('Fig', 'Fig'), ('.', '.')]


------------------- Sentence 2 -------------------

3).

>> Tokens are: 
 ['3', ')', '.']

>> Bigrams are: 
 [('3', ')'), (')', '.')]

>> Trigrams are: 
 [('3', ')', '.')]

>> POS Tags are: 
 [('3', 'LS'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('3', '3'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('3', '3'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('3', '3'), (')', ')'), ('.', '.')]


------------------- Sentence 3 -------------------

The encoder here is a deep Con- vNet that converts the pixels into an activity vector in its last hidden  layer.

>> Tokens are: 
 ['The', 'encoder', 'deep', 'Con-', 'vNet', 'converts', 'pixels', 'activity', 'vector', 'last', 'hidden', 'layer', '.']

>> Bigrams are: 
 [('The', 'encoder'), ('encoder', 'deep'), ('deep', 'Con-'), ('Con-', 'vNet'), ('vNet', 'converts'), ('converts', 'pixels'), ('pixels', 'activity'), ('activity', 'vector'), ('vector', 'last'), ('last', 'hidden'), ('hidden', 'layer'), ('layer', '.')]

>> Trigrams are: 
 [('The', 'encoder', 'deep'), ('encoder', 'deep', 'Con-'), ('deep', 'Con-', 'vNet'), ('Con-', 'vNet', 'converts'), ('vNet', 'converts', 'pixels'), ('converts', 'pixels', 'activity'), ('pixels', 'activity', 'vector'), ('activity', 'vector', 'last'), ('vector', 'last', 'hidden'), ('last', 'hidden', 'layer'), ('hidden', 'layer', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('encoder', 'NN'), ('deep', 'JJ'), ('Con-', 'JJ'), ('vNet', 'NN'), ('converts', 'NNS'), ('pixels', 'VBP'), ('activity', 'NN'), ('vector', 'NN'), ('last', 'JJ'), ('hidden', 'JJ'), ('layer', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['The encoder', 'deep Con- vNet converts', 'activity vector', 'last hidden layer']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('encoder', 'encod'), ('deep', 'deep'), ('Con-', 'con-'), ('vNet', 'vnet'), ('converts', 'convert'), ('pixels', 'pixel'), ('activity', 'activ'), ('vector', 'vector'), ('last', 'last'), ('hidden', 'hidden'), ('layer', 'layer'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('encoder', 'encod'), ('deep', 'deep'), ('Con-', 'con-'), ('vNet', 'vnet'), ('converts', 'convert'), ('pixels', 'pixel'), ('activity', 'activ'), ('vector', 'vector'), ('last', 'last'), ('hidden', 'hidden'), ('layer', 'layer'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('encoder', 'encoder'), ('deep', 'deep'), ('Con-', 'Con-'), ('vNet', 'vNet'), ('converts', 'convert'), ('pixels', 'pixel'), ('activity', 'activity'), ('vector', 'vector'), ('last', 'last'), ('hidden', 'hidden'), ('layer', 'layer'), ('.', '.')]


------------------- Sentence 4 -------------------

The decoder is an RNN similar to the ones used for machine  translation and neural language modelling.

>> Tokens are: 
 ['The', 'decoder', 'RNN', 'similar', 'ones', 'used', 'machine', 'translation', 'neural', 'language', 'modelling', '.']

>> Bigrams are: 
 [('The', 'decoder'), ('decoder', 'RNN'), ('RNN', 'similar'), ('similar', 'ones'), ('ones', 'used'), ('used', 'machine'), ('machine', 'translation'), ('translation', 'neural'), ('neural', 'language'), ('language', 'modelling'), ('modelling', '.')]

>> Trigrams are: 
 [('The', 'decoder', 'RNN'), ('decoder', 'RNN', 'similar'), ('RNN', 'similar', 'ones'), ('similar', 'ones', 'used'), ('ones', 'used', 'machine'), ('used', 'machine', 'translation'), ('machine', 'translation', 'neural'), ('translation', 'neural', 'language'), ('neural', 'language', 'modelling'), ('language', 'modelling', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('decoder', 'NN'), ('RNN', 'NNP'), ('similar', 'JJ'), ('ones', 'NNS'), ('used', 'VBN'), ('machine', 'NN'), ('translation', 'NN'), ('neural', 'JJ'), ('language', 'NN'), ('modelling', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['The decoder RNN', 'similar ones', 'machine translation', 'neural language modelling']

>> Named Entities are: 
 [('ORGANIZATION', 'RNN')] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('decoder', 'decod'), ('RNN', 'rnn'), ('similar', 'similar'), ('ones', 'one'), ('used', 'use'), ('machine', 'machin'), ('translation', 'translat'), ('neural', 'neural'), ('language', 'languag'), ('modelling', 'model'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('decoder', 'decod'), ('RNN', 'rnn'), ('similar', 'similar'), ('ones', 'one'), ('used', 'use'), ('machine', 'machin'), ('translation', 'translat'), ('neural', 'neural'), ('language', 'languag'), ('modelling', 'model'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('decoder', 'decoder'), ('RNN', 'RNN'), ('similar', 'similar'), ('ones', 'one'), ('used', 'used'), ('machine', 'machine'), ('translation', 'translation'), ('neural', 'neural'), ('language', 'language'), ('modelling', 'modelling'), ('.', '.')]


------------------- Sentence 5 -------------------

There has been a surge of  interest in such systems recently (see examples mentioned in ref.

>> Tokens are: 
 ['There', 'surge', 'interest', 'systems', 'recently', '(', 'see', 'examples', 'mentioned', 'ref', '.']

>> Bigrams are: 
 [('There', 'surge'), ('surge', 'interest'), ('interest', 'systems'), ('systems', 'recently'), ('recently', '('), ('(', 'see'), ('see', 'examples'), ('examples', 'mentioned'), ('mentioned', 'ref'), ('ref', '.')]

>> Trigrams are: 
 [('There', 'surge', 'interest'), ('surge', 'interest', 'systems'), ('interest', 'systems', 'recently'), ('systems', 'recently', '('), ('recently', '(', 'see'), ('(', 'see', 'examples'), ('see', 'examples', 'mentioned'), ('examples', 'mentioned', 'ref'), ('mentioned', 'ref', '.')]

>> POS Tags are: 
 [('There', 'EX'), ('surge', 'JJ'), ('interest', 'NN'), ('systems', 'NNS'), ('recently', 'RB'), ('(', '('), ('see', 'VB'), ('examples', 'NNS'), ('mentioned', 'VBN'), ('ref', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['surge interest systems', 'examples', 'ref']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('There', 'there'), ('surge', 'surg'), ('interest', 'interest'), ('systems', 'system'), ('recently', 'recent'), ('(', '('), ('see', 'see'), ('examples', 'exampl'), ('mentioned', 'mention'), ('ref', 'ref'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('There', 'there'), ('surge', 'surg'), ('interest', 'interest'), ('systems', 'system'), ('recently', 'recent'), ('(', '('), ('see', 'see'), ('examples', 'exampl'), ('mentioned', 'mention'), ('ref', 'ref'), ('.', '.')]

>> Lemmatization: 
 [('There', 'There'), ('surge', 'surge'), ('interest', 'interest'), ('systems', 'system'), ('recently', 'recently'), ('(', '('), ('see', 'see'), ('examples', 'example'), ('mentioned', 'mentioned'), ('ref', 'ref'), ('.', '.')]


------------------- Sentence 6 -------------------

86).

>> Tokens are: 
 ['86', ')', '.']

>> Bigrams are: 
 [('86', ')'), (')', '.')]

>> Trigrams are: 
 [('86', ')', '.')]

>> POS Tags are: 
 [('86', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('86', '86'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('86', '86'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('86', '86'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 217 ===========================================

RNNs, once unfolded in time (Fig. 5), can be seen as very deep  feedforward networks in which all the layers share the same weights.  Although their main purpose is to learn long-term dependencies,  theoretical and empirical evidence shows that it is difficult to learn  to store information for very long78.   

------------------- Sentence 1 -------------------

RNNs, once unfolded in time (Fig.

>> Tokens are: 
 ['RNNs', ',', 'unfolded', 'time', '(', 'Fig', '.']

>> Bigrams are: 
 [('RNNs', ','), (',', 'unfolded'), ('unfolded', 'time'), ('time', '('), ('(', 'Fig'), ('Fig', '.')]

>> Trigrams are: 
 [('RNNs', ',', 'unfolded'), (',', 'unfolded', 'time'), ('unfolded', 'time', '('), ('time', '(', 'Fig'), ('(', 'Fig', '.')]

>> POS Tags are: 
 [('RNNs', 'NNP'), (',', ','), ('unfolded', 'JJ'), ('time', 'NN'), ('(', '('), ('Fig', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['RNNs', 'unfolded time', 'Fig']

>> Named Entities are: 
 [('GPE', 'RNNs'), ('ORGANIZATION', 'Fig')] 

>> Stemming using Porter Stemmer: 
 [('RNNs', 'rnn'), (',', ','), ('unfolded', 'unfold'), ('time', 'time'), ('(', '('), ('Fig', 'fig'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('RNNs', 'rnns'), (',', ','), ('unfolded', 'unfold'), ('time', 'time'), ('(', '('), ('Fig', 'fig'), ('.', '.')]

>> Lemmatization: 
 [('RNNs', 'RNNs'), (',', ','), ('unfolded', 'unfolded'), ('time', 'time'), ('(', '('), ('Fig', 'Fig'), ('.', '.')]


------------------- Sentence 2 -------------------

5), can be seen as very deep  feedforward networks in which all the layers share the same weights.

>> Tokens are: 
 ['5', ')', ',', 'seen', 'deep', 'feedforward', 'networks', 'layers', 'share', 'weights', '.']

>> Bigrams are: 
 [('5', ')'), (')', ','), (',', 'seen'), ('seen', 'deep'), ('deep', 'feedforward'), ('feedforward', 'networks'), ('networks', 'layers'), ('layers', 'share'), ('share', 'weights'), ('weights', '.')]

>> Trigrams are: 
 [('5', ')', ','), (')', ',', 'seen'), (',', 'seen', 'deep'), ('seen', 'deep', 'feedforward'), ('deep', 'feedforward', 'networks'), ('feedforward', 'networks', 'layers'), ('networks', 'layers', 'share'), ('layers', 'share', 'weights'), ('share', 'weights', '.')]

>> POS Tags are: 
 [('5', 'CD'), (')', ')'), (',', ','), ('seen', 'VBN'), ('deep', 'JJ'), ('feedforward', 'NN'), ('networks', 'NNS'), ('layers', 'NNS'), ('share', 'NN'), ('weights', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['deep feedforward networks layers share weights']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('5', '5'), (')', ')'), (',', ','), ('seen', 'seen'), ('deep', 'deep'), ('feedforward', 'feedforward'), ('networks', 'network'), ('layers', 'layer'), ('share', 'share'), ('weights', 'weight'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('5', '5'), (')', ')'), (',', ','), ('seen', 'seen'), ('deep', 'deep'), ('feedforward', 'feedforward'), ('networks', 'network'), ('layers', 'layer'), ('share', 'share'), ('weights', 'weight'), ('.', '.')]

>> Lemmatization: 
 [('5', '5'), (')', ')'), (',', ','), ('seen', 'seen'), ('deep', 'deep'), ('feedforward', 'feedforward'), ('networks', 'network'), ('layers', 'layer'), ('share', 'share'), ('weights', 'weight'), ('.', '.')]


------------------- Sentence 3 -------------------

Although their main purpose is to learn long-term dependencies,  theoretical and empirical evidence shows that it is difficult to learn  to store information for very long78.

>> Tokens are: 
 ['Although', 'main', 'purpose', 'learn', 'long-term', 'dependencies', ',', 'theoretical', 'empirical', 'evidence', 'shows', 'difficult', 'learn', 'store', 'information', 'long78', '.']

>> Bigrams are: 
 [('Although', 'main'), ('main', 'purpose'), ('purpose', 'learn'), ('learn', 'long-term'), ('long-term', 'dependencies'), ('dependencies', ','), (',', 'theoretical'), ('theoretical', 'empirical'), ('empirical', 'evidence'), ('evidence', 'shows'), ('shows', 'difficult'), ('difficult', 'learn'), ('learn', 'store'), ('store', 'information'), ('information', 'long78'), ('long78', '.')]

>> Trigrams are: 
 [('Although', 'main', 'purpose'), ('main', 'purpose', 'learn'), ('purpose', 'learn', 'long-term'), ('learn', 'long-term', 'dependencies'), ('long-term', 'dependencies', ','), ('dependencies', ',', 'theoretical'), (',', 'theoretical', 'empirical'), ('theoretical', 'empirical', 'evidence'), ('empirical', 'evidence', 'shows'), ('evidence', 'shows', 'difficult'), ('shows', 'difficult', 'learn'), ('difficult', 'learn', 'store'), ('learn', 'store', 'information'), ('store', 'information', 'long78'), ('information', 'long78', '.')]

>> POS Tags are: 
 [('Although', 'IN'), ('main', 'JJ'), ('purpose', 'NN'), ('learn', 'RBR'), ('long-term', 'JJ'), ('dependencies', 'NNS'), (',', ','), ('theoretical', 'JJ'), ('empirical', 'JJ'), ('evidence', 'NN'), ('shows', 'NNS'), ('difficult', 'JJ'), ('learn', 'JJ'), ('store', 'NN'), ('information', 'NN'), ('long78', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['main purpose', 'long-term dependencies', 'theoretical empirical evidence shows', 'difficult learn store information long78']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Although', 'although'), ('main', 'main'), ('purpose', 'purpos'), ('learn', 'learn'), ('long-term', 'long-term'), ('dependencies', 'depend'), (',', ','), ('theoretical', 'theoret'), ('empirical', 'empir'), ('evidence', 'evid'), ('shows', 'show'), ('difficult', 'difficult'), ('learn', 'learn'), ('store', 'store'), ('information', 'inform'), ('long78', 'long78'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Although', 'although'), ('main', 'main'), ('purpose', 'purpos'), ('learn', 'learn'), ('long-term', 'long-term'), ('dependencies', 'depend'), (',', ','), ('theoretical', 'theoret'), ('empirical', 'empir'), ('evidence', 'evid'), ('shows', 'show'), ('difficult', 'difficult'), ('learn', 'learn'), ('store', 'store'), ('information', 'inform'), ('long78', 'long78'), ('.', '.')]

>> Lemmatization: 
 [('Although', 'Although'), ('main', 'main'), ('purpose', 'purpose'), ('learn', 'learn'), ('long-term', 'long-term'), ('dependencies', 'dependency'), (',', ','), ('theoretical', 'theoretical'), ('empirical', 'empirical'), ('evidence', 'evidence'), ('shows', 'show'), ('difficult', 'difficult'), ('learn', 'learn'), ('store', 'store'), ('information', 'information'), ('long78', 'long78'), ('.', '.')]



========================================== PARAGRAPH 218 ===========================================

To correct for that, one idea is to augment the network with an  explicit memory. The first proposal of this kind is the long short-term  memory (LSTM) networks that use special hidden units, the natural  behaviour of which is to remember inputs for a long time79. A special  unit called the memory cell acts like an accumulator or a gated leaky  neuron: it has a connection to itself at the next time step that has a  weight of one, so it copies its own real-valued state and accumulates  the external signal, but this self-connection is multiplicatively gated  by another unit that learns to decide when to clear the content of the  memory.  

------------------- Sentence 1 -------------------

To correct for that, one idea is to augment the network with an  explicit memory.

>> Tokens are: 
 ['To', 'correct', ',', 'one', 'idea', 'augment', 'network', 'explicit', 'memory', '.']

>> Bigrams are: 
 [('To', 'correct'), ('correct', ','), (',', 'one'), ('one', 'idea'), ('idea', 'augment'), ('augment', 'network'), ('network', 'explicit'), ('explicit', 'memory'), ('memory', '.')]

>> Trigrams are: 
 [('To', 'correct', ','), ('correct', ',', 'one'), (',', 'one', 'idea'), ('one', 'idea', 'augment'), ('idea', 'augment', 'network'), ('augment', 'network', 'explicit'), ('network', 'explicit', 'memory'), ('explicit', 'memory', '.')]

>> POS Tags are: 
 [('To', 'TO'), ('correct', 'VB'), (',', ','), ('one', 'CD'), ('idea', 'NN'), ('augment', 'NN'), ('network', 'NN'), ('explicit', 'JJ'), ('memory', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['idea augment network', 'explicit memory']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('To', 'to'), ('correct', 'correct'), (',', ','), ('one', 'one'), ('idea', 'idea'), ('augment', 'augment'), ('network', 'network'), ('explicit', 'explicit'), ('memory', 'memori'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('To', 'to'), ('correct', 'correct'), (',', ','), ('one', 'one'), ('idea', 'idea'), ('augment', 'augment'), ('network', 'network'), ('explicit', 'explicit'), ('memory', 'memori'), ('.', '.')]

>> Lemmatization: 
 [('To', 'To'), ('correct', 'correct'), (',', ','), ('one', 'one'), ('idea', 'idea'), ('augment', 'augment'), ('network', 'network'), ('explicit', 'explicit'), ('memory', 'memory'), ('.', '.')]


------------------- Sentence 2 -------------------

The first proposal of this kind is the long short-term  memory (LSTM) networks that use special hidden units, the natural  behaviour of which is to remember inputs for a long time79.

>> Tokens are: 
 ['The', 'first', 'proposal', 'kind', 'long', 'short-term', 'memory', '(', 'LSTM', ')', 'networks', 'use', 'special', 'hidden', 'units', ',', 'natural', 'behaviour', 'remember', 'inputs', 'long', 'time79', '.']

>> Bigrams are: 
 [('The', 'first'), ('first', 'proposal'), ('proposal', 'kind'), ('kind', 'long'), ('long', 'short-term'), ('short-term', 'memory'), ('memory', '('), ('(', 'LSTM'), ('LSTM', ')'), (')', 'networks'), ('networks', 'use'), ('use', 'special'), ('special', 'hidden'), ('hidden', 'units'), ('units', ','), (',', 'natural'), ('natural', 'behaviour'), ('behaviour', 'remember'), ('remember', 'inputs'), ('inputs', 'long'), ('long', 'time79'), ('time79', '.')]

>> Trigrams are: 
 [('The', 'first', 'proposal'), ('first', 'proposal', 'kind'), ('proposal', 'kind', 'long'), ('kind', 'long', 'short-term'), ('long', 'short-term', 'memory'), ('short-term', 'memory', '('), ('memory', '(', 'LSTM'), ('(', 'LSTM', ')'), ('LSTM', ')', 'networks'), (')', 'networks', 'use'), ('networks', 'use', 'special'), ('use', 'special', 'hidden'), ('special', 'hidden', 'units'), ('hidden', 'units', ','), ('units', ',', 'natural'), (',', 'natural', 'behaviour'), ('natural', 'behaviour', 'remember'), ('behaviour', 'remember', 'inputs'), ('remember', 'inputs', 'long'), ('inputs', 'long', 'time79'), ('long', 'time79', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('first', 'JJ'), ('proposal', 'NN'), ('kind', 'NN'), ('long', 'JJ'), ('short-term', 'JJ'), ('memory', 'NN'), ('(', '('), ('LSTM', 'NNP'), (')', ')'), ('networks', 'NNS'), ('use', 'VBP'), ('special', 'JJ'), ('hidden', 'JJ'), ('units', 'NNS'), (',', ','), ('natural', 'JJ'), ('behaviour', 'NN'), ('remember', 'NN'), ('inputs', 'NNS'), ('long', 'JJ'), ('time79', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['The first proposal kind', 'long short-term memory', 'LSTM', 'networks', 'special hidden units', 'natural behaviour remember inputs', 'long time79']

>> Named Entities are: 
 [('ORGANIZATION', 'LSTM')] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('first', 'first'), ('proposal', 'propos'), ('kind', 'kind'), ('long', 'long'), ('short-term', 'short-term'), ('memory', 'memori'), ('(', '('), ('LSTM', 'lstm'), (')', ')'), ('networks', 'network'), ('use', 'use'), ('special', 'special'), ('hidden', 'hidden'), ('units', 'unit'), (',', ','), ('natural', 'natur'), ('behaviour', 'behaviour'), ('remember', 'rememb'), ('inputs', 'input'), ('long', 'long'), ('time79', 'time79'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('first', 'first'), ('proposal', 'propos'), ('kind', 'kind'), ('long', 'long'), ('short-term', 'short-term'), ('memory', 'memori'), ('(', '('), ('LSTM', 'lstm'), (')', ')'), ('networks', 'network'), ('use', 'use'), ('special', 'special'), ('hidden', 'hidden'), ('units', 'unit'), (',', ','), ('natural', 'natur'), ('behaviour', 'behaviour'), ('remember', 'rememb'), ('inputs', 'input'), ('long', 'long'), ('time79', 'time79'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('first', 'first'), ('proposal', 'proposal'), ('kind', 'kind'), ('long', 'long'), ('short-term', 'short-term'), ('memory', 'memory'), ('(', '('), ('LSTM', 'LSTM'), (')', ')'), ('networks', 'network'), ('use', 'use'), ('special', 'special'), ('hidden', 'hidden'), ('units', 'unit'), (',', ','), ('natural', 'natural'), ('behaviour', 'behaviour'), ('remember', 'remember'), ('inputs', 'input'), ('long', 'long'), ('time79', 'time79'), ('.', '.')]


------------------- Sentence 3 -------------------

A special  unit called the memory cell acts like an accumulator or a gated leaky  neuron: it has a connection to itself at the next time step that has a  weight of one, so it copies its own real-valued state and accumulates  the external signal, but this self-connection is multiplicatively gated  by another unit that learns to decide when to clear the content of the  memory.

>> Tokens are: 
 ['A', 'special', 'unit', 'called', 'memory', 'cell', 'acts', 'like', 'accumulator', 'gated', 'leaky', 'neuron', ':', 'connection', 'next', 'time', 'step', 'weight', 'one', ',', 'copies', 'real-valued', 'state', 'accumulates', 'external', 'signal', ',', 'self-connection', 'multiplicatively', 'gated', 'another', 'unit', 'learns', 'decide', 'clear', 'content', 'memory', '.']

>> Bigrams are: 
 [('A', 'special'), ('special', 'unit'), ('unit', 'called'), ('called', 'memory'), ('memory', 'cell'), ('cell', 'acts'), ('acts', 'like'), ('like', 'accumulator'), ('accumulator', 'gated'), ('gated', 'leaky'), ('leaky', 'neuron'), ('neuron', ':'), (':', 'connection'), ('connection', 'next'), ('next', 'time'), ('time', 'step'), ('step', 'weight'), ('weight', 'one'), ('one', ','), (',', 'copies'), ('copies', 'real-valued'), ('real-valued', 'state'), ('state', 'accumulates'), ('accumulates', 'external'), ('external', 'signal'), ('signal', ','), (',', 'self-connection'), ('self-connection', 'multiplicatively'), ('multiplicatively', 'gated'), ('gated', 'another'), ('another', 'unit'), ('unit', 'learns'), ('learns', 'decide'), ('decide', 'clear'), ('clear', 'content'), ('content', 'memory'), ('memory', '.')]

>> Trigrams are: 
 [('A', 'special', 'unit'), ('special', 'unit', 'called'), ('unit', 'called', 'memory'), ('called', 'memory', 'cell'), ('memory', 'cell', 'acts'), ('cell', 'acts', 'like'), ('acts', 'like', 'accumulator'), ('like', 'accumulator', 'gated'), ('accumulator', 'gated', 'leaky'), ('gated', 'leaky', 'neuron'), ('leaky', 'neuron', ':'), ('neuron', ':', 'connection'), (':', 'connection', 'next'), ('connection', 'next', 'time'), ('next', 'time', 'step'), ('time', 'step', 'weight'), ('step', 'weight', 'one'), ('weight', 'one', ','), ('one', ',', 'copies'), (',', 'copies', 'real-valued'), ('copies', 'real-valued', 'state'), ('real-valued', 'state', 'accumulates'), ('state', 'accumulates', 'external'), ('accumulates', 'external', 'signal'), ('external', 'signal', ','), ('signal', ',', 'self-connection'), (',', 'self-connection', 'multiplicatively'), ('self-connection', 'multiplicatively', 'gated'), ('multiplicatively', 'gated', 'another'), ('gated', 'another', 'unit'), ('another', 'unit', 'learns'), ('unit', 'learns', 'decide'), ('learns', 'decide', 'clear'), ('decide', 'clear', 'content'), ('clear', 'content', 'memory'), ('content', 'memory', '.')]

>> POS Tags are: 
 [('A', 'DT'), ('special', 'JJ'), ('unit', 'NN'), ('called', 'VBD'), ('memory', 'NN'), ('cell', 'NN'), ('acts', 'NNS'), ('like', 'IN'), ('accumulator', 'NN'), ('gated', 'VBD'), ('leaky', 'JJ'), ('neuron', 'NN'), (':', ':'), ('connection', 'NN'), ('next', 'IN'), ('time', 'NN'), ('step', 'NN'), ('weight', 'VBD'), ('one', 'CD'), (',', ','), ('copies', 'VBZ'), ('real-valued', 'JJ'), ('state', 'NN'), ('accumulates', 'NNS'), ('external', 'JJ'), ('signal', 'NN'), (',', ','), ('self-connection', 'NN'), ('multiplicatively', 'RB'), ('gated', 'VBD'), ('another', 'DT'), ('unit', 'NN'), ('learns', 'VBZ'), ('decide', 'RB'), ('clear', 'JJ'), ('content', 'JJ'), ('memory', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['A special unit', 'memory cell acts', 'accumulator', 'leaky neuron', 'connection', 'time step', 'real-valued state accumulates', 'external signal', 'self-connection', 'another unit', 'clear content memory']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('A', 'a'), ('special', 'special'), ('unit', 'unit'), ('called', 'call'), ('memory', 'memori'), ('cell', 'cell'), ('acts', 'act'), ('like', 'like'), ('accumulator', 'accumul'), ('gated', 'gate'), ('leaky', 'leaki'), ('neuron', 'neuron'), (':', ':'), ('connection', 'connect'), ('next', 'next'), ('time', 'time'), ('step', 'step'), ('weight', 'weight'), ('one', 'one'), (',', ','), ('copies', 'copi'), ('real-valued', 'real-valu'), ('state', 'state'), ('accumulates', 'accumul'), ('external', 'extern'), ('signal', 'signal'), (',', ','), ('self-connection', 'self-connect'), ('multiplicatively', 'multipl'), ('gated', 'gate'), ('another', 'anoth'), ('unit', 'unit'), ('learns', 'learn'), ('decide', 'decid'), ('clear', 'clear'), ('content', 'content'), ('memory', 'memori'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('A', 'a'), ('special', 'special'), ('unit', 'unit'), ('called', 'call'), ('memory', 'memori'), ('cell', 'cell'), ('acts', 'act'), ('like', 'like'), ('accumulator', 'accumul'), ('gated', 'gate'), ('leaky', 'leaki'), ('neuron', 'neuron'), (':', ':'), ('connection', 'connect'), ('next', 'next'), ('time', 'time'), ('step', 'step'), ('weight', 'weight'), ('one', 'one'), (',', ','), ('copies', 'copi'), ('real-valued', 'real-valu'), ('state', 'state'), ('accumulates', 'accumul'), ('external', 'extern'), ('signal', 'signal'), (',', ','), ('self-connection', 'self-connect'), ('multiplicatively', 'multipl'), ('gated', 'gate'), ('another', 'anoth'), ('unit', 'unit'), ('learns', 'learn'), ('decide', 'decid'), ('clear', 'clear'), ('content', 'content'), ('memory', 'memori'), ('.', '.')]

>> Lemmatization: 
 [('A', 'A'), ('special', 'special'), ('unit', 'unit'), ('called', 'called'), ('memory', 'memory'), ('cell', 'cell'), ('acts', 'act'), ('like', 'like'), ('accumulator', 'accumulator'), ('gated', 'gated'), ('leaky', 'leaky'), ('neuron', 'neuron'), (':', ':'), ('connection', 'connection'), ('next', 'next'), ('time', 'time'), ('step', 'step'), ('weight', 'weight'), ('one', 'one'), (',', ','), ('copies', 'copy'), ('real-valued', 'real-valued'), ('state', 'state'), ('accumulates', 'accumulates'), ('external', 'external'), ('signal', 'signal'), (',', ','), ('self-connection', 'self-connection'), ('multiplicatively', 'multiplicatively'), ('gated', 'gated'), ('another', 'another'), ('unit', 'unit'), ('learns', 'learns'), ('decide', 'decide'), ('clear', 'clear'), ('content', 'content'), ('memory', 'memory'), ('.', '.')]



========================================== PARAGRAPH 219 ===========================================

LSTM networks have subsequently proved to be more effective  than conventional RNNs, especially when they have several layers for  each time step87, enabling an entire speech recognition system that  goes all the way from acoustics to the sequence of characters in the  transcription. LSTM networks or related forms of gated units are also  currently used for the encoder and decoder networks that perform  so well at machine translation17,72,76.  

------------------- Sentence 1 -------------------

LSTM networks have subsequently proved to be more effective  than conventional RNNs, especially when they have several layers for  each time step87, enabling an entire speech recognition system that  goes all the way from acoustics to the sequence of characters in the  transcription.

>> Tokens are: 
 ['LSTM', 'networks', 'subsequently', 'proved', 'effective', 'conventional', 'RNNs', ',', 'especially', 'several', 'layers', 'time', 'step87', ',', 'enabling', 'entire', 'speech', 'recognition', 'system', 'goes', 'way', 'acoustics', 'sequence', 'characters', 'transcription', '.']

>> Bigrams are: 
 [('LSTM', 'networks'), ('networks', 'subsequently'), ('subsequently', 'proved'), ('proved', 'effective'), ('effective', 'conventional'), ('conventional', 'RNNs'), ('RNNs', ','), (',', 'especially'), ('especially', 'several'), ('several', 'layers'), ('layers', 'time'), ('time', 'step87'), ('step87', ','), (',', 'enabling'), ('enabling', 'entire'), ('entire', 'speech'), ('speech', 'recognition'), ('recognition', 'system'), ('system', 'goes'), ('goes', 'way'), ('way', 'acoustics'), ('acoustics', 'sequence'), ('sequence', 'characters'), ('characters', 'transcription'), ('transcription', '.')]

>> Trigrams are: 
 [('LSTM', 'networks', 'subsequently'), ('networks', 'subsequently', 'proved'), ('subsequently', 'proved', 'effective'), ('proved', 'effective', 'conventional'), ('effective', 'conventional', 'RNNs'), ('conventional', 'RNNs', ','), ('RNNs', ',', 'especially'), (',', 'especially', 'several'), ('especially', 'several', 'layers'), ('several', 'layers', 'time'), ('layers', 'time', 'step87'), ('time', 'step87', ','), ('step87', ',', 'enabling'), (',', 'enabling', 'entire'), ('enabling', 'entire', 'speech'), ('entire', 'speech', 'recognition'), ('speech', 'recognition', 'system'), ('recognition', 'system', 'goes'), ('system', 'goes', 'way'), ('goes', 'way', 'acoustics'), ('way', 'acoustics', 'sequence'), ('acoustics', 'sequence', 'characters'), ('sequence', 'characters', 'transcription'), ('characters', 'transcription', '.')]

>> POS Tags are: 
 [('LSTM', 'NNP'), ('networks', 'NNS'), ('subsequently', 'RB'), ('proved', 'VBD'), ('effective', 'JJ'), ('conventional', 'JJ'), ('RNNs', 'NNP'), (',', ','), ('especially', 'RB'), ('several', 'JJ'), ('layers', 'NNS'), ('time', 'NN'), ('step87', 'NN'), (',', ','), ('enabling', 'VBG'), ('entire', 'JJ'), ('speech', 'NN'), ('recognition', 'NN'), ('system', 'NN'), ('goes', 'VBZ'), ('way', 'NN'), ('acoustics', 'NNS'), ('sequence', 'NN'), ('characters', 'NNS'), ('transcription', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['LSTM networks', 'effective conventional RNNs', 'several layers time step87', 'entire speech recognition system', 'way acoustics sequence characters transcription']

>> Named Entities are: 
 [('ORGANIZATION', 'RNNs')] 

>> Stemming using Porter Stemmer: 
 [('LSTM', 'lstm'), ('networks', 'network'), ('subsequently', 'subsequ'), ('proved', 'prove'), ('effective', 'effect'), ('conventional', 'convent'), ('RNNs', 'rnn'), (',', ','), ('especially', 'especi'), ('several', 'sever'), ('layers', 'layer'), ('time', 'time'), ('step87', 'step87'), (',', ','), ('enabling', 'enabl'), ('entire', 'entir'), ('speech', 'speech'), ('recognition', 'recognit'), ('system', 'system'), ('goes', 'goe'), ('way', 'way'), ('acoustics', 'acoust'), ('sequence', 'sequenc'), ('characters', 'charact'), ('transcription', 'transcript'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('LSTM', 'lstm'), ('networks', 'network'), ('subsequently', 'subsequ'), ('proved', 'prove'), ('effective', 'effect'), ('conventional', 'convent'), ('RNNs', 'rnns'), (',', ','), ('especially', 'especi'), ('several', 'sever'), ('layers', 'layer'), ('time', 'time'), ('step87', 'step87'), (',', ','), ('enabling', 'enabl'), ('entire', 'entir'), ('speech', 'speech'), ('recognition', 'recognit'), ('system', 'system'), ('goes', 'goe'), ('way', 'way'), ('acoustics', 'acoust'), ('sequence', 'sequenc'), ('characters', 'charact'), ('transcription', 'transcript'), ('.', '.')]

>> Lemmatization: 
 [('LSTM', 'LSTM'), ('networks', 'network'), ('subsequently', 'subsequently'), ('proved', 'proved'), ('effective', 'effective'), ('conventional', 'conventional'), ('RNNs', 'RNNs'), (',', ','), ('especially', 'especially'), ('several', 'several'), ('layers', 'layer'), ('time', 'time'), ('step87', 'step87'), (',', ','), ('enabling', 'enabling'), ('entire', 'entire'), ('speech', 'speech'), ('recognition', 'recognition'), ('system', 'system'), ('goes', 'go'), ('way', 'way'), ('acoustics', 'acoustic'), ('sequence', 'sequence'), ('characters', 'character'), ('transcription', 'transcription'), ('.', '.')]


------------------- Sentence 2 -------------------

LSTM networks or related forms of gated units are also  currently used for the encoder and decoder networks that perform  so well at machine translation17,72,76.

>> Tokens are: 
 ['LSTM', 'networks', 'related', 'forms', 'gated', 'units', 'also', 'currently', 'used', 'encoder', 'decoder', 'networks', 'perform', 'well', 'machine', 'translation17,72,76', '.']

>> Bigrams are: 
 [('LSTM', 'networks'), ('networks', 'related'), ('related', 'forms'), ('forms', 'gated'), ('gated', 'units'), ('units', 'also'), ('also', 'currently'), ('currently', 'used'), ('used', 'encoder'), ('encoder', 'decoder'), ('decoder', 'networks'), ('networks', 'perform'), ('perform', 'well'), ('well', 'machine'), ('machine', 'translation17,72,76'), ('translation17,72,76', '.')]

>> Trigrams are: 
 [('LSTM', 'networks', 'related'), ('networks', 'related', 'forms'), ('related', 'forms', 'gated'), ('forms', 'gated', 'units'), ('gated', 'units', 'also'), ('units', 'also', 'currently'), ('also', 'currently', 'used'), ('currently', 'used', 'encoder'), ('used', 'encoder', 'decoder'), ('encoder', 'decoder', 'networks'), ('decoder', 'networks', 'perform'), ('networks', 'perform', 'well'), ('perform', 'well', 'machine'), ('well', 'machine', 'translation17,72,76'), ('machine', 'translation17,72,76', '.')]

>> POS Tags are: 
 [('LSTM', 'NNP'), ('networks', 'NNS'), ('related', 'VBD'), ('forms', 'NNS'), ('gated', 'VBN'), ('units', 'NNS'), ('also', 'RB'), ('currently', 'RB'), ('used', 'VBN'), ('encoder', 'NN'), ('decoder', 'NN'), ('networks', 'NNS'), ('perform', 'VBP'), ('well', 'RB'), ('machine', 'NN'), ('translation17,72,76', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['LSTM networks', 'forms', 'units', 'encoder decoder networks', 'machine translation17,72,76']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('LSTM', 'lstm'), ('networks', 'network'), ('related', 'relat'), ('forms', 'form'), ('gated', 'gate'), ('units', 'unit'), ('also', 'also'), ('currently', 'current'), ('used', 'use'), ('encoder', 'encod'), ('decoder', 'decod'), ('networks', 'network'), ('perform', 'perform'), ('well', 'well'), ('machine', 'machin'), ('translation17,72,76', 'translation17,72,76'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('LSTM', 'lstm'), ('networks', 'network'), ('related', 'relat'), ('forms', 'form'), ('gated', 'gate'), ('units', 'unit'), ('also', 'also'), ('currently', 'current'), ('used', 'use'), ('encoder', 'encod'), ('decoder', 'decod'), ('networks', 'network'), ('perform', 'perform'), ('well', 'well'), ('machine', 'machin'), ('translation17,72,76', 'translation17,72,76'), ('.', '.')]

>> Lemmatization: 
 [('LSTM', 'LSTM'), ('networks', 'network'), ('related', 'related'), ('forms', 'form'), ('gated', 'gated'), ('units', 'unit'), ('also', 'also'), ('currently', 'currently'), ('used', 'used'), ('encoder', 'encoder'), ('decoder', 'decoder'), ('networks', 'network'), ('perform', 'perform'), ('well', 'well'), ('machine', 'machine'), ('translation17,72,76', 'translation17,72,76'), ('.', '.')]



========================================== PARAGRAPH 220 ===========================================

Over the past year, several authors have made different proposals to  augment RNNs with a memory module. Proposals include the Neural  Turing Machine in which the network is augmented by a ‘tape-like’  memory that the RNN can choose to read from or write to88, and  memory networks, in which a regular network is augmented by a  kind of associative memory89. Memory networks have yielded excel- lent performance on standard question-answering benchmarks. The  memory is used to remember the story about which the network is  later asked to answer questions.  

------------------- Sentence 1 -------------------

Over the past year, several authors have made different proposals to  augment RNNs with a memory module.

>> Tokens are: 
 ['Over', 'past', 'year', ',', 'several', 'authors', 'made', 'different', 'proposals', 'augment', 'RNNs', 'memory', 'module', '.']

>> Bigrams are: 
 [('Over', 'past'), ('past', 'year'), ('year', ','), (',', 'several'), ('several', 'authors'), ('authors', 'made'), ('made', 'different'), ('different', 'proposals'), ('proposals', 'augment'), ('augment', 'RNNs'), ('RNNs', 'memory'), ('memory', 'module'), ('module', '.')]

>> Trigrams are: 
 [('Over', 'past', 'year'), ('past', 'year', ','), ('year', ',', 'several'), (',', 'several', 'authors'), ('several', 'authors', 'made'), ('authors', 'made', 'different'), ('made', 'different', 'proposals'), ('different', 'proposals', 'augment'), ('proposals', 'augment', 'RNNs'), ('augment', 'RNNs', 'memory'), ('RNNs', 'memory', 'module'), ('memory', 'module', '.')]

>> POS Tags are: 
 [('Over', 'IN'), ('past', 'JJ'), ('year', 'NN'), (',', ','), ('several', 'JJ'), ('authors', 'NNS'), ('made', 'VBD'), ('different', 'JJ'), ('proposals', 'NNS'), ('augment', 'JJ'), ('RNNs', 'NNP'), ('memory', 'NN'), ('module', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['past year', 'several authors', 'different proposals', 'augment RNNs memory module']

>> Named Entities are: 
 [('ORGANIZATION', 'RNNs')] 

>> Stemming using Porter Stemmer: 
 [('Over', 'over'), ('past', 'past'), ('year', 'year'), (',', ','), ('several', 'sever'), ('authors', 'author'), ('made', 'made'), ('different', 'differ'), ('proposals', 'propos'), ('augment', 'augment'), ('RNNs', 'rnn'), ('memory', 'memori'), ('module', 'modul'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Over', 'over'), ('past', 'past'), ('year', 'year'), (',', ','), ('several', 'sever'), ('authors', 'author'), ('made', 'made'), ('different', 'differ'), ('proposals', 'propos'), ('augment', 'augment'), ('RNNs', 'rnns'), ('memory', 'memori'), ('module', 'modul'), ('.', '.')]

>> Lemmatization: 
 [('Over', 'Over'), ('past', 'past'), ('year', 'year'), (',', ','), ('several', 'several'), ('authors', 'author'), ('made', 'made'), ('different', 'different'), ('proposals', 'proposal'), ('augment', 'augment'), ('RNNs', 'RNNs'), ('memory', 'memory'), ('module', 'module'), ('.', '.')]


------------------- Sentence 2 -------------------

Proposals include the Neural  Turing Machine in which the network is augmented by a ‘tape-like’  memory that the RNN can choose to read from or write to88, and  memory networks, in which a regular network is augmented by a  kind of associative memory89.

>> Tokens are: 
 ['Proposals', 'include', 'Neural', 'Turing', 'Machine', 'network', 'augmented', '‘', 'tape-like', '’', 'memory', 'RNN', 'choose', 'read', 'write', 'to88', ',', 'memory', 'networks', ',', 'regular', 'network', 'augmented', 'kind', 'associative', 'memory89', '.']

>> Bigrams are: 
 [('Proposals', 'include'), ('include', 'Neural'), ('Neural', 'Turing'), ('Turing', 'Machine'), ('Machine', 'network'), ('network', 'augmented'), ('augmented', '‘'), ('‘', 'tape-like'), ('tape-like', '’'), ('’', 'memory'), ('memory', 'RNN'), ('RNN', 'choose'), ('choose', 'read'), ('read', 'write'), ('write', 'to88'), ('to88', ','), (',', 'memory'), ('memory', 'networks'), ('networks', ','), (',', 'regular'), ('regular', 'network'), ('network', 'augmented'), ('augmented', 'kind'), ('kind', 'associative'), ('associative', 'memory89'), ('memory89', '.')]

>> Trigrams are: 
 [('Proposals', 'include', 'Neural'), ('include', 'Neural', 'Turing'), ('Neural', 'Turing', 'Machine'), ('Turing', 'Machine', 'network'), ('Machine', 'network', 'augmented'), ('network', 'augmented', '‘'), ('augmented', '‘', 'tape-like'), ('‘', 'tape-like', '’'), ('tape-like', '’', 'memory'), ('’', 'memory', 'RNN'), ('memory', 'RNN', 'choose'), ('RNN', 'choose', 'read'), ('choose', 'read', 'write'), ('read', 'write', 'to88'), ('write', 'to88', ','), ('to88', ',', 'memory'), (',', 'memory', 'networks'), ('memory', 'networks', ','), ('networks', ',', 'regular'), (',', 'regular', 'network'), ('regular', 'network', 'augmented'), ('network', 'augmented', 'kind'), ('augmented', 'kind', 'associative'), ('kind', 'associative', 'memory89'), ('associative', 'memory89', '.')]

>> POS Tags are: 
 [('Proposals', 'NNS'), ('include', 'VBP'), ('Neural', 'JJ'), ('Turing', 'NNP'), ('Machine', 'NNP'), ('network', 'NN'), ('augmented', 'VBD'), ('‘', 'JJ'), ('tape-like', 'JJ'), ('’', 'NNP'), ('memory', 'NN'), ('RNN', 'NNP'), ('choose', 'NN'), ('read', 'VBD'), ('write', 'JJ'), ('to88', 'NNS'), (',', ','), ('memory', 'NN'), ('networks', 'NNS'), (',', ','), ('regular', 'JJ'), ('network', 'NN'), ('augmented', 'VBD'), ('kind', 'NN'), ('associative', 'JJ'), ('memory89', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Proposals', 'Neural Turing Machine network', '‘ tape-like ’ memory RNN choose', 'write to88', 'memory networks', 'regular network', 'kind', 'associative memory89']

>> Named Entities are: 
 [('ORGANIZATION', 'Neural Turing Machine'), ('ORGANIZATION', 'RNN')] 

>> Stemming using Porter Stemmer: 
 [('Proposals', 'propos'), ('include', 'includ'), ('Neural', 'neural'), ('Turing', 'ture'), ('Machine', 'machin'), ('network', 'network'), ('augmented', 'augment'), ('‘', '‘'), ('tape-like', 'tape-lik'), ('’', '’'), ('memory', 'memori'), ('RNN', 'rnn'), ('choose', 'choos'), ('read', 'read'), ('write', 'write'), ('to88', 'to88'), (',', ','), ('memory', 'memori'), ('networks', 'network'), (',', ','), ('regular', 'regular'), ('network', 'network'), ('augmented', 'augment'), ('kind', 'kind'), ('associative', 'associ'), ('memory89', 'memory89'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Proposals', 'propos'), ('include', 'includ'), ('Neural', 'neural'), ('Turing', 'ture'), ('Machine', 'machin'), ('network', 'network'), ('augmented', 'augment'), ('‘', '‘'), ('tape-like', 'tape-lik'), ('’', '’'), ('memory', 'memori'), ('RNN', 'rnn'), ('choose', 'choos'), ('read', 'read'), ('write', 'write'), ('to88', 'to88'), (',', ','), ('memory', 'memori'), ('networks', 'network'), (',', ','), ('regular', 'regular'), ('network', 'network'), ('augmented', 'augment'), ('kind', 'kind'), ('associative', 'associ'), ('memory89', 'memory89'), ('.', '.')]

>> Lemmatization: 
 [('Proposals', 'Proposals'), ('include', 'include'), ('Neural', 'Neural'), ('Turing', 'Turing'), ('Machine', 'Machine'), ('network', 'network'), ('augmented', 'augmented'), ('‘', '‘'), ('tape-like', 'tape-like'), ('’', '’'), ('memory', 'memory'), ('RNN', 'RNN'), ('choose', 'choose'), ('read', 'read'), ('write', 'write'), ('to88', 'to88'), (',', ','), ('memory', 'memory'), ('networks', 'network'), (',', ','), ('regular', 'regular'), ('network', 'network'), ('augmented', 'augmented'), ('kind', 'kind'), ('associative', 'associative'), ('memory89', 'memory89'), ('.', '.')]


------------------- Sentence 3 -------------------

Memory networks have yielded excel- lent performance on standard question-answering benchmarks.

>> Tokens are: 
 ['Memory', 'networks', 'yielded', 'excel-', 'lent', 'performance', 'standard', 'question-answering', 'benchmarks', '.']

>> Bigrams are: 
 [('Memory', 'networks'), ('networks', 'yielded'), ('yielded', 'excel-'), ('excel-', 'lent'), ('lent', 'performance'), ('performance', 'standard'), ('standard', 'question-answering'), ('question-answering', 'benchmarks'), ('benchmarks', '.')]

>> Trigrams are: 
 [('Memory', 'networks', 'yielded'), ('networks', 'yielded', 'excel-'), ('yielded', 'excel-', 'lent'), ('excel-', 'lent', 'performance'), ('lent', 'performance', 'standard'), ('performance', 'standard', 'question-answering'), ('standard', 'question-answering', 'benchmarks'), ('question-answering', 'benchmarks', '.')]

>> POS Tags are: 
 [('Memory', 'NN'), ('networks', 'NNS'), ('yielded', 'VBD'), ('excel-', 'JJ'), ('lent', 'JJ'), ('performance', 'NN'), ('standard', 'JJ'), ('question-answering', 'JJ'), ('benchmarks', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['Memory networks', 'excel- lent performance', 'standard question-answering benchmarks']

>> Named Entities are: 
 [('GPE', 'Memory')] 

>> Stemming using Porter Stemmer: 
 [('Memory', 'memori'), ('networks', 'network'), ('yielded', 'yield'), ('excel-', 'excel-'), ('lent', 'lent'), ('performance', 'perform'), ('standard', 'standard'), ('question-answering', 'question-answ'), ('benchmarks', 'benchmark'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Memory', 'memori'), ('networks', 'network'), ('yielded', 'yield'), ('excel-', 'excel-'), ('lent', 'lent'), ('performance', 'perform'), ('standard', 'standard'), ('question-answering', 'question-answ'), ('benchmarks', 'benchmark'), ('.', '.')]

>> Lemmatization: 
 [('Memory', 'Memory'), ('networks', 'network'), ('yielded', 'yielded'), ('excel-', 'excel-'), ('lent', 'lent'), ('performance', 'performance'), ('standard', 'standard'), ('question-answering', 'question-answering'), ('benchmarks', 'benchmark'), ('.', '.')]


------------------- Sentence 4 -------------------

The  memory is used to remember the story about which the network is  later asked to answer questions.

>> Tokens are: 
 ['The', 'memory', 'used', 'remember', 'story', 'network', 'later', 'asked', 'answer', 'questions', '.']

>> Bigrams are: 
 [('The', 'memory'), ('memory', 'used'), ('used', 'remember'), ('remember', 'story'), ('story', 'network'), ('network', 'later'), ('later', 'asked'), ('asked', 'answer'), ('answer', 'questions'), ('questions', '.')]

>> Trigrams are: 
 [('The', 'memory', 'used'), ('memory', 'used', 'remember'), ('used', 'remember', 'story'), ('remember', 'story', 'network'), ('story', 'network', 'later'), ('network', 'later', 'asked'), ('later', 'asked', 'answer'), ('asked', 'answer', 'questions'), ('answer', 'questions', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('memory', 'NN'), ('used', 'VBN'), ('remember', 'VB'), ('story', 'NN'), ('network', 'NN'), ('later', 'RB'), ('asked', 'VBD'), ('answer', 'RP'), ('questions', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['The memory', 'story network', 'questions']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('memory', 'memori'), ('used', 'use'), ('remember', 'rememb'), ('story', 'stori'), ('network', 'network'), ('later', 'later'), ('asked', 'ask'), ('answer', 'answer'), ('questions', 'question'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('memory', 'memori'), ('used', 'use'), ('remember', 'rememb'), ('story', 'stori'), ('network', 'network'), ('later', 'later'), ('asked', 'ask'), ('answer', 'answer'), ('questions', 'question'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('memory', 'memory'), ('used', 'used'), ('remember', 'remember'), ('story', 'story'), ('network', 'network'), ('later', 'later'), ('asked', 'asked'), ('answer', 'answer'), ('questions', 'question'), ('.', '.')]



========================================== PARAGRAPH 221 ===========================================

Beyond simple memorization, neural Turing machines and mem- ory networks are being used for tasks that would normally require  reasoning and symbol manipulation. Neural Turing machines can  be taught ‘algorithms’. Among other things, they can learn to output  

------------------- Sentence 1 -------------------

Beyond simple memorization, neural Turing machines and mem- ory networks are being used for tasks that would normally require  reasoning and symbol manipulation.

>> Tokens are: 
 ['Beyond', 'simple', 'memorization', ',', 'neural', 'Turing', 'machines', 'mem-', 'ory', 'networks', 'used', 'tasks', 'would', 'normally', 'require', 'reasoning', 'symbol', 'manipulation', '.']

>> Bigrams are: 
 [('Beyond', 'simple'), ('simple', 'memorization'), ('memorization', ','), (',', 'neural'), ('neural', 'Turing'), ('Turing', 'machines'), ('machines', 'mem-'), ('mem-', 'ory'), ('ory', 'networks'), ('networks', 'used'), ('used', 'tasks'), ('tasks', 'would'), ('would', 'normally'), ('normally', 'require'), ('require', 'reasoning'), ('reasoning', 'symbol'), ('symbol', 'manipulation'), ('manipulation', '.')]

>> Trigrams are: 
 [('Beyond', 'simple', 'memorization'), ('simple', 'memorization', ','), ('memorization', ',', 'neural'), (',', 'neural', 'Turing'), ('neural', 'Turing', 'machines'), ('Turing', 'machines', 'mem-'), ('machines', 'mem-', 'ory'), ('mem-', 'ory', 'networks'), ('ory', 'networks', 'used'), ('networks', 'used', 'tasks'), ('used', 'tasks', 'would'), ('tasks', 'would', 'normally'), ('would', 'normally', 'require'), ('normally', 'require', 'reasoning'), ('require', 'reasoning', 'symbol'), ('reasoning', 'symbol', 'manipulation'), ('symbol', 'manipulation', '.')]

>> POS Tags are: 
 [('Beyond', 'NN'), ('simple', 'JJ'), ('memorization', 'NN'), (',', ','), ('neural', 'JJ'), ('Turing', 'NNP'), ('machines', 'NNS'), ('mem-', 'JJ'), ('ory', 'JJ'), ('networks', 'NNS'), ('used', 'VBN'), ('tasks', 'NNS'), ('would', 'MD'), ('normally', 'RB'), ('require', 'VB'), ('reasoning', 'VBG'), ('symbol', 'NN'), ('manipulation', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Beyond', 'simple memorization', 'neural Turing machines', 'mem- ory networks', 'tasks', 'symbol manipulation']

>> Named Entities are: 
 [('GPE', 'Beyond')] 

>> Stemming using Porter Stemmer: 
 [('Beyond', 'beyond'), ('simple', 'simpl'), ('memorization', 'memor'), (',', ','), ('neural', 'neural'), ('Turing', 'ture'), ('machines', 'machin'), ('mem-', 'mem-'), ('ory', 'ori'), ('networks', 'network'), ('used', 'use'), ('tasks', 'task'), ('would', 'would'), ('normally', 'normal'), ('require', 'requir'), ('reasoning', 'reason'), ('symbol', 'symbol'), ('manipulation', 'manipul'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Beyond', 'beyond'), ('simple', 'simpl'), ('memorization', 'memor'), (',', ','), ('neural', 'neural'), ('Turing', 'ture'), ('machines', 'machin'), ('mem-', 'mem-'), ('ory', 'ori'), ('networks', 'network'), ('used', 'use'), ('tasks', 'task'), ('would', 'would'), ('normally', 'normal'), ('require', 'requir'), ('reasoning', 'reason'), ('symbol', 'symbol'), ('manipulation', 'manipul'), ('.', '.')]

>> Lemmatization: 
 [('Beyond', 'Beyond'), ('simple', 'simple'), ('memorization', 'memorization'), (',', ','), ('neural', 'neural'), ('Turing', 'Turing'), ('machines', 'machine'), ('mem-', 'mem-'), ('ory', 'ory'), ('networks', 'network'), ('used', 'used'), ('tasks', 'task'), ('would', 'would'), ('normally', 'normally'), ('require', 'require'), ('reasoning', 'reasoning'), ('symbol', 'symbol'), ('manipulation', 'manipulation'), ('.', '.')]


------------------- Sentence 2 -------------------

Neural Turing machines can  be taught ‘algorithms’.

>> Tokens are: 
 ['Neural', 'Turing', 'machines', 'taught', '‘', 'algorithms', '’', '.']

>> Bigrams are: 
 [('Neural', 'Turing'), ('Turing', 'machines'), ('machines', 'taught'), ('taught', '‘'), ('‘', 'algorithms'), ('algorithms', '’'), ('’', '.')]

>> Trigrams are: 
 [('Neural', 'Turing', 'machines'), ('Turing', 'machines', 'taught'), ('machines', 'taught', '‘'), ('taught', '‘', 'algorithms'), ('‘', 'algorithms', '’'), ('algorithms', '’', '.')]

>> POS Tags are: 
 [('Neural', 'JJ'), ('Turing', 'NNP'), ('machines', 'NNS'), ('taught', 'VBD'), ('‘', 'NNP'), ('algorithms', 'NN'), ('’', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Neural Turing machines', '‘ algorithms ’']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Neural', 'neural'), ('Turing', 'ture'), ('machines', 'machin'), ('taught', 'taught'), ('‘', '‘'), ('algorithms', 'algorithm'), ('’', '’'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Neural', 'neural'), ('Turing', 'ture'), ('machines', 'machin'), ('taught', 'taught'), ('‘', '‘'), ('algorithms', 'algorithm'), ('’', '’'), ('.', '.')]

>> Lemmatization: 
 [('Neural', 'Neural'), ('Turing', 'Turing'), ('machines', 'machine'), ('taught', 'taught'), ('‘', '‘'), ('algorithms', 'algorithm'), ('’', '’'), ('.', '.')]


------------------- Sentence 3 -------------------

Among other things, they can learn to output

>> Tokens are: 
 ['Among', 'things', ',', 'learn', 'output']

>> Bigrams are: 
 [('Among', 'things'), ('things', ','), (',', 'learn'), ('learn', 'output')]

>> Trigrams are: 
 [('Among', 'things', ','), ('things', ',', 'learn'), (',', 'learn', 'output')]

>> POS Tags are: 
 [('Among', 'IN'), ('things', 'NNS'), (',', ','), ('learn', 'VBP'), ('output', 'NN')]

>> Noun Phrases are: 
 ['things', 'output']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Among', 'among'), ('things', 'thing'), (',', ','), ('learn', 'learn'), ('output', 'output')]

>> Stemming using Snowball Stemmer: 
 [('Among', 'among'), ('things', 'thing'), (',', ','), ('learn', 'learn'), ('output', 'output')]

>> Lemmatization: 
 [('Among', 'Among'), ('things', 'thing'), (',', ','), ('learn', 'learn'), ('output', 'output')]



========================================== PARAGRAPH 222 ===========================================

a sorted list of symbols when their input consists of an unsorted  sequence in which each symbol is accompanied by a real value that  indicates its priority in the list88. Memory networks can be trained  to keep track of the state of the world in a setting similar to a text  adventure game and after reading a story, they can answer questions  that require complex inference90. In one test example, the network is  shown a 15-sentence version of the The Lord of the Rings and correctly  answers questions such as “where is Frodo now?”89.   

------------------- Sentence 1 -------------------

a sorted list of symbols when their input consists of an unsorted  sequence in which each symbol is accompanied by a real value that  indicates its priority in the list88.

>> Tokens are: 
 ['sorted', 'list', 'symbols', 'input', 'consists', 'unsorted', 'sequence', 'symbol', 'accompanied', 'real', 'value', 'indicates', 'priority', 'list88', '.']

>> Bigrams are: 
 [('sorted', 'list'), ('list', 'symbols'), ('symbols', 'input'), ('input', 'consists'), ('consists', 'unsorted'), ('unsorted', 'sequence'), ('sequence', 'symbol'), ('symbol', 'accompanied'), ('accompanied', 'real'), ('real', 'value'), ('value', 'indicates'), ('indicates', 'priority'), ('priority', 'list88'), ('list88', '.')]

>> Trigrams are: 
 [('sorted', 'list', 'symbols'), ('list', 'symbols', 'input'), ('symbols', 'input', 'consists'), ('input', 'consists', 'unsorted'), ('consists', 'unsorted', 'sequence'), ('unsorted', 'sequence', 'symbol'), ('sequence', 'symbol', 'accompanied'), ('symbol', 'accompanied', 'real'), ('accompanied', 'real', 'value'), ('real', 'value', 'indicates'), ('value', 'indicates', 'priority'), ('indicates', 'priority', 'list88'), ('priority', 'list88', '.')]

>> POS Tags are: 
 [('sorted', 'VBN'), ('list', 'NN'), ('symbols', 'NNS'), ('input', 'VBP'), ('consists', 'NNS'), ('unsorted', 'VBD'), ('sequence', 'NN'), ('symbol', 'NN'), ('accompanied', 'VBN'), ('real', 'JJ'), ('value', 'NN'), ('indicates', 'VBZ'), ('priority', 'NN'), ('list88', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['list symbols', 'consists', 'sequence symbol', 'real value', 'priority list88']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('sorted', 'sort'), ('list', 'list'), ('symbols', 'symbol'), ('input', 'input'), ('consists', 'consist'), ('unsorted', 'unsort'), ('sequence', 'sequenc'), ('symbol', 'symbol'), ('accompanied', 'accompani'), ('real', 'real'), ('value', 'valu'), ('indicates', 'indic'), ('priority', 'prioriti'), ('list88', 'list88'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('sorted', 'sort'), ('list', 'list'), ('symbols', 'symbol'), ('input', 'input'), ('consists', 'consist'), ('unsorted', 'unsort'), ('sequence', 'sequenc'), ('symbol', 'symbol'), ('accompanied', 'accompani'), ('real', 'real'), ('value', 'valu'), ('indicates', 'indic'), ('priority', 'prioriti'), ('list88', 'list88'), ('.', '.')]

>> Lemmatization: 
 [('sorted', 'sorted'), ('list', 'list'), ('symbols', 'symbol'), ('input', 'input'), ('consists', 'consists'), ('unsorted', 'unsorted'), ('sequence', 'sequence'), ('symbol', 'symbol'), ('accompanied', 'accompanied'), ('real', 'real'), ('value', 'value'), ('indicates', 'indicates'), ('priority', 'priority'), ('list88', 'list88'), ('.', '.')]


------------------- Sentence 2 -------------------

Memory networks can be trained  to keep track of the state of the world in a setting similar to a text  adventure game and after reading a story, they can answer questions  that require complex inference90.

>> Tokens are: 
 ['Memory', 'networks', 'trained', 'keep', 'track', 'state', 'world', 'setting', 'similar', 'text', 'adventure', 'game', 'reading', 'story', ',', 'answer', 'questions', 'require', 'complex', 'inference90', '.']

>> Bigrams are: 
 [('Memory', 'networks'), ('networks', 'trained'), ('trained', 'keep'), ('keep', 'track'), ('track', 'state'), ('state', 'world'), ('world', 'setting'), ('setting', 'similar'), ('similar', 'text'), ('text', 'adventure'), ('adventure', 'game'), ('game', 'reading'), ('reading', 'story'), ('story', ','), (',', 'answer'), ('answer', 'questions'), ('questions', 'require'), ('require', 'complex'), ('complex', 'inference90'), ('inference90', '.')]

>> Trigrams are: 
 [('Memory', 'networks', 'trained'), ('networks', 'trained', 'keep'), ('trained', 'keep', 'track'), ('keep', 'track', 'state'), ('track', 'state', 'world'), ('state', 'world', 'setting'), ('world', 'setting', 'similar'), ('setting', 'similar', 'text'), ('similar', 'text', 'adventure'), ('text', 'adventure', 'game'), ('adventure', 'game', 'reading'), ('game', 'reading', 'story'), ('reading', 'story', ','), ('story', ',', 'answer'), (',', 'answer', 'questions'), ('answer', 'questions', 'require'), ('questions', 'require', 'complex'), ('require', 'complex', 'inference90'), ('complex', 'inference90', '.')]

>> POS Tags are: 
 [('Memory', 'NN'), ('networks', 'NNS'), ('trained', 'VBD'), ('keep', 'JJ'), ('track', 'NN'), ('state', 'NN'), ('world', 'NN'), ('setting', 'VBG'), ('similar', 'JJ'), ('text', 'JJ'), ('adventure', 'NN'), ('game', 'NN'), ('reading', 'VBG'), ('story', 'NN'), (',', ','), ('answer', 'VBP'), ('questions', 'NNS'), ('require', 'VBP'), ('complex', 'JJ'), ('inference90', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Memory networks', 'keep track state world', 'similar text adventure game', 'story', 'questions', 'complex inference90']

>> Named Entities are: 
 [('GPE', 'Memory')] 

>> Stemming using Porter Stemmer: 
 [('Memory', 'memori'), ('networks', 'network'), ('trained', 'train'), ('keep', 'keep'), ('track', 'track'), ('state', 'state'), ('world', 'world'), ('setting', 'set'), ('similar', 'similar'), ('text', 'text'), ('adventure', 'adventur'), ('game', 'game'), ('reading', 'read'), ('story', 'stori'), (',', ','), ('answer', 'answer'), ('questions', 'question'), ('require', 'requir'), ('complex', 'complex'), ('inference90', 'inference90'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Memory', 'memori'), ('networks', 'network'), ('trained', 'train'), ('keep', 'keep'), ('track', 'track'), ('state', 'state'), ('world', 'world'), ('setting', 'set'), ('similar', 'similar'), ('text', 'text'), ('adventure', 'adventur'), ('game', 'game'), ('reading', 'read'), ('story', 'stori'), (',', ','), ('answer', 'answer'), ('questions', 'question'), ('require', 'requir'), ('complex', 'complex'), ('inference90', 'inference90'), ('.', '.')]

>> Lemmatization: 
 [('Memory', 'Memory'), ('networks', 'network'), ('trained', 'trained'), ('keep', 'keep'), ('track', 'track'), ('state', 'state'), ('world', 'world'), ('setting', 'setting'), ('similar', 'similar'), ('text', 'text'), ('adventure', 'adventure'), ('game', 'game'), ('reading', 'reading'), ('story', 'story'), (',', ','), ('answer', 'answer'), ('questions', 'question'), ('require', 'require'), ('complex', 'complex'), ('inference90', 'inference90'), ('.', '.')]


------------------- Sentence 3 -------------------

In one test example, the network is  shown a 15-sentence version of the The Lord of the Rings and correctly  answers questions such as “where is Frodo now?”89.

>> Tokens are: 
 ['In', 'one', 'test', 'example', ',', 'network', 'shown', '15-sentence', 'version', 'The', 'Lord', 'Rings', 'correctly', 'answers', 'questions', '“', 'Frodo', '?', '”', '89', '.']

>> Bigrams are: 
 [('In', 'one'), ('one', 'test'), ('test', 'example'), ('example', ','), (',', 'network'), ('network', 'shown'), ('shown', '15-sentence'), ('15-sentence', 'version'), ('version', 'The'), ('The', 'Lord'), ('Lord', 'Rings'), ('Rings', 'correctly'), ('correctly', 'answers'), ('answers', 'questions'), ('questions', '“'), ('“', 'Frodo'), ('Frodo', '?'), ('?', '”'), ('”', '89'), ('89', '.')]

>> Trigrams are: 
 [('In', 'one', 'test'), ('one', 'test', 'example'), ('test', 'example', ','), ('example', ',', 'network'), (',', 'network', 'shown'), ('network', 'shown', '15-sentence'), ('shown', '15-sentence', 'version'), ('15-sentence', 'version', 'The'), ('version', 'The', 'Lord'), ('The', 'Lord', 'Rings'), ('Lord', 'Rings', 'correctly'), ('Rings', 'correctly', 'answers'), ('correctly', 'answers', 'questions'), ('answers', 'questions', '“'), ('questions', '“', 'Frodo'), ('“', 'Frodo', '?'), ('Frodo', '?', '”'), ('?', '”', '89'), ('”', '89', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('one', 'CD'), ('test', 'NN'), ('example', 'NN'), (',', ','), ('network', 'NN'), ('shown', 'VBN'), ('15-sentence', 'JJ'), ('version', 'NN'), ('The', 'DT'), ('Lord', 'NNP'), ('Rings', 'NNP'), ('correctly', 'RB'), ('answers', 'VBZ'), ('questions', 'NNS'), ('“', 'IN'), ('Frodo', 'NNP'), ('?', '.'), ('”', '$'), ('89', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['test example', 'network', '15-sentence version', 'The Lord Rings', 'questions', 'Frodo']

>> Named Entities are: 
 [('ORGANIZATION', 'Lord'), ('PERSON', 'Frodo')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('one', 'one'), ('test', 'test'), ('example', 'exampl'), (',', ','), ('network', 'network'), ('shown', 'shown'), ('15-sentence', '15-sentenc'), ('version', 'version'), ('The', 'the'), ('Lord', 'lord'), ('Rings', 'ring'), ('correctly', 'correctli'), ('answers', 'answer'), ('questions', 'question'), ('“', '“'), ('Frodo', 'frodo'), ('?', '?'), ('”', '”'), ('89', '89'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('one', 'one'), ('test', 'test'), ('example', 'exampl'), (',', ','), ('network', 'network'), ('shown', 'shown'), ('15-sentence', '15-sentenc'), ('version', 'version'), ('The', 'the'), ('Lord', 'lord'), ('Rings', 'ring'), ('correctly', 'correct'), ('answers', 'answer'), ('questions', 'question'), ('“', '“'), ('Frodo', 'frodo'), ('?', '?'), ('”', '”'), ('89', '89'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('one', 'one'), ('test', 'test'), ('example', 'example'), (',', ','), ('network', 'network'), ('shown', 'shown'), ('15-sentence', '15-sentence'), ('version', 'version'), ('The', 'The'), ('Lord', 'Lord'), ('Rings', 'Rings'), ('correctly', 'correctly'), ('answers', 'answer'), ('questions', 'question'), ('“', '“'), ('Frodo', 'Frodo'), ('?', '?'), ('”', '”'), ('89', '89'), ('.', '.')]



========================================== PARAGRAPH 223 ===========================================

The future of deep learning  Unsupervised learning91–98 had a catalytic effect in reviving interest in  deep learning, but has since been overshadowed by the successes of  purely supervised learning. Although we have not focused on it in this  Review, we expect unsupervised learning to become far more important  in the longer term. Human and animal learning is largely unsupervised:  we discover the structure of the world by observing it, not by being told  the name of every object.  

------------------- Sentence 1 -------------------

The future of deep learning  Unsupervised learning91–98 had a catalytic effect in reviving interest in  deep learning, but has since been overshadowed by the successes of  purely supervised learning.

>> Tokens are: 
 ['The', 'future', 'deep', 'learning', 'Unsupervised', 'learning91–98', 'catalytic', 'effect', 'reviving', 'interest', 'deep', 'learning', ',', 'since', 'overshadowed', 'successes', 'purely', 'supervised', 'learning', '.']

>> Bigrams are: 
 [('The', 'future'), ('future', 'deep'), ('deep', 'learning'), ('learning', 'Unsupervised'), ('Unsupervised', 'learning91–98'), ('learning91–98', 'catalytic'), ('catalytic', 'effect'), ('effect', 'reviving'), ('reviving', 'interest'), ('interest', 'deep'), ('deep', 'learning'), ('learning', ','), (',', 'since'), ('since', 'overshadowed'), ('overshadowed', 'successes'), ('successes', 'purely'), ('purely', 'supervised'), ('supervised', 'learning'), ('learning', '.')]

>> Trigrams are: 
 [('The', 'future', 'deep'), ('future', 'deep', 'learning'), ('deep', 'learning', 'Unsupervised'), ('learning', 'Unsupervised', 'learning91–98'), ('Unsupervised', 'learning91–98', 'catalytic'), ('learning91–98', 'catalytic', 'effect'), ('catalytic', 'effect', 'reviving'), ('effect', 'reviving', 'interest'), ('reviving', 'interest', 'deep'), ('interest', 'deep', 'learning'), ('deep', 'learning', ','), ('learning', ',', 'since'), (',', 'since', 'overshadowed'), ('since', 'overshadowed', 'successes'), ('overshadowed', 'successes', 'purely'), ('successes', 'purely', 'supervised'), ('purely', 'supervised', 'learning'), ('supervised', 'learning', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('future', 'JJ'), ('deep', 'JJ'), ('learning', 'NN'), ('Unsupervised', 'VBD'), ('learning91–98', 'JJ'), ('catalytic', 'JJ'), ('effect', 'NN'), ('reviving', 'VBG'), ('interest', 'NN'), ('deep', 'NN'), ('learning', 'NN'), (',', ','), ('since', 'IN'), ('overshadowed', 'VBN'), ('successes', 'NNS'), ('purely', 'RB'), ('supervised', 'VBD'), ('learning', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['The future deep learning', 'learning91–98 catalytic effect', 'interest deep learning', 'successes', 'learning']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('future', 'futur'), ('deep', 'deep'), ('learning', 'learn'), ('Unsupervised', 'unsupervis'), ('learning91–98', 'learning91–98'), ('catalytic', 'catalyt'), ('effect', 'effect'), ('reviving', 'reviv'), ('interest', 'interest'), ('deep', 'deep'), ('learning', 'learn'), (',', ','), ('since', 'sinc'), ('overshadowed', 'overshadow'), ('successes', 'success'), ('purely', 'pure'), ('supervised', 'supervis'), ('learning', 'learn'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('future', 'futur'), ('deep', 'deep'), ('learning', 'learn'), ('Unsupervised', 'unsupervis'), ('learning91–98', 'learning91–98'), ('catalytic', 'catalyt'), ('effect', 'effect'), ('reviving', 'reviv'), ('interest', 'interest'), ('deep', 'deep'), ('learning', 'learn'), (',', ','), ('since', 'sinc'), ('overshadowed', 'overshadow'), ('successes', 'success'), ('purely', 'pure'), ('supervised', 'supervis'), ('learning', 'learn'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('future', 'future'), ('deep', 'deep'), ('learning', 'learning'), ('Unsupervised', 'Unsupervised'), ('learning91–98', 'learning91–98'), ('catalytic', 'catalytic'), ('effect', 'effect'), ('reviving', 'reviving'), ('interest', 'interest'), ('deep', 'deep'), ('learning', 'learning'), (',', ','), ('since', 'since'), ('overshadowed', 'overshadowed'), ('successes', 'success'), ('purely', 'purely'), ('supervised', 'supervised'), ('learning', 'learning'), ('.', '.')]


------------------- Sentence 2 -------------------

Although we have not focused on it in this  Review, we expect unsupervised learning to become far more important  in the longer term.

>> Tokens are: 
 ['Although', 'focused', 'Review', ',', 'expect', 'unsupervised', 'learning', 'become', 'far', 'important', 'longer', 'term', '.']

>> Bigrams are: 
 [('Although', 'focused'), ('focused', 'Review'), ('Review', ','), (',', 'expect'), ('expect', 'unsupervised'), ('unsupervised', 'learning'), ('learning', 'become'), ('become', 'far'), ('far', 'important'), ('important', 'longer'), ('longer', 'term'), ('term', '.')]

>> Trigrams are: 
 [('Although', 'focused', 'Review'), ('focused', 'Review', ','), ('Review', ',', 'expect'), (',', 'expect', 'unsupervised'), ('expect', 'unsupervised', 'learning'), ('unsupervised', 'learning', 'become'), ('learning', 'become', 'far'), ('become', 'far', 'important'), ('far', 'important', 'longer'), ('important', 'longer', 'term'), ('longer', 'term', '.')]

>> POS Tags are: 
 [('Although', 'IN'), ('focused', 'VBN'), ('Review', 'NNP'), (',', ','), ('expect', 'VBP'), ('unsupervised', 'JJ'), ('learning', 'NN'), ('become', 'NN'), ('far', 'RB'), ('important', 'JJ'), ('longer', 'JJR'), ('term', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Review', 'unsupervised learning become', 'term']

>> Named Entities are: 
 [('PERSON', 'Review')] 

>> Stemming using Porter Stemmer: 
 [('Although', 'although'), ('focused', 'focus'), ('Review', 'review'), (',', ','), ('expect', 'expect'), ('unsupervised', 'unsupervis'), ('learning', 'learn'), ('become', 'becom'), ('far', 'far'), ('important', 'import'), ('longer', 'longer'), ('term', 'term'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Although', 'although'), ('focused', 'focus'), ('Review', 'review'), (',', ','), ('expect', 'expect'), ('unsupervised', 'unsupervis'), ('learning', 'learn'), ('become', 'becom'), ('far', 'far'), ('important', 'import'), ('longer', 'longer'), ('term', 'term'), ('.', '.')]

>> Lemmatization: 
 [('Although', 'Although'), ('focused', 'focused'), ('Review', 'Review'), (',', ','), ('expect', 'expect'), ('unsupervised', 'unsupervised'), ('learning', 'learning'), ('become', 'become'), ('far', 'far'), ('important', 'important'), ('longer', 'longer'), ('term', 'term'), ('.', '.')]


------------------- Sentence 3 -------------------

Human and animal learning is largely unsupervised:  we discover the structure of the world by observing it, not by being told  the name of every object.

>> Tokens are: 
 ['Human', 'animal', 'learning', 'largely', 'unsupervised', ':', 'discover', 'structure', 'world', 'observing', ',', 'told', 'name', 'every', 'object', '.']

>> Bigrams are: 
 [('Human', 'animal'), ('animal', 'learning'), ('learning', 'largely'), ('largely', 'unsupervised'), ('unsupervised', ':'), (':', 'discover'), ('discover', 'structure'), ('structure', 'world'), ('world', 'observing'), ('observing', ','), (',', 'told'), ('told', 'name'), ('name', 'every'), ('every', 'object'), ('object', '.')]

>> Trigrams are: 
 [('Human', 'animal', 'learning'), ('animal', 'learning', 'largely'), ('learning', 'largely', 'unsupervised'), ('largely', 'unsupervised', ':'), ('unsupervised', ':', 'discover'), (':', 'discover', 'structure'), ('discover', 'structure', 'world'), ('structure', 'world', 'observing'), ('world', 'observing', ','), ('observing', ',', 'told'), (',', 'told', 'name'), ('told', 'name', 'every'), ('name', 'every', 'object'), ('every', 'object', '.')]

>> POS Tags are: 
 [('Human', 'NNP'), ('animal', 'NN'), ('learning', 'VBG'), ('largely', 'RB'), ('unsupervised', 'JJ'), (':', ':'), ('discover', 'NN'), ('structure', 'NN'), ('world', 'NN'), ('observing', 'NN'), (',', ','), ('told', 'VBD'), ('name', 'NN'), ('every', 'DT'), ('object', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Human animal', 'discover structure world observing', 'name', 'every object']

>> Named Entities are: 
 [('GPE', 'Human')] 

>> Stemming using Porter Stemmer: 
 [('Human', 'human'), ('animal', 'anim'), ('learning', 'learn'), ('largely', 'larg'), ('unsupervised', 'unsupervis'), (':', ':'), ('discover', 'discov'), ('structure', 'structur'), ('world', 'world'), ('observing', 'observ'), (',', ','), ('told', 'told'), ('name', 'name'), ('every', 'everi'), ('object', 'object'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Human', 'human'), ('animal', 'anim'), ('learning', 'learn'), ('largely', 'larg'), ('unsupervised', 'unsupervis'), (':', ':'), ('discover', 'discov'), ('structure', 'structur'), ('world', 'world'), ('observing', 'observ'), (',', ','), ('told', 'told'), ('name', 'name'), ('every', 'everi'), ('object', 'object'), ('.', '.')]

>> Lemmatization: 
 [('Human', 'Human'), ('animal', 'animal'), ('learning', 'learning'), ('largely', 'largely'), ('unsupervised', 'unsupervised'), (':', ':'), ('discover', 'discover'), ('structure', 'structure'), ('world', 'world'), ('observing', 'observing'), (',', ','), ('told', 'told'), ('name', 'name'), ('every', 'every'), ('object', 'object'), ('.', '.')]



========================================== PARAGRAPH 224 ===========================================

Human vision is an active process that sequentially samples the optic  array in an intelligent, task-specific way using a small, high-resolution  fovea with a large, low-resolution surround. We expect much of the  future progress in vision to come from systems that are trained end-to- end and combine ConvNets with RNNs that use reinforcement learning  to decide where to look. Systems combining deep learning and rein- forcement learning are in their infancy, but they already outperform  passive vision systems99 at classification tasks and produce impressive  results in learning to play many different video games100.  

------------------- Sentence 1 -------------------

Human vision is an active process that sequentially samples the optic  array in an intelligent, task-specific way using a small, high-resolution  fovea with a large, low-resolution surround.

>> Tokens are: 
 ['Human', 'vision', 'active', 'process', 'sequentially', 'samples', 'optic', 'array', 'intelligent', ',', 'task-specific', 'way', 'using', 'small', ',', 'high-resolution', 'fovea', 'large', ',', 'low-resolution', 'surround', '.']

>> Bigrams are: 
 [('Human', 'vision'), ('vision', 'active'), ('active', 'process'), ('process', 'sequentially'), ('sequentially', 'samples'), ('samples', 'optic'), ('optic', 'array'), ('array', 'intelligent'), ('intelligent', ','), (',', 'task-specific'), ('task-specific', 'way'), ('way', 'using'), ('using', 'small'), ('small', ','), (',', 'high-resolution'), ('high-resolution', 'fovea'), ('fovea', 'large'), ('large', ','), (',', 'low-resolution'), ('low-resolution', 'surround'), ('surround', '.')]

>> Trigrams are: 
 [('Human', 'vision', 'active'), ('vision', 'active', 'process'), ('active', 'process', 'sequentially'), ('process', 'sequentially', 'samples'), ('sequentially', 'samples', 'optic'), ('samples', 'optic', 'array'), ('optic', 'array', 'intelligent'), ('array', 'intelligent', ','), ('intelligent', ',', 'task-specific'), (',', 'task-specific', 'way'), ('task-specific', 'way', 'using'), ('way', 'using', 'small'), ('using', 'small', ','), ('small', ',', 'high-resolution'), (',', 'high-resolution', 'fovea'), ('high-resolution', 'fovea', 'large'), ('fovea', 'large', ','), ('large', ',', 'low-resolution'), (',', 'low-resolution', 'surround'), ('low-resolution', 'surround', '.')]

>> POS Tags are: 
 [('Human', 'NNP'), ('vision', 'NN'), ('active', 'JJ'), ('process', 'NN'), ('sequentially', 'RB'), ('samples', 'VBZ'), ('optic', 'JJ'), ('array', 'NN'), ('intelligent', 'NN'), (',', ','), ('task-specific', 'JJ'), ('way', 'NN'), ('using', 'VBG'), ('small', 'JJ'), (',', ','), ('high-resolution', 'JJ'), ('fovea', 'NN'), ('large', 'JJ'), (',', ','), ('low-resolution', 'JJ'), ('surround', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Human vision', 'active process', 'optic array intelligent', 'task-specific way', 'high-resolution fovea', 'low-resolution surround']

>> Named Entities are: 
 [('GPE', 'Human')] 

>> Stemming using Porter Stemmer: 
 [('Human', 'human'), ('vision', 'vision'), ('active', 'activ'), ('process', 'process'), ('sequentially', 'sequenti'), ('samples', 'sampl'), ('optic', 'optic'), ('array', 'array'), ('intelligent', 'intellig'), (',', ','), ('task-specific', 'task-specif'), ('way', 'way'), ('using', 'use'), ('small', 'small'), (',', ','), ('high-resolution', 'high-resolut'), ('fovea', 'fovea'), ('large', 'larg'), (',', ','), ('low-resolution', 'low-resolut'), ('surround', 'surround'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Human', 'human'), ('vision', 'vision'), ('active', 'activ'), ('process', 'process'), ('sequentially', 'sequenti'), ('samples', 'sampl'), ('optic', 'optic'), ('array', 'array'), ('intelligent', 'intellig'), (',', ','), ('task-specific', 'task-specif'), ('way', 'way'), ('using', 'use'), ('small', 'small'), (',', ','), ('high-resolution', 'high-resolut'), ('fovea', 'fovea'), ('large', 'larg'), (',', ','), ('low-resolution', 'low-resolut'), ('surround', 'surround'), ('.', '.')]

>> Lemmatization: 
 [('Human', 'Human'), ('vision', 'vision'), ('active', 'active'), ('process', 'process'), ('sequentially', 'sequentially'), ('samples', 'sample'), ('optic', 'optic'), ('array', 'array'), ('intelligent', 'intelligent'), (',', ','), ('task-specific', 'task-specific'), ('way', 'way'), ('using', 'using'), ('small', 'small'), (',', ','), ('high-resolution', 'high-resolution'), ('fovea', 'fovea'), ('large', 'large'), (',', ','), ('low-resolution', 'low-resolution'), ('surround', 'surround'), ('.', '.')]


------------------- Sentence 2 -------------------

We expect much of the  future progress in vision to come from systems that are trained end-to- end and combine ConvNets with RNNs that use reinforcement learning  to decide where to look.

>> Tokens are: 
 ['We', 'expect', 'much', 'future', 'progress', 'vision', 'come', 'systems', 'trained', 'end-to-', 'end', 'combine', 'ConvNets', 'RNNs', 'use', 'reinforcement', 'learning', 'decide', 'look', '.']

>> Bigrams are: 
 [('We', 'expect'), ('expect', 'much'), ('much', 'future'), ('future', 'progress'), ('progress', 'vision'), ('vision', 'come'), ('come', 'systems'), ('systems', 'trained'), ('trained', 'end-to-'), ('end-to-', 'end'), ('end', 'combine'), ('combine', 'ConvNets'), ('ConvNets', 'RNNs'), ('RNNs', 'use'), ('use', 'reinforcement'), ('reinforcement', 'learning'), ('learning', 'decide'), ('decide', 'look'), ('look', '.')]

>> Trigrams are: 
 [('We', 'expect', 'much'), ('expect', 'much', 'future'), ('much', 'future', 'progress'), ('future', 'progress', 'vision'), ('progress', 'vision', 'come'), ('vision', 'come', 'systems'), ('come', 'systems', 'trained'), ('systems', 'trained', 'end-to-'), ('trained', 'end-to-', 'end'), ('end-to-', 'end', 'combine'), ('end', 'combine', 'ConvNets'), ('combine', 'ConvNets', 'RNNs'), ('ConvNets', 'RNNs', 'use'), ('RNNs', 'use', 'reinforcement'), ('use', 'reinforcement', 'learning'), ('reinforcement', 'learning', 'decide'), ('learning', 'decide', 'look'), ('decide', 'look', '.')]

>> POS Tags are: 
 [('We', 'PRP'), ('expect', 'VBP'), ('much', 'JJ'), ('future', 'NN'), ('progress', 'NN'), ('vision', 'NN'), ('come', 'VBP'), ('systems', 'NNS'), ('trained', 'VBD'), ('end-to-', 'JJ'), ('end', 'NN'), ('combine', 'NN'), ('ConvNets', 'NNP'), ('RNNs', 'NNP'), ('use', 'NN'), ('reinforcement', 'NN'), ('learning', 'VBG'), ('decide', 'JJ'), ('look', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['much future progress vision', 'systems', 'end-to- end combine ConvNets RNNs use reinforcement', 'decide look']

>> Named Entities are: 
 [('ORGANIZATION', 'ConvNets')] 

>> Stemming using Porter Stemmer: 
 [('We', 'we'), ('expect', 'expect'), ('much', 'much'), ('future', 'futur'), ('progress', 'progress'), ('vision', 'vision'), ('come', 'come'), ('systems', 'system'), ('trained', 'train'), ('end-to-', 'end-to-'), ('end', 'end'), ('combine', 'combin'), ('ConvNets', 'convnet'), ('RNNs', 'rnn'), ('use', 'use'), ('reinforcement', 'reinforc'), ('learning', 'learn'), ('decide', 'decid'), ('look', 'look'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('We', 'we'), ('expect', 'expect'), ('much', 'much'), ('future', 'futur'), ('progress', 'progress'), ('vision', 'vision'), ('come', 'come'), ('systems', 'system'), ('trained', 'train'), ('end-to-', 'end-to-'), ('end', 'end'), ('combine', 'combin'), ('ConvNets', 'convnet'), ('RNNs', 'rnns'), ('use', 'use'), ('reinforcement', 'reinforc'), ('learning', 'learn'), ('decide', 'decid'), ('look', 'look'), ('.', '.')]

>> Lemmatization: 
 [('We', 'We'), ('expect', 'expect'), ('much', 'much'), ('future', 'future'), ('progress', 'progress'), ('vision', 'vision'), ('come', 'come'), ('systems', 'system'), ('trained', 'trained'), ('end-to-', 'end-to-'), ('end', 'end'), ('combine', 'combine'), ('ConvNets', 'ConvNets'), ('RNNs', 'RNNs'), ('use', 'use'), ('reinforcement', 'reinforcement'), ('learning', 'learning'), ('decide', 'decide'), ('look', 'look'), ('.', '.')]


------------------- Sentence 3 -------------------

Systems combining deep learning and rein- forcement learning are in their infancy, but they already outperform  passive vision systems99 at classification tasks and produce impressive  results in learning to play many different video games100.

>> Tokens are: 
 ['Systems', 'combining', 'deep', 'learning', 'rein-', 'forcement', 'learning', 'infancy', ',', 'already', 'outperform', 'passive', 'vision', 'systems99', 'classification', 'tasks', 'produce', 'impressive', 'results', 'learning', 'play', 'many', 'different', 'video', 'games100', '.']

>> Bigrams are: 
 [('Systems', 'combining'), ('combining', 'deep'), ('deep', 'learning'), ('learning', 'rein-'), ('rein-', 'forcement'), ('forcement', 'learning'), ('learning', 'infancy'), ('infancy', ','), (',', 'already'), ('already', 'outperform'), ('outperform', 'passive'), ('passive', 'vision'), ('vision', 'systems99'), ('systems99', 'classification'), ('classification', 'tasks'), ('tasks', 'produce'), ('produce', 'impressive'), ('impressive', 'results'), ('results', 'learning'), ('learning', 'play'), ('play', 'many'), ('many', 'different'), ('different', 'video'), ('video', 'games100'), ('games100', '.')]

>> Trigrams are: 
 [('Systems', 'combining', 'deep'), ('combining', 'deep', 'learning'), ('deep', 'learning', 'rein-'), ('learning', 'rein-', 'forcement'), ('rein-', 'forcement', 'learning'), ('forcement', 'learning', 'infancy'), ('learning', 'infancy', ','), ('infancy', ',', 'already'), (',', 'already', 'outperform'), ('already', 'outperform', 'passive'), ('outperform', 'passive', 'vision'), ('passive', 'vision', 'systems99'), ('vision', 'systems99', 'classification'), ('systems99', 'classification', 'tasks'), ('classification', 'tasks', 'produce'), ('tasks', 'produce', 'impressive'), ('produce', 'impressive', 'results'), ('impressive', 'results', 'learning'), ('results', 'learning', 'play'), ('learning', 'play', 'many'), ('play', 'many', 'different'), ('many', 'different', 'video'), ('different', 'video', 'games100'), ('video', 'games100', '.')]

>> POS Tags are: 
 [('Systems', 'NNPS'), ('combining', 'VBG'), ('deep', 'JJ'), ('learning', 'VBG'), ('rein-', 'JJ'), ('forcement', 'NN'), ('learning', 'NN'), ('infancy', 'NN'), (',', ','), ('already', 'RB'), ('outperform', 'VB'), ('passive', 'JJ'), ('vision', 'NN'), ('systems99', 'NN'), ('classification', 'NN'), ('tasks', 'NNS'), ('produce', 'VBP'), ('impressive', 'JJ'), ('results', 'NNS'), ('learning', 'VBG'), ('play', 'VBP'), ('many', 'JJ'), ('different', 'JJ'), ('video', 'NN'), ('games100', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['rein- forcement learning infancy', 'passive vision systems99 classification tasks', 'impressive results', 'many different video games100']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Systems', 'system'), ('combining', 'combin'), ('deep', 'deep'), ('learning', 'learn'), ('rein-', 'rein-'), ('forcement', 'forcement'), ('learning', 'learn'), ('infancy', 'infanc'), (',', ','), ('already', 'alreadi'), ('outperform', 'outperform'), ('passive', 'passiv'), ('vision', 'vision'), ('systems99', 'systems99'), ('classification', 'classif'), ('tasks', 'task'), ('produce', 'produc'), ('impressive', 'impress'), ('results', 'result'), ('learning', 'learn'), ('play', 'play'), ('many', 'mani'), ('different', 'differ'), ('video', 'video'), ('games100', 'games100'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Systems', 'system'), ('combining', 'combin'), ('deep', 'deep'), ('learning', 'learn'), ('rein-', 'rein-'), ('forcement', 'forcement'), ('learning', 'learn'), ('infancy', 'infanc'), (',', ','), ('already', 'alreadi'), ('outperform', 'outperform'), ('passive', 'passiv'), ('vision', 'vision'), ('systems99', 'systems99'), ('classification', 'classif'), ('tasks', 'task'), ('produce', 'produc'), ('impressive', 'impress'), ('results', 'result'), ('learning', 'learn'), ('play', 'play'), ('many', 'mani'), ('different', 'differ'), ('video', 'video'), ('games100', 'games100'), ('.', '.')]

>> Lemmatization: 
 [('Systems', 'Systems'), ('combining', 'combining'), ('deep', 'deep'), ('learning', 'learning'), ('rein-', 'rein-'), ('forcement', 'forcement'), ('learning', 'learning'), ('infancy', 'infancy'), (',', ','), ('already', 'already'), ('outperform', 'outperform'), ('passive', 'passive'), ('vision', 'vision'), ('systems99', 'systems99'), ('classification', 'classification'), ('tasks', 'task'), ('produce', 'produce'), ('impressive', 'impressive'), ('results', 'result'), ('learning', 'learning'), ('play', 'play'), ('many', 'many'), ('different', 'different'), ('video', 'video'), ('games100', 'games100'), ('.', '.')]



========================================== PARAGRAPH 225 ===========================================

Natural language understanding is another area in which deep learn- ing is poised to make a large impact over the next few years. We expect  systems that use RNNs to understand sentences or whole documents  will become much better when they learn strategies for selectively  attending to one part at a time76,86.  

------------------- Sentence 1 -------------------

Natural language understanding is another area in which deep learn- ing is poised to make a large impact over the next few years.

>> Tokens are: 
 ['Natural', 'language', 'understanding', 'another', 'area', 'deep', 'learn-', 'ing', 'poised', 'make', 'large', 'impact', 'next', 'years', '.']

>> Bigrams are: 
 [('Natural', 'language'), ('language', 'understanding'), ('understanding', 'another'), ('another', 'area'), ('area', 'deep'), ('deep', 'learn-'), ('learn-', 'ing'), ('ing', 'poised'), ('poised', 'make'), ('make', 'large'), ('large', 'impact'), ('impact', 'next'), ('next', 'years'), ('years', '.')]

>> Trigrams are: 
 [('Natural', 'language', 'understanding'), ('language', 'understanding', 'another'), ('understanding', 'another', 'area'), ('another', 'area', 'deep'), ('area', 'deep', 'learn-'), ('deep', 'learn-', 'ing'), ('learn-', 'ing', 'poised'), ('ing', 'poised', 'make'), ('poised', 'make', 'large'), ('make', 'large', 'impact'), ('large', 'impact', 'next'), ('impact', 'next', 'years'), ('next', 'years', '.')]

>> POS Tags are: 
 [('Natural', 'JJ'), ('language', 'NN'), ('understanding', 'VBG'), ('another', 'DT'), ('area', 'NN'), ('deep', 'RB'), ('learn-', 'JJ'), ('ing', 'NN'), ('poised', 'VBN'), ('make', 'VB'), ('large', 'JJ'), ('impact', 'NN'), ('next', 'JJ'), ('years', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['Natural language', 'another area', 'learn- ing', 'large impact', 'next years']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Natural', 'natur'), ('language', 'languag'), ('understanding', 'understand'), ('another', 'anoth'), ('area', 'area'), ('deep', 'deep'), ('learn-', 'learn-'), ('ing', 'ing'), ('poised', 'pois'), ('make', 'make'), ('large', 'larg'), ('impact', 'impact'), ('next', 'next'), ('years', 'year'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Natural', 'natur'), ('language', 'languag'), ('understanding', 'understand'), ('another', 'anoth'), ('area', 'area'), ('deep', 'deep'), ('learn-', 'learn-'), ('ing', 'ing'), ('poised', 'pois'), ('make', 'make'), ('large', 'larg'), ('impact', 'impact'), ('next', 'next'), ('years', 'year'), ('.', '.')]

>> Lemmatization: 
 [('Natural', 'Natural'), ('language', 'language'), ('understanding', 'understanding'), ('another', 'another'), ('area', 'area'), ('deep', 'deep'), ('learn-', 'learn-'), ('ing', 'ing'), ('poised', 'poised'), ('make', 'make'), ('large', 'large'), ('impact', 'impact'), ('next', 'next'), ('years', 'year'), ('.', '.')]


------------------- Sentence 2 -------------------

We expect  systems that use RNNs to understand sentences or whole documents  will become much better when they learn strategies for selectively  attending to one part at a time76,86.

>> Tokens are: 
 ['We', 'expect', 'systems', 'use', 'RNNs', 'understand', 'sentences', 'whole', 'documents', 'become', 'much', 'better', 'learn', 'strategies', 'selectively', 'attending', 'one', 'part', 'time76,86', '.']

>> Bigrams are: 
 [('We', 'expect'), ('expect', 'systems'), ('systems', 'use'), ('use', 'RNNs'), ('RNNs', 'understand'), ('understand', 'sentences'), ('sentences', 'whole'), ('whole', 'documents'), ('documents', 'become'), ('become', 'much'), ('much', 'better'), ('better', 'learn'), ('learn', 'strategies'), ('strategies', 'selectively'), ('selectively', 'attending'), ('attending', 'one'), ('one', 'part'), ('part', 'time76,86'), ('time76,86', '.')]

>> Trigrams are: 
 [('We', 'expect', 'systems'), ('expect', 'systems', 'use'), ('systems', 'use', 'RNNs'), ('use', 'RNNs', 'understand'), ('RNNs', 'understand', 'sentences'), ('understand', 'sentences', 'whole'), ('sentences', 'whole', 'documents'), ('whole', 'documents', 'become'), ('documents', 'become', 'much'), ('become', 'much', 'better'), ('much', 'better', 'learn'), ('better', 'learn', 'strategies'), ('learn', 'strategies', 'selectively'), ('strategies', 'selectively', 'attending'), ('selectively', 'attending', 'one'), ('attending', 'one', 'part'), ('one', 'part', 'time76,86'), ('part', 'time76,86', '.')]

>> POS Tags are: 
 [('We', 'PRP'), ('expect', 'VBP'), ('systems', 'NNS'), ('use', 'VBP'), ('RNNs', 'NNP'), ('understand', 'NN'), ('sentences', 'NNS'), ('whole', 'JJ'), ('documents', 'NNS'), ('become', 'VBP'), ('much', 'JJ'), ('better', 'JJR'), ('learn', 'NN'), ('strategies', 'NNS'), ('selectively', 'RB'), ('attending', 'VBG'), ('one', 'CD'), ('part', 'NN'), ('time76,86', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['systems', 'RNNs understand sentences', 'whole documents', 'learn strategies', 'part time76,86']

>> Named Entities are: 
 [('ORGANIZATION', 'RNNs')] 

>> Stemming using Porter Stemmer: 
 [('We', 'we'), ('expect', 'expect'), ('systems', 'system'), ('use', 'use'), ('RNNs', 'rnn'), ('understand', 'understand'), ('sentences', 'sentenc'), ('whole', 'whole'), ('documents', 'document'), ('become', 'becom'), ('much', 'much'), ('better', 'better'), ('learn', 'learn'), ('strategies', 'strategi'), ('selectively', 'select'), ('attending', 'attend'), ('one', 'one'), ('part', 'part'), ('time76,86', 'time76,86'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('We', 'we'), ('expect', 'expect'), ('systems', 'system'), ('use', 'use'), ('RNNs', 'rnns'), ('understand', 'understand'), ('sentences', 'sentenc'), ('whole', 'whole'), ('documents', 'document'), ('become', 'becom'), ('much', 'much'), ('better', 'better'), ('learn', 'learn'), ('strategies', 'strategi'), ('selectively', 'select'), ('attending', 'attend'), ('one', 'one'), ('part', 'part'), ('time76,86', 'time76,86'), ('.', '.')]

>> Lemmatization: 
 [('We', 'We'), ('expect', 'expect'), ('systems', 'system'), ('use', 'use'), ('RNNs', 'RNNs'), ('understand', 'understand'), ('sentences', 'sentence'), ('whole', 'whole'), ('documents', 'document'), ('become', 'become'), ('much', 'much'), ('better', 'better'), ('learn', 'learn'), ('strategies', 'strategy'), ('selectively', 'selectively'), ('attending', 'attending'), ('one', 'one'), ('part', 'part'), ('time76,86', 'time76,86'), ('.', '.')]



========================================== PARAGRAPH 226 ===========================================

Ultimately, major progress in artificial intelligence will come about  through systems that combine representation learning with complex  reasoning. Although deep learning and simple reasoning have been  used for speech and handwriting recognition for a long time, new  paradigms are needed to replace rule-based manipulation of symbolic  expressions by operations on large vectors101. ■ 

------------------- Sentence 1 -------------------

Ultimately, major progress in artificial intelligence will come about  through systems that combine representation learning with complex  reasoning.

>> Tokens are: 
 ['Ultimately', ',', 'major', 'progress', 'artificial', 'intelligence', 'come', 'systems', 'combine', 'representation', 'learning', 'complex', 'reasoning', '.']

>> Bigrams are: 
 [('Ultimately', ','), (',', 'major'), ('major', 'progress'), ('progress', 'artificial'), ('artificial', 'intelligence'), ('intelligence', 'come'), ('come', 'systems'), ('systems', 'combine'), ('combine', 'representation'), ('representation', 'learning'), ('learning', 'complex'), ('complex', 'reasoning'), ('reasoning', '.')]

>> Trigrams are: 
 [('Ultimately', ',', 'major'), (',', 'major', 'progress'), ('major', 'progress', 'artificial'), ('progress', 'artificial', 'intelligence'), ('artificial', 'intelligence', 'come'), ('intelligence', 'come', 'systems'), ('come', 'systems', 'combine'), ('systems', 'combine', 'representation'), ('combine', 'representation', 'learning'), ('representation', 'learning', 'complex'), ('learning', 'complex', 'reasoning'), ('complex', 'reasoning', '.')]

>> POS Tags are: 
 [('Ultimately', 'RB'), (',', ','), ('major', 'JJ'), ('progress', 'NN'), ('artificial', 'JJ'), ('intelligence', 'NN'), ('come', 'VBN'), ('systems', 'NNS'), ('combine', 'JJ'), ('representation', 'NN'), ('learning', 'VBG'), ('complex', 'JJ'), ('reasoning', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['major progress', 'artificial intelligence', 'systems', 'combine representation', 'complex reasoning']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Ultimately', 'ultim'), (',', ','), ('major', 'major'), ('progress', 'progress'), ('artificial', 'artifici'), ('intelligence', 'intellig'), ('come', 'come'), ('systems', 'system'), ('combine', 'combin'), ('representation', 'represent'), ('learning', 'learn'), ('complex', 'complex'), ('reasoning', 'reason'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Ultimately', 'ultim'), (',', ','), ('major', 'major'), ('progress', 'progress'), ('artificial', 'artifici'), ('intelligence', 'intellig'), ('come', 'come'), ('systems', 'system'), ('combine', 'combin'), ('representation', 'represent'), ('learning', 'learn'), ('complex', 'complex'), ('reasoning', 'reason'), ('.', '.')]

>> Lemmatization: 
 [('Ultimately', 'Ultimately'), (',', ','), ('major', 'major'), ('progress', 'progress'), ('artificial', 'artificial'), ('intelligence', 'intelligence'), ('come', 'come'), ('systems', 'system'), ('combine', 'combine'), ('representation', 'representation'), ('learning', 'learning'), ('complex', 'complex'), ('reasoning', 'reasoning'), ('.', '.')]


------------------- Sentence 2 -------------------

Although deep learning and simple reasoning have been  used for speech and handwriting recognition for a long time, new  paradigms are needed to replace rule-based manipulation of symbolic  expressions by operations on large vectors101.

>> Tokens are: 
 ['Although', 'deep', 'learning', 'simple', 'reasoning', 'used', 'speech', 'handwriting', 'recognition', 'long', 'time', ',', 'new', 'paradigms', 'needed', 'replace', 'rule-based', 'manipulation', 'symbolic', 'expressions', 'operations', 'large', 'vectors101', '.']

>> Bigrams are: 
 [('Although', 'deep'), ('deep', 'learning'), ('learning', 'simple'), ('simple', 'reasoning'), ('reasoning', 'used'), ('used', 'speech'), ('speech', 'handwriting'), ('handwriting', 'recognition'), ('recognition', 'long'), ('long', 'time'), ('time', ','), (',', 'new'), ('new', 'paradigms'), ('paradigms', 'needed'), ('needed', 'replace'), ('replace', 'rule-based'), ('rule-based', 'manipulation'), ('manipulation', 'symbolic'), ('symbolic', 'expressions'), ('expressions', 'operations'), ('operations', 'large'), ('large', 'vectors101'), ('vectors101', '.')]

>> Trigrams are: 
 [('Although', 'deep', 'learning'), ('deep', 'learning', 'simple'), ('learning', 'simple', 'reasoning'), ('simple', 'reasoning', 'used'), ('reasoning', 'used', 'speech'), ('used', 'speech', 'handwriting'), ('speech', 'handwriting', 'recognition'), ('handwriting', 'recognition', 'long'), ('recognition', 'long', 'time'), ('long', 'time', ','), ('time', ',', 'new'), (',', 'new', 'paradigms'), ('new', 'paradigms', 'needed'), ('paradigms', 'needed', 'replace'), ('needed', 'replace', 'rule-based'), ('replace', 'rule-based', 'manipulation'), ('rule-based', 'manipulation', 'symbolic'), ('manipulation', 'symbolic', 'expressions'), ('symbolic', 'expressions', 'operations'), ('expressions', 'operations', 'large'), ('operations', 'large', 'vectors101'), ('large', 'vectors101', '.')]

>> POS Tags are: 
 [('Although', 'IN'), ('deep', 'JJ'), ('learning', 'VBG'), ('simple', 'JJ'), ('reasoning', 'NN'), ('used', 'VBN'), ('speech', 'NN'), ('handwriting', 'VBG'), ('recognition', 'NN'), ('long', 'JJ'), ('time', 'NN'), (',', ','), ('new', 'JJ'), ('paradigms', 'NN'), ('needed', 'VBN'), ('replace', 'VB'), ('rule-based', 'JJ'), ('manipulation', 'NN'), ('symbolic', 'JJ'), ('expressions', 'NNS'), ('operations', 'NNS'), ('large', 'JJ'), ('vectors101', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['simple reasoning', 'speech', 'recognition', 'long time', 'new paradigms', 'rule-based manipulation', 'symbolic expressions operations', 'large vectors101']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Although', 'although'), ('deep', 'deep'), ('learning', 'learn'), ('simple', 'simpl'), ('reasoning', 'reason'), ('used', 'use'), ('speech', 'speech'), ('handwriting', 'handwrit'), ('recognition', 'recognit'), ('long', 'long'), ('time', 'time'), (',', ','), ('new', 'new'), ('paradigms', 'paradigm'), ('needed', 'need'), ('replace', 'replac'), ('rule-based', 'rule-bas'), ('manipulation', 'manipul'), ('symbolic', 'symbol'), ('expressions', 'express'), ('operations', 'oper'), ('large', 'larg'), ('vectors101', 'vectors101'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Although', 'although'), ('deep', 'deep'), ('learning', 'learn'), ('simple', 'simpl'), ('reasoning', 'reason'), ('used', 'use'), ('speech', 'speech'), ('handwriting', 'handwrit'), ('recognition', 'recognit'), ('long', 'long'), ('time', 'time'), (',', ','), ('new', 'new'), ('paradigms', 'paradigm'), ('needed', 'need'), ('replace', 'replac'), ('rule-based', 'rule-bas'), ('manipulation', 'manipul'), ('symbolic', 'symbol'), ('expressions', 'express'), ('operations', 'oper'), ('large', 'larg'), ('vectors101', 'vectors101'), ('.', '.')]

>> Lemmatization: 
 [('Although', 'Although'), ('deep', 'deep'), ('learning', 'learning'), ('simple', 'simple'), ('reasoning', 'reasoning'), ('used', 'used'), ('speech', 'speech'), ('handwriting', 'handwriting'), ('recognition', 'recognition'), ('long', 'long'), ('time', 'time'), (',', ','), ('new', 'new'), ('paradigms', 'paradigm'), ('needed', 'needed'), ('replace', 'replace'), ('rule-based', 'rule-based'), ('manipulation', 'manipulation'), ('symbolic', 'symbolic'), ('expressions', 'expression'), ('operations', 'operation'), ('large', 'large'), ('vectors101', 'vectors101'), ('.', '.')]


------------------- Sentence 3 -------------------

■

>> Tokens are: 
 ['■']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('■', 'NN')]

>> Noun Phrases are: 
 ['■']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('■', '■')]

>> Stemming using Snowball Stemmer: 
 [('■', '■')]

>> Lemmatization: 
 [('■', '■')]



========================================== PARAGRAPH 227 ===========================================

Received 25 February; accepted 1 May 2015. 

------------------- Sentence 1 -------------------

Received 25 February; accepted 1 May 2015.

>> Tokens are: 
 ['Received', '25', 'February', ';', 'accepted', '1', 'May', '2015', '.']

>> Bigrams are: 
 [('Received', '25'), ('25', 'February'), ('February', ';'), (';', 'accepted'), ('accepted', '1'), ('1', 'May'), ('May', '2015'), ('2015', '.')]

>> Trigrams are: 
 [('Received', '25', 'February'), ('25', 'February', ';'), ('February', ';', 'accepted'), (';', 'accepted', '1'), ('accepted', '1', 'May'), ('1', 'May', '2015'), ('May', '2015', '.')]

>> POS Tags are: 
 [('Received', 'VBN'), ('25', 'CD'), ('February', 'NNP'), (';', ':'), ('accepted', 'VBD'), ('1', 'CD'), ('May', 'NNP'), ('2015', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 ['February', 'May']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Received', 'receiv'), ('25', '25'), ('February', 'februari'), (';', ';'), ('accepted', 'accept'), ('1', '1'), ('May', 'may'), ('2015', '2015'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Received', 'receiv'), ('25', '25'), ('February', 'februari'), (';', ';'), ('accepted', 'accept'), ('1', '1'), ('May', 'may'), ('2015', '2015'), ('.', '.')]

>> Lemmatization: 
 [('Received', 'Received'), ('25', '25'), ('February', 'February'), (';', ';'), ('accepted', 'accepted'), ('1', '1'), ('May', 'May'), ('2015', '2015'), ('.', '.')]



========================================== PARAGRAPH 228 ===========================================

1. Krizhevsky, A., Sutskever, I. & Hinton, G. ImageNet classification with deep  convolutional neural networks. In Proc. Advances in Neural Information  Processing Systems 25 1090–1098 (2012). 

------------------- Sentence 1 -------------------

1.

>> Tokens are: 
 ['1', '.']

>> Bigrams are: 
 [('1', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('1', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('1', '1'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('1', '1'), ('.', '.')]

>> Lemmatization: 
 [('1', '1'), ('.', '.')]


------------------- Sentence 2 -------------------

Krizhevsky, A., Sutskever, I.

>> Tokens are: 
 ['Krizhevsky', ',', 'A.', ',', 'Sutskever', ',', 'I', '.']

>> Bigrams are: 
 [('Krizhevsky', ','), (',', 'A.'), ('A.', ','), (',', 'Sutskever'), ('Sutskever', ','), (',', 'I'), ('I', '.')]

>> Trigrams are: 
 [('Krizhevsky', ',', 'A.'), (',', 'A.', ','), ('A.', ',', 'Sutskever'), (',', 'Sutskever', ','), ('Sutskever', ',', 'I'), (',', 'I', '.')]

>> POS Tags are: 
 [('Krizhevsky', 'NNP'), (',', ','), ('A.', 'NNP'), (',', ','), ('Sutskever', 'NNP'), (',', ','), ('I', 'PRP'), ('.', '.')]

>> Noun Phrases are: 
 ['Krizhevsky', 'A.', 'Sutskever']

>> Named Entities are: 
 [('GPE', 'Krizhevsky'), ('GPE', 'Sutskever')] 

>> Stemming using Porter Stemmer: 
 [('Krizhevsky', 'krizhevski'), (',', ','), ('A.', 'a.'), (',', ','), ('Sutskever', 'sutskev'), (',', ','), ('I', 'i'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Krizhevsky', 'krizhevski'), (',', ','), ('A.', 'a.'), (',', ','), ('Sutskever', 'sutskev'), (',', ','), ('I', 'i'), ('.', '.')]

>> Lemmatization: 
 [('Krizhevsky', 'Krizhevsky'), (',', ','), ('A.', 'A.'), (',', ','), ('Sutskever', 'Sutskever'), (',', ','), ('I', 'I'), ('.', '.')]


------------------- Sentence 3 -------------------

& Hinton, G. ImageNet classification with deep  convolutional neural networks.

>> Tokens are: 
 ['&', 'Hinton', ',', 'G.', 'ImageNet', 'classification', 'deep', 'convolutional', 'neural', 'networks', '.']

>> Bigrams are: 
 [('&', 'Hinton'), ('Hinton', ','), (',', 'G.'), ('G.', 'ImageNet'), ('ImageNet', 'classification'), ('classification', 'deep'), ('deep', 'convolutional'), ('convolutional', 'neural'), ('neural', 'networks'), ('networks', '.')]

>> Trigrams are: 
 [('&', 'Hinton', ','), ('Hinton', ',', 'G.'), (',', 'G.', 'ImageNet'), ('G.', 'ImageNet', 'classification'), ('ImageNet', 'classification', 'deep'), ('classification', 'deep', 'convolutional'), ('deep', 'convolutional', 'neural'), ('convolutional', 'neural', 'networks'), ('neural', 'networks', '.')]

>> POS Tags are: 
 [('&', 'CC'), ('Hinton', 'NNP'), (',', ','), ('G.', 'NNP'), ('ImageNet', 'NNP'), ('classification', 'NN'), ('deep', 'JJ'), ('convolutional', 'JJ'), ('neural', 'JJ'), ('networks', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['Hinton', 'G. ImageNet classification', 'deep convolutional neural networks']

>> Named Entities are: 
 [('GPE', 'Hinton')] 

>> Stemming using Porter Stemmer: 
 [('&', '&'), ('Hinton', 'hinton'), (',', ','), ('G.', 'g.'), ('ImageNet', 'imagenet'), ('classification', 'classif'), ('deep', 'deep'), ('convolutional', 'convolut'), ('neural', 'neural'), ('networks', 'network'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('&', '&'), ('Hinton', 'hinton'), (',', ','), ('G.', 'g.'), ('ImageNet', 'imagenet'), ('classification', 'classif'), ('deep', 'deep'), ('convolutional', 'convolut'), ('neural', 'neural'), ('networks', 'network'), ('.', '.')]

>> Lemmatization: 
 [('&', '&'), ('Hinton', 'Hinton'), (',', ','), ('G.', 'G.'), ('ImageNet', 'ImageNet'), ('classification', 'classification'), ('deep', 'deep'), ('convolutional', 'convolutional'), ('neural', 'neural'), ('networks', 'network'), ('.', '.')]


------------------- Sentence 4 -------------------

In Proc.

>> Tokens are: 
 ['In', 'Proc', '.']

>> Bigrams are: 
 [('In', 'Proc'), ('Proc', '.')]

>> Trigrams are: 
 [('In', 'Proc', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('Proc', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Proc']

>> Named Entities are: 
 [('GPE', 'Proc')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('Proc', 'proc'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('Proc', 'proc'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('Proc', 'Proc'), ('.', '.')]


------------------- Sentence 5 -------------------

Advances in Neural Information  Processing Systems 25 1090–1098 (2012).

>> Tokens are: 
 ['Advances', 'Neural', 'Information', 'Processing', 'Systems', '25', '1090–1098', '(', '2012', ')', '.']

>> Bigrams are: 
 [('Advances', 'Neural'), ('Neural', 'Information'), ('Information', 'Processing'), ('Processing', 'Systems'), ('Systems', '25'), ('25', '1090–1098'), ('1090–1098', '('), ('(', '2012'), ('2012', ')'), (')', '.')]

>> Trigrams are: 
 [('Advances', 'Neural', 'Information'), ('Neural', 'Information', 'Processing'), ('Information', 'Processing', 'Systems'), ('Processing', 'Systems', '25'), ('Systems', '25', '1090–1098'), ('25', '1090–1098', '('), ('1090–1098', '(', '2012'), ('(', '2012', ')'), ('2012', ')', '.')]

>> POS Tags are: 
 [('Advances', 'NNS'), ('Neural', 'NNP'), ('Information', 'NNP'), ('Processing', 'NNP'), ('Systems', 'NNPS'), ('25', 'CD'), ('1090–1098', 'CD'), ('(', '('), ('2012', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['Advances Neural Information Processing']

>> Named Entities are: 
 [('ORGANIZATION', 'Neural Information Processing Systems')] 

>> Stemming using Porter Stemmer: 
 [('Advances', 'advanc'), ('Neural', 'neural'), ('Information', 'inform'), ('Processing', 'process'), ('Systems', 'system'), ('25', '25'), ('1090–1098', '1090–1098'), ('(', '('), ('2012', '2012'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Advances', 'advanc'), ('Neural', 'neural'), ('Information', 'inform'), ('Processing', 'process'), ('Systems', 'system'), ('25', '25'), ('1090–1098', '1090–1098'), ('(', '('), ('2012', '2012'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Advances', 'Advances'), ('Neural', 'Neural'), ('Information', 'Information'), ('Processing', 'Processing'), ('Systems', 'Systems'), ('25', '25'), ('1090–1098', '1090–1098'), ('(', '('), ('2012', '2012'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 229 ===========================================

 This report was a breakthrough that used convolutional nets to almost halve  the error rate for object recognition, and precipitated the rapid adoption of  deep learning by the computer vision community. 

------------------- Sentence 1 -------------------

 This report was a breakthrough that used convolutional nets to almost halve  the error rate for object recognition, and precipitated the rapid adoption of  deep learning by the computer vision community.

>> Tokens are: 
 ['This', 'report', 'breakthrough', 'used', 'convolutional', 'nets', 'almost', 'halve', 'error', 'rate', 'object', 'recognition', ',', 'precipitated', 'rapid', 'adoption', 'deep', 'learning', 'computer', 'vision', 'community', '.']

>> Bigrams are: 
 [('This', 'report'), ('report', 'breakthrough'), ('breakthrough', 'used'), ('used', 'convolutional'), ('convolutional', 'nets'), ('nets', 'almost'), ('almost', 'halve'), ('halve', 'error'), ('error', 'rate'), ('rate', 'object'), ('object', 'recognition'), ('recognition', ','), (',', 'precipitated'), ('precipitated', 'rapid'), ('rapid', 'adoption'), ('adoption', 'deep'), ('deep', 'learning'), ('learning', 'computer'), ('computer', 'vision'), ('vision', 'community'), ('community', '.')]

>> Trigrams are: 
 [('This', 'report', 'breakthrough'), ('report', 'breakthrough', 'used'), ('breakthrough', 'used', 'convolutional'), ('used', 'convolutional', 'nets'), ('convolutional', 'nets', 'almost'), ('nets', 'almost', 'halve'), ('almost', 'halve', 'error'), ('halve', 'error', 'rate'), ('error', 'rate', 'object'), ('rate', 'object', 'recognition'), ('object', 'recognition', ','), ('recognition', ',', 'precipitated'), (',', 'precipitated', 'rapid'), ('precipitated', 'rapid', 'adoption'), ('rapid', 'adoption', 'deep'), ('adoption', 'deep', 'learning'), ('deep', 'learning', 'computer'), ('learning', 'computer', 'vision'), ('computer', 'vision', 'community'), ('vision', 'community', '.')]

>> POS Tags are: 
 [('This', 'DT'), ('report', 'NN'), ('breakthrough', 'IN'), ('used', 'VBN'), ('convolutional', 'JJ'), ('nets', 'NNS'), ('almost', 'RB'), ('halve', 'VBP'), ('error', 'NN'), ('rate', 'NN'), ('object', 'JJ'), ('recognition', 'NN'), (',', ','), ('precipitated', 'VBD'), ('rapid', 'JJ'), ('adoption', 'NN'), ('deep', 'RB'), ('learning', 'VBG'), ('computer', 'NN'), ('vision', 'NN'), ('community', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['This report', 'convolutional nets', 'error rate', 'object recognition', 'rapid adoption', 'computer vision community']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('This', 'thi'), ('report', 'report'), ('breakthrough', 'breakthrough'), ('used', 'use'), ('convolutional', 'convolut'), ('nets', 'net'), ('almost', 'almost'), ('halve', 'halv'), ('error', 'error'), ('rate', 'rate'), ('object', 'object'), ('recognition', 'recognit'), (',', ','), ('precipitated', 'precipit'), ('rapid', 'rapid'), ('adoption', 'adopt'), ('deep', 'deep'), ('learning', 'learn'), ('computer', 'comput'), ('vision', 'vision'), ('community', 'commun'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('This', 'this'), ('report', 'report'), ('breakthrough', 'breakthrough'), ('used', 'use'), ('convolutional', 'convolut'), ('nets', 'net'), ('almost', 'almost'), ('halve', 'halv'), ('error', 'error'), ('rate', 'rate'), ('object', 'object'), ('recognition', 'recognit'), (',', ','), ('precipitated', 'precipit'), ('rapid', 'rapid'), ('adoption', 'adopt'), ('deep', 'deep'), ('learning', 'learn'), ('computer', 'comput'), ('vision', 'vision'), ('community', 'communiti'), ('.', '.')]

>> Lemmatization: 
 [('This', 'This'), ('report', 'report'), ('breakthrough', 'breakthrough'), ('used', 'used'), ('convolutional', 'convolutional'), ('nets', 'net'), ('almost', 'almost'), ('halve', 'halve'), ('error', 'error'), ('rate', 'rate'), ('object', 'object'), ('recognition', 'recognition'), (',', ','), ('precipitated', 'precipitated'), ('rapid', 'rapid'), ('adoption', 'adoption'), ('deep', 'deep'), ('learning', 'learning'), ('computer', 'computer'), ('vision', 'vision'), ('community', 'community'), ('.', '.')]



========================================== PARAGRAPH 230 ===========================================

2. Farabet, C., Couprie, C., Najman, L. & LeCun, Y. Learning hierarchical features for  scene labeling. IEEE Trans. Pattern Anal. Mach. Intell. 35, 1915–1929 (2013).  

------------------- Sentence 1 -------------------

2.

>> Tokens are: 
 ['2', '.']

>> Bigrams are: 
 [('2', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('2', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('2', '2'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('2', '2'), ('.', '.')]

>> Lemmatization: 
 [('2', '2'), ('.', '.')]


------------------- Sentence 2 -------------------

Farabet, C., Couprie, C., Najman, L. & LeCun, Y.

>> Tokens are: 
 ['Farabet', ',', 'C.', ',', 'Couprie', ',', 'C.', ',', 'Najman', ',', 'L.', '&', 'LeCun', ',', 'Y', '.']

>> Bigrams are: 
 [('Farabet', ','), (',', 'C.'), ('C.', ','), (',', 'Couprie'), ('Couprie', ','), (',', 'C.'), ('C.', ','), (',', 'Najman'), ('Najman', ','), (',', 'L.'), ('L.', '&'), ('&', 'LeCun'), ('LeCun', ','), (',', 'Y'), ('Y', '.')]

>> Trigrams are: 
 [('Farabet', ',', 'C.'), (',', 'C.', ','), ('C.', ',', 'Couprie'), (',', 'Couprie', ','), ('Couprie', ',', 'C.'), (',', 'C.', ','), ('C.', ',', 'Najman'), (',', 'Najman', ','), ('Najman', ',', 'L.'), (',', 'L.', '&'), ('L.', '&', 'LeCun'), ('&', 'LeCun', ','), ('LeCun', ',', 'Y'), (',', 'Y', '.')]

>> POS Tags are: 
 [('Farabet', 'NNP'), (',', ','), ('C.', 'NNP'), (',', ','), ('Couprie', 'NNP'), (',', ','), ('C.', 'NNP'), (',', ','), ('Najman', 'NNP'), (',', ','), ('L.', 'NNP'), ('&', 'CC'), ('LeCun', 'NNP'), (',', ','), ('Y', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Farabet', 'C.', 'Couprie', 'C.', 'Najman', 'L.', 'LeCun', 'Y']

>> Named Entities are: 
 [('GPE', 'Farabet'), ('PERSON', 'Couprie'), ('PERSON', 'Najman'), ('ORGANIZATION', 'LeCun')] 

>> Stemming using Porter Stemmer: 
 [('Farabet', 'farabet'), (',', ','), ('C.', 'c.'), (',', ','), ('Couprie', 'coupri'), (',', ','), ('C.', 'c.'), (',', ','), ('Najman', 'najman'), (',', ','), ('L.', 'l.'), ('&', '&'), ('LeCun', 'lecun'), (',', ','), ('Y', 'y'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Farabet', 'farabet'), (',', ','), ('C.', 'c.'), (',', ','), ('Couprie', 'coupri'), (',', ','), ('C.', 'c.'), (',', ','), ('Najman', 'najman'), (',', ','), ('L.', 'l.'), ('&', '&'), ('LeCun', 'lecun'), (',', ','), ('Y', 'y'), ('.', '.')]

>> Lemmatization: 
 [('Farabet', 'Farabet'), (',', ','), ('C.', 'C.'), (',', ','), ('Couprie', 'Couprie'), (',', ','), ('C.', 'C.'), (',', ','), ('Najman', 'Najman'), (',', ','), ('L.', 'L.'), ('&', '&'), ('LeCun', 'LeCun'), (',', ','), ('Y', 'Y'), ('.', '.')]


------------------- Sentence 3 -------------------

Learning hierarchical features for  scene labeling.

>> Tokens are: 
 ['Learning', 'hierarchical', 'features', 'scene', 'labeling', '.']

>> Bigrams are: 
 [('Learning', 'hierarchical'), ('hierarchical', 'features'), ('features', 'scene'), ('scene', 'labeling'), ('labeling', '.')]

>> Trigrams are: 
 [('Learning', 'hierarchical', 'features'), ('hierarchical', 'features', 'scene'), ('features', 'scene', 'labeling'), ('scene', 'labeling', '.')]

>> POS Tags are: 
 [('Learning', 'VBG'), ('hierarchical', 'JJ'), ('features', 'NNS'), ('scene', 'VBP'), ('labeling', 'VBG'), ('.', '.')]

>> Noun Phrases are: 
 ['hierarchical features']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Learning', 'learn'), ('hierarchical', 'hierarch'), ('features', 'featur'), ('scene', 'scene'), ('labeling', 'label'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Learning', 'learn'), ('hierarchical', 'hierarch'), ('features', 'featur'), ('scene', 'scene'), ('labeling', 'label'), ('.', '.')]

>> Lemmatization: 
 [('Learning', 'Learning'), ('hierarchical', 'hierarchical'), ('features', 'feature'), ('scene', 'scene'), ('labeling', 'labeling'), ('.', '.')]


------------------- Sentence 4 -------------------

IEEE Trans.

>> Tokens are: 
 ['IEEE', 'Trans', '.']

>> Bigrams are: 
 [('IEEE', 'Trans'), ('Trans', '.')]

>> Trigrams are: 
 [('IEEE', 'Trans', '.')]

>> POS Tags are: 
 [('IEEE', 'NNP'), ('Trans', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['IEEE Trans']

>> Named Entities are: 
 [('ORGANIZATION', 'IEEE Trans')] 

>> Stemming using Porter Stemmer: 
 [('IEEE', 'ieee'), ('Trans', 'tran'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('IEEE', 'ieee'), ('Trans', 'tran'), ('.', '.')]

>> Lemmatization: 
 [('IEEE', 'IEEE'), ('Trans', 'Trans'), ('.', '.')]


------------------- Sentence 5 -------------------

Pattern Anal.

>> Tokens are: 
 ['Pattern', 'Anal', '.']

>> Bigrams are: 
 [('Pattern', 'Anal'), ('Anal', '.')]

>> Trigrams are: 
 [('Pattern', 'Anal', '.')]

>> POS Tags are: 
 [('Pattern', 'NNP'), ('Anal', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Pattern Anal']

>> Named Entities are: 
 [('PERSON', 'Pattern'), ('ORGANIZATION', 'Anal')] 

>> Stemming using Porter Stemmer: 
 [('Pattern', 'pattern'), ('Anal', 'anal'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Pattern', 'pattern'), ('Anal', 'anal'), ('.', '.')]

>> Lemmatization: 
 [('Pattern', 'Pattern'), ('Anal', 'Anal'), ('.', '.')]


------------------- Sentence 6 -------------------

Mach.

>> Tokens are: 
 ['Mach', '.']

>> Bigrams are: 
 [('Mach', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Mach', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Mach']

>> Named Entities are: 
 [('GPE', 'Mach')] 

>> Stemming using Porter Stemmer: 
 [('Mach', 'mach'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Mach', 'mach'), ('.', '.')]

>> Lemmatization: 
 [('Mach', 'Mach'), ('.', '.')]


------------------- Sentence 7 -------------------

Intell.

>> Tokens are: 
 ['Intell', '.']

>> Bigrams are: 
 [('Intell', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Intell', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Intell']

>> Named Entities are: 
 [('GPE', 'Intell')] 

>> Stemming using Porter Stemmer: 
 [('Intell', 'intel'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Intell', 'intel'), ('.', '.')]

>> Lemmatization: 
 [('Intell', 'Intell'), ('.', '.')]


------------------- Sentence 8 -------------------

35, 1915–1929 (2013).

>> Tokens are: 
 ['35', ',', '1915–1929', '(', '2013', ')', '.']

>> Bigrams are: 
 [('35', ','), (',', '1915–1929'), ('1915–1929', '('), ('(', '2013'), ('2013', ')'), (')', '.')]

>> Trigrams are: 
 [('35', ',', '1915–1929'), (',', '1915–1929', '('), ('1915–1929', '(', '2013'), ('(', '2013', ')'), ('2013', ')', '.')]

>> POS Tags are: 
 [('35', 'CD'), (',', ','), ('1915–1929', 'CD'), ('(', '('), ('2013', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('35', '35'), (',', ','), ('1915–1929', '1915–1929'), ('(', '('), ('2013', '2013'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('35', '35'), (',', ','), ('1915–1929', '1915–1929'), ('(', '('), ('2013', '2013'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('35', '35'), (',', ','), ('1915–1929', '1915–1929'), ('(', '('), ('2013', '2013'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 231 ===========================================

3. Tompson, J., Jain, A., LeCun, Y. & Bregler, C. Joint training of a convolutional  network and a graphical model for human pose estimation. In Proc. Advances in  Neural Information Processing Systems 27 1799–1807 (2014).  

------------------- Sentence 1 -------------------

3.

>> Tokens are: 
 ['3', '.']

>> Bigrams are: 
 [('3', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('3', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('3', '3'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('3', '3'), ('.', '.')]

>> Lemmatization: 
 [('3', '3'), ('.', '.')]


------------------- Sentence 2 -------------------

Tompson, J., Jain, A., LeCun, Y.

>> Tokens are: 
 ['Tompson', ',', 'J.', ',', 'Jain', ',', 'A.', ',', 'LeCun', ',', 'Y', '.']

>> Bigrams are: 
 [('Tompson', ','), (',', 'J.'), ('J.', ','), (',', 'Jain'), ('Jain', ','), (',', 'A.'), ('A.', ','), (',', 'LeCun'), ('LeCun', ','), (',', 'Y'), ('Y', '.')]

>> Trigrams are: 
 [('Tompson', ',', 'J.'), (',', 'J.', ','), ('J.', ',', 'Jain'), (',', 'Jain', ','), ('Jain', ',', 'A.'), (',', 'A.', ','), ('A.', ',', 'LeCun'), (',', 'LeCun', ','), ('LeCun', ',', 'Y'), (',', 'Y', '.')]

>> POS Tags are: 
 [('Tompson', 'NNP'), (',', ','), ('J.', 'NNP'), (',', ','), ('Jain', 'NNP'), (',', ','), ('A.', 'NNP'), (',', ','), ('LeCun', 'NNP'), (',', ','), ('Y', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Tompson', 'J.', 'Jain', 'A.', 'LeCun', 'Y']

>> Named Entities are: 
 [('PERSON', 'Tompson'), ('GPE', 'Jain'), ('ORGANIZATION', 'LeCun')] 

>> Stemming using Porter Stemmer: 
 [('Tompson', 'tompson'), (',', ','), ('J.', 'j.'), (',', ','), ('Jain', 'jain'), (',', ','), ('A.', 'a.'), (',', ','), ('LeCun', 'lecun'), (',', ','), ('Y', 'y'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Tompson', 'tompson'), (',', ','), ('J.', 'j.'), (',', ','), ('Jain', 'jain'), (',', ','), ('A.', 'a.'), (',', ','), ('LeCun', 'lecun'), (',', ','), ('Y', 'y'), ('.', '.')]

>> Lemmatization: 
 [('Tompson', 'Tompson'), (',', ','), ('J.', 'J.'), (',', ','), ('Jain', 'Jain'), (',', ','), ('A.', 'A.'), (',', ','), ('LeCun', 'LeCun'), (',', ','), ('Y', 'Y'), ('.', '.')]


------------------- Sentence 3 -------------------

& Bregler, C. Joint training of a convolutional  network and a graphical model for human pose estimation.

>> Tokens are: 
 ['&', 'Bregler', ',', 'C.', 'Joint', 'training', 'convolutional', 'network', 'graphical', 'model', 'human', 'pose', 'estimation', '.']

>> Bigrams are: 
 [('&', 'Bregler'), ('Bregler', ','), (',', 'C.'), ('C.', 'Joint'), ('Joint', 'training'), ('training', 'convolutional'), ('convolutional', 'network'), ('network', 'graphical'), ('graphical', 'model'), ('model', 'human'), ('human', 'pose'), ('pose', 'estimation'), ('estimation', '.')]

>> Trigrams are: 
 [('&', 'Bregler', ','), ('Bregler', ',', 'C.'), (',', 'C.', 'Joint'), ('C.', 'Joint', 'training'), ('Joint', 'training', 'convolutional'), ('training', 'convolutional', 'network'), ('convolutional', 'network', 'graphical'), ('network', 'graphical', 'model'), ('graphical', 'model', 'human'), ('model', 'human', 'pose'), ('human', 'pose', 'estimation'), ('pose', 'estimation', '.')]

>> POS Tags are: 
 [('&', 'CC'), ('Bregler', 'NNP'), (',', ','), ('C.', 'NNP'), ('Joint', 'NNP'), ('training', 'VBG'), ('convolutional', 'JJ'), ('network', 'NN'), ('graphical', 'JJ'), ('model', 'NN'), ('human', 'JJ'), ('pose', 'JJ'), ('estimation', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Bregler', 'C. Joint', 'convolutional network', 'graphical model', 'human pose estimation']

>> Named Entities are: 
 [('PERSON', 'Bregler')] 

>> Stemming using Porter Stemmer: 
 [('&', '&'), ('Bregler', 'bregler'), (',', ','), ('C.', 'c.'), ('Joint', 'joint'), ('training', 'train'), ('convolutional', 'convolut'), ('network', 'network'), ('graphical', 'graphic'), ('model', 'model'), ('human', 'human'), ('pose', 'pose'), ('estimation', 'estim'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('&', '&'), ('Bregler', 'bregler'), (',', ','), ('C.', 'c.'), ('Joint', 'joint'), ('training', 'train'), ('convolutional', 'convolut'), ('network', 'network'), ('graphical', 'graphic'), ('model', 'model'), ('human', 'human'), ('pose', 'pose'), ('estimation', 'estim'), ('.', '.')]

>> Lemmatization: 
 [('&', '&'), ('Bregler', 'Bregler'), (',', ','), ('C.', 'C.'), ('Joint', 'Joint'), ('training', 'training'), ('convolutional', 'convolutional'), ('network', 'network'), ('graphical', 'graphical'), ('model', 'model'), ('human', 'human'), ('pose', 'pose'), ('estimation', 'estimation'), ('.', '.')]


------------------- Sentence 4 -------------------

In Proc.

>> Tokens are: 
 ['In', 'Proc', '.']

>> Bigrams are: 
 [('In', 'Proc'), ('Proc', '.')]

>> Trigrams are: 
 [('In', 'Proc', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('Proc', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Proc']

>> Named Entities are: 
 [('GPE', 'Proc')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('Proc', 'proc'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('Proc', 'proc'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('Proc', 'Proc'), ('.', '.')]


------------------- Sentence 5 -------------------

Advances in  Neural Information Processing Systems 27 1799–1807 (2014).

>> Tokens are: 
 ['Advances', 'Neural', 'Information', 'Processing', 'Systems', '27', '1799–1807', '(', '2014', ')', '.']

>> Bigrams are: 
 [('Advances', 'Neural'), ('Neural', 'Information'), ('Information', 'Processing'), ('Processing', 'Systems'), ('Systems', '27'), ('27', '1799–1807'), ('1799–1807', '('), ('(', '2014'), ('2014', ')'), (')', '.')]

>> Trigrams are: 
 [('Advances', 'Neural', 'Information'), ('Neural', 'Information', 'Processing'), ('Information', 'Processing', 'Systems'), ('Processing', 'Systems', '27'), ('Systems', '27', '1799–1807'), ('27', '1799–1807', '('), ('1799–1807', '(', '2014'), ('(', '2014', ')'), ('2014', ')', '.')]

>> POS Tags are: 
 [('Advances', 'NNS'), ('Neural', 'NNP'), ('Information', 'NNP'), ('Processing', 'NNP'), ('Systems', 'NNPS'), ('27', 'CD'), ('1799–1807', 'CD'), ('(', '('), ('2014', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['Advances Neural Information Processing']

>> Named Entities are: 
 [('ORGANIZATION', 'Neural Information Processing Systems')] 

>> Stemming using Porter Stemmer: 
 [('Advances', 'advanc'), ('Neural', 'neural'), ('Information', 'inform'), ('Processing', 'process'), ('Systems', 'system'), ('27', '27'), ('1799–1807', '1799–1807'), ('(', '('), ('2014', '2014'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Advances', 'advanc'), ('Neural', 'neural'), ('Information', 'inform'), ('Processing', 'process'), ('Systems', 'system'), ('27', '27'), ('1799–1807', '1799–1807'), ('(', '('), ('2014', '2014'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Advances', 'Advances'), ('Neural', 'Neural'), ('Information', 'Information'), ('Processing', 'Processing'), ('Systems', 'Systems'), ('27', '27'), ('1799–1807', '1799–1807'), ('(', '('), ('2014', '2014'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 232 ===========================================

4. Szegedy, C. et al. Going deeper with convolutions. Preprint at http://arxiv.org/ abs/1409.4842 (2014).  

------------------- Sentence 1 -------------------

4.

>> Tokens are: 
 ['4', '.']

>> Bigrams are: 
 [('4', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('4', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('4', '4'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('4', '4'), ('.', '.')]

>> Lemmatization: 
 [('4', '4'), ('.', '.')]


------------------- Sentence 2 -------------------

Szegedy, C. et al.

>> Tokens are: 
 ['Szegedy', ',', 'C.', 'et', 'al', '.']

>> Bigrams are: 
 [('Szegedy', ','), (',', 'C.'), ('C.', 'et'), ('et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('Szegedy', ',', 'C.'), (',', 'C.', 'et'), ('C.', 'et', 'al'), ('et', 'al', '.')]

>> POS Tags are: 
 [('Szegedy', 'NNP'), (',', ','), ('C.', 'NNP'), ('et', 'CC'), ('al', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Szegedy', 'C.', 'al']

>> Named Entities are: 
 [('GPE', 'Szegedy')] 

>> Stemming using Porter Stemmer: 
 [('Szegedy', 'szegedi'), (',', ','), ('C.', 'c.'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Szegedy', 'szegedi'), (',', ','), ('C.', 'c.'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('Szegedy', 'Szegedy'), (',', ','), ('C.', 'C.'), ('et', 'et'), ('al', 'al'), ('.', '.')]


------------------- Sentence 3 -------------------

Going deeper with convolutions.

>> Tokens are: 
 ['Going', 'deeper', 'convolutions', '.']

>> Bigrams are: 
 [('Going', 'deeper'), ('deeper', 'convolutions'), ('convolutions', '.')]

>> Trigrams are: 
 [('Going', 'deeper', 'convolutions'), ('deeper', 'convolutions', '.')]

>> POS Tags are: 
 [('Going', 'VBG'), ('deeper', 'JJ'), ('convolutions', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['deeper convolutions']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Going', 'go'), ('deeper', 'deeper'), ('convolutions', 'convolut'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Going', 'go'), ('deeper', 'deeper'), ('convolutions', 'convolut'), ('.', '.')]

>> Lemmatization: 
 [('Going', 'Going'), ('deeper', 'deeper'), ('convolutions', 'convolution'), ('.', '.')]


------------------- Sentence 4 -------------------

Preprint at http://arxiv.org/ abs/1409.4842 (2014).

>> Tokens are: 
 ['Preprint', 'http', ':', '//arxiv.org/', 'abs/1409.4842', '(', '2014', ')', '.']

>> Bigrams are: 
 [('Preprint', 'http'), ('http', ':'), (':', '//arxiv.org/'), ('//arxiv.org/', 'abs/1409.4842'), ('abs/1409.4842', '('), ('(', '2014'), ('2014', ')'), (')', '.')]

>> Trigrams are: 
 [('Preprint', 'http', ':'), ('http', ':', '//arxiv.org/'), (':', '//arxiv.org/', 'abs/1409.4842'), ('//arxiv.org/', 'abs/1409.4842', '('), ('abs/1409.4842', '(', '2014'), ('(', '2014', ')'), ('2014', ')', '.')]

>> POS Tags are: 
 [('Preprint', 'NN'), ('http', 'NN'), (':', ':'), ('//arxiv.org/', 'NN'), ('abs/1409.4842', 'NN'), ('(', '('), ('2014', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['Preprint http', '//arxiv.org/ abs/1409.4842']

>> Named Entities are: 
 [('GPE', 'Preprint')] 

>> Stemming using Porter Stemmer: 
 [('Preprint', 'preprint'), ('http', 'http'), (':', ':'), ('//arxiv.org/', '//arxiv.org/'), ('abs/1409.4842', 'abs/1409.4842'), ('(', '('), ('2014', '2014'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Preprint', 'preprint'), ('http', 'http'), (':', ':'), ('//arxiv.org/', '//arxiv.org/'), ('abs/1409.4842', 'abs/1409.4842'), ('(', '('), ('2014', '2014'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Preprint', 'Preprint'), ('http', 'http'), (':', ':'), ('//arxiv.org/', '//arxiv.org/'), ('abs/1409.4842', 'abs/1409.4842'), ('(', '('), ('2014', '2014'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 233 ===========================================

5. Mikolov, T., Deoras, A., Povey, D., Burget, L. & Cernocky, J. Strategies for training  large scale neural network language models. In Proc. Automatic Speech  Recognition and Understanding 196–201 (2011).  

------------------- Sentence 1 -------------------

5.

>> Tokens are: 
 ['5', '.']

>> Bigrams are: 
 [('5', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('5', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('5', '5'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('5', '5'), ('.', '.')]

>> Lemmatization: 
 [('5', '5'), ('.', '.')]


------------------- Sentence 2 -------------------

Mikolov, T., Deoras, A., Povey, D., Burget, L. & Cernocky, J.

>> Tokens are: 
 ['Mikolov', ',', 'T.', ',', 'Deoras', ',', 'A.', ',', 'Povey', ',', 'D.', ',', 'Burget', ',', 'L.', '&', 'Cernocky', ',', 'J', '.']

>> Bigrams are: 
 [('Mikolov', ','), (',', 'T.'), ('T.', ','), (',', 'Deoras'), ('Deoras', ','), (',', 'A.'), ('A.', ','), (',', 'Povey'), ('Povey', ','), (',', 'D.'), ('D.', ','), (',', 'Burget'), ('Burget', ','), (',', 'L.'), ('L.', '&'), ('&', 'Cernocky'), ('Cernocky', ','), (',', 'J'), ('J', '.')]

>> Trigrams are: 
 [('Mikolov', ',', 'T.'), (',', 'T.', ','), ('T.', ',', 'Deoras'), (',', 'Deoras', ','), ('Deoras', ',', 'A.'), (',', 'A.', ','), ('A.', ',', 'Povey'), (',', 'Povey', ','), ('Povey', ',', 'D.'), (',', 'D.', ','), ('D.', ',', 'Burget'), (',', 'Burget', ','), ('Burget', ',', 'L.'), (',', 'L.', '&'), ('L.', '&', 'Cernocky'), ('&', 'Cernocky', ','), ('Cernocky', ',', 'J'), (',', 'J', '.')]

>> POS Tags are: 
 [('Mikolov', 'NNP'), (',', ','), ('T.', 'NNP'), (',', ','), ('Deoras', 'NNP'), (',', ','), ('A.', 'NNP'), (',', ','), ('Povey', 'NNP'), (',', ','), ('D.', 'NNP'), (',', ','), ('Burget', 'NNP'), (',', ','), ('L.', 'NNP'), ('&', 'CC'), ('Cernocky', 'NNP'), (',', ','), ('J', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Mikolov', 'T.', 'Deoras', 'A.', 'Povey', 'D.', 'Burget', 'L.', 'Cernocky', 'J']

>> Named Entities are: 
 [('PERSON', 'Mikolov'), ('GPE', 'Deoras'), ('PERSON', 'Povey'), ('GPE', 'Burget'), ('GPE', 'Cernocky')] 

>> Stemming using Porter Stemmer: 
 [('Mikolov', 'mikolov'), (',', ','), ('T.', 't.'), (',', ','), ('Deoras', 'deora'), (',', ','), ('A.', 'a.'), (',', ','), ('Povey', 'povey'), (',', ','), ('D.', 'd.'), (',', ','), ('Burget', 'burget'), (',', ','), ('L.', 'l.'), ('&', '&'), ('Cernocky', 'cernocki'), (',', ','), ('J', 'j'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Mikolov', 'mikolov'), (',', ','), ('T.', 't.'), (',', ','), ('Deoras', 'deora'), (',', ','), ('A.', 'a.'), (',', ','), ('Povey', 'povey'), (',', ','), ('D.', 'd.'), (',', ','), ('Burget', 'burget'), (',', ','), ('L.', 'l.'), ('&', '&'), ('Cernocky', 'cernocki'), (',', ','), ('J', 'j'), ('.', '.')]

>> Lemmatization: 
 [('Mikolov', 'Mikolov'), (',', ','), ('T.', 'T.'), (',', ','), ('Deoras', 'Deoras'), (',', ','), ('A.', 'A.'), (',', ','), ('Povey', 'Povey'), (',', ','), ('D.', 'D.'), (',', ','), ('Burget', 'Burget'), (',', ','), ('L.', 'L.'), ('&', '&'), ('Cernocky', 'Cernocky'), (',', ','), ('J', 'J'), ('.', '.')]


------------------- Sentence 3 -------------------

Strategies for training  large scale neural network language models.

>> Tokens are: 
 ['Strategies', 'training', 'large', 'scale', 'neural', 'network', 'language', 'models', '.']

>> Bigrams are: 
 [('Strategies', 'training'), ('training', 'large'), ('large', 'scale'), ('scale', 'neural'), ('neural', 'network'), ('network', 'language'), ('language', 'models'), ('models', '.')]

>> Trigrams are: 
 [('Strategies', 'training', 'large'), ('training', 'large', 'scale'), ('large', 'scale', 'neural'), ('scale', 'neural', 'network'), ('neural', 'network', 'language'), ('network', 'language', 'models'), ('language', 'models', '.')]

>> POS Tags are: 
 [('Strategies', 'NNS'), ('training', 'VBG'), ('large', 'JJ'), ('scale', 'JJ'), ('neural', 'JJ'), ('network', 'NN'), ('language', 'NN'), ('models', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['Strategies', 'large scale neural network language models']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Strategies', 'strategi'), ('training', 'train'), ('large', 'larg'), ('scale', 'scale'), ('neural', 'neural'), ('network', 'network'), ('language', 'languag'), ('models', 'model'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Strategies', 'strategi'), ('training', 'train'), ('large', 'larg'), ('scale', 'scale'), ('neural', 'neural'), ('network', 'network'), ('language', 'languag'), ('models', 'model'), ('.', '.')]

>> Lemmatization: 
 [('Strategies', 'Strategies'), ('training', 'training'), ('large', 'large'), ('scale', 'scale'), ('neural', 'neural'), ('network', 'network'), ('language', 'language'), ('models', 'model'), ('.', '.')]


------------------- Sentence 4 -------------------

In Proc.

>> Tokens are: 
 ['In', 'Proc', '.']

>> Bigrams are: 
 [('In', 'Proc'), ('Proc', '.')]

>> Trigrams are: 
 [('In', 'Proc', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('Proc', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Proc']

>> Named Entities are: 
 [('GPE', 'Proc')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('Proc', 'proc'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('Proc', 'proc'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('Proc', 'Proc'), ('.', '.')]


------------------- Sentence 5 -------------------

Automatic Speech  Recognition and Understanding 196–201 (2011).

>> Tokens are: 
 ['Automatic', 'Speech', 'Recognition', 'Understanding', '196–201', '(', '2011', ')', '.']

>> Bigrams are: 
 [('Automatic', 'Speech'), ('Speech', 'Recognition'), ('Recognition', 'Understanding'), ('Understanding', '196–201'), ('196–201', '('), ('(', '2011'), ('2011', ')'), (')', '.')]

>> Trigrams are: 
 [('Automatic', 'Speech', 'Recognition'), ('Speech', 'Recognition', 'Understanding'), ('Recognition', 'Understanding', '196–201'), ('Understanding', '196–201', '('), ('196–201', '(', '2011'), ('(', '2011', ')'), ('2011', ')', '.')]

>> POS Tags are: 
 [('Automatic', 'NNP'), ('Speech', 'NNP'), ('Recognition', 'NNP'), ('Understanding', 'VBG'), ('196–201', 'CD'), ('(', '('), ('2011', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['Automatic Speech Recognition']

>> Named Entities are: 
 [('PERSON', 'Automatic'), ('PERSON', 'Speech')] 

>> Stemming using Porter Stemmer: 
 [('Automatic', 'automat'), ('Speech', 'speech'), ('Recognition', 'recognit'), ('Understanding', 'understand'), ('196–201', '196–201'), ('(', '('), ('2011', '2011'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Automatic', 'automat'), ('Speech', 'speech'), ('Recognition', 'recognit'), ('Understanding', 'understand'), ('196–201', '196–201'), ('(', '('), ('2011', '2011'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Automatic', 'Automatic'), ('Speech', 'Speech'), ('Recognition', 'Recognition'), ('Understanding', 'Understanding'), ('196–201', '196–201'), ('(', '('), ('2011', '2011'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 234 ===========================================

6. Hinton, G. et al. Deep neural networks for acoustic modeling in speech  recognition. IEEE Signal Processing Magazine 29, 82–97 (2012). 

------------------- Sentence 1 -------------------

6.

>> Tokens are: 
 ['6', '.']

>> Bigrams are: 
 [('6', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('6', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('6', '6'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('6', '6'), ('.', '.')]

>> Lemmatization: 
 [('6', '6'), ('.', '.')]


------------------- Sentence 2 -------------------

Hinton, G. et al.

>> Tokens are: 
 ['Hinton', ',', 'G.', 'et', 'al', '.']

>> Bigrams are: 
 [('Hinton', ','), (',', 'G.'), ('G.', 'et'), ('et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('Hinton', ',', 'G.'), (',', 'G.', 'et'), ('G.', 'et', 'al'), ('et', 'al', '.')]

>> POS Tags are: 
 [('Hinton', 'NNP'), (',', ','), ('G.', 'NNP'), ('et', 'CC'), ('al', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Hinton', 'G.', 'al']

>> Named Entities are: 
 [('GPE', 'Hinton')] 

>> Stemming using Porter Stemmer: 
 [('Hinton', 'hinton'), (',', ','), ('G.', 'g.'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Hinton', 'hinton'), (',', ','), ('G.', 'g.'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('Hinton', 'Hinton'), (',', ','), ('G.', 'G.'), ('et', 'et'), ('al', 'al'), ('.', '.')]


------------------- Sentence 3 -------------------

Deep neural networks for acoustic modeling in speech  recognition.

>> Tokens are: 
 ['Deep', 'neural', 'networks', 'acoustic', 'modeling', 'speech', 'recognition', '.']

>> Bigrams are: 
 [('Deep', 'neural'), ('neural', 'networks'), ('networks', 'acoustic'), ('acoustic', 'modeling'), ('modeling', 'speech'), ('speech', 'recognition'), ('recognition', '.')]

>> Trigrams are: 
 [('Deep', 'neural', 'networks'), ('neural', 'networks', 'acoustic'), ('networks', 'acoustic', 'modeling'), ('acoustic', 'modeling', 'speech'), ('modeling', 'speech', 'recognition'), ('speech', 'recognition', '.')]

>> POS Tags are: 
 [('Deep', 'JJ'), ('neural', 'JJ'), ('networks', 'NNS'), ('acoustic', 'JJ'), ('modeling', 'VBG'), ('speech', 'NN'), ('recognition', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Deep neural networks', 'speech recognition']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Deep', 'deep'), ('neural', 'neural'), ('networks', 'network'), ('acoustic', 'acoust'), ('modeling', 'model'), ('speech', 'speech'), ('recognition', 'recognit'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Deep', 'deep'), ('neural', 'neural'), ('networks', 'network'), ('acoustic', 'acoust'), ('modeling', 'model'), ('speech', 'speech'), ('recognition', 'recognit'), ('.', '.')]

>> Lemmatization: 
 [('Deep', 'Deep'), ('neural', 'neural'), ('networks', 'network'), ('acoustic', 'acoustic'), ('modeling', 'modeling'), ('speech', 'speech'), ('recognition', 'recognition'), ('.', '.')]


------------------- Sentence 4 -------------------

IEEE Signal Processing Magazine 29, 82–97 (2012).

>> Tokens are: 
 ['IEEE', 'Signal', 'Processing', 'Magazine', '29', ',', '82–97', '(', '2012', ')', '.']

>> Bigrams are: 
 [('IEEE', 'Signal'), ('Signal', 'Processing'), ('Processing', 'Magazine'), ('Magazine', '29'), ('29', ','), (',', '82–97'), ('82–97', '('), ('(', '2012'), ('2012', ')'), (')', '.')]

>> Trigrams are: 
 [('IEEE', 'Signal', 'Processing'), ('Signal', 'Processing', 'Magazine'), ('Processing', 'Magazine', '29'), ('Magazine', '29', ','), ('29', ',', '82–97'), (',', '82–97', '('), ('82–97', '(', '2012'), ('(', '2012', ')'), ('2012', ')', '.')]

>> POS Tags are: 
 [('IEEE', 'NNP'), ('Signal', 'NNP'), ('Processing', 'NNP'), ('Magazine', 'NNP'), ('29', 'CD'), (',', ','), ('82–97', 'CD'), ('(', '('), ('2012', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['IEEE Signal Processing Magazine']

>> Named Entities are: 
 [('ORGANIZATION', 'IEEE Signal')] 

>> Stemming using Porter Stemmer: 
 [('IEEE', 'ieee'), ('Signal', 'signal'), ('Processing', 'process'), ('Magazine', 'magazin'), ('29', '29'), (',', ','), ('82–97', '82–97'), ('(', '('), ('2012', '2012'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('IEEE', 'ieee'), ('Signal', 'signal'), ('Processing', 'process'), ('Magazine', 'magazin'), ('29', '29'), (',', ','), ('82–97', '82–97'), ('(', '('), ('2012', '2012'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('IEEE', 'IEEE'), ('Signal', 'Signal'), ('Processing', 'Processing'), ('Magazine', 'Magazine'), ('29', '29'), (',', ','), ('82–97', '82–97'), ('(', '('), ('2012', '2012'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 235 ===========================================

 This joint paper from the major speech recognition laboratories, summarizing  the breakthrough achieved with deep learning on the task of phonetic  classification for automatic speech recognition, was the first major industrial  application of deep learning. 

------------------- Sentence 1 -------------------

 This joint paper from the major speech recognition laboratories, summarizing  the breakthrough achieved with deep learning on the task of phonetic  classification for automatic speech recognition, was the first major industrial  application of deep learning.

>> Tokens are: 
 ['This', 'joint', 'paper', 'major', 'speech', 'recognition', 'laboratories', ',', 'summarizing', 'breakthrough', 'achieved', 'deep', 'learning', 'task', 'phonetic', 'classification', 'automatic', 'speech', 'recognition', ',', 'first', 'major', 'industrial', 'application', 'deep', 'learning', '.']

>> Bigrams are: 
 [('This', 'joint'), ('joint', 'paper'), ('paper', 'major'), ('major', 'speech'), ('speech', 'recognition'), ('recognition', 'laboratories'), ('laboratories', ','), (',', 'summarizing'), ('summarizing', 'breakthrough'), ('breakthrough', 'achieved'), ('achieved', 'deep'), ('deep', 'learning'), ('learning', 'task'), ('task', 'phonetic'), ('phonetic', 'classification'), ('classification', 'automatic'), ('automatic', 'speech'), ('speech', 'recognition'), ('recognition', ','), (',', 'first'), ('first', 'major'), ('major', 'industrial'), ('industrial', 'application'), ('application', 'deep'), ('deep', 'learning'), ('learning', '.')]

>> Trigrams are: 
 [('This', 'joint', 'paper'), ('joint', 'paper', 'major'), ('paper', 'major', 'speech'), ('major', 'speech', 'recognition'), ('speech', 'recognition', 'laboratories'), ('recognition', 'laboratories', ','), ('laboratories', ',', 'summarizing'), (',', 'summarizing', 'breakthrough'), ('summarizing', 'breakthrough', 'achieved'), ('breakthrough', 'achieved', 'deep'), ('achieved', 'deep', 'learning'), ('deep', 'learning', 'task'), ('learning', 'task', 'phonetic'), ('task', 'phonetic', 'classification'), ('phonetic', 'classification', 'automatic'), ('classification', 'automatic', 'speech'), ('automatic', 'speech', 'recognition'), ('speech', 'recognition', ','), ('recognition', ',', 'first'), (',', 'first', 'major'), ('first', 'major', 'industrial'), ('major', 'industrial', 'application'), ('industrial', 'application', 'deep'), ('application', 'deep', 'learning'), ('deep', 'learning', '.')]

>> POS Tags are: 
 [('This', 'DT'), ('joint', 'JJ'), ('paper', 'NN'), ('major', 'JJ'), ('speech', 'NN'), ('recognition', 'NN'), ('laboratories', 'NNS'), (',', ','), ('summarizing', 'VBG'), ('breakthrough', 'NN'), ('achieved', 'VBN'), ('deep', 'JJ'), ('learning', 'NN'), ('task', 'NN'), ('phonetic', 'JJ'), ('classification', 'NN'), ('automatic', 'JJ'), ('speech', 'NN'), ('recognition', 'NN'), (',', ','), ('first', 'RB'), ('major', 'JJ'), ('industrial', 'JJ'), ('application', 'NN'), ('deep', 'RB'), ('learning', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['This joint paper', 'major speech recognition laboratories', 'breakthrough', 'deep learning task', 'phonetic classification', 'automatic speech recognition', 'major industrial application', 'learning']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('This', 'thi'), ('joint', 'joint'), ('paper', 'paper'), ('major', 'major'), ('speech', 'speech'), ('recognition', 'recognit'), ('laboratories', 'laboratori'), (',', ','), ('summarizing', 'summar'), ('breakthrough', 'breakthrough'), ('achieved', 'achiev'), ('deep', 'deep'), ('learning', 'learn'), ('task', 'task'), ('phonetic', 'phonet'), ('classification', 'classif'), ('automatic', 'automat'), ('speech', 'speech'), ('recognition', 'recognit'), (',', ','), ('first', 'first'), ('major', 'major'), ('industrial', 'industri'), ('application', 'applic'), ('deep', 'deep'), ('learning', 'learn'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('This', 'this'), ('joint', 'joint'), ('paper', 'paper'), ('major', 'major'), ('speech', 'speech'), ('recognition', 'recognit'), ('laboratories', 'laboratori'), (',', ','), ('summarizing', 'summar'), ('breakthrough', 'breakthrough'), ('achieved', 'achiev'), ('deep', 'deep'), ('learning', 'learn'), ('task', 'task'), ('phonetic', 'phonet'), ('classification', 'classif'), ('automatic', 'automat'), ('speech', 'speech'), ('recognition', 'recognit'), (',', ','), ('first', 'first'), ('major', 'major'), ('industrial', 'industri'), ('application', 'applic'), ('deep', 'deep'), ('learning', 'learn'), ('.', '.')]

>> Lemmatization: 
 [('This', 'This'), ('joint', 'joint'), ('paper', 'paper'), ('major', 'major'), ('speech', 'speech'), ('recognition', 'recognition'), ('laboratories', 'laboratory'), (',', ','), ('summarizing', 'summarizing'), ('breakthrough', 'breakthrough'), ('achieved', 'achieved'), ('deep', 'deep'), ('learning', 'learning'), ('task', 'task'), ('phonetic', 'phonetic'), ('classification', 'classification'), ('automatic', 'automatic'), ('speech', 'speech'), ('recognition', 'recognition'), (',', ','), ('first', 'first'), ('major', 'major'), ('industrial', 'industrial'), ('application', 'application'), ('deep', 'deep'), ('learning', 'learning'), ('.', '.')]



========================================== PARAGRAPH 236 ===========================================

7. Sainath, T., Mohamed, A.-R., Kingsbury, B. & Ramabhadran, B. Deep  convolutional neural networks for LVCSR. In Proc. Acoustics, Speech and Signal  Processing 8614–8618 (2013).  

------------------- Sentence 1 -------------------

7.

>> Tokens are: 
 ['7', '.']

>> Bigrams are: 
 [('7', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('7', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('7', '7'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('7', '7'), ('.', '.')]

>> Lemmatization: 
 [('7', '7'), ('.', '.')]


------------------- Sentence 2 -------------------

Sainath, T., Mohamed, A.-R., Kingsbury, B.

>> Tokens are: 
 ['Sainath', ',', 'T.', ',', 'Mohamed', ',', 'A.-R.', ',', 'Kingsbury', ',', 'B', '.']

>> Bigrams are: 
 [('Sainath', ','), (',', 'T.'), ('T.', ','), (',', 'Mohamed'), ('Mohamed', ','), (',', 'A.-R.'), ('A.-R.', ','), (',', 'Kingsbury'), ('Kingsbury', ','), (',', 'B'), ('B', '.')]

>> Trigrams are: 
 [('Sainath', ',', 'T.'), (',', 'T.', ','), ('T.', ',', 'Mohamed'), (',', 'Mohamed', ','), ('Mohamed', ',', 'A.-R.'), (',', 'A.-R.', ','), ('A.-R.', ',', 'Kingsbury'), (',', 'Kingsbury', ','), ('Kingsbury', ',', 'B'), (',', 'B', '.')]

>> POS Tags are: 
 [('Sainath', 'NNP'), (',', ','), ('T.', 'NNP'), (',', ','), ('Mohamed', 'NNP'), (',', ','), ('A.-R.', 'NNP'), (',', ','), ('Kingsbury', 'NNP'), (',', ','), ('B', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Sainath', 'T.', 'Mohamed', 'A.-R.', 'Kingsbury', 'B']

>> Named Entities are: 
 [('GPE', 'Sainath'), ('PERSON', 'Mohamed'), ('PERSON', 'Kingsbury')] 

>> Stemming using Porter Stemmer: 
 [('Sainath', 'sainath'), (',', ','), ('T.', 't.'), (',', ','), ('Mohamed', 'moham'), (',', ','), ('A.-R.', 'a.-r.'), (',', ','), ('Kingsbury', 'kingsburi'), (',', ','), ('B', 'b'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Sainath', 'sainath'), (',', ','), ('T.', 't.'), (',', ','), ('Mohamed', 'moham'), (',', ','), ('A.-R.', 'a.-r.'), (',', ','), ('Kingsbury', 'kingsburi'), (',', ','), ('B', 'b'), ('.', '.')]

>> Lemmatization: 
 [('Sainath', 'Sainath'), (',', ','), ('T.', 'T.'), (',', ','), ('Mohamed', 'Mohamed'), (',', ','), ('A.-R.', 'A.-R.'), (',', ','), ('Kingsbury', 'Kingsbury'), (',', ','), ('B', 'B'), ('.', '.')]


------------------- Sentence 3 -------------------

& Ramabhadran, B.

>> Tokens are: 
 ['&', 'Ramabhadran', ',', 'B', '.']

>> Bigrams are: 
 [('&', 'Ramabhadran'), ('Ramabhadran', ','), (',', 'B'), ('B', '.')]

>> Trigrams are: 
 [('&', 'Ramabhadran', ','), ('Ramabhadran', ',', 'B'), (',', 'B', '.')]

>> POS Tags are: 
 [('&', 'CC'), ('Ramabhadran', 'NNP'), (',', ','), ('B', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Ramabhadran', 'B']

>> Named Entities are: 
 [('GPE', 'Ramabhadran')] 

>> Stemming using Porter Stemmer: 
 [('&', '&'), ('Ramabhadran', 'ramabhadran'), (',', ','), ('B', 'b'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('&', '&'), ('Ramabhadran', 'ramabhadran'), (',', ','), ('B', 'b'), ('.', '.')]

>> Lemmatization: 
 [('&', '&'), ('Ramabhadran', 'Ramabhadran'), (',', ','), ('B', 'B'), ('.', '.')]


------------------- Sentence 4 -------------------

Deep  convolutional neural networks for LVCSR.

>> Tokens are: 
 ['Deep', 'convolutional', 'neural', 'networks', 'LVCSR', '.']

>> Bigrams are: 
 [('Deep', 'convolutional'), ('convolutional', 'neural'), ('neural', 'networks'), ('networks', 'LVCSR'), ('LVCSR', '.')]

>> Trigrams are: 
 [('Deep', 'convolutional', 'neural'), ('convolutional', 'neural', 'networks'), ('neural', 'networks', 'LVCSR'), ('networks', 'LVCSR', '.')]

>> POS Tags are: 
 [('Deep', 'JJ'), ('convolutional', 'JJ'), ('neural', 'JJ'), ('networks', 'NNS'), ('LVCSR', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Deep convolutional neural networks LVCSR']

>> Named Entities are: 
 [('ORGANIZATION', 'LVCSR')] 

>> Stemming using Porter Stemmer: 
 [('Deep', 'deep'), ('convolutional', 'convolut'), ('neural', 'neural'), ('networks', 'network'), ('LVCSR', 'lvcsr'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Deep', 'deep'), ('convolutional', 'convolut'), ('neural', 'neural'), ('networks', 'network'), ('LVCSR', 'lvcsr'), ('.', '.')]

>> Lemmatization: 
 [('Deep', 'Deep'), ('convolutional', 'convolutional'), ('neural', 'neural'), ('networks', 'network'), ('LVCSR', 'LVCSR'), ('.', '.')]


------------------- Sentence 5 -------------------

In Proc.

>> Tokens are: 
 ['In', 'Proc', '.']

>> Bigrams are: 
 [('In', 'Proc'), ('Proc', '.')]

>> Trigrams are: 
 [('In', 'Proc', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('Proc', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Proc']

>> Named Entities are: 
 [('GPE', 'Proc')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('Proc', 'proc'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('Proc', 'proc'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('Proc', 'Proc'), ('.', '.')]


------------------- Sentence 6 -------------------

Acoustics, Speech and Signal  Processing 8614–8618 (2013).

>> Tokens are: 
 ['Acoustics', ',', 'Speech', 'Signal', 'Processing', '8614–8618', '(', '2013', ')', '.']

>> Bigrams are: 
 [('Acoustics', ','), (',', 'Speech'), ('Speech', 'Signal'), ('Signal', 'Processing'), ('Processing', '8614–8618'), ('8614–8618', '('), ('(', '2013'), ('2013', ')'), (')', '.')]

>> Trigrams are: 
 [('Acoustics', ',', 'Speech'), (',', 'Speech', 'Signal'), ('Speech', 'Signal', 'Processing'), ('Signal', 'Processing', '8614–8618'), ('Processing', '8614–8618', '('), ('8614–8618', '(', '2013'), ('(', '2013', ')'), ('2013', ')', '.')]

>> POS Tags are: 
 [('Acoustics', 'NNS'), (',', ','), ('Speech', 'NNP'), ('Signal', 'NNP'), ('Processing', 'NNP'), ('8614–8618', 'CD'), ('(', '('), ('2013', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['Acoustics', 'Speech Signal Processing']

>> Named Entities are: 
 [('PERSON', 'Speech Signal')] 

>> Stemming using Porter Stemmer: 
 [('Acoustics', 'acoust'), (',', ','), ('Speech', 'speech'), ('Signal', 'signal'), ('Processing', 'process'), ('8614–8618', '8614–8618'), ('(', '('), ('2013', '2013'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Acoustics', 'acoust'), (',', ','), ('Speech', 'speech'), ('Signal', 'signal'), ('Processing', 'process'), ('8614–8618', '8614–8618'), ('(', '('), ('2013', '2013'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Acoustics', 'Acoustics'), (',', ','), ('Speech', 'Speech'), ('Signal', 'Signal'), ('Processing', 'Processing'), ('8614–8618', '8614–8618'), ('(', '('), ('2013', '2013'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 237 ===========================================

8. Ma, J., Sheridan, R. P., Liaw, A., Dahl, G. E. & Svetnik, V. Deep neural nets as a  method for quantitative structure-activity relationships. J. Chem. Inf. Model. 55,  263–274 (2015).  

------------------- Sentence 1 -------------------

8.

>> Tokens are: 
 ['8', '.']

>> Bigrams are: 
 [('8', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('8', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('8', '8'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('8', '8'), ('.', '.')]

>> Lemmatization: 
 [('8', '8'), ('.', '.')]


------------------- Sentence 2 -------------------

Ma, J., Sheridan, R. P., Liaw, A., Dahl, G. E. & Svetnik, V. Deep neural nets as a  method for quantitative structure-activity relationships.

>> Tokens are: 
 ['Ma', ',', 'J.', ',', 'Sheridan', ',', 'R.', 'P.', ',', 'Liaw', ',', 'A.', ',', 'Dahl', ',', 'G.', 'E.', '&', 'Svetnik', ',', 'V.', 'Deep', 'neural', 'nets', 'method', 'quantitative', 'structure-activity', 'relationships', '.']

>> Bigrams are: 
 [('Ma', ','), (',', 'J.'), ('J.', ','), (',', 'Sheridan'), ('Sheridan', ','), (',', 'R.'), ('R.', 'P.'), ('P.', ','), (',', 'Liaw'), ('Liaw', ','), (',', 'A.'), ('A.', ','), (',', 'Dahl'), ('Dahl', ','), (',', 'G.'), ('G.', 'E.'), ('E.', '&'), ('&', 'Svetnik'), ('Svetnik', ','), (',', 'V.'), ('V.', 'Deep'), ('Deep', 'neural'), ('neural', 'nets'), ('nets', 'method'), ('method', 'quantitative'), ('quantitative', 'structure-activity'), ('structure-activity', 'relationships'), ('relationships', '.')]

>> Trigrams are: 
 [('Ma', ',', 'J.'), (',', 'J.', ','), ('J.', ',', 'Sheridan'), (',', 'Sheridan', ','), ('Sheridan', ',', 'R.'), (',', 'R.', 'P.'), ('R.', 'P.', ','), ('P.', ',', 'Liaw'), (',', 'Liaw', ','), ('Liaw', ',', 'A.'), (',', 'A.', ','), ('A.', ',', 'Dahl'), (',', 'Dahl', ','), ('Dahl', ',', 'G.'), (',', 'G.', 'E.'), ('G.', 'E.', '&'), ('E.', '&', 'Svetnik'), ('&', 'Svetnik', ','), ('Svetnik', ',', 'V.'), (',', 'V.', 'Deep'), ('V.', 'Deep', 'neural'), ('Deep', 'neural', 'nets'), ('neural', 'nets', 'method'), ('nets', 'method', 'quantitative'), ('method', 'quantitative', 'structure-activity'), ('quantitative', 'structure-activity', 'relationships'), ('structure-activity', 'relationships', '.')]

>> POS Tags are: 
 [('Ma', 'NNP'), (',', ','), ('J.', 'NNP'), (',', ','), ('Sheridan', 'NNP'), (',', ','), ('R.', 'NNP'), ('P.', 'NNP'), (',', ','), ('Liaw', 'NNP'), (',', ','), ('A.', 'NNP'), (',', ','), ('Dahl', 'NNP'), (',', ','), ('G.', 'NNP'), ('E.', 'NNP'), ('&', 'CC'), ('Svetnik', 'NNP'), (',', ','), ('V.', 'NNP'), ('Deep', 'NNP'), ('neural', 'JJ'), ('nets', 'NNS'), ('method', 'VBP'), ('quantitative', 'JJ'), ('structure-activity', 'JJ'), ('relationships', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['Ma', 'J.', 'Sheridan', 'R. P.', 'Liaw', 'A.', 'Dahl', 'G. E.', 'Svetnik', 'V. Deep', 'neural nets', 'quantitative structure-activity relationships']

>> Named Entities are: 
 [('GPE', 'Ma'), ('GPE', 'Sheridan'), ('PERSON', 'Liaw'), ('PERSON', 'Dahl'), ('PERSON', 'Svetnik')] 

>> Stemming using Porter Stemmer: 
 [('Ma', 'ma'), (',', ','), ('J.', 'j.'), (',', ','), ('Sheridan', 'sheridan'), (',', ','), ('R.', 'r.'), ('P.', 'p.'), (',', ','), ('Liaw', 'liaw'), (',', ','), ('A.', 'a.'), (',', ','), ('Dahl', 'dahl'), (',', ','), ('G.', 'g.'), ('E.', 'e.'), ('&', '&'), ('Svetnik', 'svetnik'), (',', ','), ('V.', 'v.'), ('Deep', 'deep'), ('neural', 'neural'), ('nets', 'net'), ('method', 'method'), ('quantitative', 'quantit'), ('structure-activity', 'structure-act'), ('relationships', 'relationship'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Ma', 'ma'), (',', ','), ('J.', 'j.'), (',', ','), ('Sheridan', 'sheridan'), (',', ','), ('R.', 'r.'), ('P.', 'p.'), (',', ','), ('Liaw', 'liaw'), (',', ','), ('A.', 'a.'), (',', ','), ('Dahl', 'dahl'), (',', ','), ('G.', 'g.'), ('E.', 'e.'), ('&', '&'), ('Svetnik', 'svetnik'), (',', ','), ('V.', 'v.'), ('Deep', 'deep'), ('neural', 'neural'), ('nets', 'net'), ('method', 'method'), ('quantitative', 'quantit'), ('structure-activity', 'structure-act'), ('relationships', 'relationship'), ('.', '.')]

>> Lemmatization: 
 [('Ma', 'Ma'), (',', ','), ('J.', 'J.'), (',', ','), ('Sheridan', 'Sheridan'), (',', ','), ('R.', 'R.'), ('P.', 'P.'), (',', ','), ('Liaw', 'Liaw'), (',', ','), ('A.', 'A.'), (',', ','), ('Dahl', 'Dahl'), (',', ','), ('G.', 'G.'), ('E.', 'E.'), ('&', '&'), ('Svetnik', 'Svetnik'), (',', ','), ('V.', 'V.'), ('Deep', 'Deep'), ('neural', 'neural'), ('nets', 'net'), ('method', 'method'), ('quantitative', 'quantitative'), ('structure-activity', 'structure-activity'), ('relationships', 'relationship'), ('.', '.')]


------------------- Sentence 3 -------------------

J. Chem.

>> Tokens are: 
 ['J.', 'Chem', '.']

>> Bigrams are: 
 [('J.', 'Chem'), ('Chem', '.')]

>> Trigrams are: 
 [('J.', 'Chem', '.')]

>> POS Tags are: 
 [('J.', 'NNP'), ('Chem', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['J. Chem']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('J.', 'j.'), ('Chem', 'chem'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('J.', 'j.'), ('Chem', 'chem'), ('.', '.')]

>> Lemmatization: 
 [('J.', 'J.'), ('Chem', 'Chem'), ('.', '.')]


------------------- Sentence 4 -------------------

Inf.

>> Tokens are: 
 ['Inf', '.']

>> Bigrams are: 
 [('Inf', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Inf', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Inf']

>> Named Entities are: 
 [('GPE', 'Inf')] 

>> Stemming using Porter Stemmer: 
 [('Inf', 'inf'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Inf', 'inf'), ('.', '.')]

>> Lemmatization: 
 [('Inf', 'Inf'), ('.', '.')]


------------------- Sentence 5 -------------------

Model.

>> Tokens are: 
 ['Model', '.']

>> Bigrams are: 
 [('Model', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Model', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Model']

>> Named Entities are: 
 [('GPE', 'Model')] 

>> Stemming using Porter Stemmer: 
 [('Model', 'model'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Model', 'model'), ('.', '.')]

>> Lemmatization: 
 [('Model', 'Model'), ('.', '.')]


------------------- Sentence 6 -------------------

55,  263–274 (2015).

>> Tokens are: 
 ['55', ',', '263–274', '(', '2015', ')', '.']

>> Bigrams are: 
 [('55', ','), (',', '263–274'), ('263–274', '('), ('(', '2015'), ('2015', ')'), (')', '.')]

>> Trigrams are: 
 [('55', ',', '263–274'), (',', '263–274', '('), ('263–274', '(', '2015'), ('(', '2015', ')'), ('2015', ')', '.')]

>> POS Tags are: 
 [('55', 'CD'), (',', ','), ('263–274', 'CD'), ('(', '('), ('2015', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('55', '55'), (',', ','), ('263–274', '263–274'), ('(', '('), ('2015', '2015'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('55', '55'), (',', ','), ('263–274', '263–274'), ('(', '('), ('2015', '2015'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('55', '55'), (',', ','), ('263–274', '263–274'), ('(', '('), ('2015', '2015'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 238 ===========================================

9. Ciodaro, T., Deva, D., de Seixas, J. & Damazio, D. Online particle detection with  neural networks based on topological calorimetry information. J. Phys. Conf.  Series 368, 012030 (2012).  

------------------- Sentence 1 -------------------

9.

>> Tokens are: 
 ['9', '.']

>> Bigrams are: 
 [('9', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('9', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('9', '9'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('9', '9'), ('.', '.')]

>> Lemmatization: 
 [('9', '9'), ('.', '.')]


------------------- Sentence 2 -------------------

Ciodaro, T., Deva, D., de Seixas, J.

>> Tokens are: 
 ['Ciodaro', ',', 'T.', ',', 'Deva', ',', 'D.', ',', 'de', 'Seixas', ',', 'J', '.']

>> Bigrams are: 
 [('Ciodaro', ','), (',', 'T.'), ('T.', ','), (',', 'Deva'), ('Deva', ','), (',', 'D.'), ('D.', ','), (',', 'de'), ('de', 'Seixas'), ('Seixas', ','), (',', 'J'), ('J', '.')]

>> Trigrams are: 
 [('Ciodaro', ',', 'T.'), (',', 'T.', ','), ('T.', ',', 'Deva'), (',', 'Deva', ','), ('Deva', ',', 'D.'), (',', 'D.', ','), ('D.', ',', 'de'), (',', 'de', 'Seixas'), ('de', 'Seixas', ','), ('Seixas', ',', 'J'), (',', 'J', '.')]

>> POS Tags are: 
 [('Ciodaro', 'NNP'), (',', ','), ('T.', 'NNP'), (',', ','), ('Deva', 'NNP'), (',', ','), ('D.', 'NNP'), (',', ','), ('de', 'NNP'), ('Seixas', 'NNP'), (',', ','), ('J', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Ciodaro', 'T.', 'Deva', 'D.', 'de Seixas', 'J']

>> Named Entities are: 
 [('GPE', 'Ciodaro'), ('GPE', 'Deva')] 

>> Stemming using Porter Stemmer: 
 [('Ciodaro', 'ciodaro'), (',', ','), ('T.', 't.'), (',', ','), ('Deva', 'deva'), (',', ','), ('D.', 'd.'), (',', ','), ('de', 'de'), ('Seixas', 'seixa'), (',', ','), ('J', 'j'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Ciodaro', 'ciodaro'), (',', ','), ('T.', 't.'), (',', ','), ('Deva', 'deva'), (',', ','), ('D.', 'd.'), (',', ','), ('de', 'de'), ('Seixas', 'seixa'), (',', ','), ('J', 'j'), ('.', '.')]

>> Lemmatization: 
 [('Ciodaro', 'Ciodaro'), (',', ','), ('T.', 'T.'), (',', ','), ('Deva', 'Deva'), (',', ','), ('D.', 'D.'), (',', ','), ('de', 'de'), ('Seixas', 'Seixas'), (',', ','), ('J', 'J'), ('.', '.')]


------------------- Sentence 3 -------------------

& Damazio, D. Online particle detection with  neural networks based on topological calorimetry information.

>> Tokens are: 
 ['&', 'Damazio', ',', 'D.', 'Online', 'particle', 'detection', 'neural', 'networks', 'based', 'topological', 'calorimetry', 'information', '.']

>> Bigrams are: 
 [('&', 'Damazio'), ('Damazio', ','), (',', 'D.'), ('D.', 'Online'), ('Online', 'particle'), ('particle', 'detection'), ('detection', 'neural'), ('neural', 'networks'), ('networks', 'based'), ('based', 'topological'), ('topological', 'calorimetry'), ('calorimetry', 'information'), ('information', '.')]

>> Trigrams are: 
 [('&', 'Damazio', ','), ('Damazio', ',', 'D.'), (',', 'D.', 'Online'), ('D.', 'Online', 'particle'), ('Online', 'particle', 'detection'), ('particle', 'detection', 'neural'), ('detection', 'neural', 'networks'), ('neural', 'networks', 'based'), ('networks', 'based', 'topological'), ('based', 'topological', 'calorimetry'), ('topological', 'calorimetry', 'information'), ('calorimetry', 'information', '.')]

>> POS Tags are: 
 [('&', 'CC'), ('Damazio', 'NNP'), (',', ','), ('D.', 'NNP'), ('Online', 'NNP'), ('particle', 'NN'), ('detection', 'NN'), ('neural', 'JJ'), ('networks', 'NNS'), ('based', 'VBN'), ('topological', 'JJ'), ('calorimetry', 'NN'), ('information', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Damazio', 'D. Online particle detection', 'neural networks', 'topological calorimetry information']

>> Named Entities are: 
 [('PERSON', 'Damazio')] 

>> Stemming using Porter Stemmer: 
 [('&', '&'), ('Damazio', 'damazio'), (',', ','), ('D.', 'd.'), ('Online', 'onlin'), ('particle', 'particl'), ('detection', 'detect'), ('neural', 'neural'), ('networks', 'network'), ('based', 'base'), ('topological', 'topolog'), ('calorimetry', 'calorimetri'), ('information', 'inform'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('&', '&'), ('Damazio', 'damazio'), (',', ','), ('D.', 'd.'), ('Online', 'onlin'), ('particle', 'particl'), ('detection', 'detect'), ('neural', 'neural'), ('networks', 'network'), ('based', 'base'), ('topological', 'topolog'), ('calorimetry', 'calorimetri'), ('information', 'inform'), ('.', '.')]

>> Lemmatization: 
 [('&', '&'), ('Damazio', 'Damazio'), (',', ','), ('D.', 'D.'), ('Online', 'Online'), ('particle', 'particle'), ('detection', 'detection'), ('neural', 'neural'), ('networks', 'network'), ('based', 'based'), ('topological', 'topological'), ('calorimetry', 'calorimetry'), ('information', 'information'), ('.', '.')]


------------------- Sentence 4 -------------------

J. Phys.

>> Tokens are: 
 ['J.', 'Phys', '.']

>> Bigrams are: 
 [('J.', 'Phys'), ('Phys', '.')]

>> Trigrams are: 
 [('J.', 'Phys', '.')]

>> POS Tags are: 
 [('J.', 'NNP'), ('Phys', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['J. Phys']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('J.', 'j.'), ('Phys', 'phi'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('J.', 'j.'), ('Phys', 'phys'), ('.', '.')]

>> Lemmatization: 
 [('J.', 'J.'), ('Phys', 'Phys'), ('.', '.')]


------------------- Sentence 5 -------------------

Conf.

>> Tokens are: 
 ['Conf', '.']

>> Bigrams are: 
 [('Conf', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Conf', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Conf']

>> Named Entities are: 
 [('GSP', 'Conf')] 

>> Stemming using Porter Stemmer: 
 [('Conf', 'conf'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Conf', 'conf'), ('.', '.')]

>> Lemmatization: 
 [('Conf', 'Conf'), ('.', '.')]


------------------- Sentence 6 -------------------

Series 368, 012030 (2012).

>> Tokens are: 
 ['Series', '368', ',', '012030', '(', '2012', ')', '.']

>> Bigrams are: 
 [('Series', '368'), ('368', ','), (',', '012030'), ('012030', '('), ('(', '2012'), ('2012', ')'), (')', '.')]

>> Trigrams are: 
 [('Series', '368', ','), ('368', ',', '012030'), (',', '012030', '('), ('012030', '(', '2012'), ('(', '2012', ')'), ('2012', ')', '.')]

>> POS Tags are: 
 [('Series', 'NNS'), ('368', 'CD'), (',', ','), ('012030', 'CD'), ('(', '('), ('2012', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['Series']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Series', 'seri'), ('368', '368'), (',', ','), ('012030', '012030'), ('(', '('), ('2012', '2012'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Series', 'seri'), ('368', '368'), (',', ','), ('012030', '012030'), ('(', '('), ('2012', '2012'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Series', 'Series'), ('368', '368'), (',', ','), ('012030', '012030'), ('(', '('), ('2012', '2012'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 239 ===========================================

10. Kaggle. Higgs boson machine learning challenge. Kaggle https://www.kaggle. com/c/higgs-boson (2014).  

------------------- Sentence 1 -------------------

10.

>> Tokens are: 
 ['10', '.']

>> Bigrams are: 
 [('10', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('10', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('10', '10'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('10', '10'), ('.', '.')]

>> Lemmatization: 
 [('10', '10'), ('.', '.')]


------------------- Sentence 2 -------------------

Kaggle.

>> Tokens are: 
 ['Kaggle', '.']

>> Bigrams are: 
 [('Kaggle', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Kaggle', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Kaggle']

>> Named Entities are: 
 [('GPE', 'Kaggle')] 

>> Stemming using Porter Stemmer: 
 [('Kaggle', 'kaggl'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Kaggle', 'kaggl'), ('.', '.')]

>> Lemmatization: 
 [('Kaggle', 'Kaggle'), ('.', '.')]


------------------- Sentence 3 -------------------

Higgs boson machine learning challenge.

>> Tokens are: 
 ['Higgs', 'boson', 'machine', 'learning', 'challenge', '.']

>> Bigrams are: 
 [('Higgs', 'boson'), ('boson', 'machine'), ('machine', 'learning'), ('learning', 'challenge'), ('challenge', '.')]

>> Trigrams are: 
 [('Higgs', 'boson', 'machine'), ('boson', 'machine', 'learning'), ('machine', 'learning', 'challenge'), ('learning', 'challenge', '.')]

>> POS Tags are: 
 [('Higgs', 'NNP'), ('boson', 'NN'), ('machine', 'NN'), ('learning', 'NN'), ('challenge', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Higgs boson machine learning challenge']

>> Named Entities are: 
 [('GPE', 'Higgs')] 

>> Stemming using Porter Stemmer: 
 [('Higgs', 'higg'), ('boson', 'boson'), ('machine', 'machin'), ('learning', 'learn'), ('challenge', 'challeng'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Higgs', 'higg'), ('boson', 'boson'), ('machine', 'machin'), ('learning', 'learn'), ('challenge', 'challeng'), ('.', '.')]

>> Lemmatization: 
 [('Higgs', 'Higgs'), ('boson', 'boson'), ('machine', 'machine'), ('learning', 'learning'), ('challenge', 'challenge'), ('.', '.')]


------------------- Sentence 4 -------------------

Kaggle https://www.kaggle.

>> Tokens are: 
 ['Kaggle', 'https', ':', '//www.kaggle', '.']

>> Bigrams are: 
 [('Kaggle', 'https'), ('https', ':'), (':', '//www.kaggle'), ('//www.kaggle', '.')]

>> Trigrams are: 
 [('Kaggle', 'https', ':'), ('https', ':', '//www.kaggle'), (':', '//www.kaggle', '.')]

>> POS Tags are: 
 [('Kaggle', 'NNP'), ('https', 'NN'), (':', ':'), ('//www.kaggle', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Kaggle https', '//www.kaggle']

>> Named Entities are: 
 [('GPE', 'Kaggle')] 

>> Stemming using Porter Stemmer: 
 [('Kaggle', 'kaggl'), ('https', 'http'), (':', ':'), ('//www.kaggle', '//www.kaggl'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Kaggle', 'kaggl'), ('https', 'https'), (':', ':'), ('//www.kaggle', '//www.kaggl'), ('.', '.')]

>> Lemmatization: 
 [('Kaggle', 'Kaggle'), ('https', 'http'), (':', ':'), ('//www.kaggle', '//www.kaggle'), ('.', '.')]


------------------- Sentence 5 -------------------

com/c/higgs-boson (2014).

>> Tokens are: 
 ['com/c/higgs-boson', '(', '2014', ')', '.']

>> Bigrams are: 
 [('com/c/higgs-boson', '('), ('(', '2014'), ('2014', ')'), (')', '.')]

>> Trigrams are: 
 [('com/c/higgs-boson', '(', '2014'), ('(', '2014', ')'), ('2014', ')', '.')]

>> POS Tags are: 
 [('com/c/higgs-boson', 'NN'), ('(', '('), ('2014', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['com/c/higgs-boson']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('com/c/higgs-boson', 'com/c/higgs-boson'), ('(', '('), ('2014', '2014'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('com/c/higgs-boson', 'com/c/higgs-boson'), ('(', '('), ('2014', '2014'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('com/c/higgs-boson', 'com/c/higgs-boson'), ('(', '('), ('2014', '2014'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 240 ===========================================

11. Helmstaedter, M. et al. Connectomic reconstruction of the inner plexiform layer  in the mouse retina. Nature 500, 168–174 (2013).  

------------------- Sentence 1 -------------------

11.

>> Tokens are: 
 ['11', '.']

>> Bigrams are: 
 [('11', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('11', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('11', '11'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('11', '11'), ('.', '.')]

>> Lemmatization: 
 [('11', '11'), ('.', '.')]


------------------- Sentence 2 -------------------

Helmstaedter, M. et al.

>> Tokens are: 
 ['Helmstaedter', ',', 'M.', 'et', 'al', '.']

>> Bigrams are: 
 [('Helmstaedter', ','), (',', 'M.'), ('M.', 'et'), ('et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('Helmstaedter', ',', 'M.'), (',', 'M.', 'et'), ('M.', 'et', 'al'), ('et', 'al', '.')]

>> POS Tags are: 
 [('Helmstaedter', 'NNP'), (',', ','), ('M.', 'NNP'), ('et', 'CC'), ('al', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Helmstaedter', 'M.', 'al']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Helmstaedter', 'helmstaedt'), (',', ','), ('M.', 'm.'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Helmstaedter', 'helmstaedt'), (',', ','), ('M.', 'm.'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('Helmstaedter', 'Helmstaedter'), (',', ','), ('M.', 'M.'), ('et', 'et'), ('al', 'al'), ('.', '.')]


------------------- Sentence 3 -------------------

Connectomic reconstruction of the inner plexiform layer  in the mouse retina.

>> Tokens are: 
 ['Connectomic', 'reconstruction', 'inner', 'plexiform', 'layer', 'mouse', 'retina', '.']

>> Bigrams are: 
 [('Connectomic', 'reconstruction'), ('reconstruction', 'inner'), ('inner', 'plexiform'), ('plexiform', 'layer'), ('layer', 'mouse'), ('mouse', 'retina'), ('retina', '.')]

>> Trigrams are: 
 [('Connectomic', 'reconstruction', 'inner'), ('reconstruction', 'inner', 'plexiform'), ('inner', 'plexiform', 'layer'), ('plexiform', 'layer', 'mouse'), ('layer', 'mouse', 'retina'), ('mouse', 'retina', '.')]

>> POS Tags are: 
 [('Connectomic', 'NNP'), ('reconstruction', 'NN'), ('inner', 'NN'), ('plexiform', 'NN'), ('layer', 'NN'), ('mouse', 'NN'), ('retina', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Connectomic reconstruction inner plexiform layer mouse retina']

>> Named Entities are: 
 [('GSP', 'Connectomic')] 

>> Stemming using Porter Stemmer: 
 [('Connectomic', 'connectom'), ('reconstruction', 'reconstruct'), ('inner', 'inner'), ('plexiform', 'plexiform'), ('layer', 'layer'), ('mouse', 'mous'), ('retina', 'retina'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Connectomic', 'connectom'), ('reconstruction', 'reconstruct'), ('inner', 'inner'), ('plexiform', 'plexiform'), ('layer', 'layer'), ('mouse', 'mous'), ('retina', 'retina'), ('.', '.')]

>> Lemmatization: 
 [('Connectomic', 'Connectomic'), ('reconstruction', 'reconstruction'), ('inner', 'inner'), ('plexiform', 'plexiform'), ('layer', 'layer'), ('mouse', 'mouse'), ('retina', 'retina'), ('.', '.')]


------------------- Sentence 4 -------------------

Nature 500, 168–174 (2013).

>> Tokens are: 
 ['Nature', '500', ',', '168–174', '(', '2013', ')', '.']

>> Bigrams are: 
 [('Nature', '500'), ('500', ','), (',', '168–174'), ('168–174', '('), ('(', '2013'), ('2013', ')'), (')', '.')]

>> Trigrams are: 
 [('Nature', '500', ','), ('500', ',', '168–174'), (',', '168–174', '('), ('168–174', '(', '2013'), ('(', '2013', ')'), ('2013', ')', '.')]

>> POS Tags are: 
 [('Nature', 'NN'), ('500', 'CD'), (',', ','), ('168–174', 'CD'), ('(', '('), ('2013', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['Nature']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Nature', 'natur'), ('500', '500'), (',', ','), ('168–174', '168–174'), ('(', '('), ('2013', '2013'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Nature', 'natur'), ('500', '500'), (',', ','), ('168–174', '168–174'), ('(', '('), ('2013', '2013'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Nature', 'Nature'), ('500', '500'), (',', ','), ('168–174', '168–174'), ('(', '('), ('2013', '2013'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 241 ===========================================

xtxt−1 xt+1x 

------------------- Sentence 1 -------------------

xtxt−1 xt+1x

>> Tokens are: 
 ['xtxt−1', 'xt+1x']

>> Bigrams are: 
 [('xtxt−1', 'xt+1x')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('xtxt−1', 'NN'), ('xt+1x', 'NN')]

>> Noun Phrases are: 
 ['xtxt−1 xt+1x']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('xtxt−1', 'xtxt−1'), ('xt+1x', 'xt+1x')]

>> Stemming using Snowball Stemmer: 
 [('xtxt−1', 'xtxt−1'), ('xt+1x', 'xt+1x')]

>> Lemmatization: 
 [('xtxt−1', 'xtxt−1'), ('xt+1x', 'xt+1x')]



========================================== PARAGRAPH 242 ===========================================

Unfold 

------------------- Sentence 1 -------------------

Unfold

>> Tokens are: 
 ['Unfold']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Unfold', 'NN')]

>> Noun Phrases are: 
 ['Unfold']

>> Named Entities are: 
 [('GPE', 'Unfold')] 

>> Stemming using Porter Stemmer: 
 [('Unfold', 'unfold')]

>> Stemming using Snowball Stemmer: 
 [('Unfold', 'unfold')]

>> Lemmatization: 
 [('Unfold', 'Unfold')]



========================================== PARAGRAPH 243 ===========================================

V W 

------------------- Sentence 1 -------------------

V W

>> Tokens are: 
 ['V', 'W']

>> Bigrams are: 
 [('V', 'W')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('V', 'NNP'), ('W', 'NNP')]

>> Noun Phrases are: 
 ['V W']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('V', 'v'), ('W', 'w')]

>> Stemming using Snowball Stemmer: 
 [('V', 'v'), ('W', 'w')]

>> Lemmatization: 
 [('V', 'V'), ('W', 'W')]



========================================== PARAGRAPH 244 ===========================================

W W W W 

------------------- Sentence 1 -------------------

W W W W

>> Tokens are: 
 ['W', 'W', 'W', 'W']

>> Bigrams are: 
 [('W', 'W'), ('W', 'W'), ('W', 'W')]

>> Trigrams are: 
 [('W', 'W', 'W'), ('W', 'W', 'W')]

>> POS Tags are: 
 [('W', 'NNP'), ('W', 'NNP'), ('W', 'NNP'), ('W', 'NNP')]

>> Noun Phrases are: 
 ['W W W W']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('W', 'w'), ('W', 'w'), ('W', 'w'), ('W', 'w')]

>> Stemming using Snowball Stemmer: 
 [('W', 'w'), ('W', 'w'), ('W', 'w'), ('W', 'w')]

>> Lemmatization: 
 [('W', 'W'), ('W', 'W'), ('W', 'W'), ('W', 'W')]



========================================== PARAGRAPH 245 ===========================================

V V V 

------------------- Sentence 1 -------------------

V V V

>> Tokens are: 
 ['V', 'V', 'V']

>> Bigrams are: 
 [('V', 'V'), ('V', 'V')]

>> Trigrams are: 
 [('V', 'V', 'V')]

>> POS Tags are: 
 [('V', 'NNP'), ('V', 'NNP'), ('V', 'NNP')]

>> Noun Phrases are: 
 ['V V V']

>> Named Entities are: 
 [('PERSON', 'V V V')] 

>> Stemming using Porter Stemmer: 
 [('V', 'v'), ('V', 'v'), ('V', 'v')]

>> Stemming using Snowball Stemmer: 
 [('V', 'v'), ('V', 'v'), ('V', 'v')]

>> Lemmatization: 
 [('V', 'V'), ('V', 'V'), ('V', 'V')]



========================================== PARAGRAPH 246 ===========================================

U U U U 

------------------- Sentence 1 -------------------

U U U U

>> Tokens are: 
 ['U', 'U', 'U', 'U']

>> Bigrams are: 
 [('U', 'U'), ('U', 'U'), ('U', 'U')]

>> Trigrams are: 
 [('U', 'U', 'U'), ('U', 'U', 'U')]

>> POS Tags are: 
 [('U', 'NNP'), ('U', 'NNP'), ('U', 'NNP'), ('U', 'NNP')]

>> Noun Phrases are: 
 ['U U U U']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('U', 'u'), ('U', 'u'), ('U', 'u'), ('U', 'u')]

>> Stemming using Snowball Stemmer: 
 [('U', 'u'), ('U', 'u'), ('U', 'u'), ('U', 'u')]

>> Lemmatization: 
 [('U', 'U'), ('U', 'U'), ('U', 'U'), ('U', 'U')]



========================================== PARAGRAPH 247 ===========================================

s 

------------------- Sentence 1 -------------------

s

>> Tokens are: 
 []

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 []

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 []

>> Stemming using Snowball Stemmer: 
 []

>> Lemmatization: 
 []



========================================== PARAGRAPH 248 ===========================================

o 

------------------- Sentence 1 -------------------

o

>> Tokens are: 
 []

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 []

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 []

>> Stemming using Snowball Stemmer: 
 []

>> Lemmatization: 
 []



========================================== PARAGRAPH 249 ===========================================

st−1 

------------------- Sentence 1 -------------------

st−1

>> Tokens are: 
 ['st−1']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('st−1', 'NN')]

>> Noun Phrases are: 
 ['st−1']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('st−1', 'st−1')]

>> Stemming using Snowball Stemmer: 
 [('st−1', 'st−1')]

>> Lemmatization: 
 [('st−1', 'st−1')]



========================================== PARAGRAPH 250 ===========================================

ot−1 ot 

------------------- Sentence 1 -------------------

ot−1 ot

>> Tokens are: 
 ['ot−1', 'ot']

>> Bigrams are: 
 [('ot−1', 'ot')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('ot−1', 'NN'), ('ot', 'NN')]

>> Noun Phrases are: 
 ['ot−1 ot']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('ot−1', 'ot−1'), ('ot', 'ot')]

>> Stemming using Snowball Stemmer: 
 [('ot−1', 'ot−1'), ('ot', 'ot')]

>> Lemmatization: 
 [('ot−1', 'ot−1'), ('ot', 'ot')]



========================================== PARAGRAPH 251 ===========================================

st st+1 

------------------- Sentence 1 -------------------

st st+1

>> Tokens are: 
 ['st', 'st+1']

>> Bigrams are: 
 [('st', 'st+1')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('st', 'NN'), ('st+1', 'NN')]

>> Noun Phrases are: 
 ['st st+1']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('st', 'st'), ('st+1', 'st+1')]

>> Stemming using Snowball Stemmer: 
 [('st', 'st'), ('st+1', 'st+1')]

>> Lemmatization: 
 [('st', 'st'), ('st+1', 'st+1')]



========================================== PARAGRAPH 252 ===========================================

ot+1 

------------------- Sentence 1 -------------------

ot+1

>> Tokens are: 
 ['ot+1']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('ot+1', 'NN')]

>> Noun Phrases are: 
 ['ot+1']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('ot+1', 'ot+1')]

>> Stemming using Snowball Stemmer: 
 [('ot+1', 'ot+1')]

>> Lemmatization: 
 [('ot+1', 'ot+1')]



========================================== PARAGRAPH 253 ===========================================

Figure 5 | A recurrent neural network and the unfolding in time of the  computation involved in its forward computation. The artificial neurons  (for example, hidden units grouped under node s with values st at time t) get  inputs from other neurons at previous time steps (this is represented with the  black square, representing a delay of one time step, on the left). In this way, a  recurrent neural network can map an input sequence with elements xt into an  output sequence with elements ot, with each ot depending on all the previous  xtʹ (for tʹ ≤ t). The same parameters (matrices U,V,W ) are used at each time  step. Many other architectures are possible, including a variant in which the  network can generate a sequence of outputs (for example, words), each of  which is used as inputs for the next time step. The backpropagation algorithm  (Fig. 1) can be directly applied to the computational graph of the unfolded  network on the right, to compute the derivative of a total error (for example,  the log-probability of generating the right sequence of outputs) with respect to  all the states st and all the parameters. 

------------------- Sentence 1 -------------------

Figure 5 | A recurrent neural network and the unfolding in time of the  computation involved in its forward computation.

>> Tokens are: 
 ['Figure', '5', '|', 'A', 'recurrent', 'neural', 'network', 'unfolding', 'time', 'computation', 'involved', 'forward', 'computation', '.']

>> Bigrams are: 
 [('Figure', '5'), ('5', '|'), ('|', 'A'), ('A', 'recurrent'), ('recurrent', 'neural'), ('neural', 'network'), ('network', 'unfolding'), ('unfolding', 'time'), ('time', 'computation'), ('computation', 'involved'), ('involved', 'forward'), ('forward', 'computation'), ('computation', '.')]

>> Trigrams are: 
 [('Figure', '5', '|'), ('5', '|', 'A'), ('|', 'A', 'recurrent'), ('A', 'recurrent', 'neural'), ('recurrent', 'neural', 'network'), ('neural', 'network', 'unfolding'), ('network', 'unfolding', 'time'), ('unfolding', 'time', 'computation'), ('time', 'computation', 'involved'), ('computation', 'involved', 'forward'), ('involved', 'forward', 'computation'), ('forward', 'computation', '.')]

>> POS Tags are: 
 [('Figure', 'NN'), ('5', 'CD'), ('|', 'NN'), ('A', 'DT'), ('recurrent', 'NN'), ('neural', 'JJ'), ('network', 'NN'), ('unfolding', 'JJ'), ('time', 'NN'), ('computation', 'NN'), ('involved', 'VBN'), ('forward', 'RB'), ('computation', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Figure', '|', 'A recurrent', 'neural network', 'unfolding time computation', 'computation']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Figure', 'figur'), ('5', '5'), ('|', '|'), ('A', 'a'), ('recurrent', 'recurr'), ('neural', 'neural'), ('network', 'network'), ('unfolding', 'unfold'), ('time', 'time'), ('computation', 'comput'), ('involved', 'involv'), ('forward', 'forward'), ('computation', 'comput'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Figure', 'figur'), ('5', '5'), ('|', '|'), ('A', 'a'), ('recurrent', 'recurr'), ('neural', 'neural'), ('network', 'network'), ('unfolding', 'unfold'), ('time', 'time'), ('computation', 'comput'), ('involved', 'involv'), ('forward', 'forward'), ('computation', 'comput'), ('.', '.')]

>> Lemmatization: 
 [('Figure', 'Figure'), ('5', '5'), ('|', '|'), ('A', 'A'), ('recurrent', 'recurrent'), ('neural', 'neural'), ('network', 'network'), ('unfolding', 'unfolding'), ('time', 'time'), ('computation', 'computation'), ('involved', 'involved'), ('forward', 'forward'), ('computation', 'computation'), ('.', '.')]


------------------- Sentence 2 -------------------

The artificial neurons  (for example, hidden units grouped under node s with values st at time t) get  inputs from other neurons at previous time steps (this is represented with the  black square, representing a delay of one time step, on the left).

>> Tokens are: 
 ['The', 'artificial', 'neurons', '(', 'example', ',', 'hidden', 'units', 'grouped', 'node', 'values', 'st', 'time', ')', 'get', 'inputs', 'neurons', 'previous', 'time', 'steps', '(', 'represented', 'black', 'square', ',', 'representing', 'delay', 'one', 'time', 'step', ',', 'left', ')', '.']

>> Bigrams are: 
 [('The', 'artificial'), ('artificial', 'neurons'), ('neurons', '('), ('(', 'example'), ('example', ','), (',', 'hidden'), ('hidden', 'units'), ('units', 'grouped'), ('grouped', 'node'), ('node', 'values'), ('values', 'st'), ('st', 'time'), ('time', ')'), (')', 'get'), ('get', 'inputs'), ('inputs', 'neurons'), ('neurons', 'previous'), ('previous', 'time'), ('time', 'steps'), ('steps', '('), ('(', 'represented'), ('represented', 'black'), ('black', 'square'), ('square', ','), (',', 'representing'), ('representing', 'delay'), ('delay', 'one'), ('one', 'time'), ('time', 'step'), ('step', ','), (',', 'left'), ('left', ')'), (')', '.')]

>> Trigrams are: 
 [('The', 'artificial', 'neurons'), ('artificial', 'neurons', '('), ('neurons', '(', 'example'), ('(', 'example', ','), ('example', ',', 'hidden'), (',', 'hidden', 'units'), ('hidden', 'units', 'grouped'), ('units', 'grouped', 'node'), ('grouped', 'node', 'values'), ('node', 'values', 'st'), ('values', 'st', 'time'), ('st', 'time', ')'), ('time', ')', 'get'), (')', 'get', 'inputs'), ('get', 'inputs', 'neurons'), ('inputs', 'neurons', 'previous'), ('neurons', 'previous', 'time'), ('previous', 'time', 'steps'), ('time', 'steps', '('), ('steps', '(', 'represented'), ('(', 'represented', 'black'), ('represented', 'black', 'square'), ('black', 'square', ','), ('square', ',', 'representing'), (',', 'representing', 'delay'), ('representing', 'delay', 'one'), ('delay', 'one', 'time'), ('one', 'time', 'step'), ('time', 'step', ','), ('step', ',', 'left'), (',', 'left', ')'), ('left', ')', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('artificial', 'JJ'), ('neurons', 'NNS'), ('(', '('), ('example', 'NN'), (',', ','), ('hidden', 'VBN'), ('units', 'NNS'), ('grouped', 'VBD'), ('node', 'JJ'), ('values', 'NNS'), ('st', 'VBP'), ('time', 'NN'), (')', ')'), ('get', 'VB'), ('inputs', 'JJ'), ('neurons', 'NNS'), ('previous', 'JJ'), ('time', 'NN'), ('steps', 'NNS'), ('(', '('), ('represented', 'VBN'), ('black', 'JJ'), ('square', 'NN'), (',', ','), ('representing', 'VBG'), ('delay', 'VB'), ('one', 'CD'), ('time', 'NN'), ('step', 'NN'), (',', ','), ('left', 'VBD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['The artificial neurons', 'example', 'units', 'node values', 'time', 'inputs neurons', 'previous time steps', 'black square', 'time step']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('artificial', 'artifici'), ('neurons', 'neuron'), ('(', '('), ('example', 'exampl'), (',', ','), ('hidden', 'hidden'), ('units', 'unit'), ('grouped', 'group'), ('node', 'node'), ('values', 'valu'), ('st', 'st'), ('time', 'time'), (')', ')'), ('get', 'get'), ('inputs', 'input'), ('neurons', 'neuron'), ('previous', 'previou'), ('time', 'time'), ('steps', 'step'), ('(', '('), ('represented', 'repres'), ('black', 'black'), ('square', 'squar'), (',', ','), ('representing', 'repres'), ('delay', 'delay'), ('one', 'one'), ('time', 'time'), ('step', 'step'), (',', ','), ('left', 'left'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('artificial', 'artifici'), ('neurons', 'neuron'), ('(', '('), ('example', 'exampl'), (',', ','), ('hidden', 'hidden'), ('units', 'unit'), ('grouped', 'group'), ('node', 'node'), ('values', 'valu'), ('st', 'st'), ('time', 'time'), (')', ')'), ('get', 'get'), ('inputs', 'input'), ('neurons', 'neuron'), ('previous', 'previous'), ('time', 'time'), ('steps', 'step'), ('(', '('), ('represented', 'repres'), ('black', 'black'), ('square', 'squar'), (',', ','), ('representing', 'repres'), ('delay', 'delay'), ('one', 'one'), ('time', 'time'), ('step', 'step'), (',', ','), ('left', 'left'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('artificial', 'artificial'), ('neurons', 'neuron'), ('(', '('), ('example', 'example'), (',', ','), ('hidden', 'hidden'), ('units', 'unit'), ('grouped', 'grouped'), ('node', 'node'), ('values', 'value'), ('st', 'st'), ('time', 'time'), (')', ')'), ('get', 'get'), ('inputs', 'input'), ('neurons', 'neuron'), ('previous', 'previous'), ('time', 'time'), ('steps', 'step'), ('(', '('), ('represented', 'represented'), ('black', 'black'), ('square', 'square'), (',', ','), ('representing', 'representing'), ('delay', 'delay'), ('one', 'one'), ('time', 'time'), ('step', 'step'), (',', ','), ('left', 'left'), (')', ')'), ('.', '.')]


------------------- Sentence 3 -------------------

In this way, a  recurrent neural network can map an input sequence with elements xt into an  output sequence with elements ot, with each ot depending on all the previous  xtʹ (for tʹ ≤ t).

>> Tokens are: 
 ['In', 'way', ',', 'recurrent', 'neural', 'network', 'map', 'input', 'sequence', 'elements', 'xt', 'output', 'sequence', 'elements', 'ot', ',', 'ot', 'depending', 'previous', 'xtʹ', '(', 'tʹ', '≤', ')', '.']

>> Bigrams are: 
 [('In', 'way'), ('way', ','), (',', 'recurrent'), ('recurrent', 'neural'), ('neural', 'network'), ('network', 'map'), ('map', 'input'), ('input', 'sequence'), ('sequence', 'elements'), ('elements', 'xt'), ('xt', 'output'), ('output', 'sequence'), ('sequence', 'elements'), ('elements', 'ot'), ('ot', ','), (',', 'ot'), ('ot', 'depending'), ('depending', 'previous'), ('previous', 'xtʹ'), ('xtʹ', '('), ('(', 'tʹ'), ('tʹ', '≤'), ('≤', ')'), (')', '.')]

>> Trigrams are: 
 [('In', 'way', ','), ('way', ',', 'recurrent'), (',', 'recurrent', 'neural'), ('recurrent', 'neural', 'network'), ('neural', 'network', 'map'), ('network', 'map', 'input'), ('map', 'input', 'sequence'), ('input', 'sequence', 'elements'), ('sequence', 'elements', 'xt'), ('elements', 'xt', 'output'), ('xt', 'output', 'sequence'), ('output', 'sequence', 'elements'), ('sequence', 'elements', 'ot'), ('elements', 'ot', ','), ('ot', ',', 'ot'), (',', 'ot', 'depending'), ('ot', 'depending', 'previous'), ('depending', 'previous', 'xtʹ'), ('previous', 'xtʹ', '('), ('xtʹ', '(', 'tʹ'), ('(', 'tʹ', '≤'), ('tʹ', '≤', ')'), ('≤', ')', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('way', 'NN'), (',', ','), ('recurrent', 'JJ'), ('neural', 'JJ'), ('network', 'NN'), ('map', 'NN'), ('input', 'NN'), ('sequence', 'NN'), ('elements', 'NNS'), ('xt', 'VBP'), ('output', 'NN'), ('sequence', 'NN'), ('elements', 'NNS'), ('ot', 'VBP'), (',', ','), ('ot', 'JJ'), ('depending', 'VBG'), ('previous', 'JJ'), ('xtʹ', 'NN'), ('(', '('), ('tʹ', 'JJ'), ('≤', 'NN'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['way', 'recurrent neural network map input sequence elements', 'output sequence elements', 'previous xtʹ', 'tʹ ≤']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('way', 'way'), (',', ','), ('recurrent', 'recurr'), ('neural', 'neural'), ('network', 'network'), ('map', 'map'), ('input', 'input'), ('sequence', 'sequenc'), ('elements', 'element'), ('xt', 'xt'), ('output', 'output'), ('sequence', 'sequenc'), ('elements', 'element'), ('ot', 'ot'), (',', ','), ('ot', 'ot'), ('depending', 'depend'), ('previous', 'previou'), ('xtʹ', 'xtʹ'), ('(', '('), ('tʹ', 'tʹ'), ('≤', '≤'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('way', 'way'), (',', ','), ('recurrent', 'recurr'), ('neural', 'neural'), ('network', 'network'), ('map', 'map'), ('input', 'input'), ('sequence', 'sequenc'), ('elements', 'element'), ('xt', 'xt'), ('output', 'output'), ('sequence', 'sequenc'), ('elements', 'element'), ('ot', 'ot'), (',', ','), ('ot', 'ot'), ('depending', 'depend'), ('previous', 'previous'), ('xtʹ', 'xtʹ'), ('(', '('), ('tʹ', 'tʹ'), ('≤', '≤'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('way', 'way'), (',', ','), ('recurrent', 'recurrent'), ('neural', 'neural'), ('network', 'network'), ('map', 'map'), ('input', 'input'), ('sequence', 'sequence'), ('elements', 'element'), ('xt', 'xt'), ('output', 'output'), ('sequence', 'sequence'), ('elements', 'element'), ('ot', 'ot'), (',', ','), ('ot', 'ot'), ('depending', 'depending'), ('previous', 'previous'), ('xtʹ', 'xtʹ'), ('(', '('), ('tʹ', 'tʹ'), ('≤', '≤'), (')', ')'), ('.', '.')]


------------------- Sentence 4 -------------------

The same parameters (matrices U,V,W ) are used at each time  step.

>> Tokens are: 
 ['The', 'parameters', '(', 'matrices', 'U', ',', 'V', ',', 'W', ')', 'used', 'time', 'step', '.']

>> Bigrams are: 
 [('The', 'parameters'), ('parameters', '('), ('(', 'matrices'), ('matrices', 'U'), ('U', ','), (',', 'V'), ('V', ','), (',', 'W'), ('W', ')'), (')', 'used'), ('used', 'time'), ('time', 'step'), ('step', '.')]

>> Trigrams are: 
 [('The', 'parameters', '('), ('parameters', '(', 'matrices'), ('(', 'matrices', 'U'), ('matrices', 'U', ','), ('U', ',', 'V'), (',', 'V', ','), ('V', ',', 'W'), (',', 'W', ')'), ('W', ')', 'used'), (')', 'used', 'time'), ('used', 'time', 'step'), ('time', 'step', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('parameters', 'NNS'), ('(', '('), ('matrices', 'NNS'), ('U', 'NNP'), (',', ','), ('V', 'NNP'), (',', ','), ('W', 'NNP'), (')', ')'), ('used', 'VBD'), ('time', 'NN'), ('step', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['The parameters', 'matrices U', 'V', 'W', 'time step']

>> Named Entities are: 
 [('GPE', 'V')] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('parameters', 'paramet'), ('(', '('), ('matrices', 'matric'), ('U', 'u'), (',', ','), ('V', 'v'), (',', ','), ('W', 'w'), (')', ')'), ('used', 'use'), ('time', 'time'), ('step', 'step'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('parameters', 'paramet'), ('(', '('), ('matrices', 'matric'), ('U', 'u'), (',', ','), ('V', 'v'), (',', ','), ('W', 'w'), (')', ')'), ('used', 'use'), ('time', 'time'), ('step', 'step'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('parameters', 'parameter'), ('(', '('), ('matrices', 'matrix'), ('U', 'U'), (',', ','), ('V', 'V'), (',', ','), ('W', 'W'), (')', ')'), ('used', 'used'), ('time', 'time'), ('step', 'step'), ('.', '.')]


------------------- Sentence 5 -------------------

Many other architectures are possible, including a variant in which the  network can generate a sequence of outputs (for example, words), each of  which is used as inputs for the next time step.

>> Tokens are: 
 ['Many', 'architectures', 'possible', ',', 'including', 'variant', 'network', 'generate', 'sequence', 'outputs', '(', 'example', ',', 'words', ')', ',', 'used', 'inputs', 'next', 'time', 'step', '.']

>> Bigrams are: 
 [('Many', 'architectures'), ('architectures', 'possible'), ('possible', ','), (',', 'including'), ('including', 'variant'), ('variant', 'network'), ('network', 'generate'), ('generate', 'sequence'), ('sequence', 'outputs'), ('outputs', '('), ('(', 'example'), ('example', ','), (',', 'words'), ('words', ')'), (')', ','), (',', 'used'), ('used', 'inputs'), ('inputs', 'next'), ('next', 'time'), ('time', 'step'), ('step', '.')]

>> Trigrams are: 
 [('Many', 'architectures', 'possible'), ('architectures', 'possible', ','), ('possible', ',', 'including'), (',', 'including', 'variant'), ('including', 'variant', 'network'), ('variant', 'network', 'generate'), ('network', 'generate', 'sequence'), ('generate', 'sequence', 'outputs'), ('sequence', 'outputs', '('), ('outputs', '(', 'example'), ('(', 'example', ','), ('example', ',', 'words'), (',', 'words', ')'), ('words', ')', ','), (')', ',', 'used'), (',', 'used', 'inputs'), ('used', 'inputs', 'next'), ('inputs', 'next', 'time'), ('next', 'time', 'step'), ('time', 'step', '.')]

>> POS Tags are: 
 [('Many', 'JJ'), ('architectures', 'NNS'), ('possible', 'JJ'), (',', ','), ('including', 'VBG'), ('variant', 'JJ'), ('network', 'NN'), ('generate', 'NN'), ('sequence', 'NN'), ('outputs', 'NNS'), ('(', '('), ('example', 'NN'), (',', ','), ('words', 'NNS'), (')', ')'), (',', ','), ('used', 'VBD'), ('inputs', 'NNS'), ('next', 'JJ'), ('time', 'NN'), ('step', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Many architectures', 'variant network generate sequence outputs', 'example', 'words', 'inputs', 'next time step']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Many', 'mani'), ('architectures', 'architectur'), ('possible', 'possibl'), (',', ','), ('including', 'includ'), ('variant', 'variant'), ('network', 'network'), ('generate', 'gener'), ('sequence', 'sequenc'), ('outputs', 'output'), ('(', '('), ('example', 'exampl'), (',', ','), ('words', 'word'), (')', ')'), (',', ','), ('used', 'use'), ('inputs', 'input'), ('next', 'next'), ('time', 'time'), ('step', 'step'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Many', 'mani'), ('architectures', 'architectur'), ('possible', 'possibl'), (',', ','), ('including', 'includ'), ('variant', 'variant'), ('network', 'network'), ('generate', 'generat'), ('sequence', 'sequenc'), ('outputs', 'output'), ('(', '('), ('example', 'exampl'), (',', ','), ('words', 'word'), (')', ')'), (',', ','), ('used', 'use'), ('inputs', 'input'), ('next', 'next'), ('time', 'time'), ('step', 'step'), ('.', '.')]

>> Lemmatization: 
 [('Many', 'Many'), ('architectures', 'architecture'), ('possible', 'possible'), (',', ','), ('including', 'including'), ('variant', 'variant'), ('network', 'network'), ('generate', 'generate'), ('sequence', 'sequence'), ('outputs', 'output'), ('(', '('), ('example', 'example'), (',', ','), ('words', 'word'), (')', ')'), (',', ','), ('used', 'used'), ('inputs', 'input'), ('next', 'next'), ('time', 'time'), ('step', 'step'), ('.', '.')]


------------------- Sentence 6 -------------------

The backpropagation algorithm  (Fig.

>> Tokens are: 
 ['The', 'backpropagation', 'algorithm', '(', 'Fig', '.']

>> Bigrams are: 
 [('The', 'backpropagation'), ('backpropagation', 'algorithm'), ('algorithm', '('), ('(', 'Fig'), ('Fig', '.')]

>> Trigrams are: 
 [('The', 'backpropagation', 'algorithm'), ('backpropagation', 'algorithm', '('), ('algorithm', '(', 'Fig'), ('(', 'Fig', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('backpropagation', 'NN'), ('algorithm', 'NN'), ('(', '('), ('Fig', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['The backpropagation algorithm', 'Fig']

>> Named Entities are: 
 [('ORGANIZATION', 'Fig')] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('backpropagation', 'backpropag'), ('algorithm', 'algorithm'), ('(', '('), ('Fig', 'fig'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('backpropagation', 'backpropag'), ('algorithm', 'algorithm'), ('(', '('), ('Fig', 'fig'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('backpropagation', 'backpropagation'), ('algorithm', 'algorithm'), ('(', '('), ('Fig', 'Fig'), ('.', '.')]


------------------- Sentence 7 -------------------

1) can be directly applied to the computational graph of the unfolded  network on the right, to compute the derivative of a total error (for example,  the log-probability of generating the right sequence of outputs) with respect to  all the states st and all the parameters.

>> Tokens are: 
 ['1', ')', 'directly', 'applied', 'computational', 'graph', 'unfolded', 'network', 'right', ',', 'compute', 'derivative', 'total', 'error', '(', 'example', ',', 'log-probability', 'generating', 'right', 'sequence', 'outputs', ')', 'respect', 'states', 'st', 'parameters', '.']

>> Bigrams are: 
 [('1', ')'), (')', 'directly'), ('directly', 'applied'), ('applied', 'computational'), ('computational', 'graph'), ('graph', 'unfolded'), ('unfolded', 'network'), ('network', 'right'), ('right', ','), (',', 'compute'), ('compute', 'derivative'), ('derivative', 'total'), ('total', 'error'), ('error', '('), ('(', 'example'), ('example', ','), (',', 'log-probability'), ('log-probability', 'generating'), ('generating', 'right'), ('right', 'sequence'), ('sequence', 'outputs'), ('outputs', ')'), (')', 'respect'), ('respect', 'states'), ('states', 'st'), ('st', 'parameters'), ('parameters', '.')]

>> Trigrams are: 
 [('1', ')', 'directly'), (')', 'directly', 'applied'), ('directly', 'applied', 'computational'), ('applied', 'computational', 'graph'), ('computational', 'graph', 'unfolded'), ('graph', 'unfolded', 'network'), ('unfolded', 'network', 'right'), ('network', 'right', ','), ('right', ',', 'compute'), (',', 'compute', 'derivative'), ('compute', 'derivative', 'total'), ('derivative', 'total', 'error'), ('total', 'error', '('), ('error', '(', 'example'), ('(', 'example', ','), ('example', ',', 'log-probability'), (',', 'log-probability', 'generating'), ('log-probability', 'generating', 'right'), ('generating', 'right', 'sequence'), ('right', 'sequence', 'outputs'), ('sequence', 'outputs', ')'), ('outputs', ')', 'respect'), (')', 'respect', 'states'), ('respect', 'states', 'st'), ('states', 'st', 'parameters'), ('st', 'parameters', '.')]

>> POS Tags are: 
 [('1', 'CD'), (')', ')'), ('directly', 'RB'), ('applied', 'VBN'), ('computational', 'JJ'), ('graph', 'NN'), ('unfolded', 'VBD'), ('network', 'NN'), ('right', 'RB'), (',', ','), ('compute', 'VB'), ('derivative', 'JJ'), ('total', 'JJ'), ('error', 'NN'), ('(', '('), ('example', 'NN'), (',', ','), ('log-probability', 'NN'), ('generating', 'VBG'), ('right', 'JJ'), ('sequence', 'NN'), ('outputs', 'NNS'), (')', ')'), ('respect', 'VBP'), ('states', 'NNS'), ('st', 'JJ'), ('parameters', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['computational graph', 'network', 'derivative total error', 'example', 'log-probability', 'right sequence outputs', 'states', 'st parameters']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('1', '1'), (')', ')'), ('directly', 'directli'), ('applied', 'appli'), ('computational', 'comput'), ('graph', 'graph'), ('unfolded', 'unfold'), ('network', 'network'), ('right', 'right'), (',', ','), ('compute', 'comput'), ('derivative', 'deriv'), ('total', 'total'), ('error', 'error'), ('(', '('), ('example', 'exampl'), (',', ','), ('log-probability', 'log-prob'), ('generating', 'gener'), ('right', 'right'), ('sequence', 'sequenc'), ('outputs', 'output'), (')', ')'), ('respect', 'respect'), ('states', 'state'), ('st', 'st'), ('parameters', 'paramet'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('1', '1'), (')', ')'), ('directly', 'direct'), ('applied', 'appli'), ('computational', 'comput'), ('graph', 'graph'), ('unfolded', 'unfold'), ('network', 'network'), ('right', 'right'), (',', ','), ('compute', 'comput'), ('derivative', 'deriv'), ('total', 'total'), ('error', 'error'), ('(', '('), ('example', 'exampl'), (',', ','), ('log-probability', 'log-prob'), ('generating', 'generat'), ('right', 'right'), ('sequence', 'sequenc'), ('outputs', 'output'), (')', ')'), ('respect', 'respect'), ('states', 'state'), ('st', 'st'), ('parameters', 'paramet'), ('.', '.')]

>> Lemmatization: 
 [('1', '1'), (')', ')'), ('directly', 'directly'), ('applied', 'applied'), ('computational', 'computational'), ('graph', 'graph'), ('unfolded', 'unfolded'), ('network', 'network'), ('right', 'right'), (',', ','), ('compute', 'compute'), ('derivative', 'derivative'), ('total', 'total'), ('error', 'error'), ('(', '('), ('example', 'example'), (',', ','), ('log-probability', 'log-probability'), ('generating', 'generating'), ('right', 'right'), ('sequence', 'sequence'), ('outputs', 'output'), (')', ')'), ('respect', 'respect'), ('states', 'state'), ('st', 'st'), ('parameters', 'parameter'), ('.', '.')]



========================================== PARAGRAPH 254 ===========================================

4 4 2  |  N A T U R E  |  V O L  5 2 1  |  2 8  M A Y  2 0 1 5 

------------------- Sentence 1 -------------------

4 4 2  |  N A T U R E  |  V O L  5 2 1  |  2 8  M A Y  2 0 1 5

>> Tokens are: 
 ['4', '4', '2', '|', 'N', 'A', 'T', 'U', 'R', 'E', '|', 'V', 'O', 'L', '5', '2', '1', '|', '2', '8', 'M', 'A', 'Y', '2', '0', '1', '5']

>> Bigrams are: 
 [('4', '4'), ('4', '2'), ('2', '|'), ('|', 'N'), ('N', 'A'), ('A', 'T'), ('T', 'U'), ('U', 'R'), ('R', 'E'), ('E', '|'), ('|', 'V'), ('V', 'O'), ('O', 'L'), ('L', '5'), ('5', '2'), ('2', '1'), ('1', '|'), ('|', '2'), ('2', '8'), ('8', 'M'), ('M', 'A'), ('A', 'Y'), ('Y', '2'), ('2', '0'), ('0', '1'), ('1', '5')]

>> Trigrams are: 
 [('4', '4', '2'), ('4', '2', '|'), ('2', '|', 'N'), ('|', 'N', 'A'), ('N', 'A', 'T'), ('A', 'T', 'U'), ('T', 'U', 'R'), ('U', 'R', 'E'), ('R', 'E', '|'), ('E', '|', 'V'), ('|', 'V', 'O'), ('V', 'O', 'L'), ('O', 'L', '5'), ('L', '5', '2'), ('5', '2', '1'), ('2', '1', '|'), ('1', '|', '2'), ('|', '2', '8'), ('2', '8', 'M'), ('8', 'M', 'A'), ('M', 'A', 'Y'), ('A', 'Y', '2'), ('Y', '2', '0'), ('2', '0', '1'), ('0', '1', '5')]

>> POS Tags are: 
 [('4', 'CD'), ('4', 'CD'), ('2', 'CD'), ('|', 'NN'), ('N', 'NNP'), ('A', 'NNP'), ('T', 'NNP'), ('U', 'NNP'), ('R', 'NNP'), ('E', 'NNP'), ('|', 'NNP'), ('V', 'NNP'), ('O', 'NNP'), ('L', 'NNP'), ('5', 'CD'), ('2', 'CD'), ('1', 'CD'), ('|', 'NN'), ('2', 'CD'), ('8', 'CD'), ('M', 'NNP'), ('A', 'NNP'), ('Y', 'NNP'), ('2', 'CD'), ('0', 'CD'), ('1', 'CD'), ('5', 'CD')]

>> Noun Phrases are: 
 ['| N A T U R E | V O L', '|', 'M A Y']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('4', '4'), ('4', '4'), ('2', '2'), ('|', '|'), ('N', 'n'), ('A', 'a'), ('T', 't'), ('U', 'u'), ('R', 'r'), ('E', 'e'), ('|', '|'), ('V', 'v'), ('O', 'o'), ('L', 'l'), ('5', '5'), ('2', '2'), ('1', '1'), ('|', '|'), ('2', '2'), ('8', '8'), ('M', 'm'), ('A', 'a'), ('Y', 'y'), ('2', '2'), ('0', '0'), ('1', '1'), ('5', '5')]

>> Stemming using Snowball Stemmer: 
 [('4', '4'), ('4', '4'), ('2', '2'), ('|', '|'), ('N', 'n'), ('A', 'a'), ('T', 't'), ('U', 'u'), ('R', 'r'), ('E', 'e'), ('|', '|'), ('V', 'v'), ('O', 'o'), ('L', 'l'), ('5', '5'), ('2', '2'), ('1', '1'), ('|', '|'), ('2', '2'), ('8', '8'), ('M', 'm'), ('A', 'a'), ('Y', 'y'), ('2', '2'), ('0', '0'), ('1', '1'), ('5', '5')]

>> Lemmatization: 
 [('4', '4'), ('4', '4'), ('2', '2'), ('|', '|'), ('N', 'N'), ('A', 'A'), ('T', 'T'), ('U', 'U'), ('R', 'R'), ('E', 'E'), ('|', '|'), ('V', 'V'), ('O', 'O'), ('L', 'L'), ('5', '5'), ('2', '2'), ('1', '1'), ('|', '|'), ('2', '2'), ('8', '8'), ('M', 'M'), ('A', 'A'), ('Y', 'Y'), ('2', '2'), ('0', '0'), ('1', '1'), ('5', '5')]



========================================== PARAGRAPH 255 ===========================================

REVIEWINSIGHT 

------------------- Sentence 1 -------------------

REVIEWINSIGHT

>> Tokens are: 
 ['REVIEWINSIGHT']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('REVIEWINSIGHT', 'NN')]

>> Noun Phrases are: 
 ['REVIEWINSIGHT']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('REVIEWINSIGHT', 'reviewinsight')]

>> Stemming using Snowball Stemmer: 
 [('REVIEWINSIGHT', 'reviewinsight')]

>> Lemmatization: 
 [('REVIEWINSIGHT', 'REVIEWINSIGHT')]



========================================== PARAGRAPH 256 ===========================================

© 2015 Macmillan Publishers Limited. All rights reserved

------------------- Sentence 1 -------------------

© 2015 Macmillan Publishers Limited.

>> Tokens are: 
 ['©', '2015', 'Macmillan', 'Publishers', 'Limited', '.']

>> Bigrams are: 
 [('©', '2015'), ('2015', 'Macmillan'), ('Macmillan', 'Publishers'), ('Publishers', 'Limited'), ('Limited', '.')]

>> Trigrams are: 
 [('©', '2015', 'Macmillan'), ('2015', 'Macmillan', 'Publishers'), ('Macmillan', 'Publishers', 'Limited'), ('Publishers', 'Limited', '.')]

>> POS Tags are: 
 [('©', 'NN'), ('2015', 'CD'), ('Macmillan', 'NNP'), ('Publishers', 'NNP'), ('Limited', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['©', 'Macmillan Publishers Limited']

>> Named Entities are: 
 [('PERSON', 'Macmillan Publishers Limited')] 

>> Stemming using Porter Stemmer: 
 [('©', '©'), ('2015', '2015'), ('Macmillan', 'macmillan'), ('Publishers', 'publish'), ('Limited', 'limit'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('©', '©'), ('2015', '2015'), ('Macmillan', 'macmillan'), ('Publishers', 'publish'), ('Limited', 'limit'), ('.', '.')]

>> Lemmatization: 
 [('©', '©'), ('2015', '2015'), ('Macmillan', 'Macmillan'), ('Publishers', 'Publishers'), ('Limited', 'Limited'), ('.', '.')]


------------------- Sentence 2 -------------------

All rights reserved

>> Tokens are: 
 ['All', 'rights', 'reserved']

>> Bigrams are: 
 [('All', 'rights'), ('rights', 'reserved')]

>> Trigrams are: 
 [('All', 'rights', 'reserved')]

>> POS Tags are: 
 [('All', 'DT'), ('rights', 'NNS'), ('reserved', 'VBN')]

>> Noun Phrases are: 
 ['All rights']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('All', 'all'), ('rights', 'right'), ('reserved', 'reserv')]

>> Stemming using Snowball Stemmer: 
 [('All', 'all'), ('rights', 'right'), ('reserved', 'reserv')]

>> Lemmatization: 
 [('All', 'All'), ('rights', 'right'), ('reserved', 'reserved')]



========================================== PARAGRAPH 257 ===========================================

12. Leung, M. K., Xiong, H. Y., Lee, L. J. & Frey, B. J. Deep learning of the tissue- regulated splicing code. Bioinformatics 30, i121–i129 (2014).  

------------------- Sentence 1 -------------------

12.

>> Tokens are: 
 ['12', '.']

>> Bigrams are: 
 [('12', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('12', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('12', '12'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('12', '12'), ('.', '.')]

>> Lemmatization: 
 [('12', '12'), ('.', '.')]


------------------- Sentence 2 -------------------

Leung, M. K., Xiong, H. Y., Lee, L. J.

>> Tokens are: 
 ['Leung', ',', 'M.', 'K.', ',', 'Xiong', ',', 'H.', 'Y.', ',', 'Lee', ',', 'L.', 'J', '.']

>> Bigrams are: 
 [('Leung', ','), (',', 'M.'), ('M.', 'K.'), ('K.', ','), (',', 'Xiong'), ('Xiong', ','), (',', 'H.'), ('H.', 'Y.'), ('Y.', ','), (',', 'Lee'), ('Lee', ','), (',', 'L.'), ('L.', 'J'), ('J', '.')]

>> Trigrams are: 
 [('Leung', ',', 'M.'), (',', 'M.', 'K.'), ('M.', 'K.', ','), ('K.', ',', 'Xiong'), (',', 'Xiong', ','), ('Xiong', ',', 'H.'), (',', 'H.', 'Y.'), ('H.', 'Y.', ','), ('Y.', ',', 'Lee'), (',', 'Lee', ','), ('Lee', ',', 'L.'), (',', 'L.', 'J'), ('L.', 'J', '.')]

>> POS Tags are: 
 [('Leung', 'NNP'), (',', ','), ('M.', 'NNP'), ('K.', 'NNP'), (',', ','), ('Xiong', 'NNP'), (',', ','), ('H.', 'NNP'), ('Y.', 'NNP'), (',', ','), ('Lee', 'NNP'), (',', ','), ('L.', 'NNP'), ('J', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Leung', 'M. K.', 'Xiong', 'H. Y.', 'Lee', 'L. J']

>> Named Entities are: 
 [('GPE', 'Leung'), ('GPE', 'Xiong'), ('PERSON', 'Lee')] 

>> Stemming using Porter Stemmer: 
 [('Leung', 'leung'), (',', ','), ('M.', 'm.'), ('K.', 'k.'), (',', ','), ('Xiong', 'xiong'), (',', ','), ('H.', 'h.'), ('Y.', 'y.'), (',', ','), ('Lee', 'lee'), (',', ','), ('L.', 'l.'), ('J', 'j'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Leung', 'leung'), (',', ','), ('M.', 'm.'), ('K.', 'k.'), (',', ','), ('Xiong', 'xiong'), (',', ','), ('H.', 'h.'), ('Y.', 'y.'), (',', ','), ('Lee', 'lee'), (',', ','), ('L.', 'l.'), ('J', 'j'), ('.', '.')]

>> Lemmatization: 
 [('Leung', 'Leung'), (',', ','), ('M.', 'M.'), ('K.', 'K.'), (',', ','), ('Xiong', 'Xiong'), (',', ','), ('H.', 'H.'), ('Y.', 'Y.'), (',', ','), ('Lee', 'Lee'), (',', ','), ('L.', 'L.'), ('J', 'J'), ('.', '.')]


------------------- Sentence 3 -------------------

& Frey, B. J.

>> Tokens are: 
 ['&', 'Frey', ',', 'B.', 'J', '.']

>> Bigrams are: 
 [('&', 'Frey'), ('Frey', ','), (',', 'B.'), ('B.', 'J'), ('J', '.')]

>> Trigrams are: 
 [('&', 'Frey', ','), ('Frey', ',', 'B.'), (',', 'B.', 'J'), ('B.', 'J', '.')]

>> POS Tags are: 
 [('&', 'CC'), ('Frey', 'NNP'), (',', ','), ('B.', 'NNP'), ('J', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Frey', 'B. J']

>> Named Entities are: 
 [('GPE', 'Frey')] 

>> Stemming using Porter Stemmer: 
 [('&', '&'), ('Frey', 'frey'), (',', ','), ('B.', 'b.'), ('J', 'j'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('&', '&'), ('Frey', 'frey'), (',', ','), ('B.', 'b.'), ('J', 'j'), ('.', '.')]

>> Lemmatization: 
 [('&', '&'), ('Frey', 'Frey'), (',', ','), ('B.', 'B.'), ('J', 'J'), ('.', '.')]


------------------- Sentence 4 -------------------

Deep learning of the tissue- regulated splicing code.

>> Tokens are: 
 ['Deep', 'learning', 'tissue-', 'regulated', 'splicing', 'code', '.']

>> Bigrams are: 
 [('Deep', 'learning'), ('learning', 'tissue-'), ('tissue-', 'regulated'), ('regulated', 'splicing'), ('splicing', 'code'), ('code', '.')]

>> Trigrams are: 
 [('Deep', 'learning', 'tissue-'), ('learning', 'tissue-', 'regulated'), ('tissue-', 'regulated', 'splicing'), ('regulated', 'splicing', 'code'), ('splicing', 'code', '.')]

>> POS Tags are: 
 [('Deep', 'JJ'), ('learning', 'VBG'), ('tissue-', 'JJ'), ('regulated', 'JJ'), ('splicing', 'NN'), ('code', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['tissue- regulated splicing code']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Deep', 'deep'), ('learning', 'learn'), ('tissue-', 'tissue-'), ('regulated', 'regul'), ('splicing', 'splice'), ('code', 'code'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Deep', 'deep'), ('learning', 'learn'), ('tissue-', 'tissue-'), ('regulated', 'regul'), ('splicing', 'splice'), ('code', 'code'), ('.', '.')]

>> Lemmatization: 
 [('Deep', 'Deep'), ('learning', 'learning'), ('tissue-', 'tissue-'), ('regulated', 'regulated'), ('splicing', 'splicing'), ('code', 'code'), ('.', '.')]


------------------- Sentence 5 -------------------

Bioinformatics 30, i121–i129 (2014).

>> Tokens are: 
 ['Bioinformatics', '30', ',', 'i121–i129', '(', '2014', ')', '.']

>> Bigrams are: 
 [('Bioinformatics', '30'), ('30', ','), (',', 'i121–i129'), ('i121–i129', '('), ('(', '2014'), ('2014', ')'), (')', '.')]

>> Trigrams are: 
 [('Bioinformatics', '30', ','), ('30', ',', 'i121–i129'), (',', 'i121–i129', '('), ('i121–i129', '(', '2014'), ('(', '2014', ')'), ('2014', ')', '.')]

>> POS Tags are: 
 [('Bioinformatics', 'NNS'), ('30', 'CD'), (',', ','), ('i121–i129', 'NN'), ('(', '('), ('2014', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['Bioinformatics', 'i121–i129']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Bioinformatics', 'bioinformat'), ('30', '30'), (',', ','), ('i121–i129', 'i121–i129'), ('(', '('), ('2014', '2014'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Bioinformatics', 'bioinformat'), ('30', '30'), (',', ','), ('i121–i129', 'i121–i129'), ('(', '('), ('2014', '2014'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Bioinformatics', 'Bioinformatics'), ('30', '30'), (',', ','), ('i121–i129', 'i121–i129'), ('(', '('), ('2014', '2014'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 258 ===========================================

13. Xiong, H. Y. et al. The human splicing code reveals new insights into the genetic  determinants of disease. Science 347, 6218 (2015).  

------------------- Sentence 1 -------------------

13.

>> Tokens are: 
 ['13', '.']

>> Bigrams are: 
 [('13', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('13', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('13', '13'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('13', '13'), ('.', '.')]

>> Lemmatization: 
 [('13', '13'), ('.', '.')]


------------------- Sentence 2 -------------------

Xiong, H. Y. et al.

>> Tokens are: 
 ['Xiong', ',', 'H.', 'Y.', 'et', 'al', '.']

>> Bigrams are: 
 [('Xiong', ','), (',', 'H.'), ('H.', 'Y.'), ('Y.', 'et'), ('et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('Xiong', ',', 'H.'), (',', 'H.', 'Y.'), ('H.', 'Y.', 'et'), ('Y.', 'et', 'al'), ('et', 'al', '.')]

>> POS Tags are: 
 [('Xiong', 'RB'), (',', ','), ('H.', 'NNP'), ('Y.', 'NNP'), ('et', 'FW'), ('al', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['H. Y.', 'al']

>> Named Entities are: 
 [('GPE', 'Xiong')] 

>> Stemming using Porter Stemmer: 
 [('Xiong', 'xiong'), (',', ','), ('H.', 'h.'), ('Y.', 'y.'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Xiong', 'xiong'), (',', ','), ('H.', 'h.'), ('Y.', 'y.'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('Xiong', 'Xiong'), (',', ','), ('H.', 'H.'), ('Y.', 'Y.'), ('et', 'et'), ('al', 'al'), ('.', '.')]


------------------- Sentence 3 -------------------

The human splicing code reveals new insights into the genetic  determinants of disease.

>> Tokens are: 
 ['The', 'human', 'splicing', 'code', 'reveals', 'new', 'insights', 'genetic', 'determinants', 'disease', '.']

>> Bigrams are: 
 [('The', 'human'), ('human', 'splicing'), ('splicing', 'code'), ('code', 'reveals'), ('reveals', 'new'), ('new', 'insights'), ('insights', 'genetic'), ('genetic', 'determinants'), ('determinants', 'disease'), ('disease', '.')]

>> Trigrams are: 
 [('The', 'human', 'splicing'), ('human', 'splicing', 'code'), ('splicing', 'code', 'reveals'), ('code', 'reveals', 'new'), ('reveals', 'new', 'insights'), ('new', 'insights', 'genetic'), ('insights', 'genetic', 'determinants'), ('genetic', 'determinants', 'disease'), ('determinants', 'disease', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('human', 'JJ'), ('splicing', 'NN'), ('code', 'NN'), ('reveals', 'VBZ'), ('new', 'JJ'), ('insights', 'NNS'), ('genetic', 'JJ'), ('determinants', 'NNS'), ('disease', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['The human splicing code', 'new insights', 'genetic determinants disease']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('human', 'human'), ('splicing', 'splice'), ('code', 'code'), ('reveals', 'reveal'), ('new', 'new'), ('insights', 'insight'), ('genetic', 'genet'), ('determinants', 'determin'), ('disease', 'diseas'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('human', 'human'), ('splicing', 'splice'), ('code', 'code'), ('reveals', 'reveal'), ('new', 'new'), ('insights', 'insight'), ('genetic', 'genet'), ('determinants', 'determin'), ('disease', 'diseas'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('human', 'human'), ('splicing', 'splicing'), ('code', 'code'), ('reveals', 'reveals'), ('new', 'new'), ('insights', 'insight'), ('genetic', 'genetic'), ('determinants', 'determinant'), ('disease', 'disease'), ('.', '.')]


------------------- Sentence 4 -------------------

Science 347, 6218 (2015).

>> Tokens are: 
 ['Science', '347', ',', '6218', '(', '2015', ')', '.']

>> Bigrams are: 
 [('Science', '347'), ('347', ','), (',', '6218'), ('6218', '('), ('(', '2015'), ('2015', ')'), (')', '.')]

>> Trigrams are: 
 [('Science', '347', ','), ('347', ',', '6218'), (',', '6218', '('), ('6218', '(', '2015'), ('(', '2015', ')'), ('2015', ')', '.')]

>> POS Tags are: 
 [('Science', 'NN'), ('347', 'CD'), (',', ','), ('6218', 'CD'), ('(', '('), ('2015', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['Science']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Science', 'scienc'), ('347', '347'), (',', ','), ('6218', '6218'), ('(', '('), ('2015', '2015'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Science', 'scienc'), ('347', '347'), (',', ','), ('6218', '6218'), ('(', '('), ('2015', '2015'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Science', 'Science'), ('347', '347'), (',', ','), ('6218', '6218'), ('(', '('), ('2015', '2015'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 259 ===========================================

14. Collobert, R., et al. Natural language processing (almost) from scratch. J. Mach.  Learn. Res. 12, 2493–2537 (2011).  

------------------- Sentence 1 -------------------

14.

>> Tokens are: 
 ['14', '.']

>> Bigrams are: 
 [('14', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('14', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('14', '14'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('14', '14'), ('.', '.')]

>> Lemmatization: 
 [('14', '14'), ('.', '.')]


------------------- Sentence 2 -------------------

Collobert, R., et al.

>> Tokens are: 
 ['Collobert', ',', 'R.', ',', 'et', 'al', '.']

>> Bigrams are: 
 [('Collobert', ','), (',', 'R.'), ('R.', ','), (',', 'et'), ('et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('Collobert', ',', 'R.'), (',', 'R.', ','), ('R.', ',', 'et'), (',', 'et', 'al'), ('et', 'al', '.')]

>> POS Tags are: 
 [('Collobert', 'NNP'), (',', ','), ('R.', 'NNP'), (',', ','), ('et', 'RB'), ('al', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Collobert', 'R.', 'al']

>> Named Entities are: 
 [('GPE', 'Collobert')] 

>> Stemming using Porter Stemmer: 
 [('Collobert', 'collobert'), (',', ','), ('R.', 'r.'), (',', ','), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Collobert', 'collobert'), (',', ','), ('R.', 'r.'), (',', ','), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('Collobert', 'Collobert'), (',', ','), ('R.', 'R.'), (',', ','), ('et', 'et'), ('al', 'al'), ('.', '.')]


------------------- Sentence 3 -------------------

Natural language processing (almost) from scratch.

>> Tokens are: 
 ['Natural', 'language', 'processing', '(', 'almost', ')', 'scratch', '.']

>> Bigrams are: 
 [('Natural', 'language'), ('language', 'processing'), ('processing', '('), ('(', 'almost'), ('almost', ')'), (')', 'scratch'), ('scratch', '.')]

>> Trigrams are: 
 [('Natural', 'language', 'processing'), ('language', 'processing', '('), ('processing', '(', 'almost'), ('(', 'almost', ')'), ('almost', ')', 'scratch'), (')', 'scratch', '.')]

>> POS Tags are: 
 [('Natural', 'JJ'), ('language', 'NN'), ('processing', 'NN'), ('(', '('), ('almost', 'RB'), (')', ')'), ('scratch', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Natural language processing', 'scratch']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Natural', 'natur'), ('language', 'languag'), ('processing', 'process'), ('(', '('), ('almost', 'almost'), (')', ')'), ('scratch', 'scratch'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Natural', 'natur'), ('language', 'languag'), ('processing', 'process'), ('(', '('), ('almost', 'almost'), (')', ')'), ('scratch', 'scratch'), ('.', '.')]

>> Lemmatization: 
 [('Natural', 'Natural'), ('language', 'language'), ('processing', 'processing'), ('(', '('), ('almost', 'almost'), (')', ')'), ('scratch', 'scratch'), ('.', '.')]


------------------- Sentence 4 -------------------

J. Mach.

>> Tokens are: 
 ['J.', 'Mach', '.']

>> Bigrams are: 
 [('J.', 'Mach'), ('Mach', '.')]

>> Trigrams are: 
 [('J.', 'Mach', '.')]

>> POS Tags are: 
 [('J.', 'NNP'), ('Mach', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['J. Mach']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('J.', 'j.'), ('Mach', 'mach'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('J.', 'j.'), ('Mach', 'mach'), ('.', '.')]

>> Lemmatization: 
 [('J.', 'J.'), ('Mach', 'Mach'), ('.', '.')]


------------------- Sentence 5 -------------------

Learn.

>> Tokens are: 
 ['Learn', '.']

>> Bigrams are: 
 [('Learn', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Learn', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Learn']

>> Named Entities are: 
 [('GPE', 'Learn')] 

>> Stemming using Porter Stemmer: 
 [('Learn', 'learn'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Learn', 'learn'), ('.', '.')]

>> Lemmatization: 
 [('Learn', 'Learn'), ('.', '.')]


------------------- Sentence 6 -------------------

Res.

>> Tokens are: 
 ['Res', '.']

>> Bigrams are: 
 [('Res', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Res', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Res']

>> Named Entities are: 
 [('GPE', 'Res')] 

>> Stemming using Porter Stemmer: 
 [('Res', 're'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Res', 'res'), ('.', '.')]

>> Lemmatization: 
 [('Res', 'Res'), ('.', '.')]


------------------- Sentence 7 -------------------

12, 2493–2537 (2011).

>> Tokens are: 
 ['12', ',', '2493–2537', '(', '2011', ')', '.']

>> Bigrams are: 
 [('12', ','), (',', '2493–2537'), ('2493–2537', '('), ('(', '2011'), ('2011', ')'), (')', '.')]

>> Trigrams are: 
 [('12', ',', '2493–2537'), (',', '2493–2537', '('), ('2493–2537', '(', '2011'), ('(', '2011', ')'), ('2011', ')', '.')]

>> POS Tags are: 
 [('12', 'CD'), (',', ','), ('2493–2537', 'CD'), ('(', '('), ('2011', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('12', '12'), (',', ','), ('2493–2537', '2493–2537'), ('(', '('), ('2011', '2011'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('12', '12'), (',', ','), ('2493–2537', '2493–2537'), ('(', '('), ('2011', '2011'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('12', '12'), (',', ','), ('2493–2537', '2493–2537'), ('(', '('), ('2011', '2011'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 260 ===========================================

15. Bordes, A., Chopra, S. & Weston, J. Question answering with subgraph  embeddings. In Proc. Empirical Methods in Natural Language Processing http:// arxiv.org/abs/1406.3676v3 (2014).  

------------------- Sentence 1 -------------------

15.

>> Tokens are: 
 ['15', '.']

>> Bigrams are: 
 [('15', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('15', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('15', '15'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('15', '15'), ('.', '.')]

>> Lemmatization: 
 [('15', '15'), ('.', '.')]


------------------- Sentence 2 -------------------

Bordes, A., Chopra, S. & Weston, J.

>> Tokens are: 
 ['Bordes', ',', 'A.', ',', 'Chopra', ',', 'S.', '&', 'Weston', ',', 'J', '.']

>> Bigrams are: 
 [('Bordes', ','), (',', 'A.'), ('A.', ','), (',', 'Chopra'), ('Chopra', ','), (',', 'S.'), ('S.', '&'), ('&', 'Weston'), ('Weston', ','), (',', 'J'), ('J', '.')]

>> Trigrams are: 
 [('Bordes', ',', 'A.'), (',', 'A.', ','), ('A.', ',', 'Chopra'), (',', 'Chopra', ','), ('Chopra', ',', 'S.'), (',', 'S.', '&'), ('S.', '&', 'Weston'), ('&', 'Weston', ','), ('Weston', ',', 'J'), (',', 'J', '.')]

>> POS Tags are: 
 [('Bordes', 'NNS'), (',', ','), ('A.', 'NNP'), (',', ','), ('Chopra', 'NNP'), (',', ','), ('S.', 'NNP'), ('&', 'CC'), ('Weston', 'NNP'), (',', ','), ('J', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Bordes', 'A.', 'Chopra', 'S.', 'Weston', 'J']

>> Named Entities are: 
 [('GPE', 'Bordes'), ('GPE', 'Chopra'), ('GPE', 'Weston')] 

>> Stemming using Porter Stemmer: 
 [('Bordes', 'bord'), (',', ','), ('A.', 'a.'), (',', ','), ('Chopra', 'chopra'), (',', ','), ('S.', 's.'), ('&', '&'), ('Weston', 'weston'), (',', ','), ('J', 'j'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Bordes', 'bord'), (',', ','), ('A.', 'a.'), (',', ','), ('Chopra', 'chopra'), (',', ','), ('S.', 's.'), ('&', '&'), ('Weston', 'weston'), (',', ','), ('J', 'j'), ('.', '.')]

>> Lemmatization: 
 [('Bordes', 'Bordes'), (',', ','), ('A.', 'A.'), (',', ','), ('Chopra', 'Chopra'), (',', ','), ('S.', 'S.'), ('&', '&'), ('Weston', 'Weston'), (',', ','), ('J', 'J'), ('.', '.')]


------------------- Sentence 3 -------------------

Question answering with subgraph  embeddings.

>> Tokens are: 
 ['Question', 'answering', 'subgraph', 'embeddings', '.']

>> Bigrams are: 
 [('Question', 'answering'), ('answering', 'subgraph'), ('subgraph', 'embeddings'), ('embeddings', '.')]

>> Trigrams are: 
 [('Question', 'answering', 'subgraph'), ('answering', 'subgraph', 'embeddings'), ('subgraph', 'embeddings', '.')]

>> POS Tags are: 
 [('Question', 'NN'), ('answering', 'VBG'), ('subgraph', 'JJ'), ('embeddings', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['Question', 'subgraph embeddings']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Question', 'question'), ('answering', 'answer'), ('subgraph', 'subgraph'), ('embeddings', 'embed'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Question', 'question'), ('answering', 'answer'), ('subgraph', 'subgraph'), ('embeddings', 'embed'), ('.', '.')]

>> Lemmatization: 
 [('Question', 'Question'), ('answering', 'answering'), ('subgraph', 'subgraph'), ('embeddings', 'embeddings'), ('.', '.')]


------------------- Sentence 4 -------------------

In Proc.

>> Tokens are: 
 ['In', 'Proc', '.']

>> Bigrams are: 
 [('In', 'Proc'), ('Proc', '.')]

>> Trigrams are: 
 [('In', 'Proc', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('Proc', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Proc']

>> Named Entities are: 
 [('GPE', 'Proc')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('Proc', 'proc'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('Proc', 'proc'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('Proc', 'Proc'), ('.', '.')]


------------------- Sentence 5 -------------------

Empirical Methods in Natural Language Processing http:// arxiv.org/abs/1406.3676v3 (2014).

>> Tokens are: 
 ['Empirical', 'Methods', 'Natural', 'Language', 'Processing', 'http', ':', '//', 'arxiv.org/abs/1406.3676v3', '(', '2014', ')', '.']

>> Bigrams are: 
 [('Empirical', 'Methods'), ('Methods', 'Natural'), ('Natural', 'Language'), ('Language', 'Processing'), ('Processing', 'http'), ('http', ':'), (':', '//'), ('//', 'arxiv.org/abs/1406.3676v3'), ('arxiv.org/abs/1406.3676v3', '('), ('(', '2014'), ('2014', ')'), (')', '.')]

>> Trigrams are: 
 [('Empirical', 'Methods', 'Natural'), ('Methods', 'Natural', 'Language'), ('Natural', 'Language', 'Processing'), ('Language', 'Processing', 'http'), ('Processing', 'http', ':'), ('http', ':', '//'), (':', '//', 'arxiv.org/abs/1406.3676v3'), ('//', 'arxiv.org/abs/1406.3676v3', '('), ('arxiv.org/abs/1406.3676v3', '(', '2014'), ('(', '2014', ')'), ('2014', ')', '.')]

>> POS Tags are: 
 [('Empirical', 'JJ'), ('Methods', 'NNP'), ('Natural', 'NNP'), ('Language', 'NNP'), ('Processing', 'NNP'), ('http', 'NN'), (':', ':'), ('//', 'NN'), ('arxiv.org/abs/1406.3676v3', 'NN'), ('(', '('), ('2014', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['Empirical Methods Natural Language Processing http', '// arxiv.org/abs/1406.3676v3']

>> Named Entities are: 
 [('ORGANIZATION', 'Methods Natural Language')] 

>> Stemming using Porter Stemmer: 
 [('Empirical', 'empir'), ('Methods', 'method'), ('Natural', 'natur'), ('Language', 'languag'), ('Processing', 'process'), ('http', 'http'), (':', ':'), ('//', '//'), ('arxiv.org/abs/1406.3676v3', 'arxiv.org/abs/1406.3676v3'), ('(', '('), ('2014', '2014'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Empirical', 'empir'), ('Methods', 'method'), ('Natural', 'natur'), ('Language', 'languag'), ('Processing', 'process'), ('http', 'http'), (':', ':'), ('//', '//'), ('arxiv.org/abs/1406.3676v3', 'arxiv.org/abs/1406.3676v3'), ('(', '('), ('2014', '2014'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Empirical', 'Empirical'), ('Methods', 'Methods'), ('Natural', 'Natural'), ('Language', 'Language'), ('Processing', 'Processing'), ('http', 'http'), (':', ':'), ('//', '//'), ('arxiv.org/abs/1406.3676v3', 'arxiv.org/abs/1406.3676v3'), ('(', '('), ('2014', '2014'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 261 ===========================================

16. Jean, S., Cho, K., Memisevic, R. & Bengio, Y. On using very large target  vocabulary for neural machine translation. In Proc. ACL-IJCNLP http://arxiv.org/ abs/1412.2007 (2015). 

------------------- Sentence 1 -------------------

16.

>> Tokens are: 
 ['16', '.']

>> Bigrams are: 
 [('16', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('16', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('16', '16'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('16', '16'), ('.', '.')]

>> Lemmatization: 
 [('16', '16'), ('.', '.')]


------------------- Sentence 2 -------------------

Jean, S., Cho, K., Memisevic, R. & Bengio, Y.

>> Tokens are: 
 ['Jean', ',', 'S.', ',', 'Cho', ',', 'K.', ',', 'Memisevic', ',', 'R.', '&', 'Bengio', ',', 'Y', '.']

>> Bigrams are: 
 [('Jean', ','), (',', 'S.'), ('S.', ','), (',', 'Cho'), ('Cho', ','), (',', 'K.'), ('K.', ','), (',', 'Memisevic'), ('Memisevic', ','), (',', 'R.'), ('R.', '&'), ('&', 'Bengio'), ('Bengio', ','), (',', 'Y'), ('Y', '.')]

>> Trigrams are: 
 [('Jean', ',', 'S.'), (',', 'S.', ','), ('S.', ',', 'Cho'), (',', 'Cho', ','), ('Cho', ',', 'K.'), (',', 'K.', ','), ('K.', ',', 'Memisevic'), (',', 'Memisevic', ','), ('Memisevic', ',', 'R.'), (',', 'R.', '&'), ('R.', '&', 'Bengio'), ('&', 'Bengio', ','), ('Bengio', ',', 'Y'), (',', 'Y', '.')]

>> POS Tags are: 
 [('Jean', 'NNP'), (',', ','), ('S.', 'NNP'), (',', ','), ('Cho', 'NNP'), (',', ','), ('K.', 'NNP'), (',', ','), ('Memisevic', 'NNP'), (',', ','), ('R.', 'NNP'), ('&', 'CC'), ('Bengio', 'NNP'), (',', ','), ('Y', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Jean', 'S.', 'Cho', 'K.', 'Memisevic', 'R.', 'Bengio', 'Y']

>> Named Entities are: 
 [('GPE', 'Jean'), ('PERSON', 'Cho'), ('PERSON', 'Memisevic'), ('PERSON', 'Bengio')] 

>> Stemming using Porter Stemmer: 
 [('Jean', 'jean'), (',', ','), ('S.', 's.'), (',', ','), ('Cho', 'cho'), (',', ','), ('K.', 'k.'), (',', ','), ('Memisevic', 'memisev'), (',', ','), ('R.', 'r.'), ('&', '&'), ('Bengio', 'bengio'), (',', ','), ('Y', 'y'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Jean', 'jean'), (',', ','), ('S.', 's.'), (',', ','), ('Cho', 'cho'), (',', ','), ('K.', 'k.'), (',', ','), ('Memisevic', 'memisev'), (',', ','), ('R.', 'r.'), ('&', '&'), ('Bengio', 'bengio'), (',', ','), ('Y', 'y'), ('.', '.')]

>> Lemmatization: 
 [('Jean', 'Jean'), (',', ','), ('S.', 'S.'), (',', ','), ('Cho', 'Cho'), (',', ','), ('K.', 'K.'), (',', ','), ('Memisevic', 'Memisevic'), (',', ','), ('R.', 'R.'), ('&', '&'), ('Bengio', 'Bengio'), (',', ','), ('Y', 'Y'), ('.', '.')]


------------------- Sentence 3 -------------------

On using very large target  vocabulary for neural machine translation.

>> Tokens are: 
 ['On', 'using', 'large', 'target', 'vocabulary', 'neural', 'machine', 'translation', '.']

>> Bigrams are: 
 [('On', 'using'), ('using', 'large'), ('large', 'target'), ('target', 'vocabulary'), ('vocabulary', 'neural'), ('neural', 'machine'), ('machine', 'translation'), ('translation', '.')]

>> Trigrams are: 
 [('On', 'using', 'large'), ('using', 'large', 'target'), ('large', 'target', 'vocabulary'), ('target', 'vocabulary', 'neural'), ('vocabulary', 'neural', 'machine'), ('neural', 'machine', 'translation'), ('machine', 'translation', '.')]

>> POS Tags are: 
 [('On', 'IN'), ('using', 'VBG'), ('large', 'JJ'), ('target', 'NN'), ('vocabulary', 'JJ'), ('neural', 'JJ'), ('machine', 'NN'), ('translation', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['large target', 'vocabulary neural machine translation']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('On', 'on'), ('using', 'use'), ('large', 'larg'), ('target', 'target'), ('vocabulary', 'vocabulari'), ('neural', 'neural'), ('machine', 'machin'), ('translation', 'translat'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('On', 'on'), ('using', 'use'), ('large', 'larg'), ('target', 'target'), ('vocabulary', 'vocabulari'), ('neural', 'neural'), ('machine', 'machin'), ('translation', 'translat'), ('.', '.')]

>> Lemmatization: 
 [('On', 'On'), ('using', 'using'), ('large', 'large'), ('target', 'target'), ('vocabulary', 'vocabulary'), ('neural', 'neural'), ('machine', 'machine'), ('translation', 'translation'), ('.', '.')]


------------------- Sentence 4 -------------------

In Proc.

>> Tokens are: 
 ['In', 'Proc', '.']

>> Bigrams are: 
 [('In', 'Proc'), ('Proc', '.')]

>> Trigrams are: 
 [('In', 'Proc', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('Proc', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Proc']

>> Named Entities are: 
 [('GPE', 'Proc')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('Proc', 'proc'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('Proc', 'proc'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('Proc', 'Proc'), ('.', '.')]


------------------- Sentence 5 -------------------

ACL-IJCNLP http://arxiv.org/ abs/1412.2007 (2015).

>> Tokens are: 
 ['ACL-IJCNLP', 'http', ':', '//arxiv.org/', 'abs/1412.2007', '(', '2015', ')', '.']

>> Bigrams are: 
 [('ACL-IJCNLP', 'http'), ('http', ':'), (':', '//arxiv.org/'), ('//arxiv.org/', 'abs/1412.2007'), ('abs/1412.2007', '('), ('(', '2015'), ('2015', ')'), (')', '.')]

>> Trigrams are: 
 [('ACL-IJCNLP', 'http', ':'), ('http', ':', '//arxiv.org/'), (':', '//arxiv.org/', 'abs/1412.2007'), ('//arxiv.org/', 'abs/1412.2007', '('), ('abs/1412.2007', '(', '2015'), ('(', '2015', ')'), ('2015', ')', '.')]

>> POS Tags are: 
 [('ACL-IJCNLP', 'JJ'), ('http', 'NN'), (':', ':'), ('//arxiv.org/', 'NN'), ('abs/1412.2007', 'NN'), ('(', '('), ('2015', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['ACL-IJCNLP http', '//arxiv.org/ abs/1412.2007']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('ACL-IJCNLP', 'acl-ijcnlp'), ('http', 'http'), (':', ':'), ('//arxiv.org/', '//arxiv.org/'), ('abs/1412.2007', 'abs/1412.2007'), ('(', '('), ('2015', '2015'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('ACL-IJCNLP', 'acl-ijcnlp'), ('http', 'http'), (':', ':'), ('//arxiv.org/', '//arxiv.org/'), ('abs/1412.2007', 'abs/1412.2007'), ('(', '('), ('2015', '2015'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('ACL-IJCNLP', 'ACL-IJCNLP'), ('http', 'http'), (':', ':'), ('//arxiv.org/', '//arxiv.org/'), ('abs/1412.2007', 'abs/1412.2007'), ('(', '('), ('2015', '2015'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 262 ===========================================

17. Sutskever, I. Vinyals, O. & Le. Q. V. Sequence to sequence learning with neural  networks. In Proc. Advances in Neural Information Processing Systems 27  3104–3112 (2014).  

------------------- Sentence 1 -------------------

17.

>> Tokens are: 
 ['17', '.']

>> Bigrams are: 
 [('17', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('17', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('17', '17'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('17', '17'), ('.', '.')]

>> Lemmatization: 
 [('17', '17'), ('.', '.')]


------------------- Sentence 2 -------------------

Sutskever, I. Vinyals, O.

>> Tokens are: 
 ['Sutskever', ',', 'I.', 'Vinyals', ',', 'O', '.']

>> Bigrams are: 
 [('Sutskever', ','), (',', 'I.'), ('I.', 'Vinyals'), ('Vinyals', ','), (',', 'O'), ('O', '.')]

>> Trigrams are: 
 [('Sutskever', ',', 'I.'), (',', 'I.', 'Vinyals'), ('I.', 'Vinyals', ','), ('Vinyals', ',', 'O'), (',', 'O', '.')]

>> POS Tags are: 
 [('Sutskever', 'NNP'), (',', ','), ('I.', 'NNP'), ('Vinyals', 'NNP'), (',', ','), ('O', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Sutskever', 'I. Vinyals', 'O']

>> Named Entities are: 
 [('GPE', 'Sutskever')] 

>> Stemming using Porter Stemmer: 
 [('Sutskever', 'sutskev'), (',', ','), ('I.', 'i.'), ('Vinyals', 'vinyal'), (',', ','), ('O', 'o'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Sutskever', 'sutskev'), (',', ','), ('I.', 'i.'), ('Vinyals', 'vinyal'), (',', ','), ('O', 'o'), ('.', '.')]

>> Lemmatization: 
 [('Sutskever', 'Sutskever'), (',', ','), ('I.', 'I.'), ('Vinyals', 'Vinyals'), (',', ','), ('O', 'O'), ('.', '.')]


------------------- Sentence 3 -------------------

& Le.

>> Tokens are: 
 ['&', 'Le', '.']

>> Bigrams are: 
 [('&', 'Le'), ('Le', '.')]

>> Trigrams are: 
 [('&', 'Le', '.')]

>> POS Tags are: 
 [('&', 'CC'), ('Le', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Le']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('&', '&'), ('Le', 'le'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('&', '&'), ('Le', 'le'), ('.', '.')]

>> Lemmatization: 
 [('&', '&'), ('Le', 'Le'), ('.', '.')]


------------------- Sentence 4 -------------------

Q. V. Sequence to sequence learning with neural  networks.

>> Tokens are: 
 ['Q.', 'V.', 'Sequence', 'sequence', 'learning', 'neural', 'networks', '.']

>> Bigrams are: 
 [('Q.', 'V.'), ('V.', 'Sequence'), ('Sequence', 'sequence'), ('sequence', 'learning'), ('learning', 'neural'), ('neural', 'networks'), ('networks', '.')]

>> Trigrams are: 
 [('Q.', 'V.', 'Sequence'), ('V.', 'Sequence', 'sequence'), ('Sequence', 'sequence', 'learning'), ('sequence', 'learning', 'neural'), ('learning', 'neural', 'networks'), ('neural', 'networks', '.')]

>> POS Tags are: 
 [('Q.', 'NNP'), ('V.', 'NNP'), ('Sequence', 'NNP'), ('sequence', 'NN'), ('learning', 'VBG'), ('neural', 'JJ'), ('networks', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['Q. V. Sequence sequence', 'neural networks']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Q.', 'q.'), ('V.', 'v.'), ('Sequence', 'sequenc'), ('sequence', 'sequenc'), ('learning', 'learn'), ('neural', 'neural'), ('networks', 'network'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Q.', 'q.'), ('V.', 'v.'), ('Sequence', 'sequenc'), ('sequence', 'sequenc'), ('learning', 'learn'), ('neural', 'neural'), ('networks', 'network'), ('.', '.')]

>> Lemmatization: 
 [('Q.', 'Q.'), ('V.', 'V.'), ('Sequence', 'Sequence'), ('sequence', 'sequence'), ('learning', 'learning'), ('neural', 'neural'), ('networks', 'network'), ('.', '.')]


------------------- Sentence 5 -------------------

In Proc.

>> Tokens are: 
 ['In', 'Proc', '.']

>> Bigrams are: 
 [('In', 'Proc'), ('Proc', '.')]

>> Trigrams are: 
 [('In', 'Proc', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('Proc', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Proc']

>> Named Entities are: 
 [('GPE', 'Proc')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('Proc', 'proc'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('Proc', 'proc'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('Proc', 'Proc'), ('.', '.')]


------------------- Sentence 6 -------------------

Advances in Neural Information Processing Systems 27  3104–3112 (2014).

>> Tokens are: 
 ['Advances', 'Neural', 'Information', 'Processing', 'Systems', '27', '3104–3112', '(', '2014', ')', '.']

>> Bigrams are: 
 [('Advances', 'Neural'), ('Neural', 'Information'), ('Information', 'Processing'), ('Processing', 'Systems'), ('Systems', '27'), ('27', '3104–3112'), ('3104–3112', '('), ('(', '2014'), ('2014', ')'), (')', '.')]

>> Trigrams are: 
 [('Advances', 'Neural', 'Information'), ('Neural', 'Information', 'Processing'), ('Information', 'Processing', 'Systems'), ('Processing', 'Systems', '27'), ('Systems', '27', '3104–3112'), ('27', '3104–3112', '('), ('3104–3112', '(', '2014'), ('(', '2014', ')'), ('2014', ')', '.')]

>> POS Tags are: 
 [('Advances', 'NNS'), ('Neural', 'NNP'), ('Information', 'NNP'), ('Processing', 'NNP'), ('Systems', 'NNPS'), ('27', 'CD'), ('3104–3112', 'CD'), ('(', '('), ('2014', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['Advances Neural Information Processing']

>> Named Entities are: 
 [('ORGANIZATION', 'Neural Information Processing Systems')] 

>> Stemming using Porter Stemmer: 
 [('Advances', 'advanc'), ('Neural', 'neural'), ('Information', 'inform'), ('Processing', 'process'), ('Systems', 'system'), ('27', '27'), ('3104–3112', '3104–3112'), ('(', '('), ('2014', '2014'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Advances', 'advanc'), ('Neural', 'neural'), ('Information', 'inform'), ('Processing', 'process'), ('Systems', 'system'), ('27', '27'), ('3104–3112', '3104–3112'), ('(', '('), ('2014', '2014'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Advances', 'Advances'), ('Neural', 'Neural'), ('Information', 'Information'), ('Processing', 'Processing'), ('Systems', 'Systems'), ('27', '27'), ('3104–3112', '3104–3112'), ('(', '('), ('2014', '2014'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 263 ===========================================

 This paper showed state-of-the-art machine translation results with the  architecture introduced in ref. 72, with a recurrent network trained to read a  sentence in one language, produce a semantic representation of its meaning,  and generate a translation in another language. 

------------------- Sentence 1 -------------------

 This paper showed state-of-the-art machine translation results with the  architecture introduced in ref.

>> Tokens are: 
 ['This', 'paper', 'showed', 'state-of-the-art', 'machine', 'translation', 'results', 'architecture', 'introduced', 'ref', '.']

>> Bigrams are: 
 [('This', 'paper'), ('paper', 'showed'), ('showed', 'state-of-the-art'), ('state-of-the-art', 'machine'), ('machine', 'translation'), ('translation', 'results'), ('results', 'architecture'), ('architecture', 'introduced'), ('introduced', 'ref'), ('ref', '.')]

>> Trigrams are: 
 [('This', 'paper', 'showed'), ('paper', 'showed', 'state-of-the-art'), ('showed', 'state-of-the-art', 'machine'), ('state-of-the-art', 'machine', 'translation'), ('machine', 'translation', 'results'), ('translation', 'results', 'architecture'), ('results', 'architecture', 'introduced'), ('architecture', 'introduced', 'ref'), ('introduced', 'ref', '.')]

>> POS Tags are: 
 [('This', 'DT'), ('paper', 'NN'), ('showed', 'VBD'), ('state-of-the-art', 'JJ'), ('machine', 'NN'), ('translation', 'NN'), ('results', 'NNS'), ('architecture', 'NN'), ('introduced', 'VBD'), ('ref', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['This paper', 'state-of-the-art machine translation results architecture', 'ref']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('This', 'thi'), ('paper', 'paper'), ('showed', 'show'), ('state-of-the-art', 'state-of-the-art'), ('machine', 'machin'), ('translation', 'translat'), ('results', 'result'), ('architecture', 'architectur'), ('introduced', 'introduc'), ('ref', 'ref'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('This', 'this'), ('paper', 'paper'), ('showed', 'show'), ('state-of-the-art', 'state-of-the-art'), ('machine', 'machin'), ('translation', 'translat'), ('results', 'result'), ('architecture', 'architectur'), ('introduced', 'introduc'), ('ref', 'ref'), ('.', '.')]

>> Lemmatization: 
 [('This', 'This'), ('paper', 'paper'), ('showed', 'showed'), ('state-of-the-art', 'state-of-the-art'), ('machine', 'machine'), ('translation', 'translation'), ('results', 'result'), ('architecture', 'architecture'), ('introduced', 'introduced'), ('ref', 'ref'), ('.', '.')]


------------------- Sentence 2 -------------------

72, with a recurrent network trained to read a  sentence in one language, produce a semantic representation of its meaning,  and generate a translation in another language.

>> Tokens are: 
 ['72', ',', 'recurrent', 'network', 'trained', 'read', 'sentence', 'one', 'language', ',', 'produce', 'semantic', 'representation', 'meaning', ',', 'generate', 'translation', 'another', 'language', '.']

>> Bigrams are: 
 [('72', ','), (',', 'recurrent'), ('recurrent', 'network'), ('network', 'trained'), ('trained', 'read'), ('read', 'sentence'), ('sentence', 'one'), ('one', 'language'), ('language', ','), (',', 'produce'), ('produce', 'semantic'), ('semantic', 'representation'), ('representation', 'meaning'), ('meaning', ','), (',', 'generate'), ('generate', 'translation'), ('translation', 'another'), ('another', 'language'), ('language', '.')]

>> Trigrams are: 
 [('72', ',', 'recurrent'), (',', 'recurrent', 'network'), ('recurrent', 'network', 'trained'), ('network', 'trained', 'read'), ('trained', 'read', 'sentence'), ('read', 'sentence', 'one'), ('sentence', 'one', 'language'), ('one', 'language', ','), ('language', ',', 'produce'), (',', 'produce', 'semantic'), ('produce', 'semantic', 'representation'), ('semantic', 'representation', 'meaning'), ('representation', 'meaning', ','), ('meaning', ',', 'generate'), (',', 'generate', 'translation'), ('generate', 'translation', 'another'), ('translation', 'another', 'language'), ('another', 'language', '.')]

>> POS Tags are: 
 [('72', 'CD'), (',', ','), ('recurrent', 'NN'), ('network', 'NN'), ('trained', 'VBN'), ('read', 'JJ'), ('sentence', 'NN'), ('one', 'CD'), ('language', 'NN'), (',', ','), ('produce', 'VBP'), ('semantic', 'JJ'), ('representation', 'NN'), ('meaning', 'NN'), (',', ','), ('generate', 'JJ'), ('translation', 'NN'), ('another', 'DT'), ('language', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['recurrent network', 'read sentence', 'language', 'semantic representation meaning', 'generate translation', 'another language']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('72', '72'), (',', ','), ('recurrent', 'recurr'), ('network', 'network'), ('trained', 'train'), ('read', 'read'), ('sentence', 'sentenc'), ('one', 'one'), ('language', 'languag'), (',', ','), ('produce', 'produc'), ('semantic', 'semant'), ('representation', 'represent'), ('meaning', 'mean'), (',', ','), ('generate', 'gener'), ('translation', 'translat'), ('another', 'anoth'), ('language', 'languag'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('72', '72'), (',', ','), ('recurrent', 'recurr'), ('network', 'network'), ('trained', 'train'), ('read', 'read'), ('sentence', 'sentenc'), ('one', 'one'), ('language', 'languag'), (',', ','), ('produce', 'produc'), ('semantic', 'semant'), ('representation', 'represent'), ('meaning', 'mean'), (',', ','), ('generate', 'generat'), ('translation', 'translat'), ('another', 'anoth'), ('language', 'languag'), ('.', '.')]

>> Lemmatization: 
 [('72', '72'), (',', ','), ('recurrent', 'recurrent'), ('network', 'network'), ('trained', 'trained'), ('read', 'read'), ('sentence', 'sentence'), ('one', 'one'), ('language', 'language'), (',', ','), ('produce', 'produce'), ('semantic', 'semantic'), ('representation', 'representation'), ('meaning', 'meaning'), (',', ','), ('generate', 'generate'), ('translation', 'translation'), ('another', 'another'), ('language', 'language'), ('.', '.')]



========================================== PARAGRAPH 264 ===========================================

18. Bottou, L. & Bousquet, O. The tradeoffs of large scale learning. In Proc. Advances  in Neural Information Processing Systems 20 161–168 (2007).  

------------------- Sentence 1 -------------------

18.

>> Tokens are: 
 ['18', '.']

>> Bigrams are: 
 [('18', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('18', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('18', '18'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('18', '18'), ('.', '.')]

>> Lemmatization: 
 [('18', '18'), ('.', '.')]


------------------- Sentence 2 -------------------

Bottou, L. & Bousquet, O.

>> Tokens are: 
 ['Bottou', ',', 'L.', '&', 'Bousquet', ',', 'O', '.']

>> Bigrams are: 
 [('Bottou', ','), (',', 'L.'), ('L.', '&'), ('&', 'Bousquet'), ('Bousquet', ','), (',', 'O'), ('O', '.')]

>> Trigrams are: 
 [('Bottou', ',', 'L.'), (',', 'L.', '&'), ('L.', '&', 'Bousquet'), ('&', 'Bousquet', ','), ('Bousquet', ',', 'O'), (',', 'O', '.')]

>> POS Tags are: 
 [('Bottou', 'NNP'), (',', ','), ('L.', 'NNP'), ('&', 'CC'), ('Bousquet', 'NNP'), (',', ','), ('O', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Bottou', 'L.', 'Bousquet', 'O']

>> Named Entities are: 
 [('GPE', 'Bottou'), ('GPE', 'Bousquet')] 

>> Stemming using Porter Stemmer: 
 [('Bottou', 'bottou'), (',', ','), ('L.', 'l.'), ('&', '&'), ('Bousquet', 'bousquet'), (',', ','), ('O', 'o'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Bottou', 'bottou'), (',', ','), ('L.', 'l.'), ('&', '&'), ('Bousquet', 'bousquet'), (',', ','), ('O', 'o'), ('.', '.')]

>> Lemmatization: 
 [('Bottou', 'Bottou'), (',', ','), ('L.', 'L.'), ('&', '&'), ('Bousquet', 'Bousquet'), (',', ','), ('O', 'O'), ('.', '.')]


------------------- Sentence 3 -------------------

The tradeoffs of large scale learning.

>> Tokens are: 
 ['The', 'tradeoffs', 'large', 'scale', 'learning', '.']

>> Bigrams are: 
 [('The', 'tradeoffs'), ('tradeoffs', 'large'), ('large', 'scale'), ('scale', 'learning'), ('learning', '.')]

>> Trigrams are: 
 [('The', 'tradeoffs', 'large'), ('tradeoffs', 'large', 'scale'), ('large', 'scale', 'learning'), ('scale', 'learning', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('tradeoffs', 'NNS'), ('large', 'JJ'), ('scale', 'JJ'), ('learning', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['The tradeoffs', 'large scale learning']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('tradeoffs', 'tradeoff'), ('large', 'larg'), ('scale', 'scale'), ('learning', 'learn'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('tradeoffs', 'tradeoff'), ('large', 'larg'), ('scale', 'scale'), ('learning', 'learn'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('tradeoffs', 'tradeoff'), ('large', 'large'), ('scale', 'scale'), ('learning', 'learning'), ('.', '.')]


------------------- Sentence 4 -------------------

In Proc.

>> Tokens are: 
 ['In', 'Proc', '.']

>> Bigrams are: 
 [('In', 'Proc'), ('Proc', '.')]

>> Trigrams are: 
 [('In', 'Proc', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('Proc', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Proc']

>> Named Entities are: 
 [('GPE', 'Proc')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('Proc', 'proc'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('Proc', 'proc'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('Proc', 'Proc'), ('.', '.')]


------------------- Sentence 5 -------------------

Advances  in Neural Information Processing Systems 20 161–168 (2007).

>> Tokens are: 
 ['Advances', 'Neural', 'Information', 'Processing', 'Systems', '20', '161–168', '(', '2007', ')', '.']

>> Bigrams are: 
 [('Advances', 'Neural'), ('Neural', 'Information'), ('Information', 'Processing'), ('Processing', 'Systems'), ('Systems', '20'), ('20', '161–168'), ('161–168', '('), ('(', '2007'), ('2007', ')'), (')', '.')]

>> Trigrams are: 
 [('Advances', 'Neural', 'Information'), ('Neural', 'Information', 'Processing'), ('Information', 'Processing', 'Systems'), ('Processing', 'Systems', '20'), ('Systems', '20', '161–168'), ('20', '161–168', '('), ('161–168', '(', '2007'), ('(', '2007', ')'), ('2007', ')', '.')]

>> POS Tags are: 
 [('Advances', 'NNS'), ('Neural', 'NNP'), ('Information', 'NNP'), ('Processing', 'NNP'), ('Systems', 'NNPS'), ('20', 'CD'), ('161–168', 'CD'), ('(', '('), ('2007', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['Advances Neural Information Processing']

>> Named Entities are: 
 [('ORGANIZATION', 'Neural Information Processing Systems')] 

>> Stemming using Porter Stemmer: 
 [('Advances', 'advanc'), ('Neural', 'neural'), ('Information', 'inform'), ('Processing', 'process'), ('Systems', 'system'), ('20', '20'), ('161–168', '161–168'), ('(', '('), ('2007', '2007'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Advances', 'advanc'), ('Neural', 'neural'), ('Information', 'inform'), ('Processing', 'process'), ('Systems', 'system'), ('20', '20'), ('161–168', '161–168'), ('(', '('), ('2007', '2007'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Advances', 'Advances'), ('Neural', 'Neural'), ('Information', 'Information'), ('Processing', 'Processing'), ('Systems', 'Systems'), ('20', '20'), ('161–168', '161–168'), ('(', '('), ('2007', '2007'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 265 ===========================================

19. Duda, R. O. & Hart, P. E. Pattern Classification and Scene Analysis (Wiley, 1973).  20. Schölkopf, B. & Smola, A. Learning with Kernels (MIT Press, 2002).  21. Bengio, Y., Delalleau, O. & Le Roux, N. The curse of highly variable functions  

------------------- Sentence 1 -------------------

19.

>> Tokens are: 
 ['19', '.']

>> Bigrams are: 
 [('19', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('19', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('19', '19'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('19', '19'), ('.', '.')]

>> Lemmatization: 
 [('19', '19'), ('.', '.')]


------------------- Sentence 2 -------------------

Duda, R. O.

>> Tokens are: 
 ['Duda', ',', 'R.', 'O', '.']

>> Bigrams are: 
 [('Duda', ','), (',', 'R.'), ('R.', 'O'), ('O', '.')]

>> Trigrams are: 
 [('Duda', ',', 'R.'), (',', 'R.', 'O'), ('R.', 'O', '.')]

>> POS Tags are: 
 [('Duda', 'NNP'), (',', ','), ('R.', 'NNP'), ('O', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Duda', 'R. O']

>> Named Entities are: 
 [('GPE', 'Duda')] 

>> Stemming using Porter Stemmer: 
 [('Duda', 'duda'), (',', ','), ('R.', 'r.'), ('O', 'o'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Duda', 'duda'), (',', ','), ('R.', 'r.'), ('O', 'o'), ('.', '.')]

>> Lemmatization: 
 [('Duda', 'Duda'), (',', ','), ('R.', 'R.'), ('O', 'O'), ('.', '.')]


------------------- Sentence 3 -------------------

& Hart, P. E. Pattern Classification and Scene Analysis (Wiley, 1973).

>> Tokens are: 
 ['&', 'Hart', ',', 'P.', 'E.', 'Pattern', 'Classification', 'Scene', 'Analysis', '(', 'Wiley', ',', '1973', ')', '.']

>> Bigrams are: 
 [('&', 'Hart'), ('Hart', ','), (',', 'P.'), ('P.', 'E.'), ('E.', 'Pattern'), ('Pattern', 'Classification'), ('Classification', 'Scene'), ('Scene', 'Analysis'), ('Analysis', '('), ('(', 'Wiley'), ('Wiley', ','), (',', '1973'), ('1973', ')'), (')', '.')]

>> Trigrams are: 
 [('&', 'Hart', ','), ('Hart', ',', 'P.'), (',', 'P.', 'E.'), ('P.', 'E.', 'Pattern'), ('E.', 'Pattern', 'Classification'), ('Pattern', 'Classification', 'Scene'), ('Classification', 'Scene', 'Analysis'), ('Scene', 'Analysis', '('), ('Analysis', '(', 'Wiley'), ('(', 'Wiley', ','), ('Wiley', ',', '1973'), (',', '1973', ')'), ('1973', ')', '.')]

>> POS Tags are: 
 [('&', 'CC'), ('Hart', 'NNP'), (',', ','), ('P.', 'NNP'), ('E.', 'NNP'), ('Pattern', 'NNP'), ('Classification', 'NNP'), ('Scene', 'NNP'), ('Analysis', 'NNP'), ('(', '('), ('Wiley', 'NNP'), (',', ','), ('1973', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['Hart', 'P. E. Pattern Classification Scene Analysis', 'Wiley']

>> Named Entities are: 
 [('PERSON', 'Hart'), ('PERSON', 'Pattern Classification Scene Analysis'), ('PERSON', 'Wiley')] 

>> Stemming using Porter Stemmer: 
 [('&', '&'), ('Hart', 'hart'), (',', ','), ('P.', 'p.'), ('E.', 'e.'), ('Pattern', 'pattern'), ('Classification', 'classif'), ('Scene', 'scene'), ('Analysis', 'analysi'), ('(', '('), ('Wiley', 'wiley'), (',', ','), ('1973', '1973'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('&', '&'), ('Hart', 'hart'), (',', ','), ('P.', 'p.'), ('E.', 'e.'), ('Pattern', 'pattern'), ('Classification', 'classif'), ('Scene', 'scene'), ('Analysis', 'analysi'), ('(', '('), ('Wiley', 'wiley'), (',', ','), ('1973', '1973'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('&', '&'), ('Hart', 'Hart'), (',', ','), ('P.', 'P.'), ('E.', 'E.'), ('Pattern', 'Pattern'), ('Classification', 'Classification'), ('Scene', 'Scene'), ('Analysis', 'Analysis'), ('(', '('), ('Wiley', 'Wiley'), (',', ','), ('1973', '1973'), (')', ')'), ('.', '.')]


------------------- Sentence 4 -------------------

20.

>> Tokens are: 
 ['20', '.']

>> Bigrams are: 
 [('20', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('20', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('20', '20'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('20', '20'), ('.', '.')]

>> Lemmatization: 
 [('20', '20'), ('.', '.')]


------------------- Sentence 5 -------------------

Schölkopf, B.

>> Tokens are: 
 ['Schölkopf', ',', 'B', '.']

>> Bigrams are: 
 [('Schölkopf', ','), (',', 'B'), ('B', '.')]

>> Trigrams are: 
 [('Schölkopf', ',', 'B'), (',', 'B', '.')]

>> POS Tags are: 
 [('Schölkopf', 'NNP'), (',', ','), ('B', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Schölkopf', 'B']

>> Named Entities are: 
 [('GPE', 'Schölkopf')] 

>> Stemming using Porter Stemmer: 
 [('Schölkopf', 'schölkopf'), (',', ','), ('B', 'b'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Schölkopf', 'schölkopf'), (',', ','), ('B', 'b'), ('.', '.')]

>> Lemmatization: 
 [('Schölkopf', 'Schölkopf'), (',', ','), ('B', 'B'), ('.', '.')]


------------------- Sentence 6 -------------------

& Smola, A.

>> Tokens are: 
 ['&', 'Smola', ',', 'A', '.']

>> Bigrams are: 
 [('&', 'Smola'), ('Smola', ','), (',', 'A'), ('A', '.')]

>> Trigrams are: 
 [('&', 'Smola', ','), ('Smola', ',', 'A'), (',', 'A', '.')]

>> POS Tags are: 
 [('&', 'CC'), ('Smola', 'NNP'), (',', ','), ('A', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Smola', 'A']

>> Named Entities are: 
 [('PERSON', 'Smola')] 

>> Stemming using Porter Stemmer: 
 [('&', '&'), ('Smola', 'smola'), (',', ','), ('A', 'a'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('&', '&'), ('Smola', 'smola'), (',', ','), ('A', 'a'), ('.', '.')]

>> Lemmatization: 
 [('&', '&'), ('Smola', 'Smola'), (',', ','), ('A', 'A'), ('.', '.')]


------------------- Sentence 7 -------------------

Learning with Kernels (MIT Press, 2002).

>> Tokens are: 
 ['Learning', 'Kernels', '(', 'MIT', 'Press', ',', '2002', ')', '.']

>> Bigrams are: 
 [('Learning', 'Kernels'), ('Kernels', '('), ('(', 'MIT'), ('MIT', 'Press'), ('Press', ','), (',', '2002'), ('2002', ')'), (')', '.')]

>> Trigrams are: 
 [('Learning', 'Kernels', '('), ('Kernels', '(', 'MIT'), ('(', 'MIT', 'Press'), ('MIT', 'Press', ','), ('Press', ',', '2002'), (',', '2002', ')'), ('2002', ')', '.')]

>> POS Tags are: 
 [('Learning', 'VBG'), ('Kernels', 'NNP'), ('(', '('), ('MIT', 'NNP'), ('Press', 'NNP'), (',', ','), ('2002', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['Kernels', 'MIT Press']

>> Named Entities are: 
 [('GPE', 'Kernels'), ('ORGANIZATION', 'MIT')] 

>> Stemming using Porter Stemmer: 
 [('Learning', 'learn'), ('Kernels', 'kernel'), ('(', '('), ('MIT', 'mit'), ('Press', 'press'), (',', ','), ('2002', '2002'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Learning', 'learn'), ('Kernels', 'kernel'), ('(', '('), ('MIT', 'mit'), ('Press', 'press'), (',', ','), ('2002', '2002'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Learning', 'Learning'), ('Kernels', 'Kernels'), ('(', '('), ('MIT', 'MIT'), ('Press', 'Press'), (',', ','), ('2002', '2002'), (')', ')'), ('.', '.')]


------------------- Sentence 8 -------------------

21.

>> Tokens are: 
 ['21', '.']

>> Bigrams are: 
 [('21', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('21', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('21', '21'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('21', '21'), ('.', '.')]

>> Lemmatization: 
 [('21', '21'), ('.', '.')]


------------------- Sentence 9 -------------------

Bengio, Y., Delalleau, O.

>> Tokens are: 
 ['Bengio', ',', 'Y.', ',', 'Delalleau', ',', 'O', '.']

>> Bigrams are: 
 [('Bengio', ','), (',', 'Y.'), ('Y.', ','), (',', 'Delalleau'), ('Delalleau', ','), (',', 'O'), ('O', '.')]

>> Trigrams are: 
 [('Bengio', ',', 'Y.'), (',', 'Y.', ','), ('Y.', ',', 'Delalleau'), (',', 'Delalleau', ','), ('Delalleau', ',', 'O'), (',', 'O', '.')]

>> POS Tags are: 
 [('Bengio', 'NNP'), (',', ','), ('Y.', 'NNP'), (',', ','), ('Delalleau', 'NNP'), (',', ','), ('O', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Bengio', 'Y.', 'Delalleau', 'O']

>> Named Entities are: 
 [('GPE', 'Bengio'), ('PERSON', 'Delalleau')] 

>> Stemming using Porter Stemmer: 
 [('Bengio', 'bengio'), (',', ','), ('Y.', 'y.'), (',', ','), ('Delalleau', 'delalleau'), (',', ','), ('O', 'o'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Bengio', 'bengio'), (',', ','), ('Y.', 'y.'), (',', ','), ('Delalleau', 'delalleau'), (',', ','), ('O', 'o'), ('.', '.')]

>> Lemmatization: 
 [('Bengio', 'Bengio'), (',', ','), ('Y.', 'Y.'), (',', ','), ('Delalleau', 'Delalleau'), (',', ','), ('O', 'O'), ('.', '.')]


------------------- Sentence 10 -------------------

& Le Roux, N. The curse of highly variable functions

>> Tokens are: 
 ['&', 'Le', 'Roux', ',', 'N.', 'The', 'curse', 'highly', 'variable', 'functions']

>> Bigrams are: 
 [('&', 'Le'), ('Le', 'Roux'), ('Roux', ','), (',', 'N.'), ('N.', 'The'), ('The', 'curse'), ('curse', 'highly'), ('highly', 'variable'), ('variable', 'functions')]

>> Trigrams are: 
 [('&', 'Le', 'Roux'), ('Le', 'Roux', ','), ('Roux', ',', 'N.'), (',', 'N.', 'The'), ('N.', 'The', 'curse'), ('The', 'curse', 'highly'), ('curse', 'highly', 'variable'), ('highly', 'variable', 'functions')]

>> POS Tags are: 
 [('&', 'CC'), ('Le', 'NNP'), ('Roux', 'NNP'), (',', ','), ('N.', 'NNP'), ('The', 'DT'), ('curse', 'NN'), ('highly', 'RB'), ('variable', 'JJ'), ('functions', 'NNS')]

>> Noun Phrases are: 
 ['Le Roux', 'N.', 'The curse', 'variable functions']

>> Named Entities are: 
 [('PERSON', 'Le Roux')] 

>> Stemming using Porter Stemmer: 
 [('&', '&'), ('Le', 'le'), ('Roux', 'roux'), (',', ','), ('N.', 'n.'), ('The', 'the'), ('curse', 'curs'), ('highly', 'highli'), ('variable', 'variabl'), ('functions', 'function')]

>> Stemming using Snowball Stemmer: 
 [('&', '&'), ('Le', 'le'), ('Roux', 'roux'), (',', ','), ('N.', 'n.'), ('The', 'the'), ('curse', 'curs'), ('highly', 'high'), ('variable', 'variabl'), ('functions', 'function')]

>> Lemmatization: 
 [('&', '&'), ('Le', 'Le'), ('Roux', 'Roux'), (',', ','), ('N.', 'N.'), ('The', 'The'), ('curse', 'curse'), ('highly', 'highly'), ('variable', 'variable'), ('functions', 'function')]



========================================== PARAGRAPH 266 ===========================================

for local kernel machines. In Proc. Advances in Neural Information Processing  Systems 18 107–114 (2005).  

------------------- Sentence 1 -------------------

for local kernel machines.

>> Tokens are: 
 ['local', 'kernel', 'machines', '.']

>> Bigrams are: 
 [('local', 'kernel'), ('kernel', 'machines'), ('machines', '.')]

>> Trigrams are: 
 [('local', 'kernel', 'machines'), ('kernel', 'machines', '.')]

>> POS Tags are: 
 [('local', 'JJ'), ('kernel', 'NN'), ('machines', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['local kernel machines']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('local', 'local'), ('kernel', 'kernel'), ('machines', 'machin'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('local', 'local'), ('kernel', 'kernel'), ('machines', 'machin'), ('.', '.')]

>> Lemmatization: 
 [('local', 'local'), ('kernel', 'kernel'), ('machines', 'machine'), ('.', '.')]


------------------- Sentence 2 -------------------

In Proc.

>> Tokens are: 
 ['In', 'Proc', '.']

>> Bigrams are: 
 [('In', 'Proc'), ('Proc', '.')]

>> Trigrams are: 
 [('In', 'Proc', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('Proc', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Proc']

>> Named Entities are: 
 [('GPE', 'Proc')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('Proc', 'proc'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('Proc', 'proc'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('Proc', 'Proc'), ('.', '.')]


------------------- Sentence 3 -------------------

Advances in Neural Information Processing  Systems 18 107–114 (2005).

>> Tokens are: 
 ['Advances', 'Neural', 'Information', 'Processing', 'Systems', '18', '107–114', '(', '2005', ')', '.']

>> Bigrams are: 
 [('Advances', 'Neural'), ('Neural', 'Information'), ('Information', 'Processing'), ('Processing', 'Systems'), ('Systems', '18'), ('18', '107–114'), ('107–114', '('), ('(', '2005'), ('2005', ')'), (')', '.')]

>> Trigrams are: 
 [('Advances', 'Neural', 'Information'), ('Neural', 'Information', 'Processing'), ('Information', 'Processing', 'Systems'), ('Processing', 'Systems', '18'), ('Systems', '18', '107–114'), ('18', '107–114', '('), ('107–114', '(', '2005'), ('(', '2005', ')'), ('2005', ')', '.')]

>> POS Tags are: 
 [('Advances', 'NNS'), ('Neural', 'NNP'), ('Information', 'NNP'), ('Processing', 'NNP'), ('Systems', 'NNPS'), ('18', 'CD'), ('107–114', 'CD'), ('(', '('), ('2005', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['Advances Neural Information Processing']

>> Named Entities are: 
 [('ORGANIZATION', 'Neural Information Processing Systems')] 

>> Stemming using Porter Stemmer: 
 [('Advances', 'advanc'), ('Neural', 'neural'), ('Information', 'inform'), ('Processing', 'process'), ('Systems', 'system'), ('18', '18'), ('107–114', '107–114'), ('(', '('), ('2005', '2005'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Advances', 'advanc'), ('Neural', 'neural'), ('Information', 'inform'), ('Processing', 'process'), ('Systems', 'system'), ('18', '18'), ('107–114', '107–114'), ('(', '('), ('2005', '2005'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Advances', 'Advances'), ('Neural', 'Neural'), ('Information', 'Information'), ('Processing', 'Processing'), ('Systems', 'Systems'), ('18', '18'), ('107–114', '107–114'), ('(', '('), ('2005', '2005'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 267 ===========================================

22. Selfridge, O. G. Pandemonium: a paradigm for learning in mechanisation of  thought processes. In Proc. Symposium on Mechanisation of Thought Processes  513–526 (1958).  

------------------- Sentence 1 -------------------

22.

>> Tokens are: 
 ['22', '.']

>> Bigrams are: 
 [('22', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('22', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('22', '22'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('22', '22'), ('.', '.')]

>> Lemmatization: 
 [('22', '22'), ('.', '.')]


------------------- Sentence 2 -------------------

Selfridge, O. G. Pandemonium: a paradigm for learning in mechanisation of  thought processes.

>> Tokens are: 
 ['Selfridge', ',', 'O.', 'G.', 'Pandemonium', ':', 'paradigm', 'learning', 'mechanisation', 'thought', 'processes', '.']

>> Bigrams are: 
 [('Selfridge', ','), (',', 'O.'), ('O.', 'G.'), ('G.', 'Pandemonium'), ('Pandemonium', ':'), (':', 'paradigm'), ('paradigm', 'learning'), ('learning', 'mechanisation'), ('mechanisation', 'thought'), ('thought', 'processes'), ('processes', '.')]

>> Trigrams are: 
 [('Selfridge', ',', 'O.'), (',', 'O.', 'G.'), ('O.', 'G.', 'Pandemonium'), ('G.', 'Pandemonium', ':'), ('Pandemonium', ':', 'paradigm'), (':', 'paradigm', 'learning'), ('paradigm', 'learning', 'mechanisation'), ('learning', 'mechanisation', 'thought'), ('mechanisation', 'thought', 'processes'), ('thought', 'processes', '.')]

>> POS Tags are: 
 [('Selfridge', 'NNP'), (',', ','), ('O.', 'NNP'), ('G.', 'NNP'), ('Pandemonium', 'NNP'), (':', ':'), ('paradigm', 'NN'), ('learning', 'VBG'), ('mechanisation', 'NN'), ('thought', 'VBD'), ('processes', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['Selfridge', 'O. G. Pandemonium', 'paradigm', 'mechanisation', 'processes']

>> Named Entities are: 
 [('GPE', 'Selfridge')] 

>> Stemming using Porter Stemmer: 
 [('Selfridge', 'selfridg'), (',', ','), ('O.', 'o.'), ('G.', 'g.'), ('Pandemonium', 'pandemonium'), (':', ':'), ('paradigm', 'paradigm'), ('learning', 'learn'), ('mechanisation', 'mechanis'), ('thought', 'thought'), ('processes', 'process'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Selfridge', 'selfridg'), (',', ','), ('O.', 'o.'), ('G.', 'g.'), ('Pandemonium', 'pandemonium'), (':', ':'), ('paradigm', 'paradigm'), ('learning', 'learn'), ('mechanisation', 'mechanis'), ('thought', 'thought'), ('processes', 'process'), ('.', '.')]

>> Lemmatization: 
 [('Selfridge', 'Selfridge'), (',', ','), ('O.', 'O.'), ('G.', 'G.'), ('Pandemonium', 'Pandemonium'), (':', ':'), ('paradigm', 'paradigm'), ('learning', 'learning'), ('mechanisation', 'mechanisation'), ('thought', 'thought'), ('processes', 'process'), ('.', '.')]


------------------- Sentence 3 -------------------

In Proc.

>> Tokens are: 
 ['In', 'Proc', '.']

>> Bigrams are: 
 [('In', 'Proc'), ('Proc', '.')]

>> Trigrams are: 
 [('In', 'Proc', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('Proc', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Proc']

>> Named Entities are: 
 [('GPE', 'Proc')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('Proc', 'proc'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('Proc', 'proc'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('Proc', 'Proc'), ('.', '.')]


------------------- Sentence 4 -------------------

Symposium on Mechanisation of Thought Processes  513–526 (1958).

>> Tokens are: 
 ['Symposium', 'Mechanisation', 'Thought', 'Processes', '513–526', '(', '1958', ')', '.']

>> Bigrams are: 
 [('Symposium', 'Mechanisation'), ('Mechanisation', 'Thought'), ('Thought', 'Processes'), ('Processes', '513–526'), ('513–526', '('), ('(', '1958'), ('1958', ')'), (')', '.')]

>> Trigrams are: 
 [('Symposium', 'Mechanisation', 'Thought'), ('Mechanisation', 'Thought', 'Processes'), ('Thought', 'Processes', '513–526'), ('Processes', '513–526', '('), ('513–526', '(', '1958'), ('(', '1958', ')'), ('1958', ')', '.')]

>> POS Tags are: 
 [('Symposium', 'NNP'), ('Mechanisation', 'NNP'), ('Thought', 'NNP'), ('Processes', 'VBZ'), ('513–526', 'CD'), ('(', '('), ('1958', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['Symposium Mechanisation Thought']

>> Named Entities are: 
 [('PERSON', 'Symposium'), ('ORGANIZATION', 'Mechanisation Thought')] 

>> Stemming using Porter Stemmer: 
 [('Symposium', 'symposium'), ('Mechanisation', 'mechanis'), ('Thought', 'thought'), ('Processes', 'process'), ('513–526', '513–526'), ('(', '('), ('1958', '1958'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Symposium', 'symposium'), ('Mechanisation', 'mechanis'), ('Thought', 'thought'), ('Processes', 'process'), ('513–526', '513–526'), ('(', '('), ('1958', '1958'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Symposium', 'Symposium'), ('Mechanisation', 'Mechanisation'), ('Thought', 'Thought'), ('Processes', 'Processes'), ('513–526', '513–526'), ('(', '('), ('1958', '1958'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 268 ===========================================

23. Rosenblatt, F. The Perceptron — A Perceiving and Recognizing Automaton. Tech.  Rep. 85-460-1 (Cornell Aeronautical Laboratory, 1957).  

------------------- Sentence 1 -------------------

23.

>> Tokens are: 
 ['23', '.']

>> Bigrams are: 
 [('23', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('23', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('23', '23'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('23', '23'), ('.', '.')]

>> Lemmatization: 
 [('23', '23'), ('.', '.')]


------------------- Sentence 2 -------------------

Rosenblatt, F. The Perceptron — A Perceiving and Recognizing Automaton.

>> Tokens are: 
 ['Rosenblatt', ',', 'F.', 'The', 'Perceptron', '—', 'A', 'Perceiving', 'Recognizing', 'Automaton', '.']

>> Bigrams are: 
 [('Rosenblatt', ','), (',', 'F.'), ('F.', 'The'), ('The', 'Perceptron'), ('Perceptron', '—'), ('—', 'A'), ('A', 'Perceiving'), ('Perceiving', 'Recognizing'), ('Recognizing', 'Automaton'), ('Automaton', '.')]

>> Trigrams are: 
 [('Rosenblatt', ',', 'F.'), (',', 'F.', 'The'), ('F.', 'The', 'Perceptron'), ('The', 'Perceptron', '—'), ('Perceptron', '—', 'A'), ('—', 'A', 'Perceiving'), ('A', 'Perceiving', 'Recognizing'), ('Perceiving', 'Recognizing', 'Automaton'), ('Recognizing', 'Automaton', '.')]

>> POS Tags are: 
 [('Rosenblatt', 'NNP'), (',', ','), ('F.', 'NNP'), ('The', 'DT'), ('Perceptron', 'NNP'), ('—', 'VBZ'), ('A', 'NNP'), ('Perceiving', 'NNP'), ('Recognizing', 'NNP'), ('Automaton', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Rosenblatt', 'F.', 'The Perceptron', 'A Perceiving Recognizing Automaton']

>> Named Entities are: 
 [('GPE', 'Rosenblatt'), ('ORGANIZATION', 'Perceptron')] 

>> Stemming using Porter Stemmer: 
 [('Rosenblatt', 'rosenblatt'), (',', ','), ('F.', 'f.'), ('The', 'the'), ('Perceptron', 'perceptron'), ('—', '—'), ('A', 'a'), ('Perceiving', 'perceiv'), ('Recognizing', 'recogn'), ('Automaton', 'automaton'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Rosenblatt', 'rosenblatt'), (',', ','), ('F.', 'f.'), ('The', 'the'), ('Perceptron', 'perceptron'), ('—', '—'), ('A', 'a'), ('Perceiving', 'perceiv'), ('Recognizing', 'recogn'), ('Automaton', 'automaton'), ('.', '.')]

>> Lemmatization: 
 [('Rosenblatt', 'Rosenblatt'), (',', ','), ('F.', 'F.'), ('The', 'The'), ('Perceptron', 'Perceptron'), ('—', '—'), ('A', 'A'), ('Perceiving', 'Perceiving'), ('Recognizing', 'Recognizing'), ('Automaton', 'Automaton'), ('.', '.')]


------------------- Sentence 3 -------------------

Tech.

>> Tokens are: 
 ['Tech', '.']

>> Bigrams are: 
 [('Tech', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Tech', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Tech']

>> Named Entities are: 
 [('GPE', 'Tech')] 

>> Stemming using Porter Stemmer: 
 [('Tech', 'tech'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Tech', 'tech'), ('.', '.')]

>> Lemmatization: 
 [('Tech', 'Tech'), ('.', '.')]


------------------- Sentence 4 -------------------

Rep. 85-460-1 (Cornell Aeronautical Laboratory, 1957).

>> Tokens are: 
 ['Rep.', '85-460-1', '(', 'Cornell', 'Aeronautical', 'Laboratory', ',', '1957', ')', '.']

>> Bigrams are: 
 [('Rep.', '85-460-1'), ('85-460-1', '('), ('(', 'Cornell'), ('Cornell', 'Aeronautical'), ('Aeronautical', 'Laboratory'), ('Laboratory', ','), (',', '1957'), ('1957', ')'), (')', '.')]

>> Trigrams are: 
 [('Rep.', '85-460-1', '('), ('85-460-1', '(', 'Cornell'), ('(', 'Cornell', 'Aeronautical'), ('Cornell', 'Aeronautical', 'Laboratory'), ('Aeronautical', 'Laboratory', ','), ('Laboratory', ',', '1957'), (',', '1957', ')'), ('1957', ')', '.')]

>> POS Tags are: 
 [('Rep.', 'NNP'), ('85-460-1', 'CD'), ('(', '('), ('Cornell', 'NNP'), ('Aeronautical', 'NNP'), ('Laboratory', 'NNP'), (',', ','), ('1957', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['Rep.', 'Cornell Aeronautical Laboratory']

>> Named Entities are: 
 [('ORGANIZATION', 'Cornell Aeronautical Laboratory')] 

>> Stemming using Porter Stemmer: 
 [('Rep.', 'rep.'), ('85-460-1', '85-460-1'), ('(', '('), ('Cornell', 'cornel'), ('Aeronautical', 'aeronaut'), ('Laboratory', 'laboratori'), (',', ','), ('1957', '1957'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Rep.', 'rep.'), ('85-460-1', '85-460-1'), ('(', '('), ('Cornell', 'cornel'), ('Aeronautical', 'aeronaut'), ('Laboratory', 'laboratori'), (',', ','), ('1957', '1957'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Rep.', 'Rep.'), ('85-460-1', '85-460-1'), ('(', '('), ('Cornell', 'Cornell'), ('Aeronautical', 'Aeronautical'), ('Laboratory', 'Laboratory'), (',', ','), ('1957', '1957'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 269 ===========================================

24. Werbos, P. Beyond Regression: New Tools for Prediction and Analysis in the  Behavioral Sciences. PhD thesis, Harvard Univ. (1974).  

------------------- Sentence 1 -------------------

24.

>> Tokens are: 
 ['24', '.']

>> Bigrams are: 
 [('24', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('24', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('24', '24'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('24', '24'), ('.', '.')]

>> Lemmatization: 
 [('24', '24'), ('.', '.')]


------------------- Sentence 2 -------------------

Werbos, P. Beyond Regression: New Tools for Prediction and Analysis in the  Behavioral Sciences.

>> Tokens are: 
 ['Werbos', ',', 'P.', 'Beyond', 'Regression', ':', 'New', 'Tools', 'Prediction', 'Analysis', 'Behavioral', 'Sciences', '.']

>> Bigrams are: 
 [('Werbos', ','), (',', 'P.'), ('P.', 'Beyond'), ('Beyond', 'Regression'), ('Regression', ':'), (':', 'New'), ('New', 'Tools'), ('Tools', 'Prediction'), ('Prediction', 'Analysis'), ('Analysis', 'Behavioral'), ('Behavioral', 'Sciences'), ('Sciences', '.')]

>> Trigrams are: 
 [('Werbos', ',', 'P.'), (',', 'P.', 'Beyond'), ('P.', 'Beyond', 'Regression'), ('Beyond', 'Regression', ':'), ('Regression', ':', 'New'), (':', 'New', 'Tools'), ('New', 'Tools', 'Prediction'), ('Tools', 'Prediction', 'Analysis'), ('Prediction', 'Analysis', 'Behavioral'), ('Analysis', 'Behavioral', 'Sciences'), ('Behavioral', 'Sciences', '.')]

>> POS Tags are: 
 [('Werbos', 'NNP'), (',', ','), ('P.', 'NNP'), ('Beyond', 'NNP'), ('Regression', 'NNP'), (':', ':'), ('New', 'NNP'), ('Tools', 'NNP'), ('Prediction', 'NNP'), ('Analysis', 'NNP'), ('Behavioral', 'NNP'), ('Sciences', 'NNPS'), ('.', '.')]

>> Noun Phrases are: 
 ['Werbos', 'P. Beyond Regression', 'New Tools Prediction Analysis Behavioral']

>> Named Entities are: 
 [('GPE', 'Werbos'), ('ORGANIZATION', 'Behavioral Sciences')] 

>> Stemming using Porter Stemmer: 
 [('Werbos', 'werbo'), (',', ','), ('P.', 'p.'), ('Beyond', 'beyond'), ('Regression', 'regress'), (':', ':'), ('New', 'new'), ('Tools', 'tool'), ('Prediction', 'predict'), ('Analysis', 'analysi'), ('Behavioral', 'behavior'), ('Sciences', 'scienc'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Werbos', 'werbo'), (',', ','), ('P.', 'p.'), ('Beyond', 'beyond'), ('Regression', 'regress'), (':', ':'), ('New', 'new'), ('Tools', 'tool'), ('Prediction', 'predict'), ('Analysis', 'analysi'), ('Behavioral', 'behavior'), ('Sciences', 'scienc'), ('.', '.')]

>> Lemmatization: 
 [('Werbos', 'Werbos'), (',', ','), ('P.', 'P.'), ('Beyond', 'Beyond'), ('Regression', 'Regression'), (':', ':'), ('New', 'New'), ('Tools', 'Tools'), ('Prediction', 'Prediction'), ('Analysis', 'Analysis'), ('Behavioral', 'Behavioral'), ('Sciences', 'Sciences'), ('.', '.')]


------------------- Sentence 3 -------------------

PhD thesis, Harvard Univ.

>> Tokens are: 
 ['PhD', 'thesis', ',', 'Harvard', 'Univ', '.']

>> Bigrams are: 
 [('PhD', 'thesis'), ('thesis', ','), (',', 'Harvard'), ('Harvard', 'Univ'), ('Univ', '.')]

>> Trigrams are: 
 [('PhD', 'thesis', ','), ('thesis', ',', 'Harvard'), (',', 'Harvard', 'Univ'), ('Harvard', 'Univ', '.')]

>> POS Tags are: 
 [('PhD', 'NNP'), ('thesis', 'NN'), (',', ','), ('Harvard', 'NNP'), ('Univ', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['PhD thesis', 'Harvard Univ']

>> Named Entities are: 
 [('PERSON', 'Harvard Univ')] 

>> Stemming using Porter Stemmer: 
 [('PhD', 'phd'), ('thesis', 'thesi'), (',', ','), ('Harvard', 'harvard'), ('Univ', 'univ'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('PhD', 'phd'), ('thesis', 'thesi'), (',', ','), ('Harvard', 'harvard'), ('Univ', 'univ'), ('.', '.')]

>> Lemmatization: 
 [('PhD', 'PhD'), ('thesis', 'thesis'), (',', ','), ('Harvard', 'Harvard'), ('Univ', 'Univ'), ('.', '.')]


------------------- Sentence 4 -------------------

(1974).

>> Tokens are: 
 ['(', '1974', ')', '.']

>> Bigrams are: 
 [('(', '1974'), ('1974', ')'), (')', '.')]

>> Trigrams are: 
 [('(', '1974', ')'), ('1974', ')', '.')]

>> POS Tags are: 
 [('(', '('), ('1974', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('1974', '1974'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('1974', '1974'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('(', '('), ('1974', '1974'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 270 ===========================================

25. Parker, D. B. Learning Logic Report TR–47 (MIT Press, 1985).  26. LeCun, Y. Une procédure d’apprentissage pour Réseau à seuil assymétrique  

------------------- Sentence 1 -------------------

25.

>> Tokens are: 
 ['25', '.']

>> Bigrams are: 
 [('25', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('25', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('25', '25'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('25', '25'), ('.', '.')]

>> Lemmatization: 
 [('25', '25'), ('.', '.')]


------------------- Sentence 2 -------------------

Parker, D. B.

>> Tokens are: 
 ['Parker', ',', 'D.', 'B', '.']

>> Bigrams are: 
 [('Parker', ','), (',', 'D.'), ('D.', 'B'), ('B', '.')]

>> Trigrams are: 
 [('Parker', ',', 'D.'), (',', 'D.', 'B'), ('D.', 'B', '.')]

>> POS Tags are: 
 [('Parker', 'NNP'), (',', ','), ('D.', 'NNP'), ('B', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Parker', 'D. B']

>> Named Entities are: 
 [('GPE', 'Parker')] 

>> Stemming using Porter Stemmer: 
 [('Parker', 'parker'), (',', ','), ('D.', 'd.'), ('B', 'b'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Parker', 'parker'), (',', ','), ('D.', 'd.'), ('B', 'b'), ('.', '.')]

>> Lemmatization: 
 [('Parker', 'Parker'), (',', ','), ('D.', 'D.'), ('B', 'B'), ('.', '.')]


------------------- Sentence 3 -------------------

Learning Logic Report TR–47 (MIT Press, 1985).

>> Tokens are: 
 ['Learning', 'Logic', 'Report', 'TR–47', '(', 'MIT', 'Press', ',', '1985', ')', '.']

>> Bigrams are: 
 [('Learning', 'Logic'), ('Logic', 'Report'), ('Report', 'TR–47'), ('TR–47', '('), ('(', 'MIT'), ('MIT', 'Press'), ('Press', ','), (',', '1985'), ('1985', ')'), (')', '.')]

>> Trigrams are: 
 [('Learning', 'Logic', 'Report'), ('Logic', 'Report', 'TR–47'), ('Report', 'TR–47', '('), ('TR–47', '(', 'MIT'), ('(', 'MIT', 'Press'), ('MIT', 'Press', ','), ('Press', ',', '1985'), (',', '1985', ')'), ('1985', ')', '.')]

>> POS Tags are: 
 [('Learning', 'VBG'), ('Logic', 'NNP'), ('Report', 'NNP'), ('TR–47', 'NNP'), ('(', '('), ('MIT', 'NNP'), ('Press', 'NNP'), (',', ','), ('1985', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['Logic Report TR–47', 'MIT Press']

>> Named Entities are: 
 [('PERSON', 'Logic Report'), ('ORGANIZATION', 'MIT')] 

>> Stemming using Porter Stemmer: 
 [('Learning', 'learn'), ('Logic', 'logic'), ('Report', 'report'), ('TR–47', 'tr–47'), ('(', '('), ('MIT', 'mit'), ('Press', 'press'), (',', ','), ('1985', '1985'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Learning', 'learn'), ('Logic', 'logic'), ('Report', 'report'), ('TR–47', 'tr–47'), ('(', '('), ('MIT', 'mit'), ('Press', 'press'), (',', ','), ('1985', '1985'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Learning', 'Learning'), ('Logic', 'Logic'), ('Report', 'Report'), ('TR–47', 'TR–47'), ('(', '('), ('MIT', 'MIT'), ('Press', 'Press'), (',', ','), ('1985', '1985'), (')', ')'), ('.', '.')]


------------------- Sentence 4 -------------------

26.

>> Tokens are: 
 ['26', '.']

>> Bigrams are: 
 [('26', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('26', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('26', '26'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('26', '26'), ('.', '.')]

>> Lemmatization: 
 [('26', '26'), ('.', '.')]


------------------- Sentence 5 -------------------

LeCun, Y. Une procédure d’apprentissage pour Réseau à seuil assymétrique

>> Tokens are: 
 ['LeCun', ',', 'Y.', 'Une', 'procédure', '’', 'apprentissage', 'pour', 'Réseau', 'à', 'seuil', 'assymétrique']

>> Bigrams are: 
 [('LeCun', ','), (',', 'Y.'), ('Y.', 'Une'), ('Une', 'procédure'), ('procédure', '’'), ('’', 'apprentissage'), ('apprentissage', 'pour'), ('pour', 'Réseau'), ('Réseau', 'à'), ('à', 'seuil'), ('seuil', 'assymétrique')]

>> Trigrams are: 
 [('LeCun', ',', 'Y.'), (',', 'Y.', 'Une'), ('Y.', 'Une', 'procédure'), ('Une', 'procédure', '’'), ('procédure', '’', 'apprentissage'), ('’', 'apprentissage', 'pour'), ('apprentissage', 'pour', 'Réseau'), ('pour', 'Réseau', 'à'), ('Réseau', 'à', 'seuil'), ('à', 'seuil', 'assymétrique')]

>> POS Tags are: 
 [('LeCun', 'NNP'), (',', ','), ('Y.', 'NNP'), ('Une', 'NNP'), ('procédure', 'NN'), ('’', 'NNP'), ('apprentissage', 'NN'), ('pour', 'NN'), ('Réseau', 'NNP'), ('à', 'NNP'), ('seuil', 'NN'), ('assymétrique', 'NN')]

>> Noun Phrases are: 
 ['LeCun', 'Y. Une procédure ’ apprentissage pour Réseau à seuil assymétrique']

>> Named Entities are: 
 [('GPE', 'LeCun'), ('PERSON', 'Réseau')] 

>> Stemming using Porter Stemmer: 
 [('LeCun', 'lecun'), (',', ','), ('Y.', 'y.'), ('Une', 'une'), ('procédure', 'procédur'), ('’', '’'), ('apprentissage', 'apprentissag'), ('pour', 'pour'), ('Réseau', 'réseau'), ('à', 'à'), ('seuil', 'seuil'), ('assymétrique', 'assymétriqu')]

>> Stemming using Snowball Stemmer: 
 [('LeCun', 'lecun'), (',', ','), ('Y.', 'y.'), ('Une', 'une'), ('procédure', 'procédur'), ('’', '’'), ('apprentissage', 'apprentissag'), ('pour', 'pour'), ('Réseau', 'réseau'), ('à', 'à'), ('seuil', 'seuil'), ('assymétrique', 'assymétriqu')]

>> Lemmatization: 
 [('LeCun', 'LeCun'), (',', ','), ('Y.', 'Y.'), ('Une', 'Une'), ('procédure', 'procédure'), ('’', '’'), ('apprentissage', 'apprentissage'), ('pour', 'pour'), ('Réseau', 'Réseau'), ('à', 'à'), ('seuil', 'seuil'), ('assymétrique', 'assymétrique')]



========================================== PARAGRAPH 271 ===========================================

in Cognitiva 85: a la Frontière de l’Intelligence Artificielle, des Sciences de la  Connaissance et des Neurosciences [in French] 599–604 (1985).  

------------------- Sentence 1 -------------------

in Cognitiva 85: a la Frontière de l’Intelligence Artificielle, des Sciences de la  Connaissance et des Neurosciences [in French] 599–604 (1985).

>> Tokens are: 
 ['Cognitiva', '85', ':', 'la', 'Frontière', 'de', 'l', '’', 'Intelligence', 'Artificielle', ',', 'des', 'Sciences', 'de', 'la', 'Connaissance', 'et', 'des', 'Neurosciences', '[', 'French', ']', '599–604', '(', '1985', ')', '.']

>> Bigrams are: 
 [('Cognitiva', '85'), ('85', ':'), (':', 'la'), ('la', 'Frontière'), ('Frontière', 'de'), ('de', 'l'), ('l', '’'), ('’', 'Intelligence'), ('Intelligence', 'Artificielle'), ('Artificielle', ','), (',', 'des'), ('des', 'Sciences'), ('Sciences', 'de'), ('de', 'la'), ('la', 'Connaissance'), ('Connaissance', 'et'), ('et', 'des'), ('des', 'Neurosciences'), ('Neurosciences', '['), ('[', 'French'), ('French', ']'), (']', '599–604'), ('599–604', '('), ('(', '1985'), ('1985', ')'), (')', '.')]

>> Trigrams are: 
 [('Cognitiva', '85', ':'), ('85', ':', 'la'), (':', 'la', 'Frontière'), ('la', 'Frontière', 'de'), ('Frontière', 'de', 'l'), ('de', 'l', '’'), ('l', '’', 'Intelligence'), ('’', 'Intelligence', 'Artificielle'), ('Intelligence', 'Artificielle', ','), ('Artificielle', ',', 'des'), (',', 'des', 'Sciences'), ('des', 'Sciences', 'de'), ('Sciences', 'de', 'la'), ('de', 'la', 'Connaissance'), ('la', 'Connaissance', 'et'), ('Connaissance', 'et', 'des'), ('et', 'des', 'Neurosciences'), ('des', 'Neurosciences', '['), ('Neurosciences', '[', 'French'), ('[', 'French', ']'), ('French', ']', '599–604'), (']', '599–604', '('), ('599–604', '(', '1985'), ('(', '1985', ')'), ('1985', ')', '.')]

>> POS Tags are: 
 [('Cognitiva', 'JJ'), ('85', 'CD'), (':', ':'), ('la', 'NN'), ('Frontière', 'NNP'), ('de', 'IN'), ('l', 'FW'), ('’', 'JJ'), ('Intelligence', 'NNP'), ('Artificielle', 'NNP'), (',', ','), ('des', 'VBZ'), ('Sciences', 'NNP'), ('de', 'NNP'), ('la', 'FW'), ('Connaissance', 'NNP'), ('et', 'FW'), ('des', 'NNS'), ('Neurosciences', 'NNPS'), ('[', 'NNP'), ('French', 'NNP'), (']', 'NNP'), ('599–604', 'CD'), ('(', '('), ('1985', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['la Frontière', '’ Intelligence Artificielle', 'Sciences de', 'Connaissance', 'des', '[ French ]']

>> Named Entities are: 
 [('PERSON', 'Frontière'), ('ORGANIZATION', 'Intelligence Artificielle'), ('PERSON', 'Sciences de'), ('PERSON', 'French')] 

>> Stemming using Porter Stemmer: 
 [('Cognitiva', 'cognitiva'), ('85', '85'), (':', ':'), ('la', 'la'), ('Frontière', 'frontièr'), ('de', 'de'), ('l', 'l'), ('’', '’'), ('Intelligence', 'intellig'), ('Artificielle', 'artificiel'), (',', ','), ('des', 'de'), ('Sciences', 'scienc'), ('de', 'de'), ('la', 'la'), ('Connaissance', 'connaiss'), ('et', 'et'), ('des', 'de'), ('Neurosciences', 'neurosci'), ('[', '['), ('French', 'french'), (']', ']'), ('599–604', '599–604'), ('(', '('), ('1985', '1985'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Cognitiva', 'cognitiva'), ('85', '85'), (':', ':'), ('la', 'la'), ('Frontière', 'frontièr'), ('de', 'de'), ('l', 'l'), ('’', '’'), ('Intelligence', 'intellig'), ('Artificielle', 'artificiell'), (',', ','), ('des', 'des'), ('Sciences', 'scienc'), ('de', 'de'), ('la', 'la'), ('Connaissance', 'connaiss'), ('et', 'et'), ('des', 'des'), ('Neurosciences', 'neurosci'), ('[', '['), ('French', 'french'), (']', ']'), ('599–604', '599–604'), ('(', '('), ('1985', '1985'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Cognitiva', 'Cognitiva'), ('85', '85'), (':', ':'), ('la', 'la'), ('Frontière', 'Frontière'), ('de', 'de'), ('l', 'l'), ('’', '’'), ('Intelligence', 'Intelligence'), ('Artificielle', 'Artificielle'), (',', ','), ('des', 'de'), ('Sciences', 'Sciences'), ('de', 'de'), ('la', 'la'), ('Connaissance', 'Connaissance'), ('et', 'et'), ('des', 'de'), ('Neurosciences', 'Neurosciences'), ('[', '['), ('French', 'French'), (']', ']'), ('599–604', '599–604'), ('(', '('), ('1985', '1985'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 272 ===========================================

27. Rumelhart, D. E., Hinton, G. E. & Williams, R. J. Learning representations by  back-propagating errors. Nature 323, 533–536 (1986).  

------------------- Sentence 1 -------------------

27.

>> Tokens are: 
 ['27', '.']

>> Bigrams are: 
 [('27', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('27', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('27', '27'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('27', '27'), ('.', '.')]

>> Lemmatization: 
 [('27', '27'), ('.', '.')]


------------------- Sentence 2 -------------------

Rumelhart, D. E., Hinton, G. E. & Williams, R. J.

>> Tokens are: 
 ['Rumelhart', ',', 'D.', 'E.', ',', 'Hinton', ',', 'G.', 'E.', '&', 'Williams', ',', 'R.', 'J', '.']

>> Bigrams are: 
 [('Rumelhart', ','), (',', 'D.'), ('D.', 'E.'), ('E.', ','), (',', 'Hinton'), ('Hinton', ','), (',', 'G.'), ('G.', 'E.'), ('E.', '&'), ('&', 'Williams'), ('Williams', ','), (',', 'R.'), ('R.', 'J'), ('J', '.')]

>> Trigrams are: 
 [('Rumelhart', ',', 'D.'), (',', 'D.', 'E.'), ('D.', 'E.', ','), ('E.', ',', 'Hinton'), (',', 'Hinton', ','), ('Hinton', ',', 'G.'), (',', 'G.', 'E.'), ('G.', 'E.', '&'), ('E.', '&', 'Williams'), ('&', 'Williams', ','), ('Williams', ',', 'R.'), (',', 'R.', 'J'), ('R.', 'J', '.')]

>> POS Tags are: 
 [('Rumelhart', 'NNP'), (',', ','), ('D.', 'NNP'), ('E.', 'NNP'), (',', ','), ('Hinton', 'NNP'), (',', ','), ('G.', 'NNP'), ('E.', 'NNP'), ('&', 'CC'), ('Williams', 'NNP'), (',', ','), ('R.', 'NNP'), ('J', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Rumelhart', 'D. E.', 'Hinton', 'G. E.', 'Williams', 'R. J']

>> Named Entities are: 
 [('GPE', 'Rumelhart'), ('GPE', 'Hinton'), ('PERSON', 'Williams')] 

>> Stemming using Porter Stemmer: 
 [('Rumelhart', 'rumelhart'), (',', ','), ('D.', 'd.'), ('E.', 'e.'), (',', ','), ('Hinton', 'hinton'), (',', ','), ('G.', 'g.'), ('E.', 'e.'), ('&', '&'), ('Williams', 'william'), (',', ','), ('R.', 'r.'), ('J', 'j'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Rumelhart', 'rumelhart'), (',', ','), ('D.', 'd.'), ('E.', 'e.'), (',', ','), ('Hinton', 'hinton'), (',', ','), ('G.', 'g.'), ('E.', 'e.'), ('&', '&'), ('Williams', 'william'), (',', ','), ('R.', 'r.'), ('J', 'j'), ('.', '.')]

>> Lemmatization: 
 [('Rumelhart', 'Rumelhart'), (',', ','), ('D.', 'D.'), ('E.', 'E.'), (',', ','), ('Hinton', 'Hinton'), (',', ','), ('G.', 'G.'), ('E.', 'E.'), ('&', '&'), ('Williams', 'Williams'), (',', ','), ('R.', 'R.'), ('J', 'J'), ('.', '.')]


------------------- Sentence 3 -------------------

Learning representations by  back-propagating errors.

>> Tokens are: 
 ['Learning', 'representations', 'back-propagating', 'errors', '.']

>> Bigrams are: 
 [('Learning', 'representations'), ('representations', 'back-propagating'), ('back-propagating', 'errors'), ('errors', '.')]

>> Trigrams are: 
 [('Learning', 'representations', 'back-propagating'), ('representations', 'back-propagating', 'errors'), ('back-propagating', 'errors', '.')]

>> POS Tags are: 
 [('Learning', 'VBG'), ('representations', 'NNS'), ('back-propagating', 'JJ'), ('errors', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['representations', 'back-propagating errors']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Learning', 'learn'), ('representations', 'represent'), ('back-propagating', 'back-propag'), ('errors', 'error'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Learning', 'learn'), ('representations', 'represent'), ('back-propagating', 'back-propag'), ('errors', 'error'), ('.', '.')]

>> Lemmatization: 
 [('Learning', 'Learning'), ('representations', 'representation'), ('back-propagating', 'back-propagating'), ('errors', 'error'), ('.', '.')]


------------------- Sentence 4 -------------------

Nature 323, 533–536 (1986).

>> Tokens are: 
 ['Nature', '323', ',', '533–536', '(', '1986', ')', '.']

>> Bigrams are: 
 [('Nature', '323'), ('323', ','), (',', '533–536'), ('533–536', '('), ('(', '1986'), ('1986', ')'), (')', '.')]

>> Trigrams are: 
 [('Nature', '323', ','), ('323', ',', '533–536'), (',', '533–536', '('), ('533–536', '(', '1986'), ('(', '1986', ')'), ('1986', ')', '.')]

>> POS Tags are: 
 [('Nature', 'NN'), ('323', 'CD'), (',', ','), ('533–536', 'CD'), ('(', '('), ('1986', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['Nature']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Nature', 'natur'), ('323', '323'), (',', ','), ('533–536', '533–536'), ('(', '('), ('1986', '1986'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Nature', 'natur'), ('323', '323'), (',', ','), ('533–536', '533–536'), ('(', '('), ('1986', '1986'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Nature', 'Nature'), ('323', '323'), (',', ','), ('533–536', '533–536'), ('(', '('), ('1986', '1986'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 273 ===========================================

28. Glorot, X., Bordes, A. & Bengio. Y. Deep sparse rectifier neural networks. In Proc.  14th International Conference on Artificial Intelligence and Statistics 315–323  (2011).  

------------------- Sentence 1 -------------------

28.

>> Tokens are: 
 ['28', '.']

>> Bigrams are: 
 [('28', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('28', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('28', '28'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('28', '28'), ('.', '.')]

>> Lemmatization: 
 [('28', '28'), ('.', '.')]


------------------- Sentence 2 -------------------

Glorot, X., Bordes, A.

>> Tokens are: 
 ['Glorot', ',', 'X.', ',', 'Bordes', ',', 'A', '.']

>> Bigrams are: 
 [('Glorot', ','), (',', 'X.'), ('X.', ','), (',', 'Bordes'), ('Bordes', ','), (',', 'A'), ('A', '.')]

>> Trigrams are: 
 [('Glorot', ',', 'X.'), (',', 'X.', ','), ('X.', ',', 'Bordes'), (',', 'Bordes', ','), ('Bordes', ',', 'A'), (',', 'A', '.')]

>> POS Tags are: 
 [('Glorot', 'NNP'), (',', ','), ('X.', 'NNP'), (',', ','), ('Bordes', 'NNP'), (',', ','), ('A', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Glorot', 'X.', 'Bordes', 'A']

>> Named Entities are: 
 [('GPE', 'Glorot'), ('GPE', 'Bordes')] 

>> Stemming using Porter Stemmer: 
 [('Glorot', 'glorot'), (',', ','), ('X.', 'x.'), (',', ','), ('Bordes', 'bord'), (',', ','), ('A', 'a'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Glorot', 'glorot'), (',', ','), ('X.', 'x.'), (',', ','), ('Bordes', 'bord'), (',', ','), ('A', 'a'), ('.', '.')]

>> Lemmatization: 
 [('Glorot', 'Glorot'), (',', ','), ('X.', 'X.'), (',', ','), ('Bordes', 'Bordes'), (',', ','), ('A', 'A'), ('.', '.')]


------------------- Sentence 3 -------------------

& Bengio.

>> Tokens are: 
 ['&', 'Bengio', '.']

>> Bigrams are: 
 [('&', 'Bengio'), ('Bengio', '.')]

>> Trigrams are: 
 [('&', 'Bengio', '.')]

>> POS Tags are: 
 [('&', 'CC'), ('Bengio', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Bengio']

>> Named Entities are: 
 [('PERSON', 'Bengio')] 

>> Stemming using Porter Stemmer: 
 [('&', '&'), ('Bengio', 'bengio'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('&', '&'), ('Bengio', 'bengio'), ('.', '.')]

>> Lemmatization: 
 [('&', '&'), ('Bengio', 'Bengio'), ('.', '.')]


------------------- Sentence 4 -------------------

Y.

>> Tokens are: 
 ['Y', '.']

>> Bigrams are: 
 [('Y', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Y', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Y']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Y', 'y'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Y', 'y'), ('.', '.')]

>> Lemmatization: 
 [('Y', 'Y'), ('.', '.')]


------------------- Sentence 5 -------------------

Deep sparse rectifier neural networks.

>> Tokens are: 
 ['Deep', 'sparse', 'rectifier', 'neural', 'networks', '.']

>> Bigrams are: 
 [('Deep', 'sparse'), ('sparse', 'rectifier'), ('rectifier', 'neural'), ('neural', 'networks'), ('networks', '.')]

>> Trigrams are: 
 [('Deep', 'sparse', 'rectifier'), ('sparse', 'rectifier', 'neural'), ('rectifier', 'neural', 'networks'), ('neural', 'networks', '.')]

>> POS Tags are: 
 [('Deep', 'JJ'), ('sparse', 'NN'), ('rectifier', 'JJ'), ('neural', 'JJ'), ('networks', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['Deep sparse', 'rectifier neural networks']

>> Named Entities are: 
 [('GPE', 'Deep')] 

>> Stemming using Porter Stemmer: 
 [('Deep', 'deep'), ('sparse', 'spars'), ('rectifier', 'rectifi'), ('neural', 'neural'), ('networks', 'network'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Deep', 'deep'), ('sparse', 'spars'), ('rectifier', 'rectifi'), ('neural', 'neural'), ('networks', 'network'), ('.', '.')]

>> Lemmatization: 
 [('Deep', 'Deep'), ('sparse', 'sparse'), ('rectifier', 'rectifier'), ('neural', 'neural'), ('networks', 'network'), ('.', '.')]


------------------- Sentence 6 -------------------

In Proc.

>> Tokens are: 
 ['In', 'Proc', '.']

>> Bigrams are: 
 [('In', 'Proc'), ('Proc', '.')]

>> Trigrams are: 
 [('In', 'Proc', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('Proc', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Proc']

>> Named Entities are: 
 [('GPE', 'Proc')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('Proc', 'proc'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('Proc', 'proc'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('Proc', 'Proc'), ('.', '.')]


------------------- Sentence 7 -------------------

14th International Conference on Artificial Intelligence and Statistics 315–323  (2011).

>> Tokens are: 
 ['14th', 'International', 'Conference', 'Artificial', 'Intelligence', 'Statistics', '315–323', '(', '2011', ')', '.']

>> Bigrams are: 
 [('14th', 'International'), ('International', 'Conference'), ('Conference', 'Artificial'), ('Artificial', 'Intelligence'), ('Intelligence', 'Statistics'), ('Statistics', '315–323'), ('315–323', '('), ('(', '2011'), ('2011', ')'), (')', '.')]

>> Trigrams are: 
 [('14th', 'International', 'Conference'), ('International', 'Conference', 'Artificial'), ('Conference', 'Artificial', 'Intelligence'), ('Artificial', 'Intelligence', 'Statistics'), ('Intelligence', 'Statistics', '315–323'), ('Statistics', '315–323', '('), ('315–323', '(', '2011'), ('(', '2011', ')'), ('2011', ')', '.')]

>> POS Tags are: 
 [('14th', 'CD'), ('International', 'NNP'), ('Conference', 'NNP'), ('Artificial', 'NNP'), ('Intelligence', 'NNP'), ('Statistics', 'NNPS'), ('315–323', 'CD'), ('(', '('), ('2011', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['International Conference Artificial Intelligence']

>> Named Entities are: 
 [('ORGANIZATION', 'International Conference Artificial Intelligence Statistics')] 

>> Stemming using Porter Stemmer: 
 [('14th', '14th'), ('International', 'intern'), ('Conference', 'confer'), ('Artificial', 'artifici'), ('Intelligence', 'intellig'), ('Statistics', 'statist'), ('315–323', '315–323'), ('(', '('), ('2011', '2011'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('14th', '14th'), ('International', 'intern'), ('Conference', 'confer'), ('Artificial', 'artifici'), ('Intelligence', 'intellig'), ('Statistics', 'statist'), ('315–323', '315–323'), ('(', '('), ('2011', '2011'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('14th', '14th'), ('International', 'International'), ('Conference', 'Conference'), ('Artificial', 'Artificial'), ('Intelligence', 'Intelligence'), ('Statistics', 'Statistics'), ('315–323', '315–323'), ('(', '('), ('2011', '2011'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 274 ===========================================

 This paper showed that supervised training of very deep neural networks is  much faster if the hidden layers are composed of ReLU. 

------------------- Sentence 1 -------------------

 This paper showed that supervised training of very deep neural networks is  much faster if the hidden layers are composed of ReLU.

>> Tokens are: 
 ['This', 'paper', 'showed', 'supervised', 'training', 'deep', 'neural', 'networks', 'much', 'faster', 'hidden', 'layers', 'composed', 'ReLU', '.']

>> Bigrams are: 
 [('This', 'paper'), ('paper', 'showed'), ('showed', 'supervised'), ('supervised', 'training'), ('training', 'deep'), ('deep', 'neural'), ('neural', 'networks'), ('networks', 'much'), ('much', 'faster'), ('faster', 'hidden'), ('hidden', 'layers'), ('layers', 'composed'), ('composed', 'ReLU'), ('ReLU', '.')]

>> Trigrams are: 
 [('This', 'paper', 'showed'), ('paper', 'showed', 'supervised'), ('showed', 'supervised', 'training'), ('supervised', 'training', 'deep'), ('training', 'deep', 'neural'), ('deep', 'neural', 'networks'), ('neural', 'networks', 'much'), ('networks', 'much', 'faster'), ('much', 'faster', 'hidden'), ('faster', 'hidden', 'layers'), ('hidden', 'layers', 'composed'), ('layers', 'composed', 'ReLU'), ('composed', 'ReLU', '.')]

>> POS Tags are: 
 [('This', 'DT'), ('paper', 'NN'), ('showed', 'VBD'), ('supervised', 'JJ'), ('training', 'NN'), ('deep', 'JJ'), ('neural', 'JJ'), ('networks', 'NNS'), ('much', 'RB'), ('faster', 'RBR'), ('hidden', 'JJ'), ('layers', 'NNS'), ('composed', 'VBD'), ('ReLU', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['This paper', 'supervised training', 'deep neural networks', 'hidden layers', 'ReLU']

>> Named Entities are: 
 [('ORGANIZATION', 'ReLU')] 

>> Stemming using Porter Stemmer: 
 [('This', 'thi'), ('paper', 'paper'), ('showed', 'show'), ('supervised', 'supervis'), ('training', 'train'), ('deep', 'deep'), ('neural', 'neural'), ('networks', 'network'), ('much', 'much'), ('faster', 'faster'), ('hidden', 'hidden'), ('layers', 'layer'), ('composed', 'compos'), ('ReLU', 'relu'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('This', 'this'), ('paper', 'paper'), ('showed', 'show'), ('supervised', 'supervis'), ('training', 'train'), ('deep', 'deep'), ('neural', 'neural'), ('networks', 'network'), ('much', 'much'), ('faster', 'faster'), ('hidden', 'hidden'), ('layers', 'layer'), ('composed', 'compos'), ('ReLU', 'relu'), ('.', '.')]

>> Lemmatization: 
 [('This', 'This'), ('paper', 'paper'), ('showed', 'showed'), ('supervised', 'supervised'), ('training', 'training'), ('deep', 'deep'), ('neural', 'neural'), ('networks', 'network'), ('much', 'much'), ('faster', 'faster'), ('hidden', 'hidden'), ('layers', 'layer'), ('composed', 'composed'), ('ReLU', 'ReLU'), ('.', '.')]



========================================== PARAGRAPH 275 ===========================================

29. Dauphin, Y. et al. Identifying and attacking the saddle point problem in high- dimensional non-convex optimization. In Proc. Advances in Neural Information  Processing Systems 27 2933–2941 (2014).  

------------------- Sentence 1 -------------------

29.

>> Tokens are: 
 ['29', '.']

>> Bigrams are: 
 [('29', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('29', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('29', '29'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('29', '29'), ('.', '.')]

>> Lemmatization: 
 [('29', '29'), ('.', '.')]


------------------- Sentence 2 -------------------

Dauphin, Y. et al.

>> Tokens are: 
 ['Dauphin', ',', 'Y.', 'et', 'al', '.']

>> Bigrams are: 
 [('Dauphin', ','), (',', 'Y.'), ('Y.', 'et'), ('et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('Dauphin', ',', 'Y.'), (',', 'Y.', 'et'), ('Y.', 'et', 'al'), ('et', 'al', '.')]

>> POS Tags are: 
 [('Dauphin', 'NNP'), (',', ','), ('Y.', 'NNP'), ('et', 'CC'), ('al', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Dauphin', 'Y.', 'al']

>> Named Entities are: 
 [('GPE', 'Dauphin')] 

>> Stemming using Porter Stemmer: 
 [('Dauphin', 'dauphin'), (',', ','), ('Y.', 'y.'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Dauphin', 'dauphin'), (',', ','), ('Y.', 'y.'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('Dauphin', 'Dauphin'), (',', ','), ('Y.', 'Y.'), ('et', 'et'), ('al', 'al'), ('.', '.')]


------------------- Sentence 3 -------------------

Identifying and attacking the saddle point problem in high- dimensional non-convex optimization.

>> Tokens are: 
 ['Identifying', 'attacking', 'saddle', 'point', 'problem', 'high-', 'dimensional', 'non-convex', 'optimization', '.']

>> Bigrams are: 
 [('Identifying', 'attacking'), ('attacking', 'saddle'), ('saddle', 'point'), ('point', 'problem'), ('problem', 'high-'), ('high-', 'dimensional'), ('dimensional', 'non-convex'), ('non-convex', 'optimization'), ('optimization', '.')]

>> Trigrams are: 
 [('Identifying', 'attacking', 'saddle'), ('attacking', 'saddle', 'point'), ('saddle', 'point', 'problem'), ('point', 'problem', 'high-'), ('problem', 'high-', 'dimensional'), ('high-', 'dimensional', 'non-convex'), ('dimensional', 'non-convex', 'optimization'), ('non-convex', 'optimization', '.')]

>> POS Tags are: 
 [('Identifying', 'VBG'), ('attacking', 'VBG'), ('saddle', 'JJ'), ('point', 'NN'), ('problem', 'NN'), ('high-', 'JJ'), ('dimensional', 'JJ'), ('non-convex', 'JJ'), ('optimization', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['saddle point problem', 'high- dimensional non-convex optimization']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Identifying', 'identifi'), ('attacking', 'attack'), ('saddle', 'saddl'), ('point', 'point'), ('problem', 'problem'), ('high-', 'high-'), ('dimensional', 'dimension'), ('non-convex', 'non-convex'), ('optimization', 'optim'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Identifying', 'identifi'), ('attacking', 'attack'), ('saddle', 'saddl'), ('point', 'point'), ('problem', 'problem'), ('high-', 'high-'), ('dimensional', 'dimension'), ('non-convex', 'non-convex'), ('optimization', 'optim'), ('.', '.')]

>> Lemmatization: 
 [('Identifying', 'Identifying'), ('attacking', 'attacking'), ('saddle', 'saddle'), ('point', 'point'), ('problem', 'problem'), ('high-', 'high-'), ('dimensional', 'dimensional'), ('non-convex', 'non-convex'), ('optimization', 'optimization'), ('.', '.')]


------------------- Sentence 4 -------------------

In Proc.

>> Tokens are: 
 ['In', 'Proc', '.']

>> Bigrams are: 
 [('In', 'Proc'), ('Proc', '.')]

>> Trigrams are: 
 [('In', 'Proc', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('Proc', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Proc']

>> Named Entities are: 
 [('GPE', 'Proc')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('Proc', 'proc'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('Proc', 'proc'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('Proc', 'Proc'), ('.', '.')]


------------------- Sentence 5 -------------------

Advances in Neural Information  Processing Systems 27 2933–2941 (2014).

>> Tokens are: 
 ['Advances', 'Neural', 'Information', 'Processing', 'Systems', '27', '2933–2941', '(', '2014', ')', '.']

>> Bigrams are: 
 [('Advances', 'Neural'), ('Neural', 'Information'), ('Information', 'Processing'), ('Processing', 'Systems'), ('Systems', '27'), ('27', '2933–2941'), ('2933–2941', '('), ('(', '2014'), ('2014', ')'), (')', '.')]

>> Trigrams are: 
 [('Advances', 'Neural', 'Information'), ('Neural', 'Information', 'Processing'), ('Information', 'Processing', 'Systems'), ('Processing', 'Systems', '27'), ('Systems', '27', '2933–2941'), ('27', '2933–2941', '('), ('2933–2941', '(', '2014'), ('(', '2014', ')'), ('2014', ')', '.')]

>> POS Tags are: 
 [('Advances', 'NNS'), ('Neural', 'NNP'), ('Information', 'NNP'), ('Processing', 'NNP'), ('Systems', 'NNPS'), ('27', 'CD'), ('2933–2941', 'CD'), ('(', '('), ('2014', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['Advances Neural Information Processing']

>> Named Entities are: 
 [('ORGANIZATION', 'Neural Information Processing Systems')] 

>> Stemming using Porter Stemmer: 
 [('Advances', 'advanc'), ('Neural', 'neural'), ('Information', 'inform'), ('Processing', 'process'), ('Systems', 'system'), ('27', '27'), ('2933–2941', '2933–2941'), ('(', '('), ('2014', '2014'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Advances', 'advanc'), ('Neural', 'neural'), ('Information', 'inform'), ('Processing', 'process'), ('Systems', 'system'), ('27', '27'), ('2933–2941', '2933–2941'), ('(', '('), ('2014', '2014'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Advances', 'Advances'), ('Neural', 'Neural'), ('Information', 'Information'), ('Processing', 'Processing'), ('Systems', 'Systems'), ('27', '27'), ('2933–2941', '2933–2941'), ('(', '('), ('2014', '2014'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 276 ===========================================

30. Choromanska, A., Henaff, M., Mathieu, M., Arous, G. B. & LeCun, Y. The loss  surface of multilayer networks. In Proc. Conference on AI and Statistics http:// arxiv.org/abs/1412.0233 (2014).  

------------------- Sentence 1 -------------------

30.

>> Tokens are: 
 ['30', '.']

>> Bigrams are: 
 [('30', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('30', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('30', '30'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('30', '30'), ('.', '.')]

>> Lemmatization: 
 [('30', '30'), ('.', '.')]


------------------- Sentence 2 -------------------

Choromanska, A., Henaff, M., Mathieu, M., Arous, G. B.

>> Tokens are: 
 ['Choromanska', ',', 'A.', ',', 'Henaff', ',', 'M.', ',', 'Mathieu', ',', 'M.', ',', 'Arous', ',', 'G.', 'B', '.']

>> Bigrams are: 
 [('Choromanska', ','), (',', 'A.'), ('A.', ','), (',', 'Henaff'), ('Henaff', ','), (',', 'M.'), ('M.', ','), (',', 'Mathieu'), ('Mathieu', ','), (',', 'M.'), ('M.', ','), (',', 'Arous'), ('Arous', ','), (',', 'G.'), ('G.', 'B'), ('B', '.')]

>> Trigrams are: 
 [('Choromanska', ',', 'A.'), (',', 'A.', ','), ('A.', ',', 'Henaff'), (',', 'Henaff', ','), ('Henaff', ',', 'M.'), (',', 'M.', ','), ('M.', ',', 'Mathieu'), (',', 'Mathieu', ','), ('Mathieu', ',', 'M.'), (',', 'M.', ','), ('M.', ',', 'Arous'), (',', 'Arous', ','), ('Arous', ',', 'G.'), (',', 'G.', 'B'), ('G.', 'B', '.')]

>> POS Tags are: 
 [('Choromanska', 'NNP'), (',', ','), ('A.', 'NNP'), (',', ','), ('Henaff', 'NNP'), (',', ','), ('M.', 'NNP'), (',', ','), ('Mathieu', 'NNP'), (',', ','), ('M.', 'NNP'), (',', ','), ('Arous', 'NNP'), (',', ','), ('G.', 'NNP'), ('B', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Choromanska', 'A.', 'Henaff', 'M.', 'Mathieu', 'M.', 'Arous', 'G. B']

>> Named Entities are: 
 [('GPE', 'Choromanska'), ('PERSON', 'Henaff'), ('PERSON', 'Mathieu'), ('PERSON', 'Arous')] 

>> Stemming using Porter Stemmer: 
 [('Choromanska', 'choromanska'), (',', ','), ('A.', 'a.'), (',', ','), ('Henaff', 'henaff'), (',', ','), ('M.', 'm.'), (',', ','), ('Mathieu', 'mathieu'), (',', ','), ('M.', 'm.'), (',', ','), ('Arous', 'arou'), (',', ','), ('G.', 'g.'), ('B', 'b'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Choromanska', 'choromanska'), (',', ','), ('A.', 'a.'), (',', ','), ('Henaff', 'henaff'), (',', ','), ('M.', 'm.'), (',', ','), ('Mathieu', 'mathieu'), (',', ','), ('M.', 'm.'), (',', ','), ('Arous', 'arous'), (',', ','), ('G.', 'g.'), ('B', 'b'), ('.', '.')]

>> Lemmatization: 
 [('Choromanska', 'Choromanska'), (',', ','), ('A.', 'A.'), (',', ','), ('Henaff', 'Henaff'), (',', ','), ('M.', 'M.'), (',', ','), ('Mathieu', 'Mathieu'), (',', ','), ('M.', 'M.'), (',', ','), ('Arous', 'Arous'), (',', ','), ('G.', 'G.'), ('B', 'B'), ('.', '.')]


------------------- Sentence 3 -------------------

& LeCun, Y.

>> Tokens are: 
 ['&', 'LeCun', ',', 'Y', '.']

>> Bigrams are: 
 [('&', 'LeCun'), ('LeCun', ','), (',', 'Y'), ('Y', '.')]

>> Trigrams are: 
 [('&', 'LeCun', ','), ('LeCun', ',', 'Y'), (',', 'Y', '.')]

>> POS Tags are: 
 [('&', 'CC'), ('LeCun', 'NNP'), (',', ','), ('Y', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['LeCun', 'Y']

>> Named Entities are: 
 [('ORGANIZATION', 'LeCun')] 

>> Stemming using Porter Stemmer: 
 [('&', '&'), ('LeCun', 'lecun'), (',', ','), ('Y', 'y'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('&', '&'), ('LeCun', 'lecun'), (',', ','), ('Y', 'y'), ('.', '.')]

>> Lemmatization: 
 [('&', '&'), ('LeCun', 'LeCun'), (',', ','), ('Y', 'Y'), ('.', '.')]


------------------- Sentence 4 -------------------

The loss  surface of multilayer networks.

>> Tokens are: 
 ['The', 'loss', 'surface', 'multilayer', 'networks', '.']

>> Bigrams are: 
 [('The', 'loss'), ('loss', 'surface'), ('surface', 'multilayer'), ('multilayer', 'networks'), ('networks', '.')]

>> Trigrams are: 
 [('The', 'loss', 'surface'), ('loss', 'surface', 'multilayer'), ('surface', 'multilayer', 'networks'), ('multilayer', 'networks', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('loss', 'NN'), ('surface', 'NN'), ('multilayer', 'NN'), ('networks', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['The loss surface multilayer networks']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('loss', 'loss'), ('surface', 'surfac'), ('multilayer', 'multilay'), ('networks', 'network'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('loss', 'loss'), ('surface', 'surfac'), ('multilayer', 'multilay'), ('networks', 'network'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('loss', 'loss'), ('surface', 'surface'), ('multilayer', 'multilayer'), ('networks', 'network'), ('.', '.')]


------------------- Sentence 5 -------------------

In Proc.

>> Tokens are: 
 ['In', 'Proc', '.']

>> Bigrams are: 
 [('In', 'Proc'), ('Proc', '.')]

>> Trigrams are: 
 [('In', 'Proc', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('Proc', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Proc']

>> Named Entities are: 
 [('GPE', 'Proc')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('Proc', 'proc'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('Proc', 'proc'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('Proc', 'Proc'), ('.', '.')]


------------------- Sentence 6 -------------------

Conference on AI and Statistics http:// arxiv.org/abs/1412.0233 (2014).

>> Tokens are: 
 ['Conference', 'AI', 'Statistics', 'http', ':', '//', 'arxiv.org/abs/1412.0233', '(', '2014', ')', '.']

>> Bigrams are: 
 [('Conference', 'AI'), ('AI', 'Statistics'), ('Statistics', 'http'), ('http', ':'), (':', '//'), ('//', 'arxiv.org/abs/1412.0233'), ('arxiv.org/abs/1412.0233', '('), ('(', '2014'), ('2014', ')'), (')', '.')]

>> Trigrams are: 
 [('Conference', 'AI', 'Statistics'), ('AI', 'Statistics', 'http'), ('Statistics', 'http', ':'), ('http', ':', '//'), (':', '//', 'arxiv.org/abs/1412.0233'), ('//', 'arxiv.org/abs/1412.0233', '('), ('arxiv.org/abs/1412.0233', '(', '2014'), ('(', '2014', ')'), ('2014', ')', '.')]

>> POS Tags are: 
 [('Conference', 'NN'), ('AI', 'NNP'), ('Statistics', 'NNPS'), ('http', 'NN'), (':', ':'), ('//', 'NN'), ('arxiv.org/abs/1412.0233', 'NN'), ('(', '('), ('2014', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['Conference AI', 'http', '// arxiv.org/abs/1412.0233']

>> Named Entities are: 
 [('ORGANIZATION', 'Conference'), ('ORGANIZATION', 'AI Statistics')] 

>> Stemming using Porter Stemmer: 
 [('Conference', 'confer'), ('AI', 'ai'), ('Statistics', 'statist'), ('http', 'http'), (':', ':'), ('//', '//'), ('arxiv.org/abs/1412.0233', 'arxiv.org/abs/1412.0233'), ('(', '('), ('2014', '2014'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Conference', 'confer'), ('AI', 'ai'), ('Statistics', 'statist'), ('http', 'http'), (':', ':'), ('//', '//'), ('arxiv.org/abs/1412.0233', 'arxiv.org/abs/1412.0233'), ('(', '('), ('2014', '2014'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Conference', 'Conference'), ('AI', 'AI'), ('Statistics', 'Statistics'), ('http', 'http'), (':', ':'), ('//', '//'), ('arxiv.org/abs/1412.0233', 'arxiv.org/abs/1412.0233'), ('(', '('), ('2014', '2014'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 277 ===========================================

31. Hinton, G. E. What kind of graphical model is the brain? In Proc. 19th  International Joint Conference on Artificial intelligence 1765–1775 (2005).  

------------------- Sentence 1 -------------------

31.

>> Tokens are: 
 ['31', '.']

>> Bigrams are: 
 [('31', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('31', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('31', '31'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('31', '31'), ('.', '.')]

>> Lemmatization: 
 [('31', '31'), ('.', '.')]


------------------- Sentence 2 -------------------

Hinton, G. E. What kind of graphical model is the brain?

>> Tokens are: 
 ['Hinton', ',', 'G.', 'E.', 'What', 'kind', 'graphical', 'model', 'brain', '?']

>> Bigrams are: 
 [('Hinton', ','), (',', 'G.'), ('G.', 'E.'), ('E.', 'What'), ('What', 'kind'), ('kind', 'graphical'), ('graphical', 'model'), ('model', 'brain'), ('brain', '?')]

>> Trigrams are: 
 [('Hinton', ',', 'G.'), (',', 'G.', 'E.'), ('G.', 'E.', 'What'), ('E.', 'What', 'kind'), ('What', 'kind', 'graphical'), ('kind', 'graphical', 'model'), ('graphical', 'model', 'brain'), ('model', 'brain', '?')]

>> POS Tags are: 
 [('Hinton', 'NNP'), (',', ','), ('G.', 'NNP'), ('E.', 'NNP'), ('What', 'WP'), ('kind', 'NN'), ('graphical', 'JJ'), ('model', 'NN'), ('brain', 'NN'), ('?', '.')]

>> Noun Phrases are: 
 ['Hinton', 'G. E.', 'kind', 'graphical model brain']

>> Named Entities are: 
 [('GPE', 'Hinton')] 

>> Stemming using Porter Stemmer: 
 [('Hinton', 'hinton'), (',', ','), ('G.', 'g.'), ('E.', 'e.'), ('What', 'what'), ('kind', 'kind'), ('graphical', 'graphic'), ('model', 'model'), ('brain', 'brain'), ('?', '?')]

>> Stemming using Snowball Stemmer: 
 [('Hinton', 'hinton'), (',', ','), ('G.', 'g.'), ('E.', 'e.'), ('What', 'what'), ('kind', 'kind'), ('graphical', 'graphic'), ('model', 'model'), ('brain', 'brain'), ('?', '?')]

>> Lemmatization: 
 [('Hinton', 'Hinton'), (',', ','), ('G.', 'G.'), ('E.', 'E.'), ('What', 'What'), ('kind', 'kind'), ('graphical', 'graphical'), ('model', 'model'), ('brain', 'brain'), ('?', '?')]


------------------- Sentence 3 -------------------

In Proc.

>> Tokens are: 
 ['In', 'Proc', '.']

>> Bigrams are: 
 [('In', 'Proc'), ('Proc', '.')]

>> Trigrams are: 
 [('In', 'Proc', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('Proc', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Proc']

>> Named Entities are: 
 [('GPE', 'Proc')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('Proc', 'proc'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('Proc', 'proc'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('Proc', 'Proc'), ('.', '.')]


------------------- Sentence 4 -------------------

19th  International Joint Conference on Artificial intelligence 1765–1775 (2005).

>> Tokens are: 
 ['19th', 'International', 'Joint', 'Conference', 'Artificial', 'intelligence', '1765–1775', '(', '2005', ')', '.']

>> Bigrams are: 
 [('19th', 'International'), ('International', 'Joint'), ('Joint', 'Conference'), ('Conference', 'Artificial'), ('Artificial', 'intelligence'), ('intelligence', '1765–1775'), ('1765–1775', '('), ('(', '2005'), ('2005', ')'), (')', '.')]

>> Trigrams are: 
 [('19th', 'International', 'Joint'), ('International', 'Joint', 'Conference'), ('Joint', 'Conference', 'Artificial'), ('Conference', 'Artificial', 'intelligence'), ('Artificial', 'intelligence', '1765–1775'), ('intelligence', '1765–1775', '('), ('1765–1775', '(', '2005'), ('(', '2005', ')'), ('2005', ')', '.')]

>> POS Tags are: 
 [('19th', 'CD'), ('International', 'NNP'), ('Joint', 'NNP'), ('Conference', 'NNP'), ('Artificial', 'NNP'), ('intelligence', 'NN'), ('1765–1775', 'CD'), ('(', '('), ('2005', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['International Joint Conference Artificial intelligence']

>> Named Entities are: 
 [('ORGANIZATION', 'International Joint Conference Artificial')] 

>> Stemming using Porter Stemmer: 
 [('19th', '19th'), ('International', 'intern'), ('Joint', 'joint'), ('Conference', 'confer'), ('Artificial', 'artifici'), ('intelligence', 'intellig'), ('1765–1775', '1765–1775'), ('(', '('), ('2005', '2005'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('19th', '19th'), ('International', 'intern'), ('Joint', 'joint'), ('Conference', 'confer'), ('Artificial', 'artifici'), ('intelligence', 'intellig'), ('1765–1775', '1765–1775'), ('(', '('), ('2005', '2005'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('19th', '19th'), ('International', 'International'), ('Joint', 'Joint'), ('Conference', 'Conference'), ('Artificial', 'Artificial'), ('intelligence', 'intelligence'), ('1765–1775', '1765–1775'), ('(', '('), ('2005', '2005'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 278 ===========================================

32. Hinton, G. E., Osindero, S. & Teh, Y.-W. A fast learning algorithm for deep belief  nets. Neural Comp. 18, 1527–1554 (2006). 

------------------- Sentence 1 -------------------

32.

>> Tokens are: 
 ['32', '.']

>> Bigrams are: 
 [('32', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('32', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('32', '32'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('32', '32'), ('.', '.')]

>> Lemmatization: 
 [('32', '32'), ('.', '.')]


------------------- Sentence 2 -------------------

Hinton, G. E., Osindero, S. & Teh, Y.-W. A fast learning algorithm for deep belief  nets.

>> Tokens are: 
 ['Hinton', ',', 'G.', 'E.', ',', 'Osindero', ',', 'S.', '&', 'Teh', ',', 'Y.-W.', 'A', 'fast', 'learning', 'algorithm', 'deep', 'belief', 'nets', '.']

>> Bigrams are: 
 [('Hinton', ','), (',', 'G.'), ('G.', 'E.'), ('E.', ','), (',', 'Osindero'), ('Osindero', ','), (',', 'S.'), ('S.', '&'), ('&', 'Teh'), ('Teh', ','), (',', 'Y.-W.'), ('Y.-W.', 'A'), ('A', 'fast'), ('fast', 'learning'), ('learning', 'algorithm'), ('algorithm', 'deep'), ('deep', 'belief'), ('belief', 'nets'), ('nets', '.')]

>> Trigrams are: 
 [('Hinton', ',', 'G.'), (',', 'G.', 'E.'), ('G.', 'E.', ','), ('E.', ',', 'Osindero'), (',', 'Osindero', ','), ('Osindero', ',', 'S.'), (',', 'S.', '&'), ('S.', '&', 'Teh'), ('&', 'Teh', ','), ('Teh', ',', 'Y.-W.'), (',', 'Y.-W.', 'A'), ('Y.-W.', 'A', 'fast'), ('A', 'fast', 'learning'), ('fast', 'learning', 'algorithm'), ('learning', 'algorithm', 'deep'), ('algorithm', 'deep', 'belief'), ('deep', 'belief', 'nets'), ('belief', 'nets', '.')]

>> POS Tags are: 
 [('Hinton', 'NNP'), (',', ','), ('G.', 'NNP'), ('E.', 'NNP'), (',', ','), ('Osindero', 'NNP'), (',', ','), ('S.', 'NNP'), ('&', 'CC'), ('Teh', 'NNP'), (',', ','), ('Y.-W.', 'NNP'), ('A', 'NNP'), ('fast', 'RB'), ('learning', 'VBG'), ('algorithm', 'JJ'), ('deep', 'JJ'), ('belief', 'NN'), ('nets', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['Hinton', 'G. E.', 'Osindero', 'S.', 'Teh', 'Y.-W. A', 'algorithm deep belief nets']

>> Named Entities are: 
 [('GPE', 'Hinton'), ('GPE', 'Osindero'), ('PERSON', 'Teh')] 

>> Stemming using Porter Stemmer: 
 [('Hinton', 'hinton'), (',', ','), ('G.', 'g.'), ('E.', 'e.'), (',', ','), ('Osindero', 'osindero'), (',', ','), ('S.', 's.'), ('&', '&'), ('Teh', 'teh'), (',', ','), ('Y.-W.', 'y.-w.'), ('A', 'a'), ('fast', 'fast'), ('learning', 'learn'), ('algorithm', 'algorithm'), ('deep', 'deep'), ('belief', 'belief'), ('nets', 'net'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Hinton', 'hinton'), (',', ','), ('G.', 'g.'), ('E.', 'e.'), (',', ','), ('Osindero', 'osindero'), (',', ','), ('S.', 's.'), ('&', '&'), ('Teh', 'teh'), (',', ','), ('Y.-W.', 'y.-w.'), ('A', 'a'), ('fast', 'fast'), ('learning', 'learn'), ('algorithm', 'algorithm'), ('deep', 'deep'), ('belief', 'belief'), ('nets', 'net'), ('.', '.')]

>> Lemmatization: 
 [('Hinton', 'Hinton'), (',', ','), ('G.', 'G.'), ('E.', 'E.'), (',', ','), ('Osindero', 'Osindero'), (',', ','), ('S.', 'S.'), ('&', '&'), ('Teh', 'Teh'), (',', ','), ('Y.-W.', 'Y.-W.'), ('A', 'A'), ('fast', 'fast'), ('learning', 'learning'), ('algorithm', 'algorithm'), ('deep', 'deep'), ('belief', 'belief'), ('nets', 'net'), ('.', '.')]


------------------- Sentence 3 -------------------

Neural Comp.

>> Tokens are: 
 ['Neural', 'Comp', '.']

>> Bigrams are: 
 [('Neural', 'Comp'), ('Comp', '.')]

>> Trigrams are: 
 [('Neural', 'Comp', '.')]

>> POS Tags are: 
 [('Neural', 'JJ'), ('Comp', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Neural Comp']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Neural', 'neural'), ('Comp', 'comp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Neural', 'neural'), ('Comp', 'comp'), ('.', '.')]

>> Lemmatization: 
 [('Neural', 'Neural'), ('Comp', 'Comp'), ('.', '.')]


------------------- Sentence 4 -------------------

18, 1527–1554 (2006).

>> Tokens are: 
 ['18', ',', '1527–1554', '(', '2006', ')', '.']

>> Bigrams are: 
 [('18', ','), (',', '1527–1554'), ('1527–1554', '('), ('(', '2006'), ('2006', ')'), (')', '.')]

>> Trigrams are: 
 [('18', ',', '1527–1554'), (',', '1527–1554', '('), ('1527–1554', '(', '2006'), ('(', '2006', ')'), ('2006', ')', '.')]

>> POS Tags are: 
 [('18', 'CD'), (',', ','), ('1527–1554', 'CD'), ('(', '('), ('2006', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('18', '18'), (',', ','), ('1527–1554', '1527–1554'), ('(', '('), ('2006', '2006'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('18', '18'), (',', ','), ('1527–1554', '1527–1554'), ('(', '('), ('2006', '2006'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('18', '18'), (',', ','), ('1527–1554', '1527–1554'), ('(', '('), ('2006', '2006'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 279 ===========================================

 This paper introduced a novel and effective way of training very deep neural  networks by pre-training one hidden layer at a time using the unsupervised  learning procedure for restricted Boltzmann machines.  

------------------- Sentence 1 -------------------

 This paper introduced a novel and effective way of training very deep neural  networks by pre-training one hidden layer at a time using the unsupervised  learning procedure for restricted Boltzmann machines.

>> Tokens are: 
 ['This', 'paper', 'introduced', 'novel', 'effective', 'way', 'training', 'deep', 'neural', 'networks', 'pre-training', 'one', 'hidden', 'layer', 'time', 'using', 'unsupervised', 'learning', 'procedure', 'restricted', 'Boltzmann', 'machines', '.']

>> Bigrams are: 
 [('This', 'paper'), ('paper', 'introduced'), ('introduced', 'novel'), ('novel', 'effective'), ('effective', 'way'), ('way', 'training'), ('training', 'deep'), ('deep', 'neural'), ('neural', 'networks'), ('networks', 'pre-training'), ('pre-training', 'one'), ('one', 'hidden'), ('hidden', 'layer'), ('layer', 'time'), ('time', 'using'), ('using', 'unsupervised'), ('unsupervised', 'learning'), ('learning', 'procedure'), ('procedure', 'restricted'), ('restricted', 'Boltzmann'), ('Boltzmann', 'machines'), ('machines', '.')]

>> Trigrams are: 
 [('This', 'paper', 'introduced'), ('paper', 'introduced', 'novel'), ('introduced', 'novel', 'effective'), ('novel', 'effective', 'way'), ('effective', 'way', 'training'), ('way', 'training', 'deep'), ('training', 'deep', 'neural'), ('deep', 'neural', 'networks'), ('neural', 'networks', 'pre-training'), ('networks', 'pre-training', 'one'), ('pre-training', 'one', 'hidden'), ('one', 'hidden', 'layer'), ('hidden', 'layer', 'time'), ('layer', 'time', 'using'), ('time', 'using', 'unsupervised'), ('using', 'unsupervised', 'learning'), ('unsupervised', 'learning', 'procedure'), ('learning', 'procedure', 'restricted'), ('procedure', 'restricted', 'Boltzmann'), ('restricted', 'Boltzmann', 'machines'), ('Boltzmann', 'machines', '.')]

>> POS Tags are: 
 [('This', 'DT'), ('paper', 'NN'), ('introduced', 'VBD'), ('novel', 'JJ'), ('effective', 'JJ'), ('way', 'NN'), ('training', 'VBG'), ('deep', 'JJ'), ('neural', 'JJ'), ('networks', 'NNS'), ('pre-training', 'VBG'), ('one', 'CD'), ('hidden', 'JJ'), ('layer', 'NN'), ('time', 'NN'), ('using', 'VBG'), ('unsupervised', 'JJ'), ('learning', 'JJ'), ('procedure', 'NN'), ('restricted', 'VBN'), ('Boltzmann', 'NNP'), ('machines', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['This paper', 'novel effective way', 'deep neural networks', 'hidden layer time', 'unsupervised learning procedure', 'Boltzmann machines']

>> Named Entities are: 
 [('ORGANIZATION', 'Boltzmann')] 

>> Stemming using Porter Stemmer: 
 [('This', 'thi'), ('paper', 'paper'), ('introduced', 'introduc'), ('novel', 'novel'), ('effective', 'effect'), ('way', 'way'), ('training', 'train'), ('deep', 'deep'), ('neural', 'neural'), ('networks', 'network'), ('pre-training', 'pre-train'), ('one', 'one'), ('hidden', 'hidden'), ('layer', 'layer'), ('time', 'time'), ('using', 'use'), ('unsupervised', 'unsupervis'), ('learning', 'learn'), ('procedure', 'procedur'), ('restricted', 'restrict'), ('Boltzmann', 'boltzmann'), ('machines', 'machin'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('This', 'this'), ('paper', 'paper'), ('introduced', 'introduc'), ('novel', 'novel'), ('effective', 'effect'), ('way', 'way'), ('training', 'train'), ('deep', 'deep'), ('neural', 'neural'), ('networks', 'network'), ('pre-training', 'pre-train'), ('one', 'one'), ('hidden', 'hidden'), ('layer', 'layer'), ('time', 'time'), ('using', 'use'), ('unsupervised', 'unsupervis'), ('learning', 'learn'), ('procedure', 'procedur'), ('restricted', 'restrict'), ('Boltzmann', 'boltzmann'), ('machines', 'machin'), ('.', '.')]

>> Lemmatization: 
 [('This', 'This'), ('paper', 'paper'), ('introduced', 'introduced'), ('novel', 'novel'), ('effective', 'effective'), ('way', 'way'), ('training', 'training'), ('deep', 'deep'), ('neural', 'neural'), ('networks', 'network'), ('pre-training', 'pre-training'), ('one', 'one'), ('hidden', 'hidden'), ('layer', 'layer'), ('time', 'time'), ('using', 'using'), ('unsupervised', 'unsupervised'), ('learning', 'learning'), ('procedure', 'procedure'), ('restricted', 'restricted'), ('Boltzmann', 'Boltzmann'), ('machines', 'machine'), ('.', '.')]



========================================== PARAGRAPH 280 ===========================================

33. Bengio, Y., Lamblin, P., Popovici, D. & Larochelle, H. Greedy layer-wise training  of deep networks. In Proc. Advances in Neural Information Processing Systems 19  153–160 (2006).  

------------------- Sentence 1 -------------------

33.

>> Tokens are: 
 ['33', '.']

>> Bigrams are: 
 [('33', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('33', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('33', '33'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('33', '33'), ('.', '.')]

>> Lemmatization: 
 [('33', '33'), ('.', '.')]


------------------- Sentence 2 -------------------

Bengio, Y., Lamblin, P., Popovici, D. & Larochelle, H. Greedy layer-wise training  of deep networks.

>> Tokens are: 
 ['Bengio', ',', 'Y.', ',', 'Lamblin', ',', 'P.', ',', 'Popovici', ',', 'D.', '&', 'Larochelle', ',', 'H.', 'Greedy', 'layer-wise', 'training', 'deep', 'networks', '.']

>> Bigrams are: 
 [('Bengio', ','), (',', 'Y.'), ('Y.', ','), (',', 'Lamblin'), ('Lamblin', ','), (',', 'P.'), ('P.', ','), (',', 'Popovici'), ('Popovici', ','), (',', 'D.'), ('D.', '&'), ('&', 'Larochelle'), ('Larochelle', ','), (',', 'H.'), ('H.', 'Greedy'), ('Greedy', 'layer-wise'), ('layer-wise', 'training'), ('training', 'deep'), ('deep', 'networks'), ('networks', '.')]

>> Trigrams are: 
 [('Bengio', ',', 'Y.'), (',', 'Y.', ','), ('Y.', ',', 'Lamblin'), (',', 'Lamblin', ','), ('Lamblin', ',', 'P.'), (',', 'P.', ','), ('P.', ',', 'Popovici'), (',', 'Popovici', ','), ('Popovici', ',', 'D.'), (',', 'D.', '&'), ('D.', '&', 'Larochelle'), ('&', 'Larochelle', ','), ('Larochelle', ',', 'H.'), (',', 'H.', 'Greedy'), ('H.', 'Greedy', 'layer-wise'), ('Greedy', 'layer-wise', 'training'), ('layer-wise', 'training', 'deep'), ('training', 'deep', 'networks'), ('deep', 'networks', '.')]

>> POS Tags are: 
 [('Bengio', 'NNP'), (',', ','), ('Y.', 'NNP'), (',', ','), ('Lamblin', 'NNP'), (',', ','), ('P.', 'NNP'), (',', ','), ('Popovici', 'NNP'), (',', ','), ('D.', 'NNP'), ('&', 'CC'), ('Larochelle', 'NNP'), (',', ','), ('H.', 'NNP'), ('Greedy', 'NNP'), ('layer-wise', 'JJ'), ('training', 'NN'), ('deep', 'JJ'), ('networks', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['Bengio', 'Y.', 'Lamblin', 'P.', 'Popovici', 'D.', 'Larochelle', 'H. Greedy', 'layer-wise training', 'deep networks']

>> Named Entities are: 
 [('GPE', 'Bengio'), ('PERSON', 'Lamblin'), ('GPE', 'Popovici'), ('GPE', 'Larochelle')] 

>> Stemming using Porter Stemmer: 
 [('Bengio', 'bengio'), (',', ','), ('Y.', 'y.'), (',', ','), ('Lamblin', 'lamblin'), (',', ','), ('P.', 'p.'), (',', ','), ('Popovici', 'popovici'), (',', ','), ('D.', 'd.'), ('&', '&'), ('Larochelle', 'larochel'), (',', ','), ('H.', 'h.'), ('Greedy', 'greedi'), ('layer-wise', 'layer-wis'), ('training', 'train'), ('deep', 'deep'), ('networks', 'network'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Bengio', 'bengio'), (',', ','), ('Y.', 'y.'), (',', ','), ('Lamblin', 'lamblin'), (',', ','), ('P.', 'p.'), (',', ','), ('Popovici', 'popovici'), (',', ','), ('D.', 'd.'), ('&', '&'), ('Larochelle', 'larochell'), (',', ','), ('H.', 'h.'), ('Greedy', 'greedi'), ('layer-wise', 'layer-wis'), ('training', 'train'), ('deep', 'deep'), ('networks', 'network'), ('.', '.')]

>> Lemmatization: 
 [('Bengio', 'Bengio'), (',', ','), ('Y.', 'Y.'), (',', ','), ('Lamblin', 'Lamblin'), (',', ','), ('P.', 'P.'), (',', ','), ('Popovici', 'Popovici'), (',', ','), ('D.', 'D.'), ('&', '&'), ('Larochelle', 'Larochelle'), (',', ','), ('H.', 'H.'), ('Greedy', 'Greedy'), ('layer-wise', 'layer-wise'), ('training', 'training'), ('deep', 'deep'), ('networks', 'network'), ('.', '.')]


------------------- Sentence 3 -------------------

In Proc.

>> Tokens are: 
 ['In', 'Proc', '.']

>> Bigrams are: 
 [('In', 'Proc'), ('Proc', '.')]

>> Trigrams are: 
 [('In', 'Proc', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('Proc', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Proc']

>> Named Entities are: 
 [('GPE', 'Proc')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('Proc', 'proc'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('Proc', 'proc'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('Proc', 'Proc'), ('.', '.')]


------------------- Sentence 4 -------------------

Advances in Neural Information Processing Systems 19  153–160 (2006).

>> Tokens are: 
 ['Advances', 'Neural', 'Information', 'Processing', 'Systems', '19', '153–160', '(', '2006', ')', '.']

>> Bigrams are: 
 [('Advances', 'Neural'), ('Neural', 'Information'), ('Information', 'Processing'), ('Processing', 'Systems'), ('Systems', '19'), ('19', '153–160'), ('153–160', '('), ('(', '2006'), ('2006', ')'), (')', '.')]

>> Trigrams are: 
 [('Advances', 'Neural', 'Information'), ('Neural', 'Information', 'Processing'), ('Information', 'Processing', 'Systems'), ('Processing', 'Systems', '19'), ('Systems', '19', '153–160'), ('19', '153–160', '('), ('153–160', '(', '2006'), ('(', '2006', ')'), ('2006', ')', '.')]

>> POS Tags are: 
 [('Advances', 'NNS'), ('Neural', 'NNP'), ('Information', 'NNP'), ('Processing', 'NNP'), ('Systems', 'NNPS'), ('19', 'CD'), ('153–160', 'CD'), ('(', '('), ('2006', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['Advances Neural Information Processing']

>> Named Entities are: 
 [('ORGANIZATION', 'Neural Information Processing Systems')] 

>> Stemming using Porter Stemmer: 
 [('Advances', 'advanc'), ('Neural', 'neural'), ('Information', 'inform'), ('Processing', 'process'), ('Systems', 'system'), ('19', '19'), ('153–160', '153–160'), ('(', '('), ('2006', '2006'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Advances', 'advanc'), ('Neural', 'neural'), ('Information', 'inform'), ('Processing', 'process'), ('Systems', 'system'), ('19', '19'), ('153–160', '153–160'), ('(', '('), ('2006', '2006'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Advances', 'Advances'), ('Neural', 'Neural'), ('Information', 'Information'), ('Processing', 'Processing'), ('Systems', 'Systems'), ('19', '19'), ('153–160', '153–160'), ('(', '('), ('2006', '2006'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 281 ===========================================

 This report demonstrated that the unsupervised pre-training method  introduced in ref. 32 significantly improves performance on test data and  generalizes the method to other unsupervised representation-learning  techniques, such as auto-encoders. 

------------------- Sentence 1 -------------------

 This report demonstrated that the unsupervised pre-training method  introduced in ref.

>> Tokens are: 
 ['This', 'report', 'demonstrated', 'unsupervised', 'pre-training', 'method', 'introduced', 'ref', '.']

>> Bigrams are: 
 [('This', 'report'), ('report', 'demonstrated'), ('demonstrated', 'unsupervised'), ('unsupervised', 'pre-training'), ('pre-training', 'method'), ('method', 'introduced'), ('introduced', 'ref'), ('ref', '.')]

>> Trigrams are: 
 [('This', 'report', 'demonstrated'), ('report', 'demonstrated', 'unsupervised'), ('demonstrated', 'unsupervised', 'pre-training'), ('unsupervised', 'pre-training', 'method'), ('pre-training', 'method', 'introduced'), ('method', 'introduced', 'ref'), ('introduced', 'ref', '.')]

>> POS Tags are: 
 [('This', 'DT'), ('report', 'NN'), ('demonstrated', 'VBD'), ('unsupervised', 'JJ'), ('pre-training', 'NN'), ('method', 'NN'), ('introduced', 'VBD'), ('ref', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['This report', 'unsupervised pre-training method', 'ref']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('This', 'thi'), ('report', 'report'), ('demonstrated', 'demonstr'), ('unsupervised', 'unsupervis'), ('pre-training', 'pre-train'), ('method', 'method'), ('introduced', 'introduc'), ('ref', 'ref'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('This', 'this'), ('report', 'report'), ('demonstrated', 'demonstr'), ('unsupervised', 'unsupervis'), ('pre-training', 'pre-train'), ('method', 'method'), ('introduced', 'introduc'), ('ref', 'ref'), ('.', '.')]

>> Lemmatization: 
 [('This', 'This'), ('report', 'report'), ('demonstrated', 'demonstrated'), ('unsupervised', 'unsupervised'), ('pre-training', 'pre-training'), ('method', 'method'), ('introduced', 'introduced'), ('ref', 'ref'), ('.', '.')]


------------------- Sentence 2 -------------------

32 significantly improves performance on test data and  generalizes the method to other unsupervised representation-learning  techniques, such as auto-encoders.

>> Tokens are: 
 ['32', 'significantly', 'improves', 'performance', 'test', 'data', 'generalizes', 'method', 'unsupervised', 'representation-learning', 'techniques', ',', 'auto-encoders', '.']

>> Bigrams are: 
 [('32', 'significantly'), ('significantly', 'improves'), ('improves', 'performance'), ('performance', 'test'), ('test', 'data'), ('data', 'generalizes'), ('generalizes', 'method'), ('method', 'unsupervised'), ('unsupervised', 'representation-learning'), ('representation-learning', 'techniques'), ('techniques', ','), (',', 'auto-encoders'), ('auto-encoders', '.')]

>> Trigrams are: 
 [('32', 'significantly', 'improves'), ('significantly', 'improves', 'performance'), ('improves', 'performance', 'test'), ('performance', 'test', 'data'), ('test', 'data', 'generalizes'), ('data', 'generalizes', 'method'), ('generalizes', 'method', 'unsupervised'), ('method', 'unsupervised', 'representation-learning'), ('unsupervised', 'representation-learning', 'techniques'), ('representation-learning', 'techniques', ','), ('techniques', ',', 'auto-encoders'), (',', 'auto-encoders', '.')]

>> POS Tags are: 
 [('32', 'CD'), ('significantly', 'RB'), ('improves', 'VBZ'), ('performance', 'NN'), ('test', 'NN'), ('data', 'NNS'), ('generalizes', 'NNS'), ('method', 'VBP'), ('unsupervised', 'JJ'), ('representation-learning', 'NN'), ('techniques', 'NNS'), (',', ','), ('auto-encoders', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['performance test data generalizes', 'unsupervised representation-learning techniques', 'auto-encoders']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('32', '32'), ('significantly', 'significantli'), ('improves', 'improv'), ('performance', 'perform'), ('test', 'test'), ('data', 'data'), ('generalizes', 'gener'), ('method', 'method'), ('unsupervised', 'unsupervis'), ('representation-learning', 'representation-learn'), ('techniques', 'techniqu'), (',', ','), ('auto-encoders', 'auto-encod'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('32', '32'), ('significantly', 'signific'), ('improves', 'improv'), ('performance', 'perform'), ('test', 'test'), ('data', 'data'), ('generalizes', 'general'), ('method', 'method'), ('unsupervised', 'unsupervis'), ('representation-learning', 'representation-learn'), ('techniques', 'techniqu'), (',', ','), ('auto-encoders', 'auto-encod'), ('.', '.')]

>> Lemmatization: 
 [('32', '32'), ('significantly', 'significantly'), ('improves', 'improves'), ('performance', 'performance'), ('test', 'test'), ('data', 'data'), ('generalizes', 'generalizes'), ('method', 'method'), ('unsupervised', 'unsupervised'), ('representation-learning', 'representation-learning'), ('techniques', 'technique'), (',', ','), ('auto-encoders', 'auto-encoders'), ('.', '.')]



========================================== PARAGRAPH 282 ===========================================

34. Ranzato, M., Poultney, C., Chopra, S. & LeCun, Y. Efficient learning of sparse  representations with an energy-based model. In Proc. Advances in Neural  Information Processing Systems 19 1137–1144 (2006).  

------------------- Sentence 1 -------------------

34.

>> Tokens are: 
 ['34', '.']

>> Bigrams are: 
 [('34', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('34', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('34', '34'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('34', '34'), ('.', '.')]

>> Lemmatization: 
 [('34', '34'), ('.', '.')]


------------------- Sentence 2 -------------------

Ranzato, M., Poultney, C., Chopra, S. & LeCun, Y.

>> Tokens are: 
 ['Ranzato', ',', 'M.', ',', 'Poultney', ',', 'C.', ',', 'Chopra', ',', 'S.', '&', 'LeCun', ',', 'Y', '.']

>> Bigrams are: 
 [('Ranzato', ','), (',', 'M.'), ('M.', ','), (',', 'Poultney'), ('Poultney', ','), (',', 'C.'), ('C.', ','), (',', 'Chopra'), ('Chopra', ','), (',', 'S.'), ('S.', '&'), ('&', 'LeCun'), ('LeCun', ','), (',', 'Y'), ('Y', '.')]

>> Trigrams are: 
 [('Ranzato', ',', 'M.'), (',', 'M.', ','), ('M.', ',', 'Poultney'), (',', 'Poultney', ','), ('Poultney', ',', 'C.'), (',', 'C.', ','), ('C.', ',', 'Chopra'), (',', 'Chopra', ','), ('Chopra', ',', 'S.'), (',', 'S.', '&'), ('S.', '&', 'LeCun'), ('&', 'LeCun', ','), ('LeCun', ',', 'Y'), (',', 'Y', '.')]

>> POS Tags are: 
 [('Ranzato', 'NNP'), (',', ','), ('M.', 'NNP'), (',', ','), ('Poultney', 'NNP'), (',', ','), ('C.', 'NNP'), (',', ','), ('Chopra', 'NNP'), (',', ','), ('S.', 'NNP'), ('&', 'CC'), ('LeCun', 'NNP'), (',', ','), ('Y', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Ranzato', 'M.', 'Poultney', 'C.', 'Chopra', 'S.', 'LeCun', 'Y']

>> Named Entities are: 
 [('GPE', 'Ranzato'), ('GPE', 'Poultney'), ('GPE', 'Chopra'), ('ORGANIZATION', 'LeCun')] 

>> Stemming using Porter Stemmer: 
 [('Ranzato', 'ranzato'), (',', ','), ('M.', 'm.'), (',', ','), ('Poultney', 'poultney'), (',', ','), ('C.', 'c.'), (',', ','), ('Chopra', 'chopra'), (',', ','), ('S.', 's.'), ('&', '&'), ('LeCun', 'lecun'), (',', ','), ('Y', 'y'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Ranzato', 'ranzato'), (',', ','), ('M.', 'm.'), (',', ','), ('Poultney', 'poultney'), (',', ','), ('C.', 'c.'), (',', ','), ('Chopra', 'chopra'), (',', ','), ('S.', 's.'), ('&', '&'), ('LeCun', 'lecun'), (',', ','), ('Y', 'y'), ('.', '.')]

>> Lemmatization: 
 [('Ranzato', 'Ranzato'), (',', ','), ('M.', 'M.'), (',', ','), ('Poultney', 'Poultney'), (',', ','), ('C.', 'C.'), (',', ','), ('Chopra', 'Chopra'), (',', ','), ('S.', 'S.'), ('&', '&'), ('LeCun', 'LeCun'), (',', ','), ('Y', 'Y'), ('.', '.')]


------------------- Sentence 3 -------------------

Efficient learning of sparse  representations with an energy-based model.

>> Tokens are: 
 ['Efficient', 'learning', 'sparse', 'representations', 'energy-based', 'model', '.']

>> Bigrams are: 
 [('Efficient', 'learning'), ('learning', 'sparse'), ('sparse', 'representations'), ('representations', 'energy-based'), ('energy-based', 'model'), ('model', '.')]

>> Trigrams are: 
 [('Efficient', 'learning', 'sparse'), ('learning', 'sparse', 'representations'), ('sparse', 'representations', 'energy-based'), ('representations', 'energy-based', 'model'), ('energy-based', 'model', '.')]

>> POS Tags are: 
 [('Efficient', 'JJ'), ('learning', 'VBG'), ('sparse', 'JJ'), ('representations', 'NNS'), ('energy-based', 'JJ'), ('model', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['sparse representations', 'energy-based model']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Efficient', 'effici'), ('learning', 'learn'), ('sparse', 'spars'), ('representations', 'represent'), ('energy-based', 'energy-bas'), ('model', 'model'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Efficient', 'effici'), ('learning', 'learn'), ('sparse', 'spars'), ('representations', 'represent'), ('energy-based', 'energy-bas'), ('model', 'model'), ('.', '.')]

>> Lemmatization: 
 [('Efficient', 'Efficient'), ('learning', 'learning'), ('sparse', 'sparse'), ('representations', 'representation'), ('energy-based', 'energy-based'), ('model', 'model'), ('.', '.')]


------------------- Sentence 4 -------------------

In Proc.

>> Tokens are: 
 ['In', 'Proc', '.']

>> Bigrams are: 
 [('In', 'Proc'), ('Proc', '.')]

>> Trigrams are: 
 [('In', 'Proc', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('Proc', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Proc']

>> Named Entities are: 
 [('GPE', 'Proc')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('Proc', 'proc'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('Proc', 'proc'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('Proc', 'Proc'), ('.', '.')]


------------------- Sentence 5 -------------------

Advances in Neural  Information Processing Systems 19 1137–1144 (2006).

>> Tokens are: 
 ['Advances', 'Neural', 'Information', 'Processing', 'Systems', '19', '1137–1144', '(', '2006', ')', '.']

>> Bigrams are: 
 [('Advances', 'Neural'), ('Neural', 'Information'), ('Information', 'Processing'), ('Processing', 'Systems'), ('Systems', '19'), ('19', '1137–1144'), ('1137–1144', '('), ('(', '2006'), ('2006', ')'), (')', '.')]

>> Trigrams are: 
 [('Advances', 'Neural', 'Information'), ('Neural', 'Information', 'Processing'), ('Information', 'Processing', 'Systems'), ('Processing', 'Systems', '19'), ('Systems', '19', '1137–1144'), ('19', '1137–1144', '('), ('1137–1144', '(', '2006'), ('(', '2006', ')'), ('2006', ')', '.')]

>> POS Tags are: 
 [('Advances', 'NNS'), ('Neural', 'NNP'), ('Information', 'NNP'), ('Processing', 'NNP'), ('Systems', 'NNPS'), ('19', 'CD'), ('1137–1144', 'CD'), ('(', '('), ('2006', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['Advances Neural Information Processing']

>> Named Entities are: 
 [('ORGANIZATION', 'Neural Information Processing Systems')] 

>> Stemming using Porter Stemmer: 
 [('Advances', 'advanc'), ('Neural', 'neural'), ('Information', 'inform'), ('Processing', 'process'), ('Systems', 'system'), ('19', '19'), ('1137–1144', '1137–1144'), ('(', '('), ('2006', '2006'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Advances', 'advanc'), ('Neural', 'neural'), ('Information', 'inform'), ('Processing', 'process'), ('Systems', 'system'), ('19', '19'), ('1137–1144', '1137–1144'), ('(', '('), ('2006', '2006'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Advances', 'Advances'), ('Neural', 'Neural'), ('Information', 'Information'), ('Processing', 'Processing'), ('Systems', 'Systems'), ('19', '19'), ('1137–1144', '1137–1144'), ('(', '('), ('2006', '2006'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 283 ===========================================

35. Hinton, G. E. & Salakhutdinov, R. Reducing the dimensionality of data with  neural networks. Science 313, 504–507 (2006).  

------------------- Sentence 1 -------------------

35.

>> Tokens are: 
 ['35', '.']

>> Bigrams are: 
 [('35', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('35', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('35', '35'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('35', '35'), ('.', '.')]

>> Lemmatization: 
 [('35', '35'), ('.', '.')]


------------------- Sentence 2 -------------------

Hinton, G. E. & Salakhutdinov, R. Reducing the dimensionality of data with  neural networks.

>> Tokens are: 
 ['Hinton', ',', 'G.', 'E.', '&', 'Salakhutdinov', ',', 'R.', 'Reducing', 'dimensionality', 'data', 'neural', 'networks', '.']

>> Bigrams are: 
 [('Hinton', ','), (',', 'G.'), ('G.', 'E.'), ('E.', '&'), ('&', 'Salakhutdinov'), ('Salakhutdinov', ','), (',', 'R.'), ('R.', 'Reducing'), ('Reducing', 'dimensionality'), ('dimensionality', 'data'), ('data', 'neural'), ('neural', 'networks'), ('networks', '.')]

>> Trigrams are: 
 [('Hinton', ',', 'G.'), (',', 'G.', 'E.'), ('G.', 'E.', '&'), ('E.', '&', 'Salakhutdinov'), ('&', 'Salakhutdinov', ','), ('Salakhutdinov', ',', 'R.'), (',', 'R.', 'Reducing'), ('R.', 'Reducing', 'dimensionality'), ('Reducing', 'dimensionality', 'data'), ('dimensionality', 'data', 'neural'), ('data', 'neural', 'networks'), ('neural', 'networks', '.')]

>> POS Tags are: 
 [('Hinton', 'NNP'), (',', ','), ('G.', 'NNP'), ('E.', 'NNP'), ('&', 'CC'), ('Salakhutdinov', 'NNP'), (',', ','), ('R.', 'NNP'), ('Reducing', 'NNP'), ('dimensionality', 'NN'), ('data', 'NNS'), ('neural', 'JJ'), ('networks', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['Hinton', 'G. E.', 'Salakhutdinov', 'R. Reducing dimensionality data', 'neural networks']

>> Named Entities are: 
 [('GPE', 'Hinton'), ('PERSON', 'Salakhutdinov')] 

>> Stemming using Porter Stemmer: 
 [('Hinton', 'hinton'), (',', ','), ('G.', 'g.'), ('E.', 'e.'), ('&', '&'), ('Salakhutdinov', 'salakhutdinov'), (',', ','), ('R.', 'r.'), ('Reducing', 'reduc'), ('dimensionality', 'dimension'), ('data', 'data'), ('neural', 'neural'), ('networks', 'network'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Hinton', 'hinton'), (',', ','), ('G.', 'g.'), ('E.', 'e.'), ('&', '&'), ('Salakhutdinov', 'salakhutdinov'), (',', ','), ('R.', 'r.'), ('Reducing', 'reduc'), ('dimensionality', 'dimension'), ('data', 'data'), ('neural', 'neural'), ('networks', 'network'), ('.', '.')]

>> Lemmatization: 
 [('Hinton', 'Hinton'), (',', ','), ('G.', 'G.'), ('E.', 'E.'), ('&', '&'), ('Salakhutdinov', 'Salakhutdinov'), (',', ','), ('R.', 'R.'), ('Reducing', 'Reducing'), ('dimensionality', 'dimensionality'), ('data', 'data'), ('neural', 'neural'), ('networks', 'network'), ('.', '.')]


------------------- Sentence 3 -------------------

Science 313, 504–507 (2006).

>> Tokens are: 
 ['Science', '313', ',', '504–507', '(', '2006', ')', '.']

>> Bigrams are: 
 [('Science', '313'), ('313', ','), (',', '504–507'), ('504–507', '('), ('(', '2006'), ('2006', ')'), (')', '.')]

>> Trigrams are: 
 [('Science', '313', ','), ('313', ',', '504–507'), (',', '504–507', '('), ('504–507', '(', '2006'), ('(', '2006', ')'), ('2006', ')', '.')]

>> POS Tags are: 
 [('Science', 'NN'), ('313', 'CD'), (',', ','), ('504–507', 'CD'), ('(', '('), ('2006', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['Science']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Science', 'scienc'), ('313', '313'), (',', ','), ('504–507', '504–507'), ('(', '('), ('2006', '2006'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Science', 'scienc'), ('313', '313'), (',', ','), ('504–507', '504–507'), ('(', '('), ('2006', '2006'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Science', 'Science'), ('313', '313'), (',', ','), ('504–507', '504–507'), ('(', '('), ('2006', '2006'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 284 ===========================================

36. Sermanet, P., Kavukcuoglu, K., Chintala, S. & LeCun, Y. Pedestrian detection with  unsupervised multi-stage feature learning. In Proc. International Conference  on Computer Vision and Pattern Recognition http://arxiv.org/abs/1212.0142  (2013).  

------------------- Sentence 1 -------------------

36.

>> Tokens are: 
 ['36', '.']

>> Bigrams are: 
 [('36', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('36', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('36', '36'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('36', '36'), ('.', '.')]

>> Lemmatization: 
 [('36', '36'), ('.', '.')]


------------------- Sentence 2 -------------------

Sermanet, P., Kavukcuoglu, K., Chintala, S. & LeCun, Y. Pedestrian detection with  unsupervised multi-stage feature learning.

>> Tokens are: 
 ['Sermanet', ',', 'P.', ',', 'Kavukcuoglu', ',', 'K.', ',', 'Chintala', ',', 'S.', '&', 'LeCun', ',', 'Y.', 'Pedestrian', 'detection', 'unsupervised', 'multi-stage', 'feature', 'learning', '.']

>> Bigrams are: 
 [('Sermanet', ','), (',', 'P.'), ('P.', ','), (',', 'Kavukcuoglu'), ('Kavukcuoglu', ','), (',', 'K.'), ('K.', ','), (',', 'Chintala'), ('Chintala', ','), (',', 'S.'), ('S.', '&'), ('&', 'LeCun'), ('LeCun', ','), (',', 'Y.'), ('Y.', 'Pedestrian'), ('Pedestrian', 'detection'), ('detection', 'unsupervised'), ('unsupervised', 'multi-stage'), ('multi-stage', 'feature'), ('feature', 'learning'), ('learning', '.')]

>> Trigrams are: 
 [('Sermanet', ',', 'P.'), (',', 'P.', ','), ('P.', ',', 'Kavukcuoglu'), (',', 'Kavukcuoglu', ','), ('Kavukcuoglu', ',', 'K.'), (',', 'K.', ','), ('K.', ',', 'Chintala'), (',', 'Chintala', ','), ('Chintala', ',', 'S.'), (',', 'S.', '&'), ('S.', '&', 'LeCun'), ('&', 'LeCun', ','), ('LeCun', ',', 'Y.'), (',', 'Y.', 'Pedestrian'), ('Y.', 'Pedestrian', 'detection'), ('Pedestrian', 'detection', 'unsupervised'), ('detection', 'unsupervised', 'multi-stage'), ('unsupervised', 'multi-stage', 'feature'), ('multi-stage', 'feature', 'learning'), ('feature', 'learning', '.')]

>> POS Tags are: 
 [('Sermanet', 'NNP'), (',', ','), ('P.', 'NNP'), (',', ','), ('Kavukcuoglu', 'NNP'), (',', ','), ('K.', 'NNP'), (',', ','), ('Chintala', 'NNP'), (',', ','), ('S.', 'NNP'), ('&', 'CC'), ('LeCun', 'NNP'), (',', ','), ('Y.', 'NNP'), ('Pedestrian', 'NNP'), ('detection', 'NN'), ('unsupervised', 'VBD'), ('multi-stage', 'JJ'), ('feature', 'NN'), ('learning', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Sermanet', 'P.', 'Kavukcuoglu', 'K.', 'Chintala', 'S.', 'LeCun', 'Y. Pedestrian detection', 'multi-stage feature learning']

>> Named Entities are: 
 [('GPE', 'Sermanet'), ('GPE', 'Kavukcuoglu'), ('GPE', 'Chintala'), ('ORGANIZATION', 'LeCun')] 

>> Stemming using Porter Stemmer: 
 [('Sermanet', 'sermanet'), (',', ','), ('P.', 'p.'), (',', ','), ('Kavukcuoglu', 'kavukcuoglu'), (',', ','), ('K.', 'k.'), (',', ','), ('Chintala', 'chintala'), (',', ','), ('S.', 's.'), ('&', '&'), ('LeCun', 'lecun'), (',', ','), ('Y.', 'y.'), ('Pedestrian', 'pedestrian'), ('detection', 'detect'), ('unsupervised', 'unsupervis'), ('multi-stage', 'multi-stag'), ('feature', 'featur'), ('learning', 'learn'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Sermanet', 'sermanet'), (',', ','), ('P.', 'p.'), (',', ','), ('Kavukcuoglu', 'kavukcuoglu'), (',', ','), ('K.', 'k.'), (',', ','), ('Chintala', 'chintala'), (',', ','), ('S.', 's.'), ('&', '&'), ('LeCun', 'lecun'), (',', ','), ('Y.', 'y.'), ('Pedestrian', 'pedestrian'), ('detection', 'detect'), ('unsupervised', 'unsupervis'), ('multi-stage', 'multi-stag'), ('feature', 'featur'), ('learning', 'learn'), ('.', '.')]

>> Lemmatization: 
 [('Sermanet', 'Sermanet'), (',', ','), ('P.', 'P.'), (',', ','), ('Kavukcuoglu', 'Kavukcuoglu'), (',', ','), ('K.', 'K.'), (',', ','), ('Chintala', 'Chintala'), (',', ','), ('S.', 'S.'), ('&', '&'), ('LeCun', 'LeCun'), (',', ','), ('Y.', 'Y.'), ('Pedestrian', 'Pedestrian'), ('detection', 'detection'), ('unsupervised', 'unsupervised'), ('multi-stage', 'multi-stage'), ('feature', 'feature'), ('learning', 'learning'), ('.', '.')]


------------------- Sentence 3 -------------------

In Proc.

>> Tokens are: 
 ['In', 'Proc', '.']

>> Bigrams are: 
 [('In', 'Proc'), ('Proc', '.')]

>> Trigrams are: 
 [('In', 'Proc', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('Proc', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Proc']

>> Named Entities are: 
 [('GPE', 'Proc')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('Proc', 'proc'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('Proc', 'proc'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('Proc', 'Proc'), ('.', '.')]


------------------- Sentence 4 -------------------

International Conference  on Computer Vision and Pattern Recognition http://arxiv.org/abs/1212.0142  (2013).

>> Tokens are: 
 ['International', 'Conference', 'Computer', 'Vision', 'Pattern', 'Recognition', 'http', ':', '//arxiv.org/abs/1212.0142', '(', '2013', ')', '.']

>> Bigrams are: 
 [('International', 'Conference'), ('Conference', 'Computer'), ('Computer', 'Vision'), ('Vision', 'Pattern'), ('Pattern', 'Recognition'), ('Recognition', 'http'), ('http', ':'), (':', '//arxiv.org/abs/1212.0142'), ('//arxiv.org/abs/1212.0142', '('), ('(', '2013'), ('2013', ')'), (')', '.')]

>> Trigrams are: 
 [('International', 'Conference', 'Computer'), ('Conference', 'Computer', 'Vision'), ('Computer', 'Vision', 'Pattern'), ('Vision', 'Pattern', 'Recognition'), ('Pattern', 'Recognition', 'http'), ('Recognition', 'http', ':'), ('http', ':', '//arxiv.org/abs/1212.0142'), (':', '//arxiv.org/abs/1212.0142', '('), ('//arxiv.org/abs/1212.0142', '(', '2013'), ('(', '2013', ')'), ('2013', ')', '.')]

>> POS Tags are: 
 [('International', 'NNP'), ('Conference', 'NNP'), ('Computer', 'NNP'), ('Vision', 'NNP'), ('Pattern', 'NNP'), ('Recognition', 'NNP'), ('http', 'NN'), (':', ':'), ('//arxiv.org/abs/1212.0142', 'NN'), ('(', '('), ('2013', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['International Conference Computer Vision Pattern Recognition http', '//arxiv.org/abs/1212.0142']

>> Named Entities are: 
 [('ORGANIZATION', 'International Conference Computer Vision Pattern')] 

>> Stemming using Porter Stemmer: 
 [('International', 'intern'), ('Conference', 'confer'), ('Computer', 'comput'), ('Vision', 'vision'), ('Pattern', 'pattern'), ('Recognition', 'recognit'), ('http', 'http'), (':', ':'), ('//arxiv.org/abs/1212.0142', '//arxiv.org/abs/1212.0142'), ('(', '('), ('2013', '2013'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('International', 'intern'), ('Conference', 'confer'), ('Computer', 'comput'), ('Vision', 'vision'), ('Pattern', 'pattern'), ('Recognition', 'recognit'), ('http', 'http'), (':', ':'), ('//arxiv.org/abs/1212.0142', '//arxiv.org/abs/1212.0142'), ('(', '('), ('2013', '2013'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('International', 'International'), ('Conference', 'Conference'), ('Computer', 'Computer'), ('Vision', 'Vision'), ('Pattern', 'Pattern'), ('Recognition', 'Recognition'), ('http', 'http'), (':', ':'), ('//arxiv.org/abs/1212.0142', '//arxiv.org/abs/1212.0142'), ('(', '('), ('2013', '2013'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 285 ===========================================

37. Raina, R., Madhavan, A. & Ng, A. Y. Large-scale deep unsupervised learning  using graphics processors. In Proc. 26th Annual International Conference on  Machine Learning 873–880 (2009).  

------------------- Sentence 1 -------------------

37.

>> Tokens are: 
 ['37', '.']

>> Bigrams are: 
 [('37', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('37', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('37', '37'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('37', '37'), ('.', '.')]

>> Lemmatization: 
 [('37', '37'), ('.', '.')]


------------------- Sentence 2 -------------------

Raina, R., Madhavan, A.

>> Tokens are: 
 ['Raina', ',', 'R.', ',', 'Madhavan', ',', 'A', '.']

>> Bigrams are: 
 [('Raina', ','), (',', 'R.'), ('R.', ','), (',', 'Madhavan'), ('Madhavan', ','), (',', 'A'), ('A', '.')]

>> Trigrams are: 
 [('Raina', ',', 'R.'), (',', 'R.', ','), ('R.', ',', 'Madhavan'), (',', 'Madhavan', ','), ('Madhavan', ',', 'A'), (',', 'A', '.')]

>> POS Tags are: 
 [('Raina', 'NNP'), (',', ','), ('R.', 'NNP'), (',', ','), ('Madhavan', 'NNP'), (',', ','), ('A', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Raina', 'R.', 'Madhavan', 'A']

>> Named Entities are: 
 [('GPE', 'Raina'), ('PERSON', 'Madhavan')] 

>> Stemming using Porter Stemmer: 
 [('Raina', 'raina'), (',', ','), ('R.', 'r.'), (',', ','), ('Madhavan', 'madhavan'), (',', ','), ('A', 'a'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Raina', 'raina'), (',', ','), ('R.', 'r.'), (',', ','), ('Madhavan', 'madhavan'), (',', ','), ('A', 'a'), ('.', '.')]

>> Lemmatization: 
 [('Raina', 'Raina'), (',', ','), ('R.', 'R.'), (',', ','), ('Madhavan', 'Madhavan'), (',', ','), ('A', 'A'), ('.', '.')]


------------------- Sentence 3 -------------------

& Ng, A. Y.

>> Tokens are: 
 ['&', 'Ng', ',', 'A.', 'Y', '.']

>> Bigrams are: 
 [('&', 'Ng'), ('Ng', ','), (',', 'A.'), ('A.', 'Y'), ('Y', '.')]

>> Trigrams are: 
 [('&', 'Ng', ','), ('Ng', ',', 'A.'), (',', 'A.', 'Y'), ('A.', 'Y', '.')]

>> POS Tags are: 
 [('&', 'CC'), ('Ng', 'NNP'), (',', ','), ('A.', 'NNP'), ('Y', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Ng', 'A. Y']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('&', '&'), ('Ng', 'ng'), (',', ','), ('A.', 'a.'), ('Y', 'y'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('&', '&'), ('Ng', 'ng'), (',', ','), ('A.', 'a.'), ('Y', 'y'), ('.', '.')]

>> Lemmatization: 
 [('&', '&'), ('Ng', 'Ng'), (',', ','), ('A.', 'A.'), ('Y', 'Y'), ('.', '.')]


------------------- Sentence 4 -------------------

Large-scale deep unsupervised learning  using graphics processors.

>> Tokens are: 
 ['Large-scale', 'deep', 'unsupervised', 'learning', 'using', 'graphics', 'processors', '.']

>> Bigrams are: 
 [('Large-scale', 'deep'), ('deep', 'unsupervised'), ('unsupervised', 'learning'), ('learning', 'using'), ('using', 'graphics'), ('graphics', 'processors'), ('processors', '.')]

>> Trigrams are: 
 [('Large-scale', 'deep', 'unsupervised'), ('deep', 'unsupervised', 'learning'), ('unsupervised', 'learning', 'using'), ('learning', 'using', 'graphics'), ('using', 'graphics', 'processors'), ('graphics', 'processors', '.')]

>> POS Tags are: 
 [('Large-scale', 'JJ'), ('deep', 'NN'), ('unsupervised', 'VBD'), ('learning', 'VBG'), ('using', 'VBG'), ('graphics', 'NNS'), ('processors', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['Large-scale deep', 'graphics processors']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Large-scale', 'large-scal'), ('deep', 'deep'), ('unsupervised', 'unsupervis'), ('learning', 'learn'), ('using', 'use'), ('graphics', 'graphic'), ('processors', 'processor'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Large-scale', 'large-scal'), ('deep', 'deep'), ('unsupervised', 'unsupervis'), ('learning', 'learn'), ('using', 'use'), ('graphics', 'graphic'), ('processors', 'processor'), ('.', '.')]

>> Lemmatization: 
 [('Large-scale', 'Large-scale'), ('deep', 'deep'), ('unsupervised', 'unsupervised'), ('learning', 'learning'), ('using', 'using'), ('graphics', 'graphic'), ('processors', 'processor'), ('.', '.')]


------------------- Sentence 5 -------------------

In Proc.

>> Tokens are: 
 ['In', 'Proc', '.']

>> Bigrams are: 
 [('In', 'Proc'), ('Proc', '.')]

>> Trigrams are: 
 [('In', 'Proc', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('Proc', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Proc']

>> Named Entities are: 
 [('GPE', 'Proc')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('Proc', 'proc'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('Proc', 'proc'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('Proc', 'Proc'), ('.', '.')]


------------------- Sentence 6 -------------------

26th Annual International Conference on  Machine Learning 873–880 (2009).

>> Tokens are: 
 ['26th', 'Annual', 'International', 'Conference', 'Machine', 'Learning', '873–880', '(', '2009', ')', '.']

>> Bigrams are: 
 [('26th', 'Annual'), ('Annual', 'International'), ('International', 'Conference'), ('Conference', 'Machine'), ('Machine', 'Learning'), ('Learning', '873–880'), ('873–880', '('), ('(', '2009'), ('2009', ')'), (')', '.')]

>> Trigrams are: 
 [('26th', 'Annual', 'International'), ('Annual', 'International', 'Conference'), ('International', 'Conference', 'Machine'), ('Conference', 'Machine', 'Learning'), ('Machine', 'Learning', '873–880'), ('Learning', '873–880', '('), ('873–880', '(', '2009'), ('(', '2009', ')'), ('2009', ')', '.')]

>> POS Tags are: 
 [('26th', 'CD'), ('Annual', 'NNP'), ('International', 'NNP'), ('Conference', 'NNP'), ('Machine', 'NNP'), ('Learning', 'NNP'), ('873–880', 'CD'), ('(', '('), ('2009', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['Annual International Conference Machine Learning']

>> Named Entities are: 
 [('PERSON', 'Annual International Conference Machine')] 

>> Stemming using Porter Stemmer: 
 [('26th', '26th'), ('Annual', 'annual'), ('International', 'intern'), ('Conference', 'confer'), ('Machine', 'machin'), ('Learning', 'learn'), ('873–880', '873–880'), ('(', '('), ('2009', '2009'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('26th', '26th'), ('Annual', 'annual'), ('International', 'intern'), ('Conference', 'confer'), ('Machine', 'machin'), ('Learning', 'learn'), ('873–880', '873–880'), ('(', '('), ('2009', '2009'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('26th', '26th'), ('Annual', 'Annual'), ('International', 'International'), ('Conference', 'Conference'), ('Machine', 'Machine'), ('Learning', 'Learning'), ('873–880', '873–880'), ('(', '('), ('2009', '2009'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 286 ===========================================

38. Mohamed, A.-R., Dahl, G. E. & Hinton, G. Acoustic modeling using deep belief  networks. IEEE Trans. Audio Speech Lang. Process. 20, 14–22 (2012).  

------------------- Sentence 1 -------------------

38.

>> Tokens are: 
 ['38', '.']

>> Bigrams are: 
 [('38', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('38', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('38', '38'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('38', '38'), ('.', '.')]

>> Lemmatization: 
 [('38', '38'), ('.', '.')]


------------------- Sentence 2 -------------------

Mohamed, A.-R., Dahl, G. E. & Hinton, G. Acoustic modeling using deep belief  networks.

>> Tokens are: 
 ['Mohamed', ',', 'A.-R.', ',', 'Dahl', ',', 'G.', 'E.', '&', 'Hinton', ',', 'G.', 'Acoustic', 'modeling', 'using', 'deep', 'belief', 'networks', '.']

>> Bigrams are: 
 [('Mohamed', ','), (',', 'A.-R.'), ('A.-R.', ','), (',', 'Dahl'), ('Dahl', ','), (',', 'G.'), ('G.', 'E.'), ('E.', '&'), ('&', 'Hinton'), ('Hinton', ','), (',', 'G.'), ('G.', 'Acoustic'), ('Acoustic', 'modeling'), ('modeling', 'using'), ('using', 'deep'), ('deep', 'belief'), ('belief', 'networks'), ('networks', '.')]

>> Trigrams are: 
 [('Mohamed', ',', 'A.-R.'), (',', 'A.-R.', ','), ('A.-R.', ',', 'Dahl'), (',', 'Dahl', ','), ('Dahl', ',', 'G.'), (',', 'G.', 'E.'), ('G.', 'E.', '&'), ('E.', '&', 'Hinton'), ('&', 'Hinton', ','), ('Hinton', ',', 'G.'), (',', 'G.', 'Acoustic'), ('G.', 'Acoustic', 'modeling'), ('Acoustic', 'modeling', 'using'), ('modeling', 'using', 'deep'), ('using', 'deep', 'belief'), ('deep', 'belief', 'networks'), ('belief', 'networks', '.')]

>> POS Tags are: 
 [('Mohamed', 'NNP'), (',', ','), ('A.-R.', 'NNP'), (',', ','), ('Dahl', 'NNP'), (',', ','), ('G.', 'NNP'), ('E.', 'NNP'), ('&', 'CC'), ('Hinton', 'NNP'), (',', ','), ('G.', 'NNP'), ('Acoustic', 'NNP'), ('modeling', 'VBG'), ('using', 'VBG'), ('deep', 'JJ'), ('belief', 'NN'), ('networks', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['Mohamed', 'A.-R.', 'Dahl', 'G. E.', 'Hinton', 'G. Acoustic', 'deep belief networks']

>> Named Entities are: 
 [('GPE', 'Mohamed'), ('PERSON', 'Dahl'), ('GPE', 'Hinton')] 

>> Stemming using Porter Stemmer: 
 [('Mohamed', 'moham'), (',', ','), ('A.-R.', 'a.-r.'), (',', ','), ('Dahl', 'dahl'), (',', ','), ('G.', 'g.'), ('E.', 'e.'), ('&', '&'), ('Hinton', 'hinton'), (',', ','), ('G.', 'g.'), ('Acoustic', 'acoust'), ('modeling', 'model'), ('using', 'use'), ('deep', 'deep'), ('belief', 'belief'), ('networks', 'network'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Mohamed', 'moham'), (',', ','), ('A.-R.', 'a.-r.'), (',', ','), ('Dahl', 'dahl'), (',', ','), ('G.', 'g.'), ('E.', 'e.'), ('&', '&'), ('Hinton', 'hinton'), (',', ','), ('G.', 'g.'), ('Acoustic', 'acoust'), ('modeling', 'model'), ('using', 'use'), ('deep', 'deep'), ('belief', 'belief'), ('networks', 'network'), ('.', '.')]

>> Lemmatization: 
 [('Mohamed', 'Mohamed'), (',', ','), ('A.-R.', 'A.-R.'), (',', ','), ('Dahl', 'Dahl'), (',', ','), ('G.', 'G.'), ('E.', 'E.'), ('&', '&'), ('Hinton', 'Hinton'), (',', ','), ('G.', 'G.'), ('Acoustic', 'Acoustic'), ('modeling', 'modeling'), ('using', 'using'), ('deep', 'deep'), ('belief', 'belief'), ('networks', 'network'), ('.', '.')]


------------------- Sentence 3 -------------------

IEEE Trans.

>> Tokens are: 
 ['IEEE', 'Trans', '.']

>> Bigrams are: 
 [('IEEE', 'Trans'), ('Trans', '.')]

>> Trigrams are: 
 [('IEEE', 'Trans', '.')]

>> POS Tags are: 
 [('IEEE', 'NNP'), ('Trans', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['IEEE Trans']

>> Named Entities are: 
 [('ORGANIZATION', 'IEEE Trans')] 

>> Stemming using Porter Stemmer: 
 [('IEEE', 'ieee'), ('Trans', 'tran'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('IEEE', 'ieee'), ('Trans', 'tran'), ('.', '.')]

>> Lemmatization: 
 [('IEEE', 'IEEE'), ('Trans', 'Trans'), ('.', '.')]


------------------- Sentence 4 -------------------

Audio Speech Lang.

>> Tokens are: 
 ['Audio', 'Speech', 'Lang', '.']

>> Bigrams are: 
 [('Audio', 'Speech'), ('Speech', 'Lang'), ('Lang', '.')]

>> Trigrams are: 
 [('Audio', 'Speech', 'Lang'), ('Speech', 'Lang', '.')]

>> POS Tags are: 
 [('Audio', 'NNP'), ('Speech', 'NNP'), ('Lang', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Audio Speech Lang']

>> Named Entities are: 
 [('PERSON', 'Audio'), ('PERSON', 'Speech Lang')] 

>> Stemming using Porter Stemmer: 
 [('Audio', 'audio'), ('Speech', 'speech'), ('Lang', 'lang'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Audio', 'audio'), ('Speech', 'speech'), ('Lang', 'lang'), ('.', '.')]

>> Lemmatization: 
 [('Audio', 'Audio'), ('Speech', 'Speech'), ('Lang', 'Lang'), ('.', '.')]


------------------- Sentence 5 -------------------

Process.

>> Tokens are: 
 ['Process', '.']

>> Bigrams are: 
 [('Process', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Process', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Process']

>> Named Entities are: 
 [('GPE', 'Process')] 

>> Stemming using Porter Stemmer: 
 [('Process', 'process'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Process', 'process'), ('.', '.')]

>> Lemmatization: 
 [('Process', 'Process'), ('.', '.')]


------------------- Sentence 6 -------------------

20, 14–22 (2012).

>> Tokens are: 
 ['20', ',', '14–22', '(', '2012', ')', '.']

>> Bigrams are: 
 [('20', ','), (',', '14–22'), ('14–22', '('), ('(', '2012'), ('2012', ')'), (')', '.')]

>> Trigrams are: 
 [('20', ',', '14–22'), (',', '14–22', '('), ('14–22', '(', '2012'), ('(', '2012', ')'), ('2012', ')', '.')]

>> POS Tags are: 
 [('20', 'CD'), (',', ','), ('14–22', 'CD'), ('(', '('), ('2012', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('20', '20'), (',', ','), ('14–22', '14–22'), ('(', '('), ('2012', '2012'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('20', '20'), (',', ','), ('14–22', '14–22'), ('(', '('), ('2012', '2012'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('20', '20'), (',', ','), ('14–22', '14–22'), ('(', '('), ('2012', '2012'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 287 ===========================================

39. Dahl, G. E., Yu, D., Deng, L. & Acero, A. Context-dependent pre-trained deep  neural networks for large vocabulary speech recognition. IEEE Trans. Audio  Speech Lang. Process. 20, 33–42 (2012).  

------------------- Sentence 1 -------------------

39.

>> Tokens are: 
 ['39', '.']

>> Bigrams are: 
 [('39', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('39', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('39', '39'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('39', '39'), ('.', '.')]

>> Lemmatization: 
 [('39', '39'), ('.', '.')]


------------------- Sentence 2 -------------------

Dahl, G. E., Yu, D., Deng, L. & Acero, A. Context-dependent pre-trained deep  neural networks for large vocabulary speech recognition.

>> Tokens are: 
 ['Dahl', ',', 'G.', 'E.', ',', 'Yu', ',', 'D.', ',', 'Deng', ',', 'L.', '&', 'Acero', ',', 'A.', 'Context-dependent', 'pre-trained', 'deep', 'neural', 'networks', 'large', 'vocabulary', 'speech', 'recognition', '.']

>> Bigrams are: 
 [('Dahl', ','), (',', 'G.'), ('G.', 'E.'), ('E.', ','), (',', 'Yu'), ('Yu', ','), (',', 'D.'), ('D.', ','), (',', 'Deng'), ('Deng', ','), (',', 'L.'), ('L.', '&'), ('&', 'Acero'), ('Acero', ','), (',', 'A.'), ('A.', 'Context-dependent'), ('Context-dependent', 'pre-trained'), ('pre-trained', 'deep'), ('deep', 'neural'), ('neural', 'networks'), ('networks', 'large'), ('large', 'vocabulary'), ('vocabulary', 'speech'), ('speech', 'recognition'), ('recognition', '.')]

>> Trigrams are: 
 [('Dahl', ',', 'G.'), (',', 'G.', 'E.'), ('G.', 'E.', ','), ('E.', ',', 'Yu'), (',', 'Yu', ','), ('Yu', ',', 'D.'), (',', 'D.', ','), ('D.', ',', 'Deng'), (',', 'Deng', ','), ('Deng', ',', 'L.'), (',', 'L.', '&'), ('L.', '&', 'Acero'), ('&', 'Acero', ','), ('Acero', ',', 'A.'), (',', 'A.', 'Context-dependent'), ('A.', 'Context-dependent', 'pre-trained'), ('Context-dependent', 'pre-trained', 'deep'), ('pre-trained', 'deep', 'neural'), ('deep', 'neural', 'networks'), ('neural', 'networks', 'large'), ('networks', 'large', 'vocabulary'), ('large', 'vocabulary', 'speech'), ('vocabulary', 'speech', 'recognition'), ('speech', 'recognition', '.')]

>> POS Tags are: 
 [('Dahl', 'NNP'), (',', ','), ('G.', 'NNP'), ('E.', 'NNP'), (',', ','), ('Yu', 'NNP'), (',', ','), ('D.', 'NNP'), (',', ','), ('Deng', 'NNP'), (',', ','), ('L.', 'NNP'), ('&', 'CC'), ('Acero', 'NNP'), (',', ','), ('A.', 'NNP'), ('Context-dependent', 'NNP'), ('pre-trained', 'JJ'), ('deep', 'JJ'), ('neural', 'JJ'), ('networks', 'NNS'), ('large', 'JJ'), ('vocabulary', 'JJ'), ('speech', 'NN'), ('recognition', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Dahl', 'G. E.', 'Yu', 'D.', 'Deng', 'L.', 'Acero', 'A. Context-dependent', 'pre-trained deep neural networks', 'large vocabulary speech recognition']

>> Named Entities are: 
 [('GPE', 'Dahl'), ('GPE', 'Yu'), ('PERSON', 'Deng'), ('PERSON', 'Acero')] 

>> Stemming using Porter Stemmer: 
 [('Dahl', 'dahl'), (',', ','), ('G.', 'g.'), ('E.', 'e.'), (',', ','), ('Yu', 'yu'), (',', ','), ('D.', 'd.'), (',', ','), ('Deng', 'deng'), (',', ','), ('L.', 'l.'), ('&', '&'), ('Acero', 'acero'), (',', ','), ('A.', 'a.'), ('Context-dependent', 'context-depend'), ('pre-trained', 'pre-train'), ('deep', 'deep'), ('neural', 'neural'), ('networks', 'network'), ('large', 'larg'), ('vocabulary', 'vocabulari'), ('speech', 'speech'), ('recognition', 'recognit'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Dahl', 'dahl'), (',', ','), ('G.', 'g.'), ('E.', 'e.'), (',', ','), ('Yu', 'yu'), (',', ','), ('D.', 'd.'), (',', ','), ('Deng', 'deng'), (',', ','), ('L.', 'l.'), ('&', '&'), ('Acero', 'acero'), (',', ','), ('A.', 'a.'), ('Context-dependent', 'context-depend'), ('pre-trained', 'pre-train'), ('deep', 'deep'), ('neural', 'neural'), ('networks', 'network'), ('large', 'larg'), ('vocabulary', 'vocabulari'), ('speech', 'speech'), ('recognition', 'recognit'), ('.', '.')]

>> Lemmatization: 
 [('Dahl', 'Dahl'), (',', ','), ('G.', 'G.'), ('E.', 'E.'), (',', ','), ('Yu', 'Yu'), (',', ','), ('D.', 'D.'), (',', ','), ('Deng', 'Deng'), (',', ','), ('L.', 'L.'), ('&', '&'), ('Acero', 'Acero'), (',', ','), ('A.', 'A.'), ('Context-dependent', 'Context-dependent'), ('pre-trained', 'pre-trained'), ('deep', 'deep'), ('neural', 'neural'), ('networks', 'network'), ('large', 'large'), ('vocabulary', 'vocabulary'), ('speech', 'speech'), ('recognition', 'recognition'), ('.', '.')]


------------------- Sentence 3 -------------------

IEEE Trans.

>> Tokens are: 
 ['IEEE', 'Trans', '.']

>> Bigrams are: 
 [('IEEE', 'Trans'), ('Trans', '.')]

>> Trigrams are: 
 [('IEEE', 'Trans', '.')]

>> POS Tags are: 
 [('IEEE', 'NNP'), ('Trans', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['IEEE Trans']

>> Named Entities are: 
 [('ORGANIZATION', 'IEEE Trans')] 

>> Stemming using Porter Stemmer: 
 [('IEEE', 'ieee'), ('Trans', 'tran'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('IEEE', 'ieee'), ('Trans', 'tran'), ('.', '.')]

>> Lemmatization: 
 [('IEEE', 'IEEE'), ('Trans', 'Trans'), ('.', '.')]


------------------- Sentence 4 -------------------

Audio  Speech Lang.

>> Tokens are: 
 ['Audio', 'Speech', 'Lang', '.']

>> Bigrams are: 
 [('Audio', 'Speech'), ('Speech', 'Lang'), ('Lang', '.')]

>> Trigrams are: 
 [('Audio', 'Speech', 'Lang'), ('Speech', 'Lang', '.')]

>> POS Tags are: 
 [('Audio', 'NNP'), ('Speech', 'NNP'), ('Lang', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Audio Speech Lang']

>> Named Entities are: 
 [('PERSON', 'Audio'), ('PERSON', 'Speech Lang')] 

>> Stemming using Porter Stemmer: 
 [('Audio', 'audio'), ('Speech', 'speech'), ('Lang', 'lang'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Audio', 'audio'), ('Speech', 'speech'), ('Lang', 'lang'), ('.', '.')]

>> Lemmatization: 
 [('Audio', 'Audio'), ('Speech', 'Speech'), ('Lang', 'Lang'), ('.', '.')]


------------------- Sentence 5 -------------------

Process.

>> Tokens are: 
 ['Process', '.']

>> Bigrams are: 
 [('Process', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Process', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Process']

>> Named Entities are: 
 [('GPE', 'Process')] 

>> Stemming using Porter Stemmer: 
 [('Process', 'process'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Process', 'process'), ('.', '.')]

>> Lemmatization: 
 [('Process', 'Process'), ('.', '.')]


------------------- Sentence 6 -------------------

20, 33–42 (2012).

>> Tokens are: 
 ['20', ',', '33–42', '(', '2012', ')', '.']

>> Bigrams are: 
 [('20', ','), (',', '33–42'), ('33–42', '('), ('(', '2012'), ('2012', ')'), (')', '.')]

>> Trigrams are: 
 [('20', ',', '33–42'), (',', '33–42', '('), ('33–42', '(', '2012'), ('(', '2012', ')'), ('2012', ')', '.')]

>> POS Tags are: 
 [('20', 'CD'), (',', ','), ('33–42', 'CD'), ('(', '('), ('2012', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('20', '20'), (',', ','), ('33–42', '33–42'), ('(', '('), ('2012', '2012'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('20', '20'), (',', ','), ('33–42', '33–42'), ('(', '('), ('2012', '2012'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('20', '20'), (',', ','), ('33–42', '33–42'), ('(', '('), ('2012', '2012'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 288 ===========================================

40. Bengio, Y., Courville, A. & Vincent, P. Representation learning: a review and new  perspectives. IEEE Trans. Pattern Anal. Machine Intell. 35, 1798–1828 (2013).  

------------------- Sentence 1 -------------------

40.

>> Tokens are: 
 ['40', '.']

>> Bigrams are: 
 [('40', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('40', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('40', '40'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('40', '40'), ('.', '.')]

>> Lemmatization: 
 [('40', '40'), ('.', '.')]


------------------- Sentence 2 -------------------

Bengio, Y., Courville, A.

>> Tokens are: 
 ['Bengio', ',', 'Y.', ',', 'Courville', ',', 'A', '.']

>> Bigrams are: 
 [('Bengio', ','), (',', 'Y.'), ('Y.', ','), (',', 'Courville'), ('Courville', ','), (',', 'A'), ('A', '.')]

>> Trigrams are: 
 [('Bengio', ',', 'Y.'), (',', 'Y.', ','), ('Y.', ',', 'Courville'), (',', 'Courville', ','), ('Courville', ',', 'A'), (',', 'A', '.')]

>> POS Tags are: 
 [('Bengio', 'NNP'), (',', ','), ('Y.', 'NNP'), (',', ','), ('Courville', 'NNP'), (',', ','), ('A', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Bengio', 'Y.', 'Courville', 'A']

>> Named Entities are: 
 [('GPE', 'Bengio'), ('GPE', 'Courville')] 

>> Stemming using Porter Stemmer: 
 [('Bengio', 'bengio'), (',', ','), ('Y.', 'y.'), (',', ','), ('Courville', 'courvil'), (',', ','), ('A', 'a'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Bengio', 'bengio'), (',', ','), ('Y.', 'y.'), (',', ','), ('Courville', 'courvill'), (',', ','), ('A', 'a'), ('.', '.')]

>> Lemmatization: 
 [('Bengio', 'Bengio'), (',', ','), ('Y.', 'Y.'), (',', ','), ('Courville', 'Courville'), (',', ','), ('A', 'A'), ('.', '.')]


------------------- Sentence 3 -------------------

& Vincent, P. Representation learning: a review and new  perspectives.

>> Tokens are: 
 ['&', 'Vincent', ',', 'P.', 'Representation', 'learning', ':', 'review', 'new', 'perspectives', '.']

>> Bigrams are: 
 [('&', 'Vincent'), ('Vincent', ','), (',', 'P.'), ('P.', 'Representation'), ('Representation', 'learning'), ('learning', ':'), (':', 'review'), ('review', 'new'), ('new', 'perspectives'), ('perspectives', '.')]

>> Trigrams are: 
 [('&', 'Vincent', ','), ('Vincent', ',', 'P.'), (',', 'P.', 'Representation'), ('P.', 'Representation', 'learning'), ('Representation', 'learning', ':'), ('learning', ':', 'review'), (':', 'review', 'new'), ('review', 'new', 'perspectives'), ('new', 'perspectives', '.')]

>> POS Tags are: 
 [('&', 'CC'), ('Vincent', 'NNP'), (',', ','), ('P.', 'NNP'), ('Representation', 'NNP'), ('learning', 'NN'), (':', ':'), ('review', 'VB'), ('new', 'JJ'), ('perspectives', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['Vincent', 'P. Representation learning', 'new perspectives']

>> Named Entities are: 
 [('PERSON', 'Vincent')] 

>> Stemming using Porter Stemmer: 
 [('&', '&'), ('Vincent', 'vincent'), (',', ','), ('P.', 'p.'), ('Representation', 'represent'), ('learning', 'learn'), (':', ':'), ('review', 'review'), ('new', 'new'), ('perspectives', 'perspect'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('&', '&'), ('Vincent', 'vincent'), (',', ','), ('P.', 'p.'), ('Representation', 'represent'), ('learning', 'learn'), (':', ':'), ('review', 'review'), ('new', 'new'), ('perspectives', 'perspect'), ('.', '.')]

>> Lemmatization: 
 [('&', '&'), ('Vincent', 'Vincent'), (',', ','), ('P.', 'P.'), ('Representation', 'Representation'), ('learning', 'learning'), (':', ':'), ('review', 'review'), ('new', 'new'), ('perspectives', 'perspective'), ('.', '.')]


------------------- Sentence 4 -------------------

IEEE Trans.

>> Tokens are: 
 ['IEEE', 'Trans', '.']

>> Bigrams are: 
 [('IEEE', 'Trans'), ('Trans', '.')]

>> Trigrams are: 
 [('IEEE', 'Trans', '.')]

>> POS Tags are: 
 [('IEEE', 'NNP'), ('Trans', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['IEEE Trans']

>> Named Entities are: 
 [('ORGANIZATION', 'IEEE Trans')] 

>> Stemming using Porter Stemmer: 
 [('IEEE', 'ieee'), ('Trans', 'tran'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('IEEE', 'ieee'), ('Trans', 'tran'), ('.', '.')]

>> Lemmatization: 
 [('IEEE', 'IEEE'), ('Trans', 'Trans'), ('.', '.')]


------------------- Sentence 5 -------------------

Pattern Anal.

>> Tokens are: 
 ['Pattern', 'Anal', '.']

>> Bigrams are: 
 [('Pattern', 'Anal'), ('Anal', '.')]

>> Trigrams are: 
 [('Pattern', 'Anal', '.')]

>> POS Tags are: 
 [('Pattern', 'NNP'), ('Anal', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Pattern Anal']

>> Named Entities are: 
 [('PERSON', 'Pattern'), ('ORGANIZATION', 'Anal')] 

>> Stemming using Porter Stemmer: 
 [('Pattern', 'pattern'), ('Anal', 'anal'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Pattern', 'pattern'), ('Anal', 'anal'), ('.', '.')]

>> Lemmatization: 
 [('Pattern', 'Pattern'), ('Anal', 'Anal'), ('.', '.')]


------------------- Sentence 6 -------------------

Machine Intell.

>> Tokens are: 
 ['Machine', 'Intell', '.']

>> Bigrams are: 
 [('Machine', 'Intell'), ('Intell', '.')]

>> Trigrams are: 
 [('Machine', 'Intell', '.')]

>> POS Tags are: 
 [('Machine', 'NN'), ('Intell', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Machine Intell']

>> Named Entities are: 
 [('PERSON', 'Machine'), ('ORGANIZATION', 'Intell')] 

>> Stemming using Porter Stemmer: 
 [('Machine', 'machin'), ('Intell', 'intel'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Machine', 'machin'), ('Intell', 'intel'), ('.', '.')]

>> Lemmatization: 
 [('Machine', 'Machine'), ('Intell', 'Intell'), ('.', '.')]


------------------- Sentence 7 -------------------

35, 1798–1828 (2013).

>> Tokens are: 
 ['35', ',', '1798–1828', '(', '2013', ')', '.']

>> Bigrams are: 
 [('35', ','), (',', '1798–1828'), ('1798–1828', '('), ('(', '2013'), ('2013', ')'), (')', '.')]

>> Trigrams are: 
 [('35', ',', '1798–1828'), (',', '1798–1828', '('), ('1798–1828', '(', '2013'), ('(', '2013', ')'), ('2013', ')', '.')]

>> POS Tags are: 
 [('35', 'CD'), (',', ','), ('1798–1828', 'CD'), ('(', '('), ('2013', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('35', '35'), (',', ','), ('1798–1828', '1798–1828'), ('(', '('), ('2013', '2013'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('35', '35'), (',', ','), ('1798–1828', '1798–1828'), ('(', '('), ('2013', '2013'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('35', '35'), (',', ','), ('1798–1828', '1798–1828'), ('(', '('), ('2013', '2013'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 289 ===========================================

41. LeCun, Y. et al. Handwritten digit recognition with a back-propagation network.  In Proc. Advances in Neural Information Processing Systems 396–404 (1990).  

------------------- Sentence 1 -------------------

41.

>> Tokens are: 
 ['41', '.']

>> Bigrams are: 
 [('41', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('41', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('41', '41'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('41', '41'), ('.', '.')]

>> Lemmatization: 
 [('41', '41'), ('.', '.')]


------------------- Sentence 2 -------------------

LeCun, Y. et al.

>> Tokens are: 
 ['LeCun', ',', 'Y.', 'et', 'al', '.']

>> Bigrams are: 
 [('LeCun', ','), (',', 'Y.'), ('Y.', 'et'), ('et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('LeCun', ',', 'Y.'), (',', 'Y.', 'et'), ('Y.', 'et', 'al'), ('et', 'al', '.')]

>> POS Tags are: 
 [('LeCun', 'NNP'), (',', ','), ('Y.', 'NNP'), ('et', 'CC'), ('al', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['LeCun', 'Y.', 'al']

>> Named Entities are: 
 [('GPE', 'LeCun')] 

>> Stemming using Porter Stemmer: 
 [('LeCun', 'lecun'), (',', ','), ('Y.', 'y.'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('LeCun', 'lecun'), (',', ','), ('Y.', 'y.'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('LeCun', 'LeCun'), (',', ','), ('Y.', 'Y.'), ('et', 'et'), ('al', 'al'), ('.', '.')]


------------------- Sentence 3 -------------------

Handwritten digit recognition with a back-propagation network.

>> Tokens are: 
 ['Handwritten', 'digit', 'recognition', 'back-propagation', 'network', '.']

>> Bigrams are: 
 [('Handwritten', 'digit'), ('digit', 'recognition'), ('recognition', 'back-propagation'), ('back-propagation', 'network'), ('network', '.')]

>> Trigrams are: 
 [('Handwritten', 'digit', 'recognition'), ('digit', 'recognition', 'back-propagation'), ('recognition', 'back-propagation', 'network'), ('back-propagation', 'network', '.')]

>> POS Tags are: 
 [('Handwritten', 'NNP'), ('digit', 'JJ'), ('recognition', 'NN'), ('back-propagation', 'NN'), ('network', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Handwritten', 'digit recognition back-propagation network']

>> Named Entities are: 
 [('GPE', 'Handwritten')] 

>> Stemming using Porter Stemmer: 
 [('Handwritten', 'handwritten'), ('digit', 'digit'), ('recognition', 'recognit'), ('back-propagation', 'back-propag'), ('network', 'network'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Handwritten', 'handwritten'), ('digit', 'digit'), ('recognition', 'recognit'), ('back-propagation', 'back-propag'), ('network', 'network'), ('.', '.')]

>> Lemmatization: 
 [('Handwritten', 'Handwritten'), ('digit', 'digit'), ('recognition', 'recognition'), ('back-propagation', 'back-propagation'), ('network', 'network'), ('.', '.')]


------------------- Sentence 4 -------------------

In Proc.

>> Tokens are: 
 ['In', 'Proc', '.']

>> Bigrams are: 
 [('In', 'Proc'), ('Proc', '.')]

>> Trigrams are: 
 [('In', 'Proc', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('Proc', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Proc']

>> Named Entities are: 
 [('GPE', 'Proc')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('Proc', 'proc'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('Proc', 'proc'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('Proc', 'Proc'), ('.', '.')]


------------------- Sentence 5 -------------------

Advances in Neural Information Processing Systems 396–404 (1990).

>> Tokens are: 
 ['Advances', 'Neural', 'Information', 'Processing', 'Systems', '396–404', '(', '1990', ')', '.']

>> Bigrams are: 
 [('Advances', 'Neural'), ('Neural', 'Information'), ('Information', 'Processing'), ('Processing', 'Systems'), ('Systems', '396–404'), ('396–404', '('), ('(', '1990'), ('1990', ')'), (')', '.')]

>> Trigrams are: 
 [('Advances', 'Neural', 'Information'), ('Neural', 'Information', 'Processing'), ('Information', 'Processing', 'Systems'), ('Processing', 'Systems', '396–404'), ('Systems', '396–404', '('), ('396–404', '(', '1990'), ('(', '1990', ')'), ('1990', ')', '.')]

>> POS Tags are: 
 [('Advances', 'NNS'), ('Neural', 'NNP'), ('Information', 'NNP'), ('Processing', 'NNP'), ('Systems', 'NNPS'), ('396–404', 'CD'), ('(', '('), ('1990', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['Advances Neural Information Processing']

>> Named Entities are: 
 [('ORGANIZATION', 'Neural Information Processing Systems')] 

>> Stemming using Porter Stemmer: 
 [('Advances', 'advanc'), ('Neural', 'neural'), ('Information', 'inform'), ('Processing', 'process'), ('Systems', 'system'), ('396–404', '396–404'), ('(', '('), ('1990', '1990'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Advances', 'advanc'), ('Neural', 'neural'), ('Information', 'inform'), ('Processing', 'process'), ('Systems', 'system'), ('396–404', '396–404'), ('(', '('), ('1990', '1990'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Advances', 'Advances'), ('Neural', 'Neural'), ('Information', 'Information'), ('Processing', 'Processing'), ('Systems', 'Systems'), ('396–404', '396–404'), ('(', '('), ('1990', '1990'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 290 ===========================================

 This is the first paper on convolutional networks trained by backpropagation  

------------------- Sentence 1 -------------------

 This is the first paper on convolutional networks trained by backpropagation

>> Tokens are: 
 ['This', 'first', 'paper', 'convolutional', 'networks', 'trained', 'backpropagation']

>> Bigrams are: 
 [('This', 'first'), ('first', 'paper'), ('paper', 'convolutional'), ('convolutional', 'networks'), ('networks', 'trained'), ('trained', 'backpropagation')]

>> Trigrams are: 
 [('This', 'first', 'paper'), ('first', 'paper', 'convolutional'), ('paper', 'convolutional', 'networks'), ('convolutional', 'networks', 'trained'), ('networks', 'trained', 'backpropagation')]

>> POS Tags are: 
 [('This', 'DT'), ('first', 'JJ'), ('paper', 'NN'), ('convolutional', 'JJ'), ('networks', 'NNS'), ('trained', 'VBD'), ('backpropagation', 'NN')]

>> Noun Phrases are: 
 ['This first paper', 'convolutional networks', 'backpropagation']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('This', 'thi'), ('first', 'first'), ('paper', 'paper'), ('convolutional', 'convolut'), ('networks', 'network'), ('trained', 'train'), ('backpropagation', 'backpropag')]

>> Stemming using Snowball Stemmer: 
 [('This', 'this'), ('first', 'first'), ('paper', 'paper'), ('convolutional', 'convolut'), ('networks', 'network'), ('trained', 'train'), ('backpropagation', 'backpropag')]

>> Lemmatization: 
 [('This', 'This'), ('first', 'first'), ('paper', 'paper'), ('convolutional', 'convolutional'), ('networks', 'network'), ('trained', 'trained'), ('backpropagation', 'backpropagation')]



========================================== PARAGRAPH 291 ===========================================

for the task of classifying low-resolution images of handwritten digits. 42. LeCun, Y., Bottou, L., Bengio, Y. & Haffner, P. Gradient-based learning applied to  

------------------- Sentence 1 -------------------

for the task of classifying low-resolution images of handwritten digits.

>> Tokens are: 
 ['task', 'classifying', 'low-resolution', 'images', 'handwritten', 'digits', '.']

>> Bigrams are: 
 [('task', 'classifying'), ('classifying', 'low-resolution'), ('low-resolution', 'images'), ('images', 'handwritten'), ('handwritten', 'digits'), ('digits', '.')]

>> Trigrams are: 
 [('task', 'classifying', 'low-resolution'), ('classifying', 'low-resolution', 'images'), ('low-resolution', 'images', 'handwritten'), ('images', 'handwritten', 'digits'), ('handwritten', 'digits', '.')]

>> POS Tags are: 
 [('task', 'NN'), ('classifying', 'VBG'), ('low-resolution', 'NN'), ('images', 'NNS'), ('handwritten', 'VBP'), ('digits', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['task', 'low-resolution images', 'digits']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('task', 'task'), ('classifying', 'classifi'), ('low-resolution', 'low-resolut'), ('images', 'imag'), ('handwritten', 'handwritten'), ('digits', 'digit'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('task', 'task'), ('classifying', 'classifi'), ('low-resolution', 'low-resolut'), ('images', 'imag'), ('handwritten', 'handwritten'), ('digits', 'digit'), ('.', '.')]

>> Lemmatization: 
 [('task', 'task'), ('classifying', 'classifying'), ('low-resolution', 'low-resolution'), ('images', 'image'), ('handwritten', 'handwritten'), ('digits', 'digit'), ('.', '.')]


------------------- Sentence 2 -------------------

42.

>> Tokens are: 
 ['42', '.']

>> Bigrams are: 
 [('42', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('42', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('42', '42'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('42', '42'), ('.', '.')]

>> Lemmatization: 
 [('42', '42'), ('.', '.')]


------------------- Sentence 3 -------------------

LeCun, Y., Bottou, L., Bengio, Y.

>> Tokens are: 
 ['LeCun', ',', 'Y.', ',', 'Bottou', ',', 'L.', ',', 'Bengio', ',', 'Y', '.']

>> Bigrams are: 
 [('LeCun', ','), (',', 'Y.'), ('Y.', ','), (',', 'Bottou'), ('Bottou', ','), (',', 'L.'), ('L.', ','), (',', 'Bengio'), ('Bengio', ','), (',', 'Y'), ('Y', '.')]

>> Trigrams are: 
 [('LeCun', ',', 'Y.'), (',', 'Y.', ','), ('Y.', ',', 'Bottou'), (',', 'Bottou', ','), ('Bottou', ',', 'L.'), (',', 'L.', ','), ('L.', ',', 'Bengio'), (',', 'Bengio', ','), ('Bengio', ',', 'Y'), (',', 'Y', '.')]

>> POS Tags are: 
 [('LeCun', 'NNP'), (',', ','), ('Y.', 'NNP'), (',', ','), ('Bottou', 'NNP'), (',', ','), ('L.', 'NNP'), (',', ','), ('Bengio', 'NNP'), (',', ','), ('Y', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['LeCun', 'Y.', 'Bottou', 'L.', 'Bengio', 'Y']

>> Named Entities are: 
 [('GPE', 'LeCun'), ('GPE', 'Bottou'), ('PERSON', 'Bengio')] 

>> Stemming using Porter Stemmer: 
 [('LeCun', 'lecun'), (',', ','), ('Y.', 'y.'), (',', ','), ('Bottou', 'bottou'), (',', ','), ('L.', 'l.'), (',', ','), ('Bengio', 'bengio'), (',', ','), ('Y', 'y'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('LeCun', 'lecun'), (',', ','), ('Y.', 'y.'), (',', ','), ('Bottou', 'bottou'), (',', ','), ('L.', 'l.'), (',', ','), ('Bengio', 'bengio'), (',', ','), ('Y', 'y'), ('.', '.')]

>> Lemmatization: 
 [('LeCun', 'LeCun'), (',', ','), ('Y.', 'Y.'), (',', ','), ('Bottou', 'Bottou'), (',', ','), ('L.', 'L.'), (',', ','), ('Bengio', 'Bengio'), (',', ','), ('Y', 'Y'), ('.', '.')]


------------------- Sentence 4 -------------------

& Haffner, P. Gradient-based learning applied to

>> Tokens are: 
 ['&', 'Haffner', ',', 'P.', 'Gradient-based', 'learning', 'applied']

>> Bigrams are: 
 [('&', 'Haffner'), ('Haffner', ','), (',', 'P.'), ('P.', 'Gradient-based'), ('Gradient-based', 'learning'), ('learning', 'applied')]

>> Trigrams are: 
 [('&', 'Haffner', ','), ('Haffner', ',', 'P.'), (',', 'P.', 'Gradient-based'), ('P.', 'Gradient-based', 'learning'), ('Gradient-based', 'learning', 'applied')]

>> POS Tags are: 
 [('&', 'CC'), ('Haffner', 'NNP'), (',', ','), ('P.', 'NNP'), ('Gradient-based', 'VBD'), ('learning', 'VBG'), ('applied', 'VBN')]

>> Noun Phrases are: 
 ['Haffner', 'P.']

>> Named Entities are: 
 [('PERSON', 'Haffner')] 

>> Stemming using Porter Stemmer: 
 [('&', '&'), ('Haffner', 'haffner'), (',', ','), ('P.', 'p.'), ('Gradient-based', 'gradient-bas'), ('learning', 'learn'), ('applied', 'appli')]

>> Stemming using Snowball Stemmer: 
 [('&', '&'), ('Haffner', 'haffner'), (',', ','), ('P.', 'p.'), ('Gradient-based', 'gradient-bas'), ('learning', 'learn'), ('applied', 'appli')]

>> Lemmatization: 
 [('&', '&'), ('Haffner', 'Haffner'), (',', ','), ('P.', 'P.'), ('Gradient-based', 'Gradient-based'), ('learning', 'learning'), ('applied', 'applied')]



========================================== PARAGRAPH 292 ===========================================

document recognition. Proc. IEEE 86, 2278–2324 (1998).   This overview paper on the principles of end-to-end training of modular  

------------------- Sentence 1 -------------------

document recognition.

>> Tokens are: 
 ['document', 'recognition', '.']

>> Bigrams are: 
 [('document', 'recognition'), ('recognition', '.')]

>> Trigrams are: 
 [('document', 'recognition', '.')]

>> POS Tags are: 
 [('document', 'NN'), ('recognition', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['document recognition']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('document', 'document'), ('recognition', 'recognit'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('document', 'document'), ('recognition', 'recognit'), ('.', '.')]

>> Lemmatization: 
 [('document', 'document'), ('recognition', 'recognition'), ('.', '.')]


------------------- Sentence 2 -------------------

Proc.

>> Tokens are: 
 ['Proc', '.']

>> Bigrams are: 
 [('Proc', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Proc', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Proc']

>> Named Entities are: 
 [('GPE', 'Proc')] 

>> Stemming using Porter Stemmer: 
 [('Proc', 'proc'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Proc', 'proc'), ('.', '.')]

>> Lemmatization: 
 [('Proc', 'Proc'), ('.', '.')]


------------------- Sentence 3 -------------------

IEEE 86, 2278–2324 (1998).

>> Tokens are: 
 ['IEEE', '86', ',', '2278–2324', '(', '1998', ')', '.']

>> Bigrams are: 
 [('IEEE', '86'), ('86', ','), (',', '2278–2324'), ('2278–2324', '('), ('(', '1998'), ('1998', ')'), (')', '.')]

>> Trigrams are: 
 [('IEEE', '86', ','), ('86', ',', '2278–2324'), (',', '2278–2324', '('), ('2278–2324', '(', '1998'), ('(', '1998', ')'), ('1998', ')', '.')]

>> POS Tags are: 
 [('IEEE', 'NNP'), ('86', 'CD'), (',', ','), ('2278–2324', 'CD'), ('(', '('), ('1998', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['IEEE']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('IEEE', 'ieee'), ('86', '86'), (',', ','), ('2278–2324', '2278–2324'), ('(', '('), ('1998', '1998'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('IEEE', 'ieee'), ('86', '86'), (',', ','), ('2278–2324', '2278–2324'), ('(', '('), ('1998', '1998'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('IEEE', 'IEEE'), ('86', '86'), (',', ','), ('2278–2324', '2278–2324'), ('(', '('), ('1998', '1998'), (')', ')'), ('.', '.')]


------------------- Sentence 4 -------------------

This overview paper on the principles of end-to-end training of modular

>> Tokens are: 
 ['This', 'overview', 'paper', 'principles', 'end-to-end', 'training', 'modular']

>> Bigrams are: 
 [('This', 'overview'), ('overview', 'paper'), ('paper', 'principles'), ('principles', 'end-to-end'), ('end-to-end', 'training'), ('training', 'modular')]

>> Trigrams are: 
 [('This', 'overview', 'paper'), ('overview', 'paper', 'principles'), ('paper', 'principles', 'end-to-end'), ('principles', 'end-to-end', 'training'), ('end-to-end', 'training', 'modular')]

>> POS Tags are: 
 [('This', 'DT'), ('overview', 'JJ'), ('paper', 'NN'), ('principles', 'NNS'), ('end-to-end', 'VBP'), ('training', 'NN'), ('modular', 'NN')]

>> Noun Phrases are: 
 ['This overview paper principles', 'training modular']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('This', 'thi'), ('overview', 'overview'), ('paper', 'paper'), ('principles', 'principl'), ('end-to-end', 'end-to-end'), ('training', 'train'), ('modular', 'modular')]

>> Stemming using Snowball Stemmer: 
 [('This', 'this'), ('overview', 'overview'), ('paper', 'paper'), ('principles', 'principl'), ('end-to-end', 'end-to-end'), ('training', 'train'), ('modular', 'modular')]

>> Lemmatization: 
 [('This', 'This'), ('overview', 'overview'), ('paper', 'paper'), ('principles', 'principle'), ('end-to-end', 'end-to-end'), ('training', 'training'), ('modular', 'modular')]



========================================== PARAGRAPH 293 ===========================================

systems such as deep neural networks using gradient-based optimization  showed how neural networks (and in particular convolutional nets) can be  combined with search or inference mechanisms to model complex outputs  that are interdependent, such as sequences of characters associated with the  content of a document. 

------------------- Sentence 1 -------------------

systems such as deep neural networks using gradient-based optimization  showed how neural networks (and in particular convolutional nets) can be  combined with search or inference mechanisms to model complex outputs  that are interdependent, such as sequences of characters associated with the  content of a document.

>> Tokens are: 
 ['systems', 'deep', 'neural', 'networks', 'using', 'gradient-based', 'optimization', 'showed', 'neural', 'networks', '(', 'particular', 'convolutional', 'nets', ')', 'combined', 'search', 'inference', 'mechanisms', 'model', 'complex', 'outputs', 'interdependent', ',', 'sequences', 'characters', 'associated', 'content', 'document', '.']

>> Bigrams are: 
 [('systems', 'deep'), ('deep', 'neural'), ('neural', 'networks'), ('networks', 'using'), ('using', 'gradient-based'), ('gradient-based', 'optimization'), ('optimization', 'showed'), ('showed', 'neural'), ('neural', 'networks'), ('networks', '('), ('(', 'particular'), ('particular', 'convolutional'), ('convolutional', 'nets'), ('nets', ')'), (')', 'combined'), ('combined', 'search'), ('search', 'inference'), ('inference', 'mechanisms'), ('mechanisms', 'model'), ('model', 'complex'), ('complex', 'outputs'), ('outputs', 'interdependent'), ('interdependent', ','), (',', 'sequences'), ('sequences', 'characters'), ('characters', 'associated'), ('associated', 'content'), ('content', 'document'), ('document', '.')]

>> Trigrams are: 
 [('systems', 'deep', 'neural'), ('deep', 'neural', 'networks'), ('neural', 'networks', 'using'), ('networks', 'using', 'gradient-based'), ('using', 'gradient-based', 'optimization'), ('gradient-based', 'optimization', 'showed'), ('optimization', 'showed', 'neural'), ('showed', 'neural', 'networks'), ('neural', 'networks', '('), ('networks', '(', 'particular'), ('(', 'particular', 'convolutional'), ('particular', 'convolutional', 'nets'), ('convolutional', 'nets', ')'), ('nets', ')', 'combined'), (')', 'combined', 'search'), ('combined', 'search', 'inference'), ('search', 'inference', 'mechanisms'), ('inference', 'mechanisms', 'model'), ('mechanisms', 'model', 'complex'), ('model', 'complex', 'outputs'), ('complex', 'outputs', 'interdependent'), ('outputs', 'interdependent', ','), ('interdependent', ',', 'sequences'), (',', 'sequences', 'characters'), ('sequences', 'characters', 'associated'), ('characters', 'associated', 'content'), ('associated', 'content', 'document'), ('content', 'document', '.')]

>> POS Tags are: 
 [('systems', 'NNS'), ('deep', 'JJ'), ('neural', 'JJ'), ('networks', 'NNS'), ('using', 'VBG'), ('gradient-based', 'JJ'), ('optimization', 'NN'), ('showed', 'VBD'), ('neural', 'JJ'), ('networks', 'NNS'), ('(', '('), ('particular', 'JJ'), ('convolutional', 'JJ'), ('nets', 'NNS'), (')', ')'), ('combined', 'VBN'), ('search', 'NN'), ('inference', 'NN'), ('mechanisms', 'NNS'), ('model', 'NN'), ('complex', 'JJ'), ('outputs', 'NNS'), ('interdependent', 'NN'), (',', ','), ('sequences', 'VBZ'), ('characters', 'NNS'), ('associated', 'VBN'), ('content', 'JJ'), ('document', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['systems', 'deep neural networks', 'gradient-based optimization', 'neural networks', 'particular convolutional nets', 'search inference mechanisms model', 'complex outputs interdependent', 'characters', 'content document']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('systems', 'system'), ('deep', 'deep'), ('neural', 'neural'), ('networks', 'network'), ('using', 'use'), ('gradient-based', 'gradient-bas'), ('optimization', 'optim'), ('showed', 'show'), ('neural', 'neural'), ('networks', 'network'), ('(', '('), ('particular', 'particular'), ('convolutional', 'convolut'), ('nets', 'net'), (')', ')'), ('combined', 'combin'), ('search', 'search'), ('inference', 'infer'), ('mechanisms', 'mechan'), ('model', 'model'), ('complex', 'complex'), ('outputs', 'output'), ('interdependent', 'interdepend'), (',', ','), ('sequences', 'sequenc'), ('characters', 'charact'), ('associated', 'associ'), ('content', 'content'), ('document', 'document'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('systems', 'system'), ('deep', 'deep'), ('neural', 'neural'), ('networks', 'network'), ('using', 'use'), ('gradient-based', 'gradient-bas'), ('optimization', 'optim'), ('showed', 'show'), ('neural', 'neural'), ('networks', 'network'), ('(', '('), ('particular', 'particular'), ('convolutional', 'convolut'), ('nets', 'net'), (')', ')'), ('combined', 'combin'), ('search', 'search'), ('inference', 'infer'), ('mechanisms', 'mechan'), ('model', 'model'), ('complex', 'complex'), ('outputs', 'output'), ('interdependent', 'interdepend'), (',', ','), ('sequences', 'sequenc'), ('characters', 'charact'), ('associated', 'associ'), ('content', 'content'), ('document', 'document'), ('.', '.')]

>> Lemmatization: 
 [('systems', 'system'), ('deep', 'deep'), ('neural', 'neural'), ('networks', 'network'), ('using', 'using'), ('gradient-based', 'gradient-based'), ('optimization', 'optimization'), ('showed', 'showed'), ('neural', 'neural'), ('networks', 'network'), ('(', '('), ('particular', 'particular'), ('convolutional', 'convolutional'), ('nets', 'net'), (')', ')'), ('combined', 'combined'), ('search', 'search'), ('inference', 'inference'), ('mechanisms', 'mechanism'), ('model', 'model'), ('complex', 'complex'), ('outputs', 'output'), ('interdependent', 'interdependent'), (',', ','), ('sequences', 'sequence'), ('characters', 'character'), ('associated', 'associated'), ('content', 'content'), ('document', 'document'), ('.', '.')]



========================================== PARAGRAPH 294 ===========================================

43. Hubel, D. H. & Wiesel, T. N. Receptive fields, binocular interaction, and functional  architecture in the cat’s visual cortex. J. Physiol. 160, 106–154 (1962).  

------------------- Sentence 1 -------------------

43.

>> Tokens are: 
 ['43', '.']

>> Bigrams are: 
 [('43', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('43', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('43', '43'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('43', '43'), ('.', '.')]

>> Lemmatization: 
 [('43', '43'), ('.', '.')]


------------------- Sentence 2 -------------------

Hubel, D. H. & Wiesel, T. N. Receptive fields, binocular interaction, and functional  architecture in the cat’s visual cortex.

>> Tokens are: 
 ['Hubel', ',', 'D.', 'H.', '&', 'Wiesel', ',', 'T.', 'N.', 'Receptive', 'fields', ',', 'binocular', 'interaction', ',', 'functional', 'architecture', 'cat', '’', 'visual', 'cortex', '.']

>> Bigrams are: 
 [('Hubel', ','), (',', 'D.'), ('D.', 'H.'), ('H.', '&'), ('&', 'Wiesel'), ('Wiesel', ','), (',', 'T.'), ('T.', 'N.'), ('N.', 'Receptive'), ('Receptive', 'fields'), ('fields', ','), (',', 'binocular'), ('binocular', 'interaction'), ('interaction', ','), (',', 'functional'), ('functional', 'architecture'), ('architecture', 'cat'), ('cat', '’'), ('’', 'visual'), ('visual', 'cortex'), ('cortex', '.')]

>> Trigrams are: 
 [('Hubel', ',', 'D.'), (',', 'D.', 'H.'), ('D.', 'H.', '&'), ('H.', '&', 'Wiesel'), ('&', 'Wiesel', ','), ('Wiesel', ',', 'T.'), (',', 'T.', 'N.'), ('T.', 'N.', 'Receptive'), ('N.', 'Receptive', 'fields'), ('Receptive', 'fields', ','), ('fields', ',', 'binocular'), (',', 'binocular', 'interaction'), ('binocular', 'interaction', ','), ('interaction', ',', 'functional'), (',', 'functional', 'architecture'), ('functional', 'architecture', 'cat'), ('architecture', 'cat', '’'), ('cat', '’', 'visual'), ('’', 'visual', 'cortex'), ('visual', 'cortex', '.')]

>> POS Tags are: 
 [('Hubel', 'NNP'), (',', ','), ('D.', 'NNP'), ('H.', 'NNP'), ('&', 'CC'), ('Wiesel', 'NNP'), (',', ','), ('T.', 'NNP'), ('N.', 'NNP'), ('Receptive', 'NNP'), ('fields', 'NNS'), (',', ','), ('binocular', 'JJ'), ('interaction', 'NN'), (',', ','), ('functional', 'JJ'), ('architecture', 'NN'), ('cat', 'NN'), ('’', 'NNP'), ('visual', 'JJ'), ('cortex', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Hubel', 'D. H.', 'Wiesel', 'T. N. Receptive fields', 'binocular interaction', 'functional architecture cat ’', 'visual cortex']

>> Named Entities are: 
 [('GPE', 'Hubel'), ('PERSON', 'Wiesel')] 

>> Stemming using Porter Stemmer: 
 [('Hubel', 'hubel'), (',', ','), ('D.', 'd.'), ('H.', 'h.'), ('&', '&'), ('Wiesel', 'wiesel'), (',', ','), ('T.', 't.'), ('N.', 'n.'), ('Receptive', 'recept'), ('fields', 'field'), (',', ','), ('binocular', 'binocular'), ('interaction', 'interact'), (',', ','), ('functional', 'function'), ('architecture', 'architectur'), ('cat', 'cat'), ('’', '’'), ('visual', 'visual'), ('cortex', 'cortex'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Hubel', 'hubel'), (',', ','), ('D.', 'd.'), ('H.', 'h.'), ('&', '&'), ('Wiesel', 'wiesel'), (',', ','), ('T.', 't.'), ('N.', 'n.'), ('Receptive', 'recept'), ('fields', 'field'), (',', ','), ('binocular', 'binocular'), ('interaction', 'interact'), (',', ','), ('functional', 'function'), ('architecture', 'architectur'), ('cat', 'cat'), ('’', '’'), ('visual', 'visual'), ('cortex', 'cortex'), ('.', '.')]

>> Lemmatization: 
 [('Hubel', 'Hubel'), (',', ','), ('D.', 'D.'), ('H.', 'H.'), ('&', '&'), ('Wiesel', 'Wiesel'), (',', ','), ('T.', 'T.'), ('N.', 'N.'), ('Receptive', 'Receptive'), ('fields', 'field'), (',', ','), ('binocular', 'binocular'), ('interaction', 'interaction'), (',', ','), ('functional', 'functional'), ('architecture', 'architecture'), ('cat', 'cat'), ('’', '’'), ('visual', 'visual'), ('cortex', 'cortex'), ('.', '.')]


------------------- Sentence 3 -------------------

J. Physiol.

>> Tokens are: 
 ['J.', 'Physiol', '.']

>> Bigrams are: 
 [('J.', 'Physiol'), ('Physiol', '.')]

>> Trigrams are: 
 [('J.', 'Physiol', '.')]

>> POS Tags are: 
 [('J.', 'NNP'), ('Physiol', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['J. Physiol']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('J.', 'j.'), ('Physiol', 'physiol'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('J.', 'j.'), ('Physiol', 'physiol'), ('.', '.')]

>> Lemmatization: 
 [('J.', 'J.'), ('Physiol', 'Physiol'), ('.', '.')]


------------------- Sentence 4 -------------------

160, 106–154 (1962).

>> Tokens are: 
 ['160', ',', '106–154', '(', '1962', ')', '.']

>> Bigrams are: 
 [('160', ','), (',', '106–154'), ('106–154', '('), ('(', '1962'), ('1962', ')'), (')', '.')]

>> Trigrams are: 
 [('160', ',', '106–154'), (',', '106–154', '('), ('106–154', '(', '1962'), ('(', '1962', ')'), ('1962', ')', '.')]

>> POS Tags are: 
 [('160', 'CD'), (',', ','), ('106–154', 'CD'), ('(', '('), ('1962', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('160', '160'), (',', ','), ('106–154', '106–154'), ('(', '('), ('1962', '1962'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('160', '160'), (',', ','), ('106–154', '106–154'), ('(', '('), ('1962', '1962'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('160', '160'), (',', ','), ('106–154', '106–154'), ('(', '('), ('1962', '1962'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 295 ===========================================

44. Felleman, D. J. & Essen, D. C. V. Distributed hierarchical processing in the  primate cerebral cortex. Cereb. Cortex 1, 1–47 (1991).  

------------------- Sentence 1 -------------------

44.

>> Tokens are: 
 ['44', '.']

>> Bigrams are: 
 [('44', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('44', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('44', '44'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('44', '44'), ('.', '.')]

>> Lemmatization: 
 [('44', '44'), ('.', '.')]


------------------- Sentence 2 -------------------

Felleman, D. J.

>> Tokens are: 
 ['Felleman', ',', 'D.', 'J', '.']

>> Bigrams are: 
 [('Felleman', ','), (',', 'D.'), ('D.', 'J'), ('J', '.')]

>> Trigrams are: 
 [('Felleman', ',', 'D.'), (',', 'D.', 'J'), ('D.', 'J', '.')]

>> POS Tags are: 
 [('Felleman', 'NNP'), (',', ','), ('D.', 'NNP'), ('J', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Felleman', 'D. J']

>> Named Entities are: 
 [('GPE', 'Felleman')] 

>> Stemming using Porter Stemmer: 
 [('Felleman', 'felleman'), (',', ','), ('D.', 'd.'), ('J', 'j'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Felleman', 'felleman'), (',', ','), ('D.', 'd.'), ('J', 'j'), ('.', '.')]

>> Lemmatization: 
 [('Felleman', 'Felleman'), (',', ','), ('D.', 'D.'), ('J', 'J'), ('.', '.')]


------------------- Sentence 3 -------------------

& Essen, D. C. V. Distributed hierarchical processing in the  primate cerebral cortex.

>> Tokens are: 
 ['&', 'Essen', ',', 'D.', 'C.', 'V.', 'Distributed', 'hierarchical', 'processing', 'primate', 'cerebral', 'cortex', '.']

>> Bigrams are: 
 [('&', 'Essen'), ('Essen', ','), (',', 'D.'), ('D.', 'C.'), ('C.', 'V.'), ('V.', 'Distributed'), ('Distributed', 'hierarchical'), ('hierarchical', 'processing'), ('processing', 'primate'), ('primate', 'cerebral'), ('cerebral', 'cortex'), ('cortex', '.')]

>> Trigrams are: 
 [('&', 'Essen', ','), ('Essen', ',', 'D.'), (',', 'D.', 'C.'), ('D.', 'C.', 'V.'), ('C.', 'V.', 'Distributed'), ('V.', 'Distributed', 'hierarchical'), ('Distributed', 'hierarchical', 'processing'), ('hierarchical', 'processing', 'primate'), ('processing', 'primate', 'cerebral'), ('primate', 'cerebral', 'cortex'), ('cerebral', 'cortex', '.')]

>> POS Tags are: 
 [('&', 'CC'), ('Essen', 'NNP'), (',', ','), ('D.', 'NNP'), ('C.', 'NNP'), ('V.', 'NNP'), ('Distributed', 'NNP'), ('hierarchical', 'JJ'), ('processing', 'NN'), ('primate', 'JJ'), ('cerebral', 'JJ'), ('cortex', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Essen', 'D. C. V. Distributed', 'hierarchical processing', 'primate cerebral cortex']

>> Named Entities are: 
 [('PERSON', 'Essen')] 

>> Stemming using Porter Stemmer: 
 [('&', '&'), ('Essen', 'essen'), (',', ','), ('D.', 'd.'), ('C.', 'c.'), ('V.', 'v.'), ('Distributed', 'distribut'), ('hierarchical', 'hierarch'), ('processing', 'process'), ('primate', 'primat'), ('cerebral', 'cerebr'), ('cortex', 'cortex'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('&', '&'), ('Essen', 'essen'), (',', ','), ('D.', 'd.'), ('C.', 'c.'), ('V.', 'v.'), ('Distributed', 'distribut'), ('hierarchical', 'hierarch'), ('processing', 'process'), ('primate', 'primat'), ('cerebral', 'cerebr'), ('cortex', 'cortex'), ('.', '.')]

>> Lemmatization: 
 [('&', '&'), ('Essen', 'Essen'), (',', ','), ('D.', 'D.'), ('C.', 'C.'), ('V.', 'V.'), ('Distributed', 'Distributed'), ('hierarchical', 'hierarchical'), ('processing', 'processing'), ('primate', 'primate'), ('cerebral', 'cerebral'), ('cortex', 'cortex'), ('.', '.')]


------------------- Sentence 4 -------------------

Cereb.

>> Tokens are: 
 ['Cereb', '.']

>> Bigrams are: 
 [('Cereb', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Cereb', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Cereb']

>> Named Entities are: 
 [('GPE', 'Cereb')] 

>> Stemming using Porter Stemmer: 
 [('Cereb', 'cereb'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Cereb', 'cereb'), ('.', '.')]

>> Lemmatization: 
 [('Cereb', 'Cereb'), ('.', '.')]


------------------- Sentence 5 -------------------

Cortex 1, 1–47 (1991).

>> Tokens are: 
 ['Cortex', '1', ',', '1–47', '(', '1991', ')', '.']

>> Bigrams are: 
 [('Cortex', '1'), ('1', ','), (',', '1–47'), ('1–47', '('), ('(', '1991'), ('1991', ')'), (')', '.')]

>> Trigrams are: 
 [('Cortex', '1', ','), ('1', ',', '1–47'), (',', '1–47', '('), ('1–47', '(', '1991'), ('(', '1991', ')'), ('1991', ')', '.')]

>> POS Tags are: 
 [('Cortex', 'NNP'), ('1', 'CD'), (',', ','), ('1–47', 'CD'), ('(', '('), ('1991', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['Cortex']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Cortex', 'cortex'), ('1', '1'), (',', ','), ('1–47', '1–47'), ('(', '('), ('1991', '1991'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Cortex', 'cortex'), ('1', '1'), (',', ','), ('1–47', '1–47'), ('(', '('), ('1991', '1991'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Cortex', 'Cortex'), ('1', '1'), (',', ','), ('1–47', '1–47'), ('(', '('), ('1991', '1991'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 296 ===========================================

45. Cadieu, C. F. et al. Deep neural networks rival the representation of primate  it cortex for core visual object recognition. PLoS Comp. Biol. 10, e1003963  (2014).  

------------------- Sentence 1 -------------------

45.

>> Tokens are: 
 ['45', '.']

>> Bigrams are: 
 [('45', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('45', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('45', '45'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('45', '45'), ('.', '.')]

>> Lemmatization: 
 [('45', '45'), ('.', '.')]


------------------- Sentence 2 -------------------

Cadieu, C. F. et al.

>> Tokens are: 
 ['Cadieu', ',', 'C.', 'F.', 'et', 'al', '.']

>> Bigrams are: 
 [('Cadieu', ','), (',', 'C.'), ('C.', 'F.'), ('F.', 'et'), ('et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('Cadieu', ',', 'C.'), (',', 'C.', 'F.'), ('C.', 'F.', 'et'), ('F.', 'et', 'al'), ('et', 'al', '.')]

>> POS Tags are: 
 [('Cadieu', 'NNP'), (',', ','), ('C.', 'NNP'), ('F.', 'NNP'), ('et', 'FW'), ('al', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Cadieu', 'C. F.', 'al']

>> Named Entities are: 
 [('GPE', 'Cadieu')] 

>> Stemming using Porter Stemmer: 
 [('Cadieu', 'cadieu'), (',', ','), ('C.', 'c.'), ('F.', 'f.'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Cadieu', 'cadieu'), (',', ','), ('C.', 'c.'), ('F.', 'f.'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('Cadieu', 'Cadieu'), (',', ','), ('C.', 'C.'), ('F.', 'F.'), ('et', 'et'), ('al', 'al'), ('.', '.')]


------------------- Sentence 3 -------------------

Deep neural networks rival the representation of primate  it cortex for core visual object recognition.

>> Tokens are: 
 ['Deep', 'neural', 'networks', 'rival', 'representation', 'primate', 'cortex', 'core', 'visual', 'object', 'recognition', '.']

>> Bigrams are: 
 [('Deep', 'neural'), ('neural', 'networks'), ('networks', 'rival'), ('rival', 'representation'), ('representation', 'primate'), ('primate', 'cortex'), ('cortex', 'core'), ('core', 'visual'), ('visual', 'object'), ('object', 'recognition'), ('recognition', '.')]

>> Trigrams are: 
 [('Deep', 'neural', 'networks'), ('neural', 'networks', 'rival'), ('networks', 'rival', 'representation'), ('rival', 'representation', 'primate'), ('representation', 'primate', 'cortex'), ('primate', 'cortex', 'core'), ('cortex', 'core', 'visual'), ('core', 'visual', 'object'), ('visual', 'object', 'recognition'), ('object', 'recognition', '.')]

>> POS Tags are: 
 [('Deep', 'JJ'), ('neural', 'JJ'), ('networks', 'NNS'), ('rival', 'JJ'), ('representation', 'NN'), ('primate', 'NN'), ('cortex', 'NN'), ('core', 'NN'), ('visual', 'JJ'), ('object', 'JJ'), ('recognition', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Deep neural networks', 'rival representation primate cortex core', 'visual object recognition']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Deep', 'deep'), ('neural', 'neural'), ('networks', 'network'), ('rival', 'rival'), ('representation', 'represent'), ('primate', 'primat'), ('cortex', 'cortex'), ('core', 'core'), ('visual', 'visual'), ('object', 'object'), ('recognition', 'recognit'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Deep', 'deep'), ('neural', 'neural'), ('networks', 'network'), ('rival', 'rival'), ('representation', 'represent'), ('primate', 'primat'), ('cortex', 'cortex'), ('core', 'core'), ('visual', 'visual'), ('object', 'object'), ('recognition', 'recognit'), ('.', '.')]

>> Lemmatization: 
 [('Deep', 'Deep'), ('neural', 'neural'), ('networks', 'network'), ('rival', 'rival'), ('representation', 'representation'), ('primate', 'primate'), ('cortex', 'cortex'), ('core', 'core'), ('visual', 'visual'), ('object', 'object'), ('recognition', 'recognition'), ('.', '.')]


------------------- Sentence 4 -------------------

PLoS Comp.

>> Tokens are: 
 ['PLoS', 'Comp', '.']

>> Bigrams are: 
 [('PLoS', 'Comp'), ('Comp', '.')]

>> Trigrams are: 
 [('PLoS', 'Comp', '.')]

>> POS Tags are: 
 [('PLoS', 'NNP'), ('Comp', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['PLoS Comp']

>> Named Entities are: 
 [('ORGANIZATION', 'PLoS Comp')] 

>> Stemming using Porter Stemmer: 
 [('PLoS', 'plo'), ('Comp', 'comp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('PLoS', 'plos'), ('Comp', 'comp'), ('.', '.')]

>> Lemmatization: 
 [('PLoS', 'PLoS'), ('Comp', 'Comp'), ('.', '.')]


------------------- Sentence 5 -------------------

Biol.

>> Tokens are: 
 ['Biol', '.']

>> Bigrams are: 
 [('Biol', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Biol', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Biol']

>> Named Entities are: 
 [('GPE', 'Biol')] 

>> Stemming using Porter Stemmer: 
 [('Biol', 'biol'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Biol', 'biol'), ('.', '.')]

>> Lemmatization: 
 [('Biol', 'Biol'), ('.', '.')]


------------------- Sentence 6 -------------------

10, e1003963  (2014).

>> Tokens are: 
 ['10', ',', 'e1003963', '(', '2014', ')', '.']

>> Bigrams are: 
 [('10', ','), (',', 'e1003963'), ('e1003963', '('), ('(', '2014'), ('2014', ')'), (')', '.')]

>> Trigrams are: 
 [('10', ',', 'e1003963'), (',', 'e1003963', '('), ('e1003963', '(', '2014'), ('(', '2014', ')'), ('2014', ')', '.')]

>> POS Tags are: 
 [('10', 'CD'), (',', ','), ('e1003963', 'NN'), ('(', '('), ('2014', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['e1003963']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('10', '10'), (',', ','), ('e1003963', 'e1003963'), ('(', '('), ('2014', '2014'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('10', '10'), (',', ','), ('e1003963', 'e1003963'), ('(', '('), ('2014', '2014'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('10', '10'), (',', ','), ('e1003963', 'e1003963'), ('(', '('), ('2014', '2014'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 297 ===========================================

46. Fukushima, K. & Miyake, S. Neocognitron: a new algorithm for pattern  recognition tolerant of deformations and shifts in position. Pattern Recognition  15, 455–469 (1982).  

------------------- Sentence 1 -------------------

46.

>> Tokens are: 
 ['46', '.']

>> Bigrams are: 
 [('46', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('46', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('46', '46'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('46', '46'), ('.', '.')]

>> Lemmatization: 
 [('46', '46'), ('.', '.')]


------------------- Sentence 2 -------------------

Fukushima, K. & Miyake, S. Neocognitron: a new algorithm for pattern  recognition tolerant of deformations and shifts in position.

>> Tokens are: 
 ['Fukushima', ',', 'K.', '&', 'Miyake', ',', 'S.', 'Neocognitron', ':', 'new', 'algorithm', 'pattern', 'recognition', 'tolerant', 'deformations', 'shifts', 'position', '.']

>> Bigrams are: 
 [('Fukushima', ','), (',', 'K.'), ('K.', '&'), ('&', 'Miyake'), ('Miyake', ','), (',', 'S.'), ('S.', 'Neocognitron'), ('Neocognitron', ':'), (':', 'new'), ('new', 'algorithm'), ('algorithm', 'pattern'), ('pattern', 'recognition'), ('recognition', 'tolerant'), ('tolerant', 'deformations'), ('deformations', 'shifts'), ('shifts', 'position'), ('position', '.')]

>> Trigrams are: 
 [('Fukushima', ',', 'K.'), (',', 'K.', '&'), ('K.', '&', 'Miyake'), ('&', 'Miyake', ','), ('Miyake', ',', 'S.'), (',', 'S.', 'Neocognitron'), ('S.', 'Neocognitron', ':'), ('Neocognitron', ':', 'new'), (':', 'new', 'algorithm'), ('new', 'algorithm', 'pattern'), ('algorithm', 'pattern', 'recognition'), ('pattern', 'recognition', 'tolerant'), ('recognition', 'tolerant', 'deformations'), ('tolerant', 'deformations', 'shifts'), ('deformations', 'shifts', 'position'), ('shifts', 'position', '.')]

>> POS Tags are: 
 [('Fukushima', 'NNP'), (',', ','), ('K.', 'NNP'), ('&', 'CC'), ('Miyake', 'NNP'), (',', ','), ('S.', 'NNP'), ('Neocognitron', 'NNP'), (':', ':'), ('new', 'JJ'), ('algorithm', 'NN'), ('pattern', 'JJ'), ('recognition', 'NN'), ('tolerant', 'JJ'), ('deformations', 'NNS'), ('shifts', 'NNS'), ('position', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Fukushima', 'K.', 'Miyake', 'S. Neocognitron', 'new algorithm', 'pattern recognition', 'tolerant deformations shifts position']

>> Named Entities are: 
 [('GPE', 'Fukushima'), ('GPE', 'Miyake')] 

>> Stemming using Porter Stemmer: 
 [('Fukushima', 'fukushima'), (',', ','), ('K.', 'k.'), ('&', '&'), ('Miyake', 'miyak'), (',', ','), ('S.', 's.'), ('Neocognitron', 'neocognitron'), (':', ':'), ('new', 'new'), ('algorithm', 'algorithm'), ('pattern', 'pattern'), ('recognition', 'recognit'), ('tolerant', 'toler'), ('deformations', 'deform'), ('shifts', 'shift'), ('position', 'posit'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Fukushima', 'fukushima'), (',', ','), ('K.', 'k.'), ('&', '&'), ('Miyake', 'miyak'), (',', ','), ('S.', 's.'), ('Neocognitron', 'neocognitron'), (':', ':'), ('new', 'new'), ('algorithm', 'algorithm'), ('pattern', 'pattern'), ('recognition', 'recognit'), ('tolerant', 'toler'), ('deformations', 'deform'), ('shifts', 'shift'), ('position', 'posit'), ('.', '.')]

>> Lemmatization: 
 [('Fukushima', 'Fukushima'), (',', ','), ('K.', 'K.'), ('&', '&'), ('Miyake', 'Miyake'), (',', ','), ('S.', 'S.'), ('Neocognitron', 'Neocognitron'), (':', ':'), ('new', 'new'), ('algorithm', 'algorithm'), ('pattern', 'pattern'), ('recognition', 'recognition'), ('tolerant', 'tolerant'), ('deformations', 'deformation'), ('shifts', 'shift'), ('position', 'position'), ('.', '.')]


------------------- Sentence 3 -------------------

Pattern Recognition  15, 455–469 (1982).

>> Tokens are: 
 ['Pattern', 'Recognition', '15', ',', '455–469', '(', '1982', ')', '.']

>> Bigrams are: 
 [('Pattern', 'Recognition'), ('Recognition', '15'), ('15', ','), (',', '455–469'), ('455–469', '('), ('(', '1982'), ('1982', ')'), (')', '.')]

>> Trigrams are: 
 [('Pattern', 'Recognition', '15'), ('Recognition', '15', ','), ('15', ',', '455–469'), (',', '455–469', '('), ('455–469', '(', '1982'), ('(', '1982', ')'), ('1982', ')', '.')]

>> POS Tags are: 
 [('Pattern', 'NNP'), ('Recognition', 'NNP'), ('15', 'CD'), (',', ','), ('455–469', 'CD'), ('(', '('), ('1982', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['Pattern Recognition']

>> Named Entities are: 
 [('PERSON', 'Pattern')] 

>> Stemming using Porter Stemmer: 
 [('Pattern', 'pattern'), ('Recognition', 'recognit'), ('15', '15'), (',', ','), ('455–469', '455–469'), ('(', '('), ('1982', '1982'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Pattern', 'pattern'), ('Recognition', 'recognit'), ('15', '15'), (',', ','), ('455–469', '455–469'), ('(', '('), ('1982', '1982'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Pattern', 'Pattern'), ('Recognition', 'Recognition'), ('15', '15'), (',', ','), ('455–469', '455–469'), ('(', '('), ('1982', '1982'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 298 ===========================================

47. Waibel, A., Hanazawa, T., Hinton, G. E., Shikano, K. & Lang, K. Phoneme  recognition using time-delay neural networks. IEEE Trans. Acoustics Speech  Signal Process. 37, 328–339 (1989).  

------------------- Sentence 1 -------------------

47.

>> Tokens are: 
 ['47', '.']

>> Bigrams are: 
 [('47', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('47', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('47', '47'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('47', '47'), ('.', '.')]

>> Lemmatization: 
 [('47', '47'), ('.', '.')]


------------------- Sentence 2 -------------------

Waibel, A., Hanazawa, T., Hinton, G. E., Shikano, K. & Lang, K. Phoneme  recognition using time-delay neural networks.

>> Tokens are: 
 ['Waibel', ',', 'A.', ',', 'Hanazawa', ',', 'T.', ',', 'Hinton', ',', 'G.', 'E.', ',', 'Shikano', ',', 'K.', '&', 'Lang', ',', 'K.', 'Phoneme', 'recognition', 'using', 'time-delay', 'neural', 'networks', '.']

>> Bigrams are: 
 [('Waibel', ','), (',', 'A.'), ('A.', ','), (',', 'Hanazawa'), ('Hanazawa', ','), (',', 'T.'), ('T.', ','), (',', 'Hinton'), ('Hinton', ','), (',', 'G.'), ('G.', 'E.'), ('E.', ','), (',', 'Shikano'), ('Shikano', ','), (',', 'K.'), ('K.', '&'), ('&', 'Lang'), ('Lang', ','), (',', 'K.'), ('K.', 'Phoneme'), ('Phoneme', 'recognition'), ('recognition', 'using'), ('using', 'time-delay'), ('time-delay', 'neural'), ('neural', 'networks'), ('networks', '.')]

>> Trigrams are: 
 [('Waibel', ',', 'A.'), (',', 'A.', ','), ('A.', ',', 'Hanazawa'), (',', 'Hanazawa', ','), ('Hanazawa', ',', 'T.'), (',', 'T.', ','), ('T.', ',', 'Hinton'), (',', 'Hinton', ','), ('Hinton', ',', 'G.'), (',', 'G.', 'E.'), ('G.', 'E.', ','), ('E.', ',', 'Shikano'), (',', 'Shikano', ','), ('Shikano', ',', 'K.'), (',', 'K.', '&'), ('K.', '&', 'Lang'), ('&', 'Lang', ','), ('Lang', ',', 'K.'), (',', 'K.', 'Phoneme'), ('K.', 'Phoneme', 'recognition'), ('Phoneme', 'recognition', 'using'), ('recognition', 'using', 'time-delay'), ('using', 'time-delay', 'neural'), ('time-delay', 'neural', 'networks'), ('neural', 'networks', '.')]

>> POS Tags are: 
 [('Waibel', 'NNP'), (',', ','), ('A.', 'NNP'), (',', ','), ('Hanazawa', 'NNP'), (',', ','), ('T.', 'NNP'), (',', ','), ('Hinton', 'NNP'), (',', ','), ('G.', 'NNP'), ('E.', 'NNP'), (',', ','), ('Shikano', 'NNP'), (',', ','), ('K.', 'NNP'), ('&', 'CC'), ('Lang', 'NNP'), (',', ','), ('K.', 'NNP'), ('Phoneme', 'NNP'), ('recognition', 'NN'), ('using', 'VBG'), ('time-delay', 'JJ'), ('neural', 'JJ'), ('networks', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['Waibel', 'A.', 'Hanazawa', 'T.', 'Hinton', 'G. E.', 'Shikano', 'K.', 'Lang', 'K. Phoneme recognition', 'time-delay neural networks']

>> Named Entities are: 
 [('GPE', 'Waibel'), ('GPE', 'Hanazawa'), ('GPE', 'Hinton'), ('GPE', 'Shikano'), ('PERSON', 'Lang')] 

>> Stemming using Porter Stemmer: 
 [('Waibel', 'waibel'), (',', ','), ('A.', 'a.'), (',', ','), ('Hanazawa', 'hanazawa'), (',', ','), ('T.', 't.'), (',', ','), ('Hinton', 'hinton'), (',', ','), ('G.', 'g.'), ('E.', 'e.'), (',', ','), ('Shikano', 'shikano'), (',', ','), ('K.', 'k.'), ('&', '&'), ('Lang', 'lang'), (',', ','), ('K.', 'k.'), ('Phoneme', 'phonem'), ('recognition', 'recognit'), ('using', 'use'), ('time-delay', 'time-delay'), ('neural', 'neural'), ('networks', 'network'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Waibel', 'waibel'), (',', ','), ('A.', 'a.'), (',', ','), ('Hanazawa', 'hanazawa'), (',', ','), ('T.', 't.'), (',', ','), ('Hinton', 'hinton'), (',', ','), ('G.', 'g.'), ('E.', 'e.'), (',', ','), ('Shikano', 'shikano'), (',', ','), ('K.', 'k.'), ('&', '&'), ('Lang', 'lang'), (',', ','), ('K.', 'k.'), ('Phoneme', 'phonem'), ('recognition', 'recognit'), ('using', 'use'), ('time-delay', 'time-delay'), ('neural', 'neural'), ('networks', 'network'), ('.', '.')]

>> Lemmatization: 
 [('Waibel', 'Waibel'), (',', ','), ('A.', 'A.'), (',', ','), ('Hanazawa', 'Hanazawa'), (',', ','), ('T.', 'T.'), (',', ','), ('Hinton', 'Hinton'), (',', ','), ('G.', 'G.'), ('E.', 'E.'), (',', ','), ('Shikano', 'Shikano'), (',', ','), ('K.', 'K.'), ('&', '&'), ('Lang', 'Lang'), (',', ','), ('K.', 'K.'), ('Phoneme', 'Phoneme'), ('recognition', 'recognition'), ('using', 'using'), ('time-delay', 'time-delay'), ('neural', 'neural'), ('networks', 'network'), ('.', '.')]


------------------- Sentence 3 -------------------

IEEE Trans.

>> Tokens are: 
 ['IEEE', 'Trans', '.']

>> Bigrams are: 
 [('IEEE', 'Trans'), ('Trans', '.')]

>> Trigrams are: 
 [('IEEE', 'Trans', '.')]

>> POS Tags are: 
 [('IEEE', 'NNP'), ('Trans', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['IEEE Trans']

>> Named Entities are: 
 [('ORGANIZATION', 'IEEE Trans')] 

>> Stemming using Porter Stemmer: 
 [('IEEE', 'ieee'), ('Trans', 'tran'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('IEEE', 'ieee'), ('Trans', 'tran'), ('.', '.')]

>> Lemmatization: 
 [('IEEE', 'IEEE'), ('Trans', 'Trans'), ('.', '.')]


------------------- Sentence 4 -------------------

Acoustics Speech  Signal Process.

>> Tokens are: 
 ['Acoustics', 'Speech', 'Signal', 'Process', '.']

>> Bigrams are: 
 [('Acoustics', 'Speech'), ('Speech', 'Signal'), ('Signal', 'Process'), ('Process', '.')]

>> Trigrams are: 
 [('Acoustics', 'Speech', 'Signal'), ('Speech', 'Signal', 'Process'), ('Signal', 'Process', '.')]

>> POS Tags are: 
 [('Acoustics', 'NNS'), ('Speech', 'NNP'), ('Signal', 'NNP'), ('Process', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Acoustics Speech Signal Process']

>> Named Entities are: 
 [('PERSON', 'Speech Signal Process')] 

>> Stemming using Porter Stemmer: 
 [('Acoustics', 'acoust'), ('Speech', 'speech'), ('Signal', 'signal'), ('Process', 'process'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Acoustics', 'acoust'), ('Speech', 'speech'), ('Signal', 'signal'), ('Process', 'process'), ('.', '.')]

>> Lemmatization: 
 [('Acoustics', 'Acoustics'), ('Speech', 'Speech'), ('Signal', 'Signal'), ('Process', 'Process'), ('.', '.')]


------------------- Sentence 5 -------------------

37, 328–339 (1989).

>> Tokens are: 
 ['37', ',', '328–339', '(', '1989', ')', '.']

>> Bigrams are: 
 [('37', ','), (',', '328–339'), ('328–339', '('), ('(', '1989'), ('1989', ')'), (')', '.')]

>> Trigrams are: 
 [('37', ',', '328–339'), (',', '328–339', '('), ('328–339', '(', '1989'), ('(', '1989', ')'), ('1989', ')', '.')]

>> POS Tags are: 
 [('37', 'CD'), (',', ','), ('328–339', 'CD'), ('(', '('), ('1989', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('37', '37'), (',', ','), ('328–339', '328–339'), ('(', '('), ('1989', '1989'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('37', '37'), (',', ','), ('328–339', '328–339'), ('(', '('), ('1989', '1989'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('37', '37'), (',', ','), ('328–339', '328–339'), ('(', '('), ('1989', '1989'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 299 ===========================================

48. Bottou, L., Fogelman-Soulié, F., Blanchet, P. & Lienard, J. Experiments with time  delay networks and dynamic time warping for speaker independent isolated  digit recognition. In Proc. EuroSpeech 89 537–540 (1989).  

------------------- Sentence 1 -------------------

48.

>> Tokens are: 
 ['48', '.']

>> Bigrams are: 
 [('48', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('48', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('48', '48'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('48', '48'), ('.', '.')]

>> Lemmatization: 
 [('48', '48'), ('.', '.')]


------------------- Sentence 2 -------------------

Bottou, L., Fogelman-Soulié, F., Blanchet, P. & Lienard, J.

>> Tokens are: 
 ['Bottou', ',', 'L.', ',', 'Fogelman-Soulié', ',', 'F.', ',', 'Blanchet', ',', 'P.', '&', 'Lienard', ',', 'J', '.']

>> Bigrams are: 
 [('Bottou', ','), (',', 'L.'), ('L.', ','), (',', 'Fogelman-Soulié'), ('Fogelman-Soulié', ','), (',', 'F.'), ('F.', ','), (',', 'Blanchet'), ('Blanchet', ','), (',', 'P.'), ('P.', '&'), ('&', 'Lienard'), ('Lienard', ','), (',', 'J'), ('J', '.')]

>> Trigrams are: 
 [('Bottou', ',', 'L.'), (',', 'L.', ','), ('L.', ',', 'Fogelman-Soulié'), (',', 'Fogelman-Soulié', ','), ('Fogelman-Soulié', ',', 'F.'), (',', 'F.', ','), ('F.', ',', 'Blanchet'), (',', 'Blanchet', ','), ('Blanchet', ',', 'P.'), (',', 'P.', '&'), ('P.', '&', 'Lienard'), ('&', 'Lienard', ','), ('Lienard', ',', 'J'), (',', 'J', '.')]

>> POS Tags are: 
 [('Bottou', 'NNP'), (',', ','), ('L.', 'NNP'), (',', ','), ('Fogelman-Soulié', 'NNP'), (',', ','), ('F.', 'NNP'), (',', ','), ('Blanchet', 'NNP'), (',', ','), ('P.', 'NNP'), ('&', 'CC'), ('Lienard', 'NNP'), (',', ','), ('J', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Bottou', 'L.', 'Fogelman-Soulié', 'F.', 'Blanchet', 'P.', 'Lienard', 'J']

>> Named Entities are: 
 [('GPE', 'Bottou'), ('PERSON', 'Blanchet'), ('PERSON', 'Lienard')] 

>> Stemming using Porter Stemmer: 
 [('Bottou', 'bottou'), (',', ','), ('L.', 'l.'), (',', ','), ('Fogelman-Soulié', 'fogelman-soulié'), (',', ','), ('F.', 'f.'), (',', ','), ('Blanchet', 'blanchet'), (',', ','), ('P.', 'p.'), ('&', '&'), ('Lienard', 'lienard'), (',', ','), ('J', 'j'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Bottou', 'bottou'), (',', ','), ('L.', 'l.'), (',', ','), ('Fogelman-Soulié', 'fogelman-soulié'), (',', ','), ('F.', 'f.'), (',', ','), ('Blanchet', 'blanchet'), (',', ','), ('P.', 'p.'), ('&', '&'), ('Lienard', 'lienard'), (',', ','), ('J', 'j'), ('.', '.')]

>> Lemmatization: 
 [('Bottou', 'Bottou'), (',', ','), ('L.', 'L.'), (',', ','), ('Fogelman-Soulié', 'Fogelman-Soulié'), (',', ','), ('F.', 'F.'), (',', ','), ('Blanchet', 'Blanchet'), (',', ','), ('P.', 'P.'), ('&', '&'), ('Lienard', 'Lienard'), (',', ','), ('J', 'J'), ('.', '.')]


------------------- Sentence 3 -------------------

Experiments with time  delay networks and dynamic time warping for speaker independent isolated  digit recognition.

>> Tokens are: 
 ['Experiments', 'time', 'delay', 'networks', 'dynamic', 'time', 'warping', 'speaker', 'independent', 'isolated', 'digit', 'recognition', '.']

>> Bigrams are: 
 [('Experiments', 'time'), ('time', 'delay'), ('delay', 'networks'), ('networks', 'dynamic'), ('dynamic', 'time'), ('time', 'warping'), ('warping', 'speaker'), ('speaker', 'independent'), ('independent', 'isolated'), ('isolated', 'digit'), ('digit', 'recognition'), ('recognition', '.')]

>> Trigrams are: 
 [('Experiments', 'time', 'delay'), ('time', 'delay', 'networks'), ('delay', 'networks', 'dynamic'), ('networks', 'dynamic', 'time'), ('dynamic', 'time', 'warping'), ('time', 'warping', 'speaker'), ('warping', 'speaker', 'independent'), ('speaker', 'independent', 'isolated'), ('independent', 'isolated', 'digit'), ('isolated', 'digit', 'recognition'), ('digit', 'recognition', '.')]

>> POS Tags are: 
 [('Experiments', 'NNS'), ('time', 'NN'), ('delay', 'NN'), ('networks', 'NNS'), ('dynamic', 'JJ'), ('time', 'NN'), ('warping', 'VBG'), ('speaker', 'NN'), ('independent', 'JJ'), ('isolated', 'JJ'), ('digit', 'JJ'), ('recognition', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Experiments time delay networks', 'dynamic time', 'speaker', 'independent isolated digit recognition']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Experiments', 'experi'), ('time', 'time'), ('delay', 'delay'), ('networks', 'network'), ('dynamic', 'dynam'), ('time', 'time'), ('warping', 'warp'), ('speaker', 'speaker'), ('independent', 'independ'), ('isolated', 'isol'), ('digit', 'digit'), ('recognition', 'recognit'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Experiments', 'experi'), ('time', 'time'), ('delay', 'delay'), ('networks', 'network'), ('dynamic', 'dynam'), ('time', 'time'), ('warping', 'warp'), ('speaker', 'speaker'), ('independent', 'independ'), ('isolated', 'isol'), ('digit', 'digit'), ('recognition', 'recognit'), ('.', '.')]

>> Lemmatization: 
 [('Experiments', 'Experiments'), ('time', 'time'), ('delay', 'delay'), ('networks', 'network'), ('dynamic', 'dynamic'), ('time', 'time'), ('warping', 'warping'), ('speaker', 'speaker'), ('independent', 'independent'), ('isolated', 'isolated'), ('digit', 'digit'), ('recognition', 'recognition'), ('.', '.')]


------------------- Sentence 4 -------------------

In Proc.

>> Tokens are: 
 ['In', 'Proc', '.']

>> Bigrams are: 
 [('In', 'Proc'), ('Proc', '.')]

>> Trigrams are: 
 [('In', 'Proc', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('Proc', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Proc']

>> Named Entities are: 
 [('GPE', 'Proc')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('Proc', 'proc'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('Proc', 'proc'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('Proc', 'Proc'), ('.', '.')]


------------------- Sentence 5 -------------------

EuroSpeech 89 537–540 (1989).

>> Tokens are: 
 ['EuroSpeech', '89', '537–540', '(', '1989', ')', '.']

>> Bigrams are: 
 [('EuroSpeech', '89'), ('89', '537–540'), ('537–540', '('), ('(', '1989'), ('1989', ')'), (')', '.')]

>> Trigrams are: 
 [('EuroSpeech', '89', '537–540'), ('89', '537–540', '('), ('537–540', '(', '1989'), ('(', '1989', ')'), ('1989', ')', '.')]

>> POS Tags are: 
 [('EuroSpeech', 'NNP'), ('89', 'CD'), ('537–540', 'CD'), ('(', '('), ('1989', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['EuroSpeech']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('EuroSpeech', 'eurospeech'), ('89', '89'), ('537–540', '537–540'), ('(', '('), ('1989', '1989'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('EuroSpeech', 'eurospeech'), ('89', '89'), ('537–540', '537–540'), ('(', '('), ('1989', '1989'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('EuroSpeech', 'EuroSpeech'), ('89', '89'), ('537–540', '537–540'), ('(', '('), ('1989', '1989'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 300 ===========================================

49. Simard, D., Steinkraus, P. Y. & Platt, J. C. Best practices for convolutional neural  networks. In Proc. Document Analysis and Recognition 958–963 (2003).  

------------------- Sentence 1 -------------------

49.

>> Tokens are: 
 ['49', '.']

>> Bigrams are: 
 [('49', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('49', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('49', '49'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('49', '49'), ('.', '.')]

>> Lemmatization: 
 [('49', '49'), ('.', '.')]


------------------- Sentence 2 -------------------

Simard, D., Steinkraus, P. Y.

>> Tokens are: 
 ['Simard', ',', 'D.', ',', 'Steinkraus', ',', 'P.', 'Y', '.']

>> Bigrams are: 
 [('Simard', ','), (',', 'D.'), ('D.', ','), (',', 'Steinkraus'), ('Steinkraus', ','), (',', 'P.'), ('P.', 'Y'), ('Y', '.')]

>> Trigrams are: 
 [('Simard', ',', 'D.'), (',', 'D.', ','), ('D.', ',', 'Steinkraus'), (',', 'Steinkraus', ','), ('Steinkraus', ',', 'P.'), (',', 'P.', 'Y'), ('P.', 'Y', '.')]

>> POS Tags are: 
 [('Simard', 'NNP'), (',', ','), ('D.', 'NNP'), (',', ','), ('Steinkraus', 'NNP'), (',', ','), ('P.', 'NNP'), ('Y', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Simard', 'D.', 'Steinkraus', 'P. Y']

>> Named Entities are: 
 [('GPE', 'Simard'), ('PERSON', 'Steinkraus')] 

>> Stemming using Porter Stemmer: 
 [('Simard', 'simard'), (',', ','), ('D.', 'd.'), (',', ','), ('Steinkraus', 'steinkrau'), (',', ','), ('P.', 'p.'), ('Y', 'y'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Simard', 'simard'), (',', ','), ('D.', 'd.'), (',', ','), ('Steinkraus', 'steinkraus'), (',', ','), ('P.', 'p.'), ('Y', 'y'), ('.', '.')]

>> Lemmatization: 
 [('Simard', 'Simard'), (',', ','), ('D.', 'D.'), (',', ','), ('Steinkraus', 'Steinkraus'), (',', ','), ('P.', 'P.'), ('Y', 'Y'), ('.', '.')]


------------------- Sentence 3 -------------------

& Platt, J. C. Best practices for convolutional neural  networks.

>> Tokens are: 
 ['&', 'Platt', ',', 'J.', 'C.', 'Best', 'practices', 'convolutional', 'neural', 'networks', '.']

>> Bigrams are: 
 [('&', 'Platt'), ('Platt', ','), (',', 'J.'), ('J.', 'C.'), ('C.', 'Best'), ('Best', 'practices'), ('practices', 'convolutional'), ('convolutional', 'neural'), ('neural', 'networks'), ('networks', '.')]

>> Trigrams are: 
 [('&', 'Platt', ','), ('Platt', ',', 'J.'), (',', 'J.', 'C.'), ('J.', 'C.', 'Best'), ('C.', 'Best', 'practices'), ('Best', 'practices', 'convolutional'), ('practices', 'convolutional', 'neural'), ('convolutional', 'neural', 'networks'), ('neural', 'networks', '.')]

>> POS Tags are: 
 [('&', 'CC'), ('Platt', 'NNP'), (',', ','), ('J.', 'NNP'), ('C.', 'NNP'), ('Best', 'NNP'), ('practices', 'NNS'), ('convolutional', 'JJ'), ('neural', 'JJ'), ('networks', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['Platt', 'J. C. Best practices', 'convolutional neural networks']

>> Named Entities are: 
 [('PERSON', 'Platt'), ('PERSON', 'J. C. Best')] 

>> Stemming using Porter Stemmer: 
 [('&', '&'), ('Platt', 'platt'), (',', ','), ('J.', 'j.'), ('C.', 'c.'), ('Best', 'best'), ('practices', 'practic'), ('convolutional', 'convolut'), ('neural', 'neural'), ('networks', 'network'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('&', '&'), ('Platt', 'platt'), (',', ','), ('J.', 'j.'), ('C.', 'c.'), ('Best', 'best'), ('practices', 'practic'), ('convolutional', 'convolut'), ('neural', 'neural'), ('networks', 'network'), ('.', '.')]

>> Lemmatization: 
 [('&', '&'), ('Platt', 'Platt'), (',', ','), ('J.', 'J.'), ('C.', 'C.'), ('Best', 'Best'), ('practices', 'practice'), ('convolutional', 'convolutional'), ('neural', 'neural'), ('networks', 'network'), ('.', '.')]


------------------- Sentence 4 -------------------

In Proc.

>> Tokens are: 
 ['In', 'Proc', '.']

>> Bigrams are: 
 [('In', 'Proc'), ('Proc', '.')]

>> Trigrams are: 
 [('In', 'Proc', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('Proc', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Proc']

>> Named Entities are: 
 [('GPE', 'Proc')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('Proc', 'proc'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('Proc', 'proc'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('Proc', 'Proc'), ('.', '.')]


------------------- Sentence 5 -------------------

Document Analysis and Recognition 958–963 (2003).

>> Tokens are: 
 ['Document', 'Analysis', 'Recognition', '958–963', '(', '2003', ')', '.']

>> Bigrams are: 
 [('Document', 'Analysis'), ('Analysis', 'Recognition'), ('Recognition', '958–963'), ('958–963', '('), ('(', '2003'), ('2003', ')'), (')', '.')]

>> Trigrams are: 
 [('Document', 'Analysis', 'Recognition'), ('Analysis', 'Recognition', '958–963'), ('Recognition', '958–963', '('), ('958–963', '(', '2003'), ('(', '2003', ')'), ('2003', ')', '.')]

>> POS Tags are: 
 [('Document', 'NNP'), ('Analysis', 'NNP'), ('Recognition', 'NNP'), ('958–963', 'CD'), ('(', '('), ('2003', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['Document Analysis Recognition']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Document', 'document'), ('Analysis', 'analysi'), ('Recognition', 'recognit'), ('958–963', '958–963'), ('(', '('), ('2003', '2003'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Document', 'document'), ('Analysis', 'analysi'), ('Recognition', 'recognit'), ('958–963', '958–963'), ('(', '('), ('2003', '2003'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Document', 'Document'), ('Analysis', 'Analysis'), ('Recognition', 'Recognition'), ('958–963', '958–963'), ('(', '('), ('2003', '2003'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 301 ===========================================

50. Vaillant, R., Monrocq, C. & LeCun, Y. Original approach for the localisation of  objects in images. In Proc. Vision, Image, and Signal Processing 141, 245–250  (1994).  

------------------- Sentence 1 -------------------

50.

>> Tokens are: 
 ['50', '.']

>> Bigrams are: 
 [('50', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('50', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('50', '50'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('50', '50'), ('.', '.')]

>> Lemmatization: 
 [('50', '50'), ('.', '.')]


------------------- Sentence 2 -------------------

Vaillant, R., Monrocq, C. & LeCun, Y.

>> Tokens are: 
 ['Vaillant', ',', 'R.', ',', 'Monrocq', ',', 'C.', '&', 'LeCun', ',', 'Y', '.']

>> Bigrams are: 
 [('Vaillant', ','), (',', 'R.'), ('R.', ','), (',', 'Monrocq'), ('Monrocq', ','), (',', 'C.'), ('C.', '&'), ('&', 'LeCun'), ('LeCun', ','), (',', 'Y'), ('Y', '.')]

>> Trigrams are: 
 [('Vaillant', ',', 'R.'), (',', 'R.', ','), ('R.', ',', 'Monrocq'), (',', 'Monrocq', ','), ('Monrocq', ',', 'C.'), (',', 'C.', '&'), ('C.', '&', 'LeCun'), ('&', 'LeCun', ','), ('LeCun', ',', 'Y'), (',', 'Y', '.')]

>> POS Tags are: 
 [('Vaillant', 'NNP'), (',', ','), ('R.', 'NNP'), (',', ','), ('Monrocq', 'NNP'), (',', ','), ('C.', 'NNP'), ('&', 'CC'), ('LeCun', 'NNP'), (',', ','), ('Y', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Vaillant', 'R.', 'Monrocq', 'C.', 'LeCun', 'Y']

>> Named Entities are: 
 [('GPE', 'Vaillant'), ('PERSON', 'Monrocq'), ('ORGANIZATION', 'LeCun')] 

>> Stemming using Porter Stemmer: 
 [('Vaillant', 'vaillant'), (',', ','), ('R.', 'r.'), (',', ','), ('Monrocq', 'monrocq'), (',', ','), ('C.', 'c.'), ('&', '&'), ('LeCun', 'lecun'), (',', ','), ('Y', 'y'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Vaillant', 'vaillant'), (',', ','), ('R.', 'r.'), (',', ','), ('Monrocq', 'monrocq'), (',', ','), ('C.', 'c.'), ('&', '&'), ('LeCun', 'lecun'), (',', ','), ('Y', 'y'), ('.', '.')]

>> Lemmatization: 
 [('Vaillant', 'Vaillant'), (',', ','), ('R.', 'R.'), (',', ','), ('Monrocq', 'Monrocq'), (',', ','), ('C.', 'C.'), ('&', '&'), ('LeCun', 'LeCun'), (',', ','), ('Y', 'Y'), ('.', '.')]


------------------- Sentence 3 -------------------

Original approach for the localisation of  objects in images.

>> Tokens are: 
 ['Original', 'approach', 'localisation', 'objects', 'images', '.']

>> Bigrams are: 
 [('Original', 'approach'), ('approach', 'localisation'), ('localisation', 'objects'), ('objects', 'images'), ('images', '.')]

>> Trigrams are: 
 [('Original', 'approach', 'localisation'), ('approach', 'localisation', 'objects'), ('localisation', 'objects', 'images'), ('objects', 'images', '.')]

>> POS Tags are: 
 [('Original', 'JJ'), ('approach', 'NN'), ('localisation', 'NN'), ('objects', 'NNS'), ('images', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['Original approach localisation objects images']

>> Named Entities are: 
 [('GPE', 'Original')] 

>> Stemming using Porter Stemmer: 
 [('Original', 'origin'), ('approach', 'approach'), ('localisation', 'localis'), ('objects', 'object'), ('images', 'imag'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Original', 'origin'), ('approach', 'approach'), ('localisation', 'localis'), ('objects', 'object'), ('images', 'imag'), ('.', '.')]

>> Lemmatization: 
 [('Original', 'Original'), ('approach', 'approach'), ('localisation', 'localisation'), ('objects', 'object'), ('images', 'image'), ('.', '.')]


------------------- Sentence 4 -------------------

In Proc.

>> Tokens are: 
 ['In', 'Proc', '.']

>> Bigrams are: 
 [('In', 'Proc'), ('Proc', '.')]

>> Trigrams are: 
 [('In', 'Proc', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('Proc', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Proc']

>> Named Entities are: 
 [('GPE', 'Proc')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('Proc', 'proc'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('Proc', 'proc'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('Proc', 'Proc'), ('.', '.')]


------------------- Sentence 5 -------------------

Vision, Image, and Signal Processing 141, 245–250  (1994).

>> Tokens are: 
 ['Vision', ',', 'Image', ',', 'Signal', 'Processing', '141', ',', '245–250', '(', '1994', ')', '.']

>> Bigrams are: 
 [('Vision', ','), (',', 'Image'), ('Image', ','), (',', 'Signal'), ('Signal', 'Processing'), ('Processing', '141'), ('141', ','), (',', '245–250'), ('245–250', '('), ('(', '1994'), ('1994', ')'), (')', '.')]

>> Trigrams are: 
 [('Vision', ',', 'Image'), (',', 'Image', ','), ('Image', ',', 'Signal'), (',', 'Signal', 'Processing'), ('Signal', 'Processing', '141'), ('Processing', '141', ','), ('141', ',', '245–250'), (',', '245–250', '('), ('245–250', '(', '1994'), ('(', '1994', ')'), ('1994', ')', '.')]

>> POS Tags are: 
 [('Vision', 'NN'), (',', ','), ('Image', 'NNP'), (',', ','), ('Signal', 'NNP'), ('Processing', 'NNP'), ('141', 'CD'), (',', ','), ('245–250', 'CD'), ('(', '('), ('1994', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['Vision', 'Image', 'Signal Processing']

>> Named Entities are: 
 [('GPE', 'Vision'), ('PERSON', 'Image'), ('PERSON', 'Signal')] 

>> Stemming using Porter Stemmer: 
 [('Vision', 'vision'), (',', ','), ('Image', 'imag'), (',', ','), ('Signal', 'signal'), ('Processing', 'process'), ('141', '141'), (',', ','), ('245–250', '245–250'), ('(', '('), ('1994', '1994'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Vision', 'vision'), (',', ','), ('Image', 'imag'), (',', ','), ('Signal', 'signal'), ('Processing', 'process'), ('141', '141'), (',', ','), ('245–250', '245–250'), ('(', '('), ('1994', '1994'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Vision', 'Vision'), (',', ','), ('Image', 'Image'), (',', ','), ('Signal', 'Signal'), ('Processing', 'Processing'), ('141', '141'), (',', ','), ('245–250', '245–250'), ('(', '('), ('1994', '1994'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 302 ===========================================

51. Nowlan, S. & Platt, J. in Neural Information Processing Systems 901–908 (1995).  52. Lawrence, S., Giles, C. L., Tsoi, A. C. & Back, A. D. Face recognition: a  

------------------- Sentence 1 -------------------

51.

>> Tokens are: 
 ['51', '.']

>> Bigrams are: 
 [('51', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('51', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('51', '51'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('51', '51'), ('.', '.')]

>> Lemmatization: 
 [('51', '51'), ('.', '.')]


------------------- Sentence 2 -------------------

Nowlan, S. & Platt, J. in Neural Information Processing Systems 901–908 (1995).

>> Tokens are: 
 ['Nowlan', ',', 'S.', '&', 'Platt', ',', 'J.', 'Neural', 'Information', 'Processing', 'Systems', '901–908', '(', '1995', ')', '.']

>> Bigrams are: 
 [('Nowlan', ','), (',', 'S.'), ('S.', '&'), ('&', 'Platt'), ('Platt', ','), (',', 'J.'), ('J.', 'Neural'), ('Neural', 'Information'), ('Information', 'Processing'), ('Processing', 'Systems'), ('Systems', '901–908'), ('901–908', '('), ('(', '1995'), ('1995', ')'), (')', '.')]

>> Trigrams are: 
 [('Nowlan', ',', 'S.'), (',', 'S.', '&'), ('S.', '&', 'Platt'), ('&', 'Platt', ','), ('Platt', ',', 'J.'), (',', 'J.', 'Neural'), ('J.', 'Neural', 'Information'), ('Neural', 'Information', 'Processing'), ('Information', 'Processing', 'Systems'), ('Processing', 'Systems', '901–908'), ('Systems', '901–908', '('), ('901–908', '(', '1995'), ('(', '1995', ')'), ('1995', ')', '.')]

>> POS Tags are: 
 [('Nowlan', 'NNP'), (',', ','), ('S.', 'NNP'), ('&', 'CC'), ('Platt', 'NNP'), (',', ','), ('J.', 'NNP'), ('Neural', 'NNP'), ('Information', 'NNP'), ('Processing', 'NNP'), ('Systems', 'NNPS'), ('901–908', 'CD'), ('(', '('), ('1995', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['Nowlan', 'S.', 'Platt', 'J. Neural Information Processing']

>> Named Entities are: 
 [('GPE', 'Nowlan'), ('PERSON', 'Platt'), ('PERSON', 'J. Neural')] 

>> Stemming using Porter Stemmer: 
 [('Nowlan', 'nowlan'), (',', ','), ('S.', 's.'), ('&', '&'), ('Platt', 'platt'), (',', ','), ('J.', 'j.'), ('Neural', 'neural'), ('Information', 'inform'), ('Processing', 'process'), ('Systems', 'system'), ('901–908', '901–908'), ('(', '('), ('1995', '1995'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Nowlan', 'nowlan'), (',', ','), ('S.', 's.'), ('&', '&'), ('Platt', 'platt'), (',', ','), ('J.', 'j.'), ('Neural', 'neural'), ('Information', 'inform'), ('Processing', 'process'), ('Systems', 'system'), ('901–908', '901–908'), ('(', '('), ('1995', '1995'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Nowlan', 'Nowlan'), (',', ','), ('S.', 'S.'), ('&', '&'), ('Platt', 'Platt'), (',', ','), ('J.', 'J.'), ('Neural', 'Neural'), ('Information', 'Information'), ('Processing', 'Processing'), ('Systems', 'Systems'), ('901–908', '901–908'), ('(', '('), ('1995', '1995'), (')', ')'), ('.', '.')]


------------------- Sentence 3 -------------------

52.

>> Tokens are: 
 ['52', '.']

>> Bigrams are: 
 [('52', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('52', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('52', '52'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('52', '52'), ('.', '.')]

>> Lemmatization: 
 [('52', '52'), ('.', '.')]


------------------- Sentence 4 -------------------

Lawrence, S., Giles, C. L., Tsoi, A. C. & Back, A. D. Face recognition: a

>> Tokens are: 
 ['Lawrence', ',', 'S.', ',', 'Giles', ',', 'C.', 'L.', ',', 'Tsoi', ',', 'A.', 'C.', '&', 'Back', ',', 'A.', 'D.', 'Face', 'recognition', ':']

>> Bigrams are: 
 [('Lawrence', ','), (',', 'S.'), ('S.', ','), (',', 'Giles'), ('Giles', ','), (',', 'C.'), ('C.', 'L.'), ('L.', ','), (',', 'Tsoi'), ('Tsoi', ','), (',', 'A.'), ('A.', 'C.'), ('C.', '&'), ('&', 'Back'), ('Back', ','), (',', 'A.'), ('A.', 'D.'), ('D.', 'Face'), ('Face', 'recognition'), ('recognition', ':')]

>> Trigrams are: 
 [('Lawrence', ',', 'S.'), (',', 'S.', ','), ('S.', ',', 'Giles'), (',', 'Giles', ','), ('Giles', ',', 'C.'), (',', 'C.', 'L.'), ('C.', 'L.', ','), ('L.', ',', 'Tsoi'), (',', 'Tsoi', ','), ('Tsoi', ',', 'A.'), (',', 'A.', 'C.'), ('A.', 'C.', '&'), ('C.', '&', 'Back'), ('&', 'Back', ','), ('Back', ',', 'A.'), (',', 'A.', 'D.'), ('A.', 'D.', 'Face'), ('D.', 'Face', 'recognition'), ('Face', 'recognition', ':')]

>> POS Tags are: 
 [('Lawrence', 'NNP'), (',', ','), ('S.', 'NNP'), (',', ','), ('Giles', 'NNP'), (',', ','), ('C.', 'NNP'), ('L.', 'NNP'), (',', ','), ('Tsoi', 'NNP'), (',', ','), ('A.', 'NNP'), ('C.', 'NNP'), ('&', 'CC'), ('Back', 'NNP'), (',', ','), ('A.', 'NNP'), ('D.', 'NNP'), ('Face', 'NNP'), ('recognition', 'NN'), (':', ':')]

>> Noun Phrases are: 
 ['Lawrence', 'S.', 'Giles', 'C. L.', 'Tsoi', 'A. C.', 'Back', 'A. D. Face recognition']

>> Named Entities are: 
 [('GPE', 'Lawrence'), ('PERSON', 'Giles'), ('PERSON', 'Tsoi')] 

>> Stemming using Porter Stemmer: 
 [('Lawrence', 'lawrenc'), (',', ','), ('S.', 's.'), (',', ','), ('Giles', 'gile'), (',', ','), ('C.', 'c.'), ('L.', 'l.'), (',', ','), ('Tsoi', 'tsoi'), (',', ','), ('A.', 'a.'), ('C.', 'c.'), ('&', '&'), ('Back', 'back'), (',', ','), ('A.', 'a.'), ('D.', 'd.'), ('Face', 'face'), ('recognition', 'recognit'), (':', ':')]

>> Stemming using Snowball Stemmer: 
 [('Lawrence', 'lawrenc'), (',', ','), ('S.', 's.'), (',', ','), ('Giles', 'gile'), (',', ','), ('C.', 'c.'), ('L.', 'l.'), (',', ','), ('Tsoi', 'tsoi'), (',', ','), ('A.', 'a.'), ('C.', 'c.'), ('&', '&'), ('Back', 'back'), (',', ','), ('A.', 'a.'), ('D.', 'd.'), ('Face', 'face'), ('recognition', 'recognit'), (':', ':')]

>> Lemmatization: 
 [('Lawrence', 'Lawrence'), (',', ','), ('S.', 'S.'), (',', ','), ('Giles', 'Giles'), (',', ','), ('C.', 'C.'), ('L.', 'L.'), (',', ','), ('Tsoi', 'Tsoi'), (',', ','), ('A.', 'A.'), ('C.', 'C.'), ('&', '&'), ('Back', 'Back'), (',', ','), ('A.', 'A.'), ('D.', 'D.'), ('Face', 'Face'), ('recognition', 'recognition'), (':', ':')]



========================================== PARAGRAPH 303 ===========================================

convolutional neural-network approach. IEEE Trans. Neural Networks 8, 98–113  (1997).  

------------------- Sentence 1 -------------------

convolutional neural-network approach.

>> Tokens are: 
 ['convolutional', 'neural-network', 'approach', '.']

>> Bigrams are: 
 [('convolutional', 'neural-network'), ('neural-network', 'approach'), ('approach', '.')]

>> Trigrams are: 
 [('convolutional', 'neural-network', 'approach'), ('neural-network', 'approach', '.')]

>> POS Tags are: 
 [('convolutional', 'JJ'), ('neural-network', 'JJ'), ('approach', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['convolutional neural-network approach']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('convolutional', 'convolut'), ('neural-network', 'neural-network'), ('approach', 'approach'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('convolutional', 'convolut'), ('neural-network', 'neural-network'), ('approach', 'approach'), ('.', '.')]

>> Lemmatization: 
 [('convolutional', 'convolutional'), ('neural-network', 'neural-network'), ('approach', 'approach'), ('.', '.')]


------------------- Sentence 2 -------------------

IEEE Trans.

>> Tokens are: 
 ['IEEE', 'Trans', '.']

>> Bigrams are: 
 [('IEEE', 'Trans'), ('Trans', '.')]

>> Trigrams are: 
 [('IEEE', 'Trans', '.')]

>> POS Tags are: 
 [('IEEE', 'NNP'), ('Trans', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['IEEE Trans']

>> Named Entities are: 
 [('ORGANIZATION', 'IEEE Trans')] 

>> Stemming using Porter Stemmer: 
 [('IEEE', 'ieee'), ('Trans', 'tran'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('IEEE', 'ieee'), ('Trans', 'tran'), ('.', '.')]

>> Lemmatization: 
 [('IEEE', 'IEEE'), ('Trans', 'Trans'), ('.', '.')]


------------------- Sentence 3 -------------------

Neural Networks 8, 98–113  (1997).

>> Tokens are: 
 ['Neural', 'Networks', '8', ',', '98–113', '(', '1997', ')', '.']

>> Bigrams are: 
 [('Neural', 'Networks'), ('Networks', '8'), ('8', ','), (',', '98–113'), ('98–113', '('), ('(', '1997'), ('1997', ')'), (')', '.')]

>> Trigrams are: 
 [('Neural', 'Networks', '8'), ('Networks', '8', ','), ('8', ',', '98–113'), (',', '98–113', '('), ('98–113', '(', '1997'), ('(', '1997', ')'), ('1997', ')', '.')]

>> POS Tags are: 
 [('Neural', 'JJ'), ('Networks', 'NNP'), ('8', 'CD'), (',', ','), ('98–113', 'CD'), ('(', '('), ('1997', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['Neural Networks']

>> Named Entities are: 
 [('ORGANIZATION', 'Networks')] 

>> Stemming using Porter Stemmer: 
 [('Neural', 'neural'), ('Networks', 'network'), ('8', '8'), (',', ','), ('98–113', '98–113'), ('(', '('), ('1997', '1997'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Neural', 'neural'), ('Networks', 'network'), ('8', '8'), (',', ','), ('98–113', '98–113'), ('(', '('), ('1997', '1997'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Neural', 'Neural'), ('Networks', 'Networks'), ('8', '8'), (',', ','), ('98–113', '98–113'), ('(', '('), ('1997', '1997'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 304 ===========================================

53. Ciresan, D., Meier, U. Masci, J. & Schmidhuber, J. Multi-column deep neural  network for traffic sign classification. Neural Networks 32, 333–338 (2012).  

------------------- Sentence 1 -------------------

53.

>> Tokens are: 
 ['53', '.']

>> Bigrams are: 
 [('53', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('53', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('53', '53'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('53', '53'), ('.', '.')]

>> Lemmatization: 
 [('53', '53'), ('.', '.')]


------------------- Sentence 2 -------------------

Ciresan, D., Meier, U. Masci, J.

>> Tokens are: 
 ['Ciresan', ',', 'D.', ',', 'Meier', ',', 'U.', 'Masci', ',', 'J', '.']

>> Bigrams are: 
 [('Ciresan', ','), (',', 'D.'), ('D.', ','), (',', 'Meier'), ('Meier', ','), (',', 'U.'), ('U.', 'Masci'), ('Masci', ','), (',', 'J'), ('J', '.')]

>> Trigrams are: 
 [('Ciresan', ',', 'D.'), (',', 'D.', ','), ('D.', ',', 'Meier'), (',', 'Meier', ','), ('Meier', ',', 'U.'), (',', 'U.', 'Masci'), ('U.', 'Masci', ','), ('Masci', ',', 'J'), (',', 'J', '.')]

>> POS Tags are: 
 [('Ciresan', 'NNP'), (',', ','), ('D.', 'NNP'), (',', ','), ('Meier', 'NNP'), (',', ','), ('U.', 'NNP'), ('Masci', 'NNP'), (',', ','), ('J', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Ciresan', 'D.', 'Meier', 'U. Masci', 'J']

>> Named Entities are: 
 [('GPE', 'Ciresan'), ('PERSON', 'Meier')] 

>> Stemming using Porter Stemmer: 
 [('Ciresan', 'ciresan'), (',', ','), ('D.', 'd.'), (',', ','), ('Meier', 'meier'), (',', ','), ('U.', 'u.'), ('Masci', 'masci'), (',', ','), ('J', 'j'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Ciresan', 'ciresan'), (',', ','), ('D.', 'd.'), (',', ','), ('Meier', 'meier'), (',', ','), ('U.', 'u.'), ('Masci', 'masci'), (',', ','), ('J', 'j'), ('.', '.')]

>> Lemmatization: 
 [('Ciresan', 'Ciresan'), (',', ','), ('D.', 'D.'), (',', ','), ('Meier', 'Meier'), (',', ','), ('U.', 'U.'), ('Masci', 'Masci'), (',', ','), ('J', 'J'), ('.', '.')]


------------------- Sentence 3 -------------------

& Schmidhuber, J. Multi-column deep neural  network for traffic sign classification.

>> Tokens are: 
 ['&', 'Schmidhuber', ',', 'J.', 'Multi-column', 'deep', 'neural', 'network', 'traffic', 'sign', 'classification', '.']

>> Bigrams are: 
 [('&', 'Schmidhuber'), ('Schmidhuber', ','), (',', 'J.'), ('J.', 'Multi-column'), ('Multi-column', 'deep'), ('deep', 'neural'), ('neural', 'network'), ('network', 'traffic'), ('traffic', 'sign'), ('sign', 'classification'), ('classification', '.')]

>> Trigrams are: 
 [('&', 'Schmidhuber', ','), ('Schmidhuber', ',', 'J.'), (',', 'J.', 'Multi-column'), ('J.', 'Multi-column', 'deep'), ('Multi-column', 'deep', 'neural'), ('deep', 'neural', 'network'), ('neural', 'network', 'traffic'), ('network', 'traffic', 'sign'), ('traffic', 'sign', 'classification'), ('sign', 'classification', '.')]

>> POS Tags are: 
 [('&', 'CC'), ('Schmidhuber', 'NNP'), (',', ','), ('J.', 'NNP'), ('Multi-column', 'NNP'), ('deep', 'JJ'), ('neural', 'JJ'), ('network', 'NN'), ('traffic', 'NN'), ('sign', 'NN'), ('classification', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Schmidhuber', 'J. Multi-column', 'deep neural network traffic sign classification']

>> Named Entities are: 
 [('PERSON', 'J.')] 

>> Stemming using Porter Stemmer: 
 [('&', '&'), ('Schmidhuber', 'schmidhub'), (',', ','), ('J.', 'j.'), ('Multi-column', 'multi-column'), ('deep', 'deep'), ('neural', 'neural'), ('network', 'network'), ('traffic', 'traffic'), ('sign', 'sign'), ('classification', 'classif'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('&', '&'), ('Schmidhuber', 'schmidhub'), (',', ','), ('J.', 'j.'), ('Multi-column', 'multi-column'), ('deep', 'deep'), ('neural', 'neural'), ('network', 'network'), ('traffic', 'traffic'), ('sign', 'sign'), ('classification', 'classif'), ('.', '.')]

>> Lemmatization: 
 [('&', '&'), ('Schmidhuber', 'Schmidhuber'), (',', ','), ('J.', 'J.'), ('Multi-column', 'Multi-column'), ('deep', 'deep'), ('neural', 'neural'), ('network', 'network'), ('traffic', 'traffic'), ('sign', 'sign'), ('classification', 'classification'), ('.', '.')]


------------------- Sentence 4 -------------------

Neural Networks 32, 333–338 (2012).

>> Tokens are: 
 ['Neural', 'Networks', '32', ',', '333–338', '(', '2012', ')', '.']

>> Bigrams are: 
 [('Neural', 'Networks'), ('Networks', '32'), ('32', ','), (',', '333–338'), ('333–338', '('), ('(', '2012'), ('2012', ')'), (')', '.')]

>> Trigrams are: 
 [('Neural', 'Networks', '32'), ('Networks', '32', ','), ('32', ',', '333–338'), (',', '333–338', '('), ('333–338', '(', '2012'), ('(', '2012', ')'), ('2012', ')', '.')]

>> POS Tags are: 
 [('Neural', 'JJ'), ('Networks', 'NNP'), ('32', 'CD'), (',', ','), ('333–338', 'CD'), ('(', '('), ('2012', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['Neural Networks']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Neural', 'neural'), ('Networks', 'network'), ('32', '32'), (',', ','), ('333–338', '333–338'), ('(', '('), ('2012', '2012'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Neural', 'neural'), ('Networks', 'network'), ('32', '32'), (',', ','), ('333–338', '333–338'), ('(', '('), ('2012', '2012'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Neural', 'Neural'), ('Networks', 'Networks'), ('32', '32'), (',', ','), ('333–338', '333–338'), ('(', '('), ('2012', '2012'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 305 ===========================================

54. Ning, F. et al. Toward automatic phenotyping of developing embryos from  videos. IEEE Trans. Image Process. 14, 1360–1371 (2005).  

------------------- Sentence 1 -------------------

54.

>> Tokens are: 
 ['54', '.']

>> Bigrams are: 
 [('54', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('54', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('54', '54'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('54', '54'), ('.', '.')]

>> Lemmatization: 
 [('54', '54'), ('.', '.')]


------------------- Sentence 2 -------------------

Ning, F. et al.

>> Tokens are: 
 ['Ning', ',', 'F.', 'et', 'al', '.']

>> Bigrams are: 
 [('Ning', ','), (',', 'F.'), ('F.', 'et'), ('et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('Ning', ',', 'F.'), (',', 'F.', 'et'), ('F.', 'et', 'al'), ('et', 'al', '.')]

>> POS Tags are: 
 [('Ning', 'NNP'), (',', ','), ('F.', 'NNP'), ('et', 'CC'), ('al', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Ning', 'F.', 'al']

>> Named Entities are: 
 [('GPE', 'Ning')] 

>> Stemming using Porter Stemmer: 
 [('Ning', 'ning'), (',', ','), ('F.', 'f.'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Ning', 'ning'), (',', ','), ('F.', 'f.'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('Ning', 'Ning'), (',', ','), ('F.', 'F.'), ('et', 'et'), ('al', 'al'), ('.', '.')]


------------------- Sentence 3 -------------------

Toward automatic phenotyping of developing embryos from  videos.

>> Tokens are: 
 ['Toward', 'automatic', 'phenotyping', 'developing', 'embryos', 'videos', '.']

>> Bigrams are: 
 [('Toward', 'automatic'), ('automatic', 'phenotyping'), ('phenotyping', 'developing'), ('developing', 'embryos'), ('embryos', 'videos'), ('videos', '.')]

>> Trigrams are: 
 [('Toward', 'automatic', 'phenotyping'), ('automatic', 'phenotyping', 'developing'), ('phenotyping', 'developing', 'embryos'), ('developing', 'embryos', 'videos'), ('embryos', 'videos', '.')]

>> POS Tags are: 
 [('Toward', 'NNP'), ('automatic', 'JJ'), ('phenotyping', 'VBG'), ('developing', 'VBG'), ('embryos', 'JJ'), ('videos', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['Toward', 'embryos videos']

>> Named Entities are: 
 [('PERSON', 'Toward')] 

>> Stemming using Porter Stemmer: 
 [('Toward', 'toward'), ('automatic', 'automat'), ('phenotyping', 'phenotyp'), ('developing', 'develop'), ('embryos', 'embryo'), ('videos', 'video'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Toward', 'toward'), ('automatic', 'automat'), ('phenotyping', 'phenotyp'), ('developing', 'develop'), ('embryos', 'embryo'), ('videos', 'video'), ('.', '.')]

>> Lemmatization: 
 [('Toward', 'Toward'), ('automatic', 'automatic'), ('phenotyping', 'phenotyping'), ('developing', 'developing'), ('embryos', 'embryo'), ('videos', 'video'), ('.', '.')]


------------------- Sentence 4 -------------------

IEEE Trans.

>> Tokens are: 
 ['IEEE', 'Trans', '.']

>> Bigrams are: 
 [('IEEE', 'Trans'), ('Trans', '.')]

>> Trigrams are: 
 [('IEEE', 'Trans', '.')]

>> POS Tags are: 
 [('IEEE', 'NNP'), ('Trans', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['IEEE Trans']

>> Named Entities are: 
 [('ORGANIZATION', 'IEEE Trans')] 

>> Stemming using Porter Stemmer: 
 [('IEEE', 'ieee'), ('Trans', 'tran'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('IEEE', 'ieee'), ('Trans', 'tran'), ('.', '.')]

>> Lemmatization: 
 [('IEEE', 'IEEE'), ('Trans', 'Trans'), ('.', '.')]


------------------- Sentence 5 -------------------

Image Process.

>> Tokens are: 
 ['Image', 'Process', '.']

>> Bigrams are: 
 [('Image', 'Process'), ('Process', '.')]

>> Trigrams are: 
 [('Image', 'Process', '.')]

>> POS Tags are: 
 [('Image', 'NN'), ('Process', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Image Process']

>> Named Entities are: 
 [('GPE', 'Image'), ('ORGANIZATION', 'Process')] 

>> Stemming using Porter Stemmer: 
 [('Image', 'imag'), ('Process', 'process'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Image', 'imag'), ('Process', 'process'), ('.', '.')]

>> Lemmatization: 
 [('Image', 'Image'), ('Process', 'Process'), ('.', '.')]


------------------- Sentence 6 -------------------

14, 1360–1371 (2005).

>> Tokens are: 
 ['14', ',', '1360–1371', '(', '2005', ')', '.']

>> Bigrams are: 
 [('14', ','), (',', '1360–1371'), ('1360–1371', '('), ('(', '2005'), ('2005', ')'), (')', '.')]

>> Trigrams are: 
 [('14', ',', '1360–1371'), (',', '1360–1371', '('), ('1360–1371', '(', '2005'), ('(', '2005', ')'), ('2005', ')', '.')]

>> POS Tags are: 
 [('14', 'CD'), (',', ','), ('1360–1371', 'CD'), ('(', '('), ('2005', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('14', '14'), (',', ','), ('1360–1371', '1360–1371'), ('(', '('), ('2005', '2005'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('14', '14'), (',', ','), ('1360–1371', '1360–1371'), ('(', '('), ('2005', '2005'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('14', '14'), (',', ','), ('1360–1371', '1360–1371'), ('(', '('), ('2005', '2005'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 306 ===========================================

55. Turaga, S. C. et al. Convolutional networks can learn to generate affinity graphs  for image segmentation. Neural Comput. 22, 511–538 (2010).  

------------------- Sentence 1 -------------------

55.

>> Tokens are: 
 ['55', '.']

>> Bigrams are: 
 [('55', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('55', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('55', '55'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('55', '55'), ('.', '.')]

>> Lemmatization: 
 [('55', '55'), ('.', '.')]


------------------- Sentence 2 -------------------

Turaga, S. C. et al.

>> Tokens are: 
 ['Turaga', ',', 'S.', 'C.', 'et', 'al', '.']

>> Bigrams are: 
 [('Turaga', ','), (',', 'S.'), ('S.', 'C.'), ('C.', 'et'), ('et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('Turaga', ',', 'S.'), (',', 'S.', 'C.'), ('S.', 'C.', 'et'), ('C.', 'et', 'al'), ('et', 'al', '.')]

>> POS Tags are: 
 [('Turaga', 'NNP'), (',', ','), ('S.', 'NNP'), ('C.', 'NNP'), ('et', 'FW'), ('al', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Turaga', 'S. C.', 'al']

>> Named Entities are: 
 [('GPE', 'Turaga')] 

>> Stemming using Porter Stemmer: 
 [('Turaga', 'turaga'), (',', ','), ('S.', 's.'), ('C.', 'c.'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Turaga', 'turaga'), (',', ','), ('S.', 's.'), ('C.', 'c.'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('Turaga', 'Turaga'), (',', ','), ('S.', 'S.'), ('C.', 'C.'), ('et', 'et'), ('al', 'al'), ('.', '.')]


------------------- Sentence 3 -------------------

Convolutional networks can learn to generate affinity graphs  for image segmentation.

>> Tokens are: 
 ['Convolutional', 'networks', 'learn', 'generate', 'affinity', 'graphs', 'image', 'segmentation', '.']

>> Bigrams are: 
 [('Convolutional', 'networks'), ('networks', 'learn'), ('learn', 'generate'), ('generate', 'affinity'), ('affinity', 'graphs'), ('graphs', 'image'), ('image', 'segmentation'), ('segmentation', '.')]

>> Trigrams are: 
 [('Convolutional', 'networks', 'learn'), ('networks', 'learn', 'generate'), ('learn', 'generate', 'affinity'), ('generate', 'affinity', 'graphs'), ('affinity', 'graphs', 'image'), ('graphs', 'image', 'segmentation'), ('image', 'segmentation', '.')]

>> POS Tags are: 
 [('Convolutional', 'JJ'), ('networks', 'NNS'), ('learn', 'VBP'), ('generate', 'JJ'), ('affinity', 'NN'), ('graphs', 'NN'), ('image', 'NN'), ('segmentation', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Convolutional networks', 'generate affinity graphs image segmentation']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Convolutional', 'convolut'), ('networks', 'network'), ('learn', 'learn'), ('generate', 'gener'), ('affinity', 'affin'), ('graphs', 'graph'), ('image', 'imag'), ('segmentation', 'segment'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Convolutional', 'convolut'), ('networks', 'network'), ('learn', 'learn'), ('generate', 'generat'), ('affinity', 'affin'), ('graphs', 'graph'), ('image', 'imag'), ('segmentation', 'segment'), ('.', '.')]

>> Lemmatization: 
 [('Convolutional', 'Convolutional'), ('networks', 'network'), ('learn', 'learn'), ('generate', 'generate'), ('affinity', 'affinity'), ('graphs', 'graph'), ('image', 'image'), ('segmentation', 'segmentation'), ('.', '.')]


------------------- Sentence 4 -------------------

Neural Comput.

>> Tokens are: 
 ['Neural', 'Comput', '.']

>> Bigrams are: 
 [('Neural', 'Comput'), ('Comput', '.')]

>> Trigrams are: 
 [('Neural', 'Comput', '.')]

>> POS Tags are: 
 [('Neural', 'JJ'), ('Comput', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Neural Comput']

>> Named Entities are: 
 [('ORGANIZATION', 'Comput')] 

>> Stemming using Porter Stemmer: 
 [('Neural', 'neural'), ('Comput', 'comput'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Neural', 'neural'), ('Comput', 'comput'), ('.', '.')]

>> Lemmatization: 
 [('Neural', 'Neural'), ('Comput', 'Comput'), ('.', '.')]


------------------- Sentence 5 -------------------

22, 511–538 (2010).

>> Tokens are: 
 ['22', ',', '511–538', '(', '2010', ')', '.']

>> Bigrams are: 
 [('22', ','), (',', '511–538'), ('511–538', '('), ('(', '2010'), ('2010', ')'), (')', '.')]

>> Trigrams are: 
 [('22', ',', '511–538'), (',', '511–538', '('), ('511–538', '(', '2010'), ('(', '2010', ')'), ('2010', ')', '.')]

>> POS Tags are: 
 [('22', 'CD'), (',', ','), ('511–538', 'CD'), ('(', '('), ('2010', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('22', '22'), (',', ','), ('511–538', '511–538'), ('(', '('), ('2010', '2010'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('22', '22'), (',', ','), ('511–538', '511–538'), ('(', '('), ('2010', '2010'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('22', '22'), (',', ','), ('511–538', '511–538'), ('(', '('), ('2010', '2010'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 307 ===========================================

56. Garcia, C. & Delakis, M. Convolutional face finder: a neural architecture for  fast and robust face detection. IEEE Trans. Pattern Anal. Machine Intell. 26,  1408–1423 (2004).  

------------------- Sentence 1 -------------------

56.

>> Tokens are: 
 ['56', '.']

>> Bigrams are: 
 [('56', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('56', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('56', '56'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('56', '56'), ('.', '.')]

>> Lemmatization: 
 [('56', '56'), ('.', '.')]


------------------- Sentence 2 -------------------

Garcia, C. & Delakis, M. Convolutional face finder: a neural architecture for  fast and robust face detection.

>> Tokens are: 
 ['Garcia', ',', 'C.', '&', 'Delakis', ',', 'M.', 'Convolutional', 'face', 'finder', ':', 'neural', 'architecture', 'fast', 'robust', 'face', 'detection', '.']

>> Bigrams are: 
 [('Garcia', ','), (',', 'C.'), ('C.', '&'), ('&', 'Delakis'), ('Delakis', ','), (',', 'M.'), ('M.', 'Convolutional'), ('Convolutional', 'face'), ('face', 'finder'), ('finder', ':'), (':', 'neural'), ('neural', 'architecture'), ('architecture', 'fast'), ('fast', 'robust'), ('robust', 'face'), ('face', 'detection'), ('detection', '.')]

>> Trigrams are: 
 [('Garcia', ',', 'C.'), (',', 'C.', '&'), ('C.', '&', 'Delakis'), ('&', 'Delakis', ','), ('Delakis', ',', 'M.'), (',', 'M.', 'Convolutional'), ('M.', 'Convolutional', 'face'), ('Convolutional', 'face', 'finder'), ('face', 'finder', ':'), ('finder', ':', 'neural'), (':', 'neural', 'architecture'), ('neural', 'architecture', 'fast'), ('architecture', 'fast', 'robust'), ('fast', 'robust', 'face'), ('robust', 'face', 'detection'), ('face', 'detection', '.')]

>> POS Tags are: 
 [('Garcia', 'NNP'), (',', ','), ('C.', 'NNP'), ('&', 'CC'), ('Delakis', 'NNP'), (',', ','), ('M.', 'NNP'), ('Convolutional', 'NNP'), ('face', 'NN'), ('finder', 'NN'), (':', ':'), ('neural', 'JJ'), ('architecture', 'NN'), ('fast', 'RB'), ('robust', 'JJ'), ('face', 'NN'), ('detection', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Garcia', 'C.', 'Delakis', 'M. Convolutional face finder', 'neural architecture', 'robust face detection']

>> Named Entities are: 
 [('GPE', 'Garcia'), ('PERSON', 'Delakis')] 

>> Stemming using Porter Stemmer: 
 [('Garcia', 'garcia'), (',', ','), ('C.', 'c.'), ('&', '&'), ('Delakis', 'delaki'), (',', ','), ('M.', 'm.'), ('Convolutional', 'convolut'), ('face', 'face'), ('finder', 'finder'), (':', ':'), ('neural', 'neural'), ('architecture', 'architectur'), ('fast', 'fast'), ('robust', 'robust'), ('face', 'face'), ('detection', 'detect'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Garcia', 'garcia'), (',', ','), ('C.', 'c.'), ('&', '&'), ('Delakis', 'delaki'), (',', ','), ('M.', 'm.'), ('Convolutional', 'convolut'), ('face', 'face'), ('finder', 'finder'), (':', ':'), ('neural', 'neural'), ('architecture', 'architectur'), ('fast', 'fast'), ('robust', 'robust'), ('face', 'face'), ('detection', 'detect'), ('.', '.')]

>> Lemmatization: 
 [('Garcia', 'Garcia'), (',', ','), ('C.', 'C.'), ('&', '&'), ('Delakis', 'Delakis'), (',', ','), ('M.', 'M.'), ('Convolutional', 'Convolutional'), ('face', 'face'), ('finder', 'finder'), (':', ':'), ('neural', 'neural'), ('architecture', 'architecture'), ('fast', 'fast'), ('robust', 'robust'), ('face', 'face'), ('detection', 'detection'), ('.', '.')]


------------------- Sentence 3 -------------------

IEEE Trans.

>> Tokens are: 
 ['IEEE', 'Trans', '.']

>> Bigrams are: 
 [('IEEE', 'Trans'), ('Trans', '.')]

>> Trigrams are: 
 [('IEEE', 'Trans', '.')]

>> POS Tags are: 
 [('IEEE', 'NNP'), ('Trans', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['IEEE Trans']

>> Named Entities are: 
 [('ORGANIZATION', 'IEEE Trans')] 

>> Stemming using Porter Stemmer: 
 [('IEEE', 'ieee'), ('Trans', 'tran'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('IEEE', 'ieee'), ('Trans', 'tran'), ('.', '.')]

>> Lemmatization: 
 [('IEEE', 'IEEE'), ('Trans', 'Trans'), ('.', '.')]


------------------- Sentence 4 -------------------

Pattern Anal.

>> Tokens are: 
 ['Pattern', 'Anal', '.']

>> Bigrams are: 
 [('Pattern', 'Anal'), ('Anal', '.')]

>> Trigrams are: 
 [('Pattern', 'Anal', '.')]

>> POS Tags are: 
 [('Pattern', 'NNP'), ('Anal', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Pattern Anal']

>> Named Entities are: 
 [('PERSON', 'Pattern'), ('ORGANIZATION', 'Anal')] 

>> Stemming using Porter Stemmer: 
 [('Pattern', 'pattern'), ('Anal', 'anal'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Pattern', 'pattern'), ('Anal', 'anal'), ('.', '.')]

>> Lemmatization: 
 [('Pattern', 'Pattern'), ('Anal', 'Anal'), ('.', '.')]


------------------- Sentence 5 -------------------

Machine Intell.

>> Tokens are: 
 ['Machine', 'Intell', '.']

>> Bigrams are: 
 [('Machine', 'Intell'), ('Intell', '.')]

>> Trigrams are: 
 [('Machine', 'Intell', '.')]

>> POS Tags are: 
 [('Machine', 'NN'), ('Intell', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Machine Intell']

>> Named Entities are: 
 [('PERSON', 'Machine'), ('ORGANIZATION', 'Intell')] 

>> Stemming using Porter Stemmer: 
 [('Machine', 'machin'), ('Intell', 'intel'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Machine', 'machin'), ('Intell', 'intel'), ('.', '.')]

>> Lemmatization: 
 [('Machine', 'Machine'), ('Intell', 'Intell'), ('.', '.')]


------------------- Sentence 6 -------------------

26,  1408–1423 (2004).

>> Tokens are: 
 ['26', ',', '1408–1423', '(', '2004', ')', '.']

>> Bigrams are: 
 [('26', ','), (',', '1408–1423'), ('1408–1423', '('), ('(', '2004'), ('2004', ')'), (')', '.')]

>> Trigrams are: 
 [('26', ',', '1408–1423'), (',', '1408–1423', '('), ('1408–1423', '(', '2004'), ('(', '2004', ')'), ('2004', ')', '.')]

>> POS Tags are: 
 [('26', 'CD'), (',', ','), ('1408–1423', 'CD'), ('(', '('), ('2004', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('26', '26'), (',', ','), ('1408–1423', '1408–1423'), ('(', '('), ('2004', '2004'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('26', '26'), (',', ','), ('1408–1423', '1408–1423'), ('(', '('), ('2004', '2004'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('26', '26'), (',', ','), ('1408–1423', '1408–1423'), ('(', '('), ('2004', '2004'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 308 ===========================================

57. Osadchy, M., LeCun, Y. & Miller, M. Synergistic face detection and pose  estimation with energy-based models. J. Mach. Learn. Res. 8, 1197–1215  (2007).  

------------------- Sentence 1 -------------------

57.

>> Tokens are: 
 ['57', '.']

>> Bigrams are: 
 [('57', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('57', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('57', '57'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('57', '57'), ('.', '.')]

>> Lemmatization: 
 [('57', '57'), ('.', '.')]


------------------- Sentence 2 -------------------

Osadchy, M., LeCun, Y.

>> Tokens are: 
 ['Osadchy', ',', 'M.', ',', 'LeCun', ',', 'Y', '.']

>> Bigrams are: 
 [('Osadchy', ','), (',', 'M.'), ('M.', ','), (',', 'LeCun'), ('LeCun', ','), (',', 'Y'), ('Y', '.')]

>> Trigrams are: 
 [('Osadchy', ',', 'M.'), (',', 'M.', ','), ('M.', ',', 'LeCun'), (',', 'LeCun', ','), ('LeCun', ',', 'Y'), (',', 'Y', '.')]

>> POS Tags are: 
 [('Osadchy', 'NNP'), (',', ','), ('M.', 'NNP'), (',', ','), ('LeCun', 'NNP'), (',', ','), ('Y', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Osadchy', 'M.', 'LeCun', 'Y']

>> Named Entities are: 
 [('GPE', 'Osadchy'), ('ORGANIZATION', 'LeCun')] 

>> Stemming using Porter Stemmer: 
 [('Osadchy', 'osadchi'), (',', ','), ('M.', 'm.'), (',', ','), ('LeCun', 'lecun'), (',', ','), ('Y', 'y'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Osadchy', 'osadchi'), (',', ','), ('M.', 'm.'), (',', ','), ('LeCun', 'lecun'), (',', ','), ('Y', 'y'), ('.', '.')]

>> Lemmatization: 
 [('Osadchy', 'Osadchy'), (',', ','), ('M.', 'M.'), (',', ','), ('LeCun', 'LeCun'), (',', ','), ('Y', 'Y'), ('.', '.')]


------------------- Sentence 3 -------------------

& Miller, M. Synergistic face detection and pose  estimation with energy-based models.

>> Tokens are: 
 ['&', 'Miller', ',', 'M.', 'Synergistic', 'face', 'detection', 'pose', 'estimation', 'energy-based', 'models', '.']

>> Bigrams are: 
 [('&', 'Miller'), ('Miller', ','), (',', 'M.'), ('M.', 'Synergistic'), ('Synergistic', 'face'), ('face', 'detection'), ('detection', 'pose'), ('pose', 'estimation'), ('estimation', 'energy-based'), ('energy-based', 'models'), ('models', '.')]

>> Trigrams are: 
 [('&', 'Miller', ','), ('Miller', ',', 'M.'), (',', 'M.', 'Synergistic'), ('M.', 'Synergistic', 'face'), ('Synergistic', 'face', 'detection'), ('face', 'detection', 'pose'), ('detection', 'pose', 'estimation'), ('pose', 'estimation', 'energy-based'), ('estimation', 'energy-based', 'models'), ('energy-based', 'models', '.')]

>> POS Tags are: 
 [('&', 'CC'), ('Miller', 'NNP'), (',', ','), ('M.', 'NNP'), ('Synergistic', 'NNP'), ('face', 'NN'), ('detection', 'NN'), ('pose', 'JJ'), ('estimation', 'NN'), ('energy-based', 'JJ'), ('models', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['Miller', 'M. Synergistic face detection', 'pose estimation', 'energy-based models']

>> Named Entities are: 
 [('PERSON', 'Miller')] 

>> Stemming using Porter Stemmer: 
 [('&', '&'), ('Miller', 'miller'), (',', ','), ('M.', 'm.'), ('Synergistic', 'synergist'), ('face', 'face'), ('detection', 'detect'), ('pose', 'pose'), ('estimation', 'estim'), ('energy-based', 'energy-bas'), ('models', 'model'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('&', '&'), ('Miller', 'miller'), (',', ','), ('M.', 'm.'), ('Synergistic', 'synergist'), ('face', 'face'), ('detection', 'detect'), ('pose', 'pose'), ('estimation', 'estim'), ('energy-based', 'energy-bas'), ('models', 'model'), ('.', '.')]

>> Lemmatization: 
 [('&', '&'), ('Miller', 'Miller'), (',', ','), ('M.', 'M.'), ('Synergistic', 'Synergistic'), ('face', 'face'), ('detection', 'detection'), ('pose', 'pose'), ('estimation', 'estimation'), ('energy-based', 'energy-based'), ('models', 'model'), ('.', '.')]


------------------- Sentence 4 -------------------

J. Mach.

>> Tokens are: 
 ['J.', 'Mach', '.']

>> Bigrams are: 
 [('J.', 'Mach'), ('Mach', '.')]

>> Trigrams are: 
 [('J.', 'Mach', '.')]

>> POS Tags are: 
 [('J.', 'NNP'), ('Mach', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['J. Mach']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('J.', 'j.'), ('Mach', 'mach'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('J.', 'j.'), ('Mach', 'mach'), ('.', '.')]

>> Lemmatization: 
 [('J.', 'J.'), ('Mach', 'Mach'), ('.', '.')]


------------------- Sentence 5 -------------------

Learn.

>> Tokens are: 
 ['Learn', '.']

>> Bigrams are: 
 [('Learn', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Learn', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Learn']

>> Named Entities are: 
 [('GPE', 'Learn')] 

>> Stemming using Porter Stemmer: 
 [('Learn', 'learn'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Learn', 'learn'), ('.', '.')]

>> Lemmatization: 
 [('Learn', 'Learn'), ('.', '.')]


------------------- Sentence 6 -------------------

Res.

>> Tokens are: 
 ['Res', '.']

>> Bigrams are: 
 [('Res', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Res', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Res']

>> Named Entities are: 
 [('GPE', 'Res')] 

>> Stemming using Porter Stemmer: 
 [('Res', 're'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Res', 'res'), ('.', '.')]

>> Lemmatization: 
 [('Res', 'Res'), ('.', '.')]


------------------- Sentence 7 -------------------

8, 1197–1215  (2007).

>> Tokens are: 
 ['8', ',', '1197–1215', '(', '2007', ')', '.']

>> Bigrams are: 
 [('8', ','), (',', '1197–1215'), ('1197–1215', '('), ('(', '2007'), ('2007', ')'), (')', '.')]

>> Trigrams are: 
 [('8', ',', '1197–1215'), (',', '1197–1215', '('), ('1197–1215', '(', '2007'), ('(', '2007', ')'), ('2007', ')', '.')]

>> POS Tags are: 
 [('8', 'CD'), (',', ','), ('1197–1215', 'CD'), ('(', '('), ('2007', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('8', '8'), (',', ','), ('1197–1215', '1197–1215'), ('(', '('), ('2007', '2007'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('8', '8'), (',', ','), ('1197–1215', '1197–1215'), ('(', '('), ('2007', '2007'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('8', '8'), (',', ','), ('1197–1215', '1197–1215'), ('(', '('), ('2007', '2007'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 309 ===========================================

58. Tompson, J., Goroshin, R. R., Jain, A., LeCun, Y. Y. & Bregler, C. C. Efficient object  localization using convolutional networks. In Proc. Conference on Computer  Vision and Pattern Recognition http://arxiv.org/abs/1411.4280 (2014).  

------------------- Sentence 1 -------------------

58.

>> Tokens are: 
 ['58', '.']

>> Bigrams are: 
 [('58', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('58', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('58', '58'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('58', '58'), ('.', '.')]

>> Lemmatization: 
 [('58', '58'), ('.', '.')]


------------------- Sentence 2 -------------------

Tompson, J., Goroshin, R. R., Jain, A., LeCun, Y. Y.

>> Tokens are: 
 ['Tompson', ',', 'J.', ',', 'Goroshin', ',', 'R.', 'R.', ',', 'Jain', ',', 'A.', ',', 'LeCun', ',', 'Y.', 'Y', '.']

>> Bigrams are: 
 [('Tompson', ','), (',', 'J.'), ('J.', ','), (',', 'Goroshin'), ('Goroshin', ','), (',', 'R.'), ('R.', 'R.'), ('R.', ','), (',', 'Jain'), ('Jain', ','), (',', 'A.'), ('A.', ','), (',', 'LeCun'), ('LeCun', ','), (',', 'Y.'), ('Y.', 'Y'), ('Y', '.')]

>> Trigrams are: 
 [('Tompson', ',', 'J.'), (',', 'J.', ','), ('J.', ',', 'Goroshin'), (',', 'Goroshin', ','), ('Goroshin', ',', 'R.'), (',', 'R.', 'R.'), ('R.', 'R.', ','), ('R.', ',', 'Jain'), (',', 'Jain', ','), ('Jain', ',', 'A.'), (',', 'A.', ','), ('A.', ',', 'LeCun'), (',', 'LeCun', ','), ('LeCun', ',', 'Y.'), (',', 'Y.', 'Y'), ('Y.', 'Y', '.')]

>> POS Tags are: 
 [('Tompson', 'NNP'), (',', ','), ('J.', 'NNP'), (',', ','), ('Goroshin', 'NNP'), (',', ','), ('R.', 'NNP'), ('R.', 'NNP'), (',', ','), ('Jain', 'NNP'), (',', ','), ('A.', 'NNP'), (',', ','), ('LeCun', 'NNP'), (',', ','), ('Y.', 'NNP'), ('Y', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Tompson', 'J.', 'Goroshin', 'R. R.', 'Jain', 'A.', 'LeCun', 'Y. Y']

>> Named Entities are: 
 [('PERSON', 'Tompson'), ('PERSON', 'Goroshin'), ('GPE', 'Jain'), ('ORGANIZATION', 'LeCun')] 

>> Stemming using Porter Stemmer: 
 [('Tompson', 'tompson'), (',', ','), ('J.', 'j.'), (',', ','), ('Goroshin', 'goroshin'), (',', ','), ('R.', 'r.'), ('R.', 'r.'), (',', ','), ('Jain', 'jain'), (',', ','), ('A.', 'a.'), (',', ','), ('LeCun', 'lecun'), (',', ','), ('Y.', 'y.'), ('Y', 'y'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Tompson', 'tompson'), (',', ','), ('J.', 'j.'), (',', ','), ('Goroshin', 'goroshin'), (',', ','), ('R.', 'r.'), ('R.', 'r.'), (',', ','), ('Jain', 'jain'), (',', ','), ('A.', 'a.'), (',', ','), ('LeCun', 'lecun'), (',', ','), ('Y.', 'y.'), ('Y', 'y'), ('.', '.')]

>> Lemmatization: 
 [('Tompson', 'Tompson'), (',', ','), ('J.', 'J.'), (',', ','), ('Goroshin', 'Goroshin'), (',', ','), ('R.', 'R.'), ('R.', 'R.'), (',', ','), ('Jain', 'Jain'), (',', ','), ('A.', 'A.'), (',', ','), ('LeCun', 'LeCun'), (',', ','), ('Y.', 'Y.'), ('Y', 'Y'), ('.', '.')]


------------------- Sentence 3 -------------------

& Bregler, C. C. Efficient object  localization using convolutional networks.

>> Tokens are: 
 ['&', 'Bregler', ',', 'C.', 'C.', 'Efficient', 'object', 'localization', 'using', 'convolutional', 'networks', '.']

>> Bigrams are: 
 [('&', 'Bregler'), ('Bregler', ','), (',', 'C.'), ('C.', 'C.'), ('C.', 'Efficient'), ('Efficient', 'object'), ('object', 'localization'), ('localization', 'using'), ('using', 'convolutional'), ('convolutional', 'networks'), ('networks', '.')]

>> Trigrams are: 
 [('&', 'Bregler', ','), ('Bregler', ',', 'C.'), (',', 'C.', 'C.'), ('C.', 'C.', 'Efficient'), ('C.', 'Efficient', 'object'), ('Efficient', 'object', 'localization'), ('object', 'localization', 'using'), ('localization', 'using', 'convolutional'), ('using', 'convolutional', 'networks'), ('convolutional', 'networks', '.')]

>> POS Tags are: 
 [('&', 'CC'), ('Bregler', 'NNP'), (',', ','), ('C.', 'NNP'), ('C.', 'NNP'), ('Efficient', 'NNP'), ('object', 'JJ'), ('localization', 'NN'), ('using', 'VBG'), ('convolutional', 'JJ'), ('networks', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['Bregler', 'C. C. Efficient', 'object localization', 'convolutional networks']

>> Named Entities are: 
 [('PERSON', 'Bregler')] 

>> Stemming using Porter Stemmer: 
 [('&', '&'), ('Bregler', 'bregler'), (',', ','), ('C.', 'c.'), ('C.', 'c.'), ('Efficient', 'effici'), ('object', 'object'), ('localization', 'local'), ('using', 'use'), ('convolutional', 'convolut'), ('networks', 'network'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('&', '&'), ('Bregler', 'bregler'), (',', ','), ('C.', 'c.'), ('C.', 'c.'), ('Efficient', 'effici'), ('object', 'object'), ('localization', 'local'), ('using', 'use'), ('convolutional', 'convolut'), ('networks', 'network'), ('.', '.')]

>> Lemmatization: 
 [('&', '&'), ('Bregler', 'Bregler'), (',', ','), ('C.', 'C.'), ('C.', 'C.'), ('Efficient', 'Efficient'), ('object', 'object'), ('localization', 'localization'), ('using', 'using'), ('convolutional', 'convolutional'), ('networks', 'network'), ('.', '.')]


------------------- Sentence 4 -------------------

In Proc.

>> Tokens are: 
 ['In', 'Proc', '.']

>> Bigrams are: 
 [('In', 'Proc'), ('Proc', '.')]

>> Trigrams are: 
 [('In', 'Proc', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('Proc', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Proc']

>> Named Entities are: 
 [('GPE', 'Proc')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('Proc', 'proc'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('Proc', 'proc'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('Proc', 'Proc'), ('.', '.')]


------------------- Sentence 5 -------------------

Conference on Computer  Vision and Pattern Recognition http://arxiv.org/abs/1411.4280 (2014).

>> Tokens are: 
 ['Conference', 'Computer', 'Vision', 'Pattern', 'Recognition', 'http', ':', '//arxiv.org/abs/1411.4280', '(', '2014', ')', '.']

>> Bigrams are: 
 [('Conference', 'Computer'), ('Computer', 'Vision'), ('Vision', 'Pattern'), ('Pattern', 'Recognition'), ('Recognition', 'http'), ('http', ':'), (':', '//arxiv.org/abs/1411.4280'), ('//arxiv.org/abs/1411.4280', '('), ('(', '2014'), ('2014', ')'), (')', '.')]

>> Trigrams are: 
 [('Conference', 'Computer', 'Vision'), ('Computer', 'Vision', 'Pattern'), ('Vision', 'Pattern', 'Recognition'), ('Pattern', 'Recognition', 'http'), ('Recognition', 'http', ':'), ('http', ':', '//arxiv.org/abs/1411.4280'), (':', '//arxiv.org/abs/1411.4280', '('), ('//arxiv.org/abs/1411.4280', '(', '2014'), ('(', '2014', ')'), ('2014', ')', '.')]

>> POS Tags are: 
 [('Conference', 'NN'), ('Computer', 'NNP'), ('Vision', 'NNP'), ('Pattern', 'NNP'), ('Recognition', 'NNP'), ('http', 'NN'), (':', ':'), ('//arxiv.org/abs/1411.4280', 'NN'), ('(', '('), ('2014', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['Conference Computer Vision Pattern Recognition http', '//arxiv.org/abs/1411.4280']

>> Named Entities are: 
 [('ORGANIZATION', 'Conference'), ('ORGANIZATION', 'Computer Vision Pattern')] 

>> Stemming using Porter Stemmer: 
 [('Conference', 'confer'), ('Computer', 'comput'), ('Vision', 'vision'), ('Pattern', 'pattern'), ('Recognition', 'recognit'), ('http', 'http'), (':', ':'), ('//arxiv.org/abs/1411.4280', '//arxiv.org/abs/1411.4280'), ('(', '('), ('2014', '2014'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Conference', 'confer'), ('Computer', 'comput'), ('Vision', 'vision'), ('Pattern', 'pattern'), ('Recognition', 'recognit'), ('http', 'http'), (':', ':'), ('//arxiv.org/abs/1411.4280', '//arxiv.org/abs/1411.4280'), ('(', '('), ('2014', '2014'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Conference', 'Conference'), ('Computer', 'Computer'), ('Vision', 'Vision'), ('Pattern', 'Pattern'), ('Recognition', 'Recognition'), ('http', 'http'), (':', ':'), ('//arxiv.org/abs/1411.4280', '//arxiv.org/abs/1411.4280'), ('(', '('), ('2014', '2014'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 310 ===========================================

59. Taigman, Y., Yang, M., Ranzato, M. & Wolf, L. Deepface: closing the gap to  human-level performance in face verification. In Proc. Conference on Computer  Vision and Pattern Recognition 1701–1708 (2014).  

------------------- Sentence 1 -------------------

59.

>> Tokens are: 
 ['59', '.']

>> Bigrams are: 
 [('59', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('59', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('59', '59'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('59', '59'), ('.', '.')]

>> Lemmatization: 
 [('59', '59'), ('.', '.')]


------------------- Sentence 2 -------------------

Taigman, Y., Yang, M., Ranzato, M. & Wolf, L. Deepface: closing the gap to  human-level performance in face verification.

>> Tokens are: 
 ['Taigman', ',', 'Y.', ',', 'Yang', ',', 'M.', ',', 'Ranzato', ',', 'M.', '&', 'Wolf', ',', 'L.', 'Deepface', ':', 'closing', 'gap', 'human-level', 'performance', 'face', 'verification', '.']

>> Bigrams are: 
 [('Taigman', ','), (',', 'Y.'), ('Y.', ','), (',', 'Yang'), ('Yang', ','), (',', 'M.'), ('M.', ','), (',', 'Ranzato'), ('Ranzato', ','), (',', 'M.'), ('M.', '&'), ('&', 'Wolf'), ('Wolf', ','), (',', 'L.'), ('L.', 'Deepface'), ('Deepface', ':'), (':', 'closing'), ('closing', 'gap'), ('gap', 'human-level'), ('human-level', 'performance'), ('performance', 'face'), ('face', 'verification'), ('verification', '.')]

>> Trigrams are: 
 [('Taigman', ',', 'Y.'), (',', 'Y.', ','), ('Y.', ',', 'Yang'), (',', 'Yang', ','), ('Yang', ',', 'M.'), (',', 'M.', ','), ('M.', ',', 'Ranzato'), (',', 'Ranzato', ','), ('Ranzato', ',', 'M.'), (',', 'M.', '&'), ('M.', '&', 'Wolf'), ('&', 'Wolf', ','), ('Wolf', ',', 'L.'), (',', 'L.', 'Deepface'), ('L.', 'Deepface', ':'), ('Deepface', ':', 'closing'), (':', 'closing', 'gap'), ('closing', 'gap', 'human-level'), ('gap', 'human-level', 'performance'), ('human-level', 'performance', 'face'), ('performance', 'face', 'verification'), ('face', 'verification', '.')]

>> POS Tags are: 
 [('Taigman', 'NNP'), (',', ','), ('Y.', 'NNP'), (',', ','), ('Yang', 'NNP'), (',', ','), ('M.', 'NNP'), (',', ','), ('Ranzato', 'NNP'), (',', ','), ('M.', 'NNP'), ('&', 'CC'), ('Wolf', 'NNP'), (',', ','), ('L.', 'NNP'), ('Deepface', 'NNP'), (':', ':'), ('closing', 'NN'), ('gap', 'NN'), ('human-level', 'JJ'), ('performance', 'NN'), ('face', 'NN'), ('verification', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Taigman', 'Y.', 'Yang', 'M.', 'Ranzato', 'M.', 'Wolf', 'L. Deepface', 'closing gap', 'human-level performance face verification']

>> Named Entities are: 
 [('GPE', 'Taigman'), ('PERSON', 'Yang'), ('PERSON', 'Ranzato'), ('PERSON', 'Wolf')] 

>> Stemming using Porter Stemmer: 
 [('Taigman', 'taigman'), (',', ','), ('Y.', 'y.'), (',', ','), ('Yang', 'yang'), (',', ','), ('M.', 'm.'), (',', ','), ('Ranzato', 'ranzato'), (',', ','), ('M.', 'm.'), ('&', '&'), ('Wolf', 'wolf'), (',', ','), ('L.', 'l.'), ('Deepface', 'deepfac'), (':', ':'), ('closing', 'close'), ('gap', 'gap'), ('human-level', 'human-level'), ('performance', 'perform'), ('face', 'face'), ('verification', 'verif'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Taigman', 'taigman'), (',', ','), ('Y.', 'y.'), (',', ','), ('Yang', 'yang'), (',', ','), ('M.', 'm.'), (',', ','), ('Ranzato', 'ranzato'), (',', ','), ('M.', 'm.'), ('&', '&'), ('Wolf', 'wolf'), (',', ','), ('L.', 'l.'), ('Deepface', 'deepfac'), (':', ':'), ('closing', 'close'), ('gap', 'gap'), ('human-level', 'human-level'), ('performance', 'perform'), ('face', 'face'), ('verification', 'verif'), ('.', '.')]

>> Lemmatization: 
 [('Taigman', 'Taigman'), (',', ','), ('Y.', 'Y.'), (',', ','), ('Yang', 'Yang'), (',', ','), ('M.', 'M.'), (',', ','), ('Ranzato', 'Ranzato'), (',', ','), ('M.', 'M.'), ('&', '&'), ('Wolf', 'Wolf'), (',', ','), ('L.', 'L.'), ('Deepface', 'Deepface'), (':', ':'), ('closing', 'closing'), ('gap', 'gap'), ('human-level', 'human-level'), ('performance', 'performance'), ('face', 'face'), ('verification', 'verification'), ('.', '.')]


------------------- Sentence 3 -------------------

In Proc.

>> Tokens are: 
 ['In', 'Proc', '.']

>> Bigrams are: 
 [('In', 'Proc'), ('Proc', '.')]

>> Trigrams are: 
 [('In', 'Proc', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('Proc', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Proc']

>> Named Entities are: 
 [('GPE', 'Proc')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('Proc', 'proc'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('Proc', 'proc'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('Proc', 'Proc'), ('.', '.')]


------------------- Sentence 4 -------------------

Conference on Computer  Vision and Pattern Recognition 1701–1708 (2014).

>> Tokens are: 
 ['Conference', 'Computer', 'Vision', 'Pattern', 'Recognition', '1701–1708', '(', '2014', ')', '.']

>> Bigrams are: 
 [('Conference', 'Computer'), ('Computer', 'Vision'), ('Vision', 'Pattern'), ('Pattern', 'Recognition'), ('Recognition', '1701–1708'), ('1701–1708', '('), ('(', '2014'), ('2014', ')'), (')', '.')]

>> Trigrams are: 
 [('Conference', 'Computer', 'Vision'), ('Computer', 'Vision', 'Pattern'), ('Vision', 'Pattern', 'Recognition'), ('Pattern', 'Recognition', '1701–1708'), ('Recognition', '1701–1708', '('), ('1701–1708', '(', '2014'), ('(', '2014', ')'), ('2014', ')', '.')]

>> POS Tags are: 
 [('Conference', 'NN'), ('Computer', 'NNP'), ('Vision', 'NNP'), ('Pattern', 'NNP'), ('Recognition', 'NNP'), ('1701–1708', 'CD'), ('(', '('), ('2014', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['Conference Computer Vision Pattern Recognition']

>> Named Entities are: 
 [('ORGANIZATION', 'Conference'), ('ORGANIZATION', 'Computer Vision Pattern')] 

>> Stemming using Porter Stemmer: 
 [('Conference', 'confer'), ('Computer', 'comput'), ('Vision', 'vision'), ('Pattern', 'pattern'), ('Recognition', 'recognit'), ('1701–1708', '1701–1708'), ('(', '('), ('2014', '2014'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Conference', 'confer'), ('Computer', 'comput'), ('Vision', 'vision'), ('Pattern', 'pattern'), ('Recognition', 'recognit'), ('1701–1708', '1701–1708'), ('(', '('), ('2014', '2014'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Conference', 'Conference'), ('Computer', 'Computer'), ('Vision', 'Vision'), ('Pattern', 'Pattern'), ('Recognition', 'Recognition'), ('1701–1708', '1701–1708'), ('(', '('), ('2014', '2014'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 311 ===========================================

60. Hadsell, R. et al. Learning long-range vision for autonomous off-road driving.  J. Field Robot. 26, 120–144 (2009).  

------------------- Sentence 1 -------------------

60.

>> Tokens are: 
 ['60', '.']

>> Bigrams are: 
 [('60', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('60', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('60', '60'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('60', '60'), ('.', '.')]

>> Lemmatization: 
 [('60', '60'), ('.', '.')]


------------------- Sentence 2 -------------------

Hadsell, R. et al.

>> Tokens are: 
 ['Hadsell', ',', 'R.', 'et', 'al', '.']

>> Bigrams are: 
 [('Hadsell', ','), (',', 'R.'), ('R.', 'et'), ('et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('Hadsell', ',', 'R.'), (',', 'R.', 'et'), ('R.', 'et', 'al'), ('et', 'al', '.')]

>> POS Tags are: 
 [('Hadsell', 'NNP'), (',', ','), ('R.', 'NNP'), ('et', 'CC'), ('al', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Hadsell', 'R.', 'al']

>> Named Entities are: 
 [('GPE', 'Hadsell')] 

>> Stemming using Porter Stemmer: 
 [('Hadsell', 'hadsel'), (',', ','), ('R.', 'r.'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Hadsell', 'hadsel'), (',', ','), ('R.', 'r.'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('Hadsell', 'Hadsell'), (',', ','), ('R.', 'R.'), ('et', 'et'), ('al', 'al'), ('.', '.')]


------------------- Sentence 3 -------------------

Learning long-range vision for autonomous off-road driving.

>> Tokens are: 
 ['Learning', 'long-range', 'vision', 'autonomous', 'off-road', 'driving', '.']

>> Bigrams are: 
 [('Learning', 'long-range'), ('long-range', 'vision'), ('vision', 'autonomous'), ('autonomous', 'off-road'), ('off-road', 'driving'), ('driving', '.')]

>> Trigrams are: 
 [('Learning', 'long-range', 'vision'), ('long-range', 'vision', 'autonomous'), ('vision', 'autonomous', 'off-road'), ('autonomous', 'off-road', 'driving'), ('off-road', 'driving', '.')]

>> POS Tags are: 
 [('Learning', 'VBG'), ('long-range', 'JJ'), ('vision', 'NN'), ('autonomous', 'JJ'), ('off-road', 'JJ'), ('driving', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['long-range vision', 'autonomous off-road driving']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Learning', 'learn'), ('long-range', 'long-rang'), ('vision', 'vision'), ('autonomous', 'autonom'), ('off-road', 'off-road'), ('driving', 'drive'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Learning', 'learn'), ('long-range', 'long-rang'), ('vision', 'vision'), ('autonomous', 'autonom'), ('off-road', 'off-road'), ('driving', 'drive'), ('.', '.')]

>> Lemmatization: 
 [('Learning', 'Learning'), ('long-range', 'long-range'), ('vision', 'vision'), ('autonomous', 'autonomous'), ('off-road', 'off-road'), ('driving', 'driving'), ('.', '.')]


------------------- Sentence 4 -------------------

J.

>> Tokens are: 
 ['J', '.']

>> Bigrams are: 
 [('J', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('J', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['J']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('J', 'j'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('J', 'j'), ('.', '.')]

>> Lemmatization: 
 [('J', 'J'), ('.', '.')]


------------------- Sentence 5 -------------------

Field Robot.

>> Tokens are: 
 ['Field', 'Robot', '.']

>> Bigrams are: 
 [('Field', 'Robot'), ('Robot', '.')]

>> Trigrams are: 
 [('Field', 'Robot', '.')]

>> POS Tags are: 
 [('Field', 'NNP'), ('Robot', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Field Robot']

>> Named Entities are: 
 [('PERSON', 'Field'), ('ORGANIZATION', 'Robot')] 

>> Stemming using Porter Stemmer: 
 [('Field', 'field'), ('Robot', 'robot'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Field', 'field'), ('Robot', 'robot'), ('.', '.')]

>> Lemmatization: 
 [('Field', 'Field'), ('Robot', 'Robot'), ('.', '.')]


------------------- Sentence 6 -------------------

26, 120–144 (2009).

>> Tokens are: 
 ['26', ',', '120–144', '(', '2009', ')', '.']

>> Bigrams are: 
 [('26', ','), (',', '120–144'), ('120–144', '('), ('(', '2009'), ('2009', ')'), (')', '.')]

>> Trigrams are: 
 [('26', ',', '120–144'), (',', '120–144', '('), ('120–144', '(', '2009'), ('(', '2009', ')'), ('2009', ')', '.')]

>> POS Tags are: 
 [('26', 'CD'), (',', ','), ('120–144', 'CD'), ('(', '('), ('2009', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('26', '26'), (',', ','), ('120–144', '120–144'), ('(', '('), ('2009', '2009'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('26', '26'), (',', ','), ('120–144', '120–144'), ('(', '('), ('2009', '2009'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('26', '26'), (',', ','), ('120–144', '120–144'), ('(', '('), ('2009', '2009'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 312 ===========================================

61. Farabet, C., Couprie, C., Najman, L. & LeCun, Y. Scene parsing with multiscale  feature learning, purity trees, and optimal covers. In Proc. International  Conference on Machine Learning http://arxiv.org/abs/1202.2160 (2012).  

------------------- Sentence 1 -------------------

61.

>> Tokens are: 
 ['61', '.']

>> Bigrams are: 
 [('61', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('61', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('61', '61'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('61', '61'), ('.', '.')]

>> Lemmatization: 
 [('61', '61'), ('.', '.')]


------------------- Sentence 2 -------------------

Farabet, C., Couprie, C., Najman, L. & LeCun, Y.

>> Tokens are: 
 ['Farabet', ',', 'C.', ',', 'Couprie', ',', 'C.', ',', 'Najman', ',', 'L.', '&', 'LeCun', ',', 'Y', '.']

>> Bigrams are: 
 [('Farabet', ','), (',', 'C.'), ('C.', ','), (',', 'Couprie'), ('Couprie', ','), (',', 'C.'), ('C.', ','), (',', 'Najman'), ('Najman', ','), (',', 'L.'), ('L.', '&'), ('&', 'LeCun'), ('LeCun', ','), (',', 'Y'), ('Y', '.')]

>> Trigrams are: 
 [('Farabet', ',', 'C.'), (',', 'C.', ','), ('C.', ',', 'Couprie'), (',', 'Couprie', ','), ('Couprie', ',', 'C.'), (',', 'C.', ','), ('C.', ',', 'Najman'), (',', 'Najman', ','), ('Najman', ',', 'L.'), (',', 'L.', '&'), ('L.', '&', 'LeCun'), ('&', 'LeCun', ','), ('LeCun', ',', 'Y'), (',', 'Y', '.')]

>> POS Tags are: 
 [('Farabet', 'NNP'), (',', ','), ('C.', 'NNP'), (',', ','), ('Couprie', 'NNP'), (',', ','), ('C.', 'NNP'), (',', ','), ('Najman', 'NNP'), (',', ','), ('L.', 'NNP'), ('&', 'CC'), ('LeCun', 'NNP'), (',', ','), ('Y', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Farabet', 'C.', 'Couprie', 'C.', 'Najman', 'L.', 'LeCun', 'Y']

>> Named Entities are: 
 [('GPE', 'Farabet'), ('PERSON', 'Couprie'), ('PERSON', 'Najman'), ('ORGANIZATION', 'LeCun')] 

>> Stemming using Porter Stemmer: 
 [('Farabet', 'farabet'), (',', ','), ('C.', 'c.'), (',', ','), ('Couprie', 'coupri'), (',', ','), ('C.', 'c.'), (',', ','), ('Najman', 'najman'), (',', ','), ('L.', 'l.'), ('&', '&'), ('LeCun', 'lecun'), (',', ','), ('Y', 'y'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Farabet', 'farabet'), (',', ','), ('C.', 'c.'), (',', ','), ('Couprie', 'coupri'), (',', ','), ('C.', 'c.'), (',', ','), ('Najman', 'najman'), (',', ','), ('L.', 'l.'), ('&', '&'), ('LeCun', 'lecun'), (',', ','), ('Y', 'y'), ('.', '.')]

>> Lemmatization: 
 [('Farabet', 'Farabet'), (',', ','), ('C.', 'C.'), (',', ','), ('Couprie', 'Couprie'), (',', ','), ('C.', 'C.'), (',', ','), ('Najman', 'Najman'), (',', ','), ('L.', 'L.'), ('&', '&'), ('LeCun', 'LeCun'), (',', ','), ('Y', 'Y'), ('.', '.')]


------------------- Sentence 3 -------------------

Scene parsing with multiscale  feature learning, purity trees, and optimal covers.

>> Tokens are: 
 ['Scene', 'parsing', 'multiscale', 'feature', 'learning', ',', 'purity', 'trees', ',', 'optimal', 'covers', '.']

>> Bigrams are: 
 [('Scene', 'parsing'), ('parsing', 'multiscale'), ('multiscale', 'feature'), ('feature', 'learning'), ('learning', ','), (',', 'purity'), ('purity', 'trees'), ('trees', ','), (',', 'optimal'), ('optimal', 'covers'), ('covers', '.')]

>> Trigrams are: 
 [('Scene', 'parsing', 'multiscale'), ('parsing', 'multiscale', 'feature'), ('multiscale', 'feature', 'learning'), ('feature', 'learning', ','), ('learning', ',', 'purity'), (',', 'purity', 'trees'), ('purity', 'trees', ','), ('trees', ',', 'optimal'), (',', 'optimal', 'covers'), ('optimal', 'covers', '.')]

>> POS Tags are: 
 [('Scene', 'NNP'), ('parsing', 'VBG'), ('multiscale', 'JJ'), ('feature', 'NN'), ('learning', 'NN'), (',', ','), ('purity', 'NN'), ('trees', 'NNS'), (',', ','), ('optimal', 'JJ'), ('covers', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['Scene', 'multiscale feature learning', 'purity trees', 'optimal covers']

>> Named Entities are: 
 [('GPE', 'Scene')] 

>> Stemming using Porter Stemmer: 
 [('Scene', 'scene'), ('parsing', 'pars'), ('multiscale', 'multiscal'), ('feature', 'featur'), ('learning', 'learn'), (',', ','), ('purity', 'puriti'), ('trees', 'tree'), (',', ','), ('optimal', 'optim'), ('covers', 'cover'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Scene', 'scene'), ('parsing', 'pars'), ('multiscale', 'multiscal'), ('feature', 'featur'), ('learning', 'learn'), (',', ','), ('purity', 'puriti'), ('trees', 'tree'), (',', ','), ('optimal', 'optim'), ('covers', 'cover'), ('.', '.')]

>> Lemmatization: 
 [('Scene', 'Scene'), ('parsing', 'parsing'), ('multiscale', 'multiscale'), ('feature', 'feature'), ('learning', 'learning'), (',', ','), ('purity', 'purity'), ('trees', 'tree'), (',', ','), ('optimal', 'optimal'), ('covers', 'cover'), ('.', '.')]


------------------- Sentence 4 -------------------

In Proc.

>> Tokens are: 
 ['In', 'Proc', '.']

>> Bigrams are: 
 [('In', 'Proc'), ('Proc', '.')]

>> Trigrams are: 
 [('In', 'Proc', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('Proc', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Proc']

>> Named Entities are: 
 [('GPE', 'Proc')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('Proc', 'proc'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('Proc', 'proc'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('Proc', 'Proc'), ('.', '.')]


------------------- Sentence 5 -------------------

International  Conference on Machine Learning http://arxiv.org/abs/1202.2160 (2012).

>> Tokens are: 
 ['International', 'Conference', 'Machine', 'Learning', 'http', ':', '//arxiv.org/abs/1202.2160', '(', '2012', ')', '.']

>> Bigrams are: 
 [('International', 'Conference'), ('Conference', 'Machine'), ('Machine', 'Learning'), ('Learning', 'http'), ('http', ':'), (':', '//arxiv.org/abs/1202.2160'), ('//arxiv.org/abs/1202.2160', '('), ('(', '2012'), ('2012', ')'), (')', '.')]

>> Trigrams are: 
 [('International', 'Conference', 'Machine'), ('Conference', 'Machine', 'Learning'), ('Machine', 'Learning', 'http'), ('Learning', 'http', ':'), ('http', ':', '//arxiv.org/abs/1202.2160'), (':', '//arxiv.org/abs/1202.2160', '('), ('//arxiv.org/abs/1202.2160', '(', '2012'), ('(', '2012', ')'), ('2012', ')', '.')]

>> POS Tags are: 
 [('International', 'NNP'), ('Conference', 'NNP'), ('Machine', 'NNP'), ('Learning', 'NNP'), ('http', 'NN'), (':', ':'), ('//arxiv.org/abs/1202.2160', 'NN'), ('(', '('), ('2012', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['International Conference Machine Learning http', '//arxiv.org/abs/1202.2160']

>> Named Entities are: 
 [('ORGANIZATION', 'International Conference Machine')] 

>> Stemming using Porter Stemmer: 
 [('International', 'intern'), ('Conference', 'confer'), ('Machine', 'machin'), ('Learning', 'learn'), ('http', 'http'), (':', ':'), ('//arxiv.org/abs/1202.2160', '//arxiv.org/abs/1202.2160'), ('(', '('), ('2012', '2012'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('International', 'intern'), ('Conference', 'confer'), ('Machine', 'machin'), ('Learning', 'learn'), ('http', 'http'), (':', ':'), ('//arxiv.org/abs/1202.2160', '//arxiv.org/abs/1202.2160'), ('(', '('), ('2012', '2012'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('International', 'International'), ('Conference', 'Conference'), ('Machine', 'Machine'), ('Learning', 'Learning'), ('http', 'http'), (':', ':'), ('//arxiv.org/abs/1202.2160', '//arxiv.org/abs/1202.2160'), ('(', '('), ('2012', '2012'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 313 ===========================================

62. Srivastava, N., Hinton, G., Krizhevsky, A., Sutskever, I. & Salakhutdinov, R.  Dropout: a simple way to prevent neural networks from overfitting. J. Machine  Learning Res. 15, 1929–1958 (2014).  

------------------- Sentence 1 -------------------

62.

>> Tokens are: 
 ['62', '.']

>> Bigrams are: 
 [('62', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('62', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('62', '62'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('62', '62'), ('.', '.')]

>> Lemmatization: 
 [('62', '62'), ('.', '.')]


------------------- Sentence 2 -------------------

Srivastava, N., Hinton, G., Krizhevsky, A., Sutskever, I.

>> Tokens are: 
 ['Srivastava', ',', 'N.', ',', 'Hinton', ',', 'G.', ',', 'Krizhevsky', ',', 'A.', ',', 'Sutskever', ',', 'I', '.']

>> Bigrams are: 
 [('Srivastava', ','), (',', 'N.'), ('N.', ','), (',', 'Hinton'), ('Hinton', ','), (',', 'G.'), ('G.', ','), (',', 'Krizhevsky'), ('Krizhevsky', ','), (',', 'A.'), ('A.', ','), (',', 'Sutskever'), ('Sutskever', ','), (',', 'I'), ('I', '.')]

>> Trigrams are: 
 [('Srivastava', ',', 'N.'), (',', 'N.', ','), ('N.', ',', 'Hinton'), (',', 'Hinton', ','), ('Hinton', ',', 'G.'), (',', 'G.', ','), ('G.', ',', 'Krizhevsky'), (',', 'Krizhevsky', ','), ('Krizhevsky', ',', 'A.'), (',', 'A.', ','), ('A.', ',', 'Sutskever'), (',', 'Sutskever', ','), ('Sutskever', ',', 'I'), (',', 'I', '.')]

>> POS Tags are: 
 [('Srivastava', 'NNP'), (',', ','), ('N.', 'NNP'), (',', ','), ('Hinton', 'NNP'), (',', ','), ('G.', 'NNP'), (',', ','), ('Krizhevsky', 'NNP'), (',', ','), ('A.', 'NNP'), (',', ','), ('Sutskever', 'NNP'), (',', ','), ('I', 'PRP'), ('.', '.')]

>> Noun Phrases are: 
 ['Srivastava', 'N.', 'Hinton', 'G.', 'Krizhevsky', 'A.', 'Sutskever']

>> Named Entities are: 
 [('GPE', 'Srivastava'), ('GPE', 'Hinton'), ('PERSON', 'Krizhevsky'), ('GPE', 'Sutskever')] 

>> Stemming using Porter Stemmer: 
 [('Srivastava', 'srivastava'), (',', ','), ('N.', 'n.'), (',', ','), ('Hinton', 'hinton'), (',', ','), ('G.', 'g.'), (',', ','), ('Krizhevsky', 'krizhevski'), (',', ','), ('A.', 'a.'), (',', ','), ('Sutskever', 'sutskev'), (',', ','), ('I', 'i'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Srivastava', 'srivastava'), (',', ','), ('N.', 'n.'), (',', ','), ('Hinton', 'hinton'), (',', ','), ('G.', 'g.'), (',', ','), ('Krizhevsky', 'krizhevski'), (',', ','), ('A.', 'a.'), (',', ','), ('Sutskever', 'sutskev'), (',', ','), ('I', 'i'), ('.', '.')]

>> Lemmatization: 
 [('Srivastava', 'Srivastava'), (',', ','), ('N.', 'N.'), (',', ','), ('Hinton', 'Hinton'), (',', ','), ('G.', 'G.'), (',', ','), ('Krizhevsky', 'Krizhevsky'), (',', ','), ('A.', 'A.'), (',', ','), ('Sutskever', 'Sutskever'), (',', ','), ('I', 'I'), ('.', '.')]


------------------- Sentence 3 -------------------

& Salakhutdinov, R.  Dropout: a simple way to prevent neural networks from overfitting.

>> Tokens are: 
 ['&', 'Salakhutdinov', ',', 'R.', 'Dropout', ':', 'simple', 'way', 'prevent', 'neural', 'networks', 'overfitting', '.']

>> Bigrams are: 
 [('&', 'Salakhutdinov'), ('Salakhutdinov', ','), (',', 'R.'), ('R.', 'Dropout'), ('Dropout', ':'), (':', 'simple'), ('simple', 'way'), ('way', 'prevent'), ('prevent', 'neural'), ('neural', 'networks'), ('networks', 'overfitting'), ('overfitting', '.')]

>> Trigrams are: 
 [('&', 'Salakhutdinov', ','), ('Salakhutdinov', ',', 'R.'), (',', 'R.', 'Dropout'), ('R.', 'Dropout', ':'), ('Dropout', ':', 'simple'), (':', 'simple', 'way'), ('simple', 'way', 'prevent'), ('way', 'prevent', 'neural'), ('prevent', 'neural', 'networks'), ('neural', 'networks', 'overfitting'), ('networks', 'overfitting', '.')]

>> POS Tags are: 
 [('&', 'CC'), ('Salakhutdinov', 'NNP'), (',', ','), ('R.', 'NNP'), ('Dropout', 'NNP'), (':', ':'), ('simple', 'JJ'), ('way', 'NN'), ('prevent', 'JJ'), ('neural', 'JJ'), ('networks', 'NNS'), ('overfitting', 'VBG'), ('.', '.')]

>> Noun Phrases are: 
 ['Salakhutdinov', 'R. Dropout', 'simple way', 'prevent neural networks']

>> Named Entities are: 
 [('PERSON', 'Salakhutdinov')] 

>> Stemming using Porter Stemmer: 
 [('&', '&'), ('Salakhutdinov', 'salakhutdinov'), (',', ','), ('R.', 'r.'), ('Dropout', 'dropout'), (':', ':'), ('simple', 'simpl'), ('way', 'way'), ('prevent', 'prevent'), ('neural', 'neural'), ('networks', 'network'), ('overfitting', 'overfit'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('&', '&'), ('Salakhutdinov', 'salakhutdinov'), (',', ','), ('R.', 'r.'), ('Dropout', 'dropout'), (':', ':'), ('simple', 'simpl'), ('way', 'way'), ('prevent', 'prevent'), ('neural', 'neural'), ('networks', 'network'), ('overfitting', 'overfit'), ('.', '.')]

>> Lemmatization: 
 [('&', '&'), ('Salakhutdinov', 'Salakhutdinov'), (',', ','), ('R.', 'R.'), ('Dropout', 'Dropout'), (':', ':'), ('simple', 'simple'), ('way', 'way'), ('prevent', 'prevent'), ('neural', 'neural'), ('networks', 'network'), ('overfitting', 'overfitting'), ('.', '.')]


------------------- Sentence 4 -------------------

J.

>> Tokens are: 
 ['J', '.']

>> Bigrams are: 
 [('J', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('J', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['J']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('J', 'j'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('J', 'j'), ('.', '.')]

>> Lemmatization: 
 [('J', 'J'), ('.', '.')]


------------------- Sentence 5 -------------------

Machine  Learning Res.

>> Tokens are: 
 ['Machine', 'Learning', 'Res', '.']

>> Bigrams are: 
 [('Machine', 'Learning'), ('Learning', 'Res'), ('Res', '.')]

>> Trigrams are: 
 [('Machine', 'Learning', 'Res'), ('Learning', 'Res', '.')]

>> POS Tags are: 
 [('Machine', 'NN'), ('Learning', 'NNP'), ('Res', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Machine Learning Res']

>> Named Entities are: 
 [('PERSON', 'Machine Learning Res')] 

>> Stemming using Porter Stemmer: 
 [('Machine', 'machin'), ('Learning', 'learn'), ('Res', 're'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Machine', 'machin'), ('Learning', 'learn'), ('Res', 'res'), ('.', '.')]

>> Lemmatization: 
 [('Machine', 'Machine'), ('Learning', 'Learning'), ('Res', 'Res'), ('.', '.')]


------------------- Sentence 6 -------------------

15, 1929–1958 (2014).

>> Tokens are: 
 ['15', ',', '1929–1958', '(', '2014', ')', '.']

>> Bigrams are: 
 [('15', ','), (',', '1929–1958'), ('1929–1958', '('), ('(', '2014'), ('2014', ')'), (')', '.')]

>> Trigrams are: 
 [('15', ',', '1929–1958'), (',', '1929–1958', '('), ('1929–1958', '(', '2014'), ('(', '2014', ')'), ('2014', ')', '.')]

>> POS Tags are: 
 [('15', 'CD'), (',', ','), ('1929–1958', 'CD'), ('(', '('), ('2014', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('15', '15'), (',', ','), ('1929–1958', '1929–1958'), ('(', '('), ('2014', '2014'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('15', '15'), (',', ','), ('1929–1958', '1929–1958'), ('(', '('), ('2014', '2014'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('15', '15'), (',', ','), ('1929–1958', '1929–1958'), ('(', '('), ('2014', '2014'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 314 ===========================================

63. Sermanet, P. et al. Overfeat: integrated recognition, localization and detection  using convolutional networks. In Proc. International Conference on Learning  Representations http://arxiv.org/abs/1312.6229 (2014).  

------------------- Sentence 1 -------------------

63.

>> Tokens are: 
 ['63', '.']

>> Bigrams are: 
 [('63', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('63', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('63', '63'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('63', '63'), ('.', '.')]

>> Lemmatization: 
 [('63', '63'), ('.', '.')]


------------------- Sentence 2 -------------------

Sermanet, P. et al.

>> Tokens are: 
 ['Sermanet', ',', 'P.', 'et', 'al', '.']

>> Bigrams are: 
 [('Sermanet', ','), (',', 'P.'), ('P.', 'et'), ('et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('Sermanet', ',', 'P.'), (',', 'P.', 'et'), ('P.', 'et', 'al'), ('et', 'al', '.')]

>> POS Tags are: 
 [('Sermanet', 'NNP'), (',', ','), ('P.', 'NNP'), ('et', 'CC'), ('al', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Sermanet', 'P.', 'al']

>> Named Entities are: 
 [('GPE', 'Sermanet')] 

>> Stemming using Porter Stemmer: 
 [('Sermanet', 'sermanet'), (',', ','), ('P.', 'p.'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Sermanet', 'sermanet'), (',', ','), ('P.', 'p.'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('Sermanet', 'Sermanet'), (',', ','), ('P.', 'P.'), ('et', 'et'), ('al', 'al'), ('.', '.')]


------------------- Sentence 3 -------------------

Overfeat: integrated recognition, localization and detection  using convolutional networks.

>> Tokens are: 
 ['Overfeat', ':', 'integrated', 'recognition', ',', 'localization', 'detection', 'using', 'convolutional', 'networks', '.']

>> Bigrams are: 
 [('Overfeat', ':'), (':', 'integrated'), ('integrated', 'recognition'), ('recognition', ','), (',', 'localization'), ('localization', 'detection'), ('detection', 'using'), ('using', 'convolutional'), ('convolutional', 'networks'), ('networks', '.')]

>> Trigrams are: 
 [('Overfeat', ':', 'integrated'), (':', 'integrated', 'recognition'), ('integrated', 'recognition', ','), ('recognition', ',', 'localization'), (',', 'localization', 'detection'), ('localization', 'detection', 'using'), ('detection', 'using', 'convolutional'), ('using', 'convolutional', 'networks'), ('convolutional', 'networks', '.')]

>> POS Tags are: 
 [('Overfeat', 'NN'), (':', ':'), ('integrated', 'JJ'), ('recognition', 'NN'), (',', ','), ('localization', 'NN'), ('detection', 'NN'), ('using', 'VBG'), ('convolutional', 'JJ'), ('networks', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['Overfeat', 'integrated recognition', 'localization detection', 'convolutional networks']

>> Named Entities are: 
 [('GPE', 'Overfeat')] 

>> Stemming using Porter Stemmer: 
 [('Overfeat', 'overfeat'), (':', ':'), ('integrated', 'integr'), ('recognition', 'recognit'), (',', ','), ('localization', 'local'), ('detection', 'detect'), ('using', 'use'), ('convolutional', 'convolut'), ('networks', 'network'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Overfeat', 'overfeat'), (':', ':'), ('integrated', 'integr'), ('recognition', 'recognit'), (',', ','), ('localization', 'local'), ('detection', 'detect'), ('using', 'use'), ('convolutional', 'convolut'), ('networks', 'network'), ('.', '.')]

>> Lemmatization: 
 [('Overfeat', 'Overfeat'), (':', ':'), ('integrated', 'integrated'), ('recognition', 'recognition'), (',', ','), ('localization', 'localization'), ('detection', 'detection'), ('using', 'using'), ('convolutional', 'convolutional'), ('networks', 'network'), ('.', '.')]


------------------- Sentence 4 -------------------

In Proc.

>> Tokens are: 
 ['In', 'Proc', '.']

>> Bigrams are: 
 [('In', 'Proc'), ('Proc', '.')]

>> Trigrams are: 
 [('In', 'Proc', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('Proc', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Proc']

>> Named Entities are: 
 [('GPE', 'Proc')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('Proc', 'proc'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('Proc', 'proc'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('Proc', 'Proc'), ('.', '.')]


------------------- Sentence 5 -------------------

International Conference on Learning  Representations http://arxiv.org/abs/1312.6229 (2014).

>> Tokens are: 
 ['International', 'Conference', 'Learning', 'Representations', 'http', ':', '//arxiv.org/abs/1312.6229', '(', '2014', ')', '.']

>> Bigrams are: 
 [('International', 'Conference'), ('Conference', 'Learning'), ('Learning', 'Representations'), ('Representations', 'http'), ('http', ':'), (':', '//arxiv.org/abs/1312.6229'), ('//arxiv.org/abs/1312.6229', '('), ('(', '2014'), ('2014', ')'), (')', '.')]

>> Trigrams are: 
 [('International', 'Conference', 'Learning'), ('Conference', 'Learning', 'Representations'), ('Learning', 'Representations', 'http'), ('Representations', 'http', ':'), ('http', ':', '//arxiv.org/abs/1312.6229'), (':', '//arxiv.org/abs/1312.6229', '('), ('//arxiv.org/abs/1312.6229', '(', '2014'), ('(', '2014', ')'), ('2014', ')', '.')]

>> POS Tags are: 
 [('International', 'NNP'), ('Conference', 'NNP'), ('Learning', 'NNP'), ('Representations', 'NNP'), ('http', 'NN'), (':', ':'), ('//arxiv.org/abs/1312.6229', 'NN'), ('(', '('), ('2014', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['International Conference Learning Representations http', '//arxiv.org/abs/1312.6229']

>> Named Entities are: 
 [('ORGANIZATION', 'International Conference')] 

>> Stemming using Porter Stemmer: 
 [('International', 'intern'), ('Conference', 'confer'), ('Learning', 'learn'), ('Representations', 'represent'), ('http', 'http'), (':', ':'), ('//arxiv.org/abs/1312.6229', '//arxiv.org/abs/1312.6229'), ('(', '('), ('2014', '2014'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('International', 'intern'), ('Conference', 'confer'), ('Learning', 'learn'), ('Representations', 'represent'), ('http', 'http'), (':', ':'), ('//arxiv.org/abs/1312.6229', '//arxiv.org/abs/1312.6229'), ('(', '('), ('2014', '2014'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('International', 'International'), ('Conference', 'Conference'), ('Learning', 'Learning'), ('Representations', 'Representations'), ('http', 'http'), (':', ':'), ('//arxiv.org/abs/1312.6229', '//arxiv.org/abs/1312.6229'), ('(', '('), ('2014', '2014'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 315 ===========================================

64. Girshick, R., Donahue, J., Darrell, T. & Malik, J. Rich feature hierarchies for  accurate object detection and semantic segmentation. In Proc. Conference on  Computer Vision and Pattern Recognition 580–587 (2014).  

------------------- Sentence 1 -------------------

64.

>> Tokens are: 
 ['64', '.']

>> Bigrams are: 
 [('64', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('64', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('64', '64'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('64', '64'), ('.', '.')]

>> Lemmatization: 
 [('64', '64'), ('.', '.')]


------------------- Sentence 2 -------------------

Girshick, R., Donahue, J., Darrell, T. & Malik, J.

>> Tokens are: 
 ['Girshick', ',', 'R.', ',', 'Donahue', ',', 'J.', ',', 'Darrell', ',', 'T.', '&', 'Malik', ',', 'J', '.']

>> Bigrams are: 
 [('Girshick', ','), (',', 'R.'), ('R.', ','), (',', 'Donahue'), ('Donahue', ','), (',', 'J.'), ('J.', ','), (',', 'Darrell'), ('Darrell', ','), (',', 'T.'), ('T.', '&'), ('&', 'Malik'), ('Malik', ','), (',', 'J'), ('J', '.')]

>> Trigrams are: 
 [('Girshick', ',', 'R.'), (',', 'R.', ','), ('R.', ',', 'Donahue'), (',', 'Donahue', ','), ('Donahue', ',', 'J.'), (',', 'J.', ','), ('J.', ',', 'Darrell'), (',', 'Darrell', ','), ('Darrell', ',', 'T.'), (',', 'T.', '&'), ('T.', '&', 'Malik'), ('&', 'Malik', ','), ('Malik', ',', 'J'), (',', 'J', '.')]

>> POS Tags are: 
 [('Girshick', 'NNP'), (',', ','), ('R.', 'NNP'), (',', ','), ('Donahue', 'NNP'), (',', ','), ('J.', 'NNP'), (',', ','), ('Darrell', 'NNP'), (',', ','), ('T.', 'NNP'), ('&', 'CC'), ('Malik', 'NNP'), (',', ','), ('J', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Girshick', 'R.', 'Donahue', 'J.', 'Darrell', 'T.', 'Malik', 'J']

>> Named Entities are: 
 [('GPE', 'Girshick'), ('PERSON', 'Donahue'), ('PERSON', 'Darrell'), ('GPE', 'Malik')] 

>> Stemming using Porter Stemmer: 
 [('Girshick', 'girshick'), (',', ','), ('R.', 'r.'), (',', ','), ('Donahue', 'donahu'), (',', ','), ('J.', 'j.'), (',', ','), ('Darrell', 'darrel'), (',', ','), ('T.', 't.'), ('&', '&'), ('Malik', 'malik'), (',', ','), ('J', 'j'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Girshick', 'girshick'), (',', ','), ('R.', 'r.'), (',', ','), ('Donahue', 'donahu'), (',', ','), ('J.', 'j.'), (',', ','), ('Darrell', 'darrel'), (',', ','), ('T.', 't.'), ('&', '&'), ('Malik', 'malik'), (',', ','), ('J', 'j'), ('.', '.')]

>> Lemmatization: 
 [('Girshick', 'Girshick'), (',', ','), ('R.', 'R.'), (',', ','), ('Donahue', 'Donahue'), (',', ','), ('J.', 'J.'), (',', ','), ('Darrell', 'Darrell'), (',', ','), ('T.', 'T.'), ('&', '&'), ('Malik', 'Malik'), (',', ','), ('J', 'J'), ('.', '.')]


------------------- Sentence 3 -------------------

Rich feature hierarchies for  accurate object detection and semantic segmentation.

>> Tokens are: 
 ['Rich', 'feature', 'hierarchies', 'accurate', 'object', 'detection', 'semantic', 'segmentation', '.']

>> Bigrams are: 
 [('Rich', 'feature'), ('feature', 'hierarchies'), ('hierarchies', 'accurate'), ('accurate', 'object'), ('object', 'detection'), ('detection', 'semantic'), ('semantic', 'segmentation'), ('segmentation', '.')]

>> Trigrams are: 
 [('Rich', 'feature', 'hierarchies'), ('feature', 'hierarchies', 'accurate'), ('hierarchies', 'accurate', 'object'), ('accurate', 'object', 'detection'), ('object', 'detection', 'semantic'), ('detection', 'semantic', 'segmentation'), ('semantic', 'segmentation', '.')]

>> POS Tags are: 
 [('Rich', 'JJ'), ('feature', 'NN'), ('hierarchies', 'NNS'), ('accurate', 'VBP'), ('object', 'JJ'), ('detection', 'NN'), ('semantic', 'JJ'), ('segmentation', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Rich feature hierarchies', 'object detection', 'semantic segmentation']

>> Named Entities are: 
 [('GPE', 'Rich')] 

>> Stemming using Porter Stemmer: 
 [('Rich', 'rich'), ('feature', 'featur'), ('hierarchies', 'hierarchi'), ('accurate', 'accur'), ('object', 'object'), ('detection', 'detect'), ('semantic', 'semant'), ('segmentation', 'segment'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Rich', 'rich'), ('feature', 'featur'), ('hierarchies', 'hierarchi'), ('accurate', 'accur'), ('object', 'object'), ('detection', 'detect'), ('semantic', 'semant'), ('segmentation', 'segment'), ('.', '.')]

>> Lemmatization: 
 [('Rich', 'Rich'), ('feature', 'feature'), ('hierarchies', 'hierarchy'), ('accurate', 'accurate'), ('object', 'object'), ('detection', 'detection'), ('semantic', 'semantic'), ('segmentation', 'segmentation'), ('.', '.')]


------------------- Sentence 4 -------------------

In Proc.

>> Tokens are: 
 ['In', 'Proc', '.']

>> Bigrams are: 
 [('In', 'Proc'), ('Proc', '.')]

>> Trigrams are: 
 [('In', 'Proc', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('Proc', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Proc']

>> Named Entities are: 
 [('GPE', 'Proc')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('Proc', 'proc'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('Proc', 'proc'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('Proc', 'Proc'), ('.', '.')]


------------------- Sentence 5 -------------------

Conference on  Computer Vision and Pattern Recognition 580–587 (2014).

>> Tokens are: 
 ['Conference', 'Computer', 'Vision', 'Pattern', 'Recognition', '580–587', '(', '2014', ')', '.']

>> Bigrams are: 
 [('Conference', 'Computer'), ('Computer', 'Vision'), ('Vision', 'Pattern'), ('Pattern', 'Recognition'), ('Recognition', '580–587'), ('580–587', '('), ('(', '2014'), ('2014', ')'), (')', '.')]

>> Trigrams are: 
 [('Conference', 'Computer', 'Vision'), ('Computer', 'Vision', 'Pattern'), ('Vision', 'Pattern', 'Recognition'), ('Pattern', 'Recognition', '580–587'), ('Recognition', '580–587', '('), ('580–587', '(', '2014'), ('(', '2014', ')'), ('2014', ')', '.')]

>> POS Tags are: 
 [('Conference', 'NN'), ('Computer', 'NNP'), ('Vision', 'NNP'), ('Pattern', 'NNP'), ('Recognition', 'NNP'), ('580–587', 'CD'), ('(', '('), ('2014', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['Conference Computer Vision Pattern Recognition']

>> Named Entities are: 
 [('ORGANIZATION', 'Conference'), ('ORGANIZATION', 'Computer Vision Pattern')] 

>> Stemming using Porter Stemmer: 
 [('Conference', 'confer'), ('Computer', 'comput'), ('Vision', 'vision'), ('Pattern', 'pattern'), ('Recognition', 'recognit'), ('580–587', '580–587'), ('(', '('), ('2014', '2014'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Conference', 'confer'), ('Computer', 'comput'), ('Vision', 'vision'), ('Pattern', 'pattern'), ('Recognition', 'recognit'), ('580–587', '580–587'), ('(', '('), ('2014', '2014'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Conference', 'Conference'), ('Computer', 'Computer'), ('Vision', 'Vision'), ('Pattern', 'Pattern'), ('Recognition', 'Recognition'), ('580–587', '580–587'), ('(', '('), ('2014', '2014'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 316 ===========================================

65. Simonyan, K. & Zisserman, A. Very deep convolutional networks for large-scale  image recognition. In Proc. International Conference on Learning Representations  http://arxiv.org/abs/1409.1556 (2014).  

------------------- Sentence 1 -------------------

65.

>> Tokens are: 
 ['65', '.']

>> Bigrams are: 
 [('65', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('65', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('65', '65'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('65', '65'), ('.', '.')]

>> Lemmatization: 
 [('65', '65'), ('.', '.')]


------------------- Sentence 2 -------------------

Simonyan, K. & Zisserman, A.

>> Tokens are: 
 ['Simonyan', ',', 'K.', '&', 'Zisserman', ',', 'A', '.']

>> Bigrams are: 
 [('Simonyan', ','), (',', 'K.'), ('K.', '&'), ('&', 'Zisserman'), ('Zisserman', ','), (',', 'A'), ('A', '.')]

>> Trigrams are: 
 [('Simonyan', ',', 'K.'), (',', 'K.', '&'), ('K.', '&', 'Zisserman'), ('&', 'Zisserman', ','), ('Zisserman', ',', 'A'), (',', 'A', '.')]

>> POS Tags are: 
 [('Simonyan', 'NNP'), (',', ','), ('K.', 'NNP'), ('&', 'CC'), ('Zisserman', 'NNP'), (',', ','), ('A', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Simonyan', 'K.', 'Zisserman', 'A']

>> Named Entities are: 
 [('GPE', 'Simonyan'), ('PERSON', 'Zisserman')] 

>> Stemming using Porter Stemmer: 
 [('Simonyan', 'simonyan'), (',', ','), ('K.', 'k.'), ('&', '&'), ('Zisserman', 'zisserman'), (',', ','), ('A', 'a'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Simonyan', 'simonyan'), (',', ','), ('K.', 'k.'), ('&', '&'), ('Zisserman', 'zisserman'), (',', ','), ('A', 'a'), ('.', '.')]

>> Lemmatization: 
 [('Simonyan', 'Simonyan'), (',', ','), ('K.', 'K.'), ('&', '&'), ('Zisserman', 'Zisserman'), (',', ','), ('A', 'A'), ('.', '.')]


------------------- Sentence 3 -------------------

Very deep convolutional networks for large-scale  image recognition.

>> Tokens are: 
 ['Very', 'deep', 'convolutional', 'networks', 'large-scale', 'image', 'recognition', '.']

>> Bigrams are: 
 [('Very', 'deep'), ('deep', 'convolutional'), ('convolutional', 'networks'), ('networks', 'large-scale'), ('large-scale', 'image'), ('image', 'recognition'), ('recognition', '.')]

>> Trigrams are: 
 [('Very', 'deep', 'convolutional'), ('deep', 'convolutional', 'networks'), ('convolutional', 'networks', 'large-scale'), ('networks', 'large-scale', 'image'), ('large-scale', 'image', 'recognition'), ('image', 'recognition', '.')]

>> POS Tags are: 
 [('Very', 'RB'), ('deep', 'JJ'), ('convolutional', 'JJ'), ('networks', 'NNS'), ('large-scale', 'JJ'), ('image', 'NN'), ('recognition', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['deep convolutional networks', 'large-scale image recognition']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Very', 'veri'), ('deep', 'deep'), ('convolutional', 'convolut'), ('networks', 'network'), ('large-scale', 'large-scal'), ('image', 'imag'), ('recognition', 'recognit'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Very', 'veri'), ('deep', 'deep'), ('convolutional', 'convolut'), ('networks', 'network'), ('large-scale', 'large-scal'), ('image', 'imag'), ('recognition', 'recognit'), ('.', '.')]

>> Lemmatization: 
 [('Very', 'Very'), ('deep', 'deep'), ('convolutional', 'convolutional'), ('networks', 'network'), ('large-scale', 'large-scale'), ('image', 'image'), ('recognition', 'recognition'), ('.', '.')]


------------------- Sentence 4 -------------------

In Proc.

>> Tokens are: 
 ['In', 'Proc', '.']

>> Bigrams are: 
 [('In', 'Proc'), ('Proc', '.')]

>> Trigrams are: 
 [('In', 'Proc', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('Proc', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Proc']

>> Named Entities are: 
 [('GPE', 'Proc')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('Proc', 'proc'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('Proc', 'proc'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('Proc', 'Proc'), ('.', '.')]


------------------- Sentence 5 -------------------

International Conference on Learning Representations  http://arxiv.org/abs/1409.1556 (2014).

>> Tokens are: 
 ['International', 'Conference', 'Learning', 'Representations', 'http', ':', '//arxiv.org/abs/1409.1556', '(', '2014', ')', '.']

>> Bigrams are: 
 [('International', 'Conference'), ('Conference', 'Learning'), ('Learning', 'Representations'), ('Representations', 'http'), ('http', ':'), (':', '//arxiv.org/abs/1409.1556'), ('//arxiv.org/abs/1409.1556', '('), ('(', '2014'), ('2014', ')'), (')', '.')]

>> Trigrams are: 
 [('International', 'Conference', 'Learning'), ('Conference', 'Learning', 'Representations'), ('Learning', 'Representations', 'http'), ('Representations', 'http', ':'), ('http', ':', '//arxiv.org/abs/1409.1556'), (':', '//arxiv.org/abs/1409.1556', '('), ('//arxiv.org/abs/1409.1556', '(', '2014'), ('(', '2014', ')'), ('2014', ')', '.')]

>> POS Tags are: 
 [('International', 'NNP'), ('Conference', 'NNP'), ('Learning', 'NNP'), ('Representations', 'NNP'), ('http', 'NN'), (':', ':'), ('//arxiv.org/abs/1409.1556', 'NN'), ('(', '('), ('2014', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['International Conference Learning Representations http', '//arxiv.org/abs/1409.1556']

>> Named Entities are: 
 [('ORGANIZATION', 'International Conference')] 

>> Stemming using Porter Stemmer: 
 [('International', 'intern'), ('Conference', 'confer'), ('Learning', 'learn'), ('Representations', 'represent'), ('http', 'http'), (':', ':'), ('//arxiv.org/abs/1409.1556', '//arxiv.org/abs/1409.1556'), ('(', '('), ('2014', '2014'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('International', 'intern'), ('Conference', 'confer'), ('Learning', 'learn'), ('Representations', 'represent'), ('http', 'http'), (':', ':'), ('//arxiv.org/abs/1409.1556', '//arxiv.org/abs/1409.1556'), ('(', '('), ('2014', '2014'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('International', 'International'), ('Conference', 'Conference'), ('Learning', 'Learning'), ('Representations', 'Representations'), ('http', 'http'), (':', ':'), ('//arxiv.org/abs/1409.1556', '//arxiv.org/abs/1409.1556'), ('(', '('), ('2014', '2014'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 317 ===========================================

66. Boser, B., Sackinger, E., Bromley, J., LeCun, Y. & Jackel, L. An analog neural  network processor with programmable topology. J. Solid State Circuits 26,  2017–2025 (1991).  

------------------- Sentence 1 -------------------

66.

>> Tokens are: 
 ['66', '.']

>> Bigrams are: 
 [('66', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('66', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('66', '66'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('66', '66'), ('.', '.')]

>> Lemmatization: 
 [('66', '66'), ('.', '.')]


------------------- Sentence 2 -------------------

Boser, B., Sackinger, E., Bromley, J., LeCun, Y.

>> Tokens are: 
 ['Boser', ',', 'B.', ',', 'Sackinger', ',', 'E.', ',', 'Bromley', ',', 'J.', ',', 'LeCun', ',', 'Y', '.']

>> Bigrams are: 
 [('Boser', ','), (',', 'B.'), ('B.', ','), (',', 'Sackinger'), ('Sackinger', ','), (',', 'E.'), ('E.', ','), (',', 'Bromley'), ('Bromley', ','), (',', 'J.'), ('J.', ','), (',', 'LeCun'), ('LeCun', ','), (',', 'Y'), ('Y', '.')]

>> Trigrams are: 
 [('Boser', ',', 'B.'), (',', 'B.', ','), ('B.', ',', 'Sackinger'), (',', 'Sackinger', ','), ('Sackinger', ',', 'E.'), (',', 'E.', ','), ('E.', ',', 'Bromley'), (',', 'Bromley', ','), ('Bromley', ',', 'J.'), (',', 'J.', ','), ('J.', ',', 'LeCun'), (',', 'LeCun', ','), ('LeCun', ',', 'Y'), (',', 'Y', '.')]

>> POS Tags are: 
 [('Boser', 'NNP'), (',', ','), ('B.', 'NNP'), (',', ','), ('Sackinger', 'NNP'), (',', ','), ('E.', 'NNP'), (',', ','), ('Bromley', 'NNP'), (',', ','), ('J.', 'NNP'), (',', ','), ('LeCun', 'NNP'), (',', ','), ('Y', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Boser', 'B.', 'Sackinger', 'E.', 'Bromley', 'J.', 'LeCun', 'Y']

>> Named Entities are: 
 [('GPE', 'Boser'), ('PERSON', 'Sackinger'), ('PERSON', 'Bromley'), ('ORGANIZATION', 'LeCun')] 

>> Stemming using Porter Stemmer: 
 [('Boser', 'boser'), (',', ','), ('B.', 'b.'), (',', ','), ('Sackinger', 'sacking'), (',', ','), ('E.', 'e.'), (',', ','), ('Bromley', 'bromley'), (',', ','), ('J.', 'j.'), (',', ','), ('LeCun', 'lecun'), (',', ','), ('Y', 'y'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Boser', 'boser'), (',', ','), ('B.', 'b.'), (',', ','), ('Sackinger', 'sacking'), (',', ','), ('E.', 'e.'), (',', ','), ('Bromley', 'bromley'), (',', ','), ('J.', 'j.'), (',', ','), ('LeCun', 'lecun'), (',', ','), ('Y', 'y'), ('.', '.')]

>> Lemmatization: 
 [('Boser', 'Boser'), (',', ','), ('B.', 'B.'), (',', ','), ('Sackinger', 'Sackinger'), (',', ','), ('E.', 'E.'), (',', ','), ('Bromley', 'Bromley'), (',', ','), ('J.', 'J.'), (',', ','), ('LeCun', 'LeCun'), (',', ','), ('Y', 'Y'), ('.', '.')]


------------------- Sentence 3 -------------------

& Jackel, L. An analog neural  network processor with programmable topology.

>> Tokens are: 
 ['&', 'Jackel', ',', 'L.', 'An', 'analog', 'neural', 'network', 'processor', 'programmable', 'topology', '.']

>> Bigrams are: 
 [('&', 'Jackel'), ('Jackel', ','), (',', 'L.'), ('L.', 'An'), ('An', 'analog'), ('analog', 'neural'), ('neural', 'network'), ('network', 'processor'), ('processor', 'programmable'), ('programmable', 'topology'), ('topology', '.')]

>> Trigrams are: 
 [('&', 'Jackel', ','), ('Jackel', ',', 'L.'), (',', 'L.', 'An'), ('L.', 'An', 'analog'), ('An', 'analog', 'neural'), ('analog', 'neural', 'network'), ('neural', 'network', 'processor'), ('network', 'processor', 'programmable'), ('processor', 'programmable', 'topology'), ('programmable', 'topology', '.')]

>> POS Tags are: 
 [('&', 'CC'), ('Jackel', 'NNP'), (',', ','), ('L.', 'NNP'), ('An', 'DT'), ('analog', 'NN'), ('neural', 'JJ'), ('network', 'NN'), ('processor', 'NN'), ('programmable', 'JJ'), ('topology', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Jackel', 'L.', 'An analog', 'neural network processor', 'programmable topology']

>> Named Entities are: 
 [('PERSON', 'Jackel')] 

>> Stemming using Porter Stemmer: 
 [('&', '&'), ('Jackel', 'jackel'), (',', ','), ('L.', 'l.'), ('An', 'an'), ('analog', 'analog'), ('neural', 'neural'), ('network', 'network'), ('processor', 'processor'), ('programmable', 'programm'), ('topology', 'topolog'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('&', '&'), ('Jackel', 'jackel'), (',', ','), ('L.', 'l.'), ('An', 'an'), ('analog', 'analog'), ('neural', 'neural'), ('network', 'network'), ('processor', 'processor'), ('programmable', 'programm'), ('topology', 'topolog'), ('.', '.')]

>> Lemmatization: 
 [('&', '&'), ('Jackel', 'Jackel'), (',', ','), ('L.', 'L.'), ('An', 'An'), ('analog', 'analog'), ('neural', 'neural'), ('network', 'network'), ('processor', 'processor'), ('programmable', 'programmable'), ('topology', 'topology'), ('.', '.')]


------------------- Sentence 4 -------------------

J.

>> Tokens are: 
 ['J', '.']

>> Bigrams are: 
 [('J', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('J', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['J']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('J', 'j'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('J', 'j'), ('.', '.')]

>> Lemmatization: 
 [('J', 'J'), ('.', '.')]


------------------- Sentence 5 -------------------

Solid State Circuits 26,  2017–2025 (1991).

>> Tokens are: 
 ['Solid', 'State', 'Circuits', '26', ',', '2017–2025', '(', '1991', ')', '.']

>> Bigrams are: 
 [('Solid', 'State'), ('State', 'Circuits'), ('Circuits', '26'), ('26', ','), (',', '2017–2025'), ('2017–2025', '('), ('(', '1991'), ('1991', ')'), (')', '.')]

>> Trigrams are: 
 [('Solid', 'State', 'Circuits'), ('State', 'Circuits', '26'), ('Circuits', '26', ','), ('26', ',', '2017–2025'), (',', '2017–2025', '('), ('2017–2025', '(', '1991'), ('(', '1991', ')'), ('1991', ')', '.')]

>> POS Tags are: 
 [('Solid', 'JJ'), ('State', 'NNP'), ('Circuits', 'NNP'), ('26', 'CD'), (',', ','), ('2017–2025', 'CD'), ('(', '('), ('1991', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['Solid State Circuits']

>> Named Entities are: 
 [('PERSON', 'Solid'), ('ORGANIZATION', 'State')] 

>> Stemming using Porter Stemmer: 
 [('Solid', 'solid'), ('State', 'state'), ('Circuits', 'circuit'), ('26', '26'), (',', ','), ('2017–2025', '2017–2025'), ('(', '('), ('1991', '1991'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Solid', 'solid'), ('State', 'state'), ('Circuits', 'circuit'), ('26', '26'), (',', ','), ('2017–2025', '2017–2025'), ('(', '('), ('1991', '1991'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Solid', 'Solid'), ('State', 'State'), ('Circuits', 'Circuits'), ('26', '26'), (',', ','), ('2017–2025', '2017–2025'), ('(', '('), ('1991', '1991'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 318 ===========================================

67. Farabet, C. et al. Large-scale FPGA-based convolutional networks. In Scaling  up Machine Learning: Parallel and Distributed Approaches (eds Bekkerman, R.,  Bilenko, M. & Langford, J.) 399–419 (Cambridge Univ. Press, 2011).  

------------------- Sentence 1 -------------------

67.

>> Tokens are: 
 ['67', '.']

>> Bigrams are: 
 [('67', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('67', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('67', '67'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('67', '67'), ('.', '.')]

>> Lemmatization: 
 [('67', '67'), ('.', '.')]


------------------- Sentence 2 -------------------

Farabet, C. et al.

>> Tokens are: 
 ['Farabet', ',', 'C.', 'et', 'al', '.']

>> Bigrams are: 
 [('Farabet', ','), (',', 'C.'), ('C.', 'et'), ('et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('Farabet', ',', 'C.'), (',', 'C.', 'et'), ('C.', 'et', 'al'), ('et', 'al', '.')]

>> POS Tags are: 
 [('Farabet', 'NNP'), (',', ','), ('C.', 'NNP'), ('et', 'CC'), ('al', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Farabet', 'C.', 'al']

>> Named Entities are: 
 [('GPE', 'Farabet')] 

>> Stemming using Porter Stemmer: 
 [('Farabet', 'farabet'), (',', ','), ('C.', 'c.'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Farabet', 'farabet'), (',', ','), ('C.', 'c.'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('Farabet', 'Farabet'), (',', ','), ('C.', 'C.'), ('et', 'et'), ('al', 'al'), ('.', '.')]


------------------- Sentence 3 -------------------

Large-scale FPGA-based convolutional networks.

>> Tokens are: 
 ['Large-scale', 'FPGA-based', 'convolutional', 'networks', '.']

>> Bigrams are: 
 [('Large-scale', 'FPGA-based'), ('FPGA-based', 'convolutional'), ('convolutional', 'networks'), ('networks', '.')]

>> Trigrams are: 
 [('Large-scale', 'FPGA-based', 'convolutional'), ('FPGA-based', 'convolutional', 'networks'), ('convolutional', 'networks', '.')]

>> POS Tags are: 
 [('Large-scale', 'JJ'), ('FPGA-based', 'JJ'), ('convolutional', 'JJ'), ('networks', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['Large-scale FPGA-based convolutional networks']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Large-scale', 'large-scal'), ('FPGA-based', 'fpga-bas'), ('convolutional', 'convolut'), ('networks', 'network'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Large-scale', 'large-scal'), ('FPGA-based', 'fpga-bas'), ('convolutional', 'convolut'), ('networks', 'network'), ('.', '.')]

>> Lemmatization: 
 [('Large-scale', 'Large-scale'), ('FPGA-based', 'FPGA-based'), ('convolutional', 'convolutional'), ('networks', 'network'), ('.', '.')]


------------------- Sentence 4 -------------------

In Scaling  up Machine Learning: Parallel and Distributed Approaches (eds Bekkerman, R.,  Bilenko, M. & Langford, J.)

>> Tokens are: 
 ['In', 'Scaling', 'Machine', 'Learning', ':', 'Parallel', 'Distributed', 'Approaches', '(', 'eds', 'Bekkerman', ',', 'R.', ',', 'Bilenko', ',', 'M.', '&', 'Langford', ',', 'J', '.', ')']

>> Bigrams are: 
 [('In', 'Scaling'), ('Scaling', 'Machine'), ('Machine', 'Learning'), ('Learning', ':'), (':', 'Parallel'), ('Parallel', 'Distributed'), ('Distributed', 'Approaches'), ('Approaches', '('), ('(', 'eds'), ('eds', 'Bekkerman'), ('Bekkerman', ','), (',', 'R.'), ('R.', ','), (',', 'Bilenko'), ('Bilenko', ','), (',', 'M.'), ('M.', '&'), ('&', 'Langford'), ('Langford', ','), (',', 'J'), ('J', '.'), ('.', ')')]

>> Trigrams are: 
 [('In', 'Scaling', 'Machine'), ('Scaling', 'Machine', 'Learning'), ('Machine', 'Learning', ':'), ('Learning', ':', 'Parallel'), (':', 'Parallel', 'Distributed'), ('Parallel', 'Distributed', 'Approaches'), ('Distributed', 'Approaches', '('), ('Approaches', '(', 'eds'), ('(', 'eds', 'Bekkerman'), ('eds', 'Bekkerman', ','), ('Bekkerman', ',', 'R.'), (',', 'R.', ','), ('R.', ',', 'Bilenko'), (',', 'Bilenko', ','), ('Bilenko', ',', 'M.'), (',', 'M.', '&'), ('M.', '&', 'Langford'), ('&', 'Langford', ','), ('Langford', ',', 'J'), (',', 'J', '.'), ('J', '.', ')')]

>> POS Tags are: 
 [('In', 'IN'), ('Scaling', 'NNP'), ('Machine', 'NNP'), ('Learning', 'NNP'), (':', ':'), ('Parallel', 'NNP'), ('Distributed', 'NNP'), ('Approaches', 'NNP'), ('(', '('), ('eds', 'JJ'), ('Bekkerman', 'NNP'), (',', ','), ('R.', 'NNP'), (',', ','), ('Bilenko', 'NNP'), (',', ','), ('M.', 'NNP'), ('&', 'CC'), ('Langford', 'NNP'), (',', ','), ('J', 'NNP'), ('.', '.'), (')', ')')]

>> Noun Phrases are: 
 ['Scaling Machine Learning', 'Parallel Distributed Approaches', 'eds Bekkerman', 'R.', 'Bilenko', 'M.', 'Langford', 'J']

>> Named Entities are: 
 [('PERSON', 'Machine Learning'), ('PERSON', 'Parallel Distributed Approaches'), ('PERSON', 'Bilenko'), ('GPE', 'Langford')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('Scaling', 'scale'), ('Machine', 'machin'), ('Learning', 'learn'), (':', ':'), ('Parallel', 'parallel'), ('Distributed', 'distribut'), ('Approaches', 'approach'), ('(', '('), ('eds', 'ed'), ('Bekkerman', 'bekkerman'), (',', ','), ('R.', 'r.'), (',', ','), ('Bilenko', 'bilenko'), (',', ','), ('M.', 'm.'), ('&', '&'), ('Langford', 'langford'), (',', ','), ('J', 'j'), ('.', '.'), (')', ')')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('Scaling', 'scale'), ('Machine', 'machin'), ('Learning', 'learn'), (':', ':'), ('Parallel', 'parallel'), ('Distributed', 'distribut'), ('Approaches', 'approach'), ('(', '('), ('eds', 'ed'), ('Bekkerman', 'bekkerman'), (',', ','), ('R.', 'r.'), (',', ','), ('Bilenko', 'bilenko'), (',', ','), ('M.', 'm.'), ('&', '&'), ('Langford', 'langford'), (',', ','), ('J', 'j'), ('.', '.'), (')', ')')]

>> Lemmatization: 
 [('In', 'In'), ('Scaling', 'Scaling'), ('Machine', 'Machine'), ('Learning', 'Learning'), (':', ':'), ('Parallel', 'Parallel'), ('Distributed', 'Distributed'), ('Approaches', 'Approaches'), ('(', '('), ('eds', 'ed'), ('Bekkerman', 'Bekkerman'), (',', ','), ('R.', 'R.'), (',', ','), ('Bilenko', 'Bilenko'), (',', ','), ('M.', 'M.'), ('&', '&'), ('Langford', 'Langford'), (',', ','), ('J', 'J'), ('.', '.'), (')', ')')]


------------------- Sentence 5 -------------------

399–419 (Cambridge Univ.

>> Tokens are: 
 ['399–419', '(', 'Cambridge', 'Univ', '.']

>> Bigrams are: 
 [('399–419', '('), ('(', 'Cambridge'), ('Cambridge', 'Univ'), ('Univ', '.')]

>> Trigrams are: 
 [('399–419', '(', 'Cambridge'), ('(', 'Cambridge', 'Univ'), ('Cambridge', 'Univ', '.')]

>> POS Tags are: 
 [('399–419', 'CD'), ('(', '('), ('Cambridge', 'NNP'), ('Univ', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Cambridge Univ']

>> Named Entities are: 
 [('PERSON', 'Cambridge Univ')] 

>> Stemming using Porter Stemmer: 
 [('399–419', '399–419'), ('(', '('), ('Cambridge', 'cambridg'), ('Univ', 'univ'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('399–419', '399–419'), ('(', '('), ('Cambridge', 'cambridg'), ('Univ', 'univ'), ('.', '.')]

>> Lemmatization: 
 [('399–419', '399–419'), ('(', '('), ('Cambridge', 'Cambridge'), ('Univ', 'Univ'), ('.', '.')]


------------------- Sentence 6 -------------------

Press, 2011).

>> Tokens are: 
 ['Press', ',', '2011', ')', '.']

>> Bigrams are: 
 [('Press', ','), (',', '2011'), ('2011', ')'), (')', '.')]

>> Trigrams are: 
 [('Press', ',', '2011'), (',', '2011', ')'), ('2011', ')', '.')]

>> POS Tags are: 
 [('Press', 'NN'), (',', ','), ('2011', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['Press']

>> Named Entities are: 
 [('GPE', 'Press')] 

>> Stemming using Porter Stemmer: 
 [('Press', 'press'), (',', ','), ('2011', '2011'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Press', 'press'), (',', ','), ('2011', '2011'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Press', 'Press'), (',', ','), ('2011', '2011'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 319 ===========================================

68. Bengio, Y. Learning Deep Architectures for AI (Now, 2009).  69. Montufar, G. & Morton, J. When does a mixture of products contain a product of  

------------------- Sentence 1 -------------------

68.

>> Tokens are: 
 ['68', '.']

>> Bigrams are: 
 [('68', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('68', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('68', '68'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('68', '68'), ('.', '.')]

>> Lemmatization: 
 [('68', '68'), ('.', '.')]


------------------- Sentence 2 -------------------

Bengio, Y.

>> Tokens are: 
 ['Bengio', ',', 'Y', '.']

>> Bigrams are: 
 [('Bengio', ','), (',', 'Y'), ('Y', '.')]

>> Trigrams are: 
 [('Bengio', ',', 'Y'), (',', 'Y', '.')]

>> POS Tags are: 
 [('Bengio', 'NNP'), (',', ','), ('Y', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Bengio', 'Y']

>> Named Entities are: 
 [('GPE', 'Bengio')] 

>> Stemming using Porter Stemmer: 
 [('Bengio', 'bengio'), (',', ','), ('Y', 'y'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Bengio', 'bengio'), (',', ','), ('Y', 'y'), ('.', '.')]

>> Lemmatization: 
 [('Bengio', 'Bengio'), (',', ','), ('Y', 'Y'), ('.', '.')]


------------------- Sentence 3 -------------------

Learning Deep Architectures for AI (Now, 2009).

>> Tokens are: 
 ['Learning', 'Deep', 'Architectures', 'AI', '(', 'Now', ',', '2009', ')', '.']

>> Bigrams are: 
 [('Learning', 'Deep'), ('Deep', 'Architectures'), ('Architectures', 'AI'), ('AI', '('), ('(', 'Now'), ('Now', ','), (',', '2009'), ('2009', ')'), (')', '.')]

>> Trigrams are: 
 [('Learning', 'Deep', 'Architectures'), ('Deep', 'Architectures', 'AI'), ('Architectures', 'AI', '('), ('AI', '(', 'Now'), ('(', 'Now', ','), ('Now', ',', '2009'), (',', '2009', ')'), ('2009', ')', '.')]

>> POS Tags are: 
 [('Learning', 'VBG'), ('Deep', 'NNP'), ('Architectures', 'NNP'), ('AI', 'NNP'), ('(', '('), ('Now', 'RB'), (',', ','), ('2009', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['Deep Architectures AI']

>> Named Entities are: 
 [('PERSON', 'Deep Architectures AI')] 

>> Stemming using Porter Stemmer: 
 [('Learning', 'learn'), ('Deep', 'deep'), ('Architectures', 'architectur'), ('AI', 'ai'), ('(', '('), ('Now', 'now'), (',', ','), ('2009', '2009'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Learning', 'learn'), ('Deep', 'deep'), ('Architectures', 'architectur'), ('AI', 'ai'), ('(', '('), ('Now', 'now'), (',', ','), ('2009', '2009'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Learning', 'Learning'), ('Deep', 'Deep'), ('Architectures', 'Architectures'), ('AI', 'AI'), ('(', '('), ('Now', 'Now'), (',', ','), ('2009', '2009'), (')', ')'), ('.', '.')]


------------------- Sentence 4 -------------------

69.

>> Tokens are: 
 ['69', '.']

>> Bigrams are: 
 [('69', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('69', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('69', '69'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('69', '69'), ('.', '.')]

>> Lemmatization: 
 [('69', '69'), ('.', '.')]


------------------- Sentence 5 -------------------

Montufar, G. & Morton, J.

>> Tokens are: 
 ['Montufar', ',', 'G.', '&', 'Morton', ',', 'J', '.']

>> Bigrams are: 
 [('Montufar', ','), (',', 'G.'), ('G.', '&'), ('&', 'Morton'), ('Morton', ','), (',', 'J'), ('J', '.')]

>> Trigrams are: 
 [('Montufar', ',', 'G.'), (',', 'G.', '&'), ('G.', '&', 'Morton'), ('&', 'Morton', ','), ('Morton', ',', 'J'), (',', 'J', '.')]

>> POS Tags are: 
 [('Montufar', 'NNP'), (',', ','), ('G.', 'NNP'), ('&', 'CC'), ('Morton', 'NNP'), (',', ','), ('J', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Montufar', 'G.', 'Morton', 'J']

>> Named Entities are: 
 [('GPE', 'Montufar'), ('GPE', 'Morton')] 

>> Stemming using Porter Stemmer: 
 [('Montufar', 'montufar'), (',', ','), ('G.', 'g.'), ('&', '&'), ('Morton', 'morton'), (',', ','), ('J', 'j'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Montufar', 'montufar'), (',', ','), ('G.', 'g.'), ('&', '&'), ('Morton', 'morton'), (',', ','), ('J', 'j'), ('.', '.')]

>> Lemmatization: 
 [('Montufar', 'Montufar'), (',', ','), ('G.', 'G.'), ('&', '&'), ('Morton', 'Morton'), (',', ','), ('J', 'J'), ('.', '.')]


------------------- Sentence 6 -------------------

When does a mixture of products contain a product of

>> Tokens are: 
 ['When', 'mixture', 'products', 'contain', 'product']

>> Bigrams are: 
 [('When', 'mixture'), ('mixture', 'products'), ('products', 'contain'), ('contain', 'product')]

>> Trigrams are: 
 [('When', 'mixture', 'products'), ('mixture', 'products', 'contain'), ('products', 'contain', 'product')]

>> POS Tags are: 
 [('When', 'WRB'), ('mixture', 'NN'), ('products', 'NNS'), ('contain', 'VBP'), ('product', 'NN')]

>> Noun Phrases are: 
 ['mixture products', 'product']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('When', 'when'), ('mixture', 'mixtur'), ('products', 'product'), ('contain', 'contain'), ('product', 'product')]

>> Stemming using Snowball Stemmer: 
 [('When', 'when'), ('mixture', 'mixtur'), ('products', 'product'), ('contain', 'contain'), ('product', 'product')]

>> Lemmatization: 
 [('When', 'When'), ('mixture', 'mixture'), ('products', 'product'), ('contain', 'contain'), ('product', 'product')]



========================================== PARAGRAPH 320 ===========================================

mixtures? J. Discrete Math. 29, 321–347 (2014).  70. Montufar, G. F., Pascanu, R., Cho, K. & Bengio, Y. On the number of linear regions  

------------------- Sentence 1 -------------------

mixtures?

>> Tokens are: 
 ['mixtures', '?']

>> Bigrams are: 
 [('mixtures', '?')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('mixtures', 'NNS'), ('?', '.')]

>> Noun Phrases are: 
 ['mixtures']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('mixtures', 'mixtur'), ('?', '?')]

>> Stemming using Snowball Stemmer: 
 [('mixtures', 'mixtur'), ('?', '?')]

>> Lemmatization: 
 [('mixtures', 'mixture'), ('?', '?')]


------------------- Sentence 2 -------------------

J. Discrete Math.

>> Tokens are: 
 ['J.', 'Discrete', 'Math', '.']

>> Bigrams are: 
 [('J.', 'Discrete'), ('Discrete', 'Math'), ('Math', '.')]

>> Trigrams are: 
 [('J.', 'Discrete', 'Math'), ('Discrete', 'Math', '.')]

>> POS Tags are: 
 [('J.', 'NNP'), ('Discrete', 'NNP'), ('Math', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['J. Discrete Math']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('J.', 'j.'), ('Discrete', 'discret'), ('Math', 'math'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('J.', 'j.'), ('Discrete', 'discret'), ('Math', 'math'), ('.', '.')]

>> Lemmatization: 
 [('J.', 'J.'), ('Discrete', 'Discrete'), ('Math', 'Math'), ('.', '.')]


------------------- Sentence 3 -------------------

29, 321–347 (2014).

>> Tokens are: 
 ['29', ',', '321–347', '(', '2014', ')', '.']

>> Bigrams are: 
 [('29', ','), (',', '321–347'), ('321–347', '('), ('(', '2014'), ('2014', ')'), (')', '.')]

>> Trigrams are: 
 [('29', ',', '321–347'), (',', '321–347', '('), ('321–347', '(', '2014'), ('(', '2014', ')'), ('2014', ')', '.')]

>> POS Tags are: 
 [('29', 'CD'), (',', ','), ('321–347', 'CD'), ('(', '('), ('2014', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('29', '29'), (',', ','), ('321–347', '321–347'), ('(', '('), ('2014', '2014'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('29', '29'), (',', ','), ('321–347', '321–347'), ('(', '('), ('2014', '2014'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('29', '29'), (',', ','), ('321–347', '321–347'), ('(', '('), ('2014', '2014'), (')', ')'), ('.', '.')]


------------------- Sentence 4 -------------------

70.

>> Tokens are: 
 ['70', '.']

>> Bigrams are: 
 [('70', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('70', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('70', '70'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('70', '70'), ('.', '.')]

>> Lemmatization: 
 [('70', '70'), ('.', '.')]


------------------- Sentence 5 -------------------

Montufar, G. F., Pascanu, R., Cho, K. & Bengio, Y.

>> Tokens are: 
 ['Montufar', ',', 'G.', 'F.', ',', 'Pascanu', ',', 'R.', ',', 'Cho', ',', 'K.', '&', 'Bengio', ',', 'Y', '.']

>> Bigrams are: 
 [('Montufar', ','), (',', 'G.'), ('G.', 'F.'), ('F.', ','), (',', 'Pascanu'), ('Pascanu', ','), (',', 'R.'), ('R.', ','), (',', 'Cho'), ('Cho', ','), (',', 'K.'), ('K.', '&'), ('&', 'Bengio'), ('Bengio', ','), (',', 'Y'), ('Y', '.')]

>> Trigrams are: 
 [('Montufar', ',', 'G.'), (',', 'G.', 'F.'), ('G.', 'F.', ','), ('F.', ',', 'Pascanu'), (',', 'Pascanu', ','), ('Pascanu', ',', 'R.'), (',', 'R.', ','), ('R.', ',', 'Cho'), (',', 'Cho', ','), ('Cho', ',', 'K.'), (',', 'K.', '&'), ('K.', '&', 'Bengio'), ('&', 'Bengio', ','), ('Bengio', ',', 'Y'), (',', 'Y', '.')]

>> POS Tags are: 
 [('Montufar', 'NNP'), (',', ','), ('G.', 'NNP'), ('F.', 'NNP'), (',', ','), ('Pascanu', 'NNP'), (',', ','), ('R.', 'NNP'), (',', ','), ('Cho', 'NNP'), (',', ','), ('K.', 'NNP'), ('&', 'CC'), ('Bengio', 'NNP'), (',', ','), ('Y', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Montufar', 'G. F.', 'Pascanu', 'R.', 'Cho', 'K.', 'Bengio', 'Y']

>> Named Entities are: 
 [('GPE', 'Montufar'), ('PERSON', 'Pascanu'), ('PERSON', 'Cho'), ('PERSON', 'Bengio')] 

>> Stemming using Porter Stemmer: 
 [('Montufar', 'montufar'), (',', ','), ('G.', 'g.'), ('F.', 'f.'), (',', ','), ('Pascanu', 'pascanu'), (',', ','), ('R.', 'r.'), (',', ','), ('Cho', 'cho'), (',', ','), ('K.', 'k.'), ('&', '&'), ('Bengio', 'bengio'), (',', ','), ('Y', 'y'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Montufar', 'montufar'), (',', ','), ('G.', 'g.'), ('F.', 'f.'), (',', ','), ('Pascanu', 'pascanu'), (',', ','), ('R.', 'r.'), (',', ','), ('Cho', 'cho'), (',', ','), ('K.', 'k.'), ('&', '&'), ('Bengio', 'bengio'), (',', ','), ('Y', 'y'), ('.', '.')]

>> Lemmatization: 
 [('Montufar', 'Montufar'), (',', ','), ('G.', 'G.'), ('F.', 'F.'), (',', ','), ('Pascanu', 'Pascanu'), (',', ','), ('R.', 'R.'), (',', ','), ('Cho', 'Cho'), (',', ','), ('K.', 'K.'), ('&', '&'), ('Bengio', 'Bengio'), (',', ','), ('Y', 'Y'), ('.', '.')]


------------------- Sentence 6 -------------------

On the number of linear regions

>> Tokens are: 
 ['On', 'number', 'linear', 'regions']

>> Bigrams are: 
 [('On', 'number'), ('number', 'linear'), ('linear', 'regions')]

>> Trigrams are: 
 [('On', 'number', 'linear'), ('number', 'linear', 'regions')]

>> POS Tags are: 
 [('On', 'IN'), ('number', 'NN'), ('linear', 'JJ'), ('regions', 'NNS')]

>> Noun Phrases are: 
 ['number', 'linear regions']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('On', 'on'), ('number', 'number'), ('linear', 'linear'), ('regions', 'region')]

>> Stemming using Snowball Stemmer: 
 [('On', 'on'), ('number', 'number'), ('linear', 'linear'), ('regions', 'region')]

>> Lemmatization: 
 [('On', 'On'), ('number', 'number'), ('linear', 'linear'), ('regions', 'region')]



========================================== PARAGRAPH 321 ===========================================

of deep neural networks. In Proc. Advances in Neural Information Processing  Systems 27 2924–2932 (2014).  

------------------- Sentence 1 -------------------

of deep neural networks.

>> Tokens are: 
 ['deep', 'neural', 'networks', '.']

>> Bigrams are: 
 [('deep', 'neural'), ('neural', 'networks'), ('networks', '.')]

>> Trigrams are: 
 [('deep', 'neural', 'networks'), ('neural', 'networks', '.')]

>> POS Tags are: 
 [('deep', 'JJ'), ('neural', 'JJ'), ('networks', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['deep neural networks']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('deep', 'deep'), ('neural', 'neural'), ('networks', 'network'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('deep', 'deep'), ('neural', 'neural'), ('networks', 'network'), ('.', '.')]

>> Lemmatization: 
 [('deep', 'deep'), ('neural', 'neural'), ('networks', 'network'), ('.', '.')]


------------------- Sentence 2 -------------------

In Proc.

>> Tokens are: 
 ['In', 'Proc', '.']

>> Bigrams are: 
 [('In', 'Proc'), ('Proc', '.')]

>> Trigrams are: 
 [('In', 'Proc', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('Proc', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Proc']

>> Named Entities are: 
 [('GPE', 'Proc')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('Proc', 'proc'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('Proc', 'proc'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('Proc', 'Proc'), ('.', '.')]


------------------- Sentence 3 -------------------

Advances in Neural Information Processing  Systems 27 2924–2932 (2014).

>> Tokens are: 
 ['Advances', 'Neural', 'Information', 'Processing', 'Systems', '27', '2924–2932', '(', '2014', ')', '.']

>> Bigrams are: 
 [('Advances', 'Neural'), ('Neural', 'Information'), ('Information', 'Processing'), ('Processing', 'Systems'), ('Systems', '27'), ('27', '2924–2932'), ('2924–2932', '('), ('(', '2014'), ('2014', ')'), (')', '.')]

>> Trigrams are: 
 [('Advances', 'Neural', 'Information'), ('Neural', 'Information', 'Processing'), ('Information', 'Processing', 'Systems'), ('Processing', 'Systems', '27'), ('Systems', '27', '2924–2932'), ('27', '2924–2932', '('), ('2924–2932', '(', '2014'), ('(', '2014', ')'), ('2014', ')', '.')]

>> POS Tags are: 
 [('Advances', 'NNS'), ('Neural', 'NNP'), ('Information', 'NNP'), ('Processing', 'NNP'), ('Systems', 'NNPS'), ('27', 'CD'), ('2924–2932', 'CD'), ('(', '('), ('2014', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['Advances Neural Information Processing']

>> Named Entities are: 
 [('ORGANIZATION', 'Neural Information Processing Systems')] 

>> Stemming using Porter Stemmer: 
 [('Advances', 'advanc'), ('Neural', 'neural'), ('Information', 'inform'), ('Processing', 'process'), ('Systems', 'system'), ('27', '27'), ('2924–2932', '2924–2932'), ('(', '('), ('2014', '2014'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Advances', 'advanc'), ('Neural', 'neural'), ('Information', 'inform'), ('Processing', 'process'), ('Systems', 'system'), ('27', '27'), ('2924–2932', '2924–2932'), ('(', '('), ('2014', '2014'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Advances', 'Advances'), ('Neural', 'Neural'), ('Information', 'Information'), ('Processing', 'Processing'), ('Systems', 'Systems'), ('27', '27'), ('2924–2932', '2924–2932'), ('(', '('), ('2014', '2014'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 322 ===========================================

71. Bengio, Y., Ducharme, R. & Vincent, P. A neural probabilistic language model. In  Proc. Advances in Neural Information Processing Systems 13 932–938 (2001).  

------------------- Sentence 1 -------------------

71.

>> Tokens are: 
 ['71', '.']

>> Bigrams are: 
 [('71', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('71', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('71', '71'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('71', '71'), ('.', '.')]

>> Lemmatization: 
 [('71', '71'), ('.', '.')]


------------------- Sentence 2 -------------------

Bengio, Y., Ducharme, R. & Vincent, P. A neural probabilistic language model.

>> Tokens are: 
 ['Bengio', ',', 'Y.', ',', 'Ducharme', ',', 'R.', '&', 'Vincent', ',', 'P.', 'A', 'neural', 'probabilistic', 'language', 'model', '.']

>> Bigrams are: 
 [('Bengio', ','), (',', 'Y.'), ('Y.', ','), (',', 'Ducharme'), ('Ducharme', ','), (',', 'R.'), ('R.', '&'), ('&', 'Vincent'), ('Vincent', ','), (',', 'P.'), ('P.', 'A'), ('A', 'neural'), ('neural', 'probabilistic'), ('probabilistic', 'language'), ('language', 'model'), ('model', '.')]

>> Trigrams are: 
 [('Bengio', ',', 'Y.'), (',', 'Y.', ','), ('Y.', ',', 'Ducharme'), (',', 'Ducharme', ','), ('Ducharme', ',', 'R.'), (',', 'R.', '&'), ('R.', '&', 'Vincent'), ('&', 'Vincent', ','), ('Vincent', ',', 'P.'), (',', 'P.', 'A'), ('P.', 'A', 'neural'), ('A', 'neural', 'probabilistic'), ('neural', 'probabilistic', 'language'), ('probabilistic', 'language', 'model'), ('language', 'model', '.')]

>> POS Tags are: 
 [('Bengio', 'NNP'), (',', ','), ('Y.', 'NNP'), (',', ','), ('Ducharme', 'NNP'), (',', ','), ('R.', 'NNP'), ('&', 'CC'), ('Vincent', 'NNP'), (',', ','), ('P.', 'NNP'), ('A', 'NNP'), ('neural', 'JJ'), ('probabilistic', 'JJ'), ('language', 'NN'), ('model', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Bengio', 'Y.', 'Ducharme', 'R.', 'Vincent', 'P. A', 'neural probabilistic language model']

>> Named Entities are: 
 [('GPE', 'Bengio'), ('GPE', 'Ducharme'), ('PERSON', 'Vincent')] 

>> Stemming using Porter Stemmer: 
 [('Bengio', 'bengio'), (',', ','), ('Y.', 'y.'), (',', ','), ('Ducharme', 'ducharm'), (',', ','), ('R.', 'r.'), ('&', '&'), ('Vincent', 'vincent'), (',', ','), ('P.', 'p.'), ('A', 'a'), ('neural', 'neural'), ('probabilistic', 'probabilist'), ('language', 'languag'), ('model', 'model'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Bengio', 'bengio'), (',', ','), ('Y.', 'y.'), (',', ','), ('Ducharme', 'ducharm'), (',', ','), ('R.', 'r.'), ('&', '&'), ('Vincent', 'vincent'), (',', ','), ('P.', 'p.'), ('A', 'a'), ('neural', 'neural'), ('probabilistic', 'probabilist'), ('language', 'languag'), ('model', 'model'), ('.', '.')]

>> Lemmatization: 
 [('Bengio', 'Bengio'), (',', ','), ('Y.', 'Y.'), (',', ','), ('Ducharme', 'Ducharme'), (',', ','), ('R.', 'R.'), ('&', '&'), ('Vincent', 'Vincent'), (',', ','), ('P.', 'P.'), ('A', 'A'), ('neural', 'neural'), ('probabilistic', 'probabilistic'), ('language', 'language'), ('model', 'model'), ('.', '.')]


------------------- Sentence 3 -------------------

In  Proc.

>> Tokens are: 
 ['In', 'Proc', '.']

>> Bigrams are: 
 [('In', 'Proc'), ('Proc', '.')]

>> Trigrams are: 
 [('In', 'Proc', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('Proc', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Proc']

>> Named Entities are: 
 [('GPE', 'Proc')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('Proc', 'proc'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('Proc', 'proc'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('Proc', 'Proc'), ('.', '.')]


------------------- Sentence 4 -------------------

Advances in Neural Information Processing Systems 13 932–938 (2001).

>> Tokens are: 
 ['Advances', 'Neural', 'Information', 'Processing', 'Systems', '13', '932–938', '(', '2001', ')', '.']

>> Bigrams are: 
 [('Advances', 'Neural'), ('Neural', 'Information'), ('Information', 'Processing'), ('Processing', 'Systems'), ('Systems', '13'), ('13', '932–938'), ('932–938', '('), ('(', '2001'), ('2001', ')'), (')', '.')]

>> Trigrams are: 
 [('Advances', 'Neural', 'Information'), ('Neural', 'Information', 'Processing'), ('Information', 'Processing', 'Systems'), ('Processing', 'Systems', '13'), ('Systems', '13', '932–938'), ('13', '932–938', '('), ('932–938', '(', '2001'), ('(', '2001', ')'), ('2001', ')', '.')]

>> POS Tags are: 
 [('Advances', 'NNS'), ('Neural', 'NNP'), ('Information', 'NNP'), ('Processing', 'NNP'), ('Systems', 'NNPS'), ('13', 'CD'), ('932–938', 'CD'), ('(', '('), ('2001', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['Advances Neural Information Processing']

>> Named Entities are: 
 [('ORGANIZATION', 'Neural Information Processing Systems')] 

>> Stemming using Porter Stemmer: 
 [('Advances', 'advanc'), ('Neural', 'neural'), ('Information', 'inform'), ('Processing', 'process'), ('Systems', 'system'), ('13', '13'), ('932–938', '932–938'), ('(', '('), ('2001', '2001'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Advances', 'advanc'), ('Neural', 'neural'), ('Information', 'inform'), ('Processing', 'process'), ('Systems', 'system'), ('13', '13'), ('932–938', '932–938'), ('(', '('), ('2001', '2001'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Advances', 'Advances'), ('Neural', 'Neural'), ('Information', 'Information'), ('Processing', 'Processing'), ('Systems', 'Systems'), ('13', '13'), ('932–938', '932–938'), ('(', '('), ('2001', '2001'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 323 ===========================================

 This paper introduced neural language models, which learn to convert a word  symbol into a word vector or word embedding composed of learned semantic  features in order to predict the next word in a sequence. 

------------------- Sentence 1 -------------------

 This paper introduced neural language models, which learn to convert a word  symbol into a word vector or word embedding composed of learned semantic  features in order to predict the next word in a sequence.

>> Tokens are: 
 ['This', 'paper', 'introduced', 'neural', 'language', 'models', ',', 'learn', 'convert', 'word', 'symbol', 'word', 'vector', 'word', 'embedding', 'composed', 'learned', 'semantic', 'features', 'order', 'predict', 'next', 'word', 'sequence', '.']

>> Bigrams are: 
 [('This', 'paper'), ('paper', 'introduced'), ('introduced', 'neural'), ('neural', 'language'), ('language', 'models'), ('models', ','), (',', 'learn'), ('learn', 'convert'), ('convert', 'word'), ('word', 'symbol'), ('symbol', 'word'), ('word', 'vector'), ('vector', 'word'), ('word', 'embedding'), ('embedding', 'composed'), ('composed', 'learned'), ('learned', 'semantic'), ('semantic', 'features'), ('features', 'order'), ('order', 'predict'), ('predict', 'next'), ('next', 'word'), ('word', 'sequence'), ('sequence', '.')]

>> Trigrams are: 
 [('This', 'paper', 'introduced'), ('paper', 'introduced', 'neural'), ('introduced', 'neural', 'language'), ('neural', 'language', 'models'), ('language', 'models', ','), ('models', ',', 'learn'), (',', 'learn', 'convert'), ('learn', 'convert', 'word'), ('convert', 'word', 'symbol'), ('word', 'symbol', 'word'), ('symbol', 'word', 'vector'), ('word', 'vector', 'word'), ('vector', 'word', 'embedding'), ('word', 'embedding', 'composed'), ('embedding', 'composed', 'learned'), ('composed', 'learned', 'semantic'), ('learned', 'semantic', 'features'), ('semantic', 'features', 'order'), ('features', 'order', 'predict'), ('order', 'predict', 'next'), ('predict', 'next', 'word'), ('next', 'word', 'sequence'), ('word', 'sequence', '.')]

>> POS Tags are: 
 [('This', 'DT'), ('paper', 'NN'), ('introduced', 'VBD'), ('neural', 'JJ'), ('language', 'NN'), ('models', 'NNS'), (',', ','), ('learn', 'VBP'), ('convert', 'JJ'), ('word', 'NN'), ('symbol', 'NN'), ('word', 'NN'), ('vector', 'NN'), ('word', 'NN'), ('embedding', 'VBG'), ('composed', 'VBN'), ('learned', 'VBN'), ('semantic', 'JJ'), ('features', 'NNS'), ('order', 'NN'), ('predict', 'VBP'), ('next', 'JJ'), ('word', 'NN'), ('sequence', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['This paper', 'neural language models', 'convert word symbol word vector word', 'semantic features order', 'next word sequence']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('This', 'thi'), ('paper', 'paper'), ('introduced', 'introduc'), ('neural', 'neural'), ('language', 'languag'), ('models', 'model'), (',', ','), ('learn', 'learn'), ('convert', 'convert'), ('word', 'word'), ('symbol', 'symbol'), ('word', 'word'), ('vector', 'vector'), ('word', 'word'), ('embedding', 'embed'), ('composed', 'compos'), ('learned', 'learn'), ('semantic', 'semant'), ('features', 'featur'), ('order', 'order'), ('predict', 'predict'), ('next', 'next'), ('word', 'word'), ('sequence', 'sequenc'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('This', 'this'), ('paper', 'paper'), ('introduced', 'introduc'), ('neural', 'neural'), ('language', 'languag'), ('models', 'model'), (',', ','), ('learn', 'learn'), ('convert', 'convert'), ('word', 'word'), ('symbol', 'symbol'), ('word', 'word'), ('vector', 'vector'), ('word', 'word'), ('embedding', 'embed'), ('composed', 'compos'), ('learned', 'learn'), ('semantic', 'semant'), ('features', 'featur'), ('order', 'order'), ('predict', 'predict'), ('next', 'next'), ('word', 'word'), ('sequence', 'sequenc'), ('.', '.')]

>> Lemmatization: 
 [('This', 'This'), ('paper', 'paper'), ('introduced', 'introduced'), ('neural', 'neural'), ('language', 'language'), ('models', 'model'), (',', ','), ('learn', 'learn'), ('convert', 'convert'), ('word', 'word'), ('symbol', 'symbol'), ('word', 'word'), ('vector', 'vector'), ('word', 'word'), ('embedding', 'embedding'), ('composed', 'composed'), ('learned', 'learned'), ('semantic', 'semantic'), ('features', 'feature'), ('order', 'order'), ('predict', 'predict'), ('next', 'next'), ('word', 'word'), ('sequence', 'sequence'), ('.', '.')]



========================================== PARAGRAPH 324 ===========================================

72. Cho, K. et al. Learning phrase representations using RNN encoder-decoder  

------------------- Sentence 1 -------------------

72.

>> Tokens are: 
 ['72', '.']

>> Bigrams are: 
 [('72', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('72', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('72', '72'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('72', '72'), ('.', '.')]

>> Lemmatization: 
 [('72', '72'), ('.', '.')]


------------------- Sentence 2 -------------------

Cho, K. et al.

>> Tokens are: 
 ['Cho', ',', 'K.', 'et', 'al', '.']

>> Bigrams are: 
 [('Cho', ','), (',', 'K.'), ('K.', 'et'), ('et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('Cho', ',', 'K.'), (',', 'K.', 'et'), ('K.', 'et', 'al'), ('et', 'al', '.')]

>> POS Tags are: 
 [('Cho', 'NNP'), (',', ','), ('K.', 'NNP'), ('et', 'CC'), ('al', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Cho', 'K.', 'al']

>> Named Entities are: 
 [('GPE', 'Cho')] 

>> Stemming using Porter Stemmer: 
 [('Cho', 'cho'), (',', ','), ('K.', 'k.'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Cho', 'cho'), (',', ','), ('K.', 'k.'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('Cho', 'Cho'), (',', ','), ('K.', 'K.'), ('et', 'et'), ('al', 'al'), ('.', '.')]


------------------- Sentence 3 -------------------

Learning phrase representations using RNN encoder-decoder

>> Tokens are: 
 ['Learning', 'phrase', 'representations', 'using', 'RNN', 'encoder-decoder']

>> Bigrams are: 
 [('Learning', 'phrase'), ('phrase', 'representations'), ('representations', 'using'), ('using', 'RNN'), ('RNN', 'encoder-decoder')]

>> Trigrams are: 
 [('Learning', 'phrase', 'representations'), ('phrase', 'representations', 'using'), ('representations', 'using', 'RNN'), ('using', 'RNN', 'encoder-decoder')]

>> POS Tags are: 
 [('Learning', 'VBG'), ('phrase', 'NN'), ('representations', 'NNS'), ('using', 'VBG'), ('RNN', 'NNP'), ('encoder-decoder', 'NN')]

>> Noun Phrases are: 
 ['phrase representations', 'RNN encoder-decoder']

>> Named Entities are: 
 [('ORGANIZATION', 'RNN')] 

>> Stemming using Porter Stemmer: 
 [('Learning', 'learn'), ('phrase', 'phrase'), ('representations', 'represent'), ('using', 'use'), ('RNN', 'rnn'), ('encoder-decoder', 'encoder-decod')]

>> Stemming using Snowball Stemmer: 
 [('Learning', 'learn'), ('phrase', 'phrase'), ('representations', 'represent'), ('using', 'use'), ('RNN', 'rnn'), ('encoder-decoder', 'encoder-decod')]

>> Lemmatization: 
 [('Learning', 'Learning'), ('phrase', 'phrase'), ('representations', 'representation'), ('using', 'using'), ('RNN', 'RNN'), ('encoder-decoder', 'encoder-decoder')]



========================================== PARAGRAPH 325 ===========================================

2 8  M A Y  2 0 1 5  |  V O L  5 2 1  |  N A T U R E  |  4 4 3 

------------------- Sentence 1 -------------------

2 8  M A Y  2 0 1 5  |  V O L  5 2 1  |  N A T U R E  |  4 4 3

>> Tokens are: 
 ['2', '8', 'M', 'A', 'Y', '2', '0', '1', '5', '|', 'V', 'O', 'L', '5', '2', '1', '|', 'N', 'A', 'T', 'U', 'R', 'E', '|', '4', '4', '3']

>> Bigrams are: 
 [('2', '8'), ('8', 'M'), ('M', 'A'), ('A', 'Y'), ('Y', '2'), ('2', '0'), ('0', '1'), ('1', '5'), ('5', '|'), ('|', 'V'), ('V', 'O'), ('O', 'L'), ('L', '5'), ('5', '2'), ('2', '1'), ('1', '|'), ('|', 'N'), ('N', 'A'), ('A', 'T'), ('T', 'U'), ('U', 'R'), ('R', 'E'), ('E', '|'), ('|', '4'), ('4', '4'), ('4', '3')]

>> Trigrams are: 
 [('2', '8', 'M'), ('8', 'M', 'A'), ('M', 'A', 'Y'), ('A', 'Y', '2'), ('Y', '2', '0'), ('2', '0', '1'), ('0', '1', '5'), ('1', '5', '|'), ('5', '|', 'V'), ('|', 'V', 'O'), ('V', 'O', 'L'), ('O', 'L', '5'), ('L', '5', '2'), ('5', '2', '1'), ('2', '1', '|'), ('1', '|', 'N'), ('|', 'N', 'A'), ('N', 'A', 'T'), ('A', 'T', 'U'), ('T', 'U', 'R'), ('U', 'R', 'E'), ('R', 'E', '|'), ('E', '|', '4'), ('|', '4', '4'), ('4', '4', '3')]

>> POS Tags are: 
 [('2', 'CD'), ('8', 'CD'), ('M', 'NNP'), ('A', 'NNP'), ('Y', 'NNP'), ('2', 'CD'), ('0', 'CD'), ('1', 'CD'), ('5', 'CD'), ('|', 'NN'), ('V', 'NNP'), ('O', 'NNP'), ('L', 'NNP'), ('5', 'CD'), ('2', 'CD'), ('1', 'CD'), ('|', 'NN'), ('N', 'NNP'), ('A', 'NNP'), ('T', 'NNP'), ('U', 'NNP'), ('R', 'NNP'), ('E', 'NNP'), ('|', 'VBD'), ('4', 'CD'), ('4', 'CD'), ('3', 'CD')]

>> Noun Phrases are: 
 ['M A Y', '| V O L', '| N A T U R E']

>> Named Entities are: 
 [('PERSON', 'V O')] 

>> Stemming using Porter Stemmer: 
 [('2', '2'), ('8', '8'), ('M', 'm'), ('A', 'a'), ('Y', 'y'), ('2', '2'), ('0', '0'), ('1', '1'), ('5', '5'), ('|', '|'), ('V', 'v'), ('O', 'o'), ('L', 'l'), ('5', '5'), ('2', '2'), ('1', '1'), ('|', '|'), ('N', 'n'), ('A', 'a'), ('T', 't'), ('U', 'u'), ('R', 'r'), ('E', 'e'), ('|', '|'), ('4', '4'), ('4', '4'), ('3', '3')]

>> Stemming using Snowball Stemmer: 
 [('2', '2'), ('8', '8'), ('M', 'm'), ('A', 'a'), ('Y', 'y'), ('2', '2'), ('0', '0'), ('1', '1'), ('5', '5'), ('|', '|'), ('V', 'v'), ('O', 'o'), ('L', 'l'), ('5', '5'), ('2', '2'), ('1', '1'), ('|', '|'), ('N', 'n'), ('A', 'a'), ('T', 't'), ('U', 'u'), ('R', 'r'), ('E', 'e'), ('|', '|'), ('4', '4'), ('4', '4'), ('3', '3')]

>> Lemmatization: 
 [('2', '2'), ('8', '8'), ('M', 'M'), ('A', 'A'), ('Y', 'Y'), ('2', '2'), ('0', '0'), ('1', '1'), ('5', '5'), ('|', '|'), ('V', 'V'), ('O', 'O'), ('L', 'L'), ('5', '5'), ('2', '2'), ('1', '1'), ('|', '|'), ('N', 'N'), ('A', 'A'), ('T', 'T'), ('U', 'U'), ('R', 'R'), ('E', 'E'), ('|', '|'), ('4', '4'), ('4', '4'), ('3', '3')]



========================================== PARAGRAPH 326 ===========================================

REVIEW INSIGHT 

------------------- Sentence 1 -------------------

REVIEW INSIGHT

>> Tokens are: 
 ['REVIEW', 'INSIGHT']

>> Bigrams are: 
 [('REVIEW', 'INSIGHT')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('REVIEW', 'NNP'), ('INSIGHT', 'NNP')]

>> Noun Phrases are: 
 ['REVIEW INSIGHT']

>> Named Entities are: 
 [('ORGANIZATION', 'REVIEW')] 

>> Stemming using Porter Stemmer: 
 [('REVIEW', 'review'), ('INSIGHT', 'insight')]

>> Stemming using Snowball Stemmer: 
 [('REVIEW', 'review'), ('INSIGHT', 'insight')]

>> Lemmatization: 
 [('REVIEW', 'REVIEW'), ('INSIGHT', 'INSIGHT')]



========================================== PARAGRAPH 327 ===========================================

© 2015 Macmillan Publishers Limited. All rights reserved

------------------- Sentence 1 -------------------

© 2015 Macmillan Publishers Limited.

>> Tokens are: 
 ['©', '2015', 'Macmillan', 'Publishers', 'Limited', '.']

>> Bigrams are: 
 [('©', '2015'), ('2015', 'Macmillan'), ('Macmillan', 'Publishers'), ('Publishers', 'Limited'), ('Limited', '.')]

>> Trigrams are: 
 [('©', '2015', 'Macmillan'), ('2015', 'Macmillan', 'Publishers'), ('Macmillan', 'Publishers', 'Limited'), ('Publishers', 'Limited', '.')]

>> POS Tags are: 
 [('©', 'NN'), ('2015', 'CD'), ('Macmillan', 'NNP'), ('Publishers', 'NNP'), ('Limited', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['©', 'Macmillan Publishers Limited']

>> Named Entities are: 
 [('PERSON', 'Macmillan Publishers Limited')] 

>> Stemming using Porter Stemmer: 
 [('©', '©'), ('2015', '2015'), ('Macmillan', 'macmillan'), ('Publishers', 'publish'), ('Limited', 'limit'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('©', '©'), ('2015', '2015'), ('Macmillan', 'macmillan'), ('Publishers', 'publish'), ('Limited', 'limit'), ('.', '.')]

>> Lemmatization: 
 [('©', '©'), ('2015', '2015'), ('Macmillan', 'Macmillan'), ('Publishers', 'Publishers'), ('Limited', 'Limited'), ('.', '.')]


------------------- Sentence 2 -------------------

All rights reserved

>> Tokens are: 
 ['All', 'rights', 'reserved']

>> Bigrams are: 
 [('All', 'rights'), ('rights', 'reserved')]

>> Trigrams are: 
 [('All', 'rights', 'reserved')]

>> POS Tags are: 
 [('All', 'DT'), ('rights', 'NNS'), ('reserved', 'VBN')]

>> Noun Phrases are: 
 ['All rights']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('All', 'all'), ('rights', 'right'), ('reserved', 'reserv')]

>> Stemming using Snowball Stemmer: 
 [('All', 'all'), ('rights', 'right'), ('reserved', 'reserv')]

>> Lemmatization: 
 [('All', 'All'), ('rights', 'right'), ('reserved', 'reserved')]



========================================== PARAGRAPH 328 ===========================================

for statistical machine translation. In Proc. Conference on Empirical Methods in  Natural Language Processing 1724–1734 (2014).   

------------------- Sentence 1 -------------------

for statistical machine translation.

>> Tokens are: 
 ['statistical', 'machine', 'translation', '.']

>> Bigrams are: 
 [('statistical', 'machine'), ('machine', 'translation'), ('translation', '.')]

>> Trigrams are: 
 [('statistical', 'machine', 'translation'), ('machine', 'translation', '.')]

>> POS Tags are: 
 [('statistical', 'JJ'), ('machine', 'NN'), ('translation', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['statistical machine translation']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('statistical', 'statist'), ('machine', 'machin'), ('translation', 'translat'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('statistical', 'statist'), ('machine', 'machin'), ('translation', 'translat'), ('.', '.')]

>> Lemmatization: 
 [('statistical', 'statistical'), ('machine', 'machine'), ('translation', 'translation'), ('.', '.')]


------------------- Sentence 2 -------------------

In Proc.

>> Tokens are: 
 ['In', 'Proc', '.']

>> Bigrams are: 
 [('In', 'Proc'), ('Proc', '.')]

>> Trigrams are: 
 [('In', 'Proc', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('Proc', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Proc']

>> Named Entities are: 
 [('GPE', 'Proc')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('Proc', 'proc'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('Proc', 'proc'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('Proc', 'Proc'), ('.', '.')]


------------------- Sentence 3 -------------------

Conference on Empirical Methods in  Natural Language Processing 1724–1734 (2014).

>> Tokens are: 
 ['Conference', 'Empirical', 'Methods', 'Natural', 'Language', 'Processing', '1724–1734', '(', '2014', ')', '.']

>> Bigrams are: 
 [('Conference', 'Empirical'), ('Empirical', 'Methods'), ('Methods', 'Natural'), ('Natural', 'Language'), ('Language', 'Processing'), ('Processing', '1724–1734'), ('1724–1734', '('), ('(', '2014'), ('2014', ')'), (')', '.')]

>> Trigrams are: 
 [('Conference', 'Empirical', 'Methods'), ('Empirical', 'Methods', 'Natural'), ('Methods', 'Natural', 'Language'), ('Natural', 'Language', 'Processing'), ('Language', 'Processing', '1724–1734'), ('Processing', '1724–1734', '('), ('1724–1734', '(', '2014'), ('(', '2014', ')'), ('2014', ')', '.')]

>> POS Tags are: 
 [('Conference', 'NNP'), ('Empirical', 'NNP'), ('Methods', 'NNP'), ('Natural', 'NNP'), ('Language', 'NNP'), ('Processing', 'VBG'), ('1724–1734', 'CD'), ('(', '('), ('2014', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['Conference Empirical Methods Natural Language']

>> Named Entities are: 
 [('PERSON', 'Methods Natural Language')] 

>> Stemming using Porter Stemmer: 
 [('Conference', 'confer'), ('Empirical', 'empir'), ('Methods', 'method'), ('Natural', 'natur'), ('Language', 'languag'), ('Processing', 'process'), ('1724–1734', '1724–1734'), ('(', '('), ('2014', '2014'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Conference', 'confer'), ('Empirical', 'empir'), ('Methods', 'method'), ('Natural', 'natur'), ('Language', 'languag'), ('Processing', 'process'), ('1724–1734', '1724–1734'), ('(', '('), ('2014', '2014'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Conference', 'Conference'), ('Empirical', 'Empirical'), ('Methods', 'Methods'), ('Natural', 'Natural'), ('Language', 'Language'), ('Processing', 'Processing'), ('1724–1734', '1724–1734'), ('(', '('), ('2014', '2014'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 329 ===========================================

73. Schwenk, H. Continuous space language models. Computer Speech Lang. 21,  492–518 (2007).  

------------------- Sentence 1 -------------------

73.

>> Tokens are: 
 ['73', '.']

>> Bigrams are: 
 [('73', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('73', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('73', '73'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('73', '73'), ('.', '.')]

>> Lemmatization: 
 [('73', '73'), ('.', '.')]


------------------- Sentence 2 -------------------

Schwenk, H. Continuous space language models.

>> Tokens are: 
 ['Schwenk', ',', 'H.', 'Continuous', 'space', 'language', 'models', '.']

>> Bigrams are: 
 [('Schwenk', ','), (',', 'H.'), ('H.', 'Continuous'), ('Continuous', 'space'), ('space', 'language'), ('language', 'models'), ('models', '.')]

>> Trigrams are: 
 [('Schwenk', ',', 'H.'), (',', 'H.', 'Continuous'), ('H.', 'Continuous', 'space'), ('Continuous', 'space', 'language'), ('space', 'language', 'models'), ('language', 'models', '.')]

>> POS Tags are: 
 [('Schwenk', 'NNP'), (',', ','), ('H.', 'NNP'), ('Continuous', 'NNP'), ('space', 'NN'), ('language', 'NN'), ('models', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['Schwenk', 'H. Continuous space language models']

>> Named Entities are: 
 [('GPE', 'Schwenk')] 

>> Stemming using Porter Stemmer: 
 [('Schwenk', 'schwenk'), (',', ','), ('H.', 'h.'), ('Continuous', 'continu'), ('space', 'space'), ('language', 'languag'), ('models', 'model'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Schwenk', 'schwenk'), (',', ','), ('H.', 'h.'), ('Continuous', 'continu'), ('space', 'space'), ('language', 'languag'), ('models', 'model'), ('.', '.')]

>> Lemmatization: 
 [('Schwenk', 'Schwenk'), (',', ','), ('H.', 'H.'), ('Continuous', 'Continuous'), ('space', 'space'), ('language', 'language'), ('models', 'model'), ('.', '.')]


------------------- Sentence 3 -------------------

Computer Speech Lang.

>> Tokens are: 
 ['Computer', 'Speech', 'Lang', '.']

>> Bigrams are: 
 [('Computer', 'Speech'), ('Speech', 'Lang'), ('Lang', '.')]

>> Trigrams are: 
 [('Computer', 'Speech', 'Lang'), ('Speech', 'Lang', '.')]

>> POS Tags are: 
 [('Computer', 'NNP'), ('Speech', 'NNP'), ('Lang', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Computer Speech Lang']

>> Named Entities are: 
 [('ORGANIZATION', 'Computer'), ('PERSON', 'Speech Lang')] 

>> Stemming using Porter Stemmer: 
 [('Computer', 'comput'), ('Speech', 'speech'), ('Lang', 'lang'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Computer', 'comput'), ('Speech', 'speech'), ('Lang', 'lang'), ('.', '.')]

>> Lemmatization: 
 [('Computer', 'Computer'), ('Speech', 'Speech'), ('Lang', 'Lang'), ('.', '.')]


------------------- Sentence 4 -------------------

21,  492–518 (2007).

>> Tokens are: 
 ['21', ',', '492–518', '(', '2007', ')', '.']

>> Bigrams are: 
 [('21', ','), (',', '492–518'), ('492–518', '('), ('(', '2007'), ('2007', ')'), (')', '.')]

>> Trigrams are: 
 [('21', ',', '492–518'), (',', '492–518', '('), ('492–518', '(', '2007'), ('(', '2007', ')'), ('2007', ')', '.')]

>> POS Tags are: 
 [('21', 'CD'), (',', ','), ('492–518', 'CD'), ('(', '('), ('2007', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('21', '21'), (',', ','), ('492–518', '492–518'), ('(', '('), ('2007', '2007'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('21', '21'), (',', ','), ('492–518', '492–518'), ('(', '('), ('2007', '2007'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('21', '21'), (',', ','), ('492–518', '492–518'), ('(', '('), ('2007', '2007'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 330 ===========================================

74. Socher, R., Lin, C. C-Y., Manning, C. & Ng, A. Y. Parsing natural scenes and  natural language with recursive neural networks. In Proc. International  Conference on Machine Learning 129–136 (2011).  

------------------- Sentence 1 -------------------

74.

>> Tokens are: 
 ['74', '.']

>> Bigrams are: 
 [('74', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('74', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('74', '74'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('74', '74'), ('.', '.')]

>> Lemmatization: 
 [('74', '74'), ('.', '.')]


------------------- Sentence 2 -------------------

Socher, R., Lin, C.

>> Tokens are: 
 ['Socher', ',', 'R.', ',', 'Lin', ',', 'C', '.']

>> Bigrams are: 
 [('Socher', ','), (',', 'R.'), ('R.', ','), (',', 'Lin'), ('Lin', ','), (',', 'C'), ('C', '.')]

>> Trigrams are: 
 [('Socher', ',', 'R.'), (',', 'R.', ','), ('R.', ',', 'Lin'), (',', 'Lin', ','), ('Lin', ',', 'C'), (',', 'C', '.')]

>> POS Tags are: 
 [('Socher', 'NNP'), (',', ','), ('R.', 'NNP'), (',', ','), ('Lin', 'NNP'), (',', ','), ('C', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Socher', 'R.', 'Lin', 'C']

>> Named Entities are: 
 [('GPE', 'Socher'), ('PERSON', 'Lin')] 

>> Stemming using Porter Stemmer: 
 [('Socher', 'socher'), (',', ','), ('R.', 'r.'), (',', ','), ('Lin', 'lin'), (',', ','), ('C', 'c'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Socher', 'socher'), (',', ','), ('R.', 'r.'), (',', ','), ('Lin', 'lin'), (',', ','), ('C', 'c'), ('.', '.')]

>> Lemmatization: 
 [('Socher', 'Socher'), (',', ','), ('R.', 'R.'), (',', ','), ('Lin', 'Lin'), (',', ','), ('C', 'C'), ('.', '.')]


------------------- Sentence 3 -------------------

C-Y., Manning, C. & Ng, A. Y. Parsing natural scenes and  natural language with recursive neural networks.

>> Tokens are: 
 ['C-Y.', ',', 'Manning', ',', 'C.', '&', 'Ng', ',', 'A.', 'Y.', 'Parsing', 'natural', 'scenes', 'natural', 'language', 'recursive', 'neural', 'networks', '.']

>> Bigrams are: 
 [('C-Y.', ','), (',', 'Manning'), ('Manning', ','), (',', 'C.'), ('C.', '&'), ('&', 'Ng'), ('Ng', ','), (',', 'A.'), ('A.', 'Y.'), ('Y.', 'Parsing'), ('Parsing', 'natural'), ('natural', 'scenes'), ('scenes', 'natural'), ('natural', 'language'), ('language', 'recursive'), ('recursive', 'neural'), ('neural', 'networks'), ('networks', '.')]

>> Trigrams are: 
 [('C-Y.', ',', 'Manning'), (',', 'Manning', ','), ('Manning', ',', 'C.'), (',', 'C.', '&'), ('C.', '&', 'Ng'), ('&', 'Ng', ','), ('Ng', ',', 'A.'), (',', 'A.', 'Y.'), ('A.', 'Y.', 'Parsing'), ('Y.', 'Parsing', 'natural'), ('Parsing', 'natural', 'scenes'), ('natural', 'scenes', 'natural'), ('scenes', 'natural', 'language'), ('natural', 'language', 'recursive'), ('language', 'recursive', 'neural'), ('recursive', 'neural', 'networks'), ('neural', 'networks', '.')]

>> POS Tags are: 
 [('C-Y.', 'NNP'), (',', ','), ('Manning', 'NNP'), (',', ','), ('C.', 'NNP'), ('&', 'CC'), ('Ng', 'NNP'), (',', ','), ('A.', 'NNP'), ('Y.', 'NNP'), ('Parsing', 'NNP'), ('natural', 'JJ'), ('scenes', 'NNS'), ('natural', 'JJ'), ('language', 'NN'), ('recursive', 'JJ'), ('neural', 'JJ'), ('networks', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['C-Y.', 'Manning', 'C.', 'Ng', 'A. Y. Parsing', 'natural scenes', 'natural language', 'recursive neural networks']

>> Named Entities are: 
 [('GPE', 'Manning')] 

>> Stemming using Porter Stemmer: 
 [('C-Y.', 'c-y.'), (',', ','), ('Manning', 'man'), (',', ','), ('C.', 'c.'), ('&', '&'), ('Ng', 'ng'), (',', ','), ('A.', 'a.'), ('Y.', 'y.'), ('Parsing', 'pars'), ('natural', 'natur'), ('scenes', 'scene'), ('natural', 'natur'), ('language', 'languag'), ('recursive', 'recurs'), ('neural', 'neural'), ('networks', 'network'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('C-Y.', 'c-y.'), (',', ','), ('Manning', 'man'), (',', ','), ('C.', 'c.'), ('&', '&'), ('Ng', 'ng'), (',', ','), ('A.', 'a.'), ('Y.', 'y.'), ('Parsing', 'pars'), ('natural', 'natur'), ('scenes', 'scene'), ('natural', 'natur'), ('language', 'languag'), ('recursive', 'recurs'), ('neural', 'neural'), ('networks', 'network'), ('.', '.')]

>> Lemmatization: 
 [('C-Y.', 'C-Y.'), (',', ','), ('Manning', 'Manning'), (',', ','), ('C.', 'C.'), ('&', '&'), ('Ng', 'Ng'), (',', ','), ('A.', 'A.'), ('Y.', 'Y.'), ('Parsing', 'Parsing'), ('natural', 'natural'), ('scenes', 'scene'), ('natural', 'natural'), ('language', 'language'), ('recursive', 'recursive'), ('neural', 'neural'), ('networks', 'network'), ('.', '.')]


------------------- Sentence 4 -------------------

In Proc.

>> Tokens are: 
 ['In', 'Proc', '.']

>> Bigrams are: 
 [('In', 'Proc'), ('Proc', '.')]

>> Trigrams are: 
 [('In', 'Proc', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('Proc', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Proc']

>> Named Entities are: 
 [('GPE', 'Proc')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('Proc', 'proc'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('Proc', 'proc'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('Proc', 'Proc'), ('.', '.')]


------------------- Sentence 5 -------------------

International  Conference on Machine Learning 129–136 (2011).

>> Tokens are: 
 ['International', 'Conference', 'Machine', 'Learning', '129–136', '(', '2011', ')', '.']

>> Bigrams are: 
 [('International', 'Conference'), ('Conference', 'Machine'), ('Machine', 'Learning'), ('Learning', '129–136'), ('129–136', '('), ('(', '2011'), ('2011', ')'), (')', '.')]

>> Trigrams are: 
 [('International', 'Conference', 'Machine'), ('Conference', 'Machine', 'Learning'), ('Machine', 'Learning', '129–136'), ('Learning', '129–136', '('), ('129–136', '(', '2011'), ('(', '2011', ')'), ('2011', ')', '.')]

>> POS Tags are: 
 [('International', 'NNP'), ('Conference', 'NNP'), ('Machine', 'NNP'), ('Learning', 'NNP'), ('129–136', 'CD'), ('(', '('), ('2011', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['International Conference Machine Learning']

>> Named Entities are: 
 [('ORGANIZATION', 'International Conference Machine')] 

>> Stemming using Porter Stemmer: 
 [('International', 'intern'), ('Conference', 'confer'), ('Machine', 'machin'), ('Learning', 'learn'), ('129–136', '129–136'), ('(', '('), ('2011', '2011'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('International', 'intern'), ('Conference', 'confer'), ('Machine', 'machin'), ('Learning', 'learn'), ('129–136', '129–136'), ('(', '('), ('2011', '2011'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('International', 'International'), ('Conference', 'Conference'), ('Machine', 'Machine'), ('Learning', 'Learning'), ('129–136', '129–136'), ('(', '('), ('2011', '2011'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 331 ===========================================

75. Mikolov, T., Sutskever, I., Chen, K., Corrado, G. & Dean, J. Distributed  representations of words and phrases and their compositionality. In Proc.  Advances in Neural Information Processing Systems 26 3111–3119 (2013).  

------------------- Sentence 1 -------------------

75.

>> Tokens are: 
 ['75', '.']

>> Bigrams are: 
 [('75', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('75', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('75', '75'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('75', '75'), ('.', '.')]

>> Lemmatization: 
 [('75', '75'), ('.', '.')]


------------------- Sentence 2 -------------------

Mikolov, T., Sutskever, I., Chen, K., Corrado, G. & Dean, J.

>> Tokens are: 
 ['Mikolov', ',', 'T.', ',', 'Sutskever', ',', 'I.', ',', 'Chen', ',', 'K.', ',', 'Corrado', ',', 'G.', '&', 'Dean', ',', 'J', '.']

>> Bigrams are: 
 [('Mikolov', ','), (',', 'T.'), ('T.', ','), (',', 'Sutskever'), ('Sutskever', ','), (',', 'I.'), ('I.', ','), (',', 'Chen'), ('Chen', ','), (',', 'K.'), ('K.', ','), (',', 'Corrado'), ('Corrado', ','), (',', 'G.'), ('G.', '&'), ('&', 'Dean'), ('Dean', ','), (',', 'J'), ('J', '.')]

>> Trigrams are: 
 [('Mikolov', ',', 'T.'), (',', 'T.', ','), ('T.', ',', 'Sutskever'), (',', 'Sutskever', ','), ('Sutskever', ',', 'I.'), (',', 'I.', ','), ('I.', ',', 'Chen'), (',', 'Chen', ','), ('Chen', ',', 'K.'), (',', 'K.', ','), ('K.', ',', 'Corrado'), (',', 'Corrado', ','), ('Corrado', ',', 'G.'), (',', 'G.', '&'), ('G.', '&', 'Dean'), ('&', 'Dean', ','), ('Dean', ',', 'J'), (',', 'J', '.')]

>> POS Tags are: 
 [('Mikolov', 'NNP'), (',', ','), ('T.', 'NNP'), (',', ','), ('Sutskever', 'NNP'), (',', ','), ('I.', 'NNP'), (',', ','), ('Chen', 'NNP'), (',', ','), ('K.', 'NNP'), (',', ','), ('Corrado', 'NNP'), (',', ','), ('G.', 'NNP'), ('&', 'CC'), ('Dean', 'NNP'), (',', ','), ('J', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Mikolov', 'T.', 'Sutskever', 'I.', 'Chen', 'K.', 'Corrado', 'G.', 'Dean', 'J']

>> Named Entities are: 
 [('PERSON', 'Mikolov'), ('GPE', 'Sutskever'), ('GPE', 'Chen'), ('GPE', 'Corrado'), ('GPE', 'Dean')] 

>> Stemming using Porter Stemmer: 
 [('Mikolov', 'mikolov'), (',', ','), ('T.', 't.'), (',', ','), ('Sutskever', 'sutskev'), (',', ','), ('I.', 'i.'), (',', ','), ('Chen', 'chen'), (',', ','), ('K.', 'k.'), (',', ','), ('Corrado', 'corrado'), (',', ','), ('G.', 'g.'), ('&', '&'), ('Dean', 'dean'), (',', ','), ('J', 'j'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Mikolov', 'mikolov'), (',', ','), ('T.', 't.'), (',', ','), ('Sutskever', 'sutskev'), (',', ','), ('I.', 'i.'), (',', ','), ('Chen', 'chen'), (',', ','), ('K.', 'k.'), (',', ','), ('Corrado', 'corrado'), (',', ','), ('G.', 'g.'), ('&', '&'), ('Dean', 'dean'), (',', ','), ('J', 'j'), ('.', '.')]

>> Lemmatization: 
 [('Mikolov', 'Mikolov'), (',', ','), ('T.', 'T.'), (',', ','), ('Sutskever', 'Sutskever'), (',', ','), ('I.', 'I.'), (',', ','), ('Chen', 'Chen'), (',', ','), ('K.', 'K.'), (',', ','), ('Corrado', 'Corrado'), (',', ','), ('G.', 'G.'), ('&', '&'), ('Dean', 'Dean'), (',', ','), ('J', 'J'), ('.', '.')]


------------------- Sentence 3 -------------------

Distributed  representations of words and phrases and their compositionality.

>> Tokens are: 
 ['Distributed', 'representations', 'words', 'phrases', 'compositionality', '.']

>> Bigrams are: 
 [('Distributed', 'representations'), ('representations', 'words'), ('words', 'phrases'), ('phrases', 'compositionality'), ('compositionality', '.')]

>> Trigrams are: 
 [('Distributed', 'representations', 'words'), ('representations', 'words', 'phrases'), ('words', 'phrases', 'compositionality'), ('phrases', 'compositionality', '.')]

>> POS Tags are: 
 [('Distributed', 'VBN'), ('representations', 'NNS'), ('words', 'NNS'), ('phrases', 'NNS'), ('compositionality', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['representations words phrases compositionality']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Distributed', 'distribut'), ('representations', 'represent'), ('words', 'word'), ('phrases', 'phrase'), ('compositionality', 'composition'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Distributed', 'distribut'), ('representations', 'represent'), ('words', 'word'), ('phrases', 'phrase'), ('compositionality', 'composit'), ('.', '.')]

>> Lemmatization: 
 [('Distributed', 'Distributed'), ('representations', 'representation'), ('words', 'word'), ('phrases', 'phrase'), ('compositionality', 'compositionality'), ('.', '.')]


------------------- Sentence 4 -------------------

In Proc.

>> Tokens are: 
 ['In', 'Proc', '.']

>> Bigrams are: 
 [('In', 'Proc'), ('Proc', '.')]

>> Trigrams are: 
 [('In', 'Proc', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('Proc', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Proc']

>> Named Entities are: 
 [('GPE', 'Proc')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('Proc', 'proc'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('Proc', 'proc'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('Proc', 'Proc'), ('.', '.')]


------------------- Sentence 5 -------------------

Advances in Neural Information Processing Systems 26 3111–3119 (2013).

>> Tokens are: 
 ['Advances', 'Neural', 'Information', 'Processing', 'Systems', '26', '3111–3119', '(', '2013', ')', '.']

>> Bigrams are: 
 [('Advances', 'Neural'), ('Neural', 'Information'), ('Information', 'Processing'), ('Processing', 'Systems'), ('Systems', '26'), ('26', '3111–3119'), ('3111–3119', '('), ('(', '2013'), ('2013', ')'), (')', '.')]

>> Trigrams are: 
 [('Advances', 'Neural', 'Information'), ('Neural', 'Information', 'Processing'), ('Information', 'Processing', 'Systems'), ('Processing', 'Systems', '26'), ('Systems', '26', '3111–3119'), ('26', '3111–3119', '('), ('3111–3119', '(', '2013'), ('(', '2013', ')'), ('2013', ')', '.')]

>> POS Tags are: 
 [('Advances', 'NNS'), ('Neural', 'NNP'), ('Information', 'NNP'), ('Processing', 'NNP'), ('Systems', 'NNPS'), ('26', 'CD'), ('3111–3119', 'CD'), ('(', '('), ('2013', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['Advances Neural Information Processing']

>> Named Entities are: 
 [('ORGANIZATION', 'Neural Information Processing Systems')] 

>> Stemming using Porter Stemmer: 
 [('Advances', 'advanc'), ('Neural', 'neural'), ('Information', 'inform'), ('Processing', 'process'), ('Systems', 'system'), ('26', '26'), ('3111–3119', '3111–3119'), ('(', '('), ('2013', '2013'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Advances', 'advanc'), ('Neural', 'neural'), ('Information', 'inform'), ('Processing', 'process'), ('Systems', 'system'), ('26', '26'), ('3111–3119', '3111–3119'), ('(', '('), ('2013', '2013'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Advances', 'Advances'), ('Neural', 'Neural'), ('Information', 'Information'), ('Processing', 'Processing'), ('Systems', 'Systems'), ('26', '26'), ('3111–3119', '3111–3119'), ('(', '('), ('2013', '2013'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 332 ===========================================

76. Bahdanau, D., Cho, K. & Bengio, Y. Neural machine translation by jointly  learning to align and translate. In Proc. International Conference on Learning  Representations http://arxiv.org/abs/1409.0473 (2015). 

------------------- Sentence 1 -------------------

76.

>> Tokens are: 
 ['76', '.']

>> Bigrams are: 
 [('76', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('76', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('76', '76'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('76', '76'), ('.', '.')]

>> Lemmatization: 
 [('76', '76'), ('.', '.')]


------------------- Sentence 2 -------------------

Bahdanau, D., Cho, K. & Bengio, Y. Neural machine translation by jointly  learning to align and translate.

>> Tokens are: 
 ['Bahdanau', ',', 'D.', ',', 'Cho', ',', 'K.', '&', 'Bengio', ',', 'Y.', 'Neural', 'machine', 'translation', 'jointly', 'learning', 'align', 'translate', '.']

>> Bigrams are: 
 [('Bahdanau', ','), (',', 'D.'), ('D.', ','), (',', 'Cho'), ('Cho', ','), (',', 'K.'), ('K.', '&'), ('&', 'Bengio'), ('Bengio', ','), (',', 'Y.'), ('Y.', 'Neural'), ('Neural', 'machine'), ('machine', 'translation'), ('translation', 'jointly'), ('jointly', 'learning'), ('learning', 'align'), ('align', 'translate'), ('translate', '.')]

>> Trigrams are: 
 [('Bahdanau', ',', 'D.'), (',', 'D.', ','), ('D.', ',', 'Cho'), (',', 'Cho', ','), ('Cho', ',', 'K.'), (',', 'K.', '&'), ('K.', '&', 'Bengio'), ('&', 'Bengio', ','), ('Bengio', ',', 'Y.'), (',', 'Y.', 'Neural'), ('Y.', 'Neural', 'machine'), ('Neural', 'machine', 'translation'), ('machine', 'translation', 'jointly'), ('translation', 'jointly', 'learning'), ('jointly', 'learning', 'align'), ('learning', 'align', 'translate'), ('align', 'translate', '.')]

>> POS Tags are: 
 [('Bahdanau', 'NNP'), (',', ','), ('D.', 'NNP'), (',', ','), ('Cho', 'NNP'), (',', ','), ('K.', 'NNP'), ('&', 'CC'), ('Bengio', 'NNP'), (',', ','), ('Y.', 'NNP'), ('Neural', 'NNP'), ('machine', 'NN'), ('translation', 'NN'), ('jointly', 'RB'), ('learning', 'VBG'), ('align', 'JJ'), ('translate', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Bahdanau', 'D.', 'Cho', 'K.', 'Bengio', 'Y. Neural machine translation', 'align translate']

>> Named Entities are: 
 [('GPE', 'Bahdanau'), ('PERSON', 'Cho'), ('PERSON', 'Bengio')] 

>> Stemming using Porter Stemmer: 
 [('Bahdanau', 'bahdanau'), (',', ','), ('D.', 'd.'), (',', ','), ('Cho', 'cho'), (',', ','), ('K.', 'k.'), ('&', '&'), ('Bengio', 'bengio'), (',', ','), ('Y.', 'y.'), ('Neural', 'neural'), ('machine', 'machin'), ('translation', 'translat'), ('jointly', 'jointli'), ('learning', 'learn'), ('align', 'align'), ('translate', 'translat'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Bahdanau', 'bahdanau'), (',', ','), ('D.', 'd.'), (',', ','), ('Cho', 'cho'), (',', ','), ('K.', 'k.'), ('&', '&'), ('Bengio', 'bengio'), (',', ','), ('Y.', 'y.'), ('Neural', 'neural'), ('machine', 'machin'), ('translation', 'translat'), ('jointly', 'joint'), ('learning', 'learn'), ('align', 'align'), ('translate', 'translat'), ('.', '.')]

>> Lemmatization: 
 [('Bahdanau', 'Bahdanau'), (',', ','), ('D.', 'D.'), (',', ','), ('Cho', 'Cho'), (',', ','), ('K.', 'K.'), ('&', '&'), ('Bengio', 'Bengio'), (',', ','), ('Y.', 'Y.'), ('Neural', 'Neural'), ('machine', 'machine'), ('translation', 'translation'), ('jointly', 'jointly'), ('learning', 'learning'), ('align', 'align'), ('translate', 'translate'), ('.', '.')]


------------------- Sentence 3 -------------------

In Proc.

>> Tokens are: 
 ['In', 'Proc', '.']

>> Bigrams are: 
 [('In', 'Proc'), ('Proc', '.')]

>> Trigrams are: 
 [('In', 'Proc', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('Proc', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Proc']

>> Named Entities are: 
 [('GPE', 'Proc')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('Proc', 'proc'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('Proc', 'proc'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('Proc', 'Proc'), ('.', '.')]


------------------- Sentence 4 -------------------

International Conference on Learning  Representations http://arxiv.org/abs/1409.0473 (2015).

>> Tokens are: 
 ['International', 'Conference', 'Learning', 'Representations', 'http', ':', '//arxiv.org/abs/1409.0473', '(', '2015', ')', '.']

>> Bigrams are: 
 [('International', 'Conference'), ('Conference', 'Learning'), ('Learning', 'Representations'), ('Representations', 'http'), ('http', ':'), (':', '//arxiv.org/abs/1409.0473'), ('//arxiv.org/abs/1409.0473', '('), ('(', '2015'), ('2015', ')'), (')', '.')]

>> Trigrams are: 
 [('International', 'Conference', 'Learning'), ('Conference', 'Learning', 'Representations'), ('Learning', 'Representations', 'http'), ('Representations', 'http', ':'), ('http', ':', '//arxiv.org/abs/1409.0473'), (':', '//arxiv.org/abs/1409.0473', '('), ('//arxiv.org/abs/1409.0473', '(', '2015'), ('(', '2015', ')'), ('2015', ')', '.')]

>> POS Tags are: 
 [('International', 'NNP'), ('Conference', 'NNP'), ('Learning', 'NNP'), ('Representations', 'NNP'), ('http', 'NN'), (':', ':'), ('//arxiv.org/abs/1409.0473', 'NN'), ('(', '('), ('2015', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['International Conference Learning Representations http', '//arxiv.org/abs/1409.0473']

>> Named Entities are: 
 [('ORGANIZATION', 'International Conference')] 

>> Stemming using Porter Stemmer: 
 [('International', 'intern'), ('Conference', 'confer'), ('Learning', 'learn'), ('Representations', 'represent'), ('http', 'http'), (':', ':'), ('//arxiv.org/abs/1409.0473', '//arxiv.org/abs/1409.0473'), ('(', '('), ('2015', '2015'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('International', 'intern'), ('Conference', 'confer'), ('Learning', 'learn'), ('Representations', 'represent'), ('http', 'http'), (':', ':'), ('//arxiv.org/abs/1409.0473', '//arxiv.org/abs/1409.0473'), ('(', '('), ('2015', '2015'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('International', 'International'), ('Conference', 'Conference'), ('Learning', 'Learning'), ('Representations', 'Representations'), ('http', 'http'), (':', ':'), ('//arxiv.org/abs/1409.0473', '//arxiv.org/abs/1409.0473'), ('(', '('), ('2015', '2015'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 333 ===========================================

77. Hochreiter, S. Untersuchungen zu dynamischen neuronalen Netzen [in  German] Diploma thesis, T.U. Münich (1991).  

------------------- Sentence 1 -------------------

77.

>> Tokens are: 
 ['77', '.']

>> Bigrams are: 
 [('77', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('77', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('77', '77'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('77', '77'), ('.', '.')]

>> Lemmatization: 
 [('77', '77'), ('.', '.')]


------------------- Sentence 2 -------------------

Hochreiter, S. Untersuchungen zu dynamischen neuronalen Netzen [in  German] Diploma thesis, T.U.

>> Tokens are: 
 ['Hochreiter', ',', 'S.', 'Untersuchungen', 'zu', 'dynamischen', 'neuronalen', 'Netzen', '[', 'German', ']', 'Diploma', 'thesis', ',', 'T.U', '.']

>> Bigrams are: 
 [('Hochreiter', ','), (',', 'S.'), ('S.', 'Untersuchungen'), ('Untersuchungen', 'zu'), ('zu', 'dynamischen'), ('dynamischen', 'neuronalen'), ('neuronalen', 'Netzen'), ('Netzen', '['), ('[', 'German'), ('German', ']'), (']', 'Diploma'), ('Diploma', 'thesis'), ('thesis', ','), (',', 'T.U'), ('T.U', '.')]

>> Trigrams are: 
 [('Hochreiter', ',', 'S.'), (',', 'S.', 'Untersuchungen'), ('S.', 'Untersuchungen', 'zu'), ('Untersuchungen', 'zu', 'dynamischen'), ('zu', 'dynamischen', 'neuronalen'), ('dynamischen', 'neuronalen', 'Netzen'), ('neuronalen', 'Netzen', '['), ('Netzen', '[', 'German'), ('[', 'German', ']'), ('German', ']', 'Diploma'), (']', 'Diploma', 'thesis'), ('Diploma', 'thesis', ','), ('thesis', ',', 'T.U'), (',', 'T.U', '.')]

>> POS Tags are: 
 [('Hochreiter', 'NNP'), (',', ','), ('S.', 'NNP'), ('Untersuchungen', 'NNP'), ('zu', 'NNP'), ('dynamischen', 'NN'), ('neuronalen', 'FW'), ('Netzen', 'NNP'), ('[', 'JJ'), ('German', 'NNP'), (']', 'NNP'), ('Diploma', 'NNP'), ('thesis', 'NN'), (',', ','), ('T.U', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Hochreiter', 'S. Untersuchungen zu dynamischen', 'Netzen', '[ German ] Diploma thesis', 'T.U']

>> Named Entities are: 
 [('PERSON', 'Netzen'), ('PERSON', 'German')] 

>> Stemming using Porter Stemmer: 
 [('Hochreiter', 'hochreit'), (',', ','), ('S.', 's.'), ('Untersuchungen', 'untersuchungen'), ('zu', 'zu'), ('dynamischen', 'dynamischen'), ('neuronalen', 'neuronalen'), ('Netzen', 'netzen'), ('[', '['), ('German', 'german'), (']', ']'), ('Diploma', 'diploma'), ('thesis', 'thesi'), (',', ','), ('T.U', 't.u'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Hochreiter', 'hochreit'), (',', ','), ('S.', 's.'), ('Untersuchungen', 'untersuchungen'), ('zu', 'zu'), ('dynamischen', 'dynamischen'), ('neuronalen', 'neuronalen'), ('Netzen', 'netzen'), ('[', '['), ('German', 'german'), (']', ']'), ('Diploma', 'diploma'), ('thesis', 'thesi'), (',', ','), ('T.U', 't.u'), ('.', '.')]

>> Lemmatization: 
 [('Hochreiter', 'Hochreiter'), (',', ','), ('S.', 'S.'), ('Untersuchungen', 'Untersuchungen'), ('zu', 'zu'), ('dynamischen', 'dynamischen'), ('neuronalen', 'neuronalen'), ('Netzen', 'Netzen'), ('[', '['), ('German', 'German'), (']', ']'), ('Diploma', 'Diploma'), ('thesis', 'thesis'), (',', ','), ('T.U', 'T.U'), ('.', '.')]


------------------- Sentence 3 -------------------

Münich (1991).

>> Tokens are: 
 ['Münich', '(', '1991', ')', '.']

>> Bigrams are: 
 [('Münich', '('), ('(', '1991'), ('1991', ')'), (')', '.')]

>> Trigrams are: 
 [('Münich', '(', '1991'), ('(', '1991', ')'), ('1991', ')', '.')]

>> POS Tags are: 
 [('Münich', 'NNP'), ('(', '('), ('1991', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['Münich']

>> Named Entities are: 
 [('GPE', 'Münich')] 

>> Stemming using Porter Stemmer: 
 [('Münich', 'münich'), ('(', '('), ('1991', '1991'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Münich', 'münich'), ('(', '('), ('1991', '1991'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Münich', 'Münich'), ('(', '('), ('1991', '1991'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 334 ===========================================

78. Bengio, Y., Simard, P. & Frasconi, P. Learning long-term dependencies with  gradient descent is difficult. IEEE Trans. Neural Networks 5, 157–166 (1994).  

------------------- Sentence 1 -------------------

78.

>> Tokens are: 
 ['78', '.']

>> Bigrams are: 
 [('78', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('78', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('78', '78'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('78', '78'), ('.', '.')]

>> Lemmatization: 
 [('78', '78'), ('.', '.')]


------------------- Sentence 2 -------------------

Bengio, Y., Simard, P. & Frasconi, P. Learning long-term dependencies with  gradient descent is difficult.

>> Tokens are: 
 ['Bengio', ',', 'Y.', ',', 'Simard', ',', 'P.', '&', 'Frasconi', ',', 'P.', 'Learning', 'long-term', 'dependencies', 'gradient', 'descent', 'difficult', '.']

>> Bigrams are: 
 [('Bengio', ','), (',', 'Y.'), ('Y.', ','), (',', 'Simard'), ('Simard', ','), (',', 'P.'), ('P.', '&'), ('&', 'Frasconi'), ('Frasconi', ','), (',', 'P.'), ('P.', 'Learning'), ('Learning', 'long-term'), ('long-term', 'dependencies'), ('dependencies', 'gradient'), ('gradient', 'descent'), ('descent', 'difficult'), ('difficult', '.')]

>> Trigrams are: 
 [('Bengio', ',', 'Y.'), (',', 'Y.', ','), ('Y.', ',', 'Simard'), (',', 'Simard', ','), ('Simard', ',', 'P.'), (',', 'P.', '&'), ('P.', '&', 'Frasconi'), ('&', 'Frasconi', ','), ('Frasconi', ',', 'P.'), (',', 'P.', 'Learning'), ('P.', 'Learning', 'long-term'), ('Learning', 'long-term', 'dependencies'), ('long-term', 'dependencies', 'gradient'), ('dependencies', 'gradient', 'descent'), ('gradient', 'descent', 'difficult'), ('descent', 'difficult', '.')]

>> POS Tags are: 
 [('Bengio', 'NNP'), (',', ','), ('Y.', 'NNP'), (',', ','), ('Simard', 'NNP'), (',', ','), ('P.', 'NNP'), ('&', 'CC'), ('Frasconi', 'NNP'), (',', ','), ('P.', 'NNP'), ('Learning', 'NNP'), ('long-term', 'JJ'), ('dependencies', 'NNS'), ('gradient', 'JJ'), ('descent', 'NN'), ('difficult', 'JJ'), ('.', '.')]

>> Noun Phrases are: 
 ['Bengio', 'Y.', 'Simard', 'P.', 'Frasconi', 'P. Learning', 'long-term dependencies', 'gradient descent']

>> Named Entities are: 
 [('GPE', 'Bengio'), ('PERSON', 'Simard'), ('GPE', 'Frasconi')] 

>> Stemming using Porter Stemmer: 
 [('Bengio', 'bengio'), (',', ','), ('Y.', 'y.'), (',', ','), ('Simard', 'simard'), (',', ','), ('P.', 'p.'), ('&', '&'), ('Frasconi', 'frasconi'), (',', ','), ('P.', 'p.'), ('Learning', 'learn'), ('long-term', 'long-term'), ('dependencies', 'depend'), ('gradient', 'gradient'), ('descent', 'descent'), ('difficult', 'difficult'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Bengio', 'bengio'), (',', ','), ('Y.', 'y.'), (',', ','), ('Simard', 'simard'), (',', ','), ('P.', 'p.'), ('&', '&'), ('Frasconi', 'frasconi'), (',', ','), ('P.', 'p.'), ('Learning', 'learn'), ('long-term', 'long-term'), ('dependencies', 'depend'), ('gradient', 'gradient'), ('descent', 'descent'), ('difficult', 'difficult'), ('.', '.')]

>> Lemmatization: 
 [('Bengio', 'Bengio'), (',', ','), ('Y.', 'Y.'), (',', ','), ('Simard', 'Simard'), (',', ','), ('P.', 'P.'), ('&', '&'), ('Frasconi', 'Frasconi'), (',', ','), ('P.', 'P.'), ('Learning', 'Learning'), ('long-term', 'long-term'), ('dependencies', 'dependency'), ('gradient', 'gradient'), ('descent', 'descent'), ('difficult', 'difficult'), ('.', '.')]


------------------- Sentence 3 -------------------

IEEE Trans.

>> Tokens are: 
 ['IEEE', 'Trans', '.']

>> Bigrams are: 
 [('IEEE', 'Trans'), ('Trans', '.')]

>> Trigrams are: 
 [('IEEE', 'Trans', '.')]

>> POS Tags are: 
 [('IEEE', 'NNP'), ('Trans', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['IEEE Trans']

>> Named Entities are: 
 [('ORGANIZATION', 'IEEE Trans')] 

>> Stemming using Porter Stemmer: 
 [('IEEE', 'ieee'), ('Trans', 'tran'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('IEEE', 'ieee'), ('Trans', 'tran'), ('.', '.')]

>> Lemmatization: 
 [('IEEE', 'IEEE'), ('Trans', 'Trans'), ('.', '.')]


------------------- Sentence 4 -------------------

Neural Networks 5, 157–166 (1994).

>> Tokens are: 
 ['Neural', 'Networks', '5', ',', '157–166', '(', '1994', ')', '.']

>> Bigrams are: 
 [('Neural', 'Networks'), ('Networks', '5'), ('5', ','), (',', '157–166'), ('157–166', '('), ('(', '1994'), ('1994', ')'), (')', '.')]

>> Trigrams are: 
 [('Neural', 'Networks', '5'), ('Networks', '5', ','), ('5', ',', '157–166'), (',', '157–166', '('), ('157–166', '(', '1994'), ('(', '1994', ')'), ('1994', ')', '.')]

>> POS Tags are: 
 [('Neural', 'JJ'), ('Networks', 'NNP'), ('5', 'CD'), (',', ','), ('157–166', 'CD'), ('(', '('), ('1994', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['Neural Networks']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Neural', 'neural'), ('Networks', 'network'), ('5', '5'), (',', ','), ('157–166', '157–166'), ('(', '('), ('1994', '1994'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Neural', 'neural'), ('Networks', 'network'), ('5', '5'), (',', ','), ('157–166', '157–166'), ('(', '('), ('1994', '1994'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Neural', 'Neural'), ('Networks', 'Networks'), ('5', '5'), (',', ','), ('157–166', '157–166'), ('(', '('), ('1994', '1994'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 335 ===========================================

79. Hochreiter, S. & Schmidhuber, J. Long short-term memory. Neural Comput. 9,  1735–1780 (1997).  

------------------- Sentence 1 -------------------

79.

>> Tokens are: 
 ['79', '.']

>> Bigrams are: 
 [('79', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('79', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('79', '79'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('79', '79'), ('.', '.')]

>> Lemmatization: 
 [('79', '79'), ('.', '.')]


------------------- Sentence 2 -------------------

Hochreiter, S. & Schmidhuber, J.

>> Tokens are: 
 ['Hochreiter', ',', 'S.', '&', 'Schmidhuber', ',', 'J', '.']

>> Bigrams are: 
 [('Hochreiter', ','), (',', 'S.'), ('S.', '&'), ('&', 'Schmidhuber'), ('Schmidhuber', ','), (',', 'J'), ('J', '.')]

>> Trigrams are: 
 [('Hochreiter', ',', 'S.'), (',', 'S.', '&'), ('S.', '&', 'Schmidhuber'), ('&', 'Schmidhuber', ','), ('Schmidhuber', ',', 'J'), (',', 'J', '.')]

>> POS Tags are: 
 [('Hochreiter', 'NNP'), (',', ','), ('S.', 'NNP'), ('&', 'CC'), ('Schmidhuber', 'NNP'), (',', ','), ('J', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Hochreiter', 'S.', 'Schmidhuber', 'J']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Hochreiter', 'hochreit'), (',', ','), ('S.', 's.'), ('&', '&'), ('Schmidhuber', 'schmidhub'), (',', ','), ('J', 'j'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Hochreiter', 'hochreit'), (',', ','), ('S.', 's.'), ('&', '&'), ('Schmidhuber', 'schmidhub'), (',', ','), ('J', 'j'), ('.', '.')]

>> Lemmatization: 
 [('Hochreiter', 'Hochreiter'), (',', ','), ('S.', 'S.'), ('&', '&'), ('Schmidhuber', 'Schmidhuber'), (',', ','), ('J', 'J'), ('.', '.')]


------------------- Sentence 3 -------------------

Long short-term memory.

>> Tokens are: 
 ['Long', 'short-term', 'memory', '.']

>> Bigrams are: 
 [('Long', 'short-term'), ('short-term', 'memory'), ('memory', '.')]

>> Trigrams are: 
 [('Long', 'short-term', 'memory'), ('short-term', 'memory', '.')]

>> POS Tags are: 
 [('Long', 'RB'), ('short-term', 'JJ'), ('memory', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['short-term memory']

>> Named Entities are: 
 [('GPE', 'Long')] 

>> Stemming using Porter Stemmer: 
 [('Long', 'long'), ('short-term', 'short-term'), ('memory', 'memori'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Long', 'long'), ('short-term', 'short-term'), ('memory', 'memori'), ('.', '.')]

>> Lemmatization: 
 [('Long', 'Long'), ('short-term', 'short-term'), ('memory', 'memory'), ('.', '.')]


------------------- Sentence 4 -------------------

Neural Comput.

>> Tokens are: 
 ['Neural', 'Comput', '.']

>> Bigrams are: 
 [('Neural', 'Comput'), ('Comput', '.')]

>> Trigrams are: 
 [('Neural', 'Comput', '.')]

>> POS Tags are: 
 [('Neural', 'JJ'), ('Comput', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Neural Comput']

>> Named Entities are: 
 [('ORGANIZATION', 'Comput')] 

>> Stemming using Porter Stemmer: 
 [('Neural', 'neural'), ('Comput', 'comput'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Neural', 'neural'), ('Comput', 'comput'), ('.', '.')]

>> Lemmatization: 
 [('Neural', 'Neural'), ('Comput', 'Comput'), ('.', '.')]


------------------- Sentence 5 -------------------

9,  1735–1780 (1997).

>> Tokens are: 
 ['9', ',', '1735–1780', '(', '1997', ')', '.']

>> Bigrams are: 
 [('9', ','), (',', '1735–1780'), ('1735–1780', '('), ('(', '1997'), ('1997', ')'), (')', '.')]

>> Trigrams are: 
 [('9', ',', '1735–1780'), (',', '1735–1780', '('), ('1735–1780', '(', '1997'), ('(', '1997', ')'), ('1997', ')', '.')]

>> POS Tags are: 
 [('9', 'CD'), (',', ','), ('1735–1780', 'CD'), ('(', '('), ('1997', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('9', '9'), (',', ','), ('1735–1780', '1735–1780'), ('(', '('), ('1997', '1997'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('9', '9'), (',', ','), ('1735–1780', '1735–1780'), ('(', '('), ('1997', '1997'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('9', '9'), (',', ','), ('1735–1780', '1735–1780'), ('(', '('), ('1997', '1997'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 336 ===========================================

 This paper introduced LSTM recurrent networks, which have become a crucial  ingredient in recent advances with recurrent networks because they are good  at learning long-range dependencies.  

------------------- Sentence 1 -------------------

 This paper introduced LSTM recurrent networks, which have become a crucial  ingredient in recent advances with recurrent networks because they are good  at learning long-range dependencies.

>> Tokens are: 
 ['This', 'paper', 'introduced', 'LSTM', 'recurrent', 'networks', ',', 'become', 'crucial', 'ingredient', 'recent', 'advances', 'recurrent', 'networks', 'good', 'learning', 'long-range', 'dependencies', '.']

>> Bigrams are: 
 [('This', 'paper'), ('paper', 'introduced'), ('introduced', 'LSTM'), ('LSTM', 'recurrent'), ('recurrent', 'networks'), ('networks', ','), (',', 'become'), ('become', 'crucial'), ('crucial', 'ingredient'), ('ingredient', 'recent'), ('recent', 'advances'), ('advances', 'recurrent'), ('recurrent', 'networks'), ('networks', 'good'), ('good', 'learning'), ('learning', 'long-range'), ('long-range', 'dependencies'), ('dependencies', '.')]

>> Trigrams are: 
 [('This', 'paper', 'introduced'), ('paper', 'introduced', 'LSTM'), ('introduced', 'LSTM', 'recurrent'), ('LSTM', 'recurrent', 'networks'), ('recurrent', 'networks', ','), ('networks', ',', 'become'), (',', 'become', 'crucial'), ('become', 'crucial', 'ingredient'), ('crucial', 'ingredient', 'recent'), ('ingredient', 'recent', 'advances'), ('recent', 'advances', 'recurrent'), ('advances', 'recurrent', 'networks'), ('recurrent', 'networks', 'good'), ('networks', 'good', 'learning'), ('good', 'learning', 'long-range'), ('learning', 'long-range', 'dependencies'), ('long-range', 'dependencies', '.')]

>> POS Tags are: 
 [('This', 'DT'), ('paper', 'NN'), ('introduced', 'VBD'), ('LSTM', 'NNP'), ('recurrent', 'NN'), ('networks', 'NNS'), (',', ','), ('become', 'VBP'), ('crucial', 'JJ'), ('ingredient', 'JJ'), ('recent', 'JJ'), ('advances', 'NNS'), ('recurrent', 'JJ'), ('networks', 'RB'), ('good', 'JJ'), ('learning', 'VBG'), ('long-range', 'JJ'), ('dependencies', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['This paper', 'LSTM recurrent networks', 'crucial ingredient recent advances', 'long-range dependencies']

>> Named Entities are: 
 [('ORGANIZATION', 'LSTM')] 

>> Stemming using Porter Stemmer: 
 [('This', 'thi'), ('paper', 'paper'), ('introduced', 'introduc'), ('LSTM', 'lstm'), ('recurrent', 'recurr'), ('networks', 'network'), (',', ','), ('become', 'becom'), ('crucial', 'crucial'), ('ingredient', 'ingredi'), ('recent', 'recent'), ('advances', 'advanc'), ('recurrent', 'recurr'), ('networks', 'network'), ('good', 'good'), ('learning', 'learn'), ('long-range', 'long-rang'), ('dependencies', 'depend'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('This', 'this'), ('paper', 'paper'), ('introduced', 'introduc'), ('LSTM', 'lstm'), ('recurrent', 'recurr'), ('networks', 'network'), (',', ','), ('become', 'becom'), ('crucial', 'crucial'), ('ingredient', 'ingredi'), ('recent', 'recent'), ('advances', 'advanc'), ('recurrent', 'recurr'), ('networks', 'network'), ('good', 'good'), ('learning', 'learn'), ('long-range', 'long-rang'), ('dependencies', 'depend'), ('.', '.')]

>> Lemmatization: 
 [('This', 'This'), ('paper', 'paper'), ('introduced', 'introduced'), ('LSTM', 'LSTM'), ('recurrent', 'recurrent'), ('networks', 'network'), (',', ','), ('become', 'become'), ('crucial', 'crucial'), ('ingredient', 'ingredient'), ('recent', 'recent'), ('advances', 'advance'), ('recurrent', 'recurrent'), ('networks', 'network'), ('good', 'good'), ('learning', 'learning'), ('long-range', 'long-range'), ('dependencies', 'dependency'), ('.', '.')]



========================================== PARAGRAPH 337 ===========================================

80. ElHihi, S. & Bengio, Y. Hierarchical recurrent neural networks for long-term  dependencies. In Proc. Advances in Neural Information Processing Systems 8  http://papers.nips.cc/paper/1102-hierarchical-recurrent-neural-networks-for- long-term-dependencies (1995).  

------------------- Sentence 1 -------------------

80.

>> Tokens are: 
 ['80', '.']

>> Bigrams are: 
 [('80', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('80', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('80', '80'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('80', '80'), ('.', '.')]

>> Lemmatization: 
 [('80', '80'), ('.', '.')]


------------------- Sentence 2 -------------------

ElHihi, S. & Bengio, Y. Hierarchical recurrent neural networks for long-term  dependencies.

>> Tokens are: 
 ['ElHihi', ',', 'S.', '&', 'Bengio', ',', 'Y.', 'Hierarchical', 'recurrent', 'neural', 'networks', 'long-term', 'dependencies', '.']

>> Bigrams are: 
 [('ElHihi', ','), (',', 'S.'), ('S.', '&'), ('&', 'Bengio'), ('Bengio', ','), (',', 'Y.'), ('Y.', 'Hierarchical'), ('Hierarchical', 'recurrent'), ('recurrent', 'neural'), ('neural', 'networks'), ('networks', 'long-term'), ('long-term', 'dependencies'), ('dependencies', '.')]

>> Trigrams are: 
 [('ElHihi', ',', 'S.'), (',', 'S.', '&'), ('S.', '&', 'Bengio'), ('&', 'Bengio', ','), ('Bengio', ',', 'Y.'), (',', 'Y.', 'Hierarchical'), ('Y.', 'Hierarchical', 'recurrent'), ('Hierarchical', 'recurrent', 'neural'), ('recurrent', 'neural', 'networks'), ('neural', 'networks', 'long-term'), ('networks', 'long-term', 'dependencies'), ('long-term', 'dependencies', '.')]

>> POS Tags are: 
 [('ElHihi', 'NNP'), (',', ','), ('S.', 'NNP'), ('&', 'CC'), ('Bengio', 'NNP'), (',', ','), ('Y.', 'NNP'), ('Hierarchical', 'NNP'), ('recurrent', 'NN'), ('neural', 'JJ'), ('networks', 'NNS'), ('long-term', 'JJ'), ('dependencies', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['ElHihi', 'S.', 'Bengio', 'Y. Hierarchical recurrent', 'neural networks', 'long-term dependencies']

>> Named Entities are: 
 [('GPE', 'ElHihi'), ('PERSON', 'Bengio')] 

>> Stemming using Porter Stemmer: 
 [('ElHihi', 'elhihi'), (',', ','), ('S.', 's.'), ('&', '&'), ('Bengio', 'bengio'), (',', ','), ('Y.', 'y.'), ('Hierarchical', 'hierarch'), ('recurrent', 'recurr'), ('neural', 'neural'), ('networks', 'network'), ('long-term', 'long-term'), ('dependencies', 'depend'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('ElHihi', 'elhihi'), (',', ','), ('S.', 's.'), ('&', '&'), ('Bengio', 'bengio'), (',', ','), ('Y.', 'y.'), ('Hierarchical', 'hierarch'), ('recurrent', 'recurr'), ('neural', 'neural'), ('networks', 'network'), ('long-term', 'long-term'), ('dependencies', 'depend'), ('.', '.')]

>> Lemmatization: 
 [('ElHihi', 'ElHihi'), (',', ','), ('S.', 'S.'), ('&', '&'), ('Bengio', 'Bengio'), (',', ','), ('Y.', 'Y.'), ('Hierarchical', 'Hierarchical'), ('recurrent', 'recurrent'), ('neural', 'neural'), ('networks', 'network'), ('long-term', 'long-term'), ('dependencies', 'dependency'), ('.', '.')]


------------------- Sentence 3 -------------------

In Proc.

>> Tokens are: 
 ['In', 'Proc', '.']

>> Bigrams are: 
 [('In', 'Proc'), ('Proc', '.')]

>> Trigrams are: 
 [('In', 'Proc', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('Proc', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Proc']

>> Named Entities are: 
 [('GPE', 'Proc')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('Proc', 'proc'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('Proc', 'proc'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('Proc', 'Proc'), ('.', '.')]


------------------- Sentence 4 -------------------

Advances in Neural Information Processing Systems 8  http://papers.nips.cc/paper/1102-hierarchical-recurrent-neural-networks-for- long-term-dependencies (1995).

>> Tokens are: 
 ['Advances', 'Neural', 'Information', 'Processing', 'Systems', '8', 'http', ':', '//papers.nips.cc/paper/1102-hierarchical-recurrent-neural-networks-for-', 'long-term-dependencies', '(', '1995', ')', '.']

>> Bigrams are: 
 [('Advances', 'Neural'), ('Neural', 'Information'), ('Information', 'Processing'), ('Processing', 'Systems'), ('Systems', '8'), ('8', 'http'), ('http', ':'), (':', '//papers.nips.cc/paper/1102-hierarchical-recurrent-neural-networks-for-'), ('//papers.nips.cc/paper/1102-hierarchical-recurrent-neural-networks-for-', 'long-term-dependencies'), ('long-term-dependencies', '('), ('(', '1995'), ('1995', ')'), (')', '.')]

>> Trigrams are: 
 [('Advances', 'Neural', 'Information'), ('Neural', 'Information', 'Processing'), ('Information', 'Processing', 'Systems'), ('Processing', 'Systems', '8'), ('Systems', '8', 'http'), ('8', 'http', ':'), ('http', ':', '//papers.nips.cc/paper/1102-hierarchical-recurrent-neural-networks-for-'), (':', '//papers.nips.cc/paper/1102-hierarchical-recurrent-neural-networks-for-', 'long-term-dependencies'), ('//papers.nips.cc/paper/1102-hierarchical-recurrent-neural-networks-for-', 'long-term-dependencies', '('), ('long-term-dependencies', '(', '1995'), ('(', '1995', ')'), ('1995', ')', '.')]

>> POS Tags are: 
 [('Advances', 'NNS'), ('Neural', 'NNP'), ('Information', 'NNP'), ('Processing', 'NNP'), ('Systems', 'NNPS'), ('8', 'CD'), ('http', 'NN'), (':', ':'), ('//papers.nips.cc/paper/1102-hierarchical-recurrent-neural-networks-for-', 'JJ'), ('long-term-dependencies', 'NNS'), ('(', '('), ('1995', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['Advances Neural Information Processing', 'http', '//papers.nips.cc/paper/1102-hierarchical-recurrent-neural-networks-for- long-term-dependencies']

>> Named Entities are: 
 [('ORGANIZATION', 'Neural Information Processing Systems')] 

>> Stemming using Porter Stemmer: 
 [('Advances', 'advanc'), ('Neural', 'neural'), ('Information', 'inform'), ('Processing', 'process'), ('Systems', 'system'), ('8', '8'), ('http', 'http'), (':', ':'), ('//papers.nips.cc/paper/1102-hierarchical-recurrent-neural-networks-for-', '//papers.nips.cc/paper/1102-hierarchical-recurrent-neural-networks-for-'), ('long-term-dependencies', 'long-term-depend'), ('(', '('), ('1995', '1995'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Advances', 'advanc'), ('Neural', 'neural'), ('Information', 'inform'), ('Processing', 'process'), ('Systems', 'system'), ('8', '8'), ('http', 'http'), (':', ':'), ('//papers.nips.cc/paper/1102-hierarchical-recurrent-neural-networks-for-', '//papers.nips.cc/paper/1102-hierarchical-recurrent-neural-networks-for-'), ('long-term-dependencies', 'long-term-depend'), ('(', '('), ('1995', '1995'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Advances', 'Advances'), ('Neural', 'Neural'), ('Information', 'Information'), ('Processing', 'Processing'), ('Systems', 'Systems'), ('8', '8'), ('http', 'http'), (':', ':'), ('//papers.nips.cc/paper/1102-hierarchical-recurrent-neural-networks-for-', '//papers.nips.cc/paper/1102-hierarchical-recurrent-neural-networks-for-'), ('long-term-dependencies', 'long-term-dependencies'), ('(', '('), ('1995', '1995'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 338 ===========================================

81. Sutskever, I. Training Recurrent Neural Networks. PhD thesis, Univ. Toronto  (2012).  

------------------- Sentence 1 -------------------

81.

>> Tokens are: 
 ['81', '.']

>> Bigrams are: 
 [('81', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('81', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('81', '81'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('81', '81'), ('.', '.')]

>> Lemmatization: 
 [('81', '81'), ('.', '.')]


------------------- Sentence 2 -------------------

Sutskever, I.

>> Tokens are: 
 ['Sutskever', ',', 'I', '.']

>> Bigrams are: 
 [('Sutskever', ','), (',', 'I'), ('I', '.')]

>> Trigrams are: 
 [('Sutskever', ',', 'I'), (',', 'I', '.')]

>> POS Tags are: 
 [('Sutskever', 'NNP'), (',', ','), ('I', 'PRP'), ('.', '.')]

>> Noun Phrases are: 
 ['Sutskever']

>> Named Entities are: 
 [('GPE', 'Sutskever')] 

>> Stemming using Porter Stemmer: 
 [('Sutskever', 'sutskev'), (',', ','), ('I', 'i'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Sutskever', 'sutskev'), (',', ','), ('I', 'i'), ('.', '.')]

>> Lemmatization: 
 [('Sutskever', 'Sutskever'), (',', ','), ('I', 'I'), ('.', '.')]


------------------- Sentence 3 -------------------

Training Recurrent Neural Networks.

>> Tokens are: 
 ['Training', 'Recurrent', 'Neural', 'Networks', '.']

>> Bigrams are: 
 [('Training', 'Recurrent'), ('Recurrent', 'Neural'), ('Neural', 'Networks'), ('Networks', '.')]

>> Trigrams are: 
 [('Training', 'Recurrent', 'Neural'), ('Recurrent', 'Neural', 'Networks'), ('Neural', 'Networks', '.')]

>> POS Tags are: 
 [('Training', 'VBG'), ('Recurrent', 'NNP'), ('Neural', 'NNP'), ('Networks', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Recurrent Neural Networks']

>> Named Entities are: 
 [('PERSON', 'Recurrent Neural Networks')] 

>> Stemming using Porter Stemmer: 
 [('Training', 'train'), ('Recurrent', 'recurr'), ('Neural', 'neural'), ('Networks', 'network'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Training', 'train'), ('Recurrent', 'recurr'), ('Neural', 'neural'), ('Networks', 'network'), ('.', '.')]

>> Lemmatization: 
 [('Training', 'Training'), ('Recurrent', 'Recurrent'), ('Neural', 'Neural'), ('Networks', 'Networks'), ('.', '.')]


------------------- Sentence 4 -------------------

PhD thesis, Univ.

>> Tokens are: 
 ['PhD', 'thesis', ',', 'Univ', '.']

>> Bigrams are: 
 [('PhD', 'thesis'), ('thesis', ','), (',', 'Univ'), ('Univ', '.')]

>> Trigrams are: 
 [('PhD', 'thesis', ','), ('thesis', ',', 'Univ'), (',', 'Univ', '.')]

>> POS Tags are: 
 [('PhD', 'NNP'), ('thesis', 'NN'), (',', ','), ('Univ', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['PhD thesis', 'Univ']

>> Named Entities are: 
 [('GPE', 'Univ')] 

>> Stemming using Porter Stemmer: 
 [('PhD', 'phd'), ('thesis', 'thesi'), (',', ','), ('Univ', 'univ'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('PhD', 'phd'), ('thesis', 'thesi'), (',', ','), ('Univ', 'univ'), ('.', '.')]

>> Lemmatization: 
 [('PhD', 'PhD'), ('thesis', 'thesis'), (',', ','), ('Univ', 'Univ'), ('.', '.')]


------------------- Sentence 5 -------------------

Toronto  (2012).

>> Tokens are: 
 ['Toronto', '(', '2012', ')', '.']

>> Bigrams are: 
 [('Toronto', '('), ('(', '2012'), ('2012', ')'), (')', '.')]

>> Trigrams are: 
 [('Toronto', '(', '2012'), ('(', '2012', ')'), ('2012', ')', '.')]

>> POS Tags are: 
 [('Toronto', 'NNP'), ('(', '('), ('2012', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['Toronto']

>> Named Entities are: 
 [('GPE', 'Toronto')] 

>> Stemming using Porter Stemmer: 
 [('Toronto', 'toronto'), ('(', '('), ('2012', '2012'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Toronto', 'toronto'), ('(', '('), ('2012', '2012'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Toronto', 'Toronto'), ('(', '('), ('2012', '2012'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 339 ===========================================

82. Pascanu, R., Mikolov, T. & Bengio, Y. On the difficulty of training recurrent neural  networks. In Proc. 30th International Conference on Machine Learning 1310– 1318 (2013).  

------------------- Sentence 1 -------------------

82.

>> Tokens are: 
 ['82', '.']

>> Bigrams are: 
 [('82', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('82', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('82', '82'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('82', '82'), ('.', '.')]

>> Lemmatization: 
 [('82', '82'), ('.', '.')]


------------------- Sentence 2 -------------------

Pascanu, R., Mikolov, T. & Bengio, Y.

>> Tokens are: 
 ['Pascanu', ',', 'R.', ',', 'Mikolov', ',', 'T.', '&', 'Bengio', ',', 'Y', '.']

>> Bigrams are: 
 [('Pascanu', ','), (',', 'R.'), ('R.', ','), (',', 'Mikolov'), ('Mikolov', ','), (',', 'T.'), ('T.', '&'), ('&', 'Bengio'), ('Bengio', ','), (',', 'Y'), ('Y', '.')]

>> Trigrams are: 
 [('Pascanu', ',', 'R.'), (',', 'R.', ','), ('R.', ',', 'Mikolov'), (',', 'Mikolov', ','), ('Mikolov', ',', 'T.'), (',', 'T.', '&'), ('T.', '&', 'Bengio'), ('&', 'Bengio', ','), ('Bengio', ',', 'Y'), (',', 'Y', '.')]

>> POS Tags are: 
 [('Pascanu', 'NNP'), (',', ','), ('R.', 'NNP'), (',', ','), ('Mikolov', 'NNP'), (',', ','), ('T.', 'NNP'), ('&', 'CC'), ('Bengio', 'NNP'), (',', ','), ('Y', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Pascanu', 'R.', 'Mikolov', 'T.', 'Bengio', 'Y']

>> Named Entities are: 
 [('GPE', 'Pascanu'), ('PERSON', 'Mikolov'), ('PERSON', 'Bengio')] 

>> Stemming using Porter Stemmer: 
 [('Pascanu', 'pascanu'), (',', ','), ('R.', 'r.'), (',', ','), ('Mikolov', 'mikolov'), (',', ','), ('T.', 't.'), ('&', '&'), ('Bengio', 'bengio'), (',', ','), ('Y', 'y'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Pascanu', 'pascanu'), (',', ','), ('R.', 'r.'), (',', ','), ('Mikolov', 'mikolov'), (',', ','), ('T.', 't.'), ('&', '&'), ('Bengio', 'bengio'), (',', ','), ('Y', 'y'), ('.', '.')]

>> Lemmatization: 
 [('Pascanu', 'Pascanu'), (',', ','), ('R.', 'R.'), (',', ','), ('Mikolov', 'Mikolov'), (',', ','), ('T.', 'T.'), ('&', '&'), ('Bengio', 'Bengio'), (',', ','), ('Y', 'Y'), ('.', '.')]


------------------- Sentence 3 -------------------

On the difficulty of training recurrent neural  networks.

>> Tokens are: 
 ['On', 'difficulty', 'training', 'recurrent', 'neural', 'networks', '.']

>> Bigrams are: 
 [('On', 'difficulty'), ('difficulty', 'training'), ('training', 'recurrent'), ('recurrent', 'neural'), ('neural', 'networks'), ('networks', '.')]

>> Trigrams are: 
 [('On', 'difficulty', 'training'), ('difficulty', 'training', 'recurrent'), ('training', 'recurrent', 'neural'), ('recurrent', 'neural', 'networks'), ('neural', 'networks', '.')]

>> POS Tags are: 
 [('On', 'IN'), ('difficulty', 'NN'), ('training', 'NN'), ('recurrent', 'JJ'), ('neural', 'JJ'), ('networks', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['difficulty training', 'recurrent neural networks']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('On', 'on'), ('difficulty', 'difficulti'), ('training', 'train'), ('recurrent', 'recurr'), ('neural', 'neural'), ('networks', 'network'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('On', 'on'), ('difficulty', 'difficulti'), ('training', 'train'), ('recurrent', 'recurr'), ('neural', 'neural'), ('networks', 'network'), ('.', '.')]

>> Lemmatization: 
 [('On', 'On'), ('difficulty', 'difficulty'), ('training', 'training'), ('recurrent', 'recurrent'), ('neural', 'neural'), ('networks', 'network'), ('.', '.')]


------------------- Sentence 4 -------------------

In Proc.

>> Tokens are: 
 ['In', 'Proc', '.']

>> Bigrams are: 
 [('In', 'Proc'), ('Proc', '.')]

>> Trigrams are: 
 [('In', 'Proc', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('Proc', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Proc']

>> Named Entities are: 
 [('GPE', 'Proc')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('Proc', 'proc'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('Proc', 'proc'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('Proc', 'Proc'), ('.', '.')]


------------------- Sentence 5 -------------------

30th International Conference on Machine Learning 1310– 1318 (2013).

>> Tokens are: 
 ['30th', 'International', 'Conference', 'Machine', 'Learning', '1310–', '1318', '(', '2013', ')', '.']

>> Bigrams are: 
 [('30th', 'International'), ('International', 'Conference'), ('Conference', 'Machine'), ('Machine', 'Learning'), ('Learning', '1310–'), ('1310–', '1318'), ('1318', '('), ('(', '2013'), ('2013', ')'), (')', '.')]

>> Trigrams are: 
 [('30th', 'International', 'Conference'), ('International', 'Conference', 'Machine'), ('Conference', 'Machine', 'Learning'), ('Machine', 'Learning', '1310–'), ('Learning', '1310–', '1318'), ('1310–', '1318', '('), ('1318', '(', '2013'), ('(', '2013', ')'), ('2013', ')', '.')]

>> POS Tags are: 
 [('30th', 'LS'), ('International', 'NNP'), ('Conference', 'NNP'), ('Machine', 'NNP'), ('Learning', 'NNP'), ('1310–', 'CD'), ('1318', 'CD'), ('(', '('), ('2013', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['International Conference Machine Learning']

>> Named Entities are: 
 [('ORGANIZATION', 'International Conference Machine')] 

>> Stemming using Porter Stemmer: 
 [('30th', '30th'), ('International', 'intern'), ('Conference', 'confer'), ('Machine', 'machin'), ('Learning', 'learn'), ('1310–', '1310–'), ('1318', '1318'), ('(', '('), ('2013', '2013'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('30th', '30th'), ('International', 'intern'), ('Conference', 'confer'), ('Machine', 'machin'), ('Learning', 'learn'), ('1310–', '1310–'), ('1318', '1318'), ('(', '('), ('2013', '2013'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('30th', '30th'), ('International', 'International'), ('Conference', 'Conference'), ('Machine', 'Machine'), ('Learning', 'Learning'), ('1310–', '1310–'), ('1318', '1318'), ('(', '('), ('2013', '2013'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 340 ===========================================

83. Sutskever, I., Martens, J. & Hinton, G. E. Generating text with recurrent neural  networks. In Proc. 28th International Conference on Machine Learning 1017– 1024 (2011).  

------------------- Sentence 1 -------------------

83.

>> Tokens are: 
 ['83', '.']

>> Bigrams are: 
 [('83', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('83', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('83', '83'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('83', '83'), ('.', '.')]

>> Lemmatization: 
 [('83', '83'), ('.', '.')]


------------------- Sentence 2 -------------------

Sutskever, I., Martens, J.

>> Tokens are: 
 ['Sutskever', ',', 'I.', ',', 'Martens', ',', 'J', '.']

>> Bigrams are: 
 [('Sutskever', ','), (',', 'I.'), ('I.', ','), (',', 'Martens'), ('Martens', ','), (',', 'J'), ('J', '.')]

>> Trigrams are: 
 [('Sutskever', ',', 'I.'), (',', 'I.', ','), ('I.', ',', 'Martens'), (',', 'Martens', ','), ('Martens', ',', 'J'), (',', 'J', '.')]

>> POS Tags are: 
 [('Sutskever', 'NNP'), (',', ','), ('I.', 'NNP'), (',', ','), ('Martens', 'NNP'), (',', ','), ('J', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Sutskever', 'I.', 'Martens', 'J']

>> Named Entities are: 
 [('GPE', 'Sutskever'), ('PERSON', 'Martens')] 

>> Stemming using Porter Stemmer: 
 [('Sutskever', 'sutskev'), (',', ','), ('I.', 'i.'), (',', ','), ('Martens', 'marten'), (',', ','), ('J', 'j'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Sutskever', 'sutskev'), (',', ','), ('I.', 'i.'), (',', ','), ('Martens', 'marten'), (',', ','), ('J', 'j'), ('.', '.')]

>> Lemmatization: 
 [('Sutskever', 'Sutskever'), (',', ','), ('I.', 'I.'), (',', ','), ('Martens', 'Martens'), (',', ','), ('J', 'J'), ('.', '.')]


------------------- Sentence 3 -------------------

& Hinton, G. E. Generating text with recurrent neural  networks.

>> Tokens are: 
 ['&', 'Hinton', ',', 'G.', 'E.', 'Generating', 'text', 'recurrent', 'neural', 'networks', '.']

>> Bigrams are: 
 [('&', 'Hinton'), ('Hinton', ','), (',', 'G.'), ('G.', 'E.'), ('E.', 'Generating'), ('Generating', 'text'), ('text', 'recurrent'), ('recurrent', 'neural'), ('neural', 'networks'), ('networks', '.')]

>> Trigrams are: 
 [('&', 'Hinton', ','), ('Hinton', ',', 'G.'), (',', 'G.', 'E.'), ('G.', 'E.', 'Generating'), ('E.', 'Generating', 'text'), ('Generating', 'text', 'recurrent'), ('text', 'recurrent', 'neural'), ('recurrent', 'neural', 'networks'), ('neural', 'networks', '.')]

>> POS Tags are: 
 [('&', 'CC'), ('Hinton', 'NNP'), (',', ','), ('G.', 'NNP'), ('E.', 'NNP'), ('Generating', 'NNP'), ('text', 'JJ'), ('recurrent', 'NN'), ('neural', 'JJ'), ('networks', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['Hinton', 'G. E. Generating', 'text recurrent', 'neural networks']

>> Named Entities are: 
 [('GPE', 'Hinton')] 

>> Stemming using Porter Stemmer: 
 [('&', '&'), ('Hinton', 'hinton'), (',', ','), ('G.', 'g.'), ('E.', 'e.'), ('Generating', 'gener'), ('text', 'text'), ('recurrent', 'recurr'), ('neural', 'neural'), ('networks', 'network'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('&', '&'), ('Hinton', 'hinton'), (',', ','), ('G.', 'g.'), ('E.', 'e.'), ('Generating', 'generat'), ('text', 'text'), ('recurrent', 'recurr'), ('neural', 'neural'), ('networks', 'network'), ('.', '.')]

>> Lemmatization: 
 [('&', '&'), ('Hinton', 'Hinton'), (',', ','), ('G.', 'G.'), ('E.', 'E.'), ('Generating', 'Generating'), ('text', 'text'), ('recurrent', 'recurrent'), ('neural', 'neural'), ('networks', 'network'), ('.', '.')]


------------------- Sentence 4 -------------------

In Proc.

>> Tokens are: 
 ['In', 'Proc', '.']

>> Bigrams are: 
 [('In', 'Proc'), ('Proc', '.')]

>> Trigrams are: 
 [('In', 'Proc', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('Proc', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Proc']

>> Named Entities are: 
 [('GPE', 'Proc')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('Proc', 'proc'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('Proc', 'proc'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('Proc', 'Proc'), ('.', '.')]


------------------- Sentence 5 -------------------

28th International Conference on Machine Learning 1017– 1024 (2011).

>> Tokens are: 
 ['28th', 'International', 'Conference', 'Machine', 'Learning', '1017–', '1024', '(', '2011', ')', '.']

>> Bigrams are: 
 [('28th', 'International'), ('International', 'Conference'), ('Conference', 'Machine'), ('Machine', 'Learning'), ('Learning', '1017–'), ('1017–', '1024'), ('1024', '('), ('(', '2011'), ('2011', ')'), (')', '.')]

>> Trigrams are: 
 [('28th', 'International', 'Conference'), ('International', 'Conference', 'Machine'), ('Conference', 'Machine', 'Learning'), ('Machine', 'Learning', '1017–'), ('Learning', '1017–', '1024'), ('1017–', '1024', '('), ('1024', '(', '2011'), ('(', '2011', ')'), ('2011', ')', '.')]

>> POS Tags are: 
 [('28th', 'CD'), ('International', 'NNP'), ('Conference', 'NNP'), ('Machine', 'NNP'), ('Learning', 'NNP'), ('1017–', 'CD'), ('1024', 'CD'), ('(', '('), ('2011', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['International Conference Machine Learning']

>> Named Entities are: 
 [('ORGANIZATION', 'International Conference Machine')] 

>> Stemming using Porter Stemmer: 
 [('28th', '28th'), ('International', 'intern'), ('Conference', 'confer'), ('Machine', 'machin'), ('Learning', 'learn'), ('1017–', '1017–'), ('1024', '1024'), ('(', '('), ('2011', '2011'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('28th', '28th'), ('International', 'intern'), ('Conference', 'confer'), ('Machine', 'machin'), ('Learning', 'learn'), ('1017–', '1017–'), ('1024', '1024'), ('(', '('), ('2011', '2011'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('28th', '28th'), ('International', 'International'), ('Conference', 'Conference'), ('Machine', 'Machine'), ('Learning', 'Learning'), ('1017–', '1017–'), ('1024', '1024'), ('(', '('), ('2011', '2011'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 341 ===========================================

84. Lakoff, G. & Johnson, M. Metaphors We Live By (Univ. Chicago Press, 2008).  85. Rogers, T. T. & McClelland, J. L. Semantic Cognition: A Parallel Distributed  

------------------- Sentence 1 -------------------

84.

>> Tokens are: 
 ['84', '.']

>> Bigrams are: 
 [('84', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('84', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('84', '84'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('84', '84'), ('.', '.')]

>> Lemmatization: 
 [('84', '84'), ('.', '.')]


------------------- Sentence 2 -------------------

Lakoff, G. & Johnson, M. Metaphors We Live By (Univ.

>> Tokens are: 
 ['Lakoff', ',', 'G.', '&', 'Johnson', ',', 'M.', 'Metaphors', 'We', 'Live', 'By', '(', 'Univ', '.']

>> Bigrams are: 
 [('Lakoff', ','), (',', 'G.'), ('G.', '&'), ('&', 'Johnson'), ('Johnson', ','), (',', 'M.'), ('M.', 'Metaphors'), ('Metaphors', 'We'), ('We', 'Live'), ('Live', 'By'), ('By', '('), ('(', 'Univ'), ('Univ', '.')]

>> Trigrams are: 
 [('Lakoff', ',', 'G.'), (',', 'G.', '&'), ('G.', '&', 'Johnson'), ('&', 'Johnson', ','), ('Johnson', ',', 'M.'), (',', 'M.', 'Metaphors'), ('M.', 'Metaphors', 'We'), ('Metaphors', 'We', 'Live'), ('We', 'Live', 'By'), ('Live', 'By', '('), ('By', '(', 'Univ'), ('(', 'Univ', '.')]

>> POS Tags are: 
 [('Lakoff', 'NNP'), (',', ','), ('G.', 'NNP'), ('&', 'CC'), ('Johnson', 'NNP'), (',', ','), ('M.', 'NNP'), ('Metaphors', 'NNP'), ('We', 'PRP'), ('Live', 'VBP'), ('By', 'IN'), ('(', '('), ('Univ', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Lakoff', 'G.', 'Johnson', 'M. Metaphors', 'Univ']

>> Named Entities are: 
 [('GPE', 'Lakoff'), ('PERSON', 'Johnson'), ('ORGANIZATION', 'Univ')] 

>> Stemming using Porter Stemmer: 
 [('Lakoff', 'lakoff'), (',', ','), ('G.', 'g.'), ('&', '&'), ('Johnson', 'johnson'), (',', ','), ('M.', 'm.'), ('Metaphors', 'metaphor'), ('We', 'we'), ('Live', 'live'), ('By', 'by'), ('(', '('), ('Univ', 'univ'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Lakoff', 'lakoff'), (',', ','), ('G.', 'g.'), ('&', '&'), ('Johnson', 'johnson'), (',', ','), ('M.', 'm.'), ('Metaphors', 'metaphor'), ('We', 'we'), ('Live', 'live'), ('By', 'by'), ('(', '('), ('Univ', 'univ'), ('.', '.')]

>> Lemmatization: 
 [('Lakoff', 'Lakoff'), (',', ','), ('G.', 'G.'), ('&', '&'), ('Johnson', 'Johnson'), (',', ','), ('M.', 'M.'), ('Metaphors', 'Metaphors'), ('We', 'We'), ('Live', 'Live'), ('By', 'By'), ('(', '('), ('Univ', 'Univ'), ('.', '.')]


------------------- Sentence 3 -------------------

Chicago Press, 2008).

>> Tokens are: 
 ['Chicago', 'Press', ',', '2008', ')', '.']

>> Bigrams are: 
 [('Chicago', 'Press'), ('Press', ','), (',', '2008'), ('2008', ')'), (')', '.')]

>> Trigrams are: 
 [('Chicago', 'Press', ','), ('Press', ',', '2008'), (',', '2008', ')'), ('2008', ')', '.')]

>> POS Tags are: 
 [('Chicago', 'NNP'), ('Press', 'NNP'), (',', ','), ('2008', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['Chicago Press']

>> Named Entities are: 
 [('GPE', 'Chicago')] 

>> Stemming using Porter Stemmer: 
 [('Chicago', 'chicago'), ('Press', 'press'), (',', ','), ('2008', '2008'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Chicago', 'chicago'), ('Press', 'press'), (',', ','), ('2008', '2008'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Chicago', 'Chicago'), ('Press', 'Press'), (',', ','), ('2008', '2008'), (')', ')'), ('.', '.')]


------------------- Sentence 4 -------------------

85.

>> Tokens are: 
 ['85', '.']

>> Bigrams are: 
 [('85', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('85', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('85', '85'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('85', '85'), ('.', '.')]

>> Lemmatization: 
 [('85', '85'), ('.', '.')]


------------------- Sentence 5 -------------------

Rogers, T. T. & McClelland, J. L. Semantic Cognition: A Parallel Distributed

>> Tokens are: 
 ['Rogers', ',', 'T.', 'T.', '&', 'McClelland', ',', 'J.', 'L.', 'Semantic', 'Cognition', ':', 'A', 'Parallel', 'Distributed']

>> Bigrams are: 
 [('Rogers', ','), (',', 'T.'), ('T.', 'T.'), ('T.', '&'), ('&', 'McClelland'), ('McClelland', ','), (',', 'J.'), ('J.', 'L.'), ('L.', 'Semantic'), ('Semantic', 'Cognition'), ('Cognition', ':'), (':', 'A'), ('A', 'Parallel'), ('Parallel', 'Distributed')]

>> Trigrams are: 
 [('Rogers', ',', 'T.'), (',', 'T.', 'T.'), ('T.', 'T.', '&'), ('T.', '&', 'McClelland'), ('&', 'McClelland', ','), ('McClelland', ',', 'J.'), (',', 'J.', 'L.'), ('J.', 'L.', 'Semantic'), ('L.', 'Semantic', 'Cognition'), ('Semantic', 'Cognition', ':'), ('Cognition', ':', 'A'), (':', 'A', 'Parallel'), ('A', 'Parallel', 'Distributed')]

>> POS Tags are: 
 [('Rogers', 'NNS'), (',', ','), ('T.', 'NNP'), ('T.', 'NNP'), ('&', 'CC'), ('McClelland', 'NNP'), (',', ','), ('J.', 'NNP'), ('L.', 'NNP'), ('Semantic', 'NNP'), ('Cognition', 'NNP'), (':', ':'), ('A', 'DT'), ('Parallel', 'NNP'), ('Distributed', 'NNP')]

>> Noun Phrases are: 
 ['Rogers', 'T. T.', 'McClelland', 'J. L. Semantic Cognition', 'A Parallel Distributed']

>> Named Entities are: 
 [('ORGANIZATION', 'McClelland'), ('PERSON', 'J. L. Semantic'), ('ORGANIZATION', 'Parallel Distributed')] 

>> Stemming using Porter Stemmer: 
 [('Rogers', 'roger'), (',', ','), ('T.', 't.'), ('T.', 't.'), ('&', '&'), ('McClelland', 'mcclelland'), (',', ','), ('J.', 'j.'), ('L.', 'l.'), ('Semantic', 'semant'), ('Cognition', 'cognit'), (':', ':'), ('A', 'a'), ('Parallel', 'parallel'), ('Distributed', 'distribut')]

>> Stemming using Snowball Stemmer: 
 [('Rogers', 'roger'), (',', ','), ('T.', 't.'), ('T.', 't.'), ('&', '&'), ('McClelland', 'mcclelland'), (',', ','), ('J.', 'j.'), ('L.', 'l.'), ('Semantic', 'semant'), ('Cognition', 'cognit'), (':', ':'), ('A', 'a'), ('Parallel', 'parallel'), ('Distributed', 'distribut')]

>> Lemmatization: 
 [('Rogers', 'Rogers'), (',', ','), ('T.', 'T.'), ('T.', 'T.'), ('&', '&'), ('McClelland', 'McClelland'), (',', ','), ('J.', 'J.'), ('L.', 'L.'), ('Semantic', 'Semantic'), ('Cognition', 'Cognition'), (':', ':'), ('A', 'A'), ('Parallel', 'Parallel'), ('Distributed', 'Distributed')]



========================================== PARAGRAPH 342 ===========================================

Processing Approach (MIT Press, 2004).  86. Xu, K. et al. Show, attend and tell: Neural image caption generation with visual  

------------------- Sentence 1 -------------------

Processing Approach (MIT Press, 2004).

>> Tokens are: 
 ['Processing', 'Approach', '(', 'MIT', 'Press', ',', '2004', ')', '.']

>> Bigrams are: 
 [('Processing', 'Approach'), ('Approach', '('), ('(', 'MIT'), ('MIT', 'Press'), ('Press', ','), (',', '2004'), ('2004', ')'), (')', '.')]

>> Trigrams are: 
 [('Processing', 'Approach', '('), ('Approach', '(', 'MIT'), ('(', 'MIT', 'Press'), ('MIT', 'Press', ','), ('Press', ',', '2004'), (',', '2004', ')'), ('2004', ')', '.')]

>> POS Tags are: 
 [('Processing', 'VBG'), ('Approach', 'NNP'), ('(', '('), ('MIT', 'NNP'), ('Press', 'NNP'), (',', ','), ('2004', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['Approach', 'MIT Press']

>> Named Entities are: 
 [('GPE', 'Approach'), ('ORGANIZATION', 'MIT')] 

>> Stemming using Porter Stemmer: 
 [('Processing', 'process'), ('Approach', 'approach'), ('(', '('), ('MIT', 'mit'), ('Press', 'press'), (',', ','), ('2004', '2004'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Processing', 'process'), ('Approach', 'approach'), ('(', '('), ('MIT', 'mit'), ('Press', 'press'), (',', ','), ('2004', '2004'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Processing', 'Processing'), ('Approach', 'Approach'), ('(', '('), ('MIT', 'MIT'), ('Press', 'Press'), (',', ','), ('2004', '2004'), (')', ')'), ('.', '.')]


------------------- Sentence 2 -------------------

86.

>> Tokens are: 
 ['86', '.']

>> Bigrams are: 
 [('86', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('86', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('86', '86'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('86', '86'), ('.', '.')]

>> Lemmatization: 
 [('86', '86'), ('.', '.')]


------------------- Sentence 3 -------------------

Xu, K. et al.

>> Tokens are: 
 ['Xu', ',', 'K.', 'et', 'al', '.']

>> Bigrams are: 
 [('Xu', ','), (',', 'K.'), ('K.', 'et'), ('et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('Xu', ',', 'K.'), (',', 'K.', 'et'), ('K.', 'et', 'al'), ('et', 'al', '.')]

>> POS Tags are: 
 [('Xu', 'NN'), (',', ','), ('K.', 'NNP'), ('et', 'CC'), ('al', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Xu', 'K.', 'al']

>> Named Entities are: 
 [('GPE', 'Xu')] 

>> Stemming using Porter Stemmer: 
 [('Xu', 'xu'), (',', ','), ('K.', 'k.'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Xu', 'xu'), (',', ','), ('K.', 'k.'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('Xu', 'Xu'), (',', ','), ('K.', 'K.'), ('et', 'et'), ('al', 'al'), ('.', '.')]


------------------- Sentence 4 -------------------

Show, attend and tell: Neural image caption generation with visual

>> Tokens are: 
 ['Show', ',', 'attend', 'tell', ':', 'Neural', 'image', 'caption', 'generation', 'visual']

>> Bigrams are: 
 [('Show', ','), (',', 'attend'), ('attend', 'tell'), ('tell', ':'), (':', 'Neural'), ('Neural', 'image'), ('image', 'caption'), ('caption', 'generation'), ('generation', 'visual')]

>> Trigrams are: 
 [('Show', ',', 'attend'), (',', 'attend', 'tell'), ('attend', 'tell', ':'), ('tell', ':', 'Neural'), (':', 'Neural', 'image'), ('Neural', 'image', 'caption'), ('image', 'caption', 'generation'), ('caption', 'generation', 'visual')]

>> POS Tags are: 
 [('Show', 'NNP'), (',', ','), ('attend', 'VBP'), ('tell', 'NN'), (':', ':'), ('Neural', 'JJ'), ('image', 'NN'), ('caption', 'NN'), ('generation', 'NN'), ('visual', 'JJ')]

>> Noun Phrases are: 
 ['Show', 'tell', 'Neural image caption generation']

>> Named Entities are: 
 [('GPE', 'Show')] 

>> Stemming using Porter Stemmer: 
 [('Show', 'show'), (',', ','), ('attend', 'attend'), ('tell', 'tell'), (':', ':'), ('Neural', 'neural'), ('image', 'imag'), ('caption', 'caption'), ('generation', 'gener'), ('visual', 'visual')]

>> Stemming using Snowball Stemmer: 
 [('Show', 'show'), (',', ','), ('attend', 'attend'), ('tell', 'tell'), (':', ':'), ('Neural', 'neural'), ('image', 'imag'), ('caption', 'caption'), ('generation', 'generat'), ('visual', 'visual')]

>> Lemmatization: 
 [('Show', 'Show'), (',', ','), ('attend', 'attend'), ('tell', 'tell'), (':', ':'), ('Neural', 'Neural'), ('image', 'image'), ('caption', 'caption'), ('generation', 'generation'), ('visual', 'visual')]



========================================== PARAGRAPH 343 ===========================================

attention. In Proc. International Conference on Learning Representations http:// arxiv.org/abs/1502.03044 (2015).  

------------------- Sentence 1 -------------------

attention.

>> Tokens are: 
 ['attention', '.']

>> Bigrams are: 
 [('attention', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('attention', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['attention']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('attention', 'attent'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('attention', 'attent'), ('.', '.')]

>> Lemmatization: 
 [('attention', 'attention'), ('.', '.')]


------------------- Sentence 2 -------------------

In Proc.

>> Tokens are: 
 ['In', 'Proc', '.']

>> Bigrams are: 
 [('In', 'Proc'), ('Proc', '.')]

>> Trigrams are: 
 [('In', 'Proc', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('Proc', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Proc']

>> Named Entities are: 
 [('GPE', 'Proc')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('Proc', 'proc'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('Proc', 'proc'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('Proc', 'Proc'), ('.', '.')]


------------------- Sentence 3 -------------------

International Conference on Learning Representations http:// arxiv.org/abs/1502.03044 (2015).

>> Tokens are: 
 ['International', 'Conference', 'Learning', 'Representations', 'http', ':', '//', 'arxiv.org/abs/1502.03044', '(', '2015', ')', '.']

>> Bigrams are: 
 [('International', 'Conference'), ('Conference', 'Learning'), ('Learning', 'Representations'), ('Representations', 'http'), ('http', ':'), (':', '//'), ('//', 'arxiv.org/abs/1502.03044'), ('arxiv.org/abs/1502.03044', '('), ('(', '2015'), ('2015', ')'), (')', '.')]

>> Trigrams are: 
 [('International', 'Conference', 'Learning'), ('Conference', 'Learning', 'Representations'), ('Learning', 'Representations', 'http'), ('Representations', 'http', ':'), ('http', ':', '//'), (':', '//', 'arxiv.org/abs/1502.03044'), ('//', 'arxiv.org/abs/1502.03044', '('), ('arxiv.org/abs/1502.03044', '(', '2015'), ('(', '2015', ')'), ('2015', ')', '.')]

>> POS Tags are: 
 [('International', 'NNP'), ('Conference', 'NNP'), ('Learning', 'NNP'), ('Representations', 'NNP'), ('http', 'NN'), (':', ':'), ('//', 'NN'), ('arxiv.org/abs/1502.03044', 'NN'), ('(', '('), ('2015', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['International Conference Learning Representations http', '// arxiv.org/abs/1502.03044']

>> Named Entities are: 
 [('ORGANIZATION', 'International Conference')] 

>> Stemming using Porter Stemmer: 
 [('International', 'intern'), ('Conference', 'confer'), ('Learning', 'learn'), ('Representations', 'represent'), ('http', 'http'), (':', ':'), ('//', '//'), ('arxiv.org/abs/1502.03044', 'arxiv.org/abs/1502.03044'), ('(', '('), ('2015', '2015'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('International', 'intern'), ('Conference', 'confer'), ('Learning', 'learn'), ('Representations', 'represent'), ('http', 'http'), (':', ':'), ('//', '//'), ('arxiv.org/abs/1502.03044', 'arxiv.org/abs/1502.03044'), ('(', '('), ('2015', '2015'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('International', 'International'), ('Conference', 'Conference'), ('Learning', 'Learning'), ('Representations', 'Representations'), ('http', 'http'), (':', ':'), ('//', '//'), ('arxiv.org/abs/1502.03044', 'arxiv.org/abs/1502.03044'), ('(', '('), ('2015', '2015'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 344 ===========================================

87. Graves, A., Mohamed, A.-R. & Hinton, G. Speech recognition with deep recurrent  neural networks. In Proc. International Conference on Acoustics, Speech and  Signal Processing 6645–6649 (2013).  

------------------- Sentence 1 -------------------

87.

>> Tokens are: 
 ['87', '.']

>> Bigrams are: 
 [('87', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('87', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('87', '87'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('87', '87'), ('.', '.')]

>> Lemmatization: 
 [('87', '87'), ('.', '.')]


------------------- Sentence 2 -------------------

Graves, A., Mohamed, A.-R. & Hinton, G. Speech recognition with deep recurrent  neural networks.

>> Tokens are: 
 ['Graves', ',', 'A.', ',', 'Mohamed', ',', 'A.-R.', '&', 'Hinton', ',', 'G.', 'Speech', 'recognition', 'deep', 'recurrent', 'neural', 'networks', '.']

>> Bigrams are: 
 [('Graves', ','), (',', 'A.'), ('A.', ','), (',', 'Mohamed'), ('Mohamed', ','), (',', 'A.-R.'), ('A.-R.', '&'), ('&', 'Hinton'), ('Hinton', ','), (',', 'G.'), ('G.', 'Speech'), ('Speech', 'recognition'), ('recognition', 'deep'), ('deep', 'recurrent'), ('recurrent', 'neural'), ('neural', 'networks'), ('networks', '.')]

>> Trigrams are: 
 [('Graves', ',', 'A.'), (',', 'A.', ','), ('A.', ',', 'Mohamed'), (',', 'Mohamed', ','), ('Mohamed', ',', 'A.-R.'), (',', 'A.-R.', '&'), ('A.-R.', '&', 'Hinton'), ('&', 'Hinton', ','), ('Hinton', ',', 'G.'), (',', 'G.', 'Speech'), ('G.', 'Speech', 'recognition'), ('Speech', 'recognition', 'deep'), ('recognition', 'deep', 'recurrent'), ('deep', 'recurrent', 'neural'), ('recurrent', 'neural', 'networks'), ('neural', 'networks', '.')]

>> POS Tags are: 
 [('Graves', 'NNS'), (',', ','), ('A.', 'NNP'), (',', ','), ('Mohamed', 'NNP'), (',', ','), ('A.-R.', 'NNP'), ('&', 'CC'), ('Hinton', 'NNP'), (',', ','), ('G.', 'NNP'), ('Speech', 'NNP'), ('recognition', 'NN'), ('deep', 'JJ'), ('recurrent', 'NN'), ('neural', 'JJ'), ('networks', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['Graves', 'A.', 'Mohamed', 'A.-R.', 'Hinton', 'G. Speech recognition', 'deep recurrent', 'neural networks']

>> Named Entities are: 
 [('GPE', 'Graves'), ('PERSON', 'Mohamed'), ('GPE', 'Hinton')] 

>> Stemming using Porter Stemmer: 
 [('Graves', 'grave'), (',', ','), ('A.', 'a.'), (',', ','), ('Mohamed', 'moham'), (',', ','), ('A.-R.', 'a.-r.'), ('&', '&'), ('Hinton', 'hinton'), (',', ','), ('G.', 'g.'), ('Speech', 'speech'), ('recognition', 'recognit'), ('deep', 'deep'), ('recurrent', 'recurr'), ('neural', 'neural'), ('networks', 'network'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Graves', 'grave'), (',', ','), ('A.', 'a.'), (',', ','), ('Mohamed', 'moham'), (',', ','), ('A.-R.', 'a.-r.'), ('&', '&'), ('Hinton', 'hinton'), (',', ','), ('G.', 'g.'), ('Speech', 'speech'), ('recognition', 'recognit'), ('deep', 'deep'), ('recurrent', 'recurr'), ('neural', 'neural'), ('networks', 'network'), ('.', '.')]

>> Lemmatization: 
 [('Graves', 'Graves'), (',', ','), ('A.', 'A.'), (',', ','), ('Mohamed', 'Mohamed'), (',', ','), ('A.-R.', 'A.-R.'), ('&', '&'), ('Hinton', 'Hinton'), (',', ','), ('G.', 'G.'), ('Speech', 'Speech'), ('recognition', 'recognition'), ('deep', 'deep'), ('recurrent', 'recurrent'), ('neural', 'neural'), ('networks', 'network'), ('.', '.')]


------------------- Sentence 3 -------------------

In Proc.

>> Tokens are: 
 ['In', 'Proc', '.']

>> Bigrams are: 
 [('In', 'Proc'), ('Proc', '.')]

>> Trigrams are: 
 [('In', 'Proc', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('Proc', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Proc']

>> Named Entities are: 
 [('GPE', 'Proc')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('Proc', 'proc'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('Proc', 'proc'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('Proc', 'Proc'), ('.', '.')]


------------------- Sentence 4 -------------------

International Conference on Acoustics, Speech and  Signal Processing 6645–6649 (2013).

>> Tokens are: 
 ['International', 'Conference', 'Acoustics', ',', 'Speech', 'Signal', 'Processing', '6645–6649', '(', '2013', ')', '.']

>> Bigrams are: 
 [('International', 'Conference'), ('Conference', 'Acoustics'), ('Acoustics', ','), (',', 'Speech'), ('Speech', 'Signal'), ('Signal', 'Processing'), ('Processing', '6645–6649'), ('6645–6649', '('), ('(', '2013'), ('2013', ')'), (')', '.')]

>> Trigrams are: 
 [('International', 'Conference', 'Acoustics'), ('Conference', 'Acoustics', ','), ('Acoustics', ',', 'Speech'), (',', 'Speech', 'Signal'), ('Speech', 'Signal', 'Processing'), ('Signal', 'Processing', '6645–6649'), ('Processing', '6645–6649', '('), ('6645–6649', '(', '2013'), ('(', '2013', ')'), ('2013', ')', '.')]

>> POS Tags are: 
 [('International', 'NNP'), ('Conference', 'NNP'), ('Acoustics', 'NNP'), (',', ','), ('Speech', 'NNP'), ('Signal', 'NNP'), ('Processing', 'NNP'), ('6645–6649', 'CD'), ('(', '('), ('2013', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['International Conference Acoustics', 'Speech Signal Processing']

>> Named Entities are: 
 [('ORGANIZATION', 'International Conference Acoustics'), ('PERSON', 'Speech Signal')] 

>> Stemming using Porter Stemmer: 
 [('International', 'intern'), ('Conference', 'confer'), ('Acoustics', 'acoust'), (',', ','), ('Speech', 'speech'), ('Signal', 'signal'), ('Processing', 'process'), ('6645–6649', '6645–6649'), ('(', '('), ('2013', '2013'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('International', 'intern'), ('Conference', 'confer'), ('Acoustics', 'acoust'), (',', ','), ('Speech', 'speech'), ('Signal', 'signal'), ('Processing', 'process'), ('6645–6649', '6645–6649'), ('(', '('), ('2013', '2013'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('International', 'International'), ('Conference', 'Conference'), ('Acoustics', 'Acoustics'), (',', ','), ('Speech', 'Speech'), ('Signal', 'Signal'), ('Processing', 'Processing'), ('6645–6649', '6645–6649'), ('(', '('), ('2013', '2013'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 345 ===========================================

88. Graves, A., Wayne, G. & Danihelka, I. Neural Turing machines. http://arxiv.org/ abs/1410.5401 (2014).  

------------------- Sentence 1 -------------------

88.

>> Tokens are: 
 ['88', '.']

>> Bigrams are: 
 [('88', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('88', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('88', '88'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('88', '88'), ('.', '.')]

>> Lemmatization: 
 [('88', '88'), ('.', '.')]


------------------- Sentence 2 -------------------

Graves, A., Wayne, G. & Danihelka, I. Neural Turing machines.

>> Tokens are: 
 ['Graves', ',', 'A.', ',', 'Wayne', ',', 'G.', '&', 'Danihelka', ',', 'I.', 'Neural', 'Turing', 'machines', '.']

>> Bigrams are: 
 [('Graves', ','), (',', 'A.'), ('A.', ','), (',', 'Wayne'), ('Wayne', ','), (',', 'G.'), ('G.', '&'), ('&', 'Danihelka'), ('Danihelka', ','), (',', 'I.'), ('I.', 'Neural'), ('Neural', 'Turing'), ('Turing', 'machines'), ('machines', '.')]

>> Trigrams are: 
 [('Graves', ',', 'A.'), (',', 'A.', ','), ('A.', ',', 'Wayne'), (',', 'Wayne', ','), ('Wayne', ',', 'G.'), (',', 'G.', '&'), ('G.', '&', 'Danihelka'), ('&', 'Danihelka', ','), ('Danihelka', ',', 'I.'), (',', 'I.', 'Neural'), ('I.', 'Neural', 'Turing'), ('Neural', 'Turing', 'machines'), ('Turing', 'machines', '.')]

>> POS Tags are: 
 [('Graves', 'NNS'), (',', ','), ('A.', 'NNP'), (',', ','), ('Wayne', 'NNP'), (',', ','), ('G.', 'NNP'), ('&', 'CC'), ('Danihelka', 'NNP'), (',', ','), ('I.', 'NNP'), ('Neural', 'NNP'), ('Turing', 'NNP'), ('machines', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['Graves', 'A.', 'Wayne', 'G.', 'Danihelka', 'I. Neural Turing machines']

>> Named Entities are: 
 [('GPE', 'Graves'), ('PERSON', 'Wayne'), ('PERSON', 'Danihelka')] 

>> Stemming using Porter Stemmer: 
 [('Graves', 'grave'), (',', ','), ('A.', 'a.'), (',', ','), ('Wayne', 'wayn'), (',', ','), ('G.', 'g.'), ('&', '&'), ('Danihelka', 'danihelka'), (',', ','), ('I.', 'i.'), ('Neural', 'neural'), ('Turing', 'ture'), ('machines', 'machin'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Graves', 'grave'), (',', ','), ('A.', 'a.'), (',', ','), ('Wayne', 'wayn'), (',', ','), ('G.', 'g.'), ('&', '&'), ('Danihelka', 'danihelka'), (',', ','), ('I.', 'i.'), ('Neural', 'neural'), ('Turing', 'ture'), ('machines', 'machin'), ('.', '.')]

>> Lemmatization: 
 [('Graves', 'Graves'), (',', ','), ('A.', 'A.'), (',', ','), ('Wayne', 'Wayne'), (',', ','), ('G.', 'G.'), ('&', '&'), ('Danihelka', 'Danihelka'), (',', ','), ('I.', 'I.'), ('Neural', 'Neural'), ('Turing', 'Turing'), ('machines', 'machine'), ('.', '.')]


------------------- Sentence 3 -------------------

http://arxiv.org/ abs/1410.5401 (2014).

>> Tokens are: 
 ['http', ':', '//arxiv.org/', 'abs/1410.5401', '(', '2014', ')', '.']

>> Bigrams are: 
 [('http', ':'), (':', '//arxiv.org/'), ('//arxiv.org/', 'abs/1410.5401'), ('abs/1410.5401', '('), ('(', '2014'), ('2014', ')'), (')', '.')]

>> Trigrams are: 
 [('http', ':', '//arxiv.org/'), (':', '//arxiv.org/', 'abs/1410.5401'), ('//arxiv.org/', 'abs/1410.5401', '('), ('abs/1410.5401', '(', '2014'), ('(', '2014', ')'), ('2014', ')', '.')]

>> POS Tags are: 
 [('http', 'NN'), (':', ':'), ('//arxiv.org/', 'NN'), ('abs/1410.5401', 'NN'), ('(', '('), ('2014', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['http', '//arxiv.org/ abs/1410.5401']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('http', 'http'), (':', ':'), ('//arxiv.org/', '//arxiv.org/'), ('abs/1410.5401', 'abs/1410.5401'), ('(', '('), ('2014', '2014'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('http', 'http'), (':', ':'), ('//arxiv.org/', '//arxiv.org/'), ('abs/1410.5401', 'abs/1410.5401'), ('(', '('), ('2014', '2014'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('http', 'http'), (':', ':'), ('//arxiv.org/', '//arxiv.org/'), ('abs/1410.5401', 'abs/1410.5401'), ('(', '('), ('2014', '2014'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 346 ===========================================

89. Weston, J. Chopra, S. & Bordes, A. Memory networks. http://arxiv.org/ abs/1410.3916 (2014).  

------------------- Sentence 1 -------------------

89.

>> Tokens are: 
 ['89', '.']

>> Bigrams are: 
 [('89', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('89', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('89', '89'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('89', '89'), ('.', '.')]

>> Lemmatization: 
 [('89', '89'), ('.', '.')]


------------------- Sentence 2 -------------------

Weston, J. Chopra, S. & Bordes, A.

>> Tokens are: 
 ['Weston', ',', 'J.', 'Chopra', ',', 'S.', '&', 'Bordes', ',', 'A', '.']

>> Bigrams are: 
 [('Weston', ','), (',', 'J.'), ('J.', 'Chopra'), ('Chopra', ','), (',', 'S.'), ('S.', '&'), ('&', 'Bordes'), ('Bordes', ','), (',', 'A'), ('A', '.')]

>> Trigrams are: 
 [('Weston', ',', 'J.'), (',', 'J.', 'Chopra'), ('J.', 'Chopra', ','), ('Chopra', ',', 'S.'), (',', 'S.', '&'), ('S.', '&', 'Bordes'), ('&', 'Bordes', ','), ('Bordes', ',', 'A'), (',', 'A', '.')]

>> POS Tags are: 
 [('Weston', 'NNP'), (',', ','), ('J.', 'NNP'), ('Chopra', 'NNP'), (',', ','), ('S.', 'NNP'), ('&', 'CC'), ('Bordes', 'NNP'), (',', ','), ('A', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Weston', 'J. Chopra', 'S.', 'Bordes', 'A']

>> Named Entities are: 
 [('GPE', 'Weston'), ('PERSON', 'J. Chopra'), ('GPE', 'Bordes')] 

>> Stemming using Porter Stemmer: 
 [('Weston', 'weston'), (',', ','), ('J.', 'j.'), ('Chopra', 'chopra'), (',', ','), ('S.', 's.'), ('&', '&'), ('Bordes', 'bord'), (',', ','), ('A', 'a'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Weston', 'weston'), (',', ','), ('J.', 'j.'), ('Chopra', 'chopra'), (',', ','), ('S.', 's.'), ('&', '&'), ('Bordes', 'bord'), (',', ','), ('A', 'a'), ('.', '.')]

>> Lemmatization: 
 [('Weston', 'Weston'), (',', ','), ('J.', 'J.'), ('Chopra', 'Chopra'), (',', ','), ('S.', 'S.'), ('&', '&'), ('Bordes', 'Bordes'), (',', ','), ('A', 'A'), ('.', '.')]


------------------- Sentence 3 -------------------

Memory networks.

>> Tokens are: 
 ['Memory', 'networks', '.']

>> Bigrams are: 
 [('Memory', 'networks'), ('networks', '.')]

>> Trigrams are: 
 [('Memory', 'networks', '.')]

>> POS Tags are: 
 [('Memory', 'NN'), ('networks', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['Memory networks']

>> Named Entities are: 
 [('GPE', 'Memory')] 

>> Stemming using Porter Stemmer: 
 [('Memory', 'memori'), ('networks', 'network'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Memory', 'memori'), ('networks', 'network'), ('.', '.')]

>> Lemmatization: 
 [('Memory', 'Memory'), ('networks', 'network'), ('.', '.')]


------------------- Sentence 4 -------------------

http://arxiv.org/ abs/1410.3916 (2014).

>> Tokens are: 
 ['http', ':', '//arxiv.org/', 'abs/1410.3916', '(', '2014', ')', '.']

>> Bigrams are: 
 [('http', ':'), (':', '//arxiv.org/'), ('//arxiv.org/', 'abs/1410.3916'), ('abs/1410.3916', '('), ('(', '2014'), ('2014', ')'), (')', '.')]

>> Trigrams are: 
 [('http', ':', '//arxiv.org/'), (':', '//arxiv.org/', 'abs/1410.3916'), ('//arxiv.org/', 'abs/1410.3916', '('), ('abs/1410.3916', '(', '2014'), ('(', '2014', ')'), ('2014', ')', '.')]

>> POS Tags are: 
 [('http', 'NN'), (':', ':'), ('//arxiv.org/', 'NN'), ('abs/1410.3916', 'NN'), ('(', '('), ('2014', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['http', '//arxiv.org/ abs/1410.3916']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('http', 'http'), (':', ':'), ('//arxiv.org/', '//arxiv.org/'), ('abs/1410.3916', 'abs/1410.3916'), ('(', '('), ('2014', '2014'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('http', 'http'), (':', ':'), ('//arxiv.org/', '//arxiv.org/'), ('abs/1410.3916', 'abs/1410.3916'), ('(', '('), ('2014', '2014'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('http', 'http'), (':', ':'), ('//arxiv.org/', '//arxiv.org/'), ('abs/1410.3916', 'abs/1410.3916'), ('(', '('), ('2014', '2014'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 347 ===========================================

90. Weston, J., Bordes, A., Chopra, S. & Mikolov, T. Towards AI-complete question  answering: a set of prerequisite toy tasks. http://arxiv.org/abs/1502.05698  (2015).  

------------------- Sentence 1 -------------------

90.

>> Tokens are: 
 ['90', '.']

>> Bigrams are: 
 [('90', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('90', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('90', '90'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('90', '90'), ('.', '.')]

>> Lemmatization: 
 [('90', '90'), ('.', '.')]


------------------- Sentence 2 -------------------

Weston, J., Bordes, A., Chopra, S. & Mikolov, T. Towards AI-complete question  answering: a set of prerequisite toy tasks.

>> Tokens are: 
 ['Weston', ',', 'J.', ',', 'Bordes', ',', 'A.', ',', 'Chopra', ',', 'S.', '&', 'Mikolov', ',', 'T.', 'Towards', 'AI-complete', 'question', 'answering', ':', 'set', 'prerequisite', 'toy', 'tasks', '.']

>> Bigrams are: 
 [('Weston', ','), (',', 'J.'), ('J.', ','), (',', 'Bordes'), ('Bordes', ','), (',', 'A.'), ('A.', ','), (',', 'Chopra'), ('Chopra', ','), (',', 'S.'), ('S.', '&'), ('&', 'Mikolov'), ('Mikolov', ','), (',', 'T.'), ('T.', 'Towards'), ('Towards', 'AI-complete'), ('AI-complete', 'question'), ('question', 'answering'), ('answering', ':'), (':', 'set'), ('set', 'prerequisite'), ('prerequisite', 'toy'), ('toy', 'tasks'), ('tasks', '.')]

>> Trigrams are: 
 [('Weston', ',', 'J.'), (',', 'J.', ','), ('J.', ',', 'Bordes'), (',', 'Bordes', ','), ('Bordes', ',', 'A.'), (',', 'A.', ','), ('A.', ',', 'Chopra'), (',', 'Chopra', ','), ('Chopra', ',', 'S.'), (',', 'S.', '&'), ('S.', '&', 'Mikolov'), ('&', 'Mikolov', ','), ('Mikolov', ',', 'T.'), (',', 'T.', 'Towards'), ('T.', 'Towards', 'AI-complete'), ('Towards', 'AI-complete', 'question'), ('AI-complete', 'question', 'answering'), ('question', 'answering', ':'), ('answering', ':', 'set'), (':', 'set', 'prerequisite'), ('set', 'prerequisite', 'toy'), ('prerequisite', 'toy', 'tasks'), ('toy', 'tasks', '.')]

>> POS Tags are: 
 [('Weston', 'NNP'), (',', ','), ('J.', 'NNP'), (',', ','), ('Bordes', 'NNP'), (',', ','), ('A.', 'NNP'), (',', ','), ('Chopra', 'NNP'), (',', ','), ('S.', 'NNP'), ('&', 'CC'), ('Mikolov', 'NNP'), (',', ','), ('T.', 'NNP'), ('Towards', 'NNP'), ('AI-complete', 'NNP'), ('question', 'NN'), ('answering', 'NN'), (':', ':'), ('set', 'VBN'), ('prerequisite', 'JJ'), ('toy', 'NN'), ('tasks', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['Weston', 'J.', 'Bordes', 'A.', 'Chopra', 'S.', 'Mikolov', 'T. Towards AI-complete question answering', 'prerequisite toy tasks']

>> Named Entities are: 
 [('GPE', 'Weston'), ('GPE', 'Bordes'), ('GPE', 'Chopra'), ('PERSON', 'Mikolov')] 

>> Stemming using Porter Stemmer: 
 [('Weston', 'weston'), (',', ','), ('J.', 'j.'), (',', ','), ('Bordes', 'bord'), (',', ','), ('A.', 'a.'), (',', ','), ('Chopra', 'chopra'), (',', ','), ('S.', 's.'), ('&', '&'), ('Mikolov', 'mikolov'), (',', ','), ('T.', 't.'), ('Towards', 'toward'), ('AI-complete', 'ai-complet'), ('question', 'question'), ('answering', 'answer'), (':', ':'), ('set', 'set'), ('prerequisite', 'prerequisit'), ('toy', 'toy'), ('tasks', 'task'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Weston', 'weston'), (',', ','), ('J.', 'j.'), (',', ','), ('Bordes', 'bord'), (',', ','), ('A.', 'a.'), (',', ','), ('Chopra', 'chopra'), (',', ','), ('S.', 's.'), ('&', '&'), ('Mikolov', 'mikolov'), (',', ','), ('T.', 't.'), ('Towards', 'toward'), ('AI-complete', 'ai-complet'), ('question', 'question'), ('answering', 'answer'), (':', ':'), ('set', 'set'), ('prerequisite', 'prerequisit'), ('toy', 'toy'), ('tasks', 'task'), ('.', '.')]

>> Lemmatization: 
 [('Weston', 'Weston'), (',', ','), ('J.', 'J.'), (',', ','), ('Bordes', 'Bordes'), (',', ','), ('A.', 'A.'), (',', ','), ('Chopra', 'Chopra'), (',', ','), ('S.', 'S.'), ('&', '&'), ('Mikolov', 'Mikolov'), (',', ','), ('T.', 'T.'), ('Towards', 'Towards'), ('AI-complete', 'AI-complete'), ('question', 'question'), ('answering', 'answering'), (':', ':'), ('set', 'set'), ('prerequisite', 'prerequisite'), ('toy', 'toy'), ('tasks', 'task'), ('.', '.')]


------------------- Sentence 3 -------------------

http://arxiv.org/abs/1502.05698  (2015).

>> Tokens are: 
 ['http', ':', '//arxiv.org/abs/1502.05698', '(', '2015', ')', '.']

>> Bigrams are: 
 [('http', ':'), (':', '//arxiv.org/abs/1502.05698'), ('//arxiv.org/abs/1502.05698', '('), ('(', '2015'), ('2015', ')'), (')', '.')]

>> Trigrams are: 
 [('http', ':', '//arxiv.org/abs/1502.05698'), (':', '//arxiv.org/abs/1502.05698', '('), ('//arxiv.org/abs/1502.05698', '(', '2015'), ('(', '2015', ')'), ('2015', ')', '.')]

>> POS Tags are: 
 [('http', 'NN'), (':', ':'), ('//arxiv.org/abs/1502.05698', 'NN'), ('(', '('), ('2015', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['http', '//arxiv.org/abs/1502.05698']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('http', 'http'), (':', ':'), ('//arxiv.org/abs/1502.05698', '//arxiv.org/abs/1502.05698'), ('(', '('), ('2015', '2015'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('http', 'http'), (':', ':'), ('//arxiv.org/abs/1502.05698', '//arxiv.org/abs/1502.05698'), ('(', '('), ('2015', '2015'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('http', 'http'), (':', ':'), ('//arxiv.org/abs/1502.05698', '//arxiv.org/abs/1502.05698'), ('(', '('), ('2015', '2015'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 348 ===========================================

91. Hinton, G. E., Dayan, P., Frey, B. J. & Neal, R. M. The wake-sleep algorithm for  unsupervised neural networks. Science 268, 1558–1161 (1995).  

------------------- Sentence 1 -------------------

91.

>> Tokens are: 
 ['91', '.']

>> Bigrams are: 
 [('91', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('91', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('91', '91'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('91', '91'), ('.', '.')]

>> Lemmatization: 
 [('91', '91'), ('.', '.')]


------------------- Sentence 2 -------------------

Hinton, G. E., Dayan, P., Frey, B. J.

>> Tokens are: 
 ['Hinton', ',', 'G.', 'E.', ',', 'Dayan', ',', 'P.', ',', 'Frey', ',', 'B.', 'J', '.']

>> Bigrams are: 
 [('Hinton', ','), (',', 'G.'), ('G.', 'E.'), ('E.', ','), (',', 'Dayan'), ('Dayan', ','), (',', 'P.'), ('P.', ','), (',', 'Frey'), ('Frey', ','), (',', 'B.'), ('B.', 'J'), ('J', '.')]

>> Trigrams are: 
 [('Hinton', ',', 'G.'), (',', 'G.', 'E.'), ('G.', 'E.', ','), ('E.', ',', 'Dayan'), (',', 'Dayan', ','), ('Dayan', ',', 'P.'), (',', 'P.', ','), ('P.', ',', 'Frey'), (',', 'Frey', ','), ('Frey', ',', 'B.'), (',', 'B.', 'J'), ('B.', 'J', '.')]

>> POS Tags are: 
 [('Hinton', 'NNP'), (',', ','), ('G.', 'NNP'), ('E.', 'NNP'), (',', ','), ('Dayan', 'NNP'), (',', ','), ('P.', 'NNP'), (',', ','), ('Frey', 'NNP'), (',', ','), ('B.', 'NNP'), ('J', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Hinton', 'G. E.', 'Dayan', 'P.', 'Frey', 'B. J']

>> Named Entities are: 
 [('GPE', 'Hinton'), ('PERSON', 'Dayan'), ('GPE', 'Frey')] 

>> Stemming using Porter Stemmer: 
 [('Hinton', 'hinton'), (',', ','), ('G.', 'g.'), ('E.', 'e.'), (',', ','), ('Dayan', 'dayan'), (',', ','), ('P.', 'p.'), (',', ','), ('Frey', 'frey'), (',', ','), ('B.', 'b.'), ('J', 'j'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Hinton', 'hinton'), (',', ','), ('G.', 'g.'), ('E.', 'e.'), (',', ','), ('Dayan', 'dayan'), (',', ','), ('P.', 'p.'), (',', ','), ('Frey', 'frey'), (',', ','), ('B.', 'b.'), ('J', 'j'), ('.', '.')]

>> Lemmatization: 
 [('Hinton', 'Hinton'), (',', ','), ('G.', 'G.'), ('E.', 'E.'), (',', ','), ('Dayan', 'Dayan'), (',', ','), ('P.', 'P.'), (',', ','), ('Frey', 'Frey'), (',', ','), ('B.', 'B.'), ('J', 'J'), ('.', '.')]


------------------- Sentence 3 -------------------

& Neal, R. M. The wake-sleep algorithm for  unsupervised neural networks.

>> Tokens are: 
 ['&', 'Neal', ',', 'R.', 'M.', 'The', 'wake-sleep', 'algorithm', 'unsupervised', 'neural', 'networks', '.']

>> Bigrams are: 
 [('&', 'Neal'), ('Neal', ','), (',', 'R.'), ('R.', 'M.'), ('M.', 'The'), ('The', 'wake-sleep'), ('wake-sleep', 'algorithm'), ('algorithm', 'unsupervised'), ('unsupervised', 'neural'), ('neural', 'networks'), ('networks', '.')]

>> Trigrams are: 
 [('&', 'Neal', ','), ('Neal', ',', 'R.'), (',', 'R.', 'M.'), ('R.', 'M.', 'The'), ('M.', 'The', 'wake-sleep'), ('The', 'wake-sleep', 'algorithm'), ('wake-sleep', 'algorithm', 'unsupervised'), ('algorithm', 'unsupervised', 'neural'), ('unsupervised', 'neural', 'networks'), ('neural', 'networks', '.')]

>> POS Tags are: 
 [('&', 'CC'), ('Neal', 'NNP'), (',', ','), ('R.', 'NNP'), ('M.', 'NNP'), ('The', 'DT'), ('wake-sleep', 'JJ'), ('algorithm', 'NN'), ('unsupervised', 'JJ'), ('neural', 'JJ'), ('networks', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['Neal', 'R. M.', 'The wake-sleep algorithm', 'unsupervised neural networks']

>> Named Entities are: 
 [('GPE', 'Neal')] 

>> Stemming using Porter Stemmer: 
 [('&', '&'), ('Neal', 'neal'), (',', ','), ('R.', 'r.'), ('M.', 'm.'), ('The', 'the'), ('wake-sleep', 'wake-sleep'), ('algorithm', 'algorithm'), ('unsupervised', 'unsupervis'), ('neural', 'neural'), ('networks', 'network'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('&', '&'), ('Neal', 'neal'), (',', ','), ('R.', 'r.'), ('M.', 'm.'), ('The', 'the'), ('wake-sleep', 'wake-sleep'), ('algorithm', 'algorithm'), ('unsupervised', 'unsupervis'), ('neural', 'neural'), ('networks', 'network'), ('.', '.')]

>> Lemmatization: 
 [('&', '&'), ('Neal', 'Neal'), (',', ','), ('R.', 'R.'), ('M.', 'M.'), ('The', 'The'), ('wake-sleep', 'wake-sleep'), ('algorithm', 'algorithm'), ('unsupervised', 'unsupervised'), ('neural', 'neural'), ('networks', 'network'), ('.', '.')]


------------------- Sentence 4 -------------------

Science 268, 1558–1161 (1995).

>> Tokens are: 
 ['Science', '268', ',', '1558–1161', '(', '1995', ')', '.']

>> Bigrams are: 
 [('Science', '268'), ('268', ','), (',', '1558–1161'), ('1558–1161', '('), ('(', '1995'), ('1995', ')'), (')', '.')]

>> Trigrams are: 
 [('Science', '268', ','), ('268', ',', '1558–1161'), (',', '1558–1161', '('), ('1558–1161', '(', '1995'), ('(', '1995', ')'), ('1995', ')', '.')]

>> POS Tags are: 
 [('Science', 'NN'), ('268', 'CD'), (',', ','), ('1558–1161', 'CD'), ('(', '('), ('1995', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['Science']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Science', 'scienc'), ('268', '268'), (',', ','), ('1558–1161', '1558–1161'), ('(', '('), ('1995', '1995'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Science', 'scienc'), ('268', '268'), (',', ','), ('1558–1161', '1558–1161'), ('(', '('), ('1995', '1995'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Science', 'Science'), ('268', '268'), (',', ','), ('1558–1161', '1558–1161'), ('(', '('), ('1995', '1995'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 349 ===========================================

92. Salakhutdinov, R. & Hinton, G. Deep Boltzmann machines. In Proc. International  Conference on Artificial Intelligence and Statistics 448–455 (2009).  

------------------- Sentence 1 -------------------

92.

>> Tokens are: 
 ['92', '.']

>> Bigrams are: 
 [('92', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('92', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('92', '92'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('92', '92'), ('.', '.')]

>> Lemmatization: 
 [('92', '92'), ('.', '.')]


------------------- Sentence 2 -------------------

Salakhutdinov, R. & Hinton, G. Deep Boltzmann machines.

>> Tokens are: 
 ['Salakhutdinov', ',', 'R.', '&', 'Hinton', ',', 'G.', 'Deep', 'Boltzmann', 'machines', '.']

>> Bigrams are: 
 [('Salakhutdinov', ','), (',', 'R.'), ('R.', '&'), ('&', 'Hinton'), ('Hinton', ','), (',', 'G.'), ('G.', 'Deep'), ('Deep', 'Boltzmann'), ('Boltzmann', 'machines'), ('machines', '.')]

>> Trigrams are: 
 [('Salakhutdinov', ',', 'R.'), (',', 'R.', '&'), ('R.', '&', 'Hinton'), ('&', 'Hinton', ','), ('Hinton', ',', 'G.'), (',', 'G.', 'Deep'), ('G.', 'Deep', 'Boltzmann'), ('Deep', 'Boltzmann', 'machines'), ('Boltzmann', 'machines', '.')]

>> POS Tags are: 
 [('Salakhutdinov', 'NNP'), (',', ','), ('R.', 'NNP'), ('&', 'CC'), ('Hinton', 'NNP'), (',', ','), ('G.', 'NNP'), ('Deep', 'NNP'), ('Boltzmann', 'NNP'), ('machines', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['Salakhutdinov', 'R.', 'Hinton', 'G. Deep Boltzmann machines']

>> Named Entities are: 
 [('GPE', 'Salakhutdinov'), ('GPE', 'Hinton')] 

>> Stemming using Porter Stemmer: 
 [('Salakhutdinov', 'salakhutdinov'), (',', ','), ('R.', 'r.'), ('&', '&'), ('Hinton', 'hinton'), (',', ','), ('G.', 'g.'), ('Deep', 'deep'), ('Boltzmann', 'boltzmann'), ('machines', 'machin'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Salakhutdinov', 'salakhutdinov'), (',', ','), ('R.', 'r.'), ('&', '&'), ('Hinton', 'hinton'), (',', ','), ('G.', 'g.'), ('Deep', 'deep'), ('Boltzmann', 'boltzmann'), ('machines', 'machin'), ('.', '.')]

>> Lemmatization: 
 [('Salakhutdinov', 'Salakhutdinov'), (',', ','), ('R.', 'R.'), ('&', '&'), ('Hinton', 'Hinton'), (',', ','), ('G.', 'G.'), ('Deep', 'Deep'), ('Boltzmann', 'Boltzmann'), ('machines', 'machine'), ('.', '.')]


------------------- Sentence 3 -------------------

In Proc.

>> Tokens are: 
 ['In', 'Proc', '.']

>> Bigrams are: 
 [('In', 'Proc'), ('Proc', '.')]

>> Trigrams are: 
 [('In', 'Proc', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('Proc', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Proc']

>> Named Entities are: 
 [('GPE', 'Proc')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('Proc', 'proc'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('Proc', 'proc'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('Proc', 'Proc'), ('.', '.')]


------------------- Sentence 4 -------------------

International  Conference on Artificial Intelligence and Statistics 448–455 (2009).

>> Tokens are: 
 ['International', 'Conference', 'Artificial', 'Intelligence', 'Statistics', '448–455', '(', '2009', ')', '.']

>> Bigrams are: 
 [('International', 'Conference'), ('Conference', 'Artificial'), ('Artificial', 'Intelligence'), ('Intelligence', 'Statistics'), ('Statistics', '448–455'), ('448–455', '('), ('(', '2009'), ('2009', ')'), (')', '.')]

>> Trigrams are: 
 [('International', 'Conference', 'Artificial'), ('Conference', 'Artificial', 'Intelligence'), ('Artificial', 'Intelligence', 'Statistics'), ('Intelligence', 'Statistics', '448–455'), ('Statistics', '448–455', '('), ('448–455', '(', '2009'), ('(', '2009', ')'), ('2009', ')', '.')]

>> POS Tags are: 
 [('International', 'NNP'), ('Conference', 'NNP'), ('Artificial', 'NNP'), ('Intelligence', 'NNP'), ('Statistics', 'NNPS'), ('448–455', 'CD'), ('(', '('), ('2009', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['International Conference Artificial Intelligence']

>> Named Entities are: 
 [('ORGANIZATION', 'International Conference Artificial Intelligence Statistics')] 

>> Stemming using Porter Stemmer: 
 [('International', 'intern'), ('Conference', 'confer'), ('Artificial', 'artifici'), ('Intelligence', 'intellig'), ('Statistics', 'statist'), ('448–455', '448–455'), ('(', '('), ('2009', '2009'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('International', 'intern'), ('Conference', 'confer'), ('Artificial', 'artifici'), ('Intelligence', 'intellig'), ('Statistics', 'statist'), ('448–455', '448–455'), ('(', '('), ('2009', '2009'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('International', 'International'), ('Conference', 'Conference'), ('Artificial', 'Artificial'), ('Intelligence', 'Intelligence'), ('Statistics', 'Statistics'), ('448–455', '448–455'), ('(', '('), ('2009', '2009'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 350 ===========================================

93. Vincent, P., Larochelle, H., Bengio, Y. & Manzagol, P.-A. Extracting and composing  robust features with denoising autoencoders. In Proc. 25th International  Conference on Machine Learning 1096–1103 (2008).  

------------------- Sentence 1 -------------------

93.

>> Tokens are: 
 ['93', '.']

>> Bigrams are: 
 [('93', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('93', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('93', '93'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('93', '93'), ('.', '.')]

>> Lemmatization: 
 [('93', '93'), ('.', '.')]


------------------- Sentence 2 -------------------

Vincent, P., Larochelle, H., Bengio, Y.

>> Tokens are: 
 ['Vincent', ',', 'P.', ',', 'Larochelle', ',', 'H.', ',', 'Bengio', ',', 'Y', '.']

>> Bigrams are: 
 [('Vincent', ','), (',', 'P.'), ('P.', ','), (',', 'Larochelle'), ('Larochelle', ','), (',', 'H.'), ('H.', ','), (',', 'Bengio'), ('Bengio', ','), (',', 'Y'), ('Y', '.')]

>> Trigrams are: 
 [('Vincent', ',', 'P.'), (',', 'P.', ','), ('P.', ',', 'Larochelle'), (',', 'Larochelle', ','), ('Larochelle', ',', 'H.'), (',', 'H.', ','), ('H.', ',', 'Bengio'), (',', 'Bengio', ','), ('Bengio', ',', 'Y'), (',', 'Y', '.')]

>> POS Tags are: 
 [('Vincent', 'NNP'), (',', ','), ('P.', 'NNP'), (',', ','), ('Larochelle', 'NNP'), (',', ','), ('H.', 'NNP'), (',', ','), ('Bengio', 'NNP'), (',', ','), ('Y', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Vincent', 'P.', 'Larochelle', 'H.', 'Bengio', 'Y']

>> Named Entities are: 
 [('GPE', 'Vincent'), ('GPE', 'Larochelle'), ('PERSON', 'Bengio')] 

>> Stemming using Porter Stemmer: 
 [('Vincent', 'vincent'), (',', ','), ('P.', 'p.'), (',', ','), ('Larochelle', 'larochel'), (',', ','), ('H.', 'h.'), (',', ','), ('Bengio', 'bengio'), (',', ','), ('Y', 'y'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Vincent', 'vincent'), (',', ','), ('P.', 'p.'), (',', ','), ('Larochelle', 'larochell'), (',', ','), ('H.', 'h.'), (',', ','), ('Bengio', 'bengio'), (',', ','), ('Y', 'y'), ('.', '.')]

>> Lemmatization: 
 [('Vincent', 'Vincent'), (',', ','), ('P.', 'P.'), (',', ','), ('Larochelle', 'Larochelle'), (',', ','), ('H.', 'H.'), (',', ','), ('Bengio', 'Bengio'), (',', ','), ('Y', 'Y'), ('.', '.')]


------------------- Sentence 3 -------------------

& Manzagol, P.-A.

>> Tokens are: 
 ['&', 'Manzagol', ',', 'P.-A', '.']

>> Bigrams are: 
 [('&', 'Manzagol'), ('Manzagol', ','), (',', 'P.-A'), ('P.-A', '.')]

>> Trigrams are: 
 [('&', 'Manzagol', ','), ('Manzagol', ',', 'P.-A'), (',', 'P.-A', '.')]

>> POS Tags are: 
 [('&', 'CC'), ('Manzagol', 'NNP'), (',', ','), ('P.-A', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Manzagol', 'P.-A']

>> Named Entities are: 
 [('GPE', 'Manzagol')] 

>> Stemming using Porter Stemmer: 
 [('&', '&'), ('Manzagol', 'manzagol'), (',', ','), ('P.-A', 'p.-a'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('&', '&'), ('Manzagol', 'manzagol'), (',', ','), ('P.-A', 'p.-a'), ('.', '.')]

>> Lemmatization: 
 [('&', '&'), ('Manzagol', 'Manzagol'), (',', ','), ('P.-A', 'P.-A'), ('.', '.')]


------------------- Sentence 4 -------------------

Extracting and composing  robust features with denoising autoencoders.

>> Tokens are: 
 ['Extracting', 'composing', 'robust', 'features', 'denoising', 'autoencoders', '.']

>> Bigrams are: 
 [('Extracting', 'composing'), ('composing', 'robust'), ('robust', 'features'), ('features', 'denoising'), ('denoising', 'autoencoders'), ('autoencoders', '.')]

>> Trigrams are: 
 [('Extracting', 'composing', 'robust'), ('composing', 'robust', 'features'), ('robust', 'features', 'denoising'), ('features', 'denoising', 'autoencoders'), ('denoising', 'autoencoders', '.')]

>> POS Tags are: 
 [('Extracting', 'VBG'), ('composing', 'VBG'), ('robust', 'JJ'), ('features', 'NNS'), ('denoising', 'VBG'), ('autoencoders', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['robust features', 'autoencoders']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Extracting', 'extract'), ('composing', 'compos'), ('robust', 'robust'), ('features', 'featur'), ('denoising', 'denois'), ('autoencoders', 'autoencod'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Extracting', 'extract'), ('composing', 'compos'), ('robust', 'robust'), ('features', 'featur'), ('denoising', 'denois'), ('autoencoders', 'autoencod'), ('.', '.')]

>> Lemmatization: 
 [('Extracting', 'Extracting'), ('composing', 'composing'), ('robust', 'robust'), ('features', 'feature'), ('denoising', 'denoising'), ('autoencoders', 'autoencoders'), ('.', '.')]


------------------- Sentence 5 -------------------

In Proc.

>> Tokens are: 
 ['In', 'Proc', '.']

>> Bigrams are: 
 [('In', 'Proc'), ('Proc', '.')]

>> Trigrams are: 
 [('In', 'Proc', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('Proc', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Proc']

>> Named Entities are: 
 [('GPE', 'Proc')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('Proc', 'proc'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('Proc', 'proc'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('Proc', 'Proc'), ('.', '.')]


------------------- Sentence 6 -------------------

25th International  Conference on Machine Learning 1096–1103 (2008).

>> Tokens are: 
 ['25th', 'International', 'Conference', 'Machine', 'Learning', '1096–1103', '(', '2008', ')', '.']

>> Bigrams are: 
 [('25th', 'International'), ('International', 'Conference'), ('Conference', 'Machine'), ('Machine', 'Learning'), ('Learning', '1096–1103'), ('1096–1103', '('), ('(', '2008'), ('2008', ')'), (')', '.')]

>> Trigrams are: 
 [('25th', 'International', 'Conference'), ('International', 'Conference', 'Machine'), ('Conference', 'Machine', 'Learning'), ('Machine', 'Learning', '1096–1103'), ('Learning', '1096–1103', '('), ('1096–1103', '(', '2008'), ('(', '2008', ')'), ('2008', ')', '.')]

>> POS Tags are: 
 [('25th', 'CD'), ('International', 'NNP'), ('Conference', 'NNP'), ('Machine', 'NNP'), ('Learning', 'NNP'), ('1096–1103', 'CD'), ('(', '('), ('2008', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['International Conference Machine Learning']

>> Named Entities are: 
 [('ORGANIZATION', 'International Conference Machine')] 

>> Stemming using Porter Stemmer: 
 [('25th', '25th'), ('International', 'intern'), ('Conference', 'confer'), ('Machine', 'machin'), ('Learning', 'learn'), ('1096–1103', '1096–1103'), ('(', '('), ('2008', '2008'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('25th', '25th'), ('International', 'intern'), ('Conference', 'confer'), ('Machine', 'machin'), ('Learning', 'learn'), ('1096–1103', '1096–1103'), ('(', '('), ('2008', '2008'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('25th', '25th'), ('International', 'International'), ('Conference', 'Conference'), ('Machine', 'Machine'), ('Learning', 'Learning'), ('1096–1103', '1096–1103'), ('(', '('), ('2008', '2008'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 351 ===========================================

94. Kavukcuoglu, K. et al. Learning convolutional feature hierarchies for visual  recognition. In Proc. Advances in Neural Information Processing Systems 23  1090–1098 (2010).  

------------------- Sentence 1 -------------------

94.

>> Tokens are: 
 ['94', '.']

>> Bigrams are: 
 [('94', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('94', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('94', '94'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('94', '94'), ('.', '.')]

>> Lemmatization: 
 [('94', '94'), ('.', '.')]


------------------- Sentence 2 -------------------

Kavukcuoglu, K. et al.

>> Tokens are: 
 ['Kavukcuoglu', ',', 'K.', 'et', 'al', '.']

>> Bigrams are: 
 [('Kavukcuoglu', ','), (',', 'K.'), ('K.', 'et'), ('et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('Kavukcuoglu', ',', 'K.'), (',', 'K.', 'et'), ('K.', 'et', 'al'), ('et', 'al', '.')]

>> POS Tags are: 
 [('Kavukcuoglu', 'NNP'), (',', ','), ('K.', 'NNP'), ('et', 'CC'), ('al', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Kavukcuoglu', 'K.', 'al']

>> Named Entities are: 
 [('GPE', 'Kavukcuoglu')] 

>> Stemming using Porter Stemmer: 
 [('Kavukcuoglu', 'kavukcuoglu'), (',', ','), ('K.', 'k.'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Kavukcuoglu', 'kavukcuoglu'), (',', ','), ('K.', 'k.'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('Kavukcuoglu', 'Kavukcuoglu'), (',', ','), ('K.', 'K.'), ('et', 'et'), ('al', 'al'), ('.', '.')]


------------------- Sentence 3 -------------------

Learning convolutional feature hierarchies for visual  recognition.

>> Tokens are: 
 ['Learning', 'convolutional', 'feature', 'hierarchies', 'visual', 'recognition', '.']

>> Bigrams are: 
 [('Learning', 'convolutional'), ('convolutional', 'feature'), ('feature', 'hierarchies'), ('hierarchies', 'visual'), ('visual', 'recognition'), ('recognition', '.')]

>> Trigrams are: 
 [('Learning', 'convolutional', 'feature'), ('convolutional', 'feature', 'hierarchies'), ('feature', 'hierarchies', 'visual'), ('hierarchies', 'visual', 'recognition'), ('visual', 'recognition', '.')]

>> POS Tags are: 
 [('Learning', 'VBG'), ('convolutional', 'JJ'), ('feature', 'NN'), ('hierarchies', 'NNS'), ('visual', 'JJ'), ('recognition', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['convolutional feature hierarchies', 'visual recognition']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Learning', 'learn'), ('convolutional', 'convolut'), ('feature', 'featur'), ('hierarchies', 'hierarchi'), ('visual', 'visual'), ('recognition', 'recognit'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Learning', 'learn'), ('convolutional', 'convolut'), ('feature', 'featur'), ('hierarchies', 'hierarchi'), ('visual', 'visual'), ('recognition', 'recognit'), ('.', '.')]

>> Lemmatization: 
 [('Learning', 'Learning'), ('convolutional', 'convolutional'), ('feature', 'feature'), ('hierarchies', 'hierarchy'), ('visual', 'visual'), ('recognition', 'recognition'), ('.', '.')]


------------------- Sentence 4 -------------------

In Proc.

>> Tokens are: 
 ['In', 'Proc', '.']

>> Bigrams are: 
 [('In', 'Proc'), ('Proc', '.')]

>> Trigrams are: 
 [('In', 'Proc', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('Proc', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Proc']

>> Named Entities are: 
 [('GPE', 'Proc')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('Proc', 'proc'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('Proc', 'proc'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('Proc', 'Proc'), ('.', '.')]


------------------- Sentence 5 -------------------

Advances in Neural Information Processing Systems 23  1090–1098 (2010).

>> Tokens are: 
 ['Advances', 'Neural', 'Information', 'Processing', 'Systems', '23', '1090–1098', '(', '2010', ')', '.']

>> Bigrams are: 
 [('Advances', 'Neural'), ('Neural', 'Information'), ('Information', 'Processing'), ('Processing', 'Systems'), ('Systems', '23'), ('23', '1090–1098'), ('1090–1098', '('), ('(', '2010'), ('2010', ')'), (')', '.')]

>> Trigrams are: 
 [('Advances', 'Neural', 'Information'), ('Neural', 'Information', 'Processing'), ('Information', 'Processing', 'Systems'), ('Processing', 'Systems', '23'), ('Systems', '23', '1090–1098'), ('23', '1090–1098', '('), ('1090–1098', '(', '2010'), ('(', '2010', ')'), ('2010', ')', '.')]

>> POS Tags are: 
 [('Advances', 'NNS'), ('Neural', 'NNP'), ('Information', 'NNP'), ('Processing', 'NNP'), ('Systems', 'NNPS'), ('23', 'CD'), ('1090–1098', 'CD'), ('(', '('), ('2010', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['Advances Neural Information Processing']

>> Named Entities are: 
 [('ORGANIZATION', 'Neural Information Processing Systems')] 

>> Stemming using Porter Stemmer: 
 [('Advances', 'advanc'), ('Neural', 'neural'), ('Information', 'inform'), ('Processing', 'process'), ('Systems', 'system'), ('23', '23'), ('1090–1098', '1090–1098'), ('(', '('), ('2010', '2010'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Advances', 'advanc'), ('Neural', 'neural'), ('Information', 'inform'), ('Processing', 'process'), ('Systems', 'system'), ('23', '23'), ('1090–1098', '1090–1098'), ('(', '('), ('2010', '2010'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Advances', 'Advances'), ('Neural', 'Neural'), ('Information', 'Information'), ('Processing', 'Processing'), ('Systems', 'Systems'), ('23', '23'), ('1090–1098', '1090–1098'), ('(', '('), ('2010', '2010'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 352 ===========================================

95. Gregor, K. & LeCun, Y. Learning fast approximations of sparse coding. In Proc.  International Conference on Machine Learning 399–406 (2010).  

------------------- Sentence 1 -------------------

95.

>> Tokens are: 
 ['95', '.']

>> Bigrams are: 
 [('95', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('95', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('95', '95'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('95', '95'), ('.', '.')]

>> Lemmatization: 
 [('95', '95'), ('.', '.')]


------------------- Sentence 2 -------------------

Gregor, K. & LeCun, Y.

>> Tokens are: 
 ['Gregor', ',', 'K.', '&', 'LeCun', ',', 'Y', '.']

>> Bigrams are: 
 [('Gregor', ','), (',', 'K.'), ('K.', '&'), ('&', 'LeCun'), ('LeCun', ','), (',', 'Y'), ('Y', '.')]

>> Trigrams are: 
 [('Gregor', ',', 'K.'), (',', 'K.', '&'), ('K.', '&', 'LeCun'), ('&', 'LeCun', ','), ('LeCun', ',', 'Y'), (',', 'Y', '.')]

>> POS Tags are: 
 [('Gregor', 'NNP'), (',', ','), ('K.', 'NNP'), ('&', 'CC'), ('LeCun', 'NNP'), (',', ','), ('Y', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Gregor', 'K.', 'LeCun', 'Y']

>> Named Entities are: 
 [('GPE', 'Gregor'), ('ORGANIZATION', 'LeCun')] 

>> Stemming using Porter Stemmer: 
 [('Gregor', 'gregor'), (',', ','), ('K.', 'k.'), ('&', '&'), ('LeCun', 'lecun'), (',', ','), ('Y', 'y'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Gregor', 'gregor'), (',', ','), ('K.', 'k.'), ('&', '&'), ('LeCun', 'lecun'), (',', ','), ('Y', 'y'), ('.', '.')]

>> Lemmatization: 
 [('Gregor', 'Gregor'), (',', ','), ('K.', 'K.'), ('&', '&'), ('LeCun', 'LeCun'), (',', ','), ('Y', 'Y'), ('.', '.')]


------------------- Sentence 3 -------------------

Learning fast approximations of sparse coding.

>> Tokens are: 
 ['Learning', 'fast', 'approximations', 'sparse', 'coding', '.']

>> Bigrams are: 
 [('Learning', 'fast'), ('fast', 'approximations'), ('approximations', 'sparse'), ('sparse', 'coding'), ('coding', '.')]

>> Trigrams are: 
 [('Learning', 'fast', 'approximations'), ('fast', 'approximations', 'sparse'), ('approximations', 'sparse', 'coding'), ('sparse', 'coding', '.')]

>> POS Tags are: 
 [('Learning', 'VBG'), ('fast', 'JJ'), ('approximations', 'NNS'), ('sparse', 'VBP'), ('coding', 'VBG'), ('.', '.')]

>> Noun Phrases are: 
 ['fast approximations']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Learning', 'learn'), ('fast', 'fast'), ('approximations', 'approxim'), ('sparse', 'spars'), ('coding', 'code'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Learning', 'learn'), ('fast', 'fast'), ('approximations', 'approxim'), ('sparse', 'spars'), ('coding', 'code'), ('.', '.')]

>> Lemmatization: 
 [('Learning', 'Learning'), ('fast', 'fast'), ('approximations', 'approximation'), ('sparse', 'sparse'), ('coding', 'coding'), ('.', '.')]


------------------- Sentence 4 -------------------

In Proc.

>> Tokens are: 
 ['In', 'Proc', '.']

>> Bigrams are: 
 [('In', 'Proc'), ('Proc', '.')]

>> Trigrams are: 
 [('In', 'Proc', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('Proc', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Proc']

>> Named Entities are: 
 [('GPE', 'Proc')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('Proc', 'proc'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('Proc', 'proc'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('Proc', 'Proc'), ('.', '.')]


------------------- Sentence 5 -------------------

International Conference on Machine Learning 399–406 (2010).

>> Tokens are: 
 ['International', 'Conference', 'Machine', 'Learning', '399–406', '(', '2010', ')', '.']

>> Bigrams are: 
 [('International', 'Conference'), ('Conference', 'Machine'), ('Machine', 'Learning'), ('Learning', '399–406'), ('399–406', '('), ('(', '2010'), ('2010', ')'), (')', '.')]

>> Trigrams are: 
 [('International', 'Conference', 'Machine'), ('Conference', 'Machine', 'Learning'), ('Machine', 'Learning', '399–406'), ('Learning', '399–406', '('), ('399–406', '(', '2010'), ('(', '2010', ')'), ('2010', ')', '.')]

>> POS Tags are: 
 [('International', 'NNP'), ('Conference', 'NNP'), ('Machine', 'NNP'), ('Learning', 'NNP'), ('399–406', 'CD'), ('(', '('), ('2010', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['International Conference Machine Learning']

>> Named Entities are: 
 [('ORGANIZATION', 'International Conference Machine')] 

>> Stemming using Porter Stemmer: 
 [('International', 'intern'), ('Conference', 'confer'), ('Machine', 'machin'), ('Learning', 'learn'), ('399–406', '399–406'), ('(', '('), ('2010', '2010'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('International', 'intern'), ('Conference', 'confer'), ('Machine', 'machin'), ('Learning', 'learn'), ('399–406', '399–406'), ('(', '('), ('2010', '2010'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('International', 'International'), ('Conference', 'Conference'), ('Machine', 'Machine'), ('Learning', 'Learning'), ('399–406', '399–406'), ('(', '('), ('2010', '2010'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 353 ===========================================

96. Ranzato, M., Mnih, V., Susskind, J. M. & Hinton, G. E. Modeling natural images  using gated MRFs. IEEE Trans. Pattern Anal. Machine Intell. 35, 2206–2222  (2013).  

------------------- Sentence 1 -------------------

96.

>> Tokens are: 
 ['96', '.']

>> Bigrams are: 
 [('96', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('96', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('96', '96'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('96', '96'), ('.', '.')]

>> Lemmatization: 
 [('96', '96'), ('.', '.')]


------------------- Sentence 2 -------------------

Ranzato, M., Mnih, V., Susskind, J. M. & Hinton, G. E. Modeling natural images  using gated MRFs.

>> Tokens are: 
 ['Ranzato', ',', 'M.', ',', 'Mnih', ',', 'V.', ',', 'Susskind', ',', 'J.', 'M.', '&', 'Hinton', ',', 'G.', 'E.', 'Modeling', 'natural', 'images', 'using', 'gated', 'MRFs', '.']

>> Bigrams are: 
 [('Ranzato', ','), (',', 'M.'), ('M.', ','), (',', 'Mnih'), ('Mnih', ','), (',', 'V.'), ('V.', ','), (',', 'Susskind'), ('Susskind', ','), (',', 'J.'), ('J.', 'M.'), ('M.', '&'), ('&', 'Hinton'), ('Hinton', ','), (',', 'G.'), ('G.', 'E.'), ('E.', 'Modeling'), ('Modeling', 'natural'), ('natural', 'images'), ('images', 'using'), ('using', 'gated'), ('gated', 'MRFs'), ('MRFs', '.')]

>> Trigrams are: 
 [('Ranzato', ',', 'M.'), (',', 'M.', ','), ('M.', ',', 'Mnih'), (',', 'Mnih', ','), ('Mnih', ',', 'V.'), (',', 'V.', ','), ('V.', ',', 'Susskind'), (',', 'Susskind', ','), ('Susskind', ',', 'J.'), (',', 'J.', 'M.'), ('J.', 'M.', '&'), ('M.', '&', 'Hinton'), ('&', 'Hinton', ','), ('Hinton', ',', 'G.'), (',', 'G.', 'E.'), ('G.', 'E.', 'Modeling'), ('E.', 'Modeling', 'natural'), ('Modeling', 'natural', 'images'), ('natural', 'images', 'using'), ('images', 'using', 'gated'), ('using', 'gated', 'MRFs'), ('gated', 'MRFs', '.')]

>> POS Tags are: 
 [('Ranzato', 'NNP'), (',', ','), ('M.', 'NNP'), (',', ','), ('Mnih', 'NNP'), (',', ','), ('V.', 'NNP'), (',', ','), ('Susskind', 'NNP'), (',', ','), ('J.', 'NNP'), ('M.', 'NNP'), ('&', 'CC'), ('Hinton', 'NNP'), (',', ','), ('G.', 'NNP'), ('E.', 'NNP'), ('Modeling', 'NNP'), ('natural', 'JJ'), ('images', 'NNS'), ('using', 'VBG'), ('gated', 'JJ'), ('MRFs', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Ranzato', 'M.', 'Mnih', 'V.', 'Susskind', 'J. M.', 'Hinton', 'G. E. Modeling', 'natural images', 'gated MRFs']

>> Named Entities are: 
 [('GPE', 'Ranzato'), ('PERSON', 'Mnih'), ('GPE', 'Susskind'), ('PERSON', 'J. M.'), ('GPE', 'Hinton'), ('ORGANIZATION', 'MRFs')] 

>> Stemming using Porter Stemmer: 
 [('Ranzato', 'ranzato'), (',', ','), ('M.', 'm.'), (',', ','), ('Mnih', 'mnih'), (',', ','), ('V.', 'v.'), (',', ','), ('Susskind', 'susskind'), (',', ','), ('J.', 'j.'), ('M.', 'm.'), ('&', '&'), ('Hinton', 'hinton'), (',', ','), ('G.', 'g.'), ('E.', 'e.'), ('Modeling', 'model'), ('natural', 'natur'), ('images', 'imag'), ('using', 'use'), ('gated', 'gate'), ('MRFs', 'mrf'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Ranzato', 'ranzato'), (',', ','), ('M.', 'm.'), (',', ','), ('Mnih', 'mnih'), (',', ','), ('V.', 'v.'), (',', ','), ('Susskind', 'susskind'), (',', ','), ('J.', 'j.'), ('M.', 'm.'), ('&', '&'), ('Hinton', 'hinton'), (',', ','), ('G.', 'g.'), ('E.', 'e.'), ('Modeling', 'model'), ('natural', 'natur'), ('images', 'imag'), ('using', 'use'), ('gated', 'gate'), ('MRFs', 'mrfs'), ('.', '.')]

>> Lemmatization: 
 [('Ranzato', 'Ranzato'), (',', ','), ('M.', 'M.'), (',', ','), ('Mnih', 'Mnih'), (',', ','), ('V.', 'V.'), (',', ','), ('Susskind', 'Susskind'), (',', ','), ('J.', 'J.'), ('M.', 'M.'), ('&', '&'), ('Hinton', 'Hinton'), (',', ','), ('G.', 'G.'), ('E.', 'E.'), ('Modeling', 'Modeling'), ('natural', 'natural'), ('images', 'image'), ('using', 'using'), ('gated', 'gated'), ('MRFs', 'MRFs'), ('.', '.')]


------------------- Sentence 3 -------------------

IEEE Trans.

>> Tokens are: 
 ['IEEE', 'Trans', '.']

>> Bigrams are: 
 [('IEEE', 'Trans'), ('Trans', '.')]

>> Trigrams are: 
 [('IEEE', 'Trans', '.')]

>> POS Tags are: 
 [('IEEE', 'NNP'), ('Trans', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['IEEE Trans']

>> Named Entities are: 
 [('ORGANIZATION', 'IEEE Trans')] 

>> Stemming using Porter Stemmer: 
 [('IEEE', 'ieee'), ('Trans', 'tran'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('IEEE', 'ieee'), ('Trans', 'tran'), ('.', '.')]

>> Lemmatization: 
 [('IEEE', 'IEEE'), ('Trans', 'Trans'), ('.', '.')]


------------------- Sentence 4 -------------------

Pattern Anal.

>> Tokens are: 
 ['Pattern', 'Anal', '.']

>> Bigrams are: 
 [('Pattern', 'Anal'), ('Anal', '.')]

>> Trigrams are: 
 [('Pattern', 'Anal', '.')]

>> POS Tags are: 
 [('Pattern', 'NNP'), ('Anal', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Pattern Anal']

>> Named Entities are: 
 [('PERSON', 'Pattern'), ('ORGANIZATION', 'Anal')] 

>> Stemming using Porter Stemmer: 
 [('Pattern', 'pattern'), ('Anal', 'anal'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Pattern', 'pattern'), ('Anal', 'anal'), ('.', '.')]

>> Lemmatization: 
 [('Pattern', 'Pattern'), ('Anal', 'Anal'), ('.', '.')]


------------------- Sentence 5 -------------------

Machine Intell.

>> Tokens are: 
 ['Machine', 'Intell', '.']

>> Bigrams are: 
 [('Machine', 'Intell'), ('Intell', '.')]

>> Trigrams are: 
 [('Machine', 'Intell', '.')]

>> POS Tags are: 
 [('Machine', 'NN'), ('Intell', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Machine Intell']

>> Named Entities are: 
 [('PERSON', 'Machine'), ('ORGANIZATION', 'Intell')] 

>> Stemming using Porter Stemmer: 
 [('Machine', 'machin'), ('Intell', 'intel'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Machine', 'machin'), ('Intell', 'intel'), ('.', '.')]

>> Lemmatization: 
 [('Machine', 'Machine'), ('Intell', 'Intell'), ('.', '.')]


------------------- Sentence 6 -------------------

35, 2206–2222  (2013).

>> Tokens are: 
 ['35', ',', '2206–2222', '(', '2013', ')', '.']

>> Bigrams are: 
 [('35', ','), (',', '2206–2222'), ('2206–2222', '('), ('(', '2013'), ('2013', ')'), (')', '.')]

>> Trigrams are: 
 [('35', ',', '2206–2222'), (',', '2206–2222', '('), ('2206–2222', '(', '2013'), ('(', '2013', ')'), ('2013', ')', '.')]

>> POS Tags are: 
 [('35', 'CD'), (',', ','), ('2206–2222', 'CD'), ('(', '('), ('2013', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('35', '35'), (',', ','), ('2206–2222', '2206–2222'), ('(', '('), ('2013', '2013'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('35', '35'), (',', ','), ('2206–2222', '2206–2222'), ('(', '('), ('2013', '2013'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('35', '35'), (',', ','), ('2206–2222', '2206–2222'), ('(', '('), ('2013', '2013'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 354 ===========================================

97. Bengio, Y., Thibodeau-Laufer, E., Alain, G. & Yosinski, J. Deep generative  stochastic networks trainable by backprop. In Proc. 31st International  Conference on Machine Learning 226–234 (2014).  

------------------- Sentence 1 -------------------

97.

>> Tokens are: 
 ['97', '.']

>> Bigrams are: 
 [('97', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('97', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('97', '97'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('97', '97'), ('.', '.')]

>> Lemmatization: 
 [('97', '97'), ('.', '.')]


------------------- Sentence 2 -------------------

Bengio, Y., Thibodeau-Laufer, E., Alain, G. & Yosinski, J.

>> Tokens are: 
 ['Bengio', ',', 'Y.', ',', 'Thibodeau-Laufer', ',', 'E.', ',', 'Alain', ',', 'G.', '&', 'Yosinski', ',', 'J', '.']

>> Bigrams are: 
 [('Bengio', ','), (',', 'Y.'), ('Y.', ','), (',', 'Thibodeau-Laufer'), ('Thibodeau-Laufer', ','), (',', 'E.'), ('E.', ','), (',', 'Alain'), ('Alain', ','), (',', 'G.'), ('G.', '&'), ('&', 'Yosinski'), ('Yosinski', ','), (',', 'J'), ('J', '.')]

>> Trigrams are: 
 [('Bengio', ',', 'Y.'), (',', 'Y.', ','), ('Y.', ',', 'Thibodeau-Laufer'), (',', 'Thibodeau-Laufer', ','), ('Thibodeau-Laufer', ',', 'E.'), (',', 'E.', ','), ('E.', ',', 'Alain'), (',', 'Alain', ','), ('Alain', ',', 'G.'), (',', 'G.', '&'), ('G.', '&', 'Yosinski'), ('&', 'Yosinski', ','), ('Yosinski', ',', 'J'), (',', 'J', '.')]

>> POS Tags are: 
 [('Bengio', 'NNP'), (',', ','), ('Y.', 'NNP'), (',', ','), ('Thibodeau-Laufer', 'NNP'), (',', ','), ('E.', 'NNP'), (',', ','), ('Alain', 'NNP'), (',', ','), ('G.', 'NNP'), ('&', 'CC'), ('Yosinski', 'NNP'), (',', ','), ('J', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Bengio', 'Y.', 'Thibodeau-Laufer', 'E.', 'Alain', 'G.', 'Yosinski', 'J']

>> Named Entities are: 
 [('GPE', 'Bengio'), ('GPE', 'Alain'), ('PERSON', 'Yosinski')] 

>> Stemming using Porter Stemmer: 
 [('Bengio', 'bengio'), (',', ','), ('Y.', 'y.'), (',', ','), ('Thibodeau-Laufer', 'thibodeau-lauf'), (',', ','), ('E.', 'e.'), (',', ','), ('Alain', 'alain'), (',', ','), ('G.', 'g.'), ('&', '&'), ('Yosinski', 'yosinski'), (',', ','), ('J', 'j'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Bengio', 'bengio'), (',', ','), ('Y.', 'y.'), (',', ','), ('Thibodeau-Laufer', 'thibodeau-lauf'), (',', ','), ('E.', 'e.'), (',', ','), ('Alain', 'alain'), (',', ','), ('G.', 'g.'), ('&', '&'), ('Yosinski', 'yosinski'), (',', ','), ('J', 'j'), ('.', '.')]

>> Lemmatization: 
 [('Bengio', 'Bengio'), (',', ','), ('Y.', 'Y.'), (',', ','), ('Thibodeau-Laufer', 'Thibodeau-Laufer'), (',', ','), ('E.', 'E.'), (',', ','), ('Alain', 'Alain'), (',', ','), ('G.', 'G.'), ('&', '&'), ('Yosinski', 'Yosinski'), (',', ','), ('J', 'J'), ('.', '.')]


------------------- Sentence 3 -------------------

Deep generative  stochastic networks trainable by backprop.

>> Tokens are: 
 ['Deep', 'generative', 'stochastic', 'networks', 'trainable', 'backprop', '.']

>> Bigrams are: 
 [('Deep', 'generative'), ('generative', 'stochastic'), ('stochastic', 'networks'), ('networks', 'trainable'), ('trainable', 'backprop'), ('backprop', '.')]

>> Trigrams are: 
 [('Deep', 'generative', 'stochastic'), ('generative', 'stochastic', 'networks'), ('stochastic', 'networks', 'trainable'), ('networks', 'trainable', 'backprop'), ('trainable', 'backprop', '.')]

>> POS Tags are: 
 [('Deep', 'JJ'), ('generative', 'JJ'), ('stochastic', 'JJ'), ('networks', 'NNS'), ('trainable', 'JJ'), ('backprop', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Deep generative stochastic networks', 'trainable backprop']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Deep', 'deep'), ('generative', 'gener'), ('stochastic', 'stochast'), ('networks', 'network'), ('trainable', 'trainabl'), ('backprop', 'backprop'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Deep', 'deep'), ('generative', 'generat'), ('stochastic', 'stochast'), ('networks', 'network'), ('trainable', 'trainabl'), ('backprop', 'backprop'), ('.', '.')]

>> Lemmatization: 
 [('Deep', 'Deep'), ('generative', 'generative'), ('stochastic', 'stochastic'), ('networks', 'network'), ('trainable', 'trainable'), ('backprop', 'backprop'), ('.', '.')]


------------------- Sentence 4 -------------------

In Proc.

>> Tokens are: 
 ['In', 'Proc', '.']

>> Bigrams are: 
 [('In', 'Proc'), ('Proc', '.')]

>> Trigrams are: 
 [('In', 'Proc', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('Proc', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Proc']

>> Named Entities are: 
 [('GPE', 'Proc')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('Proc', 'proc'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('Proc', 'proc'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('Proc', 'Proc'), ('.', '.')]


------------------- Sentence 5 -------------------

31st International  Conference on Machine Learning 226–234 (2014).

>> Tokens are: 
 ['31st', 'International', 'Conference', 'Machine', 'Learning', '226–234', '(', '2014', ')', '.']

>> Bigrams are: 
 [('31st', 'International'), ('International', 'Conference'), ('Conference', 'Machine'), ('Machine', 'Learning'), ('Learning', '226–234'), ('226–234', '('), ('(', '2014'), ('2014', ')'), (')', '.')]

>> Trigrams are: 
 [('31st', 'International', 'Conference'), ('International', 'Conference', 'Machine'), ('Conference', 'Machine', 'Learning'), ('Machine', 'Learning', '226–234'), ('Learning', '226–234', '('), ('226–234', '(', '2014'), ('(', '2014', ')'), ('2014', ')', '.')]

>> POS Tags are: 
 [('31st', 'CD'), ('International', 'NNP'), ('Conference', 'NNP'), ('Machine', 'NNP'), ('Learning', 'NNP'), ('226–234', 'CD'), ('(', '('), ('2014', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['International Conference Machine Learning']

>> Named Entities are: 
 [('ORGANIZATION', 'International Conference Machine')] 

>> Stemming using Porter Stemmer: 
 [('31st', '31st'), ('International', 'intern'), ('Conference', 'confer'), ('Machine', 'machin'), ('Learning', 'learn'), ('226–234', '226–234'), ('(', '('), ('2014', '2014'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('31st', '31st'), ('International', 'intern'), ('Conference', 'confer'), ('Machine', 'machin'), ('Learning', 'learn'), ('226–234', '226–234'), ('(', '('), ('2014', '2014'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('31st', '31st'), ('International', 'International'), ('Conference', 'Conference'), ('Machine', 'Machine'), ('Learning', 'Learning'), ('226–234', '226–234'), ('(', '('), ('2014', '2014'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 355 ===========================================

98. Kingma, D., Rezende, D., Mohamed, S. & Welling, M. Semi-supervised learning  with deep generative models. In Proc. Advances in Neural Information Processing  Systems 27 3581–3589 (2014).  

------------------- Sentence 1 -------------------

98.

>> Tokens are: 
 ['98', '.']

>> Bigrams are: 
 [('98', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('98', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('98', '98'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('98', '98'), ('.', '.')]

>> Lemmatization: 
 [('98', '98'), ('.', '.')]


------------------- Sentence 2 -------------------

Kingma, D., Rezende, D., Mohamed, S. & Welling, M. Semi-supervised learning  with deep generative models.

>> Tokens are: 
 ['Kingma', ',', 'D.', ',', 'Rezende', ',', 'D.', ',', 'Mohamed', ',', 'S.', '&', 'Welling', ',', 'M.', 'Semi-supervised', 'learning', 'deep', 'generative', 'models', '.']

>> Bigrams are: 
 [('Kingma', ','), (',', 'D.'), ('D.', ','), (',', 'Rezende'), ('Rezende', ','), (',', 'D.'), ('D.', ','), (',', 'Mohamed'), ('Mohamed', ','), (',', 'S.'), ('S.', '&'), ('&', 'Welling'), ('Welling', ','), (',', 'M.'), ('M.', 'Semi-supervised'), ('Semi-supervised', 'learning'), ('learning', 'deep'), ('deep', 'generative'), ('generative', 'models'), ('models', '.')]

>> Trigrams are: 
 [('Kingma', ',', 'D.'), (',', 'D.', ','), ('D.', ',', 'Rezende'), (',', 'Rezende', ','), ('Rezende', ',', 'D.'), (',', 'D.', ','), ('D.', ',', 'Mohamed'), (',', 'Mohamed', ','), ('Mohamed', ',', 'S.'), (',', 'S.', '&'), ('S.', '&', 'Welling'), ('&', 'Welling', ','), ('Welling', ',', 'M.'), (',', 'M.', 'Semi-supervised'), ('M.', 'Semi-supervised', 'learning'), ('Semi-supervised', 'learning', 'deep'), ('learning', 'deep', 'generative'), ('deep', 'generative', 'models'), ('generative', 'models', '.')]

>> POS Tags are: 
 [('Kingma', 'NNP'), (',', ','), ('D.', 'NNP'), (',', ','), ('Rezende', 'NNP'), (',', ','), ('D.', 'NNP'), (',', ','), ('Mohamed', 'NNP'), (',', ','), ('S.', 'NNP'), ('&', 'CC'), ('Welling', 'NNP'), (',', ','), ('M.', 'NNP'), ('Semi-supervised', 'JJ'), ('learning', 'VBG'), ('deep', 'JJ'), ('generative', 'JJ'), ('models', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['Kingma', 'D.', 'Rezende', 'D.', 'Mohamed', 'S.', 'Welling', 'M.', 'deep generative models']

>> Named Entities are: 
 [('GPE', 'Kingma'), ('PERSON', 'Rezende'), ('PERSON', 'Mohamed')] 

>> Stemming using Porter Stemmer: 
 [('Kingma', 'kingma'), (',', ','), ('D.', 'd.'), (',', ','), ('Rezende', 'rezend'), (',', ','), ('D.', 'd.'), (',', ','), ('Mohamed', 'moham'), (',', ','), ('S.', 's.'), ('&', '&'), ('Welling', 'well'), (',', ','), ('M.', 'm.'), ('Semi-supervised', 'semi-supervis'), ('learning', 'learn'), ('deep', 'deep'), ('generative', 'gener'), ('models', 'model'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Kingma', 'kingma'), (',', ','), ('D.', 'd.'), (',', ','), ('Rezende', 'rezend'), (',', ','), ('D.', 'd.'), (',', ','), ('Mohamed', 'moham'), (',', ','), ('S.', 's.'), ('&', '&'), ('Welling', 'well'), (',', ','), ('M.', 'm.'), ('Semi-supervised', 'semi-supervis'), ('learning', 'learn'), ('deep', 'deep'), ('generative', 'generat'), ('models', 'model'), ('.', '.')]

>> Lemmatization: 
 [('Kingma', 'Kingma'), (',', ','), ('D.', 'D.'), (',', ','), ('Rezende', 'Rezende'), (',', ','), ('D.', 'D.'), (',', ','), ('Mohamed', 'Mohamed'), (',', ','), ('S.', 'S.'), ('&', '&'), ('Welling', 'Welling'), (',', ','), ('M.', 'M.'), ('Semi-supervised', 'Semi-supervised'), ('learning', 'learning'), ('deep', 'deep'), ('generative', 'generative'), ('models', 'model'), ('.', '.')]


------------------- Sentence 3 -------------------

In Proc.

>> Tokens are: 
 ['In', 'Proc', '.']

>> Bigrams are: 
 [('In', 'Proc'), ('Proc', '.')]

>> Trigrams are: 
 [('In', 'Proc', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('Proc', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Proc']

>> Named Entities are: 
 [('GPE', 'Proc')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('Proc', 'proc'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('Proc', 'proc'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('Proc', 'Proc'), ('.', '.')]


------------------- Sentence 4 -------------------

Advances in Neural Information Processing  Systems 27 3581–3589 (2014).

>> Tokens are: 
 ['Advances', 'Neural', 'Information', 'Processing', 'Systems', '27', '3581–3589', '(', '2014', ')', '.']

>> Bigrams are: 
 [('Advances', 'Neural'), ('Neural', 'Information'), ('Information', 'Processing'), ('Processing', 'Systems'), ('Systems', '27'), ('27', '3581–3589'), ('3581–3589', '('), ('(', '2014'), ('2014', ')'), (')', '.')]

>> Trigrams are: 
 [('Advances', 'Neural', 'Information'), ('Neural', 'Information', 'Processing'), ('Information', 'Processing', 'Systems'), ('Processing', 'Systems', '27'), ('Systems', '27', '3581–3589'), ('27', '3581–3589', '('), ('3581–3589', '(', '2014'), ('(', '2014', ')'), ('2014', ')', '.')]

>> POS Tags are: 
 [('Advances', 'NNS'), ('Neural', 'NNP'), ('Information', 'NNP'), ('Processing', 'NNP'), ('Systems', 'NNPS'), ('27', 'CD'), ('3581–3589', 'CD'), ('(', '('), ('2014', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['Advances Neural Information Processing']

>> Named Entities are: 
 [('ORGANIZATION', 'Neural Information Processing Systems')] 

>> Stemming using Porter Stemmer: 
 [('Advances', 'advanc'), ('Neural', 'neural'), ('Information', 'inform'), ('Processing', 'process'), ('Systems', 'system'), ('27', '27'), ('3581–3589', '3581–3589'), ('(', '('), ('2014', '2014'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Advances', 'advanc'), ('Neural', 'neural'), ('Information', 'inform'), ('Processing', 'process'), ('Systems', 'system'), ('27', '27'), ('3581–3589', '3581–3589'), ('(', '('), ('2014', '2014'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Advances', 'Advances'), ('Neural', 'Neural'), ('Information', 'Information'), ('Processing', 'Processing'), ('Systems', 'Systems'), ('27', '27'), ('3581–3589', '3581–3589'), ('(', '('), ('2014', '2014'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 356 ===========================================

99. Ba, J., Mnih, V. & Kavukcuoglu, K. Multiple object recognition with visual  attention. In Proc. International Conference on Learning Representations http:// arxiv.org/abs/1412.7755 (2014).  

------------------- Sentence 1 -------------------

99.

>> Tokens are: 
 ['99', '.']

>> Bigrams are: 
 [('99', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('99', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('99', '99'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('99', '99'), ('.', '.')]

>> Lemmatization: 
 [('99', '99'), ('.', '.')]


------------------- Sentence 2 -------------------

Ba, J., Mnih, V. & Kavukcuoglu, K. Multiple object recognition with visual  attention.

>> Tokens are: 
 ['Ba', ',', 'J.', ',', 'Mnih', ',', 'V.', '&', 'Kavukcuoglu', ',', 'K.', 'Multiple', 'object', 'recognition', 'visual', 'attention', '.']

>> Bigrams are: 
 [('Ba', ','), (',', 'J.'), ('J.', ','), (',', 'Mnih'), ('Mnih', ','), (',', 'V.'), ('V.', '&'), ('&', 'Kavukcuoglu'), ('Kavukcuoglu', ','), (',', 'K.'), ('K.', 'Multiple'), ('Multiple', 'object'), ('object', 'recognition'), ('recognition', 'visual'), ('visual', 'attention'), ('attention', '.')]

>> Trigrams are: 
 [('Ba', ',', 'J.'), (',', 'J.', ','), ('J.', ',', 'Mnih'), (',', 'Mnih', ','), ('Mnih', ',', 'V.'), (',', 'V.', '&'), ('V.', '&', 'Kavukcuoglu'), ('&', 'Kavukcuoglu', ','), ('Kavukcuoglu', ',', 'K.'), (',', 'K.', 'Multiple'), ('K.', 'Multiple', 'object'), ('Multiple', 'object', 'recognition'), ('object', 'recognition', 'visual'), ('recognition', 'visual', 'attention'), ('visual', 'attention', '.')]

>> POS Tags are: 
 [('Ba', 'NNP'), (',', ','), ('J.', 'NNP'), (',', ','), ('Mnih', 'NNP'), (',', ','), ('V.', 'NNP'), ('&', 'CC'), ('Kavukcuoglu', 'NNP'), (',', ','), ('K.', 'NNP'), ('Multiple', 'NNP'), ('object', 'JJ'), ('recognition', 'NN'), ('visual', 'JJ'), ('attention', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Ba', 'J.', 'Mnih', 'V.', 'Kavukcuoglu', 'K. Multiple', 'object recognition', 'visual attention']

>> Named Entities are: 
 [('GPE', 'Ba'), ('PERSON', 'Mnih'), ('GPE', 'Kavukcuoglu')] 

>> Stemming using Porter Stemmer: 
 [('Ba', 'ba'), (',', ','), ('J.', 'j.'), (',', ','), ('Mnih', 'mnih'), (',', ','), ('V.', 'v.'), ('&', '&'), ('Kavukcuoglu', 'kavukcuoglu'), (',', ','), ('K.', 'k.'), ('Multiple', 'multipl'), ('object', 'object'), ('recognition', 'recognit'), ('visual', 'visual'), ('attention', 'attent'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Ba', 'ba'), (',', ','), ('J.', 'j.'), (',', ','), ('Mnih', 'mnih'), (',', ','), ('V.', 'v.'), ('&', '&'), ('Kavukcuoglu', 'kavukcuoglu'), (',', ','), ('K.', 'k.'), ('Multiple', 'multipl'), ('object', 'object'), ('recognition', 'recognit'), ('visual', 'visual'), ('attention', 'attent'), ('.', '.')]

>> Lemmatization: 
 [('Ba', 'Ba'), (',', ','), ('J.', 'J.'), (',', ','), ('Mnih', 'Mnih'), (',', ','), ('V.', 'V.'), ('&', '&'), ('Kavukcuoglu', 'Kavukcuoglu'), (',', ','), ('K.', 'K.'), ('Multiple', 'Multiple'), ('object', 'object'), ('recognition', 'recognition'), ('visual', 'visual'), ('attention', 'attention'), ('.', '.')]


------------------- Sentence 3 -------------------

In Proc.

>> Tokens are: 
 ['In', 'Proc', '.']

>> Bigrams are: 
 [('In', 'Proc'), ('Proc', '.')]

>> Trigrams are: 
 [('In', 'Proc', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('Proc', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Proc']

>> Named Entities are: 
 [('GPE', 'Proc')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('Proc', 'proc'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('Proc', 'proc'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('Proc', 'Proc'), ('.', '.')]


------------------- Sentence 4 -------------------

International Conference on Learning Representations http:// arxiv.org/abs/1412.7755 (2014).

>> Tokens are: 
 ['International', 'Conference', 'Learning', 'Representations', 'http', ':', '//', 'arxiv.org/abs/1412.7755', '(', '2014', ')', '.']

>> Bigrams are: 
 [('International', 'Conference'), ('Conference', 'Learning'), ('Learning', 'Representations'), ('Representations', 'http'), ('http', ':'), (':', '//'), ('//', 'arxiv.org/abs/1412.7755'), ('arxiv.org/abs/1412.7755', '('), ('(', '2014'), ('2014', ')'), (')', '.')]

>> Trigrams are: 
 [('International', 'Conference', 'Learning'), ('Conference', 'Learning', 'Representations'), ('Learning', 'Representations', 'http'), ('Representations', 'http', ':'), ('http', ':', '//'), (':', '//', 'arxiv.org/abs/1412.7755'), ('//', 'arxiv.org/abs/1412.7755', '('), ('arxiv.org/abs/1412.7755', '(', '2014'), ('(', '2014', ')'), ('2014', ')', '.')]

>> POS Tags are: 
 [('International', 'NNP'), ('Conference', 'NNP'), ('Learning', 'NNP'), ('Representations', 'NNP'), ('http', 'NN'), (':', ':'), ('//', 'NN'), ('arxiv.org/abs/1412.7755', 'NN'), ('(', '('), ('2014', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['International Conference Learning Representations http', '// arxiv.org/abs/1412.7755']

>> Named Entities are: 
 [('ORGANIZATION', 'International Conference')] 

>> Stemming using Porter Stemmer: 
 [('International', 'intern'), ('Conference', 'confer'), ('Learning', 'learn'), ('Representations', 'represent'), ('http', 'http'), (':', ':'), ('//', '//'), ('arxiv.org/abs/1412.7755', 'arxiv.org/abs/1412.7755'), ('(', '('), ('2014', '2014'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('International', 'intern'), ('Conference', 'confer'), ('Learning', 'learn'), ('Representations', 'represent'), ('http', 'http'), (':', ':'), ('//', '//'), ('arxiv.org/abs/1412.7755', 'arxiv.org/abs/1412.7755'), ('(', '('), ('2014', '2014'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('International', 'International'), ('Conference', 'Conference'), ('Learning', 'Learning'), ('Representations', 'Representations'), ('http', 'http'), (':', ':'), ('//', '//'), ('arxiv.org/abs/1412.7755', 'arxiv.org/abs/1412.7755'), ('(', '('), ('2014', '2014'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 357 ===========================================

100. Mnih, V. et al. Human-level control through deep reinforcement learning. Nature   518, 529–533 (2015). 

------------------- Sentence 1 -------------------

100.

>> Tokens are: 
 ['100', '.']

>> Bigrams are: 
 [('100', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('100', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('100', '100'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('100', '100'), ('.', '.')]

>> Lemmatization: 
 [('100', '100'), ('.', '.')]


------------------- Sentence 2 -------------------

Mnih, V. et al.

>> Tokens are: 
 ['Mnih', ',', 'V.', 'et', 'al', '.']

>> Bigrams are: 
 [('Mnih', ','), (',', 'V.'), ('V.', 'et'), ('et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('Mnih', ',', 'V.'), (',', 'V.', 'et'), ('V.', 'et', 'al'), ('et', 'al', '.')]

>> POS Tags are: 
 [('Mnih', 'NNP'), (',', ','), ('V.', 'NNP'), ('et', 'CC'), ('al', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Mnih', 'V.', 'al']

>> Named Entities are: 
 [('GPE', 'Mnih')] 

>> Stemming using Porter Stemmer: 
 [('Mnih', 'mnih'), (',', ','), ('V.', 'v.'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Mnih', 'mnih'), (',', ','), ('V.', 'v.'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('Mnih', 'Mnih'), (',', ','), ('V.', 'V.'), ('et', 'et'), ('al', 'al'), ('.', '.')]


------------------- Sentence 3 -------------------

Human-level control through deep reinforcement learning.

>> Tokens are: 
 ['Human-level', 'control', 'deep', 'reinforcement', 'learning', '.']

>> Bigrams are: 
 [('Human-level', 'control'), ('control', 'deep'), ('deep', 'reinforcement'), ('reinforcement', 'learning'), ('learning', '.')]

>> Trigrams are: 
 [('Human-level', 'control', 'deep'), ('control', 'deep', 'reinforcement'), ('deep', 'reinforcement', 'learning'), ('reinforcement', 'learning', '.')]

>> POS Tags are: 
 [('Human-level', 'NNP'), ('control', 'NN'), ('deep', 'JJ'), ('reinforcement', 'NN'), ('learning', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Human-level control', 'deep reinforcement learning']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Human-level', 'human-level'), ('control', 'control'), ('deep', 'deep'), ('reinforcement', 'reinforc'), ('learning', 'learn'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Human-level', 'human-level'), ('control', 'control'), ('deep', 'deep'), ('reinforcement', 'reinforc'), ('learning', 'learn'), ('.', '.')]

>> Lemmatization: 
 [('Human-level', 'Human-level'), ('control', 'control'), ('deep', 'deep'), ('reinforcement', 'reinforcement'), ('learning', 'learning'), ('.', '.')]


------------------- Sentence 4 -------------------

Nature   518, 529–533 (2015).

>> Tokens are: 
 ['Nature', '518', ',', '529–533', '(', '2015', ')', '.']

>> Bigrams are: 
 [('Nature', '518'), ('518', ','), (',', '529–533'), ('529–533', '('), ('(', '2015'), ('2015', ')'), (')', '.')]

>> Trigrams are: 
 [('Nature', '518', ','), ('518', ',', '529–533'), (',', '529–533', '('), ('529–533', '(', '2015'), ('(', '2015', ')'), ('2015', ')', '.')]

>> POS Tags are: 
 [('Nature', 'NN'), ('518', 'CD'), (',', ','), ('529–533', 'CD'), ('(', '('), ('2015', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['Nature']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Nature', 'natur'), ('518', '518'), (',', ','), ('529–533', '529–533'), ('(', '('), ('2015', '2015'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Nature', 'natur'), ('518', '518'), (',', ','), ('529–533', '529–533'), ('(', '('), ('2015', '2015'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Nature', 'Nature'), ('518', '518'), (',', ','), ('529–533', '529–533'), ('(', '('), ('2015', '2015'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 358 ===========================================

101. Bottou, L. From machine learning to machine reasoning. Mach. Learn. 94,  133–149 (2014).  

------------------- Sentence 1 -------------------

101.

>> Tokens are: 
 ['101', '.']

>> Bigrams are: 
 [('101', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('101', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('101', '101'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('101', '101'), ('.', '.')]

>> Lemmatization: 
 [('101', '101'), ('.', '.')]


------------------- Sentence 2 -------------------

Bottou, L. From machine learning to machine reasoning.

>> Tokens are: 
 ['Bottou', ',', 'L.', 'From', 'machine', 'learning', 'machine', 'reasoning', '.']

>> Bigrams are: 
 [('Bottou', ','), (',', 'L.'), ('L.', 'From'), ('From', 'machine'), ('machine', 'learning'), ('learning', 'machine'), ('machine', 'reasoning'), ('reasoning', '.')]

>> Trigrams are: 
 [('Bottou', ',', 'L.'), (',', 'L.', 'From'), ('L.', 'From', 'machine'), ('From', 'machine', 'learning'), ('machine', 'learning', 'machine'), ('learning', 'machine', 'reasoning'), ('machine', 'reasoning', '.')]

>> POS Tags are: 
 [('Bottou', 'NNP'), (',', ','), ('L.', 'NNP'), ('From', 'NNP'), ('machine', 'NN'), ('learning', 'VBG'), ('machine', 'NN'), ('reasoning', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Bottou', 'L. From machine', 'machine reasoning']

>> Named Entities are: 
 [('GPE', 'Bottou')] 

>> Stemming using Porter Stemmer: 
 [('Bottou', 'bottou'), (',', ','), ('L.', 'l.'), ('From', 'from'), ('machine', 'machin'), ('learning', 'learn'), ('machine', 'machin'), ('reasoning', 'reason'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Bottou', 'bottou'), (',', ','), ('L.', 'l.'), ('From', 'from'), ('machine', 'machin'), ('learning', 'learn'), ('machine', 'machin'), ('reasoning', 'reason'), ('.', '.')]

>> Lemmatization: 
 [('Bottou', 'Bottou'), (',', ','), ('L.', 'L.'), ('From', 'From'), ('machine', 'machine'), ('learning', 'learning'), ('machine', 'machine'), ('reasoning', 'reasoning'), ('.', '.')]


------------------- Sentence 3 -------------------

Mach.

>> Tokens are: 
 ['Mach', '.']

>> Bigrams are: 
 [('Mach', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Mach', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Mach']

>> Named Entities are: 
 [('GPE', 'Mach')] 

>> Stemming using Porter Stemmer: 
 [('Mach', 'mach'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Mach', 'mach'), ('.', '.')]

>> Lemmatization: 
 [('Mach', 'Mach'), ('.', '.')]


------------------- Sentence 4 -------------------

Learn.

>> Tokens are: 
 ['Learn', '.']

>> Bigrams are: 
 [('Learn', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Learn', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Learn']

>> Named Entities are: 
 [('GPE', 'Learn')] 

>> Stemming using Porter Stemmer: 
 [('Learn', 'learn'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Learn', 'learn'), ('.', '.')]

>> Lemmatization: 
 [('Learn', 'Learn'), ('.', '.')]


------------------- Sentence 5 -------------------

94,  133–149 (2014).

>> Tokens are: 
 ['94', ',', '133–149', '(', '2014', ')', '.']

>> Bigrams are: 
 [('94', ','), (',', '133–149'), ('133–149', '('), ('(', '2014'), ('2014', ')'), (')', '.')]

>> Trigrams are: 
 [('94', ',', '133–149'), (',', '133–149', '('), ('133–149', '(', '2014'), ('(', '2014', ')'), ('2014', ')', '.')]

>> POS Tags are: 
 [('94', 'CD'), (',', ','), ('133–149', 'CD'), ('(', '('), ('2014', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('94', '94'), (',', ','), ('133–149', '133–149'), ('(', '('), ('2014', '2014'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('94', '94'), (',', ','), ('133–149', '133–149'), ('(', '('), ('2014', '2014'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('94', '94'), (',', ','), ('133–149', '133–149'), ('(', '('), ('2014', '2014'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 359 ===========================================

102. Vinyals, O., Toshev, A., Bengio, S. & Erhan, D. Show and tell: a neural image  caption generator. In Proc. International Conference on Machine Learning http:// arxiv.org/abs/1502.03044 (2014). 

------------------- Sentence 1 -------------------

102.

>> Tokens are: 
 ['102', '.']

>> Bigrams are: 
 [('102', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('102', 'CD'), ('.', '.')]

>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('102', '102'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('102', '102'), ('.', '.')]

>> Lemmatization: 
 [('102', '102'), ('.', '.')]


------------------- Sentence 2 -------------------

Vinyals, O., Toshev, A., Bengio, S. & Erhan, D. Show and tell: a neural image  caption generator.

>> Tokens are: 
 ['Vinyals', ',', 'O.', ',', 'Toshev', ',', 'A.', ',', 'Bengio', ',', 'S.', '&', 'Erhan', ',', 'D.', 'Show', 'tell', ':', 'neural', 'image', 'caption', 'generator', '.']

>> Bigrams are: 
 [('Vinyals', ','), (',', 'O.'), ('O.', ','), (',', 'Toshev'), ('Toshev', ','), (',', 'A.'), ('A.', ','), (',', 'Bengio'), ('Bengio', ','), (',', 'S.'), ('S.', '&'), ('&', 'Erhan'), ('Erhan', ','), (',', 'D.'), ('D.', 'Show'), ('Show', 'tell'), ('tell', ':'), (':', 'neural'), ('neural', 'image'), ('image', 'caption'), ('caption', 'generator'), ('generator', '.')]

>> Trigrams are: 
 [('Vinyals', ',', 'O.'), (',', 'O.', ','), ('O.', ',', 'Toshev'), (',', 'Toshev', ','), ('Toshev', ',', 'A.'), (',', 'A.', ','), ('A.', ',', 'Bengio'), (',', 'Bengio', ','), ('Bengio', ',', 'S.'), (',', 'S.', '&'), ('S.', '&', 'Erhan'), ('&', 'Erhan', ','), ('Erhan', ',', 'D.'), (',', 'D.', 'Show'), ('D.', 'Show', 'tell'), ('Show', 'tell', ':'), ('tell', ':', 'neural'), (':', 'neural', 'image'), ('neural', 'image', 'caption'), ('image', 'caption', 'generator'), ('caption', 'generator', '.')]

>> POS Tags are: 
 [('Vinyals', 'NNS'), (',', ','), ('O.', 'NNP'), (',', ','), ('Toshev', 'NNP'), (',', ','), ('A.', 'NNP'), (',', ','), ('Bengio', 'NNP'), (',', ','), ('S.', 'NNP'), ('&', 'CC'), ('Erhan', 'NNP'), (',', ','), ('D.', 'NNP'), ('Show', 'NNP'), ('tell', 'NN'), (':', ':'), ('neural', 'JJ'), ('image', 'NN'), ('caption', 'NN'), ('generator', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Vinyals', 'O.', 'Toshev', 'A.', 'Bengio', 'S.', 'Erhan', 'D. Show tell', 'neural image caption generator']

>> Named Entities are: 
 [('PERSON', 'Toshev'), ('PERSON', 'Bengio'), ('PERSON', 'Erhan')] 

>> Stemming using Porter Stemmer: 
 [('Vinyals', 'vinyal'), (',', ','), ('O.', 'o.'), (',', ','), ('Toshev', 'toshev'), (',', ','), ('A.', 'a.'), (',', ','), ('Bengio', 'bengio'), (',', ','), ('S.', 's.'), ('&', '&'), ('Erhan', 'erhan'), (',', ','), ('D.', 'd.'), ('Show', 'show'), ('tell', 'tell'), (':', ':'), ('neural', 'neural'), ('image', 'imag'), ('caption', 'caption'), ('generator', 'gener'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Vinyals', 'vinyal'), (',', ','), ('O.', 'o.'), (',', ','), ('Toshev', 'toshev'), (',', ','), ('A.', 'a.'), (',', ','), ('Bengio', 'bengio'), (',', ','), ('S.', 's.'), ('&', '&'), ('Erhan', 'erhan'), (',', ','), ('D.', 'd.'), ('Show', 'show'), ('tell', 'tell'), (':', ':'), ('neural', 'neural'), ('image', 'imag'), ('caption', 'caption'), ('generator', 'generat'), ('.', '.')]

>> Lemmatization: 
 [('Vinyals', 'Vinyals'), (',', ','), ('O.', 'O.'), (',', ','), ('Toshev', 'Toshev'), (',', ','), ('A.', 'A.'), (',', ','), ('Bengio', 'Bengio'), (',', ','), ('S.', 'S.'), ('&', '&'), ('Erhan', 'Erhan'), (',', ','), ('D.', 'D.'), ('Show', 'Show'), ('tell', 'tell'), (':', ':'), ('neural', 'neural'), ('image', 'image'), ('caption', 'caption'), ('generator', 'generator'), ('.', '.')]


------------------- Sentence 3 -------------------

In Proc.

>> Tokens are: 
 ['In', 'Proc', '.']

>> Bigrams are: 
 [('In', 'Proc'), ('Proc', '.')]

>> Trigrams are: 
 [('In', 'Proc', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('Proc', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Proc']

>> Named Entities are: 
 [('GPE', 'Proc')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('Proc', 'proc'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('Proc', 'proc'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('Proc', 'Proc'), ('.', '.')]


------------------- Sentence 4 -------------------

International Conference on Machine Learning http:// arxiv.org/abs/1502.03044 (2014).

>> Tokens are: 
 ['International', 'Conference', 'Machine', 'Learning', 'http', ':', '//', 'arxiv.org/abs/1502.03044', '(', '2014', ')', '.']

>> Bigrams are: 
 [('International', 'Conference'), ('Conference', 'Machine'), ('Machine', 'Learning'), ('Learning', 'http'), ('http', ':'), (':', '//'), ('//', 'arxiv.org/abs/1502.03044'), ('arxiv.org/abs/1502.03044', '('), ('(', '2014'), ('2014', ')'), (')', '.')]

>> Trigrams are: 
 [('International', 'Conference', 'Machine'), ('Conference', 'Machine', 'Learning'), ('Machine', 'Learning', 'http'), ('Learning', 'http', ':'), ('http', ':', '//'), (':', '//', 'arxiv.org/abs/1502.03044'), ('//', 'arxiv.org/abs/1502.03044', '('), ('arxiv.org/abs/1502.03044', '(', '2014'), ('(', '2014', ')'), ('2014', ')', '.')]

>> POS Tags are: 
 [('International', 'NNP'), ('Conference', 'NNP'), ('Machine', 'NNP'), ('Learning', 'NNP'), ('http', 'NN'), (':', ':'), ('//', 'NN'), ('arxiv.org/abs/1502.03044', 'NN'), ('(', '('), ('2014', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['International Conference Machine Learning http', '// arxiv.org/abs/1502.03044']

>> Named Entities are: 
 [('ORGANIZATION', 'International Conference Machine')] 

>> Stemming using Porter Stemmer: 
 [('International', 'intern'), ('Conference', 'confer'), ('Machine', 'machin'), ('Learning', 'learn'), ('http', 'http'), (':', ':'), ('//', '//'), ('arxiv.org/abs/1502.03044', 'arxiv.org/abs/1502.03044'), ('(', '('), ('2014', '2014'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('International', 'intern'), ('Conference', 'confer'), ('Machine', 'machin'), ('Learning', 'learn'), ('http', 'http'), (':', ':'), ('//', '//'), ('arxiv.org/abs/1502.03044', 'arxiv.org/abs/1502.03044'), ('(', '('), ('2014', '2014'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('International', 'International'), ('Conference', 'Conference'), ('Machine', 'Machine'), ('Learning', 'Learning'), ('http', 'http'), (':', ':'), ('//', '//'), ('arxiv.org/abs/1502.03044', 'arxiv.org/abs/1502.03044'), ('(', '('), ('2014', '2014'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 360 ===========================================

103. van der Maaten, L. & Hinton, G. E. Visualizing data using t-SNE. J. Mach. Learn. Research 9, 2579–2605 (2008). 

------------------- Sentence 1 -------------------

103. van der Maaten, L. & Hinton, G. E. Visualizing data using t-SNE.

>> Tokens are: 
 ['103.', 'van', 'der', 'Maaten', ',', 'L.', '&', 'Hinton', ',', 'G.', 'E.', 'Visualizing', 'data', 'using', 't-SNE', '.']

>> Bigrams are: 
 [('103.', 'van'), ('van', 'der'), ('der', 'Maaten'), ('Maaten', ','), (',', 'L.'), ('L.', '&'), ('&', 'Hinton'), ('Hinton', ','), (',', 'G.'), ('G.', 'E.'), ('E.', 'Visualizing'), ('Visualizing', 'data'), ('data', 'using'), ('using', 't-SNE'), ('t-SNE', '.')]

>> Trigrams are: 
 [('103.', 'van', 'der'), ('van', 'der', 'Maaten'), ('der', 'Maaten', ','), ('Maaten', ',', 'L.'), (',', 'L.', '&'), ('L.', '&', 'Hinton'), ('&', 'Hinton', ','), ('Hinton', ',', 'G.'), (',', 'G.', 'E.'), ('G.', 'E.', 'Visualizing'), ('E.', 'Visualizing', 'data'), ('Visualizing', 'data', 'using'), ('data', 'using', 't-SNE'), ('using', 't-SNE', '.')]

>> POS Tags are: 
 [('103.', 'CD'), ('van', 'JJ'), ('der', 'NN'), ('Maaten', 'NNP'), (',', ','), ('L.', 'NNP'), ('&', 'CC'), ('Hinton', 'NNP'), (',', ','), ('G.', 'NNP'), ('E.', 'NNP'), ('Visualizing', 'NNP'), ('data', 'NNS'), ('using', 'VBG'), ('t-SNE', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['van der Maaten', 'L.', 'Hinton', 'G. E. Visualizing data', 't-SNE']

>> Named Entities are: 
 [('PERSON', 'Maaten'), ('GPE', 'Hinton')] 

>> Stemming using Porter Stemmer: 
 [('103.', '103.'), ('van', 'van'), ('der', 'der'), ('Maaten', 'maaten'), (',', ','), ('L.', 'l.'), ('&', '&'), ('Hinton', 'hinton'), (',', ','), ('G.', 'g.'), ('E.', 'e.'), ('Visualizing', 'visual'), ('data', 'data'), ('using', 'use'), ('t-SNE', 't-sne'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('103.', '103.'), ('van', 'van'), ('der', 'der'), ('Maaten', 'maaten'), (',', ','), ('L.', 'l.'), ('&', '&'), ('Hinton', 'hinton'), (',', ','), ('G.', 'g.'), ('E.', 'e.'), ('Visualizing', 'visual'), ('data', 'data'), ('using', 'use'), ('t-SNE', 't-sne'), ('.', '.')]

>> Lemmatization: 
 [('103.', '103.'), ('van', 'van'), ('der', 'der'), ('Maaten', 'Maaten'), (',', ','), ('L.', 'L.'), ('&', '&'), ('Hinton', 'Hinton'), (',', ','), ('G.', 'G.'), ('E.', 'E.'), ('Visualizing', 'Visualizing'), ('data', 'data'), ('using', 'using'), ('t-SNE', 't-SNE'), ('.', '.')]


------------------- Sentence 2 -------------------

J. Mach.

>> Tokens are: 
 ['J.', 'Mach', '.']

>> Bigrams are: 
 [('J.', 'Mach'), ('Mach', '.')]

>> Trigrams are: 
 [('J.', 'Mach', '.')]

>> POS Tags are: 
 [('J.', 'NNP'), ('Mach', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['J. Mach']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('J.', 'j.'), ('Mach', 'mach'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('J.', 'j.'), ('Mach', 'mach'), ('.', '.')]

>> Lemmatization: 
 [('J.', 'J.'), ('Mach', 'Mach'), ('.', '.')]


------------------- Sentence 3 -------------------

Learn.

>> Tokens are: 
 ['Learn', '.']

>> Bigrams are: 
 [('Learn', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Learn', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Learn']

>> Named Entities are: 
 [('GPE', 'Learn')] 

>> Stemming using Porter Stemmer: 
 [('Learn', 'learn'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Learn', 'learn'), ('.', '.')]

>> Lemmatization: 
 [('Learn', 'Learn'), ('.', '.')]


------------------- Sentence 4 -------------------

Research 9, 2579–2605 (2008).

>> Tokens are: 
 ['Research', '9', ',', '2579–2605', '(', '2008', ')', '.']

>> Bigrams are: 
 [('Research', '9'), ('9', ','), (',', '2579–2605'), ('2579–2605', '('), ('(', '2008'), ('2008', ')'), (')', '.')]

>> Trigrams are: 
 [('Research', '9', ','), ('9', ',', '2579–2605'), (',', '2579–2605', '('), ('2579–2605', '(', '2008'), ('(', '2008', ')'), ('2008', ')', '.')]

>> POS Tags are: 
 [('Research', 'NN'), ('9', 'CD'), (',', ','), ('2579–2605', 'CD'), ('(', '('), ('2008', 'CD'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['Research']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Research', 'research'), ('9', '9'), (',', ','), ('2579–2605', '2579–2605'), ('(', '('), ('2008', '2008'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Research', 'research'), ('9', '9'), (',', ','), ('2579–2605', '2579–2605'), ('(', '('), ('2008', '2008'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Research', 'Research'), ('9', '9'), (',', ','), ('2579–2605', '2579–2605'), ('(', '('), ('2008', '2008'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 361 ===========================================

Acknowledgements The authors would like to thank the Natural Sciences and  Engineering Research Council of Canada, the Canadian Institute For Advanced  Research (CIFAR), the National Science Foundation and Office of Naval Research  for support. Y.L. and Y.B. are CIFAR fellows. 

------------------- Sentence 1 -------------------

Acknowledgements The authors would like to thank the Natural Sciences and  Engineering Research Council of Canada, the Canadian Institute For Advanced  Research (CIFAR), the National Science Foundation and Office of Naval Research  for support.

>> Tokens are: 
 ['Acknowledgements', 'The', 'authors', 'would', 'like', 'thank', 'Natural', 'Sciences', 'Engineering', 'Research', 'Council', 'Canada', ',', 'Canadian', 'Institute', 'For', 'Advanced', 'Research', '(', 'CIFAR', ')', ',', 'National', 'Science', 'Foundation', 'Office', 'Naval', 'Research', 'support', '.']

>> Bigrams are: 
 [('Acknowledgements', 'The'), ('The', 'authors'), ('authors', 'would'), ('would', 'like'), ('like', 'thank'), ('thank', 'Natural'), ('Natural', 'Sciences'), ('Sciences', 'Engineering'), ('Engineering', 'Research'), ('Research', 'Council'), ('Council', 'Canada'), ('Canada', ','), (',', 'Canadian'), ('Canadian', 'Institute'), ('Institute', 'For'), ('For', 'Advanced'), ('Advanced', 'Research'), ('Research', '('), ('(', 'CIFAR'), ('CIFAR', ')'), (')', ','), (',', 'National'), ('National', 'Science'), ('Science', 'Foundation'), ('Foundation', 'Office'), ('Office', 'Naval'), ('Naval', 'Research'), ('Research', 'support'), ('support', '.')]

>> Trigrams are: 
 [('Acknowledgements', 'The', 'authors'), ('The', 'authors', 'would'), ('authors', 'would', 'like'), ('would', 'like', 'thank'), ('like', 'thank', 'Natural'), ('thank', 'Natural', 'Sciences'), ('Natural', 'Sciences', 'Engineering'), ('Sciences', 'Engineering', 'Research'), ('Engineering', 'Research', 'Council'), ('Research', 'Council', 'Canada'), ('Council', 'Canada', ','), ('Canada', ',', 'Canadian'), (',', 'Canadian', 'Institute'), ('Canadian', 'Institute', 'For'), ('Institute', 'For', 'Advanced'), ('For', 'Advanced', 'Research'), ('Advanced', 'Research', '('), ('Research', '(', 'CIFAR'), ('(', 'CIFAR', ')'), ('CIFAR', ')', ','), (')', ',', 'National'), (',', 'National', 'Science'), ('National', 'Science', 'Foundation'), ('Science', 'Foundation', 'Office'), ('Foundation', 'Office', 'Naval'), ('Office', 'Naval', 'Research'), ('Naval', 'Research', 'support'), ('Research', 'support', '.')]

>> POS Tags are: 
 [('Acknowledgements', 'NNS'), ('The', 'DT'), ('authors', 'NNS'), ('would', 'MD'), ('like', 'VB'), ('thank', 'VB'), ('Natural', 'NNP'), ('Sciences', 'NNPS'), ('Engineering', 'NNP'), ('Research', 'NNP'), ('Council', 'NNP'), ('Canada', 'NNP'), (',', ','), ('Canadian', 'NNP'), ('Institute', 'NNP'), ('For', 'IN'), ('Advanced', 'NNP'), ('Research', 'NNP'), ('(', '('), ('CIFAR', 'NNP'), (')', ')'), (',', ','), ('National', 'NNP'), ('Science', 'NNP'), ('Foundation', 'NNP'), ('Office', 'NNP'), ('Naval', 'NNP'), ('Research', 'NNP'), ('support', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Acknowledgements', 'The authors', 'Natural', 'Engineering Research Council Canada', 'Canadian Institute', 'Advanced Research', 'CIFAR', 'National Science Foundation Office Naval Research support']

>> Named Entities are: 
 [('ORGANIZATION', 'Natural Sciences'), ('GPE', 'Canadian'), ('ORGANIZATION', 'Advanced Research'), ('ORGANIZATION', 'CIFAR'), ('ORGANIZATION', 'National Science Foundation'), ('PERSON', 'Naval Research')] 

>> Stemming using Porter Stemmer: 
 [('Acknowledgements', 'acknowledg'), ('The', 'the'), ('authors', 'author'), ('would', 'would'), ('like', 'like'), ('thank', 'thank'), ('Natural', 'natur'), ('Sciences', 'scienc'), ('Engineering', 'engin'), ('Research', 'research'), ('Council', 'council'), ('Canada', 'canada'), (',', ','), ('Canadian', 'canadian'), ('Institute', 'institut'), ('For', 'for'), ('Advanced', 'advanc'), ('Research', 'research'), ('(', '('), ('CIFAR', 'cifar'), (')', ')'), (',', ','), ('National', 'nation'), ('Science', 'scienc'), ('Foundation', 'foundat'), ('Office', 'offic'), ('Naval', 'naval'), ('Research', 'research'), ('support', 'support'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Acknowledgements', 'acknowledg'), ('The', 'the'), ('authors', 'author'), ('would', 'would'), ('like', 'like'), ('thank', 'thank'), ('Natural', 'natur'), ('Sciences', 'scienc'), ('Engineering', 'engin'), ('Research', 'research'), ('Council', 'council'), ('Canada', 'canada'), (',', ','), ('Canadian', 'canadian'), ('Institute', 'institut'), ('For', 'for'), ('Advanced', 'advanc'), ('Research', 'research'), ('(', '('), ('CIFAR', 'cifar'), (')', ')'), (',', ','), ('National', 'nation'), ('Science', 'scienc'), ('Foundation', 'foundat'), ('Office', 'offic'), ('Naval', 'naval'), ('Research', 'research'), ('support', 'support'), ('.', '.')]

>> Lemmatization: 
 [('Acknowledgements', 'Acknowledgements'), ('The', 'The'), ('authors', 'author'), ('would', 'would'), ('like', 'like'), ('thank', 'thank'), ('Natural', 'Natural'), ('Sciences', 'Sciences'), ('Engineering', 'Engineering'), ('Research', 'Research'), ('Council', 'Council'), ('Canada', 'Canada'), (',', ','), ('Canadian', 'Canadian'), ('Institute', 'Institute'), ('For', 'For'), ('Advanced', 'Advanced'), ('Research', 'Research'), ('(', '('), ('CIFAR', 'CIFAR'), (')', ')'), (',', ','), ('National', 'National'), ('Science', 'Science'), ('Foundation', 'Foundation'), ('Office', 'Office'), ('Naval', 'Naval'), ('Research', 'Research'), ('support', 'support'), ('.', '.')]


------------------- Sentence 2 -------------------

Y.L.

>> Tokens are: 
 ['Y.L', '.']

>> Bigrams are: 
 [('Y.L', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Y.L', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Y.L']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Y.L', 'y.l'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Y.L', 'y.l'), ('.', '.')]

>> Lemmatization: 
 [('Y.L', 'Y.L'), ('.', '.')]


------------------- Sentence 3 -------------------

and Y.B.

>> Tokens are: 
 ['Y.B', '.']

>> Bigrams are: 
 [('Y.B', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Y.B', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Y.B']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Y.B', 'y.b'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Y.B', 'y.b'), ('.', '.')]

>> Lemmatization: 
 [('Y.B', 'Y.B'), ('.', '.')]


------------------- Sentence 4 -------------------

are CIFAR fellows.

>> Tokens are: 
 ['CIFAR', 'fellows', '.']

>> Bigrams are: 
 [('CIFAR', 'fellows'), ('fellows', '.')]

>> Trigrams are: 
 [('CIFAR', 'fellows', '.')]

>> POS Tags are: 
 [('CIFAR', 'NNP'), ('fellows', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['CIFAR fellows']

>> Named Entities are: 
 [('GPE', 'CIFAR')] 

>> Stemming using Porter Stemmer: 
 [('CIFAR', 'cifar'), ('fellows', 'fellow'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('CIFAR', 'cifar'), ('fellows', 'fellow'), ('.', '.')]

>> Lemmatization: 
 [('CIFAR', 'CIFAR'), ('fellows', 'fellow'), ('.', '.')]



========================================== PARAGRAPH 362 ===========================================

Author Information Reprints and permissions information is available at  www.nature.com/reprints. The authors declare no competing financial  interests. Readers are welcome to comment on the online version of this  paper at go.nature.com/7cjbaa. Correspondence should be addressed to Y.L.  (yann@cs.nyu.edu). 

------------------- Sentence 1 -------------------

Author Information Reprints and permissions information is available at  www.nature.com/reprints.

>> Tokens are: 
 ['Author', 'Information', 'Reprints', 'permissions', 'information', 'available', 'www.nature.com/reprints', '.']

>> Bigrams are: 
 [('Author', 'Information'), ('Information', 'Reprints'), ('Reprints', 'permissions'), ('permissions', 'information'), ('information', 'available'), ('available', 'www.nature.com/reprints'), ('www.nature.com/reprints', '.')]

>> Trigrams are: 
 [('Author', 'Information', 'Reprints'), ('Information', 'Reprints', 'permissions'), ('Reprints', 'permissions', 'information'), ('permissions', 'information', 'available'), ('information', 'available', 'www.nature.com/reprints'), ('available', 'www.nature.com/reprints', '.')]

>> POS Tags are: 
 [('Author', 'NN'), ('Information', 'NN'), ('Reprints', 'NNP'), ('permissions', 'NNS'), ('information', 'NN'), ('available', 'JJ'), ('www.nature.com/reprints', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['Author Information Reprints permissions information', 'available www.nature.com/reprints']

>> Named Entities are: 
 [('GPE', 'Author'), ('ORGANIZATION', 'Information Reprints')] 

>> Stemming using Porter Stemmer: 
 [('Author', 'author'), ('Information', 'inform'), ('Reprints', 'reprint'), ('permissions', 'permiss'), ('information', 'inform'), ('available', 'avail'), ('www.nature.com/reprints', 'www.nature.com/reprint'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Author', 'author'), ('Information', 'inform'), ('Reprints', 'reprint'), ('permissions', 'permiss'), ('information', 'inform'), ('available', 'avail'), ('www.nature.com/reprints', 'www.nature.com/reprint'), ('.', '.')]

>> Lemmatization: 
 [('Author', 'Author'), ('Information', 'Information'), ('Reprints', 'Reprints'), ('permissions', 'permission'), ('information', 'information'), ('available', 'available'), ('www.nature.com/reprints', 'www.nature.com/reprints'), ('.', '.')]


------------------- Sentence 2 -------------------

The authors declare no competing financial  interests.

>> Tokens are: 
 ['The', 'authors', 'declare', 'competing', 'financial', 'interests', '.']

>> Bigrams are: 
 [('The', 'authors'), ('authors', 'declare'), ('declare', 'competing'), ('competing', 'financial'), ('financial', 'interests'), ('interests', '.')]

>> Trigrams are: 
 [('The', 'authors', 'declare'), ('authors', 'declare', 'competing'), ('declare', 'competing', 'financial'), ('competing', 'financial', 'interests'), ('financial', 'interests', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('authors', 'NNS'), ('declare', 'VBP'), ('competing', 'VBG'), ('financial', 'JJ'), ('interests', 'NNS'), ('.', '.')]

>> Noun Phrases are: 
 ['The authors', 'financial interests']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('authors', 'author'), ('declare', 'declar'), ('competing', 'compet'), ('financial', 'financi'), ('interests', 'interest'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('authors', 'author'), ('declare', 'declar'), ('competing', 'compet'), ('financial', 'financi'), ('interests', 'interest'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('authors', 'author'), ('declare', 'declare'), ('competing', 'competing'), ('financial', 'financial'), ('interests', 'interest'), ('.', '.')]


------------------- Sentence 3 -------------------

Readers are welcome to comment on the online version of this  paper at go.nature.com/7cjbaa.

>> Tokens are: 
 ['Readers', 'welcome', 'comment', 'online', 'version', 'paper', 'go.nature.com/7cjbaa', '.']

>> Bigrams are: 
 [('Readers', 'welcome'), ('welcome', 'comment'), ('comment', 'online'), ('online', 'version'), ('version', 'paper'), ('paper', 'go.nature.com/7cjbaa'), ('go.nature.com/7cjbaa', '.')]

>> Trigrams are: 
 [('Readers', 'welcome', 'comment'), ('welcome', 'comment', 'online'), ('comment', 'online', 'version'), ('online', 'version', 'paper'), ('version', 'paper', 'go.nature.com/7cjbaa'), ('paper', 'go.nature.com/7cjbaa', '.')]

>> POS Tags are: 
 [('Readers', 'NNS'), ('welcome', 'JJ'), ('comment', 'NN'), ('online', 'JJ'), ('version', 'NN'), ('paper', 'NN'), ('go.nature.com/7cjbaa', 'NN'), ('.', '.')]

>> Noun Phrases are: 
 ['Readers', 'welcome comment', 'online version paper go.nature.com/7cjbaa']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Readers', 'reader'), ('welcome', 'welcom'), ('comment', 'comment'), ('online', 'onlin'), ('version', 'version'), ('paper', 'paper'), ('go.nature.com/7cjbaa', 'go.nature.com/7cjbaa'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Readers', 'reader'), ('welcome', 'welcom'), ('comment', 'comment'), ('online', 'onlin'), ('version', 'version'), ('paper', 'paper'), ('go.nature.com/7cjbaa', 'go.nature.com/7cjbaa'), ('.', '.')]

>> Lemmatization: 
 [('Readers', 'Readers'), ('welcome', 'welcome'), ('comment', 'comment'), ('online', 'online'), ('version', 'version'), ('paper', 'paper'), ('go.nature.com/7cjbaa', 'go.nature.com/7cjbaa'), ('.', '.')]


------------------- Sentence 4 -------------------

Correspondence should be addressed to Y.L.

>> Tokens are: 
 ['Correspondence', 'addressed', 'Y.L', '.']

>> Bigrams are: 
 [('Correspondence', 'addressed'), ('addressed', 'Y.L'), ('Y.L', '.')]

>> Trigrams are: 
 [('Correspondence', 'addressed', 'Y.L'), ('addressed', 'Y.L', '.')]

>> POS Tags are: 
 [('Correspondence', 'NN'), ('addressed', 'VBD'), ('Y.L', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['Correspondence', 'Y.L']

>> Named Entities are: 
 [('GPE', 'Correspondence')] 

>> Stemming using Porter Stemmer: 
 [('Correspondence', 'correspond'), ('addressed', 'address'), ('Y.L', 'y.l'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Correspondence', 'correspond'), ('addressed', 'address'), ('Y.L', 'y.l'), ('.', '.')]

>> Lemmatization: 
 [('Correspondence', 'Correspondence'), ('addressed', 'addressed'), ('Y.L', 'Y.L'), ('.', '.')]


------------------- Sentence 5 -------------------

(yann@cs.nyu.edu).

>> Tokens are: 
 ['(', 'yann', '@', 'cs.nyu.edu', ')', '.']

>> Bigrams are: 
 [('(', 'yann'), ('yann', '@'), ('@', 'cs.nyu.edu'), ('cs.nyu.edu', ')'), (')', '.')]

>> Trigrams are: 
 [('(', 'yann', '@'), ('yann', '@', 'cs.nyu.edu'), ('@', 'cs.nyu.edu', ')'), ('cs.nyu.edu', ')', '.')]

>> POS Tags are: 
 [('(', '('), ('yann', 'PRP'), ('@', 'NNP'), ('cs.nyu.edu', 'NN'), (')', ')'), ('.', '.')]

>> Noun Phrases are: 
 ['@ cs.nyu.edu']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('yann', 'yann'), ('@', '@'), ('cs.nyu.edu', 'cs.nyu.edu'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('yann', 'yann'), ('@', '@'), ('cs.nyu.edu', 'cs.nyu.edu'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('(', '('), ('yann', 'yann'), ('@', '@'), ('cs.nyu.edu', 'cs.nyu.edu'), (')', ')'), ('.', '.')]



========================================== PARAGRAPH 363 ===========================================

4 4 4  |  N A T U R E  |  V O L  5 2 1  |  2 8  M A Y  2 0 1 5 

------------------- Sentence 1 -------------------

4 4 4  |  N A T U R E  |  V O L  5 2 1  |  2 8  M A Y  2 0 1 5

>> Tokens are: 
 ['4', '4', '4', '|', 'N', 'A', 'T', 'U', 'R', 'E', '|', 'V', 'O', 'L', '5', '2', '1', '|', '2', '8', 'M', 'A', 'Y', '2', '0', '1', '5']

>> Bigrams are: 
 [('4', '4'), ('4', '4'), ('4', '|'), ('|', 'N'), ('N', 'A'), ('A', 'T'), ('T', 'U'), ('U', 'R'), ('R', 'E'), ('E', '|'), ('|', 'V'), ('V', 'O'), ('O', 'L'), ('L', '5'), ('5', '2'), ('2', '1'), ('1', '|'), ('|', '2'), ('2', '8'), ('8', 'M'), ('M', 'A'), ('A', 'Y'), ('Y', '2'), ('2', '0'), ('0', '1'), ('1', '5')]

>> Trigrams are: 
 [('4', '4', '4'), ('4', '4', '|'), ('4', '|', 'N'), ('|', 'N', 'A'), ('N', 'A', 'T'), ('A', 'T', 'U'), ('T', 'U', 'R'), ('U', 'R', 'E'), ('R', 'E', '|'), ('E', '|', 'V'), ('|', 'V', 'O'), ('V', 'O', 'L'), ('O', 'L', '5'), ('L', '5', '2'), ('5', '2', '1'), ('2', '1', '|'), ('1', '|', '2'), ('|', '2', '8'), ('2', '8', 'M'), ('8', 'M', 'A'), ('M', 'A', 'Y'), ('A', 'Y', '2'), ('Y', '2', '0'), ('2', '0', '1'), ('0', '1', '5')]

>> POS Tags are: 
 [('4', 'CD'), ('4', 'CD'), ('4', 'CD'), ('|', 'NN'), ('N', 'NNP'), ('A', 'NNP'), ('T', 'NNP'), ('U', 'NNP'), ('R', 'NNP'), ('E', 'NNP'), ('|', 'NNP'), ('V', 'NNP'), ('O', 'NNP'), ('L', 'NNP'), ('5', 'CD'), ('2', 'CD'), ('1', 'CD'), ('|', 'NN'), ('2', 'CD'), ('8', 'CD'), ('M', 'NNP'), ('A', 'NNP'), ('Y', 'NNP'), ('2', 'CD'), ('0', 'CD'), ('1', 'CD'), ('5', 'CD')]

>> Noun Phrases are: 
 ['| N A T U R E | V O L', '|', 'M A Y']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('4', '4'), ('4', '4'), ('4', '4'), ('|', '|'), ('N', 'n'), ('A', 'a'), ('T', 't'), ('U', 'u'), ('R', 'r'), ('E', 'e'), ('|', '|'), ('V', 'v'), ('O', 'o'), ('L', 'l'), ('5', '5'), ('2', '2'), ('1', '1'), ('|', '|'), ('2', '2'), ('8', '8'), ('M', 'm'), ('A', 'a'), ('Y', 'y'), ('2', '2'), ('0', '0'), ('1', '1'), ('5', '5')]

>> Stemming using Snowball Stemmer: 
 [('4', '4'), ('4', '4'), ('4', '4'), ('|', '|'), ('N', 'n'), ('A', 'a'), ('T', 't'), ('U', 'u'), ('R', 'r'), ('E', 'e'), ('|', '|'), ('V', 'v'), ('O', 'o'), ('L', 'l'), ('5', '5'), ('2', '2'), ('1', '1'), ('|', '|'), ('2', '2'), ('8', '8'), ('M', 'm'), ('A', 'a'), ('Y', 'y'), ('2', '2'), ('0', '0'), ('1', '1'), ('5', '5')]

>> Lemmatization: 
 [('4', '4'), ('4', '4'), ('4', '4'), ('|', '|'), ('N', 'N'), ('A', 'A'), ('T', 'T'), ('U', 'U'), ('R', 'R'), ('E', 'E'), ('|', '|'), ('V', 'V'), ('O', 'O'), ('L', 'L'), ('5', '5'), ('2', '2'), ('1', '1'), ('|', '|'), ('2', '2'), ('8', '8'), ('M', 'M'), ('A', 'A'), ('Y', 'Y'), ('2', '2'), ('0', '0'), ('1', '1'), ('5', '5')]



========================================== PARAGRAPH 364 ===========================================

REVIEWINSIGHT 

------------------- Sentence 1 -------------------

REVIEWINSIGHT

>> Tokens are: 
 ['REVIEWINSIGHT']

>> Bigrams are: 
 []

>> Trigrams are: 
 []

>> POS Tags are: 
 [('REVIEWINSIGHT', 'NN')]

>> Noun Phrases are: 
 ['REVIEWINSIGHT']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('REVIEWINSIGHT', 'reviewinsight')]

>> Stemming using Snowball Stemmer: 
 [('REVIEWINSIGHT', 'reviewinsight')]

>> Lemmatization: 
 [('REVIEWINSIGHT', 'REVIEWINSIGHT')]



========================================== PARAGRAPH 365 ===========================================

© 2015 Macmillan Publishers Limited. All rights reserved

------------------- Sentence 1 -------------------

© 2015 Macmillan Publishers Limited.

>> Tokens are: 
 ['©', '2015', 'Macmillan', 'Publishers', 'Limited', '.']

>> Bigrams are: 
 [('©', '2015'), ('2015', 'Macmillan'), ('Macmillan', 'Publishers'), ('Publishers', 'Limited'), ('Limited', '.')]

>> Trigrams are: 
 [('©', '2015', 'Macmillan'), ('2015', 'Macmillan', 'Publishers'), ('Macmillan', 'Publishers', 'Limited'), ('Publishers', 'Limited', '.')]

>> POS Tags are: 
 [('©', 'NN'), ('2015', 'CD'), ('Macmillan', 'NNP'), ('Publishers', 'NNP'), ('Limited', 'NNP'), ('.', '.')]

>> Noun Phrases are: 
 ['©', 'Macmillan Publishers Limited']

>> Named Entities are: 
 [('PERSON', 'Macmillan Publishers Limited')] 

>> Stemming using Porter Stemmer: 
 [('©', '©'), ('2015', '2015'), ('Macmillan', 'macmillan'), ('Publishers', 'publish'), ('Limited', 'limit'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('©', '©'), ('2015', '2015'), ('Macmillan', 'macmillan'), ('Publishers', 'publish'), ('Limited', 'limit'), ('.', '.')]

>> Lemmatization: 
 [('©', '©'), ('2015', '2015'), ('Macmillan', 'Macmillan'), ('Publishers', 'Publishers'), ('Limited', 'Limited'), ('.', '.')]


------------------- Sentence 2 -------------------

All rights reserved

>> Tokens are: 
 ['All', 'rights', 'reserved']

>> Bigrams are: 
 [('All', 'rights'), ('rights', 'reserved')]

>> Trigrams are: 
 [('All', 'rights', 'reserved')]

>> POS Tags are: 
 [('All', 'DT'), ('rights', 'NNS'), ('reserved', 'VBN')]

>> Noun Phrases are: 
 ['All rights']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('All', 'all'), ('rights', 'right'), ('reserved', 'reserv')]

>> Stemming using Snowball Stemmer: 
 [('All', 'all'), ('rights', 'right'), ('reserved', 'reserv')]

>> Lemmatization: 
 [('All', 'All'), ('rights', 'right'), ('reserved', 'reserved')]

