				 *** Text Processing using Stanza *** 


================================ Paragraph 1 =================================

W H I T E  P A P E R 


------------------- Sentence 1 -------------------

 W H I T E  P A P E R 

Tokens are: 
>> ['W', 'H', 'I', 'T', 'E', 'P', 'A', 'P', 'E', 'R'] 

 UPOS tags are: 
>> [('W', 'PROPN'), ('H', 'PUNCT'), ('I', 'PRON'), ('T', 'AUX'), ('E', 'PROPN'), ('P', 'NOUN'), ('A', 'NOUN'), ('P', 'NOUN'), ('E', 'NOUN'), ('R', 'NOUN')] 

 XPOS tags are: 
>> [('W', 'NNP'), ('H', ','), ('I', 'PRP'), ('T', 'VBP'), ('E', 'NNP'), ('P', 'NN'), ('A', 'NN'), ('P', 'NN'), ('E', 'NN'), ('R', 'NN')] 

 Lemmas are: 
>> [('W', 'W'), ('H', 'H'), ('I', 'I'), ('T', 'T'), ('E', 'E'), ('P', 'p'), ('A', 'a'), ('P', 'p'), ('E', 'e'), ('R', 'R')] 

 Dependency tags are: 
>> [(('W', 'T'), 'vocative'), (('H', 'W'), 'punct'), (('I', 'T'), 'nsubj'), (('T', 'root'), 'root'), (('E', 'T'), 'obj'), (('P', 'T'), 'obj'), (('A', 'E'), 'compound'), (('P', 'E'), 'compound'), (('E', 'R'), 'compound'), (('R', 'T'), 'obj')]

 Named Entites are: 
>> []

================================ Paragraph 2 =================================

sentiment 


------------------- Sentence 1 -------------------

 sentiment 

Tokens are: 
>> ['sentiment'] 

 UPOS tags are: 
>> [('sentiment', 'NOUN')] 

 XPOS tags are: 
>> [('sentiment', 'NN')] 

 Lemmas are: 
>> [('sentiment', 'sentiment')] 

 Dependency tags are: 
>> [(('sentiment', 'root'), 'root')]

 Named Entites are: 
>> []

================================ Paragraph 3 =================================

recall 


------------------- Sentence 1 -------------------

 recall 

Tokens are: 
>> ['recall'] 

 UPOS tags are: 
>> [('recall', 'VERB')] 

 XPOS tags are: 
>> [('recall', 'VB')] 

 Lemmas are: 
>> [('recall', 'recall')] 

 Dependency tags are: 
>> [(('recall', 'root'), 'root')]

 Named Entites are: 
>> []

================================ Paragraph 4 =================================

precision 


------------------- Sentence 1 -------------------

 precision 

Tokens are: 
>> ['precision'] 

 UPOS tags are: 
>> [('precision', 'NOUN')] 

 XPOS tags are: 
>> [('precision', 'NN')] 

 Lemmas are: 
>> [('precision', 'precision')] 

 Dependency tags are: 
>> [(('precision', 'root'), 'root')]

 Named Entites are: 
>> []

================================ Paragraph 5 =================================

part of speech 


------------------- Sentence 1 -------------------

 part of speech 

Tokens are: 
>> ['part', 'of', 'speech'] 

 UPOS tags are: 
>> [('part', 'NOUN'), ('of', 'ADP'), ('speech', 'NOUN')] 

 XPOS tags are: 
>> [('part', 'NN'), ('of', 'IN'), ('speech', 'NN')] 

 Lemmas are: 
>> [('part', 'part'), ('of', 'of'), ('speech', 'speech')] 

 Dependency tags are: 
>> [(('part', 'root'), 'root'), (('of', 'speech'), 'case'), (('speech', 'part'), 'nmod')]

 Named Entites are: 
>> []

================================ Paragraph 6 =================================

machine learning 


------------------- Sentence 1 -------------------

 machine learning 

Tokens are: 
>> ['machine', 'learning'] 

 UPOS tags are: 
>> [('machine', 'NOUN'), ('learning', 'NOUN')] 

 XPOS tags are: 
>> [('machine', 'NN'), ('learning', 'NN')] 

 Lemmas are: 
>> [('machine', 'machine'), ('learning', 'learning')] 

 Dependency tags are: 
>> [(('machine', 'learning'), 'compound'), (('learning', 'root'), 'root')]

 Named Entites are: 
>> []

================================ Paragraph 7 =================================

data ratio 


------------------- Sentence 1 -------------------

 data ratio 

Tokens are: 
>> ['data', 'ratio'] 

 UPOS tags are: 
>> [('data', 'NOUN'), ('ratio', 'NOUN')] 

 XPOS tags are: 
>> [('data', 'NNS'), ('ratio', 'NN')] 

 Lemmas are: 
>> [('data', 'datum'), ('ratio', 'ratio')] 

 Dependency tags are: 
>> [(('data', 'ratio'), 'compound'), (('ratio', 'root'), 'root')]

 Named Entites are: 
>> []

================================ Paragraph 8 =================================

NLP 


------------------- Sentence 1 -------------------

 NLP 

Tokens are: 
>> ['NLP'] 

 UPOS tags are: 
>> [('NLP', 'PROPN')] 

 XPOS tags are: 
>> [('NLP', 'NNP')] 

 Lemmas are: 
>> [('NLP', 'NLP')] 

 Dependency tags are: 
>> [(('NLP', 'root'), 'root')]

 Named Entites are: 
>> []

================================ Paragraph 9 =================================

syntax tuning 


------------------- Sentence 1 -------------------

 syntax tuning 

Tokens are: 
>> ['syntax', 'tuning'] 

 UPOS tags are: 
>> [('syntax', 'NOUN'), ('tuning', 'NOUN')] 

 XPOS tags are: 
>> [('syntax', 'NN'), ('tuning', 'NN')] 

 Lemmas are: 
>> [('syntax', 'syntax'), ('tuning', 'tuning')] 

 Dependency tags are: 
>> [(('syntax', 'tuning'), 'compound'), (('tuning', 'root'), 'root')]

 Named Entites are: 
>> []

================================ Paragraph 10 =================================

themes 


------------------- Sentence 1 -------------------

 themes 

Tokens are: 
>> ['themes'] 

 UPOS tags are: 
>> [('themes', 'NOUN')] 

 XPOS tags are: 
>> [('themes', 'NNS')] 

 Lemmas are: 
>> [('themes', 'theme')] 

 Dependency tags are: 
>> [(('themes', 'root'), 'root')]

 Named Entites are: 
>> []

================================ Paragraph 11 =================================

named entity extraction 


------------------- Sentence 1 -------------------

 named entity extraction 

Tokens are: 
>> ['named', 'entity', 'extraction'] 

 UPOS tags are: 
>> [('named', 'VERB'), ('entity', 'NOUN'), ('extraction', 'NOUN')] 

 XPOS tags are: 
>> [('named', 'VBN'), ('entity', 'NN'), ('extraction', 'NN')] 

 Lemmas are: 
>> [('named', 'name'), ('entity', 'entity'), ('extraction', 'extraction')] 

 Dependency tags are: 
>> [(('named', 'root'), 'root'), (('entity', 'extraction'), 'compound'), (('extraction', 'named'), 'obj')]

 Named Entites are: 
>> []

================================ Paragraph 12 =================================

accuracy 


------------------- Sentence 1 -------------------

 accuracy 

Tokens are: 
>> ['accuracy'] 

 UPOS tags are: 
>> [('accuracy', 'NOUN')] 

 XPOS tags are: 
>> [('accuracy', 'NN')] 

 Lemmas are: 
>> [('accuracy', 'accuracy')] 

 Dependency tags are: 
>> [(('accuracy', 'root'), 'root')]

 Named Entites are: 
>> []

================================ Paragraph 13 =================================

training 


------------------- Sentence 1 -------------------

 training 

Tokens are: 
>> ['training'] 

 UPOS tags are: 
>> [('training', 'NOUN')] 

 XPOS tags are: 
>> [('training', 'NN')] 

 Lemmas are: 
>> [('training', 'training')] 

 Dependency tags are: 
>> [(('training', 'root'), 'root')]

 Named Entites are: 
>> []

================================ Paragraph 14 =================================

AI 


------------------- Sentence 1 -------------------

 AI 

Tokens are: 
>> ['AI'] 

 UPOS tags are: 
>> [('AI', 'PROPN')] 

 XPOS tags are: 
>> [('AI', 'NNP')] 

 Lemmas are: 
>> [('AI', 'AI')] 

 Dependency tags are: 
>> [(('AI', 'root'), 'root')]

 Named Entites are: 
>> []

================================ Paragraph 15 =================================

Lexalytics, Inc., 48 North Pleasant St. Unit 301, Amherst MA 01002 USA | 1-800-377-8036 | www.lexalytics.com 


------------------- Sentence 1 -------------------

 Lexalytics, Inc., 48 North Pleasant St. Unit 301, Amherst MA 01002 USA | 1-800-377-8036 | www.lexalytics.com 

Tokens are: 
>> ['Lexalytics', ',', 'Inc.', ',', '48', 'North', 'Pleasant', 'St.', 'Unit', '301', ',', 'Amherst', 'MA', '01002', 'USA', '|', '1-800-377-8036', '|', 'www.lexalytics.com'] 

 UPOS tags are: 
>> [('Lexalytics', 'PROPN'), (',', 'PUNCT'), ('Inc.', 'PROPN'), (',', 'PUNCT'), ('48', 'NUM'), ('North', 'PROPN'), ('Pleasant', 'ADJ'), ('St.', 'PROPN'), ('Unit', 'PROPN'), ('301', 'NUM'), (',', 'PUNCT'), ('Amherst', 'PROPN'), ('MA', 'PROPN'), ('01002', 'NUM'), ('USA', 'PROPN'), ('|', 'PUNCT'), ('1-800-377-8036', 'NUM'), ('|', 'PUNCT'), ('www.lexalytics.com', 'X')] 

 XPOS tags are: 
>> [('Lexalytics', 'NNPS'), (',', ','), ('Inc.', 'NNP'), (',', ','), ('48', 'CD'), ('North', 'NNP'), ('Pleasant', 'NNP'), ('St.', 'NNP'), ('Unit', 'NNP'), ('301', 'CD'), (',', ','), ('Amherst', 'NNP'), ('MA', 'NNP'), ('01002', 'CD'), ('USA', 'NNP'), ('|', 'NFP'), ('1-800-377-8036', 'CD'), ('|', 'NFP'), ('www.lexalytics.com', 'ADD')] 

 Lemmas are: 
>> [('Lexalytics', 'Lexalytics'), (',', ','), ('Inc.', 'Inc.'), (',', ','), ('48', '48'), ('North', 'North'), ('Pleasant', 'Pleasant'), ('St.', 'St.'), ('Unit', 'unit'), ('301', '301'), (',', ','), ('Amherst', 'Amherst'), ('MA', 'MA'), ('01002', '01002'), ('USA', 'USA'), ('|', '|'), ('1-800-377-8036', '1-800-377-8036'), ('|', '|'), ('www.lexalytics.com', 'www.lexalytics.com')] 

 Dependency tags are: 
>> [(('Lexalytics', 'root'), 'root'), ((',', 'Inc.'), 'punct'), (('Inc.', 'Lexalytics'), 'list'), ((',', 'Lexalytics'), 'punct'), (('48', 'St.'), 'nummod'), (('North', 'St.'), 'compound'), (('Pleasant', 'St.'), 'amod'), (('St.', 'Lexalytics'), 'list'), (('Unit', 'Lexalytics'), 'list'), (('301', 'Unit'), 'nummod'), ((',', 'Unit'), 'punct'), (('Amherst', 'Unit'), 'appos'), (('MA', 'Lexalytics'), 'list'), (('01002', 'USA'), 'nummod'), (('USA', 'MA'), 'appos'), (('|', 'USA'), 'punct'), (('1-800-377-8036', 'Lexalytics'), 'list'), (('|', '1-800-377-8036'), 'punct'), (('www.lexalytics.com', 'Lexalytics'), 'list')]

 Named Entites are: 
>> [('Lexalytics, Inc.', 'ORG'), ('301', 'CARDINAL'), ('Amherst', 'GPE')]

================================ Paragraph 16 =================================

 Machine Learning for   Natural Language Processing   


------------------- Sentence 1 -------------------

 Machine Learning for   Natural Language Processing 

Tokens are: 
>> ['Machine', 'Learning', 'for', 'Natural', 'Language', 'Processing'] 

 UPOS tags are: 
>> [('Machine', 'NOUN'), ('Learning', 'NOUN'), ('for', 'ADP'), ('Natural', 'ADJ'), ('Language', 'NOUN'), ('Processing', 'NOUN')] 

 XPOS tags are: 
>> [('Machine', 'NN'), ('Learning', 'NN'), ('for', 'IN'), ('Natural', 'JJ'), ('Language', 'NN'), ('Processing', 'NN')] 

 Lemmas are: 
>> [('Machine', 'Machine'), ('Learning', 'learning'), ('for', 'for'), ('Natural', 'Natural'), ('Language', 'language'), ('Processing', 'processing')] 

 Dependency tags are: 
>> [(('Machine', 'Learning'), 'compound'), (('Learning', 'root'), 'root'), (('for', 'Processing'), 'case'), (('Natural', 'Processing'), 'amod'), (('Language', 'Processing'), 'compound'), (('Processing', 'Learning'), 'nmod')]

 Named Entites are: 
>> []

================================ Paragraph 17 =================================

and Text Analytics


------------------- Sentence 1 -------------------

 and Text Analytics 

Tokens are: 
>> ['and', 'Text', 'Analytics'] 

 UPOS tags are: 
>> [('and', 'CCONJ'), ('Text', 'NOUN'), ('Analytics', 'NOUN')] 

 XPOS tags are: 
>> [('and', 'CC'), ('Text', 'NN'), ('Analytics', 'NNS')] 

 Lemmas are: 
>> [('and', 'and'), ('Text', 'text'), ('Analytics', 'Analytics')] 

 Dependency tags are: 
>> [(('and', 'Analytics'), 'cc'), (('Text', 'Analytics'), 'compound'), (('Analytics', 'root'), 'root')]

 Named Entites are: 
>> []

================================ Paragraph 18 =================================

W H I T E  P A P E R 


------------------- Sentence 1 -------------------

 W H I T E  P A P E R 

Tokens are: 
>> ['W', 'H', 'I', 'T', 'E', 'P', 'A', 'P', 'E', 'R'] 

 UPOS tags are: 
>> [('W', 'PROPN'), ('H', 'PUNCT'), ('I', 'PRON'), ('T', 'AUX'), ('E', 'PROPN'), ('P', 'NOUN'), ('A', 'NOUN'), ('P', 'NOUN'), ('E', 'NOUN'), ('R', 'NOUN')] 

 XPOS tags are: 
>> [('W', 'NNP'), ('H', ','), ('I', 'PRP'), ('T', 'VBP'), ('E', 'NNP'), ('P', 'NN'), ('A', 'NN'), ('P', 'NN'), ('E', 'NN'), ('R', 'NN')] 

 Lemmas are: 
>> [('W', 'W'), ('H', 'H'), ('I', 'I'), ('T', 'T'), ('E', 'E'), ('P', 'p'), ('A', 'a'), ('P', 'p'), ('E', 'e'), ('R', 'R')] 

 Dependency tags are: 
>> [(('W', 'T'), 'vocative'), (('H', 'W'), 'punct'), (('I', 'T'), 'nsubj'), (('T', 'root'), 'root'), (('E', 'T'), 'obj'), (('P', 'T'), 'obj'), (('A', 'E'), 'compound'), (('P', 'E'), 'compound'), (('E', 'R'), 'compound'), (('R', 'T'), 'obj')]

 Named Entites are: 
>> []

================================ Paragraph 19 =================================

T A B L E  O F  C O N T E N T S 


------------------- Sentence 1 -------------------

 T A B L E  O F  C O N T E N T S 

Tokens are: 
>> ['T', 'A', 'B', 'L', 'E', 'O', 'F', 'C', 'O', 'N', 'T', 'E', 'N', 'T', 'S'] 

 UPOS tags are: 
>> [('T', 'PROPN'), ('A', 'PROPN'), ('B', 'NOUN'), ('L', 'PROPN'), ('E', 'NOUN'), ('O', 'NOUN'), ('F', 'PROPN'), ('C', 'PROPN'), ('O', 'PROPN'), ('N', 'PROPN'), ('T', 'PROPN'), ('E', 'PROPN'), ('N', 'PROPN'), ('T', 'PROPN'), ('S', 'PUNCT')] 

 XPOS tags are: 
>> [('T', 'NNP'), ('A', 'NNP'), ('B', 'NN'), ('L', 'NNP'), ('E', 'NN'), ('O', 'NN'), ('F', 'NNP'), ('C', 'NNP'), ('O', 'NNP'), ('N', 'NNP'), ('T', 'NNP'), ('E', 'NNP'), ('N', 'NNP'), ('T', 'NNP'), ('S', '.')] 

 Lemmas are: 
>> [('T', 'T'), ('A', 'A'), ('B', 'b'), ('L', 'L'), ('E', 'e'), ('O', 'o'), ('F', 'F'), ('C', 'C'), ('O', 'o'), ('N', 'N'), ('T', 'T'), ('E', 'E'), ('N', 'N'), ('T', 'T'), ('S', 'S')] 

 Dependency tags are: 
>> [(('T', 'root'), 'root'), (('A', 'T'), 'flat'), (('B', 'T'), 'list'), (('L', 'B'), 'flat'), (('E', 'B'), 'flat'), (('O', 'B'), 'list'), (('F', 'O'), 'appos'), (('C', 'F'), 'appos'), (('O', 'N'), 'compound'), (('N', 'T'), 'compound'), (('T', 'F'), 'appos'), (('E', 'T'), 'flat'), (('N', 'T'), 'compound'), (('T', 'E'), 'flat'), (('S', 'T'), 'punct')]

 Named Entites are: 
>> []

================================ Paragraph 20 =================================

2|       |   Lexalytics, Inc., 48 North Pleasant St. Unit 301, Amherst MA 01002 USA   |   1-800-377-8036 |   www.lexalytics.com 


------------------- Sentence 1 -------------------

 2|       |   Lexalytics, Inc., 48 North Pleasant St. Unit 301, Amherst MA 01002 USA   |   1-800-377-8036 |   www.lexalytics.com 

Tokens are: 
>> ['2', '|', '|', 'Lexalytics', ',', 'Inc.', ',', '48', 'North', 'Pleasant', 'St.', 'Unit', '301', ',', 'Amherst', 'MA', '01002', 'USA', '|', '1-800-377-8036', '|', 'www.lexalytics.com'] 

 UPOS tags are: 
>> [('2', 'NUM'), ('|', 'PUNCT'), ('|', 'PUNCT'), ('Lexalytics', 'PROPN'), (',', 'PUNCT'), ('Inc.', 'PROPN'), (',', 'PUNCT'), ('48', 'NUM'), ('North', 'PROPN'), ('Pleasant', 'ADJ'), ('St.', 'PROPN'), ('Unit', 'NOUN'), ('301', 'NUM'), (',', 'PUNCT'), ('Amherst', 'PROPN'), ('MA', 'PROPN'), ('01002', 'NUM'), ('USA', 'PROPN'), ('|', 'PUNCT'), ('1-800-377-8036', 'NUM'), ('|', 'PUNCT'), ('www.lexalytics.com', 'X')] 

 XPOS tags are: 
>> [('2', 'LS'), ('|', 'NFP'), ('|', 'NFP'), ('Lexalytics', 'NNP'), (',', ','), ('Inc.', 'NNP'), (',', ','), ('48', 'CD'), ('North', 'NNP'), ('Pleasant', 'NNP'), ('St.', 'NNP'), ('Unit', 'NN'), ('301', 'CD'), (',', ','), ('Amherst', 'NNP'), ('MA', 'NNP'), ('01002', 'CD'), ('USA', 'NNP'), ('|', 'NFP'), ('1-800-377-8036', 'CD'), ('|', 'NFP'), ('www.lexalytics.com', 'ADD')] 

 Lemmas are: 
>> [('2', '2'), ('|', '|'), ('|', '|'), ('Lexalytics', 'Lexalytics'), (',', ','), ('Inc.', 'Inc.'), (',', ','), ('48', '48'), ('North', 'North'), ('Pleasant', 'Pleasant'), ('St.', 'St.'), ('Unit', 'unit'), ('301', '301'), (',', ','), ('Amherst', 'Amherst'), ('MA', 'MA'), ('01002', '01002'), ('USA', 'USA'), ('|', '|'), ('1-800-377-8036', '1-800-377-8036'), ('|', '|'), ('www.lexalytics.com', 'www.lexalytics.com')] 

 Dependency tags are: 
>> [(('2', 'Inc.'), 'nummod'), (('|', '2'), 'punct'), (('|', '2'), 'punct'), (('Lexalytics', 'Inc.'), 'compound'), ((',', 'Inc.'), 'punct'), (('Inc.', 'root'), 'root'), ((',', 'Inc.'), 'punct'), (('48', 'St.'), 'nummod'), (('North', 'St.'), 'compound'), (('Pleasant', 'St.'), 'amod'), (('St.', 'Inc.'), 'list'), (('Unit', 'St.'), 'appos'), (('301', 'Unit'), 'nummod'), ((',', 'MA'), 'punct'), (('Amherst', 'MA'), 'appos'), (('MA', 'Inc.'), 'list'), (('01002', 'USA'), 'nummod'), (('USA', 'MA'), 'appos'), (('|', 'USA'), 'punct'), (('1-800-377-8036', 'Inc.'), 'list'), (('|', '1-800-377-8036'), 'punct'), (('www.lexalytics.com', 'Inc.'), 'list')]

 Named Entites are: 
>> [('2|       |   Lexalytics, Inc.', 'ORG'), ('301', 'CARDINAL')]

================================ Paragraph 21 =================================

Introduction Machine learning is everywhere, from helping us make better toast to  researching drug discovery and designs. Sometimes the term is used  interchangeably with artificial intelligence (AI), but they’re not the same  thing. While all AI involves machine learning, not all machine learning is AI.  


------------------- Sentence 1 -------------------

 Introduction Machine learning is everywhere, from helping us make better toast to  researching drug discovery and designs. 

Tokens are: 
>> ['Introduction', 'Machine', 'learning', 'is', 'everywhere', ',', 'from', 'helping', 'us', 'make', 'better', 'toast', 'to', 'researching', 'drug', 'discovery', 'and', 'designs', '.'] 

 UPOS tags are: 
>> [('Introduction', 'NOUN'), ('Machine', 'NOUN'), ('learning', 'NOUN'), ('is', 'AUX'), ('everywhere', 'ADV'), (',', 'PUNCT'), ('from', 'SCONJ'), ('helping', 'VERB'), ('us', 'PRON'), ('make', 'VERB'), ('better', 'ADJ'), ('toast', 'NOUN'), ('to', 'SCONJ'), ('researching', 'VERB'), ('drug', 'NOUN'), ('discovery', 'NOUN'), ('and', 'CCONJ'), ('designs', 'NOUN'), ('.', 'PUNCT')] 

 XPOS tags are: 
>> [('Introduction', 'NN'), ('Machine', 'NN'), ('learning', 'NN'), ('is', 'VBZ'), ('everywhere', 'RB'), (',', ','), ('from', 'IN'), ('helping', 'VBG'), ('us', 'PRP'), ('make', 'VB'), ('better', 'JJR'), ('toast', 'NN'), ('to', 'IN'), ('researching', 'VBG'), ('drug', 'NN'), ('discovery', 'NN'), ('and', 'CC'), ('designs', 'NNS'), ('.', '.')] 

 Lemmas are: 
>> [('Introduction', 'introduction'), ('Machine', 'Machine'), ('learning', 'learning'), ('is', 'be'), ('everywhere', 'everywhere'), (',', ','), ('from', 'from'), ('helping', 'help'), ('us', 'we'), ('make', 'make'), ('better', 'good'), ('toast', 'toast'), ('to', 'to'), ('researching', 'research'), ('drug', 'drug'), ('discovery', 'discovery'), ('and', 'and'), ('designs', 'design'), ('.', '.')] 

 Dependency tags are: 
>> [(('Introduction', 'learning'), 'compound'), (('Machine', 'learning'), 'compound'), (('learning', 'everywhere'), 'nsubj'), (('is', 'everywhere'), 'cop'), (('everywhere', 'root'), 'root'), ((',', 'helping'), 'punct'), (('from', 'helping'), 'mark'), (('helping', 'everywhere'), 'advcl'), (('us', 'helping'), 'obj'), (('make', 'helping'), 'xcomp'), (('better', 'toast'), 'amod'), (('toast', 'make'), 'obj'), (('to', 'researching'), 'mark'), (('researching', 'make'), 'advcl'), (('drug', 'discovery'), 'compound'), (('discovery', 'researching'), 'obj'), (('and', 'designs'), 'cc'), (('designs', 'discovery'), 'conj'), (('.', 'everywhere'), 'punct')]

 Named Entites are: 
>> []

------------------- Sentence 2 -------------------

 Sometimes the term is used  interchangeably with artificial intelligence (AI), but they’re not the same  thing. 

Tokens are: 
>> ['Sometimes', 'the', 'term', 'is', 'used', 'interchangeably', 'with', 'artificial', 'intelligence', '(', 'AI', ')', ',', 'but', 'they', '’re', 'not', 'the', 'same', 'thing', '.'] 

 UPOS tags are: 
>> [('Sometimes', 'ADV'), ('the', 'DET'), ('term', 'NOUN'), ('is', 'AUX'), ('used', 'VERB'), ('interchangeably', 'ADV'), ('with', 'ADP'), ('artificial', 'ADJ'), ('intelligence', 'NOUN'), ('(', 'PUNCT'), ('AI', 'NOUN'), (')', 'PUNCT'), (',', 'PUNCT'), ('but', 'CCONJ'), ('they', 'PRON'), ('’re', 'AUX'), ('not', 'PART'), ('the', 'DET'), ('same', 'ADJ'), ('thing', 'NOUN'), ('.', 'PUNCT')] 

 XPOS tags are: 
>> [('Sometimes', 'RB'), ('the', 'DT'), ('term', 'NN'), ('is', 'VBZ'), ('used', 'VBN'), ('interchangeably', 'RB'), ('with', 'IN'), ('artificial', 'JJ'), ('intelligence', 'NN'), ('(', '-LRB-'), ('AI', 'NN'), (')', '-RRB-'), (',', ','), ('but', 'CC'), ('they', 'PRP'), ('’re', 'VBP'), ('not', 'RB'), ('the', 'DT'), ('same', 'JJ'), ('thing', 'NN'), ('.', '.')] 

 Lemmas are: 
>> [('Sometimes', 'sometimes'), ('the', 'the'), ('term', 'term'), ('is', 'be'), ('used', 'use'), ('interchangeably', 'interchangeably'), ('with', 'with'), ('artificial', 'artificial'), ('intelligence', 'intelligence'), ('(', '('), ('AI', 'ai'), (')', ')'), (',', ','), ('but', 'but'), ('they', 'they'), ('’re', 'be'), ('not', 'not'), ('the', 'the'), ('same', 'same'), ('thing', 'thing'), ('.', '.')] 

 Dependency tags are: 
>> [(('Sometimes', 'used'), 'advmod'), (('the', 'term'), 'det'), (('term', 'used'), 'nsubj:pass'), (('is', 'used'), 'aux:pass'), (('used', 'root'), 'root'), (('interchangeably', 'used'), 'advmod'), (('with', 'intelligence'), 'case'), (('artificial', 'intelligence'), 'amod'), (('intelligence', 'used'), 'obl'), (('(', 'AI'), 'punct'), (('AI', 'intelligence'), 'appos'), ((')', 'AI'), 'punct'), ((',', 'thing'), 'punct'), (('but', 'thing'), 'cc'), (('they', 'thing'), 'nsubj'), (('’re', 'thing'), 'cop'), (('not', 'thing'), 'advmod'), (('the', 'thing'), 'det'), (('same', 'thing'), 'amod'), (('thing', 'used'), 'conj'), (('.', 'used'), 'punct')]

 Named Entites are: 
>> []

------------------- Sentence 3 -------------------

 While all AI involves machine learning, not all machine learning is AI. 

Tokens are: 
>> ['While', 'all', 'AI', 'involves', 'machine', 'learning', ',', 'not', 'all', 'machine', 'learning', 'is', 'AI', '.'] 

 UPOS tags are: 
>> [('While', 'SCONJ'), ('all', 'DET'), ('AI', 'NOUN'), ('involves', 'VERB'), ('machine', 'NOUN'), ('learning', 'NOUN'), (',', 'PUNCT'), ('not', 'ADV'), ('all', 'DET'), ('machine', 'NOUN'), ('learning', 'NOUN'), ('is', 'AUX'), ('AI', 'VERB'), ('.', 'PUNCT')] 

 XPOS tags are: 
>> [('While', 'IN'), ('all', 'DT'), ('AI', 'NN'), ('involves', 'VBZ'), ('machine', 'NN'), ('learning', 'NN'), (',', ','), ('not', 'RB'), ('all', 'DT'), ('machine', 'NN'), ('learning', 'NN'), ('is', 'VBZ'), ('AI', 'VBN'), ('.', '.')] 

 Lemmas are: 
>> [('While', 'while'), ('all', 'all'), ('AI', 'ai'), ('involves', 'involve'), ('machine', 'machine'), ('learning', 'learning'), (',', ','), ('not', 'not'), ('all', 'all'), ('machine', 'machine'), ('learning', 'learning'), ('is', 'be'), ('AI', 'be'), ('.', '.')] 

 Dependency tags are: 
>> [(('While', 'involves'), 'mark'), (('all', 'AI'), 'det'), (('AI', 'involves'), 'nsubj'), (('involves', 'AI'), 'advcl'), (('machine', 'learning'), 'compound'), (('learning', 'involves'), 'obj'), ((',', 'AI'), 'punct'), (('not', 'learning'), 'advmod'), (('all', 'learning'), 'det'), (('machine', 'learning'), 'compound'), (('learning', 'AI'), 'nsubj'), (('is', 'AI'), 'cop'), (('AI', 'root'), 'root'), (('.', 'AI'), 'punct')]

 Named Entites are: 
>> [('AI', 'ORG')]

================================ Paragraph 22 =================================

Lexalytics’ core text analytics engine, Salience, can be considered a  “narrow” AI: It uses many different types of machine learning to solve  the task of understanding and analyzing text, but is focused exclusively  on text. We’ll be looking at the machine learning and natural language  processing (NLP) elements that Salience is built upon. 


------------------- Sentence 1 -------------------

 Lexalytics’ core text analytics engine, Salience, can be considered a  “narrow” AI: 

Tokens are: 
>> ['Lexalytics', '’', 'core', 'text', 'analytics', 'engine', ',', 'Salience', ',', 'can', 'be', 'considered', 'a', '“', 'narrow', '”', 'AI', ':'] 

 UPOS tags are: 
>> [('Lexalytics', 'NOUN'), ('’', 'PART'), ('core', 'NOUN'), ('text', 'NOUN'), ('analytics', 'NOUN'), ('engine', 'NOUN'), (',', 'PUNCT'), ('Salience', 'NOUN'), (',', 'PUNCT'), ('can', 'AUX'), ('be', 'AUX'), ('considered', 'VERB'), ('a', 'DET'), ('“', 'PUNCT'), ('narrow', 'ADJ'), ('”', 'PUNCT'), ('AI', 'NOUN'), (':', 'PUNCT')] 

 XPOS tags are: 
>> [('Lexalytics', 'NNS'), ('’', 'POS'), ('core', 'NN'), ('text', 'NN'), ('analytics', 'NN'), ('engine', 'NN'), (',', ','), ('Salience', 'NN'), (',', ','), ('can', 'MD'), ('be', 'VB'), ('considered', 'VBN'), ('a', 'DT'), ('“', '``'), ('narrow', 'JJ'), ('”', "''"), ('AI', 'NN'), (':', ':')] 

 Lemmas are: 
>> [('Lexalytics', 'lexalytics'), ('’', "'s"), ('core', 'core'), ('text', 'text'), ('analytics', 'analytic'), ('engine', 'engine'), (',', ','), ('Salience', 'salience'), (',', ','), ('can', 'can'), ('be', 'be'), ('considered', 'consider'), ('a', 'a'), ('“', "''"), ('narrow', 'narrow'), ('”', "''"), ('AI', 'ai'), (':', ':')] 

 Dependency tags are: 
>> [(('Lexalytics', 'engine'), 'nmod:poss'), (('’', 'Lexalytics'), 'case'), (('core', 'text'), 'compound'), (('text', 'engine'), 'compound'), (('analytics', 'engine'), 'compound'), (('engine', 'considered'), 'nsubj:pass'), ((',', 'Salience'), 'punct'), (('Salience', 'engine'), 'conj'), ((',', 'considered'), 'punct'), (('can', 'considered'), 'aux'), (('be', 'considered'), 'aux:pass'), (('considered', 'root'), 'root'), (('a', 'AI'), 'det'), (('“', 'AI'), 'punct'), (('narrow', 'AI'), 'amod'), (('”', 'narrow'), 'punct'), (('AI', 'considered'), 'xcomp'), ((':', 'considered'), 'punct')]

 Named Entites are: 
>> [('Salience', 'PRODUCT')]

------------------- Sentence 2 -------------------

 It uses many different types of machine learning to solve  the task of understanding and analyzing text, but is focused exclusively  on text. 

Tokens are: 
>> ['It', 'uses', 'many', 'different', 'types', 'of', 'machine', 'learning', 'to', 'solve', 'the', 'task', 'of', 'understanding', 'and', 'analyzing', 'text', ',', 'but', 'is', 'focused', 'exclusively', 'on', 'text', '.'] 

 UPOS tags are: 
>> [('It', 'PRON'), ('uses', 'VERB'), ('many', 'ADJ'), ('different', 'ADJ'), ('types', 'NOUN'), ('of', 'ADP'), ('machine', 'NOUN'), ('learning', 'NOUN'), ('to', 'PART'), ('solve', 'VERB'), ('the', 'DET'), ('task', 'NOUN'), ('of', 'SCONJ'), ('understanding', 'NOUN'), ('and', 'CCONJ'), ('analyzing', 'VERB'), ('text', 'NOUN'), (',', 'PUNCT'), ('but', 'CCONJ'), ('is', 'AUX'), ('focused', 'VERB'), ('exclusively', 'ADV'), ('on', 'ADP'), ('text', 'NOUN'), ('.', 'PUNCT')] 

 XPOS tags are: 
>> [('It', 'PRP'), ('uses', 'VBZ'), ('many', 'JJ'), ('different', 'JJ'), ('types', 'NNS'), ('of', 'IN'), ('machine', 'NN'), ('learning', 'NN'), ('to', 'TO'), ('solve', 'VB'), ('the', 'DT'), ('task', 'NN'), ('of', 'IN'), ('understanding', 'NN'), ('and', 'CC'), ('analyzing', 'VBG'), ('text', 'NN'), (',', ','), ('but', 'CC'), ('is', 'VBZ'), ('focused', 'VBN'), ('exclusively', 'RB'), ('on', 'IN'), ('text', 'NN'), ('.', '.')] 

 Lemmas are: 
>> [('It', 'it'), ('uses', 'use'), ('many', 'many'), ('different', 'different'), ('types', 'type'), ('of', 'of'), ('machine', 'machine'), ('learning', 'learning'), ('to', 'to'), ('solve', 'solve'), ('the', 'the'), ('task', 'task'), ('of', 'of'), ('understanding', 'understanding'), ('and', 'and'), ('analyzing', 'analyze'), ('text', 'text'), (',', ','), ('but', 'but'), ('is', 'be'), ('focused', 'focus'), ('exclusively', 'exclusively'), ('on', 'on'), ('text', 'text'), ('.', '.')] 

 Dependency tags are: 
>> [(('It', 'uses'), 'nsubj'), (('uses', 'root'), 'root'), (('many', 'types'), 'amod'), (('different', 'types'), 'amod'), (('types', 'uses'), 'obj'), (('of', 'learning'), 'case'), (('machine', 'learning'), 'compound'), (('learning', 'types'), 'nmod'), (('to', 'solve'), 'mark'), (('solve', 'uses'), 'csubj'), (('the', 'task'), 'det'), (('task', 'solve'), 'obj'), (('of', 'understanding'), 'case'), (('understanding', 'task'), 'nmod'), (('and', 'analyzing'), 'cc'), (('analyzing', 'understanding'), 'conj'), (('text', 'understanding'), 'conj'), ((',', 'focused'), 'punct'), (('but', 'focused'), 'cc'), (('is', 'focused'), 'aux:pass'), (('focused', 'uses'), 'conj'), (('exclusively', 'focused'), 'advmod'), (('on', 'text'), 'case'), (('text', 'focused'), 'obl'), (('.', 'uses'), 'punct')]

 Named Entites are: 
>> []

------------------- Sentence 3 -------------------

 We’ll be looking at the machine learning and natural language  processing (NLP) elements that Salience is built upon. 

Tokens are: 
>> ['We', '’ll', 'be', 'looking', 'at', 'the', 'machine', 'learning', 'and', 'natural', 'language', 'processing', '(', 'NLP', ')', 'elements', 'that', 'Salience', 'is', 'built', 'upon', '.'] 

 UPOS tags are: 
>> [('We', 'PRON'), ('’ll', 'AUX'), ('be', 'AUX'), ('looking', 'VERB'), ('at', 'ADP'), ('the', 'DET'), ('machine', 'NOUN'), ('learning', 'NOUN'), ('and', 'CCONJ'), ('natural', 'ADJ'), ('language', 'NOUN'), ('processing', 'NOUN'), ('(', 'PUNCT'), ('NLP', 'NOUN'), (')', 'PUNCT'), ('elements', 'NOUN'), ('that', 'PRON'), ('Salience', 'NOUN'), ('is', 'AUX'), ('built', 'VERB'), ('upon', 'ADP'), ('.', 'PUNCT')] 

 XPOS tags are: 
>> [('We', 'PRP'), ('’ll', 'MD'), ('be', 'VB'), ('looking', 'VBG'), ('at', 'IN'), ('the', 'DT'), ('machine', 'NN'), ('learning', 'NN'), ('and', 'CC'), ('natural', 'JJ'), ('language', 'NN'), ('processing', 'NN'), ('(', '-LRB-'), ('NLP', 'NN'), (')', '-RRB-'), ('elements', 'NNS'), ('that', 'WDT'), ('Salience', 'NN'), ('is', 'VBZ'), ('built', 'VBN'), ('upon', 'IN'), ('.', '.')] 

 Lemmas are: 
>> [('We', 'we'), ('’ll', 'will'), ('be', 'be'), ('looking', 'look'), ('at', 'at'), ('the', 'the'), ('machine', 'machine'), ('learning', 'learning'), ('and', 'and'), ('natural', 'natural'), ('language', 'language'), ('processing', 'processing'), ('(', '('), ('NLP', 'nlp'), (')', ')'), ('elements', 'element'), ('that', 'that'), ('Salience', 'salience'), ('is', 'be'), ('built', 'build'), ('upon', 'upon'), ('.', '.')] 

 Dependency tags are: 
>> [(('We', 'looking'), 'nsubj'), (('’ll', 'looking'), 'aux'), (('be', 'looking'), 'aux'), (('looking', 'root'), 'root'), (('at', 'elements'), 'case'), (('the', 'elements'), 'det'), (('machine', 'learning'), 'compound'), (('learning', 'processing'), 'compound'), (('and', 'language'), 'cc'), (('natural', 'language'), 'amod'), (('language', 'learning'), 'conj'), (('processing', 'elements'), 'compound'), (('(', 'NLP'), 'punct'), (('NLP', 'processing'), 'appos'), ((')', 'NLP'), 'punct'), (('elements', 'looking'), 'obl'), (('that', 'built'), 'obl'), (('Salience', 'built'), 'nsubj:pass'), (('is', 'built'), 'aux:pass'), (('built', 'elements'), 'acl:relcl'), (('upon', 'that'), 'case'), (('.', 'looking'), 'punct')]

 Named Entites are: 
>> [('Salience', 'ORG')]

================================ Paragraph 23 =================================

We’ll discuss the different aspects of text analytics and how Lexalytics,  a company with more than a decade of experience in machine learning,  applies machine learning to solve problems in natural language processing.  


------------------- Sentence 1 -------------------

 We’ll discuss the different aspects of text analytics and how Lexalytics,  a company with more than a decade of experience in machine learning,  applies machine learning to solve problems in natural language processing. 

Tokens are: 
>> ['We', '’ll', 'discuss', 'the', 'different', 'aspects', 'of', 'text', 'analytics', 'and', 'how', 'Lexalytics', ',', 'a', 'company', 'with', 'more', 'than', 'a', 'decade', 'of', 'experience', 'in', 'machine', 'learning', ',', 'applies', 'machine', 'learning', 'to', 'solve', 'problems', 'in', 'natural', 'language', 'processing', '.'] 

 UPOS tags are: 
>> [('We', 'PRON'), ('’ll', 'AUX'), ('discuss', 'VERB'), ('the', 'DET'), ('different', 'ADJ'), ('aspects', 'NOUN'), ('of', 'ADP'), ('text', 'NOUN'), ('analytics', 'NOUN'), ('and', 'CCONJ'), ('how', 'SCONJ'), ('Lexalytics', 'PROPN'), (',', 'PUNCT'), ('a', 'DET'), ('company', 'NOUN'), ('with', 'ADP'), ('more', 'ADJ'), ('than', 'ADP'), ('a', 'DET'), ('decade', 'NOUN'), ('of', 'ADP'), ('experience', 'NOUN'), ('in', 'ADP'), ('machine', 'NOUN'), ('learning', 'NOUN'), (',', 'PUNCT'), ('applies', 'VERB'), ('machine', 'NOUN'), ('learning', 'NOUN'), ('to', 'PART'), ('solve', 'VERB'), ('problems', 'NOUN'), ('in', 'ADP'), ('natural', 'ADJ'), ('language', 'NOUN'), ('processing', 'NOUN'), ('.', 'PUNCT')] 

 XPOS tags are: 
>> [('We', 'PRP'), ('’ll', 'MD'), ('discuss', 'VB'), ('the', 'DT'), ('different', 'JJ'), ('aspects', 'NNS'), ('of', 'IN'), ('text', 'NN'), ('analytics', 'NNS'), ('and', 'CC'), ('how', 'WRB'), ('Lexalytics', 'NNPS'), (',', ','), ('a', 'DT'), ('company', 'NN'), ('with', 'IN'), ('more', 'JJR'), ('than', 'IN'), ('a', 'DT'), ('decade', 'NN'), ('of', 'IN'), ('experience', 'NN'), ('in', 'IN'), ('machine', 'NN'), ('learning', 'NN'), (',', ','), ('applies', 'VBZ'), ('machine', 'NN'), ('learning', 'NN'), ('to', 'TO'), ('solve', 'VB'), ('problems', 'NNS'), ('in', 'IN'), ('natural', 'JJ'), ('language', 'NN'), ('processing', 'NN'), ('.', '.')] 

 Lemmas are: 
>> [('We', 'we'), ('’ll', 'will'), ('discuss', 'discuss'), ('the', 'the'), ('different', 'different'), ('aspects', 'aspect'), ('of', 'of'), ('text', 'text'), ('analytics', 'analytic'), ('and', 'and'), ('how', 'how'), ('Lexalytics', 'Lexalytics'), (',', ','), ('a', 'a'), ('company', 'company'), ('with', 'with'), ('more', 'more'), ('than', 'than'), ('a', 'a'), ('decade', 'decade'), ('of', 'of'), ('experience', 'experience'), ('in', 'in'), ('machine', 'machine'), ('learning', 'learning'), (',', ','), ('applies', 'apply'), ('machine', 'machine'), ('learning', 'learning'), ('to', 'to'), ('solve', 'solve'), ('problems', 'problem'), ('in', 'in'), ('natural', 'natural'), ('language', 'language'), ('processing', 'processing'), ('.', '.')] 

 Dependency tags are: 
>> [(('We', 'discuss'), 'nsubj'), (('’ll', 'discuss'), 'aux'), (('discuss', 'root'), 'root'), (('the', 'aspects'), 'det'), (('different', 'aspects'), 'amod'), (('aspects', 'discuss'), 'obj'), (('of', 'analytics'), 'case'), (('text', 'analytics'), 'compound'), (('analytics', 'aspects'), 'nmod'), (('and', 'applies'), 'cc'), (('how', 'applies'), 'mark'), (('Lexalytics', 'applies'), 'nsubj'), ((',', 'Lexalytics'), 'punct'), (('a', 'company'), 'det'), (('company', 'Lexalytics'), 'appos'), (('with', 'decade'), 'case'), (('more', 'decade'), 'advmod'), (('than', 'more'), 'fixed'), (('a', 'decade'), 'det'), (('decade', 'company'), 'nmod'), (('of', 'experience'), 'case'), (('experience', 'decade'), 'nmod'), (('in', 'learning'), 'case'), (('machine', 'learning'), 'compound'), (('learning', 'decade'), 'nmod'), ((',', 'applies'), 'punct'), (('applies', 'discuss'), 'advcl'), (('machine', 'learning'), 'compound'), (('learning', 'applies'), 'obj'), (('to', 'solve'), 'mark'), (('solve', 'applies'), 'advcl'), (('problems', 'solve'), 'obj'), (('in', 'processing'), 'case'), (('natural', 'processing'), 'amod'), (('language', 'processing'), 'compound'), (('processing', 'solve'), 'obl'), (('.', 'discuss'), 'punct')]

 Named Entites are: 
>> [('Lexalytics', 'ORG')]

================================ Paragraph 24 =================================

    3 KINDS OF TEXT ANALYTICS SYSTEMS  


------------------- Sentence 1 -------------------

 3 KINDS OF TEXT ANALYTICS SYSTEMS 

Tokens are: 
>> ['3', 'KINDS', 'OF', 'TEXT', 'ANALYTICS', 'SYSTEMS'] 

 UPOS tags are: 
>> [('3', 'NUM'), ('KINDS', 'NOUN'), ('OF', 'ADP'), ('TEXT', 'NOUN'), ('ANALYTICS', 'NOUN'), ('SYSTEMS', 'NOUN')] 

 XPOS tags are: 
>> [('3', 'CD'), ('KINDS', 'NNS'), ('OF', 'IN'), ('TEXT', 'NN'), ('ANALYTICS', 'NNS'), ('SYSTEMS', 'NNS')] 

 Lemmas are: 
>> [('3', '3'), ('KINDS', 'kind'), ('OF', 'of'), ('TEXT', 'text'), ('ANALYTICS', 'analytics'), ('SYSTEMS', 'systems')] 

 Dependency tags are: 
>> [(('3', 'KINDS'), 'nummod'), (('KINDS', 'root'), 'root'), (('OF', 'SYSTEMS'), 'case'), (('TEXT', 'ANALYTICS'), 'compound'), (('ANALYTICS', 'SYSTEMS'), 'compound'), (('SYSTEMS', 'KINDS'), 'nmod')]

 Named Entites are: 
>> [('3', 'CARDINAL')]

================================ Paragraph 25 =================================

 Rules-based (pure NLP)   


------------------- Sentence 1 -------------------

 Rules-based (pure NLP) 

Tokens are: 
>> ['Rules-based', '(', 'pure', 'NLP', ')'] 

 UPOS tags are: 
>> [('Rules-based', 'ADJ'), ('(', 'PUNCT'), ('pure', 'ADJ'), ('NLP', 'NOUN'), (')', 'PUNCT')] 

 XPOS tags are: 
>> [('Rules-based', 'JJ'), ('(', '-LRB-'), ('pure', 'JJ'), ('NLP', 'NN'), (')', '-RRB-')] 

 Lemmas are: 
>> [('Rules-based', 'Rules-based'), ('(', '('), ('pure', 'pure'), ('NLP', 'nlp'), (')', ')')] 

 Dependency tags are: 
>> [(('Rules-based', 'root'), 'root'), (('(', 'NLP'), 'punct'), (('pure', 'NLP'), 'amod'), (('NLP', 'Rules-based'), 'parataxis'), ((')', 'NLP'), 'punct')]

 Named Entites are: 
>> []

================================ Paragraph 26 =================================

 Machine learning-based (pure ML)  


------------------- Sentence 1 -------------------

 Machine learning-based (pure ML) 

Tokens are: 
>> ['Machine', 'learning', '-', 'based', '(', 'pure', 'ML', ')'] 

 UPOS tags are: 
>> [('Machine', 'NOUN'), ('learning', 'NOUN'), ('-', 'PUNCT'), ('based', 'VERB'), ('(', 'PUNCT'), ('pure', 'ADJ'), ('ML', 'NOUN'), (')', 'PUNCT')] 

 XPOS tags are: 
>> [('Machine', 'NN'), ('learning', 'NN'), ('-', 'HYPH'), ('based', 'VBN'), ('(', '-LRB-'), ('pure', 'JJ'), ('ML', 'NNS'), (')', '-RRB-')] 

 Lemmas are: 
>> [('Machine', 'Machine'), ('learning', 'learning'), ('-', '-'), ('based', 'base'), ('(', '('), ('pure', 'pure'), ('ML', 'ml'), (')', ')')] 

 Dependency tags are: 
>> [(('Machine', 'based'), 'compound'), (('learning', 'based'), 'compound'), (('-', 'based'), 'punct'), (('based', 'root'), 'root'), (('(', 'ML'), 'punct'), (('pure', 'ML'), 'amod'), (('ML', 'based'), 'appos'), ((')', 'ML'), 'punct')]

 Named Entites are: 
>> []

================================ Paragraph 27 =================================

 Hybrid (a combination of ML and NLP) 


------------------- Sentence 1 -------------------

 Hybrid (a combination of ML and NLP) 

Tokens are: 
>> ['Hybrid', '(', 'a', 'combination', 'of', 'ML', 'and', 'NLP', ')'] 

 UPOS tags are: 
>> [('Hybrid', 'NOUN'), ('(', 'PUNCT'), ('a', 'DET'), ('combination', 'NOUN'), ('of', 'ADP'), ('ML', 'NOUN'), ('and', 'CCONJ'), ('NLP', 'NOUN'), (')', 'PUNCT')] 

 XPOS tags are: 
>> [('Hybrid', 'NN'), ('(', '-LRB-'), ('a', 'DT'), ('combination', 'NN'), ('of', 'IN'), ('ML', 'NN'), ('and', 'CC'), ('NLP', 'NN'), (')', '-RRB-')] 

 Lemmas are: 
>> [('Hybrid', 'hybrid'), ('(', '('), ('a', 'a'), ('combination', 'combination'), ('of', 'of'), ('ML', 'ml'), ('and', 'and'), ('NLP', 'nlp'), (')', ')')] 

 Dependency tags are: 
>> [(('Hybrid', 'root'), 'root'), (('(', 'combination'), 'punct'), (('a', 'combination'), 'det'), (('combination', 'Hybrid'), 'appos'), (('of', 'ML'), 'case'), (('ML', 'combination'), 'nmod'), (('and', 'NLP'), 'cc'), (('NLP', 'ML'), 'conj'), ((')', 'combination'), 'punct')]

 Named Entites are: 
>> [('ML', 'ORG')]

================================ Paragraph 28 =================================

For further reading, you can consult our white papers “Build vs. Buy,”  which talks about the economics of machine learning in a text analytics  context, and “Tune First, Then Train,” which discusses our philosophy   of customization for better accuracy and more-relevant results. When  taken together with this paper, these resources offer a more complete  view of text analytics solutions. 


------------------- Sentence 1 -------------------

 For further reading, you can consult our white papers “Build vs. 

Tokens are: 
>> ['For', 'further', 'reading', ',', 'you', 'can', 'consult', 'our', 'white', 'papers', '“', 'Build', 'vs', '.'] 

 UPOS tags are: 
>> [('For', 'ADP'), ('further', 'ADJ'), ('reading', 'NOUN'), (',', 'PUNCT'), ('you', 'PRON'), ('can', 'AUX'), ('consult', 'VERB'), ('our', 'PRON'), ('white', 'ADJ'), ('papers', 'NOUN'), ('“', 'PUNCT'), ('Build', 'VERB'), ('vs', 'ADP'), ('.', 'PUNCT')] 

 XPOS tags are: 
>> [('For', 'IN'), ('further', 'JJ'), ('reading', 'NN'), (',', ','), ('you', 'PRP'), ('can', 'MD'), ('consult', 'VB'), ('our', 'PRP$'), ('white', 'JJ'), ('papers', 'NNS'), ('“', '``'), ('Build', 'VB'), ('vs', 'IN'), ('.', '.')] 

 Lemmas are: 
>> [('For', 'for'), ('further', 'further'), ('reading', 'reading'), (',', ','), ('you', 'you'), ('can', 'can'), ('consult', 'consult'), ('our', 'we'), ('white', 'white'), ('papers', 'paper'), ('“', "''"), ('Build', 'build'), ('vs', 'versus'), ('.', '.')] 

 Dependency tags are: 
>> [(('For', 'reading'), 'case'), (('further', 'reading'), 'amod'), (('reading', 'consult'), 'obl'), ((',', 'consult'), 'punct'), (('you', 'consult'), 'nsubj'), (('can', 'consult'), 'aux'), (('consult', 'root'), 'root'), (('our', 'papers'), 'nmod:poss'), (('white', 'papers'), 'amod'), (('papers', 'consult'), 'obj'), (('“', 'Build'), 'punct'), (('Build', 'consult'), 'xcomp'), (('vs', 'Build'), 'obl'), (('.', 'consult'), 'punct')]

 Named Entites are: 
>> []

------------------- Sentence 2 -------------------

 Buy,”  which talks about the economics of machine learning in a text analytics  context, and “Tune First, Then Train,” which discusses our philosophy   of customization for better accuracy and more-relevant results. 

Tokens are: 
>> ['Buy', ',', '”', 'which', 'talks', 'about', 'the', 'economics', 'of', 'machine', 'learning', 'in', 'a', 'text', 'analytics', 'context', ',', 'and', '“', 'Tune', 'First', ',', 'Then', 'Train', ',', '”', 'which', 'discusses', 'our', 'philosophy', 'of', 'customization', 'for', 'better', 'accuracy', 'and', 'more-relevant', 'results', '.'] 

 UPOS tags are: 
>> [('Buy', 'VERB'), (',', 'PUNCT'), ('”', 'PUNCT'), ('which', 'PRON'), ('talks', 'VERB'), ('about', 'ADP'), ('the', 'DET'), ('economics', 'NOUN'), ('of', 'ADP'), ('machine', 'NOUN'), ('learning', 'VERB'), ('in', 'ADP'), ('a', 'DET'), ('text', 'NOUN'), ('analytics', 'NOUN'), ('context', 'NOUN'), (',', 'PUNCT'), ('and', 'CCONJ'), ('“', 'PUNCT'), ('Tune', 'PROPN'), ('First', 'ADJ'), (',', 'PUNCT'), ('Then', 'ADV'), ('Train', 'PROPN'), (',', 'PUNCT'), ('”', 'PUNCT'), ('which', 'PRON'), ('discusses', 'VERB'), ('our', 'PRON'), ('philosophy', 'NOUN'), ('of', 'ADP'), ('customization', 'NOUN'), ('for', 'ADP'), ('better', 'ADJ'), ('accuracy', 'NOUN'), ('and', 'CCONJ'), ('more-relevant', 'ADJ'), ('results', 'NOUN'), ('.', 'PUNCT')] 

 XPOS tags are: 
>> [('Buy', 'VB'), (',', ','), ('”', "''"), ('which', 'WDT'), ('talks', 'VBZ'), ('about', 'IN'), ('the', 'DT'), ('economics', 'NNS'), ('of', 'IN'), ('machine', 'NN'), ('learning', 'VBG'), ('in', 'IN'), ('a', 'DT'), ('text', 'NN'), ('analytics', 'NN'), ('context', 'NN'), (',', ','), ('and', 'CC'), ('“', '``'), ('Tune', 'NNP'), ('First', 'JJ'), (',', ','), ('Then', 'RB'), ('Train', 'NNP'), (',', ','), ('”', "''"), ('which', 'WDT'), ('discusses', 'VBZ'), ('our', 'PRP$'), ('philosophy', 'NN'), ('of', 'IN'), ('customization', 'NN'), ('for', 'IN'), ('better', 'JJR'), ('accuracy', 'NN'), ('and', 'CC'), ('more-relevant', 'JJ'), ('results', 'NNS'), ('.', '.')] 

 Lemmas are: 
>> [('Buy', 'buy'), (',', ','), ('”', "''"), ('which', 'which'), ('talks', 'talk'), ('about', 'about'), ('the', 'the'), ('economics', 'economics'), ('of', 'of'), ('machine', 'machine'), ('learning', 'learn'), ('in', 'in'), ('a', 'a'), ('text', 'text'), ('analytics', 'analytic'), ('context', 'context'), (',', ','), ('and', 'and'), ('“', "''"), ('Tune', 'Tune'), ('First', 'first'), (',', ','), ('Then', 'then'), ('Train', 'Train'), (',', ','), ('”', "''"), ('which', 'which'), ('discusses', 'discuss'), ('our', 'we'), ('philosophy', 'philosophy'), ('of', 'of'), ('customization', 'customization'), ('for', 'for'), ('better', 'good'), ('accuracy', 'accuracy'), ('and', 'and'), ('more-relevant', 'more-relevant'), ('results', 'result'), ('.', '.')] 

 Dependency tags are: 
>> [(('Buy', 'root'), 'root'), ((',', 'Buy'), 'punct'), (('”', 'Buy'), 'punct'), (('which', 'talks'), 'nsubj'), (('talks', 'Buy'), 'parataxis'), (('about', 'economics'), 'case'), (('the', 'economics'), 'det'), (('economics', 'talks'), 'obl'), (('of', 'machine'), 'case'), (('machine', 'economics'), 'nmod'), (('learning', 'economics'), 'acl'), (('in', 'context'), 'case'), (('a', 'context'), 'det'), (('text', 'context'), 'compound'), (('analytics', 'context'), 'compound'), (('context', 'learning'), 'obl'), ((',', 'Tune'), 'punct'), (('and', 'Tune'), 'cc'), (('“', 'Tune'), 'punct'), (('Tune', 'economics'), 'conj'), (('First', 'Tune'), 'amod'), ((',', 'Train'), 'punct'), (('Then', 'Train'), 'advmod'), (('Train', 'Tune'), 'appos'), ((',', 'Train'), 'punct'), (('”', 'Train'), 'punct'), (('which', 'discusses'), 'nsubj'), (('discusses', 'Tune'), 'acl:relcl'), (('our', 'philosophy'), 'nmod:poss'), (('philosophy', 'discusses'), 'obj'), (('of', 'customization'), 'case'), (('customization', 'philosophy'), 'nmod'), (('for', 'accuracy'), 'case'), (('better', 'accuracy'), 'amod'), (('accuracy', 'customization'), 'nmod'), (('and', 'results'), 'cc'), (('more-relevant', 'results'), 'amod'), (('results', 'accuracy'), 'conj'), (('.', 'Buy'), 'punct')]

 Named Entites are: 
>> [('Tune First, Then Train', 'WORK_OF_ART')]

------------------- Sentence 3 -------------------

 When  taken together with this paper, these resources offer a more complete  view of text analytics solutions. 

Tokens are: 
>> ['When', 'taken', 'together', 'with', 'this', 'paper', ',', 'these', 'resources', 'offer', 'a', 'more', 'complete', 'view', 'of', 'text', 'analytics', 'solutions', '.'] 

 UPOS tags are: 
>> [('When', 'SCONJ'), ('taken', 'VERB'), ('together', 'ADV'), ('with', 'ADP'), ('this', 'DET'), ('paper', 'NOUN'), (',', 'PUNCT'), ('these', 'DET'), ('resources', 'NOUN'), ('offer', 'VERB'), ('a', 'DET'), ('more', 'ADV'), ('complete', 'ADJ'), ('view', 'NOUN'), ('of', 'ADP'), ('text', 'NOUN'), ('analytics', 'NOUN'), ('solutions', 'NOUN'), ('.', 'PUNCT')] 

 XPOS tags are: 
>> [('When', 'WRB'), ('taken', 'VBN'), ('together', 'RB'), ('with', 'IN'), ('this', 'DT'), ('paper', 'NN'), (',', ','), ('these', 'DT'), ('resources', 'NNS'), ('offer', 'VBP'), ('a', 'DT'), ('more', 'RBR'), ('complete', 'JJ'), ('view', 'NN'), ('of', 'IN'), ('text', 'NN'), ('analytics', 'NN'), ('solutions', 'NNS'), ('.', '.')] 

 Lemmas are: 
>> [('When', 'when'), ('taken', 'take'), ('together', 'together'), ('with', 'with'), ('this', 'this'), ('paper', 'paper'), (',', ','), ('these', 'this'), ('resources', 'resource'), ('offer', 'offer'), ('a', 'a'), ('more', 'more'), ('complete', 'complete'), ('view', 'view'), ('of', 'of'), ('text', 'text'), ('analytics', 'analytic'), ('solutions', 'solution'), ('.', '.')] 

 Dependency tags are: 
>> [(('When', 'taken'), 'mark'), (('taken', 'offer'), 'advcl'), (('together', 'taken'), 'advmod'), (('with', 'paper'), 'case'), (('this', 'paper'), 'det'), (('paper', 'taken'), 'obl'), ((',', 'offer'), 'punct'), (('these', 'resources'), 'det'), (('resources', 'offer'), 'nsubj'), (('offer', 'root'), 'root'), (('a', 'view'), 'det'), (('more', 'complete'), 'advmod'), (('complete', 'view'), 'amod'), (('view', 'offer'), 'obj'), (('of', 'solutions'), 'case'), (('text', 'analytics'), 'compound'), (('analytics', 'solutions'), 'compound'), (('solutions', 'view'), 'nmod'), (('.', 'offer'), 'punct')]

 Named Entites are: 
>> []

================================ Paragraph 29 =================================

Machine Learning   is Really Machine Teaching  .........................3   Supervised, Semi-Supervised and  Unsupervised Machine Learning   Supervised Learning ..............................5  Semi-Supervised Learning ................6  Unsupervised Learning ........................6 


------------------- Sentence 1 -------------------

 Machine Learning   is Really Machine Teaching  .........................3   Supervised, Semi-Supervised and  Unsupervised Machine Learning   Supervised Learning ..............................5  Semi-Supervised Learning ................6  Unsupervised Learning ........................6 

Tokens are: 
>> ['Machine', 'Learning', 'is', 'Really', 'Machine', 'Teaching', '.........................', '3', 'Supervised', ',', 'Semi-Supervised', 'and', 'Unsupervised', 'Machine', 'Learning', 'Supervised', 'Learning', '..............................', '5', 'Semi-Supervised', 'Learning', '................6', 'Unsupervised', 'Learning', '........................', '6'] 

 UPOS tags are: 
>> [('Machine', 'NOUN'), ('Learning', 'NOUN'), ('is', 'AUX'), ('Really', 'ADV'), ('Machine', 'NOUN'), ('Teaching', 'NOUN'), ('.........................', 'PUNCT'), ('3', 'NUM'), ('Supervised', 'VERB'), (',', 'PUNCT'), ('Semi-Supervised', 'VERB'), ('and', 'CCONJ'), ('Unsupervised', 'VERB'), ('Machine', 'NOUN'), ('Learning', 'NOUN'), ('Supervised', 'VERB'), ('Learning', 'NOUN'), ('..............................', 'PUNCT'), ('5', 'NUM'), ('Semi-Supervised', 'ADJ'), ('Learning', 'NOUN'), ('................6', 'PUNCT'), ('Unsupervised', 'VERB'), ('Learning', 'NOUN'), ('........................', 'PUNCT'), ('6', 'NUM')] 

 XPOS tags are: 
>> [('Machine', 'NN'), ('Learning', 'NN'), ('is', 'VBZ'), ('Really', 'RB'), ('Machine', 'NN'), ('Teaching', 'NN'), ('.........................', ','), ('3', 'CD'), ('Supervised', 'VBN'), (',', ','), ('Semi-Supervised', 'VBN'), ('and', 'CC'), ('Unsupervised', 'VBN'), ('Machine', 'NN'), ('Learning', 'NN'), ('Supervised', 'VBN'), ('Learning', 'NN'), ('..............................', ','), ('5', 'CD'), ('Semi-Supervised', 'JJ'), ('Learning', 'NN'), ('................6', ','), ('Unsupervised', 'VBN'), ('Learning', 'NN'), ('........................', ','), ('6', 'CD')] 

 Lemmas are: 
>> [('Machine', 'Machine'), ('Learning', 'learning'), ('is', 'be'), ('Really', 'really'), ('Machine', 'Machine'), ('Teaching', 'Teaching'), ('.........................', '.........................'), ('3', '3'), ('Supervised', 'supervise'), (',', ','), ('Semi-Supervised', 'semi-'), ('and', 'and'), ('Unsupervised', 'unsupervise'), ('Machine', 'Machine'), ('Learning', 'learning'), ('Supervised', 'supervise'), ('Learning', 'learning'), ('..............................', '..............................'), ('5', '5'), ('Semi-Supervised', 'semi-supervised'), ('Learning', 'learning'), ('................6', '................6'), ('Unsupervised', 'unsupervise'), ('Learning', 'learning'), ('........................', '........................'), ('6', '6')] 

 Dependency tags are: 
>> [(('Machine', 'Learning'), 'compound'), (('Learning', 'Teaching'), 'nsubj'), (('is', 'Teaching'), 'cop'), (('Really', 'Teaching'), 'advmod'), (('Machine', 'Teaching'), 'compound'), (('Teaching', 'root'), 'root'), (('.........................', 'Teaching'), 'punct'), (('3', 'Machine'), 'nummod'), (('Supervised', 'Machine'), 'amod'), ((',', 'Semi-Supervised'), 'punct'), (('Semi-Supervised', 'Supervised'), 'conj'), (('and', 'Unsupervised'), 'cc'), (('Unsupervised', 'Supervised'), 'conj'), (('Machine', 'Teaching'), 'list'), (('Learning', 'Learning'), 'compound'), (('Supervised', 'Learning'), 'amod'), (('Learning', 'Machine'), 'appos'), (('..............................', 'Teaching'), 'punct'), (('5', 'Learning'), 'nummod'), (('Semi-Supervised', 'Learning'), 'amod'), (('Learning', 'Teaching'), 'list'), (('................6', 'Learning'), 'punct'), (('Unsupervised', 'Learning'), 'amod'), (('Learning', 'Teaching'), 'list'), (('........................', 'Teaching'), 'punct'), (('6', 'Learning'), 'appos')]

 Named Entites are: 
>> [('3', 'CARDINAL'), ('5', 'CARDINAL')]

================================ Paragraph 30 =================================

Happier by the Dozen:   The More Models, the Merrier .................... 7 


------------------- Sentence 1 -------------------

 Happier by the Dozen:   The More Models, the Merrier .................... 

Tokens are: 
>> ['Happier', 'by', 'the', 'Dozen', ':', 'The', 'More', 'Models', ',', 'the', 'Merrier', '....................'] 

 UPOS tags are: 
>> [('Happier', 'ADJ'), ('by', 'ADP'), ('the', 'DET'), ('Dozen', 'NOUN'), (':', 'PUNCT'), ('The', 'DET'), ('More', 'ADJ'), ('Models', 'NOUN'), (',', 'PUNCT'), ('the', 'DET'), ('Merrier', 'ADJ'), ('....................', 'PUNCT')] 

 XPOS tags are: 
>> [('Happier', 'JJR'), ('by', 'IN'), ('the', 'DT'), ('Dozen', 'NN'), (':', ':'), ('The', 'DT'), ('More', 'JJR'), ('Models', 'NNS'), (',', ','), ('the', 'DT'), ('Merrier', 'JJ'), ('....................', '.')] 

 Lemmas are: 
>> [('Happier', 'happy'), ('by', 'by'), ('the', 'the'), ('Dozen', 'Dozen'), (':', ':'), ('The', 'the'), ('More', 'more'), ('Models', 'model'), (',', ','), ('the', 'the'), ('Merrier', 'merrier'), ('....................', '....................')] 

 Dependency tags are: 
>> [(('Happier', 'root'), 'root'), (('by', 'Dozen'), 'case'), (('the', 'Dozen'), 'det'), (('Dozen', 'Happier'), 'obl'), ((':', 'Models'), 'punct'), (('The', 'Models'), 'det'), (('More', 'Models'), 'amod'), (('Models', 'Happier'), 'parataxis'), ((',', 'Merrier'), 'punct'), (('the', 'Merrier'), 'det'), (('Merrier', 'Models'), 'appos'), (('....................', 'Happier'), 'punct')]

 Named Entites are: 
>> [('Dozen', 'CARDINAL'), ('Merrier', 'PERSON')]

------------------- Sentence 2 -------------------

 7 

Tokens are: 
>> ['7'] 

 UPOS tags are: 
>> [('7', 'X')] 

 XPOS tags are: 
>> [('7', 'LS')] 

 Lemmas are: 
>> [('7', '7')] 

 Dependency tags are: 
>> [(('7', 'root'), 'root')]

 Named Entites are: 
>> []

================================ Paragraph 31 =================================

Coding vs. Learning:   Making the Case for Each ............................9 


------------------- Sentence 1 -------------------

 Coding vs. Learning:   Making the Case for Each ............................9 

Tokens are: 
>> ['Coding', 'vs.', 'Learning', ':', 'Making', 'the', 'Case', 'for', 'Each', '............................', '9'] 

 UPOS tags are: 
>> [('Coding', 'VERB'), ('vs.', 'ADP'), ('Learning', 'NOUN'), (':', 'PUNCT'), ('Making', 'VERB'), ('the', 'DET'), ('Case', 'NOUN'), ('for', 'ADP'), ('Each', 'DET'), ('............................', 'PUNCT'), ('9', 'NUM')] 

 XPOS tags are: 
>> [('Coding', 'VBG'), ('vs.', 'IN'), ('Learning', 'NN'), (':', ':'), ('Making', 'VBG'), ('the', 'DT'), ('Case', 'NN'), ('for', 'IN'), ('Each', 'DT'), ('............................', ','), ('9', 'CD')] 

 Lemmas are: 
>> [('Coding', 'code'), ('vs.', 'vs.'), ('Learning', 'learning'), (':', ':'), ('Making', 'make'), ('the', 'the'), ('Case', 'case'), ('for', 'for'), ('Each', 'each'), ('............................', '............................'), ('9', '9')] 

 Dependency tags are: 
>> [(('Coding', 'root'), 'root'), (('vs.', 'Learning'), 'case'), (('Learning', 'Coding'), 'obl'), ((':', 'Coding'), 'punct'), (('Making', 'Coding'), 'parataxis'), (('the', 'Case'), 'det'), (('Case', 'Making'), 'obj'), (('for', 'Each'), 'case'), (('Each', 'Case'), 'nmod'), (('............................', 'Coding'), 'punct'), (('9', 'Making'), 'obl')]

 Named Entites are: 
>> []

================================ Paragraph 32 =================================

Black Box/Clear Box:   Looking Inside the Data ............................... 10 


------------------- Sentence 1 -------------------

 Black Box/Clear Box:   Looking Inside the Data ............................... 10 

Tokens are: 
>> ['Black', 'Box', '/', 'Clear', 'Box', ':', 'Looking', 'Inside', 'the', 'Data', '...............................', '10'] 

 UPOS tags are: 
>> [('Black', 'ADJ'), ('Box', 'NOUN'), ('/', 'SYM'), ('Clear', 'ADJ'), ('Box', 'NOUN'), (':', 'PUNCT'), ('Looking', 'VERB'), ('Inside', 'ADP'), ('the', 'DET'), ('Data', 'NOUN'), ('...............................', 'PUNCT'), ('10', 'NUM')] 

 XPOS tags are: 
>> [('Black', 'JJ'), ('Box', 'NN'), ('/', ','), ('Clear', 'JJ'), ('Box', 'NN'), (':', ':'), ('Looking', 'VBG'), ('Inside', 'IN'), ('the', 'DT'), ('Data', 'NN'), ('...............................', ','), ('10', 'CD')] 

 Lemmas are: 
>> [('Black', 'Black'), ('Box', 'box'), ('/', '/'), ('Clear', 'Clear'), ('Box', 'box'), (':', ':'), ('Looking', 'look'), ('Inside', 'Inside'), ('the', 'the'), ('Data', 'data'), ('...............................', '...............................'), ('10', '10')] 

 Dependency tags are: 
>> [(('Black', 'Box'), 'amod'), (('Box', 'root'), 'root'), (('/', 'Box'), 'cc'), (('Clear', 'Box'), 'amod'), (('Box', 'Box'), 'conj'), ((':', 'Looking'), 'punct'), (('Looking', 'Box'), 'acl'), (('Inside', 'Data'), 'case'), (('the', 'Data'), 'det'), (('Data', 'Looking'), 'obl'), (('...............................', 'Box'), 'punct'), (('10', 'Box'), 'list')]

 Named Entites are: 
>> [('10', 'CARDINAL')]

================================ Paragraph 33 =================================

Tune First, Then Train:   Efficiency before Complexity ....................12 


------------------- Sentence 1 -------------------

 Tune First, Then Train:   Efficiency before Complexity ....................12 

Tokens are: 
>> ['Tune', 'First', ',', 'Then', 'Train', ':', 'Efficiency', 'before', 'Complexity', '....................', '12'] 

 UPOS tags are: 
>> [('Tune', 'VERB'), ('First', 'ADV'), (',', 'PUNCT'), ('Then', 'ADV'), ('Train', 'NOUN'), (':', 'PUNCT'), ('Efficiency', 'NOUN'), ('before', 'ADP'), ('Complexity', 'NOUN'), ('....................', 'PUNCT'), ('12', 'NUM')] 

 XPOS tags are: 
>> [('Tune', 'VB'), ('First', 'RB'), (',', ','), ('Then', 'RB'), ('Train', 'NN'), (':', ':'), ('Efficiency', 'NN'), ('before', 'IN'), ('Complexity', 'NN'), ('....................', ','), ('12', 'CD')] 

 Lemmas are: 
>> [('Tune', 'tune'), ('First', 'first'), (',', ','), ('Then', 'then'), ('Train', 'train'), (':', ':'), ('Efficiency', 'efficiency'), ('before', 'before'), ('Complexity', 'complexity'), ('....................', '....................'), ('12', '12')] 

 Dependency tags are: 
>> [(('Tune', 'root'), 'root'), (('First', 'Tune'), 'advmod'), ((',', 'Tune'), 'punct'), (('Then', 'Train'), 'advmod'), (('Train', 'Tune'), 'parataxis'), ((':', 'Efficiency'), 'punct'), (('Efficiency', 'Train'), 'appos'), (('before', 'Complexity'), 'case'), (('Complexity', 'Efficiency'), 'nmod'), (('....................', 'Tune'), 'punct'), (('12', 'Tune'), 'dep')]

 Named Entites are: 
>> [('First', 'ORDINAL'), ('12', 'CARDINAL')]

================================ Paragraph 34 =================================

Summary/Conclusion .................................. 14


------------------- Sentence 1 -------------------

 Summary/Conclusion .................................. 14 

Tokens are: 
>> ['Summary', '/', 'Conclusion', '..................................', '14'] 

 UPOS tags are: 
>> [('Summary', 'NOUN'), ('/', 'PUNCT'), ('Conclusion', 'NOUN'), ('..................................', 'PUNCT'), ('14', 'NUM')] 

 XPOS tags are: 
>> [('Summary', 'NN'), ('/', ','), ('Conclusion', 'NN'), ('..................................', ','), ('14', 'CD')] 

 Lemmas are: 
>> [('Summary', 'summary'), ('/', '/'), ('Conclusion', 'conclusion'), ('..................................', '..................................'), ('14', '14')] 

 Dependency tags are: 
>> [(('Summary', 'root'), 'root'), (('/', 'Conclusion'), 'cc'), (('Conclusion', 'Summary'), 'conj'), (('..................................', 'Summary'), 'punct'), (('14', 'Summary'), 'appos')]

 Named Entites are: 
>> [('14', 'CARDINAL')]

================================ Paragraph 35 =================================

W H I T E  P A P E R 


------------------- Sentence 1 -------------------

 W H I T E  P A P E R 

Tokens are: 
>> ['W', 'H', 'I', 'T', 'E', 'P', 'A', 'P', 'E', 'R'] 

 UPOS tags are: 
>> [('W', 'PROPN'), ('H', 'PUNCT'), ('I', 'PRON'), ('T', 'AUX'), ('E', 'PROPN'), ('P', 'NOUN'), ('A', 'NOUN'), ('P', 'NOUN'), ('E', 'NOUN'), ('R', 'NOUN')] 

 XPOS tags are: 
>> [('W', 'NNP'), ('H', ','), ('I', 'PRP'), ('T', 'VBP'), ('E', 'NNP'), ('P', 'NN'), ('A', 'NN'), ('P', 'NN'), ('E', 'NN'), ('R', 'NN')] 

 Lemmas are: 
>> [('W', 'W'), ('H', 'H'), ('I', 'I'), ('T', 'T'), ('E', 'E'), ('P', 'p'), ('A', 'a'), ('P', 'p'), ('E', 'e'), ('R', 'R')] 

 Dependency tags are: 
>> [(('W', 'T'), 'vocative'), (('H', 'W'), 'punct'), (('I', 'T'), 'nsubj'), (('T', 'root'), 'root'), (('E', 'T'), 'obj'), (('P', 'T'), 'obj'), (('A', 'E'), 'compound'), (('P', 'E'), 'compound'), (('E', 'R'), 'compound'), (('R', 'T'), 'obj')]

 Named Entites are: 
>> []

================================ Paragraph 36 =================================

3|       |   Lexalytics, Inc., 48 North Pleasant St. Unit 301, Amherst MA 01002 USA   |   1-800-377-8036 |   www.lexalytics.com 


------------------- Sentence 1 -------------------

 3|       |   Lexalytics, Inc., 48 North Pleasant St. Unit 301, Amherst MA 01002 USA   |   1-800-377-8036 |   www.lexalytics.com 

Tokens are: 
>> ['3', '|', '|', 'Lexalytics', ',', 'Inc.', ',', '48', 'North', 'Pleasant', 'St.', 'Unit', '301', ',', 'Amherst', 'MA', '01002', 'USA', '|', '1-800-377-8036', '|', 'www.lexalytics.com'] 

 UPOS tags are: 
>> [('3', 'NUM'), ('|', 'PUNCT'), ('|', 'PUNCT'), ('Lexalytics', 'PROPN'), (',', 'PUNCT'), ('Inc.', 'PROPN'), (',', 'PUNCT'), ('48', 'NUM'), ('North', 'PROPN'), ('Pleasant', 'ADJ'), ('St.', 'PROPN'), ('Unit', 'NOUN'), ('301', 'NUM'), (',', 'PUNCT'), ('Amherst', 'PROPN'), ('MA', 'PROPN'), ('01002', 'NUM'), ('USA', 'PROPN'), ('|', 'PUNCT'), ('1-800-377-8036', 'NUM'), ('|', 'PUNCT'), ('www.lexalytics.com', 'X')] 

 XPOS tags are: 
>> [('3', 'LS'), ('|', 'NFP'), ('|', 'NFP'), ('Lexalytics', 'NNP'), (',', ','), ('Inc.', 'NNP'), (',', ','), ('48', 'CD'), ('North', 'NNP'), ('Pleasant', 'NNP'), ('St.', 'NNP'), ('Unit', 'NN'), ('301', 'CD'), (',', ','), ('Amherst', 'NNP'), ('MA', 'NNP'), ('01002', 'CD'), ('USA', 'NNP'), ('|', 'NFP'), ('1-800-377-8036', 'CD'), ('|', 'NFP'), ('www.lexalytics.com', 'ADD')] 

 Lemmas are: 
>> [('3', '3'), ('|', '|'), ('|', '|'), ('Lexalytics', 'Lexalytics'), (',', ','), ('Inc.', 'Inc.'), (',', ','), ('48', '48'), ('North', 'North'), ('Pleasant', 'Pleasant'), ('St.', 'St.'), ('Unit', 'unit'), ('301', '301'), (',', ','), ('Amherst', 'Amherst'), ('MA', 'MA'), ('01002', '01002'), ('USA', 'USA'), ('|', '|'), ('1-800-377-8036', '1-800-377-8036'), ('|', '|'), ('www.lexalytics.com', 'www.lexalytics.com')] 

 Dependency tags are: 
>> [(('3', 'Inc.'), 'nummod'), (('|', '3'), 'punct'), (('|', '3'), 'punct'), (('Lexalytics', 'Inc.'), 'compound'), ((',', 'Inc.'), 'punct'), (('Inc.', 'root'), 'root'), ((',', 'Inc.'), 'punct'), (('48', 'St.'), 'nummod'), (('North', 'St.'), 'compound'), (('Pleasant', 'St.'), 'amod'), (('St.', 'Inc.'), 'list'), (('Unit', 'St.'), 'appos'), (('301', 'Unit'), 'nummod'), ((',', 'MA'), 'punct'), (('Amherst', 'MA'), 'appos'), (('MA', 'Inc.'), 'list'), (('01002', 'USA'), 'nummod'), (('USA', 'MA'), 'appos'), (('|', 'USA'), 'punct'), (('1-800-377-8036', 'Inc.'), 'list'), (('|', '1-800-377-8036'), 'punct'), (('www.lexalytics.com', 'Inc.'), 'list')]

 Named Entites are: 
>> [('3|       |   Lexalytics, Inc.', 'ORG'), ('301', 'CARDINAL')]

================================ Paragraph 37 =================================

M A C H I N E  L E A R N I N G   I S  R E A L L Y  M A C H I N E  T E A C H I N G  Before we start delving into the different aspects of text analytics, let’s clarify  some basic machine learning concepts.  


------------------- Sentence 1 -------------------

 M A C H I N E  L E A R N I N G   I S  R E A L L Y  M A C H I N E  T E A C H I N G  Before we start delving into the different aspects of text analytics, let’s clarify  some basic machine learning concepts. 

Tokens are: 
>> ['M', 'A', 'C', 'H', 'I', 'N', 'E', 'L', 'E', 'A', 'R', 'N', 'I', 'N', 'G', 'I', 'S', 'R', 'E', 'A', 'L', 'L', 'Y', 'M', 'A', 'C', 'H', 'I', 'N', 'E', 'T', 'E', 'A', 'C', 'H', 'I', 'N', 'G', 'Before', 'we', 'start', 'delving', 'into', 'the', 'different', 'aspects', 'of', 'text', 'analytics', ',', 'let', '’s', 'clarify', 'some', 'basic', 'machine', 'learning', 'concepts', '.'] 

 UPOS tags are: 
>> [('M', 'PRON'), ('A', 'NOUN'), ('C', 'NOUN'), ('H', 'PUNCT'), ('I', 'PRON'), ('N', 'AUX'), ('E', 'PROPN'), ('L', 'PUNCT'), ('E', 'PROPN'), ('A', 'NOUN'), ('R', 'PROPN'), ('N', 'PROPN'), ('I', 'PRON'), ('N', 'VERB'), ('G', 'PROPN'), ('I', 'PRON'), ('S', 'AUX'), ('R', 'AUX'), ('E', 'PROPN'), ('A', 'DET'), ('L', 'PROPN'), ('L', 'PROPN'), ('Y', 'PROPN'), ('M', 'NOUN'), ('A', 'NOUN'), ('C', 'NOUN'), ('H', 'NOUN'), ('I', 'PRON'), ('N', 'AUX'), ('E', 'PROPN'), ('T', 'PROPN'), ('E', 'PROPN'), ('A', 'PROPN'), ('C', 'PROPN'), ('H', 'NOUN'), ('I', 'PRON'), ('N', 'VERB'), ('G', 'PROPN'), ('Before', 'SCONJ'), ('we', 'PRON'), ('start', 'VERB'), ('delving', 'VERB'), ('into', 'ADP'), ('the', 'DET'), ('different', 'ADJ'), ('aspects', 'NOUN'), ('of', 'ADP'), ('text', 'NOUN'), ('analytics', 'NOUN'), (',', 'PUNCT'), ('let', 'VERB'), ('’s', 'PRON'), ('clarify', 'VERB'), ('some', 'DET'), ('basic', 'ADJ'), ('machine', 'NOUN'), ('learning', 'NOUN'), ('concepts', 'NOUN'), ('.', 'PUNCT')] 

 XPOS tags are: 
>> [('M', 'PRP'), ('A', 'NN'), ('C', 'NN'), ('H', ','), ('I', 'PRP'), ('N', 'VBP'), ('E', 'NNP'), ('L', ','), ('E', 'NNP'), ('A', 'NN'), ('R', 'NNP'), ('N', 'NNP'), ('I', 'PRP'), ('N', 'VBP'), ('G', 'NNP'), ('I', 'PRP'), ('S', 'VBZ'), ('R', 'VBP'), ('E', 'NNP'), ('A', 'DT'), ('L', 'NNP'), ('L', 'NNP'), ('Y', 'NNP'), ('M', 'NN'), ('A', 'NN'), ('C', 'NN'), ('H', 'NN'), ('I', 'PRP'), ('N', 'VBP'), ('E', 'NNP'), ('T', 'NNP'), ('E', 'NNP'), ('A', 'NNP'), ('C', 'NNP'), ('H', 'NN'), ('I', 'PRP'), ('N', 'VBP'), ('G', 'NNP'), ('Before', 'IN'), ('we', 'PRP'), ('start', 'VBP'), ('delving', 'VBG'), ('into', 'IN'), ('the', 'DT'), ('different', 'JJ'), ('aspects', 'NNS'), ('of', 'IN'), ('text', 'NN'), ('analytics', 'NNS'), (',', ','), ('let', 'VB'), ('’s', 'PRP'), ('clarify', 'VB'), ('some', 'DT'), ('basic', 'JJ'), ('machine', 'NN'), ('learning', 'NN'), ('concepts', 'NNS'), ('.', '.')] 

 Lemmas are: 
>> [('M', 'm'), ('A', 'a'), ('C', 'c'), ('H', 'H'), ('I', 'I'), ('N', 'N'), ('E', 'E'), ('L', 'L'), ('E', 'E'), ('A', 'a'), ('R', 'R'), ('N', 'N'), ('I', 'I'), ('N', 'N'), ('G', 'G'), ('I', 'I'), ('S', 'be'), ('R', 'R'), ('E', 'E'), ('A', 'a'), ('L', 'L'), ('L', 'L'), ('Y', 'Y'), ('M', 'm'), ('A', 'a'), ('C', 'c'), ('H', 'h'), ('I', 'I'), ('N', 'N'), ('E', 'E'), ('T', 'T'), ('E', 'E'), ('A', 'A'), ('C', 'C'), ('H', 'h'), ('I', 'I'), ('N', 'N'), ('G', 'G'), ('Before', 'before'), ('we', 'we'), ('start', 'start'), ('delving', 'delve'), ('into', 'into'), ('the', 'the'), ('different', 'different'), ('aspects', 'aspect'), ('of', 'of'), ('text', 'text'), ('analytics', 'analytic'), (',', ','), ('let', 'let'), ('’s', 'us'), ('clarify', 'clarify'), ('some', 'some'), ('basic', 'basic'), ('machine', 'machine'), ('learning', 'learning'), ('concepts', 'concept'), ('.', '.')] 

 Dependency tags are: 
>> [(('M', 'C'), 'compound'), (('A', 'C'), 'compound'), (('C', 'root'), 'root'), (('H', 'C'), 'punct'), (('I', 'E'), 'nsubj'), (('N', 'E'), 'cop'), (('E', 'C'), 'appos'), (('L', 'E'), 'punct'), (('E', 'N'), 'compound'), (('A', 'N'), 'compound'), (('R', 'N'), 'compound'), (('N', 'E'), 'appos'), (('I', 'N'), 'nsubj'), (('N', 'C'), 'parataxis'), (('G', 'N'), 'obj'), (('I', 'E'), 'nsubj'), (('S', 'E'), 'cop'), (('R', 'E'), 'case'), (('E', 'N'), 'ccomp'), (('A', 'H'), 'det'), (('L', 'H'), 'compound'), (('L', 'M'), 'compound'), (('Y', 'M'), 'compound'), (('M', 'H'), 'compound'), (('A', 'H'), 'compound'), (('C', 'H'), 'compound'), (('H', 'E'), 'obj'), (('I', 'E'), 'nsubj'), (('N', 'E'), 'cop'), (('E', 'E'), 'compound'), (('T', 'E'), 'compound'), (('E', 'H'), 'compound'), (('A', 'H'), 'compound'), (('C', 'H'), 'compound'), (('H', 'C'), 'parataxis'), (('I', 'N'), 'nsubj'), (('N', 'C'), 'parataxis'), (('G', 'N'), 'obj'), (('Before', 'start'), 'mark'), (('we', 'start'), 'nsubj'), (('start', 'N'), 'advcl'), (('delving', 'start'), 'xcomp'), (('into', 'aspects'), 'case'), (('the', 'aspects'), 'det'), (('different', 'aspects'), 'amod'), (('aspects', 'delving'), 'obl'), (('of', 'analytics'), 'case'), (('text', 'analytics'), 'compound'), (('analytics', 'aspects'), 'nmod'), ((',', 'let'), 'punct'), (('let', 'E'), 'conj'), (('’s', 'let'), 'obj'), (('clarify', 'let'), 'xcomp'), (('some', 'concepts'), 'det'), (('basic', 'concepts'), 'amod'), (('machine', 'concepts'), 'compound'), (('learning', 'concepts'), 'compound'), (('concepts', 'clarify'), 'obj'), (('.', 'C'), 'punct')]

 Named Entites are: 
>> []

================================ Paragraph 38 =================================

Most importantly, “machine learning” really means “machine teaching.” We  know what the machine needs to learn, so our task is to create a learning  framework and provide properly-formatted, relevant, clean data that the  machine can learn from. 


------------------- Sentence 1 -------------------

 Most importantly, “machine learning” really means “machine teaching.” 

Tokens are: 
>> ['Most', 'importantly', ',', '“', 'machine', 'learning', '”', 'really', 'means', '“', 'machine', 'teaching', '.', '”'] 

 UPOS tags are: 
>> [('Most', 'ADV'), ('importantly', 'ADV'), (',', 'PUNCT'), ('“', 'PUNCT'), ('machine', 'NOUN'), ('learning', 'NOUN'), ('”', 'PUNCT'), ('really', 'ADV'), ('means', 'VERB'), ('“', 'PUNCT'), ('machine', 'NOUN'), ('teaching', 'NOUN'), ('.', 'PUNCT'), ('”', 'PUNCT')] 

 XPOS tags are: 
>> [('Most', 'RBS'), ('importantly', 'RB'), (',', ','), ('“', '``'), ('machine', 'NN'), ('learning', 'NN'), ('”', "''"), ('really', 'RB'), ('means', 'VBZ'), ('“', '``'), ('machine', 'NN'), ('teaching', 'NN'), ('.', '.'), ('”', "''")] 

 Lemmas are: 
>> [('Most', 'most'), ('importantly', 'importantly'), (',', ','), ('“', "''"), ('machine', 'machine'), ('learning', 'learning'), ('”', "''"), ('really', 'really'), ('means', 'mean'), ('“', "''"), ('machine', 'machine'), ('teaching', 'teaching'), ('.', '.'), ('”', "''")] 

 Dependency tags are: 
>> [(('Most', 'importantly'), 'advmod'), (('importantly', 'means'), 'advmod'), ((',', 'means'), 'punct'), (('“', 'learning'), 'punct'), (('machine', 'learning'), 'compound'), (('learning', 'means'), 'nsubj'), (('”', 'learning'), 'punct'), (('really', 'means'), 'advmod'), (('means', 'root'), 'root'), (('“', 'teaching'), 'punct'), (('machine', 'teaching'), 'compound'), (('teaching', 'means'), 'obj'), (('.', 'teaching'), 'punct'), (('”', 'teaching'), 'punct')]

 Named Entites are: 
>> []

------------------- Sentence 2 -------------------

 We  know what the machine needs to learn, so our task is to create a learning  framework and provide properly-formatted, relevant, clean data that the  machine can learn from. 

Tokens are: 
>> ['We', 'know', 'what', 'the', 'machine', 'needs', 'to', 'learn', ',', 'so', 'our', 'task', 'is', 'to', 'create', 'a', 'learning', 'framework', 'and', 'provide', 'properly', '-', 'formatted', ',', 'relevant', ',', 'clean', 'data', 'that', 'the', 'machine', 'can', 'learn', 'from', '.'] 

 UPOS tags are: 
>> [('We', 'PRON'), ('know', 'VERB'), ('what', 'PRON'), ('the', 'DET'), ('machine', 'NOUN'), ('needs', 'VERB'), ('to', 'PART'), ('learn', 'VERB'), (',', 'PUNCT'), ('so', 'ADV'), ('our', 'PRON'), ('task', 'NOUN'), ('is', 'VERB'), ('to', 'PART'), ('create', 'VERB'), ('a', 'DET'), ('learning', 'NOUN'), ('framework', 'NOUN'), ('and', 'CCONJ'), ('provide', 'VERB'), ('properly', 'ADV'), ('-', 'PUNCT'), ('formatted', 'VERB'), (',', 'PUNCT'), ('relevant', 'ADJ'), (',', 'PUNCT'), ('clean', 'ADJ'), ('data', 'NOUN'), ('that', 'PRON'), ('the', 'DET'), ('machine', 'NOUN'), ('can', 'AUX'), ('learn', 'VERB'), ('from', 'ADP'), ('.', 'PUNCT')] 

 XPOS tags are: 
>> [('We', 'PRP'), ('know', 'VBP'), ('what', 'WP'), ('the', 'DT'), ('machine', 'NN'), ('needs', 'VBZ'), ('to', 'TO'), ('learn', 'VB'), (',', ','), ('so', 'RB'), ('our', 'PRP$'), ('task', 'NN'), ('is', 'VBZ'), ('to', 'TO'), ('create', 'VB'), ('a', 'DT'), ('learning', 'NN'), ('framework', 'NN'), ('and', 'CC'), ('provide', 'VB'), ('properly', 'RB'), ('-', 'HYPH'), ('formatted', 'VBN'), (',', ','), ('relevant', 'JJ'), (',', ','), ('clean', 'JJ'), ('data', 'NNS'), ('that', 'WDT'), ('the', 'DT'), ('machine', 'NN'), ('can', 'MD'), ('learn', 'VB'), ('from', 'IN'), ('.', '.')] 

 Lemmas are: 
>> [('We', 'we'), ('know', 'know'), ('what', 'what'), ('the', 'the'), ('machine', 'machine'), ('needs', 'need'), ('to', 'to'), ('learn', 'learn'), (',', ','), ('so', 'so'), ('our', 'we'), ('task', 'task'), ('is', 'be'), ('to', 'to'), ('create', 'create'), ('a', 'a'), ('learning', 'learning'), ('framework', 'framework'), ('and', 'and'), ('provide', 'provide'), ('properly', 'properly'), ('-', '-'), ('formatted', 'format'), (',', ','), ('relevant', 'relevant'), (',', ','), ('clean', 'clean'), ('data', 'datum'), ('that', 'that'), ('the', 'the'), ('machine', 'machine'), ('can', 'can'), ('learn', 'learn'), ('from', 'from'), ('.', '.')] 

 Dependency tags are: 
>> [(('We', 'know'), 'nsubj'), (('know', 'root'), 'root'), (('what', 'needs'), 'obj'), (('the', 'machine'), 'det'), (('machine', 'needs'), 'nsubj'), (('needs', 'know'), 'ccomp'), (('to', 'learn'), 'mark'), (('learn', 'needs'), 'xcomp'), ((',', 'is'), 'punct'), (('so', 'is'), 'advmod'), (('our', 'task'), 'nmod:poss'), (('task', 'is'), 'nsubj'), (('is', 'know'), 'parataxis'), (('to', 'create'), 'mark'), (('create', 'is'), 'ccomp'), (('a', 'framework'), 'det'), (('learning', 'framework'), 'compound'), (('framework', 'create'), 'obj'), (('and', 'provide'), 'cc'), (('provide', 'create'), 'conj'), (('properly', 'formatted'), 'advmod'), (('-', 'formatted'), 'punct'), (('formatted', 'data'), 'amod'), ((',', 'data'), 'punct'), (('relevant', 'data'), 'amod'), ((',', 'data'), 'punct'), (('clean', 'data'), 'amod'), (('data', 'provide'), 'obj'), (('that', 'learn'), 'obl'), (('the', 'machine'), 'det'), (('machine', 'learn'), 'nsubj'), (('can', 'learn'), 'aux'), (('learn', 'data'), 'acl:relcl'), (('from', 'that'), 'case'), (('.', 'know'), 'punct')]

 Named Entites are: 
>> []

================================ Paragraph 39 =================================

The goal is to create a system where the model continuously improves  at the task you’ve set it. Input is key. Unlike algorithmic programming, a  machine learning model is able to generalize and deal with novel cases. If a  case resembles something the model has seen before, the model can use  this prior “learning” to evaluate the case. 


------------------- Sentence 1 -------------------

 The goal is to create a system where the model continuously improves  at the task you’ve set it. 

Tokens are: 
>> ['The', 'goal', 'is', 'to', 'create', 'a', 'system', 'where', 'the', 'model', 'continuously', 'improves', 'at', 'the', 'task', 'you', '’ve', 'set', 'it', '.'] 

 UPOS tags are: 
>> [('The', 'DET'), ('goal', 'NOUN'), ('is', 'VERB'), ('to', 'PART'), ('create', 'VERB'), ('a', 'DET'), ('system', 'NOUN'), ('where', 'SCONJ'), ('the', 'DET'), ('model', 'NOUN'), ('continuously', 'ADV'), ('improves', 'VERB'), ('at', 'ADP'), ('the', 'DET'), ('task', 'NOUN'), ('you', 'PRON'), ('’ve', 'AUX'), ('set', 'VERB'), ('it', 'PRON'), ('.', 'PUNCT')] 

 XPOS tags are: 
>> [('The', 'DT'), ('goal', 'NN'), ('is', 'VBZ'), ('to', 'TO'), ('create', 'VB'), ('a', 'DT'), ('system', 'NN'), ('where', 'WRB'), ('the', 'DT'), ('model', 'NN'), ('continuously', 'RB'), ('improves', 'VBZ'), ('at', 'IN'), ('the', 'DT'), ('task', 'NN'), ('you', 'PRP'), ('’ve', 'VBP'), ('set', 'VBN'), ('it', 'PRP'), ('.', '.')] 

 Lemmas are: 
>> [('The', 'the'), ('goal', 'goal'), ('is', 'be'), ('to', 'to'), ('create', 'create'), ('a', 'a'), ('system', 'system'), ('where', 'where'), ('the', 'the'), ('model', 'model'), ('continuously', 'continuously'), ('improves', 'improve'), ('at', 'at'), ('the', 'the'), ('task', 'task'), ('you', 'you'), ('’ve', 'have'), ('set', 'set'), ('it', 'it'), ('.', '.')] 

 Dependency tags are: 
>> [(('The', 'goal'), 'det'), (('goal', 'is'), 'nsubj'), (('is', 'root'), 'root'), (('to', 'create'), 'mark'), (('create', 'is'), 'ccomp'), (('a', 'system'), 'det'), (('system', 'create'), 'obj'), (('where', 'improves'), 'mark'), (('the', 'model'), 'det'), (('model', 'improves'), 'nsubj'), (('continuously', 'improves'), 'advmod'), (('improves', 'system'), 'acl:relcl'), (('at', 'task'), 'case'), (('the', 'task'), 'det'), (('task', 'improves'), 'obl'), (('you', 'set'), 'nsubj'), (('’ve', 'set'), 'aux'), (('set', 'task'), 'acl:relcl'), (('it', 'set'), 'obj'), (('.', 'is'), 'punct')]

 Named Entites are: 
>> []

------------------- Sentence 2 -------------------

 Input is key. 

Tokens are: 
>> ['Input', 'is', 'key', '.'] 

 UPOS tags are: 
>> [('Input', 'NOUN'), ('is', 'AUX'), ('key', 'ADJ'), ('.', 'PUNCT')] 

 XPOS tags are: 
>> [('Input', 'NN'), ('is', 'VBZ'), ('key', 'JJ'), ('.', '.')] 

 Lemmas are: 
>> [('Input', 'input'), ('is', 'be'), ('key', 'key'), ('.', '.')] 

 Dependency tags are: 
>> [(('Input', 'key'), 'nsubj'), (('is', 'key'), 'cop'), (('key', 'root'), 'root'), (('.', 'key'), 'punct')]

 Named Entites are: 
>> []

------------------- Sentence 3 -------------------

 Unlike algorithmic programming, a  machine learning model is able to generalize and deal with novel cases. 

Tokens are: 
>> ['Unlike', 'algorithmic', 'programming', ',', 'a', 'machine', 'learning', 'model', 'is', 'able', 'to', 'generalize', 'and', 'deal', 'with', 'novel', 'cases', '.'] 

 UPOS tags are: 
>> [('Unlike', 'ADP'), ('algorithmic', 'ADJ'), ('programming', 'NOUN'), (',', 'PUNCT'), ('a', 'DET'), ('machine', 'NOUN'), ('learning', 'NOUN'), ('model', 'NOUN'), ('is', 'AUX'), ('able', 'ADJ'), ('to', 'PART'), ('generalize', 'VERB'), ('and', 'CCONJ'), ('deal', 'VERB'), ('with', 'ADP'), ('novel', 'ADJ'), ('cases', 'NOUN'), ('.', 'PUNCT')] 

 XPOS tags are: 
>> [('Unlike', 'IN'), ('algorithmic', 'JJ'), ('programming', 'NN'), (',', ','), ('a', 'DT'), ('machine', 'NN'), ('learning', 'NN'), ('model', 'NN'), ('is', 'VBZ'), ('able', 'JJ'), ('to', 'TO'), ('generalize', 'VB'), ('and', 'CC'), ('deal', 'VB'), ('with', 'IN'), ('novel', 'JJ'), ('cases', 'NNS'), ('.', '.')] 

 Lemmas are: 
>> [('Unlike', 'unlike'), ('algorithmic', 'algorithmic'), ('programming', 'programming'), (',', ','), ('a', 'a'), ('machine', 'machine'), ('learning', 'learning'), ('model', 'model'), ('is', 'be'), ('able', 'able'), ('to', 'to'), ('generalize', 'generalize'), ('and', 'and'), ('deal', 'deal'), ('with', 'with'), ('novel', 'novel'), ('cases', 'case'), ('.', '.')] 

 Dependency tags are: 
>> [(('Unlike', 'programming'), 'case'), (('algorithmic', 'programming'), 'amod'), (('programming', 'able'), 'obl'), ((',', 'able'), 'punct'), (('a', 'model'), 'det'), (('machine', 'model'), 'compound'), (('learning', 'model'), 'compound'), (('model', 'able'), 'nsubj'), (('is', 'able'), 'cop'), (('able', 'root'), 'root'), (('to', 'generalize'), 'mark'), (('generalize', 'able'), 'xcomp'), (('and', 'deal'), 'cc'), (('deal', 'generalize'), 'conj'), (('with', 'cases'), 'case'), (('novel', 'cases'), 'amod'), (('cases', 'deal'), 'obl'), (('.', 'able'), 'punct')]

 Named Entites are: 
>> []

------------------- Sentence 4 -------------------

 If a  case resembles something the model has seen before, the model can use  this prior “learning” to evaluate the case. 

Tokens are: 
>> ['If', 'a', 'case', 'resembles', 'something', 'the', 'model', 'has', 'seen', 'before', ',', 'the', 'model', 'can', 'use', 'this', 'prior', '“', 'learning', '”', 'to', 'evaluate', 'the', 'case', '.'] 

 UPOS tags are: 
>> [('If', 'SCONJ'), ('a', 'DET'), ('case', 'NOUN'), ('resembles', 'VERB'), ('something', 'PRON'), ('the', 'DET'), ('model', 'NOUN'), ('has', 'AUX'), ('seen', 'VERB'), ('before', 'ADV'), (',', 'PUNCT'), ('the', 'DET'), ('model', 'NOUN'), ('can', 'AUX'), ('use', 'VERB'), ('this', 'DET'), ('prior', 'ADJ'), ('“', 'PUNCT'), ('learning', 'NOUN'), ('”', 'PUNCT'), ('to', 'PART'), ('evaluate', 'VERB'), ('the', 'DET'), ('case', 'NOUN'), ('.', 'PUNCT')] 

 XPOS tags are: 
>> [('If', 'IN'), ('a', 'DT'), ('case', 'NN'), ('resembles', 'VBZ'), ('something', 'NN'), ('the', 'DT'), ('model', 'NN'), ('has', 'VBZ'), ('seen', 'VBN'), ('before', 'RB'), (',', ','), ('the', 'DT'), ('model', 'NN'), ('can', 'MD'), ('use', 'VB'), ('this', 'DT'), ('prior', 'JJ'), ('“', '``'), ('learning', 'NN'), ('”', "''"), ('to', 'TO'), ('evaluate', 'VB'), ('the', 'DT'), ('case', 'NN'), ('.', '.')] 

 Lemmas are: 
>> [('If', 'if'), ('a', 'a'), ('case', 'case'), ('resembles', 'resemble'), ('something', 'something'), ('the', 'the'), ('model', 'model'), ('has', 'have'), ('seen', 'see'), ('before', 'before'), (',', ','), ('the', 'the'), ('model', 'model'), ('can', 'can'), ('use', 'use'), ('this', 'this'), ('prior', 'prior'), ('“', "''"), ('learning', 'learning'), ('”', "''"), ('to', 'to'), ('evaluate', 'evaluate'), ('the', 'the'), ('case', 'case'), ('.', '.')] 

 Dependency tags are: 
>> [(('If', 'resembles'), 'mark'), (('a', 'case'), 'det'), (('case', 'resembles'), 'nsubj'), (('resembles', 'use'), 'advcl'), (('something', 'resembles'), 'obj'), (('the', 'model'), 'det'), (('model', 'seen'), 'nsubj'), (('has', 'seen'), 'aux'), (('seen', 'something'), 'acl:relcl'), (('before', 'seen'), 'advmod'), ((',', 'use'), 'punct'), (('the', 'model'), 'det'), (('model', 'use'), 'nsubj'), (('can', 'use'), 'aux'), (('use', 'root'), 'root'), (('this', 'learning'), 'det'), (('prior', 'learning'), 'amod'), (('“', 'learning'), 'punct'), (('learning', 'use'), 'obj'), (('”', 'learning'), 'punct'), (('to', 'evaluate'), 'mark'), (('evaluate', 'use'), 'advcl'), (('the', 'case'), 'det'), (('case', 'evaluate'), 'obj'), (('.', 'use'), 'punct')]

 Named Entites are: 
>> []

================================ Paragraph 40 =================================

When we talk about a “model,” we’re talking about a mathematical  representation. A machine learning model is the sum of the learning  that has been acquired from the training data. The model changes as  more learning is acquired. 


------------------- Sentence 1 -------------------

 When we talk about a “model,” we’re talking about a mathematical  representation. 

Tokens are: 
>> ['When', 'we', 'talk', 'about', 'a', '“', 'model', ',', '”', 'we', '’re', 'talking', 'about', 'a', 'mathematical', 'representation', '.'] 

 UPOS tags are: 
>> [('When', 'SCONJ'), ('we', 'PRON'), ('talk', 'VERB'), ('about', 'ADP'), ('a', 'DET'), ('“', 'PUNCT'), ('model', 'NOUN'), (',', 'PUNCT'), ('”', 'PUNCT'), ('we', 'PRON'), ('’re', 'AUX'), ('talking', 'VERB'), ('about', 'ADP'), ('a', 'DET'), ('mathematical', 'ADJ'), ('representation', 'NOUN'), ('.', 'PUNCT')] 

 XPOS tags are: 
>> [('When', 'WRB'), ('we', 'PRP'), ('talk', 'VBP'), ('about', 'IN'), ('a', 'DT'), ('“', '``'), ('model', 'NN'), (',', ','), ('”', "''"), ('we', 'PRP'), ('’re', 'VBP'), ('talking', 'VBG'), ('about', 'IN'), ('a', 'DT'), ('mathematical', 'JJ'), ('representation', 'NN'), ('.', '.')] 

 Lemmas are: 
>> [('When', 'when'), ('we', 'we'), ('talk', 'talk'), ('about', 'about'), ('a', 'a'), ('“', "''"), ('model', 'model'), (',', ','), ('”', "''"), ('we', 'we'), ('’re', 'be'), ('talking', 'talk'), ('about', 'about'), ('a', 'a'), ('mathematical', 'mathematical'), ('representation', 'representation'), ('.', '.')] 

 Dependency tags are: 
>> [(('When', 'talk'), 'mark'), (('we', 'talk'), 'nsubj'), (('talk', 'talking'), 'advcl'), (('about', 'model'), 'case'), (('a', 'model'), 'det'), (('“', 'model'), 'punct'), (('model', 'talk'), 'obl'), ((',', 'model'), 'punct'), (('”', 'model'), 'punct'), (('we', 'talking'), 'nsubj'), (('’re', 'talking'), 'aux'), (('talking', 'root'), 'root'), (('about', 'representation'), 'case'), (('a', 'representation'), 'det'), (('mathematical', 'representation'), 'amod'), (('representation', 'talking'), 'obl'), (('.', 'talking'), 'punct')]

 Named Entites are: 
>> []

------------------- Sentence 2 -------------------

 A machine learning model is the sum of the learning  that has been acquired from the training data. 

Tokens are: 
>> ['A', 'machine', 'learning', 'model', 'is', 'the', 'sum', 'of', 'the', 'learning', 'that', 'has', 'been', 'acquired', 'from', 'the', 'training', 'data', '.'] 

 UPOS tags are: 
>> [('A', 'DET'), ('machine', 'NOUN'), ('learning', 'NOUN'), ('model', 'NOUN'), ('is', 'AUX'), ('the', 'DET'), ('sum', 'NOUN'), ('of', 'ADP'), ('the', 'DET'), ('learning', 'NOUN'), ('that', 'PRON'), ('has', 'AUX'), ('been', 'AUX'), ('acquired', 'VERB'), ('from', 'ADP'), ('the', 'DET'), ('training', 'NOUN'), ('data', 'NOUN'), ('.', 'PUNCT')] 

 XPOS tags are: 
>> [('A', 'DT'), ('machine', 'NN'), ('learning', 'NN'), ('model', 'NN'), ('is', 'VBZ'), ('the', 'DT'), ('sum', 'NN'), ('of', 'IN'), ('the', 'DT'), ('learning', 'NN'), ('that', 'WDT'), ('has', 'VBZ'), ('been', 'VBN'), ('acquired', 'VBN'), ('from', 'IN'), ('the', 'DT'), ('training', 'NN'), ('data', 'NN'), ('.', '.')] 

 Lemmas are: 
>> [('A', 'a'), ('machine', 'machine'), ('learning', 'learning'), ('model', 'model'), ('is', 'be'), ('the', 'the'), ('sum', 'sum'), ('of', 'of'), ('the', 'the'), ('learning', 'learning'), ('that', 'that'), ('has', 'have'), ('been', 'be'), ('acquired', 'acquire'), ('from', 'from'), ('the', 'the'), ('training', 'training'), ('data', 'datum'), ('.', '.')] 

 Dependency tags are: 
>> [(('A', 'model'), 'det'), (('machine', 'model'), 'compound'), (('learning', 'model'), 'compound'), (('model', 'sum'), 'nsubj'), (('is', 'sum'), 'cop'), (('the', 'sum'), 'det'), (('sum', 'root'), 'root'), (('of', 'learning'), 'case'), (('the', 'learning'), 'det'), (('learning', 'sum'), 'nmod'), (('that', 'acquired'), 'nsubj:pass'), (('has', 'acquired'), 'aux'), (('been', 'acquired'), 'aux:pass'), (('acquired', 'learning'), 'acl:relcl'), (('from', 'data'), 'case'), (('the', 'data'), 'det'), (('training', 'data'), 'compound'), (('data', 'acquired'), 'obl'), (('.', 'sum'), 'punct')]

 Named Entites are: 
>> []

------------------- Sentence 3 -------------------

 The model changes as  more learning is acquired. 

Tokens are: 
>> ['The', 'model', 'changes', 'as', 'more', 'learning', 'is', 'acquired', '.'] 

 UPOS tags are: 
>> [('The', 'DET'), ('model', 'NOUN'), ('changes', 'VERB'), ('as', 'SCONJ'), ('more', 'ADJ'), ('learning', 'NOUN'), ('is', 'AUX'), ('acquired', 'VERB'), ('.', 'PUNCT')] 

 XPOS tags are: 
>> [('The', 'DT'), ('model', 'NN'), ('changes', 'VBZ'), ('as', 'IN'), ('more', 'JJR'), ('learning', 'NN'), ('is', 'VBZ'), ('acquired', 'VBN'), ('.', '.')] 

 Lemmas are: 
>> [('The', 'the'), ('model', 'model'), ('changes', 'change'), ('as', 'as'), ('more', 'more'), ('learning', 'learning'), ('is', 'be'), ('acquired', 'acquire'), ('.', '.')] 

 Dependency tags are: 
>> [(('The', 'model'), 'det'), (('model', 'changes'), 'nsubj'), (('changes', 'root'), 'root'), (('as', 'acquired'), 'mark'), (('more', 'learning'), 'amod'), (('learning', 'acquired'), 'nsubj:pass'), (('is', 'acquired'), 'aux:pass'), (('acquired', 'changes'), 'advcl'), (('.', 'changes'), 'punct')]

 Named Entites are: 
>> []

================================ Paragraph 41 =================================

3 MAJOR PARTS TO MACHINE LEARNING 


------------------- Sentence 1 -------------------

 3 MAJOR PARTS TO MACHINE LEARNING 

Tokens are: 
>> ['3', 'MAJOR', 'PARTS', 'TO', 'MACHINE', 'LEARNING'] 

 UPOS tags are: 
>> [('3', 'NUM'), ('MAJOR', 'ADJ'), ('PARTS', 'NOUN'), ('TO', 'ADP'), ('MACHINE', 'NOUN'), ('LEARNING', 'NOUN')] 

 XPOS tags are: 
>> [('3', 'CD'), ('MAJOR', 'JJ'), ('PARTS', 'NNS'), ('TO', 'IN'), ('MACHINE', 'NN'), ('LEARNING', 'NN')] 

 Lemmas are: 
>> [('3', '3'), ('MAJOR', 'major'), ('PARTS', 'part'), ('TO', 'to'), ('MACHINE', 'machine'), ('LEARNING', 'learning')] 

 Dependency tags are: 
>> [(('3', 'PARTS'), 'nummod'), (('MAJOR', 'PARTS'), 'amod'), (('PARTS', 'root'), 'root'), (('TO', 'LEARNING'), 'case'), (('MACHINE', 'LEARNING'), 'compound'), (('LEARNING', 'PARTS'), 'nmod')]

 Named Entites are: 
>> [('3', 'CARDINAL')]

================================ Paragraph 42 =================================

 Training data  


------------------- Sentence 1 -------------------

 Training data 

Tokens are: 
>> ['Training', 'data'] 

 UPOS tags are: 
>> [('Training', 'NOUN'), ('data', 'NOUN')] 

 XPOS tags are: 
>> [('Training', 'NN'), ('data', 'NNS')] 

 Lemmas are: 
>> [('Training', 'training'), ('data', 'datum')] 

 Dependency tags are: 
>> [(('Training', 'data'), 'compound'), (('data', 'root'), 'root')]

 Named Entites are: 
>> []

================================ Paragraph 43 =================================

 Model algorithm  


------------------- Sentence 1 -------------------

 Model algorithm 

Tokens are: 
>> ['Model', 'algorithm'] 

 UPOS tags are: 
>> [('Model', 'NOUN'), ('algorithm', 'NOUN')] 

 XPOS tags are: 
>> [('Model', 'NN'), ('algorithm', 'NN')] 

 Lemmas are: 
>> [('Model', 'model'), ('algorithm', 'algorithm')] 

 Dependency tags are: 
>> [(('Model', 'algorithm'), 'compound'), (('algorithm', 'root'), 'root')]

 Named Entites are: 
>> []

================================ Paragraph 44 =================================

 Hyper-parameters 


------------------- Sentence 1 -------------------

 Hyper-parameters 

Tokens are: 
>> ['Hyper-parameters'] 

 UPOS tags are: 
>> [('Hyper-parameters', 'NOUN')] 

 XPOS tags are: 
>> [('Hyper-parameters', 'NNS')] 

 Lemmas are: 
>> [('Hyper-parameters', 'hyper-parameters')] 

 Dependency tags are: 
>> [(('Hyper-parameters', 'root'), 'root')]

 Named Entites are: 
>> []

================================ Paragraph 45 =================================

creates a learning framework   


------------------- Sentence 1 -------------------

 creates a learning framework 

Tokens are: 
>> ['creates', 'a', 'learning', 'framework'] 

 UPOS tags are: 
>> [('creates', 'VERB'), ('a', 'DET'), ('learning', 'NOUN'), ('framework', 'NOUN')] 

 XPOS tags are: 
>> [('creates', 'VBZ'), ('a', 'DT'), ('learning', 'NN'), ('framework', 'NN')] 

 Lemmas are: 
>> [('creates', 'create'), ('a', 'a'), ('learning', 'learning'), ('framework', 'framework')] 

 Dependency tags are: 
>> [(('creates', 'root'), 'root'), (('a', 'framework'), 'det'), (('learning', 'framework'), 'compound'), (('framework', 'creates'), 'obj')]

 Named Entites are: 
>> []

================================ Paragraph 46 =================================

and provides data that the  


------------------- Sentence 1 -------------------

 and provides data that the 

Tokens are: 
>> ['and', 'provides', 'data', 'that', 'the'] 

 UPOS tags are: 
>> [('and', 'CCONJ'), ('provides', 'VERB'), ('data', 'NOUN'), ('that', 'PRON'), ('the', 'DET')] 

 XPOS tags are: 
>> [('and', 'CC'), ('provides', 'VBZ'), ('data', 'NNS'), ('that', 'DT'), ('the', 'DT')] 

 Lemmas are: 
>> [('and', 'and'), ('provides', 'provide'), ('data', 'datum'), ('that', 'that'), ('the', 'the')] 

 Dependency tags are: 
>> [(('and', 'provides'), 'cc'), (('provides', 'root'), 'root'), (('data', 'provides'), 'obj'), (('that', 'provides'), 'obj'), (('the', 'provides'), 'obj')]

 Named Entites are: 
>> []

================================ Paragraph 47 =================================

machine can learn from. 


------------------- Sentence 1 -------------------

 machine can learn from. 

Tokens are: 
>> ['machine', 'can', 'learn', 'from', '.'] 

 UPOS tags are: 
>> [('machine', 'NOUN'), ('can', 'AUX'), ('learn', 'VERB'), ('from', 'ADP'), ('.', 'PUNCT')] 

 XPOS tags are: 
>> [('machine', 'NN'), ('can', 'MD'), ('learn', 'VB'), ('from', 'IN'), ('.', '.')] 

 Lemmas are: 
>> [('machine', 'machine'), ('can', 'can'), ('learn', 'learn'), ('from', 'from'), ('.', '.')] 

 Dependency tags are: 
>> [(('machine', 'learn'), 'nsubj'), (('can', 'learn'), 'aux'), (('learn', 'root'), 'root'), (('from', 'learn'), 'obl'), (('.', 'learn'), 'punct')]

 Named Entites are: 
>> []

================================ Paragraph 48 =================================

Machine  teaching   


------------------- Sentence 1 -------------------

 Machine  teaching 

Tokens are: 
>> ['Machine', 'teaching'] 

 UPOS tags are: 
>> [('Machine', 'NOUN'), ('teaching', 'NOUN')] 

 XPOS tags are: 
>> [('Machine', 'NN'), ('teaching', 'NN')] 

 Lemmas are: 
>> [('Machine', 'Machine'), ('teaching', 'teaching')] 

 Dependency tags are: 
>> [(('Machine', 'teaching'), 'compound'), (('teaching', 'root'), 'root')]

 Named Entites are: 
>> []

================================ Paragraph 49 =================================

(aka learning)


------------------- Sentence 1 -------------------

 (aka learning) 

Tokens are: 
>> ['(', 'aka', 'learning', ')'] 

 UPOS tags are: 
>> [('(', 'PUNCT'), ('aka', 'ADP'), ('learning', 'NOUN'), (')', 'PUNCT')] 

 XPOS tags are: 
>> [('(', '-LRB-'), ('aka', 'IN'), ('learning', 'NN'), (')', '-RRB-')] 

 Lemmas are: 
>> [('(', '('), ('aka', 'aka'), ('learning', 'learning'), (')', ')')] 

 Dependency tags are: 
>> [(('(', 'learning'), 'punct'), (('aka', 'learning'), 'case'), (('learning', 'root'), 'root'), ((')', 'learning'), 'punct')]

 Named Entites are: 
>> []

================================ Paragraph 50 =================================

W H I T E  P A P E R 


------------------- Sentence 1 -------------------

 W H I T E  P A P E R 

Tokens are: 
>> ['W', 'H', 'I', 'T', 'E', 'P', 'A', 'P', 'E', 'R'] 

 UPOS tags are: 
>> [('W', 'PROPN'), ('H', 'PUNCT'), ('I', 'PRON'), ('T', 'AUX'), ('E', 'PROPN'), ('P', 'NOUN'), ('A', 'NOUN'), ('P', 'NOUN'), ('E', 'NOUN'), ('R', 'NOUN')] 

 XPOS tags are: 
>> [('W', 'NNP'), ('H', ','), ('I', 'PRP'), ('T', 'VBP'), ('E', 'NNP'), ('P', 'NN'), ('A', 'NN'), ('P', 'NN'), ('E', 'NN'), ('R', 'NN')] 

 Lemmas are: 
>> [('W', 'W'), ('H', 'H'), ('I', 'I'), ('T', 'T'), ('E', 'E'), ('P', 'p'), ('A', 'a'), ('P', 'p'), ('E', 'e'), ('R', 'R')] 

 Dependency tags are: 
>> [(('W', 'T'), 'vocative'), (('H', 'W'), 'punct'), (('I', 'T'), 'nsubj'), (('T', 'root'), 'root'), (('E', 'T'), 'obj'), (('P', 'T'), 'obj'), (('A', 'E'), 'compound'), (('P', 'E'), 'compound'), (('E', 'R'), 'compound'), (('R', 'T'), 'obj')]

 Named Entites are: 
>> []

================================ Paragraph 51 =================================

4|       |   Lexalytics, Inc., 48 North Pleasant St. Unit 301, Amherst MA 01002 USA   |   1-800-377-8036 |   www.lexalytics.com 


------------------- Sentence 1 -------------------

 4|       |   Lexalytics, Inc., 48 North Pleasant St. Unit 301, Amherst MA 01002 USA   |   1-800-377-8036 |   www.lexalytics.com 

Tokens are: 
>> ['4', '|', '|', 'Lexalytics', ',', 'Inc.', ',', '48', 'North', 'Pleasant', 'St.', 'Unit', '301', ',', 'Amherst', 'MA', '01002', 'USA', '|', '1-800-377-8036', '|', 'www.lexalytics.com'] 

 UPOS tags are: 
>> [('4', 'NUM'), ('|', 'PUNCT'), ('|', 'PUNCT'), ('Lexalytics', 'PROPN'), (',', 'PUNCT'), ('Inc.', 'PROPN'), (',', 'PUNCT'), ('48', 'NUM'), ('North', 'PROPN'), ('Pleasant', 'ADJ'), ('St.', 'PROPN'), ('Unit', 'NOUN'), ('301', 'NUM'), (',', 'PUNCT'), ('Amherst', 'PROPN'), ('MA', 'PROPN'), ('01002', 'NUM'), ('USA', 'PROPN'), ('|', 'PUNCT'), ('1-800-377-8036', 'NUM'), ('|', 'PUNCT'), ('www.lexalytics.com', 'X')] 

 XPOS tags are: 
>> [('4', 'LS'), ('|', 'NFP'), ('|', 'NFP'), ('Lexalytics', 'NNP'), (',', ','), ('Inc.', 'NNP'), (',', ','), ('48', 'CD'), ('North', 'NNP'), ('Pleasant', 'NNP'), ('St.', 'NNP'), ('Unit', 'NN'), ('301', 'CD'), (',', ','), ('Amherst', 'NNP'), ('MA', 'NNP'), ('01002', 'CD'), ('USA', 'NNP'), ('|', 'NFP'), ('1-800-377-8036', 'CD'), ('|', 'NFP'), ('www.lexalytics.com', 'ADD')] 

 Lemmas are: 
>> [('4', '4'), ('|', '|'), ('|', '|'), ('Lexalytics', 'Lexalytics'), (',', ','), ('Inc.', 'Inc.'), (',', ','), ('48', '48'), ('North', 'North'), ('Pleasant', 'Pleasant'), ('St.', 'St.'), ('Unit', 'unit'), ('301', '301'), (',', ','), ('Amherst', 'Amherst'), ('MA', 'MA'), ('01002', '01002'), ('USA', 'USA'), ('|', '|'), ('1-800-377-8036', '1-800-377-8036'), ('|', '|'), ('www.lexalytics.com', 'www.lexalytics.com')] 

 Dependency tags are: 
>> [(('4', 'Inc.'), 'nummod'), (('|', '4'), 'punct'), (('|', '4'), 'punct'), (('Lexalytics', 'Inc.'), 'compound'), ((',', 'Inc.'), 'punct'), (('Inc.', 'root'), 'root'), ((',', 'Inc.'), 'punct'), (('48', 'St.'), 'nummod'), (('North', 'St.'), 'compound'), (('Pleasant', 'St.'), 'amod'), (('St.', 'Inc.'), 'list'), (('Unit', 'St.'), 'appos'), (('301', 'Unit'), 'nummod'), ((',', 'MA'), 'punct'), (('Amherst', 'MA'), 'appos'), (('MA', 'Inc.'), 'list'), (('01002', 'USA'), 'nummod'), (('USA', 'MA'), 'appos'), (('|', 'USA'), 'punct'), (('1-800-377-8036', 'Inc.'), 'list'), (('|', '1-800-377-8036'), 'punct'), (('www.lexalytics.com', 'Inc.'), 'list')]

 Named Entites are: 
>> [('4|       |   Lexalytics, Inc.', 'ORG'), ('301', 'CARDINAL')]

================================ Paragraph 52 =================================

The output of this system is a machine learning model.  


------------------- Sentence 1 -------------------

 The output of this system is a machine learning model. 

Tokens are: 
>> ['The', 'output', 'of', 'this', 'system', 'is', 'a', 'machine', 'learning', 'model', '.'] 

 UPOS tags are: 
>> [('The', 'DET'), ('output', 'NOUN'), ('of', 'ADP'), ('this', 'DET'), ('system', 'NOUN'), ('is', 'AUX'), ('a', 'DET'), ('machine', 'NOUN'), ('learning', 'NOUN'), ('model', 'NOUN'), ('.', 'PUNCT')] 

 XPOS tags are: 
>> [('The', 'DT'), ('output', 'NN'), ('of', 'IN'), ('this', 'DT'), ('system', 'NN'), ('is', 'VBZ'), ('a', 'DT'), ('machine', 'NN'), ('learning', 'NN'), ('model', 'NN'), ('.', '.')] 

 Lemmas are: 
>> [('The', 'the'), ('output', 'output'), ('of', 'of'), ('this', 'this'), ('system', 'system'), ('is', 'be'), ('a', 'a'), ('machine', 'machine'), ('learning', 'learning'), ('model', 'model'), ('.', '.')] 

 Dependency tags are: 
>> [(('The', 'output'), 'det'), (('output', 'model'), 'nsubj'), (('of', 'system'), 'case'), (('this', 'system'), 'det'), (('system', 'output'), 'nmod'), (('is', 'model'), 'cop'), (('a', 'model'), 'det'), (('machine', 'model'), 'compound'), (('learning', 'model'), 'compound'), (('model', 'root'), 'root'), (('.', 'model'), 'punct')]

 Named Entites are: 
>> []

================================ Paragraph 53 =================================

If you were baking a cake: 


------------------- Sentence 1 -------------------

 If you were baking a cake: 

Tokens are: 
>> ['If', 'you', 'were', 'baking', 'a', 'cake', ':'] 

 UPOS tags are: 
>> [('If', 'SCONJ'), ('you', 'PRON'), ('were', 'AUX'), ('baking', 'VERB'), ('a', 'DET'), ('cake', 'NOUN'), (':', 'PUNCT')] 

 XPOS tags are: 
>> [('If', 'IN'), ('you', 'PRP'), ('were', 'VBD'), ('baking', 'VBG'), ('a', 'DT'), ('cake', 'NN'), (':', ':')] 

 Lemmas are: 
>> [('If', 'if'), ('you', 'you'), ('were', 'be'), ('baking', 'bake'), ('a', 'a'), ('cake', 'cake'), (':', ':')] 

 Dependency tags are: 
>> [(('If', 'baking'), 'mark'), (('you', 'baking'), 'nsubj'), (('were', 'baking'), 'aux'), (('baking', 'root'), 'root'), (('a', 'cake'), 'det'), (('cake', 'baking'), 'obj'), ((':', 'baking'), 'punct')]

 Named Entites are: 
>> []

================================ Paragraph 54 =================================

• the training data would be the ingredients  • the time and temperature would be the hyper-parameters  • the cake would be the model 


------------------- Sentence 1 -------------------

 • the training data would be the ingredients  • the time and temperature would be the hyper-parameters  • the cake would be the model 

Tokens are: 
>> ['•', 'the', 'training', 'data', 'would', 'be', 'the', 'ingredients', '•', 'the', 'time', 'and', 'temperature', 'would', 'be', 'the', 'hyper', '-', 'parameters', '•', 'the', 'cake', 'would', 'be', 'the', 'model'] 

 UPOS tags are: 
>> [('•', 'PUNCT'), ('the', 'DET'), ('training', 'NOUN'), ('data', 'NOUN'), ('would', 'AUX'), ('be', 'AUX'), ('the', 'DET'), ('ingredients', 'NOUN'), ('•', 'PUNCT'), ('the', 'DET'), ('time', 'NOUN'), ('and', 'CCONJ'), ('temperature', 'NOUN'), ('would', 'AUX'), ('be', 'AUX'), ('the', 'DET'), ('hyper', 'ADJ'), ('-', 'PUNCT'), ('parameters', 'NOUN'), ('•', 'PUNCT'), ('the', 'DET'), ('cake', 'NOUN'), ('would', 'AUX'), ('be', 'AUX'), ('the', 'DET'), ('model', 'NOUN')] 

 XPOS tags are: 
>> [('•', 'NFP'), ('the', 'DT'), ('training', 'NN'), ('data', 'NNS'), ('would', 'MD'), ('be', 'VB'), ('the', 'DT'), ('ingredients', 'NNS'), ('•', 'NFP'), ('the', 'DT'), ('time', 'NN'), ('and', 'CC'), ('temperature', 'NN'), ('would', 'MD'), ('be', 'VB'), ('the', 'DT'), ('hyper', 'JJ'), ('-', 'HYPH'), ('parameters', 'NNS'), ('•', 'NFP'), ('the', 'DT'), ('cake', 'NN'), ('would', 'MD'), ('be', 'VB'), ('the', 'DT'), ('model', 'NN')] 

 Lemmas are: 
>> [('•', "''"), ('the', 'the'), ('training', 'training'), ('data', 'datum'), ('would', 'would'), ('be', 'be'), ('the', 'the'), ('ingredients', 'ingredient'), ('•', "''"), ('the', 'the'), ('time', 'time'), ('and', 'and'), ('temperature', 'temperature'), ('would', 'would'), ('be', 'be'), ('the', 'the'), ('hyper', 'hyper'), ('-', '-'), ('parameters', 'parameter'), ('•', "''"), ('the', 'the'), ('cake', 'cake'), ('would', 'would'), ('be', 'be'), ('the', 'the'), ('model', 'model')] 

 Dependency tags are: 
>> [(('•', 'ingredients'), 'punct'), (('the', 'data'), 'det'), (('training', 'data'), 'compound'), (('data', 'ingredients'), 'nsubj'), (('would', 'ingredients'), 'aux'), (('be', 'ingredients'), 'cop'), (('the', 'ingredients'), 'det'), (('ingredients', 'root'), 'root'), (('•', 'ingredients'), 'punct'), (('the', 'time'), 'det'), (('time', 'ingredients'), 'appos'), (('and', 'parameters'), 'cc'), (('temperature', 'parameters'), 'nsubj'), (('would', 'parameters'), 'aux'), (('be', 'parameters'), 'cop'), (('the', 'parameters'), 'det'), (('hyper', 'parameters'), 'amod'), (('-', 'parameters'), 'punct'), (('parameters', 'ingredients'), 'conj'), (('•', 'ingredients'), 'punct'), (('the', 'cake'), 'det'), (('cake', 'model'), 'nsubj'), (('would', 'model'), 'aux'), (('be', 'model'), 'cop'), (('the', 'model'), 'det'), (('model', 'ingredients'), 'parataxis')]

 Named Entites are: 
>> []

================================ Paragraph 55 =================================

 Lexalytics Hyper-Parameter Optimization Video  |  3:35 


------------------- Sentence 1 -------------------

 Lexalytics Hyper-Parameter Optimization Video  |  3:35 

Tokens are: 
>> ['Lexalytics', 'Hyper-', 'Parameter', 'Optimization', 'Video', '|', '3:35'] 

 UPOS tags are: 
>> [('Lexalytics', 'NOUN'), ('Hyper-', 'PROPN'), ('Parameter', 'NOUN'), ('Optimization', 'NOUN'), ('Video', 'NOUN'), ('|', 'PUNCT'), ('3:35', 'NUM')] 

 XPOS tags are: 
>> [('Lexalytics', 'NNS'), ('Hyper-', 'NNP'), ('Parameter', 'NN'), ('Optimization', 'NN'), ('Video', 'NN'), ('|', ','), ('3:35', 'CD')] 

 Lemmas are: 
>> [('Lexalytics', 'lexalytics'), ('Hyper-', 'Hyper-'), ('Parameter', 'parameter'), ('Optimization', 'optimization'), ('Video', 'video'), ('|', '|'), ('3:35', '3:35')] 

 Dependency tags are: 
>> [(('Lexalytics', 'root'), 'root'), (('Hyper-', 'Lexalytics'), 'flat'), (('Parameter', 'Video'), 'compound'), (('Optimization', 'Video'), 'compound'), (('Video', 'Lexalytics'), 'list'), (('|', 'Video'), 'punct'), (('3:35', 'Video'), 'appos')]

 Named Entites are: 
>> []

================================ Paragraph 56 =================================

Once the model is created (baked), we can run it against new data  to evaluate what it’s learned, and whether further adjustments   are needed.  


------------------- Sentence 1 -------------------

 Once the model is created (baked), we can run it against new data  to evaluate what it’s learned, and whether further adjustments   are needed. 

Tokens are: 
>> ['Once', 'the', 'model', 'is', 'created', '(', 'baked', ')', ',', 'we', 'can', 'run', 'it', 'against', 'new', 'data', 'to', 'evaluate', 'what', 'it', '’s', 'learned', ',', 'and', 'whether', 'further', 'adjustments', 'are', 'needed', '.'] 

 UPOS tags are: 
>> [('Once', 'SCONJ'), ('the', 'DET'), ('model', 'NOUN'), ('is', 'AUX'), ('created', 'VERB'), ('(', 'PUNCT'), ('baked', 'VERB'), (')', 'PUNCT'), (',', 'PUNCT'), ('we', 'PRON'), ('can', 'AUX'), ('run', 'VERB'), ('it', 'PRON'), ('against', 'ADP'), ('new', 'ADJ'), ('data', 'NOUN'), ('to', 'PART'), ('evaluate', 'VERB'), ('what', 'PRON'), ('it', 'PRON'), ('’s', 'AUX'), ('learned', 'VERB'), (',', 'PUNCT'), ('and', 'CCONJ'), ('whether', 'SCONJ'), ('further', 'ADJ'), ('adjustments', 'NOUN'), ('are', 'AUX'), ('needed', 'VERB'), ('.', 'PUNCT')] 

 XPOS tags are: 
>> [('Once', 'IN'), ('the', 'DT'), ('model', 'NN'), ('is', 'VBZ'), ('created', 'VBN'), ('(', '-LRB-'), ('baked', 'VBN'), (')', '-RRB-'), (',', ','), ('we', 'PRP'), ('can', 'MD'), ('run', 'VB'), ('it', 'PRP'), ('against', 'IN'), ('new', 'JJ'), ('data', 'NNS'), ('to', 'TO'), ('evaluate', 'VB'), ('what', 'WP'), ('it', 'PRP'), ('’s', 'VBZ'), ('learned', 'VBN'), (',', ','), ('and', 'CC'), ('whether', 'IN'), ('further', 'JJ'), ('adjustments', 'NNS'), ('are', 'VBP'), ('needed', 'VBN'), ('.', '.')] 

 Lemmas are: 
>> [('Once', 'once'), ('the', 'the'), ('model', 'model'), ('is', 'be'), ('created', 'create'), ('(', '('), ('baked', 'bake'), (')', ')'), (',', ','), ('we', 'we'), ('can', 'can'), ('run', 'run'), ('it', 'it'), ('against', 'against'), ('new', 'new'), ('data', 'datum'), ('to', 'to'), ('evaluate', 'evaluate'), ('what', 'what'), ('it', 'it'), ('’s', 'be'), ('learned', 'learn'), (',', ','), ('and', 'and'), ('whether', 'whether'), ('further', 'further'), ('adjustments', 'adjustment'), ('are', 'be'), ('needed', 'need'), ('.', '.')] 

 Dependency tags are: 
>> [(('Once', 'created'), 'mark'), (('the', 'model'), 'det'), (('model', 'created'), 'nsubj:pass'), (('is', 'created'), 'aux:pass'), (('created', 'run'), 'advcl'), (('(', 'baked'), 'punct'), (('baked', 'created'), 'advcl'), ((')', 'baked'), 'punct'), ((',', 'run'), 'punct'), (('we', 'run'), 'nsubj'), (('can', 'run'), 'aux'), (('run', 'root'), 'root'), (('it', 'run'), 'obj'), (('against', 'data'), 'case'), (('new', 'data'), 'amod'), (('data', 'run'), 'obl'), (('to', 'evaluate'), 'mark'), (('evaluate', 'run'), 'advcl'), (('what', 'evaluate'), 'obj'), (('it', 'learned'), 'nsubj:pass'), (('’s', 'learned'), 'aux:pass'), (('learned', 'what'), 'acl:relcl'), ((',', 'needed'), 'punct'), (('and', 'needed'), 'cc'), (('whether', 'needed'), 'mark'), (('further', 'adjustments'), 'amod'), (('adjustments', 'needed'), 'nsubj:pass'), (('are', 'needed'), 'aux:pass'), (('needed', 'learned'), 'conj'), (('.', 'run'), 'punct')]

 Named Entites are: 
>> []

================================ Paragraph 57 =================================

However, making adjustments isn’t just a matter of writing a line   of code that tells the model what to do. That kind of direct approach is  known as “algorithmic programming” – what most people call “coding.”   With machine learning, we need to convince the model that it wants to do   what we want it to do.  


------------------- Sentence 1 -------------------

 However, making adjustments isn’t just a matter of writing a line   of code that tells the model what to do. 

Tokens are: 
>> ['However', ',', 'making', 'adjustments', 'is', 'n’t', 'just', 'a', 'matter', 'of', 'writing', 'a', 'line', 'of', 'code', 'that', 'tells', 'the', 'model', 'what', 'to', 'do', '.'] 

 UPOS tags are: 
>> [('However', 'ADV'), (',', 'PUNCT'), ('making', 'VERB'), ('adjustments', 'NOUN'), ('is', 'AUX'), ('n’t', 'PART'), ('just', 'ADV'), ('a', 'DET'), ('matter', 'NOUN'), ('of', 'SCONJ'), ('writing', 'VERB'), ('a', 'DET'), ('line', 'NOUN'), ('of', 'ADP'), ('code', 'NOUN'), ('that', 'PRON'), ('tells', 'VERB'), ('the', 'DET'), ('model', 'NOUN'), ('what', 'PRON'), ('to', 'PART'), ('do', 'VERB'), ('.', 'PUNCT')] 

 XPOS tags are: 
>> [('However', 'RB'), (',', ','), ('making', 'VBG'), ('adjustments', 'NNS'), ('is', 'VBZ'), ('n’t', 'RB'), ('just', 'RB'), ('a', 'DT'), ('matter', 'NN'), ('of', 'IN'), ('writing', 'VBG'), ('a', 'DT'), ('line', 'NN'), ('of', 'IN'), ('code', 'NN'), ('that', 'WDT'), ('tells', 'VBZ'), ('the', 'DT'), ('model', 'NN'), ('what', 'WP'), ('to', 'TO'), ('do', 'VB'), ('.', '.')] 

 Lemmas are: 
>> [('However', 'however'), (',', ','), ('making', 'make'), ('adjustments', 'adjustment'), ('is', 'be'), ('n’t', 'not'), ('just', 'just'), ('a', 'a'), ('matter', 'matter'), ('of', 'of'), ('writing', 'write'), ('a', 'a'), ('line', 'line'), ('of', 'of'), ('code', 'code'), ('that', 'that'), ('tells', 'tell'), ('the', 'the'), ('model', 'model'), ('what', 'what'), ('to', 'to'), ('do', 'do'), ('.', '.')] 

 Dependency tags are: 
>> [(('However', 'matter'), 'advmod'), ((',', 'matter'), 'punct'), (('making', 'matter'), 'csubj'), (('adjustments', 'making'), 'obj'), (('is', 'matter'), 'cop'), (('n’t', 'matter'), 'advmod'), (('just', 'matter'), 'advmod'), (('a', 'matter'), 'det'), (('matter', 'root'), 'root'), (('of', 'writing'), 'mark'), (('writing', 'matter'), 'acl'), (('a', 'line'), 'det'), (('line', 'writing'), 'obj'), (('of', 'code'), 'case'), (('code', 'line'), 'nmod'), (('that', 'tells'), 'nsubj'), (('tells', 'code'), 'acl:relcl'), (('the', 'model'), 'det'), (('model', 'tells'), 'obj'), (('what', 'do'), 'obj'), (('to', 'do'), 'mark'), (('do', 'model'), 'acl'), (('.', 'matter'), 'punct')]

 Named Entites are: 
>> []

------------------- Sentence 2 -------------------

 That kind of direct approach is  known as “algorithmic programming” – what most people call “coding.” 

Tokens are: 
>> ['That', 'kind', 'of', 'direct', 'approach', 'is', 'known', 'as', '“', 'algorithmic', 'programming', '”', '–', 'what', 'most', 'people', 'call', '“', 'coding', '.', '”'] 

 UPOS tags are: 
>> [('That', 'DET'), ('kind', 'NOUN'), ('of', 'ADP'), ('direct', 'ADJ'), ('approach', 'NOUN'), ('is', 'AUX'), ('known', 'VERB'), ('as', 'ADP'), ('“', 'PUNCT'), ('algorithmic', 'ADJ'), ('programming', 'NOUN'), ('”', 'PUNCT'), ('–', 'PUNCT'), ('what', 'PRON'), ('most', 'ADJ'), ('people', 'NOUN'), ('call', 'VERB'), ('“', 'PUNCT'), ('coding', 'NOUN'), ('.', 'PUNCT'), ('”', 'PUNCT')] 

 XPOS tags are: 
>> [('That', 'DT'), ('kind', 'NN'), ('of', 'IN'), ('direct', 'JJ'), ('approach', 'NN'), ('is', 'VBZ'), ('known', 'VBN'), ('as', 'IN'), ('“', '``'), ('algorithmic', 'JJ'), ('programming', 'NN'), ('”', "''"), ('–', ':'), ('what', 'WP'), ('most', 'JJS'), ('people', 'NNS'), ('call', 'VBP'), ('“', '``'), ('coding', 'NN'), ('.', '.'), ('”', "''")] 

 Lemmas are: 
>> [('That', 'that'), ('kind', 'kind'), ('of', 'of'), ('direct', 'direct'), ('approach', 'approach'), ('is', 'be'), ('known', 'know'), ('as', 'as'), ('“', "''"), ('algorithmic', 'algorithmic'), ('programming', 'programming'), ('”', "''"), ('–', '-'), ('what', 'what'), ('most', 'most'), ('people', 'people'), ('call', 'call'), ('“', "''"), ('coding', 'coding'), ('.', '.'), ('”', "''")] 

 Dependency tags are: 
>> [(('That', 'kind'), 'det'), (('kind', 'known'), 'nsubj:pass'), (('of', 'approach'), 'case'), (('direct', 'approach'), 'amod'), (('approach', 'kind'), 'nmod'), (('is', 'known'), 'aux:pass'), (('known', 'root'), 'root'), (('as', 'programming'), 'case'), (('“', 'programming'), 'punct'), (('algorithmic', 'programming'), 'amod'), (('programming', 'known'), 'obl'), (('”', 'programming'), 'punct'), (('–', 'programming'), 'punct'), (('what', 'programming'), 'appos'), (('most', 'people'), 'amod'), (('people', 'call'), 'nsubj'), (('call', 'what'), 'acl:relcl'), (('“', 'coding'), 'punct'), (('coding', 'call'), 'obj'), (('.', 'coding'), 'punct'), (('”', 'coding'), 'punct')]

 Named Entites are: 
>> []

------------------- Sentence 3 -------------------

 With machine learning, we need to convince the model that it wants to do   what we want it to do. 

Tokens are: 
>> ['With', 'machine', 'learning', ',', 'we', 'need', 'to', 'convince', 'the', 'model', 'that', 'it', 'wants', 'to', 'do', 'what', 'we', 'want', 'it', 'to', 'do', '.'] 

 UPOS tags are: 
>> [('With', 'ADP'), ('machine', 'NOUN'), ('learning', 'NOUN'), (',', 'PUNCT'), ('we', 'PRON'), ('need', 'VERB'), ('to', 'PART'), ('convince', 'VERB'), ('the', 'DET'), ('model', 'NOUN'), ('that', 'PRON'), ('it', 'PRON'), ('wants', 'VERB'), ('to', 'PART'), ('do', 'VERB'), ('what', 'PRON'), ('we', 'PRON'), ('want', 'VERB'), ('it', 'PRON'), ('to', 'PART'), ('do', 'VERB'), ('.', 'PUNCT')] 

 XPOS tags are: 
>> [('With', 'IN'), ('machine', 'NN'), ('learning', 'NN'), (',', ','), ('we', 'PRP'), ('need', 'VBP'), ('to', 'TO'), ('convince', 'VB'), ('the', 'DT'), ('model', 'NN'), ('that', 'WDT'), ('it', 'PRP'), ('wants', 'VBZ'), ('to', 'TO'), ('do', 'VB'), ('what', 'WP'), ('we', 'PRP'), ('want', 'VBP'), ('it', 'PRP'), ('to', 'TO'), ('do', 'VB'), ('.', '.')] 

 Lemmas are: 
>> [('With', 'with'), ('machine', 'machine'), ('learning', 'learning'), (',', ','), ('we', 'we'), ('need', 'need'), ('to', 'to'), ('convince', 'convince'), ('the', 'the'), ('model', 'model'), ('that', 'that'), ('it', 'it'), ('wants', 'want'), ('to', 'to'), ('do', 'do'), ('what', 'what'), ('we', 'we'), ('want', 'want'), ('it', 'it'), ('to', 'to'), ('do', 'do'), ('.', '.')] 

 Dependency tags are: 
>> [(('With', 'learning'), 'case'), (('machine', 'learning'), 'compound'), (('learning', 'need'), 'obl'), ((',', 'need'), 'punct'), (('we', 'need'), 'nsubj'), (('need', 'root'), 'root'), (('to', 'convince'), 'mark'), (('convince', 'need'), 'xcomp'), (('the', 'model'), 'det'), (('model', 'convince'), 'obj'), (('that', 'wants'), 'obj'), (('it', 'wants'), 'nsubj'), (('wants', 'model'), 'acl:relcl'), (('to', 'do'), 'mark'), (('do', 'wants'), 'xcomp'), (('what', 'want'), 'obj'), (('we', 'want'), 'nsubj'), (('want', 'do'), 'ccomp'), (('it', 'want'), 'obj'), (('to', 'do'), 'mark'), (('do', 'want'), 'xcomp'), (('.', 'need'), 'punct')]

 Named Entites are: 
>> []

================================ Paragraph 58 =================================

Writing a line of code is clearly the more precise, concise approach –   and one that’s going to almost certainly be less work than machine   learning. We talk about this in the white paper “Tune First, Then Train.” 


------------------- Sentence 1 -------------------

 Writing a line of code is clearly the more precise, concise approach –   and one that’s going to almost certainly be less work than machine   learning. 

Tokens are: 
>> ['Writing', 'a', 'line', 'of', 'code', 'is', 'clearly', 'the', 'more', 'precise', ',', 'concise', 'approach', '–', 'and', 'one', 'that', '’s', 'going', 'to', 'almost', 'certainly', 'be', 'less', 'work', 'than', 'machine', 'learning', '.'] 

 UPOS tags are: 
>> [('Writing', 'VERB'), ('a', 'DET'), ('line', 'NOUN'), ('of', 'ADP'), ('code', 'NOUN'), ('is', 'AUX'), ('clearly', 'ADV'), ('the', 'DET'), ('more', 'ADV'), ('precise', 'ADJ'), (',', 'PUNCT'), ('concise', 'ADJ'), ('approach', 'NOUN'), ('–', 'PUNCT'), ('and', 'CCONJ'), ('one', 'NUM'), ('that', 'PRON'), ('’s', 'AUX'), ('going', 'VERB'), ('to', 'PART'), ('almost', 'ADV'), ('certainly', 'ADV'), ('be', 'AUX'), ('less', 'ADJ'), ('work', 'NOUN'), ('than', 'ADP'), ('machine', 'NOUN'), ('learning', 'NOUN'), ('.', 'PUNCT')] 

 XPOS tags are: 
>> [('Writing', 'VBG'), ('a', 'DT'), ('line', 'NN'), ('of', 'IN'), ('code', 'NN'), ('is', 'VBZ'), ('clearly', 'RB'), ('the', 'DT'), ('more', 'RBR'), ('precise', 'JJ'), (',', ','), ('concise', 'JJ'), ('approach', 'NN'), ('–', ':'), ('and', 'CC'), ('one', 'CD'), ('that', 'WDT'), ('’s', 'VBZ'), ('going', 'VBG'), ('to', 'TO'), ('almost', 'RB'), ('certainly', 'RB'), ('be', 'VB'), ('less', 'JJR'), ('work', 'NN'), ('than', 'IN'), ('machine', 'NN'), ('learning', 'NN'), ('.', '.')] 

 Lemmas are: 
>> [('Writing', 'write'), ('a', 'a'), ('line', 'line'), ('of', 'of'), ('code', 'code'), ('is', 'be'), ('clearly', 'clearly'), ('the', 'the'), ('more', 'more'), ('precise', 'precise'), (',', ','), ('concise', 'concise'), ('approach', 'approach'), ('–', '-'), ('and', 'and'), ('one', 'one'), ('that', 'that'), ('’s', 'be'), ('going', 'go'), ('to', 'to'), ('almost', 'almost'), ('certainly', 'certainly'), ('be', 'be'), ('less', 'less'), ('work', 'work'), ('than', 'than'), ('machine', 'machine'), ('learning', 'learning'), ('.', '.')] 

 Dependency tags are: 
>> [(('Writing', 'approach'), 'csubj'), (('a', 'line'), 'det'), (('line', 'Writing'), 'obj'), (('of', 'code'), 'case'), (('code', 'line'), 'nmod'), (('is', 'approach'), 'cop'), (('clearly', 'approach'), 'advmod'), (('the', 'approach'), 'det'), (('more', 'precise'), 'advmod'), (('precise', 'approach'), 'amod'), ((',', 'approach'), 'punct'), (('concise', 'approach'), 'amod'), (('approach', 'root'), 'root'), (('–', 'one'), 'punct'), (('and', 'one'), 'cc'), (('one', 'approach'), 'conj'), (('that', 'going'), 'nsubj'), (('’s', 'going'), 'aux'), (('going', 'one'), 'acl:relcl'), (('to', 'work'), 'mark'), (('almost', 'work'), 'advmod'), (('certainly', 'work'), 'advmod'), (('be', 'work'), 'cop'), (('less', 'work'), 'amod'), (('work', 'going'), 'xcomp'), (('than', 'learning'), 'case'), (('machine', 'learning'), 'compound'), (('learning', 'work'), 'nmod'), (('.', 'approach'), 'punct')]

 Named Entites are: 
>> []

------------------- Sentence 2 -------------------

 We talk about this in the white paper “Tune First, Then Train.” 

Tokens are: 
>> ['We', 'talk', 'about', 'this', 'in', 'the', 'white', 'paper', '“', 'Tune', 'First', ',', 'Then', 'Train', '.', '”'] 

 UPOS tags are: 
>> [('We', 'PRON'), ('talk', 'VERB'), ('about', 'ADP'), ('this', 'PRON'), ('in', 'ADP'), ('the', 'DET'), ('white', 'ADJ'), ('paper', 'NOUN'), ('“', 'PUNCT'), ('Tune', 'PROPN'), ('First', 'ADV'), (',', 'PUNCT'), ('Then', 'ADV'), ('Train', 'PROPN'), ('.', 'PUNCT'), ('”', 'PUNCT')] 

 XPOS tags are: 
>> [('We', 'PRP'), ('talk', 'VBP'), ('about', 'IN'), ('this', 'DT'), ('in', 'IN'), ('the', 'DT'), ('white', 'JJ'), ('paper', 'NN'), ('“', '``'), ('Tune', 'NNP'), ('First', 'RB'), (',', ','), ('Then', 'RB'), ('Train', 'NNP'), ('.', '.'), ('”', "''")] 

 Lemmas are: 
>> [('We', 'we'), ('talk', 'talk'), ('about', 'about'), ('this', 'this'), ('in', 'in'), ('the', 'the'), ('white', 'white'), ('paper', 'paper'), ('“', "''"), ('Tune', 'Tune'), ('First', 'first'), (',', ','), ('Then', 'then'), ('Train', 'Train'), ('.', '.'), ('”', "''")] 

 Dependency tags are: 
>> [(('We', 'talk'), 'nsubj'), (('talk', 'root'), 'root'), (('about', 'this'), 'case'), (('this', 'talk'), 'obl'), (('in', 'paper'), 'case'), (('the', 'paper'), 'det'), (('white', 'paper'), 'amod'), (('paper', 'talk'), 'obl'), (('“', 'Tune'), 'punct'), (('Tune', 'talk'), 'parataxis'), (('First', 'Tune'), 'advmod'), ((',', 'Tune'), 'punct'), (('Then', 'Train'), 'advmod'), (('Train', 'Tune'), 'appos'), (('.', 'Tune'), 'punct'), (('”', 'Tune'), 'punct')]

 Named Entites are: 
>> [('Tune First, Then Train', 'WORK_OF_ART')]

================================ Paragraph 59 =================================

However, coding isn’t always the right solution. Machine learning is   much better than coding at dealing with novel cases and learning   from the experience.  


------------------- Sentence 1 -------------------

 However, coding isn’t always the right solution. 

Tokens are: 
>> ['However', ',', 'coding', 'is', 'n’t', 'always', 'the', 'right', 'solution', '.'] 

 UPOS tags are: 
>> [('However', 'ADV'), (',', 'PUNCT'), ('coding', 'NOUN'), ('is', 'AUX'), ('n’t', 'PART'), ('always', 'ADV'), ('the', 'DET'), ('right', 'ADJ'), ('solution', 'NOUN'), ('.', 'PUNCT')] 

 XPOS tags are: 
>> [('However', 'RB'), (',', ','), ('coding', 'NN'), ('is', 'VBZ'), ('n’t', 'RB'), ('always', 'RB'), ('the', 'DT'), ('right', 'JJ'), ('solution', 'NN'), ('.', '.')] 

 Lemmas are: 
>> [('However', 'however'), (',', ','), ('coding', 'coding'), ('is', 'be'), ('n’t', 'not'), ('always', 'always'), ('the', 'the'), ('right', 'right'), ('solution', 'solution'), ('.', '.')] 

 Dependency tags are: 
>> [(('However', 'solution'), 'advmod'), ((',', 'solution'), 'punct'), (('coding', 'solution'), 'nsubj'), (('is', 'solution'), 'cop'), (('n’t', 'solution'), 'advmod'), (('always', 'solution'), 'advmod'), (('the', 'solution'), 'det'), (('right', 'solution'), 'amod'), (('solution', 'root'), 'root'), (('.', 'solution'), 'punct')]

 Named Entites are: 
>> []

------------------- Sentence 2 -------------------

 Machine learning is   much better than coding at dealing with novel cases and learning   from the experience. 

Tokens are: 
>> ['Machine', 'learning', 'is', 'much', 'better', 'than', 'coding', 'at', 'dealing', 'with', 'novel', 'cases', 'and', 'learning', 'from', 'the', 'experience', '.'] 

 UPOS tags are: 
>> [('Machine', 'NOUN'), ('learning', 'NOUN'), ('is', 'AUX'), ('much', 'ADV'), ('better', 'ADJ'), ('than', 'SCONJ'), ('coding', 'VERB'), ('at', 'SCONJ'), ('dealing', 'VERB'), ('with', 'ADP'), ('novel', 'ADJ'), ('cases', 'NOUN'), ('and', 'CCONJ'), ('learning', 'NOUN'), ('from', 'ADP'), ('the', 'DET'), ('experience', 'NOUN'), ('.', 'PUNCT')] 

 XPOS tags are: 
>> [('Machine', 'NN'), ('learning', 'NN'), ('is', 'VBZ'), ('much', 'RB'), ('better', 'JJR'), ('than', 'IN'), ('coding', 'VBG'), ('at', 'IN'), ('dealing', 'VBG'), ('with', 'IN'), ('novel', 'JJ'), ('cases', 'NNS'), ('and', 'CC'), ('learning', 'NN'), ('from', 'IN'), ('the', 'DT'), ('experience', 'NN'), ('.', '.')] 

 Lemmas are: 
>> [('Machine', 'Machine'), ('learning', 'learning'), ('is', 'be'), ('much', 'much'), ('better', 'good'), ('than', 'than'), ('coding', 'code'), ('at', 'at'), ('dealing', 'deal'), ('with', 'with'), ('novel', 'novel'), ('cases', 'case'), ('and', 'and'), ('learning', 'learning'), ('from', 'from'), ('the', 'the'), ('experience', 'experience'), ('.', '.')] 

 Dependency tags are: 
>> [(('Machine', 'learning'), 'compound'), (('learning', 'better'), 'nsubj'), (('is', 'better'), 'cop'), (('much', 'better'), 'advmod'), (('better', 'root'), 'root'), (('than', 'coding'), 'mark'), (('coding', 'better'), 'advcl'), (('at', 'dealing'), 'mark'), (('dealing', 'coding'), 'advcl'), (('with', 'cases'), 'case'), (('novel', 'cases'), 'amod'), (('cases', 'dealing'), 'obl'), (('and', 'learning'), 'cc'), (('learning', 'cases'), 'conj'), (('from', 'experience'), 'case'), (('the', 'experience'), 'det'), (('experience', 'dealing'), 'obl'), (('.', 'better'), 'punct')]

 Named Entites are: 
>> []

================================ Paragraph 60 =================================

In the next section we’ll review the main classes of machine learning. 


------------------- Sentence 1 -------------------

 In the next section we’ll review the main classes of machine learning. 

Tokens are: 
>> ['In', 'the', 'next', 'section', 'we', '’ll', 'review', 'the', 'main', 'classes', 'of', 'machine', 'learning', '.'] 

 UPOS tags are: 
>> [('In', 'ADP'), ('the', 'DET'), ('next', 'ADJ'), ('section', 'NOUN'), ('we', 'PRON'), ('’ll', 'AUX'), ('review', 'VERB'), ('the', 'DET'), ('main', 'ADJ'), ('classes', 'NOUN'), ('of', 'ADP'), ('machine', 'NOUN'), ('learning', 'NOUN'), ('.', 'PUNCT')] 

 XPOS tags are: 
>> [('In', 'IN'), ('the', 'DT'), ('next', 'JJ'), ('section', 'NN'), ('we', 'PRP'), ('’ll', 'MD'), ('review', 'VB'), ('the', 'DT'), ('main', 'JJ'), ('classes', 'NNS'), ('of', 'IN'), ('machine', 'NN'), ('learning', 'NN'), ('.', '.')] 

 Lemmas are: 
>> [('In', 'in'), ('the', 'the'), ('next', 'next'), ('section', 'section'), ('we', 'we'), ('’ll', 'will'), ('review', 'review'), ('the', 'the'), ('main', 'main'), ('classes', 'class'), ('of', 'of'), ('machine', 'machine'), ('learning', 'learning'), ('.', '.')] 

 Dependency tags are: 
>> [(('In', 'section'), 'case'), (('the', 'section'), 'det'), (('next', 'section'), 'amod'), (('section', 'review'), 'obl'), (('we', 'review'), 'nsubj'), (('’ll', 'review'), 'aux'), (('review', 'root'), 'root'), (('the', 'classes'), 'det'), (('main', 'classes'), 'amod'), (('classes', 'review'), 'obj'), (('of', 'learning'), 'case'), (('machine', 'learning'), 'compound'), (('learning', 'classes'), 'nmod'), (('.', 'review'), 'punct')]

 Named Entites are: 
>> []

================================ Paragraph 61 =================================

is simply a matter of writing   


------------------- Sentence 1 -------------------

 is simply a matter of writing 

Tokens are: 
>> ['is', 'simply', 'a', 'matter', 'of', 'writing'] 

 UPOS tags are: 
>> [('is', 'AUX'), ('simply', 'ADV'), ('a', 'DET'), ('matter', 'NOUN'), ('of', 'ADP'), ('writing', 'NOUN')] 

 XPOS tags are: 
>> [('is', 'VBZ'), ('simply', 'RB'), ('a', 'DT'), ('matter', 'NN'), ('of', 'IN'), ('writing', 'NN')] 

 Lemmas are: 
>> [('is', 'be'), ('simply', 'simply'), ('a', 'a'), ('matter', 'matter'), ('of', 'of'), ('writing', 'writing')] 

 Dependency tags are: 
>> [(('is', 'matter'), 'cop'), (('simply', 'matter'), 'advmod'), (('a', 'matter'), 'det'), (('matter', 'root'), 'root'), (('of', 'writing'), 'case'), (('writing', 'matter'), 'nmod')]

 Named Entites are: 
>> []

================================ Paragraph 62 =================================

a line of code that tells the   


------------------- Sentence 1 -------------------

 a line of code that tells the 

Tokens are: 
>> ['a', 'line', 'of', 'code', 'that', 'tells', 'the'] 

 UPOS tags are: 
>> [('a', 'DET'), ('line', 'NOUN'), ('of', 'ADP'), ('code', 'NOUN'), ('that', 'PRON'), ('tells', 'VERB'), ('the', 'DET')] 

 XPOS tags are: 
>> [('a', 'DT'), ('line', 'NN'), ('of', 'IN'), ('code', 'NN'), ('that', 'WDT'), ('tells', 'VBZ'), ('the', 'DT')] 

 Lemmas are: 
>> [('a', 'a'), ('line', 'line'), ('of', 'of'), ('code', 'code'), ('that', 'that'), ('tells', 'tell'), ('the', 'the')] 

 Dependency tags are: 
>> [(('a', 'line'), 'det'), (('line', 'root'), 'root'), (('of', 'code'), 'case'), (('code', 'line'), 'nmod'), (('that', 'tells'), 'nsubj'), (('tells', 'code'), 'acl:relcl'), (('the', 'tells'), 'obj')]

 Named Entites are: 
>> []

================================ Paragraph 63 =================================

model what to do. 


------------------- Sentence 1 -------------------

 model what to do. 

Tokens are: 
>> ['model', 'what', 'to', 'do', '.'] 

 UPOS tags are: 
>> [('model', 'VERB'), ('what', 'PRON'), ('to', 'PART'), ('do', 'VERB'), ('.', 'PUNCT')] 

 XPOS tags are: 
>> [('model', 'VB'), ('what', 'WP'), ('to', 'TO'), ('do', 'VB'), ('.', '.')] 

 Lemmas are: 
>> [('model', 'model'), ('what', 'what'), ('to', 'to'), ('do', 'do'), ('.', '.')] 

 Dependency tags are: 
>> [(('model', 'root'), 'root'), (('what', 'model'), 'obj'), (('to', 'do'), 'mark'), (('do', 'model'), 'xcomp'), (('.', 'model'), 'punct')]

 Named Entites are: 
>> []

================================ Paragraph 64 =================================

Algorithmic  programming


------------------- Sentence 1 -------------------

 Algorithmic  programming 

Tokens are: 
>> ['Algorithmic', 'programming'] 

 UPOS tags are: 
>> [('Algorithmic', 'ADJ'), ('programming', 'NOUN')] 

 XPOS tags are: 
>> [('Algorithmic', 'JJ'), ('programming', 'NN')] 

 Lemmas are: 
>> [('Algorithmic', 'algorithmic'), ('programming', 'programming')] 

 Dependency tags are: 
>> [(('Algorithmic', 'programming'), 'amod'), (('programming', 'root'), 'root')]

 Named Entites are: 
>> []

================================ Paragraph 65 =================================

W H I T E  P A P E R 


------------------- Sentence 1 -------------------

 W H I T E  P A P E R 

Tokens are: 
>> ['W', 'H', 'I', 'T', 'E', 'P', 'A', 'P', 'E', 'R'] 

 UPOS tags are: 
>> [('W', 'PROPN'), ('H', 'PUNCT'), ('I', 'PRON'), ('T', 'AUX'), ('E', 'PROPN'), ('P', 'NOUN'), ('A', 'NOUN'), ('P', 'NOUN'), ('E', 'NOUN'), ('R', 'NOUN')] 

 XPOS tags are: 
>> [('W', 'NNP'), ('H', ','), ('I', 'PRP'), ('T', 'VBP'), ('E', 'NNP'), ('P', 'NN'), ('A', 'NN'), ('P', 'NN'), ('E', 'NN'), ('R', 'NN')] 

 Lemmas are: 
>> [('W', 'W'), ('H', 'H'), ('I', 'I'), ('T', 'T'), ('E', 'E'), ('P', 'p'), ('A', 'a'), ('P', 'p'), ('E', 'e'), ('R', 'R')] 

 Dependency tags are: 
>> [(('W', 'T'), 'vocative'), (('H', 'W'), 'punct'), (('I', 'T'), 'nsubj'), (('T', 'root'), 'root'), (('E', 'T'), 'obj'), (('P', 'T'), 'obj'), (('A', 'E'), 'compound'), (('P', 'E'), 'compound'), (('E', 'R'), 'compound'), (('R', 'T'), 'obj')]

 Named Entites are: 
>> []

================================ Paragraph 66 =================================

5|       |   Lexalytics, Inc., 48 North Pleasant St. Unit 301, Amherst MA 01002 USA   |   1-800-377-8036 |   www.lexalytics.com 


------------------- Sentence 1 -------------------

 5|       |   Lexalytics, Inc., 48 North Pleasant St. Unit 301, Amherst MA 01002 USA   |   1-800-377-8036 |   www.lexalytics.com 

Tokens are: 
>> ['5', '|', '|', 'Lexalytics', ',', 'Inc.', ',', '48', 'North', 'Pleasant', 'St.', 'Unit', '301', ',', 'Amherst', 'MA', '01002', 'USA', '|', '1-800-377-8036', '|', 'www.lexalytics.com'] 

 UPOS tags are: 
>> [('5', 'NUM'), ('|', 'PUNCT'), ('|', 'PUNCT'), ('Lexalytics', 'PROPN'), (',', 'PUNCT'), ('Inc.', 'PROPN'), (',', 'PUNCT'), ('48', 'NUM'), ('North', 'PROPN'), ('Pleasant', 'ADJ'), ('St.', 'PROPN'), ('Unit', 'PROPN'), ('301', 'NUM'), (',', 'PUNCT'), ('Amherst', 'PROPN'), ('MA', 'PROPN'), ('01002', 'NUM'), ('USA', 'PROPN'), ('|', 'PUNCT'), ('1-800-377-8036', 'NUM'), ('|', 'PUNCT'), ('www.lexalytics.com', 'X')] 

 XPOS tags are: 
>> [('5', 'LS'), ('|', 'NFP'), ('|', 'NFP'), ('Lexalytics', 'NNP'), (',', ','), ('Inc.', 'NNP'), (',', ','), ('48', 'CD'), ('North', 'NNP'), ('Pleasant', 'NNP'), ('St.', 'NNP'), ('Unit', 'NNP'), ('301', 'CD'), (',', ','), ('Amherst', 'NNP'), ('MA', 'NNP'), ('01002', 'CD'), ('USA', 'NNP'), ('|', 'NFP'), ('1-800-377-8036', 'CD'), ('|', 'NFP'), ('www.lexalytics.com', 'ADD')] 

 Lemmas are: 
>> [('5', '5'), ('|', '|'), ('|', '|'), ('Lexalytics', 'Lexalytics'), (',', ','), ('Inc.', 'Inc.'), (',', ','), ('48', '48'), ('North', 'North'), ('Pleasant', 'Pleasant'), ('St.', 'St.'), ('Unit', 'unit'), ('301', '301'), (',', ','), ('Amherst', 'Amherst'), ('MA', 'MA'), ('01002', '01002'), ('USA', 'USA'), ('|', '|'), ('1-800-377-8036', '1-800-377-8036'), ('|', '|'), ('www.lexalytics.com', 'www.lexalytics.com')] 

 Dependency tags are: 
>> [(('5', 'Inc.'), 'nummod'), (('|', '5'), 'punct'), (('|', '5'), 'punct'), (('Lexalytics', 'Inc.'), 'compound'), ((',', 'Inc.'), 'punct'), (('Inc.', 'root'), 'root'), ((',', 'Inc.'), 'punct'), (('48', 'St.'), 'nummod'), (('North', 'St.'), 'compound'), (('Pleasant', 'St.'), 'amod'), (('St.', 'Unit'), 'compound'), (('Unit', 'Inc.'), 'list'), (('301', 'Unit'), 'nummod'), ((',', 'Unit'), 'punct'), (('Amherst', 'MA'), 'appos'), (('MA', 'Inc.'), 'list'), (('01002', 'USA'), 'nummod'), (('USA', 'MA'), 'appos'), (('|', 'USA'), 'punct'), (('1-800-377-8036', 'Inc.'), 'list'), (('|', '1-800-377-8036'), 'punct'), (('www.lexalytics.com', 'Inc.'), 'list')]

 Named Entites are: 
>> [('5|       |   Lexalytics, Inc.', 'ORG'), ('301', 'CARDINAL')]

================================ Paragraph 67 =================================

means feeding a   


------------------- Sentence 1 -------------------

 means feeding a 

Tokens are: 
>> ['means', 'feeding', 'a'] 

 UPOS tags are: 
>> [('means', 'VERB'), ('feeding', 'VERB'), ('a', 'DET')] 

 XPOS tags are: 
>> [('means', 'VBZ'), ('feeding', 'VBG'), ('a', 'DT')] 

 Lemmas are: 
>> [('means', 'mean'), ('feeding', 'feed'), ('a', 'a')] 

 Dependency tags are: 
>> [(('means', 'root'), 'root'), (('feeding', 'means'), 'xcomp'), (('a', 'feeding'), 'obj')]

 Named Entites are: 
>> []

================================ Paragraph 68 =================================

machine learning model   


------------------- Sentence 1 -------------------

 machine learning model 

Tokens are: 
>> ['machine', 'learning', 'model'] 

 UPOS tags are: 
>> [('machine', 'NOUN'), ('learning', 'NOUN'), ('model', 'NOUN')] 

 XPOS tags are: 
>> [('machine', 'NN'), ('learning', 'NN'), ('model', 'NN')] 

 Lemmas are: 
>> [('machine', 'machine'), ('learning', 'learning'), ('model', 'model')] 

 Dependency tags are: 
>> [(('machine', 'model'), 'compound'), (('learning', 'model'), 'compound'), (('model', 'root'), 'root')]

 Named Entites are: 
>> []

================================ Paragraph 69 =================================

an annotated dataset. 


------------------- Sentence 1 -------------------

 an annotated dataset. 

Tokens are: 
>> ['an', 'annotated', 'dataset', '.'] 

 UPOS tags are: 
>> [('an', 'DET'), ('annotated', 'VERB'), ('dataset', 'NOUN'), ('.', 'PUNCT')] 

 XPOS tags are: 
>> [('an', 'DT'), ('annotated', 'VBN'), ('dataset', 'NN'), ('.', '.')] 

 Lemmas are: 
>> [('an', 'a'), ('annotated', 'annotate'), ('dataset', 'dataset'), ('.', '.')] 

 Dependency tags are: 
>> [(('an', 'dataset'), 'det'), (('annotated', 'dataset'), 'amod'), (('dataset', 'root'), 'root'), (('.', 'dataset'), 'punct')]

 Named Entites are: 
>> []

================================ Paragraph 70 =================================

Supervised  learning 


------------------- Sentence 1 -------------------

 Supervised  learning 

Tokens are: 
>> ['Supervised', 'learning'] 

 UPOS tags are: 
>> [('Supervised', 'VERB'), ('learning', 'NOUN')] 

 XPOS tags are: 
>> [('Supervised', 'VBN'), ('learning', 'NN')] 

 Lemmas are: 
>> [('Supervised', 'supervise'), ('learning', 'learning')] 

 Dependency tags are: 
>> [(('Supervised', 'learning'), 'amod'), (('learning', 'root'), 'root')]

 Named Entites are: 
>> []

================================ Paragraph 71 =================================

S U P E R V I S E D ,  U N S U P E R V I S E D ,   A N D  S E M I - S U P E R V I S E D   M A C H I N E  L E A R N I N G  There are three relevant classes of machine learning: supervised learning,  unsupervised learning, and semi-supervised learning. Lexalytics uses all  three depending on the problem we’re trying to solve. 


------------------- Sentence 1 -------------------

 S U P E R V I S E D ,  U N S U P E R V I S E D ,   A N D  S E M I - S U P E R V I S E D   M A C H I N E  L E A R N I N G 

Tokens are: 
>> ['S', 'U', 'P', 'E', 'R', 'V', 'I', 'S', 'E', 'D', ',', 'U', 'N', 'S', 'U', 'P', 'E', 'R', 'V', 'I', 'S', 'E', 'D', ',', 'A', 'N', 'D', 'S', 'E', 'M', 'I', '-', 'S', 'U', 'P', 'E', 'R', 'V', 'I', 'S', 'E', 'D', 'M', 'A', 'C', 'H', 'I', 'N', 'E', 'L', 'E', 'A', 'R', 'N', 'I', 'N', 'G'] 

 UPOS tags are: 
>> [('S', 'PROPN'), ('U', 'PROPN'), ('P', 'PROPN'), ('E', 'PROPN'), ('R', 'PROPN'), ('V', 'PROPN'), ('I', 'PRON'), ('S', 'PROPN'), ('E', 'PROPN'), ('D', 'PROPN'), (',', 'PUNCT'), ('U', 'PROPN'), ('N', 'PROPN'), ('S', 'PROPN'), ('U', 'PROPN'), ('P', 'PROPN'), ('E', 'PROPN'), ('R', 'PROPN'), ('V', 'PROPN'), ('I', 'PRON'), ('S', 'ADP'), ('E', 'PROPN'), ('D', 'PROPN'), (',', 'PUNCT'), ('A', 'DET'), ('N', 'PROPN'), ('D', 'PROPN'), ('S', 'PROPN'), ('E', 'NOUN'), ('M', 'NOUN'), ('I', 'PRON'), ('-', 'PUNCT'), ('S', 'DET'), ('U', 'NOUN'), ('P', 'NOUN'), ('E', 'NOUN'), ('R', 'X'), ('V', 'NOUN'), ('I', 'PRON'), ('S', 'AUX'), ('E', 'NOUN'), ('D', 'NOUN'), ('M', 'NOUN'), ('A', 'NOUN'), ('C', 'NOUN'), ('H', 'NOUN'), ('I', 'PRON'), ('N', 'PROPN'), ('E', 'PROPN'), ('L', 'PROPN'), ('E', 'PROPN'), ('A', 'PROPN'), ('R', 'PROPN'), ('N', 'PROPN'), ('I', 'PRON'), ('N', 'PROPN'), ('G', 'PUNCT')] 

 XPOS tags are: 
>> [('S', 'NNP'), ('U', 'NNP'), ('P', 'NNP'), ('E', 'NNP'), ('R', 'NNP'), ('V', 'NNP'), ('I', 'PRP'), ('S', 'NNP'), ('E', 'NNP'), ('D', 'NNP'), (',', ','), ('U', 'NNP'), ('N', 'NNP'), ('S', 'NNP'), ('U', 'NNP'), ('P', 'NNP'), ('E', 'NNP'), ('R', 'NNP'), ('V', 'NNP'), ('I', 'PRP'), ('S', 'IN'), ('E', 'NNP'), ('D', 'NNP'), (',', ','), ('A', 'DT'), ('N', 'NNP'), ('D', 'NNP'), ('S', 'NNP'), ('E', 'NN'), ('M', 'NN'), ('I', 'PRP'), ('-', ','), ('S', 'DT'), ('U', 'NN'), ('P', 'NN'), ('E', 'NN'), ('R', 'GW'), ('V', 'NN'), ('I', 'PRP'), ('S', 'VBZ'), ('E', 'NN'), ('D', 'NN'), ('M', 'NN'), ('A', 'NN'), ('C', 'NN'), ('H', 'NN'), ('I', 'PRP'), ('N', 'NNP'), ('E', 'NNP'), ('L', 'NNP'), ('E', 'NNP'), ('A', 'NNP'), ('R', 'NNP'), ('N', 'NNP'), ('I', 'PRP'), ('N', 'NNP'), ('G', '.')] 

 Lemmas are: 
>> [('S', 'S'), ('U', 'U'), ('P', 'P'), ('E', 'E'), ('R', 'R'), ('V', 'V'), ('I', 'I'), ('S', 'S'), ('E', 'E'), ('D', 'D'), (',', ','), ('U', 'U'), ('N', 'N'), ('S', 'S'), ('U', 'U'), ('P', 'P'), ('E', 'E'), ('R', 'R'), ('V', 'V'), ('I', 'I'), ('S', 'S'), ('E', 'E'), ('D', 'D'), (',', ','), ('A', 'a'), ('N', 'N'), ('D', 'D'), ('S', 'S'), ('E', 'e'), ('M', 'm'), ('I', 'I'), ('-', '-'), ('S', 'S'), ('U', 'U'), ('P', 'p'), ('E', 'e'), ('R', 'r'), ('V', 'V'), ('I', 'I'), ('S', 'be'), ('E', 'e'), ('D', 'd'), ('M', 'm'), ('A', 'a'), ('C', 'c'), ('H', 'h'), ('I', 'I'), ('N', 'N'), ('E', 'E'), ('L', 'L'), ('E', 'E'), ('A', 'A'), ('R', 'R'), ('N', 'N'), ('I', 'I'), ('N', 'N'), ('G', 'G')] 

 Dependency tags are: 
>> [(('S', 'root'), 'root'), (('U', 'S'), 'flat'), (('P', 'S'), 'flat'), (('E', 'S'), 'flat'), (('R', 'V'), 'compound'), (('V', 'S'), 'appos'), (('I', 'D'), 'compound'), (('S', 'V'), 'flat'), (('E', 'D'), 'compound'), (('D', 'S'), 'flat'), ((',', 'U'), 'punct'), (('U', 'U'), 'compound'), (('N', 'U'), 'compound'), (('S', 'U'), 'compound'), (('U', 'S'), 'list'), (('P', 'U'), 'flat'), (('E', 'U'), 'flat'), (('R', 'V'), 'compound'), (('V', 'U'), 'appos'), (('I', 'S'), 'conj'), (('S', 'E'), 'case'), (('E', 'S'), 'flat'), (('D', 'E'), 'flat'), ((',', 'D'), 'punct'), (('A', 'D'), 'det'), (('N', 'D'), 'compound'), (('D', 'S'), 'appos'), (('S', 'D'), 'flat'), (('E', 'M'), 'compound'), (('M', 'S'), 'list'), (('I', 'M'), 'appos'), (('-', 'S'), 'punct'), (('S', 'P'), 'det'), (('U', 'P'), 'compound'), (('P', 'S'), 'parataxis'), (('E', 'P'), 'compound'), (('R', 'E'), 'case'), (('V', 'E'), 'punct'), (('I', 'E'), 'nsubj'), (('S', 'E'), 'cop'), (('E', 'S'), 'parataxis'), (('D', 'M'), 'compound'), (('M', 'E'), 'obj'), (('A', 'M'), 'nummod'), (('C', 'M'), 'compound'), (('H', 'E'), 'obj'), (('I', 'E'), 'compound'), (('N', 'E'), 'flat'), (('E', 'H'), 'appos'), (('L', 'E'), 'flat'), (('E', 'E'), 'flat'), (('A', 'N'), 'compound'), (('R', 'N'), 'compound'), (('N', 'E'), 'flat'), (('I', 'N'), 'compound'), (('N', 'N'), 'appos'), (('G', 'M'), 'punct')]

 Named Entites are: 
>> []

------------------- Sentence 2 -------------------

 There are three relevant classes of machine learning: supervised learning,  unsupervised learning, and semi-supervised learning. 

Tokens are: 
>> ['There', 'are', 'three', 'relevant', 'classes', 'of', 'machine', 'learning', ':', 'supervised', 'learning', ',', 'unsupervised', 'learning', ',', 'and', 'semi-supervised', 'learning', '.'] 

 UPOS tags are: 
>> [('There', 'PRON'), ('are', 'VERB'), ('three', 'NUM'), ('relevant', 'ADJ'), ('classes', 'NOUN'), ('of', 'ADP'), ('machine', 'NOUN'), ('learning', 'NOUN'), (':', 'PUNCT'), ('supervised', 'VERB'), ('learning', 'NOUN'), (',', 'PUNCT'), ('unsupervised', 'ADJ'), ('learning', 'NOUN'), (',', 'PUNCT'), ('and', 'CCONJ'), ('semi-supervised', 'VERB'), ('learning', 'NOUN'), ('.', 'PUNCT')] 

 XPOS tags are: 
>> [('There', 'EX'), ('are', 'VBP'), ('three', 'CD'), ('relevant', 'JJ'), ('classes', 'NNS'), ('of', 'IN'), ('machine', 'NN'), ('learning', 'NN'), (':', ':'), ('supervised', 'VBN'), ('learning', 'NN'), (',', ','), ('unsupervised', 'JJ'), ('learning', 'NN'), (',', ','), ('and', 'CC'), ('semi-supervised', 'VBN'), ('learning', 'NN'), ('.', '.')] 

 Lemmas are: 
>> [('There', 'there'), ('are', 'be'), ('three', 'three'), ('relevant', 'relevant'), ('classes', 'class'), ('of', 'of'), ('machine', 'machine'), ('learning', 'learning'), (':', ':'), ('supervised', 'supervise'), ('learning', 'learning'), (',', ','), ('unsupervised', 'unsupervised'), ('learning', 'learning'), (',', ','), ('and', 'and'), ('semi-supervised', 'semi-supervise'), ('learning', 'learning'), ('.', '.')] 

 Dependency tags are: 
>> [(('There', 'are'), 'expl'), (('are', 'root'), 'root'), (('three', 'classes'), 'nummod'), (('relevant', 'classes'), 'amod'), (('classes', 'are'), 'nsubj'), (('of', 'learning'), 'case'), (('machine', 'learning'), 'compound'), (('learning', 'classes'), 'nmod'), ((':', 'learning'), 'punct'), (('supervised', 'learning'), 'amod'), (('learning', 'classes'), 'appos'), ((',', 'learning'), 'punct'), (('unsupervised', 'learning'), 'amod'), (('learning', 'learning'), 'conj'), ((',', 'learning'), 'punct'), (('and', 'learning'), 'cc'), (('semi-supervised', 'learning'), 'amod'), (('learning', 'learning'), 'conj'), (('.', 'are'), 'punct')]

 Named Entites are: 
>> [('three', 'CARDINAL')]

------------------- Sentence 3 -------------------

 Lexalytics uses all  three depending on the problem we’re trying to solve. 

Tokens are: 
>> ['Lexalytics', 'uses', 'all', 'three', 'depending', 'on', 'the', 'problem', 'we', '’re', 'trying', 'to', 'solve', '.'] 

 UPOS tags are: 
>> [('Lexalytics', 'NOUN'), ('uses', 'VERB'), ('all', 'DET'), ('three', 'NUM'), ('depending', 'VERB'), ('on', 'ADP'), ('the', 'DET'), ('problem', 'NOUN'), ('we', 'PRON'), ('’re', 'AUX'), ('trying', 'VERB'), ('to', 'PART'), ('solve', 'VERB'), ('.', 'PUNCT')] 

 XPOS tags are: 
>> [('Lexalytics', 'NNS'), ('uses', 'VBZ'), ('all', 'DT'), ('three', 'CD'), ('depending', 'VBG'), ('on', 'IN'), ('the', 'DT'), ('problem', 'NN'), ('we', 'PRP'), ('’re', 'VBP'), ('trying', 'VBG'), ('to', 'TO'), ('solve', 'VB'), ('.', '.')] 

 Lemmas are: 
>> [('Lexalytics', 'lexalytics'), ('uses', 'use'), ('all', 'all'), ('three', 'three'), ('depending', 'depend'), ('on', 'on'), ('the', 'the'), ('problem', 'problem'), ('we', 'we'), ('’re', 'be'), ('trying', 'try'), ('to', 'to'), ('solve', 'solve'), ('.', '.')] 

 Dependency tags are: 
>> [(('Lexalytics', 'uses'), 'nsubj'), (('uses', 'root'), 'root'), (('all', 'three'), 'det'), (('three', 'uses'), 'obj'), (('depending', 'problem'), 'case'), (('on', 'depending'), 'fixed'), (('the', 'problem'), 'det'), (('problem', 'uses'), 'obl'), (('we', 'trying'), 'nsubj'), (('’re', 'trying'), 'aux'), (('trying', 'problem'), 'acl:relcl'), (('to', 'solve'), 'mark'), (('solve', 'trying'), 'xcomp'), (('.', 'uses'), 'punct')]

 Named Entites are: 
>> [('Lexalytics', 'ORG'), ('three', 'CARDINAL')]

================================ Paragraph 72 =================================

Supervised learning  


------------------- Sentence 1 -------------------

 Supervised learning 

Tokens are: 
>> ['Supervised', 'learning'] 

 UPOS tags are: 
>> [('Supervised', 'VERB'), ('learning', 'NOUN')] 

 XPOS tags are: 
>> [('Supervised', 'VBN'), ('learning', 'NN')] 

 Lemmas are: 
>> [('Supervised', 'supervise'), ('learning', 'learning')] 

 Dependency tags are: 
>> [(('Supervised', 'learning'), 'amod'), (('learning', 'root'), 'root')]

 Named Entites are: 
>> []

================================ Paragraph 73 =================================

Supervised learning means feeding a machine learning model a dataset   that has been annotated in some way. For example, we might collect 10,000  customer support comments and mark them up based on which are  related to software and which are related to hardware. In doing so, we’re  showing the machine what information it needs to evaluate each comment.  


------------------- Sentence 1 -------------------

 Supervised learning means feeding a machine learning model a dataset   that has been annotated in some way. 

Tokens are: 
>> ['Supervised', 'learning', 'means', 'feeding', 'a', 'machine', 'learning', 'model', 'a', 'dataset', 'that', 'has', 'been', 'annotated', 'in', 'some', 'way', '.'] 

 UPOS tags are: 
>> [('Supervised', 'VERB'), ('learning', 'NOUN'), ('means', 'VERB'), ('feeding', 'VERB'), ('a', 'DET'), ('machine', 'NOUN'), ('learning', 'NOUN'), ('model', 'NOUN'), ('a', 'DET'), ('dataset', 'NOUN'), ('that', 'PRON'), ('has', 'AUX'), ('been', 'AUX'), ('annotated', 'VERB'), ('in', 'ADP'), ('some', 'DET'), ('way', 'NOUN'), ('.', 'PUNCT')] 

 XPOS tags are: 
>> [('Supervised', 'VBN'), ('learning', 'NN'), ('means', 'VBZ'), ('feeding', 'VBG'), ('a', 'DT'), ('machine', 'NN'), ('learning', 'NN'), ('model', 'NN'), ('a', 'DT'), ('dataset', 'NN'), ('that', 'WDT'), ('has', 'VBZ'), ('been', 'VBN'), ('annotated', 'VBN'), ('in', 'IN'), ('some', 'DT'), ('way', 'NN'), ('.', '.')] 

 Lemmas are: 
>> [('Supervised', 'supervise'), ('learning', 'learning'), ('means', 'mean'), ('feeding', 'feed'), ('a', 'a'), ('machine', 'machine'), ('learning', 'learning'), ('model', 'model'), ('a', 'a'), ('dataset', 'dataset'), ('that', 'that'), ('has', 'have'), ('been', 'be'), ('annotated', 'annotate'), ('in', 'in'), ('some', 'some'), ('way', 'way'), ('.', '.')] 

 Dependency tags are: 
>> [(('Supervised', 'learning'), 'amod'), (('learning', 'means'), 'nsubj'), (('means', 'root'), 'root'), (('feeding', 'means'), 'xcomp'), (('a', 'model'), 'det'), (('machine', 'model'), 'compound'), (('learning', 'model'), 'compound'), (('model', 'feeding'), 'obj'), (('a', 'dataset'), 'det'), (('dataset', 'feeding'), 'obj'), (('that', 'annotated'), 'nsubj:pass'), (('has', 'annotated'), 'aux'), (('been', 'annotated'), 'aux:pass'), (('annotated', 'dataset'), 'acl:relcl'), (('in', 'way'), 'case'), (('some', 'way'), 'det'), (('way', 'annotated'), 'obl'), (('.', 'means'), 'punct')]

 Named Entites are: 
>> []

------------------- Sentence 2 -------------------

 For example, we might collect 10,000  customer support comments and mark them up based on which are  related to software and which are related to hardware. 

Tokens are: 
>> ['For', 'example', ',', 'we', 'might', 'collect', '10,000', 'customer', 'support', 'comments', 'and', 'mark', 'them', 'up', 'based', 'on', 'which', 'are', 'related', 'to', 'software', 'and', 'which', 'are', 'related', 'to', 'hardware', '.'] 

 UPOS tags are: 
>> [('For', 'ADP'), ('example', 'NOUN'), (',', 'PUNCT'), ('we', 'PRON'), ('might', 'AUX'), ('collect', 'VERB'), ('10,000', 'NUM'), ('customer', 'NOUN'), ('support', 'NOUN'), ('comments', 'NOUN'), ('and', 'CCONJ'), ('mark', 'VERB'), ('them', 'PRON'), ('up', 'ADP'), ('based', 'VERB'), ('on', 'ADP'), ('which', 'PRON'), ('are', 'AUX'), ('related', 'ADJ'), ('to', 'ADP'), ('software', 'NOUN'), ('and', 'CCONJ'), ('which', 'PRON'), ('are', 'AUX'), ('related', 'ADJ'), ('to', 'ADP'), ('hardware', 'NOUN'), ('.', 'PUNCT')] 

 XPOS tags are: 
>> [('For', 'IN'), ('example', 'NN'), (',', ','), ('we', 'PRP'), ('might', 'MD'), ('collect', 'VB'), ('10,000', 'CD'), ('customer', 'NN'), ('support', 'NN'), ('comments', 'NNS'), ('and', 'CC'), ('mark', 'VB'), ('them', 'PRP'), ('up', 'RP'), ('based', 'VBN'), ('on', 'IN'), ('which', 'WDT'), ('are', 'VBP'), ('related', 'JJ'), ('to', 'IN'), ('software', 'NN'), ('and', 'CC'), ('which', 'WDT'), ('are', 'VBP'), ('related', 'JJ'), ('to', 'IN'), ('hardware', 'NN'), ('.', '.')] 

 Lemmas are: 
>> [('For', 'for'), ('example', 'example'), (',', ','), ('we', 'we'), ('might', 'might'), ('collect', 'collect'), ('10,000', '10000'), ('customer', 'customer'), ('support', 'support'), ('comments', 'comment'), ('and', 'and'), ('mark', 'mark'), ('them', 'they'), ('up', 'up'), ('based', 'base'), ('on', 'on'), ('which', 'which'), ('are', 'be'), ('related', 'related'), ('to', 'to'), ('software', 'software'), ('and', 'and'), ('which', 'which'), ('are', 'be'), ('related', 'related'), ('to', 'to'), ('hardware', 'hardware'), ('.', '.')] 

 Dependency tags are: 
>> [(('For', 'example'), 'case'), (('example', 'collect'), 'obl'), ((',', 'collect'), 'punct'), (('we', 'collect'), 'nsubj'), (('might', 'collect'), 'aux'), (('collect', 'root'), 'root'), (('10,000', 'comments'), 'nummod'), (('customer', 'support'), 'compound'), (('support', 'comments'), 'compound'), (('comments', 'collect'), 'obj'), (('and', 'mark'), 'cc'), (('mark', 'collect'), 'conj'), (('them', 'mark'), 'obj'), (('up', 'mark'), 'compound:prt'), (('based', 'related'), 'mark'), (('on', 'which'), 'case'), (('which', 'related'), 'obl'), (('are', 'related'), 'cop'), (('related', 'mark'), 'acl:relcl'), (('to', 'software'), 'case'), (('software', 'related'), 'obl'), (('and', 'related'), 'cc'), (('which', 'related'), 'nsubj'), (('are', 'related'), 'cop'), (('related', 'related'), 'conj'), (('to', 'hardware'), 'case'), (('hardware', 'related'), 'obl'), (('.', 'collect'), 'punct')]

 Named Entites are: 
>> [('10,000', 'CARDINAL')]

------------------- Sentence 3 -------------------

 In doing so, we’re  showing the machine what information it needs to evaluate each comment. 

Tokens are: 
>> ['In', 'doing', 'so', ',', 'we', '’re', 'showing', 'the', 'machine', 'what', 'information', 'it', 'needs', 'to', 'evaluate', 'each', 'comment', '.'] 

 UPOS tags are: 
>> [('In', 'SCONJ'), ('doing', 'VERB'), ('so', 'ADV'), (',', 'PUNCT'), ('we', 'PRON'), ('’re', 'AUX'), ('showing', 'VERB'), ('the', 'DET'), ('machine', 'NOUN'), ('what', 'DET'), ('information', 'NOUN'), ('it', 'PRON'), ('needs', 'VERB'), ('to', 'PART'), ('evaluate', 'VERB'), ('each', 'DET'), ('comment', 'NOUN'), ('.', 'PUNCT')] 

 XPOS tags are: 
>> [('In', 'IN'), ('doing', 'VBG'), ('so', 'RB'), (',', ','), ('we', 'PRP'), ('’re', 'VBP'), ('showing', 'VBG'), ('the', 'DT'), ('machine', 'NN'), ('what', 'WDT'), ('information', 'NN'), ('it', 'PRP'), ('needs', 'VBZ'), ('to', 'TO'), ('evaluate', 'VB'), ('each', 'DT'), ('comment', 'NN'), ('.', '.')] 

 Lemmas are: 
>> [('In', 'in'), ('doing', 'do'), ('so', 'so'), (',', ','), ('we', 'we'), ('’re', 'be'), ('showing', 'show'), ('the', 'the'), ('machine', 'machine'), ('what', 'what'), ('information', 'information'), ('it', 'it'), ('needs', 'need'), ('to', 'to'), ('evaluate', 'evaluate'), ('each', 'each'), ('comment', 'comment'), ('.', '.')] 

 Dependency tags are: 
>> [(('In', 'doing'), 'mark'), (('doing', 'showing'), 'advcl'), (('so', 'doing'), 'advmod'), ((',', 'showing'), 'punct'), (('we', 'showing'), 'nsubj'), (('’re', 'showing'), 'aux'), (('showing', 'root'), 'root'), (('the', 'machine'), 'det'), (('machine', 'showing'), 'obj'), (('what', 'information'), 'det'), (('information', 'needs'), 'obj'), (('it', 'needs'), 'nsubj'), (('needs', 'machine'), 'acl:relcl'), (('to', 'evaluate'), 'mark'), (('evaluate', 'needs'), 'xcomp'), (('each', 'comment'), 'det'), (('comment', 'evaluate'), 'obj'), (('.', 'showing'), 'punct')]

 Named Entites are: 
>> []

================================ Paragraph 74 =================================

This is the most direct way of teaching a model what you want it to do. It’s  also the most work. At Lexalytics, we use supervised learning for NLP tasks  like sentiment analysis and for certain methods of categorization.  


------------------- Sentence 1 -------------------

 This is the most direct way of teaching a model what you want it to do. 

Tokens are: 
>> ['This', 'is', 'the', 'most', 'direct', 'way', 'of', 'teaching', 'a', 'model', 'what', 'you', 'want', 'it', 'to', 'do', '.'] 

 UPOS tags are: 
>> [('This', 'PRON'), ('is', 'AUX'), ('the', 'DET'), ('most', 'ADV'), ('direct', 'ADJ'), ('way', 'NOUN'), ('of', 'SCONJ'), ('teaching', 'VERB'), ('a', 'DET'), ('model', 'NOUN'), ('what', 'PRON'), ('you', 'PRON'), ('want', 'VERB'), ('it', 'PRON'), ('to', 'PART'), ('do', 'VERB'), ('.', 'PUNCT')] 

 XPOS tags are: 
>> [('This', 'DT'), ('is', 'VBZ'), ('the', 'DT'), ('most', 'RBS'), ('direct', 'JJ'), ('way', 'NN'), ('of', 'IN'), ('teaching', 'VBG'), ('a', 'DT'), ('model', 'NN'), ('what', 'WP'), ('you', 'PRP'), ('want', 'VBP'), ('it', 'PRP'), ('to', 'TO'), ('do', 'VB'), ('.', '.')] 

 Lemmas are: 
>> [('This', 'this'), ('is', 'be'), ('the', 'the'), ('most', 'most'), ('direct', 'direct'), ('way', 'way'), ('of', 'of'), ('teaching', 'teach'), ('a', 'a'), ('model', 'model'), ('what', 'what'), ('you', 'you'), ('want', 'want'), ('it', 'it'), ('to', 'to'), ('do', 'do'), ('.', '.')] 

 Dependency tags are: 
>> [(('This', 'way'), 'nsubj'), (('is', 'way'), 'cop'), (('the', 'way'), 'det'), (('most', 'direct'), 'advmod'), (('direct', 'way'), 'amod'), (('way', 'root'), 'root'), (('of', 'teaching'), 'mark'), (('teaching', 'way'), 'acl'), (('a', 'model'), 'det'), (('model', 'teaching'), 'obj'), (('what', 'want'), 'obj'), (('you', 'want'), 'nsubj'), (('want', 'model'), 'acl:relcl'), (('it', 'want'), 'obj'), (('to', 'do'), 'mark'), (('do', 'want'), 'xcomp'), (('.', 'way'), 'punct')]

 Named Entites are: 
>> []

------------------- Sentence 2 -------------------

 It’s  also the most work. 

Tokens are: 
>> ['It', '’s', 'also', 'the', 'most', 'work', '.'] 

 UPOS tags are: 
>> [('It', 'PRON'), ('’s', 'AUX'), ('also', 'ADV'), ('the', 'DET'), ('most', 'ADJ'), ('work', 'NOUN'), ('.', 'PUNCT')] 

 XPOS tags are: 
>> [('It', 'PRP'), ('’s', 'VBZ'), ('also', 'RB'), ('the', 'DT'), ('most', 'JJS'), ('work', 'NN'), ('.', '.')] 

 Lemmas are: 
>> [('It', 'it'), ('’s', 'be'), ('also', 'also'), ('the', 'the'), ('most', 'most'), ('work', 'work'), ('.', '.')] 

 Dependency tags are: 
>> [(('It', 'work'), 'nsubj'), (('’s', 'work'), 'cop'), (('also', 'work'), 'advmod'), (('the', 'work'), 'det'), (('most', 'work'), 'amod'), (('work', 'root'), 'root'), (('.', 'work'), 'punct')]

 Named Entites are: 
>> []

------------------- Sentence 3 -------------------

 At Lexalytics, we use supervised learning for NLP tasks  like sentiment analysis and for certain methods of categorization. 

Tokens are: 
>> ['At', 'Lexalytics', ',', 'we', 'use', 'supervised', 'learning', 'for', 'NLP', 'tasks', 'like', 'sentiment', 'analysis', 'and', 'for', 'certain', 'methods', 'of', 'categorization', '.'] 

 UPOS tags are: 
>> [('At', 'ADP'), ('Lexalytics', 'PROPN'), (',', 'PUNCT'), ('we', 'PRON'), ('use', 'VERB'), ('supervised', 'VERB'), ('learning', 'NOUN'), ('for', 'ADP'), ('NLP', 'NOUN'), ('tasks', 'NOUN'), ('like', 'ADP'), ('sentiment', 'NOUN'), ('analysis', 'NOUN'), ('and', 'CCONJ'), ('for', 'ADP'), ('certain', 'ADJ'), ('methods', 'NOUN'), ('of', 'ADP'), ('categorization', 'NOUN'), ('.', 'PUNCT')] 

 XPOS tags are: 
>> [('At', 'IN'), ('Lexalytics', 'NNPS'), (',', ','), ('we', 'PRP'), ('use', 'VBP'), ('supervised', 'VBN'), ('learning', 'NN'), ('for', 'IN'), ('NLP', 'NN'), ('tasks', 'NNS'), ('like', 'IN'), ('sentiment', 'NN'), ('analysis', 'NN'), ('and', 'CC'), ('for', 'IN'), ('certain', 'JJ'), ('methods', 'NNS'), ('of', 'IN'), ('categorization', 'NN'), ('.', '.')] 

 Lemmas are: 
>> [('At', 'at'), ('Lexalytics', 'Lexalytics'), (',', ','), ('we', 'we'), ('use', 'use'), ('supervised', 'supervise'), ('learning', 'learning'), ('for', 'for'), ('NLP', 'nlp'), ('tasks', 'task'), ('like', 'like'), ('sentiment', 'sentiment'), ('analysis', 'analysis'), ('and', 'and'), ('for', 'for'), ('certain', 'certain'), ('methods', 'method'), ('of', 'of'), ('categorization', 'categorization'), ('.', '.')] 

 Dependency tags are: 
>> [(('At', 'Lexalytics'), 'case'), (('Lexalytics', 'use'), 'obl'), ((',', 'use'), 'punct'), (('we', 'use'), 'nsubj'), (('use', 'root'), 'root'), (('supervised', 'learning'), 'amod'), (('learning', 'use'), 'obj'), (('for', 'tasks'), 'case'), (('NLP', 'tasks'), 'compound'), (('tasks', 'learning'), 'nmod'), (('like', 'analysis'), 'case'), (('sentiment', 'analysis'), 'compound'), (('analysis', 'tasks'), 'nmod'), (('and', 'methods'), 'cc'), (('for', 'methods'), 'case'), (('certain', 'methods'), 'amod'), (('methods', 'analysis'), 'conj'), (('of', 'categorization'), 'case'), (('categorization', 'methods'), 'nmod'), (('.', 'use'), 'punct')]

 Named Entites are: 
>> [('Lexalytics', 'ORG')]

================================ Paragraph 75 =================================

For example, we train sentiment analysis models on hand-scored examples  because the perspective of the sentiment analysis can change based on  context. Consider the following: 


------------------- Sentence 1 -------------------

 For example, we train sentiment analysis models on hand-scored examples  because the perspective of the sentiment analysis can change based on  context. 

Tokens are: 
>> ['For', 'example', ',', 'we', 'train', 'sentiment', 'analysis', 'models', 'on', 'hand', '-', 'scored', 'examples', 'because', 'the', 'perspective', 'of', 'the', 'sentiment', 'analysis', 'can', 'change', 'based', 'on', 'context', '.'] 

 UPOS tags are: 
>> [('For', 'ADP'), ('example', 'NOUN'), (',', 'PUNCT'), ('we', 'PRON'), ('train', 'VERB'), ('sentiment', 'NOUN'), ('analysis', 'NOUN'), ('models', 'NOUN'), ('on', 'ADP'), ('hand', 'NOUN'), ('-', 'PUNCT'), ('scored', 'VERB'), ('examples', 'NOUN'), ('because', 'SCONJ'), ('the', 'DET'), ('perspective', 'NOUN'), ('of', 'ADP'), ('the', 'DET'), ('sentiment', 'NOUN'), ('analysis', 'NOUN'), ('can', 'AUX'), ('change', 'VERB'), ('based', 'VERB'), ('on', 'ADP'), ('context', 'NOUN'), ('.', 'PUNCT')] 

 XPOS tags are: 
>> [('For', 'IN'), ('example', 'NN'), (',', ','), ('we', 'PRP'), ('train', 'VBP'), ('sentiment', 'NN'), ('analysis', 'NN'), ('models', 'NNS'), ('on', 'IN'), ('hand', 'NN'), ('-', 'HYPH'), ('scored', 'VBN'), ('examples', 'NNS'), ('because', 'IN'), ('the', 'DT'), ('perspective', 'NN'), ('of', 'IN'), ('the', 'DT'), ('sentiment', 'NN'), ('analysis', 'NN'), ('can', 'MD'), ('change', 'VB'), ('based', 'VBN'), ('on', 'IN'), ('context', 'NN'), ('.', '.')] 

 Lemmas are: 
>> [('For', 'for'), ('example', 'example'), (',', ','), ('we', 'we'), ('train', 'train'), ('sentiment', 'sentiment'), ('analysis', 'analysis'), ('models', 'model'), ('on', 'on'), ('hand', 'hand'), ('-', '-'), ('scored', 'score'), ('examples', 'example'), ('because', 'because'), ('the', 'the'), ('perspective', 'perspective'), ('of', 'of'), ('the', 'the'), ('sentiment', 'sentiment'), ('analysis', 'analysis'), ('can', 'can'), ('change', 'change'), ('based', 'base'), ('on', 'on'), ('context', 'context'), ('.', '.')] 

 Dependency tags are: 
>> [(('For', 'example'), 'case'), (('example', 'train'), 'obl'), ((',', 'example'), 'punct'), (('we', 'train'), 'nsubj'), (('train', 'root'), 'root'), (('sentiment', 'analysis'), 'compound'), (('analysis', 'models'), 'compound'), (('models', 'train'), 'obj'), (('on', 'examples'), 'case'), (('hand', 'scored'), 'compound'), (('-', 'scored'), 'punct'), (('scored', 'examples'), 'amod'), (('examples', 'train'), 'obl'), (('because', 'change'), 'mark'), (('the', 'perspective'), 'det'), (('perspective', 'change'), 'nsubj'), (('of', 'analysis'), 'case'), (('the', 'analysis'), 'det'), (('sentiment', 'analysis'), 'compound'), (('analysis', 'perspective'), 'nmod'), (('can', 'change'), 'aux'), (('change', 'train'), 'advcl'), (('based', 'change'), 'advcl'), (('on', 'context'), 'case'), (('context', 'based'), 'obl'), (('.', 'train'), 'punct')]

 Named Entites are: 
>> []

------------------- Sentence 2 -------------------

 Consider the following: 

Tokens are: 
>> ['Consider', 'the', 'following', ':'] 

 UPOS tags are: 
>> [('Consider', 'VERB'), ('the', 'DET'), ('following', 'VERB'), (':', 'PUNCT')] 

 XPOS tags are: 
>> [('Consider', 'VB'), ('the', 'DT'), ('following', 'VBG'), (':', ':')] 

 Lemmas are: 
>> [('Consider', 'consider'), ('the', 'the'), ('following', 'follow'), (':', ':')] 

 Dependency tags are: 
>> [(('Consider', 'root'), 'root'), (('the', 'Consider'), 'obj'), (('following', 'Consider'), 'obj'), ((':', 'Consider'), 'punct')]

 Named Entites are: 
>> []

================================ Paragraph 76 =================================

“SuperBank lost US$100,000,000 last month.” 


------------------- Sentence 1 -------------------

 “Super 

Tokens are: 
>> ['“', 'Super'] 

 UPOS tags are: 
>> [('“', 'PUNCT'), ('Super', 'ADV')] 

 XPOS tags are: 
>> [('“', '``'), ('Super', 'RB')] 

 Lemmas are: 
>> [('“', "''"), ('Super', 'super')] 

 Dependency tags are: 
>> [(('“', 'Super'), 'punct'), (('Super', 'root'), 'root')]

 Named Entites are: 
>> []

------------------- Sentence 2 -------------------

 Bank lost US$100,000,000 last month.” 

Tokens are: 
>> ['Bank', 'lost', 'US', '$', '100,000,000', 'last', 'month', '.', '”'] 

 UPOS tags are: 
>> [('Bank', 'NOUN'), ('lost', 'VERB'), ('US', 'PROPN'), ('$', 'SYM'), ('100,000,000', 'NUM'), ('last', 'ADJ'), ('month', 'NOUN'), ('.', 'PUNCT'), ('”', 'PUNCT')] 

 XPOS tags are: 
>> [('Bank', 'NN'), ('lost', 'VBD'), ('US', 'NNP'), ('$', '$'), ('100,000,000', 'CD'), ('last', 'JJ'), ('month', 'NN'), ('.', '.'), ('”', "''")] 

 Lemmas are: 
>> [('Bank', 'bank'), ('lost', 'lose'), ('US', 'US'), ('$', '$'), ('100,000,000', '10000000'), ('last', 'last'), ('month', 'month'), ('.', '.'), ('”', "''")] 

 Dependency tags are: 
>> [(('Bank', 'lost'), 'nsubj'), (('lost', 'root'), 'root'), (('US', '$'), 'compound'), (('$', 'lost'), 'obj'), (('100,000,000', '$'), 'nummod'), (('last', 'month'), 'amod'), (('month', 'lost'), 'obl:tmod'), (('.', 'lost'), 'punct'), (('”', 'lost'), 'punct')]

 Named Entites are: 
>> [('Bank', 'ORG'), ('US', 'GPE'), ('100,000,000', 'MONEY'), ('last month', 'DATE')]

================================ Paragraph 77 =================================

Well, were they expected to lose US$200,000,000? US$50,000,000? The  sentiment of this statement very much depends on who is looking at it.  


------------------- Sentence 1 -------------------

 Well, were they expected to lose US$200,000,000? 

Tokens are: 
>> ['Well', ',', 'were', 'they', 'expected', 'to', 'lose', 'US', '$', '200,000,000', '?'] 

 UPOS tags are: 
>> [('Well', 'INTJ'), (',', 'PUNCT'), ('were', 'AUX'), ('they', 'PRON'), ('expected', 'VERB'), ('to', 'PART'), ('lose', 'VERB'), ('US', 'PROPN'), ('$', 'SYM'), ('200,000,000', 'NUM'), ('?', 'PUNCT')] 

 XPOS tags are: 
>> [('Well', 'UH'), (',', ','), ('were', 'VBD'), ('they', 'PRP'), ('expected', 'VBN'), ('to', 'TO'), ('lose', 'VB'), ('US', 'NNP'), ('$', '$'), ('200,000,000', 'CD'), ('?', '.')] 

 Lemmas are: 
>> [('Well', 'well'), (',', ','), ('were', 'be'), ('they', 'they'), ('expected', 'expect'), ('to', 'to'), ('lose', 'lose'), ('US', 'US'), ('$', '$'), ('200,000,000', '20000000'), ('?', '?')] 

 Dependency tags are: 
>> [(('Well', 'expected'), 'discourse'), ((',', 'expected'), 'punct'), (('were', 'expected'), 'aux'), (('they', 'expected'), 'nsubj'), (('expected', 'root'), 'root'), (('to', 'lose'), 'mark'), (('lose', 'expected'), 'xcomp'), (('US', '$'), 'compound'), (('$', 'lose'), 'obj'), (('200,000,000', '$'), 'nummod'), (('?', 'expected'), 'punct')]

 Named Entites are: 
>> [('US$200,000,000', 'MONEY')]

------------------- Sentence 2 -------------------

 US$50,000,000? 

Tokens are: 
>> ['US', '$', '50,000,000', '?'] 

 UPOS tags are: 
>> [('US', 'PROPN'), ('$', 'SYM'), ('50,000,000', 'NUM'), ('?', 'PUNCT')] 

 XPOS tags are: 
>> [('US', 'NNP'), ('$', '$'), ('50,000,000', 'CD'), ('?', '.')] 

 Lemmas are: 
>> [('US', 'US'), ('$', '$'), ('50,000,000', '5000000'), ('?', '?')] 

 Dependency tags are: 
>> [(('US', '$'), 'compound'), (('$', 'root'), 'root'), (('50,000,000', '$'), 'nummod'), (('?', '$'), 'punct')]

 Named Entites are: 
>> [('US', 'GPE'), ('50,000,000', 'MONEY')]

------------------- Sentence 3 -------------------

 The  sentiment of this statement very much depends on who is looking at it. 

Tokens are: 
>> ['The', 'sentiment', 'of', 'this', 'statement', 'very', 'much', 'depends', 'on', 'who', 'is', 'looking', 'at', 'it', '.'] 

 UPOS tags are: 
>> [('The', 'DET'), ('sentiment', 'NOUN'), ('of', 'ADP'), ('this', 'DET'), ('statement', 'NOUN'), ('very', 'ADV'), ('much', 'ADV'), ('depends', 'VERB'), ('on', 'ADP'), ('who', 'PRON'), ('is', 'AUX'), ('looking', 'VERB'), ('at', 'ADP'), ('it', 'PRON'), ('.', 'PUNCT')] 

 XPOS tags are: 
>> [('The', 'DT'), ('sentiment', 'NN'), ('of', 'IN'), ('this', 'DT'), ('statement', 'NN'), ('very', 'RB'), ('much', 'RB'), ('depends', 'VBZ'), ('on', 'IN'), ('who', 'WP'), ('is', 'VBZ'), ('looking', 'VBG'), ('at', 'IN'), ('it', 'PRP'), ('.', '.')] 

 Lemmas are: 
>> [('The', 'the'), ('sentiment', 'sentiment'), ('of', 'of'), ('this', 'this'), ('statement', 'statement'), ('very', 'very'), ('much', 'much'), ('depends', 'depend'), ('on', 'on'), ('who', 'who'), ('is', 'be'), ('looking', 'look'), ('at', 'at'), ('it', 'it'), ('.', '.')] 

 Dependency tags are: 
>> [(('The', 'sentiment'), 'det'), (('sentiment', 'depends'), 'nsubj'), (('of', 'statement'), 'case'), (('this', 'statement'), 'det'), (('statement', 'sentiment'), 'nmod'), (('very', 'much'), 'advmod'), (('much', 'depends'), 'advmod'), (('depends', 'root'), 'root'), (('on', 'who'), 'case'), (('who', 'looking'), 'nsubj'), (('is', 'looking'), 'aux'), (('looking', 'depends'), 'ccomp'), (('at', 'it'), 'case'), (('it', 'looking'), 'obl'), (('.', 'depends'), 'punct')]

 Named Entites are: 
>> []

================================ Paragraph 78 =================================

Another example would be “This perfume smells like my grandmother.”   Do you love your grandmother?  


------------------- Sentence 1 -------------------

 Another example would be “This perfume smells like my grandmother.” 

Tokens are: 
>> ['Another', 'example', 'would', 'be', '“', 'This', 'perfume', 'smells', 'like', 'my', 'grandmother', '.', '”'] 

 UPOS tags are: 
>> [('Another', 'DET'), ('example', 'NOUN'), ('would', 'AUX'), ('be', 'AUX'), ('“', 'PUNCT'), ('This', 'DET'), ('perfume', 'NOUN'), ('smells', 'VERB'), ('like', 'ADP'), ('my', 'PRON'), ('grandmother', 'NOUN'), ('.', 'PUNCT'), ('”', 'PUNCT')] 

 XPOS tags are: 
>> [('Another', 'DT'), ('example', 'NN'), ('would', 'MD'), ('be', 'VB'), ('“', '``'), ('This', 'DT'), ('perfume', 'NN'), ('smells', 'VBZ'), ('like', 'IN'), ('my', 'PRP$'), ('grandmother', 'NN'), ('.', '.'), ('”', "''")] 

 Lemmas are: 
>> [('Another', 'another'), ('example', 'example'), ('would', 'would'), ('be', 'be'), ('“', "''"), ('This', 'this'), ('perfume', 'perfume'), ('smells', 'smell'), ('like', 'like'), ('my', 'my'), ('grandmother', 'grandmother'), ('.', '.'), ('”', "''")] 

 Dependency tags are: 
>> [(('Another', 'example'), 'det'), (('example', 'be'), 'nsubj'), (('would', 'be'), 'aux'), (('be', 'root'), 'root'), (('“', 'smells'), 'punct'), (('This', 'perfume'), 'det'), (('perfume', 'smells'), 'nsubj'), (('smells', 'be'), 'ccomp'), (('like', 'grandmother'), 'case'), (('my', 'grandmother'), 'nmod:poss'), (('grandmother', 'smells'), 'obl'), (('.', 'smells'), 'punct'), (('”', 'smells'), 'punct')]

 Named Entites are: 
>> []

------------------- Sentence 2 -------------------

 Do you love your grandmother? 

Tokens are: 
>> ['Do', 'you', 'love', 'your', 'grandmother', '?'] 

 UPOS tags are: 
>> [('Do', 'AUX'), ('you', 'PRON'), ('love', 'VERB'), ('your', 'PRON'), ('grandmother', 'NOUN'), ('?', 'PUNCT')] 

 XPOS tags are: 
>> [('Do', 'VBP'), ('you', 'PRP'), ('love', 'VB'), ('your', 'PRP$'), ('grandmother', 'NN'), ('?', '.')] 

 Lemmas are: 
>> [('Do', 'do'), ('you', 'you'), ('love', 'love'), ('your', 'you'), ('grandmother', 'grandmother'), ('?', '?')] 

 Dependency tags are: 
>> [(('Do', 'love'), 'aux'), (('you', 'love'), 'nsubj'), (('love', 'root'), 'root'), (('your', 'grandmother'), 'nmod:poss'), (('grandmother', 'love'), 'obj'), (('?', 'love'), 'punct')]

 Named Entites are: 
>> []

================================ Paragraph 79 =================================

Ultimately, any extraction that requires that the machine understand   your perspective needs to be supervised somehow, and this requires   lots of work.


------------------- Sentence 1 -------------------

 Ultimately, any extraction that requires that the machine understand   your perspective needs to be supervised somehow, and this requires   lots of work. 

Tokens are: 
>> ['Ultimately', ',', 'any', 'extraction', 'that', 'requires', 'that', 'the', 'machine', 'understand', 'your', 'perspective', 'needs', 'to', 'be', 'supervised', 'somehow', ',', 'and', 'this', 'requires', 'lots', 'of', 'work', '.'] 

 UPOS tags are: 
>> [('Ultimately', 'ADV'), (',', 'PUNCT'), ('any', 'DET'), ('extraction', 'NOUN'), ('that', 'PRON'), ('requires', 'VERB'), ('that', 'SCONJ'), ('the', 'DET'), ('machine', 'NOUN'), ('understand', 'VERB'), ('your', 'PRON'), ('perspective', 'NOUN'), ('needs', 'VERB'), ('to', 'PART'), ('be', 'AUX'), ('supervised', 'VERB'), ('somehow', 'ADV'), (',', 'PUNCT'), ('and', 'CCONJ'), ('this', 'PRON'), ('requires', 'VERB'), ('lots', 'NOUN'), ('of', 'ADP'), ('work', 'NOUN'), ('.', 'PUNCT')] 

 XPOS tags are: 
>> [('Ultimately', 'RB'), (',', ','), ('any', 'DT'), ('extraction', 'NN'), ('that', 'WDT'), ('requires', 'VBZ'), ('that', 'IN'), ('the', 'DT'), ('machine', 'NN'), ('understand', 'VB'), ('your', 'PRP$'), ('perspective', 'NN'), ('needs', 'VBZ'), ('to', 'TO'), ('be', 'VB'), ('supervised', 'VBN'), ('somehow', 'RB'), (',', ','), ('and', 'CC'), ('this', 'DT'), ('requires', 'VBZ'), ('lots', 'NNS'), ('of', 'IN'), ('work', 'NN'), ('.', '.')] 

 Lemmas are: 
>> [('Ultimately', 'ultimately'), (',', ','), ('any', 'any'), ('extraction', 'extraction'), ('that', 'that'), ('requires', 'require'), ('that', 'that'), ('the', 'the'), ('machine', 'machine'), ('understand', 'understand'), ('your', 'you'), ('perspective', 'perspective'), ('needs', 'need'), ('to', 'to'), ('be', 'be'), ('supervised', 'supervise'), ('somehow', 'somehow'), (',', ','), ('and', 'and'), ('this', 'this'), ('requires', 'require'), ('lots', 'lot'), ('of', 'of'), ('work', 'work'), ('.', '.')] 

 Dependency tags are: 
>> [(('Ultimately', 'needs'), 'advmod'), ((',', 'Ultimately'), 'punct'), (('any', 'extraction'), 'det'), (('extraction', 'needs'), 'nsubj'), (('that', 'requires'), 'nsubj'), (('requires', 'extraction'), 'acl:relcl'), (('that', 'understand'), 'mark'), (('the', 'machine'), 'det'), (('machine', 'understand'), 'nsubj'), (('understand', 'requires'), 'ccomp'), (('your', 'perspective'), 'nmod:poss'), (('perspective', 'understand'), 'obj'), (('needs', 'root'), 'root'), (('to', 'supervised'), 'mark'), (('be', 'supervised'), 'aux:pass'), (('supervised', 'needs'), 'xcomp'), (('somehow', 'supervised'), 'advmod'), ((',', 'requires'), 'punct'), (('and', 'requires'), 'cc'), (('this', 'requires'), 'nsubj'), (('requires', 'needs'), 'conj'), (('lots', 'requires'), 'obj'), (('of', 'work'), 'case'), (('work', 'lots'), 'nmod'), (('.', 'needs'), 'punct')]

 Named Entites are: 
>> []

================================ Paragraph 80 =================================

W H I T E  P A P E R 


------------------- Sentence 1 -------------------

 W H I T E  P A P E R 

Tokens are: 
>> ['W', 'H', 'I', 'T', 'E', 'P', 'A', 'P', 'E', 'R'] 

 UPOS tags are: 
>> [('W', 'PROPN'), ('H', 'PUNCT'), ('I', 'PRON'), ('T', 'AUX'), ('E', 'PROPN'), ('P', 'NOUN'), ('A', 'NOUN'), ('P', 'NOUN'), ('E', 'NOUN'), ('R', 'NOUN')] 

 XPOS tags are: 
>> [('W', 'NNP'), ('H', ','), ('I', 'PRP'), ('T', 'VBP'), ('E', 'NNP'), ('P', 'NN'), ('A', 'NN'), ('P', 'NN'), ('E', 'NN'), ('R', 'NN')] 

 Lemmas are: 
>> [('W', 'W'), ('H', 'H'), ('I', 'I'), ('T', 'T'), ('E', 'E'), ('P', 'p'), ('A', 'a'), ('P', 'p'), ('E', 'e'), ('R', 'R')] 

 Dependency tags are: 
>> [(('W', 'T'), 'vocative'), (('H', 'W'), 'punct'), (('I', 'T'), 'nsubj'), (('T', 'root'), 'root'), (('E', 'T'), 'obj'), (('P', 'T'), 'obj'), (('A', 'E'), 'compound'), (('P', 'E'), 'compound'), (('E', 'R'), 'compound'), (('R', 'T'), 'obj')]

 Named Entites are: 
>> []

================================ Paragraph 81 =================================

6|       |   Lexalytics, Inc., 48 North Pleasant St. Unit 301, Amherst MA 01002 USA   |   1-800-377-8036 |   www.lexalytics.com 


------------------- Sentence 1 -------------------

 6|       |   Lexalytics, Inc., 48 North Pleasant St. Unit 301, Amherst MA 01002 USA   |   1-800-377-8036 |   www.lexalytics.com 

Tokens are: 
>> ['6', '|', '|', 'Lexalytics', ',', 'Inc.', ',', '48', 'North', 'Pleasant', 'St.', 'Unit', '301', ',', 'Amherst', 'MA', '01002', 'USA', '|', '1-800-377-8036', '|', 'www.lexalytics.com'] 

 UPOS tags are: 
>> [('6', 'NUM'), ('|', 'PUNCT'), ('|', 'PUNCT'), ('Lexalytics', 'PROPN'), (',', 'PUNCT'), ('Inc.', 'PROPN'), (',', 'PUNCT'), ('48', 'NUM'), ('North', 'PROPN'), ('Pleasant', 'ADJ'), ('St.', 'PROPN'), ('Unit', 'NOUN'), ('301', 'NUM'), (',', 'PUNCT'), ('Amherst', 'PROPN'), ('MA', 'PROPN'), ('01002', 'NUM'), ('USA', 'PROPN'), ('|', 'PUNCT'), ('1-800-377-8036', 'NUM'), ('|', 'PUNCT'), ('www.lexalytics.com', 'X')] 

 XPOS tags are: 
>> [('6', 'LS'), ('|', 'NFP'), ('|', 'NFP'), ('Lexalytics', 'NNP'), (',', ','), ('Inc.', 'NNP'), (',', ','), ('48', 'CD'), ('North', 'NNP'), ('Pleasant', 'NNP'), ('St.', 'NNP'), ('Unit', 'NN'), ('301', 'CD'), (',', ','), ('Amherst', 'NNP'), ('MA', 'NNP'), ('01002', 'CD'), ('USA', 'NNP'), ('|', 'NFP'), ('1-800-377-8036', 'CD'), ('|', 'NFP'), ('www.lexalytics.com', 'ADD')] 

 Lemmas are: 
>> [('6', '6'), ('|', '|'), ('|', '|'), ('Lexalytics', 'Lexalytics'), (',', ','), ('Inc.', 'Inc.'), (',', ','), ('48', '48'), ('North', 'North'), ('Pleasant', 'Pleasant'), ('St.', 'St.'), ('Unit', 'unit'), ('301', '301'), (',', ','), ('Amherst', 'Amherst'), ('MA', 'MA'), ('01002', '01002'), ('USA', 'USA'), ('|', '|'), ('1-800-377-8036', '1-800-377-8036'), ('|', '|'), ('www.lexalytics.com', 'www.lexalytics.com')] 

 Dependency tags are: 
>> [(('6', 'Inc.'), 'nummod'), (('|', '6'), 'punct'), (('|', '6'), 'punct'), (('Lexalytics', 'Inc.'), 'compound'), ((',', 'Inc.'), 'punct'), (('Inc.', 'root'), 'root'), ((',', 'Inc.'), 'punct'), (('48', 'St.'), 'nummod'), (('North', 'St.'), 'compound'), (('Pleasant', 'St.'), 'amod'), (('St.', 'Inc.'), 'list'), (('Unit', 'St.'), 'appos'), (('301', 'Unit'), 'nummod'), ((',', 'MA'), 'punct'), (('Amherst', 'MA'), 'appos'), (('MA', 'Inc.'), 'list'), (('01002', 'USA'), 'nummod'), (('USA', 'MA'), 'appos'), (('|', 'USA'), 'punct'), (('1-800-377-8036', 'Inc.'), 'list'), (('|', '1-800-377-8036'), 'punct'), (('www.lexalytics.com', 'Inc.'), 'list')]

 Named Entites are: 
>> [('6|       |   Lexalytics, Inc.', 'ORG'), ('301', 'CARDINAL')]

================================ Paragraph 82 =================================

Unsupervised learning 


------------------- Sentence 1 -------------------

 Unsupervised learning 

Tokens are: 
>> ['Unsupervised', 'learning'] 

 UPOS tags are: 
>> [('Unsupervised', 'VERB'), ('learning', 'NOUN')] 

 XPOS tags are: 
>> [('Unsupervised', 'VBN'), ('learning', 'NN')] 

 Lemmas are: 
>> [('Unsupervised', 'unsupervise'), ('learning', 'learning')] 

 Dependency tags are: 
>> [(('Unsupervised', 'learning'), 'amod'), (('learning', 'root'), 'root')]

 Named Entites are: 
>> []

================================ Paragraph 83 =================================

Unsupervised learning is where we hand the machine a whole bunch  of content and tell it to find the patterns. This is how we built the syntax parser in Salience: We took 40GB of text and had the parser analyze every  sentence to understand how subjects and verbs fit together. Consider   the following:  


------------------- Sentence 1 -------------------

 Unsupervised learning is where we hand the machine a whole bunch  of content and tell it to find the patterns. 

Tokens are: 
>> ['Unsupervised', 'learning', 'is', 'where', 'we', 'hand', 'the', 'machine', 'a', 'whole', 'bunch', 'of', 'content', 'and', 'tell', 'it', 'to', 'find', 'the', 'patterns', '.'] 

 UPOS tags are: 
>> [('Unsupervised', 'VERB'), ('learning', 'NOUN'), ('is', 'AUX'), ('where', 'SCONJ'), ('we', 'PRON'), ('hand', 'VERB'), ('the', 'DET'), ('machine', 'NOUN'), ('a', 'DET'), ('whole', 'ADJ'), ('bunch', 'NOUN'), ('of', 'ADP'), ('content', 'NOUN'), ('and', 'CCONJ'), ('tell', 'VERB'), ('it', 'PRON'), ('to', 'PART'), ('find', 'VERB'), ('the', 'DET'), ('patterns', 'NOUN'), ('.', 'PUNCT')] 

 XPOS tags are: 
>> [('Unsupervised', 'VBN'), ('learning', 'NN'), ('is', 'VBZ'), ('where', 'WRB'), ('we', 'PRP'), ('hand', 'VBP'), ('the', 'DT'), ('machine', 'NN'), ('a', 'DT'), ('whole', 'JJ'), ('bunch', 'NN'), ('of', 'IN'), ('content', 'NN'), ('and', 'CC'), ('tell', 'VBP'), ('it', 'PRP'), ('to', 'TO'), ('find', 'VB'), ('the', 'DT'), ('patterns', 'NNS'), ('.', '.')] 

 Lemmas are: 
>> [('Unsupervised', 'unsupervise'), ('learning', 'learning'), ('is', 'be'), ('where', 'where'), ('we', 'we'), ('hand', 'hand'), ('the', 'the'), ('machine', 'machine'), ('a', 'a'), ('whole', 'whole'), ('bunch', 'bunch'), ('of', 'of'), ('content', 'content'), ('and', 'and'), ('tell', 'tell'), ('it', 'it'), ('to', 'to'), ('find', 'find'), ('the', 'the'), ('patterns', 'pattern'), ('.', '.')] 

 Dependency tags are: 
>> [(('Unsupervised', 'learning'), 'amod'), (('learning', 'is'), 'nsubj'), (('is', 'root'), 'root'), (('where', 'hand'), 'mark'), (('we', 'hand'), 'nsubj'), (('hand', 'is'), 'ccomp'), (('the', 'machine'), 'det'), (('machine', 'hand'), 'obj'), (('a', 'bunch'), 'det'), (('whole', 'bunch'), 'amod'), (('bunch', 'hand'), 'obj'), (('of', 'content'), 'case'), (('content', 'bunch'), 'nmod'), (('and', 'tell'), 'cc'), (('tell', 'hand'), 'conj'), (('it', 'tell'), 'obj'), (('to', 'find'), 'mark'), (('find', 'tell'), 'xcomp'), (('the', 'patterns'), 'det'), (('patterns', 'find'), 'obj'), (('.', 'is'), 'punct')]

 Named Entites are: 
>> []

------------------- Sentence 2 -------------------

 This is how we built the syntax parser in Salience: 

Tokens are: 
>> ['This', 'is', 'how', 'we', 'built', 'the', 'syntax', 'parser', 'in', 'Salience', ':'] 

 UPOS tags are: 
>> [('This', 'PRON'), ('is', 'AUX'), ('how', 'SCONJ'), ('we', 'PRON'), ('built', 'VERB'), ('the', 'DET'), ('syntax', 'NOUN'), ('parser', 'NOUN'), ('in', 'ADP'), ('Salience', 'NOUN'), (':', 'PUNCT')] 

 XPOS tags are: 
>> [('This', 'DT'), ('is', 'VBZ'), ('how', 'WRB'), ('we', 'PRP'), ('built', 'VBD'), ('the', 'DT'), ('syntax', 'NN'), ('parser', 'NN'), ('in', 'IN'), ('Salience', 'NN'), (':', ':')] 

 Lemmas are: 
>> [('This', 'this'), ('is', 'be'), ('how', 'how'), ('we', 'we'), ('built', 'build'), ('the', 'the'), ('syntax', 'syntax'), ('parser', 'parser'), ('in', 'in'), ('Salience', 'salience'), (':', ':')] 

 Dependency tags are: 
>> [(('This', 'is'), 'nsubj'), (('is', 'root'), 'root'), (('how', 'built'), 'mark'), (('we', 'built'), 'nsubj'), (('built', 'is'), 'ccomp'), (('the', 'parser'), 'det'), (('syntax', 'parser'), 'compound'), (('parser', 'built'), 'obj'), (('in', 'Salience'), 'case'), (('Salience', 'built'), 'obl'), ((':', 'is'), 'punct')]

 Named Entites are: 
>> [('Salience', 'GPE')]

------------------- Sentence 3 -------------------

 We took 40GB of text and had the parser analyze every  sentence to understand how subjects and verbs fit together. 

Tokens are: 
>> ['We', 'took', '40', 'GB', 'of', 'text', 'and', 'had', 'the', 'parser', 'analyze', 'every', 'sentence', 'to', 'understand', 'how', 'subjects', 'and', 'verbs', 'fit', 'together', '.'] 

 UPOS tags are: 
>> [('We', 'PRON'), ('took', 'VERB'), ('40', 'NUM'), ('GB', 'NOUN'), ('of', 'ADP'), ('text', 'NOUN'), ('and', 'CCONJ'), ('had', 'VERB'), ('the', 'DET'), ('parser', 'NOUN'), ('analyze', 'VERB'), ('every', 'DET'), ('sentence', 'NOUN'), ('to', 'PART'), ('understand', 'VERB'), ('how', 'SCONJ'), ('subjects', 'NOUN'), ('and', 'CCONJ'), ('verbs', 'NOUN'), ('fit', 'VERB'), ('together', 'ADV'), ('.', 'PUNCT')] 

 XPOS tags are: 
>> [('We', 'PRP'), ('took', 'VBD'), ('40', 'CD'), ('GB', 'NN'), ('of', 'IN'), ('text', 'NN'), ('and', 'CC'), ('had', 'VBD'), ('the', 'DT'), ('parser', 'NN'), ('analyze', 'VB'), ('every', 'DT'), ('sentence', 'NN'), ('to', 'TO'), ('understand', 'VB'), ('how', 'WRB'), ('subjects', 'NNS'), ('and', 'CC'), ('verbs', 'NNS'), ('fit', 'VBP'), ('together', 'RB'), ('.', '.')] 

 Lemmas are: 
>> [('We', 'we'), ('took', 'take'), ('40', '40'), ('GB', 'gb'), ('of', 'of'), ('text', 'text'), ('and', 'and'), ('had', 'have'), ('the', 'the'), ('parser', 'parser'), ('analyze', 'analyze'), ('every', 'every'), ('sentence', 'sentence'), ('to', 'to'), ('understand', 'understand'), ('how', 'how'), ('subjects', 'subject'), ('and', 'and'), ('verbs', 'verb'), ('fit', 'fit'), ('together', 'together'), ('.', '.')] 

 Dependency tags are: 
>> [(('We', 'took'), 'nsubj'), (('took', 'root'), 'root'), (('40', 'GB'), 'nummod'), (('GB', 'took'), 'obj'), (('of', 'text'), 'case'), (('text', 'GB'), 'nmod'), (('and', 'had'), 'cc'), (('had', 'took'), 'conj'), (('the', 'parser'), 'det'), (('parser', 'had'), 'obj'), (('analyze', 'had'), 'xcomp'), (('every', 'sentence'), 'det'), (('sentence', 'analyze'), 'obj'), (('to', 'understand'), 'mark'), (('understand', 'analyze'), 'advcl'), (('how', 'fit'), 'mark'), (('subjects', 'fit'), 'nsubj'), (('and', 'verbs'), 'cc'), (('verbs', 'subjects'), 'conj'), (('fit', 'understand'), 'ccomp'), (('together', 'fit'), 'advmod'), (('.', 'took'), 'punct')]

 Named Entites are: 
>> [('40GB', 'QUANTITY')]

------------------- Sentence 4 -------------------

 Consider   the following: 

Tokens are: 
>> ['Consider', 'the', 'following', ':'] 

 UPOS tags are: 
>> [('Consider', 'VERB'), ('the', 'DET'), ('following', 'VERB'), (':', 'PUNCT')] 

 XPOS tags are: 
>> [('Consider', 'VB'), ('the', 'DT'), ('following', 'VBG'), (':', ':')] 

 Lemmas are: 
>> [('Consider', 'consider'), ('the', 'the'), ('following', 'follow'), (':', ':')] 

 Dependency tags are: 
>> [(('Consider', 'root'), 'root'), (('the', 'Consider'), 'obj'), (('following', 'Consider'), 'obj'), ((':', 'Consider'), 'punct')]

 Named Entites are: 
>> []

================================ Paragraph 84 =================================

“I threw the ball over the mountain.” 


------------------- Sentence 1 -------------------

 “I threw the ball over the mountain.” 

Tokens are: 
>> ['“', 'I', 'threw', 'the', 'ball', 'over', 'the', 'mountain', '.', '”'] 

 UPOS tags are: 
>> [('“', 'PUNCT'), ('I', 'PRON'), ('threw', 'VERB'), ('the', 'DET'), ('ball', 'NOUN'), ('over', 'ADP'), ('the', 'DET'), ('mountain', 'NOUN'), ('.', 'PUNCT'), ('”', 'PUNCT')] 

 XPOS tags are: 
>> [('“', '``'), ('I', 'PRP'), ('threw', 'VBD'), ('the', 'DT'), ('ball', 'NN'), ('over', 'IN'), ('the', 'DT'), ('mountain', 'NN'), ('.', '.'), ('”', "''")] 

 Lemmas are: 
>> [('“', "''"), ('I', 'I'), ('threw', 'throw'), ('the', 'the'), ('ball', 'ball'), ('over', 'over'), ('the', 'the'), ('mountain', 'mountain'), ('.', '.'), ('”', "''")] 

 Dependency tags are: 
>> [(('“', 'threw'), 'punct'), (('I', 'threw'), 'nsubj'), (('threw', 'root'), 'root'), (('the', 'ball'), 'det'), (('ball', 'threw'), 'obj'), (('over', 'mountain'), 'case'), (('the', 'mountain'), 'det'), (('mountain', 'threw'), 'obl'), (('.', 'threw'), 'punct'), (('”', 'threw'), 'punct')]

 Named Entites are: 
>> []

================================ Paragraph 85 =================================

One way to understand syntax is to parse the entire sentence, like   you’re doing a sentence diagram from 6th grade. Those are quite  computationally intensive (along with being irritating for 6th graders),   and so you can’t do that for high-volume content – it just takes too long  for each document to process. 


------------------- Sentence 1 -------------------

 One way to understand syntax is to parse the entire sentence, like   you’re doing a sentence diagram from 6th grade. 

Tokens are: 
>> ['One', 'way', 'to', 'understand', 'syntax', 'is', 'to', 'parse', 'the', 'entire', 'sentence', ',', 'like', 'you', '’re', 'doing', 'a', 'sentence', 'diagram', 'from', '6th', 'grade', '.'] 

 UPOS tags are: 
>> [('One', 'NUM'), ('way', 'NOUN'), ('to', 'PART'), ('understand', 'VERB'), ('syntax', 'NOUN'), ('is', 'VERB'), ('to', 'PART'), ('parse', 'VERB'), ('the', 'DET'), ('entire', 'ADJ'), ('sentence', 'NOUN'), (',', 'PUNCT'), ('like', 'SCONJ'), ('you', 'PRON'), ('’re', 'AUX'), ('doing', 'VERB'), ('a', 'DET'), ('sentence', 'NOUN'), ('diagram', 'NOUN'), ('from', 'ADP'), ('6th', 'ADJ'), ('grade', 'NOUN'), ('.', 'PUNCT')] 

 XPOS tags are: 
>> [('One', 'CD'), ('way', 'NN'), ('to', 'TO'), ('understand', 'VB'), ('syntax', 'NN'), ('is', 'VBZ'), ('to', 'TO'), ('parse', 'VB'), ('the', 'DT'), ('entire', 'JJ'), ('sentence', 'NN'), (',', ','), ('like', 'IN'), ('you', 'PRP'), ('’re', 'VBP'), ('doing', 'VBG'), ('a', 'DT'), ('sentence', 'NN'), ('diagram', 'NN'), ('from', 'IN'), ('6th', 'JJ'), ('grade', 'NN'), ('.', '.')] 

 Lemmas are: 
>> [('One', 'one'), ('way', 'way'), ('to', 'to'), ('understand', 'understand'), ('syntax', 'syntax'), ('is', 'be'), ('to', 'to'), ('parse', 'parse'), ('the', 'the'), ('entire', 'entire'), ('sentence', 'sentence'), (',', ','), ('like', 'like'), ('you', 'you'), ('’re', 'be'), ('doing', 'do'), ('a', 'a'), ('sentence', 'sentence'), ('diagram', 'diagram'), ('from', 'from'), ('6th', '6th'), ('grade', 'grade'), ('.', '.')] 

 Dependency tags are: 
>> [(('One', 'way'), 'nummod'), (('way', 'parse'), 'nsubj'), (('to', 'understand'), 'mark'), (('understand', 'way'), 'acl'), (('syntax', 'understand'), 'obj'), (('is', 'parse'), 'cop'), (('to', 'parse'), 'mark'), (('parse', 'root'), 'root'), (('the', 'sentence'), 'det'), (('entire', 'sentence'), 'amod'), (('sentence', 'parse'), 'obj'), ((',', 'parse'), 'punct'), (('like', 'doing'), 'mark'), (('you', 'doing'), 'nsubj'), (('’re', 'doing'), 'aux'), (('doing', 'parse'), 'advcl'), (('a', 'diagram'), 'det'), (('sentence', 'diagram'), 'compound'), (('diagram', 'doing'), 'obj'), (('from', 'grade'), 'case'), (('6th', 'grade'), 'amod'), (('grade', 'doing'), 'obl'), (('.', 'parse'), 'punct')]

 Named Entites are: 
>> [('One', 'CARDINAL'), ('6th', 'ORDINAL')]

------------------- Sentence 2 -------------------

 Those are quite  computationally intensive (along with being irritating for 6th graders),   and so you can’t do that for high-volume content – it just takes too long  for each document to process. 

Tokens are: 
>> ['Those', 'are', 'quite', 'computationally', 'intensive', '(', 'along', 'with', 'being', 'irritating', 'for', '6th', 'graders', ')', ',', 'and', 'so', 'you', 'ca', 'n’t', 'do', 'that', 'for', 'high', '-', 'volume', 'content', '–', 'it', 'just', 'takes', 'too', 'long', 'for', 'each', 'document', 'to', 'process', '.'] 

 UPOS tags are: 
>> [('Those', 'PRON'), ('are', 'AUX'), ('quite', 'ADV'), ('computationally', 'ADV'), ('intensive', 'ADJ'), ('(', 'PUNCT'), ('along', 'ADP'), ('with', 'SCONJ'), ('being', 'AUX'), ('irritating', 'ADJ'), ('for', 'ADP'), ('6th', 'ADJ'), ('graders', 'NOUN'), (')', 'PUNCT'), (',', 'PUNCT'), ('and', 'CCONJ'), ('so', 'ADV'), ('you', 'PRON'), ('ca', 'AUX'), ('n’t', 'PART'), ('do', 'VERB'), ('that', 'PRON'), ('for', 'ADP'), ('high', 'ADJ'), ('-', 'PUNCT'), ('volume', 'NOUN'), ('content', 'NOUN'), ('–', 'PUNCT'), ('it', 'PRON'), ('just', 'ADV'), ('takes', 'VERB'), ('too', 'ADV'), ('long', 'ADV'), ('for', 'ADP'), ('each', 'DET'), ('document', 'NOUN'), ('to', 'ADP'), ('process', 'NOUN'), ('.', 'PUNCT')] 

 XPOS tags are: 
>> [('Those', 'DT'), ('are', 'VBP'), ('quite', 'RB'), ('computationally', 'RB'), ('intensive', 'JJ'), ('(', '-LRB-'), ('along', 'IN'), ('with', 'IN'), ('being', 'VBG'), ('irritating', 'JJ'), ('for', 'IN'), ('6th', 'JJ'), ('graders', 'NNS'), (')', '-RRB-'), (',', ','), ('and', 'CC'), ('so', 'RB'), ('you', 'PRP'), ('ca', 'MD'), ('n’t', 'RB'), ('do', 'VB'), ('that', 'DT'), ('for', 'IN'), ('high', 'JJ'), ('-', 'HYPH'), ('volume', 'NN'), ('content', 'NN'), ('–', ':'), ('it', 'PRP'), ('just', 'RB'), ('takes', 'VBZ'), ('too', 'RB'), ('long', 'RB'), ('for', 'IN'), ('each', 'DT'), ('document', 'NN'), ('to', 'IN'), ('process', 'NN'), ('.', '.')] 

 Lemmas are: 
>> [('Those', 'that'), ('are', 'be'), ('quite', 'quite'), ('computationally', 'computationally'), ('intensive', 'intensive'), ('(', '('), ('along', 'along'), ('with', 'with'), ('being', 'be'), ('irritating', 'irritating'), ('for', 'for'), ('6th', '6th'), ('graders', 'grader'), (')', ')'), (',', ','), ('and', 'and'), ('so', 'so'), ('you', 'you'), ('ca', 'can'), ('n’t', 'not'), ('do', 'do'), ('that', 'that'), ('for', 'for'), ('high', 'high'), ('-', '-'), ('volume', 'volume'), ('content', 'content'), ('–', '-'), ('it', 'it'), ('just', 'just'), ('takes', 'take'), ('too', 'too'), ('long', 'long'), ('for', 'for'), ('each', 'each'), ('document', 'document'), ('to', 'to'), ('process', 'process'), ('.', '.')] 

 Dependency tags are: 
>> [(('Those', 'intensive'), 'nsubj'), (('are', 'intensive'), 'cop'), (('quite', 'computationally'), 'advmod'), (('computationally', 'intensive'), 'advmod'), (('intensive', 'root'), 'root'), (('(', 'irritating'), 'punct'), (('along', 'irritating'), 'mark'), (('with', 'irritating'), 'mark'), (('being', 'irritating'), 'cop'), (('irritating', 'intensive'), 'advcl'), (('for', 'graders'), 'case'), (('6th', 'graders'), 'amod'), (('graders', 'irritating'), 'obl'), ((')', 'irritating'), 'punct'), ((',', 'do'), 'punct'), (('and', 'do'), 'cc'), (('so', 'do'), 'advmod'), (('you', 'do'), 'nsubj'), (('ca', 'do'), 'aux'), (('n’t', 'do'), 'advmod'), (('do', 'intensive'), 'conj'), (('that', 'do'), 'obj'), (('for', 'content'), 'case'), (('high', 'volume'), 'amod'), (('-', 'volume'), 'punct'), (('volume', 'content'), 'compound'), (('content', 'do'), 'obl'), (('–', 'takes'), 'punct'), (('it', 'takes'), 'nsubj'), (('just', 'takes'), 'advmod'), (('takes', 'intensive'), 'parataxis'), (('too', 'long'), 'advmod'), (('long', 'takes'), 'advmod'), (('for', 'document'), 'case'), (('each', 'document'), 'det'), (('document', 'takes'), 'obl'), (('to', 'process'), 'case'), (('process', 'document'), 'nmod'), (('.', 'intensive'), 'punct')]

 Named Entites are: 
>> [('6th', 'ORDINAL')]

================================ Paragraph 86 =================================

But what if you were to process a bunch of content ahead of time to  come up with a set of relationships that shows how words like “ball,”  “threw” and “mountain” were typically related across millions and billions of  sentences.  


------------------- Sentence 1 -------------------

 But what if you were to process a bunch of content ahead of time to  come up with a set of relationships that shows how words like “ball,”  “threw” and “mountain” were typically related across millions and billions of  sentences. 

Tokens are: 
>> ['But', 'what', 'if', 'you', 'were', 'to', 'process', 'a', 'bunch', 'of', 'content', 'ahead', 'of', 'time', 'to', 'come', 'up', 'with', 'a', 'set', 'of', 'relationships', 'that', 'shows', 'how', 'words', 'like', '“', 'ball', ',', '”', '“', 'threw', '”', 'and', '“', 'mountain', '”', 'were', 'typically', 'related', 'across', 'millions', 'and', 'billions', 'of', 'sentences', '.'] 

 UPOS tags are: 
>> [('But', 'CCONJ'), ('what', 'PRON'), ('if', 'SCONJ'), ('you', 'PRON'), ('were', 'VERB'), ('to', 'PART'), ('process', 'VERB'), ('a', 'DET'), ('bunch', 'NOUN'), ('of', 'ADP'), ('content', 'NOUN'), ('ahead', 'ADV'), ('of', 'ADP'), ('time', 'NOUN'), ('to', 'PART'), ('come', 'VERB'), ('up', 'ADP'), ('with', 'ADP'), ('a', 'DET'), ('set', 'NOUN'), ('of', 'ADP'), ('relationships', 'NOUN'), ('that', 'PRON'), ('shows', 'VERB'), ('how', 'SCONJ'), ('words', 'NOUN'), ('like', 'ADP'), ('“', 'PUNCT'), ('ball', 'NOUN'), (',', 'PUNCT'), ('”', 'PUNCT'), ('“', 'PUNCT'), ('threw', 'VERB'), ('”', 'PUNCT'), ('and', 'CCONJ'), ('“', 'PUNCT'), ('mountain', 'NOUN'), ('”', 'PUNCT'), ('were', 'AUX'), ('typically', 'ADV'), ('related', 'ADJ'), ('across', 'ADP'), ('millions', 'NOUN'), ('and', 'CCONJ'), ('billions', 'NOUN'), ('of', 'ADP'), ('sentences', 'NOUN'), ('.', 'PUNCT')] 

 XPOS tags are: 
>> [('But', 'CC'), ('what', 'WP'), ('if', 'IN'), ('you', 'PRP'), ('were', 'VBD'), ('to', 'TO'), ('process', 'VB'), ('a', 'DT'), ('bunch', 'NN'), ('of', 'IN'), ('content', 'NN'), ('ahead', 'RB'), ('of', 'IN'), ('time', 'NN'), ('to', 'TO'), ('come', 'VB'), ('up', 'RP'), ('with', 'IN'), ('a', 'DT'), ('set', 'NN'), ('of', 'IN'), ('relationships', 'NNS'), ('that', 'WDT'), ('shows', 'VBZ'), ('how', 'WRB'), ('words', 'NNS'), ('like', 'IN'), ('“', '``'), ('ball', 'NN'), (',', ','), ('”', "''"), ('“', '``'), ('threw', 'VBD'), ('”', "''"), ('and', 'CC'), ('“', '``'), ('mountain', 'NN'), ('”', "''"), ('were', 'VBD'), ('typically', 'RB'), ('related', 'JJ'), ('across', 'IN'), ('millions', 'NNS'), ('and', 'CC'), ('billions', 'NNS'), ('of', 'IN'), ('sentences', 'NNS'), ('.', '.')] 

 Lemmas are: 
>> [('But', 'but'), ('what', 'what'), ('if', 'if'), ('you', 'you'), ('were', 'be'), ('to', 'to'), ('process', 'process'), ('a', 'a'), ('bunch', 'bunch'), ('of', 'of'), ('content', 'content'), ('ahead', 'ahead'), ('of', 'of'), ('time', 'time'), ('to', 'to'), ('come', 'come'), ('up', 'up'), ('with', 'with'), ('a', 'a'), ('set', 'set'), ('of', 'of'), ('relationships', 'relationship'), ('that', 'that'), ('shows', 'show'), ('how', 'how'), ('words', 'word'), ('like', 'like'), ('“', "''"), ('ball', 'ball'), (',', ','), ('”', "''"), ('“', "''"), ('threw', 'throw'), ('”', "''"), ('and', 'and'), ('“', "''"), ('mountain', 'mountain'), ('”', "''"), ('were', 'be'), ('typically', 'typically'), ('related', 'related'), ('across', 'across'), ('millions', 'million'), ('and', 'and'), ('billions', 'billion'), ('of', 'of'), ('sentences', 'sentence'), ('.', '.')] 

 Dependency tags are: 
>> [(('But', 'related'), 'cc'), (('what', 'root'), 'root'), (('if', 'were'), 'mark'), (('you', 'were'), 'nsubj'), (('were', 'what'), 'advcl'), (('to', 'process'), 'mark'), (('process', 'were'), 'xcomp'), (('a', 'bunch'), 'det'), (('bunch', 'process'), 'obj'), (('of', 'content'), 'case'), (('content', 'bunch'), 'nmod'), (('ahead', 'process'), 'advmod'), (('of', 'time'), 'case'), (('time', 'bunch'), 'nmod'), (('to', 'come'), 'mark'), (('come', 'process'), 'advcl'), (('up', 'come'), 'compound:prt'), (('with', 'set'), 'case'), (('a', 'set'), 'det'), (('set', 'come'), 'obl'), (('of', 'relationships'), 'case'), (('relationships', 'set'), 'nmod'), (('that', 'shows'), 'nsubj'), (('shows', 'relationships'), 'acl:relcl'), (('how', 'shows'), 'obj'), (('words', 'shows'), 'obj'), (('like', 'ball'), 'case'), (('“', 'ball'), 'punct'), (('ball', 'words'), 'nmod'), ((',', 'ball'), 'punct'), (('”', 'ball'), 'punct'), (('“', 'threw'), 'punct'), (('threw', 'ball'), 'conj'), (('”', 'threw'), 'punct'), (('and', 'mountain'), 'cc'), (('“', 'mountain'), 'punct'), (('mountain', 'threw'), 'conj'), (('”', 'mountain'), 'punct'), (('were', 'related'), 'cop'), (('typically', 'related'), 'advmod'), (('related', 'threw'), 'conj'), (('across', 'millions'), 'case'), (('millions', 'related'), 'obl'), (('and', 'billions'), 'cc'), (('billions', 'millions'), 'conj'), (('of', 'sentences'), 'case'), (('sentences', 'billions'), 'nmod'), (('.', 'related'), 'punct')]

 Named Entites are: 
>> [('millions and billions', 'CARDINAL')]

================================ Paragraph 87 =================================

As a human, you naturally know that it is far more likely that “threw”   is acting on “ball,” than it is likely that “threw” is acting on “mountain.”  You don’t throw mountains, you throw balls. 


------------------- Sentence 1 -------------------

 As a human, you naturally know that it is far more likely that “threw”   is acting on “ball,” than it is likely that “threw” is acting on “mountain.” 

Tokens are: 
>> ['As', 'a', 'human', ',', 'you', 'naturally', 'know', 'that', 'it', 'is', 'far', 'more', 'likely', 'that', '“', 'threw', '”', 'is', 'acting', 'on', '“', 'ball', ',', '”', 'than', 'it', 'is', 'likely', 'that', '“', 'threw', '”', 'is', 'acting', 'on', '“', 'mountain', '.', '”'] 

 UPOS tags are: 
>> [('As', 'ADP'), ('a', 'DET'), ('human', 'NOUN'), (',', 'PUNCT'), ('you', 'PRON'), ('naturally', 'ADV'), ('know', 'VERB'), ('that', 'SCONJ'), ('it', 'PRON'), ('is', 'AUX'), ('far', 'ADV'), ('more', 'ADV'), ('likely', 'ADJ'), ('that', 'SCONJ'), ('“', 'PUNCT'), ('threw', 'VERB'), ('”', 'PUNCT'), ('is', 'AUX'), ('acting', 'VERB'), ('on', 'ADP'), ('“', 'PUNCT'), ('ball', 'NOUN'), (',', 'PUNCT'), ('”', 'PUNCT'), ('than', 'SCONJ'), ('it', 'PRON'), ('is', 'AUX'), ('likely', 'ADJ'), ('that', 'SCONJ'), ('“', 'PUNCT'), ('threw', 'VERB'), ('”', 'PUNCT'), ('is', 'AUX'), ('acting', 'VERB'), ('on', 'ADP'), ('“', 'PUNCT'), ('mountain', 'NOUN'), ('.', 'PUNCT'), ('”', 'PUNCT')] 

 XPOS tags are: 
>> [('As', 'IN'), ('a', 'DT'), ('human', 'NN'), (',', ','), ('you', 'PRP'), ('naturally', 'RB'), ('know', 'VBP'), ('that', 'IN'), ('it', 'PRP'), ('is', 'VBZ'), ('far', 'RB'), ('more', 'RBR'), ('likely', 'JJ'), ('that', 'IN'), ('“', '``'), ('threw', 'VBD'), ('”', "''"), ('is', 'VBZ'), ('acting', 'VBG'), ('on', 'IN'), ('“', '``'), ('ball', 'NN'), (',', ','), ('”', "''"), ('than', 'IN'), ('it', 'PRP'), ('is', 'VBZ'), ('likely', 'JJ'), ('that', 'IN'), ('“', '``'), ('threw', 'VBD'), ('”', "''"), ('is', 'VBZ'), ('acting', 'VBG'), ('on', 'IN'), ('“', '``'), ('mountain', 'NN'), ('.', '.'), ('”', "''")] 

 Lemmas are: 
>> [('As', 'as'), ('a', 'a'), ('human', 'human'), (',', ','), ('you', 'you'), ('naturally', 'naturally'), ('know', 'know'), ('that', 'that'), ('it', 'it'), ('is', 'be'), ('far', 'far'), ('more', 'more'), ('likely', 'likely'), ('that', 'that'), ('“', "''"), ('threw', 'throw'), ('”', "''"), ('is', 'be'), ('acting', 'act'), ('on', 'on'), ('“', "''"), ('ball', 'ball'), (',', ','), ('”', "''"), ('than', 'than'), ('it', 'it'), ('is', 'be'), ('likely', 'likely'), ('that', 'that'), ('“', "''"), ('threw', 'throw'), ('”', "''"), ('is', 'be'), ('acting', 'act'), ('on', 'on'), ('“', "''"), ('mountain', 'mountain'), ('.', '.'), ('”', "''")] 

 Dependency tags are: 
>> [(('As', 'human'), 'case'), (('a', 'human'), 'det'), (('human', 'know'), 'obl'), ((',', 'know'), 'punct'), (('you', 'know'), 'nsubj'), (('naturally', 'know'), 'advmod'), (('know', 'root'), 'root'), (('that', 'likely'), 'mark'), (('it', 'likely'), 'expl'), (('is', 'likely'), 'cop'), (('far', 'more'), 'advmod'), (('more', 'likely'), 'advmod'), (('likely', 'know'), 'ccomp'), (('that', 'threw'), 'mark'), (('“', 'threw'), 'punct'), (('threw', 'acting'), 'nsubj'), (('”', 'threw'), 'punct'), (('is', 'acting'), 'aux'), (('acting', 'likely'), 'ccomp'), (('on', 'ball'), 'case'), (('“', 'ball'), 'punct'), (('ball', 'acting'), 'obl'), ((',', 'ball'), 'punct'), (('”', 'ball'), 'punct'), (('than', 'likely'), 'mark'), (('it', 'likely'), 'expl'), (('is', 'likely'), 'cop'), (('likely', 'acting'), 'advcl'), (('that', 'threw'), 'mark'), (('“', 'threw'), 'punct'), (('threw', 'likely'), 'ccomp'), (('”', 'threw'), 'punct'), (('is', 'acting'), 'aux'), (('acting', 'likely'), 'ccomp'), (('on', 'mountain'), 'case'), (('“', 'mountain'), 'punct'), (('mountain', 'acting'), 'obl'), (('.', 'threw'), 'punct'), (('”', 'mountain'), 'punct')]

 Named Entites are: 
>> []

------------------- Sentence 2 -------------------

 You don’t throw mountains, you throw balls. 

Tokens are: 
>> ['You', 'do', 'n’t', 'throw', 'mountains', ',', 'you', 'throw', 'balls', '.'] 

 UPOS tags are: 
>> [('You', 'PRON'), ('do', 'AUX'), ('n’t', 'PART'), ('throw', 'VERB'), ('mountains', 'NOUN'), (',', 'PUNCT'), ('you', 'PRON'), ('throw', 'VERB'), ('balls', 'NOUN'), ('.', 'PUNCT')] 

 XPOS tags are: 
>> [('You', 'PRP'), ('do', 'VBP'), ('n’t', 'RB'), ('throw', 'VB'), ('mountains', 'NNS'), (',', ','), ('you', 'PRP'), ('throw', 'VBP'), ('balls', 'NNS'), ('.', '.')] 

 Lemmas are: 
>> [('You', 'you'), ('do', 'do'), ('n’t', 'not'), ('throw', 'throw'), ('mountains', 'mountain'), (',', ','), ('you', 'you'), ('throw', 'throw'), ('balls', 'ball'), ('.', '.')] 

 Dependency tags are: 
>> [(('You', 'throw'), 'nsubj'), (('do', 'throw'), 'aux'), (('n’t', 'throw'), 'advmod'), (('throw', 'root'), 'root'), (('mountains', 'throw'), 'obj'), ((',', 'throw'), 'punct'), (('you', 'throw'), 'nsubj'), (('throw', 'throw'), 'parataxis'), (('balls', 'throw'), 'obj'), (('.', 'throw'), 'punct')]

 Named Entites are: 
>> []

================================ Paragraph 88 =================================

That sort of probabilistic relationship can be extracted using unsupervised  learning. The syntax matrix was an excellent candidate for unsupervised  learning, as it involved discovering generally applicable patterns from a very  large corpus of content. Because it is a matrix, it can be evaluated really fast  for each sentence, unlike a full parser. 


------------------- Sentence 1 -------------------

 That sort of probabilistic relationship can be extracted using unsupervised  learning. 

Tokens are: 
>> ['That', 'sort', 'of', 'probabilistic', 'relationship', 'can', 'be', 'extracted', 'using', 'unsupervised', 'learning', '.'] 

 UPOS tags are: 
>> [('That', 'DET'), ('sort', 'NOUN'), ('of', 'ADP'), ('probabilistic', 'ADJ'), ('relationship', 'NOUN'), ('can', 'AUX'), ('be', 'AUX'), ('extracted', 'VERB'), ('using', 'VERB'), ('unsupervised', 'ADJ'), ('learning', 'NOUN'), ('.', 'PUNCT')] 

 XPOS tags are: 
>> [('That', 'DT'), ('sort', 'NN'), ('of', 'IN'), ('probabilistic', 'JJ'), ('relationship', 'NN'), ('can', 'MD'), ('be', 'VB'), ('extracted', 'VBN'), ('using', 'VBG'), ('unsupervised', 'JJ'), ('learning', 'NN'), ('.', '.')] 

 Lemmas are: 
>> [('That', 'that'), ('sort', 'sort'), ('of', 'of'), ('probabilistic', 'probabilistic'), ('relationship', 'relationship'), ('can', 'can'), ('be', 'be'), ('extracted', 'extract'), ('using', 'use'), ('unsupervised', 'unsupervised'), ('learning', 'learning'), ('.', '.')] 

 Dependency tags are: 
>> [(('That', 'sort'), 'det'), (('sort', 'extracted'), 'nsubj:pass'), (('of', 'relationship'), 'case'), (('probabilistic', 'relationship'), 'amod'), (('relationship', 'sort'), 'nmod'), (('can', 'extracted'), 'aux'), (('be', 'extracted'), 'aux:pass'), (('extracted', 'root'), 'root'), (('using', 'extracted'), 'advcl'), (('unsupervised', 'learning'), 'amod'), (('learning', 'using'), 'obj'), (('.', 'extracted'), 'punct')]

 Named Entites are: 
>> []

------------------- Sentence 2 -------------------

 The syntax matrix was an excellent candidate for unsupervised  learning, as it involved discovering generally applicable patterns from a very  large corpus of content. 

Tokens are: 
>> ['The', 'syntax', 'matrix', 'was', 'an', 'excellent', 'candidate', 'for', 'unsupervised', 'learning', ',', 'as', 'it', 'involved', 'discovering', 'generally', 'applicable', 'patterns', 'from', 'a', 'very', 'large', 'corpus', 'of', 'content', '.'] 

 UPOS tags are: 
>> [('The', 'DET'), ('syntax', 'NOUN'), ('matrix', 'NOUN'), ('was', 'AUX'), ('an', 'DET'), ('excellent', 'ADJ'), ('candidate', 'NOUN'), ('for', 'ADP'), ('unsupervised', 'ADJ'), ('learning', 'NOUN'), (',', 'PUNCT'), ('as', 'SCONJ'), ('it', 'PRON'), ('involved', 'VERB'), ('discovering', 'VERB'), ('generally', 'ADV'), ('applicable', 'ADJ'), ('patterns', 'NOUN'), ('from', 'ADP'), ('a', 'DET'), ('very', 'ADV'), ('large', 'ADJ'), ('corpus', 'NOUN'), ('of', 'ADP'), ('content', 'NOUN'), ('.', 'PUNCT')] 

 XPOS tags are: 
>> [('The', 'DT'), ('syntax', 'NN'), ('matrix', 'NN'), ('was', 'VBD'), ('an', 'DT'), ('excellent', 'JJ'), ('candidate', 'NN'), ('for', 'IN'), ('unsupervised', 'JJ'), ('learning', 'NN'), (',', ','), ('as', 'IN'), ('it', 'PRP'), ('involved', 'VBD'), ('discovering', 'VBG'), ('generally', 'RB'), ('applicable', 'JJ'), ('patterns', 'NNS'), ('from', 'IN'), ('a', 'DT'), ('very', 'RB'), ('large', 'JJ'), ('corpus', 'NN'), ('of', 'IN'), ('content', 'NN'), ('.', '.')] 

 Lemmas are: 
>> [('The', 'the'), ('syntax', 'syntax'), ('matrix', 'matrix'), ('was', 'be'), ('an', 'a'), ('excellent', 'excellent'), ('candidate', 'candidate'), ('for', 'for'), ('unsupervised', 'unsupervised'), ('learning', 'learning'), (',', ','), ('as', 'as'), ('it', 'it'), ('involved', 'involve'), ('discovering', 'discover'), ('generally', 'generally'), ('applicable', 'applicable'), ('patterns', 'pattern'), ('from', 'from'), ('a', 'a'), ('very', 'very'), ('large', 'large'), ('corpus', 'corpus'), ('of', 'of'), ('content', 'content'), ('.', '.')] 

 Dependency tags are: 
>> [(('The', 'matrix'), 'det'), (('syntax', 'matrix'), 'compound'), (('matrix', 'candidate'), 'nsubj'), (('was', 'candidate'), 'cop'), (('an', 'candidate'), 'det'), (('excellent', 'candidate'), 'amod'), (('candidate', 'root'), 'root'), (('for', 'learning'), 'case'), (('unsupervised', 'learning'), 'amod'), (('learning', 'candidate'), 'nmod'), ((',', 'involved'), 'punct'), (('as', 'involved'), 'mark'), (('it', 'involved'), 'nsubj'), (('involved', 'candidate'), 'advcl'), (('discovering', 'involved'), 'xcomp'), (('generally', 'applicable'), 'advmod'), (('applicable', 'patterns'), 'amod'), (('patterns', 'discovering'), 'obj'), (('from', 'corpus'), 'case'), (('a', 'corpus'), 'det'), (('very', 'large'), 'advmod'), (('large', 'corpus'), 'amod'), (('corpus', 'discovering'), 'obl'), (('of', 'content'), 'case'), (('content', 'corpus'), 'nmod'), (('.', 'candidate'), 'punct')]

 Named Entites are: 
>> []

------------------- Sentence 3 -------------------

 Because it is a matrix, it can be evaluated really fast  for each sentence, unlike a full parser. 

Tokens are: 
>> ['Because', 'it', 'is', 'a', 'matrix', ',', 'it', 'can', 'be', 'evaluated', 'really', 'fast', 'for', 'each', 'sentence', ',', 'unlike', 'a', 'full', 'parser', '.'] 

 UPOS tags are: 
>> [('Because', 'SCONJ'), ('it', 'PRON'), ('is', 'AUX'), ('a', 'DET'), ('matrix', 'NOUN'), (',', 'PUNCT'), ('it', 'PRON'), ('can', 'AUX'), ('be', 'AUX'), ('evaluated', 'VERB'), ('really', 'ADV'), ('fast', 'ADV'), ('for', 'ADP'), ('each', 'DET'), ('sentence', 'NOUN'), (',', 'PUNCT'), ('unlike', 'ADP'), ('a', 'DET'), ('full', 'ADJ'), ('parser', 'NOUN'), ('.', 'PUNCT')] 

 XPOS tags are: 
>> [('Because', 'IN'), ('it', 'PRP'), ('is', 'VBZ'), ('a', 'DT'), ('matrix', 'NN'), (',', ','), ('it', 'PRP'), ('can', 'MD'), ('be', 'VB'), ('evaluated', 'VBN'), ('really', 'RB'), ('fast', 'RB'), ('for', 'IN'), ('each', 'DT'), ('sentence', 'NN'), (',', ','), ('unlike', 'IN'), ('a', 'DT'), ('full', 'JJ'), ('parser', 'NN'), ('.', '.')] 

 Lemmas are: 
>> [('Because', 'because'), ('it', 'it'), ('is', 'be'), ('a', 'a'), ('matrix', 'matrix'), (',', ','), ('it', 'it'), ('can', 'can'), ('be', 'be'), ('evaluated', 'evaluate'), ('really', 'really'), ('fast', 'fast'), ('for', 'for'), ('each', 'each'), ('sentence', 'sentence'), (',', ','), ('unlike', 'unlike'), ('a', 'a'), ('full', 'full'), ('parser', 'parser'), ('.', '.')] 

 Dependency tags are: 
>> [(('Because', 'matrix'), 'mark'), (('it', 'matrix'), 'nsubj'), (('is', 'matrix'), 'cop'), (('a', 'matrix'), 'det'), (('matrix', 'evaluated'), 'advcl'), ((',', 'evaluated'), 'punct'), (('it', 'evaluated'), 'nsubj:pass'), (('can', 'evaluated'), 'aux'), (('be', 'evaluated'), 'aux:pass'), (('evaluated', 'root'), 'root'), (('really', 'fast'), 'advmod'), (('fast', 'evaluated'), 'advmod'), (('for', 'sentence'), 'case'), (('each', 'sentence'), 'det'), (('sentence', 'evaluated'), 'obl'), ((',', 'parser'), 'punct'), (('unlike', 'parser'), 'case'), (('a', 'parser'), 'det'), (('full', 'parser'), 'amod'), (('parser', 'evaluated'), 'obl'), (('.', 'evaluated'), 'punct')]

 Named Entites are: 
>> []

================================ Paragraph 89 =================================

As the amount of content created every day grows exponentially,  unsupervised techniques become more and more valuable. 


------------------- Sentence 1 -------------------

 As the amount of content created every day grows exponentially,  unsupervised techniques become more and more valuable. 

Tokens are: 
>> ['As', 'the', 'amount', 'of', 'content', 'created', 'every', 'day', 'grows', 'exponentially', ',', 'unsupervised', 'techniques', 'become', 'more', 'and', 'more', 'valuable', '.'] 

 UPOS tags are: 
>> [('As', 'SCONJ'), ('the', 'DET'), ('amount', 'NOUN'), ('of', 'ADP'), ('content', 'NOUN'), ('created', 'VERB'), ('every', 'DET'), ('day', 'NOUN'), ('grows', 'VERB'), ('exponentially', 'ADV'), (',', 'PUNCT'), ('unsupervised', 'ADJ'), ('techniques', 'NOUN'), ('become', 'VERB'), ('more', 'ADV'), ('and', 'CCONJ'), ('more', 'ADV'), ('valuable', 'ADJ'), ('.', 'PUNCT')] 

 XPOS tags are: 
>> [('As', 'IN'), ('the', 'DT'), ('amount', 'NN'), ('of', 'IN'), ('content', 'NN'), ('created', 'VBD'), ('every', 'DT'), ('day', 'NN'), ('grows', 'VBZ'), ('exponentially', 'RB'), (',', ','), ('unsupervised', 'JJ'), ('techniques', 'NNS'), ('become', 'VBP'), ('more', 'RBR'), ('and', 'CC'), ('more', 'RBR'), ('valuable', 'JJ'), ('.', '.')] 

 Lemmas are: 
>> [('As', 'as'), ('the', 'the'), ('amount', 'amount'), ('of', 'of'), ('content', 'content'), ('created', 'create'), ('every', 'every'), ('day', 'day'), ('grows', 'grow'), ('exponentially', 'exponentially'), (',', ','), ('unsupervised', 'unsupervised'), ('techniques', 'technique'), ('become', 'become'), ('more', 'more'), ('and', 'and'), ('more', 'more'), ('valuable', 'valuable'), ('.', '.')] 

 Dependency tags are: 
>> [(('As', 'created'), 'mark'), (('the', 'amount'), 'det'), (('amount', 'created'), 'nsubj'), (('of', 'content'), 'case'), (('content', 'amount'), 'nmod'), (('created', 'become'), 'advcl'), (('every', 'day'), 'det'), (('day', 'created'), 'obl:tmod'), (('grows', 'become'), 'advcl'), (('exponentially', 'grows'), 'advmod'), ((',', 'become'), 'punct'), (('unsupervised', 'techniques'), 'amod'), (('techniques', 'become'), 'nsubj'), (('become', 'root'), 'root'), (('more', 'valuable'), 'advmod'), (('and', 'more'), 'cc'), (('more', 'more'), 'conj'), (('valuable', 'become'), 'xcomp'), (('.', 'become'), 'punct')]

 Named Entites are: 
>> []

================================ Paragraph 90 =================================

Semi-supervised learning 


------------------- Sentence 1 -------------------

 Semi-supervised learning 

Tokens are: 
>> ['Semi-supervised', 'learning'] 

 UPOS tags are: 
>> [('Semi-supervised', 'ADJ'), ('learning', 'NOUN')] 

 XPOS tags are: 
>> [('Semi-supervised', 'JJ'), ('learning', 'NN')] 

 Lemmas are: 
>> [('Semi-supervised', 'semi-supervised'), ('learning', 'learning')] 

 Dependency tags are: 
>> [(('Semi-supervised', 'learning'), 'amod'), (('learning', 'root'), 'root')]

 Named Entites are: 
>> []

================================ Paragraph 91 =================================

Semi-supervised learning is a combination of unsupervised and supervised  learning techniques. With this approach we’ll have both marked-up  supervised content and un-marked data. The machine learning model   uses the marked-up content to generalize and make assertions about   the rest of the data.  


------------------- Sentence 1 -------------------

 Semi-supervised learning is a combination of unsupervised and supervised  learning techniques. 

Tokens are: 
>> ['Semi-supervised', 'learning', 'is', 'a', 'combination', 'of', 'unsupervised', 'and', 'supervised', 'learning', 'techniques', '.'] 

 UPOS tags are: 
>> [('Semi-supervised', 'ADJ'), ('learning', 'NOUN'), ('is', 'AUX'), ('a', 'DET'), ('combination', 'NOUN'), ('of', 'ADP'), ('unsupervised', 'ADJ'), ('and', 'CCONJ'), ('supervised', 'VERB'), ('learning', 'NOUN'), ('techniques', 'NOUN'), ('.', 'PUNCT')] 

 XPOS tags are: 
>> [('Semi-supervised', 'JJ'), ('learning', 'NN'), ('is', 'VBZ'), ('a', 'DT'), ('combination', 'NN'), ('of', 'IN'), ('unsupervised', 'JJ'), ('and', 'CC'), ('supervised', 'VBN'), ('learning', 'NN'), ('techniques', 'NNS'), ('.', '.')] 

 Lemmas are: 
>> [('Semi-supervised', 'semi-supervised'), ('learning', 'learning'), ('is', 'be'), ('a', 'a'), ('combination', 'combination'), ('of', 'of'), ('unsupervised', 'unsupervised'), ('and', 'and'), ('supervised', 'supervise'), ('learning', 'learning'), ('techniques', 'technique'), ('.', '.')] 

 Dependency tags are: 
>> [(('Semi-supervised', 'learning'), 'amod'), (('learning', 'combination'), 'nsubj'), (('is', 'combination'), 'cop'), (('a', 'combination'), 'det'), (('combination', 'root'), 'root'), (('of', 'techniques'), 'case'), (('unsupervised', 'techniques'), 'amod'), (('and', 'supervised'), 'cc'), (('supervised', 'unsupervised'), 'conj'), (('learning', 'techniques'), 'compound'), (('techniques', 'combination'), 'nmod'), (('.', 'combination'), 'punct')]

 Named Entites are: 
>> []

------------------- Sentence 2 -------------------

 With this approach we’ll have both marked-up  supervised content and un-marked data. 

Tokens are: 
>> ['With', 'this', 'approach', 'we', '’ll', 'have', 'both', 'marked', '-', 'up', 'supervised', 'content', 'and', 'un-', 'marked', 'data', '.'] 

 UPOS tags are: 
>> [('With', 'ADP'), ('this', 'DET'), ('approach', 'NOUN'), ('we', 'PRON'), ('’ll', 'AUX'), ('have', 'VERB'), ('both', 'CCONJ'), ('marked', 'VERB'), ('-', 'PUNCT'), ('up', 'ADP'), ('supervised', 'VERB'), ('content', 'NOUN'), ('and', 'CCONJ'), ('un-', 'ADV'), ('marked', 'VERB'), ('data', 'NOUN'), ('.', 'PUNCT')] 

 XPOS tags are: 
>> [('With', 'IN'), ('this', 'DT'), ('approach', 'NN'), ('we', 'PRP'), ('’ll', 'MD'), ('have', 'VB'), ('both', 'CC'), ('marked', 'VBN'), ('-', 'HYPH'), ('up', 'RP'), ('supervised', 'VBN'), ('content', 'NN'), ('and', 'CC'), ('un-', 'RB'), ('marked', 'VBN'), ('data', 'NNS'), ('.', '.')] 

 Lemmas are: 
>> [('With', 'with'), ('this', 'this'), ('approach', 'approach'), ('we', 'we'), ('’ll', 'will'), ('have', 'have'), ('both', 'both'), ('marked', 'mark'), ('-', '-'), ('up', 'up'), ('supervised', 'supervise'), ('content', 'content'), ('and', 'and'), ('un-', 'un-'), ('marked', 'mark'), ('data', 'datum'), ('.', '.')] 

 Dependency tags are: 
>> [(('With', 'approach'), 'case'), (('this', 'approach'), 'det'), (('approach', 'have'), 'obl'), (('we', 'have'), 'nsubj'), (('’ll', 'have'), 'aux'), (('have', 'root'), 'root'), (('both', 'content'), 'cc:preconj'), (('marked', 'content'), 'amod'), (('-', 'marked'), 'punct'), (('up', 'marked'), 'compound:prt'), (('supervised', 'content'), 'amod'), (('content', 'have'), 'obj'), (('and', 'data'), 'cc'), (('un-', 'marked'), 'advmod'), (('marked', 'data'), 'amod'), (('data', 'content'), 'conj'), (('.', 'have'), 'punct')]

 Named Entites are: 
>> []

------------------- Sentence 3 -------------------

 The machine learning model   uses the marked-up content to generalize and make assertions about   the rest of the data. 

Tokens are: 
>> ['The', 'machine', 'learning', 'model', 'uses', 'the', 'marked', '-', 'up', 'content', 'to', 'generalize', 'and', 'make', 'assertions', 'about', 'the', 'rest', 'of', 'the', 'data', '.'] 

 UPOS tags are: 
>> [('The', 'DET'), ('machine', 'NOUN'), ('learning', 'NOUN'), ('model', 'NOUN'), ('uses', 'VERB'), ('the', 'DET'), ('marked', 'VERB'), ('-', 'PUNCT'), ('up', 'ADP'), ('content', 'NOUN'), ('to', 'PART'), ('generalize', 'VERB'), ('and', 'CCONJ'), ('make', 'VERB'), ('assertions', 'NOUN'), ('about', 'ADP'), ('the', 'DET'), ('rest', 'NOUN'), ('of', 'ADP'), ('the', 'DET'), ('data', 'NOUN'), ('.', 'PUNCT')] 

 XPOS tags are: 
>> [('The', 'DT'), ('machine', 'NN'), ('learning', 'NN'), ('model', 'NN'), ('uses', 'VBZ'), ('the', 'DT'), ('marked', 'VBN'), ('-', 'HYPH'), ('up', 'RP'), ('content', 'NN'), ('to', 'TO'), ('generalize', 'VB'), ('and', 'CC'), ('make', 'VB'), ('assertions', 'NNS'), ('about', 'IN'), ('the', 'DT'), ('rest', 'NN'), ('of', 'IN'), ('the', 'DT'), ('data', 'NN'), ('.', '.')] 

 Lemmas are: 
>> [('The', 'the'), ('machine', 'machine'), ('learning', 'learning'), ('model', 'model'), ('uses', 'use'), ('the', 'the'), ('marked', 'mark'), ('-', '-'), ('up', 'up'), ('content', 'content'), ('to', 'to'), ('generalize', 'generalize'), ('and', 'and'), ('make', 'make'), ('assertions', 'assertion'), ('about', 'about'), ('the', 'the'), ('rest', 'rest'), ('of', 'of'), ('the', 'the'), ('data', 'datum'), ('.', '.')] 

 Dependency tags are: 
>> [(('The', 'model'), 'det'), (('machine', 'model'), 'compound'), (('learning', 'model'), 'compound'), (('model', 'uses'), 'nsubj'), (('uses', 'root'), 'root'), (('the', 'content'), 'det'), (('marked', 'content'), 'amod'), (('-', 'up'), 'punct'), (('up', 'marked'), 'compound:prt'), (('content', 'uses'), 'obj'), (('to', 'generalize'), 'mark'), (('generalize', 'content'), 'acl'), (('and', 'make'), 'cc'), (('make', 'generalize'), 'conj'), (('assertions', 'make'), 'obj'), (('about', 'rest'), 'case'), (('the', 'rest'), 'det'), (('rest', 'assertions'), 'nmod'), (('of', 'data'), 'case'), (('the', 'data'), 'det'), (('data', 'rest'), 'nmod'), (('.', 'uses'), 'punct')]

 Named Entites are: 
>> []

================================ Paragraph 92 =================================

Now that we’ve reviewed the machine learning essentials, let’s look at  how to combine machine learning and algorithmic natural language  processing to build a high-performing text analytics AI. 


------------------- Sentence 1 -------------------

 Now that we’ve reviewed the machine learning essentials, let’s look at  how to combine machine learning and algorithmic natural language  processing to build a high-performing text analytics AI. 

Tokens are: 
>> ['Now', 'that', 'we', '’ve', 'reviewed', 'the', 'machine', 'learning', 'essentials', ',', 'let', '’s', 'look', 'at', 'how', 'to', 'combine', 'machine', 'learning', 'and', 'algorithmic', 'natural', 'language', 'processing', 'to', 'build', 'a', 'high', '-', 'performing', 'text', 'analytics', 'AI', '.'] 

 UPOS tags are: 
>> [('Now', 'ADV'), ('that', 'SCONJ'), ('we', 'PRON'), ('’ve', 'AUX'), ('reviewed', 'VERB'), ('the', 'DET'), ('machine', 'NOUN'), ('learning', 'NOUN'), ('essentials', 'NOUN'), (',', 'PUNCT'), ('let', 'VERB'), ('’s', 'PRON'), ('look', 'VERB'), ('at', 'ADP'), ('how', 'SCONJ'), ('to', 'PART'), ('combine', 'VERB'), ('machine', 'NOUN'), ('learning', 'NOUN'), ('and', 'CCONJ'), ('algorithmic', 'ADJ'), ('natural', 'ADJ'), ('language', 'NOUN'), ('processing', 'NOUN'), ('to', 'PART'), ('build', 'VERB'), ('a', 'DET'), ('high', 'ADJ'), ('-', 'PUNCT'), ('performing', 'VERB'), ('text', 'NOUN'), ('analytics', 'NOUN'), ('AI', 'VERB'), ('.', 'PUNCT')] 

 XPOS tags are: 
>> [('Now', 'RB'), ('that', 'IN'), ('we', 'PRP'), ('’ve', 'VBP'), ('reviewed', 'VBN'), ('the', 'DT'), ('machine', 'NN'), ('learning', 'NN'), ('essentials', 'NNS'), (',', ','), ('let', 'VB'), ('’s', 'PRP'), ('look', 'VB'), ('at', 'IN'), ('how', 'WRB'), ('to', 'TO'), ('combine', 'VB'), ('machine', 'NN'), ('learning', 'NN'), ('and', 'CC'), ('algorithmic', 'JJ'), ('natural', 'JJ'), ('language', 'NN'), ('processing', 'NN'), ('to', 'TO'), ('build', 'VB'), ('a', 'DT'), ('high', 'JJ'), ('-', 'HYPH'), ('performing', 'VBG'), ('text', 'NN'), ('analytics', 'NN'), ('AI', 'VBZ'), ('.', '.')] 

 Lemmas are: 
>> [('Now', 'now'), ('that', 'that'), ('we', 'we'), ('’ve', 'have'), ('reviewed', 'review'), ('the', 'the'), ('machine', 'machine'), ('learning', 'learning'), ('essentials', 'essential'), (',', ','), ('let', 'let'), ('’s', 'us'), ('look', 'look'), ('at', 'at'), ('how', 'how'), ('to', 'to'), ('combine', 'combine'), ('machine', 'machine'), ('learning', 'learning'), ('and', 'and'), ('algorithmic', 'algorithmic'), ('natural', 'natural'), ('language', 'language'), ('processing', 'processing'), ('to', 'to'), ('build', 'build'), ('a', 'a'), ('high', 'high'), ('-', '-'), ('performing', 'perform'), ('text', 'text'), ('analytics', 'analytic'), ('AI', 'be'), ('.', '.')] 

 Dependency tags are: 
>> [(('Now', 'let'), 'advmod'), (('that', 'reviewed'), 'mark'), (('we', 'reviewed'), 'nsubj'), (('’ve', 'reviewed'), 'aux'), (('reviewed', 'Now'), 'ccomp'), (('the', 'essentials'), 'det'), (('machine', 'essentials'), 'compound'), (('learning', 'essentials'), 'compound'), (('essentials', 'reviewed'), 'obj'), ((',', 'let'), 'punct'), (('let', 'root'), 'root'), (('’s', 'let'), 'obj'), (('look', 'let'), 'xcomp'), (('at', 'how'), 'case'), (('how', 'combine'), 'mark'), (('to', 'combine'), 'mark'), (('combine', 'look'), 'advcl'), (('machine', 'learning'), 'compound'), (('learning', 'processing'), 'compound'), (('and', 'algorithmic'), 'cc'), (('algorithmic', 'learning'), 'conj'), (('natural', 'language'), 'amod'), (('language', 'processing'), 'compound'), (('processing', 'combine'), 'obj'), (('to', 'build'), 'mark'), (('build', 'processing'), 'acl'), (('a', 'analytics'), 'det'), (('high', 'performing'), 'compound'), (('-', 'performing'), 'punct'), (('performing', 'analytics'), 'amod'), (('text', 'analytics'), 'compound'), (('analytics', 'build'), 'obj'), (('AI', 'build'), 'ccomp'), (('.', 'let'), 'punct')]

 Named Entites are: 
>> []

================================ Paragraph 93 =================================

is the combination   


------------------- Sentence 1 -------------------

 is the combination 

Tokens are: 
>> ['is', 'the', 'combination'] 

 UPOS tags are: 
>> [('is', 'AUX'), ('the', 'DET'), ('combination', 'NOUN')] 

 XPOS tags are: 
>> [('is', 'VBZ'), ('the', 'DT'), ('combination', 'NN')] 

 Lemmas are: 
>> [('is', 'be'), ('the', 'the'), ('combination', 'combination')] 

 Dependency tags are: 
>> [(('is', 'combination'), 'cop'), (('the', 'combination'), 'det'), (('combination', 'root'), 'root')]

 Named Entites are: 
>> []

================================ Paragraph 94 =================================

of unsupervised and  


------------------- Sentence 1 -------------------

 of unsupervised and 

Tokens are: 
>> ['of', 'unsupervised', 'and'] 

 UPOS tags are: 
>> [('of', 'ADP'), ('unsupervised', 'ADJ'), ('and', 'CCONJ')] 

 XPOS tags are: 
>> [('of', 'IN'), ('unsupervised', 'JJ'), ('and', 'CC')] 

 Lemmas are: 
>> [('of', 'of'), ('unsupervised', 'unsupervised'), ('and', 'and')] 

 Dependency tags are: 
>> [(('of', 'unsupervised'), 'case'), (('unsupervised', 'root'), 'root'), (('and', 'unsupervised'), 'cc')]

 Named Entites are: 
>> []

================================ Paragraph 95 =================================

supervised learning. 


------------------- Sentence 1 -------------------

 supervised learning. 

Tokens are: 
>> ['supervised', 'learning', '.'] 

 UPOS tags are: 
>> [('supervised', 'VERB'), ('learning', 'NOUN'), ('.', 'PUNCT')] 

 XPOS tags are: 
>> [('supervised', 'VBN'), ('learning', 'NN'), ('.', '.')] 

 Lemmas are: 
>> [('supervised', 'supervise'), ('learning', 'learning'), ('.', '.')] 

 Dependency tags are: 
>> [(('supervised', 'learning'), 'amod'), (('learning', 'root'), 'root'), (('.', 'learning'), 'punct')]

 Named Entites are: 
>> []

================================ Paragraph 96 =================================

Semi-supervised  learning 


------------------- Sentence 1 -------------------

 Semi-supervised  learning 

Tokens are: 
>> ['Semi-supervised', 'learning'] 

 UPOS tags are: 
>> [('Semi-supervised', 'ADJ'), ('learning', 'NOUN')] 

 XPOS tags are: 
>> [('Semi-supervised', 'JJ'), ('learning', 'NN')] 

 Lemmas are: 
>> [('Semi-supervised', 'semi-supervised'), ('learning', 'learning')] 

 Dependency tags are: 
>> [(('Semi-supervised', 'learning'), 'amod'), (('learning', 'root'), 'root')]

 Named Entites are: 
>> []

================================ Paragraph 97 =================================

is where the machine   


------------------- Sentence 1 -------------------

 is where the machine 

Tokens are: 
>> ['is', 'where', 'the', 'machine'] 

 UPOS tags are: 
>> [('is', 'AUX'), ('where', 'SCONJ'), ('the', 'DET'), ('machine', 'NOUN')] 

 XPOS tags are: 
>> [('is', 'VBZ'), ('where', 'WRB'), ('the', 'DT'), ('machine', 'NN')] 

 Lemmas are: 
>> [('is', 'be'), ('where', 'where'), ('the', 'the'), ('machine', 'machine')] 

 Dependency tags are: 
>> [(('is', 'where'), 'cop'), (('where', 'root'), 'root'), (('the', 'machine'), 'det'), (('machine', 'where'), 'nsubj')]

 Named Entites are: 
>> []

================================ Paragraph 98 =================================

takes content and is told to  


------------------- Sentence 1 -------------------

 takes content and is told to 

Tokens are: 
>> ['takes', 'content', 'and', 'is', 'told', 'to'] 

 UPOS tags are: 
>> [('takes', 'VERB'), ('content', 'NOUN'), ('and', 'CCONJ'), ('is', 'AUX'), ('told', 'VERB'), ('to', 'ADP')] 

 XPOS tags are: 
>> [('takes', 'VBZ'), ('content', 'NN'), ('and', 'CC'), ('is', 'VBZ'), ('told', 'VBN'), ('to', 'IN')] 

 Lemmas are: 
>> [('takes', 'take'), ('content', 'content'), ('and', 'and'), ('is', 'be'), ('told', 'tell'), ('to', 'to')] 

 Dependency tags are: 
>> [(('takes', 'root'), 'root'), (('content', 'takes'), 'obj'), (('and', 'told'), 'cc'), (('is', 'told'), 'aux:pass'), (('told', 'takes'), 'conj'), (('to', 'told'), 'obl')]

 Named Entites are: 
>> []

================================ Paragraph 99 =================================

find patterns within it. 


------------------- Sentence 1 -------------------

 find patterns within it. 

Tokens are: 
>> ['find', 'patterns', 'within', 'it', '.'] 

 UPOS tags are: 
>> [('find', 'VERB'), ('patterns', 'NOUN'), ('within', 'ADP'), ('it', 'PRON'), ('.', 'PUNCT')] 

 XPOS tags are: 
>> [('find', 'VB'), ('patterns', 'NNS'), ('within', 'IN'), ('it', 'PRP'), ('.', '.')] 

 Lemmas are: 
>> [('find', 'find'), ('patterns', 'pattern'), ('within', 'within'), ('it', 'it'), ('.', '.')] 

 Dependency tags are: 
>> [(('find', 'root'), 'root'), (('patterns', 'find'), 'obj'), (('within', 'it'), 'case'), (('it', 'find'), 'obl'), (('.', 'find'), 'punct')]

 Named Entites are: 
>> []

================================ Paragraph 100 =================================

Unsupervised  learning


------------------- Sentence 1 -------------------

 Unsupervised  learning 

Tokens are: 
>> ['Unsupervised', 'learning'] 

 UPOS tags are: 
>> [('Unsupervised', 'VERB'), ('learning', 'NOUN')] 

 XPOS tags are: 
>> [('Unsupervised', 'VBN'), ('learning', 'NN')] 

 Lemmas are: 
>> [('Unsupervised', 'unsupervise'), ('learning', 'learning')] 

 Dependency tags are: 
>> [(('Unsupervised', 'learning'), 'amod'), (('learning', 'root'), 'root')]

 Named Entites are: 
>> []

================================ Paragraph 101 =================================

W H I T E  P A P E R 


------------------- Sentence 1 -------------------

 W H I T E  P A P E R 

Tokens are: 
>> ['W', 'H', 'I', 'T', 'E', 'P', 'A', 'P', 'E', 'R'] 

 UPOS tags are: 
>> [('W', 'PROPN'), ('H', 'PUNCT'), ('I', 'PRON'), ('T', 'AUX'), ('E', 'PROPN'), ('P', 'NOUN'), ('A', 'NOUN'), ('P', 'NOUN'), ('E', 'NOUN'), ('R', 'NOUN')] 

 XPOS tags are: 
>> [('W', 'NNP'), ('H', ','), ('I', 'PRP'), ('T', 'VBP'), ('E', 'NNP'), ('P', 'NN'), ('A', 'NN'), ('P', 'NN'), ('E', 'NN'), ('R', 'NN')] 

 Lemmas are: 
>> [('W', 'W'), ('H', 'H'), ('I', 'I'), ('T', 'T'), ('E', 'E'), ('P', 'p'), ('A', 'a'), ('P', 'p'), ('E', 'e'), ('R', 'R')] 

 Dependency tags are: 
>> [(('W', 'T'), 'vocative'), (('H', 'W'), 'punct'), (('I', 'T'), 'nsubj'), (('T', 'root'), 'root'), (('E', 'T'), 'obj'), (('P', 'T'), 'obj'), (('A', 'E'), 'compound'), (('P', 'E'), 'compound'), (('E', 'R'), 'compound'), (('R', 'T'), 'obj')]

 Named Entites are: 
>> []

================================ Paragraph 102 =================================

7|       |   Lexalytics, Inc., 48 North Pleasant St. Unit 301, Amherst MA 01002 USA   |   1-800-377-8036 |   www.lexalytics.com 


------------------- Sentence 1 -------------------

 7|       |   Lexalytics, Inc., 48 North Pleasant St. Unit 301, Amherst MA 01002 USA   |   1-800-377-8036 |   www.lexalytics.com 

Tokens are: 
>> ['7', '|', '|', 'Lexalytics', ',', 'Inc.', ',', '48', 'North', 'Pleasant', 'St.', 'Unit', '301', ',', 'Amherst', 'MA', '01002', 'USA', '|', '1-800-377-8036', '|', 'www.lexalytics.com'] 

 UPOS tags are: 
>> [('7', 'NUM'), ('|', 'PUNCT'), ('|', 'PUNCT'), ('Lexalytics', 'PROPN'), (',', 'PUNCT'), ('Inc.', 'PROPN'), (',', 'PUNCT'), ('48', 'NUM'), ('North', 'PROPN'), ('Pleasant', 'ADJ'), ('St.', 'PROPN'), ('Unit', 'NOUN'), ('301', 'NUM'), (',', 'PUNCT'), ('Amherst', 'PROPN'), ('MA', 'PROPN'), ('01002', 'NUM'), ('USA', 'PROPN'), ('|', 'PUNCT'), ('1-800-377-8036', 'NUM'), ('|', 'PUNCT'), ('www.lexalytics.com', 'X')] 

 XPOS tags are: 
>> [('7', 'LS'), ('|', 'NFP'), ('|', 'NFP'), ('Lexalytics', 'NNP'), (',', ','), ('Inc.', 'NNP'), (',', ','), ('48', 'CD'), ('North', 'NNP'), ('Pleasant', 'NNP'), ('St.', 'NNP'), ('Unit', 'NN'), ('301', 'CD'), (',', ','), ('Amherst', 'NNP'), ('MA', 'NNP'), ('01002', 'CD'), ('USA', 'NNP'), ('|', 'NFP'), ('1-800-377-8036', 'CD'), ('|', 'NFP'), ('www.lexalytics.com', 'ADD')] 

 Lemmas are: 
>> [('7', '7'), ('|', '|'), ('|', '|'), ('Lexalytics', 'Lexalytics'), (',', ','), ('Inc.', 'Inc.'), (',', ','), ('48', '48'), ('North', 'North'), ('Pleasant', 'Pleasant'), ('St.', 'St.'), ('Unit', 'unit'), ('301', '301'), (',', ','), ('Amherst', 'Amherst'), ('MA', 'MA'), ('01002', '01002'), ('USA', 'USA'), ('|', '|'), ('1-800-377-8036', '1-800-377-8036'), ('|', '|'), ('www.lexalytics.com', 'www.lexalytics.com')] 

 Dependency tags are: 
>> [(('7', 'Inc.'), 'nummod'), (('|', '7'), 'punct'), (('|', '7'), 'punct'), (('Lexalytics', 'Inc.'), 'compound'), ((',', 'Inc.'), 'punct'), (('Inc.', 'root'), 'root'), ((',', 'Inc.'), 'punct'), (('48', 'St.'), 'nummod'), (('North', 'St.'), 'compound'), (('Pleasant', 'St.'), 'amod'), (('St.', 'Inc.'), 'list'), (('Unit', 'St.'), 'appos'), (('301', 'Unit'), 'nummod'), ((',', 'MA'), 'punct'), (('Amherst', 'MA'), 'appos'), (('MA', 'Inc.'), 'list'), (('01002', 'USA'), 'nummod'), (('USA', 'MA'), 'appos'), (('|', 'USA'), 'punct'), (('1-800-377-8036', 'Inc.'), 'list'), (('|', '1-800-377-8036'), 'punct'), (('www.lexalytics.com', 'Inc.'), 'list')]

 Named Entites are: 
>> [('7|       |   Lexalytics, Inc.', 'ORG'), ('301', 'CARDINAL')]

================================ Paragraph 103 =================================

H A P P I E R  B Y  T H E  D O Z E N :   T H E  M O R E  M O D E L S ,  T H E  M E R R I E R  Machine learning models are very good at performing single tasks, such   as determining the sentiment polarity of a document or the part-of-speech  for a given word. However, models are not good at tasks that require layers  of interpretation. Take the following sentence: 


------------------- Sentence 1 -------------------

 H A P P I E R  B Y  T H E  D O Z E N :   T H E  M O R E  M O D E L S ,  T H E  M E R R I E R  Machine learning models are very good at performing single tasks, such   as determining the sentiment polarity of a document or the part-of-speech  for a given word. 

Tokens are: 
>> ['H', 'A', 'P', 'P', 'I', 'E', 'R', 'B', 'Y', 'T', 'H', 'E', 'D', 'O', 'Z', 'E', 'N', ':', 'T', 'H', 'E', 'M', 'O', 'R', 'E', 'M', 'O', 'D', 'E', 'L', 'S', ',', 'T', 'H', 'E', 'M', 'E', 'R', 'R', 'I', 'E', 'R', 'Machine', 'learning', 'models', 'are', 'very', 'good', 'at', 'performing', 'single', 'tasks', ',', 'such', 'as', 'determining', 'the', 'sentiment', 'polarity', 'of', 'a', 'document', 'or', 'the', 'part-of', '-', 'speech', 'for', 'a', 'given', 'word', '.'] 

 UPOS tags are: 
>> [('H', 'NOUN'), ('A', 'DET'), ('P', 'NOUN'), ('P', 'NOUN'), ('I', 'PRON'), ('E', 'NOUN'), ('R', 'NOUN'), ('B', 'NOUN'), ('Y', 'NOUN'), ('T', 'NOUN'), ('H', 'NOUN'), ('E', 'NOUN'), ('D', 'NOUN'), ('O', 'NOUN'), ('Z', 'NOUN'), ('E', 'NOUN'), ('N', 'NOUN'), (':', 'PUNCT'), ('T', 'PUNCT'), ('H', 'PUNCT'), ('E', 'NOUN'), ('M', 'NOUN'), ('O', 'PUNCT'), ('R', 'PUNCT'), ('E', 'NOUN'), ('M', 'NOUN'), ('O', 'NOUN'), ('D', 'NOUN'), ('E', 'NOUN'), ('L', 'PUNCT'), ('S', 'NOUN'), (',', 'PUNCT'), ('T', 'PUNCT'), ('H', 'PUNCT'), ('E', 'NOUN'), ('M', 'PUNCT'), ('E', 'NOUN'), ('R', 'AUX'), ('R', 'PUNCT'), ('I', 'PRON'), ('E', 'NOUN'), ('R', 'NOUN'), ('Machine', 'NOUN'), ('learning', 'NOUN'), ('models', 'NOUN'), ('are', 'AUX'), ('very', 'ADV'), ('good', 'ADJ'), ('at', 'SCONJ'), ('performing', 'VERB'), ('single', 'ADJ'), ('tasks', 'NOUN'), (',', 'PUNCT'), ('such', 'ADJ'), ('as', 'SCONJ'), ('determining', 'VERB'), ('the', 'DET'), ('sentiment', 'NOUN'), ('polarity', 'NOUN'), ('of', 'ADP'), ('a', 'DET'), ('document', 'NOUN'), ('or', 'CCONJ'), ('the', 'DET'), ('part-of', 'NOUN'), ('-', 'PUNCT'), ('speech', 'NOUN'), ('for', 'ADP'), ('a', 'DET'), ('given', 'VERB'), ('word', 'NOUN'), ('.', 'PUNCT')] 

 XPOS tags are: 
>> [('H', 'NN'), ('A', 'DT'), ('P', 'NN'), ('P', 'NN'), ('I', 'PRP'), ('E', 'NN'), ('R', 'NN'), ('B', 'NN'), ('Y', 'NN'), ('T', 'NN'), ('H', 'NN'), ('E', 'NN'), ('D', 'NN'), ('O', 'NN'), ('Z', 'NN'), ('E', 'NN'), ('N', 'NN'), (':', ':'), ('T', ','), ('H', ','), ('E', 'NN'), ('M', 'NN'), ('O', ','), ('R', ','), ('E', 'NN'), ('M', 'NN'), ('O', 'NN'), ('D', 'NN'), ('E', 'NN'), ('L', ','), ('S', 'NNS'), (',', ','), ('T', ','), ('H', ','), ('E', 'NN'), ('M', ','), ('E', 'NN'), ('R', 'VBP'), ('R', ','), ('I', 'PRP'), ('E', 'NN'), ('R', 'NN'), ('Machine', 'NN'), ('learning', 'NN'), ('models', 'NNS'), ('are', 'VBP'), ('very', 'RB'), ('good', 'JJ'), ('at', 'IN'), ('performing', 'VBG'), ('single', 'JJ'), ('tasks', 'NNS'), (',', ','), ('such', 'JJ'), ('as', 'IN'), ('determining', 'VBG'), ('the', 'DT'), ('sentiment', 'NN'), ('polarity', 'NN'), ('of', 'IN'), ('a', 'DT'), ('document', 'NN'), ('or', 'CC'), ('the', 'DT'), ('part-of', 'NN'), ('-', 'HYPH'), ('speech', 'NN'), ('for', 'IN'), ('a', 'DT'), ('given', 'VBN'), ('word', 'NN'), ('.', '.')] 

 Lemmas are: 
>> [('H', 'h'), ('A', 'a'), ('P', 'p'), ('P', 'p'), ('I', 'I'), ('E', 'e'), ('R', 'R'), ('B', 'b'), ('Y', 'Y'), ('T', 'T'), ('H', 'h'), ('E', 'e'), ('D', 'd'), ('O', 'o'), ('Z', 'z'), ('E', 'e'), ('N', 'N'), (':', ':'), ('T', 'T'), ('H', 'H'), ('E', 'e'), ('M', 'm'), ('O', 'o'), ('R', 'R'), ('E', 'e'), ('M', 'm'), ('O', 'o'), ('D', 'd'), ('E', 'e'), ('L', 'L'), ('S', 's'), (',', ','), ('T', 'T'), ('H', 'H'), ('E', 'e'), ('M', 'm'), ('E', 'e'), ('R', 'R'), ('R', 'R'), ('I', 'I'), ('E', 'e'), ('R', 'R'), ('Machine', 'Machine'), ('learning', 'learning'), ('models', 'model'), ('are', 'be'), ('very', 'very'), ('good', 'good'), ('at', 'at'), ('performing', 'perform'), ('single', 'single'), ('tasks', 'task'), (',', ','), ('such', 'such'), ('as', 'as'), ('determining', 'determine'), ('the', 'the'), ('sentiment', 'sentiment'), ('polarity', 'polarity'), ('of', 'of'), ('a', 'a'), ('document', 'document'), ('or', 'or'), ('the', 'the'), ('part-of', 'part-of'), ('-', '-'), ('speech', 'speech'), ('for', 'for'), ('a', 'a'), ('given', 'give'), ('word', 'word'), ('.', '.')] 

 Dependency tags are: 
>> [(('H', 'P'), 'nsubj'), (('A', 'P'), 'det'), (('P', 'P'), 'nsubj'), (('P', 'root'), 'root'), (('I', 'B'), 'nsubj'), (('E', 'B'), 'case'), (('R', 'B'), 'compound'), (('B', 'P'), 'nmod'), (('Y', 'B'), 'obj'), (('T', 'E'), 'compound'), (('H', 'E'), 'compound'), (('E', 'B'), 'nmod'), (('D', 'E'), 'compound'), (('O', 'Z'), 'compound'), (('Z', 'D'), 'compound'), (('E', 'N'), 'compound'), (('N', 'Z'), 'appos'), ((':', 'N'), 'punct'), (('T', 'N'), 'punct'), (('H', 'M'), 'punct'), (('E', 'M'), 'nummod'), (('M', 'N'), 'appos'), (('O', 'M'), 'punct'), (('R', 'M'), 'punct'), (('E', 'M'), 'appos'), (('M', 'E'), 'compound'), (('O', 'M'), 'punct'), (('D', 'E'), 'compound'), (('E', 'M'), 'appos'), (('L', 'E'), 'punct'), (('S', 'M'), 'appos'), ((',', 'P'), 'punct'), (('T', 'E'), 'punct'), (('H', 'E'), 'punct'), (('E', 'P'), 'parataxis'), (('M', 'E'), 'punct'), (('E', 'E'), 'appos'), (('R', 'E'), 'punct'), (('R', 'P'), 'punct'), (('I', 'good'), 'nsubj'), (('E', 'P'), 'parataxis'), (('R', 'models'), 'compound'), (('Machine', 'models'), 'compound'), (('learning', 'models'), 'compound'), (('models', 'good'), 'nsubj'), (('are', 'good'), 'cop'), (('very', 'good'), 'advmod'), (('good', 'E'), 'ccomp'), (('at', 'performing'), 'mark'), (('performing', 'good'), 'advcl'), (('single', 'tasks'), 'amod'), (('tasks', 'performing'), 'obj'), ((',', 'determining'), 'punct'), (('such', 'determining'), 'mark'), (('as', 'such'), 'fixed'), (('determining', 'good'), 'advcl'), (('the', 'polarity'), 'det'), (('sentiment', 'polarity'), 'compound'), (('polarity', 'determining'), 'obj'), (('of', 'document'), 'case'), (('a', 'document'), 'det'), (('document', 'polarity'), 'nmod'), (('or', 'speech'), 'cc'), (('the', 'speech'), 'det'), (('part-of', 'speech'), 'compound'), (('-', 'speech'), 'punct'), (('speech', 'document'), 'conj'), (('for', 'word'), 'case'), (('a', 'word'), 'det'), (('given', 'word'), 'amod'), (('word', 'speech'), 'nmod'), (('.', 'good'), 'punct')]

 Named Entites are: 
>> []

------------------- Sentence 2 -------------------

 However, models are not good at tasks that require layers  of interpretation. 

Tokens are: 
>> ['However', ',', 'models', 'are', 'not', 'good', 'at', 'tasks', 'that', 'require', 'layers', 'of', 'interpretation', '.'] 

 UPOS tags are: 
>> [('However', 'ADV'), (',', 'PUNCT'), ('models', 'NOUN'), ('are', 'AUX'), ('not', 'PART'), ('good', 'ADJ'), ('at', 'ADP'), ('tasks', 'NOUN'), ('that', 'PRON'), ('require', 'VERB'), ('layers', 'NOUN'), ('of', 'ADP'), ('interpretation', 'NOUN'), ('.', 'PUNCT')] 

 XPOS tags are: 
>> [('However', 'RB'), (',', ','), ('models', 'NNS'), ('are', 'VBP'), ('not', 'RB'), ('good', 'JJ'), ('at', 'IN'), ('tasks', 'NNS'), ('that', 'WDT'), ('require', 'VBP'), ('layers', 'NNS'), ('of', 'IN'), ('interpretation', 'NN'), ('.', '.')] 

 Lemmas are: 
>> [('However', 'however'), (',', ','), ('models', 'model'), ('are', 'be'), ('not', 'not'), ('good', 'good'), ('at', 'at'), ('tasks', 'task'), ('that', 'that'), ('require', 'require'), ('layers', 'layer'), ('of', 'of'), ('interpretation', 'interpretation'), ('.', '.')] 

 Dependency tags are: 
>> [(('However', 'good'), 'advmod'), ((',', 'good'), 'punct'), (('models', 'good'), 'nsubj'), (('are', 'good'), 'cop'), (('not', 'good'), 'advmod'), (('good', 'root'), 'root'), (('at', 'tasks'), 'case'), (('tasks', 'good'), 'obl'), (('that', 'require'), 'nsubj'), (('require', 'tasks'), 'acl:relcl'), (('layers', 'require'), 'obj'), (('of', 'interpretation'), 'case'), (('interpretation', 'layers'), 'nmod'), (('.', 'good'), 'punct')]

 Named Entites are: 
>> []

------------------- Sentence 3 -------------------

 Take the following sentence: 

Tokens are: 
>> ['Take', 'the', 'following', 'sentence', ':'] 

 UPOS tags are: 
>> [('Take', 'VERB'), ('the', 'DET'), ('following', 'VERB'), ('sentence', 'NOUN'), (':', 'PUNCT')] 

 XPOS tags are: 
>> [('Take', 'VB'), ('the', 'DT'), ('following', 'VBG'), ('sentence', 'NN'), (':', ':')] 

 Lemmas are: 
>> [('Take', 'take'), ('the', 'the'), ('following', 'follow'), ('sentence', 'sentence'), (':', ':')] 

 Dependency tags are: 
>> [(('Take', 'root'), 'root'), (('the', 'sentence'), 'det'), (('following', 'sentence'), 'amod'), (('sentence', 'Take'), 'obj'), ((':', 'Take'), 'punct')]

 Named Entites are: 
>> []

================================ Paragraph 104 =================================

“Lexalytics is the best text analytics company ever.”  


------------------- Sentence 1 -------------------

 “Lexalytics is the best text analytics company ever.” 

Tokens are: 
>> ['“', 'Lexalytics', 'is', 'the', 'best', 'text', 'analytics', 'company', 'ever', '.', '”'] 

 UPOS tags are: 
>> [('“', 'PUNCT'), ('Lexalytics', 'NOUN'), ('is', 'AUX'), ('the', 'DET'), ('best', 'ADJ'), ('text', 'NOUN'), ('analytics', 'NOUN'), ('company', 'NOUN'), ('ever', 'ADV'), ('.', 'PUNCT'), ('”', 'PUNCT')] 

 XPOS tags are: 
>> [('“', '``'), ('Lexalytics', 'NNS'), ('is', 'VBZ'), ('the', 'DT'), ('best', 'JJS'), ('text', 'NN'), ('analytics', 'NN'), ('company', 'NN'), ('ever', 'RB'), ('.', '.'), ('”', "''")] 

 Lemmas are: 
>> [('“', "''"), ('Lexalytics', 'lexalytics'), ('is', 'be'), ('the', 'the'), ('best', 'good'), ('text', 'text'), ('analytics', 'analytic'), ('company', 'company'), ('ever', 'ever'), ('.', '.'), ('”', "''")] 

 Dependency tags are: 
>> [(('“', 'company'), 'punct'), (('Lexalytics', 'company'), 'nsubj'), (('is', 'company'), 'cop'), (('the', 'company'), 'det'), (('best', 'company'), 'amod'), (('text', 'analytics'), 'compound'), (('analytics', 'company'), 'compound'), (('company', 'root'), 'root'), (('ever', 'company'), 'advmod'), (('.', 'company'), 'punct'), (('”', 'company'), 'punct')]

 Named Entites are: 
>> [('Lexalytics', 'ORG')]

================================ Paragraph 105 =================================

Besides agreeing with its obvious truth, what might we want to know   about this sentence? First, we want to know whether it contains any   entities (companies, people, products and so on). Second, we want to   know whether there’s any sentiment associated with those entities.   Third, we want to know whether a particular industry is being discussed.  Finally, we might ask whether any sentiment is being expressed   towards that industry. 


------------------- Sentence 1 -------------------

 Besides agreeing with its obvious truth, what might we want to know   about this sentence? 

Tokens are: 
>> ['Besides', 'agreeing', 'with', 'its', 'obvious', 'truth', ',', 'what', 'might', 'we', 'want', 'to', 'know', 'about', 'this', 'sentence', '?'] 

 UPOS tags are: 
>> [('Besides', 'SCONJ'), ('agreeing', 'VERB'), ('with', 'ADP'), ('its', 'PRON'), ('obvious', 'ADJ'), ('truth', 'NOUN'), (',', 'PUNCT'), ('what', 'PRON'), ('might', 'AUX'), ('we', 'PRON'), ('want', 'VERB'), ('to', 'PART'), ('know', 'VERB'), ('about', 'ADP'), ('this', 'DET'), ('sentence', 'NOUN'), ('?', 'PUNCT')] 

 XPOS tags are: 
>> [('Besides', 'IN'), ('agreeing', 'VBG'), ('with', 'IN'), ('its', 'PRP$'), ('obvious', 'JJ'), ('truth', 'NN'), (',', ','), ('what', 'WP'), ('might', 'MD'), ('we', 'PRP'), ('want', 'VB'), ('to', 'TO'), ('know', 'VB'), ('about', 'IN'), ('this', 'DT'), ('sentence', 'NN'), ('?', '.')] 

 Lemmas are: 
>> [('Besides', 'besides'), ('agreeing', 'agree'), ('with', 'with'), ('its', 'its'), ('obvious', 'obvious'), ('truth', 'truth'), (',', ','), ('what', 'what'), ('might', 'might'), ('we', 'we'), ('want', 'want'), ('to', 'to'), ('know', 'know'), ('about', 'about'), ('this', 'this'), ('sentence', 'sentence'), ('?', '?')] 

 Dependency tags are: 
>> [(('Besides', 'agreeing'), 'mark'), (('agreeing', 'want'), 'advcl'), (('with', 'truth'), 'case'), (('its', 'truth'), 'nmod:poss'), (('obvious', 'truth'), 'amod'), (('truth', 'agreeing'), 'obl'), ((',', 'want'), 'punct'), (('what', 'know'), 'obj'), (('might', 'want'), 'aux'), (('we', 'want'), 'nsubj'), (('want', 'root'), 'root'), (('to', 'know'), 'mark'), (('know', 'want'), 'xcomp'), (('about', 'sentence'), 'case'), (('this', 'sentence'), 'det'), (('sentence', 'know'), 'obl'), (('?', 'want'), 'punct')]

 Named Entites are: 
>> []

------------------- Sentence 2 -------------------

 First, we want to know whether it contains any   entities (companies, people, products and so on). 

Tokens are: 
>> ['First', ',', 'we', 'want', 'to', 'know', 'whether', 'it', 'contains', 'any', 'entities', '(', 'companies', ',', 'people', ',', 'products', 'and', 'so', 'on', ')', '.'] 

 UPOS tags are: 
>> [('First', 'ADV'), (',', 'PUNCT'), ('we', 'PRON'), ('want', 'VERB'), ('to', 'PART'), ('know', 'VERB'), ('whether', 'SCONJ'), ('it', 'PRON'), ('contains', 'VERB'), ('any', 'DET'), ('entities', 'NOUN'), ('(', 'PUNCT'), ('companies', 'NOUN'), (',', 'PUNCT'), ('people', 'NOUN'), (',', 'PUNCT'), ('products', 'NOUN'), ('and', 'CCONJ'), ('so', 'ADV'), ('on', 'ADV'), (')', 'PUNCT'), ('.', 'PUNCT')] 

 XPOS tags are: 
>> [('First', 'RB'), (',', ','), ('we', 'PRP'), ('want', 'VBP'), ('to', 'TO'), ('know', 'VB'), ('whether', 'IN'), ('it', 'PRP'), ('contains', 'VBZ'), ('any', 'DT'), ('entities', 'NNS'), ('(', '-LRB-'), ('companies', 'NNS'), (',', ','), ('people', 'NNS'), (',', ','), ('products', 'NNS'), ('and', 'CC'), ('so', 'RB'), ('on', 'RB'), (')', '-RRB-'), ('.', '.')] 

 Lemmas are: 
>> [('First', 'first'), (',', ','), ('we', 'we'), ('want', 'want'), ('to', 'to'), ('know', 'know'), ('whether', 'whether'), ('it', 'it'), ('contains', 'contain'), ('any', 'any'), ('entities', 'entity'), ('(', '('), ('companies', 'company'), (',', ','), ('people', 'people'), (',', ','), ('products', 'product'), ('and', 'and'), ('so', 'so'), ('on', 'on'), (')', ')'), ('.', '.')] 

 Dependency tags are: 
>> [(('First', 'want'), 'advmod'), ((',', 'want'), 'punct'), (('we', 'want'), 'nsubj'), (('want', 'root'), 'root'), (('to', 'know'), 'mark'), (('know', 'want'), 'xcomp'), (('whether', 'contains'), 'mark'), (('it', 'contains'), 'nsubj'), (('contains', 'know'), 'ccomp'), (('any', 'entities'), 'det'), (('entities', 'contains'), 'obj'), (('(', 'companies'), 'punct'), (('companies', 'entities'), 'appos'), ((',', 'people'), 'punct'), (('people', 'companies'), 'conj'), ((',', 'products'), 'punct'), (('products', 'companies'), 'conj'), (('and', 'so'), 'cc'), (('so', 'on'), 'advmod'), (('on', 'companies'), 'conj'), ((')', 'companies'), 'punct'), (('.', 'want'), 'punct')]

 Named Entites are: 
>> [('First', 'ORDINAL')]

------------------- Sentence 3 -------------------

 Second, we want to   know whether there’s any sentiment associated with those entities. 

Tokens are: 
>> ['Second', ',', 'we', 'want', 'to', 'know', 'whether', 'there', '’s', 'any', 'sentiment', 'associated', 'with', 'those', 'entities', '.'] 

 UPOS tags are: 
>> [('Second', 'ADV'), (',', 'PUNCT'), ('we', 'PRON'), ('want', 'VERB'), ('to', 'PART'), ('know', 'VERB'), ('whether', 'SCONJ'), ('there', 'PRON'), ('’s', 'VERB'), ('any', 'DET'), ('sentiment', 'NOUN'), ('associated', 'VERB'), ('with', 'ADP'), ('those', 'DET'), ('entities', 'NOUN'), ('.', 'PUNCT')] 

 XPOS tags are: 
>> [('Second', 'RB'), (',', ','), ('we', 'PRP'), ('want', 'VBP'), ('to', 'TO'), ('know', 'VB'), ('whether', 'IN'), ('there', 'EX'), ('’s', 'VBZ'), ('any', 'DT'), ('sentiment', 'NN'), ('associated', 'VBN'), ('with', 'IN'), ('those', 'DT'), ('entities', 'NNS'), ('.', '.')] 

 Lemmas are: 
>> [('Second', 'second'), (',', ','), ('we', 'we'), ('want', 'want'), ('to', 'to'), ('know', 'know'), ('whether', 'whether'), ('there', 'there'), ('’s', 'be'), ('any', 'any'), ('sentiment', 'sentiment'), ('associated', 'associate'), ('with', 'with'), ('those', 'that'), ('entities', 'entity'), ('.', '.')] 

 Dependency tags are: 
>> [(('Second', 'want'), 'advmod'), ((',', 'want'), 'punct'), (('we', 'want'), 'nsubj'), (('want', 'root'), 'root'), (('to', 'know'), 'mark'), (('know', 'want'), 'xcomp'), (('whether', '’s'), 'mark'), (('there', '’s'), 'expl'), (('’s', 'know'), 'ccomp'), (('any', 'sentiment'), 'det'), (('sentiment', '’s'), 'nsubj'), (('associated', 'sentiment'), 'acl'), (('with', 'entities'), 'case'), (('those', 'entities'), 'det'), (('entities', 'associated'), 'obl'), (('.', 'want'), 'punct')]

 Named Entites are: 
>> [('Second', 'ORDINAL')]

------------------- Sentence 4 -------------------

 Third, we want to know whether a particular industry is being discussed. 

Tokens are: 
>> ['Third', ',', 'we', 'want', 'to', 'know', 'whether', 'a', 'particular', 'industry', 'is', 'being', 'discussed', '.'] 

 UPOS tags are: 
>> [('Third', 'ADV'), (',', 'PUNCT'), ('we', 'PRON'), ('want', 'VERB'), ('to', 'PART'), ('know', 'VERB'), ('whether', 'SCONJ'), ('a', 'DET'), ('particular', 'ADJ'), ('industry', 'NOUN'), ('is', 'AUX'), ('being', 'AUX'), ('discussed', 'VERB'), ('.', 'PUNCT')] 

 XPOS tags are: 
>> [('Third', 'RB'), (',', ','), ('we', 'PRP'), ('want', 'VBP'), ('to', 'TO'), ('know', 'VB'), ('whether', 'IN'), ('a', 'DT'), ('particular', 'JJ'), ('industry', 'NN'), ('is', 'VBZ'), ('being', 'VBG'), ('discussed', 'VBN'), ('.', '.')] 

 Lemmas are: 
>> [('Third', 'third'), (',', ','), ('we', 'we'), ('want', 'want'), ('to', 'to'), ('know', 'know'), ('whether', 'whether'), ('a', 'a'), ('particular', 'particular'), ('industry', 'industry'), ('is', 'be'), ('being', 'be'), ('discussed', 'discuss'), ('.', '.')] 

 Dependency tags are: 
>> [(('Third', 'want'), 'advmod'), ((',', 'want'), 'punct'), (('we', 'want'), 'nsubj'), (('want', 'root'), 'root'), (('to', 'know'), 'mark'), (('know', 'want'), 'xcomp'), (('whether', 'discussed'), 'mark'), (('a', 'industry'), 'det'), (('particular', 'industry'), 'amod'), (('industry', 'discussed'), 'nsubj:pass'), (('is', 'discussed'), 'aux'), (('being', 'discussed'), 'aux:pass'), (('discussed', 'know'), 'ccomp'), (('.', 'want'), 'punct')]

 Named Entites are: 
>> [('Third', 'ORDINAL')]

------------------- Sentence 5 -------------------

 Finally, we might ask whether any sentiment is being expressed   towards that industry. 

Tokens are: 
>> ['Finally', ',', 'we', 'might', 'ask', 'whether', 'any', 'sentiment', 'is', 'being', 'expressed', 'towards', 'that', 'industry', '.'] 

 UPOS tags are: 
>> [('Finally', 'ADV'), (',', 'PUNCT'), ('we', 'PRON'), ('might', 'AUX'), ('ask', 'VERB'), ('whether', 'SCONJ'), ('any', 'DET'), ('sentiment', 'NOUN'), ('is', 'AUX'), ('being', 'AUX'), ('expressed', 'VERB'), ('towards', 'ADP'), ('that', 'DET'), ('industry', 'NOUN'), ('.', 'PUNCT')] 

 XPOS tags are: 
>> [('Finally', 'RB'), (',', ','), ('we', 'PRP'), ('might', 'MD'), ('ask', 'VB'), ('whether', 'IN'), ('any', 'DT'), ('sentiment', 'NN'), ('is', 'VBZ'), ('being', 'VBG'), ('expressed', 'VBN'), ('towards', 'IN'), ('that', 'DT'), ('industry', 'NN'), ('.', '.')] 

 Lemmas are: 
>> [('Finally', 'finally'), (',', ','), ('we', 'we'), ('might', 'might'), ('ask', 'ask'), ('whether', 'whether'), ('any', 'any'), ('sentiment', 'sentiment'), ('is', 'be'), ('being', 'be'), ('expressed', 'express'), ('towards', 'towards'), ('that', 'that'), ('industry', 'industry'), ('.', '.')] 

 Dependency tags are: 
>> [(('Finally', 'ask'), 'advmod'), ((',', 'ask'), 'punct'), (('we', 'ask'), 'nsubj'), (('might', 'ask'), 'aux'), (('ask', 'root'), 'root'), (('whether', 'expressed'), 'mark'), (('any', 'sentiment'), 'det'), (('sentiment', 'expressed'), 'nsubj:pass'), (('is', 'expressed'), 'aux'), (('being', 'expressed'), 'aux:pass'), (('expressed', 'ask'), 'ccomp'), (('towards', 'industry'), 'case'), (('that', 'industry'), 'det'), (('industry', 'expressed'), 'obl'), (('.', 'ask'), 'punct')]

 Named Entites are: 
>> []

================================ Paragraph 106 =================================

One single machine learning model can’t do all of that. You’ll need at least  four separate models:  


------------------- Sentence 1 -------------------

 One single machine learning model can’t do all of that. 

Tokens are: 
>> ['One', 'single', 'machine', 'learning', 'model', 'ca', 'n’t', 'do', 'all', 'of', 'that', '.'] 

 UPOS tags are: 
>> [('One', 'NUM'), ('single', 'ADJ'), ('machine', 'NOUN'), ('learning', 'NOUN'), ('model', 'NOUN'), ('ca', 'AUX'), ('n’t', 'PART'), ('do', 'VERB'), ('all', 'DET'), ('of', 'ADP'), ('that', 'PRON'), ('.', 'PUNCT')] 

 XPOS tags are: 
>> [('One', 'CD'), ('single', 'JJ'), ('machine', 'NN'), ('learning', 'NN'), ('model', 'NN'), ('ca', 'MD'), ('n’t', 'RB'), ('do', 'VB'), ('all', 'DT'), ('of', 'IN'), ('that', 'DT'), ('.', '.')] 

 Lemmas are: 
>> [('One', 'one'), ('single', 'single'), ('machine', 'machine'), ('learning', 'learning'), ('model', 'model'), ('ca', 'can'), ('n’t', 'not'), ('do', 'do'), ('all', 'all'), ('of', 'of'), ('that', 'that'), ('.', '.')] 

 Dependency tags are: 
>> [(('One', 'model'), 'nummod'), (('single', 'model'), 'amod'), (('machine', 'model'), 'compound'), (('learning', 'model'), 'compound'), (('model', 'do'), 'nsubj'), (('ca', 'do'), 'aux'), (('n’t', 'do'), 'advmod'), (('do', 'root'), 'root'), (('all', 'do'), 'obj'), (('of', 'that'), 'case'), (('that', 'all'), 'nmod'), (('.', 'do'), 'punct')]

 Named Entites are: 
>> [('One', 'CARDINAL')]

------------------- Sentence 2 -------------------

 You’ll need at least  four separate models: 

Tokens are: 
>> ['You', '’ll', 'need', 'at', 'least', 'four', 'separate', 'models', ':'] 

 UPOS tags are: 
>> [('You', 'PRON'), ('’ll', 'AUX'), ('need', 'VERB'), ('at', 'ADP'), ('least', 'ADJ'), ('four', 'NUM'), ('separate', 'ADJ'), ('models', 'NOUN'), (':', 'PUNCT')] 

 XPOS tags are: 
>> [('You', 'PRP'), ('’ll', 'MD'), ('need', 'VB'), ('at', 'IN'), ('least', 'JJS'), ('four', 'CD'), ('separate', 'JJ'), ('models', 'NNS'), (':', ':')] 

 Lemmas are: 
>> [('You', 'you'), ('’ll', 'will'), ('need', 'need'), ('at', 'at'), ('least', 'least'), ('four', 'four'), ('separate', 'separate'), ('models', 'model'), (':', ':')] 

 Dependency tags are: 
>> [(('You', 'need'), 'nsubj'), (('’ll', 'need'), 'aux'), (('need', 'root'), 'root'), (('at', 'least'), 'case'), (('least', 'four'), 'nmod'), (('four', 'models'), 'nummod'), (('separate', 'models'), 'amod'), (('models', 'need'), 'obj'), ((':', 'need'), 'punct')]

 Named Entites are: 
>> [('at least  four', 'CARDINAL')]

================================ Paragraph 107 =================================

Identify and name any entities (Lexalytics)  


------------------- Sentence 1 -------------------

 Identify and name any entities (Lexalytics) 

Tokens are: 
>> ['Identify', 'and', 'name', 'any', 'entities', '(', 'Lexalytics', ')'] 

 UPOS tags are: 
>> [('Identify', 'VERB'), ('and', 'CCONJ'), ('name', 'VERB'), ('any', 'DET'), ('entities', 'NOUN'), ('(', 'PUNCT'), ('Lexalytics', 'PROPN'), (')', 'PUNCT')] 

 XPOS tags are: 
>> [('Identify', 'VB'), ('and', 'CC'), ('name', 'VB'), ('any', 'DT'), ('entities', 'NNS'), ('(', '-LRB-'), ('Lexalytics', 'NNPS'), (')', '-RRB-')] 

 Lemmas are: 
>> [('Identify', 'identify'), ('and', 'and'), ('name', 'name'), ('any', 'any'), ('entities', 'entity'), ('(', '('), ('Lexalytics', 'Lexalytics'), (')', ')')] 

 Dependency tags are: 
>> [(('Identify', 'root'), 'root'), (('and', 'name'), 'cc'), (('name', 'Identify'), 'conj'), (('any', 'entities'), 'det'), (('entities', 'name'), 'obj'), (('(', 'Lexalytics'), 'punct'), (('Lexalytics', 'entities'), 'appos'), ((')', 'Lexalytics'), 'punct')]

 Named Entites are: 
>> []

================================ Paragraph 108 =================================

Determine the sentiment associated with that entity (positive)  


------------------- Sentence 1 -------------------

 Determine the sentiment associated with that entity (positive) 

Tokens are: 
>> ['Determine', 'the', 'sentiment', 'associated', 'with', 'that', 'entity', '(', 'positive', ')'] 

 UPOS tags are: 
>> [('Determine', 'VERB'), ('the', 'DET'), ('sentiment', 'NOUN'), ('associated', 'VERB'), ('with', 'ADP'), ('that', 'DET'), ('entity', 'NOUN'), ('(', 'PUNCT'), ('positive', 'ADJ'), (')', 'PUNCT')] 

 XPOS tags are: 
>> [('Determine', 'VB'), ('the', 'DT'), ('sentiment', 'NN'), ('associated', 'VBN'), ('with', 'IN'), ('that', 'DT'), ('entity', 'NN'), ('(', '-LRB-'), ('positive', 'JJ'), (')', '-RRB-')] 

 Lemmas are: 
>> [('Determine', 'determine'), ('the', 'the'), ('sentiment', 'sentiment'), ('associated', 'associate'), ('with', 'with'), ('that', 'that'), ('entity', 'entity'), ('(', '('), ('positive', 'positive'), (')', ')')] 

 Dependency tags are: 
>> [(('Determine', 'root'), 'root'), (('the', 'sentiment'), 'det'), (('sentiment', 'Determine'), 'obj'), (('associated', 'sentiment'), 'acl'), (('with', 'entity'), 'case'), (('that', 'entity'), 'det'), (('entity', 'associated'), 'obl'), (('(', 'positive'), 'punct'), (('positive', 'entity'), 'amod'), ((')', 'positive'), 'punct')]

 Named Entites are: 
>> []

================================ Paragraph 109 =================================

Industry classification (text analytics)  


------------------- Sentence 1 -------------------

 Industry classification (text analytics) 

Tokens are: 
>> ['Industry', 'classification', '(', 'text', 'analytics', ')'] 

 UPOS tags are: 
>> [('Industry', 'NOUN'), ('classification', 'NOUN'), ('(', 'PUNCT'), ('text', 'NOUN'), ('analytics', 'NOUN'), (')', 'PUNCT')] 

 XPOS tags are: 
>> [('Industry', 'NN'), ('classification', 'NN'), ('(', '-LRB-'), ('text', 'NN'), ('analytics', 'NNS'), (')', '-RRB-')] 

 Lemmas are: 
>> [('Industry', 'Industry'), ('classification', 'classification'), ('(', '('), ('text', 'text'), ('analytics', 'analytic'), (')', ')')] 

 Dependency tags are: 
>> [(('Industry', 'classification'), 'compound'), (('classification', 'root'), 'root'), (('(', 'analytics'), 'punct'), (('text', 'analytics'), 'compound'), (('analytics', 'classification'), 'appos'), ((')', 'analytics'), 'punct')]

 Named Entites are: 
>> []

================================ Paragraph 110 =================================

Industry sentiment (neutral) 


------------------- Sentence 1 -------------------

 Industry sentiment (neutral) 

Tokens are: 
>> ['Industry', 'sentiment', '(', 'neutral', ')'] 

 UPOS tags are: 
>> [('Industry', 'NOUN'), ('sentiment', 'NOUN'), ('(', 'PUNCT'), ('neutral', 'ADJ'), (')', 'PUNCT')] 

 XPOS tags are: 
>> [('Industry', 'NN'), ('sentiment', 'NN'), ('(', '-LRB-'), ('neutral', 'JJ'), (')', '-RRB-')] 

 Lemmas are: 
>> [('Industry', 'Industry'), ('sentiment', 'sentiment'), ('(', '('), ('neutral', 'neutral'), (')', ')')] 

 Dependency tags are: 
>> [(('Industry', 'sentiment'), 'compound'), (('sentiment', 'root'), 'root'), (('(', 'neutral'), 'punct'), (('neutral', 'sentiment'), 'amod'), ((')', 'neutral'), 'punct')]

 Named Entites are: 
>> []

================================ Paragraph 111 =================================

If you just train a single model, you can only solve #1 or #3. Calculating the  sentiment needed for #2 or #4 requires first knowing which entity you’re  trying to associate the sentiment with. If you only have a single model for  sentiment, you’ll end up rating the whole sentence as positive. Additionally,  if you’re only using keywords to look for the term “text analytics,” you’ll rate  this sentence as positive for that phrase, which isn’t true. Depending on what’s optimal for  


------------------- Sentence 1 -------------------

 If you just train a single model, you can only solve #1 or #3. 

Tokens are: 
>> ['If', 'you', 'just', 'train', 'a', 'single', 'model', ',', 'you', 'can', 'only', 'solve', '#', '1', 'or', '#', '3', '.'] 

 UPOS tags are: 
>> [('If', 'SCONJ'), ('you', 'PRON'), ('just', 'ADV'), ('train', 'VERB'), ('a', 'DET'), ('single', 'ADJ'), ('model', 'NOUN'), (',', 'PUNCT'), ('you', 'PRON'), ('can', 'AUX'), ('only', 'ADV'), ('solve', 'VERB'), ('#', 'SYM'), ('1', 'NUM'), ('or', 'CCONJ'), ('#', 'SYM'), ('3', 'NUM'), ('.', 'PUNCT')] 

 XPOS tags are: 
>> [('If', 'IN'), ('you', 'PRP'), ('just', 'RB'), ('train', 'VBP'), ('a', 'DT'), ('single', 'JJ'), ('model', 'NN'), (',', ','), ('you', 'PRP'), ('can', 'MD'), ('only', 'RB'), ('solve', 'VB'), ('#', 'NN'), ('1', 'CD'), ('or', 'CC'), ('#', 'NN'), ('3', 'CD'), ('.', '.')] 

 Lemmas are: 
>> [('If', 'if'), ('you', 'you'), ('just', 'just'), ('train', 'train'), ('a', 'a'), ('single', 'single'), ('model', 'model'), (',', ','), ('you', 'you'), ('can', 'can'), ('only', 'only'), ('solve', 'solve'), ('#', '#'), ('1', '1'), ('or', 'or'), ('#', '#'), ('3', '3'), ('.', '.')] 

 Dependency tags are: 
>> [(('If', 'train'), 'mark'), (('you', 'train'), 'nsubj'), (('just', 'train'), 'advmod'), (('train', 'solve'), 'advcl'), (('a', 'model'), 'det'), (('single', 'model'), 'amod'), (('model', 'train'), 'obj'), ((',', 'solve'), 'punct'), (('you', 'solve'), 'nsubj'), (('can', 'solve'), 'aux'), (('only', 'solve'), 'advmod'), (('solve', 'root'), 'root'), (('#', 'solve'), 'obj'), (('1', '#'), 'nummod'), (('or', '#'), 'cc'), (('#', '1'), 'conj'), (('3', '#'), 'nummod'), (('.', 'solve'), 'punct')]

 Named Entites are: 
>> [('1', 'CARDINAL'), ('#3', 'CARDINAL')]

------------------- Sentence 2 -------------------

 Calculating the  sentiment needed for #2 or #4 requires first knowing which entity you’re  trying to associate the sentiment with. 

Tokens are: 
>> ['Calculating', 'the', 'sentiment', 'needed', 'for', '#', '2', 'or', '#', '4', 'requires', 'first', 'knowing', 'which', 'entity', 'you', '’re', 'trying', 'to', 'associate', 'the', 'sentiment', 'with', '.'] 

 UPOS tags are: 
>> [('Calculating', 'VERB'), ('the', 'DET'), ('sentiment', 'NOUN'), ('needed', 'VERB'), ('for', 'ADP'), ('#', 'SYM'), ('2', 'NUM'), ('or', 'CCONJ'), ('#', 'SYM'), ('4', 'NUM'), ('requires', 'VERB'), ('first', 'ADV'), ('knowing', 'VERB'), ('which', 'DET'), ('entity', 'NOUN'), ('you', 'PRON'), ('’re', 'AUX'), ('trying', 'VERB'), ('to', 'PART'), ('associate', 'VERB'), ('the', 'DET'), ('sentiment', 'NOUN'), ('with', 'ADP'), ('.', 'PUNCT')] 

 XPOS tags are: 
>> [('Calculating', 'VBG'), ('the', 'DT'), ('sentiment', 'NN'), ('needed', 'VBN'), ('for', 'IN'), ('#', 'NN'), ('2', 'CD'), ('or', 'CC'), ('#', 'NN'), ('4', 'CD'), ('requires', 'VBZ'), ('first', 'RB'), ('knowing', 'VBG'), ('which', 'WDT'), ('entity', 'NN'), ('you', 'PRP'), ('’re', 'VBP'), ('trying', 'VBG'), ('to', 'TO'), ('associate', 'VB'), ('the', 'DT'), ('sentiment', 'NN'), ('with', 'IN'), ('.', '.')] 

 Lemmas are: 
>> [('Calculating', 'calculate'), ('the', 'the'), ('sentiment', 'sentiment'), ('needed', 'need'), ('for', 'for'), ('#', '#'), ('2', '2'), ('or', 'or'), ('#', '#'), ('4', '4'), ('requires', 'require'), ('first', 'first'), ('knowing', 'know'), ('which', 'which'), ('entity', 'entity'), ('you', 'you'), ('’re', 'be'), ('trying', 'try'), ('to', 'to'), ('associate', 'associate'), ('the', 'the'), ('sentiment', 'sentiment'), ('with', 'with'), ('.', '.')] 

 Dependency tags are: 
>> [(('Calculating', 'requires'), 'csubj'), (('the', 'sentiment'), 'det'), (('sentiment', 'Calculating'), 'obj'), (('needed', 'sentiment'), 'acl'), (('for', '#'), 'case'), (('#', 'needed'), 'obl'), (('2', '#'), 'nummod'), (('or', '#'), 'cc'), (('#', '2'), 'conj'), (('4', '#'), 'nummod'), (('requires', 'root'), 'root'), (('first', 'requires'), 'advmod'), (('knowing', 'requires'), 'xcomp'), (('which', 'entity'), 'det'), (('entity', 'trying'), 'obj'), (('you', 'trying'), 'nsubj'), (('’re', 'trying'), 'aux'), (('trying', 'knowing'), 'ccomp'), (('to', 'associate'), 'mark'), (('associate', 'trying'), 'xcomp'), (('the', 'sentiment'), 'det'), (('sentiment', 'associate'), 'obj'), (('with', 'associate'), 'obl'), (('.', 'requires'), 'punct')]

 Named Entites are: 
>> [('2', 'CARDINAL'), ('#4', 'CARDINAL')]

------------------- Sentence 3 -------------------

 If you only have a single model for  sentiment, you’ll end up rating the whole sentence as positive. 

Tokens are: 
>> ['If', 'you', 'only', 'have', 'a', 'single', 'model', 'for', 'sentiment', ',', 'you', '’ll', 'end', 'up', 'rating', 'the', 'whole', 'sentence', 'as', 'positive', '.'] 

 UPOS tags are: 
>> [('If', 'SCONJ'), ('you', 'PRON'), ('only', 'ADV'), ('have', 'VERB'), ('a', 'DET'), ('single', 'ADJ'), ('model', 'NOUN'), ('for', 'ADP'), ('sentiment', 'NOUN'), (',', 'PUNCT'), ('you', 'PRON'), ('’ll', 'AUX'), ('end', 'VERB'), ('up', 'ADP'), ('rating', 'VERB'), ('the', 'DET'), ('whole', 'ADJ'), ('sentence', 'NOUN'), ('as', 'SCONJ'), ('positive', 'ADJ'), ('.', 'PUNCT')] 

 XPOS tags are: 
>> [('If', 'IN'), ('you', 'PRP'), ('only', 'RB'), ('have', 'VBP'), ('a', 'DT'), ('single', 'JJ'), ('model', 'NN'), ('for', 'IN'), ('sentiment', 'NN'), (',', ','), ('you', 'PRP'), ('’ll', 'MD'), ('end', 'VB'), ('up', 'RP'), ('rating', 'VBG'), ('the', 'DT'), ('whole', 'JJ'), ('sentence', 'NN'), ('as', 'IN'), ('positive', 'JJ'), ('.', '.')] 

 Lemmas are: 
>> [('If', 'if'), ('you', 'you'), ('only', 'only'), ('have', 'have'), ('a', 'a'), ('single', 'single'), ('model', 'model'), ('for', 'for'), ('sentiment', 'sentiment'), (',', ','), ('you', 'you'), ('’ll', 'will'), ('end', 'end'), ('up', 'up'), ('rating', 'rate'), ('the', 'the'), ('whole', 'whole'), ('sentence', 'sentence'), ('as', 'as'), ('positive', 'positive'), ('.', '.')] 

 Dependency tags are: 
>> [(('If', 'have'), 'mark'), (('you', 'have'), 'nsubj'), (('only', 'have'), 'advmod'), (('have', 'end'), 'advcl'), (('a', 'model'), 'det'), (('single', 'model'), 'amod'), (('model', 'have'), 'obj'), (('for', 'sentiment'), 'case'), (('sentiment', 'model'), 'nmod'), ((',', 'end'), 'punct'), (('you', 'end'), 'nsubj'), (('’ll', 'end'), 'aux'), (('end', 'root'), 'root'), (('up', 'end'), 'compound:prt'), (('rating', 'end'), 'xcomp'), (('the', 'sentence'), 'det'), (('whole', 'sentence'), 'amod'), (('sentence', 'rating'), 'obj'), (('as', 'positive'), 'mark'), (('positive', 'rating'), 'advcl'), (('.', 'end'), 'punct')]

 Named Entites are: 
>> []

------------------- Sentence 4 -------------------

 Additionally,  if you’re only using keywords to look for the term “text analytics,” you’ll rate  this sentence as positive for that phrase, which isn’t true. 

Tokens are: 
>> ['Additionally', ',', 'if', 'you', '’re', 'only', 'using', 'keywords', 'to', 'look', 'for', 'the', 'term', '“', 'text', 'analytics', ',', '”', 'you', '’ll', 'rate', 'this', 'sentence', 'as', 'positive', 'for', 'that', 'phrase', ',', 'which', 'is', 'n’t', 'true', '.'] 

 UPOS tags are: 
>> [('Additionally', 'ADV'), (',', 'PUNCT'), ('if', 'SCONJ'), ('you', 'PRON'), ('’re', 'AUX'), ('only', 'ADV'), ('using', 'VERB'), ('keywords', 'NOUN'), ('to', 'PART'), ('look', 'VERB'), ('for', 'ADP'), ('the', 'DET'), ('term', 'NOUN'), ('“', 'PUNCT'), ('text', 'NOUN'), ('analytics', 'NOUN'), (',', 'PUNCT'), ('”', 'PUNCT'), ('you', 'PRON'), ('’ll', 'AUX'), ('rate', 'VERB'), ('this', 'DET'), ('sentence', 'NOUN'), ('as', 'ADV'), ('positive', 'ADJ'), ('for', 'ADP'), ('that', 'DET'), ('phrase', 'NOUN'), (',', 'PUNCT'), ('which', 'PRON'), ('is', 'AUX'), ('n’t', 'PART'), ('true', 'ADJ'), ('.', 'PUNCT')] 

 XPOS tags are: 
>> [('Additionally', 'RB'), (',', ','), ('if', 'IN'), ('you', 'PRP'), ('’re', 'VBP'), ('only', 'RB'), ('using', 'VBG'), ('keywords', 'NNS'), ('to', 'TO'), ('look', 'VB'), ('for', 'IN'), ('the', 'DT'), ('term', 'NN'), ('“', '``'), ('text', 'NN'), ('analytics', 'NNS'), (',', ','), ('”', "''"), ('you', 'PRP'), ('’ll', 'MD'), ('rate', 'VB'), ('this', 'DT'), ('sentence', 'NN'), ('as', 'RB'), ('positive', 'JJ'), ('for', 'IN'), ('that', 'DT'), ('phrase', 'NN'), (',', ','), ('which', 'WDT'), ('is', 'VBZ'), ('n’t', 'RB'), ('true', 'JJ'), ('.', '.')] 

 Lemmas are: 
>> [('Additionally', 'additionally'), (',', ','), ('if', 'if'), ('you', 'you'), ('’re', 'be'), ('only', 'only'), ('using', 'use'), ('keywords', 'keyword'), ('to', 'to'), ('look', 'look'), ('for', 'for'), ('the', 'the'), ('term', 'term'), ('“', "''"), ('text', 'text'), ('analytics', 'analytic'), (',', ','), ('”', "''"), ('you', 'you'), ('’ll', 'will'), ('rate', 'rate'), ('this', 'this'), ('sentence', 'sentence'), ('as', 'as'), ('positive', 'positive'), ('for', 'for'), ('that', 'that'), ('phrase', 'phrase'), (',', ','), ('which', 'which'), ('is', 'be'), ('n’t', 'not'), ('true', 'true'), ('.', '.')] 

 Dependency tags are: 
>> [(('Additionally', 'rate'), 'advmod'), ((',', 'rate'), 'punct'), (('if', 'using'), 'mark'), (('you', 'using'), 'nsubj'), (('’re', 'using'), 'aux'), (('only', 'using'), 'advmod'), (('using', 'rate'), 'advcl'), (('keywords', 'using'), 'obj'), (('to', 'look'), 'mark'), (('look', 'keywords'), 'acl'), (('for', 'term'), 'case'), (('the', 'term'), 'det'), (('term', 'look'), 'obl'), (('“', 'analytics'), 'punct'), (('text', 'analytics'), 'compound'), (('analytics', 'term'), 'appos'), ((',', 'analytics'), 'punct'), (('”', 'analytics'), 'punct'), (('you', 'rate'), 'nsubj'), (('’ll', 'rate'), 'aux'), (('rate', 'root'), 'root'), (('this', 'sentence'), 'det'), (('sentence', 'rate'), 'obj'), (('as', 'positive'), 'advmod'), (('positive', 'sentence'), 'amod'), (('for', 'phrase'), 'case'), (('that', 'phrase'), 'det'), (('phrase', 'positive'), 'obl'), ((',', 'true'), 'punct'), (('which', 'true'), 'nsubj'), (('is', 'true'), 'cop'), (('n’t', 'true'), 'advmod'), (('true', 'phrase'), 'acl:relcl'), (('.', 'rate'), 'punct')]

 Named Entites are: 
>> []

------------------- Sentence 5 -------------------

 Depending on what’s optimal for 

Tokens are: 
>> ['Depending', 'on', 'what', '’s', 'optimal', 'for'] 

 UPOS tags are: 
>> [('Depending', 'VERB'), ('on', 'ADP'), ('what', 'PRON'), ('’s', 'AUX'), ('optimal', 'ADJ'), ('for', 'ADP')] 

 XPOS tags are: 
>> [('Depending', 'VBG'), ('on', 'IN'), ('what', 'WP'), ('’s', 'VBZ'), ('optimal', 'JJ'), ('for', 'IN')] 

 Lemmas are: 
>> [('Depending', 'depend'), ('on', 'on'), ('what', 'what'), ('’s', 'be'), ('optimal', 'optimal'), ('for', 'for')] 

 Dependency tags are: 
>> [(('Depending', 'what'), 'case'), (('on', 'Depending'), 'fixed'), (('what', 'optimal'), 'nsubj'), (('’s', 'optimal'), 'cop'), (('optimal', 'root'), 'root'), (('for', 'optimal'), 'obl')]

 Named Entites are: 
>> []

================================ Paragraph 112 =================================

the language, each of these steps is  machine learning or NLP code. 


------------------- Sentence 1 -------------------

 the language, each of these steps is  machine learning or NLP code. 

Tokens are: 
>> ['the', 'language', ',', 'each', 'of', 'these', 'steps', 'is', 'machine', 'learning', 'or', 'NLP', 'code', '.'] 

 UPOS tags are: 
>> [('the', 'DET'), ('language', 'NOUN'), (',', 'PUNCT'), ('each', 'DET'), ('of', 'ADP'), ('these', 'DET'), ('steps', 'NOUN'), ('is', 'AUX'), ('machine', 'NOUN'), ('learning', 'NOUN'), ('or', 'CCONJ'), ('NLP', 'NOUN'), ('code', 'NOUN'), ('.', 'PUNCT')] 

 XPOS tags are: 
>> [('the', 'DT'), ('language', 'NN'), (',', ','), ('each', 'DT'), ('of', 'IN'), ('these', 'DT'), ('steps', 'NNS'), ('is', 'VBZ'), ('machine', 'NN'), ('learning', 'NN'), ('or', 'CC'), ('NLP', 'NN'), ('code', 'NN'), ('.', '.')] 

 Lemmas are: 
>> [('the', 'the'), ('language', 'language'), (',', ','), ('each', 'each'), ('of', 'of'), ('these', 'this'), ('steps', 'step'), ('is', 'be'), ('machine', 'machine'), ('learning', 'learning'), ('or', 'or'), ('NLP', 'nlp'), ('code', 'code'), ('.', '.')] 

 Dependency tags are: 
>> [(('the', 'language'), 'det'), (('language', 'code'), 'nsubj'), ((',', 'code'), 'punct'), (('each', 'language'), 'appos'), (('of', 'steps'), 'case'), (('these', 'steps'), 'det'), (('steps', 'each'), 'nmod'), (('is', 'code'), 'cop'), (('machine', 'code'), 'compound'), (('learning', 'code'), 'compound'), (('or', 'NLP'), 'cc'), (('NLP', 'learning'), 'conj'), (('code', 'root'), 'root'), (('.', 'code'), 'punct')]

 Named Entites are: 
>> []

================================ Paragraph 113 =================================

TOKENS 


------------------- Sentence 1 -------------------

 TOKENS 

Tokens are: 
>> ['TOKENS'] 

 UPOS tags are: 
>> [('TOKENS', 'NOUN')] 

 XPOS tags are: 
>> [('TOKENS', 'NNS')] 

 Lemmas are: 
>> [('TOKENS', 'token')] 

 Dependency tags are: 
>> [(('TOKENS', 'root'), 'root')]

 Named Entites are: 
>> []

================================ Paragraph 114 =================================

PHRASES 


------------------- Sentence 1 -------------------

 PHRASES 

Tokens are: 
>> ['PHRASES'] 

 UPOS tags are: 
>> [('PHRASES', 'NOUN')] 

 XPOS tags are: 
>> [('PHRASES', 'NNS')] 

 Lemmas are: 
>> [('PHRASES', 'phrase')] 

 Dependency tags are: 
>> [(('PHRASES', 'root'), 'root')]

 Named Entites are: 
>> [('PHRASES', 'PERSON')]

================================ Paragraph 115 =================================

SYNTAX  TREES 


------------------- Sentence 1 -------------------

 SYNTAX  TREES 

Tokens are: 
>> ['SYNTAX', 'TREES'] 

 UPOS tags are: 
>> [('SYNTAX', 'NOUN'), ('TREES', 'NOUN')] 

 XPOS tags are: 
>> [('SYNTAX', 'NN'), ('TREES', 'NNS')] 

 Lemmas are: 
>> [('SYNTAX', 'syntax'), ('TREES', 'tree')] 

 Dependency tags are: 
>> [(('SYNTAX', 'TREES'), 'compound'), (('TREES', 'root'), 'root')]

 Named Entites are: 
>> []

================================ Paragraph 116 =================================

SENTENCES 


------------------- Sentence 1 -------------------

 SENTENCES 

Tokens are: 
>> ['SENTENCES'] 

 UPOS tags are: 
>> [('SENTENCES', 'NOUN')] 

 XPOS tags are: 
>> [('SENTENCES', 'NNS')] 

 Lemmas are: 
>> [('SENTENCES', 'sentence')] 

 Dependency tags are: 
>> [(('SENTENCES', 'root'), 'root')]

 Named Entites are: 
>> []

================================ Paragraph 117 =================================

text  parsing (NLP) 


------------------- Sentence 1 -------------------

 text  parsing (NLP) 

Tokens are: 
>> ['text', 'parsing', '(', 'NLP', ')'] 

 UPOS tags are: 
>> [('text', 'NOUN'), ('parsing', 'NOUN'), ('(', 'PUNCT'), ('NLP', 'NOUN'), (')', 'PUNCT')] 

 XPOS tags are: 
>> [('text', 'NN'), ('parsing', 'NN'), ('(', '-LRB-'), ('NLP', 'NN'), (')', '-RRB-')] 

 Lemmas are: 
>> [('text', 'text'), ('parsing', 'parsing'), ('(', '('), ('NLP', 'nlp'), (')', ')')] 

 Dependency tags are: 
>> [(('text', 'parsing'), 'compound'), (('parsing', 'root'), 'root'), (('(', 'NLP'), 'punct'), (('NLP', 'parsing'), 'appos'), ((')', 'NLP'), 'punct')]

 Named Entites are: 
>> []

================================ Paragraph 118 =================================

PARTS  OF SPEECH 


------------------- Sentence 1 -------------------

 PARTS  OF SPEECH 

Tokens are: 
>> ['PARTS', 'OF', 'SPEECH'] 

 UPOS tags are: 
>> [('PARTS', 'NOUN'), ('OF', 'ADP'), ('SPEECH', 'NOUN')] 

 XPOS tags are: 
>> [('PARTS', 'NNS'), ('OF', 'IN'), ('SPEECH', 'NN')] 

 Lemmas are: 
>> [('PARTS', 'part'), ('OF', 'of'), ('SPEECH', 'speech')] 

 Dependency tags are: 
>> [(('PARTS', 'root'), 'root'), (('OF', 'SPEECH'), 'case'), (('SPEECH', 'PARTS'), 'nmod')]

 Named Entites are: 
>> []

================================ Paragraph 119 =================================

SEMANTIC  RELATIONSHIPS


------------------- Sentence 1 -------------------

 SEMANTIC  RELATIONSHIPS 

Tokens are: 
>> ['SEMANTIC', 'RELATIONSHIPS'] 

 UPOS tags are: 
>> [('SEMANTIC', 'ADJ'), ('RELATIONSHIPS', 'NOUN')] 

 XPOS tags are: 
>> [('SEMANTIC', 'JJ'), ('RELATIONSHIPS', 'NNS')] 

 Lemmas are: 
>> [('SEMANTIC', 'semantic'), ('RELATIONSHIPS', 'relation')] 

 Dependency tags are: 
>> [(('SEMANTIC', 'RELATIONSHIPS'), 'amod'), (('RELATIONSHIPS', 'root'), 'root')]

 Named Entites are: 
>> []

================================ Paragraph 120 =================================

W H I T E  P A P E R 


------------------- Sentence 1 -------------------

 W H I T E  P A P E R 

Tokens are: 
>> ['W', 'H', 'I', 'T', 'E', 'P', 'A', 'P', 'E', 'R'] 

 UPOS tags are: 
>> [('W', 'PROPN'), ('H', 'PUNCT'), ('I', 'PRON'), ('T', 'AUX'), ('E', 'PROPN'), ('P', 'NOUN'), ('A', 'NOUN'), ('P', 'NOUN'), ('E', 'NOUN'), ('R', 'NOUN')] 

 XPOS tags are: 
>> [('W', 'NNP'), ('H', ','), ('I', 'PRP'), ('T', 'VBP'), ('E', 'NNP'), ('P', 'NN'), ('A', 'NN'), ('P', 'NN'), ('E', 'NN'), ('R', 'NN')] 

 Lemmas are: 
>> [('W', 'W'), ('H', 'H'), ('I', 'I'), ('T', 'T'), ('E', 'E'), ('P', 'p'), ('A', 'a'), ('P', 'p'), ('E', 'e'), ('R', 'R')] 

 Dependency tags are: 
>> [(('W', 'T'), 'vocative'), (('H', 'W'), 'punct'), (('I', 'T'), 'nsubj'), (('T', 'root'), 'root'), (('E', 'T'), 'obj'), (('P', 'T'), 'obj'), (('A', 'E'), 'compound'), (('P', 'E'), 'compound'), (('E', 'R'), 'compound'), (('R', 'T'), 'obj')]

 Named Entites are: 
>> []

================================ Paragraph 121 =================================

8|       |   Lexalytics, Inc., 48 North Pleasant St. Unit 301, Amherst MA 01002 USA   |   1-800-377-8036 |   www.lexalytics.com 


------------------- Sentence 1 -------------------

 8|       |   Lexalytics, Inc., 48 North Pleasant St. Unit 301, Amherst MA 01002 USA   |   1-800-377-8036 |   www.lexalytics.com 

Tokens are: 
>> ['8', '|', '|', 'Lexalytics', ',', 'Inc.', ',', '48', 'North', 'Pleasant', 'St.', 'Unit', '301', ',', 'Amherst', 'MA', '01002', 'USA', '|', '1-800-377-8036', '|', 'www.lexalytics.com'] 

 UPOS tags are: 
>> [('8', 'NUM'), ('|', 'PUNCT'), ('|', 'PUNCT'), ('Lexalytics', 'PROPN'), (',', 'PUNCT'), ('Inc.', 'PROPN'), (',', 'PUNCT'), ('48', 'NUM'), ('North', 'PROPN'), ('Pleasant', 'ADJ'), ('St.', 'PROPN'), ('Unit', 'NOUN'), ('301', 'NUM'), (',', 'PUNCT'), ('Amherst', 'PROPN'), ('MA', 'PROPN'), ('01002', 'NUM'), ('USA', 'PROPN'), ('|', 'PUNCT'), ('1-800-377-8036', 'NUM'), ('|', 'PUNCT'), ('www.lexalytics.com', 'X')] 

 XPOS tags are: 
>> [('8', 'LS'), ('|', 'NFP'), ('|', 'NFP'), ('Lexalytics', 'NNP'), (',', ','), ('Inc.', 'NNP'), (',', ','), ('48', 'CD'), ('North', 'NNP'), ('Pleasant', 'JJ'), ('St.', 'NNP'), ('Unit', 'NN'), ('301', 'CD'), (',', ','), ('Amherst', 'NNP'), ('MA', 'NNP'), ('01002', 'CD'), ('USA', 'NNP'), ('|', 'NFP'), ('1-800-377-8036', 'CD'), ('|', 'NFP'), ('www.lexalytics.com', 'ADD')] 

 Lemmas are: 
>> [('8', '8'), ('|', '|'), ('|', '|'), ('Lexalytics', 'Lexalytics'), (',', ','), ('Inc.', 'Inc.'), (',', ','), ('48', '48'), ('North', 'North'), ('Pleasant', 'Pleasant'), ('St.', 'St.'), ('Unit', 'unit'), ('301', '301'), (',', ','), ('Amherst', 'Amherst'), ('MA', 'MA'), ('01002', '01002'), ('USA', 'USA'), ('|', '|'), ('1-800-377-8036', '1-800-377-8036'), ('|', '|'), ('www.lexalytics.com', 'www.lexalytics.com')] 

 Dependency tags are: 
>> [(('8', 'Inc.'), 'nummod'), (('|', '8'), 'punct'), (('|', '8'), 'punct'), (('Lexalytics', 'Inc.'), 'compound'), ((',', 'Inc.'), 'punct'), (('Inc.', 'root'), 'root'), ((',', 'Inc.'), 'punct'), (('48', 'St.'), 'nummod'), (('North', 'St.'), 'compound'), (('Pleasant', 'St.'), 'amod'), (('St.', 'Inc.'), 'list'), (('Unit', 'St.'), 'appos'), (('301', 'St.'), 'nummod'), ((',', 'MA'), 'punct'), (('Amherst', 'MA'), 'appos'), (('MA', 'St.'), 'appos'), (('01002', 'USA'), 'nummod'), (('USA', 'MA'), 'appos'), (('|', 'USA'), 'punct'), (('1-800-377-8036', 'Inc.'), 'list'), (('|', '1-800-377-8036'), 'punct'), (('www.lexalytics.com', 'Inc.'), 'list')]

 Named Entites are: 
>> [('8|       |   Lexalytics, Inc.', 'ORG'), ('301', 'CARDINAL')]

================================ Paragraph 122 =================================

Not only do you need at least four models to solve this task, but these  models are interdependent and have to interact with each other. To   create this kind of multi-model solution, we developed proprietary   AI building software.  


------------------- Sentence 1 -------------------

 Not only do you need at least four models to solve this task, but these  models are interdependent and have to interact with each other. 

Tokens are: 
>> ['Not', 'only', 'do', 'you', 'need', 'at', 'least', 'four', 'models', 'to', 'solve', 'this', 'task', ',', 'but', 'these', 'models', 'are', 'interdependent', 'and', 'have', 'to', 'interact', 'with', 'each', 'other', '.'] 

 UPOS tags are: 
>> [('Not', 'PART'), ('only', 'ADV'), ('do', 'AUX'), ('you', 'PRON'), ('need', 'VERB'), ('at', 'ADP'), ('least', 'ADJ'), ('four', 'NUM'), ('models', 'NOUN'), ('to', 'PART'), ('solve', 'VERB'), ('this', 'DET'), ('task', 'NOUN'), (',', 'PUNCT'), ('but', 'CCONJ'), ('these', 'DET'), ('models', 'NOUN'), ('are', 'AUX'), ('interdependent', 'ADJ'), ('and', 'CCONJ'), ('have', 'VERB'), ('to', 'PART'), ('interact', 'VERB'), ('with', 'ADP'), ('each', 'DET'), ('other', 'ADJ'), ('.', 'PUNCT')] 

 XPOS tags are: 
>> [('Not', 'RB'), ('only', 'RB'), ('do', 'VBP'), ('you', 'PRP'), ('need', 'VB'), ('at', 'IN'), ('least', 'JJS'), ('four', 'CD'), ('models', 'NNS'), ('to', 'TO'), ('solve', 'VB'), ('this', 'DT'), ('task', 'NN'), (',', ','), ('but', 'CC'), ('these', 'DT'), ('models', 'NNS'), ('are', 'VBP'), ('interdependent', 'JJ'), ('and', 'CC'), ('have', 'VBP'), ('to', 'TO'), ('interact', 'VB'), ('with', 'IN'), ('each', 'DT'), ('other', 'JJ'), ('.', '.')] 

 Lemmas are: 
>> [('Not', 'not'), ('only', 'only'), ('do', 'do'), ('you', 'you'), ('need', 'need'), ('at', 'at'), ('least', 'least'), ('four', 'four'), ('models', 'model'), ('to', 'to'), ('solve', 'solve'), ('this', 'this'), ('task', 'task'), (',', ','), ('but', 'but'), ('these', 'this'), ('models', 'model'), ('are', 'be'), ('interdependent', 'interdependent'), ('and', 'and'), ('have', 'have'), ('to', 'to'), ('interact', 'interact'), ('with', 'with'), ('each', 'each'), ('other', 'other'), ('.', '.')] 

 Dependency tags are: 
>> [(('Not', 'need'), 'advmod'), (('only', 'need'), 'advmod'), (('do', 'need'), 'aux'), (('you', 'need'), 'nsubj'), (('need', 'root'), 'root'), (('at', 'least'), 'case'), (('least', 'four'), 'nmod'), (('four', 'models'), 'nummod'), (('models', 'need'), 'obj'), (('to', 'solve'), 'mark'), (('solve', 'models'), 'acl'), (('this', 'task'), 'det'), (('task', 'solve'), 'obj'), ((',', 'interdependent'), 'punct'), (('but', 'interdependent'), 'cc'), (('these', 'models'), 'det'), (('models', 'interdependent'), 'nsubj'), (('are', 'interdependent'), 'cop'), (('interdependent', 'need'), 'conj'), (('and', 'have'), 'cc'), (('have', 'interdependent'), 'conj'), (('to', 'interact'), 'mark'), (('interact', 'have'), 'xcomp'), (('with', 'other'), 'case'), (('each', 'other'), 'det'), (('other', 'interact'), 'obl'), (('.', 'need'), 'punct')]

 Named Entites are: 
>> [('at least four', 'CARDINAL')]

------------------- Sentence 2 -------------------

 To   create this kind of multi-model solution, we developed proprietary   AI building software. 

Tokens are: 
>> ['To', 'create', 'this', 'kind', 'of', 'multi-model', 'solution', ',', 'we', 'developed', 'proprietary', 'AI', 'building', 'software', '.'] 

 UPOS tags are: 
>> [('To', 'PART'), ('create', 'VERB'), ('this', 'DET'), ('kind', 'NOUN'), ('of', 'ADP'), ('multi-model', 'ADJ'), ('solution', 'NOUN'), (',', 'PUNCT'), ('we', 'PRON'), ('developed', 'VERB'), ('proprietary', 'ADJ'), ('AI', 'NOUN'), ('building', 'NOUN'), ('software', 'NOUN'), ('.', 'PUNCT')] 

 XPOS tags are: 
>> [('To', 'TO'), ('create', 'VB'), ('this', 'DT'), ('kind', 'NN'), ('of', 'IN'), ('multi-model', 'JJ'), ('solution', 'NN'), (',', ','), ('we', 'PRP'), ('developed', 'VBD'), ('proprietary', 'JJ'), ('AI', 'NN'), ('building', 'NN'), ('software', 'NN'), ('.', '.')] 

 Lemmas are: 
>> [('To', 'to'), ('create', 'create'), ('this', 'this'), ('kind', 'kind'), ('of', 'of'), ('multi-model', 'multi-model'), ('solution', 'solution'), (',', ','), ('we', 'we'), ('developed', 'develop'), ('proprietary', 'proprietary'), ('AI', 'ai'), ('building', 'building'), ('software', 'software'), ('.', '.')] 

 Dependency tags are: 
>> [(('To', 'create'), 'mark'), (('create', 'developed'), 'advcl'), (('this', 'kind'), 'det'), (('kind', 'create'), 'obj'), (('of', 'solution'), 'case'), (('multi-model', 'solution'), 'amod'), (('solution', 'kind'), 'nmod'), ((',', 'developed'), 'punct'), (('we', 'developed'), 'nsubj'), (('developed', 'root'), 'root'), (('proprietary', 'software'), 'amod'), (('AI', 'software'), 'compound'), (('building', 'software'), 'compound'), (('software', 'developed'), 'obj'), (('.', 'developed'), 'punct')]

 Named Entites are: 
>> []

================================ Paragraph 123 =================================

This tool, “AI Assembler,” is used to build our features like sentiment,   named entity extraction, intention analysis and more. We also use AI  Assembler to build custom machine learning models used by our customers  and partners. Among other things, AI Assembler manages dependencies  between models, allowing us to easily upgrade one model and then   re-build other models as necessary. 


------------------- Sentence 1 -------------------

 This tool, “AI Assembler,” is used to build our features like sentiment,   named entity extraction, intention analysis and more. 

Tokens are: 
>> ['This', 'tool', ',', '“', 'AI', 'Assembler', ',', '”', 'is', 'used', 'to', 'build', 'our', 'features', 'like', 'sentiment', ',', 'named', 'entity', 'extraction', ',', 'intention', 'analysis', 'and', 'more', '.'] 

 UPOS tags are: 
>> [('This', 'DET'), ('tool', 'NOUN'), (',', 'PUNCT'), ('“', 'PUNCT'), ('AI', 'AUX'), ('Assembler', 'PROPN'), (',', 'PUNCT'), ('”', 'PUNCT'), ('is', 'AUX'), ('used', 'VERB'), ('to', 'PART'), ('build', 'VERB'), ('our', 'PRON'), ('features', 'NOUN'), ('like', 'ADP'), ('sentiment', 'NOUN'), (',', 'PUNCT'), ('named', 'VERB'), ('entity', 'NOUN'), ('extraction', 'NOUN'), (',', 'PUNCT'), ('intention', 'NOUN'), ('analysis', 'NOUN'), ('and', 'CCONJ'), ('more', 'ADV'), ('.', 'PUNCT')] 

 XPOS tags are: 
>> [('This', 'DT'), ('tool', 'NN'), (',', ','), ('“', '``'), ('AI', 'VBZ'), ('Assembler', 'NNP'), (',', ','), ('”', "''"), ('is', 'VBZ'), ('used', 'VBN'), ('to', 'TO'), ('build', 'VB'), ('our', 'PRP$'), ('features', 'NNS'), ('like', 'IN'), ('sentiment', 'NN'), (',', ','), ('named', 'VBN'), ('entity', 'NN'), ('extraction', 'NN'), (',', ','), ('intention', 'NN'), ('analysis', 'NN'), ('and', 'CC'), ('more', 'RBR'), ('.', '.')] 

 Lemmas are: 
>> [('This', 'this'), ('tool', 'tool'), (',', ','), ('“', "''"), ('AI', 'be'), ('Assembler', 'Assembler'), (',', ','), ('”', "''"), ('is', 'be'), ('used', 'use'), ('to', 'to'), ('build', 'build'), ('our', 'we'), ('features', 'feature'), ('like', 'like'), ('sentiment', 'sentiment'), (',', ','), ('named', 'name'), ('entity', 'entity'), ('extraction', 'extraction'), (',', ','), ('intention', 'intention'), ('analysis', 'analysis'), ('and', 'and'), ('more', 'more'), ('.', '.')] 

 Dependency tags are: 
>> [(('This', 'tool'), 'det'), (('tool', 'used'), 'nsubj:pass'), ((',', 'Assembler'), 'punct'), (('“', 'Assembler'), 'punct'), (('AI', 'Assembler'), 'cop'), (('Assembler', 'used'), 'advcl'), ((',', 'Assembler'), 'punct'), (('”', 'Assembler'), 'punct'), (('is', 'used'), 'aux:pass'), (('used', 'root'), 'root'), (('to', 'build'), 'mark'), (('build', 'used'), 'xcomp'), (('our', 'features'), 'nmod:poss'), (('features', 'build'), 'obj'), (('like', 'sentiment'), 'case'), (('sentiment', 'features'), 'nmod'), ((',', 'named'), 'punct'), (('named', 'sentiment'), 'acl'), (('entity', 'extraction'), 'compound'), (('extraction', 'sentiment'), 'conj'), ((',', 'analysis'), 'punct'), (('intention', 'analysis'), 'compound'), (('analysis', 'sentiment'), 'conj'), (('and', 'more'), 'cc'), (('more', 'sentiment'), 'conj'), (('.', 'used'), 'punct')]

 Named Entites are: 
>> [('AI Assembler', 'PRODUCT')]

------------------- Sentence 2 -------------------

 We also use AI  Assembler to build custom machine learning models used by our customers  and partners. 

Tokens are: 
>> ['We', 'also', 'use', 'AI', 'Assembler', 'to', 'build', 'custom', 'machine', 'learning', 'models', 'used', 'by', 'our', 'customers', 'and', 'partners', '.'] 

 UPOS tags are: 
>> [('We', 'PRON'), ('also', 'ADV'), ('use', 'VERB'), ('AI', 'PROPN'), ('Assembler', 'NOUN'), ('to', 'PART'), ('build', 'VERB'), ('custom', 'ADJ'), ('machine', 'NOUN'), ('learning', 'NOUN'), ('models', 'NOUN'), ('used', 'VERB'), ('by', 'ADP'), ('our', 'PRON'), ('customers', 'NOUN'), ('and', 'CCONJ'), ('partners', 'NOUN'), ('.', 'PUNCT')] 

 XPOS tags are: 
>> [('We', 'PRP'), ('also', 'RB'), ('use', 'VBP'), ('AI', 'NNP'), ('Assembler', 'NN'), ('to', 'TO'), ('build', 'VB'), ('custom', 'JJ'), ('machine', 'NN'), ('learning', 'NN'), ('models', 'NNS'), ('used', 'VBN'), ('by', 'IN'), ('our', 'PRP$'), ('customers', 'NNS'), ('and', 'CC'), ('partners', 'NNS'), ('.', '.')] 

 Lemmas are: 
>> [('We', 'we'), ('also', 'also'), ('use', 'use'), ('AI', 'AI'), ('Assembler', 'assembler'), ('to', 'to'), ('build', 'build'), ('custom', 'custom'), ('machine', 'machine'), ('learning', 'learning'), ('models', 'model'), ('used', 'use'), ('by', 'by'), ('our', 'we'), ('customers', 'customer'), ('and', 'and'), ('partners', 'partner'), ('.', '.')] 

 Dependency tags are: 
>> [(('We', 'use'), 'nsubj'), (('also', 'use'), 'advmod'), (('use', 'root'), 'root'), (('AI', 'Assembler'), 'compound'), (('Assembler', 'use'), 'obj'), (('to', 'build'), 'mark'), (('build', 'use'), 'advcl'), (('custom', 'models'), 'amod'), (('machine', 'models'), 'compound'), (('learning', 'models'), 'compound'), (('models', 'build'), 'obj'), (('used', 'models'), 'acl'), (('by', 'customers'), 'case'), (('our', 'customers'), 'nmod:poss'), (('customers', 'used'), 'obl'), (('and', 'partners'), 'cc'), (('partners', 'customers'), 'conj'), (('.', 'use'), 'punct')]

 Named Entites are: 
>> [('AI  Assembler', 'ORG')]

------------------- Sentence 3 -------------------

 Among other things, AI Assembler manages dependencies  between models, allowing us to easily upgrade one model and then   re-build other models as necessary. 

Tokens are: 
>> ['Among', 'other', 'things', ',', 'AI', 'Assembler', 'manages', 'dependencies', 'between', 'models', ',', 'allowing', 'us', 'to', 'easily', 'upgrade', 'one', 'model', 'and', 'then', 're-build', 'other', 'models', 'as', 'necessary', '.'] 

 UPOS tags are: 
>> [('Among', 'ADP'), ('other', 'ADJ'), ('things', 'NOUN'), (',', 'PUNCT'), ('AI', 'PROPN'), ('Assembler', 'PROPN'), ('manages', 'VERB'), ('dependencies', 'NOUN'), ('between', 'ADP'), ('models', 'NOUN'), (',', 'PUNCT'), ('allowing', 'VERB'), ('us', 'PRON'), ('to', 'PART'), ('easily', 'ADV'), ('upgrade', 'VERB'), ('one', 'NUM'), ('model', 'NOUN'), ('and', 'CCONJ'), ('then', 'ADV'), ('re-build', 'VERB'), ('other', 'ADJ'), ('models', 'NOUN'), ('as', 'SCONJ'), ('necessary', 'ADJ'), ('.', 'PUNCT')] 

 XPOS tags are: 
>> [('Among', 'IN'), ('other', 'JJ'), ('things', 'NNS'), (',', ','), ('AI', 'NNP'), ('Assembler', 'NNP'), ('manages', 'VBZ'), ('dependencies', 'NNS'), ('between', 'IN'), ('models', 'NNS'), (',', ','), ('allowing', 'VBG'), ('us', 'PRP'), ('to', 'TO'), ('easily', 'RB'), ('upgrade', 'VB'), ('one', 'CD'), ('model', 'NN'), ('and', 'CC'), ('then', 'RB'), ('re-build', 'VB'), ('other', 'JJ'), ('models', 'NNS'), ('as', 'IN'), ('necessary', 'JJ'), ('.', '.')] 

 Lemmas are: 
>> [('Among', 'among'), ('other', 'other'), ('things', 'thing'), (',', ','), ('AI', 'AI'), ('Assembler', 'Assembler'), ('manages', 'manage'), ('dependencies', 'dependency'), ('between', 'between'), ('models', 'model'), (',', ','), ('allowing', 'allow'), ('us', 'we'), ('to', 'to'), ('easily', 'easily'), ('upgrade', 'upgrade'), ('one', 'one'), ('model', 'model'), ('and', 'and'), ('then', 'then'), ('re-build', 're-build'), ('other', 'other'), ('models', 'model'), ('as', 'as'), ('necessary', 'necessary'), ('.', '.')] 

 Dependency tags are: 
>> [(('Among', 'things'), 'case'), (('other', 'things'), 'amod'), (('things', 'manages'), 'obl'), ((',', 'manages'), 'punct'), (('AI', 'manages'), 'nsubj'), (('Assembler', 'AI'), 'flat'), (('manages', 'root'), 'root'), (('dependencies', 'manages'), 'obj'), (('between', 'models'), 'case'), (('models', 'dependencies'), 'nmod'), ((',', 'allowing'), 'punct'), (('allowing', 'manages'), 'advcl'), (('us', 'allowing'), 'obj'), (('to', 'upgrade'), 'mark'), (('easily', 'upgrade'), 'advmod'), (('upgrade', 'allowing'), 'xcomp'), (('one', 'model'), 'nummod'), (('model', 'upgrade'), 'obj'), (('and', 're-build'), 'cc'), (('then', 're-build'), 'advmod'), (('re-build', 'upgrade'), 'conj'), (('other', 'models'), 'amod'), (('models', 're-build'), 'obj'), (('as', 'necessary'), 'mark'), (('necessary', 're-build'), 'advcl'), (('.', 'manages'), 'punct')]

 Named Entites are: 
>> [('AI Assembler', 'ORG'), ('one', 'CARDINAL')]

================================ Paragraph 124 =================================

Multi-level granular sentiment analysis is difficult due to the model complexity   and dependencies. Lexalytics is one of the few companies that actually  provides this service – most companies simply provide document sentiment  and call it done. Truth is, solving for entity and category sentiment is very  difficult, and multiplies the amount of work required. We do it because our  customers are making business critical decisions, and they need context-rich  insights to make informed decisions that drive business growth. 


------------------- Sentence 1 -------------------

 Multi-level granular sentiment analysis is difficult due to the model complexity   and dependencies. 

Tokens are: 
>> ['Multi-level', 'granular', 'sentiment', 'analysis', 'is', 'difficult', 'due', 'to', 'the', 'model', 'complexity', 'and', 'dependencies', '.'] 

 UPOS tags are: 
>> [('Multi-level', 'ADJ'), ('granular', 'ADJ'), ('sentiment', 'NOUN'), ('analysis', 'NOUN'), ('is', 'AUX'), ('difficult', 'ADJ'), ('due', 'ADP'), ('to', 'ADP'), ('the', 'DET'), ('model', 'NOUN'), ('complexity', 'NOUN'), ('and', 'CCONJ'), ('dependencies', 'NOUN'), ('.', 'PUNCT')] 

 XPOS tags are: 
>> [('Multi-level', 'JJ'), ('granular', 'JJ'), ('sentiment', 'NN'), ('analysis', 'NN'), ('is', 'VBZ'), ('difficult', 'JJ'), ('due', 'IN'), ('to', 'IN'), ('the', 'DT'), ('model', 'NN'), ('complexity', 'NN'), ('and', 'CC'), ('dependencies', 'NNS'), ('.', '.')] 

 Lemmas are: 
>> [('Multi-level', 'multi-level'), ('granular', 'granular'), ('sentiment', 'sentiment'), ('analysis', 'analysis'), ('is', 'be'), ('difficult', 'difficult'), ('due', 'due'), ('to', 'to'), ('the', 'the'), ('model', 'model'), ('complexity', 'complexity'), ('and', 'and'), ('dependencies', 'dependency'), ('.', '.')] 

 Dependency tags are: 
>> [(('Multi-level', 'analysis'), 'amod'), (('granular', 'analysis'), 'amod'), (('sentiment', 'analysis'), 'compound'), (('analysis', 'difficult'), 'nsubj'), (('is', 'difficult'), 'cop'), (('difficult', 'root'), 'root'), (('due', 'complexity'), 'case'), (('to', 'due'), 'fixed'), (('the', 'complexity'), 'det'), (('model', 'complexity'), 'compound'), (('complexity', 'difficult'), 'obl'), (('and', 'dependencies'), 'cc'), (('dependencies', 'complexity'), 'conj'), (('.', 'difficult'), 'punct')]

 Named Entites are: 
>> []

------------------- Sentence 2 -------------------

 Lexalytics is one of the few companies that actually  provides this service – most companies simply provide document sentiment  and call it done. 

Tokens are: 
>> ['Lexalytics', 'is', 'one', 'of', 'the', 'few', 'companies', 'that', 'actually', 'provides', 'this', 'service', '–', 'most', 'companies', 'simply', 'provide', 'document', 'sentiment', 'and', 'call', 'it', 'done', '.'] 

 UPOS tags are: 
>> [('Lexalytics', 'PROPN'), ('is', 'AUX'), ('one', 'NUM'), ('of', 'ADP'), ('the', 'DET'), ('few', 'ADJ'), ('companies', 'NOUN'), ('that', 'PRON'), ('actually', 'ADV'), ('provides', 'VERB'), ('this', 'DET'), ('service', 'NOUN'), ('–', 'PUNCT'), ('most', 'ADJ'), ('companies', 'NOUN'), ('simply', 'ADV'), ('provide', 'VERB'), ('document', 'NOUN'), ('sentiment', 'NOUN'), ('and', 'CCONJ'), ('call', 'VERB'), ('it', 'PRON'), ('done', 'VERB'), ('.', 'PUNCT')] 

 XPOS tags are: 
>> [('Lexalytics', 'NNPS'), ('is', 'VBZ'), ('one', 'CD'), ('of', 'IN'), ('the', 'DT'), ('few', 'JJ'), ('companies', 'NNS'), ('that', 'WDT'), ('actually', 'RB'), ('provides', 'VBZ'), ('this', 'DT'), ('service', 'NN'), ('–', ','), ('most', 'JJS'), ('companies', 'NNS'), ('simply', 'RB'), ('provide', 'VBP'), ('document', 'NN'), ('sentiment', 'NN'), ('and', 'CC'), ('call', 'VBP'), ('it', 'PRP'), ('done', 'VBN'), ('.', '.')] 

 Lemmas are: 
>> [('Lexalytics', 'Lexalytics'), ('is', 'be'), ('one', 'one'), ('of', 'of'), ('the', 'the'), ('few', 'few'), ('companies', 'company'), ('that', 'that'), ('actually', 'actually'), ('provides', 'provide'), ('this', 'this'), ('service', 'service'), ('–', '-'), ('most', 'most'), ('companies', 'company'), ('simply', 'simply'), ('provide', 'provide'), ('document', 'document'), ('sentiment', 'sentiment'), ('and', 'and'), ('call', 'call'), ('it', 'it'), ('done', 'do'), ('.', '.')] 

 Dependency tags are: 
>> [(('Lexalytics', 'one'), 'nsubj'), (('is', 'one'), 'cop'), (('one', 'root'), 'root'), (('of', 'companies'), 'case'), (('the', 'companies'), 'det'), (('few', 'companies'), 'amod'), (('companies', 'one'), 'nmod'), (('that', 'provides'), 'nsubj'), (('actually', 'provides'), 'advmod'), (('provides', 'companies'), 'acl:relcl'), (('this', 'service'), 'det'), (('service', 'provides'), 'obj'), (('–', 'one'), 'punct'), (('most', 'companies'), 'amod'), (('companies', 'provide'), 'nsubj'), (('simply', 'provide'), 'advmod'), (('provide', 'one'), 'parataxis'), (('document', 'sentiment'), 'compound'), (('sentiment', 'provide'), 'obj'), (('and', 'call'), 'cc'), (('call', 'provide'), 'conj'), (('it', 'call'), 'obj'), (('done', 'call'), 'xcomp'), (('.', 'one'), 'punct')]

 Named Entites are: 
>> [('Lexalytics', 'ORG'), ('one', 'CARDINAL')]

------------------- Sentence 3 -------------------

 Truth is, solving for entity and category sentiment is very  difficult, and multiplies the amount of work required. 

Tokens are: 
>> ['Truth', 'is', ',', 'solving', 'for', 'entity', 'and', 'category', 'sentiment', 'is', 'very', 'difficult', ',', 'and', 'multiplies', 'the', 'amount', 'of', 'work', 'required', '.'] 

 UPOS tags are: 
>> [('Truth', 'NOUN'), ('is', 'AUX'), (',', 'PUNCT'), ('solving', 'VERB'), ('for', 'ADP'), ('entity', 'NOUN'), ('and', 'CCONJ'), ('category', 'NOUN'), ('sentiment', 'NOUN'), ('is', 'AUX'), ('very', 'ADV'), ('difficult', 'ADJ'), (',', 'PUNCT'), ('and', 'CCONJ'), ('multiplies', 'VERB'), ('the', 'DET'), ('amount', 'NOUN'), ('of', 'ADP'), ('work', 'NOUN'), ('required', 'VERB'), ('.', 'PUNCT')] 

 XPOS tags are: 
>> [('Truth', 'NN'), ('is', 'VBZ'), (',', ','), ('solving', 'VBG'), ('for', 'IN'), ('entity', 'NN'), ('and', 'CC'), ('category', 'NN'), ('sentiment', 'NN'), ('is', 'VBZ'), ('very', 'RB'), ('difficult', 'JJ'), (',', ','), ('and', 'CC'), ('multiplies', 'VBZ'), ('the', 'DT'), ('amount', 'NN'), ('of', 'IN'), ('work', 'NN'), ('required', 'VBN'), ('.', '.')] 

 Lemmas are: 
>> [('Truth', 'Truth'), ('is', 'be'), (',', ','), ('solving', 'solve'), ('for', 'for'), ('entity', 'entity'), ('and', 'and'), ('category', 'category'), ('sentiment', 'sentiment'), ('is', 'be'), ('very', 'very'), ('difficult', 'difficult'), (',', ','), ('and', 'and'), ('multiplies', 'multiply'), ('the', 'the'), ('amount', 'amount'), ('of', 'of'), ('work', 'work'), ('required', 'require'), ('.', '.')] 

 Dependency tags are: 
>> [(('Truth', 'difficult'), 'nsubj'), (('is', 'difficult'), 'cop'), ((',', 'difficult'), 'punct'), (('solving', 'difficult'), 'csubj'), (('for', 'entity'), 'case'), (('entity', 'solving'), 'obl'), (('and', 'sentiment'), 'cc'), (('category', 'sentiment'), 'compound'), (('sentiment', 'entity'), 'conj'), (('is', 'difficult'), 'cop'), (('very', 'difficult'), 'advmod'), (('difficult', 'root'), 'root'), ((',', 'multiplies'), 'punct'), (('and', 'multiplies'), 'cc'), (('multiplies', 'difficult'), 'conj'), (('the', 'amount'), 'det'), (('amount', 'multiplies'), 'obj'), (('of', 'work'), 'case'), (('work', 'amount'), 'nmod'), (('required', 'work'), 'acl'), (('.', 'difficult'), 'punct')]

 Named Entites are: 
>> []

------------------- Sentence 4 -------------------

 We do it because our  customers are making business critical decisions, and they need context-rich  insights to make informed decisions that drive business growth. 

Tokens are: 
>> ['We', 'do', 'it', 'because', 'our', 'customers', 'are', 'making', 'business', 'critical', 'decisions', ',', 'and', 'they', 'need', 'context-', 'rich', 'insights', 'to', 'make', 'informed', 'decisions', 'that', 'drive', 'business', 'growth', '.'] 

 UPOS tags are: 
>> [('We', 'PRON'), ('do', 'VERB'), ('it', 'PRON'), ('because', 'SCONJ'), ('our', 'PRON'), ('customers', 'NOUN'), ('are', 'AUX'), ('making', 'VERB'), ('business', 'NOUN'), ('critical', 'ADJ'), ('decisions', 'NOUN'), (',', 'PUNCT'), ('and', 'CCONJ'), ('they', 'PRON'), ('need', 'VERB'), ('context-', 'ADJ'), ('rich', 'ADJ'), ('insights', 'NOUN'), ('to', 'PART'), ('make', 'VERB'), ('informed', 'VERB'), ('decisions', 'NOUN'), ('that', 'PRON'), ('drive', 'VERB'), ('business', 'NOUN'), ('growth', 'NOUN'), ('.', 'PUNCT')] 

 XPOS tags are: 
>> [('We', 'PRP'), ('do', 'VBP'), ('it', 'PRP'), ('because', 'IN'), ('our', 'PRP$'), ('customers', 'NNS'), ('are', 'VBP'), ('making', 'VBG'), ('business', 'NN'), ('critical', 'JJ'), ('decisions', 'NNS'), (',', ','), ('and', 'CC'), ('they', 'PRP'), ('need', 'VBP'), ('context-', 'JJ'), ('rich', 'JJ'), ('insights', 'NNS'), ('to', 'TO'), ('make', 'VB'), ('informed', 'VBN'), ('decisions', 'NNS'), ('that', 'WDT'), ('drive', 'VBP'), ('business', 'NN'), ('growth', 'NN'), ('.', '.')] 

 Lemmas are: 
>> [('We', 'we'), ('do', 'do'), ('it', 'it'), ('because', 'because'), ('our', 'we'), ('customers', 'customer'), ('are', 'be'), ('making', 'make'), ('business', 'business'), ('critical', 'critical'), ('decisions', 'decision'), (',', ','), ('and', 'and'), ('they', 'they'), ('need', 'need'), ('context-', 'context-'), ('rich', 'rich'), ('insights', 'insight'), ('to', 'to'), ('make', 'make'), ('informed', 'inform'), ('decisions', 'decision'), ('that', 'that'), ('drive', 'drive'), ('business', 'business'), ('growth', 'growth'), ('.', '.')] 

 Dependency tags are: 
>> [(('We', 'do'), 'nsubj'), (('do', 'root'), 'root'), (('it', 'do'), 'obj'), (('because', 'making'), 'mark'), (('our', 'customers'), 'nmod:poss'), (('customers', 'making'), 'nsubj'), (('are', 'making'), 'aux'), (('making', 'do'), 'advcl'), (('business', 'decisions'), 'compound'), (('critical', 'decisions'), 'amod'), (('decisions', 'making'), 'obj'), ((',', 'need'), 'punct'), (('and', 'need'), 'cc'), (('they', 'need'), 'nsubj'), (('need', 'do'), 'conj'), (('context-', 'insights'), 'amod'), (('rich', 'insights'), 'amod'), (('insights', 'need'), 'obj'), (('to', 'make'), 'mark'), (('make', 'insights'), 'acl'), (('informed', 'decisions'), 'amod'), (('decisions', 'make'), 'obj'), (('that', 'drive'), 'nsubj'), (('drive', 'decisions'), 'acl:relcl'), (('business', 'growth'), 'compound'), (('growth', 'drive'), 'obj'), (('.', 'do'), 'punct')]

 Named Entites are: 
>> []

================================ Paragraph 125 =================================

To borrow from another industry, imagine if you have a wonderful spy  satellite. Do you want to just be able to say, “There are a bunch of people  there” or, “There’s a known terrorist there, and he’s holding a gun?” 


------------------- Sentence 1 -------------------

 To borrow from another industry, imagine if you have a wonderful spy  satellite. 

Tokens are: 
>> ['To', 'borrow', 'from', 'another', 'industry', ',', 'imagine', 'if', 'you', 'have', 'a', 'wonderful', 'spy', 'satellite', '.'] 

 UPOS tags are: 
>> [('To', 'PART'), ('borrow', 'VERB'), ('from', 'ADP'), ('another', 'DET'), ('industry', 'NOUN'), (',', 'PUNCT'), ('imagine', 'VERB'), ('if', 'SCONJ'), ('you', 'PRON'), ('have', 'VERB'), ('a', 'DET'), ('wonderful', 'ADJ'), ('spy', 'NOUN'), ('satellite', 'NOUN'), ('.', 'PUNCT')] 

 XPOS tags are: 
>> [('To', 'TO'), ('borrow', 'VB'), ('from', 'IN'), ('another', 'DT'), ('industry', 'NN'), (',', ','), ('imagine', 'VB'), ('if', 'IN'), ('you', 'PRP'), ('have', 'VBP'), ('a', 'DT'), ('wonderful', 'JJ'), ('spy', 'NN'), ('satellite', 'NN'), ('.', '.')] 

 Lemmas are: 
>> [('To', 'to'), ('borrow', 'borrow'), ('from', 'from'), ('another', 'another'), ('industry', 'industry'), (',', ','), ('imagine', 'imagine'), ('if', 'if'), ('you', 'you'), ('have', 'have'), ('a', 'a'), ('wonderful', 'wonderful'), ('spy', 'spy'), ('satellite', 'satellite'), ('.', '.')] 

 Dependency tags are: 
>> [(('To', 'borrow'), 'mark'), (('borrow', 'imagine'), 'advcl'), (('from', 'industry'), 'case'), (('another', 'industry'), 'det'), (('industry', 'borrow'), 'obl'), ((',', 'imagine'), 'punct'), (('imagine', 'root'), 'root'), (('if', 'have'), 'mark'), (('you', 'have'), 'nsubj'), (('have', 'imagine'), 'advcl'), (('a', 'satellite'), 'det'), (('wonderful', 'satellite'), 'amod'), (('spy', 'satellite'), 'compound'), (('satellite', 'have'), 'obj'), (('.', 'imagine'), 'punct')]

 Named Entites are: 
>> []

------------------- Sentence 2 -------------------

 Do you want to just be able to say, “There are a bunch of people  there” or, “There’s a known terrorist there, and he’s holding a gun?” 

Tokens are: 
>> ['Do', 'you', 'want', 'to', 'just', 'be', 'able', 'to', 'say', ',', '“', 'There', 'are', 'a', 'bunch', 'of', 'people', 'there', '”', 'or', ',', '“', 'There', '’s', 'a', 'known', 'terrorist', 'there', ',', 'and', 'he', '’s', 'holding', 'a', 'gun', '?', '”'] 

 UPOS tags are: 
>> [('Do', 'AUX'), ('you', 'PRON'), ('want', 'VERB'), ('to', 'PART'), ('just', 'ADV'), ('be', 'AUX'), ('able', 'ADJ'), ('to', 'PART'), ('say', 'VERB'), (',', 'PUNCT'), ('“', 'PUNCT'), ('There', 'PRON'), ('are', 'VERB'), ('a', 'DET'), ('bunch', 'NOUN'), ('of', 'ADP'), ('people', 'NOUN'), ('there', 'ADV'), ('”', 'PUNCT'), ('or', 'CCONJ'), (',', 'PUNCT'), ('“', 'PUNCT'), ('There', 'PRON'), ('’s', 'VERB'), ('a', 'DET'), ('known', 'VERB'), ('terrorist', 'NOUN'), ('there', 'ADV'), (',', 'PUNCT'), ('and', 'CCONJ'), ('he', 'PRON'), ('’s', 'AUX'), ('holding', 'VERB'), ('a', 'DET'), ('gun', 'NOUN'), ('?', 'PUNCT'), ('”', 'PUNCT')] 

 XPOS tags are: 
>> [('Do', 'VBP'), ('you', 'PRP'), ('want', 'VB'), ('to', 'TO'), ('just', 'RB'), ('be', 'VB'), ('able', 'JJ'), ('to', 'TO'), ('say', 'VB'), (',', ','), ('“', '``'), ('There', 'EX'), ('are', 'VBP'), ('a', 'DT'), ('bunch', 'NN'), ('of', 'IN'), ('people', 'NNS'), ('there', 'RB'), ('”', "''"), ('or', 'CC'), (',', ','), ('“', '``'), ('There', 'EX'), ('’s', 'VBZ'), ('a', 'DT'), ('known', 'VBN'), ('terrorist', 'NN'), ('there', 'RB'), (',', ','), ('and', 'CC'), ('he', 'PRP'), ('’s', 'VBZ'), ('holding', 'VBG'), ('a', 'DT'), ('gun', 'NN'), ('?', '.'), ('”', "''")] 

 Lemmas are: 
>> [('Do', 'do'), ('you', 'you'), ('want', 'want'), ('to', 'to'), ('just', 'just'), ('be', 'be'), ('able', 'able'), ('to', 'to'), ('say', 'say'), (',', ','), ('“', "''"), ('There', 'there'), ('are', 'be'), ('a', 'a'), ('bunch', 'bunch'), ('of', 'of'), ('people', 'people'), ('there', 'there'), ('”', "''"), ('or', 'or'), (',', ','), ('“', "''"), ('There', 'there'), ('’s', 'be'), ('a', 'a'), ('known', 'know'), ('terrorist', 'terrorist'), ('there', 'there'), (',', ','), ('and', 'and'), ('he', 'he'), ('’s', 'be'), ('holding', 'hold'), ('a', 'a'), ('gun', 'gun'), ('?', '?'), ('”', "''")] 

 Dependency tags are: 
>> [(('Do', 'want'), 'aux'), (('you', 'want'), 'nsubj'), (('want', 'root'), 'root'), (('to', 'able'), 'mark'), (('just', 'able'), 'advmod'), (('be', 'able'), 'cop'), (('able', 'want'), 'xcomp'), (('to', 'say'), 'mark'), (('say', 'able'), 'xcomp'), ((',', 'are'), 'punct'), (('“', 'are'), 'punct'), (('There', 'are'), 'expl'), (('are', 'want'), 'parataxis'), (('a', 'bunch'), 'det'), (('bunch', 'are'), 'nsubj'), (('of', 'people'), 'case'), (('people', 'bunch'), 'nmod'), (('there', 'people'), 'advmod'), (('”', 'are'), 'punct'), (('or', '’s'), 'cc'), ((',', '’s'), 'punct'), (('“', '’s'), 'punct'), (('There', '’s'), 'expl'), (('’s', 'want'), 'conj'), (('a', 'terrorist'), 'det'), (('known', 'terrorist'), 'amod'), (('terrorist', '’s'), 'nsubj'), (('there', '’s'), 'advmod'), ((',', 'holding'), 'punct'), (('and', 'holding'), 'cc'), (('he', 'holding'), 'nsubj'), (('’s', 'holding'), 'aux'), (('holding', '’s'), 'conj'), (('a', 'gun'), 'det'), (('gun', 'holding'), 'obj'), (('?', '’s'), 'punct'), (('”', '’s'), 'punct')]

 Named Entites are: 
>> []

================================ Paragraph 126 =================================

builds NLP machine   


------------------- Sentence 1 -------------------

 builds NLP machine 

Tokens are: 
>> ['builds', 'NLP', 'machine'] 

 UPOS tags are: 
>> [('builds', 'VERB'), ('NLP', 'NOUN'), ('machine', 'NOUN')] 

 XPOS tags are: 
>> [('builds', 'VBZ'), ('NLP', 'NN'), ('machine', 'NN')] 

 Lemmas are: 
>> [('builds', 'build'), ('NLP', 'nlp'), ('machine', 'machine')] 

 Dependency tags are: 
>> [(('builds', 'root'), 'root'), (('NLP', 'machine'), 'compound'), (('machine', 'builds'), 'obj')]

 Named Entites are: 
>> [('NLP', 'ORG')]

================================ Paragraph 127 =================================

learning models and manages   


------------------- Sentence 1 -------------------

 learning models and manages 

Tokens are: 
>> ['learning', 'models', 'and', 'manages'] 

 UPOS tags are: 
>> [('learning', 'VERB'), ('models', 'NOUN'), ('and', 'CCONJ'), ('manages', 'NOUN')] 

 XPOS tags are: 
>> [('learning', 'VBG'), ('models', 'NNS'), ('and', 'CC'), ('manages', 'NNS')] 

 Lemmas are: 
>> [('learning', 'learn'), ('models', 'model'), ('and', 'and'), ('manages', 'manage')] 

 Dependency tags are: 
>> [(('learning', 'root'), 'root'), (('models', 'learning'), 'obj'), (('and', 'manages'), 'cc'), (('manages', 'models'), 'conj')]

 Named Entites are: 
>> []

================================ Paragraph 128 =================================

dependencies between them. 


------------------- Sentence 1 -------------------

 dependencies between them. 

Tokens are: 
>> ['dependencies', 'between', 'them', '.'] 

 UPOS tags are: 
>> [('dependencies', 'NOUN'), ('between', 'ADP'), ('them', 'PRON'), ('.', 'PUNCT')] 

 XPOS tags are: 
>> [('dependencies', 'NNS'), ('between', 'IN'), ('them', 'PRP'), ('.', '.')] 

 Lemmas are: 
>> [('dependencies', 'dependency'), ('between', 'between'), ('them', 'they'), ('.', '.')] 

 Dependency tags are: 
>> [(('dependencies', 'root'), 'root'), (('between', 'them'), 'case'), (('them', 'dependencies'), 'nmod'), (('.', 'dependencies'), 'punct')]

 Named Entites are: 
>> []

================================ Paragraph 129 =================================

AI   Assembler  


------------------- Sentence 1 -------------------

 AI   Assembler 

Tokens are: 
>> ['AI', 'Assembler'] 

 UPOS tags are: 
>> [('AI', 'PROPN'), ('Assembler', 'PROPN')] 

 XPOS tags are: 
>> [('AI', 'NNP'), ('Assembler', 'NNP')] 

 Lemmas are: 
>> [('AI', 'AI'), ('Assembler', 'Assembler')] 

 Dependency tags are: 
>> [(('AI', 'Assembler'), 'compound'), (('Assembler', 'root'), 'root')]

 Named Entites are: 
>> []

================================ Paragraph 130 =================================

(our proprietary   software)


------------------- Sentence 1 -------------------

 (our proprietary   software) 

Tokens are: 
>> ['(', 'our', 'proprietary', 'software', ')'] 

 UPOS tags are: 
>> [('(', 'PUNCT'), ('our', 'PRON'), ('proprietary', 'ADJ'), ('software', 'NOUN'), (')', 'PUNCT')] 

 XPOS tags are: 
>> [('(', '-LRB-'), ('our', 'PRP$'), ('proprietary', 'JJ'), ('software', 'NN'), (')', '-RRB-')] 

 Lemmas are: 
>> [('(', '('), ('our', 'we'), ('proprietary', 'proprietary'), ('software', 'software'), (')', ')')] 

 Dependency tags are: 
>> [(('(', 'software'), 'punct'), (('our', 'software'), 'nmod:poss'), (('proprietary', 'software'), 'amod'), (('software', 'root'), 'root'), ((')', 'software'), 'punct')]

 Named Entites are: 
>> []

================================ Paragraph 131 =================================

W H I T E  P A P E R 


------------------- Sentence 1 -------------------

 W H I T E  P A P E R 

Tokens are: 
>> ['W', 'H', 'I', 'T', 'E', 'P', 'A', 'P', 'E', 'R'] 

 UPOS tags are: 
>> [('W', 'PROPN'), ('H', 'PUNCT'), ('I', 'PRON'), ('T', 'AUX'), ('E', 'PROPN'), ('P', 'NOUN'), ('A', 'NOUN'), ('P', 'NOUN'), ('E', 'NOUN'), ('R', 'NOUN')] 

 XPOS tags are: 
>> [('W', 'NNP'), ('H', ','), ('I', 'PRP'), ('T', 'VBP'), ('E', 'NNP'), ('P', 'NN'), ('A', 'NN'), ('P', 'NN'), ('E', 'NN'), ('R', 'NN')] 

 Lemmas are: 
>> [('W', 'W'), ('H', 'H'), ('I', 'I'), ('T', 'T'), ('E', 'E'), ('P', 'p'), ('A', 'a'), ('P', 'p'), ('E', 'e'), ('R', 'R')] 

 Dependency tags are: 
>> [(('W', 'T'), 'vocative'), (('H', 'W'), 'punct'), (('I', 'T'), 'nsubj'), (('T', 'root'), 'root'), (('E', 'T'), 'obj'), (('P', 'T'), 'obj'), (('A', 'E'), 'compound'), (('P', 'E'), 'compound'), (('E', 'R'), 'compound'), (('R', 'T'), 'obj')]

 Named Entites are: 
>> []

================================ Paragraph 132 =================================

9|       |   Lexalytics, Inc., 48 North Pleasant St. Unit 301, Amherst MA 01002 USA   |   1-800-377-8036 |   www.lexalytics.com 


------------------- Sentence 1 -------------------

 9|       |   Lexalytics, Inc., 48 North Pleasant St. Unit 301, Amherst MA 01002 USA   |   1-800-377-8036 |   www.lexalytics.com 

Tokens are: 
>> ['9', '|', '|', 'Lexalytics', ',', 'Inc.', ',', '48', 'North', 'Pleasant', 'St.', 'Unit', '301', ',', 'Amherst', 'MA', '01002', 'USA', '|', '1-800-377-8036', '|', 'www.lexalytics.com'] 

 UPOS tags are: 
>> [('9', 'NUM'), ('|', 'PUNCT'), ('|', 'PUNCT'), ('Lexalytics', 'PROPN'), (',', 'PUNCT'), ('Inc.', 'PROPN'), (',', 'PUNCT'), ('48', 'NUM'), ('North', 'PROPN'), ('Pleasant', 'ADJ'), ('St.', 'PROPN'), ('Unit', 'NOUN'), ('301', 'NUM'), (',', 'PUNCT'), ('Amherst', 'PROPN'), ('MA', 'PROPN'), ('01002', 'NUM'), ('USA', 'PROPN'), ('|', 'PUNCT'), ('1-800-377-8036', 'NUM'), ('|', 'PUNCT'), ('www.lexalytics.com', 'X')] 

 XPOS tags are: 
>> [('9', 'LS'), ('|', 'NFP'), ('|', 'NFP'), ('Lexalytics', 'NNP'), (',', ','), ('Inc.', 'NNP'), (',', ','), ('48', 'CD'), ('North', 'NNP'), ('Pleasant', 'NNP'), ('St.', 'NNP'), ('Unit', 'NN'), ('301', 'CD'), (',', ','), ('Amherst', 'NNP'), ('MA', 'NNP'), ('01002', 'CD'), ('USA', 'NNP'), ('|', 'NFP'), ('1-800-377-8036', 'CD'), ('|', 'NFP'), ('www.lexalytics.com', 'ADD')] 

 Lemmas are: 
>> [('9', '9'), ('|', '|'), ('|', '|'), ('Lexalytics', 'Lexalytics'), (',', ','), ('Inc.', 'Inc.'), (',', ','), ('48', '48'), ('North', 'North'), ('Pleasant', 'Pleasant'), ('St.', 'St.'), ('Unit', 'unit'), ('301', '301'), (',', ','), ('Amherst', 'Amherst'), ('MA', 'MA'), ('01002', '01002'), ('USA', 'USA'), ('|', '|'), ('1-800-377-8036', '1-800-377-8036'), ('|', '|'), ('www.lexalytics.com', 'www.lexalytics.com')] 

 Dependency tags are: 
>> [(('9', 'Inc.'), 'nummod'), (('|', '9'), 'punct'), (('|', '9'), 'punct'), (('Lexalytics', 'Inc.'), 'compound'), ((',', 'Inc.'), 'punct'), (('Inc.', 'root'), 'root'), ((',', 'Inc.'), 'punct'), (('48', 'St.'), 'nummod'), (('North', 'St.'), 'compound'), (('Pleasant', 'St.'), 'amod'), (('St.', 'Inc.'), 'list'), (('Unit', 'St.'), 'appos'), (('301', 'Unit'), 'nummod'), ((',', 'MA'), 'punct'), (('Amherst', 'MA'), 'appos'), (('MA', 'Inc.'), 'list'), (('01002', 'USA'), 'nummod'), (('USA', 'MA'), 'appos'), (('|', 'USA'), 'punct'), (('1-800-377-8036', 'Inc.'), 'list'), (('|', '1-800-377-8036'), 'punct'), (('www.lexalytics.com', 'Inc.'), 'list')]

 Named Entites are: 
>> [('9|       |   Lexalytics, Inc.', 'ORG'), ('301', 'CARDINAL')]

================================ Paragraph 133 =================================

C O D I N G  V S .  L E A R N I N G :   M A K I N G  T H E  C A S E  F O R  E A C H  Let’s use the same sentence for this next example. Let me hear you say: 


------------------- Sentence 1 -------------------

 C O D I N G  V S .  L E A R N I N G :   M A K I N G  T H E  C A S E  F O R  E A C H  Let’s use the same sentence for this next example. 

Tokens are: 
>> ['C', 'O', 'D', 'I', 'N', 'G', 'V', 'S', '.', 'L', 'E', 'A', 'R', 'N', 'I', 'N', 'G', ':', 'M', 'A', 'K', 'I', 'N', 'G', 'T', 'H', 'E', 'C', 'A', 'S', 'E', 'F', 'O', 'R', 'E', 'A', 'C', 'H', 'Let', '’s', 'use', 'the', 'same', 'sentence', 'for', 'this', 'next', 'example', '.'] 

 UPOS tags are: 
>> [('C', 'PROPN'), ('O', 'INTJ'), ('D', 'INTJ'), ('I', 'PRON'), ('N', 'VERB'), ('G', 'PROPN'), ('V', 'PROPN'), ('S', 'PART'), ('.', 'PUNCT'), ('L', 'PUNCT'), ('E', 'X'), ('A', 'PROPN'), ('R', 'X'), ('N', 'X'), ('I', 'PRON'), ('N', 'VERB'), ('G', 'NOUN'), (':', 'PUNCT'), ('M', 'NOUN'), ('A', 'DET'), ('K', 'NOUN'), ('I', 'NUM'), ('N', 'NOUN'), ('G', 'NOUN'), ('T', 'NOUN'), ('H', 'NOUN'), ('E', 'NOUN'), ('C', 'PROPN'), ('A', 'PROPN'), ('S', 'PROPN'), ('E', 'PROPN'), ('F', 'PROPN'), ('O', 'NOUN'), ('R', 'PUNCT'), ('E', 'PROPN'), ('A', 'PUNCT'), ('C', 'PROPN'), ('H', 'PUNCT'), ('Let', 'VERB'), ('’s', 'PRON'), ('use', 'VERB'), ('the', 'DET'), ('same', 'ADJ'), ('sentence', 'NOUN'), ('for', 'ADP'), ('this', 'DET'), ('next', 'ADJ'), ('example', 'NOUN'), ('.', 'PUNCT')] 

 XPOS tags are: 
>> [('C', 'NNP'), ('O', 'UH'), ('D', 'UH'), ('I', 'PRP'), ('N', 'VBP'), ('G', 'NNP'), ('V', 'NNP'), ('S', 'POS'), ('.', '.'), ('L', ','), ('E', 'FW'), ('A', 'NNP'), ('R', 'FW'), ('N', 'FW'), ('I', 'PRP'), ('N', 'VBP'), ('G', 'NN'), (':', ':'), ('M', 'NN'), ('A', 'DT'), ('K', 'NN'), ('I', 'CD'), ('N', 'NN'), ('G', 'NN'), ('T', 'NN'), ('H', 'NN'), ('E', 'NN'), ('C', 'NNP'), ('A', 'NNP'), ('S', 'NNP'), ('E', 'NNP'), ('F', 'NNP'), ('O', 'NN'), ('R', ','), ('E', 'NNP'), ('A', ','), ('C', 'NNP'), ('H', ','), ('Let', 'VB'), ('’s', 'PRP'), ('use', 'VB'), ('the', 'DT'), ('same', 'JJ'), ('sentence', 'NN'), ('for', 'IN'), ('this', 'DT'), ('next', 'JJ'), ('example', 'NN'), ('.', '.')] 

 Lemmas are: 
>> [('C', 'C'), ('O', 'o'), ('D', 'D'), ('I', 'I'), ('N', 'N'), ('G', 'G'), ('V', 'V'), ('S', "'s"), ('.', '.'), ('L', 'L'), ('E', 'E'), ('A', 'A'), ('R', 'r'), ('N', 'N'), ('I', 'I'), ('N', 'N'), ('G', 'g'), (':', ':'), ('M', 'm'), ('A', 'a'), ('K', 'k'), ('I', 'i'), ('N', 'N'), ('G', 'g'), ('T', 'T'), ('H', 'h'), ('E', 'e'), ('C', 'C'), ('A', 'A'), ('S', 'S'), ('E', 'E'), ('F', 'F'), ('O', 'o'), ('R', 'R'), ('E', 'E'), ('A', 'a'), ('C', 'C'), ('H', 'H'), ('Let', 'let'), ('’s', 'us'), ('use', 'use'), ('the', 'the'), ('same', 'same'), ('sentence', 'sentence'), ('for', 'for'), ('this', 'this'), ('next', 'next'), ('example', 'example'), ('.', '.')] 

 Dependency tags are: 
>> [(('C', 'N'), 'discourse'), (('O', 'N'), 'discourse'), (('D', 'N'), 'discourse'), (('I', 'N'), 'nsubj'), (('N', 'root'), 'root'), (('G', 'V'), 'compound'), (('V', 'N'), 'obj'), (('S', 'V'), 'case'), (('.', 'N'), 'punct'), (('L', 'N'), 'punct'), (('E', 'N'), 'parataxis'), (('A', 'E'), 'flat'), (('R', 'N'), 'compound'), (('N', 'E'), 'nmod'), (('I', 'N'), 'nsubj'), (('N', 'N'), 'parataxis'), (('G', 'N'), 'obj'), ((':', 'M'), 'punct'), (('M', 'N'), 'obj'), (('A', 'K'), 'det'), (('K', 'M'), 'appos'), (('I', 'G'), 'nummod'), (('N', 'G'), 'compound'), (('G', 'M'), 'appos'), (('T', 'E'), 'compound'), (('H', 'E'), 'compound'), (('E', 'M'), 'conj'), (('C', 'E'), 'compound'), (('A', 'E'), 'compound'), (('S', 'E'), 'compound'), (('E', 'E'), 'appos'), (('F', 'O'), 'compound'), (('O', 'E'), 'appos'), (('R', 'N'), 'punct'), (('E', 'E'), 'appos'), (('A', 'C'), 'compound'), (('C', 'E'), 'appos'), (('H', 'Let'), 'punct'), (('Let', 'N'), 'parataxis'), (('’s', 'Let'), 'obj'), (('use', 'Let'), 'xcomp'), (('the', 'sentence'), 'det'), (('same', 'sentence'), 'amod'), (('sentence', 'use'), 'obj'), (('for', 'example'), 'case'), (('this', 'example'), 'det'), (('next', 'example'), 'amod'), (('example', 'use'), 'obl'), (('.', 'C'), 'punct')]

 Named Entites are: 
>> []

------------------- Sentence 2 -------------------

 Let me hear you say: 

Tokens are: 
>> ['Let', 'me', 'hear', 'you', 'say', ':'] 

 UPOS tags are: 
>> [('Let', 'VERB'), ('me', 'PRON'), ('hear', 'VERB'), ('you', 'PRON'), ('say', 'VERB'), (':', 'PUNCT')] 

 XPOS tags are: 
>> [('Let', 'VB'), ('me', 'PRP'), ('hear', 'VB'), ('you', 'PRP'), ('say', 'VBP'), (':', ':')] 

 Lemmas are: 
>> [('Let', 'let'), ('me', 'I'), ('hear', 'hear'), ('you', 'you'), ('say', 'say'), (':', ':')] 

 Dependency tags are: 
>> [(('Let', 'root'), 'root'), (('me', 'Let'), 'obj'), (('hear', 'Let'), 'xcomp'), (('you', 'say'), 'nsubj'), (('say', 'hear'), 'ccomp'), ((':', 'Let'), 'punct')]

 Named Entites are: 
>> []

================================ Paragraph 134 =================================

“Lexalytics is the best text analytics company ever.” 


------------------- Sentence 1 -------------------

 “Lexalytics is the best text analytics company ever.” 

Tokens are: 
>> ['“', 'Lexalytics', 'is', 'the', 'best', 'text', 'analytics', 'company', 'ever', '.', '”'] 

 UPOS tags are: 
>> [('“', 'PUNCT'), ('Lexalytics', 'NOUN'), ('is', 'AUX'), ('the', 'DET'), ('best', 'ADJ'), ('text', 'NOUN'), ('analytics', 'NOUN'), ('company', 'NOUN'), ('ever', 'ADV'), ('.', 'PUNCT'), ('”', 'PUNCT')] 

 XPOS tags are: 
>> [('“', '``'), ('Lexalytics', 'NNS'), ('is', 'VBZ'), ('the', 'DT'), ('best', 'JJS'), ('text', 'NN'), ('analytics', 'NN'), ('company', 'NN'), ('ever', 'RB'), ('.', '.'), ('”', "''")] 

 Lemmas are: 
>> [('“', "''"), ('Lexalytics', 'lexalytics'), ('is', 'be'), ('the', 'the'), ('best', 'good'), ('text', 'text'), ('analytics', 'analytic'), ('company', 'company'), ('ever', 'ever'), ('.', '.'), ('”', "''")] 

 Dependency tags are: 
>> [(('“', 'company'), 'punct'), (('Lexalytics', 'company'), 'nsubj'), (('is', 'company'), 'cop'), (('the', 'company'), 'det'), (('best', 'company'), 'amod'), (('text', 'analytics'), 'compound'), (('analytics', 'company'), 'compound'), (('company', 'root'), 'root'), (('ever', 'company'), 'advmod'), (('.', 'company'), 'punct'), (('”', 'company'), 'punct')]

 Named Entites are: 
>> [('Lexalytics', 'ORG')]

================================ Paragraph 135 =================================

Now look at the period at the end of the sentence. Periods are important   in English because they frequently denote the end of a sentence. It’s  important to be able to break sentences apart so that you can figure out  which statements go together.  


------------------- Sentence 1 -------------------

 Now look at the period at the end of the sentence. 

Tokens are: 
>> ['Now', 'look', 'at', 'the', 'period', 'at', 'the', 'end', 'of', 'the', 'sentence', '.'] 

 UPOS tags are: 
>> [('Now', 'ADV'), ('look', 'VERB'), ('at', 'ADP'), ('the', 'DET'), ('period', 'NOUN'), ('at', 'ADP'), ('the', 'DET'), ('end', 'NOUN'), ('of', 'ADP'), ('the', 'DET'), ('sentence', 'NOUN'), ('.', 'PUNCT')] 

 XPOS tags are: 
>> [('Now', 'RB'), ('look', 'VB'), ('at', 'IN'), ('the', 'DT'), ('period', 'NN'), ('at', 'IN'), ('the', 'DT'), ('end', 'NN'), ('of', 'IN'), ('the', 'DT'), ('sentence', 'NN'), ('.', '.')] 

 Lemmas are: 
>> [('Now', 'now'), ('look', 'look'), ('at', 'at'), ('the', 'the'), ('period', 'period'), ('at', 'at'), ('the', 'the'), ('end', 'end'), ('of', 'of'), ('the', 'the'), ('sentence', 'sentence'), ('.', '.')] 

 Dependency tags are: 
>> [(('Now', 'look'), 'advmod'), (('look', 'root'), 'root'), (('at', 'period'), 'case'), (('the', 'period'), 'det'), (('period', 'look'), 'obl'), (('at', 'end'), 'case'), (('the', 'end'), 'det'), (('end', 'look'), 'obl'), (('of', 'sentence'), 'case'), (('the', 'sentence'), 'det'), (('sentence', 'end'), 'nmod'), (('.', 'look'), 'punct')]

 Named Entites are: 
>> []

------------------- Sentence 2 -------------------

 Periods are important   in English because they frequently denote the end of a sentence. 

Tokens are: 
>> ['Periods', 'are', 'important', 'in', 'English', 'because', 'they', 'frequently', 'denote', 'the', 'end', 'of', 'a', 'sentence', '.'] 

 UPOS tags are: 
>> [('Periods', 'NOUN'), ('are', 'AUX'), ('important', 'ADJ'), ('in', 'ADP'), ('English', 'PROPN'), ('because', 'SCONJ'), ('they', 'PRON'), ('frequently', 'ADV'), ('denote', 'VERB'), ('the', 'DET'), ('end', 'NOUN'), ('of', 'ADP'), ('a', 'DET'), ('sentence', 'NOUN'), ('.', 'PUNCT')] 

 XPOS tags are: 
>> [('Periods', 'NNS'), ('are', 'VBP'), ('important', 'JJ'), ('in', 'IN'), ('English', 'NNP'), ('because', 'IN'), ('they', 'PRP'), ('frequently', 'RB'), ('denote', 'VBP'), ('the', 'DT'), ('end', 'NN'), ('of', 'IN'), ('a', 'DT'), ('sentence', 'NN'), ('.', '.')] 

 Lemmas are: 
>> [('Periods', 'period'), ('are', 'be'), ('important', 'important'), ('in', 'in'), ('English', 'English'), ('because', 'because'), ('they', 'they'), ('frequently', 'frequently'), ('denote', 'denote'), ('the', 'the'), ('end', 'end'), ('of', 'of'), ('a', 'a'), ('sentence', 'sentence'), ('.', '.')] 

 Dependency tags are: 
>> [(('Periods', 'important'), 'nsubj'), (('are', 'important'), 'cop'), (('important', 'root'), 'root'), (('in', 'English'), 'case'), (('English', 'important'), 'obl'), (('because', 'denote'), 'mark'), (('they', 'denote'), 'nsubj'), (('frequently', 'denote'), 'advmod'), (('denote', 'important'), 'advcl'), (('the', 'end'), 'det'), (('end', 'denote'), 'obj'), (('of', 'sentence'), 'case'), (('a', 'sentence'), 'det'), (('sentence', 'end'), 'nmod'), (('.', 'important'), 'punct')]

 Named Entites are: 
>> [('English', 'LANGUAGE')]

------------------- Sentence 3 -------------------

 It’s  important to be able to break sentences apart so that you can figure out  which statements go together. 

Tokens are: 
>> ['It', '’s', 'important', 'to', 'be', 'able', 'to', 'break', 'sentences', 'apart', 'so', 'that', 'you', 'can', 'figure', 'out', 'which', 'statements', 'go', 'together', '.'] 

 UPOS tags are: 
>> [('It', 'PRON'), ('’s', 'AUX'), ('important', 'ADJ'), ('to', 'PART'), ('be', 'AUX'), ('able', 'ADJ'), ('to', 'PART'), ('break', 'VERB'), ('sentences', 'NOUN'), ('apart', 'ADV'), ('so', 'SCONJ'), ('that', 'SCONJ'), ('you', 'PRON'), ('can', 'AUX'), ('figure', 'VERB'), ('out', 'ADP'), ('which', 'DET'), ('statements', 'NOUN'), ('go', 'VERB'), ('together', 'ADV'), ('.', 'PUNCT')] 

 XPOS tags are: 
>> [('It', 'PRP'), ('’s', 'VBZ'), ('important', 'JJ'), ('to', 'TO'), ('be', 'VB'), ('able', 'JJ'), ('to', 'TO'), ('break', 'VB'), ('sentences', 'NNS'), ('apart', 'RB'), ('so', 'IN'), ('that', 'IN'), ('you', 'PRP'), ('can', 'MD'), ('figure', 'VB'), ('out', 'RP'), ('which', 'WDT'), ('statements', 'NNS'), ('go', 'VBP'), ('together', 'RB'), ('.', '.')] 

 Lemmas are: 
>> [('It', 'it'), ('’s', 'be'), ('important', 'important'), ('to', 'to'), ('be', 'be'), ('able', 'able'), ('to', 'to'), ('break', 'break'), ('sentences', 'sentence'), ('apart', 'apart'), ('so', 'so'), ('that', 'that'), ('you', 'you'), ('can', 'can'), ('figure', 'figure'), ('out', 'out'), ('which', 'which'), ('statements', 'statement'), ('go', 'go'), ('together', 'together'), ('.', '.')] 

 Dependency tags are: 
>> [(('It', 'important'), 'expl'), (('’s', 'important'), 'cop'), (('important', 'root'), 'root'), (('to', 'able'), 'mark'), (('be', 'able'), 'cop'), (('able', 'important'), 'csubj'), (('to', 'break'), 'mark'), (('break', 'able'), 'xcomp'), (('sentences', 'break'), 'obj'), (('apart', 'break'), 'advmod'), (('so', 'figure'), 'mark'), (('that', 'so'), 'fixed'), (('you', 'figure'), 'nsubj'), (('can', 'figure'), 'aux'), (('figure', 'break'), 'advcl'), (('out', 'figure'), 'compound:prt'), (('which', 'statements'), 'det'), (('statements', 'go'), 'nsubj'), (('go', 'figure'), 'ccomp'), (('together', 'go'), 'advmod'), (('.', 'important'), 'punct')]

 Named Entites are: 
>> []

================================ Paragraph 136 =================================

However, periods also denote other things, like “Dr.” for doctor, or “Mr.”   for mister. How can a machine tell whether the period is denoting the end   of a sentence or a form of address? We could train a machine learning model  for this task by marking up examples of each. But this isn’t necessarily the  most efficient approach. After all, there are only a few cases in the English  language where the period is used for anything other than denoting the end  of a sentence. It is more efficient, faster computationally, and more precise  to just hard-code these cases using NLP code or other algorithms.  


------------------- Sentence 1 -------------------

 However, periods also denote other things, like “Dr.” for doctor, or “Mr.”   for mister. 

Tokens are: 
>> ['However', ',', 'periods', 'also', 'denote', 'other', 'things', ',', 'like', '“', 'Dr.', '”', 'for', 'doctor', ',', 'or', '“', 'Mr.', '”', 'for', 'mister', '.'] 

 UPOS tags are: 
>> [('However', 'ADV'), (',', 'PUNCT'), ('periods', 'NOUN'), ('also', 'ADV'), ('denote', 'VERB'), ('other', 'ADJ'), ('things', 'NOUN'), (',', 'PUNCT'), ('like', 'ADP'), ('“', 'PUNCT'), ('Dr.', 'PROPN'), ('”', 'PUNCT'), ('for', 'ADP'), ('doctor', 'NOUN'), (',', 'PUNCT'), ('or', 'CCONJ'), ('“', 'PUNCT'), ('Mr.', 'PROPN'), ('”', 'PUNCT'), ('for', 'ADP'), ('mister', 'NOUN'), ('.', 'PUNCT')] 

 XPOS tags are: 
>> [('However', 'RB'), (',', ','), ('periods', 'NNS'), ('also', 'RB'), ('denote', 'VBP'), ('other', 'JJ'), ('things', 'NNS'), (',', ','), ('like', 'IN'), ('“', '``'), ('Dr.', 'NNP'), ('”', "''"), ('for', 'IN'), ('doctor', 'NN'), (',', ','), ('or', 'CC'), ('“', '``'), ('Mr.', 'NNP'), ('”', "''"), ('for', 'IN'), ('mister', 'NN'), ('.', '.')] 

 Lemmas are: 
>> [('However', 'however'), (',', ','), ('periods', 'period'), ('also', 'also'), ('denote', 'denote'), ('other', 'other'), ('things', 'thing'), (',', ','), ('like', 'like'), ('“', "''"), ('Dr.', 'Dr.'), ('”', "''"), ('for', 'for'), ('doctor', 'doctor'), (',', ','), ('or', 'or'), ('“', "''"), ('Mr.', 'Mr.'), ('”', "''"), ('for', 'for'), ('mister', 'mister'), ('.', '.')] 

 Dependency tags are: 
>> [(('However', 'denote'), 'advmod'), ((',', 'denote'), 'punct'), (('periods', 'denote'), 'nsubj'), (('also', 'denote'), 'advmod'), (('denote', 'root'), 'root'), (('other', 'things'), 'amod'), (('things', 'denote'), 'obj'), ((',', 'Dr.'), 'punct'), (('like', 'Dr.'), 'case'), (('“', 'Dr.'), 'punct'), (('Dr.', 'things'), 'nmod'), (('”', 'Dr.'), 'punct'), (('for', 'doctor'), 'case'), (('doctor', 'Dr.'), 'nmod'), ((',', 'Mr.'), 'punct'), (('or', 'Mr.'), 'cc'), (('“', 'Mr.'), 'punct'), (('Mr.', 'Dr.'), 'conj'), (('”', 'Mr.'), 'punct'), (('for', 'mister'), 'case'), (('mister', 'Mr.'), 'nmod'), (('.', 'denote'), 'punct')]

 Named Entites are: 
>> []

------------------- Sentence 2 -------------------

 How can a machine tell whether the period is denoting the end   of a sentence or a form of address? 

Tokens are: 
>> ['How', 'can', 'a', 'machine', 'tell', 'whether', 'the', 'period', 'is', 'denoting', 'the', 'end', 'of', 'a', 'sentence', 'or', 'a', 'form', 'of', 'address', '?'] 

 UPOS tags are: 
>> [('How', 'ADV'), ('can', 'AUX'), ('a', 'DET'), ('machine', 'NOUN'), ('tell', 'VERB'), ('whether', 'SCONJ'), ('the', 'DET'), ('period', 'NOUN'), ('is', 'AUX'), ('denoting', 'VERB'), ('the', 'DET'), ('end', 'NOUN'), ('of', 'ADP'), ('a', 'DET'), ('sentence', 'NOUN'), ('or', 'CCONJ'), ('a', 'DET'), ('form', 'NOUN'), ('of', 'ADP'), ('address', 'NOUN'), ('?', 'PUNCT')] 

 XPOS tags are: 
>> [('How', 'WRB'), ('can', 'MD'), ('a', 'DT'), ('machine', 'NN'), ('tell', 'VB'), ('whether', 'IN'), ('the', 'DT'), ('period', 'NN'), ('is', 'VBZ'), ('denoting', 'VBG'), ('the', 'DT'), ('end', 'NN'), ('of', 'IN'), ('a', 'DT'), ('sentence', 'NN'), ('or', 'CC'), ('a', 'DT'), ('form', 'NN'), ('of', 'IN'), ('address', 'NN'), ('?', '.')] 

 Lemmas are: 
>> [('How', 'how'), ('can', 'can'), ('a', 'a'), ('machine', 'machine'), ('tell', 'tell'), ('whether', 'whether'), ('the', 'the'), ('period', 'period'), ('is', 'be'), ('denoting', 'denote'), ('the', 'the'), ('end', 'end'), ('of', 'of'), ('a', 'a'), ('sentence', 'sentence'), ('or', 'or'), ('a', 'a'), ('form', 'form'), ('of', 'of'), ('address', 'address'), ('?', '?')] 

 Dependency tags are: 
>> [(('How', 'tell'), 'advmod'), (('can', 'tell'), 'aux'), (('a', 'machine'), 'det'), (('machine', 'tell'), 'nsubj'), (('tell', 'root'), 'root'), (('whether', 'denoting'), 'mark'), (('the', 'period'), 'det'), (('period', 'denoting'), 'nsubj'), (('is', 'denoting'), 'aux'), (('denoting', 'tell'), 'ccomp'), (('the', 'end'), 'det'), (('end', 'denoting'), 'obj'), (('of', 'sentence'), 'case'), (('a', 'sentence'), 'det'), (('sentence', 'end'), 'nmod'), (('or', 'form'), 'cc'), (('a', 'form'), 'det'), (('form', 'sentence'), 'conj'), (('of', 'address'), 'case'), (('address', 'form'), 'nmod'), (('?', 'tell'), 'punct')]

 Named Entites are: 
>> []

------------------- Sentence 3 -------------------

 We could train a machine learning model  for this task by marking up examples of each. 

Tokens are: 
>> ['We', 'could', 'train', 'a', 'machine', 'learning', 'model', 'for', 'this', 'task', 'by', 'marking', 'up', 'examples', 'of', 'each', '.'] 

 UPOS tags are: 
>> [('We', 'PRON'), ('could', 'AUX'), ('train', 'VERB'), ('a', 'DET'), ('machine', 'NOUN'), ('learning', 'NOUN'), ('model', 'NOUN'), ('for', 'ADP'), ('this', 'DET'), ('task', 'NOUN'), ('by', 'SCONJ'), ('marking', 'VERB'), ('up', 'ADP'), ('examples', 'NOUN'), ('of', 'ADP'), ('each', 'DET'), ('.', 'PUNCT')] 

 XPOS tags are: 
>> [('We', 'PRP'), ('could', 'MD'), ('train', 'VB'), ('a', 'DT'), ('machine', 'NN'), ('learning', 'NN'), ('model', 'NN'), ('for', 'IN'), ('this', 'DT'), ('task', 'NN'), ('by', 'IN'), ('marking', 'VBG'), ('up', 'RP'), ('examples', 'NNS'), ('of', 'IN'), ('each', 'DT'), ('.', '.')] 

 Lemmas are: 
>> [('We', 'we'), ('could', 'could'), ('train', 'train'), ('a', 'a'), ('machine', 'machine'), ('learning', 'learning'), ('model', 'model'), ('for', 'for'), ('this', 'this'), ('task', 'task'), ('by', 'by'), ('marking', 'mark'), ('up', 'up'), ('examples', 'example'), ('of', 'of'), ('each', 'each'), ('.', '.')] 

 Dependency tags are: 
>> [(('We', 'train'), 'nsubj'), (('could', 'train'), 'aux'), (('train', 'root'), 'root'), (('a', 'model'), 'det'), (('machine', 'model'), 'compound'), (('learning', 'model'), 'compound'), (('model', 'train'), 'obj'), (('for', 'task'), 'case'), (('this', 'task'), 'det'), (('task', 'train'), 'obl'), (('by', 'marking'), 'mark'), (('marking', 'train'), 'advcl'), (('up', 'marking'), 'compound:prt'), (('examples', 'marking'), 'obj'), (('of', 'each'), 'case'), (('each', 'examples'), 'nmod'), (('.', 'train'), 'punct')]

 Named Entites are: 
>> []

------------------- Sentence 4 -------------------

 But this isn’t necessarily the  most efficient approach. 

Tokens are: 
>> ['But', 'this', 'is', 'n’t', 'necessarily', 'the', 'most', 'efficient', 'approach', '.'] 

 UPOS tags are: 
>> [('But', 'CCONJ'), ('this', 'PRON'), ('is', 'AUX'), ('n’t', 'PART'), ('necessarily', 'ADV'), ('the', 'DET'), ('most', 'ADV'), ('efficient', 'ADJ'), ('approach', 'NOUN'), ('.', 'PUNCT')] 

 XPOS tags are: 
>> [('But', 'CC'), ('this', 'DT'), ('is', 'VBZ'), ('n’t', 'RB'), ('necessarily', 'RB'), ('the', 'DT'), ('most', 'RBS'), ('efficient', 'JJ'), ('approach', 'NN'), ('.', '.')] 

 Lemmas are: 
>> [('But', 'but'), ('this', 'this'), ('is', 'be'), ('n’t', 'not'), ('necessarily', 'necessarily'), ('the', 'the'), ('most', 'most'), ('efficient', 'efficient'), ('approach', 'approach'), ('.', '.')] 

 Dependency tags are: 
>> [(('But', 'approach'), 'cc'), (('this', 'approach'), 'nsubj'), (('is', 'approach'), 'cop'), (('n’t', 'approach'), 'advmod'), (('necessarily', 'approach'), 'advmod'), (('the', 'approach'), 'det'), (('most', 'efficient'), 'advmod'), (('efficient', 'approach'), 'amod'), (('approach', 'root'), 'root'), (('.', 'approach'), 'punct')]

 Named Entites are: 
>> []

------------------- Sentence 5 -------------------

 After all, there are only a few cases in the English  language where the period is used for anything other than denoting the end  of a sentence. 

Tokens are: 
>> ['After', 'all', ',', 'there', 'are', 'only', 'a', 'few', 'cases', 'in', 'the', 'English', 'language', 'where', 'the', 'period', 'is', 'used', 'for', 'anything', 'other', 'than', 'denoting', 'the', 'end', 'of', 'a', 'sentence', '.'] 

 UPOS tags are: 
>> [('After', 'ADP'), ('all', 'DET'), (',', 'PUNCT'), ('there', 'PRON'), ('are', 'VERB'), ('only', 'ADV'), ('a', 'DET'), ('few', 'ADJ'), ('cases', 'NOUN'), ('in', 'ADP'), ('the', 'DET'), ('English', 'ADJ'), ('language', 'NOUN'), ('where', 'SCONJ'), ('the', 'DET'), ('period', 'NOUN'), ('is', 'AUX'), ('used', 'VERB'), ('for', 'ADP'), ('anything', 'NOUN'), ('other', 'ADJ'), ('than', 'SCONJ'), ('denoting', 'VERB'), ('the', 'DET'), ('end', 'NOUN'), ('of', 'ADP'), ('a', 'DET'), ('sentence', 'NOUN'), ('.', 'PUNCT')] 

 XPOS tags are: 
>> [('After', 'IN'), ('all', 'DT'), (',', ','), ('there', 'EX'), ('are', 'VBP'), ('only', 'RB'), ('a', 'DT'), ('few', 'JJ'), ('cases', 'NNS'), ('in', 'IN'), ('the', 'DT'), ('English', 'JJ'), ('language', 'NN'), ('where', 'WRB'), ('the', 'DT'), ('period', 'NN'), ('is', 'VBZ'), ('used', 'VBN'), ('for', 'IN'), ('anything', 'NN'), ('other', 'JJ'), ('than', 'IN'), ('denoting', 'VBG'), ('the', 'DT'), ('end', 'NN'), ('of', 'IN'), ('a', 'DT'), ('sentence', 'NN'), ('.', '.')] 

 Lemmas are: 
>> [('After', 'after'), ('all', 'all'), (',', ','), ('there', 'there'), ('are', 'be'), ('only', 'only'), ('a', 'a'), ('few', 'few'), ('cases', 'case'), ('in', 'in'), ('the', 'the'), ('English', 'English'), ('language', 'language'), ('where', 'where'), ('the', 'the'), ('period', 'period'), ('is', 'be'), ('used', 'use'), ('for', 'for'), ('anything', 'anything'), ('other', 'other'), ('than', 'than'), ('denoting', 'denote'), ('the', 'the'), ('end', 'end'), ('of', 'of'), ('a', 'a'), ('sentence', 'sentence'), ('.', '.')] 

 Dependency tags are: 
>> [(('After', 'all'), 'case'), (('all', 'are'), 'obl'), ((',', 'are'), 'punct'), (('there', 'are'), 'expl'), (('are', 'root'), 'root'), (('only', 'cases'), 'advmod'), (('a', 'cases'), 'det'), (('few', 'cases'), 'amod'), (('cases', 'are'), 'nsubj'), (('in', 'language'), 'case'), (('the', 'language'), 'det'), (('English', 'language'), 'amod'), (('language', 'cases'), 'nmod'), (('where', 'used'), 'mark'), (('the', 'period'), 'det'), (('period', 'used'), 'nsubj:pass'), (('is', 'used'), 'aux:pass'), (('used', 'language'), 'acl:relcl'), (('for', 'anything'), 'case'), (('anything', 'used'), 'obl'), (('other', 'anything'), 'amod'), (('than', 'denoting'), 'mark'), (('denoting', 'anything'), 'acl'), (('the', 'end'), 'det'), (('end', 'denoting'), 'obj'), (('of', 'sentence'), 'case'), (('a', 'sentence'), 'det'), (('sentence', 'end'), 'nmod'), (('.', 'are'), 'punct')]

 Named Entites are: 
>> [('English', 'LANGUAGE')]

------------------- Sentence 6 -------------------

 It is more efficient, faster computationally, and more precise  to just hard-code these cases using NLP code or other algorithms. 

Tokens are: 
>> ['It', 'is', 'more', 'efficient', ',', 'faster', 'computationally', ',', 'and', 'more', 'precise', 'to', 'just', 'hard', '-', 'code', 'these', 'cases', 'using', 'NLP', 'code', 'or', 'other', 'algorithms', '.'] 

 UPOS tags are: 
>> [('It', 'PRON'), ('is', 'AUX'), ('more', 'ADV'), ('efficient', 'ADJ'), (',', 'PUNCT'), ('faster', 'ADV'), ('computationally', 'ADV'), (',', 'PUNCT'), ('and', 'CCONJ'), ('more', 'ADV'), ('precise', 'ADJ'), ('to', 'ADP'), ('just', 'ADV'), ('hard', 'ADJ'), ('-', 'PUNCT'), ('code', 'VERB'), ('these', 'DET'), ('cases', 'NOUN'), ('using', 'VERB'), ('NLP', 'NOUN'), ('code', 'NOUN'), ('or', 'CCONJ'), ('other', 'ADJ'), ('algorithms', 'NOUN'), ('.', 'PUNCT')] 

 XPOS tags are: 
>> [('It', 'PRP'), ('is', 'VBZ'), ('more', 'RBR'), ('efficient', 'JJ'), (',', ','), ('faster', 'RBR'), ('computationally', 'RB'), (',', ','), ('and', 'CC'), ('more', 'RBR'), ('precise', 'JJ'), ('to', 'IN'), ('just', 'RB'), ('hard', 'JJ'), ('-', 'HYPH'), ('code', 'VB'), ('these', 'DT'), ('cases', 'NNS'), ('using', 'VBG'), ('NLP', 'NN'), ('code', 'NN'), ('or', 'CC'), ('other', 'JJ'), ('algorithms', 'NNS'), ('.', '.')] 

 Lemmas are: 
>> [('It', 'it'), ('is', 'be'), ('more', 'more'), ('efficient', 'efficient'), (',', ','), ('faster', 'fast'), ('computationally', 'computationally'), (',', ','), ('and', 'and'), ('more', 'more'), ('precise', 'precise'), ('to', 'to'), ('just', 'just'), ('hard', 'hard'), ('-', '-'), ('code', 'code'), ('these', 'this'), ('cases', 'case'), ('using', 'use'), ('NLP', 'nlp'), ('code', 'code'), ('or', 'or'), ('other', 'other'), ('algorithms', 'algorithm'), ('.', '.')] 

 Dependency tags are: 
>> [(('It', 'efficient'), 'nsubj'), (('is', 'efficient'), 'cop'), (('more', 'efficient'), 'advmod'), (('efficient', 'root'), 'root'), ((',', 'computationally'), 'punct'), (('faster', 'computationally'), 'advmod'), (('computationally', 'efficient'), 'advmod'), ((',', 'precise'), 'punct'), (('and', 'precise'), 'cc'), (('more', 'precise'), 'advmod'), (('precise', 'efficient'), 'conj'), (('to', 'code'), 'case'), (('just', 'code'), 'advmod'), (('hard', 'code'), 'amod'), (('-', 'code'), 'punct'), (('code', 'precise'), 'obl'), (('these', 'cases'), 'det'), (('cases', 'code'), 'obj'), (('using', 'code'), 'advcl'), (('NLP', 'code'), 'compound'), (('code', 'using'), 'obj'), (('or', 'algorithms'), 'cc'), (('other', 'algorithms'), 'amod'), (('algorithms', 'code'), 'conj'), (('.', 'efficient'), 'punct')]

 Named Entites are: 
>> []

================================ Paragraph 137 =================================

Where there are cases that are best handled by NLP code, we write NLP  code or use rules. When we need to build models, we build models.  


------------------- Sentence 1 -------------------

 Where there are cases that are best handled by NLP code, we write NLP  code or use rules. 

Tokens are: 
>> ['Where', 'there', 'are', 'cases', 'that', 'are', 'best', 'handled', 'by', 'NLP', 'code', ',', 'we', 'write', 'NLP', 'code', 'or', 'use', 'rules', '.'] 

 UPOS tags are: 
>> [('Where', 'SCONJ'), ('there', 'PRON'), ('are', 'VERB'), ('cases', 'NOUN'), ('that', 'PRON'), ('are', 'AUX'), ('best', 'ADV'), ('handled', 'VERB'), ('by', 'ADP'), ('NLP', 'NOUN'), ('code', 'NOUN'), (',', 'PUNCT'), ('we', 'PRON'), ('write', 'VERB'), ('NLP', 'NOUN'), ('code', 'NOUN'), ('or', 'CCONJ'), ('use', 'VERB'), ('rules', 'NOUN'), ('.', 'PUNCT')] 

 XPOS tags are: 
>> [('Where', 'WRB'), ('there', 'EX'), ('are', 'VBP'), ('cases', 'NNS'), ('that', 'WDT'), ('are', 'VBP'), ('best', 'RBS'), ('handled', 'VBN'), ('by', 'IN'), ('NLP', 'NN'), ('code', 'NN'), (',', ','), ('we', 'PRP'), ('write', 'VBP'), ('NLP', 'NN'), ('code', 'NN'), ('or', 'CC'), ('use', 'VBP'), ('rules', 'NNS'), ('.', '.')] 

 Lemmas are: 
>> [('Where', 'where'), ('there', 'there'), ('are', 'be'), ('cases', 'case'), ('that', 'that'), ('are', 'be'), ('best', 'well'), ('handled', 'handle'), ('by', 'by'), ('NLP', 'nlp'), ('code', 'code'), (',', ','), ('we', 'we'), ('write', 'write'), ('NLP', 'nlp'), ('code', 'code'), ('or', 'or'), ('use', 'use'), ('rules', 'rule'), ('.', '.')] 

 Dependency tags are: 
>> [(('Where', 'are'), 'mark'), (('there', 'are'), 'expl'), (('are', 'write'), 'advcl'), (('cases', 'are'), 'nsubj'), (('that', 'handled'), 'nsubj:pass'), (('are', 'handled'), 'aux:pass'), (('best', 'handled'), 'advmod'), (('handled', 'cases'), 'acl:relcl'), (('by', 'code'), 'case'), (('NLP', 'code'), 'compound'), (('code', 'handled'), 'obl'), ((',', 'write'), 'punct'), (('we', 'write'), 'nsubj'), (('write', 'root'), 'root'), (('NLP', 'code'), 'compound'), (('code', 'write'), 'obj'), (('or', 'use'), 'cc'), (('use', 'write'), 'conj'), (('rules', 'use'), 'obj'), (('.', 'write'), 'punct')]

 Named Entites are: 
>> [('NLP', 'LAW'), ('NLP', 'LAW')]

------------------- Sentence 2 -------------------

 When we need to build models, we build models. 

Tokens are: 
>> ['When', 'we', 'need', 'to', 'build', 'models', ',', 'we', 'build', 'models', '.'] 

 UPOS tags are: 
>> [('When', 'SCONJ'), ('we', 'PRON'), ('need', 'VERB'), ('to', 'PART'), ('build', 'VERB'), ('models', 'NOUN'), (',', 'PUNCT'), ('we', 'PRON'), ('build', 'VERB'), ('models', 'NOUN'), ('.', 'PUNCT')] 

 XPOS tags are: 
>> [('When', 'WRB'), ('we', 'PRP'), ('need', 'VBP'), ('to', 'TO'), ('build', 'VB'), ('models', 'NNS'), (',', ','), ('we', 'PRP'), ('build', 'VBP'), ('models', 'NNS'), ('.', '.')] 

 Lemmas are: 
>> [('When', 'when'), ('we', 'we'), ('need', 'need'), ('to', 'to'), ('build', 'build'), ('models', 'model'), (',', ','), ('we', 'we'), ('build', 'build'), ('models', 'model'), ('.', '.')] 

 Dependency tags are: 
>> [(('When', 'need'), 'mark'), (('we', 'need'), 'nsubj'), (('need', 'build'), 'advcl'), (('to', 'build'), 'mark'), (('build', 'need'), 'xcomp'), (('models', 'build'), 'obj'), ((',', 'build'), 'punct'), (('we', 'build'), 'nsubj'), (('build', 'root'), 'root'), (('models', 'build'), 'obj'), (('.', 'build'), 'punct')]

 Named Entites are: 
>> []

================================ Paragraph 138 =================================

When we need NLP code or rules,   


------------------- Sentence 1 -------------------

 When we need NLP code or rules, 

Tokens are: 
>> ['When', 'we', 'need', 'NLP', 'code', 'or', 'rules', ','] 

 UPOS tags are: 
>> [('When', 'SCONJ'), ('we', 'PRON'), ('need', 'VERB'), ('NLP', 'NOUN'), ('code', 'NOUN'), ('or', 'CCONJ'), ('rules', 'NOUN'), (',', 'PUNCT')] 

 XPOS tags are: 
>> [('When', 'WRB'), ('we', 'PRP'), ('need', 'VBP'), ('NLP', 'NN'), ('code', 'NN'), ('or', 'CC'), ('rules', 'NNS'), (',', ',')] 

 Lemmas are: 
>> [('When', 'when'), ('we', 'we'), ('need', 'need'), ('NLP', 'nlp'), ('code', 'code'), ('or', 'or'), ('rules', 'rule'), (',', ',')] 

 Dependency tags are: 
>> [(('When', 'need'), 'mark'), (('we', 'need'), 'nsubj'), (('need', 'root'), 'root'), (('NLP', 'code'), 'compound'), (('code', 'need'), 'obj'), (('or', 'rules'), 'cc'), (('rules', 'code'), 'conj'), ((',', 'need'), 'punct')]

 Named Entites are: 
>> [('NLP', 'LAW')]

================================ Paragraph 139 =================================

we write them; when we need   


------------------- Sentence 1 -------------------

 we write them; when we need 

Tokens are: 
>> ['we', 'write', 'them', ';', 'when', 'we', 'need'] 

 UPOS tags are: 
>> [('we', 'PRON'), ('write', 'VERB'), ('them', 'PRON'), (';', 'PUNCT'), ('when', 'SCONJ'), ('we', 'PRON'), ('need', 'VERB')] 

 XPOS tags are: 
>> [('we', 'PRP'), ('write', 'VBP'), ('them', 'PRP'), (';', ','), ('when', 'WRB'), ('we', 'PRP'), ('need', 'VBP')] 

 Lemmas are: 
>> [('we', 'we'), ('write', 'write'), ('them', 'they'), (';', ';'), ('when', 'when'), ('we', 'we'), ('need', 'need')] 

 Dependency tags are: 
>> [(('we', 'write'), 'nsubj'), (('write', 'root'), 'root'), (('them', 'write'), 'obj'), ((';', 'write'), 'punct'), (('when', 'need'), 'mark'), (('we', 'need'), 'nsubj'), (('need', 'write'), 'advcl')]

 Named Entites are: 
>> []

================================ Paragraph 140 =================================

models, we build them. 


------------------- Sentence 1 -------------------

 models, we build them. 

Tokens are: 
>> ['models', ',', 'we', 'build', 'them', '.'] 

 UPOS tags are: 
>> [('models', 'NOUN'), (',', 'PUNCT'), ('we', 'PRON'), ('build', 'VERB'), ('them', 'PRON'), ('.', 'PUNCT')] 

 XPOS tags are: 
>> [('models', 'NNS'), (',', ','), ('we', 'PRP'), ('build', 'VBP'), ('them', 'PRP'), ('.', '.')] 

 Lemmas are: 
>> [('models', 'model'), (',', ','), ('we', 'we'), ('build', 'build'), ('them', 'they'), ('.', '.')] 

 Dependency tags are: 
>> [(('models', 'build'), 'vocative'), ((',', 'build'), 'punct'), (('we', 'build'), 'nsubj'), (('build', 'root'), 'root'), (('them', 'build'), 'obj'), (('.', 'build'), 'punct')]

 Named Entites are: 
>> []

================================ Paragraph 141 =================================

Practical   efficiencies:


------------------- Sentence 1 -------------------

 Practical   efficiencies: 

Tokens are: 
>> ['Practical', 'efficiencies', ':'] 

 UPOS tags are: 
>> [('Practical', 'ADJ'), ('efficiencies', 'NOUN'), (':', 'PUNCT')] 

 XPOS tags are: 
>> [('Practical', 'JJ'), ('efficiencies', 'NNS'), (':', ':')] 

 Lemmas are: 
>> [('Practical', 'practical'), ('efficiencies', 'efficiency'), (':', ':')] 

 Dependency tags are: 
>> [(('Practical', 'efficiencies'), 'amod'), (('efficiencies', 'root'), 'root'), ((':', 'efficiencies'), 'punct')]

 Named Entites are: 
>> []

================================ Paragraph 142 =================================

W H I T E  P A P E R 


------------------- Sentence 1 -------------------

 W H I T E  P A P E R 

Tokens are: 
>> ['W', 'H', 'I', 'T', 'E', 'P', 'A', 'P', 'E', 'R'] 

 UPOS tags are: 
>> [('W', 'PROPN'), ('H', 'PUNCT'), ('I', 'PRON'), ('T', 'AUX'), ('E', 'PROPN'), ('P', 'NOUN'), ('A', 'NOUN'), ('P', 'NOUN'), ('E', 'NOUN'), ('R', 'NOUN')] 

 XPOS tags are: 
>> [('W', 'NNP'), ('H', ','), ('I', 'PRP'), ('T', 'VBP'), ('E', 'NNP'), ('P', 'NN'), ('A', 'NN'), ('P', 'NN'), ('E', 'NN'), ('R', 'NN')] 

 Lemmas are: 
>> [('W', 'W'), ('H', 'H'), ('I', 'I'), ('T', 'T'), ('E', 'E'), ('P', 'p'), ('A', 'a'), ('P', 'p'), ('E', 'e'), ('R', 'R')] 

 Dependency tags are: 
>> [(('W', 'T'), 'vocative'), (('H', 'W'), 'punct'), (('I', 'T'), 'nsubj'), (('T', 'root'), 'root'), (('E', 'T'), 'obj'), (('P', 'T'), 'obj'), (('A', 'E'), 'compound'), (('P', 'E'), 'compound'), (('E', 'R'), 'compound'), (('R', 'T'), 'obj')]

 Named Entites are: 
>> []

================================ Paragraph 143 =================================

10|       |   Lexalytics, Inc., 48 North Pleasant St. Unit 301, Amherst MA 01002 USA   |   1-800-377-8036 |   www.lexalytics.com 


------------------- Sentence 1 -------------------

 10|       |   Lexalytics, Inc., 48 North Pleasant St. Unit 301, Amherst MA 01002 USA   |   1-800-377-8036 |   www.lexalytics.com 

Tokens are: 
>> ['10', '|', '|', 'Lexalytics', ',', 'Inc.', ',', '48', 'North', 'Pleasant', 'St.', 'Unit', '301', ',', 'Amherst', 'MA', '01002', 'USA', '|', '1-800-377-8036', '|', 'www.lexalytics.com'] 

 UPOS tags are: 
>> [('10', 'NUM'), ('|', 'PUNCT'), ('|', 'PUNCT'), ('Lexalytics', 'PROPN'), (',', 'PUNCT'), ('Inc.', 'PROPN'), (',', 'PUNCT'), ('48', 'NUM'), ('North', 'PROPN'), ('Pleasant', 'ADJ'), ('St.', 'PROPN'), ('Unit', 'NOUN'), ('301', 'NUM'), (',', 'PUNCT'), ('Amherst', 'PROPN'), ('MA', 'PROPN'), ('01002', 'NUM'), ('USA', 'PROPN'), ('|', 'PUNCT'), ('1-800-377-8036', 'NUM'), ('|', 'PUNCT'), ('www.lexalytics.com', 'X')] 

 XPOS tags are: 
>> [('10', 'LS'), ('|', 'NFP'), ('|', 'NFP'), ('Lexalytics', 'NNP'), (',', ','), ('Inc.', 'NNP'), (',', ','), ('48', 'CD'), ('North', 'NNP'), ('Pleasant', 'NNP'), ('St.', 'NNP'), ('Unit', 'NN'), ('301', 'CD'), (',', ','), ('Amherst', 'NNP'), ('MA', 'NNP'), ('01002', 'CD'), ('USA', 'NNP'), ('|', 'NFP'), ('1-800-377-8036', 'CD'), ('|', 'NFP'), ('www.lexalytics.com', 'ADD')] 

 Lemmas are: 
>> [('10', '10'), ('|', '|'), ('|', '|'), ('Lexalytics', 'Lexalytics'), (',', ','), ('Inc.', 'Inc.'), (',', ','), ('48', '48'), ('North', 'North'), ('Pleasant', 'Pleasant'), ('St.', 'St.'), ('Unit', 'unit'), ('301', '301'), (',', ','), ('Amherst', 'Amherst'), ('MA', 'MA'), ('01002', '01002'), ('USA', 'USA'), ('|', '|'), ('1-800-377-8036', '1-800-377-8036'), ('|', '|'), ('www.lexalytics.com', 'www.lexalytics.com')] 

 Dependency tags are: 
>> [(('10', 'Inc.'), 'nummod'), (('|', '10'), 'punct'), (('|', '10'), 'punct'), (('Lexalytics', 'Inc.'), 'compound'), ((',', 'Inc.'), 'punct'), (('Inc.', 'root'), 'root'), ((',', 'Inc.'), 'punct'), (('48', 'St.'), 'nummod'), (('North', 'St.'), 'compound'), (('Pleasant', 'St.'), 'amod'), (('St.', 'Inc.'), 'list'), (('Unit', 'Inc.'), 'list'), (('301', 'Unit'), 'nummod'), ((',', 'MA'), 'punct'), (('Amherst', 'MA'), 'appos'), (('MA', 'Inc.'), 'list'), (('01002', 'USA'), 'nummod'), (('USA', 'MA'), 'appos'), (('|', 'USA'), 'punct'), (('1-800-377-8036', 'Inc.'), 'list'), (('|', '1-800-377-8036'), 'punct'), (('www.lexalytics.com', 'Inc.'), 'list')]

 Named Entites are: 
>> [('10|       |   Lexalytics, Inc.', 'ORG'), ('301', 'CARDINAL')]

================================ Paragraph 144 =================================

B L A C K  B O X / C L E A R  B O X :   L O O K I N G  I N S I D E  T H E  D A T A  It is important to understand not just what decision a model has made,   but why it has made that decision. There are two reasons for this:  


------------------- Sentence 1 -------------------

 B L A C K  B O X / C L E A R  B O X :   L O O K I N G  I N S I D E  T H E  D A T A 

Tokens are: 
>> ['B', 'L', 'A', 'C', 'K', 'B', 'O', 'X', '/', 'C', 'L', 'E', 'A', 'R', 'B', 'O', 'X', ':', 'L', 'O', 'O', 'K', 'I', 'N', 'G', 'I', 'N', 'S', 'I', 'D', 'E', 'T', 'H', 'E', 'D', 'A', 'T', 'A'] 

 UPOS tags are: 
>> [('B', 'NUM'), ('L', 'PROPN'), ('A', 'DET'), ('C', 'NOUN'), ('K', 'NUM'), ('B', 'NOUN'), ('O', 'NOUN'), ('X', 'NOUN'), ('/', 'SYM'), ('C', 'NOUN'), ('L', 'NOUN'), ('E', 'NOUN'), ('A', 'NOUN'), ('R', 'NOUN'), ('B', 'NOUN'), ('O', 'NOUN'), ('X', 'NOUN'), (':', 'PUNCT'), ('L', 'NOUN'), ('O', 'NOUN'), ('O', 'ADP'), ('K', 'NOUN'), ('I', 'PRON'), ('N', 'PROPN'), ('G', 'PROPN'), ('I', 'PRON'), ('N', 'PROPN'), ('S', 'PART'), ('I', 'PRON'), ('D', 'PROPN'), ('E', 'PROPN'), ('T', 'PROPN'), ('H', 'PROPN'), ('E', 'NOUN'), ('D', 'PROPN'), ('A', 'NOUN'), ('T', 'NOUN'), ('A', 'PUNCT')] 

 XPOS tags are: 
>> [('B', 'LS'), ('L', 'NNP'), ('A', 'DT'), ('C', 'NN'), ('K', 'CD'), ('B', 'NN'), ('O', 'NN'), ('X', 'NN'), ('/', ','), ('C', 'NN'), ('L', 'NN'), ('E', 'NN'), ('A', 'NN'), ('R', 'NN'), ('B', 'NN'), ('O', 'NN'), ('X', 'NN'), (':', ':'), ('L', 'NN'), ('O', 'NN'), ('O', 'IN'), ('K', 'NN'), ('I', 'PRP'), ('N', 'NNP'), ('G', 'NNP'), ('I', 'PRP'), ('N', 'NNP'), ('S', 'POS'), ('I', 'PRP'), ('D', 'NNP'), ('E', 'NNP'), ('T', 'NNP'), ('H', 'NNP'), ('E', 'NN'), ('D', 'NNP'), ('A', 'NN'), ('T', 'NN'), ('A', '.')] 

 Lemmas are: 
>> [('B', 'b'), ('L', 'L'), ('A', 'a'), ('C', 'c'), ('K', 'k'), ('B', 'b'), ('O', 'o'), ('X', 'x'), ('/', '/'), ('C', 'c'), ('L', 'L'), ('E', 'e'), ('A', 'a'), ('R', 'R'), ('B', 'b'), ('O', 'o'), ('X', 'x'), (':', ':'), ('L', 'L'), ('O', 'o'), ('O', 'of'), ('K', 'k'), ('I', 'I'), ('N', 'N'), ('G', 'G'), ('I', 'I'), ('N', 'N'), ('S', "'s"), ('I', 'I'), ('D', 'D'), ('E', 'E'), ('T', 'T'), ('H', 'H'), ('E', 'e'), ('D', 'D'), ('A', 'a'), ('T', 'T'), ('A', 'a')] 

 Dependency tags are: 
>> [(('B', 'B'), 'nummod'), (('L', 'B'), 'compound'), (('A', 'B'), 'det'), (('C', 'K'), 'compound'), (('K', 'B'), 'nummod'), (('B', 'root'), 'root'), (('O', 'B'), 'punct'), (('X', 'O'), 'nmod'), (('/', 'C'), 'punct'), (('C', 'X'), 'nmod'), (('L', 'E'), 'compound'), (('E', 'O'), 'nmod'), (('A', 'B'), 'compound'), (('R', 'B'), 'compound'), (('B', 'E'), 'appos'), (('O', 'X'), 'compound'), (('X', 'B'), 'appos'), ((':', 'X'), 'punct'), (('L', 'O'), 'compound'), (('O', 'X'), 'appos'), (('O', 'K'), 'case'), (('K', 'O'), 'nmod'), (('I', 'G'), 'nsubj'), (('N', 'G'), 'compound'), (('G', 'O'), 'appos'), (('I', 'N'), 'compound'), (('N', 'G'), 'nmod:poss'), (('S', 'N'), 'case'), (('I', 'D'), 'compound'), (('D', 'G'), 'flat'), (('E', 'D'), 'flat'), (('T', 'D'), 'flat'), (('H', 'D'), 'compound'), (('E', 'D'), 'compound'), (('D', 'D'), 'flat'), (('A', 'T'), 'compound'), (('T', 'D'), 'appos'), (('A', 'B'), 'punct')]

 Named Entites are: 
>> []

------------------- Sentence 2 -------------------

 It is important to understand not just what decision a model has made,   but why it has made that decision. 

Tokens are: 
>> ['It', 'is', 'important', 'to', 'understand', 'not', 'just', 'what', 'decision', 'a', 'model', 'has', 'made', ',', 'but', 'why', 'it', 'has', 'made', 'that', 'decision', '.'] 

 UPOS tags are: 
>> [('It', 'PRON'), ('is', 'AUX'), ('important', 'ADJ'), ('to', 'PART'), ('understand', 'VERB'), ('not', 'ADV'), ('just', 'ADV'), ('what', 'DET'), ('decision', 'NOUN'), ('a', 'DET'), ('model', 'NOUN'), ('has', 'AUX'), ('made', 'VERB'), (',', 'PUNCT'), ('but', 'CCONJ'), ('why', 'SCONJ'), ('it', 'PRON'), ('has', 'AUX'), ('made', 'VERB'), ('that', 'DET'), ('decision', 'NOUN'), ('.', 'PUNCT')] 

 XPOS tags are: 
>> [('It', 'PRP'), ('is', 'VBZ'), ('important', 'JJ'), ('to', 'TO'), ('understand', 'VB'), ('not', 'RB'), ('just', 'RB'), ('what', 'WDT'), ('decision', 'NN'), ('a', 'DT'), ('model', 'NN'), ('has', 'VBZ'), ('made', 'VBN'), (',', ','), ('but', 'CC'), ('why', 'WRB'), ('it', 'PRP'), ('has', 'VBZ'), ('made', 'VBN'), ('that', 'DT'), ('decision', 'NN'), ('.', '.')] 

 Lemmas are: 
>> [('It', 'it'), ('is', 'be'), ('important', 'important'), ('to', 'to'), ('understand', 'understand'), ('not', 'not'), ('just', 'just'), ('what', 'what'), ('decision', 'decision'), ('a', 'a'), ('model', 'model'), ('has', 'have'), ('made', 'make'), (',', ','), ('but', 'but'), ('why', 'why'), ('it', 'it'), ('has', 'have'), ('made', 'make'), ('that', 'that'), ('decision', 'decision'), ('.', '.')] 

 Dependency tags are: 
>> [(('It', 'important'), 'expl'), (('is', 'important'), 'cop'), (('important', 'root'), 'root'), (('to', 'understand'), 'mark'), (('understand', 'important'), 'csubj'), (('not', 'decision'), 'advmod'), (('just', 'decision'), 'advmod'), (('what', 'decision'), 'det'), (('decision', 'understand'), 'obj'), (('a', 'model'), 'det'), (('model', 'made'), 'nsubj'), (('has', 'made'), 'aux'), (('made', 'decision'), 'acl:relcl'), ((',', 'made'), 'punct'), (('but', 'made'), 'cc'), (('why', 'made'), 'mark'), (('it', 'made'), 'nsubj'), (('has', 'made'), 'aux'), (('made', 'important'), 'conj'), (('that', 'decision'), 'det'), (('decision', 'made'), 'obj'), (('.', 'important'), 'punct')]

 Named Entites are: 
>> []

------------------- Sentence 3 -------------------

 There are two reasons for this: 

Tokens are: 
>> ['There', 'are', 'two', 'reasons', 'for', 'this', ':'] 

 UPOS tags are: 
>> [('There', 'PRON'), ('are', 'VERB'), ('two', 'NUM'), ('reasons', 'NOUN'), ('for', 'ADP'), ('this', 'PRON'), (':', 'PUNCT')] 

 XPOS tags are: 
>> [('There', 'EX'), ('are', 'VBP'), ('two', 'CD'), ('reasons', 'NNS'), ('for', 'IN'), ('this', 'DT'), (':', ':')] 

 Lemmas are: 
>> [('There', 'there'), ('are', 'be'), ('two', 'two'), ('reasons', 'reason'), ('for', 'for'), ('this', 'this'), (':', ':')] 

 Dependency tags are: 
>> [(('There', 'are'), 'expl'), (('are', 'root'), 'root'), (('two', 'reasons'), 'nummod'), (('reasons', 'are'), 'nsubj'), (('for', 'this'), 'case'), (('this', 'reasons'), 'nmod'), ((':', 'are'), 'punct')]

 Named Entites are: 
>> [('two', 'CARDINAL')]

================================ Paragraph 145 =================================

There’s often other business-relevant information encoded   in the “why.” For example, knowing simply that certain survey  results are full of negative feedback is not particularly useful.   We want to know which phrases were scored negatively. 


------------------- Sentence 1 -------------------

 There’s often other business-relevant information encoded   in the “why.” 

Tokens are: 
>> ['There', '’s', 'often', 'other', 'business', '-', 'relevant', 'information', 'encoded', 'in', 'the', '“', 'why', '.', '”'] 

 UPOS tags are: 
>> [('There', 'PRON'), ('’s', 'VERB'), ('often', 'ADV'), ('other', 'ADJ'), ('business', 'NOUN'), ('-', 'PUNCT'), ('relevant', 'ADJ'), ('information', 'NOUN'), ('encoded', 'VERB'), ('in', 'ADP'), ('the', 'DET'), ('“', 'PUNCT'), ('why', 'SCONJ'), ('.', 'PUNCT'), ('”', 'PUNCT')] 

 XPOS tags are: 
>> [('There', 'EX'), ('’s', 'VBZ'), ('often', 'RB'), ('other', 'JJ'), ('business', 'NN'), ('-', 'HYPH'), ('relevant', 'JJ'), ('information', 'NN'), ('encoded', 'VBN'), ('in', 'IN'), ('the', 'DT'), ('“', '``'), ('why', 'WRB'), ('.', '.'), ('”', "''")] 

 Lemmas are: 
>> [('There', 'there'), ('’s', 'be'), ('often', 'often'), ('other', 'other'), ('business', 'business'), ('-', '-'), ('relevant', 'relevant'), ('information', 'information'), ('encoded', 'encode'), ('in', 'in'), ('the', 'the'), ('“', "''"), ('why', 'why'), ('.', '.'), ('”', "''")] 

 Dependency tags are: 
>> [(('There', '’s'), 'expl'), (('’s', 'root'), 'root'), (('often', '’s'), 'advmod'), (('other', 'information'), 'amod'), (('business', 'relevant'), 'obl:npmod'), (('-', 'relevant'), 'punct'), (('relevant', 'information'), 'amod'), (('information', '’s'), 'nsubj'), (('encoded', 'information'), 'acl'), (('in', 'why'), 'case'), (('the', 'why'), 'det'), (('“', 'why'), 'punct'), (('why', 'encoded'), 'obl'), (('.', 'why'), 'punct'), (('”', 'why'), 'punct')]

 Named Entites are: 
>> []

------------------- Sentence 2 -------------------

 For example, knowing simply that certain survey  results are full of negative feedback is not particularly useful. 

Tokens are: 
>> ['For', 'example', ',', 'knowing', 'simply', 'that', 'certain', 'survey', 'results', 'are', 'full', 'of', 'negative', 'feedback', 'is', 'not', 'particularly', 'useful', '.'] 

 UPOS tags are: 
>> [('For', 'ADP'), ('example', 'NOUN'), (',', 'PUNCT'), ('knowing', 'VERB'), ('simply', 'ADV'), ('that', 'SCONJ'), ('certain', 'ADJ'), ('survey', 'NOUN'), ('results', 'NOUN'), ('are', 'AUX'), ('full', 'ADJ'), ('of', 'ADP'), ('negative', 'ADJ'), ('feedback', 'NOUN'), ('is', 'AUX'), ('not', 'PART'), ('particularly', 'ADV'), ('useful', 'ADJ'), ('.', 'PUNCT')] 

 XPOS tags are: 
>> [('For', 'IN'), ('example', 'NN'), (',', ','), ('knowing', 'VBG'), ('simply', 'RB'), ('that', 'IN'), ('certain', 'JJ'), ('survey', 'NN'), ('results', 'NNS'), ('are', 'VBP'), ('full', 'JJ'), ('of', 'IN'), ('negative', 'JJ'), ('feedback', 'NN'), ('is', 'VBZ'), ('not', 'RB'), ('particularly', 'RB'), ('useful', 'JJ'), ('.', '.')] 

 Lemmas are: 
>> [('For', 'for'), ('example', 'example'), (',', ','), ('knowing', 'know'), ('simply', 'simply'), ('that', 'that'), ('certain', 'certain'), ('survey', 'survey'), ('results', 'result'), ('are', 'be'), ('full', 'full'), ('of', 'of'), ('negative', 'negative'), ('feedback', 'feedback'), ('is', 'be'), ('not', 'not'), ('particularly', 'particularly'), ('useful', 'useful'), ('.', '.')] 

 Dependency tags are: 
>> [(('For', 'example'), 'case'), (('example', 'useful'), 'obl'), ((',', 'useful'), 'punct'), (('knowing', 'useful'), 'csubj'), (('simply', 'knowing'), 'advmod'), (('that', 'full'), 'mark'), (('certain', 'results'), 'amod'), (('survey', 'results'), 'compound'), (('results', 'full'), 'nsubj'), (('are', 'full'), 'cop'), (('full', 'knowing'), 'ccomp'), (('of', 'feedback'), 'case'), (('negative', 'feedback'), 'amod'), (('feedback', 'full'), 'obl'), (('is', 'useful'), 'cop'), (('not', 'useful'), 'advmod'), (('particularly', 'useful'), 'advmod'), (('useful', 'root'), 'root'), (('.', 'useful'), 'punct')]

 Named Entites are: 
>> []

------------------- Sentence 3 -------------------

 We want to know which phrases were scored negatively. 

Tokens are: 
>> ['We', 'want', 'to', 'know', 'which', 'phrases', 'were', 'scored', 'negatively', '.'] 

 UPOS tags are: 
>> [('We', 'PRON'), ('want', 'VERB'), ('to', 'PART'), ('know', 'VERB'), ('which', 'DET'), ('phrases', 'NOUN'), ('were', 'AUX'), ('scored', 'VERB'), ('negatively', 'ADV'), ('.', 'PUNCT')] 

 XPOS tags are: 
>> [('We', 'PRP'), ('want', 'VBP'), ('to', 'TO'), ('know', 'VB'), ('which', 'WDT'), ('phrases', 'NNS'), ('were', 'VBD'), ('scored', 'VBN'), ('negatively', 'RB'), ('.', '.')] 

 Lemmas are: 
>> [('We', 'we'), ('want', 'want'), ('to', 'to'), ('know', 'know'), ('which', 'which'), ('phrases', 'phrase'), ('were', 'be'), ('scored', 'score'), ('negatively', 'negatively'), ('.', '.')] 

 Dependency tags are: 
>> [(('We', 'want'), 'nsubj'), (('want', 'root'), 'root'), (('to', 'know'), 'mark'), (('know', 'want'), 'xcomp'), (('which', 'phrases'), 'det'), (('phrases', 'scored'), 'nsubj:pass'), (('were', 'scored'), 'aux:pass'), (('scored', 'know'), 'ccomp'), (('negatively', 'scored'), 'advmod'), (('.', 'want'), 'punct')]

 Named Entites are: 
>> []

================================ Paragraph 146 =================================

We might want to adjust the scoring somehow. If we can’t   see why the model is making a decision, we can’t really affect   the decision and it can be hard to figure out what to do next. 


------------------- Sentence 1 -------------------

 We might want to adjust the scoring somehow. 

Tokens are: 
>> ['We', 'might', 'want', 'to', 'adjust', 'the', 'scoring', 'somehow', '.'] 

 UPOS tags are: 
>> [('We', 'PRON'), ('might', 'AUX'), ('want', 'VERB'), ('to', 'PART'), ('adjust', 'VERB'), ('the', 'DET'), ('scoring', 'NOUN'), ('somehow', 'ADV'), ('.', 'PUNCT')] 

 XPOS tags are: 
>> [('We', 'PRP'), ('might', 'MD'), ('want', 'VB'), ('to', 'TO'), ('adjust', 'VB'), ('the', 'DT'), ('scoring', 'NN'), ('somehow', 'RB'), ('.', '.')] 

 Lemmas are: 
>> [('We', 'we'), ('might', 'might'), ('want', 'want'), ('to', 'to'), ('adjust', 'adjust'), ('the', 'the'), ('scoring', 'scoring'), ('somehow', 'somehow'), ('.', '.')] 

 Dependency tags are: 
>> [(('We', 'want'), 'nsubj'), (('might', 'want'), 'aux'), (('want', 'root'), 'root'), (('to', 'adjust'), 'mark'), (('adjust', 'want'), 'xcomp'), (('the', 'scoring'), 'det'), (('scoring', 'adjust'), 'obj'), (('somehow', 'adjust'), 'advmod'), (('.', 'want'), 'punct')]

 Named Entites are: 
>> []

------------------- Sentence 2 -------------------

 If we can’t   see why the model is making a decision, we can’t really affect   the decision and it can be hard to figure out what to do next. 

Tokens are: 
>> ['If', 'we', 'ca', 'n’t', 'see', 'why', 'the', 'model', 'is', 'making', 'a', 'decision', ',', 'we', 'ca', 'n’t', 'really', 'affect', 'the', 'decision', 'and', 'it', 'can', 'be', 'hard', 'to', 'figure', 'out', 'what', 'to', 'do', 'next', '.'] 

 UPOS tags are: 
>> [('If', 'SCONJ'), ('we', 'PRON'), ('ca', 'AUX'), ('n’t', 'PART'), ('see', 'VERB'), ('why', 'SCONJ'), ('the', 'DET'), ('model', 'NOUN'), ('is', 'AUX'), ('making', 'VERB'), ('a', 'DET'), ('decision', 'NOUN'), (',', 'PUNCT'), ('we', 'PRON'), ('ca', 'AUX'), ('n’t', 'PART'), ('really', 'ADV'), ('affect', 'VERB'), ('the', 'DET'), ('decision', 'NOUN'), ('and', 'CCONJ'), ('it', 'PRON'), ('can', 'AUX'), ('be', 'AUX'), ('hard', 'ADJ'), ('to', 'PART'), ('figure', 'VERB'), ('out', 'ADP'), ('what', 'PRON'), ('to', 'PART'), ('do', 'VERB'), ('next', 'ADV'), ('.', 'PUNCT')] 

 XPOS tags are: 
>> [('If', 'IN'), ('we', 'PRP'), ('ca', 'MD'), ('n’t', 'RB'), ('see', 'VB'), ('why', 'WRB'), ('the', 'DT'), ('model', 'NN'), ('is', 'VBZ'), ('making', 'VBG'), ('a', 'DT'), ('decision', 'NN'), (',', ','), ('we', 'PRP'), ('ca', 'MD'), ('n’t', 'RB'), ('really', 'RB'), ('affect', 'VB'), ('the', 'DT'), ('decision', 'NN'), ('and', 'CC'), ('it', 'PRP'), ('can', 'MD'), ('be', 'VB'), ('hard', 'JJ'), ('to', 'TO'), ('figure', 'VB'), ('out', 'RP'), ('what', 'WP'), ('to', 'TO'), ('do', 'VB'), ('next', 'RB'), ('.', '.')] 

 Lemmas are: 
>> [('If', 'if'), ('we', 'we'), ('ca', 'can'), ('n’t', 'not'), ('see', 'see'), ('why', 'why'), ('the', 'the'), ('model', 'model'), ('is', 'be'), ('making', 'make'), ('a', 'a'), ('decision', 'decision'), (',', ','), ('we', 'we'), ('ca', 'can'), ('n’t', 'not'), ('really', 'really'), ('affect', 'affect'), ('the', 'the'), ('decision', 'decision'), ('and', 'and'), ('it', 'it'), ('can', 'can'), ('be', 'be'), ('hard', 'hard'), ('to', 'to'), ('figure', 'figure'), ('out', 'out'), ('what', 'what'), ('to', 'to'), ('do', 'do'), ('next', 'next'), ('.', '.')] 

 Dependency tags are: 
>> [(('If', 'see'), 'mark'), (('we', 'see'), 'nsubj'), (('ca', 'see'), 'aux'), (('n’t', 'see'), 'advmod'), (('see', 'affect'), 'advcl'), (('why', 'see'), 'obj'), (('the', 'model'), 'det'), (('model', 'making'), 'nsubj'), (('is', 'making'), 'aux'), (('making', 'why'), 'acl:relcl'), (('a', 'decision'), 'det'), (('decision', 'making'), 'obj'), ((',', 'affect'), 'punct'), (('we', 'affect'), 'nsubj'), (('ca', 'affect'), 'aux'), (('n’t', 'affect'), 'advmod'), (('really', 'affect'), 'advmod'), (('affect', 'root'), 'root'), (('the', 'decision'), 'det'), (('decision', 'affect'), 'obj'), (('and', 'hard'), 'cc'), (('it', 'hard'), 'expl'), (('can', 'hard'), 'aux'), (('be', 'hard'), 'cop'), (('hard', 'affect'), 'conj'), (('to', 'figure'), 'mark'), (('figure', 'hard'), 'csubj'), (('out', 'figure'), 'compound:prt'), (('what', 'do'), 'nsubj'), (('to', 'do'), 'mark'), (('do', 'figure'), 'xcomp'), (('next', 'do'), 'advmod'), (('.', 'affect'), 'punct')]

 Named Entites are: 
>> []

================================ Paragraph 147 =================================

It’s often difficult to see how or why a model is making a decision. This is  particularly true of deep learning models. Despite their popularity, they   are profoundly black box algorithms.


------------------- Sentence 1 -------------------

 It’s often difficult to see how or why a model is making a decision. 

Tokens are: 
>> ['It', '’s', 'often', 'difficult', 'to', 'see', 'how', 'or', 'why', 'a', 'model', 'is', 'making', 'a', 'decision', '.'] 

 UPOS tags are: 
>> [('It', 'PRON'), ('’s', 'AUX'), ('often', 'ADV'), ('difficult', 'ADJ'), ('to', 'PART'), ('see', 'VERB'), ('how', 'SCONJ'), ('or', 'CCONJ'), ('why', 'SCONJ'), ('a', 'DET'), ('model', 'NOUN'), ('is', 'AUX'), ('making', 'VERB'), ('a', 'DET'), ('decision', 'NOUN'), ('.', 'PUNCT')] 

 XPOS tags are: 
>> [('It', 'PRP'), ('’s', 'VBZ'), ('often', 'RB'), ('difficult', 'JJ'), ('to', 'TO'), ('see', 'VB'), ('how', 'WRB'), ('or', 'CC'), ('why', 'WRB'), ('a', 'DT'), ('model', 'NN'), ('is', 'VBZ'), ('making', 'VBG'), ('a', 'DT'), ('decision', 'NN'), ('.', '.')] 

 Lemmas are: 
>> [('It', 'it'), ('’s', 'be'), ('often', 'often'), ('difficult', 'difficult'), ('to', 'to'), ('see', 'see'), ('how', 'how'), ('or', 'or'), ('why', 'why'), ('a', 'a'), ('model', 'model'), ('is', 'be'), ('making', 'make'), ('a', 'a'), ('decision', 'decision'), ('.', '.')] 

 Dependency tags are: 
>> [(('It', 'difficult'), 'expl'), (('’s', 'difficult'), 'cop'), (('often', 'difficult'), 'advmod'), (('difficult', 'root'), 'root'), (('to', 'see'), 'mark'), (('see', 'difficult'), 'csubj'), (('how', 'making'), 'mark'), (('or', 'why'), 'cc'), (('why', 'how'), 'conj'), (('a', 'model'), 'det'), (('model', 'making'), 'nsubj'), (('is', 'making'), 'aux'), (('making', 'see'), 'ccomp'), (('a', 'decision'), 'det'), (('decision', 'making'), 'obj'), (('.', 'difficult'), 'punct')]

 Named Entites are: 
>> []

------------------- Sentence 2 -------------------

 This is  particularly true of deep learning models. 

Tokens are: 
>> ['This', 'is', 'particularly', 'true', 'of', 'deep', 'learning', 'models', '.'] 

 UPOS tags are: 
>> [('This', 'PRON'), ('is', 'AUX'), ('particularly', 'ADV'), ('true', 'ADJ'), ('of', 'ADP'), ('deep', 'ADJ'), ('learning', 'NOUN'), ('models', 'NOUN'), ('.', 'PUNCT')] 

 XPOS tags are: 
>> [('This', 'DT'), ('is', 'VBZ'), ('particularly', 'RB'), ('true', 'JJ'), ('of', 'IN'), ('deep', 'JJ'), ('learning', 'NN'), ('models', 'NNS'), ('.', '.')] 

 Lemmas are: 
>> [('This', 'this'), ('is', 'be'), ('particularly', 'particularly'), ('true', 'true'), ('of', 'of'), ('deep', 'deep'), ('learning', 'learning'), ('models', 'model'), ('.', '.')] 

 Dependency tags are: 
>> [(('This', 'true'), 'nsubj'), (('is', 'true'), 'cop'), (('particularly', 'true'), 'advmod'), (('true', 'root'), 'root'), (('of', 'models'), 'case'), (('deep', 'models'), 'amod'), (('learning', 'models'), 'compound'), (('models', 'true'), 'obl'), (('.', 'true'), 'punct')]

 Named Entites are: 
>> []

------------------- Sentence 3 -------------------

 Despite their popularity, they   are profoundly black box algorithms. 

Tokens are: 
>> ['Despite', 'their', 'popularity', ',', 'they', 'are', 'profoundly', 'black', 'box', 'algorithms', '.'] 

 UPOS tags are: 
>> [('Despite', 'ADP'), ('their', 'PRON'), ('popularity', 'NOUN'), (',', 'PUNCT'), ('they', 'PRON'), ('are', 'AUX'), ('profoundly', 'ADV'), ('black', 'ADJ'), ('box', 'NOUN'), ('algorithms', 'NOUN'), ('.', 'PUNCT')] 

 XPOS tags are: 
>> [('Despite', 'IN'), ('their', 'PRP$'), ('popularity', 'NN'), (',', ','), ('they', 'PRP'), ('are', 'VBP'), ('profoundly', 'RB'), ('black', 'JJ'), ('box', 'NN'), ('algorithms', 'NNS'), ('.', '.')] 

 Lemmas are: 
>> [('Despite', 'despite'), ('their', 'they'), ('popularity', 'popularity'), (',', ','), ('they', 'they'), ('are', 'be'), ('profoundly', 'profoundly'), ('black', 'black'), ('box', 'box'), ('algorithms', 'algorithm'), ('.', '.')] 

 Dependency tags are: 
>> [(('Despite', 'popularity'), 'case'), (('their', 'popularity'), 'nmod:poss'), (('popularity', 'algorithms'), 'obl'), ((',', 'algorithms'), 'punct'), (('they', 'algorithms'), 'nsubj'), (('are', 'algorithms'), 'cop'), (('profoundly', 'algorithms'), 'advmod'), (('black', 'algorithms'), 'amod'), (('box', 'algorithms'), 'compound'), (('algorithms', 'root'), 'root'), (('.', 'algorithms'), 'punct')]

 Named Entites are: 
>> []

================================ Paragraph 148 =================================

W H I T E  P A P E R 


------------------- Sentence 1 -------------------

 W H I T E  P A P E R 

Tokens are: 
>> ['W', 'H', 'I', 'T', 'E', 'P', 'A', 'P', 'E', 'R'] 

 UPOS tags are: 
>> [('W', 'PROPN'), ('H', 'PUNCT'), ('I', 'PRON'), ('T', 'AUX'), ('E', 'PROPN'), ('P', 'NOUN'), ('A', 'NOUN'), ('P', 'NOUN'), ('E', 'NOUN'), ('R', 'NOUN')] 

 XPOS tags are: 
>> [('W', 'NNP'), ('H', ','), ('I', 'PRP'), ('T', 'VBP'), ('E', 'NNP'), ('P', 'NN'), ('A', 'NN'), ('P', 'NN'), ('E', 'NN'), ('R', 'NN')] 

 Lemmas are: 
>> [('W', 'W'), ('H', 'H'), ('I', 'I'), ('T', 'T'), ('E', 'E'), ('P', 'p'), ('A', 'a'), ('P', 'p'), ('E', 'e'), ('R', 'R')] 

 Dependency tags are: 
>> [(('W', 'T'), 'vocative'), (('H', 'W'), 'punct'), (('I', 'T'), 'nsubj'), (('T', 'root'), 'root'), (('E', 'T'), 'obj'), (('P', 'T'), 'obj'), (('A', 'E'), 'compound'), (('P', 'E'), 'compound'), (('E', 'R'), 'compound'), (('R', 'T'), 'obj')]

 Named Entites are: 
>> []

================================ Paragraph 149 =================================

1 1|       |   Lexalytics, Inc., 48 North Pleasant St. Unit 301, Amherst MA 01002 USA   |   1-800-377-8036 |   www.lexalytics.com 


------------------- Sentence 1 -------------------

 1 1|       |   Lexalytics, Inc., 48 North Pleasant St. Unit 301, Amherst MA 01002 USA   |   1-800-377-8036 |   www.lexalytics.com 

Tokens are: 
>> ['1', '1', '|', '|', 'Lexalytics', ',', 'Inc.', ',', '48', 'North', 'Pleasant', 'St.', 'Unit', '301', ',', 'Amherst', 'MA', '01002', 'USA', '|', '1-800-377-8036', '|', 'www.lexalytics.com'] 

 UPOS tags are: 
>> [('1', 'NUM'), ('1', 'NUM'), ('|', 'PUNCT'), ('|', 'PUNCT'), ('Lexalytics', 'PROPN'), (',', 'PUNCT'), ('Inc.', 'PROPN'), (',', 'PUNCT'), ('48', 'NUM'), ('North', 'PROPN'), ('Pleasant', 'ADJ'), ('St.', 'PROPN'), ('Unit', 'PROPN'), ('301', 'NUM'), (',', 'PUNCT'), ('Amherst', 'PROPN'), ('MA', 'PROPN'), ('01002', 'NUM'), ('USA', 'PROPN'), ('|', 'PUNCT'), ('1-800-377-8036', 'NUM'), ('|', 'PUNCT'), ('www.lexalytics.com', 'X')] 

 XPOS tags are: 
>> [('1', 'CD'), ('1', 'LS'), ('|', 'NFP'), ('|', 'NFP'), ('Lexalytics', 'NNP'), (',', ','), ('Inc.', 'NNP'), (',', ','), ('48', 'CD'), ('North', 'NNP'), ('Pleasant', 'NNP'), ('St.', 'NNP'), ('Unit', 'NNP'), ('301', 'CD'), (',', ','), ('Amherst', 'NNP'), ('MA', 'NNP'), ('01002', 'CD'), ('USA', 'NNP'), ('|', 'NFP'), ('1-800-377-8036', 'CD'), ('|', 'NFP'), ('www.lexalytics.com', 'ADD')] 

 Lemmas are: 
>> [('1', '1'), ('1', '1'), ('|', '|'), ('|', '|'), ('Lexalytics', 'Lexalytics'), (',', ','), ('Inc.', 'Inc.'), (',', ','), ('48', '48'), ('North', 'North'), ('Pleasant', 'Pleasant'), ('St.', 'St.'), ('Unit', 'unit'), ('301', '301'), (',', ','), ('Amherst', 'Amherst'), ('MA', 'MA'), ('01002', '01002'), ('USA', 'USA'), ('|', '|'), ('1-800-377-8036', '1-800-377-8036'), ('|', '|'), ('www.lexalytics.com', 'www.lexalytics.com')] 

 Dependency tags are: 
>> [(('1', '1'), 'compound'), (('1', 'Inc.'), 'nummod'), (('|', '1'), 'punct'), (('|', '1'), 'punct'), (('Lexalytics', 'Inc.'), 'compound'), ((',', 'Inc.'), 'punct'), (('Inc.', 'root'), 'root'), ((',', 'Inc.'), 'punct'), (('48', 'St.'), 'nummod'), (('North', 'St.'), 'compound'), (('Pleasant', 'St.'), 'amod'), (('St.', 'Unit'), 'compound'), (('Unit', 'Inc.'), 'list'), (('301', 'Unit'), 'nummod'), ((',', 'MA'), 'punct'), (('Amherst', 'MA'), 'appos'), (('MA', 'Inc.'), 'list'), (('01002', 'USA'), 'nummod'), (('USA', 'MA'), 'appos'), (('|', 'USA'), 'punct'), (('1-800-377-8036', 'Inc.'), 'list'), (('|', '1-800-377-8036'), 'punct'), (('www.lexalytics.com', 'Inc.'), 'list')]

 Named Entites are: 
>> [('1 1', 'CARDINAL'), ('301', 'CARDINAL')]

================================ Paragraph 150 =================================

One solution to this black box problem is to break big, general models   into smaller, targeted models. 


------------------- Sentence 1 -------------------

 One solution to this black box problem is to break big, general models   into smaller, targeted models. 

Tokens are: 
>> ['One', 'solution', 'to', 'this', 'black', 'box', 'problem', 'is', 'to', 'break', 'big', ',', 'general', 'models', 'into', 'smaller', ',', 'targeted', 'models', '.'] 

 UPOS tags are: 
>> [('One', 'NUM'), ('solution', 'NOUN'), ('to', 'ADP'), ('this', 'DET'), ('black', 'ADJ'), ('box', 'NOUN'), ('problem', 'NOUN'), ('is', 'VERB'), ('to', 'PART'), ('break', 'VERB'), ('big', 'ADJ'), (',', 'PUNCT'), ('general', 'ADJ'), ('models', 'NOUN'), ('into', 'ADP'), ('smaller', 'ADJ'), (',', 'PUNCT'), ('targeted', 'VERB'), ('models', 'NOUN'), ('.', 'PUNCT')] 

 XPOS tags are: 
>> [('One', 'CD'), ('solution', 'NN'), ('to', 'IN'), ('this', 'DT'), ('black', 'JJ'), ('box', 'NN'), ('problem', 'NN'), ('is', 'VBZ'), ('to', 'TO'), ('break', 'VB'), ('big', 'JJ'), (',', ','), ('general', 'JJ'), ('models', 'NNS'), ('into', 'IN'), ('smaller', 'JJR'), (',', ','), ('targeted', 'VBN'), ('models', 'NNS'), ('.', '.')] 

 Lemmas are: 
>> [('One', 'one'), ('solution', 'solution'), ('to', 'to'), ('this', 'this'), ('black', 'black'), ('box', 'box'), ('problem', 'problem'), ('is', 'be'), ('to', 'to'), ('break', 'break'), ('big', 'big'), (',', ','), ('general', 'general'), ('models', 'model'), ('into', 'into'), ('smaller', 'small'), (',', ','), ('targeted', 'target'), ('models', 'model'), ('.', '.')] 

 Dependency tags are: 
>> [(('One', 'solution'), 'nummod'), (('solution', 'break'), 'nsubj'), (('to', 'problem'), 'case'), (('this', 'problem'), 'det'), (('black', 'problem'), 'amod'), (('box', 'problem'), 'compound'), (('problem', 'solution'), 'nmod'), (('is', 'break'), 'cop'), (('to', 'break'), 'mark'), (('break', 'root'), 'root'), (('big', 'models'), 'amod'), ((',', 'models'), 'punct'), (('general', 'models'), 'amod'), (('models', 'break'), 'obj'), (('into', 'models'), 'case'), (('smaller', 'models'), 'amod'), ((',', 'models'), 'punct'), (('targeted', 'models'), 'amod'), (('models', 'break'), 'obl'), (('.', 'break'), 'punct')]

 Named Entites are: 
>> [('One', 'CARDINAL')]

================================ Paragraph 151 =================================

A model’s internal decisions are often hidden from view, so you should   make sure that the model isn’t doing too much in the first place.  


------------------- Sentence 1 -------------------

 A model’s internal decisions are often hidden from view, so you should   make sure that the model isn’t doing too much in the first place. 

Tokens are: 
>> ['A', 'model', '’s', 'internal', 'decisions', 'are', 'often', 'hidden', 'from', 'view', ',', 'so', 'you', 'should', 'make', 'sure', 'that', 'the', 'model', 'is', 'n’t', 'doing', 'too', 'much', 'in', 'the', 'first', 'place', '.'] 

 UPOS tags are: 
>> [('A', 'DET'), ('model', 'NOUN'), ('’s', 'PART'), ('internal', 'ADJ'), ('decisions', 'NOUN'), ('are', 'AUX'), ('often', 'ADV'), ('hidden', 'VERB'), ('from', 'ADP'), ('view', 'NOUN'), (',', 'PUNCT'), ('so', 'ADV'), ('you', 'PRON'), ('should', 'AUX'), ('make', 'VERB'), ('sure', 'ADJ'), ('that', 'SCONJ'), ('the', 'DET'), ('model', 'NOUN'), ('is', 'AUX'), ('n’t', 'PART'), ('doing', 'VERB'), ('too', 'ADV'), ('much', 'ADV'), ('in', 'ADP'), ('the', 'DET'), ('first', 'ADJ'), ('place', 'NOUN'), ('.', 'PUNCT')] 

 XPOS tags are: 
>> [('A', 'DT'), ('model', 'NN'), ('’s', 'POS'), ('internal', 'JJ'), ('decisions', 'NNS'), ('are', 'VBP'), ('often', 'RB'), ('hidden', 'VBN'), ('from', 'IN'), ('view', 'NN'), (',', ','), ('so', 'RB'), ('you', 'PRP'), ('should', 'MD'), ('make', 'VB'), ('sure', 'JJ'), ('that', 'IN'), ('the', 'DT'), ('model', 'NN'), ('is', 'VBZ'), ('n’t', 'RB'), ('doing', 'VBG'), ('too', 'RB'), ('much', 'RB'), ('in', 'IN'), ('the', 'DT'), ('first', 'JJ'), ('place', 'NN'), ('.', '.')] 

 Lemmas are: 
>> [('A', 'a'), ('model', 'model'), ('’s', "'s"), ('internal', 'internal'), ('decisions', 'decision'), ('are', 'be'), ('often', 'often'), ('hidden', 'hide'), ('from', 'from'), ('view', 'view'), (',', ','), ('so', 'so'), ('you', 'you'), ('should', 'should'), ('make', 'make'), ('sure', 'sure'), ('that', 'that'), ('the', 'the'), ('model', 'model'), ('is', 'be'), ('n’t', 'not'), ('doing', 'do'), ('too', 'too'), ('much', 'much'), ('in', 'in'), ('the', 'the'), ('first', 'first'), ('place', 'place'), ('.', '.')] 

 Dependency tags are: 
>> [(('A', 'model'), 'det'), (('model', 'decisions'), 'nmod:poss'), (('’s', 'model'), 'case'), (('internal', 'decisions'), 'amod'), (('decisions', 'hidden'), 'nsubj:pass'), (('are', 'hidden'), 'aux:pass'), (('often', 'hidden'), 'advmod'), (('hidden', 'root'), 'root'), (('from', 'view'), 'case'), (('view', 'hidden'), 'obl'), ((',', 'make'), 'punct'), (('so', 'make'), 'advmod'), (('you', 'make'), 'nsubj'), (('should', 'make'), 'aux'), (('make', 'hidden'), 'parataxis'), (('sure', 'make'), 'xcomp'), (('that', 'doing'), 'mark'), (('the', 'model'), 'det'), (('model', 'doing'), 'nsubj'), (('is', 'doing'), 'aux'), (('n’t', 'doing'), 'advmod'), (('doing', 'sure'), 'ccomp'), (('too', 'much'), 'advmod'), (('much', 'doing'), 'advmod'), (('in', 'place'), 'case'), (('the', 'place'), 'det'), (('first', 'place'), 'amod'), (('place', 'doing'), 'obl'), (('.', 'hidden'), 'punct')]

 Named Entites are: 
>> [('first', 'ORDINAL')]

================================ Paragraph 152 =================================

For example, if we were using one big model that analyzes an entire  document at once, we’d only be able to work at the document level. 


------------------- Sentence 1 -------------------

 For example, if we were using one big model that analyzes an entire  document at once, we’d only be able to work at the document level. 

Tokens are: 
>> ['For', 'example', ',', 'if', 'we', 'were', 'using', 'one', 'big', 'model', 'that', 'analyzes', 'an', 'entire', 'document', 'at', 'once', ',', 'we', '’d', 'only', 'be', 'able', 'to', 'work', 'at', 'the', 'document', 'level', '.'] 

 UPOS tags are: 
>> [('For', 'ADP'), ('example', 'NOUN'), (',', 'PUNCT'), ('if', 'SCONJ'), ('we', 'PRON'), ('were', 'AUX'), ('using', 'VERB'), ('one', 'NUM'), ('big', 'ADJ'), ('model', 'NOUN'), ('that', 'PRON'), ('analyzes', 'VERB'), ('an', 'DET'), ('entire', 'ADJ'), ('document', 'NOUN'), ('at', 'ADP'), ('once', 'ADV'), (',', 'PUNCT'), ('we', 'PRON'), ('’d', 'AUX'), ('only', 'ADV'), ('be', 'AUX'), ('able', 'ADJ'), ('to', 'PART'), ('work', 'VERB'), ('at', 'ADP'), ('the', 'DET'), ('document', 'NOUN'), ('level', 'NOUN'), ('.', 'PUNCT')] 

 XPOS tags are: 
>> [('For', 'IN'), ('example', 'NN'), (',', ','), ('if', 'IN'), ('we', 'PRP'), ('were', 'VBD'), ('using', 'VBG'), ('one', 'CD'), ('big', 'JJ'), ('model', 'NN'), ('that', 'WDT'), ('analyzes', 'VBZ'), ('an', 'DT'), ('entire', 'JJ'), ('document', 'NN'), ('at', 'IN'), ('once', 'RB'), (',', ','), ('we', 'PRP'), ('’d', 'MD'), ('only', 'RB'), ('be', 'VB'), ('able', 'JJ'), ('to', 'TO'), ('work', 'VB'), ('at', 'IN'), ('the', 'DT'), ('document', 'NN'), ('level', 'NN'), ('.', '.')] 

 Lemmas are: 
>> [('For', 'for'), ('example', 'example'), (',', ','), ('if', 'if'), ('we', 'we'), ('were', 'be'), ('using', 'use'), ('one', 'one'), ('big', 'big'), ('model', 'model'), ('that', 'that'), ('analyzes', 'analyze'), ('an', 'a'), ('entire', 'entire'), ('document', 'document'), ('at', 'at'), ('once', 'once'), (',', ','), ('we', 'we'), ('’d', 'have'), ('only', 'only'), ('be', 'be'), ('able', 'able'), ('to', 'to'), ('work', 'work'), ('at', 'at'), ('the', 'the'), ('document', 'document'), ('level', 'level'), ('.', '.')] 

 Dependency tags are: 
>> [(('For', 'example'), 'case'), (('example', 'able'), 'obl'), ((',', 'able'), 'punct'), (('if', 'using'), 'mark'), (('we', 'using'), 'nsubj'), (('were', 'using'), 'aux'), (('using', 'able'), 'advcl'), (('one', 'model'), 'nummod'), (('big', 'model'), 'amod'), (('model', 'using'), 'obj'), (('that', 'analyzes'), 'nsubj'), (('analyzes', 'model'), 'acl:relcl'), (('an', 'document'), 'det'), (('entire', 'document'), 'amod'), (('document', 'analyzes'), 'obj'), (('at', 'once'), 'case'), (('once', 'analyzes'), 'obl'), ((',', 'able'), 'punct'), (('we', 'able'), 'nsubj'), (('’d', 'able'), 'aux'), (('only', 'able'), 'advmod'), (('be', 'able'), 'cop'), (('able', 'root'), 'root'), (('to', 'work'), 'mark'), (('work', 'able'), 'xcomp'), (('at', 'level'), 'case'), (('the', 'level'), 'det'), (('document', 'level'), 'compound'), (('level', 'work'), 'obl'), (('.', 'able'), 'punct')]

 Named Entites are: 
>> [('one', 'CARDINAL')]

================================ Paragraph 153 =================================

Instead, Lexalytics utilizes a pipeline interaction between our models.   We start with tokenization, move on to parts of speech, then to phrases,   and all the way up until we’ve deconstructed the document at every   level. When there’s an issue in the pipeline, this approach helps us  see exactly where it is. Then, we can make adjustments to individual  components, such as retraining the part of speech tagger or tuning  its configuration files. Using smaller models gives us more flexibility to  determine where an issue is, as well as how to fix it.  


------------------- Sentence 1 -------------------

 Instead, Lexalytics utilizes a pipeline interaction between our models. 

Tokens are: 
>> ['Instead', ',', 'Lexalytics', 'utilizes', 'a', 'pipeline', 'interaction', 'between', 'our', 'models', '.'] 

 UPOS tags are: 
>> [('Instead', 'ADV'), (',', 'PUNCT'), ('Lexalytics', 'PROPN'), ('utilizes', 'VERB'), ('a', 'DET'), ('pipeline', 'NOUN'), ('interaction', 'NOUN'), ('between', 'ADP'), ('our', 'PRON'), ('models', 'NOUN'), ('.', 'PUNCT')] 

 XPOS tags are: 
>> [('Instead', 'RB'), (',', ','), ('Lexalytics', 'NNPS'), ('utilizes', 'VBZ'), ('a', 'DT'), ('pipeline', 'NN'), ('interaction', 'NN'), ('between', 'IN'), ('our', 'PRP$'), ('models', 'NNS'), ('.', '.')] 

 Lemmas are: 
>> [('Instead', 'instead'), (',', ','), ('Lexalytics', 'Lexalytics'), ('utilizes', 'utilize'), ('a', 'a'), ('pipeline', 'pipeline'), ('interaction', 'interaction'), ('between', 'between'), ('our', 'we'), ('models', 'model'), ('.', '.')] 

 Dependency tags are: 
>> [(('Instead', 'utilizes'), 'advmod'), ((',', 'utilizes'), 'punct'), (('Lexalytics', 'utilizes'), 'nsubj'), (('utilizes', 'root'), 'root'), (('a', 'interaction'), 'det'), (('pipeline', 'interaction'), 'compound'), (('interaction', 'utilizes'), 'obj'), (('between', 'models'), 'case'), (('our', 'models'), 'nmod:poss'), (('models', 'interaction'), 'nmod'), (('.', 'utilizes'), 'punct')]

 Named Entites are: 
>> [('Lexalytics', 'ORG')]

------------------- Sentence 2 -------------------

 We start with tokenization, move on to parts of speech, then to phrases,   and all the way up until we’ve deconstructed the document at every   level. 

Tokens are: 
>> ['We', 'start', 'with', 'tokenization', ',', 'move', 'on', 'to', 'parts', 'of', 'speech', ',', 'then', 'to', 'phrases', ',', 'and', 'all', 'the', 'way', 'up', 'until', 'we', '’ve', 'deconstructed', 'the', 'document', 'at', 'every', 'level', '.'] 

 UPOS tags are: 
>> [('We', 'PRON'), ('start', 'VERB'), ('with', 'ADP'), ('tokenization', 'NOUN'), (',', 'PUNCT'), ('move', 'VERB'), ('on', 'ADP'), ('to', 'ADP'), ('parts', 'NOUN'), ('of', 'ADP'), ('speech', 'NOUN'), (',', 'PUNCT'), ('then', 'ADV'), ('to', 'ADP'), ('phrases', 'NOUN'), (',', 'PUNCT'), ('and', 'CCONJ'), ('all', 'PRON'), ('the', 'DET'), ('way', 'NOUN'), ('up', 'ADP'), ('until', 'SCONJ'), ('we', 'PRON'), ('’ve', 'AUX'), ('deconstructed', 'VERB'), ('the', 'DET'), ('document', 'NOUN'), ('at', 'ADP'), ('every', 'DET'), ('level', 'NOUN'), ('.', 'PUNCT')] 

 XPOS tags are: 
>> [('We', 'PRP'), ('start', 'VBP'), ('with', 'IN'), ('tokenization', 'NN'), (',', ','), ('move', 'VBP'), ('on', 'RP'), ('to', 'IN'), ('parts', 'NNS'), ('of', 'IN'), ('speech', 'NN'), (',', ','), ('then', 'RB'), ('to', 'IN'), ('phrases', 'NNS'), (',', ','), ('and', 'CC'), ('all', 'PDT'), ('the', 'DT'), ('way', 'NN'), ('up', 'RP'), ('until', 'IN'), ('we', 'PRP'), ('’ve', 'VBP'), ('deconstructed', 'VBN'), ('the', 'DT'), ('document', 'NN'), ('at', 'IN'), ('every', 'DT'), ('level', 'NN'), ('.', '.')] 

 Lemmas are: 
>> [('We', 'we'), ('start', 'start'), ('with', 'with'), ('tokenization', 'tokenization'), (',', ','), ('move', 'move'), ('on', 'on'), ('to', 'to'), ('parts', 'part'), ('of', 'of'), ('speech', 'speech'), (',', ','), ('then', 'then'), ('to', 'to'), ('phrases', 'phrase'), (',', ','), ('and', 'and'), ('all', 'all'), ('the', 'the'), ('way', 'way'), ('up', 'up'), ('until', 'until'), ('we', 'we'), ('’ve', 'have'), ('deconstructed', 'deconstruct'), ('the', 'the'), ('document', 'document'), ('at', 'at'), ('every', 'every'), ('level', 'level'), ('.', '.')] 

 Dependency tags are: 
>> [(('We', 'start'), 'nsubj'), (('start', 'root'), 'root'), (('with', 'tokenization'), 'case'), (('tokenization', 'start'), 'obl'), ((',', 'move'), 'punct'), (('move', 'start'), 'conj'), (('on', 'move'), 'compound:prt'), (('to', 'parts'), 'case'), (('parts', 'move'), 'obl'), (('of', 'speech'), 'case'), (('speech', 'parts'), 'nmod'), ((',', 'phrases'), 'punct'), (('then', 'phrases'), 'advmod'), (('to', 'phrases'), 'case'), (('phrases', 'parts'), 'nmod'), ((',', 'way'), 'punct'), (('and', 'way'), 'cc'), (('all', 'way'), 'det:predet'), (('the', 'way'), 'det'), (('way', 'phrases'), 'conj'), (('up', 'way'), 'advmod'), (('until', 'deconstructed'), 'mark'), (('we', 'deconstructed'), 'nsubj'), (('’ve', 'deconstructed'), 'aux'), (('deconstructed', 'way'), 'acl'), (('the', 'document'), 'det'), (('document', 'deconstructed'), 'obj'), (('at', 'level'), 'case'), (('every', 'level'), 'det'), (('level', 'deconstructed'), 'obl'), (('.', 'start'), 'punct')]

 Named Entites are: 
>> []

------------------- Sentence 3 -------------------

 When there’s an issue in the pipeline, this approach helps us  see exactly where it is. 

Tokens are: 
>> ['When', 'there', '’s', 'an', 'issue', 'in', 'the', 'pipeline', ',', 'this', 'approach', 'helps', 'us', 'see', 'exactly', 'where', 'it', 'is', '.'] 

 UPOS tags are: 
>> [('When', 'SCONJ'), ('there', 'PRON'), ('’s', 'VERB'), ('an', 'DET'), ('issue', 'NOUN'), ('in', 'ADP'), ('the', 'DET'), ('pipeline', 'NOUN'), (',', 'PUNCT'), ('this', 'DET'), ('approach', 'NOUN'), ('helps', 'VERB'), ('us', 'PRON'), ('see', 'VERB'), ('exactly', 'ADV'), ('where', 'SCONJ'), ('it', 'PRON'), ('is', 'AUX'), ('.', 'PUNCT')] 

 XPOS tags are: 
>> [('When', 'WRB'), ('there', 'EX'), ('’s', 'VBZ'), ('an', 'DT'), ('issue', 'NN'), ('in', 'IN'), ('the', 'DT'), ('pipeline', 'NN'), (',', ','), ('this', 'DT'), ('approach', 'NN'), ('helps', 'VBZ'), ('us', 'PRP'), ('see', 'VB'), ('exactly', 'RB'), ('where', 'WRB'), ('it', 'PRP'), ('is', 'VBZ'), ('.', '.')] 

 Lemmas are: 
>> [('When', 'when'), ('there', 'there'), ('’s', 'be'), ('an', 'a'), ('issue', 'issue'), ('in', 'in'), ('the', 'the'), ('pipeline', 'pipeline'), (',', ','), ('this', 'this'), ('approach', 'approach'), ('helps', 'help'), ('us', 'we'), ('see', 'see'), ('exactly', 'exactly'), ('where', 'where'), ('it', 'it'), ('is', 'be'), ('.', '.')] 

 Dependency tags are: 
>> [(('When', '’s'), 'mark'), (('there', '’s'), 'expl'), (('’s', 'helps'), 'advcl'), (('an', 'issue'), 'det'), (('issue', '’s'), 'nsubj'), (('in', 'pipeline'), 'case'), (('the', 'pipeline'), 'det'), (('pipeline', 'issue'), 'nmod'), ((',', 'helps'), 'punct'), (('this', 'approach'), 'det'), (('approach', 'helps'), 'nsubj'), (('helps', 'root'), 'root'), (('us', 'helps'), 'obj'), (('see', 'helps'), 'xcomp'), (('exactly', 'where'), 'advmod'), (('where', 'see'), 'ccomp'), (('it', 'where'), 'nsubj'), (('is', 'where'), 'cop'), (('.', 'helps'), 'punct')]

 Named Entites are: 
>> []

------------------- Sentence 4 -------------------

 Then, we can make adjustments to individual  components, such as retraining the part of speech tagger or tuning  its configuration files. 

Tokens are: 
>> ['Then', ',', 'we', 'can', 'make', 'adjustments', 'to', 'individual', 'components', ',', 'such', 'as', 'retraining', 'the', 'part', 'of', 'speech', 'tagger', 'or', 'tuning', 'its', 'configuration', 'files', '.'] 

 UPOS tags are: 
>> [('Then', 'ADV'), (',', 'PUNCT'), ('we', 'PRON'), ('can', 'AUX'), ('make', 'VERB'), ('adjustments', 'NOUN'), ('to', 'ADP'), ('individual', 'ADJ'), ('components', 'NOUN'), (',', 'PUNCT'), ('such', 'ADJ'), ('as', 'SCONJ'), ('retraining', 'VERB'), ('the', 'DET'), ('part', 'NOUN'), ('of', 'ADP'), ('speech', 'NOUN'), ('tagger', 'NOUN'), ('or', 'CCONJ'), ('tuning', 'VERB'), ('its', 'PRON'), ('configuration', 'NOUN'), ('files', 'NOUN'), ('.', 'PUNCT')] 

 XPOS tags are: 
>> [('Then', 'RB'), (',', ','), ('we', 'PRP'), ('can', 'MD'), ('make', 'VB'), ('adjustments', 'NNS'), ('to', 'IN'), ('individual', 'JJ'), ('components', 'NNS'), (',', ','), ('such', 'JJ'), ('as', 'IN'), ('retraining', 'VBG'), ('the', 'DT'), ('part', 'NN'), ('of', 'IN'), ('speech', 'NN'), ('tagger', 'NN'), ('or', 'CC'), ('tuning', 'VBG'), ('its', 'PRP$'), ('configuration', 'NN'), ('files', 'NNS'), ('.', '.')] 

 Lemmas are: 
>> [('Then', 'then'), (',', ','), ('we', 'we'), ('can', 'can'), ('make', 'make'), ('adjustments', 'adjustment'), ('to', 'to'), ('individual', 'individual'), ('components', 'component'), (',', ','), ('such', 'such'), ('as', 'as'), ('retraining', 'retrain'), ('the', 'the'), ('part', 'part'), ('of', 'of'), ('speech', 'speech'), ('tagger', 'tagger'), ('or', 'or'), ('tuning', 'tuning'), ('its', 'its'), ('configuration', 'configuration'), ('files', 'file'), ('.', '.')] 

 Dependency tags are: 
>> [(('Then', 'make'), 'advmod'), ((',', 'make'), 'punct'), (('we', 'make'), 'nsubj'), (('can', 'make'), 'aux'), (('make', 'root'), 'root'), (('adjustments', 'make'), 'obj'), (('to', 'components'), 'case'), (('individual', 'components'), 'amod'), (('components', 'make'), 'obl'), ((',', 'retraining'), 'punct'), (('such', 'retraining'), 'mark'), (('as', 'such'), 'fixed'), (('retraining', 'components'), 'acl'), (('the', 'part'), 'det'), (('part', 'retraining'), 'obj'), (('of', 'tagger'), 'case'), (('speech', 'tagger'), 'compound'), (('tagger', 'part'), 'nmod'), (('or', 'tuning'), 'cc'), (('tuning', 'retraining'), 'conj'), (('its', 'files'), 'nmod:poss'), (('configuration', 'files'), 'compound'), (('files', 'tuning'), 'obj'), (('.', 'make'), 'punct')]

 Named Entites are: 
>> []

------------------- Sentence 5 -------------------

 Using smaller models gives us more flexibility to  determine where an issue is, as well as how to fix it. 

Tokens are: 
>> ['Using', 'smaller', 'models', 'gives', 'us', 'more', 'flexibility', 'to', 'determine', 'where', 'an', 'issue', 'is', ',', 'as', 'well', 'as', 'how', 'to', 'fix', 'it', '.'] 

 UPOS tags are: 
>> [('Using', 'VERB'), ('smaller', 'ADJ'), ('models', 'NOUN'), ('gives', 'VERB'), ('us', 'PRON'), ('more', 'ADJ'), ('flexibility', 'NOUN'), ('to', 'PART'), ('determine', 'VERB'), ('where', 'SCONJ'), ('an', 'DET'), ('issue', 'NOUN'), ('is', 'AUX'), (',', 'PUNCT'), ('as', 'ADV'), ('well', 'ADV'), ('as', 'SCONJ'), ('how', 'SCONJ'), ('to', 'PART'), ('fix', 'VERB'), ('it', 'PRON'), ('.', 'PUNCT')] 

 XPOS tags are: 
>> [('Using', 'VBG'), ('smaller', 'JJR'), ('models', 'NNS'), ('gives', 'VBZ'), ('us', 'PRP'), ('more', 'JJR'), ('flexibility', 'NN'), ('to', 'TO'), ('determine', 'VB'), ('where', 'WRB'), ('an', 'DT'), ('issue', 'NN'), ('is', 'VBZ'), (',', ','), ('as', 'RB'), ('well', 'RB'), ('as', 'IN'), ('how', 'WRB'), ('to', 'TO'), ('fix', 'VB'), ('it', 'PRP'), ('.', '.')] 

 Lemmas are: 
>> [('Using', 'use'), ('smaller', 'small'), ('models', 'model'), ('gives', 'give'), ('us', 'we'), ('more', 'more'), ('flexibility', 'flexibility'), ('to', 'to'), ('determine', 'determine'), ('where', 'where'), ('an', 'a'), ('issue', 'issue'), ('is', 'be'), (',', ','), ('as', 'as'), ('well', 'well'), ('as', 'as'), ('how', 'how'), ('to', 'to'), ('fix', 'fix'), ('it', 'it'), ('.', '.')] 

 Dependency tags are: 
>> [(('Using', 'gives'), 'csubj'), (('smaller', 'models'), 'amod'), (('models', 'Using'), 'obj'), (('gives', 'root'), 'root'), (('us', 'gives'), 'iobj'), (('more', 'flexibility'), 'amod'), (('flexibility', 'gives'), 'obj'), (('to', 'determine'), 'mark'), (('determine', 'flexibility'), 'acl'), (('where', 'determine'), 'ccomp'), (('an', 'issue'), 'det'), (('issue', 'where'), 'nsubj'), (('is', 'where'), 'cop'), ((',', 'fix'), 'punct'), (('as', 'fix'), 'cc'), (('well', 'as'), 'fixed'), (('as', 'as'), 'fixed'), (('how', 'fix'), 'mark'), (('to', 'fix'), 'mark'), (('fix', 'where'), 'conj'), (('it', 'fix'), 'obj'), (('.', 'gives'), 'punct')]

 Named Entites are: 
>> []

================================ Paragraph 154 =================================

Take the phrase “Good   Morning America.” It looks  innocuous, but it’s not. If your  part-of-speech tagger fails to  apply “proper noun” to the  phrase “Good Morning America,”  this phrase won’t be denoted   as being an entity. 


------------------- Sentence 1 -------------------

 Take the phrase “Good   Morning America.” 

Tokens are: 
>> ['Take', 'the', 'phrase', '“', 'Good', 'Morning', 'America', '.', '”'] 

 UPOS tags are: 
>> [('Take', 'VERB'), ('the', 'DET'), ('phrase', 'NOUN'), ('“', 'PUNCT'), ('Good', 'ADJ'), ('Morning', 'PROPN'), ('America', 'PROPN'), ('.', 'PUNCT'), ('”', 'PUNCT')] 

 XPOS tags are: 
>> [('Take', 'VB'), ('the', 'DT'), ('phrase', 'NN'), ('“', '``'), ('Good', 'NNP'), ('Morning', 'NNP'), ('America', 'NNP'), ('.', '.'), ('”', "''")] 

 Lemmas are: 
>> [('Take', 'take'), ('the', 'the'), ('phrase', 'phrase'), ('“', "''"), ('Good', 'good'), ('Morning', 'Morning'), ('America', 'America'), ('.', '.'), ('”', "''")] 

 Dependency tags are: 
>> [(('Take', 'root'), 'root'), (('the', 'phrase'), 'det'), (('phrase', 'Take'), 'obj'), (('“', 'America'), 'punct'), (('Good', 'Morning'), 'amod'), (('Morning', 'America'), 'compound'), (('America', 'Take'), 'obj'), (('.', 'America'), 'punct'), (('”', 'America'), 'punct')]

 Named Entites are: 
>> [('Good   Morning America', 'WORK_OF_ART')]

------------------- Sentence 2 -------------------

 It looks  innocuous, but it’s not. 

Tokens are: 
>> ['It', 'looks', 'innocuous', ',', 'but', 'it', '’s', 'not', '.'] 

 UPOS tags are: 
>> [('It', 'PRON'), ('looks', 'VERB'), ('innocuous', 'ADJ'), (',', 'PUNCT'), ('but', 'CCONJ'), ('it', 'PRON'), ('’s', 'AUX'), ('not', 'PART'), ('.', 'PUNCT')] 

 XPOS tags are: 
>> [('It', 'PRP'), ('looks', 'VBZ'), ('innocuous', 'JJ'), (',', ','), ('but', 'CC'), ('it', 'PRP'), ('’s', 'VBZ'), ('not', 'RB'), ('.', '.')] 

 Lemmas are: 
>> [('It', 'it'), ('looks', 'look'), ('innocuous', 'innocuous'), (',', ','), ('but', 'but'), ('it', 'it'), ('’s', 'be'), ('not', 'not'), ('.', '.')] 

 Dependency tags are: 
>> [(('It', 'looks'), 'nsubj'), (('looks', 'root'), 'root'), (('innocuous', 'looks'), 'xcomp'), ((',', '’s'), 'punct'), (('but', '’s'), 'cc'), (('it', '’s'), 'nsubj'), (('’s', 'looks'), 'conj'), (('not', '’s'), 'advmod'), (('.', 'looks'), 'punct')]

 Named Entites are: 
>> []

------------------- Sentence 3 -------------------

 If your  part-of-speech tagger fails to  apply “proper noun” to the  phrase “Good Morning America,”  this phrase won’t be denoted   as being an entity. 

Tokens are: 
>> ['If', 'your', 'part', '-', 'of', '-', 'speech', 'tagger', 'fails', 'to', 'apply', '“', 'proper', 'noun', '”', 'to', 'the', 'phrase', '“', 'Good', 'Morning', 'America', ',', '”', 'this', 'phrase', 'wo', 'n’t', 'be', 'denoted', 'as', 'being', 'an', 'entity', '.'] 

 UPOS tags are: 
>> [('If', 'SCONJ'), ('your', 'PRON'), ('part', 'NOUN'), ('-', 'PUNCT'), ('of', 'ADP'), ('-', 'PUNCT'), ('speech', 'NOUN'), ('tagger', 'NOUN'), ('fails', 'VERB'), ('to', 'PART'), ('apply', 'VERB'), ('“', 'PUNCT'), ('proper', 'ADJ'), ('noun', 'NOUN'), ('”', 'PUNCT'), ('to', 'ADP'), ('the', 'DET'), ('phrase', 'NOUN'), ('“', 'PUNCT'), ('Good', 'ADJ'), ('Morning', 'PROPN'), ('America', 'PROPN'), (',', 'PUNCT'), ('”', 'PUNCT'), ('this', 'DET'), ('phrase', 'NOUN'), ('wo', 'AUX'), ('n’t', 'PART'), ('be', 'AUX'), ('denoted', 'VERB'), ('as', 'SCONJ'), ('being', 'AUX'), ('an', 'DET'), ('entity', 'NOUN'), ('.', 'PUNCT')] 

 XPOS tags are: 
>> [('If', 'IN'), ('your', 'PRP$'), ('part', 'NN'), ('-', 'HYPH'), ('of', 'IN'), ('-', 'HYPH'), ('speech', 'NN'), ('tagger', 'NN'), ('fails', 'VBZ'), ('to', 'TO'), ('apply', 'VB'), ('“', '``'), ('proper', 'JJ'), ('noun', 'NN'), ('”', "''"), ('to', 'IN'), ('the', 'DT'), ('phrase', 'NN'), ('“', '``'), ('Good', 'NNP'), ('Morning', 'NNP'), ('America', 'NNP'), (',', ','), ('”', "''"), ('this', 'DT'), ('phrase', 'NN'), ('wo', 'MD'), ('n’t', 'RB'), ('be', 'VB'), ('denoted', 'VBN'), ('as', 'IN'), ('being', 'VBG'), ('an', 'DT'), ('entity', 'NN'), ('.', '.')] 

 Lemmas are: 
>> [('If', 'if'), ('your', 'you'), ('part', 'part'), ('-', '-'), ('of', 'of'), ('-', '-'), ('speech', 'speech'), ('tagger', 'tagger'), ('fails', 'fail'), ('to', 'to'), ('apply', 'apply'), ('“', "''"), ('proper', 'proper'), ('noun', 'noun'), ('”', "''"), ('to', 'to'), ('the', 'the'), ('phrase', 'phrase'), ('“', "''"), ('Good', 'good'), ('Morning', 'Morning'), ('America', 'America'), (',', ','), ('”', "''"), ('this', 'this'), ('phrase', 'phrase'), ('wo', 'will'), ('n’t', 'not'), ('be', 'be'), ('denoted', 'denote'), ('as', 'as'), ('being', 'be'), ('an', 'a'), ('entity', 'entity'), ('.', '.')] 

 Dependency tags are: 
>> [(('If', 'fails'), 'mark'), (('your', 'tagger'), 'nmod:poss'), (('part', 'tagger'), 'compound'), (('-', 'part'), 'punct'), (('of', 'speech'), 'case'), (('-', 'speech'), 'punct'), (('speech', 'part'), 'nmod'), (('tagger', 'fails'), 'nsubj'), (('fails', 'denoted'), 'advcl'), (('to', 'apply'), 'mark'), (('apply', 'fails'), 'xcomp'), (('“', 'noun'), 'punct'), (('proper', 'noun'), 'amod'), (('noun', 'apply'), 'obj'), (('”', 'noun'), 'punct'), (('to', 'phrase'), 'case'), (('the', 'phrase'), 'det'), (('phrase', 'apply'), 'obl'), (('“', 'America'), 'punct'), (('Good', 'Morning'), 'amod'), (('Morning', 'America'), 'compound'), (('America', 'phrase'), 'appos'), ((',', 'America'), 'punct'), (('”', 'America'), 'punct'), (('this', 'phrase'), 'det'), (('phrase', 'denoted'), 'nsubj:pass'), (('wo', 'denoted'), 'aux'), (('n’t', 'denoted'), 'advmod'), (('be', 'denoted'), 'aux:pass'), (('denoted', 'root'), 'root'), (('as', 'entity'), 'mark'), (('being', 'entity'), 'cop'), (('an', 'entity'), 'det'), (('entity', 'denoted'), 'advcl'), (('.', 'denoted'), 'punct')]

 Named Entites are: 
>> [('Good Morning America', 'WORK_OF_ART')]

================================ Paragraph 155 =================================

You have to know that it’s an entity (TV Show) and not a greeting. If you   don’t, you might interpret “good” as being positive, rather than just part   of the entity name. 


------------------- Sentence 1 -------------------

 You have to know that it’s an entity (TV Show) and not a greeting. 

Tokens are: 
>> ['You', 'have', 'to', 'know', 'that', 'it', '’s', 'an', 'entity', '(', 'TV', 'Show', ')', 'and', 'not', 'a', 'greeting', '.'] 

 UPOS tags are: 
>> [('You', 'PRON'), ('have', 'VERB'), ('to', 'PART'), ('know', 'VERB'), ('that', 'SCONJ'), ('it', 'PRON'), ('’s', 'AUX'), ('an', 'DET'), ('entity', 'NOUN'), ('(', 'PUNCT'), ('TV', 'NOUN'), ('Show', 'NOUN'), (')', 'PUNCT'), ('and', 'CCONJ'), ('not', 'PART'), ('a', 'DET'), ('greeting', 'NOUN'), ('.', 'PUNCT')] 

 XPOS tags are: 
>> [('You', 'PRP'), ('have', 'VBP'), ('to', 'TO'), ('know', 'VB'), ('that', 'IN'), ('it', 'PRP'), ('’s', 'VBZ'), ('an', 'DT'), ('entity', 'NN'), ('(', '-LRB-'), ('TV', 'NN'), ('Show', 'NN'), (')', '-RRB-'), ('and', 'CC'), ('not', 'RB'), ('a', 'DT'), ('greeting', 'NN'), ('.', '.')] 

 Lemmas are: 
>> [('You', 'you'), ('have', 'have'), ('to', 'to'), ('know', 'know'), ('that', 'that'), ('it', 'it'), ('’s', 'be'), ('an', 'a'), ('entity', 'entity'), ('(', '('), ('TV', 'tv'), ('Show', 'show'), (')', ')'), ('and', 'and'), ('not', 'not'), ('a', 'a'), ('greeting', 'greeting'), ('.', '.')] 

 Dependency tags are: 
>> [(('You', 'have'), 'nsubj'), (('have', 'root'), 'root'), (('to', 'know'), 'mark'), (('know', 'have'), 'xcomp'), (('that', 'entity'), 'mark'), (('it', 'entity'), 'nsubj'), (('’s', 'entity'), 'cop'), (('an', 'entity'), 'det'), (('entity', 'know'), 'ccomp'), (('(', 'Show'), 'punct'), (('TV', 'Show'), 'compound'), (('Show', 'entity'), 'appos'), ((')', 'Show'), 'punct'), (('and', 'greeting'), 'cc'), (('not', 'greeting'), 'advmod'), (('a', 'greeting'), 'det'), (('greeting', 'entity'), 'conj'), (('.', 'have'), 'punct')]

 Named Entites are: 
>> []

------------------- Sentence 2 -------------------

 If you   don’t, you might interpret “good” as being positive, rather than just part   of the entity name. 

Tokens are: 
>> ['If', 'you', 'do', 'n’t', ',', 'you', 'might', 'interpret', '“', 'good', '”', 'as', 'being', 'positive', ',', 'rather', 'than', 'just', 'part', 'of', 'the', 'entity', 'name', '.'] 

 UPOS tags are: 
>> [('If', 'SCONJ'), ('you', 'PRON'), ('do', 'AUX'), ('n’t', 'PART'), (',', 'PUNCT'), ('you', 'PRON'), ('might', 'AUX'), ('interpret', 'VERB'), ('“', 'PUNCT'), ('good', 'ADJ'), ('”', 'PUNCT'), ('as', 'SCONJ'), ('being', 'AUX'), ('positive', 'ADJ'), (',', 'PUNCT'), ('rather', 'ADV'), ('than', 'ADP'), ('just', 'ADV'), ('part', 'NOUN'), ('of', 'ADP'), ('the', 'DET'), ('entity', 'NOUN'), ('name', 'NOUN'), ('.', 'PUNCT')] 

 XPOS tags are: 
>> [('If', 'IN'), ('you', 'PRP'), ('do', 'VBP'), ('n’t', 'RB'), (',', ','), ('you', 'PRP'), ('might', 'MD'), ('interpret', 'VB'), ('“', '``'), ('good', 'JJ'), ('”', "''"), ('as', 'IN'), ('being', 'VBG'), ('positive', 'JJ'), (',', ','), ('rather', 'RB'), ('than', 'IN'), ('just', 'RB'), ('part', 'NN'), ('of', 'IN'), ('the', 'DT'), ('entity', 'NN'), ('name', 'NN'), ('.', '.')] 

 Lemmas are: 
>> [('If', 'if'), ('you', 'you'), ('do', 'do'), ('n’t', 'not'), (',', ','), ('you', 'you'), ('might', 'might'), ('interpret', 'interpret'), ('“', "''"), ('good', 'good'), ('”', "''"), ('as', 'as'), ('being', 'be'), ('positive', 'positive'), (',', ','), ('rather', 'rather'), ('than', 'than'), ('just', 'just'), ('part', 'part'), ('of', 'of'), ('the', 'the'), ('entity', 'entity'), ('name', 'name'), ('.', '.')] 

 Dependency tags are: 
>> [(('If', 'do'), 'mark'), (('you', 'do'), 'nsubj'), (('do', 'interpret'), 'advcl'), (('n’t', 'do'), 'advmod'), ((',', 'interpret'), 'punct'), (('you', 'interpret'), 'nsubj'), (('might', 'interpret'), 'aux'), (('interpret', 'root'), 'root'), (('“', 'good'), 'punct'), (('good', 'interpret'), 'xcomp'), (('”', 'good'), 'punct'), (('as', 'positive'), 'mark'), (('being', 'positive'), 'cop'), (('positive', 'interpret'), 'advcl'), ((',', 'part'), 'punct'), (('rather', 'part'), 'cc'), (('than', 'rather'), 'fixed'), (('just', 'part'), 'advmod'), (('part', 'good'), 'conj'), (('of', 'name'), 'case'), (('the', 'name'), 'det'), (('entity', 'name'), 'compound'), (('name', 'part'), 'nmod'), (('.', 'interpret'), 'punct')]

 Named Entites are: 
>> []

================================ Paragraph 156 =================================

GOOD MORNING AMERICA is a registered trademark and brand of American Broadcasting Companies, Inc.  and is not affiliated with Lexalytics, Inc


------------------- Sentence 1 -------------------

 GOOD MORNING AMERICA is a registered trademark and brand of American Broadcasting Companies, Inc.  and is not affiliated with Lexalytics, Inc 

Tokens are: 
>> ['GOOD', 'MORNING', 'AMERICA', 'is', 'a', 'registered', 'trademark', 'and', 'brand', 'of', 'American', 'Broadcasting', 'Companies', ',', 'Inc.', 'and', 'is', 'not', 'affiliated', 'with', 'Lexalytics', ',', 'Inc'] 

 UPOS tags are: 
>> [('GOOD', 'ADJ'), ('MORNING', 'NOUN'), ('AMERICA', 'PROPN'), ('is', 'AUX'), ('a', 'DET'), ('registered', 'VERB'), ('trademark', 'NOUN'), ('and', 'CCONJ'), ('brand', 'NOUN'), ('of', 'ADP'), ('American', 'ADJ'), ('Broadcasting', 'PROPN'), ('Companies', 'PROPN'), (',', 'PUNCT'), ('Inc.', 'PROPN'), ('and', 'CCONJ'), ('is', 'AUX'), ('not', 'PART'), ('affiliated', 'VERB'), ('with', 'ADP'), ('Lexalytics', 'PROPN'), (',', 'PUNCT'), ('Inc', 'PROPN')] 

 XPOS tags are: 
>> [('GOOD', 'JJ'), ('MORNING', 'NN'), ('AMERICA', 'NNP'), ('is', 'VBZ'), ('a', 'DT'), ('registered', 'VBN'), ('trademark', 'NN'), ('and', 'CC'), ('brand', 'NN'), ('of', 'IN'), ('American', 'JJ'), ('Broadcasting', 'NNP'), ('Companies', 'NNPS'), (',', ','), ('Inc.', 'NNP'), ('and', 'CC'), ('is', 'VBZ'), ('not', 'RB'), ('affiliated', 'VBN'), ('with', 'IN'), ('Lexalytics', 'NNPS'), (',', ','), ('Inc', 'NNP')] 

 Lemmas are: 
>> [('GOOD', 'good'), ('MORNING', 'morning'), ('AMERICA', 'AMERICA'), ('is', 'be'), ('a', 'a'), ('registered', 'register'), ('trademark', 'trademark'), ('and', 'and'), ('brand', 'brand'), ('of', 'of'), ('American', 'American'), ('Broadcasting', 'Broadcasting'), ('Companies', 'company'), (',', ','), ('Inc.', 'Inc.'), ('and', 'and'), ('is', 'be'), ('not', 'not'), ('affiliated', 'affiliate'), ('with', 'with'), ('Lexalytics', 'Lexalytics'), (',', ','), ('Inc', 'Inc')] 

 Dependency tags are: 
>> [(('GOOD', 'MORNING'), 'amod'), (('MORNING', 'trademark'), 'obl:tmod'), (('AMERICA', 'trademark'), 'nsubj'), (('is', 'trademark'), 'cop'), (('a', 'trademark'), 'det'), (('registered', 'trademark'), 'amod'), (('trademark', 'root'), 'root'), (('and', 'brand'), 'cc'), (('brand', 'trademark'), 'conj'), (('of', 'Companies'), 'case'), (('American', 'Companies'), 'amod'), (('Broadcasting', 'Companies'), 'compound'), (('Companies', 'brand'), 'nmod'), ((',', 'Inc.'), 'punct'), (('Inc.', 'Companies'), 'conj'), (('and', 'affiliated'), 'cc'), (('is', 'affiliated'), 'aux:pass'), (('not', 'affiliated'), 'advmod'), (('affiliated', 'trademark'), 'conj'), (('with', 'Lexalytics'), 'case'), (('Lexalytics', 'affiliated'), 'obl'), ((',', 'Lexalytics'), 'punct'), (('Inc', 'Lexalytics'), 'appos')]

 Named Entites are: 
>> [('GOOD MORNING AMERICA', 'ORG'), ('American Broadcasting Companies, Inc.', 'ORG'), ('Lexalytics, Inc', 'ORG')]

================================ Paragraph 157 =================================

W H I T E  P A P E R 


------------------- Sentence 1 -------------------

 W H I T E  P A P E R 

Tokens are: 
>> ['W', 'H', 'I', 'T', 'E', 'P', 'A', 'P', 'E', 'R'] 

 UPOS tags are: 
>> [('W', 'PROPN'), ('H', 'PUNCT'), ('I', 'PRON'), ('T', 'AUX'), ('E', 'PROPN'), ('P', 'NOUN'), ('A', 'NOUN'), ('P', 'NOUN'), ('E', 'NOUN'), ('R', 'NOUN')] 

 XPOS tags are: 
>> [('W', 'NNP'), ('H', ','), ('I', 'PRP'), ('T', 'VBP'), ('E', 'NNP'), ('P', 'NN'), ('A', 'NN'), ('P', 'NN'), ('E', 'NN'), ('R', 'NN')] 

 Lemmas are: 
>> [('W', 'W'), ('H', 'H'), ('I', 'I'), ('T', 'T'), ('E', 'E'), ('P', 'p'), ('A', 'a'), ('P', 'p'), ('E', 'e'), ('R', 'R')] 

 Dependency tags are: 
>> [(('W', 'T'), 'vocative'), (('H', 'W'), 'punct'), (('I', 'T'), 'nsubj'), (('T', 'root'), 'root'), (('E', 'T'), 'obj'), (('P', 'T'), 'obj'), (('A', 'E'), 'compound'), (('P', 'E'), 'compound'), (('E', 'R'), 'compound'), (('R', 'T'), 'obj')]

 Named Entites are: 
>> []

================================ Paragraph 158 =================================

12|       |   Lexalytics, Inc., 48 North Pleasant St. Unit 301, Amherst MA 01002 USA   |   1-800-377-8036 |   www.lexalytics.com 


------------------- Sentence 1 -------------------

 12|       |   Lexalytics, Inc., 48 North Pleasant St. Unit 301, Amherst MA 01002 USA   |   1-800-377-8036 |   www.lexalytics.com 

Tokens are: 
>> ['12', '|', '|', 'Lexalytics', ',', 'Inc.', ',', '48', 'North', 'Pleasant', 'St.', 'Unit', '301', ',', 'Amherst', 'MA', '01002', 'USA', '|', '1-800-377-8036', '|', 'www.lexalytics.com'] 

 UPOS tags are: 
>> [('12', 'NUM'), ('|', 'PUNCT'), ('|', 'PUNCT'), ('Lexalytics', 'PROPN'), (',', 'PUNCT'), ('Inc.', 'PROPN'), (',', 'PUNCT'), ('48', 'NUM'), ('North', 'PROPN'), ('Pleasant', 'ADJ'), ('St.', 'PROPN'), ('Unit', 'PROPN'), ('301', 'NUM'), (',', 'PUNCT'), ('Amherst', 'PROPN'), ('MA', 'PROPN'), ('01002', 'NUM'), ('USA', 'PROPN'), ('|', 'PUNCT'), ('1-800-377-8036', 'NUM'), ('|', 'PUNCT'), ('www.lexalytics.com', 'X')] 

 XPOS tags are: 
>> [('12', 'LS'), ('|', 'NFP'), ('|', 'NFP'), ('Lexalytics', 'NNP'), (',', ','), ('Inc.', 'NNP'), (',', ','), ('48', 'CD'), ('North', 'NNP'), ('Pleasant', 'NNP'), ('St.', 'NNP'), ('Unit', 'NNP'), ('301', 'CD'), (',', ','), ('Amherst', 'NNP'), ('MA', 'NNP'), ('01002', 'CD'), ('USA', 'NNP'), ('|', 'NFP'), ('1-800-377-8036', 'CD'), ('|', 'NFP'), ('www.lexalytics.com', 'ADD')] 

 Lemmas are: 
>> [('12', '12'), ('|', '|'), ('|', '|'), ('Lexalytics', 'Lexalytics'), (',', ','), ('Inc.', 'Inc.'), (',', ','), ('48', '48'), ('North', 'North'), ('Pleasant', 'Pleasant'), ('St.', 'St.'), ('Unit', 'unit'), ('301', '301'), (',', ','), ('Amherst', 'Amherst'), ('MA', 'MA'), ('01002', '01002'), ('USA', 'USA'), ('|', '|'), ('1-800-377-8036', '1-800-377-8036'), ('|', '|'), ('www.lexalytics.com', 'www.lexalytics.com')] 

 Dependency tags are: 
>> [(('12', 'Inc.'), 'nummod'), (('|', '12'), 'punct'), (('|', '12'), 'punct'), (('Lexalytics', 'Inc.'), 'compound'), ((',', 'Inc.'), 'punct'), (('Inc.', 'root'), 'root'), ((',', 'Inc.'), 'punct'), (('48', 'St.'), 'nummod'), (('North', 'St.'), 'compound'), (('Pleasant', 'St.'), 'amod'), (('St.', 'Unit'), 'compound'), (('Unit', 'Inc.'), 'list'), (('301', 'Unit'), 'nummod'), ((',', 'Unit'), 'punct'), (('Amherst', 'MA'), 'appos'), (('MA', 'Inc.'), 'list'), (('01002', 'USA'), 'nummod'), (('USA', 'MA'), 'appos'), (('|', 'USA'), 'punct'), (('1-800-377-8036', 'Inc.'), 'list'), (('|', '1-800-377-8036'), 'punct'), (('www.lexalytics.com', 'Inc.'), 'list')]

 Named Entites are: 
>> [('12|       |   Lexalytics, Inc.', 'ORG'), ('301', 'CARDINAL'), ('Amherst', 'GPE')]

================================ Paragraph 159 =================================

T U N E  F I R S T ,  T H E N  T R A I N :   E F F I C I E N C Y  B E F O R E  C O M P L E X I T Y  We have a whole white paper devoted to this discussion, but let’s review   the key points. We talked above about how machine learning is really  machine teaching, and how changing how a model interprets something  means having to convince it to do that. To achieve this, you have to have   data, and enough of it, that supports the changes needed to make the  model behave differently. 


------------------- Sentence 1 -------------------

 T U N E  F I R S T ,  T H E N  T R A I N :   E F F I C I E N C Y  B E F O R E  C O M P L E X I T Y 

Tokens are: 
>> ['T', 'U', 'N', 'E', 'F', 'I', 'R', 'S', 'T', ',', 'T', 'H', 'E', 'N', 'T', 'R', 'A', 'I', 'N', ':', 'E', 'F', 'F', 'I', 'C', 'I', 'E', 'N', 'C', 'Y', 'B', 'E', 'F', 'O', 'R', 'E', 'C', 'O', 'M', 'P', 'L', 'E', 'X', 'I', 'T', 'Y'] 

 UPOS tags are: 
>> [('T', 'PRON'), ('U', 'PRON'), ('N', 'PRON'), ('E', 'PRON'), ('F', 'PRON'), ('I', 'PRON'), ('R', 'AUX'), ('S', 'DET'), ('T', 'PRON'), (',', 'PUNCT'), ('T', 'PRON'), ('H', 'PUNCT'), ('E', 'NOUN'), ('N', 'PRON'), ('T', 'PRON'), ('R', 'AUX'), ('A', 'NOUN'), ('I', 'PRON'), ('N', 'NOUN'), (':', 'PUNCT'), ('E', 'PRON'), ('F', 'PRON'), ('F', 'PRON'), ('I', 'PRON'), ('C', 'PUNCT'), ('I', 'PRON'), ('E', 'NOUN'), ('N', 'NOUN'), ('C', 'NOUN'), ('Y', 'NOUN'), ('B', 'NOUN'), ('E', 'NOUN'), ('F', 'NOUN'), ('O', 'PUNCT'), ('R', 'AUX'), ('E', 'NOUN'), ('C', 'NOUN'), ('O', 'PUNCT'), ('M', 'NOUN'), ('P', 'NOUN'), ('L', 'PUNCT'), ('E', 'NOUN'), ('X', 'PUNCT'), ('I', 'NOUN'), ('T', 'NOUN'), ('Y', 'PUNCT')] 

 XPOS tags are: 
>> [('T', 'PRP'), ('U', 'PRP'), ('N', 'PRP'), ('E', 'PRP'), ('F', 'PRP'), ('I', 'PRP'), ('R', 'VBP'), ('S', 'DT'), ('T', 'PRP'), (',', ','), ('T', 'PRP'), ('H', ','), ('E', 'NN'), ('N', 'PRP'), ('T', 'PRP'), ('R', 'VBP'), ('A', 'NN'), ('I', 'PRP'), ('N', 'NN'), (':', ':'), ('E', 'PRP'), ('F', 'PRP'), ('F', 'PRP'), ('I', 'PRP'), ('C', ','), ('I', 'PRP'), ('E', 'NN'), ('N', 'NN'), ('C', 'NN'), ('Y', 'NN'), ('B', 'NN'), ('E', 'NN'), ('F', 'NN'), ('O', ','), ('R', 'VBZ'), ('E', 'NN'), ('C', 'NN'), ('O', ','), ('M', 'NN'), ('P', 'NN'), ('L', ','), ('E', 'NN'), ('X', ','), ('I', 'NN'), ('T', 'NN'), ('Y', '.')] 

 Lemmas are: 
>> [('T', 'T'), ('U', 'you'), ('N', 'N'), ('E', 'E'), ('F', 'F'), ('I', 'I'), ('R', 'R'), ('S', 'S'), ('T', 'T'), (',', ','), ('T', 'T'), ('H', 'H'), ('E', 'e'), ('N', 'N'), ('T', 'T'), ('R', 'R'), ('A', 'a'), ('I', 'I'), ('N', 'N'), (':', ':'), ('E', 'E'), ('F', 'F'), ('F', 'F'), ('I', 'I'), ('C', 'C'), ('I', 'I'), ('E', 'e'), ('N', 'N'), ('C', 'c'), ('Y', 'Y'), ('B', 'b'), ('E', 'e'), ('F', 'f'), ('O', 'o'), ('R', 'R'), ('E', 'e'), ('C', 'c'), ('O', 'o'), ('M', 'm'), ('P', 'p'), ('L', 'L'), ('E', 'e'), ('X', 'X'), ('I', 'I'), ('T', 'T'), ('Y', 'Y')] 

 Dependency tags are: 
>> [(('T', 'R'), 'punct'), (('U', 'R'), 'nsubj'), (('N', 'R'), 'nsubj'), (('E', 'R'), 'punct'), (('F', 'R'), 'punct'), (('I', 'R'), 'nsubj'), (('R', 'root'), 'root'), (('S', 'T'), 'det'), (('T', 'R'), 'obj'), ((',', 'E'), 'punct'), (('T', 'E'), 'nsubj'), (('H', 'E'), 'punct'), (('E', 'R'), 'conj'), (('N', 'N'), 'punct'), (('T', 'N'), 'nsubj'), (('R', 'N'), 'aux'), (('A', 'N'), 'det'), (('I', 'N'), 'nsubj'), (('N', 'E'), 'ccomp'), ((':', 'N'), 'punct'), (('E', 'N'), 'punct'), (('F', 'N'), 'punct'), (('F', 'I'), 'nsubj'), (('I', 'N'), 'parataxis'), (('C', 'E'), 'punct'), (('I', 'E'), 'nsubj'), (('E', 'R'), 'parataxis'), (('N', 'C'), 'det'), (('C', 'E'), 'obj'), (('Y', 'B'), 'case'), (('B', 'C'), 'obj'), (('E', 'F'), 'case'), (('F', 'B'), 'obj'), (('O', 'E'), 'punct'), (('R', 'E'), 'det'), (('E', 'F'), 'case'), (('C', 'E'), 'obj'), (('O', 'E'), 'punct'), (('M', 'P'), 'compound'), (('P', 'C'), 'appos'), (('L', 'P'), 'punct'), (('E', 'P'), 'appos'), (('X', 'I'), 'punct'), (('I', 'E'), 'appos'), (('T', 'I'), 'flat'), (('Y', 'R'), 'punct')]

 Named Entites are: 
>> []

------------------- Sentence 2 -------------------

 We have a whole white paper devoted to this discussion, but let’s review   the key points. 

Tokens are: 
>> ['We', 'have', 'a', 'whole', 'white', 'paper', 'devoted', 'to', 'this', 'discussion', ',', 'but', 'let', '’s', 'review', 'the', 'key', 'points', '.'] 

 UPOS tags are: 
>> [('We', 'PRON'), ('have', 'VERB'), ('a', 'DET'), ('whole', 'ADJ'), ('white', 'ADJ'), ('paper', 'NOUN'), ('devoted', 'VERB'), ('to', 'ADP'), ('this', 'DET'), ('discussion', 'NOUN'), (',', 'PUNCT'), ('but', 'CCONJ'), ('let', 'VERB'), ('’s', 'PRON'), ('review', 'VERB'), ('the', 'DET'), ('key', 'ADJ'), ('points', 'NOUN'), ('.', 'PUNCT')] 

 XPOS tags are: 
>> [('We', 'PRP'), ('have', 'VBP'), ('a', 'DT'), ('whole', 'JJ'), ('white', 'JJ'), ('paper', 'NN'), ('devoted', 'VBN'), ('to', 'IN'), ('this', 'DT'), ('discussion', 'NN'), (',', ','), ('but', 'CC'), ('let', 'VB'), ('’s', 'PRP'), ('review', 'VB'), ('the', 'DT'), ('key', 'JJ'), ('points', 'NNS'), ('.', '.')] 

 Lemmas are: 
>> [('We', 'we'), ('have', 'have'), ('a', 'a'), ('whole', 'whole'), ('white', 'white'), ('paper', 'paper'), ('devoted', 'devote'), ('to', 'to'), ('this', 'this'), ('discussion', 'discussion'), (',', ','), ('but', 'but'), ('let', 'let'), ('’s', 'us'), ('review', 'review'), ('the', 'the'), ('key', 'key'), ('points', 'point'), ('.', '.')] 

 Dependency tags are: 
>> [(('We', 'have'), 'nsubj'), (('have', 'root'), 'root'), (('a', 'paper'), 'det'), (('whole', 'paper'), 'amod'), (('white', 'paper'), 'amod'), (('paper', 'have'), 'obj'), (('devoted', 'paper'), 'acl'), (('to', 'discussion'), 'case'), (('this', 'discussion'), 'det'), (('discussion', 'devoted'), 'obl'), ((',', 'let'), 'punct'), (('but', 'let'), 'cc'), (('let', 'have'), 'conj'), (('’s', 'let'), 'obj'), (('review', 'let'), 'xcomp'), (('the', 'points'), 'det'), (('key', 'points'), 'amod'), (('points', 'review'), 'obj'), (('.', 'have'), 'punct')]

 Named Entites are: 
>> []

------------------- Sentence 3 -------------------

 We talked above about how machine learning is really  machine teaching, and how changing how a model interprets something  means having to convince it to do that. 

Tokens are: 
>> ['We', 'talked', 'above', 'about', 'how', 'machine', 'learning', 'is', 'really', 'machine', 'teaching', ',', 'and', 'how', 'changing', 'how', 'a', 'model', 'interprets', 'something', 'means', 'having', 'to', 'convince', 'it', 'to', 'do', 'that', '.'] 

 UPOS tags are: 
>> [('We', 'PRON'), ('talked', 'VERB'), ('above', 'ADV'), ('about', 'SCONJ'), ('how', 'SCONJ'), ('machine', 'NOUN'), ('learning', 'NOUN'), ('is', 'AUX'), ('really', 'ADV'), ('machine', 'NOUN'), ('teaching', 'NOUN'), (',', 'PUNCT'), ('and', 'CCONJ'), ('how', 'SCONJ'), ('changing', 'VERB'), ('how', 'SCONJ'), ('a', 'DET'), ('model', 'NOUN'), ('interprets', 'VERB'), ('something', 'PRON'), ('means', 'VERB'), ('having', 'VERB'), ('to', 'PART'), ('convince', 'VERB'), ('it', 'PRON'), ('to', 'PART'), ('do', 'VERB'), ('that', 'PRON'), ('.', 'PUNCT')] 

 XPOS tags are: 
>> [('We', 'PRP'), ('talked', 'VBD'), ('above', 'RB'), ('about', 'IN'), ('how', 'WRB'), ('machine', 'NN'), ('learning', 'NN'), ('is', 'VBZ'), ('really', 'RB'), ('machine', 'NN'), ('teaching', 'NN'), (',', ','), ('and', 'CC'), ('how', 'WRB'), ('changing', 'VBG'), ('how', 'WRB'), ('a', 'DT'), ('model', 'NN'), ('interprets', 'VBZ'), ('something', 'NN'), ('means', 'VBZ'), ('having', 'VBG'), ('to', 'TO'), ('convince', 'VB'), ('it', 'PRP'), ('to', 'TO'), ('do', 'VB'), ('that', 'DT'), ('.', '.')] 

 Lemmas are: 
>> [('We', 'we'), ('talked', 'talk'), ('above', 'above'), ('about', 'about'), ('how', 'how'), ('machine', 'machine'), ('learning', 'learning'), ('is', 'be'), ('really', 'really'), ('machine', 'machine'), ('teaching', 'teaching'), (',', ','), ('and', 'and'), ('how', 'how'), ('changing', 'change'), ('how', 'how'), ('a', 'a'), ('model', 'model'), ('interprets', 'interpret'), ('something', 'something'), ('means', 'mean'), ('having', 'have'), ('to', 'to'), ('convince', 'convince'), ('it', 'it'), ('to', 'to'), ('do', 'do'), ('that', 'that'), ('.', '.')] 

 Dependency tags are: 
>> [(('We', 'talked'), 'nsubj'), (('talked', 'root'), 'root'), (('above', 'talked'), 'advmod'), (('about', 'teaching'), 'mark'), (('how', 'teaching'), 'mark'), (('machine', 'learning'), 'compound'), (('learning', 'teaching'), 'nsubj'), (('is', 'teaching'), 'cop'), (('really', 'teaching'), 'advmod'), (('machine', 'teaching'), 'compound'), (('teaching', 'talked'), 'advcl'), ((',', 'means'), 'punct'), (('and', 'means'), 'cc'), (('how', 'changing'), 'mark'), (('changing', 'means'), 'csubj'), (('how', 'interprets'), 'mark'), (('a', 'model'), 'det'), (('model', 'interprets'), 'nsubj'), (('interprets', 'changing'), 'ccomp'), (('something', 'interprets'), 'obj'), (('means', 'talked'), 'conj'), (('having', 'means'), 'xcomp'), (('to', 'convince'), 'mark'), (('convince', 'having'), 'xcomp'), (('it', 'convince'), 'obj'), (('to', 'do'), 'mark'), (('do', 'convince'), 'xcomp'), (('that', 'do'), 'obj'), (('.', 'talked'), 'punct')]

 Named Entites are: 
>> []

------------------- Sentence 4 -------------------

 To achieve this, you have to have   data, and enough of it, that supports the changes needed to make the  model behave differently. 

Tokens are: 
>> ['To', 'achieve', 'this', ',', 'you', 'have', 'to', 'have', 'data', ',', 'and', 'enough', 'of', 'it', ',', 'that', 'supports', 'the', 'changes', 'needed', 'to', 'make', 'the', 'model', 'behave', 'differently', '.'] 

 UPOS tags are: 
>> [('To', 'PART'), ('achieve', 'VERB'), ('this', 'PRON'), (',', 'PUNCT'), ('you', 'PRON'), ('have', 'VERB'), ('to', 'PART'), ('have', 'VERB'), ('data', 'NOUN'), (',', 'PUNCT'), ('and', 'CCONJ'), ('enough', 'ADJ'), ('of', 'ADP'), ('it', 'PRON'), (',', 'PUNCT'), ('that', 'PRON'), ('supports', 'VERB'), ('the', 'DET'), ('changes', 'NOUN'), ('needed', 'VERB'), ('to', 'PART'), ('make', 'VERB'), ('the', 'DET'), ('model', 'NOUN'), ('behave', 'VERB'), ('differently', 'ADV'), ('.', 'PUNCT')] 

 XPOS tags are: 
>> [('To', 'TO'), ('achieve', 'VB'), ('this', 'DT'), (',', ','), ('you', 'PRP'), ('have', 'VBP'), ('to', 'TO'), ('have', 'VB'), ('data', 'NN'), (',', ','), ('and', 'CC'), ('enough', 'JJ'), ('of', 'IN'), ('it', 'PRP'), (',', ','), ('that', 'DT'), ('supports', 'VBZ'), ('the', 'DT'), ('changes', 'NNS'), ('needed', 'VBN'), ('to', 'TO'), ('make', 'VB'), ('the', 'DT'), ('model', 'NN'), ('behave', 'VB'), ('differently', 'RB'), ('.', '.')] 

 Lemmas are: 
>> [('To', 'to'), ('achieve', 'achieve'), ('this', 'this'), (',', ','), ('you', 'you'), ('have', 'have'), ('to', 'to'), ('have', 'have'), ('data', 'datum'), (',', ','), ('and', 'and'), ('enough', 'enough'), ('of', 'of'), ('it', 'it'), (',', ','), ('that', 'that'), ('supports', 'support'), ('the', 'the'), ('changes', 'change'), ('needed', 'need'), ('to', 'to'), ('make', 'make'), ('the', 'the'), ('model', 'model'), ('behave', 'behave'), ('differently', 'differently'), ('.', '.')] 

 Dependency tags are: 
>> [(('To', 'achieve'), 'mark'), (('achieve', 'have'), 'advcl'), (('this', 'achieve'), 'obj'), ((',', 'have'), 'punct'), (('you', 'have'), 'nsubj'), (('have', 'root'), 'root'), (('to', 'have'), 'mark'), (('have', 'have'), 'xcomp'), (('data', 'have'), 'obj'), ((',', 'supports'), 'punct'), (('and', 'supports'), 'cc'), (('enough', 'supports'), 'obl:tmod'), (('of', 'it'), 'case'), (('it', 'enough'), 'nmod'), ((',', 'supports'), 'punct'), (('that', 'supports'), 'nsubj'), (('supports', 'have'), 'conj'), (('the', 'changes'), 'det'), (('changes', 'supports'), 'obj'), (('needed', 'changes'), 'acl'), (('to', 'make'), 'mark'), (('make', 'needed'), 'xcomp'), (('the', 'model'), 'det'), (('model', 'make'), 'obj'), (('behave', 'make'), 'xcomp'), (('differently', 'behave'), 'advmod'), (('.', 'have'), 'punct')]

 Named Entites are: 
>> []

================================ Paragraph 160 =================================

This is different than tuning. Tuning is a type of written instruction. With  tuning, you might tell a model that the airport term “gate change” carries   


------------------- Sentence 1 -------------------

 This is different than tuning. 

Tokens are: 
>> ['This', 'is', 'different', 'than', 'tuning', '.'] 

 UPOS tags are: 
>> [('This', 'PRON'), ('is', 'AUX'), ('different', 'ADJ'), ('than', 'ADP'), ('tuning', 'NOUN'), ('.', 'PUNCT')] 

 XPOS tags are: 
>> [('This', 'DT'), ('is', 'VBZ'), ('different', 'JJ'), ('than', 'IN'), ('tuning', 'NN'), ('.', '.')] 

 Lemmas are: 
>> [('This', 'this'), ('is', 'be'), ('different', 'different'), ('than', 'than'), ('tuning', 'tuning'), ('.', '.')] 

 Dependency tags are: 
>> [(('This', 'different'), 'nsubj'), (('is', 'different'), 'cop'), (('different', 'root'), 'root'), (('than', 'tuning'), 'case'), (('tuning', 'different'), 'obl'), (('.', 'different'), 'punct')]

 Named Entites are: 
>> []

------------------- Sentence 2 -------------------

 Tuning is a type of written instruction. 

Tokens are: 
>> ['Tuning', 'is', 'a', 'type', 'of', 'written', 'instruction', '.'] 

 UPOS tags are: 
>> [('Tuning', 'NOUN'), ('is', 'AUX'), ('a', 'DET'), ('type', 'NOUN'), ('of', 'ADP'), ('written', 'VERB'), ('instruction', 'NOUN'), ('.', 'PUNCT')] 

 XPOS tags are: 
>> [('Tuning', 'NN'), ('is', 'VBZ'), ('a', 'DT'), ('type', 'NN'), ('of', 'IN'), ('written', 'VBN'), ('instruction', 'NN'), ('.', '.')] 

 Lemmas are: 
>> [('Tuning', 'tuning'), ('is', 'be'), ('a', 'a'), ('type', 'type'), ('of', 'of'), ('written', 'write'), ('instruction', 'instruction'), ('.', '.')] 

 Dependency tags are: 
>> [(('Tuning', 'type'), 'nsubj'), (('is', 'type'), 'cop'), (('a', 'type'), 'det'), (('type', 'root'), 'root'), (('of', 'instruction'), 'case'), (('written', 'instruction'), 'amod'), (('instruction', 'type'), 'nmod'), (('.', 'type'), 'punct')]

 Named Entites are: 
>> []

------------------- Sentence 3 -------------------

 With  tuning, you might tell a model that the airport term “gate change” carries 

Tokens are: 
>> ['With', 'tuning', ',', 'you', 'might', 'tell', 'a', 'model', 'that', 'the', 'airport', 'term', '“', 'gate', 'change', '”', 'carries'] 

 UPOS tags are: 
>> [('With', 'ADP'), ('tuning', 'NOUN'), (',', 'PUNCT'), ('you', 'PRON'), ('might', 'AUX'), ('tell', 'VERB'), ('a', 'DET'), ('model', 'NOUN'), ('that', 'PRON'), ('the', 'DET'), ('airport', 'NOUN'), ('term', 'NOUN'), ('“', 'PUNCT'), ('gate', 'NOUN'), ('change', 'NOUN'), ('”', 'PUNCT'), ('carries', 'VERB')] 

 XPOS tags are: 
>> [('With', 'IN'), ('tuning', 'NN'), (',', ','), ('you', 'PRP'), ('might', 'MD'), ('tell', 'VB'), ('a', 'DT'), ('model', 'NN'), ('that', 'WDT'), ('the', 'DT'), ('airport', 'NN'), ('term', 'NN'), ('“', '``'), ('gate', 'NN'), ('change', 'NN'), ('”', "''"), ('carries', 'VBZ')] 

 Lemmas are: 
>> [('With', 'with'), ('tuning', 'tuning'), (',', ','), ('you', 'you'), ('might', 'might'), ('tell', 'tell'), ('a', 'a'), ('model', 'model'), ('that', 'that'), ('the', 'the'), ('airport', 'airport'), ('term', 'term'), ('“', "''"), ('gate', 'gate'), ('change', 'change'), ('”', "''"), ('carries', 'carry')] 

 Dependency tags are: 
>> [(('With', 'tuning'), 'case'), (('tuning', 'tell'), 'obl'), ((',', 'tell'), 'punct'), (('you', 'tell'), 'nsubj'), (('might', 'tell'), 'aux'), (('tell', 'root'), 'root'), (('a', 'model'), 'det'), (('model', 'tell'), 'obj'), (('that', 'carries'), 'obj'), (('the', 'term'), 'det'), (('airport', 'term'), 'compound'), (('term', 'carries'), 'nsubj'), (('“', 'change'), 'punct'), (('gate', 'change'), 'compound'), (('change', 'term'), 'appos'), (('”', 'change'), 'punct'), (('carries', 'model'), 'acl:relcl')]

 Named Entites are: 
>> []

================================ Paragraph 161 =================================

-0.5 sentiment points, and that this value should be used every time the  model sees the phrase. This new command will instantly apply to everything  that matches the entry. Training, on the other hand, requires the model  to parse a significant amount of data before it starts to apply (“learn”) the  change. Additionally, the more the model “wants” to score something a  particular way, the more that you’re going to have to work to change it.   Old habits are hard to unlearn for machine learning systems, too. 


------------------- Sentence 1 -------------------

 -0.5 sentiment points, and that this value should be used every time the  model sees the phrase. 

Tokens are: 
>> ['-0.5', 'sentiment', 'points', ',', 'and', 'that', 'this', 'value', 'should', 'be', 'used', 'every', 'time', 'the', 'model', 'sees', 'the', 'phrase', '.'] 

 UPOS tags are: 
>> [('-0.5', 'NUM'), ('sentiment', 'NOUN'), ('points', 'NOUN'), (',', 'PUNCT'), ('and', 'CCONJ'), ('that', 'SCONJ'), ('this', 'DET'), ('value', 'NOUN'), ('should', 'AUX'), ('be', 'AUX'), ('used', 'VERB'), ('every', 'DET'), ('time', 'NOUN'), ('the', 'DET'), ('model', 'NOUN'), ('sees', 'VERB'), ('the', 'DET'), ('phrase', 'NOUN'), ('.', 'PUNCT')] 

 XPOS tags are: 
>> [('-0.5', 'CD'), ('sentiment', 'NN'), ('points', 'NNS'), (',', ','), ('and', 'CC'), ('that', 'IN'), ('this', 'DT'), ('value', 'NN'), ('should', 'MD'), ('be', 'VB'), ('used', 'VBN'), ('every', 'DT'), ('time', 'NN'), ('the', 'DT'), ('model', 'NN'), ('sees', 'VBZ'), ('the', 'DT'), ('phrase', 'NN'), ('.', '.')] 

 Lemmas are: 
>> [('-0.5', '-0.5'), ('sentiment', 'sentiment'), ('points', 'point'), (',', ','), ('and', 'and'), ('that', 'that'), ('this', 'this'), ('value', 'value'), ('should', 'should'), ('be', 'be'), ('used', 'use'), ('every', 'every'), ('time', 'time'), ('the', 'the'), ('model', 'model'), ('sees', 'see'), ('the', 'the'), ('phrase', 'phrase'), ('.', '.')] 

 Dependency tags are: 
>> [(('-0.5', 'points'), 'nummod'), (('sentiment', 'points'), 'compound'), (('points', 'root'), 'root'), ((',', 'used'), 'punct'), (('and', 'used'), 'cc'), (('that', 'used'), 'mark'), (('this', 'value'), 'det'), (('value', 'used'), 'nsubj:pass'), (('should', 'used'), 'aux'), (('be', 'used'), 'aux:pass'), (('used', 'points'), 'conj'), (('every', 'time'), 'det'), (('time', 'used'), 'obl:tmod'), (('the', 'model'), 'det'), (('model', 'sees'), 'nsubj'), (('sees', 'time'), 'acl:relcl'), (('the', 'phrase'), 'det'), (('phrase', 'sees'), 'obj'), (('.', 'points'), 'punct')]

 Named Entites are: 
>> [('-0.5', 'CARDINAL')]

------------------- Sentence 2 -------------------

 This new command will instantly apply to everything  that matches the entry. 

Tokens are: 
>> ['This', 'new', 'command', 'will', 'instantly', 'apply', 'to', 'everything', 'that', 'matches', 'the', 'entry', '.'] 

 UPOS tags are: 
>> [('This', 'DET'), ('new', 'ADJ'), ('command', 'NOUN'), ('will', 'AUX'), ('instantly', 'ADV'), ('apply', 'VERB'), ('to', 'ADP'), ('everything', 'PRON'), ('that', 'PRON'), ('matches', 'VERB'), ('the', 'DET'), ('entry', 'NOUN'), ('.', 'PUNCT')] 

 XPOS tags are: 
>> [('This', 'DT'), ('new', 'JJ'), ('command', 'NN'), ('will', 'MD'), ('instantly', 'RB'), ('apply', 'VB'), ('to', 'IN'), ('everything', 'NN'), ('that', 'WDT'), ('matches', 'VBZ'), ('the', 'DT'), ('entry', 'NN'), ('.', '.')] 

 Lemmas are: 
>> [('This', 'this'), ('new', 'new'), ('command', 'command'), ('will', 'will'), ('instantly', 'instantly'), ('apply', 'apply'), ('to', 'to'), ('everything', 'everything'), ('that', 'that'), ('matches', 'match'), ('the', 'the'), ('entry', 'entry'), ('.', '.')] 

 Dependency tags are: 
>> [(('This', 'command'), 'det'), (('new', 'command'), 'amod'), (('command', 'apply'), 'nsubj'), (('will', 'apply'), 'aux'), (('instantly', 'apply'), 'advmod'), (('apply', 'root'), 'root'), (('to', 'everything'), 'case'), (('everything', 'apply'), 'obl'), (('that', 'matches'), 'nsubj'), (('matches', 'everything'), 'acl:relcl'), (('the', 'entry'), 'det'), (('entry', 'matches'), 'obj'), (('.', 'apply'), 'punct')]

 Named Entites are: 
>> []

------------------- Sentence 3 -------------------

 Training, on the other hand, requires the model  to parse a significant amount of data before it starts to apply (“learn”) the  change. 

Tokens are: 
>> ['Training', ',', 'on', 'the', 'other', 'hand', ',', 'requires', 'the', 'model', 'to', 'parse', 'a', 'significant', 'amount', 'of', 'data', 'before', 'it', 'starts', 'to', 'apply', '(', '“', 'learn', '”', ')', 'the', 'change', '.'] 

 UPOS tags are: 
>> [('Training', 'NOUN'), (',', 'PUNCT'), ('on', 'ADP'), ('the', 'DET'), ('other', 'ADJ'), ('hand', 'NOUN'), (',', 'PUNCT'), ('requires', 'VERB'), ('the', 'DET'), ('model', 'NOUN'), ('to', 'PART'), ('parse', 'VERB'), ('a', 'DET'), ('significant', 'ADJ'), ('amount', 'NOUN'), ('of', 'ADP'), ('data', 'NOUN'), ('before', 'SCONJ'), ('it', 'PRON'), ('starts', 'VERB'), ('to', 'PART'), ('apply', 'VERB'), ('(', 'PUNCT'), ('“', 'PUNCT'), ('learn', 'VERB'), ('”', 'PUNCT'), (')', 'PUNCT'), ('the', 'DET'), ('change', 'NOUN'), ('.', 'PUNCT')] 

 XPOS tags are: 
>> [('Training', 'NN'), (',', ','), ('on', 'IN'), ('the', 'DT'), ('other', 'JJ'), ('hand', 'NN'), (',', ','), ('requires', 'VBZ'), ('the', 'DT'), ('model', 'NN'), ('to', 'TO'), ('parse', 'VB'), ('a', 'DT'), ('significant', 'JJ'), ('amount', 'NN'), ('of', 'IN'), ('data', 'NNS'), ('before', 'IN'), ('it', 'PRP'), ('starts', 'VBZ'), ('to', 'TO'), ('apply', 'VB'), ('(', '-LRB-'), ('“', '``'), ('learn', 'VB'), ('”', "''"), (')', '-RRB-'), ('the', 'DT'), ('change', 'NN'), ('.', '.')] 

 Lemmas are: 
>> [('Training', 'training'), (',', ','), ('on', 'on'), ('the', 'the'), ('other', 'other'), ('hand', 'hand'), (',', ','), ('requires', 'require'), ('the', 'the'), ('model', 'model'), ('to', 'to'), ('parse', 'parse'), ('a', 'a'), ('significant', 'significant'), ('amount', 'amount'), ('of', 'of'), ('data', 'datum'), ('before', 'before'), ('it', 'it'), ('starts', 'start'), ('to', 'to'), ('apply', 'apply'), ('(', '('), ('“', "''"), ('learn', 'learn'), ('”', "''"), (')', ')'), ('the', 'the'), ('change', 'change'), ('.', '.')] 

 Dependency tags are: 
>> [(('Training', 'requires'), 'nsubj'), ((',', 'Training'), 'punct'), (('on', 'hand'), 'case'), (('the', 'hand'), 'det'), (('other', 'hand'), 'amod'), (('hand', 'requires'), 'obl'), ((',', 'requires'), 'punct'), (('requires', 'root'), 'root'), (('the', 'model'), 'det'), (('model', 'requires'), 'obj'), (('to', 'parse'), 'mark'), (('parse', 'requires'), 'xcomp'), (('a', 'amount'), 'det'), (('significant', 'amount'), 'amod'), (('amount', 'parse'), 'obj'), (('of', 'data'), 'case'), (('data', 'amount'), 'nmod'), (('before', 'starts'), 'mark'), (('it', 'starts'), 'nsubj'), (('starts', 'parse'), 'advcl'), (('to', 'apply'), 'mark'), (('apply', 'starts'), 'xcomp'), (('(', 'learn'), 'punct'), (('“', 'learn'), 'punct'), (('learn', 'apply'), 'parataxis'), (('”', 'learn'), 'punct'), ((')', 'learn'), 'punct'), (('the', 'change'), 'det'), (('change', 'apply'), 'obj'), (('.', 'requires'), 'punct')]

 Named Entites are: 
>> []

------------------- Sentence 4 -------------------

 Additionally, the more the model “wants” to score something a  particular way, the more that you’re going to have to work to change it. 

Tokens are: 
>> ['Additionally', ',', 'the', 'more', 'the', 'model', '“', 'wants', '”', 'to', 'score', 'something', 'a', 'particular', 'way', ',', 'the', 'more', 'that', 'you', '’re', 'going', 'to', 'have', 'to', 'work', 'to', 'change', 'it', '.'] 

 UPOS tags are: 
>> [('Additionally', 'ADV'), (',', 'PUNCT'), ('the', 'DET'), ('more', 'ADV'), ('the', 'DET'), ('model', 'NOUN'), ('“', 'PUNCT'), ('wants', 'VERB'), ('”', 'PUNCT'), ('to', 'PART'), ('score', 'VERB'), ('something', 'PRON'), ('a', 'DET'), ('particular', 'ADJ'), ('way', 'NOUN'), (',', 'PUNCT'), ('the', 'DET'), ('more', 'ADJ'), ('that', 'PRON'), ('you', 'PRON'), ('’re', 'AUX'), ('going', 'VERB'), ('to', 'PART'), ('have', 'VERB'), ('to', 'PART'), ('work', 'VERB'), ('to', 'PART'), ('change', 'VERB'), ('it', 'PRON'), ('.', 'PUNCT')] 

 XPOS tags are: 
>> [('Additionally', 'RB'), (',', ','), ('the', 'DT'), ('more', 'RBR'), ('the', 'DT'), ('model', 'NN'), ('“', '``'), ('wants', 'VBZ'), ('”', "''"), ('to', 'TO'), ('score', 'VB'), ('something', 'NN'), ('a', 'DT'), ('particular', 'JJ'), ('way', 'NN'), (',', ','), ('the', 'DT'), ('more', 'JJR'), ('that', 'WDT'), ('you', 'PRP'), ('’re', 'VBP'), ('going', 'VBG'), ('to', 'TO'), ('have', 'VB'), ('to', 'TO'), ('work', 'VB'), ('to', 'TO'), ('change', 'VB'), ('it', 'PRP'), ('.', '.')] 

 Lemmas are: 
>> [('Additionally', 'additionally'), (',', ','), ('the', 'the'), ('more', 'more'), ('the', 'the'), ('model', 'model'), ('“', "''"), ('wants', 'want'), ('”', "''"), ('to', 'to'), ('score', 'score'), ('something', 'something'), ('a', 'a'), ('particular', 'particular'), ('way', 'way'), (',', ','), ('the', 'the'), ('more', 'more'), ('that', 'that'), ('you', 'you'), ('’re', 'be'), ('going', 'go'), ('to', 'to'), ('have', 'have'), ('to', 'to'), ('work', 'work'), ('to', 'to'), ('change', 'change'), ('it', 'it'), ('.', '.')] 

 Dependency tags are: 
>> [(('Additionally', 'more'), 'advmod'), ((',', 'Additionally'), 'punct'), (('the', 'more'), 'det'), (('more', 'more'), 'advmod'), (('the', 'model'), 'det'), (('model', 'wants'), 'nsubj'), (('“', 'wants'), 'punct'), (('wants', 'more'), 'acl:relcl'), (('”', 'wants'), 'punct'), (('to', 'score'), 'mark'), (('score', 'wants'), 'xcomp'), (('something', 'score'), 'obj'), (('a', 'way'), 'det'), (('particular', 'way'), 'amod'), (('way', 'score'), 'obl:npmod'), ((',', 'more'), 'punct'), (('the', 'more'), 'det'), (('more', 'root'), 'root'), (('that', 'going'), 'obj'), (('you', 'going'), 'nsubj'), (('’re', 'going'), 'aux'), (('going', 'more'), 'acl:relcl'), (('to', 'have'), 'mark'), (('have', 'going'), 'xcomp'), (('to', 'work'), 'mark'), (('work', 'have'), 'xcomp'), (('to', 'change'), 'mark'), (('change', 'work'), 'advcl'), (('it', 'change'), 'obj'), (('.', 'more'), 'punct')]

 Named Entites are: 
>> []

------------------- Sentence 5 -------------------

 Old habits are hard to unlearn for machine learning systems, too. 

Tokens are: 
>> ['Old', 'habits', 'are', 'hard', 'to', 'unlearn', 'for', 'machine', 'learning', 'systems', ',', 'too', '.'] 

 UPOS tags are: 
>> [('Old', 'ADJ'), ('habits', 'NOUN'), ('are', 'AUX'), ('hard', 'ADJ'), ('to', 'PART'), ('unlearn', 'VERB'), ('for', 'ADP'), ('machine', 'NOUN'), ('learning', 'NOUN'), ('systems', 'NOUN'), (',', 'PUNCT'), ('too', 'ADV'), ('.', 'PUNCT')] 

 XPOS tags are: 
>> [('Old', 'JJ'), ('habits', 'NNS'), ('are', 'VBP'), ('hard', 'JJ'), ('to', 'TO'), ('unlearn', 'VB'), ('for', 'IN'), ('machine', 'NN'), ('learning', 'NN'), ('systems', 'NNS'), (',', ','), ('too', 'RB'), ('.', '.')] 

 Lemmas are: 
>> [('Old', 'Old'), ('habits', 'habit'), ('are', 'be'), ('hard', 'hard'), ('to', 'to'), ('unlearn', 'unlearn'), ('for', 'for'), ('machine', 'machine'), ('learning', 'learning'), ('systems', 'system'), (',', ','), ('too', 'too'), ('.', '.')] 

 Dependency tags are: 
>> [(('Old', 'habits'), 'amod'), (('habits', 'hard'), 'nsubj'), (('are', 'hard'), 'cop'), (('hard', 'root'), 'root'), (('to', 'unlearn'), 'mark'), (('unlearn', 'hard'), 'xcomp'), (('for', 'systems'), 'case'), (('machine', 'systems'), 'compound'), (('learning', 'systems'), 'compound'), (('systems', 'unlearn'), 'obl'), ((',', 'hard'), 'punct'), (('too', 'hard'), 'advmod'), (('.', 'hard'), 'punct')]

 Named Entites are: 
>> []

================================ Paragraph 162 =================================

Assuming the right use case, tuning will always be faster.  But there are many cases when the use of a particular word    is so multifaceted or ambiguous that the number of tuning     rules we’d have to put into place is prohibitive. This is where       machine learning shines. Give the model enough examples,         and it figures out the rules for itself.


------------------- Sentence 1 -------------------

 Assuming the right use case, tuning will always be faster. 

Tokens are: 
>> ['Assuming', 'the', 'right', 'use', 'case', ',', 'tuning', 'will', 'always', 'be', 'faster', '.'] 

 UPOS tags are: 
>> [('Assuming', 'VERB'), ('the', 'DET'), ('right', 'ADJ'), ('use', 'NOUN'), ('case', 'NOUN'), (',', 'PUNCT'), ('tuning', 'NOUN'), ('will', 'AUX'), ('always', 'ADV'), ('be', 'AUX'), ('faster', 'ADJ'), ('.', 'PUNCT')] 

 XPOS tags are: 
>> [('Assuming', 'VBG'), ('the', 'DT'), ('right', 'JJ'), ('use', 'NN'), ('case', 'NN'), (',', ','), ('tuning', 'NN'), ('will', 'MD'), ('always', 'RB'), ('be', 'VB'), ('faster', 'JJR'), ('.', '.')] 

 Lemmas are: 
>> [('Assuming', 'assume'), ('the', 'the'), ('right', 'right'), ('use', 'use'), ('case', 'case'), (',', ','), ('tuning', 'tuning'), ('will', 'will'), ('always', 'always'), ('be', 'be'), ('faster', 'fast'), ('.', '.')] 

 Dependency tags are: 
>> [(('Assuming', 'faster'), 'advcl'), (('the', 'case'), 'det'), (('right', 'case'), 'amod'), (('use', 'case'), 'compound'), (('case', 'Assuming'), 'obj'), ((',', 'faster'), 'punct'), (('tuning', 'faster'), 'nsubj'), (('will', 'faster'), 'aux'), (('always', 'faster'), 'advmod'), (('be', 'faster'), 'cop'), (('faster', 'root'), 'root'), (('.', 'faster'), 'punct')]

 Named Entites are: 
>> []

------------------- Sentence 2 -------------------

 But there are many cases when the use of a particular word    is so multifaceted or ambiguous that the number of tuning     rules we’d have to put into place is prohibitive. 

Tokens are: 
>> ['But', 'there', 'are', 'many', 'cases', 'when', 'the', 'use', 'of', 'a', 'particular', 'word', 'is', 'so', 'multifaceted', 'or', 'ambiguous', 'that', 'the', 'number', 'of', 'tuning', 'rules', 'we', '’d', 'have', 'to', 'put', 'into', 'place', 'is', 'prohibitive', '.'] 

 UPOS tags are: 
>> [('But', 'CCONJ'), ('there', 'PRON'), ('are', 'VERB'), ('many', 'ADJ'), ('cases', 'NOUN'), ('when', 'SCONJ'), ('the', 'DET'), ('use', 'NOUN'), ('of', 'ADP'), ('a', 'DET'), ('particular', 'ADJ'), ('word', 'NOUN'), ('is', 'AUX'), ('so', 'ADV'), ('multifaceted', 'ADJ'), ('or', 'CCONJ'), ('ambiguous', 'ADJ'), ('that', 'SCONJ'), ('the', 'DET'), ('number', 'NOUN'), ('of', 'ADP'), ('tuning', 'NOUN'), ('rules', 'NOUN'), ('we', 'PRON'), ('’d', 'AUX'), ('have', 'VERB'), ('to', 'PART'), ('put', 'VERB'), ('into', 'ADP'), ('place', 'NOUN'), ('is', 'AUX'), ('prohibitive', 'ADJ'), ('.', 'PUNCT')] 

 XPOS tags are: 
>> [('But', 'CC'), ('there', 'EX'), ('are', 'VBP'), ('many', 'JJ'), ('cases', 'NNS'), ('when', 'WRB'), ('the', 'DT'), ('use', 'NN'), ('of', 'IN'), ('a', 'DT'), ('particular', 'JJ'), ('word', 'NN'), ('is', 'VBZ'), ('so', 'RB'), ('multifaceted', 'JJ'), ('or', 'CC'), ('ambiguous', 'JJ'), ('that', 'IN'), ('the', 'DT'), ('number', 'NN'), ('of', 'IN'), ('tuning', 'NN'), ('rules', 'NNS'), ('we', 'PRP'), ('’d', 'MD'), ('have', 'VB'), ('to', 'TO'), ('put', 'VB'), ('into', 'IN'), ('place', 'NN'), ('is', 'VBZ'), ('prohibitive', 'JJ'), ('.', '.')] 

 Lemmas are: 
>> [('But', 'but'), ('there', 'there'), ('are', 'be'), ('many', 'many'), ('cases', 'case'), ('when', 'when'), ('the', 'the'), ('use', 'use'), ('of', 'of'), ('a', 'a'), ('particular', 'particular'), ('word', 'word'), ('is', 'be'), ('so', 'so'), ('multifaceted', 'multifaceted'), ('or', 'or'), ('ambiguous', 'ambiguous'), ('that', 'that'), ('the', 'the'), ('number', 'number'), ('of', 'of'), ('tuning', 'tuning'), ('rules', 'rule'), ('we', 'we'), ('’d', 'have'), ('have', 'have'), ('to', 'to'), ('put', 'put'), ('into', 'into'), ('place', 'place'), ('is', 'be'), ('prohibitive', 'prohibitive'), ('.', '.')] 

 Dependency tags are: 
>> [(('But', 'are'), 'cc'), (('there', 'are'), 'expl'), (('are', 'root'), 'root'), (('many', 'cases'), 'amod'), (('cases', 'are'), 'nsubj'), (('when', 'multifaceted'), 'mark'), (('the', 'use'), 'det'), (('use', 'multifaceted'), 'nsubj'), (('of', 'word'), 'case'), (('a', 'word'), 'det'), (('particular', 'word'), 'amod'), (('word', 'use'), 'nmod'), (('is', 'multifaceted'), 'cop'), (('so', 'multifaceted'), 'advmod'), (('multifaceted', 'are'), 'advcl'), (('or', 'ambiguous'), 'cc'), (('ambiguous', 'multifaceted'), 'conj'), (('that', 'prohibitive'), 'mark'), (('the', 'number'), 'det'), (('number', 'prohibitive'), 'nsubj'), (('of', 'rules'), 'case'), (('tuning', 'rules'), 'compound'), (('rules', 'number'), 'nmod'), (('we', 'have'), 'nsubj'), (('’d', 'have'), 'aux'), (('have', 'rules'), 'acl:relcl'), (('to', 'put'), 'mark'), (('put', 'have'), 'xcomp'), (('into', 'place'), 'case'), (('place', 'put'), 'obl'), (('is', 'prohibitive'), 'cop'), (('prohibitive', 'multifaceted'), 'conj'), (('.', 'are'), 'punct')]

 Named Entites are: 
>> []

------------------- Sentence 3 -------------------

 This is where       machine learning shines. 

Tokens are: 
>> ['This', 'is', 'where', 'machine', 'learning', 'shines', '.'] 

 UPOS tags are: 
>> [('This', 'PRON'), ('is', 'AUX'), ('where', 'SCONJ'), ('machine', 'NOUN'), ('learning', 'NOUN'), ('shines', 'VERB'), ('.', 'PUNCT')] 

 XPOS tags are: 
>> [('This', 'DT'), ('is', 'VBZ'), ('where', 'WRB'), ('machine', 'NN'), ('learning', 'NN'), ('shines', 'VBZ'), ('.', '.')] 

 Lemmas are: 
>> [('This', 'this'), ('is', 'be'), ('where', 'where'), ('machine', 'machine'), ('learning', 'learning'), ('shines', 'shine'), ('.', '.')] 

 Dependency tags are: 
>> [(('This', 'where'), 'nsubj'), (('is', 'where'), 'cop'), (('where', 'root'), 'root'), (('machine', 'learning'), 'compound'), (('learning', 'shines'), 'nsubj'), (('shines', 'where'), 'acl:relcl'), (('.', 'where'), 'punct')]

 Named Entites are: 
>> []

------------------- Sentence 4 -------------------

 Give the model enough examples,         and it figures out the rules for itself. 

Tokens are: 
>> ['Give', 'the', 'model', 'enough', 'examples', ',', 'and', 'it', 'figures', 'out', 'the', 'rules', 'for', 'itself', '.'] 

 UPOS tags are: 
>> [('Give', 'VERB'), ('the', 'DET'), ('model', 'NOUN'), ('enough', 'ADJ'), ('examples', 'NOUN'), (',', 'PUNCT'), ('and', 'CCONJ'), ('it', 'PRON'), ('figures', 'VERB'), ('out', 'ADP'), ('the', 'DET'), ('rules', 'NOUN'), ('for', 'ADP'), ('itself', 'PRON'), ('.', 'PUNCT')] 

 XPOS tags are: 
>> [('Give', 'VB'), ('the', 'DT'), ('model', 'NN'), ('enough', 'JJ'), ('examples', 'NNS'), (',', ','), ('and', 'CC'), ('it', 'PRP'), ('figures', 'VBZ'), ('out', 'RP'), ('the', 'DT'), ('rules', 'NNS'), ('for', 'IN'), ('itself', 'PRP'), ('.', '.')] 

 Lemmas are: 
>> [('Give', 'give'), ('the', 'the'), ('model', 'model'), ('enough', 'enough'), ('examples', 'example'), (',', ','), ('and', 'and'), ('it', 'it'), ('figures', 'figure'), ('out', 'out'), ('the', 'the'), ('rules', 'rule'), ('for', 'for'), ('itself', 'itself'), ('.', '.')] 

 Dependency tags are: 
>> [(('Give', 'root'), 'root'), (('the', 'model'), 'det'), (('model', 'Give'), 'iobj'), (('enough', 'examples'), 'amod'), (('examples', 'Give'), 'obj'), ((',', 'figures'), 'punct'), (('and', 'figures'), 'cc'), (('it', 'figures'), 'nsubj'), (('figures', 'Give'), 'conj'), (('out', 'figures'), 'compound:prt'), (('the', 'rules'), 'det'), (('rules', 'figures'), 'obj'), (('for', 'itself'), 'case'), (('itself', 'rules'), 'nmod'), (('.', 'Give'), 'punct')]

 Named Entites are: 
>> []

================================ Paragraph 163 =================================

W H I T E  P A P E R 


------------------- Sentence 1 -------------------

 W H I T E  P A P E R 

Tokens are: 
>> ['W', 'H', 'I', 'T', 'E', 'P', 'A', 'P', 'E', 'R'] 

 UPOS tags are: 
>> [('W', 'PROPN'), ('H', 'PUNCT'), ('I', 'PRON'), ('T', 'AUX'), ('E', 'PROPN'), ('P', 'NOUN'), ('A', 'NOUN'), ('P', 'NOUN'), ('E', 'NOUN'), ('R', 'NOUN')] 

 XPOS tags are: 
>> [('W', 'NNP'), ('H', ','), ('I', 'PRP'), ('T', 'VBP'), ('E', 'NNP'), ('P', 'NN'), ('A', 'NN'), ('P', 'NN'), ('E', 'NN'), ('R', 'NN')] 

 Lemmas are: 
>> [('W', 'W'), ('H', 'H'), ('I', 'I'), ('T', 'T'), ('E', 'E'), ('P', 'p'), ('A', 'a'), ('P', 'p'), ('E', 'e'), ('R', 'R')] 

 Dependency tags are: 
>> [(('W', 'T'), 'vocative'), (('H', 'W'), 'punct'), (('I', 'T'), 'nsubj'), (('T', 'root'), 'root'), (('E', 'T'), 'obj'), (('P', 'T'), 'obj'), (('A', 'E'), 'compound'), (('P', 'E'), 'compound'), (('E', 'R'), 'compound'), (('R', 'T'), 'obj')]

 Named Entites are: 
>> []

================================ Paragraph 164 =================================

13|       |   Lexalytics, Inc., 48 North Pleasant St. Unit 301, Amherst MA 01002 USA   |   1-800-377-8036 |   www.lexalytics.com 


------------------- Sentence 1 -------------------

 13|       |   Lexalytics, Inc., 48 North Pleasant St. Unit 301, Amherst MA 01002 USA   |   1-800-377-8036 |   www.lexalytics.com 

Tokens are: 
>> ['13', '|', '|', 'Lexalytics', ',', 'Inc.', ',', '48', 'North', 'Pleasant', 'St.', 'Unit', '301', ',', 'Amherst', 'MA', '01002', 'USA', '|', '1-800-377-8036', '|', 'www.lexalytics.com'] 

 UPOS tags are: 
>> [('13', 'NUM'), ('|', 'PUNCT'), ('|', 'PUNCT'), ('Lexalytics', 'PROPN'), (',', 'PUNCT'), ('Inc.', 'PROPN'), (',', 'PUNCT'), ('48', 'NUM'), ('North', 'PROPN'), ('Pleasant', 'ADJ'), ('St.', 'PROPN'), ('Unit', 'NOUN'), ('301', 'NUM'), (',', 'PUNCT'), ('Amherst', 'PROPN'), ('MA', 'PROPN'), ('01002', 'NUM'), ('USA', 'PROPN'), ('|', 'PUNCT'), ('1-800-377-8036', 'NUM'), ('|', 'PUNCT'), ('www.lexalytics.com', 'X')] 

 XPOS tags are: 
>> [('13', 'LS'), ('|', 'NFP'), ('|', 'NFP'), ('Lexalytics', 'NNP'), (',', ','), ('Inc.', 'NNP'), (',', ','), ('48', 'CD'), ('North', 'NNP'), ('Pleasant', 'NNP'), ('St.', 'NNP'), ('Unit', 'NN'), ('301', 'CD'), (',', ','), ('Amherst', 'NNP'), ('MA', 'NNP'), ('01002', 'CD'), ('USA', 'NNP'), ('|', 'NFP'), ('1-800-377-8036', 'CD'), ('|', 'NFP'), ('www.lexalytics.com', 'ADD')] 

 Lemmas are: 
>> [('13', '13'), ('|', '|'), ('|', '|'), ('Lexalytics', 'Lexalytics'), (',', ','), ('Inc.', 'Inc.'), (',', ','), ('48', '48'), ('North', 'North'), ('Pleasant', 'Pleasant'), ('St.', 'St.'), ('Unit', 'unit'), ('301', '301'), (',', ','), ('Amherst', 'Amherst'), ('MA', 'MA'), ('01002', '01002'), ('USA', 'USA'), ('|', '|'), ('1-800-377-8036', '1-800-377-8036'), ('|', '|'), ('www.lexalytics.com', 'www.lexalytics.com')] 

 Dependency tags are: 
>> [(('13', 'Inc.'), 'nummod'), (('|', '13'), 'punct'), (('|', '13'), 'punct'), (('Lexalytics', 'Inc.'), 'compound'), ((',', 'Inc.'), 'punct'), (('Inc.', 'root'), 'root'), ((',', 'Inc.'), 'punct'), (('48', 'St.'), 'nummod'), (('North', 'St.'), 'compound'), (('Pleasant', 'St.'), 'amod'), (('St.', 'Inc.'), 'list'), (('Unit', 'Inc.'), 'list'), (('301', 'Unit'), 'nummod'), ((',', 'MA'), 'punct'), (('Amherst', 'MA'), 'appos'), (('MA', 'Inc.'), 'list'), (('01002', 'USA'), 'nummod'), (('USA', 'MA'), 'appos'), (('|', 'USA'), 'punct'), (('1-800-377-8036', 'Inc.'), 'list'), (('|', '1-800-377-8036'), 'punct'), (('www.lexalytics.com', 'Inc.'), 'list')]

 Named Entites are: 
>> [('13|       |   Lexalytics, Inc.', 'ORG'), ('301', 'CARDINAL'), ('Amherst', 'GPE')]

================================ Paragraph 165 =================================

There are more potential side-effects of training that you must be aware of.  


------------------- Sentence 1 -------------------

 There are more potential side-effects of training that you must be aware of. 

Tokens are: 
>> ['There', 'are', 'more', 'potential', 'side-effects', 'of', 'training', 'that', 'you', 'must', 'be', 'aware', 'of', '.'] 

 UPOS tags are: 
>> [('There', 'PRON'), ('are', 'VERB'), ('more', 'ADV'), ('potential', 'ADJ'), ('side-effects', 'NOUN'), ('of', 'ADP'), ('training', 'NOUN'), ('that', 'PRON'), ('you', 'PRON'), ('must', 'AUX'), ('be', 'AUX'), ('aware', 'ADJ'), ('of', 'ADP'), ('.', 'PUNCT')] 

 XPOS tags are: 
>> [('There', 'EX'), ('are', 'VBP'), ('more', 'RBR'), ('potential', 'JJ'), ('side-effects', 'NNS'), ('of', 'IN'), ('training', 'NN'), ('that', 'WDT'), ('you', 'PRP'), ('must', 'MD'), ('be', 'VB'), ('aware', 'JJ'), ('of', 'IN'), ('.', '.')] 

 Lemmas are: 
>> [('There', 'there'), ('are', 'be'), ('more', 'more'), ('potential', 'potential'), ('side-effects', 'side-effects'), ('of', 'of'), ('training', 'training'), ('that', 'that'), ('you', 'you'), ('must', 'must'), ('be', 'be'), ('aware', 'aware'), ('of', 'of'), ('.', '.')] 

 Dependency tags are: 
>> [(('There', 'are'), 'expl'), (('are', 'root'), 'root'), (('more', 'potential'), 'advmod'), (('potential', 'side-effects'), 'amod'), (('side-effects', 'are'), 'nsubj'), (('of', 'training'), 'case'), (('training', 'side-effects'), 'nmod'), (('that', 'aware'), 'obj'), (('you', 'aware'), 'nsubj'), (('must', 'aware'), 'aux'), (('be', 'aware'), 'cop'), (('aware', 'side-effects'), 'acl:relcl'), (('of', 'that'), 'case'), (('.', 'are'), 'punct')]

 Named Entites are: 
>> []

================================ Paragraph 166 =================================

Say we’re scoring a bunch of documents to try to effect change on a  particular phrase. Each of those documents contains more than that one  phrase, and the other phrases in each document will also be affected by our  scoring and re-tuning. This is particularly true of common phrases, which  appear often enough that they end up influencing the model.  


------------------- Sentence 1 -------------------

 Say we’re scoring a bunch of documents to try to effect change on a  particular phrase. 

Tokens are: 
>> ['Say', 'we', '’re', 'scoring', 'a', 'bunch', 'of', 'documents', 'to', 'try', 'to', 'effect', 'change', 'on', 'a', 'particular', 'phrase', '.'] 

 UPOS tags are: 
>> [('Say', 'VERB'), ('we', 'PRON'), ('’re', 'AUX'), ('scoring', 'VERB'), ('a', 'DET'), ('bunch', 'NOUN'), ('of', 'ADP'), ('documents', 'NOUN'), ('to', 'PART'), ('try', 'VERB'), ('to', 'PART'), ('effect', 'VERB'), ('change', 'NOUN'), ('on', 'ADP'), ('a', 'DET'), ('particular', 'ADJ'), ('phrase', 'NOUN'), ('.', 'PUNCT')] 

 XPOS tags are: 
>> [('Say', 'VB'), ('we', 'PRP'), ('’re', 'VBP'), ('scoring', 'VBG'), ('a', 'DT'), ('bunch', 'NN'), ('of', 'IN'), ('documents', 'NNS'), ('to', 'TO'), ('try', 'VB'), ('to', 'TO'), ('effect', 'VB'), ('change', 'NN'), ('on', 'IN'), ('a', 'DT'), ('particular', 'JJ'), ('phrase', 'NN'), ('.', '.')] 

 Lemmas are: 
>> [('Say', 'say'), ('we', 'we'), ('’re', 'be'), ('scoring', 'score'), ('a', 'a'), ('bunch', 'bunch'), ('of', 'of'), ('documents', 'document'), ('to', 'to'), ('try', 'try'), ('to', 'to'), ('effect', 'effect'), ('change', 'change'), ('on', 'on'), ('a', 'a'), ('particular', 'particular'), ('phrase', 'phrase'), ('.', '.')] 

 Dependency tags are: 
>> [(('Say', 'root'), 'root'), (('we', 'scoring'), 'nsubj'), (('’re', 'scoring'), 'aux'), (('scoring', 'Say'), 'ccomp'), (('a', 'bunch'), 'det'), (('bunch', 'scoring'), 'obj'), (('of', 'documents'), 'case'), (('documents', 'bunch'), 'nmod'), (('to', 'try'), 'mark'), (('try', 'scoring'), 'advcl'), (('to', 'effect'), 'mark'), (('effect', 'try'), 'xcomp'), (('change', 'effect'), 'obj'), (('on', 'phrase'), 'case'), (('a', 'phrase'), 'det'), (('particular', 'phrase'), 'amod'), (('phrase', 'effect'), 'obl'), (('.', 'Say'), 'punct')]

 Named Entites are: 
>> []

------------------- Sentence 2 -------------------

 Each of those documents contains more than that one  phrase, and the other phrases in each document will also be affected by our  scoring and re-tuning. 

Tokens are: 
>> ['Each', 'of', 'those', 'documents', 'contains', 'more', 'than', 'that', 'one', 'phrase', ',', 'and', 'the', 'other', 'phrases', 'in', 'each', 'document', 'will', 'also', 'be', 'affected', 'by', 'our', 'scoring', 'and', 're-tuning', '.'] 

 UPOS tags are: 
>> [('Each', 'DET'), ('of', 'ADP'), ('those', 'DET'), ('documents', 'NOUN'), ('contains', 'VERB'), ('more', 'ADJ'), ('than', 'ADP'), ('that', 'DET'), ('one', 'NUM'), ('phrase', 'NOUN'), (',', 'PUNCT'), ('and', 'CCONJ'), ('the', 'DET'), ('other', 'ADJ'), ('phrases', 'NOUN'), ('in', 'ADP'), ('each', 'DET'), ('document', 'NOUN'), ('will', 'AUX'), ('also', 'ADV'), ('be', 'AUX'), ('affected', 'VERB'), ('by', 'ADP'), ('our', 'PRON'), ('scoring', 'NOUN'), ('and', 'CCONJ'), ('re-tuning', 'NOUN'), ('.', 'PUNCT')] 

 XPOS tags are: 
>> [('Each', 'DT'), ('of', 'IN'), ('those', 'DT'), ('documents', 'NNS'), ('contains', 'VBZ'), ('more', 'JJR'), ('than', 'IN'), ('that', 'DT'), ('one', 'CD'), ('phrase', 'NN'), (',', ','), ('and', 'CC'), ('the', 'DT'), ('other', 'JJ'), ('phrases', 'NNS'), ('in', 'IN'), ('each', 'DT'), ('document', 'NN'), ('will', 'MD'), ('also', 'RB'), ('be', 'VB'), ('affected', 'VBN'), ('by', 'IN'), ('our', 'PRP$'), ('scoring', 'NN'), ('and', 'CC'), ('re-tuning', 'NN'), ('.', '.')] 

 Lemmas are: 
>> [('Each', 'each'), ('of', 'of'), ('those', 'that'), ('documents', 'document'), ('contains', 'contain'), ('more', 'more'), ('than', 'than'), ('that', 'that'), ('one', 'one'), ('phrase', 'phrase'), (',', ','), ('and', 'and'), ('the', 'the'), ('other', 'other'), ('phrases', 'phrase'), ('in', 'in'), ('each', 'each'), ('document', 'document'), ('will', 'will'), ('also', 'also'), ('be', 'be'), ('affected', 'affect'), ('by', 'by'), ('our', 'we'), ('scoring', 'scoring'), ('and', 'and'), ('re-tuning', 're-tuning'), ('.', '.')] 

 Dependency tags are: 
>> [(('Each', 'contains'), 'nsubj'), (('of', 'documents'), 'case'), (('those', 'documents'), 'det'), (('documents', 'Each'), 'nmod'), (('contains', 'root'), 'root'), (('more', 'contains'), 'obj'), (('than', 'phrase'), 'case'), (('that', 'phrase'), 'det'), (('one', 'phrase'), 'nummod'), (('phrase', 'contains'), 'obj'), ((',', 'affected'), 'punct'), (('and', 'affected'), 'cc'), (('the', 'phrases'), 'det'), (('other', 'phrases'), 'amod'), (('phrases', 'affected'), 'nsubj:pass'), (('in', 'document'), 'case'), (('each', 'document'), 'det'), (('document', 'phrases'), 'nmod'), (('will', 'affected'), 'aux'), (('also', 'affected'), 'advmod'), (('be', 'affected'), 'aux:pass'), (('affected', 'contains'), 'conj'), (('by', 'scoring'), 'case'), (('our', 'scoring'), 'nmod:poss'), (('scoring', 'affected'), 'obl'), (('and', 're-tuning'), 'cc'), (('re-tuning', 'scoring'), 'conj'), (('.', 'contains'), 'punct')]

 Named Entites are: 
>> [('one', 'CARDINAL')]

------------------- Sentence 3 -------------------

 This is particularly true of common phrases, which  appear often enough that they end up influencing the model. 

Tokens are: 
>> ['This', 'is', 'particularly', 'true', 'of', 'common', 'phrases', ',', 'which', 'appear', 'often', 'enough', 'that', 'they', 'end', 'up', 'influencing', 'the', 'model', '.'] 

 UPOS tags are: 
>> [('This', 'PRON'), ('is', 'AUX'), ('particularly', 'ADV'), ('true', 'ADJ'), ('of', 'ADP'), ('common', 'ADJ'), ('phrases', 'NOUN'), (',', 'PUNCT'), ('which', 'PRON'), ('appear', 'VERB'), ('often', 'ADV'), ('enough', 'ADJ'), ('that', 'SCONJ'), ('they', 'PRON'), ('end', 'VERB'), ('up', 'ADP'), ('influencing', 'VERB'), ('the', 'DET'), ('model', 'NOUN'), ('.', 'PUNCT')] 

 XPOS tags are: 
>> [('This', 'DT'), ('is', 'VBZ'), ('particularly', 'RB'), ('true', 'JJ'), ('of', 'IN'), ('common', 'JJ'), ('phrases', 'NNS'), (',', ','), ('which', 'WDT'), ('appear', 'VBP'), ('often', 'RB'), ('enough', 'JJ'), ('that', 'IN'), ('they', 'PRP'), ('end', 'VBP'), ('up', 'RP'), ('influencing', 'VBG'), ('the', 'DT'), ('model', 'NN'), ('.', '.')] 

 Lemmas are: 
>> [('This', 'this'), ('is', 'be'), ('particularly', 'particularly'), ('true', 'true'), ('of', 'of'), ('common', 'common'), ('phrases', 'phrase'), (',', ','), ('which', 'which'), ('appear', 'appear'), ('often', 'often'), ('enough', 'enough'), ('that', 'that'), ('they', 'they'), ('end', 'end'), ('up', 'up'), ('influencing', 'influence'), ('the', 'the'), ('model', 'model'), ('.', '.')] 

 Dependency tags are: 
>> [(('This', 'true'), 'nsubj'), (('is', 'true'), 'cop'), (('particularly', 'true'), 'advmod'), (('true', 'root'), 'root'), (('of', 'phrases'), 'case'), (('common', 'phrases'), 'amod'), (('phrases', 'true'), 'obl'), ((',', 'appear'), 'punct'), (('which', 'appear'), 'nsubj'), (('appear', 'phrases'), 'acl:relcl'), (('often', 'enough'), 'advmod'), (('enough', 'appear'), 'xcomp'), (('that', 'end'), 'mark'), (('they', 'end'), 'nsubj'), (('end', 'enough'), 'ccomp'), (('up', 'end'), 'compound:prt'), (('influencing', 'end'), 'xcomp'), (('the', 'model'), 'det'), (('model', 'influencing'), 'obj'), (('.', 'true'), 'punct')]

 Named Entites are: 
>> []

================================ Paragraph 167 =================================

Imagine that you’re scoring news stories from 2008. 2008 was truly awful for  business and economics as a whole. If you are focused on scoring financial  results from businesses, you’ll be marking a lot of content as negative.  Then, machine learning algorithms will weigh the phrases in the content in  proportion to their occurrence.  


------------------- Sentence 1 -------------------

 Imagine that you’re scoring news stories from 2008. 

Tokens are: 
>> ['Imagine', 'that', 'you', '’re', 'scoring', 'news', 'stories', 'from', '2008', '.'] 

 UPOS tags are: 
>> [('Imagine', 'VERB'), ('that', 'SCONJ'), ('you', 'PRON'), ('’re', 'AUX'), ('scoring', 'VERB'), ('news', 'NOUN'), ('stories', 'NOUN'), ('from', 'ADP'), ('2008', 'NUM'), ('.', 'PUNCT')] 

 XPOS tags are: 
>> [('Imagine', 'VB'), ('that', 'IN'), ('you', 'PRP'), ('’re', 'VBP'), ('scoring', 'VBG'), ('news', 'NN'), ('stories', 'NNS'), ('from', 'IN'), ('2008', 'CD'), ('.', '.')] 

 Lemmas are: 
>> [('Imagine', 'imagine'), ('that', 'that'), ('you', 'you'), ('’re', 'be'), ('scoring', 'score'), ('news', 'news'), ('stories', 'story'), ('from', 'from'), ('2008', '2008'), ('.', '.')] 

 Dependency tags are: 
>> [(('Imagine', 'root'), 'root'), (('that', 'scoring'), 'mark'), (('you', 'scoring'), 'nsubj'), (('’re', 'scoring'), 'aux'), (('scoring', 'Imagine'), 'ccomp'), (('news', 'stories'), 'compound'), (('stories', 'scoring'), 'obj'), (('from', '2008'), 'case'), (('2008', 'scoring'), 'obl'), (('.', 'Imagine'), 'punct')]

 Named Entites are: 
>> [('2008', 'DATE')]

------------------- Sentence 2 -------------------

 2008 was truly awful for  business and economics as a whole. 

Tokens are: 
>> ['2008', 'was', 'truly', 'awful', 'for', 'business', 'and', 'economics', 'as', 'a', 'whole', '.'] 

 UPOS tags are: 
>> [('2008', 'NUM'), ('was', 'AUX'), ('truly', 'ADV'), ('awful', 'ADJ'), ('for', 'ADP'), ('business', 'NOUN'), ('and', 'CCONJ'), ('economics', 'NOUN'), ('as', 'ADP'), ('a', 'DET'), ('whole', 'NOUN'), ('.', 'PUNCT')] 

 XPOS tags are: 
>> [('2008', 'CD'), ('was', 'VBD'), ('truly', 'RB'), ('awful', 'JJ'), ('for', 'IN'), ('business', 'NN'), ('and', 'CC'), ('economics', 'NNS'), ('as', 'IN'), ('a', 'DT'), ('whole', 'NN'), ('.', '.')] 

 Lemmas are: 
>> [('2008', '2008'), ('was', 'be'), ('truly', 'truly'), ('awful', 'awful'), ('for', 'for'), ('business', 'business'), ('and', 'and'), ('economics', 'economics'), ('as', 'as'), ('a', 'a'), ('whole', 'whole'), ('.', '.')] 

 Dependency tags are: 
>> [(('2008', 'awful'), 'nsubj'), (('was', 'awful'), 'cop'), (('truly', 'awful'), 'advmod'), (('awful', 'root'), 'root'), (('for', 'business'), 'case'), (('business', 'awful'), 'obl'), (('and', 'economics'), 'cc'), (('economics', 'business'), 'conj'), (('as', 'whole'), 'case'), (('a', 'whole'), 'det'), (('whole', 'awful'), 'obl'), (('.', 'awful'), 'punct')]

 Named Entites are: 
>> [('2008', 'DATE')]

------------------- Sentence 3 -------------------

 If you are focused on scoring financial  results from businesses, you’ll be marking a lot of content as negative. 

Tokens are: 
>> ['If', 'you', 'are', 'focused', 'on', 'scoring', 'financial', 'results', 'from', 'businesses', ',', 'you', '’ll', 'be', 'marking', 'a', 'lot', 'of', 'content', 'as', 'negative', '.'] 

 UPOS tags are: 
>> [('If', 'SCONJ'), ('you', 'PRON'), ('are', 'AUX'), ('focused', 'VERB'), ('on', 'SCONJ'), ('scoring', 'VERB'), ('financial', 'ADJ'), ('results', 'NOUN'), ('from', 'ADP'), ('businesses', 'NOUN'), (',', 'PUNCT'), ('you', 'PRON'), ('’ll', 'AUX'), ('be', 'AUX'), ('marking', 'VERB'), ('a', 'DET'), ('lot', 'NOUN'), ('of', 'ADP'), ('content', 'NOUN'), ('as', 'ADP'), ('negative', 'ADJ'), ('.', 'PUNCT')] 

 XPOS tags are: 
>> [('If', 'IN'), ('you', 'PRP'), ('are', 'VBP'), ('focused', 'VBN'), ('on', 'IN'), ('scoring', 'VBG'), ('financial', 'JJ'), ('results', 'NNS'), ('from', 'IN'), ('businesses', 'NNS'), (',', ','), ('you', 'PRP'), ('’ll', 'MD'), ('be', 'VB'), ('marking', 'VBG'), ('a', 'DT'), ('lot', 'NN'), ('of', 'IN'), ('content', 'NN'), ('as', 'IN'), ('negative', 'JJ'), ('.', '.')] 

 Lemmas are: 
>> [('If', 'if'), ('you', 'you'), ('are', 'be'), ('focused', 'focus'), ('on', 'on'), ('scoring', 'score'), ('financial', 'financial'), ('results', 'result'), ('from', 'from'), ('businesses', 'business'), (',', ','), ('you', 'you'), ('’ll', 'will'), ('be', 'be'), ('marking', 'mark'), ('a', 'a'), ('lot', 'lot'), ('of', 'of'), ('content', 'content'), ('as', 'as'), ('negative', 'negative'), ('.', '.')] 

 Dependency tags are: 
>> [(('If', 'focused'), 'mark'), (('you', 'focused'), 'nsubj:pass'), (('are', 'focused'), 'aux:pass'), (('focused', 'marking'), 'advcl'), (('on', 'scoring'), 'mark'), (('scoring', 'focused'), 'advcl'), (('financial', 'results'), 'amod'), (('results', 'scoring'), 'obj'), (('from', 'businesses'), 'case'), (('businesses', 'scoring'), 'obl'), ((',', 'marking'), 'punct'), (('you', 'marking'), 'nsubj'), (('’ll', 'marking'), 'aux'), (('be', 'marking'), 'aux'), (('marking', 'root'), 'root'), (('a', 'lot'), 'det'), (('lot', 'marking'), 'obj'), (('of', 'content'), 'case'), (('content', 'lot'), 'nmod'), (('as', 'negative'), 'case'), (('negative', 'marking'), 'obl'), (('.', 'marking'), 'punct')]

 Named Entites are: 
>> []

------------------- Sentence 4 -------------------

 Then, machine learning algorithms will weigh the phrases in the content in  proportion to their occurrence. 

Tokens are: 
>> ['Then', ',', 'machine', 'learning', 'algorithms', 'will', 'weigh', 'the', 'phrases', 'in', 'the', 'content', 'in', 'proportion', 'to', 'their', 'occurrence', '.'] 

 UPOS tags are: 
>> [('Then', 'ADV'), (',', 'PUNCT'), ('machine', 'NOUN'), ('learning', 'NOUN'), ('algorithms', 'NOUN'), ('will', 'AUX'), ('weigh', 'VERB'), ('the', 'DET'), ('phrases', 'NOUN'), ('in', 'ADP'), ('the', 'DET'), ('content', 'NOUN'), ('in', 'ADP'), ('proportion', 'NOUN'), ('to', 'ADP'), ('their', 'PRON'), ('occurrence', 'NOUN'), ('.', 'PUNCT')] 

 XPOS tags are: 
>> [('Then', 'RB'), (',', ','), ('machine', 'NN'), ('learning', 'NN'), ('algorithms', 'NNS'), ('will', 'MD'), ('weigh', 'VB'), ('the', 'DT'), ('phrases', 'NNS'), ('in', 'IN'), ('the', 'DT'), ('content', 'NN'), ('in', 'IN'), ('proportion', 'NN'), ('to', 'IN'), ('their', 'PRP$'), ('occurrence', 'NN'), ('.', '.')] 

 Lemmas are: 
>> [('Then', 'then'), (',', ','), ('machine', 'machine'), ('learning', 'learning'), ('algorithms', 'algorithm'), ('will', 'will'), ('weigh', 'weigh'), ('the', 'the'), ('phrases', 'phrase'), ('in', 'in'), ('the', 'the'), ('content', 'content'), ('in', 'in'), ('proportion', 'proportion'), ('to', 'to'), ('their', 'they'), ('occurrence', 'occurrence'), ('.', '.')] 

 Dependency tags are: 
>> [(('Then', 'weigh'), 'advmod'), ((',', 'weigh'), 'punct'), (('machine', 'algorithms'), 'compound'), (('learning', 'algorithms'), 'compound'), (('algorithms', 'weigh'), 'nsubj'), (('will', 'weigh'), 'aux'), (('weigh', 'root'), 'root'), (('the', 'phrases'), 'det'), (('phrases', 'weigh'), 'obj'), (('in', 'content'), 'case'), (('the', 'content'), 'det'), (('content', 'weigh'), 'obl'), (('in', 'proportion'), 'case'), (('proportion', 'content'), 'nmod'), (('to', 'occurrence'), 'case'), (('their', 'occurrence'), 'nmod:poss'), (('occurrence', 'proportion'), 'nmod'), (('.', 'weigh'), 'punct')]

 Named Entites are: 
>> []

================================ Paragraph 168 =================================

Unfortunately, that leaves some collateral damage: “first quarter,” “second  quarter,” “third quarter,” and “fourth quarter.” These are neutral terms, but  they occurred in frequent conjunction with negative financial news. So, the  machine learning algorithm will weight those phrases as being negative.   That will end up negatively impacting your results for years to come. 


------------------- Sentence 1 -------------------

 Unfortunately, that leaves some collateral damage: “first quarter,” “second  quarter,” “third quarter,” and “fourth quarter.” 

Tokens are: 
>> ['Unfortunately', ',', 'that', 'leaves', 'some', 'collateral', 'damage', ':', '“', 'first', 'quarter', ',', '”', '“', 'second', 'quarter', ',', '”', '“', 'third', 'quarter', ',', '”', 'and', '“', 'fourth', 'quarter', '.', '”'] 

 UPOS tags are: 
>> [('Unfortunately', 'ADV'), (',', 'PUNCT'), ('that', 'PRON'), ('leaves', 'VERB'), ('some', 'DET'), ('collateral', 'ADJ'), ('damage', 'NOUN'), (':', 'PUNCT'), ('“', 'PUNCT'), ('first', 'ADJ'), ('quarter', 'NOUN'), (',', 'PUNCT'), ('”', 'PUNCT'), ('“', 'PUNCT'), ('second', 'ADJ'), ('quarter', 'NOUN'), (',', 'PUNCT'), ('”', 'PUNCT'), ('“', 'PUNCT'), ('third', 'ADJ'), ('quarter', 'NOUN'), (',', 'PUNCT'), ('”', 'PUNCT'), ('and', 'CCONJ'), ('“', 'PUNCT'), ('fourth', 'ADJ'), ('quarter', 'NOUN'), ('.', 'PUNCT'), ('”', 'PUNCT')] 

 XPOS tags are: 
>> [('Unfortunately', 'RB'), (',', ','), ('that', 'DT'), ('leaves', 'VBZ'), ('some', 'DT'), ('collateral', 'JJ'), ('damage', 'NN'), (':', ':'), ('“', '``'), ('first', 'JJ'), ('quarter', 'NN'), (',', ','), ('”', "''"), ('“', '``'), ('second', 'JJ'), ('quarter', 'NN'), (',', ','), ('”', "''"), ('“', '``'), ('third', 'JJ'), ('quarter', 'NN'), (',', ','), ('”', "''"), ('and', 'CC'), ('“', '``'), ('fourth', 'JJ'), ('quarter', 'NN'), ('.', '.'), ('”', "''")] 

 Lemmas are: 
>> [('Unfortunately', 'unfortunately'), (',', ','), ('that', 'that'), ('leaves', 'leave'), ('some', 'some'), ('collateral', 'collateral'), ('damage', 'damage'), (':', ':'), ('“', "''"), ('first', 'first'), ('quarter', 'quarter'), (',', ','), ('”', "''"), ('“', "''"), ('second', 'second'), ('quarter', 'quarter'), (',', ','), ('”', "''"), ('“', "''"), ('third', 'third'), ('quarter', 'quarter'), (',', ','), ('”', "''"), ('and', 'and'), ('“', "''"), ('fourth', 'fourth'), ('quarter', 'quarter'), ('.', '.'), ('”', "''")] 

 Dependency tags are: 
>> [(('Unfortunately', 'leaves'), 'advmod'), ((',', 'leaves'), 'punct'), (('that', 'leaves'), 'nsubj'), (('leaves', 'root'), 'root'), (('some', 'damage'), 'det'), (('collateral', 'damage'), 'amod'), (('damage', 'leaves'), 'obj'), ((':', 'quarter'), 'punct'), (('“', 'quarter'), 'punct'), (('first', 'quarter'), 'amod'), (('quarter', 'damage'), 'appos'), ((',', 'quarter'), 'punct'), (('”', 'quarter'), 'punct'), (('“', 'quarter'), 'punct'), (('second', 'quarter'), 'amod'), (('quarter', 'quarter'), 'appos'), ((',', 'quarter'), 'punct'), (('”', 'quarter'), 'punct'), (('“', 'quarter'), 'punct'), (('third', 'quarter'), 'amod'), (('quarter', 'quarter'), 'appos'), ((',', 'quarter'), 'punct'), (('”', 'quarter'), 'punct'), (('and', 'quarter'), 'cc'), (('“', 'quarter'), 'punct'), (('fourth', 'quarter'), 'amod'), (('quarter', 'quarter'), 'conj'), (('.', 'quarter'), 'punct'), (('”', 'quarter'), 'punct')]

 Named Entites are: 
>> [('“first quarter', 'DATE'), ('” “second  quarter,” “third quarter,” and “fourth quarter', 'DATE')]

------------------- Sentence 2 -------------------

 These are neutral terms, but  they occurred in frequent conjunction with negative financial news. 

Tokens are: 
>> ['These', 'are', 'neutral', 'terms', ',', 'but', 'they', 'occurred', 'in', 'frequent', 'conjunction', 'with', 'negative', 'financial', 'news', '.'] 

 UPOS tags are: 
>> [('These', 'PRON'), ('are', 'AUX'), ('neutral', 'ADJ'), ('terms', 'NOUN'), (',', 'PUNCT'), ('but', 'CCONJ'), ('they', 'PRON'), ('occurred', 'VERB'), ('in', 'ADP'), ('frequent', 'ADJ'), ('conjunction', 'NOUN'), ('with', 'ADP'), ('negative', 'ADJ'), ('financial', 'ADJ'), ('news', 'NOUN'), ('.', 'PUNCT')] 

 XPOS tags are: 
>> [('These', 'DT'), ('are', 'VBP'), ('neutral', 'JJ'), ('terms', 'NNS'), (',', ','), ('but', 'CC'), ('they', 'PRP'), ('occurred', 'VBD'), ('in', 'IN'), ('frequent', 'JJ'), ('conjunction', 'NN'), ('with', 'IN'), ('negative', 'JJ'), ('financial', 'JJ'), ('news', 'NN'), ('.', '.')] 

 Lemmas are: 
>> [('These', 'this'), ('are', 'be'), ('neutral', 'neutral'), ('terms', 'term'), (',', ','), ('but', 'but'), ('they', 'they'), ('occurred', 'occur'), ('in', 'in'), ('frequent', 'frequent'), ('conjunction', 'conjunction'), ('with', 'with'), ('negative', 'negative'), ('financial', 'financial'), ('news', 'news'), ('.', '.')] 

 Dependency tags are: 
>> [(('These', 'terms'), 'nsubj'), (('are', 'terms'), 'cop'), (('neutral', 'terms'), 'amod'), (('terms', 'root'), 'root'), ((',', 'occurred'), 'punct'), (('but', 'occurred'), 'cc'), (('they', 'occurred'), 'nsubj'), (('occurred', 'terms'), 'conj'), (('in', 'conjunction'), 'case'), (('frequent', 'conjunction'), 'amod'), (('conjunction', 'occurred'), 'obl'), (('with', 'news'), 'case'), (('negative', 'news'), 'amod'), (('financial', 'news'), 'amod'), (('news', 'conjunction'), 'nmod'), (('.', 'terms'), 'punct')]

 Named Entites are: 
>> []

------------------- Sentence 3 -------------------

 So, the  machine learning algorithm will weight those phrases as being negative. 

Tokens are: 
>> ['So', ',', 'the', 'machine', 'learning', 'algorithm', 'will', 'weight', 'those', 'phrases', 'as', 'being', 'negative', '.'] 

 UPOS tags are: 
>> [('So', 'ADV'), (',', 'PUNCT'), ('the', 'DET'), ('machine', 'NOUN'), ('learning', 'NOUN'), ('algorithm', 'NOUN'), ('will', 'AUX'), ('weight', 'VERB'), ('those', 'DET'), ('phrases', 'NOUN'), ('as', 'SCONJ'), ('being', 'AUX'), ('negative', 'ADJ'), ('.', 'PUNCT')] 

 XPOS tags are: 
>> [('So', 'RB'), (',', ','), ('the', 'DT'), ('machine', 'NN'), ('learning', 'NN'), ('algorithm', 'NN'), ('will', 'MD'), ('weight', 'VB'), ('those', 'DT'), ('phrases', 'NNS'), ('as', 'IN'), ('being', 'VBG'), ('negative', 'JJ'), ('.', '.')] 

 Lemmas are: 
>> [('So', 'so'), (',', ','), ('the', 'the'), ('machine', 'machine'), ('learning', 'learning'), ('algorithm', 'algorithm'), ('will', 'will'), ('weight', 'weight'), ('those', 'that'), ('phrases', 'phrase'), ('as', 'as'), ('being', 'be'), ('negative', 'negative'), ('.', '.')] 

 Dependency tags are: 
>> [(('So', 'weight'), 'advmod'), ((',', 'weight'), 'punct'), (('the', 'algorithm'), 'det'), (('machine', 'algorithm'), 'compound'), (('learning', 'algorithm'), 'compound'), (('algorithm', 'weight'), 'nsubj'), (('will', 'weight'), 'aux'), (('weight', 'root'), 'root'), (('those', 'phrases'), 'det'), (('phrases', 'weight'), 'obj'), (('as', 'negative'), 'mark'), (('being', 'negative'), 'cop'), (('negative', 'weight'), 'advcl'), (('.', 'weight'), 'punct')]

 Named Entites are: 
>> []

------------------- Sentence 4 -------------------

 That will end up negatively impacting your results for years to come. 

Tokens are: 
>> ['That', 'will', 'end', 'up', 'negatively', 'impacting', 'your', 'results', 'for', 'years', 'to', 'come', '.'] 

 UPOS tags are: 
>> [('That', 'PRON'), ('will', 'AUX'), ('end', 'VERB'), ('up', 'ADP'), ('negatively', 'ADV'), ('impacting', 'VERB'), ('your', 'PRON'), ('results', 'NOUN'), ('for', 'ADP'), ('years', 'NOUN'), ('to', 'PART'), ('come', 'VERB'), ('.', 'PUNCT')] 

 XPOS tags are: 
>> [('That', 'DT'), ('will', 'MD'), ('end', 'VB'), ('up', 'RP'), ('negatively', 'RB'), ('impacting', 'VBG'), ('your', 'PRP$'), ('results', 'NNS'), ('for', 'IN'), ('years', 'NNS'), ('to', 'TO'), ('come', 'VB'), ('.', '.')] 

 Lemmas are: 
>> [('That', 'that'), ('will', 'will'), ('end', 'end'), ('up', 'up'), ('negatively', 'negatively'), ('impacting', 'impact'), ('your', 'you'), ('results', 'result'), ('for', 'for'), ('years', 'year'), ('to', 'to'), ('come', 'come'), ('.', '.')] 

 Dependency tags are: 
>> [(('That', 'end'), 'nsubj'), (('will', 'end'), 'aux'), (('end', 'root'), 'root'), (('up', 'end'), 'compound:prt'), (('negatively', 'impacting'), 'advmod'), (('impacting', 'end'), 'advcl'), (('your', 'results'), 'nmod:poss'), (('results', 'impacting'), 'obj'), (('for', 'years'), 'case'), (('years', 'impacting'), 'obl'), (('to', 'come'), 'mark'), (('come', 'impacting'), 'advcl'), (('.', 'end'), 'punct')]

 Named Entites are: 
>> [('years', 'DATE')]

================================ Paragraph 169 =================================

Lexalytics has put a number of checks and balances into our text analytics  system to handle situations like this. Sometimes you just need to be able   to reach in and tell the software that “first quarter” is really just neutral,   despite what it might think. 


------------------- Sentence 1 -------------------

 Lexalytics has put a number of checks and balances into our text analytics  system to handle situations like this. 

Tokens are: 
>> ['Lexalytics', 'has', 'put', 'a', 'number', 'of', 'checks', 'and', 'balances', 'into', 'our', 'text', 'analytics', 'system', 'to', 'handle', 'situations', 'like', 'this', '.'] 

 UPOS tags are: 
>> [('Lexalytics', 'PROPN'), ('has', 'AUX'), ('put', 'VERB'), ('a', 'DET'), ('number', 'NOUN'), ('of', 'ADP'), ('checks', 'NOUN'), ('and', 'CCONJ'), ('balances', 'NOUN'), ('into', 'ADP'), ('our', 'PRON'), ('text', 'NOUN'), ('analytics', 'NOUN'), ('system', 'NOUN'), ('to', 'PART'), ('handle', 'VERB'), ('situations', 'NOUN'), ('like', 'ADP'), ('this', 'PRON'), ('.', 'PUNCT')] 

 XPOS tags are: 
>> [('Lexalytics', 'NNPS'), ('has', 'VBZ'), ('put', 'VBN'), ('a', 'DT'), ('number', 'NN'), ('of', 'IN'), ('checks', 'NNS'), ('and', 'CC'), ('balances', 'NNS'), ('into', 'IN'), ('our', 'PRP$'), ('text', 'NN'), ('analytics', 'NN'), ('system', 'NN'), ('to', 'TO'), ('handle', 'VB'), ('situations', 'NNS'), ('like', 'IN'), ('this', 'DT'), ('.', '.')] 

 Lemmas are: 
>> [('Lexalytics', 'Lexalytics'), ('has', 'have'), ('put', 'put'), ('a', 'a'), ('number', 'number'), ('of', 'of'), ('checks', 'check'), ('and', 'and'), ('balances', 'balance'), ('into', 'into'), ('our', 'we'), ('text', 'text'), ('analytics', 'analytic'), ('system', 'system'), ('to', 'to'), ('handle', 'handle'), ('situations', 'situation'), ('like', 'like'), ('this', 'this'), ('.', '.')] 

 Dependency tags are: 
>> [(('Lexalytics', 'put'), 'nsubj'), (('has', 'put'), 'aux'), (('put', 'root'), 'root'), (('a', 'number'), 'det'), (('number', 'put'), 'obj'), (('of', 'checks'), 'case'), (('checks', 'number'), 'nmod'), (('and', 'balances'), 'cc'), (('balances', 'checks'), 'conj'), (('into', 'system'), 'case'), (('our', 'system'), 'nmod:poss'), (('text', 'analytics'), 'compound'), (('analytics', 'system'), 'compound'), (('system', 'put'), 'obl'), (('to', 'handle'), 'mark'), (('handle', 'put'), 'advcl'), (('situations', 'handle'), 'obj'), (('like', 'this'), 'case'), (('this', 'situations'), 'nmod'), (('.', 'put'), 'punct')]

 Named Entites are: 
>> [('Lexalytics', 'ORG')]

------------------- Sentence 2 -------------------

 Sometimes you just need to be able   to reach in and tell the software that “first quarter” is really just neutral,   despite what it might think. 

Tokens are: 
>> ['Sometimes', 'you', 'just', 'need', 'to', 'be', 'able', 'to', 'reach', 'in', 'and', 'tell', 'the', 'software', 'that', '“', 'first', 'quarter', '”', 'is', 'really', 'just', 'neutral', ',', 'despite', 'what', 'it', 'might', 'think', '.'] 

 UPOS tags are: 
>> [('Sometimes', 'ADV'), ('you', 'PRON'), ('just', 'ADV'), ('need', 'VERB'), ('to', 'PART'), ('be', 'AUX'), ('able', 'ADJ'), ('to', 'PART'), ('reach', 'VERB'), ('in', 'ADP'), ('and', 'CCONJ'), ('tell', 'VERB'), ('the', 'DET'), ('software', 'NOUN'), ('that', 'SCONJ'), ('“', 'PUNCT'), ('first', 'ADJ'), ('quarter', 'NOUN'), ('”', 'PUNCT'), ('is', 'AUX'), ('really', 'ADV'), ('just', 'ADV'), ('neutral', 'ADJ'), (',', 'PUNCT'), ('despite', 'SCONJ'), ('what', 'PRON'), ('it', 'PRON'), ('might', 'AUX'), ('think', 'VERB'), ('.', 'PUNCT')] 

 XPOS tags are: 
>> [('Sometimes', 'RB'), ('you', 'PRP'), ('just', 'RB'), ('need', 'VBP'), ('to', 'TO'), ('be', 'VB'), ('able', 'JJ'), ('to', 'TO'), ('reach', 'VB'), ('in', 'RP'), ('and', 'CC'), ('tell', 'VB'), ('the', 'DT'), ('software', 'NN'), ('that', 'IN'), ('“', '``'), ('first', 'JJ'), ('quarter', 'NN'), ('”', "''"), ('is', 'VBZ'), ('really', 'RB'), ('just', 'RB'), ('neutral', 'JJ'), (',', ','), ('despite', 'IN'), ('what', 'WP'), ('it', 'PRP'), ('might', 'MD'), ('think', 'VB'), ('.', '.')] 

 Lemmas are: 
>> [('Sometimes', 'sometimes'), ('you', 'you'), ('just', 'just'), ('need', 'need'), ('to', 'to'), ('be', 'be'), ('able', 'able'), ('to', 'to'), ('reach', 'reach'), ('in', 'in'), ('and', 'and'), ('tell', 'tell'), ('the', 'the'), ('software', 'software'), ('that', 'that'), ('“', "''"), ('first', 'first'), ('quarter', 'quarter'), ('”', "''"), ('is', 'be'), ('really', 'really'), ('just', 'just'), ('neutral', 'neutral'), (',', ','), ('despite', 'despite'), ('what', 'what'), ('it', 'it'), ('might', 'might'), ('think', 'think'), ('.', '.')] 

 Dependency tags are: 
>> [(('Sometimes', 'need'), 'advmod'), (('you', 'need'), 'nsubj'), (('just', 'need'), 'advmod'), (('need', 'root'), 'root'), (('to', 'able'), 'mark'), (('be', 'able'), 'cop'), (('able', 'need'), 'xcomp'), (('to', 'reach'), 'mark'), (('reach', 'able'), 'xcomp'), (('in', 'reach'), 'compound:prt'), (('and', 'tell'), 'cc'), (('tell', 'reach'), 'conj'), (('the', 'software'), 'det'), (('software', 'tell'), 'obj'), (('that', 'neutral'), 'mark'), (('“', 'quarter'), 'punct'), (('first', 'quarter'), 'amod'), (('quarter', 'neutral'), 'nsubj'), (('”', 'quarter'), 'punct'), (('is', 'neutral'), 'cop'), (('really', 'neutral'), 'advmod'), (('just', 'neutral'), 'advmod'), (('neutral', 'tell'), 'ccomp'), ((',', 'neutral'), 'punct'), (('despite', 'what'), 'case'), (('what', 'neutral'), 'obl'), (('it', 'think'), 'nsubj'), (('might', 'think'), 'aux'), (('think', 'what'), 'acl:relcl'), (('.', 'need'), 'punct')]

 Named Entites are: 
>> [('“first quarter', 'DATE')]

================================ Paragraph 170 =================================

CHART SOURCE: ThomsonOne; Bullion Management Group Inc.,   http://bmg-group.com/2008-financial-crisis/ 


------------------- Sentence 1 -------------------

 CHART SOURCE: Thomson 

Tokens are: 
>> ['CHART', 'SOURCE', ':', 'Thomson'] 

 UPOS tags are: 
>> [('CHART', 'NOUN'), ('SOURCE', 'NOUN'), (':', 'PUNCT'), ('Thomson', 'PROPN')] 

 XPOS tags are: 
>> [('CHART', 'NN'), ('SOURCE', 'NN'), (':', ':'), ('Thomson', 'NNP')] 

 Lemmas are: 
>> [('CHART', 'chart'), ('SOURCE', 'source'), (':', ':'), ('Thomson', 'Thomson')] 

 Dependency tags are: 
>> [(('CHART', 'SOURCE'), 'compound'), (('SOURCE', 'root'), 'root'), ((':', 'SOURCE'), 'punct'), (('Thomson', 'SOURCE'), 'appos')]

 Named Entites are: 
>> [('Thomson', 'ORG')]

------------------- Sentence 2 -------------------

 One; Bullion Management Group Inc.,   http://bmg-group.com/2008-financial-crisis/ 

Tokens are: 
>> ['One', ';', 'Bullion', 'Management', 'Group', 'Inc.', ',', 'http://bmg-group.com/2008-financial-crisis/'] 

 UPOS tags are: 
>> [('One', 'NUM'), (';', 'PUNCT'), ('Bullion', 'NOUN'), ('Management', 'NOUN'), ('Group', 'NOUN'), ('Inc.', 'PROPN'), (',', 'PUNCT'), ('http://bmg-group.com/2008-financial-crisis/', 'X')] 

 XPOS tags are: 
>> [('One', 'CD'), (';', ','), ('Bullion', 'NN'), ('Management', 'NN'), ('Group', 'NN'), ('Inc.', 'NNP'), (',', ','), ('http://bmg-group.com/2008-financial-crisis/', 'ADD')] 

 Lemmas are: 
>> [('One', 'one'), (';', ';'), ('Bullion', 'bullion'), ('Management', 'management'), ('Group', 'group'), ('Inc.', 'Inc.'), (',', ','), ('http://bmg-group.com/2008-financial-crisis/', 'http://bmg-group.com/2008-financial-crisis/')] 

 Dependency tags are: 
>> [(('One', 'root'), 'root'), ((';', 'One'), 'punct'), (('Bullion', 'Inc.'), 'compound'), (('Management', 'Inc.'), 'compound'), (('Group', 'Inc.'), 'compound'), (('Inc.', 'One'), 'appos'), ((',', 'Inc.'), 'punct'), (('http://bmg-group.com/2008-financial-crisis/', 'Inc.'), 'appos')]

 Named Entites are: 
>> [('One', 'CARDINAL'), ('Bullion Management Group Inc.', 'ORG')]

================================ Paragraph 171 =================================

can have many   


------------------- Sentence 1 -------------------

 can have many 

Tokens are: 
>> ['can', 'have', 'many'] 

 UPOS tags are: 
>> [('can', 'AUX'), ('have', 'VERB'), ('many', 'ADJ')] 

 XPOS tags are: 
>> [('can', 'MD'), ('have', 'VB'), ('many', 'JJ')] 

 Lemmas are: 
>> [('can', 'can'), ('have', 'have'), ('many', 'many')] 

 Dependency tags are: 
>> [(('can', 'have'), 'aux'), (('have', 'root'), 'root'), (('many', 'have'), 'obj')]

 Named Entites are: 
>> []

================================ Paragraph 172 =================================

unforeseen side-effects. 


------------------- Sentence 1 -------------------

 unforeseen side-effects. 

Tokens are: 
>> ['unforeseen', 'side-effects', '.'] 

 UPOS tags are: 
>> [('unforeseen', 'ADJ'), ('side-effects', 'NOUN'), ('.', 'PUNCT')] 

 XPOS tags are: 
>> [('unforeseen', 'JJ'), ('side-effects', 'NNS'), ('.', '.')] 

 Lemmas are: 
>> [('unforeseen', 'unforeseen'), ('side-effects', 'side-effects'), ('.', '.')] 

 Dependency tags are: 
>> [(('unforeseen', 'side-effects'), 'amod'), (('side-effects', 'root'), 'root'), (('.', 'side-effects'), 'punct')]

 Named Entites are: 
>> []

================================ Paragraph 173 =================================

Training  a model


------------------- Sentence 1 -------------------

 Training  a model 

Tokens are: 
>> ['Training', 'a', 'model'] 

 UPOS tags are: 
>> [('Training', 'VERB'), ('a', 'DET'), ('model', 'NOUN')] 

 XPOS tags are: 
>> [('Training', 'VBG'), ('a', 'DT'), ('model', 'NN')] 

 Lemmas are: 
>> [('Training', 'train'), ('a', 'a'), ('model', 'model')] 

 Dependency tags are: 
>> [(('Training', 'root'), 'root'), (('a', 'model'), 'det'), (('model', 'Training'), 'obj')]

 Named Entites are: 
>> []

================================ Paragraph 174 =================================

W H I T E  P A P E R 


------------------- Sentence 1 -------------------

 W H I T E  P A P E R 

Tokens are: 
>> ['W', 'H', 'I', 'T', 'E', 'P', 'A', 'P', 'E', 'R'] 

 UPOS tags are: 
>> [('W', 'PROPN'), ('H', 'PUNCT'), ('I', 'PRON'), ('T', 'AUX'), ('E', 'PROPN'), ('P', 'NOUN'), ('A', 'NOUN'), ('P', 'NOUN'), ('E', 'NOUN'), ('R', 'NOUN')] 

 XPOS tags are: 
>> [('W', 'NNP'), ('H', ','), ('I', 'PRP'), ('T', 'VBP'), ('E', 'NNP'), ('P', 'NN'), ('A', 'NN'), ('P', 'NN'), ('E', 'NN'), ('R', 'NN')] 

 Lemmas are: 
>> [('W', 'W'), ('H', 'H'), ('I', 'I'), ('T', 'T'), ('E', 'E'), ('P', 'p'), ('A', 'a'), ('P', 'p'), ('E', 'e'), ('R', 'R')] 

 Dependency tags are: 
>> [(('W', 'T'), 'vocative'), (('H', 'W'), 'punct'), (('I', 'T'), 'nsubj'), (('T', 'root'), 'root'), (('E', 'T'), 'obj'), (('P', 'T'), 'obj'), (('A', 'E'), 'compound'), (('P', 'E'), 'compound'), (('E', 'R'), 'compound'), (('R', 'T'), 'obj')]

 Named Entites are: 
>> []

================================ Paragraph 175 =================================

14|       |   Lexalytics, Inc., 48 North Pleasant St. Unit 301, Amherst MA 01002 USA   |   1-800-377-8036 |   www.lexalytics.com 


------------------- Sentence 1 -------------------

 14|       |   Lexalytics, Inc., 48 North Pleasant St. Unit 301, Amherst MA 01002 USA   |   1-800-377-8036 |   www.lexalytics.com 

Tokens are: 
>> ['14', '|', '|', 'Lexalytics', ',', 'Inc.', ',', '48', 'North', 'Pleasant', 'St.', 'Unit', '301', ',', 'Amherst', 'MA', '01002', 'USA', '|', '1-800-377-8036', '|', 'www.lexalytics.com'] 

 UPOS tags are: 
>> [('14', 'NUM'), ('|', 'PUNCT'), ('|', 'PUNCT'), ('Lexalytics', 'PROPN'), (',', 'PUNCT'), ('Inc.', 'PROPN'), (',', 'PUNCT'), ('48', 'NUM'), ('North', 'PROPN'), ('Pleasant', 'ADJ'), ('St.', 'PROPN'), ('Unit', 'PROPN'), ('301', 'NUM'), (',', 'PUNCT'), ('Amherst', 'PROPN'), ('MA', 'PROPN'), ('01002', 'NUM'), ('USA', 'PROPN'), ('|', 'PUNCT'), ('1-800-377-8036', 'NUM'), ('|', 'PUNCT'), ('www.lexalytics.com', 'X')] 

 XPOS tags are: 
>> [('14', 'CD'), ('|', 'NFP'), ('|', 'NFP'), ('Lexalytics', 'NNP'), (',', ','), ('Inc.', 'NNP'), (',', ','), ('48', 'CD'), ('North', 'NNP'), ('Pleasant', 'NNP'), ('St.', 'NNP'), ('Unit', 'NNP'), ('301', 'CD'), (',', ','), ('Amherst', 'NNP'), ('MA', 'NNP'), ('01002', 'CD'), ('USA', 'NNP'), ('|', 'NFP'), ('1-800-377-8036', 'CD'), ('|', 'NFP'), ('www.lexalytics.com', 'ADD')] 

 Lemmas are: 
>> [('14', '14'), ('|', '|'), ('|', '|'), ('Lexalytics', 'Lexalytics'), (',', ','), ('Inc.', 'Inc.'), (',', ','), ('48', '48'), ('North', 'North'), ('Pleasant', 'Pleasant'), ('St.', 'St.'), ('Unit', 'unit'), ('301', '301'), (',', ','), ('Amherst', 'Amherst'), ('MA', 'MA'), ('01002', '01002'), ('USA', 'USA'), ('|', '|'), ('1-800-377-8036', '1-800-377-8036'), ('|', '|'), ('www.lexalytics.com', 'www.lexalytics.com')] 

 Dependency tags are: 
>> [(('14', 'root'), 'root'), (('|', '14'), 'punct'), (('|', '14'), 'punct'), (('Lexalytics', 'Inc.'), 'compound'), ((',', 'Inc.'), 'punct'), (('Inc.', '14'), 'appos'), ((',', 'Inc.'), 'punct'), (('48', 'St.'), 'nummod'), (('North', 'St.'), 'compound'), (('Pleasant', 'St.'), 'amod'), (('St.', 'Unit'), 'compound'), (('Unit', 'Inc.'), 'list'), (('301', 'Unit'), 'nummod'), ((',', 'MA'), 'punct'), (('Amherst', 'MA'), 'appos'), (('MA', 'Unit'), 'appos'), (('01002', 'USA'), 'nummod'), (('USA', 'MA'), 'appos'), (('|', 'USA'), 'punct'), (('1-800-377-8036', '14'), 'list'), (('|', '1-800-377-8036'), 'punct'), (('www.lexalytics.com', '14'), 'parataxis')]

 Named Entites are: 
>> [('14|       |   Lexalytics, Inc.', 'ORG'), ('301', 'CARDINAL'), ('Amherst', 'GPE')]

================================ Paragraph 176 =================================

S U M M A R Y  /  C O N C L U S I O N  Text analytics is arguably one of the most complex tasks for an AI.   Language is messy and complex. Meaning varies from speaker to speaker  and listener to listener. Machine learning provides a rich solution set for  handling this complexity, but must be implemented in a way that’s relevant  to the problem – and hand-in-hand with natural language processing code. 


------------------- Sentence 1 -------------------

 S U M M A R Y  /  C O N C L U S I O N  Text analytics is arguably one of the most complex tasks for an AI. 

Tokens are: 
>> ['S', 'U', 'M', 'M', 'A', 'R', 'Y', '/', 'C', 'O', 'N', 'C', 'L', 'U', 'S', 'I', 'O', 'N', 'Text', 'analytics', 'is', 'arguably', 'one', 'of', 'the', 'most', 'complex', 'tasks', 'for', 'an', 'AI', '.'] 

 UPOS tags are: 
>> [('S', 'PRON'), ('U', 'NOUN'), ('M', 'NOUN'), ('M', 'NOUN'), ('A', 'PROPN'), ('R', 'PROPN'), ('Y', 'PROPN'), ('/', 'PUNCT'), ('C', 'PROPN'), ('O', 'PROPN'), ('N', 'PROPN'), ('C', 'PROPN'), ('L', 'PROPN'), ('U', 'PROPN'), ('S', 'PART'), ('I', 'PRON'), ('O', 'ADP'), ('N', 'PROPN'), ('Text', 'PROPN'), ('analytics', 'NOUN'), ('is', 'AUX'), ('arguably', 'ADV'), ('one', 'NUM'), ('of', 'ADP'), ('the', 'DET'), ('most', 'ADV'), ('complex', 'ADJ'), ('tasks', 'NOUN'), ('for', 'ADP'), ('an', 'DET'), ('AI', 'NOUN'), ('.', 'PUNCT')] 

 XPOS tags are: 
>> [('S', 'PRP'), ('U', 'NN'), ('M', 'NN'), ('M', 'NN'), ('A', 'NNP'), ('R', 'NNP'), ('Y', 'NNP'), ('/', ','), ('C', 'NNP'), ('O', 'NNP'), ('N', 'NNP'), ('C', 'NNP'), ('L', 'NNP'), ('U', 'NNP'), ('S', 'POS'), ('I', 'PRP'), ('O', 'IN'), ('N', 'NNP'), ('Text', 'NNP'), ('analytics', 'NN'), ('is', 'VBZ'), ('arguably', 'RB'), ('one', 'CD'), ('of', 'IN'), ('the', 'DT'), ('most', 'RBS'), ('complex', 'JJ'), ('tasks', 'NNS'), ('for', 'IN'), ('an', 'DT'), ('AI', 'NN'), ('.', '.')] 

 Lemmas are: 
>> [('S', 'S'), ('U', 'U'), ('M', 'm'), ('M', 'm'), ('A', 'A'), ('R', 'R'), ('Y', 'Y'), ('/', '/'), ('C', 'C'), ('O', 'o'), ('N', 'N'), ('C', 'C'), ('L', 'L'), ('U', 'U'), ('S', "'s"), ('I', 'I'), ('O', 'of'), ('N', 'N'), ('Text', 'text'), ('analytics', 'analytic'), ('is', 'be'), ('arguably', 'arguably'), ('one', 'one'), ('of', 'of'), ('the', 'the'), ('most', 'most'), ('complex', 'complex'), ('tasks', 'task'), ('for', 'for'), ('an', 'a'), ('AI', 'ai'), ('.', '.')] 

 Dependency tags are: 
>> [(('S', 'one'), 'nsubj'), (('U', 'M'), 'compound'), (('M', 'M'), 'compound'), (('M', 'Y'), 'compound'), (('A', 'M'), 'compound'), (('R', 'Y'), 'compound'), (('Y', 'N'), 'compound'), (('/', 'N'), 'cc'), (('C', 'N'), 'compound'), (('O', 'N'), 'compound'), (('N', 'C'), 'compound'), (('C', 'I'), 'compound'), (('L', 'U'), 'compound'), (('U', 'C'), 'flat'), (('S', 'U'), 'case'), (('I', 'one'), 'nsubj'), (('O', 'analytics'), 'case'), (('N', 'analytics'), 'compound'), (('Text', 'analytics'), 'compound'), (('analytics', 'I'), 'nmod'), (('is', 'one'), 'cop'), (('arguably', 'one'), 'advmod'), (('one', 'root'), 'root'), (('of', 'tasks'), 'case'), (('the', 'tasks'), 'det'), (('most', 'complex'), 'advmod'), (('complex', 'tasks'), 'amod'), (('tasks', 'one'), 'nmod'), (('for', 'AI'), 'case'), (('an', 'AI'), 'det'), (('AI', 'tasks'), 'nmod'), (('.', 'one'), 'punct')]

 Named Entites are: 
>> []

------------------- Sentence 2 -------------------

 Language is messy and complex. 

Tokens are: 
>> ['Language', 'is', 'messy', 'and', 'complex', '.'] 

 UPOS tags are: 
>> [('Language', 'NOUN'), ('is', 'AUX'), ('messy', 'ADJ'), ('and', 'CCONJ'), ('complex', 'ADJ'), ('.', 'PUNCT')] 

 XPOS tags are: 
>> [('Language', 'NN'), ('is', 'VBZ'), ('messy', 'JJ'), ('and', 'CC'), ('complex', 'JJ'), ('.', '.')] 

 Lemmas are: 
>> [('Language', 'language'), ('is', 'be'), ('messy', 'messy'), ('and', 'and'), ('complex', 'complex'), ('.', '.')] 

 Dependency tags are: 
>> [(('Language', 'messy'), 'nsubj'), (('is', 'messy'), 'cop'), (('messy', 'root'), 'root'), (('and', 'complex'), 'cc'), (('complex', 'messy'), 'conj'), (('.', 'messy'), 'punct')]

 Named Entites are: 
>> []

------------------- Sentence 3 -------------------

 Meaning varies from speaker to speaker  and listener to listener. 

Tokens are: 
>> ['Meaning', 'varies', 'from', 'speaker', 'to', 'speaker', 'and', 'listener', 'to', 'listener', '.'] 

 UPOS tags are: 
>> [('Meaning', 'NOUN'), ('varies', 'VERB'), ('from', 'ADP'), ('speaker', 'NOUN'), ('to', 'ADP'), ('speaker', 'NOUN'), ('and', 'CCONJ'), ('listener', 'NOUN'), ('to', 'ADP'), ('listener', 'NOUN'), ('.', 'PUNCT')] 

 XPOS tags are: 
>> [('Meaning', 'NN'), ('varies', 'VBZ'), ('from', 'IN'), ('speaker', 'NN'), ('to', 'IN'), ('speaker', 'NN'), ('and', 'CC'), ('listener', 'NN'), ('to', 'IN'), ('listener', 'NN'), ('.', '.')] 

 Lemmas are: 
>> [('Meaning', 'meaning'), ('varies', 'vary'), ('from', 'from'), ('speaker', 'speaker'), ('to', 'to'), ('speaker', 'speaker'), ('and', 'and'), ('listener', 'listener'), ('to', 'to'), ('listener', 'listener'), ('.', '.')] 

 Dependency tags are: 
>> [(('Meaning', 'varies'), 'nsubj'), (('varies', 'root'), 'root'), (('from', 'speaker'), 'case'), (('speaker', 'varies'), 'obl'), (('to', 'speaker'), 'case'), (('speaker', 'varies'), 'obl'), (('and', 'listener'), 'cc'), (('listener', 'speaker'), 'conj'), (('to', 'listener'), 'case'), (('listener', 'varies'), 'obl'), (('.', 'varies'), 'punct')]

 Named Entites are: 
>> []

------------------- Sentence 4 -------------------

 Machine learning provides a rich solution set for  handling this complexity, but must be implemented in a way that’s relevant  to the problem – and hand-in-hand with natural language processing code. 

Tokens are: 
>> ['Machine', 'learning', 'provides', 'a', 'rich', 'solution', 'set', 'for', 'handling', 'this', 'complexity', ',', 'but', 'must', 'be', 'implemented', 'in', 'a', 'way', 'that', '’s', 'relevant', 'to', 'the', 'problem', '–', 'and', 'hand', '-', 'in', '-', 'hand', 'with', 'natural', 'language', 'processing', 'code', '.'] 

 UPOS tags are: 
>> [('Machine', 'NOUN'), ('learning', 'NOUN'), ('provides', 'VERB'), ('a', 'DET'), ('rich', 'ADJ'), ('solution', 'NOUN'), ('set', 'VERB'), ('for', 'SCONJ'), ('handling', 'VERB'), ('this', 'DET'), ('complexity', 'NOUN'), (',', 'PUNCT'), ('but', 'CCONJ'), ('must', 'AUX'), ('be', 'AUX'), ('implemented', 'VERB'), ('in', 'ADP'), ('a', 'DET'), ('way', 'NOUN'), ('that', 'PRON'), ('’s', 'AUX'), ('relevant', 'ADJ'), ('to', 'ADP'), ('the', 'DET'), ('problem', 'NOUN'), ('–', 'PUNCT'), ('and', 'CCONJ'), ('hand', 'NOUN'), ('-', 'PUNCT'), ('in', 'ADP'), ('-', 'PUNCT'), ('hand', 'NOUN'), ('with', 'ADP'), ('natural', 'ADJ'), ('language', 'NOUN'), ('processing', 'NOUN'), ('code', 'NOUN'), ('.', 'PUNCT')] 

 XPOS tags are: 
>> [('Machine', 'NN'), ('learning', 'NN'), ('provides', 'VBZ'), ('a', 'DT'), ('rich', 'JJ'), ('solution', 'NN'), ('set', 'VBN'), ('for', 'IN'), ('handling', 'VBG'), ('this', 'DT'), ('complexity', 'NN'), (',', ','), ('but', 'CC'), ('must', 'MD'), ('be', 'VB'), ('implemented', 'VBN'), ('in', 'IN'), ('a', 'DT'), ('way', 'NN'), ('that', 'WDT'), ('’s', 'VBZ'), ('relevant', 'JJ'), ('to', 'IN'), ('the', 'DT'), ('problem', 'NN'), ('–', ':'), ('and', 'CC'), ('hand', 'NN'), ('-', 'HYPH'), ('in', 'IN'), ('-', 'HYPH'), ('hand', 'NN'), ('with', 'IN'), ('natural', 'JJ'), ('language', 'NN'), ('processing', 'NN'), ('code', 'NN'), ('.', '.')] 

 Lemmas are: 
>> [('Machine', 'Machine'), ('learning', 'learning'), ('provides', 'provide'), ('a', 'a'), ('rich', 'rich'), ('solution', 'solution'), ('set', 'set'), ('for', 'for'), ('handling', 'handle'), ('this', 'this'), ('complexity', 'complexity'), (',', ','), ('but', 'but'), ('must', 'must'), ('be', 'be'), ('implemented', 'implement'), ('in', 'in'), ('a', 'a'), ('way', 'way'), ('that', 'that'), ('’s', 'be'), ('relevant', 'relevant'), ('to', 'to'), ('the', 'the'), ('problem', 'problem'), ('–', '-'), ('and', 'and'), ('hand', 'hand'), ('-', '-'), ('in', 'in'), ('-', '-'), ('hand', 'hand'), ('with', 'with'), ('natural', 'natural'), ('language', 'language'), ('processing', 'processing'), ('code', 'code'), ('.', '.')] 

 Dependency tags are: 
>> [(('Machine', 'learning'), 'compound'), (('learning', 'provides'), 'nsubj'), (('provides', 'root'), 'root'), (('a', 'solution'), 'det'), (('rich', 'solution'), 'amod'), (('solution', 'provides'), 'obj'), (('set', 'solution'), 'acl'), (('for', 'handling'), 'mark'), (('handling', 'set'), 'advcl'), (('this', 'complexity'), 'det'), (('complexity', 'handling'), 'obj'), ((',', 'implemented'), 'punct'), (('but', 'implemented'), 'cc'), (('must', 'implemented'), 'aux'), (('be', 'implemented'), 'aux:pass'), (('implemented', 'provides'), 'conj'), (('in', 'way'), 'case'), (('a', 'way'), 'det'), (('way', 'implemented'), 'obl'), (('that', 'relevant'), 'nsubj'), (('’s', 'relevant'), 'cop'), (('relevant', 'way'), 'acl:relcl'), (('to', 'problem'), 'case'), (('the', 'problem'), 'det'), (('problem', 'relevant'), 'obl'), (('–', 'hand'), 'punct'), (('and', 'hand'), 'cc'), (('hand', 'hand'), 'compound'), (('-', 'hand'), 'punct'), (('in', 'hand'), 'case'), (('-', 'hand'), 'punct'), (('hand', 'problem'), 'conj'), (('with', 'code'), 'case'), (('natural', 'code'), 'amod'), (('language', 'code'), 'compound'), (('processing', 'code'), 'compound'), (('code', 'hand'), 'nmod'), (('.', 'provides'), 'punct')]

 Named Entites are: 
>> []

================================ Paragraph 177 =================================

Moreover, although it’s necessary to use machine learning, it’s not sufficient  to use a single type of model, like a big “unsupervised learning” system.  Certain aspects of machine learning are very subjective, and need to be  trained or tuned to match your perspective. Lexalytics combines many   types of machine learning along with pure natural language processing code.  We have no prejudice for one algorithm over another except in how they  help us provide the best possible text analytics system to our customers. 


------------------- Sentence 1 -------------------

 Moreover, although it’s necessary to use machine learning, it’s not sufficient  to use a single type of model, like a big “unsupervised learning” system. 

Tokens are: 
>> ['Moreover', ',', 'although', 'it', '’s', 'necessary', 'to', 'use', 'machine', 'learning', ',', 'it', '’s', 'not', 'sufficient', 'to', 'use', 'a', 'single', 'type', 'of', 'model', ',', 'like', 'a', 'big', '“', 'unsupervised', 'learning', '”', 'system', '.'] 

 UPOS tags are: 
>> [('Moreover', 'ADV'), (',', 'PUNCT'), ('although', 'SCONJ'), ('it', 'PRON'), ('’s', 'AUX'), ('necessary', 'ADJ'), ('to', 'PART'), ('use', 'VERB'), ('machine', 'NOUN'), ('learning', 'NOUN'), (',', 'PUNCT'), ('it', 'PRON'), ('’s', 'AUX'), ('not', 'PART'), ('sufficient', 'ADJ'), ('to', 'PART'), ('use', 'VERB'), ('a', 'DET'), ('single', 'ADJ'), ('type', 'NOUN'), ('of', 'ADP'), ('model', 'NOUN'), (',', 'PUNCT'), ('like', 'ADP'), ('a', 'DET'), ('big', 'ADJ'), ('“', 'PUNCT'), ('unsupervised', 'ADJ'), ('learning', 'NOUN'), ('”', 'PUNCT'), ('system', 'NOUN'), ('.', 'PUNCT')] 

 XPOS tags are: 
>> [('Moreover', 'RB'), (',', ','), ('although', 'IN'), ('it', 'PRP'), ('’s', 'VBZ'), ('necessary', 'JJ'), ('to', 'TO'), ('use', 'VB'), ('machine', 'NN'), ('learning', 'NN'), (',', ','), ('it', 'PRP'), ('’s', 'VBZ'), ('not', 'RB'), ('sufficient', 'JJ'), ('to', 'TO'), ('use', 'VB'), ('a', 'DT'), ('single', 'JJ'), ('type', 'NN'), ('of', 'IN'), ('model', 'NN'), (',', ','), ('like', 'IN'), ('a', 'DT'), ('big', 'JJ'), ('“', '``'), ('unsupervised', 'JJ'), ('learning', 'NN'), ('”', "''"), ('system', 'NN'), ('.', '.')] 

 Lemmas are: 
>> [('Moreover', 'moreover'), (',', ','), ('although', 'although'), ('it', 'it'), ('’s', 'be'), ('necessary', 'necessary'), ('to', 'to'), ('use', 'use'), ('machine', 'machine'), ('learning', 'learning'), (',', ','), ('it', 'it'), ('’s', 'be'), ('not', 'not'), ('sufficient', 'sufficient'), ('to', 'to'), ('use', 'use'), ('a', 'a'), ('single', 'single'), ('type', 'type'), ('of', 'of'), ('model', 'model'), (',', ','), ('like', 'like'), ('a', 'a'), ('big', 'big'), ('“', "''"), ('unsupervised', 'unsupervised'), ('learning', 'learning'), ('”', "''"), ('system', 'system'), ('.', '.')] 

 Dependency tags are: 
>> [(('Moreover', 'sufficient'), 'advmod'), ((',', 'sufficient'), 'punct'), (('although', 'necessary'), 'mark'), (('it', 'necessary'), 'expl'), (('’s', 'necessary'), 'cop'), (('necessary', 'sufficient'), 'advcl'), (('to', 'use'), 'mark'), (('use', 'necessary'), 'csubj'), (('machine', 'learning'), 'compound'), (('learning', 'use'), 'obj'), ((',', 'sufficient'), 'punct'), (('it', 'sufficient'), 'expl'), (('’s', 'sufficient'), 'cop'), (('not', 'sufficient'), 'advmod'), (('sufficient', 'root'), 'root'), (('to', 'use'), 'mark'), (('use', 'sufficient'), 'csubj'), (('a', 'type'), 'det'), (('single', 'type'), 'amod'), (('type', 'use'), 'obj'), (('of', 'model'), 'case'), (('model', 'type'), 'nmod'), ((',', 'type'), 'punct'), (('like', 'system'), 'case'), (('a', 'system'), 'det'), (('big', 'system'), 'amod'), (('“', 'learning'), 'punct'), (('unsupervised', 'learning'), 'amod'), (('learning', 'system'), 'compound'), (('”', 'learning'), 'punct'), (('system', 'type'), 'nmod'), (('.', 'sufficient'), 'punct')]

 Named Entites are: 
>> []

------------------- Sentence 2 -------------------

 Certain aspects of machine learning are very subjective, and need to be  trained or tuned to match your perspective. 

Tokens are: 
>> ['Certain', 'aspects', 'of', 'machine', 'learning', 'are', 'very', 'subjective', ',', 'and', 'need', 'to', 'be', 'trained', 'or', 'tuned', 'to', 'match', 'your', 'perspective', '.'] 

 UPOS tags are: 
>> [('Certain', 'ADJ'), ('aspects', 'NOUN'), ('of', 'ADP'), ('machine', 'NOUN'), ('learning', 'NOUN'), ('are', 'AUX'), ('very', 'ADV'), ('subjective', 'ADJ'), (',', 'PUNCT'), ('and', 'CCONJ'), ('need', 'VERB'), ('to', 'PART'), ('be', 'AUX'), ('trained', 'VERB'), ('or', 'CCONJ'), ('tuned', 'VERB'), ('to', 'PART'), ('match', 'VERB'), ('your', 'PRON'), ('perspective', 'NOUN'), ('.', 'PUNCT')] 

 XPOS tags are: 
>> [('Certain', 'JJ'), ('aspects', 'NNS'), ('of', 'IN'), ('machine', 'NN'), ('learning', 'NN'), ('are', 'VBP'), ('very', 'RB'), ('subjective', 'JJ'), (',', ','), ('and', 'CC'), ('need', 'VBP'), ('to', 'TO'), ('be', 'VB'), ('trained', 'VBN'), ('or', 'CC'), ('tuned', 'VBN'), ('to', 'TO'), ('match', 'VB'), ('your', 'PRP$'), ('perspective', 'NN'), ('.', '.')] 

 Lemmas are: 
>> [('Certain', 'Certain'), ('aspects', 'aspect'), ('of', 'of'), ('machine', 'machine'), ('learning', 'learning'), ('are', 'be'), ('very', 'very'), ('subjective', 'subjective'), (',', ','), ('and', 'and'), ('need', 'need'), ('to', 'to'), ('be', 'be'), ('trained', 'train'), ('or', 'or'), ('tuned', 'tune'), ('to', 'to'), ('match', 'match'), ('your', 'you'), ('perspective', 'perspective'), ('.', '.')] 

 Dependency tags are: 
>> [(('Certain', 'aspects'), 'amod'), (('aspects', 'subjective'), 'nsubj'), (('of', 'learning'), 'case'), (('machine', 'learning'), 'compound'), (('learning', 'aspects'), 'nmod'), (('are', 'subjective'), 'cop'), (('very', 'subjective'), 'advmod'), (('subjective', 'root'), 'root'), ((',', 'need'), 'punct'), (('and', 'need'), 'cc'), (('need', 'subjective'), 'conj'), (('to', 'trained'), 'mark'), (('be', 'trained'), 'aux:pass'), (('trained', 'need'), 'xcomp'), (('or', 'tuned'), 'cc'), (('tuned', 'trained'), 'conj'), (('to', 'match'), 'mark'), (('match', 'trained'), 'advcl'), (('your', 'perspective'), 'nmod:poss'), (('perspective', 'match'), 'obj'), (('.', 'subjective'), 'punct')]

 Named Entites are: 
>> []

------------------- Sentence 3 -------------------

 Lexalytics combines many   types of machine learning along with pure natural language processing code. 

Tokens are: 
>> ['Lexalytics', 'combines', 'many', 'types', 'of', 'machine', 'learning', 'along', 'with', 'pure', 'natural', 'language', 'processing', 'code', '.'] 

 UPOS tags are: 
>> [('Lexalytics', 'NOUN'), ('combines', 'VERB'), ('many', 'ADJ'), ('types', 'NOUN'), ('of', 'ADP'), ('machine', 'NOUN'), ('learning', 'VERB'), ('along', 'ADP'), ('with', 'ADP'), ('pure', 'ADJ'), ('natural', 'ADJ'), ('language', 'NOUN'), ('processing', 'NOUN'), ('code', 'NOUN'), ('.', 'PUNCT')] 

 XPOS tags are: 
>> [('Lexalytics', 'NNS'), ('combines', 'VBZ'), ('many', 'JJ'), ('types', 'NNS'), ('of', 'IN'), ('machine', 'NN'), ('learning', 'VBG'), ('along', 'IN'), ('with', 'IN'), ('pure', 'JJ'), ('natural', 'JJ'), ('language', 'NN'), ('processing', 'NN'), ('code', 'NN'), ('.', '.')] 

 Lemmas are: 
>> [('Lexalytics', 'lexalytics'), ('combines', 'combine'), ('many', 'many'), ('types', 'type'), ('of', 'of'), ('machine', 'machine'), ('learning', 'learn'), ('along', 'along'), ('with', 'with'), ('pure', 'pure'), ('natural', 'natural'), ('language', 'language'), ('processing', 'processing'), ('code', 'code'), ('.', '.')] 

 Dependency tags are: 
>> [(('Lexalytics', 'combines'), 'nsubj'), (('combines', 'root'), 'root'), (('many', 'types'), 'amod'), (('types', 'combines'), 'obj'), (('of', 'machine'), 'case'), (('machine', 'types'), 'nmod'), (('learning', 'machine'), 'acl'), (('along', 'code'), 'case'), (('with', 'code'), 'case'), (('pure', 'code'), 'amod'), (('natural', 'code'), 'amod'), (('language', 'processing'), 'compound'), (('processing', 'code'), 'compound'), (('code', 'learning'), 'obl'), (('.', 'combines'), 'punct')]

 Named Entites are: 
>> []

------------------- Sentence 4 -------------------

 We have no prejudice for one algorithm over another except in how they  help us provide the best possible text analytics system to our customers. 

Tokens are: 
>> ['We', 'have', 'no', 'prejudice', 'for', 'one', 'algorithm', 'over', 'another', 'except', 'in', 'how', 'they', 'help', 'us', 'provide', 'the', 'best', 'possible', 'text', 'analytics', 'system', 'to', 'our', 'customers', '.'] 

 UPOS tags are: 
>> [('We', 'PRON'), ('have', 'VERB'), ('no', 'DET'), ('prejudice', 'NOUN'), ('for', 'ADP'), ('one', 'NUM'), ('algorithm', 'NOUN'), ('over', 'ADP'), ('another', 'DET'), ('except', 'ADP'), ('in', 'ADP'), ('how', 'SCONJ'), ('they', 'PRON'), ('help', 'VERB'), ('us', 'PRON'), ('provide', 'VERB'), ('the', 'DET'), ('best', 'ADJ'), ('possible', 'ADJ'), ('text', 'NOUN'), ('analytics', 'NOUN'), ('system', 'NOUN'), ('to', 'ADP'), ('our', 'PRON'), ('customers', 'NOUN'), ('.', 'PUNCT')] 

 XPOS tags are: 
>> [('We', 'PRP'), ('have', 'VBP'), ('no', 'DT'), ('prejudice', 'NN'), ('for', 'IN'), ('one', 'CD'), ('algorithm', 'NN'), ('over', 'IN'), ('another', 'DT'), ('except', 'IN'), ('in', 'IN'), ('how', 'WRB'), ('they', 'PRP'), ('help', 'VBP'), ('us', 'PRP'), ('provide', 'VB'), ('the', 'DT'), ('best', 'JJS'), ('possible', 'JJ'), ('text', 'NN'), ('analytics', 'NN'), ('system', 'NN'), ('to', 'IN'), ('our', 'PRP$'), ('customers', 'NNS'), ('.', '.')] 

 Lemmas are: 
>> [('We', 'we'), ('have', 'have'), ('no', 'no'), ('prejudice', 'prejudice'), ('for', 'for'), ('one', 'one'), ('algorithm', 'algorithm'), ('over', 'over'), ('another', 'another'), ('except', 'except'), ('in', 'in'), ('how', 'how'), ('they', 'they'), ('help', 'help'), ('us', 'we'), ('provide', 'provide'), ('the', 'the'), ('best', 'good'), ('possible', 'possible'), ('text', 'text'), ('analytics', 'analytic'), ('system', 'system'), ('to', 'to'), ('our', 'we'), ('customers', 'customer'), ('.', '.')] 

 Dependency tags are: 
>> [(('We', 'have'), 'nsubj'), (('have', 'root'), 'root'), (('no', 'prejudice'), 'det'), (('prejudice', 'have'), 'obj'), (('for', 'algorithm'), 'case'), (('one', 'algorithm'), 'nummod'), (('algorithm', 'prejudice'), 'nmod'), (('over', 'another'), 'case'), (('another', 'algorithm'), 'nmod'), (('except', 'how'), 'case'), (('in', 'how'), 'case'), (('how', 'help'), 'mark'), (('they', 'help'), 'nsubj'), (('help', 'have'), 'advcl'), (('us', 'help'), 'obj'), (('provide', 'help'), 'xcomp'), (('the', 'system'), 'det'), (('best', 'system'), 'amod'), (('possible', 'system'), 'amod'), (('text', 'analytics'), 'compound'), (('analytics', 'system'), 'compound'), (('system', 'provide'), 'obj'), (('to', 'customers'), 'case'), (('our', 'customers'), 'nmod:poss'), (('customers', 'system'), 'nmod'), (('.', 'have'), 'punct')]

 Named Entites are: 
>> [('one', 'CARDINAL')]

================================ Paragraph 178 =================================

to explore how Lexalytics   


------------------- Sentence 1 -------------------

 to explore how Lexalytics 

Tokens are: 
>> ['to', 'explore', 'how', 'Lexalytics'] 

 UPOS tags are: 
>> [('to', 'PART'), ('explore', 'VERB'), ('how', 'SCONJ'), ('Lexalytics', 'PROPN')] 

 XPOS tags are: 
>> [('to', 'TO'), ('explore', 'VB'), ('how', 'WRB'), ('Lexalytics', 'NNPS')] 

 Lemmas are: 
>> [('to', 'to'), ('explore', 'explore'), ('how', 'how'), ('Lexalytics', 'Lexalytics')] 

 Dependency tags are: 
>> [(('to', 'explore'), 'mark'), (('explore', 'root'), 'root'), (('how', 'Lexalytics'), 'mark'), (('Lexalytics', 'explore'), 'obj')]

 Named Entites are: 
>> [('Lexalytics', 'PERSON')]

================================ Paragraph 179 =================================

can help your business at  


------------------- Sentence 1 -------------------

 can help your business at 

Tokens are: 
>> ['can', 'help', 'your', 'business', 'at'] 

 UPOS tags are: 
>> [('can', 'AUX'), ('help', 'VERB'), ('your', 'PRON'), ('business', 'NOUN'), ('at', 'ADP')] 

 XPOS tags are: 
>> [('can', 'MD'), ('help', 'VB'), ('your', 'PRP$'), ('business', 'NN'), ('at', 'IN')] 

 Lemmas are: 
>> [('can', 'can'), ('help', 'help'), ('your', 'you'), ('business', 'business'), ('at', 'at')] 

 Dependency tags are: 
>> [(('can', 'help'), 'aux'), (('help', 'root'), 'root'), (('your', 'business'), 'nmod:poss'), (('business', 'help'), 'obj'), (('at', 'help'), 'advmod')]

 Named Entites are: 
>> []

================================ Paragraph 180 =================================

lexalytics.com/contact 


------------------- Sentence 1 -------------------

 lexalytics.com/contact 

Tokens are: 
>> ['lexalytics.com/contact'] 

 UPOS tags are: 
>> [('lexalytics.com/contact', 'X')] 

 XPOS tags are: 
>> [('lexalytics.com/contact', 'ADD')] 

 Lemmas are: 
>> [('lexalytics.com/contact', 'lexalytics.com/contact')] 

 Dependency tags are: 
>> [(('lexalytics.com/contact', 'root'), 'root')]

 Named Entites are: 
>> []

================================ Paragraph 181 =================================

Contact  us


------------------- Sentence 1 -------------------

 Contact  us 

Tokens are: 
>> ['Contact', 'us'] 

 UPOS tags are: 
>> [('Contact', 'VERB'), ('us', 'PRON')] 

 XPOS tags are: 
>> [('Contact', 'VB'), ('us', 'PRP')] 

 Lemmas are: 
>> [('Contact', 'contact'), ('us', 'we')] 

 Dependency tags are: 
>> [(('Contact', 'root'), 'root'), (('us', 'Contact'), 'obj')]

 Named Entites are: 
>> []

================================ Paragraph 182 =================================

©  2019 Lexalytics, Inc. | M 


------------------- Sentence 1 -------------------

 ©  2019 Lexalytics, Inc. | M 

Tokens are: 
>> ['©', '2019', 'Lexalytics', ',', 'Inc.', '|', 'M'] 

 UPOS tags are: 
>> [('©', 'ADP'), ('2019', 'NUM'), ('Lexalytics', 'PROPN'), (',', 'PUNCT'), ('Inc.', 'PROPN'), ('|', 'PUNCT'), ('M', 'PROPN')] 

 XPOS tags are: 
>> [('©', 'IN'), ('2019', 'CD'), ('Lexalytics', 'NNP'), (',', ','), ('Inc.', 'NNP'), ('|', ','), ('M', 'NNP')] 

 Lemmas are: 
>> [('©', 'at'), ('2019', '2019'), ('Lexalytics', 'Lexalytics'), (',', ','), ('Inc.', 'Inc.'), ('|', '|'), ('M', 'M')] 

 Dependency tags are: 
>> [(('©', 'Inc.'), 'case'), (('2019', 'Inc.'), 'nummod'), (('Lexalytics', 'Inc.'), 'compound'), ((',', 'Inc.'), 'punct'), (('Inc.', 'M'), 'compound'), (('|', 'M'), 'punct'), (('M', 'root'), 'root')]

 Named Entites are: 
>> [('2019', 'DATE')]

================================ Paragraph 183 =================================

achine Learning W hite Paper | v3c 


------------------- Sentence 1 -------------------

 achine Learning W hite Paper | v3c 

Tokens are: 
>> ['achine', 'Learning', 'W', 'hite', 'Paper', '|', 'v3', 'c'] 

 UPOS tags are: 
>> [('achine', 'PROPN'), ('Learning', 'PROPN'), ('W', 'PROPN'), ('hite', 'PROPN'), ('Paper', 'PROPN'), ('|', 'PUNCT'), ('v3', 'PROPN'), ('c', 'PUNCT')] 

 XPOS tags are: 
>> [('achine', 'NNP'), ('Learning', 'NNP'), ('W', 'NNP'), ('hite', 'NNP'), ('Paper', 'NNP'), ('|', ','), ('v3', 'NNP'), ('c', '.')] 

 Lemmas are: 
>> [('achine', 'achine'), ('Learning', 'learning'), ('W', 'W'), ('hite', 'hite'), ('Paper', 'Paper'), ('|', '|'), ('v3', 'v3'), ('c', 'c')] 

 Dependency tags are: 
>> [(('achine', 'Paper'), 'compound'), (('Learning', 'Paper'), 'compound'), (('W', 'Paper'), 'compound'), (('hite', 'Paper'), 'compound'), (('Paper', 'root'), 'root'), (('|', 'Paper'), 'punct'), (('v3', 'Paper'), 'appos'), (('c', 'Paper'), 'punct')]

 Named Entites are: 
>> []

================================ Paragraph 184 =================================

Lexalytics processes BILLIONS of   unstructured documents every day, GLOBALLY. We transform unstructured text into usable data and powerful stories. 


------------------- Sentence 1 -------------------

 Lexalytics processes BILLIONS of   unstructured documents every day, GLOBALLY. 

Tokens are: 
>> ['Lexalytics', 'processes', 'BILLIONS', 'of', 'unstructured', 'documents', 'every', 'day', ',', 'GLOBALLY', '.'] 

 UPOS tags are: 
>> [('Lexalytics', 'NOUN'), ('processes', 'VERB'), ('BILLIONS', 'NOUN'), ('of', 'ADP'), ('unstructured', 'ADJ'), ('documents', 'NOUN'), ('every', 'DET'), ('day', 'NOUN'), (',', 'PUNCT'), ('GLOBALLY', 'ADV'), ('.', 'PUNCT')] 

 XPOS tags are: 
>> [('Lexalytics', 'NNS'), ('processes', 'VBZ'), ('BILLIONS', 'NNS'), ('of', 'IN'), ('unstructured', 'JJ'), ('documents', 'NNS'), ('every', 'DT'), ('day', 'NN'), (',', ','), ('GLOBALLY', 'RB'), ('.', '.')] 

 Lemmas are: 
>> [('Lexalytics', 'lexalytics'), ('processes', 'process'), ('BILLIONS', 'billion'), ('of', 'of'), ('unstructured', 'unstructured'), ('documents', 'document'), ('every', 'every'), ('day', 'day'), (',', ','), ('GLOBALLY', 'globally'), ('.', '.')] 

 Dependency tags are: 
>> [(('Lexalytics', 'processes'), 'nsubj'), (('processes', 'root'), 'root'), (('BILLIONS', 'processes'), 'obj'), (('of', 'documents'), 'case'), (('unstructured', 'documents'), 'amod'), (('documents', 'BILLIONS'), 'nmod'), (('every', 'day'), 'det'), (('day', 'processes'), 'obl:tmod'), ((',', 'processes'), 'punct'), (('GLOBALLY', 'processes'), 'advmod'), (('.', 'processes'), 'punct')]

 Named Entites are: 
>> []

------------------- Sentence 2 -------------------

 We transform unstructured text into usable data and powerful stories. 

Tokens are: 
>> ['We', 'transform', 'unstructured', 'text', 'into', 'usable', 'data', 'and', 'powerful', 'stories', '.'] 

 UPOS tags are: 
>> [('We', 'PRON'), ('transform', 'VERB'), ('unstructured', 'ADJ'), ('text', 'NOUN'), ('into', 'ADP'), ('usable', 'ADJ'), ('data', 'NOUN'), ('and', 'CCONJ'), ('powerful', 'ADJ'), ('stories', 'NOUN'), ('.', 'PUNCT')] 

 XPOS tags are: 
>> [('We', 'PRP'), ('transform', 'VBP'), ('unstructured', 'JJ'), ('text', 'NN'), ('into', 'IN'), ('usable', 'JJ'), ('data', 'NNS'), ('and', 'CC'), ('powerful', 'JJ'), ('stories', 'NNS'), ('.', '.')] 

 Lemmas are: 
>> [('We', 'we'), ('transform', 'transform'), ('unstructured', 'unstructured'), ('text', 'text'), ('into', 'into'), ('usable', 'usable'), ('data', 'datum'), ('and', 'and'), ('powerful', 'powerful'), ('stories', 'story'), ('.', '.')] 

 Dependency tags are: 
>> [(('We', 'transform'), 'nsubj'), (('transform', 'root'), 'root'), (('unstructured', 'text'), 'amod'), (('text', 'transform'), 'obj'), (('into', 'data'), 'case'), (('usable', 'data'), 'amod'), (('data', 'transform'), 'obl'), (('and', 'stories'), 'cc'), (('powerful', 'stories'), 'amod'), (('stories', 'data'), 'conj'), (('.', 'transform'), 'punct')]

 Named Entites are: 
>> []

================================ Paragraph 185 =================================

Our on-premise Salience® engine, SaaS Semantria® API, and end-to-end Lexalytics  Intelligence Platform® combine natural language processing with artificial intelligence  to reveal context-rich patterns and insights within comments, reviews, surveys, and   other text documents.  


------------------- Sentence 1 -------------------

 Our on-premise Salience® engine, SaaS Semantria® API, and end-to-end Lexalytics  Intelligence Platform® combine natural language processing with artificial intelligence  to reveal context-rich patterns and insights within comments, reviews, surveys, and   other text documents. 

Tokens are: 
>> ['Our', 'on-', 'premise', 'Salience', '®', 'engine', ',', 'SaaS', 'Semantria®', 'API', ',', 'and', 'end', '-', 'to', '-', 'end', 'Lexalytics', 'Intelligence', 'Platform', '®', 'combine', 'natural', 'language', 'processing', 'with', 'artificial', 'intelligence', 'to', 'reveal', 'context-', 'rich', 'patterns', 'and', 'insights', 'within', 'comments', ',', 'reviews', ',', 'surveys', ',', 'and', 'other', 'text', 'documents', '.'] 

 UPOS tags are: 
>> [('Our', 'PRON'), ('on-', 'ADJ'), ('premise', 'NOUN'), ('Salience', 'NOUN'), ('®', 'NOUN'), ('engine', 'NOUN'), (',', 'PUNCT'), ('SaaS', 'PROPN'), ('Semantria®', 'PROPN'), ('API', 'PROPN'), (',', 'PUNCT'), ('and', 'CCONJ'), ('end', 'NOUN'), ('-', 'PUNCT'), ('to', 'ADP'), ('-', 'PUNCT'), ('end', 'NOUN'), ('Lexalytics', 'PROPN'), ('Intelligence', 'PROPN'), ('Platform', 'PROPN'), ('®', 'PART'), ('combine', 'VERB'), ('natural', 'ADJ'), ('language', 'NOUN'), ('processing', 'NOUN'), ('with', 'ADP'), ('artificial', 'ADJ'), ('intelligence', 'NOUN'), ('to', 'PART'), ('reveal', 'VERB'), ('context-', 'ADJ'), ('rich', 'ADJ'), ('patterns', 'NOUN'), ('and', 'CCONJ'), ('insights', 'NOUN'), ('within', 'ADP'), ('comments', 'NOUN'), (',', 'PUNCT'), ('reviews', 'NOUN'), (',', 'PUNCT'), ('surveys', 'NOUN'), (',', 'PUNCT'), ('and', 'CCONJ'), ('other', 'ADJ'), ('text', 'NOUN'), ('documents', 'NOUN'), ('.', 'PUNCT')] 

 XPOS tags are: 
>> [('Our', 'PRP$'), ('on-', 'JJ'), ('premise', 'NN'), ('Salience', 'NN'), ('®', 'NN'), ('engine', 'NN'), (',', ','), ('SaaS', 'NNP'), ('Semantria®', 'NNP'), ('API', 'NNP'), (',', ','), ('and', 'CC'), ('end', 'NN'), ('-', 'HYPH'), ('to', 'IN'), ('-', 'HYPH'), ('end', 'NN'), ('Lexalytics', 'NNPS'), ('Intelligence', 'NNP'), ('Platform', 'NNP'), ('®', 'TO'), ('combine', 'VB'), ('natural', 'JJ'), ('language', 'NN'), ('processing', 'NN'), ('with', 'IN'), ('artificial', 'JJ'), ('intelligence', 'NN'), ('to', 'TO'), ('reveal', 'VB'), ('context-', 'JJ'), ('rich', 'JJ'), ('patterns', 'NNS'), ('and', 'CC'), ('insights', 'NNS'), ('within', 'IN'), ('comments', 'NNS'), (',', ','), ('reviews', 'NNS'), (',', ','), ('surveys', 'NNS'), (',', ','), ('and', 'CC'), ('other', 'JJ'), ('text', 'NN'), ('documents', 'NNS'), ('.', '.')] 

 Lemmas are: 
>> [('Our', 'we'), ('on-', 'on-'), ('premise', 'premise'), ('Salience', 'salience'), ('®', '®'), ('engine', 'engine'), (',', ','), ('SaaS', 'SaaS'), ('Semantria®', 'Semantria®'), ('API', 'api'), (',', ','), ('and', 'and'), ('end', 'end'), ('-', '-'), ('to', 'to'), ('-', '-'), ('end', 'end'), ('Lexalytics', 'Lexalytics'), ('Intelligence', 'Intelligence'), ('Platform', 'Platform'), ('®', "'s"), ('combine', 'combine'), ('natural', 'natural'), ('language', 'language'), ('processing', 'processing'), ('with', 'with'), ('artificial', 'artificial'), ('intelligence', 'intelligence'), ('to', 'to'), ('reveal', 'reveal'), ('context-', 'context-'), ('rich', 'rich'), ('patterns', 'pattern'), ('and', 'and'), ('insights', 'insight'), ('within', 'within'), ('comments', 'comment'), (',', ','), ('reviews', 'review'), (',', ','), ('surveys', 'survey'), (',', ','), ('and', 'and'), ('other', 'other'), ('text', 'text'), ('documents', 'document'), ('.', '.')] 

 Dependency tags are: 
>> [(('Our', 'engine'), 'nmod:poss'), (('on-', 'premise'), 'amod'), (('premise', 'engine'), 'compound'), (('Salience', '®'), 'compound'), (('®', 'engine'), 'compound'), (('engine', 'combine'), 'nsubj'), ((',', 'API'), 'punct'), (('SaaS', 'API'), 'compound'), (('Semantria®', 'API'), 'compound'), (('API', 'engine'), 'conj'), ((',', 'Platform'), 'punct'), (('and', 'Platform'), 'cc'), (('end', 'Platform'), 'compound'), (('-', 'end'), 'punct'), (('to', 'end'), 'case'), (('-', 'end'), 'punct'), (('end', 'end'), 'nmod'), (('Lexalytics', 'Platform'), 'compound'), (('Intelligence', 'Platform'), 'compound'), (('Platform', 'engine'), 'conj'), (('®', 'Platform'), 'case'), (('combine', 'root'), 'root'), (('natural', 'processing'), 'amod'), (('language', 'processing'), 'compound'), (('processing', 'combine'), 'obj'), (('with', 'intelligence'), 'case'), (('artificial', 'intelligence'), 'amod'), (('intelligence', 'processing'), 'nmod'), (('to', 'reveal'), 'mark'), (('reveal', 'combine'), 'advcl'), (('context-', 'patterns'), 'amod'), (('rich', 'patterns'), 'amod'), (('patterns', 'reveal'), 'obj'), (('and', 'insights'), 'cc'), (('insights', 'patterns'), 'conj'), (('within', 'comments'), 'case'), (('comments', 'patterns'), 'nmod'), ((',', 'reviews'), 'punct'), (('reviews', 'comments'), 'conj'), ((',', 'surveys'), 'punct'), (('surveys', 'comments'), 'conj'), ((',', 'documents'), 'punct'), (('and', 'documents'), 'cc'), (('other', 'documents'), 'amod'), (('text', 'documents'), 'compound'), (('documents', 'comments'), 'conj'), (('.', 'combine'), 'punct')]

 Named Entites are: 
>> []

================================ Paragraph 186 =================================

Data analytics and data analyst companies rely on Lexalytics to build better  products, share insights between engineering, marketing, PR, and support teams,  and drive business growth. 


------------------- Sentence 1 -------------------

 Data analytics and data analyst companies rely on Lexalytics to build better  products, share insights between engineering, marketing, PR, and support teams,  and drive business growth. 

Tokens are: 
>> ['Data', 'analytics', 'and', 'data', 'analyst', 'companies', 'rely', 'on', 'Lexalytics', 'to', 'build', 'better', 'products', ',', 'share', 'insights', 'between', 'engineering', ',', 'marketing', ',', 'PR', ',', 'and', 'support', 'teams', ',', 'and', 'drive', 'business', 'growth', '.'] 

 UPOS tags are: 
>> [('Data', 'NOUN'), ('analytics', 'NOUN'), ('and', 'CCONJ'), ('data', 'NOUN'), ('analyst', 'NOUN'), ('companies', 'NOUN'), ('rely', 'VERB'), ('on', 'ADP'), ('Lexalytics', 'PROPN'), ('to', 'PART'), ('build', 'VERB'), ('better', 'ADJ'), ('products', 'NOUN'), (',', 'PUNCT'), ('share', 'VERB'), ('insights', 'NOUN'), ('between', 'ADP'), ('engineering', 'NOUN'), (',', 'PUNCT'), ('marketing', 'NOUN'), (',', 'PUNCT'), ('PR', 'NOUN'), (',', 'PUNCT'), ('and', 'CCONJ'), ('support', 'NOUN'), ('teams', 'NOUN'), (',', 'PUNCT'), ('and', 'CCONJ'), ('drive', 'VERB'), ('business', 'NOUN'), ('growth', 'NOUN'), ('.', 'PUNCT')] 

 XPOS tags are: 
>> [('Data', 'NN'), ('analytics', 'NNS'), ('and', 'CC'), ('data', 'NNS'), ('analyst', 'NN'), ('companies', 'NNS'), ('rely', 'VBP'), ('on', 'IN'), ('Lexalytics', 'NNPS'), ('to', 'TO'), ('build', 'VB'), ('better', 'JJR'), ('products', 'NNS'), (',', ','), ('share', 'VB'), ('insights', 'NNS'), ('between', 'IN'), ('engineering', 'NN'), (',', ','), ('marketing', 'NN'), (',', ','), ('PR', 'NN'), (',', ','), ('and', 'CC'), ('support', 'NN'), ('teams', 'NNS'), (',', ','), ('and', 'CC'), ('drive', 'VB'), ('business', 'NN'), ('growth', 'NN'), ('.', '.')] 

 Lemmas are: 
>> [('Data', 'data'), ('analytics', 'analytic'), ('and', 'and'), ('data', 'datum'), ('analyst', 'analyst'), ('companies', 'company'), ('rely', 'rely'), ('on', 'on'), ('Lexalytics', 'Lexalytics'), ('to', 'to'), ('build', 'build'), ('better', 'good'), ('products', 'product'), (',', ','), ('share', 'share'), ('insights', 'insight'), ('between', 'between'), ('engineering', 'engineering'), (',', ','), ('marketing', 'marketing'), (',', ','), ('PR', 'pr'), (',', ','), ('and', 'and'), ('support', 'support'), ('teams', 'team'), (',', ','), ('and', 'and'), ('drive', 'drive'), ('business', 'business'), ('growth', 'growth'), ('.', '.')] 

 Dependency tags are: 
>> [(('Data', 'analytics'), 'compound'), (('analytics', 'rely'), 'nsubj'), (('and', 'companies'), 'cc'), (('data', 'analyst'), 'compound'), (('analyst', 'companies'), 'compound'), (('companies', 'rely'), 'nsubj'), (('rely', 'root'), 'root'), (('on', 'Lexalytics'), 'case'), (('Lexalytics', 'rely'), 'obl'), (('to', 'build'), 'mark'), (('build', 'rely'), 'advcl'), (('better', 'products'), 'amod'), (('products', 'build'), 'obj'), ((',', 'share'), 'punct'), (('share', 'build'), 'conj'), (('insights', 'share'), 'obj'), (('between', 'engineering'), 'case'), (('engineering', 'insights'), 'nmod'), ((',', 'marketing'), 'punct'), (('marketing', 'engineering'), 'conj'), ((',', 'PR'), 'punct'), (('PR', 'engineering'), 'conj'), ((',', 'teams'), 'punct'), (('and', 'teams'), 'cc'), (('support', 'teams'), 'compound'), (('teams', 'engineering'), 'conj'), ((',', 'drive'), 'punct'), (('and', 'drive'), 'cc'), (('drive', 'build'), 'conj'), (('business', 'growth'), 'compound'), (('growth', 'drive'), 'obj'), (('.', 'rely'), 'punct')]

 Named Entites are: 
>> [('Lexalytics', 'ORG')]

================================ Paragraph 187 =================================

For more information, visit www.lexalytics.com or call 1-800-377-8036  


------------------- Sentence 1 -------------------

 For more information, visit www.lexalytics.com or call 1-800-377-8036 

Tokens are: 
>> ['For', 'more', 'information', ',', 'visit', 'www.lexalytics.com', 'or', 'call', '1-800-377-8036'] 

 UPOS tags are: 
>> [('For', 'ADP'), ('more', 'ADJ'), ('information', 'NOUN'), (',', 'PUNCT'), ('visit', 'VERB'), ('www.lexalytics.com', 'X'), ('or', 'CCONJ'), ('call', 'VERB'), ('1-800-377-8036', 'NUM')] 

 XPOS tags are: 
>> [('For', 'IN'), ('more', 'JJR'), ('information', 'NN'), (',', ','), ('visit', 'VB'), ('www.lexalytics.com', 'ADD'), ('or', 'CC'), ('call', 'VB'), ('1-800-377-8036', 'CD')] 

 Lemmas are: 
>> [('For', 'for'), ('more', 'more'), ('information', 'information'), (',', ','), ('visit', 'visit'), ('www.lexalytics.com', 'www.lexalytics.com'), ('or', 'or'), ('call', 'call'), ('1-800-377-8036', '1-800-377-8036')] 

 Dependency tags are: 
>> [(('For', 'information'), 'case'), (('more', 'information'), 'amod'), (('information', 'visit'), 'obl'), ((',', 'visit'), 'punct'), (('visit', 'root'), 'root'), (('www.lexalytics.com', 'visit'), 'obj'), (('or', 'call'), 'cc'), (('call', 'visit'), 'conj'), (('1-800-377-8036', 'call'), 'obj')]

 Named Entites are: 
>> [('1-800-377-8036', 'TIME')]

================================ Paragraph 188 =================================

W H I T E  P A P E R 


------------------- Sentence 1 -------------------

 W H I T E  P A P E R 

Tokens are: 
>> ['W', 'H', 'I', 'T', 'E', 'P', 'A', 'P', 'E', 'R'] 

 UPOS tags are: 
>> [('W', 'PROPN'), ('H', 'PUNCT'), ('I', 'PRON'), ('T', 'AUX'), ('E', 'PROPN'), ('P', 'NOUN'), ('A', 'NOUN'), ('P', 'NOUN'), ('E', 'NOUN'), ('R', 'NOUN')] 

 XPOS tags are: 
>> [('W', 'NNP'), ('H', ','), ('I', 'PRP'), ('T', 'VBP'), ('E', 'NNP'), ('P', 'NN'), ('A', 'NN'), ('P', 'NN'), ('E', 'NN'), ('R', 'NN')] 

 Lemmas are: 
>> [('W', 'W'), ('H', 'H'), ('I', 'I'), ('T', 'T'), ('E', 'E'), ('P', 'p'), ('A', 'a'), ('P', 'p'), ('E', 'e'), ('R', 'R')] 

 Dependency tags are: 
>> [(('W', 'T'), 'vocative'), (('H', 'W'), 'punct'), (('I', 'T'), 'nsubj'), (('T', 'root'), 'root'), (('E', 'T'), 'obj'), (('P', 'T'), 'obj'), (('A', 'E'), 'compound'), (('P', 'E'), 'compound'), (('E', 'R'), 'compound'), (('R', 'T'), 'obj')]

 Named Entites are: 
>> []

================================ Paragraph 189 =================================

15|       | Lexalytics, Inc., 48 North Pleasant St. Unit 301, Amherst MA 01002 USA | 1-800-377-8036 | www.lexalytics.com


------------------- Sentence 1 -------------------

 15|       | Lexalytics, Inc., 48 North Pleasant St. Unit 301, Amherst MA 01002 USA | 1-800-377-8036 | www.lexalytics.com 

Tokens are: 
>> ['15', '|', '|', 'Lexalytics', ',', 'Inc.', ',', '48', 'North', 'Pleasant', 'St.', 'Unit', '301', ',', 'Amherst', 'MA', '01002', 'USA', '|', '1-800-377-8036', '|', 'www.lexalytics.com'] 

 UPOS tags are: 
>> [('15', 'NUM'), ('|', 'PUNCT'), ('|', 'PUNCT'), ('Lexalytics', 'PROPN'), (',', 'PUNCT'), ('Inc.', 'PROPN'), (',', 'PUNCT'), ('48', 'NUM'), ('North', 'PROPN'), ('Pleasant', 'ADJ'), ('St.', 'PROPN'), ('Unit', 'PROPN'), ('301', 'NUM'), (',', 'PUNCT'), ('Amherst', 'PROPN'), ('MA', 'PROPN'), ('01002', 'NUM'), ('USA', 'PROPN'), ('|', 'PUNCT'), ('1-800-377-8036', 'NUM'), ('|', 'PUNCT'), ('www.lexalytics.com', 'X')] 

 XPOS tags are: 
>> [('15', 'CD'), ('|', 'NFP'), ('|', 'NFP'), ('Lexalytics', 'NNP'), (',', ','), ('Inc.', 'NNP'), (',', ','), ('48', 'CD'), ('North', 'NNP'), ('Pleasant', 'NNP'), ('St.', 'NNP'), ('Unit', 'NNP'), ('301', 'CD'), (',', ','), ('Amherst', 'NNP'), ('MA', 'NNP'), ('01002', 'CD'), ('USA', 'NNP'), ('|', 'NFP'), ('1-800-377-8036', 'CD'), ('|', 'NFP'), ('www.lexalytics.com', 'ADD')] 

 Lemmas are: 
>> [('15', '15'), ('|', '|'), ('|', '|'), ('Lexalytics', 'Lexalytics'), (',', ','), ('Inc.', 'Inc.'), (',', ','), ('48', '48'), ('North', 'North'), ('Pleasant', 'Pleasant'), ('St.', 'St.'), ('Unit', 'unit'), ('301', '301'), (',', ','), ('Amherst', 'Amherst'), ('MA', 'MA'), ('01002', '01002'), ('USA', 'USA'), ('|', '|'), ('1-800-377-8036', '1-800-377-8036'), ('|', '|'), ('www.lexalytics.com', 'www.lexalytics.com')] 

 Dependency tags are: 
>> [(('15', 'root'), 'root'), (('|', '15'), 'punct'), (('|', '15'), 'punct'), (('Lexalytics', 'Inc.'), 'compound'), ((',', 'Inc.'), 'punct'), (('Inc.', '15'), 'appos'), ((',', 'Inc.'), 'punct'), (('48', 'St.'), 'nummod'), (('North', 'St.'), 'compound'), (('Pleasant', 'St.'), 'amod'), (('St.', 'Unit'), 'compound'), (('Unit', 'Inc.'), 'list'), (('301', 'Unit'), 'nummod'), ((',', 'MA'), 'punct'), (('Amherst', 'MA'), 'appos'), (('MA', 'Unit'), 'appos'), (('01002', 'USA'), 'nummod'), (('USA', 'MA'), 'appos'), (('|', 'USA'), 'punct'), (('1-800-377-8036', '15'), 'list'), (('|', '1-800-377-8036'), 'punct'), (('www.lexalytics.com', '15'), 'parataxis')]

 Named Entites are: 
>> [('15|       | Lexalytics, Inc.', 'ORG'), ('301', 'CARDINAL'), ('Amherst', 'GPE')]